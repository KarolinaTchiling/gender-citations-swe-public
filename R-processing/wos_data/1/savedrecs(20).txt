FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Zeng, W
   Su, B
   Chen, Y
   Yuan, CZ
AF Zeng, Wei
   Su, Bo
   Chen, Yang
   Yuan, Chengzhi
TI Arrhythmia detection using TQWT, CEEMD and deep CNN-LSTM neural networks
   with ECG signals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electrocardiography (ECG); Arrhythmia detection; Tunable Q-factor
   wavelet transform (TQWT); Complete ensemble empirical mode decomposition
   (CEEMD); Convolutional neural networks (CNN); Long-short term memory
   (LSTM)
ID HEARTBEAT CLASSIFICATION; RECOGNITION; FEATURES; DIAGNOSIS; ENTROPY;
   FOREST; MODEL
AB Cardiac arrhythmia is a typically clinical manifestation of cardiovascular disease which leads to serious health problem. Detection of arrhythmia is traditionally relying on manual interpretation of electrocardiography (ECG) signals by cardiologists, which is time consuming and subjective. Therefore, development of an automated arrhythmia detection system with high accuracy becomes urgent in clinical applications. In the present study, we propose an effective deep learning model with one-lead ECG signals to automatically detect different types of arrhythmias based upon tunable Q-factor wavelet transform (TQWT) and complete ensemble empirical mode decomposition (CEEMD). First, TQWT decomposes the ECG signal into different frequency bands by using the input parameters (Q, R, and J) without any segmentation, which are used to extract the main subband with majority of the ECG signal's energy. Second, CEEMD is used to decompose the main subband of ECG signals into different intrinsic modes. It captures most part of the main subband's information, preserving important waveform features as a slightly asymmetry. It is employed to measure the variability of ECG signals. There is no need for the preprocessing of QRS detection. Then, they are selected as features and fed to combined neural networks consisting of one-dimensional (1D) convolutional neural networks (CNN) and long short-term memory (LSTM) networks for multi-class classification of cardiac arrhythmias. Finally, experiments are carried out on the well-known and publicly available MIT-BIH arrhythmia database to evaluate the performance of the proposed method, in which 744 ECG signal fragments for one lead (MLII) of seventeen classes of heart beats from 29 persons were extracted. By using 10-fold cross-validation style, the achieved average classification accuracy is reported to be 97.20%, 96.85%, 96.48% and 96.13%, respectively, for five-class, thirteen-class, fifteen-class and seventeen-class classification. Compared with other state-of-the-art methods, the results demonstrate superior performance and the proposed method has the potential to serve as a candidate for the automatic detection of myocardial dysfunction in the clinical ECG examination.
C1 [Zeng, Wei; Su, Bo; Chen, Yang] Longyan Univ, Sch Phys & Mech & Elect Engn, Longyan 364012, Peoples R China.
   [Zeng, Wei; Su, Bo; Chen, Yang] Fuzhou Univ, Sch Mech Engn & Automat, Fuzhou 350116, Peoples R China.
   [Yuan, Chengzhi] Univ Rhode Isl, Dept Mech Ind & Syst Engn, Kingston, RI 02881 USA.
C3 Longyan University; Fuzhou University; University of Rhode Island
RP Zeng, W (corresponding author), Longyan Univ, Sch Phys & Mech & Elect Engn, Longyan 364012, Peoples R China.; Zeng, W (corresponding author), Fuzhou Univ, Sch Mech Engn & Automat, Fuzhou 350116, Peoples R China.
EM zengwei@lyun.edu.cn
RI Zeng, Wei/AFO-2103-2022; Su, Bo/ABC-2881-2021
OI Su, Bo/0000-0002-1184-0828
FU National Natural Science Foundation of China [61773194]; Natural Science
   Foundation of Fujian Province [2022J011146]
FX This work was supported by the National Natural Science Foundation of
   China (Grant no. 61773194) and by the Natural Science Foundation of
   Fujian Province (Grant no. 2022J011146).
CR Acharya U.R., 2007, ADV CARDIAC SIGNAL P, DOI DOI 10.1007/978-3-540-36675-1_5
   Acharya UR, 2017, COMPUT BIOL MED, V89, P389, DOI 10.1016/j.compbiomed.2017.08.022
   Acharya UR, 2017, INFORM SCIENCES, V405, P81, DOI 10.1016/j.ins.2017.04.012
   Alfaras M, 2019, FRONT PHYS-LAUSANNE, V7, DOI 10.3389/fphy.2019.00103
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Asgharzadeh-Bonab A, 2020, BIOCYBERN BIOMED ENG, V40, P691, DOI 10.1016/j.bbe.2020.02.004
   Atal DK, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105607
   Azar AT, 2014, NEURAL COMPUT APPL, V24, P1163, DOI 10.1007/s00521-012-1324-4
   BAIM DS, 1986, J AM COLL CARDIOL, V7, P661, DOI 10.1016/S0735-1097(86)80478-8
   Baygin M, 2021, INFORM SCIENCES, V575, P323, DOI 10.1016/j.ins.2021.06.022
   Bhaduri A, 2016, FRONT PHYSIOL, V7, DOI 10.3389/fphys.2016.00044
   Burnicka-Turek O, 2020, CIRC RES, V127, pE94, DOI 10.1161/CIRCRESAHA.118.314460
   Chakraborty C, 2022, IEEE T COMPUT SOC SY, V9, P1613, DOI 10.1109/TCSS.2022.3170375
   Chakraborty C, 2022, COMPUT ELECTR ENG, V99, DOI 10.1016/j.compeleceng.2022.107778
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen C, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101819
   Chu K., 1999, Emerg Med, V11, P175, DOI DOI 10.1046/J.1442-2026.1999.00041.X
   Dey M, 2021, IEEE SENS J, V21, P21688, DOI 10.1109/JSEN.2021.3079241
   Dora C, 2020, COMPUT METH PROG BIO, V183, DOI 10.1016/j.cmpb.2019.105092
   Elhaj FA, 2016, COMPUT METH PROG BIO, V127, P52, DOI 10.1016/j.cmpb.2015.12.024
   Eltrass AS, 2021, BIOMED SIGNAL PROCES, V65, DOI 10.1016/j.bspc.2020.102326
   Fan XM, 2018, IEEE J BIOMED HEALTH, V22, P1744, DOI 10.1109/JBHI.2018.2858789
   Faust O, 2016, J MECH MED BIOL, V16, DOI 10.1142/S0219519416400017
   Feng KY, 2022, BIOMED SIGNAL PROCES, V76, DOI 10.1016/j.bspc.2022.103663
   Feng W, 2019, IEEE J-STARS, V12, P2159, DOI 10.1109/JSTARS.2019.2922297
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Golrizkhatami Z, 2018, EXPERT SYST APPL, V114, P54, DOI 10.1016/j.eswa.2018.07.030
   Hammad M, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3033072
   Hammad M, 2018, MEASUREMENT, V125, P634, DOI 10.1016/j.measurement.2018.05.033
   He H, 2017, APPL SOFT COMPUT, V55, P238, DOI 10.1016/j.asoc.2017.02.001
   Houssein EH, 2021, EXPERT SYST APPL, V181, DOI 10.1016/j.eswa.2021.115131
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Ibn Hasan N, 2019, BIOMED SIGNAL PROCES, V52, P128, DOI 10.1016/j.bspc.2019.04.005
   Jaros R, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113648
   Jekova I, 2004, PHYSIOL MEAS, V25, P1167, DOI 10.1088/0967-3334/25/5/007
   Kishor A, 2022, WIRELESS PERS COMMUN, V127, P1615, DOI 10.1007/s11277-021-08708-5
   Kishor A, 2021, INT J SYST ASSUR ENG, DOI 10.1007/s13198-021-01174-z
   Kishor A, 2021, MULTIMED TOOLS APPL, V80, P23983, DOI 10.1007/s11042-021-10840-0
   Li TY, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18080285
   Li YZ, 2018, NEUROCOMPUTING, V314, P336, DOI 10.1016/j.neucom.2018.06.068
   Lin CH, 2008, COMPUT MATH APPL, V55, P680, DOI 10.1016/j.camwa.2007.04.035
   Martis RJ, 2014, COMPUT BIOL MED, V48, P133, DOI 10.1016/j.compbiomed.2014.02.012
   Martis RJ, 2013, BIOMED SIGNAL PROCES, V8, P437, DOI 10.1016/j.bspc.2013.01.005
   Masetic Z, 2016, COMPUT METH PROG BIO, V130, P54, DOI 10.1016/j.cmpb.2016.03.020
   Mazaheri V, 2020, EXPERT SYST APPL, V161, DOI 10.1016/j.eswa.2020.113697
   Mishra AK, 2010, BIOMED SIGNAL PROCES, V5, P114, DOI 10.1016/j.bspc.2010.01.002
   Moody G. B., 1983, Computers in Cardiology 10th Annual Meeting (IEEE Cat. No. 83CH1927-3), P227
   Moody GA, 2001, IEEE ENG MED BIOL, V20, P45, DOI 10.1109/51.932724
   Oh SL, 2019, COMPUT BIOL MED, V105, P92, DOI 10.1016/j.compbiomed.2018.12.012
   Oh SL, 2018, COMPUT BIOL MED, V102, P278, DOI 10.1016/j.compbiomed.2018.06.002
   Osowski S, 2004, IEEE T BIO-MED ENG, V51, P582, DOI 10.1109/TBME.2004.824138
   Padmavathi S., 2015, Procedia Computer Science, V47, P222, DOI 10.1016/j.procs.2015.03.201
   Petmezas G, 2021, BIOMED SIGNAL PROCES, V63, DOI 10.1016/j.bspc.2020.102194
   Plawiak P, 2020, NEURAL COMPUT APPL, V32, P11137, DOI 10.1007/s00521-018-03980-2
   Plawiak P, 2018, EXPERT SYST APPL, V92, P334, DOI 10.1016/j.eswa.2017.09.022
   Prashar N, 2021, BIOMED SIGNAL PROCES, V63, DOI 10.1016/j.bspc.2020.102212
   Qiu X, 2021, INT J DATA SCI ANAL, V11, P181, DOI 10.1007/s41060-020-00239-9
   Rahman QA, 2015, IEEE T NANOBIOSCI, V14, P505, DOI 10.1109/TNB.2015.2426213
   Raj S, 2017, IEEE T INSTRUM MEAS, V66, P470, DOI 10.1109/TIM.2016.2642758
   Rajesh KNVPS, 2018, BIOMED SIGNAL PROCES, V41, P242, DOI 10.1016/j.bspc.2017.12.004
   Ramasamy K, 2022, BIOMED SIGNAL PROCES, V76, DOI 10.1016/j.bspc.2022.103654
   Rivera WA, 2016, EXPERT SYST APPL, V66, P124, DOI 10.1016/j.eswa.2016.09.010
   Romdhane TF, 2020, COMPUT BIOL MED, V123, DOI 10.1016/j.compbiomed.2020.103866
   Rubart M, 2005, J CLIN INVEST, V115, P2305, DOI 10.1172/JCI26381
   Saadatnejad S, 2020, IEEE J BIOMED HEALTH, V24, P515, DOI 10.1109/JBHI.2019.2911367
   Sahoo S, 2017, MEASUREMENT, V108, P55, DOI 10.1016/j.measurement.2017.05.022
   Selesnick IW, 2011, IEEE T SIGNAL PROCES, V59, P3560, DOI 10.1109/TSP.2011.2143711
   Shao MG, 2018, PHYSIOL MEAS, V39, DOI 10.1088/1361-6579/aadf48
   Sharma M, 2019, COMPUT BIOL MED, V115, DOI 10.1016/j.compbiomed.2019.103446
   Stoer J., 1980, INTRO NUMERICAL ANAL
   Tjolleng A, 2017, APPL ERGON, V59, P326, DOI 10.1016/j.apergo.2016.09.013
   Torres ME, 2011, INT CONF ACOUST SPEE, P4144
   Tuncer T, 2019, KNOWL-BASED SYST, V186, DOI 10.1016/j.knosys.2019.104923
   Übeyli ED, 2009, COMPUT METH PROG BIO, V93, P313, DOI 10.1016/j.cmpb.2008.10.012
   Venkatesan C, 2018, MULTIMED TOOLS APPL, V77, P10365, DOI 10.1007/s11042-018-5762-6
   Wang JB, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101662
   Wang QF, 2019, IEEE ACCESS, V7, P18450, DOI 10.1109/ACCESS.2019.2896409
   Yanase J, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.112821
   Yang H, 2020, IEEE ACCESS, V8, P47103, DOI 10.1109/ACCESS.2020.2979256
   Yang H, 2011, IEEE T BIO-MED ENG, V58, P339, DOI 10.1109/TBME.2010.2063704
   Yang WY, 2018, COMPUT BIOL MED, V101, P22, DOI 10.1016/j.compbiomed.2018.08.003
   Ye C, 2012, IEEE T BIO-MED ENG, V59, P2930, DOI 10.1109/TBME.2012.2213253
   Yildirim O, 2020, COMPUT METH PROG BIO, V197, DOI 10.1016/j.cmpb.2020.105740
   Yildirim Ö, 2018, COMPUT BIOL MED, V102, P411, DOI 10.1016/j.compbiomed.2018.09.009
   Yildirim Ö, 2018, COMPUT BIOL MED, V96, P189, DOI 10.1016/j.compbiomed.2018.03.016
   Yochum M, 2016, BIOMED SIGNAL PROCES, V25, P46, DOI 10.1016/j.bspc.2015.10.011
   Yuan QF, 2007, COMM COM INF SC, V2, P1250
   Zeng W, 2021, SOFT COMPUT, V25, P4571, DOI 10.1007/s00500-020-05465-8
   Zhang J, 2010, MECH SYST SIGNAL PR, V24, P2104, DOI 10.1016/j.ymssp.2010.03.003
   Zheng JW, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-0386-x
NR 92
TC 3
Z9 3
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29913
EP 29941
DI 10.1007/s11042-022-14227-7
EA NOV 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000889032600005
DA 2024-07-18
ER

PT J
AU Siddique, A
   Bhatti, AR
   Butt, AD
   Awan, AB
   Ashique, RH
   Younus, MU
AF Siddique, Ali
   Bhatti, Abdul Rauf
   Butt, Arslan Dawood
   Awan, Ahmed Bilal
   Ashique, Ratil H.
   Younus, Muhammad Usman
TI A hardware-friendly motion estimation algorithm for the HEVC standard in
   the context of low-delay video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE eHealth; HEVC; Low delay; Motion estimation; Ultra High Definition
   (UHD); Video on demand (VoD)
ID SEARCH ALGORITHM; DESIGN; ARCHITECTURE; H.264/AVC; COST
AB Low-delay video coding systems are becoming more and more popular with each passing year. However, due to huge size of video data, raw video transmission is not possible, and compression is required. High efficiency video coding (HEVC) standard is able to compress videos at half the bitrate as compared to the previous standard. However, HEVC is extremely complex, and its software implementations are either coding-inefficient or slow. Hardware-based coding systems for HEVC, on the other hand, are not only able to achieve high throughput, but also offer low power consumption and some other benefits, when compared with software-based solutions. However, hardware efficiency can be achieved only when the underlying algorithm is hardware friendly. Of the many video encoder modules, motion estimation (ME) is the most computationally intensive one, which is why it is advisable to carry out ME on a hardware-based system, if high performance is required. Most of the ME algorithms presented in the literature focus only on coding efficiency and not on hardware efficiency. In this article, we present a coding- efficient ME algorithm which is more hardware friendly than most modern implementations. The proposed algorithm achieves a throughput of 4 K@42 frames per second (4 K = 3840 x 2160) at a maximum operating frequency of 200 MHz with no degradation in quality, and is comparable to state of the art algorithms, making it suitable for low delay video coding applications such as eHealth.
C1 [Siddique, Ali] Univ Macau, Dept Elect & Comp Engn, Macau, Peoples R China.
   [Bhatti, Abdul Rauf; Butt, Arslan Dawood] Govt Coll Univ Faisalabad, Dept Elect Engn & Technol, Faisalabad, Pakistan.
   [Awan, Ahmed Bilal] Ajman Univ, Dept Elect & Comp Engn, Ajman, U Arab Emirates.
   [Ashique, Ratil H.] Green Univ Bangladesh, Dept EEE, Dhaka, Bangladesh.
   [Younus, Muhammad Usman] Univ Jhang, Dept Comp Sci & IT, Jhang, Pakistan.
C3 University of Macau; Government College University Faisalabad; Ajman
   University
RP Bhatti, AR (corresponding author), Govt Coll Univ Faisalabad, Dept Elect Engn & Technol, Faisalabad, Pakistan.
EM bhatti_abdulrauf@gcuf.edu.pk
RI Butt, Arslan Dawood/K-9096-2018; Bhatti, Prof. Dr. Abdul
   Rauf/P-8244-2017; Ashique, Ratil H/T-7277-2019; Butt, Arslan
   Dawood/A-4100-2017
OI Bhatti, Prof. Dr. Abdul Rauf/0000-0001-9609-4563; Butt, Arslan
   Dawood/0000-0002-4704-2553
CR [Anonymous], 2017, HEVC REFERENCE MODEL
   Belghith F, 2016, J REAL-TIME IMAGE PR, V11, P675, DOI 10.1007/s11554-014-0407-0
   Bossen F, 2012, JCTVCL1100
   Chen K, 2021, ARXIV
   Chen Z, 2002, JVTF017, P5
   Finkelstein SM, 2006, TELEMED J E-HEALTH, V12, P128, DOI 10.1089/tmj.2006.12.128
   He G, 2015, IEEE T VLSI SYST, V23, P3138, DOI 10.1109/TVLSI.2014.2386897
   Healy J-C, 2008, IMPLEMENTING E HLTH, V11
   Hsieh JH, 2013, IEEE T VLSI SYST, V21, P33, DOI 10.1109/TVLSI.2011.2178439
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Jou SY, 2015, IEEE T CIRC SYST VID, V25, P1533, DOI 10.1109/TCSVT.2015.2389472
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   Liu C, 2011, J SYST SOFTWARE, V84, P2022, DOI 10.1016/j.jss.2011.06.049
   Mohammadzadeh Niloofar, 2014, Med Arch, V68, P57
   Nakamura K, 1999, MED CARE, V37, P117, DOI 10.1097/00005650-199902000-00002
   Panayides A, 2013, IEEE J BIOMED HEALTH, V17, P619, DOI 10.1109/TITB.2012.2232675
   Pastuszak G, 2016, J REAL-TIME IMAGE PR, V12, P517, DOI 10.1007/s11554-015-0516-4
   Purnachand N., 2012, 2012 IEEE Second International Conference on Consumer Electronics - Berlin (ICCE-Berlin), P34, DOI 10.1109/ICCE-Berlin.2012.6336494
   Sanchez G, 2015, ANALOG INTEGR CIRC S, V82, P135, DOI 10.1007/s10470-014-0342-9
   Sanchez G, 2013, IEEE IMAGE PROC, P1991, DOI 10.1109/ICIP.2013.6738410
   Sanchez G, 2013, IEEE LAT AMER SYMP
   Shahid MU, 2015, IEEE T CIRC SYST VID, V25, P701, DOI 10.1109/TCSVT.2014.2351111
   Sinangil ME, 2013, IEEE J-STSP, V7, P1017, DOI 10.1109/JSTSP.2013.2273658
   Singh K, 2018, J SIGNAL PROCESS SYS, V90, P1713, DOI 10.1007/s11265-017-1321-z
   Stone JH, 2009, CLINICIAN'S PEARLS AND MYTHS IN RHEUMATOLOGY, P1
   Tham JY, 1998, IEEE T CIRC SYST VID, V8, P369, DOI 10.1109/76.709403
   Tourapis AM, 2002, IEEE T CIRC SYST VID, V12, P934, DOI 10.1109/TCSVT.2002.804894
   Wali I, 2019, SIGNAL IMAGE VIDEO P, V13, P145, DOI 10.1007/s11760-018-1339-0
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xu WZ, 2015, SENSORS-BASEL, V15, P20752, DOI 10.3390/s150820752
   Yang M., 2009, WiCom '09. 5th International Conference on Wireless Communications, Networking and Mobile Computing, P1
   Yang SH, 2014, ELECTRON LETT, V50, P673, DOI 10.1049/el.2014.0536
   Yilmaz AA, 2020, IEEE ACCESS, V8, P100631, DOI 10.1109/ACCESS.2020.2997962
   Zatt B, 2011, ICCAD-IEEE ACM INT, P40, DOI 10.1109/ICCAD.2011.6105303
NR 34
TC 0
Z9 0
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16519
EP 16532
DI 10.1007/s11042-022-14178-z
EA NOV 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000883287200004
DA 2024-07-18
ER

PT J
AU Xu, LX
   Zhao, FJ
   Xu, P
   Cao, BX
AF Xu, Laixiang
   Zhao, Fengjie
   Xu, Peng
   Cao, Bingxu
TI Infrared target recognition with deep learning algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Infrared automatic target recognition; Deep learning; ALPHA-Beta
   divergence
AB Infrared automatic target recognition (ATR) technology still is a challenging problem in military applications. In recent years, convolutional neural networks (CNNs) models have already led to breakthrough developments in object detection and target recognition. However, the complex environment and the bad weather caused the poor texture information and the weak background of infrared imaging. It's difficult to use standard CNNs to perform accurate feature extraction and target classification. To overcome these shortcomings, we propose a novel deep learning framework, composed of the multi-kernel transformation and the Alpha-Beta divergence. The multi-kernel transformation operation is designed between convolutional layers and pooling layers to increase the confidence of feature extraction. The Alpha-Beta divergence is used as a penalty term to re-encode the output neurons of improved CNNs, which can promote the recognition performance of the entire network. Furthermore, comprehensive theoretical analysis and extensive experiments are confirmed that our proposed framework outperforms ResNet, VGG-19, DenseNet, and the different combinations of models in many aspects, such as short time-consuming, high accuracy, and strong robustness. Our approach yields a maximum accuracy score of 98.43% on our dataset. Meanwhile, we use the OKTAL-SE-based synthetic database and the SENSIAC dataset to verify our models. Experimental results demonstrate the maximum average accuracy is 97.16%, it is feasible and effective for infrared target recognition.
C1 [Xu, Laixiang] Hainan Univ, Sch Informat & Commun Engn, Haikou 570228, Hainan, Peoples R China.
   [Xu, Laixiang] Hainan Univ, Sch Biomed Engn, Key Lab Biomed Engn Hainan Prov, Haikou 570228, Hainan, Peoples R China.
   [Zhao, Fengjie] Zhengzhou Univ, Henan Sui Xian Peoples Hosp, Shangqiu Peoples Hosp 1, Dept Pediat, Shangqiu 476000, Peoples R China.
   [Zhao, Fengjie] Zhengzhou Univ, Affiliated Hosp 1, Shangqiu 476000, Peoples R China.
   [Xu, Peng] Xinjiang Shen Huo Garbon Co Ltd, Roasting 2 Branch, Fukang 831500, Peoples R China.
   [Cao, Bingxu] Henan Univ Technol, Luohe Vocat Technol Coll, Luohe Inst Technol, Sch Informat Engn, Luohe 462000, Peoples R China.
C3 Hainan University; Hainan University; Zhengzhou University; Zhengzhou
   University; Henan University of Technology
RP Xu, LX (corresponding author), Hainan Univ, Sch Informat & Commun Engn, Haikou 570228, Hainan, Peoples R China.; Xu, LX (corresponding author), Hainan Univ, Sch Biomed Engn, Key Lab Biomed Engn Hainan Prov, Haikou 570228, Hainan, Peoples R China.
EM xulaixiang@hainanu.edu.cn; pediatrieszhao@yeah.net;
   shenhuoxupeng@yeah.net; 328532625@qq.com
RI Xu, Laixiang/IAM-7518-2023
OI Xu, Laixiang/0000-0001-5412-7689
FU National Key Research and Development Program of China [2018YFC1407505];
   Aeronautical Science Foundation of China [20170142002]; Natural Science
   Foundation of Henan Province [162300410095]; Natural Science Foundation
   of Hainan Province [119MS001]; scientific research fund of Hainan
   University [kyqd1653]
FX This work is supported by National Key Research and Development Program
   of China (2018YFC1407505), Aeronautical Science Foundation of China
   (20170142002), Natural Science Foundation of Henan Province
   (162300410095), Natural Science Foundation of Hainan Province
   (119MS001), and the scientific research fund of Hainan University (No.
   kyqd1653).
CR Chen F, 2022, COMPUT INTEL NEUROSC
   Chen J, 2022, TARGET ATTENTIONAL C
   Chen ZB, 2019, J VIS COMMUN IMAGE R, V59, P401, DOI 10.1016/j.jvcir.2018.12.044
   Ding BY, 2022, OPTIK, V252, DOI 10.1016/j.ijleo.2021.168561
   Divya SV, 2020, IET IMAGE PROCESS, V14, P929, DOI 10.1049/iet-ipr.2019.0568
   Fang F, 2020, IEEE T IMAGE PROCESS, V29, P2052, DOI 10.1109/TIP.2019.2947792
   Gan BR, 2019, SPECTROSC SPECT ANAL, V39, P96, DOI 10.3964/j.issn.1000-0593(2019)01-0096-07
   Huang H, 2022, WIREL COMMUN MOBILE
   Lang Y, 2021, ALGORITHM APPL BASED
   Li J, 2021, 7 S NOVEL PHOTOELECT, P11763
   Li TL, 2019, IEEE SENS J, V19, P4598, DOI 10.1109/JSEN.2019.2901050
   Luo JY, 2018, LIMNOL OCEANOGR-METH, V16, P814, DOI 10.1002/lom3.10285
   Naiemi F, 2019, SOFT COMPUT, V23, P11759, DOI 10.1007/s00500-018-03728-z
   Qi SH, 2021, DISPLAYS, V69, DOI 10.1016/j.displa.2021.102053
   Riu L, 2022, REV SCI INSTRUM, V93, DOI 10.1063/5.0082456
   Shang MS, 2022, IEEE T CYBERNETICS, V52, P8006, DOI 10.1109/TCYB.2020.3026425
   Shen CP, 2018, WATER RESOUR RES, V54, P8558, DOI 10.1029/2018WR022643
   Vijayalakshmi D, 2022, DIGIT SIGNAL PROCESS, V127, DOI 10.1016/j.dsp.2022.103532
   Wang CS, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3170493
   Wang C, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108498
   Wang SN, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12073588
   Wang TC, 2022, ANAL METHODS-UK, V14, P508, DOI [10.1039/D1AY01726H, 10.1039/d1ay01726h]
   Wu G, 2022, IEEE GEOSCI REMOTE S, V19
   Wu J, 2017, ELECTRON LETT, V53, P1642, DOI 10.1049/el.2017.3159
   Xu XW, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14041018
   Yan H, 2020, ISA T, V107, P160, DOI 10.1016/j.isatra.2020.07.040
   Zeng ZZ, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3070417
   Zhang H, 2020, IEEE T IMAGE PROCESS, V29, P2078, DOI 10.1109/TIP.2019.2947806
   Zhang M, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2020.3031593
   Zhang RH, 2022, IEEE T MULTIMEDIA, V24, P1735, DOI 10.1109/TMM.2021.3070138
   Zheng TS, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13071356
   Zhou JW, 2021, OPTIK, V248, DOI 10.1016/j.ijleo.2021.168084
NR 32
TC 1
Z9 1
U1 5
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 17213
EP 17230
DI 10.1007/s11042-022-14142-x
EA NOV 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000881891300003
DA 2024-07-18
ER

PT J
AU Wu, QH
   Huang, Q
   Li, X
AF Wu, Qianhan
   Huang, Qian
   Li, Xing
TI Multimodal human action recognition based on spatio-temporal action
   representation recognition model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action recognition; Multimode learning; HP-DMI; ST-GCN extractor;
   HTMCCA
ID CONVOLUTIONAL NEURAL-NETWORKS; RGB-D; DESCRIPTOR; MOTION; VIDEOS; CNN
AB Human action recognition methods based on single-modal data lack adequate information. It is necessary to propose the methods based on multimodal data and the fusion algorithms to fuse different features. Meanwhile, the existing features extracted from depth videos and skeleton sequences are not representative. In this paper, we propose a new model named Spatio-temporal Action Representation Recognition Model for recognizing human actions. This model proposes a new depth feature map called Hierarchical Pyramid Depth Motion Images (HP-DMI) to represent depth videos and adopts Spatial-temporal Graph Convolutional Networks (ST-GCN) extractor to summarize skeleton features named Spatio-temporal Joint Descriptors (STJD). Histogram of Oriented Gradient (HOG) is used on HP-DMI to extract HP-DMI-HOG features. Then two kinds of features are input into a fusion algorithm High Trust Mean Canonical correlation analysis (HTMCCA). HTMCCA mitigates the impact of noisy samples on multi-feature fusion and reduces computational complexity. Finally, Support Vector Machine (SVM) is used for human action recognition. To evaluate the performance of our approach, several experiments are conducted on two public datasets. Eexperiments results prove its effectiveness.
C1 [Wu, Qianhan; Huang, Qian; Li, Xing] Hohai Univ, Key Lab Water Big Data Technol, Minist Water Resources, 8 West Focheng Rd, Nanjing 211106, Jiangsu, Peoples R China.
   [Wu, Qianhan; Huang, Qian; Li, Xing] Hohai Univ, Sch Comp & Informat, 8 West Focheng Rd, Nanjing 211106, Jiangsu, Peoples R China.
C3 Hohai University; Hohai University
RP Huang, Q (corresponding author), Hohai Univ, Key Lab Water Big Data Technol, Minist Water Resources, 8 West Focheng Rd, Nanjing 211106, Jiangsu, Peoples R China.; Huang, Q (corresponding author), Hohai Univ, Sch Comp & Informat, 8 West Focheng Rd, Nanjing 211106, Jiangsu, Peoples R China.
EM wuqianhan@hhu.edu.cn; huangqian@hhu.edu.cn; lixing@hhu.edu.cn
RI Huang, Qian/GPX-9181-2022
OI Huang, Qian/0000-0001-5625-0402
CR [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247923
   Ben Amor B, 2016, IEEE T PATTERN ANAL, V38, P1, DOI 10.1109/TPAMI.2015.2439257
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bregonzio M, 2009, PROC CVPR IEEE, P1948, DOI 10.1109/CVPRW.2009.5206779
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Bulbul MF, 2019, J INTELL FUZZY SYST, V36, P3385, DOI 10.3233/JIFS-181136
   Chao X, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185180
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Cherkassky V, 2004, NEURAL NETWORKS, V17, P113, DOI 10.1016/S0893-6080(03)00169-2
   Das Srijan, 2020, COMPUTER VISIONECCV, P72
   Dhiman C, 2020, IEEE T IMAGE PROCESS, V29, P3835, DOI 10.1109/TIP.2020.2965299
   Dhiman C, 2019, ENG APPL ARTIF INTEL, V77, P21, DOI 10.1016/j.engappai.2018.08.014
   Elmadany NE, 2019, IEEE T MULTIMEDIA, V21, P1317, DOI 10.1109/TMM.2018.2875510
   Elmadany NE, 2018, IEEE T IMAGE PROCESS, V27, P5275, DOI 10.1109/TIP.2018.2855438
   Gowayyed M.A., 2013, Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence, IJCAI '13, P1351
   Guo GD, 2003, LECT NOTES COMPUT SC, V2888, P986
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hou YH, 2018, IEEE T CIRC SYST VID, V28, P807, DOI 10.1109/TCSVT.2016.2628339
   Hu JF, 2018, LECT NOTES COMPUT SC, V11211, P346, DOI 10.1007/978-3-030-01234-2_21
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Kamel A, 2019, IEEE T SYST MAN CY-S, V49, P1806, DOI 10.1109/TSMC.2018.2850149
   Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740
   Kattenborn T, 2021, ISPRS J PHOTOGRAMM, V173, P24, DOI 10.1016/j.isprsjprs.2020.12.010
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Ke QH, 2017, IEEE SIGNAL PROC LET, V24, P731, DOI 10.1109/LSP.2017.2690339
   Khaire Pushpajit, 2018, Proceedings of 2nd International Conference on Computer Vision & Image Processing. CVIP 2017. Advances in Intelligent Systems and Computing (AISC 703), P409, DOI 10.1007/978-981-10-7895-8_32
   Khaire P, 2018, PATTERN RECOGN LETT, V115, P107, DOI 10.1016/j.patrec.2018.04.035
   Kim HG, 2019, IEEE T CONSUM ELECTR, V65, P349, DOI 10.1109/TCE.2019.2924177
   Koniusz P, 2016, LECT NOTES COMPUT SC, V9908, P37, DOI 10.1007/978-3-319-46493-0_3
   Li CK, 2017, IEEE SIGNAL PROC LET, V24, P624, DOI 10.1109/LSP.2017.2678539
   Li JN, 2020, PATTERN RECOGN, V104, DOI 10.1016/j.patcog.2020.107356
   Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Jingen Liu, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1996, DOI [10.1109/ICINIS.2009.13, 10.1109/CVPRW.2009.5206744]
   Nguyen XS, 2018, MULTIMED TOOLS APPL, V77, P21617, DOI 10.1007/s11042-017-5593-x
   Ohn-Bar E, 2013, IEEE COMPUT SOC CONF, P465, DOI 10.1109/CVPRW.2013.76
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Qin XL, 2020, NEUROCOMPUTING, V406, P127
   Rahmani H, 2017, IEEE I CONF COMP VIS, P5833, DOI 10.1109/ICCV.2017.621
   Rani SS, 2021, MATER TODAY-PROC, V37, P3164, DOI 10.1016/j.matpr.2020.09.052
   Rasiwasia N, 2014, JMLR WORKSH CONF PRO, V33, P823
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Shahroudy A, 2018, IEEE T PATTERN ANAL, V40, P1045, DOI 10.1109/TPAMI.2017.2691321
   Si CY, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107511
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Song SJ, 2018, IEEE INT CON MULTI
   Sun L, 2017, IEEE I CONF COMP VIS, P2166, DOI 10.1109/ICCV.2017.236
   Tran QD, 2013, PROCEEDINGS OF 2013 IEEE RIVF INTERNATIONAL CONFERENCE ON COMPUTING AND COMMUNICATION TECHNOLOGIES: RESEARCH, INNOVATION, AND VISION FOR THE FUTURE (RIVF), P253, DOI 10.1109/RIVF.2013.6719903
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Vishwakarma D., 2017, Int. J. Comput. Vis. Robot., V7, P454, DOI 10.1504/IJCVR.2017.084991
   Vishwakarma DK, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P336
   Vishwakarma D. K., 2012, 4 INT C INTELLIGENT, P1, DOI DOI 10.1109/IHCI.2012.6481804
   Wang HG, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20113305
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang KY, 2016, IEEE T PATTERN ANAL, V38, P2010, DOI 10.1109/TPAMI.2015.2505311
   Wang LC, 2019, IEEE I CONF COMP VIS, P6221, DOI 10.1109/ICCV.2019.00631
   Wang P., 2017, P IEEE C COMP VIS PA, P595
   Wei P, 2019, IEEE T MULTIMEDIA, V21, P2195, DOI 10.1109/TMM.2019.2897902
   Xia L., 2012, IEEE COMP SOC C COMP, P20, DOI DOI 10.1109/CVPRW.2012.6239233
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang X., 2012, IEEE COMP SOC C COMP, V2012, P14, DOI [DOI 10.1109/CVPRW.2012.6239232, 10.1109/CVPRW.2012.6239232]
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108
   Zhao C, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040716
   Zolfaghari M, 2017, IEEE I CONF COMP VIS, P2923, DOI 10.1109/ICCV.2017.316
NR 67
TC 2
Z9 2
U1 4
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16409
EP 16430
DI 10.1007/s11042-022-14193-0
EA NOV 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000881891200001
DA 2024-07-18
ER

PT J
AU Ajij, M
   Roy, DS
   Pratihar, S
AF Ajij, Md
   Roy, Diptendu Sinha
   Pratihar, Sanjoy
TI Automated generation of text handles from scanned images of scholarly
   articles for indexing in digital archive
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Document indexing; Digital library; Scholarly article categorization;
   Document retrieval
ID SLANT CORRECTION; DOCUMENT; CLASSIFICATION; SEGMENTATION; LINES; SLOPE
AB There have been extensive studies and rapid improvements in automated document categorization, document retrieval, document recommendations, etc. These trendy and essential tasks are associated with information retrieval or data extraction. Also, the document organization process is gradually becoming fully automated for storage in archives. The categorization and indexing of scholarly articles remain a challenge and a real need with a rapid increase in the volume of scholarly articles. Also, there is a need of automation for proper indexing and retrieval of the old scholarly articles in libraries that are available in thousands as print versions. In this paper, we propose a method for simple and robust generation of text handles from the scanned images of scholarly articles to manage them in digital archives efficiently. We have also proposed a Delaunay triangulation based feature set for the associated categorization work. The theme of the proposed work is mainly based on the idea of tracking the locality of emphasized (italic) words. We have primarily considered the articles' titles and reference pages for crucial information extraction to find handles. The detection of italics is proposed using Principal Component Analysis (PCA). The PCA is applied to a selective subset of object boundary pixels representing the vertical or column edges. We have shown how efficiently this proposed method can generate text handles for indexing scholarly articles.
C1 [Ajij, Md; Roy, Diptendu Sinha] Natl Inst Technol Meghalaya, Dept Comp Sci & Engn, Shillong, Meghalaya, India.
   [Pratihar, Sanjoy] Indian Inst Informat Technol Kalyani, Dept Comp Sci & Engn, Kalyani, W Bengal, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Meghalaya
RP Pratihar, S (corresponding author), Indian Inst Informat Technol Kalyani, Dept Comp Sci & Engn, Kalyani, W Bengal, India.
EM mdajij@nitm.ac.in; diptendu.sr@nitm.ac.in; sanjoy.pratihar@gmail.com
RI Pratihar, Sanjoy/K-8029-2017; Pratihar, Sanjoy/Q-3547-2016
OI Pratihar, Sanjoy/0000-0002-0833-6989
CR Antonacopoulos A, 2011, PROC INT CONF DOC, P1516, DOI 10.1109/ICDAR.2011.301
   Appiani E., 2001, International Journal on Document Analysis and Recognition, V4, P69, DOI 10.1007/PL00010904
   Audebert N, 2019, ARXIV
   Baeza-Yates R., 1999, Modern information retrieval
   Berg M., 2008, COMPUTATIONAL GEOMET, DOI DOI 10.1007/978-3-540-77974-2
   BinMakhashen GM, 2020, INT J DIGIT LIBRARIE, V21, P329, DOI 10.1007/s00799-020-00280-w
   Binmakhashen GM, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3355610
   Boukhari K, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01684-x
   Chen J., 2016, Electronic Imaging, V2016, P1
   Chen N, 2007, INT J DOC ANAL RECOG, V10, P1, DOI 10.1007/s10032-006-0020-2
   Das Gupta J, 2014, PROC INT CONF EMERG, P204, DOI 10.1109/EAIT.2014.19
   Esser D, 2012, PROC SPIE, V8297, DOI 10.1117/12.908542
   Garain U., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P341, DOI 10.1109/ICDAR.1999.791794
   Gatos Basilis, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P271, DOI 10.1109/ICDAR.2009.236
   Hu J., 2000, Information Retrieval, V2, P227, DOI 10.1023/A:1009910911387
   Jain A. K., 1992, Machine Vision and Applications, V5, P169, DOI 10.1007/BF02626996
   Kar R, 2019, IMAGING SCI J, V67, P159, DOI 10.1080/13682199.2019.1574368
   Kim SH, 2002, INT C PATT RECOG, P320, DOI 10.1109/ICPR.2002.1048304
   Kise K., 2014, HDB DOCUMENT IMAGE P, P135, DOI DOI 10.1007/978-0-85729-859-1_5
   Kumar J, 2014, PATTERN RECOGN LETT, V43, P119, DOI 10.1016/j.patrec.2013.10.030
   Lee YS, 2006, PATTERN RECOGN LETT, V27, P1744, DOI 10.1016/j.patrec.2006.04.016
   Li YJ, 2007, IEEE T PATTERN ANAL, V29, P1091, DOI 10.1109/TPAMI.2007.1070
   Liu J, 2011, PROC INT CONF DOC, P698, DOI [10.1109/ICDAR.2011.146, 10.1109/TMEE.2011.6199298]
   Lu Y, 2004, IEEE T KNOWL DATA EN, V16, P1398, DOI 10.1109/TKDE.2004.76
   Marinai S, 2004, FIRST INTERNATIONAL WORKSHOP ON DOCUMENT IMAGE ANALYSIS FOR LIBRARIES, PROCEEDINGS, P150, DOI 10.1109/DIAL.2004.1263246
   Nanba Hidetsugu., 2000, Advances in Classification Research Online, V11, P117, DOI [DOI 10.7152/ACR0.V11I1.12774, DOI 10.7152/ACRO.V11I1.12774]
   Papavassiliou V, 2010, PATTERN RECOGN, V43, P369, DOI 10.1016/j.patcog.2009.05.007
   Rivest M, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0251493
   Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2
   Shahid M, 2020, ADV INTELL SYST COMP, V978, P297, DOI 10.1007/978-3-030-36056-6_29
   Su Bolan, 2010, ACM INT C P SERIES D, P159, DOI [10.1145/1815330.1815351, DOI 10.1145/1815330.1815351]
   Taheriyan Mohsen., 2011, Proceedings of the 2011 workshop on Knowledge discovery, modeling and simulation, KDMS'11, P39, DOI [DOI 10.1145/2023568.2023579, 10.1145/2023568.2023579]
   Thien Hai Nguyen, 2013, Natural Language Processing and Information Systems. 18th International Conference on Applications of Natural Language to Information Systems, NLDB 2013. Proceedings: LNCS 7934, P278, DOI 10.1007/978-3-642-38824-8_25
   Tian SX, 2015, PROC INT CONF DOC, P331, DOI 10.1109/ICDAR.2015.7333778
   Zhang L, 2004, INT C PATT RECOG, P835
   Zhang P, 2020, ARXIV
NR 36
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22373
EP 22404
DI 10.1007/s11042-022-13974-x
EA NOV 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000880546100004
DA 2024-07-18
ER

PT J
AU Wu, YH
   Zhang, ZN
   Qiu, D
   Li, WQ
   Su, ZY
AF Wu, Yihe
   Zhang, Zhenning
   Qiu, Dong
   Li, Weiqing
   Su, Zhiyong
TI Video driven adaptive grasp planning of virtual hand using deep
   reinforcement learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual hand; Grasp planning; Motion generation; Deep reinforcement
   learning; Monocular 3D hand pose estimation
AB Data-driven grasp planning can generate anthropopathic grasps, providing controllers with robust and natural responses to environmental changes or morphological discrepancies. Mocap data, which is the widely used source of motion data, can provide high-fidelity dynamic motions. However, it is challenging for non-professionals to quickly get start and collect sufficient mocap data for grasp training. Furthermore, current grasp planning approaches suffer from limited adaptive abilities, and thus cannot be applied to objects of different shapes and sizes directly. In this paper, we propose the first framework, to the best of our knowledge, for fast and easy design of grasping controller with kinematic algorithms based on monocular 3D hand pose estimation and deep reinforcement learning, leveraging abundant and flexible videos of desired grasps. Specially, we first get original grasping sequences through 3D hand pose estimation from given monocular video fragments. Then, we reconstruct the motion sequences using data smoothing based on the peek clipping filter, and further optimize them using the CMA-ES (Covariance Matrix Adaptation Evolution Strategy). Finally, we integrate the reference motion with the adaptive grasping controller through deep reinforcement learning. Quantitative and qualitative results demonstrate that our framework is able to generate natural and stable grasps easily from monocular video demonstrations, added the adaptive ability to primitive objects of different shapes and sizes in the target object library.
C1 [Wu, Yihe; Qiu, Dong; Su, Zhiyong] Nanjing Univ Sci & Technol, Sch Automat, Nanjing 210094, Peoples R China.
   [Zhang, Zhenning; Li, Weiqing] Nanjing Univ Sci & Technol, Sch Comp Sci & Engineer, Nanjing 210094, Peoples R China.
C3 Nanjing University of Science & Technology; Nanjing University of
   Science & Technology
RP Su, ZY (corresponding author), Nanjing Univ Sci & Technol, Sch Automat, Nanjing 210094, Peoples R China.
EM su@njust.edu.cn
OI su, zhiyong/0000-0001-9483-5268
FU National Key R&D Program of China [2018YFB1004904]; Fundamental Research
   Funds for the Central Universities [30918012203]
FX This work was supported by the National Key R&D Program of China (grant
   number: 2018YFB1004904), the Fundamental Research Funds for the Central
   Universities under Grant 30918012203.
CR Antotsiou D, 2019, LECT NOTES COMPUT SC, V11134, P287, DOI 10.1007/978-3-030-11024-6_19
   Brahmbhatt S, 2019, IEEE INT C INT ROBOT, P2386, DOI [10.1109/IROS40897.2019.8967960, 10.1109/iros40897.2019.8967960]
   Buckingham G, 2021, ARXIV
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Chen YJ, 2019, IEEE I CONF COMP VIS, P6960, DOI 10.1109/ICCV.2019.00706
   Ciocarlie M, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P3276
   Documentation U, 2021, RIGIDB
   FERRARI C, 1992, 1992 IEEE INTERNATIONAL CONF ON ROBOTICS AND AUTOMATION : PROCEEDINGS, VOLS 1-3, P2290, DOI 10.1109/ROBOT.1992.219918
   Ferreira JP, 2021, COMPUT GRAPH-UK, V94, P11, DOI 10.1016/j.cag.2020.09.009
   Fu Yi-lil, 2009, Computer Integrated Manufacturing Systems, V15, P681
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Kim J.-H., 2009, Industrial Electronics, P1013
   Kopicki M, 2016, INT J ROBOT RES, V35, P959, DOI 10.1177/0278364915594244
   [黎子聪 Li Zicong], 2020, [计算机辅助设计与图形学学报, Journal of Computer-Aided Design & Computer Graphics], V32, P997
   Liu LB, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201315
   Liu LB, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3083723
   Liu M, 2019, IEEE INT C INT ROBOT, P1518, DOI [10.1109/iros40897.2019.8968115, 10.1109/IROS40897.2019.8968115]
   [刘乃军 Liu Naijun], 2019, [自动化学报, Acta Automatica Sinica], V45, P458
   Miller AT, 2004, IEEE ROBOT AUTOM MAG, V11, P110, DOI 10.1109/MRA.2004.1371616
   Mueller F, 2018, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2018.00013
   Peng XB, 2021, ACM T GRAPHIC, V40, DOI [10.1145/3197517.3201311, 10.1145/3450626.3459670]
   Peng XB, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275014
   Rajeswaran A, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV
   Roccetti M., 2010, Comput Entertain (CIE), V8, P1, DOI [10.1145/1921141.1921148, DOI 10.1145/1921141.1921148]
   Shimada S, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417877
   Song P, 2018, VISUAL COMPUT, V34, P257, DOI 10.1007/s00371-016-1333-x
   Starke J, 2018, IEEE-RAS INT C HUMAN, P327
   Tian H, 2019, IEEE T VIS COMPUT GR, V25, P2623, DOI 10.1109/TVCG.2018.2849381
   Wang H, 2019, COMPUT GRAPH FORUM, V38, P367, DOI 10.1111/cgf.13644
   Weichang C., 2014, THESIS TIANJIN U
   Xiaoyuan W, 2020, J COMPUTER AIDED DES, V32, P1
   Yu R, 2019, COMPUT GRAPH FORUM, V38, P225, DOI 10.1111/cgf.13831
   Zhang X, 2019, IEEE I CONF COMP VIS, P2354, DOI 10.1109/ICCV.2019.00244
   Zhou YX, 2020, PROC CVPR IEEE, P5345, DOI 10.1109/CVPR42600.2020.00539
NR 34
TC 0
Z9 0
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16301
EP 16322
DI 10.1007/s11042-022-14190-3
EA NOV 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000880546200005
DA 2024-07-18
ER

PT J
AU Wang, J
   Shi, L
   Zhao, Y
   Zhang, HX
   Szczerbicki, E
AF Wang, Juan
   Shi, Lei
   Zhao, Yang
   Zhang, Haoxi
   Szczerbicki, Edward
TI Adversarial attack algorithm for traffic sign recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Adversarial attack; Black box; Traffic sign recognition; Algorithm
   security
ID FACE RECOGNITION; BLACK
AB Deep learning suffers from the threat of adversarial attacks, and its defense methods have become a research hotspot. In all applications of deep learning, intelligent driving is an important and promising one, facing serious threat of adversarial attack in the meanwhile. To address the adversarial attack, this paper takes the traffic sign recognition as a typical object, for it is the core function of intelligent driving. Considering that the black box attack does not need to know the internal characteristics of the model, it can have more practical value. However, the existing black box attack algorithm has high visit time and low efficiency in attacking sample generation. In this regard, the SimBA algorithm with high efficiency is selected and improved according to the characteristics of traffic signs, named the L-SimBA algorithm. According to the graphic characteristics of traffic signs that are already known, L-SimBA algorithm limits the search subspace consciously and specifies the set of search directions, and that is the core idea of it. By this way, L-SimBA algorithm can generate adversarial samples faster. Experimental comparison shows that in the field of traffic sign recognition, L-SimBA algorithm is better than SimBA algorithm. On the premise of obtaining similar quality adversarial attack samples, the success rate of adversarial measures gets higher, and the number of model visits reduces considerably, thus the attack efficiency of the algorithm improves greatly.
C1 [Wang, Juan; Shi, Lei; Zhao, Yang; Zhang, Haoxi] Chengdu Univ Informat Technol, Sch Cyberspace Secur, Chengdu 610225, Peoples R China.
   [Wang, Juan; Zhang, Haoxi] Adv Cryptog & Syst Secur Key Lab Sichuan Prov, Chengdu 610225, Peoples R China.
   [Szczerbicki, Edward] Gdansk Univ Technol, Fac Management & Econ, Dept Management, Gabriela Narutowicza 11-12, PL-80233 Gdansk, Poland.
C3 Chengdu University of Information Technology; Fahrenheit Universities;
   Gdansk University of Technology
RP Shi, L (corresponding author), Chengdu Univ Informat Technol, Sch Cyberspace Secur, Chengdu 610225, Peoples R China.
EM wangjuan@cuit.edu.cn; 1402687676@qq.com; haoxi@cuit.edu.cn;
   Edward.Szczerbicki@zie.pg.gda.pl
OI Wang, Juan/0000-0002-5893-2367
FU Sichuan Science and Technology Program [2021YFH0076]
FX This research was funded by Sichuan Science and Technology Program
   No.2021YFH0076.
CR Bai S, 2021, IEEE T PATTERN ANAL, V43, P2119, DOI 10.1109/TPAMI.2020.3031625
   Cai KT, 2022, IEEE ACCESS, V10, P51548, DOI 10.1109/ACCESS.2022.3174963
   Esmaeilpour M, 2022, IEEE T INF FOREN SEC, V17, P2044, DOI 10.1109/TIFS.2022.3175603
   Esmaeilpour M, 2021, IEEE SIGNAL PROC LET, V28, P1769, DOI 10.1109/LSP.2021.3106239
   Guo C., 2019, INT C MACHINE LEARNI, P2484
   Heo H, 2021, IEEE ACCESS, V9, P146938, DOI 10.1109/ACCESS.2021.3124050
   Kim Y, 2020, IEEE T CIRCUITS-II, V67, P846, DOI 10.1109/TCSII.2020.2980022
   Li NN, 2021, IEEE T IMAGE PROCESS, V30, P6156, DOI 10.1109/TIP.2021.3092822
   Lo SY, 2022, IEEE T IMAGE PROCESS, V31, P962, DOI 10.1109/TIP.2021.3137648
   Mahmood K, 2022, IEEE ACCESS, V10, P998, DOI 10.1109/ACCESS.2021.3138338
   Peng BW, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2022.3184311
   Qi PH, 2022, IEEE T RELIAB, V71, P674, DOI 10.1109/TR.2022.3161138
   Song Dawn, 2018, 12 USENIX WORKSHOP O
   Vakhshiteh F, 2021, IEEE ACCESS, V9, P92735, DOI 10.1109/ACCESS.2021.3092646
   Zheng Y., 2020, IEEE ACCESS, V8, P91
   Zhong YY, 2021, IEEE T INF FOREN SEC, V16, P1452, DOI 10.1109/TIFS.2020.3036801
NR 16
TC 2
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 OCT 26
PY 2022
DI 10.1007/s11042-022-14067-5
EA OCT 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5P9JI
UT WOS:000873458400002
DA 2024-07-18
ER

PT J
AU Vargas, H
   Heradio, R
   Donoso, M
   Farias, G
AF Vargas, Hector
   Heradio, Ruben
   Donoso, Matias
   Farias, Gonzalo
TI Teaching automation with Factory I/O under a competency-based curriculum
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Control education; Educational technologies; 3D simulations;
   Competency-based education
ID EDUCATION; SYSTEM; MATLAB
AB Some of the most critical competencies students need to acquire to become control engineers require performing practices under actual industrial conditions. This means that they must not only master the theoretical aspects of the discipline but also acquire skills and attitudes to face unpredictable real-world situations. Software tools such as Matlab/Simulink are widely used to train the design and validation of controllers, but they fail to provide real industrial contexts. Nowadays, there are 3D simulation tools that support recreating industrial environments to a remarkable extent, making them very attractive for university courses. Nevertheless, their application in engineering courses is scarce yet. This paper presents a methodological framework for seizing into competency-based courses one of these simulation tools, called Factory I/O. Our approach was evaluated in a master's course on Industrial PID Control at Pontifical Catholic University of Valparaiso (PUCV) in Chile. The evaluation comprised the qualitative analysis of students' grades over four consecutive course editions and the qualitative study of students' opinion on Factory I/O educational value. The objectives of our evaluation were (i) testing if Factory I/O helped students develop skills hard to practice in academic contexts, such as detecting faults or recognizing the importance of having well-defined operation protocols; (ii) validating our methodology for competency-based courses; and (iii) surveying our students about Matlab/Simulink and Factory I/O strengths/weaknesses to teach control engineering. According to the results, (a) Factory I/O complements Simulink by providing an adequate virtual environment to learn the aforementioned skills; and (b) our methodology supports courses' continuous improvement through the statistical analysis of students' achievements at different abstraction levels.
C1 [Vargas, Hector; Donoso, Matias; Farias, Gonzalo] Pontificia Univ Catolica Valparaiso PUCV, Sch Elect Engn, Valparaiso 2362804, Chile.
   [Heradio, Ruben] Univ Nacl Educ Distancia UNED, Dept Software & Syst Engn, Madrid 28040, Spain.
C3 Pontificia Universidad Catolica de Valparaiso; Universidad Nacional de
   Educacion a Distancia (UNED)
RP Heradio, R (corresponding author), Univ Nacl Educ Distancia UNED, Dept Software & Syst Engn, Madrid 28040, Spain.
EM hector.vargas@pucv.cl; rheradio@issi.uned.es;
   matias.donoso.m@mail.pucv.cl
RI Heradio, Ruben/D-3675-2013
OI Heradio, Ruben/0000-0002-7131-0482
FU Chilean Ministry of Science under Project FONDECYT [1191188];
   Universidad Nacional de Educacion a Distancia (UNED) [096-034091]
FX This work was supported by the Chilean Ministry of Science under Project
   FONDECYT 1191188, and the Universidad Nacional de Educacion a Distancia
   (UNED) under Project OPTIVAC Ref. 096-034091.
CR Alothman A, 2019, AM SOC ENG ED ANN C, DOI [10.18260/1-2--32382, DOI 10.18260/1-2--32382]
   Alvarez S., 2020, IEEE INT C ENG VERAC, P1, DOI [10.1109/ICEV50249.2020.9289670, DOI 10.1109/ICEV50249.2020.9289670]
   [Anonymous], 2022, REAL GAMES
   [Anonymous], 2022, FACTORY I O
   Back M, 2010, IEEE INT CON MULTI, P1160, DOI 10.1109/ICME.2010.5582532
   Bajpai S, 2016, IFAC PAPERSONLINE, V49, P813, DOI 10.1016/j.ifacol.2016.03.157
   Bencomo SD, 2004, ANNU REV CONTROL, V28, P115, DOI 10.1016/j.arcontrol.2003.12.002
   Bolton W., 2015, PROGRAMMABLE LOGIC C
   Chaos D, 2013, SENSORS-BASEL, V13, P2595, DOI 10.3390/s130202595
   Checa D, 2020, MULTIMED TOOLS APPL, V79, P5501, DOI 10.1007/s11042-019-08348-9
   Chiou RY, 2010, INT MANUFACTURING SC, P41, DOI [10.1115/MSEC2010-34089, DOI 10.1115/MSEC2010-34089]
   Choi B., 2004, J ADV MANUFACTURING, V3, P5, DOI [10.1142/S0219686704000363, DOI 10.1142/S0219686704000363]
   Cipriano A, 1996, IEEE CONTR SYST MAG, V16, P15, DOI 10.1109/37.487402
   Cohen L., 2018, Research Methods in education, DOI 10.4324/9781315456539-14
   Collaborative EPI, 2021, COMP BAS ED SURV INS
   Dangelmaier W, 2005, COMPUT IND, V56, P371, DOI 10.1016/j.compind.2005.01.007
   Dormido R, 2008, IEEE T EDUC, V51, P35, DOI 10.1109/TE.2007.893356
   Duro N, 2008, COMPUT SCI ENG, V10, P50, DOI 10.1109/MCSE.2008.89
   Farias G, 2010, IEEE T IND ELECTRON, V57, P3266, DOI 10.1109/TIE.2010.2041130
   Freese M, 2010, LECT NOTES ARTIF INT, V6472, P51, DOI 10.1007/978-3-642-17319-6_8
   Gasmi H, 2018, IEEE ACCESS, V6, P1362, DOI 10.1109/ACCESS.2017.2778879
   Gonzalez Perez Isaias, 2014, Proceedings of the 11th International Conference on Informatics in Control, Automation and Robotics ICINCO 2014, P156
   Hadi Hala H., 2019, 2019 4th Scientific International Conference Najaf (SICN), P37, DOI 10.1109/SICN47020.2019.9019356
   Halabi O, 2020, MULTIMED TOOLS APPL, V79, P2987, DOI 10.1007/s11042-019-08214-8
   Henri M, 2017, J ENG EDUC, V106, P607, DOI 10.1002/jee.20180
   Heradio R, 2016, ANNU REV CONTROL, V42, P1, DOI 10.1016/j.arcontrol.2016.08.001
   Hollands RJ, 1995, IEE C MANUFACTURING, P6, DOI [10.1049/ic:19951026, DOI 10.1049/IC:19951026]
   Hoogveld AWM, 2005, TEACH TEACH EDUC, V21, P287, DOI 10.1016/j.tate.2005.01.002
   Khare S, 2014, 2014 INTERNATIONAL CONFERENCE ON POWER, CONTROL AND EMBEDDED SYSTEMS (ICPCES)
   Kim JW, 2020, MULTIMED TOOLS APPL, V79, P16281, DOI 10.1007/s11042-019-08156-1
   Ko MS, 2010, WINT SIMUL C PROC, P1727, DOI 10.1109/WSC.2010.5678898
   Ko MS, 2008, VISUAL VALIDATION PL, DOI [10.7148/2008-0410, DOI 10.7148/2008-0410]
   Letelier M. F., 1993, European Journal of Engineering Education, V18, P345, DOI 10.1080/03043799308923254
   Li J, 2018, P I CONF MEC EL AUT, P186, DOI 10.1109/ICMEAE.2018.00042
   Liang Dong, 2018, MATEC Web of Conferences, V214, DOI 10.1051/matecconf/201821404001
   Méndez JA, 2010, COMPUT EDUC, V54, P856, DOI 10.1016/j.compedu.2009.09.015
   Moon YL, 2007, ASIA PAC EDUC REV, V8, P337, DOI 10.1007/BF03029267
   Necoara I, 2013, 2013 EUROPEAN CONTROL CONFERENCE (ECC), P3596
   Oppenheim A.N., 1998, Questionnaire design, interviewing, and attitude measurement
   Park SC, 2008, INT J ADV MANUF TECH, V39, P1262, DOI 10.1007/s00170-007-1306-3
   Perez CG., 2017, J COMPETENCY BASED E, V2, DOI [10.1002/cbe2.1054, DOI 10.1002/CBE2.1054]
   Philippot A, 2017, EAEEIE ANN CONF
   Pichard R, 2018, 15 INT C INFORMATICS, P231, DOI [10.5220/0006885502310239, DOI 10.5220/0006885502310239]
   Riera B, 2017, IFAC PAPERSONLINE, V50, P9144, DOI 10.1016/j.ifacol.2017.08.1719
   Delgado LDR, 2020, P I CONF MEC EL AUT, P180, DOI 10.1109/ICMEAE51770.2020.00038
   Salah B, 2020, PROCESSES, V8, DOI 10.3390/pr8091007
   Shiakolas PS, 2003, IEEE T EDUC, V46, P79, DOI 10.1109/TE.2002.808268
   Siemens TIA Portal, US
   Tran TK, 2019, I C SOFTWARE KNOWL I, DOI 10.1109/skima47702.2019.8982491
   Vargas H, 2019, IEEE ACCESS, V7, P41043, DOI 10.1109/ACCESS.2019.2908160
   Virtual Labs (Ministry of Human Resource Development Government of India), 2022, US
   Wang Y., 2018, IEEE INT C KNOWL INN, DOI DOI 10.1109/ICKII.2018.8569048
   Xu ZA, 2021, MEAS CONTROL-UK, V54, P711, DOI 10.1177/0020294020944956
   Zhang ZN, 2021, MULTIMED TOOLS APPL, V80, P575, DOI 10.1007/s11042-020-09684-x
   Zheng Xie, 2019, 2019 International Conference on Virtual Reality and Intelligent Systems (ICVRIS). Proceedings, P17, DOI 10.1109/ICVRIS.2019.00012
NR 55
TC 2
Z9 2
U1 4
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19221
EP 19246
DI 10.1007/s11042-022-14047-9
EA OCT 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000871167100003
OA hybrid
DA 2024-07-18
ER

PT J
AU Singh, A
   Gutub, A
   Nayyar, A
   Khan, MK
AF Singh, Ashish
   Gutub, Adnan
   Nayyar, Anand
   Khan, Muhammad Khurram
TI Redefining food safety traceability system through blockchain: findings,
   challenges and open issues
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Food safety traceability systems; Blockchain technology; Consensus
   algorithms; Security and privacy issues
ID SUPPLY-CHAIN; PRODUCT TRACEABILITY; RFID TECHNOLOGY; COLD CHAIN; HEALTH;
   AUTHENTICATION; SECURITY; ADOPTION
AB In the last few decades, there has been an increase in food safety and traceability issues. To prevent accidents and misconduct, it became essential to establish Food Safety Traceability System (FSTS) to trace the food from producer to consumer. The traceability systems can help track food in supply chains from farms to retail. Numerous technologies such as Radio Frequency Identification (RFID), sensor networks, and data mining have been integrated into traditional food supply chain systems to remove unsafe food products from the chain. But, these are not adequate for the current supply chain market. The emerging technology of blockchain can overcome safety and tracking issues. This can be possible with the help of blockchain features like transparent, decentralized, distributed, and immutable. Most of the previous works missed the discussion of the systematic process and technology involved in implementing the FSTS using blockchain. In this paper, we have discussed an organized state of research of the existing FSTS using blockchain. This survey paper aims to outline a detailed analysis of blockchain technology, FSTS using blockchain, consensus algorithms, security attacks, and solutions. Several survey papers and solutions based on blockchain are included in this research paper. Also, this work discusses some of the open research issues related to FSTS.
C1 [Singh, Ashish] KIIT Deemed Univ, Sch Comp Engn, Bhubaneswar 751024, Odisha, India.
   [Gutub, Adnan] Umm Al Qura Univ, Comp Engn Dept, Mecca, Saudi Arabia.
   [Nayyar, Anand] Duy Tan Univ, Sch Comp Sci, Da Nang, Vietnam.
   [Khan, Muhammad Khurram] King Saud Univ, Coll Comp & Informat Sci, Ctr Excellence Informat Assurance, Riyadh 11653, Saudi Arabia.
C3 Kalinga Institute of Industrial Technology (KIIT); Umm Al Qura
   University; Duy Tan University; King Saud University
RP Nayyar, A (corresponding author), Duy Tan Univ, Sch Comp Sci, Da Nang, Vietnam.
EM ashishashish307@gmail.com; anandnayyar@duytan.edu.vn;
   aagutub@uqu.edu.sa; mkhurram@ksu.edu.sa
RI Gutub, Adnan Abdul-Aziz/O-1240-2016; Nayyar, Anand/F-3732-2015; KHAN,
   MUHAMMAD KHURRAM/E-4836-2014
OI Gutub, Adnan Abdul-Aziz/0000-0003-0923-202X; Nayyar,
   Anand/0000-0002-9821-6146; KHAN, MUHAMMAD KHURRAM/0000-0001-6636-0533
CR Abad E, 2009, J FOOD ENG, V93, P394, DOI 10.1016/j.jfoodeng.2009.02.004
   Abou Jaoude J, 2019, IEEE ACCESS, V7, P45360, DOI 10.1109/ACCESS.2019.2902501
   Aldrighetti Anna, 2021, International Journal on Food System Dynamics, V12, P6, DOI 10.18461/ijfsd.v12i1.72
   Alfian G, 2017, J FOOD ENG, V212, P65, DOI 10.1016/j.jfoodeng.2017.05.008
   Alkhalifah A., 2020, Blockchain for Cybersecurity and Privacy, P3, DOI DOI 10.20944/PREPRINTS201909.0117.V1
   Andryukhin AA, 2019, 2019 INTERNATIONAL CONFERENCE ON ENGINEERING TECHNOLOGIES AND COMPUTER SCIENCE (ENT): INNOVATION & APPLICATION, P15, DOI 10.1109/EnT.2019.00008
   Angeles R, 2005, INFORM SYST MANAGE, V22, P51, DOI 10.1201/1078/44912.22.1.20051201/85739.7
   [Anonymous], 2015, STELLAR DEV FDN
   [Anonymous], 2018, Network Security, DOI [10.1016/S1353-4858(18)30006-0, DOI 10.1016/S1353-4858(18)30006-0]
   [Anonymous], 2011, SOFTCOM 2011 19 INT
   Armknecht F., 2017, IACR CRYPTOL EPRINT, V2017, P1067
   Attaran M, 2007, SUPPLY CHAIN MANAG, V12, P249, DOI 10.1108/13598540710759763
   Aydar M, 2020, Arxiv, DOI arXiv:1907.04156
   Badzar A., 2016, Blockchain for securing sustainable transport contracts and supply chain transparency-an explorative study of blockchain technology in logistics
   Baralla G, 2019, 2019 IEEE/ACM 2ND INTERNATIONAL WORKSHOP ON EMERGING TRENDS IN SOFTWARE ENGINEERING FOR BLOCKCHAIN (WETSEB 2019), P40, DOI 10.1109/WETSEB.2019.00012
   Bartoletti Massimo, 2017, Financial Cryptography and Data Security. FC 2017 International Workshops WAHC, BITCOIN, VOTING, WTSC, and TA. Revised Selected Papers: LNCS 10323, P494, DOI 10.1007/978-3-319-70278-0_31
   Behnke K, 2020, INT J INFORM MANAGE, V52, DOI 10.1016/j.ijinfomgt.2019.05.025
   Bentov I., 2014, ACM SIGMETRICS Performance Evaluation Review, V42, P34
   Biswas K., 2017, FUTURE TECHNOLOGIES, P1, DOI DOI 10.1007/978-3-319-54460-1_1
   Bitcoin Forum, 2014, BITC FOR LIST MAJ BI
   Bordel B, 2019, ADV INTELL SYST, V850, P224, DOI 10.1007/978-3-030-02351-5_27
   Boverman A., 2011, TIMEJACKING BITCOIN
   Bumblauskas D, 2020, INT J INFORM MANAGE, V52, DOI 10.1016/j.ijinfomgt.2019.09.004
   Buterin V., 2014, CISC VIS NETW IND GL, V3, P1, DOI DOI 10.1145/2939672.2939785
   Cachin C., 2016, P WORKSH DISTR CRYPT, V310, P1, DOI DOI 10.4230/LIPICS.OPODIS.2016.24
   Caro Miguel Pincheira, 2018, 2018 IoT Vertical and Topical Summit on Agriculture - Tuscany (IOT Tuscany), DOI 10.1109/IOT-TUSCANY.2018.8373021
   Castro M, 1999, USENIX ASSOCIATION PROCEEDINGS OF THE THIRD SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '99), P173, DOI 10.1145/571637.571640
   Centers for Disease Control and Prevention (CDC), 2004, MMWR Morb Mortal Wkly Rep, V53, P790
   Chen L, 2018, LECT NOTES COMPUT SC, V10616, P282, DOI 10.1007/978-3-319-69084-1_19
   Chen S, 2021, INF SYST E-BUS MANAG, V19, P909, DOI 10.1007/s10257-020-00467-3
   Chen YY, 2014, J FOOD ENG, V141, P113, DOI 10.1016/j.jfoodeng.2014.05.014
   Cocco L, 2021, CASE STUDY TRADITION
   Crain T, 2018, 2018 IEEE 17TH INTERNATIONAL SYMPOSIUM ON NETWORK COMPUTING AND APPLICATIONS (NCA)
   Creydt M, 2019, FOOD CONTROL, V105, P45, DOI 10.1016/j.foodcont.2019.05.019
   Curran K., 2012, Int. J. Electr. Comput. Eng, V2, P371, DOI DOI 10.11591/ijece.v2i3.234
   De Angelis S., 2018, IT C CYB SEC
   Delgado-Segura S, 2018, MOB INF SYST, V2018, DOI 10.1155/2018/2159082
   Dhillon V., 2017, Blockchain Enabled Applications: Understand the Blockchain Ecosystem and How to Make it Work for You, P67, DOI DOI 10.1007/978-1-4842-3081-7_6
   Dib O, 2018, Int J Adv Telecommun, V11, P51
   Donet JAD, 2014, LECT NOTES COMPUT SC, V8438, P87, DOI 10.1007/978-3-662-44774-1_7
   Douceur JR, 2002, LECT NOTES COMPUT SC, V2429, P251, DOI 10.1007/3-540-45748-8_24
   Du MX, 2017, IEEE SYS MAN CYBERN, P2567, DOI 10.1109/SMC.2017.8123011
   Dziembowski S, 2015, LECT NOTES COMPUT SC, V9216, P585, DOI 10.1007/978-3-662-48000-7_29
   Eyal I, 2014, LECT NOTES COMPUT SC, V8437, P436, DOI 10.1007/978-3-662-45472-5_28
   Feng HH, 2020, J CLEAN PROD, V260, DOI 10.1016/j.jclepro.2020.121031
   Feng JY, 2013, FOOD CONTROL, V31, P314, DOI 10.1016/j.foodcont.2012.10.016
   Feng Tian, 2016, 2016 13th International Conference on Service Systems and Service Management (ICSSSM), P1, DOI 10.1109/ICSSSM.2016.7538424
   Galvez JF, 2018, TRAC-TREND ANAL CHEM, V107, P222, DOI 10.1016/j.trac.2018.08.011
   Gao K, 2020, COMM COM INF SC, V1156, P648, DOI 10.1007/978-981-15-2777-7_53
   Garaus M, 2021, FOOD CONTROL, V129, DOI 10.1016/j.foodcont.2021.108082
   Gaurav A, 2022, INT J SOFTW SCI COMP, V14, DOI 10.4018/IJSSCI.285593
   Gelpí E, 2002, ENVIRON HEALTH PERSP, V110, P457, DOI 10.1289/ehp.02110457
   George RV, 2019, J CLEAN PROD, V240, DOI 10.1016/j.jclepro.2019.118021
   Ghosh A, 2020, J NETW COMPUT APPL, V163, DOI 10.1016/j.jnca.2020.102635
   Nguyen GN, 2021, J PARALLEL DISTR COM, V153, P150, DOI 10.1016/j.jpdc.2021.03.011
   Gould LH, 2009, CLIN INFECT DIS, V49, P1480, DOI 10.1086/644621
   Greenspan G., 2015, Multichain private blockchain-white paper"
   GREENWOOD MR, 1985, J APPL TOXICOL, V5, P148, DOI 10.1002/jat.2550050305
   Gupta N., 2020, Advanced Applications Of Blockchain Technology, P207
   Halpin H, 2017, 2017 2ND IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (EUROS&PW), P1, DOI 10.1109/EuroSPW.2017.43
   Hao ZH, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17072300
   Hayati Hashri, 2018, 2018 International Seminar on Research of Information Technology and Intelligent Systems (ISRITI), P120, DOI 10.1109/ISRITI.2018.8864477
   Hearn M., 2016, CORDA DISTRIBUTED LE
   Heilman E, 2015, PROCEEDINGS OF THE 24TH USENIX SECURITY SYMPOSIUM, P129
   Hewa T, 2021, J NETW COMPUT APPL, V177, DOI 10.1016/j.jnca.2020.102857
   Hong WB, 2018, PROCEEDINGS OF 2018 1ST IEEE INTERNATIONAL CONFERENCE ON HOT INFORMATION-CENTRIC NETWORKING (HOTICN 2018), P254, DOI 10.1109/HOTICN.2018.8605963
   Hu YN, 2019, Arxiv, DOI arXiv:1810.04699
   Huang HH, 2019, LECT NOTES COMPUT SC, V11911, P32, DOI 10.1007/978-3-030-34083-4_4
   Ismail H, 2015, INT C PAR DISTRIB SY, P224, DOI 10.1109/ICPADS.2015.36
   Ji Q, 2021, FINANC RES LETT, V38, DOI 10.1016/j.frl.2019.101391
   Jones P., 2004, International Journal of Retail Distribution Management, V32, P164
   Joshi AP, 2018, MATH FDN COMPUT, V1, P121, DOI 10.3934/mfc.2018007
   Juan Y, 2021, SMART INNOV SYST TEC, V218, P313, DOI 10.1007/978-981-33-6141-6_34
   Kamath R, 2018, J BRIT BLOCKCHAIN AS, V1, P47, DOI 10.31585/jbba-1-1-(10)2018
   Kamble SS, 2020, INT J INFORM MANAGE, V52, DOI 10.1016/j.ijinfomgt.2019.05.023
   Karame G, 2018, IEEE SECUR PRIV, V16, P11, DOI 10.1109/MSP.2018.3111241
   Karantias K, 2020, LECT NOTES COMPUT SC, V12059, P523, DOI 10.1007/978-3-030-51280-4_28
   Lai R, 2018, HANDBOOK OF BLOCKCHAIN, DIGITAL FINANCE, AND INCLUSION, VOL 2: CHINATECH, MOBILE SECURITY, DISTRIBUTED LEDGER, AND BLOCKCHAIN, P145, DOI 10.1016/B978-0-12-812282-2.00007-3
   Larimer D., 2014, Bitshare whitepaper, V81, P85
   Lee MJ, 2021, 35TH INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN 2021), P546, DOI 10.1109/ICOIN50884.2021.9334025
   Leng KJ, 2018, FUTURE GENER COMP SY, V86, P641, DOI 10.1016/j.future.2018.04.061
   Li S., 2022, INT J SEMANT WEB INF, V18, P1, DOI DOI 10.4018/IJSWIS.297035
   Li XQ, 2020, FUTURE GENER COMP SY, V107, P841, DOI 10.1016/j.future.2017.08.020
   Li Z, 2018, INT SYMP PARA DISTR, P118, DOI DOI 10.1109/ISPDC2018.2018.00025
   Lin J., 2018, INT J INFORM TECHNOL, V24, P1, DOI [10.1145/3265689.3265692, DOI 10.1145/3265689.3265692]
   Lin QJ, 2019, IEEE ACCESS, V7, P20698, DOI 10.1109/ACCESS.2019.2897792
   Lin WJ, 2020, IEEE ACCESS, V8, P143920, DOI 10.1109/ACCESS.2020.3014522
   Liu XJ, 2018, IEEE WIREL COMMUN LE, V7, P760, DOI 10.1109/LWC.2018.2820009
   Lu JQ, 2022, IEEE T IND INFORM, V18, P5422, DOI 10.1109/TII.2021.3112601
   Mainetti L, 2013, COMPUT ELECTRON AGR, V98, P146, DOI 10.1016/j.compag.2013.07.015
   Mamta, 2021, IEEE-CAA J AUTOMATIC, V8, P1877, DOI 10.1109/JAS.2021.1004003
   Maull R, 2017, STRATEG CHANG, V26, P481, DOI 10.1002/jsc.2148
   Mehar MI, 2019, J CASES INF TECHNOL, V21, P19, DOI 10.4018/JCIT.2019010102
   Mercer R, 2016, Arxiv, DOI arXiv:1612.01188
   Meyer R, 1996, FOOD SCI TECHNOL-LEB, V29, P1, DOI 10.1006/fstl.1996.0001
   Mohan Tharun., 2018, Masters Thesis
   Mohanta BK, 2019, INTERNET THINGS-NETH, V8, DOI 10.1016/j.iot.2019.100107
   Monrat AA, 2019, IEEE ACCESS, V7, P117134, DOI 10.1109/ACCESS.2019.2936094
   Montet D, 2017, FOOD TRACEABILITY AU, P1
   Nakamoto S., 2008, DECENT BUS REV, V21260, DOI https://bitcoin.org/bitcoin.pdf
   Ngai EWT, 2007, DECIS SUPPORT SYST, V43, P62, DOI 10.1016/j.dss.2005.05.006
   Nguyen CT, 2019, IEEE ACCESS, V7, P85727, DOI 10.1109/ACCESS.2019.2925010
   Northcutt JK, 2013, GUIDE TO US FOOD LAWS AND REGULATIONS, 2ND EDITION, P73
   Oksiiuk O, 2020, P IEEE 15 INT C ADV, P1
   Olsen P, 2013, TRENDS FOOD SCI TECH, V29, P142, DOI 10.1016/j.tifs.2012.10.003
   Ongaro Diego, 2014, 2014 USENIX ANN TECH, P305, DOI DOI 10.1007/0-387-34805-0_21
   Ortea I, 2015, FOOD CHEM, V170, P145, DOI 10.1016/j.foodchem.2014.08.049
   Parzefall W, 2002, FOOD CHEM TOXICOL, V40, P1185, DOI 10.1016/S0278-6915(02)00059-5
   Patelli N, 2020, J FOOD SCI, V85, P3670, DOI 10.1111/1750-3841.15477
   Peercoin, 2014, INTR PEERC
   Pei XF, 2011, FOOD POLICY, V36, P412, DOI 10.1016/j.foodpol.2011.03.008
   Pigini D, 2017, SUSTAINABILITY-BASEL, V9, DOI 10.3390/su9101910
   POA Network, 2017, PROOF AUTH CONS MOD
   Podio NS, 2013, J AGR FOOD CHEM, V61, P3763, DOI 10.1021/jf305258r
   Pongnumkul S, 2017, 2017 26TH INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATION AND NETWORKS (ICCCN 2017)
   Prashar D, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12083497
   Queiroz MM, 2019, INT J INFORM MANAGE, V46, P70, DOI 10.1016/j.ijinfomgt.2018.11.021
   Quinn Ben., 2016, GUARDIAN
   Ray PP, 2021, IEEE SYST J, V15, P85, DOI 10.1109/JSYST.2020.2963840
   Ruey-Shun Chen, 2008, WSEAS Transactions on Information Science and Applications, V5, P1551
   Salah K, 2019, IEEE ACCESS, V7, P73295, DOI 10.1109/ACCESS.2019.2918000
   Schwartz D., 2014, RIPPLE LABS INC WHIT, V5, P151
   Sforza S, 2011, CHEM SOC REV, V40, P221, DOI 10.1039/b907695f
   Shahbazi Z, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10010041
   Shahid A, 2020, IEEE ACCESS, V8, P69230, DOI 10.1109/ACCESS.2020.2986257
   Sharma BD, 2002, TROP DOCT, V32, P70, DOI 10.1177/004947550203200204
   Sheng QZ, 2011, J NETW COMPUT APPL, V34, P797, DOI 10.1016/j.jnca.2010.07.008
   Shukla S, 2014, FOOD CONTROL, V37, P401, DOI 10.1016/j.foodcont.2013.08.015
   Singh A, 2018, 2018 INTERNATIONAL CONFERENCE ON COMPUTING, POWER AND COMMUNICATION TECHNOLOGIES (GUCON), P863, DOI 10.1109/GUCON.2018.8675008
   Singh J, 2018, 2018 3RD IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (EUROS&PW 2018), P67, DOI 10.1109/EuroSPW.2018.00015
   Sompolinsky Y, 2016, Arxiv, DOI arXiv:1605.09193
   Stewart I, 2012, PROOF BURN BITCOIN W
   Sugahara K, 2009, COMPUTER AND COMPUTING TECHNOLOGIES IN AGRICULTURE II, VOLUME 3, P2293
   Sukhwani H, 2017, SYM REL DIST SYST, P253, DOI 10.1109/SRDS.2017.36
   Surasak T, 2019, INT J ADV COMPUT SC, V10, P578
   Suzuki J, 2018, AMB INTELL SMART ENV, V23, P186, DOI 10.3233/978-1-61499-874-7-186
   Swathi P., 2019, 2019 10th International Conference on Computing, Communication and Networking Technologies (ICCCNT)
   Huynh TT, 2019, INT CONF SYST SCI EN, P362, DOI [10.1109/ICSSE.2019.8823094, 10.1109/icsse.2019.8823094]
   Taranto PD, 2016, BIOMOLECULAR IDENTIF
   Tauxe RV, 1997, EMERG INFECT DIS, V3, P425, DOI 10.3201/eid0304.970403
   Tewari A, 2020, INT J SEMANT WEB INF, V16, P20, DOI 10.4018/IJSWIS.2020070102
   Tian F, 2017, I C SERV SYST SERV M
   Tsang YP, 2019, IEEE ACCESS, V7, P129000, DOI 10.1109/ACCESS.2019.2940227
   Tse D, 2017, IN C IND ENG ENG MAN, P1357, DOI 10.1109/IEEM.2017.8290114
   van der Vorst JGAJ, 2006, ACCREDIT QUAL ASSUR, V11, P33, DOI 10.1007/s00769-005-0028-1
   Vasek M, 2014, LECT NOTES COMPUT SC, V8438, P57, DOI 10.1007/978-3-662-44774-1_5
   Vikaliana R, 2021, ESTUD ECON APL, V39, DOI 10.25115/eea.v39i4.4565
   Wang LC, 2019, J NETW COMPUT APPL, V127, P43, DOI 10.1016/j.jnca.2018.11.003
   Wang MN, 2018, PROCEEDINGS OF THE 2ND ACM WORKSHOP ON BLOCKCHAINS, CRYPTOCURRENCIES, AND CONTRACTS (BCC'18), P47, DOI 10.1145/3205230.3205238
   Wang SP, 2019, IEEE ACCESS, V7, P115122, DOI 10.1109/ACCESS.2019.2935873
   Wang S, 2019, IEEE T SYST MAN CY-S, V49, P2266, DOI 10.1109/TSMC.2019.2895123
   Weber Kristin, 2020, Learning and Collaboration Technologies. Human and Technology Ecosystems. 7th International Conference, LCT 2020. Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12206), P650, DOI 10.1007/978-3-030-50506-6_45
   Wenlong Yi, 2021, Journal of Physics: Conference Series, V1864, DOI 10.1088/1742-6596/1864/1/012115
   Westerkamp M, 2018, IEEE 2018 INTERNATIONAL CONGRESS ON CYBERMATICS / 2018 IEEE CONFERENCES ON INTERNET OF THINGS, GREEN COMPUTING AND COMMUNICATIONS, CYBER, PHYSICAL AND SOCIAL COMPUTING, SMART DATA, BLOCKCHAIN, COMPUTER AND INFORMATION TECHNOLOGY, P1595, DOI 10.1109/Cybermatics_2018.2018.00267
   Yang ZL, 2021, J CLEAN PROD, V290, DOI 10.1016/j.jclepro.2020.125191
   Ye CC, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON DEPENDABLE SYSTEMS AND THEIR APPLICATIONS (DSA), P15, DOI 10.1109/DSA.2018.00015
   Zhang JingJing Zhang JingJing, 2016, Journal of Henan Agricultural Sciences, V45, P155
   Zhang L, 2017, INT S INTELLIGENCE C, P204
   Zhang X, 2020, IEEE ACCESS, V8, P36398, DOI 10.1109/ACCESS.2020.2975415
   Zhang YJ, 2021, J FOOD PROCESS ENG, V44, DOI 10.1111/jfpe.13669
   Zhao Y, 2014, FOOD CHEM, V145, P300, DOI 10.1016/j.foodchem.2013.08.062
   Zheng MM, 2021, IEEE ACCESS, V9, P70571, DOI 10.1109/ACCESS.2021.3078536
   Zheng XY, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9224731
   Zheng ZB, 2017, IEEE INT CONGR BIG, P557, DOI 10.1109/BigDataCongress.2017.85
   Zhou Z, 2021, IEEE T ENG MANAG
   Zou YJ, 2020, IEEE ACCESS, V8, P187182, DOI 10.1109/ACCESS.2020.3030491
NR 166
TC 18
Z9 18
U1 16
U2 63
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21243
EP 21277
DI 10.1007/s11042-022-14006-4
EA OCT 2022
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000869339100001
PM 36276604
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Zhang, J
   Shi, WC
   Zhang, H
AF Zhang, Jun
   Shi, Wenchen
   Zhang, Hao
TI Study on versatile video coding multiple transform selection of hardware
   architecture based on FPGA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Versatile video coding; Multiple transform selection; FPGA; Pipeline
ID IMPLEMENTATION
AB The new generation of video coding standard, Versatile Video Coding (VVC), reduces the code stream by 50% at the cost of huge computational complexity by comparison with High Efficiency Video Coding standard (HEVC), especially in the transform module. In order to alleviate the high computational complexity of VVC multiple transform selection (MTS) algorithm, a new high-performance VVC MTS hardware architecture based on field programmable gate array (FPGA) is proposed. In this paper, a pipelined MTS processor architecture is able to efficiently perform the one-dimensional (1-D) transform from 4 x 4 to 64 x 64 residual blocks. The architecture design takes advantages of parallel computing and time-division multiplexing to increase the reuse rate of hardware architecture and further enhance the speed performance. The proposed implementation in Intel's Stratix 10 FPGA can reach the maximum operational frequency of 366 MHz. The 1-D MTS processor is able to process 44 fps@7680 x 4320 and greatly reduces the computational complexity of transformation in encoding and decoding.
C1 [Zhang, Jun; Shi, Wenchen] Cent South Univ, Sch Automat, Changsha 410083, Peoples R China.
   [Zhang, Hao] Cent South Univ, Sch Comp Sci & Engn, Changsha 410083, Peoples R China.
C3 Central South University; Central South University
RP Zhang, H (corresponding author), Cent South Univ, Sch Comp Sci & Engn, Changsha 410083, Peoples R China.
EM hao@csu.edu.cn
FU National Natural Science Foundation of China
FX This study was funded by National Natural Science Foundation of China.
CR [Anonymous], 2019, WORKING DRAFT 4 VERS
   [Anonymous], 2017, Algorithm descriptions of projection format conversion and video quality metrics in 360lib
   Ben Jdidia S, 2017, I C SCI TECH AUTO CO, P146, DOI 10.1109/STA.2017.8314921
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Fan YB, 2020, IEEE T CIRC SYST VID, V30, P3289, DOI 10.1109/TCSVT.2019.2934752
   Farhat I, 2020, INT CONF ACOUST SPEE, P1663, DOI [10.1109/icassp40776.2020.9054281, 10.1109/ICASSP40776.2020.9054281]
   Garrido MJ, 2020, IEEE ACCESS, V8, P81887, DOI 10.1109/ACCESS.2020.2991299
   Garrido MJ, 2019, IEEE T CONSUM ELECTR, V65, P274, DOI 10.1109/TCE.2019.2913327
   Garrido MJ, 2018, IEEE T CONSUM ELECTR, V64, P53, DOI 10.1109/TCE.2018.2812459
   High Efficiency Video Coding (HEVC),, 2013, 23008 MPEGH
   KAMMOUN A, 2018, 2018 4 INT C ADV TEC, P1, DOI DOI 10.1109/ATSIP.2018.8364448
   Kammoun A, 2020, IEEE T CIRC SYST VID, V30, P4340, DOI 10.1109/TCSVT.2019.2954749
   Kammoun A, 2018, IEEE T CONSUM ELECTR, V64, P424, DOI 10.1109/TCE.2018.2875528
   Mert AC, 2017, IEEE T CONSUM ELECTR, V63, P117, DOI 10.1109/TCE.2017.014862
   Nguyen T, 2019, PICT COD SYMP, DOI 10.1109/pcs48520.2019.8954540
NR 15
TC 0
Z9 0
U1 7
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 14929
EP 14944
DI 10.1007/s11042-022-14069-3
EA OCT 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000869194800006
DA 2024-07-18
ER

PT J
AU Gao, Z
   Zhuang, Y
   Chen, C
   Wang, QH
AF Gao, Zeng
   Zhuang, Yi
   Chen, Chen
   Wang, Qiuhong
TI Hybrid modified marine predators algorithm with teaching-learning-based
   optimization for global optimization and abrupt motion tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Marine predators algorithm; Teaching-learning-based optimization;
   Benchmark functions; Engineering design problems; Visual tracking
ID VISUAL TRACKING; PARTICLE SWARM; DESIGN
AB Marine predators algorithm (MPA) has solved many challenging optimization problems since proposed. However, corresponding to specific optimization tasks (e.g., visual tracking), it is usually hard to select correct multiple parameters in MPA, which will greatly limit the exploitation and exploration performance. As a result, MPA could be misled to a local minima or even did not converge. To solve this issue, we advise an enhanced version of MPA based on teaching-learning-based optimization (MMPA-TLBO) which can concurrently improve the solution accuracy and the convergence speed. Specifically, first, we propose a modified MPA (MMPA) that leverages chaotic map and opposition-based learning strategy in the initialization stage to generate high-quality individuals. Second, we introduce a parameter-free teaching-learning-based optimization method with strong exploitation operator into MPA, called MMPA-TLBO, which effectively trade-off between the exploitation and exploration procedures. Finally, extensive experiments over 23 benchmark functions, CEC2017 benchmark problems and two engineering design problems show that MMPA-TLBO is better than other algorithms. Furthermore, we perform a thought-provoking case study of MMPA-TLBO on visual tracking. The experimental results show that the MMPA-TLBO tracker can outperform other trackers with a satisfied margin, especially for abrupt motion tracking.
C1 [Gao, Zeng; Zhuang, Yi; Chen, Chen; Wang, Qiuhong] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, 29 Jiangjun Rd, Nanjing 211106, Jiangsu, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics
RP Zhuang, Y (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, 29 Jiangjun Rd, Nanjing 211106, Jiangsu, Peoples R China.
EM nuaa317@163.com
RI Zhuang, Yi/W-8655-2018; WANG, Qiuhong/L-9577-2016
OI Gao, Zeng/0000-0003-1400-7820
FU National Natural Science Foundation of China [62072235]
FX Authors would like to thank the anonymous reviewers and editors for
   their valuable comments and suggestions to improve this paper. Besides,
   This work was supported by the National Natural Science Foundation of
   China under Grant No.62072235.
CR Abd El Sattar M, 2021, NEURAL COMPUT APPL, V33, P11799, DOI 10.1007/s00521-021-05822-0
   Abdel-Basset M, 2021, ENERG CONVERS MANAGE, V227, DOI 10.1016/j.enconman.2020.113491
   Abdel-Basset M, 2019, MULTIMED TOOLS APPL, V78, P3861, DOI 10.1007/s11042-017-4803-x
   Abualigah L, 2021, COMPUT METHOD APPL M, V376, DOI 10.1016/j.cma.2020.113609
   Ahmad S, 2022, CLUSTER COMPUT, V25, P3733, DOI 10.1007/s10586-022-03598-z
   Al-shameri WFH., 2013, INT J MATH ANAL, V7, P1433, DOI DOI 10.12988/IJMA.2013.3361
   Awad N., 2016, PROBLEM DEFINITIONS
   Awad NH, 2017, IEEE C EVOL COMPUTAT, P372, DOI 10.1109/CEC.2017.7969336
   Charef-Khodja D, 2021, MULTIMED TOOLS APPL, V80, P21381, DOI 10.1007/s11042-021-10691-9
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Daneshyar SA, 2022, APPL SOFT COMPUT, V122, DOI 10.1016/j.asoc.2022.108802
   Dhiman G, 2019, KNOWL-BASED SYST, V165, P169, DOI 10.1016/j.knosys.2018.11.024
   Dorigo M, 2010, INT SER OPER RES MAN, V146, P227, DOI 10.1007/978-1-4419-1665-5_8
   Du NT, 2022, MULTIMED TOOLS APPL, V81, P27397, DOI 10.1007/s11042-022-12882-4
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Elaziz MA, 2021, ENERG CONVERS MANAGE, V236, DOI 10.1016/j.enconman.2021.113971
   Faramarzi A, 2020, EXPERT SYST APPL, V152, DOI 10.1016/j.eswa.2020.113377
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Houssein EH, 2022, EXPERT SYST APPL, V187, DOI 10.1016/j.eswa.2021.115870
   Issa M, 2018, EXPERT SYST APPL, V99, P56, DOI 10.1016/j.eswa.2018.01.019
   Kaidi W, 2022, KNOWL-BASED SYST, V235, DOI 10.1016/j.knosys.2021.107625
   Kanmani M, 2019, INT J BIOMED ENG TEC, V31, P278
   Madheswari K, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P2826, DOI 10.1109/TENCON.2016.7848558
   Madheswari K., 2015, INT J APPL ENG RES, V10, P1590
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Nathan SS., 2018, INT J APPL ENG RES, V13, P8187
   Nathan SS., 2018, INT J APPL ENG RES, V13, P8179
   Nyo MT, 2022, MULTIMED TOOLS APPL, V81, P43837, DOI 10.1007/s11042-022-13215-1
   Parameswaran T., 2012, INT J COMPUT APPL, V975, P8887
   Dinh PH, 2021, BIOMED SIGNAL PROCES, V67, DOI 10.1016/j.bspc.2021.102536
   RAGSDELL KM, 1976, J ENG IND-T ASME, V98, P1021, DOI 10.1115/1.3438995
   Rao RV, 2011, COMPUT AIDED DESIGN, V43, P303, DOI 10.1016/j.cad.2010.12.015
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   RUTENBAR RA, 1989, IEEE CIRCUITS DEVICE, V5, P19, DOI 10.1109/101.17235
   Saremi S, 2017, ADV ENG SOFTW, V105, P30, DOI 10.1016/j.advengsoft.2017.01.004
   Shadravan S, 2019, ENG APPL ARTIF INTEL, V80, P20, DOI 10.1016/j.engappai.2019.01.001
   Shaheen MAM, 2020, ENERGIES, V13, DOI 10.3390/en13215679
   Simon D, 2008, IEEE T EVOLUT COMPUT, V12, P702, DOI 10.1109/TEVC.2008.919004
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Sun XK, 2021, J CLEAN PROD, V284, DOI 10.1016/j.jclepro.2020.124776
   Talbi E-G, 2009, Metaheuristics: from Design to Implementation, DOI DOI 10.1002/9780470496916
   Tanabe R, 2013, 2013 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC), P71
   Tao ZL, 2023, IEEE T MULTIMEDIA, V25, P5107, DOI 10.1109/TMM.2022.3187556
   Theresa XB., 2018, INT J APPL ENG RES, V13, P8831
   Umamaheswari S, 2018, INT J APPL ENG RES, V13, P8407
   Wang D, 2016, IEEE T CIRC SYST VID, V26, P1709, DOI 10.1109/TCSVT.2015.2462012
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Xu XL, 2020, APPL SOFT COMPUT, V89, DOI 10.1016/j.asoc.2020.106086
   Xu YD, 2020, AAAI CONF ARTIF INTE, V34, P12549
   Yang WB, 2022, ENG APPL ARTIF INTEL, V108, DOI 10.1016/j.engappai.2021.104558
   Yousri D, 2021, ENERG CONVERS MANAGE, V228, DOI 10.1016/j.enconman.2020.113692
   Zhang H, 2019, LECT NOTES COMPUTER, P217, DOI DOI 10.1007/978-3-030-31654-9_19
   Zhang HL, 2019, IEEE ACCESS, V7, P168575, DOI 10.1109/ACCESS.2019.2954500
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   Zhou WZ, 2021, IEEE T IMAGE PROCESS, V30, P3597, DOI 10.1109/TIP.2021.3060905
NR 58
TC 5
Z9 5
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19793
EP 19828
DI 10.1007/s11042-022-13819-7
EA OCT 2022
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000866314300001
DA 2024-07-18
ER

PT J
AU Nair, SC
   Elayidom, S
   Gopalan, S
AF Nair, Suja Chandrasekharan
   Elayidom, Sudheep
   Gopalan, Sasi
TI Mining frequent patterns with generalized linear model for traffic
   density analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Traffic density analysis; Call data record; Frequent pattern mining;
   Mobile network; Generalized linear models
ID SMART; INTERNET; CITIES
AB Call Detail Record (CDR) is the detailed record of all the telephonic calls that pass through a telephone exchange or any other telecommunications equipment. It contains temporal and spatial data, and can also convey other information that would be helpful to the user. Large numbers of vehicles on roads creates substantial traffic, which makes it very difficult to maintain safety and control traffic especially in the urban areas. Several works were carried out in the past to estimate the traffic density. However, they were inappropriate and quite expensive, owing to the dynamics of the traffic flow. This paper proposes the use of CDR data to find the high traffic density zones (HTDZs). For prediction purpose, we mine the frequent patterns from CDR data to find the co-occurrence of the position associated with a mobile user. In addition, Recurrent neural Networks (RNN) using LSTM (Long Short-term memory) are used for the time series prediction. The proposed system helps the whole public not only the registered users by decreasing the accident rates. Statistical performance evaluation integrated with time series causality is done for the proposed system. The proposed system is evaluated over standard data sets and an accuracy of 96% is achieved and a root mean square value was obtained as 3.84 during prediction.
C1 [Nair, Suja Chandrasekharan; Elayidom, Sudheep; Gopalan, Sasi] Cochin Univ Sci & Technol, Kochi, Kerala, India.
C3 Cochin University Science & Technology
RP Nair, SC (corresponding author), Cochin Univ Sci & Technol, Kochi, Kerala, India.
EM sujanair.phd@gmail.com; sudheepelayidom@gmail.com; sgcusat@gmail.com
RI Elayidom, Sudheep M/AAQ-9356-2021
OI Elayidom, Sudheep M/0000-0003-3836-7425
CR Abu Taher K, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON ROBOTICS, ELECTRICAL AND SIGNAL PROCESSING TECHNIQUES (ICREST), P643, DOI [10.1109/ICREST.2019.8644161, 10.1109/icrest.2019.8644161]
   Akande A, 2019, SUSTAIN CITIES SOC, V44, P475, DOI 10.1016/j.scs.2018.10.009
   Akhtar M, 2021, J ADV TRANSPORT, V2021, DOI 10.1155/2021/8878011
   Amini MH, 2017, SUSTAIN CITIES SOC, V28, P332, DOI 10.1016/j.scs.2016.10.006
   Baldi S, 2019, TRANSPORT SCI, V53, P6, DOI 10.1287/trsc.2017.0754
   Bhatia M, 2017, PEER PEER NETW APPL, V10, P1182, DOI 10.1007/s12083-016-0471-2
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Buczak AL, 2016, IEEE COMMUN SURV TUT, V18, P1153, DOI 10.1109/COMST.2015.2494502
   Callado A, 2009, IEEE COMMUN SURV TUT, V11, P37, DOI 10.1109/SURV.2009.090304
   Chapaneri R, 2009, SMART INTELLIGENT CO, P345
   Datir Harshal N., 2019, Data Management, Analytics and Innovation. Proceedings of ICDMAI 2018. Advances in Intelligent Systems and Computing (AISC 808), P291, DOI 10.1007/978-981-13-1402-5_22
   Deo N, 2018, IEEE COMPUT SOC CONF, P1549, DOI 10.1109/CVPRW.2018.00196
   Ding YK, 2020, NEUROCOMPUTING, V403, P348, DOI 10.1016/j.neucom.2020.04.110
   Dogan E, 2022, SOFT COMPUT, V26, P5227, DOI 10.1007/s00500-022-07023-w
   García-Teodoro P, 2009, COMPUT SECUR, V28, P18, DOI 10.1016/j.cose.2008.08.003
   Kashinath SA, 2021, IEEE ACCESS, V9, P51258, DOI 10.1109/ACCESS.2021.3069770
   Kidando E, 2021, ACCIDENT ANAL PREV, V149, DOI 10.1016/j.aap.2020.105869
   Le KG, 2022, INT J CRASHWORTHINES, V27, P543, DOI 10.1080/13588265.2020.1826800
   Lei T, 2021, J ADV TRANSPORT, V2021, DOI 10.1155/2021/8820402
   Lin L, 2022, IEEE INTEL TRANSP SY, V14, P197, DOI 10.1109/MITS.2021.3049404
   Mao Y, 2022, INT J URBAN SCI, V26, P87, DOI 10.1080/12265934.2021.1882331
   Martín J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19204505
   Nguyen TTT, 2008, IEEE COMMUN SURV TUT, V10, P56, DOI 10.1109/SURV.2008.080406
   Ouyang PY, 2022, J TRANSP SAF SECUR, V14, P630, DOI 10.1080/19439962.2020.1801924
   Peng LZ, 2017, COMPUT COMMUN, V102, P177, DOI 10.1016/j.comcom.2016.05.010
   Roy KC, 2018, TRB COMMITTEE ABR20, P6
   Saeed A, 2019, IEEE ACCESS, V7, P3122, DOI 10.1109/ACCESS.2018.2888813
   Sanagavarapu S, 2021, 2021 IEEE 11TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P264, DOI 10.1109/CCWC51732.2021.9376123
   Shafiq M, 2020, FUTURE GENER COMP SY, V107, P433, DOI 10.1016/j.future.2020.02.017
   Uluturk I, 2020, THESIS U S FLORIDA
   Vadhwani Diya, 2021, Advances in VLSI and Embedded Systems. Select Proceedings of AVES 2019. Lecture Notes in Electrical Engineering (LNEE 676), P55, DOI 10.1007/978-981-15-6229-7_5
   Vehicledenas O, 2018, LOGFORUM, V14
   Wong S., 2021, P 3 C LEARN DYN CONT, P917
   Wu L, 2022, CONNECT SCI, V34, P874, DOI 10.1080/09540091.2021.1993137
   Yigitcanlar T, 2019, SUSTAIN CITIES SOC, V45, P348, DOI 10.1016/j.scs.2018.11.033
   Yu Jingyu, 2021, IOP Conference Series: Earth and Environmental Science, V783, DOI 10.1088/1755-1315/783/1/012153
   Zhang J, 2021, KSCE J CIV ENG, V25, P3995
   Zhang KN, 2022, TRANSPORT RES A-POL, V159, P96, DOI 10.1016/j.tra.2022.01.017
NR 38
TC 0
Z9 0
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18327
EP 18352
DI 10.1007/s11042-022-13802-2
EA OCT 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000865911200001
DA 2024-07-18
ER

PT J
AU Jain, S
AF Jain, Sarika
TI Product discovery utilizing the semantic data model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Knowledge graph; Ontology; Engineering equipment; Multimedia data;
   Product categorization; Product matching; Recommendation
ID ONTOLOGY; OFFERS
AB Most of the existing techniques to product discovery and recommendations rely on syntactic approaches, thus ignoring valuable and specific semantic information of the underlying standards during the process. The product data comes from different heterogeneous sources and formats (text and multimedia) giving rise to the problem of interoperability. Above all, due to the continuously increasing influx of data, the manual labeling is getting costlier. Integrating the descriptions of different products into a single representation requires organizing all the products across vendors in a single taxonomy. Practically relevant and quality product categorization standards are still limited in number; and that too in academic research projects where we can majorly see only prototypes as compared to industry. This work presents a cost-effective aggregator semantic web portal for product catalogues on the Data Web as a digital marketplace. The proposed architecture creates a knowledge graph of available products through the ETL (Extract-Transform-Load)) approach and stores the resulting RDF serializations in the Jena triple store. User input textual and multimedia specifications for certain products are matched against the available product categories to recommend matching products with price comparison across the vendors. The experimental results show that semantic intelligence technologies could provide the necessary data integration and interoperability for efficient product/service discovery including multimedia.
C1 [Jain, Sarika] Natl Inst Technol Kurukshetra, Dept Comp Applicat, Kurukshetra, Haryana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra
RP Jain, S (corresponding author), Natl Inst Technol Kurukshetra, Dept Comp Applicat, Kurukshetra, Haryana, India.
EM jasarika@nitkkr.ac.in
CR Akritidis L, 2018, 2018 INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA)
   Allan J., 1998, Topic Detection and Tracking Pilot Study Final Report
   Bhatt S, 2020, IEEE INTERNET COMPUT, V24, P66, DOI 10.1109/MIC.2020.2979620
   Bhutani P, 2021, 2021 ADV COMPUTATION, V2823, P30
   Bolelli L, 2009, LECT NOTES COMPUT SC, V5478, P776, DOI 10.1007/978-3-642-00958-7_84
   Brunner JS, 2007, P 16 INT C WORLD WID, P747, DOI DOI 10.1145/1242572.1242673
   Calvanese D, 2017, SEMANT WEB, V8, P471, DOI 10.3233/SW-160217
   Chaves-Fraga D, 2018, STUDIES SEMANTIC WEB, P235, DOI DOI 10.3233/978-1-61499-894-5-235
   Curry E., 2020, REAL TIME LINKED DAT, P15, DOI [10.1007/978-3-030-29665-0_2, DOI 10.1007/978-3-030-29665-0_2]
   Diaz-Agudo B, 2019, LECT NOTES ARTIF INT, V11680, P33, DOI 10.1007/978-3-030-29249-2_3
   Dubey S, 2021, WEB SEMANTICS CUTTIN
   Duvvuru A, 2013, PROCEDIA COMPUT SCI, V20, P439, DOI 10.1016/j.procs.2013.09.300
   Fitzpatrick D, 2012, IFIP ADV INF COMM TE, V388, P559
   García-González H, 2020, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.318
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Hepp, 2005, P ISWC2005 GALW
   Hepp M, 2008, LECT NOTES ARTIF INT, V5268, P329, DOI 10.1007/978-3-540-87696-0_29
   Iglesias E, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P3039, DOI 10.1145/3340531.3412881
   Jain S, 2021, WEB SEMANTICS CUTTIN
   Jain S, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION & AUTOMATION (ICCCA), P955, DOI 10.1109/CCAA.2015.7148534
   Jozashoori S, 2020, LECT NOTES COMPUT SC, V12506, P276, DOI 10.1007/978-3-030-62419-4_16
   Junior A.C., 2016, P IIWAS, P267, DOI DOI 10.1145/3011141.3011152
   Kim H, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13041722
   Li XY, 2021, COMPUT IND, V129, DOI 10.1016/j.compind.2021.103449
   Li XY, 2020, J MECH DESIGN, V142, DOI 10.1115/1.4046807
   Lin YC, 2019, PROCEEDINGS OF THE 2019 ACM SIGIR INTERNATIONAL CONFERENCE ON THEORY OF INFORMATION RETRIEVAL (ICTIR'19), P212, DOI 10.1145/3341981.3344237
   Tosi MDL, 2022, J INF SCI, V48, P71, DOI 10.1177/0165551520937915
   Mauge Karin, 2012, P 50 ANN M ASS COMP, P805
   Meusel R, 2015, LECT NOTES BUS INF P, V239, P83, DOI 10.1007/978-3-319-27729-5_7
   Meusel R, 2014, LECT NOTES COMPUT SC, V8796, P277, DOI 10.1007/978-3-319-11964-9_18
   Nederstigt LJ, 2014, DECIS SUPPORT SYST, V59, P296, DOI 10.1016/j.dss.2014.01.001
   Nigam P, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2876, DOI 10.1145/3292500.3330759
   Noy NF, 2003, INT J HUM-COMPUT ST, V59, P983, DOI 10.1016/j.ijhcs.2003.08.002
   Osborne Francesco, 2012, The Semantic Web. 11th International Semantic Web Conference (ISWC 2012). Proceedings, P410, DOI 10.1007/978-3-642-35176-1_26
   Patel A, 2019, INFECT CONT HOSP EP, V40, P392, DOI [10.1017/ice.2019.20, 10.1080/1206212X.2019.1570666]
   Pohorec S, 2013, COMPUT STAND INTER, V36, P256, DOI 10.1016/j.csi.2013.06.003
   Roos T., 2002, IEEE Transactions on Mobile Computing, V1, P59, DOI 10.1109/TMC.2002.1011059
   Sehgal S, 2016, PROCEDIA COMPUT SCI, V92, P562, DOI 10.1016/j.procs.2016.07.383
   Sheth A, 2004, SEMANTIC ENTERPRISE, DOI [10.1201/9780203507223.ch9, DOI 10.1201/9780203507223.CH9]
   Sjekavica T, 2013, 4 EUROPEAN C COMPUTE
   Stolz Alex, 2013, Semantic Web: Semantics and Big Data. Proceedings of 10th International Conference (ESWC 2013): LNCS 7882, P623
   Vandic D, 2012, DECIS SUPPORT SYST, V53, P425, DOI 10.1016/j.dss.2012.02.010
   Wauer M, 2010, P 12 INT C INF INT W, P325
   Wu J, 2017, ACM-IEEE J CONF DIG, P241
   Xian YK, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P285, DOI 10.1145/3331184.3331203
   Zhang LY, 2009, J COMPUT, V4, P4369
   Zhang Y, 2018, J INFORMETR, V12, P1099, DOI 10.1016/j.joi.2018.09.004
NR 47
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 9173
EP 9199
DI 10.1007/s11042-022-13804-0
EA SEP 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000863188000006
DA 2024-07-18
ER

PT J
AU Hassan, E
   Shams, MY
   Hikal, NA
   Elmougy, S
AF Hassan, Esraa
   Shams, Mahmoud Y.
   Hikal, Noha A.
   Elmougy, Samir
TI The effect of choosing optimizer algorithms to improve computer vision
   tasks: a comparative study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optimization algorithm; Stochastic gradient decent; Rung Kutta
   optimization; Deep ensembles; Medical images
AB Optimization algorithms are used to improve model accuracy. The optimization process undergoes multiple cycles until convergence. A variety of optimization strategies have been developed to overcome the obstacles involved in the learning process. Some of these strategies have been considered in this study to learn more about their complexities. It is crucial to analyse and summarise optimization techniques methodically from a machine learning standpoint since this can provide direction for future work in both machine learning and optimization. The approaches under consideration include the Stochastic Gradient Descent (SGD), Stochastic Optimization Descent with Momentum, Rung Kutta, Adaptive Learning Rate, Root Mean Square Propagation, Adaptive Moment Estimation, Deep Ensembles, Feedback Alignment, Direct Feedback Alignment, Adfactor, AMSGrad, and Gravity. prove the ability of each optimizer applied to machine learning models. Firstly, tests on a skin cancer using the ISIC standard dataset for skin cancer detection were applied using three common optimizers (Adaptive Moment, SGD, and Root Mean Square Propagation) to explore the effect of the algorithms on the skin images. The optimal training results from the analysis indicate that the performance values are enhanced using the Adam optimizer, which achieved 97.30% accuracy. The second dataset is COVIDx CT images, and the results achieved are 99.07% accuracy based on the Adam optimizer. The result indicated that the utilisation of optimizers such as SGD and Adam improved the accuracy in training, testing, and validation stages.
C1 [Hassan, Esraa; Shams, Mahmoud Y.] Kafrelsheikh Univ, Fac Artificial Intelligence, Kafrelsheikh 33516, Egypt.
   [Hikal, Noha A.] Mansoura Univ, Fac Comp & Informat, Dept Informat Technol, Mansoura 35516, Egypt.
   [Elmougy, Samir] Mansoura Univ, Fac Comp & Informat, Dept Comp Sci, Mansoura 35516, Egypt.
C3 Egyptian Knowledge Bank (EKB); Kafrelsheikh University; Egyptian
   Knowledge Bank (EKB); Mansoura University; Egyptian Knowledge Bank
   (EKB); Mansoura University
RP Hassan, E (corresponding author), Kafrelsheikh Univ, Fac Artificial Intelligence, Kafrelsheikh 33516, Egypt.
EM esraa.hassan@ai.kfs.edu.eg; mahmoud.yasin@ai.kfs.edu.eg
RI Mougy, Samir E El/P-9783-2018; Shams, Mahmoud Y./AAM-9251-2020
OI Shams, Mahmoud Y./0000-0003-3021-5902
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Ahmadianfar I, 2021, EXPERT SYST APPL, V181, DOI 10.1016/j.eswa.2021.115079
   Akbari H, 2021, ADV NEUR IN
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Assran M, 2019, PR MACH LEARN RES, V97
   Bahrami D, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2101.09192
   Basak J, 2020, ADV INTELL SYST COMP, V1137, P418, DOI 10.1007/978-3-030-40690-5_41
   Bass C, 2021, ARXIV
   Benton Gregory W., 2021, PMLR, V139, P769
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Brochu E, 2010, ARXIV10122599
   Castrogiovanni P, 2020, IEEE ACCESS, V8, P58377, DOI 10.1109/ACCESS.2020.2982218
   Chen TY, 2021, PR MACH LEARN RES, V130, P613
   Chen T, 2020, PR MACH LEARN RES, V119
   Curtin RR., 2021, J MACH LEARN RES, V22, P166
   Dai J, 2019, PROCEEDINGS OF THE 2019 TENTH ACM SYMPOSIUM ON CLOUD COMPUTING (SOCC '19), P50, DOI 10.1145/3357223.3362707
   Datta SK, 2021, LECT NOTES COMPUT SC, V12929, P13, DOI 10.1007/978-3-030-87444-5_2
   Defazio A, 2017, ADAPTIVITY COMPROMIS, P1
   Defazio A, 2022, J MACH LEARN RES, V23
   Ding XH, 2021, PROC CVPR IEEE, P13728, DOI 10.1109/CVPR46437.2021.01352
   El-Nouby A., 2021, ARXIV
   Elleuch M, 2016, PROCEDIA COMPUT SCI, V80, P1712, DOI 10.1016/j.procs.2016.05.512
   Elzeki OM, 2021, PEERJ COMPUT SCI, DOI [10.7717/peerj-sc.358, 10.7717/peerj-cs.358]
   Elzeki OM, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.364
   Ensmallen.org, US
   Fadda E, 2019, WORKSHOP COMPUTATION, P71
   Fadda E, 2021, TRANSPORT RES E-LOG, V145, DOI 10.1016/j.tre.2020.102174
   Fu Y, 2022, ARXIV
   Gower RM, 2019, PR MACH LEARN RES, V97
   Goyal P., 2021, arXiv
   Hameed N, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112961
   Pham H, 2021, PROC CVPR IEEE, P11552, DOI 10.1109/CVPR46437.2021.01139
   Hoffman M, 2020, ADV CONCEPTS HUMAN I, P1, DOI DOI 10.1007/978-3-030-33946-3_1
   Hosny KM, 2018, CAIRO INT BIOM ENG, P90, DOI 10.1109/CIBEC.2018.8641762
   Izmailov P, 2021, PR MACH LEARN RES, V139
   Jinia AJ, 2020, IEEE ACCESS, V8, P111347, DOI 10.1109/ACCESS.2020.3002886
   Kamran SA, 2021, INT C PATT RECOG, P9122, DOI 10.1109/ICPR48806.2021.9412428
   Kefato ZT, 2021, ARXIV
   Khosla Prannay, 2020, ADV NEURAL INFORM PR, V33, P18661
   Kittler Harald, 2018, ISIC CHALLENGE
   Kumar A, 2020, DEEP LEARNING TECHNI, P211, DOI [DOI 10.1007/978-3-030-33966-111, DOI 10.1007/978-3-030-33966-1_11]
   Lample G., 2019, ARXIV
   Li C. L., 2021, ARXIV
   Li N, 2020, ARXIV
   Lim DY, 2021, ARXIV
   Liu J., 2020, ADV NEURAL INFORM PR, V33, P7498, DOI DOI 10.5555/3495724.3496353
   Liu XY, 2019, FRONT BIOENG BIOTECH, V7, DOI 10.3389/fbioe.2019.00358
   Liu Y, 2020, NAT MED, V26, P900, DOI 10.1038/s41591-020-0842-3
   Mahbod A, 2020, COMPUT METH PROG BIO, V197, DOI 10.1016/j.cmpb.2020.105725
   Marin G, 2004, SIGMETRICS PERFORM E, P2, DOI DOI 10.1145/1005686.1005691
   Martin R, 2001, IEEE T SPEECH AUDI P, V9, P504, DOI 10.1109/89.928915
   Nadipineni H, 2020, ARXIV
   Najafi A, COMSTREAMCLUST ACOMM
   Narayanan DL, 2010, INT J DERMATOL, V49, P978, DOI 10.1111/j.1365-4632.2010.04474.x
   Noroozi V, 2020, ARXIV
   Ohana R, 2020, INT CONF ACOUST SPEE, P9294, DOI [10.1109/ICASSP40776.2020.9053272, 10.1109/icassp40776.2020.9053272]
   Osaba E, 2021, SWARM EVOL COMPUT, V64, DOI 10.1016/j.swevo.2021.100888
   Ouyang LH, 2015, QUAL RELIAB ENG INT, V31, P193, DOI 10.1002/qre.1571
   Pang TY, 2019, PR MACH LEARN RES, V97
   Proposal C, CORNER PROPOSAL NETW, P1
   Qiao A, 2021, PROCEEDINGS OF THE 15TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '21), P1
   Radosavovic I, 2019, IEEE I CONF COMP VIS, P1882, DOI 10.1109/ICCV.2019.00197
   Radosavovic Ilija, 2020, P IEEE CVF C COMP VI, P10428
   Ritter H., 2021, ADV NEURAL INF PROCE, V34, P6515
   Ruder S., 2016, ARXIV
   Saha S, 2021, PROC CVPR IEEE, P8193, DOI 10.1109/CVPR46437.2021.00810
   Salem H., 2021, Medical Informatics and Bioimaging Using Artificial Intelligence: Challenges, Issues, Innovations and Recent Developments, V1005, P93, DOI 10.1007/978-3-030-91103-4_6
   Salem H, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12030950
   Sarhan S, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/8821868
   Shams M.Y., 2020, Big Data Analytics and Artificial Intelligence Against COVID-19: Innovation Vision and Approach, P147, DOI DOI 10.1007/978-3-030-55258-9_9
   Siems Julien, 2020, ARXIV
   Spall James C., 2012, Handbook of computational statistics, P173
   Sun Z, 2020, ARXIV
   Tang HL, 2021, PR MACH LEARN RES, V139, P7124
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang S, 2020, MEDRXIV, DOI [10.1101/2020.02,14, DOI 10.1101/2020.02,14]
   Wenzel F, 2020, 37 INT C MACH LEARN, P10179
   Wright L, 2021, ARXIV
   Xianzhi Du, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11589, DOI 10.1109/CVPR42600.2020.01161
   Xin Y, 2018, IEEE ACCESS, V6, P35365, DOI 10.1109/ACCESS.2018.2836950
   Xu YY, 2020, SCI PROGRAMMING-NETH, V2020, DOI 10.1155/2020/7845384
   Xue D, 2020, IEEE ACCESS, V8, P104603, DOI 10.1109/ACCESS.2020.2999816
   Yao SY, 2021, IEEE T IMAGE PROCESS, V30, P1989, DOI 10.1109/TIP.2021.3050314
   Yao ZW, 2021, AAAI CONF ARTIF INTE, V35, P10665
   Yeung DS, 2016, IEEE T NEUR NET LEAR, V27, P978, DOI 10.1109/TNNLS.2015.2431251
   Yfpeng, 2021, US
   Zaheer Raniah, 2019, 2019 Third International Conference on Inventive Systems and Control (ICISC), P536, DOI 10.1109/ICISC44355.2019.9036442
   Zanotti T, 2021, INT INTEG REL WRKSP, P7, DOI 10.1109/IIRW53245.2021.9635626
   Zhang H, 2022, IEEE COMPUT SOC CONF, P2735, DOI 10.1109/CVPRW56347.2022.00309
   ZHANG ST, 2021, PR MACH LEARN RES, V139
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
   Zhu TF, 2022, KNOWL-BASED SYST, V247, DOI 10.1016/j.knosys.2022.108764
   ZHUGE M, 2022, IEEE T PATTERN ANAL, P1, DOI DOI 10.1109/TPAMI.2022.3179526
NR 95
TC 36
Z9 37
U1 4
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16591
EP 16633
DI 10.1007/s11042-022-13820-0
EA SEP 2022
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000861190800007
PM 36185324
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Jindal, A
   Ghosh, R
AF Jindal, Amar
   Ghosh, Rajib
TI Text line segmentation in indian ancient handwritten documents using
   faster R-CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text line segmentation; Ancient documents; Devanagari script; Faster
   R-CNN
ID WORD RECOGNITION; DEVANAGARI
AB Textline segmentation in ancient handwritten documents is still considered as a challenging task in document analysis and recognition field even though various rule-based methods exist. These methods succeed under constraint such as a roughly uniform background. They do not contribute well in case of variable inter-line spacing and overlapping characters. This article proposes faster region-convolution neural network (R-CNN) based robust method to segment the textlines in the ancient handwritten document in Devanagari script for the first time in literature. The feature matrix has been generated by residual network and proposals have been predicted through the region proposal network (RPN). A pooling layer has been used to extract regions of interest, known as region of interest pooling layer, to locate the textlines. The performance of the proposed textline segmentation system has been evaluated on self generated dataset of ancient handwritten documents in Devanagari script and it has achieved the f-measure of 99.98%. Experimental results demonstrate that the proposed system outperforms the existing state-of-the-art methods of textline segmentation.
C1 [Jindal, Amar; Ghosh, Rajib] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna 800005, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Ghosh, R (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna 800005, Bihar, India.
EM rajib.ghosh@nitp.ac.in
RI GHOSH, RAJIB/C-9927-2017; Jindal, Amar/IZP-7693-2023
OI GHOSH, RAJIB/0000-0002-8553-8656; Jindal, Amar/0000-0002-5442-6811
CR Ben Messaoud I, 2012, INT CONF FRONT HAND, P515, DOI 10.1109/ICFHR.2012.159
   Chammas E, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), P43, DOI 10.1109/DAS.2018.15
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Garz A., 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P95, DOI 10.1109/DAS.2012.23
   Ghosh R, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114249
   Ghosh R, 2019, PATTERN RECOGN, V92, P203, DOI 10.1016/j.patcog.2019.03.030
   Ghosh R, 2018, INT CONF FRONT HAND, P517, DOI 10.1109/ICFHR-2018.2018.00096
   Grüning T, 2019, INT J DOC ANAL RECOG, V22, P285, DOI 10.1007/s10032-019-00332-1
   Gupta MR, 2007, PATTERN RECOGN, V40, P389, DOI 10.1016/j.patcog.2006.04.043
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Kavitha AS, 2016, EGYPT INFORM J, V17, P189, DOI 10.1016/j.eij.2015.11.003
   Kim S, 2020, AAAI CONF ARTIF INTE, V34, P11270
   Kleber F, 2008, INT C PATT RECOG, P1893
   Lenc L, 2021, EVOL SYST-GER, V12, P177, DOI 10.1007/s12530-020-09343-4
   Likforman-Sulem L., 1994, Advances in handwriting and drawing: a multidisciplinary approach, P117
   Liu SY, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P730, DOI 10.1109/ACPR.2015.7486599
   Louloudis G, 2009, PATTERN RECOGN, V42, P3169, DOI 10.1016/j.patcog.2008.12.016
   Martínek J, 2020, NEURAL COMPUT APPL, V32, P17209, DOI 10.1007/s00521-020-04910-x
   Moysset B, 2015, PROC INT CONF DOC, P456, DOI 10.1109/ICDAR.2015.7333803
   Narang S, 2019, SADHANA-ACAD P ENG S, V44, DOI 10.1007/s12046-019-1126-9
   Narang SR., 2019, P NATL A SCI INDIA A, V90, P1
   Pelikan M, 1999, GECCO-99: PROCEEDINGS OF THE GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P525
   Vo QN, 2016, IEEE IMAGE PROC, P3264, DOI 10.1109/ICIP.2016.7532963
   Rabaev I, 2013, PROC INT CONF DOC, P812, DOI 10.1109/ICDAR.2013.166
   Redmon J., 2018, P IEEE C COMP VIS PA
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Renton G, 2018, INT J DOC ANAL RECOG, V21, P177, DOI 10.1007/s10032-018-0304-3
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Saabni R, 2014, PATTERN RECOGN LETT, V35, P23, DOI 10.1016/j.patrec.2013.07.007
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Yang SM, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.601109
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 33
TC 9
Z9 9
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10703
EP 10722
DI 10.1007/s11042-022-13709-y
EA SEP 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000852929600005
DA 2024-07-18
ER

PT J
AU Mundra, S
   Mittal, N
AF Mundra, Shikha
   Mittal, Namita
TI CMHE-AN: Code mixed hybrid embedding based attention network for
   aggression identification in hindi english code-mixed text
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Aggressive; Hate speech; Offensive; Classification; Hindi english code
   mixed; Deep learning; Embedding
ID BIDIRECTIONAL LSTM; MECHANISM
AB The widespread growth in social media platforms provides a plethora of opportunities to enhance interaction and bring awareness about recent activities happening across the countries. Many people use social media to share their thoughts and opinions on societal and political issues. Nonetheless, some individuals misuse these platforms by posting toxic, hostile, and insulting comments. Hence, detecting and controlling such content at its earliest stage is crucial since its spread can harm social relations and negatively impact a person's life. In current scenarios, social media text consisting non-English languages is increasing due to active participation from multilingual societies. Of several non-English languages, Hindi English code-mixed is more prevalent in India. Most of the previous work to detect cyber aggression concentrates on English texts; therefore, there is high scope left to work on other languages such as Hindi English code-mixed. This paper has proposed a code-mixed hybrid embedding (CMHE) at the character and word level to capture similarly spelled and contextually related words. Furthermore, proposed embedding contributes significantly to the reduction of out of vocabulary words and capture words having similar polarity. After this, a deep learning framework based on CMHE, and a self-attention mechanism is proposed to retrieve significant features for classification. To evaluate proposed model, experiments were performed with two publicly available datasets: TRAC 2-2020 Hindi English code-mixed dataset (77.54% accuracy, 77.09% weighted average f1 score) and hate speech dataset (75.23% accuracy, 73.34% weighted average f1 score). The attained experimental results validate the effectiveness of proposed approach against the state-of-the-art.
C1 [Mundra, Shikha; Mittal, Namita] Malaviya Natl Inst Technol, Jaipur, Rajasthan, India.
   [Mundra, Shikha] Manipal Univ Jaipur, Jaipur, Rajasthan, India.
C3 National Institute of Technology (NIT System); Malaviya National
   Institute of Technology Jaipur; Manipal University Jaipur
RP Mundra, S (corresponding author), Malaviya Natl Inst Technol, Jaipur, Rajasthan, India.; Mundra, S (corresponding author), Manipal Univ Jaipur, Jaipur, Rajasthan, India.
EM a.shikha1990@gmail.com; nmittal.cse@mnit.ac.in
RI Mittal, Namita/AAL-3336-2020
OI Mittal, Namita/0000-0001-6886-9974
CR Athavale V., 2016, P 13 INT C NAT LANG, P154, DOI DOI 10.48550/ARXIV.1610.09756
   Badjatiya P, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P759, DOI 10.1145/3041021.3054223
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bakliwal A, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1189
   Bhat, 2015, IIIT H SYSTEM SUBMIS, DOI [10.1145/2824864.2824872, DOI 10.1145/2824864.2824872]
   Bhattacharya S., 2020, P 2 WORKSH TROLL AGG, P158
   Bohra A., 2018, P 2 WORKSH COMP MOD, P36, DOI DOI 10.18653/V1/W18-1105
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   Chetty N, 2018, AGGRESS VIOLENT BEH, V40, P108, DOI 10.1016/j.avb.2018.05.003
   Das A., 2010, Proceedings of the Eighth Workshop on Asian Language Resouces, P56
   DATTA A., 2020, P 2 WORKSH TROLL AGG, P87
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Guo QP, 2020, AAAI CONF ARTIF INTE, V34, P7847
   Huang FL, 2022, IEEE T NEUR NET LEAR, V33, P4332, DOI [10.1109/TNNLS.2021.3056664, 10.1145/3480571.3480572]
   Joshi A., 2016, P COLING 2016 26 INT, P2482
   Kamble S, 2018, 15 INT C NATURAL LAN
   Khanuja S, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2103.10730
   Kim H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9112347
   Kim Y., 2014, P 2014 C EMP METH NA, P1746, DOI [DOI 10.3115/V1/D14-1181, 10.3115/v1/D14-1181]
   Koufakou A., 2020, P 2 WORKSHOP TROLLIN, P106
   Kumar A, 2022, MULTIMEDIA SYST, V28, P2027, DOI 10.1007/s00530-020-00672-7
   Kumari K, 2021, SOFT COMPUT, DOI 10.1007/s00500-021-05817-y
   Kumhar S. H., 2021, MATER TODAY-PROC
   Li WJ, 2020, NEUROCOMPUTING, V387, P63, DOI 10.1016/j.neucom.2020.01.006
   Liu G, 2019, NEUROCOMPUTING, V337, P325, DOI 10.1016/j.neucom.2019.01.078
   Ma QL, 2019, IEEE-ACM T AUDIO SPE, V27, P2127, DOI 10.1109/TASLP.2019.2942160
   Mandal S, 2019, NORMALIZATION TRANSL, P49, DOI [10.18653/v1/w18-6107, DOI 10.18653/V1/W18-6107]
   Martin-Jones M., 1995, ONE SPEAKER 2 LANGUA
   Mathur P, 2018, NATURAL LANGUAGE PROCESSING FOR SOCIAL MEDIA (AFNLP SIG SOCIALNLP), P18
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Modha S, 2020, EXPERT SYST APPL, V161, DOI 10.1016/j.eswa.2020.113725
   Paul S, 2023, MULTIMED TOOLS APPL, V82, P8773, DOI 10.1007/s11042-021-11601-9
   Pires T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4996
   Samghabadi Niloofar Safi, 2018, P 1 WORKSH TROLL AGG, DOI DOI 10.48550/ARXIV.1807.11712
   Santosh TYSS, 2019, PROCEEDINGS OF THE 6TH ACM IKDD CODS AND 24TH COMAD, P310, DOI 10.1145/3297001.3297048
   Sharma A, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102760
   Sharma S, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1468, DOI 10.1109/ICACCI.2015.7275819
   Singh V., 2018, P 2 WORKSHOP ABUSIVE, P43
   Tompson J, 2015, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.2015.7298664
   Waseem Zeerak, 2016, P 1 WORKSHOP NLP COM, P138, DOI DOI 10.18653/V1/W16-5618
   Yilmaz S, 2020, NEURAL COMPUT APPL, V32, P2909, DOI 10.1007/s00521-020-04725-w
   Zhao R., 2016, P 17 INT C DISTR COM, P1, DOI DOI 10.1145/2833312.2849567
NR 42
TC 3
Z9 3
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11337
EP 11364
DI 10.1007/s11042-022-13668-4
EA SEP 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000852127600001
DA 2024-07-18
ER

PT J
AU Marticorena, LG
   Morales, LA
   Antonelli, L
   Rossi, G
   Firmenich, D
AF Marticorena, Lucy Gutierrez
   Morales, Leonardo A.
   Antonelli, Leandro
   Rossi, Gustavo
   Firmenich, Diego
TI Development iterations based on web augmentation and context tasks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Web engineering; Web augmentation; Requirements engineering; Software
   development environments; Task contexts; Software tools
ID SOFTWARE; AGILE; MODEL
AB The use of prototypes in requirements engineering has widely known benefits since they actively involve the stakeholders in the development process. Web Augmentation techniques make it possible to build prototypes relying on existing web applications. Thus, high fidelity mockups can be quickly generated. One of the most critical activities is dividing requirements into tasks and managing them through the development process. This paper proposes an approach that includes high fidelity mockups into the Task-oriented Development approach. The proposed approach consists of the following steps: (i) end-users specifies requirements, (ii) a product owner verifies and prioritizes the requirements, (iii) tasks are defined and included in a kanban board, (iv) developers should provide the functionality, and (v) the product owner should approved the functionality. The main contribution of this approach is to integrate the requirements specified through web augmentation mockups, into the development environment via a task-oriented development approach. Thus, developers will have a rich context that facilitates the understanding of the requirements. At the same time, the management of the development process will have benefits because of the traceability between tasks and requirements. This paper describes the approach proposed, called "WAMRI", and an application of its usage, as well as a tool to support the application.
C1 [Marticorena, Lucy Gutierrez; Morales, Leonardo A.; Firmenich, Diego] UNPSJB, Fac Ingn, DIT, Dept Informat Sede Trelew, Chubut, Argentina.
   [Morales, Leonardo A.] Consejo Nacl Invest Cient & Tecn, CENPAT, IPCSH, Puerto Madryn, Chubut, Argentina.
   [Antonelli, Leandro; Rossi, Gustavo] UNLP, Fac Informat, LIFIA, La Plata, Buenos Aires, Argentina.
C3 Consejo Nacional de Investigaciones Cientificas y Tecnicas (CONICET);
   Centro Nacional Patagonico (CENPAT); National University of La Plata
RP Firmenich, D (corresponding author), UNPSJB, Fac Ingn, DIT, Dept Informat Sede Trelew, Chubut, Argentina.
EM dafirmenich@ing.unp.edu.ar
OI Firmenich, Diego/0000-0002-7212-4454
CR Almonacid S, 2019, C CLOUD COMPUTING BI, P137
   [Anonymous], GREASESPOT WEBLOG
   [Anonymous], DARKREADER BROWSER E
   [Anonymous], 2005, Proc. of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering (ESEC/FSE'05)
   [Anonymous], MOZILLA BROWSER EXTE
   [Anonymous], GREASYFORK SAFE USEF
   [Anonymous], MYLYN TASK APPL LIFE
   [Anonymous], 2010, P 2010 C CTR ADV STU
   [Anonymous], CHROME DEV EXTENSION
   [Anonymous], GOOGLE CHROME WEB ST
   [Anonymous], Eclipse Foundation Eclipse Ignite|IoT
   [Anonymous], 2021, Microsoft Visual Studio
   Antoniol G., 1999, Sixth Working Conference on Reverse Engineering (Cat. No.PR00303), P136, DOI 10.1109/WCRE.1999.806954
   Atlassian Trello REST API, ATLASSIAN TRELLO RES
   Beynon-Davies P., 1998, IEE Proceedings-Software, V145, P105, DOI 10.1049/ip-sen:19982196
   Biniok J., Tampermonkey
   Bouvin N. O., 1999, Hypertext '99. Returning to our Diverse Roots. The 10th ACM Conference on Hypertext and Hypermedia, P91, DOI 10.1145/294469.294493
   Bradley NC, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P993, DOI 10.1145/3180155.3180238
   Coman I. D., 2009, International Journal of Computers & Applications, V31, P159, DOI 10.2316/Journal.202.2009.3.202-2963
   Coman ID, 2008, INT C PROGRAM COMPRE, P212, DOI 10.1109/ICPC.2008.16
   Diaz Oscar, 2012, Current Trends in Web Engineering (ICWE 2012). International Workshops (MDWE), Composable Web, WeRE, QWE, and Doctoral Consortium. Revised Selected Papers, P79, DOI 10.1007/978-3-642-35623-0_8
   Díaz O, 2015, ACM T WEB, V9, DOI 10.1145/2735633
   Firmenich D, 2022, INFORM SOFTWARE TECH, V141, DOI 10.1016/j.infsof.2021.106735
   Firmenich D, 2018, REQUIR ENG, V23, P33, DOI 10.1007/s00766-016-0257-3
   Firmenich D, 2014, LECT NOTES COMPUT SC, V8541, P1, DOI 10.1007/978-3-319-08245-5_1
   Firrmenich, WAMRI COMPONENT C TE, DOI [10.6084/m9.figshare.19096781, DOI 10.6084/M9.FIGSHARE.19096781]
   Fowler M., 2001, Software Development, V9, P28
   Gasparic M, 2017, J SYST SOFTWARE, V128, P200, DOI 10.1016/j.jss.2016.09.012
   Gobbo F, 2008, LECT NOTES BUS INF P, V9, P180
   Gonzalez V.M., 2004, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P113, DOI [DOI 10.1145/985692.985707, 10.1145/985692.985707]
   Holmes Reid, 2005, P 10 EUR SOFTW ENG C, V30, P237, DOI DOI 10.1145/1095430.1081744
   Hummel O, 2008, IEEE SOFTWARE, V25, P45, DOI 10.1109/MS.2008.110
   Kersten M, 2005, P 2005 INT C ASP OR, P159, DOI DOI 10.1145/1052898.1052912
   Kersten M, 2007, THESIS U BRIT COLUMB
   Kersten M, 2015, AI MAG, V36, P33, DOI 10.1609/aimag.v36i2.2581
   Kersten Mik, 2006, P 14 ACM SIGSOFT INT, P1
   Luo LH, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '21), P1178, DOI 10.1145/3468264.3468535
   Ma XJ, 2021, IEEE T NETW SERV MAN, V18, P4002, DOI 10.1109/TNSM.2021.3125395
   Maalej W, 2017, J SYST SOFTWARE, V128, P267, DOI 10.1016/j.jss.2016.11.033
   Maalej W, 2009, IEEE INT CONF AUTOM, P344, DOI 10.1109/ASE.2009.36
   Macaulay L, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON REQUIREMENTS ENGINEERING, P157, DOI 10.1109/ICRE.1996.491440
   Rivero JM, 2014, INFORM SOFTWARE TECH, V56, P670, DOI 10.1016/j.infsof.2014.01.011
   Melo G, 2021, 2021 ACM/IEEE 43RD INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: NEW IDEAS AND EMERGING RESULTS (ICSE-NIER 2021), P11, DOI 10.1109/ICSE-NIER52604.2021.00011
   Molina-Ríos J, 2020, INFORM SOFTWARE TECH, V119, DOI 10.1016/j.infsof.2019.106238
   Moore JM, 2003, 18TH IEEE INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING, PROCEEDINGS, P360, DOI 10.1109/ASE.2003.1240338
   Morales L, 2021, IEEE COMPUT GRAPH
   Murphy GC, 2019, 2019 IEEE/ACM 41ST INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: NEW IDEAS AND EMERGING RESULTS (ICSE-NIER 2019), P73, DOI 10.1109/ICSE-NIER.2019.00027
   Muslu K, 2012, ACM SIGPLAN NOTICES, V47, P669, DOI 10.1145/2398857.2384665
   Portugal Ivens, 2020, Journal of the Brazilian Computer Society, V26, DOI 10.1186/s13173-020-00100-8
   Rashid A, 2006, 1 INT WORK MULT REQ, P6
   Robbes R, 2010, AUTOMAT SOFTW ENG, V17, P181, DOI 10.1007/s10515-010-0064-x
   Rodríguez P, 2019, ADV COMPUT, V113, P135, DOI 10.1016/bs.adcom.2018.03.014
   Rodríguez P, 2012, INT SYMP EMP SOFTWAR, P139, DOI 10.1145/2372251.2372275
   Röthlisberger D, 2009, WORK CONF REVERSE EN, P237, DOI 10.1109/WCRE.2009.18
   Ruensuk Mintra, 2016, 2016 IEEE ACIS 15 IN, P1, DOI [10.1109/ICIS.2016.7550835, DOI 10.1109/ICIS.2016.7550835]
   Sarkar S, 2017, 2017 IEEE/ACM 2ND INTERNATIONAL WORKSHOP ON EMOTION AWARENESS IN SOFTWARE ENGINEERING (SEMOTION 2017), P32, DOI 10.1109/SEmotion.2017.2
   Schön EM, 2017, COMPUT STAND INTER, V49, P79, DOI 10.1016/j.csi.2016.08.011
   Vieira Roger Denis, 2020, SBES '20: Proceedings of the 34th Brazilian Symposium on Software Engineering, P393, DOI 10.1145/3422392.3422453
   Whittle J, 2014, IEEE SOFTWARE, V31, P79, DOI 10.1109/MS.2013.65
   Zhu YH, 2019, EURASIP J WIREL COMM, V2019, DOI 10.1186/s13638-019-1605-z
NR 60
TC 1
Z9 1
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11793
EP 11817
DI 10.1007/s11042-022-13694-2
EA SEP 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000850023000005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Jena, KK
   Nayak, SR
   Bhoi, SK
   Verma, KD
   Prakash, D
   Gupta, A
AF Jena, Kalyan Kumar
   Nayak, Soumya Ranjan
   Bhoi, Sourav Kumar
   Verma, K. D.
   Prakash, Deo
   Gupta, Abhishek
TI A novel service robot assignment approach for COVID-19 infected
   patients: a case of medical data driven decision making
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; PSRs assignment framework; PB method; FRB approach; HACI; LACI
ID ARTIFICIAL-INTELLIGENCE; CHINA; EPIDEMIC
AB Coronavirus Disease-19 (COVID-19) is a major concern for the entire world in the current era. Coronavirus is a very dangerous infectious virus that spreads rapidly from person to person. It spreads in exponential manner on a global scale. It affects the doctors, nurse and other COVID-19 warriors those who are actively involved for the treatment of COVID-19 infected (CI) patients. So, it is very much essential to focus on automation and artificial intelligence (AI) in different hospitals for the treatment of such infected patients and all should be very much careful to break the chain of spreading this novel virus. In this paper, a novel patient service robots (PSRs) assignment framework and a priority based (PB) method using fuzzy rule based (FRB) approach is proposed for the assignment of PSRs for CI patients in hospitals in order to provide safety to the COVID-19 warriors as well as to the CI infected patients. This novel approach is mainly focused on lowering the active involvement of COVID-19 warriors for the treatment of high asymptotic COVID-19 infected (HACI) patients for handling this tough situation. In this work, we have focused on HACI and low asymptotic COVID-19 infected (LACI) patients. Higher priority is given to HACI patients as compared to LACI patients to handle this critical situation in order to increase the survival probability of these patients. The proposed method deals with situations that practically arise during the assignment of PSRs for the treatment of such patients. The simulation of the work is carried out using MATLAB R2015b.
C1 [Jena, Kalyan Kumar; Bhoi, Sourav Kumar] PMECParala Maharaja Engn Coll, Dept Comp Sci & Engn, Berhampur, India.
   [Nayak, Soumya Ranjan] Amity Univ Uttar Pradesh, PradeshAmity Sch Engn & Technol, Noida, India.
   [Verma, K. D.] Shri Varshney PG Coll, Dept Phys, Aligarh 202001, Uttar Pradesh, India.
   [Prakash, Deo; Gupta, Abhishek] Shri Mata Vaishno Devi Univ, Sch Comp Sci & Engn, Katra 182320, J&K, India.
C3 Amity University Noida; Shri Mata Vaishno Devi University
RP Prakash, D (corresponding author), Shri Mata Vaishno Devi Univ, Sch Comp Sci & Engn, Katra 182320, J&K, India.
EM deoprakash.a@gmail.com
RI Prakash, Deo/O-9722-2015; Verma, K.D./K-5758-2018; Bhoi, Sourav
   Kumar/AAX-9796-2020; Gupta, Abhishek/O-3016-2019
OI Verma, K.D./0000-0002-5492-2997; Bhoi, Sourav Kumar/0000-0002-5173-3453;
   Gupta, Abhishek/0000-0002-8592-9964
CR Alimadadi A, 2020, PHYSIOL GENOMICS, V52, P200, DOI 10.1152/physiolgenomics.00029.2020
   Amina M, 2020, ARTIF INTELL MED, V106, DOI 10.1016/j.artmed.2020.101819
   Anderson RM, 2020, LANCET, V395, P931, DOI 10.1016/S0140-6736(20)30567-5
   Bai Y, 2020, JAMA-J AM MED ASSOC, V323, P1406, DOI 10.1001/jama.2020.2565
   Bhargava A, 2003, 14TH INTERNATIONAL WORKSHOP ON DATABASE AND EXPERT SYSTEMS APPLICATIONS, PROCEEDINGS, P956, DOI 10.1109/DEXA.2003.1232145
   Bharti Urmil, 2020, 2020 5th International Conference on Communication and Electronics Systems (ICCES). Proceedings, P870, DOI 10.1109/ICCES48766.2020.9137944
   Bostelman R, 2006, 3 INT WORKSHOP ADV S, P1
   Chen SM, 2020, LANCET, V395, P764, DOI 10.1016/S0140-6736(20)30421-9
   Cuevas E, 2020, STUD COMPUT INTELL, V854, P135, DOI 10.1007/978-3-030-28917-1_6
   Dalton CB, 2020, MED J AUSTRALIA, V212, P443, DOI 10.5694/mja2.50602
   Davenport T. H., 2018, NEJM CATALYST, V4
   Desai Angel N, 2020, JAMA, V323, P1516, DOI 10.1001/jama.2020.4269
   Eubank S, 2020, B MATH BIOL, V82, DOI 10.1007/s11538-020-00726-x
   Fong SJ, 2020, ARXIV
   Hick John L, 2020, NAM Perspect, V2020, DOI 10.31478/202003b
   Huang ZX, 2020, J AM COLL RADIOL, V17, P710, DOI 10.1016/j.jacr.2020.03.011
   Javaid M, 2020, DIABETES METAB SYND, V14, P419, DOI 10.1016/j.dsx.2020.04.032
   Jiang F, 2020, J GEN INTERN MED, V35, P1545, DOI 10.1007/s11606-020-05762-w
   Kamruzzaman MM, 2020, IEEE INT CONF MULTI, DOI 10.1109/icmew46912.2020.9106026
   Karuppan AS., 2019, INT C COMP NETW COMM
   Khan ZH, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17113819
   Kimmig R, 2020, J GYNECOL ONCOL, V31, DOI 10.3802/jgo.2020.31.e59
   Kumar N, 2019, P 2 INT C ADV COMPUT, P312
   Li Ruoran, 2020, medRxiv, DOI 10.1101/2020.03.09.20033241
   Li XB, 2021, INT J PROD RES, V59, P1776, DOI 10.1080/00207543.2020.1725681
   Lipsitch M, 2020, NEW ENGL J MED, V382, P1194, DOI 10.1056/NEJMp2002125
   Luengo-Oroz M, 2020, NAT MACH INTELL, V2, P295, DOI 10.1038/s42256-020-0184-3
   Meares HDD, 2020, MED J AUSTRALIA, V212, P470, DOI 10.5694/mja2.50605
   Milan ST, 2020, CLUSTER COMPUT, V23, P663, DOI 10.1007/s10586-019-02951-z
   Mohamadou Y, 2020, APPL INTELL, V50, P3913, DOI 10.1007/s10489-020-01770-9
   Neri E, 2020, RADIOL MED, V125, P505, DOI 10.1007/s11547-020-01197-9
   Nishiyama T, 2003, IEEE INT CONF ROBOT, P2979
   O'Leary DE, 2020, J ORG COMP ELECT COM, V30, P1, DOI 10.1080/10919392.2020.1755790
   Pu H, 2020, MEDRXIV
   Rahmatizadeh S., 2020, Journal of Cellular and Molecular Anesthesia, V5, P16
   Roosa K, 2020, INFECT DIS MODEL, V5, P256, DOI 10.1016/j.idm.2020.02.002
   Sumrit D, 2020, DECISION SCI LETT, V9, P233, DOI 10.5267/j.dsl.2019.10.002
   Swangnetr M, 2013, IEEE T HUM-MACH SYST, V43, P63, DOI 10.1109/TSMCA.2012.2210408
   Tan Z, 2020, J CARDIOTHOR VASC AN
   Tavakoli M, 2020, ADV INTELL SYST-GER, V2, DOI 10.1002/aisy.202000071
   Thomson G, 2020, INT J CLIN PRACT, V74, DOI 10.1111/ijcp.13503
   Vaishnavi P., 2020, ARTIF INTELL
   Vaishya R, 2020, DIABETES METAB SYND, V14, P337, DOI 10.1016/j.dsx.2020.04.012
   Wang WY, 2019, J DATABASE MANAGE, V30, P61, DOI 10.4018/JDM.2019010104
   WHO, 2019, COR DIS COV 19 OUTBR
   WHO, 73 WHO
   Wong J, 2020, CAN J ANESTH, V67, P732, DOI 10.1007/s12630-020-01620-9
   Wu ZY, 2020, JAMA-J AM MED ASSOC, V323, P1239, DOI 10.1001/jama.2020.2648
   Xiang YT, 2020, INT J BIOL SCI, V16, P1741, DOI 10.7150/ijbs.45072
   Xie JF, 2020, INTENS CARE MED, V46, P837, DOI 10.1007/s00134-020-05979-7
   Ye R, 2020, CHEST
   Yu C, 2013, COMPUT ELECTR ENG, V39, P1276, DOI 10.1016/j.compeleceng.2013.03.002
   Zeng ZJ, 2020, TOURISM GEOGR, V22, P724, DOI 10.1080/14616688.2020.1762118
   Zhang T, 2010, INTEL SERV ROBOT, V3, P73, DOI 10.1007/s11370-010-0060-9
   Zhang T, 2008, IEEE INT CON AUTO SC, P674, DOI 10.1109/COASE.2008.4626532
   Zouaoui S., 2019, INT J ELECT COMPUTER, V9, P2088, DOI DOI 10.11591/IJECE.V9I1
NR 56
TC 0
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 41995
EP 42021
DI 10.1007/s11042-022-13524-5
EA SEP 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000849487500001
PM 36090152
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Shi, F
   Jia, ZH
   Lai, HC
   Kasabov, NK
   Song, SS
   Wang, JN
AF Shi, Fei
   Jia, Zhenhong
   Lai, Huicheng
   Kasabov, Nikola K.
   Song, Sensen
   Wang, Junnan
TI Sand-dust image enhancement based on light attenuation and transmission
   compensation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Light attenuation; Red and green channel; Single image dust removal;
   Transmission compensation
ID WEATHER; VISIBILITY; RESTORATION
AB The study of sand-dust images has made remarkable progress in recent years. However, it is challenging to balance the image quality, color casts correction, and running time well in the existing sand-dust image processing methods. This paper introduces a novel compensation coefficient and effective intensity difference prior, which leads to an efficient and robust sand dust removal method. This method assumes that the medium transmission coefficients of each pixel are not equal. First, the rough transmission is estimated by the red-green channel pixel-wise, thereby leading to significantly reduced running time. Then, the difference between the blue channel and red-green channel is utilized to compensate for the rough transmission. Besides, ambient light is estimated using the minimum absolute intensity difference between channels, according to the attenuation characteristics of light in sand dust. Meanwhile, a color adjustment method based on global stretch and the green channel is also improved, making the method effective on various sand-dust images. A series of experiments are conducted on a number of challenging sand-dust images with the proposed method and other state-of-the-art sand dust removal techniques, revealing the superiority of the proposed method in terms of calculation time, color shift correction, and restoration quality over all the comparable techniques.
C1 [Shi, Fei; Jia, Zhenhong; Lai, Huicheng; Song, Sensen; Wang, Junnan] Xinjiang Univ, Sch Informat Sci & Engn, Urumqi 830046, Peoples R China.
   [Shi, Fei; Jia, Zhenhong; Lai, Huicheng; Song, Sensen; Wang, Junnan] Xinjiang Univ, Key Lab Signal Detect & Proc, Urumqi 830046, Peoples R China.
   [Kasabov, Nikola K.] Auckland Univ Technol, Sch Engn Comp & Math Sci, Auckland 1010, New Zealand.
C3 Xinjiang University; Xinjiang University; Auckland University of
   Technology
RP Jia, ZH (corresponding author), Xinjiang Univ, Sch Informat Sci & Engn, Urumqi 830046, Peoples R China.; Jia, ZH (corresponding author), Xinjiang Univ, Key Lab Signal Detect & Proc, Urumqi 830046, Peoples R China.
EM sigofei@xju.edu.cn; jzhh9009@sohu.com; lai@xju.edu.cn;
   nkasabov@aut.ac.nz; 1477920156@qq.com; 1254982138@qq.com
RI Song, Sensen/ABC-6122-2021; Kasabov, Nikola Kirilov/JQJ-5530-2023
FU International Science and Technology Cooperation Project of the Ministry
   of Education of the People's Republic of China [DICE 2016-2196];
   National Natural Science Foundation of China [U1803261]; scientific
   research plan of universities in Xinjiang Uygur Autonomous Region
   [XJEDU2019Y006]; Natural Science Foundation of XinJiang [2021D01C057]
FX This work was supported by the International Science and Technology
   Cooperation Project of the Ministry of Education of the People's
   Republic of China under Grant DICE 2016-2196, the National Natural
   Science Foundation of China under Grant U1803261, scientific research
   plan of universities in Xinjiang Uygur Autonomous Region under grant
   XJEDU2019Y006, and the Natural Science Foundation of XinJiang under
   Grants 2021D01C057. We sincerely thank the editors and reviewers for
   taking the time to review our manuscript.
CR Achanta SDM, 2019, SOFT COMPUT, V23, P8359, DOI 10.1007/s00500-019-04108-x
   Al-Ameen Zohair, 2016, International Journal of Intelligent Systems and Applications, V8, P10, DOI 10.5815/ijisa.2016.08.02
   Alruwaili M, 2015, INT CONF ELECTRO INF, P286, DOI 10.1109/EIT.2015.7293354
   [Anonymous], 2019, Time-Space, Spiking Neural Networks and Brain-inspired Artificial intelligence
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Carlevaris-Bianco N., 2010, OCEANS, P1, DOI DOI 10.1109/OCEANS.2010.5664428
   Chen BH, 2013, IEEE INT SYM MULTIM, P267, DOI 10.1109/ISM.2013.51
   Chen WT, 2020, IEEE T IMAGE PROCESS, V29, P6773, DOI 10.1109/TIP.2020.2993407
   Cheng Y, 2020, FAST SAND DUST IMAGE, V8
   Cheng YQ, 2020, IEEE ACCESS, V8, P66931, DOI 10.1109/ACCESS.2020.2985869
   Darwante S, 2019, 2019 5TH INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, CONTROL AND AUTOMATION (ICCUBEA), DOI 10.1109/iccubea47591.2019.9128792
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Fu X, 2014, 2014 IEEE 16 INT WOR, P1, DOI [10.1109/MMSP.2014.6958791, DOI 10.1109/MMSP.2014.6958791]
   Gao GX, 2021, OPTIK, V226, DOI 10.1016/j.ijleo.2020.165659
   Gao GX, 2020, IEEE PHOTONICS J, V12, DOI 10.1109/JPHOT.2020.2975833
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Huang SC, 2015, IEEE T IND ELECTRON, V62, P2962, DOI 10.1109/TIE.2014.2364798
   Huang SC, 2014, IEEE T CIRC SYST VID, V24, P1814, DOI 10.1109/TCSVT.2014.2317854
   Jian Wang, 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P842, DOI 10.1007/978-3-319-27671-7_70
   Khodayari-Rostamabad A, 2009, IEEE T MAGN, V45, P3073, DOI 10.1109/TMAG.2009.2020160
   Kim SE, 2020, IEEE T IMAGE PROCESS, V29, P1985, DOI 10.1109/TIP.2019.2948279
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li Ce, 2018, Journal of Lanzhou University of Technology, V44, P90
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Narasimhan SG, 2000, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2000.855874
   Park TH, 2021, IEEE ACCESS, V9, P19749, DOI 10.1109/ACCESS.2021.3054899
   Peng YT, 2020, IEEE T CIRC SYST VID, V30, P1385, DOI 10.1109/TCSVT.2019.2902795
   Peng YT, 2018, IEEE T IMAGE PROCESS, V27, P2856, DOI 10.1109/TIP.2018.2813092
   Peng YT, 2016, IEEE IMAGE PROC, P1953, DOI 10.1109/ICIP.2016.7532699
   Ren DW, 2020, IEEE T IMAGE PROCESS, V29, P6852, DOI 10.1109/TIP.2020.2994443
   Shi ZH, 2020, IET IMAGE PROCESS, V14, P747, DOI 10.1049/iet-ipr.2019.0992
   Shi ZH, 2019, IEEE ACCESS, V7, P116722, DOI 10.1109/ACCESS.2019.2936444
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Ting Yan, 2014, Journal of Software, V9, P2672, DOI 10.4304/jsw.9.10.2672-2677
   Wang B, 2021, SIGNAL IMAGE VIDEO P, V15, P637, DOI 10.1007/s11760-020-01786-1
   Wang XD, 2010, INT CONF COMP SCI, P7, DOI 10.1109/ICCSIT.2010.5564480
   Xu GL, 2020, IEEE-CAA J AUTOMATIC, V7, P1649, DOI 10.1109/JAS.2020.1003423
   Yang Y, 2020, MULTIDIM SYST SIGN P, V31, P619, DOI 10.1007/s11045-019-00678-z
   [杨燕 Yang Yan], 2017, [通信学报, Journal on Communications], V38, P48
   Yu SY, 2016, J MOD OPTIC, V63, P2121, DOI 10.1080/09500340.2016.1184340
   Yuanyu Wang, 2010, 2010 IEEE International Conference on Mechatronics and Automation (ICMA), P294, DOI 10.1109/ICMA.2010.5589057
   Zeng W, 2014, IEEE T VIS COMPUT GR, V20, P1833, DOI 10.1109/TVCG.2014.2346893
   [智宁 Zhi Ning], 2016, [中国图象图形学报, Journal of Image and Graphics], V21, P1585
NR 46
TC 3
Z9 3
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7055
EP 7077
DI 10.1007/s11042-022-13118-1
EA AUG 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000840291300001
DA 2024-07-18
ER

PT J
AU Zhao, S
   Wu, Y
   Wang, YM
   Han, Y
AF Zhao, Shan
   Wu, Yan
   Wang, Yongmao
   Han, Yu
TI Multi-channel local oblique symmetry texture patterns for image
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image descriptor; Texture feature; Local binary pattern (LBP);
   Multi-channel local oblique symmetry texture patterns (MLOSTP); Image
   retrieval
ID FEATURE DESCRIPTOR; BINARY PATTERN; CLASSIFICATION; FEATURES
AB An image descriptor, multi-channel local oblique symmetry texture pattern (MLOSTP), has been introduced for image retrieval. To capture color, texture, and local spatial information in different channels, three cross-channels, including RV, GV, and BV, are adopted through the combination of RGB with HSV. In each cross-channel, two meaningful local difference maps are introduced between center pixels and surrounding pixels according to their gray differences, which results in more local pixel variations. Based on the maps, two oblique symmetry texture patterns are derived. Not only is the difference between the two color channels explored, but the diagonal asymmetry information of the image is also incorporated into the local patterns. Furthermore, the spatial structure information between different spectral channels is considered. The performance of MLOSTP is estimated by several experiments on four databases. The results show that MLOSTP can achieve better performance than other descriptors.
C1 [Zhao, Shan; Han, Yu] Henan Polytech Univ, Sch Software, Jiaozuo 454000, Henan, Peoples R China.
   [Wu, Yan; Wang, Yongmao] Henan Polytech Univ, Sch Comp Sci & Technol, Jiaozuo 454000, Henan, Peoples R China.
C3 Henan Polytechnic University; Henan Polytechnic University
RP Zhao, S (corresponding author), Henan Polytech Univ, Sch Software, Jiaozuo 454000, Henan, Peoples R China.
EM zhaoshan@hpu.edu.cn
FU National Natural Science Foundation of China [61602157]; Henan Science
   and Technology Planning Program [202102210167]; Key Research Project of
   Henan Province Higher School [18B520017]; Doctor Fund of Henan
   Polytechnic University [B2014-043]
FX This work was supported by the National Natural Science Foundation of
   China [grant number 61602157], Henan Science and Technology Planning
   Program [grant number 202102210167], the Key Research Project of Henan
   Province Higher School [grant number 18B520017] and Doctor Fund of Henan
   Polytechnic University [grant number B2014-043].
CR Agarwal M, 2020, IJST-T ELECTR ENG, V44, P495, DOI 10.1007/s40998-019-00219-1
   Agarwal M, 2019, PATTERN ANAL APPL, V22, P1585, DOI 10.1007/s10044-019-00787-2
   Chakraborti T, 2018, IEEE SIGNAL PROC LET, V25, P635, DOI 10.1109/LSP.2018.2817176
   Chakraborty S, 2018, PATTERN RECOGN LETT, V115, P50, DOI 10.1016/j.patrec.2017.10.015
   Charles YR, 2016, AEU-INT J ELECTRON C, V70, P225, DOI 10.1016/j.aeue.2015.11.009
   Dubey SR, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2577887
   Gadelmawla ES, 2004, NDT&E INT, V37, P577, DOI 10.1016/j.ndteint.2004.03.004
   Jacob IJ, 2014, PATTERN RECOGN LETT, V42, P72, DOI 10.1016/j.patrec.2014.01.017
   Karanwal S, 2021, OPTIK, V241, DOI 10.1016/j.ijleo.2021.166965
   Karanwal S, 2021, DIGIT SIGNAL PROCESS, V110, DOI 10.1016/j.dsp.2020.102948
   Karanwal S, 2021, OPTIK, V226, DOI 10.1016/j.ijleo.2020.166007
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pan ZB, 2021, EXPERT SYST APPL, V180, DOI 10.1016/j.eswa.2021.115123
   Rampun A, 2020, COMPUT BIOL MED, V122, DOI 10.1016/j.compbiomed.2020.103842
   Rao LK, 2019, MULTIDIM SYST SIGN P, V30, P1413, DOI 10.1007/s11045-018-0609-x
   Rao LK, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-2664-9
   Reddy AH, 2015, AEU-INT J ELECTRON C, V69, P290, DOI 10.1016/j.aeue.2014.09.015
   Shu X, 2021, SIGNAL PROCESS-IMAGE, V98, DOI 10.1016/j.image.2021.116392
   Singh C, 2018, PATTERN RECOGN, V76, P50, DOI 10.1016/j.patcog.2017.10.021
   Song TC, 2021, PATTERN RECOGN, V115, DOI 10.1016/j.patcog.2021.107891
   Song W, 2018, EXPERT SYST APPL, V96, P347, DOI 10.1016/j.eswa.2017.12.006
   Sucharitha G, 2020, MULTIMED TOOLS APPL, V79, P1847, DOI 10.1007/s11042-019-08215-7
   Tamura H., 1978, IEEE Transactions on Systems, Man and Cybernetics, VSMC-8, P460, DOI 10.1109/TSMC.1978.4309999
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Yin HG, 2021, COMPUT ELECTR ENG, V90, DOI 10.1016/j.compeleceng.2021.106983
   Yu LH, 2018, SIGNAL IMAGE VIDEO P, V12, P247, DOI 10.1007/s11760-017-1152-1
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhao S, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.4.043003
NR 33
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8423
EP 8445
DI 10.1007/s11042-022-13549-w
EA AUG 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000836366300005
DA 2024-07-18
ER

PT J
AU Cheng, L
   Yi, JZ
   Chen, AB
   Zhang, Y
AF Cheng, Le
   Yi, Jizheng
   Chen, Aibin
   Zhang, Yi
TI Fabric defect detection based on separate convolutional UNet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Deep learning; Fabric defect detection; UNet
ID CONDITIONAL RANDOM-FIELD; NEURAL-NETWORK; VESSEL SEGMENTATION;
   INSPECTION
AB Defect detection in the textile industry is an important and demanding task. Traditional methods rely on manual inspection, which is costly and damaging to the fabric. The deep learning methods based on semantic segmentation network simply and efficiently implement the fabric defect detection with high accuracy. In this paper, we proposed a Separation Convolution UNet (SCUNet) combined with convolutional down sampling, depth-separable convolution and cross-parallel ratio loss function(IoU Loss), and the number of parameters is only 4.27 M (Million). The location detection of fabric defects is performed by extracting surface features in fabric pictures. We selected a dataset containing 106 fabric grayscale images and performed preprocessing including image cutting and data enhancement. We tested the SCUNet with four metrics on the AITEX dataset, and the results showed that the accuracy, recall, specificity and mIoU are 98.01%, 96.86%, 98.07%, and 34.32%, respectively.
C1 [Cheng, Le; Yi, Jizheng; Chen, Aibin; Zhang, Yi] Cent South Univ Forestry & Technol, Coll Comp & Informat Engn, Changsha 410004, Peoples R China.
   [Cheng, Le; Yi, Jizheng; Chen, Aibin; Zhang, Yi] Cent South Univ Forestry & Technol, Inst Artificial Intelligence Applicat, Changsha 410004, Peoples R China.
C3 Central South University of Forestry & Technology; Central South
   University of Forestry & Technology
RP Yi, JZ (corresponding author), Cent South Univ Forestry & Technol, Coll Comp & Informat Engn, Changsha 410004, Peoples R China.; Yi, JZ (corresponding author), Cent South Univ Forestry & Technol, Inst Artificial Intelligence Applicat, Changsha 410004, Peoples R China.
EM kingkong148@163.com
FU General Program Hunan Provincial Natural Science Foundation
   [2022JJ31022]; Undergraduate Education Reform Project of Hunan Province
   [HNJG-2021-0532]
FX The author would like to thank the Artificial Intelligence Application
   Institute of Central South University of forestry and technology for its
   machine support and the dataset provider used in this paper. This work
   was supported in part by the General Program Hunan Provincial Natural
   Science Foundation of 2022 (Grant no. 2022JJ31022), the Undergraduate
   Education Reform Project of Hunan Province (Grant no. HNJG-2021-0532).
CR Alom M Z, 2018, ARXIV, DOI DOI 10.48550/ARXIV.1802.06955
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   Basu A., 2012, P COMPUTING COMMUNIC, P1
   Bissi L, 2013, J VIS COMMUN IMAGE R, V24, P838, DOI 10.1016/j.jvcir.2013.05.011
   Campbell JG, 1998, OPT ENG, V37, P2536, DOI 10.1117/1.601692
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Davis A, 2015, PROC CVPR IEEE, P5335, DOI 10.1109/CVPR.2015.7299171
   Dongyun Wang, 2010, Proceedings 2010 Sixth International Conference on Natural Computation (ICNC 2010), P3943, DOI 10.1109/ICNC.2010.5584778
   Eldessouki M, 2015, EXPERT SYST APPL, V42, P2098, DOI 10.1016/j.eswa.2014.10.013
   Emadi M., 2020, J TEXTILES POLYM, V8, P41
   Feng J, 2021, J PHYS C SERIES IOP, V2010
   Garg M, 2021, Autonomous driving and advanced driver-assistance systems (ADAS), P233
   Hanbay K, 2016, OPTIK, V127, P11960, DOI 10.1016/j.ijleo.2016.09.110
   HUART J, 1994, P SOC PHOTO-OPT INS, V2183, P155, DOI 10.1117/12.171205
   Orlando JI, 2017, IEEE T BIO-MED ENG, V64, P16, DOI 10.1109/TBME.2016.2535311
   Jia L, 2020, INFORM SCIENCES, V512, P964, DOI 10.1016/j.ins.2019.10.032
   Kaur A, 2023, IETE J RES, V69, P7907, DOI 10.1080/03772063.2022.2060869
   Kaur A, 2021, EXPERT SYST APPL, V186, DOI 10.1016/j.eswa.2021.115686
   Kolhe S., 2009, Adv. Comput. Res, V1, P18
   Kumar A, 2003, PATTERN RECOGN, V36, P1645, DOI 10.1016/S0031-3203(03)00005-0
   Kumar A, 2008, IEEE T IND ELECTRON, V55, P348, DOI 10.1109/TIE.1930.896476
   Kumar I, 2022, J INTELL FUZZY SYST, V42, P1075, DOI 10.3233/JIFS-189773
   Li TH, 2022, BORSA ISTANB REV, V22, P560, DOI 10.1016/j.bir.2021.07.005
   Li YD, 2017, IEEE T AUTOM SCI ENG, V14, P1256, DOI 10.1109/TASE.2016.2520955
   Li ZH, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9151750
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Machin M, 2018, IEEE WIREL COMMUNN, P332, DOI 10.1109/WCNCW.2018.8369029
   Obuchi T, 2016, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2016/05/053304
   Peng T, 2021, MULTIMED TOOLS APPL, V80, P7567, DOI 10.1007/s11042-020-10085-3
   Popov D. A., 2004, Problems of Information Transmission, V40, P254, DOI 10.1023/B:PRIT.0000044261.87490.05
   Roesler U, 1992, MELLIAND TEXTILBERIC, V73, P635
   Rong-qiang L., 2021, J PHYS C SERIES, V1948
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roychowdhury S, 2015, IEEE J BIOMED HEALTH, V19, P1118, DOI 10.1109/JBHI.2014.2335617
   Seçkin AC, 2022, ALEX ENG J, V61, P2887, DOI 10.1016/j.aej.2021.08.017
   Seker A, 2016, 2016 24TH SIGNAL PROCESSING AND COMMUNICATION APPLICATION CONFERENCE (SIU), P1437, DOI 10.1109/SIU.2016.7496020
   Shaha Manali, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P656, DOI 10.1109/ICECA.2018.8474802
   Shaheed K, 2022, EXPERT SYST APPL, V198, DOI 10.1016/j.eswa.2022.116786
   Shaheed K, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116288
   Shaheed K, 2022, INFORM FUSION, V79, P84, DOI 10.1016/j.inffus.2021.10.004
   Silvestre-Blanes J, 2019, AUTEX RES J, V19, P363, DOI 10.2478/aut-2019-0035
   Tang TKY, 2003, J MATER PROCESS TECH, V139, P596, DOI 10.1016/S0924-0136(03)00517-X
   Tsai DM, 1999, IMAGE VISION COMPUT, V18, P49, DOI 10.1016/S0262-8856(99)00009-8
   TSAI IS, 1995, TEXT RES J, V65, P123, DOI 10.1177/004051759506500301
   Ubhi JS, 2022, J VIS COMMUN IMAGE R, V85, DOI 10.1016/j.jvcir.2022.103483
   Walia S, 2021, IEEE ACCESS, V9, P99742, DOI 10.1109/ACCESS.2021.3096240
   Wang B, 2019, LECT NOTES COMPUT SC, V11764, P84, DOI 10.1007/978-3-030-32239-7_10
   Wang Yuxiang, 2021, Journal of Physics: Conference Series, V1914, DOI 10.1088/1742-6596/1914/1/012037
   Wong WK, 2009, EXPERT SYST APPL, V36, P3845, DOI 10.1016/j.eswa.2008.02.066
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yang K, 2022, ENG APPL ARTIF INTEL, V113, DOI 10.1016/j.engappai.2022.104916
   Yang K, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3093101
   Yapi D, 2015, IFAC PAPERSONLINE, V48, P2423, DOI 10.1016/j.ifacol.2015.06.451
   Yu J., 2016, P 24 ACM INT C MULT, P516, DOI DOI 10.1145/2964284.2967274
   Zhang H., 2019, 2019 IEEE 8 DAT DRIV, P1263, DOI DOI 10.1109/2DDCLS.2019.8908944
   Zhang J, 2021, MACH TOOLS HYDRAUL, V49, P77
   Zhou L, 2017, COMPUT METH PROG BIO, V148, P13, DOI 10.1016/j.cmpb.2017.06.016
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
   Zhuang J, 2018, ARXIV, DOI DOI 10.48550/ARXIV.1810.07810
NR 60
TC 19
Z9 19
U1 13
U2 82
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 3101
EP 3122
DI 10.1007/s11042-022-13568-7
EA JUL 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000832844000004
DA 2024-07-18
ER

PT J
AU Karabulut, D
   Ozcinar, C
   Anbarjafari, G
AF Karabulut, Dogus
   Ozcinar, Cagri
   Anbarjafari, Gholamreza
TI Automatic content moderation on social media
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Inappropriate scene recognition; Content obfuscation; Convolutional
   neural networks
ID WEB PAGES
AB Millions of users produce and consume billions of content on social media. Therefore, human-reviewed content moderation is not achievable in such volume. Automating content moderation is a scalable solution for social media platforms. In this research work, we propose an automatic content moderation pipeline based on deep neural networks. Our solution consists of two main parts: the first part classifies a given image into granular content classes; and a second part obfuscates the part of a given image that might be inappropriate for the target audience. Our proposed solution is a cost-efficient in terms of human labour and practical for deploying the real-time systems. Our classification network is trained with automatically labelled data using noise-robust techniques. Our automatic obfuscation algorithm uses the information obtained from the classification network and does not require additional annotation or supplementary training. This obfuscation algorithm presents a novel-use case of class-specific activation mappings for censoring regional explicit nudity in images. The classification network achieves a top-1 accuracy of 0.903 and a top-2 accuracy of 0.986. The obfuscation algorithm covers a minimum explicitly nude area of 0.68 on average.
C1 [Karabulut, Dogus; Ozcinar, Cagri; Anbarjafari, Gholamreza] Univ Tartu, Inst Technol, iCV Res Lab, EE-50411 Tartu, Estonia.
   [Anbarjafari, Gholamreza] Yildiz Tech Univ, Istanbul, Turkey.
   [Anbarjafari, Gholamreza] iVCV OU, Tartu, Estonia.
   [Anbarjafari, Gholamreza] PwC Advisory, Helsinki, Finland.
C3 University of Tartu; Yildiz Technical University
RP Anbarjafari, G (corresponding author), Univ Tartu, Inst Technol, iCV Res Lab, EE-50411 Tartu, Estonia.; Anbarjafari, G (corresponding author), Yildiz Tech Univ, Istanbul, Turkey.; Anbarjafari, G (corresponding author), iVCV OU, Tartu, Estonia.; Anbarjafari, G (corresponding author), PwC Advisory, Helsinki, Finland.
EM dogus@icv.tuit.ut.ee; co@icv.tuit.ut.ee; shb@icv.tuit.ut.ee
RI Anbarjafari, Gholamreza/A-3845-2010
OI Anbarjafari, Gholamreza/0000-0001-8460-5717
FU Estonian Centre of Excellence in IT (EXCITE) - European Regional
   Development Fund; NVIDIA Corporation
FX This work has been partially supported by the Estonian Centre of
   Excellence in IT (EXCITE) funded by the European Regional Development
   Fund. The authors also gratefully acknowledge the support of NVIDIA
   Corporation with the donation of the Titan V and X Pascal GPU.
CR Agrawal A, 2016, ARXIV
   [Anonymous], 2005, IRAN J ELECT ELECT E
   Arentz WA, 2004, COMPUT VIS IMAGE UND, V94, P295, DOI 10.1016/j.cviu.2003.10.007
   Arsht A, 2018, HARVARD J LAW TECHNO, P1
   Batrinca B, 2015, AI SOC, V30, P89, DOI 10.1007/s00146-014-0549-4
   Caetano C, 2016, NEUROCOMPUTING, V213, P102, DOI 10.1016/j.neucom.2016.03.099
   da Silva MV, 2018, IB C PATT REC, P547
   Duarte Natasha, 2018, FAT, V81, P106
   Fan, 2019, uS Patent App, Patent No. [14 /(343)-931, 14343931]
   Fleck M M, 1996, P EUR C COMP VIS, P593, DOI DOI 10.1007/3-540-61123-1_173
   Gajula G, 2019, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM-2020), P181, DOI [10.23919/INDIACom49435.2020.9083700, 10.23919/indiacom49435.2020.9083700]
   Gangwar Abhishek, 2017, 8th International Conference on Imaging for Crime Detection and Prevention (ICDP 2017), P37
   Gorbova J, 2019, MULTIMED TOOLS APPL, V78, P23161, DOI 10.1007/s11042-019-7658-5
   Guo JZ, 2018, IEEE ACCESS, V6, P26391, DOI 10.1109/ACCESS.2018.2831927
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoiem D, 2012, LECT NOTES COMPUT SC, V7574, P340, DOI 10.1007/978-3-642-33712-3_25
   Hu WM, 2007, IEEE T PATTERN ANAL, V29, P1019, DOI 10.1109/TPAMI.2007.1133
   Jahromi MNS, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21111033
   Jeong H., 2017, INT ROBOT AUTOM J, V6, P3
   Jhaver S, 2019, ACM T COMPUT-HUM INT, V26, DOI 10.1145/3338243
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Kakumanu P, 2007, PATTERN RECOGN, V40, P1106, DOI 10.1016/j.patcog.2006.06.010
   Karaica D, 2020, MYCOTOXIN RES, V36, P339, DOI 10.1007/s12550-020-00399-4
   Kingma D. P., 2014, arXiv
   Kotenko I, 2017, INT J INTERNET PROTO, V10, P61, DOI 10.1504/IJIPT.2017.10003851
   Lipton ZC, 2018, COMMUN ACM, V61, P36, DOI 10.1145/3233231
   Litvin A, 2019, MULTIMED TOOLS APPL, V78, P25259, DOI 10.1007/s11042-019-7667-4
   Lopes Ana P. B., 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P1552
   Mahadeokar J., 2016, YAHOO ENG, V24, P2018
   Malamuth NM, 1996, J COMMUN, V46, P8, DOI 10.1111/j.1460-2466.1996.tb01486.x
   Moustafa M, 2015, ARXIV
   Narayanan BK, 2018, EDUC INF TECHNOL, V23, P2719, DOI 10.1007/s10639-018-9738-y
   Noroozi Fatemeh, 2021, IEEE Transactions on Affective Computing, V12, P505, DOI 10.1109/TAFFC.2018.2874986
   Noroozi F, 2019, IEEE T AFFECT COMPUT, V10, P60, DOI 10.1109/TAFFC.2017.2713783
   Ofodile I, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21040414
   Park N, 2010, LECT NOTES ARTIF INT, V6422, P193, DOI 10.1007/978-3-642-16732-4_21
   Perez M, 2017, NEUROCOMPUTING, V230, P279, DOI 10.1016/j.neucom.2016.12.017
   Rowley HA, 2006, VISAPP 2006: PROCEEDINGS OF THE FIRST INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P290
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sapinski T, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21070646
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Singh M, 2016, SCI REP-UK, V6, DOI 10.1038/srep26900
   Sugimoto CR, 2017, J ASSOC INF SCI TECH, V68, P2037, DOI 10.1002/asi.23833
   Sundararajan M, 2017, PR MACH LEARN RES, V70
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tan WR, 2019, IEEE T IMAGE PROCESS, V28, P394, DOI 10.1109/TIP.2018.2866698
   Wang YS, 2019, IEEE I CONF COMP VIS, P322, DOI 10.1109/ICCV.2019.00041
   Wehrmann J, 2018, NEUROCOMPUTING, V272, P432, DOI 10.1016/j.neucom.2017.07.012
   Yuan K, 2019, P IEEE S SECUR PRIV, P952, DOI 10.1109/SP.2019.00032
   Zheng QF, 2006, INT J IMAGE GRAPH, V6, P115, DOI 10.1142/S0219467806002082
   Zhu H, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P801, DOI 10.1109/ICIG.2007.29
   Zhu Y, 2020, IEEE T AFFECT COMPUT
NR 52
TC 0
Z9 0
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4439
EP 4463
DI 10.1007/s11042-022-11968-3
EA JUL 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000832565900006
DA 2024-07-18
ER

PT J
AU Otair, M
   Hasan, OA
   Abualigah, L
AF Otair, Mohammed
   Hasan, Osama Abdulraziq
   Abualigah, Laith
TI The effect of using minimum decreasing technique on enhancing the
   quality of lossy compressed images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Minimum decreasing technique; Image quality; Compressed images; Lossless
   and lossy techniques
ID SEARCH ALGORITHM; TRANSFORM; COLOR
AB With the wide use of social media platforms, the critical matter is to reduce the image size while maintaining the image quality to achieve faster transfer speeds over the networks and save space on storage devices. The compression techniques are categorized into lossless and lossy. Lossless techniques produced high-quality compressed images with no loss of any part of the images, but it has low performance compared to the lossy technique with high distortion rates. This paper studies the effects of applying the Minimum Decreasing Technique (MDT) over a set of lossy compression techniques and evaluates the impact on the image quality and size. This was achieved by applying specific steps that decrease the minimum pixel values from the pixel values inside the image. We implemented the MDT technique first before using the lossy ones on several images wildly used in the image processing field. The results were obtained based on quality standard metrics (MSE, MAE, PSNR, and CR). The MDT technique managed to keep the image quality as is without increasing or decreasing in the metrics when used with the lossy techniques, whether alone or hybrid; it also managed to reduce the compression ratio due to the MDT mechanism, which depends on the other arrays included with the compressed image. Moreover, the results showed the highest compression ratio obtained by the proposed technique with 2-8% impartments compared to the other single or hybrid methods.
C1 [Otair, Mohammed; Hasan, Osama Abdulraziq; Abualigah, Laith] Amman Arab Univ, Fac Comp Sci & Informat, Amman 11953, Jordan.
   [Abualigah, Laith] Al Ahliyya Amman Univ, Hourani Ctr Appl Sci Res, Amman 19328, Jordan.
   [Abualigah, Laith] Univ Sains Malaysia, Sch Comp Sci, George Town 11800, Malaysia.
   [Abualigah, Laith] Middle East Univ, Fac Informat Technol, Amman 11831, Jordan.
C3 Al-Ahliyya Amman University; Universiti Sains Malaysia; Middle East
   University
RP Abualigah, L (corresponding author), Amman Arab Univ, Fac Comp Sci & Informat, Amman 11953, Jordan.; Abualigah, L (corresponding author), Al Ahliyya Amman Univ, Hourani Ctr Appl Sci Res, Amman 19328, Jordan.; Abualigah, L (corresponding author), Univ Sains Malaysia, Sch Comp Sci, George Town 11800, Malaysia.; Abualigah, L (corresponding author), Middle East Univ, Fac Informat Technol, Amman 11831, Jordan.
EM Otair@aau.edi.jo; osama.a.hasan@aau.edu.jo; Aligah.2020@gmail.com
RI Abualigah, Laith/ABC-9695-2020
OI Abualigah, Laith/0000-0002-2203-4549
CR Abdelghany H. M., 2017, INT J RES APPL SCI E, V5, P169, DOI [10.22214/ijraset.2017.11027, DOI 10.22214/IJRASET.2017.11027]
   Abualigah L., 2021, CLUSTER COMPUT, V24, P2161, DOI DOI 10.1007/s10586-021-03254-y
   Abualigah L. M. Q., 2019, Feature selection and enhanced krill herd algorithm for text document clustering, DOI [DOI 10.1007/978-3-030-10674-4, 10.1007/978-3-030-10674-4]
   Abualigah L, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116158
   Abualigah L, 2021, COMPUT METHOD APPL M, V376, DOI 10.1016/j.cma.2020.113609
   Abualigah L, 2021, ARTIF INTELL REV, V54, P2567, DOI 10.1007/s10462-020-09909-3
   Abualigah LM, 2018, J COMPUT SCI-NETH, V25, P456, DOI 10.1016/j.jocs.2017.07.018
   Abualigah LM, 2017, J SUPERCOMPUT, V73, P4773, DOI 10.1007/s11227-017-2046-2
   Abuowaida SFA, 2021, JORDAN J COMPUT INFO, V7, P74, DOI 10.5455/jjcit.71-1603701313
   Agushaka JO, 2022, COMPUT METHOD APPL M, V391, DOI 10.1016/j.cma.2022.114570
   Ahar A, 2018, IEEE T IMAGE PROCESS, V27, P879, DOI 10.1109/TIP.2017.2771412
   Alshami AL, 2018, INT J ADV COMPUT SC, V9, P397
   Amirshahi S.A., 2018, P COLOR IMAGING C SO, V2018, P241
   [Anonymous], 1985, COMPUTATIONAL GEOMET, DOI DOI 10.1007/978-1-4612-1098-6
   [Anonymous], 2016, IEEE COMPUT GRAPH
   [Anonymous], 2016, International Journal of Computer Applications
   Bhateja V, 2018, INFORM SYSTEMS DESIG, V672
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Deng LB, 2021, APPL INTELL, V51, P359, DOI 10.1007/s10489-020-01795-0
   Ha M, 2016, WORKSHOP IMAGE PROCE
   Haque NI, 2018, 2018 5 INT C NETWORK
   Hasan TS., 2017, J APPL SCI RESEARCHE, V13, P1
   Hilles SM, 2018, INT J DATA SCI RES, V1, P1
   Irmak E, 2016, 2016 THE 4TH IEEE INTERNATIONAL CONFERENCE ON SMART ENERGY GRID ENGINEERING (SEGE), P371, DOI 10.1109/SEGE.2016.7589554
   Kouadria N, 2019, COMPUT ELECTR ENG, V73, P194, DOI 10.1016/j.compeleceng.2018.11.010
   Langdon WB, 2016, INFORM SOFTWARE TECH, V73, P16, DOI 10.1016/j.infsof.2016.01.003
   Menassel R, 2018, J EXP THEOR ARTIF IN, V30, P429, DOI 10.1080/0952813X.2017.1409281
   Otair M. A., 2016, RES J APPL SCI ENG T, V12, P680
   Oyelade ON, 2022, IEEE ACCESS, V10, P16150, DOI 10.1109/ACCESS.2022.3147821
   Padmapriya VM, 2020, MULTIMED TOOLS APPL, V79, P17945, DOI 10.1007/s11042-020-08610-5
   Patin F., 2003, An introduction to digital image processing
   Phamila YAV, 2014, SIGNAL PROCESS, V95, P161, DOI 10.1016/j.sigpro.2013.09.001
   Raghavendra C, 2019, CLUSTER COMPUT, V22, pS3911, DOI 10.1007/s10586-018-2508-1
   Rajan PVS, 2019, J INTELL SYST, V28, P87, DOI 10.1515/jisys-2016-0096
   Ren WQ, 2020, INT J COMPUT VISION, V128, P240, DOI 10.1007/s11263-019-01235-8
   Ren WQ, 2019, IEEE T IMAGE PROCESS, V28, P4364, DOI 10.1109/TIP.2019.2910412
   Richardson D, 2007, MATH COMPUT SCI, V1, P21, DOI 10.1007/s11786-007-0002-x
   Said A, 1996, IEEE T IMAGE PROCESS, V5, P1303, DOI 10.1109/83.535842
   Shehab M, 2019, INT J BIO-INSPIR COM, V14, P190, DOI 10.1504/IJBIC.2019.103606
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Tang ZS, 2019, IEEE T BROADCAST, V65, P138, DOI 10.1109/TBC.2018.2871376
   Uthayakumar J, 2020, IEEE T RELIAB, V69, P1398, DOI 10.1109/TR.2020.2972567
   Vyas A, 2018, SIGNALS COMMUN TECHN, P133, DOI 10.1007/978-981-10-7272-7_5
   Yam KL, 2004, J FOOD ENG, V61, P137, DOI 10.1016/S0260-8774(03)00195-X
   Yousri D, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.107052
NR 45
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4107
EP 4138
DI 10.1007/s11042-022-13404-y
EA JUL 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000828446600001
DA 2024-07-18
ER

PT J
AU Pei, SW
   Ni, B
   Shen, TM
   Zhou, ZL
   Chen, YW
   Qiu, MK
AF Pei, Songwen
   Ni, Bo
   Shen, Tianma
   Zhou, Zhenling
   Chen, Yewang
   Qiu, Meikang
TI RISAT: real-time instance segmentation with adversarial training
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Autonomous driving; Real-time instance segmentation; Object detection;
   GAN
ID VEHICLES
AB With the development of artificial intelligence, autonomous driving has gradually attracted attentions from academia and industry. Detecting road conditions correctly and timely is essential to autonomous driving. Thus, we propose a flexible and parallel framework called RISAT for real-time instance segmentation. RISAT improves on YOLOv3 by adding a new parallel branch to generate masks. RISAT can produce a good performance on high-quality segmentation for each instance using GAN. Furthermore, we utilizes ROI class loss on both mask learning for each class and perceptual loss on detailed information. On the benchmark of MS COCO, the frame per second(FPS) of RISAT can achieve 43, which is much faster than that of MNC and FCIS. Besides, the average precision(AP) of RISAT is greater than the previous one-stage object detection method by 0.5.
C1 [Pei, Songwen; Ni, Bo; Zhou, Zhenling] Univ Shanghai Sci & Technol, Dept Comp Sci & Engn, Shanghai 200093, Peoples R China.
   [Pei, Songwen] Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing 100190, Peoples R China.
   [Pei, Songwen] Fudan Univ, Shanghai Key Lab Data Sci, Shanghai 200433, Peoples R China.
   [Shen, Tianma] Santa Clara Univ, Dept Comp Sci & Engn, Santa Clara, CA 95053 USA.
   [Chen, Yewang] Huaqiao Univ, Coll Comp Sci & Technol, Xiamen 361021, Peoples R China.
   [Qiu, Meikang] Texas A&M Univ, Dept Comp Sci, Commerce, TX USA.
C3 University of Shanghai for Science & Technology; Chinese Academy of
   Sciences; Institute of Computing Technology, CAS; Fudan University;
   Santa Clara University; Huaqiao University; Texas A&M University System
RP Pei, SW (corresponding author), Univ Shanghai Sci & Technol, Dept Comp Sci & Engn, Shanghai 200093, Peoples R China.; Pei, SW (corresponding author), Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing 100190, Peoples R China.; Pei, SW (corresponding author), Fudan Univ, Shanghai Key Lab Data Sci, Shanghai 200433, Peoples R China.
EM swpei@usst.edu.cn
RI Chen, Yewang/AAN-6803-2020
OI Chen, Yewang/0000-0001-9691-0807
FU National Natural Science Foundation of China [61975124]; Shanghai
   Natural Science Foundation [20ZR1428600]; Open Project Program of
   Shanghai Key Laboratory of Data Science [2020090600003]; State Key Lab
   of Computer Architecture, ICT, CAS [CARCHA202111]
FX This work was partially funded by the National Natural Science
   Foundation of China under Grant (61975124), Shanghai Natural Science
   Foundation(20ZR1428600), the Open Project Program of Shanghai Key
   Laboratory of Data Science (NO.2020090600003), and the Open Project
   Funding from the State Key Lab of Computer Architecture, ICT, CAS under
   Grant CARCHA202111. Any opinions, findings and conclusions expressed in
   this paper are those of the authors and do not necessarily reflect the
   views of the sponsors.
CR Al-Qizwini M, 2017, IEEE INT VEH SYM, P89, DOI 10.1109/IVS.2017.7995703
   [Anonymous], 2017, ELECT IMAG, DOI [DOI 10.2352/ISSN.2470-1173.2017.19.AVM-023, 10.2352/ISSN.2470-1173.2017.19.AVM-023]
   Aqqa, 2021, 16 INT C COMPUTER VI
   Bagloee SA, 2016, J MOD TRANSP, V24, P284, DOI 10.1007/s40534-016-0117-3
   Bolya D, 2019, IEEE I CONF COMP VIS, P9156, DOI 10.1109/ICCV.2019.00925
   Chen LC, 2018, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2018.00422
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343
   Fu C-Y, 2019, ARXIV 190103353
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoermann S, 2018, IEEE INT CONF ROBOT, P2056
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang ZJ, 2019, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2019.00657
   Jian LH, 2019, IEEE CONSUM ELECTR M, V8, P81, DOI 10.1109/MCE.2019.2892286
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kawasaki A, 2021, IEEE WINT CONF APPL, P3722, DOI 10.1109/WACV48630.2021.00377
   Kim H, 2021, ARXIV 210414754
   Kirillov A, 2017, PROC CVPR IEEE, P7322, DOI 10.1109/CVPR.2017.774
   Kohli P, 2009, INT J COMPUT VISION, V82, P302, DOI 10.1007/s11263-008-0202-0
   Koul S, 2022, MULTIMED TOOLS APPL, V81, P11259, DOI 10.1007/s11042-022-11974-5
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee Y, 2020, P IEEE CVF C COMP VI
   Li PL, 2019, PROC CVPR IEEE, P7636, DOI 10.1109/CVPR.2019.00783
   LI Y, 2017, PROC CVPR IEEE, P4438, DOI [DOI 10.1109/CVPR.2017.472, DOI 10.1109/CVPR.2017.199]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu R, 2021, ARXIV 210307893
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2019, 2019 4 INT C INTELLI
   Liu Y, 2022, J INTELL TRANSPORT S, V26, P253, DOI 10.1080/15472450.2020.1848561
   Luc P, 2016, ARXIV 161108408
   Miksys L, 2019, ARXIV 190511358
   Pei SW, 2020, INFORM SCIENCES, V513, P17, DOI 10.1016/j.ins.2019.11.040
   Pei SW, 2018, P INT COMP SOFTW APP, P355, DOI 10.1109/COMPSAC.2018.00056
   Pinheiro PO, 2015, ADV NEUR IN, V28
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Richardson E, 2020, ARXIV 200800951
   Sarkar K, 2021, ARXIV 210306902
   Shaheed K, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116288
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tan Z, 2021, ARXIV 210306878
   Uricar M, 2019, LETS GET DIRTY GAN B
   Xie E, 2019, ARXIV 190913226
   Yao J, 2020, IEEE T CYBERNETICS
   Zeng NY, 2021, NEUROCOMPUTING, V425, P173, DOI 10.1016/j.neucom.2020.04.001
   Zhou C, 2019, ARXIV 190209080
NR 47
TC 2
Z9 2
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4063
EP 4080
DI 10.1007/s11042-022-13447-1
EA JUL 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000828446600005
DA 2024-07-18
ER

PT J
AU Wang, HY
   Tsung, CK
   Hung, CH
   Chen, CH
AF Wang, Hsiao-Yu
   Tsung, Chen-Kun
   Hung, Ching-Hua
   Chen, Chen-Huei
TI Designing the rule classification with oversampling approach with high
   accuracy for imbalanced data in semiconductor production lines
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Manufacturing quality cause analysis; Oversampling; Imbalanced data;
   Synthetic minority over-sampling technique
ID PERFORMANCE; SELECTION; CLUSTER
AB The product quality is the major factor for enhancing the production ability and competitiveness. Decreasing the cost and increasing production capacity are common approaches to realize the enhancement of the product quality. The production managers apply various multimedia data to evaluate the product quality. For example, capturing the stamping sound to evaluate the correct cutting and taking the component image to measure the chip positions are common heterogeneous multimedia data that are applied to manufacturing. However, the production managers prefer to minimize the number of defective products, e. g. the secondary operation and fixing the product tolerance in the assembly stage, to fitting the production target. Therefore, contrasting the defective product identification procedure with high accuracy becomes a challenge due to the decrease of the number of the defective products. In this paper, we propose the Rule Classification with Oversampling (RCOS) approach to provide the high accuracy with few defective products. The proposed RCOS includes the oversampling technique and the rule classification approach to emphasize the properties of the defective products and provide the precise classes. Given few defective products, capturing the properties of the failure is difficult. The RCOS considers the revised Synthetic Minority Over-Sampling Technique (SMOTE) to highlight the failure properties, and then the rule model is considered to extract the root cause of the defective products. We implement the proposed RCOS in the semiconductor production line. From the experiment results, the proposed RCOS provide about at most 98% in accuracy, and the comparison shows that the results have been improved in common criteria e. g. the true-positive rate, G mean, F1 score, and False Alarm Rate. Therefore, the proposed RCOS provides high practicality for the implementation consideration.
C1 [Wang, Hsiao-Yu; Hung, Ching-Hua] Natl Yang Ming Chiao Tung Univ, Dept Mech Engn, 1001 Univ Rd, Hsinchu 300, Taiwan.
   [Tsung, Chen-Kun] Natl Chin Yi Univ Technol, Dept Comp Sci & Informat Engn, 57 Sec 2 Zhongshan Rd, Taichung 41170, Taiwan.
   [Chen, Chen-Huei] Natl Chung Hsing Univ, Dept Comp Sci & Engn, 145 Xingda Rd South Dist, Taichung 402, Taiwan.
C3 National Yang Ming Chiao Tung University; National Chin-Yi University of
   Technology; National Chung Hsing University
RP Tsung, CK (corresponding author), Natl Chin Yi Univ Technol, Dept Comp Sci & Informat Engn, 57 Sec 2 Zhongshan Rd, Taichung 41170, Taiwan.
EM ckt@ncut.edu.tw
RI Tsung, Chen-Kun/AEW-1270-2022
OI Tsung, Chen-Kun/0000-0002-0042-233X
CR Agrawal R., 1994, P INT VLDB C VLDB 94, P487, DOI DOI 10.5555/645920.672836
   Aha, UCIML REPOSITORY SEC
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Anand A, 2010, AMINO ACIDS, V39, P1385, DOI 10.1007/s00726-010-0595-2
   Arif F., 2013, International Journal of Computer Applications, V69, P35
   Arif F, 2013, IERI PROC, V4, P201, DOI 10.1016/j.ieri.2013.11.029
   Boukerche A, 2020, ACM COMPUT SURV, V53, DOI [10.1145/3381028, 10.1145/3421763]
   Chan YW, 2020, IEEE ACCESS, V8, P24385, DOI 10.1109/ACCESS.2020.2971082
   Chang CH, 2020, IEEE ACCESS, V8, P170162, DOI 10.1109/ACCESS.2020.3023924
   Chomboon K, 2013, P INT MULT ENG COMP, P1
   Colledani M, 2020, CIRP ANN-MANUF TECHN, V69, P365, DOI 10.1016/j.cirp.2020.04.018
   Fan SKS, 2020, ADV ENG INFORM, V46, DOI 10.1016/j.aei.2020.101166
   García S, 2012, KNOWL-BASED SYST, V25, P3, DOI 10.1016/j.knosys.2011.01.012
   García S, 2009, EVOL COMPUT, V17, P275, DOI 10.1162/evco.2009.17.3.275
   Hassan MM, 2017, INT RES J ENG TECHNO, V4
   Huang CX, 2020, PATTERN RECOGN LETT, V133, P280, DOI 10.1016/j.patrec.2020.03.016
   Ijaz MF, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8081325
   Jiang PY, 2014, J INTELL MANUF, V25, P521, DOI 10.1007/s10845-012-0703-0
   Kerdprasop K., 2011, P INT MULT ENG COMP
   Kovács G, 2019, APPL SOFT COMPUT, V83, DOI 10.1016/j.asoc.2019.105662
   Kristiani E, 2021, IEEE INTERNET THINGS, V8, P309, DOI 10.1109/JIOT.2020.3004244
   Kumar Adarsh, 2021, International Conference on Innovative Computing and Communications. Proceedings of ICICC 2020. Advances in Intelligent Systems and Computing (AISC 1166), P571, DOI 10.1007/978-981-15-5148-2_51
   Lee DH, 2019, J MANUF SYST, V52, P146, DOI 10.1016/j.jmsy.2019.07.001
   Lim P, 2017, IEEE T CYBERNETICS, V47, P2850, DOI 10.1109/TCYB.2016.2579658
   Mairal J., 2009, P 26 ANN INT C MACHI, P689, DOI 10.1145/1553374.1553463
   McCann M, 2010, Causality: Objectives and Assessment, V6, P277
   Mubarik MS, 2021, J CLEAN PROD, V292, DOI 10.1016/j.jclepro.2021.126058
   Munirathinam Sathyan, 2016, International Journal of Engineering and Technology, V8, P273, DOI 10.7763/IJET.2016.V8.898
   Sowade E, 2016, SCI REP-UK, V6, DOI 10.1038/srep33490
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Khoa TV, 2020, IEEE WCNC, DOI 10.1109/wcnc45663.2020.9120761
   Triguero I, 2017, INT J COMPUT INT SYS, V10, P1238
   Tsung CK, 2019, IEEE ACCESS, V7, P26497, DOI 10.1109/ACCESS.2019.2901115
   Wang C, 2020, IEEE ACCESS, V8, P57674, DOI 10.1109/ACCESS.2020.2982410
   Wang H, THESIS NATL CHUNG CH
   Yang CT, 2019, FUTURE GENER COMP SY, V96, P731, DOI 10.1016/j.future.2018.02.041
   Yang CT, 2014, FUTURE GENER COMP SY, V37, P26, DOI 10.1016/j.future.2014.03.001
   Yap B.W., 2014, LNEE, V285, P13, DOI [DOI 10.1007/978-981-4585-18-7_2, 10.1007/978-981- 4585-18-7_2]
   Zakzeski J, 2010, CHEM REV, V110, P3552, DOI 10.1021/cr900354u
   Zeng Y, 2016, J QUAL TECHNOL, V48, P284
   Zhong G, 2022, IEEE T KNOWL DATA EN, V34, P2106, DOI 10.1109/TKDE.2020.3009488
   Zhou X, 2021, IEEE T IND INF
   Zhou XK, 2021, IEEE T IND INFORM, V17, P3469, DOI 10.1109/TII.2020.3022432
   Zou J, 2018, IEEE T SYST MAN CY-S, V48, P255, DOI 10.1109/TSMC.2016.2597062
NR 44
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36437
EP 36452
DI 10.1007/s11042-021-11552-1
EA JUL 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000823376700008
DA 2024-07-18
ER

PT J
AU Sayed, WS
   Noeman, AM
   Abdellatif, A
   Abdelrazek, M
   Badawy, MG
   Hamed, A
   El-Tantawy, S
AF Sayed, Wafaa S.
   Noeman, Ahmed M.
   Abdellatif, Abdelrahman
   Abdelrazek, Moemen
   Badawy, Mostafa G.
   Hamed, Ahmed
   El-Tantawy, Samah
TI AI-based adaptive personalized content presentation and exercises
   navigation for an effective and engaging E-learning platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic learner model; Gamification; Learning style; Primary school
   mathematics; Reinforcement learning
ID SCHOOL STUDENTS; SYSTEM; INTELLIGENT; EDUCATION; STYLES; ICT;
   GAMIFICATION; INSTRUCTION; TECHNOLOGY; LITERACY
AB Effective and engaging E-learning becomes necessary in unusual conditions such as COVID-19 pandemic, especially for the early stages of K-12 education. This paper proposes an adaptive personalized E-learning platform with a novel combination of Visual/Aural/Read, Write/Kinesthetic (VARK) presentation or gamification and exercises difficulty scaffolding through skipping/hiding/ reattempting. Cognitive, behavior and affective adaptation means are included in developing a dynamic learner model, which detects and corrects each student's learning style and cognitive level. As adaptation targets, the platform provides adaptive content presentation in two groups (VARK and gamification), adaptive exercises navigation and adaptive feedback. To achieve its goal, the platform utilizes a Deep Q-Network Reinforcement Learning (DQN-RL) and an online rule-based decision making implementation. The platform interfaces front-end dedicated website and back-end adaptation algorithms. An improvement in learning effectiveness is achieved comparing the post-test to the pre-test in a pilot experiment for grade 3 mathematics curriculum. Both groups witnessed academic performance and satisfaction level improvements, most importantly, for the students who started the experiment with a relatively low performance. VARK group witnessed a slightly more improvement and higher satisfaction level, since interactive activities and games in the kinesthetic presentation can provide engagement, while keeping other presentation styles available, when needed.
C1 [Sayed, Wafaa S.; El-Tantawy, Samah] Cairo Univ, Fac Engn, Engn Math & Phys Dept, Giza 12613, Egypt.
   [Abdellatif, Abdelrahman] Cairo Univ, Mech Power Engn Dept, Fac Engn, Giza 12613, Egypt.
   [Abdelrazek, Moemen; Badawy, Mostafa G.] Cairo Univ, Fac Engn, Comp Engn Dept, Giza 12613, Egypt.
C3 Egyptian Knowledge Bank (EKB); Cairo University; Egyptian Knowledge Bank
   (EKB); Cairo University; Egyptian Knowledge Bank (EKB); Cairo University
RP Sayed, WS (corresponding author), Cairo Univ, Fac Engn, Engn Math & Phys Dept, Giza 12613, Egypt.
EM wafaasayed@eng1.cu.edu.eg; ahmed.noeman11@gmail.com;
   abdelrahman.mahmoud97@eng-st.cu.edu.eg;
   moemen.abdelrazek96@alumni.eng.cu.edu.eg;
   mostafa.gamal95@alumni.eng.cu.edu.eg; me@ahmedhamed.net;
   samah.el.tantawy@cu.edu.eg
RI Sayed, Wafaa Saber/AAT-9268-2020
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Abu Arqub O, 2020, SOFT COMPUT, V24, P12501, DOI 10.1007/s00500-020-04687-0
   Abu Arqub O, 2014, INFORM SCIENCES, V279, P396, DOI 10.1016/j.ins.2014.03.128
   Alhathli M, 2017, ADJUNCT PUBLICATION OF THE 25TH CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION (UMAP'17), P275, DOI 10.1145/3099023.3099079
   Analytica O, 2016, GAMIFICATION FUTURE
   Balasubramanian V, 2018, AIN SHAMS ENG J, V9, P895, DOI 10.1016/j.asej.2016.04.012
   Beck JE, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P552
   Bimba AT, 2017, ADAPT BEHAV, V25, P217, DOI 10.1177/1059712317727590
   Bloom B. S., 1968, Evaluation Comment, V1, DOI DOI 10.1021/ED063P318
   BLOOM BS, 1984, EDUC LEADERSHIP, V41, P4
   Bocconi S, 2013, EUR J EDUC, V48, P113, DOI 10.1111/ejed.12021
   Chen CH, 2014, AUSTRALAS J EDUC TEC, V30, P342
   Chu YS, 2014, EDUC TECHNOL SOC, V17, P347
   Covaci A, 2018, MULTIMED TOOLS APPL, V77, P21245, DOI 10.1007/s11042-017-5459-2
   Dolenc K, 2015, COMPUT EDUC, V82, P354, DOI 10.1016/j.compedu.2014.12.010
   Early DM, 2007, CHILD DEV, V78, P558, DOI 10.1111/j.1467-8624.2007.01014.x
   El-Tantawy S, 2014, J INTELL TRANSPORT S, V18, P227, DOI 10.1080/15472450.2013.810991
   Faiella F, 2015, J E-LEARN KNOWL SOC, V11, P13
   Feng MY, 2018, LECT NOTES ARTIF INT, V10948, P89, DOI 10.1007/978-3-319-93846-2_17
   Fössl T, 2016, EDUC TECHNOL SOC, V19, P321
   Gylfason T, 2001, EUR ECON REV, V45, P847, DOI 10.1016/S0014-2921(01)00127-1
   Hsieh SW, 2011, COMPUT EDUC, V57, P1194, DOI 10.1016/j.compedu.2011.01.004
   Hsieh YH, 2015, EDUC TECHNOL SOC, V18, P336
   Huang CJ, 2010, EDUC TECHNOL SOC, V13, P126
   Hubalovsky S, 2019, COMPUT HUM BEHAV, V92, P691, DOI 10.1016/j.chb.2018.05.033
   Iglesias A, 2009, KNOWL-BASED SYST, V22, P266, DOI 10.1016/j.knosys.2009.01.007
   Iglesias A, 2009, APPL INTELL, V31, P89, DOI 10.1007/s10489-008-0115-1
   James W., 1993, APPLYING COGNITIVE L, V59, P47
   Johnson L., 2014, NMC HORIZON REPORT 2
   Keefe JamesW., 1987, LEARNING STYLE THEOR
   Knutas A, 2019, MULTIMED TOOLS APPL, V78, P13593, DOI 10.1007/s11042-018-6913-5
   Koc-Januchta MM, 2019, J COMPUT ASSIST LEAR, V35, P747, DOI 10.1111/jcal.12381
   Krathwohl D.R., 2009, A taxonomy for learning, teaching, and assessing: A revision of Bloom's taxonomy of educational objectives
   Kulik JA, 2016, REV EDUC RES, V86, P42, DOI 10.3102/0034654315581420
   Leite WL, 2010, EDUC PSYCHOL MEAS, V70, P323, DOI 10.1177/0013164409344507
   Lin CH, 2013, EDUC TECHNOL SOC, V16, P271
   Lin HT, 2015, SCI WORLD J
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Mosharraf, 2016, INTERDISCIPLINARY J, V12, P19, DOI [10.28945/3411, DOI 10.28945/3411]
   Neumann MM, 2018, EARLY CHILD RES Q, V42, P239, DOI 10.1016/j.ecresq.2017.10.006
   Nolan J, 2014, INFORM COMMUN SOC, V17, P594, DOI 10.1080/1369118X.2013.808365
   Normadhi NBA, 2019, COMPUT EDUC, V130, P168, DOI 10.1016/j.compedu.2018.11.005
   Okpo JA, 2018, NEW REV HYPERMEDIA M, V24, P193, DOI 10.1080/13614568.2018.1477999
   Pan WF, 2017, EDUC TECHNOL SOC, V20, P188
   Papousek J, 2017, ADJUNCT PUBLICATION OF THE 25TH CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION (UMAP'17), P299, DOI 10.1145/3099023.3099080
   Potter K., 2006, VLUDS, P97
   Prabha S. L., 2014, OPERATIONS RES APPL, V1, P23
   Premlatha KR, 2015, ARTIF INTELL REV, V44, P443, DOI 10.1007/s10462-015-9432-z
   Pruet P, 2016, COMPUT HUM BEHAV, V55, P1131, DOI 10.1016/j.chb.2014.09.063
   Sarwar S, 2019, MULTIMED TOOLS APPL, V78, P34745, DOI 10.1007/s11042-019-08125-8
   Shawky D., 2019, MACHINE LEARNING PAR, P169, DOI [10.1007/978-3-030-02357-7_8, DOI 10.1007/978-3-030-02357-7_8]
   Shawky D, 2018, ADV INTELL SYST COMP, V723, P221, DOI 10.1007/978-3-319-74690-6_22
   Shen ST, 2018, PROCEEDINGS OF THE 26TH CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION (UMAP'18), P43, DOI 10.1145/3209219.3209232
   Shyr WJ, 2018, J COMPUT ASSIST LEAR, V34, P53, DOI 10.1111/jcal.12213
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Tashtoush YM, 2017, INT CONF INFORM COMM, P86, DOI 10.1109/IACS.2017.7921951
   Tetreault J., 2006, P EUR ASS COMP LING
   Thepsatitporn S, 2016, ADV PHYSIOL EDUC, V40, P206, DOI 10.1152/advan.00081.2015
   Turchi T, 2019, MULTIMED TOOLS APPL, V78, P13649, DOI 10.1007/s11042-019-7229-9
   Vandewaetere M., 2014, HDB RES ED COMMUNICA, P425, DOI [DOI 10.1007/978-1-4614-3185-5_34, 10.1007/978-1-4614-3185-5_34]
   Vandewaetere M, 2011, COMPUT HUM BEHAV, V27, P118, DOI 10.1016/j.chb.2010.07.038
   VARK, 2018, US
   Wang TH, 2014, COMPUT EDUC, V73, P189, DOI 10.1016/j.compedu.2013.12.002
   Webb S, 2015, STUD SECOND LANG ACQ, V37, P651, DOI 10.1017/S0272263114000606
   Wu HM, 2017, EDUC TECHNOL SOC, V20, P61
   Xiao L, 2018, IEEE SIGNAL PROC MAG, V35, P41, DOI 10.1109/MSP.2018.2825478
   Young SSC, 2008, EDUC TECHNOL SOC, V11, P52
NR 66
TC 14
Z9 15
U1 35
U2 81
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3303
EP 3333
DI 10.1007/s11042-022-13076-8
EA JUN 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000818623900001
PM 35789938
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Dubey, AK
   Saraswat, M
   Kapoor, R
   Khanna, S
AF Dubey, Anil Kumar
   Saraswat, Mala
   Kapoor, Raman
   Khanna, Shaweta
TI Improved method for analyzing electrical data obtained from EEG for
   better diagnosis of brain related disorders
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain behavior; Cognition; EEG waves; Electrical data analysis; And
   neural disorders
ID CEREBROSPINAL-FLUID; VISUALIZATION
AB Interpretation of data obtained from electroencephalogram (EEG) has been commonly used for studying the condition of the brain and to diagnose any abnormalities. However, it is a common occurrence that different characteristic waves from EEG may overlap each other which may cause inaccuracies leading to wrong interpretation and hence incorrect diagnosis. In this paper, we present a modified approach to analyze the EEG signals differently. Firstly, the data is normalized, and then divided into three different ranges of equal intervals. This is done for each characteristic wave of EEG data. We have applied the proposed approach to brainwave datasets taken from Kaggle and IEEE dataport. The proposed method helps in estimating the current condition of the brain with higher accuracy, due to quantified contribution of different waves. The presented approach is expected to eliminate any errors, which may exist presently in the diagnosis of brain-related diseases and disorders. The discussed approach presented in this paper is dependent on data analysis, and it does not depends on the way of conducting the EEG tests. Hence, it is extendable to other disorders of the human body. The proposed approach finds many applications to improve the accuracy of brain related disorders by repudiating data overlap by 0.01% improvements.
C1 [Dubey, Anil Kumar; Saraswat, Mala; Kapoor, Raman] ABES Engn Coll, Dept CSE, Ghaziabad 201009, Uttar Pradesh, India.
   [Khanna, Shaweta] ITS Engn Coll, Dept ASH, Greater Noida, India.
RP Dubey, AK (corresponding author), ABES Engn Coll, Dept CSE, Ghaziabad 201009, Uttar Pradesh, India.; Khanna, S (corresponding author), ITS Engn Coll, Dept ASH, Greater Noida, India.
EM anildudenish@gmail.com; shweta.khanna04@gmail.com
OI KHANNA, SHAWETA/0000-0002-8879-2158
CR Abásolo D, 2008, IEEE T BIO-MED ENG, V55, P2171, DOI 10.1109/TBME.2008.923145
   Abhang P. A., 2016, Introduction to EEG- and Speech-Based Emotion Recognition, P19, DOI [10.1016/B978-0-12-804490-2.00002-6, DOI 10.1016/B978-0-12-804490-2.00002-6, 10.1016/B978-0-12, DOI 10.1016/B978-0-12]
   Accardo AP, 2004, P ANN INT IEEE EMBS, V26, P699
   Akbari H, 2021, HEALTH INF SCI SYST, V9, DOI 10.1007/s13755-021-00139-7
   Alturki FA, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092505
   [Anonymous], 2010, P 7 IEEE CONSUMER CO
   Awanti R, 2016, INT J EMERGING TECHN, V23, P54
   Bauer S, 2012, IEEE T BIO-MED ENG, V59, P25, DOI 10.1109/TBME.2011.2163406
   Baumann SB, 1997, IEEE T BIO-MED ENG, V44, P220, DOI 10.1109/10.554770
   Bhandari A, 2017, IEEE T NANOBIOSCI, V16, P634, DOI 10.1109/TNB.2017.2737038
   Chen PY, 2019, IEEE ACCESS, V7, P89043, DOI 10.1109/ACCESS.2019.2923221
   Conte R, 2019, 2019 IEEE 23RD INTERNATIONAL SYMPOSIUM ON CONSUMER TECHNOLOGIES (ISCT), P5, DOI [10.1109/isce.2019.8901045, 10.1109/ISCE.2019.8901045]
   Dai Y, 2019, IEEE ACCESS, V7, P106940, DOI 10.1109/ACCESS.2019.2931744
   Damhorst GL, 2015, P IEEE, V103, P150, DOI 10.1109/JPROC.2014.2385078
   De Leener B, 2015, IEEE T MED IMAGING, V34, P1705, DOI 10.1109/TMI.2015.2437192
   Deivasigamani S, 2021, J AMB INTEL HUM COMP, V12, P4215, DOI 10.1007/s12652-020-01816-3
   Demirhan A, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON FRONTIERS OF SIGNAL PROCESSING (ICFSP), P156, DOI 10.1109/ICFSP.2017.8097161
   Ladino LD, 2019, COMORBIDITIES OF EPILEPSY, P131, DOI 10.1016/B978-0-12-814877-8.00007-6
   Dubey AK., 2020, INT J COMPUT VISION, V10, P426, DOI [10.1504/IJCVR.2020.109392, DOI 10.1504/IJCVR.2020.109392]
   Dubey AK, 2021, SADHANA-ACAD P ENG S, V46, DOI 10.1007/s12046-021-01574-8
   Durongbhan P, 2019, IEEE T NEUR SYS REH, V27, P826, DOI 10.1109/TNSRE.2019.2909100
   Facchin S, 2015, IEEE T MAGN, V51, DOI 10.1109/TMAG.2014.2356594
   Gumaei A, 2019, IEEE ACCESS, V7, P36266, DOI 10.1109/ACCESS.2019.2904145
   Hawley LL, 2021, BEHAV RES THER, V136, DOI 10.1016/j.brat.2020.103757
   Hu PJH, 2007, IEEE T INF TECHNOL B, V11, P483, DOI 10.1109/TITB.2007.893286
   Huang JS, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00808
   Islam A, 2013, IEEE T BIO-MED ENG, V60, P3204, DOI 10.1109/TBME.2013.2271383
   Kakouri AC, 2019, IEEE J BIOMED HEALTH, V23, P26, DOI 10.1109/JBHI.2018.2865569
   Khoo Michael C K, 2013, IEEE Rev Biomed Eng, V6, P143, DOI 10.1109/RBME.2012.2232651
   Kropotov JD, 2009, QUANTITATIVE EEG, EVENT-RELATED POTENTIALS AND NEUROTHERAPY, P77, DOI 10.1016/B978-0-12-374512-5.00004-9
   Lee M, 2018, IEEE ACCESS, V6, P47206, DOI 10.1109/ACCESS.2018.2867030
   Linninger AA, 2007, IEEE T BIO-MED ENG, V54, P291, DOI 10.1109/TBME.2006.886853
   Marmarelis VZ, 2014, IEEE T BIO-MED ENG, V61, P694, DOI 10.1109/TBME.2013.2287120
   Michel M, 2021, TRANSL PSYCHIAT, V11, DOI 10.1038/s41398-021-01423-6
   Padilla P, 2012, IEEE T MED IMAGING, V31, P207, DOI 10.1109/TMI.2011.2167628
   Pham TD, 2018, IEEE T NEUR SYS REH, V26, P188, DOI 10.1109/TNSRE.2017.2732448
   Prabhakar SK, 2020, IEEE ACCESS, V8, P39875, DOI 10.1109/ACCESS.2020.2975848
   Ramzan M, 2019, P 2019 12 INT C CONT, P1
   Rashid A., 2014, INT J APPL MATH ELEC, V3, P78, DOI [10.18100/ijamec.80354, DOI 10.18100/IJAMEC.80354]
   Rollin G, 2019, IEEE ACCESS, V7, P26073, DOI 10.1109/ACCESS.2019.2899339
   Siuly S, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/576437
   Syeda F, 2019, IEEE T MAGN, V55, DOI 10.1109/TMAG.2019.2904023
   Tazi S, 2017, ADV COMPUTER COMPUTA, V553, DOI [10.1007/978-981-10-3770-2_60, DOI 10.1007/978-981-10-3770-2_60]
   Tor HT, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2021.105941
   Vaidya M, 2019, IEEE T NEUR SYS REH, V27, P1467, DOI 10.1109/TNSRE.2019.2912298
   Vogtle LK, 2009, DEV MED CHILD NEUROL, V51, P113, DOI 10.1111/j.1469-8749.2009.03423.x
   Youn CH, 2011, IEEE T BIO-MED ENG, V58, P809, DOI 10.1109/TBME.2010.2088397
   Zacharaki EI, 2008, IEEE T BIO-MED ENG, V55, P1233, DOI 10.1109/TBME.2007.905484
NR 48
TC 1
Z9 1
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 35223
EP 35244
DI 10.1007/s11042-021-11826-8
EA JUN 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000814451000001
DA 2024-07-18
ER

PT J
AU Zarachoff, MM
   Sheikh-Akbari, A
   Monekosso, D
AF Zarachoff, Matthew Martin
   Sheikh-Akbari, Akbar
   Monekosso, Dorothy
TI Multi-band PCA based ear recognition technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ear recognition; Principal component analysis; Multi-band image
   creation; Image classification; Image partitioning; Boundary selection
ID FEATURE-EXTRACTION; FACE REPRESENTATION; 2-DIMENSIONAL PCA; PROJECTION;
   REDUCTION
AB Principal Component Analysis (PCA) has been successfully applied to many applications, including ear recognition. This paper presents a Two Dimensional Multi-Band PCA (2D-MBPCA) method, inspired by PCA based techniques for multispectral and hyperspectral images, which have demonstrated significantly higher performance to that of standard PCA. The proposed method divides the input image into a number of images based on the intensity of the pixels. Three different methods are used to calculate the pixel intensity boundaries, called: equal size, histogram, and greedy hill climbing based techniques. Conventional PCA is then applied on the resulting images to extract their eigenvectors, which are used as features. The optimal number of bands was determined using the intersection of number of features and total eigenvector energy. Experimental results on two benchmark ear image datasets demonstrate that the proposed 2D-MBPCA technique significantly outperforms single image PCA by up to 56.41% and the eigenfaces technique by up to 29.62% with respect to matching accuracy on images from two benchmark datasets. Furthermore, it gives very competitive results to those of learning based techniques at a fraction of their computational cost and without a need for training.
C1 [Zarachoff, Matthew Martin; Sheikh-Akbari, Akbar; Monekosso, Dorothy] Leeds Beckett Univ, Sch Built Environm Engn & Comp, Caedmon Hall,43 Church Wood Ave, Leeds LS6 3QR, W Yorkshire, England.
C3 Leeds Beckett University
RP Zarachoff, MM (corresponding author), Leeds Beckett Univ, Sch Built Environm Engn & Comp, Caedmon Hall,43 Church Wood Ave, Leeds LS6 3QR, W Yorkshire, England.
EM m.zarachoff4868@student.leedsbeckett.ac.uk
RI Sheikh-Akbari, Akbar/AAA-7302-2022
OI Sheikh-Akbari, Akbar/0000-0003-0677-7083; Monekosso,
   Dorothy/0000-0001-7322-5911
FU Innovate UK [KTP 10304]
FX This research has been funded under a knowledge transfer partnership by
   Innovate UK (KTP 10304).
CR Alaraj M, 2010, TENCON IEEE REGION, P1595, DOI 10.1109/TENCON.2010.5686043
   Alshazly H, 2020, IEEE ACCESS, V8, P170295, DOI 10.1109/ACCESS.2020.3024116
   [Anonymous], 2002, USTB
   Benzaoui A, 2017, INT C CONTROL DECISI, P827, DOI 10.1109/CoDIT.2017.8102697
   Benzaoui A, 2015, 2015 INTERNATIONAL CONFERENCE ON APPLIED RESEARCH IN COMPUTER SCIENCE AND ENGINEERING (ICAR)
   Chang K, 2003, IEEE T PATTERN ANAL, V25, P1160, DOI 10.1109/TPAMI.2003.1227990
   Dodge S, 2018, IET BIOMETRICS, V7, P207, DOI 10.1049/iet-bmt.2017.0208
   Emersic Z, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P715, DOI 10.1109/BTAS.2017.8272761
   Emersic Z, 2017, NEUROCOMPUTING, V255, P26, DOI 10.1016/j.neucom.2016.08.139
   Gadre V., 2019, 2019 IEEE BOMB SECT, P1
   GHAFFAR A, 2019, 2019 2 INT C COMP, pNI701
   HARSANYI JC, 1994, IEEE T GEOSCI REMOTE, V32, P779, DOI 10.1109/36.298007
   Hassaballah M, 2020, MULTIMED TOOLS APPL, V79, P31183, DOI 10.1007/s11042-020-09456-7
   Hoi, 2020, P IEEE CVF C COMP VI, P8960, DOI DOI 10.1109/CVPR42600.2020.00898
   Jia XP, 1999, IEEE T GEOSCI REMOTE, V37, P538, DOI 10.1109/36.739109
   Kumar A, 2012, PATTERN RECOGN, V45, P956, DOI 10.1016/j.patcog.2011.06.005
   Kumar A, 2007, PROC SPIE, V6539, DOI 10.1117/12.720244
   Lu X, 2020, ARXIV 200707020
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Galdámez PL, 2014, 2014 17TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION)
   Minaee S., 2016, IEEE Region, P1
   Nejati H, 2012, INT C PATT RECOG, P1201
   Ning X, 2018, IEEE T IMAGE PROCESS, V27, P2575, DOI 10.1109/TIP.2018.2806229
   Nosrati MS, 2007, ICIAS 2007: INTERNATIONAL CONFERENCE ON INTELLIGENT & ADVANCED SYSTEMS, VOLS 1-3, PROCEEDINGS, P616
   Omara I., 2020, IEEEIAPR INT JOINT, P1, DOI DOI 10.1109/ijcb48548.2020.9304871
   Omara I, 2017, 2017 16TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS 2017), P341
   Pflug A, 2012, IET BIOMETRICS, V1, P114, DOI 10.1049/iet-bmt.2011.0003
   Querencias-Uceta D., 2017, INT CARN CONF SECU, P1
   Tian Y, 2018, CHIN CONT DECIS CONF, P1830, DOI 10.1109/CCDC.2018.8407424
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   Victor B, 2002, INT C PATT RECOG, P429, DOI 10.1109/ICPR.2002.1044746
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yuan X, 2005, IEEE INT SYMP CIRC S, P3211
   Zabalza J, 2014, ISPRS J PHOTOGRAMM, V93, P112, DOI 10.1016/j.isprsjprs.2014.04.006
   Zarachoff M, 2018, IEEE CONF IMAGING SY, P324
   Zarachoff MM, 2022, IEEE ACCESS, V10, P3949, DOI 10.1109/ACCESS.2021.3139684
   Zhang DQ, 2005, NEUROCOMPUTING, V69, P224, DOI 10.1016/j.neucom.2005.06.004
   Zhang HJ, 2005, Proceedings of 2005 International Conference on Machine Learning and Cybernetics, Vols 1-9, P4511
   Zhang Liping, 2018, Journal of Computer Aided Design & Computer Graphics, V30, P254, DOI 10.3724/SP.J.1089.2018.16302
   Zhao HL, 2009, 2009 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND INFORMATION TECHNOLOGY, VOL 2, P228, DOI 10.1109/ICCSIT.2009.5234392
NR 40
TC 2
Z9 2
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2077
EP 2099
DI 10.1007/s11042-022-12905-0
EA JUN 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000812445100003
OA Green Accepted, hybrid
DA 2024-07-18
ER

PT J
AU Wan, YJ
   Wang, SM
   Du, BX
AF Wan, Yujie
   Wang, Simiao
   Du, Baoxiang
TI A bit plane image encryption algorithm based on compound chaos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic system; Image encryption; Bit plane; Arnold transforming
ID SYSTEM; COMBINATION; MAP
AB In order to combine chaos with image encryption better, a composite hyperchaotic system is constructed by introducing a feedback controller, and then a new image encryption method based on hyperchaos and bit plane is proposed. Two images are scrambled into one through the method of bit plane decomposition. The image is divided into high-bit and low-bit planes, which are put into two matrices respectively, and then an auxiliary matrix is constructed with hyperchaotic sequence for encryption. After a round of scrambling diffusion algorithm, a picture is synthesized by bit plane, and then a round of modular diffusion encryption is carried out. The experimental results show that the proposed algorithm has high sensitivity and can resist several common attacks. It is proved that the combination of chaotic system and image encryption technology can effectively improve the security of this system.
C1 [Wan, Yujie; Wang, Simiao; Du, Baoxiang] Heilongjiang Univ, Elect Engn Coll, Harbin, Peoples R China.
C3 Heilongjiang University
RP Du, BX (corresponding author), Heilongjiang Univ, Elect Engn Coll, Harbin, Peoples R China.
EM dubaoxiang@hlju.edu.cn
RI Baoxiang, Du/ABF-5445-2021
OI Baoxiang, Du/0000-0001-6300-5907
CR Cao LC, 2015, CHINESE PHYS B, V24, DOI 10.1088/1674-1056/24/10/100501
   Ding X., 2020, J MOD OPTIC, V67, P1
   Gan ZH, 2019, NEURAL COMPUT APPL, V31, P7111, DOI 10.1007/s00521-018-3541-y
   Hasheminejad A, 2019, OPTIK, V184, P205, DOI 10.1016/j.ijleo.2019.03.065
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Lan Zhang-li, 2015, Applied Mechanics and Materials, V743, P379, DOI 10.4028/www.scientific.net/AMM.743.379
   Li CL, 2018, OPTIK, V171, P277, DOI 10.1016/j.ijleo.2018.06.029
   Liu J, 2013, CONTROL ENG COMMUNIC
   Liu JY, 2018, MULTIMED TOOLS APPL, V77, P10217, DOI 10.1007/s11042-017-5406-2
   Liu XB, 2019, IEEE ACCESS, V7, P6937, DOI 10.1109/ACCESS.2018.2889896
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Parvaz R, 2018, OPT LASER TECHNOL, V101, P30, DOI 10.1016/j.optlastec.2017.10.024
   Ren HG, 2016, INT J SECUR APPL, V10, P241, DOI 10.14257/ijsia.2016.10.12.19
   Tang R., 2017, J COMPUT APPL, V1, P89
   Wang Shuai, 2015, Application Research of Computers, V32, P512, DOI 10.3969/j.issn.1001-3695.2015.02.042
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu Yi-feng, 2018, Electronics Optics & Control, V25, P42, DOI 10.3969/j.issn.1671-637X.2018.11.008
   Xu C, 2020, MULTIMED TOOLS APPL, V79, P5573, DOI 10.1007/s11042-019-08273-x
   Zhang L, 2020, MULTIMED TOOLS APPL, V79, P20753, DOI 10.1007/s11042-020-08835-4
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 22
TC 7
Z9 7
U1 6
U2 62
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 22103
EP 22121
DI 10.1007/s11042-022-13345-6
EA JUN 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000811988300003
DA 2024-07-18
ER

PT J
AU Miled, M
   Ben Messaoud, MA
   Bouzid, A
AF Miled, Malek
   Ben Messaoud, Mohammed Anouar
   Bouzid, Aicha
TI Lip reading of words with lip segmentation and deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lip segmentation; DRLSE; Lip reading; Convolutional neural networks
   (CNN); Bi-directional gated recurrent (BI-GRU); Global average pooling
   1D
AB Speech perception is recognized as a multimodal task, that is, it solicits more than one meaning. Lip reading, which superimposes visual signals to auditory signals, is useful and sometimes even necessary for understanding a message. Lip-reading is an area of great importance for a wide range of applications, such as silent dictation, speech recognition in noisy environment, improved hearing aids and biometrics. It is a difficult research subject in the field of computer vision, whose main purpose is to observe the movement of human lips from the video to identify the corresponding textual content. However, because of the limitations of lip changes and the richness of linguistic content, the increased difficulty of lip recognition slows down the development of lip language research topics. Recently, the development of deep learning in various fields gives us enough confidence to carry out the task of lip recognition. Unlike recognition of lip characteristics in traditional lip recognition, lip learning based on deep learning typically involves extracting features and understanding images using a network model. In this topic, we focus on the design of the acquisition, processing, and data recognition network framework for lip reading. In this work, we developed an accurate and robust algorithm, for lip reading. First, we extract the mouth region and segmented the mouth by using a proposed hybrid model with a new proposed edge based on a proposed filter, then we train our spatio-temporal model by the combination of Convolutional Neural Networks (CNN) and Bi-directional Gated Recurrent Units (Bi-GRU). Finally, we test our algorithm, and we get an evaluation of 90.38% of accuracy. The result shows the performance of our system by application of lip segmented as inputs to the proposed spatio-temporal model.
C1 [Miled, Malek; Ben Messaoud, Mohammed Anouar; Bouzid, Aicha] Natl Engn Sch Tunis, Tunis, Tunisia.
   [Ben Messaoud, Mohammed Anouar] Fac Sci Tunis, Tunis, Tunisia.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT); Universite de Tunis-El-Manar; Faculte des Sciences de Tunis
   (FST)
RP Miled, M (corresponding author), Natl Engn Sch Tunis, Tunis, Tunisia.
EM malekmiled22@gmail.com
RI Bouzid, Aicha/HJP-3379-2023
OI MILED, Malek/0009-0002-4456-3748; Ben messaoud, Mohamed
   Anouar/0000-0002-7190-2736
CR Agrawal S, 2016, PROCEEDINGS OF THE 2016 2ND INTERNATIONAL CONFERENCE ON APPLIED AND THEORETICAL COMPUTING AND COMMUNICATION TECHNOLOGY (ICATCCT), P753, DOI 10.1109/ICATCCT.2016.7912100
   Bradski G., 2000, Opencv. Dr. Dobb's Journal of Software Tools, V3
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen YT, 2020, NEUROCOMPUTING, V399, P491, DOI 10.1016/j.neucom.2020.03.011
   Cheng SY, 2020, INT CONF ACOUST SPEE, P4357, DOI [10.1109/ICASSP40776.2020.9054384, 10.1109/icassp40776.2020.9054384]
   Chung JS, 2017, LECT NOTES COMPUT SC, V10112, P87, DOI 10.1007/978-3-319-54184-6_6
   Courtney L., 2020, PATTERN RECOGN, P307, DOI [10.1007/978-3, DOI 10.1007/978-3]
   Dahl GE, 2013, INT CONF ACOUST SPEE, P8609, DOI 10.1109/ICASSP.2013.6639346
   Danielis A, 2017, PATTERN RECOGN, V63, P355, DOI 10.1016/j.patcog.2016.10.007
   Eveno N, 2004, IEEE T CIRC SYST VID, V14, P706, DOI 10.1109/TCSVT.2004.826754
   Jiang Huiyan, 2011, Wuhan University Journal of Natural Sciences, V16, P265, DOI 10.1007/s11859-011-0748-5
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li L, 2010, IEEE T IMAGE PROCESS, V19, P1, DOI 10.1109/TIP.2009.2032341
   Liew AWC, 2003, IEEE T FUZZY SYST, V11, P542, DOI 10.1109/TFUZZ.2003.814843
   Luo MS, 2020, IEEE INT CONF AUTOMA, P273, DOI 10.1109/FG47880.2020.00010
   Martinez B, 2020, INT CONF ACOUST SPEE, P6319, DOI [10.1109/ICASSP40776.2020.9053841, 10.1109/icassp40776.2020.9053841]
   Ngiam J., 2011, IEEE INT C MACH LEAR, P689, DOI DOI 10.5555/3104482.3104569
   Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sakly H, 2019, J FLOW VIS IMAGE PRO, V26, P19, DOI 10.1615/JFlowVisImageProc.2018027194
   Stafylakis T, 2017, INTERSPEECH, P3652, DOI 10.21437/Interspeech.2017-85
   Wand M, 2016, INT CONF ACOUST SPEE, P6115, DOI 10.1109/ICASSP.2016.7472852
   Wang LF, 2013, PATTERN RECOGN LETT, V34, P637, DOI 10.1016/j.patrec.2012.12.022
   Xiao JY, 2020, IEEE INT CONF AUTOMA, P364, DOI 10.1109/FG47880.2020.00132
   Yan XP, 2010, LECT NOTES COMPUT SC, V6297, P731
   Yang HL, 2016, GREEN CHEM SUSTAIN T, P85, DOI [10.1007/978-3-662-47510-2_5, 10.1007/978-3-319-48890-5_9]
   Zhu HY, 2018, J BIOMED INFORM, V84, P148, DOI 10.1016/j.jbi.2018.07.006
NR 31
TC 2
Z9 2
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 551
EP 571
DI 10.1007/s11042-022-13321-0
EA JUN 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000809901300001
DA 2024-07-18
ER

PT J
AU Cong, RC
   Tago, KC
   Jin, Q
AF Cong, Ruichen
   Tago, Kiichi
   Jin, Qun
TI Measurement and verification of cognitive load in multimedia
   presentation using an eye tracker
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cognitive load; Multimedia presentation; Quantitative model;
   Eye-tracker; Pupil diameter variation
ID PUPIL SIZE
AB The development of interface designs can reduce extraneous processing for users and increase the effectiveness of multimedia presentations. In this study, we investigate cognitive load in multimedia presentations. First, we present a quantitative model to measure cognitive load in terms of information comprehension in which the pupil diameter variation is used as an indicator of cognitive load based on cognitive load theory. We design a verification experiment to measure the pupil diameter using an eye-tracker when different combinations of texts, audio-narrations, and images are presented to subjects. We further allow the subjects take a comprehension test on the presented information and analyze the relationship between cognitive load and the test score using the generalized linear mixed model (GLMM). Moreover, we obtain the subjective cognitive load via a pre-designed questionnaire taken after the experiment and compare these two types of cognitive loads in terms of the mean absolute error (MAE). The experiment results show that there is a gap between the objective cognitive load obtained via the pupillary response and the subjective cognitive load obtained via a questionnaire, and the presentation with an optimized combination of multimedia can enhance information comprehension while reducing cognitive load.
C1 [Cong, Ruichen; Tago, Kiichi] Waseda Univ, Grad Sch Human Sci, Tokorozawa, Saitama, Japan.
   [Jin, Qun] Waseda Univ, Fac Human Sci, Tokorozawa, Saitama, Japan.
C3 Waseda University; Waseda University
RP Jin, Q (corresponding author), Waseda Univ, Fac Human Sci, Tokorozawa, Saitama, Japan.
EM carriecong@moegi.waseda.jp; kiichi.tg@ruri.waseda.jp; jin@waseda.jp
RI Jin, Qun/H-3752-2012
OI Jin, Qun/0000-0002-1325-4275; CONG, RUICHEN/0000-0001-9435-4739
CR Chen SY, 2013, IEEE ENG MED BIO, P3202, DOI 10.1109/EMBC.2013.6610222
   Clark JM, 1991, EDUC PSYCHOL REV, V3, P149, DOI 10.1007/BF01320076
   Faraway J.J., 2016, Extending the Linear Model with R: Generalized Linear, Mixed Effects and Nonparametric Regression Models
   Galy E, 2012, INT J PSYCHOPHYSIOL, V83, P269, DOI 10.1016/j.ijpsycho.2011.09.023
   Goldinger SD, 2012, CURR DIR PSYCHOL SCI, V21, P90, DOI 10.1177/0963721412436811
   HESS EH, 1964, SCIENCE, V143, P1190, DOI 10.1126/science.143.3611.1190
   HESS EH, 1960, SCIENCE, V132, P349, DOI 10.1126/science.132.3423.349
   Hossain G, 2014, IEEE COMPUT SOC CONF, P381, DOI 10.1109/CVPRW.2014.62
   Jercic P, 2020, MULTIMED TOOLS APPL, V79, P3145, DOI 10.1007/s11042-018-6518-z
   Jiang X, 2014, P S EYE TRACK RES AP, DOI 10.1145/2578153.2578178
   Johannessen E, 2020, COMPUT HUM BEHAV, V111, DOI 10.1016/j.chb.2020.106393
   Joseph A.W., 2020, J SCI RES, V64, P168, DOI [10.37398/JSR.2020.640137, DOI 10.37398/JSR.2020.640137]
   Klingner J, 2011, PSYCHOPHYSIOLOGY, V48, P323, DOI 10.1111/j.1469-8986.2010.01069.x
   Kumar A., 2020, MULTIMEDIA BIG DATA, P289
   Leppink J, 2014, LEARN INSTR, V30, P32, DOI 10.1016/j.learninstruc.2013.12.001
   Liu Y, 2019, HUM-CENT COMPUT INFO, V9, DOI 10.1186/s13673-019-0166-9
   Mayer RE, 2002, PSYCHOL LEARN MOTIV, V41, P85, DOI 10.1016/S0079-7421(02)80005-6
   Pfleging B, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5776, DOI 10.1145/2858036.2858117
   Pomplun M., 2003, P INT C HCI, DOI DOI 10.1145/355017.355029
   Rafiqi S, 2015, 8TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2015), DOI 10.1145/2769493.2769506
   Reilly J, 2019, BEHAV RES METHODS, V51, P865, DOI 10.3758/s13428-018-1134-4
   Schnotz W, 2007, EDUC PSYCHOL REV, V19, P469, DOI 10.1007/s10648-007-9053-4
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Song H, 2019, J INF PROCESS SYST, V15, P645, DOI 10.3745/JIPS.01.0044
   Sweller J, 2011, PSYCHOL LEARN MOTIV, V55, P37
   Sweller J, 2010, EDUC PSYCHOL REV, V22, P123, DOI 10.1007/s10648-010-9128-5
   Wang LB, 2019, J INF PROCESS SYST, V15, P1422, DOI 10.3745/JIPS.04.0152
   Xiaoli Wu, 2015, Human-Computer Interaction, Users and Contexts. 17th International Conference, HCI International 2015. Proceedings: LNCS 9171, P525, DOI 10.1007/978-3-319-21006-3_50
   Xue Y.F., 2019, MOD ED TECHNOL, V29, P59
   Zagermann J, 2016, BEYOND TIME AND ERRORS: NOVEL EVALUATION METHODS FOR VISUALIZATION, BELIV 2016, P78, DOI 10.1145/2993901.2993908
   Zeng X., 2018, ANAL DESIGN POWER SP
NR 31
TC 4
Z9 4
U1 9
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 26821
EP 26835
DI 10.1007/s11042-022-13294-0
EA JUN 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000807318300007
DA 2024-07-18
ER

PT J
AU Mok, K
   Zhang, LM
AF Mok, Kawai
   Zhang, Liming
TI Adaptive traffic signal management method combining deep learning and
   simulation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning based vehicle detection; Adaptive traffic signal
   management; Traffic data acquisition; Traffic flow prediction
AB Deep neural networks (DNN) have recently demonstrated the ability to use big data to predict the traffic flow. However, the disadvantage of DNNs is that a large amount of data needs to be collected for each intersection and different intersections need to train different deep networks to estimate traffic flow accurately. This study proposes a new adaptive signal management method for the overall processing of smart cities, which combines deep learning and simulation to balance the issue of large-scale data collection. First, a computer-vision-based deep-learning network is trained offline to detect different types of vehicles. A large amount of training data can be collected throughout the city or country of interest, and the deep network only needs to be trained once. Then, for each intersection where traffic flow should be predicted, a small amount of data is collected, and a computer simulation model is developed to estimate local traffic flow. Finally, combining the traffic monitoring system based on deep learning with optimized simulation results, an adaptive traffic light management algorithm is developed. The proposed method can be easily adapted to different intersections by collecting a small amount of traffic data for each new intersection. Experimental results with real data for a complex T-shaped intersection in Macao show that the proposed method can significantly improve the overall traffic efficiency.
C1 [Mok, Kawai; Zhang, Liming] Univ Macau, Fac Sci & Technol, Taipa, Macao, Peoples R China.
C3 University of Macau
RP Zhang, LM (corresponding author), Univ Macau, Fac Sci & Technol, Taipa, Macao, Peoples R China.
EM mb65480@um.edu.mo; lmzhang@um.edu.mo
RI Zhang, Liming/ABG-5996-2020
OI Zhang, Liming/0000-0002-2664-8193
FU Science and Technology Development Fund of Macao SAR [FDCT 0060/2021/A];
   University of Macau [MYRG2018-00111-FST]
FX The Science and Technology Development Fund of Macao SAR FDCT
   0060/2021/A and multi-year research grant from the University of Macau
   MYRG2018-00111-FST.
CR Abdelhalim A., 2020, P IEEE CVF C COMP VI, P592
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Alzubi JA, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4069
   [Anonymous], YOLO REAL TIME OBJEC
   Asaithambi G, 2018, TRANSP LETT, V10, P92, DOI 10.1080/19427867.2016.1190887
   Audebert N, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9040368
   Azlan Nurul Nasuha Nor, 2018, MATEC Web of Conferences, V150, DOI 10.1051/matecconf/201815003006
   Babu MV, 2021, MOBILE NETW APPL, V26, P1059, DOI 10.1007/s11036-020-01664-7
   Barceló J, 2010, INT SER OPER RES MAN, V145, P1, DOI 10.1007/978-1-4419-6142-6_1
   Chen C, 2021, IEEE T INTELL TRANSP, V22, P1840, DOI 10.1109/TITS.2020.3025687
   Chen LK, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0350-2
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Das D, 2021, PEER PEER NETW APPL, V14, P672, DOI 10.1007/s12083-020-01022-0
   Datondji SRE, 2016, IEEE T INTELL TRANSP, V17, P2681, DOI 10.1109/TITS.2016.2530146
   Deng Y, 2019, THESIS AUCKLAND U TE
   Dongare AD., 2012, Int J Eng Innovative Technol (IJEIT), V2, P189, DOI DOI 10.1007/978-1-4757-3167-5_5
   Faye S, 2016, IEEE T VEH TECHNOL, V65, P5720, DOI 10.1109/TVT.2015.2465811
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Fuller W.A., 2009, Measurement error models
   Gharaibeh A, 2017, IEEE COMMUN SURV TUT, V19, P2456, DOI 10.1109/COMST.2017.2736886
   Gupta AK, 2019, TRAIT SIGNAL, V36, P425, DOI 10.18280/ts.360507
   Javaid S, 2018, INT CONF ADV COMMUN, P393, DOI 10.23919/ICACT.2018.8323770
   Lee WH, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020508
   Liang XY, 2019, IEEE T VEH TECHNOL, V68, P1243, DOI 10.1109/TVT.2018.2890726
   Liu XX, 2021, MULTIMED TOOLS APPL, V80, P15161, DOI 10.1007/s11042-020-10455-x
   Lopez PA, 2018, IEEE INT C INTELL TR, P2575, DOI 10.1109/ITSC.2018.8569938
   Lv YS, 2015, IEEE T INTELL TRANSP, V16, P865, DOI 10.1109/TITS.2014.2345663
   Menouar H, 2017, IEEE COMMUN MAG, V55, P22, DOI 10.1109/MCOM.2017.1600238CM
   Mishra KN, 2020, DIGITAL TWIN TECHNOL
   Nagy AM, 2018, PERVASIVE MOB COMPUT, V50, P148, DOI 10.1016/j.pmcj.2018.07.004
   Nallaperuma D, 2019, IEEE T INTELL TRANSP, V20, P4679, DOI 10.1109/TITS.2019.2924883
   Okai E, 2018, IEEE 20TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS / IEEE 16TH INTERNATIONAL CONFERENCE ON SMART CITY / IEEE 4TH INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), P1726, DOI 10.1109/HPCC/SmartCity/DSS.2018.00282
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Salimifard Khodakaram, 2013, International Journal of Modeling and Optimization, V3, P172, DOI 10.7763/IJMO.2013.V3.261
   Samadi S., 2019, INT J EL COMP ENG SY, V9, P1765, DOI DOI 10.11591/IJECE.913
   Seo SB, 2022, MULTIMED TOOLS APPL, V81, P26593, DOI 10.1007/s11042-020-10091-5
   Song HS, 2019, EUR TRANSP RES REV, V11, DOI 10.1186/s12544-019-0390-4
   Sucharitha M, 2020, COMPUTER VISION BRAI, P8194
   Suh W, 2017, MULTIMED TOOLS APPL, V76, P25253, DOI 10.1007/s11042-016-4318-x
   Wang C, 2018, TRANSPORT RES C-EMER, V90, P281, DOI 10.1016/j.trc.2018.03.011
   Wang H, 2019, IEEE INTEL TRANSP SY, V11, P82, DOI 10.1109/MITS.2019.2903518
   Yang MY, 2019, PHOTOGRAMM ENG REM S, V85, P297, DOI 10.14358/PERS.85.4.297
   Yang Z, 2018, IMAGE VISION COMPUT, V69, P143, DOI 10.1016/j.imavis.2017.09.008
   Zhang C, 2020, IEEE T VEH TECHNOL, V69, P10336, DOI 10.1109/TVT.2020.3005363
   Zhao DB, 2012, IEEE T SYST MAN CY C, V42, P485, DOI 10.1109/TSMCC.2011.2161577
NR 50
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 15439
EP 15459
DI 10.1007/s11042-022-13033-5
EA JUN 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:000806706600001
DA 2024-07-18
ER

PT J
AU Bhardwaj, R
AF Bhardwaj, Rupali
TI Enhanced reversible and secure patient data hiding algorithm based on
   cellular automata
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE E-healthcare; Homomorphic encryption; 2D Cellular automata (Rule 171);
   EPI; Authentication analysis; Reversible data hiding
ID SIGNALS
AB To guarantee a secure communication in E-medical platform, an enhanced reversible data hiding algorithm based on cellular automata has been presented in this paper. Highlight of proposed method is to embed electronic patient information (EPI) in base(4) numeral framework at seed and in base(2) numeral framework at non-seed pixels of a 3 x 3 sized overlapped block and simultaneously encrypted though Paillier cryptosystem respectively. EPI is embedded at central non-seed pixel using two dimensional cellular automata (2D-CA (rule 171)) depending upon the parity (Odd or Even) of least significant bits of non-seed pixels of a 3 x 3 sized block. To prove the effectiveness of proposed method, experimental study has been carried out using MATLAB R2017a platform for different 256 x 256 sized test images obtained from open-source image database (USC-SIPI) whereas medical images obtained from the database of The Cancer Imaging Archive (TCIA) respectively. Maximum average embedding rate (2.24 bpp) is achieved by proposed method and precisely recover EPI with a PSNR value of infinity dB between the cover image and reconstructed image respectively. The average embedding rate is 2.24 bpp for all test images which demonstrates that the proposed method is capable for embedding high payload in comparison of other methods respectively.
C1 [Bhardwaj, Rupali] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Bhardwaj, R (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
EM rupali.bhardwaj@thapar.edu
CR Bhalerao S, 2019, PATTERN RECOGN LETT, V125, P463, DOI 10.1016/j.patrec.2019.06.004
   Bhardwaj R, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102276
   Bhardwaj R, 2021, J AMB INTEL HUM COMP, V12, P2915, DOI 10.1007/s12652-020-02449-2
   Bhardwaj R, 2020, PATTERN RECOGN LETT, V139, P60, DOI 10.1016/j.patrec.2018.01.014
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Chi LP, 2018, MULTIMED TOOLS APPL, V77, P8785, DOI 10.1007/s11042-017-4774-y
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Kim YS., 2015, Applied Mathematics Information Sciences, V9, P2627, DOI [10.12988/ams.2015.52103, DOI 10.12988/AMS.2015.52103]
   Lee CF, 2013, TELECOMMUN SYST, V52, P2237, DOI 10.1007/s11235-011-9529-x
   Lu TC, 2017, MULTIMED TOOLS APPL, V76, P23903, DOI 10.1007/s11042-016-4135-2
   Lu TC, 2015, SIGNAL PROCESS, V115, P195, DOI 10.1016/j.sigpro.2015.03.017
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Mansour RF, 2019, MULTIDIM SYST SIGN P, V30, P791, DOI 10.1007/s11045-018-0575-3
   Mariano, 2008, AUTOMATA 2008 THEORY
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Shi YQ, 2005, LECT NOTES COMPUT SC, V3304, P1
   Shiu HJ, 2017, COMPUT METH PROG BIO, V151, P159, DOI 10.1016/j.cmpb.2017.08.015
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wu XT, 2016, J VIS COMMUN IMAGE R, V41, P58, DOI 10.1016/j.jvcir.2016.09.005
   Yao H, 2017, SIGNAL PROCESS, V135, P26, DOI 10.1016/j.sigpro.2016.12.029
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 22
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 44363
EP 44381
DI 10.1007/s11042-022-12501-2
EA JUN 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000805063200008
DA 2024-07-18
ER

PT J
AU Yang, L
   Guo, YQ
   Sang, J
   Wu, WQ
   Wu, ZY
   Liu, Q
   Xia, XF
AF Yang, Li
   Guo, Yanqun
   Sang, Jun
   Wu, Weiqun
   Wu, Zhongyuan
   Liu, Qi
   Xia, Xiaofeng
TI A crowd counting method via density map and counting residual estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowd counting; Density map; Counting residual; Estimation
AB Recently, state-of-the-art crowd counting methods have focused more on predicting a density map and then obtaining the final aggregated count. In 2018, a typical density map-based network for congested scene recognition called CSRNet was proposed, and it achieved better crowd counting performance than previous methods with a simple architecture. It utilizes the first 10 layers from VGG-16 as the front end and deploys dilated convolutional layers as the back-end to generate high-quality density maps. CSRNet has been demonstrated on four datasets (ShanghaiTech dataset, the UCF_CC_50 dataset, the World Expo'10 dataset, and the UCSD dataset) and delivered great performance. To obtain better performance, in this paper, we propose a small network as a new component that generates a counting residual estimation, and we combine our component with CSRNet. We demonstrate this combined network on three datasets (ShanghaiTech dataset, the UCF_CC_50 dataset, and the World Expo'10 dataset) and compare the results with those of CSRNet. The results show that our method has significantly improved the results of CSRNet. Through a series of experiments, such as ablation experiments and control experiments, we demonstrate the effectiveness of our method. In the future, we will apply our method to other networks to achieve better results.
C1 [Yang, Li; Sang, Jun; Wu, Weiqun; Wu, Zhongyuan; Liu, Qi; Xia, Xiaofeng] Chongqing Univ, Key Lab Dependable Serv Comp Cyber Phys Soc, Minist Educ, Chongqing 400044, Peoples R China.
   [Yang, Li; Sang, Jun; Wu, Weiqun; Wu, Zhongyuan; Liu, Qi; Xia, Xiaofeng] Chongqing Univ, Sch Big Data & Software Engn, Chongqing 401331, Peoples R China.
   [Guo, Yanqun] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Peoples R China.
   [Guo, Yanqun] Southwest Inst Elect Equipment, Chengdu 610036, Peoples R China.
C3 Chongqing University; Chongqing University; Southwest Jiaotong
   University
RP Sang, J (corresponding author), Chongqing Univ, Key Lab Dependable Serv Comp Cyber Phys Soc, Minist Educ, Chongqing 400044, Peoples R China.; Sang, J (corresponding author), Chongqing Univ, Sch Big Data & Software Engn, Chongqing 401331, Peoples R China.
EM jsang@cqu.edu.cn
OI Sang, Jun/0000-0002-8703-7310
FU National Natural Science Foundation of China [61971073]
FX This work was supported by National Natural Science Foundation of China
   (No. 61971073).
CR [Anonymous], 2014, ARXIV14097618
   Bai S, 2020, PROC CVPR IEEE, P4593, DOI 10.1109/CVPR42600.2020.00465
   Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45
   Chan AB, 2009, IEEE I CONF COMP VIS, P545, DOI 10.1109/ICCV.2009.5459191
   Chen K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.21
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   de Sá CCA, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P95, DOI 10.1145/2911451.2911540
   Diwakar M, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101754
   Diwakar M, 2018, BIOMED SIGNAL PROCES, V42, P73, DOI 10.1016/j.bspc.2018.01.010
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Idrees H, 2018, LECT NOTES COMPUT SC, V11206, P544, DOI 10.1007/978-3-030-01216-8_33
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Kumar M, 2019, J KING SAUD UNIV-COM, V31, P113, DOI 10.1016/j.jksuci.2016.12.002
   Leibe B, 2005, PROC CVPR IEEE, P878
   Lempitsky V., 2010, Advances in Neural Information Processing Systems, V23
   Li M, 2008, INT C PATT RECOG, P1998
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Liu J, 2018, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2018.00545
   Liu LB, 2019, IEEE I CONF COMP VIS, P1774, DOI 10.1109/ICCV.2019.00186
   Liu N, 2019, PROC CVPR IEEE, P3220, DOI 10.1109/CVPR.2019.00334
   Liu WZ, 2019, PROC CVPR IEEE, P5094, DOI 10.1109/CVPR.2019.00524
   Luo WH, 2020, IEEE T PATTERN ANAL, V42, P1317, DOI 10.1109/TPAMI.2019.2899570
   Mohan A, 2011, YLRC 10 P 2010 INT C, P7789
   Ryan D, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P81, DOI 10.1109/DICTA.2009.22
   Sang J, 2019, IEEE ACCESS, V7, P24411, DOI 10.1109/ACCESS.2019.2899939
   Sindagi VA, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Sindagi VA, 2017, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2017.206
   Sindagi VA, 2018, PATTERN RECOGN LETT, V107, P3, DOI 10.1016/j.patrec.2017.07.007
   Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75
   Pham VQ, 2015, IEEE I CONF COMP VIS, P3253, DOI 10.1109/ICCV.2015.372
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wan J, 2019, IEEE I CONF COMP VIS, P1130, DOI 10.1109/ICCV.2019.00122
   Wan J, 2019, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2019.00416
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Yan ZY, 2019, IEEE I CONF COMP VIS, P952, DOI 10.1109/ICCV.2019.00104
   Yu F., 2015, ARXIV
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
NR 42
TC 0
Z9 0
U1 4
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43503
EP 43512
DI 10.1007/s11042-022-13220-4
EA MAY 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000800967900002
DA 2024-07-18
ER

PT J
AU Matheen, MA
   Sundar, S
AF Matheen, M. A.
   Sundar, S.
TI Histogram and entropy oriented image coding for clustered wireless
   multimedia sensor networks (WMSNS)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless multimedia sensor networks; Histograms; Cluster heads (CH);
   Entropy; Clustering; Distortion; PSNR; SSIM; Energy consumption
ID COMPRESSION SCHEME; INFORMATION; ALGORITHM
AB Recently, the advent of Wireless Multimedia Sensor Networks (WMSNs) has given birth to different applications. Some of the applications those required the deployment of low cost multimedia sensors include traffic monitoring, visual surveillance, habitat monitoring, environment monitoring etc. Unlike the traditional Wireless Sensor Networks (WSNs) which aims at the maximization of network lifetime, the main objective of WMSNs is an optimized multimedia data delivery along with the minimization of energy consumption. The major aspect in the WMSNs is the removal of redundant data before its transmission to sink. Even though several standard image compression techniques (ex. JPEG and MPEG) are there in the existence, they are not suitable for resource constrained WMSNs. To solve these problems, in this paper, we propose a new and simple image coding and transmission method. In this method, the histogram based representation is employed to encode the image while entropy based assessment is employed for data redundancy. Initially the network is clustered into several clusters and the nodes with rich resources are chosen as Cluster Heads (CH). After receiving the image data from sensor nodes, the CH performs joint entropy evaluation and discovers the uncorrelated data and then forwards to sink. Furthermore, the CH also determines the uncorrelated camera sensor nodes and allows only those nodes to report. An extensive simulation experiments are conducted over the developed approach and the performance is measured through several performance metrics like Energy Consumption, Peak Signal to Noise Ratio (PSNR), Structural Similarity Index Measure (SSIM).
C1 [Matheen, M. A.; Sundar, S.] Vellore Inst Technol, Sch Elect Engn, Vellore 632014, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Matheen, MA (corresponding author), Vellore Inst Technol, Sch Elect Engn, Vellore 632014, Tamil Nadu, India.
EM matheen.ma2018@vitstudent.ac.in
RI Abdul Matheen, Mohammed/H-3135-2018
OI Abdul Matheen, Mohammed/0000-0002-2141-3942
CR Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   Alaybeyoglu A, 2015, AD HOC SENS WIREL NE, V26, P287
   Almalkawi IT, 2010, SENSORS-BASEL, V10, P6662, DOI 10.3390/s100706662
   Banerjee R, 2019, WIREL NETW, V25, P167, DOI 10.1007/s11276-017-1543-9
   Bovik A, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, pV, DOI 10.1016/B978-012119792-6/50062-0
   Brante G, 2013, IEEE SENS J, V13, P4375, DOI 10.1109/JSEN.2013.2269798
   Chen YL, 2017, PATTERN RECOGN, V67, P139, DOI 10.1016/j.patcog.2017.02.013
   Chowdhury M. M. H., 2012, Int J Comput Sci Issues, V9, P327
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Cover T., 1991, Wiley Series in Telecommunications, DOI [10.1002/0471200611, DOI 10.1002/0471200611]
   Dai R, 2009, IEEE T MULTIMEDIA, V11, P1148, DOI 10.1109/TMM.2009.2026100
   Deligiannis N, 2012, IEEE T IMAGE PROCESS, V21, P1934, DOI 10.1109/TIP.2011.2181400
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Han Chong, 2012, Journal of Southeast University (Natural Science Edition), V42, P814, DOI 10.3969/j.issn.1001-0505.2012.05.004
   Heng S, 2017, WIREL COMMUN MOB COM, DOI 10.1155/2017/5471721
   Jiang Peng, 2012, Chinese Journal of Sensors and Actuators, V25, P815, DOI 10.3969/j.issn.1004-1699.2012.06.019
   Kong SK, 2017, INFORMATION, V8, DOI 10.3390/info8010026
   Li H, 2020, IEEE ACCESS, V8, P86024, DOI 10.1109/ACCESS.2020.2992795
   Liang YQ, 2020, INTEGR COMPUT-AID E, V27, P417, DOI 10.3233/ICA-200641
   Liang YQ, 2019, ADV ENG INFORM, V42, DOI 10.1016/j.aei.2019.100963
   Ma N, 2019, EURASIP J WIREL COMM, V2019, DOI 10.1186/s13638-019-1571-5
   Ma T, 2013, IEEE COMMUN SURV TUT, V15, P963, DOI 10.1109/SURV.2012.060912.00149
   Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867
   Puri R, 2007, IEEE T IMAGE PROCESS, V16, P2436, DOI 10.1109/TIP.2007.904949
   Radha HM, 2001, IEEE T MULTIMEDIA, V3, P53, DOI 10.1109/6046.966110
   Rehman YAU, 2016, IEEE SENS J, V16, P5942, DOI 10.1109/JSEN.2016.2574989
   Senturk A, 2016, TEH VJESN, V23, P1863, DOI 10.17559/TV-20150313101530
   Skorupa J, 2012, IEEE T CIRC SYST VID, V22, P530, DOI 10.1109/TCSVT.2011.2168289
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Wang P, 2011, IEEE T MULTIMEDIA, V13, P388, DOI 10.1109/TMM.2010.2100374
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu C-M, 2016, J INF HIDING MULTIME, V7
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Xiong ZX, 2004, IEEE SIGNAL PROC MAG, V21, P80, DOI 10.1109/MSP.2004.1328091
   Xiong ZY, INT C INF SCI TECHN
   Yang H, 2018, MULTIMED TOOLS APPL, V77, P4453, DOI 10.1007/s11042-016-4245-x
   ZainEldin H, 2015, AIN SHAMS ENG J, V6, P481, DOI 10.1016/j.asej.2014.11.001
   Zhou Wei, 2016, Journal of China Universities of Posts and Telecommunications, V23, P22, DOI 10.1016/S1005-8885(16)60004-3
   Zhu XQ, 2009, SENSORS-BASEL, V9, P4901, DOI 10.3390/s90604901
NR 40
TC 2
Z9 2
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 38253
EP 38276
DI 10.1007/s11042-022-13060-2
EA APR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000785933700005
DA 2024-07-18
ER

PT J
AU Haq, IU
   Du, XJ
   Jan, H
AF Haq, Izaz Ul
   Du, Xianjun
   Jan, Haseeb
TI Implementation of smart social distancing for COVID-19 based on deep
   learning algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Covid-19; Pandemic; Social distancing; Audio signal
AB The first step to reducing the effect of viral disease is to prevent the spread which could be achieved by implementing social distancing (reducing the number of close physical interactions between peoples). Almost every viral disease whose means of communication is air, and enters through mouth or nose, definitely will affect our vocal organs which cause changes in features of our voice and could be traceable using feature analysis of voice using deep learning. The detection of an affected person using deep neural networks and tracking him would help us in the implementation of the social distancing rule in an area where it is needed. The aim of this paper is to study different solutions which help in enabling, encouraging, and even enforcing social distancing. In this paper, we implemented and analyzed scenarios on the basis of COVID-19 patient detection using cough and tracking him using smart cameras, or emerging wireless technologies with deep learning techniques for prediction and preventing the spread of disease. Thus these techniques are easy to be implemented in the initial stage of any pandemic as well and will help us in the implementation of smart social distancing (apply whenever needed).
C1 [Haq, Izaz Ul; Du, Xianjun] Lanzhou Univ Technol, Coll Elect & Informat Engn, Lanzhou 730050, Peoples R China.
   [Jan, Haseeb] Univ Engn & Technol, Peshawar, Pakistan.
C3 Lanzhou University of Technology; University of Engineering & Technology
   Peshawar
RP Du, XJ (corresponding author), Lanzhou Univ Technol, Coll Elect & Informat Engn, Lanzhou 730050, Peoples R China.
EM izaz.lut@gmail.com; xdu@lut.edu.cn; engrhaseebjan@gmail.com
RI Du, Xianjun/HZK-5314-2023
FU National Natural Science Foundation of China [61563032]
FX This work was supported by the National Natural Science Foundation of
   China grant number 61563032.
CR Ahmed I, 2021, SUSTAIN CITIES SOC, V69, DOI 10.1016/j.scs.2021.102777
   Akkaya I., 2019, Solving rubik's cube with a robot hand
   Alkhateeb A, 2018, IEEE ACCESS, V6, P37328, DOI 10.1109/ACCESS.2018.2850226
   [Anonymous], 2018, DCASE
   Ardakani AA, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103795
   Bagad P., 2020, ARXIV PREPRINT ARXIV
   Bakator Mihalj, 2018, Multimodal Technologies and Interaction, V2, DOI 10.3390/mti2030047
   Bassi Pedro R. A. S., 2022, Research on Biomedical Engineering, V38, P139, DOI 10.1007/s42600-021-00132-9
   Blake, 2020, YEAR REV IMP COV 19
   Brunese L, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105608
   Bu JQ, 2021, TALANTA, V225, DOI 10.1016/j.talanta.2020.121977
   Candamo J, 2010, IEEE T INTELL TRANSP, V11, P206, DOI 10.1109/TITS.2009.2030963
   Challita U, 2019, IEEE WIREL COMMUN, V26, P28, DOI 10.1109/MWC.2018.1800155
   Chaudhari G., 2020, Virufy: Global Applicability of Crowdsourced and Clinical Datasets for AI Detection of COVID-19 from Cough Audio Samples
   Chen CH, 2017, PROC CVPR IEEE, P5759, DOI 10.1109/CVPR.2017.610
   Cho SB, 2016, NEUROCOMPUTING, V176, P98, DOI 10.1016/j.neucom.2015.02.079
   Coppock H, 2021, LANCET DIGIT HEALTH, V3, pE537, DOI 10.1016/S2589-7500(21)00141-2
   Di Domenico L, 2020, BMC MED, V18, DOI 10.1186/s12916-020-01698-4
   Elloumi W, 2016, IEEE SENS J, V16, P5376, DOI 10.1109/JSEN.2016.2565899
   Fernandes N., 2020, IESE Business School, DOI [10.2139/ssrn.3557504, DOI 10.2139/SSRN.3557504]
   Ghaderzadeh M, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/6677314
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gozes O., 2020, RAPID AI DEV CYCLE C
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Imran Ali, 2020, Inform Med Unlocked, V20, P100378, DOI 10.1016/j.imu.2020.100378
   Irfan U, 2020, VOX
   Jia YT, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2816824
   Johnson Jr J, 2020, SOCIAL DISTANCINGMON
   Kiefer P, 2018, 14 INT C LOC BAS SER, DOI 10.3929/ethz-b-000224043
   김규영, 2012, [The Journal of The Korea Institute of Electronic Communication Sciences, 한국전자통신학회 논문지], V7, P1293
   Ko H, 2020, J MED INTERNET RES, V22, DOI 10.2196/19569
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lempinen E., 2021, Berkeley News
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu MT, 2021, INT J CONTEMP HOSP M, V33, P1249, DOI 10.1108/IJCHM-07-2020-0678
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu XX, 2021, APPL INTELL, V51, P4162, DOI 10.1007/s10489-020-01938-3
   Loey M, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12040651
   Mangal A, 2020, 200409803 ARXIV
   Martinez F., 2020, Int. J. Adv. Sci. Eng. Inf. Technol., V10, P662
   Niimi-Burch S, 2020, INCOME BASED POLICY
   Pahar M, 2021, MACHINE LEARNING BAS, DOI 10.1016/j.compbiomed.2021.105153
   Pahar M, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104572
   Park Jisu, 2020, [The Journal of The Institute of Internet, Broadcasting and Communication, 한국인터넷방송통신학회 논문지], V20, P89, DOI 10.7236/JIIBC.2020.20.3.89
   Poulose A, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235084
   Rahimzadeh Mohammad, 2020, Inform Med Unlocked, V19, P100360, DOI 10.1016/j.imu.2020.100360
   Rathgeb C, 2020, ARXIV PREPRINT ARXIV
   Redmon J., 2018, COMPUTER VISION PATT
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shao N., 2020, REPROD NUMBER R0 COV, DOI [10.1101/2020.02.17.20023747, DOI 10.1101/2020.02.17.20023747]
   Sharma N., 2020, COSWARA DATABASE BRE
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Sina I, 2013, INT C ADV COMP SCI I, P149, DOI 10.1109/ICACSIS.2013.6761567
   Sun TR, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR 2020), P290, DOI [10.1109/A1VR50618.2020.00058, 10.1109/AIVR50618.2020.00058]
   Sun Y., 2015, ARXIV150200873
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Szeliski R, 2011, TEXTS COMPUT SCI, P1
   Togaçar M, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103805
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Ucar F, 2020, MED HYPOTHESES, V140, DOI 10.1016/j.mehy.2020.109761
   Vaid S, 2020, INT ORTHOP, V44, P1539, DOI 10.1007/s00264-020-04609-7
   Washington P, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451701
   Wong MH, 2017, LECT NOTES ARTIF INT, V10604, P582, DOI 10.1007/978-3-319-69179-4_41
   Xu Y, 2021, MEASUREMENT, V169, DOI 10.1016/j.measurement.2020.108502
   Yao H, 2019, WIRELESS NETW-GER, P1, DOI 10.1007/978-3-030-15028-0
NR 65
TC 5
Z9 5
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33569
EP 33589
DI 10.1007/s11042-022-13154-x
EA APR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784951200003
PM 35463218
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Bagade, JV
   Singh, K
   Dandawate, YH
AF Bagade, Jayashri, V
   Singh, Kulbir
   Dandawate, Yogesh H.
TI No reference image quality assessment with shape adaptive discrete
   wavelet features using neuro-wavelet model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image quality assessment; No-reference image quality assessment; Shape
   adaptive wavelet; Neuro-wavelet model
ID NATURAL SCENE STATISTICS; STRENGTH
AB No reference method for image quality assessment using shape adaptive wavelet features by applying neuro-wavelet model is proposed in this paper. Images usually consist of visual objects. Degradation of an image ultimately causes distortions to the objects present in the image. Distortions can change the shape of these objects. Quality assessment of an image cannot be said to be complete without assessing the quality of individual objects present in the image. Therefore, deviation in shape has to be quantified along with the quality assessment of an image. Shape Adaptive Discrete Wavelet Transform offers a solution to shape identification problem. The variations in magnitude of feature values are found not proportional to the amount of degradation due to the presence of other artifacts. Wavelet decomposition is applied to capture the small variations observed in extracted features. Separate back propagation neural network models are trained for quality assessment of all kind of images ranging from pristine to bad. Results show improvement in accuracy independent of image databases. It has been observed that the predicted score correlates well with the mean opinion score with 90% accuracy for LIVE dataset, 93% and 95% for TID2008 and TID2013 respectively.
C1 [Bagade, Jayashri, V] Vishwakarma Inst Informat Technol, Dept Informat Technol, Pune, Maharashtra, India.
   [Singh, Kulbir] Thapar Inst Engn & Technol, Dept Elect & Telecommun, Patiala, Punjab, India.
   [Dandawate, Yogesh H.] Vishwakarma Inst Informat Technol, Dept Elect & Telecommun, Pune, Maharashtra, India.
C3 Thapar Institute of Engineering & Technology
RP Bagade, JV (corresponding author), Vishwakarma Inst Informat Technol, Dept Informat Technol, Pune, Maharashtra, India.
EM jayashrihedaoo@rediffmail.com; ksingh@thapar.edu; yhdandawate@gmail.com
CR [Anonymous], 2013, International Scholarly Research Notices., DOI DOI 10.1155/2013/905685
   [Anonymous], 2009, 4 INT WORKSH VID PRO
   Avcibas I, 2002, J ELECTRON IMAGING, V11, P206, DOI 10.1117/1.1455011
   Bagade J, 2011, 4 INT C COMM COMP IN, P128
   Bagade JV, 2020, MULTIMED TOOLS APPL, V79, P2109, DOI 10.1007/s11042-019-08217-5
   Bagade JV, 2014, INT J COMMUN NETW DI, V12, P95, DOI 10.1504/IJCNDS.2014.057990
   Bianco S, 2018, SIGNAL IMAGE VIDEO P, V12, P355, DOI 10.1007/s11760-017-1166-8
   Bosse S, 2016, IEEE IMAGE PROC, P3773, DOI 10.1109/ICIP.2016.7533065
   Cagnazzo M, 2004, IEEE IMAGE PROC, P2459
   Campos RG, 2019, 14 WORKSH COMP VIS P
   Chen MJ, 2009, INT WORK QUAL MULTIM, P70, DOI 10.1109/QOMEX.2009.5246973
   Chen X, 2019, EURASIP J ADV SIG PR, DOI 10.1186/s13634-019-0602-z
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Fang YM, 2015, IEEE SIGNAL PROC LET, V22, P838, DOI 10.1109/LSP.2014.2372333
   Gadre V., 2017, MULTIRESOLUTION MULT
   Gastaldo P, 2005, SIGNAL PROCESS-IMAGE, V20, P643, DOI 10.1016/j.image.2005.03.013
   Kang L, 2014, PROC CVPR IEEE, P1733, DOI 10.1109/CVPR.2014.224
   Lee S, 2012, SIGNAL PROCESS-IMAGE, V27, P31, DOI 10.1016/j.image.2011.08.002
   Li LD, 2016, KSII T INTERNET INF, V10, P288, DOI 10.3837/tiis.2016.01.017
   Li SP, 2000, IEEE T CIRC SYST VID, V10, P725, DOI 10.1109/76.856450
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P494, DOI 10.1016/j.image.2014.02.004
   Liu XL, 2017, IEEE I CONF COMP VIS, P1040, DOI 10.1109/ICCV.2017.118
   Lu W, 2010, NEUROCOMPUTING, V73, P784, DOI 10.1016/j.neucom.2009.10.012
   Mallat S, 2009, WAVELET TOUR OF SIGNAL PROCESSING: THE SPARSE WAY, P1
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Ponomarenko Nikolay, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P106
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Saad MA, 2010, IEEE SIGNAL PROC LET, V17, P583, DOI 10.1109/LSP.2010.2045550
   Shahid M, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-40
   Sheikh H.R., Live Image Quality Assessment Database
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P1918, DOI 10.1109/TIP.2005.854492
   Suresh S, 2009, APPL SOFT COMPUT, V9, P541, DOI 10.1016/j.asoc.2008.07.005
   Suthaharan S, 2009, SIGNAL PROCESS, V89, P1647, DOI 10.1016/j.sigpro.2009.02.007
   Varga D, 2021, J IMAGING, V7, DOI 10.3390/jimaging7020029
   Wang GJ, 2016, OPTOELECTRON LETT, V12, P152, DOI 10.1007/s11801-016-5276-2
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z., 2006, Modern Image Quality Assessment, DOI 10.2200/S00010ED1V01Y200508IVM003
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Zhai GT, 2008, SIGNAL PROCESS-IMAGE, V23, P417, DOI 10.1016/j.image.2008.04.007
   Zhang XD, 2013, IEEE SIGNAL PROC LET, V20, P319, DOI 10.1109/LSP.2013.2244081
   Zhang Y, 2014, SIGNAL PROCESS-IMAGE, V29, P725, DOI 10.1016/j.image.2014.05.004
   Zhou LY, 2014, OPTIK, V125, P5677, DOI 10.1016/j.ijleo.2014.07.010
NR 47
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 31145
EP 31160
DI 10.1007/s11042-022-12983-0
EA APR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000781336500012
DA 2024-07-18
ER

PT J
AU Mendoza, O
   Martínez, F
   Olmos, J
AF Mendoza, Oscar
   Martinez, Fabio
   Olmos, Juan
TI A local volumetric covariance descriptor for markerless Parkinsonian
   gait pattern quantification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Parkinson's disease; Convolutional features; Dense Trajectories;
   Volumetric covariance
ID ACTION RECOGNITION; DISEASE; PEOPLE
AB Gait is one of the most important biomarkers for Parkinson's disease (PD). Nonetheless, current clinical diagnosis to quantify locomotion patterns uses coarse approximations, from a set of reduced marker-based trajectories. This approximation, among others, results restrictive, invasive, alters natural gait gestures, and leaves out relevant PD patterns. This paper introduces a new computational approach to quantify, classify and explain Parkinson gait patterns using a markerless video strategy. The core of the work is a local volumetric covariance to codify motion patterns during locomotion. Such covariance codifies convolutional pre-trained features tracked along a set of dense trajectories which represent subject's gait. Covariance pattern computation involves an integral strategy to remain efficient in terms of computational cost. The proposed method was evaluated on 176 gait video sequences of a total of 22 patients among control and diagnosed with PD. The proposed approach achieved a remarkable average accuracy of 96.59% (+/- 0.13) with a sensitivity of 98.86%, specificity of 94.31%, and precision of 94.56%. These results suggest that the proposed approach may support clinical PD diagnosis and analysis using ordinary videos.
C1 [Mendoza, Oscar; Martinez, Fabio; Olmos, Juan] Univ Ind Santander UIS, Biomed Imaging Vis & Learning Lab BIVL2ab, Bucaramanga, Colombia.
C3 Universidad Industrial de Santander
RP Martínez, F (corresponding author), Univ Ind Santander UIS, Biomed Imaging Vis & Learning Lab BIVL2ab, Bucaramanga, Colombia.
EM famarcar@saber.uis.edu.co; juan2218060@correo.uis.edu.co
FU Vicerrectoria de Investigacion y Extension of Universidad Industrial de
   Santander [2697]
FX This work was partially funded by the Vicerrectoria de Investigacion y
   Extension of Universidad Industrial de Santander with the project:
   Cuantificacion de patrones locomotores para el diagnostico y seguimiento
   remoto en zonas de dificil acceso, with SIVIE code 2697.
CR Abdulhay E, 2018, FUTURE GENER COMP SY, V83, P366, DOI 10.1016/j.future.2018.02.009
   Belic M, 2019, CLIN NEUROL NEUROSUR, V184, DOI 10.1016/j.clineuro.2019.105442
   Bovonsunthonchai S, 2014, PHYSIOTHER RES INT, V19, P158, DOI 10.1002/pri.1579
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Caramia C, 2018, IEEE J BIOMED HEALTH, V22, P1765, DOI 10.1109/JBHI.2018.2865218
   Ceseracciu E, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0087640
   Cole MH, 2017, NEUROREHAB NEURAL RE, V31, P34, DOI 10.1177/1545968316656057
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dorsey ER, 2018, JAMA NEUROL, V75, P9, DOI 10.1001/jamaneurol.2017.3299
   Duncan RP, 2015, GAIT POSTURE, V42, P306, DOI 10.1016/j.gaitpost.2015.06.007
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Guayacan L.C., 2021, VISUALISING QUANTIFY, V123
   Halliday SE, 1998, GAIT POSTURE, V8, P8, DOI 10.1016/S0966-6362(98)00020-4
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Hussein, 2013, INT JOINT C ART INT
   Larrazabal AJ, 2019, COMPUT BIOL MED, V108, P57, DOI 10.1016/j.compbiomed.2019.03.025
   Latt MD, 2009, J GERONTOL A-BIOL, V64, P700, DOI 10.1093/gerona/glp009
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Ma BP, 2014, IMAGE VISION COMPUT, V32, P379, DOI 10.1016/j.imavis.2014.04.002
   Matikainen Pyry, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P514, DOI 10.1109/ICCVW.2009.5457659
   Messing R, 2009, IEEE I CONF COMP VIS, P104, DOI 10.1109/ICCV.2009.5459154
   Minh H.Q., 2017, SYNTH LECT COMPUT VI, V7, P1
   Minh HQ., 2017, COVARIANCES COMPUTER
   Naghavi N, 2019, IEEE T NEUR SYS REH, V27, P947, DOI 10.1109/TNSRE.2019.2910165
   Pistacchi M, 2017, FUNCT NEUROL, V32, P28, DOI 10.11138/FNeur/2017.32.1.028
   Poewe W, 2017, NAT REV DIS PRIMERS, V3, DOI 10.1038/nrdp.2017.13
   Rizzo G, 2016, NEUROLOGY, V86, P566, DOI 10.1212/WNL.0000000000002350
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sun J, 2009, PROC CVPR IEEE, P2004, DOI 10.1109/CVPRW.2009.5206721
   Sutherland DH, 2002, GAIT POSTURE, V16, P159, DOI 10.1016/S0966-6362(02)00004-8
   Thenganatt MA, 2014, TREMOR OTHER HYPERK, V4, DOI 10.7916/D8FJ2F0Q
   Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589
   Ullah A, 2018, IEEE ACCESS, V6, P1155, DOI 10.1109/ACCESS.2017.2778011
   Varol G, 2018, IEEE T PATTERN ANAL, V40, P1510, DOI 10.1109/TPAMI.2017.2712608
   Verlekar T. T., 2018, AUTOMATIC CLASSIFICA
   Verlekar TT, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092743
   Vos T, 2015, LANCET, V386, P743, DOI 10.1016/S0140-6736(15)60692-4
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
NR 39
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30733
EP 30748
DI 10.1007/s11042-022-12280-w
EA APR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779233200008
DA 2024-07-18
ER

PT J
AU Santini, S
AF Santini, Simone
TI A meta-indexing method for fast probably approximately correct nearest
   neighbor searches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Indexing; Approximate nearest neighbor; Error modeling; Curse of
   dimensionality; Multimedia data base; Approximate search
ID QUERIES; ALGORITHM; FILE
AB In this paper we present an indexing method for probably approximately correct nearest neighbor queries in high dimensional spaces capable of improving the performance of any index whose performance degrades with the increased dimensionality of the query space. The basic idea of the method is quite simple: we use SVD to concentrate the variance of the inter-element distance in a lower dimensional space, Xi. We do a nearest neighbor query in this space and then we "peek" forward from the nearest neighbor by gathering all the elements whose distance from the query is less than d(Xi) (1 + zeta sigma(2)(Xi)), where d(Xi) is the distance from the nearest neighbor in Xi, sigma(2)(Xi) is the variance of the data in Xi, and zeta a parameter. All the data thus collected form a tentative set T, in which we do a scan using the complete feature space to find the point closest to the query. The advantages of the method are that (1) it can be built on top of virtually any indexing method and (2) we can build a model of the distribution of the error precise enough to allow designing a compromise between error and speed. We show the improvement that we can obtain using data from the SUN data base.
C1 [Santini, Simone] Univ Autonoma Madrid, Escuela Politecn Super, C Tomas & Valiente 11, Madrid 28049, Spain.
C3 Autonomous University of Madrid
RP Santini, S (corresponding author), Univ Autonoma Madrid, Escuela Politecn Super, C Tomas & Valiente 11, Madrid 28049, Spain.
EM simone.santini@uam.es
RI Santini, Simone/B-7219-2014
OI Santini, Simone/0000-0002-1869-5301
FU CRUE-CSIC agreement; Springer Nature
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature.
CR Aggarwal C. C., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P119, DOI 10.1145/347090.347116
   Andoni A, 2006, ANN IEEE SYMP FOUND, P459
   [Anonymous], 1994, Multidimensional Scaling
   Arandjelovic R, 2014, IEEE T PATTERN ANAL, V36, P2396, DOI 10.1109/TPAMI.2014.2339821
   Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348
   Babenko A, 2015, IEEE T PATTERN ANAL, V37, P1247, DOI 10.1109/TPAMI.2014.2361319
   Baeza-Yates R, 1998, STRING PROCESSING AND INFORMATION RETRIEVAL - PROCEEDINGS, P14, DOI 10.1109/SPIRE.1998.712978
   Baeza-Yates R., 1994, LNCS, V807/1994, P198
   BAEZAYATES R, 1997, ENCY COMPUTER SCI TE, V37, P331
   Bayer R, 1970, D1820989 MATH INF SC
   BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93605.98741
   BENTLEY JL, 1990, PROCEEDINGS OF THE SIXTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY, P187, DOI 10.1145/98524.98564
   Berchtold S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P28
   Beyer K, 1999, LECT NOTES COMPUT SC, V1540, P217
   Bozkaya T., 1997, SIGMOD Record, V26, P357, DOI 10.1145/253262.253345
   BURKHARD WA, 1973, COMMUN ACM, V16, P230, DOI 10.1145/362003.362025
   BURKHARD WA, 1983, BIT, V23, P274, DOI 10.1007/BF01934457
   Chávez E, 2001, ACM COMPUT SURV, V33, P273, DOI 10.1145/502807.502808
   Chávez E, 2001, MULTIMED TOOLS APPL, V14, P113, DOI 10.1023/A:1011343115154
   Chiueh Tzi-cker., 1994, VLDB 94, P582
   Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426
   Ciaccia P., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), P244, DOI 10.1109/ICDE.2000.839417
   Cobzas S, 2019, LECT NOTES MATH, V2241, P1, DOI 10.1007/978-3-030-16489-8_1
   Cui B, 2004, IEEE T KNOWL DATA EN, V16, P870
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Ge TZ, 2013, PROC CVPR IEEE, P2946, DOI 10.1109/CVPR.2013.379
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Gromov Misha, 1999, PROGR MATH, V152
   Guttman A., 1984, SIGMOD Record, V14, P47, DOI 10.1145/971697.602266
   Hoel EG, 1993, P 23 INT C PAR PROC, P49
   Huang Q, 2015, PROC VLDB ENDOW, V9, P1
   Iscen A, 2018, IEEE T BIG DATA, V4, P65, DOI 10.1109/TBDATA.2017.2677964
   Johnson N., 1994, Continuous Univariate Distributions
   Johnson W.B., 1984, CONTEMP MATH-SINGAP, V26, P189, DOI DOI 10.1090/CONM/026/737400
   Kamel I, 1992, CSTR2820 U MAR
   Kazukawa D, 2020, ARXIV200305105
   KE L, 2017, P 34 INT C MACH LEAR, V70, P2081
   Korn F, 2001, IEEE T KNOWL DATA EN, V13, P96, DOI 10.1109/69.908983
   KUMAR A, 1994, IEEE T KNOWL DATA EN, V6, P341, DOI 10.1109/69.277778
   Ledoux M., 2001, CONCENTRATION MEASUR, V89
   Li K, 2016, PR MACH LEARN RES, V48
   LI M, 2018, INT C DAT SYST ADV A, P37
   Liu Ting, 2004, P ADV NEURAL INFORM, V17, P825
   Malkov YA, 2020, IEEE T PATTERN ANAL, V42, P824, DOI 10.1109/TPAMI.2018.2889473
   MILMAN VD, 1986, LECT NOTES MATH, V1200, P1
   Moore A.W., 2000, UAI
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Nene SA, 1997, IEEE T PATTERN ANAL, V19, P989, DOI 10.1109/34.615448
   NIEVERGELT J, 1984, ACM T DATABASE SYST, V9, P38, DOI 10.1145/348.318586
   Omohundro S. M., 1987, Complex Systems, V1, P273
   Pestov V., 2007, Proc. of the 22-nd Int. Joint Conf. on Neural Networks (IJCNN'07), P1775
   Pestov V, 2008, NEURAL NETWORKS, V21, P204, DOI 10.1016/j.neunet.2007.12.030
   Prabhakar S, 1998, P ACM SPAA 98
   Sellis T., 1987, Proceedings of the Thirteenth International Conference on Very Large Data Bases: 1987 13th VLDB, P507
   Slaney M, 2008, IEEE SIGNAL PROC MAG, V25, P128, DOI 10.1109/MSP.2007.914237
   Sun YF, 2014, PROC VLDB ENDOW, V8, P1
   Thurstone LL, 1927, PSYCHOL REV, V34, P273, DOI 10.1037/h0070288
   TORGERSON WS, 1965, PSYCHOMETRIKA, V30, P379, DOI 10.1007/BF02289530
   UHLMANN JK, 1991, INFORM PROCESS LETT, V40, P175, DOI 10.1016/0020-0190(91)90074-R
   Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P194
   White DA, 1996, PROC INT CONF DATA, P516, DOI 10.1109/ICDE.1996.492202
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Yianilos PeterN., 1999, DIMACS Implementation Challenge, ALENEX'99
   Zhong Y, 2015, ARXIV150503090
NR 65
TC 1
Z9 1
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30465
EP 30491
DI 10.1007/s11042-022-12690-w
EA APR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000778917900007
OA hybrid
DA 2024-07-18
ER

PT J
AU Yan, XH
   Wang, GX
   Jiang, GQ
   Wang, YF
   Mi, ZT
   Fu, XP
AF Yan, Xiaohong
   Wang, Guangxin
   Jiang, Guangqi
   Wang, Yafei
   Mi, Zetian
   Fu, Xianping
TI A natural-based fusion strategy for underwater image enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Under water; Image fusion; White balance; Particle swarm optimization
ID COLOR CORRECTION; RESTORATION; CONTRAST
AB Underwater images generally are characterized by color cast and low contrast due to selective absorption and light scattering in water medium. Such degraded images reveal some limitations when used for further analysis. To overcome underwater image degradation, various enhancement techniques are developed. Especially, the fusion-based methods have made remarkable success in this filed. However, there are still some defects in the fusion of input images and weight maps, which cause their results to be unnatural. In this paper, we propose a novel and effective natural-based fusion method for underwater image enhancement that applies several image processing algorithms. First, we design an adaptive underwater image white balance method motivated by our statistical prior to mitigate the impact of color deviation of underwater scenes. We then derive two inputs that represent local detail-improved and global contrast-enhanced versions of the color corrected image. Instead of explicitly estimating weight map, like most existing algorithms, we propose a naturalness-preserving weight map estimation (NP-WME) method, which models the weight map estimation as an optimization problem. Particle swarm optimization (PSO) is used to solve it. Benefiting a proper weighting, the proposed method can achieve a trade-off between detail enhancement and contrast improvement, resulting a natural appearance of the fused image. Through this synthesis, we merge the advantages of different algorithms to obtain the output image. Experimental results show that the proposed method outperforms the several related methods based on quantitative and qualitative evaluations.
C1 [Yan, Xiaohong; Wang, Guangxin; Jiang, Guangqi; Wang, Yafei; Mi, Zetian; Fu, Xianping] Dalian Maritime Univ, Informat Sci & Technol Sch, Dalian 116026, Peoples R China.
   [Fu, Xianping] Pengcheng Lab, Shenzhen 518055, Guangdong, Peoples R China.
C3 Dalian Maritime University
RP Wang, YF; Fu, XP (corresponding author), Dalian Maritime Univ, Informat Sci & Technol Sch, Dalian 116026, Peoples R China.; Fu, XP (corresponding author), Pengcheng Lab, Shenzhen 518055, Guangdong, Peoples R China.
EM wangyafei@dlmu.edu.cn; fxp@dlmu.edu.cn
RI yi, zhang/KGL-4990-2024; yan, xiao/JVP-0766-2024
FU National Natural Science Foundation of China [62176037, 62002043,
   61802043]; Liaoning Revitalization Talents Program [XLYC1908007];
   Foundation of Liaoning Key Research and Development Program [201801728];
   Dalian Science and Technology Innovation Fund [2018J12GX037,
   2019J11CY001, 2021JJ12GX028]
FX The authors sincerely thank the editors and anonymous reviewers for the
   very helpful and kind comments to assist in improving the presentation
   of our paper. This work was supported in part by the National Natural
   Science Foundation of China under Grant 62176037, Grant 62002043, and
   Grant 61802043, by the Liaoning Revitalization Talents Program under
   Grant XLYC1908007, by the Foundation of Liaoning Key Research and
   Development Program under Grant 201801728, by the Dalian Science and
   Technology Innovation Fund under Grant 2018J12GX037, Grant 2019J11CY001,
   and Grant 2021JJ12GX028.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Adnan RM, 2021, NEURAL COMPUT APPL, V33, P2853, DOI 10.1007/s00521-020-05164-3
   Akkaynak D, 2018, PROC CVPR IEEE, P6723, DOI 10.1109/CVPR.2018.00703
   Ancuti C., 2012, PROC CVPR IEEE, P81, DOI DOI 10.1109/CVPR.2012.6247661
   Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Avidan S, 2017, BRIT MACH VIS C BMVC
   Azmi KZM, 2019, APPL SOFT COMPUT, V85, DOI 10.1016/j.asoc.2019.105810
   Bai LF, 2020, IEEE ACCESS, V8, P128973, DOI 10.1109/ACCESS.2020.3009161
   Barros W, 2018, J VIS COMMUN IMAGE R, V55, P363, DOI 10.1016/j.jvcir.2018.06.018
   Boom BJ, 2014, ECOL INFORM, V23, P83, DOI 10.1016/j.ecoinf.2013.10.006
   Bratton D, 2007, 2007 IEEE SWARM INTELLIGENCE SYMPOSIUM, P120, DOI 10.1109/SIS.2007.368035
   BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7
   Chambah M, 2004, P SPIE INT SOC OPTIC
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Codruta AO, 2020, IEEE T IMAGE PROCESS, V29, P2653, DOI 10.1109/TIP.2019.2951304
   Crete F, 2007, PROC SPIE, V6492, DOI 10.1117/12.702790
   Drews P, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P825, DOI 10.1109/ICCVW.2013.113
   Drews PLJ, 2016, IEEE COMPUT GRAPH, V36, P24, DOI 10.1109/MCG.2016.26
   Fabbri C, 2018, IEEE INT CONF ROBOT, P7159
   Finlayson GD, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P37
   Fu XY, 2017, I S INTELL SIG PROC, P789, DOI 10.1109/ISPACS.2017.8266583
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Guo F, 2017, CCF CHIN C COMP VIS
   Guo YC, 2020, IEEE J OCEANIC ENG, V45, P862, DOI 10.1109/JOE.2019.2911447
   Hassan N, 2021, MULTIMED TOOLS APPL, V80, P1839, DOI 10.1007/s11042-020-09752-2
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hou GJ, 2020, J VIS COMMUN IMAGE R, V66, DOI 10.1016/j.jvcir.2019.102732
   Hou GJ, 2019, NEUROCOMPUTING, V369, P106, DOI 10.1016/j.neucom.2019.08.041
   Iqbal Kashif, 2007, IAENG International Journal of Computer Science, V34, P239
   Islam MJ, 2020, IEEE ROBOT AUTOM LET, V5, P3227, DOI 10.1109/LRA.2020.2974710
   Jian MW, 2018, J VIS COMMUN IMAGE R, V53, P31, DOI 10.1016/j.jvcir.2018.03.008
   Kopf J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409069
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li CY, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107038
   Li CY, 2018, IEEE SIGNAL PROC LET, V25, P323, DOI 10.1109/LSP.2018.2792050
   Liu RS, 2020, IEEE T CIRC SYST VID, V30, P4861, DOI 10.1109/TCSVT.2019.2963772
   Marques TP, 2020, IEEE COMPUT SOC CONF, P2286, DOI 10.1109/CVPRW50498.2020.00277
   Mi ZT, 2020, IEEE ACCESS, V8, P112957, DOI 10.1109/ACCESS.2020.3002883
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Panetta K, 2016, IEEE J OCEANIC ENG, V41, P541, DOI 10.1109/JOE.2015.2469915
   Peng YT, 2018, IEEE T IMAGE PROCESS, V27, P2856, DOI 10.1109/TIP.2018.2813092
   Peng YT, 2017, IEEE T IMAGE PROCESS, V26, P1579, DOI 10.1109/TIP.2017.2663846
   Roznere M, 2019, IEEE INT C INT ROBOT, P7191, DOI [10.1109/iros40897.2019.8967557, 10.1109/IROS40897.2019.8967557]
   Schechner YY, 2007, IEEE T PATTERN ANAL, V29, P1655, DOI 10.1109/TPAMI.2007.1141
   Sethi R, 2019, MULTIMED TOOLS APPL, V78, P31823, DOI 10.1007/s11042-019-07938-x
   Sharma G, 2005, COLOR RES APPL, V30, P21, DOI 10.1002/col.20070
   Shi Y., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), P1945, DOI 10.1109/CEC.1999.785511
   Shi YH, 1998, IEEE C EVOL COMPUTAT, P69, DOI 10.1109/ICEC.1998.699146
   Torres-Méndez LA, 2005, LECT NOTES COMPUT SC, V3757, P60, DOI 10.1007/11585978_5
   Van de Weijer J, 2007, IEEE T IMAGE PROCESS, V16, P2207, DOI 10.1109/TIP.2007.901808
   Wang DS, 2018, SOFT COMPUT, V22, P387, DOI 10.1007/s00500-016-2474-6
   Wang SQ, 2015, IEEE SIGNAL PROC LET, V22, P2387, DOI 10.1109/LSP.2015.2487369
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Wang Y, 2018, IEEE T CIRCUITS-I, V65, P992, DOI 10.1109/TCSI.2017.2751671
   Yang M, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115723
   Yu HF, 2020, MULTIMED TOOLS APPL, V79, P20373, DOI 10.1007/s11042-020-08701-3
   Zhang S, 2017, NEUROCOMPUTING, V245, P1, DOI 10.1016/j.neucom.2017.03.029
   Zhou JC, 2021, MULTIMED TOOLS APPL, V80, P7771, DOI 10.1007/s11042-020-10049-7
NR 60
TC 5
Z9 5
U1 3
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30051
EP 30068
DI 10.1007/s11042-022-12267-7
EA APR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779045500015
DA 2024-07-18
ER

PT J
AU Fang, ME
   Jin, ZX
   Qin, FW
   Peng, Y
   Jiang, C
   Pan, ZG
AF Fang, Meie
   Jin, Zhuxin
   Qin, Feiwei
   Peng, Yong
   Jiang, Chao
   Pan, Zhigeng
TI Re-transfer learning and multi-modal learning assisted early diagnosis
   of Alzheimer's disease
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Transfer learning; Multi-modal learning; Fine-grained classification;
   Convolutional neural network
ID MILD COGNITIVE IMPAIRMENT; CLASSIFICATION; MRI; MACHINE
AB Nowadays more and more elderly people are suffering from Alzheimer's disease (AD). Finely recognizing mild cognitive impairment (MCI) in early stage of the symptom is vital for AD therapy. However, brain image samples are relatively scarce, meanwhile have multiple modalities, which makes finely classifying brain images by computers extremely difficult. This paper proposes a fine-grained brain image classification approach for diagnosing Alzheimer's disease, with re-transfer learning and multi-modal learning. First of all, an end-to-end deep neural network classifier CNN4AD is designed to finely classify diffusion tensor image (DTI) into four categories. And according to the characteristics of multi-modal brain image dataset, the re-transfer learning method is proposed based on transfer learning and multi-modal learning theories. Experimental results show that the proposed approach obtain higher accuracy with less labeled training samples. This could help doctors diagnose Alzheimer's disease more timely and accurately.
C1 [Fang, Meie] Guangzhou Univ, Sch Comp Sci & Cyber Engn, Guangzhou, Peoples R China.
   [Jin, Zhuxin; Qin, Feiwei; Peng, Yong] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou, Peoples R China.
   [Qin, Feiwei; Jiang, Chao] Sir Run Run Shaw Hosp, Engn Res Ctr Cognit Healthcare Zhejiang Prov, Hangzhou, Zhejiang, Peoples R China.
   [Pan, Zhigeng] Nanjing Univ Informat Sci & Technol, Sch Artif Intelligence, Nanjing, Peoples R China.
   [Pan, Zhigeng] Hangzhou Normal Univ, Digital Media, Interact, Hangzhou, Peoples R China.
C3 Guangzhou University; Hangzhou Dianzi University; Zhejiang University;
   Nanjing University of Information Science & Technology; Hangzhou Normal
   University
RP Qin, FW (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou, Peoples R China.; Qin, FW (corresponding author), Sir Run Run Shaw Hosp, Engn Res Ctr Cognit Healthcare Zhejiang Prov, Hangzhou, Zhejiang, Peoples R China.
EM qinfeiwei@hdu.edu.cn
RI Fang, Meie/IYS-4458-2023; Qin, Feiwei/ABE-8478-2020; Peng,
   Yong/JCO-0601-2023
OI Fang, Meie/0000-0003-4292-8889; Peng, Yong/0000-0003-1208-972X; Qin,
   Feiwei/0000-0001-5036-9365
FU National Natural Science Foundation of China [62072126, 61772164,
   61972121, 61971173, U1909210]; Zhejiang Provincial Natural Science
   Foundation of China [L221F020008, LY21F020015]
FX This work was supported in part by National Natural Science Foundation
   of China (Nos. 62072126, 61772164, 61972121, 61971173, U1909210),
   Zhejiang Provincial Natural Science Foundation of China (Nos.
   L221F020008, LY21F020015). The authors would like to thank the reviewers
   for their comments and suggestions in advance.
CR Aderghal K, 2017, LECT NOTES COMPUT SC, V10132, P690, DOI 10.1007/978-3-319-51811-4_56
   Afzal S, 2019, IEEE ACCESS, V7, P115528, DOI 10.1109/ACCESS.2019.2932786
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Alnæs D, 2015, NEUROIMAGE, V109, P260, DOI 10.1016/j.neuroimage.2015.01.026
   [Anonymous], 2016, HIDDEN CUES DEEP LEA
   [Anonymous], 2018, ARXIV180903972
   BAKKOURI I, 2019, 2019 INT C CONTENT B, P1
   Ben Ahmed O, 2017, NEUROCOMPUTING, V220, P98, DOI 10.1016/j.neucom.2016.08.041
   Ben Ahmed O, 2015, COMPUT MED IMAG GRAP, V44, P13, DOI 10.1016/j.compmedimag.2015.04.007
   Bin Tufail A, 2020, J DIGIT IMAGING, V33, P1073, DOI 10.1007/s10278-019-00265-5
   Cheng DN, 2017, PROC SPIE, V10420, DOI 10.1117/12.2281808
   Ebadi A, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00056
   Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Heppner FL, 2015, NAT REV NEUROSCI, V16, P358, DOI 10.1038/nrn3880
   Hosseini-Asl E, 2016, IEEE IMAGE PROC, P126, DOI 10.1109/ICIP.2016.7532332
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Islam J, 2017, LECT NOTES ARTIF INT, V10654, P213, DOI 10.1007/978-3-319-70772-3_20
   Jack CR, 2008, J MAGN RESON IMAGING, V27, P685, DOI 10.1002/jmri.21049
   Korolev IO., 2014, MSRJ, V4, P24, DOI DOI 10.3402/MSRJ.V3I0.201333
   Korolev S, 2017, I S BIOMED IMAGING, P835, DOI 10.1109/ISBI.2017.7950647
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Le Bihan D, 2012, NEUROIMAGE, V61, P324, DOI 10.1016/j.neuroimage.2011.11.006
   Lei BY, 2016, FRONT AGING NEUROSCI, V8, DOI 10.3389/fnagi.2016.00077
   Lella E, 2020, PATTERN RECOGN LETT, V136, P168, DOI 10.1016/j.patrec.2020.06.001
   Lella E, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10030934
   Lu S, 2015, IEEE ENG MED BIO, P2251, DOI 10.1109/EMBC.2015.7318840
   Luo S., 2017, Journal of Applied Mathematics and Physics, V5, P1892
   Magnin B, 2009, NEURORADIOLOGY, V51, P73, DOI 10.1007/s00234-008-0463-x
   Mei M., 2020, NEURAL COMPUT APPL, P1
   Mwangi B, 2014, NEUROINFORMATICS, V12, P229, DOI 10.1007/s12021-013-9204-3
   Peng Y, 2017, NEUROCOMPUTING, V261, P242, DOI 10.1016/j.neucom.2016.05.113
   Petersen RC, 1999, ARCH NEUROL-CHICAGO, V56, P303, DOI 10.1001/archneur.56.3.303
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Suk HI, 2016, NEUROIMAGE, V129, P292, DOI 10.1016/j.neuroimage.2016.01.005
   Vu TD, 2017, INT CONF BIG DATA, P309, DOI 10.1109/BIGCOMP.2017.7881683
   Weiner MichaelW., 2017, The Alzheimer's Disease Neuroimaging Initiative 3: Continued innovation for clinical trial improvement
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wood D, 2019, ARXIV191004721
   Yang JH, 2018, IEEE ACCESS, V6, P187, DOI 10.1109/ACCESS.2017.2761898
   Zu C, 2016, BRAIN IMAGING BEHAV, V10, P1148, DOI 10.1007/s11682-015-9480-7
NR 42
TC 4
Z9 4
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 29159
EP 29175
DI 10.1007/s11042-022-11911-6
EA APR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777241600002
DA 2024-07-18
ER

PT J
AU Tang, XL
   Yang, JM
   Xiong, DY
   Luo, Y
   Wang, HM
   Peng, DG
AF Tang, Xianlun
   Yang, Jingming
   Xiong, Deyi
   Luo, Yang
   Wang, Huimin
   Peng, Deguang
TI Knowledge-enhanced graph convolutional network for recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Knowledge-enhanced recommendation; Graph convolutional network;
   Aggregator; Attention mechanism
AB Recommendation systems based on collaborative filtering (CF) are often accompanied by cold start and sparsity issues, which can be alleviated by using user information, item attributes and optimizing algorithms fully and reasonably. Empirically, the side information, such as item attributes, is not isolated but connected to each other in the form of the knowledge graph (KG). In this article, we put forward Knowledge-Enhanced Graph Convolutional Network (KE-GCN), a well-designed end-to-end architecture for recommendation, mining associated attributes of inter-item on the KG. To capture relatedness of inter-item effectively, we improve the attention mechanism to better probe into the correlation of the item's neighbors, and design a new aggregator to enhance feature aggregation. We conducted experiments on three public benchmarks, and empirical results of them show that KE-GCN is markedly superior to state-of-the-art methods.
C1 [Tang, Xianlun; Yang, Jingming; Luo, Yang; Wang, Huimin] Chongqing Univ Posts & Telecommun, Coll Automat, Chongqing, Peoples R China.
   [Xiong, Deyi] Chongqing Acad Metrol & Qual Inspect, Chongqing, Peoples R China.
   [Peng, Deguang] Chongqing Megalight Technol Co LTD, Chongqing, Peoples R China.
C3 Chongqing University of Posts & Telecommunications
RP Yang, JM (corresponding author), Chongqing Univ Posts & Telecommun, Coll Automat, Chongqing, Peoples R China.
EM yangjingming0601@qq.com
RI Wang, Hui/HMU-9512-2023; wang, huimin/HDM-8421-2022; wang,
   hui/HSG-6135-2023
OI Yang, Jingming/0000-0001-6698-5381
FU National Nature Science Foundation of China [61673079]; Natural Science
   Foundation of Chongqing [cstc2018jcyjAX0160]; Innovation research group
   of universities in Chongqing
FX This work is supported by the National Nature Science Foundation of
   China under Project 61673079, the Natural Science Foundation of
   Chongqing under Project cstc2018jcyjAX0160 and the Innovation research
   group of universities in Chongqing.
CR Bordes A., 2013, P 26 INT C NEURAL IN, P2787
   Chen C, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P177, DOI 10.1145/3289600.3290982
   Chen C, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1583, DOI 10.1145/3178876.3186070
   Gadekallu TR, 2021, COMPLEX INTELL SYST, V7, P1855, DOI 10.1007/s40747-021-00324-x
   He SF, 2022, MULTIMED TOOLS APPL, V81, P19135, DOI 10.1007/s11042-020-10089-z
   He XN, 2018, IEEE T KNOWL DATA EN, V30, P2354, DOI 10.1109/TKDE.2018.2831682
   He XN, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P355, DOI 10.1145/3077136.3080777
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Hu YF, 2008, IEEE DATA MINING, P263, DOI 10.1109/ICDM.2008.22
   Huang J, 2018, ACM/SIGIR PROCEEDINGS 2018, P505, DOI 10.1145/3209978.3210017
   Javed AR, 2021, IEEE T NETW SCI ENG, V8, P1456, DOI 10.1109/TNSE.2021.3059881
   Ju CH, 2019, MULTIMED TOOLS APPL, V78, P29867, DOI 10.1007/s11042-018-6604-2
   Koren Y., 2008, P 14 ACM SIGKDD INT, P426
   Lin YK, 2015, AAAI CONF ARTIF INTE, P2181
   Ma WZ, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P1210, DOI 10.1145/3308558.3313607
   Monti F, 2017, ADV NEUR IN, V30
   Rendle S., 2009, P 25 C UNC ART INT, P452, DOI DOI 10.5555/1795114.1795167
   Rendle S, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168771
   van der Merwe R, 2019, ARCH REC, V40, P239, DOI 10.1080/23257962.2017.1388224
   Vasan D, 2020, COMPUT SECUR, V92, DOI 10.1016/j.cose.2020.101748
   Wang HW, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P968, DOI 10.1145/3292500.3330836
   Wang HW, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3307, DOI 10.1145/3308558.3313417
   Wang HW, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1835, DOI 10.1145/3178876.3186175
   Wang HW, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P417, DOI 10.1145/3269206.3271739
   Wang HW, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P592, DOI 10.1145/3159652.3159666
   Wang Q, 2017, IEEE T KNOWL DATA EN, V29, P2724, DOI 10.1109/TKDE.2017.2754499
   Wang X, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P165, DOI 10.1145/3331184.3331267
   Wu YX, 2018, P 10 INT JOINT C KNO, P51, DOI [10.5220/0006900000510060, DOI 10.5220/0006900000510060]
   Xian YK, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P285, DOI 10.1145/3331184.3331203
   Xin X, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P125, DOI 10.1145/3331184.3331188
   Xu KYL, 2018, PR MACH LEARN RES, V80
   Ying R, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P974, DOI 10.1145/3219819.3219890
   Yu X, 2014, WSDM'14: PROCEEDINGS OF THE 7TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P283, DOI 10.1145/2556195.2556259
   Zhang FZ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P353, DOI 10.1145/2939672.2939673
NR 34
TC 2
Z9 2
U1 2
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28899
EP 28916
DI 10.1007/s11042-022-12272-w
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777375900001
DA 2024-07-18
ER

PT J
AU Dubey, AK
   Jain, V
AF Dubey, Arun Kumar
   Jain, Vanita
TI An accurate recognition of facial expression by extended wavelet deep
   convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image pre-processing; Face detection; Feature extraction; Feature
   selection; Facial expression recognition
ID CNN
AB Facial expressions are essential in community based interactions and in the analysis of emotions behaviour. The automatic identification of face is a motivating topic for the researchers because of its numerous applications like health care, video conferencing, cognitive science etc. In the computer vision with the facial images, the automatic detection of facial expression is a very challenging issue to be resolved. An innovative methodology is introduced in the presented work for the recognition of facial expressions. The presented methodology is described in subsequent stages. At first, input image is taken from the facial expression database and pre-processed with high frequency emphasis (HFE) filtering and modified histogram equalization (MHE). After the process of image enhancement, Viola Jones (VJ) framework is utilized to detect the face in the images and also the face region is cropped by finding the face coordinates. Afterwards, different effective features such as shape information is extracted from enhanced histogram of gradient (EHOG feature), intensity variation is extracted with mean, standard deviation and skewness, facial movement variation is extracted with facial action coding (FAC),texture is extracted using weighted patch based local binary pattern (WLBP) and spatial information is extracted byentropy based Spatial feature. Subsequently, dimensionality of the features are reduced by attaining the most relevant features using Residual Network (ResNet). Finally, extended wavelet deep convolutional neural network (EWDCNN) classifier uses the extracted features and accurately detects the face expressions as sad, happy, anger, fear disgust, surprise and neutral classes. The implementation platform used in the work is PYTHON. The presented technique is tested with the three datasets such as JAFFE, CK+ and Oulu-CASIA.
C1 [Dubey, Arun Kumar] GGSIPU, Univ Sch Informat Commun & Technol, Delhi, India.
   [Jain, Vanita] Bharati Vidyapeeths Coll Engn, New Delhi, India.
C3 GGS Indraprastha University
RP Dubey, AK (corresponding author), GGSIPU, Univ Sch Informat Commun & Technol, Delhi, India.
EM arudubey@gmail.com; vanita.jain@bharatividyapeeth.edu
OI dubey, Arun Kumar/0000-0002-6844-9213
CR Al-Dabagh M.Z. N., 2018, International Journal of Research and Engineering, V5, P335
   Alenazy WM, 2021, J AMB INTEL HUM COMP, V12, P1631, DOI 10.1007/s12652-020-02235-0
   Amani N., 2013, INT J ADV SCI TECHNO, V52, P1
   Arora M, 2021, MULTIMED TOOLS APPL, V80, P3039, DOI 10.1007/s11042-020-09726-4
   Ashir AM, 2020, NEURAL COMPUT APPL, V32, P6295, DOI 10.1007/s00521-019-04138-4
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   Bargshady G, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113305
   Chen JK, 2018, IEEE T AFFECT COMPUT, V9, P38, DOI 10.1109/TAFFC.2016.2593719
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Dino Hivi Ismat, 2019, 2019 International Conference on Advanced Science and Engineering (ICOASE), P70, DOI 10.1109/ICOASE.2019.8723728
   Du LS, 2019, COMPUT VIS IMAGE UND, V186, P13, DOI 10.1016/j.cviu.2019.06.003
   Dubey Arun Kumar, 2019, Applications of Computing, Automation and Wireless Systems in Electrical Engineering. Proceedings of MARC 2018. Lecture Notes in Electrical Engineering (LNEE 553), P873, DOI 10.1007/978-981-13-6772-4_76
   Dubey AK, 2020, P 3 INT C COMP INF N
   Dubey AK, 2020, J INFORM OPTIM SCI, V41, P1589, DOI 10.1080/02522667.2020.1809126
   Dubey AK, 2019, J INFORM OPTIM SCI, V40, P547, DOI 10.1080/02522667.2019.1582875
   Gautam G, 2017, 2017 FOURTH INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P62
   Georgescu MI, 2019, IEEE ACCESS, V7, P64827, DOI 10.1109/ACCESS.2019.2917266
   González-Hernández F, 2018, J INTELL FUZZY SYST, V34, P3325, DOI 10.3233/JIFS-169514
   Han B, 2020, IEEE ACCESS, V8, P159172, DOI 10.1109/ACCESS.2020.3018738
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   Kalsum T, 2018, IET IMAGE PROCESS, V12, P1004, DOI 10.1049/iet-ipr.2017.0499
   Kamarol SKA, 2016, IET IMAGE PROCESS, V10, P534, DOI 10.1049/iet-ipr.2015.0519
   Kas M, 2021, INFORM SCIENCES, V549, P200, DOI 10.1016/j.ins.2020.10.065
   Kawakami T, 2009, 2009 INTERNATIONAL SYMPOSIUM ON INTELLIGENT SIGNAL PROCESSING AND COMMUNICATION SYSTEMS (ISPACS 2009), P570, DOI 10.1109/ISPACS.2009.5383776
   Kola DGR, 2021, MULTIMED TOOLS APPL, V80, P2243, DOI 10.1007/s11042-020-09663-2
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Kumar A, 2019, ARTIF INTELL REV, V52, P927, DOI 10.1007/s10462-018-9650-2
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Lalitha SD, 2020, ARXIV PREPRINT ARXIV
   Li J, 2020, NEUROCOMPUTING, V411, P340, DOI 10.1016/j.neucom.2020.06.014
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   Mahmood M.R., 2021, INDONES J ELECT ENG, V21, P176, DOI DOI 10.11591/IJEECS.V21.I2.PP1176-1184
   Makhmudkhujaev F, 2019, SIGNAL PROCESS-IMAGE, V74, P1, DOI 10.1016/j.image.2019.01.002
   Meng ZB, 2017, IEEE INT CONF AUTOMA, P558, DOI 10.1109/FG.2017.140
   Mistry K, 2017, IEEE T CYBERNETICS, V47, P1496, DOI 10.1109/TCYB.2016.2549639
   Mohan K, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3031835
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Monika, 2021, Computational Methods and Data Engineering. Proceedings of ICMDE 2020. Advances in Intelligent Systems and Computing (AISC 1227), P207, DOI 10.1007/978-981-15-6876-3_16
   Ouellet S., 2014, ARXIV PREPRINT ARXIV
   Owayjan M, 2016, MID EAST CONF BIO, P115, DOI 10.1109/MECBME.2016.7745421
   Singh S, 2021, MULTIMED TOOLS APPL, V80, P19753, DOI 10.1007/s11042-021-10711-8
   Sun A, 2018, HUM-CENT COMPUT INFO, V8, DOI 10.1186/s13673-018-0156-3
   Turan C, 2018, J VIS COMMUN IMAGE R, V55, P331, DOI 10.1016/j.jvcir.2018.05.024
   Uçar A, 2016, NEURAL COMPUT APPL, V27, P131, DOI 10.1007/s00521-014-1569-1
   Wu BF, 2018, IEEE ACCESS, V6, P12451, DOI 10.1109/ACCESS.2018.2805861
   Zeng NY, 2018, NEUROCOMPUTING, V273, P643, DOI 10.1016/j.neucom.2017.08.043
   Zhang FF, 2020, IEEE T IMAGE PROCESS, V29, P4445, DOI 10.1109/TIP.2020.2972114
   Zhang ZP, 2018, INT J COMPUT VISION, V126, P550, DOI 10.1007/s11263-017-1055-1
NR 48
TC 1
Z9 1
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28295
EP 28325
DI 10.1007/s11042-022-12871-7
EA MAR 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000774644000005
DA 2024-07-18
ER

PT J
AU Patel, B
   Alsadoon, A
   Prasad, PWC
   Dawoud, A
   Rashid, TA
   Alsadoon, OH
   Jerew, OD
AF Patel, Bhoomiben
   Alsadoon, Abeer
   Prasad, P. W. C.
   Dawoud, Ahmed
   Rashid, Tarik A.
   Alsadoon, Omar Hisham
   Jerew, Oday D.
TI Secure data transmission in a real-time network for a tele-training
   education system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hybrid encryption algorithms; Advanced encryption standard (AES)
   algorithm; Rivcst-Shamir-Adclman (RSA) algorithm; Embedding technique;
   Security; Entropy; Surgical tele-training system
ID IMAGE WATERMARKING; REVERSIBLE WATERMARKING; ENCRYPTION; STEGANOGRAPHY;
   AUTHENTICATION; SCHEME; ROBUST
AB Surgical training provides a solution for the trainee surgeons living remotely and needs to improve their surgical skills learned from the experts around the globe. One of the main challenges in implementing an effective tele-training system is security vulnerabilities during data transmission. The current security solutions come at a price in terms of efficiency and performance. This research aims to enhance security during video transmission over the Internet with decreased processing time. y: The proposed system consists of a hybrid encryption model with 2D discrete wavelet transform level 1 steganography technique, which enhances security during data transmission by encrypting the data first and then hiding it in the cover image. This creates a ciphered image that is difficult to crack for the attackers. Advanced Encryption Standard (AES) and (Rivest-Shamir-Adleman) RSA algorithms are used for the encryption process. It modifies and improves the key generation part of the encryption algorithm to achieve higher security. The hybrid encryption algorithm with the modified and improved key generation enhances security by improving the entropy by 29% over the current best solution. Additionally, the average processing time of the encryption and decryption process has been reduced by 33% compared to the state of the art solution. The processing time for the encryption process has been reduced by 2.55 similar to 2.92 ms, and for the decryption process, 2.45 similar to 2.55 ms. The entropy is increased by 8.174 (average) for the proposed system against 6.895 for the existing best solution. The proposed approach is mainly focused on providing improved security to the video data transmission over the Internet by modifying and improving the key generation step. Finally, this study proposes a solution for brute-force attacks in RSA during a real-time transmission.
C1 [Patel, Bhoomiben; Alsadoon, Abeer; Prasad, P. W. C.; Dawoud, Ahmed] Charles Start Univ CSU, Sch Comp Math & Engn, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Prasad, P. W. C.; Dawoud, Ahmed] Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Prasad, P. W. C.] Kent Inst Australia, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Jerew, Oday D.] Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
   [Rashid, Tarik A.] Univ Kurdistan Hewler, Comp Sci & Engn, Erbil, Krg, Iraq.
   [Alsadoon, Omar Hisham] Al Iraqis Univ, Dept Islamic Sci, Baghdad, Iraq.
C3 Charles Sturt University; Western Sydney University; University of
   Kurdistan Hewler
RP Alsadoon, A (corresponding author), Charles Start Univ CSU, Sch Comp Math & Engn, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Kent Inst Australia, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Rashid, Tarik A./HLX-0184-2023; Alsadoon, A/Prof. Abeer/AAU-1532-2021;
   Rashid, Tarik A./P-3473-2019
OI Rashid, Tarik A./0000-0002-8661-258X; Alsadoon, A/Prof.
   Abeer/0000-0002-2309-3540; Rashid, Tarik A./0000-0002-8661-258X;
   Alsadoon, Omar Hisham/0000-0001-7797-6392; withana,
   chandana/0000-0002-3007-687X
CR AlShaikh M, 2017, MULTIMED TOOLS APPL, V76, P8937, DOI 10.1007/s11042-016-3499-7
   Araujo A, 2012, EURASIP J WIREL COMM, P1, DOI 10.1186/1687-1499-2012-48
   Atta R, 2018, J VIS COMMUN IMAGE R, V53, P42, DOI 10.1016/j.jvcir.2018.03.009
   Avudaiappan T, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1053-z
   Balu S, 2019, CLUSTER COMPUT, V22, pS4057, DOI 10.1007/s10586-018-2639-4
   Dagadu JC, 2018, MULTIMED TOOLS APPL, V77, P24289, DOI 10.1007/s11042-018-5725-y
   Elhoseny M, 2018, IEEE ACCESS, V6, P20596, DOI 10.1109/ACCESS.2018.2817615
   Frnda J, 2016, TELECOMMUN SYST, V62, P265, DOI 10.1007/s11235-015-0037-2
   Han X, 2020, MULTIMED TOOLS APPL, V79, P9655, DOI 10.1007/s11042-017-5598-5
   Kalra GS, 2015, MULTIMED TOOLS APPL, V74, P6849, DOI 10.1007/s11042-014-1932-3
   Kumar, 2015, INT J COMPUT APPL, V97, P18
   Lee HY, 2019, MULTIMED TOOLS APPL, V78, P19663, DOI 10.1007/s11042-019-7322-0
   Lian, 2010, J ELECTRON IMAGING, V17, P3
   Madhu, 2015, INT J COMPUT APPL, V104, P30
   Naskar R, 2013, IET IMAGE PROCESS, V7, P99, DOI 10.1049/iet-ipr.2012.0232
   Priyanka, 2017, MULTIMED TOOLS APPL, V76, P3617, DOI 10.1007/s11042-016-3913-1
   Puentes J, 2007, INT J BIOMED ENG TEC, V1, P59, DOI 10.1504/IJBET.2007.014137
   Razzaq MA, 2017, INT J ADV COMPUT SC, V8, P224
   Rosen J, 2006, IEEE SPECTRUM, V43, P34, DOI 10.1109/MSPEC.2006.1705774
   Sallam AI, 2018, MULTIMED TOOLS APPL, V77, P28395, DOI 10.1007/s11042-018-5994-5
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Sun QD, 2018, INT J DISTRIB SENS N, V14, DOI 10.1177/1550147718810694
   Swaraja K, 2018, MULTIMED TOOLS APPL, V77, P28249, DOI 10.1007/s11042-018-6020-7
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   Wagle A., 2018, AM J APPL SCI, V15, P476, DOI [10.3844/ajassp.2018.476.488, DOI 10.3844/AJASSP.2018.476.488]
   Wong PW, 2001, IEEE T IMAGE PROCESS, V10, P1593, DOI 10.1109/83.951543
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zahiri M, 2018, SURG INNOV, V25, P81, DOI 10.1177/1553350617739425
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
NR 30
TC 1
Z9 1
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27819
EP 27836
DI 10.1007/s11042-022-12903-2
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000774644100018
DA 2024-07-18
ER

PT J
AU Sun, WY
   He, YT
   Ge, RJ
   Yang, GY
   Chen, Y
   Shu, HZ
AF Sun, Weiya
   He, Yuting
   Ge, Rongjun
   Yang, Guanyu
   Chen, Yang
   Shu, Huazhong
TI Projection network with Spatio-temporal information: 2D+time DSA to 2D
   aorta segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Aortic dissection; Segmentation; X-ray; Digital
   subtraction angiography
ID DIGITAL-SUBTRACTION-ANGIOGRAPHY; DISSECTION
AB Aortic dissection (AD) is an acute cardiovascular disease with high mortality and disability rates. AD is commonly treated by the thoracic endovascular aortic repair(TEVAR) which relies on the aorta's position in the Digital Subtraction Angiography (DSA). However, patients and doctors need to be constantly exposed to the X-rays during the DSA process. Besides, the aorta is partially displayed in each frame with blurred boundaries and inhomogeneously distributed contrast agent. The accurate segmentation of AD in DSA is essential for stent placement. This paper proposes a projection network with spatio-temporal information (PNet-ST) for the aortic segmentation of DSA. We introduce a spatial encoder to learn the partial aortic structure information in each frame. Meanwhile, the max intensity projection (MIP) skip connections are used to fuse the temporal information preserved by the encoder to obtain the complete aortic structure. Furthermore, the dense biased connections integrate the multi-receptive field to enhance the network's sensitivity for the multi-resolution feature. The experiment results show that our PNet-ST with segmentation DSC of 0.897, Precision of 0.8757, Recall of 0.9202 and Acc of 0.9684, outperforming the previous image segmentation techniques, such as CE-Net, HRNET and U-Net. The segmentation results of our PNet-ST can offer assistance in endovascular surgery and help the doctors observe the entire aorta to place the stent more accurately.
C1 [Sun, Weiya; He, Yuting; Yang, Guanyu; Chen, Yang; Shu, Huazhong] Southeast Univ, Sch Comp Sci & Engn, Lab Image Sci & Technol, Key Lab Comp Network & Informat Integrat, Nanjing 210096, Peoples R China.
   [Sun, Weiya; He, Yuting; Yang, Guanyu; Chen, Yang; Shu, Huazhong] Ctr Rech Informat BioMd Sino Franais CRIBs, Nanjing, Peoples R China.
   [Ge, Rongjun] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 211106, Peoples R China.
C3 Southeast University - China; Nanjing University of Aeronautics &
   Astronautics
RP Shu, HZ (corresponding author), Southeast Univ, Sch Comp Sci & Engn, Lab Image Sci & Technol, Key Lab Comp Network & Informat Integrat, Nanjing 210096, Peoples R China.; Shu, HZ (corresponding author), Ctr Rech Informat BioMd Sino Franais CRIBs, Nanjing, Peoples R China.
EM weiyasun.list@seu.edu.cn; 18856327400@163.com; rongjun.ge@nuaa.edu.cn;
   yang.list@seu.edu.cn; chenyang.list@seu.edu.cn; shu.list@seu.edu.cn
RI he, yuting/HLX-6751-2023
CR Aylward S, 1996, PROCEEDINGS OF THE IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, P131, DOI 10.1109/MMBIA.1996.534065
   CHILCOTE WA, 1981, RADIOLOGY, V139, P287, DOI 10.1148/radiology.139.2.7012921
   cicek Ozgtin, 2016, INT C MED IM COMP CO, P424, DOI DOI 10.1007/978-3-319-46723-8_49
   Criado Frank J, 2011, Tex Heart Inst J, V38, P694
   Donizelli M, 1998, BILDVERARBEITUNG MED, DOI [10.1007/978-3-642-58775-7_59, DOI 10.1007/978-3-642-58775-7_59]
   Fan JF, 2019, CHIN C IM GRAPH TECH, P625, DOI [10.1007/978-981-13-9917-6_59, DOI 10.1007/978-981-13-9917-6_59]
   Franchi D, 2009, COMPUT METH PROG BIO, V94, P267, DOI 10.1016/j.cmpb.2009.02.002
   Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562
   Jin HL, 2020, J NEUROINTERV SURG, V12, P1023, DOI 10.1136/neurintsurg-2020-015824
   Jin HL, 2019, PROC SPIE, V10949, DOI 10.1117/12.2512623
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Luo H, 2000, PROC CVPR IEEE, P452, DOI 10.1109/CVPR.2000.855854
   Meng C, 2020, NEUROCOMPUTING, V373, P123, DOI 10.1016/j.neucom.2019.10.035
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Neumann C, 2018, VISAPP: PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL 4: VISAPP, P331, DOI 10.5220/0006570603310338
   Park S, 1997, TENCON IEEE REGION, P671, DOI 10.1109/TENCON.1997.648511
   Picano E, 2004, BMJ-BRIT MED J, V329, P849, DOI 10.1136/bmj.329.7470.849
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Tsai TT, 2009, EUR J VASC ENDOVASC, V37, P149, DOI 10.1016/j.ejvs.2008.11.032
   White A, 2013, ADV EMERG NURS J, V35, P28, DOI 10.1097/TME.0b013e31827145d0
   Yu F, 2019, LECT NOTES COMPUT SC, V11765, P714, DOI 10.1007/978-3-030-32245-8_79
   Zhang M, 2020, COMPUT METH PROG BIO, V185, DOI 10.1016/j.cmpb.2019.105159
   Zhou YZ., 2013, INNER MONGOLIA MED J, V45, P797, DOI [10.3969/j.issn.1004-0951.2013.07.010, DOI 10.3969/J.ISSN.1004-0951.2013.07.010]
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
NR 25
TC 0
Z9 0
U1 5
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 28021
EP 28035
DI 10.1007/s11042-022-12117-6
EA MAR 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000774644100004
DA 2024-07-18
ER

PT J
AU Wang, FS
   Yin, SS
   Mbelwa, JT
   Sun, FM
AF Wang, Fasheng
   Yin, Shuangshuang
   Mbelwa, Jimmy T.
   Sun, Fuming
TI Context and saliency aware correlation filter for visual tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Correlation filter; Context information; Saliency
   feature map
AB Visual tracking in complex scenarios is a big challenge in the computer vision community. Due to correlation filter (CF) recently have achieved excellent results both on accuracy and robustness in visual tracking, many researchers have focused on incorporating different features for better represent the tracking target. However, CF-based trackers have poor ability to handle problem in many complex scenes with challenges like deformation, motion blur and background clutters. To overcome these defects, we propose a context and saliency aware CF for visual tracking (CSCF). Context information around the target of interest is introduced into correlation filters to strengthen the discriminative ability of CF, which can reduce the boundary effect and the influence of the background. Then the saliency feature map of the target is combined with CF to strengthen the ability to extract targets of interest from complex background. Experimental results show that the proposed method shows competitive performance on OTB dataset and UAV dataset compared to several other CF trackers.
C1 [Wang, Fasheng; Yin, Shuangshuang; Sun, Fuming] Dalian Minzu Univ, Sch Informat & Commun Engn, Dalian 116600, Peoples R China.
   [Mbelwa, Jimmy T.] Univ Dar es Salaam, Dept Comp Sci & Engn, Da Es Salaam 33335, Tanzania.
C3 Dalian Minzu University; University of Dar es Salaam
RP Sun, FM (corresponding author), Dalian Minzu Univ, Sch Informat & Commun Engn, Dalian 116600, Peoples R China.
EM jmbelwa@udsm.ac.tz; sunfuming@dlnu.edu.cn
RI Sun, Fuming/HGT-8610-2022; Sun, Fuming/HKN-9901-2023
OI Sun, Fuming/0000-0003-3932-2712
FU National Natural Science Foundation of China [61972068, 61976042];
   LiaoNing Revitalization Talents Program [XLYC2007023]; Innovative
   Talents Program for Liaoning Universities [LR2019020]; Wuhan Chegu
   Industrial Talents Program
FX This work was supported by National Natural Science Foundation of China
   (Grant No. 61972068, 61976042), LiaoNing Revitalization Talents Program
   (Grant No. XLYC2007023), Wuhan Chegu Industrial Talents Program,
   Innovative Talents Program for Liaoning Universities (Grant No.
   LR2019020).
CR Abbass MY, 2021, VISUAL COMPUT, V37, P993, DOI 10.1007/s00371-020-01848-y
   Chen ZD, 2020, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR42600.2020.00670
   Dai KN, 2019, PROC CVPR IEEE, P4665, DOI 10.1109/CVPR.2019.00480
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Fan JQ, 2020, FRONT COMPUT SCI-CHI, V14, P334, DOI 10.1007/s11704-018-8104-y
   Feng W, 2019, IEEE T IMAGE PROCESS, V28, P3232, DOI 10.1109/TIP.2019.2895411
   Fu CH, 2020, IEEE T GEOSCI REMOTE, V58, P8940, DOI 10.1109/TGRS.2020.2992301
   Fu CH, 2020, NEURAL COMPUT APPL, V32, P12591, DOI 10.1007/s00521-020-04716-x
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Han R.Z., 2018, Proceedings of the 2018 IEEE International Symposium on Circuits and Systems (ISCAS), P1
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Huang yueping, 2021, Systems Engineering and Electronics, V43, P2051, DOI 10.12305/j.issn.1001-506X.2021.08.05
   Huang Z., 2017, P IEEE C COMP VIS PA, P4021, DOI DOI 10.1109/CVPR.2017.510
   Javanmardi M, 2020, NEURAL NETWORKS, V129, P334, DOI 10.1016/j.neunet.2020.06.011
   Kumar A, 2020, EXPERT SYST APPL, V162, DOI 10.1016/j.eswa.2020.113711
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liang Y, 2022, MULTIMED TOOLS APPL, V81, P26669, DOI 10.1007/s11042-020-10468-6
   Liu S, 2021, COMPLEX INTELL SYST, V7, P1895, DOI 10.1007/s40747-020-00161-4
   Marvasti-Zadeh SM, 2022, IEEE T INTELL TRANSP, V23, P3943, DOI 10.1109/TITS.2020.3046478
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Qi YW, 2020, IEEE T SYST MAN CY-S, V50, P1442, DOI 10.1109/TSMC.2018.2801284
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Sevilla-Lara L, 2012, PROC CVPR IEEE, P1910, DOI 10.1109/CVPR.2012.6247891
   She Y, 2020, LECT NOTES COMPUT SC, V11961, P480, DOI 10.1007/978-3-030-37731-1_39
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Song YB, 2018, PROC CVPR IEEE, P8990, DOI 10.1109/CVPR.2018.00937
   Tu Fangwen, 2018, ARXIV PREPRINT ARXIV
   Wang F, 2020, CAN J DIET PRACT RES, V81, P142, DOI 10.3148/cjdpr-2020-004
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Xu TY, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2919201
   Yu YC, 2020, PROC CVPR IEEE, P6727, DOI 10.1109/CVPR42600.2020.00676
   Yuan Y, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-0496-6
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhang YH, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113937
   Zhao J., 2020, COMPUT ELECTR ENG, V86, P1
   Zhu CF, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030790
   Zhu Z., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508710
   Zuo WM, 2019, IEEE T PATTERN ANAL, V41, P1158, DOI 10.1109/TPAMI.2018.2829180
NR 47
TC 7
Z9 9
U1 3
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27879
EP 27893
DI 10.1007/s11042-022-12760-z
EA MAR 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000774644100014
DA 2024-07-18
ER

PT J
AU Singh, LK
   Pooja
   Garg, H
   Khanna, M
AF Singh, Law Kumar
   Pooja
   Garg, Hitendra
   Khanna, Munish
TI Performance evaluation of various deep learning based models for
   effective glaucoma evaluation using optical coherence tomography images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Glaucoma; Optical coherence tomography; Deep learning; Convolution
   neural network; VGG16; Efficient net
ID DIAGNOSTIC ABILITY; NERVE HEAD; DOMAIN; OCT; PROGRESSION; SEGMENTATION;
   PARAMETERS
AB Glaucoma is the dominant reason for irreversible blindness worldwide, and its best remedy is early and timely detection. Optical coherence tomography has come to be the most commonly used imaging modality in detecting glaucomatous damage in recent years. Deep Learning using Optical Coherence Tomography Modality helps in predicting glaucoma more accurately and less tediously. This experimental study aims to perform glaucoma prediction using eight different ImageNet models from Optical Coherence Tomography of Glaucoma. A thorough investigation is performed to evaluate these models' performances on various efficiency metrics, which will help discover the best performing model. Every net is tested on three different optimizers, namely Adam, Root Mean Squared Propagation, and Stochastic Gradient Descent, to find the best relevant results. An attempt has been made to improvise the performance of models using transfer learning and fine-tuning. The work presented in this study was initially trained and tested on a private database that consists of 4220 images (2110 normal optical coherence tomography and 2110 glaucoma optical coherence tomography). Based on the results, the four best-performing models are shortlisted. Later, these models are tested on the well-recognized standard public Mendeley dataset. Experimental results illustrate that VGG16 using the Root Mean Squared Propagation Optimizer attains auspicious performance with 95.68% accuracy. The proposed work concludes that different ImageNet models are a good alternative as a computer-based automatic glaucoma screening system. This fully automated system has a lot of potential to tell the difference between normal Optical Coherence Tomography and glaucomatous Optical Coherence Tomography automatically. The proposed system helps in efficiently detecting this retinal infection in suspected patients for better diagnosis to avoid vision loss and also decreases senior ophthalmologists' (experts) precious time and involvement.
C1 [Singh, Law Kumar; Pooja] Sharda Univ, Dept Comp Sci & Engn, Greater Noida, India.
   [Singh, Law Kumar; Khanna, Munish] Hindustan Coll Sci & Technol, Dept Comp Sci & Engn, Mathura, India.
   [Garg, Hitendra] GLA Univ, Dept Comp Engn & Applicat, Mathura, India.
C3 Sharda University; GLA University
RP Singh, LK (corresponding author), Sharda Univ, Dept Comp Sci & Engn, Greater Noida, India.; Singh, LK (corresponding author), Hindustan Coll Sci & Technol, Dept Comp Sci & Engn, Mathura, India.
EM lawkumares@gmail.com; pooja.1@sharda.ac.in; Hitendra.garg@gmail.com;
   munishkhanna.official@rocketmail.com
RI Singh, Law Kumar/AAI-5450-2021; Garg, Hitendra/AAV-6756-2020
OI Singh, Law Kumar/0000-0002-7073-6852; Garg, Dr.
   Hitendra/0000-0002-4273-2328
CR Abramoff Michael D, 2010, IEEE Rev Biomed Eng, V3, P169, DOI 10.1109/RBME.2010.2084567
   Ajesh F, 2020, INT J IMAG SYST TECH, V30, P1143, DOI 10.1002/ima.22435
   Amorim R, 2019, IEEE VTS VEH TECHNOL, DOI 10.1109/vtcspring.2019.8746579
   An GZ, 2019, J HEALTHC ENG, V2019, DOI 10.1155/2019/4061313
   Asaoka R, 2019, AM J OPHTHALMOL, V198, P136, DOI 10.1016/j.ajo.2018.10.007
   Bock R, 2010, MED IMAGE ANAL, V14, P471, DOI 10.1016/j.media.2009.12.006
   Bussel II, 2014, BRIT J OPHTHALMOL, V98, P15, DOI 10.1136/bjophthalmol-2013-304326
   Charlson ES, 2015, OPHTHALMOLOGY, V122, P711, DOI 10.1016/j.ophtha.2014.11.015
   DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595
   Dey N, 2021, PATTERN RECOGN LETT, V143, P67, DOI 10.1016/j.patrec.2020.12.010
   Dong N, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106311
   Ferreira CA, 2018, LECT NOTES COMPUT SC, V10882, P763, DOI 10.1007/978-3-319-93000-8_86
   Fu HZ, 2019, AM J OPHTHALMOL, V203, P37, DOI 10.1016/j.ajo.2019.02.028
   Fu HZ, 2017, IEEE T MED IMAGING, V36, P1930, DOI 10.1109/TMI.2017.2703147
   Fujimoto JG, 2000, NEOPLASIA, V2, P9, DOI 10.1038/sj.neo.7900071
   Gaddipati DJ, 2019, IEEE ENG MED BIO, P5581, DOI [10.1109/EMBC.2019.8857493, 10.1109/embc.2019.8857493]
   Garcia G, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105855
   García G, 2020, IEEE IMAGE PROC, P2526, DOI 10.1109/ICIP40778.2020.9190916
   Grewal DS, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182816
   Haleem MS, 2013, COMPUT MED IMAG GRAP, V37, P581, DOI 10.1016/j.compmedimag.2013.09.005
   Hao HY, 2019, IEEE ENG MED BIO, P849, DOI [10.1109/EMBC.2019.8857615, 10.1109/embc.2019.8857615]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Kansal V, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0190621
   Kass MA, 2002, ARCH OPHTHALMOL-CHIC, V120, P701
   Khan MA, 2021, ADV CIV ENG, V2021, DOI 10.1155/2021/6618407
   Kotowski J, 2012, BRIT J OPHTHALMOL, V96, P1420, DOI 10.1136/bjophthalmol-2011-301021
   Lee J, 2020, J GLAUCOMA, V29, P287, DOI 10.1097/IJG.0000000000001458
   Lee K, 2010, IEEE T MED IMAGING, V29, P159, DOI 10.1109/TMI.2009.2031324
   Lee SY, 2018, YONSEI MED J, V59, P887, DOI 10.3349/ymj.2018.59.7.887
   Leske MC, 2003, ARCH OPHTHALMOL-CHIC, V121, P48
   Li H, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8090421
   Li YX, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2979-y
   Maetschke S, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0219126
   Mansberger SL, 2017, AM J OPHTHALMOL, V174, P1, DOI 10.1016/j.ajo.2016.10.020
   Marques G, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106691
   McCann P, 2019, OPHTHALMOL GLAUCOMA, V2, P336, DOI 10.1016/j.ogla.2019.06.003
   Medeiros FA, 2019, OPHTHALMOLOGY, V126, P513, DOI 10.1016/j.ophtha.2018.12.033
   Mirzania D, 2021, EUR J OPHTHALMOL, V31, P1618, DOI 10.1177/1120672120977346
   Muhammad H, 2017, J GLAUCOMA, V26, P1086, DOI 10.1097/IJG.0000000000000765
   Murtagh P, 2020, INT J OPHTHALMOL-CHI, V13, P149, DOI 10.18240/ijo.2020.01.22
   Mwanza JC, 2018, TRANSL VIS SCI TECHN, V7, DOI 10.1167/tvst.7.2.16
   Mwanza JC, 2011, OPHTHALMOLOGY, V118, P241, DOI 10.1016/j.ophtha.2010.06.036
   Naveed M, 2017, 2017 1ST INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING APPLICATIONS (NEXTCOMP), P157, DOI 10.1109/NEXTCOMP.2017.8016192
   Nawaz H, 2021, MULTIMED TOOLS APPL, V80, P35789, DOI 10.1007/s11042-020-09087-y
   Pachiyappan A, 2012, LIPIDS HEALTH DIS, V11, DOI 10.1186/1476-511X-11-73
   Quigley HA, 2006, BRIT J OPHTHALMOL, V90, P262, DOI 10.1136/bjo.2005.081224
   Rahimzadeh Mohammad, 2020, Inform Med Unlocked, V19, P100360, DOI 10.1016/j.imu.2020.100360
   Raja H, 2020, J DIGIT IMAGING, V33, P1428, DOI 10.1007/s10278-020-00383-5
   Ran AR, 2021, EYE, V35, P188, DOI 10.1038/s41433-020-01191-5
   Ran AR, 2019, LANCET DIGIT HEALTH, V1, pE172, DOI 10.1016/S2589-7500(19)30085-8
   Ren WQ, 2019, IEEE T IMAGE PROCESS, V28, P4364, DOI 10.1109/TIP.2019.2910412
   Russakoff DB, 2020, TRANSL VIS SCI TECHN, V9, DOI 10.1167/tvst.9.2.12
   Schmitt JM, 1999, IEEE J SEL TOP QUANT, V5, P1205, DOI 10.1109/2944.796348
   Sehi M, 2009, AM J OPHTHALMOL, V148, P597, DOI 10.1016/j.ajo.2009.05.030
   Shehryar T, 2020, INT J IMAG SYST TECH, V30, P1046, DOI 10.1002/ima.22413
   Singh LK, 2021, INT J E-HEALTH MED C, V12, P32, DOI 10.4018/IJEHMC.20210701.oa3
   Singh LK, 2021, MED BIOL ENG COMPUT, V59, P333, DOI 10.1007/s11517-020-02307-5
   Sitaula C, 2021, APPL INTELL, V51, P2850, DOI 10.1007/s10489-020-02055-x
   Sung KR, 2012, J GLAUCOMA, V21, P498, DOI 10.1097/IJG.0b013e318220dbb7
   Sunija AP, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103192
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tatham AJ, 2017, OPHTHALMOLOGY, V124, pS57, DOI 10.1016/j.ophtha.2017.07.015
   Thakoor KA, 2019, IEEE ENG MED BIO, P2036, DOI [10.1109/EMBC.2019.8856899, 10.1109/embc.2019.8856899]
   Thompson AC, 2020, JAMA OPHTHALMOL, V138, P333, DOI 10.1001/jamaophthalmol.2019.5983
   Thompson AC, 2019, AM J OPHTHALMOL, V201, P9, DOI 10.1016/j.ajo.2019.01.011
   TUCK MW, 1992, OPHTHAL PHYSL OPT, V12, P400, DOI 10.1111/j.1475-1313.1992.tb00307.x
   Vajaranant TS, 2012, INVEST OPHTH VIS SCI, V53, P2464, DOI 10.1167/iovs.12-9483d
   Wang X, 2020, MED IMAGE ANAL, V63, DOI 10.1016/j.media.2020.101695
   Xu BY, 2019, AM J OPHTHALMOL, V208, P273, DOI 10.1016/j.ajo.2019.08.004
   Xu J, 2011, IEEE ENG MED BIO, P3395, DOI 10.1109/IEMBS.2011.6090919
   Zhang JM, 2019, MATH BIOSCI ENG, V16, P3345, DOI 10.3934/mbe.2019167
   Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39
   Zhang XB, 2017, AM J OPHTHALMOL, V184, P63, DOI 10.1016/j.ajo.2017.09.020
   Zheng CJ, 2019, CURR OPIN OPHTHALMOL, V30, P97, DOI 10.1097/ICU.0000000000000552
NR 75
TC 16
Z9 16
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27737
EP 27781
DI 10.1007/s11042-022-12826-y
EA MAR 2022
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000774643900001
PM 35368855
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Aljabri, M
   AlAmir, M
   AlGhamdi, M
   Abdel-Mottaleb, M
   Collado-Mesa, F
AF Aljabri, Manar
   AlAmir, Manal
   AlGhamdi, Manal
   Abdel-Mottaleb, Mohamed
   Collado-Mesa, Fernando
TI Towards a better understanding of annotation tools for medical imaging:
   a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Annotations; Medical images; Segmentation; Taggining
ID AUTOMATIC SEGMENTATION; CAPSULE ENDOSCOPY; NEURAL-NETWORKS; INTERNET;
   PLATFORM; IMAGES; MODEL; CT
AB Medical imaging refers to several different technologies that are used to view the human body to diagnose, monitor, or treat medical conditions. It requires significant expertise to efficiently and correctly interpret the images generated by each of these technologies, which among others include radiography, ultrasound, and magnetic resonance imaging. Deep learning and machine learning techniques provide different solutions for medical image interpretation including those associated with detection and diagnosis. Despite the huge success of deep learning algorithms in image analysis, training algorithms to reach human-level performance in these tasks depends on the availability of large amounts of high-quality training data, including high-quality annotations to serve as ground-truth. Different annotation tools have been developed to assist with the annotation process. In this survey, we present the currently available annotation tools for medical imaging, including descriptions of graphical user interfaces (GUI) and supporting instruments. The main contribution of this study is to provide an intensive review of the popular annotation tools and show their successful usage in annotating medical imaging dataset to guide researchers in this area.
C1 [Aljabri, Manar; AlAmir, Manal; AlGhamdi, Manal] Umm Al Qura Univ, Dept Comp Sci, Mecca, Saudi Arabia.
   [Abdel-Mottaleb, Mohamed] Univ Miami, Dept Elect & Comp Engn, Coral Gables, FL 33124 USA.
   [Collado-Mesa, Fernando] Univ Miami, Miller Sch Med, Dept Radiol, Coral Gables, FL 33124 USA.
C3 Umm Al Qura University; University of Miami; University of Miami
RP AlGhamdi, M (corresponding author), Umm Al Qura Univ, Dept Comp Sci, Mecca, Saudi Arabia.
EM maalghamdi@uqu.edu.sa
OI Collado-Mesa, Fernando/0000-0003-0489-3566; Al Ghamdi,
   Manal/0000-0002-7895-6999
CR Abtahi S., 2014, P 5 ACM MULT SYST C, P24, DOI DOI 10.1145/2557642.2563678
   Afouras T., 2020, P EUR C COMP VIS, V12363, P208, DOI 10.1007/978-3-030- 58523-5-13
   Ahmad Harris A., 2014, Medical Imaging in Clinical Trials, P3, DOI [DOI 10.1007/978-1-84882-710-3_1, 10.1007/978-1-84882-710-3_1]
   AlGhamdi M, 2020, IEEE T MED IMAGING, V39, P3240, DOI 10.1109/TMI.2020.2989737
   Ali S, 2019, Endoscopy artifact detection (EAD 2019) challenge dataset
   Amini Z, 2016, CURR MED IMAGING, V12, P130, DOI 10.2174/1573394711666150827203543
   [Anonymous], LABELME IMAGE POLYGO
   [Anonymous], 2018, ARXIV180403270
   Aote SS, 2019, MULTIMED TOOLS APPL, V78, P14465, DOI 10.1007/s11042-018-6826-3
   Araújo T, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177544
   Bain M, 2019, IEEE INT CONF COMP V, P236, DOI 10.1109/ICCVW.2019.00032
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Barrile V, 2019, POINT CLOUD SEGMENTA
   Belko A., 2020, ARXIV200408606
   Bernal J, 2019, INT J COMPUT ASS RAD, V14, P191, DOI 10.1007/s11548-018-1864-x
   Besson FL, 2018, RADIOLOGY, V288, P277, DOI 10.1148/radiol.2018171756
   Betti A., 2020, ARXIV200300800
   Bianco S, 2015, COMPUT VIS IMAGE UND, V131, P88, DOI 10.1016/j.cviu.2014.06.015
   Billheimer J, 2019, SCREEN CLASSIC, P59
   Biresaw TA, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P295, DOI 10.1109/AVSS.2016.7738055
   Brehar R, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20113085
   Bromiley PA, 2014, FRONT ZOOL, V11, DOI 10.1186/s12983-014-0061-1
   Candemir S, 2014, IEEE T MED IMAGING, V33, P577, DOI 10.1109/TMI.2013.2290491
   Cassidy B., 2020, ARXIV200411853
   Chaichulee S, 2018, PROC SPIE, V10501, DOI 10.1117/12.2289759
   Chen J, 2020, IEEE ACCESS, V8, P103772, DOI 10.1109/ACCESS.2020.2999198
   Chen Y., 2019, THESIS PURDUE U
   Chen Y, 2020, IEEE ACCESS, V8, P93527, DOI 10.1109/ACCESS.2020.2993953
   Choi BK, 2020, CURR MED IMAGING, V16, P27, DOI 10.2174/1573405615666191021123854
   Christensen JH., 2020, ARXIV200609034
   Chunge Li, 2020, 2020 IEEE 5th Information Technology and Mechatronics Engineering Conference (ITOEC). Proceedings, P633, DOI 10.1109/ITOEC49072.2020.9141557
   Ciaparrone G, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9206854
   Dargan S, 2020, EXPERT SYST APPL, V143, DOI 10.1016/j.eswa.2019.113114
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Dasiopoulou S, 2011, LECT NOTES ARTIF INT, V6050, P196, DOI 10.1007/978-3-642-20795-2_8
   Deeba F, 2017, IEEE J TRANSL ENG HE, V5, DOI 10.1109/JTEHM.2017.2691339
   Dhieb N, 2019, INT C MICROELECTRON, P300, DOI [10.1109/ICM48031.2019.9021862, 10.1109/icm48031.2019.9021862]
   Dias PA, 2019, IEEE WINT CONF APPL, P21, DOI 10.1109/WACV.2019.00010
   Dondi C, 2020, USE REUSE PRINTED IL
   Dong XY, 2018, PROC CVPR IEEE, P379, DOI 10.1109/CVPR.2018.00047
   Dutta A, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2276, DOI 10.1145/3343031.3350535
   Ezhilarasi R., 2018, 2018 2nd International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), P388, DOI 10.1109/I-SMAC.2018.8653705
   Fedorov A, 2012, MAGN RESON IMAGING, V30, P1323, DOI 10.1016/j.mri.2012.05.001
   François T, 2020, INT J COMPUT ASS RAD, V15, P1177, DOI 10.1007/s11548-020-02151-w
   Fukuda M, 2020, ARXIV200801251
   Gambella C, 2021, EUR J OPER RES, V290, P807, DOI 10.1016/j.ejor.2020.08.045
   Gang Sha, 2020, 2020 Proceedings of IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA), P235, DOI 10.1109/ICAICA50127.2020.9182582
   Gaonkar B., 2018, ARXIV181001621
   Gaur Eshan, 2018, 2018 International Conference on Advances in Computing, Communication Control and Networking (ICACCCN). Proceedings, P911, DOI 10.1109/ICACCCN.2018.8748669
   Gentil M, 2016, P 3 INT MED IM COMP
   Ghanem S, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P236, DOI 10.1145/3316782.3321534
   Ghosh KK, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114485
   Gillespie D, 2019, J NEUROSCI METH, V328, DOI 10.1016/j.jneumeth.2019.108440
   Gou M, 2019, LECT NOTES COMPUT SC, V11902, P519, DOI 10.1007/978-3-030-34110-7_43
   Guohua Zhu, 2020, 2020 International Conference on Artificial Intelligence in Information and Communication (ICAIIC), P070, DOI 10.1109/ICAIIC48513.2020.9065216
   Gupta S, 2021, VISUAL COMPUT, V37, P447, DOI 10.1007/s00371-020-01814-8
   Gupte T., 2021, DEEP LEARNING MODELS
   Gurari D, 2015, IEEE WINT CONF APPL, P1169, DOI 10.1109/WACV.2015.160
   Hadush S, 2020, ARXIV200307911
   Hahn S, 2019, I S BIOMED IMAGING, P759, DOI [10.1109/isbi.2019.8759187, 10.1109/ISBI.2019.8759187]
   Haider M. U. C. J. A., 2020, EPIC SERIES COMPUTIN, V69, P372, DOI 10.29007/67kk
   Heath M, 2001, IWDM 2000: 5TH INTERNATIONAL WORKSHOP ON DIGITAL MAMMOGRAPHY, P212
   Hidayatullah P, 2019, 2019 5TH INTERNATIONAL CONFERENCE ON SCIENCE ININFORMATION TECHNOLOGY (ICSITECH), P211, DOI [10.1109/ICSITech46713.2019.8987471, 10.1109/icsitech46713.2019.8987471]
   Hong J., 2020, Trashcan: A semantically-segmented dataset towards visual detection of marine debris
   Hosseini SMH, 2021, PRO BIOMED OPT IMAG, V11317, DOI 10.1117/12.2567454
   Hu K, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102352
   Huang JW, 2020, SPINE J, V20, P590, DOI 10.1016/j.spinee.2019.11.010
   Iakovidis DK, 2014, SCI WORLD J, DOI 10.1155/2014/286856
   Iakovidis DK, 2015, IEEE ENG MED BIO, P731, DOI 10.1109/EMBC.2015.7318466
   Iakovidis DK, 2014, IEEE IMAGE PROC, P2236, DOI 10.1109/ICIP.2014.7025453
   Iakovidis DK, 2014, GASTROINTEST ENDOSC, V80, P877, DOI 10.1016/j.gie.2014.06.026
   Iglovikov VI, 2018, LECT NOTES COMPUT SC, V11045, P300, DOI 10.1007/978-3-030-00889-5_34
   Intel, 2018, COMP VIS ANN TOOL CV
   Jamtsho Y, 2020, ICT EXPRESS, V6, P121
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Joel B-G, 2019, LAT AM HIGH PERF COM, P398
   Kasban H., 2015, Int. J. Inf. Sci. Intell. Syst., V4, P37
   Kaur P, 2019, MULTIMED TOOLS APPL, V78, P19905, DOI 10.1007/s11042-019-7327-8
   Kawamura R., 2017, RECTLABEL APPL ANNOT
   Kawazoe Y, 2018, J IMAGING, V4, DOI 10.3390/jimaging4070091
   Khaki S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092721
   Kim JY, 2019, COMPUT METH PROG BIO, V182, DOI 10.1016/j.cmpb.2019.105063
   Kondal S, 2020, ARXIV200408572
   Kordon Florian, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P671, DOI 10.1007/978-3-030-59725-2_65
   Koulaouzidis A, 2017, ENDOSC INT OPEN, V5, pE477, DOI 10.1055/s-0043-105488
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Kumar Munish, 2020, ACM Digital Government: Research and Practice, V1, DOI 10.1145/3411760
   Kummerfeld Jonathan K., 2019, ARXIV190708236
   Larobina M, 2014, J DIGIT IMAGING, V27, P200, DOI 10.1007/s10278-013-9657-9
   Lee EJ, 2019, HEALTHC TECHNOL LETT, V6, P231, DOI 10.1049/htl.2019.0083
   Lee SK., 2020, THESIS S DAKOTA STAT
   Liu F, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101793
   Liu YL, 2020, BMC OPHTHALMOL, V20, DOI 10.1186/s12886-020-01553-3
   Lynnette NHX, 2020, ARXIV200802421
   Macarini LAB, 2020, ARXIV200208331
   Mallissery S., 2020, P 15 ACM ASIA C COMP, DOI [10.1145/3320269.3405437, DOI 10.1145/3320269.3405437]
   Mansoor A, 2016, IEEE T MED IMAGING, V35, P1856, DOI 10.1109/TMI.2016.2535222
   Marzahl C, 2019, ARXIV191200142
   Microsoft, 2019, VOTT VIS OBJ TAGG TO
   Miok K., 2020, ARXIV201014872
   Moehrmann J., 2012, P 1 INT WORKSH VIS I, P1
   Müller M, 2020, MUSCLE NERVE, V61, P600, DOI 10.1002/mus.26827
   Nakasi R, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-3000-0
   Neves M, 2014, BRIEF BIOINFORM, V15, P327, DOI 10.1093/bib/bbs084
   Nobis F, 2019, 2019 SYMPOSIUM ON SENSOR DATA FUSION: TRENDS, SOLUTIONS, APPLICATIONS (SDF 2019), DOI 10.1109/sdf.2019.8916629
   Nowak S., 2010, P INT C MULT INF RET, P557, DOI [10.1145/1743384.1743478, DOI 10.1145/1743384.1743478]
   Ohee MNS., 2020, INT J COMPUTER APPL, V975, P8887
   Park A, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.5600
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Prado E, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12152466
   Qi Dou, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P149, DOI 10.1007/978-3-319-46723-8_18
   Rahim T., 2020, ARXIV PREPRINT ARXIV
   Rajaraman S, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0242301
   Rasoulian A, 2013, PROC SPIE, V8671, DOI 10.1117/12.2007448
   Ray Susmita, 2019, 2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon), P35, DOI 10.1109/COMITCon.2019.8862451
   Rebinth A., 2019, J ADV RES DYNAMICAL, V10, P1880
   Rella S., 2020, THESIS
   Roihan Ahmad, 2020, Journal of Physics: Conference Series, V1477, DOI 10.1088/1742-6596/1477/3/032012
   Roth HR, 2015, LECT NOTES COMPUT SC, V9349, P556, DOI 10.1007/978-3-319-24553-9_68
   Roth HR, 2020, ARXIV200911988
   Roy S, 2020, IEEE T MED IMAGING, V39, P2676, DOI 10.1109/TMI.2020.2994459
   Rubin DL, 2019, TOMOGRAPHY, V5, P170, DOI 10.18383/j.tom.2018.00055
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Rusu M, 2017, EUR RADIOL, V27, P4209, DOI 10.1007/s00330-017-4813-0
   Sánchez JCG, 2020, PHYS MEDICA, V69, P241, DOI 10.1016/j.ejmp.2019.12.014
   Sharma M, 2019, Labelbox: The best way to create and manage training data
   Shen J, 2016, EUR J RADIOL, V85, P1613, DOI 10.1016/j.ejrad.2016.06.006
   Siam M, 2019, IEEE INT CONF ROBOT, P50, DOI [10.1109/ICRA.2019.8794254, 10.1109/icra.2019.8794254]
   Silva Joed Lopes, 2020, Image Analysis and Recognition. 17th International Conference, ICIAR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12131), P356, DOI 10.1007/978-3-030-50347-5_31
   Singh P, 2019, INT C COMP VIS IM PR, P373
   Singh S, 2021, MULTIMED TOOLS APPL, V80, P19753, DOI 10.1007/s11042-021-10711-8
   Sirazitdinov I, 2020, ARXIV201000907
   Song T, 2019, IEEE ACCESS, V7, P166823, DOI 10.1109/ACCESS.2019.2953934
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Sun CJ, 2017, ARTIF INTELL MED, V83, P58, DOI 10.1016/j.artmed.2017.03.008
   Systems D, 2017, SUPERVISELY WEB PLAT
   Tang H, 2020, SEGMENTATION MODEL O
   Tolkachev A., 2020, IEEE J BIOMED HEALTH
   Ullah H, 2017, NEUROCOMPUTING, V242, P28, DOI 10.1016/j.neucom.2017.02.023
   Vats V, 2020, ARXIV200901179
   Vickery S, 2020, ELIFE, V9, DOI 10.7554/eLife.60136
   Vlontzos A., 2018, BRIT MACH VIS C
   Vostrikov Anton, 2019, Intelligent Decision Technologies 2019. Proceedings of the 11th KES International Conference on Intelligent Decision Technologies (KES-IDT 2019). Smart Innovation, Systems and Technologies (SIST 143), P145, DOI 10.1007/978-981-13-8303-8_13
   Wang F, 2019, IEEE I CONF COMP VIS, P5451, DOI 10.1109/ICCV.2019.00555
   Wei JW, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.3398
   Weinstein B, 2020, ECOL INFORM, V56, DOI 10.1016/j.ecoinf.2020.101061
   Weinstein BG, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111309
   Xian ZC, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/8858344
   Xie MY, 2019, IEEE INT C BIOINFORM, P2393, DOI 10.1109/BIBM47256.2019.8982980
   Xu XW, 2020, ENGINEERING-PRC, V6, P1122, DOI 10.1016/j.eng.2020.04.010
   Yang J., 2017, P ACL 2018 SYSTEM DE, DOI [10.18653/v1/P18-4006, DOI 10.18653/V1/P18-4006]
   Yi X, 2018, ARXIV180403700
   Yu C.W., 2019, 2019 IEEE 13 INT S, P1, DOI DOI 10.1109/MCSoC.2019.00008
   Yudin DA, 2019, OPT MEMORY NEURAL, V28, P283, DOI 10.3103/S1060992X19040118
   Yushkevich PA, 2019, NEUROINFORMATICS, V17, P83, DOI 10.1007/s12021-018-9385-x
   Yushkevich PA, 2016, IEEE ENG MED BIO, P3342, DOI 10.1109/EMBC.2016.7591443
   Zadeh SM, 2020, SURG ENDOSC, V34, P5377, DOI 10.1007/s00464-019-07330-8
   Zaki G, 2020, CYTOM PART A, V97, P1248, DOI 10.1002/cyto.a.24257
   Zhang C., 2018, ARXIV180906461
   Zhang F, 2019, MED PHYS, V46, P1300, DOI 10.1002/mp.13394
   Zhe L, 2018, PROC CVPR IEEE, P8290, DOI 10.1109/CVPR.2018.00865
NR 161
TC 19
Z9 20
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25877
EP 25911
DI 10.1007/s11042-022-12100-1
EA MAR 2022
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000773206100008
PM 35350630
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Deng, XY
   Yang, YH
   Zhang, H
   Ma, YD
AF Deng, Xiangyu
   Yang, Yahan
   Zhang, Huan
   Ma, Yide
TI PCNN double step firing mode for image edge detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Working characteristics of PCNN; Double step firing; Parameter
   constraint condition; Neighborhood template design; Image edge detection
ID ALGORITHM; SEGMENTATION; FEATURES
AB Pulse-coupled Neural Network (PCNN) is a third-generation artificial neural network that requires no training. Neurons in PCNN have two pulse burst modes: firing mode and fire-extinguishing mode. A lot of research has been conducted on achieving image segmentation using the fire-extinguishing mode, yet remains deficient on the characteristics and applications of the firing mode. Through analysis of the firing process of PCNN, we find that the network that works only on the firing mode has the characteristic of image edge detection. Then, we give a mathematical expression for the neuron firing time, and, using the expression, propose an image edge detection algorithm based on the characteristic of PCNN double step firing. Then, we analyze the parameter constraints for achieving PCNN double step firing and provide a method for the self-adaptive setting of the network parameters. To achieve the best edge detection, we conduct mathematical analysis on the relationship between edge detection performance and neighbor coupling, and provide a neighbor template structure and the setting of its values. Our results show that the proposed algorithm can obtain smooth and unbroken single pixels edges, and has nice robustness and efficiency for various kinds of images.
C1 [Deng, Xiangyu; Yang, Yahan; Zhang, Huan] Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Gansu, Peoples R China.
   [Ma, Yide] Lanzhou Univ, Sch Informat Sci & Engn, Lanzhou 730000, Gansu, Peoples R China.
C3 Northwest Normal University - China; Lanzhou University
RP Deng, XY (corresponding author), Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Gansu, Peoples R China.
EM dengxy000@126.com
OI deng, xiangyu/0000-0002-5007-6797
FU National Natural Science Foundation of China [61961037]; Industrial
   Support Plan of Education Department of Gansu Province [2021CYZC-30]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61961037), and the Industrial Support Plan of Education
   Department of Gansu Province (No. 2021CYZC-30)
CR ABDOU IE, 1979, P IEEE, V67, P753, DOI 10.1109/PROC.1979.11325
   ALAM M, 2020, MICROWAVE OPTICAL TE, V6
   Biswas R, 2012, PROC TECH, V4, P820, DOI 10.1016/j.protcy.2012.05.134
   Chacon MMI, 2008, IEEE IJCNN, P463, DOI 10.1109/IJCNN.2008.4633833
   Chang CY, 2006, OPT ENG, V45, DOI 10.1117/1.2185488
   Chen RB, 2012, PHYSCS PROC, V24, P1350, DOI 10.1016/j.phpro.2012.02.201
   Deng X., 2012, AUTOM INSTRUMENT, DOI [10.3969/j.issn.1001-9227.2012.03.054, DOI 10.3969/J.ISSN.1001-9227.2012.03.054]
   Deng XY, 2020, IEEE T NEUR NET LEAR, V31, P488, DOI 10.1109/TNNLS.2019.2905113
   Deng XY, 2016, PATTERN RECOGN LETT, V79, P8, DOI 10.1016/j.patrec.2016.04.019
   Deng XY, 2014, CHINESE J ELECTRON, V23, P97
   [邓翔宇 Deng Xiangyu], 2012, [电子学报, Acta Electronica Sinica], V40, P955
   Eckhorn R, 1990, NEURAL COMPUT, V2, P293, DOI 10.1162/neco.1990.2.3.293
   Elaraby WS., 2017, 2017 29 INT C MICR I
   Elons AS, 2013, APPL SOFT COMPUT, V13, P1646, DOI 10.1016/j.asoc.2012.11.036
   He YB, 2018, INT J MOD PHYS C, V29, DOI 10.1142/S0129183118500079
   Johnson JL, 1999, IEEE T NEURAL NETWOR, V10, P480, DOI 10.1109/72.761706
   Kozik R, 2018, J PARALLEL DISTR COM, V119, P18, DOI 10.1016/j.jpdc.2018.03.006
   Kun Zhang, 2018, Procedia Computer Science, V131, P243, DOI 10.1016/j.procs.2018.04.209
   Li W, 2005, PROCEEDINGS OF 2005 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-9, P5297
   Liang Zhou, 2008, WSEAS Transactions on Computers, V7, P184
   Lin WC, 2018, BIOMED SIGNAL PROCES, V39, P294, DOI 10.1016/j.bspc.2017.08.011
   Liu XC, 2015, OPT COMMUN, V353, P147, DOI 10.1016/j.optcom.2015.05.019
   Liu Y, 2019, IEEE T PATTERN ANAL, V41, P1939, DOI 10.1109/TPAMI.2018.2878849
   Lu SW, 2003, PATTERN RECOGN, V36, P2395, DOI 10.1016/S0031-3203(03)00083-9
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Medina-Carnicer R, 2011, PATTERN RECOGN LETT, V32, P676, DOI 10.1016/j.patrec.2010.12.012
   Mohammed MM, 2015, EXPERT SYST APPL, V42, P4927, DOI 10.1016/j.eswa.2015.02.019
   Orujov F, 2020, APPL SOFT COMPUT, V94, DOI 10.1016/j.asoc.2020.106452
   Qu YD, 2005, IMAGE VISION COMPUT, V23, P11, DOI 10.1016/j.imavis.2004.07.003
   Qu Z, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/2641516
   Rajathilagam B, 2017, PATTERN RECOGN, V67, P1, DOI 10.1016/j.patcog.2017.01.028
   Ray K, 2013, PATTERN RECOGN, V46, P2067, DOI 10.1016/j.patcog.2013.01.029
   Ren WQ, 2020, INT J COMPUT VISION, V128, P240, DOI 10.1007/s11263-019-01235-8
   Ren WQ, 2019, IEEE T IMAGE PROCESS, V28, P4364, DOI 10.1109/TIP.2019.2910412
   Shang LF, 2007, NEUROCOMPUTING, V70, P1096, DOI 10.1016/j.neucom.2006.08.006
   Sharma B., 2015, INT J ADVANC SCI RES, V1, P346, DOI [10.1002/gepi.20609, DOI 10.1002/GEPI.20609]
   Sheela CJJ, 2020, MULTIMED TOOLS APPL, V79, P17483, DOI 10.1007/s11042-020-08636-9
   Song Y., 2019, ACTA MICROSCOPICA, V28, P30
   Soni R, 2019, APPL INTELL, V49, P1376, DOI 10.1007/s10489-018-1338-4
   Sun GY, 2007, PATTERN RECOGN, V40, P2766, DOI 10.1016/j.patcog.2007.01.006
   Sun JX, 2004, PATTERN RECOGN, V37, P1315, DOI 10.1016/j.patcog.2003.11.006
   Tan Ying-fang, 2009, Computer Engineering and Applications, V45, P174, DOI 10.3778/j.issn.1002-8331.2009.12.056
   Tang XL, 2014, 2014 11TH INTERNATIONAL COMPUTER CONFERENCE ON WAVELET ACTIVE MEDIA TECHNOLOGY AND INFORMATION PROCESSING (ICCWAMTIP), P169, DOI 10.1109/ICCWAMTIP.2014.7073383
   Vasavada J., 2013, INT J COMPUT APPL, V67, P22, DOI [10.5120/11368-6627, DOI 10.5120/11368-6627]
   Verma OP, 2011, PATTERN RECOGN LETT, V32, P1187, DOI 10.1016/j.patrec.2011.03.008
   Wang ZB, 2010, PATTERN RECOGN, V43, P2003, DOI 10.1016/j.patcog.2010.01.011
   Wu CD, 2018, OPTIK, V157, P914, DOI 10.1016/j.ijleo.2017.11.171
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yang Y., 2014, ELECTRON J GEOTECH E, V19, P10111
   Zhang YD, 2010, SCI CHINA INFORM SCI, V53, P1963, DOI 10.1007/s11432-010-4075-9
   Zheng S, 2004, PATTERN RECOGN LETT, V25, P1143, DOI 10.1016/j.patrec.2004.03.009
NR 51
TC 8
Z9 9
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27187
EP 27213
DI 10.1007/s11042-022-12725-2
EA MAR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000772288200005
DA 2024-07-18
ER

PT J
AU Gomaa, A
   Minematsu, T
   Abdelwahab, MM
   Abo-Zahhad, M
   Taniguchi, R
AF Gomaa, Ahmed
   Minematsu, Tsubasa
   Abdelwahab, Moataz M.
   Abo-Zahhad, Mohammed
   Taniguchi, Rin-ichiro
TI Faster CNN-based vehicle detection and counting strategy for fixed
   camera scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vehicle detection and counting; Convolution neural network; Fixed
   camera; Faster R-CNN; YOLOv2; Featue point analysis
ID TRACKING
AB Automatic detection and counting of vehicles in a video is a challenging task and has become a key application area of traffic monitoring and management. In this paper, an efficient real-time approach for the detection and counting of moving vehicles is presented based on YOLOv2 and features point motion analysis. The work is based on synchronous vehicle features detection and tracking to achieve accurate counting results. The proposed strategy works in two phases; the first one is vehicle detection and the second is the counting of moving vehicles. Different convolutional neural networks including pixel by pixel classification networks and regression networks are investigated to improve the detection and counting decisions. For initial object detection, we have utilized state-of-the-art faster deep learning object detection algorithm YOLOv2 before refining them using K-means clustering and KLT tracker. Then an efficient approach is introduced using temporal information of the detection and tracking feature points between the framesets to assign each vehicle label with their corresponding trajectories and truly counted it. Experimental results on twelve challenging videos have shown that the proposed scheme generally outperforms state-of-the-art strategies. Moreover, the proposed approach using YOLOv2 increases the average time performance for the twelve tested sequences by 93.4% and 98.9% from 1.24 frames per second achieved using Faster Region-based Convolutional Neural Network (F R-CNN ) and 0.19 frames per second achieved using the background subtraction based CNN approach (BS-CNN ), respectively to 18.7 frames per second.
C1 [Gomaa, Ahmed] Natl Res Inst Astron & Geophys NRIAG, Helwan 11421, Egypt.
   [Minematsu, Tsubasa; Taniguchi, Rin-ichiro] Kyushu Univ, Sch Informat Sci & Elect Engn, Nishi Ku, 744 Motooka, Fukuoka 8190395, Japan.
   [Abdelwahab, Moataz M.; Abo-Zahhad, Mohammed] Egypt Japan Univ Sci & Technol, Elect & Commun Engn Dept, Alexandria 21934, Egypt.
   [Abo-Zahhad, Mohammed] Assiut Univ, Fac Engn, Elect & Elect Engn Dept, Assiut 71511, Egypt.
C3 Egyptian Knowledge Bank (EKB); National Research Institute of Astronomy
   & Geophysics - NRIAG; Kyushu University; Egyptian Knowledge Bank (EKB);
   Egypt-Japan University of Science & Technology; Egyptian Knowledge Bank
   (EKB); Assiut University
RP Gomaa, A (corresponding author), Natl Res Inst Astron & Geophys NRIAG, Helwan 11421, Egypt.
EM ahmed.gomaa@nriag.sci.eg
RI Gomaa, Ahmed/W-9060-2019
OI Gomaa, Ahmed/0000-0003-0130-9088
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Bochkovskiy A., 2020, PREPRINT
   Bouguet, 2001, INTEL CORP, V5, P4, DOI DOI 10.1109/HPDC.2004.1323531
   Chen DY, 2013, IET COMPUT VIS, V7, P81, DOI 10.1049/iet-cvi.2012.0088
   Chen Y, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092686
   Chmiel W, 2016, MULTIMED TOOLS APPL, V75, P10529, DOI 10.1007/s11042-016-3367-5
   Doulamis ND, 2014, IEEE T COMPUT, V63, P461, DOI 10.1109/TC.2012.222
   Doulamis ND, 2010, MULTIMED TOOLS APPL, V50, P173, DOI 10.1007/s11042-009-0370-0
   Farag W, 2019, ADV VEHICLE DETECTIO
   Fu WN, 2016, MULTIMED TOOLS APPL, V75, P13001, DOI 10.1007/s11042-014-2391-6
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gomaa A, 2020, MULTIMED TOOLS APPL, V79, P26023, DOI 10.1007/s11042-020-09242-5
   Gomaa A, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19204588
   Gomaa A, 2018, MIDWEST SYMP CIRCUIT, P222, DOI 10.1109/MWSCAS.2018.8624022
   Guerrero-Gomez-Olmedo Ricardo, 2013, Natural and Artificial Computation in Engineering and Medical Applications. 5th International Work-Conference on the Interplay Between Natural and Artificial Computation, IWINAC 2013. Proceedings: LNCS 7931, P306, DOI 10.1007/978-3-642-38622-0_32
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Karim S, 2019, MULTIMED TOOLS APPL, V78, P32565, DOI 10.1007/s11042-019-08033-x
   Kasturi R, 2009, IEEE T PATTERN ANAL, V31, P319, DOI 10.1109/TPAMI.2008.57
   Li S, 2020, IET INTELL TRANSP SY
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Minematsu T, 2018, J IMAGING, V4, DOI 10.3390/jimaging4060078
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Peng G.S., 2019, Performance and Accuracy Analysis in Object Detection
   Quesada J, 2016, IEEE IMAGE PROC, P3822, DOI 10.1109/ICIP.2016.7533075
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Santos AM, 2020, SIBGRAPI, P69, DOI 10.1109/SIBGRAPI51738.2020.00018
   Shakeri M, 2016, COMPUT VIS IMAGE UND, V146, P27, DOI 10.1016/j.cviu.2016.02.009
   Sheorey S, 2015, LECT NOTES COMPUT SC, V9009, P475, DOI 10.1007/978-3-319-16631-5_35
   Song HS, 2019, EUR TRANSP RES REV, V11, DOI 10.1186/s12544-019-0390-4
   Tang Y, 2017, MULTIMED TOOLS APPL, V76, P5817, DOI 10.1007/s11042-015-2520-x
   Wang Y, 2014, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2014.126
   Wen L., 2015, ARXIV PREPRINT ARXIV, V2, P7
   Yang B, 2017, IET INTELL TRANSP SY, V11, P76, DOI [10.1049/iet-its.2017.0047, 10.1049/iet-its.2016.0084]
   Yang Z, 2018, IMAGE VISION COMPUT, V69, P143, DOI 10.1016/j.imavis.2017.09.008
   Zeng DD, 2018, IEEE ACCESS, V6, P16010, DOI 10.1109/ACCESS.2018.2817129
   Zhang YS, 2016, IET INTELL TRANSP SY, V10, P445, DOI 10.1049/iet-its.2015.0141
   Zhu XF, 2019, IEEE T KNOWL DATA EN, V31, P2022, DOI 10.1109/TKDE.2018.2873378
   Zhu XF, 2019, IEEE T KNOWL DATA EN, V31, P1532, DOI 10.1109/TKDE.2018.2858782
NR 42
TC 25
Z9 26
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25443
EP 25471
DI 10.1007/s11042-022-12370-9
EA MAR 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000772288200007
OA hybrid
DA 2024-07-18
ER

PT J
AU Peyvandi, A
   Majidi, B
   Peyvandi, S
   Patra, JC
AF Peyvandi, Amirhossein
   Majidi, Babak
   Peyvandi, Soodeh
   Patra, Jagdish C.
TI Privacy-preserving federated learning for scalable and high data quality
   computational-intelligence-as-a-service in Society 5.0
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Federated learning; Blockchain; Privacy preserving; Decentralized
   machine learning; Data as a service; Society 5; 0
AB Training supervised machine learning models like deep learning requires high-quality labelled datasets that contain enough samples from various categories and specific cases. The Data as a Service (DaaS) can provide this high-quality data for training efficient machine learning models. However, the issue of privacy can minimize the participation of the data owners in DaaS provision. In this paper, a blockchain-based decentralized federated learning framework for secure, scalable, and privacy-preserving computational intelligence, called Decentralized Computational Intelligence as a Service (DCIaaS), is proposed. The proposed framework is able to improve data quality, computational intelligence quality, data equality, and computational intelligence equality for complex machine learning tasks. The proposed framework uses the blockchain network for secure decentralized transfer and sharing of data and machine learning models on the cloud. As a case study for multimedia applications, the performance of DCIaaS framework for biomedical image classification and hazardous litter management is analysed. Experimental results show an increase in the accuracy of the models trained using the proposed framework compared to decentralized training. The proposed framework addresses the issue of privacy-preserving in DaaS using the distributed ledger technology and acts as a platform for crowdsourcing the training process of machine learning models.
C1 [Peyvandi, Amirhossein; Majidi, Babak] Khatam Univ, Dept Comp Engn, Tehran, Iran.
   [Majidi, Babak] York Univ, Fac Liberal Arts & Profess Studies, Emergency & Rapid Response Simulat ADERSIM Artifi, Toronto, ON, Canada.
   [Peyvandi, Soodeh] Univ Appl Sci Upper Austria, Proc Management & Business Intelligence, Steyr, Austria.
   [Patra, Jagdish C.] Swinburne Univ Technol, Fac Sci Engn & Technol, Melbourne, Vic, Australia.
C3 York University - Canada; Swinburne University of Technology
RP Majidi, B (corresponding author), Khatam Univ, Dept Comp Engn, Tehran, Iran.; Majidi, B (corresponding author), York Univ, Fac Liberal Arts & Profess Studies, Emergency & Rapid Response Simulat ADERSIM Artifi, Toronto, ON, Canada.
EM b.majidi@khatam.ac.ir
RI Majidi, Babak/AAB-2365-2019; Patra, Jagdish C/J-4895-2016
OI Majidi, Babak/0000-0001-6309-6407; 
CR Abbasi MH, 2019, 2019 IEEE 5TH CONFERENCE ON KNOWLEDGE BASED ENGINEERING AND INNOVATION (KBEI 2019), P292, DOI 10.1109/KBEI.2019.8735033
   Abdellatif T, 2018, INT CONF NEW TECHNOL
   Aledhari M, 2020, IEEE ACCESS, V8, P140699, DOI [10.1109/access.2020.3013541, 10.1109/ACCESS.2020.3013541]
   Alt L., 2018, INT S LEV APPL FORM
   Bai X., 2018, P 2018 7 INT C SOFTW
   Baldominos A, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21080723
   Beillahi SM, 2020, P 41 ACM SIGPLAN C P
   Bigi G, 2015, LECT NOTES COMPUT SC, V9465, P142, DOI 10.1007/978-3-319-25527-9_11
   Blanchard P, 2017, P 31 INT C NEUR INF
   Borkowski AA, 2019, Lung and Colon Cancer Histopathological Image Dataset (LC25000)
   Brakerski Zvika, 2014, ACM Transactions on Computation Theory, V6, DOI 10.1145/2633600
   Briggs C., 2021, Federated Learning Systems, P21
   Brisimi TS, 2018, INT J MED INFORM, V112, P59, DOI 10.1016/j.ijmedinf.2018.01.007
   Cabrero-Holgueras Jose, 2021, Proceedings on Privacy Enhancing Technologies, V2021, P139, DOI 10.2478/popets-2021-0064
   Dias JP, 2018, ARXIV PREPRINT ARXIV
   Dwork C, 2013, FOUND TRENDS THEOR C, V9, P211, DOI 10.1561/0400000042
   Entriken, INTRO SMART CONTRACT
   Fadaeddini A, 2020, J SUPERCOMPUT, V76, P10354, DOI 10.1007/s11227-020-03251-9
   Ge S, 2020, ARXIV PREPRINT ARXIV
   Gilad Y, 2017, PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '17), P51, DOI 10.1145/3132747.3132757
   Goel A, 2019, IEEE COMPUT SOC CONF, P2821, DOI 10.1109/CVPRW.2019.00341
   Hajdu, 2019, WORK C VER SOFTW THE
   Hasan HR, 2018, IEEE ACCESS, V6, P65439, DOI 10.1109/ACCESS.2018.2876971
   Hitaj B, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P603, DOI 10.1145/3133956.3134012
   Kaissis GA, 2020, NAT MACH INTELL, V2, P305, DOI 10.1038/s42256-020-0186-1
   Karki D., CAN YOU GUESS MUCH D
   Kasiviswanathan SP, 2014, J PRIV CONFID, V6
   Keydana, RSTUDIO BLOG HACK DE
   Khan LU, 2021, IEEE COMMUN SURV TUT, V23, P1759, DOI 10.1109/COMST.2021.3090430
   Kim JMJ, 2014, STELLAR
   Konecny J, 2016, ARXIV161005492
   Kumar R, 2021, BLOCKCHAIN BASED PRI
   Kuo T.-T., 2018, ModelChain: Decentralized Privacy-Preserving Healthcare Predictive Modeling Framework on Private Blockchain Networks
   Li T, 2020, IEEE SIGNAL PROC MAG, V37, P50, DOI 10.1109/MSP.2020.2975749
   Liu B., 2020, ARXIV PREPRINT ARXIV
   Majidi B., 2021, ENABLING APPL DATA S, P471, DOI [10.1007/978-3-030-52067-0_21, DOI 10.1007/978-3-030-52067-0_21]
   Mallaki M, 2021, INT J COMPUT APPL, P1
   McMahan H.B., 2017, Artificial intelligence and statistics
   McMahan H. Brendan, 2018, ARXIV181206210
   Melis L., 2018, Exploiting unintended feature leakage in collaborative learning
   Menezes A. J., 2018, HDB APPL CRYPTOGRAPH, DOI DOI 10.1201/9780429466335
   Naz M, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11247054
   Nguyen HT, 2021, IEEE J SEL AREA COMM, V39, P201, DOI 10.1109/JSAC.2020.3036952
   Norouzi A, 2018, 2018 9TH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), P221, DOI 10.1109/ISTEL.2018.8660986
   Peyvandi A, 2021, N GENER COMPUT, P1
   Peyvandi A., 2022, COMPUTATIONAL INTELL, P405, DOI [10.1007/978-981-16-3783-4_19, DOI 10.1007/978-981-16-3783-4_19]
   Phong LT, 2018, IEEE T INF FOREN SEC, V13, P1333, DOI 10.1109/TIFS.2017.2787987
   Rajendran S, 2021, JCO CLIN CANCER INFO, V5, P1, DOI 10.1200/CCI.20.00060
   Shayan M, 2018, ARXIV PREPRINT ARXIV
   Sheller MJ, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-69250-1
   Shokri R, 2017, P IEEE S SECUR PRIV, P3, DOI 10.1109/SP.2017.41
   Shokri R, 2015, ANN ALLERTON CONF, P909, DOI 10.1109/ALLERTON.2015.7447103
   Song CZ, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P587, DOI 10.1145/3133956.3134077
   Tan MX, 2019, PR MACH LEARN RES, V97
   Weng JS, 2021, IEEE T DEPEND SECURE, V18, P2438, DOI 10.1109/TDSC.2019.2952332
   Yang Z, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2369
   Zhang C, 2021, KNOWL-BASED SYST, V216, DOI 10.1016/j.knosys.2021.106775
   Zhang WS, 2021, IEEE INTERNET THINGS, V8, P15884, DOI 10.1109/JIOT.2021.3056185
   Zhang Y, 2012, IEEE INFOCOM SER, P2140, DOI 10.1109/INFCOM.2012.6195597
   Zhang YH, 2020, PROC CVPR IEEE, P250, DOI 10.1109/CVPR42600.2020.00033
   Zhao Y, 2021, IEEE INTERNET THINGS, V8, P1817, DOI 10.1109/JIOT.2020.3017377
   Zhou J., 2021, ARXIV PREPRINT ARXIV
   Zhu TQ, 2017, ADV INFORM SECUR, V69, P7, DOI 10.1007/978-3-319-62004-6_2
NR 63
TC 10
Z9 10
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25029
EP 25050
DI 10.1007/s11042-022-12900-5
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000771882300020
PM 35342329
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Li, CB
   Zhou, Z
   Li, HJ
   Xie, ZG
   Zhang, GA
AF Li, Chaobo
   Zhou, Ze
   Li, Hongjun
   Xie, Zhengguang
   Zhang, Guoan
TI A novel vertical-cross-horizontal network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vertical-cross-horizontal network; Vertical operation; Horizontal
   operation; Fuzzy system
ID BROAD LEARNING-SYSTEM; NEURAL-NETWORK; RECOGNITION
AB In order to integrate the ability of feature extraction of deep structure and short training time of broad structure, we propose a novel Vertical-Cross-Horizontal Network (VCHN) for data recognition, which mainly contains vertical operation, horizontal operation, nonlinear mapping and recognition decision. For vertical operation, we design a hierarchical structure, which is responsible for providing structural conditions for features evolution that are significant for classification decision. For horizontal operation, we use the fuzzy system with interpretability to design an expandable group of fuzzy subsystems to extract diverse features as much as possible, trying to replace the high-level features extracted via cascading more hidden layers. In that way, it mitigates the time-consuming burden generated by vertically deepening network blindly. The nonlinear mapping is used to transform extracted features into nonlinear ones, which are utilized to calculate the outputs for recognition decision. Extensive experiments show that the recognition accuracy of proposed method are 99.37% and 98.47% on ORL and EYaleB datasets, respectively. The proposed VCHN can not only mine the discriminative features via vertical operation, but also shorten the training time via the horizontal operation, which outperforms the other methods.
C1 [Li, Chaobo; Zhou, Ze; Li, Hongjun; Xie, Zhengguang; Zhang, Guoan] Nantong Univ, Sch Informat Sci & Technol, 9 Seyuan Rd, Nantong 226019, Jiangsu, Peoples R China.
   [Li, Hongjun] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.
C3 Nantong University; Nanjing University
RP Li, HJ; Xie, ZG (corresponding author), Nantong Univ, Sch Informat Sci & Technol, 9 Seyuan Rd, Nantong 226019, Jiangsu, Peoples R China.; Li, HJ (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.
EM 1811310007@yjs.ntu.edu.cn; 17110040@yjs.ntu.edu.cn;
   lihongjun@ntu.edu.cn; xie_zg@126.com; gzhang@ntu.edu.cn
OI Li, Chaobo/0000-0003-3772-3344; li, hongjun/0000-0001-7500-4979; Zhang,
   Guoan/0000-0001-8439-3478
FU National Natural Science Foundation of China [61971245, 61976120];
   Nanjing University State Key Lab [KFKT2019B15]; Nantong Science and
   Technology Program [JC2021131]; Postgraduate Research and Practice
   Innovation Program of Jiangsu Province [KYCX21_3084]
FX This work is funded by National Natural Science Foundation of China
   (NO.61971245, NO.61976120); Nanjing University State Key Lab. for Novel
   Software Technology (KFKT2019B15); Nantong Science and Technology
   Program of (JC2021131); Postgraduate Research and Practice Innovation
   Program of Jiangsu Province (KYCX21_3084).
CR Alkhasawneh MS, 2018, ARAB J SCI ENG, V43, P6737, DOI 10.1007/s13369-017-2833-3
   Bilenko M., 2004, P INT C MACH LEARN, P11
   Chen C. L. Philip, 2018, IEEE Transactions on Neural Networks and Learning Systems, V29, P10, DOI 10.1109/TNNLS.2017.2716952
   Chen CLP, 2019, IEEE T NEUR NET LEAR, V30, P1191, DOI 10.1109/TNNLS.2018.2866622
   Chen LF, 2020, INFORM SCIENCES, V509, P150, DOI 10.1016/j.ins.2019.09.005
   Chen MZ, 2020, INT WIREL COMMUN, P940, DOI 10.1109/IWCMC48107.2020.9148092
   Chernyshova YS, 2020, IEEE ACCESS, V8, P32587, DOI 10.1109/ACCESS.2020.2974051
   Chu YH, 2020, KNOWL-BASED SYST, V206, DOI 10.1016/j.knosys.2020.106319
   Dumitrescu CM, 2019, I C CONTR SYS COMP S, P216, DOI 10.1109/CSCS.2019.00043
   Fan W, 2021, MEASUREMENT, V185, DOI 10.1016/j.measurement.2021.110040
   Feng S, 2018, IEEE SYS MAN CYBERN, P2230, DOI 10.1109/SMC.2018.00383
   Feng S, 2020, IEEE T CYBERNETICS, V50, P414, DOI 10.1109/TCYB.2018.2857815
   Frank E, 2012, ARXIV12122487
   Gao YB, 2021, IEEE T SYST MAN CY-S, V51, P1981, DOI 10.1109/TSMC.2019.2911726
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hongjun Li, 2020, Pattern Recognition and Artificial Intelligence. International Conference, ICPRAI 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12068), P312, DOI 10.1007/978-3-030-59830-3_27
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Janiesch C, 2021, ELECTRON MARK, V31, P685, DOI 10.1007/s12525-021-00475-2
   Kim H.-C., 2012, INT C ARTIFICIAL INT, P619
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Li HJ, 2020, IEEE ACCESS, V8, P15369, DOI 10.1109/ACCESS.2020.2966667
   Liu Z, 2021, LECT NOTES COMPUT SC, V13019, P55, DOI 10.1007/978-3-030-88004-0_5
   Luo WL, 2020, IEEE CIRC SYST MAG, V20, P65, DOI 10.1109/MCAS.2020.3027222
   Luo XL, 2019, PATTERN RECOGN, V93, P283, DOI 10.1016/j.patcog.2019.04.027
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Mabrouki Rebeh, 2016, 2016 2nd International Conference on Advanced Technologies for Signal and Image Processing (ATSIP), P268, DOI 10.1109/ATSIP.2016.7523112
   Madi S, 2018, P INT C ADV INT SYST, P98
   Marsanova L, 2020, P COMPUTING CARDIOLO, P1
   Moody GA, 2001, IEEE ENG MED BIOL, V20, P45, DOI 10.1109/51.932724
   Newman D., 1998, UCI REPOSITORY MACHI
   Niu JH, 2020, IEEE J BIOMED HEALTH, V24, P1321, DOI 10.1109/JBHI.2019.2942938
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Rakshit RD, 2021, MULTIMED TOOLS APPL, V80, P20733, DOI 10.1007/s11042-021-10745-y
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shi DM, 2021, MULTIMED TOOLS APPL, V80, P23899, DOI 10.1007/s11042-021-10825-z
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   TOLLENAERE T, 1990, NEURAL NETWORKS, V3, P561, DOI 10.1016/0893-6080(90)90006-7
   Wang XH, 2018, IEEE INT C BIOINFORM, P1240, DOI 10.1109/BIBM.2018.8621147
   Wu GD, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE IN INFORMATION AND COMMUNICATION (ICAIIC 2019), P210, DOI [10.1109/ICAIIC.2019.8669019, 10.1109/icaiic.2019.8669019]
   Xu Y, 2014, 2014 9TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP), P336, DOI 10.1109/ISCSLP.2014.6936608
   Yosinski J, 2014, ADV NEUR IN, V27
   Yu Z, 2022, INT J FUZZY SYST, V24, P1170, DOI 10.1007/s40815-020-00979-7
   Zhang T, 2018, IEEE SYS MAN CYBERN, P1898, DOI 10.1109/SMC.2018.00328
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 52
TC 0
Z9 0
U1 3
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21027
EP 21045
DI 10.1007/s11042-022-12639-z
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000770061500014
DA 2024-07-18
ER

PT J
AU Gambhir, M
   Gupta, V
AF Gambhir, Mahak
   Gupta, Vishal
TI Deep learning-based extractive text summarization with word-level
   attention mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Extractive text summarization; Natural language processing; Artificial
   intelligence; Neural networks; Deep learning; Recurrent neural networks;
   Convolution neural networks; Bi-directional gated recurrent unit;
   Attention mechanism
AB With the rise in the amount of textual data over the internet, the demand for summarizing it in a short, readable, easy-to-understand form has increased. Much of the research is being carried out to improve the efficiency of these text summarization systems. In the past, extractive text summarization was mainly carried out through human-crafted features which were unable to learn the semantic information from the text. Therefore, in an attempt to improve the quality of summary, we have designed a neural network-based completely data-driven model for extractive single-document summarization of text which we have termed as WL-AttenSumm. Our proposed model implements a Word-level Attention mechanism that focuses more on the important parts in the input sequence so relevant semantic features are captured at the word-level that helps in selecting significant sentences for the summary. Another advantage of this model is that it can extract syntactic and semantic relationships from the text by using a Convolutional Bi-GRU (Bi-directional Gated Recurrent Unit) network. We have trained our proposed model on the combined CNN/Daily Mail corpus and evaluated on the Daily Mail, combined CNN/Daily Mail, and DUC 2002 test dataset for single document summarization and obtained better results as compared to the state-of-the-art baseline approaches in terms of ROUGE metrics. For the summary length limited to 75 words, our attention-based approach generates ROUGE recall scores for R-1, R-2, R-L measures as 32.8%, 11.0%, 27.5% with Daily Mail corpus and 55.9%, 24.8%, 53.9% with DUC 2002 dataset, respectively. Experiments performed with the joint CNN/Daily dataset yield full-length ROUGE F1 scores as 42.9%, 19.7%, 39.3%. Therefore, our deep learning-based summarization framework achieves competitive performance.
C1 [Gambhir, Mahak; Gupta, Vishal] Panjab Univ, Univ Inst Engn & Technol, Chandigarh, India.
C3 Panjab University
RP Gupta, V (corresponding author), Panjab Univ, Univ Inst Engn & Technol, Chandigarh, India.
EM gambhir.mahak@gmail.com; vishal@pu.ac.in
CR Al-Sabahi K, 2018, IEEE ACCESS, V6, P24205, DOI 10.1109/ACCESS.2018.2829199
   Alguliyev RM, 2019, EXPERT SYST, V36, DOI 10.1111/exsy.12340
   [Anonymous], 2005, IMPACT FREQUENCY SUM
   [Anonymous], 2015, P 2015 C EMP METH NA
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bansal N, 2019, J MANAG ANAL, V6, P323, DOI 10.1080/23270012.2019.1655672
   Baralis E, 2013, INFORM SCIENCES, V249, P96, DOI 10.1016/j.ins.2013.06.046
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bi K., 2020, ARXIV200703331
   Cao Z., 2016, P COLING 2016 26 INT
   Cao ZQ, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P829
   Carbonell J., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P335, DOI 10.1145/290941.291025
   Cheng JP, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P484
   Cho K., 2014, ARXIV14061078
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   DanqingWang Pengfei Liu, 2020, ACL, P6209
   Diao YF, 2020, NEURAL COMPUT APPL, V32, P11491, DOI 10.1007/s00521-019-04638-3
   Dong Y, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3739
   Du JC, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3988
   EDMUNDSON HP, 1969, J ACM, V16, P264, DOI 10.1145/321510.321519
   El-Kassas WS, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102264
   Erkan G, 2004, J ARTIF INTELL RES, V22, P457, DOI 10.1613/jair.1523
   Fan A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P889
   Fang CJ, 2017, EXPERT SYST APPL, V72, P189, DOI 10.1016/j.eswa.2016.12.021
   Fattah MA, 2009, COMPUT SPEECH LANG, V23, P126, DOI 10.1016/j.csl.2008.04.002
   Feng C, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1499, DOI 10.1145/3269206.3269251
   Gambhir M, 2017, ARTIF INTELL REV, V47, P1, DOI 10.1007/s10462-016-9475-9
   Gui L., 2017, ABS170805482 CORR, P1593
   Gupta V, 2016, COGN COMPUT, V8, P261, DOI 10.1007/s12559-015-9359-3
   Hark C, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102187
   Hermann Karl Moritz, 2015, Advances in Neural Information Processing Systems, P1693
   Kim JH, 2018, ADV NEUR IN, V31
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Kingma D. P., 2014, arXiv
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Liu Y, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1745
   Lu JS, 2016, ADV NEUR IN, V29
   LUHN HP, 1958, IBM J RES DEV, V2, P159, DOI 10.1147/rd.22.0159
   Luo L, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3033
   Luong T., 2015, P 2015 C EMP METH NA, DOI [DOI 10.18653/V1/D15-1166, 10.18653/v1/D15-1166]
   McDonald R, 2007, LECT NOTES COMPUT SC, V4425, P557
   Meena YK, 2016, IETE J RES, V62, P581, DOI 10.1080/03772063.2015.1136574
   Mehta P, 2018, INFORM PROCESS MANAG, V54, P145, DOI 10.1016/j.ipm.2017.11.002
   Mendoza M, 2014, EXPERT SYST APPL, V41, P4158, DOI 10.1016/j.eswa.2013.12.042
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Mohamed M, 2019, INFORM PROCESS MANAG, V56, P1356, DOI 10.1016/j.ipm.2019.04.003
   Nallapati R., 2016, CoRR
   Nallapati R, 2017, AAAI CONF ARTIF INTE, P3075
   Narayan Shashi, 2018, NAACL HLT, DOI DOI 10.18653/V1/N18-1158
   Nenkova A, 2011, FOUND TRENDS INF RET, V5, P103, DOI 10.1561/1500000015
   Parveen Daraksha., 2016, P OFTHE 2016 C EMPIR, P772
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Saini N, 2019, KNOWL-BASED SYST, V164, P45, DOI 10.1016/j.knosys.2018.10.021
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Shao L., 2017, INT JO C KNOWL DISC, P118, DOI DOI 10.1007/978-3-030-15640-4_7
   Shen T, 2018, AAAI CONF ARTIF INTE, P5446
   Singh AK, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2303, DOI 10.1145/3132847.3133127
   Sutskever I, 2014, ADV NEUR IN, V27
   Vaswani A, 2017, ADV NEUR IN, V30
   Wan Xiaojun., 2010, P 23 INT C COMPUTATI, P1137
   Woodsend K, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P565
   Xu JC, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3292
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang K, 2019, CONCURR COMP-PRACT E, V31, DOI 10.1002/cpe.5206
   Yao JG, 2017, KNOWL INF SYST, V53, P297, DOI 10.1007/s10115-017-1042-4
   Yao KC, 2018, NEUROCOMPUTING, V284, P52, DOI 10.1016/j.neucom.2018.01.020
   Yasunaga Michihiro, 2017, P 21 C COMPUTATIONAL, P452
   Yin WP, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1383
   Zhang XX, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P779
   Zhong M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1049
NR 72
TC 12
Z9 12
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 20829
EP 20852
DI 10.1007/s11042-022-12729-y
EA MAR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000767922000008
DA 2024-07-18
ER

PT J
AU Ali, TS
   Ali, R
AF Ali, Tahir Sajjad
   Ali, Rashid
TI A novel color image encryption scheme based on a new dynamic compound
   chaotic map and S-box
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Chaos; Chaotic system; Tent logistic map; Piecewise
   linear chaotic map; S-box
ID DNA-SEQUENCE OPERATION; SYSTEM
AB In modern technological era image encryption has become an attractive and interesting field for researchers. They work for improving the security of image data from unauthorized sources. Chaos theory, due to its randomness and unpredictable behaviors, is considered favorite for the purpose of image encryption. This paper proposes a diffusion based image encryption algorithm by using chaotic maps. Firstly a chaotic map (piecewise linear chaotic map) is used for the generation of S-box, then it is used for the pixel values modification to generate element of non-linearity. After this these modified values are further diffused with another random sequence, generated by tent logistic chaotic map. Finally the color components of pre-encrypted image are mixed with each other so that the developed randomness uniformly distributed in them. For image data we develop non-linearity and diffusion by using S-box and then more randomness is added in the pre-encrypted image with the help of Boolean operation XOR. The use of this combination of chaotic maps along with S-box and Boolean operation XOR is a different technique, that provides satisfactory results for security aspects and also works efficiently.
C1 [Ali, Tahir Sajjad; Ali, Rashid] Capital Univ Sci & Technol, Islamabad, Pakistan.
C3 Capital University of Science & Technology
RP Ali, TS (corresponding author), Capital Univ Sci & Technol, Islamabad, Pakistan.
EM tahir.sajjad@cust.edu.pk
OI Ali, Tahir Sajjad/0000-0002-1262-9426; Ali, Rashid/0000-0002-4952-6199
CR Alawida M, 2019, SIGNAL PROCESS, V160, P45, DOI 10.1016/j.sigpro.2019.02.016
   Ali TS, 2020, IEEE ACCESS, V8, P71974, DOI 10.1109/ACCESS.2020.2987615
   Ali TS, 2020, MULTIMED TOOLS APPL, V79, P19853, DOI 10.1007/s11042-020-08850-5
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Asim M, 2008, ETRI J, V30, P170, DOI 10.4218/etrij.08.0207.0188
   Chai XL, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.108041
   Chai XL, 2021, INFORM SCIENCES, V556, P305, DOI 10.1016/j.ins.2020.10.007
   Chai XL, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107684
   Chandrawat RK, 2017, ADV INTELL SYST, V546, P197, DOI 10.1007/978-981-10-3322-3_18
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Choi J, 2016, MULTIMED TOOLS APPL, V75, P14685, DOI 10.1007/s11042-016-3274-9
   Curiac DI, 2012, MATH PROBL ENG, V2012, DOI 10.1155/2012/940276
   Daemen J., 2001, KATHOL U LEUVENESAT
   Dhiman G, 2020, CURR MED IMAGING
   Dhiman G, 2019, ADV INTELL SYST, V741, P857, DOI 10.1007/978-981-13-0761-4_81
   Diomidous Marianna, 2016, Acta Inform Med, V24, P66, DOI 10.5455/aim.2016.24.66-68
   Dressing H, 2014, CYBERPSYCH BEH SOC N, V17, P61, DOI 10.1089/cyber.2012.0231
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Fu C, 2011, OPT COMMUN, V284, P5415, DOI 10.1016/j.optcom.2011.08.013
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Habutsu T, 1991, LECT NOTES COMPUT SC
   Hussain I, 2012, Z NATURFORSCH A, V67, P327, DOI 10.5560/ZNA.2012-0023
   Jamal SS, 2019, IEEE ACCESS, V7, P173273, DOI 10.1109/ACCESS.2019.2956385
   Kammer RG, 1999, FIPS PUB, V46, P3
   Kanwal S, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/5499538
   Kaur A, 2019, ADV INTELL SYST COMP, V741, P909, DOI 10.1007/978-981-13-0761-4_86
   Kaur S, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103541
   Khan M., 2015, NEURAL COMPUTING APP, DOI [10.1007/s00521-015-1887, DOI 10.1007/S00521-015-1887]
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   LORENZ EN, 1969, J ATMOS SCI, V26, P636, DOI 10.1175/1520-0469(1969)26<636:APARBN>2.0.CO;2
   Lu Q, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21101004
   Mankar VH, 2010, NAT C EM TRENDS EL E
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   MARKUS M, 1989, COMPUT GRAPH, V13, P553, DOI 10.1016/0097-8493(89)90019-8
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Meier W., 1994, Advances in Cryptology - EUROCRYPT '93. Workshop on the Theory and Application of Cryptographic Techniques Proceedings, P371
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Patidar V, 2010, COMMUN NONLINEAR SCI, V15, P2755, DOI 10.1016/j.cnsns.2009.11.010
   Pearson K., 1895, P R SOC LOND, V58, P240, DOI 10.1098/rspl.1895.0041
   Picek S, 2014, LECT NOTES COMPUT SC, V8501, P140, DOI 10.1007/978-3-662-43826-8_10
   Rehman AU, 2015, MULTIMED TOOLS APPL, V74, P4655, DOI 10.1007/s11042-013-1828-7
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Singh P, 2018, APPL SOFT COMPUT, V72, P121, DOI 10.1016/j.asoc.2018.07.038
   Stoyanov B, 2015, ENTROPY-SWITZ, V17, P2117, DOI 10.3390/e17042117
   Stoyanov B, 2014, SCI WORLD J, DOI 10.1155/2014/283639
   Tiwari V., 2021, MULTIMED TOOLS APPL
   Wang XY, 2018, OPT LASER ENG, V107, P370, DOI 10.1016/j.optlaseng.2017.06.015
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Whitehead N., 2011, PRECISION PERFORMANC, V21, P18749
   Wu JH, 2017, SIGNAL PROCESS, V141, P109, DOI 10.1016/j.sigpro.2017.04.006
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu Y, 2014, INFORM SCIENCES, V264, P317, DOI 10.1016/j.ins.2013.11.027
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Yuvaraj N, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/6644652
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 59
TC 27
Z9 27
U1 8
U2 67
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 20585
EP 20609
DI 10.1007/s11042-022-12268-6
EA MAR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000767748600023
PM 35291717
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Samaiya, D
   Gupta, KK
AF Samaiya, Devesh
   Gupta, Karunesh Kumar
TI Segmentation & bitstream encoding of foreground objects in HEVC encoder
   for edge computing environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Foreground segmentation; HEVC; Video analytics; Edge computing
ID BACKGROUND SUBTRACTION; VIDEO ANALYSIS; SURVEILLANCE
AB Segmentation of foreground object is pivotal in identifying the other finer details about objects in a scene. Our work serves to investigate ways to not only segment but encode the foreground objects in the HEVC encoder with minimal change in original HEVC encoder performance in terms of bitrate increase and encoding time. We achieve this by reutilizing the intermediate residual data at the encoder to segment the foreground activity in each frame and finally encoding the same in the final compressed bitstream using specific provisions of HEVC high level bitstream syntax. The method operates entirely in the HEVC encoder loop, taking residual data of the frame, it divides the entire frame into 8 x 8 target patches and applies the proposed algorithm Median of Discrete Variance (MoDV) to classify the target block of each frame of the video sequence as foreground or background. The foreground information in each frame is then encoded into the compressed bitstream by harnessing our proposed format of supplemental enhancement information (SEI) Network Abstraction Layer (NAL) units to tag the location of the foreground activity. Along with the segmentation accuracy, change in encoder performance is also measured to judge the various trade-offs. We conclude by testing its efficacy on a variety of videos with difference frame resolutions and background conditions.
C1 [Samaiya, Devesh; Gupta, Karunesh Kumar] Birla Inst Technol & Sci, Pilani 333031, Rajasthan, India.
C3 Birla Institute of Technology & Science Pilani (BITS Pilani)
RP Samaiya, D (corresponding author), Birla Inst Technol & Sci, Pilani 333031, Rajasthan, India.
EM devesh.samaiya@pilani.bits.pilani.ac.in; kgupta@pilani.bits-pilani.ac.in
RI Gupta, Karunesh K./K-3538-2016
OI Gupta, Karunesh K./0000-0002-0003-4601
CR Akilan T, 2019, IEEE T VEH TECHNOL, V68, P9478, DOI 10.1109/TVT.2019.2937076
   [Anonymous], 2012, COMMON CONDITIONS SO
   [Anonymous], 1999, JTC1144962 ISOIEC
   Babu RV, 2007, MULTIMED TOOLS APPL, V32, P93, DOI 10.1007/s11042-006-0048-9
   Babu RV, 2016, MULTIMED TOOLS APPL, V75, P1043, DOI 10.1007/s11042-014-2345-z
   Baser M., 2020, 2020 IEEE 17 IND COU
   Chiranjeevi P, 2014, IEEE T IMAGE PROCESS, V23, P645, DOI 10.1109/TIP.2013.2285598
   Dey B, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2445631
   Dey B, 2013, IEEE T CIRC SYST VID, V23, P1695, DOI 10.1109/TCSVT.2013.2255416
   F. H. H. Institute, HIGH EFFICIENCY VIDE
   Fan JP, 2003, MULTIMED TOOLS APPL, V21, P75, DOI 10.1023/A:1025086200838
   Haines TSF, 2014, IEEE T PATTERN ANAL, V36, P670, DOI 10.1109/TPAMI.2013.239
   Helle P, 2012, IEEE T CIRC SYST VID, V22, P1720, DOI 10.1109/TCSVT.2012.2223051
   Huang TJ, 2014, IEEE J EM SEL TOP C, V4, P5, DOI 10.1109/JETCAS.2014.2298274
   LIANG YL, 2015, INT CONF WIRE COMMUN, pNI940
   Maddalena L., 2012, 2012 IEEE COMP VIS P
   Meier T, 1998, IEEE T CIRC SYST VID, V8, P525, DOI 10.1109/76.718500
   Moriyama M, 2015, I S INTELL SIG PROC, P48, DOI 10.1109/ISPACS.2015.7432735
   Reddy V, 2013, IEEE T CIRC SYST VID, V23, P83, DOI 10.1109/TCSVT.2012.2203199
   Sabirin H, 2012, IEEE T MULTIMEDIA, V14, P657, DOI 10.1109/TMM.2012.2187777
   Samaiya D, 2018, MULTIMED TOOLS APPL, V77, P29059, DOI 10.1007/s11042-018-6087-1
   Sanches SRR, 2019, APPL INTELL, V49, P1771, DOI 10.1007/s10489-018-1346-4
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Wang Y, 2014, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2014.126
   Xu Y, 2016, CAAI T INTELL TECHNO, V1, P43, DOI 10.1016/j.trit.2020.03.005
   Zhao L, 2018, IEEE T CIRC SYST VID, V28, P1346, DOI 10.1109/TCSVT.2016.2645616
NR 27
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18397
EP 18416
DI 10.1007/s11042-022-12198-3
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766438300005
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Chen, AG
   Chen, B
AF Zhang, Yong
   Chen, Aiguo
   Chen, Bin
TI A unified improvement of the AES algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Advanced encryption standard (AES); Unified algorithm; Key expansion;
   Symmetric cipher; System sensitivity
ID IMAGE ENCRYPTION SCHEME; SYSTEM
AB Symmetric cryptography is widely used in information exchange and storage. The advanced encryption standard (AES) is one of the most important symmetric ciphers. Based on the AES algorithm, this paper designs a new symmetric cipher, called unified algorithm. In the unified algorithm, the secret key is 256-bit long and the plaintext and cipher-text are both 128-bit long. The unified algorithm is composed of the modules and their improved versions of AES and a sequence-flip module, and has the same encryption and decryption processes. The simulation results show that the unified algorithm has the same processing speed as AES, and its single-thread running speed in Mathematica can reach up to 1.6570Mbps. Meanwhile, the unified algorithm has the same encryption intensity as AES, and its relative errors of system sensitivity index are less than 0.5%. The unified algorithm can be applied to various secure communication occasions to replace the AES algorithm. In addition, due to the encryption and decryption sharing the same module, the unified algorithm can save the hardware resources and simplify the secure communication protocol effectively.
C1 [Zhang, Yong; Chen, Aiguo; Chen, Bin] Jiangxi Univ Finance & Econ, Sch Software & Internet Things Engn, Nanchang 330013, Jiangxi, Peoples R China.
C3 Jiangxi University of Finance & Economics
RP Zhang, Y (corresponding author), Jiangxi Univ Finance & Econ, Sch Software & Internet Things Engn, Nanchang 330013, Jiangxi, Peoples R China.
EM zhangyong@jxufe.edu.cn
OI Zhang, Yong/0000-0002-7428-1816
FU National Natural Science Foundation of China [61762043]; Natural Science
   Foundation of Jiangxi Province, China [20192BAB207022]; Scientific
   Research Foundation of Jiangxi Provincial Education Department, China
   [GJJ190249, GJJ210507]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61762043), the Natural Science Foundation of Jiangxi
   Province, China (No. 20192BAB207022), and the Scientific Research
   Foundation of Jiangxi Provincial Education Department, China (No.
   GJJ190249, GJJ210507).
CR Alamsyah, 2018, NONLINEAR DYNAM, V93, P2105, DOI 10.1007/s11071-018-4310-2
   Artiles JAP, 2019, SIGNAL PROCESS-IMAGE, V79, P24, DOI 10.1016/j.image.2019.08.014
   Basu Sandipan., 2011, Journal of global research in Computer Science, V2, P116
   Burr W. E., 2003, IEEE Security & Privacy, V1, P43, DOI 10.1109/MSECP.2003.1193210
   Cheng SL, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12030332
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185162
   Daemen J, 2001, DR DOBBS J, V26, P137
   Davis R. M., 1978, IEEE Communications Society Magazine, V16, P5, DOI 10.1109/MCOM.1978.1089771
   Devi RR, 2020, INT J PARALLEL PROG, V48, P515, DOI 10.1007/s10766-018-0592-8
   Dzwonkowski M, 2019, IEEE T IMAGE PROCESS, V28, P371, DOI 10.1109/TIP.2018.2868388
   Gupta SS, 2013, IEEE T COMPUT, V62, P730, DOI 10.1109/TC.2012.19
   Haddad S, 2020, IEEE T INF FOREN SEC, V15, P2556, DOI 10.1109/TIFS.2020.2972159
   Komargodski I, 2020, J CRYPTOL, V33, P406, DOI 10.1007/s00145-019-09327-x
   Kundi DES, 2020, IEEE T CIRCUITS-I, V67, P4869, DOI 10.1109/TCSI.2020.2997916
   Langenberg B., 2020, IEEE Transactions on Quantum Engineering, V1, P1, DOI 10.1109/TQE.2020.2965697
   Liao X., 2016, MULTIMED TOOLS APPL, V75, P13779
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Masoumi M, 2019, J INF SECUR APPL, V48, DOI 10.1016/j.jisa.2019.102371
   Saravanan P, 2018, WIRELESS PERS COMMUN, V100, P1427, DOI 10.1007/s11277-018-5647-z
   Seghier A, 2019, IET INFORM SECUR, V13, P552, DOI 10.1049/iet-ifs.2018.5043
   Shah D, 2020, MULTIMED TOOLS APPL, V79, P28023, DOI 10.1007/s11042-020-09182-0
   Shen Y., 2020, IACR T SYM CRYPTOL, V1, P457, DOI [10.46586/tosc.v2020.i1.425-457, DOI 10.46586/TOSC.V2020.I1.425-457]
   Singh G., 2011, INT J ENG RES APPL, V1, P321
   Stoyanov B, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12010073
   Sweatha AA, 2020, J INTELL FUZZY SYST, V39, P4313, DOI 10.3233/JIFS-200326
   Wang Chen-guang, 2013, Computer Engineering, V39, P177, DOI 10.3969/j.issn.1000-3428.2013.07.040
   Wang XY, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110102
   Xinmiao Zhang, 2002, IEEE Circuits and Systems Magazine, V2, P24, DOI 10.1109/MCAS.2002.1173133
   Yang CH, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12020189
   Yu WZ, 2017, IEEE T CIRCUITS-I, V64, P2934, DOI 10.1109/TCSI.2017.2702098
   Zhang Y, 2021, INFORM SCIENCES, V547, P307, DOI 10.1016/j.ins.2020.07.058
   Zhang Y, 2020, INFORM SCIENCES, V526, P180, DOI 10.1016/j.ins.2020.03.054
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P6647, DOI 10.1007/s11042-017-4577-1
   Zhang Y, 2017, CHINESE J ELECTRON, V26, P1022, DOI 10.1049/cje.2017.08.022
   Zhou MJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107484
NR 35
TC 2
Z9 2
U1 11
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18875
EP 18895
DI 10.1007/s11042-022-12742-1
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766430800004
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Song, CL
   Zhang, DW
AF Zhang, Yang
   Song, Chenglong
   Zhang, Dongwen
TI Small-scale aircraft detection in remote sensing images based on
   Faster-RCNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote sensing image; Small-scale aircraft; Object detection; Deep
   learning; Clustering algorithm
AB Detecting aircraft in remote sensing images becomes increasingly important in both military and civilian fields. However, the accuracy of existing detection approach is not high enough especially for the small-scale aircraft when considering the size and scenario of the remote sensing images. To improve the accuracy of detecting small-scale aircraft, this paper proposes a detection approach for aircraft based on Faster-RCNN, called MFRC. Firstly, the K-means algorithm is used to cluster aircraft data in remote sensing images. Anchors are improved based on clustering results. Secondly, to extract location features of small-scale aircraft, the layer of pooling in the VGG16 network is reduced from four to two. Finally, the Soft-NMS algorithm is used to optimize the aircraft bounding boxes. In the experimentation, MFRC is evaluated under different conditions and compared with other models. The experimental results show that MFRC can detect small-scale aircraft effectively and the accuracy is improved by 3% compared to existing methods.
C1 [Zhang, Yang; Song, Chenglong; Zhang, Dongwen] Hebei Univ Sci & Technol, Sch Informat Sci & Engn, Shijiazhuang 050018, Hebei, Peoples R China.
C3 Hebei University of Science & Technology
RP Zhang, Y (corresponding author), Hebei Univ Sci & Technol, Sch Informat Sci & Engn, Shijiazhuang 050018, Hebei, Peoples R China.
EM zhangyang@hebust.edu.cn; 3129782009@qq.com; zdwwtx@hebust.edu.cn
CR [Anonymous], 2011, 2011 S PHOT OPT SOPO, DOI DOI 10.1109/SOPO.2011.5780562
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Cao CQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20174696
   Chen F, 2020, INT GEOSCI REMOTE SE, P264, DOI 10.1109/IGARSS39084.2020.9323517
   Ding QG, 2019, IEEE INT CONF MULTI, P13, DOI 10.1109/ICMEW.2019.00010
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Guo XJ, 2016, MEASUREMENT, V93, P490, DOI 10.1016/j.measurement.2016.07.054
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Krishna K, 1999, IEEE T SYST MAN CY B, V29, P433, DOI 10.1109/3477.764879
   Laroca R., 2018, P INT JOINT C NEUR N, P1
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li W, 2011, IEEE IMAGE PROC
   Li XB, 2017, PROCEEDINGS OF 2017 IEEE 2ND INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC), P235, DOI 10.1109/ITNEC.2017.8284943
   Li YT, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8091678
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu G, 2013, IEEE GEOSCI REMOTE S, V10, P573, DOI 10.1109/LGRS.2012.2214022
   Nencini F, 2007, INFORM FUSION, V8, P143, DOI 10.1016/j.inffus.2006.02.001
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Qassim H, 2018, 2018 IEEE 8TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P169, DOI 10.1109/CCWC.2018.8301729
   Qiu ZS, 2019, IEEE T INSTRUM MEAS, V68, P27, DOI 10.1109/TIM.2018.2834085
   Ravì D, 2017, IEEE J BIOMED HEALTH, V21, P4, DOI 10.1109/JBHI.2016.2636665
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sachdeva P, 2019, U.S. Patent, Patent No. [10,169,678, 10169678]
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Wei WJ, 2019, INT C INTEL HUM MACH, P173, DOI 10.1109/IHMSC.2019.00048
   Williams CKI, 1998, IEEE T PATTERN ANAL, V20, P1342, DOI 10.1109/34.735807
   Yang YD, 2017, IEEE GEOSCI REMOTE S, V14, P1293, DOI 10.1109/LGRS.2017.2708722
   YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169
   Zhang LB, 2017, IEEE J-STARS, V10, P1511, DOI 10.1109/JSTARS.2016.2620900
   Zhang Y, 2024, J SOFTW-EVOL PROC, V36, DOI 10.1002/smr.2403
   Zhou LC, 2023, INF SYST E-BUS MANAG, V21, P7, DOI 10.1007/s10257-021-00503-w
NR 35
TC 9
Z9 8
U1 1
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18091
EP 18103
DI 10.1007/s11042-022-12609-5
EA MAR 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766064000006
DA 2024-07-18
ER

PT J
AU Abdulhammed, OY
AF Abdulhammed, Omar Younis
TI A novel approach of steganography by using strong edge detection and
   chaos theory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Security; Steganography; Edges detection; Strong edges detection;
   Chirikov
AB The growth of the Internet and rapid development of digital devices and network technology led to increase the risks and threats of attackers, therefore the important data that is sent via the Internet must be preserved, one of the most substantial security methods utilized to protect this data is steganography, so this technology must be developed and strengthened in order to face the modern technologies used by the attackers. The aim of this paper is to preserve the data sent via internet by proposing a new method that treats to solve the gaps and weakness of previous methods. Since the edge region of the image is more permissive of alteration, therefore is more convenient for concealing secret information. A novel schema of concealing secret information is suggested by creating new algorithm in the name of strong edges detection algorithm (SEDA) to detect strong edges of the image and using chaotic mapping method to generate random numbers. This schema consist of five stages, where in the first stage the canny algorithm is utilized to reveal edges of the carrier media and store it in the new array called (na1), secondly, the SEDA is used to identified strong edges of the (na1) and the results is stored in the new array called (na2) as the strong edges are utilized to conceal mystery information. Thirdly, chirikov map method are using to generate random keys, where these keys are used to choose the locations in the (na2) and which are used to hide secret information. In the fourth stage, the important data is hidden in the chosen pixel locations. The extraction of important information carry out in the fifth stage, which is the opposite of concealing stage. The results proved that the proposed system increase security, robustness, payload capacity, efficiency and maintaining stego image's quality.
C1 [Abdulhammed, Omar Younis] Univ Garmian, Coll Sci, Dept Comp Sci, Kalar, Iraq.
RP Abdulhammed, OY (corresponding author), Univ Garmian, Coll Sci, Dept Comp Sci, Kalar, Iraq.
EM Omar.y@garmian.edu.krd
CR Adhikary MC, 2014, ARXIV PREPRINT ARXIV
   Al-Husainy Mohammed A. F., 2009, Journal of Computer Sciences, V5, P33, DOI 10.3844/jcs.2009.33.38
   Al-Nofaie S, 2021, J KING SAUD UNIV-COM, V33, P963, DOI 10.1016/j.jksuci.2019.06.010
   Al-shatnawi A, 1996, APPL MATH SCI, V6, P3907
   Alabaichi A., 2020, INT J ELECT COMPUTER, V10, P935, DOI [10.11591/ijece.v10i1.pp935-946, DOI 10.11591/IJECE.V10I1.PP935-946]
   Bai JL, 2017, DISPLAYS, V46, P42, DOI 10.1016/j.displa.2016.12.004
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Chang CC., 2014, INT J NETWORK SECUR, V16, P201
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Gaurav K, 2018, J INF SECUR APPL, V41, P41, DOI 10.1016/j.jisa.2018.05.001
   Gutub A, 2019, 3D RES, V10, DOI 10.1007/s13319-019-0216-0
   Hashim Mohammed Mahdi, 2017, Journal of Theoretical and Applied Information Technology, V95, P5977
   Islam S, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-8
   Kalra M., 2014, INT J TECHNOL EXPLOR, V3
   Morkel T., 2005, ISSA, V1, P1
   Permella AJ, 2019, INT J ENG ADV TECHNO, V8
   Saha S, 2018, ELECTRON LETT, V54, P498, DOI 10.1049/el.2017.3336
   Sethi N, 2013, INT J COMPUT SCI BUS, V5, P1
   Setiadi DIM, 2019, INT J ELECTRON TELEC, V65, P287, DOI 10.24425/ijet.2019.126312
   Setiadi DIM, 2022, J KING SAUD UNIV-COM, V34, P104, DOI 10.1016/j.jksuci.2019.12.007
   Setiadi DIM, 2018, CYBERN INF TECHNOL, V18, P74, DOI 10.2478/cait-2018-0029
NR 21
TC 3
Z9 3
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 17875
EP 17888
DI 10.1007/s11042-022-12643-3
EA MAR 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000765701900015
DA 2024-07-18
ER

PT J
AU Kumar, V
   Walia, R
   Sharma, S
AF Kumar, Vijay
   Walia, Ranjeet
   Sharma, Shivam
TI DeepHumor: a novel deep learning framework for humor detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Humor detection; Deep learning; Social network analysis; Convolutional
   neural networks
AB The automation of humor detection is a complex task due to the semantic structure of the textual content. In this paper, an automatic humor detection model named as DeepHumor is proposed. The proposed model is based on the combination of convolutional neural network (CNN) and long short term memory (LSTM). The highway network is also incorporated in the proposed model to enhance the performance. The hybrid model uses CNN layers for feature extraction with LSTM layers for sequence learning. To overcome the overfitting problem in the proposed model, dropout layers are added. The performance of the proposed DeepHumor model is compared with seven recently developed techniques over Yelp user review dataset. The proposed DeepHumor model attained the significantly better performance than the exiting techniques in terms of precision, recall, accuracy and F1-measure.
C1 [Kumar, Vijay; Walia, Ranjeet; Sharma, Shivam] CSED Natl Inst Technol, Hamirpur 177005, Himachal Prades, India.
RP Kumar, V (corresponding author), CSED Natl Inst Technol, Hamirpur 177005, Himachal Prades, India.
EM vijaykumarchahar@gmail.com; ranjeetwalia2000@gmail.com;
   sharmashivam778@gmail.com
RI Chahar, Vijay Kumar/A-2782-2015
OI Chahar, Vijay Kumar/0000-0002-3460-6989
CR Annamoradnejad I, 2021, ARXIV200412765
   Bertero D, 2016, NAACL HLT C N AM CHA
   Castro S, 2016, LECT NOTES ARTIF INT, V10022, P139, DOI 10.1007/978-3-319-47955-2_12
   Chaudhary T, 2021, P 11 HUM RES C
   Chen L, 2017, ARXIV170202584
   Chen P.-Y., 2018, P 2018 C N AM CHAPT, V2, P113, DOI [DOI 10.18653/V1/N18-2018, 10.18653/v1/N18-2018]
   Chen T., 2016, P 22 ACM SIGKDD INT, P785
   Chiruzzo L, 2019, IBERLEF SEPLN, P132
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Han J, 2012, MOR KAUF D, P1
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jain M, 2017, THESIS HARRISBURG U
   Jaiswal A, 2019, INT C MACH LEARN BIG
   Joulin A., 2017, P 15 C EUR CHAPT ASS, P427, DOI DOI 10.18653/V1/E17-2068
   Kamal A, 2020, COMMUN COMPUT PHYS, V1215
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5070
   Mihalcea R., 2005, The Human Language Technology/Empirical Methods in Natural Language Processing
   Oliveira L-D, 2015, HUMOR DETECTION YELP
   Sane SR, 2019, NAACL HLT 2019, P57
   Song Yan-Yan, 2015, Shanghai Arch Psychiatry, V27, P130, DOI 10.11919/j.issn.1002-0829.215044
   Srivastava RK., 2015, P 28 INT C NEURAL IN, P2377, DOI DOI 10.48550/ARXIV.1507.06228
   Weller O, 2019, P 2019 C EMP METH NA, P3619
   Winters T, 2019, P INT C COMP CREAT
   Winters T, 2020, P 32 BEN C ART INT B
   Yang D., 2015, EMNLP, P2367
   Yang H, 2020, AAAI WORKSH 2020
   Yang ZXF, 2019, INTERSPEECH, P496, DOI 10.21437/Interspeech.2019-3113
   Yelp, 2014, YELP DAT CHALL
   Zhang H, 2004, LECT NOTES COMPUT SC, V3201, P501
   Ziser Y, 2020, 43 INT ACM SIGIR C R
NR 31
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16797
EP 16812
DI 10.1007/s11042-022-12739-w
EA MAR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763872100016
DA 2024-07-18
ER

PT J
AU Low, WS
   Goh, KY
   Goh, SK
   Yeow, CH
   Lai, KW
   Goh, SL
   Chuah, JH
   Chan, CK
AF Low, Wan Shi
   Goh, Kheng Yee
   Goh, Sim Kuan
   Yeow, Chen Hua
   Lai, Khin Wee
   Goh, Siew Li
   Chuah, Joon Huang
   Chan, Chow Khuen
TI Lower extremity kinematics walking speed classification using long
   short-term memory neural frameworks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Computational biomechanics; Gait; Kinematics; LSTM
ID MOTION CAPTURE SYSTEM; GAIT ANALYSIS; ANGULAR VELOCITY; BIOMECHANICS;
   NETWORKS; VALIDITY; TOOLS; AGE
AB Walking speed provides a good proxy for gait abnormalities as individuals with medical morbidities tend to walk slower than healthy subjects. The walking speed assessment can be utilized as a powerful predictor of health events, which are related to musculoskeletal disorder and mental disease. The expanding need to distinguish gait pattern of individual according to health status has driven various analytical methods such as observational and instrumented gait analysis methods in capturing the human movement. Significant advances in 3D-gait analysis system have enabled a myriad of studies that advance our understanding of gait biomechanics. However, the data samples obtained from this system are large, with high degrees of variability. Hence, developing a reliable approach to distinguish gait patterns specific to the underlying pathologies is of paramount importance. Through this study, we have proposed the use of a deep learning framework with recurrent neural network (RNN) to interpret human walking speed based on kinematic data, whereby RNN is capable for time series data processing. Nevertheless, this model can hardly learn long-range dependencies across time steps in a sequence due to vanishing gradient. In this study, an improved RNN integrated with NVIDIA CUDA (R) Deep Neural Network Library Long Short-Term Memory (cuDNN LSTM) is introduced. This model is capable to classify the gait patterns of different walking speeds from seventeen healthy subjects, with a total of 453 gait cycles. Gait kinematic parameters were employed as the input layer of the deep learning architecture based on RNN is integrated with cuDNN LSTM. Our proposed framework has achieved an accuracy of 97% to classify different speeds (slow, normal and fast). This study therefore presents a method towards establishing a powerful tool to translate machine learning for gait analysis into clinical practice, whereby automated classifications of gait pattern could now improve acuity of clinical diagnoses.
C1 [Low, Wan Shi; Goh, Kheng Yee; Lai, Khin Wee; Chan, Chow Khuen] Univ Malaya, Fac Engn, Dept Biomed Engn, Block A, Kuala Lumpur 50603, Wilayah Perseku, Malaysia.
   [Goh, Sim Kuan] Xiamen Univ Malaysia, Sch Elect & Comp Engn, Sepang, Selangor, Malaysia.
   [Yeow, Chen Hua; Chan, Chow Khuen] Natl Univ Singapore, Fac Engn, Dept Biomed Engn, Singapore, Singapore.
   [Goh, Siew Li] Univ Malaya, Fac Med, Dept Sports Med, Kuala Lumpur, Malaysia.
   [Chuah, Joon Huang] Univ Malaya, Fac Engn, Dept Elect Engn, Kuala Lumpur, Malaysia.
C3 Universiti Malaya; Xiamen University Malaysia Campus; National
   University of Singapore; Universiti Malaya; Universiti Malaya
RP Chan, CK (corresponding author), Univ Malaya, Fac Engn, Dept Biomed Engn, Block A, Kuala Lumpur 50603, Wilayah Perseku, Malaysia.; Chan, CK (corresponding author), Natl Univ Singapore, Fac Engn, Dept Biomed Engn, Singapore, Singapore.
EM ckchan@um.edu.my
RI Lai, Khin Wee/A-2997-2011; Chuah, Joon Huang/F-9990-2010; Goh, Siew
   Li/L-1533-2014; Chan, Chow Khuen/A-8263-2019
OI Lai, Khin Wee/0000-0002-8602-0533; Chuah, Joon
   Huang/0000-0001-9058-3497; Goh, Siew Li/0000-0001-5898-1196; Chan, Chow
   Khuen/0000-0001-5541-6095
FU MOE AcRF Tier 2 [R-397-000-203-112]; SLAI Malaysian Government
   Fellowship; RU Grant [ST039-2021];  [GPF026A-2019]
FX The study was funded through R-397-000-203-112, MOE AcRF Tier 2. Chan
   Chow Khuen was supported by the SLAI Malaysian Government Fellowship.
   Chan Chow Khuen is currently the recipient of the RU Grant (ST039-2021)
   and Faculty Research Grant (GPF026A-2019). The authors have stated no
   conflict of interest, financial or otherwise.
CR Aertbeliën E, 2014, P IEEE RAS-EMBS INT, P520, DOI 10.1109/BIOROB.2014.6913830
   Akhtaruzzaman M, 2016, J MECH MED BIOL, V16, DOI 10.1142/S0219519416300039
   Alexander NB, 2003, J GERONTOL A-BIOL, V58, P734
   [Anonymous], J KING SAUD UNIV-COM, V34, P204
   Azzouni A, 2017, ARXIVABS170505690
   Baker R, 2006, J NEUROENG REHABIL, V3, DOI 10.1186/1743-0003-3-4
   BENGIO Y, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P1183, DOI 10.1109/ICNN.1993.298725
   Brunnekreef JJ, 2005, BMC MUSCULOSKEL DIS, V6, DOI 10.1186/1471-2474-6-17
   Burnfield JM, 2000, ARCH PHYS MED REHAB, V81, P1153, DOI 10.1053/apmr.2000.7174
   Ceseracciu E, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0087640
   CHAN CW, 1994, MAYO CLIN PROC, V69, P448, DOI 10.1016/S0025-6196(12)61642-5
   Chia K., 2017, GAIT POSTURE, V57, P141
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Collins TD, 2009, GAIT POSTURE, V30, P173, DOI 10.1016/j.gaitpost.2009.04.004
   Colyer SL, 2018, SPORTS MED-OPEN, V4, DOI 10.1186/s40798-018-0139-y
   Corazza S, 2006, ANN BIOMED ENG, V34, P1019, DOI 10.1007/s10439-006-9122-8
   Cunningham R, 2019, ROY SOC OPEN SCI, V6, DOI 10.1098/rsos.191011
   Dorschky E, 2020, FRONT BIOENG BIOTECH, V8, DOI 10.3389/fbioe.2020.00604
   Faber H, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0204575
   Ferrarello F, 2013, PHYS THER, V93, P1673, DOI 10.2522/ptj.20120344
   Filtjens B, 2020, GAIT POSTURE, V80, P130, DOI 10.1016/j.gaitpost.2020.05.026
   Granata KP, 2000, J BONE JOINT SURG AM, V82A, P174, DOI 10.2106/00004623-200002000-00003
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Hackett RA, 2018, J AM GERIATR SOC, V66, P1670, DOI 10.1111/jgs.15312
   Hawas AR, 2019, MULTIMED TOOLS APPL, V78, P25873, DOI 10.1007/s11042-019-7638-9
   Hemmatpour M, 2019, ADV HUM-COMPUT INTER, V2019, DOI 10.1155/2019/9610567
   HIMANN JE, 1988, MED SCI SPORT EXER, V20, P161, DOI 10.1249/00005768-198820020-00010
   Hof AL, 2002, GAIT POSTURE, V16, P78, DOI 10.1016/S0966-6362(01)00206-5
   Horst F, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-38748-8
   Huang WNW, 2019, GAIT POSTURE, V71, P192, DOI 10.1016/j.gaitpost.2019.04.008
   Ivanov AV, 2019, IEEE NW RUSS YOUNG, P235, DOI [10.1109/eiconrus.2019.8657282, 10.1109/EIConRus.2019.8657282]
   James EM., 2015, MACHINE LEARNING TEC
   Lee Gyusung, 2001, Journal of Clinical Engineering, V26, P129
   Lempereur M, 2020, J BIOMECH, V98, DOI 10.1016/j.jbiomech.2019.109490
   Loya A, 2020, J ENG SCI MED DIAGN, V3
   Luo J., 2016, J SENSORS, V2016, P1
   Marino FR, 2019, J AM HEART ASSOC, V8, DOI 10.1161/JAHA.119.013212
   Martinez-Hernandez U, 2018, P IEEE RAS-EMBS INT, P897, DOI 10.1109/BIOROB.2018.8487220
   Mentiplay BF, 2018, GAIT POSTURE, V65, P190, DOI 10.1016/j.gaitpost.2018.06.162
   Miao YJ, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P167, DOI 10.1109/ASRU.2015.7404790
   Miller ME, 2018, J AM GERIATR SOC, V66, P954, DOI 10.1111/jgs.15331
   Moraes R, 2013, EXPERT SYST APPL, V40, P621, DOI 10.1016/j.eswa.2012.07.059
   Mündermann L, 2006, J NEUROENG REHABIL, V3, DOI 10.1186/1743-0003-3-6
   Neckel ND, 2008, J NEUROENG REHABIL, V5, DOI 10.1186/1743-0003-5-19
   Neptune RR, 2016, J BIOMECH, V49, P2975, DOI 10.1016/j.jbiomech.2016.07.016
   Norris M, 2014, P I MECH ENG P-J SPO, V228, P3, DOI 10.1177/1754337113502472
   Payne C., 2002, ASSESSMENT LOWER LIM, P304
   Pusara Apiwan, 2019, Int Biomech, V6, P85, DOI 10.1080/23335432.2019.1671221
   Rasmussen LJH, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.13123
   Rathinam C, 2014, GAIT POSTURE, V40, P279, DOI 10.1016/j.gaitpost.2014.04.187
   Redkar S, 2017, INT ROBOT AUTOM J, V3
   Ridao-Fernández C, 2019, BIOMED RES INT-UK, V2019, DOI 10.1155/2019/2085039
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Schülein S, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0228-z
   Schwartz MH, 2008, J BIOMECH, V41, P1639, DOI 10.1016/j.jbiomech.2008.03.015
   Shemmell J, 2007, J NEUROENG REHABIL, V4, DOI 10.1186/1743-0003-4-10
   Soubra R, 2019, BIOMED RES INT, V2019, DOI 10.1155/2019/1354362
   Stansfield BW, 2001, J PEDIATR ORTHOPED, V21, P395, DOI 10.1097/00004694-200105000-00026
   Stief F, 2018, HDB HUMAN MOTION, DOI [10.1007/978-3-319-14418-4_26, DOI 10.1007/978-3-319-14418-4_26]
   Topley M, 2020, J BIOMECH, V106, DOI 10.1016/j.jbiomech.2020.109820
   Toro B, 2003, ARCH PHYS MED REHAB, V84, P1878, DOI 10.1016/S0003-9993(03)00482-9
   Turner A, 2019, IEEE T BIO-MED ENG, V66, P3136, DOI 10.1109/TBME.2019.2900863
   Veltink P.H., 2018, ARXIV PREPRINT ARXIV
   Venkataraman K, 2020, PHYS THER, V100, P708, DOI 10.1093/ptj/pzaa005
   Weber D, 2016, BMC GERIATR, V16, DOI 10.1186/s12877-016-0201-x
   Wren TAL, 2011, GAIT POSTURE, V34, P149, DOI 10.1016/j.gaitpost.2011.03.027
   Zeng HS, 2011, SENSORS-BASEL, V11, P638, DOI 10.3390/s110100638
   Zhang YQ, 2019, PATTERN RECOGN, V93, P228, DOI 10.1016/j.patcog.2019.04.023
NR 68
TC 1
Z9 1
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 9745
EP 9760
DI 10.1007/s11042-021-11838-4
EA MAR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000763256600001
DA 2024-07-18
ER

PT J
AU Yang, ZY
   Leng, L
   Li, M
   Chu, J
AF Yang, Ziyuan
   Leng, Lu
   Li, Ming
   Chu, Jun
TI A computer-aid multi-task light-weight network for macroscopic feces
   diagnosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-task diagnosing; Data augmentation; over-sampling; Weighting
   selection; Macroscopic feces image; Color recognition; Trait recognition
ID CONVOLUTIONAL NEURAL-NETWORKS; HEALTH; MODEL
AB The abnormal traits and colors of feces typically indicate that the patients are probably suffering from tumor or digestive-system diseases. Thus a fast, accurate and automatic health diagnosis system based on feces is urgently necessary for improving the examination speed and reducing the infection risk. The rarity of the pathological images would deteriorate the accuracy performance of the trained models. In order to alleviate this problem, we employ augmentation and over-sampling to expand the samples of the classes that have few samples in the training batch. In order to achieve an impressive recognition performance and leverage the latent correlation between the traits and colors of feces pathological samples, a multi-task network is developed to recognize colors and traits of the macroscopic feces images. The parameter number of a single multi-task network is generally much smaller than the total parameter number of multiple single-task networks, so the storage cost is reduced. The loss function of the multi-task network is the weighted sum of the losses of the two tasks. In this paper, the weights of the tasks are determined according to their difficulty levels that are measured by the fitted linear functions. The sufficient experiments confirm that the proposed method can yield higher accuracies, and the efficiency is also improved.
C1 [Yang, Ziyuan; Leng, Lu; Chu, Jun] Nanchang Hangkong Univ, Sch Software, Nanchang 330063, Jiangxi, Peoples R China.
   [Yang, Ziyuan] Sichuan Univ, Coll Comp Sci, Chengdu 610065, Peoples R China.
   [Leng, Lu] Yonsei Univ, Coll Engn, Sch Elect & Elect Engn, Seoul 120749, South Korea.
   [Li, Ming] Nanchang Hangkong Univ, Sch Informat Engn, Nanchang 330063, Jiangxi, Peoples R China.
C3 Nanchang Hangkong University; Sichuan University; Yonsei University;
   Nanchang Hangkong University
RP Leng, L (corresponding author), Nanchang Hangkong Univ, Sch Software, Nanchang 330063, Jiangxi, Peoples R China.; Leng, L (corresponding author), Yonsei Univ, Coll Engn, Sch Elect & Elect Engn, Seoul 120749, South Korea.
EM leng@nchu.edu.cn
RI Yang, Ziyuan/AAT-1866-2020
OI Yang, Ziyuan/0000-0002-0275-4098
FU National Natural Science Foundation of China [61866028, 61866025,
   61663031, 62162045]; Key Program Project of Research and Development
   (Jiangxi Provincial Department of Science and Technology)
   [20192BBE50073]
FX This research was funded by the National Natural Science Foundation of
   China (61866028, 61866025, 61663031, 62162045), Key Program Project of
   Research and Development (Jiangxi Provincial Department of Science and
   Technology) (20192BBE50073).
CR Abdulnabi AH, 2015, IEEE T MULTIMEDIA, V17, P1949, DOI 10.1109/TMM.2015.2477680
   Alomari YM, 2014, COMPUT MATH METHOD M, V2014, DOI 10.1155/2014/979302
   Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   Baldoumas G, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8111288
   Bao JQ, 2021, MULTIMED TOOLS APPL, V80, P3489, DOI 10.1007/s11042-020-09821-6
   Bergquist R, 2009, TRENDS PARASITOL, V25, P151, DOI 10.1016/j.pt.2009.01.004
   Berhe N, 2004, ACTA TROP, V92, P205, DOI 10.1016/j.actatropica.2004.06.011
   Black CJ, 2020, NAT REV GASTRO HEPAT, V17, P473, DOI 10.1038/s41575-020-0286-8
   Caselli F, 2021, IEEE T BIO-MED ENG, V68, P340, DOI 10.1109/TBME.2020.2995364
   Chang SJ, 2021, IEEE T RADIAT PLASMA, V5, P253, DOI 10.1109/TRPMS.2020.2983391
   Charoensuk L, 2019, ACTA TROP, V191, P13, DOI 10.1016/j.actatropica.2018.12.018
   Chen H, 2017, IEEE T MED IMAGING, V36, P2524, DOI 10.1109/TMI.2017.2715284
   Cheng J, 2018, IEEE T MED IMAGING, V37, P2729, DOI 10.1109/TMI.2018.2851607
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   de Carvalho AO, 2017, J SIGNAL PROCESS SYS, V87, P179, DOI 10.1007/s11265-016-1134-5
   Du XH, 2019, BIOSCIENCE REP, V39, DOI 10.1042/BSR20182100
   Esposito C, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102468
   Eun H, 2018, COMPUT METH PROG BIO, V165, P215, DOI 10.1016/j.cmpb.2018.08.012
   Gu Y, 2019, IEEE T BIO-MED ENG, V66, P2423, DOI 10.1109/TBME.2018.2889915
   Hachuel D, 2019, GASTROENTEROLOGY, V156, pS937
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu CF, 2020, IEEE T IND ELECTRON, V67, P10922, DOI 10.1109/TIE.2019.2962437
   Huang LL, 2020, COMPUT METH PROG BIO, V184, DOI 10.1016/j.cmpb.2019.105115
   Jodeiri A, 2020, COMPUT METH PROG BIO, V184, DOI 10.1016/j.cmpb.2019.105282
   Kermany DS, 2018, CELL, V172, P1122, DOI 10.1016/j.cell.2018.02.010
   Kinross JM, 2020, NAT REV GASTRO HEPAT, V17, P430, DOI 10.1038/s41575-020-0290-z
   Kumar A, 2017, IEEE J BIOMED HEALTH, V21, P31, DOI 10.1109/JBHI.2016.2635663
   Leng L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092644
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2015, PATTERN RECOGN, V48, P2290, DOI 10.1016/j.patcog.2015.01.021
   Li QL, 2020, MED PHYS, V47, P4212, DOI 10.1002/mp.14352
   Liu J, 2018, IEEE T BIO-MED ENG, V65, P1943, DOI 10.1109/TBME.2018.2845706
   Liu J, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab18db
   Liu MX, 2019, IEEE T BIO-MED ENG, V66, P1195, DOI 10.1109/TBME.2018.2869989
   Mao R, 2020, LANCET GASTROENTEROL, V5, P667, DOI 10.1016/S2468-1253(20)30126-6
   Masud M, 2021, IEEE INTERNET THINGS, V8, P15694, DOI 10.1109/JIOT.2020.3047662
   Nkamgang Oscar Takam, 2019, Informatics in Medicine Unlocked, V15, P65, DOI 10.1016/j.imu.2019.100165
   Pollastri F, 2020, MULTIMED TOOLS APPL, V79, P15575, DOI 10.1007/s11042-019-7717-y
   Qureshi MNI, 2019, ARTIF INTELL MED, V98, P10, DOI 10.1016/j.artmed.2019.06.003
   Reena MR, 2020, COMPUT BIOL MED, V126, DOI 10.1016/j.compbiomed.2020.104034
   Savelli B, 2020, ARTIF INTELL MED, V103, DOI 10.1016/j.artmed.2019.101749
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Su AT, 2021, MULTIMED TOOLS APPL, V80, P3349, DOI 10.1007/s11042-020-09350-2
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tewari A, 2017, J SUPERCOMPUT, V73, P1085, DOI 10.1007/s11227-016-1849-x
   Tian CW, 2020, NEURAL NETWORKS, V121, P461, DOI 10.1016/j.neunet.2019.08.022
   van Ginneken B, 2002, IEEE T MED IMAGING, V21, P924, DOI 10.1109/TMI.2002.803121
   Wang GJ, 2018, IEEE J BIOMED HEALTH, V22, P579, DOI 10.1109/JBHI.2016.2634587
   Wong WJ, 2020, PATTERN RECOGN, V101, DOI 10.1016/j.patcog.2020.107203
   Yang W, 2018, IEEE T MED IMAGING, V37, P977, DOI 10.1109/TMI.2018.2790962
   Yang ZY, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8121464
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhang YQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041010
NR 53
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15671
EP 15686
DI 10.1007/s11042-022-12565-0
EA FEB 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762173600022
PM 35250359
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Srivastava, A
   Raghu, S
   Thyagarajan, AK
   Vaidyaraman, J
   Kothandaraman, M
   Sudheendra, P
   Goel, A
AF Srivastava, Akshat
   Raghu, Srivatsav
   Thyagarajan, Abitha K.
   Vaidyaraman, Jayasri
   Kothandaraman, Mohanaprasad
   Sudheendra, Pavan
   Goel, Avinav
TI Alpha matting for portraits using encoder-decoder models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Alpha matting; Image segmentation; Deep learning; Encoder-decoder models
ID IMAGE
AB Image matting is a technique used to extract the foreground and background from a given image. In the past, classical algorithms based on sampling, propagation, or a combination of the two were used to perform image matting; however, most of these have produced poor results when applied to images with complex backgrounds. They are also unable to extract with high accuracy foreground images that are comprised of thin objects. In this context, the use of deep learning to solve the image matting problem has gained increasing popularity. In this paper, an encoder-decoder model for alpha matting of human portraits using deep learning is proposed. The model used comprises two parts: the first is an encoder-decoder model, which is a deep convolutional network that has 11 convolutional layers and 5 max-pooling layers in the encoder stage and 11 convolutional layers and 5 unpooling layers in the decoder stage. This portion of the model takes the image and trimap as input produces the coarse alpha matte as the output. The second part is the refinement stage with four convolutional layers, responsible for further refining the coarse alpha matte that was produced by the encoder-decoder stage to obtain an alpha matte of high accuracy. The model was trained using 43,100 images. When tested using the dataset, our model's output was comparable to the industry standard, yielding an average MSE of 0.023 and an average SAD loss of 66.5.
C1 [Srivastava, Akshat; Raghu, Srivatsav; Thyagarajan, Abitha K.; Vaidyaraman, Jayasri; Kothandaraman, Mohanaprasad] VIT Univ, Sch Elect Engn SENSE, Chennai 600127, Tamil Nadu, India.
   [Sudheendra, Pavan; Goel, Avinav] Samsung R&D Inst, Bangalore 560037, Karnataka, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai
RP Kothandaraman, M (corresponding author), VIT Univ, Sch Elect Engn SENSE, Chennai 600127, Tamil Nadu, India.
EM srivastava.2017@vitstudent.ac.in; srsrivatsay.2017@vitstudent.ac.in;
   abithak.thyagarajan2017@vitstudent.ac.in;
   jayasri.vaidyaraman2017@vitstudent.ac.in; kmohanaprasad@vit.ac.in;
   pavan.s@samsung.com; avinay.goel@samsung.com
OI Kothandaraman, Mohanaprasad/0000-0003-3938-7495
CR Aksoy Y, 2017, PROC CVPR IEEE, P228, DOI 10.1109/CVPR.2017.32
   [Anonymous], 2019, P IEEECVF INT C COMP
   Chen Q, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P618, DOI 10.1145/3240508.3240610
   Forte, 2020, ARXIV200307711CS
   Li Y, 2020, ARXIV200104069CS
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu C, 2017, PROC CVPR IEEE, P4782, DOI 10.1109/CVPR.2017.508
   Lutz S., 2018, BMVC
   Porter T., 1984, Computers & Graphics, V18, P253
   Rhemann C, 2009, PROC CVPR IEEE, P1826, DOI 10.1109/CVPRW.2009.5206503
   Shen X, 2016, LECT NOTES COMPUT SC, V9905, P92, DOI 10.1007/978-3-319-46448-0_6
   Wang J, 2007, FOUND TRENDS COMPUT, V3, P97, DOI 10.1561/0600000019
   Xu N, 2017, PROC CVPR IEEE, P311, DOI 10.1109/CVPR.2017.41
   Yu H, 2020, ARXIV200906613CS
   Zhu BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P297, DOI 10.1145/3123266.3123286
   Zhu QS, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1695, DOI 10.1109/ROBIO.2013.6739711
NR 16
TC 1
Z9 1
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 14517
EP 14528
DI 10.1007/s11042-022-12514-x
EA FEB 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761886300011
DA 2024-07-18
ER

PT J
AU Yu, Y
   Da, FP
   Zhang, ZY
AF Yu, Yi
   Da, Feipeng
   Zhang, Ziyu
TI Few-data guided learning upon end-to-end point cloud network for 3D face
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; 3D face recognition; Point cloud network
ID KEYPOINT DETECTION; LOCAL DESCRIPTORS; REPRESENTATION; EXPRESSION;
   EFFICIENT; FEATURES
AB Deep-learning-based 3D face recognition methods have developed vigorously in recent years, while the potential of these methods is being exploited in more and more scenarios. In this paper, an end-to-end deep learning network entitled Sur3dNet-Face for point-cloud-based 3D face recognition is proposed. The method uses PointNet, which is a successful point cloud classification solution but performs unexpectedly in face recognition, as the backbone. To adapt the backbone to 3D face recognition, modifications in network architecture and a few-data guided learning framework based on Gaussian process morphable model is supplemented. Instead of mass data in multiple datasets for training, our method takes only Spring2003 subset of FRGC v2.0 for training which contains 943 facial scans and the network is well trained with such a small amount of real data. The processing time to generate face representation is less than 0.15 s. Without fine-tuning on the test set, the Rank-1 Recognition Rate (RR1) is achieved as follows: 98.85% on FRGC v2.0 dataset and 99.33% on Bosphorus dataset, which proves the effectiveness and the potentiality of our method. When facing scenarios with limited resource, the proposed method is expected to give a competitive performance.
C1 [Yu, Yi; Da, Feipeng; Zhang, Ziyu] Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.
   [Yu, Yi; Da, Feipeng; Zhang, Ziyu] Southeast Univ, Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Peoples R China.
C3 Southeast University - China; Southeast University - China
RP Da, FP (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.; Da, FP (corresponding author), Southeast Univ, Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Peoples R China.
EM dafp@seu.edu.cn
RI Yu, Yi/JYP-5643-2024
OI Yu, Yi/0000-0002-9841-4687
FU Shenzhen Science and Technology Innovation Commission (STIC)
   [JCYJ20180306174455080]; Natural Science Foundation of Jiangsu Province
   of China [BK20181269]; Special Project on Basic Research of Frontier
   Leading Technology of Jiangsu Province of China [BK20192004C]
FX This work is supported by Shenzhen Science and Technology Innovation
   Commission (STIC) (Grant Nos. JCYJ20180306174455080), Natural Science
   Foundation of Jiangsu Province of China (Grant Nos. BK20181269), and
   Special Project on Basic Research of Frontier Leading Technology of
   Jiangsu Province of China (Grant Nos. BK20192004C).
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Al-Osaimi FR, 2016, IEEE T IMAGE PROCESS, V25, P658, DOI 10.1109/TIP.2015.2492826
   Ali W, 2021, MULTIMED TOOLS APPL, V80, P4825, DOI 10.1007/s11042-020-09850-1
   [Anonymous], 2005, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2005.268
   Bastanfard A, 2004, COMPUT ANIMAT VIRT W, V15, P347, DOI 10.1002/cav.38
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Berretti S, 2014, VISUAL COMPUT, V30, P1275, DOI 10.1007/s00371-014-0932-7
   Berretti S, 2013, COMPUT GRAPH-UK, V37, P509, DOI 10.1016/j.cag.2013.04.001
   Bhople AR, 2021, MULTIMED TOOLS APPL, V80, P30237, DOI 10.1007/s11042-020-09008-z
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Cai Y, 2019, NEUROCOMPUTING, V363, P375, DOI 10.1016/j.neucom.2019.07.047
   Cai Y, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/678973
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Creusot C, 2013, INT J COMPUT VISION, V102, P146, DOI 10.1007/s11263-012-0605-9
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Dou P, 2017, PROC CVPR IEEE, P1503, DOI 10.1109/CVPR.2017.164
   Elaiwat S, 2015, PATTERN RECOGN, V48, P1235, DOI 10.1016/j.patcog.2014.10.013
   Emambakhsh M, 2017, IEEE T PATTERN ANAL, V39, P995, DOI 10.1109/TPAMI.2016.2565473
   Gauthier JP, 2014, CONF P INDIUM PHOSPH
   Gecer B, 2019, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2019.00125
   Gerig T, 2018, IEEE INT CONF AUTOMA, P75, DOI 10.1109/FG.2018.00021
   Gilani SZ, 2018, PROC CVPR IEEE, P1896, DOI 10.1109/CVPR.2018.00203
   Gilani SZ, 2018, IEEE T PATTERN ANAL, V40, P1584, DOI 10.1109/TPAMI.2017.2725279
   Huang D, 2012, IEEE T INF FOREN SEC, V7, P1551, DOI 10.1109/TIFS.2012.2206807
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Kim D, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P133, DOI 10.1109/BTAS.2017.8272691
   Kingma D. P., 2014, arXiv
   Kollreider K, 2008, PROC CVPR IEEE, P1200
   Lei YJ, 2016, PATTERN RECOGN, V52, P218, DOI 10.1016/j.patcog.2015.09.035
   Li XL, 2012, IMAGE VISION COMPUT, V30, P668, DOI 10.1016/j.imavis.2012.07.011
   Li YY, 2018, ADV NEUR IN, V31
   Liu F, 2017, 3D FACE RECONSTRUCTI
   Liu JX, 2019, IEEE I CONF COMP VIS, P7545, DOI 10.1109/ICCV.2019.00764
   Liu PJ, 2013, IEEE T IMAGE PROCESS, V22, P914, DOI 10.1109/TIP.2012.2222897
   Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212
   Lüthi M, 2018, IEEE T PATTERN ANAL, V40, P1860, DOI 10.1109/TPAMI.2017.2739743
   Mian AS, 2008, INT J COMPUT VISION, V79, P1, DOI 10.1007/s11263-007-0085-5
   Modhej N, 2020, IEEE ACCESS, V8, P212803, DOI 10.1109/ACCESS.2020.3040298
   Mohammadzade H, 2013, IEEE T PATTERN ANAL, V35, P381, DOI 10.1109/TPAMI.2012.107
   Neves J, 2019, IEEE T INF FOREN SEC, V14, P151, DOI 10.1109/TIFS.2018.2846617
   Ouamane A, 2017, IEEE T INF FOREN SEC, V12, P2751, DOI 10.1109/TIFS.2017.2718490
   Paszke A, 2019, ADV NEUR IN, V32
   Patil H, 2015, ARTIF INTELL REV, V44, P393, DOI 10.1007/s10462-015-9431-0
   Qi C., 2017, NeurIPS, P5105, DOI [10.1109/ CVPR.2017.16, DOI 10.1109/CVPR.2017.16]
   Qi CR, 2017, ADV NEUR IN, V30
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Soltanpour S, 2017, PATTERN RECOGN, V72, P391, DOI 10.1016/j.patcog.2017.08.003
   Soltanpour S, 2017, IET BIOMETRICS, V6, P27, DOI 10.1049/iet-bmt.2015.0120
   Song XN, 2018, IEEE T INF FOREN SEC, V13, P2734, DOI 10.1109/TIFS.2018.2833052
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Taskiran M, 2020, DIGIT SIGNAL PROCESS, V106, DOI 10.1016/j.dsp.2020.102809
   Thomas H, 2019, IEEE I CONF COMP VIS, P6420, DOI 10.1109/ICCV.2019.00651
   Toshpulatov M, 2021, IMAGE VISION COMPUT, V108, DOI 10.1016/j.imavis.2021.104119
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Yi Dong, 2014, ARXIV14117923
   Yi HW, 2019, PROC CVPR IEEE, P7655, DOI 10.1109/CVPR.2019.00785
   Yu Y, 2019, IEEE T INF FOREN SEC, V14, P1917, DOI 10.1109/TIFS.2018.2889255
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhang Z., 2019, ARXIV191104731
NR 61
TC 5
Z9 5
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12795
EP 12814
DI 10.1007/s11042-022-12211-9
EA FEB 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000758973600007
DA 2024-07-18
ER

PT J
AU Li, QD
   Fu, Y
   Zhang, ZH
   Fofanah, AJ
   Gao, TG
AF Li, Qingdan
   Fu, Yao
   Zhang, Zehui
   Fofanah, Abdul Joseph
   Gao, Tiegang
TI Medical images lossless recovery based on POB number system and image
   compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lossless recovery; Permutation ordered binary (POB) number system;
   Block-wise compression; Image processing
ID WATERMARKING SCHEME; TAMPERING DETECTION; AUTHENTICATION; LOCALIZATION;
   ROI; PROTECTION
AB To protect the information integrity of the medical images, this paper proposes a secure lossless recovery scheme for medical images based on image block compression and permutation ordered binary (POB) number system, which includes two parts: share generation, and lossless recovery. In the shares generation stage, the region of interest (ROI) of the original medical image and the image block compression coding algorithm JPEG-LS, are firstly adopted to generate the compressed data, which can use limited storage space to place the data repeatedly. Then, after separating the bit-plane, the compressed data are executed by data reorganization and data encryption respectively on the high-plane and the low-plane. Finally, two authentication bits are extracted by 8-bit pixel of two planes to be inserted into the pixel itself, and then the 10-bit pixel is converted into an 8-bit POB value to produce two shares of ShareH and ShareL, respectively. In the lossless recovery stage, data of placing repeatedly can restore the original image. At the same time, three attacks are carried in the two shares, which contain content cropping, content exchange, and text addition. Some comparisons with other schemes present that the proposed scheme implements a better performance under some criteria. Theoretical analysis and experimental results demonstrate that the original image can be recovered losslessly even if two shares are tampered at the ration more than 50%.
C1 [Li, Qingdan; Fu, Yao; Zhang, Zehui; Gao, Tiegang] Nankai Univ, Coll Software, Tianjin 300350, Peoples R China.
   [Fofanah, Abdul Joseph] Milton Margai Univ Educ & Technol, Freetown, Sierra Leone.
C3 Nankai University
RP Gao, TG (corresponding author), Nankai Univ, Coll Software, Tianjin 300350, Peoples R China.
EM lqd18812745024@163.com; FuYao_TJ@163.com; zhangtianxia918@163.com;
   abduljoseph.fofanah@gmail.com; gaotiegang@nankai.edu.cn
OI Fofanah, Abdul Joseph/0000-0001-8742-9325
FU National Science and Technology Major Project, China [2018YFB0204304]
FX This work was supported by the National Science and Technology Major
   Project, China (Grant No. 2018YFB0204304).
CR [Anonymous], 1997, 14495 FCD
   Arnold V. I., 1967, Problemes Ergodiques de la Mecanique Classique
   Arsalan M, 2017, APPL SOFT COMPUT, V51, P168, DOI 10.1016/j.asoc.2016.11.044
   Bhimani D, 2016, 2016 CONFERENCE ON ADVANCES IN SIGNAL PROCESSING (CASP), P223
   Caldelli R, 2006, SIGNAL PROCESS-IMAGE, V21, P890, DOI 10.1016/j.image.2006.08.006
   Chamlawi R, 2010, INFORM SCIENCES, V180, P4909, DOI 10.1016/j.ins.2010.08.039
   Gao GY, 2017, INFORM SCIENCES, V385, P250, DOI 10.1016/j.ins.2017.01.009
   Haddad S, 2017, IRBM, V38, P198, DOI 10.1016/j.irbm.2017.06.007
   Ibn Afjal M, 2019, J VIS COMMUN IMAGE R, V59, P514, DOI 10.1016/j.jvcir.2019.01.042
   Khor HL, 2017, J DIGIT IMAGING, V30, P328, DOI 10.1007/s10278-016-9930-9
   Li J, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-01328-2
   Li L, 2012, PROCEEDINGS OF THE 2012 SECOND INTERNATIONAL CONFERENCE ON INSTRUMENTATION & MEASUREMENT, COMPUTER, COMMUNICATION AND CONTROL (IMCCC 2012), P1247, DOI 10.1109/IMCCC.2012.293
   Liu Y, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107293
   Naskar R, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2487268.2487272
   Sasikaladevi N, 2019, MULTIMED TOOLS APPL, V78, P26163, DOI 10.1007/s11042-019-7738-6
   Shi H, 2021, MULTIMED TOOLS APPL, V80, P24631, DOI 10.1007/s11042-021-10853-9
   Singh D, 2016, J VIS COMMUN IMAGE R, V38, P775, DOI 10.1016/j.jvcir.2016.04.023
   Singh P, 2019, SIGNAL PROCESS-IMAGE, V74, P96, DOI 10.1016/j.image.2019.01.009
   Singh P, 2018, IEEE T CIRC SYST VID, V28, P2116, DOI 10.1109/TCSVT.2017.2716828
   Singh P, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3077140
   Sreekumar A., 2009, Hack, V2009, P33
   Tai WL, 2018, SIGNAL PROCESS-IMAGE, V65, P11, DOI 10.1016/j.image.2018.03.011
   Wang CP, 2020, IEEE T CIRC SYST VID, V30, P4440, DOI 10.1109/TCSVT.2019.2960507
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang XY, 2007, ACTA PHYS SIN-CH ED, V56, P5136, DOI 10.7498/aps.56.5136
   Wang XY, 2021, INFORM SCIENCES, V579, P128, DOI 10.1016/j.ins.2021.07.096
   Wang XY, 2021, INFORM SCIENCES, V569, P217, DOI 10.1016/j.ins.2021.04.013
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Xiang YP, 2019, SIGNAL PROCESS, V162, P282, DOI 10.1016/j.sigpro.2019.04.022
   [徐光宪 Xu Guangxian], 2012, [计算机科学, Computer Science], V39, P79
   Yan XH, 2015, MULTIMED TOOLS APPL, V74, P3231, DOI 10.1007/s11042-013-1784-2
   Zhang XR, 2020, CMC-COMPUT MATER CON, V64, P1435, DOI 10.32604/cmc.2020.011359
   Zhou J, 2020, IEEE ACCESS, V8, P122210, DOI 10.1109/ACCESS.2020.3007550
NR 33
TC 7
Z9 7
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11415
EP 11440
DI 10.1007/s11042-022-12266-8
EA FEB 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757168400004
PM 35194383
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Zhang, H
   Liu, J
AF Zhang, Hang
   Liu, Jian
TI Fuzzy c-means clustering algorithm with deformable spatial information
   for image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fuzzy clustering; Deformable spatial information; Fuzzy c-means; Image
   segmentation
ID LOCAL INFORMATION
AB Due to the fuzzy c-means(FCM) clustering algorithm is very sensitive to noise and outliers, the spatial information derived from neighborhood window is often used to improve its image segmentation performance. However, the geometric structures of neighborhood window are usually fixed for each pixel. This may affect the quality of spatial information. In this paper, a deformable strategy is presented to address this problem. The proposed strategy defines a novel neighborhood window with free deformation form, whose shape can be adjusted adaptively for each pixel. Specifically, the offset is introduced for each pixel within the neighborhood window to obtain the deformable neighborhood window. The offset can be learned in each iteration of FCM. By using the proposed deformable strategy, the FCM algorithms with deformable spatial information can be easily developed based on previous FCM algorithms with spatial information. Those deformable spatial information based FCM algorithms perform well than their original variants on noisy images. In the meantime, the ability of image details preservation of fuzzy local information c-means clustering algorithm (FLICM) is significantly improved by using the deformable strategy. The experiment results of six spatial information based FCM algorithms show that the proposed deformable strategy is very effective.
C1 [Zhang, Hang; Liu, Jian] Hunan Univ, State Key Lab Adv Design & Manufacture Vehicle Bo, Changsha 410082, Hunan, Peoples R China.
C3 Hunan University
RP Liu, J (corresponding author), Hunan Univ, State Key Lab Adv Design & Manufacture Vehicle Bo, Changsha 410082, Hunan, Peoples R China.
EM liujian@hnu.edu.cn
FU China-Japan Science and Technology Joint Committee of the Ministry of
   Science and Technology of the People's Republic of China
   [2017YFE0128400]; Key Project of Science and Technology of Changsha
   [kq1804005]
FX This work is supported by the China-Japan Science and Technology Joint
   Committee of the Ministry of Science and Technology of the People's
   Republic of China (Grant No. 2017YFE0128400) and the Key Project of
   Science and Technology of Changsha (Grant No. kq1804005). Also, the
   authors would like to express their thanks to the reviewers for their
   valuable suggestions.
CR Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Bezdek J. C., 1981, Pattern recognition with fuzzy objective function algorithms
   Cai WL, 2007, PATTERN RECOGN, V40, P825, DOI 10.1016/j.patcog.2006.07.011
   Chatzis SP, 2008, IEEE T FUZZY SYST, V16, P1351, DOI 10.1109/TFUZZ.2008.2005008
   Chen N, 2013, APPL MATH MODEL, V37, P2197, DOI 10.1016/j.apm.2012.04.031
   Chen SC, 2004, IEEE T SYST MAN CY B, V34, P1907, DOI 10.1109/TSMCB.2004.831165
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046
   Gharieb RR, 2017, APPL SOFT COMPUT, V59, P143, DOI 10.1016/j.asoc.2017.05.055
   Ghosh KK, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114485
   Gong MG, 2013, IEEE T IMAGE PROCESS, V22, P573, DOI 10.1109/TIP.2012.2219547
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Gupta S, 2021, VISUAL COMPUT, V37, P447, DOI 10.1007/s00371-020-01814-8
   Han YF, 2007, NEUROCOMPUTING, V70, P665, DOI 10.1016/j.neucom.2006.10.022
   Jaderberg M, 2015, ADV NEUR IN, V28
   Kolhe L, 2021, CLUSTER COMPUT, V24, P953, DOI 10.1007/s10586-020-03171-6
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Miguel, SIGNAL PROCESS-IMAGE, V23, P490
   Pham DL, 1999, PATTERN RECOGN LETT, V20, P57, DOI 10.1016/S0167-8655(98)00121-4
   Senthilkumar C, 2019, CLUSTER COMPUT, V22, P12305, DOI 10.1007/s10586-017-1613-x
   Shang RH, 2016, IEEE J-STARS, V9, P1640, DOI 10.1109/JSTARS.2016.2516014
   Song G, 2018, PROC CVPR IEEE, P1760, DOI 10.1109/CVPR.2018.00189
   Tolias YA, 1998, IEEE T SYST MAN CY A, V28, P359, DOI 10.1109/3468.668967
   Wang LC, 2013, IEEE T MED IMAGING, V32, P943, DOI 10.1109/TMI.2013.2252431
   Zeng S, 2018, IEEE T FUZZY SYST, V26, P1671, DOI 10.1109/TFUZZ.2017.2743679
   ZHANG H, 2021, MEASUREMENT, V174
   Zhang H, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108201
   Zhang MX, 2016, APPL SOFT COMPUT, V48, P621, DOI 10.1016/j.asoc.2016.07.051
   Zhao F, 2014, EXPERT SYST APPL, V41, P4083, DOI 10.1016/j.eswa.2014.01.003
   Zhao F, 2013, NEUROCOMPUTING, V106, P115, DOI 10.1016/j.neucom.2012.10.022
   Zhao F, 2011, SIGNAL PROCESS, V91, P988, DOI 10.1016/j.sigpro.2010.10.001
NR 37
TC 4
Z9 4
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11239
EP 11258
DI 10.1007/s11042-022-11904-5
EA FEB 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000756332000001
DA 2024-07-18
ER

PT J
AU Ahmadian, K
   Reza-Alikhani, HR
AF Ahmadian, Khodabakhsh
   Reza-Alikhani, Hamid-reza
TI Single image super-resolution with self-organization neural networks and
   image laplace gradient operator
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image super-resolution; Self-organizing map; K-nearest neighbor; Image
   enhancement; Laplace gradient operator; Image processing
AB At present, artificial neural networks have received wide applications in the field of image processing and image resolution because of their fast algorithm implementation and their high accuracy. Learning-based super-resolution methods used stochastic computation in their algorithms, leading to a manual and experimental adjustment of the regularization parameter to the solving imaging system model problem. In this paper, we present a new hybrid algorithm for low-resolution image enhancement, whose parameters are automatically adjusted by the training data and, in contrast to other super-resolution methods, do not require regular adjustment parameters. The method is a hybrid method that includes self-organizing maps as a preprocessor, the k-nearest neighbor algorithm as a classifier, and the Laplace operational edge detection operator as an edge extractor. We built a single external dictionary using a combination of low-resolution and high-resolution feature patches and then train our proposed network. Subsequently, we reconstruct the high-resolution image by Converting the low-resolution input image to feature patch vectors. Then for each vector, find the matching neuron in the network and retrieve all the vectors that belong to it. Then we train the k-nearest neighbor algorithm with these vectors plus the input vector and find the best vector most similar to the input vector and reconstruct our high super-resolution image. The proposed image super-resolution method presents in practical experiments better results with better resolution and quality than many traditional and state-of-the-art methods, both visually compared with each other using human and computational benchmarks to compare the quality of the image super-resolution algorithms. The proposed image enhancement method is best for reconstructing high-resolution images that need high-frequency details and sharp edges with a smooth slope of image objects in their structures.
C1 [Ahmadian, Khodabakhsh] Islamic Azad Univ, Dept Elect & Comp Engn, Mahshahr Branch, Mahshahr, Iran.
   [Reza-Alikhani, Hamid-reza] Natl Univ, Dept Elect & Comp Engn, Tafresh Branch, Tafresh, Iran.
C3 Islamic Azad University
RP Ahmadian, K (corresponding author), Islamic Azad Univ, Dept Elect & Comp Engn, Mahshahr Branch, Mahshahr, Iran.
EM Kh.ahmadian@mhriau.ac.ir; Alikhani.hamid@aut.ac.ir
RI ahmadian, khodabakhsh/ACK-0672-2022
OI ahmadian, khodabakhsh/0000-0003-3594-2762
FU Mahshar Branch, Islamic Azad University
FX This study was supported by Mahshar Branch, Islamic Azad University. The
   authors are very grateful for the constructive advice and guidance of
   reviewers.
CR Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   Burger H., 2012, CVPR
   Ding SS, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102224
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Hardie RC, 1997, IEEE T IMAGE PROCESS, V6, P1621, DOI 10.1109/83.650116
   Haykin S., 1999, NEURAL NETWORKS COMP, DOI [10.1017/S0269888998214044, DOI 10.1017/S0269888998214044]
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   HUANG JB, 2015, PROC CVPR IEEE, P5197, DOI DOI 10.1109/CVPR.2015.7299156
   Hui Z, 2020, NEUROCOMPUTING, V404, P50, DOI 10.1016/j.neucom.2020.05.008
   Ignatov A, 2019, LECT NOTES COMPUT SC, V11133, P315, DOI 10.1007/978-3-030-11021-5_20
   Jalali M, 2020, BIOMED SIGNAL PROCES, V58, DOI 10.1016/j.bspc.2020.101868
   Jiang K, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107475
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai W-S, 2017, PROC CVPR IEEE, P624, DOI DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu H, 2020, BIOMED SIGNAL PROCES, V62, DOI 10.1016/j.bspc.2020.102085
   LIU J, 2021, SIGNAL PROCESS, V188
   Macwan R, 2014, INT J COMPUT APPL, V90
   Mao X., 2016, CoRR
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Matsui Y, 2017, MULTIMED TOOLS APPL, V76, P21811, DOI 10.1007/s11042-016-4020-z
   Nasrollahi K, 2014, MACH VISION APPL, V25, P1423, DOI 10.1007/s00138-014-0623-4
   Padraig C, 2007, MULT CLASSIF SYST
   Peleg T, 2014, IEEE T IMAGE PROCESS, V23, P2569, DOI 10.1109/TIP.2014.2305844
   Rauber A., 1999, Methodologies for Knowledge Discovery and Data Mining. Third Pacific-Asia Conference, PAKDD-99. Proceedings, P228
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schuler CJ, 2013, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.2013.142
   Schulter S, 2015, PROC CVPR IEEE, P3791, DOI 10.1109/CVPR.2015.7299003
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Teuvo K, 2014, MATLAB IMPLEMENTATIO, V1st ed.
   Tian CW, 2020, KNOWL-BASED SYST, V205, DOI 10.1016/j.knosys.2020.106235
   Tian CW, 2021, IEEE T MULTIMEDIA, V23, P1489, DOI 10.1109/TMM.2020.2999182
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Vesanto J, 2000, P P MATL DSP C, V99
   Wang X, 2007, IEEE T PATTERN ANAL, V29, P886, DOI 10.1109/TPAMI.2007.1027
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Wu JJ, 2016, IEEE T IMAGE PROCESS, V25, P5369, DOI 10.1109/TIP.2016.2604489
   Yang F, 2017, AIP CONF PROC, V1864, DOI 10.1063/1.4993002
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zheng H, 2017, BMC MED IMAGING, V17, DOI 10.1186/s12880-016-0176-2
NR 53
TC 4
Z9 4
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 10607
EP 10630
DI 10.1007/s11042-022-11970-9
EA FEB 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000756332700028
DA 2024-07-18
ER

PT J
AU Jiang, Y
   Jiang, ZY
   He, L
   Chen, S
AF Jiang, Yi
   Jiang, Zhongyu
   He, Liang
   Chen, Shuai
TI Text recognition in natural scenes based on deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text recognition; Convolution neural network; Attention mechanism;
   Connection time classification; Long short; Term memory network
AB Aiming at the problems of character segmentation and dictionary dependence in text recognition in natural scenes, a text recognition algorithm based on Attention mechanism and connection time classification (CTC) loss is proposed. Convolutional neural network and bidirectional long short - term memory network are used to realize image feature coding, which avoids the gradient vanishing problem of recurrent neural network (RNN) with the increase of time. And the Attention-CTC structure is used to decode the feature sequence, which effectively solves the problem of unconstrained attention decoding. The algorithm avoids extra processing of alignment and subsequent syntax processing, and improves the speed of training convergence and significantly improves the recognition rate of text. It has a certain research value in recognition accuracy. Experimental results show that the algorithm has good robustness to text images with fuzzy fonts and complex background.
C1 [Jiang, Yi] Harbin Univ Sci & Technol, Dept Commun Engn, 52 Xuefu Rd, Harbin, Heilongjiang, Peoples R China.
   [Jiang, Zhongyu; Chen, Shuai] Harbin Univ Sci & Technol, Sch Automat, Harbin, Peoples R China.
   [He, Liang] Northwestern Polytech Univ, Sch Software, Xian, Peoples R China.
C3 Harbin University of Science & Technology; Harbin University of Science
   & Technology; Northwestern Polytechnical University
RP Jiang, ZY (corresponding author), Harbin Univ Sci & Technol, Sch Automat, Harbin, Peoples R China.
EM jasonj@hrbust.edu.cn; 1179544217@qq.com
OI Jiang, Yi/0000-0003-2800-9114
CR Alazab M, 2020, IEEE ACCESS, V8, P85454, DOI 10.1109/ACCESS.2020.2991067
   Bahdanau D., 2015, NEURAL MACHINE TRANS, P89
   Bandanau D, 2016, INT CONF ACOUST SPEE, P4945, DOI 10.1109/ICASSP.2016.7472618
   Chen J., 2020, SPROUTSOCIAL COM MAY, P6
   Chen JN, 2020, SYST ENG SOC CHINA, P640
   Chen ZJ, 2020, SAFETY SCI, V130, DOI 10.1016/j.ssci.2020.104812
   Chen ZJ., 2020, EXPERT SYST APPL, V144, P516
   Fernández-Díaz M, 2020, ENG APPL ARTIF INTEL, V96, DOI 10.1016/j.engappai.2020.103976
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Graves A., 2016, 2016 HONG KONG INT C, P742
   Hakak S, 2021, FUTURE GENER COMP SY, V117, P47, DOI 10.1016/j.future.2020.11.022
   Hari T, 2017, INTERSPEECH, P949, DOI 10.21437/Interspeech.2017-1296
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang XH., 2020, INT J COMPUT INT SYS, V13, P73, DOI [10.2991/ijcis.d.200120.002, DOI 10.2991/IJCIS.D.200120.002]
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jabbari M, 2020, IEEE ENG MED BIO, P3302, DOI 10.1109/EMBC44109.2020.9175279
   Jha G, 2020, MULTIMED TOOLS APPL, V79, P35055, DOI 10.1007/s11042-020-08883-w
   Kim S, 2017, INT CONF ACOUST SPEE, P4835, DOI 10.1109/ICASSP.2017.7953075
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Luong MT, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P11
   Qu SR, 2017, CHIN CONT DECIS CONF, P4789, DOI 10.1109/CCDC.2017.7979342
   Redmon J., 2016, 2016 IEEE Conf. Comp. Vis. Patt. Recog. (CVPR), P779
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Sitalakshmi V., 2018, SECURITY COMMUN NETW, V2018, P807
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tian Z, 2016, LECT NOTES COMPUT SC, V9912, P56, DOI 10.1007/978-3-319-46484-8_4
   Tsai ST, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-18959-8
   Vasan D, 2020, COMPUT NETW, V171, DOI 10.1016/j.comnet.2020.107138
   Wang LL., 2020, CHINESE J ELECTRON, V29, P473
   Xiong HP., 2018, ELECT SCI TECHNOL, V31, P59
   Xu K, 2018, LCANET END TO END LI, P351
   Xu MX, 2019, SUPER RESOLUTION RES, P517
   Xue Haotian, 2015, Electronic Science and Technology, V28, P20, DOI 10.16180/j.cnki.issn1007-7820.2015.05.006
   Yin Zheng, 2016, Electronic Science and Technology, V29, P124, DOI 10.16180/j.cnki.issn1007-7820.2016.01.034
NR 36
TC 1
Z9 1
U1 2
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 10545
EP 10559
DI 10.1007/s11042-022-12024-w
EA FEB 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000756332700030
DA 2024-07-18
ER

PT J
AU Iqbal, N
   Hanif, M
   Ul Rehman, Z
   Zohaib, M
AF Iqbal, Nadeem
   Hanif, Muhammad
   Ul Rehman, Zia
   Zohaib, Muhammad
TI On the novel image encryption based on chaotic system and DNA computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia security; Encryption; Decryption; Chaos; DNA computing
ID SEQUENCE OPERATION; CRYPTANALYSIS; MAP; PERMUTATION
AB A new image encryption scheme is presented based on the chaotic system and the swapping operations of the pixels both at the decimal and DNA levels. By randomly choosing two arrays of the given input image for a number of times, randomly chosen pixels of these two arrays are swapped with each other. Same operation is performed on the two randomly chosen columns to get the scrambled image. Next, an XOR operation is performed between the scrambled image and the key stream of random data given by the chaotic system. Further, both the image data and the streams of random numbers are DNA-encoded. Again, the DNA-encoded pixels data are scrambled the way, scrambling was performed on the decimal data but with the different key streams of random numbers. To realize the effects of diffusion at the DNA level, the DNA-encoded scrambled pixels data and the DNA-encoded key stream are XORed with each other. Finally, the DNA-encoded data is translated back into its decimal equivalent. SHA-256 hash codes for the given input image have been used in the proposed cipher in order to achieve the plaintext sensitivity. The simulation and the performance analysis portray the good security effects, defiance to the varied threats and the bright prospects for the real world application of the proposed cipher.
C1 [Iqbal, Nadeem] Univ Lahore, Dept Comp Sci & IT, Lahore, Pakistan.
   [Hanif, Muhammad] Riphah Int Univ, Fac Comp, Malakand Campus, Islamabad, Pakistan.
   [Ul Rehman, Zia] Bahria Univ, Dept Comp Sci, Lahore Campus, Lahore, Pakistan.
   [Zohaib, Muhammad] Imperial Coll Business Studies, Sch Comp & Informat Sci, Lahore, Pakistan.
C3 University of Lahore
RP Iqbal, N (corresponding author), Univ Lahore, Dept Comp Sci & IT, Lahore, Pakistan.
EM nadeem.iqbal537@gmail.com; muhammad.hanif@riphah.edu.pk;
   zrehman182@gmail.com; mzohaib@imperial.edu.pk
RI Zohaib, Muhammad/KFS-5161-2024; hanif, Muhammad/HJH-5889-2023; Iqbal,
   Nadeem/GWB-9856-2022
OI Iqbal, Nadeem/0000-0002-0954-5563; , Muhammad Hanif/0000-0002-6520-4464;
   Hanif, Dr. Muhammad/0000-0003-2669-2327
CR Abdelfattah Roayat Ismail, 2020, Journal of Physics: Conference Series, V1447, DOI 10.1088/1742-6596/1447/1/012053
   Aqeel-ur-Rehman, 2018, OPTIK, V153, P117, DOI 10.1016/j.ijleo.2017.09.099
   Aqeel-ur-Rehman, 2016, MULTIMED TOOLS APPL, V75, P11241, DOI 10.1007/s11042-015-2851-7
   Babaei M, 2013, NAT COMPUT, V12, P101, DOI 10.1007/s11047-012-9334-9
   Bashir Z, 2021, MULTIMED TOOLS APPL, V80, P1029, DOI 10.1007/s11042-020-09695-8
   Ben Farah MA, 2020, NONLINEAR DYNAM, V99, P3041, DOI 10.1007/s11071-019-05413-8
   Boreale M, 2020, SCI COMPUT PROGRAM, V193, DOI 10.1016/j.scico.2020.102441
   Broumandnia A, 2019, FUTURE GENER COMP SY, V99, P489, DOI 10.1016/j.future.2019.04.005
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen L, 2017, NONLINEAR DYNAM, V87, P1797, DOI 10.1007/s11071-016-3153-y
   ElKamchouchi DH, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22020180
   Enayatifar R, 2015, OPT LASER ENG, V71, P33, DOI 10.1016/j.optlaseng.2015.03.007
   Floating-Point Working Group, 1985, IEEE STAND BIN FLOAT, P754
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Guesmi R, 2021, MULTIMED TOOLS APPL, V80, P1925, DOI 10.1007/s11042-020-09672-1
   Iqbal N, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2021.102809
   Iqbal N, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.2.023025
   Iqbal N, 2019, IEEE ACCESS, V7, P174051, DOI 10.1109/ACCESS.2019.2956389
   King OD, 2007, DISCRETE APPL MATH, V155, P831, DOI 10.1016/j.dam.2005.07.015
   Kulsoom A, 2016, MULTIMED TOOLS APPL, V75, P1, DOI 10.1007/s11042-014-2221-x
   Li CQ, 2011, SIGNAL PROCESS, V91, P949, DOI 10.1016/j.sigpro.2010.09.014
   Li S, 2004, IACR's Crypto ePrint Arch Rep, V374, P2004
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Loukhaoukha K, 2012, J ELECTR COMPUT ENG, V2012, DOI 10.1155/2012/173931
   Nestor T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010083
   Njitacke ZT, 2021, NEURAL COMPUT APPL, V33, P6733, DOI 10.1007/s00521-020-05451-z
   Norouzi B, 2014, NONLINEAR DYNAM, V78, P995, DOI 10.1007/s11071-014-1492-0
   Özkaynak F, 2013, SIG PROCESS COMMUN
   Özkaynak F, 2016, OPTIK, V127, P5190, DOI 10.1016/j.ijleo.2016.03.018
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   Patro K. Abhimanyu Kumar, 2020, Advances in Data and Information Sciences. Proceedings of ICDIS 2019. Lecture Notes in Networks and Systems (LNNS 94), P67, DOI 10.1007/978-981-15-0694-9_8
   Qayyum A, 2020, IEEE ACCESS, V8, P140876, DOI 10.1109/ACCESS.2020.3012912
   Ramesh VP., 2017, RAMANUJAN MATH SOC M, V28, P10
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Sivakumar T, 2016, J INF SCI ENG, V32, P133
   Tamang J, 2021, IEEE ACCESS, V9, P18762, DOI 10.1109/ACCESS.2021.3054250
   Taneja N, 2012, MULTIMED TOOLS APPL, V59, P775, DOI 10.1007/s11042-011-0775-4
   Hoang TM, 2018, OPTIK, V155, P366, DOI 10.1016/j.ijleo.2017.10.072
   Wang B, 2021, OPTIK, V225, DOI 10.1016/j.ijleo.2020.165737
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2020, OPT LASER ENG, V125, DOI 10.1016/j.optlaseng.2019.105851
   Wu JH, 2018, SIGNAL PROCESS, V142, P292, DOI 10.1016/j.sigpro.2017.06.014
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Xiong ZG, 2019, MULTIMED TOOLS APPL, V78, P31035, DOI 10.1007/s11042-018-7081-3
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Yavuz E, 2016, COMPUT ELECTR ENG, V54, P471, DOI 10.1016/j.compeleceng.2015.11.008
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zaman J., 2012, Journal of Theoretical Physics and Cryptography, V1, P18
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P584, DOI 10.1016/j.cnsns.2012.08.010
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   Zhang YP, 2012, ADV INTEL SOFT COMPU, V149, P103
   Zhou GM, 2015, NEUROCOMPUTING, V169, P150, DOI 10.1016/j.neucom.2014.11.095
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 61
TC 16
Z9 17
U1 1
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8107
EP 8137
DI 10.1007/s11042-022-11912-5
EA JAN 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000750302600001
DA 2024-07-18
ER

PT J
AU El Alami, A
   Berrahou, N
   Lakhili, Z
   Mesbah, A
   Berrahou, A
   Qjidaa, H
AF El Alami, Abdelmajid
   Berrahou, Nadia
   Lakhili, Zouhir
   Mesbah, Abderrahim
   Berrahou, Aissam
   Qjidaa, Hassan
TI Efficient color face recognition based on quaternion discrete orthogonal
   moments neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quaternion representation; Quaternion discrete orthogonal moments;
   Neural networks; Noisy conditions; Color face recognition;
   Classification; Time consuming
ID IMAGE-ANALYSIS; FOURIER MOMENTS; INVARIANTS
AB In recent years, with the rapid development of multimedia technologies, color face recognition has attracted more attention in various areas related to the computer vision. Extracting pertinent features from color image is a challenging problem due to the lack of efficient descriptors. Many methods in literature have been reported. However, some inconveniences arising from these methods are: insufficient color information and time consuming for features extraction. In this paper, a new model quaternion discrete orthogonal moments neural networks (QDOMNN) is proposed to improve the accuracy of color face recognition. The quaternion representation is used to represent color image in a holistic manner instead of monochromatic intensity information. Furthermore, the discrete orthogonal moments are used to extract compact and pertinent features from quaternion representation of image. The main purpose of the utilization of quaternion discrete orthogonal moments is to reduce the number of parameters in the input vector of the model, and consequently decreasing the computational time of training process, while improving the classification rate. The performance of our model is evaluated on some face databases, we obtain 100% as classification accuracy on faces94, grimace and GT, 91.93% on FEI, more than 94.72% on faces95 and more than 98.01% on faces96. Experiment results show the outperformance of our model (QDOMNN) against other existing methods in terms of classification rate, and robustness in noisy conditions.
C1 [El Alami, Abdelmajid; Berrahou, Nadia; Lakhili, Zouhir; Qjidaa, Hassan] Sidi Mohamed Ben Abdellah Univ, Fes, Morocco.
   [Mesbah, Abderrahim; Berrahou, Aissam] Mohammed V Univ, Rabat, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Mohammed V University in
   Rabat
RP El Alami, A (corresponding author), Sidi Mohamed Ben Abdellah Univ, Fes, Morocco.
EM abdelmajid.elalami@usmba.ac.ma
RI El Alami, Abdelmajid/CAF-5211-2022; El Alami, Abdelmajid/CAI-1690-2022
OI EL ALAMI, Abdelmajid/0000-0002-2489-661X
CR Akhmedova F, 2019, Recent advances in computer vision, P189
   Almabdy S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9204397
   Brandoni D, 2020, CALCOLO, V57, DOI 10.1007/s10092-020-0358-8
   Cai WW, 2020, IEEE ACCESS, V8, P48451, DOI 10.1109/ACCESS.2020.2979348
   Chen BJ, 2012, SIGNAL PROCESS, V92, P308, DOI 10.1016/j.sigpro.2011.07.018
   Chen BJ, 2015, J MATH IMAGING VIS, V51, P124, DOI 10.1007/s10851-014-0511-6
   Dad N, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.1.011007
   Deng ZY, 2019, IEEE T IMAGE PROCESS, V28, P3102, DOI 10.1109/TIP.2019.2894272
   El Alami A, 2019, 2019 INTERNATIONAL CONFERENCE ON WIRELESS TECHNOLOGIES, EMBEDDED AND INTELLIGENT SYSTEMS (WITS), DOI 10.1109/wits.2019.8723788
   Feng QH, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020315
   Guo GD, 2019, COMPUT VIS IMAGE UND, V189, DOI 10.1016/j.cviu.2019.102805
   Guo LQ, 2011, PATTERN RECOGN, V44, P187, DOI 10.1016/j.patcog.2010.08.017
   Guo LQ, 2014, INFORM SCIENCES, V273, P132, DOI 10.1016/j.ins.2014.03.037
   Hamilton W., 1866, ELEMENTS QUATERNIONS
   Hassaballah M, 2015, IET COMPUT VIS, V9, P614, DOI 10.1049/iet-cvi.2014.0084
   Hosny K.M., 2019, RECENT ADV COMPUTER, P169, DOI DOI 10.1007/978-3-030-03000-1_7
   Hosny KM, 2021, NEURAL COMPUT APPL, V33, P5419, DOI 10.1007/s00521-020-05280-0
   Kanan HR, 2008, APPL MATH COMPUT, V205, P706, DOI 10.1016/j.amc.2008.05.114
   Koschan A., 2008, DIGITAL COLOR IMAGE
   Lakhili Z, 2020, INT C EL ENG REN EN, P151, DOI [10.1007/978-981-15-6259-4_14, DOI 10.1007/978-981-15-6259-4_14]
   Lakhili Z, 2020, MULTIMED TOOLS APPL, V79, P18883, DOI 10.1007/s11042-020-08654-7
   Lakhili Z, 2019, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON NETWORKING, INFORMATION SYSTEMS & SECURITY (NISS19), DOI 10.1145/3320326.3320398
   Lakhili Z, 2019, PROCEDIA COMPUT SCI, V148, P12, DOI 10.1016/j.procs.2019.01.002
   Lan RS, 2016, IEEE T IMAGE PROCESS, V25, P566, DOI 10.1109/TIP.2015.2507404
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2015, PATTERN RECOGN, V48, P2290, DOI 10.1016/j.patcog.2015.01.021
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Masi I, 2019, IEEE T PATTERN ANAL, V41, P379, DOI 10.1109/TPAMI.2018.2792452
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Muqeet Mohd Abdul, 2019, Applied Computing and Informatics, V15, P163, DOI 10.1016/j.aci.2017.11.002
   Nwankpa C., 2018, ARXIV181103378
   Parcollet T, 2018, INTERSPEECH, P22
   Rani JS, 2012, SADHANA-ACAD P ENG S, V37, P441, DOI 10.1007/s12046-012-0090-4
   Rassem TH., 2017, INT J ELECT COMPUTER, V7, P1594, DOI [10.11591/ijece.v7i3.pp1594-1601, DOI 10.11591/IJECE.V7I3.PP1594-1601]
   Reverdy P, 2016, IEEE T AUTOM SCI ENG, V13, P54, DOI 10.1109/TASE.2015.2499244
   Shao ZH, 2014, PATTERN RECOGN, V47, P603, DOI 10.1016/j.patcog.2013.08.016
   Singh C, 2018, OPT LASER TECHNOL, V106, P234, DOI 10.1016/j.optlastec.2018.03.033
   Singh R, 2017, MULTIMED TOOLS APPL, V76, P19005, DOI 10.1007/s11042-016-4342-x
   Spacek L, 2008, DESCRIPTION COLLECTI
   Subakan ON, 2011, INT J COMPUT VISION, V91, P233, DOI 10.1007/s11263-010-0388-9
   Wang XY, 2015, OPT LASER TECHNOL, V66, P78, DOI 10.1016/j.optlastec.2014.07.020
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xi M, 2016, IEEE IMAGE PROC, P3224, DOI 10.1109/ICIP.2016.7532955
   Xu D, 2017, NEURAL NETW WORLD, V27, P271, DOI 10.14311/NNW.2017.27.014
   Yang HY, 2016, FUND INFORM, V145, P189, DOI 10.3233/FI-2016-1354
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
   Zafar U, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0406-y
   Zeng SN, 2019, NEURAL COMPUT APPL, V31, P5689, DOI 10.1007/s00521-018-3403-7
   Zhou J, 2005, LECT NOTES COMPUT SC, V3656, P524, DOI 10.1007/11559573_65
   Zhu H., 2014, INT J SIGNAL PROCESS, V7, P149, DOI [10.14257/ijsip.2014.7.6.13, DOI 10.14257/IJSIP.2014.7.6.13]
NR 51
TC 7
Z9 7
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 7685
EP 7710
DI 10.1007/s11042-021-11669-3
EA JAN 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000750865600001
DA 2024-07-18
ER

PT J
AU Zolfaghari, M
   Sajedi, H
AF Zolfaghari, Mohammad
   Sajedi, Hedieh
TI A survey on automated detection and classification of acute leukemia and
   WBCs in microscopic blood cells
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Leukemia; Data augmentation; Image preprocessing; Image segmentation;
   Feature selection; Classification; Traditional machine learning; DNN
   learning
ID ACUTE LYMPHOBLASTIC-LEUKEMIA; SEGMENTATION; DIAGNOSIS; SYSTEM; SMEAR;
   RECOGNITION; SVM
AB Leukemia (blood cancer) is an unusual spread of White Blood Cells or Leukocytes (WBCs) in the bone marrow and blood. Pathologists can diagnose leukemia by looking at a person's blood sample under a microscope. They identify and categorize leukemia by counting various blood cells and morphological features. This technique is time-consuming for the prediction of leukemia. The pathologist's professional skills and experiences may be affecting this procedure, too. In computer vision, traditional machine learning and deep learning techniques are practical roadmaps that increase the accuracy and speed in diagnosing and classifying medical images such as microscopic blood cells. This paper provides a comprehensive analysis of the detection and classification of acute leukemia and WBCs in the microscopic blood cells. First, we have divided the previous works into six categories based on the output of the models. Then, we describe various steps of detection and classification of acute leukemia and WBCs, including Data Augmentation, Preprocessing, Segmentation, Feature Extraction, Feature Selection (Reduction), Classification, and focus on classification step in the methods. Finally, we divide automated detection and classification of acute leukemia and WBCs into three categories, including traditional, Deep Neural Network (DNN), and mixture (traditional and DNN) methods based on the type of classifier in the classification step and analyze them. The results of this study show that in the diagnosis and classification of acute leukemia and WBCs, the Support Vector Machine (SVM) classifier in traditional machine learning models and Convolutional Neural Network (CNN) classifier in deep learning models have widely employed. The performance metrics of the models that use these classifiers compared to the others model are higher. We propose providing models in detecting and classify acute leukemia and WBCs that use a combination of SVM and CNN classifiers in their classification step to achieve optimum performance metrics.
C1 [Zolfaghari, Mohammad] Univ Tehran, Dept Comp Sci, Kish Int Campus, Kish, Iran.
   [Sajedi, Hedieh] Univ Tehran, Dept Math Stat & Comp Sci, Tehran, Iran.
C3 University of Tehran
RP Sajedi, H (corresponding author), Univ Tehran, Dept Math Stat & Comp Sci, Tehran, Iran.
EM mmzolfaghari@ut.ac.ir; hhsajedi@ut.ac.ir
CR Abdeldaim AM, 2018, STUD COMPUT INTELL, V730, P131, DOI 10.1007/978-3-319-63754-9_7
   Acharya V, 2019, MED BIOL ENG COMPUT, V57, P1783, DOI 10.1007/s11517-019-01984-1
   Agaian S, 2018, COMP M BIO BIO E-IV, V6, P303, DOI 10.1080/21681163.2016.1234948
   Ahmed N, 2019, DIAGNOSTICS, V9, DOI 10.3390/diagnostics9030104
   Al-jaboriy S., 2019, SEGMENTATION DETECTI, P511
   Al-jaboriy SS, 2019, PATTERN RECOGN LETT, V125, P85, DOI 10.1016/j.patrec.2019.03.024
   Alsalem MA, 2018, COMPUT METH PROG BIO, V158, P93, DOI 10.1016/j.cmpb.2018.02.005
   Anilkumar K.K., 2018, INT C CIRC SYST DIG
   Bagasjvara RG, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON SCIENCE AND TECHNOLOGY-COMPUTER (ICST)
   Banik PP, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE IN INFORMATION AND COMMUNICATION (ICAIIC 2019), P238, DOI 10.1109/icaiic.2019.8669049
   Banik PP, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113211
   BENNETT JM, 1976, BRIT J HAEMATOL, V33, P451, DOI 10.1111/j.1365-2141.1976.tb03563.x
   Benomar M.L., 2019, INT J BIOMED ENG TEC
   Bibi N, 2020, J HEALTHC ENG, V2020, DOI 10.1155/2020/6648574
   Bodzas A, 2020, FRONT BIOENG BIOTECH, V8, DOI 10.3389/fbioe.2020.01005
   Claro M, 2020, INT CONF SYST SIGNAL, P63, DOI [10.1109/iwssip48289.2020.9145406, 10.1109/IWSSIP48289.2020.9145406]
   Dasariraju S, 2020, BIOENGINEERING-BASEL, V7, DOI 10.3390/bioengineering7040120
   Dhanachandra N, 2015, PROCEDIA COMPUT SCI, V54, P764, DOI 10.1016/j.procs.2015.06.090
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Gautam A, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P1023, DOI 10.1109/TENCON.2016.7848161
   Gayathri, 2018, INT 744 RES J ENG TE, V5, P4254
   Ghane N, 2019, EXCLI J, V18, P382, DOI 10.17179/excli2019-1292
   Gonzalez R.C., 2018, Digital Image Processing
   Habibzadeh M, 2018, PROC SPIE, V10696, DOI 10.1117/12.2311282
   Hariprasath S., 2019, 2 INT C ADV SCI TECH
   Hegde RB, 2020, J DIGIT IMAGING, V33, P361, DOI 10.1007/s10278-019-00288-y
   Huang DC, 2012, J SYST SOFTWARE, V85, P2104, DOI 10.1016/j.jss.2012.04.012
   Macawile MJ, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON CONTROL AND ROBOTICS ENGINEERING (ICCRE), P259, DOI 10.1109/ICCRE.2018.8376476
   Jha KK, 2019, COMPUT METH PROG BIO, V179, DOI 10.1016/j.cmpb.2019.104987
   Jin, 2016, ENCY MACHINE LEARNIN
   Jothi G, 2019, NEURAL COMPUT APPL, V31, P5175, DOI 10.1007/s00521-018-3359-7
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Kassani SH, 2019, I C INF COMM TECH CO, P519, DOI 10.1109/ictc46691.2019.8939878
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar P., 2017, INT C ADV COMP COMM
   Labati R.D., 2018, 18 IEEE INT C IMAGE
   Lai JZC, 2013, PATTERN RECOGN, V46, P2538, DOI 10.1016/j.patcog.2013.02.003
   Laosai J, 2018, BIOMED SIGNAL PROCES, V44, P127, DOI 10.1016/j.bspc.2018.01.020
   Liang GB, 2018, IEEE ACCESS, V6, P36188, DOI 10.1109/ACCESS.2018.2846685
   Lin LQ, 2018, J ALGORITHMS COMPUT, V13, P1, DOI 10.1177/1748301818813322
   Liu Y., 2019, CNMC CHALLENGE CLASS
   Loey M, 2020, COMPUTERS, V9, DOI 10.3390/computers9020029
   Loni J, 2014, INT CONF COMM SYST, P1, DOI 10.1109/CSNT.2014.9
   Madhloom HT, 2012, INT CONF ADV COMPUT, P330, DOI 10.1109/ACSAT.2012.62
   Mirmohammadi P, 2018, CURR SCI INDIA, V115, P1512, DOI 10.18520/cs/v115/i8/1512-1518
   Mishra S, 2019, BIOMED SIGNAL PROCES, V47, P303, DOI 10.1016/j.bspc.2018.08.012
   Mohapatra S, 2014, NEURAL COMPUT APPL, V24, P1887, DOI 10.1007/s00521-013-1438-3
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pandey P, 2020, ALGO INTELL SY, P1, DOI 10.1007/978-981-15-1100-4_1
   Pang SC, 2019, MED BIOL ENG COMPUT, V57, P107, DOI 10.1007/s11517-018-1819-y
   Pansombut T, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/7519603
   Pardakhti N, 2020, MULTIMED TOOLS APPL, V79, P25051, DOI 10.1007/s11042-020-09121-z
   Patel N, 2015, PROCEDIA COMPUT SCI, V58, P635, DOI 10.1016/j.procs.2015.08.082
   Patil S., 2020, INT J FUTURE GEN COM, V13, P1539
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Putzu L, 2013, PROCEEDINGS IWBBIO 2013: INTERNATIONAL WORK-CONFERENCE ON BIOINFORMATICS AND BIOMEDICAL ENGINEERING, P99
   Ravikumar S, 2016, ARTIF CELL NANOMED B, V44, P985, DOI 10.3109/21691401.2015.1008506
   Rawat J, 2017, BIOCYBERN BIOMED ENG, V37, P637, DOI 10.1016/j.bbe.2017.07.003
   Razzak MI, 2017, IEEE COMPUT SOC CONF, P801, DOI 10.1109/CVPRW.2017.111
   Rehman A, 2018, MICROSC RES TECHNIQ, V81, P1310, DOI 10.1002/jemt.23139
   Safuan SNM., 2019, INDONESIAN J ELECT E, V14, P597
   Sah S., 2007, Machine Learning: A Review of Learning Types, DOI DOI 10.20944/PREPRINTS202007.0230.V1
   Sahlol AT, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-59215-9
   Shafique S, 2018, TECHNOL CANCER RES T, V17, DOI 10.1177/1533033818802789
   Shafique S, 2018, COMPUT MATH METHOD M, V2018, DOI 10.1155/2018/6125289
   Shahin AI, 2019, COMPUT METH PROG BIO, V168, P69, DOI 10.1016/j.cmpb.2017.11.015
   Supardi N.Z., 2012, IEEE 8 INT C SIGN PR
   Terwilliger T, 2017, BLOOD CANCER J, V7, DOI 10.1038/bcj.2017.53
   Thanh T. T. P., 2018, International Journal of Computer Theory and Engineering, V10, P54, DOI 10.7763/IJCTE.2018.V10.1198
   Umamaheswari Duraiswamy, 2018, CIT. Journal of Computing and Information Technology, V26, P131, DOI 10.20532/cit.2018.1004123
   Vogado L.H, 2020, ANAIS ESTENDIDOS DA
   Vogado LHS, 2018, ENG APPL ARTIF INTEL, V72, P415, DOI 10.1016/j.engappai.2018.04.024
   Vogado LHS, 2017, SIBGRAPI, P367, DOI 10.1109/SIBGRAPI.2017.55
   Wang JL., 2018, IEEE INT S SIGN PROC
   Wiharto W., 2019, TELKOMNIKA TELECOMMU, V17, P645, DOI DOI 10.12928/TELKOMNIKA.V17I2.8666
   Yu W, 2017, INT CONF ASIC, P1041, DOI 10.1109/ASICON.2017.8252657
   ZACK GW, 1977, J HISTOCHEM CYTOCHEM, V25, P741, DOI 10.1177/25.7.70454
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zaitoun NM, 2015, PROCEDIA COMPUT SCI, V65, P797, DOI 10.1016/j.procs.2015.09.027
   Zhang QH, 2016, CAAI T INTELL TECHNO, V1, P323, DOI 10.1016/j.trit.2016.11.001
   Zhao JW, 2017, MED BIOL ENG COMPUT, V55, P1287, DOI 10.1007/s11517-016-1590-x
NR 81
TC 10
Z9 10
U1 1
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6723
EP 6753
DI 10.1007/s11042-022-12108-7
EA JAN 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000743891900005
DA 2024-07-18
ER

PT J
AU Prudviraj, J
   Sravani, Y
   Mohan, CK
AF Prudviraj, Jeripothula
   Sravani, Yenduri
   Mohan, C. Krishna
TI Incorporating attentive multi-scale context information for image
   captioning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image captioning; Visual attention; Multi-scale context information;
   Image encoding mechanism
AB In this paper, we propose a novel encoding framework to learn the multi-scale context information of the visual scene for image captioning task. The devised multi-scale context information constitutes spatial, semantic, and instance level features of an input mage. We draw spatial features from early convolutional layers, and multi-scale semantic features are achieved by employing a feature pyramid network on top of deep convolutional neural networks. Then, we concatenate the spatial and multi-scale semantic features to harvest fine-to-coarse details of the visual scene. Further, the instance level features are captured by employing a bi-linear interpolation technique on fused representation to hold object-level semantics of an image. We exploit an attention mechanism on attained features to guide the caption decoding module. In addition, we explore various combinations of encoding techniques to acquire global and local features of an image. The efficacy of the proposed approaches is demonstrated on the COCO dataset.
C1 [Prudviraj, Jeripothula; Sravani, Yenduri; Mohan, C. Krishna] Indian Inst Technol Hyderabad, Dept Comp Sci, Hyderabad, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Hyderabad
RP Prudviraj, J (corresponding author), Indian Inst Technol Hyderabad, Dept Comp Sci, Hyderabad, India.
EM cs17resch01005@iith.ac.in
OI , JERIPOTHULA PRUDVIRAJ/0000-0002-6653-4991
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   [Anonymous], 2013, EMNLP
   [Anonymous], CoRR abs/1511.07122
   [Anonymous], 2013, P 2013 C EMP METH NA
   Arik S.O., 2019, ARXIV190807442
   Biswas P, 2005, I CONF VLSI DESIGN, P651
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Breve B, 2021, BIG DATA RES, V25, DOI 10.1016/j.bdr.2021.100240
   Cai DL, 2018, LEC NO MULTI IND ENG, P499, DOI 10.1007/978-3-319-59280-0_40
   Caruccio L, 2020, ACM J DATA INF QUAL, V12, DOI 10.1145/3397462
   Chen L, 2019, ASIA-PAC J ATMOS SCI, V55, P303
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Chen S, 2018, LECT NOTES COMPUT SC, V11215, P72, DOI 10.1007/978-3-030-01252-6_5
   Chen X, 2015, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2015.7298856
   Cho K., 2014, ARXIV14061078
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755
   Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059
   Dai Zihang, 2019, arXiv
   Diop R, 2011, BIOL MED PHYS BIOMED, P227, DOI 10.1007/978-1-4419-7835-6_10
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Firat Orhan, 2016, P 2016 C N AM CHAPT, P866
   Fu K, 2017, IEEE T PATTERN ANAL, V39, P2321, DOI 10.1109/TPAMI.2016.2642953
   Gan Z, 2017, PROC CVPR IEEE, P1141, DOI 10.1109/CVPR.2017.127
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hossain MZ, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3295748
   Hsieh HY, 2021, MULTIMED TOOLS APPL, V80, P12525, DOI 10.1007/s11042-020-10292-y
   Huang L, 2019, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2019.00473
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Karpathy Andrej, 2014, Advances in neural information processing systems, P1889
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Li L, 2017, P AAAI C ART INT, V31
   Li LH, 2018, IEEE T MULTIMEDIA, V20, P726, DOI 10.1109/TMM.2017.2751140
   Li ZR, 2019, ICMLC 2019: 2019 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING, P91, DOI 10.1145/3318299.3318332
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Ma Xutai, 2019, ARXIV190912406
   Mao J, 2014, CELL DEATH DIS, V5, DOI 10.1038/cddis.2013.515
   Mitchell M, 2012, P 13 C EUR CHAPT ASS, P747
   Ordonez V., 2011, ADV NEURAL INFORM PR, P1143
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parikh, 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299087
   Pedersoli M, 2017, IEEE I CONF COMP VIS, P1251, DOI 10.1109/ICCV.2017.140
   Peng YX, 2019, IEEE T MULTIMEDIA, V21, P1538, DOI 10.1109/TMM.2018.2877885
   Rensink RA, 2000, VIS COGN, V7, P17, DOI 10.1080/135062800394667
   Su JS, 2019, NEUROCOMPUTING, V367, P144, DOI 10.1016/j.neucom.2019.08.012
   Sutskever I., 2014, ADV NEURAL INFORM PR, V4, P3104, DOI DOI 10.5555/2969033.2969173
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tan JH, 2019, IEEE T MULTIMEDIA, V21, P2686, DOI 10.1109/TMM.2019.2904878
   Tian P, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13071184
   Venugopalan S, 2017, PROC CVPR IEEE, P1170, DOI 10.1109/CVPR.2017.130
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wu LX, 2020, IEEE T MULTIMEDIA, V22, P808, DOI 10.1109/TMM.2019.2931815
   Wu Q, 2018, IEEE T PATTERN ANAL, V40, P1367, DOI 10.1109/TPAMI.2017.2708709
   Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29
   Xiao XY, 2019, IEEE T MULTIMEDIA, V21, P2942, DOI 10.1109/TMM.2019.2915033
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang Y., 2011, P C EMP METH NAT LAN, P444
   Yang ZL, 2017, LECT NOTES COMPUT SC, V10667, P109, DOI 10.1007/978-3-319-71589-6_10
   Yao T, 2017, IEEE I CONF COMP VIS, P4904, DOI 10.1109/ICCV.2017.524
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Yu NG, 2019, IEEE T IMAGE PROCESS, V28, P2743, DOI 10.1109/TIP.2018.2889922
   Zhang SY, 2021, IEEE ACCESS, V9, P27638, DOI 10.1109/ACCESS.2021.3058425
   Zhang XD, 2020, NEUROCOMPUTING, V395, P212, DOI 10.1016/j.neucom.2018.02.112
   Zhou L, 2020, IEEE T IMAGE PROCESS, V29, P694, DOI 10.1109/TIP.2019.2928144
NR 70
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10017
EP 10037
DI 10.1007/s11042-021-11895-9
EA JAN 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000742319000010
DA 2024-07-18
ER

PT J
AU Gómez-Huélamo, C
   Del Egido, J
   Bergasa, LM
   Barea, R
   López-Guillén, E
   Araluce, J
   Antunes, M
AF Gomez-Huelamo, Carlos
   Del Egido, Javier
   Miguel Bergasa, Luis
   Barea, Rafael
   Lopez-Guillen, Elena
   Araluce, Javier
   Antunes, Miguel
TI 360° real-time and power-efficient 3D DAMOT for autonomous driving
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real-time; CARLA; LiDAR; 3D multi-object tracking; ROS; DAMOT;
   Autonomous navigation
AB Autonomous Driving (AD) promises an efficient, comfortable and safe driving experience. Nevertheless, fatalities involving vehicles equipped with Automated Driving Systems (ADSs) are on the rise, especially those related to the perception module of the vehicle. This paper presents a real-time and power-efficient 3D Multi-Object Detection and Tracking (DAMOT) method proposed for Intelligent Vehicles (IV) applications, allowing the vehicle to track 360 degrees surrounding objects as a preliminary stage to perform trajectory forecasting to prevent collisions and anticipate the ego-vehicle to future traffic scenarios. First, we present our DAMOT pipeline based on Fast Encoders for object detection and a combination of a 3D Kalman Filter and Hungarian Algorithm, used for state estimation and data association respectively. We extend our previous work ellaborating a preliminary version of sensor fusion based DAMOT, merging the extracted features by a Convolutional Neural Network (CNN) using camera information for long-term re-identification and obstacles retrieved by the 3D object detector. Both pipelines exploit the concepts of lightweight Linux containers using the Docker approach to provide the system with isolation, flexibility and portability, and standard communication in robotics using the Robot Operating System (ROS). Second, both pipelines are validated using the recently proposed KITTI-3DMOT evaluation tool that demonstrates the full strength of 3D localization and tracking of a MOT system. Finally, the most efficient architecture is validated in some interesting traffic scenarios implemented in the CARLA (Car Learning to Act) open-source driving simulator and in our real-world autonomous electric car using the NVIDIA AGX Xavier, an AI embedded system for autonomous machines, studying its performance in a controlled but realistic urban environment with real-time execution (results).
C1 [Gomez-Huelamo, Carlos; Del Egido, Javier; Miguel Bergasa, Luis; Barea, Rafael; Lopez-Guillen, Elena; Araluce, Javier; Antunes, Miguel] Univ Alcala UAH, Dept Elect, Madrid, Spain.
C3 Universidad de Alcala
RP Gómez-Huélamo, C (corresponding author), Univ Alcala UAH, Dept Elect, Madrid, Spain.
EM carlos.gomezh@edu.uah.es; javier.egido@edu.uah.es; luism.bergasa@uah.es;
   rafael.barea@uah.es; elena.lopezg@uah.es; javier.araluce@edu.uah.es;
   miguel.antunes@edu.uah.es
RI Antunes, Miguel/JYP-8253-2024; Bergasa, Luis M./H-9810-2013; Barea,
   Rafael/R-5760-2016
OI Antunes, Miguel/0009-0008-5627-5325; Bergasa, Luis
   M./0000-0002-0087-3077; Araluce, Javier/0000-0001-5101-0485;
   Lopez-Guillen, Elena/0000-0002-8145-9045; Gomez-Huelamo,
   Carlos/0000-0002-3819-3747
FU CRUE-CSIC; Springer Nature
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature.
CR Baser E, 2019, IEEE INT VEH SYM, P1426, DOI [10.1109/ivs.2019.8813779, 10.1109/IVS.2019.8813779]
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Chiu H.-K., 2020, ARXIV200105673
   Choi WG, 2015, IEEE I CONF COMP VIS, P3029, DOI 10.1109/ICCV.2015.347
   Dao MQ, 2021, ARXIV PREPRINT ARXIV
   DelEgido J, 2020, WORKSH PHYS AG, P241
   Dosovitskiy A., 2017, P 1 ANN C ROB LEARN, P1, DOI DOI 10.48550/ARXIV.1711.03938
   Frossard D, 2018, IEEE INT CONF ROBOT, P635, DOI 10.1109/ICRA.2018.8462884
   Geiger A., 2012, CVPR
   Gomez-Huelamo C., 2020, WORKSH PHYS AG, P44
   Gómez-Huélamo C, 2020, IEEE INT C INTELL TR
   Gómez-Huelamo C, 2019, IEEE INT C INTELL TR, P2305, DOI 10.1109/ITSC.2019.8917017
   Jullien JM, 2009, ICALT: 2009 IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, P509, DOI 10.1109/ICALT.2009.24
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Königshofe H, 2019, IEEE INT C INTELL TR, P1405, DOI 10.1109/ITSC.2019.8917330
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Lang AH, 2019, PROC CVPR IEEE, P12689, DOI 10.1109/CVPR.2019.01298
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Luiten J, 2021, INT J COMPUT VISION, V129, P548, DOI 10.1007/s11263-020-01375-2
   Merkel D., 2014, LINUX J, V2014, P2, DOI DOI 10.5555/2600239.2600241
   Mousavian A, 2017, PROC CVPR IEEE, P7074, DOI DOI 10.1109/CVPR.2017.597
   Osep A., 2017, P IEEE INT C ROB AUT, P1988
   Patil A, 2019, IEEE INT CONF ROBOT, P9552, DOI [10.1109/icra.2019.8793925, 10.1109/ICRA.2019.8793925]
   Pirsiavash H, 2011, PROC CVPR IEEE, P1201, DOI 10.1109/CVPR.2011.5995604
   Pitas I., 2020, ARXIV PREPRINT ARXIV
   Qi CR, 2017, ADV NEUR IN, V30
   Qin ZY, 2019, PROC CVPR IEEE, P7607, DOI 10.1109/CVPR.2019.00780
   Quigley M, 2009, IEEE INT CONF ROBOT, P3604
   Sanders A., 2016, INTRO UNREAL ENGINE
   Scheidegger S, 2018, IEEE INT VEH SYM, P433
   Schoner, 2017, DRIV SIM C STUTTG
   Schulter S, 2017, PROC CVPR IEEE, P2730, DOI 10.1109/CVPR.2017.292
   Shaoshuai Shi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10526, DOI 10.1109/CVPR42600.2020.01054
   Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086
   Shi SS, 2021, IEEE T PATTERN ANAL, V43, P2647, DOI 10.1109/TPAMI.2020.2977026
   Simon M, 2019, IEEE COMPUT SOC CONF, P1190, DOI 10.1109/CVPRW.2019.00158
   Song SR, 2014, LECT NOTES COMPUT SC, V8694, P634, DOI 10.1007/978-3-319-10599-4_41
   Taxonomy S., 2016, Definitions for terms related to driving automation systems for on-road motor vehicles (j3016)
   Team OD, 2020, OP OP SOURC TOOLB 3D
   Voigtlaender P, 2019, PROC CVPR IEEE, P7934, DOI 10.1109/CVPR.2019.00813
   Weng X., 2019, A Baseline for 3D Multi-Object Tracking
   Weng XS, 2019, IEEE INT CONF COMP V, P857, DOI 10.1109/ICCVW.2019.00114
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Xu Y., 2019, IEEE ICC, DOI DOI 10.1109/icc.2019.8761264
   Yan Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103337
   Yurtsever E, 2020, IEEE ACCESS, V8, P58443, DOI 10.1109/ACCESS.2020.2983149
   Zhang L, 2008, INT C WAVEL ANAL PAT, P11, DOI 10.1109/ICWAPR.2008.4635742
   Zhang WW, 2019, IEEE I CONF COMP VIS, P2365, DOI 10.1109/ICCV.2019.00245
   Zhou X., 2019, arXiv
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 51
TC 2
Z9 2
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 26915
EP 26940
DI 10.1007/s11042-021-11624-2
EA JAN 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000740429700023
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhang, T
AF Zhang, Tao
TI Deepfake generation and detection, a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deepfake; Detection; Generation; Survey; Media forensics
ID NETWORKS
AB Deepfake refers to realistic, but fake images, sounds, and videos generated by articial intelligence methods. Recent advances in deepfake generation make deepfake more realistic and easier to make. Deepfake has been a signicant threat to national security, democracy, society, and our privacy, which calls for deepfake detection methods to combat potential threats. In the paper, we make a survey on state-ofthe-art deepfake generation methods, detection methods, and existing datasets. Current deepfake generation methods can be classified into face swapping and facial reenactment. Deepfake detection methods are mainly based features and machine learning methods. There are still some challenges for deepfake detection, such as progress on deepfake generation, lack of high quality datasets and benchmark. Future trends on deepfake detection can be efficient, robust and systematical detection methods and high quality datasets.
C1 [Zhang, Tao] Beihang Univ, Sch Cyber Sci & Technol, Beijing, Peoples R China.
   [Zhang, Tao] Guilin Univ Elect Technol, Guangxi Key Lab Cryptog & Informat Secur, Guilin, Peoples R China.
   [Zhang, Tao] Guilin Univ Elect Technol, Guangxi Key Lab Trusted Software, Guilin, Peoples R China.
   [Zhang, Tao] Key Lab Film & TV Media Technol Zhejiang Prov, Hangzhou, Peoples R China.
C3 Beihang University; Guilin University of Electronic Technology; Guilin
   University of Electronic Technology
RP Zhang, T (corresponding author), Beihang Univ, Sch Cyber Sci & Technol, Beijing, Peoples R China.; Zhang, T (corresponding author), Guilin Univ Elect Technol, Guangxi Key Lab Cryptog & Informat Secur, Guilin, Peoples R China.; Zhang, T (corresponding author), Guilin Univ Elect Technol, Guangxi Key Lab Trusted Software, Guilin, Peoples R China.; Zhang, T (corresponding author), Key Lab Film & TV Media Technol Zhejiang Prov, Hangzhou, Peoples R China.
EM tao.zhang.cn@outlook.com
FU Guangxi Key Laboratory of Cryptography and Information Security
   [GCIS201806]; Guangxi Key Laboratory of Trusted Software [kx202016]; Key
   Lab of Film and TV Media Technology of Zhejiang Province [2020E10015];
   Guangxi Key Laboratory of Hybrid Computation and IC Design Analysis,
   Guangxi University for Nationalities [GXIC20-03]; Key Laboratory of
   Oceanographic Big Data Mining & Application of Zhejiang Province
   [obdma202001]
FX This work was supported by Guangxi Key Laboratory of Cryptography and
   Information Security (GCIS201806), Guangxi Key Laboratory of Trusted
   Software (No. kx202016), Key Lab of Film and TV Media Technology of
   Zhejiang Province (No.2020E10015), Guangxi Key Laboratory of Hybrid
   Computation and IC Design Analysis, Guangxi University for
   Nationalities(GXIC20-03), Key Laboratory of Oceanographic Big Data
   Mining & Application of Zhejiang Province(obdma202001). We'd like to
   thank Zelei Cheng from Purdue University and Yingjie Wang from Virginia
   Tech for writing assistance, language editing, and proofreading.
CR Afchar D, 2018, IEEE INT WORKS INFOR
   Agarwal S., 2019, P IEEE C COMP VIS PA, P38, DOI DOI 10.1109/ICCV.2015.425
   Ajder H., 2019, The State of Deepfakes: Landscape, Threats, and Impact
   Amerini Irene, 2020, IH&MMSec '20: Proceedings of the 2020 ACM Workshop on Information Hiding and Multimedia Security, P97, DOI 10.1145/3369412.3395070
   Amerini I, 2019, IEEE INT CONF COMP V, P1205, DOI 10.1109/ICCVW.2019.00152
   CARLINI N, 2020, 2020 IEEE CVF C COMP
   Chan Caroline, 2018, Everybody dance now
   Chang X, 2020, CHIN CONTR CONF, P7252, DOI [10.23919/CCC50068.2020.9189596, 10.23919/ccc50068.2020.9189596]
   Chen DY, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/8902701
   Chesney B, 2019, CALIF LAW REV, V107, P1753, DOI 10.15779/Z38RV0D15J
   Chintha A, 2020, IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2020), DOI 10.1109/ijcb48548.2020.9304936
   Chintha A, 2020, IEEE J-STSP, V14, P1024, DOI 10.1109/JSTSP.2020.2999185
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Ciftci UA, 2020, IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2020)
   Dang LM, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8122610
   Dieleman S, 2016, ARXIV160903499
   Ding, 2019, ARXIV190904217
   Dolhansky B., 2020, arXiv preprint arXiv:200607397
   Dolhansky Brian, 2019, ARXIV191008854
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Fernandes S, 2019, IEEE INT CONF COMP V, P1721, DOI 10.1109/ICCVW.2019.00213
   Gandhi A, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207034
   Geng ZL, 2019, PROC CVPR IEEE, P9813, DOI 10.1109/CVPR.2019.01005
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   GOUHARA K, 1991, IEEE IJCNN, P746, DOI 10.1109/IJCNN.1991.170489
   Guan HY, 2019, IEEE WINT CONF APPL, P63, DOI 10.1109/WACVW.2019.00018
   Guarnera L, 2020, IEEE COMPUT SOC CONF, P2841, DOI 10.1109/CVPRW50498.2020.00341
   Güera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   Gupta Parul, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P519, DOI 10.1145/3382507.3418857
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hsu CC, 2018, INT SYMP COMP CONS, P388, DOI 10.1109/IS3C.2018.00104
   Huang YH, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1217, DOI 10.1145/3394171.3413732
   Huh M, 2018, LECT NOTES COMPUT SC, V11215, P106, DOI 10.1007/978-3-030-01252-6_7
   Hyeongwoo Kim, 2018, ACM Transactions on Graphics, V37, DOI [10.1145/3197517.3201283, 10.18022/acfco.2018.37.1.001]
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jung T, 2020, IEEE ACCESS, V8, P83144, DOI 10.1109/ACCESS.2020.2988660
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Kharbat T., 2019, I C COMP SYST APPLIC, P1, DOI DOI 10.1109/aiccsa47632.2019.9035360
   Khodabakhsh A, 2020, LECT NOTE INFORM, VP-306
   Khodabakhsh A, 2018, 2018 INTERNATIONAL CONFERENCE OF THE BIOMETRICS SPECIAL INTEREST GROUP (BIOSIG)
   Korshunov P., 2018, arXiv
   Korshunov P, 2019, INT CONF BIOMETR
   Korshunov P, 2018, EUR SIGNAL PR CONF, P2375, DOI 10.23919/EUSIPCO.2018.8553270
   Korshunova I, 2017, IEEE I CONF COMP VIS, P3697, DOI 10.1109/ICCV.2017.397
   Li HD, 2018, ASIAPAC SIGN INFO PR, P722, DOI 10.23919/APSIPA.2018.8659461
   [李艳歌 Li Yange], 2018, [高分子通报, Polymer Bulletin], P46
   Li YZ, 2018, IEEE INT WORKS INFOR
   Li YZ, 2020, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR42600.2020.00327
   Liang T, 2020, PROC INT C TOOLS ART, P675, DOI 10.1109/ICTAI50040.2020.00108
   Liu LW, 2019, IEEE C ELEC DEVICES, DOI 10.1109/edssc.2019.8754181
   Lu DX, 2020, 2020 CONFERENCE ON LASERS AND ELECTRO-OPTICS PACIFIC RIM (CLEO-PR), DOI 10.1364/CLEOPR.2020.P2_9
   Ma S, 2020, IEEE INT SYM BROADB, DOI 10.1109/BMSB49480.2020.9379523
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   Mittal T, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2823, DOI 10.1145/3394171.3413570
   Mo HX, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P43, DOI 10.1145/3206004.3206009
   Montserrat DM, 2020, IEEE INT WORKS INFOR, DOI 10.1109/WIFS49906.2020.9360909
   Nataraj L., 2019, Electron. Imaging, V5, P1, DOI 10.2352/
   Natsume R., 2018, ARXIV180403447, P1, DOI [DOI 10.1145/3230744.3230818, 10.1145/3230744.3230818]
   Neves JC, 2020, IEEE J-STSP, V14, P1038, DOI 10.1109/JSTSP.2020.3007250
   Nguyen H, 2020, LECT NOTE INFORM, VP-306
   Nguyen HH, 2019, INT CONF ACOUST SPEE, P2307, DOI 10.1109/ICASSP.2019.8682602
   Nirkin Y, 2019, IEEE I CONF COMP VIS, P7183, DOI 10.1109/ICCV.2019.00728
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Patel M., 2020, 2020 IEEE 5 INT C CO, V2020, P796, DOI DOI 10.1109/ICCCA49541.2020.9250803
   Pu JM, 2020, ANN COMPUT SECURITY, P913, DOI 10.1145/3427228.3427285
   Pumarola A, 2018, LECT NOTES COMPUT SC, V11214, P835, DOI 10.1007/978-3-030-01249-6_50
   Rahmouni N, 2017, IEEE INT WORKS INFOR
   Rana MS, 2020, 2020 7TH IEEE INTERNATIONAL CONFERENCE ON CYBER SECURITY AND CLOUD COMPUTING (CSCLOUD 2020)/2020 6TH IEEE INTERNATIONAL CONFERENCE ON EDGE COMPUTING AND SCALABLE CLOUD (EDGECOM 2020), P70, DOI 10.1109/CSCloud-EdgeCom49738.2020.00021
   Ranjan P, 2020, 2020 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND SIGNAL PROCESSING (AISP), DOI 10.1109/aisp48273.2020.9073131
   Rössler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Rssler, 2018, ARXIV180309179
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sabir E., 2019, INTERFACES GUI, V3, P80
   Samuel O, 2020, IEEE GLOB COMM CONF, DOI 10.1109/GLOBECOM42002.2020.9348231
   Stamm Matthew C., 2016, P 4 ACM WORKSH INF H, P5
   Theobalt Chris- tian, 2016, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2016.262
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Thies J, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201350
   Tursman E, 2020, IEEE COMPUT SOC CONF, P2784, DOI 10.1109/CVPRW50498.2020.00335
   Wang SY, 2019, IEEE I CONF COMP VIS, P10071, DOI 10.1109/ICCV.2019.01017
   Xie D, 2020, 2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), P1866, DOI 10.1109/SSCI47803.2020.9308428
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Yu Ning, 2018, ARXIV181108180
   Zakharov E, 2019, IEEE I CONF COMP VIS, P9458, DOI 10.1109/ICCV.2019.00955
   Zhao, 2020, CAPTURING PERSISTENC, DOI [10.1007/978-3-030-41579-2_37, DOI 10.1007/978-3-030-41579-2_37]
   Zheng Zhao, 2020, ICCAI '20: Proceedings of the 2020 6th International Conference on Computing and Artificial Intelligence, P291, DOI 10.1145/3404555.3404564
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
   Zhu K, 2020, 2020 IEEE 5 INT C DA
   Zi BJ, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2382, DOI 10.1145/3394171.3413769
NR 91
TC 27
Z9 29
U1 66
U2 226
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6259
EP 6276
DI 10.1007/s11042-021-11733-y
EA JAN 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000740419000005
DA 2024-07-18
ER

PT J
AU Liu, S
   Liu, YN
   Zhu, XD
   Liu, Z
AF Liu, Shuai
   Liu, Yuanning
   Zhu, Xiaodong
   Liu, Zhen
TI An iris quality evaluation method with pre-recognition screening
   function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Iris image quality evaluation; Category homology; Qualified logic
   standard; Qualified index data; Pre-recognition screening
AB An iris image quality evaluation method for iris multi-category recognition scenes is designed in this article. The problem that the poor applicability of uniformly quality indexes and the iris physiological morphology in different states leads to poor expression of qualified image features can be solved. The method can also improve the overall effect of quality evaluation on the iris recognition process. In this method, a person with authoritative knowledge sets the qualified logic standard for qualified eye images. Every single person need to take homology to digitally express the qualified logic standard as qualified index data in each person. People are used as the evaluation unit to make the qualified indicators closer to everyone's physiological form through the category homology mode. It can avoid the difficulty of adding new person to the quality assessment and the inflexible adjustment of changes in the collection status due to the mechanization of the qualified indexes setting. The applicability of the qualified indexes can be improved. In addition, the category homology mode carry out category screening based on physiological morphology before feature expression, which can narrow the scope of iris recognition, and give quality evaluation a pre-recognition screening function. The experiment results of different iris libraries show that the qualified indexes of the method are reasonably. It can eliminate some unqualified iris categories. It can also prove that the idea of pre-screening for iris recognition in the quality evaluation process is feasible.
C1 [Liu, Shuai; Liu, Yuanning; Zhu, Xiaodong] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Liu, Shuai; Liu, Yuanning; Zhu, Xiaodong] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.
   [Liu, Zhen] Nagasaki Inst Appl Sci, Grad Sch Engn, Nagasaki 8510193, Japan.
C3 Jilin University; Jilin University; Nagasaki Institute of Applied
   Science
RP Zhu, XD (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.; Zhu, XD (corresponding author), Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.
EM zhuxd@jlu.edu.cn
RI Liu, Shuai/G-8181-2018
OI Liu, Shuai/0000-0003-1337-6034; Zhu, Xiaodong/0000-0002-7200-7629
FU National Natural Science Foundation of China (NSFC) [61471181]; Natural
   Science Foundation of Jilin Province [YDZJ202101ZYTS144]; Jilin Province
   Industrial Innovation Special Fund Project [2019C053-2]; Jilin
   Provincial Key Laboratory of Biometrics New Technology
FX This research was funded by the National Natural Science Foundation of
   China (NSFC), Grant Number 61471181; Natural Science Foundation of Jilin
   Province, Grant Number YDZJ202101ZYTS144. Jilin Province Industrial
   Innovation Special Fund Project, Grant Number 2019C053-2. Thanks to the
   Jilin Provincial Key Laboratory of Biometrics New Technology for
   supporting this project.
CR [Anonymous], 2018, JLU Iris Image Database
   Chen LL, 2013, 2013 2ND INTERNATIONAL SYMPOSIUM ON INSTRUMENTATION AND MEASUREMENT, SENSOR NETWORK AND AUTOMATION (IMSNA), P300, DOI 10.1109/IMSNA.2013.6743274
   Chu X, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9214532
   Cui JL, 2004, LECT NOTES COMPUT SC, V3072, P442
   Dargan S, 2020, EXPERT SYST APPL, V143, DOI 10.1016/j.eswa.2019.113114
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Daugman J, 2003, PATTERN RECOGN, V36, P279, DOI 10.1016/S0031-3203(02)00030-4
   [冯薪桦 Feng Xinhua], 2005, [中国图象图形学报. A, Journal of image and graphics], V10, P731
   Feng Xinhua, 2007, Journal of Tsinghua University (Science and Technology), V47, P80
   Llano EG, 2018, PATTERN RECOGN LETT, V101, P44, DOI 10.1016/j.patrec.2017.11.012
   Garea-Llano E, 2019, LECT NOTES COMPUT SC, V11896, P198, DOI 10.1007/978-3-030-33904-3_18
   John B, 2020, IEEE T VIS COMPUT GR, V26, P1880, DOI 10.1109/TVCG.2020.2973052
   Kumar SVM, 2019, 6 IEEE INT C SMART S, P14
   Lavanya M, 2021, J AMB INTEL HUM COMP, V12, P8913, DOI 10.1007/s12652-020-02691-8
   [李星光 Li Xingguang], 2014, [中国图象图形学报, Journal of Image and Graphics], V19, P813
   Liu S, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0232319
   Liu S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061785
   Liu S, 2019, LECT NOTES COMPUT SC, V11818, P337, DOI 10.1007/978-3-030-31456-9_38
   Liu S, 2019, IEEE ACCESS, V7, P132871, DOI 10.1109/ACCESS.2019.2941225
   Liu Shuai, 2018, Journal of Jilin University (Science Edition), V56, P1156, DOI 10.13413/j.cnki.jdxblxb.2018.05.20
   [刘帅 Liu Shuai], 2018, [计算机辅助设计与图形学学报, Journal of Computer-Aided Design & Computer Graphics], V30, P1604
   Mandalapu H, 2018, 2018 14TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS), P587, DOI 10.1109/SITIS.2018.00095
   Némesin V, 2016, SIGNAL IMAGE VIDEO P, V10, P153, DOI 10.1007/s11760-014-0720-x
   Nsimba CB, 2019, MULTIMED TOOLS APPL, V78, P31959, DOI 10.1007/s11042-019-07916-3
   Susitha N, 2019, COGN SYST RES, V57, P78, DOI 10.1016/j.cogsys.2018.09.029
   Wang Shou-jue, 2002, Acta Electronica Sinica, V30, P1417
   Wu CD, 2020, IET IMAGE PROCESS, V14, P2588, DOI 10.1049/iet-ipr.2018.5716
   Yu L, 2015, J COMPUT INFORM SYST, V11, P4221
   Zhou YH, 2014, INT CONF INSTR MEAS, P809, DOI 10.1109/IMCCC.2014.171
   Zhu X, 2006, CHIN J SCI INSTRUM, V27, P2173
NR 31
TC 1
Z9 1
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 907
EP 925
DI 10.1007/s11042-021-11377-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8O9DG
UT WOS:000926130400001
DA 2024-07-18
ER

PT J
AU Karthik, P
   Parashar, M
   Reka, SS
   Rajamani, KT
   Heinrich, MP
AF Karthik, Pullalarevu
   Parashar, Mansi
   Reka, S. Sofana
   Rajamani, Kumar T.
   Heinrich, Mattias P.
TI Semantic segmentation for plant phenotyping using advanced deep learning
   pipelines
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Phenotyping; U-Net; Attention-Net; Attention augmented net; Semantic
   segmentation
ID ARABIDOPSIS
AB Large strides have been made in the field of semantic segmentation which finds its application in extensive areas of research. However, these advancements have not been completely utilized in the field of plant phenotyping. Deriving quantitative plant phenotypes in a non-destructive manner from plant images is a key challenge that strongly relies on the precise segmentation of plant images. In this paper, we propose novel semantic segmentation pipelines for the task to improve the automated phenotyping process. In this work architectures such as U-Net, Attention-Net and Attention-Augmented Net are introduced that are trained on the Arabidopsis Thaliana plant dataset released under the CVPPP14 competition. Dice coefficient is used as the evaluation metric to compare performances of the proposed architectures, and also benchmark them against existing algorithms in literature. Results of semantic segmentation of Rosette plants shows the state-of-the-art results, with attention net achieving a 0.985 dice score that easily outperforms all the other deep learning and image processing techniques proposed earlier for plant segmentation in this domain. Results are exhibited with comparison analysis successfully with these advanced deep learning architectures and can be used as a base for plant phenotyping related applications.
C1 [Karthik, Pullalarevu; Reka, S. Sofana] Vellore Inst Technol, Sch Elect Engn, Chennai, Tamil Nadu, India.
   [Parashar, Mansi] Vellore Inst Technol, Sch Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Rajamani, Kumar T.; Heinrich, Mattias P.] Univ Lubeck, Inst Med Informat, Lubeck, Germany.
C3 Vellore Institute of Technology (VIT); VIT Chennai; Vellore Institute of
   Technology (VIT); VIT Chennai; University of Lubeck
RP Reka, SS (corresponding author), Vellore Inst Technol, Sch Elect Engn, Chennai, Tamil Nadu, India.
EM chocos.sofana@gmail.com
RI Rajamani, Kumar/AAH-4281-2019
OI Rajamani, Kumar/0000-0003-2327-5819; S, Sofana Reka/0000-0002-4057-1911
CR Aich S, 2018, ARXIV PREPRINT ARXIV
   Aich S, 2017, IEEE INT CONF COMP V, P2080, DOI 10.1109/ICCVW.2017.244
   Alexandratos N., 2012, WORLD AGR 2030 2050, DOI [DOI 10.22004/AG.ECON.288998, 10.22004/ag.econ.288998]
   Atanbori J, 2019, MACH VISION APPL, V31, DOI 10.1007/s00138-019-01051-7
   Augustin M, 2016, MACH VISION APPL, V27, P647, DOI 10.1007/s00138-015-0720-z
   Bell J, 2017, IET COMPUT VIS, V11, P113, DOI 10.1049/iet-cvi.2016.0127
   Bello I, 2019, IEEE I CONF COMP VIS, P3285, DOI 10.1109/ICCV.2019.00338
   Chan W, 2016, INT CONF ACOUST SPEE, P4960, DOI 10.1109/ICASSP.2016.7472621
   Chorowski J, 2015, ADV NEUR IN, V28
   Choudhury SD, 2019, FRONT PLANT SCI, V10, DOI 10.3389/fpls.2019.00508
   Danzi D, 2019, FRONT PLANT SCI, V10, DOI 10.3389/fpls.2019.00015
   Dong H, 2017, COMM COM INF SC, V723, P506, DOI 10.1007/978-3-319-60964-5_44
   Dong X, 2019, MED PHYS, V46, P2157, DOI 10.1002/mp.13458
   Dornbusch T, 2012, FUNCT PLANT BIOL, V39, P860, DOI 10.1071/FP12018
   Furbank RT, 2011, TRENDS PLANT SCI, V16, P635, DOI 10.1016/j.tplants.2011.09.005
   Giuffrida M.V., 2015, P COMP VIS PROB PLAN, p1.1, DOI [10.5244/C.29.CVPPP.1, DOI 10.5244/C.29.CVPPP.1]
   Hahnloser RHR, 2000, NATURE, V405, P947, DOI 10.1038/35016072
   Isensee F, 2021, NAT METHODS, V18, P203, DOI 10.1038/s41592-020-01008-z
   King DB, 2015, ACS SYM SER, V1214, P1
   Klose R., 2009, BORNIMER AGRARTECHNI, V69, P12
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lozej J, 2018, 2018 IEEE INT WORK C, P16, DOI [DOI 10.1109/IWOBI.2018.8464213, 10.1109/IWOBI.2018.8464213]
   Minervini M, 2016, PATTERN RECOGN LETT, V81, P80, DOI 10.1016/j.patrec.2015.10.013
   Norman B, 2018, RADIOLOGY, V288, P177, DOI 10.1148/radiol.2018172322
   O'Malley RC, 2010, PLANT J, V61, P928, DOI 10.1111/j.1365-313X.2010.04119.x
   Pape JM, 2015, LECT NOTES COMPUT SC, V8928, P61, DOI 10.1007/978-3-319-16220-1_5
   Pound MP, 2017, GIGASCIENCE, V6, DOI 10.1093/gigascience/gix083
   Ramachandran P, 2019, ADV NEUR IN, V32
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sakurai S, 2018, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS (ICPRAM 2018), P332, DOI 10.5220/0006576303320339
   Santos TT, 2015, LECT NOTES COMPUT SC, V8928, P247, DOI 10.1007/978-3-319-16220-1_18
   Scharr H, 2016, MACH VISION APPL, V27, P585, DOI 10.1007/s00138-015-0737-3
   Sevastopolsky A., 2017, Pattern Recognition and Image Analysis, V27, P618, DOI 10.1134/S1054661817030269
   Smith LN, 2017, IEEE WINT CONF APPL, P464, DOI 10.1109/WACV.2017.58
   Wu YZ, 2019, IEEE INT CONF BIG DA, P1971, DOI [10.1109/BigData47090.2019.9006104, 10.1109/bigdata47090.2019.9006104]
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang BS, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4040
   Yu F., 2017, PROC CVPR IEEE, P472, DOI [DOI 10.1109/CVPR.2017.75, 10.1109/CVPR.2017.75]
   Zambaldi Vinicius, 2018, INT C LEARN REPR
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
NR 41
TC 3
Z9 3
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 4535
EP 4547
DI 10.1007/s11042-021-11770-7
EA DEC 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000730052100003
DA 2024-07-18
ER

PT J
AU Li, JN
   Fei, JL
   Cheng, SC
   Tang, Z
   Hui, GB
AF Li, Jianjun
   Fei, Jialuo
   Cheng, Shichao
   Tang, Zheng
   Hui, Guobao
TI TSG-net: a residual-based informing network for 3D Gaze estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gaze estimation; True gaze; Single gaze; Head pose
ID TRACKING
AB The appearance-based method for gaze estimation has great potential to work well under various conditions, but current learning-based methods ignore inferior eye images in datasets caused by poor eye region locating, occlusions and abnormal head poses. These images badly impact the accuracy of estimation. In the study, inspired by binocular vision characteristics, we propose two cooperative sub-networks, True Gaze Consistency Network (TG-Net) and Single Gaze Inconsistency Network(SG-Net) which composes TSG-Net. TG-Net and SG-Net cooperate through a residual paradigm and Informing module. More specially, TG-Net explicitly extracts the consistency of paired eyes and weights high-level features from two paired-eye images utilizing SE-Block and an artificial gaze direction, named True Gaze. SG-Net outputs residual momentums based on True Gaze for better estimation of paired eyes. Experimental results on three benchmark datasets demonstrate that the proposed method performs competitively against the existed representative CNN-Based methods. TSG-Net improves on the state-of-the-art by 22% on MPIIGaze and shows more advantages in additional analysis.
C1 [Li, Jianjun; Fei, Jialuo; Cheng, Shichao] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou, Peoples R China.
   [Li, Jianjun; Fei, Jialuo; Cheng, Shichao] Key Lab Brain Machine Collaborat Intelligence Zhe, Hangzhou, Zhejiang, Peoples R China.
   [Tang, Zheng; Hui, Guobao] Key Lab Data Link Technol CETC, Xian, Peoples R China.
C3 Hangzhou Dianzi University
RP Li, JN (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou, Peoples R China.; Li, JN (corresponding author), Key Lab Brain Machine Collaborat Intelligence Zhe, Hangzhou, Zhejiang, Peoples R China.
EM jianjun.li@hdu.edu.cn; 398080890@qq.com
OI Li, Jianjun/0000-0001-6658-9709
FU National Science Fund of China [61871170, KY2017210A001]; Key Laboratory
   of Brain Machine Collaborative Intelligence of Zhejiang Province
FX This work was supported in part by National Science Fund of China
   no.61871170; The Basic Research Program of KY2017210A001; Key Laboratory
   of Brain Machine Collaborative Intelligence of Zhejiang Province.
CR [Anonymous], 2006, P S EYE TRACK RES AP, DOI DOI 10.1145/1117309.1117349
   Cazzato D, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20133739
   Chen HT, 2020, PROC CVPR IEEE, P1465, DOI 10.1109/CVPR42600.2020.00154
   Cheng YH, 2018, LECT NOTES COMPUT SC, V11218, P105, DOI 10.1007/978-3-030-01264-9_7
   Chennamma H., 2013, arXiv Prepr. arXiv1312.6410, V4, P388
   Fischer T, 2018, LECT NOTES COMPUT SC, V11214, P339, DOI 10.1007/978-3-030-01249-6_21
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Kaur H, 2020, IEEE WINTER C APPL C, P310
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Krafka K, 2016, PROC CVPR IEEE, P2176, DOI 10.1109/CVPR.2016.239
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lu F, 2014, IEEE T PATTERN ANAL, V36, P2033, DOI 10.1109/TPAMI.2014.2313123
   Mora K. A. F., 2014, P S EYE TRACK RES AP, P255, DOI [10.1145/2578153.2578190, 10.1145/2578153]
   Morimoto CH, 2005, COMPUT VIS IMAGE UND, V98, P4, DOI 10.1016/j.cviu.2004.07.010
   Park S, 2019, IEEE I CONF COMP VIS, P9367, DOI 10.1109/ICCV.2019.00946
   Park S, 2018, LECT NOTES COMPUT SC, V11217, P741, DOI 10.1007/978-3-030-01261-8_44
   Ranjan R, 2018, IEEE COMPUT SOC CONF, P2237, DOI 10.1109/CVPRW.2018.00290
   Sandler Mark, 2018, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2018.00474, DOI 10.1109/CVPR.2018.00474]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sugano Y, 2014, PROC CVPR IEEE, P1821, DOI 10.1109/CVPR.2014.235
   Tan KH, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P191, DOI 10.1109/ACV.2002.1182180
   Valenti R, 2012, IEEE T IMAGE PROCESS, V21, P802, DOI 10.1109/TIP.2011.2162740
   Vaswani A, 2017, ADV NEUR IN, V30
   Walsh T., 2010, VISUAL FIELDS EXAMIN, DOI [10.1093/oso/9780195389685.001.0001, DOI 10.1093/OSO/9780195389685.001.0001]
   Wilson AC, 2017, ADV NEUR IN, V30
   Yamazoe H, 2008, PROCEEDINGS OF THE EYE TRACKING RESEARCH AND APPLICATIONS SYMPOSIUM (ETRA 2008), P245, DOI 10.1145/1344471.1344527
   Yoo DH, 2005, COMPUT VIS IMAGE UND, V98, P25, DOI 10.1016/j.cviu.2004.07.011
   Zhang X., 2015, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, DOI 10.1109/CVPR.2015.7299081
   Zhang XC, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P193, DOI 10.1145/3126594.3126614
   Zhang XC, 2019, IEEE T PATTERN ANAL, V41, P162, DOI 10.1109/TPAMI.2017.2778103
   Zhu ZW, 2006, INT C PATT RECOG, P1132
   Zhu ZW, 2005, PROC CVPR IEEE, P918
NR 34
TC 0
Z9 0
U1 3
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3647
EP 3662
DI 10.1007/s11042-021-11666-6
EA NOV 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000719681800001
DA 2024-07-18
ER

PT J
AU Boussakssou, M
   Ezzikouri, H
   Erritali, M
AF Boussakssou, M.
   Ezzikouri, H.
   Erritali, M.
TI Chatbot in Arabic language using seq to seq model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Seq2seq; Arabic chatbot dialogue; System conversation agents
ID TRANSLITERATION; SEQUENCE
AB A conversational agent (chatbot) is a software that can communicate with humans using natural language. Conversation modeling is an extremely important topic in natural language processing and artificial intelligence (AI). Indeed, since the birth of AI, creating a good chatbot remains one of the most difficult challenges in this field. Although chatbots can be used for a variety of tasks, they generally need to understand what users are saying and to provide appropriate answers to their questions. In this paper, we present midoBot: a deep learning Arabic chatbot based on the seq2seq model. midoBot is capable of conversing with humans on popular conversation topics through text. We built the model and tested it in the Tensorflow 2 deep learning framework using the most seq 2 seq Model architectures. We use a dataset of similar to 81,659 pairs of conversations created manually and without any handcrafted rules. Our algorithm was trained on a VM on google cloud (GPU TESLA K80 10 GO). The results obtained are significant, In most questions the chatbot was able to reproduce good answers.
C1 [Boussakssou, M.; Ezzikouri, H.; Erritali, M.] Sultan Moulay Slimane Univ, TIAD Lab, FST Beni Mellal, Beni Mellal, Morocco.
C3 Sultan Moulay Slimane University of Beni Mellal
RP Boussakssou, M (corresponding author), Sultan Moulay Slimane Univ, TIAD Lab, FST Beni Mellal, Beni Mellal, Morocco.
EM boussakssoumohamed@gmail.com
CR Al-Ghadhban D, 2020, INT J ADV COMPUT SC, V11, P452
   AlHumoud S, 2018, INT J ADV COMPUT SC, V9, P535
   Ali D.A., 2016, P INT C COMP LING CO, P208
   Alotaiby F., 2012, J ENG COMPUT INNOV, V3, P11, DOI [10.5897/JECI11.053, DOI 10.5897/JECI11.053]
   Ameur MSH, 2017, PROCEDIA COMPUT SCI, V117, P287, DOI 10.1016/j.procs.2017.10.120
   Antoun W., 2020, ARABERT TRANSFORMER
   Cho K., 2014, ARXIV14061078
   ElJundi O, 2019, FOURTH ARABIC NATURAL LANGUAGE PROCESSING WORKSHOP (WANLP 2019), P68
   Fadhil A, 2019, OLLOBOT TOWARDS TEXT, DOI 10.13140/RG.2.2.16090.90560
   Fouad M, 2020, MASDAR NOVEL SEQUENC, DOI 10.1007/978-3-030-29513-4_26
   Goda Y., 2014, Information and System in Education, V13, P1, DOI [DOI 10.12937/EJSISE.13.1, 10.12937/EJSISE.13.1]
   Microsoft, 2017, MICR BOT FRAM
   Mozannar H, 2019, FOURTH ARABIC NATURAL LANGUAGE PROCESSING WORKSHOP (WANLP 2019), P108
   Nguyen Huyen T. M., 2017, A Neural Chatbot with Personality
   Palasundram K, 2019, INT J EMERG TECHNOL, V14, P56, DOI 10.3991/ijet.v14i24.12187
   Serban IV, 2017, ARXIV PREPRINT ARXIV
   Shang L., 2015, Neural responding machine for short-text conversation
   Soliman A, 2017, PROCEDIA COMPUT SCI, V117, P256, DOI 10.1016/j.procs.2017.10.117
   Sutskever I, 2014, ADV NEUR IN, V27
   Turing A. M., 1950, Mind, London, N. S., V59, P433, DOI [DOI 10.1007/978-1-4020-6710-5_3, DOI 10.1093/MIND/LIX.236.433]
   Vinyals Oriol, 2015, ARXIV150605869
   Wallace Richard S., 2009, Parsing the Turing Test: Philosophical and Methodological Issues in the Quest for the Thinking Computer, P181, DOI [10.1007/978-1-4020-6710-5_13, DOI 10.1007/978-1-4020-6710-5_13]
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991
   Yin, 2019, DEEP LEARNING BASED
   Younes J, 2018, PROCEDIA COMPUT SCI, V142, P238, DOI 10.1016/j.procs.2018.10.481
NR 25
TC 10
Z9 10
U1 6
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2859
EP 2871
DI 10.1007/s11042-021-11709-y
EA NOV 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000714884600001
DA 2024-07-18
ER

PT J
AU Das, A
   Bhardwaj, K
   Patra, S
AF Das, Arundhati
   Bhardwaj, Kaushal
   Patra, Swarnajyoti
TI Deep convolution neural network with automatic attribute profiles for
   hyperspectral image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral images; Attribute profiles; Mathematical morphology;
   Convolutional neural network; Spectral-spatial classification
AB Performance of deep convolutional neural network (CNN) has shown tremendous improvement when applied to various image classifications including hyperspectral images (HSIs). However, CNN requires a large number of labeled samples to train its parameters in different layers, the scarcity of which, in HSIs leads to overfitting problem. Prior integration of spectral-spatial information acts complementary to the deep features resulting in reduced computational load of deep CNN and also helps in mitigating overfitting problem. In this paper, we propose a CNN based classification model that first integrates spectral-spatial information by using an extended attribute profile constructed by selecting suitable threshold values automatically. Then, the constructed spectral-spatial features are utilized by 2D or 3D deep CNN models for classification. Experimental results on three real HSI data sets show that the proposed model can successfully integrate the individual strength of both the automatic extended attribute profile and deep CNN, and provide better classification accuracies.
C1 [Das, Arundhati; Patra, Swarnajyoti] Tezpur Univ, Comp Sci & Engn Dept, Tezpur 784028, Assam, India.
   [Bhardwaj, Kaushal] Indian Inst Informat Technol, Comp Sci & Engn Dept, Senapati 795002, Manipur, India.
C3 Tezpur University
RP Patra, S (corresponding author), Tezpur Univ, Comp Sci & Engn Dept, Tezpur 784028, Assam, India.
EM kaushal@iiitmanipur.ac.in; swpatra@tezu.ernet.in
OI Patra, Swarnajyoti/0000-0003-4300-9307; Das,
   Arundhati/0000-0001-5691-394X
FU All India Council for Technical Education, New Delhi, India
FX This work was supported in part by the RPS-NER Research Grant from the
   All India Council for Technical Education, New Delhi, India. Authors
   would like to thank Dr. S. Prasad for providing University of Houston
   data set and Dr. P. Ghamisi for providing standard training and test
   sets of the data sets used in the experiments.
CR Aptoula E, 2016, IEEE GEOSCI REMOTE S, V13, P1970, DOI 10.1109/LGRS.2016.2619354
   Benediktsson JA, 2005, IEEE T GEOSCI REMOTE, V43, P480, DOI 10.1109/TGRS.2004.842478
   Bhardwaj K, 2019, IEEE T GEOSCI REMOTE, V57, P7731, DOI 10.1109/TGRS.2019.2916169
   Bhardwaj K, 2018, ISPRS J PHOTOGRAMM, V138, P139, DOI 10.1016/j.isprsjprs.2018.02.005
   Cao CH, 2019, MULTIMED TOOLS APPL, V78, P15011, DOI 10.1007/s11042-018-6885-5
   Cavallaro G, 2017, IEEE T IMAGE PROCESS, V26, P1859, DOI 10.1109/TIP.2017.2664667
   Chen YS, 2017, IEEE GEOSCI REMOTE S, V14, P2355, DOI 10.1109/LGRS.2017.2764915
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Chen YS, 2015, IEEE J-STARS, V8, P2381, DOI 10.1109/JSTARS.2015.2388577
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Dalla Mura M, 2010, INT J REMOTE SENS, V31, P5975, DOI 10.1080/01431161.2010.512425
   Dalla Mura M, 2010, IEEE T GEOSCI REMOTE, V48, P3747, DOI 10.1109/TGRS.2010.2048116
   Das A, 2018, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2018.00008
   Das A, 2020, SOFT COMPUT, V24, P12569, DOI 10.1007/s00500-020-04697-y
   Das A, 2019, LECT NOTES COMPUT SC, V11941, P13, DOI 10.1007/978-3-030-34869-4_2
   Ghamisi P, 2018, IEEE GEOSC REM SEN M, V6, P10, DOI 10.1109/MGRS.2018.2854840
   Ghamisi P, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2016.2616418
   Ghamisi P, 2015, IEEE T GEOSCI REMOTE, V53, P2335, DOI 10.1109/TGRS.2014.2358934
   Ghamisi P, 2014, IEEE T GEOSCI REMOTE, V52, P5771, DOI 10.1109/TGRS.2013.2292544
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Holzwarth S., 2003, P 3 EARSEL WORKSH IM, P3
   Hu W, 2015, J SENSORS, V2015, DOI 10.1155/2015/258619
   IEEE GRSS, 2013, IM AN DAT FUS
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lagrange A, 2015, INT GEOSCI REMOTE SE, P4173, DOI 10.1109/IGARSS.2015.7326745
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li ST, 2019, IEEE T GEOSCI REMOTE, V57, P6690, DOI 10.1109/TGRS.2019.2907932
   Li T, 2014, IEEE IMAGE PROC, P5132, DOI 10.1109/ICIP.2014.7026039
   Li W, 2017, IEEE T GEOSCI REMOTE, V55, P844, DOI 10.1109/TGRS.2016.2616355
   Li Y, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9010067
   Liang HM, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8020099
   Mahmood Z, 2012, INT GEOSCI REMOTE SE, P4946, DOI 10.1109/IGARSS.2012.6352502
   Makantasis K, 2015, INT GEOSCI REMOTE SE, P4959, DOI 10.1109/IGARSS.2015.7326945
   Haut JM, 2018, IEEE T GEOSCI REMOTE, V56, P6440, DOI 10.1109/TGRS.2018.2838665
   Marpu PR, 2013, IEEE GEOSCI REMOTE S, V10, P293, DOI 10.1109/LGRS.2012.2203784
   Paoletti ME, 2018, ISPRS J PHOTOGRAMM, V145, P120, DOI 10.1016/j.isprsjprs.2017.11.021
   Pedergnana M, 2013, IEEE T GEOSCI REMOTE, V51, P3514, DOI 10.1109/TGRS.2012.2224874
   Salembier P, 1998, IEEE T IMAGE PROCESS, V7, P555, DOI 10.1109/83.663500
   Singhal V, 2017, IEEE T GEOSCI REMOTE, V55, P5274, DOI 10.1109/TGRS.2017.2704590
   Xing C, 2016, J SENSORS, V2016, DOI 10.1155/2016/3632943
   Yang XF, 2018, IEEE T GEOSCI REMOTE, V56, P5408, DOI 10.1109/TGRS.2018.2815613
   Yue J, 2015, REMOTE SENS LETT, V6, P468, DOI 10.1080/2150704X.2015.1047045
   Zabalza J, 2016, NEUROCOMPUTING, V185, P1, DOI 10.1016/j.neucom.2015.11.044
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang QS, 2013, PROCEEDINGS OF 2013 IEEE INTERNATIONAL CONFERENCE ON GREY SYSTEMS AND INTELLIGENT SERVICES (GSIS), P16, DOI 10.1109/GSIS.2013.6714730
   Zhang XR, 2018, MULTIMED TOOLS APPL, V77, P29759, DOI 10.1007/s11042-017-5552-6
   Zhao WZ, 2016, IEEE T GEOSCI REMOTE, V54, P4544, DOI 10.1109/TGRS.2016.2543748
   Zhao WZ, 2015, INT J REMOTE SENS, V36, P3368, DOI 10.1080/2150704X.2015.1062157
   Zhong P, 2017, IEEE T GEOSCI REMOTE, V55, P3516, DOI 10.1109/TGRS.2017.2675902
   Zhu L, 2018, IEEE T GEOSCI REMOTE, V56, P5046, DOI 10.1109/TGRS.2018.2805286
NR 51
TC 3
Z9 3
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35365
EP 35385
DI 10.1007/s11042-020-10169-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA VM6PC
UT WOS:001028176800001
DA 2024-07-18
ER

PT J
AU Gao, P
   Wei, MQ
AF Gao, Pan
   Wei, Mingqiang
TI Block size selection in rate-constrained geometry based point cloud
   compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Block size selection; Rate constrained; Octree level; Point cloud
   compression
ID VIDEO; MPEG
AB In geometry-based point cloud compression, the geometry information is typically compressed using octree coding. In octree coding, the size of the blocks in the voxelized point clouds, i.e., the number of voxels contained in a block, determines whether the geometry coding is lossless or lossy, and the degree of geometry compression in lossy coding. Therefore, selecting an appropriate block size for octree coding is crucial for compression quality of voxelized point clouds. In this paper, we propose an optimal block size selection scheme for geometry based point cloud compression with a given bit rate constraint. Firstly, we analyze the gradients of the overall quality of the point clouds with color coding bit rate and geometry coding bit rate in lossy geometry coding. Then, we propose an octree level selection approach that can output the optimal octree level for point cloud compression under a target bit rate. In this approach, we consider the difference between the impacts of lossy geometry coding and lossless geometry coding on the overall quality of the point clouds. Experimental results demonstrate that, using the level selected by the proposed algorithm for geometry coding can yield best coding results in terms of the average quality of the images rendered from decoded point clouds.
C1 [Gao, Pan; Wei, Mingqiang] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing, Peoples R China.
   [Gao, Pan] Sci & Technol Electroopt Control Lab, Luoyang, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics
RP Gao, P (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing, Peoples R China.; Gao, P (corresponding author), Sci & Technol Electroopt Control Lab, Luoyang, Peoples R China.
EM gaopan.1005@gmail.com
FU Aeronautical Science Foundation of China [201951052001]; Natural Science
   Foundation of Jiangsu Province [BK20170806]; Natural Science Foundation
   of China [61701227]
FX The authors would like to thank Professor Aljosa Smolic from Trinity
   College Dublin, Ireland, for the insightful advice and fruitful
   discussion on the design of the proposed algorithm in this paper. This
   work is supported in part by Aeronautical Science Foundation of China
   under Grant 201951052001, the Natural Science Foundation of Jiangsu
   Province under Grant BK20170806, and the Natural Science Foundation of
   China under Grant 61701227.
CR Alexiou E, 2018, IEEE INT CON MULTI
   [Anonymous], 2015, BT709
   Cao C., 2019, 24 INT C 3D WEB TECH, P1
   Chou PA, 2017, POINT CLOUD COMPRESS
   Chou PA, 2020, IEEE T IMAGE PROCESS, V29, P2203, DOI 10.1109/TIP.2019.2908095
   de Queiroz RL, 2017, IEEE T IMAGE PROCESS, V26, P3886, DOI 10.1109/TIP.2017.2707807
   de Queiroz RL, 2016, IEEE T IMAGE PROCESS, V25, P3947, DOI 10.1109/TIP.2016.2575005
   dEon E., 2017, Standard ISO/IEC JTC1/SC29 Joint WG11/WG1 (MPEG/JPEG)input document WG11M40059/WG1M74006
   Fiengo A, 2017, IEEE T IMAGE PROCESS, V26, P479, DOI 10.1109/TIP.2016.2621666
   Filali A, 2019, IEEE IMAGE PROC, P1099, DOI [10.1109/icip.2019.8803403, 10.1109/ICIP.2019.8803403]
   Gao P., 2020, P 12 INT C QUAL MULT, P1
   Gao P, 2019, IEEE T IMAGE PROCESS, V28, P5266, DOI 10.1109/TIP.2019.2919198
   Guo JJ, 2017, ACM T APPL PERCEPT, V14, DOI 10.1145/2996296
   Hosseini M, 2018, PROCEEDINGS OF THE 23TH ACM WORKSHOP ON PACKET VIDEO (PV'18), P25, DOI 10.1145/3210424.3210429
   Huang Y, 2008, IEEE T VIS COMPUT GR, V14, P440, DOI 10.1109/TVCG.2007.70441
   Jang ES, 2019, IEEE SIGNAL PROC MAG, V36, P118, DOI 10.1109/MSP.2019.2900721
   Kammerl J, 2012, IEEE INT CONF ROBOT, P778, DOI 10.1109/ICRA.2012.6224647
   Krivokuca M, 2020, IEEE T IMAGE PROCESS, V29, P2217, DOI 10.1109/TIP.2019.2957853
   Li L, 2020, IEEE T IMAGE PROCESS, V29, P289, DOI 10.1109/TIP.2019.2931621
   Liu QL, 2020, IEEE INT CONF COMMUN, P1, DOI [10.1109/iccc49849.2020.9238836, 10.1109/ICCC49849.2020.9238836, 10.1109/IPDPSW50202.2020.00177]
   Loop C, 2006, MICROSOFT VOXELIZED
   Ma SW, 2005, IEEE T CIRC SYST VID, V15, P1533, DOI 10.1109/TCSVT.2005.857300
   Mammou K, 2019, G PCC CODEC DESCRIPT
   Mammou K, 2017, PCC TEST MODEL CATEG
   Mekuria R, 2017, IEEE T CIRC SYST VID, V27, P828, DOI 10.1109/TCSVT.2016.2543039
   Meynet G, 2020, INT WORK QUAL MULTIM, DOI 10.1109/qomex48832.2020.9123147
   MPEG, 2019, GEOM BAS POINT CLOUD
   MPEG 3DG and Requirements, 2017, N16763 MPEG 3DG REQ
   Orts-Escolano S, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P741, DOI 10.1145/2984511.2984517
   Pagés R, 2018, J VIS COMMUN IMAGE R, V53, P192, DOI 10.1016/j.jvcir.2018.03.012
   Perry S., 2020, JPEG Pleno Point Cloud Coding Common Test Conditions v3. ISO/IEC JTC1/SC29/WG1 N 86044
   Qian F, 2019, HOTMOBILE '19 - PROCEEDINGS OF THE 20TH INTERNATIONAL WORKSHOP ON MOBILE COMPUTING SYSTEMS AND APPLICATIONS, P135, DOI 10.1145/3301293.3302358
   Quach M, 2019, IEEE IMAGE PROC, P4320, DOI [10.1109/ICIP.2019.8803413, 10.1109/icip.2019.8803413]
   Rente PD, 2019, IEEE T MULTIMEDIA, V21, P284, DOI 10.1109/TMM.2018.2859591
   Schnabel R., 2006, P S POINT BAS GRAPH, V6, P111, DOI DOI 10.2312/SPBG/SPBG06/111-120
   Schneider P.J., 2002, GEOMETRIC TOOLS COMP
   Schwarz S, 2019, IEEE J EM SEL TOP C, V9, P133, DOI 10.1109/JETCAS.2018.2885981
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Song H, 2008, COMPUT AIDED DESIGN, V40, P281, DOI 10.1016/j.cad.2007.10.013
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Subramanyam S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P127, DOI [10.1109/VR46266.2020.1581260728335, 10.1109/VR46266.2020.00-73]
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sun XB, 2019, IEEE ROBOT AUTOM LET, V4, P2132, DOI 10.1109/LRA.2019.2900747
   Thanou D, 2016, IEEE T IMAGE PROCESS, V25, P1765, DOI 10.1109/TIP.2016.2529506
   Tian D, 2017, EVALUATION METRICS P
   Torlig EM, 2018, PROC SPIE, V10752, DOI 10.1117/12.2322741
   van der Hooft J, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2405, DOI 10.1145/3343031.3350917
   Zerman E., 2019, IS &T Electronic Imaging, Image Quality and System Performance XVI
   Zhang C, 2014, IEEE IMAGE PROC, P2066, DOI 10.1109/ICIP.2014.7025414
NR 49
TC 0
Z9 0
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2557
EP 2575
DI 10.1007/s11042-021-11672-8
EA OCT 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000713070300001
DA 2024-07-18
ER

PT J
AU Jemimma, TA
   Raj, YJV
AF Jemimma, T. A.
   Raj, Y. Jacob Vetha
TI Significant LOOP with clustering approach and optimization enabled deep
   learning classifier for the brain tumor segmentation and classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Magnetic resonance images; Significant local binary pattern; Fractional
   probabilistic fuzzy clustering; Deep convolutional neural network; Cat
   swarm optimization
AB Magnetic resonance images (MRI) is the imperative imaging modality utilized in medical diagnosis tool for detecting brain tumors. The MRI possess the capability to offer detailed information based on anatomical structures of brain. However, the major obstacle in the MRI classification is semantic gap among low-level visual information obtained by the high-level information alleged from clinician and MRI machine. This paper proposes the novel technique, named Chaotic whale cat swarm optimization-enabled Deep Convolutional Neural Network (CWCSO-enabled Deep CNN) for brain tumor classification. Here, pre-processing is employed for removing noise and artifacts contained in image. Moreover, Fractional Probabilistic Fuzzy Clustering is employed for segmentation for identifying the tumor regions. Consequently, the feature extraction is carried out from segmented regions of image using wavelet transform, Empirical Mode Decomposition (EMD), scattering transform, Local Directional Pattern (LDP) and information theoretic measures. In addition, Significant LOOP is newly developed through modifying Significant Local Binary Pattern (SLBP) by LOOP. The extracted features are induced by Deep CNN to determine non-tumor, edema, tumor, and enhanced tumor, which is trained by the proposed CWCSO. Thus, the resulted output of proposed CWCSO-based Deep CNN is employed for brain tumor classification. The proposed model showed improved results with maximal specificity of 98.59%, maximal accuracy of 95.52%, and maximal sensitivity of 97.37%, respectively.
C1 [Jemimma, T. A.; Raj, Y. Jacob Vetha] Manonmaniam Sundaranar Univ, Nesamony Mem Christian Coll, Dept Comp Sci, Tirunelveli 627012, Tamil Nadu, India.
C3 Manonmaniam Sundaranar University
RP Jemimma, TA (corresponding author), Manonmaniam Sundaranar Univ, Nesamony Mem Christian Coll, Dept Comp Sci, Tirunelveli 627012, Tamil Nadu, India.
EM jemisudhar@gmail.com; jacobvetharaj@gmail.com
OI Jemimma, T.A/0000-0001-5715-1393
CR Abd-Ellah MK, 2016, INT C MICROELECTRON, P73, DOI 10.1109/ICM.2016.7847911
   Ahmadvand A, 2018, MULTIMED TOOLS APPL, V77, P8001, DOI 10.1007/s11042-017-4696-8
   Amin J, 2020, PATTERN RECOGN LETT, V139, P118, DOI 10.1016/j.patrec.2017.10.036
   Anbeek Petronella., 2008, MIDAS Journal
   ANGULAKSHMI M, 2018, J KING SAUD U COMPUT
   Anitha V, 2016, IET COMPUT VIS, V10, P9, DOI 10.1049/iet-cvi.2014.0193
   [Anonymous], 2012, INT J COMPUT SCI INF
   [Anonymous], 2012, International Journal of Scientific & Engineering Research
   [Anonymous], 2015, INT J ADV SCI ENG TE
   Badran EF, 2010, ICCES'2010: THE 2010 INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING & SYSTEMS, P368, DOI 10.1109/ICCES.2010.5674887
   Bahadure NB, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9749108
   Bahrami M, 2018, STUD COMPUT INTELL, V720, P9, DOI [10.1007/978-981-10-5221-7_2, 10.1007/978-3-319-72929-9_2]
   Bauer S, 2013, PHYS MED BIOL, V58, pR97, DOI 10.1088/0031-9155/58/13/R97
   Bhaladhare PR., 2014, Adv Comput Eng, V2014, P1, DOI [DOI 10.1155/2014/396529, 10.1155/2014/396529]
   Cabria I, 2017, INFORM FUSION, V36, P1, DOI 10.1016/j.inffus.2016.10.003
   Chakraborti T, 2018, IEEE SIGNAL PROC LET, V25, P635, DOI 10.1109/LSP.2018.2817176
   Chakraborty T, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3091106
   Charutha S, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTROL, INSTRUMENTATION, COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICCICCT), P1193, DOI 10.1109/ICCICCT.2014.6993142
   Chen H, 2020, NEUROCOMPUTING, V392, P305, DOI 10.1016/j.neucom.2019.01.111
   Corso JJ, 2008, IEEE T MED IMAGING, V27, P629, DOI 10.1109/TMI.2007.912817
   Dian RW, 2018, IEEE T NEUR NET LEAR, V29, P5345, DOI 10.1109/TNNLS.2018.2798162
   Huang SQ, 2016, Adv Inform Managemen, P615, DOI 10.1109/IMCEC.2016.7867283
   Ilunga-Mbuyamba E, 2017, COMPUT BIOL MED, V91, P69, DOI 10.1016/j.compbiomed.2017.10.003
   Ismael MR, 2018, INT CONF ELECTRO INF, P252, DOI 10.1109/EIT.2018.8500308
   Jan Vojt B., 2016, Deep neural networks and their implementation
   Kamal M., 2010, Inflation Targeting in Brazil, Chile, and South Africa: An empirical Investigation of their monetary policy framework, P1
   Lavanyadevi R, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON ELECTRICAL, INSTRUMENTATION AND COMMUNICATION ENGINEERING (ICEICE)
   Ludwig O, 2014, NEUROCOMPUTING, V124, P33, DOI 10.1016/j.neucom.2013.08.005
   Mallick PK, 2019, IEEE ACCESS, V7, P46278, DOI 10.1109/ACCESS.2019.2902252
   Mathew AR, 2017, PROCEEDINGS OF 2017 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION (ICSPC'17), P75, DOI 10.1109/CSPC.2017.8305810
   Meenakshi R, 2015, CURR MED IMAGING REV, V11, P70, DOI 10.2174/157340561102150624143233
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Naik J, 2014, INT J COMPUT SCI NET, V14, P87
   Nefti S, 2004, IEEE SYS MAN CYBERN, P4786
   Parveen, 2015, 2ND INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN) 2015, P98, DOI 10.1109/SPIN.2015.7095308
   Raju AR, 2018, BIOCYBERN BIOMED ENG, V38, P646, DOI 10.1016/j.bbe.2018.05.001
   Rashid M.H.O., 2018, INTRO CHAPTER ADSORP, DOI [10.1109/IC4ME2.2018.8465613, DOI 10.5772/INTECHOPEN.77190]
   Sajid S, 2019, ARAB J SCI ENG, V44, P9249, DOI 10.1007/s13369-019-03967-8
   Sharmila R., 2018, INT J SCI RES COMPUT, V3, P2456
   Thillaikkarasi R, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1223-7
   Usman K, 2017, PATTERN ANAL APPL, V20, P871, DOI 10.1007/s10044-017-0597-8
   Zulpe N., 2012, Int. J. Comput. Sci. Issues (IJCSI), V9, P354
NR 42
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2365
EP 2391
DI 10.1007/s11042-021-11591-8
EA OCT 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000710918100001
DA 2024-07-18
ER

PT J
AU Mohan, N
   Kumar, M
AF Mohan, Narendra
   Kumar, Manoj
TI Room layout estimation in indoor environment: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Indoor environment; Layout estimation; Object detection; Semantic
   segmentation; Scene understanding
ID 3D OBJECT DETECTION; SCENES
AB Scene understanding from the single image of an indoor scene is identified as a challenging task. This involves interpreting the assessment of multiple scene components, such as to identify the spatial layout from room, detect the objects in 3D space and classify the scene, to understand the nature of an indoor scene. Assessing the spatial structure of indoor scenes offers important geometric details and limits for various activities, such as indoor 3D-reconstruction, navigation, scene awareness and virtual reality. Most of the layout estimation function lacks the clutter and decorations present in the background, instead concentrating mainly on the horizontal wall contours. Room layout states the orientations, heights, and positions of walls with respective to its camera center. Then, a set of estimated boundaries or corner positions, or as a 3D mesh is characterized from layout. Nevertheless, identifying the 3D model from a single 2D picture is an ill-posed and challenging problem. Large number of techniques applies "Manhattan assumption" for layout estimation. The layout estimation approach is combined with few computer vision based techniques like semantic segmentation, object orientation estimation, scene classification, and 3D object detection to achieve indoor scene understanding. Additionally, the object detection and semantic segmentation is also reviewed along with this layout estimation approach. This survey provides valuable information to all researchers and those who are looking for better techniques in layout estimation.
C1 [Mohan, Narendra; Kumar, Manoj] GLA Univ, Mathura 284106, Uttar Pradesh, India.
C3 GLA University
RP Mohan, N (corresponding author), GLA Univ, Mathura 284106, Uttar Pradesh, India.
EM narendra.mohan@gla.ac.in
RI Kumar, Manoj/AFS-0700-2022
OI Kumar, Manoj/0000-0001-9598-0280
CR Abdallah AA, 2019, INT C INDOOR POSIT
   [Anonymous], 2016, Asian Conference on Computer Vision
   [Anonymous], 2016, ARXIV160601178
   Bao SY, 2014, IEEE WINT CONF APPL, P690, DOI 10.1109/WACV.2014.6836035
   Bao SY, 2013, PROC CVPR IEEE, P1264, DOI 10.1109/CVPR.2013.167
   Brucker M, 2018, IEEE INT CONF ROBOT, P1871
   Cavanagh P, 2011, VISION RES, V51, P1538, DOI 10.1016/j.visres.2011.01.015
   Chang J, 2019, IEEE I CONF COMP VIS, P10192, DOI 10.1109/ICCV.2019.01029
   Chao YW, 2013, LECT NOTES COMPUT SC, V8157, P489, DOI 10.1007/978-3-642-41184-7_50
   Choi WG, 2013, PROC CVPR IEEE, P33, DOI 10.1109/CVPR.2013.12
   Couprie C., 2013, ARXIV13013572, P1
   Couprie C., 2014, The Journal of Machine Learning Research
   Dai A, 2018, LECT NOTES COMPUT SC, V11214, P458, DOI 10.1007/978-3-030-01249-6_28
   Dai A, 2018, PROC CVPR IEEE, P4578, DOI 10.1109/CVPR.2018.00481
   Dasgupta S, 2016, PROC CVPR IEEE, P616, DOI 10.1109/CVPR.2016.73
   Dong HY, 2018, 2018 WRC SYMPOSIUM ON ADVANCED ROBOTICS AND AUTOMATION (WRC SARA), P178, DOI 10.1109/WRC-SARA.2018.8584204
   Engelmann F, 2017, IEEE INT CONF COMP V, P716, DOI 10.1109/ICCVW.2017.90
   Espinace P, 2013, ROBOT AUTON SYST, V61, P932, DOI 10.1016/j.robot.2013.05.002
   Fernandez-Labrador C, 2020, IEEE ROBOT AUTOM LET, V5, P1255, DOI 10.1109/LRA.2020.2967274
   Fouhey DF, 2014, LECT NOTES COMPUT SC, V8694, P687, DOI 10.1007/978-3-319-10599-4_44
   Furlan A, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.24
   Garcia A, 2017, APPR DIGIT GAME STUD, V5, P1
   Guo R., 2015, ARXIV150402437
   Guo RQ, 2013, IEEE I CONF COMP VIS, P2144, DOI 10.1109/ICCV.2013.266
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Hayat M, 2016, IEEE T IMAGE PROCESS, V25, P4829, DOI 10.1109/TIP.2016.2599292
   Hazirbas C, 2017, LECT NOTES COMPUT SC, V10111, P213, DOI 10.1007/978-3-319-54181-5_14
   Hermans A, 2014, IEEE INT CONF ROBOT, P2631, DOI 10.1109/ICRA.2014.6907236
   Hirzer M, 2020, IEEE WINT CONF APPL, P2901, DOI [10.1109/WACV45572.2020.9093451, 10.1109/wacv45572.2020.9093451]
   Hsiao Chi-Wei, 2019, ARXIV190512571
   Huang S., 2018, ARXIV181013049
   Ikehata S, 2015, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2015.156
   Kar A, 2015, IEEE I CONF COMP VIS, P127, DOI 10.1109/ICCV.2015.23
   Kim HS, 2016, INT CONF 3D VISION, P519, DOI 10.1109/3DV.2016.83
   Lee CY, 2017, IEEE I CONF COMP VIS, P4875, DOI 10.1109/ICCV.2017.521
   Lee JK, 2017, IEEE I CONF COMP VIS, P162, DOI 10.1109/ICCV.2017.27
   Li J., 2020, ELECT IMAGING, V2020, P391, DOI DOI 10.2352/ISSN.2470-1173.2020.14.COIMG-391
   Lin DH, 2013, IEEE I CONF COMP VIS, P1417, DOI 10.1109/ICCV.2013.179
   Lin HJ, 2018, INT C PATT RECOG, P842, DOI 10.1109/ICPR.2018.8546278
   Liu CX, 2015, PROC CVPR IEEE, P3413, DOI 10.1109/CVPR.2015.7298963
   López-Nicolás G, 2014, ROBOT AUTON SYST, V62, P1271, DOI 10.1016/j.robot.2014.03.018
   Lu HM, 2021, IEEE T KNOWL DATA EN, V33, P2669, DOI 10.1109/TKDE.2019.2953728
   Lukierski Robert, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P6315, DOI 10.1109/ICRA.2017.7989747
   Mallya A, 2015, IEEE I CONF COMP VIS, P936, DOI 10.1109/ICCV.2015.113
   Martin-Brualla R, 2014, LECT NOTES COMPUT SC, V8691, P1, DOI [10.7749/citiescommunitiesterritories.dec2014.029.art01, 10.1007/978-3-319-10578-9_1]
   Mattausch O, 2014, COMPUT GRAPH FORUM, V33, P11, DOI 10.1111/cgf.12286
   Mitash C, 2018, IEEE INT CONF ROBOT, P3331
   Müller AC, 2014, IEEE INT CONF ROBOT, P6232, DOI 10.1109/ICRA.2014.6907778
   Naseer M, 2019, IEEE ACCESS, V7, P1859, DOI 10.1109/ACCESS.2018.2886133
   Pradeep, 2018, PROCEDIA COMPUT SCI, V125, P124, DOI 10.1016/j.procs.2017.12.018
   Pham QH, 2019, IEEE WINT CONF APPL, P1089, DOI 10.1109/WACV.2019.00121
   Ren YZ, 2018, J VIS COMMUN IMAGE R, V55, P131, DOI 10.1016/j.jvcir.2018.05.019
   REN Z, 2016, PROC CVPR IEEE, P1525, DOI DOI 10.1109/CVPR.2016.169
   Ren ZL, 2020, IEEE T PATTERN ANAL, V42, P2670, DOI 10.1109/TPAMI.2019.2923201
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Silberman N, 2014, LECT NOTES COMPUT SC, V8689, P616, DOI 10.1007/978-3-319-10590-1_40
   Song SR, 2017, PROC CVPR IEEE, P190, DOI 10.1109/CVPR.2017.28
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Song SR, 2014, LECT NOTES COMPUT SC, V8694, P634, DOI 10.1007/978-3-319-10599-4_41
   Tsitsipa V, 2018, USING BIG DATA DESIG
   Wang JH, 2016, LECT NOTES COMPUT SC, V9909, P664, DOI 10.1007/978-3-319-46454-1_40
   Wang L, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19194092
   Wang L, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19040893
   Wang RZ, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11101143
   Wang YD, 2018, INT CONF 3D VISION, P426, DOI 10.1109/3DV.2018.00056
   Xiao JX, 2012, LECT NOTES COMPUT SC, V7572, P668, DOI [10.1007/s11263-014-0711-y, 10.1007/978-3-642-33718-5_48]
   Xie Q., 2019, MLCVNET MULTILEVEL C, V62, P444
   Xiong HJ, 2019, INT J DIGIT EARTH, V12, P525, DOI 10.1080/17538947.2018.1456569
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P3014, DOI 10.1109/TMM.2020.2967645
   Zhang J, 2013, IEEE I CONF COMP VIS, P1273, DOI 10.1109/ICCV.2013.161
   Zhang WD, 2020, IEEE T CYBERNETICS, V50, P2730, DOI 10.1109/TCYB.2019.2895837
   Zhang WD, 2017, IEEE T MULTIMEDIA, V19, P935, DOI 10.1109/TMM.2016.2642780
   Zhang XS, 2017, IEEE T NEUR NET LEAR, V28, P177, DOI 10.1109/TNNLS.2015.2496195
   Zhang Y, 2017, IEEE C COMP VIS PATT, P5287, DOI DOI 10.1109/CVPR.2017.537
   Zhao F, 2013, P 12 ACM SIGGRAPH IN, P157
   Zhao YB, 2013, PROC CVPR IEEE, P3119, DOI 10.1109/CVPR.2013.401
   Zhou ZH, 2017, IEEE T MULTIMEDIA, V19, P2651, DOI 10.1109/TMM.2017.2703954
NR 77
TC 3
Z9 3
U1 7
U2 62
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 1921
EP 1951
DI 10.1007/s11042-021-11358-1
EA OCT 2021
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000707534700001
DA 2024-07-18
ER

PT J
AU Zhou, JC
   Yao, J
   Zhang, WS
   Zhang, DH
AF Zhou, Jingchun
   Yao, Jian
   Zhang, Weishi
   Zhang, Dehuan
TI Multi-scale retinex-based adaptive gray-scale transformation method for
   underwater image enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater image enhancement; Multi-scale retinex; Heterogeneous
   diffusion filtering; Simulated annealing; Underwater image; Color
   correction
ID MODEL
AB Underwater images play an irreplaceable role as one of the carriers of underwater information acquisition. Underwater degraded images are usually affected by the color cast, noise, and blurred details, which are difficult to apply to various vision tasks. We propose a multi-scale retinex adaptive grayscale transformation underwater image enhancement method, which includes three parts: color correction, image denoising, and detail enhancement. Firstly, the multi-scale Retinex algorithm is adopted to extract the lighting components. Mean and mean square errors were introduced through linear quantization, and color recovery factors were adopted to adjust the three channels for color correction. Second, by treating the image as an anisotropic thermal field diffusing in all direction,image noise is eliminated and edge details are preserved. Finally, for different underwater degraded images, a simulated annealing optimization algorithm is introduced to perform adaptive gray-scale transformation on the image to enhance image details. The results show that the proposed method can comprehensively solve the problems of color distortion, noise, and low contrast. Compared with the state-of-the-art underwater image enhancement and restoration methods, our method has achieved better visual effects.
C1 [Zhou, Jingchun; Yao, Jian; Zhang, Weishi; Zhang, Dehuan] Dalian Maritime Univ, Dalian, Peoples R China.
C3 Dalian Maritime University
RP Zhou, JC; Zhang, WS (corresponding author), Dalian Maritime Univ, Dalian, Peoples R China.
EM zhoujingchun@dlmu.edu.cn; yaojian@dlmu.edu.cn; teesiv1962@dlmu.edu.cn;
   zhangdehuan@dlmu.edu.cn
RI Zhou, Jingchun/AAF-6817-2019
OI Zhou, Jingchun/0000-0002-4111-6240
FU National Natural Science Foundation of China [61702074]; Liaoning
   Provincial Natural Science Foundation of China [20170520196];
   Fundamental Research Funds for the Central Universities [3132019205,
   3132019354]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61702074), the Liaoning Provincial Natural Science Foundation
   of China (No. 20170520196), and the Fundamental Research Funds for the
   Central Universities (Nos.3132019205 and 3132019354).
CR Ancuti C., 2012, PROC CVPR IEEE, P81, DOI DOI 10.1109/CVPR.2012.6247661
   Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Anwar S, 2020, SIGNAL PROCESS-IMAGE, V89, DOI 10.1016/j.image.2020.115978
   Artyukov IA, 2019, J RUSS LASER RES, V40, P150, DOI 10.1007/s10946-019-09782-8
   Barnard, 1999, PRACTICAL COLOR CONS
   BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7
   Chen Y, 2010 INT C DISPL PHO, V7749
   [丛润民 Cong Runmin], 2020, [信号处理, Journal of Signal Processing], V36, P1377
   Deng LZ, 2019, OPT LASER TECHNOL, V110, P184, DOI 10.1016/j.optlastec.2018.08.043
   Drews P, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P825, DOI 10.1109/ICCVW.2013.113
   Drews PLJ, 2016, IEEE COMPUT GRAPH, V36, P24, DOI 10.1109/MCG.2016.26
   Fabbri C, 2018, IEEE INT CONF ROBOT, P7159
   Fu XY, 2017, I S INTELL SIG PROC, P789, DOI 10.1109/ISPACS.2017.8266583
   Fu XY, 2014, IEEE IMAGE PROC, P4572, DOI 10.1109/ICIP.2014.7025927
   Guo FC, 2020, IEEE T GEOSCI REMOTE, V58, P2398, DOI 10.1109/TGRS.2019.2948890
   Guo PF, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105608
   Guo YC, 2020, IEEE J OCEANIC ENG, V45, P862, DOI 10.1109/JOE.2019.2911447
   Han M, 2020, IEEE T SYST MAN CY-S, V50, P1820, DOI 10.1109/TSMC.2017.2788902
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   HUMMEL R, 1977, COMPUT VISION GRAPH, V6, P184, DOI 10.1016/S0146-664X(77)80011-7
   Hussain DM, 2020, MULTIMED TOOLS APPL, V79, P3683, DOI 10.1007/s11042-018-6708-8
   Iqbal Kashif, 2007, IAENG International Journal of Computer Science, V34, P239
   Iqbal K, 2010, IEEE INT C SYSTEMS M
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   Kim TK., 1988, IEEE T CONSUM ELECTR, V44, p1 82 87
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Lee HS, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12081220
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li CY, 2018, IEEE SIGNAL PROC LET, V25, P323, DOI 10.1109/LSP.2018.2792050
   Li CY, 2017, PATTERN RECOGN LETT, V94, P62, DOI 10.1016/j.patrec.2017.05.023
   Li J, 2018, IEEE ROBOT AUTOM LET, V3, P387, DOI 10.1109/LRA.2017.2730363
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu HM, 2017, MOBILE NETW APPL, V22, P1204, DOI 10.1007/s11036-017-0863-4
   Panetta K, 2016, IEEE J OCEANIC ENG, V41, P541, DOI 10.1109/JOE.2015.2469915
   Parthasarathy S., 2012, NATL C COMMUNICATION, P1, DOI DOI 10.1109/NCC.2012.6176791
   Peng YT, 2017, IEEE T IMAGE PROCESS, V26, P1579, DOI 10.1109/TIP.2017.2663846
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Rahman Z, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P1003, DOI 10.1109/ICIP.1996.560995
   Ren WQ, 2020, INT J COMPUT VISION, V128, P240, DOI 10.1007/s11263-019-01235-8
   Ren WQ, 2019, IEEE T IMAGE PROCESS, V28, P4364, DOI 10.1109/TIP.2019.2910412
   Ren WQ, 2019, IEEE T IMAGE PROCESS, V28, P1895, DOI 10.1109/TIP.2018.2876178
   Roser M, 2014, IEEE INT CONF ROBOT, P3840, DOI 10.1109/ICRA.2014.6907416
   Sankpal SS., 2016, ADV COMPUTATIONAL SC, V9, P11
   Schechner YY, 2005, IEEE J OCEANIC ENG, V30, P570, DOI 10.1109/JOE.2005.850871
   Song W, 2018, LECT NOTES COMPUT SC, V11164, P678, DOI 10.1007/978-3-030-00776-8_62
   Tan CS, 2005, OPT LASER ENG, V43, P995, DOI 10.1016/j.optlaseng.2004.10.005
   Tang C, 2019, SIGNAL IMAGE VIDEO P, V13, P1011, DOI 10.1007/s11760-019-01439-y
   Tang JR, 2017, APPL SOFT COMPUT, V55, P31, DOI 10.1016/j.asoc.2017.01.053
   Wang JB, 2018, IEEE T CIRC SYST VID, V28, P2190, DOI 10.1109/TCSVT.2017.2728822
   Wang Y, 2019, IEEE ACCESS, V7, P140233, DOI 10.1109/ACCESS.2019.2932130
   Weickert J., 1996, COMPUTING WIEN SUPPL, V11, P221, DOI [DOI 10.1007/978-3-7091-6586-713, 10.1007/978-3-7091-6586-7_13, DOI 10.1007/978-3-7091-6586-7_13]
   Wen HC, 2013, IEEE INT SYMP CIRC S, P753, DOI 10.1109/ISCAS.2013.6571956
   Weng CC, 2005, IEEE INT SYMP CIRC S, P3801
   Xia H., 2019, J PHYS C SER, V1213, DOI [DOI 10.1088/1742-6596/1213/5/052072, 10.1088/1742-6596/1213/5/052072]
   Yang M, 2020, IEEE J OCEANIC ENG, V45, P521, DOI 10.1109/JOE.2018.2886093
   Yang M, 2019, IEEE ACCESS, V7, P123638, DOI 10.1109/ACCESS.2019.2932611
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
   [张凯 Zhang Kai], 2011, [红外技术, Infrared Technology], V33, P630
   Zhang S, 2017, NEUROCOMPUTING, V245, P1, DOI 10.1016/j.neucom.2017.03.029
   Zhishen L., 2003, J OCEAN U QINGDAO, V2, P85, DOI DOI 10.1007/S11802-003-0033-0
   Zhou JC, 2020, FRONT INFORM TECH EL, V21, P1745, DOI 10.1631/FITEE.2000190
   Zhou JC, 2019, IEEE ACCESS, V7, P122459, DOI 10.1109/ACCESS.2019.2934981
   Zhou Y, 2019, IEEE T CIRC SYST VID, V29, P907, DOI 10.1109/TCSVT.2018.2884615
   Zhuang PX, 2020, MULTIMED TOOLS APPL, V79, P17257, DOI 10.1007/s11042-019-08404-4
NR 67
TC 27
Z9 28
U1 13
U2 92
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 1811
EP 1831
DI 10.1007/s11042-021-11327-8
EA OCT 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000706943000003
DA 2024-07-18
ER

PT J
AU Gu, XQ
   Shen, ZX
   Qu, J
   Ni, TG
AF Gu, Xiaoqing
   Shen, Zongxuan
   Qu, Jia
   Ni, Tongguang
TI Cross-domain EEG signal classification via geometric preserving transfer
   discriminative dictionary learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE EEG signal; Sparse representation; Dictionary learning; Transfer
   learning
ID SEIZURE DETECTION; FEATURES
AB EEG signal classification is a key technology for EEG signal processing and identification systems. Dictionary learning has shown excellent performance due to its sparse representation and learning capability. Usually dictionary learning requires sufficient labeled EEG signals to build classification models, and assumes that the data distribution of training and test signals are the same. However, in new EEG signal domain, often only a small amount of signals are labeled, and more are not labeled. At the same time, data dynamicity, confounding factors and strong interclass similarity also seriously disrupt the performance of EEG signal classifier. To this end, a geometric preserving transfer discriminative dictionary learning method called GPTDDL is developed for cross-domain EEG signal classification. Through projected signals of different domains to the common subspace, a shared discriminative dictionary is obtained, which explores the geometric structure information by graph Laplacian regularization and discriminative information by principal component analysis regularization. Benefiting from the discriminative information transferred from source domain, the discriminability of the learned sparse coding of target domain is strengthened. GPTDDL integrates this idea into the framework of LC-KSVD, and learns the subspace and dictionary learning parameters in an iterative strategy. The experimental results on Bonn EEG signal dataset demonstrate the validity of the GPTDDL method.
C1 [Gu, Xiaoqing; Shen, Zongxuan; Qu, Jia; Ni, Tongguang] Changzhou Univ, Sch Comp Sci & Artificial Intelligence, Changzhou 213164, Peoples R China.
C3 Changzhou University
RP Ni, TG (corresponding author), Changzhou Univ, Sch Comp Sci & Artificial Intelligence, Changzhou 213164, Peoples R China.
EM czxqgu@163.com; 19081203309@smail.cczu.edu.cn; hbxtntg-12@163.com
RI Ni, Tongguang/GPP-6949-2022; Gu, Xiaoqing/GPP-6913-2022
OI Ni, Tongguang/0000-0002-0354-5116
FU Changzhou Scientific and Technological Support Social Development
   Project [CE20215032]; Natural Science Foundation of Jiangsu Province [BK
   20211333]; National Natural Science Foundation of China [61806026]
FX This work was supported in part by the Changzhou Scientific and
   Technological Support Social Development Project CE20215032, Natural
   Science Foundation of Jiangsu Province under Grant BK 20211333, and
   National Natural Science Foundation of China under Grant 61806026.
CR Abdulkader SN, 2015, EGYPT INFORM J, V16, P213, DOI 10.1016/j.eij.2015.06.002
   Al-Shedivat M, 2014, AAAI CONF ARTIF INTE, P1665
   Chen JX, 2020, MULTIMED TOOLS APPL, V79, P10655, DOI 10.1007/s11042-019-7258-4
   Dai YX, 2018, MULTIMED TOOLS APPL, V77, P21967, DOI 10.1007/s11042-018-5618-0
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Gao Q, 2020, MULTIMED TOOLS APPL, V79, P27057, DOI 10.1007/s11042-020-09354-y
   Gao ZK, 2020, IEEE T IND INFORM, V16, P7159, DOI 10.1109/TII.2019.2955447
   Gu XQ, 2021, IEEE ACM T COMPUT BI, V18, P1679, DOI 10.1109/TCBB.2020.3006699
   Gu XQ, 2020, INT J MACH LEARN CYB, V11, P33, DOI 10.1007/s13042-019-00936-3
   Jiang YZ, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3340240
   Jiang YZ, 2017, IEEE T NEUR SYS REH, V25, P2270, DOI 10.1109/TNSRE.2017.2748388
   Jiang YZ, 2017, IEEE T FUZZY SYST, V25, P3, DOI 10.1109/TFUZZ.2016.2637405
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200
   Kashefpoor M, 2019, BIOMED SIGNAL PROCES, V53, DOI 10.1016/j.bspc.2019.101559
   Kaur B, 2020, MULTIMED TOOLS APPL, V79, P10805, DOI 10.1007/s11042-020-08667-2
   Khatun S, 2019, IEEE T NEUR SYS REH, V27, P1063, DOI 10.1109/TNSRE.2019.2911970
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Ni TG, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02620-9
   Ni TG, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00837
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Dao PT, 2018, PROC INT CONF ADV, P179, DOI 10.1109/ATC.2018.8587475
   Qiu Q, 2012, LECT NOTES COMPUT SC, V7575, P631, DOI 10.1007/978-3-642-33765-9_45
   Quanz Brian., 2009, P 18 ACM C INF KNOWL, P1327
   Ramakrishnan S, 2019, PATTERN ANAL APPL, V22, P1161, DOI 10.1007/s10044-018-0691-6
   Shekhar S, 2013, PROC CVPR IEEE, P361, DOI 10.1109/CVPR.2013.53
   Shin Y, 2015, BIOMED SIGNAL PROCES, V21, P8, DOI 10.1016/j.bspc.2015.05.007
   Song JQ, 2019, PATTERN RECOGN, V91, P135, DOI 10.1016/j.patcog.2019.02.018
   Sreeja SR, 2020, MULTIMED TOOLS APPL, V79, P13775, DOI 10.1007/s11042-019-08602-0
   Sreeja SR, 2019, NEUROCOMPUTING, V368, P133, DOI 10.1016/j.neucom.2019.08.037
   Tzallas AT, 2009, IEEE T INF TECHNOL B, V13, P703, DOI 10.1109/TITB.2009.2017939
   Uddin M, 2017, I C NETWORK PROTOCOL, DOI 10.1109/TPAMI.2017.2656884
   Vidyaratne LS, 2017, IEEE T NEUR SYS REH, V25, P2146, DOI 10.1109/TNSRE.2017.2697920
   Xia KJ, 2021, IEEE ACM T COMPUT BI, V18, P53, DOI 10.1109/TCBB.2020.2973978
   Xue J, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.586149
   Yadava M, 2017, MULTIMED TOOLS APPL, V76, P19087, DOI 10.1007/s11042-017-4580-6
   Zhang Q.Z.Q., 2010, PROC CVPR IEEE, DOI [10.1109/CVPR.2010.5539989, DOI 10.1109/CVPR.2010.5539989]
   Zhang T, 2017, IEEE T NEUR SYS REH, V25, P1100, DOI 10.1109/TNSRE.2016.2611601
   Zheng AH, 2020, PATTERN RECOGN, V104, DOI 10.1016/j.patcog.2020.107352
NR 39
TC 4
Z9 4
U1 2
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 41733
EP 41750
DI 10.1007/s11042-021-11244-w
EA OCT 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000704942100002
DA 2024-07-18
ER

PT J
AU Singh, G
   Singh, K
AF Singh, Gurvinder
   Singh, Kulbir
TI Chroma key foreground forgery detection under various attacks in digital
   video based on frame edge identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chroma key foreground forgery; Difference frame; Edge frame; Green; Blue
   screen composition; Attacks
ID DETECTION ALGORITHM; DUPLICATION FORGERY; IMAGE; KEYPOINT; FORENSICS;
   SIFT
AB Chroma key foreground forgery is the most common forgery to manipulate the contents of a digital video. This kind of video can be presented in courts to show fake evidence, in political campaigns to misguide people and in the social media to distribute fake information. There are few techniques to discover this type of forgery. But a technique is required to detect the chroma key foreground forgery in the digital videos under various attacks to provide its robustness. In this paper, a passive approach is proposed for the detection of chroma key foreground forgery which is based on frame edge identification. The proposed approach generates difference frames for each frame pair of a digital video. The edges of each difference frame are identified in the proposed approach using canny edge detector. Then the proposed approach differentiates the edges pixels of each edge frame into large and small edge pixel difference values by applying threshold. After detection of the chroma key foreground forgery, the forged foreground is isolated from the authentic part of each edge frame in the digital video. Then the isolated forged foreground is localized and tracked within each frame of a forged digital video. The proposed approach is examined on the digital videos with different cases which shows high recall rate than precision rate in the experimental work. The proposed approach is then evaluated on the digital videos which are forged under the various attacks for its effective robustness. The proposed approach is also performed effectively on digital videos having realistic cases of chroma key foreground forgery with efficient results. The experimental results indicate higher detection accuracy, lower execution time and better robustness of the proposed approach than the other existing techniques.
C1 [Singh, Gurvinder; Singh, Kulbir] Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Singh, K (corresponding author), Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
EM ksingh@thapar.edu
RI Singh, Kulbir/T-7453-2019
OI Singh, Kulbir/0000-0001-8070-3395
CR Alkawaz MH, 2018, NEURAL COMPUT APPL, V30, P183, DOI 10.1007/s00521-016-2663-3
   alZahir S, 2020, MULTIMED TOOLS APPL, V79, P28643, DOI 10.1007/s11042-020-09502-4
   Bagiwa MA, 2016, DIGIT INVEST, V19, P29, DOI 10.1016/j.diin.2016.09.001
   Bao P, 2005, IEEE T PATTERN ANAL, V27, P1485, DOI 10.1109/TPAMI.2005.173
   Biswas R, 2012, PROC TECH, V4, P820, DOI 10.1016/j.protcy.2012.05.134
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen CC, 2019, MULTIMED TOOLS APPL, V78, P18293, DOI 10.1007/s11042-019-7165-8
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cozzolino D, 2012, LECT NOTES COMPUT SC, V7626, P693, DOI 10.1007/978-3-642-34166-3_76
   Ding LJ, 2001, PATTERN RECOGN, V34, P721, DOI 10.1016/S0031-3203(00)00023-6
   Emam M, 2016, MULTIMED TOOLS APPL, V75, P11513, DOI 10.1007/s11042-015-2872-2
   Ferreira WD, 2020, COMPUT ELECTR ENG, V85, DOI 10.1016/j.compeleceng.2020.106685
   Hashmi MF, 2014, AASRI PROC, V9, P84, DOI 10.1016/j.aasri.2014.09.015
   Hegazi A, 2021, J KING SAUD UNIV-COM, V33, P1055, DOI 10.1016/j.jksuci.2019.07.007
   Ivanov Y, 2015, PROCEEDINGS OF XIIITH INTERNATIONAL CONFERENCE - EXPERIENCE OF DESIGNING AND APPLICATION OF CAD SYSTEMS IN MICROELECTRONICS CADSM 2015, P97, DOI 10.1109/CADSM.2015.7230806
   Jaiprakash SP, 2020, MULTIMED TOOLS APPL, V79, P29977, DOI 10.1007/s11042-020-09415-2
   Jindal N, 2014, SIGNAL IMAGE VIDEO P, V8, P1543, DOI 10.1007/s11760-012-0391-4
   Johnston P, 2019, DIGIT INVEST, V29, P67, DOI 10.1016/j.diin.2019.03.006
   Kaur J., 2015, INT J ADV RES COMP S, V5, P235
   Kaur N, 2020, MULTIMED TOOLS APPL, V79, P32037, DOI 10.1007/s11042-020-09275-w
   Lin C, 2019, MULTIMED TOOLS APPL, V78, P30081, DOI 10.1007/s11042-018-6922-4
   Lin C, 2019, MULTIMED TOOLS APPL, V78, P20739, DOI 10.1007/s11042-019-7342-9
   Lin C, 2018, MULTIMED TOOLS APPL, V77, P14241, DOI 10.1007/s11042-017-5027-9
   Liu K, 2019, MULTIMED TOOLS APPL, V78, P31387, DOI 10.1007/s11042-019-07930-5
   Liu YQ, 2018, MULTIMED TOOLS APPL, V77, P7405, DOI 10.1007/s11042-017-4652-7
   Lyu S, 2005, IEEE T SIGNAL PROCES, V53, P845, DOI 10.1109/TSP.2004.839896
   Mahmood T, 2020, MULTIMED TOOLS APPL, V79, P31759, DOI 10.1007/s11042-020-09655-2
   Manu VT, 2018, SIGNAL IMAGE VIDEO P, V12, P549, DOI 10.1007/s11760-017-1191-7
   Meena KB, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102481
   Meena KB, 2020, MULTIMED TOOLS APPL, V79, P8197, DOI 10.1007/s11042-019-08343-0
   Niyishaka P, 2020, MULTIMED TOOLS APPL, V79, P26045, DOI 10.1007/s11042-020-09225-6
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pavlovic A, 2019, MULTIMED TOOLS APPL, V78, P20655, DOI 10.1007/s11042-019-7277-1
   Peleshko D, 2016, PROCEEDINGS OF THE 2016 IEEE FIRST INTERNATIONAL CONFERENCE ON DATA STREAM MINING & PROCESSING (DSMP), P159, DOI 10.1109/DSMP.2016.7583531
   Porter T., 1984, Computers & Graphics, V18, P253
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Prakash CS, 2019, MULTIMED TOOLS APPL, V78, P23535, DOI 10.1007/s11042-019-7629-x
   Priyanka, 2020, MULTIMED TOOLS APPL, V79, P13011, DOI 10.1007/s11042-019-08354-x
   Rong WB, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (IEEE ICMA 2014), P577, DOI 10.1109/ICMA.2014.6885761
   Sharma P., 2019, INT J RECENT TECH EN, V8, P43
   Singh A, 2018, MULTIMED TOOLS APPL, V77, P28949, DOI 10.1007/s11042-018-6075-5
   Singh G, 2020, FORENS SCI INT-DIGIT, V32, DOI 10.1016/j.fsidi.2019.200899
   Singh G, 2018, MULTIMED TOOLS APPL, V77, P485, DOI 10.1007/s11042-016-4290-5
   Singh G, 2019, MULTIMED TOOLS APPL, V78, P11527, DOI 10.1007/s11042-018-6585-1
   Smith A. R., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P259, DOI 10.1145/237170.237263
   Su LC, 2019, IEEE ACCESS, V7, P109719, DOI 10.1109/ACCESS.2019.2933871
   Su LC, 2018, MULTIDIM SYST SIGN P, V29, P1173, DOI 10.1007/s11045-017-0496-6
   Tkachenko R, 2018, STUD COMPUT INTELL, V730, P537, DOI 10.1007/978-3-319-63754-9_25
   Vaishnavi D, 2019, J INF SECUR APPL, V44, P23, DOI 10.1016/j.jisa.2018.11.001
   Vijayarani, 2013, International Journal of Innovative Research in Computer and Communication Engineering, V1, P1760
   Wang XY, 2019, MULTIMED TOOLS APPL, V78, P2311, DOI 10.1007/s11042-018-6354-1
   Xu JY, 2012, PHYSCS PROC, V33, P1316, DOI 10.1016/j.phpro.2012.05.217
   Yang JM, 2016, MULTIMED TOOLS APPL, V75, P1793, DOI 10.1007/s11042-014-2374-7
   Yedidia Adam, 2016, Against the F-score
   Yuting Su, 2011, 2011 6th IEEE Joint International Information Technology and Artificial Intelligence Conference (ITAIC 2011), P469, DOI 10.1109/ITAIC.2011.6030375
   Zhao DN, 2018, MULTIMED TOOLS APPL, V77, P25389, DOI 10.1007/s11042-018-5791-1
   Zhao J, 2013, FORENSIC SCI INT, V233, P158, DOI 10.1016/j.forsciint.2013.09.013
   Zheng LL, 2019, J VIS COMMUN IMAGE R, V58, P380, DOI 10.1016/j.jvcir.2018.12.022
NR 58
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 1419
EP 1446
DI 10.1007/s11042-021-11380-3
EA OCT 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000702800000001
DA 2024-07-18
ER

PT J
AU Nagakrishnan, R
   Revathi, A
AF Nagakrishnan, R.
   Revathi, A.
TI Generic speech based person authentication system with genuine and
   spoofed utterances: different feature sets and models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature extraction; Modeling technique; Person authentication system;
   Performance metrics; Spoofing attacks
ID SPEAKER IDENTIFICATION
AB Biometrics is a common method of securely and efficiently identifying and authenticating individuals by using unique biological features. In this work, speech based person authentication system has been developed based on a different set of features such as Mel frequency cepstral coefficient (MFCC), Linear predictive cepstral coefficient (LPCC) and Perceptual features with critical band analysis done in Bark scale (PLPC), Mel Frequency (MF-PLPC) scale, and Equivalent rectangular bandwidth (ERB-PLPC) scale respectively. The implementation of a speech-based authentication system assimilates feature extraction from speech, modeling methods, and testing procedures for validating the person. Efficiency of the text dependent and text independent system is compared with respect to different features for the database encompassing genuine and attack utterances. In this work, AVSpoof and TIMIT database speech utterances are used for validating 44 and 104 speakers respectively. Efficiency of the proposed system is investigated with different metrics such as correlation coefficient, PSNR, F-ratio, recognition accuracy and ROC curve. ERBPLPC has provided better overall recognition accuracy for the system with genuine set of utterances considered for training and testing. This work is also extended to evaluate the authentication system against attack utterances chosen from speech synthesis attack, replay attack, and voice conversion attack in AVSpoof database and the performance of the system is assessed in terms of rejection rate. ERB-PLPC provides the high rejection rate as 91% on an average against all attacks and ensures that the feature selection is more robust by performing testing against spoofing attack set and genuine set of test utterances.
C1 [Nagakrishnan, R.; Revathi, A.] SASTRA Deemed Univ, Dept ECE, Sch EEE, Thanjavur, Tamil Nadu, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Revathi, A (corresponding author), SASTRA Deemed Univ, Dept ECE, Sch EEE, Thanjavur, Tamil Nadu, India.
EM nagakrishnan@sastra.ac.in; revathi@ece.sastra.edu
CR Al-Kaltakchi MTS, 2017, EURASIP J ADV SIG PR, DOI 10.1186/s13634-017-0515-7
   Almaadeed N, 2015, IET BIOMETRICS, V4, P18, DOI 10.1049/iet-bmt.2014.0011
   Bhardwaj S, 2013, IEEE T CYBERNETICS, V43, P1047, DOI 10.1109/TSMCB.2012.2223461
   Das RK, 2017, J SIGNAL PROCESS SYS, V88, P259, DOI 10.1007/s11265-016-1148-z
   El Ayadi M, 2017, SPEECH COMMUN, V92, P52, DOI 10.1016/j.specom.2017.05.005
   Ergünay SK, 2015, INT CONF BIOMETR THE
   Garofolo J. S., 1993, Timit acoustic phonetic continuous speech corpus
   Groza V, 2016, 2016 IEEE INT INSTR, P1, DOI [10.1109/I2MTC.2016.7520363, DOI 10.1109/I2MTC.2016.7520363]
   Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423
   Hu YK, 2013, IEEE T AUDIO SPEECH, V21, DOI 10.1109/TASL.2012.2234113
   Inthavisas K, 2012, IET BIOMETRICS, V1, P46, DOI 10.1049/iet-bmt.2011.0008
   Jalil M, 2013, 2013 INTERNATIONAL CONFERENCE ON TECHNOLOGICAL ADVANCES IN ELECTRICAL, ELECTRONICS AND COMPUTER ENGINEERING (TAEECE), P208
   Kinnunen T, 2012, INT CONF ACOUST SPEE, P4401, DOI 10.1109/ICASSP.2012.6288895
   Kreuk F, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1962, DOI 10.1109/ICASSP.2018.8462693
   Lai CI, 2019, INT CONF ACOUST SPEE, P6316, DOI 10.1109/ICASSP.2019.8682640
   Li Q, 2011, IEEE T AUDIO SPEECH, V19, P1791, DOI 10.1109/TASL.2010.2101594
   Matejka P, 2016, INT CONF ACOUST SPEE, P5100, DOI 10.1109/ICASSP.2016.7472649
   Nayana PA, 2017, PROCEDIA COMPUT SCI, V115, P47, DOI 10.1016/j.procs.2017.09.075
   Panagiotakis C, 2005, IEEE T MULTIMEDIA, V7, P155, DOI 10.1109/TMM.2004.840604
   PEACOCKE RD, 1990, COMPUTER, V23, P26, DOI 10.1109/2.56868
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   Revathi A, 2019, MULTIMED TOOLS APPL, V78, P1569, DOI 10.1007/s11042-018-6258-0
   Revathi A, 2018, INT J SPEECH TECHNOL, V21, P1021, DOI 10.1007/s10772-018-09563-9
   Revathi A., 2011, 2011 International Conference on Communications and Signal Processing (ICCSP), P198, DOI 10.1109/ICCSP.2011.5739300
   Revathi A, 2009, INT J COMPUT SCI INF, V1
   Sadjadi SO, 2015, SPEECH COMMUN, V72, P138, DOI 10.1016/j.specom.2015.04.005
   Tharwat A, 2021, APPL COMPUT INFORM, V17, P168, DOI 10.1016/j.aci.2018.08.003
   Todisco M, 2017, COMPUT SPEECH LANG, V45, P516, DOI 10.1016/j.csl.2017.01.001
   Togneri R, 2011, IEEE CIRC SYST MAG, V11, P23, DOI 10.1109/MCAS.2011.941079
   Wu JD, 2011, EXPERT SYST APPL, V38, P6112, DOI 10.1016/j.eswa.2010.11.013
   Yang H, 2014, IET BIOMETRICS, V3, P9, DOI 10.1049/iet-bmt.2013.0027
   Yoo IC, 2015, IEEE-ACM T AUDIO SPE, V23, P2238, DOI 10.1109/TASLP.2015.2476762
   Zhao XJ, 2014, IEEE-ACM T AUDIO SPE, V22, P836, DOI 10.1109/TASLP.2014.2308398
NR 34
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 1179
EP 1208
DI 10.1007/s11042-021-11365-2
EA SEP 2021
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000699014000001
DA 2024-07-18
ER

PT J
AU Lee, J
   Hwang, KI
AF Lee, Jeonghun
   Hwang, Kwang-il
TI YOLO with adaptive frame control for real-time object detection
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Embedded systems; Frame control; Object detection; Real-time; YOLO
AB You only look once (YOLO) is being used as the most popular object detection software in many intelligent video applications due to its ease of use and high object detection precision. In addition, in recent years, various intelligent vision systems based on high-performance embedded systems are being developed. Nevertheless, the YOLO still requires high-end hardware for successful real-time object detection. In this paper, we first discuss real-time object detection service of the YOLO on AI embedded systems with resource constraints. In particular, we point out the problems related to real-time processing in YOLO object detection associated with network cameras, and then propose a novel YOLO architecture with adaptive frame control (AFC) that can efficiently cope with these problems. Through various experiments, we show that the proposed AFC can maintain the high precision and convenience of YOLO, and provide real-time object detection service by minimizing total service delay, which remains a limitation of the pure YOLO.
C1 [Lee, Jeonghun; Hwang, Kwang-il] Incheon Natl Univ, Dept Embedded Syst Engn, Incheon 22012, South Korea.
C3 Incheon National University
RP Hwang, KI (corresponding author), Incheon Natl Univ, Dept Embedded Syst Engn, Incheon 22012, South Korea.
EM hkwangil@inu.ac.kr
FU National Research Foundation of Korea (NRF) - Korea Government (MSIT)
   [NRF-2019R1F1A1054896]
FX This work was supported by the National Research Foundation of Korea
   (NRF) Grant funded by the Korea Government (MSIT) (No.
   NRF-2019R1F1A1054896).
CR Barry D, 2019, INT CONF IMAG VIS, DOI 10.1109/ivcnz48456.2019.8960963
   Barthélemy J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092048
   Cao ZG, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.113833
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fang W, 2020, IEEE ACCESS, V8, P1935, DOI 10.1109/ACCESS.2019.2961959
   Fikri RM, 2020, LECT NOTES ELECTR EN, V621, P229, DOI 10.1007/978-981-15-1465-4_24
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gour D., 2019, INT J ENG RES TECHNO, V8, P160
   He WP, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9163225
   Jamtsho Y, 2020, ICT EXPRESS, V6, P121
   Jingting, 2020, 2020 INT C EL COMM
   Kalhagen ES, 2020, THESIS U AGDER
   Kim S., 2019, Spiking-yolo: Spiking neural network for energy-efficient object detection
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lu SY, 2019, COMPUT ELECTR ENG, V77, P398, DOI 10.1016/j.compeleceng.2019.05.009
   Mohd P, 2020, THESIS U TEKNOLOGI M
   Novak B, 2020, 2020 ZOOMING INNOVATION IN CONSUMER TECHNOLOGIES CONFERENCE (ZINC), P165, DOI [10.1109/zinc50678.2020.9161446, 10.1109/ZINC50678.2020.9161446]
   Oltean G, 2019, INT SYM DES TECH ELE, P240, DOI [10.1109/SIITME47687.2019.8990708, 10.1109/siitme47687.2019.8990708]
   Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren PM, 2020, INT J BIO-INSPIR COM, V16, P94, DOI 10.1504/IJBIC.2020.109674
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Schulzrinne H., 1998, 2326 RFC
   Shaobin Chen, 2019, 2019 IEEE 3rd Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC), P1400, DOI 10.1109/IMCEC46724.2019.8984055
   Shi R, 2020, COMPUT ELECTRON AGR, V169, DOI 10.1016/j.compag.2020.105214
   Silva P, 2019, THESIS U INVESTIGACI
   Ullah MB, 2020, IEEE REGION 10 SYMP, P552
   Wang J, 2020, NEURAL COMPUT APPL, V32, P5471, DOI 10.1007/s00521-019-04645-4
   Wang ZX, 2020, IEEE ACCESS, V8, P116569, DOI 10.1109/ACCESS.2020.3004198
   Zhou Z, 2019, P IEEE, V107, P1738, DOI 10.1109/JPROC.2019.2918951
NR 31
TC 21
Z9 22
U1 42
U2 201
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36375
EP 36396
DI 10.1007/s11042-021-11480-0
EA SEP 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000696768600002
OA hybrid
DA 2024-07-18
ER

PT J
AU Miranda, JD
   Parada, DJ
AF Miranda, Julian D.
   Parada, Diego J.
TI LSB steganography detection in monochromatic still images using
   artificial neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Steganalysis; Artificial neural networks; Least
   significant bit
AB Embedding graphic content in multimedia through steganography is a useful and fast practice to hide information. However, detecting the use of this technique is complex and sometimes unsuccessful because variations are not visually perceptible. This article proposes the use of a binary classification model based on artificial neural networks to detect the presence of LSB steganography on monochromatic still images of 256x256 and 8 bits, based on the Standford Genome Project. The steganograms were generated by varying the payload from 0.1 to 0.5 to obtain image pairs of carriers and steganograms. For each steganogram, the following features were extracted from image histograms: kurtosis, skewness, standard deviation, range, median, harmonic mean, Hjorth mobility, and complexity. The results show that the classifier reaches a 91.45% accuracy in detecting LSB steganography when learning from all payloads, as well as a 96.78% individual classification accuracy in the best case with a payload of 0.5.
C1 [Miranda, Julian D.; Parada, Diego J.] Pontifical Bolivarian Univ, Fac Syst & Informat Engn, Bucaramanga, Colombia.
C3 Universidad Pontificia Bolivariana
RP Miranda, JD (corresponding author), Pontifical Bolivarian Univ, Fac Syst & Informat Engn, Bucaramanga, Colombia.
EM julian.miranda@upb.edu.co; diego.parada@upb.edu.co
OI Miranda, Julian/0000-0002-7580-2361
FU Pontifical Bolivarian University
FX This study was funded by Pontifical Bolivarian University (in kind
   money).
CR AgarpA, 2019, DEEP LEARNING RECTIF, P7
   [Anonymous], 2017, ARXIV170709725
   Bai L, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7510852
   Chandrababu A., 2009, Using an artificial neural network to detect the presence of image steganography
   Chhikara R, 2017, 2017 INT C COMP COMM
   CoxJ, 2018, SHAKESPEARE TINY PIC
   Emam MM, 2016, INT J ADV COMPUT SC, V7, P361
   Fairchild MD., 2013, COLOR APPEARANCE MOD, DOI DOI 10.1002/9781118653128
   Filippas J, 2017, J INFORM HIDING MULT, V8, P16
   Fridrich J, 2005, PROC SPIE, V5681, P595, DOI 10.1117/12.584426
   GeoEdge PR Department, 2018, EMB MAL ADS AD IM AC
   Gonzalez R, 2009, DIGITAL IMAGE PROCES, V826
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hansson M, 2017, FEEDFORWARD NEURAL N
   Huang GB, 2003, IEEE T NEURAL NETWOR, V14, P274, DOI 10.1109/TNN.2003.809401
   Ingale AK, 2016, 2016 INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (ICONSIP)
   Janocha Katarzyna, 2017, Theor Found Mach Learn, DOI [DOI 10.4467/20838476SI.16.004.6185, 10.4467/20838476SI.16. 004.6185]
   Jiaohua Qin, 2010, Information Technology Journal, V9, P1725, DOI 10.3923/itj.2010.1725.1738
   Judd D, 1952, COLOR BUSINESS SCI I, P388
   Kim D-H., 2017, INT J MATH COMPUT SI, V11, P5
   Kim DH, 2017, 2017 EUROPEAN CONFERENCE ON ELECTRICAL ENGINEERING AND COMPUTER SCIENCE (EECS), P1, DOI 10.1109/EECS.2017.9
   Kolata G, 2001, NEW YORK TIMES MAG, P4
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Larochelle H, 2009, J MACH LEARN RES, V10, P1
   Mathworks' Algortimos Machine Learning for classification (SVM), 2018, THE MATHWORKS
   Patestas M., 2006, TXB NEUROANATOMY, P256
   Pevny T, 2007, P SPIE INT SOC OPTIC, P13
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Qian Y., 2016, LEARNING REPRESENTAT
   Qian YL, 2018, MULTIMED TOOLS APPL, V77, P19633, DOI 10.1007/s11042-017-5326-1
   Ruder S., 2017, OVERVIEW GRADIENT DE, P14
   Sharifzadeh M, 2017, CONVOLUTIONAL NEURAL
   Sterling B, 2001, NEW YORK TIMES MAG, P109
   Sun Y, 2019, J REAL-TIME IMAGE PR, V16, P635, DOI 10.1007/s11554-019-00849-y
   Wu SJ, 2017, I S INTELL SIG PROC, P12, DOI 10.1109/ISPACS.2017.8265637
NR 35
TC 3
Z9 3
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 785
EP 805
DI 10.1007/s11042-021-11527-2
EA SEP 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000696768700006
OA hybrid
DA 2024-07-18
ER

PT J
AU Velez, G
   Perez, J
   Martin, A
AF Velez, Gorka
   Perez, Josu
   Martin, Angel
TI 5G MEC-enabled vehicle discovery service for streaming-based CAM
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 5G; MEC; Streaming; Vehicle Discovery Service (VDS); WebRTC
ID PREDICTION
AB Cooperative perception represents an important technology to fulfil the higher automation levels of connected and automated mobility (CAM). In cooperative perception, the sensor data, either raw or processed, is shared among neighbour vehicles with the objective of enhancing or complementing the perception obtained by on-board sensors. The vehicle that requests this external perception data needs to have this data quickly. However, it first needs to discover the network address of the neighbour vehicle that wants to connect to. Specially in a dense urban area or in a congested radio channel, an inefficient method for neighbour vehicle discovery could prevent a timely start of the cooperative perception session. This paper describes a novel 5G multi-access edge computing (MEC) solution that that boosts the selection of interesting neighbour vehicles according to a geographical region of interest (ROI) after applying pertinent adjustments considering vehicles' dynamics and network communication latencies. In contrast to broadcast-based methods, in the proposed method the vehicles are only sending their periodical position data to a MEC service, which centralises the vehicle discovery requests. The objective of this Vehicle Discovery Service (VDS) is to support the startup of Web Real-Time Communications (WebRTC)-based Extended Sensors CAM applications. The proposed VDS has been validated using a public vehicular traffic dataset evaluating geo-position accuracy. The WebRTC-based streaming pipeline has been validated testing its feasibility for a See-Through video streaming application.
C1 [Velez, Gorka; Perez, Josu; Martin, Angel] Basque Res & Technol Alliance BRTA, Vicomtech Fdn, Mikeletegi 57, Donostia San Sebastian 20009, Spain.
RP Velez, G (corresponding author), Basque Res & Technol Alliance BRTA, Vicomtech Fdn, Mikeletegi 57, Donostia San Sebastian 20009, Spain.
EM gvelez@vicomtech.org; jperez@vicomtech.org; amartin@vicomtech.org
RI Velez, Gorka/AAD-2821-2020; Martin, Angel/I-8049-2017
OI Velez, Gorka/0000-0002-8367-2413; Martin, Angel/0000-0002-1213-6787
FU European Union [825496]
FX This work is a part of the 5G-MOBIX project. This project has received
   funding from the European Union's Horizon 2020 research and innovation
   programme under grant agreement No 825496. Content reflects only the
   authors' view and European Commission is not responsible for any use
   that may be made of the information it contains.
CR 3GPP, 2018, 22886 3GPPP TS
   3GPP, 2019, Tech. Rep. 3GPP TS 22.186 V16.2.0
   Abbas F, 2019, IEEE T INTELL TRANSP, V20, P2185, DOI 10.1109/TITS.2018.2865173
   Althoff M, 2017, IEEE INT VEH SYM, P719, DOI 10.1109/IVS.2017.7995802
   [Anonymous], 2016, 002 ETSI GS MEC, P1
   Arregui H, 2019, IEEE ACCESS, V7, P144408, DOI 10.1109/ACCESS.2019.2910225
   Barros MT, 2020, IET INTELL TRANSP SY, V14, P182, DOI 10.1049/iet-its.2019.0111
   Boban M, 2018, IEEE VEH TECHNOL MAG, V13, P110, DOI 10.1109/MVT.2017.2777259
   BULFONE A, 2020, MULTIMED TOOLS APPL
   Canonical Ubuntu, 2019, TRAFF CONTR
   ETSI, 2019, Standard ETSI TR 103 562 V2.1.1
   ETSI, 2017, 22185 3GPP TS
   Fodor Gabor, 2019, IEEE Communications Standards Magazine, V3, P26, DOI 10.1109/MCOMSTD.2019.1800049
   Ghosh A, 2019, IEEE ACCESS, V7, P127639, DOI 10.1109/ACCESS.2019.2939938
   Gomes P, 2012, IEEE VEHIC NETW CONF, P40, DOI 10.1109/VNC.2012.6407443
   GSM Alliance, 2017, CELL VEH EVER V2X EN
   Higuchi T, 2019, IEEE INT VEH SYM, P1947, DOI 10.1109/IVS.2019.8814110
   IETF, 2020, IPWAVE WG VEH NEIGHB
   KIM D, 2020, MULTIMED TOOLS APPL
   Klaine PV, 2017, IEEE COMMUN SURV TUT, V19, P2392, DOI 10.1109/COMST.2017.2727878
   LEE YS, 2019, MULTIMED TOOLS APPL
   LI D, 2020, MULTIMED TOOLS APPL
   Light RA, 2017, J Open Source Software, V2, P265, DOI [DOI 10.21105/JOSS.00265, 10.21105/joss.00265]
   Lin L, 2019, MULTIMED TOOLS APPL, V78, P14591, DOI 10.1007/s11042-018-6848-x
   Liu CF, 2020, IEEE T INTELL TRANSP, V21, P159, DOI 10.1109/TITS.2018.2889923
   Martin A, 2020, IEEE T BROADCAST, V66, P264, DOI 10.1109/TBC.2019.2954097
   Martin A, 2018, IEEE T BROADCAST, V64, P561, DOI 10.1109/TBC.2018.2828608
   MARTINSACRISTAN D, 2020, IEEE T INTELL TRANSP
   McKinsey & Company, 2018, BUZZ BUCKS AUT PLAY
   Palacios S, 2019, MULTIMED TOOLS APPL, V78, P24657, DOI 10.1007/s11042-018-6940-2
   Porambage P, 2018, IEEE COMMUN SURV TUT, V20, P2961, DOI 10.1109/COMST.2018.2849509
   Reid T., 2019, SAE International Journal of Connected and Automated Vehicles, V3, P173, DOI [10.4271/12-02-03-0012, DOI 10.4271/12-02-03-0012]
   Thandavarayan G, 2019, IEEE INT VEH SYM, P134, DOI 10.1109/IVS.2019.8813806
   Thompson RL, 2018, SAE TECHNICAL PAPER, DOI 10.4271/2018-01-0611
   Velez G, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20226622
   VIVEKANANDA GN, 2019, MULTIMED TOOLS APPL
   W3C, 2019, WEBRTC 1 0 REAL TIME
   Yan Z., 2019, I SYMP CONSUM ELECTR, P1, DOI [10.1109/APACE47377.2019.9020951, DOI 10.1109/icce.2019.8662016]
NR 38
TC 8
Z9 8
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12349
EP 12370
DI 10.1007/s11042-021-11421-x
EA SEP 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000696465700001
DA 2024-07-18
ER

PT J
AU Kaur, N
   Mittal, A
   Singh, G
AF Kaur, Navdeep
   Mittal, Ajay
   Singh, Gurprem
TI Methods for automatic generation of radiological reports of chest
   radiographs: a comprehensive survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Radiological reports; Chest radiographs; Deep-learning; Radiological
   report generation; Medical image report generation; Textual description
ID EMERGENCY-DEPARTMENT
AB Generation of a clear, correct, concise, complete, and coherent linguistic description of the visual patterns in a medical image is a challenging task. Unfortunately, many radiologists fail to satisfactorily perform this task due to various reasons such as workload, scant time, and fatigue. Although AI-based computer-aided detection (CADe) and computer-aided diagnosis (CADx) systems have been developed for observing and interpreting patterns in medical images, they do not generate radiological reports. In recent years, a lot of research has been done to develop automated report generation methods. This paper presents a comprehensive survey of all such methods specifically developed for chest radiographs. It consolidates information about standard chest X-ray datasets, state-of-the-art report generation methods, evaluation metrics, and their results. Deep learning-based techniques for automatically generating chest radiographic reports have been classified and discussed in detail. The encoder-decoder-based techniques have been meticulously categorized for a better understanding of the developments in this area. This paper is also beneficial for the researchers interested in developing automatic report generation systems for imaging modalities other than chest radiographs.
C1 [Kaur, Navdeep] Mehr Chand Mahajan DAV Coll Women, Sect 36 A, Chandigarh 160036, India.
   [Mittal, Ajay] Panjab Univ, UIET, Sect 25, Chandigarh 160014, India.
   [Singh, Gurprem] Ciena Corp, San Jose, CA USA.
C3 Panjab University; Ciena Corporation
RP Mittal, A (corresponding author), Panjab Univ, UIET, Sect 25, Chandigarh 160014, India.
EM aulakh83@gmail.com; ajaymittal825@gmail.com; gurpremsingh94@gmail.com
OI Kaur, Navdeep/0000-0002-8159-4749
FU Ministry of Electronics and Information Technology (MeITy), Government
   of India, New Delhi-India through Visvesvaraya Research Fellowship
FX This research is funded by Ministry of Electronics and Information
   Technology (MeITy), Government of India, New Delhi-India through
   Visvesvaraya Research Fellowship.
CR Al Aseri Z, 2009, EMERG RADIOL, V16, P111, DOI 10.1007/s10140-008-0763-9
   Alfarghaly O., 2021, INFORM MED UNLOCKED, V24, DOI DOI 10.1016/J.IMU.2021.100557
   Aronson AR, 2010, J AM MED INFORM ASSN, V17, P229, DOI 10.1136/jamia.2009.002733
   Babu AS, 2015, RADIOGRAPHICS, V35, P547, DOI 10.1148/rg.352140046
   Banerjee S., 2005, P WORKSHOP INTRINSIC, P65
   Benger JR, 2003, EMERG MED J, V20, P40, DOI 10.1136/emj.20.1.40
   Bengio Y., 2009, P 26 ANN INT C MACH, V60, P6, DOI [DOI 10.1145/1553374.1553380, 10.1145/1553374.1553380]
   Bustos A, 2020, MED IMAGE ANAL, V66, DOI 10.1016/j.media.2020.101797
   Callison-Burch C, 2006, 11 C EUR CHAPT ASS C
   Chen ZH, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1439
   Cho K., 2014, ARXIV14061078
   Chung Junyoung, 2014, ARXIV14123555
   de Hoop B, 2010, RADIOLOGY, V255, P629, DOI 10.1148/radiol.09091308
   Demner-Fushman Dina, 2012, Journal of Computing Science and Engineering, V6, P168, DOI 10.5626/JCSE.2012.6.2.168
   ESR, 2018, INSIGHTS IMAGING, V9, P1, DOI 10.1007/s13244-017-0588-8
   ESR, 2011, INSIGHTS IMAGING, V2, P93, DOI 10.1007/s13244-011-0066-7
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Gatt ME, 2003, POSTGRAD MED J, V79, P214, DOI 10.1136/pmj.79.930.214
   Grosvenor LJ, 2003, CLIN RADIOL, V58, P719, DOI 10.1016/S0009-9260(03)00219-8
   Harzig Philipp, 2019, ARXIV190802123
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He X, 2018, DEEP LEARNING NATURA, P289, DOI DOI 10.1007/978-981-10-5209-5_10
   Herdade S, 2019, ADV NEUR IN, V32
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Horváth G, 2009, IFMBE PROC, V25, P210, DOI 10.1007/978-3-642-03904-1_59
   HorvathA Horvath G, 2011, 5 EUR C INT FED MED, P655, DOI [10.1007/978-3-642-23508-5_170, DOI 10.1007/978-3-642-23508-5_170]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang X, 2019, IEEE ACCESS, V7, P154808, DOI 10.1109/ACCESS.2019.2947134
   Irvin J, 2019, AAAI CONF ARTIF INTE, P590
   Jaiswal AK, 2019, MEASUREMENT, V145, P511, DOI 10.1016/j.measurement.2019.05.076
   Jing B., 2019, Acl, DOI DOI 10.18653/V1/P19-1657
   Jing BY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2577
   Johnson AE, 2019, ARXIV PREPRINT ARXIV, DOI [10.1038/s41597-019-0322-0, DOI 10.1038/S41597-019-0322-0]
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kisilev P, 2015, BMVC, P171, DOI [10.5244/C.29.171, DOI 10.5244/C.29.171]
   Krause J, 2017, PROC CVPR IEEE, P3337, DOI 10.1109/CVPR.2017.356
   Lam TK, 2018, ARXIV PREPRINT ARXIV
   Leaman R, 2015, J BIOMED INFORM, V57, P28, DOI 10.1016/j.jbi.2015.07.010
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee GH, 2017, P 8 INT JOINT C NAT, V2, P193
   Li CY, 2019, AAAI CONF ARTIF INTE, P6666
   Li X., 2019, P 5 WORKSH NOIS US G, P34
   Li YZ, 2018, ADV NEUR IN, V31
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   Liu G., 2019, MACHINE LEARNING HEA
   Liu SQ, 2017, IEEE I CONF COMP VIS, P873, DOI 10.1109/ICCV.2017.100
   Lovelace J, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1235
   Marrie T J, 1997, Can J Infect Dis, V8, P95
   Mittal A, 2017, IET IMAGE PROCESS, V11, P937, DOI 10.1049/iet-ipr.2016.0526
   Nooralahzadeh F, 2021, ARXIV PREPRINT ARXIV
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parikh, 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299087
   Petinaux B, 2011, AM J EMERG MED, V29, P18, DOI 10.1016/j.ajem.2009.07.011
   Radford A., 2019, LANGUAGE MODELS ARE
   Rajpurkar Pranav, 2017, ARXIV170701836
   REN Z, 2017, PROC CVPR IEEE, P1151, DOI DOI 10.1109/CVPR.2017.128
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Robertson S, 2004, J DOC, V60, P503, DOI 10.1108/00220410410560582
   Royal College of Radiologists, 2015, UNR XRAYS COMP TOM C
   Santosh KC, 2014, COMP MED SY, P138, DOI 10.1109/CBMS.2014.56
   Schlegl Thomas, 2015, Inf Process Med Imaging, V24, P437, DOI 10.1007/978-3-319-19992-4_34
   Shin HC, 2016, PROC CVPR IEEE, P2497, DOI 10.1109/CVPR.2016.274
   Shin HC, 2015, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2015.7298712
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sutskever I, 2014, ADV NEUR IN, V27
   Vaswani A, 2017, ADV NEUR IN, V30
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   von Berg J, 2016, INT J COMPUT ASS RAD, V11, P641, DOI 10.1007/s11548-015-1278-y
   Wang X., 2017, PROC CVPR IEEE, P2097, DOI [DOI 10.1109/CVPR.2017.369, 10.1109/CVPR.2017.369]
   Wang XS, 2018, PROC CVPR IEEE, P9049, DOI 10.1109/CVPR.2018.00943
   Xiong YX, 2019, LECT NOTES COMPUT SC, V11861, P673, DOI 10.1007/978-3-030-32692-0_77
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xue Y, 2018, LECT NOTES COMPUT SC, V11070, P457, DOI 10.1007/978-3-030-00928-1_52
   Xue ZY, 2015, COMP MED SY, P66, DOI 10.1109/CBMS.2015.49
   Xue ZY, 2015, IEEE INT C BIOINFORM, P956, DOI 10.1109/BIBM.2015.7359812
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yang Y., 2011, P C EMP METH NAT LAN, P444
   Yin CC, 2019, IEEE DATA MINING, P728, DOI 10.1109/ICDM.2019.00083
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Yu J, 2020, IEEE T CIRC SYST VID, V30, P4467, DOI 10.1109/TCSVT.2019.2947482
   Yuan JB, 2019, LECT NOTES COMPUT SC, V11769, P721, DOI 10.1007/978-3-030-32226-7_80
   Zhang YX, 2020, AAAI CONF ARTIF INTE, V34, P12910
NR 83
TC 10
Z9 11
U1 8
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13409
EP 13439
DI 10.1007/s11042-021-11272-6
EA SEP 2021
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000695631600002
DA 2024-07-18
ER

PT J
AU Xie, XZ
   Chang, CC
AF Xie, Xiao-Zhu
   Chang, Chin-Chen
TI Hiding data in dual images based on turtle shell matrix with high
   embedding capacity and reversibility
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High capacity; Reversible data hiding; Turtle shell; Pixel-value
   differencing histogram; RS analysis
ID SCHEME
AB Reversible data hiding (RDH) is a technology that embeds secret data into a carrier where both the secret data and the carrier can be recovered without any data loss. Inspired by dual images technology, this article proposes to employ a high capacity RDH scheme that is based on turtle shell (TS). We start by constructing a newly designed TS-based reference matrix. Then, two meaningful shadows will be generated after hiding the secret data in the cover image with the reference matrix's help. Meanwhile, the location conflict problem is solved. On the decoder side, when both shadows are gathered, the data extraction and image recovery can be accomplished using the orientation relationship between two stego pixels that are located at the same coordinates in the two shadows and the reference matrix. Moreover, we introduce a security enhancement technology that improves the security of data extraction. The experiment shows that compared with other state-of-the-art RDH schemes, a higher embedding capacity is achieved by this method, and a good visual quality is retained. Simultaneously, the proposed scheme is effective against attacks on pixel value difference histograms (PDH) and regular singular (RS) analysis.
C1 [Xie, Xiao-Zhu] Xiamen Univ Technol, Dept Informat Engn & Comp Sci, Xiamen 361024, Peoples R China.
   [Xie, Xiao-Zhu; Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
C3 Xiamen University of Technology; Feng Chia University
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
EM alan3c@gmail.com
RI Chang, Ching-Chun/JAN-6210-2023
FU Scientific Research Foundation for the Introduction of Talent at Xiamen
   University of Technology [YKJ21007R]; Open Fund of Engineering Research
   Center for Software Testing and Evaluation of Fujian Province
FX This work is supported by Scientific Research Foundation for the
   Introduction of Talent at Xiamen University of Technology (YKJ21007R)
   and the Open Fund of Engineering Research Center for Software Testing
   and Evaluation of Fujian Province.
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Chang C.-C., 2008, 2008 3 INT C INN COM, P17, DOI 10.1109/ICICIC.2008.149
   Chang CC, 2009, THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING (MUE 2009), P145, DOI 10.1109/MUE.2009.35
   Chang CC, 2019, MATH BIOSCI ENG, V16, P3367, DOI 10.3934/mbe.2019168
   Chang CC, 2019, IEEE ACCESS, V7, P54117, DOI 10.1109/ACCESS.2019.2908924
   Chang CC, 2018, IEEE ACCESS, V6, P70720, DOI 10.1109/ACCESS.2018.2880904
   Chang CC, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P89, DOI 10.1109/IIH-MSP.2014.29
   Chang T. Duc, 2007, P IEEE REG 10 C NOV, P1, DOI [10.1109/TENCON.2007.4483783, DOI 10.1109/TENCON.2007.4483783]
   Di FQ, 2019, MULTIMED TOOLS APPL, V78, P7125, DOI 10.1007/s11042-018-6469-4
   Fridrich J., 2001, P ACM WORKSH MULT SE, P27
   Jia YJ, 2019, SIGNAL PROCESS, V163, P238, DOI 10.1016/j.sigpro.2019.05.020
   Lee CF, 2013, TELECOMMUN SYST, V52, P2237, DOI 10.1007/s11235-011-9529-x
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Lin JY, 2019, J REAL-TIME IMAGE PR, V16, P673, DOI 10.1007/s11554-019-00863-0
   Liu YJ, 2018, MULTIMED TOOLS APPL, V77, P25295, DOI 10.1007/s11042-018-5785-z
   Lu TC, 2020, IEEE ACCESS, V8, P90824, DOI 10.1109/ACCESS.2020.2994244
   Huynh NT, 2015, J VIS COMMUN IMAGE R, V28, P105, DOI 10.1016/j.jvcir.2015.01.011
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Qu X, 2015, SIGNAL PROCESS, V111, P249, DOI 10.1016/j.sigpro.2015.01.002
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang X, 2015, INFORM SCIENCES, V310, P16, DOI 10.1016/j.ins.2015.03.022
   Xie XZ, 2020, IEEE ACCESS, V8, P37, DOI 10.1109/ACCESS.2019.2961764
   Xie XZ, 2019, MULTIMED TOOLS APPL, V78, P19413, DOI 10.1007/s11042-018-7098-7
   Yao H, 2020, SIGNAL PROCESS, V170, DOI 10.1016/j.sigpro.2019.107447
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 28
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2021
VL 80
IS 30
BP 36567
EP 36584
DI 10.1007/s11042-021-11368-z
EA SEP 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XI4QI
UT WOS:000694561500001
DA 2024-07-18
ER

PT J
AU Testa, RL
   Machado-Lima, A
   Nunes, FLS
AF Testa, Rafael Luiz
   Machado-Lima, Ariane
   Nunes, Fatima L. S.
TI Facial expression synthesis based on similar faces
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face similarity; Facial Expression Synthesis; Facial Expression Mapping;
   Facial Expression Reenactment; Facial Expression Generation; Facial
   Attribute Editing
ID HIGH-FUNCTIONING AUTISM; DATA-DRIVEN APPROACH; HALLUCINATION;
   RECOGNITION
AB Facial expression synthesis has several applications involving animation, human-computer interaction, entertainment, and training people with mental disorders. Facial expression synthesis aims to alter an image's facial expression, usually by reenacting the facial movements from an example image in the target image. Deformation-based approaches usually choose the example image manually, leading to different results depending on this choice. This study differs from the literature by proposing and evaluating techniques that consider the similarity between facial images to choose the source image. The primary goal is to investigate the influence of selecting the source image in generated facial expressions of emotions. We propose three techniques for selecting similar faces in the facial expression synthesis pipeline and compare them to other approaches. We also compare the generated synthetic emotions with the results of recent methods from the literature by using objective metrics. Our findings suggest that one of the proposed techniques presented higher results in the search for similar faces and similar or better results for the synthesis when compared to the literature. Additionally, a visual analysis showed that similar faces can improve synthetic images' realism, especially when compared to randomly selected facial images.
C1 [Testa, Rafael Luiz; Machado-Lima, Ariane; Nunes, Fatima L. S.] Univ Sao Paulo, Sch Arts Sci & Humanities, Sao Paulo, Brazil.
C3 Universidade de Sao Paulo
RP Testa, RL (corresponding author), Univ Sao Paulo, Sch Arts Sci & Humanities, Sao Paulo, Brazil.
EM rafael.testa@usp.br
RI Machado-Lima, Ariane/F-4245-2012; Nunes, Fatima/C-4126-2012; Testa,
   Rafael Luiz/Q-6960-2016
OI Nunes, Fatima/0000-0003-0040-0752; Testa, Rafael
   Luiz/0000-0002-7209-1111
FU Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior - Brasil
   (CAPES) [001]; Dean's Office for Research of the University of Sao Paulo
   [18.5.245.86.7]; Brazilian National Council of Scientific and
   Technological Development (CNPq) [157535/2017-7]; Sao Paulo Research
   Foundation (FAPESP) [14/50889-7]; Fundacao de Amparo a Pesquisa do
   Estado de Sao Paulo (FAPESP) [14/50889-7] Funding Source: FAPESP
FX The authors would like to thank the VISGRAF Lab at the Instituto
   Nacional de Matematica Pura e Aplicada and the Multimedia Understanding
   Group at the Aristotle University of Thessaloniki for providing the
   images used in this study. This study was financed in part by the
   Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior - Brasil
   (CAPES) - Finance Code 001, the Dean's Office for Research of the
   University of SAo Paulo (process 18.5.245.86.7 - Intelligent psychiatric
   disorder classification system based on facial anthropometric
   measurements), Brazilian National Council of Scientific and
   Technological Development (CNPq) (Process 157535/2017-7) and SAo Paulo
   Research Foundation (FAPESP) (Process 14/50889-7): National Institute of
   Science and Technology - Medicine Assisted by Scientific Computing
   (INCT-MACC).
CR Abboud B, 2004, SIGNAL PROCESS-IMAGE, V19, P723, DOI 10.1016/j.image.2004.05.009
   Agarwal S, 2012, P 8 IND C COMP VIS G, V12, P1, DOI 10.1145/2425333.2425361
   Aifanti N., 2010, P 11 INT WORKSH IM A, DOI DOI 10.1371/JOURNAL.PONE.0009715
   [Anonymous], 2015, BRIT MACH VIS C
   [Anonymous], 2002, A Hum. Face
   [Anonymous], 2016, in Face Detec-tion and Facial Image Analysis, DOI DOI 10.1007/978-3-319-25958-1_8
   [Anonymous], 1971, The face of emotion
   [Anonymous], 1972, Emotion in the Human Face: guidelines for Research and an Integration of Findings
   Averbuch-Elor H, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130818
   Bailey D. G., 2011, Design for Embedded Image Processing on FPGAs
   Bradski G, 2000, DR DOBBS J, V25, P120
   Cheng YF, 2008, 8TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P17, DOI 10.1109/ICALT.2008.220
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Deb D, 2020, IEEEIAPR INT JOINT, P1, DOI DOI 10.1109/ijcb48548.2020.9304898
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding H, 2018, AAAI CONF ARTIF INTE, P6781
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fujishiro H, 2009, SIGGRAPH 09
   Geng JH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275043
   Ghent J, 2005, IMAGE VISION COMPUT, V23, P1041, DOI 10.1016/j.imavis.2005.06.011
   Golan O, 2006, DEV PSYCHOPATHOL, V18, P591, DOI 10.1017/S0954579406060305
   Grynszpan O, 2008, INT J HUM-COMPUT ST, V66, P628, DOI 10.1016/j.ijhcs.2008.04.001
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Horn R., 1985, Matrix Analysis, DOI [10.1017/CBO9780511810817, 10.1017/CBO9781139020411]
   Jian MW, 2019, INFORM SCIENCES, V488, P181, DOI 10.1016/j.ins.2019.03.026
   Jian M, 2015, IEEE T CIRC SYST VID, V25, P1761, DOI 10.1109/TCSVT.2015.2400772
   Jian MW, 2014, SIGNAL PROCESS, V100, P9, DOI 10.1016/j.sigpro.2014.01.004
   Jian MW, 2014, INFORM SCIENCES, V262, P1, DOI 10.1016/j.ins.2013.12.001
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   King D, 2017, HIGH QUALITY FACE RE
   King DE, 2016, DLIB FACE DETECTION
   Köstinger M, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Lahiri U, 2013, IEEE T NEUR SYS REH, V21, P55, DOI 10.1109/TNSRE.2012.2218618
   Lei Xiong, 2009, 2009 4th IEEE Conference on Industrial Electronics and Applications, P1582, DOI 10.1109/ICIEA.2009.5138461
   Li K, 2014, IEEE T MULTIMEDIA, V16, P299, DOI 10.1109/TMM.2013.2293064
   Li K, 2012, PROC CVPR IEEE, P57, DOI 10.1109/CVPR.2012.6247658
   Li X, 2007, J VISUAL LANG COMPUT, V18, P440, DOI 10.1016/j.jvlc.2007.02.008
   Li Z., 2004, DIGITAL TERRAIN MODE
   Liu ZC, 2001, COMP GRAPH, P271
   Marcetic D, 2017, LECT NOTES COMPUT SC, V10425, P379, DOI 10.1007/978-3-319-64698-5_32
   Masi I, 2018, SIBGRAPI, P471, DOI 10.1109/SIBGRAPI.2018.00067
   Mena-Chalco J, 2008, BANCO DADOS FACES 3D
   Mendi E., 2011, 2011 IEEE 13th International Conference on e-Health Networking, Applications and Services (Healthcom 2011), P52, DOI 10.1109/HEALTH.2011.6026785
   Mima D, 2011, SIGGRAPH AS 2011 POS
   Moghadam SM, 2018, NEURAL NETWORKS, V105, P304, DOI 10.1016/j.neunet.2018.05.016
   Ng HW, 2014, IEEE IMAGE PROC, P343, DOI 10.1109/ICIP.2014.7025068
   Noh JY, 2001, COMP GRAPH, P277, DOI 10.1145/383259.383290
   Otberdout N, 2022, IEEE T PATTERN ANAL, V44, P848, DOI 10.1109/TPAMI.2020.3002500
   Pickering MJ, 2003, COMPUT VIS IMAGE UND, V92, P217, DOI 10.1016/j.cviu.2003.06.002
   Sagonas C, 2016, IMAGE VISION COMPUT, V47, P3, DOI 10.1016/j.imavis.2016.01.002
   Seo M, 2012, 2012 6TH INTERNATIONAL CONFERENCE ON NEW TRENDS IN INFORMATION SCIENCE, SERVICE SCIENCE AND DATA MINING (ISSDM2012), P483
   Song LX, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P627, DOI 10.1145/3240508.3240612
   Testa RL, 2018, SIBGRAPI, P297, DOI 10.1109/SIBGRAPI.2018.00045
   Testa RL, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3292652
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Tulyakov S, 2018, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR.2018.00165
   Udupa JK, 2006, COMPUT MED IMAG GRAP, V30, P75, DOI 10.1016/j.compmedimag.2005.12.001
   Vondrick C, 2016, 30 C NEURAL INFORM P, V29
   Wang NN, 2018, NEUROCOMPUTING, V275, P50, DOI 10.1016/j.neucom.2017.05.013
   Wang YH, 2020, IEEE WINT CONF APPL, P1149, DOI [10.1109/WACV45572.2020.9093492, 10.1109/wacv45572.2020.9093492]
   Wang Z., 2006, SYNTHESIS LECT IMAGE, V1, P1, DOI DOI 10.1007/978-3-031-02238-8
   Wei W, 2016, PATTERN RECOGN, V49, P115, DOI 10.1016/j.patcog.2015.08.004
   Xie WC, 2018, MULTIMED TOOLS APPL, V77, P7565, DOI 10.1007/s11042-017-4661-6
   Xie WC, 2017, IEEE T MULTIMEDIA, V19, P279, DOI 10.1109/TMM.2016.2614429
   Xiong L, 2010, IMAGE VISION COMPUT, V28, P329, DOI 10.1016/j.imavis.2009.06.001
   YANG S, 2016, PROC CVPR IEEE, P5525, DOI DOI 10.1109/CVPR.2016.596
   Zhang H, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P100
   Zhi Xiong, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P136, DOI 10.1145/3372278.3390683
   Zhou YQ, 2017, INT CONF AFFECT, P370, DOI 10.1109/ACII.2017.8273626
NR 69
TC 2
Z9 2
U1 3
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2021
VL 80
IS 30
BP 36465
EP 36489
DI 10.1007/s11042-021-11525-4
EA SEP 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XI4QI
UT WOS:000693494700003
DA 2024-07-18
ER

PT J
AU Dong, BW
   Wang, RG
   Yang, J
   Xue, LX
AF Dong, Bowen
   Wang, Ronggui
   Yang, Juan
   Xue, Lixia
TI Multi-scale feature self-enhancement network for few-shot learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Few-shot learning; Multi-scale feature; Selective graph neural network;
   Meta-learner; Improved prototypes
AB The goal of few-shot learning(FSL) is to learn from a hand of labeled examples and quickly adapt to a new task. The traditional FSL models use the single-scale feature that does not have strong representative ability. Besides, some previous methods construct graph neural network to get better classifications, while they update nodes indiscriminately, which will result in intra-class information passing between inter-class nodes. In this paper, we propose a new method called Multi-scale Feature Self-enhancement Network(MFSN) for few-shot learning, which extracts multi-scale feature through a novel extractor, and then enhance the multiple features by the selective graph neural networks that can filter out the incorrect passings between nodes through a meta-learner. At last, classification is performed by measuring distances between the augmented unlabeled features and the improved prototypes computed from augmented labeled features. Comparing to the traditional method, our method improves 1-shot accuracy by 11.8% and improves 5-shot by 10.3% on MiniImagenet dataset. Experiments on MiniImagenet, Cifar-100, and Caltech-256 datasets show the effectiveness of the proposed model.
C1 [Dong, Bowen; Wang, Ronggui; Yang, Juan; Xue, Lixia] Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Peoples R China.
C3 Hefei University of Technology
RP Yang, J (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Peoples R China.
EM wangrgui@foxmail.com; yangjuan6985@163.com; xlxzzm@163.com
RI Lin, Kuan-Yu/JXM-6653-2024
FU National Natural Science Foundation of China [61672202]; State Key
   Program of NSFC-Shenzhen Joint Foundation [U1613217]
FX This work was supported by the National Natural Science Foundation of
   China (grant number 61672202) and State Key Program of NSFC-Shenzhen
   Joint Foundation (grant number U1613217).
CR Alfassy A, 2019, PROC CVPR IEEE, P6541, DOI 10.1109/CVPR.2019.00671
   [Anonymous], 2002, ADV NEURAL INF PROCE
   Benaim S., 2018, PROC NEURAL INF PROC, P2104
   Boney R, 2018, SEMISUPERVISED FEW S
   Chen MT, 2020, AAAI CONF ARTIF INTE, V34, P10559
   Chen ZT, 2019, IEEE T IMAGE PROCESS, V28, P4594, DOI 10.1109/TIP.2019.2910052
   Fink M., 2005, 2005 Advances in Neural Information Processing Systems, V17, P449
   Finn C, 2017, PR MACH LEARN RES, V70
   Garcia V., 2017, ARXIV PREPRINT ARXIV
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Han-Jia Ye, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8805, DOI 10.1109/CVPR42600.2020.00883
   Hariharan B, 2017, IEEE I CONF COMP VIS, P3037, DOI 10.1109/ICCV.2017.328
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Honari S, 2016, PROC CVPR IEEE, P5743, DOI 10.1109/CVPR.2016.619
   Jamal MA, 2019, PROC CVPR IEEE, P11711, DOI 10.1109/CVPR.2019.01199
   Keshari R, 2018, PROC CVPR IEEE, P9349, DOI 10.1109/CVPR.2018.00974
   Kim J, 2019, PROC CVPR IEEE, P11, DOI 10.1109/CVPR.2019.00010
   Koch G., 2015, ICML DEEP LEARNING W, V2
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Liu Y, 2018, INT C LEARN REPR
   Mehrotra A., 2017, ARXIV170308033
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Mishra N., 2017, ICLR
   Munkhdalai Tsendsuren, 2017, Proc Mach Learn Res, V70, P2554
   Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846
   Qiao LM, 2019, IEEE I CONF COMP VIS, P3602, DOI 10.1109/ICCV.2019.00370
   Ravi S., 2016, INT C LEARNING REPRE
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Snell J, 2017, ADV NEUR IN, V30
   Sun QR, 2019, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.2019.00049
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tremblay J, 2018, IEEE COMPUT SOC CONF, P1082, DOI 10.1109/CVPRW.2018.00143
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2017, ADV NEUR IN, V30
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Wang P, 2017, PROC CVPR IEEE, P6212, DOI 10.1109/CVPR.2017.658
   Wang X, 2019, PROC CVPR IEEE, P1831, DOI 10.1109/CVPR.2019.00193
   Yu M., 2018, ARXIV PREPRINT ARXIV
   Zamir AR, 2018, PROC CVPR IEEE, P3712, DOI 10.1109/CVPR.2018.00391
NR 40
TC 5
Z9 5
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 25
BP 33865
EP 33883
DI 10.1007/s11042-021-11205-3
EA AUG 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WK6LS
UT WOS:000690339900001
DA 2024-07-18
ER

PT J
AU Patel, SC
   Alsadoon, A
   Prasad, PWC
   Al-Khalil, AB
   Jerew, OD
AF Patel, Simran C.
   Alsadoon, Abeer
   Prasad, P. W. C.
   Al-Khalil, Ahmad B.
   Jerew, Oday D.
TI Multi-stage error control technique for improving 3DV transmission over
   OFDM wireless systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3DV; Security; PSNR; PAPR; SNR; BER; OFDM; Wireless systems; Error
   controlling; PLR
ID VIDEO TRANSMISSION; ALGORITHM
AB The transmission of the three-dimensional video and image over wireless channels always have random corruption occurrences and burst due to Orthogonal Frequency Division Multiplexing wireless systems' predictive coding structure. This paper aims to decrease multi-stage errors during three-dimensional video transmission to reduce the processing rate and increase Peak-Average-to-Power-Ratio. For the implementation and simulation, we have chosen four different datasets with 40 different three-dimensional videos. The proposed system consists of two techniques: the modulated entropy coding and adding guard interval to avoid ISI on the wireless channel during the three-dimensional video transmission process. The proposed method reduces the errors based on the multi-stage error control technique and improves the transmission process performance and video quality. The obtained results showed that the processing time, Bit Error Rate, and Peak-Average-to-Power-Ratio decreased noticeably by 20%, 40%, and 50%, respectively, compared to state-of-the-art solutions (i.e. less processing time and less error rate with high Peak-Signal-to-Noise-Ratio). Additionally, the Peak-Signal-to-Noise-Ratio has been increased by nearly 40% for the three-dimensional video transmission over the Orthogonal Frequency Division Multiplexing wireless channels.
C1 [Patel, Simran C.; Alsadoon, Abeer] Charles Sturt Univ CSU, Sch Comp & Math, Wagga Wagga, NSW, Australia.
   [Alsadoon, Abeer; Prasad, P. W. C.] Univ Western Sydney UWS, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Prasad, P. W. C.] Kent Inst Australia, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Jerew, Oday D.] Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
   [Al-Khalil, Ahmad B.] Univ Duhok, Dept Comp Sci, Coll Sci, Duhok, Krg, Iraq.
C3 Charles Sturt University; Western Sydney University; University of Duhok
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp & Math, Wagga Wagga, NSW, Australia.; Alsadoon, A (corresponding author), Univ Western Sydney UWS, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Kent Inst Australia, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021; Al-Khalil, Ahmad/AAS-7475-2020
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; Al-Khalil,
   Ahmad/0000-0002-4855-4147
CR Al-Moliki YM, 2020, IEEE ACCESS, V8, P125013, DOI 10.1109/ACCESS.2020.3007429
   Darwish SM, 2019, MULTIMED TOOLS APPL, V78, P19229, DOI 10.1007/s11042-019-7256-6
   Dharavathu K, 2020, INT J COMMUN SYST, V33, DOI 10.1002/dac.4369
   El-Bakary EM, 2019, MULTIMED TOOLS APPL, V78, P14173, DOI 10.1007/s11042-018-6765-z
   El-Bakary EM, 2019, MULTIMED TOOLS APPL, V78, P11337, DOI 10.1007/s11042-018-6464-9
   El-Bendary MAM, 2019, MULTIMED TOOLS APPL, V78, P16633, DOI 10.1007/s11042-018-6843-2
   El-Khamy SE, 2019, MULTIMED TOOLS APPL, V78, P34373, DOI 10.1007/s11042-019-08122-x
   El-Shafai W, 2019, J KING SAUD UNIV-COM, V31, P469, DOI 10.1016/j.jksuci.2018.02.007
   El-Shafai W, 2019, WIREL NETW, V25, P1619, DOI 10.1007/s11276-017-1618-7
   Hagras EAA, 2019, WIRELESS PERS COMMUN, V107, P729, DOI 10.1007/s11277-019-06297-y
   Li F, 2019, MULTIMED TOOLS APPL, V78, P26807, DOI 10.1007/s11042-019-07868-8
   Liang YQ, 2020, INTEGR COMPUT-AID E, V27, P417, DOI 10.3233/ICA-200641
   Liu Y, 2020, MULTIMED TOOLS APPL, V79, P17669, DOI 10.1007/s11042-020-08645-8
   Nancharla BK, 2020, 2020 5 INT C COMM EL, P1309, DOI DOI 10.1109/ICCES48766.2020.09138102
   Ramasamy P, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21070656
   Shafique A, 2018, EUR PHYS J PLUS, V133, DOI 10.1140/epjp/i2018-12138-3
   Vijayalakshmi M, 2020, ANALOG INTEGR CIRC S, V102, P145, DOI 10.1007/s10470-019-01475-1
   Wang JQ, 2020, IEEE T WIREL COMMUN, V19, P4, DOI 10.1109/TWC.2019.2933201
   Wang XY, 2021, OPT LASER TECHNOL, V138, DOI 10.1016/j.optlastec.2020.106837
   Wang ZP, 2019, IEEE ACCESS, V7, P126985, DOI 10.1109/ACCESS.2019.2939266
   Wang ZP, 2019, OPT COMMUN, V431, P229, DOI 10.1016/j.optcom.2018.09.045
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
NR 22
TC 0
Z9 0
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 25
BP 33799
EP 33825
DI 10.1007/s11042-021-11408-8
EA AUG 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WK6LS
UT WOS:000689522000002
DA 2024-07-18
ER

PT J
AU Bhateja, A
   Shrivastav, A
   Chaudhary, H
   Lall, B
   Kalra, PK
AF Bhateja, Aditi
   Shrivastav, Adarsh
   Chaudhary, Himanshu
   Lall, Brejesh
   Kalra, Prem K.
TI Depth analysis of kinect v2 sensor in different mediums
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kinect v2; Time-of-Flight; Field of View; Error Analysis; Error
   Compensation; Depth Entropy; Depth Sensor; RGB-D
ID CALIBRATION; ACCURACY
AB From the last few years, RGB-D cameras are widely used by researchers in various fields. Their reasonable cost and the ability to estimate distances at a high frame rate have made these sensors recommendable for applications in gaming accessories, robotics, computer vision, etc. In addition to color, these sensors also provide depth information. Aspects like the stability, accuracy and reliability of depth-sensing cameras like Kinect v2 must also be considered before using the device for applications like that of 3D space modelling. In this paper, an analysis of the error in the depth measurement as well as calculation of Depth Entropy given by Kinect v2 sensor in different mediums viz. air, glass and water has been done. We have validated our findings using the theories of optics. The findings from error analysis are used to make an error compensation model which can correct depth at each pixel of the image. The error analysis and error compensation model proposed herewith will help in improving the accuracy of present and future depth sensing devices.
C1 [Bhateja, Aditi; Shrivastav, Adarsh; Chaudhary, Himanshu; Lall, Brejesh; Kalra, Prem K.] Indian Inst Technol Delhi, Delhi, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Delhi
RP Bhateja, A (corresponding author), Indian Inst Technol Delhi, Delhi, India.
EM aditibhateja89@gmail.com; adarshsri11@gmail.com; himanshu2031@gmail.com;
   brejesh@ee.iitd.ac.in; pkalra@cse.iitd.ac.in
RI Zorzi, Michele/GQQ-2252-2022
OI Bhateja, Aditi/0000-0001-6537-8002
CR Andersen M. R., TECHNICAL REPORT ELE, V1
   Berger K., 2011, VISION MODELING VISU, P317
   Chiu WC, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.116
   CURCIO JA, 1951, J OPT SOC AM, V41, P302, DOI 10.1364/JOSA.41.000302
   Elaraby AF, 2018, 2018 IEEE 9TH ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON), P247, DOI 10.1109/IEMCON.2018.8615020
   Furntratt H, 2014, INT C MULTIMEDIA HUM, P124
   Gaber A, 2015, 2015 INTERNATIONAL CONFERENCE ON VIRTUAL REHABILITATION PROCEEDINGS (ICVR), P258, DOI 10.1109/ICVR.2015.7358577
   Gaffney M., 2011, Kinect/3D scanner calibration pattern
   Khoshelham K., 2011, ISPRS workshop laser scanning, V38, pW12
   Konolige K., 2011, Technical description of Kinect calibration
   LACHAT E, 2015, INT ARCH PHOTOGRAMM, P93, DOI [DOI 10.5194/ISPRSARCHIVES-XL-5-W4-93-2015, 10.5194/isprs-archives-xlii-3-w11-93-2020, DOI 10.5194/ISPRS-ARCHIVES-XLII-3-W11-93-2020]
   Lachat E, 2015, REMOTE SENS-BASEL, V7, P13070, DOI 10.3390/rs71013070
   Lee IJ, 2021, INTERACT LEARN ENVIR, V29, P688, DOI 10.1080/10494820.2019.1710851
   Li G, 2020, SIGNAL PROCESS-IMAGE, V84, DOI 10.1016/j.image.2020.115814
   Li J, 2014, PROC CVPR IEEE, P3374, DOI 10.1109/CVPR.2014.431
   Liu BH, 2020, IEEE ACCESS, V8, P41108, DOI 10.1109/ACCESS.2020.2977201
   Maimone A, 2011, INT SYM MIX AUGMENT
   Matyunin S, 2011, 3DTV CONF
   Pagliari D, 2015, SENSORS-BASEL, V15, P27569, DOI 10.3390/s151127569
   Raghuraman S., 2012, Proceedings of the 20th ACM international conference on Multimedia, MM '12, New York, NY, USA, P1481
   Ramamonjisoa M, 2019, IEEE INT CONF COMP V, P2109, DOI 10.1109/ICCVW.2019.00266
   Sarbolandi H, 2015, COMPUT VIS IMAGE UND, V139, P1, DOI 10.1016/j.cviu.2015.05.006
   Sassetti A, 2015, NUI BIOMETRICS WINDO
   Seewald LA, 2019, COMPUT VIS IMAGE UND, V178, P1, DOI 10.1016/j.cviu.2018.09.010
   Shifrin KS., 1998, Physical optics of ocean water
   Smisek J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1154, DOI 10.1109/ICCVW.2011.6130380
   Song XB, 2020, PROC CVPR IEEE, P5630, DOI 10.1109/CVPR42600.2020.00567
   Song XB, 2017, LECT NOTES COMPUT SC, V10114, P360, DOI 10.1007/978-3-319-54190-7_22
   Song XB, 2014, VISUAL COMPUT, V30, P855, DOI 10.1007/s00371-014-0965-y
   Stoyanov T., 2011, P EUROPEAN C MOBILE, P19
   Tseng C.-M., 2016, Proceedings of the Workshop on Electric Vehicle Systems, Data, and Applications p, P1
   Xie J, 2016, IEEE T IMAGE PROCESS, V25, P428, DOI 10.1109/TIP.2015.2501749
   Yang L, 2015, IEEE SENS J, V15, P4275, DOI 10.1109/JSEN.2015.2416651
   Zennaro S, 2015, IEEE INT CON MULTI
NR 34
TC 4
Z9 4
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 35775
EP 35800
DI 10.1007/s11042-021-11392-z
EA AUG 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000687926200004
DA 2024-07-18
ER

PT J
AU Wang, YB
   Yin, SB
   Basu, A
AF Wang, Yibin
   Yin, Shibai
   Basu, Anup
TI A multi-scale attentive recurrent network for image dehazing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encoder-decoder network; Image dehazing; Multi-scale fusion; Recurrent
   residual operation
ID SINGLE; TRANSMISSION; FRAMEWORK; REMOVAL
AB Image dehazing is a pre-processing step in computer vision tasks, that has attracted considerable attention from the research community. Existing CNN-based methods ignore haze-related priors and rarely use a coarse-to-fine scheme in a feed-forward architecture to remove haze due to increasing network depth and parameters. This results in sub-optimal dehazing results. To address these problems, a multi-scale attentive recurrent network is proposed for image dehazing, which consists of a haze attention map predicted network and a recurrent encoder-decoder network. First, by assuming that haze in an image is formed by multiple layers with different depths, the haze attention map predicted network is designed for generating the map with multiple stages via a multi-scale recurrent framework. Second, the haze attention map is viewed as the haze-related prior and guides the subsequent recurrent encoder-decoder network to be aware of haze concentration information. Finally, for leveraging the intermediate information and optimizing the dehazing result with less parameters and more robust features, the recurrent residual operations which pass the features of selected layers at the current time step to the corresponding layers at the next time step are applied in the recurrent encoder-decoder network for removing haze following a coarse-to-fine strategy. Experiments on synthetic and real images demonstrate that our method outperforms state-of-the-art methods considering both visual and quantitative evaluations. In addition, our method is also suitable for real-time processing.
C1 [Wang, Yibin] Sichuan Normal Univ, Dept Engn, Chengdu 610066, Peoples R China.
   [Yin, Shibai] Southwestern Univ Finance & Econ, Dept Econ Informat Engn, Chengdu 611130, Peoples R China.
   [Wang, Yibin; Yin, Shibai; Basu, Anup] Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada.
C3 Sichuan Normal University; Southwestern University of Finance &
   Economics - China; University of Alberta
RP Wang, YB (corresponding author), Sichuan Normal Univ, Dept Engn, Chengdu 610066, Peoples R China.; Wang, YB (corresponding author), Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada.
EM yibeen.wong@gmail.com; shibaiyin@swufe.edu.cn; basu@ualberta.ca
RI Yin, Shibai/KIK-4319-2024; xin, liang/JFS-5770-2023
FU National Natural Science Foundation of China [61502396]; Education
   Department Foundation of Sichuan Province [18ZB0484]; NSERC, Canada
FX This research was funded by National Natural Science Foundation of
   China: 61502396; the Education Department Foundation of Sichuan
   Province: 18ZB0484; and NSERC, Canada.
CR Alajarmeh A, 2018, INFORM SCIENCES, V436, P108, DOI 10.1016/j.ins.2018.01.009
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen Chun-Fu, 2018, ARXIV180703848
   Chen DD, 2019, IEEE WINT CONF APPL, P1375, DOI 10.1109/WACV.2019.00151
   [陈书贞 Chen Shuzhen], 2016, [自动化学报, Acta Automatica Sinica], V42, P455
   Chen YB, 2020, J CONTEMP CHINA, V29, P1, DOI [10.1080/10670564.2019.1621526, 10.1080/01932691.2020.1791172, 10.1007/s12652-020-02066-z]
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7435, DOI 10.1007/s10586-018-1772-4
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Chen YT, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9112316
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   Deng ZJ, 2019, IEEE I CONF COMP VIS, P2453, DOI 10.1109/ICCV.2019.00254
   Dong Y, 2020, AAAI CONF ARTIF INTE, V34, P10729
   Hernandez-Beltran JE, 2019, SWARM EVOL COMPUT, V44, P49, DOI 10.1016/j.swevo.2018.11.008
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Galdran A, 2018, SIGNAL PROCESS, V149, P135, DOI 10.1016/j.sigpro.2018.03.008
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Guan B, 2019, PATTERN RECOGN LETT, V125, P521, DOI 10.1016/j.patrec.2019.06.015
   Haoran Xu, 2012, 2012 IEEE International Conference on Information Science and Technology, P663, DOI 10.1109/ICIST.2012.6221729
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jia H., 2020, AAAI, P11908
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li JJ, 2018, IEEE ACCESS, V6, P26831, DOI 10.1109/ACCESS.2018.2833888
   Ling ZG, 2019, MULTIMED TOOLS APPL, V78, P213, DOI 10.1007/s11042-018-5687-0
   Liu RS, 2019, IEEE T NEUR NET LEAR, V30, P2973, DOI 10.1109/TNNLS.2018.2862631
   Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741
   Liu Y, 2019, IEEE I CONF COMP VIS, P2492, DOI 10.1109/ICCV.2019.00258
   Liu Y, 2019, IEEE ACCESS, V7, P15722, DOI 10.1109/ACCESS.2019.2894525
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Qian R, 2018, PROC CVPR IEEE, P2482, DOI 10.1109/CVPR.2018.00263
   Qu YY, 2019, PROC CVPR IEEE, P8152, DOI 10.1109/CVPR.2019.00835
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tao X, 2018, PROC CVPR IEEE, P8174, DOI 10.1109/CVPR.2018.00853
   Wang JB, 2015, NEUROCOMPUTING, V149, P718, DOI 10.1016/j.neucom.2014.08.005
   Wang WG, 2019, PROC CVPR IEEE, P1448, DOI 10.1109/CVPR.2019.00154
   Yang D, 2018, LECT NOTES COMPUT SC, V11211, P729, DOI 10.1007/978-3-030-01234-2_43
   Yin SB, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107255
   Yin SB, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21111123
   Yu F, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/4047957
   Yu F, 2019, NEUROCOMPUTING, V350, P108, DOI 10.1016/j.neucom.2019.03.053
   Yu T, 2019, IEEE ACCESS, V7, P114619, DOI 10.1109/ACCESS.2019.2936049
   Zhang H, 2018, IEEE COMPUT SOC CONF, P1015, DOI 10.1109/CVPRW.2018.00135
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhang JM, 2020, IEEE ACCESS, V8, P29742, DOI 10.1109/ACCESS.2020.2972338
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhu HY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1234
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 58
TC 3
Z9 3
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32539
EP 32565
DI 10.1007/s11042-021-11209-z
EA JUL 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000679633200001
DA 2024-07-18
ER

PT J
AU Mizdos, T
   Barkowsky, M
   Uhrina, M
   Pocta, P
AF Mizdos, Tomas
   Barkowsky, Marcus
   Uhrina, Miroslav
   Pocta, Peter
TI How to reuse existing annotated image quality datasets to enlarge
   available training data with new distortion types
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; Image quality; JPEG; QoE; Quality mapping; Subjective tests; VQM
AB There is a continuing demand for objective measures that predict perceived media quality. Researchers are developing new methods for mapping technical parameters of digital media to the perceived quality. It is quite common to use machine learning algorithms for these purposes especially deep learning algorithms, which need large amounts of data for training. In this paper, we aim towards getting more training data with recent types of distortions. Instead of doing expensive subjective experiments, we evaluate the reuse of previously published, well-known image datasets with subjective annotation. In this contribution, the procedure of mapping Mean Opinion Scores (MOS) from an already published subjectively annotated dataset with older codecs to new codecs is presented. In particular, we map from Joint Photographic Experts Group (JPEG) distortions to newer High Efficiency Video Coding (HEVC) distortions. We have used values of three different objective methods as a connection between these two different distortion types. In order to investigate the significance of our approach, subjective verification tests were designed and conducted. The design goals led to two types of experiments, i.e. Pair Comparison (PC) test and Absolute Category Rating (ACR) test, in which 40 participants provided their opinion. Results of the subjective experiments indicate that it may be possible to use information gained from older datasets to describe the perceived quality of more recent compression algorithms.
C1 [Mizdos, Tomas; Uhrina, Miroslav; Pocta, Peter] Univ Zilina, Fac Elect Engn & Informat Technol, Univ 8215-1, Zilina 01026, Slovakia.
   [Barkowsky, Marcus] Deggendorf Inst Technol, Fac Comp Sci, Dieter Gorlitz Pl 1, D-94469 Deggendorf, Germany.
C3 University of Zilina
RP Mizdos, T (corresponding author), Univ Zilina, Fac Elect Engn & Informat Technol, Univ 8215-1, Zilina 01026, Slovakia.
EM tomas.mizdos@feit.uniza.sk; marcus.barkowsky@th-deg.de;
   miroslav.uhrina@feit.uniza.sk; peter.pocta@feit.uniza.sk
RI Uhrina, Miroslav/GPG-1668-2022; Pocta, Peter/A-6228-2010
OI Uhrina, Miroslav/0000-0002-5983-6019; Pocta, Peter/0000-0001-6791-1325
CR Abdellaoui M, 2020, TRAIT SIGNAL, V37, P37, DOI 10.18280/ts.370105
   Ahn S., 2018, NO REFERENCE VIDEO Q
   Alizadeh M, 2018, 2018 8TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P130, DOI 10.1109/ICCKE.2018.8566395
   [Anonymous], 2015, HM REFERENCE SOFTWAR
   [Anonymous], 2008, SUBJ VID QUAL ASS ME
   [Anonymous], 2008, VQEG MULTIMEDIA TEST
   [Anonymous], 2000, SCHAUMS OUTLINE THEO
   [Anonymous], 2012, Methods, metrics and procedures for statistical evaluation, qualification and comparison of objective quality prediction models
   [Anonymous], 2012, METHODOLOGY SUBJECTI
   Bagui K., 2017, INT MATH FORUM, V12, P368
   Behroozi H, 2019, 5 IR C SIGN PROC INT
   Berument H, 2002, APPL ECON, V34, P1645, DOI 10.1080/00036840110115118
   Hou R, 2020, SIGNAL PROCESS-IMAGE, V83, DOI 10.1016/j.image.2020.115782
   Katsigiannis S, 2018, UNDERSTANDING USER E, V3
   Mantiuk RK, 2012, COMPUT GRAPH FORUM, V31, P2478, DOI 10.1111/j.1467-8659.2012.03188.x
   Mohan J, 2018, DYNAMIC SUMMARIZATIO, V6
   Multimedia signal processing group, 2013, VID QUAL MEAS TOOL
   Ninassi A, 2006, PROC SPIE, V6057, DOI 10.1117/12.650780
   Pinson M, 2003, P SOC PHOTO-OPT INS, V5150, P583, DOI 10.1117/12.509909
   Pitrey Y, 2011, ALIGNINGSUBJECTIVE T
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Sheikh H.R., 2006, LIVE image quality assessment database release 2
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Thurstone LL, 1927, AM J PSYCHOL, V38, P368, DOI 10.2307/1415006
   Varga D, 2019, SIGNAL IMAGE VIDEO P, V13, P1569, DOI 10.1007/s11760-019-01510-8
   Vranjes M, 2013, SIGNAL PROCESS-IMAGE, V28, P1, DOI 10.1016/j.image.2012.10.003
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Wang CF, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P224, DOI 10.1109/ICISCE.2017.56
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   You JY, 2019, IEEE IMAGE PROC, P2349, DOI [10.1109/icip.2019.8803395, 10.1109/ICIP.2019.8803395]
   Zhang ZP, 2019, IEEE ACM T COMPUT BI, V16, P407, DOI 10.1109/TCBB.2017.2704587
NR 32
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 28137
EP 28159
DI 10.1007/s11042-021-10679-5
EA MAY 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000656384900002
DA 2024-07-18
ER

PT J
AU Aamir, N
   Mir, J
   Nizami, IF
   Shaukat, F
   Majid, M
AF Aamir, Naima
   Mir, Junaid
   Nizami, Imran Fareed
   Shaukat, Furqan
   Majid, Muhammad
TI HDR-BVQM: High dynamic range blind video quality model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High dynamic range videos; Subjective evaluation; Video quality
   assessment; HDR video quality assessment
ID IMAGE
AB Considerable progress has been made toward developing standard dynamic range (SDR) blind video quality assessment (BVQA) models that do not require any baseline reference for quality prediction. However, there is no such method for the high dynamic range (HDR) content. Unlike SDR video, HDR video represents a high-fidelity representation of the real-world scene by preserving the wide luminance range and color gamut. Therefore, SDR BVQA models are not suitable for HDR BVQA. Towards ameliorating this, a first-of-its-kind BVQA model for HDR content is presented in this work. The proposed HDR blind video quality model (HDR-BVQM) is inspired by the spatio-temporal natural scene statistics model, previously employed in SDR blind quality assessment metrics. To build our proposed model, we first develop a comprehensive subjective HDR video quality dataset, including 228 distorted videos generated through three different (H.264, HEVC, packet drop) distortion processes from 19 pristine HDR videos. The developed dataset is then used to extract HDR relevant features, which vary in different distortion types, to train and test the proposed HDR-BVQM. The features are based on the pointwise, pairwise log-derivative, and motion coherence based statistics. Finally, detailed validation and performance comparison is performed with full-reference HDR and no-reference SDR quality assessment methods. The results reveal that the quality prediction by HDR-BVQM correlates with the human judgment of quality.
C1 [Aamir, Naima; Mir, Junaid] Univ Engn & Technol, Dept Elect Engn, Taxila 47050, Pakistan.
   [Nizami, Imran Fareed] Bahria Univ, Dept Elect Engn, Islamabad, Pakistan.
   [Shaukat, Furqan] Univ Chakwal, Dept Elect Engn, Chakwal, Pakistan.
   [Majid, Muhammad] Univ Engn & Technol, Dept Compute Engn, Taxila 47050, Pakistan.
C3 University of Engineering & Technology Taxila; University of Engineering
   & Technology Taxila
RP Mir, J (corresponding author), Univ Engn & Technol, Dept Elect Engn, Taxila 47050, Pakistan.
EM junaid.mir@uettaxila.edu.pk
RI Majid, Muhammad/Z-5667-2019; Shaukat, Furqan/HLV-9526-2023; Shoukat,
   Furqan/Y-9499-2019
OI Majid, Muhammad/0000-0003-3662-2525; Shaukat,
   Furqan/0000-0003-1591-6380; Shoukat, Furqan/0000-0003-1591-6380
FU project entitled "Brain Activity Analysis in response to High Dynamic
   Range content using Electroencephalography" - Higher Education
   Commission (HEC) of Pakistan [21-1951/SRGP/RD/HEC/2018]
FX This work was supported by the project entitled "Brain Activity Analysis
   in response to High Dynamic Range content using Electroencephalography"
   funded by the Higher Education Commission (HEC) of Pakistan under the
   "Start-Up Research Grant Program" (21-1951/SRGP/R&D/HEC/2018).
CR [Anonymous], 2008, P910 ITUT, P2
   [Anonymous], 2018, RECOMMENDATION ITU R
   AYDIN TO, 2010, ACM T GRAPHIC, V29, P1
   Aydin TO, 2008, PROC SPIE, V6806, DOI 10.1117/12.765095
   Aydin TO, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360668
   Ballestad Anders, 2019, Information Display, V35, P16
   Bampis CG, 2017, IEEE SIGNAL PROC LET, V24, P1333, DOI 10.1109/LSP.2017.2726542
   Boitard R, 2015, IEEE CONSUM ELECTR M, V4, P72, DOI 10.1109/MCE.2015.2463294
   Bong DBL, 2015, MULTIMED TOOLS APPL, V74, P7355, DOI 10.1007/s11042-014-1983-5
   Cadík M, 2011, PROC SPIE, V7865, DOI 10.1117/12.878875
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   Fan Q, 2019, MULTIMED TOOLS APPL, V78, P31019, DOI 10.1007/s11042-017-4848-x
   Fraunhofer HHI, H265HEVC REFERENCE S
   Froehlich J, 2014, PROC SPIE, V9023, DOI 10.1117/12.2040003
   GPy, 2012, Technical Report
   Hanhart P, 2015, PROC SPIE, V9599, DOI 10.1117/12.2193832
   Karsten Suehring, H264AVC REFERENCE SO
   Kulupana G, 2016, IEEE INT C CONS EL A, P1
   Kundu D, 2016, CONF REC ASILOMAR C, P1847, DOI 10.1109/ACSSC.2016.7869704
   Lasserre S, 2013, JCTVCP0228 ISOIEC JT
   Loh WT, 2018, MULTIMED TOOLS APPL, V77, P30791, DOI 10.1007/s11042-018-6107-1
   Mir J, 2016, 2016 IEEE INT C CONS, P1
   Mir J, 2019, ARAB J SCI ENG, V44, P2427, DOI 10.1007/s13369-018-3583-6
   Mittal A, 2016, IEEE T IMAGE PROCESS, V25, P289, DOI 10.1109/TIP.2015.2502725
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Mukherjee R, 2016, SIGNAL PROCESS-IMAGE, V47, P426, DOI 10.1016/j.image.2016.08.001
   Narwaria M, 2015, SIGNAL PROCESS-IMAGE, V35, P46, DOI 10.1016/j.image.2015.04.009
   Narwaria M, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.1.010501
   Nasiopoulos P, 2018, ARXIV PREPRINT ARXIV
   Pan XF, 2018, J VIS COMMUN IMAGE R, V57, P76, DOI 10.1016/j.jvcir.2018.10.016
   Saad MA, 2014, IEEE T IMAGE PROCESS, V23, P1352, DOI 10.1109/TIP.2014.2299154
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   SHARIFI K, 1995, IEEE T CIRC SYST VID, V5, P52, DOI 10.1109/76.350779
   Soong HC, 2017, 2017 IEEE 13TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA), P232, DOI 10.1109/CSPA.2017.8064957
   Soundararajan R, 2013, IEEE T CIRC SYST VID, V23, P684, DOI 10.1109/TCSVT.2012.2214933
   2000, VQEG M
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang Y, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.043025
NR 40
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27701
EP 27715
DI 10.1007/s11042-021-11040-6
EA MAY 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000653019500001
DA 2024-07-18
ER

PT J
AU Garai, A
   Biswas, S
   Mandal, S
   Chaudhuri, BB
AF Garai, Arpan
   Biswas, Samit
   Mandal, Sekhar
   Chaudhuri, Bidyut. B.
TI Dewarping of document images: A semi-CNN based approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dewarping; Document image processing; Convolutional neural networks;
   Distortion rectification in Document
ID SKEW DETECTION; GEOMETRIC RECTIFICATION; TEXT; EFFICIENT
AB The camera-captured digital documents may be often distorted and warped due to various document surfaces or camera angles. Also, the OCR systems find difficulty in reading such distorted images. In this paper, a framework for dewarping the images based on estimating the change of pixel-positions due to the unevenness of the surface is proposed. Here, at first, the changes of pixel-positions are measured using the warping factors, which depend on warping position and control parameters. The warping control parameters are calculated from the top and bottom text lines of the document. The warping positional parameters are estimated using the convolution neural network (CNN) that needs many images for training. Capturing such a large number of images is very difficult. For this purpose, we synthetically generated a warped document image dataset. The proposed dewarping technique works for both alphabetic and alpha-syllabary scripts. The results on Bangla (alphasyllabary) and English (alphabetic) are encouraging.
C1 [Garai, Arpan; Biswas, Samit; Mandal, Sekhar] Indian Inst Engn Sci & Technol, Dept Comp Sci & Technol, Hawrah 711103, W Bengal, India.
   [Chaudhuri, Bidyut. B.] Techno India Univ, Kolkata, India.
   [Chaudhuri, Bidyut. B.] Indian Stat Inst, Comp Vis & Pattern Recognit Unit, Kolkata, India.
C3 Indian Institute of Engineering Science Technology Shibpur (IIEST);
   Indian Statistical Institute; Indian Statistical Institute Kolkata
RP Garai, A (corresponding author), Indian Inst Engn Sci & Technol, Dept Comp Sci & Technol, Hawrah 711103, W Bengal, India.
EM arpangarai@gmail.com; samit@cs.iiests.ac.in; sekhar@cs.iiests.ac.in;
   bidyutbaranchaudhuri@gmail.com
RI Biswas, Samit/T-6889-2019; Garai, Arpan/AFI-9618-2022
OI Biswas, Samit/0000-0001-9379-4484; Garai, Arpan/0000-0002-8233-3591
CR [Anonymous], 2018, 2018 INT C CONTENT B
   Avanindra, 1997, IEEE T IMAGE PROCESS, V6, P344
   Brown MS, 2004, IEEE T PATTERN ANAL, V26, P1295, DOI 10.1109/TPAMI.2004.87
   Bukhari Syed Saqib, 2012, Camera-Based Document Analysis and Recognition. 4th International Workshop, CBDAR 2011. Revised Selected Papers, P164, DOI 10.1007/978-3-642-29364-1_13
   Bukhari Syed Saqib, 2012, Camera-Based Document Analysis and Recognition. 4th International Workshop, CBDAR 2011. Revised Selected Papers, P126, DOI 10.1007/978-3-642-29364-1_10
   BUKHARI S.S., 2009, P 3 INT WORKSHOP CAM, P34
   Cao HG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P228, DOI 10.1109/ICCV.2003.1238346
   Das S, 2019, MULTIMED TOOLS APPL, V78, P27449, DOI 10.1007/s11042-019-07857-x
   Diwakar M, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101754
   Diwakar M, 2018, IET IMAGE PROCESS, V12, P708, DOI 10.1049/iet-ipr.2017.0639
   Egozi A, 2011, PATTERN RECOGN LETT, V32, P1912, DOI 10.1016/j.patrec.2011.07.004
   El Bahi H, 2019, MULTIMED TOOLS APPL, V78, P26453, DOI 10.1007/s11042-019-07855-z
   Ezaki H, 2005, PROC INT CONF DOC, P302, DOI 10.1109/ICDAR.2005.87
   Fan HJ, 2010, INT J DOC ANAL RECOG, V13, P261, DOI 10.1007/s10032-010-0119-3
   Fu B., 2007, 2 INT WORKSH CAM BAS
   Fu B, 2012, INT J IMAGE GRAPH, V12, DOI 10.1142/S0219467812500027
   Garai Arpan, 2020, Computational Intelligence in Pattern Recognition. Proceedings of CIPR 2019. Advances in Intelligent Systems and Computing (AISC 999), P647, DOI 10.1007/978-981-13-9042-5_55
   Garai A, 2021, PATTERN RECOGN, V109, DOI 10.1016/j.patcog.2020.107621
   Garai A, 2020, IET IMAGE PROCESS, V14, P74, DOI 10.1049/iet-ipr.2019.0831
   Garai A, 2017, 2017 NINTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION (ICAPR), P94
   Gatos B, 2007, PROC INT CONF DOC, P989
   Guan YP, 2012, IET IMAGE PROCESS, V6, P761, DOI 10.1049/iet-ipr.2011.0236
   He Y, 2013, PROC INT CONF DOC, P403, DOI 10.1109/ICDAR.2013.88
   Jiang HF, 1997, PATTERN RECOGN LETT, V18, P675, DOI 10.1016/S0167-8655(97)00032-9
   Kil T, 2017, PROC INT CONF DOC, P865, DOI 10.1109/ICDAR.2017.146
   Kim BS, 2015, PATTERN RECOGN, V48, P3600, DOI 10.1016/j.patcog.2015.04.026
   Li ST, 2007, PATTERN RECOGN LETT, V28, P555, DOI 10.1016/j.patrec.2006.10.002
   Liang J, 2008, IEEE T PATTERN ANAL, V30, P591, DOI 10.1109/TPAMI.2007.70724
   Liu CS, 2015, INT J DOC ANAL RECOG, V18, P111, DOI 10.1007/s10032-014-0233-8
   Liu H, 2008, PATTERN RECOGN LETT, V29, P1893, DOI 10.1016/j.patrec.2008.06.008
   Liu XY, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107576
   Lu SJ, 2006, INT C PATT RECOG, P971
   Lu SJ, 2005, IMAGE VISION COMPUT, V23, P541, DOI 10.1016/j.imavis.2005.01.003
   Lu Y, 2003, PATTERN RECOGN LETT, V24, P2315, DOI 10.1016/S0167-8655(03)00057-6
   Masalovitch A, 2007, USAGE CONTINUOUS SKE
   Meng GF, 2018, LECT NOTES COMPUT SC, V11220, P180, DOI 10.1007/978-3-030-01270-0_11
   Meng GF, 2012, IEEE T PATTERN ANAL, V34, P707, DOI 10.1109/TPAMI.2011.151
   Mohammad K, 2021, MULTIMED TOOLS APPL, V80, P2177, DOI 10.1007/s11042-020-09737-1
   Sahare P, 2017, IETE TECH REV, V34, P144, DOI 10.1080/02564602.2016.1160805
   Sanasam I, 2020, MULTIMED TOOLS APPL, V79, P30135, DOI 10.1007/s11042-020-09416-1
   Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2
   Shafait F., 2007, 2nd Int. Workshop on Camera-Based Document Analysis and Recognition, P181
   Shafii M, 2015, INT J DOC ANAL RECOG, V18, P59, DOI 10.1007/s10032-014-0230-y
   Stamatopoulos N, 2012, IET IMAGE PROCESS, V6, P738, DOI 10.1049/iet-ipr.2011.0208
   Stamatopoulos N, 2011, IEEE T IMAGE PROCESS, V20, P910, DOI 10.1109/TIP.2010.2080280
   Tian YD, 2011, PROC CVPR IEEE, P377, DOI 10.1109/CVPR.2011.5995540
   Tsoi YC, 2004, PROC CVPR IEEE, P240
   Ulges A, 2005, PROC INT CONF DOC, P1001, DOI 10.1109/ICDAR.2005.90
   Wagdy M, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCOINS)
   Wolberg G., 1989, Visual Computer, V5, P95, DOI 10.1007/BF01901485
   Wu EH, 2003, VISUAL COMPUT, V19, P319, DOI 10.1007/s00371-002-0183-x
   Xuejing Dai, 2010, 2010 5th International Conference on Computer Science & Education (ICCSE 2010), P1373, DOI 10.1109/ICCSE.2010.5593717
   Yamashita A, 2004, INT C PATT RECOG, P482, DOI 10.1109/ICPR.2004.1334171
   Yang P, 2017, IET IMAGE PROCESS, V11, P841, DOI 10.1049/iet-ipr.2016.0973
   You S, 2018, IEEE T PATTERN ANAL, V40, P505, DOI 10.1109/TPAMI.2017.2675980
   Yousef M, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107482
   Yu Zhang, 2009, Proceedings of the SPIE - The International Society for Optical Engineering, V7247, DOI 10.1117/12.805424
   Zhang L, 2006, INT C PATT RECOG, P642
NR 58
TC 2
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 36009
EP 36032
DI 10.1007/s11042-021-10507-w
EA MAY 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000652455300007
DA 2024-07-18
ER

PT J
AU Breves, P
   Dodel, N
AF Breves, Priska
   Dodel, Nicola
TI The influence of cybersickness and the media devices' mobility on the
   persuasive effects of 360° commercials
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Immersive advertising; Spatial presence; Cybersickness; Advertising
   effectiveness; Virtual reality
ID VIRTUAL-REALITY; IMMERSIVE TECHNOLOGY; IMPACT; KNOWLEDGE; MODEL;
   TELEPRESENCE; EXPERIENCE; ENJOYMENT; VALIDITY; OUTCOMES
AB With the rise of immersive media, advertisers have started to use 360 degrees commercials to engage and persuade consumers. Two experiments were conducted to address research gaps and to validate the positive impact of 360 degrees commercials in realistic settings. The first study (N = 62) compared the effects of 360 degrees commercials using either a mobile cardboard head-mounted display (HMD) or a laptop. This experiment was conducted in the participants' living rooms and incorporated individual feelings of cybersickness as a moderator. The participants who experienced the 360 degrees commercial with the HMD reported higher spatial presence and product evaluation, but their purchase intentions were only increased when their reported cybersickness was low. The second experiment (N = 197) was conducted online and analyzed the impact of 360 degrees commercials that were experienced with mobile (smartphone/tablet) or static (laptop/desktop) devices instead of HMDs. The positive effects of omnidirectional videos were stronger when participants used mobile devices.
C1 [Breves, Priska; Dodel, Nicola] Univ Wurzburg, Dept Media & Business Commun, Oswald Kuelpe Weg 82, D-97074 Wurzburg, Germany.
C3 University of Wurzburg
RP Breves, P (corresponding author), Univ Wurzburg, Dept Media & Business Commun, Oswald Kuelpe Weg 82, D-97074 Wurzburg, Germany.
EM priska.breves@uni-wuerzburg.de; nicola.dodel@stud-mail.uni-wuerzburg.de
FU Projekt DEAL
FX Open Access funding enabled and organized by Projekt DEAL
CR AAKER DA, 1985, J MARKETING, V49, P47, DOI 10.2307/1251564
   Ansons Tamara., 2011, Handbook of Research on Digital Media and Advertising: User Generated Content Consumption, P109, DOI [10.4018/978-1-60566-792-8.ch005, DOI 10.4018/978-1-60566-792-8.CH005]
   Bai, 2020, FAD FUTURE
   Barnes S., 2016, UNDERSTANDING VIRTUA, DOI DOI 10.2139/SSRN.2909100
   Barreda-Angeles M., 2020, COMP POL EVAL, P1, DOI [DOI 10.1101/2020.12.09.20246447, 10.1080/03637751.2020.1803496]
   Beer C., 2018, IS 2018 YEAR VR COME
   Behm-Morawitz E, 2013, COMPUT HUM BEHAV, V29, P119, DOI 10.1016/j.chb.2012.07.023
   Berger, 2017, 25 EUROPEAN C INFORM
   Biocca F, 2003, PRESENCE-VIRTUAL AUG, V12, P456, DOI 10.1162/105474603322761270
   Bracken CC, 2005, MEDIA PSYCHOL, V7, P191, DOI 10.1207/S1532785XMEP0702_4
   Breves P, 2021, COMPUT HUM BEHAV, V115, DOI 10.1016/j.chb.2020.106606
   Breves P, 2020, NONPROF VOLUNT SEC Q, V49, P1015, DOI 10.1177/0899764020903101
   Breves P, 2020, ENVIRON COMMUN, V14, P332, DOI 10.1080/17524032.2019.1665566
   Breves P, 2019, INT J ADVERT, V38, P1264, DOI 10.1080/02650487.2019.1622326
   Cauberghe V, 2011, INT J ADVERT, V30, P641, DOI 10.2501/IJA-30-4-641-663
   Choi Y.K., 2001, J INTERACTIVE ADVERT, V2, P19, DOI [10.1080/15252019.2001.10722055, DOI 10.1080/15252019.2001.10722055]
   Choi YK, 2014, J BUS RES, V67, P2164, DOI 10.1016/j.jbusres.2014.04.026
   Csikszentmihalyi M, 1997, FINDING FLOW PSYCHOL, DOI 10.5860/choice.35-1828
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Daugherty, 2005, EFFECTS 3 D VISUALIZ
   DAVIS S, 2014, P INT C INFORM SYSTE
   De Gauquier L, 2019, VIRTUAL REAL-LONDON, V23, P235, DOI 10.1007/s10055-018-0344-5
   Debbabi S, 2013, RECH APPL MARKET-ENG, V28, P3, DOI 10.1177/2051570713487480
   Debbabi S, 2010, J MARKET MANAG, V26, P967, DOI 10.1080/02672570903498819
   Draper JV, 1998, HUM FACTORS, V40, P354, DOI 10.1518/001872098779591386
   Ducoffe R.H., 1995, Journal of Current Issues & Research in Advertising, V17, P1, DOI [DOI 10.1080/10641734.1995.10505022, 10.1080/10641734.1995.10505022]
   Ducoffe RH, 1996, J ADVERTISING RES, V36, P21
   Feng Y, 2019, J ADVERTISING, V48, P137, DOI 10.1080/00913367.2019.1585305
   Flavián C, 2019, J BUS RES, V100, P547, DOI 10.1016/j.jbusres.2018.10.050
   FORGAS JP, 1995, PSYCHOL BULL, V117, P39, DOI 10.1037/0033-2909.117.1.39
   FRIESTAD M, 1994, J CONSUM RES, V21, P1, DOI 10.1086/209380
   Gersak G, 2020, MULTIMED TOOLS APPL, V79, P14491, DOI 10.1007/s11042-018-6969-2
   Gonçalves G, 2020, MULTIMED TOOLS APPL, V79, P22905, DOI 10.1007/s11042-020-09026-x
   Grigorovici D, 2003, EMERG COMMUNICAT, V5, P191
   Grigorovici D.M., 2004, Journal of Interactive Advertising, V5, P22, DOI [10.1080/15252019.2004.10722091, DOI 10.1080/15252019.2004.10722091]
   Grudzewski F, 2018, ECON BUS REV-POL, V4, P36, DOI 10.18559/ebr.2018.3.4
   Hartmann T., 2010, Immersed in media: Telepresence in everyday life, P137
   Hartmann T, 2016, J MEDIA PSYCHOL-GER, V28, P1, DOI 10.1027/1864-1105/a000137
   Hayes A. F., 2013, Introduction to mediation, moderation, and conditional process analysis: a regression -based approach
   HOPKINS C.D., 2004, MARKETING THEOR, V4, P137, DOI DOI 10.1177/1470593104044090
   Israel K, 2019, LECT NOTES COMPUT SC, V11588, P206, DOI 10.1007/978-3-030-22335-9_14
   KATZ E, 1962, PUBLIC OPIN QUART, V26, P377, DOI 10.1086/267111
   Kemp S., 2018, Digital in 2018: World's internet users pass the 4 billiom mark
   Kim D, 2019, COMPUT HUM BEHAV, V93, P346, DOI 10.1016/j.chb.2018.12.040
   Kim T., 1997, Journal of Computer-Mediated Communication, V3, P2, DOI DOI 10.1111/J.1083-6101.1997.TB00073.X
   Klein LR, 2003, J INTERACT MARK, V17, P41, DOI 10.1002/dir.10046
   König L, 2019, INT J EDUC TECHNOL H, V16, DOI 10.1186/s41239-019-0132-7
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lang, 2020, SONY ANNOUNCES
   Lanier M, 2019, COMPUT HUM BEHAV, V100, P70, DOI 10.1016/j.chb.2019.06.015
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   LEE YJ, 2020, CONSUMER RESPONSE VI
   Li HR, 2002, J ADVERTISING, V31, P43, DOI 10.1080/00913367.2002.10673675
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   McCauley M. E., 1992, Presence: Teleoperators & Virtual Environments, V1, P311, DOI DOI 10.1162/PRES.1992.1.3.311
   Nah FFH, 2011, MIS QUART, V35, P731
   Narciso D, 2020, ACM T APPL PERCEPT, V17, DOI 10.1145/3380903
   Nicovich S., 2005, Journal of Interactive Advertising, V6, P29, DOI DOI 10.1080/15252019.2005.10722105
   Oculus.com, 2018, OCULUS GO
   Oh J., 2018, Journal of Interactive Advertising, V18, P110, DOI DOI 10.1080/15252019.2018.1491812
   Parsons TD, 2008, J BEHAV THER EXP PSY, V39, P250, DOI 10.1016/j.jbtep.2007.07.007
   Peters J., 2019, ALEXAS VOICE CAN NOW
   Rauschnabel P. A., 2020, AUGMENTED REALITY VI
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Roe BE, 2009, AM J AGR ECON, V91, P1266, DOI 10.1111/j.1467-8276.2009.01295.x
   Roettl J, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0200724
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Shafer DM, 2019, GAMES HEALTH J, V8, P15, DOI 10.1089/g4h.2017.0190
   Slater Mel, 2003, Presence connect, V3, P1, DOI DOI 10.3389/FNINS.2019.01409
   Spears N., 2004, Journal of Current Issues Research in Advertising, V26, P53, DOI DOI 10.1080/10641734.2004.10505164
   Steckler A, 2008, AM J PUBLIC HEALTH, V98, P9, DOI 10.2105/AJPH.2007.126847
   Steinicke, 2016, EGVE 2016 INT C ART
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Stoffregen, 2020, CYBERSICKNESS VIRTUA
   Suh A, 2018, COMPUT HUM BEHAV, V86, P77, DOI 10.1016/j.chb.2018.04.019
   Terlutter R, 2016, MEDIA PSYCHOL, V19, P505, DOI 10.1080/15213269.2016.1142377
   Van Damme K, 2019, JOURNALISM STUD, V20, P2053, DOI 10.1080/1461670X.2018.1561208
   Van Kerrebroeck H, 2017, VIRTUAL REAL-LONDON, V21, P177, DOI 10.1007/s10055-017-0306-3
   Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540
   Vorderer P, 2004, COMMUN THEOR, V14, P388, DOI 10.1093/ct/14.4.388
   Waiguny MKJ, 2014, J CONSUM POLICY, V37, P257, DOI 10.1007/s10603-013-9227-z
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
   Wu DY, 2018, COMMUN RES REP, V35, P434, DOI 10.1080/08824096.2018.1525349
   Yildirim C, 2020, VIRTUAL REAL-LONDON, V24, P231, DOI 10.1007/s10055-019-00401-0
   Yim MYC, 2012, J ADVERTISING, V41, P113, DOI 10.2753/JOA0091-3367410208
   Yoo SC, 2018, NONPROFIT MANAG LEAD, V29, P11, DOI 10.1002/nml.21315
   YouTube.com, 2016, BAHLSEN 360 GRAD EXP
   YouTube.com, 2015, BOURSIN SENSORIUM 36
NR 88
TC 3
Z9 3
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27299
EP 27322
DI 10.1007/s11042-021-11057-x
EA MAY 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000651346700002
OA hybrid
DA 2024-07-18
ER

PT J
AU Bonifazi, G
   Corradini, E
   Ursino, D
   Virgili, L
   Anceschi, E
   De Donato, MC
AF Bonifazi, Gianluca
   Corradini, Enrico
   Ursino, Domenico
   Virgili, Luca
   Anceschi, Emiliano
   De Donato, Massimo Callisto
TI A machine learning based sentient multimedia framework to increase
   safety at work
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Safety at work; Machine learning; Industry 4; 0; Sentient multimedia
   systems; Internet of things; Fall detection; Decision trees
ID FALL-DETECTION; IMPLEMENTATION; ACCELEROMETER; SYSTEM
AB In the last few decades, we have witnessed an increasing focus on safety in the workplace. ICT has always played a leading role in this context. One ICT sector that is increasingly important in ensuring safety at work is the Internet of Things and, in particular, the new architectures referring to it, such as SIoT, MIoT and Sentient Multimedia Systems. All these architectures handle huge amounts of data to extract predictive and prescriptive information. For this purpose, they often make use of Machine Learning. In this paper, we propose a framework that uses both Sentient Multimedia Systems and Machine Learning to support safety in the workplace. After the general presentation of the framework, we describe its specialization to a particular case, i.e., fall detection. As for this application scenario, we describe a Machine Learning based wearable device for fall detection that we designed, built and tested. Moreover, we illustrate a safety coordination platform for monitoring the work environment, activating alarms in case of falls, and sending appropriate advices to help workers involved in falls.
C1 [Bonifazi, Gianluca; Corradini, Enrico; Ursino, Domenico; Virgili, Luca] Polytech Univ Marche, Dept Informat Engn, Ancona, Italy.
   [Anceschi, Emiliano; De Donato, Massimo Callisto] Grp Filippetti SpA, Ancona, Italy.
C3 Marche Polytechnic University
RP Ursino, D (corresponding author), Polytech Univ Marche, Dept Informat Engn, Ancona, Italy.
EM g.bonifazi@univpm.it; e.corradini@pm.univpm.it; d.ursino@univpm.it;
   l.virgili@pm.univpm.it; emiliano.anceschi@gruppofilippetti.it;
   massimo.callistodedonato@gruppofilippetti.it
RI Corradini, Enrico/ABB-3022-2021; Bonifazi, Gianluca/AAA-2985-2022;
   Virgili, Luca/AAG-1602-2021; Anceschi, Emiliano/GQA-4826-2022
OI Corradini, Enrico/0000-0002-1140-4209; Bonifazi,
   Gianluca/0000-0002-1947-8667; Virgili, Luca/0000-0003-1509-783X;
   Callisto De Donato, Massimo/0000-0001-6745-4785; anceschi,
   emiliano/0000-0001-5344-798X; Ursino, Domenico/0000-0003-1360-8499
FU Department of Information Engineering at the Polytechnic University of
   Marche under the project "A network-based approach to uniformly extract
   knowledge and support decision making in heterogeneous application
   contexts" (RSAB 2018); Marche Region under the project "Human Digital
   Flexible Factory of the Future Laboratory (HDSFIab) - POR MARCHE FESR
   2014-2020" [CUP B16H18000050007]
FX This work was partially funded by the Department of Information
   Engineering at the Polytechnic University of Marche under the project "A
   network-based approach to uniformly extract knowledge and support
   decision making in heterogeneous application contexts" (RSAB 2018), and
   by the Marche Region under the project "Human Digital Flexible Factory
   of the Future Laboratory (HDSFIab) - POR MARCHE FESR 2014-2020 - CUP
   B16H18000050007".
CR Addlesee M, 2001, COMPUTER, V34, P50, DOI 10.1109/2.940013
   Al-Turjman F, 2020, MULTIMED TOOLS APPL, V79, P8627, DOI 10.1007/s11042-018-6288-7
   Altun K, 2010, PATTERN RECOGN, V43, P3605, DOI 10.1016/j.patcog.2010.04.019
   Anceschi E., 2021, Studies in Computational Intelligence, V911, P493, DOI [10.1007/978-3-030-52067-022, DOI 10.1007/978-3-030-52067-022]
   Arslan M, 2019, PERS UBIQUIT COMPUT, V23, P749, DOI 10.1007/s00779-018-01199-5
   Atzori L, 2011, IEEE COMMUN LETT, V15, P1193, DOI 10.1109/LCOMM.2011.090911.111340
   Baldassarre G, 2019, FUTURE GENER COMP SY, V92, P29, DOI 10.1016/j.future.2018.09.015
   Bibi K, 2020, MULTIMED TOOLS APPL, V79, P289, DOI 10.1007/s11042-019-08022-0
   Bourke AK, 2008, MED ENG PHYS, V30, P84, DOI 10.1016/j.medengphy.2006.12.001
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breve B, 2019, IEEE INT CON INF VIS, P255, DOI 10.1109/IV.2019.00050
   Butterworth S., 1930, Wireless Eng, V7, P536
   Cabitza F, 2014, J VISUAL LANG COMPUT, V25, P684, DOI 10.1016/j.jvlc.2014.10.014
   Canós JH, 2004, IEEE MULTIMEDIA, V11, P106, DOI 10.1109/MMUL.2004.2
   Caruccio L., 2019, SEBD
   Casilari E, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17071513
   Chaccour K, 2015, IEEE CONF WIREL MOB, P225, DOI 10.1109/WiMOB.2015.7347965
   Chan, 2018, CGU BES DATASET FALL
   Chandra I, 2019, CLUSTER COMPUT, V22, P2517, DOI 10.1007/s10586-018-2329-2
   Christian MS, 2009, J APPL PSYCHOL, V94, P1103, DOI 10.1037/a0016172
   Cirillo S, 2019, J DATA INF QUAL JDIQ
   Cucchiara R, 2007, EXPERT SYST, V24, P334, DOI 10.1111/j.1468-0394.2007.00438.x
   de Miguel K, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17122864
   De Rossi, 2008, IEEE
   Diraco G, 2010, DES AUT TEST EUROPE, P1536
   Duan L, 2015, J MANAG ANAL, V2, P1, DOI 10.1080/23270012.2015.1020891
   Felder R, P INT C INF COMM TEC, V1, P1003
   Genuer R, 2010, PATTERN RECOGN LETT, V31, P2225, DOI 10.1016/j.patrec.2010.03.014
   Gibson RM, 2016, APPL SOFT COMPUT, V39, P94, DOI 10.1016/j.asoc.2015.10.062
   Griffin M A, 2000, J Occup Health Psychol, V5, P347
   Han J, 2012, MOR KAUF D, P1
   He J, 2015, CHINA COMMUN, V12, P23, DOI 10.1109/CC.2015.7114066
   Hussain F., 2019, ARXIV191111976
   Kaluza B, 2009, P INT MULT INF SOC I, VA, P22
   Karantonis DM, 2006, IEEE T INF TECHNOL B, V10, P156, DOI 10.1109/TITB.2005.856864
   Kwolek B, 2014, COMPUT METH PROG BIO, V117, P489, DOI 10.1016/j.cmpb.2014.09.005
   Lai CF, 2011, IEEE SENS J, V11, P763, DOI 10.1109/JSEN.2010.2062501
   Lo Giudice P, 2019, INFORM SCIENCES, V478, P606, DOI 10.1016/j.ins.2018.11.052
   Mastorakis G, 2014, J REAL-TIME IMAGE PR, V9, P635, DOI 10.1007/s11554-012-0246-9
   Mathie MJ, 2004, PHYSIOL MEAS, V25, pR1, DOI 10.1088/0967-3334/25/2/R01
   Matías JM, 2008, INT J COMPUT MATH, V85, P559, DOI 10.1080/00207160701297346
   Mubashir M, 2013, NEUROCOMPUTING, V100, P144, DOI 10.1016/j.neucom.2011.09.037
   Nair NG, 2019, 2019 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI 2019), P1783, DOI 10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00316
   Neal A, 2000, SAFETY SCI, V34, P99, DOI 10.1016/S0925-7535(00)00008-4
   Özdemir AT, 2014, SENSORS-BASEL, V14, P10691, DOI 10.3390/s140610691
   Pannurat N, 2017, IEEE SENS J, V17, P1749, DOI 10.1109/JSEN.2017.2649542
   Praveena D, 2020, MULTIMED TOOLS APPL, V79, P5161, DOI 10.1007/s11042-018-6339-0
   Qiu JF, 2016, EURASIP J ADV SIG PR, DOI 10.1186/s13634-016-0355-x
   Rimminen H, 2010, IEEE T INF TECHNOL B, V14, P1475, DOI 10.1109/TITB.2010.2051956
   Saadeh W, 2017, 2017 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL & HEALTH INFORMATICS (BHI), P441, DOI 10.1109/BHI.2017.7897300
   Sabatini AM, 2016, IEEE T NEUR SYS REH, V24, P774, DOI 10.1109/TNSRE.2015.2460373
   Said O., 2013, International Journal of Computer Networks, V5, P1
   Sood SK, 2020, MULTIMED TOOLS APPL, V79, P10717, DOI 10.1007/s11042-019-08573-2
   Sucerquia A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17010198
   Tabar A.M., 2006, Proceedings of the 4th ACM InternationalWorkshop on Video Surveillance and Sensor Networks, P145, DOI [10.1145/1178782.1178804, DOI 10.1145/1178782.1178804]
   Tamura T, 2009, IEEE T INF TECHNOL B, V13, P910, DOI 10.1109/TITB.2009.2033673
   Tixier AJP, 2016, AUTOMAT CONSTR, V69, P102, DOI 10.1016/j.autcon.2016.05.016
   Ursino D, INFORM SYST FRONT
   Nguyen VA, 2016, PROCEEDINGS OF THE SEVENTH SYMPOSIUM ON INFORMATION AND COMMUNICATION TECHNOLOGY (SOICT 2016), P339, DOI 10.1145/3011077.3011103
   Wang Fang, 2014, ACM INT C, P1069, DOI 10.1145/2661829.2662067
   Zhang T, 2006, LECT NOTES CONTR INF, V345, P858
   Zhuang XD, 2009, INT CONF ACOUST SPEE, P69, DOI 10.1109/ICASSP.2009.4959522
NR 62
TC 7
Z9 7
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 141
EP 169
DI 10.1007/s11042-021-10984-z
EA MAY 2021
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000650816400002
PM 34025207
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Kumar, R
   Kumar, P
   Kumar, Y
AF Kumar, Raghavendra
   Kumar, Pardeep
   Kumar, Yugal
TI Integrating big data driven sentiments polarity and ABC-optimized LSTM
   for time series forecasting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sentiment polarity; Hadoop; LSTM; Time series
ID BEE COLONY ALGORITHM; STOCK-PRICE; NEURAL-NETWORKS; MODE DECOMPOSITION;
   FINANCIAL MARKET; PREDICTION; MACHINE
AB Stock market is a dynamic and volatile market that is considered as time series data. The growth of financial data exposed the computational efficiency of the conventional systems. This paper proposed a hybrid deep learning model based on Long Short- Term Memory (LSTM) and Artificial Bee Colony (ABC) algorithm. ABC is best fit for hyper parameter selection for deep LSTM models and maintains the equilibrium of exploitation and exploration issues. Handling a large volume of multidimensional reviews from social media is a major challenge. This paper evolves the multiple aspects of market sentiments and uses the reliable Big data platform Hadoop ecosystem and its services to compute sentiment polarity index. The ABC-LSTM hybrid model is validated with other core and hybrid models with evolutionary algorithms as Differential Evolution (DE) and Genetic Algorithm (GA). For the experiments, 10 years of historical datasets and social media reviews of IT sector funds Apple Inc. (AAPL), Microsoft corporation (MSFT) and Intel corporation (INTL) from NASDAQ GS, an American stock exchange are considered to validate hybrid forecasting models. Proposed algorithm ABC-LSTM is used to tune the hyperparameters (window size, LSTM units, dropout probability, epochs, batch size and learning rate) and evaluated through Root Mean Square Error (RMSE) and Mean Absolute Percentage Error (MAPE) as loss function. Performance analysis proves that with sentiment polarity, ABC optimized LSTM obtains improved forecasting accuracy over its counterpart models.
C1 [Kumar, Raghavendra] KIET Grp Inst, Dept Informat Technol, Ghaziabad, India.
   [Kumar, Raghavendra; Kumar, Pardeep; Kumar, Yugal] Jaypee Univ Informat Technol, Dept Comp Sci & Engn, Waknaghat, India.
C3 KIET Group of Institutions; Jaypee University of Information Technology
RP Kumar, R (corresponding author), KIET Grp Inst, Dept Informat Technol, Ghaziabad, India.; Kumar, R (corresponding author), Jaypee Univ Informat Technol, Dept Comp Sci & Engn, Waknaghat, India.
EM raghavendra.dwivedi@gmail.com; pardeepkumarkhokhar@gmail.com;
   yugalkumar.14@gmail.com
RI Kumar, Raghavendra/ABG-4832-2021; Villen Retamero, Andrea
   Maria/IAR-1667-2023; Kumar, Yugal/AFP-5345-2022
OI Kumar, Yugal/0000-0003-3451-4897
CR Adebiyi AA, 2014, UKSIM INT CONF COMP, P106, DOI 10.1109/UKSim.2014.67
   Bisoi R, 2019, APPL SOFT COMPUT, V74, P652, DOI 10.1016/j.asoc.2018.11.008
   Box G.E., 2015, TIME SERIES ANAL FOR
   Chen AS, 2003, COMPUT OPER RES, V30, P901, DOI 10.1016/S0305-0548(02)00037-0
   Dwivedi RK, 2019, LECT NOTE NETW SYST, V56, P57, DOI 10.1007/978-981-13-2354-6_7
   Engle R, 2001, J ECON PERSPECT, V15, P157, DOI 10.1257/jep.15.4.157
   Fischer T, 2018, EUR J OPER RES, V270, P654, DOI 10.1016/j.ejor.2017.11.054
   Fu TC, 2011, ENG APPL ARTIF INTEL, V24, P164, DOI 10.1016/j.engappai.2010.09.007
   Göçken M, 2019, NEURAL COMPUT APPL, V31, P577, DOI 10.1007/s00521-017-3089-2
   Göçken M, 2016, EXPERT SYST APPL, V44, P320, DOI 10.1016/j.eswa.2015.09.029
   Guresen E, 2011, EXPERT SYST APPL, V38, P10389, DOI 10.1016/j.eswa.2011.02.068
   Ha I, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/417502
   Hiransha M., 2018, Procedia Computer Science, V132, P1351, DOI 10.1016/j.procs.2018.05.050
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hsieh TJ, 2011, APPL SOFT COMPUT, V11, P2510, DOI 10.1016/j.asoc.2010.09.007
   Huang FR, 2019, KNOWL-BASED SYST, V167, P26, DOI 10.1016/j.knosys.2019.01.019
   Jin ZG, 2020, NEURAL COMPUT APPL, V32, P9713, DOI 10.1007/s00521-019-04504-2
   Karaboga D., 2005, Technical Report-TR06
   Karaboga D, 2014, ARTIF INTELL REV, V42, P21, DOI 10.1007/s10462-012-9328-0
   Karaboga D, 2009, NEURAL NETW WORLD, V19, P279
   Kusuma RMI, 2019, ARXIV PREPRINT ARXIV
   Marmer V, 2008, J ECONOMETRICS, V142, P1, DOI 10.1016/j.jeconom.2007.03.002
   Mernik M, 2015, INFORM SCIENCES, V291, P115, DOI 10.1016/j.ins.2014.08.040
   Mishra, INT C INN COMP COMM, P1165
   Nikfarjam A, 2010, INT CONF COMPUT AUTO, P256, DOI 10.1109/ICCAE.2010.5451705
   Osman, 2019, J COMPUT FINAN
   Pei-Chann Chang, 2004, Journal of the Chinese Institute of Industrial Engineers, V21, P358, DOI 10.1080/10170660409509416
   Philip, 2020, IEEE T IND INFORM
   Radha S, 2006, IND I CAP MARK 9 CAP
   Rodrigues AP, 2018, COGENT ENG, V5, DOI 10.1080/23311916.2018.1534519
   Ruan YF, 2018, KNOWL-BASED SYST, V145, P207, DOI 10.1016/j.knosys.2018.01.016
   Singh R, 2017, MULTIMED TOOLS APPL, V76, P18569, DOI 10.1007/s11042-016-4159-7
   Skuza M, 2015, ACSIS-ANN COMPUT SCI, V5, P1349, DOI 10.15439/2015F230
   Wang L, 2015, EXPERT SYST APPL, V42, P855, DOI 10.1016/j.eswa.2014.08.018
   Wang WN, 2018, MULTIMED TOOLS APPL, V77, P10123, DOI 10.1007/s11042-017-5144-5
   Wei LY, 2012, INT J INNOV COMPUT I, V8, P5559
   Yang FM, 2019, APPL SOFT COMPUT, V80, P820, DOI 10.1016/j.asoc.2019.03.028
   Yang RJ, 2020, INT J INFORM MANAGE, V50, P452, DOI 10.1016/j.ijinfomgt.2019.05.027
   Zhou F, 2019, EXPERT SYST APPL, V115, P136, DOI 10.1016/j.eswa.2018.07.065
NR 39
TC 11
Z9 12
U1 5
U2 55
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34595
EP 34614
DI 10.1007/s11042-021-11029-1
EA MAY 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000650124400003
DA 2024-07-18
ER

PT J
AU Murugesan, VP
   Murugesan, P
AF Murugesan, Vijaya Prabhagar
   Murugesan, Punniyamoorthy
TI Some measures to impact on the performance of Kohonen self-organizing
   map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Initialization algorithm; Centroids placement; Cluster determination;
   Semantic relevant index
AB In the field of unsupervised learning, Self-Organizing Map (SOM) has attracted the attention of many researchers. SOM is a popular algorithm in the area of data clustering; in this paper, new algorithms are developed to find the initial weights, to assign those initial weights to the SOM grid and a new way to determine the number of clusters in the SOM algorithm. Also, a new performance measure MSRI (Modified Semantic Relevant Index) has been introduced for the SOM algorithm. For the class label datasets, the performance criteria like Classification Accuracy (CA), Quantization error (QE) and Convergence time (CT) are used to compare the proposed SOM algorithm with existing SOM algorithms. Here the existing SOM algorithms like Enhanced SOM (ESOM), SOM Particle Swarm Optimization (SOMPSO), ESOMPSO and conventional SOM are used. In addition, MSRI is used to compare the proposed SOM with the existing SOM algorithms. We have also used different image classification datasets to compare our proposed SOM and existing SOM algorithm with CA, QE, CT, and MSRI. For the non-class label dataset, the criteria like QE, CT and MSRI are employed to analyze the performance of proposed SOM with the conventional SOM algorithm. The gene index is also used to validate the number of clusters obtained by the proposed SOM algorithm. It is found that our proposed SOM algorithm has shown better performance in all cases.
C1 [Murugesan, Vijaya Prabhagar] Natl Inst Technol, Tiruchirappalli 620015, Tamil Nadu, India.
   [Murugesan, Punniyamoorthy] Natl Inst Technol, Dept Management Studies, Tiruchirappalli 620015, Tamil Nadu, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli; National Institute of Technology (NIT
   System); National Institute of Technology Tiruchirappalli
RP Murugesan, P (corresponding author), Natl Inst Technol, Dept Management Studies, Tiruchirappalli 620015, Tamil Nadu, India.
EM 415115001@nitt.edu; punniya@nitt.edu
RI Murugesan, Vijaya Prabhagar/AAD-3631-2021; M,
   punniyamoorthy/IZE-0883-2023; M, punniyamoorthy/AAO-9180-2020
OI Murugesan, Vijaya Prabhagar/0000-0002-0097-533X; 
CR Akinduko AA, 2016, INFORM SCIENCES, V364, P213, DOI 10.1016/j.ins.2015.10.013
   [Anonymous], 2000, P S TOOL ENV DEV MET
   [Anonymous], CAMBRIDGE, P17
   Apostolakis J, 2010, STRUCT BOND, V134, P1, DOI 10.1007/430-2009_1
   Astel A, 2007, WATER RES, V41, P4566, DOI 10.1016/j.watres.2007.06.030
   Asuncion A, 2007, U CALIF IRVINE SCH I
   Caruana R., 2004, P 10 ACM SIGKDD INT, P69, DOI [DOI 10.1073/pnas.0901650106, DOI 10.1145/1014052.1014063]
   Chan CKK, 2008, J BIOMED BIOTECHNOL, DOI 10.1155/2008/513701
   Chen DR, 2000, ULTRASOUND MED BIOL, V26, P405, DOI 10.1016/S0301-5629(99)00156-8
   Chen N, 2019, INT J DISAST RISK RE, V33, P196, DOI 10.1016/j.ijdrr.2018.10.005
   Chow TWS, 2007, NEUROCOMPUTING, V70, P1040, DOI 10.1016/j.neucom.2006.01.033
   Cottrell M, 1998, NEUROCOMPUTING, V21, P119, DOI 10.1016/S0925-2312(98)00034-4
   Créput JC, 2012, J COMB OPTIM, V24, P437, DOI 10.1007/s10878-011-9400-8
   Du KL, 2010, NEURAL NETWORKS, V23, P89, DOI 10.1016/j.neunet.2009.08.007
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Fisher RA., 2011, ANN EUGENIC, V7, P188
   Frank A., 2019, UCI MACHINE LEARNING
   Ghaziri H, 2006, J SCHED, V9, P97, DOI 10.1007/s10951-006-6774-z
   Hajjam, 2013, J INF OPTIM SCI, V29, P485
   Hartono P, 2015, IEEE T NEUR NET LEAR, V26, P2323, DOI 10.1109/TNNLS.2014.2379275
   Hasan S, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/121787
   Hsu AL, 2009, STUD COMPUT INTELL, V201, P363
   Khan A, 2013, MULTIMED TOOLS APPL, V64, P331, DOI 10.1007/s11042-012-1003-6
   Khu ST, 2008, ADV WATER RESOUR, V31, P1387, DOI 10.1016/j.advwatres.2008.07.011
   Kita E, 2010, ADV ENG SOFTW, V41, P148, DOI 10.1016/j.advengsoft.2009.09.011
   Kohonen T, 1996, P IEEE, V84, P1358, DOI 10.1109/5.537105
   Kohonen T., 1998, Neurocomputing, V21, P1, DOI 10.1016/S0925-2312(98)00030-7
   Kohonen T, 1997, 1997 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-4, pPL1, DOI 10.1109/ICNN.1997.611622
   Kohonen T, 2013, NEURAL NETWORKS, V37, P52, DOI 10.1016/j.neunet.2012.09.018
   Lapidot I, 2002, IEEE T NEURAL NETWOR, V13, P877, DOI 10.1109/TNN.2002.1021888
   Lee M, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101690
   Lokesh S, 2019, NEURAL COMPUT APPL, V31, P1521, DOI 10.1007/s00521-018-3466-5
   Mallick Partho, 2019, Emerging Technologies in Data Mining and Information Security. Proceedings of IEMIS 2018. Advances in Intelligent Systems and Computing (AISC 814), P863, DOI 10.1007/978-981-13-1501-5_75
   MURTAGH F, 1995, PATTERN RECOGN LETT, V16, P399, DOI 10.1016/0167-8655(94)00113-H
   Nawaratne R, 2020, MULTIMED TOOLS APPL, V79, P16299, DOI 10.1007/s11042-020-08886-7
   Neagoe VE, 2002, FIRST IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS, PROCEEDINGS, P304, DOI 10.1109/COGINF.2002.1039311
   Ozcalici M, 2020, APPL SOFT COMPUT, V90, DOI 10.1016/j.asoc.2020.106166
   Park YS, 2006, ECOL INFORM, V1, P247, DOI 10.1016/j.ecoinf.2006.03.005
   Petrilis D, 2008, NEURAL PROCESS LETT, V27, P85, DOI 10.1007/s11063-007-9061-x
   Polzlbauer G, 2010, ADV VISUALIZATION TE, P75
   Ressom H, 2003, NEURAL NETWORKS, V16, P633, DOI 10.1016/S0893-6080(03)00102-3
   Ressom H, 2003, PHYSIOL GENOMICS, V14, P35, DOI 10.1152/physiolgenomics.00138.2002
   Ritter, 2018, ROBUST CLUSTER ANAL
   Sakkari M, 2020, MULTIMED TOOLS APPL, V79, P19451, DOI 10.1007/s11042-020-08822-9
   Santos WP, 2008, COMPUT MED IMAG GRAP, V32, P17, DOI 10.1016/j.compmedimag.2007.08.004
   Sebban M, 2003, J MACH LEARN RES, V3, P863, DOI 10.1162/jmlr.2003.3.4-5.863
   Shieh SL, 2012, EXPERT SYST APPL, V39, P11924, DOI 10.1016/j.eswa.2012.02.181
   Sun L, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL II, PROCEEDINGS, P582
   Uysal I, 2004, APPL INTELL, V21, P57, DOI 10.1023/B:APIN.0000027767.87895.b2
   Valova I, 2013, PROCEDIA COMPUT SCI, V20, P52, DOI 10.1016/j.procs.2013.09.238
   Vesanto J, 2000, HELSINKI U TECHNOL N
   Wang L, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106262
   Wickramasinghe CS, 2019, IEEE T IND INFORM, V15, P5837, DOI 10.1109/TII.2019.2906083
   Wu YX, 2006, NEURAL NETWORKS, V19, P900, DOI 10.1016/j.neunet.2006.05.021
NR 54
TC 4
Z9 3
U1 2
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26381
EP 26409
DI 10.1007/s11042-021-10912-1
EA MAY 2021
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000646558000001
DA 2024-07-18
ER

PT J
AU Shi, CH
   Wang, HX
   Hu, Y
   Li, XJ
AF Shi, Canghong
   Wang, Hongxia
   Hu, Yi
   Li, Xiaojie
TI A novel NMF-based authentication scheme for encrypted speech in cloud
   computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encrypted speech authentication; Speech encryption; Non-negative matrix
   factorization; Cloud computing; Tamper localization; Common signal
   processing
AB Authentication of encrypted speeches is a technique that can judge the integrity of encrypted speech in cloud computing, even the encrypted speeches have been subjected to common signal processing operations. In this paper, a novel and effective authentication scheme for encrypted speech is proposed. At first, the host speech signal is first scrambled and encrypted by Advanced Encryption Standard (AES). Then, Integer Wavelet Transform (IWT) is performed to obtain the approximation coefficients and the detail coefficients. At last, Non-negative Matrix Factorization (NMF) is employed to generate perceptual hashing, which is embedded into the encrypted speech by differential expansion. In authentication section, the tampered region of encrypted speech is located by comparing the reconstructed perceptual hashing with the extracted perceptual hashing version. Extensive experiments are carried out, which demonstrate that the proposed scheme is not only sensitive to malicious tampering of encrypted speech files, but also robust to tolerate common signal processing operations. The comparison shows that our algorithm performs better than the existing methods on Bit Error Rate (BER) values.
C1 [Shi, Canghong] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Peoples R China.
   [Wang, Hongxia] Sichuan Univ, Sch Cyber Sci & Engn, Chengdu 610041, Peoples R China.
   [Hu, Yi] Northern Kentucky Univ, Highland Hts, KY USA.
   [Li, Xiaojie] Chengdu Univ Informat Technol, Coll Comp Sci, Chengdu 610225, Peoples R China.
C3 Southwest Jiaotong University; Sichuan University; Northern Kentucky
   University; Chengdu University of Information Technology
RP Wang, HX (corresponding author), Sichuan Univ, Sch Cyber Sci & Engn, Chengdu 610041, Peoples R China.
EM canghongshi@163.com; hxwang@scu.edu.cn; huy1@nku.edu;
   lixiaojie000000@163.com
RI Wang, Hongxia/AAE-2135-2022
FU National Natural Science Foundation of China (NSFC) [61972269];
   Fundamental Research Funds for the Central Universities [YJ201881];
   Scientific Research Foundation of the Education Department of Sichuan
   Province [17ZA0063]
FX This work is supported by the National Natural Science Foundation of
   China (NSFC) under Grants 61972269, and the Fundamental Research Funds
   for the Central Universities under Grant YJ201881, and by the Scientific
   Research Foundation of the Education Department of Sichuan Province
   (17ZA0063). The authors would like to thank Dr. Hanzhou Wu for valuable
   suggestions and discussion.
CR Abdulla, 2015, THESIS U BUCKINGHAM, V1, P1
   Al-Qerem A, 2020, SOFT COMPUT, V24, P5695, DOI 10.1007/s00500-019-04220-y
   Ali S, 2020, IEEE ACCESS, V8, P148007, DOI 10.1109/ACCESS.2020.3014671
   Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   [Anonymous], 2016, IEEE T CIRC SYST VID, DOI [10.1109/TIFS.2016.2590944, DOI 10.1109/TIFS.2016.2590944]
   Chen J, 2018, IEEE TRUST BIG, P86, DOI 10.1109/TrustCom/BigDataSE.2018.00023
   Chen OTC, 2007, IEEE T AUDIO SPEECH, V15, P1605, DOI 10.1109/TASL.2007.896658
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Deep G, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19204444
   ELLATIF A, 2018, IEEE ACCESS, V6, P10332, DOI DOI 10.1109/ACCESS.2018.2799879
   Fan MQ, 2013, INT J COMPUT MATH, V90, P2588, DOI 10.1080/00207160.2013.805752
   Gupta S, 2012, IEEE MULTIMEDIA, V19, P50, DOI 10.1109/MMUL.2011.74
   Hua G, 2016, SIGNAL PROCESS, V128, P222, DOI 10.1016/j.sigpro.2016.04.005
   Jin Yang, 2018, International Journal of High Performance Computing and Networking, V11, P231
   Kaushik S, 2019, INT J CLOUD APPL COM, V9, P21, DOI 10.4018/IJCAC.2019100102
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Lei BY, 2011, SIGNAL PROCESS, V91, P1973, DOI 10.1016/j.sigpro.2011.03.001
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Liu YL, 2018, CMC-COMPUT MATER CON, V55, P37, DOI 10.3970/cmc.2018.055.037
   Meng RH, 2018, CMC-COMPUT MATER CON, V55, P1, DOI 10.3970/cmc.2018.055.001
   Nayyar A, 2019, HDB CLOUD COMPUTING, P1
   Qian Q, 2020, TELECOMMUN SYST, V75, P273, DOI 10.1007/s11235-020-00684-8
   Qian Q, 2018, TELECOMMUN SYST, V67, P635, DOI 10.1007/s11235-017-0360-x
   Shen J, 2017, IEEE T INF FOREN SEC, V12, P2402, DOI 10.1109/TIFS.2017.2705620
   Shi, 2016, P 15 INT WORKSH DIG, P46
   Shuaishuai Zhu, 2018, International Journal of High Performance Computing and Networking, V12, P128
   Singh Saurabh, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P1625, DOI 10.1007/s12652-017-0494-4
   Singh S, 2016, J NETW COMPUT APPL, V75, P200, DOI 10.1016/j.jnca.2016.09.002
   Singh S, 2021, CURR EYE RES, V46, P765, DOI 10.1080/02713683.2020.1849727
   Singh SP, 2019, J SUPERCOMPUT, V75, P2070, DOI 10.1007/s11227-018-2701-2
   Singh S, 2016, J GRID COMPUT, V14, P217, DOI 10.1007/s10723-015-9359-2
   Tewari Aakanksha, 2019, International Journal of High Performance Computing and Networking, V15, P106
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Wu HZ, 2017, IEEE T CIRC SYST VID, V27, P1620, DOI 10.1109/TCSVT.2016.2556585
   Xiang SJ, 2018, IEEE T CIRC SYST VID, V28, P3099, DOI 10.1109/TCSVT.2017.2742023
   [项世军 Xiang Shijun], 2016, [计算机学报, Chinese Journal of Computers], V39, P571
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
   Zheng QM, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2017.2775038
NR 39
TC 6
Z9 6
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 25773
EP 25798
DI 10.1007/s11042-021-10896-y
EA APR 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000642836400003
DA 2024-07-18
ER

PT J
AU Cui, Z
   Sun, HM
   Yin, RN
   Gao, L
   Sun, HB
   Jia, RS
AF Cui, Zhe
   Sun, Hong-Mei
   Yin, Ruo-Nan
   Gao, Li
   Sun, Hai-Bin
   Jia, Rui-Sheng
TI Real-time detection method of driver fatigue state based on deep
   learning of face video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fatigue driving detection; Face video; Deep learning; Embedded
   application; Object detection
ID SYSTEM
AB The use of face video information for driver fatigue detection has received extensive attention because of its low cost and non-invasiveness. However, the current vehicle-mounted embedded device has insufficient memory and limited computing power, which cannot complete the real-time detection of driver fatigue based on deep learning. Therefore, this paper designs a lightweight neural network model to solve this problem. The model includes object detection and fatigue detection. First, a lightweight object detection network is designed, which can quickly identify the opening and closing states of the driver's eyes and mouth in the time series video. Secondly, the EYE-MOUTH (EM) driver fatigue detection model is designed, which encodes the driver's eye and mouth opening and closing state, and calculates the driver's PERCLOS (Percentage of Eyelid Closure over the Pupil) and FOM (Frequency of Open Mouth) according to the coding sequence. Finally, the multi-feature fusion judgment algorithm is used to realize the judgment of the driver's fatigue state. The experimental results show that our method has an accuracy rate of 98.30% for drowsiness and yawning behaviors in a real vehicle environment, and a detection speed of 27FPS, which is better than other advanced methods and meets the requirements of real-time detection.
C1 [Cui, Zhe; Sun, Hong-Mei; Yin, Ruo-Nan; Gao, Li; Sun, Hai-Bin; Jia, Rui-Sheng] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
   [Sun, Hong-Mei; Sun, Hai-Bin; Jia, Rui-Sheng] Shandong Univ Sci & Technol, Shandong Prov Key Lab Wisdom Mine Informat Techn, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of
   Science & Technology
RP Sun, HM; Jia, RS (corresponding author), Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.; Sun, HM; Jia, RS (corresponding author), Shandong Univ Sci & Technol, Shandong Prov Key Lab Wisdom Mine Informat Techn, Qingdao 266590, Peoples R China.
EM shm0221@163.com; jrs716@163.com
RI Jia, Rui-Sheng/D-4460-2015
OI Jia, Rui-Sheng/0000-0003-1612-4764
FU Natural Science Foundation of Shandong Province, China [ZR2018MEE008];
   Key Research and Development Project of Shandong Province, China
   [2019JZZY020326]
FX The authors are grateful for collaborative funding support from the
   Natural Science Foundation of Shandong Province, China (ZR2018MEE008),
   the Key Research and Development Project of Shandong Province, China
   (2019JZZY020326).
CR Anund A, 2017, EUR TRANSP RES REV, V9, DOI 10.1007/s12544-017-0248-6
   Azim Tayyaba, 2009, 2009 Fourth International Conference on Innovative Computing, Information and Control (ICICIC 2009), P441, DOI 10.1109/ICICIC.2009.119
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Bosso A, 2021, IEEE-ASME T MECH, V26, P1501, DOI 10.1109/TMECH.2020.3022379
   Cashman D, 2018, IEEE COMPUT GRAPH, V38, P39, DOI 10.1109/MCG.2018.2878902
   Dwivedi K, 2014, IEEE INT ADV COMPUT, P995, DOI 10.1109/IAdCC.2014.6779459
   Feldman D, 2020, SIAM J COMPUT, V49, P601, DOI 10.1137/18M1209854
   Geng Lei, 2018, Computer Engineering, V44, P274, DOI 10.3969/j.issn.1000-3428.2018.01.046
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gu WH, 2018, IET IMAGE PROCESS, V12, P2319, DOI 10.1049/iet-ipr.2018.5245
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Huang R, 2018, IEEE INT CONF BIG DA, P2503, DOI 10.1109/BigData.2018.8621865
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Ivanov Y, 2015, PROCEEDINGS OF XIIITH INTERNATIONAL CONFERENCE - EXPERIENCE OF DESIGNING AND APPLICATION OF CAD SYSTEMS IN MICROELECTRONICS CADSM 2015, P97, DOI 10.1109/CADSM.2015.7230806
   Flores MJ, 2010, J INTELL ROBOT SYST, V59, P103, DOI 10.1007/s10846-009-9391-1
   Khunpisuth O, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P661, DOI 10.1109/SITIS.2016.110
   Koh S, 2017, INT C CONTROL DECISI, P383, DOI 10.1109/CoDIT.2017.8102622
   Li KN, 2020, IEEE ACCESS, V8, P101244, DOI 10.1109/ACCESS.2020.2998363
   Lin, 1651, J PHYS C SER, V2020
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   LV ZH, 2021, IEEE INTERNET THINGS, V8, P9531, DOI DOI 10.1109/JIOT.2020.3007130
   Lv ZH, 2020, APPL SOFT COMPUT, V92, DOI 10.1016/j.asoc.2020.106300
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Mao QC, 2019, IEEE ACCESS, V7, P133529, DOI 10.1109/ACCESS.2019.2941547
   Navastara Dini Adni, 2020, Journal of Physics: Conference Series, V1529, DOI 10.1088/1742-6596/1529/5/052015
   Parekh V, 2020, Augment Hum Res, V5, P5, DOI [10.1007/s41133-019-0023-4, DOI 10.1007/S41133-019-0023-4]
   Peleshko D, 2016, PROCEEDINGS OF THE 2016 IEEE FIRST INTERNATIONAL CONFERENCE ON DATA STREAM MINING & PROCESSING (DSMP), P159, DOI 10.1109/DSMP.2016.7583531
   Ravi A., 2020, 2020 International Conference on Electronics and Sustainable Communication Systems (ICESC). Proceedings, P434, DOI 10.1109/ICESC48915.2020.9156021
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ros, 2020, INT J IMAGE PROCESS, V14, P1
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tkachenko R, 2018, STUD COMPUT INTELL, V730, P537, DOI 10.1007/978-3-319-63754-9_25
   Wong A, 2019, FIFTH WORKSHOP ON ENERGY EFFICIENT MACHINE LEARNING AND COGNITIVE COMPUTING - NEURIPS EDITION (EMC2-NIPS 2019), P22, DOI 10.1109/EMC2-NIPS53020.2019.00013
   Xu HY, 2020, ADV INTELL SYST COMP, V1131, P1263, DOI 10.1007/978-3-030-39512-4_193
   Yadav N, 2020, INT J E-HEALTH MED C, V11, P1, DOI 10.4018/IJEHMC.2020070101
   Zhang H, 2020, IEEE-CAA J AUTOMATIC, V7, P790, DOI 10.1109/JAS.2020.1003099
   Zhang PY, 2019, IEEE INT CONF COMP V, P37, DOI 10.1109/ICCVW.2019.00011
   Zhang WW, 2015, AGRICULTURAL RESOURCE USE AND MANAGEMENT, P1, DOI [10.1109/APMC.2015.7412982, 10.3390/ijerph9114170]
   Zhou ZP, 2019, TRANSPORTMETRICA A, V15, P1019, DOI 10.1080/23249935.2018.1559895
   Zhou ZP, 2017, PHYSICA A, V475, P142, DOI 10.1016/j.physa.2016.12.041
NR 45
TC 9
Z9 9
U1 9
U2 88
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 25495
EP 25515
DI 10.1007/s11042-021-10930-z
EA APR 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000640862600005
DA 2024-07-18
ER

PT J
AU Mansouri, A
   Wang, XY
AF Mansouri, Ali
   Wang, Xingyuan
TI A novel block-based image encryption scheme using a new Sine powered
   chaotic map generator
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Chaos theory; Confusion and Diffusion
ID CRYPTANALYSIS; ENTROPY; SYSTEM
AB In this paper, we propose a new Sine powered chaotic maps generator (SP-CMG). The proposed system uses one-dimensional chaotic maps as seed maps to produce new chaotic maps. The evaluation shows that the SP-CMG can generate maps with better performance in comparison with the seed maps. We further implement the SP-CMG to design a novel block-based image encryption scheme (LSSP-IE). The proposed scheme pre-processes the plain image using pixels addition and blocks generation. Using the generated chaotic sequences, We shuffle the columns and pixels between the generated blocks and execute bit-level values manipulation. The simulation results indicate that the LSSP-IE can generate random-like images with high confusion and diffusion properties. Concerning the security analysis, the LSSP-IE exhibits high resistance to various attacks compared to other image encryption schemes.
C1 [Mansouri, Ali] Dalian Univ Technol, Fac Elect Informat & Elect Engn, Dalian 116024, Peoples R China.
   [Wang, Xingyuan] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
C3 Dalian University of Technology; Dalian Maritime University
RP Wang, XY (corresponding author), Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
EM mansouriali@mail.dlut.edu.cn; wangxy@dlut.edu.cn
RI Wang, Xing-yuan/I-6353-2015
OI MANSOURI, Ali/0000-0002-3418-8166
FU National Natural Science Foundation of China [61672124]; Password Theory
   Project of the 13th Five-Year Plan National Cryptography Development
   Fund [MMJJ 20170203]; Liaoning Province Science and Technology
   Innovation Leading Talents Program Project [XLYC1802013]; Key RAMP;D
   Projects of Liaoning Province [2019020105 - JH2/103]; Jinan City '20
   Universities' Funding Projects Introducing Innovation Team Program
   [2019GXRC031]
FX This research is supported by the National Natural Science Foundation of
   China (no : 61672124), the Password Theory Project of the 13th Five-Year
   Plan National Cryptography Development Fund (no : MMJJ 20170203),
   Liaoning Province Science and Technology Innovation Leading Talents
   Program Project (no : XLYC1802013), Key R&D Projects of Liaoning
   Province (no : 2019020105 - JH2/103), and Jinan City '20 Universities'
   Funding Projects Introducing Innovation Team Program (no : 2019GXRC031).
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Anwar S, 2019, MULTIMED TOOLS APPL, V78, P27569, DOI 10.1007/s11042-019-07852-2
   Cantrell C. D., 2000, Modern Mathematical Methods for Physicists and Engineers, DOI DOI 10.1017/9780511811487
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Chen L, 2017, NONLINEAR DYNAM, V87, P1797, DOI 10.1007/s11071-016-3153-y
   Ghazvini M, 2020, MULTIMED TOOLS APPL, V79, P26927, DOI 10.1007/s11042-020-09058-3
   Hermassi H, 2014, MULTIMED TOOLS APPL, V72, P2211, DOI 10.1007/s11042-013-1533-6
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Hua ZY, 2017, INFORM SCIENCES, V396, P97, DOI 10.1016/j.ins.2017.02.036
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Li B, 2018, MULTIMED TOOLS APPL, V77, P8911, DOI 10.1007/s11042-017-4786-7
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Liu LF, 2016, IET SIGNAL PROCESS, V10, P1096, DOI 10.1049/iet-spr.2015.0522
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Liu YS, 2016, NONLINEAR DYNAM, V84, P2241, DOI 10.1007/s11071-016-2642-3
   Mansouri A, 2021, VISUAL COMPUT, V37, P189, DOI 10.1007/s00371-020-01791-y
   Mansouri A, 2020, INFORM SCIENCES, V520, P46, DOI 10.1016/j.ins.2020.02.008
   Özkaynak F, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P621, DOI 10.1109/UBMK.2017.8093481
   Özkaynak F, 2014, NONLINEAR DYNAM, V78, P1311, DOI 10.1007/s11071-014-1517-8
   Pak C, 2019, MULTIMED TOOLS APPL, V78, P12027, DOI 10.1007/s11042-018-6739-1
   Richman JS, 2000, AM J PHYSIOL-HEART C, V278, pH2039
   ROSENSTEIN MT, 1993, PHYSICA D, V65, P117, DOI 10.1016/0167-2789(93)90009-P
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Skokos C, 2016, LECT NOTES PHYS, V915, P221, DOI 10.1007/978-3-662-48410-4_7
   Su X, 2017, MULTIMED TOOLS APPL, V76, P14021, DOI 10.1007/s11042-016-3800-9
   Talhaoui MZ, 2021, INFORM SCIENCES, V550, P13, DOI 10.1016/j.ins.2020.10.048
   Talhaoui MZ, 2021, VISUAL COMPUT, V37, P541, DOI 10.1007/s00371-020-01822-8
   Talhaoui MZ, 2021, VISUAL COMPUT, V37, P1757, DOI 10.1007/s00371-020-01936-z
   Talhaoui MZ, 2021, J REAL-TIME IMAGE PR, V18, P85, DOI 10.1007/s11554-020-00948-1
   Wang MX, 2021, INFORM SCIENCES, V544, P1, DOI 10.1016/j.ins.2020.07.051
   Wang XY, 2021, MULTIMED TOOLS APPL, V80, P591, DOI 10.1007/s11042-020-09688-7
   Wang XY, 2015, NONLINEAR DYNAM, V79, P1141, DOI 10.1007/s11071-014-1729-y
   Wang YJ, 2020, MULTIMED TOOLS APPL, V79, P18317, DOI 10.1007/s11042-020-08742-8
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Xiao D, 2020, IEEE SIGNAL PROC LET, V27, P296, DOI 10.1109/LSP.2020.2967593
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Yang B, 2018, MULTIMED TOOLS APPL, V77, P21803, DOI 10.1007/s11042-017-5590-0
   Yang YG, 2021, MULTIMED TOOLS APPL, V80, P691, DOI 10.1007/s11042-020-09779-5
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zhou YC, 2013, SIGNAL PROCESS, V93, P3039, DOI 10.1016/j.sigpro.2013.04.021
NR 44
TC 24
Z9 25
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21955
EP 21978
DI 10.1007/s11042-021-10757-8
EA MAR 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000631328800001
DA 2024-07-18
ER

PT J
AU Dami, S
   Esterabi, M
AF Dami, Sina
   Esterabi, Mohammad
TI Predicting stock returns of Tehran exchange using LSTM neural network
   and feature engineering technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stock return prediction; Feature engineering; Deep neural networks; Long
   short-term memory (LSTM); AutoEncoder
AB Prediction is defined as the expression of events that will occur in the future, before they occur, based on scientific and logical principles and rules. Due to the importance of financial markets for economic activists, prediction in this field has received much attention from scholars. Prediction of the stock market, as one of the largest financial markets can be very profitable to the predictors. The dynamic and complexity of the market has added to its appeal to researchers. To date, many researchers have reported good returns for prediction in this market using neural network methods. In this paper, we attempted to obtain better results on Tehran Stock Exchange by using their findings and by applying the Long Short-Term Memory (LSTM) deep neural network. In the area of feature engineering, we have tried to reduce the number of features using AutoEncoder-based feature selection to improve stock returns and reduce prediction error. To evaluate the proposed method, a return measure that is closer to the real world of stock trading was used. Experimental results showed that using the proposed method yielded a better output with a lower error mean.
C1 [Dami, Sina; Esterabi, Mohammad] Islamic Azad Univ, West Tehran Branch, Dept Comp Engn, Tehran, Iran.
C3 Islamic Azad University
RP Dami, S (corresponding author), Islamic Azad Univ, West Tehran Branch, Dept Comp Engn, Tehran, Iran.
EM dami@wtiau.ac.ir
RI Dami, Sina/AAN-5595-2021
OI Dami, Sina/0000-0002-1309-5913
CR Abdoh, 1996, J FINANC RES, V13, P11
   Aiken M, 1999, INFORM SYST MANAGE, V16, P42, DOI 10.1201/1078/43189.16.4.19990901/31202.6
   Anish CM, 2016, J KOREAN STAT SOC, V45, P64, DOI 10.1016/j.jkss.2015.07.002
   [Anonymous], 2019, INT J SCI RES COMPUT
   Asghar MZ, 2019, COMPUT MATH ORGAN TH, V25, P271, DOI 10.1007/s10588-019-09292-7
   Chiang WC, 1996, OMEGA-INT J MANAGE S, V24, P205, DOI 10.1016/0305-0483(95)00059-3
   Cohen K.J., 1977, EXISTENCE SERIAL COR
   Egeli E, 2003, INT J PEDIATR OTORHI, V67, P467, DOI 10.1016/S0165-5876(03)00002-8
   Garliauskas, IEEE SMC 99 C P 1999, V2, P638
   Ho D., 2019, 2019 IEEE CANADIAN C, P1, DOI 10.1109/CCECE.2019.8861550
   Jozefowicz R, 2015, PR MACH LEARN RES, V37, P2342
   Kim KJ, 2000, EXPERT SYST APPL, V19, P125, DOI 10.1016/S0957-4174(00)00027-0
   Lendasse A., 2000, European Journal of Economic and Social Systems, V14, P81, DOI 10.1051/ejess:2000110
   Long W, 2019, KNOWL-BASED SYST, V164, P163, DOI 10.1016/j.knosys.2018.10.034
   Mohanty, 2020, APPL SOFT COMPUT
   Naik N, 2019, COMM COM INF SC, V1000, P445, DOI 10.1007/978-3-030-20257-6_38
   Pal SS, 2019, MATH COMPUT SIMULAT, V162, P18, DOI 10.1016/j.matcom.2019.01.001
   Ramezanian R, 2019, APPL SOFT COMPUT, V82, DOI 10.1016/j.asoc.2019.105551
   Sarasht, 2012, J FIN RES, V13, P23
   Serri, 2017, J EC MANAG PERSPECT, V11, P656
   Singh R, 2017, MULTIMED TOOLS APPL, V76, P18569, DOI 10.1007/s11042-016-4159-7
   Wang WN, 2018, MULTIMED TOOLS APPL, V77, P10123, DOI 10.1007/s11042-017-5144-5
   Wang WN, 2018, MULTIMED TOOLS APPL, V77, P4203, DOI 10.1007/s11042-017-4587-z
   Wang XH, 2020, MULTIMED TOOLS APPL, V79, P2917, DOI 10.1007/s11042-019-08509-w
   Wong KS, 2000, STROKE, V31, P2641, DOI 10.1161/01.STR.31.11.2641
   Yu PF, 2020, NEURAL COMPUT APPL, V32, P1609, DOI 10.1007/s00521-019-04212-x
NR 26
TC 7
Z9 7
U1 2
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19947
EP 19970
DI 10.1007/s11042-021-10778-3
EA MAR 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000625344600001
DA 2024-07-18
ER

PT J
AU Luo, GL
   Zhao, X
   Chen, Q
   Zhu, ZL
   Xian, CH
AF Luo, Guoliang
   Zhao, Xin
   Chen, Qiang
   Zhu, Zhiliang
   Xian, Chuhua
TI Dynamic data reshaping for 3D mesh animation compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D mesh sequence; Compression; Dynamic reshaping; Spatio-temporal
   segmentation
AB Effective compression of 3D mesh animation data has been increasingly used in a variety of multimedia systems including virtual reality, gaming, remote transmission, display and storage. In this work, we propose a spectral clustering-based dynamic reshaping model that is performed on spatio-temporal segments to enhance the compression of 3D mesh sequences. After the lossy compression of spatio-temporal segments through Principal Component Analysis (PCA), we first compute a spectral clustering of all the PCA elements. Then, we introduce three novel reshaping schemes (namely, Row-wise matrix scheme, Arch-wise matrix scheme, and Curl-wise matrix scheme) of the PCA elements within each cluster. Through extensive experiments and comparisons, we show our model can substantially improve the compression performances on various 3D mesh sequences.
C1 [Luo, Guoliang; Zhao, Xin; Chen, Qiang; Zhu, Zhiliang] East China Jiaotong Univ, Nanchang, Jiangxi, Peoples R China.
   [Xian, Chuhua] South China Univ Technol, Guangzhou, Peoples R China.
C3 East China Jiaotong University; South China University of Technology
RP Luo, GL (corresponding author), East China Jiaotong Univ, Nanchang, Jiangxi, Peoples R China.
EM luoguoliang@ecjtu.edu.cn
RI Li, Ly/JCD-4746-2023; li, yao/IYJ-1364-2023; Liu, Gui/JHU-8707-2023;
   liu, xq/JDW-2596-2023; Yang, Ying/ABD-2481-2022
OI Chen, Qiang/0000-0002-3642-8119; Zhiliang, Zhu/0000-0002-0939-0741
FU National Natural Science Foundation of China [61962021, 51978271]; Key
   Research Program of Jiangxi Province [20202ACBL202008]; Key Research and
   Development Program of Jiangxi Province [20192BBE50079]; China
   Postdoctoral Science Foundation [2020T130264, 2019M662261]; Innovation
   Fund Designated for Graduate Students of Jiangxi Province [YC2019-S269]
FX This work has been jointly supported by the National Natural Science
   Foundation of China under Grant 61962021 and 51978271, the Key Research
   Program of Jiangxi Province under Grant 20202ACBL202008, the Key
   Research and Development Program of Jiangxi Province under Grant
   20192BBE50079 and the China Postdoctoral Science Foundation under Grant
   2020T130264 and 2019M662261 and the Innovation Fund Designated for
   Graduate Students of Jiangxi Province YC2019-S269.
CR de Queiroz RL, 2016, IEEE T IMAGE PROCESS, V25, P3947, DOI 10.1109/TIP.2016.2575005
   Deutsch Peter, 1996, RFC 1950
   Gandoin PM, 2002, ACM T GRAPHIC, V21, P372, DOI 10.1145/566570.566591
   Guskov I., 2004, Proc. 2004 ACM SIG- GRAPH/Eurographics Symp. Comput. Animation (SCA '04), P183
   Hajizadeh M, 2019, VISUAL COMPUT, P1
   Hajizadeh M, 2018, MULTIMED TOOLS APPL, V77, P19347, DOI 10.1007/s11042-017-5394-2
   Jolliffe I.T., 1986, PRINCIPAL COMPONENT, P129, DOI 10.1007/978-1-4757-1904-8_8
   Karni Z, 2004, COMPUT GRAPH-UK, V28, P25, DOI 10.1016/j.cag.2003.10.002
   Khodakovsky A, 2000, COMP GRAPH, P271, DOI 10.1145/344779.344922
   Lalos AS, 2017, VISUAL COMPUT, V33, P811, DOI 10.1007/s00371-017-1395-4
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Luo GL, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3377475
   Maglo A, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2693443
   Maglo A, 2013, COMPUT GRAPH-UK, V37, P743, DOI 10.1016/j.cag.2013.05.005
   Nasiri F, 2019, INT CONF ACOUST SPEE, P4015, DOI 10.1109/ICASSP.2019.8683258
   Pele O, 2009, IEEE I CONF COMP VIS, P460, DOI 10.1109/ICCV.2009.5459199
   Rubner Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P59, DOI 10.1109/ICCV.1998.710701
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Valette S, 2004, IEEE T VIS COMPUT GR, V10, P123, DOI 10.1109/TVCG.2004.1260764
   Vása L, 2014, COMPUT GRAPH FORUM, V33, P145, DOI 10.1111/cgf.12304
   Vása L, 2009, COMPUT GRAPH FORUM, V28, P1529, DOI 10.1111/j.1467-8659.2008.01304.x
   Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696
NR 22
TC 5
Z9 5
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 55
EP 72
DI 10.1007/s11042-021-10629-1
EA MAR 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000623716500008
DA 2024-07-18
ER

PT J
AU Maharjan, R
   Alsadoon, A
   Prasad, PWC
   Giweli, N
   Alsadoon, OH
AF Maharjan, Reena
   Alsadoon, Abeer
   Prasad, P. W. C.
   Giweli, Nabil
   Alsadoon, Omar Hisham
TI A novel secure solution of using mixed reality in data transmission for
   bowel and jaw surgical training: markov property using SHA 256
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mixed reality; Telepresence surgical training; Chaotic map with Markov
   property; SHA-256; Confusion; Diffusion
AB Telepresence surgical training based on mixed reality over the Internet is exposed to various cyber-attacks. Providing an adequate level of security against such attacks becomes an essential requirement for implementing this technology. The aim of this work is to improve the security of data transmission against several potential attacks while reducing the required execution time for encryption and decryption during real-time surgical telepresence training. In this research, a cryptosystem based on an enhanced chaotic map with Markov property using the Secure Hash Algorithm with 256-bit (SHA-256) is proposed to secure data during transmission. The enhanced chaotic map governs the diffusion process for image ciphering. The proposed scheme reduces the average processing time by 23.49%, i.e., from 83.99 ms (millisecond) to 64.33 ms, compared to the current state of the art solution, which is used as a benchmark in this work. Moreover, the Peak Signal to Noise Ratio (PSNR), which is used for measuring the encryption strength, is reduced by 17.33%, i.e., from 36.13 dB (decibel) to 29.87 dB compared to the same benchmark. The proposed solution demonstrates significant improvement in securing data against brute force attack, known-plaintext attack, chosen-plaintext attack and other statistical attacks. Also, the solution reduces the processing time required for both encryption and decryption.
C1 [Maharjan, Reena; Alsadoon, Abeer; Prasad, P. W. C.] Charles Sturt Univ CSU, Sch Comp & Math, Wagga Wagga, NSW, Australia.
   [Alsadoon, Abeer; Giweli, Nabil] Univ Western Sydney UWS, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Southern Cross Univ SCU, Sch Informat Technol, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Asia Pacific Int Coll APIC, Informat Technol Dept, Sydney, NSW, Australia.
   [Alsadoon, Omar Hisham] Al Iraqia Univ, Dept Islamic Sci, Baghdad, Iraq.
C3 Charles Sturt University; Western Sydney University; Southern Cross
   University; Al-Iraqia University
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp & Math, Wagga Wagga, NSW, Australia.; Alsadoon, A (corresponding author), Univ Western Sydney UWS, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Southern Cross Univ SCU, Sch Informat Technol, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Informat Technol Dept, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; Alsadoon, Omar
   Hisham/0000-0001-7797-6392; withana, chandana/0000-0002-3007-687X
CR Alfalou A, 2011, OPT EXPRESS, V19, P24023, DOI 10.1364/OE.19.024023
   Cecil J, 2018, INT J COMPUT ASS RAD, V13, P305, DOI 10.1007/s11548-017-1688-0
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Dalal M, 2019, MULTIMED TOOLS APPL, V78, P5769, DOI 10.1007/s11042-018-6093-3
   Darwish SM, 2019, MULTIMED TOOLS APPL, V78, P19229, DOI 10.1007/s11042-019-7256-6
   Ebrahim M, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM, COMPUTING AND ENGINEERING (ICCSCE 2013), P557, DOI 10.1109/ICCSCE.2013.6720027
   Erridge S, 2019, SURG INNOV, V26, P95, DOI 10.1177/1553350618813250
   Fawaz Z, 2016, SIGNAL PROCESS-IMAGE, V42, P90, DOI 10.1016/j.image.2016.01.009
   Ge M, 2019, EGYPT INFORM J, V20, P45, DOI 10.1016/j.eij.2018.10.001
   Hamdi M, 2017, SIGNAL PROCESS, V131, P514, DOI 10.1016/j.sigpro.2016.09.011
   Himeur Y, 2018, MULTIMED TOOLS APPL, V77, P8603, DOI 10.1007/s11042-017-4754-2
   Huang XL, 2012, NONLINEAR DYNAM, V67, P2411, DOI 10.1007/s11071-011-0155-7
   Jridi M, 2018, OPT LASER ENG, V102, P59, DOI 10.1016/j.optlaseng.2017.10.007
   Lian SG, 2006, IEEE T CONSUM ELECTR, V52, P621, DOI 10.1109/TCE.2006.1649688
   Liu FW, 2010, COMPUT SECUR, V29, P3, DOI 10.1016/j.cose.2009.06.004
   Liu YX, 2016, NEUROCOMPUTING, V188, P63, DOI 10.1016/j.neucom.2014.10.109
   Liu ZJ, 2010, OPT LASER ENG, V48, P800, DOI 10.1016/j.optlaseng.2010.02.005
   Mirzaei O, 2012, NONLINEAR DYNAM, V67, P557, DOI 10.1007/s11071-011-0006-6
   Murali P, 2019, MULTIMED TOOLS APPL, V78, P2135, DOI 10.1007/s11042-018-6234-8
   Nkandeu YPK, 2019, MULTIMED TOOLS APPL, V78, P10013, DOI 10.1007/s11042-018-6612-2
   Noura HN, 2019, MULTIMED TOOLS APPL, V78, P14837, DOI 10.1007/s11042-018-6845-0
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Premkumar R, 2019, MULTIMED TOOLS APPL, V78, P9577, DOI 10.1007/s11042-018-6534-z
   Rajalakshmi K, 2018, MULTIMED TOOLS APPL, V77, P13225, DOI 10.1007/s11042-017-4942-0
   Sakthivel SM, 2018, MULTIMED TOOLS APPL, V77, P26793, DOI 10.1007/s11042-018-5889-5
   Shah RA, 2019, MULTIMED TOOLS APPL, V78, P21455, DOI 10.1007/s11042-019-7451-5
   Shahid Z, 2011, IEEE T CIRC SYST VID, V21, P565, DOI 10.1109/TCSVT.2011.2129090
   Som S, 2019, MULTIMED TOOLS APPL, V78, P10373, DOI 10.1007/s11042-018-6539-7
   Tabash FK, 2019, MULTIMED TOOLS APPL, V78, P7365, DOI 10.1007/s11042-018-6494-3
   Taneja N, 2012, MULTIMED TOOLS APPL, V59, P775, DOI 10.1007/s11042-011-0775-4
   ur Rehman M. M. S., 2019, MULTIMED TOOLS APPL, P1
   Wagle A., 2018, AM J APPL SCI, V15, P476, DOI [10.3844/ajassp.2018.476.488, DOI 10.3844/AJASSP.2018.476.488]
   Wang XY, 2015, COMPUT ELECTR ENG, V46, P403, DOI 10.1016/j.compeleceng.2015.04.001
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhu SQ, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20090716
NR 36
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18917
EP 18939
DI 10.1007/s11042-021-10674-w
EA FEB 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000620422600004
DA 2024-07-18
ER

PT J
AU Kang, JS
   Chung, K
   Hong, EJ
AF Kang, Ji-Soo
   Chung, Kyungyong
   Hong, Ellen J.
TI Multimedia knowledge-based bridge health monitoring using digital twin
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Knowledge; Bridge health monitoring; Digital twin; Modeling and
   simulation; Data model
AB Digital twins are virtual replicas of real physical entities in computers. They can be considered as abstract digital models of data and behavior for objects of interest. Nevertheless, they are not perfectly consistent with conventional data or simulation models because they achieve prediction and optimization by simulating the abstract digital model of a particular system. To maintain the characteristics of digital twins in the virtual space, digital simulation models that continue to update, change, and evolve according to continuous changes of corresponding physical factors must be used. Owing to the various advantages of digital twin technology, digital twins have gained more attention. However, the method to create digital twins is still unclear. Additionally, the availability and sufficiency of information on physical entities to which digital twins will be applied must be considered, and a model suitable for their application must be designed. Therefore, multimedia knowledge-based bridge health monitoring using digital twins is proposed herein. It synchronizes real and virtual spaces to reflect the reality based on various data collected using sensors of real systems. In this study, various situations of virtual bridge twins in a facility management area are simulated to provide digital services to ensure bridge health. This digital bridge health service analyzes situations based on a small amount of data collected from a bridge, predicts the optimal time point for maintenance, and then applies it to the real world. Hence, maintenance costs can be reduced and the bridge's lifespan extended.
C1 [Kang, Ji-Soo] Kyonggi Univ, Dept Comp Sci, 154-42 Gwanggyosan Ro, Suwon 16227, Gyeonggi Do, South Korea.
   [Chung, Kyungyong] Kyonggi Univ, Div AI Comp Sci & Engn, 154-42 Gwanggyosan Ro, Suwon 16227, Gyeonggi Do, South Korea.
   [Hong, Ellen J.] Yonsei Univ, Dept Software, Wonju 26493, South Korea.
C3 Kyonggi University; Kyonggi University; Yonsei University
RP Hong, EJ (corresponding author), Yonsei Univ, Dept Software, Wonju 26493, South Korea.
EM kangjs920@gmail.com; dragonhci@gmail.com; ellenhong@yonsei.ac.kr
RI Chung, Kyungyong/JAC-2276-2023
OI Hong, Jeong hee/0000-0002-0948-9944; Chung,
   Kyungyong/0000-0002-6439-9992
FU Korea Agency for Infrastructure Technology Advancement(KAIA) - Ministry
   of Land, Infrastructure and Transport [21CTAP-C157011-02]
FX This work is supported by the Korea Agency for Infrastructure Technology
   Advancement(KAIA) grant funded by the Ministry of Land, Infrastructure
   and Transport (Grant 21CTAP-C157011-02).
CR [Anonymous], Smart City Korea
   [Anonymous], CITY BRAIN ALIBABA C
   [Anonymous], VIRTUAL SINGAPORE NA
   Bondarenko O, 2020, ENERGY, V196, DOI 10.1016/j.energy.2020.117126
   Fan C, 2021, INT J INFORM MANAGE, V56, DOI 10.1016/j.ijinfomgt.2019.102049
   Kabak KE, 2019, PROCEDIA MANUF, V39, P794, DOI 10.1016/j.promfg.2020.01.428
   Kang JS, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9204284
   Kim BS, 2020, IEEE ACCESS, V8, P24056, DOI 10.1109/ACCESS.2020.2970547
   Kim JC, 2020, IEEE ACCESS, V8, P104933, DOI 10.1109/ACCESS.2020.2997255
   Kritzinger W, 2018, IFAC PAPERSONLINE, V51, P1016, DOI 10.1016/j.ifacol.2018.08.474
   Lee Jay, 2015, Manufacturing Letters, V3, P18, DOI 10.1016/j.mfglet.2014.12.001
   Lee KH, 2015, ETRI J, V37, P175
   Madni AM, 2019, SYSTEMS-BASEL, V7, DOI 10.3390/systems7010007
   Maria A, 1997, PROCEEDINGS OF THE 1997 WINTER SIMULATION CONFERENCE, P7, DOI 10.1145/268437.268440
   Predix, DIGITAL
   Qi QL, 2021, J MANUF SYST, V58, P3, DOI 10.1016/j.jmsy.2019.10.001
   Schroeder G, 2016, IEEE INTL CONF IND I, P522, DOI 10.1109/INDIN.2016.7819217
   Schroeder GN, 2016, IFAC PAPERSONLINE, V49, P12, DOI 10.1016/j.ifacol.2016.11.115
   Schwab Klaus, 2017, 4 IND REVOLUTION, DOI DOI 10.1080/10686967.2018.1436355
   Söderberg R, 2017, CIRP ANN-MANUF TECHN, V66, P137, DOI 10.1016/j.cirp.2017.04.038
   Stark R, 2019, CIRP ANN-MANUF TECHN, V68, P129, DOI 10.1016/j.cirp.2019.04.024
   Tao F, 2018, INT J ADV MANUF TECH, V94, P3563, DOI 10.1007/s00170-017-0233-1
   Vachálek J, 2017, 2017 21ST INTERNATIONAL CONFERENCE ON PROCESS CONTROL (PC), P258, DOI 10.1109/PC.2017.7976223
   Velosa A., 2016, USE IOT PLATFORM REF
   Ye C., 2019, 12 INT WORKSH STRUCT, DOI DOI 10.12783/SHM2019/32287
NR 25
TC 48
Z9 51
U1 41
U2 284
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34609
EP 34624
DI 10.1007/s11042-021-10649-x
EA FEB 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000618948700005
DA 2024-07-18
ER

PT J
AU Sugandhi, K
   Wahid, FF
   Raju, G
AF Sugandhi, K.
   Wahid, Farha Fatina
   Raju, G.
TI Statistical features from frame aggregation and differences for human
   gait recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human gait recognition; Frame aggregation features; Inter-frame
   differences; One-against; All block differences; Silhouette centroid
ID FLOW
AB Human gait recognition, an alternate biometric technique, received significant attention in the last decade. As many gait recognition applications require real-time response, the primary concern is to design efficient and straightforward gait features for human recognition. In this work, two novel gait features are proposed. Both features are designed by exploring the dynamic variations of different body parts during a gait cycle. The first feature set is based on one-against-all gait frame differences for person identification. This novel approach divides each frame in a gait cycle to blocks, compute the block sum, and then find the difference of respective block sum between the first frame and the rest. The second feature set is defined on the first-order statistics of the normalized sum of the frames in a cycle. Two other existing features- Centroid of Silhouette frames and feature values defined on Change Energy Images are also considered. Feature level fusion is realized by considering the different combinations of the four types of features. Experiments carried out with the CASIA Gait Dataset B demonstrated the proposal's merit with high recognition accuracy. The outcome of the investigations is promising when compared to recent contributions.
C1 [Sugandhi, K.; Wahid, Farha Fatina] Kannur Univ, Dept Informat Technol, Kannur, Kerala, India.
   [Raju, G.] Christ, Dept Comp Sci & Engn, Bengaluru, India.
C3 Christ University
RP Sugandhi, K (corresponding author), Kannur Univ, Dept Informat Technol, Kannur, Kerala, India.
EM sugandhikgs@gmail.com
RI Kurup, Raju/T-9795-2019; Wahid, Farha Fatina/Y-3682-2019; K, Dr.
   Sugandhi/H-7767-2012
OI Kurup, Raju/0000-0002-7871-1801; K, Dr. Sugandhi/0000-0002-9177-0072
FU Department of Science and Technology (DST), New Delhi
FX The authors would like to acknowledge the Department of Science and
   Technology (DST), New Delhi for the financial support extended under the
   INSPIRE fellowship scheme.
CR Andrie BR, 2011, REV CHINESE ACAD SCI
   Anusha R, 2020, MULTIMED TOOLS APPL, V79, P2873, DOI 10.1007/s11042-019-08400-8
   Arora P, 2015, PROCEDIA COMPUT SCI, V58, P408, DOI 10.1016/j.procs.2015.08.049
   Arshad H, 2019, INT J MACH LEARN CYB, V10, P3601, DOI 10.1007/s13042-019-00947-0
   Bashir K., 2010, the British Machine Vision Conference, P1, DOI DOI 10.1049/IC.2009.0230
   Bashir K, 2010, PATTERN RECOGN LETT, V31, P2052, DOI 10.1016/j.patrec.2010.05.027
   Bouchrika I, 2007, LECT NOTES COMPUTER, V4418
   Chen X, 2018, IEEE T PATTERN ANAL, V40, P1697, DOI 10.1109/TPAMI.2017.2726061
   Das S, 2004, P ANN INT IEEE EMBS, V26, P4568
   El-Alfy H, 2018, IEEE T CYBERNETICS, V48, P1526, DOI 10.1109/TCYB.2017.2705799
   Guru VGM, 2018, DATA ANAL LEARN, V43, P51, DOI [10.1007/978-981-13-2514-4_5, DOI 10.1007/978-981-13-2514-4_5]
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   He YW, 2019, IEEE T INF FOREN SEC, V14, P102, DOI 10.1109/TIFS.2018.2844819
   Huang GH, 2020, IEEE ACCESS, V8, P75381, DOI 10.1109/ACCESS.2020.2986554
   Janssen D, 2008, J NONVERBAL BEHAV, V32, P79, DOI 10.1007/s10919-007-0045-3
   JOHANSSON G, 1975, SCI AM, V232, P76, DOI 10.1038/scientificamerican0675-76
   Lam THW, 2005, LECT NOTES COMPUTER
   Lee TKM, 2014, MULTIMED TOOLS APPL, V72, P2833, DOI 10.1007/s11042-013-1574-x
   Lishani AO, 2019, MULTIMED TOOLS APPL, V78, P5715, DOI 10.1007/s11042-018-5752-8
   Liu Y.Q., 2011, PROCEDIA ENG, P1832
   Mahfouf Z, 2018, NEUROCOMPUTING, V283, P140, DOI 10.1016/j.neucom.2017.12.040
   Mehmood A, 2024, MULTIMED TOOLS APPL, V83, P14979, DOI 10.1007/s11042-020-08928-0
   Mohan Kumar H. P., 2014, International Journal of Image, Graphics and Signal Processing, V6, P1, DOI 10.5815/ijigsp.2014.04.01
   More SA, 2018, IEEE-CAA J AUTOMATIC, V5, P718, DOI 10.1109/JAS.2018.7511081
   Nabila M, 2018, IET BIOMETRICS, V7, P116, DOI 10.1049/iet-bmt.2016.0176
   Protas EJ, 2005, NEUROREHABILITATION, V20, P183
   Shirke S, 2014, INT CONF COMM SYST, P891, DOI 10.1109/CSNT.2014.252
   Sudha LR, 2014, INT J COMPUT APPL T, V49, P113, DOI 10.1504/IJCAT.2014.060522
   Sugandhi K, 2019, PROCEEDINGS 2019 AMITY INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AICAI), P355, DOI [10.1109/aicai.2019.8701366, 10.1109/AICAI.2019.8701366]
   Sugandhi K, 2019, INT J BIOMETRICS, V11, P148, DOI 10.1504/IJBM.2019.099033
   Sugandhi K, 2017, COMM COM INF SC, V721, P377, DOI 10.1007/978-981-10-5427-3_40
   Sugandhi K, 2019, COMMUNICATIONS COMPU
   Sugandhi K., 2019, INT C DATA SCI COMMU, P1
   Wang H, 2018, INT J MACH LEARN CYB, V9, P569, DOI 10.1007/s13042-016-0540-0
   Wang XH, 2018, MULTIMED TOOLS APPL, V77, P12545, DOI 10.1007/s11042-017-4903-7
   Xu WJ, 2018, PATTERN RECOGN LETT, V107, P75, DOI 10.1016/j.patrec.2017.10.033
   Yoo JH, 2005, LECT NOTES COMPUT SC, V3708, P138
   Yu SQ, 2019, PATTERN RECOGN, V87, P179, DOI 10.1016/j.patcog.2018.10.019
   Zborowski M., 2015, Wiley Encyclopedia of Electrical and Electronics Engineering, P1, DOI DOI 10.1002/047134608X.W8236
NR 39
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18345
EP 18364
DI 10.1007/s11042-021-10655-z
EA FEB 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000618948700010
DA 2024-07-18
ER

PT J
AU Trojahn, TH
   Goularte, R
AF Trojahn, Tiago Henrique
   Goularte, Rudinei
TI Temporal video scene segmentation using deep-learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Video; Temporal scene segmentation; Scene boundary
   detection; Deep learning
ID PERFORMANCE EVALUATION; SHOT; RETRIEVAL; FUSION
AB The automatic temporal video scene segmentation (also known as video story segmentation) is still an open problem without definite solutions in most cases. Among the available techniques, the ones which shows better results are multimodal using features extracted from multiple modalities. Multimodal fusion may be performed to fuse each modality as a single representation (early fusion) or by each modality segmentation (late fusion), the latter been widely due to multimodal fusion simplicity. Recently, deep learning techniques such as convolutional neural networks (CNN) has been successfully employed to extract features from multiple data sources, easing the development of early fusion methods. However, CNNs cannot adequately learn cues which are temporally distributed along the video due to difficulties to model temporal features data dependencies. A particular deep learning approach which can learn such cues is the recurrent neural network (RNN). Successfully employed on text processing, RNNs are fitted to analyze sequences of data of variable length and may better grasp the temporal relationship among low-level features of video segments, hopefully obtaining more accurate scene boundary detection. This paper goes beyond direct applying RNNs and proposes a new multimodal approach to temporally segment a video into scenes. This approach builds a new architecture carefully combining CNN and RNN capabilities, obtaining better efficacy results on the task when compared with related techniques on a public video dataset.
C1 [Trojahn, Tiago Henrique] Fed Inst Sao Paulo, Sao Carlos, SP, Brazil.
   [Goularte, Rudinei] Univ Sao Paulo, Inst Ciencias Matemat & Comp, Sao Carlos, SP, Brazil.
C3 Instituto Federal de Sao Paulo (IFSP); Universidade de Sao Paulo
RP Trojahn, TH (corresponding author), Fed Inst Sao Paulo, Sao Carlos, SP, Brazil.
EM tiagotrojahn@ifsp.edu.br; rudinei@icmc.usp.br
RI Goularte, Rudinei/E-2441-2011
OI Trojahn, Tiago Henrique/0000-0002-1826-4456
CR [Anonymous], 2009, P 17 ACM INT C MULT, DOI DOI 10.1145/1631272.1631383
   [Anonymous], 2007, Multimedia retrieval
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Ballan L, 2010, MULTIMED TOOLS APPL, V48, P69, DOI 10.1007/s11042-009-0351-3
   Baraldi L, 2017, PROC CVPR IEEE, P3185, DOI 10.1109/CVPR.2017.339
   Baraldi L, 2017, IEEE T MULTIMEDIA, V19, P955, DOI 10.1109/TMM.2016.2644872
   Baraldi L, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1199, DOI 10.1145/2733373.2806316
   Baraldi L, 2015, LECT NOTES COMPUT SC, V9256, P801, DOI 10.1007/978-3-319-23192-1_67
   Baraldi L, 2015, LECT NOTES COMPUT SC, V9117, P395, DOI 10.1007/978-3-319-19390-8_45
   Barbieri TTS, 2015, 30TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, VOLS I AND II, P1257, DOI 10.1145/2695664.2695841
   Bengio Yoshua, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P437, DOI 10.1007/978-3-642-35289-8_26
   BLAIR DC, 1979, J AM SOC INFORM SCI, V30, P374, DOI 10.1002/asi.4630300621
   Bolle RM, 1998, IBM J RES DEV, V42, P233, DOI 10.1147/rd.422.0233
   Burghouts GJ, 2009, COMPUT VIS IMAGE UND, V113, P48, DOI 10.1016/j.cviu.2008.07.003
   Caruccio L, 2019, EXPERT SYST APPL, V131, P190, DOI 10.1016/j.eswa.2019.04.031
   Chasanis V., 2009, Proceedings of the ACM International Conference on Image and Video Retrieval, p35:1, DOI DOI 10.1145/1646396.1646439
   Chasanis VT, 2009, IEEE T MULTIMEDIA, V11, P89, DOI 10.1109/TMM.2008.2008924
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen L, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P737
   Cho K., 2014, ARXIV14061078
   Del Fabro M, 2013, MULTIMEDIA SYST, V19, P427, DOI 10.1007/s00530-013-0306-4
   DESOUZA TT, 2013, P 28 ANN ACM S APPL, P961, DOI DOI 10.1145/2480362.2480547
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Goularte R, 2009, P 15 BRAZ S MULT WEB, P1, DOI [10.1145/1858477.1858520, DOI 10.1145/1858477.1858520]
   Gupta A, 2013, 2013 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND SIGNAL PROCESSING (ISSP), P170, DOI 10.1109/ISSP.2013.6526896
   Gygli M., 2018, 2018 INT C CONT BAS, P1
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P580, DOI 10.1109/76.767124
   Hare J.S., 2011, Proceedings of the 19th ACM International Conference on Multimedia, P691, DOI 10.1145/2072298.2072421
   Haroon M, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/2564963
   Hassanien A., 2017, Large-scale, fast and accurate shot boundary detection through spatio-temporal convolutional neural networks
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jacobs C. E., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P277, DOI 10.1145/218380.218454
   Jones E., 2001, SciPy: Open source scientific tools for Python
   Jozefowicz R, 2015, PR MACH LEARN RES, V37, P2342
   Kishi RM, 2019, MULTIMED TOOLS APPL, V78, P15623, DOI 10.1007/s11042-018-6959-4
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar N, 2019, ADV INTELL SYST COMP, V741, P771, DOI 10.1007/978-981-13-0761-4_74
   Lipton Z. C., 2015, ARXIV
   Liu ZT, 2018, IEEE INFOCOM SER, P1, DOI 10.1109/INFOCOM.2018.8486219
   Lopes BL., 2014, J INFORM DATA MANAGE, V5, P194
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   NEEDLEMAN SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Protasov S, 2018, SIGNAL IMAGE VIDEO P, V12, P991, DOI 10.1007/s11760-018-1244-6
   Rasheed Z, 2005, IEEE T MULTIMEDIA, V7, P1097, DOI 10.1109/TMM.2005.858392
   Rasheed Z, 2003, PROC CVPR IEEE, P343
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   ROTMAN D, 2017, 2017 IEEE 19 INT WOR, P1
   Rotman D, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P187, DOI 10.1145/3206025.3206055
   Rotman D, 2016, IEEE INT SYM MULTIM, P275, DOI [10.1109/ISM.2016.0061, 10.1109/ISM.2016.117]
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sidiropoulos P, 2012, IEEE T CIRC SYST VID, V22, P904, DOI 10.1109/TCSVT.2011.2181231
   Sidiropoulos P, 2011, IEEE T CIRC SYST VID, V21, P1163, DOI 10.1109/TCSVT.2011.2138830
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Sperandio R., 2014, J INFECTION, V5, P181
   Trojahn, 2013, P 19 BRAZ S MULT WEB, P23, DOI [10.1145/2526188.2526206, DOI 10.1145/2526188.2526206]
   Trojahn TH, 2018, WEBMEDIA'18: PROCEEDINGS OF THE 24TH BRAZILIAN SYMPOSIUM ON MULTIMEDIA AND THE WEB, P205, DOI 10.1145/3243082.3243108
   Vendrig J, 2002, IEEE T MULTIMEDIA, V4, P492, DOI 10.1109/TMM.2002.802021
   Wiatowski T, 2018, IEEE T INFORM THEORY, V64, P1845, DOI 10.1109/TIT.2017.2776228
   Xie RF, 2011, IEEE INT C BIO BIO W, P165, DOI 10.1109/BIBMW.2011.6112370
   Xu JW, 2016, 2016 30TH ANNIVERSARY OF VISUAL COMMUNICATION AND IMAGE PROCESSING (VCIP)
   Yeung M, 1998, COMPUT VIS IMAGE UND, V71, P94, DOI 10.1006/cviu.1997.0628
   YEUNG MM, 1995, P SOC PHOTO-OPT INS, V2417, P399, DOI 10.1117/12.206067
   Zengchang Qin, 2013, Advanced Data Mining and Applications. 9th International Conference, ADMA 2013. Proceedings: LNCS 8346, P564, DOI 10.1007/978-3-642-53914-5_48
   Zhao B, 2018, PROC CVPR IEEE, P7405, DOI 10.1109/CVPR.2018.00773
NR 69
TC 9
Z9 9
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 17487
EP 17513
DI 10.1007/s11042-020-10450-2
EA FEB 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000616158900003
DA 2024-07-18
ER

PT J
AU Chen, Y
   Gao, Y
AF Chen, Yong
   Gao, Yi
TI Image denoising via iterative diffusion methods combining two
   edge-indicators with adaptive thresholds
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Anisotropic diffusion; Diffusion coefficients; Spatial
   gradient; Local gray-level variance; Adaptive thresholds
AB This paper presents two effective iterative diffusion models equipped with new diffusion coefficients and adaptive thresholds for image denoising. First, two new diffusion coefficients which adopt two distinct edge-indicators (i.e., spatial gradient and local gray-level variance) to capture discontinuities in an image, are proposed to improve the robustness of the proposed models. Second, two tractable adaptive thresholds of the diffusion coefficients are further proposed to enhance the capability for feature preservation. Third, a series of experiments are conducted to verify the effectiveness of the proposed models with regard to the quantitative metrics and visual performance. Overall, compared to the traditional anisotropic diffusion models, the proposed models can improve the average of PSNR by 2.4% and SSIM by 5.3% with the desirable visual performance.
C1 [Chen, Yong] Xihua Univ, Sch Econ, Chengdu 610039, Peoples R China.
   [Gao, Yi] Southwest Jiaotong Univ, Logist & Capital Construct Off, Chengdu 610031, Peoples R China.
C3 Xihua University; Southwest Jiaotong University
RP Chen, Y (corresponding author), Xihua Univ, Sch Econ, Chengdu 610039, Peoples R China.
EM xihua_ychen@163.com; 1300073689@qq.com
FU Key Program from Data Recovery Key Laboratory of Sichuan Province
   [DRN19013]
FX The work was supported by Key Program from Data Recovery Key Laboratory
   of Sichuan Province (Grant No. DRN19013).
CR ALVAREZ L, 1992, SIAM J NUMER ANAL, V29, P845, DOI 10.1137/0729052
   Aymaz S, 2020, MULTIMED TOOLS APPL, V79, P13311, DOI 10.1007/s11042-020-08670-7
   Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   CATTE F, 1992, SIAM J NUMER ANAL, V29, P182, DOI 10.1137/0729012
   Chao SM, 2010, PATTERN RECOGN LETT, V31, P2012, DOI 10.1016/j.patrec.2010.06.004
   Chen K, 2005, IEEE T PATTERN ANAL, V27, P1552, DOI 10.1109/TPAMI.2005.190
   Chen Q, 2010, SIGNAL PROCESS, V90, P1963, DOI 10.1016/j.sigpro.2009.12.015
   Cho SI, 2014, PATTERN RECOGN LETT, V46, P36, DOI 10.1016/j.patrec.2014.05.003
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dhargupta S, 2019, MULTIMED TOOLS APPL, V78, P17589, DOI 10.1007/s11042-018-7123-x
   Gilboa G, 2004, IEEE T PATTERN ANAL, V26, P1020, DOI 10.1109/TPAMI.2004.47
   Gilboa G, 2002, IEEE T IMAGE PROCESS, V11, P689, DOI 10.1109/TIP.2002.800883
   Guo ZC, 2012, IEEE T IMAGE PROCESS, V21, P958, DOI 10.1109/TIP.2011.2169272
   Gupta D, 2015, IET IMAGE PROCESS, V9, P107, DOI 10.1049/iet-ipr.2014.0330
   Hajiaboli MR, 2011, INT J COMPUT VISION, V92, P177, DOI 10.1007/s11263-010-0330-1
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Immerkaer J, 1996, COMPUT VIS IMAGE UND, V64, P300, DOI 10.1006/cviu.1996.0060
   Khan NU, 2014, MULTIMED TOOLS APPL, V73, P573, DOI 10.1007/s11042-013-1620-8
   Khan NU, 2013, SIGNAL PROCESS, V93, P1684, DOI 10.1016/j.sigpro.2012.09.009
   Lefkimmiatis S, 2012, IEEE T IMAGE PROCESS, V21, P983, DOI 10.1109/TIP.2011.2168232
   Liu D, 2020, IEEE T IMAGE PROCESS, V29, P3695, DOI 10.1109/TIP.2020.2964518
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Prasath VBS, 2015, IEEE T IMAGE PROCESS, V24, P5220, DOI 10.1109/TIP.2015.2479471
   Prokhorov Yu.V., 1969, PROBABILITY THEORY, DOI [10.1007/978-3-642-87934-0, DOI 10.1007/978-3-642-87934-0]
   Rafsanjani HK, 2016, COMPUT MATH APPL, V72, P893, DOI 10.1016/j.camwa.2016.06.005
   Siddig A, 2018, COMPUT MATH APPL, V76, P1056, DOI 10.1016/j.camwa.2018.05.040
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang Y, 2007, IEEE T IMAGE PROCESS, V16, P1854, DOI 10.1109/TIP.2007.899002
   Weickert J, 1999, INT J COMPUT VISION, V31, P111, DOI 10.1023/A:1008009714131
   Xiankai Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8957, DOI 10.1109/CVPR42600.2020.00898
   Xu JT, 2016, SIGNAL PROCESS, V119, P80, DOI 10.1016/j.sigpro.2015.07.017
   Yang JH, 2019, COMPUT MATH APPL, V77, P1255, DOI 10.1016/j.camwa.2018.11.003
   Yang M, 2013, NEUROCOMPUTING, V120, P262, DOI 10.1016/j.neucom.2012.08.063
   Yao WJ, 2019, SIAM J IMAGING SCI, V12, P839, DOI 10.1137/18M1187192
   You YL, 2000, IEEE T IMAGE PROCESS, V9, P1723, DOI 10.1109/83.869184
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang L, 2010, PATTERN RECOGN, V43, P1531, DOI 10.1016/j.patcog.2009.09.023
   Zuo WM, 2014, IEEE T IMAGE PROCESS, V23, P2459, DOI 10.1109/TIP.2014.2316423
NR 42
TC 1
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 16027
EP 16044
DI 10.1007/s11042-021-10556-1
EA FEB 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000615771800003
DA 2024-07-18
ER

PT J
AU Cabri, G
   Gherardini, L
   Montangero, M
   Muzzini, F
AF Cabri, Giacomo
   Gherardini, Luca
   Montangero, Manuela
   Muzzini, Filippo
TI About auction strategies for intersection management when human-driven
   and autonomous vehicles coexist
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Autonomous vehicles; Coordination; Auction
AB Autonomous vehicles are appearing in our streets, and will soon populate our transportation infrastructures, which must be equipped with appropriate sensors and actuators in order to manage vehicles in a fruitful way. Besides the infrastructures, appropriate algorithms must be defined in order to coordinate the vehicles and to enable them to exploit the resources in a fair yet effective way. In the immediate future, autonomous vehicles must coexist human-driven vehicles, and this transitory scenario poses several challenges in coordinating both kinds to exploit street resources. One of these resources, whose management is quite challenging, is represented by intersections: vehicles come and aim at passing the intersection, often as soon as possible, but they must compete with other vehicles having the same aim. A possible approach that has been used in literature to this problem uses auction based mechanisms. In this paper, we place ourselves in the above-mentioned transitory scenario in which both human-driven and autonomous vehicles will compete to cross intersections, and we investigate the effectiveness of auction-based mechanism to coordinate vehicles at intersections. We devise some simple auction policies, and assume vehicle coordination strategies that are suitable also for human drivers. Our results lead us to believe that, under these assumptions, simple auction mechanisms do not introduce advantages for what concern traveling times as they do in the case of exclusively autonomous vehicles.
C1 [Cabri, Giacomo; Gherardini, Luca; Montangero, Manuela; Muzzini, Filippo] Univ Modena & Reggio Emilia, Dipartimento Sci Fis Informat & Matemat, Via Campi 213-B, I-41125 Modena, Italy.
C3 Universita di Modena e Reggio Emilia
RP Montangero, M (corresponding author), Univ Modena & Reggio Emilia, Dipartimento Sci Fis Informat & Matemat, Via Campi 213-B, I-41125 Modena, Italy.
EM giacomo.cabri@unimore.it; 218121@studenti.unimore.it;
   manuela.montangero@unimore.it; filippo.muzzini@unimore.it
RI Muzzini, Filippo/GQP-0850-2022; Montangero, Manuela/O-2400-2016
OI Muzzini, Filippo/0000-0001-6523-0366; Gherardini,
   Luca/0000-0002-7147-0734
FU EU H2020 program under the CLASS project [780622]; H2020 - Industrial
   Leadership [780622] Funding Source: H2020 - Industrial Leadership
FX This work was supported by the EU H2020 program under the CLASS project,
   grant No. 780622.
CR Alves BR, 2019, LECT NOTES ARTIF INT, V11710, P189, DOI 10.1007/978-3-030-27878-6_15
   Bergemann Dirk., 2010, WILEY ENCY OPERATION
   Bertogna M, 2017, 2017 IEEE 26TH INTERNATIONAL CONFERENCE ON ENABLING TECHNOLOGIES - INFRASTRUCTURE FOR COLLABORATIVE ENTERPRISES (WETICE), P15, DOI 10.1109/WETICE.2017.45
   Billhardt Holger, 2016, Multi-Agent Systems and Agreement Technologies. 13th European Conference, EUMAS 2015 and Third International Conference, AT 2015. Revised Selected Papers: LNCS 9571, P410, DOI 10.1007/978-3-319-33509-4_32
   Bujari A, 2018, IEEE INTERNET THINGS, V5, P3683, DOI 10.1109/JIOT.2018.2812727
   Bujari A, 2018, MOBILE NETW APPL, V23, P147, DOI 10.1007/s11036-017-0835-8
   Bujari A, 2017, PERS UBIQUIT COMPUT, V21, P235, DOI 10.1007/s00779-016-0989-6
   Cabri G, 2019, PROCEEDINGS OF THE 5TH EAI INTERNATIONAL CONFERENCE ON SMART OBJECTS AND TECHNOLOGIES FOR SOCIAL GOOD (GOODTECHS 2019), P183, DOI 10.1145/3342428.3342689
   Capodieci N., 2011, 1 INT E EN MARK CHAL, DOI [10.1145/1998640.1998641, DOI 10.1145/1998640.1998641]
   Carlin D, 2013, IEEE INT C INTELL TR, P529, DOI 10.1109/ITSC.2013.6728285
   Chen W, 2011, WIREL COMMUN MOB COM, V11, P787, DOI 10.1002/wcm.862
   Chou SY, 2008, EXPERT SYST APPL, V35, P805, DOI 10.1016/j.eswa.2007.07.042
   Deng YQ, 2019, IEEE ACCESS, V7, P14410, DOI 10.1109/ACCESS.2019.2893486
   Dresner K, 2008, J ARTIF INTELL RES, V31, P591, DOI 10.1613/jair.2502
   HajiRassouliha A, 2018, SIGNAL PROCESS-IMAGE, V68, P101, DOI 10.1016/j.image.2018.07.007
   Meliones A., 2016, Proceedings of the 9th ACM International Conference on PErvasive Technologies Related to Assistive Environments, P1, DOI [DOI 10.1145/2910674.2910721, 10.1145/2910674.2910721]
   Murthy DK, 2016, 19TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD 2016), P613, DOI 10.1109/DSD.2016.78
   Pinciroli C, 2016, COMPUTER, V49, P32, DOI 10.1109/MC.2016.376
   Revathi G., 2012, 2012 INT C COMP COMM
   Rios-Torres J, 2017, IEEE T INTELL TRANSP, V18, P1066, DOI 10.1109/TITS.2016.2600504
   Schepperle H, 2007, LECT NOTES ARTIF INT, V4676, P119
   Valente P, 2020, P INT C HUM MACH SYS
   Vasirani M, 2012, J ARTIF INTELL RES, V43, P621, DOI 10.1613/jair.3560
   VICKREY W, 1961, J FINANC, V16, P8, DOI 10.2307/2977633
   Zambonelli F., 2020, ARXIV200102443
NR 25
TC 12
Z9 13
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15921
EP 15936
DI 10.1007/s11042-020-10222-y
EA FEB 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000615173600001
DA 2024-07-18
ER

PT J
AU Bhowmick, A
   Saharia, S
   Hazarika, SM
AF Bhowmick, Alexy
   Saharia, Sarat
   Hazarika, Shyamanta M.
TI FhVLAD: Fine-grained quantization and encoding high-order descriptor
   statistics for scalable image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VLAD; Fine-grained; Residual; High-order; Image retrieval
ID VLAD; SCALE; FEATURES; VECTOR
AB We are interested in the encoding of local descriptors of an image (e.g. SIFT) to design a compact representation vector and thereby address scalable image retrieval. We revisit the implicit design choices in the popular vector of locally aggregated descriptors (VLAD), which aggregates the residuals of descriptors to the codewords. VLAD's use of a coarse codebook and first-order descriptor statistics in residual computation results in less discriminative residuals. To address this problem, we propose a division of codebook feature space using a novel fine-grained quantization strategy. After quantization, we embed the resulting residuals with high-order statistics of descriptor distribution. Experiments on three challenging image retrieval datasets (INRIA Holidays, UKBench, Oxford 5k) confirm the improved discriminative power of our novel encoding method called FhVLAD. We observe superior accuracy to baseline and competitive performance to state-of-the-art techniques with a limited increase in dimension.
C1 [Bhowmick, Alexy] Assam Don Bosco Univ, Dept Comp Sci & Engn, Airport Rd, Gauhati 781017, Assam, India.
   [Bhowmick, Alexy; Saharia, Sarat] Tezpur Univ, Dept Comp Sci & Engn, Tezpur 784028, Assam, India.
   [Hazarika, Shyamanta M.] Indian Inst Technol, Dept Mech Engn, Biomimet Robot & Artificial Intelligence Lab, Gauhati 781039, Assam, India.
C3 Assam Don Bosco University; Tezpur University; Indian Institute of
   Technology System (IIT System); Indian Institute of Technology (IIT) -
   Guwahati
RP Bhowmick, A (corresponding author), Assam Don Bosco Univ, Dept Comp Sci & Engn, Airport Rd, Gauhati 781017, Assam, India.; Bhowmick, A (corresponding author), Tezpur Univ, Dept Comp Sci & Engn, Tezpur 784028, Assam, India.
EM alexy.bhowmick@gmail.com
RI bhowmick, alexy/M-4261-2019; Hazarika, Shyamanta M/AGZ-3776-2022;
   SAHARIA, SARAT/HLW-9422-2023
OI bhowmick, alexy/0000-0003-2334-5856; Hazarika, Shyamanta
   M/0000-0003-4547-6013; SAHARIA, SARAT/0000-0001-8026-3174
CR Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Babenko A, 2015, IEEE I CONF COMP VIS, P1269, DOI 10.1109/ICCV.2015.150
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   BALANDA KP, 1988, AM STAT, V42, P111, DOI 10.2307/2684482
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Bhowmick A, 2019, LECT NOTES COMPUT SC, V11941, P559, DOI 10.1007/978-3-030-34869-4_61
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Delhumeau J, 2013, REVISITING VLAD IMAG
   Eggert C, 2014, IEEE IMAGE PROC, P3018, DOI 10.1109/ICIP.2014.7025610
   Gao WJ, 2019, COMPUT INTELL-US, V35, P496, DOI 10.1111/coin.12202
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Husain SS, 2017, IEEE T PATTERN ANAL, V39, P1783, DOI 10.1109/TPAMI.2016.2613873
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jégou H, 2014, PROC CVPR IEEE, P3310, DOI 10.1109/CVPR.2014.417
   Jégou H, 2012, LECT NOTES COMPUT SC, V7573, P774, DOI 10.1007/978-3-642-33709-3_55
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jégou H, 2010, INT J COMPUT VISION, V87, P316, DOI 10.1007/s11263-009-0285-2
   Joe Yue-Hei Ng, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P53, DOI 10.1109/CVPRW.2015.7301272
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li Q, 2018, COMPUT SCI ENG, V20, P52, DOI 10.1109/MCSE.2018.108164530
   Liu LQ, 2011, IEEE I CONF COMP VIS, P2486, DOI 10.1109/ICCV.2011.6126534
   Liu PP, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0247-0
   Liu Z, 2016, IEEE T CIRC SYST VID, V26, P375, DOI 10.1109/TCSVT.2015.2409693
   Liu ZQ, 2016, NEUROCOMPUTING, V173, P1183, DOI 10.1016/j.neucom.2015.08.076
   Long XZ, 2016, MULTIMED TOOLS APPL, V75, P5533, DOI 10.1007/s11042-015-2524-6
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mairal J., 2014, Advances in neural information processing systems
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mironica I, 2016, MULTIMED TOOLS APPL, V75, P9045, DOI 10.1007/s11042-015-2819-7
   Nister David, 2006, CVPR
   Noh H, 2017, IEEE I CONF COMP VIS, P3476, DOI 10.1109/ICCV.2017.374
   Paulin M, 2015, IEEE I CONF COMP VIS, P91, DOI 10.1109/ICCV.2015.19
   Peng XJ, 2014, LECT NOTES COMPUT SC, V8691, P660, DOI 10.1007/978-3-319-10578-9_43
   Perronnin F., 2007, 2007 IEEE C COMP VIS, ppp 1
   Perronnin F, 2010, PROC CVPR IEEE, P3384, DOI 10.1109/CVPR.2010.5540009
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Philbin J, 2008, PROC CVPR IEEE, P2285
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Razavian AS, 2016, ARXIV14126574CS
   Sattler T, 2016, PROC CVPR IEEE, P1582, DOI 10.1109/CVPR.2016.175
   Shen XH, 2014, IEEE T PATTERN ANAL, V36, P1229, DOI 10.1109/TPAMI.2013.237
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Tolias G., 2016, Conference Track Proceedings,
   Tzelepi M, 2018, NEUROCOMPUTING, V275, P2467, DOI 10.1016/j.neucom.2017.11.022
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang YT, 2015, IEEE IMAGE PROC, P4629, DOI 10.1109/ICIP.2015.7351684
   Wei XS, 2017, IEEE T IMAGE PROCESS, V26, P2868, DOI 10.1109/TIP.2017.2688133
   Wu ZB, 2019, MULTIMED TOOLS APPL, V78, P25655, DOI 10.1007/s11042-019-07771-2
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yu W, 2017, NEUROCOMPUTING, V237, P235, DOI 10.1016/j.neucom.2016.12.002
   Zhao WL, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.99
   Zheng JX, 2016, INT C PATT RECOG, P4101, DOI 10.1109/ICPR.2016.7900276
   Zhou QZ, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18080311
   Zhou RH, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P342, DOI 10.1109/VCIP.2014.7051576
   Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141, DOI 10.1007/978-3-642-15555-0_11
NR 60
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35495
EP 35520
DI 10.1007/s11042-020-10491-7
EA FEB 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000613993900006
DA 2024-07-18
ER

PT J
AU Qiao, MY
   Tang, XX
   Liu, YX
   Yan, SH
AF Qiao, MeiYing
   Tang, XiaXia
   Liu, YuXiang
   Yan, ShuHao
TI Fault diagnosis method of rolling bearings based on VMD and MDSVM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bearing fault diagnosis; Mahalanobis distance; Support vector machine;
   Variational mode decomposition; Wavelet threshold method
ID DECOMPOSITION; DISTANCE
AB Rolling bearings are one of the most vulnerable parts in rotating machines. This paper presents a novel approach to identify the rolling bearings fault based on variational mode decomposition (VMD) and Mahalanobis distance support vector machine (MDSVM). In this work, since the original vibration signal contains a lot of noise, we use wavelet threshold method to denoise the original vibration signal. The vibration signals are generally non-linear, to extract feature, VMD has been employed to reconstruct signals. When raw signals are decomposed by VMD, according to the center frequency of each decomposed mode, the number of modes is selected. Then we calculate the sample entropy of the decomposed modal component, which is considered as the feature and input of support vector machine (SVM). The Euclidean distance is usually used in the calculation of the Gaussian kernel function of the SVM, which cannot measure the distance between two samples accurately, so we combine the Mahalanobis distance with SVM, construct a Gaussian function kernel based on Mahalanobis distance, and propose a classifier model based on Mahalanobis distance Gaussian function kernel. The model integrates the parameter solutions of the Mahalanobis distance function and the support vector machine into the same framework, which makes full use of the advantages of both and makes it easier to get the solution of the parameters. Finally, all feature vectors are utilized to train improved SVM, with which the fault modes of rolling bearings are identified. The experimental results show that the proposed method has better diagnosing performance.
C1 [Qiao, MeiYing; Tang, XiaXia; Liu, YuXiang; Yan, ShuHao] Henan Polytech Univ, Sch Elect Engn & Automat, Jiaozuo 454000, Henan, Peoples R China.
C3 Henan Polytechnic University
RP Tang, XX (corresponding author), Henan Polytech Univ, Sch Elect Engn & Automat, Jiaozuo 454000, Henan, Peoples R China.
EM qiaomy@hpu.edu.cn; 1163406417@qq.com; 641573672@qq.com;
   1452597175@qq.com
OI Tang, Xia/0000-0002-2776-265X; Yan, Shu-hao/0000-0002-2880-7856; Qiao,
   Meiying/0000-0001-9281-341X
FU National Natural Science Foundation of China [61573129, 41672363];
   technology project in Henan Province [172102310239]
FX This work is supported by the National Natural Science Foundation of
   China (41672363), the National Natural Science Foundation of China
   (61573129), and technology project in Henan Province (172102310239)
CR [Anonymous], 2012, DISTANCE METRIC LEAR
   [陈海永 Chen Haiyong], 2016, [电子测量与仪器学报, Journal of Electronic Measurement and Instrument], V30, P786
   [高巍 Gao Wei], 2018, [仪器仪表学报, Chinese Journal of Scientific Instrument], V39, P250
   Gong, 2015, FAULT FEATURE EXTRAC
   [谷朝健 Gu Chaojian], 2018, [航空动力学报, Journal of Aerospace Power], V33, P1750
   [郭泰 Guo Tai], 2017, [振动与冲击, Journal of Vibration and Shock], V36, P182
   Han Han, 2013, Control and Decision, V28, P1713
   Hu JL, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2735-3
   Huang NE, 1999, ANNU REV FLUID MECH, V31, P417, DOI 10.1146/annurev.fluid.31.1.417
   HUANG NE, 1998, P ROY SOC LOND A MAT, V454, P903, DOI DOI 10.1098/RSPA.1998.0193
   Lei Yaguo, 2012, Journal of Mechanical Engineering, V48, P62, DOI 10.3901/JME.2012.07.062
   Li, 2003, WAVELET ANAL ITS APP, P130
   Li Guang-zhen, 2010, Power System Technology, V34, P149
   Li SF, 2013, COMPUT BIOL MED, V43, P807, DOI 10.1016/j.compbiomed.2013.04.002
   [李余兴 Li Yuxing], 2019, [国防科技大学学报, Journal of National University of Defense Technology], V41, P89
   Liu CF, 2018, MECH SYST SIGNAL PR, V105, P169, DOI 10.1016/j.ymssp.2017.11.046
   [刘嘉敏 Liu Jiamin], 2017, [机械科学与技术, Mechanical Science and Technology for Aerospace Engineering], V36, P1695
   Loparo K. A., 2003, BEARINGS VIBRATION D
   Lu J., 2011, COAL MINE, V32, P249
   Luo Zhong-hui, 2005, Proceedings of the CSEE, V25, P125
   Mahalanobis PC, 2018, SANKHYA SER A, V80, P1, DOI 10.1007/s13171-019-00164-5
   Nguyen N, 2008, LECT NOTES ARTIF INT, V5212, P125, DOI 10.1007/978-3-540-87481-2_9
   Pincus SM, 2001, ANN NY ACAD SCI, V954, P245
   Platt JC, 1999, ADV NEUR IN, V11, P557
   Richman JS, 2000, AM J PHYSIOL-HEART C, V278, pH2039
   [唐贵基 Tang Guiji], 2016, [振动工程学报, Journal of Vibration Engineering], V29, P638
   [王奉涛 Wang Fengtao], 2018, [振动、测试与诊断, Journal of Vibration, Measurement and Diagnosis], V38, P540
   [王新 Wang Xin], 2017, [振动与冲击, Journal of Vibration and Shock], V36, P252
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Yang Y, 2012, MEASUREMENT, V45, P561, DOI 10.1016/j.measurement.2011.10.010
   [张超 Zhang Chao], 2018, [机械设计与研究, Machine Design and Research], V34, P81
   Zhang P., 2006, SHIP ELECT ENG, V26, P167, DOI DOI 10.3969/J.ISSN.1627-9730.2006.03.048
   [赵洪山 Zhao Hongshan], 2018, [太阳能学报, Acta Energiae Solaris Sinica], V39, P350
NR 33
TC 10
Z9 12
U1 7
U2 63
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 14521
EP 14544
DI 10.1007/s11042-020-10411-9
EA JAN 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000611964400001
DA 2024-07-18
ER

PT J
AU Zhang, QY
   Han, JT
AF Zhang, Qiuyu
   Han, Jitian
TI A novel color image encryption algorithm based on image hashing, 6D
   hyperchaotic and DNA coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image encryption; Image hashing; Two-dimensional chaotic map;
   Six-dimensional hyperchaotic map; Dynamic DNA coding
AB In order to improve the key space of color image encryption algorithm, the sensitivity to the contents of plain images, the robustness against various types of known attacks, and to achieve the tamper location analysis, a novel color image encryption algorithm based on image hashing, six-dimensional (6D) hyperchaotic and dynamic DNA coding is proposed. Firstly, the color image is pre-processed and the hash sequence is extracted by image hashing algorithm which is used as the initial value and control parameter of chaotic system. Secondly, three color channels of the color image RGB are synthesized into a two-dimensional matrix and the pixels replacement are performed by using the improved two-dimensional chaotic map. Finally, a 6D hyperchaotic system is used to generate random sequences for DNA dynamic coding and arithmetic operations of color images, the encrypted image is obtained. The experimental results show that, compared with the existing methods, the proposed algorithm has a large enough key space, better plain-image sensitivity, better statistical and differential characteristics, as well as can resistant various forms of attacks such as noise and cropping, and the tampering image can be tamper-located analyzed, which has good security and strong robustness.
C1 [Zhang, Qiuyu; Han, Jitian] Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Peoples R China.
C3 Lanzhou University of Technology
RP Zhang, QY (corresponding author), Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Peoples R China.
EM zhangqylz@163.com; 2284406188@qq.com
RI Zhang, Qiu-yu/V-9223-2019
OI Zhang, Qiu-yu/0000-0003-1488-388X
FU National Natural Science Foundation of China [61862041, 61363078];
   Innovation Ability Improvement Project of Gansu Colleges and
   Universities of China [2019A-236]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61862041, 61363078), the Innovation Ability Improvement
   Project of Gansu Colleges and Universities of China (2019A-236). The
   authors also gratefully acknowledge the helpful comments and suggestions
   of the reviewers, which have improved the presentation.
CR Alam S, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENGINEERING AND APPLICATIONS (ICACEA), P332, DOI 10.1109/ICACEA.2015.7164725
   Amani HR, 2019, MULTIMED TOOLS APPL, V78, P21537, DOI 10.1007/s11042-018-6989-y
   Batool SI, 2019, MULTIMED TOOLS APPL, V78, P27611, DOI 10.1007/s11042-019-07881-x
   Ben Farah MA, 2020, NONLINEAR DYNAM, V99, P3041, DOI 10.1007/s11071-019-05413-8
   Borujeni SE, 2013, TELECOMMUN SYST, V52, P525, DOI 10.1007/s11235-011-9458-8
   Broumandnia A, 2019, FUTURE GENER COMP SY, V99, P489, DOI 10.1016/j.future.2019.04.005
   Cai ST, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20040282
   García-Martínez M, 2015, APPL MATH COMPUT, V270, P413, DOI 10.1016/j.amc.2015.08.037
   Geetha S, 2018, INT J INF SECUR PRIV, V12, P42, DOI 10.4018/IJISP.2018070104
   Girdhar A, 2018, MULTIMED TOOLS APPL, V77, P27017, DOI 10.1007/s11042-018-5902-z
   Gong LH, 2018, INT J THEOR PHYS, V57, P59, DOI 10.1007/s10773-017-3541-1
   Guo, 2020, SIGNAL PROCESS-IMAGE, V115670, P80
   Han F, 2018, MULTIMED TOOLS APPL, V77, P14285, DOI 10.1007/s11042-017-5029-7
   He XL, 2018, OPT LASER ENG, V107, P112, DOI 10.1016/j.optlaseng.2018.03.018
   Kaur M, 2018, IET IMAGE PROCESS, V12, P1273, DOI 10.1049/iet-ipr.2017.1016
   Khan M, 2015, NONLINEAR DYNAM, V82, P527, DOI 10.1007/s11071-015-2173-3
   Kumari M, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0162-2
   Li SL, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20060463
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Liu L, 2019, J OPTICS-UK, V21, DOI 10.1088/2040-8986/aaf0f4
   Liu ZT, 2019, IEEE ACCESS, V7, P78367, DOI 10.1109/ACCESS.2019.2922376
   Mohamed HG, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22020158
   Ouyang JL, 2015, COMPUT ELECTR ENG, V46, P419, DOI 10.1016/j.compeleceng.2015.03.004
   Pak C, 2019, MULTIMED TOOLS APPL, V78, P12027, DOI 10.1007/s11042-018-6739-1
   Rajagopalan S, 2018, MICROPROCESS MICROSY, V61, P257, DOI 10.1016/j.micpro.2018.06.011
   Rehman AU, 2018, OPTIK, V159, P348, DOI 10.1016/j.ijleo.2018.01.064
   Sahari ML, 2018, NONLINEAR DYNAM, V94, P723, DOI 10.1007/s11071-018-4390-z
   Sasikaladevi N, 2019, MULTIMED TOOLS APPL, V78, P11675, DOI 10.1007/s11042-018-6711-0
   Suri S, 2019, J AMB INTEL HUM COMP, V10, P2277, DOI 10.1007/s12652-018-0825-0
   Wang XY, 2019, OPT LASER ENG, V115, P107, DOI 10.1016/j.optlaseng.2018.11.010
   Wang XY, 2019, MULTIMED TOOLS APPL, V78, P6191, DOI 10.1007/s11042-018-6326-5
   Wang XY, 2018, OPT LASER ENG, V103, P1, DOI 10.1016/j.optlaseng.2017.11.009
   Wu XJ, 2016, INFORM SCIENCES, V349, P137, DOI 10.1016/j.ins.2016.02.041
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Xiong ZG, 2019, MULTIMED TOOLS APPL, V78, P31035, DOI 10.1007/s11042-018-7081-3
   Yu J, 2017, IEEE T INF FOREN SEC, V12, P1005, DOI 10.1109/TIFS.2016.2636090
   Zhang Q, 2011, APPL MATH INFORM SCI, V5, P445
   Zhang YQ, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2020.106040
NR 38
TC 43
Z9 43
U1 4
U2 63
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13841
EP 13864
DI 10.1007/s11042-020-10437-z
EA JAN 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000608968500008
DA 2024-07-18
ER

PT J
AU Shaji, C
   Sam, IS
AF Shaji, C.
   Sam, I. Shatheesh
TI Dual encoding approach with sequence folding for reversible data hiding
   in dual stego images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dual Stego images; Data embedding; Embedding capacity; PSNR; SSIM;
   Embedding rate
ID WATERMARKING; SCHEME
AB This paper proposes a dual encoding approach with sequence folding for reversible data hiding in dual stego images. This method initially encodes the secret data by creating two encoding tables that contain index as well as code sequence based on message intensities and the two encoding tables are updated. The code sequence in the second encoding table is folded if the preceding half or succeeding half of the two encoding tables gets matched. The folding is also done if the maximum intensity in the code of two encoding tables lies in the most succeeding end. The same encoding process is repeated for all message intensities. After encoding the message intensities, the encoded indices are embedded on the cover image to obtain the dual stego images. In the data extraction phase, the encoded indices are initially extracted and is decoded by using the dual decoding table. The behavior of the proposed data hiding is evaluated using the metrics such as embedding capacity, embedding rate, PSNR, and SSIM using the standard test images. Experimental verification reveals that the proposed data hiding algorithm shows outstanding performance when compared to the traditional dual stego based data hiding methods.
C1 [Shaji, C.; Sam, I. Shatheesh] ManonmaniamSundaranar Univ, Nesamony Mem Christian Coll, Dept Comp Sci, Tirunelveli 627012, Tamil Nadu, India.
C3 Manonmaniam Sundaranar University
RP Shaji, C (corresponding author), ManonmaniamSundaranar Univ, Nesamony Mem Christian Coll, Dept Comp Sci, Tirunelveli 627012, Tamil Nadu, India.
EM shaji2012@gmail.com; shatheeshsam@yahoo.com
CR [Anonymous], (Archive) CS103 S15-Picture class
   [Anonymous], Test Images
   [Anonymous], 2013, P 3 INT C INFORM COM
   [Anonymous], SIPI Image Database-Mis
   Barton J. M., 1997, U.S. Patent, Patent No. 5646997
   Bhattacharyya D, 2011, COMM COM INF SC, V151, P315
   Celik MU, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P157
   Chang T. Duc, 2007, P IEEE REG 10 C NOV, P1, DOI [10.1109/TENCON.2007.4483783, DOI 10.1109/TENCON.2007.4483783]
   Chi LP, 2018, MULTIMED TOOLS APPL, V77, P8785, DOI 10.1007/s11042-017-4774-y
   Emmanuel AUBERT, LCM3B UHP NANCY 1
   Fridrich J, 2002, P SOC PHOTO-OPT INS, V4675, P572, DOI 10.1117/12.465317
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Jung KH, 2018, MULTIMED TOOLS APPL, V77, P6225, DOI 10.1007/s11042-017-4533-0
   Lee SK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1321, DOI 10.1109/icme.2006.262782
   Lee S, 2007, IEEE T INF FOREN SEC, V2, P321, DOI 10.1109/TIFS.2007.905146
   Li HR, 2020, SOFT COMPUT, V24, P6851, DOI 10.1007/s00500-019-04324-5
   Li QM, 2010, LECT NOTES COMPUT SC, V6297, P653, DOI 10.1007/978-3-642-15702-8_60
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lin CH, 2009, PR ELECTROMAGN RES S, P327, DOI 10.1145/1516241.1516298
   Lu TC, 2015, SIGNAL PROCESS, V115, P195, DOI 10.1016/j.sigpro.2015.03.017
   Lu TC, 2015, SIGNAL PROCESS, V108, P77, DOI 10.1016/j.sigpro.2014.08.022
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Mobasseri BG, 2010, IEEE T IMAGE PROCESS, V19, P958, DOI 10.1109/TIP.2009.2035227
   Nikolaidis A, 2003, IEEE T IMAGE PROCESS, V12, P563, DOI 10.1109/TIP.2003.810586
   Qian ZX, 2012, J SYST SOFTWARE, V85, P309, DOI 10.1016/j.jss.2011.08.015
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Sakai H, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY AND ITS APPLICATIONS, VOLS 1-3, P870
   Shaji C, 2020, MULTIMED TOOLS APPL, V79, P26969, DOI 10.1007/s11042-020-09273-y
   Shaji C, 2019, PROCEEDINGS OF THE 2019 6TH INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P769
   Shaji C, 2019, IMAGING SCI J, V67, P202, DOI 10.1080/13682199.2019.1592892
   Singh G, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P2700
   Sun W, 2013, SIGNAL IMAGE VIDEO P, V7, P297, DOI 10.1007/s11760-011-0238-4
   Wahed MA, 2018, 20 INT C COMP INF TE, P1, DOI [10.1109/ICCITECHN.2017.8281771, DOI 10.1109/ICCITECHN.2017.8281771]
   Wang K, 2013, J SYST SOFTWARE, V86, P1965, DOI 10.1016/j.jss.2013.03.083
   Wang Y, 2018, NOVEL DUAL IMAGE BAS, V20, P801, DOI [10.6633/IJNS.201807, DOI 10.6633/IJNS.201807]
   Xuan GR, 2007, LECT NOTES COMPUT SC, V4633, P715
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Zhang J, 2020, MULTIMED TOOLS APPL, V79, P2085, DOI 10.1007/s11042-019-08399-y
   Zhang SD, 2020, VISUAL COMPUT, V36, P1797, DOI 10.1007/s00371-019-01774-8
NR 42
TC 4
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13595
EP 13614
DI 10.1007/s11042-020-10240-w
EA JAN 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000608106800003
DA 2024-07-18
ER

PT J
AU Singh, VK
   Kumar, N
AF Singh, Vivek Kumar
   Kumar, Nitin
TI CHELM: Convex Hull based Extreme Learning Machine for salient object
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convex hull; Extreme learning machine; Saliency detection; Multiscale
   segmentation
ID MODEL
AB Machine learning based saliency detection methods have achieved better performance than traditional methods. Here, we propose a machine learning based method that utilizes Convex Hull and Extreme Learning Machine (ELM) for detecting salient object(s) in an image. The novelty of the proposed method lies in the generation of training set without using human annotations. Initially, an input image is segmented using SLIC algorithm at different scales to produce multiscale segmented images. This is followed by estimating two different saliency priors viz. (a) Convex Hull center prior and (b) contrast prior for each segmented image. These priors exploit foreground center and spatially weighted contrast respectively. Both of these estimated priors help in computing initial saliency of each segment across all scales. For each scale, the initial saliency map along with the Convex Hull based label map is employed on a segmented image to determine the positive (salient) and negative (background) training set. Distinctive features for each segment belonging to the training set are extracted and then passes to the Extreme Learning Machine for learning the ELM model. Afterwards, multiscale saliency maps of an image are found by applying the learned ELM model on distinctive features extracted from each segment across multiple scales. These multiscale saliency maps are linearly combined to obtain the final saliency map. The effectiveness of the proposed method is supported through extensive experimental results performed on six publicly available datasets viz. MSRA10K, DUT-OMRON, ECSSD, PASCAL-S, SED2, and THUR15K. The performance of the proposed method was compared with 11 state-of-the-art methods in terms of Precision, Recall, F-Measure, Receiver Operating Characteristics (ROC), and Area under the curve (AUC). The proposed method outperforms or comparable with compared methods in terms of all the performance measures.
C1 [Singh, Vivek Kumar; Kumar, Nitin] Natl Inst Technol, Dept Comp Sci & Engn, Garhwal, Uttarakhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Uttarakhand
RP Singh, VK (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Garhwal, Uttarakhand, India.
EM vivek.kumarsingh@nituk.ac.in; nitin@nituk.ac.in
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alpert S, 2007, PROC CVPR IEEE, P359
   [Anonymous], 2010, 149300 EPFL
   [Anonymous], 2008, 2008 19 INT C PATT R
   BANERJEE KS, 1973, TECHNOMETRICS, V15, P197, DOI 10.1080/00401706.1973.10489026
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Borji A, 2012, PROC CVPR IEEE, P470, DOI 10.1109/CVPR.2012.6247710
   Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Cornia M, 2018, IEEE T IMAGE PROCESS, V27, P5142, DOI 10.1109/TIP.2018.2851672
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Huang GB, 2004, IEEE IJCNN, P985
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Ji YZ, 2019, NEUROCOMPUTING, V323, P188, DOI 10.1016/j.neucom.2018.09.081
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Li X, 2013, IEEE I CONF COMP VIS, P3328, DOI 10.1109/ICCV.2013.413
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu GH, 2019, IEEE T IMAGE PROCESS, V28, P6, DOI 10.1109/TIP.2018.2847422
   Liu N, 2018, IEEE T IMAGE PROCESS, V27, P3264, DOI 10.1109/TIP.2018.2817047
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Minhas R, 2010, NEUROCOMPUTING, V73, P1906, DOI 10.1016/j.neucom.2010.01.020
   Murray N, 2011, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2011.5995506
   Pan C, 2012, NEURAL COMPUT APPL, V21, P1217, DOI 10.1007/s00521-011-0522-9
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Serre D., 2002, MATRICES, V216
   Singh N, 2016, DIGIT SIGNAL PROCESS, V55, P22, DOI 10.1016/j.dsp.2016.05.003
   Wang JP, 2015, NEUROCOMPUTING, V152, P359, DOI 10.1016/j.neucom.2014.10.056
   Xie YL, 2013, IEEE T IMAGE PROCESS, V22, P1689, DOI 10.1109/TIP.2012.2216276
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   Yang JM, 2017, IEEE T PATTERN ANAL, V39, P576, DOI 10.1109/TPAMI.2016.2547384
   Yang Y, 2019, IEEE T MULTIMEDIA, V21, P809, DOI 10.1109/TMM.2018.2867742
   Zhang JM, 2016, IEEE T PATTERN ANAL, V38, P889, DOI 10.1109/TPAMI.2015.2473844
   Zhang LH, 2019, NEUROCOMPUTING, V340, P42, DOI 10.1016/j.neucom.2019.02.041
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhang L, 2016, NEUROCOMPUTING, V218, P103, DOI 10.1016/j.neucom.2016.08.066
   Zhang W, 2010, IEEE T MULTIMEDIA, V12, P300, DOI 10.1109/TMM.2010.2047607
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 49
TC 1
Z9 1
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13535
EP 13558
DI 10.1007/s11042-020-10374-x
EA JAN 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000607985000001
DA 2024-07-18
ER

PT J
AU Angarita, MAO
   Cañadas, AM
AF Osorio Angarita, Maria Alejandra
   Moreno Canadas, Agustin
TI Brauer configuration algebras for multimedia based cryptography and
   security applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Authentication; Biometric system; Brauer configuration algebras;
   Multimedia application; Security; Visual secret sharing schemes
AB The notion of visual cryptography was introduced without formalisms by Naor and Shamir in 1994. It provides a very powerful technique by which one secret can be distributed into two or more shares, when the shares on transparencies are superimposed exactly together, the original secret can be discovered without computer participation. In this paper, master or universal shares defined by some suitable Brauer configuration algebras are used to protect multimedia database systems and in particular digital biometric data (e.g., iris, fingerprints, handwritten signatures, DNA, faces, etc). Master shares allow to conceal effectively and efficiently multiple secrets between a number of trusted parties. In this proposal such master shares are encoded by sequences of integer numbers, thus saving storage space of the database servers involved in the protection process. According to the procedure, a master share is obtained via a digit sequencing algorithm (DSA), which define elements of a database as linear combinations of basic elements of a suitable Brauer configuration algebra (BCA).
C1 [Osorio Angarita, Maria Alejandra; Moreno Canadas, Agustin] Univ Nacl Colombia, Bogota, Colombia.
C3 Universidad Nacional de Colombia
RP Angarita, MAO (corresponding author), Univ Nacl Colombia, Bogota, Colombia.
EM maaosorioan@unal.edu.co; amorenoca@unal.edu.co
OI Moreno Canadas, Agustin/0000-0001-6812-5131; Osorio Angarita, Maria
   Alejandra/0000-0002-0189-2982
CR Blundo C, 2003, SIAM J DISCRETE MATH, V16, P224, DOI 10.1137/S0895480198336683
   Ca?adas AM., 2017, FAR E J MATH SCI FJM, V106, P1223, DOI [10.17654/MS102061223, DOI 10.17654/MS102061223]
   Chang JJY, 2018, CRYPTOGRAPHY-BASEL, V2, DOI 10.3390/cryptography2030024
   Chen TH, 2012, SIGNAL PROCESS, V92, P2229, DOI 10.1016/j.sigpro.2012.02.015
   Cimato S, 2012, DIGIT IMAG COMPUT, P1
   Green EL, 2017, B SCI MATH, V141, P539, DOI 10.1016/j.bulsci.2017.06.001
   Gurunathan K, 2020, MULTIMED TOOLS APPL, V79, P3893, DOI 10.1007/s11042-019-7471-1
   Kant, 2018, INT J SIGNAL PROCESS, V11, P9
   Nakajima M, 2002, WSCG'2002, VOLS I AND II, CONFERENCE PROCEEDINGS, P303
   Naor M., 1994, VISUAL CRYPTOGRAPHY, V950
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Ross A, 2011, IEEE T INF FOREN SEC, V6, P70, DOI 10.1109/TIFS.2010.2097252
   Shyu SJ, 2007, PATTERN RECOGN, V40, P3633, DOI 10.1016/j.patcog.2007.03.012
   Wu CC, 1998, THESIS NATL CHIAO TU
   Xi K, 2010, HANDBOOK OF INFORMATION AND COMMUNICATION SECURITY, P129, DOI 10.1007/978-3-642-04117-4_7
   Yan WQ, 2012, DIGIT IMAG COMPUT, P381
NR 16
TC 7
Z9 7
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23485
EP 23510
DI 10.1007/s11042-020-10239-3
EA JAN 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000607369000001
DA 2024-07-18
ER

PT J
AU Ahmad, SBS
   Rafie, M
   Ghorabie, SM
AF Ahmad, Saleh Beyt Sheikh
   Rafie, Mahnaz
   Ghorabie, Seyed Mojtaba
TI Spam detection on Twitter using a support vector machine and users'
   features by identifying their interactions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tweet; Twitter; Spam; Support vector machine
AB Spam tweets might cause numerous problems for users. An automatic method is introduced as a proposed method to detect spam tweets. This method is based on pre-processing and feature extraction steps. The pre-processing step is significant for our problem due to the specific structure of tweets. The pre-processing step is performed in such a way that after which only the words remain in each tweet that can play a key role in determining whether the tweet is spam or non-spam. In the proposed method, the features are classified into five classes of user profile features, account information features, user activity based features, user interaction based features, and tweet content-based features including 28 different features. In the feature selection step, an optimal subset of these features is selected for the learning process. However, a support vector classifier is used for the learning process by two Gaussian and polynomial kernels. Finally, the proposed method is compared with multi-layer perceptron (MLP), Naive Bayes (NB), random forest (RF), and k-nearest neighbors (KNN) methods in terms of standard criteria. The obtained results show the superiority of the proposed method using support vector machine (SVM) algorithm and polynomial kernel with 0.988 precision, 0.953 efficiency, 0.96 accuracy, F-0.969, and 0.985 ROC area under the curve compared to the other methods, indicating that the proposed method has better performance overall.
C1 [Ahmad, Saleh Beyt Sheikh] Arvandan Nonprofit Higher Educ Inst, Dept Comp Engn, Khorramshahr, Iran.
   [Rafie, Mahnaz] Islamic Azad Univ, Ramhormoz Branch, Dept Comp Engn, Ramhormoz, Iran.
   [Ghorabie, Seyed Mojtaba] Islamic Azad Univ, Int Branch, Dept Comp Engn, Qeshm, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Rafie, M (corresponding author), Islamic Azad Univ, Ramhormoz Branch, Dept Comp Engn, Ramhormoz, Iran.
EM m.rafie@srbiau.ac.ir
RI Rafie, Mahnaz/AAN-2340-2021; Rafie, Mahnaz/AAN-4505-2021
OI Rafie, Mahnaz/0000-0003-2546-826X
CR Al-Zoubi AM, 2018, KNOWL-BASED SYST, V153, P91, DOI 10.1016/j.knosys.2018.04.025
   Alom Z, 2020, ONLINE SOCIAL NETWOR, V18, DOI 10.1016/j.osnem.2020.100079
   Alsaleh M, 2015, 2015 IEEE 14TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P295, DOI 10.1109/ICMLA.2015.192
   Benevenuto F, 2010, COLL 2010 ANT SPAM C, P6
   Chapman P, 2000, CRISP-DM 1.0: Step-by-Step Data Mining Guide
   Chen C, 2017, IEEE T INF FOREN SEC, V12, P914, DOI 10.1109/TIFS.2016.2621888
   Cheng Cao, 2015, Advances in Information Retrieval. 37th European Conference on IR Research (ECIR 2015). Proceedings: LNCS 9022, P703, DOI 10.1007/978-3-319-16354-3_77
   Danezis George, 2009, NDSS
   El-Mawass N, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102317
   Gao HY, 2010, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'10), P681, DOI 10.1145/1866307.1866396
   Heydari A, 2015, EXPERT SYST APPL, V42, P3634, DOI 10.1016/j.eswa.2014.12.029
   Howard PN, 2016, BOTS STRONGERLN BREX
   Inuwa-Dutse I, 2018, NEUROCOMPUTING, V315, P496, DOI 10.1016/j.neucom.2018.07.044
   Jindal N., 2008, P WSDM, P219, DOI [DOI 10.1145/1341531.1341560, 10.1145/1341531.1341560]
   Kouvela M, 2020, THESIS SUBMITTED FUL
   Lee S, 2012, GREEN CHEM CHEM ENG, P181
   Liu SG, 2017, COMPUT SECUR, V69, P35, DOI 10.1016/j.cose.2016.12.004
   Mammen S, 2011, INT SER CONSUM SCI, P185, DOI 10.1007/978-1-4614-0382-1_10
   McCord M., 2011, Autonomic and Trusted Computing. Proceedings 8th International Conference (ATC 2011), P175, DOI 10.1007/978-3-642-23496-5_13
   Miller Z, 2014, INFORM SCIENCES, V260, P64, DOI 10.1016/j.ins.2013.11.016
   Qin J, 2017, I IEEE EMBS C NEUR E, P1, DOI 10.1109/NER.2017.8008277
   Sedhai S, 2018, IEEE T COMPUT SOC SY, V5, P169, DOI 10.1109/TCSS.2017.2773581
   Subba Reddy K, 2019, INT J INNOVATIVE TEC, V8, P2278
   Thomas K, 2011, P IEEE S SECUR PRIV, P447, DOI 10.1109/SP.2011.25
   Varol Onur, 2017, P INT AAAI C WEB SOC, P280, DOI DOI 10.1609/ICWSM.V11I1.14871
   Yang C, 2012, P 21 INT C WORLD WID, P71, DOI DOI 10.1145/2187836.2187847
   Yu HF, 2008, IEEE ACM T NETWORK, V16, P576, DOI 10.1109/TNET.2008.923723
NR 27
TC 14
Z9 14
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 11583
EP 11605
DI 10.1007/s11042-020-10405-7
EA JAN 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000605548700019
DA 2024-07-18
ER

PT J
AU Yang, J
   Xiang, Z
   Mou, LS
   Liu, SM
AF Yang, Jian
   Xiang, Zhen
   Mou, Lisha
   Liu, Shumu
TI Multimedia resource allocation strategy of wireless sensor networks
   using distributed heuristic algorithm in cloud computing environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Resource allocation; Sensor network; Cloud storage environment;
   Distributed heuristic algorithm; Centralized algorithm
AB The virtualized resource allocation (mapping) algorithm is the core issue of network virtualization technology. Universal and excellent resource allocation algorithms not only provide efficient and reliable network resources sharing for systems and users, but also simplify the complexity of resource scheduling and management, improve the utilization of basic resources, balance network load and optimize network performance. Based on the application of wireless sensor network, this paper proposes a wireless sensor network architecture based on cloud computing. The WSN hardware resources are mapped into resources in cloud computing through virtualization technology, and the resource allocation strategy of the network architecture is proposed. The experiment evaluates the performance of the resource allocation strategy. The proposed heuristic algorithm is a distributed algorithm. The complexity of centralized algorithms is high, distributed algorithms can handle problems in parallel, and reduce the time required to get a good solution with limited traffic.
C1 [Yang, Jian; Liu, Shumu] Sichuan Engn Tech Coll, Informat Ctr, Deyang 618000, Sichuan, Peoples R China.
   [Xiang, Zhen] Sichuan Engn Tech Coll, Deyang 618000, Sichuan, Peoples R China.
   [Mou, Lisha] Sichuan Engn Tech Coll, Elect & Informat Engn Dept, Deyang 618000, Sichuan, Peoples R China.
C3 Sichuan Engineering Technical College; Sichuan Engineering Technical
   College; Sichuan Engineering Technical College
RP Yang, J (corresponding author), Sichuan Engn Tech Coll, Informat Ctr, Deyang 618000, Sichuan, Peoples R China.
EM jianyang885@163.com
CR Acharya UR, 2019, FUTURE GENER COMP SY, V91, P290, DOI 10.1016/j.future.2018.08.044
   Aroua S, 2017, IEEE SYMP COMP COMMU, P754, DOI 10.1109/ISCC.2017.8024618
   Arunkumar N, 2017, PATTERN RECOGN LETT, V94, P112, DOI 10.1016/j.patrec.2017.05.007
   Braccini C, 2015, SENSORS-BASEL, V15, P2737, DOI 10.3390/s150202737
   Ghadi M, 2016, MULTIMED TOOLS APPL, V75, P3425, DOI 10.1007/s11042-014-2443-y
   Hao XC, 2015, WIRELESS PERS COMMUN, V80, P1557, DOI 10.1007/s11277-014-2100-9
   Khan MI, 2016, EURASIP J WIREL COMM, DOI 10.1186/s13638-015-0515-y
   Leinonen M, 2015, SIGN PROC C 2011 EUR, P407
   Li W, 2014, J PARALLEL DISTR COM, V74, P1775, DOI 10.1016/j.jpdc.2013.09.012
   Oh SL, 2020, NEURAL COMPUT APPL, V32, P10927, DOI 10.1007/s00521-018-3689-5
   Rozali AZ, 2016, WIRELESS SENS IEEE, P46
   Su J, 2014, IEEE ICC, P478, DOI 10.1109/ICC.2014.6883364
   Sultana A, 2017, PEER PEER NETW APPL, V10, P1113, DOI 10.1007/s12083-016-0465-0
   Wang T, 2015, IEEE T VEH TECHNOL, V64, P173, DOI 10.1109/TVT.2014.2320815
   Yang W, 2015, IET CONTROL THEORY A, V9, P410, DOI 10.1049/iet-cta.2014.0494
   Yu WJ, 2018, INTELL AUTOM SOFT CO, V24, P367, DOI [10.1109/TETC.2016.2620382, 10.1080/10798587.2017.1294873]
   Yun DQ, 2015, J PARALLEL DISTR COM, V84, P51, DOI 10.1016/j.jpdc.2015.07.004
   Zhang HJ, 2016, IEEE T IND INFORM, V12, P1714, DOI 10.1109/TII.2015.2489610
   Zhang P, 2014, IEEE INT C COMM SYST, P11
   Zhang YY, 2018, IET COMMUN, V12, P349, DOI 10.1049/iet-com.2017.0937
   Zhao J, 2015, INT J DISTRIB SENS N, V6, P11
NR 21
TC 4
Z9 4
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35353
EP 35367
DI 10.1007/s11042-019-07759-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000595980900035
DA 2024-07-18
ER

PT J
AU Wang, XY
   Gao, S
AF Wang, Xingyuan
   Gao, Suo
TI A chaotic image encryption algorithm based on a counting system and the
   semi-tensor product
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Matrix semi-tensor product; n-ary counting system; Chaotic image
   encryption; Hilbert fractal curve
ID BIT-LEVEL; BOOLEAN NETWORKS; PERMUTATION; TRANSFORM; MAP
AB Based on the n-ary counting system, combined with the matrix semi-tensor product theory and Hilbert curve, a chaotic image encryption algorithm is designed. Different from the traditional encryption method, the algorithm proposed in this paper is an encryption algorithm with scrambling and diffusion at the same time. First, the pixel value is converted from decimal to n-ary. In the n-ary counting system, the plaintext image is randomly divided into some groups, and the Hilbert curve is used for scrambling to each group. The blocks are converted into scrambled images, so that the scrambling and diffusion can be carried out at the same time. Then, in order to improve the security of the algorithm, another round of diffusion is carried out based on matrix semi-tensor product mechanism. Chaotic sequence is generated by Chen system. This chaotic sequence performs matrix semi-tensor product operation with the first round of encrypted image, and generate second encrypted images. Finally, this encryption method is applied to color image encryption. Compared with some representative algorithms, the experimental results show that the algorithm proposed in this paper is secure and it can resist common attacks.
C1 [Wang, Xingyuan; Gao, Suo] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian, Peoples R China.
C3 Dalian Maritime University
RP Gao, S (corresponding author), Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian, Peoples R China.
EM 1418159118@qq.com
RI suo, gao/AGX-8041-2022; Wang, Xing-yuan/I-6353-2015
OI Gao, Suo/0000-0001-5790-7429
FU National Natural Science Foundation of China [61672124]; Password Theory
   Project of the 13th Five-Year Plan National Cryptography Development
   Fund [MMJJ20170203]; Project of the Liaoning Province Science and
   Technology Innovation Leading Talents Program [XLYC1802013]; Key R&D
   Projects of Liaoning Province [2019JH2/10300057]; Jinan City '20
   Universities' Funding Projects Introducing Innovation Team Program
   [2019GXRC031]; "Double First-rate" Construction Project ("Innovation
   Project") [SSCXXM012]
FX This research was supported by the National Natural Science Foundation
   of China (No. 61672124), the Password Theory Project of the 13th
   Five-Year Plan National Cryptography Development Fund (No.
   MMJJ20170203), a Project of the Liaoning Province Science and Technology
   Innovation Leading Talents Program (No. XLYC1802013), the Key R&D
   Projects of Liaoning Province (No. 2019JH2/10300057), and the Jinan City
   '20 Universities' Funding Projects Introducing Innovation Team Program
   (No. 2019GXRC031), "Double First-rate" Construction Project ("Innovation
   Project") (No. SSCXXM012).
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Cao GH, 2019, MULTIMED TOOLS APPL, V78, P10625, DOI 10.1007/s11042-018-6635-8
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen WH, 2016, IEEE T NEUR NET LEAR, V27, P2696, DOI 10.1109/TNNLS.2015.2512849
   [程代展 Cheng Daizhan], 2012, [系统科学与数学, Journal of Systems Science and Mathematical Sciences], V32, P1488
   [程代展 Cheng Daizhan], 2011, [科学通报, Chinese Science Bulletin], V56, P2664
   Cheng DZ, 2010, IEEE T AUTOMAT CONTR, V55, P2251, DOI 10.1109/TAC.2010.2043294
   Gong LH, 2018, INT J THEOR PHYS, V57, P59, DOI 10.1007/s10773-017-3541-1
   Hamza R, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/1625678
   Hamza R, 2016, INF SECUR J, V25, P162, DOI 10.1080/19393555.2016.1212954
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hua ZY, 2017, INFORM SCIENCES, V396, P97, DOI 10.1016/j.ins.2017.02.036
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Li CQ, 2016, SIGNAL PROCESS, V118, P203, DOI 10.1016/j.sigpro.2015.07.008
   Li HT, 2018, SCI CHINA INFORM SCI, V61, DOI 10.1007/s11432-017-9238-1
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Liu HJ, 2019, MULTIMED TOOLS APPL, V78, P15997, DOI 10.1007/s11042-018-6996-z
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu H, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21040343
   LORENZ EN, 1963, J ATMOS SCI, V20, P130, DOI 10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2
   Mani P, 2019, INFORM SCIENCES, V491, P74, DOI 10.1016/j.ins.2019.04.007
   Ping P, 2018, NEUROCOMPUTING, V283, P53, DOI 10.1016/j.neucom.2017.12.048
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   Tang Song, 2012, Journal of Computer Applications, V32, P2262, DOI 10.3724/SP.J.1087.2012.02262
   Teng L, 2018, MULTIMED TOOLS APPL, V77, P6883, DOI 10.1007/s11042-017-4605-1
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang QZ, 2016, BIOMED ENG ONLINE, V15, DOI 10.1186/s12938-016-0239-1
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2019, J FRANKLIN I, V356, P11638, DOI 10.1016/j.jfranklin.2019.10.006
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2019, IEEE ACCESS, V7, P103662, DOI 10.1109/ACCESS.2019.2931052
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wang XY, 2016, NONLINEAR DYNAM, V83, P333, DOI 10.1007/s11071-015-2330-8
   Xie EY, 2017, SIGNAL PROCESS, V132, P150, DOI 10.1016/j.sigpro.2016.10.002
   Ye GD, 2018, NONLINEAR DYNAM, V94, P745, DOI 10.1007/s11071-018-4391-y
   Ye GD, 2016, J VIB CONTROL, V22, P1171, DOI 10.1177/1077546314534717
   Ye XL, 2020, OPT LASER ENG, V127, DOI 10.1016/j.optlaseng.2019.105905
   Ye XL, 2020, NONLINEAR DYNAM, V99, P1489, DOI 10.1007/s11071-019-05370-2
   Zhang H, 2014, IEEE ACM T COMPUT BI, V11, P965, DOI 10.1109/TCBB.2014.2338313
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zhou NR, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-1902-1
   Zhou YC, 2013, SIGNAL PROCESS, V93, P3039, DOI 10.1016/j.sigpro.2013.04.021
NR 44
TC 38
Z9 39
U1 3
U2 59
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10301
EP 10322
DI 10.1007/s11042-020-10101-6
EA NOV 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000590967300001
DA 2024-07-18
ER

PT J
AU Singh, TD
   Khilji, AFUR
   Divyansha
   Singh, AV
   Thokchom, S
   Bandyopadhyay, S
AF Singh, Thoudam Doren
   Khilji, Abdullah Faiz Ur Rahman
   Divyansha
   Singh, Apoorva Vikram
   Thokchom, Surmila
   Bandyopadhyay, Sivaji
TI Predictive approaches for the UNIX command line: curating and exploiting
   domain knowledge in semantics deficit data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE UNIX Command Line Prediction; Knowledge Base; LSTM; GLoVe; Joint
   Learning; BERT
AB The command line has always been the most efficient method to interact with UNIX flavor based systems while offering a great deal of flexibility and efficiency as preferred by professionals. Such a system is based on manually inputting commands to instruct the computing machine to carry out tasks as desired. This human-computer interface is quite tedious especially for a beginner. And hence, the command line has not been able to garner an overwhelming reception from new users. Therefore, to improve user-friendliness and to mark a step towards a more intuitive command line system, we propose two predictive approaches that can benefit all kinds of users specially the novice ones by integrating into the command line interface. These methods are based on deep learning based predictions. The first approach is based on the sequence to sequence (Seq2seq) model with joint learning by leveraging continuous representations of a self-curated exhaustive knowledge base (KB) comprising an all-inclusive command description to enhance the embedding employed in the model. The other is based on the attention-based transformer architecture where a pretrained model is employed. This allows the model to dynamically evolve over time making it adaptable to different circumstances by learning as the system is being used. To reinforce our idea, we have experimented with our models on three major publicly available Unix command line datasets and have achieved benchmark results using GLoVe and Word2Vec embeddings. Our finding is that the transformer based framework performs better on two different datasets of the three in our experiment in a semantic deficit scenario like UNIX command line prediction. However, Seq2seq based model outperforms bidirectional encoder representations from transformers (BERT) based model on a larger dataset.
C1 [Singh, Thoudam Doren; Khilji, Abdullah Faiz Ur Rahman; Divyansha; Bandyopadhyay, Sivaji] Natl Inst Technol Silchar, Ctr Nat Language Proc CNLP, Silchar, Assam, India.
   [Singh, Thoudam Doren; Khilji, Abdullah Faiz Ur Rahman; Divyansha; Bandyopadhyay, Sivaji] Natl Inst Technol Silchar, Dept Comp Sci & Engn, Silchar, Assam, India.
   [Singh, Apoorva Vikram] Natl Inst Technol Silchar, Dept Elect Engn, Silchar, Assam, India.
   [Thokchom, Surmila] Natl Inst Technol Meghalaya, Dept Comp Sci & Engn, Shillong, Meghalaya, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar; National Institute of Technology (NIT System);
   National Institute of Technology Silchar; National Institute of
   Technology (NIT System); National Institute of Technology Silchar;
   National Institute of Technology (NIT System); National Institute of
   Technology Meghalaya
RP Singh, TD (corresponding author), Natl Inst Technol Silchar, Ctr Nat Language Proc CNLP, Silchar, Assam, India.; Singh, TD (corresponding author), Natl Inst Technol Silchar, Dept Comp Sci & Engn, Silchar, Assam, India.
EM doren@cse.nits.ac.in; abdullah_ug@cse.nits.ac.in;
   divyansha_ug@cse.nits.ac.in; apoorva_ug@ee.nits.ac.in;
   surmila.thokchom@nitm.ac.in; sivaji.cse.ju@gmail.com
RI Singh, Thoudam Doren/JTT-1900-2023; Khilji, Abdullah/ABI-5546-2020
OI Singh, Thoudam Doren/0000-0001-9906-9136; Khilji,
   Abdullah/0000-0001-6621-1810; Singh, Apoorva Vikram/0000-0003-4061-531X;
   Ms, Divyansha/0000-0002-7901-9745; Thokchom, Surmila/0000-0003-4749-0038
CR Alsuhaibani M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193094
   [Anonymous], 2017, ARXIV170500557
   [Anonymous], 2018, INT C LEARN REPR
   Assawinjaipetch, 2016, P 3 INT WORKSH WORLD, P36
   Daee P, 2017, MACH LEARN, V106, P1599, DOI 10.1007/s10994-017-5651-7
   Davidson BJ, 1998, ADVANCES IN HEAD AND NECK ONCOLOGY, P5
   Davison BD, 1997, ADV HUM FACT ERGON, V21, P505
   Davison BD, 1997, AAAI IAAI, P827
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Rodríguez JD, 2010, IEEE T PATTERN ANAL, V32, P569, DOI 10.1109/TPAMI.2009.187
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Durant KT, 2002, WIT T INFORM COMMUNI, P28
   Goldberg Y., 2014, ARXIV PREPRINT ARXIV, V1402, P3722
   Greenberg S, 1988, USING UNIX COLLECTED
   Heimerl F, 2014, P ANN HICSS, P1833, DOI 10.1109/HICSS.2014.231
   Hendrycks Dan, 2017, INT C LEARNING REPRE
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jacobs N., 2000, Adaptive User Interfaces. Papers from the 20000 AAAI Symposium, P50
   Korvemaker B, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P230
   Lane T., 1997, P 20 NATL INFORM SYS, P366
   Levy O., 2015, Transactions of the Association for Computational Linguistics, V3, P211
   Lin XV, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P3107
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Schonlau M, 2001, STAT SCI, V16, P58
   Taylor WL, 1953, JOURNALISM QUART, V30, P415, DOI 10.1177/107769905303000401
   YOSHIDA K, 1994, PROC INT C TOOLS ART, P732, DOI 10.1109/TAI.1994.346414
NR 27
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9209
EP 9229
DI 10.1007/s11042-020-10109-y
EA NOV 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000587660500001
DA 2024-07-18
ER

PT J
AU Tan, AJ
   Zhou, GX
   He, MF
AF Tan, Aijiao
   Zhou, Guoxiong
   He, Mingfang
TI Surface defect identification of Citrus based on KF-2D-Renyi and ABC-SVM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Citrus classification; Defect recognition; Support
   vector machine; Threshold segmentation
ID FIREFLY ALGORITHM; COMPUTER VISION; CLASSIFICATION; COLOR; RECOGNITION;
   PERFORMANCE; FRUITS
AB In allusion to the problems of citrus surface defect identification such as blurred edges, unclear images, more interference and difficulty in defect identification, surface defect identification of citrus based on KF-2D-Renyi and ABC-SVM was proposed in this paper. First, the method based on the dark channel prior (DCP) was used to defog the citrus images collected. Then, the firefly algorithm based on Kent chaos was used to optimize two-dimensional Renyi entropy threshold segmentation algorithm (2D-Renyi). The citrus surface defects were segmented, and the image features were extracted. Finally, the image feature vectors were input into the ABC-SVM classifier to determine the citrus defect types. We selected 8 kinds of citrus surface defects to carry on the experiment. In testing the segmentation algorithms, compared with the traditional threshold segmentation algorithms, the KF-2D-Renyi segmentation algorithm has a great improvement. The recognition rates for the defects whose features are obvious such as Sooty mould and Anthracnose could reach 100%. The recognition rates for the defects which are difficult to identify such as Thrips scar, Oleocellosis and Scale injury reached 95.18%, 96.37% and 98.43% respectively. In testing the classification algorithms, compared with the standard SVM classifier, the PSO-SVM classifier and the neural network classifiers, the average recognition rate of the ABC-SVM classifier reached 98.45%. The experimental results show that the method in this paper can effectively detect and classify citrus surface defects.
C1 [Tan, Aijiao; Zhou, Guoxiong; He, Mingfang] Cent South Univ Forestry & Technol, Coll Comp & Informat Engn, Changsha 410004, Peoples R China.
C3 Central South University of Forestry & Technology
RP Zhou, GX (corresponding author), Cent South Univ Forestry & Technol, Coll Comp & Informat Engn, Changsha 410004, Peoples R China.
EM zhougx01@163.com
OI Zhou, Guoxiong/0000-0002-5142-4845
FU Youth Scientific Research Fundation of Central South University of
   Forestry Technology [QJ2012012B]; Scientific Research Project of
   Education Department of Hunan Province [18C0285]; National Natural
   Science Foundation of China [61703441]
FX This work was supported by Youth Scientific Research Fundation of
   Central South University of Forestry & Technology under Grant
   QJ2012012B, the Scientific Research Project of Education Department of
   Hunan Province under Grant No. 18C0285 and the National Natural Science
   Foundation of China under Grant 61703441.
CR Baykasoglu A, 2015, APPL SOFT COMPUT, V36, P152, DOI 10.1016/j.asoc.2015.06.056
   Blasco J, 2007, J FOOD ENG, V83, P384, DOI 10.1016/j.jfoodeng.2007.03.027
   Blasco J, 2009, BIOSYST ENG, V103, P137, DOI 10.1016/j.biosystemseng.2009.03.009
   Borjigin S, 2019, PATTERN RECOGN, V92, P107, DOI 10.1016/j.patcog.2019.03.011
   Chao Yuan, 2015, Optics and Precision Engineering, V23, P879, DOI 10.3788/OPE.20152303.0879
   CristianintNello, 2000, INTRO SUPPORT VECTOR, DOI [10.1609/aimag.v22i2.1566, DOI 10.1609/AIMAG.V22I2.1566]
   Cubero S, 2016, FOOD BIOPROCESS TECH, V9, P1623, DOI 10.1007/s11947-016-1767-1
   El Khoury J, 2014, 10TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY AND INTERNET-BASED SYSTEMS SITIS 2014, P606, DOI 10.1109/SITIS.2014.78
   Eswaramoorthy S, 2016, COMPEL, V35, P1513, DOI 10.1108/COMPEL-09-2015-0337
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Fu Q, 2015, T CHINESE SOC AGR EN, V31, P117, DOI [10.11975/j.issn.1002-6819.2015.11.01, DOI 10.11975/J.ISSN.1002-6819.2015.11.01]
   Gandomi AH, 2013, COMMUN NONLINEAR SCI, V18, P89, DOI 10.1016/j.cnsns.2012.06.009
   Han Shou-Dong, 2011, Acta Automatica Sinica, V37, P11, DOI 10.3724/SP.J.1004.2011.00011
   Hassanien AE, 2017, COMPUT ELECTRON AGR, V136, P86, DOI 10.1016/j.compag.2017.02.026
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He LF, 2017, NEUROCOMPUTING, V240, P152, DOI 10.1016/j.neucom.2017.02.040
   Horng MH, 2011, EXPERT SYST APPL, V38, P13785, DOI 10.1016/j.eswa.2011.04.180
   Jing Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12543, DOI 10.1109/CVPR42600.2020.01256
   Karaboga D, 2008, APPL SOFT COMPUT, V8, P687, DOI 10.1016/j.asoc.2007.05.007
   Karaboga D., 2005, Technical report-tr06
   Kecman V., 2001, LEARNING SOFT COMPUT
   Li H, 2018, SCI TECHNOL B, DOI [10.13774/j.cnki.kjtb.2018.12.039, DOI 10.13774/J.CNKI.KJTB.2018.12.039]
   Li JB, 2013, POSTHARVEST BIOL TEC, V82, P59, DOI 10.1016/j.postharvbio.2013.02.016
   Liu B, 2019, NANFANG AGR MACH, P52
   Liu PC, 2019, NONLINEAR DYNAM, V98, P1447, DOI 10.1007/s11071-019-05170-8
   Luo Y., 2008, IEEE COMPUTER SOC C, P1, DOI [DOI 10.1109/CVPRW.2008.4563088, 10.1109/CVPRW.2008.4563088]
   Lutton E, 2017, GENET PROGRAM EVOLVA, V18, P509, DOI [10.1007/s10710-017-9311-2, DOI 10.1007/S10710-017-9311-2]
   Ma Y, 2017, FINANC INNOV, V3, DOI 10.1186/s40854-017-0058-9
   Mao X., 2017, Computer Science, V44, P206
   Olague G, 2006, HONEYBEE SEARCH ALGO, DOI [10.1007/11732242_38, DOI 10.1007/11732242_38]
   Olague G, 2006, GECCO 2006: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOL 1 AND 2, P191
   Olague G, 2006, INT C PATT RECOG, P1116
   Olague G, 2006, PATTERN RECOGN LETT, V27, P1161, DOI 10.1016/j.patrec.2005.07.013
   Papakostas GA, 2010, PATTERN RECOGN, V43, P58, DOI 10.1016/j.patcog.2009.05.008
   Perez CB, 2008, INT C PATT RECOG, P3201
   Rajinikanth V, 2015, PROCEDIA COMPUT SCI, V46, P1449, DOI 10.1016/j.procs.2015.02.064
   Saber E, 1998, J ELECTRON IMAGING, V7, P684, DOI 10.1117/1.482605
   Sahoo PK, 2004, PATTERN RECOGN, V37, P1149, DOI 10.1016/j.patcog.2003.10.008
   Soh LK, 1999, IEEE T GEOSCI REMOTE, V37, P780, DOI 10.1109/36.752194
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Tang ZC, 2019, FRONT INFORM TECH EL, V20, P1087, DOI 10.1631/FITEE.1800083
   Tang ZC, 2019, IEEE ACCESS, V7, P128185, DOI 10.1109/ACCESS.2019.2940034
   Thendral R, 2017, CURR SCI INDIA, V112, P1704, DOI 10.18520/cs/v112/i08/1704-1711
   Trujillo L, 2006, INT C PATT RECOG, P211
   Wang A, 2000, MEAS CONTROL TECHNOL, V5, P1
   [王植 Wang Zhi], 2004, [中国图象图形学报. A, Journal of image and graphics], V9, P957
   Wen ZhiYuan Wen ZhiYuan, 2012, Transactions of the Chinese Society of Agricultural Engineering, V28, P152
   Xue Y, 2018, SOFT COMPUT, V22, P2935, DOI 10.1007/s00500-017-2547-1
   Yang X.-S., 2013, International Journal of Swarm Intelligence, P36, DOI DOI 10.1504/IJSI.2013.055801
   Yang XS, 2010, INT J BIO-INSPIR COM, V2, P78, DOI 10.1504/IJBIC.2010.032124
   Yu DM, 2018, SPECTROSC LETT, V51, P191, DOI 10.1080/00387010.2018.1447968
   Yu Jing, 2011, Acta Automatica Sinica, V37, P143, DOI 10.3724/SP.J.1004.2011.00143
   Zhang J., 2020, P IEEE CVF C COMP VI, P8579, DOI DOI 10.1109/CVPR42600.2020.00861
   Zhang Y, 2018, POSTHARVEST BIOL TEC, V143, P119, DOI 10.1016/j.postharvbio.2018.05.004
   Zihong Chen, 2018, Procedia Computer Science, V131, P289, DOI 10.1016/j.procs.2018.04.216
   Zou X, 2019, JIANGSU AGR SCI, V47, P248, DOI [10.15889/j.issn.1002-1302.2019.14.058, DOI 10.15889/J.ISSN.1002-1302.2019.14.058]
NR 56
TC 20
Z9 20
U1 1
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9109
EP 9136
DI 10.1007/s11042-020-10036-y
EA NOV 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000587279700002
DA 2024-07-18
ER

PT J
AU Yang, YG
   Wang, BP
   Yang, YL
   Zhou, YH
   Shi, WM
AF Yang, Yu-Guang
   Wang, Bao-Pu
   Yang, Yong-Li
   Zhou, Yi-Hua
   Shi, Wei-Min
TI Dual embedding model: a new framework for visually meaningful image
   encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Visually meaningful encrypted image; Chaotic system;
   Dual embedding
ID 2(K) CORRECTION; ALGORITHM; STEGANOGRAPHY
AB Visually meaningful image encryption (VMIE) means that a plain image is transformed into a visually meaningful cipher image which makes the plain image more imperceptible than the noise-like cipher image generated by traditional image encryption algorithms. In essence, existing VMIE algorithms exploit the idea of information steganography, i.e., embedding a secret into a host image to generate a cipher image which is visually similar to the original host image. However, it is well known that steganalysis technique is a fatal threat to steganography. Therefore, the security of existing VMIE algorithms will be potentially threatened by steganalysis technique. To improve the security of VMIE algorithms, we propose a new VMIE framework with dual embedding model. In the new framework an additional embedding phase is added. More specifically, in the first embedding process, the pre-encrypted image is embedded into the reference image to generate a visually meaningful reference cipher image. In the second embedding process, the difference between the visually meaningful reference cipher image and the original reference image is calculated to obtain a deviation matrix. Then, the deviation matrix is used as the disguised information and then embedded into the disguised host image to obtain a disguised visually meaningful encrypted image. The reference image can be any image with specified size thus ensuring the security of the VMIE algorithm. To verify the validity of the proposed VMIE framework, an example algorithm is proposed. Simulation results and performance analyses show that the example algorithm has a high time efficiency, high robustness and security.
C1 [Yang, Yu-Guang; Wang, Bao-Pu; Yang, Yong-Li; Zhou, Yi-Hua; Shi, Wei-Min] Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
   [Yang, Yu-Guang] Beijing Key Lab Trusted Comp, Beijing 100124, Peoples R China.
C3 Beijing University of Technology
RP Yang, YG (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.; Yang, YG (corresponding author), Beijing Key Lab Trusted Comp, Beijing 100124, Peoples R China.
EM yangyang7357@bjut.edu.cn
OI Yang, Yuguang/0000-0002-4040-2448
FU National Natural Science Foundation of China [62071015]; Beijing
   Municipal Science & Technology Commission [Z191100007119004]; Beijing
   Natural Science Foundation [4182006]; Guangxi Key Laboratory of
   Cryptography and Information Security [GCIS201810]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 62071015); Beijing Municipal Science & Technology
   Commission (Project Number: Z191100007119004); Beijing Natural Science
   Foundation (Grant No. 4182006); Guangxi Key Laboratory of Cryptography
   and Information Security (No. GCIS201810).
CR [Anonymous], SECUR COMMUN NETWORK
   Armijo-Correa JO, 2020, OPT LASER TECHNOL, V127, DOI 10.1016/j.optlastec.2020.106165
   Bao L, 2015, INFORM SCIENCES, V324, P197, DOI 10.1016/j.ins.2015.06.049
   Calderbank AR, 1998, APPL COMPUT HARMON A, V5, P332, DOI 10.1006/acha.1997.0238
   Cao XW, 2017, J VIS COMMUN IMAGE R, V44, P236, DOI 10.1016/j.jvcir.2016.08.003
   Cao Y, 2018, CMC-COMPUT MATER CON, V54, P197, DOI 10.3970/cmc.2018.054.197
   Chai XL, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107525
   Chai XL, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105837
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chai XL, 2017, SIGNAL PROCESS, V134, P35, DOI 10.1016/j.sigpro.2016.11.016
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Fu J, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING SERVICE AND APPLICATIONS (IEEE BIGDATASERVICE 2019), P199, DOI 10.1109/BigDataService.2019.00034
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Jiang DH, 2020, PHYS REV A, V102, DOI 10.1103/PhysRevA.102.032211
   Kanso A, 2017, OPT LASER ENG, V90, P196, DOI 10.1016/j.optlaseng.2016.10.009
   Karampidis K, 2018, J INF SECUR APPL, V40, P217, DOI 10.1016/j.jisa.2018.04.005
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Nandur D, 2018, 2018 INTERNATIONAL CONFERENCE ON COMPUTING, POWER AND COMMUNICATION TECHNOLOGIES (GUCON), P315
   Ping P, 2019, IEEE ACCESS, V7, P170168, DOI 10.1109/ACCESS.2019.2955570
   Ponuma R, 2019, MULTIMED TOOLS APPL, V78, P25707, DOI 10.1007/s11042-019-07808-6
   Sun SL, 2016, INFORM PROCESS LETT, V116, P93, DOI 10.1016/j.ipl.2015.09.016
   Tuncer T, 2019, INT J AP MAT COM-POL, V29, P817, DOI 10.2478/amcs-2019-0060
   Vanamala HR, 2019, TENCON IEEE REGION, P892, DOI [10.1109/tencon.2019.8929469, 10.1109/TENCON.2019.8929469]
   Wang H, 2019, SIGNAL PROCESS, V155, P218, DOI 10.1016/j.sigpro.2018.10.001
   Xianyi Chen, 2015, Cloud Computing and Security. First International Conference, ICCCS 2015. Revised Selected Papers: LNCS 9483, P133, DOI 10.1007/978-3-319-27051-7_12
   Xu QY, 2020, PHYS SCRIPTA, V95, DOI 10.1088/1402-4896/ab52bc
   Yang YG, 2020, OPTIK, V213, DOI 10.1016/j.ijleo.2020.164422
   Yang YG, 2019, OPT LASER TECHNOL, V119, DOI 10.1016/j.optlastec.2019.105661
   Yang YG, 2018, INFORM SCIENCES, V429, P102, DOI 10.1016/j.ins.2017.11.009
   Yang YG, 2016, INFORM SCIENCES, V345, P257, DOI 10.1016/j.ins.2016.01.078
   Zhou ZL, 2019, SOFT COMPUT, V23, P4927, DOI 10.1007/s00500-018-3151-8
   Zou LM, 2019, MULTIMED TOOLS APPL, V78, P7965, DOI 10.1007/s11042-018-6444-0
NR 33
TC 16
Z9 17
U1 4
U2 58
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9055
EP 9074
DI 10.1007/s11042-020-10149-4
EA NOV 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000587279700001
DA 2024-07-18
ER

PT J
AU He, XS
   He, F
   Xu, L
AF He, Xuan-sen
   He, Fan
   Xu, Li
TI Underdetermined mixing matrix estimation based on joint density-based
   clustering algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underdetermined blind source separation (UBSS); Mixing matrix
   estimation; Single-source-point (SSP) detection; Density based spatial
   clustering of applications with noise (DBSCAN); Clustering by fast
   search and find of density peaks (CFSFDP)
ID BLIND SOURCE SEPARATION; SPARSE COMPONENT ANALYSIS; REPRESENTATION
AB In underdetermined blind source separation (UBSS), the estimation of the mixing matrix is crucial because it directly affects the performance of UBSS. To improve the estimation accuracy, this paper proposes a joint clustering analysis method based on density based spatial clustering of applications with noise (DBSCAN) and clustering by fast search and find of density peaks (CFSFDP). In the reprocessing, the observed signals in the time domain are transformed into sparse signals in the frequency domain through a short time Fourier transform (STFT), and single-source-point (SSP) detection is used to enhance the linear clustering characteristic of signals. In addition, to facilitate the use of density-based clustering analysis, mirroring mapping is used to transform the linear clustering into compact clustering on the positive half unit circle (or sphere). For the estimation of the underdetermined mixing matrix (UMM), the DBSCAN algorithm is first used to search for high-density data points, and automatically find the number of clusters and the cluster centers; then, the CFSFDP algorithm is used to search the density peaks of the data clusters, so as to further modify the cluster centers. Because each cluster center corresponds to a column vector of the mixing matrix, the proposed algorithm can estimate the UMM through cluster analysis. The simulation results show that the proposed algorithm can not only improve the estimation accuracy of the UMM, but also provide a more robust estimator. In addition, the joint clustering method also makes up for the shortcomings of the CFSFDP algorithm that requires human intervention.
C1 [He, Xuan-sen; Xu, Li] Guangzhou Coll Commerce, Sch Informat Technol & Engn, Guangzhou 511363, Peoples R China.
   [He, Xuan-sen] Hunan Univ, Coll Informat Sci & Engn, Changsha 410082, Peoples R China.
   [He, Fan] Beijing Inst Technol, Sch Management & Econ, Beijing 100081, Peoples R China.
C3 Guangzhou College of Commerce; Hunan University; Beijing Institute of
   Technology
RP He, XS (corresponding author), Guangzhou Coll Commerce, Sch Informat Technol & Engn, Guangzhou 511363, Peoples R China.; He, XS (corresponding author), Hunan Univ, Coll Informat Sci & Engn, Changsha 410082, Peoples R China.
EM xshe2010@163.com
RI He, Xuan-sen/AAP-6658-2021
FU National Natural Science Foundation of China [60572183]
FX This project supported by National Natural Science Foundation of China
   (No. 60572183).
CR Adali T, 2014, IEEE SIGNAL PROC MAG, V31, P16, DOI 10.1109/MSP.2014.2300211
   Adali T, 2019, IEEE SENSOR LETT, V3, DOI 10.1109/LSENS.2018.2884775
   Ambroise C, 2019, ALGORITHM MOL BIOL, V14, DOI 10.1186/s13015-019-0157-4
   [Anonymous], 2009, Clustering
   Asaei A, 2016, SPEECH COMMUN, V76, P201, DOI 10.1016/j.specom.2015.07.002
   Averbuch G, 2018, GEOPHYSICS, V83, pWC43, DOI 10.1190/GEO2017-0490.1
   Bofill P, 2001, SIGNAL PROCESS, V81, P2353, DOI 10.1016/S0165-1684(01)00120-7
   Chen YW, 2018, PATTERN RECOGN, V83, P375, DOI 10.1016/j.patcog.2018.05.030
   Chen YQ, 2018, 2018 IEEE 18TH INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT), P1077, DOI 10.1109/ICCT.2018.8600136
   Chowdhury K, 2019, MULTIMED TOOLS APPL, V78, P18617, DOI 10.1007/s11042-018-7100-4
   Comon P, 2010, HANDBOOK OF BLIND SOURCE SEPARATION: INDEPENDENT COMPONENT ANALYSIS AND APPLICATIONS, P1
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Feng FC, 2019, IEEE-ACM T AUDIO SPE, V27, P442, DOI 10.1109/TASLP.2018.2881925
   Feng FC, 2018, SIGNAL PROCESS, V152, P165, DOI 10.1016/j.sigpro.2018.05.017
   Févotte C, 2006, IEEE T AUDIO SPEECH, V14, P2174, DOI 10.1109/TSA.2005.858523
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   [付宁 Fu Ning], 2008, [电子测量与仪器学报, Journal of Electronic Measurement and Instrument], V22, P63
   Georgiev P, 2005, IEEE T NEURAL NETWOR, V16, P992, DOI 10.1109/TNN.2005.849840
   Hajji Z, 2018, DIGIT SIGNAL PROCESS, V80, P70, DOI 10.1016/j.dsp.2018.05.012
   He XS, 2016, CIRC SYST SIGNAL PR, V35, P2881, DOI 10.1007/s00034-015-0173-7
   He XS, 2020, MULTIMED TOOLS APPL, V79, P13061, DOI 10.1007/s11042-020-08635-w
   He XS, 2013, CHINESE J ELECTRON, V22, P319
   He ZS, 2007, IEEE T AUDIO SPEECH, V15, P1551, DOI 10.1109/TASL.2007.898457
   Hyvärinen A, 2001, INDEPENDENT COMPONENT ANALYSIS: PRINCIPLES AND PRACTICE, P71
   Jia MS, 2018, SPEECH COMMUN, V96, P184, DOI 10.1016/j.specom.2017.12.010
   Koldovsky Z, 2019, IEEE T SIGNAL PROCES, V67, P1050, DOI 10.1109/TSP.2018.2887185
   Li YQ, 2006, IEEE T SIGNAL PROCES, V54, P423, DOI 10.1109/TSP.2005.861743
   Li YQ, 2006, IEEE T INFORM THEORY, V52, P3139, DOI 10.1109/TIT.2006.876348
   Li YQ, 2014, IEEE SIGNAL PROC MAG, V31, P96, DOI 10.1109/MSP.2013.2296790
   Mirzaei S, 2016, SPEECH COMMUN, V81, P129, DOI 10.1016/j.specom.2016.01.003
   Mohimani H, 2009, IEEE T SIGNAL PROCES, V57, P289, DOI 10.1109/TSP.2008.2007606
   Qin ZJ, 2018, IEEE SIGNAL PROC MAG, V35, P40, DOI 10.1109/MSP.2018.2789521
   Reju VG, 2009, SIGNAL PROCESS, V89, P1762, DOI 10.1016/j.sigpro.2009.03.017
   Rodriguez A, 2014, SCIENCE, V344, P1492, DOI 10.1126/science.1242072
   Su Q, 2017, AEU-INT J ELECTRON C, V77, P43, DOI 10.1016/j.aeue.2017.04.025
   Sugden P, 2003, ELECTRON LETT, V39, P158, DOI 10.1049/el:20030101
   Sun JD, 2016, NEUROCOMPUTING, V173, P623, DOI 10.1016/j.neucom.2015.08.008
   Taseska M, 2018, IEEE-ACM T AUDIO SPE, V26, P657, DOI 10.1109/TASLP.2017.2780993
   Duong TTH, 2019, IEEE-ACM T AUDIO SPE, V27, P32, DOI 10.1109/TASLP.2018.2869692
   Theis FJ, 2006, IEEE SIGNAL PROC LET, V13, P96, DOI 10.1109/LSP.2005.861590
   Took CC, 2006, IEEE T BIO-MED ENG, V53, P2123, DOI 10.1109/TBME.2006.881789
   Van Vaerenbergh S, 2006, IEEE T NEURAL NETWOR, V17, P811, DOI 10.1109/TNN.2006.872358
   Yang JJ, 2019, IEEE T CIRCUITS-I, V66, P3015, DOI 10.1109/TCSI.2019.2908394
   Zayyani H, 2009, IEEE T SIGNAL PROCES, V57, P4378, DOI 10.1109/TSP.2009.2025154
   Zhang HJ, 2017, SPEECH COMMUN, V89, P1, DOI 10.1016/j.specom.2017.02.003
   Zhang W, 2019, IEEE T BIO-MED ENG, V66, P289, DOI 10.1109/TBME.2018.2831186
   Zhen LL, 2017, IEEE T NEUR NET LEAR, V28, P3102, DOI 10.1109/TNNLS.2016.2610960
   Zhong YF, 2016, ISPRS J PHOTOGRAMM, V119, P49, DOI 10.1016/j.isprsjprs.2016.04.008
NR 48
TC 3
Z9 3
U1 2
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8281
EP 8308
DI 10.1007/s11042-020-10102-5
EA NOV 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000584348700001
DA 2024-07-18
ER

PT J
AU Tawfik, N
   Elnemr, HA
   Fakhr, M
   Dessouky, MI
   Abd El-Samie, FE
AF Tawfik, Nahed
   Elnemr, Heba A.
   Fakhr, Mahmoud
   Dessouky, Moawad I.
   Abd El-Samie, Fathi E.
TI Survey study of multimodality medical image fusion methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Imaging modalities; Medical image fusion; MRI; CT; PET; SPECT; Clinical
   diagnosis
ID WAVELET TRANSFORM; ALGORITHM; FILTER; LEVEL
AB Multimodality medical image fusion is the process of combining multiple images from single or multiple modalities of imaging. Medical image fusion methods are adopted to increase the quality of medical images by attaining the salient features in the fusion results. Hence, they raise the clinical applicability of medical images for appraisal and diagnosis problems. This purpose is achieved by capturing the complementary information presented in two or more images of different modalities in the fusion result. Medical image fusion is generally concerned with Magnetic Resonance Imaging (MRI), Magnetic Resonance Angiogram (MRA), Positron Emission Tomography (PET), Structural Positron Emission Tomography (SPET), Computerized Tomography (CT), and Single-Photon Emission Computed Tomography (SPECT) modalities. Each modality has its merits and drawbacks. This induces new fusion methods for merging information from multiple imaging modalities. Researchers have presented several methods for medical image fusion, and these methods achieved good results. However, medical image fusion is a resurgent field that needs to be enhanced to conquer the increasing challenges. This paper presents a comprehensive survey of some existing medical image fusion methods. It is expected that this study will be useful for the researchers scrutinizing medical image fusion. Furthermore, it is expected to establish a concrete foundation for developing more powerful fusion methods for medical applications.
C1 [Tawfik, Nahed; Elnemr, Heba A.; Fakhr, Mahmoud] Elect Res Inst ERI, Comp & Syst Dept, Cairo, Egypt.
   [Dessouky, Moawad I.; Abd El-Samie, Fathi E.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
   [Abd El-Samie, Fathi E.] Princess Nourah Bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Informat Technol, Riyadh 84428, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Electronics Research Institute (ERI);
   Egyptian Knowledge Bank (EKB); Menofia University; Princess Nourah bint
   Abdulrahman University
RP Tawfik, N (corresponding author), Elect Res Inst ERI, Comp & Syst Dept, Cairo, Egypt.
EM nahedtawfik@eri.sci.eg; Heba@eri.sci.eg; Mahmoud@eri.sci.eg;
   dr_moawad@yahoo.com; fathi_sayed@yahoo.com
RI Tawfik, Nahed/GYA-4057-2022; Sayed, Fathi/HRA-4752-2023
OI Sayed, Fathi/0000-0001-8749-9518; Tawfik, Nahed/0000-0002-9787-2504
CR Aishwarya N, 2018, INT J IMAG SYST TECH, V28, P175, DOI 10.1002/ima.22268
   [Anonymous], 2015, DIABETES CARE, V38, pS1, DOI 10.2337/dc15-S001
   [Anonymous], 2013, P CCSO
   [Anonymous], 2015, INDIAN J SCI TECHNOL, DOI DOI 10.17485/ijst/2015/v8i26/56192
   Bhateja V, 2015, IEEE SENS J, V15, P6783, DOI 10.1109/JSEN.2015.2465935
   Bhatnagar G, 2015, NEUROCOMPUTING, V157, P143, DOI 10.1016/j.neucom.2015.01.025
   Bhatnagar G, 2013, IEEE T MULTIMEDIA, V15, P1014, DOI 10.1109/TMM.2013.2244870
   Bhatnagar G, 2013, EXPERT SYST APPL, V40, P1708, DOI 10.1016/j.eswa.2012.09.011
   Bhatnagar G, 2012, INT J WAVELETS MULTI, V10, DOI 10.1142/S0219691311004444
   Bhatnagar V, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN HUMAN MACHINE INTERACTION (HMI), P12
   Bhavana V, 2015, PROCEDIA COMPUT SCI, V70, P625, DOI 10.1016/j.procs.2015.10.057
   Brahmbhatt KN., 2013, Int. J. Adv. Res. Eng. Technol, V4, P161
   Cao W, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P976
   Daniel E, 2017, KNOWL-BASED SYST, V131, P58, DOI 10.1016/j.knosys.2017.05.017
   Daniel E, 2017, BIOMED SIGNAL PROCES, V34, P36, DOI 10.1016/j.bspc.2017.01.003
   Das S, 2013, IEEE T BIO-MED ENG, V60, P3347, DOI 10.1109/TBME.2013.2282461
   Do MN, 2002, CONF REC ASILOMAR C, P497
   Dogra A, 2017, PATTERN RECOGN LETT, V94, P189, DOI 10.1016/j.patrec.2017.03.002
   Du J, 2016, NEUROCOMPUTING, V215, P3, DOI 10.1016/j.neucom.2015.07.160
   El-Hoseny HM, 2017, NAT RADIO SCI CO, P471, DOI 10.1109/NRSC.2017.7893518
   Ganasala P, 2016, J DIGIT IMAGING, V29, P73, DOI 10.1007/s10278-015-9806-4
   Gharbia R, 2014, ADV INTELL SYST, V303, P311, DOI 10.1007/978-3-319-08156-4_31
   Haribabu M, 2017, INT J CONTROL THEORY
   He C, 2013, MED IMAGE FUSION USI, P77
   He CT, 2010, PROCEDIA ENGINEER, V7, P280, DOI 10.1016/j.proeng.2010.11.045
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   James AP, 2014, INFORM FUSION, V19, P4, DOI 10.1016/j.inffus.2013.12.002
   Jin X, 2018, SIGNAL PROCESS, V153, P379, DOI 10.1016/j.sigpro.2018.08.002
   Kaur H, 2018, PROCEEDINGS ON 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND SECURITY (ICCCS), P112, DOI 10.1109/CCCS.2018.8586829
   Kayani BN, 2007, INNOVATIONS AND ADVANCED TECHNIQUES IN COMPUTER AND INFORMATION SCIENCES AND ENGINEERING, P129, DOI 10.1007/978-1-4020-6268-1_24
   Kor S, 2004, P ANN INT IEEE EMBS, V26, P1479
   Kumar P, 2013, INT J SCI STUDY, V1, P26
   Lewis JJ, 2007, INFORM FUSION, V8, P119, DOI 10.1016/j.inffus.2005.09.006
   Li M, 2008, LECT NOTES COMPUT SC, V5264, P658
   Liu SQ, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/156043
   Liu XB, 2017, NEUROCOMPUTING, V235, P131, DOI 10.1016/j.neucom.2017.01.006
   Liu XB, 2016, BIOMED SIGNAL PROCES, V30, P140, DOI 10.1016/j.bspc.2016.06.013
   Liu Y, 2019, IEEE SIGNAL PROC LET, V26, P485, DOI 10.1109/LSP.2019.2895749
   Liu ZD, 2014, EXPERT SYST APPL, V41, P7425, DOI 10.1016/j.eswa.2014.05.043
   Luo XQ, 2013, J ALGORITHMS COMPUT, V7, P101, DOI 10.1260/1748-3018.7.1.101
   Majumdar S, 2014, WORLD ACADSCI ENG TE, V8, P1023
   Manchanda M, 2016, J VIS COMMUN IMAGE R, V40, P197, DOI 10.1016/j.jvcir.2016.06.021
   Mehta N., 2018, BIOMED PHARMACOL J, V11, P1937, DOI [10.13005/bpj/1566, DOI 10.13005/bpj/1566]
   Nirmala DE, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P743
   Parekh P, 2014, INT J COMPUTER APPL, V90, P12
   Pohl C, 1998, INT J REMOTE SENS, V19, P823, DOI 10.1080/014311698215748
   Ramlal SD, 2018, SIGNAL IMAGE VIDEO P, V12, P1479, DOI 10.1007/s11760-018-1303-z
   Rn P, 2014, INT C ADV COMP COMM, P1
   Singh R, 2014, INFORM FUSION, V19, P49, DOI 10.1016/j.inffus.2012.09.005
   Singh S, 2015, BIOMED SIGNAL PROCES, V18, P91, DOI 10.1016/j.bspc.2014.11.009
   Srivastava R, 2016, IET COMPUT VIS, V10, P513, DOI 10.1049/iet-cvi.2015.0251
   Sruthy S, 2013, 2013 IEEE INTERNATIONAL MULTI CONFERENCE ON AUTOMATION, COMPUTING, COMMUNICATION, CONTROL AND COMPRESSED SENSING (IMAC4S), P160, DOI 10.1109/iMac4s.2013.6526400
   Vijayarajan R, 2015, AEU-INT J ELECTRON C, V69, P896, DOI 10.1016/j.aeue.2015.02.007
   Wang L, 2014, INFORM FUSION, V19, P20, DOI 10.1016/j.inffus.2012.03.002
   Xia JM, 2018, COMPUT MATH METHOD M, V2018, DOI 10.1155/2018/2806047
   Xu L, 2013, INT J ADV ROBOT SYST, V10, DOI 10.5772/56345
   Xu XJ, 2016, BIOMED SIGNAL PROCES, V27, P103, DOI 10.1016/j.bspc.2016.02.008
   Xu XZ, 2016, APPL SOFT COMPUT, V46, P588, DOI 10.1016/j.asoc.2016.03.028
   Yang Y, 2016, IEEE SENS J, V16, P3735, DOI 10.1109/JSEN.2016.2533864
   Yin F, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/3020461
   Yin M, 2019, IEEE T INSTRUM MEAS, V68, P49, DOI 10.1109/TIM.2018.2838778
   Zhang Z, 1999, P IEEE, V87, P1315, DOI 10.1109/5.775414
   Zhu ZQ, 2019, IEEE ACCESS, V7, P20811, DOI 10.1109/ACCESS.2019.2898111
   Zhu ZQ, 2016, NEUROCOMPUTING, V214, P471, DOI 10.1016/j.neucom.2016.06.036
   Zong JJ, 2017, BIOMED SIGNAL PROCES, V34, P195, DOI 10.1016/j.bspc.2017.02.005
NR 65
TC 37
Z9 37
U1 3
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 6369
EP 6396
DI 10.1007/s11042-020-08834-5
EA OCT 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000577869200001
DA 2024-07-18
ER

PT J
AU Manohar, K
   Kieu, TD
AF Manohar, Kris
   Kieu, The Duc
TI A counter-embedding IPVO based reversible data hiding technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pixel value ordering; PVO; Improved pixel value ordering; IPVO;
   Reversible data hiding; Steganography; Counter-embedding; Watermarking
ID SCHEME; PVO; VQ
AB Improved pixel value ordering utilizes two embedding procedures. These are the maximum and minimum embedding procedures. The maximum embedding procedure modifies a pixel by either 0 or 1, while the minimum embedding procedure modifies a pixel by either 0 or - 1. Our counter-embedding strategy modifies a corner pixel using both embedding procedures. This strategy exploits the opposing distortions of each embedding procedure and can embed up to 2 secret bits into a single pixel. The proposed scheme consists of two stages. The first stage applies the counter-embedding strategy to two corner pixels of an input block. Thus, it can conceal up to four bits per block. However, this stage generates some auxiliary information which is embedded in the second stage using the traditional IPVO. The second stage minimizes distortions by only modifying pixels that the first stage ignored. Our experimental results confirm that the proposed scheme improves the visual quality of the recent related works. On average, for embedding capacities of 10,000, 20,000, 30,000, and 40,000 bits, it increases the visual quality by at least 1.2 dB.
C1 [Manohar, Kris; Kieu, The Duc] Univ West Indies, Fac Sci & Technol, Dept Comp & Informat Technol, St Augustine, Trinidad Tobago.
C3 University West Indies Mona Jamaica; University West Indies Saint
   Augustine
RP Kieu, TD (corresponding author), Univ West Indies, Fac Sci & Technol, Dept Comp & Informat Technol, St Augustine, Trinidad Tobago.
EM justkrismanohar@gmail.com; ktduc0323@yahoo.com.au
CR Abbasi R, 2022, T EMERG TELECOMMUN T, V33, DOI 10.1002/ett.3680
   Chang CC, 2013, J SYST SOFTWARE, V86, P389, DOI 10.1016/j.jss.2012.09.001
   Cheng PH, 2017, MULTIMED TOOLS APPL, V76, P6031, DOI 10.1007/s11042-015-3142-z
   Davis R. M., 1978, IEEE Communications Society Magazine, V16, P5, DOI 10.1109/MCOM.1978.1089771
   Di FQ, 2019, MULTIMED TOOLS APPL, V78, P7125, DOI 10.1007/s11042-018-6469-4
   Gao ED, 2019, INFORM SCIENCES, V505, P549, DOI 10.1016/j.ins.2019.07.101
   He WG, 2018, INFORM SCIENCES, V467, P784, DOI 10.1016/j.ins.2018.04.088
   He WG, 2017, J VIS COMMUN IMAGE R, V46, P58, DOI 10.1016/j.jvcir.2017.03.010
   Hong W, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10020036
   Kim C, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040644
   Kim C, 2018, DISPLAYS, V55, P71, DOI 10.1016/j.displa.2018.04.002
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Lee CF, 2020, J SUPERCOMPUT, V76, P2683, DOI 10.1007/s11227-019-03052-9
   Li R, 2019, MATH BIOSCI ENG, V16, P5324, DOI 10.3934/mbe.2019266
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lu TC, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10120764
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ou B, 2016, J VIS COMMUN IMAGE R, V39, P12, DOI 10.1016/j.jvcir.2016.05.005
   Pan ZB, 2019, MULTIMED TOOLS APPL, V78, P26047, DOI 10.1007/s11042-019-7692-3
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Prabha KR, 2020, MULTIMED TOOLS APPL, V79, P4057, DOI 10.1007/s11042-019-07772-1
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Qin JQ, 2019, IEEE SIGNAL PROC LET, V26, P843, DOI 10.1109/LSP.2019.2909080
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Sah B, 2019, INT J INTEGR ENG, V11, P63
   Shaji C, 2019, IMAGING SCI J, V67, P202, DOI 10.1080/13682199.2019.1592892
   Swain G, 2019, ARAB J SCI ENG, V44, P2995, DOI 10.1007/s13369-018-3372-2
   Wang WQ, 2020, MULTIMED TOOLS APPL, V79, P555, DOI 10.1007/s11042-019-08065-3
   Wang Y, 2019, MULTIMED TOOLS APPL, V78, P16965, DOI 10.1007/s11042-018-7042-x
   Wang Y, 2018, MULTIMED TOOLS APPL, V77, P21571, DOI 10.1007/s11042-017-5584-y
   Weng SW, 2019, IEEE ACCESS, V7, P34570, DOI 10.1109/ACCESS.2019.2904174
   Weng SW, 2018, MULTIMED TOOLS APPL, V77, P13419, DOI 10.1007/s11042-017-4959-4
   Wu HR, 2019, J REAL-TIME IMAGE PR, V16, P685, DOI 10.1007/s11554-019-00867-w
   Wu X, 2017, IEEE IJCNN, P214, DOI 10.1109/IJCNN.2017.7965857
   Xu M, 2019, MULTIMED TOOLS APPL, V78, P8003, DOI 10.1007/s11042-018-6486-3
NR 37
TC 0
Z9 0
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5873
EP 5900
DI 10.1007/s11042-020-09963-7
EA OCT 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000576709300004
DA 2024-07-18
ER

PT J
AU Cai, MX
   Wang, SS
   Wu, C
AF Cai, Mingxin
   Wang, Shanshan
   Wu, Chao
TI Research on real-time data transmission and multi-scale video image
   decomposition of embedded optical sensor array based on machine learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Embedded; Sensor; Data transmission; Spatiotemporal online dictionary
   learning; Multi-scale image; Machine learning
ID DICTIONARY; RECOGNITION
AB Aiming at the research of real-time data transmission and multi-scale image decomposition of embedded optical sensor array, the principle, method and fusion strategy of multi-sensor image fusion are studied comprehensively, thoroughly and systematically by combining the imaging characteristics of source image with multi-scale geometric analysis tools using machine learning algorithm. A new quality scalable video image coding framework is also proposed in this paper, which is implemented by a multi-scale online dictionary learning algorithm based on structured sparse video signals. For the purpose of different types of images and image fusion, a new high quality scalable video image coding framework based on machine learning algorithm is proposed on the basis of comprehensive analysis of prior information such as imaging mechanism of image sensor and imaging characteristics of source image. A multi-scale online dictionary learning algorithm based on machine learning for sparse video signal structure is proposed. Through the hierarchical structure of wavelet decomposition, the searching domain of online learning is optimized to a hierarchical sparse block, and its sparse representation coefficients are obtained by using machine learning sparse coding idea. The real-time data transmission of embedded optical sensor array based on machine learning and multi-scale image decomposition algorithm proposed in this paper have good fusion performance, which is of great significance for further research and engineering application of image fusion technology.
C1 [Cai, Mingxin; Wang, Shanshan; Wu, Chao] Northeastern Univ, Coll Comp Sci, Shenyang 110169, Peoples R China.
C3 Northeastern University - China
RP Cai, MX (corresponding author), Northeastern Univ, Coll Comp Sci, Shenyang 110169, Peoples R China.
EM 1801700@stu.neu.edu.cn
RI Wang, Shan-Shan/S-8186-2019; Cai, Mingxin/JGM-5121-2023
OI Cai, Mingxin/0000-0002-0941-5531
CR Al-Ariki HDE, 2017, WIREL NETW, V23, P1823, DOI 10.1007/s11276-016-1256-5
   [Anonymous], 2014, IEEE SENS J, V14, P4253
   [Anonymous], 2013, J NETWORKS
   Arun KS, 2015, INT J MULTIMED INF R, V4, P165, DOI 10.1007/s13735-015-0076-1
   Barmpoutis A, 2013, IEEE T CYBERNETICS, V43, P1347, DOI 10.1109/TCYB.2013.2276430
   Cho SG, 2019, INT J INTELL ROBOT, V3, P418, DOI 10.1007/s41315-019-00115-1
   Goh H, 2014, IEEE T NEUR NET LEAR, V25, P2212, DOI 10.1109/TNNLS.2014.2307532
   Han M, 2020, J POWER ELECTRON, V20, P43, DOI 10.1007/s43236-019-00013-6
   Lee SH, 2015, WIREL NETW, V21, P883, DOI 10.1007/s11276-014-0827-6
   Li F, 2017, FRONT INFORM TECH EL, V18, P1795, DOI 10.1631/FITEE.1600039
   Li LY, 2014, IMAGE VISION COMPUT, V32, P814, DOI 10.1016/j.imavis.2014.02.007
   Liu Q, 2013, COMPUT COMMUN, V36, P269, DOI 10.1016/j.comcom.2012.09.016
   Mertens F, 2015, ASTRON ASTROPHYS, V574, DOI 10.1051/0004-6361/201424566
   Mohammadi MR, 2014, J VIS COMMUN IMAGE R, V25, P1082, DOI 10.1016/j.jvcir.2014.03.006
   Passieux JC, 2015, EXP MECH, V55, P121, DOI 10.1007/s11340-014-9872-4
   Rezaie-Balf M, 2019, HYDROL RES, V50, P498, DOI 10.2166/nh.2018.050
   Srinivas M, 2015, NEUROCOMPUTING, V168, P880, DOI 10.1016/j.neucom.2015.05.036
   Sun YQ, 2016, MULTIMED TOOLS APPL, V75, P1409, DOI 10.1007/s11042-014-2179-8
   Wang DH, 2014, PATTERN RECOGN, V47, P885, DOI 10.1016/j.patcog.2013.08.004
   Wen BH, 2015, INT J COMPUT VISION, V114, P137, DOI 10.1007/s11263-014-0761-1
   Xiang SM, 2015, INT J COMPUT VISION, V114, P248, DOI 10.1007/s11263-014-0755-z
   Xie H, 2014, IEEE SENS J, V14, P3283, DOI 10.1109/JSEN.2014.2328182
   Xing L, 2017, MATH BIOSCIE ENG ONL, V3, P389
   Yang JM, 2017, IEEE T PATTERN ANAL, V39, P576, DOI 10.1109/TPAMI.2016.2547384
   Yang YB, 2015, PATTERN RECOGN, V48, P3067, DOI 10.1016/j.patcog.2015.03.012
   Ye H, 2018, IEEE T POWER DELIVER, V33, P32, DOI 10.1109/TPWRD.2016.2630338
   Yeh CH, 2014, J VIS COMMUN IMAGE R, V25, P891, DOI 10.1016/j.jvcir.2014.02.012
   Zheng JJ, 2016, IEEE T IMAGE PROCESS, V25, P2542, DOI 10.1109/TIP.2016.2548242
   Zhou J, 2014, J TEXT I, V105, P223, DOI 10.1080/00405000.2013.836784
NR 29
TC 0
Z9 0
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 41407
EP 41427
DI 10.1007/s11042-020-09847-w
EA OCT 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000575795600006
DA 2024-07-18
ER

PT J
AU Singh, P
   Sehgal, P
AF Singh, Prerna
   Sehgal, Priti
TI G.V Black dental caries classification and preparation technique using
   optimal CNN-LSTM classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE G; V black Classification; Convolution neural network; Long short-term
   memory model; Dental caries
AB Dental caries is one of the oral diseases which are a major health problem for many people across the globe. It can lead to pain, discomfort, disfigurement, and even death in some cases. Dental caries is caused by the infection of the calcified tissue of the teeth. They can be prevented easily by early diagnosis and treated in the early stages. The development of a reliable model for the diagnosis and classification of dental caries can lead to effective and timely treatment. The G.V Black Classification system of dental caries is one of the systems which is widely accepted worldwide. It classifies caries into six classes based on the location of caries. This paper proposes a novel deep convolution layer network (CNN) with a Long Short-Term Memory (LSTM) model for the detection and diagnosis of dental caries on periapical dental images. The proposed model utilizes a convolutional neural network for extracting the features and Long Short term memory (LSTM) for conducting short-term and long-term dependencies. The main objective of this study is to detect dental caries and classify them into various classes based on G.V Black Classification. The periapical dental images are pre-processed and are fed as input to deep convolutional neural networks. The deep convolutional neural network classifies the input into various classes. The proposed algorithm is optimized using the Dragonfly optimization algorithm and gave an accuracy of 96%. Experiments are conducted to evaluate and compare the proposed model with the recent state-of-art deep learning models. This study justifies that a deep convolutional neural network is one of the most efficient ways to detect and classify dental caries into various G.V black classes. The achieved accuracy of the proposed optimal CNN-LSTM model for G.V black classification proves its efficacy as compared to the classification accuracy achieved by widely used pre-trained CNN models i.e. Alexnet (accuracy: 93%) and GoogleNet (accuracy: 94%) on the same database. The performance of the proposed CNN-LSTM model is further strengthened by comparing the results with the CNN model, 2 layer LSTM model and CNN-LSTM model without dragonfly optimization. The proposed optimal CNN-LSTM model shows the best performance with 96% accuracy and helps in dental image classification as the second opinion to the medical expert.
C1 [Singh, Prerna] Univ Delhi, Dept Comp Sci, Delhi, India.
   [Sehgal, Priti] Univ Delhi, Dept Comp Sci, Keshav Mahavidyalaya, Delhi, India.
C3 University of Delhi; University of Delhi
RP Singh, P (corresponding author), Univ Delhi, Dept Comp Sci, Delhi, India.
EM prerna.singh@jimsindia.org; psehgal@keshav.du.ac.in
RI Sehgal, Priti/KRP-8258-2024
CR Aditi M. K., 2019, INT J ENG ADV TECHNO, V8, P1342, DOI [DOI 10.35940/IJEAT.F8602.088619, 10.35940/ijeat.F8602.088619]
   Arul Selvan K, 2011, THESIS
   Datta S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS, VISION AND INFORMATION SECURITY (CGVIS), P89, DOI 10.1109/CGVIS.2015.7449899
   Fawaz HI, 2019, DATA MIN KNOWL DISC, V33, P917, DOI 10.1007/s10618-019-00619-1
   Guo YM, 2018, MULTIMED TOOLS APPL, V77, P10251, DOI 10.1007/s11042-017-5443-x
   Hwang JJ, 2019, IMAGNG SCI DENT, V49, P1, DOI 10.5624/isd.2019.49.1.1
   Imangaliyev Sultan, 2016, Machine Learning, Optimization and Big Data. Second International Workshop, MOD 2016. Revised Selected Papers: LNCS 10122, P407, DOI 10.1007/978-3-319-51469-7_34
   Karimian N, 2018, PROC SPIE, V10473, DOI 10.1117/12.2291088
   Laurence J.Walsh, 2018, CARIES DIAGNOSIS AID, DOI 10.5772/intechopen.75459
   Lee JH, 2018, J DENT, V77, P106, DOI 10.1016/j.jdent.2018.07.015
   Liu T, 2012, WELDING SENSORS, V18, P15
   Livieris IE, 2020, NEURAL COMPUT APPL, V32, P17351, DOI 10.1007/s00521-020-04867-x
   Miki Y, 2017, COMPUT BIOL MED, V80, P24, DOI 10.1016/j.compbiomed.2016.11.003
   Mirjalili S, 2016, NEURAL COMPUT APPL, V27, P495, DOI 10.1007/s00521-015-1870-7
   Murata S, 2017, P IEEE INT C E-SCI, P1, DOI 10.1109/eScience.2017.12
   Murtaza G, 2020, MULTIMED TOOLS APPL, V79, P15481, DOI 10.1007/s11042-019-7525-4
   Naebi M, 2016, INT J DENT, V2016, DOI 10.1155/2016/3264545
   Prajapati SA, 2017, 2017 5TH INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL AND BUSINESS INTELLIGENCE (ISCBI), P70, DOI 10.1109/ISCBI.2017.8053547
   Rahman CM, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/9293617
   Salehi HS, 2019, LASERS DENT, V10857
   Scheid RC, 2007, DENT ANATOMY
   Singh P, 2019, 4 INT C ADV COMP INT
   Singh P, 2017, INT CONF COMPUT
   Srivastava MM, 2017, NIPS 2017 WORKSH MAC
   Yadav AK, 2015, 2015 THIRD INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P428, DOI 10.1109/ICIIP.2015.7414811
   Zhu YL, 2013, INT CONF MEAS, P17, DOI 10.1109/ICMTMA.2013.16
NR 26
TC 30
Z9 32
U1 3
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5255
EP 5272
DI 10.1007/s11042-020-09891-6
EA OCT 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000575795600009
DA 2024-07-18
ER

PT J
AU Liang, K
   Yang, XJ
   Xu, YX
   Wang, R
   Nie, FP
AF Liang, Ke
   Yang, XiaoJun
   Xu, YuXiong
   Wang, Rong
   Nie, Feiping
TI Ratio sum formula for dimensionality reduction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ratio sum; Trace ratio; Feature selection; Dimensionality reduction
ID CRITERION
AB High-dimensional data analysis often suffers the so-called curse of dimensionality. Therefore, dimensionality reduction is usually carried out on the high-dimensional data before the actual analysis, which is a common and efficient way to eliminate this effect. And the popular trace ratio criterion is an extension of the original linear discriminant analysis (LDA) problem, which involves a search of a transformation matrixWto embed high-dimensional space into a low-dimensional space to achieve dimensionality reduction. However, the trace ratio criterion tends to obtain projection direction with very small variance, which the subset after the projection is diffcult to present the most representative information of the data with maximum efficiency. In this paper, we target on this problem and propose the ratio sum formula for dimensionality reduction. Firstly, we analyze the impact of this trend. Then in order to solve this problem, we propose a new ratio sum formula as well as the solution. In the end, we perform experiments on the Yale-B, ORL, and COIL-20 data sets. The theoretical studies and actual numerical analysis confirm the effectiveness of the proposed method.
C1 [Liang, Ke; Yang, XiaoJun; Xu, YuXiong] Guangdong Univ Technol, Sch Informat Engn, Guangzhou 510006, Guangdong, Peoples R China.
   [Yang, XiaoJun] Synergy Innovat Inst GDUT, Heyuan 517000, Guangdong, Peoples R China.
   [Wang, Rong; Nie, Feiping] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.
   [Wang, Rong; Nie, Feiping] Northwestern Polytech Univ, Ctr Opt Imagery Anal & Learning, Xian 710072, Peoples R China.
C3 Guangdong University of Technology; Northwestern Polytechnical
   University; Northwestern Polytechnical University
RP Yang, XJ (corresponding author), Guangdong Univ Technol, Sch Informat Engn, Guangzhou 510006, Guangdong, Peoples R China.; Yang, XJ (corresponding author), Synergy Innovat Inst GDUT, Heyuan 517000, Guangdong, Peoples R China.
EM yangxj18@gdut.edu.cn
RI Wang, Rong/JQI-7854-2023; zhang, xinyi/JWA-0980-2024; Nie,
   Feiping/B-3039-2012; Lu, Rui/KCJ-8212-2024
OI Wang, Rong/0009-0009-5350-5743; 
FU National R&D Program of China [2018YFB1802100]; Department of Science
   and Technology at Guangdong Province [2018B030338001, 2018B010107003,
   2018B010115002, 2015B010127015]; National Nature Science Foundation of
   China [61974035]
FX The authors would like to thank the editors and anonymous reviews for
   providing useful suggestion to improve the quality of the paper. This
   work was partially supported by National R&D Program of China
   2018YFB1802100, Department of Science and Technology at Guangdong
   Province with Grant no. 2018B030338001, 2018B010107003, 2018B010115002
   and 2015B010127015, and National Nature Science Foundation of China(No.
   61974035).
CR Ang JC, 2016, IEEE ACM T COMPUT BI, V13, P971, DOI 10.1109/TCBB.2015.2478454
   Badjio FE, 2005, P INT S APPL STOCH M, P266
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Cai D., 2007, Proceedings of the 15th international conference on Multimedia, P403, DOI [DOI 10.1145/1291233.1291329, 10.1145/1291233.1291329]
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Danubianu M, 2012, INT J COMPUT COMMUN, V7, P824
   Das S., 2001, P 18 INT C MACHINE L, P74, DOI DOI 10.5555/645530.658297
   Du L, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3476
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Gao QX, 2013, IEEE T IMAGE PROCESS, V22, P2521, DOI 10.1109/TIP.2013.2249077
   Garces E, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601131
   Guo YF, 2003, PATTERN RECOGN LETT, V24, P147, DOI 10.1016/S0167-8655(02)00207-6
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Huang Y, 2012, IEEE T NEUR NET LEAR, V23, P519, DOI 10.1109/TNNLS.2011.2178037
   Jia YQ, 2009, IEEE T NEURAL NETWOR, V20, P729, DOI 10.1109/TNN.2009.2015760
   Li JH, 2014, OPT FIBER TECHNOL, V20, P100, DOI 10.1016/j.yofte.2013.12.008
   Liu Wenyuan, 2014, Sheng Wu Yi Xue Gong Cheng Xue Za Zhi, V31, P85
   Liu XL, 2016, IEEE T IMAGE PROCESS, V25, P4514, DOI 10.1109/TIP.2016.2593344
   Liu Y, 2013, NEUROCOMPUTING, V105, P12, DOI 10.1016/j.neucom.2012.05.031
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Qu YP, 2019, ARTIF INTELL MED, V100, DOI 10.1016/j.artmed.2019.101722
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Saad Y, 1995, JAHRESBERICHT DTSCH, V97, P62
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   van der Maaten L. J. P., 2008, Journal of Machine Learning Research, V9, P2579, DOI DOI 10.1007/S10479-011-0841-3
   Wang H, 2007, WORKS POSIT NAVIGAT, P1
   Wang R, 2019, IEEE T GEOSCI REMOTE, V57, P7352, DOI 10.1109/TGRS.2019.2913004
   Wang R, 2017, IEEE T IMAGE PROCESS, V26, P5019, DOI 10.1109/TIP.2017.2726188
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Xu M, 2013, IEEE T IMAGE PROCESS, V22, P3041, DOI 10.1109/TIP.2013.2253480
   Yang XJ, 2018, MULTIMED TOOLS APPL, V77, P3071, DOI 10.1007/s11042-017-5022-1
   Yang YH, 2017, IEEE T MULTIMEDIA, V19, P519, DOI 10.1109/TMM.2016.2626959
   Yu MT, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON FRONTIERS OF SENSORS TECHNOLOGIES (ICFST), P265, DOI 10.1109/ICFST.2017.8210516
   Zhang L., 2016, BMC BIOTECHNOL, V16, P1, DOI DOI 10.1186/s12888-015-0706-4
   Zhang LF, 2015, PATTERN RECOGN, V48, P3102, DOI 10.1016/j.patcog.2014.12.016
   Zhang P, 2011, PATTERN RECOGN LETT, V32, P181, DOI 10.1016/j.patrec.2010.10.005
NR 37
TC 1
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4367
EP 4382
DI 10.1007/s11042-020-09782-w
EA SEP 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000573766700005
DA 2024-07-18
ER

PT J
AU Knapik, M
   Cyganek, B
AF Knapik, Mateusz
   Cyganek, Boguslaw
TI Fast eyes detection in thermal images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Eye detection; Thermal imaging; Virtual high dynamic range; Drowsiness
   control sparse descriptor
ID RECOGNITION
AB In recent years many methods have been proposed for eye detection. In some cases however, such as driver drowsiness detection, lighting conditions are so challenging that only the thermal imaging is a robust alternative to the visible light sensors. However, thermal images suffer from poor contrast and high noise, which arise due to the physical properties of the long waves processing. In this paper we propose an efficient method for eyes detection based on thermal image processing which can be successfully used in challenging environments. Image pre-processing with novel virtual high dynamic range procedure is proposed, which greatly enhances thermal image contrast and allows for more reliable computation of sparse image descriptors. The bag-of-visual-words approach with clustering was selected for final detections. We compare our method with the YOLOv3 deep learning model. Our method attains high accuracy and fast response in real conditions without computational complexity and requirement of a big dataset associated with the deep neural networks. For quantitative analysis a series of thermal video sequences were recorded in which eye locations were manually annotated. Created dataset was made publicly available on our website.
C1 [Knapik, Mateusz; Cyganek, Boguslaw] AGH Univ Sci & Technol, Al Adama Mickiewicza 30, PL-30059 Krakow, Poland.
C3 AGH University of Krakow
RP Cyganek, B (corresponding author), AGH Univ Sci & Technol, Al Adama Mickiewicza 30, PL-30059 Krakow, Poland.
EM mknapik@agh.edu.pl; cyganek@agh.edu.pl
RI Knapik, Mateusz/Z-4573-2019; Cyganek, Bogusław/HOC-1103-2023
OI Knapik, Mateusz/0000-0001-5042-5160; Cyganek,
   Boguslaw/0000-0001-5185-1145
FU Polish National Science Center NCN [2014/15/B/ST6/00609]
FX This work was supported by the Polish National Science Center NCN under
   the grant no. 2014/15/B/ST6/00609.
CR Abualigah L, 2020, NEURAL COMPUT APPL, V32, P11195, DOI 10.1007/s00521-019-04629-4
   Abualigah LM, 2018, INTELL DECIS TECHNOL, V12, P3, DOI 10.3233/IDT-170318
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chellappa R, 2014, FEATURE SELECTION, P291
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Cyganek B, 2013, OBJECT DETECTION AND RECOGNITION IN DIGITAL IMAGES: THEORY AND PRACTICE, P1, DOI 10.1002/9781118618387
   Cyganek B, 2018, P 6 IIAE INT C IND A
   Cyganek B, 2007, LECT NOTES COMPUT SC, V4477, P330
   Cyganek B, 2014, NEUROCOMPUTING, V126, P78, DOI 10.1016/j.neucom.2013.01.048
   Fan DP, 2019, IEEE I CONF COMP VIS, P5611, DOI 10.1109/ICCV.2019.00571
   Fulkerson B, 2008, LECT NOTES COMPUT SC, V5302, P179, DOI 10.1007/978-3-540-88682-2_15
   Ghiass R, 2014, THESIS, DOI [10.13140/2.1.4447.3122, DOI 10.13140/2.1.4447.3122]
   Ke W, 2009, 16 IEEE INT C IM PRO, P2665
   Khan SA, 2018, IEEE ACCESS, V6, P67459, DOI 10.1109/ACCESS.2018.2878601
   Knapik M, 2019, NEUROCOMPUTING, V338, P274, DOI 10.1016/j.neucom.2019.02.014
   Kwasniewska A, 2017, C HUM SYST INTERACT, P41, DOI 10.1109/HSI.2017.8004993
   Leng L, 2011, DYNAMIC WEIGHTED DIS
   Leng L, 2010, P IEEE INT C INF COM, V2010, P467, DOI DOI 10.1109/ICTC.2010.5674791
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leys C, 2013, J EXP SOC PSYCHOL, V49, P764, DOI 10.1016/j.jesp.2013.03.013
   Liao YH, 2009, BMC MICROBIOL, V9, DOI 10.1186/1471-2180-9-172
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahmood A, 2019, IEEE ACCESS, V7, P161584, DOI 10.1109/ACCESS.2019.2951468
   Malpani S, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P3135, DOI 10.1109/TENCON.2016.7848627
   Marzec M, 2016, MULTIMEDIA TOOLS APP
   MILLER J, 1991, Q J EXP PSYCHOL-A, V43, P907, DOI 10.1080/14640749108400962
   Munir A, 2018, OPTIK, V158, P1016, DOI 10.1016/j.ijleo.2018.01.003
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   qqwweee, 2018, KER YOLOV3
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Shehab M, 2021, ENG COMPUT-GERMANY, V37, P2931, DOI 10.1007/s00366-020-00971-7
   Shehab M, 2020, NEURAL COMPUT APPL, V32, P9859, DOI 10.1007/s00521-019-04570-6
   Sonkusare S, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-41172-7
   Strkowska Maria, 2015, Measurement Automation Monitoring, V61, P199
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tarannum A, 2020, J BIOMOL STRUCT DYN, V38, P918, DOI 10.1080/07391102.2019.1585952
   Wang S, 2017, FEATURE SELECTION, P503
   Wang SF, 2013, PATTERN RECOGN, V46, P2613, DOI 10.1016/j.patcog.2013.03.001
   Zeng JX, 2019, IEEE ACCESS, V7, P57163, DOI 10.1109/ACCESS.2019.2913688
   Zhang L, 2016, KNOWL-BASED SYST, V111, P248, DOI 10.1016/j.knosys.2016.08.018
   Zhang YQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041010
NR 42
TC 7
Z9 7
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3601
EP 3621
DI 10.1007/s11042-020-09403-6
EA SEP 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572335600007
OA hybrid
DA 2024-07-18
ER

PT J
AU Rashmi, M
   Ashwin, TS
   Guddeti, RMR
AF Rashmi, M.
   Ashwin, T. S.
   Guddeti, Ram Mohana Reddy
TI Surveillance video analysis for student action recognition and
   localization inside computer laboratories of a smart campus
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action recognition; Smart campus; Object detection; Object
   localization; Neural networks; Computer enabled laboratories
ID ENGAGEMENT; AGREEMENT; RETRIEVAL
AB In the era of smart campus, unobtrusive methods for students' monitoring is a challenging task. The monitoring system must have the ability to recognize and detect the actions performed by the students. Recently many deep neural network based approaches have been proposed to automate Human Action Recognition (HAR) in different domains, but these are not explored in learning environments. HAR can be used in classrooms, laboratories, and libraries to make the teaching-learning process more effective. To make the learning process more effective in computer laboratories, in this study, we proposed a system for recognition and localization of student actions from still images extracted from (Closed Circuit Television) CCTV videos. The proposed method uses (You Only Look Once) YOLOv3, state-of-the-art real-time object detection technology, for localization, recognition of students' actions. Further, the image template matching method is used to decrease the number of image frames and thus processing the video quickly. As actions performed by the humans are domain specific and since no standard dataset is available for students' action recognition in smart computer laboratories, thus we created the STUDENT ACTION dataset using the image frames obtained from the CCTV cameras placed in the computer laboratory of a university campus. The proposed method recognizes various actions performed by students in different locations within an image frame. It shows excellent performance in identifying the actions with more samples compared to actions with fewer samples.
C1 [Rashmi, M.; Ashwin, T. S.; Guddeti, Ram Mohana Reddy] Natl Inst Technol Karnataka Surathkal, Dept Informat Technol, Mangalore 575025, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka
RP Rashmi, M (corresponding author), Natl Inst Technol Karnataka Surathkal, Dept Informat Technol, Mangalore 575025, India.
EM nm.rashmi@gmail.com; ashwindixit9@gmail.com; profgrmreddy@nitk.edu.in
RI S, ASHWIN T/Z-2285-2019; Guddeti, Ram Mohana Reddy/W-9494-2018; Guddeti,
   Ram Mohana Reddy/ABB-5181-2021
OI S, ASHWIN T/0000-0002-1690-1626; Guddeti, Ram Mohana
   Reddy/0000-0003-1361-3837; M, Rashmi/0000-0003-2101-5992
CR Ashwin TS, 2019, IEEE ACCESS, V7, P150693, DOI 10.1109/ACCESS.2019.2947519
   Ashwin TS, 2020, EDUC INF TECHNOL, V25, P1387, DOI 10.1007/s10639-019-10004-6
   Baziyad M, 2018, IEEE INT CONF INNOV, P1, DOI 10.1109/INNOVATIONS.2018.8606008
   Bian CL, 2019, IET COMPUT VIS, V13, P329, DOI 10.1049/iet-cvi.2018.5281
   Bosch N, 2021, IEEE T AFFECT COMPUT, V12, P974, DOI 10.1109/TAFFC.2019.2908837
   Brownlee J, USE ROC CURVES PRECI
   Candra Kirana Kartika, 2018, 2018 3rd International Seminar on Application for Technology of Information and Communication. Proceedings, P406, DOI 10.1109/ISEMANTIC.2018.8549735
   Carlueho J, 2018, IEEE INT C INT ROBOT, P2336, DOI 10.1109/IROS.2018.8594067
   Castañón G, 2016, IEEE T CIRC SYST VID, V26, P2313, DOI 10.1109/TCSVT.2015.2473295
   Chamba L, 2016, IEEE LAT AM T, V14, P3826, DOI 10.1109/TLA.2016.7786370
   Chaudhary S, 2019, IET COMPUT VIS, V13, P15, DOI 10.1049/iet-cvi.2018.5020
   Cheng H, 2014, MULTIMED TOOLS APPL, V70, P177, DOI 10.1007/s11042-012-1162-5
   Chintalapati S, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMPUTING RESEARCH (ICCIC), P541
   Chou KP, 2018, IEEE ACCESS, V6, P15283, DOI 10.1109/ACCESS.2018.2809552
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Conte D, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/231240
   D'Mello S, 2007, IEEE INTELL SYST, V22, P53, DOI 10.1109/MIS.2007.79
   Davis JJ., 2006, PROC INT C MACHINE L, DOI DOI 10.1145/1143844.1143874
   Du SY, 2016, 2016 8TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY IN MEDICINE AND EDUCATION (ITME), P714, DOI [10.1109/ITME.2016.0166, 10.1109/ITME.2016.25]
   Eweiwi A, 2015, PATTERN RECOGN LETT, V51, P8, DOI 10.1016/j.patrec.2014.07.017
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gu J, 2019, BBOX LABEL TOOL
   Gupta SK, 2018, IEEE INT CONF ADV LE, P101, DOI 10.1109/ICALT.2018.00131
   Holland O, 2016, 2016 23RD INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS (ICT), DOI 10.1109/ICT.2016.7500442
   Huang M, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3177757
   Jo H, 2017, INT C CONTR AUTOMAT, P1035, DOI 10.23919/ICCAS.2017.8204369
   Kim Y, 2018, IEEE ACCESS, V6, P5308, DOI 10.1109/ACCESS.2018.2791861
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Li R, 2018, IEEE ACCESS, V6, P61386, DOI 10.1109/ACCESS.2018.2872798
   Li WH, 2018, IEEE ACCESS, V6, P44211, DOI 10.1109/ACCESS.2018.2863943
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Monkaresi H, 2017, IEEE T AFFECT COMPUT, V8, P15, DOI 10.1109/TAFFC.2016.2515084
   Picard R.W., 2000, Affective Computing
   Popoola OP, 2012, IEEE T SYST MAN CY C, V42, P865, DOI 10.1109/TSMCC.2011.2178594
   Poulisse GJ, 2014, MULTIMED TOOLS APPL, V70, P159, DOI 10.1007/s11042-012-1086-0
   Ramezani M, 2016, ARTIF INTELL REV, V46, P485, DOI 10.1007/s10462-016-9473-y
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Sargano AB, 2017, IEEE IJCNN, P463, DOI 10.1109/IJCNN.2017.7965890
   Sari MW, 2017, IOP CONF SER-MAT SCI, V190, DOI 10.1088/1757-899X/190/1/012032
   Shehata M, 2018, IEEE CONF IMAGING SY, P6, DOI 10.1109/IST.2018.8577168
   Sivabalan KR, 2020, ADV INTELL SYST, V1057, P877, DOI 10.1007/978-981-15-0184-5_75
   Szczuko P, 2019, MULTIMED TOOLS APPL, V78, P29357, DOI 10.1007/s11042-019-7433-7
   Szczuko P, 2014, MULTIMED TOOLS APPL, V68, P177, DOI 10.1007/s11042-012-1147-4
   Wang C, 2017, IEEE T SERV COMPUT, V10, P155, DOI 10.1109/TSC.2015.2444849
   Whitehill J, 2014, IEEE T AFFECT COMPUT, V5, P86, DOI 10.1109/TAFFC.2014.2316163
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zheng Y, 2012, IEEE IMAGE PROC, P785, DOI 10.1109/ICIP.2012.6466977
NR 49
TC 21
Z9 21
U1 3
U2 49
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2907
EP 2929
DI 10.1007/s11042-020-09741-5
EA SEP 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000570470300005
DA 2024-07-18
ER

PT J
AU Cyriac, P
   Canham, T
   Kane, D
   Bertalmío, M
AF Cyriac, Praveen
   Canham, Trevor
   Kane, David
   Bertalmio, Marcelo
TI Vision models fine-tuned by cinema professionals for High Dynamic Range
   imaging in movies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High dynamic range; Vision models; Visual perception; Tone mapping;
   Inverse tone mapping; Cinema post-production
ID VISUAL-ADAPTATION; CONE PHOTORECEPTORS; TONE; BRIGHTNESS; STATISTICS;
   APPEARANCE; LUMINANCE; NOISE
AB Many challenges that deal with processing of HDR material remain very much open for the film industry, whose extremely demanding quality standards are not met by existing automatic methods. Therefore, when dealing with HDR content, substantial work by very skilled technicians has to be carried out at every step of the movie production chain. Based on recent findings and models from vision science, we propose in this work effective tone mapping and inverse tone mapping algorithms for production, post-production and exhibition. These methods are automatic and real-time, and they have been both fine-tuned and validated by cinema professionals, with psychophysical tests demonstrating that the proposed algorithms outperform both the academic and industrial state-of-the-art. We believe these methods bring the field closer to having fully automated solutions for important challenges for the cinema industry that are currently solved manually or sub-optimally. Another contribution of our research is to highlight the limitations of existing image quality metrics when applied to the tone mapping problem, as none of them, including two state-of-the-art deep learning metrics for image perception, are able to predict the preferences of the observers.
C1 [Cyriac, Praveen; Canham, Trevor; Kane, David; Bertalmio, Marcelo] Univ Pompeu Fabra, Barcelona, Spain.
C3 Pompeu Fabra University
RP Bertalmío, M (corresponding author), Univ Pompeu Fabra, Barcelona, Spain.
EM marcelo.bertalmio@upf.edu
FU European Union's Horizon 2020 research and innovation programme [761544,
   780470]; Spanish government (MCIU/AEI/FEDER, UE) [PGC2018-099651-B-I00];
   FEDER (MCIU/AEI/FEDER, UE) [PGC2018-099651-B-I00]; H2020 - Industrial
   Leadership [761544, 780470] Funding Source: H2020 - Industrial
   Leadership
FX This work has received funding from the European Union's Horizon 2020
   research and innovation programme under grant agreement number 761544
   (project HDR4EU) and under grant agreement number 780470 (project
   SAUCE), and by the Spanish government and FEDER Fund, grant ref.
   PGC2018-099651-B-I00 (MCIU/AEI/FEDER, UE). We're very grateful to Albert
   Pascual, Brett Harrison, Stephane Cattan and everyone at Deluxe-Spain,
   Alejandro Matus and everyone at Moonlight Barcelona, for their help in
   fine-tuning and validating our method.
CR [Anonymous], 2016, Electron. Imag.
   [Anonymous], 2018, CVPR
   ARRI, 2018, ENH CAPT MAT HDR4EU
   Ashikhmin M., 2002, Rendering Techniques 2002. Eurographics Workshop Proceedings, P145
   Aticky JJ, 2011, NETWORK-COMP NEURAL, V22, P4, DOI 10.3109/0954898X.2011.638888
   Baccus SA, 2002, NEURON, V36, P909, DOI 10.1016/S0896-6273(02)01050-4
   Banterle F., 2006, P 4 INT C COMP GRAPH, P349
   Bist C, 2017, COMPUT GRAPH-UK, V62, P77, DOI 10.1016/j.cag.2016.12.006
   Bloomfield SA, 2009, NAT REV NEUROSCI, V10, P495, DOI 10.1038/nrn2636
   Boitard R, 2014, SIGNAL PROCESS-IMAGE, V29, P229, DOI 10.1016/j.image.2013.10.001
   Carandini M, 2005, J NEUROSCI, V25, P10577, DOI 10.1523/JNEUROSCI.3726-05.2005
   Chapot CA, 2017, J PHYSIOL-LONDON, V595, P5495, DOI 10.1113/JP274177
   Cinema RD, 2019, SAMPLE R3D FILES
   Demb JB, 2008, J PHYSIOL-LONDON, V586, P4377, DOI 10.1113/jphysiol.2008.156638
   Dunn FA, 2006, CURR OPIN NEUROBIOL, V16, P363, DOI 10.1016/j.conb.2006.06.013
   Ebner F, 1998, SIXTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P8
   Eilertsen G, 2017, COMPUT GRAPH FORUM, V36, P565, DOI 10.1111/cgf.13148
   Eilertsen G, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130816
   Eilertsen G, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818092
   Endo Y, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130834
   Froehlich J, 2014, PROC SPIE, V9023, DOI 10.1117/12.2040003
   Goeller K, 2015, SMPTE 2015 ANN TECHN, P1
   Gollisch T, 2010, NEURON, V65, P150, DOI 10.1016/j.neuron.2009.12.009
   Gordon F, 2018, PALGR SOC LEG STUD, P1, DOI 10.1007/978-1-137-60682-2
   Grimaldi A, 2019, J VISION, V19, DOI 10.1167/19.2.13
   Heidrich Wolfgang, ERIK REINHARD
   Huang J., 1999, IEEE COMP SOC C COMP, V1
   Hubel D. H., 1995, Eye, Brain, and Vision
   Huo YQ, 2014, VISUAL COMPUT, V30, P507, DOI 10.1007/s00371-013-0875-4
   ITU-R, 2016, BT23900 ITUR
   Jang H, 2020, IEEE ACCESS, V8, P38554, DOI 10.1109/ACCESS.2020.2975857
   Jansen M, 2019, CEREB CORTEX, V29, P336, DOI 10.1093/cercor/bhy221
   Kane D, 2016, J VISION, V16, DOI 10.1167/16.6.4
   Kohn A, 2007, J NEUROPHYSIOL, V97, P3155, DOI 10.1152/jn.00086.2007
   Krasula L, 2017, IEEE J-STSP, V11, P64, DOI 10.1109/JSTSP.2016.2637168
   Kremkow J., 2014, P NATL ACAD SCI
   Kuang JT, 2007, J VIS COMMUN IMAGE R, V18, P406, DOI 10.1016/j.jvcir.2007.06.003
   Lee BB, 2010, PROG RETIN EYE RES, V29, P622, DOI 10.1016/j.preteyeres.2010.08.004
   Luzardo G, 2018, PICT COD SYMP, P199, DOI 10.1109/PCS.2018.8456253
   Mantiuk R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964935
   Mantiuk R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360667
   Martinez-Garcia M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0201326
   Masia B, 2017, MULTIMED TOOLS APPL, V76, P631, DOI 10.1007/s11042-015-3036-0
   Masland RH, 2012, NEURON, V76, P266, DOI 10.1016/j.neuron.2012.10.002
   MATTHEWS HR, 1990, J PHYSIOL-LONDON, V420, P447, DOI 10.1113/jphysiol.1990.sp017922
   Milner ES, 2017, CELL, V171, P865, DOI 10.1016/j.cell.2017.09.005
   Morovic J., 1998, THESIS
   Nafchi HZ, 2015, IEEE SIGNAL PROC LET, V22, P1026, DOI 10.1109/LSP.2014.2381458
   Narwaria M, 2015, SIGNAL PROCESS-IMAGE, V35, P46, DOI 10.1016/j.image.2015.04.009
   Nassi JJ, 2009, NAT REV NEUROSCI, V10, P360, DOI 10.1038/nrn2619
   Nundy S, 2002, P NATL ACAD SCI USA, V99, P14482, DOI 10.1073/pnas.172520399
   Olshausen B. A., 2013, 20 Years of Computational Neuroscience, P243, DOI DOI 10.1007/978-1-4614-1424-7_12
   Olshausen BA, 2005, NEURAL COMPUT, V17, P1665, DOI 10.1162/0899766054026639
   Olshausen BA, 2000, AM SCI, V88, P238, DOI 10.1511/2000.3.238
   Olshausen BA, 1996, NETWORK-COMP NEURAL, V7, P333, DOI 10.1088/0954-898X/7/2/014
   Ozuysal Y, 2012, NEURON, V73, P1002, DOI 10.1016/j.neuron.2011.12.029
   Pascual A, 2018, UNREALEASED FOOTAGE
   Pattanaik SN, 2000, COMP GRAPH, P47, DOI 10.1145/344779.344810
   Ploumis S, 2018, SMPTE 2018, P1
   Poynton C, 2012, DIGITAL VIDEO AND HD: ALGORITHMS AND INTERFACES, 2ND EDITION, P1
   Prashnani Ekta, 2018, IEEE C COMP VIS PATT
   Radonjic A, 2011, CURR BIOL, V21, P1931, DOI 10.1016/j.cub.2011.10.013
   Rana A, 2020, IEEE T IMAGE PROCESS, V29, P1285, DOI 10.1109/TIP.2019.2936649
   Reinhard E, 2018, SMPTE 2018, P1
   Rempel AG, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239490
   Routhier PH, 2018, SMPTE 2018, P1
   Rucci M, 2015, TRENDS NEUROSCI, V38, P195, DOI 10.1016/j.tins.2015.01.005
   Schmidt BP, 2014, J OPT SOC AM A, V31, pA195, DOI 10.1364/JOSAA.31.00A195
   Shapley R., 1984, Prog Retin Res, V3, P263, DOI [10.1016/0278-4327(84)90011-7, DOI 10.1016/0278-4327(84)90011~7]
   SMPTE, 2015, SMPTE HDR STUD GROUP
   STEVENS JC, 1963, J OPT SOC AM, V53, P375, DOI 10.1364/JOSA.53.000375
   TUMBLIN J, 1993, IEEE COMPUT GRAPH, V13, P42, DOI 10.1109/38.252554
   Turner HM, 2018, RECEPTIVE FIELD CTR, P252148
   Turner MH, 2016, NEURON, V90, P1257, DOI 10.1016/j.neuron.2016.05.006
   Van Hurkman A., 2013, COLOR CORRECTION HDB
   Vandenberg J, 2018, SMPTE 2018, P1
   Wandell B. A., 1995, Foundations of vision, V8
   Ward G., 1997, IEEE T VISUALIZATION, V3, P291
   Wark B, 2007, CURR OPIN NEUROBIOL, V17, P423, DOI 10.1016/j.conb.2007.07.001
   Wark B, 2009, NEURON, V61, P750, DOI 10.1016/j.neuron.2009.01.019
   Wässle H, 2004, NAT REV NEUROSCI, V5, P747, DOI 10.1038/nrn1497
   WHITTLE P, 1969, VISION RES, V9, P1095, DOI 10.1016/0042-6989(69)90050-9
   WHITTLE P, 1992, VISION RES, V32, P1493, DOI 10.1016/0042-6989(92)90205-W
   Xie FJ, 2018, 2018 INTERNATIONAL CONFERENCE ON ELECTRONICS, INFORMATION, AND COMMUNICATION (ICEIC), P5
   Xu YC, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P142, DOI [10.1109/BigMM.2019.00030, 10.1109/BigMM.2019.00-32]
   Yedlin S, 2016, COLOR SCI
   Yeganeh H, 2013, IEEE T IMAGE PROCESS, V22, P657, DOI 10.1109/TIP.2012.2221725
   Yeonan-Kim J, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0168963
   Zhang XS, 2020, OPT EXPRESS, V28, P5953, DOI 10.1364/OE.380555
NR 89
TC 6
Z9 6
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2537
EP 2563
DI 10.1007/s11042-020-09532-y
EA SEP 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000569701000010
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Mohammad, K
   Qaroush, A
   Washha, M
   Agaian, S
   Tumar, I
AF Mohammad, Khader
   Qaroush, Aziz
   Washha, Mahdi
   Agaian, Sos
   Tumar, Iyad
TI An adaptive text-line extraction algorithm for printed Arabic documents
   with diacritics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Arabic character recognition; Line segmentation; Baseline; Diacritics
ID PERFORMANCE EVALUATION; IMAGE-ANALYSIS; SEGMENTATION; RECOGNITION;
   SYSTEM
AB The performance of document text recognition depends on text line segmentation algorithms, which heavily relies on the type of language, author's writing style, pen type, and document quality. In this paper, we present a novel unsupervised text-line segmentation algorithm for printed Arabic documents with and without diacritics. The presented approach employs a projection profile along with connected components in an iterative manner to detect text-lines. The primary benefits of the presented algorithm are (i) it is not threshold dependent, (ii) it is not required a training phase for threshold selection, and (iii) it is robust towards page rotation, font type, size, and style variation for both with and without diacritics documents. The extensive computational simulations on manually collected dataset prove the efficiency of the proposed scheme compared with several baseline and states of the art methods, including, Voronoi, X-Y Cut, Docstrum, Smearing and Seam-carving methods. Computational time analysis also presented.
C1 [Mohammad, Khader; Qaroush, Aziz; Washha, Mahdi; Tumar, Iyad] Birzeit Univ, Dept Elect & Comp Engn, Birzeit, Palestine.
   [Agaian, Sos] CUNY Coll Staten Isl, New York, NY USA.
C3 Birzeit University; City University of New York (CUNY) System; College
   of Staten Island (CUNY)
RP Mohammad, K (corresponding author), Birzeit Univ, Dept Elect & Comp Engn, Birzeit, Palestine.
EM khamadawwad@birzeit.edu; aqaroush@birzeit.edu; mwashha@birzeit.edu;
   sosagaian@yahoo.com; itumar@birzeit.edu
RI Agaian, Sos s/IZE-1724-2023
OI Agaian, Sos s/0000-0003-4601-4507
CR Aldavert D, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), P293, DOI 10.1109/DAS.2018.24
   [Anonymous], 2015, VERS 8 15 0 R2015
   [Anonymous], 2002, PRIK CIFED
   Ayesh M., 2017, Electron Imaging, V2017, P42
   Barakat B. K., 2020, UNSUPERVISED TEXT LI
   Breuel TM, 2002, LECT NOTES COMPUT SC, V2423, P188
   Bukhari SS, 2013, PROC INT CONF DOC, P748, DOI 10.1109/ICDAR.2013.153
   Forczmanski P, 2016, MACH VISION APPL, V27, P1243, DOI 10.1007/s00138-016-0803-5
   Haraty R., 2004, International Arab Journal of Information Technology (IAJIT), V1, P156
   Isheawy NAM, OPTICAL CHARACTER RE
   Jaeger S, 2006, INT C DOC REC RETR S, P1
   Jain AK, 1998, IEEE T PATTERN ANAL, V20, P294, DOI 10.1109/34.667886
   Kise K, 1998, COMPUT VIS IMAGE UND, V70, P370, DOI 10.1006/cviu.1998.0684
   Kundu S, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112916
   LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346
   Lawgali A, 2015, HANDWRITTEN DIGIT RE
   Li Y, 2008, IEEE T PATTERN ANAL, V30, P1313, DOI 10.1109/TPAMI.2007.70792
   Manmatha R, 2005, IEEE T PATTERN ANAL, V27, P1212, DOI 10.1109/TPAMI.2005.150
   Mao S, 2003, PROC SPIE, V5010, P197, DOI 10.1117/12.476326
   Mao S, 2001, IEEE T PATTERN ANAL, V23, P242, DOI 10.1109/34.910877
   Marti UV, 2001, PROC INT CONF DOC, P159, DOI 10.1109/ICDAR.2001.953775
   Mohammad K, 2012, ARABIC LICENSE PLATE
   Mohammad Khader, 2012, ISRN MACHINE VISION, V2012
   Mozaffari S., 2006, 10 INT WORKSH FRONT
   Nagy G, 2000, IEEE T PATTERN ANAL, V22, P38, DOI 10.1109/34.824820
   NAGY G, 1992, COMPUTER, V25, P10, DOI 10.1109/2.144436
   Neche C, 2019, PROC INT CONF DOC, P19, DOI 10.1109/ICDARW.2019.50110
   OGORMAN L, 1993, IEEE T PATTERN ANAL, V15, P1162, DOI 10.1109/34.244677
   Oliveira SA, 2018, INT CONF FRONT HAND, P7, DOI 10.1109/ICFHR-2018.2018.00011
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pal U, 2004, IEEE T SYST MAN CY B, V34, P1676, DOI 10.1109/TSMCB.2004.827613
   Renton G, 2018, INT J DOC ANAL RECOG, V21, P177, DOI 10.1007/s10032-018-0304-3
   SAABNI R, 2018, ROBUST EFFICIENT TEX
   Seuret M, 2017, ROBUST HEARTBEAT BAS
   Shafait F, 2008, IEEE T PATTERN ANAL, V30, P941, DOI 10.1109/TPAMI.2007.70837
   Singh S., 2013, Emerging Trends in Computing and Information Sciences, V4, P545
   Slimane Fouad, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P946, DOI 10.1109/ICDAR.2009.155
   Song Mao, 2002, International Journal on Document Analysis and Recognition, V4, P205, DOI 10.1007/s100320200070
   Suleyman E., 2019, ADAPTIVE THRESHOLD A, P302
   Tripathy N, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P306, DOI 10.1109/IWFHR.2004.50
   Wang L., 2017, MULTIMED TOOLS APPL, V10, P1, DOI DOI 10.1109/TFUZZ.2017.2774185
   Wang LA, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P335, DOI 10.1109/DAS.2016.12
   WHITE JM, 1983, IBM J RES DEV, V27, P400, DOI 10.1147/rd.274.0400
   Yu B, 1996, PATTERN RECOGN, V29, P1599, DOI 10.1016/0031-3203(96)00020-9
   Zahour A, 2001, PROC INT CONF DOC, P281
NR 45
TC 7
Z9 8
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2177
EP 2204
DI 10.1007/s11042-020-09737-1
EA SEP 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000568478700002
DA 2024-07-18
ER

PT J
AU Leong, SM
   Phan, RCW
   Baskaran, VM
   Ooi, CP
AF Leong, Shu-Min
   Phan, Raphael C. -W.
   Baskaran, Vishnu Monn
   Ooi, Chee-Pun
TI Faceless identification based on temporal strips
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial recognition; Privacy-preserving; Temporal features; Local
   directional textures; Local binary pattern (LBP); Partial facial
   features
ID RECOGNITION
AB This paper first presents a novel approach for modelling facial features, Local Directional Texture (LDT), which exploits the unique directional information in image textures for the problem of face recognition. A variant of LDT with privacy-preserving temporal strips (TS) is then considered to achieve faceless recognition with a higher degree of privacy while maintaining high accuracy. The TS uses two strips of pixel blocks from the temporal planes, XT and YT, for face recognition. By removing the reliance on spatial context (i.e., XY plane) for this task, the proposed method withholds facial appearance information from public view, where only one-dimensional temporal information that varies across time are extracted for recognition. Thus, privacy is assured, yet without impeding the facial recognition task which is vital for many security applications such as street surveillance and perimeter access control. To validate the reliability of the proposed method, experiments were carried out using the Honda/UCSD, CK+, CAS(ME)(2)and CASME II databases. The proposed method achieved a recognition rate of 98.26% in the standard video-based face recognition database, Honda/UCSD. It also offers a 81.92% reduction in the dimension length required for storing the extracted features, in contrast to the conventional LBP-TOP.
C1 [Leong, Shu-Min; Phan, Raphael C. -W.; Baskaran, Vishnu Monn] Monash Univ, Sch Informat Technol, Subang Jaya, Malaysia.
   [Phan, Raphael C. -W.] Monash Univ, Fac IT, Dept Software Syst & Cybersecur, Melbourne, Vic, Australia.
   [Ooi, Chee-Pun] Multimedia Univ, Fac Engn, Cyberjaya, Malaysia.
C3 Monash University; Monash University Malaysia; Monash University;
   Multimedia University
RP Leong, SM (corresponding author), Monash Univ, Sch Informat Technol, Subang Jaya, Malaysia.
EM shu.leong@monash.edu; raphael.phan@monash.edu; vishnu.monn@monash.edu;
   cpooi@mmu.edu.my
RI Phan, Raphael C.-W./I-7266-2013; Ooi, Chee Pun/D-3322-2012
OI Leong, Shu Min/0000-0003-1041-4170
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   [Anonymous], 2018, ARXIV PREPRINT ARXIV
   [Anonymous], 2017, MULTIMODAL BIOMETRIC
   [Anonymous], 2016, 2016 IEEE WINT C APP
   Ben Abdallah T, 2018, MULTIMED TOOLS APPL, V77, P19455, DOI 10.1007/s11042-017-5354-x
   Deng WH, 2018, IEEE T PATTERN ANAL, V40, P2513, DOI 10.1109/TPAMI.2017.2757923
   Dobs K, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01355
   Ekenel HK, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1007
   Erdélyi A, 2018, MULTIMED TOOLS APPL, V77, P2285, DOI 10.1007/s11042-016-4337-7
   Fan JM, 2018, J CHEM-NY, V2018, DOI 10.1155/2018/5137694
   Fangbing Qu, 2018, IEEE Transactions on Affective Computing, V9, P424, DOI 10.1109/TAFFC.2017.2654440
   Hadid A, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P813, DOI 10.1109/AFGR.2004.1301634
   HE DC, 1990, IEEE T GEOSCI REMOTE, V28, P509
   He LX, 2018, PROC CVPR IEEE, P7054, DOI 10.1109/CVPR.2018.00737
   Jourabloo A, 2015, INT CONF BIOMETR, P278, DOI 10.1109/ICB.2015.7139096
   Kätsyri J, 2008, INT J HUM-COMPUT ST, V66, P233, DOI 10.1016/j.ijhcs.2007.10.001
   Lee KC, 2005, COMPUT VIS IMAGE UND, V99, P303, DOI 10.1016/j.cviu.2005.02.002
   Liao SC, 2013, IEEE T PATTERN ANAL, V35, P1193, DOI 10.1109/TPAMI.2012.191
   Lin J., 2020, MATH PROBL ENG, P1
   Liu Z., 2019, ARXIV190501796
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Peng F, 2018, MULTIMED TOOLS APPL, V77, P8883, DOI 10.1007/s11042-017-4780-0
   Rahim MdAbdur., 2013, GLOBAL J COMPUTER SC
   Rani PI, 2017, MULTIMED TOOLS APPL, V76, P10017, DOI 10.1007/s11042-016-3592-y
   Scherhag U, 2019, IEEE ACCESS, V7, P23012, DOI 10.1109/ACCESS.2019.2899367
   Tang HL, 2013, SIGNAL PROCESS, V93, P2190, DOI 10.1016/j.sigpro.2012.04.002
   Tharshini G, 2017, INT CONF IND INF SYS, P212
   Wang YF, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0124812
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zheng JX, 2019, IEEE I CONF COMP VIS, P703, DOI 10.1109/ICCV.2019.00079
NR 33
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 279
EP 298
DI 10.1007/s11042-020-09391-7
EA SEP 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000565163300002
DA 2024-07-18
ER

PT J
AU Fu, LH
   Ding, Y
   Du, YB
   Zhang, B
   Wang, LY
   Wang, D
AF Fu, Li-hua
   Ding, Yu
   Du, Yu-bin
   Zhang, Bo
   Wang, Lu-yuan
   Wang, Dan
TI SiamMN: Siamese modulation network for visual object tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual object tracking; Feature modulation; Siamese network; Region
   proposal network
AB Visual object tracking methods based on Siamese network are often difficult to distinguish objects with the same semantic or similar appearance as tracking target in tracking process due to the lack of discriminating strategies for the confusing objects. We propose a visual object tracking method based on Siamese modulation network. It takes the given bounding box in the target frame and the current frame as input, and fuses these multi-layer convolutional features to obtain more target appearance information of bounding box and the current frame. The feature modulator generates feature modulation vector based on the given bounding box to enhance visual appearance information of target instance in multi-layer feature of the current frame, so as to make target instance obtain higher score in response map of region proposal network, and thus realize target instance-specific tracking task. Experiments on two public benchmark datasets, OTB2015 and VOT2018, show that the proposed tracker has a competitive performance among other state-of-the art trackers.
C1 [Fu, Li-hua; Ding, Yu; Du, Yu-bin; Zhang, Bo; Wang, Lu-yuan; Wang, Dan] Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
C3 Beijing University of Technology
RP Fu, LH (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
EM fulh@bjut.edu.cn
RI Zhang, Bo/AFV-0413-2022
CR [Anonymous], J COMPUTATIONAL VISU
   [Anonymous], 2010, 2010 IEEE C COMP VIS
   Bertinetto L, 2016, 2016 EUR C COMP VIS
   Bhat G, 2018, 2018 EUR C COMP VIS
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Danelljan M, 2016, 2016 EUR C COMP VIS
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Finn C, 2017, PR MACH LEARN RES, V70
   Galoogahi HK, 2017, 2017 IEEE INTERNATIO
   Hariharan B, 2017, 2017 IEEE INT C COMP
   He K., 2015, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2015.7299173, DOI 10.1109/CVPR.2015.7299173]
   Held D, 2016, 2016 EUR C COMP VIS
   Henriques JF, 2012, 2012 EUR C COMP VIS
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hu J, 2014, 2014 IEEE 22ND INTERNATIONAL SYMPOSIUM OF QUALITY OF SERVICE (IWQOS), P147, DOI 10.1109/IWQoS.2014.6914314
   Kristan M, 2018, 2018 EUR C COMP VIS
   Kristiansen M, 2017, 2017 1ST IEEE INTERNATIONAL CONFERENCE ON ENVIRONMENT AND ELECTRICAL ENGINEERING AND 2017 17TH IEEE INDUSTRIAL AND COMMERCIAL POWER SYSTEMS EUROPE (EEEIC / I&CPS EUROPE)
   Lee KH, 2015, IEEE T MULTIMEDIA, V17, P1429, DOI 10.1109/TMM.2015.2455418
   Li B, 2018, 2018 IEEE C COMP VIS
   Li B, 2019, 2019 IEEE C COMP VIS
   Li F, 2018, 2018 IEEE C COMP VIS
   Lu X, 2019, 2019 IEEE C COMP VIS
   Lu XK, 2021, IEEE T CIRC SYST VID, V31, P1268, DOI 10.1109/TCSVT.2019.2944654
   Lu XK, 2019, NEUROCOMPUTING, V349, P133, DOI 10.1016/j.neucom.2019.02.021
   Lukezic A, 2018, IEEE T CYBERNETICS, V48, P1849, DOI 10.1109/TCYB.2017.2716101
   Qin Y, 2016, 2016 2 INT C ART INT
   Ravi S, 2017, 2017 INT C LEARN REP
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Tang SY, 2017, PROC CVPR IEEE, P3701, DOI 10.1109/CVPR.2017.394
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang Q., 2017, ARXIV170404057
   Wang ZS, 2020, IEEE ACCESS, V8, P71353, DOI 10.1109/ACCESS.2020.2986267
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Xiao B, 2018, 2018 EUR C COMP VIS
   Xing Y, 2010, J MICROMECH MICROENG, V20, DOI 10.1088/0960-1317/20/1/015019
   ZHU Zheng, 2018, P 15 EUR C COMP VIS, P104, DOI [10.1007/978-3-030- 01240-3_7, DOI 10.1007/978-3-030-01240-3_7]
NR 38
TC 5
Z9 6
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32623
EP 32641
DI 10.1007/s11042-020-09546-6
EA AUG 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000563606600005
DA 2024-07-18
ER

PT J
AU Tripathi, D
   Edla, DR
   Kuppili, V
   Dharavath, R
AF Tripathi, Diwakar
   Edla, Damodar Reddy
   Kuppili, Venkatanareshbabu
   Dharavath, Ramesh
TI Binary BAT algorithm and RBFN based hybrid credit scoring model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optimization; Credit scoring; Feature selection; Classification
ID PARTICLE SWARM OPTIMIZATION; NEIGHBORHOOD ROUGH SET; SUPPORT VECTOR
   MACHINE; KRILL HERD ALGORITHM; FEATURE-SELECTION; GENETIC ALGORITHM;
   SEARCH; COMBINATION; REGRESSION; SVM
AB Credit scoring is a process of calculating the risk associated with an applicant on the basis of applicant's credentials such as social status, financial status, etc. and it plays a vital role to improve cash flow for financial industry. However, the credit scoring dataset may have a large number of irrelevant or redundant features which leads to poorer classification performances and higher complexity. So, by removing redundant and irrelevant features may overcome the problem with huge number of features. This work emphasized on the role of feature selection and proposed a hybrid model by combining feature selection by utilizing Binary BAT optimization technique with a novel fitness function and aggregated with for Radial Basis Function Neural Network (RBFN) for credit score classification. Further, proposed feature selection approach is aggregated with Support Vector Machine (SVM) & Random Forest (RF), and other optimization approaches namely: Hybrid Particle Swarm Optimization and Gravitational Search Algorithm (PSOGSA), Hybrid Particle Swarm Optimization and Genetic Algorithm (PSOGA), Improved Krill Herd (IKH), Improved Cuckoo Search (ICS), Firefly Algorithm (FF) and Differential Evolution (DE) are also applied for comparative analysis.
C1 [Tripathi, Diwakar] SRM Univ AP, Amaravati 522502, Andhra Pradesh, India.
   [Edla, Damodar Reddy; Kuppili, Venkatanareshbabu] Natl Inst Technol Goa, Ponda 403401, Goa, India.
   [Dharavath, Ramesh] Indian Inst Technol ISM, Dhanbad, Bihar, India.
C3 SRM University-AP; National Institute of Technology (NIT System);
   National Institute of Technology Goa; Indian Institute of Technology
   System (IIT System); Indian Institute of Technology (Indian School of
   Mines) Dhanbad
RP Tripathi, D (corresponding author), SRM Univ AP, Amaravati 522502, Andhra Pradesh, India.
EM diwakarnitgoa@gmail.com; dr.reddy@nitgoa.ac.in;
   venkatanaresh@nitgoa.ac.in; ramesh.d.in@ieee.org
RI Dharavath, Ramesh/P-5311-2019
OI Dharavath, Ramesh/0000-0003-3338-6520
CR Abualigah L., 2015, INT J COMPUTER SCI E, V5, P19, DOI [10.5121/ijcsea.2015.5102, DOI 10.5121/ijcsea.2015.5102]
   Abualigah L, 2020, CLUSTER COMPUT, P1
   Abualigah L. M. Q., 2019, FEATURE SELECTION EN, V816
   Abualigah L, 2020, NEURAL COMPUT APPL, V32, P12381, DOI 10.1007/s00521-020-04839-1
   Abualigah LM, 2018, APPL INTELL, V48, P4047, DOI 10.1007/s10489-018-1190-6
   Abualigah LM, 2018, ENG APPL ARTIF INTEL, V73, P111, DOI 10.1016/j.engappai.2018.05.003
   Abualigah LM, 2017, APPL SOFT COMPUT, V60, P423, DOI 10.1016/j.asoc.2017.06.059
   Abualigah LM, 2017, J SUPERCOMPUT, V73, P4773, DOI 10.1007/s11227-017-2046-2
   [Anonymous], 2012, NETWORK COMPLEX SYST
   [Anonymous], 1962, PRINCIPLES NEURODYNA
   [Anonymous], 1985, CALIFORNIA U SAN DIE
   Ben Brahim A, 2018, ADV DATA ANAL CLASSI, V12, P937, DOI 10.1007/s11634-017-0285-y
   Bequé A, 2017, EXPERT SYST APPL, V86, P42, DOI 10.1016/j.eswa.2017.05.050
   Broomhead D. S., 1988, RADIAL BASIS FUNCTIO
   Brown I, 2012, EXPERT SYST APPL, V39, P3446, DOI 10.1016/j.eswa.2011.09.033
   Chen FL, 2010, EXPERT SYST APPL, V37, P4902, DOI 10.1016/j.eswa.2009.12.025
   Chen WM, 2009, EXPERT SYST APPL, V36, P7611, DOI 10.1016/j.eswa.2008.09.054
   Chi BW, 2012, EXPERT SYST APPL, V39, P2650, DOI 10.1016/j.eswa.2011.08.120
   Deng SG, 2020, IEEE T IND INFORM, V16, P6103, DOI 10.1109/TII.2020.2974875
   Dong YQ, 2018, ENERGIES, V11, DOI 10.3390/en11041009
   Edla DR, 2018, ARAB J SCI ENG, V43, P6909, DOI 10.1007/s13369-017-2905-4
   Gandomi AH, 2012, COMMUN NONLINEAR SCI, V17, P4831, DOI 10.1016/j.cnsns.2012.05.010
   Gao H, 2020, P ACM SPRING MOB NET
   Gao HH, 2020, IEEE INTERNET THINGS, V7, P4532, DOI 10.1109/JIOT.2019.2956827
   Harris T, 2015, EXPERT SYST APPL, V42, P741, DOI 10.1016/j.eswa.2014.08.029
   Hens AB, 2012, EXPERT SYST APPL, V39, P6774, DOI 10.1016/j.eswa.2011.12.057
   Hong WC, 2019, APPL MATH MODEL, V72, P425, DOI 10.1016/j.apm.2019.03.031
   Hong WC, 2011, ENERGIES, V4, P960, DOI 10.3390/en4060960
   Hu QH, 2008, INFORM SCIENCES, V178, P3577, DOI 10.1016/j.ins.2008.05.024
   Hu ZY, 2015, ENG APPL ARTIF INTEL, V40, P17, DOI 10.1016/j.engappai.2014.12.014
   Huang CL, 2008, APPL SOFT COMPUT, V8, P1381, DOI 10.1016/j.asoc.2007.10.007
   Huang CL, 2007, EXPERT SYST APPL, V33, P847, DOI 10.1016/j.eswa.2006.07.007
   Huang CL, 2006, EXPERT SYST APPL, V31, P231, DOI 10.1016/j.eswa.2005.09.024
   Kala R., 2010, INT J COMPUTER SCI A, V7, P34
   Kuppili V, 2020, COMPUT INTELL-US, V36, P402, DOI 10.1111/coin.12242
   Lee TS, 2005, EXPERT SYST APPL, V28, P743, DOI 10.1016/j.eswa.2004.12.031
   Liang D, 2015, KNOWL-BASED SYST, V73, P289, DOI 10.1016/j.knosys.2014.10.010
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Lichman M., 2013, UCI MACHINE LEARNING
   Lin SW, 2008, EXPERT SYST APPL, V35, P1817, DOI 10.1016/j.eswa.2007.08.088
   Maldonado S, 2011, INFORM SCIENCES, V181, P115, DOI 10.1016/j.ins.2010.08.047
   Mester LJ, 1997, Business Review, V3, P3
   Mirjalili S, 2014, NEURAL COMPUT APPL, V25, P663, DOI 10.1007/s00521-013-1525-5
   Neumann F., 2013, Proceedings of the 15th Annual Conference Companion on Genetic and Evolutionary Computation. GECCO'13 Companion, P567, DOI [DOI 10.1145/2464576.2466738, 10.1145/2464576.2466738]
   Oreski S, 2014, EXPERT SYST APPL, V41, P2052, DOI 10.1016/j.eswa.2013.09.004
   Paleologo G, 2010, EUR J OPER RES, V201, P490, DOI 10.1016/j.ejor.2009.03.008
   Shukla AK, 2020, GENES GENOM, V42, P449, DOI 10.1007/s13258-020-00916-w
   Shukla AK, 2018, CHEMOMETR INTELL LAB, V183, P47, DOI 10.1016/j.chemolab.2018.10.009
   Soleimani H, 2015, APPL MATH MODEL, V39, P3990, DOI 10.1016/j.apm.2014.12.016
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Tawfik A. S., 2013, INT J COMPUTER APPL, V64, P30, DOI [10.5120/10641-5394, DOI 10.5120/10641-5394]
   Too J, 2019, COMPUTATION, V7, DOI 10.3390/computation7010012
   Tripathi Diwakar, 2018, Advances in Machine Learning and Data Science. Recent Achievements and Research Directives. Advances in Intelligent Systems and Computing (AISC 705), P293, DOI 10.1007/978-981-10-8569-7_30
   Tripathi Diwakar, 2018, Procedia Computer Science, V132, P22, DOI 10.1016/j.procs.2018.05.055
   Tripathi D, 2019, COMPUT INTELL-US, V35, P371, DOI 10.1111/coin.12200
   Tripathi D, 2018, J INTELL FUZZY SYST, V34, P1543, DOI 10.3233/JIFS-169449
   Tsai CF, 2008, EXPERT SYST APPL, V34, P2639, DOI 10.1016/j.eswa.2007.05.019
   Tsai CF, 2009, KNOWL-BASED SYST, V22, P120, DOI 10.1016/j.knosys.2008.08.002
   Van Hulse J., 2007, P 24 INT C MACH LEAR, DOI [DOI 10.1145/1273496.1273614, 10.1145/1273496.1273614]
   Wang G, 2011, EXPERT SYST APPL, V38, P223, DOI 10.1016/j.eswa.2010.06.048
   Wang J, 2012, EXPERT SYST APPL, V39, P6123, DOI 10.1016/j.eswa.2011.11.011
   Wang J, 2010, PROCEDIA COMPUT SCI, V1, P2419, DOI 10.1016/j.procs.2010.04.273
   West D, 2000, COMPUT OPER RES, V27, P1131, DOI 10.1016/S0305-0548(99)00149-5
   Wongchinsri P, 2017, 2017 14TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING/ELECTRONICS, COMPUTER, TELECOMMUNICATIONS AND INFORMATION TECHNOLOGY (ECTI-CON), P385, DOI 10.1109/ECTICon.2017.8096254
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   Yao P, 2011, EXPERT SYST APPL, V38, P11300, DOI 10.1016/j.eswa.2011.02.179
   Yegnanarayana B., 2009, ARTIFICIAL NEURAL NE
   Yu Q., 2011, Proceedings of the 2011 International Conference on Data Mining (DMIN 2011), P279
   Zhang Y, 2017, INFORM SCIENCES, V418, P561, DOI 10.1016/j.ins.2017.08.047
   Zhang ZC, 2020, IEEE ACCESS, V8, P14642, DOI 10.1109/ACCESS.2020.2966712
   Zhang ZC, 2019, NONLINEAR DYNAM, V98, P1107, DOI 10.1007/s11071-019-05252-7
   Zhou LG, 2009, SOFT COMPUT, V13, P149, DOI 10.1007/s00500-008-0305-0
NR 73
TC 11
Z9 11
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 31889
EP 31912
DI 10.1007/s11042-020-09538-6
EA AUG 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000562697400001
DA 2024-07-18
ER

PT J
AU Fourati, M
   Jedidi, A
   Gargouri, F
AF Fourati, Manel
   Jedidi, Anis
   Gargouri, Faiez
TI A survey on description and modeling of audiovisual documents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audiovisuel document; Low-level description; Documentary description;
   Semantic; description; audiovisual semiotic; modeling audivisual
ID VIDEO; ONTOLOGY; FRAMEWORK; SYSTEM; PERFORMANCE; RETRIEVAL; FEATURES;
   FUSION
AB The number of audiovisual documents available on the web is exponentially increasing due to the rise of the number of videos produced every day. The recent progress in audiovisual documents field has made it possible to popularize the exchange of these documents in many domains. More generally, the interest in the indexing potential of audiovisual documents has significantly increased in different disciplines, namely films, sports events, etc. Within this framework, several research studies focused on implementing this indexation based on the segmentation of the audiovisual document in fragments. This segmentation was brought by the appropriate descriptions. Although the indexing process seems essential, the way of exploiting and searching audiovisual documents remains unsatisfactory. Indeed, annotations based on generic descriptions (title, creator, publisher, etc.) are insufficient to describe the content of the audiovisual documents. With the proliferation of audiovisual documents and the mentioned indexing limits, the question that should be answered is: "What is the relevant information of the audiovisual content?". In this paper, we present a survey to characterize the description and the modeling of audiovisual documents. We classify the existing description methods into three categories: a low-level description, a documentary description and a semantic description. The main objective of this study is to propose an approach that helps describe and organize the content of an audiovisual document so as to conduct a better inquiry.
C1 [Fourati, Manel; Jedidi, Anis; Gargouri, Faiez] Univ Sfax, MIR CL Lab, Sfax, Tunisia.
C3 Universite de Sfax
RP Fourati, M (corresponding author), Univ Sfax, MIR CL Lab, Sfax, Tunisia.
EM Manel.Fourati@fsegs.rnu.tn; anis.jedidi@isimsf.rnu.tn;
   faiez.gargouri@isimsf.rnu.tn
RI jedidi, anis/AAD-1846-2021
OI jedidi, anis/0000-0002-2441-9901; Gargouri, Faiez/0000-0003-2575-8654
CR Abduraman AE, 2012, MULTIMEDIA COMPUT CO, P157
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Bachimont B, 1994, CONTROLE SYSTEMES BA
   Ballan L, 2011, MULTIMED TOOLS APPL, V51, P279, DOI 10.1007/s11042-010-0643-7
   Bhardwaj RK, 2017, LIBR REV, V66, P49, DOI 10.1108/LR-05-2016-0047
   Biswas P, 2005, I CONF VLSI DESIGN, P651
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Burghouts GJ, 2009, COMPUT VIS IMAGE UND, V113, P48, DOI 10.1016/j.cviu.2008.07.003
   Caillet M, 2014, MULTIMED TOOLS APPL, V73, P1777, DOI 10.1007/s11042-013-1651-1
   Chang XJ, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2234
   Chen M, 1995, MOSIFT RECOGNIZING H
   Chuttur MY, 2014, J INF SCI, V40, P28, DOI 10.1177/0165551513507405
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Dasiopoulou S, 2010, MULTIMED TOOLS APPL, V46, P331, DOI 10.1007/s11042-009-0387-4
   De Linde Z., 2016, The semiotics of subtitling
   Del Fabro M, 2013, MULTIMEDIA SYST, V19, P427, DOI 10.1007/s00530-013-0306-4
   Deldjoo Y, 2018, INT J MULTIMED INF R, V7, P207, DOI 10.1007/s13735-018-0155-1
   Deldjoo Y, 2016, J DATA SEMANT, V5, P99, DOI 10.1007/s13740-016-0060-9
   Dervin B., 1992, QUALITATIVE RES INFO, P61
   Egyed-Zsigmond E., 2000, CONTENT BASED MULTIM, V2, P1381
   Elleuch N, 2015, MULTIMED TOOLS APPL, V74, P1397, DOI 10.1007/s11042-014-1955-9
   Fang ZW, 2019, PATTERN RECOGN, V90, P404, DOI 10.1016/j.patcog.2019.01.038
   Fourati M, 2015, INT J MULTIMED DATA, V6, P52, DOI 10.4018/IJMDEM.2015040104
   Fourati M, 2015, LECT NOTES COMPUT SC, V9492, P453, DOI 10.1007/978-3-319-26561-2_54
   Gan Z, 2017, PROC CVPR IEEE, P1141, DOI 10.1109/CVPR.2017.127
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Gluck M, 1997, INFORMATION SEEKING IN CONTEXT, P53
   Holzinger A, 2011, LECT NOTES COMPUT SC, V6767, P183, DOI 10.1007/978-3-642-21666-4_21
   Janwe NJ, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P476, DOI 10.1109/ICIIP.2013.6707637
   Jedidi A, 2005, MODELISATION GENERIQ
   Jiang YG, 2010, IEEE T MULTIMEDIA, V12, P42, DOI 10.1109/TMM.2009.2036235
   Kim S, 2015, 2015 11TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P295, DOI 10.1109/SITIS.2015.33
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Li LH, 2018, IEEE T MULTIMEDIA, V20, P726, DOI 10.1109/TMM.2017.2751140
   Liu Z, 2013, LANDSLIDES, P1
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu ZM, 2013, IEEE T IMAGE PROCESS, V22, P5136, DOI 10.1109/TIP.2013.2282081
   Luo B, 2017, IEEE T MULTIMEDIA, V19, P1482, DOI 10.1109/TMM.2017.2671447
   Mademlis I, 2015, EUR SIGNAL PR CONF, P819, DOI 10.1109/EUSIPCO.2015.7362497
   Martin J.-P, 2005, DESCRIPTION SEMIOTIQ
   Mickan P, 2016, TEXT BASED RES TEACH
   Mingers J, 2017, INFORM ORGAN-UK, V27, P17, DOI 10.1016/j.infoandorg.2016.12.001
   MORRIS RCT, 1994, J AM SOC INFORM SCI, V45, P20, DOI 10.1002/(SICI)1097-4571(199401)45:1<20::AID-ASI3>3.0.CO;2-N
   Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Orlandi F, 2018, 2018 14TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS), P609, DOI 10.1109/SITIS.2018.00098
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parikh, 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299087
   Patel Upesh, 2013, INT J COMPUT APPL, V64, P38, DOI DOI 10.5120/10625-5347
   Peirce Charles S, 2009, Writings of Charles S. Peirce: A Chronological Edition, V8, P1890
   Poli JP, 2008, MULTIMEDIA SYST, V14, P255, DOI 10.1007/s00530-008-0140-2
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rinaldi AM, 2014, INFORM SCIENCES, V277, P234, DOI 10.1016/j.ins.2014.02.017
   ROWE LA, 1994, P SOC PHOTO-OPT INS, V2185, P150, DOI 10.1117/12.171772
   Sánchez-Nielsen E, 2019, MULTIMEDIA SYST, V25, P337, DOI 10.1007/s00530-019-00610-2
   Shrivastav S, 2017, MULTIMED TOOLS APPL, V76, P18657, DOI 10.1007/s11042-017-4350-5
   Sikos L. F., 2015, P 8 WORKSH EXPL SEM, P35, DOI 10.1145/2810133.2810141
   Sikos LF, 2018, INTEL SYST REF LIBR, V145, P97, DOI 10.1007/978-3-319-73891-8_6
   Sikos LF, 2017, DESCRIPTION LOGICS M, P51
   Smeaton AF, 2010, COMPUT VIS IMAGE UND, V114, P411, DOI 10.1016/j.cviu.2009.03.011
   Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Song JK, 2018, PATTERN RECOGN, V75, P175, DOI 10.1016/j.patcog.2017.03.021
   Song J, 2016, IEEE T IMAGE PROCESS, V25, P4999, DOI 10.1109/TIP.2016.2601260
   Stockinger P., 2003, DOCUMENT AUDIOVISUEL
   Stockinger P., 2011, ARCH AUDIOVISUELLES
   Stockinger P., 2013, AUDIOVISUAL ARCH DIG, DOI 10.1002/9781118561980
   Tamrakar A, 2012, PROC CVPR IEEE, P3681, DOI 10.1109/CVPR.2012.6248114
   Tang P, 2020, IEEE T PATTERN ANAL, V42, P1272, DOI 10.1109/TPAMI.2019.2910529
   Wang XH, 2017, IEEE SIGNAL PROC LET, V24, P510, DOI 10.1109/LSP.2016.2611485
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961
   Wu Q, 2017, COMPUT VIS IMAGE UND, V163, P21, DOI 10.1016/j.cviu.2017.05.001
   Xu Z, 2016, MULTIMED TOOLS APPL, V75, P12155, DOI 10.1007/s11042-015-3112-5
   Xu Z, 2014, 2014 IEEE 13TH INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI-CC), P323, DOI 10.1109/ICCI-CC.2014.6921478
   Yasser ChutturM., 2011, Journal of Library Metadata, V11, P51, DOI DOI 10.1080/19386389.2011.570654
   Ye GG, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P471, DOI 10.1145/2733373.2806221
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Zhou W., 2017, Recent Advance in Content-based Image Retrieval: A Literature Survey
   Zlitni T, 2016, MULTIMED TOOLS APPL, V75, P5645, DOI 10.1007/s11042-015-2531-7
NR 81
TC 5
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33519
EP 33546
DI 10.1007/s11042-020-09589-9
EA AUG 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000559953900018
DA 2024-07-18
ER

PT J
AU Merrouche, F
   Baha, N
AF Merrouche, Fairouz
   Baha, Nadia
TI Fall detection based on shape deformation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fall detection; Human activity recognition; Image processing; Kinect;
   Video monitoring; Depth information
AB Older people living alone are facing serious risks. Falls are the main risk that menace their lives. In this paper, a new vision-based method for fall detection is proposed to allow older people to live independently and safely. The proposed method uses shape deformation and motion information to distinguish between normal activity and fall. The main contribution of this paper consists on the proposition of a new descriptor based on silhouette deformation, as well as, a new image sequence representation is proposed to capture the change between different postures, which is discriminant information for action classification. Experimental results are conducted on two states-of-the art datasets (SDU fall and UR Fall dataset) and a comparative study is presented. The results obtained show the performance of the proposed method to differentiate between fall events and normal activity. The accuracy achieved is up to 98.41% with the SDU fall dataset and 95.45% with URFall dataset.
C1 [Merrouche, Fairouz; Baha, Nadia] Univ Sci & Technol USTHB, Dept Comp Sci, Algiers, Algeria.
C3 University Science & Technology Houari Boumediene
RP Merrouche, F (corresponding author), Univ Sci & Technol USTHB, Dept Comp Sci, Algiers, Algeria.
EM fmerrouche@usthb.dz; nbahatouzene@usthb.dz
CR Akagündüz E, 2017, IEEE J BIOMED HEALTH, V21, P756, DOI 10.1109/JBHI.2016.2570300
   ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   Alwan Majd., 2006, 2006 2 INT C INFORM, V1, P1003, DOI DOI 10.1109/ICTTA.2006.1684511
   Anderson D, 2009, COMPUT VIS IMAGE UND, V113, P80, DOI 10.1016/j.cviu.2008.07.006
   [Anonymous], 2008, AG WHO UN LC WHO GLO
   Bian ZP, 2015, IEEE J BIOMED HEALTH, V19, P430, DOI 10.1109/JBHI.2014.2319372
   Chen WH, 2015, 2015 17TH INTERNATIONAL CONFERENCE ON E-HEALTH NETWORKING, APPLICATION & SERVICES (HEALTHCOM), P428, DOI 10.1109/HealthCom.2015.7454538
   Cheng J, 2013, IEEE J BIOMED HEALTH, V17, P38, DOI 10.1109/TITB.2012.2226905
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ding CW, 2019, 2019 IEEE MTT-S INTERNATIONAL WIRELESS SYMPOSIUM (IWS 2019), DOI 10.1109/ieee-iws.2019.8804036
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Er PV, 2018, MEASUREMENT, V124, P91, DOI 10.1016/j.measurement.2018.04.009
   Foroughi H, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P413, DOI 10.1109/ICVGIP.2008.49
   Freund Y., 1996, INT C MACHINE LEARNI, P148
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   Jokanovic B, 2016, IEEE RAD CONF, P446
   Kim S, 2015, VISUAL COMPUT, V31, P541, DOI 10.1007/s00371-014-0946-1
   Kwolek B, 2015, NEUROCOMPUTING, V168, P637, DOI 10.1016/j.neucom.2015.05.061
   Kwolek B, 2014, COMPUT METH PROG BIO, V117, P489, DOI 10.1016/j.cmpb.2014.09.005
   LI XC, 2018, MOBILE NETW APPL, V23
   Liu CL, 2010, EXPERT SYST APPL, V37, P7174, DOI 10.1016/j.eswa.2010.04.014
   Ma X, 2014, IEEE J BIOMED HEALTH, V18, P1915, DOI 10.1109/JBHI.2014.2304357
   Mousse MA, 2017, VISUAL COMPUT, V33, P1529, DOI 10.1007/s00371-016-1296-y
   Rougier C, 2011, LECT NOTES COMPUT SC, V6719, P121, DOI 10.1007/978-3-642-21535-3_16
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   Tsai T. H., 2019, P 2019 4 INT C ROB C, P33, DOI [10.1145/3351180.3351191, DOI 10.1145/3351180.3351191]
   WALKER JE, 1991, AM J OCCUP THER, V45, P119, DOI 10.5014/ajot.45.2.119
   Worrakulpanit N, 2014, J AUTOM CONTROL ENG, V2
   Wu T, 2019, ARXIV190704788
   Yazar A., 2014, Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP-14) (Florence), P1
NR 31
TC 7
Z9 8
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30489
EP 30508
DI 10.1007/s11042-019-08428-w
EA AUG 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000559953900005
DA 2024-07-18
ER

PT J
AU Farrag, S
   Alexan, W
AF Farrag, Sara
   Alexan, Wassim
TI Secure 3D data hiding technique based on a mesh traversal algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Security; Steganography; Traversal order; 3D models; Geometrical domain
   based steganography
ID POLYGONAL MODELS; STEGANOGRAPHY
AB Due to its powerful ability to conceal secret data inside an unsuspicious cover object, image steganography has emerged as an active field of research. Recently, a lot of advancements in relation to software and hardware have been carried out, allowing for faster processing of 3D image models. In turn, this has paved the way for 3D image steganography. This paper proposes a novel approach of secure and reversible data hiding in 3D mesh models. The proposed approach employs a mesh traversal algorithm that is based on the shortest distances between neighboring vertices of the mesh. The fourth and fifth decimal places of the Cartesian coordinate vertices after the decimal point are modified to hide the secret data. The proposed approach is evaluated in terms of a number of metrics and is shown to outperform its counterparts from the literature.
C1 [Farrag, Sara; Alexan, Wassim] German Univ Cairo, Fac Informat Engn & Technol, New Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); German University in Cairo
RP Farrag, S (corresponding author), German Univ Cairo, Fac Informat Engn & Technol, New Cairo, Egypt.
EM sarah.farrag@guc.edu.eg; wassim.alexan@ieee.org
RI Alexan, Wassim/J-9944-2019
OI Alexan, Wassim/0000-0001-6159-4971
CR Amat P, 2010, SIGNAL PROCESS-IMAGE, V25, P400, DOI 10.1016/j.image.2010.05.002
   Anish K, 2017, ADV INTELL SYST, V515, P159, DOI 10.1007/978-981-10-3153-3_16
   Bogomjakov A, 2008, COMPUT GRAPH FORUM, V27, P637, DOI 10.1111/j.1467-8659.2008.01161.x
   Cayre F, 2003, IEEE T SIGNAL PROCES, V51, P939, DOI 10.1109/TSP.2003.809380
   Cheng YM, 2006, VISUAL COMPUT, V22, P845, DOI 10.1007/s00371-006-0069-4
   Chuang CH, 2010, REVERSIBLE DATA HIDI
   Egenfeldt-Nielsen S., 2013, Understanding Video Games: The Essential Introduction, V2nd
   Elkandoz MT, 2019, SIG P ALGO ARCH ARR, P290, DOI [10.23919/SPA.2019.8936718, 10.23919/spa.2019.8936718]
   Elkandoz MT, 2019, 2019 INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGIES AND NETWORKING (COMMNET), P128, DOI 10.1109/commnet.2019.8742370
   Elsherif S, 2019, PROCEEDINGS OF 2019 INTERNATIONAL CONFERENCE ON INNOVATIVE TRENDS IN COMPUTER ENGINEERING (ITCE 2019), P117, DOI [10.1109/ITCE.2019.8646685, 10.1109/itce.2019.8646685]
   Farrag S., 2019, 2019 INT C ADV COMM, P1
   Girdhar A, 2019, J AMB INTEL HUM COMP, P1
   Girdhar A, 2018, IET IMAGE PROCESS, V12, P1, DOI 10.1049/iet-ipr.2017.0162
   Huamin Ji, 2010, 2010 Proceedings of 3rd International Congress on Image and Signal Processing (CISP 2010), P3899, DOI 10.1109/CISP.2010.5647623
   Hussein R, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON COMPUTER APPLICATIONS & INFORMATION SECURITY (ICCAIS)
   Jiang N, 2015, INT J THEOR PHYS, V54, P1021, DOI 10.1007/s10773-014-2294-3
   Li NN, 2017, IEEE ACCESS, V5, P24457, DOI 10.1109/ACCESS.2017.2767072
   Mao XY, 2001, PROC SPIE, V4314, P253, DOI 10.1117/12.435406
   Maret Y., 2004, P 2004 WORKSH MULT S, P68
   Niu K, 2019, IEEE ACCESS, V7, P61523, DOI 10.1109/ACCESS.2019.2902464
   Ohbuchi R, 1998, IEEE J SEL AREA COMM, V16, P551, DOI 10.1109/49.668977
   Pan ZB, 2015, IET IMAGE PROCESS, V9, P22, DOI 10.1049/iet-ipr.2014.0310
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Rahmani P, 2018, IET IMAGE PROCESS, V12, P1195, DOI 10.1049/iet-ipr.2016.0618
   Sarreshtedari S, 2014, IET IMAGE PROCESS, V8, P78, DOI 10.1049/iet-ipr.2013.0109
   Thiyagarajan P, 2013, 3D RES, V4, DOI 10.1007/3DRes.01(2013)1
   Tsai YY, 2016, ADV MULTIMED, V2016, DOI 10.1155/2016/4267419
   Tsai YY, 2014, MULTIMED TOOLS APPL, V69, P859, DOI 10.1007/s11042-012-1135-8
   Xu DW, 2019, IEEE ACCESS, V7, P66028, DOI 10.1109/ACCESS.2019.2916484
   Yi XW, 2019, IEEE T INF FOREN SEC, V14, P2217, DOI 10.1109/TIFS.2019.2895200
   Zhang XZ, 2016, 2016 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P49, DOI 10.1109/CW.2016.15
   Zhou Z, 2019, INT J HIGH PERFORM C, V14, P1, DOI [10.1504/IJHPCN.2019.10025200, DOI 10.1504/IJHPCN.2019.099740]
NR 32
TC 11
Z9 12
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29289
EP 29303
DI 10.1007/s11042-020-09437-w
EA AUG 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000559626500001
DA 2024-07-18
ER

PT J
AU Sharma, A
   Singh, SK
AF Sharma, Anshul
   Singh, Sanjay Kumar
TI Early classification of multivariate data by learning optimal decision
   rules
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Time series; Early classification; Cost optimization; Multivariate data
   analysis; Multimedia data
AB Early classification on time series has emerged as an active research area in the field of machine learning. It covers a wide range of applications in agriculture, medical and multimedia systems, including drought prediction, health monitoring, event detection, and many more. The early classification aims to predict the class label of a time series as soon as possible without waiting for the complete series. A critical issue in early classification is the learning of decision policy that determines the adequacy of the collected data required for reliable class prediction. It is more challenging for Multivariate Time Series (MTS) data, where the decision depends on multiple variables to achieve a trade-off between earliness and accuracy. Therefore, this work proposes an optimization-based early classification model for MTS data based on optimal decision rule learning. The proposed model adopts a two-layered approach. The first layer employs the Gaussian process probabilistic classifiers for each variable in MTS that provides the class probabilities at the successive time steps in the series. The second layer defines Early Stopping Rule (ESR) that performs the class prediction task. The ESR learns its parameters through the particle swarm optimization by simultaneously minimizing the misclassification cost and delaying the decision cost. This work has utilized publicly available MTS datasets to validate the proposed early classification model. The experimental results show that the proposed model achieves promising results in terms of accuracy and earliness compared to existing methods.
C1 [Sharma, Anshul; Singh, Sanjay Kumar] Indian Inst Technol BHU, Dept Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi)
RP Sharma, A (corresponding author), Indian Inst Technol BHU, Dept Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India.
EM anshul.rs.cse16@iitbhu.ac.in; sks.cse@iitbhu.ac.in
RI Sharma, Anshul/JWO-6364-2024; Singh, Sanjay Prithviraj/IQV-1492-2023;
   Singh, Sanjay Kumar/AAC-2031-2022; kumar, Sanjay/ITT-3680-2023; Sharma,
   Anshul/JTT-5433-2023; Sharma, Anshul/AAG-9966-2021; Sharma,
   Anshul/GQB-4018-2022
OI Singh, Sanjay Prithviraj/0000-0001-5043-8762; Singh, Sanjay
   Kumar/0000-0002-9061-6313; Sharma, Anshul/0009-0002-5920-6540; Sharma,
   Anshul/0000-0002-1734-0592
CR [Anonymous], 2016, JOINT EUROPEAN C MAC
   Arzani MM, 2020, SKELETON BASED STRUC
   Bagnall A, 2017, DATA MIN KNOWL DISC, V31, P606, DOI 10.1007/s10618-016-0483-9
   Bayliss F, 2019, ICERI PROC, P541
   Bendtsen C, 2012, R PACKAGE VERSION 1
   Bregón A, 2006, LECT NOTES ARTIF INT, V4177, P211
   Chen Y., 2015, UCR TIME SERIES CLAS
   Dachraoui A, 2015, LECT NOTES ARTIF INT, V9284, P433, DOI 10.1007/978-3-319-23528-8_27
   de Weck O., 2005, 46 AIAA ASME ASCE AH, P1, DOI DOI 10.2514/6.2005-1897
   Dua D., 2017, UCI MACHINE LEARNING
   Ghalwash MF, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P402, DOI 10.1145/2623330.2623694
   Ghalwash MF, 2012, BMC BIOINFORMATICS, V13, DOI 10.1186/1471-2105-13-195
   Gonzalez CJA, 2004, SERIES MACHINE PERCE, P149
   Gupta A., 2020, INDIAN J ORTHOP, P1, DOI [10.1007/s43465-020-00121-7, DOI 10.1007/s43465-020-00121-7]
   He GL, 2020, PATTERN ANAL APPL, V23, P567, DOI 10.1007/s10044-019-00782-7
   He GL, 2019, SOFT COMPUT, V23, P6097, DOI 10.1007/s00500-018-3261-3
   He GL, 2015, NEUROCOMPUTING, V149, P777, DOI 10.1016/j.neucom.2014.07.056
   Kate RJ, 2016, DATA MIN KNOWL DISC, V30, P283, DOI 10.1007/s10618-015-0418-x
   Kaur S, 2019, INT J QUANTUM CHEM, V119, DOI 10.1002/qua.26019
   Lama N, 2016, VDMP VARIATIONAL BAY
   Li S, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3131344
   Lin YF, 2015, LECT NOTES ARTIF INT, V9077, P199, DOI 10.1007/978-3-319-18038-0_16
   Lv J, 2019, EFFECTIVE CONFIDENCE
   Ma CH, 2017, LECT NOTES COMPUT SC, V10594, P81, DOI 10.1007/978-3-319-69182-4_9
   Hoai M, 2014, INT J COMPUT VISION, V107, P191, DOI 10.1007/s11263-013-0683-3
   Mori U, 2018, IEEE T NEUR NET LEAR, V29, P4569, DOI 10.1109/TNNLS.2017.2764939
   Mori U, 2017, DATA MIN KNOWL DISC, V31, P233, DOI 10.1007/s10618-016-0462-1
   Mustafa Gokce Baydogan, 2015, Multivariate time series classification datasets
   Ng A.Y., 2004, P 21 INT C MACH LEAR, P78, DOI DOI 10.1145/1015330.1015435
   Olszewski R. T., 2001, Generalized feature extraction for structural pattern recognition in time-series data
   Parsopoulos K. E., 2002, Natural Computing, V1, P235, DOI 10.1023/A:1016568309421
   Richhariya B, 2018, EXPERT SYST APPL, V106, P169, DOI 10.1016/j.eswa.2018.03.053
   Ru wurm M, 2019, EARLY CLASSIFICATION, V1908
   Santos Tiago., 2016, SAMI@ iKNOW
   Sharma A, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3968
   Williams C, 2006, CHANDOS INF PROF SER, P3
   Xing ZZ, 2012, KNOWL INF SYST, V31, P105, DOI 10.1007/s10115-011-0400-x
   Xing ZQ, 2011, 2011 6TH INTERNATIONAL ICST CONFERENCE ON COMMUNICATIONS AND NETWORKING IN CHINA (CHINACOM), P241, DOI 10.1109/ChinaCom.2011.6158156
   Yao L., 2019, P 2019 SIAM INT C DA, P486, DOI DOI 10.1137/1.9781611975673.55
   Zhao L, 2019, P 2019 INT C INT C I
NR 40
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35081
EP 35104
DI 10.1007/s11042-020-09366-8
EA AUG 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000554436800006
DA 2024-07-18
ER

PT J
AU Mangla, FU
   Shahzad, M
   Lali, MI
   Bukhari, SAC
AF Mangla, Fakhar Ullah
   Shahzad, Muzammil
   Lali, M. IkramUllah
   Bukhari, Syed Ahmad Chan
TI Sketch-based facial recognition: a weighted component-based approach
   (WCBA)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial recognition; Biometric; Weighted component-based approach (CBA);
   Composite sketch; Forensic sketch; Multiscale local binary pattern
   (MLBP); Active shape model (ASM) weight analysis; Photosynthesizing
ID FACE; CLASSIFICATION
AB Facial recognition is a popular biometric technique to recognize an individual by comparing the facial features of a given photograph or a sketch to the digitally stored photographs. One of the important applications of facial recognition is to determine the identity of criminals through their hand-drawn or composite sketches. Despite of the development made in sketch-based facial recognition, available approaches are facing various challenges. The component-based approach (CBA) measures the similarity between each facial component of a sketch and a mugshot photograph. The major challenge in this approach is to determine which facial components are crucial in the identification process. Certain facial components provide better recognition clue than others while matching with mugshot photographs and considerably accurate identification results could be achieved to incorporate such crucial components in the recognition process. In this article, we propose a novel methodology which is based on computable weights to find the most discriminative facial components by using the Weighted Component-Based Approach (WCBA). The weight vector is used during the similarity score measurement to enhance the accuracy and performance of the facial recognition system. Experimental results on matching 50 facial images from 1193 subjects of Multiple Encounter Dataset II (MEDS-II) and 85 facial images from CHUK face sketch database (CUFS) show that the proposed method achieves promising performance (accuracies of 58.33% and 88.23%, respectively) as compared to other leading facial recognition techniques (accuracies of 52% and 80%). We believe our prototype approach will be of great value to law enforcement agencies in the apprehension of culprits in a timely fashion.
C1 [Mangla, Fakhar Ullah; Shahzad, Muzammil] Univ Sargodha, Dept CS & IT, Sargodha, Pakistan.
   [Lali, M. IkramUllah] Univ Educ Lahore, Dept Informat Sci, Div Sci & Technol, Lahore, Pakistan.
   [Bukhari, Syed Ahmad Chan] St Johns Univ, Collins Coll Profess Studies, Div Comp Sci Math & Sci, New York, NY USA.
C3 University of Sargodha; Saint John's University
RP Lali, MI (corresponding author), Univ Educ Lahore, Dept Informat Sci, Div Sci & Technol, Lahore, Pakistan.
EM ikramlali@gmail.com
RI Bukhari, Syed Abdul Rehman/ABI-5806-2020; Lali, Ikram Ullah/V-4076-2019
OI Bukhari, Syed Abdul Rehman/0000-0002-6861-2623; 
CR Ashraf J, 2015, INT J ADV RES COMPUT, V3, P433
   Barnouti NH, 2016, INT J ADV COMPUTER S, V7, P5
   Cha Z., 2010, A survey of recent advances in face detection
   FACES 4.0, 2011, FACES 4 0 IQ BIOMETR
   Founds Andrew P, 2011, NIST SPECIAL DATABAS
   Grag R, 2014, INT J ADV RES COMPUT, V2
   Han H, 2013, IEEE T INF FOREN SEC, V8, P191, DOI 10.1109/TIFS.2012.2228856
   Heisele B, 2003, COMPUT VIS IMAGE UND, V91, P6, DOI 10.1016/S1077-3142(03)00073-0
   Identi-Kit, 2011, ID KIT SOL
   Ivanov Y, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P421, DOI 10.1109/AFGR.2004.1301569
   Jain AK, 2012, IEEE MULTIMEDIA, V19, P20, DOI 10.1109/MMUL.2012.4
   Kai-lin P., 2007, Proceedings of High Density packaging and Microsystem Integration International Symposium, Shanghai, P1
   Khan MA, 2019, EXPERT SYST APPL, V134, P138, DOI 10.1016/j.eswa.2019.05.040
   Klare B, 2013, IEEE T PATTERN ANAL
   Klare BF, 2014, P 2014 IEEE IAPR INT
   Klare BF, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014)
   Klum S, 2013, INT CONF BIOMETR
   Klum SJ, 2014, IEEE T INF FOREN SEC, V9, P2248, DOI 10.1109/TIFS.2014.2360825
   Kokila R, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1458, DOI 10.1109/ICACCI.2017.8126046
   Kollreider K, 2007, IEEE T INF FOREN SEC, V2, P548, DOI 10.1109/TIFS.2007.902037
   McQuiston-Surrett D, 2006, PSYCHOL CRIME LAW, V12, P505, DOI 10.1080/10683160500254904
   National Institute of Standards and Technology (NIST), 2011, NIST SPEC DAT 32 MUL
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Peng CL, 2016, IEEE T NEUR NET LEAR, V27, P2201, DOI 10.1109/TNNLS.2015.2464681
   Sadro J, ROLE EYEBROWS FACE R
   Sannidhan MS, 2019, PATTERN RECOGN LETT, V128, P452, DOI 10.1016/j.patrec.2019.10.010
   Sharma A, 2011, PROC CVPR IEEE, P593, DOI 10.1109/CVPR.2011.5995350
   Silva MAA, 2012, FACE SKETCH PHOTOREC
   Tae-Kyun Kim, 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P507
   Tang XO, 2004, IEEE T CIRC SYST VID, V14, P50, DOI 10.1109/TCSVT.2003.818353
   Wan Q, 2016, 2016 31ST YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), P1, DOI 10.1109/YAC.2016.7804856
   Wang NN, 2018, PATTERN RECOGN LETT, V107, P59, DOI 10.1016/j.patrec.2017.06.012
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P1955, DOI 10.1109/TPAMI.2008.222
   Zhang SC, 2018, PATTERN RECOGN LETT, V109, P65, DOI 10.1016/j.patrec.2017.08.029
NR 35
TC 3
Z9 3
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27533
EP 27553
DI 10.1007/s11042-020-09246-1
EA JUL 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000555554200005
DA 2024-07-18
ER

PT J
AU Bordoloi, M
   Biswas, SK
AF Bordoloi, Monali
   Biswas, Saroj Kr.
TI Graph based sentiment analysis using keyword rank based polarity
   assignment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sentiment analysis; Text mining; Keyword ranking; Graph based model;
   Centrality measure; Polarity assignment
ID EXTRACTION
AB Decision making by analyzing the underlying sentiment has become one of the challenging task with the explosion of rich source of user generated, diverse contents on the web. Sentiment analysis can ease the process of obtaining an overall sentiment by processing millions of reviews or documents altogether. A review or any textual data consists of numerous keywords, which hold different weightage based on various factors. An efficient ranking technique for those keywords is proposed in this paper in order to aid in the sentiment analysis process. A co-occurrence graph based statistical approach is adopted in this paper to find the global rank of the keywords. A novel node weighting technique is proposed, which will be used for the improvisation of the state of art method: Node and Edge Rank (NE-Rank) along with degree, to rank the keywords. The algorithm considers five different influential parameters to propose the node weighting technique. Also, a keyword may hold bi-polarity and depict different polarity according to the domain of application. Therefore, this paper proposes a novel, well organized and efficient sentiment analysis model using a graph based keyword ranking and domain specific rank based polarity assignment algorithm. The role or impact of an important keyword will be always more in comparison to a weaker one for determining the polarity of the review. Thus, the rank based polarity assignment technique is proposed with the use of the global ranks of keywords, to solve the domain dependency problem of the keywords. The proposed model is evaluated and validated using four different existing models for four different customer review datasets.
C1 [Bordoloi, Monali; Biswas, Saroj Kr.] NIT Silchar, Silchar, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Bordoloi, M (corresponding author), NIT Silchar, Silchar, Assam, India.
EM monali.bordoloi@gmail.com; bissarojkum@yahoo.com
RI Bordoloi, Monali/AGS-1758-2022
OI Bordoloi, Monali/0000-0002-0685-9268
CR Abilhoa WD, 2014, APPL MATH COMPUT, V240, P308, DOI 10.1016/j.amc.2014.04.090
   Ahmad SR, 2019, INTELL DATA ANAL, V23, P159, DOI 10.3233/IDA-173763
   [Anonymous], 2011, P 49 ANN M ASS COMP
   [Anonymous], 2011, P 2011 C EMP METH NA
   [Anonymous], 2009, P 14 AUSTRALASIAN DO
   Avinash M., 2019, Emerging Technologies in Data Mining and Information Security. Proceedings of IEMIS 2018. Advances in Intelligent Systems and Computing (AISC 814), P475, DOI 10.1007/978-981-13-1501-5_41
   Beliga S, 2015, J INF ORGAN SCI, V39, P1
   Bellaachia A, 2012, 2012 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY (WI-IAT 2012), VOL 1, P372, DOI 10.1109/WI-IAT.2012.82
   Biswas S. K., 2015, INT J BIG DATA INTEL, V3, P111
   Bordolo Monali, 2018, INT J PURE APPL MATH, V118, P71
   Bordoloi M, 2017, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTING AND INFORMATICS (ICICI 2017), P570, DOI 10.1109/ICICI.2017.8365197
   Bougouin A., 2013, INT JOINT C NAT LANG, P543
   Chatterjee S, 2019, GEND GLOB LOC WORLD, P142
   Chaudhary M, 2016, ADV INTELL SYST, V409, P271, DOI 10.1007/978-981-10-0135-2_26
   Chen Y, 2019, COMPUT SPEECH LANG, V57, P98, DOI 10.1016/j.csl.2019.01.007
   da Cunha UC, 2020, FUT INF COMM C, P678
   DEVIKA R, 2019, WIREL NETW, P1, DOI DOI 10.1007/S11276-019-02128-X
   Do HH, 2019, EXPERT SYST APPL, V118, P272, DOI 10.1016/j.eswa.2018.10.003
   Duari S, 2019, INFORM SCIENCES, V477, P100, DOI 10.1016/j.ins.2018.10.034
   Ediger D., 2010, Proceedings 39th International Conference on Parallel Processing (ICPP 2010), P583, DOI 10.1109/ICPP.2010.66
   Gaspar R, 2016, COMPUT HUM BEHAV, V56, P179, DOI 10.1016/j.chb.2015.11.040
   Haddi E, 2013, PROCEDIA COMPUT SCI, V17, P26, DOI 10.1016/j.procs.2013.05.005
   Hotho A., 2005, LDV FORUM, V20, P19, DOI DOI 10.1111/j.1365-2621.1978.tb09773.x
   Hu MQ, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P755
   Hui Li, 2018, 2018 IEEE 3rd International Conference on Big Data Analysis (ICBDA), P38, DOI 10.1109/ICBDA.2018.8367648
   Hussein Doaa Mohey El-Din Mohamed, 2018, Journal of King Saud University - Engineering Sciences, V30, P330, DOI 10.1016/j.jksues.2016.04.002
   Ji X, 2015, SOC NETW ANAL MIN, V5, DOI 10.1007/s13278-015-0253-5
   Khan MT, 2016, PROCEEDINGS OF THE 2016 19TH INTERNATIONAL MULTI-TOPIC CONFERENCE (INMIC), P31
   Kummer Ol, 2012, 1 INT WORKSH SENT DI, P48
   Kwon K, 2015, P INT C BIG DAT APPL, P30
   Lahiri S, 2014, ARXIV14016571CSCL
   Li S., 2009, ACL/AFNLP'09, P692
   Litvak M, 2011, ADV INTEL SOFT COMPU, V86, P121, DOI 10.1007/978-3-642-18029-3_13
   Mäntylä MV, 2018, COMPUT SCI REV, V27, P16, DOI 10.1016/j.cosrev.2017.10.002
   Mars A, 2017, PROCEDIA COMPUT SCI, V112, P906, DOI 10.1016/j.procs.2017.08.114
   Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011
   Mothe J, 2018, 33RD ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, P728, DOI 10.1145/3167132.3167392
   Musto C, 2016, P 2016 C US MOD AD P
   Nagarajan R., 2016, INT J ADV RES COMPUT, V6, P25
   Nasar Z, 2019, INFORM PROCESS MANAG, V56, DOI 10.1016/j.ipm.2019.102088
   Nasukawa T., 2003, P 2 INT C KNOWLEDGE, P70, DOI DOI 10.1145/945645.945658
   Noferesti S, 2015, J BIOMED INFORM, V57, P6, DOI 10.1016/j.jbi.2015.06.017
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Ravinuthala Murali Krishna V. V., 2016, International Journal of Information Engineering and Electronic Business, V8, P18, DOI 10.5815/ijieeb.2016.04.03
   Sailunaz K, 2019, J COMPUT SCI-NETH, V36, DOI 10.1016/j.jocs.2019.05.009
   Sanchez A., 2015, IN P 9 INT WORKSHOP, P556
   Semedo David, 2019, Advances in Information Retrieval. 41st European Conference on IR Research, ECIR 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11437), P852, DOI 10.1007/978-3-030-15712-8_62
   Shams B, 2017, EXPERT SYST APPL, V67, P59, DOI 10.1016/j.eswa.2016.09.013
   Sheeba J. I., 2012, P 2 INT C COMP SCI E, P212
   Shi W, 2017, DATA SCI ENG, V2, P275, DOI 10.1007/s41019-017-0055-z
   Shim KS, 2009, 2009 3RD ACM/IEEE INTERNATIONAL SYMPOSIUM ON NETWORKS-ON-CHIP, P38, DOI 10.1109/NOCS.2009.5071443
   Sidorov DA, 2012, ZOOTAXA, P1
   Sonawane S. S., 2014, International Journal of Computer Applications, V96, DOI DOI 10.5120/16899-6972
   Tan SB, 2008, EXPERT SYST APPL, V34, P2622, DOI 10.1016/j.eswa.2007.05.028
   Tang DY, 2016, IEEE T KNOWL DATA EN, V28, P496, DOI 10.1109/TKDE.2015.2489653
   Vega-Olivero DA, 2019, INFORM PROCESS MANAG, V56, DOI 10.1016/j.ipm.2019.102063
   Wang J, 2018, APPL MATH COMPUT, V334, P388, DOI 10.1016/j.amc.2018.04.028
   Wang ZT, 2016, J MACH LEARN RES, V17, P1
   Zin HM, 2017, AIP CONF PROC, V1891, DOI 10.1063/1.5005422
NR 59
TC 7
Z9 7
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 36033
EP 36062
DI 10.1007/s11042-020-09289-4
EA JUL 2020
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000552190000010
DA 2024-07-18
ER

PT J
AU Sharma, A
   Jindal, N
   Rana, PS
AF Sharma, Akanksha
   Jindal, Neeru
   Rana, P. S.
TI Potential of generative adversarial net algorithms in image and video
   processing applications- a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cost function; Image processing; Video processing; Performance
   parameters
ID LOW-DOSE CT; NETWORKS; GAN; FACE; CLASSIFICATION; TRANSLATION; MODEL
AB Generative Adversarial Network (GAN) has gained eminence in a very short period as it can learn deep data distributions with the help of a competitive process among two networks. GANs can synthesize images/videos from latent noise with a minimized adversarial cost function. The cost function plays a deciding factor in GAN training and thus, it is often subjected to new modifications to yield better performance. To date, numerous new GAN models have been proposed owing to changes in cost function according to applications. The main objective of this research paper is to present a gist of major GAN publications and developments in image and video field. Several publications were selected after carrying out a thorough literature survey. Beginning from trends in GAN research publications, basics, literature survey, databases for performance evaluation parameters are presented under one umbrella.
C1 [Sharma, Akanksha; Jindal, Neeru] Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
   [Rana, P. S.] Thapar Inst Engn & Technol, Dept Comp Sci Engn, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology; Thapar Institute of
   Engineering & Technology
RP Jindal, N (corresponding author), Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
EM asharma2_me17@thapar.edu; neeru.jindal@thapar.edu; psrana@gmail.com
RI Rana, Prashant Singh/AAE-1784-2019
OI Rana, Prashant Singh/0000-0002-0142-7925
CR Acharya Dinesh, 2018, ARXIV181002419
   Agnese J, 2020, WIRES DATA MIN KNOWL, V10, DOI 10.1002/widm.1345
   Alqahtani H, 2021, ARCH COMPUT METHOD E, V28, P525, DOI 10.1007/s11831-019-09388-y
   [Anonymous], 2016, CORR
   [Anonymous], 2018, IEEE GEOSCI REMOTE S
   [Anonymous], 2017, ARXIV PREPRINT ARXIV
   [Anonymous], 2017, ARXIV170608224
   [Anonymous], 2018, IEEE T MED IMAGING
   Arjovsky M., 2017, ARXIV170107875
   Azar MG, 2013, MACH LEARN, V91, P325, DOI 10.1007/s10994-013-5368-1
   Bansal A, 2018, LECT NOTES COMPUT SC, V11209, P122, DOI 10.1007/978-3-030-01228-1_8
   BenTaieb A, 2018, IEEE T MED IMAGING, V37, P792, DOI 10.1109/TMI.2017.2781228
   Berg T, 2014, PROC CVPR IEEE, P2019, DOI 10.1109/CVPR.2014.259
   Bermudez JD, 2019, IEEE GEOSCI REMOTE S, V16, P1220, DOI 10.1109/LGRS.2019.2894734
   Berthelot David, 2017, CoRR
   Bhattacharjee P, 2017, ADV NEUR IN, V30
   Borji A, 2019, COMPUT VIS IMAGE UND, V179, P41, DOI 10.1016/j.cviu.2018.10.009
   Brkic K, 2017, IET SIGNAL PROCESS, V11, P1062, DOI 10.1049/iet-spr.2017.0048
   Bulat A, 2018, LECT NOTES COMPUT SC, V11210, P187, DOI 10.1007/978-3-030-01231-1_12
   Cao J, 2019, IEEE T INF FOREN SEC, V14, P2028, DOI 10.1109/TIFS.2019.2891116
   Cao YJ, 2019, IEEE ACCESS, V7, P14985, DOI 10.1109/ACCESS.2018.2886814
   Chang WK, 2018, IET COMPUT VIS, V12, P596, DOI 10.1049/iet-cvi.2017.0591
   Che Tong, 2016, CoRR
   Chen KY, 2017, VIDEO SUPER RESOLUTI
   Chen X, 2019, IEEE T IND ELECT
   Chen Xi, 2016, Advances in Neural Information Processing Systems (NIPS), V29
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Chu M., 2018, ARXIV181109393
   Coates A., 2011, P 14 INT C ART INT S, P215
   Costa P, 2018, IEEE T MED IMAGING, V37, P781, DOI 10.1109/TMI.2017.2759102
   Cousins S, 2017, MACH LEARN, V106, P863, DOI 10.1007/s10994-016-5616-2
   Dauphin Y. N., 2017, arXiv preprint arXiv: 1703.09452v3
   Demir U., 2018, Patch-based image inpainting with generative adversarial networks
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dinh L., 2016, DENSITY ESTIMATION U
   Donahue J., 2016, ARXIV160509782
   Dong JY, 2019, IEEE GEOSCI REMOTE S, V16, P173, DOI 10.1109/LGRS.2018.2870880
   Fahlman SE, 1983, NAT C ART INT
   Frey BJ, 1996, ADV NEUR IN, V8, P661
   Frey Brendan J, 1998, ADAP COMP MACH LEARN
   Gao Y, 2019, IEEE T MED IMAGING, V38, P2059, DOI 10.1109/TMI.2019.2894692
   Ge HW, 2018, IEEE ACCESS, V6, P61342, DOI 10.1109/ACCESS.2018.2876096
   Ghamisi P, 2018, IEEE GEOSCI REMOTE S, V15, P794, DOI 10.1109/LGRS.2018.2806945
   Gonçalves GR, 2018, SIBGRAPI, P110, DOI 10.1109/SIBGRAPI.2018.00021
   Gong MG, 2017, IEEE GEOSCI REMOTE S, V14, P2310, DOI 10.1109/LGRS.2017.2762694
   Goodfellow I.J., 2013, MULTIDIGIT NUMBER RE
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   Griffin G, 2007, CALTECH 101 OBJECT C
   Griffin G., 2007, CALTECH 256 OBJECT C
   Grzegorczyk M, 2016, MACH LEARN, V102, P155, DOI 10.1007/s10994-015-5503-2
   Gurumurthy S., 2017, P IEEE C COMPUTER VI, P166
   He YW, 2019, IEEE T INF FOREN SEC, V14, P102, DOI 10.1109/TIFS.2018.2844819
   Hensel M, 2017, ADV NEUR IN, V30
   Hinton G. E., 1986, Parallel Distributed Processing: Explorations in the Microstructure of Cognition: Foundations, V1, P2
   Hu B, 2017, ARXIV171111317
   Huang Z, 2019, DIVIDE AND CONQUER A
   Im D. J., 2016, ARXIV160205110
   Gulrajani I, 2017, ADV NEUR IN, V30
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jiang Y, 2017, IGGRAPH ASIA 2017 TECHNICAL BRIEFS (SA'17), DOI 10.1145/3145749.3149440
   Jolicoeur-Martineau A., 2018, The relativistic discriminator: A key element missing from standard GAN
   Juefei-Xu F., 2017, GANG GANS GENERATIVE
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Kim D, 2018, IEEE SIGNAL PROC LET, V25, DOI 10.1109/LSP.2017.2782363
   Kim T., 2017, P 34 INT C MACH LEAR, P1857, DOI DOI 10.1109/WPT.2017.7953894
   Kingma Durk P, 2016, Advances in neural information processing systems
   Kodali N., 2017, ARXIV170507215
   Krizhevsky A., 2010, UNPUB, V40, P1
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lee HJ, 2020, IEEE T CIRC SYST VID, V30, P771, DOI 10.1109/TCSVT.2019.2897243
   Lehmann E. L., 1986, TESTING STAT HYPOTHE
   Li HF, 2019, IEEE T CYBERNETICS, V49, P4398, DOI 10.1109/TCYB.2018.2865036
   Li J., 2018, IEEE Transactions on Industrial Informatics
   Li J, 2019, IEEE T IND ELECTRON, V66, P8772, DOI 10.1109/TIE.2018.2889629
   Li J, 2018, IEEE ROBOT AUTOM LET, V3, P387, DOI 10.1109/LRA.2017.2730363
   Li P, 2019, IEEE T INF FOREN SEC, V14, P2000, DOI 10.1109/TIFS.2018.2890812
   Li YX, 2018, IEEE ACCESS, V6, P14048, DOI 10.1109/ACCESS.2018.2808938
   Liang XD, 2017, IEEE I CONF COMP VIS, P1762, DOI 10.1109/ICCV.2017.194
   Liao K, 2020, IEEE T CIRC SYST VID, V30, P725, DOI 10.1109/TCSVT.2019.2897984
   Lin DY, 2017, IEEE GEOSCI REMOTE S, V14, P2092, DOI 10.1109/LGRS.2017.2752750
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Z., 2018, LARGE SCALE CELEBFAC, V15, P2018
   Lopez-Tapia S, 2018, SINGLE VIDEO SUPER R
   Lopez-Tapia S, 2019, IEEE IMAGE PROC, P2886, DOI 10.1109/ICIP.2019.8803709
   Lucas A, 2019, IEEE T IMAGE PROCESS, V28, P3312, DOI 10.1109/TIP.2019.2895768
   Lucic M, 2018, ADV NEUR IN, V31
   Ma DG, 2019, IEEE GEOSCI REMOTE S, V16, P1046, DOI 10.1109/LGRS.2018.2890413
   Ma S, 2018, PROC CVPR IEEE, P5657, DOI 10.1109/CVPR.2018.00593
   Mao XD, 2019, IEEE T PATTERN ANAL, V41, P2947, DOI 10.1109/TPAMI.2018.2872043
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Mardani M, 2019, IEEE T MED IMAGING, V38, P167, DOI 10.1109/TMI.2018.2858752
   Mathur M, 2017, INT J MICROW WIREL T, V9, P543, DOI 10.1017/S1759078716000295
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Miyato T, 2018, INT C LEARN REPR
   Nie D, 2018, IEEE T BIO-MED ENG, V65, P2720, DOI 10.1109/TBME.2018.2814538
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Niu XD, 2019, IEEE GEOSCI REMOTE S, V16, P45, DOI 10.1109/LGRS.2018.2868704
   Odena A, 2017, PR MACH LEARN RES, V70
   Ohnishi K, 2018, AAAI CONF ARTIF INTE, P2387
   Oliveira DAB, 2018, IEEE GEOSCI REMOTE S, V15, P1952, DOI 10.1109/LGRS.2018.2866199
   Oord A., 2016, ARXIV160903499
   Ouyang X., 2018, ARXIV180402047
   Pan YW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1789, DOI 10.1145/3123266.3127905
   Pang YW, 2019, IEEE T CIRC SYST VID, V29, P3211, DOI 10.1109/TCSVT.2018.2880223
   Pascual S, 2017, INTERSPEECH, P3642, DOI 10.21437/Interspeech.2017-1428
   Radford A., 2015, ARXIV
   Rezende DJ, 2015, PR MACH LEARN RES, V37, P1530
   Richardson E, 2018, ADV NEURAL INFORM PR, P5852
   Saito Y, 2018, IEEE-ACM T AUDIO SPE, V26, P84, DOI 10.1109/TASLP.2017.2761547
   Sakkos D, 2019, IEEE ACCESS, V7, P10976, DOI 10.1109/ACCESS.2019.2891943
   Salimans T, 2016, ADV NEUR IN, V29
   Shan HM, 2018, IEEE T MED IMAGING, V37, P1522, DOI 10.1109/TMI.2018.2832217
   Shen Z, 2018, PROC CVPR IEEE, P5245, DOI 10.1109/CVPR.2018.00550
   Shen ZY, 2019, IEEE I CONF COMP VIS, P5571, DOI 10.1109/ICCV.2019.00567
   Snell J, 2017, IEEE IMAGE PROC, P4277, DOI 10.1109/ICIP.2017.8297089
   Sun YH, 2017, IEEE ICC
   Theis L., 2015, ARXIV151101844
   Quan TM, 2018, IEEE T MED IMAGING, V37, P1488, DOI 10.1109/TMI.2018.2820120
   Tuan YL, 2019, IEEE-ACM T AUDIO SPE, V27, P788, DOI 10.1109/TASLP.2019.2896437
   Tulyakov S, 2018, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR.2018.00165
   Van Horn G, 2017, ARXIV170706642, V1
   VANHORN G, 2015, PROC CVPR IEEE, P595
   Vondrick C, 2016, 30 C NEURAL INFORM P, V29
   Walker J, 2017, IEEE I CONF COMP VIS, P3352, DOI 10.1109/ICCV.2017.361
   Wang WY, 2017, IEEE I CONF COMP VIS, P2317, DOI 10.1109/ICCV.2017.252
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang Y, 2019, IEEE T MED IMAGING, V38, P1328, DOI 10.1109/TMI.2018.2884053
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZL, 2018, IEEE SIGNAL PROC LET, V25, P1161, DOI 10.1109/LSP.2018.2845692
   Welinder P., 2010, Technical Report CNS-TR-2010-001
   Wen SP, 2019, IEEE T CIRC SYST VID, V29, P2337, DOI 10.1109/TCSVT.2018.2867934
   Wolterink JM, 2017, IEEE T MED IMAGING, V36, P2536, DOI 10.1109/TMI.2017.2708987
   Wu WM, 2018, IEEE ACCESS, V6, P58898, DOI 10.1109/ACCESS.2018.2874544
   Xiang S., 2017, STAT-US
   Xiao H., 2017, ARXIV170807747
   Xiong W, 2018, PROC CVPR IEEE, P2364, DOI 10.1109/CVPR.2018.00251
   Xu CG, 2019, IEEE T INF FOREN SEC, V14, P2358, DOI 10.1109/TIFS.2019.2897874
   Xuan Q, 2019, IEEE T IND ELECTRON, V66, P8244, DOI 10.1109/TIE.2018.2885684
   Yang G, 2018, IEEE T MED IMAGING, V37, P1310, DOI 10.1109/TMI.2017.2785879
   Yang QS, 2018, IEEE T MED IMAGING, V37, P1348, DOI 10.1109/TMI.2018.2827462
   Yang Y, 2018, IEEE T IMAGE PROCESS, V27, P5600, DOI 10.1109/TIP.2018.2855422
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Yu BT, 2019, IEEE T MED IMAGING, V38, P1750, DOI 10.1109/TMI.2019.2895894
   Yu Fisher, 2015, ARXIV150603365
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Yuan Y, 2018, IEEE ACCESS, V6, P5573, DOI 10.1109/ACCESS.2018.2796118
   Zeng Y., 2017, ARXIV PREPRINT ARXIV
   Zhan Y, 2018, IEEE GEOSCI REMOTE S, V15, P212, DOI 10.1109/LGRS.2017.2780890
   Zhang H., 2018, ARXIV180508318
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
   Zhang KH, 2019, IEEE T IMAGE PROCESS, V28, P291, DOI 10.1109/TIP.2018.2867733
   Zhang LM, 2019, MACH LEARN, V108, P1851, DOI 10.1007/s10994-018-05777-9
   Zhang MY, 2019, IEEE T GEOSCI REMOTE, V57, P2669, DOI 10.1109/TGRS.2018.2876123
   Zhang ZF, 2018, IEEE WINT CONF APPL, P700, DOI 10.1109/WACV.2018.00082
   Zhao J, 2016, 2016 IEEE MTT-S INTERNATIONAL WIRELESS SYMPOSIUM (IWS), DOI 10.1109/ICSSSM.2016.7538614
   Zhou Z, 2017, ARXIV170302000
   Zhu JY, 2017, ADV NEUR IN, V30
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu L, 2018, IEEE T GEOSCI REMOTE, V56, P5046, DOI 10.1109/TGRS.2018.2805286
   Zhu XN, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/5217429
NR 163
TC 3
Z9 3
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27407
EP 27437
DI 10.1007/s11042-020-09308-4
EA JUL 2020
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000552190000006
DA 2024-07-18
ER

PT J
AU Amorim, GF
   dos Santos, JAF
   Muchaluat-Saade, DC
AF Amorim, Glauco F.
   dos Santos, Joel A. F.
   Muchaluat-Saade, Debora C.
TI Providing adjustable and dynamic spatial layouts for multimedia
   applications with STyLe
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE STyLe; Template authoring; Adjustable spatial layout; Dynamic spatial
   layouts; NCL; Spatial constraints
AB Interactive multimedia applications may be presented on multiple devices with different screen sizes. Therefore, application layouts should be adapted during runtime. Besides adapting layouts to different devices, the number of visual multimedia objects may vary, thus it is desirable to provide an automatic application layout adjustment to ease the authoring effort and provide good user quality of experience. In this article, the termadjustable layoutis used to refer to an application spatial layout that adjusts itself to the number of media objects to be presented. The termdynamic layoutis used to refer to an application spatial layout that can change at runtime in reaction to presentation events. Multimedia declarative authoring languages, such as NCL and SMIL, provide simple layout construction using nested rectangular regions to design the application layout. However, these languages do not provide native facilities for authors to develop adjustable and dynamic layouts. This article proposes STyLe, a constraint-based template language for providing adjustable and dynamic spatial layouts for multimedia documents. It also presents an architecture that is capable of interpreting STyLe when used together with NCL to provide dynamic layouts for interactive digital TV applications. The results show that STyLe has more expressiveness and abstraction when compared to NCL and that the language is simple and effective for building adjustable and dynamic layouts.
C1 [Amorim, Glauco F.; dos Santos, Joel A. F.] Sch Comp & Informat CEFET RJ, Rio De Janeiro, RJ, Brazil.
   [Muchaluat-Saade, Debora C.] Fluminense Fed Univ UFF, Inst Comp, MidiaCom Lab, Rio De Janeiro, RJ, Brazil.
C3 Universidade Federal Fluminense
RP Amorim, GF (corresponding author), Sch Comp & Informat CEFET RJ, Rio De Janeiro, RJ, Brazil.
EM glauco.amorim@cefet-rj.br; jsantos@eic.cefet-rj.br;
   debora@midiacom.uff.br
RI Amorim, Glauco Fiorott/V-2663-2018; Muchaluat-Saade, Débora
   Christina/E-7794-2014; dos Santos, Joel/O-6246-2016
OI Amorim, Glauco Fiorott/0000-0001-6110-7424; dos Santos,
   Joel/0000-0001-7234-613X
CR 2IMMERSE, 2015, 2 IMM LAYOUT ENG PAC
   ABNT, 2007, 1560622007 ABNT NBR
   Albert I, 2013, 2013 IEEE EUROCON, P543, DOI 10.1109/EUROCON.2013.6625034
   Amorim G.P., 2017, THESIS
   Amorim GF, 2016, MULTIMEDIA MODELI 1
   Angulo J, 2011, TELECOMMUN POLICY, V35, P773, DOI 10.1016/j.telpol.2011.07.007
   [Anonymous], P 2006 ACM S DOC ENG
   [Anonymous], 2009, NEST CONT LANG NCL G
   Badros G. J., 1999, 99 UIST. Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology, P73, DOI 10.1145/320719.322588
   Barrett C, 2009, FRONT ARTIF INTEL AP, V185, P825, DOI 10.3233/978-1-58603-929-5-825
   BHAUMIK S., 2015, Bootstrap Essentials
   Borning A, 2000, MULTIMEDIA SYST, V8, P177, DOI 10.1007/s005300000043
   Bryant J., 2012, PROHTML5 PERFORMANCE, P37
   de Moura MSA, 2001, THESIS
   Dutertre B, 2015, YICES MANUAL VERSION
   dos Santos JAF, 2012, MULTIMED TOOLS APPL, V61, P645, DOI 10.1007/s11042-011-0732-2
   Geurts J, 2001, APPL SPECIFIC CONSTR
   Green TRG, 1996, J VISUAL LANG COMPUT, V7, P131, DOI 10.1006/jvlc.1996.0009
   HbbTV Association, 2018, HBBTV 2 0 2 SPEC
   Hickson Ian., 2014, HTML5: A vocabulary and associated apis for html and xhtml
   Ierusalimschy R., 2016, PROGRAMMING LUA, Vfourth
   ITU, 2018, INT BROADC BROADB SY
   Jacobs C, 2003, ACM T GRAPHIC, V22, P838, DOI 10.1145/882262.882353
   Li J, 2018, 2018 CHI C HUM FACT, P1
   Li J, 2018, TVX 2018: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE EXPERIENCES FOR TV AND ONLINE VIDEO, P115, DOI 10.1145/3210825.3210834
   McCormack C, 2004, ADAPTIVE LAYOUT USIN
   Muchaluat-Saade D. C., 2002, New Review of Hypermedia and Multimedia, V8, P139, DOI 10.1080/13614560208914739
   Schrier Evan, 2008, 13th International Conference on Intelligent User Interfaces. IUI 2008, p99, 106, DOI 10.1145/1378773.1378787
   Soares LFG, 2014, P 20 BRAZ S MULT WEB, P207, DOI [10.1145/2664551.2664559, DOI 10.1145/2664551.2664559]
   Soares LFG, 2012, P 2012 ACM S DOC ENG, P217, DOI [10.1145/2361354.2361403, DOI 10.1145/2361354.2361403]
   Soares Neto C.S., 2012, P 2012 ACM S DOCUMEN, P69, DOI [10.1145/2361354.2361369, DOI 10.1145/2361354.2361369]
   Tocchini D, 2016, GRID STYLE SHEETS 2
   Van den Bergh J, 2008, MULTIMEDIA SYST, V14, P89, DOI 10.1007/s00530-008-0116-2
   W3C, 2008, Synchronized multimedia integration language (SMIL 3.0)
   W3C, 2017, CSS FLEX BOX LAYOUT
   W3C, 2017, CSS GRID LAYOUT MOD
   Zhang K, 2005, MULTIMEDIA SYST, V10, P245, DOI 10.1007/s00530-004-0155-2
NR 37
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25989
EP 26021
DI 10.1007/s11042-020-09204-x
EA JUL 2020
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000546532000002
DA 2024-07-18
ER

PT J
AU Medimegh, N
   Belaid, S
   Atri, M
   Werghi, N
AF Medimegh, Nassima
   Belaid, Samir
   Atri, Mohamed
   Werghi, Naoufel
TI Statistical 3D watermarking algorithm using non negative matrix
   factorization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D watermarking; Statistical method; Non negative matrix factorization
AB In this paper, we propose a robust blind watermarking method for 3D object based on Non Negative Matrix Factorization (NMF). Our main idea is to use the NMF basis matrix guide the watermark embedding. We first segment the model into partitions based on its salient points. Then, we apply NMF algorithm to the vertex norms. The distribution of vertex is grouped into bins according to the basis matrixX. Finally, we insert watermark bits in the vertex norm distribution. Experimental results demonstrate that the proposed method achieved good visual quality and also robustness against various attacks.
C1 [Medimegh, Nassima; Atri, Mohamed] Univ Monastir, Fac Sci, Microelect Lab, Monastir, Tunisia.
   [Belaid, Samir] Univ Sousse, Higher Inst Comp Sci & Telecom ISITCom, MARS Res Lab LR17ES05, Sousse, Tunisia.
   [Werghi, Naoufel] Khalifa Univ, Dept Elect & Comp Engn, Abu Dhabi, U Arab Emirates.
C3 Universite de Monastir; Universite de Sousse; Khalifa University of
   Science & Technology
RP Medimegh, N (corresponding author), Univ Monastir, Fac Sci, Microelect Lab, Monastir, Tunisia.
EM Medimegh_nassima@yahoo.fr; Samir.Belaid@fsm.rnu.tn;
   Mohamed.Atri@fsm.rnu.tn; Naoufel.Werghi@kustar.ac.ae
RI Medimegh, Nassima/AAB-3419-2022; Werghi, Naoufel/ABA-6280-2020; ATRI,
   Mohamed/C-4069-2014; BELAID, Samir/AGA-5268-2022
OI Medimegh, Nassima/0000-0001-5614-6736; Werghi,
   Naoufel/0000-0002-5542-448X; ATRI, Mohamed/0000-0001-8528-5647; BELAID,
   Samir/0000-0003-3392-507X
CR Abdallah EE, 2008, LECT NOTES COMPUT SC, V5112, P253, DOI 10.1007/978-3-540-69812-8_25
   [Anonymous], 6 IEEE INT C SOFTW E
   Berry MW, 2007, COMPUT STAT DATA AN, V52, P155, DOI 10.1016/j.csda.2006.11.006
   Chen LM, 2011, ATL AMB PERVAS INTEL, V4, P1, DOI 10.1097/COC.0b013e3181fe41ed
   Cho JW, 2007, IEEE T SIGNAL PROCES, V55, P142, DOI 10.1109/TSP.2006.882111
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   Gebal K, 2009, COMPUT GRAPH FORUM, V28, P1405, DOI 10.1111/j.1467-8659.2009.01517.x
   Guillamet D, 2003, PATTERN RECOGN LETT, V24, P2447, DOI 10.1016/S0167-8655(03)00089-8
   Hamidi M, 2019, INFORMATION, V10, DOI 10.3390/info10020067
   Jang HU, 2018, MULTIMED TOOLS APPL, V77, P5685, DOI 10.1007/s11042-017-4483-6
   Kim H, 2008, SIAM J MATRIX ANAL A, V30, P713, DOI 10.1137/07069239X
   Kim MS, 2005, INT WORKSH DIG WAT
   Liang S, 2012, COMM COM INF SC, V308, P146
   Liu J, 2017, NEUROCOMPUTING, V237, P304, DOI 10.1016/j.neucom.2016.12.065
   Liu YJ, 2015, ARXIV150505590CSCG
   Medimegh N, 2018, MULTIMED TOOLS APPL, P1
   Medimegh N, 2015, INT J MULTIMEDIA, V1, P1, DOI DOI 10.16966/IJM.102
   Mortara M, 2002, SHAPE MODELING INT
   Mun SM, 2015, INT CONF 3D IMAG
   Ohbuchi R, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P261, DOI 10.1145/266180.266377
   Pratikakis I., 2010, EUR WORKSH 3D OBJ RE, P7, DOI DOI 10.2312/3DOR/3DOR10/007-014
   Son J, 2017, LECT NOTES ELECTR EN, V424, P315, DOI 10.1007/978-981-10-4154-9_37
   Tong M, 2018, NEURAL COMPUT APPL, P1
   Tong M, 2019, NEURAL COMPUT APPL, V31, P7447, DOI 10.1007/s00521-018-3554-6
   Vallet B, 2008, COMPUT GRAPH FORUM, V27, P251, DOI 10.1111/j.1467-8659.2008.01122.x
   Wang JR, 2012, VISUAL COMPUT, V28, P1049, DOI 10.1007/s00371-011-0650-3
   Zdunek R, 2006, LECT NOTES COMPUTER, V4029
   Zhan YZ, 2014, J ZHEJIANG U-SCI C, V15, P351, DOI 10.1631/jzus.C1300306
NR 28
TC 4
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25889
EP 25904
DI 10.1007/s11042-020-09241-6
EA JUL 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000546222400002
DA 2024-07-18
ER

PT J
AU Sharma, DK
   Pamula, R
   Chauhan, DS
AF Sharma, Dilip Kumar
   Pamula, Rajendra
   Chauhan, D. S.
TI A contemporary combined approach for query expansion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Query expansion; Pseudo-relevance feedback; Ontology on query expansion;
   Information retrieval system; Concept-based normalization
ID INFORMATION-RETRIEVAL; MODEL; WEB; SIMILARITY; TEXT
AB The use of an automatic query expansion technique is to enhance the performance of the Information Retrieval System. Selecting the candidate terms for query expansion is an essential task to make query more precise to extract the most suitable documents. This paper provides a method to select the best terms for query enhancement. Firstly, the effectof abbreviation resolution, Lexical Variation, Synonyms, n-gram pseudo-relevance feedback, Co-occurrence method on baseline approaches of query expansion is analyzed.. In this work, we used the Okapi BM25 algorithm for ranking. We used Concept-based normalization to deal with concept terms. Here our results show the improvement in results than the baseline approach. A new combined technique that integrates lexical variation, synonyms, n-gram pseudo relevance feedback for query enhancement is proposed. For experimental purpose three English written datasets CACM, CISI, and TREC-3 is used. The obtained results show improvement in the performance of query expansion concerning mean average precision, F-measure, and precision-recall curve.
C1 [Sharma, Dilip Kumar; Pamula, Rajendra] Indian Inst Technol ISM, Dhanbad, Bihar, India.
   [Sharma, Dilip Kumar; Chauhan, D. S.] GLA Univ, Mathura, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad; GLA University
RP Sharma, DK (corresponding author), Indian Inst Technol ISM, Dhanbad, Bihar, India.; Sharma, DK (corresponding author), GLA Univ, Mathura, India.
EM todilipsharma@gmail.com; rajendrapamula@gmail.com; pdschauhan@gmail.com
RI Sharma, Dilip Kumar/GSD-9300-2022; Pamula, Rajendra/V-9454-2019
OI Pamula, Rajendra/0000-0002-4806-3495; Sharma, Dilip
   Kumar/0000-0002-3860-7997; CHAUHAN, Prof. D S/0000-0002-9076-0665
CR Anand R., 2015, P 7 FORUM INFORM RET, P27
   [Anonymous], TREC
   [Anonymous], 2018, KNOWL INF SYST
   [Anonymous], P EACL
   Azad HK, 2019, INFORM PROCESS MANAG, V56, P1698, DOI 10.1016/j.ipm.2019.05.009
   Azad HK, 2019, INFORM SCIENCES, V492, P147, DOI 10.1016/j.ins.2019.04.019
   Azad HK, 2019, ARXIV190810193
   Bendersky M., 2012, P 5 ACM INT C WEB SE, P443
   Bhogal J, 2007, INFORM PROCESS MANAG, V43, P866, DOI 10.1016/j.ipm.2006.09.003
   Bouchoucha A, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P1861, DOI 10.1145/2505515.2507881
   Bounhas I, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102124
   Carpineto C, 2001, ACM T INFORM SYST, V19, P1, DOI 10.1145/366836.366860
   Carpineto C, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2071389.2071390
   Chandra G, 2019, APPL ARTIF INTELL, V33, P567, DOI 10.1080/08839514.2019.1577018
   Chang YC, 2007, J CHIN INST ENG, V30, P511, DOI 10.1080/02533839.2007.9671279
   Chaudhary C, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3375786
   Chen H., 2001, P 2 INT C WEB INF SY, P245
   Cooper JW, 1998, P ANN HICSS, P277, DOI 10.1109/HICSS.1998.651710
   Dahab M.Y., 2018, Intelligent_Natural_Language_Processing:_Trends_and_Applications, P761
   Dalton Jeffrey, 2019, Advances in Information Retrieval. 41st European Conference on IR Research, ECIR 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11437), P290, DOI 10.1007/978-3-030-15712-8_19
   Di Marco A, 2013, COMPUT LINGUIST, V39, P709, DOI 10.1162/COLI_a_00148
   Esposito M, 2020, INFORM SCIENCES, V514, P88, DOI 10.1016/j.ins.2019.12.002
   Fang F, 2018, IEEE ACCESS, V6, P45448, DOI 10.1109/ACCESS.2018.2861869
   Fattahi R, 2008, INFORM PROCESS MANAG, V44, P1503, DOI 10.1016/j.ipm.2007.09.009
   Gupta Y., 2019, INT J ENG ADV TECHNO, V8, P130
   Gupta Y, 2013, INT J COMPUT INF SCI, V7, P940
   Gupta Y, 2019, SOFT COMPUT, V23, P145, DOI 10.1007/s00500-018-3514-1
   Gupta Y, 2017, KNOWL-BASED SYST, V136, P97, DOI 10.1016/j.knosys.2017.09.004
   Gupta Y, 2014, J INF SCI, V40, P846, DOI 10.1177/0165551514548989
   Gupta Y, 2015, EXPERT SYST APPL, V42, P1223, DOI 10.1016/j.eswa.2014.09.009
   Horng JT, 2000, INFORM PROCESS MANAG, V36, P737, DOI 10.1016/S0306-4573(00)00008-X
   Hsu MH, 2008, LECT NOTES COMPUT SC, V4993, P213
   Htun NN, 2018, INFORM PROCESS MANAG, V54, P60, DOI 10.1016/j.ipm.2017.09.003
   Huang Q, 2018, SOFTWARE PRACT EXPER, V48, P1333, DOI 10.1002/spe.2574
   Keyword, 2020, QUERY SIZE COUNTRY
   Khan LF, 2002, PROC INT C TOOLS ART, P122, DOI 10.1109/TAI.2002.1180796
   Khennak I, 2020, CRITICAL APPROACHES, P1
   Khennak I, 2017, APPL INTELL, V47, P793, DOI 10.1007/s10489-017-0924-1
   Kotov A., 2012, P WSDM, DOI DOI 10.1145/2124295.2124344
   KROVETZ R, 1992, ACM T INFORM SYST, V10, P115, DOI 10.1145/146802.146810
   Kumar R, 2019, APPL INTELL, V49, P2178, DOI 10.1007/s10489-018-1383-z
   Latiri C, 2012, J INTELL INF SYST, V39, P209, DOI 10.1007/s10844-011-0189-9
   Li H, 2013, FOUND TRENDS INF RET, V7, P345, DOI 10.1561/1500000035
   Li Z, 2006, MEASURING, MONITORING AND MODELING CONCRETE PROPERTIES, P379, DOI 10.1007/978-1-4020-5104-3_46
   Macdonald C., 2007, Proceedings of the 16th ACM CIKM International Conference on Information and Knowledge Management (CIKM), P341, DOI DOI 10.1145/1321440.1321490
   Mahler D, 2004, NEW DIRECTIONS QUEST, V2004, P203
   Nasir JA, 2019, INFORM PROCESS MANAG, V56, P1605, DOI 10.1016/j.ipm.2019.04.007
   NOWACKA K, 2008, 12 INT C INF PROC MA
   Pérez F, 2019, AUTOMAT SOFTW ENG, V26, P161, DOI 10.1007/s10515-019-00251-9
   Robertson S. E., 1995, Text REtrieval Conference (TREC-3) (NIST SP 500-225), P109
   Robertson S. E., 1999, Seventh Text REtrieval Conference (TREC-7) (NIST SP 500-242), P253
   Schwartz Ariel S, 2003, Pac Symp Biocomput, P451
   Sharma DK, 2020, J BIOMOL STRUCT DYN, V38, P114, DOI 10.1080/07391102.2019.1568916
   Sharma DK, 2019, PROCEEDINGS 2019 AMITY INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AICAI), P972, DOI [10.1109/aicai.2019.8701319, 10.1109/AICAI.2019.8701319]
   Sharma DK, 2018, INT C ADV COMP DAT S, P336, DOI 10.1007/978-981-13-1813-9_34
   Sharma DK, 2019, 2019 INT C CONT COMP, P101
   Singh J, 2018, SWARM EVOL COMPUT, V38, P295, DOI 10.1016/j.swevo.2017.09.007
   Singh J, 2017, INT J INTELL INF TEC, V13, P57, DOI 10.4018/IJIIT.2017070104
   Singh J, 2017, NEURAL COMPUT APPL, V28, P2557, DOI 10.1007/s00521-016-2207-x
   Singh J, 2017, HUM-CENT COMPUT INFO, V7, DOI 10.1186/s13673-017-0116-3
   Spink A, 2001, J AM SOC INF SCI TEC, V52, P226, DOI 10.1002/1097-4571(2000)9999:9999<::AID-ASI1591>3.0.CO;2-R
   Stokes N, 2009, INFORM RETRIEVAL, V12, P17, DOI 10.1007/s10791-008-9073-9
   Torjmen-Khemakhem M, 2019, J BIOMED INFORM, V95, DOI 10.1016/j.jbi.2019.103210
   Vitaly K., 2011, INT J HYBRID INFORM, V35, P401
   Wang Yashen, 2019, IEEE T KNOWL DATA EN, V33, P1
   Wasim M, 2019, MULTIMED TOOLS APPL, V78, P29681, DOI 10.1007/s11042-018-6060-z
   Wu YT, 2019, KNOWL-BASED SYST, V163, P736, DOI 10.1016/j.knosys.2018.09.035
   Zhang C, 2005, IEEE INTELLIGENT INF, V5, P18
   Zhou W., 2006, P TREC 06
   Zingla MA, 2018, INFORM RETRIEVAL J, V21, P337, DOI 10.1007/s10791-017-9326-6
NR 70
TC 5
Z9 5
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 35195
EP 35221
DI 10.1007/s11042-020-09172-2
EA JUL 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000545195600004
DA 2024-07-18
ER

PT J
AU Lakhili, Z
   El Alami, A
   Mesbah, A
   Berrahou, A
   Qjidaa, H
AF Lakhili, Zouhir
   El Alami, Abdelmajid
   Mesbah, Abderrahim
   Berrahou, Aissam
   Qjidaa, Hassan
TI Robust classification of 3D objects using discrete orthogonal moments
   and deep neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D discrete orthogonal moments; 3D object classification; Geometric
   transformations; Noisy conditions; Deep neural networks
ID IMAGE-ANALYSIS; SCALE INVARIANTS; PATTERN-RECOGNITION; TRANSLATION;
   KRAWTCHOUK; BLUR
AB In this paper, we propose a new model based on 3D discrete orthogonal moments and deep neural networks (DNN) to improve the classification accuracy of 3D objects under geometric transformations and noise. However, the utilization of moment invariants presents some drawbacks: They can't describe the object efficiently, and their computation process is time consuming. Discrete orthogonal moments have the property to extract pertinent features from an image even in lower orders and are robust to noise. The main goal of this work is to investigate the robustness of the proposed model to geometric transformations like translation, scale and rotation and noisy conditions. The experiment simulations are conducted on datasets formed by applying some geometric transformations and noise on selected objects from McGill database. The obtained results indicate that the proposed model achieves high performance classification rates, robust to geometric transformations and noise degradation than other methods based on moment invariants.
C1 [Lakhili, Zouhir; El Alami, Abdelmajid] Sidi Mohamed Ben Abdellah Univ, CED ST Ctr Doctoral Studies Sci & Technol, LESSI Lab, Fac Sci Dhar el Mahraz, Fes, Morocco.
   [Qjidaa, Hassan] Sidi Mohamed Ben Abdellah Univ, Dept Phys, Fes, Morocco.
   [Mesbah, Abderrahim; Berrahou, Aissam] Mohammed V Univ, Rabat, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez; Mohammed V University in Rabat
RP Lakhili, Z (corresponding author), Sidi Mohamed Ben Abdellah Univ, CED ST Ctr Doctoral Studies Sci & Technol, LESSI Lab, Fac Sci Dhar el Mahraz, Fes, Morocco.
EM lakhili.zouhir@gmail.com
RI El Alami, Abdelmajid/CAF-5211-2022; El Alami, Abdelmajid/CAI-1690-2022
OI berrahou, aissam/0000-0003-2787-3138; Hassan,
   qjidaa/0000-0003-4505-5243; EL ALAMI, Abdelmajid/0000-0002-2489-661X
CR Al-Ayyoub M, 2018, MULTIMED TOOLS APPL, V77, P4939, DOI 10.1007/s11042-016-4218-0
   AlZu'bi S, 2020, PATTERN RECOGN LETT, V130, P312, DOI 10.1016/j.patrec.2018.07.026
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   Batioua I, 2017, PATTERN RECOGN, V71, P264, DOI 10.1016/j.patcog.2017.06.013
   BELKASIM SO, 1991, PATTERN RECOGN, V24, P1117, DOI 10.1016/0031-3203(91)90140-Z
   Benouini R, 2018, MULTIMED TOOLS APPL, P1
   Bishop C. M., 2006, PATTERN RECOGN
   Blum C, 2005, PHYS LIFE REV, V2, P353, DOI 10.1016/j.plrev.2005.10.001
   Canterakis N., 1999, PROC 11 SCANDINAVIAN, P85
   Chong CW, 2003, PATTERN ANAL APPL, V6, P176, DOI 10.1007/s10044-002-0183-5
   Chong CW, 2004, PATTERN RECOGN, V37, P119, DOI 10.1016/j.patcog.2003.06.003
   Clevert D., 2016, ARXIV151107289
   Cyganski D., 1988, Advances in computer vision and image processing, P101
   Dai XB, 2010, PATTERN RECOGN, V43, P1152, DOI 10.1016/j.patcog.2009.07.009
   Fehr J, 2008, INT C PATT RECOG, P616
   Flusser J, 2009, PATTERN RECOGNITION
   Flusser J., 2016, 2D and 3D image analysis by moments, P1, DOI 10.1002/9781119039402
   GALVEZ JM, 1993, PATTERN RECOGN, V26, P667, DOI 10.1016/0031-3203(93)90120-L
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Goh HA, 2009, INT J IMAGE GRAPH, V9, P271, DOI 10.1142/S0219467809003435
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Iscan Z, 2010, EXPERT SYST APPL, V37, P2540, DOI 10.1016/j.eswa.2009.08.003
   Jian MW, 2018, COMPUT IND, V99, P110, DOI 10.1016/j.compind.2018.03.034
   Jian MW, 2013, COMPUT IND, V64, P1229, DOI 10.1016/j.compind.2013.06.011
   Kazhdan M, 2007, IEEE T PATTERN ANAL, V29, P1221, DOI 10.1109/TPAMI.2007.1032
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2012, ADV NEURAL INF PROCE, P1079
   Liao S, 2002, INT C PATT RECOG, P485, DOI 10.1109/ICPR.2002.1047982
   LO CH, 1989, IEEE T PATTERN ANAL, V11, P1053, DOI 10.1109/34.42836
   Luciano L, 2018, PATTERN RECOGN LETT, V105, P182, DOI 10.1016/j.patrec.2017.05.011
   Mademlis A, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P743
   Mesbah A, 2018, NONRIGID 3D MODEL CL
   Mesbah A, 2016, INT CONF MULTIMED, P1, DOI 10.1109/ICMCS.2016.7905559
   Mesbah A, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.6.061621
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Mukundan R., 1998, Moment Functions in Image Analysis: Theory and Applications
   Mundy J., 1992, GEOMETRIC INVARIANCE
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Palaniappan R, 2000, PATTERN ANAL APPL, V3, P78, DOI 10.1007/s100440070014
   Pandey VK, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P255, DOI 10.1109/SPIN.2016.7566699
   Reiss T.H., 1993, RECOGNIZING PLANAR O
   Reverdy P, 2016, IEEE T AUTOM SCI ENG, V13, P54, DOI 10.1109/TASE.2015.2499244
   Ruder S., 2016, ARXIV
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   SADJADI FA, 1980, IEEE T PATTERN ANAL, V2, P127, DOI 10.1109/TPAMI.1980.4766990
   SHENG YL, 1994, J OPT SOC AM A, V11, P1748, DOI 10.1364/JOSAA.11.001748
   SIETSMA J, 1991, NEURAL NETWORKS, V4, P67, DOI 10.1016/0893-6080(91)90033-2
   Singh C, 2012, DIGIT SIGNAL PROCESS, V22, P1031, DOI 10.1016/j.dsp.2012.06.009
   Singh C, 2012, OPT LASER ENG, V50, P655, DOI 10.1016/j.optlaseng.2011.11.012
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Suk T, 2003, PATTERN RECOGN, V36, P2895, DOI 10.1016/S0031-3203(03)00187-0
   Suk T, 2011, LECT NOTES COMPUT SC, V6855, P212, DOI 10.1007/978-3-642-23678-5_24
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Wu HY, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/813606
   Xiao B, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.2.023002
   Xuan Guo, 1993, Computer Analysis of Images and Patterns. 5th International Conference, CAIP '93 Proceedings, P518
   Yang B, 2015, PATTERN RECOGN LETT, V54, P18, DOI 10.1016/j.patrec.2014.11.014
   Yang B, 2011, SIGNAL PROCESS, V91, P2290, DOI 10.1016/j.sigpro.2011.04.012
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
   Zhang YI, 2002, PATTERN RECOGN, V35, P211, DOI 10.1016/S0031-3203(01)00018-8
   Zhou J, 2005, LECT NOTES COMPUT SC, V3656, P524, DOI 10.1007/11559573_65
   Zhu HQ, 2007, PATTERN RECOGN LETT, V28, P1688, DOI 10.1016/j.patrec.2007.04.013
   Zhu HQ, 2007, PATTERN RECOGN, V40, P2530, DOI 10.1016/j.patcog.2006.12.003
   Zhu HQ, 2007, SIGNAL PROCESS, V87, P687, DOI 10.1016/j.sigpro.2006.07.007
NR 67
TC 6
Z9 6
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 18883
EP 18907
DI 10.1007/s11042-020-08654-7
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000558544500002
DA 2024-07-18
ER

PT J
AU Liu, YS
   Zhu, L
   Liu, F
AF Liu, Yansong
   Zhu, Li
   Liu, Feng
TI Design of Multimedia Education Network Security and Intrusion Detection
   System
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Prefixspan; Multimedia; Security; Intrusion detection; System control
ID MACHINE; ENSEMBLE
AB The existing multimedia wireless network security detection technology cannot meet the requirements of wireless network security detection. Therefore, based on the special security requirements of multimedia wireless networks, this paper constructed a multimedia wireless network security detection system that meets the actual situation of the organization. The system was designed using the B/S architecture and used Django as the framework for system development. The system presentation layer mainly presents the system page to the user and passes the user request. Simultaneously, in this paper, the application of PrefixSpan algorithm in anomaly detection was studied and experimental analysis was carried out. The experimental results are in line with expectations. This verifies the effectiveness of the proposed system and provides a theoretical reference for subsequent related research.
C1 [Liu, Yansong; Zhu, Li; Liu, Feng] Xi An Jiao Tong Univ, Xian 710049, Peoples R China.
   [Liu, Yansong] Shandong Management Univ, Jinan 250100, Peoples R China.
C3 Xi'an Jiaotong University; Shandong Management University
RP Zhu, L (corresponding author), Xi An Jiao Tong Univ, Xian 710049, Peoples R China.
EM liuyansongedu@126.com
CR Aburomman AA, 2017, COMPUT SECUR, V65, P135, DOI 10.1016/j.cose.2016.11.004
   Agrawal N, 2017, INT J WIREL INF NETW, V24, P14, DOI 10.1007/s10776-016-0330-3
   Al-Yaseen WL, 2017, EXPERT SYST APPL, V67, P296, DOI 10.1016/j.eswa.2016.09.041
   [Anonymous], ARCHAEOBOTANY, DOI DOI 10.1007/S00334-017-0661-8
   Baykara M, 2018, J INF SECUR APPL, V41, P103, DOI 10.1016/j.jisa.2018.06.004
   Ganesh S.S., 2017, J COMPUT THEOR NANOS, V14, P4249, DOI [10.1166/jctn.2017.6727, DOI 10.1166/JCTN.2017.6727]
   Haider W, 2017, J NETW COMPUT APPL, V87, P185, DOI 10.1016/j.jnca.2017.03.018
   Hajisalem V, 2018, COMPUT NETW, V136, P37, DOI 10.1016/j.comnet.2018.02.028
   Harang R, 2017, IEEE T INF FOREN SEC, V12, P2348, DOI 10.1109/TIFS.2017.2705629
   Idhammad M, 2018, PROCEDIA COMPUT SCI, V127, P35, DOI 10.1016/j.procs.2018.01.095
   Kakihata EM, 2017, IEEE LAT AM T, V15, P1988, DOI 10.1109/TLA.2017.8071245
   Li P, 2017, CHINESE J ELECTRON, V26, P675, DOI 10.1049/cje.2017.03.011
   Lin CH, 2014, IEEE T SYST MAN CY-S, V44, P705, DOI 10.1109/TSMC.2013.2277691
   Martea PF, 2019, IEEE T INF FOREN SEC, V14, P994, DOI 10.1109/TIFS.2018.2868614
   Mehmood A, 2020, IEEE T EMERG TOP COM, V8, P106, DOI 10.1109/TETC.2017.2671847
   Sultana Nasrin, 2019, Peer-to-Peer Networking and Applications, V12, P493, DOI 10.1007/s12083-017-0630-0
   Tama BA, 2017, IEICE T INF SYST, VE100D, P1729, DOI 10.1587/transinf.2016ICP0018
   Vespa L, 2011, COMPUT J, V54, P285, DOI 10.1093/comjnl/bxq077
   Zhou CJ, 2015, IEEE T SYST MAN CY-S, V45, P1345, DOI 10.1109/TSMC.2015.2415763
   Zu XS, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030514
NR 20
TC 5
Z9 5
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18801
EP 18814
DI 10.1007/s11042-020-08724-w
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000587677800068
DA 2024-07-18
ER

PT J
AU Lu, YQ
   Liu, JJ
   Liu, W
   Ma, SW
   Xiu, XC
   Liu, WQ
   Chen, H
AF Lu, Yuqiu
   Liu, Jingjing
   Liu, Wang
   Ma, Shiwei
   Xiu, Xianchao
   Liu, Wanquan
   Chen, Hui
TI Detecting moving objects from dynamic background combining subspace
   learning with mixed norm approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Moving objects detection; Subspace learning; Mixed norm; ADMM
AB Detecting moving objects from the video is an important research topic in computer vision. In this paper, we first review some traditional methods for moving objects detection. Then, some related preliminaries about the subspace learning and the mixed norm are introduced due to their remarkable advantages shown in signal processing. Combing the mixed norm and the total variation, an effective regularized framework is proposed to achieve more pure foreground. Furthermore, by introducing the subspace learning, the model has lower computational complexity. An efficient method based on the alternating direction method of multipliers (ADMM) is then developed to deal with the proposed constrained minimization problem. Extensive experiments on the private and real-world datasets show that the proposed approach outperforms the existing state-of-the-art approaches, particularly for the cases with dynamic background, which indicates the worth to integrate the subspace learning, the l(2,1) mixed norm and total variation into a low-rank representation model.
C1 [Lu, Yuqiu; Liu, Wang; Ma, Shiwei] Shanghai Univ, Sch Mechatron Engn & Automat, Shanghai, Peoples R China.
   [Liu, Jingjing] Fudan Univ, Sch Microelect, Shanghai, Peoples R China.
   [Xiu, Xianchao] Beijing Jiaotong Univ, Beijing, Peoples R China.
   [Liu, Wanquan] Curtin Univ, Dept Comp, Perth, WA, Australia.
   [Liu, Jingjing; Chen, Hui] Shanghai Univ Elect Power, Shanghai, Peoples R China.
C3 Shanghai University; Fudan University; Beijing Jiaotong University;
   Curtin University; Shanghai University of Electric Power
RP Ma, SW (corresponding author), Shanghai Univ, Sch Mechatron Engn & Automat, Shanghai, Peoples R China.
EM masw@shu.edu.cn
RI Zhao, YuHan/KIE-0813-2024; Hui, .Chen/AER-3973-2022; Huang,
   Liping/KIB-4430-2024
OI Hui, .Chen/0000-0002-5386-4078; Ma, Shiwei/0000-0001-6039-5030
CR [Anonymous], 2009, NEURAL INFORM PROCES
   [Anonymous], 2001, COMP SCI W
   [Anonymous], 2014, P 31 INT C MACH LEAR
   Aybat NS, 2013, ARXIV13096553
   [包金宇 Bao Jinyu], 2013, [计算机应用, Journal of Computer Applications], V33, P1401
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250
   Boyd S, 2011, TRENDS MACH LEARN, V3, P1, DOI DOI 10.1561/2200000016
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1014, DOI 10.1109/TCYB.2015.2419737
   Cheng J, 2005, LECT NOTES COMPUT SC, V3522, P587
   Ding XH, 2011, IEEE T IMAGE PROCESS, V20, P3419, DOI 10.1109/TIP.2011.2156801
   Gao Z, 2014, IEEE T PATTERN ANAL, V36, P1975, DOI 10.1109/TPAMI.2014.2314663
   Guyon C, 2012, IEEE IMAGE PROC, P1225, DOI 10.1109/ICIP.2012.6467087
   He J, 2012, PROC CVPR IEEE, P1568, DOI 10.1109/CVPR.2012.6247848
   Hong MY, 2016, SIAM J OPTIMIZ, V26, P337, DOI 10.1137/140990309
   Javed S, 2019, IEEE T IMAGE PROCESS, V28, P1007, DOI 10.1109/TIP.2018.2874289
   Kang Z, 2015, IEEE INT C DAT MIN I
   Kowalski M., 2009, Proc. of Int. Conference on Machine Learning, V382, P545
   Kowalski M, 2009, APPL COMPUT HARMON A, V27, P303, DOI 10.1016/j.acha.2009.05.006
   Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Shu X, 2014, 2014 IEEE C COMP VIS
   Sobral A, 2015, IEEE INT C COMP VIS
   Wang FH, 2018, SCI CHINA INFORM SCI, V61, DOI 10.1007/s11432-017-9367-6
   Wang NY, 2012, LECT NOTES COMPUT SC, V7578, P126, DOI 10.1007/978-3-642-33786-4_10
   Xu J, 2013, IEEE I CONF COMP VIS, P3376, DOI 10.1109/ICCV.2013.419
   Yang LS, 2016, EUR J INFLAMM, V14, P10, DOI 10.1177/1721727X16638667
   Ye X., 2015, IEEE TCSVT, V25, P1
   Yi X, 2016, ARXIV160507784CSIT
   Zhou T., P 28 INT C MACH LEAR
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
   Zhou ZH, 2010, IEEE INT SYMP INFO, P1518, DOI 10.1109/ISIT.2010.5513535
   [周宗伟 Zhou Zongwei], 2015, [中国图象图形学报, Journal of Image and Graphics], V20, P1482
   Zhu LG, 2019, IRONMAK STEELMAK, V46, P499, DOI 10.1080/03019233.2017.1405153
NR 36
TC 3
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18747
EP 18766
DI 10.1007/s11042-020-08779-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000587677800066
DA 2024-07-18
ER

PT J
AU Lin, YN
   Hsieh, TY
   Huang, JJ
   Yang, CY
   Shen, VRL
   Bui, HH
AF Lin, Yi-Nan
   Hsieh, Tsang-Yen
   Huang, Jr-Jen
   Yang, Cheng-Ying
   Shen, Victor R. L.
   Bui, Hai Hoang
TI Fast Iris localization using Haar-like features and AdaBoost algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Iris localization; Haar-like features; AdaBoost
   algorithm; Cascade classifier
ID RECOGNITION; FRAMEWORK; TRACKING; BEHAVIOR; CASCADE; SYSTEM
AB Traditional iris recognition methods, which are still preferred against artificial intelligence (AI) approaches in practical applications, are often required to capture high-grade iris samples by an iris scanner for accurate subsequent processing. To reduce the system cost for mass deployment of iris recognition, pricey scan devices can be replaced by the average quality cameras combined with additional processing algorithm. In this paper, we propose a Haar-like-feature-based iris localization method to quickly detect the location of human iris in the images captured by low-cost cameras for the ease of post-processing stages. The AdaBoost algorithm was chosen as a learning method for training a cascade classifier using Haar-like features, which was then utilized to detect the iris position. The experimental results have shown acceptable accuracy and processing speed for this novel cascade classifier. This achievement stimulates us to implement this novel capturing device in our iris recognition.
C1 [Lin, Yi-Nan; Hsieh, Tsang-Yen; Huang, Jr-Jen; Bui, Hai Hoang] Ming Chi Univ Technol, Dept Elect Engn, 84 Gongzhuan Rd, New Taipei 243, Taiwan.
   [Yang, Cheng-Ying] Univ Taipei, Dept Comp Sci, 1 Ai Kao W Rd, Taipei 100, Taiwan.
   [Shen, Victor R. L.] Natl Taipei Univ, Dept Comp Sci & Informat Engn, 151 Univ Rd, New Taipei 237, Taiwan.
   [Shen, Victor R. L.] Chaoyang Univ Technol, Dept Informat Management, 168 Jifeng E Rd, Taichung 413, Taiwan.
C3 Ming Chi University of Technology; University of Taipei; National Taipei
   University; Chaoyang University of Technology
RP Shen, VRL (corresponding author), Natl Taipei Univ, Dept Comp Sci & Informat Engn, 151 Univ Rd, New Taipei 237, Taiwan.; Shen, VRL (corresponding author), Chaoyang Univ Technol, Dept Informat Management, 168 Jifeng E Rd, Taichung 413, Taiwan.
EM jnlin@mail.mcut.edu.tw; tyhsieh@mail.mcut.edu.tw;
   jrjen@mail.mcut.edu.tw; cyang@utaipei.edu.tw; rlshen@mail.ntpu.edu.tw;
   hoanghai1246.hust@gmail.com
RI Lin, Yi-Nan/B-4986-2009
FU Ministry of Science and Technology, Taiwan [MOST 107-2221-E-845-001-MY3,
   MOST 107-2221-E-845-002-MY3]
FX The authors are very grateful to the anonymous reviewers for their
   constructive comments which have improved the quality of this paper.
   Also, this work was supported by the Ministry of Science and Technology,
   Taiwan, under grant MOST 107-2221-E-845-001-MY3 and MOST
   107-2221-E-845-002-MY3.
CR Attaran N, 2018, IEEE T CIRCUITS-II, V65, P2032, DOI 10.1109/TCSII.2018.2799821
   Baek SJ, 2013, IEEE T CONSUM ELECTR, V59, P415, DOI 10.1109/TCE.2013.6531125
   Burghardt T, 2006, IEE P-VIS IMAGE SIGN, V153, P305, DOI 10.1049/ip-vis:20050052
   Dasgupta A, 2013, IEEE T INTELL TRANSP, V14, P1825, DOI 10.1109/TITS.2013.2271052
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Daugman J, 2007, IEEE T SYST MAN CY B, V37, P1167, DOI 10.1109/TSMCB.2007.903540
   Dong YC, 2016, MULTIMED TOOLS APPL, V75, P11763, DOI 10.1007/s11042-015-2635-0
   Ge JF, 2009, IEEE T INTELL TRANSP, V10, P283, DOI 10.1109/TITS.2009.2018961
   Genovese M, 2014, IEEE T VLSI SYST, V22, P537, DOI 10.1109/TVLSI.2013.2249295
   Gualdi G, 2012, IEEE T PATTERN ANAL, V34, P1589, DOI 10.1109/TPAMI.2011.247
   Han YL, 2015, IET IMAGE PROCESS, V9, P405, DOI 10.1049/iet-ipr.2014.0496
   He ZF, 2009, IEEE T PATTERN ANAL, V31, P1670, DOI 10.1109/TPAMI.2008.183
   Hiromoto M, 2009, IEEE T CIRC SYST VID, V19, P41, DOI 10.1109/TCSVT.2008.2009253
   Ke RM, 2019, IEEE T INTELL TRANSP, V20, P54, DOI 10.1109/TITS.2018.2797697
   Kim S, 2012, IEEE T CONSUM ELECTR, V58, P685, DOI 10.1109/TCE.2012.6227477
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Luo AW, 2019, IEEE ACCESS, V7, P14472, DOI 10.1109/ACCESS.2019.2894169
   Ma Z, 2019, IEEE INTERNET THINGS, V6, P5778, DOI 10.1109/JIOT.2019.2905555
   Mammeri A, 2016, IEEE T SYST MAN CY-S, V46, P1287, DOI 10.1109/TSMC.2015.2497235
   Morra JH, 2010, IEEE T MED IMAGING, V29, P30, DOI 10.1109/TMI.2009.2021941
   Paisitkriangkcrai S, 2008, IEEE T CIRC SYST VID, V18, P1140, DOI 10.1109/TCSVT.2008.928213
   Prioletti A, 2013, IEEE T INTELL TRANSP, V14, P1346, DOI 10.1109/TITS.2013.2262045
   Rezaei M, 2015, IEEE T INTELL TRANSP, V16, P2723, DOI 10.1109/TITS.2015.2421482
   Rezaei M, 2011, INT J IMAGE DATA FUS, V2, P217, DOI 10.1080/19479832.2011.590458
   Song ML, 2010, IEEE T SYST MAN CY B, V40, P1460, DOI 10.1109/TSMCB.2010.2040078
   Tan CW, 2012, IEEE T IMAGE PROCESS, V21, P4068, DOI 10.1109/TIP.2012.2199125
   Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang SZ, 2007, IEEE T INF FOREN SEC, V2, P267, DOI 10.1109/TIFS.2007.897251
   Wang Z, 2018, IEEE ACCESS, V6, P17905, DOI 10.1109/ACCESS.2018.2812208
   Wen XZ, 2015, IEEE T CIRC SYST VID, V25, P508, DOI 10.1109/TCSVT.2014.2358031
   Xiang XZ, 2017, IEEE SENS J, V17, P6360, DOI 10.1109/JSEN.2017.2741722
   Xu JS, 2012, IEEE SIGNAL PROC LET, V19, P676, DOI 10.1109/LSP.2012.2210870
   Yu Y, 2018, IEEE ACCESS, V6, P71122, DOI 10.1109/ACCESS.2018.2881479
   Yuan FN, 2015, IET IMAGE PROCESS, V9, P849, DOI 10.1049/iet-ipr.2014.1032
   Zhang WW, 2011, IEEE T IMAGE PROCESS, V20, P1696, DOI 10.1109/TIP.2010.2099126
NR 36
TC 14
Z9 14
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34339
EP 34362
DI 10.1007/s11042-020-08907-5
EA JUN 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000539519200001
DA 2024-07-18
ER

PT J
AU Xiao, L
   Mei, G
   Cuomo, S
   Xu, NX
AF Xiao, Lei
   Mei, Gang
   Cuomo, Salvatore
   Xu, Nengxiong
TI Comparative investigation of GPU-accelerated triangle-triangle
   intersection algorithms for collision detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Collision detection; Triangle-triangle intersection; Graphics processing
   unit; Parallel algorithm
AB Efficient collision detection is critical in 3D geometric modeling. In this paper, we first implement three parallel triangle-triangle intersection algorithms on a GPU and then compare the computational efficiency of these three GPU-accelerated parallel triangle-triangle intersection algorithms in an application that detects collisions between triangulated models. The presented GPU-based parallel collision detection method for triangulated models has two stages: first, we propose a straightforward and efficient parallel approach to reduce the number of potentially intersecting triangle pairs based on AABBs, and second, we conduct intersection tests with the remaining triangle pairs in parallel based on three triangle-triangle intersection algorithms, i.e., the Moller's algorithm, Devillers' and Guigue's algorithm, and Shen's algorithm. To evaluate the performance of the presented GPU-based parallel collision detection method for triangulated models, we conduct four groups of benchmarks. The experimental results show the following: (1) the time required to detect collisions for the triangulated model consisting of approximately 1.5 billion triangle pairs is less than 0.5 s; (2) the GPU-based parallel collision detection method speedup over the corresponding serial version is 50x - 60x, and (3) Devillers' and Guigue's algorithm is comparatively and comprehensively the best of the three GPU-based parallel triangle-triangle intersection algorithms. The presented GPU-accelerated method is capable of efficiently detecting the potential collisions of triangulated models. Overall, the GPU-accelerated parallel Devillers' and Guigue's triangle-triangle intersection algorithm is recommended when performing practical collision detections between large triangulated models.
C1 [Xiao, Lei; Mei, Gang; Xu, Nengxiong] China Univ Geosci, Sch Engn & Technolgy, Beijing, Peoples R China.
   [Cuomo, Salvatore] Univ Naples Federico II, Dept Math & Applicat R Caccioppoli, Naples, Italy.
C3 University of Naples Federico II
RP Mei, G (corresponding author), China Univ Geosci, Sch Engn & Technolgy, Beijing, Peoples R China.
EM gang.mei@cugb.edu.cn; salvatore.cuomo@unina.it; xunengxiong@cugb.edu.cn
RI Xu, Nengxiong/AAC-1881-2022; Cuomo, Salvatore/Q-1365-2016; Mei,
   Gang/C-9124-2016
OI Cuomo, Salvatore/0000-0003-4128-2588; Mei, Gang/0000-0003-0026-5423
FU National Natural Science Foundation of China [11602235, 41772326];
   Fundamental Research Funds for China Central Universities [2652018091,
   2652018107, 2652-018109]
FX This research was jointly supported by the National Natural Science
   Foundation of China (Grant Numbers: 11602235 and 41772326), and the
   Fundamental Research Funds for China Central Universities (Grant
   Numbers: 2652018091, 2652018107 and 2652-018109). The authors would like
   to thank the editor and the reviewers for their contributions.
CR Devillers O., 2002, FASTER TRIANGLE TRIA
   Fan WS, 2013, SCI CHINA INFORM SCI, V56, DOI 10.1007/s11432-012-4616-5
   Fan WS, 2011, COMPUT GRAPH FORUM, V30, P1451, DOI 10.1111/j.1467-8659.2011.02019.x
   Giles MB, 2013, J PARALLEL DISTR COM, V73, P1451, DOI 10.1016/j.jpdc.2012.07.008
   Guigue P., 2003, Journal of Graphics Tools, V8, P25
   Hao Shen, 2003, Journal of Graphics Tools, V8, P17
   Held M., 1997, Journal of Graphics Tools, V2, P25, DOI 10.1080/10867651.1997.10487482
   Hendrich J, 2017, COMPUT GRAPH FORUM, V36, P487, DOI 10.1111/cgf.13143
   Laccetti G, 2016, INT J PARALLEL PROG, V44, P901, DOI 10.1007/s10766-015-0398-x
   Lee Y, 2010, COMPUT ANIMAT VIRT W, V21, P365, DOI 10.1002/cav.359
   Mazhar H, 2011, MULTIBODY SYST DYN, V26, P37, DOI 10.1007/s11044-011-9246-y
   Mei G., 2014, SCI WORLD J
   Mei G, 2020, IEEE INTERNET THINGS, V7, P4371, DOI 10.1109/JIOT.2019.2952593
   Mei G, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-1731-6
   Moller T., 1997, J. Graph. Tools, V2, P25, DOI [DOI 10.1080/10867651.1997.10487472, 10.1080/10867651.1997.10487472]
   Montella R, 2019, FUTURE GENER COMP SY, V94, P103, DOI 10.1016/j.future.2018.11.025
   Montella R, 2017, INT J PARALLEL PROG, V45, P1142, DOI 10.1007/s10766-016-0462-1
   Montella R, 2015, CONCURR COMP-PRACT E, V27, P4423, DOI 10.1002/cpe.3540
   NVIDIA, 2019, CUDA PROGR GUID
   Pan J., 2011, Proceedings of the 19th ACM SIGSPATIAL Interna- tional Conference on Advances in Geographic Information Systems, P211
   Pei SW, 2016, IEEE EMBED SYST LETT, V8, P26, DOI 10.1109/LES.2016.2519521
   Piccialli F, 2019, J AMBIENT INTELLIGEN
   Platt TM, 2018, REDUCING TEST TIME F, P1
   Qi WB, 2019, IEEE T SMART GRID, V10, P762, DOI 10.1109/TSG.2017.2751756
   Qi X, 2017, KEY FRAME ANAL FACE, P682
   Songwen Pei, 2018, International Journal of High Performance Computing and Networking, V12, P261
   Thompson E, 2015, J SUPERCOMPUT, V71, P3787, DOI 10.1007/s11227-015-1467-z
   Tropp O, 2006, COMPUT ANIMAT VIRT W, V17, P527, DOI 10.1002/cav.115
   Vigueras G, 2014, INT J HIGH PERFORM C, V28, P33, DOI 10.1177/1094342013476119
   Wang XL, 2018, COMPUT GRAPH FORUM, V37, P227, DOI 10.1111/cgf.13356
   Weller R, 2017, COMPUT GRAPH FORUM, V36, P131, DOI 10.1111/cgf.13113
   Wong TH, 2014, VISUAL COMPUT, V30, P729, DOI 10.1007/s00371-014-0954-1
   Ye XF, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P2689, DOI 10.1109/ICInfA.2015.7279740
   Yong BB, 2017, CLUSTER COMPUT, V20, P2591, DOI 10.1007/s10586-017-0741-7
   Zhang X., 2019, J. Phys. Conf. Ser, V1213, P042079, DOI [10.1088/1742-6596/1213/4/042079, DOI 10.1088/1742-6596/1213/4/042079]
   Zhang XY, 2007, IEEE T VIS COMPUT GR, V13, P318, DOI 10.1109/TVCG.2007.42
   Zhao W, 2010, LECT NOTES COMPUT SC, V6249, P610, DOI 10.1007/978-3-642-14533-9_62
   Zheng W, 2020, PHYS PROCEDIA, V33
NR 38
TC 5
Z9 5
U1 2
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3165
EP 3180
DI 10.1007/s11042-020-09066-3
EA JUN 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000538712600002
DA 2024-07-18
ER

PT J
AU Joo, HJ
   Jeong, HY
AF Joo, Hae-Jong
   Jeong, Hwa-Young
TI A study on eye-tracking-based Interface for VR/AR education platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality; Augmented reality; VR; AR education; VR; AR user
   Interface; Eye tracking
ID SYSTEM; VR; PROTOTYPE; AR
AB In recent years, a platform providing a Visual Programming development environment capable of 3D editing and interaction editing in an In-VR environment to quickly prototype VR/AR contents for education of VR and AR for general users and children. In the past, VR contents were mostly viewed by users. However, thanks to the rapid development of recent computing technologies, VR contents interacting with users have emerged as a device capable of tracking user behavior in a small size It was able to appear. In addition, because VR is extended to AR and MR, it can be used in all three virtual environments and requires efficient user interface (UI). In this paper, we propose UI based on eye tracking. Eye-tracking-based UI not only reduces the amount of time the user directly manipulates the controller, but also dramatically lowers the time spent on simple operations, while reducing the need for a dedicated controller by allowing multiple types of controllers to be used in combination.
C1 [Joo, Hae-Jong] Dongguk Univ, Dept Comp Sci & Engn, Seoul, South Korea.
   [Jeong, Hwa-Young] Kyung Hee Univ, Humanitas Coll, Seoul, South Korea.
C3 Dongguk University; Kyung Hee University
RP Jeong, HY (corresponding author), Kyung Hee Univ, Humanitas Coll, Seoul, South Korea.
EM hjjoo@dongguk.edu; hyjeong@khu.ac.kr
OI Jeong, Hwa-Young/0000-0002-5017-934X
CR Alam MF, 2017, J NETW COMPUT APPL, V89, P109, DOI 10.1016/j.jnca.2017.03.022
   Boemer F, 2019, ACM INT C COMP FRONT, V2019, P1
   Carlson WE, 2017, CRITICAL HIST COMPUT
   Chen T, 2018, P C SYST MACH LEARN
   CRANE HD, 1985, APPL OPTICS, V24, P527, DOI 10.1364/AO.24.000527
   Cyphers Scott, 2018, Intel ngraph: An intermediate representation, compiler, and executor for deep learning
   Dacko SG, 2017, TECHNOL FORECAST SOC, V124, P243, DOI 10.1016/j.techfore.2016.09.032
   Farshid M, 2018, BUS HORIZONS, V61, P657, DOI 10.1016/j.bushor.2018.05.009
   Gallo L, 2010, COMPUT BIOL MED, V40, P350, DOI 10.1016/j.compbiomed.2010.01.006
   Perez-Schofield BG, 2019, SCI COMPUT PROGRAM, V176, P1, DOI 10.1016/j.scico.2019.02.004
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Huang HH, 2019, J VIS COMMUN IMAGE R, V60, P28, DOI 10.1016/j.jvcir.2019.01.007
   Huey EB, 1968, PSYCHOL PEDAGOGY REA, P469
   Lattner C, 2004, CGO 04 P INT S COD G
   Li X, 2018, AUTOMAT CONSTR, V86, P150, DOI 10.1016/j.autcon.2017.11.003
   Liu DW, 2019, ENVIRON MODELL SOFTW, V114, P188, DOI 10.1016/j.envsoft.2019.01.019
   Mylonas G, 2019, ELECTRON NOTES THEOR, V343, P89, DOI 10.1016/j.entcs.2019.04.012
   Pagés R, 2018, J VIS COMMUN IMAGE R, V53, P192, DOI 10.1016/j.jvcir.2018.03.012
   Perovsek M, 2016, SCI COMPUT PROGRAM, V121, P128, DOI 10.1016/j.scico.2016.01.001
   Rauschnabel PA, 2019, J RETAIL CONSUM SERV, V49, P43, DOI 10.1016/j.jretconser.2019.03.004
   ROBINSON DA, 1963, IEEE T BIO-MED ENG, VBM10, P137, DOI 10.1109/TBMEL.1963.4322822
   Shi YL, 2018, PROC CIRP, V78, P115, DOI 10.1016/j.procir.2018.08.311
   Song H, 2016, PROC CIRP, V56, P13, DOI 10.1016/j.procir.2016.10.008
   Sun CY, 2019, J COMPUT DES ENG, V6, P189, DOI 10.1016/j.jcde.2018.05.006
   Swider M, 2019, IOS 12 RELEASE DATE
   Wakefield C, 2001, MICROSOFT NET FRAMEW, P33
   Wang C, 2011, PROCEDIA ENVIRON SCI, V10, P313, DOI 10.1016/j.proenv.2011.09.051
   Wei R, 2018, 6 INT C LEARN ICLR 2, P1
   Xia JY, 2018, FUSION ENG DES, V127, P267, DOI 10.1016/j.fusengdes.2018.01.024
   Yasui Y, 2019, J PROSTHODONT RES, V63, P210, DOI 10.1016/j.jpor.2018.11.011
   Zakai Zakai A A, 2011, P ACM INT C COMPANIO, DOI DOI 10.1145/2048147.2048224
   Zhao J, 2012, ACM SIGPLAN NOTICES, V47
NR 32
TC 6
Z9 6
U1 24
U2 156
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16719
EP 16730
DI 10.1007/s11042-019-08327-0
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600051
DA 2024-07-18
ER

PT J
AU Son, NTK
   Dong, NP
   Son, L
   Long, HV
AF Nguyen Thi Kim Son
   Nguyen Phuong Dong
   Le Hoang Son
   Hoang Viet Long
TI Towards granular calculus of single-valued neutrosophic functions under
   granular computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Triangular neutrosophic numbers; Horizontal membership functions;
   Granular computing; Single-valued neutrosophic functions
ID AGGREGATION OPERATORS; SETS; DIFFERENTIABILITY; ALGORITHM
AB Neutrosophic theory studies objects whose values vary in the sets of elements and are not true or false, but in between, that can be called by neutral, indeterminate, unclear, vague, ambiguous, incomplete or contradictory quantities. In this paper, we firstly introduce preliminaries on granular calculus and analysis related to single-valued neutrosophic functions. Based on horizontal membership functions approach, we establish some basic arithmetic operations of single-valued neutrosophic numbers, that red allow us to directly introduce the terms of neutrosophic function in usual mathematical formulas. Additionally, we build metrics on the space of single-valued neutrosophic numbers induced from Hamming distance. Then, we define some backgrounds on the limit, derivative and integral of single-valued neutrosophic functions. Finally, in order to demonstrate the usable of our theoretical results, we present some applications to well-known problems arising in engineering such as logistic model, the inverted pendulum system, Mass - Spring - Damper model.
C1 [Nguyen Thi Kim Son] Hanoi Metropolitan Univ, Fac Nat Sci, Hanoi, Vietnam.
   [Nguyen Phuong Dong] Hanoi Pedag Univ 2, Dept Math, Hanoi, Vietnam.
   [Le Hoang Son] Vietnam Natl Univ, VNU Informat Technol Inst, Hanoi, Vietnam.
   [Hoang Viet Long] Ton Duc Thang Univ, Inst Computat Sci, Div Computat Math & Engn, Ho Chi Minh City, Vietnam.
   [Hoang Viet Long] Ton Duc Thang Univ, Fac Math & Stat, Ho Chi Minh City, Vietnam.
C3 Hanoi Pedagogical University 2 (HPU2); Vietnam National University
   Hanoi; Ton Duc Thang University; Ton Duc Thang University
RP Long, HV (corresponding author), Ton Duc Thang Univ, Inst Computat Sci, Div Computat Math & Engn, Ho Chi Minh City, Vietnam.; Long, HV (corresponding author), Ton Duc Thang Univ, Fac Math & Stat, Ho Chi Minh City, Vietnam.
EM ntkson@daihocthudo.edu.vn; nguyenphuongdong@hpu2.edu.vn;
   sonlh@vnu.edu.vn; hoangvietlong@tdtu.edu.vn
RI Long, Hoang Viet/O-7699-2019; Hoang, Long Viet/L-9114-2016; Dong, Nguyen
   Phuong/GPC-7719-2022
OI Long, Hoang Viet/0000-0001-6657-0653; Hoang, Long
   Viet/0000-0001-6657-0653; Dong, Nguyen Phuong/0000-0002-5709-3733; Hoang
   Son, Le/0000-0001-6356-0046
CR Ali M, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10100510
   Ali M, 2018, APPL SOFT COMPUT, V71, P1054, DOI 10.1016/j.asoc.2017.10.012
   Ali M, 2017, J INTELL FUZZY SYST, V33, P4077, DOI 10.3233/JIFS-17999
   Amal L, 2018, ENVIRON SCI POLLUT R, V25, P27569, DOI 10.1007/s11356-018-2826-0
   [Anonymous], 1996, FUZZY LOGIC FOUND IN
   Atanassov K., 2017, Intuitionistic Fuzzy LOGICS
   Atanassov KT, 2012, STUD FUZZ SOFT COMP, V283, P1, DOI 10.1007/978-3-642-29127-2
   ATANASSOV KT, 1986, FUZZY SET SYST, V20, P87, DOI 10.1016/S0165-0114(86)80034-3
   Bede B, 2005, FUZZY SET SYST, V151, P581, DOI 10.1016/j.fss.2004.08.001
   Bede B, 2013, STUD FUZZ SOFT COMP, V295, P1, DOI 10.1007/978-3-642-35221-8
   Bede B, 2013, FUZZY SET SYST, V230, P119, DOI 10.1016/j.fss.2012.10.003
   Broumi S, 2017, NEUTROSOPHIC SETS SY, V17, P42
   Broumi S, 2017, NEUTROSOPHIC SETS SY, V18, P58
   Çevik A, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10110643
   Çevik A, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10110656
   Chakraborty A., 2018, ISME J, V8, P1
   Chalapathi T, 2018, NEUTROSOPHIC SETS SY, V21, P5
   CHANG SSL, 1972, IEEE T SYST MAN CYB, VSMC2, P30, DOI 10.1109/TSMC.1972.5408553
   Dey A, 2019, SYMMETRY, V10, P373
   Dey A, 2019, GRANULAR COMPUT, V4, P63, DOI 10.1007/s41066-018-0084-7
   Doss S, 2018, IEEE ACCESS, V6, P56954, DOI 10.1109/ACCESS.2018.2868544
   DUBOIS D, 1982, FUZZY SET SYST, V8, P225, DOI 10.1016/S0165-0114(82)80001-8
   Nguyen GN, 2019, INT J MACH LEARN CYB, V10, P1, DOI 10.1007/s13042-017-0691-7
   GOETSCHEL R, 1986, FUZZY SET SYST, V18, P31, DOI 10.1016/0165-0114(86)90026-6
   Jha S, 2019, EVOL SYST-GER, V10, P621, DOI 10.1007/s12530-018-9247-7
   Jiang W, 2018, INT J SYST SCI, V49, P582, DOI 10.1080/00207721.2017.1411989
   Joshi DK, 2018, MATHEMATICS-BASEL, V6, DOI 10.3390/math6040047
   Khan M, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10080314
   Son LH, 2019, APPL INTELL, V49, P172, DOI 10.1007/s10489-018-1262-7
   Son LH, 2017, ENG APPL ARTIF INTEL, V59, P186, DOI 10.1016/j.engappai.2017.01.003
   Son LH, 2016, EXPERT SYST APPL, V46, P380, DOI 10.1016/j.eswa.2015.11.001
   Le T, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10070250
   Majumdar P, COMPUTATIONAL INTELL, V19
   Mazandarani M, 2018, J FRANKLIN I, V355, P4931, DOI 10.1016/j.jfranklin.2018.05.022
   Mazandarani M, 2018, ISA T, V76, P1, DOI 10.1016/j.isatra.2018.02.001
   Mazandarani M, 2018, IEEE T FUZZY SYST, V26, P310, DOI 10.1109/TFUZZ.2017.2659731
   Thanh ND, 2017, COGN COMPUT, V9, P526, DOI 10.1007/s12559-017-9462-8
   Thinh NT, 2017, INT CONF SYST SCI EN, P1, DOI 10.1109/ICSSE.2017.8030825
   Thao NX, 2018, ADV INTELL SYST, V672, P834, DOI 10.1007/978-981-10-7512-4_82
   Peng JJ, 2017, INT J SYST SCI, V48, P425, DOI 10.1080/00207721.2016.1218975
   Peng JJ, 2016, INT J SYST SCI, V47, P2342, DOI 10.1080/00207721.2014.994050
   Peng JJ, 2015, INT J COMPUT INT SYS, V8, P345, DOI 10.1080/18756891.2015.1001957
   Piegat A, 2018, GRANULAR COMPUT, V3, P39, DOI 10.1007/s41066-017-0054-5
   Piegat A, 2017, STUD COMPUT INTELL, V683, P233, DOI 10.1007/978-3-319-51052-1_14
   Piegat A, 2016, ADV INTELL SYST, V401, P215, DOI 10.1007/978-3-319-26211-6_18
   PURI ML, 1983, J MATH ANAL APPL, V91, P552, DOI 10.1016/0022-247X(83)90169-5
   Sahin R, 2018, J EXP THEOR ARTIF IN, V30, P279, DOI 10.1080/0952813X.2018.1430857
   Sahin R, 2017, J EXP THEOR ARTIF IN, V29, P769, DOI 10.1080/0952813X.2016.1259266
   SEIKKALA S, 1987, FUZZY SET SYST, V24, P319, DOI 10.1016/0165-0114(87)90030-3
   Smarandache F., 1998, UNIFYING FIELD LOGIC
   Smarandache F., 2014, Introduction to Neutrosophic Statistics
   Smarandache F, 2015, Infinite Study
   Smarandache F., 2013, Introduction to neutrosophic measure, neutrosophic integral, and neutrosophic probability
   Son LH, 2018, KNOWL-BASED SYST, V154, P68, DOI 10.1016/j.knosys.2018.04.038
   Stefanini L, 2009, NONLINEAR ANAL-THEOR, V71, P1311, DOI 10.1016/j.na.2008.12.005
   Tas F, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10100430
   Tian ZP, 2016, INT J SYST SCI, V47, P3598, DOI 10.1080/00207721.2015.1102359
   Tuan TM, 2016, APPL INTELL, V45, P402, DOI 10.1007/s10489-016-0763-5
   Tuan TM, 2019, EVOL SYST-GER, V10, P629, DOI 10.1007/s12530-018-9251-y
   Wang CH, 2016, INTELL AUTOM SOFT CO, V22, P473, DOI 10.1080/10798587.2015.1095418
   Wang H., 2010, Infinite Study
   Ye J, 2020, IEEE T PATTERN ANAL, V42, P126, DOI 10.1109/TPAMI.2018.2874455
   Ye J, 2017, J EXP THEOR ARTIF IN, V29, P731, DOI [10.1080/0952813X.2016.1259263, 10.7495/j.issn.1009-3486.2017.03.001]
   Ye J, 2014, J INTELL SYST, V23, P379, DOI 10.1515/jisys-2013-0091
   Ye J, 2014, J INTELL FUZZY SYST, V27, P2453, DOI 10.3233/IFS-141215
   Ye J, 2014, APPL MATH MODEL, V38, P1170, DOI 10.1016/j.apm.2013.07.020
   Ye J, 2013, INT J GEN SYST, V42, P386, DOI 10.1080/03081079.2012.761609
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
NR 68
TC 26
Z9 26
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16845
EP 16881
DI 10.1007/s11042-019-7388-8
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600058
DA 2024-07-18
ER

PT J
AU Sairam, TD
   Boopathybagan, K
AF Sairam, T. D.
   Boopathybagan, K.
TI An improved high capacity data hiding scheme using pixel value
   adjustment and modulus operation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cover image; Data hiding; Stego image; Exploiting modification metod;
   Pixel value adjustment
AB High data hiding capacity, stego image quality and security are the measures of steganography. Of these three measures, number of bits that can be hidden in a single cover pixel, bits per pixel (bpp), is very important and many researchers are working to improve the bpp. Recently, to enhance the embedding capacity, some of the schemes were proposed which are based on the fixed equation that is used as an extraction function of secret data from the stego image. We propose an improved high capacity data hiding method that maintain the acceptable image quality that is more than 30 dB and improves the embedding capacity higher than that of the methods proposed in recent years. The method proposed in this paper usesn(2) - arynotational system and achieves higher embedding rate of 4 bpp and also maintain the good visual quality.
C1 [Sairam, T. D.] SKR Engn Coll, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
   [Boopathybagan, K.] Anna Univ, Dept Elect Engn, MIT Campus, Chennai, Tamil Nadu, India.
C3 Anna University; Anna University Chennai
RP Sairam, TD (corresponding author), SKR Engn Coll, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
EM rndsairamtd@gmail.com
CR [Anonymous], 2009, International Journal of Signal processing, Image processing and pattern
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], APPL MATH INFORM SCI
   [Anonymous], INT J ELECT COMMUNIC
   [Anonymous], INT J COMPUTER APPL
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Khan A, 2014, INFORM SCIENCES, V279, P251, DOI 10.1016/j.ins.2014.03.118
   Kuo WC, 2013, IMAGING SCI J, V61, P484, DOI 10.1179/1743131X12Y.0000000011
   Kuo WC, 2016, OPTIK, V127, P1762, DOI 10.1016/j.ijleo.2015.08.056
   Kuo WC, 2012, THIRD INTERNATIONAL CONFERENCE ON INFORMATION SECURITY AND INTELLIGENT CONTROL (ISIC 2012), P286, DOI 10.1109/ISIC.2012.6449762
   Lee CF, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P497
   Qiu YQ, 2016, IEEE SIGNAL PROC LET, V23, P130, DOI 10.1109/LSP.2015.2504464
   Shen SY, 2015, COMPUT SECUR, V48, P131, DOI 10.1016/j.cose.2014.07.008
   Tseng HW, 2014, IET IMAGE PROCESS, V8, P647, DOI 10.1049/iet-ipr.2013.0584
   Wu HT, 2015, IEEE SIGNAL PROC LET, V22, P81, DOI 10.1109/LSP.2014.2346989
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 16
TC 13
Z9 13
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 17003
EP 17013
DI 10.1007/s11042-019-7557-9
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600066
DA 2024-07-18
ER

PT J
AU Wang, SH
   Hong, J
   Yang, M
AF Wang, Shui-Hua
   Hong, Jin
   Yang, Ming
TI Sensorineural hearing loss identification via nine-layer convolutional
   neural network with batch normalization and dropout
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sensorineural hearing loss; Data augmentation; Deep learning;
   Convolutional neural network; Confusion matrix; Batch normalization;
   Dropout
ID RECONSTRUCTION
AB Traditional sensorineural hearing loss identification use the framework of feature extraction and classification. Nevertheless, this framework needs manual feature engineering. In this study, we proposed an improved convolutional neural network model to identify hearing loss. Our nine-layer deep convolutional neural network contains six conv layers and three fully-connected layers. We used batch normalization to reduce the impact caused by Internal Covariate shift and dropout techniques to prevent over-fitting to increase the performance in terms of accuracy. Data augmentation was used to enlarge the size of training set. The average results of 10 runs on test set show our method secured sensitivities of left-sided hearing loss, right-sided hearing loss, and healthy controls are 96.33 +/- 2.46%, 96.67 +/- 2.22%, and 96.67 +/- 2.72%, respectively. The overall accuracy of all three classes was 96.56 +/- 0.63%. Deep learning can effectively build the identification model. The performance of our proposed nine-layer convolutional neural network model yields better performance than five state-of-the-art approaches.
C1 [Wang, Shui-Hua] Nanjing Univ, Med Sch, Affiliated Hosp, Dept Rheumatol & Immunol,Nanjing Drum Tower Hosp, Nanjing 210008, Peoples R China.
   [Wang, Shui-Hua] Loughborough Univ, Sch Architecture Bldg & Civil Engn, Loughborough LE11 3TU, Leics, England.
   [Hong, Jin] Sun Yat Sen Univ, Sch Earth Sci & Engn, Guangzhou 510275, Guangdong, Peoples R China.
   [Yang, Ming] Nanjing Med Univ, Childrens Hosp, Dept Radiol, Nanjing 210008, Peoples R China.
C3 Nanjing University; Loughborough University; Sun Yat Sen University;
   Nanjing Medical University
RP Wang, SH (corresponding author), Nanjing Univ, Med Sch, Affiliated Hosp, Dept Rheumatol & Immunol,Nanjing Drum Tower Hosp, Nanjing 210008, Peoples R China.; Wang, SH (corresponding author), Loughborough Univ, Sch Architecture Bldg & Civil Engn, Loughborough LE11 3TU, Leics, England.; Yang, M (corresponding author), Nanjing Med Univ, Childrens Hosp, Dept Radiol, Nanjing 210008, Peoples R China.
EM shuihuawang@ieee.org; hongj5@mail2.sysu.edu.cn; yangming19710217@163.com
RI Hong, Jin/ABE-9473-2021; Wang, Shuihua/G-7326-2016; Hong,
   Jin/ABH-7194-2022
OI Hong, Jin/0000-0002-8757-2700; 
CR Chen KT, 2018, INT J PEDIATR OTORHI, V114, P5, DOI 10.1016/j.ijporl.2018.08.022
   Chen Y, 2018, MULTIMED TOOLS APPL, V77, P3775, DOI 10.1007/s11042-016-4087-6
   Doosti H, 2018, J STAT PLAN INFER, V197, P51, DOI 10.1016/j.jspi.2017.12.003
   Kyeong K, 2018, IEEE T SEMICONDUCT M, V31, P395, DOI 10.1109/TSM.2018.2841416
   Li ZL, 2015, INT J CLIN EXP MED, V8, P569
   Liu FY, 2017, ADV INTEL SYS RES, V153, P49
   Lu ZH, 2016, J MED IMAG HEALTH IN, V6, P1218, DOI 10.1166/jmihi.2016.1901
   Pereira A., 2017, ADV ENG RES, V153, P412
   Profant O, 2014, NEUROSCIENCE, V260, P87, DOI 10.1016/j.neuroscience.2013.12.010
   Shiell MM, 2016, NEURAL PLAST, V2016, DOI 10.1155/2016/7217630
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tang YJ, 2016, INT CONF DAT MIN WOR, P503, DOI [10.1109/ICDMW.2016.65, 10.1109/ICDMW.2016.0078]
   Vaden KI, 2016, EXP AGING RES, V42, P86, DOI 10.1080/0361073X.2016.1108784
   Wang SH, 2017, LECT NOTES COMPUT SC, V10262, P541, DOI 10.1007/978-3-319-59081-3_63
   Wang SH, 2017, FUND INFORM, V151, P505, DOI 10.3233/FI-2017-1507
   Wentland CJ, 2018, INT J PEDIATR OTORHI, V111, P26, DOI 10.1016/j.ijporl.2018.05.024
   Yang M, 2014, HEARING RES, V316, P37, DOI 10.1016/j.heares.2014.07.006
   Zhan TM, 2017, TECHNOL HEALTH CARE, V25, pS377, DOI 10.3233/THC-171341
   Zhang Y, 2012, PROG ELECTROMAGN RES, V130, P369, DOI 10.2528/PIER12061410
   Zhang Y, 2011, J ELECTROMAGNET WAVE, V25, P1081, DOI 10.1163/156939311795762024
   Zhang YD, 2009, PROG ELECTROMAGN RES, V94, P83, DOI 10.2528/PIER09041905
   Zhang YD, 2018, J COMPUT SCI-NETH, V28, P1, DOI 10.1016/j.jocs.2018.07.003
   Zhang YD, 2018, J COMPUT SCI-NETH, V27, P57, DOI 10.1016/j.jocs.2018.05.005
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22875, DOI 10.1007/s11042-018-6003-8
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22821, DOI 10.1007/s11042-018-5765-3
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22671, DOI 10.1007/s11042-017-5146-3
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22629, DOI 10.1007/s11042-017-5023-0
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22589, DOI 10.1007/s11042-017-4703-0
   Zhang YD, 2008, SCI CHINA SER F, V51, P2115, DOI 10.1007/s11432-008-0124-z
   Zhang YD, 2014, COMPUT MATH METHOD M, V2014, DOI 10.1155/2014/546814
   Zhang YD, 2013, SENSORS-BASEL, V13, P4029, DOI 10.3390/s130404029
   Zhang YD, 2011, SENSORS-BASEL, V11, P4721, DOI 10.3390/s110504721
   Zhang YD, 2011, ENTROPY-SWITZ, V13, P841, DOI 10.3390/e13040841
   Zhang YD, 2010, SCI CHINA INFORM SCI, V53, P1963, DOI 10.1007/s11432-010-4075-9
   Zhang YD, 2008, SENSORS-BASEL, V8, P7518, DOI 10.3390/s8117518
   Zhang YD, 2010, EXPERT SYST APPL, V37, P1911, DOI 10.1016/j.eswa.2009.07.025
   Zhang YD, 2009, SCI CHINA SER F, V52, P914, DOI 10.1007/s11432-009-0019-7
   Zhang YD, 2009, EXPERT SYST APPL, V36, P8849, DOI 10.1016/j.eswa.2008.11.028
   Zhao XP, 2018, IET COMPUT VIS, V12, P453, DOI 10.1049/iet-cvi.2017.0096
NR 39
TC 15
Z9 16
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15135
EP 15150
DI 10.1007/s11042-018-6798-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900046
DA 2024-07-18
ER

PT J
AU Yuan, YJ
   Huang, W
   Wang, XX
   Xu, HY
   Zuo, HY
   Su, RD
AF Yuan, Yijie
   Huang, Wei
   Wang, Xiangxin
   Xu, Huaiyu
   Zuo, Hongying
   Su, Ruidan
TI Automated accurate registration method between UAV image and Google
   satellite map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE UAV image; Google satellite map; Image registration; Deep convolution
   feature; VGG16
ID FRAMEWORK; ASIFT
AB Because Unmanned Aerial Vehicle (UAV) image exhibits low positioning accuracy, the accurate registration of the image is required. Since the viewpoint direction, capturing time and shoot height are considerably different between the UAV image and google satellite map, the existing methods cannot match two images accurately. For the registration between the UAV image and google satellite map, a full-automated image registration method was proposed based on deep convolution feature. Such method consists of five steps: automatically reference images downloading, uniform key point extraction, deep convolution features computation, accurately feature matching and image registration. The reference image was downloaded from google map service according to the approximate location and region of the UAV image. The deep convolution feature was extracted using the pre-trained VGG16 model. Finally, many experiments were performed to verify the efficiency of the proposed method, and the results demonstrate that the proposed method is more effective and robust than the existing method.
C1 [Yuan, Yijie; Huang, Wei; Xu, Huaiyu; Zuo, Hongying; Su, Ruidan] Chinese Acad Sci, Shanghai Adv Res Inst, Shanghai, Peoples R China.
   [Yuan, Yijie; Huang, Wei; Xu, Huaiyu] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Wang, Xiangxin] Shanghai Univ, Dept Comp Sci & Technol, Shanghai, Peoples R China.
C3 Chinese Academy of Sciences; Shanghai Advanced Research Institute, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Shanghai University
RP Zuo, HY; Su, RD (corresponding author), Chinese Acad Sci, Shanghai Adv Res Inst, Shanghai, Peoples R China.
EM zuohy@sari-hk.com; surd@sari.ac.cn
RI Su, Ruidan/S-9437-2019
OI Su, Ruidan/0000-0003-0058-4088
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2014, VERY DEEP CONVOLUTIO
   [Anonymous], GEORELATED IOT APPL
   [Anonymous], 2014, J APPL MATH
   [Anonymous], INT J REMOTE SENS
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bekele D, 2013, IEEE IMAGE PROC, P3652, DOI 10.1109/ICIP.2013.6738753
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222
   Chang HH, 2019, IEEE GEOSCI REMOTE S, V16, P1363, DOI 10.1109/LGRS.2019.2899123
   Colomina I, 2014, ISPRS J PHOTOGRAMM, V92, P79, DOI 10.1016/j.isprsjprs.2014.02.013
   COOLEY JW, 1965, MATH COMPUT, V19, P297, DOI 10.2307/2003354
   Dong YY, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111719
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Heinly J, 2012, LECT NOTES COMPUT SC, V7573, P759, DOI 10.1007/978-3-642-33709-3_54
   Leese J.A., 1971, J APPL METEOR, V16, P118, DOI [DOI 10.1175/1520-0450, 10.1175/1520-0450(1971)0102.0.CO;2, DOI 10.1175/1520-0450(1971)010<0118:AATFOC>2.0.CO;2, 10.1175/1520-0450]
   Li LJ, 2014, INT J COMPUT VISION, V107, P20, DOI 10.1007/s11263-013-0660-x
   Liu XP, 2018, FRONT EARTH SCI-PRC, V12, P779, DOI 10.1007/s11707-018-0717-9
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucchese L, 2006, IEEE T IMAGE PROCESS, V15, P3008, DOI 10.1109/TIP.2006.877519
   Morel JM, 2009, SIAM J IMAGING SCI, V2, P438, DOI 10.1137/080732730
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376
   Paul S, 2016, IEEE GEOSCI REMOTE S, V13, P1300, DOI 10.1109/LGRS.2016.2582528
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Ruidan Su, 2012, Journal of Software, V7, P1919, DOI 10.4304/jsw.7.8.1919-1922
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Turner D, 2014, IEEE T GEOSCI REMOTE, V52, P2738, DOI 10.1109/TGRS.2013.2265295
   Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918
   Wang S, 2018, ISPRS J PHOTOGRAMM, V145, P148, DOI 10.1016/j.isprsjprs.2017.12.012
   Wang XJ, 2015, REMOTE SENS-BASEL, V7, P7044, DOI 10.3390/rs70607044
   Ye YX, 2017, IEEE T GEOSCI REMOTE, V55, P2941, DOI 10.1109/TGRS.2017.2656380
   Zhao F, 2006, INT CONF ACOUST SPEE, P1977
   Zhuo XY, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9040376
NR 35
TC 11
Z9 11
U1 3
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16573
EP 16591
DI 10.1007/s11042-019-7729-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600043
DA 2024-07-18
ER

PT J
AU Zhang, XW
   Zhu, ZN
   Li, B
   Zhu, JW
AF Zhang, Xiaowei
   Zhu, Zhengnan
   Li, Bin
   Zhu, Junwu
TI Allocation and pricing of group-buying based on the fixed bidding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Incentive compatibility; Group-buying mechanism; Allocation and pricing
ID MECHANISMS
AB Online group-buying is a popular business mode based on Internet. Group-buying websites can get discount for goods or services through promotion and other means which used to gather enough number of people, and sellers can also sell more quantities of goods. However, the existing group-buying mode is that all buyers unify the fixed pricing, the mechanism cannot distinguish the contribution of different buyers and motivate buyers report truthfully. In this paper, an online group-buying pricing method based on buyer's fixed bidding is proposed in view of the influence of buyer's bidding price and demand quantity on the participants' group in the group-buying mechanism. We introduce the concept of relative importance to the allocation and pricing of mechanisms and propose a new mechanism named Fixed bids Truthful Mechanism for Group Buying (FTM4GB) based on correlation importance. At the end of the paper, we prove the economic attributes of individual rationality, incentive compatibility and budget balance.
C1 [Zhang, Xiaowei; Zhu, Zhengnan; Li, Bin; Zhu, Junwu] Yangzhou Univ, Coll Informat Engn, Yangzhou, Jiangsu, Peoples R China.
C3 Yangzhou University
RP Zhu, JW (corresponding author), Yangzhou Univ, Coll Informat Engn, Yangzhou, Jiangsu, Peoples R China.
EM xwzhang@yzu.edu.cn; 113540234@qq.com; bl@yzu.edu.cn; jwzhu@yzu.edu.cn
RI zhang, xiaowei/GQH-5387-2022; Zhu, Junwu/H-2641-2015
CR Anand KS, 2003, MANAGE SCI, V49, P1546, DOI 10.1287/mnsc.49.11.1546.20582
   [Anonymous], 1998, INT WORKSH AG MED EL
   Babaioff M, 2001, CONCURRENT AUCTIONS, P1
   Chen RR, 2011, PROD OPER MANAG, V20, P181, DOI 10.1111/j.1937-5956.2010.01173.x
   DOLAN RJ, 1987, MARKET SCI, V6, P1, DOI 10.1287/mksc.6.1.1
   GIBBARD A, 1973, ECONOMETRICA, V41, P587, DOI 10.2307/1914083
   Hendrick TE, 1997, MANAGING CHANNEL PRO
   HURWICZ L, 1973, AM ECON REV, V63, P1
   Jr JD, 2003, GAME ECON BEHAV, V74, P470
   Kauffman RJ, 2002, HDB ELECT COMMERCE B, P27
   Lesca J, 2012, FRONT ARTIF INTEL AP, V242, P522, DOI 10.3233/978-1-61499-098-7-522
   Li C, 2006, J GUANGDONG COLL FIN, V5, P61
   Li CZ, 2002, ACTA POLYM SIN, P120
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Muller E, 1985, SOCIAL GOALS SOCIAL, P131
   MYERSON RB, 1983, J ECON THEORY, V29, P265, DOI 10.1016/0022-0531(83)90048-0
   Sandholm T, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1500
   Thomson W, 1988, CAMB BOOKS, V57, P543
   VICKREY W, 1961, J FINANC, V16, P8, DOI 10.2307/2977633
   Yamamoto J., 2001, Proceedings of the Fifth International Conference on Autonomous Agents, P576, DOI 10.1145/375735.376452
   Yokoo M., 2000, Proceedings 20th IEEE International Conference on Distributed Computing Systems, P146, DOI 10.1109/ICDCS.2000.840916
   Zaman Sharrukh, 2010, Proceedings of the 2010 IEEE 2nd International Conference on Cloud Computing Technology and Science (CloudCom 2010), P127, DOI 10.1109/CloudCom.2010.28
   Zhang Y, 2018, J NETW COMPUT APPL, V117, P10, DOI 10.1016/j.jnca.2018.05.007
NR 23
TC 2
Z9 2
U1 5
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14689
EP 14710
DI 10.1007/s11042-019-7302-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900021
DA 2024-07-18
ER

PT J
AU Ashiba, HI
AF Ashiba, H., I
TI Feature enhancement angiographic images in medical diagnosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Angiographic images; The AWT; Homomorphic method
AB This paper suggest three new proposed algorithms for the feature enhancement in the angiographic images. The first approach is based on mixing the features of Homomorphic Way and the Additive Wavelet Transform (AWT) with Six Sub Bands (AWHS). The idea behind this model is based on decomposing the image into sub-bands in an additive fashion using the AWT. The homomorphic processing is applied on each sub band, separately. The second approach suggests modification for histogram equalization (MHE) for enhancement angiographic images. The MHE is depended on applying the Histogram Equalization (HE) on angiographic images and suggest modification for clip limit for the HE. Third suggested approach merges the benefits of the Histogram Processing with the features of Undecimated AWT (HPUAT) and homomorphic method. The main idea of this model depends on applying The MHE on the angiographic image. Then, the resultant image is decomposed into sub-bands using the AWT. The homomorphic enhancement is implemented on each sub-band, separately, up to the sixth sub-band. This method is performed on the angiographic image in the log domain by decomposing the image into illumination and reflectance components. The illumination is attenuated, while the reflectance is magnified. Applying this model on each sub-band obtains more details in the angiographic image. The performance evaluations are entropy, average gradient, contrast improvement factor and Sobel edge magnitude point of views. Simulation results show that the third proposed approach gives superior image quality for angiographic images.
C1 [Ashiba, H., I] Bilbis Higher Inst Engn, Dept Elect & Elect Commun, Bilbis, Sharqia, Egypt.
RP Ashiba, HI (corresponding author), Bilbis Higher Inst Engn, Dept Elect & Elect Commun, Bilbis, Sharqia, Egypt.
EM Eng_h_2006@yahoo.com
RI ashiba, huda/GQI-4310-2022
OI ashiba, huda/0000-0002-4926-8919
CR [Anonymous], 2010, Version 7.10.0 (R2010a)
   Ashiba HI, 2019, MULTIMED TOOLS APPL, V78, P11277, DOI 10.1007/s11042-018-6545-9
   Ashiba HI, 2018, WIRELESS PERS COMMUN, V99, P619, DOI 10.1007/s11277-017-4958-9
   Ashiba H. I., 2008, Progress In Electromagnetics Research C, V1, P123, DOI 10.2528/PIERC08012301
   Bhairannawar SS., 2018, Soft Computing Based Medical Image Analysis, P51, DOI [DOI 10.1016/B978-0-12-813087-2.00003-8, 10.1016/B978-0-12-813087-2.00003-8]
   Brzozowski K, 2011, EUR J RADIOL, V80, pE401, DOI 10.1016/j.ejrad.2010.12.019
   Fan JF, 2019, COMPUT METH PROG BIO, V175, P233, DOI 10.1016/j.cmpb.2019.04.006
   Gonzalez RC, 2008, DIGITAL IMAGEPROCESS
   Jae S., 1990, Two-dimensional signal and image processing
   Kumbhar U., 2013, INT J ENG RES TECHNO, V2, P2278
   Latha R, 2010, PROCEDIA COMPUT SCI, V2, P303, DOI 10.1016/j.procs.2010.11.039
   Rajalingam B., 2017, INT J PURE APPL MATH, V117, P599
   Rajalingam B, 2017, INT J ENG MANUFACTUR, V7
   Singh B.B., 2017, INT J COMPUT APPL, V167, P0975
   Wildner P, 2020, MULT SCLER RELAT DIS, V37, DOI 10.1016/j.msard.2019.101452
NR 15
TC 2
Z9 2
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21539
EP 21556
DI 10.1007/s11042-020-08899-2
EA MAY 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000531338800001
DA 2024-07-18
ER

PT J
AU Vijayan, M
   Mohan, R
AF Vijayan, Midhula
   Mohan, R.
TI A Universal Foreground Segmentation Technique using Deep-Neural Network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep-neural network; Background image; Moving object detection;
   Background subtraction; Optical-flow
ID VISUAL SURVEILLANCE; BACKGROUND SUBTRACTION; CNN
AB Background subtraction is generally used for foreground segmentation (moving object detection) from video sequences. Several background subtraction methods have been proposed for visual surveillance applications. However, the existing methods fail in case of real-surveillance challenges such as camouflage, sudden illumination variation, hard shadow, camera-jitter, non-static background, etc. A deep-neural network based background subtraction model is presented for flexible foreground segmentation. In addition to background subtraction model, a novel background modeling technique is also proposed for flexible background subtraction process. The presented deep-neural network architecture performs the background subtraction operation using the non-handcrafted features. The proposed method uses optical-flow details to make use of temporal information. This temporal information and spatial information (from the background image and current processing frame) are used for the training purpose. The model is trained using randomly selected images and its ground truth images from CDnet-2014 dataset. The presented model is evaluated using CDnet-2014 dataset, and it gives significant results compared to the existing background subtraction methods in terms of qualitative and quantitative analyzes.
C1 [Vijayan, Midhula; Mohan, R.] Natl Inst Technol, Dept Comp Sci & Engn, Tiruchirappalli 620015, Tamil Nadu, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Vijayan, M (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Tiruchirappalli 620015, Tamil Nadu, India.
EM midhula91@gmail.com; rmohan@nitt.edu
RI R, Mohan/V-6077-2019
OI Vijayan, Midhula/0000-0002-2578-6463
CR Allebosch G, 2015, LECT NOTES COMPUT SC, V9386, P130, DOI 10.1007/978-3-319-25903-1_12
   [Anonymous], 2017, IEEE T CIRCUITS SYST
   Azab MM, 2010, IEEE IMAGE PROC, P3453, DOI 10.1109/ICIP.2010.5653748
   Babaee M, 2018, PATTERN RECOGN, V76, P635, DOI 10.1016/j.patcog.2017.09.040
   Bouwmans Thierry, 2011, Recent Patents on Computer Science, V4, P147, DOI 10.2174/1874479611104030147
   Bouwmans T, 2014, Background modeling and foreground detection for video surveillance
   Braham M, 2016, INT CONF SYST SIGNAL, P113
   Chang O, 2017, J ARTIF INTELL SOFT, V7, P125, DOI 10.1515/jaiscr-2017-0009
   Chiranjeevi P, 2017, IEEE T CYBERNETICS, V47, P2544, DOI 10.1109/TCYB.2016.2585600
   Culibrk D, 2007, IEEE T NEURAL NETWOR, V18, P1614, DOI 10.1109/TNN.2007.896861
   De Gregorio M, 2016, CVPR 16 GOOGLE UNPUB
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Gao F, 2018, COMPUT MED IMAG GRAP, V70, P53, DOI 10.1016/j.compmedimag.2018.09.004
   Ghosh S, 2019, INT J MACH LEARN CYB, V10, P3145, DOI 10.1007/s13042-019-01005-5
   Hu GS, 2018, IEEE T IMAGE PROCESS, V27, P293, DOI 10.1109/TIP.2017.2756450
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Kang K., 2017, IEEE Transactions on Circuits and Systems for Video Technology
   Khaire P, 2018, PATTERN RECOGN LETT, V115, P107, DOI 10.1016/j.patrec.2018.04.035
   Khatami A, 2018, EXPERT SYST APPL, V100, P224, DOI 10.1016/j.eswa.2018.01.056
   Kim IS, 2010, INT J CONTROL AUTOM, V8, P926, DOI 10.1007/s12555-010-0501-4
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Kingma D. P., 2014, arXiv
   Krungkaew R., 2016, 2016 13 INT C ELECT, P1
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Lim LA, 2018, PATTERN RECOGN LETT, V112, P256, DOI 10.1016/j.patrec.2018.08.002
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   Maddalena L, 2010, NEURAL COMPUT APPL, V19, P179, DOI 10.1007/s00521-009-0285-8
   Martins I, 2017, LECT NOTES COMPUT SC, V10255, P50, DOI 10.1007/978-3-319-58838-4_6
   Pathak D, 2017, PROC CVPR IEEE, P6024, DOI 10.1109/CVPR.2017.638
   Paul M, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-11
   Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566
   Ramírez-Alonso G, 2016, NEUROCOMPUTING, V175, P990, DOI 10.1016/j.neucom.2015.04.118
   Ruder S., 2016, ARXIV
   Sajid H, 2015, IEEE IMAGE PROC, P4530, DOI 10.1109/ICIP.2015.7351664
   Seeliger K, 2018, NEUROIMAGE, V180, P253, DOI 10.1016/j.neuroimage.2017.07.018
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   St-Charles PL, 2016, IEEE T IMAGE PROCESS, V25, P4768, DOI 10.1109/TIP.2016.2598691
   St-Charles PL, 2015, IEEE WINT CONF APPL, P990, DOI 10.1109/WACV.2015.137
   St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Suleiman HY, 2017, JCI INSIGHT, V2, DOI 10.1172/jci.insight.94137
   Varghese A., 2017, IPSJ Transactions on Computer Vision and Applications, V9, P1, DOI DOI 10.1186/S41074-017-0036-1
   Vijayan M, 2018, INT C REC TRENDS IM, P27
   Wang KF, 2018, IEEE ACCESS, V6, P15505, DOI 10.1109/ACCESS.2018.2812880
   Wang N, 2013, P ADV NEURAL INFORM
   Wang Y., 2014, P IEEE C COMP VIS PA, P387, DOI 10.1109/ICIP40778.2020.9190887
   Wang Y, 2017, PATTERN RECOGN LETT, V96, P66, DOI 10.1016/j.patrec.2016.09.014
   Xu Jian, 2008, 2008 9th International Conference on Signal Processing (ICSP 2008), P1400, DOI 10.1109/ICOSP.2008.4697394
   Xu Y, 2015, IEEE INT CONF RFID, P1, DOI 10.1109/RFID.2015.7113066
   Yang L, 2018, IEEE T INTELL TRANSP, V19, P254, DOI 10.1109/TITS.2017.2754099
   Zeng Z, 2017, IEEE T FUZZY SYST, V25, P584, DOI 10.1109/TFUZZ.2016.2566811
NR 51
TC 6
Z9 6
U1 2
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 34835
EP 34850
DI 10.1007/s11042-020-08977-5
EA MAY 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000531339200002
DA 2024-07-18
ER

PT J
AU Lei, BY
   Jiang, F
   Zhou, F
   Ni, D
   Yao, Y
   Chen, SP
   Wang, TF
AF Lei, Baiying
   Jiang, Feng
   Zhou, Feng
   Ni, Dong
   Yao, Yuan
   Chen, Siping
   Wang, Tianfu
TI Hybrid descriptor for placental maturity grading
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Placental maturity grading; Convolutional neural networks; Hybrid
   descriptors; Fisher vector; Color Doppler energy imaging
ID ULTRASOUND; GROWTH; CLASSIFICATION
AB Placental maturity grading (PMG) is quite essential to assess fetal growth and maternal health. To this date, PMG has mostly relied on the subjective judgment of the clinician, which is time-consuming and may cause wrong estimation due to redundancy and repeatability of the process. To tackle it, we propose an automatic method to stage placental maturity via deep hybrid descriptors based on B-mode ultrasound (BUS) and color Doppler energy (CDE) images. Specifically, convolutional descriptors extracted from multiple deep convolutional neural networks (DCNNs) and hand-crafted features are integrated to get the hybrid descriptors for grading performance boosting. First, different models with various feature layers are combined to obtain hybrid descriptors from images. Second, the transfer learning strategy is also utilized to enhance the grading performance via the deeply represented features. Third, extracted descriptors are encoded by Fisher vector (FV). Finally, we use support vector machine (SVM) as the classifier to grade placental maturity. The experimental results demonstrate that our proposed method could achieve good performance in PMG.
C1 [Lei, Baiying; Jiang, Feng; Ni, Dong; Chen, Siping; Wang, Tianfu] Shenzhen Univ, Sch Biomed Engn, Natl Reg Key Technol Engn Lab Med Ultrasound, Guangdong Key Lab Biomed Measurements & Ultrasoun, Shenzhen, Peoples R China.
   [Zhou, Feng] Univ Michigan, Dept Ind & Mfg, Syst Engn, Dearborn, MI 48128 USA.
   [Yao, Yuan] Shenzhen Maternal & Child Healthcare Hosp, Dept Ultrasound, 3012 Fuqiang Rd, Shenzhen, Peoples R China.
C3 Shenzhen University; University of Michigan System; University of
   Michigan
RP Wang, TF (corresponding author), Shenzhen Univ, Sch Biomed Engn, Natl Reg Key Technol Engn Lab Med Ultrasound, Guangdong Key Lab Biomed Measurements & Ultrasoun, Shenzhen, Peoples R China.
EM tfwang@szu.edu.cn
RI Lei, Baiying/AAY-5515-2020; Feng, Jiashi/AGX-6209-2022; Lei,
   Baiying/GQO-8422-2022; Chen, Siqi/IZE-8631-2023; Lei,
   Baiying/GRE-9741-2022
OI Lei, Baiying/0000-0002-3087-2550; Lei, Baiying/0000-0002-3087-2550; Lei,
   Baiying/0000-0002-3087-2550; Zhou, Feng/0000-0001-6123-073X
FU National Key R&D Program of China [2016YFC0104700]; National Natural
   Science Foundation of China [61871274, 61801305, 81571758]; National
   Natural Science Foundation of Guangdong Province [2017A030313377];
   Guangdong Pearl River Talents Plan [2016ZT06S220]; Medical Scientific
   Research Foundation of Guangdong Province, China [B2018031]; Shenzhen
   Peacock Plan [KQTD2016053112051497, KQTD2015033016 104926]; Shenzhen Key
   Basic Research Project [JCYJ20180507184647636, JCYJ20170818142347251,
   JCYJ20170818 094109846]
FX This work was supported partly by National Key R&D Program of China
   (No.2016YFC0104700), National Natural Science Foundation of China
   (Nos.61871274, 61801305 and 81571758), National Natural Science
   Foundation of Guangdong Province (No. 2017A030313377), Guangdong Pearl
   River Talents Plan (2016ZT06S220), Medical Scientific Research
   Foundation of Guangdong Province, China (No. B2018031), Shenzhen Peacock
   Plan (Nos. KQTD2016053112051497 and KQTD2015033016 104926), and Shenzhen
   Key Basic Research Project (Nos. JCYJ20180507184647636,
   JCYJ20170818142347251 and JCYJ20170818 094109846).
CR [Anonymous], 2015, ARXIV150906033
   Bude RO, 1996, RADIOLOGY, V200, P21, DOI 10.1148/radiology.200.1.8657912
   Burton GJ, 2009, REPRODUCTION, V138, P895, DOI 10.1530/REP-09-0092
   Chang HL, 2015, NEUROCOMPUTING, V151, P632, DOI 10.1016/j.neucom.2014.05.092
   Chen H, 2017, IEEE T CYBERNETICS, V47, P1576, DOI 10.1109/TCYB.2017.2685080
   Chen H, 2015, IEEE J BIOMED HEALTH, V19, P1627, DOI 10.1109/JBHI.2015.2425041
   Chen JC, 2016, SCI REP-UK, V6, DOI [10.1038/srep24454, 10.1038/srep25671]
   CIMPOI M, 2015, PROC CVPR IEEE, P3828, DOI DOI 10.1109/CVPR.2015.7299007
   Cui CR, 2019, IEEE T MULTIMEDIA, V21, P1209, DOI 10.1109/TMM.2018.2875357
   D'hooge J, 2000, Eur J Echocardiogr, V1, P154, DOI 10.1053/euje.2000.0031
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Donahue J, 2014, PR MACH LEARN RES, V32
   Dubiel M, 2005, ULTRASOUND MED BIOL, V31, P321, DOI 10.1016/j.ultrasmedbio.2004.12.008
   Elsayes KM, 2009, RADIOGRAPHICS, V29, P1371, DOI 10.1148/rg.295085242
   Faraki M, 2014, PATTERN RECOGN, V47, P2348, DOI 10.1016/j.patcog.2013.10.011
   Goldenberg RL, 2012, AM J OBSTET GYNECOL, V206, P113, DOI 10.1016/j.ajog.2011.10.865
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   GRANNUM PAT, 1979, AM J OBSTET GYNECOL, V133, P915, DOI 10.1016/0002-9378(79)90312-0
   Guerriero S, 1999, HUM REPROD UPDATE, V5, P515, DOI 10.1093/humupd/5.5.515
   Guiot C, 2008, ULTRASOUND OBST GYN, V31, P171, DOI 10.1002/uog.5212
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang QH, 2015, IEEE T HUM-MACH SYST, V45, P385, DOI 10.1109/THMS.2014.2374551
   Huang QH, 2015, IEEE T ULTRASON FERR, V62, P392, DOI 10.1109/TUFFC.2014.006665
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Joe Yue-Hei Ng, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P53, DOI 10.1109/CVPRW.2015.7301272
   KAZZI GM, 1983, AM J OBSTET GYNECOL, V145, P733, DOI 10.1016/0002-9378(83)90582-3
   Kellow ZS, 2011, ULTRASOUND Q, V27, P187, DOI 10.1097/RUQ.0b013e318229ffb5
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Lei BY, 2017, NEUROCOMPUTING, V223, P86, DOI 10.1016/j.neucom.2016.10.033
   Lei BY, 2017, PATTERN RECOGN, V63, P719, DOI 10.1016/j.patcog.2016.09.037
   Lei BY, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0121838
   Lei BY, 2014, IEEE ENG MED BIO, P4671, DOI 10.1109/EMBC.2014.6944666
   Li WJ, 2016, I S BIOMED IMAGING, P783, DOI 10.1109/ISBI.2016.7493383
   Li XY, 2014, BIO-MED MATER ENG, V24, P2821, DOI 10.3233/BME-141100
   Linares PA, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 AND 2, P1147
   Liu L, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (IEEE ICMA 2014), P1143, DOI 10.1109/ICMA.2014.6885859
   Liu Z., 2009, ELECT DEVICES M IEDM, P1, DOI DOI 10.1109/WICOM.2009.5302548
   Long J.L., 2014, Advances in neural information processing systems, V27, P1601
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Moran M, 2014, PLACENTA, V35, P639, DOI 10.1016/j.placenta.2014.03.007
   Ozcan T, 2008, ULTRASOUND CLIN, V3, P13, DOI DOI 10.1016/j.cult.2007.12.007
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   REYNOLDS D, 2009, ENCY BIOMETRICS, P93
   Ribeiro RT, 2013, IEEE T BIO-MED ENG, V60, P1336, DOI 10.1109/TBME.2012.2235438
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Shi J, 2019, IEEE T BIO-MED ENG, V66, P2362, DOI 10.1109/TBME.2018.2889398
   SIMONYAN K, 2014, P IEEE CVPR
   Yosinski J, 2014, ADV NEUR IN, V27
   Zheng Liang, 2016, arXiv preprint arXiv
   Zheng W, 2020, PATTERN RECOGN LETT, V132, P4, DOI 10.1016/j.patrec.2018.06.029
NR 54
TC 1
Z9 1
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21223
EP 21239
DI 10.1007/s11042-019-08489-x
EA MAY 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000530228700002
DA 2024-07-18
ER

PT J
AU Devi, RS
   Aravind, ARN
   Vishal, JC
   Amritha, D
   Thenmozhi, K
   Rayappan, JBB
   Rengarajan, A
   Padmapriya, P
AF Devi, R. Santhiya
   Aravind, A. R. Nirmal
   Vishal, J. Christopher
   Amritha, D.
   Thenmozhi, K.
   Rayappan, John Bosco Balaguru
   Rengarajan, Amirtharajan
   Padmapriya, Praveenkumar
TI Image encryption through RNA approach assisted with neural key sequences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DICOM; DNA; RNA; Encryption; BAM NN
ID DNA; CHAOS; PROTEIN
AB In this paper, an image encryption algorithm is proposed for the first time, which uses coding deoxyribonucleic acid (DNA) sequences to transcript its complementary messenger ribonucleic acid (mRNA) sequence. A binary associative memory neural network (BAM NN) is trained to produce the required transfer ribonucleic acid (tRNA) sequences to bond with the mRNA sequences to assign the correct amino acids. DNA and mRNA sequences, together with tRNA sequences, provide the permutation and diffusion operations for the pixels in colour digital imaging and communications in medicine images. Then, keys, which are determined by the generated amino acids, are used to encrypt the diffused cipher pixels further. Also key sharing has been carried out using Universal Software Radio Peripheral (USRP), cloud infrastructure and One Time Password (OTP) generation mechanisms.The different sequence formation can also identify any alterations made by the intruder in the amino acid, which results in the wrong set of key generation. Various decryption quality analyses, statistical and differential attack analyses (namely mean square error, unified average changing intensity, peak signal-to-noise ratio, number of pixel changing rate, entropy, mean absolute error, key sensitivity, cropping attacks, and chosen-plaintext attacks), and correlation tests were carried out to confirm the robustness of the proposed algorithm.
C1 [Devi, R. Santhiya; Aravind, A. R. Nirmal; Vishal, J. Christopher; Amritha, D.; Thenmozhi, K.; Rayappan, John Bosco Balaguru; Rengarajan, Amirtharajan; Padmapriya, Praveenkumar] SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Padmapriya, P (corresponding author), SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
EM padmapriya@ece.sastra.edu
RI Amirtharajan, Rengarajan/C-6471-2011; praveenkumar,
   padmapriya/AAH-9426-2019; Rayappan, John Bosco Balaguru/K-6842-2013
OI Amirtharajan, Rengarajan/0000-0003-1574-3045; praveenkumar,
   padmapriya/0000-0001-8483-1538; Rayappan, John Bosco
   Balaguru/0000-0003-4641-9870; Rajasekaran, Dr. Santhiya
   Devi/0000-0003-4081-9662; Karuppuswamy, Thenmozhi/0000-0001-9829-0189
CR Abd-El-Hafiz SK, 2016, OPT LASER ENG, V85, P72, DOI 10.1016/j.optlaseng.2016.04.023
   Al-Haj A, 2015, J DIGIT IMAGING, V28, P179, DOI 10.1007/s10278-014-9734-8
   Alam S, 2017, IEEE T CIRCUITS-II, V64, P1007, DOI 10.1109/TCSII.2016.2618366
   Arumugham S, 2018, J BIOMED INFORM, V1, P2
   Barani MJ, 2019, OPTIK, V187, P205, DOI 10.1016/j.ijleo.2019.04.074
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chandrasekaran J., 2017, SECUR COMMUN NETWORK, V2017
   Diaconu AV, 2016, INFORM SCIENCES, V355, P314, DOI 10.1016/j.ins.2015.10.027
   Ding L, 2020, MULTIMED TOOLS APPL, V79, P17193, DOI 10.1007/s11042-019-08384-5
   El Assad S, 2016, SIGNAL PROCESS-IMAGE, V41, P144, DOI 10.1016/j.image.2015.10.004
   Fu C, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0115773
   Fu C, 2013, COMPUT BIOL MED, V43, P1000, DOI 10.1016/j.compbiomed.2013.05.005
   Higgs PG, 2000, Q REV BIOPHYS, V33, P199, DOI 10.1017/S0033583500003620
   Kocabas O, 2016, IEEE ACM T COMPUT BI, V13, P401, DOI 10.1109/TCBB.2016.2520933
   Kocarev L., 2001, IEEE Circuits and Systems Magazine, V1, P6, DOI 10.1109/7384.963463
   Kumar M, 2016, SIGNAL PROCESS, V125, P187, DOI 10.1016/j.sigpro.2016.01.017
   Lee S-H, 2017, MULTIMED TOOLS APPL, V77, P1, DOI [10.1007/s11042-015-3011-9, DOI 10.1007/S11042-015-3011-9]
   Leier A, 2000, BIOSYSTEMS, V57, P13, DOI 10.1016/S0303-2647(00)00083-6
   Liu P, 2019, MULTIMED TOOLS APPL, V78, P14823, DOI 10.1007/s11042-018-6758-y
   Menezes A. J., 1996, HDB APPL CRYPTOGRAPH, V1st
   Neveu M, 2013, ASTROBIOLOGY, V13, P391, DOI 10.1089/ast.2012.0868
   Patel BH, 2015, NAT CHEM, V7, P301, DOI [10.1038/NCHEM.2202, 10.1038/nchem.2202]
   Praveenkumar P, 2016, TELECOMMUN SYST, P1
   Praveenkumar P, 2015, COMPUT BIOL MED, V62, P264, DOI 10.1016/j.compbiomed.2015.04.031
   Premkumar R, 2019, MULTIMED TOOLS APPL, V78, P9577, DOI 10.1007/s11042-018-6534-z
   Ravichandran D, IEEE T NANOBIOSCIENC, V16, P850
   Ravichandran D, 2016, COMPUT BIOL MED, V72, P170, DOI 10.1016/j.compbiomed.2016.03.020
   Rehman AU, 2015, MULTIMED TOOLS APPL, V74, P4655, DOI 10.1007/s11042-013-1828-7
   Shabash B, 2017, IEEE ACM T COMPUT BI, V14, P696, DOI 10.1109/TCBB.2016.2522421
   Singh HV, 2018, DIAGNOSIS CARIOUS LE, P864
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   Tinoco I, 1999, J MOL BIOL, V293, P271, DOI 10.1006/jmbi.1999.3001
   WANG AHJ, 1979, NATURE, V282, P680, DOI 10.1038/282680a0
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P6229, DOI 10.1007/s11042-016-3311-8
   Watson D, NATURE, V171, P737
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Zhang J, 2019, MULTIMED TOOLS APPL, V78, P15605, DOI 10.1007/s11042-018-6973-6
   Zhang Q, 2013, IETE TECH REV, V30, P404, DOI 10.4103/0256-4602.123123
   Zhang S., 2014, Math. Probl. Eng, V2014
   Zhang YQ, 2016, IEEE PHOTONICS J, V8, DOI 10.1109/JPHOT.2016.2620809
   Zhong C, 2012, 2012 IEEE 2 INT C CO, P1
NR 44
TC 8
Z9 8
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12093
EP 12124
DI 10.1007/s11042-019-08562-5
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400037
DA 2024-07-18
ER

PT J
AU Nagakrishnan, R
   Revathi, A
AF Nagakrishnan, R.
   Revathi, A.
TI A robust cryptosystem to enhance the security in speech based person
   authentication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic maps; DNA addition; Speech encryption system; Speech based
   person authentication
ID ENCRYPTION; ALGORITHM
AB The developments in technology have made us utilizing speech as a biometric to authenticate persons. In this paper, speech encryption and decryption algorithm are presented for enhancing the security in speech-based person authentication systems. The implementation of the authentication system contains the feature extraction, modeling techniques and testing procedures for authenticating the person. Firstly, the Mel frequency cepstral coefficient (MFCC) features are extracted from the training speech utterances and models are developed for each speaker. The speech encryption system encrypts the test speech utterances. Multiple chaotic mapping techniques and Deoxyribonucleic acid (DNA) addition based speech cryptosystem is developed to secure test speech against attacks. The speech encryption system deals with sampled test speech signal given as input, which is subjected to intra level and inter level bit substitution. These resultant samples are encoded into the DNA sequence denoted by P(n). The DNA sequence P(n) and DNA sequences {A(n), B(n), C(n), D(n)} obtained using different techniques based on chaos, such as tent mapping, henon mapping, sine mapping, and logistic mapping and summed up together using DNA addition operation. Finally, the encrypted test speech is obtained using DNA decoding. The speaker authentication system in the receiving side decrypts the encrypted signal and identifies the speakers from the decrypted speech. The correlation coefficient test, Signal to noise ratio test, Peak Signal to Noise Ratio test, key sensitivity test, NSCR and UACI test, key space analysis, and histogram analysis are the techniques used as metrics to prove the efficiency of the proposed cryptosystem. Overall individual accuracy is 97% for the text dependent person authentication with the original test speech set and decrypted test speech set. Overall individual accuracy is 66% for the text independent person authentication with the original test speech set and decrypted test speech set. In our work, the speech utterances are taken from AVSpoof database for authenticating 44 speakers. Our work highlights the efficiency of the encryption system, to provide security for test speech and person authentication using speech as a biometric.
C1 [Nagakrishnan, R.; Revathi, A.] SASTRA Deemed Be Univ, Sch EEE, Dept ECE, Thanjavur, Tamil Nadu, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Revathi, A (corresponding author), SASTRA Deemed Be Univ, Sch EEE, Dept ECE, Thanjavur, Tamil Nadu, India.
EM nagakrishnan@sastra.ac.in; revathi@ece.sastra.edu
OI Arunachalam, Revathi/0000-0001-9515-3592
CR [Anonymous], 2014, PROC 20 NAT C COMMUN
   Das RK, 2017, J SIGNAL PROCESS SYS, V88, P259, DOI 10.1007/s11265-016-1148-z
   Dellwo V, 2018, OXFORD HDB VOICE PER, P777, DOI DOI 10.1093/OXFORDHB/9780198743187.013.36
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Ergünay SK, 2015, INT CONF BIOMETR THE
   Eshwarappa M. N., 2011, INT J ADV COMPUT SC, V1, P77
   Farsana FJ, 2020, ADV MATH PHYS, V2020, DOI 10.1155/2020/8050934
   Farsana FJ, 2016, PROCEDIA COMPUT SCI, V93, P816, DOI 10.1016/j.procs.2016.07.302
   Hamza R., 2019, LECT NOTES COMPUTER, V11806
   Hamza R., 2019, INFORM SCI
   Hamza R, 2016, INF SECUR J, V25, P162, DOI 10.1080/19393555.2016.1212954
   Kar B, 2006, INT C IND TECHN, P391
   Kocarev L., 2001, IEEE Circuits and Systems Magazine, V1, P6, DOI 10.1109/7384.963463
   Kounoudes A, 2006, 2006 2 INT C INF COM, V1, P1020
   Mosa E, 2011, INT J SPEECH TECHNOL, V14, P285, DOI 10.1007/s10772-011-9103-7
   Nagakrishnan R, 2018, 18 INT C INT SYST DE, V1, P1070, DOI [10.1007/978-3-030-16657-1_100, DOI 10.1007/978-3-030-16657-1_100]
   Pareek N. K., 2005, Communications in Nonlinear Science and Numerical Simulation, V10, P715, DOI 10.1016/j.cnsns.2004.03.006
   PEACOCKE RD, 1990, COMPUTER, V23, P26, DOI 10.1109/2.56868
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   Ravichandran D, 2017, IEEE T NANOBIOSCI, V16, P850, DOI 10.1109/TNB.2017.2780881
   Revathi A, 2019, MULTIMED TOOLS APPL, V78, P1569, DOI 10.1007/s11042-018-6258-0
   Revathi A, 2018, INT J SPEECH TECHNOL, V21, P1021, DOI 10.1007/s10772-018-09563-9
   Revathi A., 2011, 2011 International Conference on Communications and Signal Processing (ICCSP), P198, DOI 10.1109/ICCSP.2011.5739300
   SATHIYAMURTHI P, 2017, EURASIP J AUDIO SPEE, V2017, P00001
   Sheela SJ, 2017, 2017 INTERNATIONAL CONFERENCE ON ALGORITHMS, METHODOLOGY, MODELS AND APPLICATIONS IN EMERGING TECHNOLOGIES (ICAMMAET)
   Sheela SJ, 2017, J COMPUT NETW COMMUN, V2017, DOI 10.1155/2017/2721910
   Singh, 2019, CSI COMMUNICATIONS, V42, P24
   Slimani D, 2018, PROCEDIA COMPUT SCI, V128, P79, DOI 10.1016/j.procs.2018.03.011
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Yoo IC, 2015, IEEE-ACM T AUDIO SPE, V23, P2238, DOI 10.1109/TASLP.2015.2476762
NR 30
TC 8
Z9 8
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 20795
EP 20819
DI 10.1007/s11042-020-08846-1
EA APR 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000528640600001
DA 2024-07-18
ER

PT J
AU Jerith, GG
   Kumar, PN
AF Jerith, G. Gifta
   Kumar, P. Nirmal
TI Recognition of Glaucoma by means of Gray Wolf Optimized Neural Network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Glaucoma; Grey wolf optimization; Speeded up robust feature; Gray level
   C0-occurrence matrix; Histogram of oriented gradients; Neural network
ID CLASSIFICATION; CUP
AB Glaucoma is the secondary most considerable causes of blindness after Cataracts. As it shows no symptoms, it is entitled to "snake thief of sight". Glaucoma is the condition in which optic nerve fibers are damaged that causes loss of vision and may even blindness if not diagnosed on time. If this chronic disease is not identified in the initial stage it negatively rooted for permanent blindness. Many manual scanning methods are available however they are costly, time-consuming and require experts of these fields to use them. To circumvent such adversarial effects, it is necessary to spot the disease earlier. This paper proposes a technique for the recognition of Glaucoma called Gray Wolf Optimized Neural Network (GWO-NN), which recognizes the presence or the absence of Glaucoma in a patient. Initially, as a preprocessing phase, the inputted image is transformed to greyscale, noise is eliminated using Adaptive Median Filter (AMF) and image normalization is done. Now, feature extraction is executed in features of GLCM (Gray Level C0-occurrence Matrix features), SURF (Speeded Up Robust Feature), HOG (Histogram of Oriented Gradients features) along with the Global features which are taken from the previously processed image. Now, classification follows utilizing NN of GWO (grey wolf optimization) technique. Experimental outcome indicates that the proposed optimized classifier identifies the existence or nonexistence of Glaucoma more precisely than other existing methods.
C1 [Jerith, G. Gifta] VV Coll Engn, Dept Comp Sci & Engn, Tisaiyanvilai, Tamil Nadu, India.
   [Kumar, P. Nirmal] Anna Univ, Dept Elect & Commun Engn, Coll Engn, Chennai, Tamil Nadu, India.
C3 Anna University; Anna University Chennai
RP Jerith, GG (corresponding author), VV Coll Engn, Dept Comp Sci & Engn, Tisaiyanvilai, Tamil Nadu, India.
EM ggiftajerith@gmail.com; nirmal@annauniv.edu
OI , G.Gifta Jerith/0009-0009-9263-541X
CR Abd Elfattah M, 2014, ADV INTELL SYST COMP, V303, P405, DOI 10.1007/978-3-319-08156-4_40
   Akram MU, 2015, AUSTRALAS PHYS ENG S, V38, P643, DOI 10.1007/s13246-015-0377-y
   Alcantud JCR, 2015, LECT NOTES ARTIF INT, V9422, P49, DOI 10.1007/978-3-319-24598-0_5
   [Anonymous], EMB DISTR SYST EDIS
   [Anonymous], 2018, 2018 9 IFIP INT C NE, DOI DOI 10.1109/NTMS.2018.8328728
   [Anonymous], INT C INT COMP CONTR
   [Anonymous], SIGN IM PROC ICSIP I
   Anupriya K, 2018, PROC IEEE INT SOFT, P208
   Araújo VM, 2018, PROC INT C TOOLS ART, P1, DOI 10.1109/ICTAI.2018.00011
   Bai XL, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0436-2
   BalaAnand M, 2020, INT J PARALLEL PROG, V48, P329, DOI 10.1007/s10766-018-0598-2
   BalaAnand M., 2015, INT J TECHNOLOGY ENG, V7, P157
   Bechar M.E. A., 2017, Multidimensional Systems and Signal Processing, V28, P1
   Ceccon S, 2014, IEEE J BIOMED HEALTH, V18, P1008, DOI 10.1109/JBHI.2013.2289367
   Chakravarty A, 2016, I S BIOMED IMAGING, P689, DOI 10.1109/ISBI.2016.7493360
   Chauhan K, 2016, SMART INNOV SYST TEC, V50, P507, DOI 10.1007/978-3-319-30933-0_51
   Chen XY, 2015, LECT NOTES COMPUT SC, V9351, P669, DOI 10.1007/978-3-319-24574-4_80
   Haleem MS, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0859-4
   Haleem MS, 2015, IEEE ENG MED BIO, P4318, DOI 10.1109/EMBC.2015.7319350
   Li AN, 2016, IEEE ENG MED BIO, P1328, DOI 10.1109/EMBC.2016.7590952
   Maram B, 2019, SERV ORIENTED COMPUT, V13, P3, DOI 10.1007/s11761-018-0249-x
   Mohammad Suraya, 2015, 2015 International Conference on BioSignal Analysis, Processing and Systems (ICBAPS), P98, DOI 10.1109/ICBAPS.2015.7292226
   Niwas SI, 2016, IEEE J BIOMED HEALTH, V20, P343, DOI 10.1109/JBHI.2014.2387207
   Salam AA, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3175-4
   Samanta S, 2015, ADV INTELL SYST COMP, V327, P351, DOI 10.1007/978-3-319-11933-5_38
   Sarkar D, 2017, SPRINGER PROC PHYS, V194, P381, DOI 10.1007/978-981-10-3908-9_46
   Thakur N, 2016, SMART INNOV SYST TEC, V43, P219, DOI 10.1007/978-81-322-2538-6_23
   Xu YW, 2016, I S BIOMED IMAGING, P693, DOI 10.1109/ISBI.2016.7493361
   Yadav D, 2014, INT CONF CONTEMP, P109, DOI 10.1109/IC3.2014.6897157
NR 29
TC 11
Z9 11
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10341
EP 10361
DI 10.1007/s11042-019-7224-1
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600033
DA 2024-07-18
ER

PT J
AU Wang, J
   Jeong, J
AF Wang, Jin
   Jeong, Jechang
TI Real time Demosaicking algorithm using derivative difference and
   curvature for digital camera
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Curvature; Derivative difference; Digital camera
ID FILTER; INTERPOLATION
AB Lots of mobile devices adopt single image sensors to acquire scene images. In our algorithm, we propose an adaptive and effective demosaicking algorithm using derivative difference and curvature which can estimate the directional component to reconstruct the to-be-interpolated color pixels. We introduce an function to evaluate the image complexity, which is composed by the derivative difference and isophote smoothing which is calculated as the sign of image curvature.
C1 [Wang, Jin; Jeong, Jechang] Hanyang Univ, Dept Elect & Comp Engn, Seoul, South Korea.
C3 Hanyang University
RP Wang, J (corresponding author), Hanyang Univ, Dept Elect & Comp Engn, Seoul, South Korea.
EM chwj0605@hotmail.com
CR Chang LL, 2004, IEEE T CONSUM ELECTR, V50, P355, DOI 10.1109/TCE.2004.1277885
   Chen WJ, 2012, DIGIT SIGNAL PROCESS, V22, P163, DOI 10.1016/j.dsp.2011.09.006
   Chung KH, 2006, IEEE T IMAGE PROCESS, V15, P2944, DOI 10.1109/TIP.2006.877521
   Dubois E, 2005, IEEE SIGNAL PROC LET, V12, P847, DOI 10.1109/LSP.2005.859503
   Gunturk BK, 2005, IEEE SIGNAL PROC MAG, V22, P44, DOI 10.1109/MSP.2005.1407714
   Hamilton Jr J. F., 1997, US Patent, Patent No. [5,629,734, 5629734]
   Huang YH, 2018, MULTIMED TOOLS APPL, V77, P1475, DOI 10.1007/s11042-016-4326-x
   Jeon G, 2013, IEEE T IMAGE PROCESS, V22, P146, DOI 10.1109/TIP.2012.2214041
   Kim J, 2014, OPT COMMUN, V324, P194, DOI 10.1016/j.optcom.2014.03.021
   Leung B, 2011, IEEE T IMAGE PROCESS, V20, P1885, DOI 10.1109/TIP.2011.2107524
   Li JSJ, 2009, IEEE T IMAGE PROCESS, V18, P1946, DOI 10.1109/TIP.2009.2022291
   Lian NX, 2007, IEEE T IMAGE PROCESS, V16, P2515, DOI 10.1109/TIP.2007.904459
   Lukac R, 2005, IEEE T CIRC SYST VID, V15, P1475, DOI 10.1109/TCSVT.2005.856923
   Menon D, 2007, IEEE T IMAGE PROCESS, V16, P132, DOI 10.1109/TIP.2006.884928
   Menon D, 2009, IEEE T IMAGE PROCESS, V18, P2209, DOI 10.1109/TIP.2009.2025092
   Pei SC, 2003, IEEE T CIRC SYST VID, V13, P503, DOI 10.1109/TCSVT.2003.813422
   Pekkucuksen I, 2013, IEEE T IMAGE PROCESS, V22, P157, DOI 10.1109/TIP.2012.2210726
   Pekkucuksen I, 2012, IEEE T IMAGE PROCESS, V21, P393, DOI 10.1109/TIP.2011.2155073
   Sadeghipoor Z, 2011, IEEE IMAGE PROC, DOI 10.1109/ICIP.2011.6116339
   Su CY, 2009, IEEE T CONSUM ELECTR, V55, P199, DOI 10.1109/TCE.2009.4814435
   Wang J, 2017, IEEE SENS J, V17, P726, DOI 10.1109/JSEN.2016.2623422
   Zhang L, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3600632
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang X., 1997, Journal of the Society for Information Display, V5, P61, DOI 10.1889/1.1985127
NR 24
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8367
EP 8378
DI 10.1007/s11042-018-7120-0
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600003
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Liu, DF
   Yang, GW
   Hu, L
AF Zhang, Yan
   Liu, Defu
   Yang, Guowu
   Hu, Lin
TI Quantization-based hashing with optimal bits for efficient
   recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender system; Quantization-based hashing; Recommendation
   efficiency; Matrix factorization
AB Recommendation technique has been widely applied in e-commerce systems, but the efficiency becomes challenging due to the growing scale of users and items. In recent years, several hashing-based recommendation frameworks were proposed to solve the efficiency issue successfully by representing users and items with binary codes. These hashing methods consist of two types: two-stage hashing and learning-based hashing. In this paper, we focus on putting forward to a two-stage hashing called quantization-based hashing (QBH) to alleviate the efficiency bottleneck and improve the recommendation accuracy as well. To be specific, we propose the QBH that consists of similarity quantization and norm quantization. To improve the accuracy performance, we search the optimal bits of quantization by minimizing a quantization loss function. We finally evaluate the proposed method on three public datasets to show its superiority on recommendation accuracy over other two-stage hashing methods and advantage on recommendation efficiency over the state-of-the-art recommender systems.
C1 [Zhang, Yan; Liu, Defu; Yang, Guowu] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Qingshuihe Campus 2006,Xiyuan Ave, Chengdu 611731, Sichuan, Peoples R China.
   [Hu, Lin] Chongqing Univ Posts & Telecommun, Sch Commun & Informat Engn, Key Lab Mobile Commun, Chongqing 400065, Peoples R China.
C3 University of Electronic Science & Technology of China; Chongqing
   University of Posts & Telecommunications
RP Yang, GW (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Qingshuihe Campus 2006,Xiyuan Ave, Chengdu 611731, Sichuan, Peoples R China.
EM yixianqianzy@gmail.com; gxdefu@gmail.com; guowu@uestc.edu.cn;
   lin.hu@ieee.org
RI ; Hu, Lin/L-7286-2017
OI Zhang, Yan/0000-0003-1585-0801; Hu, Lin/0000-0003-1711-4971
FU National Natural Science Foundation of China [61572109, 61801060]
FX This work is supported by National Natural Science Foundation of China
   (Grant No. 61572109, 61801060).
CR [Anonymous], 2014, ARXIV14082927
   [Anonymous], 2009, P 17 ACM INT C MULT
   [Anonymous], IEEE T IND ELECT
   [Anonymous], 2018, PATTERN RECOGNITION
   [Anonymous], 2016, ADV MATER SCI ENG
   Baltrunas L., 2011, P 5 ACM C REC SYST, P301, DOI DOI 10.1145/2043932.2043988
   Cheng C., 2012, P AAAI C ART INT, P17
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Hanhuai Shan, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P1025, DOI 10.1109/ICDM.2010.116
   Håstad J, 2001, J ACM, V48, P798, DOI 10.1145/502090.502098
   Hu YF, 2008, IEEE DATA MINING, P263, DOI 10.1109/ICDM.2008.22
   Jamali M., 2010, P 4 ACM C REC SYST, P135, DOI DOI 10.1145/1864708.1864736
   Koren Y, 2011, RECOMMENDER SYSTEMS HANDBOOK, P145, DOI 10.1007/978-0-387-85820-3_5
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Lan XY, 2019, IEEE ACCESS, V7, P67761, DOI 10.1109/ACCESS.2019.2916895
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lian DF, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P831, DOI 10.1145/2623330.2623638
   Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344
   Ma C, 2016, PATTERN RECOGN LETT, V69, P62, DOI 10.1016/j.patrec.2015.09.019
   Ma Hao, 2008, P CIKM08 C INFORM KN, P931
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Zhang H., 2016, Proceedings of SIGIR'16, V16
   Zhang Y, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2758, DOI 10.1145/3219819.3220116
   Zhang Y, 2017, AAAI CONF ARTIF INTE, P1669
   Zhang YaNan Zhang YaNan, 2017, Evidence-based Complementary and Alternative Medicine, V2017, P6268378, DOI 10.1155/2017/6268378
   Zhang ZW, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P183, DOI 10.1145/2600428.2609578
   Zhou H., 2012, P 18 ACM SIGKDD INT, P498
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
NR 31
TC 0
Z9 0
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33907
EP 33924
DI 10.1007/s11042-020-08705-z
EA MAR 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000521787600002
DA 2024-07-18
ER

PT J
AU Noorizadeh, N
   Kazemi, K
   Danyali, H
   Babajani-Feremi, A
   Aarabi, A
AF Noorizadeh, Negar
   Kazemi, Kamran
   Danyali, Habibollah
   Babajani-Feremi, Abbas
   Aarabi, Ardalan
TI Multi-atlas based neonatal brain extraction using atlas library
   clustering and local label fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neonatal brain MRI; Brain extraction; Multi-atlas; Affinity propagation;
   Label fusion; Jacobian determinant
ID SKULL-STRIPPING METHOD; LEVEL SET; SEGMENTATION; IMAGE; MODEL
AB Brain extraction is one of the most important preprocessing steps in cerebral magnetic resonance (MR) image analysis. Brain extraction from neonatal MR images is particularly challenging due to significant differences in head size and shape between neonates and rapid changes in neonatal brain structure in the weeks and months after birth. In this work, a multi-atlas-based neonatal brain extraction method using atlas library clustering and local label fusion (NOBELL) is presented. In NOBELL, an affinity propagation (AP) approach is first applied to cluster images of an atlas library into clusters represented by exemplars, which are used to select best matching clusters for target images. A local weighted voting strategy based on Jacobian determinant ranking is then employed to extract brain from target images using training images in best matching clusters. The performance of NOBELL was evaluated on T2- and T1-weighted scans of 40 neonates aged between 37 and 44 weeks. NOBELL outperformed two popular brain extraction tools, FSL's Brain Extraction Tool (BET) and BrainSuite's Brain Surface Extractor (BSE), and achieved higher accuracy with brain masks very close to manually extracted ones. NOBELL showed an average Jaccard coefficient of 0.974 (0.942) on T2 (T1)-weighted images in comparison with 0.908 (0.602) and 0.845 (0.762) achieved by BSE, and BET, respectively. NOBELL allows for accurate and efficient brain extraction, a crucial step in brain MRI applications such as accurate brain tissue segmentation and volume estimation as well as accurate cortical surface delineation in neonates.
C1 [Noorizadeh, Negar; Kazemi, Kamran; Danyali, Habibollah] Shiraz Univ Technol, Dept Elect & Elect Engn, Shiraz, Iran.
   [Babajani-Feremi, Abbas] Univ Tennessee, Ctr Hlth Sci, Dept Pediat, Memphis, TN 38163 USA.
   [Babajani-Feremi, Abbas] Univ Tennessee, Ctr Hlth Sci, Dept Anat & Neurobiol, Memphis, TN 38163 USA.
   [Babajani-Feremi, Abbas] Le Bonheur Childrens Hosp, Neurosci Inst, Memphis, TN USA.
   [Aarabi, Ardalan] Univ Hosp Amiens, Univ Res Ctr CURS, Lab Funct Neurosci & Pathol LNFP, EA4559, Amiens, France.
   [Aarabi, Ardalan] Univ Picardie Jules Verne, Fac Med, Amiens, France.
C3 Shiraz University of Technology; University of Tennessee System;
   University of Tennessee Health Science Center; University of Tennessee
   System; University of Tennessee Health Science Center; Universite de
   Picardie Jules Verne (UPJV); CHU Amiens; Universite de Picardie Jules
   Verne (UPJV)
RP Kazemi, K (corresponding author), Shiraz Univ Technol, Dept Elect & Elect Engn, Shiraz, Iran.
EM kazemi@sutech.ac.ir
RI Aarabi, Ardalan/ABA-8108-2020
OI Aarabi, Ardalan/0000-0001-5141-9248; Noorizadeh,
   Negar/0009-0009-5358-8390
FU Cognitive Science and Technology Council (CSTC) of Iran [1896, 3308]; Le
   Bonheur Children's Hospital, Memphis, TN; Children's Foundation Research
   Institute, Memphis, TN; Le Bonheur Associate Board, Memphis, TN
FX This work was supported by the Cognitive Science and Technology Council
   (CSTC) of Iran under grant numbers 1896, 3308 and by Le Bonheur
   Children's Hospital, the Children's Foundation Research Institute, and
   the Le Bonheur Associate Board, Memphis, TN.
CR Aboutanos GB, 1999, IEEE T BIO-MED ENG, V46, P1346, DOI 10.1109/10.797995
   Alansary A, 2016, IEEE J BIOMED HEALTH, V20, P925, DOI 10.1109/JBHI.2015.2415477
   Andermatt S, 2016, LECT NOTES COMPUT SC, V10008, P142, DOI 10.1007/978-3-319-46976-8_15
   Ashburner J., 2014, Wellcome Trust Centre for Neuroimaging
   BRUMMER ME, 1993, IEEE T MED IMAGING, V12, P153, DOI 10.1109/42.232244
   Chang HH, 2009, NEUROIMAGE, V47, P122, DOI 10.1016/j.neuroimage.2009.03.068
   Chiverton J, 2007, COMPUT BIOL MED, V37, P342, DOI 10.1016/j.compbiomed.2006.04.001
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Doshi J, 2013, ACAD RADIOL, V20, P1566, DOI 10.1016/j.acra.2013.09.010
   Fonov V.S., 2009, Neuroimage, pS102, DOI DOI 10.1016/S1053-8119(09)70884-5
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Galdames FJ, 2012, J NEUROSCI METH, V206, P103, DOI 10.1016/j.jneumeth.2012.02.017
   Gao J, 2009, INT S COMP NETW MULT
   Grau V, 2004, IEEE T MED IMAGING, V23, P447, DOI 10.1109/TMI.2004.824224
   Hahn HK, 2000, INT C MED IM COMP CO
   Heckemann RA, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0129211
   Hughes EJ, 2017, MAGN RESON MED, V78, P794, DOI 10.1002/mrm.26462
   Hwang J, 2011, J MAGN RESON IMAGING, V34, P445, DOI 10.1002/jmri.22661
   Jaccard P., 1912, New Phytologist, V11, P37, DOI [10.1111/j.1469-8137.1912.tb05611.x, DOI 10.1111/J.1469-8137.1912.TB05611.X]
   Jenkinson M., 2005, 11 ANN M ORG HUM BRA, V17, P167
   Kalavathi P, 2016, J DIGIT IMAGING, V29, P365, DOI 10.1007/s10278-015-9847-8
   Kalavathi P, 2014, INT J SCI ENG RES, V5
   Kleesiek J, 2016, NEUROIMAGE, V129, P460, DOI 10.1016/j.neuroimage.2016.01.024
   Kobashi S, 2007, IEEE INT C GRAN COMP
   Lemieux L, 1999, SPIE C IM PROC
   Leung KK, 2011, NEUROIMAGE, V55, P1091, DOI 10.1016/j.neuroimage.2010.12.067
   Liu JX, 2009, J NEUROSCI METH, V183, P255, DOI 10.1016/j.jneumeth.2009.05.011
   Makropoulos A, 2018, NEUROIMAGE, V173, P88, DOI 10.1016/j.neuroimage.2018.01.054
   Makropoulos A, 2014, IEEE T MED IMAGING, V33, P1818, DOI 10.1109/TMI.2014.2322280
   Noorizadeh N, 2019, BIOMED SIGNAL PROCES, V54, DOI 10.1016/j.bspc.2019.101602
   Park JG, 2009, NEUROIMAGE, V47, P1394, DOI 10.1016/j.neuroimage.2009.04.047
   Peporte M, 2011, SCAND C IM AN
   Rousseau F, 2011, IEEE T MED IMAGING, V30, P1852, DOI 10.1109/TMI.2011.2156806
   Sadananthan SA, 2010, NEUROIMAGE, V49, P225, DOI 10.1016/j.neuroimage.2009.08.050
   Sandor S, 1997, IEEE T MED IMAGING, V16, P41, DOI 10.1109/42.552054
   Serag A, 2016, SCI REP-UK, V6, DOI 10.1038/srep23470
   Shattuck DW, 2001, NEUROIMAGE, V13, P856, DOI 10.1006/nimg.2000.0730
   Shi F, 2012, NEUROIMAGE, V62, P1975, DOI 10.1016/j.neuroimage.2012.05.042
   Smith SM, 2002, HUM BRAIN MAPP, V17, P143, DOI 10.1002/hbm.10062
   Somasundaram K, 2010, COMPUT BIOL MED, V40, P811, DOI 10.1016/j.compbiomed.2010.08.004
   Somasundaram K, 2010, INT C COMP COMM NETW
   Somasundaram K, 2011, P ICOM11 TIR TAM NAD
   Somasundaram K, 2010, NAT C IM PROC
   Tripathi S, 2018, P INT C REC INN APPL
   Tustison NJ, 2010, IEEE T MED IMAGING, V29, P1310, DOI 10.1109/TMI.2010.2046908
   Valente J, 2018, J NEUROSCI METH, V295, P129, DOI 10.1016/j.jneumeth.2017.12.006
   van Opbroek A, 2013, MICCAI GRAND CHALL M
   Wang Y, 2011, INT C MED IM COMP CO
   Yu HP, 2019, MULTIMED TOOLS APPL, V78, P11779, DOI 10.1007/s11042-018-6735-5
   Yu HP, 2018, MULTIMED TOOLS APPL, V77, P24097, DOI 10.1007/s11042-018-5697-y
   Yunjie C, 2009, NEW FAST CHINESE VIS
   Zabihzadeh M, 2017, INT J PEDIATR-MASSHA, V5, P4561, DOI 10.22038/ijp.2017.22292.1864
NR 52
TC 2
Z9 2
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19411
EP 19433
DI 10.1007/s11042-020-08749-1
EA MAR 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000521673400001
DA 2024-07-18
ER

PT J
AU Li, H
   Deng, LB
   Gu, ZQ
AF Li, Hao
   Deng, Lianbing
   Gu, Zhaoquan
TI An image encryption scheme based on precision limited chaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; PWLCM; Logistic map; Security analysis; Noise
   tolerance
ID ALGORITHM; PERMUTATION; CIPHER
AB In recent years, various chaotic maps have been used for image encryption. However, most of these image encryption algorithms entail a lot of floating-point operations, which slows encryption and increases the difficulty of hardware implementation. In this paper, a 32-bit precision limited piecewise linear & logistic chaotic map called 32-bit PL_PWL&LCM for short is proposed. The proposed system has excellent chaotic characteristics, is easy to realize and does not require long time for initialization. Based on the 32-bit PL_PWL&LCM, an image encryption system is proposed. Security analysis indicates that the proposed IES is robust against statistical attacks, differential attacks and brute force attacks with just one round of encryption. Performance analysis shows that the IES is a fast encryption algorithm with good performance in resisting noise disturbances.
C1 [Li, Hao; Deng, Lianbing] Da Hengqin Sci & Technol Dev Co Ltd, Zhuhai 519000, Peoples R China.
   [Gu, Zhaoquan] Guangzhou Univ, CIAT, Guangzhou 510006, Peoples R China.
C3 Guangzhou University
RP Gu, ZQ (corresponding author), Guangzhou Univ, CIAT, Guangzhou 510006, Peoples R China.
EM cuclihao@cuc.edu.cn; denglb@dhqtech.com; zqgu@gzhu.edu.cn
FU National Key R&D Program of China [2019YFB1706003]; China Postdoctoral
   Science Foundation [2019 M663358]; National Natural Science Foundation
   of China [61902082, U1636215]
FX We thank the anonymous reviewers for their very helpful comments that
   helped improve the presentation of this paper. This work is supported in
   part by National Key R&D Program of China 2019YFB1706003, China
   Postdoctoral Science Foundation 2019 M663358, National Natural Science
   Foundation of China 61902082 and China grant U1636215.
CR Abd El-Latif AA, 2014, MULTIMED TOOLS APPL, V70, P1559, DOI 10.1007/s11042-012-1173-2
   Abd El-Latif AA, 2013, SIGNAL PROCESS, V93, P2986, DOI 10.1016/j.sigpro.2013.03.031
   Ahmad J, 2018, NEURAL COMPUT APPL, V30, P3847, DOI 10.1007/s00521-017-2970-3
   Aljawarneh S, 2018, MULTIMED TOOLS APPL, V77, P10997, DOI 10.1007/s11042-017-4873-9
   Aljawarneh S, 2017, MULTIMED TOOLS APPL, V76, P22703, DOI 10.1007/s11042-016-4333-y
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Barakat ML, 2014, IET IMAGE PROCESS, V8, P33, DOI 10.1049/iet-ipr.2012.0586
   Belazi A, 2017, OPTIK, V130, P1438, DOI 10.1016/j.ijleo.2016.11.152
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   BENATTI F, 1991, LETT MATH PHYS, V21, P157, DOI 10.1007/BF00401650
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   El Assad S, 2016, SIGNAL PROCESS-IMAGE, V41, P144, DOI 10.1016/j.image.2015.10.004
   Hamidouche W, 2017, SIGNAL PROCESS-IMAGE, V58, P73, DOI 10.1016/j.image.2017.06.007
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hua ZY, 2017, INFORM SCIENCES, V396, P97, DOI 10.1016/j.ins.2017.02.036
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Huang FJ, 2005, CHAOS SOLITON FRACT, V23, P1893, DOI 10.1016/j.chaos.2004.07.031
   Joshi M, 2008, OPT COMMUN, V281, P5713, DOI 10.1016/j.optcom.2008.08.024
   L'Ecuyer P, 2007, ACM T MATH SOFTWARE, V33, DOI 10.1145/1268776.1268777
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Mondal B, 2018, MULTIMED TOOLS APPL, V77, P31177, DOI 10.1007/s11042-018-6214-z
   Muhammad K, 2018, IEEE T IND INFORM, V14, P3679, DOI 10.1109/TII.2018.2791944
   Murillo-Escobar MA, 2015, SIGNAL PROCESS, V109, P119, DOI 10.1016/j.sigpro.2014.10.033
   Nagaraj N, 2012, COMMUN NONLINEAR SCI, V17, P4029, DOI 10.1016/j.cnsns.2012.03.020
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Ping P, 2018, NEUROCOMPUTING, V283, P53, DOI 10.1016/j.neucom.2017.12.048
   Rhouma R, 2009, 2009 6 INT MULTICONF, P1
   Sys M, 2015, ROM J INF SCI TECH, V18, P18
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P6229, DOI 10.1007/s11042-016-3311-8
   Wang XY, 2014, NONLINEAR DYNAM, V75, P345, DOI 10.1007/s11071-013-1070-x
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Zhou GM, 2015, NEUROCOMPUTING, V169, P150, DOI 10.1016/j.neucom.2014.11.095
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
   Zhou Y., 2012, IEEE T CYBERNETICS, V45, P2001, DOI DOI 10.1109/TCYB.2014.2363168
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 40
TC 4
Z9 4
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19387
EP 19410
DI 10.1007/s11042-020-08826-5
EA MAR 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000520914100001
DA 2024-07-18
ER

PT J
AU Morampudi, MK
   Prasad, MVNK
   Raju, USN
AF Morampudi, Mahesh Kumar
   Prasad, Munaga V. N. K.
   Raju, U. S. N.
TI Privacy-preserving iris authentication using fully homomorphic
   encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric authentication; Homomorphic encryption; Rotation-invariant;
   Batching scheme
ID BIOMETRICS
AB Rapid advancement in technology has led to the use of biometric authentication in every field. In particular, from the past few years, iris recognition systems has gained overwhelming advancement over other biometric traits due to its stability and uniqueness. Directly storing the templates into a centralized server leads to privacy concerns. Many state-of-the-art iris authentication systems based on cancelable biometrics and bio-cryptosystems have been introduced to provide security for the iris templates. However, these works suffer from accuracy loss relative to unprotected systems, or they require auxiliary data (AD), which compromise the privacy of the templates and security of the system. To address this, we propose a novel privacy-preserving iris authentication using fully homomorphic encryption which ensures the confidentiality of the templates and restricts the leakage of data from the templates. Our method improves the recognition accuracy by generating rotation invariant iris codes and reduces the computational time by using the batching scheme. Our approach satisfies all the requirements specified in the ISO/IEC 24745 standard. The proposed method has experimented on four benchmark publicly available iris databases which illustrate that our method can be practically achievable with no loss in the accuracy and preserve the privacy of the iris templates. Our method encrypts and computes the Hamming distance of 2560-dimensional iris features in about 0.0185 seconds only with an equal error rate value of 0.19% for CASIA-V 1.0 database.
C1 [Morampudi, Mahesh Kumar; Prasad, Munaga V. N. K.] Inst Dev & Res Banking Technol, Rd 1,Castle Hills, Hyderabad 500057, India.
   [Morampudi, Mahesh Kumar; Raju, U. S. N.] Natl Inst Technol, Warangal 506004, Telangana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Warangal
RP Morampudi, MK (corresponding author), Inst Dev & Res Banking Technol, Rd 1,Castle Hills, Hyderabad 500057, India.; Morampudi, MK (corresponding author), Natl Inst Technol, Warangal 506004, Telangana, India.
EM mmahesh@idrbt.ac.in
RI Raju, U S N/AAN-7582-2020
OI Raju, U S N/0000-0003-1049-7949; Prasad, MVNK/0000-0002-5560-7649;
   morampudi, mahesh/0000-0002-6888-4637
CR Abidin A, 2016, LECT NOTES COMPUT SC, V10052, P284, DOI 10.1007/978-3-319-48965-0_17
   [Anonymous], 2016, Handbook of iris recognition
   [Anonymous], 2018, 247452011I ISOIEC
   Bami M, 2019, IET BIOMETRICS, V8, P411, DOI 10.1049/iet-bmt.2018.5138
   Barni M, 2010, LINGUISTIC LANDSCAPE IN THE CITY, P3
   Barpanda SS, 2018, MULTIMED TOOLS APPL, V77, P7637, DOI 10.1007/s11042-017-4668-z
   Bianchi T, 2010, P IEEE WORKSH BIOM M, P15
   Blanton M, 2011, LECT NOTES COMPUT SC, V6879, P190, DOI 10.1007/978-3-642-23822-2_11
   Boddeti V. N., 2018, P IEEE 9 INT C BIOM, P1
   Boneh D, 2005, LECT NOTES COMPUT SC, V3378, P325
   Brakerski Z, 2013, LECT NOTES COMPUT SC, V7778, P1, DOI 10.1007/978-3-642-36362-7_1
   Catalano D, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1518, DOI 10.1145/2810103.2813624
   Cheon J.H., 2016, Cryptology ePrint Archive, Report 2016/421
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Daugman J, 2006, P IEEE, V94, P1927, DOI 10.1109/JPROC.2006.884092
   Dwivedi R, 2017, COMPUT SECUR, V65, P373, DOI 10.1016/j.cose.2016.10.004
   Fan J., 2012, IACR CRYPTOLOGY EPRI, V2012, P144
   Fontaine C, 2007, EURASIP J INF SECUR, DOI 10.1155/2007/13801
   Gad R, 2018, FUTURE GENER COMP SY, V89, P178, DOI 10.1016/j.future.2018.06.020
   Galbally J, 2013, COMPUT VIS IMAGE UND, V117, P1512, DOI 10.1016/j.cviu.2013.06.003
   Gentry Craig, 2009, FULLY HOMOMORPHIC EN, V20
   Gomez-Barrero M, 2018, INFORM FUSION, V42, P37, DOI 10.1016/j.inffus.2017.10.003
   Gomez-Barrero M, 2017, PATTERN RECOGN, V67, P149, DOI 10.1016/j.patcog.2017.01.024
   Hadid A, 2015, IEEE SIGNAL PROC MAG, V32, P20, DOI 10.1109/MSP.2015.2437652
   Halevi S, 2014, 2014039 CRYPT EPRINT
   Im JH, 2016, 2016 IEEE 14TH INTL CONF ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, 14TH INTL CONF ON PERVASIVE INTELLIGENCE AND COMPUTING, 2ND INTL CONF ON BIG DATA INTELLIGENCE AND COMPUTING AND CYBER SCIENCE AND TECHNOLOGY CONGRESS (DASC/PICOM/DATACOM/CYBERSC, P878, DOI 10.1109/DASC-PICom-DataCom-CyberSciTec.2016.150
   Jain AK, 2000, IEEE T IMAGE PROCESS, V9, P846, DOI 10.1109/83.841531
   Jain AK, 2007, Handbook of biometrics, DOI DOI 10.1007/978-0-387-71041-9
   Jain AK, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/579416
   Kamlaskar C., 2019, SENSOR LETT, V17, P75, DOI [10.1166/sl.2019.4013, DOI 10.1166/SL.2019.4013]
   Kulkarni R, 2013, INT CONF BIOMETR
   Kumar A, 2010, PATTERN RECOGN, V43, P1016, DOI 10.1016/j.patcog.2009.08.016
   Kumar MM, 2018, P 2018 2 INT C BIOM, P43, DOI DOI 10.1145/3230820.3230828
   Lai YL, 2017, PATTERN RECOGN, V64, P105, DOI 10.1016/j.patcog.2016.10.035
   Liu XM, 2020, IEEE T DEPEND SECURE, V17, P898, DOI 10.1109/TDSC.2018.2816656
   Soldevila FEL, 2006, IMAFRONTE, P151
   Luo Z, 2014, THESIS
   Lynbashevsky V, 2010, LECT NOTES COMPUT SC, V6110, P1, DOI 10.1145/2535925
   Maiorana E, 2015, IEEE T INF FOREN SEC, V10, P900, DOI 10.1109/TIFS.2014.2384735
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P54, DOI 10.1109/MSP.2015.2434151
   Penn GM, 2014, 2014 INT C BIOM SPEC, P1
   Punithavathi P., 2017, P 6 INT C BIOINF BIO, P94
   Qu Y, 2015, THESIS
   Rathgeb C., 2012, Iris biometrics: from segmentation to template security: Book, V59
   Rathgeb C, 2011, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2011-3
   Sadhya D, 2019, IEEE T INFORM FORENS
   Shoup V, 2003, NUMBER THEORY C LIB
   Simoens K, 2010, P IEEE 4 INT C BIOM, P1
   Smart NP, 2014, DESIGN CODE CRYPTOGR, V71, P57, DOI 10.1007/s10623-012-9720-4
   Soliman RF, 2018, OPT QUANT ELECTRON, V50, DOI 10.1007/s11082-018-1591-0
   Soliman RF, 2019, MULTIMED TOOLS APPL, P1
   Torres WAA, 2015, INT J PERVASIVE COMP, V11, P151, DOI 10.1108/IJPCC-02-2015-0012
   Upmanyu M, 2010, IEEE T INF FOREN SEC, V5, P255, DOI 10.1109/TIFS.2010.2043188
   Venugopalan S, 2011, IEEE T INF FOREN SEC, V6, P385, DOI 10.1109/TIFS.2011.2108288
   Walia GS, 2019, IET BIOMETRICS, V8, P231, DOI 10.1049/iet-bmt.2018.5018
   Yasuda M, 2015, SECUR COMMUN NETW, V8, P2194, DOI 10.1002/sec.1164
   Yin Y, 2011, DECIS ENG, P269
   Zhao DD, 2018, PROC INT SYMP SOFTW, P248, DOI 10.1109/ISSRE.2018.00034
NR 58
TC 28
Z9 29
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19215
EP 19237
DI 10.1007/s11042-020-08680-5
EA MAR 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000520811300001
DA 2024-07-18
ER

PT J
AU Bakkouri, S
   Elyousfi, A
   Hamout, H
AF Bakkouri, Siham
   Elyousfi, Abderrahmane
   Hamout, Hamza
TI Fast CU size and mode decision algorithm for 3D-HEVC intercoding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D-HEVC; Inter prediction; CU size decision; Inter mode decision;
   Structure tensor
ID TEXTURE CORRELATION; VIDEO; EXTENSIONS; MULTIVIEW
AB The 3D High Efficiency Video Coding (3D-HEVC) is an extension of the last 2D video coding generation (HEVC) using the Multi-view Video plus Depth map (MVD) format. In inter-coding process, the 3D-HEVC uses multiples inter prediction modes for each Coding Unit (CU) size. These prediction modes are performed to use all the possible CU sizes to select the one with the least Rate Distortion (RD) cost as the best prediction mode using Lagrange multiplier. It achieved high coding efficiency but it consumes an extremely time coding which limits 3D-HEVC from real-time applications. In this paper, a fast inter prediction mode and CU size decision algorithm is proposed to reduce the complexity of 3D-HEVC inter-coding. This algorithm is based on the homogeneity of CU using structure tensor. An experimental analysis is first performed to study the correlation of the CU complexity with depth levels and prediction modes, then the structure tensor of each CU is extracted to characterize the CU homogeneity, which has strong relationship with coding levels and inter prediction modes. Finally, a fast algorithm is adopted to accomplish an early termination of CU split and skip unnecessary prediction modes. The experimental results demonstrate that the proposed fast algorithm can provide a considerable encoding time-saving with negligible rate-distortion performance loss compared to the original 3D-HEVC encoder.
C1 [Bakkouri, Siham; Hamout, Hamza] Ibn Zohr Univ, Comp Syst & Vis Lab, Fac Sci, Agadir, Morocco.
   [Elyousfi, Abderrahmane] Ibn Zohr Univ, Natl Engn Sch Appl Sci, Dept Comp Sci, Agadir, Morocco.
C3 Ibn Zohr University of Agadir; Ibn Zohr University of Agadir
RP Bakkouri, S (corresponding author), Ibn Zohr Univ, Comp Syst & Vis Lab, Fac Sci, Agadir, Morocco.
EM siham.bakkouri@gmail.com; elyousfiabdo@yahoo.fr; hamzahamout@gmail.com
RI BAKKOURI, Siham/AAY-8778-2021; elyousfi, Abderrahmane/AAO-7542-2021;
   Elyousfi, Abderrahmane/AAY-2726-2021
OI BAKKOURI, Siham/0000-0003-3443-7756; Elyousfi,
   Abderrahmane/0000-0001-6555-2912
CR [Anonymous], 2016, 3D HEVC REFERENCE SO
   Baghaie A, 2015, AEU-INT J ELECTRON C, V69, P515, DOI 10.1016/j.aeue.2014.10.022
   Bjntegaard G, 2001, Document VCEGM33
   Bjntegaard G, 2008, 35 VCEG M BERL
   Chen J, 2019, MULTIMED TOOLS APPL, V78, P29291, DOI 10.1007/s11042-018-6832-5
   Chen M, 2016, OPTIK, V127, P4758, DOI 10.1016/j.ijleo.2016.01.204
   Chowdhury K, 2018, MULTIMED TOOLS APPL, V77, P20889, DOI 10.1007/s11042-017-5429-8
   da Silva TL, 2016, J REAL-TIME IMAGE PR, V12, P357, DOI 10.1007/s11554-015-0533-3
   Faraklioti M, 2005, MATH INDUST, V7, P47, DOI 10.1007/3-540-26493-0_3
   Hamout H, 2020, J REAL-TIME IMAGE PR, V17, P1285, DOI 10.1007/s11554-019-00890-x
   Hamout H, 2019, J REAL-TIME IMAGE PR, V16, P2093, DOI 10.1007/s11554-017-0718-z
   Huang XP, 2017, SIGNAL IMAGE VIDEO P, V11, P33, DOI 10.1007/s11760-016-0887-4
   Lei JJ, 2018, IEEE T CIRC SYST VID, V28, P706, DOI 10.1109/TCSVT.2016.2617332
   Li Y, 2020, J REAL-TIME IMAGE PR, V17, P1227, DOI 10.1007/s11554-019-00876-9
   Li Y, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3267128
   Liao YW, 2019, MULTIMED TOOLS APPL, V78, P10181, DOI 10.1007/s11042-018-6547-7
   Lin JL, 2018, J VIS COMMUN IMAGE R, V50, P83, DOI 10.1016/j.jvcir.2017.11.003
   Müller K, 2013, IEEE T IMAGE PROCESS, V22, P3366, DOI 10.1109/TIP.2013.2264820
   Müller K, 2011, P IEEE, V99, P643, DOI 10.1109/JPROC.2010.2091090
   Muller K, 2014, ITU-T SG 16 WP 3 and ISO/IEC JTC 1/SC 29/WG 11, JCT3v, VG1100, P1
   Park CS, 2015, IEEE T IMAGE PROCESS, V24, P155, DOI 10.1109/TIP.2014.2375653
   Ramezanpour M, 2016, SIGNAL IMAGE VIDEO P, V10, P1233, DOI 10.1007/s11760-016-0885-6
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Sullivan GJ, 2013, IEEE J-STSP, V7, P1001, DOI 10.1109/JSTSP.2013.2283657
   Tanimoto M, 2008, JTC1SC29WG11M16090 I
   Tech G, 2016, IEEE T CIRC SYST VID, V26, P35, DOI 10.1109/TCSVT.2015.2477935
   Tsai TH, 2018, IET IMAGE PROCESS, V12, P644, DOI 10.1049/iet-ipr.2016.1117
   Yang HB, 2015, MULTIMED TOOLS APPL, V74, P6069, DOI 10.1007/s11042-014-1909-2
   Zhang L, 2013, 5 M VIENN AUSTR
   Zhang N, 2014, SIGNAL PROCESS-IMAGE, V29, P951, DOI 10.1016/j.image.2014.06.003
   Zhang QW, 2017, J VIS COMMUN IMAGE R, V45, P170, DOI 10.1016/j.jvcir.2017.03.004
   Zhang QW, 2016, AEU-INT J ELECTRON C, V70, P727, DOI 10.1016/j.aeue.2016.02.008
   Zhang QW, 2015, DIGIT SIGNAL PROCESS, V44, P37, DOI 10.1016/j.dsp.2015.06.005
NR 33
TC 8
Z9 8
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 6987
EP 7004
DI 10.1007/s11042-019-08461-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000523441100004
DA 2024-07-18
ER

PT J
AU Kumar, M
   Chand, S
AF Kumar, Mahender
   Chand, Satish
TI SecP2PVoD: a secure peer-to-peer video-on-demand system against
   pollution attack and untrusted service provider
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Identity-based signcryption; Peer-to-peer communication;
   Bandwidth-efficiency; Video-on-demand streaming; Security
ID CERTIFICATELESS ONLINE/OFFLINE SIGNCRYPTION; ELLIPTIC-CURVES; EFFICIENT;
   PROTOCOL; INTERNET; OVERLAY; SCHEME
AB The Peer-to-Peer video-on-demand (P2P-VoD) streaming has become widespread in recent years. Unlike the traditional client-server model based video-streaming, the P2P-VoD leverages the peer's capacity of upload bandwidth for the delivery of video contents in a distributed network. The P2P environment is susceptible to various security threats, in which the pollution attack is one of the potentially destructive threats. Moreover, video streaming is prone to other security challenges, such as authenticity, confidentiality, authorization, and integrity. There have been discussed four possible protection to the pollution attack: blacklisting, hash verification, traffic encryption, and chunk signing. In this paper, we present escrow-free identity-based signcryption (EF-IDSC) scheme for secure data transmission scheme in P2P-VoD streaming with an untrusted service provider. The proposed system enables a peer to establish a session key with other peer using the asymmetric key algorithm. The security analysis shows that the proposed P2P-VoS system prevents pollution attacks under well-known random oracle model and achieves privacy, confidentiality, and subscriber authentication simultaneously. The experimental evaluation shows that the proposed scheme has better computation and communication costs as compared to the related schemes.
C1 [Kumar, Mahender; Chand, Satish] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi, India.
C3 Jawaharlal Nehru University, New Delhi
RP Kumar, M (corresponding author), Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi, India.
EM Mahendjnu1989@gmail.com; schand@mail.jnu.ac.in
RI Kumar, Mahender/AFO-5969-2022
CR Abomhara Mohamed, 2010, Journal of Applied Sciences, V10, P1656, DOI 10.3923/jas.2010.1656.1661
   [Anonymous], 2010, The Pairing-based Cryptography (PBC) Library
   [Anonymous], 2002, IACR Cryptol. ePrintArch.
   Barbosa M., 2008, P 2008 ACM S INF COM, V3788, P369
   Barreto PSLM, 2006, LECT NOTES COMPUT SC, V3897, P319
   Barreto PSLM, 2004, LECT NOTES COMPUT SC, V3006, P17
   Boneh D, 2003, SIAM J COMPUT, V32, P586, DOI 10.1137/S0097539701398521
   Cao XF, 2010, INFORM SCIENCES, V180, P2895, DOI 10.1016/j.ins.2010.04.002
   Chung YF, 2007, COMPUT STAND INTER, V29, P601, DOI 10.1016/j.csi.2007.01.004
   Dhungel P., 2007, P2P TV PROC WORKSHOP, P323
   Dhungel P., 2009, INT J COMPUT NETWORK, V1, P99
   Do TT, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-7, P1467, DOI 10.1109/ICC.2004.1312755
   Fiandrotti A, 2015, IEEE T MULTIMEDIA, V17, P562, DOI 10.1109/TMM.2015.2402516
   Goh C. Y., 2013, J MULTIMEDIA UBIQUIT, V8, P97, DOI DOI 10.14257/ijmue.2013.8.6.10
   Hammadi A, 2017, CASE STUDY ARCHITECT
   He DB, 2011, ANN TELECOMMUN, V66, P657, DOI 10.1007/s12243-011-0244-0
   Juluri P, 2016, IEEE COMMUN SURV TUT, V18, P401, DOI 10.1109/COMST.2015.2401424
   Kang X, 2014, COMPUT NETW, V72, P62, DOI 10.1016/j.comnet.2014.07.012
   KOBLITZ N, 1987, MATH COMPUT, V48, P203, DOI 10.1090/S0025-5718-1987-0866109-5
   Kumar Mahender, 2017, Information Systems Security. 13th International Conference, ICISS 2017. Proceedings: LNCS 10717, P29, DOI 10.1007/978-3-319-72598-7_3
   Kumar M, 2017, INT C UB COMM NETW C
   Kumar M, 2019, MULTIMED TOOLS APPL, V78, P19753, DOI 10.1007/s11042-019-7155-x
   Lai JC, 2017, INT J INF SECUR, V16, P299, DOI 10.1007/s10207-016-0320-6
   Lee S, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON SOFTWARE SECURITY AND ASSURANCE (ICSSA), P43, DOI 10.1109/ICSSA.2016.15
   Li BC, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2505805
   Li FG, 2017, WIREL NETW, V23, P145, DOI 10.1007/s11276-015-1145-3
   Li F, 2012, J NETW COMPUT APPL, V35, P340, DOI 10.1016/j.jnca.2011.08.001
   Li JG, 2015, SECUR COMMUN NETW, V8, P1979, DOI 10.1002/sec.1146
   Li ZG, 2012, PLANT SCI, V185, P185, DOI 10.1016/j.plantsci.2011.10.006
   Liang J, 2006, COMPUT NETW, V50, P842, DOI 10.1016/j.comnet.2005.07.014
   Liang JA, 2005, LECT NOTES COMPUT SC, V3837, P1
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu JK, 2010, LNCS, V6584, P36
   Liu Y, 2008, PEER PEER NETW APPL, V1, P18, DOI 10.1007/s12083-007-0006-y
   Lu H, 2014, IEEE T PARALL DISTR, V25, P750, DOI 10.1109/TPDS.2013.43
   Luo M, 2014, SECUR COMMUN NETW, V7, P1560, DOI 10.1002/sec.836
   Magharei N, 2009, IEEE ACM T NETWORK, V17, P1052, DOI 10.1109/TNET.2008.2007434
   Medina-Lopez C, 2016, INT C INT SYST DES A, P144
   Miller V, ADV CRYPTOL, V85, P417
   Omala AA, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0615-1
   Picconi F, 2008, IEEE INT CONF PEER, P289, DOI 10.1109/P2P.2008.18
   Ramzan N, 2012, SIGNAL PROCESS-IMAGE, V27, P401, DOI 10.1016/j.image.2012.02.004
   Saeed MES, 2017, WIREL NETW, V24, P1, DOI [10.1007/s10776-016-0324-1, DOI 10.1007/S10776-016-0324-1]
   Selvi S. S. D, 2010, CRYPTOL EPRINT ARCH, V2010, P376
   Shamir A., 1985, Advances in Cryptology, V84 4, P47, DOI 10.1007/3-540-39568-7_5
   Shen ZJ, 2011, P IEEE, V99, P2089, DOI 10.1109/JPROC.2011.2165330
   Shi WB, 2015, PEER PEER NETW APPL, V8, P881, DOI 10.1007/s12083-014-0249-3
   Shim KA, 2013, AD HOC NETW, V11, P182, DOI 10.1016/j.adhoc.2012.04.015
   Sun DD, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL SYMPOSIUM ON PARALLEL AND DISTRIBUTED PROCESSING WITH APPLICATIONS, P707, DOI 10.1109/ISPA.2008.16
   Sun DD, 2008, IFIP INT C NETW PARA, P34, DOI 10.1109/NPC.2008.12
   Wang HZ, 2018, IET COMMUN, V12, P2119, DOI 10.1049/iet-com.2018.5069
   Xiang L, 2018, IEEE T WIREL COMMUN, V17, P736, DOI 10.1109/TWC.2017.2770097
   Yeh HL, 2011, SENSORS-BASEL, V11, P4767, DOI 10.3390/s110504767
   Zheng YL, 1997, LECT NOTES COMPUT SC, V1294, P165
NR 55
TC 3
Z9 4
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6163
EP 6190
DI 10.1007/s11042-019-08330-5
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900033
DA 2024-07-18
ER

PT J
AU Morillo, P
   Garcia-Garcia, I
   Orduna, JM
   Fernandez, M
   Juan, MC
AF Morillo, Pedro
   Garcia-Garcia, Inmaculada
   Orduna, Juan M.
   Fernandez, Marcos
   Carmen Juan, M.
TI Comparative study of AR versus video tutorials for minor maintenance
   operations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented Reality; Comparative study; Real user study; Multimedia-based
   learning; Equipment maintenance
ID AUGMENTED REALITY APPLICATIONS; VIRTUAL-REALITY; PERFORMANCE; SYSTEMS;
   DESIGN
AB Augmented Reality (AR) has become a mainstream technology in the development of solutions for repair and maintenance operations. Although most of the AR solutions are still limited to specific contexts in industry, some consumer electronics companies have started to offer pre-packaged AR solutions as alternative to video-based tutorials (VT) for minor maintenance operations. In this paper, we present a comparative study of the acquired knowledge and user perception achieved with AR and VT solutions in some maintenance tasks of IT equipment. The results indicate that both systems help users to acquire knowledge in various aspects of equipment maintenance. Although no statistically significant differences were found between AR and VT solutions, users scored higher on the AR version in all cases. Moreover, the users explicitly preferred the AR version when evaluating three different usability and satisfaction criteria. For the AR version, a strong and significant correlation was found between the satisfaction and the achieved knowledge. Since the AR solution achieved similar learning results with higher usability scores than the video-based tutorials, these results suggest that AR solutions are the most effective approach to substitute the typical paper-based instructions in consumer electronics.
C1 [Morillo, Pedro; Orduna, Juan M.; Fernandez, Marcos] Univ Valencia, Dept Informat, Valencia, Spain.
   [Garcia-Garcia, Inmaculada; Carmen Juan, M.] Univ Politecn Valencia, DSIC, Valencia, Spain.
C3 University of Valencia; Universitat Politecnica de Valencia
RP Orduna, JM (corresponding author), Univ Valencia, Dept Informat, Valencia, Spain.
EM ingarcia@dsic.upv.es; Juan.Orduna@uv.es
RI Morillo, Pedro/ABG-8408-2020; Orduña, Juan M./AAB-5732-2020; Juan,
   M.-Carmen/I-3585-2015; Fernández, Marcos/JDC-9198-2023
OI Orduña, Juan M./0000-0002-2932-0214; Morillo, Pedro/0000-0002-9506-9611;
   Fernandez Marin, Marcos/0000-0002-0307-0392; Juan,
   M.-Carmen/0000-0002-8764-1470
CR Ahn J, 2015, ACM T MULTIM COMPUT, V12, DOI 10.1145/2808207
   Anderson TW, 2011, Int Encycl Stat Sci, V1, P52, DOI DOI 10.1007/978-3-642-04898-2_118
   Arino JJ, 2014, BEHAV INFORM TECHNOL, V33, P646, DOI 10.1080/0144929X.2013.815277
   Awad N, 2015, US Patent App, Patent No. [14/829,382, 14829382]
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Baird K. M., 1999, Virtual Reality, V4, P250, DOI 10.1007/BF01421808
   Ballo P, 2018, AUGMENTED VIRTUAL RE, P45
   Barrile V, 2018, APPL GEOMAT, V10, P569, DOI 10.1007/s12518-018-0231-5
   Billinghurst M, 2012, COMPUTER, V45, P56, DOI 10.1109/MC.2012.111
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Brown TA., 2006, CONFIRMATORY FACTOR, DOI DOI 10.19030/AJBE.V6I3.7818
   Dodge Y, 2008, KRUSKAL WALLIS TEST, DOI [10.1007/978-0-387-32833-1_216, DOI 10.1007/978-0-387-32833-1_216]
   Elmunsyah H., 2019, Journal of Physics: Conference Series, V1193, DOI 10.1088/1742-6596/1193/1/012031
   Entertainment L, 2017, DOLPHIN PLAYER
   Fletcher JD, 2017, MODSIM MOD SIM SYST
   Fraga-Lamas P, 2018, IEEE ACCESS, V6, P13358, DOI 10.1109/ACCESS.2018.2808326
   Furió D, 2015, J COMPUT ASSIST LEAR, V31, P189, DOI 10.1111/jcal.12071
   Gavish N, 2015, INTERACT LEARN ENVIR, V23, P778, DOI 10.1080/10494820.2013.815221
   Gimeno J, 2013, COMPUT IND, V64, P1263, DOI 10.1016/j.compind.2013.06.012
   Holzinger A, 2008, EDUC TECHNOL SOC, V11, P279
   Hornbak Kasper, 2011, Foundations and Trends in Human-Computer Interaction, V5, P299, DOI 10.1561/1100000043
   Huang JS, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2632165
   Jiang SH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3152114
   Kim SK, 2017, KSII T INTERNET INF, V11, P982, DOI 10.3837/tiis.2017.02.019
   Langlotz T., 2012, Proceedings of the 24th Australian Computer-Human Interaction Conference, P318, DOI DOI 10.1145/2414536.2414588
   Martin-SanJose JF, 2017, INTERACT LEARN ENVIR, V25, P17, DOI 10.1080/10494820.2015.1090455
   MASSEY FJ, 1951, J AM STAT ASSOC, V46, P68, DOI 10.2307/2280095
   Mestre LS, 2012, REF SERV REV, V40, P258, DOI 10.1108/00907321211228318
   Mohr P, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6547, DOI 10.1145/3025453.3025688
   Mohr P, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3337, DOI 10.1145/2702123.2702490
   Montgomery D. C., 2003, Applied statistics and probability for engineers, V3rd ed.)
   Morillo P, 2019, MULTIMEDIA SYST, V25, P307, DOI 10.1007/s00530-019-00606-y
   Morse JM, 2000, QUAL HEALTH RES, V10, P3, DOI 10.1177/104973200129118183
   Munoz-Montoya F, 2019, IEEE ACCESS, V7, P2453, DOI 10.1109/ACCESS.2018.2886627
   Neuhauser M., 2001, WILCOXON MANN WHITNE, P1656, DOI [DOI 10.1007/978-3-642-04898-2_615, 10.1007/978-3-642-04898-2_615]
   Neumann U, 1998, P IEEE VIRT REAL ANN, P4, DOI 10.1109/VRAIS.1998.658416
   Palmarini R, 2018, ROBOT CIM-INT MANUF, V49, P215, DOI 10.1016/j.rcim.2017.06.002
   Quint F, 2015, MENSCH COMPUTER 2015
   Radkowski R, 2015, INT J HUM-COMPUT INT, V31, P337, DOI 10.1080/10447318.2014.994194
   Regenbrecht H., 2002, Measuring presence in augmented reality environments: design and a first test of a questionnaire
   Robertson J, 2012, COMMUN ACM, V55, P6, DOI 10.1145/2160718.2160721
   Rodríguez-Andrés D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0161858
   Sanna A, 2015, I SYMP CONSUM ELECTR, P178, DOI 10.1109/ICCE.2015.7066370
   Schmidt S., 2018, 2018 10 INT C QUALIT, DOI DOI 10.1109/QOMEX.2018.8463389
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.1093/biomet/52.3-4.591
   Tang A., 2003, COMP EFFECTIVENESS A, P73, DOI [10.1145/642611.642626, DOI 10.1145/642611.642626]
   Tomás JM, 2013, STRUCT EQU MODELING, V20, P299, DOI 10.1080/10705511.2013.769394
   Uva AE, 2018, INT J ADV MANUF TECH, V94, P509, DOI 10.1007/s00170-017-0846-4
   van der Meij H, 2018, ETR&D-EDUC TECH RES, V66, P597, DOI 10.1007/s11423-017-9560-z
   van der Meij J, 2015, J COMPUT ASSIST LEAR, V31, P116, DOI 10.1111/jcal.12082
   Wang X, 2016, ADV MANUF, V4, P1, DOI 10.1007/s40436-015-0131-4
   Westerfield G, 2015, INT J ARTIF INTELL E, V25, P157, DOI 10.1007/s40593-014-0032-x
   Wiedenmaier S, 2003, INT J HUM-COMPUT INT, V16, P497, DOI 10.1207/S15327590IJHC1603_7
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wu HK, 2013, COMPUT EDUC, V62, P41, DOI 10.1016/j.compedu.2012.10.024
   Yim MYC, 2017, J INTERACT MARK, V39, P89, DOI 10.1016/j.intmar.2017.04.001
   Yuan ML, 2008, INT J PROD RES, V46, P1745, DOI 10.1080/00207540600972935
NR 57
TC 8
Z9 9
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7073
EP 7100
DI 10.1007/s11042-019-08437-9
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000523441100008
OA Green Published
DA 2024-07-18
ER

PT J
AU Fadl, S
   Megahed, A
   Han, Q
   Qiong, L
AF Fadl, Sondos
   Megahed, Amr
   Han, Qi
   Qiong, Li
TI Frame duplication and shuffling forgery detection technique in
   surveillance videos based on temporal average and gray level
   co-occurrence matrix
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Passive forensics; Authenticity; Temporal average; Forgery detection;
   Gray level co-occurrence matrix
ID DIGITAL IMAGES; LOCALIZATION
AB Nowadays, due to the increasing crime and theft around the world, surveillance security systems play an important role. On the other hand, the availability of video editing tools has made authenticity of video contents significant and urgent mission to use as strong evidence in the courts. Frame duplication with/without shuffling is a common form of video forgery to repeat or cover-up an event in a video's scene. In this paper, we propose a robust method to detect inter-frame duplication forgery using a temporal average of each shot and statistical textural features. Duplicated shots containing frames that are reordered during the forgery process (frame shuffling), cannot be classified as tampered shots by the existing methods leading to an increase in false positives. To address this issue, we use a temporal average of each shot which found to be invariant with different orders. Our method is capable of detecting duplicate shots that do not have any tracing points (discontinuity points). Experimental results show that our method has achieved improved accuracy on frame duplication detection with lower computational time. Furthermore, it has successfully detected frame shuffling with high accuracy rates, even when the forged video has undergone post-processing operations such as Gaussian blurring, noise addition, brightness modification, and compression.
C1 [Fadl, Sondos; Megahed, Amr; Han, Qi; Qiong, Li] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150080, Peoples R China.
   [Fadl, Sondos] Menoufia Univ, Fac Comp & Informat, Shibin Al Kawm 32511, Egypt.
C3 Harbin Institute of Technology; Egyptian Knowledge Bank (EKB); Menofia
   University
RP Han, Q (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150080, Peoples R China.
EM sondos.magdy@ci.menofia.edu.eg; qi.han@hit.edu.cn
RI Fadl, Sondos/M-2227-2019
OI Fadl, Sondos/0000-0003-0123-2180
FU National Natural Science Foundation of China [61471141, 61361166006,
   61301099]; Key Technology Program of Shenzhen, China
   [JSGG20160427185010977]; Basic Research Project of Shenzhen, China
   [JCYJ20150513151706561]
FX This work was supported by the National Natural Science Foundation of
   China [grant numbers 61471141, 61361166006, 61301099]; Key Technology
   Program of Shenzhen, China, [grant number JSGG20160427185010977]; Basic
   Research Project of Shenzhen, China [grant number
   JCYJ20150513151706561].
CR [Anonymous], 1993, Multimedia Systems, DOI DOI 10.1007/BF01210504
   Bakas J, 2019, MULTIMED TOOLS APPL, V78, P4905, DOI 10.1007/s11042-018-6570-8
   Baudry S, 2009, IEEE IMAGE PROC, P2889, DOI 10.1109/ICIP.2009.5413438
   Baudry Severine, 2012, P ACM MULT SEC WORKS, P19
   Bharati MH, 2004, CHEMOMETR INTELL LAB, V72, P57, DOI 10.1016/j.chemolab.2004.02.005
   Boreczky JS, 1996, J ELECTRON IMAGING, V5, P122, DOI 10.1117/12.238675
   Cuevas C, 2016, COMPUT VIS IMAGE UND, V152, P103, DOI 10.1016/j.cviu.2016.08.005
   Dugad R, 1998, 1998 IEEE SECOND WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P376, DOI 10.1109/MMSP.1998.738965
   Elaskily MA, 2019, MULTIMED TOOLS APPL, V78, P15353, DOI 10.1007/s11042-018-6891-7
   Emam M, 2016, MULTIMED TOOLS APPL, V75, P11513, DOI 10.1007/s11042-015-2872-2
   Fadl S, 2019, LECT NOTES COMPUT SC, V11378, P337, DOI 10.1007/978-3-030-11389-6_25
   Fadl SM, 2018, J FORENSIC SCI, V63, P1099, DOI 10.1111/1556-4029.13658
   Fadl SM, 2017, NEUROCOMPUTING, V265, P57, DOI 10.1016/j.neucom.2016.11.091
   Guo-Shiang Lin, 2011, 2011 6th International Conference on Computer Science & Education (ICCSE 2011), P1396, DOI 10.1109/ICCSE.2011.6028891
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Lee JC, 2015, J VIS COMMUN IMAGE R, V31, P320, DOI 10.1016/j.jvcir.2015.07.007
   Li HD, 2017, IEEE T INF FOREN SEC, V12, P1240, DOI 10.1109/TIFS.2017.2656823
   Liao SY, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P864, DOI 10.1109/CISP.2013.6745286
   Lienhart R, 1998, PROC SPIE, V3656, P290, DOI 10.1117/12.333848
   Liu YQ, 2017, MULTIMEDIA SYST, V23, P223, DOI [10.1007/s00530-015-0478-1, 10.1007/s00530-015-0461-x]
   Mahmood T, 2018, J VIS COMMUN IMAGE R, V53, P202, DOI 10.1016/j.jvcir.2018.03.015
   Nixon Mark S, 2012, FEATURE EXTRACTION I, DOI DOI 10.1016/B978-0-12-396549-3.00007-0
   Ouyang JL, 2019, MULTIMED TOOLS APPL, V78, P10207, DOI 10.1007/s11042-018-6605-1
   Priya GGL, 2011, COMM COM INF SC, V157, P161
   Pun CM, 2016, J VIS COMMUN IMAGE R, V38, P195, DOI 10.1016/j.jvcir.2016.03.005
   Qadir Ghulam, 2012, Surrey university library for forensic analysis (SULFA) of video content, P121
   Shi YJ, 2013, OPTIK, V124, P3827, DOI 10.1016/j.ijleo.2012.11.078
   Singh KV, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENGINEERING AND APPLICATIONS (ICACEA), P29, DOI 10.1109/ICACEA.2015.7164708
   Sitara K, 2018, FORENSIC SCI INT, V289, P186, DOI 10.1016/j.forsciint.2018.04.056
   Sitara K, 2016, DIGIT INVEST, V18, P8, DOI 10.1016/j.diin.2016.06.003
   Sohn H, 2011, IEEE T CIRC SYST VID, V21, P170, DOI 10.1109/TCSVT.2011.2106250
   Ulutas G, 2018, MULTIMEDIA SYST, V24, P549, DOI 10.1007/s00530-017-0581-6
   Ulutas G, 2017, IET IMAGE PROCESS, V11, P333, DOI 10.1049/iet-ipr.2016.0321
   Wang W, 2014, LECT NOTES COMPUT SC, V8389, P244, DOI 10.1007/978-3-662-43886-2_18
   Wang WH, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P35
   Yang JM, 2016, MULTIMED TOOLS APPL, V75, P1793, DOI 10.1007/s11042-014-2374-7
   Zabih R., 1995, TECH REP
   Zhang QB, 2016, J VIS COMMUN IMAGE R, V40, P449, DOI 10.1016/j.jvcir.2016.07.013
   Zhang WG, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 3, PROCEEDINGS, P593
   Zhao DN, 2018, MULTIMED TOOLS APPL, V77, P25389, DOI 10.1007/s11042-018-5791-1
   Zheng LY, 2015, PROC IEEE MICR ELECT, P18, DOI 10.1109/MEMSYS.2015.7050875
NR 41
TC 12
Z9 12
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 17619
EP 17643
DI 10.1007/s11042-019-08603-z
EA FEB 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000516363300007
DA 2024-07-18
ER

PT J
AU Alarifi, A
   Tolba, A
   Hassanein, AS
AF Alarifi, Abdulaziz
   Tolba, Amr
   Hassanein, Azza S.
TI Visualization process assisted by the Eulerian video magnification
   algorithm for a heart rate monitoring system: mobile applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Heart rate monitoring; Digital image processing; Visualization process;
   Eulerian video magnification algorithm
AB Medical technology employs a range of different computational methods for analyzing noninvasive heart rate monitoring processes. During the heart rate monitoring process, accurate heart rate detection is difficult which is overcome by applying the effective image processing techniques. Thus, the present study offers a mobile application framework that uses video frames captured from mobile camera. These video frames are analyzed by Eulerian video magnification (EVM) with a region extraction technique for efficiently detecting and monitoring heart rates. Initially, EVM captures the feelings of the subject from a face visualization process. Then, temporal filtering and spatial decomposition methods are applied to reconstruct the video frames. Subtle changes in the face image are extracted from the video frames by applying an enhanced multi-scale segmentation technique. The segmented region from the face helps to identify the intensity level of the green channel feature, which differs from the normal red and blue channel features. This process identifies the hidden heart rate from the region extracted by the EVM visualization process. Finally, system efficiency is evaluated in terms of the estimated heart rate, actual heart rate, and heart rate accuracy. The mobile based video magnification analyzing process reduces mortality rate, and accurately examines heart rates.
C1 [Alarifi, Abdulaziz; Tolba, Amr] King Saud Univ, Community Coll, Comp Sci Dept, Riyadh 11437, Saudi Arabia.
   [Tolba, Amr] Menoufia Univ, Fac Sci, Math & Comp Sci Dept, Shibin Al Kawm 32511, Egypt.
   [Hassanein, Azza S.] Helwan Univ, Fac Engn, Biomed Engn Dept, Helwan 11795, Egypt.
C3 King Saud University; Egyptian Knowledge Bank (EKB); Menofia University;
   Egyptian Knowledge Bank (EKB); Helwan University
RP Hassanein, AS (corresponding author), Helwan Univ, Fac Engn, Biomed Engn Dept, Helwan 11795, Egypt.
EM aza_hassanien@h-eng.helwan.edu.cg
RI Hassanein, Azza/Z-6162-2019; Tolba, Amr/O-8464-2016; Hassanein, Azza
   S/ABC-6558-2021
OI Tolba, Amr/0000-0003-3439-6413; 
CR Abuzaghleh O, 2015, IEEE J TRANSL ENG HE, V3, DOI 10.1109/JTEHM.2015.2419612
   Altameem T, 2016, J MED IMAG HEALTH IN, V6, P1462, DOI 10.1166/jmihi.2016.1831
   Altameem T, 2016, J MED IMAG HEALTH IN, V6, P1451, DOI 10.1166/jmihi.2016.1830
   Altameem T, 2015, CONNECT SCI, V27, P305, DOI 10.1080/09540091.2014.970126
   [Anonymous], INT C MULTT EXP ICME
   [Anonymous], IEEE INT C CONS EL
   [Anonymous], CASE REP OTOLARYNGOL
   [Anonymous], J ACM T GRAPHICS TOG
   [Anonymous], IJCSI INT J COMPUTER
   [Anonymous], INT C COMP ROB VIS C
   Balakrishnan G, 2013, PROC CVPR IEEE, P3430, DOI 10.1109/CVPR.2013.440
   He XC, 2016, 2016 3RD IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL AND HEALTH INFORMATICS, P41, DOI 10.1109/BHI.2016.7455830
   Kamble VG, 2015, J MOL ENG MATER, V3, DOI 10.1142/S2251237315500057
   Khan O, 2017, ADV MATER SCI ENG, V2017, P1, DOI 10.1155/2017/5703291
   Osman Ahmed, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163150
   Poh MZ, 2010, OPT EXPRESS, V18, P10762, DOI 10.1364/OE.18.010762
   Shafqat S, 2020, J SUPERCOMPUT, V76, P1754, DOI 10.1007/s11227-017-2222-4
   Verkruysse W, 2008, OPT EXPRESS, V16, P21434, DOI 10.1364/OE.16.021434
   Vos M.D., 2015, P INT C PATT REC APP, P164
   Wadhwa N, 2017, COMMUN ACM, V60, P87, DOI 10.1145/3015573
   Wang YD, 2017, MULTIMED TOOLS APPL, V76, P21665, DOI 10.1007/s11042-016-4079-6
   Yu YP, 2015, BIOMED OPT EXPRESS, V6, P2466, DOI 10.1364/BOE.6.002466
NR 22
TC 2
Z9 2
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 5149
EP 5160
DI 10.1007/s11042-018-6313-x
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500052
DA 2024-07-18
ER

PT J
AU Govardhan, SD
   Vasuki, A
AF Govardhan, S. D.
   Vasuki, A.
TI Wavelet based iterative deformable part model for pedestrian detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature pyramid; Iterative learning deformable part model; Jaccard
   similarity score; Morlet; Multiresolution analysis; Pedestrian detection
AB Pedestrian detection is one of the challenging tasks in the urban traffic environments. A natural urban traffic environments include different objects like buildings, vehicles, pedestrians and so on. The conventional approach only used for a particular traffic scenario and it does not suitable for different scenarios. A novel approach is required to model these traffic scenarios. Multiresolution Morlet Decomposition Based Iterative Learning Deformable Part Model (MMD-ILDP) is proposed for improving the performance of multiresolution pedestrian detection to control the traffic in the urban area with higher accuracy. The MMD-ILDP Model uses Morlet wavelet transformation for decomposing the image into subbands with multiple resolutions. After wavelet decomposition, histogram of oriented gradients (HOG) feature pyramid is generated. Then, feature matching is performed between the pedestrian objects in the image and the feature pyramid generated with HOG and the root and part scores are computed. Finally, the root and part scores are combined to compute the final score of objects in the image. The performance measures used in evaluating the proposed algorithm are detection accuracy, time and space complexity. The simulation results show that the MMD-ILDP Model gives improved pedestrian detection in urban traffic environment where healthcare systems find more difficult to reach to the people and also reduces the time complexity on detecting the pedestrians in road traffic scenes when compared to the existing DPM and RealBoost methods.
C1 [Govardhan, S. D.] Coimbatore Inst Engn & Technol, Dept ECE, Coimbatore, Tamil Nadu, India.
   [Vasuki, A.] Kumaraguru Coll Technol, Dept MCE, Coimbatore, Tamilnadu, India.
C3 Kumaraguru College of Technology
RP Govardhan, SD (corresponding author), Coimbatore Inst Engn & Technol, Dept ECE, Coimbatore, Tamil Nadu, India.
EM govardhan_sd@yahoo.co.in; avasuki@gmail.com
OI SD, Govardhan/0000-0001-6322-9767
CR Afrakhteh M, 2017, ARAB J SCI ENG, V42, P3207, DOI 10.1007/s13369-017-2424-3
   [Anonymous], J REAL TIME IMAGE P
   [Anonymous], 2016, Comput Vis Media
   Biswas SK, 2017, IEEE T IMAGE PROCESS, V26, P4229, DOI 10.1109/TIP.2017.2705426
   Chen YX, 2016, INFORM SCIENCES, V372, P148, DOI 10.1016/j.ins.2016.08.050
   Choi HJ, 2016, INT J CONTROL AUTOM, V14, P1618, DOI [10.1007/s12555-016-0322-1, 10.1007/s12555-014-0471-z]
   Hong GS, 2016, MULTIMED TOOLS APPL, V75, P15229, DOI 10.1007/s11042-015-2455-2
   Jiang XH, 2016, NEUROCOMPUTING, V185, P163, DOI 10.1016/j.neucom.2015.12.042
   Kim HK, 2017, IMAGE VISION COMPUT, V61, P1, DOI 10.1016/j.imavis.2017.02.007
   Kwak JY, 2017, IEEE T INTELL TRANSP, V18, P69, DOI 10.1109/TITS.2016.2569159
   Li C, 2017, NEUROCOMPUTING, V238, P420, DOI 10.1016/j.neucom.2017.01.084
   Li JF, 2010, INFRARED PHYS TECHN, V53, P267, DOI 10.1016/j.infrared.2010.03.005
   Li KQ, 2016, IEEE T INTELL TRANSP, V17, P1368, DOI 10.1109/TITS.2015.2502325
   Liu YZ, 2016, NEUROCOMPUTING, V184, P55, DOI 10.1016/j.neucom.2015.07.143
   Luo YL, 2018, MULTIMED TOOLS APPL, V77, P26191, DOI 10.1007/s11042-018-5844-5
   Ouyang WL, 2016, IEEE T CIRC SYST VID, V26, P2123, DOI 10.1109/TCSVT.2015.2501940
   Ouyang WL, 2016, INT J COMPUT VISION, V120, P14, DOI 10.1007/s11263-016-0890-9
   Paisitkriangkrai S, 2016, IEEE T PATTERN ANAL, V38, P1243, DOI 10.1109/TPAMI.2015.2474388
   Wang Y, 2017, PATTERN RECOGN LETT, V96, P106, DOI 10.1016/j.patrec.2016.11.020
   Wei X, 2018, MULTIMED TOOLS APPL, V77, P9021, DOI 10.1007/s11042-017-4792-9
   Yan JJ, 2013, PROC CVPR IEEE, P3033, DOI 10.1109/CVPR.2013.390
   Yang DZ, 2018, SOL ENERGY, V171, pA1, DOI 10.1016/j.solener.2018.07.006
   Zhang G., 2017, Journal of Computer and Communications, V5, P102
   Zhang SS, 2016, MULTIMED TOOLS APPL, V75, P6263, DOI 10.1007/s11042-015-2571-z
NR 24
TC 0
Z9 0
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3667
EP 3681
DI 10.1007/s11042-018-6435-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700030
DA 2024-07-18
ER

PT J
AU Li, J
   Zhang, HX
   Wan, WB
   Sun, JD
AF Li, Jing
   Zhang, Huaxiang
   Wan, Wenbo
   Sun, Jiande
TI Two-class 3D-CNN classifiers combination for video copy detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D-CNN; Video classification; Two-class classifier; Video copy detection
AB 3D-CNN is the latest CNN model used for video classification. However, the required amount of computation and training data for training 3D-CNN, especially for complex classification tasks with large video data, hinders the wide application of 3D-CNN. In this paper, inspired by the exclusion method in human's judgment, a parallel 3D-CNN architecture is proposed to decompose the multi-class classification task using one 3D-CNN into the combination of multiple two-class classification tasks. 3D-CNN is used as a two-class classifier for each of the two-class classification tasks, and the difficulty and the data requirement on training such a 3D-CNN is reduced greatly comparing with the 3D-CNN for multi-class classification. In addition, the combination of two-class classifiers provides the ability of recognizing unknown class to the proposed 3D-CNN model. The feasibility of this proposed 3D-CNN model is verified via its application on video copy detection on the CC_WEB_VIDEO dataset. The experimental results show the potentiality of the proposed parallel two-class 3D-CNN model in video classification.
C1 [Li, Jing; Zhang, Huaxiang; Wan, Wenbo; Sun, Jiande] Shandong Normal Univ, Sch Informat Sci & Technol, Jinan, Peoples R China.
   [Li, Jing] Shandong Management Univ, Sch Mech & Elect Engn, Jinan, Peoples R China.
C3 Shandong Normal University; Shandong Management University
RP Li, J (corresponding author), Shandong Normal Univ, Sch Informat Sci & Technol, Jinan, Peoples R China.; Li, J (corresponding author), Shandong Management Univ, Sch Mech & Elect Engn, Jinan, Peoples R China.
EM lijingjdsun@hotmail.com
RI Zhang, Yuchen/GYI-8858-2022
CR [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], 2005, Comput. Vis. Image Understanding
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 2017, IEEE J OCEAN ENG
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Griffin Gregory, 2007, CALTECH 256 OBJECT C
   Jiang Y, 2011, ASIAN LAW S, P1
   Jiang YG, 2018, IEEE T PATTERN ANAL, V40, P352, DOI 10.1109/TPAMI.2017.2670560
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Le Callet P, 2006, IEEE T NEURAL NETWOR, V17, P1316, DOI 10.1109/TNN.2006.879766
   Li ZY, 2017, AIP CONF PROC, V1863, DOI 10.1063/1.4992364
   Liu H, 2012, CHINESE J ELECTRON, V21, P636
   Luo MN, 2018, IEEE T CYBERNETICS, V48, P648, DOI 10.1109/TCYB.2017.2647904
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Mei SH, 2017, IEEE T GEOSCI REMOTE, V55, P4520, DOI 10.1109/TGRS.2017.2693346
   Qu Y, 2018, IEEE ACCESS, V6, P3943, DOI 10.1109/ACCESS.2017.2754409
   Soomro K., 2012, CoRR, V2
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802
   Tu J, 2015, IEEE INT CONF ELECTR, P1, DOI 10.1109/ICEIEC.2015.7284474
   Wang YX, 2017, IETE J RES, V63, P358, DOI 10.1080/03772063.2016.1274240
   Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929
   Zhang HX, 2014, PATTERN RECOGN, V47, P3168, DOI 10.1016/j.patcog.2014.04.004
   Zhang HX, 2010, FUZZY SET SYST, V161, P1790, DOI 10.1016/j.fss.2009.11.013
NR 27
TC 10
Z9 13
U1 27
U2 158
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4749
EP 4761
DI 10.1007/s11042-018-6047-9
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500029
DA 2024-07-18
ER

PT J
AU Purwar, S
   Tripathi, RK
   Ranjan, R
   Saxena, R
AF Purwar, Shikha
   Tripathi, Rajiv Kumar
   Ranjan, Ravi
   Saxena, Renu
TI Detection of microcytic hypochromia using cbc and blood film features
   extracted from convolution neural network by different classifiers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial neural network; Convolution neural network; K-nearest
   neighbors; Linear discriminant analysis; Principal component analysis;
   Support vector machine
ID MULTILAYER PERCEPTRON; CLASSIFICATION
AB Diagnosis of microcytic hypochromia is done by measuring certain characteristics changes in the count of blood cell and related indices. Complete blood count test (CBC) is the common process for measuring these characteristic changes. However, the CBC test cannot be completely relied upon since there are chances of false diagnosis as these characteristics are also related to other disorders. In order to rectify the same, other expensive and lengthy tests need to be done which leads to further delay in accurate diagnosis and which may prove detrimental. In an attempt to find the solution to this problem, this paper proposes a method that uses feature fusion for classification of microcytic hypochromia. Feature fusion means combining blood smear image features extracted by the deep convolutional neural network (CNN) and clinical features from CBC test. This fused data-set is further used to predict microcytic hypochromia. After obtaining fused data set we use linear discriminant analysis (LDA) and principal component analysis (PCA) to reduce data set dimensions which further results in less computational overhead. To differentiate between microcytic hypochromia patients and normal persons, k-nearest neighbors (k-NN), support vector machine (SVM), and neural network classification models are used. In order to check the performance of the above model, various evaluation metrics are used. Results achieved from the proposed method reflect that fused data set can effectively improve the identification ratio with a very limited number of patients diagnostic images and clinical data (10 for normal and 10 for beta-thalassemia) and feed-forward back-propagation neural network on this data set achieved accuracy, sensitivity, and specificity of 99%, 1.00, and 0.98, respectively. The limited number of patients reduces the system complexity and researcher's time for getting data from different hospital to train the network.
C1 [Purwar, Shikha; Tripathi, Rajiv Kumar] Natl Inst Technol Delhi, Elect & Commun Dept, New Delhi, India.
   [Ranjan, Ravi; Saxena, Renu] All India Inst Med Sci, Haematol Dept, New Delhi, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Delhi; All India Institute of Medical Sciences (AIIMS) New
   Delhi
RP Purwar, S (corresponding author), Natl Inst Technol Delhi, Elect & Commun Dept, New Delhi, India.
EM shikhapurwar@nitdelhi.ac.in
RI Saxena, Renu/HTP-9203-2023
OI purwar, shikha/0000-0001-5362-1669
CR Cruz-Roa AA, 2013, LECT NOTES COMPUT SC, V8150, P403, DOI 10.1007/978-3-642-40763-5_50
   Amendolia SR, 2003, CHEMOMETR INTELL LAB, V69, P13, DOI 10.1016/S0169-7439(03)00094-7
   Amendolia SR, 2002, MED DECIS MAKING, V22, P18, DOI 10.1177/02729890222062883
   [Anonymous], THAL OTH HAEM REP SE
   [Anonymous], INTRO NEURAL COMPUTI
   [Anonymous], IEEE T NEURAL NETWOR
   [Anonymous], 2014, VERY DEEP CONVOLUTIO
   [Anonymous], 2014, 1 WORKSH PATT REC TE
   [Anonymous], DATA SCI CURSE DIMEN
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], 2016, DEEP LEARNING
   [Anonymous], HORMOZGAN MED J
   [Anonymous], 2017, INDONES J ELECT ENG, DOI [10.11591/ijeecs.v6.i1.pp160-165, DOI 10.11591/IJEECS.V6.I1.PP160-165]
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 2011, GLOB PREV AN
   [Anonymous], INT J COMPUT APPL
   [Anonymous], IEEE INT C SIGN PROC
   [Anonymous], P 14 INT C ART INT S
   [Anonymous], 2009, GLOB HLTH RISKS MORT
   [Anonymous], NAT FAM HLTH SURV NF
   Barnhart-Magen G, 2013, J CLIN LAB ANAL, V27, P481, DOI 10.1002/jcla.21631
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Ciresan D., 2012, ADV NEURAL INFORM PR, V25, P2843
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Das DK, 2013, J MICROSC-OXFORD, V249, P136, DOI 10.1111/jmi.12002
   Dayhoff JE, 2001, CANCER, V91, P1615, DOI 10.1002/1097-0142(20010415)91:8+<1615::AID-CNCR1175>3.0.CO;2-L
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Durant TJS, 2017, CLIN CHEM, V63, P1847, DOI 10.1373/clinchem.2017.276345
   Elsalamony HA, 2016, MEAS SCI TECHNOL, V27, DOI 10.1088/0957-0233/27/8/085401
   Elshami E. H., 2012, INT C INF APPL ICIA2, P440
   Joachims T., 1998, Machine Learning: ECML-98. 10th European Conference on Machine Learning. Proceedings, P137, DOI 10.1007/BFb0026683
   Lee JG, 2017, KOREAN J RADIOL, V18, P570, DOI 10.3348/kjr.2017.18.4.570
   Masala GL, 2013, COMPUT BIOL MED, V43, P1724, DOI 10.1016/j.compbiomed.2013.08.020
   Müller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517
   Paokanta P., 2011, International Journal of e-Education, e-Business, e-Management and e-Learning (IJEEEE), V1, P175
   Pasricha SR, 2014, BLOOD, V123, P611, DOI 10.1182/blood-2013-12-543405
   Prasoon A, 2013, LECT NOTES COMPUT SC, V8150, P246, DOI 10.1007/978-3-642-40763-5_31
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10
   Setsirichok D, 2012, BIOMED SIGNAL PROCES, V7, P202, DOI 10.1016/j.bspc.2011.03.007
   Sharma V., 2016, 2016 INT C INVENTIVE, V3, P1, DOI [DOI 10.1109/INVENTIVE.2016.7830136, 10.1109/INVENTIVE.2016.7830136]
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Wen J, 2019, IEEE T CIRC SYST VID, V29, P390, DOI 10.1109/TCSVT.2018.2799214
   Wongseree W, 2003, IEEE SYS MAN CYBERN, P2926
   Xing FY, 2016, IEEE T MED IMAGING, V35, P550, DOI 10.1109/TMI.2015.2481436
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 45
TC 20
Z9 20
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4573
EP 4595
DI 10.1007/s11042-019-07927-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500018
DA 2024-07-18
ER

PT J
AU Rakhshani, S
   Rashedi, E
   Nezamabadi-pour, H
AF Rakhshani, Sajed
   Rashedi, Esmat
   Nezamabadi-pour, Hossein
TI Representation learning in a deep network for license plate recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Representation learning; Encoder-decoder network; License
   plate recognition
ID NEURAL-NETWORKS; ENHANCEMENT; ALGORITHM
AB The goal of license plate recognition (LPR) is to read the license plate characters. Due to image degradation, there are many difficulties in the way of achieving this goal. In this paper, the proposed method recognizes the license plate characters without employing the traditional segmentation and binarization techniques. This method uses a deep learning algorithm and tries to achieve better learning experience by engaging a multi-task learning algorithm based on sharing features. The features of license plate characters are extracted by a deep encoder-decoder network, and transferred to 8 parallel classifiers for recognition. To evaluate the current work, a database of 11,000 license plate images, collected from a currently working surveillance system installed on a dual carriageway, is employed. The proposed method achieved the correct character recognition rate of 96% for 4000 test images that is acceptable in comparison to the competing methods.
C1 [Rakhshani, Sajed; Rashedi, Esmat] Grad Univ Adv Technol, Dept Elect & Comp Engn, POB 76315, Kerman, Iran.
   [Nezamabadi-pour, Hossein] Shahid Bahonar Univ Kerman, Dept Elect Engn, IDPL, Kerman, Iran.
C3 Graduate University of Advanced Technology; Shahid Bahonar University of
   Kerman (SBUK)
RP Rashedi, E (corresponding author), Grad Univ Adv Technol, Dept Elect & Comp Engn, POB 76315, Kerman, Iran.
EM sajedrakhshani@msn.com; e.rashedi@kgut.ac.ir; nezam@uk.ac.ir
RI Rakhshani, Sajed/JLL-1778-2023; Rashedi, Esmat/AAZ-7069-2020;
   Nezamabadi-pour, Hossein/AAB-4009-2019
OI Nezamabadi-pour, Hossein/0000-0002-3350-7348; Rashedi,
   Esmat/0000-0002-2539-5817
CR Abolghasemi V, 2009, IMAGE VISION COMPUT, V27, P1134, DOI 10.1016/j.imavis.2008.10.012
   Al-Rfou R, 2016, ABS16050 ARXIV
   [Anonymous], 2019, TUNISIA DATA SET KAG
   Ashtari AH, 2014, IEEE T INTELL TRANSP, V15, P1690, DOI 10.1109/TITS.2014.2304515
   Bengio Y., 2012, UNSUPERVISED TRANSFE, V7, P19
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Björklund T, 2019, PATTERN RECOGN, V93, P134, DOI 10.1016/j.patcog.2019.04.007
   Chang SL, 2004, IEEE T INTELL TRANSP, V5, P42, DOI 10.1109/TITS.2004.825086
   Chen KN, 2012, DIGIT SIGNAL PROCESS, V22, P726, DOI 10.1016/j.dsp.2012.04.010
   Chollet F, 2015, KERAS
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Erhan D, 2010, J MACH LEARN RES, V11, P625
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Günther J, 2014, PROC TECH, V15, P474, DOI 10.1016/j.protcy.2014.09.007
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hsu GS, 2013, IEEE T VEH TECHNOL, V62, P552, DOI 10.1109/TVT.2012.2226218
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Jiao JB, 2009, PATTERN RECOGN, V42, P358, DOI 10.1016/j.patcog.2008.08.016
   Kashef S, 2018, MULTIMED TOOLS APPL, V77, P16579, DOI 10.1007/s11042-017-5229-1
   Ko MA, 2004, 32ND APPLIED IMAGERY PATTERN RECOGNITION WORKSHOP, PROCEEDINGS, P269
   Ko MA, 2004, P APPL IM PATT REC W, P235, DOI [10.1109/AIPR.2004.8, DOI 10.1109/AIPR.2004.8]
   Kobchaisawat T, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING APPLICATIONS (ICSIPA), P220, DOI 10.1109/ICSIPA.2015.7412193
   Kocer HE, 2011, PROCEDIA COMPUT SCI, V3, DOI 10.1016/j.procs.2010.12.169
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Li H., 2016, ARXIV160105610
   Li HF, 2016, HYDROMETALLURGY, V160, P1, DOI 10.1016/j.hydromet.2015.11.002
   LIU X, 2016, INT CONF ACOUST SPEE, V2016, P1322
   Llorens D, 2005, CAR LICENSE PLATES E, P571
   Naito T, 2000, IEEE T VEH TECHNOL, V49, P2309, DOI 10.1109/25.901900
   Nejati M, 2015, 2015 SIGNAL PROCESSING AND INTELLIGENT SYSTEMS CONFERENCE (SPIS), P48, DOI 10.1109/SPIS.2015.7422310
   Nukano T., 2004, Proceedings of 2004 International Symposium on Intelligent Signal Processing And Communication Systems ISPACS 2004 (IEEE Cat. No.04EX910), P771, DOI 10.1109/ISPACS.2004.1439164
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Qian YM, 2016, IEEE-ACM T AUDIO SPE, V24, P2263, DOI 10.1109/TASLP.2016.2602884
   Rashedi E, 2018, MULTIMED TOOLS APPL, V77, P2771, DOI 10.1007/s11042-017-4429-z
   Salazar M.B., 2014, The Impact of Shelf Margin Geometry and Tectonics on Shelf-To-Sink Sediment Dynamics and Resultant Basin Fill Architectures, P1
   Sedighi A, 2011, EXPERT SYST APPL, V38, P13497, DOI 10.1016/j.eswa.2011.02.030
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vazquez N, 2002, J APPL RES TECHNOL, V1, P63
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang RM, 2014, OPTIK, V125, P186, DOI 10.1016/j.ijleo.2013.06.008
   Wu BF, 2007, IET COMPUT VIS, V1, P2, DOI 10.1049/iet-cvi:20050132
   Xu JF, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3904
   Yang Y, 2011, PROCEDIA ENGINEER, V15, DOI 10.1016/j.proeng.2011.08.245
   Yu SY, 2015, PATTERN RECOGN, V48, P114, DOI 10.1016/j.patcog.2014.07.027
   Zheng LH, 2013, J COMPUT SYST SCI, V79, P245, DOI 10.1016/j.jcss.2012.05.006
NR 47
TC 5
Z9 5
U1 3
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13267
EP 13289
DI 10.1007/s11042-019-08416-0
EA JAN 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000515608500001
DA 2024-07-18
ER

PT J
AU Rajendran, S
   Krithivasan, K
   Doraipandian, M
   Gao, XZ
AF Rajendran, Sujarani
   Krithivasan, Kannan
   Doraipandian, Manivannan
   Gao, Xiao-Zhi
TI Fast pre-processing hex Chaos triggered color image cryptosystem
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyper-chaotic system; Image encryption; Lorenz chaotic map; Security
ID DNA-SEQUENCE OPERATIONS; ENCRYPTION ALGORITHM; HYPER-CHAOS; MAP; SYSTEM
AB In the present study, a robust color image cryptosystem based on a novel structure of chaotic pre-processing is proposed, which greatly reduce the execution time and memory usage and also increase the performance of confusion and diffusion phases. Position of pixels are scrambled in confusion phase by applying the chaotic series of hyper Lorenz system. In diffusion phase, a novel structure of bit level merging and circular shifting operation is adopted to strengthen the security level, further an inter - exclusive OR (XOR) operation is executed between each layers (Red, Blue, Green) to obtain cipher image. Evaluation results shows that the proposed pre-processing system has better performance with minimum cost than other available pre-processing methods. Assessment results proves the ability of the algorithm to resist statistical and differential attacks. Comparison of encryption quality assures that the proposed system has better encryption effect than existing one and exhaustive attack analysis proves the robustness. Consequently, these results expose the proposed cryptosystem could be a best fit for secure storage and transfer of images in real-time applications.
C1 [Rajendran, Sujarani] SASTRA Deemed Univ, Srinivasa Ramanujan Ctr, Dept Comp Sci, Kumbakonam, Tamil Nadu, India.
   [Krithivasan, Kannan] SASTRA Deemed Univ, Dept Math, DMRL, Thanjavur, Tamil Nadu, India.
   [Doraipandian, Manivannan] SASTRA Deemed Univ, Sch Comp, Thanjavur, Tamil Nadu, India.
   [Gao, Xiao-Zhi] Univ Eastern Finland, Sch Comp, Kuopio, Finland.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   University of Eastern Finland
RP Doraipandian, M (corresponding author), SASTRA Deemed Univ, Sch Comp, Thanjavur, Tamil Nadu, India.
EM dmanivannank@gmail.com
RI k, k/KFT-2541-2024; K, Kannan/GPK-0744-2022; GAO, XIAO/JED-3257-2023; k,
   k/KFC-0221-2024; su, haobo/JPK-2362-2023; k, k/HZK-4476-2023
OI Rajendran, Sujarani/0000-0001-9827-0807
FU Department of Science and Technology, India [SR/FST/ETI371/2014,
   SR/FST/MSI-107/2015]; Tata Realty-IT City - SASTRA Srinivasa Ramanujan
   Research Cell of our University
FX The Authors gratefully acknowledge the Department of Science and
   Technology, India for Fund for Improvement of S&T Infrastructure in
   Universities and Higher Educational Institutions (SR/FST/ETI371/2014),
   (SR/FST/MSI-107/2015) and Tata Realty-IT City - SASTRA Srinivasa
   Ramanujan Research Cell of our University for the financial support
   extended to us in carrying out this research work.
CR Alawida M, 2019, SIGNAL PROCESS, V160, P45, DOI 10.1016/j.sigpro.2019.02.016
   Anees A, 2015, 3D RES, DOI [10.1109/ICNC.2008.227, DOI 10.1109/ICNC.2008.227]
   Ben Slimane N, 2018, MULTIMED TOOLS APPL, V77, P30993, DOI 10.1007/s11042-018-6145-8
   Cai ST, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20040282
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P9907, DOI 10.1007/s11042-016-3585-x
   Diab H, 2018, IEEE ACCESS, V6, P42227, DOI 10.1109/ACCESS.2018.2858839
   El Assad S, 2016, SIGNAL PROCESS-IMAGE, V41, P144, DOI 10.1016/j.image.2015.10.004
   Elgendy F, 2016, MULTIMED TOOLS APPL, V75, P11529, DOI 10.1007/s11042-015-2883-z
   Eom Sungwook, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P1411, DOI 10.1007/s12652-018-0698-2
   Eom S, 2018, MATHEMATICS-BASEL, V6, DOI 10.3390/math6100202
   Fan HJ, 2018, MULTIMED TOOLS APPL, V77, P20103, DOI 10.1007/s11042-017-5437-8
   Fu C, 2013, COMPUT BIOL MED, V43, P1000, DOI 10.1016/j.compbiomed.2013.05.005
   Gao Hao-jiang, 2006, Mini-Micro Systems, V27, P655
   Hu T, 2017, NONLINEAR DYNAM, V87, P51, DOI 10.1007/s11071-016-3024-6
   HUANG LQ, 2018, ENTROPY-SWITZ, V20, DOI DOI 10.3390/e20070535
   Huang R, 2014, MULTIMED TOOLS APPL, V72, P71, DOI 10.1007/s11042-012-1337-0
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Kadir A, 2017, OPTIK, V129, P231, DOI 10.1016/j.ijleo.2016.10.036
   Kalpana J, 2015, OPTIK, V126, P5703, DOI 10.1016/j.ijleo.2015.09.091
   Khan M, 2014, NEURAL COMPUT APPL, V25, P1717, DOI 10.1007/s00521-014-1663-4
   Kumar M, 2017, OPT LASER ENG, V88, P51, DOI 10.1016/j.optlaseng.2016.07.009
   Kumar S, 2017, MULTIMED TOOLS APPL, V76, P8757, DOI 10.1007/s11042-016-3504-1
   Li C, 2016, NONLINEAR DYNAM, P1, DOI [10.1109/IWCFTA.2009.48, DOI 10.1109/IWCFTA.2009.48]
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Liu WH, 2017, NONLINEAR DYNAM, V89, P2521, DOI 10.1007/s11071-017-3601-3
   Luo YL, 2018, MULTIMED TOOLS APPL, V77, P26191, DOI 10.1007/s11042-018-5844-5
   Mirzaei O, 2012, NONLINEAR DYNAM, V67, P557, DOI 10.1007/s11071-011-0006-6
   Mollaeefar M, 2017, MULTIMED TOOLS APPL, V76, P607, DOI 10.1007/s11042-015-3064-9
   Murillo-Escobar MA, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0698-3
   Naeem EA, 2016, COMPUT ELECTR ENG, V54, P450, DOI 10.1016/j.compeleceng.2015.08.018
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Norouzi B, 2017, MULTIMED TOOLS APPL, V76, P1817, DOI 10.1007/s11042-015-3085-4
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Patro KAK, 2019, J INF SECUR APPL, V46, P23, DOI 10.1016/j.jisa.2019.02.006
   Rehman AU, 2018, OPTIK, V159, P348, DOI 10.1016/j.ijleo.2018.01.064
   SIPI, 2019, IM DAT MISC
   Souyah A, 2016, NONLINEAR DYNAM, V86, P639, DOI 10.1007/s11071-016-2912-0
   Tan CH, 2016, INFORM PROCESS LETT, V116, P116, DOI 10.1016/j.ipl.2015.09.014
   Teng L, 2018, MULTIMED TOOLS APPL, V77, P6883, DOI 10.1007/s11042-017-4605-1
   Wang XY, 2019, MULTIMED TOOLS APPL, V78, P6191, DOI 10.1007/s11042-018-6326-5
   Wang XY, 2019, OPT LASER TECHNOL, V115, P42, DOI 10.1016/j.optlastec.2019.02.009
   Wang XY, 2016, NONLINEAR DYNAM, V83, P333, DOI 10.1007/s11071-015-2330-8
   Wu P, 2019, RES DIGITAL IMAGE WA
   Wu XJ, 2017, NONLINEAR DYNAM, V90, P855, DOI 10.1007/s11071-017-3698-4
   Wu XL, 2017, IEEE ACCESS, V5, P6429, DOI 10.1109/ACCESS.2017.2692043
   Wu XY, 2015, PLOS ONE, V10, DOI [10.1371/journal.pone.0118041, 10.1371/journal.pone.0119607]
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Yao LL, 2017, OPT LASER ENG, V89, P80, DOI 10.1016/j.optlaseng.2016.06.007
   Ye GD, 2016, SECUR COMMUN NETW, V9, P2015, DOI 10.1002/sec.1458
   Yuan HM, 2017, SIGNAL PROCESS-IMAGE, V52, P87, DOI 10.1016/j.image.2017.01.002
   Zhang M, 2015, MULTIMED TOOLS APPL, V74, P11255, DOI 10.1007/s11042-014-2227-4
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang XP, 2016, MULTIMED TOOLS APPL, V75, P1745, DOI 10.1007/s11042-014-2372-9
   Zheng YF, 2015, MULTIMED TOOLS APPL, V74, P7803, DOI 10.1007/s11042-014-2024-0
NR 56
TC 8
Z9 8
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12447
EP 12469
DI 10.1007/s11042-019-08396-1
EA JAN 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000507701400003
DA 2024-07-18
ER

PT J
AU Bagade, JV
   Singh, K
   Dandawate, YH
AF Bagade, Jayashri V.
   Singh, Kulbir
   Dandawate, Y. H.
TI No-reference image quality assessment using fusion metric
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image quality assessment; No-reference image quality assessment; Scale
   invariant feature transform (SIFT); Curvelet; Neurofuzzy classifier
ID SCENE STATISTICS APPROACH
AB This paper presents a fusion featured metric for no-reference image quality assessment of natural images. Natural images exhibit strong statistical properties across the visual contents such as leading edge, high dimensional singularity, scale invariance, etc. The leading edge represents the strong presence of continuous points, whereas high singularity conveys about non-continuous points along the curves. Both edges and curves are equally important in perceiving the natural images. Distortions to the image affect the intensities of these points. The change in the intensities of these key points can be measured using SIFT. However, SIFT tends to ignore certain points such as the points in the low contrast region which can be identified by curvelet transform. Therefore, we propose a fusion of SIFT key points and the points identified by curvelet transform to model these changes. The proposed fused feature metric is computationally efficient and light on resources. The neruofuzzy classifier is employed to evaluate the proposed feature metric. Experimental results show a good correlation between subjective and objective scores for public datasets LIVE, TID2008, and TID2013.
C1 [Bagade, Jayashri V.] Vishwakarma Inst Informat Technol, Dept Informat Technol, Pune, Maharashtra, India.
   [Singh, Kulbir] Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
   [Dandawate, Y. H.] Vishwakarma Inst Informat Technol, Dept Elect & Telecommun, Pune, Maharashtra, India.
C3 Thapar Institute of Engineering & Technology
RP Bagade, JV (corresponding author), Vishwakarma Inst Informat Technol, Dept Informat Technol, Pune, Maharashtra, India.
EM jayashrihedaoo@rediffmail.com
RI Bagade, Jayashri/AAS-7516-2020; Dandawate, Yogesh/AAN-7865-2021
OI Dandawate, Yogesh/0000-0002-2528-6856
CR [Anonymous], ADV IMAGE GRAPHICS T
   [Anonymous], 2013, SIGNAL IMAGE PROCESS
   [Anonymous], INT J SIMULATION SYS
   [Anonymous], 2009, 4 INT WORKSH VID PRO
   [Anonymous], 2006, LECT BOOK MODERN IMA
   Benitez JM, 1997, IEEE T NEURAL NETWOR, V8, P1156, DOI 10.1109/72.623216
   Bianco S, 2018, SIGNAL IMAGE VIDEO P, V12, P355, DOI 10.1007/s11760-017-1166-8
   Chen MJ, 2009, INT WORK QUAL MULTIM, P70, DOI 10.1109/QOMEX.2009.5246973
   Do QH, 2013, COMPUT INTEL NEUROSC, V2013, DOI 10.1155/2013/179097
   Fan CL, 2018, IEEE ACCESS, V6, P8934, DOI 10.1109/ACCESS.2018.2802498
   Fang YM, 2015, IEEE SIGNAL PROC LET, V22, P838, DOI 10.1109/LSP.2014.2372333
   Feng TP, 2016, INT J ADV ROBOT SYST, V13, DOI 10.1177/1729881416669486
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Kamble V, 2015, OPTIK, V126, P1090, DOI 10.1016/j.ijleo.2015.02.093
   Keelan B. W., HDB IMAGE QUALITY CH
   Li LD, 2016, KSII T INTERNET INF, V10, P288, DOI 10.3837/tiis.2016.01.017
   Liu J., 2008, INT ARCH PHOTOGRAMME
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P494, DOI 10.1016/j.image.2014.02.004
   Lu W, 2010, NEUROCOMPUTING, V73, P784, DOI 10.1016/j.neucom.2009.10.012
   Lv XX, 2018, AIP CONF PROC, V1955, DOI 10.1063/1.5033698
   Ma KD, 2018, IEEE T IMAGE PROCESS, V27, P1202, DOI 10.1109/TIP.2017.2774045
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Mittal A, 2011, CONF REC ASILOMAR C, P723, DOI 10.1109/ACSSC.2011.6190099
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Nizami IF, 2018, TURK J ELECTR ENG CO, V26, P2163, DOI 10.3906/elk-1804-116
   Ponomarenko Nikolay, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P106
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Qin M, 2017, IET IMAGE PROCESS, V11, P443, DOI 10.1049/iet-ipr.2016.0411
   Qiu F, 2008, PHOTOGRAMM ENG REM S, V74, P1235, DOI 10.14358/PERS.74.10.1235
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sheikh H.R., Live Image Quality Assessment Database
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P1918, DOI 10.1109/TIP.2005.854492
   Talebi H, 2018, IEEE T IMAGE PROCESS, V27, P3998, DOI 10.1109/TIP.2018.2831899
   Wang GJ, 2016, OPTOELECTRON LETT, V12, P152, DOI 10.1007/s11801-016-5276-2
   Wang Z, 2002, INT CONF ACOUST SPEE, P3313
   Zhang D, 2012, PROCEDIA ENGINEER, V29, P3589, DOI 10.1016/j.proeng.2012.01.536
   Zhang Y, 2014, SIGNAL PROCESS-IMAGE, V29, P725, DOI 10.1016/j.image.2014.05.004
   Zhang Y, 2013, PROC SPIE, V8653, DOI 10.1117/12.2001342
NR 41
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2109
EP 2125
DI 10.1007/s11042-019-08217-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000515433000019
DA 2024-07-18
ER

PT J
AU Bibi, K
   Naz, S
   Rehman, A
AF Bibi, Kiran
   Naz, Saeeda
   Rehman, Arshia
TI Biometric signature authentication using machine learning techniques:
   Current trends, challenges and opportunities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric; Online signature verification system; Offline signature
   verification system; Classification models
ID DISCRETE RADON-TRANSFORM; FEATURE-EXTRACTION; SPECIAL-ISSUE;
   CHARACTER-RECOGNITION; WRITER IDENTIFICATION; DEPENDENT FEATURES;
   VERIFICATION; ONLINE; SYSTEM; INFORMATION
AB Biometric systems are playing a key role in the multitude of applications and placed at the center of debate in the scientific research community. Among the numerous biometric systems, handwritten signature verification has got keen interest over the last three decades. Handwritten signature verification is the behavioral bio-metric system that discriminates the genuine signature from the pre-stored known signatures. It has been researched in the number of application areas like banking, financial and business transactions, cheque processing, access control and e-business etc. In this article, we surveyed the techniques of offline and online signature verification systems according to the taxonomy of classification model. A detailed background of signature verification system along with the available datasets are presented comprehensively. At the end, we presented the most notable challenges that guide the readers towards the current trends and future directions of the domain.
C1 [Bibi, Kiran; Naz, Saeeda; Rehman, Arshia] Govt Girls Postgrad Coll 1, Dept Comp Sci, Abbottabad, Khyber Pakhtunk, Pakistan.
RP Naz, S (corresponding author), Govt Girls Postgrad Coll 1, Dept Comp Sci, Abbottabad, Khyber Pakhtunk, Pakistan.
EM saeedanaz292@gmail.com
CR Abikoye O.C., 2011, Int. J. Comput. Appl., V35, P44
   Abuhaiba Ibrahim S. I., 2007, Turkish Journal Electrical Engineering and Computer Sciences, Elektrik, V15, P89
   Ahmad R, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0133648
   Akram M, 2012, 2012 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV), P925, DOI 10.1109/ICIEV.2012.6317435
   Al-Hmouz R, 2019, SOFT COMPUT, V23, P407, DOI 10.1007/s00500-017-2782-5
   Al-Mayyan W, 2011, DIGIT SIGNAL PROCESS, V21, P477, DOI 10.1016/j.dsp.2011.01.007
   Al-Omari Y. M., 2011, Proceedings of the 2011 International Conference on Pattern Analysis and Intelligent Robotics (ICPAIR 2011), P59, DOI 10.1109/ICPAIR.2011.5976912
   Alonso-Fernandez F, 2009, IEEE IMAGE PROC, P2725, DOI 10.1109/ICIP.2009.5414157
   Alparslan Ö, 2018, ARTS HEALTH, V10, P138, DOI 10.1080/17533015.2017.1334679
   [Anonymous], ICWET 11
   [Anonymous], INT J ADV RES COMPUT
   [Anonymous], 2009, INT J IMAGE PROCESSI
   [Anonymous], 2013, RES J ENG SCI
   [Anonymous], INT J ENG SCI RES TE
   [Anonymous], 2013 1 IR C PATT REC
   [Anonymous], ARXIV13111694
   [Anonymous], INT J GLOBAL RES COM
   [Anonymous], CLUSTER COMPUTING
   [Anonymous], INT J COMPUT APPL
   [Anonymous], 1 INT JOINT C PATT R
   [Anonymous], J RES
   [Anonymous], 2012, IOSR J ELECT COMMUN
   [Anonymous], 2014, INT J RES ENG TECHNO
   [Anonymous], 2013, INT J ENG INNOV TECH
   [Anonymous], INT J ADV SCI TECHNO
   [Anonymous], J APPL ENV BIOL SCI
   [Anonymous], INT J COMPUT APPL, DOI DOI 10.5120/499-815
   [Anonymous], PERSONAL AUTHENTICAT
   [Anonymous], INT J COMPUTER SCI N
   [Anonymous], INT J ADV RES IDEAS
   [Anonymous], INT J ADV RES COMPUT
   [Anonymous], 2015, INT J INNOVATIONS EN
   [Anonymous], REV DYNAMIC HANDWRIT
   [Anonymous], INT J COMPUT APPL
   [Anonymous], INT J COMPUTER SCI I
   [Anonymous], 2013, INT J IT ENG APPL SC
   [Anonymous], SIGNATURE ANAL TEST
   [Anonymous], INT J COMPUTER SCI I
   [Anonymous], INT J LATEST TRENDS
   [Anonymous], INT J INNOVATIVE RES
   [Anonymous], INT J INNOVATIVE RES
   [Anonymous], EXPERT SYSTEMS APPL
   [Anonymous], SOFT COMPUTING
   [Anonymous], INT J EMERGING TECHN
   [Anonymous], INT J SCI ENG RES
   [Anonymous], INT J ENG TECHNOL
   [Anonymous], INT J ADV RES ELECT
   [Anonymous], INT J COMPUTER APPL
   [Anonymous], 2018, PATTERN RECOGN
   [Anonymous], INT J ENGINE RES
   [Anonymous], IBNALHAITHAM J PURE
   [Anonymous], INT J ENG RES GEN SC
   [Anonymous], 1992, STRUCTURED DOCUMENT, DOI DOI 10.1007/978-3-642-77281-8_10
   [Anonymous], 2017, P IEEE INT C EL INST
   [Anonymous], P INT MULT ENG COMP
   [Anonymous], INT RES J ENG TECHNO
   [Anonymous], INT J ADV RES COMPUT
   [Anonymous], 2013, INT J EMERGING TECHN
   [Anonymous], INT J ELECT ELECT CO
   [Anonymous], INT RES J ENG TECHNO
   [Anonymous], IJCSI INT J COMPUTER
   [Anonymous], STATIC PERSIAN SIGNA
   [Anonymous], 2017, 2017 C INF COMM TECH
   [Anonymous], INT J SOFT COMPUTING
   [Anonymous], INT J ENG SCI INNOV
   [Anonymous], 2010, INT J COMPUT APPL, DOI DOI 10.5120/383-573
   [Anonymous], INT J ELECT ENG RES
   [Anonymous], CIRCULATION COMPUTER
   [Anonymous], AFHA
   [Anonymous], EUROPEAN J ADV ENG T
   [Anonymous], INT J
   [Anonymous], INT J COMPUT SCI MOB
   [Anonymous], IEEE T INFORM FORENS
   [Anonymous], INT J ADV RES COMPUT
   [Anonymous], INT RES J ENG TECHNO
   [Anonymous], J NETWORK COMMUNICAT
   Ansari AQ, 2014, IET BIOMETRICS, V3, P113, DOI 10.1049/iet-bmt.2012.0048
   Armand S, 2006, IEEE IJCNN, P684
   Arunalatha JS, 2015, 2015 IEEE 2ND INTERNATIONAL CONFERENCE ON RECENT TRENDS IN INFORMATION SYSTEMS (RETIS), P195, DOI 10.1109/ReTIS.2015.7232877
   Azmi AN, 2017, MULTIMED TOOLS APPL, V76, P15341, DOI 10.1007/s11042-016-3831-2
   Bharathi RK, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2309, DOI 10.1109/ICACCI.2014.6968585
   Bhattacharyya D, 2009, INT J GRID DISTRIB, V2, P13
   Bhumika P., 2015, INT J ADV RES COMPUT, V3, P182
   Bin Ahmed S, 2019, IEEE ACCESS, V7, P19801, DOI 10.1109/ACCESS.2019.2895876
   Bin Ahmed S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9020236
   Blankers Vivian L., 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1403, DOI 10.1109/ICDAR.2009.216
   Boyer KW, 2007, IEEE T SYST MAN CY B, V37, P1091, DOI 10.1109/TSMCB.2007.903196
   Cho YO, 2017, INT J HUM ROBOT, V14, DOI 10.1142/S0219843617500165
   Coetzer J, 2004, EURASIP J APPL SIG P, V2004, P559, DOI 10.1155/S1110865704309042
   Daramola S.A., 2010, Int. J. Comput. Appl., V10, P17
   Deore MR, 2015, 2015 INTERNATIONAL CONFERENCE ON INDUSTRIAL INSTRUMENTATION AND CONTROL (ICIC), P165, DOI 10.1109/IIC.2015.7150731
   Dimauro G, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P179, DOI 10.1109/IWFHR.2004.85
   Du XZ, 2013, PROC INT CONF DOC, P976, DOI 10.1109/ICDAR.2013.197
   Fahmy MMM, 2010, AIN SHAMS ENG J, V1, P59, DOI 10.1016/j.asej.2010.09.007
   Fang YX, 2017, COMPUT ELECTR ENG, V57, P1, DOI 10.1016/j.compeleceng.2016.11.010
   Fayyaz M, 2015, 2015 INTERNATIONAL SYMPOSIUM ON ARTIFICIAL INTELLIGENCE AND SIGNAL PROCESSING (AISP), P211, DOI 10.1109/AISP.2015.7123528
   Ferrer MA, 2005, IEEE T PATTERN ANAL, V27, P993, DOI 10.1109/TPAMI.2005.125
   Fierrez J., 2008, HDB BIOMETRICS, P189, DOI DOI 10.1007/978-0-387-71041-9_10
   Fierrez-Aguilar J, 2004, LECT NOTES COMPUT SC, V3087, P295
   Fischer A, 2015, PROC INT CONF DOC, P241, DOI 10.1109/ICDAR.2015.7333760
   Gomez-Barrero M, 2015, INT CONF BIOMETR, P501, DOI 10.1109/ICB.2015.7139065
   Griechisch E, 2014, INT CONF FRONT HAND, P738, DOI 10.1109/ICFHR.2014.129
   Griechisch E, 2013, PROC INT CONF DOC, P374, DOI 10.1109/ICDAR.2013.82
   Gupta N, 2017, ASIAN J UROL, V4, P3, DOI 10.1016/j.ajur.2016.11.002
   Hafemann L. G., 2017, 2017 7 INT C IM PROC, P1
   Hafemann LG, 2018, INT J DOC ANAL RECOG, V21, P219, DOI 10.1007/s10032-018-0301-6
   Hafemann LG, 2016, IEEE IJCNN, P2576, DOI 10.1109/IJCNN.2016.7727521
   Hafs T, 2016, IET BIOMETRICS, V5, P190, DOI 10.1049/iet-bmt.2014.0041
   Hanmandlu M, 2005, PATTERN RECOGN, V38, P341, DOI 10.1016/j.patcog.2004.05.015
   HERBST NM, 1977, IBM J RES DEV, V21, P245, DOI 10.1147/rd.213.0245
   Hou WP, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON INTELLIGENT MECHATRONICS AND AUTOMATION, P536
   Houmani N, 2012, PATTERN RECOGN, V45, P993, DOI 10.1016/j.patcog.2011.08.008
   Hu J, 2013, PROC INT CONF DOC, P1345, DOI 10.1109/ICDAR.2013.272
   Huang K, 2002, PATTERN RECOGN, V35, P2467, DOI 10.1016/S0031-3203(01)00222-9
   Impedovo D, 2014, INT CONF FRONT HAND, P639, DOI 10.1109/ICFHR.2014.112
   Impedovo D., 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P623, DOI 10.1109/ICFHR.2010.102
   Impedovo D, 2008, IEEE T SYST MAN CY C, V38, P609, DOI 10.1109/TSMCC.2008.923866
   Iranmanesh V, 2013, IEEE CONF OPEN SYST, P18, DOI 10.1109/ICOS.2013.6735040
   Jan Z., 2015, Sindh University Research Journal -Science Series, V47, P699
   Jarad M, 2014, INT CONF COMP SCI, P189, DOI 10.1109/CSIT.2014.6805999
   Julita A, 2009, CSPA: 2009 5TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, PROCEEDINGS, P8, DOI 10.1109/CSPA.2009.5069177
   Justino E., 2000, International Workshop on Document Analysis Systems, P211
   Justino EJR, 2005, PATTERN RECOGN LETT, V26, P1377, DOI 10.1016/j.patrec.2004.11.015
   Kai H, 1997, PATTERN RECOGN, V30, P9, DOI 10.1016/S0031-3203(96)00063-5
   Kaiyue Wang, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P943, DOI 10.1109/ICIG.2011.57
   Karouni A, 2011, PROCEDIA COMPUT SCI, V3, DOI 10.1016/j.procs.2010.12.027
   Katiyar G, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-1775-7
   Kaur M, 2015, 2015 IEEE ASIAN PACIFIC CONFERENCE ON POSTGRADUATE RESEARCH IN MICROELECTRONICS AND ELECTRONICS (PRIMEASIA), P1, DOI 10.1109/PrimeAsia.2015.7450459
   Kaur Ravneet, 2017, Journal of Entomology and Zoology Studies, V5, P1
   Kennard DJ, 2012, INT C PATT RECOG, P3733
   Khan S., 2014, International Journal of Advanced Research in Computer and Communication Engineering, V3, P6879
   Khoh WH, 2014, SECUR COMMUN NETW, V7, P1067, DOI 10.1002/sec.829
   Kholmatov A, 2005, PATTERN RECOGN LETT, V26, P2400, DOI 10.1016/j.patrec.2005.04.017
   Kruthi C, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2014), P3, DOI 10.1109/ICSIP.2014.5
   Kumar D., 2016, INDIAN J SCI TECHNOL, V9, DOI DOI 10.17485/IJST/2016/V9I17/93028
   Kumar MM, 2014, I C CONT AUTOMAT ROB, P799, DOI 10.1109/ICARCV.2014.7064406
   Kumar MM, 2014, IEEE INT ADV COMPUT, P1066, DOI 10.1109/IAdCC.2014.6779473
   Kurban U, 2014, APPL MECH MATER, V519-520, P606, DOI 10.4028/www.scientific.net/AMM.519-520.606
   Lakshmi KV, 2013, IEEE INT ADV COMPUT, P1065
   Leclerc F., 1994, International Journal of Pattern Recognition and Artificial Intelligence, V8, P643, DOI 10.1142/S0218001494000346
   Li N, 2016, P ANN HICSS, P5527, DOI 10.1109/HICSS.2016.683
   Liwicki M, 2011, PROC INT CONF DOC, P1480, DOI 10.1109/ICDAR.2011.294
   López-García M, 2014, IEEE T IND INFORM, V10, P491, DOI 10.1109/TII.2013.2269031
   Madabusi S, 2005, 2005 IEEE INTERNATIONAL WORKSHOP ON MEASUREMENT SYSTEMS FOR HOMELAND SECURITY, CONTRABAND DETECTION & PERSONAL SAFETY, P11
   Malallah Fahad Layth, 2015, International Journal of Cyber-Security and Digital Forensics, V4, P302
   Manjunatha KS, 2019, LECT NOTE NETW SYST, V43, P235, DOI 10.1007/978-981-13-2514-4_20
   Manjunatha KS, 2016, PATTERN RECOGN LETT, V80, P129, DOI 10.1016/j.patrec.2016.06.016
   Marcolin F, 2017, MULTIMED TOOLS APPL, V76, P13805, DOI 10.1007/s11042-016-3741-3
   Martínez LE, 2004, 38TH ANNUAL 2004 INTERNATIONAL CARNAHAN CONFERENCE ON SECURITY TECHNOLOGY, PROCEEDINGS, P193, DOI 10.1109/CCST.2004.1405391
   McCabe A, 2008, J COMPUT, V3, P9, DOI 10.4304/jcp.3.8.9-22
   Mehta M, 2010, PROC SPIE, V7546, DOI 10.1117/12.853308
   Miguel-Hurtado O, 2007, CAR C SECUR, P23
   Mohammed RA, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND COMPUTATIONAL INTELLIGENCE (CSCI), P519, DOI 10.1109/CSCI.2015.180
   Moos S, 2017, INT J INTERACT DES M, V11, P1, DOI 10.1007/s12008-014-0244-1
   Mukherjee A, 2017, INT J UNCERTAIN QUAN, V7, P23, DOI 10.1615/Int.J.UncertaintyQuantification.2016017192
   NAGEL RN, 1977, IEEE T COMPUT, V26, P895, DOI 10.1109/TC.1977.1674937
   Nan Xu, 2011, 2011 IEEE 3rd International Conference on Communication Software and Networks (ICCSN 2011), P357, DOI 10.1109/ICCSN.2011.6013611
   Nandi GC, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P1013, DOI 10.1109/TENCON.2016.7848159
   Nanni L, 2010, EXPERT SYST APPL, V37, P3676, DOI 10.1016/j.eswa.2009.10.023
   Naseer A., 2019, Neural Comput. Appl., P1
   Naz S, 2017, NEUROCOMPUTING, V243, P80, DOI 10.1016/j.neucom.2017.02.081
   Naz S, 2017, NEURAL COMPUT APPL, V28, P219, DOI 10.1007/s00521-015-2051-4
   Naz S, 2016, NEUROCOMPUTING, V177, P228, DOI 10.1016/j.neucom.2015.11.030
   Naz S, 2014, PATTERN RECOGN, V47, P1229, DOI 10.1016/j.patcog.2013.09.037
   Nazakat M., 2014, J APPL ENV BIOL SCI, V4, P342
   Neamah K, 2014, 3D RES, V5, DOI 10.1007/s13319-013-0002-3
   Nguyen L, 2010, ADDITIVE NUMBER THEORY: FESTSCHRIFT IN HONOR OF THE SIXTIETH BIRTHDAY OF MELVYN B. NATHANSON, P303, DOI 10.1007/978-0-387-68361-4_21
   Nguyen V, 2007, PROC INT CONF DOC, P734
   Nguyen V, 2011, PROC INT CONF DOC, P339, DOI 10.1109/ICDAR.2011.76
   Nilchiyan MR, 2013, 2013 FIRST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, MODELLING AND SIMULATION (AIMS 2013), P8, DOI 10.1109/AIMS.2013.10
   Okawa M, 2018, PATTERN RECOGN LETT, V113, P75, DOI 10.1016/j.patrec.2018.05.019
   Ong TS, 2009, 2009 INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND TECHNOLOGY, VOL II, PROCEEDINGS, P312, DOI 10.1109/ICCET.2009.128
   Ooi SY, 2016, APPL SOFT COMPUT, V40, P274, DOI 10.1016/j.asoc.2015.11.039
   Ortega-Garcia J, 2003, IEE P-VIS IMAGE SIGN, V150, P395, DOI 10.1049/ip-vis:20031078
   Pal S, 2012, INT CONF INTELL SYST, P586, DOI 10.1109/ISDA.2012.6416603
   Pansare A., 2012, Int. J. Appl. Inform. Syst, V1, P44
   Parodi M, 2011, PROC INT CONF DOC, P1289, DOI 10.1109/ICDAR.2011.259
   Parziale A, 2019, PATTERN RECOGN LETT, V121, P113, DOI 10.1016/j.patrec.2018.07.029
   Patil VM, 2017, ESMO OPEN, V2, DOI 10.1136/esmoopen-2017-000168
   Philip J, 2016, PROCEDIA COMPUT SCI, V79, P410, DOI 10.1016/j.procs.2016.03.053
   Pirlo G, 2015, IEEE T HUM-MACH SYST, V45, P805, DOI 10.1109/THMS.2015.2443050
   Pirlo G, 2013, IEEE T HUM-MACH SYST, V43, P499, DOI 10.1109/THMS.2013.2279008
   PLAMONDON R, 1989, PATTERN RECOGN, V22, P107, DOI 10.1016/0031-3203(89)90059-9
   Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821
   Polap D, 2016, INT J ELECTRON TELEC, V62, P197, DOI 10.1515/eletel-2016-0027
   Prabhakar S., 2003, IEEE Security & Privacy, V1, P33, DOI 10.1109/MSECP.2003.1193209
   Prabhakar S, 2007, IEEE T PATTERN ANAL, V29, P513, DOI 10.1109/TPAMI.2007.1025
   Putra MEW, 2015, PROCEDIA COMPUT SCI, V59, P340, DOI 10.1016/j.procs.2015.07.529
   Radhika KR, 2009, INT CONF MULTIMED, P216, DOI 10.1109/MMCS.2009.5256701
   Rajpal K., 2015, INT J COMPUTER SCI T, V3, P187
   Ramachandra AC, 2009, 2009 IEEE INTERNATIONAL ADVANCE COMPUTING CONFERENCE, VOLS 1-3, P1172
   Randhawa MK, 2013, IEEE INT ADV COMPUT, P600
   Rashidi S, 2012, SCI IRAN, V19, P1810, DOI 10.1016/j.scient.2012.05.007
   Rehman A, 2019, MULTIMED TOOLS APPL, V78, P10889, DOI 10.1007/s11042-018-6577-1
   Rehman A, 2019, IEEE ACCESS, V7, P17149, DOI 10.1109/ACCESS.2018.2890810
   Richiardi Jonas., 2003, Proceedings of the 2003 ACM SIGMM workshop on Biometrics methods and applications, P115, DOI [10.1145/982507.982528, DOI 10.1145/982507.982528]
   Rosso OA, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0166868
   Sabourin R., 1997, Advances in Document Image Analysis. First Brazilian Symposium, BSDIA '97. Proceedings, P84
   Saini R, 2015, 2015 NATIONAL CONFERENCE ON RECENT ADVANCES IN ELECTRONICS & COMPUTER ENGINEERING (RAECE), P1, DOI 10.1109/RAECE.2015.7509884
   Sanmorino A, 2012, 2012 2ND INTERNATIONAL CONFERENCE ON UNCERTAINTY REASONING AND KNOWLEDGE ENGINEERING (URKE), P54, DOI 10.1109/URKE.2012.6319582
   Sayantan R., 2014, INT J COMPUTER APPL, V86, P35, DOI [10.5120/15009-3292, DOI 10.5120/15009-3292]
   Semwal VB, 2019, ADV INTELL SYST COMP, V748, P135, DOI 10.1007/978-981-13-0923-6_12
   Semwal VB, 2018, IEEE T AUTOM SCI ENG, V15, P104, DOI 10.1109/TASE.2016.2594191
   Semwal VB, 2017, NEURAL COMPUT APPL, V28, P565, DOI 10.1007/s00521-015-2089-3
   Semwal VB, 2016, IEEE SENS J, V16, P5805, DOI 10.1109/JSEN.2016.2570281
   Shah A.S., 2016, INT J SIGNAL PROCESS, V9, P205
   Shah A.S., 2017, Int. J. Database Theory Appl, V10, n, P139, DOI DOI 10.14257/IJDTA.2017.10.1.13
   Shanker AP, 2007, PATTERN RECOGN LETT, V28, P1407, DOI 10.1016/j.patrec.2007.02.016
   Sharma A, 2018, IEEE T CYBERNETICS, V48, P611, DOI 10.1109/TCYB.2017.2647826
   Sharma A, 2017, IEEE T INF FOREN SEC, V12, P705, DOI 10.1109/TIFS.2016.2632063
   Sharma A, 2016, PATTERN RECOGN LETT, V84, P22, DOI 10.1016/j.patrec.2016.07.015
   Shekar BH, 2019, LECT NOTE NETW SYST, V43, P359, DOI 10.1007/978-981-13-2514-4_30
   Shekar B. H., 2011, 2011 International Conference on Recent Trends in Information Technology (ICRTIT 2011), P134, DOI 10.1109/ICRTIT.2011.5972461
   Shin J, 2017, APPL COMPUT REV, V17, P26, DOI 10.1145/3090058.3090062
   Shirazi SH, 2018, CLUSTER COMPUT, V21, P691, DOI 10.1007/s10586-017-0978-1
   Soleimani A, 2017, IET BIOMETRICS, V6, P1, DOI 10.1049/iet-bmt.2015.0058
   Song XY, 2017, IEEE T SYST MAN CY-S, V47, P2663, DOI 10.1109/TSMC.2016.2597240
   Soutar C, 1998, P SOC PHOTO-OPT INS, V3386, P24, DOI 10.1117/12.304770
   Taherzadeh G., 2011, Proceedings of the 2011 13th International Conference on Advanced Communication Technology (ICACT). Smart Service Innovation through Mobile Interactivity, P772
   Tahir M, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING, ELECTRONIC AND ELECTRICAL ENGINEERING (ICE CUBE), P100, DOI 10.1109/ICECUBE.2016.7495205
   Tahir M, 2015, 2015 SECOND INTERNATIONAL CONFERENCE ON INFORMATION SECURITY AND CYBER FORENSICS (INFOSEC), P11, DOI 10.1109/InfoSec.2015.7435499
   Van BL, 2007, IEEE T SYST MAN CY B, V37, P1237, DOI 10.1109/TSMCB.2007.895323
   Vargas J. F., 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P587, DOI 10.1109/ICFHR.2010.96
   Vargas JF, 2007, PROC INT CONF DOC, P764
   Veeramachaneni K, 2005, IEEE T SYST MAN CY C, V35, P344, DOI 10.1109/TSMCC.2005.848191
   Wang DX, 2010, IEEE T INSTRUM MEAS, V59, P752, DOI 10.1109/TIM.2009.2037871
   Wilkin T., 2011, 2011 7th International Conference on Information Assurance and Security (IAS), P110, DOI 10.1109/ISIAS.2011.6122804
   Yang L, 2017, CHIN CONT DECIS CONF, P224, DOI 10.1109/CCDC.2017.7978096
   Yeung DY, 2004, LECT NOTES COMPUT SC, V3072, P16
   Yogesh V, 2015, INT J EMERG TECHNOL, V6, P63
   Yu Qiao, 2011, Proceedings 2011 International Conference on Information and Automation (ICIA 2011), P333, DOI 10.1109/ICINFA.2011.5949012
   Zhang D, 2005, IEEE T SYST MAN CY C, V35, P273, DOI 10.1109/TSMCC.2005.848152
   Zois Elias N., 2019, IEEE Transactions on Biometrics, Behavior, and Identity Science, V1, P68, DOI 10.1109/TBIOM.2019.2897802
   Zois EN, 2018, IEEE COMPUT SOC CONF, P545, DOI 10.1109/CVPRW.2018.00084
NR 234
TC 25
Z9 26
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 289
EP 340
DI 10.1007/s11042-019-08022-0
PG 52
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600013
DA 2024-07-18
ER

PT J
AU Verma, B
   Choudhary, A
AF Verma, Bindu
   Choudhary, Ayesha
TI Grassmann manifold based dynamic hand gesture recognition using depth
   data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic hand gesture recognition; Grassmann Manifold; RGB-D sensors;
   Hand gesture; Subspace learning
ID REAL-TIME; TRAJECTORIES
AB In this paper, we propose a novel Grassmann manifold based framework for dynamic hand gesture recognition from depth data. Automated dynamic hand gesture recognition is important for improving man-machine communication and understanding human behavior. It finds various applications such as human computer interaction, ambient assisted living, automated driver assisted systems. We use depth data or skeleton information to detect the fingertip and store the fingertip points to create the trajectory. In fingertip detection using depth data first we detect the hand using the depth data and used hand shape properties such as finger thickness, finger length, finger width and finger orientation angle to find the shape of the hand. If skeleton data is available we use skeleton information to detect the fingertip in each frame. Then geometrical features are extracted and a unique gesture subspaces created using SVD for each feature vector matrix of each gesture set. These gesture subspaces lie on a Grassmann manifold and capture the intra-class variations and increase the inter-class discriminatory power. We apply Grassmann manifold based discriminant analysis for recognizing each test gesture. We perform experiments on standard datasets and the results show that we have achieved recognition accuracy comparable to the state-of-the-art.
C1 [Verma, Bindu; Choudhary, Ayesha] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi, India.
C3 Jawaharlal Nehru University, New Delhi
RP Choudhary, A (corresponding author), Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi, India.
EM binduverma67@gmail.com; ayeshac@mail.jnu.ac.in
RI Verma, Bindu/AAU-4007-2020
OI Verma, Bindu/0000-0003-3534-3364; Choudhary, Ayesha/0000-0002-7544-4912
CR [Anonymous], 2013, IJCAI
   [Anonymous], 2008, P BMVC 2008 19 BRIT
   Caputo F. M., 2017, P STAG
   Chen FS, 2003, IMAGE VISION COMPUT, V21, P745, DOI 10.1016/S0262-8856(03)00070-2
   Chen XH, 2017, IEEE IMAGE PROC, P2881, DOI 10.1109/ICIP.2017.8296809
   Darrell T., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P335, DOI 10.1109/CVPR.1993.341109
   De Smedt Q., 2016, P IEEE C COMP VIS PA, P1
   Desmedt Y, 2016, MIST'16: PROCEEDINGS OF THE INTERNATIONAL WORKSHOP ON MANAGING INSIDER SECURITY THREATS, P89, DOI 10.1145/2995959.2995974
   Devineau G, 2018, IEEE INT CONF AUTOMA, P106, DOI 10.1109/FG.2018.00025
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Hamm Jihun, 2008, P 25 INT C MACH LEAR, P376, DOI DOI 10.1145/1390156.1390204
   Harandi M. T., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2705, DOI 10.1109/CVPR.2011.5995564
   Huang ZW, 2015, PROC CVPR IEEE, P140, DOI 10.1109/CVPR.2015.7298609
   Kurakin A, 2012, EUR SIGNAL PR CONF, P1975
   Ma CY, 2018, VISUAL COMPUT, V34, P1053, DOI 10.1007/s00371-018-1556-0
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Molchanov Pavlo, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P1, DOI 10.1109/CVPRW.2015.7301342
   Monnier C, 2015, LECT NOTES COMPUT SC, V8925, P491, DOI 10.1007/978-3-319-16178-5_34
   Nagi J., 2011, 2011 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2011), P342, DOI 10.1109/ICSIPA.2011.6144164
   Núñez JC, 2018, PATTERN RECOGN, V76, P80, DOI 10.1016/j.patcog.2017.10.033
   Ohn-Bar E, 2014, IEEE T INTELL TRANSP, V15, P2368, DOI 10.1109/TITS.2014.2337331
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   Plouffe G, 2016, IEEE T INSTRUM MEAS, V65, P305, DOI 10.1109/TIM.2015.2498560
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   Sathyanarayana S, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P769, DOI 10.1109/ICCVW.2013.105
   Shen XH, 2012, IMAGE VISION COMPUT, V30, P227, DOI 10.1016/j.imavis.2011.11.003
   Suarez J., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P411, DOI 10.1109/ROMAN.2012.6343787
   Tang B, 2013, IEEE SYS MAN CYBERN, P1, DOI 10.1109/SMC.2013.8
   Verma B, 2017, SPRINGER ADV INTELL, V614, P1
   Wang C, 2015, IEEE T MULTIMEDIA, V17, P29, DOI 10.1109/TMM.2014.2374357
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P1061, DOI 10.1109/TPAMI.2002.1023803
   Yao Y, 2014, IEEE T CIRC SYST VID, V24, P1935, DOI 10.1109/TCSVT.2014.2302538
   Yu MY, 2016, IEEE T PATTERN ANAL, V38, P1651, DOI 10.1109/TPAMI.2015.2491925
   Zhu GM, 2017, IEEE ACCESS, V5, P4517, DOI 10.1109/ACCESS.2017.2684186
NR 35
TC 9
Z9 9
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2213
EP 2237
DI 10.1007/s11042-019-08266-w
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000515433000023
DA 2024-07-18
ER

PT J
AU El Hazzat, S
   El Akkad, N
   Merras, M
   Saaidi, A
   Satori, K
AF El Hazzat, Soulaiman
   El Akkad, Nabil
   Merras, Mostafa
   Saaidi, Abderrahim
   Satori, Khalid
TI Fast 3D reconstruction and modeling method based on the good choice of
   image pairs for modified match propagation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image couples selection; Modified match propagation; 3D reconstruction;
   3D point cloud
ID STEREO; CAMERA; SYSTEM; DEPTH
AB Structure from Motion (SfM) is a 3D reconstruction approach for estimating camera poses and 3D structure from calibrated images. The recovered 3D structure is a sparse 3D point cloud that not permit to well define the shape of the object/scene. We must therefore move to a dense 3D reconstruction that requires a step of the dense matching between pairs of consecutive images, which requires a long calculation time. To reduce computation time, we have proposed an algorithm for the good choice of image pairs that will be used by the Modified Match Propagation (MMP) to improve the sparse 3D reconstruction. These image pairs will be selected on the basis of the result already achieved by SfM. The MMP algorithm will be applied for each image pair to retrieve new matches and their 3D coordinates. The final 3D point cloud is achieved by fusion of results obtained from the image pairs selected. The realistic 3D model is recovered after applying the Poisson surface reconstruction method with texture mapping. The results of the experiments show the speed of the proposed approach without losing quality of 3D reconstructed models.
C1 [El Hazzat, Soulaiman; El Akkad, Nabil; Merras, Mostafa; Saaidi, Abderrahim; Satori, Khalid] Sidi Mohamed Ben Abdellah Univ, Fac Sci Dhar Mahraz, Dept Math & Informat, LIIAN, Fes, Morocco.
   [Saaidi, Abderrahim] Sidi Mohamed Ben Abdellah Univ, Polydisciplinary Fac Taza, Dept Math Phys & Informat, LSI, Taza, Morocco.
   [El Akkad, Nabil] Sidi Mohammed Ben Abdellah Univ, Lab Engn Syst & Applicat, ENSA Fez, Fes 30050, Morocco.
   [Merras, Mostafa] Moulay Ismail Univ, High Sch Technol, Dept Comp Sci, Meknes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez; Sidi Mohamed Ben Abdellah University of Fez; Moulay
   Ismail University of Meknes
RP El Hazzat, S (corresponding author), Sidi Mohamed Ben Abdellah Univ, Fac Sci Dhar Mahraz, Dept Math & Informat, LIIAN, Fes, Morocco.
EM soulaiman.elhazzat@yahoo.fr
RI AKKAD, Nabil EL/AAL-4049-2020; El Hazzat, Soulaiman/AAI-6689-2020;
   satori, khalid/GSE-3077-2022; Merras, Mostafa/AAJ-4405-2020
OI AKKAD, Nabil EL/0000-0003-0277-8003; Merras,
   Mostafa/0000-0002-3020-726X; SATORI, khalid/0000-0001-6055-4169; El
   Hazzat, Soulaiman/0000-0002-6647-1767
CR [Anonymous], 2008, P IEEE C COMP VIS PA
   Blumenthal-Barby DC, 2014, COMPUT GRAPH-UK, V39, P89, DOI 10.1016/j.cag.2013.12.001
   Cui HN, 2017, PROC CVPR IEEE, P2393, DOI 10.1109/CVPR.2017.257
   El Akkad N, 2016, 3D RES, V7, DOI 10.1007/s13319-016-0082-y
   El hazzat Soulaiman, 2014, 2014 Fifth International Conference on Next-Generation Networks and Services (NGNS), P194, DOI 10.1109/NGNS.2014.6990252
   El Hazzat S., 2015, Complex Systems (WCCS), 2015 Third World Conference on, P1
   El Hazzat S, 2019, MULTIMED TOOLS APPL, V78, P14251, DOI 10.1007/s11042-018-6828-1
   El Hazzat S, 2018, VISUAL COMPUT, V34, P1443, DOI 10.1007/s00371-017-1451-0
   El Hazzat S, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0041-z
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Furukawa Y, 2010, PROC CVPR IEEE, P1434, DOI 10.1109/CVPR.2010.5539802
   Haro G, 2010, IMAGE VISION COMPUT, V28, P1354, DOI 10.1016/j.imavis.2010.01.016
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Kolev K, 2009, INT J COMPUT VISION, V84, P80, DOI 10.1007/s11263-009-0233-1
   Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954
   LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735
   Li YF, 2004, IEEE T ROBOTIC AUTOM, V20, P15, DOI 10.1109/TRA.2003.820925
   Lin C, 2017, SIGNAL PROCESS-IMAGE, V52, P64, DOI 10.1016/j.image.2017.01.001
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu XS, 2019, MULTIMED TOOLS APPL, V78, P507, DOI 10.1007/s11042-017-5251-3
   Merras M, 2017, INT J AUTOM COMPUT, V14, P661, DOI 10.1007/s11633-016-0999-x
   Mouragnon E, 2009, IMAGE VISION COMPUT, V27, P1178, DOI 10.1016/j.imavis.2008.11.006
   Tola E, 2012, MACH VISION APPL, V23, P903, DOI 10.1007/s00138-011-0346-8
   VU H, 2009, P COMP VIS PATT REC
   Wang YC, 2012, IEEE T PATTERN ANAL, V34, P548, DOI 10.1109/TPAMI.2011.162
   Wu BC, 2019, IEEE INT CONF ROBOT, P4376, DOI [10.1109/ICRA.2019.8793495, 10.1109/icra.2019.8793495]
   Wu CC, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P127, DOI 10.1109/3DV.2013.25
   Xie H, 2018, IEEE T MULTIMED, V21, P2685
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yang MD, 2013, AUTOMAT CONSTR, V33, P48, DOI 10.1016/j.autcon.2012.09.017
   Zhang K, 2006, INT J ADV MANUF TECH, V29, P722, DOI 10.1007/s00170-005-2566-4
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhao SC, 2015, NEUROCOMPUTING, V151, P533, DOI 10.1016/j.neucom.2014.03.092
NR 34
TC 5
Z9 5
U1 3
U2 51
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7159
EP 7173
DI 10.1007/s11042-019-08379-2
EA DEC 2019
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000503664300001
DA 2024-07-18
ER

PT J
AU Dornaika, F
   Elorza, A
   Wang, K
   Arganda-Carreras, I
AF Dornaika, F.
   Elorza, A.
   Wang, K.
   Arganda-Carreras, I.
TI Image-based face beauty analysis via graph-based semi-supervised
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image-based face beauty analysis; Semi-supervised learning; Graph-based
   label propagation; Deep face features
ID FACIAL ATTRACTIVENESS
AB Automatic facial beauty analysis has become an emerging research topic. Despite some achieved advances, current methods and systems suffer from at least two limitations. Firstly, many developed systems rely on the use of ad-hoc hand-crafted features that were designed for generic pattern recognition problems. Secondly, while Deep Convolutional Neural Nets (DCNN) have been recently demonstrated to be a promising area of research in statistical machine learning, their use for automatic face beauty analysis may not guarantee optimal performances due to the use of a limited amount of face images with beauty scores. In this paper, we attempt to overcome these two main limitations by jointly exploiting two tricks. First, instead of using hand-crafted face features we use deep features of a pre-trained DCNN able to generate a high-level representation of a face image. Second, we exploit manifold learning theory and deploy three graph-based semi-supervised learning methods in order to enrich model learning without the need of additional labeled face images. These schemes perform graph-based score propagation. The proposed schemes were tested on three public datasets for beauty analysis: SCUT-FBP, (MB)-B-2, and SCUT-FBP5500. These experiments, as well as many comparisons with supervised schemes, show that the scheme coined Kernel Flexible Manifold Embedding compares favorably with many supervised schemes. They also show that its performances in terms of error prediction and Pearson Correlation are better than those reported for the used datasets.
C1 [Dornaika, F.; Elorza, A.; Wang, K.; Arganda-Carreras, I.] Univ Basque Country UPV EHU, San Sebastian, Spain.
   [Dornaika, F.; Arganda-Carreras, I.] Basque Fdn Sci, Ikerbasque, Bilbao, Spain.
   [Wang, K.] Northwestern Polytech Univ, Xian, Shaanxi, Peoples R China.
   [Arganda-Carreras, I.] DIPC, San Sebastian, Spain.
C3 University of Basque Country; Basque Foundation for Science;
   Northwestern Polytechnical University
RP Dornaika, F (corresponding author), Univ Basque Country UPV EHU, San Sebastian, Spain.; Dornaika, F (corresponding author), Basque Fdn Sci, Ikerbasque, Bilbao, Spain.
EM fdornaika@gmail.com
RI ; Arganda-Carreras, Ignacio/L-4605-2014
OI Dornaika, Fadi/0000-0001-6581-9680; Arganda-Carreras,
   Ignacio/0000-0003-0229-5722
CR [Anonymous], 2016, PROC IEEE INT C PATT
   [Anonymous], ARXIV180106345V1CSCV
   [Anonymous], C P IEEE INT C SYST
   [Anonymous], 2016, Computer models for facial beauty analysis
   Bainbridge WA, 2013, J EXP PSYCHOL GEN, V142, P1323, DOI 10.1037/a0033872
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Bi J., 2003, P 20 INT C MACH LEAR, P43
   Bottino A, 2010, LECT NOTES COMPUT SC, V6111, P425, DOI 10.1007/978-3-642-13772-3_43
   Cheng B, 2010, IEEE T IMAGE PROCESS, V19, P858, DOI 10.1109/TIP.2009.2038764
   DEBACCO C, 2018, ARXIV170909002
   Dornaika F, 2015, INFORM SCIENCES, V325, P118, DOI 10.1016/j.ins.2015.07.005
   Dornaika F, 2016, IEEE T CYBERNETICS, V46, P206, DOI 10.1109/TCYB.2015.2399456
   Dornaika F, 2013, LECT NOTES COMPUT SC, V8192, P182, DOI 10.1007/978-3-319-02895-8_17
   Eisenthal Y, 2006, NEURAL COMPUT, V18, P119, DOI 10.1162/089976606774841602
   El Traboulsi Y, 2015, NEUROCOMPUTING, V167, P517, DOI 10.1016/j.neucom.2015.04.042
   Gan J.Y., 2015, P INT C IM GRAPH, P350
   Gan JY, 2014, NEUROCOMPUTING, V144, P295, DOI 10.1016/j.neucom.2014.05.028
   Gray D, 2010, LECT NOTES COMPUT SC, V6316, P434, DOI 10.1007/978-3-642-15567-3_32
   He R, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995487
   KAGIAN A, 2007, HUMANLIKE PREDICTOR, P649
   Kagian A, 2008, VISION RES, V48, P235, DOI 10.1016/j.visres.2007.11.007
   Laurentini A, 2014, COMPUT VIS IMAGE UND, V125, P184, DOI 10.1016/j.cviu.2014.04.006
   Liu S, 2016, MULTIMED TOOLS APPL, V75, P16633, DOI 10.1007/s11042-016-3830-3
   Mu YD, 2013, NEUROCOMPUTING, V99, P59, DOI 10.1016/j.neucom.2012.06.020
   Nguyen TV, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2501643.2501650
   Nie FP, 2016, AAAI CONF ARTIF INTE, P1969
   Nie FP, 2010, IEEE T IMAGE PROCESS, V19, P1921, DOI 10.1109/TIP.2010.2044958
   NIE L, 2016, LEARNING MULTIPLE SO
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Parkhi OM, 2015, Proceedings of the British Machine Vision Conference, DOI DOI 10.5244/C.29.41
   Raducanu B, 2014, PATTERN RECOGN, V47, P480, DOI 10.1016/j.patcog.2013.06.021
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schmid K, 2008, PATTERN RECOGN, V41, P2710, DOI 10.1016/j.patcog.2007.11.022
   Sutic Davor, 2010, 2010 33rd International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO), P1339
   Wang SY, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P805, DOI 10.1145/2647868.2654986
   Whitehill J, 2008, IEEE INT CONF AUTOMA, P17
   Xie D., 2015, ARXIV PREPRINT ARXIV
   Xie DR, 2015, IEEE SYS MAN CYBERN, P1821, DOI 10.1109/SMC.2015.319
   Zhang D, 2011, PATTERN RECOGN, V44, P940, DOI 10.1016/j.patcog.2010.10.013
   Zhou DY, 2004, ADV NEUR IN, V16, P321
   2016, 2016 IEEE GLOB COMM, P1
NR 42
TC 6
Z9 6
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 3005
EP 3030
DI 10.1007/s11042-019-08206-8
EA DEC 2019
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000500612000004
DA 2024-07-18
ER

PT J
AU Antonio, H
   Prasad, PWC
   Alsadoon, A
AF Antonio, Harianto
   Prasad, P. W. C.
   Alsadoon, Abeer
TI Implementation of cryptography in steganography for enhanced security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Cryptography; Encryption; Advanced encryption system;
   Information hiding; Exact matching algorithm; Image,Secret message; LSB;
   Andkey-dependent data technique
AB The rapid development in technology has had a great influence on the exchange of information. In this modern era, maintaining security during information exchanges is essential. There are many algorithms were used to ensure the exchanged data is confidential, with examples being cryptography and steganography. In this paper, we present a combined of bit matching steganography and Advanced Encryption System (AES) cryptography are used to improve the security of the exchanged data. Bit matching steganography has advantages in terms of payload capacity and image quality. The bit matching algorithm presented here is capable of finding the location of matching pixels and creates a key to retrieve the secret message. The AES algorithm is secure standard cryptography that ensures security of the generated key from attack. The proposed method utilizes the entire color channel to find the bit matching and then encrypts the key generated from the bit matching method before sending it to a receiver. Experimental results show that the proposed method has higher speed, an undistorted image, and unlimited payload capacity when compared with other popular steganography algorithms. Moreover, the proposed method also provides security against statistical steganalysis.
C1 [Antonio, Harianto; Prasad, P. W. C.; Alsadoon, Abeer] Charles Sturt Univ, Sydney Campus 63,Level 1,Oxford St, Sydney, NSW 2010, Australia.
C3 Charles Sturt University
RP Prasad, PWC (corresponding author), Charles Sturt Univ, Sydney Campus 63,Level 1,Oxford St, Sydney, NSW 2010, Australia.
EM cwithana@studygroup.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; withana,
   chandana/0000-0002-3007-687X
CR Al-Dmour H, 2016, EXPERT SYST APPL, V46, P293, DOI 10.1016/j.eswa.2015.10.024
   Al-Rahal M. Shady, 2016, Journal of Theoretical and Applied Information Technology, V87, P29
   Alamsyah, 2015, Journal of Theoretical and Applied Information Technology, V82, P106
   Ali A., 2016, INT J COMPUTER APPL, V133, P27
   Alsarayreh Maher A., 2017, Journal of Theoretical and Applied Information Technology, V95, P1212
   Chen WJ, 2010, EXPERT SYST APPL, V37, P3292, DOI 10.1016/j.eswa.2009.09.050
   Eng PMKM, 2014, INT J ELECT COMM ENG, V5, P26
   Fakhredanesh M, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.043007
   Jung KH, 2014, MULTIMED TOOLS APPL, V71, P1455, DOI 10.1007/s11042-012-1293-8
   Kanan HR, 2014, EXPERT SYST APPL, V41, P6123, DOI 10.1016/j.eswa.2014.04.022
   Mohamed M. H., 2016, Appl. Math. Inf. Sci., V10, P259, DOI [10.18576/amis/100126, DOI 10.18576/AMIS/100126]
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P8597, DOI 10.1007/s11042-016-3383-5
   Muhammad K, 2016, MULTIMED TOOLS APPL, V75, P14867, DOI 10.1007/s11042-015-2671-9
   Nameer NEE., 2007, J COMPUTER SCI, V3, P223, DOI [10.3844/jcssp.2007.223.232, DOI 10.3844/JCSSP.2007.223.232]
   Parah SA, 2014, COMPUT ELECTR ENG, V40, P70, DOI 10.1016/j.compeleceng.2013.11.006
   Sabeti V, 2013, MULTIMED TOOLS APPL, V64, P777, DOI 10.1007/s11042-011-0975-y
   Sun SL, 2016, INFORM PROCESS LETT, V116, P93, DOI 10.1016/j.ipl.2015.09.016
   Nguyen TD, 2016, MULTIMED TOOLS APPL, V75, P8319, DOI 10.1007/s11042-015-2752-9
   Nguyen TD, 2015, MULTIMED TOOLS APPL, V74, P5661, DOI 10.1007/s11042-014-1877-6
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
NR 20
TC 5
Z9 6
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 32721
EP 32734
DI 10.1007/s11042-019-7559-7
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600006
DA 2024-07-18
ER

PT J
AU Chidambaram, N
   Raj, P
   Thenmozhi, K
   Rajagopalan, S
   Amirtharajan, R
AF Chidambaram, Nithya
   Raj, Pethuru
   Thenmozhi, K.
   Rajagopalan, Sundararaman
   Amirtharajan, Rengarajan
TI A cloud compatible DNA coded security solution for multimedia file
   sharing & storage
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DNA coding; Chaotic maps; Image encryption; Cloud computing
ID IMAGE; ALGORITHM; ISSUES; CHALLENGES; PRIVACY; NETWORK; THREATS; 2D
AB The faster proliferation of software-defined cloud environments across the world for efficiently hosting enterprise-grade applications has led many organisations to embrace the cloud paradigm in a significant way. The cloud storage opportunities and possibilities are consistently expanding, wherein multimedia storage occupies the entire stage in the cloud. An essential emphasis on security owing to the nature of multiuser access to cloud credentials in many situations is necessary. The security and safety of data, while in transit, in rest, and while being used by applications, have to be guaranteed through proven technology solutions. Typically, image encryption is the standard way of securing and safeguarding images. The proposed three-layer image encryption scheme uses DNA coding along with chaotic logistic and tent maps for confusion and diffusion operations. Upon verification of user credentials, the storage of encrypted image is accomplished in Amazon S3 web services. The strength of encryption has been evaluated based on the parameters namely brute force attack, statistical, encryption quality, occlusion attack and computational complexity analyses which have proved the suitability of proposed scheme to secure cloud storage of images.
C1 [Chidambaram, Nithya; Thenmozhi, K.; Rajagopalan, Sundararaman; Amirtharajan, Rengarajan] SASTRA Deemed Univ, Sch Elect & Elect Engn, Dept ECE, Thanjavur 613401, India.
   [Raj, Pethuru] RJIL, Site Reliabil Engn SRE Div, Bangalore 560025, Karnataka, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Amirtharajan, R (corresponding author), SASTRA Deemed Univ, Sch Elect & Elect Engn, Dept ECE, Thanjavur 613401, India.
EM amir@ece.sastra.edu
RI Chidambaram, Nithya/AAU-7212-2021; Amirtharajan, Rengarajan/C-6471-2011
OI Amirtharajan, Rengarajan/0000-0003-1574-3045; Chidambaram, Dr
   Nithya/0000-0001-6623-3825; Karuppuswamy, Thenmozhi/0000-0001-9829-0189
CR Abbas NA, 2016, EGYPT INFORM J, V17, P139, DOI 10.1016/j.eij.2015.10.001
   Alsaedi M, 2017, MULTIMED TOOLS APPL, V76, P24527, DOI 10.1007/s11042-016-4206-4
   Asadi S, 2017, INFORM TECHNOL MANAG, V18, P305, DOI 10.1007/s10799-016-0270-8
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Broumandnia A, 2019, J INF SECUR APPL, V47, P188, DOI 10.1016/j.jisa.2019.05.004
   Çavusoglu Ü, 2017, CHAOS SOLITON FRACT, V95, P92, DOI 10.1016/j.chaos.2016.12.018
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Diaconu AV, 2016, INFORM SCIENCES, V355, P314, DOI 10.1016/j.ins.2015.10.027
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   Hu T, 2017, SIGNAL PROCESS, V134, P234, DOI 10.1016/j.sigpro.2016.12.008
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Huang XL, 2018, MULTIMED TOOLS APPL, V77, P2611, DOI 10.1007/s11042-017-4455-x
   Khan M, 2015, NEURAL COMPUT APPL, V26, P1137, DOI 10.1007/s00521-014-1800-0
   Khan MA, 2016, J NETW COMPUT APPL, V71, P11, DOI 10.1016/j.jnca.2016.05.010
   Kumari M, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0148-5
   Ponuma R, 2018, MULTIMED TOOLS APPL, V77, P19209, DOI 10.1007/s11042-017-5378-2
   Qin Z, 2018, IEEE CLOUD COMPUT, V5, P48
   Rathore S, 2017, INFORM SCIENCES, V421, P43, DOI 10.1016/j.ins.2017.08.063
   Ravichandran D, 2017, IEEE T NANOBIOSCI, V16, P850, DOI 10.1109/TNB.2017.2780881
   Shahzadi S, 2017, J CLOUD COMPUT-ADV S, V6, DOI 10.1186/s13677-017-0097-9
   Singh A, 2017, J NETW COMPUT APPL, V79, P88, DOI 10.1016/j.jnca.2016.11.027
   Singh S, 2016, J NETW COMPUT APPL, V75, P200, DOI 10.1016/j.jnca.2016.09.002
   Tao M, 2017, FUTURE GENER COMP SY, V76, P528, DOI 10.1016/j.future.2016.11.012
   Wang B, 2016, OPTIK, V127, P3541, DOI 10.1016/j.ijleo.2016.01.015
   Wang CQ, 2017, MULTIMED TOOLS APPL, V76, P24251, DOI 10.1007/s11042-016-4102-y
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Yang RP, 2018, FUTURE GENER COMP SY, V78, P799, DOI 10.1016/j.future.2017.05.035
   Zhang Q, 2014, AEU-INT J ELECTRON C, V68, P186, DOI 10.1016/j.aeue.2013.08.007
   Zhang YS, 2018, IEEE INTERNET THINGS, V5, P3442, DOI 10.1109/JIOT.2017.2781737
NR 31
TC 14
Z9 15
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33837
EP 33863
DI 10.1007/s11042-019-08166-z
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600056
DA 2024-07-18
ER

PT J
AU Zulkifley, MA
   Abdani, SR
   Zulkifley, NH
AF Zulkifley, Mohd Asyraf
   Abdani, Siti Raihanah
   Zulkifley, Nuraisyah Hani
TI Pterygium-Net: a deep learning approach to pterygium detection and
   localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pterygium detection; Pterygium localization; Machine learning
AB Automatic pterygium detection is an essential screening tool for health community service groups. It allows non-expert to perform screening process without the needs of big and expensive equipment, especially for the application in rural areas. Thence, patients who have been screened as positive pterygium will be referred to the certified medical personnel for further diagnosis and treatment. Current state-of-the-art algorithms for pterygium detection rely on basic machine learning approach such as artificial neural network and support vector machine, which have not yet achieved high detection sensitivity and specificity as required in standard medical practice. Hence, a deep learning approach based on fully convolutional neural networks is proposed to detect and localize the pterygium infected tissues automatically. The input image requirement for the developed system is low as any commercial mobile phone camera is sufficient. Moreover, the developed algorithm, which we refer as Pterygium-Net works well even if the eye image is captured under low lighting condition with pupil position is not at the center location. Pterygium-Net utilizes three layers of convolutional neural networks (CNN) and three layers of fully connected networks. Two steps are implemented to overcome lacks of training data by generating synthetic images and pre-training the CNN weights and biases in a different public dataset. As for pterygium localization, an additional step of box proposal based on edges information is used to generate possible regions of the pterygium infected tissues. Hanning window is also applied to the generated regions to give more weightage to the center area. Experimental results show that Pterygium-Net produces high average detection sensitivity and specificity of 0.95 and 0.983, respectively. As for pterygium tissues localization, the algorithm achieves 0.811 accuracy with a very low failure rate of 0.053. In the future, deeper networks can be implemented to further improve pterygium localization.
C1 [Zulkifley, Mohd Asyraf; Abdani, Siti Raihanah] Univ Kebangsaan Malaysia, Fac Engn & Built Environm, Ctr Integrated Syst Engn & Adv Technol, Ukm Bangi, Selangor, Malaysia.
   [Zulkifley, Nuraisyah Hani] Univ Putra Malaysia, Fac Med & Hlth Sci, Dept Community Hlth, Serdang, Selangor, Malaysia.
C3 Universiti Kebangsaan Malaysia; Universiti Putra Malaysia
RP Zulkifley, MA (corresponding author), Univ Kebangsaan Malaysia, Fac Engn & Built Environm, Ctr Integrated Syst Engn & Adv Technol, Ukm Bangi, Selangor, Malaysia.
EM asyraf.zulkifley@ukm.edu.my
RI Zulkifley, Mohd Asyraf/AAZ-3652-2020; Zulkifley, Nuraisyah/KLZ-1562-2024
OI ZULKIFLEY, NURAISYAH HANI/0000-0002-9240-9668; Zulkifley, Mohd
   Asyraf/0000-0002-4010-3990
FU Universiti Kebangsaan Malaysia [DIP-2015-006, GUP-2015-053]
FX The authors would like to acknowledge fundings from Universiti
   Kebangsaan Malaysia (Dana Impak Perdana: DIP-2015-006 and Geran
   Universiti Penyelidikan: GUP-2015-053). The Titan V used for this
   research was donated by the NVIDIA Corporation (KK-2019-005).
CR Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chen XY, 2015, LECT NOTES COMPUT SC, V9351, P669, DOI 10.1007/978-3-319-24574-4_80
   Chishti SOA, 2018, 2018 IEEE 21ST INTERNATIONAL MULTI-TOPIC CONFERENCE (INMIC)
   Crewe JM, 2017, BR J OPHTHALMOL
   Dash Jyotiprava, 2017, Future Computing and Informatics Journal, V2, P103, DOI 10.1016/j.fcij.2017.10.001
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dorfler M, 2017, ARXIV170902291
   Eladawi N, 2018, MED PHYS
   Gao XT, 2012, IEEE ENG MED BIO, P4434, DOI 10.1109/EMBC.2012.6346950
   Ghazi MM, 2017, NEUROCOMPUTING, V235, P228, DOI 10.1016/j.neucom.2017.01.018
   Gondal WM, 2017, IEEE IMAGE PROC, P2069, DOI 10.1109/ICIP.2017.8296646
   Hartwell A, 2018, COMPACT DEEP NEURAL, P891
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Jamaludin A, 2017, MED IMAGE ANAL, V41, P63, DOI 10.1016/j.media.2017.07.002
   KimM Janssens O, 2018, MACH LEARN HLTH ML4H
   Kingma D. P., 2014, arXiv
   Lam C, 2018, AMIA JOINT SUMMITS T
   Lawhern V. J., 2018, Journal of neural engineering, V15, DOI DOI 10.1088/1741-2552/AACE8C
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu L, 2013, BMJ OPEN, V3, P1
   Maheshwari Sejal, 2003, Indian Journal of Ophthalmology, V51, P187
   Minami K, 2018, JPN J OPHTHALMOL, V62, P342, DOI 10.1007/s10384-018-0583-8
   Mohamed Nur Ayuni, 2015, Journal of Theoretical and Applied Information Technology, V81, P84
   Nam H., 2016, CORR
   Padmanabha AGA, 2017, 2017 12TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND KNOWLEDGE ENGINEERING (IEEE ISKE), DOI 10.1109/ISKE.2017.8258754
   Paing MP, 2016, BIOMED ENG INT CONF
   Ravishankar H, 2016, MICCAI WORKSHOP ON D
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salam AA, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3175-4
   Shi ZH, 2019, MULTIMED TOOLS APPL, V78, P1017, DOI 10.1007/s11042-018-6082-6
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smitha M, 2018, L N COMPUT VIS BIOME, V28, P982, DOI 10.1007/978-3-319-71767-8_84
   Song XM, 2018, ACM/SIGIR PROCEEDINGS 2018, P5, DOI 10.1145/3209978.3209996
   Song XM, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P753, DOI 10.1145/3123266.3123314
   Torrey L., 2010, IGI Global, P242, DOI 10.4018/978-1-60566-766-9.CH011
   Wang JT, 2018, IEEE T INTELL TRANSP, V19, P2913, DOI 10.1109/TITS.2017.2765676
   Yu Y, 2017, INFORMATION, V8
   Zaki WMDW, 2018, COMPUT METH PROG BIO, V154, P71, DOI 10.1016/j.cmpb.2017.10.026
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
   Zulkifley MA, 2019, IEEE ACCESS
   Zulkifley MA, 2019, IEEE ACCESS, V7, P32383, DOI 10.1109/ACCESS.2019.2903829
   Zulkifley MA, 2018, IEEE ACCESS, V6, P42790, DOI 10.1109/ACCESS.2018.2859595
NR 42
TC 25
Z9 26
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34563
EP 34584
DI 10.1007/s11042-019-08130-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800015
DA 2024-07-18
ER

PT J
AU Faragallah, OS
   AlZain, MA
   El-Sayed, HS
   Al-Amri, JF
   El-Shafai, W
   Afifi, A
   Naeem, EA
   Soh, B
AF Faragallah, Osama S.
   AlZain, Mohammed A.
   El-Sayed, Hala S.
   Al-Amri, Jehad F.
   El-Shafai, Walid
   Afifi, Ashraf
   Naeem, Ensherah A.
   Soh, Ben
TI Secure color image cryptosystem based on chaotic logistic in the FrFT
   domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cryptography; Image encryption; Fractional fourier transform (FrFT); 2D
   logistic map (2D LM); Security analysis; Noise immunity
ID ENCRYPTION ALGORITHM; TRANSFORM; PERMUTATION; DIFFUSION
AB Recently, the digital multimedia security technology has been an interesting research theme due to fast advancement in employing real time multimedia through Internet and wireless networks. The market of multimedia streaming, such as exclusive video on demand (VoD) is a huge multi- billion-dollar market. This market is threatened by hackers. The multimedia streaming industry needs a cryptosystem that is both fast and secure. Chaotic cryptosystems have been proposed by many researchers in order to promote communication security. However, these chaotic schemes have some major problems, such as unacceptable expansion of data, slow performance speed, and shortcomings against differential attack. Therefore, this paper provides an efficient Fractional Fourier Transform (FrFT)-based logistic map (LM) color image encryption scheme by applying a 2D LM on FrFT. In the proposed FrFT-based LM color image encryption scheme, the 2D LM is employed as a confusion step to scramble the color image pixel positions in the FrFT and confuse the relationship between the cipherimage and the plainimage. For enhancing the encryption performance characteristics of the 2D LM under the FrFT, the angle of the FrFT is taken as an extra additional key in encryption. The proposed FrFT-based LM color image encryption scheme is examined and investigated using visual inspection, entropy, histograms, encryption quality, noise tests, and differential analysis. The obtained simulation tests demonstrate and verify the effectiveness of the FrFT-based LM color image encryption scheme. Moreover, our results also show a significant improvement in the performance of the confusion property with our proposed 2D LM encryption scheme using the FrFT. Also, we compared the proposed cryptosystem with recent state-of-the-art cryptosystems. Experimental results show that our proposed image cryptosystem is highly secure from the cryptographic point of view. Furthermore, the obtained test results ensured the superiority of our proposed cryptosystem for digital image transmission compared to the recent state-of-theart cryptosystems.
C1 [Faragallah, Osama S.; AlZain, Mohammed A.; Al-Amri, Jehad F.] Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia, Egypt.
   [Faragallah, Osama S.; Afifi, Ashraf] Taif Univ, Coll Comp & Informat Technol, Dept Informat Technol, Al Hawiya 21974, Saudi Arabia.
   [El-Sayed, Hala S.] Menoufia Univ, Fac Engn, Dept Elect Engn, Shibin Al Kawm 32511, Egypt.
   [El-Shafai, Walid] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
   [Afifi, Ashraf] Higher Technol Inst, Dept Elect Engn & Comp, 10Th Of Ramadan, Egypt.
   [Naeem, Ensherah A.] Higher Inst Engn & Technol, Dept Elect & Elect Commun, Kafrelsheikh, Egypt.
   [Soh, Ben] La Trobe Univ, Dept Comp Sci & Comp Engn, Bundoora, Vic 3086, Australia.
C3 Egyptian Knowledge Bank (EKB); Menofia University; Taif University;
   Egyptian Knowledge Bank (EKB); Menofia University; Egyptian Knowledge
   Bank (EKB); Menofia University; Egyptian Knowledge Bank (EKB); Higher
   Technological Institute - Egypt; La Trobe University
RP El-Shafai, W (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
EM osam_sal@yahoo.com; hall_hhh@yahoo.com; j.alamri@tu.edu.sa;
   eng.waled.elshafai@gmail.com; a.afifi@tu.edu.sa
RI El-Shafai, Walid/AAG-4796-2021; Naeem, Ensherah/IWU-8523-2023; AlZain,
   Mohammed/ABH-2874-2021; serag, salwa/FQO-0974-2022; El-Sayed, Hala
   S./GXG-7641-2022; Faragallah, Osama S./AHB-8031-2022
OI El-Shafai, Walid/0000-0001-7509-2120; AlZain,
   Mohammed/0000-0001-5595-4280; serag, salwa/0000-0002-7474-7225;
   El-Sayed, Hala S./0000-0002-2776-783X; Faragallah, Osama
   S./0000-0003-1982-335X; Afifi, Ashraf/0000-0002-9366-4994
CR Abd El-Latif AA, 2018, IEEE ACCESS, V6, P21075, DOI 10.1109/ACCESS.2018.2820603
   Al-Ghamdi M, 2018, MULTIMED TOOLS APPL, V78, P1
   Al-Juaid N.A., 2018, J INF SECUR CYBERCRI, DOI [10.26735/16587790.2018.006, DOI 10.26735/16587790.2018.006]
   Al-Otaibi Nouf A., 2014, Lecture Notes on Information Theory, V2, P151, DOI 10.12720/lnit.2.2.151-157
   Alanazi N, 2018, 3 LAYER PC TEXT SECU
   Alassaf N., 2003, ARABIA
   Alassaf N, 2019, MULTIMED TOOLS APPL, V78, P32633, DOI 10.1007/s11042-018-6801-z
   Aljawarneh S, 2018, MULTIMED TOOLS APPL, V77, P10997, DOI 10.1007/s11042-017-4873-9
   Aljawarneh S, 2017, MULTIMED TOOLS APPL, V76, P22703, DOI 10.1007/s11042-016-4333-y
   Aljawarneh SA, 2016, FUTURE GENER COMP SY, V60, P67, DOI 10.1016/j.future.2016.01.020
   Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   Amin M, 2010, COMMUN NONLINEAR SCI, V15, P3484, DOI 10.1016/j.cnsns.2009.12.025
   [Anonymous], 2010, INT J SIGNAL IMAGE P
   [Anonymous], 2016, CIRCUITS SYSTEMS
   [Anonymous], 2018, J COMPUT SCI COMPUT, DOI DOI 10.20967/JCSCM.2018.03.002
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen JX, 2015, OPT COMMUN, V341, P263, DOI 10.1016/j.optcom.2014.12.045
   Chen JX, 2018, SIGNAL PROCESS, V142, P340, DOI 10.1016/j.sigpro.2017.07.034
   Elhosany HM, 2012, RAD SCI C NRSC 2012, P223
   Guesmi R, 2016, MULTIMED TOOLS APPL, V75, P4753, DOI 10.1007/s11042-015-2501-0
   Gupta B.B., 2018, COMPUTER CYBER SECUR, P666
   Gupta P, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P19, DOI 10.1109/ICCSP.2016.7754217
   Gutub A, 2018, MULTIBITS STEGO SYST, DOI [10.63019/jche.v1i2.513, DOI 10.63019/JCHE.V1I2.513]
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Gutub A, 2019, 3D RES, V10, DOI 10.1007/s13319-019-0216-0
   Gutub A, 2019, MULTIMED TOOLS APPL, V78, P5591, DOI 10.1007/s11042-017-5293-6
   Gutub AAA, 2012, INT CONF ADV COMPUT, P116, DOI 10.1109/ACSAT.2012.44
   Hamza R, 2019, INF SCI
   Jiang XP, 2018, IEEE T IND INFORM, V14, P3281, DOI 10.1109/TII.2018.2810188
   Kong DZ, 2014, OPT LASER TECHNOL, V57, P343, DOI 10.1016/j.optlastec.2013.08.013
   Li JZ, 2018, MULTIMED TOOLS APPL, V77, P4545, DOI 10.1007/s11042-017-4452-0
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Özkaynak F, 2016, OPTIK, V127, P5190, DOI 10.1016/j.ijleo.2016.03.018
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Patidar V, 2009, COMMUN NONLINEAR SCI, V14, P3056, DOI 10.1016/j.cnsns.2008.11.005
   Ran QW, 2014, OPT LASER ENG, V62, P80, DOI 10.1016/j.optlaseng.2014.05.008
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Xu L, 2017, OPT LASER ENG, V91, P41, DOI 10.1016/j.optlaseng.2016.10.012
   Yavuz E, 2016, COMPUT ELECTR ENG, V54, P471, DOI 10.1016/j.compeleceng.2015.11.008
   Ye GD, 2016, SECUR COMMUN NETW, V9, P2015, DOI 10.1002/sec.1458
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
   Zou LM, 2019, MULTIMED TOOLS APPL, V78, P7965, DOI 10.1007/s11042-018-6444-0
NR 46
TC 42
Z9 42
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2495
EP 2519
DI 10.1007/s11042-019-08190-z
EA NOV 2019
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NR2US
UT WOS:000498031400001
DA 2024-07-18
ER

PT J
AU Ali, KM
   Khan, M
AF Ali, Khawaja Muhammad
   Khan, Majid
TI A new construction of confusion component of block ciphers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE S-boxes; Confusion; Block ciphers
ID CHAOTIC S-BOXES; SUBSTITUTION BOX; OPTIMIZATION; SCHEME; DESIGN;
   BIFURCATION; MAP
AB Confusion is one of the most important component of modern block ciphers. The security of modern encryption scheme is based on substitution and permutation network (SP-network). The idea of SP-network was proposed by Claude Shannon in 1949. Construction of optimal confusion component (substitution box) has been a prominent topic of interest. In this article, we have proposed a new technique for the construction of S-boxes which fulfill the required cryptographic properties. Our proposed scheme utilized double affine transformation which gives nonlinearity of 112 for each primitive irreducible polynomials of degree 8. The simulation results of our proposed nonlinear component are compared with some recently suggested substitution boxes (S-boxes) which demonstrate that the proposed scheme is more capable to construct strong nonlinear component of block encryption systems.
C1 [Ali, Khawaja Muhammad; Khan, Majid] Inst Space Technol, Cyber & Informat Secur Lab, Islamabad, Pakistan.
   [Ali, Khawaja Muhammad] Inst Space Technol, Dept Elect Engn, Islamabad, Pakistan.
   [Khan, Majid] Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.
RP Ali, KM (corresponding author), Inst Space Technol, Cyber & Informat Secur Lab, Islamabad, Pakistan.; Ali, KM (corresponding author), Inst Space Technol, Dept Elect Engn, Islamabad, Pakistan.
EM khawajamuhammadalizahid@gmail.com
RI Khan, Majid/T-9408-2019
OI Khan, Majid/0000-0001-5454-3770
CR Adams C., 1990, Journal of Cryptology, V3, P27, DOI 10.1007/BF00203967
   Ahmad M., 2016, Perspectives in Science, V8, P465
   Ahmad M, 2018, WIRELESS PERS COMMUN, V101, P1715, DOI 10.1007/s11277-018-5787-1
   Ahmad M, 2015, PROCEDIA COMPUT SCI, V57, P572, DOI 10.1016/j.procs.2015.07.394
   Ahmad M, 2014, 2014 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P255, DOI 10.1109/SPIN.2014.6776958
   Alamsyah, 2018, NONLINEAR DYNAM, V93, P2105, DOI 10.1007/s11071-018-4310-2
   Ali KM, 2019, INT J THEOR PHYS, V58, P3091, DOI 10.1007/s10773-019-04188-3
   Anees A, 2015, WIRELESS PERS COMMUN, V82, P1497, DOI 10.1007/s11277-015-2295-4
   [Anonymous], 2016, HDB APPL CRYPTOGRAPH
   [Anonymous], 2005, THESIS
   Bao Ngoc Tran, 2009, Proceedings of the 2009 International Conference on Computational Intelligence and Security (CIS 2009), P463, DOI 10.1109/CIS.2009.110
   Batool SI, 2019, MULTIMED TOOLS APPL, V78, P27611, DOI 10.1007/s11042-019-07881-x
   Belazi A, 2017, OPTIK, V130, P1438, DOI 10.1016/j.ijleo.2016.11.152
   Belazi A, 2017, NONLINEAR DYNAM, V87, P337, DOI 10.1007/s11071-016-3046-0
   Biham E., 1991, Journal of Cryptology, V4, P3, DOI 10.1007/BF00630563
   Çavusoglu Ü, 2017, NONLINEAR DYNAM, V87, P1081, DOI 10.1007/s11071-016-3099-0
   Clark JA, 2005, NEW GENERAT COMPUT, V23, P219, DOI 10.1007/BF03037656
   Cui LG, 2007, INT J INNOV COMPUT I, V3, P751
   Farah T, 2017, NONLINEAR DYNAM, V88, P1059, DOI 10.1007/s11071-016-3295-y
   Fuller J, 2005, NEW GENERAT COMPUT, V23, P201, DOI 10.1007/BF03037655
   Gondal MA, 2014, 3D RES, V5, DOI 10.1007/s13319-014-0017-4
   Guesmi R, 2014, I C COMP SYST APPLIC, P678, DOI 10.1109/AICCSA.2014.7073265
   Hussain I, 2013, NONLINEAR DYNAM, V74, P869, DOI 10.1007/s11071-013-1011-8
   Isa H, 2016, NEW GENERAT COMPUT, V34, P221, DOI 10.1007/s00354-016-0302-2
   Jamal SS, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0125-z
   Kazlauskas K, 2015, INFORMATICA-LITHUAN, V26, P51, DOI 10.15388/Informatica.2015.38
   Khan M, PLOS ONE, V13
   Khan M, 2017, NEURAL COMPUTING APP
   Khan M, 2019, MULTIMED TOOLS APPL, V78, P26203, DOI 10.1007/s11042-019-07818-4
   Khan M, 2019, WIRELESS PERS COMMUN, V109, P849, DOI 10.1007/s11277-019-06594-6
   Khan M, 2019, INT J THEOR PHYS, V58, P2720, DOI 10.1007/s10773-019-04162-z
   Khan M, 2017, MULTIMED TOOLS APPL, V76, P24027, DOI 10.1007/s11042-016-4090-y
   Khan M, 2016, NEURAL COMPUT APPL, V27, P677, DOI 10.1007/s00521-015-1887-y
   Khan M, 2016, SIGNAL IMAGE VIDEO P, V10, P293, DOI 10.1007/s11760-014-0741-5
   Khan M, 2015, J VIB CONTROL, V21, P3450, DOI 10.1177/1077546314523029
   Khan M, 2015, NONLINEAR DYNAM, V82, P527, DOI 10.1007/s11071-015-2173-3
   Khan M, 2015, J INTELL FUZZY SYST, V28, P1509, DOI 10.3233/IFS-141434
   Khan M, 2015, SIGNAL IMAGE VIDEO P, V9, P1335, DOI 10.1007/s11760-013-0577-4
   Khan M, 2012, NONLINEAR DYNAM, V70, P2303, DOI 10.1007/s11071-012-0621-x
   Khan M, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0043-x
   Lambic D, 2017, NONLINEAR DYNAM, V87, P2407, DOI 10.1007/s11071-016-3199-x
   Laskari EC, 2006, 2006 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, PTS 1 AND 2, PROCEEDINGS, P1299, DOI 10.1109/ICCIAS.2006.295267
   Liu GJ, 2015, NONLINEAR DYNAM, V82, P1867, DOI 10.1007/s11071-015-2283-y
   Millan W., 1998, Information Security and Privacy. Third Australasian Conference, ACISP'98. Proceedings, P181, DOI 10.1007/BFb0053732
   Özkaynak F, 2017, SIGNAL IMAGE VIDEO P, V11, P659, DOI 10.1007/s11760-016-1007-1
   Özkaynak F, 2013, NONLINEAR DYNAM, V74, P551, DOI 10.1007/s11071-013-0987-4
   Schneier B., 1996, Applied Cryptography: Protocols, Algorithms, and Source Code in C
   ul Islam F, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0119-x
   Ullah A, 2017, NONLINEAR DYNAM, V88, P2757, DOI 10.1007/s11071-017-3409-1
   Wang Y, 2012, PHYS LETT A, V376, P827, DOI 10.1016/j.physleta.2012.01.009
   Waseem HM, 2019, APPL PHYS B-LASERS O, V125, DOI 10.1007/s00340-019-7142-y
   Waseem HM, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.6.063022
   Waseem HM, 2018, INT J THEOR PHYS, V57, P3584, DOI 10.1007/s10773-018-3872-6
   Wei ZC, 2016, NONLINEAR DYNAM, V85, P1635, DOI 10.1007/s11071-016-2783-4
   Wei ZC, 2015, NONLINEAR DYNAM, V82, P131, DOI 10.1007/s11071-015-2144-8
   Yong W., 2012, HKIE Trans, V19, P53, DOI DOI 10.1080/1023697X.2012.10669006
   Younas I, 2018, INT J ENTROPY
NR 57
TC 39
Z9 39
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 32585
EP 32604
DI 10.1007/s11042-019-07866-w
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000067
DA 2024-07-18
ER

PT J
AU Chen, KM
   Chang, CC
AF Chen, Kaimeng
   Chang, Chin-Chen
TI Error-free separable reversible data hiding in encrypted images using
   linear regression and prediction error map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Encrypted image; Linear regression
ID DIFFERENCE; DIVISION
AB In this paper, we propose a new reversible data-hiding method in encrypted images. The method is a vacating room after encryption (VRAE) method that attempts to achieve the error-free recovery of images. In previous VRAE methods, errors may occur in recovering images because of inaccurate predictions, so these methods cannot achieve complete reversibility. In addition, these methods have limited embedding rates. To solve these problems, the proposed method uses a linear, regression-based predictor to improve the accuracy of predictions, and it uses a prediction error map to eliminate errors caused by inaccurate predictions. By using the linear regression-based predictor and the prediction error map, the embedding rate of data embedding is improved significantly, and the original image can be recovered with no error. The experimental results showed that the embedding rate of the proposed method can be higher than 0.5 bpp, and the visual quality can be maintained at high embedding rates.
C1 [Chen, Kaimeng] Jimei Univ, Comp Engn Coll, Xiamen 361021, Fujian, Peoples R China.
   [Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
C3 Jimei University; Feng Chia University
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
EM chenkaimeng@jmu.edu.cn; alan3c@gmail.com
RI Chang, Ching-Chun/JAN-6210-2023
FU Natural Science Foundation of Fujian Province, China [2017 J05104,
   2019H0021]; National Natural Science Foundation of China [61701191];
   Xiamen Foundation for Science and Technology [3502Z20173028]
FX This paper is supported by the Natural Science Foundation of Fujian
   Province, China (2017 J05104, 2019H0021), the National Natural Science
   Foundation of China (61701191), and the Xiamen Foundation for Science
   and Technology (3502Z20173028).
CR Abu-Marie W., 2010, International Journal of Signal and Image Processing, V1, P196
   Al-Ghamdi M, 2019, MULTIMED TOOLS APPL, V78, P16283, DOI 10.1007/s11042-018-6977-2
   Al-Juaid N., 2018, J INF SECUR CYBERCRI, V1, P8, DOI [10.26735/16587790.2018.006, DOI 10.26735/16587790.2018.006]
   Al-Otaibi Nouf A., 2014, Lecture Notes on Information Theory, V2, P151, DOI 10.12720/lnit.2.2.151-157
   Alanizy N., 2018, J RES ENG APPL SCI J, V3, P118, DOI DOI 10.46565/JREAS.2018.V03I04.001
   Alassaf N, 2019, MULTIMED TOOLS APPL, V78, P32633, DOI 10.1007/s11042-018-6801-z
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   [Anonymous], WOSPA 2008
   [Anonymous], 2014, INT C ADV ENG TECHN
   [Anonymous], 4 IEEE GCC C EXH
   [Anonymous], 2018, J COMPUT SCI COMPUT, DOI DOI 10.20967/JCSCM.2018.03.002
   [Anonymous], 2011, P 13 INF HID C PRAG
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Caldelli R, 2010, EURASIP J INF SECUR, DOI 10.1155/2010/134546
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Chen KM, 2019, J VIS COMMUN IMAGE R, V58, P334, DOI 10.1016/j.jvcir.2018.12.023
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Dragoi IC, 2017, EUR SIGNAL PR CONF, P2186, DOI 10.23919/EUSIPCO.2017.8081597
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Gupta B.B., 2018, Computer and Cyber Security: Principles, Algorithm, Applications, and Perspectives
   Gutub A, 2018, J. Comput. Hardw. Eng, V1, P1
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Gutub A, 2019, MULTIMED TOOLS APPL, V78, P5591, DOI 10.1007/s11042-017-5293-6
   Gutub A, 2009, 2009 IEEE/ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS, VOLS 1 AND 2, P400, DOI 10.1109/AICCSA.2009.5069356
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Li M, 2015, SIGNAL PROCESS-IMAGE, V39, P234, DOI 10.1016/j.image.2015.10.001
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Liu WL, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9120308
   Liu ZL, 2018, INFORM SCIENCES, V433, P188, DOI 10.1016/j.ins.2017.12.044
   Luo L, IEEE T INFORM FOREN, V5, P187
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ni ZC, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P912
   Norah A, 2017, J RES ENG APPL SCI J, V2, P50, DOI DOI 10.46565/JREAS.2017.V02I02.002
   Ou B, 2014, SIGNAL PROCESS-IMAGE, V29, P760, DOI 10.1016/j.image.2014.05.003
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Qian ZX, 2016, IEEE SIGNAL PROC LET, V23, P1672, DOI 10.1109/LSP.2016.2585580
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Qin C, 2018, INFORM SCIENCES, V465, P285, DOI 10.1016/j.ins.2018.07.021
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qiu YQ, 2016, IEEE SIGNAL PROC LET, V23, P130, DOI 10.1109/LSP.2015.2504464
   Qu X, 2015, SIGNAL PROCESS, V111, P249, DOI 10.1016/j.sigpro.2015.01.002
   Shi YQ, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 2, PROCEEDINGS, P33
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang X, 2015, INFORM SCIENCES, V310, P16, DOI 10.1016/j.ins.2015.03.022
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Xiao D, 2017, J VIS COMMUN IMAGE R, V45, P1, DOI 10.1016/j.jvcir.2017.02.001
   Yi S, 2019, IEEE T MULTIMEDIA, V21, P51, DOI 10.1109/TMM.2018.2844679
   Yi S, 2018, SIGNAL PROCESS-IMAGE, V64, P78, DOI 10.1016/j.image.2018.03.001
   Yi S, 2017, SIGNAL PROCESS, V133, P40, DOI 10.1016/j.sigpro.2016.10.017
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhang XP, 2014, J VIS COMMUN IMAGE R, V25, P322, DOI 10.1016/j.jvcir.2013.11.001
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zheng QM, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2017.2775038
   Zhou JT, 2016, IEEE T CIRC SYST VID, V26, P441, DOI 10.1109/TCSVT.2015.2416591
NR 60
TC 18
Z9 18
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31441
EP 31465
DI 10.1007/s11042-019-07946-x
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000021
DA 2024-07-18
ER

PT J
AU Fu, B
   Zhao, XY
   Li, Y
   Wang, XH
AF Fu, Bo
   Zhao, XiaoYang
   Li, Yi
   Wang, XiangHai
TI Patch-based contour prior image denoising for salt and pepper noise
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Patch directional prior; Salt and pepper noise; Total
   variation
ID SWITCHING MEDIAN FILTER; NETWORKS; REMOVAL
AB The salt and pepper noise brings a significant challenge to image denoising technology, i.e. how to remove the noise clearly and retain the details effectively? In this paper, we propose a patch-based contour prior denoising approach for salt and pepper noise. First, noisy image is cut into patches as basic representation unit, a discrete total variation model is designed to extract contour structures; Second, a weighted Euclidean distance is designed to search the most similar patches, then, corresponding contour stencils are extracted from these similar patches; At last, we build filter from contour stencils in the framework of regression. Numerical results illustrate that the proposed method is competitive with the state-of-the-art methods in terms of the peak signal-to-noise (PSNR) and visual effects.
C1 [Fu, Bo; Zhao, XiaoYang; Li, Yi; Wang, XiangHai] Liaoning Normal Univ, Coll Comp & Informat Technol, Dalian, Peoples R China.
C3 Liaoning Normal University
RP Fu, B (corresponding author), Liaoning Normal Univ, Coll Comp & Informat Technol, Dalian, Peoples R China.
EM fubo@lnnu.edu.cn; xhwang@lnnu.edu.cn
RI Wang, Xianghai/GRR-4512-2022
OI Wang, Xianghai/0000-0002-7600-9939; Fu, Bo/0000-0001-7030-821X
FU National Natural Science Foundation of China (NSFC) [61702246,
   41671439]; Liaoning Province of China General Project of Scientific
   Research [L2015285]; Doctoral Start-up Foundation of Liaoning Province
   [201601243]
FX This work is supported by the National Natural Science Foundation of
   China (NSFC) Grant No. 61702246, 41671439,r Liaoning Province of China
   General Project of Scientific Research No. L2015285, Doctoral Start-up
   Foundation of Liaoning Province No. 201601243.
CR Aiswarya K., 2010, Proceedings of the 2010 Second International Conference on Computer Modeling and Simulation (ICCMS 2010), P409, DOI 10.1109/ICCMS.2010.310
   Astola J., 1997, Fundamentals of nonlinear digital filtering, DOI DOI 10.1201/9781003067832
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Dabov K, 2013, IEEE T IMAGE PROCESS, V22, P119, DOI [10.1109/TIP.2012.2210725, DOI 10.1109/TIP.2012.2210725]
   Delon J, 2016, IMAGE PROCESS ON LIN, V6, P130, DOI 10.5201/ipol.2016.161
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Erkan U, 2018, TURK J ELECTR ENG CO, V26, P162, DOI 10.3906/elk-1705-256
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   Fan ZL, 2017, NEUROCOMPUTING, V243, P12, DOI 10.1016/j.neucom.2017.02.066
   Getreuer P., 2011, QUAL LIFE RES, V1, P389
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Jafar IF, 2013, IEEE T IMAGE PROCESS, V22, P1223, DOI 10.1109/TIP.2012.2228496
   Nasri M, 2013, SCI IRAN, V20, P760, DOI 10.1016/j.scient.2013.01.001
   Ng PE, 2006, IEEE T IMAGE PROCESS, V15, P1506, DOI 10.1109/TIP.2005.871129
   Novoselac V, 2015, INT SCI EXP C INT TE
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Varghese J, 2015, ARAB J SCI ENG, V40, P3233, DOI 10.1007/s13369-015-1799-2
   Vasanth K, 2013, P COMPUT SCI, V54, P595
   Wang W, 2011, IEEE SIGNAL PROC LET, V18, P551, DOI 10.1109/LSP.2011.2162583
   Wang Y, 2018, IEEE T NEURAL NETWOR
   Wang Y, 2018, NEURAL NETWORKS, V103, P1, DOI 10.1016/j.neunet.2018.03.006
   Wang Y, 2015, IEEE T IMAGE PROCESS, V24, P3939, DOI 10.1109/TIP.2015.2457339
   Wu L, 2018, ARXIV180411013
   Wu L, 2019, IEEE T CYBERNETICS, V49, P1791, DOI 10.1109/TCYB.2018.2813971
   Wu L, 2018, COMPUT VIS IMAGE UND, V167, P63, DOI 10.1016/j.cviu.2017.11.009
   Wu L, 2018, PATTERN RECOGN, V76, P727, DOI 10.1016/j.patcog.2017.10.004
   Wu L, 2018, PATTERN RECOGN, V73, P275, DOI 10.1016/j.patcog.2017.08.029
   Wu L, 2017, IMAGE VISION COMPUT, V57, P58, DOI 10.1016/j.imavis.2016.11.008
   Zhang SQ, 2002, IEEE SIGNAL PROC LET, V9, P360, DOI 10.1109/LSP.2002.805310
   Zhang W., 2016, P INT JOINT C ART IN, P2153
   Zhou YY, 2012, IET IMAGE PROCESS, V6, P976, DOI 10.1049/iet-ipr.2011.0312
NR 31
TC 3
Z9 3
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30865
EP 30875
DI 10.1007/s11042-018-6811-x
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200066
OA Green Submitted
DA 2024-07-18
ER

PT J
AU He, W
   Ko, HL
   Kim, YK
   Wu, JH
   Zhang, GY
   Qi, Q
   Tu, B
   Ou, XF
AF He, Wei
   Ko, Hak-Lim
   Kim, Yong Kwan
   Wu, Jianhui
   Zhang, Guoyun
   Qi, Qi
   Tu, Bing
   Ou, Xianfeng
TI Spatiotemporal local compact binary pattern for background subtraction
   in complex scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Background modeling; binary feature learning; local compact binary
   pattern; kernel density estimation; multi-color spaces
ID COLOR SPACE; MODEL
AB A variety of binary feature descriptors such as local binary pattern (LBP) and its variations have recently attracted considerable attention for modelling backgrounds, due to their robustness and strong discriminatory power. However, most existing binary feature descriptors fail to model complex scenes due to their sensitivity to noise. In this paper, we propose an effective local compact binary descriptor for background modelling. For each image, local compact binary patterns (LCBPs) are first extracted by computing a number of low-dimensional pixel difference vectors (PDVs). Then, the LCBP is extended to the spatiotemporal domain taking into account the temporal persistence of pixels, and a novel local compact binary descriptor, STLCBP, is proposed. Multiple color spaces are also considered in order to separate foreground from background pixels accurately. Finally, a joint domain-range adaptive kernel density estimate (KDE) model is used to estimate the background and foreground scores by combining texture features with color features. Experimental results on two well-known datasets, I2R and CDnet2014, demonstrate that the proposed approach significantly outperforms many state-of-the-art methods and works effectively on a wide range of complex videos.
C1 [He, Wei; Wu, Jianhui; Zhang, Guoyun; Qi, Qi; Tu, Bing; Ou, Xianfeng] Hunan Inst Sci & Technol, Sch Informat & Commun Engn, Yueyang 414006, Peoples R China.
   [He, Wei; Ko, Hak-Lim; Kim, Yong Kwan] Hoseo Univ, Dept Informat & Commun Engn, Asan 31499, South Korea.
C3 Hunan Institute of Science & Technology; Hoseo University
RP Ou, XF (corresponding author), Hunan Inst Sci & Technol, Sch Informat & Commun Engn, Yueyang 414006, Peoples R China.; Kim, YK (corresponding author), Hoseo Univ, Dept Informat & Commun Engn, Asan 31499, South Korea.
EM ykkim@hoseo.edu; ouxf@hnist.edu.cn
RI Kim, Yong Kwan/GQZ-6055-2022
OI ou, xianfeng/0000-0003-4419-7362
FU Hunan Provincial Natural Science Foundation of China [2019JJ40104,
   2019JJ50211, 2019JJ50212]; Open Fund of Education Department of Hunan
   Province [18K086]; Science and Technology Program of Hunan Province
   [2016TP1021]; Development of Distributed Underwater Monitoring and
   Control Networks - Ministry of Ocean and Fisheries, South Korea
FX This work has been supported in part by Hunan Provincial Natural Science
   Foundation of China (2019JJ40104, 2019JJ50211, 2019JJ50212), the Open
   Fund of Education Department of Hunan Province (18K086), the Science and
   Technology Program of Hunan Province (2016TP1021), the Development of
   Distributed Underwater Monitoring and Control Networks funded by the
   Ministry of Ocean and Fisheries, South Korea.
CR Amraee S, 2018, MULTIMED TOOLS APPL, V77, P14767, DOI 10.1007/s11042-017-5061-7
   [Anonymous], IEEE INTER SYMON INN
   Balcilar M, 2014, APPL MATH INFORM SCI, V8, P1755, DOI 10.12785/amis/080433
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Bilodeau GA, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P106, DOI 10.1109/CRV.2013.29
   Chen JG, 2011, EVID-BASED COMPL ALT, V2011, P1, DOI 10.1155/2011/209406
   Chen Mingliang, 2018, IEEE Trans Pattern Anal Mach Intell, V40, P1518, DOI 10.1109/TPAMI.2017.2717828
   Cuevas C, 2012, IEEE IMAGE PROC, P313, DOI 10.1109/ICIP.2012.6466858
   Duan YQ, 2018, IEEE T PATTERN ANAL, V40, P1139, DOI 10.1109/TPAMI.2017.2710183
   Elgammal A, 2002, P IEEE, V90, P1151, DOI 10.1109/JPROC.2002.801448
   Guo Lili., 2016, P IEEE C COMP VIS PA, P86
   Han B, 2008, IEEE T PATTERN ANAL, V30, P1186, DOI 10.1109/TPAMI.2007.70771
   He W, 2018, INT C PATT RECOG, P1518, DOI 10.1109/ICPR.2018.8545062
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   HEIKKILA M., 2004, British Machine Vision Conference, P187, DOI DOI 10.5244/C.18.21
   Hofmann Martin., 2012, 2012 IEEE COMPUTER S, P38, DOI DOI 10.1109/CVPRW.2012.6238925
   Johnson GM, 2010, COLOR RES APPL, V35, P387, DOI 10.1002/col.20561
   Karpagavalli P, 2017, MULTIMED TOOLS APPL, V76, P14129, DOI 10.1007/s11042-016-3777-4
   Li L, 2003, ICCAD-2003: IEEE/ACM DIGEST OF TECHNICAL PAPERS, P2
   Liao SC, 2010, PROC CVPR IEEE, P1301, DOI 10.1109/CVPR.2010.5539817
   Lin L, 2014, IEEE T IMAGE PROCESS, V23, P3191, DOI 10.1109/TIP.2014.2326776
   Lissner I, 2013, IEEE T IMAGE PROCESS, V22, P435, DOI 10.1109/TIP.2012.2216279
   Lissner I, 2012, IEEE T IMAGE PROCESS, V21, P1153, DOI 10.1109/TIP.2011.2163522
   Liu L, 2016, IEEE T IMAGE PROCESS, V25, P1368, DOI 10.1109/TIP.2016.2522378
   Liu WC, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P722, DOI 10.1109/ACPR.2013.125
   Liu X, 2015, IEEE T IMAGE PROCESS, V24, P2502, DOI 10.1109/TIP.2015.2419084
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Maddalena L., 2012, 2012 IEEE COMP SOC C, P21, DOI [10.1109/CVPRW.2012.6238922, DOI 10.1109/CVPRW.2012.6238922]
   Maddalena L, 2014, COMPUT VIS IMAGE UND, V122, P65, DOI 10.1016/j.cviu.2013.11.006
   Narayana M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.115
   Narayana M, 2012, PROC CVPR IEEE, P2104, DOI 10.1109/CVPR.2012.6247916
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pan Z, 2017, MULTIMED TOOLS APPL, V76, P16989, DOI 10.1007/s11042-016-3647-0
   Roy SM, 2018, IEEE T CIRC SYST VID, V28, P1513, DOI 10.1109/TCSVT.2017.2669362
   Sajid H, 2017, IEEE T IMAGE PROCESS, V26, P3249, DOI 10.1109/TIP.2017.2695882
   Seki M, 2003, PROC CVPR IEEE, P65
   Sheikh Y, 2005, IEEE T PATTERN ANAL, V27, P1778, DOI 10.1109/TPAMI.2005.213
   Shu Y, 2020, MULTIMED TOOLS APPL, V79, P5043, DOI 10.1007/s11042-018-6315-8
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Teng C, 2011, ACTA POLYM SIN, P1001, DOI 10.3724/SP.J.1105.2011.11123
   Wang Y., 2014, P IEEE C COMP VIS PA, P387, DOI 10.1109/ICIP40778.2020.9190887
   Wen ZW, 2013, MATH PROGRAM, V142, P397, DOI 10.1007/s10107-012-0584-1
   Wu JH, 2019, MULTIMED TOOLS APPL, V78, P877, DOI 10.1007/s11042-018-5763-5
   Xue GJ, 2010, IEEE INT CON MULTI, P1050, DOI 10.1109/ICME.2010.5582601
   Zhang SP, 2008, IEEE IMAGE PROC, P1556, DOI 10.1109/ICIP.2008.4712065
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao GY, 2012, IEEE T IMAGE PROCESS, V21, P1465, DOI 10.1109/TIP.2011.2175739
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 49
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31415
EP 31439
DI 10.1007/s11042-019-7688-z
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000020
DA 2024-07-18
ER

PT J
AU Saleem, N
   Khattak, MI
   Witjaksono, G
   Ahmad, G
AF Saleem, Nasir
   Khattak, Muhammad Irfan
   Witjaksono, Gunawan
   Ahmad, Gulzar
TI Variance based time-frequency mask estimation for unsupervised speech
   enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE A priori SNR estimation; Speech enhancement; Time-frequency masking;
   Variance-based features; Wiener gain; Intelligibility; Speech quality
ID NOISE-ESTIMATION; RESIDUAL NOISE; ACOUSTIC NOISE; BINARY; REDUCTION;
   ALGORITHM; NETWORKS; SPECTRUM
AB Variance based two dimensional time-frequency mask estimation for unsupervised speech enhancement is proposed to improve the speech quality and intelligibility by reducing the low-frequency residual noise distortion in the noisy speech signals. Unlike conventional speech enhancement methods, the proposed method is able to reduce the residual noise distortion by utilizing benefits of the less aggressive Wiener gain and variance based two dimensional time-frequency mask to establish a two-stage speech enhancement method. In the first stage, the less aggressive Wiener gain with modified a priori signal-to-noise (SNR) estimate is applied to the input noisy speech to obtain a reduced noise pre-processed speech signal. In the second stage, variance based features are extracted from the pre-processed speech and compared to a nonparametric adaptive threshold to construct a two dimensional time-frequency mask. The estimated mask is then applied to the pre-processed speech from the first stage to suppress the annoying residual noise distortion. A comparative performance study is included to demonstrate the effectiveness of the proposed method in various noisy conditions. The experimental results showed large improvements in terms of the perceptual evaluation of speech quality (PESQ), segmental SNR (SegSNR), residual noise distortion (BAK) and speech distortion (SIG) over that achieved with competing methods at different input SNRs. To measure the understanding of enhanced speech in different noisy conditions, short-time intelligibility prediction (STOI) is used which reinforced a better performance of the proposed method in terms of the speech intelligibility. The time-varying spectral analysis validated significant reduction of the residual noise components in the enhanced speech.
C1 [Saleem, Nasir] Gomal Univ, Fac Engn & Technol, Dept Elect Engn, Dera Ismail Khan 29050, Pakistan.
   [Saleem, Nasir; Khattak, Muhammad Irfan; Ahmad, Gulzar] Univ Engn & Technol, Dept Elect Engn, Peshawar 25000, Pakistan.
   [Witjaksono, Gunawan] Univ Teknol PETRONAS, Dept Elect & Elect Engn, Seri Iskandar, Malaysia.
C3 Gomal University; University of Engineering & Technology Peshawar;
   Universiti Teknologi Petronas
RP Saleem, N (corresponding author), Gomal Univ, Fac Engn & Technol, Dept Elect Engn, Dera Ismail Khan 29050, Pakistan.; Saleem, N (corresponding author), Univ Engn & Technol, Dept Elect Engn, Peshawar 25000, Pakistan.
EM nasirsaleem@gu.edu.pk
RI Saleem, Nasir/AAG-9197-2019
OI Saleem, Nasir/0000-0003-0010-0629; Ahmad, Gulzar/0000-0001-6832-1685;
   Witjaksono, Gunawan/0000-0002-9771-4223; Khattak,
   Muhammad/0000-0003-4655-938X
CR [Anonymous], 1969, IEEE T ACOUST SPEECH, VAU17, P225
   [Anonymous], 2018, ARXIV180907454
   [Anonymous], ARXIV190106970
   [Anonymous], 2000, ASR2000 AUTOMATIC SP
   [Anonymous], 2006, Computational auditory scene analysis: Principles, algorithms, and applications
   [Anonymous], MUSICAL NOISE REDUCT
   [Anonymous], 2015, COGNITIVELY INSPIRED
   [Anonymous], 2015, TECHNICAL J
   [Anonymous], 6 INT C INT SYST DES
   Bao F, 2018, APSIPA TRANS SIGNAL, V7, DOI 10.1017/ATSIP.2018.7
   Ben Aicha A, 2017, MULTIMED TOOLS APPL, V76, P23661, DOI 10.1007/s11042-016-4145-0
   BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209
   Braun S, 2015, INT CONF ACOUST SPEE, P360, DOI 10.1109/ICASSP.2015.7177991
   Chatlani N, 2012, IEEE T AUDIO SPEECH, V20, P1158, DOI 10.1109/TASL.2011.2172428
   Chehrehsa S, 2017, INT J ADAPT CONTROL, V31, P1491, DOI 10.1002/acs.2781
   Cohen I, 2002, IEEE SIGNAL PROC LET, V9, P12, DOI 10.1109/97.988717
   DeLiang Wang, 2008, Trends Amplif, V12, P332, DOI 10.1177/1084713808326455
   EPHRAIM Y, 1985, IEEE T ACOUST SPEECH, V33, P443, DOI 10.1109/TASSP.1985.1164550
   EPHRAIM Y, 1984, IEEE T ACOUST SPEECH, V32, P1109, DOI 10.1109/TASSP.1984.1164453
   Ferreira LB, 2019, ACTA SCI-AGRON, V41, DOI 10.4025/actasciagron.v41i1.39880
   Goehring T, 2017, HEARING RES, V344, P183, DOI 10.1016/j.heares.2016.11.012
   Gogate Mandar, 2018, ARXIV180800060
   Gustafsson H, 2001, IEEE T SPEECH AUDI P, V9, P799, DOI 10.1109/89.966083
   Han TT, 2016, NEUROCOMPUTING, V171, P347, DOI 10.1016/j.neucom.2015.06.048
   Hermus K, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/45821
   Hu Y, 2003, IEEE T SPEECH AUDI P, V11, P334, DOI 10.1109/TSA.2003.814458
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Kamath S, 2002, INT CONF ACOUST SPEE, P4164
   Li HY, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418580028
   LIM JS, 1978, IEEE T ACOUST SPEECH, V26, P197, DOI 10.1109/TASSP.1978.1163086
   Loizou PC, 2007, SPEECH COMMUN, V49, P527, DOI 10.1016/j.specom.2007.05.002
   Lu CT, 2007, PATTERN RECOGN LETT, V28, P1300, DOI 10.1016/j.patrec.2007.03.001
   Lu CT, 2014, APPL ACOUST, V76, P249, DOI 10.1016/j.apacoust.2013.08.015
   Lu Y, 2011, IEEE T AUDIO SPEECH, V19, P1123, DOI 10.1109/TASL.2010.2082531
   Martin R, 2001, IEEE T SPEECH AUDI P, V9, P504, DOI 10.1109/89.928915
   Marxer R, 2017, INTERSPEECH, P1988, DOI 10.21437/Interspeech.2017-1257
   Nasir S., 2013, RES J APPL SCI ENG T, V6, P1081
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Rahali H, 2017, ANALOG INTEGR CIRC S, V93, P341, DOI 10.1007/s10470-017-1042-z
   Rangachari S, 2006, SPEECH COMMUN, V48, P220, DOI 10.1016/j.specom.2005.08.005
   Rix AW, 2001, INT CONF ACOUST SPEE, P749, DOI 10.1109/ICASSP.2001.941023
   Saleem N, 2018, APPL ACOUST, V141, P333, DOI 10.1016/j.apacoust.2018.07.027
   Saleem N, 2018, INT J SPEECH TECHNOL, V21, P217, DOI 10.1007/s10772-018-9500-2
   Saleem N, 2018, CIRC SYST SIGNAL PR, V37, P2591, DOI 10.1007/s00034-017-0684-5
   Saleem N, 2017, INT J SPEECH TECHNOL, V20, P89, DOI 10.1007/s10772-016-9391-z
   Scalart P, 1996, INT CONF ACOUST SPEE, P629, DOI 10.1109/ICASSP.1996.543199
   Singh S, 2015, INT J SPEECH TECHNOL, V18, P609, DOI 10.1007/s10772-015-9305-5
   Sorensen KV, 2005, EURASIP J APPL SIG P, V2005, P2954, DOI 10.1155/ASP.2005.2954
   Srinivasan S, 2006, SPEECH COMMUN, V48, P1486, DOI 10.1016/j.specom.2006.09.003
   Sun M., 2016, 2016 IEEE INT WORKSH, P1, DOI DOI 10.1109/IWAENC.2016.7602951
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881
   Tavares R, 2016, IEEE SIGNAL PROC LET, V23, P6, DOI 10.1109/LSP.2015.2495102
   Wang DL, 2005, SPEECH SEPARATION BY HUMANS AND MACHINES, P181, DOI 10.1007/0-387-22794-6_12
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   You XG, 2010, IEEE T IMAGE PROCESS, V19, P3271, DOI 10.1109/TIP.2010.2055570
   Zao L, 2014, IEEE-ACM T AUDIO SPE, V22, P899, DOI 10.1109/TASLP.2014.2312541
   Zhao W, 2014, INT CONF PERVAS COMP, P1
   Zou X, 2008, IEEE T SIGNAL PROCES, V56, P1812, DOI 10.1109/TSP.2007.910555
   Zou YX, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8091436
NR 61
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31867
EP 31891
DI 10.1007/s11042-019-08032-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000040
DA 2024-07-18
ER

PT J
AU Sethi, R
   Sreedevi, I
AF Sethi, Rajni
   Sreedevi, Indu
TI Adaptive enhancement of underwater images using multi-objective PSO
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater Images; Image Enhancement; MOPSO; Color correction; Fuzzy
   logic
ID COLOR; ALGORITHM; CONTRAST; SYSTEM; MODEL
AB Underwater images have poor clarity and bad contrast due to low illumination in deep water. Moreover, underwater images are bluish-green in appearance due to inherent wavelength absorption property of water. Therefore, the study of underwater images is a difficult task. Being computationally simple, histogram-based enhancement techniques are obvious choice for improvement of contrast and color of underwater images. However, due to lack of any guidance mechanism, these techniques can overstretch the histogram leading to artifacts in the image. Hence, an adaptive method named 'Contrast and Information Enhancement of Underwater Images' (CIEUI) is proposed, which enhances underwater images by improving their contrast and information content using Multi-Objective Particle Swarm Optimization (MOPSO). Objective functions of MOPSO are chosen to act as guiding mechanism to ensure color & contrast correction and information enhancement respectively without introducing artifacts. Computed results not only have good contrast and color performance but also have better information content. The proposed CIEUI technique performs quantitatively and qualitatively better as compared to state-of-the-art algorithms.
C1 [Sethi, Rajni] Delhi Technol Univ, Dept Informat Technol, Delhi, India.
   [Sreedevi, Indu] Delhi Technol Univ, Dept Elect & Commun Engn, Delhi, India.
C3 Delhi Technological University; Delhi Technological University
RP Sethi, R (corresponding author), Delhi Technol Univ, Dept Informat Technol, Delhi, India.
EM rajni_gumber23@yahoo.com; sindu@dce.ac.in
RI Sreedevi, Indu/HCH-5463-2022; Sethi, Rajni/ABH-3192-2020; Sreedevi,
   Indu/AFU-2449-2022
OI Sreedevi, Indu/0000-0002-4975-5047; 
CR AbuNaser A, 2015, J INTELL SYST, V24, P99, DOI 10.1515/jisys-2014-0012
   Alvarez-Benitez JE, 2005, LECT NOTES COMPUT SC, V3410, P459
   Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   [Anonymous], IJCAI 2016
   [Anonymous], IJCAI
   [Anonymous], UPPERCASE WHOI COLOR
   [Anonymous], 2016, ARXIV161009462
   [Anonymous], DISCOVER OCEANS WORL
   [Anonymous], 1994, EVOL COMPUT
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], MATH PROBLEMS ENG
   [Anonymous], UNDERWATER VIDEOS PI
   [Anonymous], INT C IM PROC ICIP
   [Anonymous], 2007, IAENG INT J COMPUT S
   [Anonymous], 1995, 1995 IEEE INT C
   [Anonymous], INITIAL RESULTS UNDE
   BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7
   Chambah M, 2004, PROC SPIE, V5293, P157
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Coello CAC, 2004, IEEE T EVOLUT COMPUT, V8, P256, DOI 10.1109/tevc.2004.826067
   Duarte A., 2016, OCEANS 2016, P1
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Garcia R, 2002, OCEANS 2002 MTS/IEEE CONFERENCE & EXHIBITION, VOLS 1-4, CONFERENCE PROCEEDINGS, P1018
   Garg D, 2018, MULTIMED TOOLS APPL, V77, P26545, DOI 10.1007/s11042-018-5878-8
   Ghani ASA, 2017, COMPUT ELECTRON AGR, V141, P181, DOI 10.1016/j.compag.2017.07.021
   Ghani ASA, 2015, APPL SOFT COMPUT, V27, P219, DOI 10.1016/j.asoc.2014.11.020
   Hanmandlu M, 2009, IEEE T INSTRUM MEAS, V58, P2867, DOI 10.1109/TIM.2009.2016371
   He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]
   Henke B, 2013, INT SYMP IMAGE SIG, P20
   Hitam Muhammad Suzuri, 2013, 2013 INT C COMPUTER
   Hung HC, 2012, 2012 INTERNATIONAL CONFERENCE ON FUZZY THEORY AND ITS APPLICATIONS (IFUZZY2012), P192, DOI 10.1109/iFUZZY.2012.6409699
   Hung-Yu Yang, 2011, Proceedings of the 2011 2nd International Conference on Innovations in Bio-Inspired Computing and Applications (IBICA 2011), P17, DOI 10.1109/IBICA.2011.9
   Iqbal K, 2010, IEEE INT C SYSTEMS M
   Kanmani M, 2018, MULTIMED TOOLS APPL, V77, P12701, DOI 10.1007/s11042-017-4911-7
   Knowles J, 1999, P 1999 C EV COMP CEC, P98, DOI [DOI 10.1109/CEC.1999.781913, 10.1109/cec.1999.781913]
   Kwok NM, 2013, ENG APPL ARTIF INTEL, V26, P2356, DOI 10.1016/j.engappai.2013.07.023
   Lam EY, 2005, I SYMP CONSUM ELECTR, P134, DOI 10.1109/ISCE.2005.1502356
   Lebart K, 2003, IEEE J OCEANIC ENG, V28, P673, DOI 10.1109/JOE.2003.819314
   Li CY, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.3.033012
   Liu Chao, 2010, 2010 2nd International Conference on Computer Engineering and Technology (ICCET), P35, DOI 10.1109/ICCET.2010.5485339
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu HM, 2017, MOBILE NETW APPL, V22, P1204, DOI 10.1007/s11036-017-0863-4
   Panetta K, 2016, IEEE J OCEANIC ENG, V41, P541, DOI 10.1109/JOE.2015.2469915
   Peng YT, 2017, IEEE T IMAGE PROCESS, V26, P1579, DOI 10.1109/TIP.2017.2663846
   Reyes-Sierra M., 2006, International Journal of Computational Intelligence Research, V2, P287, DOI DOI 10.5019/J.IJCIR.2006.68
   Rizzi A, 2003, PATTERN RECOGN LETT, V24, P1663, DOI 10.1016/S0167-8655(02)00323-9
   Schechner YY, 2007, IEEE T PATTERN ANAL, V29, P1655, DOI 10.1109/TPAMI.2007.1141
   Sethi R, 2015, 2015 5 NAT C COMP VI, P1
   Singh K, 2015, OPTIK, V126, P2619, DOI 10.1016/j.ijleo.2015.06.060
   Trelea IC, 2003, INFORM PROCESS LETT, V85, P317, DOI 10.1016/S0020-0190(02)00447-7
   Tripathi P, 2011, CASES ON INNOVATIONS IN EDUCATIONAL MARKETING: TRANSNATIONAL AND TECHNOLOGICAL STRATEGIES, P1, DOI 10.4018/978-1-60960-599-5
   Verma OP, 2012, APPL SOFT COMPUT, V12, P394, DOI 10.1016/j.asoc.2011.08.033
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 54
TC 11
Z9 11
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31823
EP 31845
DI 10.1007/s11042-019-07938-x
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000038
DA 2024-07-18
ER

PT J
AU Singh, AK
AF Singh, A. K.
TI Robust and distortion control dual watermarking in LWT domain using DCT
   and error correction code for color medical image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE LWT; DCT; MD5; BCH; Robustness; Complexity
ID SCHEME; TRANSFORM; ALGORITHM; SECURE
AB This paper presents lifting wavelet transform (LWT) and discrete cosine transform (DCT) based robust watermarking approach for tele-health applications. For identity authentication, 'signature watermark' of size '64x64' and 'patient report' of size '80' characters are hiding into the host medical image. Further, the signature watermark is encrypted by message-digest (MD5) and 'patient report' is encoded by BCH error correcting code before embedding into the host image. Experimental demonstrations indicate that the method provides sufficient robustness and security against various attacks without significant distortion between cover and watermarked image. Further, our results proved that the method offer NC value more than 0.9214 for most of the considered attacks. Furthermore, it is evident from results our method shows the improvement in robustness to previously reported techniques under consideration while providing low computational complexity.
C1 [Singh, A. K.] NIT Patna, Dept CSE, Patna 800005, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Singh, AK (corresponding author), NIT Patna, Dept CSE, Patna 800005, Bihar, India.
EM amit_245singh@yahoo.com
RI Singh, Amit Kumar/D-1300-2015
OI Singh, Amit Kumar/0000-0001-7359-2068
CR Abbas NH, 2018, MULTIMED TOOLS APPL, V77, P24593, DOI 10.1007/s11042-017-5488-x
   [Anonymous], 2016, GEOSCIENCE
   [Anonymous], 2017, BOOK SERIES MULTIMED
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Bouslimi D, 2012, COMPUT METH PROG BIO, V106, P47, DOI 10.1016/j.cmpb.2011.09.015
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Elhoseny M, 2018, IEEE ACCESS, V6, P20596, DOI 10.1109/ACCESS.2018.2817615
   Giakoumaki A, 2006, IEEE T INF TECHNOL B, V10, P722, DOI 10.1109/TITB.2006.875655
   Giakoumaki Aggeliki L, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P6328
   Hajjaji MA, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/313078
   Kalra GS, 2015, MULTIMED TOOLS APPL, V74, P6849, DOI 10.1007/s11042-014-1932-3
   Kumar C, 2018, MULTIMED TOOLS APPL, V77, P3597, DOI 10.1007/s11042-017-5222-8
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Li JZ, 2018, MULTIMED TOOLS APPL, V77, P4545, DOI 10.1007/s11042-017-4452-0
   Liu HY, 2017, MICROCHIM ACTA, V184, P1267, DOI 10.1007/s00604-017-2179-2
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   SINGH AK, 2016, HDB RES MODERN CRYPT, P246, DOI DOI 10.4018/978-1-5225-0105-3.CH011
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh AK, 2014, NATL ACAD SCI LETT, V37, P351, DOI 10.1007/s40009-014-0241-8
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Thabit R, 2015, DIGIT SIGNAL PROCESS, V38, P77, DOI 10.1016/j.dsp.2014.12.005
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 27
TC 78
Z9 78
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30523
EP 30533
DI 10.1007/s11042-018-7115-x
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200049
DA 2024-07-18
ER

PT J
AU Soni, R
   Kumar, B
   Chand, S
AF Soni, Rituraj
   Kumar, Bijendra
   Chand, Satish
TI Optimal feature and classifier selection for text region classification
   in natural scene images using Weka tool
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Extraction of text regions; MSER; Feature selection and extraction;
   Classification; Weka tool
ID NAIVE BAYES; EXTRACTION; DETECT; MODEL; VIDEO
AB The problem of text detection and localization in scene images has always been challenging for the researchers over the years due to diversities present in these images. This diversity includes variation in fonts, size, color, different backgrounds, etc. The textual content in such images can be helpful for humans in many different domains like visually impaired people, scene understanding, intelligent navigation, etc. The natural scene contains some non-text objects along with relevant text objects, and it is necessary to classify them appropriately & accurately to increase the performance of the detection and localization method. The classification of text regions in scene images depends on the selection of optimal features and optimal classifier. This work contributes to finding both the optimal feature set and the optimal classifier with the help of weka tool. In this paper, first, we detect the possible text regions with the help of the improved MSER algorithm; then, we extract 11 features on these potential text regions. From these 11 features, we choose an optimal feature set for discrimination between text and non-text components with the help of the CfsSubsetEval and BFS parameter of the Weka Tool. We trained several classifiers using these optimal features with the help of Weka tool on the ICDAR 2013 training set. The performance of these classifiers is compared empirically based on the classification accuracy obtained using Weka tool. Based on this empirical estimation, Naive Bayes Classifier with the highest accuracy of 92.5% is proposed as an optimal choice for classification purpose.
C1 [Soni, Rituraj; Kumar, Bijendra] NSIT, Dept Comp Engn, New Delhi, India.
   [Chand, Satish] JNU, Sch Comp & Syst Sci, New Delhi, India.
C3 Netaji Subhas University of Technology
RP Soni, R (corresponding author), NSIT, Dept Comp Engn, New Delhi, India.
EM rituraj.soni@gmail.com; bizender@gmail.com; schand20@gmail.com
RI Kumar, Bijendra/ABG-2754-2021; Soni, Rituraj/AAI-8043-2020
OI Kumar, Bijendra/0000-0002-5729-8982; Soni, Rituraj/0000-0003-3058-1750
FU UPE-II, Jawaharlal University, New Delhi, India
FX This work is supported by UPE-II, Jawaharlal University, New Delhi,
   India.
CR Amancio DR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0094137
   [Anonymous], BRIT MACH VIS C
   Ansari GJ, 2018, FUTURE GENERATION CO
   Baran R, 2018, ADV INTELL SYST COMP, V722, P42, DOI 10.1007/978-3-319-73888-8_8
   Busta M, 2017, IEEE I CONF COMP VIS, P2223, DOI 10.1109/ICCV.2017.242
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen H., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2609, DOI 10.1109/ICIP.2011.6116200
   Chen Xiangrong, 2004, Computer vision and pattern recognition, V2, pII
   Chiou YR, 2010, PROC IEEE MICR ELECT, P59, DOI 10.1109/MEMSYS.2010.5442567
   da Silva BLS, 2016, EDGE DETECTION CONFI
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dash JK, 2018, MULTIMED TOOLS APPL, V77, P459, DOI 10.1007/s11042-016-4228-y
   Dash JK, 2017, MULTIMED TOOLS APPL, V76, P2535, DOI 10.1007/s11042-015-3231-z
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Fabrizio J, 2016, INT J DOC ANAL RECOG, V19, P99, DOI 10.1007/s10032-016-0264-4
   Feng YY, 2016, INT C PATT RECOG, P645, DOI 10.1109/ICPR.2016.7899707
   Frank E., 2014, Fully supervised training of gaussian radial basis function networks in weka (computer science working papers, 04/2014)
   Freund Y, 1999, MACH LEARN, V37, P277, DOI 10.1023/A:1007662407062
   Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199
   Gang Zhou, 2011, Proceedings of the 2011 1st International Symposium on Access Spaces (ISAS), P116, DOI 10.1109/ISAS.2011.5960931
   Genkin A, 2007, TECHNOMETRICS, V49, P291, DOI 10.1198/004017007000000245
   Ghanei S, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S0218001417530020
   Ghoshal R, 2015, ADV INTELL SYST, V340, P475, DOI 10.1007/978-81-322-2247-7_49
   Gllavata J, 2004, INT C PATT RECOG, P425, DOI 10.1109/ICPR.2004.1334146
   González A, 2012, INT C PATT RECOG, P617
   Guan L, 2017, NATURAL SCENE TEXT D
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Hanif Shehzad Muhammad, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1, DOI 10.1109/ICDAR.2009.172
   He T, 2016, IEEE T IMAGE PROCESS, V25, P2529, DOI 10.1109/TIP.2016.2547588
   HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1023/A:1022623210503
   Huang J, 2016, 2016 INTERNATIONAL SYMPOSIUM ON COMPUTER, CONSUMER AND CONTROL (IS3C), P980, DOI 10.1109/IS3C.2016.248
   Iqbal Z, 2013, DIR DEV, P1, DOI 10.1596/978-0-8213-9953-8
   Jaderberg Max, 2014, WORKSH DEEP LEARN NI
   Jiang MD, 2018, J PHYS CONF SER, V960, DOI 10.1088/1742-6596/960/1/012027
   [蒋人杰 JIANG Renjie], 2006, [中国图象图形学报, Journal of Image and Graphics], V11, P1653
   Jing Zhang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3979, DOI 10.1109/ICPR.2010.968
   Joan SPF, 2017, INFORM SYST FRONT, V19, P1039, DOI 10.1007/s10796-016-9699-x
   Jung K, 2004, PATTERN RECOGN, V37, P977, DOI 10.1016/j.patcog.2003.10.012
   Karatzas D, 2013, PROC INT CONF DOC, P1484, DOI 10.1109/ICDAR.2013.221
   Kim HK, 2016, APPL INTELL, V45, P30, DOI 10.1007/s10489-015-0745-z
   Kim KI, 2003, IEEE T PATTERN ANAL, V25, P1631, DOI 10.1109/TPAMI.2003.1251157
   Klein DA, 2011, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2011.6126499
   Koo HI, 2013, IEEE T IMAGE PROCESS, V22, P2296, DOI 10.1109/TIP.2013.2249082
   Lee JJ, 2011, PROC INT CONF DOC, P429, DOI 10.1109/ICDAR.2011.93
   Li MH, 2008, IEEE IJCNN, P72, DOI 10.1109/IJCNN.2008.4633769
   Li Y, 2012, INT C PATT RECOG, P681
   Li Y, 2014, IEEE T IMAGE PROCESS, V23, P1666, DOI 10.1109/TIP.2014.2302896
   Liu JH, 2016, SIGNAL PROCESS, V124, P259, DOI 10.1016/j.sigpro.2015.06.025
   Liu XQ, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1721, DOI 10.1109/ICME.2006.262882
   Long Ma, 2010, 2010 Proceedings of 3rd International Congress on Image and Signal Processing (CISP 2010), P1961, DOI 10.1109/CISP.2010.5648158
   Lucas SM, 2005, PROC INT CONF DOC, P80, DOI 10.1109/ICDAR.2005.231
   Lucas SM, 2003, PROC INT CONF DOC, P682
   Majtey AP, 2005, PHYS REV A, V72, DOI 10.1103/PhysRevA.72.052310
   Maruyama Minoru, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1365, DOI 10.1109/ICDAR.2009.147
   McCallum A., 1998, AAAI 98 WORKSH LEARN, V752, P41, DOI DOI 10.1109/TSMC.1985.6313426
   Misra Chinmaya, 2012, INT J COMPUTER APPL, V40, P13
   Mukhopadhyay Anirban, 2019, International Journal of Computer Vision and Image Processing, V9, P48, DOI 10.4018/IJCVIP.2019040104
   Neumann L, 2012, PROC CVPR IEEE, P3538, DOI 10.1109/CVPR.2012.6248097
   Neumann L, 2011, LECT NOTES COMPUT SC, V6494, P770, DOI 10.1007/978-3-642-19318-7_60
   Nguyen K, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTER, CONTROL, INFORMATICS, AND ITS APPLICATIONS (IC3INA) - RECENT PROGRESS IN COMPUTER, CONTROL, AND INFORMATICS FOR DATA SCIENCE, P48, DOI 10.1109/IC3INA.2016.7863022
   Ou W., 2004, J CHINESE INF PROCES, V5, P6
   Pan YF, 2011, IEEE T IMAGE PROCESS, V20, P800, DOI 10.1109/TIP.2010.2070803
   Pan YF, 2010, IEEE IMAGE PROC, P2269, DOI 10.1109/ICIP.2010.5651862
   Panda M., 2010, 2010 Sixth International Conference on Information Assurance and Security (IAS 2010), P5, DOI 10.1109/ISIAS.2010.5604193
   Pietikäinen M, 2001, PROC INT CONF DOC, P286, DOI 10.1109/ICDAR.2001.953800
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Rish Irina, 2001, IJCAI 2001 WORKSHOP, V3, P41
   Salvithal NN, 2013, EVALUATING PERFORMAN
   Saric M, 2017, NEUROCOMPUTING, V266, P56, DOI 10.1016/j.neucom.2017.05.021
   SeongHun Lee, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3983, DOI 10.1109/ICPR.2010.969
   Shahab A, 2011, PROC INT CONF DOC, P1491, DOI 10.1109/ICDAR.2011.296
   Shi CZ, 2013, PATTERN RECOGN LETT, V34, P107, DOI 10.1016/j.patrec.2012.09.019
   Shi HB, 2011, LECT NOTES ARTIF INT, V7003, P680, DOI 10.1007/978-3-642-23887-1_86
   Singh A, 2017, INT J ADV COMPUT SC, V8, P1
   Soni R, 2018, APPL INTELL, P1
   Sun L, 2015, PATTERN RECOGN, V48, P2906, DOI 10.1016/j.patcog.2015.04.002
   Tang B., 2016, ARXIV160202850
   Unar S, 2018, IJCSNS, V18, P100
   Wang QQ, 2015, PROC INT CONF DOC, P106, DOI 10.1109/ICDAR.2015.7333735
   Wei YW, 2017, SIGNAL PROCESS-IMAGE, V50, P1, DOI 10.1016/j.image.2016.10.003
   Wu H, 2017, VISUAL COMPUT, V33, P113, DOI 10.1007/s00371-015-1156-1
   Xiang ZL, 2016, APPL INTELL, V44, P611, DOI 10.1007/s10489-015-0719-1
   Xu SH, 2010, J BIOMED INFORM, V43, P924, DOI 10.1016/j.jbi.2010.09.006
   Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787
   Ye QX, 2007, J VIS COMMUN IMAGE R, V18, P504, DOI 10.1016/j.jvcir.2007.07.003
   Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765
   Yi Chucai, 2011, IEEE Trans Image Process, V20, P2594, DOI 10.1109/TIP.2011.2126586
   Yu C, 2016, NEUROCOMPUTING, V175, P652, DOI 10.1016/j.neucom.2015.10.105
   Zhang G., 2017, J XIAN JIAOTONG U, V1, P21
   Zhang HY, 2017, 2017 18TH INTERNATIONAL CONFERENCE ON ELECTRONIC PACKAGING TECHNOLOGY (ICEPT), P342, DOI 10.1109/ICEPT.2017.8046468
   Zhang HG, 2013, NEUROCOMPUTING, V122, P310, DOI 10.1016/j.neucom.2013.05.037
   Zhu AN, 2015, PATTERN RECOGN LETT, V67, P153, DOI 10.1016/j.patrec.2015.06.009
   Zhu YY, 2016, NEUROCOMPUTING, V187, P83, DOI 10.1016/j.neucom.2015.09.114
   Zhu YY, 2016, FRONT COMPUT SCI-CHI, V10, P19, DOI 10.1007/s11704-015-4488-0
NR 94
TC 14
Z9 15
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31757
EP 31791
DI 10.1007/s11042-019-07998-z
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000035
DA 2024-07-18
ER

PT J
AU Ullah, A
   Javeed, A
   Shah, T
AF Ullah, Atta
   Javeed, Adnan
   Shah, Tariq
TI A scheme based on algebraic and chaotic structures for the construction
   of substitution box
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic map; Substitution box (S-box); Encryption; Substitution
ID S-BOXES; CRYPTOGRAPHY; PERMUTATION
AB The use of nonlinear (chaotic) transformations in cryptography to generate confusion in the course of encryption procedure is the recent trend. In this article, a novel chaotic system is presented based on the existing chaotic maps. A proficient cryptosystem technique is proposed for constructing substitution box using this novel 1D chaotic structure. The key based dynamical feature of the chaotic system to synthesize strong substitution boxes is the main advantage of the suggested scheme. Then, the constructed component of the block cipher is evaluated using statistical and algebraic analyses. The outcomes of theses analyses certify that the proposed cryptosystem has great potential and superior performance for noticeable dominance in various cryptographic applications in comparison with the existing procedures.
C1 [Ullah, Atta; Javeed, Adnan; Shah, Tariq] Quaid I Azam Univ, Dept Math, Islamabad, Pakistan.
C3 Quaid I Azam University
RP Ullah, A (corresponding author), Quaid I Azam Univ, Dept Math, Islamabad, Pakistan.
EM attaullah@math.qau.edu.pk; ajaveed@math.qau.edu.pk; stariqshah@gmail.com
CR Arroyo D, 2013, SIGNAL PROCESS, V93, P1358, DOI 10.1016/j.sigpro.2012.11.019
   Belazi A, 2017, NONLINEAR DYNAM, V87, P337, DOI 10.1007/s11071-016-3046-0
   Biham E., 1991, Journal of Cryptology, V4, P3, DOI 10.1007/BF00630563
   Brown R, 1996, INT J BIFURCAT CHAOS, V6, P219, DOI 10.1142/S0218127496000023
   Chen G, 2007, CHAOS SOLITON FRACT, V31, P571, DOI 10.1016/j.chaos.2005.10.022
   Dachselt F, 2001, IEEE T CIRCUITS-I, V48, P1498, DOI 10.1109/TCSI.2001.972857
   FEISTEL H, 1973, SCI AM, V228, P15, DOI 10.1038/scientificamerican0573-15
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Hao BL, 1993, Starting with parabolas-an introduction to chaotic dynamics
   Hussain I, 2013, NONLINEAR DYNAM, V71, P133, DOI 10.1007/s11071-012-0646-1
   Hussain I, 2012, NONLINEAR DYNAM, V70, P1791, DOI 10.1007/s11071-012-0573-1
   Hussain I, 2013, NEURAL COMPUT APPL, V22, P1085, DOI 10.1007/s00521-012-0870-0
   Hussain I, 2012, COMPUT MATH APPL, V64, P2450, DOI 10.1016/j.camwa.2012.05.017
   Hussain I, 2012, Z NATURFORSCH A, V67, P282, DOI 10.5560/ZNA.2012-0022
   Jakimoski G, 2001, IEEE T CIRCUITS-I, V48, P163, DOI 10.1109/81.904880
   Khan M, 2016, NEURAL COMPUT APPL, V27, P677, DOI 10.1007/s00521-015-1887-y
   Khan M, 2014, NEURAL COMPUT APPL, V25, P1717, DOI 10.1007/s00521-014-1663-4
   Khan M, 2013, NONLINEAR DYNAM, V71, P489, DOI 10.1007/s11071-012-0675-9
   Khan M, 2012, NONLINEAR DYNAM, V70, P2303, DOI 10.1007/s11071-012-0621-x
   Kocarev L., 2001, IEEE Circuits and Systems Magazine, V1, P6, DOI 10.1109/7384.963463
   Li X, 2016, OPTIK, V127, P2558, DOI 10.1016/j.ijleo.2015.11.221
   Matsui M, LECT NOTES COMPUT SC, V765, P386
   Özkaynak F, 2010, PHYS LETT A, V374, P3733, DOI 10.1016/j.physleta.2010.07.019
   Shah T, 2013, Z NATURFORSCH A, V68, P567, DOI 10.5560/ZNA.2013-0021
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Tang GP, 2005, CHAOS SOLITON FRACT, V23, P413, DOI 10.1016/j.chaos.2004.04.023
   Ullah A, 2017, NONLINEAR DYNAM, V88, P2757, DOI 10.1007/s11071-017-3409-1
   WEBSTER AF, 1986, LECT NOTES COMPUT SC, V218, P523
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhang YS, 2014, AEU-INT J ELECTRON C, V68, P361, DOI 10.1016/j.aeue.2013.10.002
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 31
TC 18
Z9 18
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 32467
EP 32484
DI 10.1007/s11042-019-07957-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000062
DA 2024-07-18
ER

PT J
AU Yaqub, MA
   Ahmed, SH
   Bouk, SH
   Kim, D
AF Yaqub, Muhammad Azfar
   Ahmed, Syed Hassan
   Bouk, Safdar Hussain
   Kim, Dongkyun
TI Towards energy efficient duty cycling in underwater wireless sensor
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of underwater things; Asynchronous duty cycle;
   Receiver-initiated MAC; Topology control; Energy efficiency
ID MAC PROTOCOL; DESIGN
AB Underwater Wireless Sensor Networks devices are usually battery powered and thereby their lifetime is limited. This issue leads to lose data measurements and thus to a performance loss of the underlying UWSN application. It also increases the maintenance cost in Internet of Underwater Things scenarios with a huge number of UWSN devices. Additionally, the unique characteristics of UWSNs pose several constraints such as the high energy consumption, long propagation delay, and node mobility. Duty Cycle management is one of the key technologies to solve this issue. In this context, the use of duty cycle based algorithms for opportunistic, autonomous and energy efficient duty cycle management can mitigate the undesirable impact of underwater communications, consequently, improve the overall efficiency of the algorithms designed for the UWSNs. In this article, we study the energy efficient data collection for asynchronous duty cycle MAC protocols for underwater sensor networks. To this end, we improve two previously proposed receiver initiated MAC protocols that use a nodes, (1) residual energy, and (2) its sleep-awake pattern to improve the overall network lifetime. We show that the considerations made in the protocols have a great impact on the performance of the network. Our results show that the protocols minimize the collisions while alleviating the need for excessive handshake and also the average active time of a node is minimized.
C1 [Yaqub, Muhammad Azfar; Kim, Dongkyun] Kyungpook Natl Univ, Sch Comp Sci & Engn, Daegu 41566, South Korea.
   [Ahmed, Syed Hassan] Georgia Southern Univ, Dept Comp Sci, Statesboro, GA 30460 USA.
   [Bouk, Safdar Hussain] DGIST, Dept Informat & Commun Engn, Daegu 42988, South Korea.
C3 Kyungpook National University; University System of Georgia; Georgia
   Southern University; Daegu Gyeongbuk Institute of Science & Technology
   (DGIST)
RP Kim, D (corresponding author), Kyungpook Natl Univ, Sch Comp Sci & Engn, Daegu 41566, South Korea.
EM yaqub@knu.ac.kr; sh.ahmed@ieee.org; bouk@dgist.ac.kr; dongkyun@knu.ac.kr
RI Bouk, Safdar Hussain/HHN-5654-2022; Yaqub, Muhammad Azfar/A-6965-2015;
   Ahmed, Syed/GSN-7305-2022; Shah, Syed Hassan/E-5058-2014
OI Bouk, Safdar Hussain/0000-0002-1764-7703; Yaqub, Muhammad
   Azfar/0000-0003-2150-952X; Shah, Syed Hassan/0000-0002-1381-5095
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2016R1D1A3B01015510]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (2016R1D1A3B01015510).
CR Abd-El-Raouf HE, 2008, 2008 IEEE INTERNATIONAL RF AND MICROWAVE CONFERENCE, PROCEEDINGS, P231
   [Anonymous], 2010, PROC WIRELESS COMMUN
   [Anonymous], WIREL COMMUN MOB COM
   [Anonymous], IEEE T SYSTEMS MAN C
   [Anonymous], P 15 IEEE ANN CONS C
   [Anonymous], INT J DISTRIB SENS N
   [Anonymous], EFFECTS NODE DENSITY
   [Anonymous], P 6 ACM INT WORKSH U
   [Anonymous], 2016, P ACM C EMB NETW SEN
   [Anonymous], P 10 INT C UND NETW
   [Anonymous], ANAL ALOHA PROTOCOLS
   Casari P, 2011, COMPUT COMMUN, V34, P2013, DOI 10.1016/j.comcom.2011.06.008
   Chirdchoo N, 2007, IEEE INFOCOM SER, P2271, DOI 10.1109/INFCOM.2007.263
   Chirdchoo N, 2008, IEEE J SEL AREA COMM, V26, P1744, DOI 10.1109/JSAC.2008.081213
   Climent S, 2012, SENSORS-BASEL, V12, P704, DOI 10.3390/s120100704
   Coutinho J, 2016, SIBGRAPI, P1, DOI [10.1109/SIBGRAPI.2016.010, 10.1109/SIBGRAPI.2016.9]
   Coutinho RWL, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3154834
   Coutinho RWL, 2015, ACM S MODEL ANAL SIM, P125, DOI 10.1145/2811587.2811608
   Ghadimi E, 2014, ACM T SENSOR NETWORK, V10, DOI 10.1145/2533686
   Guo XX, 2009, IEEE J OCEANIC ENG, V34, P170, DOI 10.1109/JOE.2009.2015164
   Harris AF, 2009, AD HOC NETW, V7, P770, DOI 10.1016/j.adhoc.2008.07.014
   Kao CC, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17071477
   Khripkov A, 2013, IEEE MTTS INT MICROW, P4
   Liao WH, 2014, 2014 INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN 2014), P1, DOI 10.1109/ICOIN.2014.6799473
   Lin B, 2016, IEEE T NETW SERV MAN, V13, P581, DOI 10.1109/TNSM.2016.2554143
   Lurton X., 2002, An introduction to underwater acoustics: principles and applications
   Molins Marcal, 2007, OCEANS 2006 ASIA PAC, P1
   Noh Y, 2014, IEEE T MOBILE COMPUT, V13, P766, DOI 10.1109/TMC.2013.2297703
   Park MK, 2007, IEEE J OCEANIC ENG, V32, P710, DOI 10.1109/JOE.2007.899277
   Sendra S, 2016, IEEE SENS J, V16, P4063, DOI 10.1109/JSEN.2015.2434890
   Wills J., 2006, P 1 ACM INT WORKSH U, P79, DOI [DOI 10.1145/1161039.1161055, 10.1145/1161039.1161055]
   Xiong NX, 2010, IEEE T PARALL DISTR, V21, P1254, DOI 10.1109/TPDS.2010.29
   Xiong NX, 2009, IEEE J SEL AREA COMM, V27, P495, DOI 10.1109/JSAC.2009.090512
NR 33
TC 9
Z9 9
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30057
EP 30079
DI 10.1007/s11042-018-6924-2
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200024
DA 2024-07-18
ER

PT J
AU Zhang, QL
   Song, XY
   Wen, T
   Fu, CG
AF Zhang, Qilong
   Song, Xiaoying
   Wen, Tao
   Fu, Chongguo
TI Reversible data hiding for 3D mesh models with hybrid prediction and
   multilayer strategy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D models; Mesh; Data hiding; Prediction; Reversibility
ID DIFFERENCE-EXPANSION; SCHEME
AB This paper presents a novel reversible data hiding (RDH) method for 3D mesh models using hybrid prediction scheme and multilayer strategy. In our prediction scheme, the prediction context is determined by the uniformity of mesh region, which means that full context and partial context are used for uniform region and nonuniform region, respectively. This kind of content-dependent prediction can further exploited vertex-vertex correlations to achieve better prediction accuration. Meanwhile, a multilayer strategy with overlapping partition is used to make a trade-off between important requirements: the embedding capacity should be large and distortion should be low. Compared with non-overlapping partition, it keeps not only the prediction context intact but also more capacity available in one pass embedding. In addition, the threshold is adaptively selected considering the magnitude of prediction errors such that the embedding distortion is reduced when embed the secret data into 3D mesh models. Experimental results also validate the effectiveness of the proposed method.
C1 [Zhang, Qilong; Wen, Tao; Fu, Chongguo] Northeastern Univ, Coll Comp Sci & Engn, Shenyang 110819, Liaoning, Peoples R China.
   [Song, Xiaoying; Wen, Tao] Dalian Neusoft Univ Informat, Liaoning Prov Key Lab Network Secur & Comp Techno, Dalian 116023, Peoples R China.
C3 Northeastern University - China
RP Song, XY (corresponding author), Dalian Neusoft Univ Informat, Liaoning Prov Key Lab Network Secur & Comp Techno, Dalian 116023, Peoples R China.
EM songxiaoying@neusoft.edu.cn
FU National Nature Science Foundation of China [61772101, 61170169,
   61602075]
FX The authors wish to thank the anonymous referees for their valuable
   comments and suggestions, which improved the technical content and the
   presentation of the paper. This research is supported by the National
   Nature Science Foundation of China (61772101, 61170169, 61602075).
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Arham A, 2017, SIGNAL PROCESS, V137, P52, DOI 10.1016/j.sigpro.2017.02.001
   Caldelli R, 2010, EURASIP J INFORM SEC, V2010, P2
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chen CC, 2017, MULTIMED TOOLS APPL, V76, P8497, DOI 10.1007/s11042-016-3452-9
   Cheng-Hung Chuang, 2010, IET International Conference on Frontier Computing. Theory, Technologies and Applications, P77, DOI 10.1049/cp.2010.0541
   Dittmann J, 2003, PROC SPIE, V5020, P653, DOI 10.1117/12.476824
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Fridrich J, 2002, P SOC PHOTO-OPT INS, V4675, P572, DOI 10.1117/12.465317
   Gao XB, 2009, SIGNAL PROCESS, V89, P2053, DOI 10.1016/j.sigpro.2009.04.015
   Huang YH, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0051-x
   Jhou CY, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P365
   Jiang RQ, 2018, MULTIMED TOOLS APPL, V77, P5263, DOI 10.1007/s11042-017-4430-6
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Li XL, 2014, 2014 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (CHINASIP), P426, DOI 10.1109/ChinaSIP.2014.6889278
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lu ZM, 2008, LECT NOTES COMPUT SC, V5041, P233
   Ma XX, 2015, J VIS COMMUN IMAGE R, V28, P71, DOI 10.1016/j.jvcir.2015.01.012
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Shi YQ, 2004, INT SYM CIRC SYST, V32, pII
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang JX, 2014, J VIS COMMUN IMAGE R, V25, P1425, DOI 10.1016/j.jvcir.2014.04.005
   Wu D, 2009, LECT NOTES COMPUT SC, V5820, P513, DOI 10.1007/978-3-642-04875-3_52
   Wu HT, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P801
   Wu HT, 2005, 2005 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, PROCEEDINGS, P774
NR 29
TC 9
Z9 9
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 29713
EP 29729
DI 10.1007/s11042-018-6219-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200005
DA 2024-07-18
ER

PT J
AU Choe, C
   Choe, W
   Wang, TJ
   Han, S
   Yuan, CH
AF Choe, Chunhwa
   Choe, Gwangmin
   Wang, Tianjiang
   Han, Sokmin
   Yuan, Caihong
TI Deep feature learning with mixed distance maximization for person
   Re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep feature learning; Mixed distance; Inter-distance; Intra-distance;
   Person re-identification
AB In despite of several advanced approaches, deep learning for person re-identification is still regarded as a challenging task due to local optima in the objective function of the deep networks in addition to various changes of poses and viewpoints etc. We introduced a novel neural network learning, or deep feature learning with mixed distance maximization, to solve the local optima problem in person re-identification. A local objective function is first defined to maximize the intra-distance among a triplet for person re-identification. Also, a global objective function is proposed to consider distances among triplets. Based on two objective functions, a main objective function is introduced to make full use of the information of triplets. This main objective function is defined based on the combination of two distances, called a mixed distance. This mixed distance can prevent that the triplets become close to each other and the matched pairs in each triplets become apart in deep learning with the relative distance comparison. We test our deep method with the mixed distance maximization on several datasets. Experimental results demonstrate that deep feature learning with the mixed distance maximization have promising discriminative capability in comparison with other ones.
C1 [Choe, Chunhwa; Choe, Gwangmin; Han, Sokmin] Kim Il Sung Univ, Sch Comp Sci & Technol, Visual Informat Proc Lab, Pyongyang, North Korea.
   [Wang, Tianjiang; Yuan, Caihong] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Intelligent & Distributed Comp Lab, Wuhan 430074, Hubei, Peoples R China.
C3 Huazhong University of Science & Technology
RP Choe, W (corresponding author), Kim Il Sung Univ, Sch Comp Sci & Technol, Visual Informat Proc Lab, Pyongyang, North Korea.
EM gm.choi@ryongnamsan.edu.kp; tjwang@hust.edu.cn; 36151795@qq.com
CR [Anonymous], 2012, BMVC
   [Anonymous], 2012, RELAXED PAIRWISE LEA
   [Anonymous], ARXIV14074979
   [Anonymous], 22 BRAZ S COMP GRAPH
   [Anonymous], 2013, CVPR
   [Anonymous], 2013, P CVPR
   [Anonymous], PROC CVPR IEEE
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], ICCV
   Chen DP, 2018, PROC CVPR IEEE, P8649, DOI 10.1109/CVPR.2018.00902
   Chen YC, 2018, IEEE T PATTERN ANAL, V40, P392, DOI 10.1109/TPAMI.2017.2666805
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Kanmani M, 2017, MULTIMED TOOLS APPL, V76, P20989, DOI 10.1007/s11042-016-4030-x
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463
   Lin LA, 2010, IEEE T PATTERN ANAL, V32, P1426, DOI 10.1109/TPAMI.2009.150
   Lin L, 2009, PATTERN RECOGN, V42, P1297, DOI 10.1016/j.patcog.2008.10.033
   Liu CX, 2012, LECT NOTES COMPUT SC, V7583, P391, DOI 10.1007/978-3-642-33863-2_39
   Liu H, 2015, NEUROCOMPUTING, V151, P1283, DOI 10.1016/j.neucom.2014.11.002
   Liu Jiawei, 2016, P 24 ACM INT C MULT, P192
   Ma B., 2012, Local descriptors encoded by fisher vectors for person re-identification
   Ma LY, 2014, IEEE T IMAGE PROCESS, V23, P3656, DOI 10.1109/TIP.2014.2331755
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Sun Y, 2014, ADV NEUR IN, V27
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
NR 33
TC 2
Z9 2
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27719
EP 27741
DI 10.1007/s11042-019-07867-9
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000043
DA 2024-07-18
ER

PT J
AU Dahmani, D
   Larabi, S
   Cheref, M
AF Dahmani, Djamila
   Larabi, Slimane
   Cheref, Mehdi
TI Efficient representation of size functions based on moments theory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand gestures recognition; Size function; Texture; Color; Tchebichef's
   moments
ID GESTURE RECOGNITION; MATCHING DISTANCE; HAND POSTURES; SYSTEM;
   AUTOCORRELATION; CLASSIFICATION; DESCRIPTORS; COMPUTATION
AB Nowadays, there is a need to develop efficient and intuitive solutions such as hand gestures recognition for the Human-machine interaction. This paper presents a hand gestures recognition system based on salient geometric features extracted using size functions theory. We propose a new representation of the reduced size function based on Tchebichef moments providing more details and information for their graphs descriptions compared to existing representations. In addition, a methodical algorithm of fast Tchebichef moments computation for grey scale images is well adapted to the encoded graph of size function. Furthermore, a contour discretization based on a convexity approach is proposed for an optimal computation of the measuring functions, and new measuring functions for hand gestures classification and retrieval are proposed. The comparison with existing systems indicates that our method competes with the best ranked method for the dynamic case and surpasses the state of the art in static case; in addition it presents the advantage to be applied in both static and dynamic cases.
C1 [Dahmani, Djamila; Larabi, Slimane; Cheref, Mehdi] USTHB, Comp Sci Dept, Algiers, Algeria.
C3 University Science & Technology Houari Boumediene
RP Dahmani, D (corresponding author), USTHB, Comp Sci Dept, Algiers, Algeria.
EM ddahmarui@usthb.dz; slarabi@usthb.dz
RI Larabi, Slimane/AAD-7871-2020
OI Dahmani, Djamiila/0000-0003-4770-9239; larabi,
   slimane/0000-0001-8994-5980
CR [Anonymous], 2013, ACM UIST, DOI DOI 10.1145/2501988.2502016
   Baraldi L, 2014, IEEE COMPUT SOC CONF, P702, DOI 10.1109/CVPRW.2014.107
   Barros P, 2017, COMPUT VIS IMAGE UND, V155, P139, DOI 10.1016/j.cviu.2016.10.006
   Biasotti S, 2011, PATTERN RECOGN LETT, V32, P1735, DOI 10.1016/j.patrec.2011.07.014
   Bourennane S, 2012, SIGNAL IMAGE VIDEO P, V6, P147, DOI 10.1007/s11760-010-0176-6
   Cheng J, 2015, SENSORS-BASEL, V15, P23303, DOI 10.3390/s150923303
   d'Amico M, 2006, INT J IMAG SYST TECH, V16, P154, DOI 10.1002/ima.20076
   Dibos F, 2004, J MATH IMAGING VIS, V21, P107, DOI 10.1023/B:JMIV.0000035177.68567.3b
   Dominio F, 2014, PATTERN RECOGN LETT, V50, P101, DOI 10.1016/j.patrec.2013.10.010
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Edelsbrunner H, 2008, CONTEMP MATH, V453, P257
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Flasinski M, 2010, PATTERN RECOGN, V43, P2249, DOI 10.1016/j.patcog.2010.01.004
   Flusser J., 2009, Moments and Moment Invariants in Pattern Recognition
   Frosini P, 2001, APPL ALGEBR ENG COMM, V12, P327, DOI 10.1007/s002000100078
   Frosini P., 1992, J COMBIN INFORM SYST, V17, P232
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hsieh CY, 2017, MULTIMED TOOLS APPL, V76, P7575, DOI 10.1007/s11042-016-3407-1
   Ilea DE, 2011, PATTERN RECOGN, V44, P2479, DOI 10.1016/j.patcog.2011.03.005
   JONES JP, 1987, J NEUROPHYSIOL, V58, P1233, DOI 10.1152/jn.1987.58.6.1233
   Ju ZJ, 2016, MULTIMED TOOLS APPL, V75, P11929, DOI 10.1007/s11042-015-2609-2
   Just A, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P351
   Kakumanu P, 2007, PATTERN RECOGN, V40, P1106, DOI 10.1016/j.patcog.2006.06.010
   Kane L, 2015, COMPUT VIS IMAGE UND, V141, P138, DOI 10.1016/j.cviu.2015.08.001
   Kelly D, 2010, PATTERN RECOGN LETT, V31, P1359, DOI 10.1016/j.patrec.2010.02.004
   Kim T-K, 2007, P IEEE C COMP VIS PA, P1, DOI [DOI 10.1109/CVPR.2007.383137, 10.1109/cvpr.2007.383137]
   Kim TK, 2009, IEEE T PATTERN ANAL, V31, P1415, DOI 10.1109/TPAMI.2008.167
   Kobayashi T, 2012, PATTERN RECOGN LETT, V33, P1188, DOI 10.1016/j.patrec.2012.01.007
   Kobayashi T, 2009, PATTERN RECOGN LETT, V30, P212, DOI 10.1016/j.patrec.2008.09.006
   Li C, 2018, PATTERN RECOGN, V77, P276, DOI 10.1016/j.patcog.2017.12.023
   Lin HT, 2007, MACH LEARN, V68, P267, DOI 10.1007/s10994-007-5018-6
   Lui YM, 2010, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2010.5540131
   Mhamdi MAA, 2014, IMAGE VISION COMPUT, V32, P1030, DOI 10.1016/j.imavis.2014.08.015
   Mukundan R, 2004, IEEE T IMAGE PROCESS, V13, P1055, DOI 10.1109/TIP.2004.828430
   Niebles JuanCarlos., 2006, British Machine Vision Conference, V3, P1249
   Papakostas GA, 2008, PATTERN RECOGN, V41, P1895, DOI 10.1016/j.patcog.2007.11.015
   Sanin A, 2013, IEEE WORK APP COMP, P103, DOI 10.1109/WACV.2013.6475006
   Shu HZ, 2010, IEEE T IMAGE PROCESS, V19, P3171, DOI 10.1109/TIP.2010.2052276
   Siqi Liu, 2015, 2015 7th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC). Proceedings, P186, DOI 10.1109/IHMSC.2015.71
   Su YT, 2017, MULTIMED TOOLS APPL, V76, P10635, DOI 10.1007/s11042-015-3090-7
   Triesch J, 2002, IMAGE VISION COMPUT, V20, P937, DOI 10.1016/S0262-8856(02)00100-2
   VERRI A, 1993, BIOL CYBERN, V70, P99, DOI 10.1007/BF00200823
   Verri A, 1996, IMAGE VISION COMPUT, V14, P189, DOI 10.1016/0262-8856(95)01056-4
   Wang C, 2017, SIGNAL PROCESS-IMAGE, V58, P87, DOI 10.1016/j.image.2017.06.015
   Wang JW, 2013, ENG APPL ARTIF INTEL, V26, P2215, DOI 10.1016/j.engappai.2013.06.019
   Yang C, 2017, PATTERN RECOGN LETT, V99, P39, DOI 10.1016/j.patrec.2017.05.016
   Yang HD, 2009, IEEE T PATTERN ANAL, V31, P1264, DOI 10.1109/TPAMI.2008.172
   Yui Man Lui, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P97, DOI 10.1109/FG.2011.5771378
NR 48
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27957
EP 27982
DI 10.1007/s11042-019-07859-9
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000053
DA 2024-07-18
ER

PT J
AU Latif, Z
   Wang, L
   Latif, S
   Pathan, ZH
   Ullah, R
   Zeng, JQ
AF Latif, Zahid
   Wang Lei
   Latif, Shahid
   Pathan, Zulfiqar Hussain
   Ullah, Rahat
   Zeng Jianqiu
TI Big data challenges: Prioritizing by decision-making process using
   Analytic Network Process technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Big data; Influential; Security; Privacy; Data protection; Analytic
   Network Process
ID INFORMATION; TECHNOLOGIES; CAPACITY; PRIVACY; ACCESS
AB This paper presents an innovative technique to find out the most influential challenge faced by big data. Presently, the key challenges faced by big data are security, privacy, and accuracy. To prioritize the most influential factor among the three, we need to select the suitable factor that accomplishes our objectives within the available resources. In this study, we propose the Analytic Network Process (ANP) technique for evaluating these challenges. The study also appraises the ANP model in comparison with the priorities of all competing challenges inside the big data. The secondary data has been taken for the ANP analysis from numerous scholarly articles focusing on big data. In our analysis, we have proposed a policy assessment of the relation between big data characteristics and the challenges; it further prioritizes the consequent results for the most influential challenge by using ANP model. The empirical results conclude that the security has the highest influence value i.e. 54% of the total measurement, while privacy and accuracy stand second and third among the most influential factors with 36% and 8% values respectively. Finally, the study provides important clues in the decision-making process in finding the solutions to such challenges faced by big data.
C1 [Latif, Zahid; Wang Lei; Pathan, Zulfiqar Hussain; Zeng Jianqiu] BUPT, Sch Econ & Management, 10 Xitucheng Rd, Beijing, Peoples R China.
   [Latif, Shahid] Sarhad Univ Sci & Technol Peshawar, Peshawar, Khyber Pakhtunk, Pakistan.
   [Ullah, Rahat] BUPT, Sch Opt & Commun, 10 Xitucheng Rd, Beijing, Peoples R China.
RP Latif, Z (corresponding author), BUPT, Sch Econ & Management, 10 Xitucheng Rd, Beijing, Peoples R China.
EM zahid251atif@yahoo.com; 18810771076@139.com; shahid.csit@suit.edu.pk;
   zulfi2k3@bcs.com; meetrahatullah@gmail.com; 113718688689@139.com
RI Latif, Zahid/V-4307-2018; Latif, Zahid/I-9541-2019
OI Latif, Zahid/0000-0001-6735-7555; Latif, Zahid/0000-0001-6735-7555
CR Agrawal D, 2013, PROC INT CONF DATA, P1268, DOI 10.1109/ICDE.2013.6544921
   Ahmed F, 2017, TELECOMMUN SYST, V64, P43, DOI 10.1007/s11235-016-0156-4
   Ali Ahmad ElmustaphaSyed., 2014, International Journal of Computer Science and Software Engineering (IJCSSE), V3, P78
   Ammu N., 2013, International Journal of Advanced Trends in Computer Science and Engineering, V2, P613, DOI [10.4172/2324-9307.1000135, DOI 10.4172/23249307(2)]
   [Anonymous], 2013, UNDEFINED DATA SURVE
   [Anonymous], 2016, ARXIV161009462
   [Anonymous], INFORMATIONSHIELD
   [Anonymous], 2013, BENEFITING BIG DATA
   [Anonymous], 2011, RISE NETWORK SOC INF
   [Anonymous], INT J ANAL HIERARCHY
   [Anonymous], INT J INF MANAG
   [Anonymous], CSRA MODEL CLOUD SER
   [Anonymous], P 2013 IEEE INT C BI
   [Anonymous], BIG DATAFOR DEV WHAT
   [Anonymous], BIG DATA POOL OPPORT
   [Anonymous], 2010, DOLAP 2010
   [Anonymous], INT SCHOLARLY SCI RE
   [Anonymous], 2015, COMMUNICATIONS STRAT
   [Anonymous], IBM BRING BIG DAT EN
   [Anonymous], 2005, P 8 INT S AHP
   [Anonymous], STUDY LAWS ACTIVATIO
   [Anonymous], ABSTR APPL AN
   [Anonymous], MEASURING INFORM SOC
   [Anonymous], BINARY LABELS POLITI
   [Anonymous], 2013, INT J ADV TRENDS COM, DOI DOI 10.4172/2324-9307.1000133
   [Anonymous], INT J ED DEV INF COM
   [Anonymous], THESIS
   Bardi M, 2014, CHINA COMMUN, V11, P135, DOI 10.1109/CC.2014.7085614
   Bello-Orgaz G, 2016, INFORM FUSION, V28, P45, DOI 10.1016/j.inffus.2015.08.005
   Brynjolfsson E., 2014, The second machine age: Work, progress, and prosperity in a time of brilliant technologies, P1
   Butler M, 2011, IEEE PERVAS COMPUT, V10, P4, DOI 10.1109/MPRV.2011.1
   Chen CLP, 2014, INFORM SCIENCES, V275, P314, DOI 10.1016/j.ins.2014.01.015
   Chen JY, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P898, DOI 10.1145/2964284.2964314
   Chen M, 2014, MOBILE NETW APPL, V19, P171, DOI 10.1007/s11036-013-0489-0
   Colombo P, 2015, BIG DATA RES, V2, P145, DOI 10.1016/j.bdr.2015.08.001
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Cuzzocrea A., 2014, Proceedings of the First International Workshop on Privacy and Secuirty of Big Data, P45, DOI DOI 10.1145/2663715.2669614
   De Mauro A, 2015, AIP CONF PROC, V1644, P97, DOI 10.1063/1.4907823
   Dong YC, 2010, DECIS SUPPORT SYST, V49, P281, DOI 10.1016/j.dss.2010.03.003
   Dumbill E, 2013, BIG DATA-US, V1, P1, DOI 10.1089/big.2012.1503
   Ellaway RH, 2014, MED TEACH, V36, P216, DOI 10.3109/0142159X.2014.874553
   Fisher Danyel, 2012, Interactions, V19, P50, DOI 10.1145/2168931.2168943
   Hashem IAT, 2016, INT J INFORM MANAGE, V36, P748, DOI 10.1016/j.ijinfomgt.2016.05.002
   Hilbert M, 2016, DEV POLICY REV, V34, P135, DOI 10.1111/dpr.12142
   Hilbert M, 2014, INFORM SOC, V30, P127, DOI 10.1080/01972243.2013.873748
   Hilbert M, 2011, SCIENCE, V332, P60, DOI 10.1126/science.1200970
   Hu JY, 2015, PHOTONICS RES, V3, P24, DOI 10.1364/PRJ.3.000024
   Hurwitz J., 2013, BIG DATA DUMMIES
   Jin XL, 2015, BIG DATA RES, V2, P59, DOI 10.1016/j.bdr.2015.01.006
   Kaisler S, 2013, P ANN HICSS, P995, DOI 10.1109/HICSS.2013.645
   Khalafzai AK, 2011, SUSTAINABILITY-BASEL, V3, P82, DOI 10.3390/su3010082
   Kim GH, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2500873
   Kshetri N, 2014, BIG DATA SOC, V1, DOI 10.1177/2053951714564227
   Kshetri N, 2016, INT J INFORM MANAGE, V36, P297, DOI 10.1016/j.ijinfomgt.2015.11.014
   Kwon TH, 2015, TECHNOL FORECAST SOC, V96, P144, DOI 10.1016/j.techfore.2015.03.017
   Laney D., 2001, Gartner
   Laney D, 2001, META GROUP RES NOTE, V6, P70
   Li M, 2013, BIOL AGRIC HORTIC, V29, P58, DOI 10.1080/01448765.2012.762729
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Yang, 2016, AAAI
   Marker P., 2002, SIGNIFICANCE INFORM
   Mayer-Schonberger V., 2014, BIG DATA REVOLUTION
   McAfee A, 2012, HARVARD BUS REV, V90, P60
   Meade L, 1998, TRANSPORT RES E-LOG, V34, P201, DOI 10.1016/S1366-5545(98)00012-X
   Meade LA, 2002, IEEE T ENG MANAGE, V49, P59, DOI 10.1109/17.985748
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Normandeau K., 2013, Inside Big Data
   PROCTOR R.A., 1992, Marketing Intelligence Planning, v, V10, n, P21
   Saaty T. L., 2008, INT J SERV SCI, V1, P83, DOI [10.1504/IJSSCI.2008.017590, DOI 10.1504/IJSSCI.2008.017590]
   Saaty T.L., 2013, Decision making with the analytic network process. International series in Operations Research Management Science, V195
   Saaty T.L., 2005, THEORY APPL ANALYTIC
   Saaty T.L., 1980, ANAL HIERARCHY PROCE
   Sadeghi M, 2012, INFORMATICA-LITHUAN, V23, P621
   Sagiroglu S, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON COLLABORATION TECHNOLOGIES AND SYSTEMS (CTS), P42
   Schlichter BR, 2014, GOV INFORM Q, V31, P170, DOI 10.1016/j.giq.2013.09.003
   Siraj S, 2015, INT T OPER RES, V22, P217, DOI 10.1111/itor.12054
   Song XM, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P213, DOI 10.1145/2766462.2767726
   Tole A.A., 2013, Database Syst. J., V4, P31
   Tran LT, 2004, ENVIRON MONIT ASSESS, V94, P263, DOI 10.1023/B:EMAS.0000016893.77348.67
   Triantaphyllou E., 2000, MULTICRITERIA DECISI, P5, DOI [10.1007/978-1-4757-3157-6_2, DOI 10.1007/978-1-4757-3157-6_2, 10.1007/978-1-4757-3157-62, DOI 10.1007/978-1-4757-3157-62]
   Wallenius J, 2008, MANAGE SCI, V54, P1336, DOI 10.1287/mnsc.1070.0838
   Weidner Martin, 2013, 2013 IEEE International Conference on Big Data, P518, DOI 10.1109/BigData.2013.6691616
   Zhou X., 2012, MATLAB - A Fundamental Tool for Scientific Computing and Engineering Applications -, V3, P133
NR 83
TC 7
Z9 7
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27127
EP 27153
DI 10.1007/s11042-017-5161-4
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000016
DA 2024-07-18
ER

PT J
AU Shih, HC
   Wang, HY
AF Shih, Huang-Chia
   Wang, Hao-You
TI A robust object verification algorithm using aligned chamfer history
   image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chamfer history image; Object tracking; Object modeling; Object
   verification; Vehicle verification
ID LICENSE PLATE RECOGNITION
AB Continual improvements in technology have meant that conventional manual methods of toll collection have been supplanted by electronic toll collection (ETC). ETC has been implemented in many jurisdictions. However, numerous motorists attempt to evade detection by concealing or changing their license plates. To identify such motorists, we propose a method to identify vehicles without depending on license plate data. In contrast to conventional methods for recognizing license plates, vehicles in the present study were matched using information on their appearance. An aligned chamfer history image (ACHI) with a standardization scheme using a speeded-up robust features descriptor was constructed to identify vehicles sans license plate data. Regardless of the vehicle image in the database has only captured a part of vehicle body. Our novel ACHI scheme allows a comprehensive vehicle model to be constructed on the basis of a training database. The robustness of our novel scheme for toll road ETC use was validated by the results of the present study.
C1 [Shih, Huang-Chia; Wang, Hao-You] Yuan Ze Univ, Human Comp Interact Multimedia Lab, Dept Elect Engn, Rm 70630,Bldg 7,135 Yuandong Rd, Taoyuan 32003, Taiwan.
C3 Yuan Ze University
RP Shih, HC (corresponding author), Yuan Ze Univ, Human Comp Interact Multimedia Lab, Dept Elect Engn, Rm 70630,Bldg 7,135 Yuandong Rd, Taoyuan 32003, Taiwan.
EM hcshih@saturn.yzu.edu.tw
RI Shih, Huang-Chia/AAH-4966-2021
FU Ministry of Science and Technology, Taiwan [MOST 107-2627-H-155-001,
   107-2221-E-155-031-MY2]
FX This work was partially supported by the Ministry of Science and
   Technology, Taiwan, under grants MOST 107-2627-H-155-001 and
   107-2221-E-155-031-MY2.
CR Anagnostopoulos CNE, 2014, IEEE INTEL TRANSP SY, V6, P59, DOI 10.1109/MITS.2013.2292652
   [Anonymous], 2004, BMVC
   Ashtari AH, 2014, IEEE T INTELL TRANSP, V15, P1690, DOI 10.1109/TITS.2014.2304515
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Brehar R., 2010, Proceedings of the 2010 IEEE 6th International Conference on Intelligent Computer Communication and Processing (ICCP 2010), P247, DOI 10.1109/ICCP.2010.5606430
   Chen ZZ, 2011, IEEE INT C INTELL TR, P74, DOI 10.1109/ITSC.2011.6083075
   Chonghua Li, 2010, 2010 International Conference on Anti-Counterfeiting, Security and Identification (2010 ASID), P281, DOI 10.1109/ICASID.2010.5551336
   Du S, 2013, IEEE T CIRC SYST VID, V23, P322, DOI 10.1109/TCSVT.2012.2203741
   Gavrila DM, 2007, IEEE T PATTERN ANAL, V29, P1408, DOI 10.1109/TPAMI.2007.1062
   Guo JM, 2016, IEEE T VEH TECHNOL, V65, P4023, DOI 10.1109/TVT.2015.2508020
   Hao-you W, 2013, I SYMP CONSUM ELECTR, P57
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hsia CH, 2017, P IEEE INT C CONS EL, P305
   Hsu GS, 2013, IEEE T VEH TECHNOL, V62, P552, DOI 10.1109/TVT.2012.2226218
   Kim DS, 2001, ISIE 2001: IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS PROCEEDINGS, VOLS I-III, P2022, DOI 10.1109/ISIE.2001.932025
   Lai AHS, 2001, 2001 IEEE INTELLIGENT TRANSPORTATION SYSTEMS - PROCEEDINGS, P201, DOI 10.1109/ITSC.2001.948656
   Lee KH, 2015, IEEE T CIRC SYST VID, V25, P38, DOI 10.1109/TCSVT.2014.2329355
   Leutenegger S, 2011, P IEEE INT C COMP VI
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Nistér D, 2008, LECT NOTES COMPUT SC, V5303, P183, DOI 10.1007/978-3-540-88688-4_14
   Perez-Cabre E, 2005, IEEE T VEH TECHNOL, V54, P1295, DOI 10.1109/TVT.2005.851358
   Qin JH, 2009, IEEE DECIS CONTR P, P3703, DOI 10.1109/CDC.2009.5400738
   Shapiro V, 2003, P INT C COMP SYST TE
   Shih HC, 2018, IEEE T CIRC SYST VID, V28, P1212, DOI 10.1109/TCSVT.2017.2655624
   Shih HC, 2016, IEEE T IMAGE PROCESS, V25, P4665, DOI 10.1109/TIP.2016.2586658
   Shih HC, 2016, IEEE T IND ELECTRON, V63, P4452, DOI 10.1109/TIE.2016.2543178
   Shih HC, 2015, PATTERN RECOGN, V48, P1707, DOI 10.1016/j.patcog.2014.11.004
   Sivaraman S, 2010, IEEE T INTELL TRANSP, V11, P267, DOI 10.1109/TITS.2010.2040177
   Thayananthan A, 2003, PROC CVPR IEEE, P127
   Wei W, 2001, IEEE VTS VEH TECHNOL, P3022, DOI 10.1109/VETECS.2001.944158
NR 31
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29343
EP 29355
DI 10.1007/s11042-019-7396-8
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700051
DA 2024-07-18
ER

PT J
AU Zhou, CM
   Li, F
   Cao, W
AF Zhou, Chengmin
   Li, Fei
   Cao, Wen
TI Architecture design and implementation of image based autonomous car:
   THUNDER-1
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Autonomous car architecture; Intelligent obstacle avoidance; Deep
   learning; Computer vision; ROS
AB Autonomous driving with high velocity is a research hotspot which challenges the scientists and engineers all over the world. This paper proposes a scheme of indoor autonomous car based on ROS which combines the method of Deep Learning using Convolutional Neural Network (CNN) with statistical approach using liDAR images and achieves a robust obstacle avoidance rate in cruise mode. In addition, the design and implementation of autonomous car are also presented in detail which involves the design of Software Framework, Hector Simultaneously Localization and Mapping (Hector SLAM) by Teleoperation, Autonomous Exploration, Path Plan, Pose Estimation, Command Processing, and Data Recording (Co- collection). what's more, the schemes of outdoor autonomous car, communication, and security are also discussed. Finally, all functional modules are integrated in nVidia Jetson TX1.
C1 [Zhou, Chengmin; Li, Fei] Chengdu Univ Informat Technol, Sch Cybersecur, Chengdu, Sichuan, Peoples R China.
   [Cao, Wen] Southwest Univ Sci & Technol, Sch Informat Engn, Mianyang, Sichuan, Peoples R China.
C3 Chengdu University of Information Technology; Southwest University of
   Science & Technology - China
RP Zhou, CM (corresponding author), Chengdu Univ Informat Technol, Sch Cybersecur, Chengdu, Sichuan, Peoples R China.
EM chuengminchou@qq.com
RI Cao, Wen/AAV-9207-2020
OI Cao, Wen/0000-0002-6273-323X; Zhou, Chengmin/0000-0002-8297-5949
FU Sci-Tech Support Plan of Sichuan Province, China [2016GZ0343]
FX The research of autonomous car are funded by Sci-Tech Support Plan of
   Sichuan Province, China [Grant Numbers: 2016GZ0343].
CR Aldibaja M, 2017, IEEE T IND INFO, V1
   Alheeti KMA, 2015, CONSUM COMM NETWORK, P916, DOI 10.1109/CCNC.2015.7158098
   [Anonymous], 2017, FUNCTIONAL SYSTEM AR
   [Anonymous], 2016, T CST
   Bag S, 2017, DEEP LEARNING LOCALI
   Carlone L, 2011, J INTELL ROBOT SYST, V63, P283, DOI 10.1007/s10846-010-9457-0
   Chu K, 2015, INT J AUTO TECH-KOR, V16, P653, DOI 10.1007/s12239-015-0067-5
   Dolgov D, 2008, 11 INT S ISER 2008 1, P55
   Endres F, 2014, IEEE T ROBOT, V30, P177, DOI 10.1109/TRO.2013.2279412
   Fernandes LC, 2014, J SYST ARCHITECT, V60, P372, DOI 10.1016/j.sysarc.2013.12.003
   Garip MT, 2015, WORKSH SEC EM NETWOR
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486
   International S, 2014, TAX DEF TERMS REL RO
   Jalalmaab M, 2015, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR), P213, DOI 10.1109/ICAR.2015.7251458
   Kang MC, 2017, IEEE T CONSUM ELECTR, V63, P169, DOI 10.1109/TCE.2017.014832
   Kohlbrecher S., 2011, 2011 Proceedings of IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR 2011), P155, DOI 10.1109/SSRR.2011.6106777
   Kohlbrecher S, 2013, HECTOR OPEN SOURCE M
   Lee SH, 2017, IEEE T CONTR SYST T, V25, P577, DOI 10.1109/TCST.2016.2562607
   Mur-Artal R, 2015, PROBABILISTIC SEMIDE
   Oliveira M, 2016, ROBOT AUTON SYST, V84, P113, DOI 10.1016/j.robot.2016.06.009
   Pink O, 2015, IT-INF TECHNOL, V57, P223, DOI 10.1515/itit-2015-0010
   Sallab AAA, 2016, NIPS 2016 WORKSH MLI
   Schellekens M, 2016, COMPUT LAW SECUR REV, V32, P307, DOI 10.1016/j.clsr.2015.12.019
   Tao S, 2016, INT VEH S
   Tijmons S, 2017, IEEE T ROBOT, V33, P858, DOI 10.1109/TRO.2017.2683530
   Wolcott RW, 2017, INT J ROBOT RES, V36, P292, DOI 10.1177/0278364917696568
NR 26
TC 4
Z9 4
U1 3
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28557
EP 28573
DI 10.1007/s11042-018-5816-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700012
DA 2024-07-18
ER

PT J
AU Gholami, S
   Jaferzadeh, K
   Shin, S
   Moon, I
AF Gholami, Samaneh
   Jaferzadeh, Keyvan
   Shin, Seokjoo
   Moon, Inkyu
TI An efficient image-based verification scheme by fusion of double random
   phase encoding and dynamic chaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optical security and encryption; Image cryptography; Double random phase
   encoding; Three-dimensional information processing; Chaotic system
ID PARALLEL FRAMEWORK; OPTICAL ENCRYPTION; INFORMATION; TRANSFORM;
   SECURITY; SYSTEM
AB This paper introduces an efficient image-based verification approach that integrates double random phase encoding (DRPE) and chaotic dynamic mapping. The main objective is to propose a new DRPE-based image verification scheme by replacing random phase masks (RPM) with efficient chaotic phase masks (CPM) which are dependent on an input image. For verification, the input image is first encrypted using the DRPE algorithm with the CPMs generated by our proposed methods. Then, the encrypted input image is sent to a database for verification. The peak-to-correlation energy between the encrypted input image and the encrypted reference image in the database verifies the image authenticity. The experiments reveal that the proposed scheme is highly sensitive to the key changes and represents good resistance against statistical attacks. This method can also be applied in the area of identity verification.
C1 [Gholami, Samaneh; Shin, Seokjoo] Chosun Univ, Dept Comp Engn, 309 Pilmun Daero, Gwangju 61452, South Korea.
   [Jaferzadeh, Keyvan; Moon, Inkyu] DGIST, Dept Robot Engn, 333 Techno Jungang daero, Daegu 42988, South Korea.
C3 Chosun University; Daegu Gyeongbuk Institute of Science & Technology
   (DGIST)
RP Moon, I (corresponding author), DGIST, Dept Robot Engn, 333 Techno Jungang daero, Daegu 42988, South Korea.
EM sgholami@chosun.kr; kjaferzadeh@dgist.ac.kr; sjshin@chosun.ac.kr;
   inkyu.moon@dgist.ac.kr
RI Jaferzadeh, Keyvan/ABE-3940-2020
OI Jaferzadeh, Keyvan/0000-0003-2844-3236
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Science, ICT & Future Planning
   [NRF2015K1A1A2029224]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Science, ICT & Future Planning (NRF2015K1A1A2029224).
CR Akhshani A, 2010, OPT COMMUN, V283, P3259, DOI 10.1016/j.optcom.2010.04.056
   ALabaichi Ashwak, 2013, International Journal of Digital Content Technology and its Applications, V7, P8
   Alfalou A, 2009, ADV OPT PHOTONICS, V1, P589, DOI 10.1364/AOP.1.000589
   [Anonymous], INT J INFORM COMPUTA
   [Anonymous], 2016, INT J COMPUTING ACAD
   [Anonymous], P 2005 INT C COMM CI
   Carnicer A, 2005, OPT LETT, V30, P1644, DOI 10.1364/OL.30.001644
   Carnicer A, 2017, ADV OPT PHOTONICS, V9, P218, DOI 10.1364/AOP.9.000218
   Chen JX, 2015, OPT COMMUN, V341, P263, DOI 10.1016/j.optcom.2014.12.045
   Chen W, 2009, OPT COMMUN, V282, P3680, DOI 10.1016/j.optcom.2009.06.014
   Chen W, 2014, ADV OPT PHOTONICS, V6, P120, DOI 10.1364/AOP.6.000120
   Frauel Y, 2007, OPT EXPRESS, V15, P10253, DOI 10.1364/OE.15.010253
   HEANUE JF, 1995, APPL OPTICS, V34, P6012, DOI 10.1364/AO.34.006012
   HORNER JL, 1992, APPL OPTICS, V31, P165, DOI 10.1364/AO.31.000165
   Javidi B, 2016, J OPTICS-UK, V18, DOI 10.1088/2040-8978/18/8/083001
   Jun He, 2010, Journal of Software, V5, P421, DOI 10.4304/jsw.5.4.421-428
   Khanzadi H, 2010, INT CONF SIGN PROCES, P2608, DOI 10.1109/ICOSP.2010.5656132
   Markman A, 2014, J OPT SOC AM A, V31, P394, DOI 10.1364/JOSAA.31.000394
   Matoba O, 2009, P IEEE, V97, P1128, DOI 10.1109/JPROC.2009.2018367
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Mogensen PC, 2000, OPT LETT, V25, P566, DOI 10.1364/OL.25.000566
   Moon I, 2016, APPL OPTICS, V55, P4328, DOI 10.1364/AO.55.004328
   Naughton TJ, 2008, J OPT SOC AM A, V25, P2608, DOI 10.1364/JOSAA.25.002608
   Nomura T, 2004, OPT ENG, V43, P2228, DOI 10.1117/1.1789991
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Singh N, 2009, OPT LASER ENG, V47, P539, DOI 10.1016/j.optlaseng.2008.10.013
   Socek D, 2005, FIRST INTERNATIONAL CONFERENCE ON SECURITY AND PRIVACY FOR EMERGING AREAS IN COMMUNICATIONS NETWORKS, PROCEEDINGS, P406, DOI 10.1109/SECURECOMM.2005.39
   Stallings W., 2017, Cryptography and Network Security: Principles and Practice, V7th ed.
   Suzuki H, 2006, OPT EXPRESS, V14, P1755, DOI 10.1364/OE.14.001755
   Tajahuerce E, 2000, APPL OPTICS, V39, P6595, DOI 10.1364/AO.39.006595
   Tan XD, 2001, APPL OPTICS, V40, P2310, DOI 10.1364/AO.40.002310
   Yan CG, 2019, IEEE T MULTIMEDIA, V21, P2675, DOI 10.1109/TMM.2019.2903448
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yi F, 2014, SENSORS-BASEL, V14, P8877, DOI 10.3390/s140508877
   Zhao TY, 2016, OPT LASER ENG, V83, P48, DOI 10.1016/j.optlaseng.2016.03.001
NR 37
TC 4
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 25001
EP 25018
DI 10.1007/s11042-019-7714-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900060
DA 2024-07-18
ER

PT J
AU Gujjunoori, S
   Oruganti, M
AF Gujjunoori, Sagar
   Oruganti, Madhu
TI Difference expansion based reversible data embedding and edge detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Difference expansion; Reversible; Data embedding; Edge detection;
   Multi-layer; Changeable difference
ID DATA HIDING SCHEME; TRANSFORM
AB Difference Expansion (DE) based techniques are evolving in the last decade. The DE based techniques aims at reversibly embedding the data into cover content. Most of the DE based reversible embedding techniques aims to reduce/avoid the amount of auxiliary information to be embedded into the cover images and then state that the auxiliary information generated in the process has no applications rather to keep track of the overflow and/or underflow problems that may arise during the reversible embedding. Our objective is to address the above issues as well as address other related issues as stated below. In this article, we present multiple contributions based on difference expansion technique. At first, we propose a DE based reversible scheme to reduce the amount of auxiliary information to be embedded into the image, to increase the length of the watermark, using the pixel pair information of the changeable differences. The application which emphasizes the need for preserving the auxiliary information, generated by layer-2 DE embedding, is identified. A simple mechanism is suggested to increase the visual quality when the data is embedded using layer-2 embedding. Next, we propose an edge detection scheme using the DE technique. We used PSNR and SSIM visual quality assessment metrics and embedding capacity measure to assess the effectiveness of the proposed data embedding algorithms. The metrics Precision and Recall are used to assess the DE based edge detection scheme. The experimental tests have been conducted on two different datasets having complex visual distinctness features. The analytical and experimental results demonstrate that the proposed work significantly improved state of the art.
C1 [Gujjunoori, Sagar] Vardhaman Coll Engn, Dept Comp Sci & Engn, Hyderabad, Telangana, India.
   [Oruganti, Madhu] Sreenidhi Inst Sci & Technol, Dept Elect & Commun Engn, Hyderabad, Telangana, India.
C3 Vardhaman College of Engineering; Sreenidhi Institute of Science &
   Technology
RP Gujjunoori, S (corresponding author), Vardhaman Coll Engn, Dept Comp Sci & Engn, Hyderabad, Telangana, India.
EM sagar.g@vardhaman.org; oruganti.madhu@gmail.com
RI Oruganti, Madhu/KIJ-9331-2024
OI Oruganti, Madhu/0000-0002-6274-3606; Gujjunoori, Dr.
   Sagar/0000-0001-7127-6061
FU Science and Engineering Research Board (SERB), Government of India, New
   Delhi under the Fast Track Young Scientist-Engineering Science Scheme
   [SB/FTP/ETA-0192/2014]
FX The work presented in this paper is part of the project Ref:
   SB/FTP/ETA-0192/2014 and is financially supported by the Science and
   Engineering Research Board (SERB), Government of India, New Delhi under
   the Fast Track Young Scientist-Engineering Science Scheme. It is
   gratefully acknowledged.
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Chang CC, 2006, J SYST SOFTWARE, V79, P1754, DOI 10.1016/j.jss.2006.03.035
   Cox Ingemar, 2008, DIGITAL WATERMARKING, V2
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Gujjunoori S, 2013, J INF SECUR APPL, V18, P157, DOI 10.1016/j.istr.2013.01.002
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Hu YJ, 2008, IEEE T MULTIMEDIA, V10, P1500, DOI 10.1109/TMM.2008.2007341
   Huang H-C, 2011, IEEE TRANS CONSUM EL, V57, P2, DOI [10.1109/TCE.2011.6131106, DOI 10.1109/TCE.2011.6131106]
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Kim KS, 2009, PATTERN RECOGN, V42, P3083, DOI 10.1016/j.patcog.2009.04.004
   Lee CF, 2010, J SYST SOFTWARE, V83, P1864, DOI 10.1016/j.jss.2010.05.078
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lin CC, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P8, DOI 10.1109/CISP.2008.64
   Liu ML, 2012, SIGNAL PROCESS, V92, P819, DOI 10.1016/j.sigpro.2011.09.028
   Liu YC, 2011, MULTIMED TOOLS APPL, V52, P263, DOI 10.1007/s11042-010-0496-0
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Thodi DM, 2004, IEEE IMAGE PROC, P1549
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   Weng SW, 2008, CIRC SYST SIGNAL PR, V27, P229, DOI 10.1007/s00034-008-9021-3
   Weng SW, 2008, IEEE SIGNAL PROC LET, V15, P721, DOI 10.1109/LSP.2008.2001984
NR 27
TC 13
Z9 13
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25889
EP 25917
DI 10.1007/s11042-019-07767-y
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700030
DA 2024-07-18
ER

PT J
AU Riaz, S
   Ali, Z
   Park, U
   Choi, J
   Masi, I
   Natarajan, P
AF Riaz, Sidra
   Ali, Zahid
   Park, Unsang
   Choi, Jongmoo
   Masi, Iacopo
   Natarajan, Prem
TI Age-invariant face recognition using gender specific 3D aging modeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Aging model; Aging simulation; Age progression; Age-invariant face
   recognition; VGG face CNN descriptor
AB The age-invariant face recognition (AIFR) is a relatively new area of research in the face recognition domain which has recently gained substantial attention due to its great potential and importance in real-world applications. However, the AIFR is still in the process of emergence and development, offering a large room for further investigation and accuracy improvement. The key challenges in the AIFR are considerable changes of appearance of facial skin (wrinkles, jaw lines), facial shape, and skin tone in combination with the variations of pose and illumination. These challenges impose limitations on the current AIFR systems and complicate the recognition task for identity verification especially for temporal variation. In order to address this problem, we need a temporally invariant face verification system that would be robust vis-a-vis several factors, such as aging (shape, texture), pose, and illumination. In this study, we present a 3D gender-specific aging model that is robust to aging and pose variations and provides a better recognition performance than the conventional state-of-the-art AIFR systems. The gender-specific age modeling is performed in a 3D domain from 2D facial images of various datasets, such as PCSO, BROWNS, Celebrities, Private, and FG-NET. The evaluation of the proposed approach is performed on FG-NET (the most referred database in the AIFR studies) and MORPH-Album2 (the largest aging database) by using the VGG face CNN descriptor for matching. In addition, we also test the effects of linear discriminant analysis (LDA) and principal component analysis (PCA) subspaces learning in our face verification experiments. The proposed AIFR system is evaluated both on the pose corrected and background composited age-simulated images. The experimental results demonstrate that the proposed system provides state-of-the-art performance on FG-NET (83.89% of rank-1, 43.24% of TAR) and comparable performance to the state-of-the-art on MORPH-Album2 (75.27% of rank-1, 96.93% of TAR).
C1 [Riaz, Sidra; Ali, Zahid; Park, Unsang] Sogang Univ, Dept Comp Sci & Engn, Seoul, South Korea.
   [Choi, Jongmoo; Masi, Iacopo] Univ Southern Calif, Inst Robot & Intelligent Syst, Los Angeles, CA USA.
   [Natarajan, Prem] Univ Southern Calif, Inst Informat Sci, Los Angeles, CA USA.
C3 Sogang University; University of Southern California; University of
   Southern California
RP Park, U (corresponding author), Sogang Univ, Dept Comp Sci & Engn, Seoul, South Korea.
EM sidra@sogang.ac.kr; zahid@sogang.ac.kr; unsangpark@sogang.ac.kr;
   jongmooc@usc.edu; iacopo.masi@usc.edu; pnataraj@usc.edu
OI Riaz, Sidra/0000-0002-0216-416X
FU IARPA's Janus program [2014-14071600011]; ICT R&D program of MSIP/IITP
   [R0126-16-1112]
FX This research has been funded in part by IARPA's Janus program under
   contract number 2014-14071600011 and the ICT R&D program of MSIP/IITP.
   [R0126-16-1112, Development of Media Application Framework based on
   Multi-modality which enables Personal Media Reconstruction].
CR [Anonymous], ARXIV160206149
   [Anonymous], 2006, COMP ROB VIS 2006 3
   [Anonymous], 2015, BRIT MACH VIS C
   [Anonymous], J VISAPP
   [Anonymous], FACEVACS SOFTW DEV K
   [Anonymous], 2014, ARXIV14117923
   [Anonymous], MCS2014003 U MASS
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Chen BC, 2015, IEEE T MULTIMEDIA, V17, P804, DOI 10.1109/TMM.2015.2420374
   Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389
   Ding CX, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2845089
   Ding L, 2012, IEEE SIGNAL PROC LET, V19, P721, DOI 10.1109/LSP.2012.2215586
   Du JX, 2013, NEUROCOMPUTING, V116, P250, DOI 10.1016/j.neucom.2012.08.030
   Farkas LG, 1994, Anthropometry of Head and Face, Vsecond
   Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733
   Gong DH, 2013, IEEE I CONF COMP VIS, P2872, DOI 10.1109/ICCV.2013.357
   Ho HT, 2013, IEEE T IMAGE PROCESS, V22, P1571, DOI 10.1109/TIP.2012.2233489
   Hwang J, 2012, SENSORS-BASEL, V12, P12870, DOI 10.3390/s121012870
   Klare B., 2011, 2011 International Joint Conference on Biometrics (IJCB), P1
   Li ZF, 2011, IEEE T INF FOREN SEC, V6, P1028, DOI 10.1109/TIFS.2011.2156787
   Nixon Nicholas., 2007, The Brown Sisters: Thirty-three Years
   Otto C, 2012, LECT NOTES COMPUT SC, V7584, P189, DOI 10.1007/978-3-642-33868-7_19
   Park U, 2010, IEEE T PATTERN ANAL, V32, P947, DOI 10.1109/TPAMI.2010.14
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tikhonov A., 1977, Solution of Ill-Posed Problems
   Yang H., 2014, IEEE INT JOINT C BIO, P1
   Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679
NR 27
TC 4
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 25163
EP 25183
DI 10.1007/s11042-019-7694-1
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900068
DA 2024-07-18
ER

PT J
AU Kandhway, P
   Bhandari, AK
AF Kandhway, Pankaj
   Bhandari, Ashish Kumar
TI Spatial context cross entropy function based multilevel image
   segmentation using multi-verse optimizer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Minimum cross entropy; Multi-verse optimizer; Energy curve; Multi-level
   image segmentation
ID CUCKOO SEARCH ALGORITHM
AB In this paper, a context-sensitive energy curve based cross-entropy method for multilevel color image segmentation is proposed. In thresholding approaches, pixels are arranged in various regions based on their intensity level. The main challenge generally faced in multilevel thresholding is the selection of best threshold values for the pixel division. However, the combination of the energy curve and the minimum cross entropy (Energy-MCE) scheme provides appropriate thresholds for a multilevel approach, but the computational cost for selecting optimal thresholds is high. Therefore, the selection of meta-heuristic optimization algorithms reduces this cost and generates optimal thresholds. A multi-verse optimizer (MVO) algorithm based on Energy-MCE thresholding approach is proposed to search the accurate and near-optimal thresholds for segmentation. Tests on natural images showed that the proposed method achieves better performance than the well-known optimization techniques in many challenging cases or images, such as identifying weak objects and revealing fine structures of complex objects while the added computational cost is minimal.
C1 [Kandhway, Pankaj; Bhandari, Ashish Kumar] Natl Inst Technol, Dept Elect & Commun Engn, Patna 800005, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Bhandari, AK (corresponding author), Natl Inst Technol, Dept Elect & Commun Engn, Patna 800005, Bihar, India.
EM pankaj.kandhway@gmail.com; bhandari.iiitj@gmail.com
RI Bhandari, Ashish Kumar/AAA-9991-2019; KANDHWAY, PANKAJ/AAE-4074-2021
OI Bhandari, Ashish Kumar/0000-0001-9842-8125; 
CR Akay B, 2013, APPL SOFT COMPUT, V13, P3066, DOI 10.1016/j.asoc.2012.03.072
   [Anonymous], NEUROCOMPUTING
   [Anonymous], CVPR
   [Anonymous], P ICASSP 04 IEEE INT
   [Anonymous], INFRARED PHYS TECHNO
   [Anonymous], 15 EUR C COMP VIS MU
   [Anonymous], OPTIMAL MULTILEVEL T
   [Anonymous], 1995, 1995 IEEE INT C
   [Anonymous], 1997, Information theory and statistics
   Avola D, 2018, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS (ICPRAM 2018), P638, DOI 10.5220/0006722506380645
   Avola D, 2017, PATTERN RECOGN LETT, V100, P110, DOI 10.1016/j.patrec.2017.10.029
   Bhandari AK, 2014, EXPERT SYST APPL, V41, P3538, DOI 10.1016/j.eswa.2013.10.059
   Chakraborty R., 2018, ARAB J SCI ENG, P1
   Chen JY, 2018, ENG APPL ARTIF INTEL, V73, P92, DOI 10.1016/j.engappai.2018.04.023
   de Albuquerque MP, 2004, PATTERN RECOGN LETT, V25, P1059, DOI 10.1016/j.patrec.2004.03.003
   Eskandar H, 2012, COMPUT STRUCT, V110, P151, DOI 10.1016/j.compstruc.2012.07.010
   Fan D.P., 2018, IJCAI
   Fan D-P, 2018, ARXIV180402975
   Ghamisi Pedram, 2014, IEEE Transactions on Geoscience and Remote Sensing, V52, P2382, DOI 10.1109/TGRS.2013.2260552
   He LF, 2017, NEUROCOMPUTING, V240, P152, DOI 10.1016/j.neucom.2017.02.040
   Horng MH, 2011, EXPERT SYST APPL, V38, P14805, DOI 10.1016/j.eswa.2011.05.069
   Horng MH, 2011, EXPERT SYST APPL, V38, P13785, DOI 10.1016/j.eswa.2011.04.180
   Ji ZX, 2014, PATTERN RECOGN, V47, P2454, DOI 10.1016/j.patcog.2014.01.017
   Jia C, 2016, NEUROCOMPUTING, V173, P406, DOI 10.1016/j.neucom.2015.03.122
   Kaheil YH, 2006, WATER RESOUR RES, V42, DOI 10.1029/2005WR004529
   Kandhway P, 2019, CIRC SYST SIGNAL PR, V38, P3058, DOI 10.1007/s00034-018-0993-3
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Kiran MS, 2015, EXPERT SYST APPL, V42, P6686, DOI 10.1016/j.eswa.2015.04.055
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   LI CH, 1993, PATTERN RECOGN, V26, P617, DOI 10.1016/0031-3203(93)90115-D
   Li CH, 1998, PATTERN RECOGN LETT, V19, P771, DOI 10.1016/S0167-8655(98)00057-9
   Liao PS, 2001, J INF SCI ENG, V17, P713
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Mirjalili S, 2015, KNOWL-BASED SYST, V89, P228, DOI 10.1016/j.knosys.2015.07.006
   Mirjalili S, 2016, NEURAL COMPUT APPL, V27, P495, DOI 10.1007/s00521-015-1870-7
   Mirjalili S, 2014, ARAB J SCI ENG, V39, P4683, DOI 10.1007/s13369-014-1156-x
   Ndajah Peter, 2010, Advances in Visualization, Imaging and Simulation. 3rd WSEAS International Conference on Visualization, Imaging and Simulation (VIS 2010), P53
   Nie FY, 2017, SIGNAL PROCESS, V134, P23, DOI 10.1016/j.sigpro.2016.11.004
   Oliva D, 2017, SOFT COMPUT, P1
   Oliva D, 2017, EXPERT SYST APPL, V79, P164, DOI 10.1016/j.eswa.2017.02.042
   Oliver DL, 2018, SPRINGER HANDB AUDIT, V65, P1, DOI 10.1007/978-3-319-71798-2_1
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pare S, 2019, ADV INTELL SYST COMP, V748, P71, DOI 10.1007/978-981-13-0923-6_7
   Pare S, 2017, APPL SOFT COMPUT, V61, P570, DOI 10.1016/j.asoc.2017.08.039
   Pare S, 2016, APPL SOFT COMPUT, V47, P76, DOI 10.1016/j.asoc.2016.05.040
   Sahoo PK, 2004, PATTERN RECOGN, V37, P1149, DOI 10.1016/j.patcog.2003.10.008
   Saremi S, 2017, ADV ENG SOFTW, V105, P30, DOI 10.1016/j.advengsoft.2017.01.004
   Sarkar S, 2015, PATTERN RECOGN LETT, V54, P27, DOI 10.1016/j.patrec.2014.11.009
   Sathya PD, 2011, EXPERT SYST APPL, V38, P15549, DOI 10.1016/j.eswa.2011.06.004
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Tang KZ, 2011, KNOWL-BASED SYST, V24, P1131, DOI 10.1016/j.knosys.2011.02.013
   THUM C, 1984, OPT ACTA, V31, P203, DOI 10.1080/713821475
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yang XB, 2010, ADV INFORM KNOWL PRO, P65, DOI 10.1007/978-1-84882-628-1_4
   Yang XS, 2009, WOR CONG NAT BIOL, P210, DOI 10.1109/nabic.2009.5393690
   Yin PY, 2007, APPL MATH COMPUT, V184, P503, DOI 10.1016/j.amc.2006.06.057
   Yu QY, 2008, IEEE T PATTERN ANAL, V30, P2126, DOI 10.1109/TPAMI.2008.15
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 58
TC 29
Z9 29
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22613
EP 22641
DI 10.1007/s11042-019-7506-7
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400020
DA 2024-07-18
ER

PT J
AU Keshavarzian, R
   Aghagolzadeh, A
   Rezaii, TY
AF Keshavarzian, Razieh
   Aghagolzadeh, Ali
   Rezaii, Tohid Yousefi
TI Image compressed sensing recovery via nonconvex garrote regularization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Alternating direction method; Compressed sensing; Garrote function;
   Image reconstruction; Low-rank regularization; Sparsity
ID MATRIX COMPLETION; SPARSITY; RECONSTRUCTION
AB Sparsity inducing model is one of the most important components of image compressed sensing (CS) recovery methods. These models are built on the image prior knowledge. The model which can reflect the image priors appropriately, yields high quality recovery results. Recent studies have shown that nonlocal low-rank prior based models often lead to superior results in CS recovery. The rank regularization problem resulting from these models is an NP-hard problem and how to solve it has a great impact on the recovery results. In this paper, we propose a new CS recovery method via nonconvex Garrote regularization (NGR) toward better exploiting the nonlocal low-rank prior. In the proposed CS-NGR method, the nonconvex Garrote function is introduced as a suitable surrogate for the rank function. To solve the resulting minimization problem efficiently, we employ the alternating direction method and so-called Garrote singular value shrinkage (GSVS) technique. Extensive experimental results show effectiveness of the proposed method compared with the state-of-the-arts methods in CS image recovery.
C1 [Keshavarzian, Razieh; Aghagolzadeh, Ali] Babol Noshirvani Univ Technol, Fac Elect & Comp Engn, Babol Sar, Iran.
   [Rezaii, Tohid Yousefi] Univ Tabriz, Fac Elect & Comp Engn, Tabriz, Iran.
C3 Babol Noshirvani University of Technology; University of Tabriz
RP Aghagolzadeh, A (corresponding author), Babol Noshirvani Univ Technol, Fac Elect & Comp Engn, Babol Sar, Iran.
EM r.keshavarzian@stu.nit.ac.ir; aghagol@nit.ac.ir; yousefi@tabrizu.ac.ir
RI Keshavarzian, Razieh/AAN-2135-2021; Aghagolzadeh, Ali/AAA-7757-2021
OI Keshavarzian, Razieh/0000-0002-7623-5282; Aghagolzadeh,
   Ali/0000-0002-6999-3464
CR Afonso MV, 2010, IEEE T IMAGE PROCESS, V19, P2345, DOI 10.1109/TIP.2010.2047910
   [Anonymous], IEEE SIGNAL PROCESS
   [Anonymous], IEEE J EMERGING SELE
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], IEEE GLOB C SIGN INF
   [Anonymous], 2013, PENALTY SHRINKAGE FU
   [Anonymous], P 15 INT C DIG SIGN
   [Anonymous], IEEE INT C COMP VIS
   BREIMAN L, 1995, TECHNOMETRICS, V37, P373, DOI 10.2307/1269730
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   Chartrand R, 2007, IEEE SIGNAL PROC LET, V14, P707, DOI 10.1109/LSP.2007.898300
   Dong WS, 2014, IEEE T IMAGE PROCESS, V23, P3618, DOI 10.1109/TIP.2014.2329449
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Eslahi N, 2016, NEUROCOMPUTING, V200, P88, DOI 10.1016/j.neucom.2016.03.013
   Eslahi N, 2016, IEEE T IMAGE PROCESS, V25, P3126, DOI 10.1109/TIP.2016.2562563
   Feng L, 2017, J VIS COMMUN IMAGE R, V42, P37, DOI 10.1016/j.jvcir.2016.11.007
   Feng L, 2016, SIGNAL PROCESS-IMAGE, V47, P28, DOI 10.1016/j.image.2016.05.012
   Gao HY, 1998, J COMPUT GRAPH STAT, V7, P469
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Guo Q, 2018, IEEE T VIS COMPUT GR, V24, P2023, DOI 10.1109/TVCG.2017.2702738
   Guo Q, 2016, IEEE T CIRC SYST VID, V26, P868, DOI 10.1109/TCSVT.2015.2416631
   He N, 2016, MULTIMED TOOLS APPL, V75, P2579, DOI 10.1007/s11042-015-2471-2
   Hu Y, 2013, IEEE T PATTERN ANAL, V35, P2117, DOI 10.1109/TPAMI.2012.271
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Li SJ, 2015, IEEE T IMAGE PROCESS, V24, P4240, DOI 10.1109/TIP.2015.2459653
   Liu S, 2017, NEUROCOMPUTING, V89, P1
   Lu CY, 2015, AAAI CONF ARTIF INTE, P1805
   Lu CY, 2016, IEEE T IMAGE PROCESS, V25, P829, DOI 10.1109/TIP.2015.2511584
   Mun S., 2009, 16 IEEE INT C IM PRO
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Parekh A, 2017, SIGNAL PROCESS, V139, P62, DOI 10.1016/j.sigpro.2017.04.011
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xie Y, 2016, IEEE T IMAGE PROCESS, V25, P4842, DOI 10.1109/TIP.2016.2599290
   Yoon H, 2014, IEEE T MED IMAGING, V33, P2069, DOI 10.1109/TMI.2014.2330426
   Zhang DB, 2012, PROC CVPR IEEE, P2192, DOI 10.1109/CVPR.2012.6247927
   Zhang J, 2014, IEEE T IMAGE PROCESS, V23, P3336, DOI 10.1109/TIP.2014.2323127
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P12853, DOI 10.1007/s11042-017-4919-z
   Zhang Z, 2016, IEEE T IMAGE PROCESS, V25, P2429, DOI 10.1109/TIP.2016.2547180
NR 41
TC 1
Z9 1
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22301
EP 22323
DI 10.1007/s11042-019-7366-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400006
DA 2024-07-18
ER

PT J
AU Liu, XW
   Liu, Z
   Jiao, QH
   Le Meur, O
   Zhao, WL
AF Liu, Xiuwen
   Liu, Zhi
   Jiao, Qihan
   Le Meur, Olivier
   Zhao, Wan-Lei
TI Saliency-aware inter-image color transfer for image manipulation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image manipulation; inter-image color transfer; saliency
AB This paper proposes a novel saliency-aware inter-image color transfer method to perform image manipulation. Specifically, given the source image, the candidate images are first retrieved from a group of images with the same semantic category, and the corresponding saliency maps are obtained using an existing saliency model. Then, the inter-image color transfer method is proposed to transfer the colors of the high-saliency region in each candidate image to the target object region in the source image, for generating the manipulated image. Finally, from a set of manipulated images, the one with the highest weighted F-measure of its saliency map is selected as the final result. Experimental results show that the proposed method not only highlights objects effectively but also preserves the naturalness of images well, and consistently outperforms other image manipulation methods when viewing the manipulated images with or without the source image as the reference.
C1 [Liu, Xiuwen; Liu, Zhi; Jiao, Qihan] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
   [Liu, Xiuwen; Liu, Zhi; Jiao, Qihan] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
   [Le Meur, Olivier] Univ Rennes 1, IRISA, F-35042 Rennes, France.
   [Zhao, Wan-Lei] Xiamen Univ, Sch Informat Sci & Technol, Xiamen 361005, Fujian, Peoples R China.
C3 Shanghai University; Shanghai University; Universite de Rennes; Xiamen
   University
RP Liu, Z (corresponding author), Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.; Liu, Z (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
EM 18817956506@163.com; liuzhisjtu@163.com; 18604544566@163.com;
   olemeur@irisa.fr; wlzhao@xmu.edu.cn
RI LIU, Zhi/D-4518-2012
OI LIU, Zhi/0000-0002-8428-1131
FU National Natural Science Foundation of China [61771301]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61771301.
CR [Anonymous], 2005, TEXTURE 2005 P 4TH I
   [Anonymous], 2014, P 1 INTERNATIONALWOR, DOI DOI 10.1145/2662996.2663009
   [Anonymous], 2011, 2011 IEEE WORKSH APP
   Bernhard M., 2011, 2011 IEEE 10th IVMSP Workshop: Perception and Visual Signal Analysis, P153, DOI 10.1109/IVMSPW.2011.5970371
   Fried O, 2015, PROC CVPR IEEE, P1703, DOI 10.1109/CVPR.2015.7298779
   Gatys Leon A, 2017, ARXIV171206492
   Hagiwara Aiko, 2011, P 1 INT WORKSH PERV
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1937, DOI 10.1109/TIP.2014.2307434
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Mateescu VA, 2016, IEEE MULTIMEDIA, V23, P82, DOI 10.1109/MMUL.2015.59
   Mechrez R, 2018, IEEE WINT CONF APPL, P1368, DOI 10.1109/WACV.2018.00154
   Nguyen TV, 2013, IEEE T MULTIMEDIA, V15, P1910, DOI 10.1109/TMM.2013.2272919
   Pal R, 2017, 2017 14TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV 2017), P337, DOI 10.1109/CRV.2017.33
   Pingping Zhang, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P202, DOI 10.1109/ICCV.2017.31
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Ren JR, 2018, J VIS COMMUN IMAGE R, V50, P227, DOI 10.1016/j.jvcir.2017.12.002
   Song HK, 2017, IEEE T IMAGE PROCESS, V26, P4204, DOI 10.1109/TIP.2017.2711277
   Song ML, 2014, INFORM SCIENCES, V281, P573, DOI 10.1016/j.ins.2013.09.036
   Takimoto H, 2017, IEICE T INF SYST, VE100D, P1339, DOI 10.1587/transinf.2016EDP7413
   Tao DP, 2016, IEEE T NEUR NET LEAR, V27, P1122, DOI 10.1109/TNNLS.2015.2461554
   Vazquez-Corral J, 2017, P COL IM C, P313
   Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50
   Yan ZC, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2790296
   Zavalishin SS, 2018, P 7 IEEE MED C EMB C, P1
   Zhou XF, 2017, MULTIMED TOOLS APPL, V76, P23187, DOI 10.1007/s11042-016-4093-8
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 29
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21629
EP 21644
DI 10.1007/s11042-019-7450-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400049
DA 2024-07-18
ER

PT J
AU Ramadevi, V
   Chari, KM
AF Ramadevi, V.
   Chari, K. Manjunatha
TI FPGA realization of an efficient image scalar with modified area
   generation technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image scalar; Vedic mathematics; Field programmable gate array (FPGA);
   Line buffer; Combinational logic blocks (CLBs)
ID EDGE-DETECTION; INTERPOLATION
AB Image scaling is extensively utilized in numerous image processing implementations, like digital camera, tablet, mobile phone, and display devices. Image scaling is a technique of enlarge or diminish the image by provided scale factor. Image scaling can also be discussed as image interpolation, image re-sampling, image resizing, and image zooming. This paper introduces VLSI (Very Large Scale Integration) architecture of an accurate and area effectual image scalar. This architecture is applied in HDL language, synthesize and simulation by Xilinx ISE simulation tool. Lastly observe quality and performance measure, in quality measure associate the PSNR value of scaled image to source image. In presentation measure numerous VLSI parameters like type of device, area, computation time, and power. From the solution in quality measure to upsurge the PSNR value by 15% and 9% Image enlargement and reduction correspondingly and diminish 18% combinational logic blocks (CLBs).
C1 [Ramadevi, V.] GITAM Univ, Sch Technol, Elect & Commun Engn, Hyderabad, India.
   [Chari, K. Manjunatha] GITAM Univ, Sch Technol, ECE Dept, Hyderabad, India.
C3 Gandhi Institute of Technology & Management (GITAM); Gandhi Institute of
   Technology & Management (GITAM)
RP Ramadevi, V (corresponding author), GITAM Univ, Sch Technol, Elect & Commun Engn, Hyderabad, India.
EM ramadeviv0283@gmail.com
RI Achari, Kamsali/V-5939-2019; Vemula, Ramadevi/AAU-2904-2020
OI Achari, Kamsali/0000-0002-0175-2779; Vemula,
   Ramadevi/0000-0001-5660-6448; k, Manjunatha Chari/0000-0002-2275-7499;
   Chari, Manjunatha/0000-0001-9586-5282
CR Acharjya P.P., 2012, Global Journal of Computer Science and Technology
   Andreadis I., 2005, P IEEE INSTR MEAS TE, V3, P2028, DOI DOI 10.1109/IMTC.2005.1604529
   [Anonymous], ARXIV170807077
   Bao P, 2005, IEEE T PATTERN ANAL, V27, P1485, DOI 10.1109/TPAMI.2005.173
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chen PY, 2009, IEEE T VLSI SYST, V17, P1275, DOI 10.1109/TVLSI.2008.2003003
   Chen SL, 2013, IEEE T CIRC SYST VID, V23, P1510, DOI 10.1109/TCSVT.2013.2248492
   Chen SL, 2013, IEEE T CIRCUITS-II, V60, P31, DOI 10.1109/TCSII.2012.2234873
   Chen SL, 2011, IEEE T CIRC SYST VID, V21, P1600, DOI 10.1109/TCSVT.2011.2129790
   Chen YM, 2016, OPTIK, V127, P11, DOI 10.1016/j.ijleo.2015.09.144
   Han J, 2010, COMPUT IND ENG, V59, P1, DOI 10.1016/j.cie.2009.06.015
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   Jain Shubham., 2014, Proceedings 2014 Workshop on Usable Security. Workshop on Usable Security, P1, DOI [10.1109/SCEECS.2014.6804465, DOI 10.1109/SCEECS.2014.6804465]
   JENSEN K, 1995, IEEE T IMAGE PROCESS, V4, P285, DOI 10.1109/83.366477
   Kim CH, 2003, IEEE T CIRC SYST VID, V13, P549, DOI 10.1109/TCSVT.2003.813431
   Kim H, 2011, IEEE T IMAGE PROCESS, V20, P1895, DOI 10.1109/TIP.2011.2107523
   Kumar G.G., 2012, INT J SCI RES PUBLIC, V2, P1
   Law MWK, 2007, IEEE T MED IMAGING, V26, P1224, DOI 10.1109/TMI.2007.903231
   Lin CC, 2010, IEEE T CIRC SYST VID, V20, P1260, DOI 10.1109/TCSVT.2010.2057017
   Öztürk S, 2015, WORLD CONFERENCE ON TECHNOLOGY, INNOVATION AND ENTREPRENEURSHIP, P2668, DOI 10.1016/j.sbspro.2015.06.477
   [庞志勇 Pang Zhiyong], 2013, [自动化学报, Acta Automatica Sinica], V39, P407
   Parker J, 1983, IEEE Trans Med Imaging, V2, P31, DOI 10.1109/TMI.1983.4307610
   Pathak B, 2014, GRAY LEVEL COOCCURRE
   Rakesh RR, 2004, IEEE T IMAGE PROCESS, V13, P927, DOI 10.1109/TIP.2004.828404
   Wu WC, 2013, IEEE WORKSHOP SIG, P65, DOI 10.1109/SiPS.2013.6674482
   Xie X, 2017, PROC IEEE MICR ELECT, P813, DOI 10.1109/MEMSYS.2017.7863532
   Xie X, 2016, PROC IEEE MICR ELECT, P75, DOI 10.1109/MEMSYS.2016.7421561
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
   Yitzhaky Y, 2003, IEEE T PATTERN ANAL, V25, P1027, DOI 10.1109/TPAMI.2003.1217608
   Zhang XJ, 2008, IEEE T IMAGE PROCESS, V17, P887, DOI 10.1109/TIP.2008.924279
NR 32
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23707
EP 23732
DI 10.1007/s11042-019-7592-6
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400067
DA 2024-07-18
ER

PT J
AU Zakraoui, J
   Saleh, M
   Al Ja'am, J
AF Zakraoui, Jezia
   Saleh, Moutaz
   Al Ja'am, Jihad
TI Text-to-picture tools, systems, and approaches: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text-to-picture systems; Natural language processing; Natural language
   understanding; Text illustration; Text visualization; Multimedia
AB Text-to-picture systems attempt to facilitate high-level, user-friendly communication between humans and computers while promoting understanding of natural language. These systems interpret a natural language text and transform it into a visual format as pictures or images that are either static or dynamic. In this paper, we aim to identify current difficulties and the main problems faced by prior systems, and in particular, we seek to investigate the feasibility of automatic visualization of Arabic story text through multimedia. Hence, we analyzed a number of well-known text-to-picture systems, tools, and approaches. We showed their constituent steps, such as knowledge extraction, mapping, and image layout, as well as their performance and limitations. We also compared these systems based on a set of criteria, mainly natural language processing, natural language understanding, and input/output modalities. Our survey showed that currently emerging techniques in natural language processing tools and computer vision have made promising advances in analyzing general text and understanding images and videos. Furthermore, important remarks and findings have been deduced from these prior works, which would help in developing an effective text-to-picture system for learning and educational purposes.
C1 [Zakraoui, Jezia; Saleh, Moutaz; Al Ja'am, Jihad] Qatar Univ, Coll Engn, Dept Comp Sci & Engn, Doha, Qatar.
C3 Qatar University
RP Al Ja'am, J (corresponding author), Qatar Univ, Coll Engn, Dept Comp Sci & Engn, Doha, Qatar.
EM jaam@qu.edu.qa
RI Saleh, Moutaz/R-7449-2018
OI Saleh, Moutaz/0000-0002-6434-1790
FU Qatar National Library
FX Open Access funding provided by the Qatar National Library.
CR Adorni G, 1984, P 10 INT C COMP LING
   Agrawal R., 2011, P 20 ACM INT C INF K
   Alami N, 2018, ARAB J SCI ENG, V43, P7803, DOI 10.1007/s13369-018-3198-y
   [Anonymous], P NIPS 2009 S ASS MA
   [Anonymous], 2014, P 9 INT C LANG RES E
   [Anonymous], 2016, ARXIV E PRINTS
   [Anonymous], 2004, P 2004 C EMP METH NA
   [Anonymous], IEEE TPMAI
   [Anonymous], 2004, P 6 ACM SIGMM INT WO
   Bernardi R, 2016, AUTOMATIC DESCRIPTIO
   Bobick AF, 1999, PRESENCE-VIRTUAL AUG, V8, P369, DOI 10.1162/105474699566297
   Boonpa SRS, 2017, 2 INT C INF TECHN IN
   Bui Duy, 2012, AMIA Annu Symp Proc, V2012, P1158
   Carney RN, 2002, J R ED PSYCHOL REV
   Chong W, 2009, IEEE C COMP VIS PATT
   Coelho F, 2011, CONTENT BASED MULTIM
   Coyne B, 2001, P 28 ANN C COMP GRAP
   Csomai A, 2007, P 2007 C ART INT ED
   Delgado D, 2010, P 2010 IEEE 4 INT C
   Dmitry U, 2012, P 2 INT WORKSH CONC
   Dmitry U, 2012, P 6 RUSS YOUNG SCI C
   Dupuy S., 2001, WORKSH TEMP SPAT INF
   Elhoseiny M, 2015, MULTIMEDIA TOOLS APP
   Eunice MM, 2006, AUTOMATIC CONVERSION
   Ganguly D, 2015, FIRE
   Goldberg A, 2008, P 12 C COMP NAT LANG
   Hanser E, 2009, ANN C ART INT
   Hanser E., 2010, P NAACL HLT 2010 WOR
   Hassani K, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2932710
   Huimei H, 2018, INF SCI, V477, P448
   Jain P, 2014, P 2014 4 INT C COMM
   Jiang Y, 2016, MULTIMEDIA SYST, V22, P5, DOI 10.1007/s00530-014-0371-3
   Joshi D, 2006, ACM T MULTIM COMPUT, V2, P68, DOI 10.1145/1126004.1126008
   Kastner M, 2018, MULTIMED TOOLS APPL
   Larson C, 1999, INTERACTIVE STORYTEL
   Li H, 2008, MM 08 P 2008 ACM INT
   Li J, 2000, P 8 ACM INT C MULT
   Lin PH, 2018, IEEE ACCESS, V6, P63416, DOI 10.1109/ACCESS.2018.2875675
   Ma M, 2005, NATURAL LANGUAGE PRO
   Ma ME, 2002, TECHNICAL REPORT
   Ma YC, 2019, MULTIMED TOOLS APPL, V78, P3767, DOI 10.1007/s11042-018-6038-x
   MacCartney B, 2014, ACI SIGAI BAY AR CHA
   Mahmood A, 2017, IEEE ACCESS
   Mihalcea R, 2008, MACH TRANSL, V22, P153, DOI 10.1007/s10590-009-9050-0
   Mihalcea Rada, 2007, P 16 ACM C C INF KNO
   Milne D, 2010, APPL WIKIPEDIA INTER
   Moawad I, 2018, ARAB J SCI ENG, V43, P7705, DOI 10.1007/s13369-018-3145-y
   Mwiny M, 2013, UNDERSTANDING SIMPLE
   Na L, 2018, MULTIMED TOOLS APPL, P1
   Poots J. K., 2017, BIG DATA INF ANAL, V2, P97, DOI DOI 10.3934/BDIA.2017001
   Poots JK, 2018, IT PROF, V20, P36, DOI 10.1109/MITP.2018.011291354
   Poots JK, 2017, 1 STEPS INVESTIGATIO
   Ruan W, 2018, IEEE INT CONF COMP
   Sampath H., 2010, ACM Sigaccess Accessibility and Computing, P32
   Shan M.-K, 2013, P 2013 C TECHN APPL
   Sumi K., 2006, P 2006 ACM SIGCHI IN
   Talsania A, 2015, P WORKSH 7 FOR INF R
   Wang Z., 2014, ACM Trans. Multimedia Comput. Commun. Appl. (TOMM), V10, P1
   Yamada A., 1992, COLING 1992
   Zhu XF, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0001244
NR 60
TC 8
Z9 8
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22833
EP 22859
DI 10.1007/s11042-019-7541-4
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400030
OA hybrid
DA 2024-07-18
ER

PT J
AU Deng, YY
   Tang, F
   Dong, WM
   Wu, FZ
   Deussen, O
   Xu, CS
AF Deng, Yingying
   Tang, Fan
   Dong, Weiming
   Wu, Fuzhang
   Deussen, Oliver
   Xu, Changsheng
TI Selective clustering for representative paintings selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital arts analysis; Pattern mining; Rejection mechanism; Deep feature
   representation
ID REJECT OPTION; CLASSIFICATION; STYLE
AB Selective classification (or rejection based classification) has been proved useful in many applications. In this paper we describe a selective clustering framework with reject option to carry out large-scale digital arts analysis. With the help of deep learning techniques, we extract content-style features from a pre-trained convolutional network for the paintings. By proposing a rejection mechanism under Bayesian framework, we focus on selecting style-oriented representative paintings of an artist, which is an interesting and challenging cultural heritage application. Two kinds of samples are rejected during the rejection based robust continuous clustering process. Representative paintings are selected during the selective clustering phase. Visual qualitative analysis on small painting set and large scale quantitative experiments on a subset of Wikiart show that the proposed rejection based selective clustering approach outperforms the standard clustering methods.
C1 [Deng, Yingying; Tang, Fan; Dong, Weiming; Xu, Changsheng] Chinese Acad Sci, Inst Automat, NLPR LIAMA, Beijing, Peoples R China.
   [Deng, Yingying; Tang, Fan] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Wu, Fuzhang] Chinese Acad Sci, Inst Software, Beijing, Peoples R China.
   [Deng, Yingying; Tang, Fan; Deussen, Oliver] Univ Konstanz, Constance, Germany.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS;
   Chinese Academy of Sciences; Institute of Software, CAS; University of
   Konstanz
RP Dong, WM (corresponding author), Chinese Acad Sci, Inst Automat, NLPR LIAMA, Beijing, Peoples R China.
EM weiming.dong@ia.ac.cn; oliver.deussen@uni-konstanz.de;
   changsheng.xu@ia.ac.cn
RI Xu, Chang/GQP-7280-2022; DONG, Weiming/AAG-7678-2020; Deussen,
   Oliver/HKF-2004-2023; xu, cj/HJZ-3488-2023; Tang, Fan/O-3923-2018
OI DONG, Weiming/0000-0001-6502-145X; Tang, Fan/0000-0002-3975-2483
FU National Natural Science Foundation of China [61832016, 61672520,
   61702488]; National Laboratory of Pattern Recognition
FX This work was supported by National Natural Science Foundation of China
   under nos. 61832016, 61672520 and 61702488, as well as the independent
   research project of National Laboratory of Pattern Recognition.
CR [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], 2016, P 24 ACM INT C MULT
   Arora RS, 2012, INT C PATT RECOG, P3541
   Bartlett PL, 2008, J MACH LEARN RES, V9, P1823
   Chen CC, 2002, REPORT OF THE DELOS
   Doersch C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185597
   Dumoulin V, 2017, ARXIV 1610 07629
   Dumoulin V.., 2017, P INT C LEARN REPR I
   FIEDLER M, 1973, CZECH MATH J, V23, P298
   Fumera G, 2000, PATTERN RECOGN, V33, P2099, DOI 10.1016/S0031-3203(00)00059-5
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Geifman Y, 2017, ADV NEUR IN, V30
   Golge Eren, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P43, DOI 10.1109/CVPRW.2015.7301353
   Grandvalet Yves, 2009, Advances in Neural Information Processing Systems, P537
   Herbei R, 2006, CAN J STAT, V34, P709, DOI 10.1002/cjs.5550340410
   Hicsonmez S, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P343, DOI 10.1145/3078971.3078982
   Hu RZ, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3092817
   Hughes JM, 2010, P NATL ACAD SCI USA, V107, P1279, DOI 10.1073/pnas.0910530107
   Jain A, 2013, PROC CVPR IEEE, P2571, DOI 10.1109/CVPR.2013.332
   Jangtjik KA, 2016, P 24 ACM INT C MULT, P635, DOI DOI 10.1145/2964284.2967299
   Karmakar B, 2018, INFORM SCIENCES, V430, P444, DOI 10.1016/j.ins.2017.11.061
   Karypis G, 1999, COMPUTER, V32, P68, DOI 10.1109/2.781637
   Kim D, 2014, SCI REP, V4, P7370
   Li QW, 2017, IEEE T SIGNAL PROCES, V65, P1068, DOI 10.1109/TSP.2016.2630038
   Li Y, 2017, INT J COMPUT VISION, V121, P344, DOI 10.1007/s11263-016-0945-y
   Liao J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073683
   Liu GW, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2162
   Ma DQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1174, DOI 10.1145/3123266.3123325
   Macqueen J., 1965, Proc of Berkeley Symposium on Mathematical Statistics Probability, P281
   Mao H, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1183, DOI 10.1145/3123266.3123405
   PUDIL P, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P92, DOI 10.1109/ICPR.1992.201729
   Rodriguez A, 2014, SCIENCE, V344, P1492, DOI 10.1126/science.1242072
   Sartori A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P311, DOI 10.1145/2733373.2806250
   Sartori A, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2503
   Shah SA, 2017, P NATL ACAD SCI USA, V114, P9814, DOI 10.1073/pnas.1700770114
   Shamir L, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1670671.1670672
   Shen JL, 2009, PATTERN RECOGN, V42, P293, DOI 10.1016/j.patcog.2008.04.016
   Soltanolkotabi M, 2014, ANN STAT, V42, P669, DOI 10.1214/13-AOS1199
   Srivastava A, 2016, ICML WORKSHOP ON HUM
   Tax DMJ, 2008, PATTERN RECOGN LETT, V29, P1565, DOI 10.1016/j.patrec.2008.03.010
   Taylor RP, 1999, NATURE, V399, P422, DOI 10.1038/20833
   van Noord N, 2015, IEEE SIGNAL PROC MAG, V32, P46, DOI 10.1109/MSP.2015.2406955
   Zhang K, 2012, LEONARDO, V45, P243, DOI 10.1162/LEON_a_00366
   Zhang XW, 2012, INT CONF DAT MIN WOR, P194, DOI 10.1109/ICDMW.2012.167
NR 44
TC 9
Z9 9
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19305
EP 19323
DI 10.1007/s11042-019-7271-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800017
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Mukherjee, S
   Sanyal, G
AF Mukherjee, Srilekha
   Sanyal, Goutam
TI A physical equation based image steganography with electro-magnetic
   embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Motion scrambling; Electro-magnetic insertion; Peak
   signal to noise ratio (PSNR); Structural similarity index measure (SSIM)
ID ENCRYPTION SCHEME; CHAOS; OPTIMIZATION; TRANSFORM
AB Steganography is adjudged to be a boon in the field of global conveyance of sensitive information. In this paper, a novel approach is proffered where all the ensued methods are epitomized in the dimensions of physics. The cardinal aim is to promote data hiding in terms of the explicit arena of applicability concerning physics. The initial step proceeds with the application of Motion Scrambling procedure. This is done by customizing the Power Modulus Scrambling (PMS) method in such a way that it uses some of the illustrious conventions from physics to procreate unique focal values. These values, in turn administer the scrambling methodology. The Electro-magnetic insertion technique then exerts specific salient formulations that efficaciously aid and expedite the mechanism of infusing secret bits. All the principles from the physics domain are elected with discreet observation. The followed experimental results show moderate competence and adeptness of the proposed work in terms of distinct benchmarking metrics, both quantitative and qualitative.
C1 [Mukherjee, Srilekha; Sanyal, Goutam] Natl Inst Technol Durgapur, Dept Comp Sci & Engn, Durgapur, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Durgapur
RP Mukherjee, S (corresponding author), Natl Inst Technol Durgapur, Dept Comp Sci & Engn, Durgapur, India.
EM srilekha.mukherjee3@gmail.com
RI Mukherjee, Srilekha/ABA-7026-2020; SANYAL, GOUTAM/AAI-6613-2020
CR Almohammad A, 2010, INT C IM PROC THEOR
   Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   [Anonymous], INT J COMPUT INFORM
   [Anonymous], 2004, IEEE INT C IND INF B
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Banerjee I, 2013, PROC TECH, V10, P157, DOI 10.1016/j.protcy.2013.12.348
   Bansal R, 2017, MULTIMED TOOLS APPL, V76, P16529, DOI 10.1007/s11042-016-3926-9
   Bao L, 2017, IEEE T IMAGE PROCESS, V26, P5618, DOI 10.1109/TIP.2017.2738561
   Bhattacharyya S, 2012, INT J APPL INFORM SY
   Chandramouli R., 2003, International Workshop on Digital Watermarking, P35
   Chang KC, 2008, J MULTIMED, V3, P37, DOI DOI 10.4304/JMM.3.3.26-33
   Dukkipati A, 2012, APPL MATH COMPUT, V218, P11674, DOI 10.1016/j.amc.2012.05.052
   Egiazarian Karen O., 2010, P SOC PHOTO-OPT INS, V7532
   El-Alfy El-Sayed M., 2011, 2011 9th IEEE/ACS International Conference on Computer Systems and Applications (AICCSA), P144, DOI 10.1109/AICCSA.2011.6126588
   Feng JH, 2017, MULTIMED TOOLS APPL, V76, P17405, DOI 10.1007/s11042-016-3907-z
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Hansen BE, 2015, ECONOMET THEOR, V31, P337, DOI 10.1017/S0266466614000322
   He JH, 2017, MULTIMED TOOLS APPL, V76, P7677, DOI 10.1007/s11042-016-3429-8
   Hiary H, 2016, INT J ADV COMPUT SC, V7, P374
   Jain R., 2012, INT J ENG SCI TECHNO, V4, P3908
   Kanan HR, 2014, EXPERT SYST APPL, V41, P6123, DOI 10.1016/j.eswa.2014.04.022
   Khalifa O.O., 2008, SPIJ, V2, P17
   Koo HI, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013020
   Li JZ, 2018, MULTIMED TOOLS APPL, V77, P4545, DOI 10.1007/s11042-017-4452-0
   Li QH, 2016, J COMPUT SCI TECH-CH, V31, P225, DOI 10.1007/s11390-016-1623-9
   Liang H, 2016, ACTA POLYM SIN, P1383, DOI 10.11777/j.issn1000-3304.2016.16032
   Luo WQ, 2011, MULTIMED TOOLS APPL, V52, P407, DOI 10.1007/s11042-009-0440-3
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P18985, DOI 10.1007/s11042-017-4420-8
   Mukherjee Srilekha, 2017, International Journal of Computers and Applications, V39, P59, DOI 10.1080/1206212X.2016.1273624
   Mukherjee S, 2015, COMPUTING SUSTAINABL
   MUKHERJEE S, 2015, TENCON IEEE REGION, pN1582
   Mukherjee S, 2015, INT J COMPUTER CONTR, V9
   Mukherjee S, 2018, MULTIMED TOOLS APPL, V77, P27851, DOI 10.1007/s11042-018-5996-3
   Mukherjee S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P406, DOI 10.1109/ICRCICN.2015.7434273
   Phad Vilthal S., 2012, INT J COMPUTER NETWO, V2, P36
   Safarpour M, 2016, 160100299 CORRABS
   Soleymani SH, 2017, MULTIMED TOOLS APPL, V76, P20847, DOI 10.1007/s11042-016-4009-7
   Tomar G, 2012, IOSR J ENG, V2, P473, DOI DOI 10.9790/3021-0203473477
   Wang G, 2017, MULTIMED TOOLS APPL, V76, P9427, DOI 10.1007/s11042-016-3549-1
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu Xue, 2013, Journal of Networks, V8, P1673, DOI 10.4304/jnw.8.7.1673-1679
   Yang CH, 2008, IEEE T INF FOREN SEC, V3, P488, DOI 10.1109/TIFS.2008.926097
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
NR 44
TC 1
Z9 1
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18571
EP 18593
DI 10.1007/s11042-019-7239-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200055
DA 2024-07-18
ER

PT J
AU Luque-Suárez, F
   Camarena-Ibarrola, A
   Chávez, E
AF Luque-Suarez, Fernando
   Camarena-Ibarrola, Antonio
   Chavez, Edgar
TI Efficient speaker identification using spectral entropy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speaker recognition; Speaker identification; Entropygrams
ID RECOGNITION
AB In voice recognition, the two main problems are speech recognition (what was said), and speaker recognition (who was speaking). The usual method for speaker recognition is to postulate a model where the speaker identity corresponds to the parameters of the model, which estimation could be time-consuming when the number of candidate speakers is large. In this paper, we model the speaker as a high dimensional point cloud of entropy-based features, extracted from the speech signal. The method allows indexing, and hence it can manage large databases. We experimentally assessed the quality of the identification with a publicly available database formed by extracting audio from a collection of YouTube videos of 1,000 different speakers. With 20 second audio excerpts, we were able to identify a speaker with 97% accuracy when the recording environment is not controlled, and with 99% accuracy for controlled recording environments.
C1 [Luque-Suarez, Fernando; Chavez, Edgar] CICESE, Ensenada, Baja California, Mexico.
   [Camarena-Ibarrola, Antonio] Univ Michoacana, Morelia, Michoacan, Mexico.
C3 CICESE - Centro de Investigacion Cientifica y de Educacion Superior de
   Ensenada; Universidad Michoacana de San Nicolas de Hidalgo
RP Luque-Suárez, F (corresponding author), CICESE, Ensenada, Baja California, Mexico.
EM fluque@cicese.edu.mx; camarena@umich.mx; elchavez@cicese.mx
RI Chavez, Edgar/M-4162-2019
OI Chavez, Edgar/0000-0002-0148-695X
CR Beltrán J, 2015, PATTERN RECOGN LETT, V68, P153, DOI 10.1016/j.patrec.2015.08.027
   Bernhardsson E., ANNOY APPROXIMATE NE
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Greenberg C. S., 2014, ODYSSEY, P224
   Hansen JHL, 2015, IEEE SIGNAL PROC MAG, V32, P74, DOI 10.1109/MSP.2015.2462851
   Kenny P., 2005, CRIM060813, P1
   Kenny P, 2003, INTERNAL REPORT, P1
   Kinnunen T, 2010, SPEECH COMMUN, V52, P12, DOI 10.1016/j.specom.2009.08.009
   Kulis B, 2012, IEEE T PATTERN ANAL, V34, P1092, DOI 10.1109/TPAMI.2011.219
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Ludwig Schmidt I.L. M., 2014, IEEE International Conference on Acoustic, Speech and Signal Processing (ICASSP), V4, P1669
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Snyder D, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P92, DOI 10.1109/ASRU.2015.7404779
   UHLMANN JK, 1991, INFORM PROCESS LETT, V40, P175, DOI 10.1016/0020-0190(91)90074-R
   YIANILOS PN, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P311
NR 17
TC 6
Z9 6
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16803
EP 16815
DI 10.1007/s11042-018-7035-9
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500047
DA 2024-07-18
ER

PT J
AU Mohanty, F
   Rup, S
   Dash, B
   Majhi, B
   Swamy, MNS
AF Mohanty, Figlu
   Rup, Suvendu
   Dash, Bodhisattva
   Majhi, Banshidhar
   Swamy, M. N. S.
TI Mammogram classification using contourlet features with forest
   optimization-based feature selection approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mammograms; Computer-aided diagnosis (CAD); Contourlet transform (CT);
   Forest optimization algorithm (FOA); Matthew's correlation coefficient
   (MCC); Area under curve (AUC)
ID FEATURE-EXTRACTION METHOD; COMPUTER-AIDED DETECTION; BREAST-CANCER;
   TRANSFORM; DIAGNOSIS; IMAGES; MASSES; SYSTEM
AB Breast cancer continues to be one of the major health issues across the world and it is mostly observed in females. However, the actual cause of this cancer is still an ongoing research topic. Hence, early detection and diagnosis of breast cancer are considered to be an effective and reliable solution. Mammography is one of the most efficacious medical tools for early detection of breast cancer. The radiologists identify the suspicious regions in the breast by carefully examining the mammograms. However, mammograms are sometimes difficult to analyze when the breast tissues are dense. Therefore, a computer-aided diagnosis (CAD) system is adopted which can improve the decisions of the radiologists. This paper proposes a hybrid CAD framework to classify the suspicious regions into either normal or abnormal, and further, benign or malignant. The proposed framework constitutes four computational modules, namely, ROI generation using cropping operation, texture feature extraction using contourlet transformation, a wrapper-based feature selection algorithm, namely, forest optimization algorithm to select the optimal features, and finally different classifiers like SVM, k-NN, Naive Bayes, and C4.5 that are employed to classify the inputs into normal or abnormal, and again benign or malignant. The proposed framework is examined on two widely used standard datasets, namely, MIAS and DDSM. The performance measures are computed with respect to normal vs. abnormal, and benign vs. malignant for four different hybrid CAD models, namely, (Contourlet + FOA + SVM), (Contourlet + FOA + k-NN), (Contourlet + FOA + Naive Bayes), and (Contourlet + FOA + C4.5). The highest classification accuracy of 100% is achieved for normal vs. abnormal classification in case of both MIAS and DDSM. The performance of the proposed hybrid scheme demonstrates its effectiveness with the other state-of-the-art schemes. Experimental results reveal that the proposed hybrid scheme is accurate and robust. Finally, the suggested scheme is considered as a reliable CAD framework to help the physicians for better diagnosis.
C1 [Mohanty, Figlu; Rup, Suvendu; Dash, Bodhisattva] Int Inst Informat Technol, Image & Video Proc Lab, Dept Comp Sci & Engn, Bhubaneswar 751003, Odisha, India.
   [Majhi, Banshidhar] Natl Inst Technol, Pattern Recognit Res Lab, Dept Comp Sci & Engn, Rourkela 769004, India.
   [Swamy, M. N. S.] Concordia Univ, Dept Elect & Comp Engn, Ctr Signal Proc & Commun, Montreal, PQ, Canada.
C3 International Institute of Information Technology, Bhubaneswar; National
   Institute of Technology (NIT System); National Institute of Technology
   Rourkela; Concordia University - Canada
RP Mohanty, F (corresponding author), Int Inst Informat Technol, Image & Video Proc Lab, Dept Comp Sci & Engn, Bhubaneswar 751003, Odisha, India.
EM figlu92@gmail.com
RI Rup, Suvendu/AAQ-6535-2021
OI Rup, Suvendu/0000-0002-9407-0469
CR AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470
   [Anonymous], 1993, MORGAN KAUFMANN SERI
   [Anonymous], 2010, IE I J
   [Anonymous], IJCAI 2001 WORKSHOP
   [Anonymous], 2013, INT AGENCY RES CANC
   [Anonymous], 2000, P 5 INT WORKSH DIG M
   Azar AT, 2013, NEURAL COMPUT APPL, V23, P1019, DOI 10.1007/s00521-012-1026-y
   BAMBERGER RH, 1992, IEEE T SIGNAL PROCES, V40, P882, DOI 10.1109/78.127960
   Berlin L, 2014, DIAGNOSIS, V1, P79, DOI 10.1515/dx-2013-0012
   Berraho S, 2017, MULTIMED TOOLS APPL, V76, P18425, DOI 10.1007/s11042-016-4174-8
   Beura S, 2015, NEUROCOMPUTING, V154, P1, DOI 10.1016/j.neucom.2014.12.032
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   de Lima SML, 2016, COMPUT METH PROG BIO, V134, P11, DOI 10.1016/j.cmpb.2016.04.029
   Dheeba J, 2014, J BIOMED INFORM, V49, P45, DOI 10.1016/j.jbi.2014.01.010
   Do M.N., 2002, Tech. Rep
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   do Nascimento MZ, 2013, EXPERT SYST APPL, V40, P6213, DOI 10.1016/j.eswa.2013.04.036
   El-Naqa I, 2002, IEEE T MED IMAGING, V21, P1552, DOI 10.1109/TMI.2002.806569
   Eltoukhy MM, 2012, COMPUT BIOL MED, V42, P123, DOI 10.1016/j.compbiomed.2011.10.016
   Fu JC, 2005, COMPUT MED IMAG GRAP, V29, P419, DOI 10.1016/j.compmedimag.2005.03.002
   Gedik N, 2016, APPL SOFT COMPUT, V44, P128, DOI 10.1016/j.asoc.2016.04.004
   Ghaemi M, 2016, PATTERN RECOGN, V60, P121, DOI 10.1016/j.patcog.2016.05.012
   Ghaemi M, 2014, EXPERT SYST APPL, V41, P6676, DOI 10.1016/j.eswa.2014.05.009
   Guo YN, 2016, COMPUT METH PROG BIO, V130, P31, DOI 10.1016/j.cmpb.2016.02.019
   Gupta S, 2006, MED PHYS, V33, P1810, DOI 10.1118/1.2188080
   Jona J. B., 2012, WSEAS Transactions on Information Science and Applications, V9, P340
   MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9
   Mohamed H, 2014, COMPUT METH PROG BIO, V116, P226, DOI 10.1016/j.cmpb.2014.04.010
   Pawar MM., 2016, PERSPECTIVESCI, V8, P247, DOI [DOI 10.1016/J.PISC.2016.04.042, 10.1016/j.pisc.2016.04.042]
   Phadke AC, 2016, SADHANA-ACAD P ENG S, V41, P385, DOI 10.1007/s12046-016-0482-y
   Rouhi R, 2015, EXPERT SYST APPL, V42, P990, DOI 10.1016/j.eswa.2014.09.020
   Roy D, 2015, IEEE IJCNN
   Siegel RL, 2015, CANC STAT 2015 CA CA, V65, p1 5 29
   SUCKLING J, 1994, INT CONGR SER, V1069, P375
   Verma B, 2001, IEEE T INF TECHNOL B, V5, P46, DOI 10.1109/4233.908389
   VETTERLI M, 1984, SIGNAL PROCESS, V6, P97, DOI 10.1016/0165-1684(84)90012-4
   Xie WY, 2016, NEUROCOMPUTING, V173, P930, DOI 10.1016/j.neucom.2015.08.048
   Zyout I, 2015, COMPUT MED IMAG GRAP, V46, P95, DOI 10.1016/j.compmedimag.2015.02.005
NR 38
TC 40
Z9 41
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 12805
EP 12834
DI 10.1007/s11042-018-5804-0
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900008
DA 2024-07-18
ER

PT J
AU Shahdoosti, HR
   Hazavei, SM
AF Shahdoosti, Hamid Reza
   Hazavei, Seyede Mahya
TI A new compressive sensing based image denoising method using
   block-matching and sparse representations over learned dictionaries
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Block-matching; Compressive sensing; Dictionary
   learning; Sparse representation
ID SHRINKAGE; ALGORITHM; FUSION; FILTER
AB Suppressing noise and preserving detail information such as edges and textures are two key challenges in image denoising. In this paper, a new method for eliminating noise from images is presented which is based on not only compressive sensing but also sparse and redundant representations over trained dictionaries. The objective function of the proposed technique consists of two terms. The first term processes the noisy image by the hard thresholding operator in the bandelet domain to provide the noise-free image as well as guaranteeing the similarity between the denoised image and the noisy image, while the second term ensures that the image admits a sparse decomposition in a dictionary. In addition, the proposed method takes advantage of the block-matching technique for representing the dictionary elements such that the noisy image is firstly grouped by the block-matching technique, and then an identical sparse vector is used for all patches in a group. Simulations using images contaminated by additive white Gaussian noise demonstrate that the performance of the proposed method considerably surpasses that of state-of-the-art methods, both visually and in terms of quantitative criteria, namely peak signal to noise ratio and structural similarity.
C1 [Shahdoosti, Hamid Reza; Hazavei, Seyede Mahya] Hamedan Univ Technol, Dept Elect Engn, Hamadan 65155, Iran.
RP Shahdoosti, HR (corresponding author), Hamedan Univ Technol, Dept Elect Engn, Hamadan 65155, Iran.
EM h.doosti@hut.ac.ir
RI Shahdoosti, Hamid/U-1005-2019
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], WAVELET TOUR SIGNAL
   [Anonymous], 1990, P IEEE, DOI DOI 10.1109/5.58325
   Balster EJ, 2005, IEEE T IMAGE PROCESS, V14, P2024, DOI 10.1109/TIP.2005.859385
   Bao BK, 2013, IEEE T IMAGE PROCESS, V22, P860, DOI 10.1109/TIP.2012.2219543
   Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P2992, DOI 10.1109/TIP.2007.909319
   Cai T., 2001, SANKHYA SER B, V63, P127
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Chen F, 2015, J VIS COMMUN IMAGE R, V30, P117, DOI 10.1016/j.jvcir.2015.03.005
   Coupé P, 2009, IEEE T IMAGE PROCESS, V18, P2221, DOI 10.1109/TIP.2009.2024064
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Durand S, 2003, SIAM J SCI COMPUT, V24, P1754, DOI 10.1137/S1064827501397792
   Easley GR, 2009, IEEE T IMAGE PROCESS, V18, P260, DOI 10.1109/TIP.2008.2008070
   Elad M, 2002, IEEE T IMAGE PROCESS, V11, P1141, DOI 10.1109/TIP.2002.801126
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Evers F.T., 1999, Fuzzy Cluster Analysis: Methods for Classification, Data Analysis and Image Recognition
   GERSHO A, 1982, IEEE T INFORM THEORY, V28, P157, DOI 10.1109/TIT.1982.1056457
   Guo ZC, 2012, IEEE T IMAGE PROCESS, V21, P958, DOI 10.1109/TIP.2011.2169272
   He KJ, 2018, IEEE ACCESS, V6, P32850, DOI 10.1109/ACCESS.2018.2845855
   Jin JQ, 2014, COMPUT GRAPH-UK, V38, P382, DOI 10.1016/j.cag.2013.11.011
   Kervrann C, 2006, IEEE T IMAGE PROCESS, V15, P2866, DOI 10.1109/TIP.2006.877529
   Le Pennec E, 2005, MULTISCALE MODEL SIM, V4, P992, DOI 10.1137/040619454
   Le Pennec E, 2005, IEEE T IMAGE PROCESS, V14, P423, DOI 10.1109/TIP.2005.843753
   Li HF, 2018, PATTERN RECOGN, V79, P130, DOI 10.1016/j.patcog.2018.02.005
   Liu J, 2016, SIGNAL PROCESS, V125, P64, DOI 10.1016/j.sigpro.2016.01.013
   Ma J, 2007, IEEE T IMAGE PROCESS, V16, P2198, DOI 10.1109/TIP.2007.902333
   PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465
   PEYRE G, 2007, WAVELETS XII, V6701
   Peyré G, 2010, IEEE T SIGNAL PROCES, V58, P2613, DOI 10.1109/TSP.2010.2042490
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Qu XB, 2007, CHIN OPT LETT, V5, P569
   Qu XB, 2012, MAGN RESON IMAGING, V30, P964, DOI 10.1016/j.mri.2012.02.019
   Ray S., 1999, PROC 4 INT C ADV PAT, P137
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Serra JG, 2017, IEEE T IMAGE PROCESS, V26, P3344, DOI 10.1109/TIP.2017.2681436
   Shahdoosti HR, 2018, MACH VISION APPL, V29, P689, DOI 10.1007/s00138-018-0929-8
   Shahdoosti HR, 2016, SIGNAL IMAGE VIDEO P, V10, P1081, DOI 10.1007/s11760-016-0862-0
   Shahdoosti HR, 2016, J INTELL FUZZY SYST, V30, P3087, DOI 10.3233/IFS-152035
   Shandoosti HR, 2017, DIGIT SIGNAL PROCESS, V67, P17, DOI 10.1016/j.dsp.2017.04.011
   Starck JL, 2007, IEEE T IMAGE PROCESS, V16, P297, DOI 10.1109/TIP.2006.887733
   Velisavljevic V, 2006, IEEE T IMAGE PROCESS, V15, P1916, DOI 10.1109/TIP.2006.877076
   Wang YT, 2017, IEEE T CIRC SYST VID, V27, P1895, DOI 10.1109/TCSVT.2016.2555740
   Wright A. H., 1991, FDN GENETIC ALGORITH, P205, DOI DOI 10.1016/B978-0-08-050684-5.50016-1
   Yang CL, 2013, PATTERN RECOGN, V46, P948, DOI 10.1016/j.patcog.2012.07.011
   Yang Y, 2014, CIRC SYST SIGNAL PR, V33, P3921, DOI 10.1007/s00034-014-9834-1
   Zhan ZF, 2016, IEEE T BIO-MED ENG, V63, P1850, DOI 10.1109/TBME.2015.2503756
   Zhou MY, 2012, IEEE T IMAGE PROCESS, V21, P130, DOI 10.1109/TIP.2011.2160072
NR 47
TC 9
Z9 9
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 12561
EP 12582
DI 10.1007/s11042-018-6818-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900066
DA 2024-07-18
ER

PT J
AU Tan, LN
   Hu, K
   Zhou, XM
   Chen, RY
   Jiang, WJ
AF Tan, Lina
   Hu, Kai
   Zhou, Xinmin
   Chen, Rongyuan
   Jiang, Weijin
TI Print-scan invariant text image watermarking for hardcopy document
   authentication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text image watermarking; Print-photocopy-scan; Print-scan invariant;
   Fourier descriptors
ID DATA HIDING SCHEME; BINARY IMAGES; ROBUST; LINES
AB In this paper, a novel contour feature-based text image watermarking scheme against print and scan processes is proposed. We employ a mathematical multiplicative transformation model to approximate the geometric invariant feature that can survive a variety of attacks during the print-scan process and thus serve as reference points for both watermark embedding and extraction. Based on the print-scan invariant, the boundary points of each character are flipped using Fourier descriptors with visual perception characteristics, so that the watermarks are embedded into the visually nonsignificant points. In the calculation process of the print-scan invariant, a certain text line serves as the benchmark line without affording additional characters for watermark adjustment. Thus, the hiding capacity is greatly improved. For the data detection, noise reduction and deskewing mechanisms are performed previously to compensate for the distortions caused by hardcopy. The watermark is then extracted by parity check of the invariant feature of connected components for soft authentication. The experimental results show that the proposed approach is not limited to a particular language, and has better robustness, watermark transparency as well as hiding capacity compared with some existing methods.
C1 [Tan, Lina; Zhou, Xinmin; Chen, Rongyuan; Jiang, Weijin] Hunan Univ Commerce, Key Lab Hunan Prov New Retail Virtual Real Techno, Changsha 410205, Hunan, Peoples R China.
   [Tan, Lina; Zhou, Xinmin; Chen, Rongyuan; Jiang, Weijin] Hunan Univ Commerce, Mobile E Business Collaborat Innovat Ctr Hunan Pr, Changsha 410205, Hunan, Peoples R China.
   [Hu, Kai] Xiangtan Univ, Key Lab Intelligent Comp & Informat Proc, Minist Educ, Xiangtan 411105, Peoples R China.
C3 Hunan University of Technology & Business; Hunan University of
   Technology & Business; Xiangtan University
RP Hu, K (corresponding author), Xiangtan Univ, Key Lab Intelligent Comp & Informat Proc, Minist Educ, Xiangtan 411105, Peoples R China.
EM kaihu@xtu.edu.cn
RI Rongyuan, Chen/F-5824-2010; hu, kai/HSG-5888-2023
OI Rongyuan, Chen/0000-0002-5355-976X; 
FU National Natural Science Foundation of China [61472136,
   61772196,61471170]; Scientific Research Project of Hunan Provincial
   Education Department for the Excellent Youth Scholars [16B142]; Key
   Project of Scientific Research Fund of Hunan Provincial Education
   Department [17A113, 16A114]; Hunan Provincial Natural Science Foundation
   of China [2016JJ2070]; Key Laboratory of Hunan Province for New Retail
   Virtual Reality Technology [2017TP1026]
FX This work was supported by the National Natural Science Foundation of
   China (Grants No. 61472136, 61772196,61471170), the Scientific Research
   Project of Hunan Provincial Education Department for the Excellent Youth
   Scholars (Grant No. 16B142), the Key Project of Scientific Research Fund
   of Hunan Provincial Education Department (Grants No. 17A113, 16A114),
   and the Hunan Provincial Natural Science Foundation of China (Grant No.
   2016JJ2070). The authors would like to thank the financial support
   provided by the Key Laboratory of Hunan Province for New Retail Virtual
   Reality Technology (2017TP1026). The authors would also like to thank
   the reviewers for their insightful comments, which have greatly helped
   to improve the quality of this paper.
CR Alotaibi RA, 2018, J KING SAUD UNIV-COM, V30, P236, DOI 10.1016/j.jksuci.2016.12.007
   Amiri SH, 2014, SIGNAL PROCESS-IMAGE, V29, P1181, DOI 10.1016/j.image.2014.07.004
   [Anonymous], 2012, P 20 ACM INT C MULTI
   Chen ZN, 2014, J COMPUT SCI TECH-CH, V29, P785, DOI 10.1007/s11390-014-1468-z
   Culnane C, 2008, IMPROVING MULTISET F
   Daraee F, 2014, PATTERN RECOGN LETT, V35, P120, DOI 10.1016/j.patrec.2013.04.022
   Fang S, 2017, MULTIMEDIA TOOLS APP, V76, P1
   González-Lee M., 2015, J. appl. res. technol, V13, P435
   Guo YF, 2016, SIGNAL PROCESS-IMAGE, V41, P85, DOI 10.1016/j.image.2015.12.002
   Huang D, 2001, IEEE T CIRC SYST VID, V11, P1237, DOI 10.1109/76.974678
   Jung KH, 2014, INFORM SCIENCES, V277, P188, DOI 10.1016/j.ins.2014.02.016
   Kim YW, 2004, PATTERN RECOGN LETT, V25, P1243, DOI 10.1016/j.patrec.2004.04.002
   Li CM, 2015, IEEE ICC, P7400, DOI 10.1109/ICC.2015.7249509
   Li RJ, 2006, I S INTELL SIG PROC, P684
   Liu N, 2017, IEEE T POWER SYST, V32, P3569, DOI 10.1109/TPWRS.2017.2649558
   Lu HP, 2004, IEEE SIGNAL PROC LET, V11, P228, DOI 10.1109/LSP.2003.821748
   [亓文法 QI Wenfa], 2008, [通信学报, Journal on Communications], V29, P183
   Sang JT, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/3001594
   Sang JT, 2012, IEEE T MULTIMEDIA, V14, P883, DOI 10.1109/TMM.2012.2188782
   Smith E. B., 2004, International Journal on Document Analysis and Recognition, V6, P146, DOI 10.1007/s10032-003-0117-9
   Solachidis V, 2004, IEEE COMPUT GRAPH, V24, P44, DOI 10.1109/MCG.2004.1297010
   Song YH, 2017, POLYMERS-BASEL, V9, DOI 10.3390/polym9010001
   SUGAI T, 2008, 70 CONV INF PROC SOC
   Tan LN, 2012, RADIOENGINEERING, V21, P170
   Varna AL, 2009, INT CONF ACOUST SPEE, P1397, DOI 10.1109/ICASSP.2009.4959854
   Villan R, 2006, SPIE IS T ELECT IMAG, V6072
   Wang CC, 2014, J SYST SOFTWARE, V93, P152, DOI 10.1016/j.jss.2014.02.023
   Wu M, 2004, IEEE T MULTIMEDIA, V6, P528, DOI 10.1109/tmm.2004.830814
   Wu NI, 2017, DISPLAYS, V49, P116, DOI 10.1016/j.displa.2017.07.009
   Xie HT, 2013, J VIS COMMUN IMAGE R, V24, P635, DOI 10.1016/j.jvcir.2013.04.012
   Yang HJ, 2008, IEEE T MULTIMEDIA, V10, P339, DOI 10.1109/TMM.2008.917404
NR 31
TC 12
Z9 16
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13189
EP 13211
DI 10.1007/s11042-018-5771-5
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900025
DA 2024-07-18
ER

PT J
AU Agarwal, N
   Singh, AK
   Singh, PK
AF Agarwal, Namita
   Singh, Amit Kumar
   Singh, Pradeep Kumar
TI Survey of robust and imperceptible watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Imperceptible; Robustness; Security; Capacity
ID DIGITAL IMAGE WATERMARKING; DISCRETE WAVELET TRANSFORM; SINGULAR-VALUE
   DECOMPOSITION; REVERSIBLE WATERMARKING; SPREAD-SPECTRUM; MULTIPLE
   WATERMARKING; HYBRID TECHNIQUE; DWT-SVD; SCHEME; ALGORITHM
AB Robustness, imperceptibility and embedding capacity are the preliminary requirements of any watermarking technique. However, research concluded that these requirements are difficult to achieve at same time. In this paper, we review various recent robust and imperceptible watermarking methods in spatial and transform domain. Further, the paper introduces elementary concepts of digital watermarking, characteristics and novel applications of watermark in detail. Furthermore, various analysis and comparison of different notable watermarking techniques are discussed in tabular format. We believe that our survey contribution will helpful for fledgling researchers to develop robust and imperceptible watermarking algorithms for various practical applications.
C1 [Agarwal, Namita; Singh, Pradeep Kumar] JUIT, Dept CSE & IT, Solan, HP, India.
   [Singh, Amit Kumar] NIT Patna, Dept CSE, Patna, Bihar, India.
C3 Jaypee University of Information Technology; National Institute of
   Technology (NIT System); National Institute of Technology Patna
RP Singh, AK (corresponding author), NIT Patna, Dept CSE, Patna, Bihar, India.
EM namita312@gmail.com; amit_245singh@yahoo.com; pradeep_84cs@yahoo.com
RI Singh, Pradeep Kumar/M-4363-2016; Singh, Amit Kumar/D-1300-2015
OI Singh, Pradeep Kumar/0000-0002-7676-9014; Singh, Amit
   Kumar/0000-0001-7359-2068
CR AL-Nabhani Y, 2015, J KING SAUD UNIV-COM, V27, P393, DOI 10.1016/j.jksuci.2015.02.002
   Ali M, 2018, INT J SYST ASSUR ENG, V9, P602, DOI 10.1007/s13198-014-0288-4
   Andalibi M, 2015, IEEE T IMAGE PROCESS, V24, P5060, DOI 10.1109/TIP.2015.2476961
   [Anonymous], J SYSTEMS SOFTWARE
   [Anonymous], 2013, INT J COMPUTER TECHN
   [Anonymous], THESIS
   [Anonymous], ELSEVIER
   [Anonymous], 2012, J SOFTW
   [Anonymous], TIP
   [Anonymous], IEEE INT S INT SIGN
   [Anonymous], MULTIRESOLUTION WATE
   [Anonymous], IEEE T INFORM FORENS
   [Anonymous], WIR COMM NETW MOB CO
   [Anonymous], INT J EMERG TRENDS E
   [Anonymous], SCIENCES
   [Anonymous], SECURITY
   [Anonymous], 2013, IOSR J COMPUTER ENG
   [Anonymous], INT J COMPUT SCI APP
   [Anonymous], INT J COMPUT ELECT E
   [Anonymous], ELSEVIER
   [Anonymous], MULTIMEDIA PROCESS
   [Anonymous], TIP
   [Anonymous], P 2004 WORKSH MULT S
   [Anonymous], INT J NETWORK SECURI
   [Anonymous], 2011, INT J COMPUT ELECT E, DOI DOI 10.7763/IJCEE.2011.V3.285
   [Anonymous], INT P COMP SCI INF T
   [Anonymous], 2014, 2014 10 INT C COMMUN
   [Anonymous], TSP
   [Anonymous], 1995, IEEE WORKSH NONL SIG
   [Anonymous], TSP
   [Anonymous], 2017, BOOK SERIES MULTIMED
   [Anonymous], 2016, IEEE T CIRC SYST VID, DOI [10.1109/TIFS.2016.2590944, DOI 10.1109/TIFS.2016.2590944]
   [Anonymous], SYMMETRY
   [Anonymous], P IEEE INT C IM PROC
   Aslantas V, 2008, AEU-INT J ELECTRON C, V62, P386, DOI 10.1016/j.aeue.2007.02.010
   Bhatnagar G, 2012, COMPUT SECUR, V31, P40, DOI 10.1016/j.cose.2011.11.003
   Bouslimi D, 2011, IEEE ENG MED BIO, P8066, DOI 10.1109/IEMBS.2011.6091989
   Celik MU, 2007, INT CONF ACOUST SPEE, P153
   Chang CC, 2002, INFORM SCIENCES, V141, P123, DOI 10.1016/S0020-0255(01)00194-3
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Chauhan DS, 2019, MULTIMED TOOLS APPL, V78, P3911, DOI 10.1007/s11042-017-4886-4
   Chen TS, 2013, J SUPERCOMPUT, V66, P907, DOI 10.1007/s11227-013-0926-7
   Coatrieux G, 2009, IEEE T INF TECHNOL B, V13, P158, DOI 10.1109/TITB.2008.2007199
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Deng C, 2010, SIGNAL PROCESS, V90, P3256, DOI 10.1016/j.sigpro.2010.05.032
   Dhole VS, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P752, DOI 10.1109/ICCUBEA.2015.150
   Dittmann J, 2001, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P60, DOI 10.1109/ITCC.2001.918766
   El'arbi M, 2014, IET IMAGE PROCESS, V8, P619, DOI 10.1049/iet-ipr.2013.0646
   Fan MQ, 2008, APPL MATH COMPUT, V203, P926, DOI 10.1016/j.amc.2008.05.003
   Fazli S, 2016, OPTIK, V127, P964, DOI 10.1016/j.ijleo.2015.09.205
   Feng LP, 2010, INT CONF COMP SCI, P455, DOI 10.1109/ICCSIT.2010.5565101
   Fung BCM, 2007, IEEE T KNOWL DATA EN, V19, P711, DOI 10.1109/TKDE.2007.1015
   Ganic E, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.2137650
   Gao XB, 2010, IEEE T SYST MAN CY C, V40, P278, DOI 10.1109/TSMCC.2009.2037512
   Ghafoor A., 2012, RADIOENGINEERING, V21, P1246
   Guorong Xuan, 2007, Digital Watermarking. Proceedings 6th International Workshop, IWDW 2007, P264
   Gupta AK, 2012, SADHANA-ACAD P ENG S, V37, P425, DOI 10.1007/s12046-012-0089-x
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Harish N., 2013, INT J ADV ELECT ELEC, V2, P137
   Hel-Or HZ, 2001, J ELECTRON IMAGING, V10, P794, DOI 10.1117/1.1382612
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Hongqin Shi, 2014, Journal of Software, V9, P1749, DOI 10.4304/jsw.9.7.1749-1756
   Iftikhar S, 2017, IEEE SYST J, V11, P197, DOI 10.1109/JSYST.2015.2416131
   Iftikhar S, 2015, IEEE T KNOWL DATA EN, V27, P1132, DOI 10.1109/TKDE.2014.2349911
   Jero SE, 2016, EXPERT SYST APPL, V49, P123, DOI 10.1016/j.eswa.2015.12.010
   Jero SE, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0132-z
   Jin C, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P71
   Kamran M, 2013, IEEE T INF FOREN SEC, V8, P1061, DOI 10.1109/TIFS.2013.2259234
   Kamran M, 2012, IEEE T KNOWL DATA EN, V24, P1950, DOI 10.1109/TKDE.2011.223
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Kapoor P., 2011, PROC INT C ADV COMPU, P20
   Khan Mohammad Ibrahim, 2013, INT J COMPUTER SCI I, V10, P223
   Kumar C, 2020, MULTIMED TOOLS APPL, V79, P11069, DOI 10.1007/s11042-018-6177-0
   Kumar C, 2018, MULTIMED TOOLS APPL, V77, P3597, DOI 10.1007/s11042-017-5222-8
   Kundur D, 1998, INT CONF ACOUST SPEE, P2969, DOI 10.1109/ICASSP.1998.678149
   Kutter M, 1997, P SOC PHOTO-OPT INS, V3022, P518, DOI 10.1117/12.263442
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Langelaar GC, 1997, P SOC PHOTO-OPT INS, V3022, P298, DOI 10.1117/12.263418
   Lee SH, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P105
   Li CT, 2003, J ELECTRON IMAGING, V12, P284, DOI 10.1117/1.1557156
   Li JZ, 2018, MULTIMED TOOLS APPL, V77, P4545, DOI 10.1007/s11042-017-4452-0
   Lin SD, 2010, COMPUT STAND INTER, V32, P54, DOI 10.1016/j.csi.2009.06.004
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Loukhaoukha K, 2014, OPTO-ELECTRON REV, V22, P45, DOI 10.2478/s11772-014-0177-z
   Mehta R, 2016, MULTIMED TOOLS APPL, V75, P4129, DOI 10.1007/s11042-015-3084-5
   Mohammad AA, 2008, SIGNAL PROCESS, V88, P2158, DOI 10.1016/j.sigpro.2008.02.015
   Mohanty SP, 2017, IEEE CONSUM ELECTR M, V6, P83, DOI 10.1109/MCE.2017.2684980
   Naderahmadian Yashar, 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P127, DOI 10.1109/IIHMSP.2010.39
   Najih A, 2017, J KING SAUD UNIV-COM, V29, P288, DOI 10.1016/j.jksuci.2016.02.005
   Nguyen TV, 2008, DIGIT SIGNAL PROCESS, V18, P762, DOI 10.1016/j.dsp.2007.10.004
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Noore A, 2004, COMPUT SECUR, V23, P679, DOI 10.1016/j.cose.2004.09.007
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P10599, DOI 10.1007/s11042-015-3127-y
   Patel S. B., 2011, Technol Research, V3, P81, DOI [10.1504/ijitst.2011.039680,2, DOI 10.1504/IJITST.2011.039680, DOI 10.1504/IJITST.2011.039680,2]
   Pei SC, 2003, IEEE T CIRC SYST VID, V13, P867, DOI 10.1109/TCSVT.2003.815943
   Peng H, 2010, J SYST SOFTWARE, V83, P1470, DOI 10.1016/j.jss.2010.03.006
   Rolland-Nevière X, 2014, IEEE IMAGE PROC, P4777, DOI 10.1109/ICIP.2014.7025968
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Senapati RK, 2014, IET IMAGE PROCESS, V8, P213, DOI 10.1049/iet-ipr.2012.0295
   Seo JS, 2004, PATTERN RECOGN, V37, P1365, DOI 10.1016/j.patcog.2003.12.013
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Shen JJ, 2010, DIGIT SIGNAL PROCESS, V20, P1408, DOI 10.1016/j.dsp.2009.10.015
   Shivani JLD, 2017, FUTURE INTERNET, V9, DOI 10.3390/fi9030033
   Singh A, 2012, INT J COMPUT APPL, V48, P9
   Singh Amit Kumar, 2018, Future Generation Computer Systems, V86, P926, DOI 10.1016/j.future.2016.11.023
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh AK, 2015, WIRELESS PERS COMMUN, V83, P2133, DOI 10.1007/s11277-015-2505-0
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P607, DOI 10.1166/jmihi.2015.1432
   Singh AK, 2014, NATL ACAD SCI LETT, V37, P351, DOI 10.1007/s40009-014-0241-8
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Song W, 2011, J CENT SOUTH UNIV T, V18, P116, DOI 10.1007/s11771-011-0668-8
   Su QT, 2013, OPTIK, V124, P6255, DOI 10.1016/j.ijleo.2013.05.013
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Thakur S, 2020, MULTIMED TOOLS APPL, V79, P4263, DOI 10.1007/s11042-018-6691-0
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Thodi DM, 2004, 6TH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P21, DOI 10.1109/IAI.2004.1300937
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Pham TD, 2015, LECT NOTES COMPUT SC, V9492, P69, DOI 10.1007/978-3-319-26561-2_9
   Duy TP, 2017, IEEE IJCNN, P4408, DOI 10.1109/IJCNN.2017.7966414
   Tsai HH, 2012, APPL SOFT COMPUT, V12, P2442, DOI 10.1016/j.asoc.2012.02.021
   Tsai JS, 2012, SIGNAL PROCESS, V92, P1431, DOI 10.1016/j.sigpro.2011.11.033
   Vacavant A, 2017, LECT NOTES COMPUT SC, V10214, P75, DOI 10.1007/978-3-319-56414-2_6
   Vander WD, 2003, Journal of Computational Methods in Sciences and Engineering, V3, P209
   Voloshynovskiy S, 2001, IEEE COMMUN MAG, V39, P118, DOI 10.1109/35.940053
   Wang HJM, 1998, OPT EXPRESS, V3, P491, DOI 10.1364/OE.3.000491
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wu HC, 2005, COMPUT SECUR, V24, P460, DOI 10.1016/j.cose.2005.05.001
   Wu XY, 2007, PHYS LETT A, V365, P403, DOI 10.1016/j.physleta.2007.01.034
   Xing Y, 2010, RADIOENGINEERING, V19, P62
   Xiong X., 2015, WORLD J ENG TECHNOL, V3, P177
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zheng ZG, 2018, FUTURE GENER COMP SY, V88, P92, DOI 10.1016/j.future.2018.05.027
   Zhi-Qiang Y, 2003, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P254
NR 137
TC 94
Z9 98
U1 4
U2 55
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8603
EP 8633
DI 10.1007/s11042-018-7128-5
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800039
DA 2024-07-18
ER

PT J
AU Cao, F
   An, BW
   Yao, H
   Tang, ZJ
AF Cao, Fang
   An, Bowen
   Yao, Heng
   Tang, Zhenjun
TI Local complexity based adaptive embedding mechanism for reversible data
   hiding in digital images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Prediction error expansion; Local complexity;
   Adaptive embedding; Hiding capacity; Image quality
ID WATERMARKING; EXPANSION; SCHEME
AB In this paper, a reversible data hiding scheme for digital images with high hiding capacity is proposed. Original image is segmented into smooth and rough regions based on local complexity. In order to achieve higher hiding capacity, we embed three bits into each pixel belonging to smooth region with lower local complexity and one bit is embedded into each pixel of rough region, which can effectively exploit more redundancy during data embedding compared with conventional methods of prediction error expansion (PEE). Additionally, the pixel selection mechanism is applied to reduce the number of shifted pixels, which leads to high visual quality of stego image. Experimental results show that, our scheme can achieve better rate-distortion performance than some of state-of-the-art schemes.
C1 [Cao, Fang; An, Bowen] Shanghai Maritime Univ, Coll Informat Engn, Shanghai 201306, Peoples R China.
   [Yao, Heng] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
   [Tang, Zhenjun] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
C3 Shanghai Maritime University; University of Shanghai for Science &
   Technology; Guangxi Normal University
RP Cao, F; An, BW (corresponding author), Shanghai Maritime Univ, Coll Informat Engn, Shanghai 201306, Peoples R China.
EM fangcao@shmtu.edu.cn; bwan@shmtu.edu.cn
RI Yao, Heng/J-9457-2019
OI Yao, Heng/0000-0002-3784-4157
FU National Natural Science Foundation of China [61171126, 61272452,
   61702332, U1636101, 61562007]; Ministry of Transport and Applied Basic
   Research Projects [2014329810060]; Science AMP; Technology Program of
   Shanghai Maritime University [20130479]; Natural Science Foundation of
   Guangxi [2017GXNSFAA198222]; Research Fund of Guangxi Key Lab of
   Multi-source Information Mining Security [MIMS15-03]
FX This work was supported by the National Natural Science Foundation of
   China (61171126, 61272452, 61702332, U1636101, 61562007), Ministry of
   Transport and Applied Basic Research Projects (2014329810060), and
   Science & Technology Program of Shanghai Maritime University (20130479),
   Natural Science Foundation of Guangxi (2017GXNSFAA198222), and Research
   Fund of Guangxi Key Lab of Multi-source Information Mining & Security
   (MIMS15-03).
CR [Anonymous], IEEE TRANS INF FOREN
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Fallahpour M, 2008, IEICE ELECTRON EXPR, V5, P870, DOI 10.1587/elex.5.870
   Hong W, 2016, KSII T INTERNET INF, V10, P2817, DOI 10.3837/tiis.2016.06.020
   Hong W, 2015, INFORM SCIENCES, V308, P140, DOI 10.1016/j.ins.2014.03.030
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   LI X, 1933, TIP, V20, P3524, DOI DOI 10.1109/TIP.2011.2150233
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   LIU JF, 2016, INF SCI, V59, P1
   Lu TC, 2017, MULTIMED TOOLS APPL, V76, P23903, DOI 10.1007/s11042-016-4135-2
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ma YY, 2019, IEEE T CIRC SYST VID, V29, P336, DOI 10.1109/TCSVT.2018.2799243
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Qin C, 2018, IEEE MULTIMEDIA, V25, P36, DOI 10.1109/MMUL.2018.112142509
   Qin C, 2018, INFORM SCIENCES, V423, P284, DOI 10.1016/j.ins.2017.09.060
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Qin C, 2016, INFORM SCIENCES, V361, P84, DOI 10.1016/j.ins.2016.04.036
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
NR 31
TC 11
Z9 11
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 7911
EP 7926
DI 10.1007/s11042-018-6031-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800003
OA Bronze
DA 2024-07-18
ER

PT J
AU El-Shafai, W
   El-Rabaie, EM
   Elhalawany, M
   Abd El-Samie, FE
AF El-Shafai, Walid
   El-Rabaie, EL-Sayed M.
   Elhalawany, Mohamed
   Abd El-Samie, Fathi E.
TI Improved joint algorithms for reliable wireless transmission of 3D
   color-plus-depth multi-view video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-view image retrieval; Depth estimation; Error resilience and
   concealment; Kalman filter; Disparity and motion compensation; Wireless
   networks
ID TEMPORAL ERROR CONCEALMENT; FRAME LOSS CONCEALMENT
AB Error control techniques like Error Resilience (ER) and Error Concealment (EC) are preferred techniques to ameliorate the lost Macro-Blocks (MBs) in the 3D Video (3DV) communication systems. In this paper, we present different enhanced ER-EC algorithms for intra-frame images for 3DV and Depth (3DV+D) communication through wireless networks. At the encoder, the slice structured coding, explicit flexible macro-block ordering, and context adaptive variable length coding are utilized. At the decoder, a hybrid approach comprising spatial circular scan order interpolation algorithm and temporal partitioning motion compensation algorithm is suggested to reconstruct the Disparity Vectors (DVs) and Motion Vectors (MVs) of the erroneous color images. For the corrupted depth images, a depth-assisted EC algorithm is proposed. Then, the optimum concealment MVs and DVs are chosen by employing the weighted overlapping block motion and disparity compensation algorithm. Furthermore, the Bayesian Kalman Filter (BKF) is utilized as an amelioration tool due to its efficiency to smooth the remnant inherent corruptions in the formerly optimally chosen color and depth DVs and MVs to obtain a good video quality. Simulation results on several 3DV streams show that the suggested algorithms have extremely adequate subjective and objective video quality performance compared to the traditional methods, particularly at high Packet Loss Rates (PLRs).
C1 [El-Shafai, Walid; El-Rabaie, EL-Sayed M.; Elhalawany, Mohamed; Abd El-Samie, Fathi E.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University
RP El-Shafai, W (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
EM eng.waled.elshafai@gmail.com; elsayedelrabaie@gmail.com;
   mmohamedelhalawany@gmail.com; fathi_sayed@yahoo.com
RI El-Shafai, Walid/AAG-4796-2021; Sayed, Fathi/HRA-4752-2023
OI El-Shafai, Walid/0000-0001-7509-2120; Sayed, Fathi/0000-0001-8749-9518;
   EL-Rabaie, El-Sayed/0000-0001-6854-5881
CR [Anonymous], JVTU207 ISOIEC JTC1, P1
   Assuncao P, 2016, MULTIMED TOOLS APPL, P1
   Chakareski J, 2013, IEEE COMMUN MAG, V51, P94, DOI 10.1109/MCOM.2013.6515052
   Chen MJ, 1997, IEEE T CIRC SYST VID, V7, P560, DOI 10.1109/76.585936
   Chung TY, 2011, IEEE T CONSUM ELECTR, V57, P1336, DOI 10.1109/TCE.2011.6018892
   Cui SH, 2014, SIGNAL IMAGE VIDEO P, V8, P1533, DOI 10.1007/s11760-012-0390-5
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   De Abreu A, 2015, IEEE J-STSP, V9, P487, DOI 10.1109/JSTSP.2015.2407320
   El Shafai W., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2201, DOI 10.1109/ICIP.2011.6116072
   El-Shafai, 2017, MULTIMED TOOLS APPL, V77, P1
   El-Shafai W, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0042-y
   El-Shafai W, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0064-5
   Gao J, 2007, PROCEEDINGS OF 2007 IEEE INTERNATIONAL CONFERENCE ON GREY SYSTEMS AND INTELLIGENT SERVICES, VOLS 1 AND 2, P1014
   Gao ZW, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 2, PROCEEDINGS, P69
   Hewage CTER, 2013, IEEE COMMUN MAG, V51, P101, DOI 10.1109/MCOM.2013.6515053
   Huo YK, 2013, IEEE T CIRC SYST VID, V23, P1622, DOI 10.1109/TCSVT.2013.2254911
   Hwang MC, 2008, IEEE T BROADCAST, V54, P198, DOI 10.1109/TBC.2008.917274
   Ibrahim Ahmed A., 2014, ICET 2014, P1
   Khattak S, 2016, IEEE T CIRC SYST VID, V26, P829, DOI 10.1109/TCSVT.2015.2418631
   Lee PJ, 2014, J DISP TECHNOL, V10, P560, DOI 10.1109/JDT.2014.2309988
   Lie WN, 2014, IEEE T MULTIMEDIA, V16, P216, DOI 10.1109/TMM.2013.2281587
   Liu J, 2012, 2012 IEEE 23RD INTERNATIONAL SYMPOSIUM ON PERSONAL INDOOR AND MOBILE RADIO COMMUNICATIONS (PIMRC), P2566, DOI 10.1109/PIMRC.2012.6362790
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu YQ, 2010, IEEE T CIRC SYST VID, V20, P600, DOI 10.1109/TCSVT.2009.2035838
   Liu Z, 2013, IEEE T CIRC SYST VID, V23, P1781, DOI 10.1109/TCSVT.2013.2269019
   Purica AI, 2016, IEEE T CIRC SYST VID, V26, P360, DOI 10.1109/TCSVT.2015.2389511
   Salim OH, 2013, 2013 IEEE WIRELESS COMMUNICATIONS AND NETWORKING CONFERENCE (WCNC), P4077
   Tai SC, 2016, MULTIMED TOOLS APPL, V75, P9927, DOI 10.1007/s11042-015-2899-4
   Wang H., 2016, MODELING OPTIMIZATIO, P1, DOI [10.1038/srep31509, DOI 10.1038/SREP31509]
   Xiang W, 2017, IEEE SYST J, V11, P2456, DOI 10.1109/JSYST.2015.2414662
   Yan B, 2012, IEEE T MULTIMEDIA, V14, P936, DOI 10.1109/TMM.2012.2184743
   Zeng HQ, 2014, IEEE T CIRC SYST VID, V24, P1566, DOI 10.1109/TCSVT.2014.2310143
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhou Y, 2015, IEEE SENS J, V15, P1892, DOI 10.1109/JSEN.2014.2366511
NR 36
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 9845
EP 9875
DI 10.1007/s11042-018-6440-4
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400016
DA 2024-07-18
ER

PT J
AU Huang, L
   Tan, WA
   Sun, Y
AF Huang, Li
   Tan, Wenan
   Sun, Yong
TI Collaborative recommendation algorithm based on probabilistic matrix
   factorization in probabilistic latent semantic analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Collaborative recommendation; Probabilistic latent semantic analysis;
   Probabilistic matrix factorization; Popularity factor; Semantic
   knowledge
AB In order to effectively solve the problem of new items and obviously improve the accuracy of the recommended results, we proposed a collaborative recommendation algorithm based on improved probabilistic latent semantic model in this paper, which introduces popularity factor into probabilistic latent semantic analysis to derive probabilistic matrix factorization model. The core idea is to integrate the semantic knowledge into the recommendation process to overcome the shortcomings of the traditional recommendation algorithm. We introduced popularity factor to form a quintuple vector so as to understand user preference, and can integrate the probabilistic matrix factorization to solve the problem of data sparsity on basis of Probabilistic Latent Semantic Analysis; then the probabilistic matrix factorization model is adopted to construct the weighted similarity function to compute the recommendation result. Experimental study on real-world data-sets demonstrates that our proposed method can outperform three state-of-the art methods in recommendation accuracy.
C1 [Huang, Li; Tan, Wenan] Nanjing Univ Aero & Astr, Sch Comp Sci & Technol, Nanjing 210016, Jiangsu, Peoples R China.
   [Huang, Li] Jiangsu Open Univ, Sch Informat & Electromech Engn, Nanjing 210017, Jiangsu, Peoples R China.
   [Tan, Wenan] Shanghai Second Polytech Univ Shanghai, Sch Comp & Informat Engn, Shanghai 210209, Peoples R China.
   [Sun, Yong] Chuzhou Univ, Coll Geog Informat & Tourism, Chuzhou 239000, Anhui, Peoples R China.
C3 Jiangsu Open University; Shanghai Polytechnic University; Chuzhou
   University
RP Tan, WA (corresponding author), Nanjing Univ Aero & Astr, Sch Comp Sci & Technol, Nanjing 210016, Jiangsu, Peoples R China.; Tan, WA (corresponding author), Shanghai Second Polytech Univ Shanghai, Sch Comp & Informat Engn, Shanghai 210209, Peoples R China.
EM huangli713@126.com; wtan@foxmail.com; ysun.nuaa@yahoo.com
OI Sun, Yong/0000-0001-7619-0363
CR [Anonymous], VIDEO ENG
   [Anonymous], TKDE
   Cantador I, 2011, INT J SEMANT WEB INF, V7, P44, DOI 10.4018/jswis.2011010103
   DuBois JG, 2011, PRIV SEC RISK TRUST, P418
   Kim HN, 2010, ELECTRON COMMER R A, V9, P73, DOI 10.1016/j.elerap.2009.08.004
   Lee JS, 2009, EXPERT SYST APPL, V36, P5353, DOI 10.1016/j.eswa.2008.06.106
   Liwei Liu, 2011, Proceedings of the 2011 IEEE International Conference on Web Services (ICWS 2011), P379, DOI 10.1109/ICWS.2011.71
   MIRANDAC JOR, 2009, P 14 PORT C ART INT, P673
   Oh HK, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P161
   Shambour Q., 2011, 2011 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies, P71, DOI 10.1109/WI-IAT.2011.109
   Su J.C, 2015, IEEE AS SOL STAT CIR, P1
   Tang A. Jiliang, 2016, 25 INT WORLD WID WEB, P31
   Tang D. Y. Jiliang, AAAI C ART INT AAAI, P251
   Tang Z, 2017, J PHYS C SERIES J PH
   Tasso C., 2012, P MENSCH COMP WORKSH, P75
   Toh K.-C., 2010, J OPTIM, V6, P15
   Wang KB, 2011, P 2 INT C ADV SWARM, P218
   Woolley AW, 2010, SCIENCE, V330, P686, DOI 10.1126/science.1193147
   Xu Bin, 2014, WWW 12, P21
   Yuan Ting, 2014, AAAI
   Zhang YF, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P313
NR 21
TC 24
Z9 25
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8711
EP 8722
DI 10.1007/s11042-018-6232-x
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800046
DA 2024-07-18
ER

PT J
AU Kumar, M
   Jindal, SR
AF Kumar, Munish
   Jindal, Simpel Rani
TI Fusion of RGB and HSV colour space for foggy image quality enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image enhancement; CLAHE; RGB; HSV; PSNR
AB The physical properties of water cause light-prompted degradation of foggy images. The light quickly loses intensity as it goes in the water, depending upon the shading range wavelength. Visible light is consumed at the longest wavelength first. Red and blue are the most and least absorbed, respectively. Foggy images with low contrast, are captured due to the degradation effects of the light spectrum. Therefore, valuable information from these images cannot be fully extracted for further processing. In this paper, the authors have proposed a new method to increase contrast and reduce the noise of foggy images using CLAHE (Contrast Limited Adaptive Histogram Equalization) algorithm. The proposed method fuses the modification of image histogram into two main colour models, namely, Red-Green-Blue (RGB) and Hue-Saturation-Value (HSV). In the primary stage, the CLAHE is connected just on the red part as in water, red shading is more influenced than the blue or green shading. Furthermore, in the second stage, without influencing the hue, the CLAHE is connected to saturation and value components of the HSV colour model. Finally, enhanced image has been produced using a fusion of output of primary phase and output produced in the second phase. Two parameters, namely, RMSE (Root Mean Squared Error) and the PSNR (Peak Signal to Noise Ratio) have been considered in comparing the experimental results of the proposed system with state-of-the-art work.
C1 [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
   [Jindal, Simpel Rani] Yadavindra Coll Engn, Dept Comp Sci & Engn, Talwandi Sabo, Punjab, India.
C3 Punjabi University
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
EM munishcse@gmail.com; simpel_jindal@rediffmail.com
RI Kumar, Munish/P-7756-2018
OI Kumar, Munish/0000-0003-0115-1620
CR Abbaspour MJ, 2016, IRAN CONF ELECTR ENG, P1855, DOI 10.1109/IranianCEE.2016.7585823
   [Anonymous], IEEE INT C COMP COMM
   Anwar MI, 2017, ENG SCI TECHNOL, V20, P1075, DOI 10.1016/j.jestch.2016.11.015
   Dixit Sonal, 2016, 2016 International Conference on Signal Processing, Communication, Power and Embedded System (SCOPES), P2042, DOI 10.1109/SCOPES.2016.7955807
   Guo JK, 2014, 2014 7TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP 2014), P243, DOI 10.1109/CISP.2014.7003785
   Iqbal K, 2010, IEEE INT C SYSTEMS M
   Kim K, 2018, IET IMAGE PROCESS, V12, P465, DOI 10.1049/iet-ipr.2016.0819
   Li CY, 2016, IEEE IMAGE PROC, P1993, DOI 10.1109/ICIP.2016.7532707
   Lu HM, 2013, IEEE IMAGE PROC, P3412, DOI 10.1109/ICIP.2013.6738704
   Peng YT, 2015, IEEE IMAGE PROC, P4952, DOI 10.1109/ICIP.2015.7351749
   Schechner YY, 2005, IEEE J OCEANIC ENG, V30, P570, DOI 10.1109/JOE.2005.850871
   Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383
   Torres-Méndez LA, 2005, LECT NOTES COMPUT SC, V3757, P60, DOI 10.1007/11585978_5
   Wang YF, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1013, DOI 10.1109/ICIT.2017.7915500
   White EM, 2003, ANIM BEHAV, V65, P693, DOI 10.1006/anbe.2003.2117
   Xu Y, 2016, IEEE ACCESS, V4, P165, DOI 10.1109/ACCESS.2015.2511558
   Xu Y, 2015, NEUROCOMPUTING, V168, P566, DOI 10.1016/j.neucom.2015.05.070
   Zhao XW, 2015, OCEAN ENG, V94, P163, DOI 10.1016/j.oceaneng.2014.11.036
NR 18
TC 12
Z9 14
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 9791
EP 9799
DI 10.1007/s11042-018-6599-8
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400013
DA 2024-07-18
ER

PT J
AU Latreche, B
   Saadi, S
   Kious, M
   Benziane, A
AF Latreche, Boubakeur
   Saadi, Slami
   Kious, Mecheri
   Benziane, Ali
TI A novel hybrid image fusion method based on integer lifting wavelet and
   discrete cosine transformer for visual sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; Visual sensor network; Integer lifting wavelet transform;
   Discrete cosine transformer
ID CONTRAST; MRI
AB In recent years, multimedia data is most used in the world such as image, audio, video and text. For reducing the great amount of generated data and for obtaining the better sensing performance, several researches have been focused on multimedia data fusion (MDF). The main objective of image fusion techniques in the visual sensor networks (VSNs) is to combine multiple images of the same scene captured by different cameras and with various focused regions into a single informative image. In this paper, we propose an efficient hybrid image fusion method which is suitable for VSNs based on the integer lifting wavelet transform (ILWT) and the discrete cosine transformer (DCT). The suggested fusion algorithm consists of two steps. Firstly, the approximate coefficients (low frequencies) generated by the ILWT are fused by selecting the variance as an activity level measure in the DCT domain. Secondly, the detail coefficients (high frequencies) are fused by taking the optimum weighted average based on the correlation between coefficients in ILWT domain. Due to the integer operations in ILWT domain, the proposed method overcomes the loss of information, computational complexity, time and energy consumption and memory space. Extensive experiments are performed to demonstrate the outperforming of the proposed method compared qualitatively and quantitatively with some literature image fusion techniques.
C1 [Latreche, Boubakeur; Kious, Mecheri] Amar Telidji Univ Laghouat, Semicond & Funct Mat Lab, BP 37G, Laghouat, Algeria.
   [Saadi, Slami; Benziane, Ali] Ziane Achour Univ Djelfa, Fac Exact Sci & Informat, Djelfa, Algeria.
C3 Universite Amar Telidji de Laghouat; Universite de Djelfa
RP Saadi, S (corresponding author), Ziane Achour Univ Djelfa, Fac Exact Sci & Informat, Djelfa, Algeria.
EM saadisdz@gmail.com
RI Latreche, Boubakeur/JHS-4928-2023; slami, saadi/O-2435-2016
OI slami, saadi/0000-0001-8091-5232; LATRECHE,
   Boubakeur/0009-0007-9367-3368
CR Abdipour M, 2016, COMPUT ELECTR ENG, V51, P74, DOI 10.1016/j.compeleceng.2016.03.011
   Adelson E. H., 1984, RCA engineer, V29, P33, DOI 10.1.1.59.9419.
   Albanesi MG, 2017, J SCH NURS, P1
   [Anonymous], IET COMPUTER VISION
   Bai XZ, 2015, INFORM FUSION, V22, P105, DOI 10.1016/j.inffus.2014.05.003
   Bavirisetti DP, 2017, INT J IMAG SYST TECH, V27, P227, DOI 10.1002/ima.22228
   Bavirisetti DP, 2016, INFRARED PHYS TECHN, V76, P52, DOI 10.1016/j.infrared.2016.01.009
   Ben Hamza A, 2005, INTEGR COMPUT-AID E, V12, P135
   Bhateja V, 2015, IEEE SENS J, V15, P6783, DOI 10.1109/JSEN.2015.2465935
   Bickelhaupt S, 2017, EUR RADIOL, V27, P562, DOI 10.1007/s00330-016-4400-9
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Calderbank AR, 1998, APPL COMPUT HARMON A, V5, P332, DOI 10.1006/acha.1997.0238
   Calderbank AR, 1997, IM PROC 1997 P INT C
   Cao L, 2015, IEEE SIGNAL PROC LET, V22, P220, DOI 10.1109/LSP.2014.2354534
   Chai T, 2014, GEOSCI MODEL DEV, V7, P1247, DOI 10.5194/gmd-7-1247-2014
   Charfi Y, 2009, IEEE WIREL COMMUN, V16, P44, DOI 10.1109/MWC.2009.4907559
   Chaudhuri S., 2013, Hyperspectral Image Fusion
   CHAVEZ PS, 1989, PHOTOGRAMM ENG REM S, V55, P339
   Chen D, 2017, EURASIP J ADV SIG PR, DOI 10.1186/s13634-016-0443-y
   Chen Z, 2016, 2016 IEEE INT C AC S
   Choi J, 2011, IEEE T GEOSCI REMOTE, V49, P295, DOI 10.1109/TGRS.2010.2051674
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   Dillen G, 2003, IEEE T CIRC SYST VID, V13, P944, DOI 10.1109/TCSVT.2003.816518
   Gharbia R, 2014, P 5 INT C INN BIOINS
   Ghassemian H, 2016, INFORM FUSION, V32, P75, DOI 10.1016/j.inffus.2016.03.003
   Grangetto M, 2002, IEEE T IMAGE PROCESS, V11, P596, DOI 10.1109/TIP.2002.1014991
   Haghighat MBA, 2011, COMPUT ELECTR ENG, V37, P789, DOI 10.1016/j.compeleceng.2011.04.016
   Hill P, 2017, IEEE T IMAGE PROCESS, V26, P1076, DOI 10.1109/TIP.2016.2633863
   Hu G, 2011, IMAGE FUSION ITS APP
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Hwang D, 2017, IEEE ACCESS, V5, P18987, DOI 10.1109/ACCESS.2017.2754585
   Jagalingam P, 2015, AQUAT PR, V4, P133, DOI 10.1016/j.aqpro.2015.02.019
   Lewis JJ, 2007, INFORM FUSION, V8, P119, DOI 10.1016/j.inffus.2005.09.006
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Li ST, 2008, IMAGE VISION COMPUT, V26, P971, DOI 10.1016/j.imavis.2007.10.012
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Liu ZD, 2017, INFORM FUSION, V35, P102, DOI 10.1016/j.inffus.2016.09.007
   Mangalraj P, 2015, PROCEDIA COMPUT SCI, V54, P713, DOI 10.1016/j.procs.2015.06.084
   Ming L, 2003, COMP INT MULT APPL 2
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Nirmala DE, 2015, COMP SUST GLOB DEV I
   Ouerghemmi W, 2017, INT ARCH PHOTOGRAMME, P42
   Petrovic V, 2006, INF FUS 2006 9 INT C
   Phamila YAV, 2014, SIGNAL PROCESS, V95, P161, DOI 10.1016/j.sigpro.2013.09.001
   Rabbani M, 2002, SIGNAL PROCESS-IMAGE, V17, P3, DOI 10.1016/S0923-5965(01)00024-8
   Rahmani S, 2010, IEEE GEOSCI REMOTE S, V7, P746, DOI 10.1109/LGRS.2010.2046715
   Redondi A, 2015, AD HOC NETW, V28, P38, DOI 10.1016/j.adhoc.2015.01.008
   Rockinger O, 1997, IM PROC 1997 P INT C
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Shah P, 2013, MULTIFOCUS MULTISPEC, P1
   Shah P, 2011, IVMSP WORKSH 2011 IE
   Shandoosti HR, 2016, INFORM FUSION, V27, P150, DOI 10.1016/j.inffus.2015.06.006
   Shreyamsha Kumar BK, 2015, SIGNAL IMAGE VIDEO P, V9, P1193, DOI 10.1007/s11760-013-0556-9
   Shreyamsha Kumar BK, 2013, SIGNAL IMAGE VIDEO P, V7, P1125, DOI 10.1007/s11760-012-0361-x
   Siddalingesh G., 2014, EMERGING RES ELECT C, V248
   Singh R, 2014, INFORM FUSION, V19, P49, DOI 10.1016/j.inffus.2012.09.005
   Stathaki T, 2011, Image fusion: algorithms and applications
   Sweldens W, 1998, SIAM J MATH ANAL, V29, P511, DOI 10.1137/S0036141095289051
   Tang JS, 2004, DIGIT SIGNAL PROCESS, V14, P218, DOI 10.1016/j.dsp.2003.06.001
   Tavli B, 2012, MULTIMED TOOLS APPL, V60, P689, DOI 10.1007/s11042-011-0840-z
   Tian J, 2011, OPT COMMUN, V284, P80, DOI 10.1016/j.optcom.2010.08.085
   Vijayarajan R, 2015, AEU-INT J ELECTRON C, V69, P896, DOI 10.1016/j.aeue.2015.02.007
   Wang XH, 2015, J OPTICS-UK, V17, DOI 10.1088/2040-8978/17/5/055702
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2008, INT CONTR AUT 2008 W
   Wu J, 2005, MECHATRONICS AUTOMAT
   Xia XH, 2014, PATTERN RECOGN LETT, V45, P115, DOI 10.1016/j.patrec.2014.03.018
   Xu WH, 2017, INT J FUZZY SYST, V19, P1200, DOI 10.1007/s40815-016-0230-9
   Xu XJ, 2016, BIOMED SIGNAL PROCES, V27, P103, DOI 10.1016/j.bspc.2016.02.008
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yang B, 2012, INFORM FUSION, V13, P10, DOI 10.1016/j.inffus.2010.04.001
   Yang Bo, 2010, Journal of Shanghai Jiaotong University (English Edition), V15, P6, DOI 10.1007/s12204-010-7186-y
   Yang J, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9010053
   Yang Y, 2015, IEEE SENS J, V15, P2824, DOI 10.1109/JSEN.2014.2380153
   Yang Y, 2014, SENSORS-BASEL, V14, P22408, DOI 10.3390/s141222408
   Yu BT, 2016, NEUROCOMPUTING, V182, P1, DOI 10.1016/j.neucom.2015.10.084
   Zhang BH, 2016, DIGIT SIGNAL PROCESS, V58, P50, DOI 10.1016/j.dsp.2016.07.010
   Zhang BH, 2016, NEUROCOMPUTING, V174, P733, DOI 10.1016/j.neucom.2015.09.092
   Zhang D, 2009, IGI GLOBAL, P328, DOI [10.4018/978-1-60566-200-8.ch015, DOI 10.4018/978-1-60566-200-8.CH015]
   Zhang Q, 2016, INFRARED PHYS TECHN, V74, P11, DOI 10.1016/j.infrared.2015.11.003
   Zhang Y, 2017, INFORM FUSION, V35, P81, DOI 10.1016/j.inffus.2016.09.006
   Zhou Z, 2014, INFORM FUSION, V20, P60, DOI 10.1016/j.inffus.2013.11.005
   Zuo YJ, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17051127
NR 83
TC 8
Z9 8
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10865
EP 10887
DI 10.1007/s11042-018-6676-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400060
DA 2024-07-18
ER

PT J
AU Li, D
   Zhang, YN
   Li, XC
   Niu, K
   Yang, XY
   Sun, YJ
AF Li, Dong
   Zhang, YingNan
   Li, XinChao
   Niu, Ke
   Yang, XiaoYuan
   Sun, YuJuan
TI Two-dimensional histogram modification based reversible data hiding
   using motion vector for H.264
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; H; 264; AVC; Histogram modification; Motion
   vector; Two-dimensional
ID DIFFERENCE EXPANSION; SCHEME; IMAGES
AB Histogram modification (HM) is an efficient algorithm for reversible data hiding into H.264 video, motion vector based methods have been applied to HM. In this paper, we present a special strategy of reversible data hiding using motion vector based on two-dimensional histogram modification. Firstly, the two components of a motion vector will compose an embedding pair. The values of embedding pairs are classified into 17 non-intersect sets. Then, according to the set that the embedding pair belongs to, we can embed data into motion vectors by modifying the value of embedding pair. Experimental results verify that the embedding capacity is increased by two times compared with the previous algorithm, and the PSNR declines about 5%. The reversibility of the algorithm is also studied, three rules are presented to judge the reversibility of an algorithm directly, and the rules are suitable for other histogram modification based methods.
C1 [Li, Dong; Zhang, YingNan; Li, XinChao; Niu, Ke; Yang, XiaoYuan] Engn Univ Peoples Armed Police, Elect Dept, Key Lab Network & Informat Secur Peoples Armed Po, Xian 710086, Shaanxi, Peoples R China.
   [Sun, YuJuan] Univ Toronto, Dept Elect & Comp Engn, Toronto, ON, Canada.
C3 University of Toronto
RP Yang, XY (corresponding author), Engn Univ Peoples Armed Police, Elect Dept, Key Lab Network & Informat Secur Peoples Armed Po, Xian 710086, Shaanxi, Peoples R China.
EM 18792733969@163.com
CR Al-Qershi OM, 2013, SIGNAL PROCESS, V93, P154, DOI 10.1016/j.sigpro.2012.07.012
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Barton J. M., 1997, United States Patent, Patent No. [5646997, 5,646,997]
   Cao Y, 2018, CMC-COMPUT MATER CON, V54, P197, DOI 10.3970/cmc.2018.054.197
   Hwang K, 2010, IEEE INTERNET COMPUT, V14, P14, DOI 10.1109/MIC.2010.86
   Lin KZ, 2008, 2008 INTERNATIONAL MULTISYMPOSIUMS ON COMPUTER AND COMPUTATIONAL SCIENCES (IMSCCS), P164, DOI 10.1109/IMSCCS.2008.46
   Liu YX, 2015, NEUROCOMPUTING, V151, P1053, DOI 10.1016/j.neucom.2014.03.088
   Ma YY, 2019, IEEE T CIRC SYST VID, V29, P336, DOI 10.1109/TCSVT.2018.2799243
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Niu K, 2017, TSINGHUA SCI TECHNOL, V22, P489
   Richardson IEG, 2003, H 264 MPEG 4 VIDEO C, P171
   Song GH, 2015, MULTIMED TOOLS APPL, V74, P3759, DOI 10.1007/s11042-013-1798-9
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Xu DW, 2014, J VIS COMMUN IMAGE R, V25, P410, DOI 10.1016/j.jvcir.2013.12.008
   Zeng XA, 2011, J INF SCI ENG, V27, P465
   Zeng XA, 2011, MULTIMED TOOLS APPL, V52, P465, DOI 10.1007/s11042-010-0476-4
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
   Zhao J, 2016, MULTIMED TOOLS APPL, V75, P5959, DOI 10.1007/s11042-015-2558-9
   Zhou QL, 2018, CMC-COMPUT MATER CON, V55, P151, DOI [10.3970/cmc.2018.055.15l, 10.3970/cmc.2018.055.151]
NR 20
TC 9
Z9 12
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8167
EP 8181
DI 10.1007/s11042-018-6729-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800016
DA 2024-07-18
ER

PT J
AU Meng, CX
   Zhang, XY
AF Meng Cai-xia
   Zhang Xin-yan
TI Object tracking method based on particle filter of adaptive patches
   combined with multi-features fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Particle filter; Color histogram; Histogram of oriented
   gradient; Adaptability; Projection
ID VISUAL TRACKING
AB Object tracking has been one of the most important and active research areas in the field of computer vision. In this paper, we address the problem of object tracking under complex conditions in a video, which propose a object tracking method based on particle filter of adaptive patches combined color histograms with Histogram of Oriented Gradient(HOG). The adaptive patch is performed by horizontal and vertical projection based on object gray levels, which can improve the patch adaptability to the object appearance diversity and the accuracy of object tracking under occlusion conditions. The fusion of color histograms and HOG features is adopted to describe each sub-patch, which not only solves the tracking divergence problem of similar objects, but also reduces the effect of local deformation. In addition, the weighted Bhattacharyya coefficient is introduced to calculate the sub-patch matching degree of the particle, and the particle sub-patch weight will be adjusted by integrating the particle space information, and the feature model is also updated in time to achieve robust object tracking. Many simulation experiments show that our proposed algorithm achieves more favorable performance than these existing state-of-the-art algorithms in handing various challenging videos, especially occlusion and shape deformation.
C1 [Meng Cai-xia] Railway Police Coll, Dept Image & Network Invest, Zhengzhou 450003, Henan, Peoples R China.
   [Zhang Xin-yan] Luoyang Inst Sci & Technol, Dept Comp & Informat Engn, Luoyang City 471023, Henan, Peoples R China.
C3 Railway Police College; Luoyang Institute of Science & Technology
RP Zhang, XY (corresponding author), Luoyang Inst Sci & Technol, Dept Comp & Informat Engn, Luoyang City 471023, Henan, Peoples R China.
EM mengcaixia@rpc.edu.cn; zxy@lit.edu.cn
FU Scientific and Technological Research Program of Henan Province
   [172102210441]; Key Scientific Research projects in Henan Colleges and
   Universities [18B520034]; Ministry of Public Security Technical Research
   Plan [2016JSYJB38]
FX 1. The Scientific and Technological Research Program of Henan Province.
   No. 172102210441.; 2. Key Scientific Research projects in Henan Colleges
   and Universities. No. 18B520034.; 3. The Ministry of Public Security
   Technical Research Plan under grant. No. 2016JSYJB38.
CR Babenko B, 2013, IEEE C COMP VIS PATT
   BAE SH, 2018, TPAMI, V40, P595, DOI DOI 10.1109/TPAMI.2017.2691769
   Bhattacharyya A, 1946, SANKHYA INDIAN J STA, V17, P401
   Danescu R, 2009, IEEE INT VEH SYM, P88, DOI 10.1109/IVS.2009.5164258
   De Ath G, 2018, ARXIV180501146
   Du B, 2018, IEEE GEOSCI REMOTE S, V15, P168, DOI 10.1109/LGRS.2017.2776899
   Habbachi S, 2018, ADV TECHN SIGN IM PR, P1
   Hu HW, 2018, IEEE T NEUR NET LEAR, V29, P1786, DOI 10.1109/TNNLS.2017.2688448
   Hu WM, 2012, IEEE T PATTERN ANAL, V34, P2420, DOI 10.1109/TPAMI.2012.42
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Li Yuanzheng, 2012, Journal of Xidian University, V39, P1, DOI 10.3969/j.issn.1001-2400.2012.04.001
   Long C, 2011, CHIN J SCI INSTRUM, V11, P21
   Wen LY, 2012, LECT NOTES COMPUT SC, V7575, P716, DOI 10.1007/978-3-642-33765-9_51
   Zhang KH, 2013, IEEE T CIRC SYST VID, V23, P1957, DOI 10.1109/TCSVT.2013.2269772
   Zhang KH, 2013, IEEE T IMAGE PROCESS, V22, P4664, DOI 10.1109/TIP.2013.2277800
   Zhang KH, 2013, PATTERN RECOGN, V46, P397, DOI 10.1016/j.patcog.2012.07.013
   Zhang TZ, 2012, LECT NOTES COMPUT SC, V7577, P470, DOI 10.1007/978-3-642-33783-3_34
   Zhang XL, 2015, IEEE T PATTERN ANAL, V37, P28, DOI 10.1109/TPAMI.2014.2343221
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zhuang BH, 2014, IEEE T IMAGE PROCESS, V23, P1872, DOI 10.1109/TIP.2014.2308414
NR 20
TC 5
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8799
EP 8811
DI 10.1007/s11042-018-6382-x
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800049
DA 2024-07-18
ER

PT J
AU Ouyang, JL
   Liu, YZ
   Liao, M
AF Ouyang, Junlin
   Liu, Yizhi
   Liao, Miao
TI Robust copy-move forgery detection method using pyramid model and
   Zernike moments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tamper detection; Copy-move forgery; Pyramid model; Image forensics
ID ALGORITHM; SCHEME
AB Copy-move forgery detection (CMFD) is probably one of the most active research subtopics within the blind image forensics field. Among existing algorithms, block-based methods achieve better detection result, but suffer from not being robust to the scaling of the copied region, which is limited to a small scaling range between 91 and 109%. To overcome this issue, a novel copy-move forgery detection method based on the pyramid model and Zernike moments is proposed in this work. First, a non-uniform sampling approach is used to build the pyramid model to improve the speed of detection, where each level of the model is a rescaled image with different scale factors. Then, the Zernike moments method is used to extract image rotation invariant feature. Furthermore, to make the proposed model be robust to the rotation and the combination of the rotation and scaling of the copied region, the random sample consensus (RANSAC) algorithm is adopted to look for the same affine transformation parameters. Compared with the existing methods, experimental results show that the proposed method has a good effect on the arbitrary rotation angle, the scaling range between 50 and 200%, and the combination of both.
C1 [Ouyang, Junlin; Liu, Yizhi; Liao, Miao] Hunan Univ Sci & Technol, Sch Comp Sci & Engn, Xiangtan 411201, Peoples R China.
   [Ouyang, Junlin; Liu, Yizhi] Hunan Univ Sci & Technol, Coll Hunan Prov, Key Lab Knowledge Proc & Networked Mfg, Xiangtan 411201, Peoples R China.
C3 Hunan University of Science & Technology; Hunan University of Science &
   Technology
RP Ouyang, JL (corresponding author), Hunan Univ Sci & Technol, Sch Comp Sci & Engn, Xiangtan 411201, Peoples R China.; Ouyang, JL (corresponding author), Hunan Univ Sci & Technol, Coll Hunan Prov, Key Lab Knowledge Proc & Networked Mfg, Xiangtan 411201, Peoples R China.
EM yangjunlin0732@163.com
OI Ouyang, Junlin/0000-0001-7155-2732
FU natural science foundation of Hunan province [2017JJ2099, 2017JJ3091];
   Hunan province education department [16C0642, 17C0643]; Doctor Fund
   University of Science and Technology of Hunan [E51684, E51754]; National
   Natural Science Foundation of China [61702179]; National Science and
   Technology Support Project of China [2015BAF32B01]
FX The authors would like to thank all the anonymous reviewers for their
   helpful comments and suggestions. This work was supported by the natural
   science foundation of Hunan province under Grants 2017JJ2099,
   2017JJ3091, by the Hunan province education department under Grants
   16C0642, 17C0643, by the Doctor Fund University of Science and
   Technology of Hunan under Grants E51684, E51754, by the National Natural
   Science Foundation of China 61702179, by National Science and Technology
   Support Project of China, under grant number 2015BAF32B01.
CR Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Bayram S, 2009, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.2009.4959768
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Bravo-Solorio S, 2011, INT CONF ACOUST SPEE, P1880
   Bravo-Solorio S, 2011, SIGNAL PROCESS, V91, P1759, DOI 10.1016/j.sigpro.2011.01.022
   Cao YJ, 2012, FORENSIC SCI INT, V214, P33, DOI 10.1016/j.forsciint.2011.07.015
   Chen CC, 2017, MULTIMED TOOLS APPL, V76, P26503, DOI 10.1007/s11042-016-4179-3
   Christlein V, 2010, IEEE INT WORKS INFOR
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Coatrieux G, 2013, IEEE J BIOMED HEALTH, V17, P1057, DOI 10.1109/JBHI.2013.2263533
   Davarzani R, 2013, FORENSIC SCI INT, V231, P61, DOI 10.1016/j.forsciint.2013.04.023
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Flusser J., 2009, Moments and Moment Invariants in Pattern Recognition
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Heng Yao, 2011, 2011 3rd International Conference on Multimedia Information Networking and Security, P591, DOI 10.1109/MINES.2011.104
   Huang HL, 2008, PACIIA: 2008 PACIFIC-ASIA WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION, VOLS 1-3, PROCEEDINGS, P1241
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Hwei-Jen Lin, 2009, WSEAS Transactions on Signal Processing, V5, P188
   Li G., 2007, IEEE INT C MULT EXP, DOI DOI 10.1109/ICME.2007.4285009
   Li JW, 2017, MULTIMED TOOLS APPL, V76, P20483, DOI 10.1007/s11042-016-3967-0
   Liu GJ, 2011, J NETW COMPUT APPL, V34, P1557, DOI 10.1016/j.jnca.2010.09.001
   LUO W, 2006, CHINESE J COMPUT, V4, P746
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Myna AN, 2007, ICCIMA 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, VOL III, PROCEEDINGS, P371, DOI 10.1109/ICCIMA.2007.271
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Popescu A.C., 2004, Exposing digital forgeries by detecting duplicated image regions
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Vedaldi A., 2010, VLFeat - an open and portable library of computer vision algorithms
   Wang Jun-Wen, 2009, Acta Automatica Sinica, V35, P1488, DOI 10.3724/SP.J.1004.2009.01488
   Wang JW, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 1, PROCEEDINGS, P25, DOI 10.1109/MINES.2009.142
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P23353, DOI 10.1007/s11042-016-4140-5
   Wu QM, 2011, IEEE SIGNAL PROC LET, V18, P559, DOI 10.1109/LSP.2011.2163507
   Xiaofeng Wang, 2011, 2011 3rd International Conference on Multimedia Information Networking and Security, P304, DOI 10.1109/MINES.2011.98
   Xu Bo, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P889, DOI 10.1109/MINES.2010.189
   Zhong JL, 2017, MULTIMED TOOLS APPL, V76, P14887, DOI 10.1007/s11042-016-4201-9
NR 38
TC 17
Z9 19
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10207
EP 10225
DI 10.1007/s11042-018-6605-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400033
DA 2024-07-18
ER

PT J
AU Qu, ZG
   Cheng, ZW
   Liu, WJ
   Wang, XJ
AF Qu, Zhiguo
   Cheng, Zhenwen
   Liu, Wenjie
   Wang, Xiaojun
TI A novel quantum image steganography algorithm based on exploiting
   modification direction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quantum image steganography; Exploiting modification direction;
   Embedding efficiency; Quantum circuit
ID REPRESENTATION
AB Quantum image steganography is the art and science of hiding secret information into quantum carrier images. This paper proposes a novel quantum image steganography algorithm based on an efficient embedding technique of exploiting modification direction. For convenience, this embedding technique is referred to the EMD embedding. In the EMD embedding, it is clear that each carrier pixel-group of the carrier image contains N pixels and each secret digit of secret information belongs to the (2N + 1)-ary notational system, where N is a system parameter. The embedding process is that at most only one pixel of the carrier pixel-group will be either increased by 1 or decreased by 1. The new algorithm takes advantage of the EMD embedding owning high embedding efficiency that the (2N + 1) different modifications to N carrier pixels represent the value of the secret digit. In addition, designing the dedicated quantum circuit for the EMD embedding contributes to better understanding the process of the new algorithm. Experimental simulation based on MATLAB shows that the new algorithm has good performance on imperceptibility, security, embedding efficiency and embedding capacity.
C1 [Qu, Zhiguo; Liu, Wenjie] Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Jiangsu, Peoples R China.
   [Cheng, Zhenwen] Nanjing Univ Informat Sci & Technol, Sch Elect & Informat Engn, Nanjing 210044, Jiangsu, Peoples R China.
   [Wang, Xiaojun] Dublin City Univ, Sch Elect Engn, Dublin, Ireland.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology; Dublin City University
RP Qu, ZG (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Jiangsu, Peoples R China.
EM qzghhh@126.com; czw381576996@163.com; wenjiel@163.com;
   xiaojun.wang@dcu.ie
RI Qu, Zhiguo/N-9008-2015; Liu, wenjie/JGL-7784-2023; Wang,
   Xiaojun/I-5025-2017
OI Qu, Zhiguo/0000-0002-5783-313X
FU National Natural Science Foundation of China [61373131, 61303039,
   61232016, 61501247]; Six Talent Peaks Project of Jiangsu Province
   [2015-XXRJ-013]; Natural Science Foundation of Jiangsu Province
   [BK20171458]; Natural Science Foundation of the Higher Education
   Institutions of Jiangsu Province (China) [16KJB520030]; Sichuan Youth
   Science and Technique Foundation [2017JQ0048]; NUIST Research Foundation
   for Talented Scholars [2015r014]; PAPD; CICAEET
FX This work was supported by the National Natural Science Foundation of
   China (No. 61373131, 61303039, 61232016, 61501247), the Six Talent Peaks
   Project of Jiangsu Province (Grant No. 2015-XXRJ-013), Natural Science
   Foundation of Jiangsu Province (Grant No. BK20171458), the Natural
   Science Foundation of the Higher Education Institutions of Jiangsu
   Province (China under Grant No.16KJB520030), Sichuan Youth Science and
   Technique Foundation (No.2017JQ0048), NUIST Research Foundation for
   Talented Scholars (2015r014), PAPD and CICAEET funds.
CR [Anonymous], 2012, J QUANTUM INFORM SCI, DOI DOI 10.4236/jqis.2012.21003
   Cao Y, 2015, COMPUTER MAT CONTINU, V54, P197
   Chen XB, 2014, QUANTUM INF COMPUT, V14, P589
   Chen XB, 2014, QUANTUM INF PROCESS, V13, P85, DOI 10.1007/s11128-013-0669-7
   Du JF, 2002, PHYS REV LETT, V88, DOI 10.1103/PhysRevLett.88.137902
   Eggeling T, 2002, PHYS REV LETT, V89, DOI 10.1103/PhysRevLett.89.097905
   Gea-Banacloche J, 2002, J MATH PHYS, V43, P4531, DOI 10.1063/1.1495073
   Guo G. C, 2012, PHYS REV A, V68, P4343
   Gupta Shailender, INT J MODERN ED COMP, V4, P27
   Heidari S, 2017, QUANTUM INF PROCESS, V16, DOI 10.1007/s11128-017-1694-8
   Islam M. S., 2009, Information Technology Journal, V8, P208, DOI 10.3923/itj.2009.208.213
   Le PQ, 2011, QUANTUM INF PROCESS, V10, P63, DOI 10.1007/s11128-010-0177-y
   Liao X, 2010, J SYST SOFTWARE, V83, P1801, DOI 10.1016/j.jss.2010.04.076
   Liu W., 2017, INT J THEOR PHYS, V57, P1
   Liu WJ, 2016, QUANTUM INF PROCESS, V15, P869, DOI 10.1007/s11128-015-1202-y
   Ma Y, 2019, IEEE T CONTR SYST T, V27, P1788, DOI 10.1109/TCST.2018.2819965
   Martin K, 2007, LECT NOTES COMPUT SC, V4567, P32
   Meng RH, 2018, CMC-COMPUT MATER CON, V55, P1, DOI 10.3970/cmc.2018.055.001
   Mihara T, 2015, PHYS LETT A, V379, P952, DOI 10.1016/j.physleta.2015.01.038
   Nie QK, 2018, CMC-COMPUT MATER CON, V55, P59, DOI 10.3970/cmc.2018.055.059
   Pradeep A, 2016, CMC-COMPUT MATER CON, V52, P187
   Qu ZG, 2017, INT J THEOR PHYS, V56, P3460, DOI 10.1007/s10773-017-3512-6
   Qu ZG, 2016, LECT NOTES COMPUT SC, V10040, P394, DOI 10.1007/978-3-319-48674-1_35
   Qu ZG, 2016, CHINA COMMUN, V13, P108, DOI 10.1109/CC.2016.7559082
   Shaw BA, 2011, PHYS REV A, V83, DOI 10.1103/PhysRevA.83.022310
   Venegas-Andraca SE, 2003, PROC SPIE, V5105, P137, DOI 10.1117/12.485960
   [王冬 Wang Dong], 2012, [计算机科学, Computer Science], V39, P302
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Wang S, 2015, MEASUREMENT, V73, P352, DOI 10.1016/j.measurement.2015.05.038
   Wei ZH, 2015, INT J THEOR PHYS, V54, P2505, DOI 10.1007/s10773-014-2478-x
   Wei ZH, 2013, INT J QUANTUM INF, V11, DOI 10.1142/S0219749913500688
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
   Zhang Y, 2013, QUANTUM INF PROCESS, V12, P3103, DOI 10.1007/s11128-013-0587-8
   Zhang Y, 2013, QUANTUM INF PROCESS, V12, P2833, DOI 10.1007/s11128-013-0567-z
   Zhou Q., 2018, COMPUT MATER CONTINU, V55, P1
   Zhou RG, 2017, QUANTUM INF PROCESS, V16, DOI 10.1007/s11128-017-1640-9
NR 37
TC 44
Z9 45
U1 2
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 7981
EP 8001
DI 10.1007/s11042-018-6476-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800006
DA 2024-07-18
ER

PT J
AU Xu, M
   Li, J
AF Xu, Meng
   Li, Jian
TI 3D PEE mapping based reversible data hiding for color images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; 3D PEE mapping; Prediction-error expansion
ID HISTOGRAM-MODIFICATION; SCHEME; WATERMARKING; PREDICTION; EXPANSION
AB The performance of prediction-error expansion (PEE) for reversible data hiding (RDH) is excellent. 2D and 3D PEE has a great improvement than the conventional PEE. However, the PEE-based method used in each channel of a color image cannot make full use of the correlation among three channels. In the paper, a reversible data hiding algorithm based on 3D PEE mapping is proposed. Firstly, a prediction-error triple is generated from three channels of a color image. Next, the prediction error triples can shift freely in 3D space. Finally, specific error triples have been shifted to embed secret data and other triples are expanded to make room for data embedding. By using the proposed reversible 3D PEE mapping, the inter-correlation of RGB channels is better exploited. Extensive experimental results demonstrate that the proposed algorithm outperforms the traditional RDH methods for color images.
C1 [Xu, Meng; Li, Jian] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing, Jiangsu, Peoples R China.
C3 Nanjing University of Information Science & Technology
RP Xu, M (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing, Jiangsu, Peoples R China.
EM 1003520694@qq.com
FU Natural Science Foundation of China [61772281, 61502241, 61272421,
   61232016, 61402235, 61572258]; Natural Science Foundation of Jiangsu
   Province, China [BK20141006]; Natural Science Foundation of the
   Universities in Jiangsu Province [14KJB520024]; PAPD fund; CICAEET fund
FX This work was supported in part by the Natural Science Foundation of
   China under Grants (Nos. 61772281, 61502241, 61272421, 61232016,
   61402235 and 61572258), in part by the Natural Science Foundation of
   Jiangsu Province, China under Grant BK20141006, and in part by the
   Natural Science Foundation of the Universities in Jiangsu Province under
   Grant 14KJB520024, the PAPD fund and the CICAEET fund.
CR [Anonymous], IEEE T CIRCUITS SYST
   Cai SR, 2016, IEEE IMAGE PROC, P2732, DOI 10.1109/ICIP.2016.7532856
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Coltuc D, 2007, IEEE SIGNAL PROC LET, V14, P255, DOI 10.1109/LSP.2006.884895
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Hong WE, 2011, J VIS COMMUN IMAGE R, V22, P131, DOI 10.1016/j.jvcir.2010.11.004
   HU Y, 2009, TECHNOLOGY, V19, P250, DOI DOI 10.1109/TCSVT.2008.2009252
   Lee S, 2007, IEEE T INF FOREN SEC, V2, P321, DOI 10.1109/TIFS.2007.905146
   Li J, 2013, SIGNAL PROCESS, V93, P2748, DOI 10.1016/j.sigpro.2013.01.020
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Ma B, 2016, IEEE T INF FOREN SEC, V11, P1914, DOI 10.1109/TIFS.2016.2566261
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Tsai YY, 2013, DIGIT SIGNAL PROCESS, V23, P919, DOI 10.1016/j.dsp.2012.12.014
   Wang JX, 2014, J VIS COMMUN IMAGE R, V25, P1425, DOI 10.1016/j.jvcir.2014.04.005
   Wang X, 2015, INFORM SCIENCES, V310, P16, DOI 10.1016/j.ins.2015.03.022
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   Wu HT, 2017, I C INTELL COMPUT TE, P1, DOI 10.1109/ICICTA.2017.8
   Yang WJ, 2012, INFORM SCIENCES, V190, P208, DOI 10.1016/j.ins.2011.11.046
   Yao H, 2017, J VIS COMMUN IMAGE R, V43, P152, DOI 10.1016/j.jvcir.2017.01.004
   Zhang XP, 2013, IEEE T MULTIMEDIA, V15, P316, DOI 10.1109/TMM.2012.2229262
NR 28
TC 3
Z9 3
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8003
EP 8016
DI 10.1007/s11042-018-6486-3
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800007
DA 2024-07-18
ER

PT J
AU Al Maadeed, S
   Jiang, XD
   Rida, I
   Bouridane, A
AF Al Maadeed, Somaya
   Jiang, Xudong
   Rida, Imad
   Bouridane, Ahmed
TI Palmprint identification using sparse and dense hybrid representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric; Palmprint; Sparse representation for classification
ID ROBUST FACE RECOGNITION; EXTRACTION; SELECTION; FEATURES; SYSTEM;
   SCHEME; DCT
AB Among various palmprint identification methods proposed in the literature, Sparse Representation for Classification (SRC) is very attractive, offering high accuracy. Although SRC has good discriminative ability, its performance strongly depends on the quality of the training data. In fact, palmprint images do not only contain identity information but they also have other information such as illumination and distortions due the acquisition conditions. In this case, SRC may not be able to classify the identity of palmprint well in the original space since samples from the same class show large variations. To overcome this problem, we propose in this work to exploit sparse-and-dense hybrid representation (SDR) for palmprint identification. Indeed, this type of representations that are based on the dictionary learning from the training data has shown its great advantage to overcome the limitations of SRC. Extensive experiments are conducted on two publicly available palmprint datasets: multispectral and PolyU. The obtained results clearly show the ability of the proposed method to outperform both the state-of-the-art holistic approaches and the coding palmprint identification methods.
C1 [Al Maadeed, Somaya; Rida, Imad] Qatar Univ, Dept Comp Sci & Engn, Doha, Qatar.
   [Jiang, Xudong] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
   [Bouridane, Ahmed] Northumbria Univ, Dept Comp Sci & Digital Technol, Newcastle Upon Tyne, Tyne & Wear, England.
C3 Qatar University; Nanyang Technological University; Northumbria
   University
RP Al Maadeed, S (corresponding author), Qatar Univ, Dept Comp Sci & Engn, Doha, Qatar.
EM S.alali@qu.edu.qa; exdjiang@ntu.edu.sg; rida.imad@gmail.com;
   ahmed.bouridane@northumbria.ac.uk
RI Rida, Imad/AAA-5044-2022; Jiang, Xudong/B-1555-2008
OI Rida, Imad/0000-0003-2789-5070; Jiang, Xudong/0000-0002-9104-2315;
   Al-maadeed, Somaya/0000-0002-0241-2899
FU Qatar National Research Fund through National Priority Research Program
   (NPRP) [6-249-1-053]
FX This publication was made possible using a grant from the Qatar National
   Research Fund through National Priority Research Program (NPRP) No.
   6-249-1-053. The contents of this publication are solely the
   responsibility of the authors and do not necessarily represent the
   official views of the Qatar National Research Fund or Qatar University.
CR [Anonymous], INT WORKSH IM PROC T
   Bertsekas D. P., 2014, CONSTRAINED OPTIMIZA
   Charfi N, 2017, MULTIMED TOOLS APPL, V76, P20457, DOI 10.1007/s11042-016-3987-9
   Connie T, 2005, IMAGE VISION COMPUT, V23, P501, DOI 10.1016/j.imavis.2005.01.002
   Cui JR, 2015, MULTIMED TOOLS APPL, V74, P10989, DOI 10.1007/s11042-014-1887-4
   De Marsico M, 2013, IEEE T SYST MAN CY-S, V43, P149, DOI 10.1109/TSMCA.2012.2192427
   Fei LK, 2017, INT J IMAGE GRAPH, V17, DOI 10.1142/S0219467817500206
   Fei LK, 2016, NEUROCOMPUTING, V218, P264, DOI 10.1016/j.neucom.2016.08.048
   Fei LK, 2016, PATTERN RECOGN LETT, V69, P35, DOI 10.1016/j.patrec.2015.10.003
   Fei LK, 2016, PATTERN RECOGN, V49, P89, DOI 10.1016/j.patcog.2015.08.001
   Guo XM, 2017, MACH VISION APPL, V28, P283, DOI 10.1007/s00138-017-0821-y
   Guo ZH, 2009, PATTERN RECOGN LETT, V30, P1219, DOI 10.1016/j.patrec.2009.05.010
   Hammami M, 2014, MULTIMED TOOLS APPL, V68, P1023, DOI 10.1007/s11042-012-1109-x
   Han CC, 2003, PATTERN RECOGN, V36, P371, DOI 10.1016/S0031-3203(02)00037-7
   Hengjian Li, 2012, Proceedings of the 2012 International Conference on Measurement, Information and Control (MIC), P563, DOI 10.1109/MIC.2012.6273448
   Hennings-Yeomans PH, 2007, IEEE T INF FOREN SEC, V2, P613, DOI 10.1109/TIFS.2007.902039
   Hong DF, 2016, NEUROCOMPUTING, V174, P999, DOI 10.1016/j.neucom.2015.10.031
   Hong DF, 2015, NEUROCOMPUTING, V151, P511, DOI 10.1016/j.neucom.2014.09.013
   Hu DW, 2007, PATTERN RECOGN, V40, P339, DOI 10.1016/j.patcog.2006.06.022
   Huang DS, 2008, PATTERN RECOGN, V41, P1316, DOI 10.1016/j.patcog.2007.08.016
   Jia W, 2008, PATTERN RECOGN, V41, P1504, DOI 10.1016/j.patcog.2007.10.011
   Jia W, 2017, IEEE T IMAGE PROCESS, V26, P4483, DOI 10.1109/TIP.2017.2705424
   Jiang XD, 2015, IEEE T PATTERN ANAL, V37, P1067, DOI 10.1109/TPAMI.2014.2359453
   Jing XY, 2004, IEEE T SYST MAN CY B, V34, P2405, DOI 10.1109/TSMCB.2004.837586
   Kong A, 2006, PATTERN RECOGN, V39, P478, DOI 10.1016/j.patcog.2005.08.014
   Kong AWK, 2004, INT C PATT RECOG, P520, DOI 10.1109/ICPR.2004.1334184
   Laadjel M, 2015, NEUROCOMPUTING, V152, P179, DOI 10.1016/j.neucom.2014.11.005
   LAI J, 2016, TIP, V25, P3261, DOI DOI 10.1109/TIP.2016.2545249
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Li G, 2017, PATTERN RECOGN, V61, P29, DOI 10.1016/j.patcog.2016.06.025
   Lu GM, 2003, PATTERN RECOGN LETT, V24, P1463, DOI 10.1016/S0167-8655(02)00386-0
   Luo YT, 2016, PATTERN RECOGN, V50, P26, DOI 10.1016/j.patcog.2015.08.025
   Meraoumia A, 2015, MULTIMED TOOLS APPL, V74, P955, DOI 10.1007/s11042-013-1706-3
   Mokni R, 2017, MULTIMED TOOLS APPL, V76, P23981, DOI 10.1007/s11042-016-4088-5
   Mokni R, 2016, J INF ASSUR SECUR, V11, P77
   Mu MR, 2011, NEUROCOMPUTING, V74, P3351, DOI 10.1016/j.neucom.2011.05.026
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Raghavendra R, 2015, EURASIP J INF SECUR, DOI 10.1186/s13635-015-0022-z
   Raghavendra R, 2014, PATTERN RECOGN, V47, P2205, DOI 10.1016/j.patcog.2013.12.011
   Rida I, 2018, IEEE ACCESS, V6, P3241, DOI 10.1109/ACCESS.2017.2787666
   Rida I, 2016, IEEE SIGNAL PROC LET, V23, P154, DOI 10.1109/LSP.2015.2507200
   Rida I, 2016, SIGNAL IMAGE VIDEO P, V10, P463, DOI 10.1007/s11760-015-0766-4
   Rigamonti R, 2011, PROC CVPR IEEE, P1545, DOI 10.1109/CVPR.2011.5995313
   Sang HF, 2009, LECT NOTES COMPUT SC, V5552, P831, DOI 10.1007/978-3-642-01510-6_93
   Shi QF, 2011, PROC CVPR IEEE, P553, DOI 10.1109/CVPR.2011.5995556
   Srinivas BG, 2009, COMM COM INF SC, V40, P250, DOI 10.1007/978-3-642-03547-0_24
   SUN Z, 1934, TIP, V23, P3922, DOI DOI 10.1109/TIP.2014.2332396
   Sun ZN, 2005, PROC CVPR IEEE, P279
   Tabejamaat M, 2017, MULTIMED TOOLS APPL, P1
   Tabejamaat M, 2017, MULTIMED TOOLS APPL, V76, P9387, DOI 10.1007/s11042-016-3544-6
   Tamrakar D, 2016, J VIS COMMUN IMAGE R, V40, P432, DOI 10.1016/j.jvcir.2016.07.008
   Tamrakar D, 2016, MULTIMED TOOLS APPL, V75, P5777, DOI 10.1007/s11042-015-2541-5
   Tamrakar D, 2015, PROCEDIA COMPUT SCI, V54, P491, DOI 10.1016/j.procs.2015.06.056
   Wang M, 2006, 8 INT C SIGN PROC, V4
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu XQ, 2003, PATTERN RECOGN LETT, V24, P2829, DOI 10.1016/S0167-8655(03)00141-7
   Xu Y, 2013, NEUROCOMPUTING, V103, P164, DOI 10.1016/j.neucom.2012.08.038
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang D, 2010, IEEE T INSTRUM MEAS, V59, P480, DOI 10.1109/TIM.2009.2028772
   Zhang L, 2015, IEEE T PATTERN ANAL, V37, P1730, DOI 10.1109/TPAMI.2014.2372764
   Zhang L, 2012, IEEE SIGNAL PROC LET, V19, P663, DOI 10.1109/LSP.2012.2211589
   Zheng Q, 2016, IEEE T INF FOREN SEC, V11, P633, DOI 10.1109/TIFS.2015.2503265
   Zuo W., 2008, International Conference on Pattern Recognition, P1, DOI [10.1109/ICPR.2008.4761868, DOI 10.1109/ICPR.2008.4761868]
NR 63
TC 19
Z9 19
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5665
EP 5679
DI 10.1007/s11042-018-5655-8
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100032
DA 2024-07-18
ER

PT J
AU Sung, CS
   Park, JY
AF Sung, Chang Soo
   Park, Joo Y.
TI A monitoring sensor-based eHealth image system for pressure ulcer
   prevention
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE eHealth image system; Sensor; Pressure ulcer prevention; Smartphone;
   Electronic monitoring system
AB Health information systems use technologies in health care to improve the overall effectiveness of patient care and become important part in health care services. Among other diseases, pressure ulcers, a skin disease arise from prolonged exposure to high pressure points, is required to check patient's body state and an electronic monitoring system enables to support constant body check with sharing accurate data with professionals. Although technological perspectives have advanced for better prevention of pressure ulcer, only few studies have reported experimental results and clinical responses on the preventive methods in terms of its effectiveness and comfort, and most preventive systems for pressure ulcer risk do not fulfill basic requirements such as sufficient reliability, unobtrusiveness, long-term usage and easy monitoring at various types of equipment. The purpose of this study is to examine a monitoring sensor-based eHealth image system to support pressure ulcer treatment and identify the effectiveness of the system presenting the system architecture. The result of this study would provide support and insight of using the eHealth monitoring system to professionals who need to manage and care of patients.
C1 [Sung, Chang Soo] Dongguk Univ, Dept Technol Entrepreneurship, Seoul, South Korea.
   [Park, Joo Y.] Yonsei Univ, Yonsei Business Inst, Seoul, South Korea.
C3 Dongguk University; Yonsei University
RP Park, JY (corresponding author), Yonsei Univ, Yonsei Business Inst, Seoul, South Korea.
EM redsun44@dongguk.edu; park3500@naver.com
OI Park, Joo Yeon/0000-0002-5231-5405
FU Let's Combine Corporation
FX This research was based on the monitoring sensor-based eHealth image
   system for pressure ulcer prevention developed by Let's Combine
   Corporation. Authors are grateful to the company and specially thank to
   Chi Ha Kim, CEO of Let's Combine Corporation for all the support and
   advice to carry out this work.
CR Babbs C. F., 1989, BIOMED INSTRUM TECHN, V24, P363
   Bennett G, 2004, AGE AGEING, V33, P230, DOI 10.1093/ageing/afh086
   Boissy P, 2011, IEEE ENG MED BIO, P5824, DOI 10.1109/IEMBS.2011.6091441
   Chen CF, 2008, BIOMED ENG-APP BAS C, V20, P387, DOI 10.4015/S1016237208000994
   Cho I, 2013, INT J MED INFORM, V82, P1059, DOI 10.1016/j.ijmedinf.2013.06.012
   Chung P, 2013, IEEE ENG MED BIO, P6506, DOI 10.1109/EMBC.2013.6611045
   Dobbins C, 2012, IEEE ICC, P6101, DOI 10.1109/ICC.2012.6364905
   Elfehri J., 2011, Proceedings of the 2011 IEEE International Conference on Mechatronics and Automation (ICMA 2011), P265, DOI 10.1109/ICMA.2011.5985668
   Esposito C, 2014, INFORM SYST, V39, P22, DOI 10.1016/j.is.2013.07.002
   Fard FD, 2013, IRAN CONF ELECTR ENG
   Farshbaf M, 2011, IEEE INT C BIO BIO W, P897, DOI 10.1109/BIBMW.2011.6112493
   Fife MM, 2001, J EXP BIOL, V204, P2371
   Fulton WS., 1993, PROC ANN INT C IEEE, V15, P98, DOI 10.1109/IEMBS.1993.978448
   Hayn D, 2015, J SENSORS, V2015, DOI 10.1155/2015/106537
   Hsia CC, 2009, IEEE ENG MED BIO, P6131, DOI 10.1109/IEMBS.2009.5334694
   Im KC, 1996, J KOREAN ACAD ADULT, V8, P274
   Kim GS, 1998, J KOREAN ACAD FUNDAM, V5, P181
   Marchione FG, 2015, INT J MED INFORM, V84, P725, DOI 10.1016/j.ijmedinf.2015.05.013
   Naghdi S, 2016, INFORM SYST, V56, P135, DOI 10.1016/j.is.2015.09.010
   Pérennou T, 2011, EURASIP J WIREL COMM, DOI 10.1155/2011/347107
   Wang F., 2010, WIRELESS HLTH 2010 W, P222
   Williams G, 1997, P ANN INT IEEE EMBS, V19, P1076, DOI 10.1109/IEMBS.1997.756535
   Wound Ostomy and Continence Nurses Society (WOCN), 2016, WOCN CLIN PRACTICE G, P164
   Yousefi R, 2011, IEEE ENG MED BIO, P7175, DOI 10.1109/IEMBS.2011.6091813
   Yu-Sheng Chiou, 1999, Chinese Journal of Medical and Biological Engineering, V19, P169
NR 25
TC 3
Z9 3
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5255
EP 5267
DI 10.1007/s11042-017-4992-3
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100010
DA 2024-07-18
ER

PT J
AU Chiu, CY
   Chiu, JS
   Markchit, S
   Chou, SH
AF Chiu, Chih-Yi
   Chiu, Jih-Sheng
   Markchit, Sarawut
   Chou, Sheng-Hao
TI Effective product quantization-based indexing for nearest neighbor
   search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Approximate nearest neighbor search; Product quantization; Learning to
   rank; Deep neural networks
AB Product quantization is a widely used lossy compression technique that can generate high quantization levels by a compact codebook set. It has been conducted in cluster-based index structures, termed as product quantization-based indexing. In this paper, we propose a novel product quantization-based indexing method for approximate nearest neighbor search. Inspired by the study for learning to rank, a ranking scheme is presented to learn the weighting relation between query-dependent features. The clusters in an index table are ranked by the relevance scores derived from the weighted features with respect to the query. We then present an approximate nearest neighbor search algorithm integrating the proposed ranking scheme with the product quantization-based index structure. Experimental results on the billion-level datasets demonstrate the effectiveness and superiority of the proposed method compared with several state-of-the-art methods.
C1 [Chiu, Chih-Yi; Chiu, Jih-Sheng; Markchit, Sarawut; Chou, Sheng-Hao] Natl Chiayi Univ, Dept Comp Sci & Informat Engn, 300 Syuefu Rd, Chiayi 60004, Taiwan.
C3 National Chiayi University
RP Chiu, CY (corresponding author), Natl Chiayi Univ, Dept Comp Sci & Informat Engn, 300 Syuefu Rd, Chiayi 60004, Taiwan.
EM cychiu@mail.ncyu.edu.tw
RI Chiu, Chih-Yi/AAN-2961-2020
OI Chiu, Chih-Yi/0000-0002-2859-6120; Markchit, Sarawut/0000-0002-7555-4724
CR [Anonymous], 2014, Hashing for similarity search: A survey
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2011, ICML
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], P IEEE INT C COMP VI
   Babenko A, 2016, PROC CVPR IEEE, P2055, DOI 10.1109/CVPR.2016.226
   Babenko A, 2015, IEEE T PATTERN ANAL, V37, P1247, DOI 10.1109/TPAMI.2014.2361319
   Babenko A, 2014, PROC CVPR IEEE, P931, DOI 10.1109/CVPR.2014.124
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Chen YJ, 2010, SENSORS-BASEL, V10, P11259, DOI 10.3390/s101211259
   Chiu CY, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2990504
   Dai Q, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1247, DOI 10.1145/2964284.2964331
   Dong W, 2008, P ACM INT C INF RETR, P128
   Ge TZ, 2014, LECT NOTES COMPUT SC, V8695, P250, DOI 10.1007/978-3-319-10584-0_17
   Gordo A, 2014, IEEE T PATTERN ANAL, V36, P33, DOI 10.1109/TPAMI.2013.101
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Jégou H, 2011, INT CONF ACOUST SPEE, P861
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Kalantidis Y, 2014, P IEEE INT C COMP VI
   Li J, 2017, MULTIMED TOOLS APPL, V76, P23273, DOI 10.1007/s11042-016-4023-9
   Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862
   Liu W, 2012, P IEEE INT C COMP VI, P2123
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Martinez J, 2016, LECT NOTES COMPUT SC, V9906, P137, DOI 10.1007/978-3-319-46475-6_9
   Matsui Y, 2015, IEEE I CONF COMP VIS, P1940, DOI 10.1109/ICCV.2015.225
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376
   Norouzi M., 2013, P IEEE INT C COMP VI
   Pauleve L, 2010, PATTERN RECOGN LETT, V31, P1348, DOI 10.1016/j.patrec.2010.04.004
   Silpa-Anan C, 2008, P IEEE INT C COMP VI
   Torralba A., 2008, P IEEE INT C COMP VI
   Wang JC, 2014, KEY ENG MATER, V579-580, P517, DOI 10.4028/www.scientific.net/KEM.579-580.517
   Wei BC, 2014, IEEE MULTIMEDIA, V21, P41, DOI 10.1109/MMUL.2013.65
   Weiss Y, 2012, LECT NOTES COMPUT SC, V7576, P340, DOI 10.1007/978-3-642-33715-4_25
   Xia Y, 2013, IEEE I CONF COMP VIS, P3416, DOI 10.1109/ICCV.2013.424
   Zhang T, 2014, P INT C MACH LEARN I
   Zhang T, 2015, PROC CVPR IEEE, P4548, DOI 10.1109/CVPR.2015.7299085
   Zhang Xiangyu, 2015, P IEEE INT C COMP VI, P1026
NR 38
TC 3
Z9 3
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 2877
EP 2895
DI 10.1007/s11042-018-6059-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600012
DA 2024-07-18
ER

PT J
AU Hao, PT
   Hu, L
   Zhao, K
   Jiang, JY
   Li, T
   Che, XL
AF Hao, Pingting
   Hu, Liang
   Zhao, Kuo
   Jiang, Jingyan
   Li, Tong
   Che, Xilong
TI Dynamic pricing with traffic engineering for adaptive video streaming
   over software-defined content delivery networking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content delivery network; Software defined network; Multimedia; Pricing
   model; Traffic engineering; Network utility theory
ID ALGORITHM; SERVICE; SECURE
AB Multimedia content has become widespread in network traffic. The high volume of data and flexibility must be addressed to guarantee the quality of experience (QoE) in large-scale adaptive video streaming services. Despite the abundance of recently proposed strategies, most concentrate on improving different aspects of performance over user fairness and initiation. We propose Dynamic Pricing with Traffic Engineering (DPTE), a prototype that generates traffic distribution using a market-driven model. In DPTE, users specify required rates, and a price module gives the current value based on observation of the states of servers as well as networks. DPTE periodically runs a heuristic algorithm that selects the path with the appropriate pricing to guarantee the service based on the software-defined content delivery networking (SDCDN) platform. As a result, DPTE not only relies on pricing to reflect the objective properties from the performance perspective but also utilizes pricing rules to influence the choice of users. Evaluation results on Youtube data show that DPTE outperforms competitive pricing rules in most cases, including path utility, user satisfaction and revenue.
C1 [Hao, Pingting; Hu, Liang; Zhao, Kuo; Jiang, Jingyan; Che, Xilong] JiLin Univ, Dept Comp Sci, Qianjin St, Changchun 130000, Jilin, Peoples R China.
   [Li, Tong] Guangzhou Univ, Dept Comp Sci, Guangzhou, Guangdong, Peoples R China.
C3 Jilin University; Guangzhou University
RP Che, XL (corresponding author), JiLin Univ, Dept Comp Sci, Qianjin St, Changchun 130000, Jilin, Peoples R China.
EM haopt15@mails.jlu.edu.cn; hul@jlu.edu.cn; zhaokuo@jlu.edu.cn;
   jiangjy14@mails.jlu.edu.cn; litongziyi@mail.nankai.edu.cn;
   chexilong@jlu.edu.cn
RI li, tong/HPC-6702-2023
FU National Key RD Plan of China [2017YFA0604500]; National Sci-Tech
   Support Plan of China [2014BAH02F00]; National Natural Science
   Foundation of China [61701190]; Youth Science Foundation of Jilin
   Province of China [20160520011JH, 20180520021JH]; Youth Sci-Tech
   Innovation Leader and Team Project of Jilin Province of China
   [20170519017JH]; Key Technology Innovation Cooperation Project of
   Government and University [SXGJSF2017-4]; Key scientific and
   technological R&D Plan of Jilin Province of China [20180201103GX]
FX This work is funded by the National Key R&D Plan of China under Grant
   No. 2017YFA0604500, National Sci-Tech Support Plan of China under Grant
   No. 2014BAH02F00, by the National Natural Science Foundation of China
   under Grant No. 61701190, by the Youth Science Foundation of Jilin
   Province of China under Grant No. 20160520011JH and No. 20180520021JH,
   by Youth Sci-Tech Innovation Leader and Team Project of Jilin Province
   of China under Grant No. 20170519017JH, and by the Key Technology
   Innovation Cooperation Project of Government and University for the
   whole Industry Demonstration under Grant No. SXGJSF2017-4. Key
   scientific and technological R&D Plan of Jilin Province of China under
   Grant No. 20180201103GX.
CR Adhikari VK, 2012, IEEE INFOCOM SER, P1620, DOI 10.1109/INFCOM.2012.6195531
   [Anonymous], 2012, P IEEE AS PAC SIGN I
   Benchaita W, 2015, ACM SIGCOMM COMP COM, V45, P347, DOI 10.1145/2829988.2790016
   Bhushan K, 2017, MULTIMED TOOLS APPL, V3, P1
   Cheng X, 2008, INT WORKSH QUAL SERV, P249
   Courcoubetis Costas A., 2003, WILEY INTERSCIENCE S
   Dobrian F, 2011, ACM SIGCOMM COMP COM, V41, P362, DOI 10.1145/2043164.2018478
   Egilmez HE, 2014, IEEE T MULTIMEDIA, V16, P1597, DOI 10.1109/TMM.2014.2325791
   Ercetin O, 2005, COMPUT NETW, V49, P840, DOI 10.1016/j.comnet.2005.03.001
   Fan LS, 2017, IEEE T VEH TECHNOL, V66, P7599, DOI 10.1109/TVT.2017.2669240
   Fan LS, 2016, IEEE J-STSP, V10, P1494, DOI 10.1109/JSTSP.2016.2607692
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Hai AT, 2013, IEEE T COMPUT, V99, P2803
   Hande P, 2009, IEEE INFOCOM SER, P990, DOI 10.1109/INFCOM.2009.5062010
   Holden J., 2016, ELEVATE FAST FORWARD
   Hosanagar K, 2004, IEEE COMPUT SOC, V7, P10
   Huang T.Y., 2012, P 2012 ACM C INT MEA, P225, DOI 10.1145/2398776.2398800
   Ibtihal M, 2017, INT J CLOUD APPL COM, V7, P27, DOI 10.4018/IJCAC.2017040103
   Jalaparti V, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '16), P73, DOI 10.1145/2934872.2934893
   Jararweh Y, 2017, COMPUT J, V60, P1443, DOI 10.1093/comjnl/bxx019
   Jiang T, 2015, FUTURE GENER COMP SY, V52, P86, DOI 10.1016/j.future.2014.11.002
   Khare V, 2012, C LOCAL COMPUT NETW, P610, DOI 10.1109/LCN.2012.6423682
   Krishnan SS, 2013, IEEE ACM T NETWORK, V21, P2001, DOI 10.1109/TNET.2013.2281542
   Kua J, 2017, IEEE COMMUN SURV TUT, V19, P1842, DOI 10.1109/COMST.2017.2685630
   Lai XZ, 2017, IEEE ACCESS, V5, P18909, DOI 10.1109/ACCESS.2017.2751105
   Lin W, 2015, SOFT COMPUT, V27, P1
   Lin WW, 2017, IEEE ACCESS, V5, P16568, DOI 10.1109/ACCESS.2017.2738069
   Lin WW, 2017, INFORM SCIENCES, V397, P168, DOI 10.1016/j.ins.2017.02.054
   Liu BY, 2015, TSINGHUA SCI TECHNOL, V20, P285, DOI 10.1109/TST.2015.7128941
   Memos VA, 2018, FUTURE GENER COMP SY, V83, P619, DOI 10.1016/j.future.2017.04.039
   Meng WZ, 2018, IEEE ACCESS, V6, P10179, DOI 10.1109/ACCESS.2018.2799854
   Nam H, 2014, IEEE GLOB COMM CONF, P1317, DOI 10.1109/GLOCOM.2014.7036990
   Odlyzko A., 1999, EC '99, P140, DOI DOI 10.1145/336992.337030
   Schwarz M, 2006, QUEUEING SYST, V54, P55, DOI 10.1007/s11134-006-8710-5
   Sun Y, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '16), P272, DOI 10.1145/2934872.2934898
   Szymaniak M, 2003, IAD INT C WWW INT 20, P435
   Wang XN, 2015, IEEE COMMUN LETT, V19, P135, DOI 10.1109/LCOMM.2014.2385052
   Wang Y, 2017, INT J PARALLEL PROG, V45, P827, DOI 10.1007/s10766-016-0445-2
   Wang YF, 2014, SCI CHINA MATH, V57, P1, DOI 10.1007/s11425-013-4750-6
   Xie GG, 2018, IEEE T CIRC SYST VID, V28, P1183, DOI 10.1109/TCSVT.2017.2652487
   Zhang YW, 2015, TSINGHUA SCI TECHNOL, V20, P90, DOI 10.1109/TST.2015.7040518
   Zhou J, 2013, TSINGHUA SCI TECHNOL, V18, P369, DOI 10.1109/TST.2013.6574675
   Zkik K, 2017, INT J CLOUD APPL COM, V7, P62, DOI 10.4018/IJCAC.2017040105
NR 43
TC 2
Z9 2
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3471
EP 3492
DI 10.1007/s11042-018-6111-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600045
DA 2024-07-18
ER

PT J
AU Jararweh, Y
   Al-Ayyoub, M
   Fakirah, M
   Alawneh, L
   Gupta, BB
AF Jararweh, Yaser
   Al-Ayyoub, Mahmoud
   Fakirah, Maged
   Alawneh, Luay
   Gupta, Brij B.
TI Improving the performance of the needleman-wunsch algorithm using
   parallelization and vectorization techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bioinformatics; Global alignment; Needleman-Wunsch; POSIX threads; SIMD
   (Single Instruction Multiple Data); Graphics Processing Unit (GPU)
ID SEQUENCE ALIGNMENT; SPEED-UP; MAFFT
AB The Needleman-Wunsch (NW) is a dynamic programming algorithm used in the pairwise global alignment of two biological sequences. In this paper, three sets of parallel implementations of the NW algorithm are presented using a mixture of specialized software and hardware solutions: POSIX Threads-based, SIMD Extensions-based and a GPU-based implementations. The three implementations aim at improving the performance of the NW algorithm on large scale input without affecting its accuracy. Our experiments show that the GPU-based implementation is the best implementation as it achieves performance 72.5X faster than the sequential implementation, whereas the best performance achieved by the POSIX threads and the SIMD techniques are 2X and 18.2X faster than the sequential implementation, respectively.
C1 [Jararweh, Yaser; Al-Ayyoub, Mahmoud; Fakirah, Maged] Jordan Univ Sci & Technol, Comp Sci, Irbid, Jordan.
   [Alawneh, Luay] Jordan Univ Sci & Technol, Dept Software Engn, Irbid, Jordan.
   [Gupta, Brij B.] Natl Inst Technol Kurukshetra, Kurukshetra, Haryana, India.
C3 Jordan University of Science & Technology; Jordan University of Science
   & Technology; National Institute of Technology (NIT System); National
   Institute of Technology Kurukshetra
RP Jararweh, Y (corresponding author), Jordan Univ Sci & Technol, Comp Sci, Irbid, Jordan.
EM yijararweh@just.edu.jo
RI Jararweh, Yaser/ABE-6543-2021; Jararweh, Yaser/JCO-2836-2023; Gupta,
   Brij B/E-9813-2011; Alawneh, Luay/GPC-8269-2022
OI Gupta, Brij B/0000-0003-4929-4698; Alawneh, Luay/0000-0002-5152-8636;
   Fakirah, Maged/0000-0002-3714-4468
FU Jordan University of Science and Technology [20150050]
FX The authors would like to thank the Deanship of Research at the Jordan
   University of Science and Technology for funding this work, grant number
   20150050. Also, they would like to thank Alexandros Stamatakis and Tomas
   Flouri from HITS, Germany, for their support.
CR Alsmirat MA, 2017, MULTIMED TOOLS APPL, V76, P3537, DOI 10.1007/s11042-016-3884-2
   [Anonymous], 2015, 2015 IEEE ACS 12 INT
   [Anonymous], 1998, BIOL SEQUENCE ANAL P
   [Anonymous], 1997, Introduction to computational molecular biology
   Balhaf K, 2017, INT CONF INFORM COMM, P7, DOI 10.1109/IACS.2017.7921937
   Balhaf K, 2016, INT CONF INFORM COMM, P80, DOI 10.1109/IACS.2016.7476090
   Butenhof David R., 1997, Programming with POSIX threads
   CHAN SC, 1992, B MATH BIOL, V54, P563, DOI 10.1007/BF02459635
   Cook S, 2013, CUDA PROGRAMMING: A DEVELOPER'S GUIDE TO PARALLEL COMPUTING WITH GPUS, P1, DOI 10.1016/B978-0-12-415933-4.00001-6
   Sandes EFD, 2016, IEEE T PARALL DISTR, V27, P2838, DOI 10.1109/TPDS.2016.2515597
   El-Metwally S, 2014, SPRINGER SCI BUS, V7, P16
   Farrar M, 2007, BIOINFORMATICS, V23, P156, DOI 10.1093/bioinformatics/btl582
   Gebali F., 2011, Algorithms and parallel computing, V84
   GOTOH O, 1982, J MOL BIOL, V162, P705, DOI 10.1016/0022-2836(82)90398-9
   Jones C, 2004, INTRO BIOINFORMATICS
   Katoh K, 2008, BRIEF BIOINFORM, V9, P286, DOI 10.1093/bib/bbn013
   Liu YC, 2015, CONCURR COMP-PRACT E, V27, P958, DOI 10.1002/cpe.3371
   Lomont C., 2011, CISC VIS NETW IND GL
   NEEDLEMAN SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4
   Serrano JP, 2017, LECT N BIOINFORMAT, V10209, P512, DOI 10.1007/978-3-319-56154-7_46
   Rognes T, 2000, BIOINFORMATICS, V16, P699, DOI 10.1093/bioinformatics/16.8.699
   Rognes T, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-221
   Sanders J, 2010, CUDA EXAMPLE INTRO G
   Shehab MA, 2015, 2015 6TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION SYSTEMS (ICICS), P130, DOI 10.1109/IACS.2015.7103215
   Siriwardena T. R. P., 2010, Proceedings of the 2010 5th International Conference on Information and Automation for Sustainability (ICIAfS), P201, DOI 10.1109/ICIAFS.2010.5715660
   Vermij P, 2011, THESIS
   Wozniak A, 1997, COMPUT APPL BIOSCI, V13, P145
   Zhou W, 2017, J SUPERCOMPUT, V73, P4517, DOI 10.1007/s11227-017-2030-x
   Zhu XY, 2015, IEEE ACM T COMPUT BI, V12, P205, DOI 10.1109/TCBB.2014.2351801
NR 29
TC 34
Z9 36
U1 4
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 3961
EP 3977
DI 10.1007/s11042-017-5092-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200006
DA 2024-07-18
ER

PT J
AU Li, HJ
   Meng, WL
   Liu, XY
   Xiang, SM
   Zhang, XP
AF Li, Hongjun
   Meng, Weiliang
   Liu, Xinying
   Xiang, Shiming
   Zhang, Xiaopeng
TI Parameter optimization criteria guided 3D point cloud classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Point cloud classification; Feature extraction; Conditional random
   field; Parameter optimization criterion; Probabilistic neural network
ID MULTISCALE
AB 3D point cloud classification is one of the basic topics in multimedia analysis and understanding. By the construction of the discriminant model and efficient parameter optimization, point cloud classification can be achieved after the training. However, most parameter optimization methods do not guarantee the highest global classification accuracy with a high classification accuracy on smaller classes. In addition, geometric features of the point cloud are not sufficiently utilized. In this paper, we use local geometric shape features including the nearest neighbor tetrahedral volume, Gaussian curvature, the neighbourhood normal vector consistency and the neighbourhood minimum principal curvature direction consistency. We propose three discrete criteria for parameter optimization to design explicit functions, and we present concrete algorithms, in which Monte Carlo method and Probabilistic Neural Network method are employed to estimate these parameters respectively. Experimental results show that our criteria can be applied to the classification of the 3D point cloud of the scene, and can be used to improve the classification accuracy of small-scale point sets when different classes have great disparities in the number.
C1 [Li, Hongjun] Beijing Forestry Univ, Coll Sci, Beijing, Peoples R China.
   [Meng, Weiliang; Liu, Xinying; Xiang, Shiming; Zhang, Xiaopeng] CAS Inst Automat, LIAMA NLPR, Beijing, Peoples R China.
C3 Beijing Forestry University; Chinese Academy of Sciences; Institute of
   Automation, CAS
RP Li, HJ (corresponding author), Beijing Forestry Univ, Coll Sci, Beijing, Peoples R China.
EM lihongjun69@bjfu.edu.cn; xiaopeng.zhang@ia.ac.cn
OI Li, Hongjun/0000-0003-1102-6225
FU Fundamental Research Funds for the Central Universities [2015ZCQ-LY-01];
   National Natural Science Foundation of China [61372190, 61571439,
   61561003, 61502490, 61501464, 6140001010207]
FX This work is partly supported by the Fundamental Research Funds for the
   Central Universities(NO. 2015ZCQ-LY-01), and partly supported by
   National Natural Science Foundation of China with Nos. 61372190,
   61571439, 61561003, 61502490 and 61501464, and partly supported by
   Project 6140001010207.
CR [Anonymous], 2009, IEEE INT C ROB AUT
   [Anonymous], LNCS
   [Anonymous], IMAGE ANAL
   [Anonymous], 2012, 22 ISPRS C TECHN COM, DOI DOI 10.5194/ISPRSANNALS-I-3-263-2012
   [Anonymous], 2001, PROC 18 INT C MACH L
   Berger M, 2017, COMPUT GRAPH FORUM, V36, P301, DOI 10.1111/cgf.12802
   Brodu N, 2012, ISPRS J PHOTOGRAMM, V68, P121, DOI 10.1016/j.isprsjprs.2012.01.006
   Chen L, 2017, J COMPUT CIVIL ENG, V31, DOI 10.1061/(ASCE)CP.1943-5487.0000631
   Chen Y., 2006, STAT, V22, P69
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   FROME A, 1998, LECT NOTES COMPUT SC, V3023, P224
   Himmelsbach M, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P994, DOI 10.1109/IROS.2009.5354493
   Holzinger A, 2017, LECT NOTES ARTIF INT, V10344, P13, DOI 10.1007/978-3-319-69775-8_2
   Hu X., 2016, REMOTE SENS, V8, P730
   Husain F, 2014, INT C PATT RECOG, P4257, DOI 10.1109/ICPR.2014.730
   Jin H, 2017, COMPUT AIDED GEOM D, V50, P1, DOI 10.1016/j.cagd.2016.11.001
   Kang ZZ, 2017, IEEE J-STARS, V10, P1651, DOI 10.1109/JSTARS.2016.2628775
   Kumar S, 2006, INT J COMPUT VISION, V68, P179, DOI 10.1007/s11263-006-7007-9
   Lalonde JF, 2006, J FIELD ROBOT, V23, P839, DOI 10.1002/rob.20134
   [李红军 Li Hongjun], 2017, [浙江大学学报. 理学版, Journal of Zhejiang University. Sciences Edition], V44, P1
   Liu XY, 2017, LECT NOTES COMPUT SC, V10345, P115, DOI 10.1007/978-3-319-65849-0_14
   Maligo A, 2017, IEEE T AUTOM SCI ENG, V14, P5, DOI 10.1109/TASE.2016.2614923
   Mount DM, 2012, ANN PROGRAMMING MANU
   Munoz D, 2009, IEEE COMP SOC C COMP
   Munoz D, 2008, INT S 3 DAT PROC VIS
   Najafi M, 2014, NONASSOCIATIVE HIGHE, P500
   Ni H, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9030288
   Niemeyer J, 2016, INT ARCH PHOTOGRAMM, V41, P655, DOI 10.5194/isprsarchives-XLI-B3-655-2016
   Paulus S, 2013, BMC BIOINFORMATICS, V14, DOI 10.1186/1471-2105-14-238
   Plaza-Leiva V, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030594
   Rodríguez-Cuenca B, 2015, REMOTE SENS-BASEL, V7, P12680, DOI 10.3390/rs71012680
   Rumelhart D.E., 1988, Nature, P696
   Rutzinger M, 2008, SENSORS-BASEL, V8, P4505, DOI 10.3390/s8084505
   Shapovalov R., 2010, INT ARCH PHOTOGRAMM, V38, P103
   Shiming Xiang, 2006, Advances in Multimedia Modeling. 13th International Multimedia Modeling Conference, MMM 2007. Proceedings (Lecture Notes in Computer Science Vol.4351), P24
   SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q
   Sutton C, 2012, FOUND TRENDS MACH LE, V4, P267, DOI 10.1561/2200000013
   Vosselman G, 2013, INT ARCH PHOTOGRAMM, V40-7-W2, P257, DOI 10.5194/isprsarchives-XL-7-W2-257-2013
   Wang Z, 2015, IEEE T GEOSCI REMOTE, V53, P2409, DOI 10.1109/TGRS.2014.2359951
   Weinmann M, 2015, ISPRS J PHOTOGRAMM, V105, P286, DOI 10.1016/j.isprsjprs.2015.01.016
   Wolf D, 2015, IEEE INT CONF ROBOT, P4867, DOI 10.1109/ICRA.2015.7139875
   Yang JQ, 2016, INFORM SCIENCES, V346, P163, DOI 10.1016/j.ins.2016.01.095
   Zhang X., 2009, J. Inf. Comput. Sci., V6, P1983
   Zhang XP, 2014, IEEE T VIS COMPUT GR, V20, P1214, DOI 10.1109/TVCG.2014.2316001
   Zhang ZX, 2016, IEEE T GEOSCI REMOTE, V54, P3309, DOI 10.1109/TGRS.2016.2514508
NR 45
TC 2
Z9 3
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 5081
EP 5104
DI 10.1007/s11042-018-6838-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200059
DA 2024-07-18
ER

PT J
AU Xiao, X
   Zhang, SF
   Mercaldo, F
   Hu, GW
   Sangaiah, AK
AF Xiao, Xi
   Zhang, Shaofeng
   Mercaldo, Francesco
   Hu, Guangwu
   Sangaiah, Arun Kumar
TI Android malware detection based on system call sequences and LSTM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Android malware detection; System call sequences; Deep learning; LSTM
   language model
AB As Android-based mobile devices become increasingly popular, malware detection on Android is very crucial nowadays. In this paper, a novel detection method based on deep learning is proposed to distinguish malware from trusted applications. Considering there is some semantic information in system call sequences as the natural language, we treat one system call sequence as a sentence in the language and construct a classifier based on the Long Short-Term Memory (LSTM) language model. In the classifier, at first two LSTM models are trained respectively by the system call sequences from malware and those from benign applications. Then according to these models, two similarity scores are computed. Finally, the classifier determines whether the application under analysis is malicious or trusted by the greater score. Thorough experiments show that our approach can achieve high efficiency and reach high recall of 96.6% with low false positive rate of 9.3%, which is better than the other methods.
C1 [Xiao, Xi; Zhang, Shaofeng] Tsinghua Univ, Grad Sch Shenzhen, Shenzhen 518055, Peoples R China.
   [Mercaldo, Francesco] Natl Res Council Italy, Inst Informat & Telemat, I-56124 Pisa, Italy.
   [Hu, Guangwu] Shenzhen Inst Informat Technol, Sch Comp Sci, Shenzhen 518172, Peoples R China.
   [Sangaiah, Arun Kumar] VIT Univ, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.
C3 Tsinghua Shenzhen International Graduate School; Tsinghua University;
   Consiglio Nazionale delle Ricerche (CNR); Istituto di Informatica e
   Telematica (IIT-CNR); Shenzhen Institute of Information Technology;
   Vellore Institute of Technology (VIT); VIT Vellore
RP Hu, GW (corresponding author), Shenzhen Inst Informat Technol, Sch Comp Sci, Shenzhen 518172, Peoples R China.
EM hugw@sziit.edu.cn
RI Sangaiah, Arun Kumar/U-6785-2019
OI Sangaiah, Arun Kumar/0000-0002-0229-2460; HU,
   Guangwu/0000-0003-3947-9998
FU NSFC [61375054, 61402255, 61202358]; National High-tech R&D Program of
   China [2015AA016102]; Guangdong Natural Science Foundation
   [2015A030310492, 2014A030313745]; RD Program of Shenzhen
   [JCYJ20150630170146831, JCYJ20160301152145171, JCYJ20160531174259309,
   JSGG20150512162853495, Shenfagai [2015] 986]; Cross fund of Graduate
   School at Shenzhen, Tsinghua University [JC20140001]
FX This work is supported by the NSFC projects (61375054, 61402255,
   61202358), the National High-tech R&D Program of China (2015AA016102),
   Guangdong Natural Science Foundation (2015A030310492, 2014A030313745)
   and the RD Program of Shenzhen (JCYJ20150630170146831,
   JCYJ20160301152145171, JCYJ20160531174259309, JSGG20150512162853495,
   Shenfagai [2015] 986), and Cross fund of Graduate School at Shenzhen,
   Tsinghua University (JC20140001).
CR [Anonymous], 2015, 6 1B SMARTPHONE USER
   [Anonymous], NEURAL NETWORK BASED
   [Anonymous], 2013, Inter- national Journal of Scientific and Technology Research
   Arp D, 2014, 21ST ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2014), DOI 10.14722/ndss.2014.23247
   Battista P, 2016, P INT C INF SYST SEC
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Canfora G., 2015, P 3 INT WORKSH SOFTW, P13, DOI [10.1145/2804345.2804349, DOI 10.1145/2804345.2804349]
   Canfora G, 2016, COMPUT SECUR, V61, P1, DOI 10.1016/j.cose.2016.04.009
   Chen PS, 2015, INFORM SCIENCES, V321, P193, DOI 10.1016/j.ins.2015.04.035
   Chen S, 2016, ASIA CCS'16: PROCEEDINGS OF THE 11TH ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P377, DOI 10.1145/2897845.2897860
   Dimjasevic M, 2016, IWSPA'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL WORKSHOP ON SECURITY AND PRIVACY ANALYTICS, P1, DOI 10.1145/2875475.2875487
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Feng Y, 2014, 22ND ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (FSE 2014), P576, DOI 10.1145/2635868.2635869
   FireEye Out of Pocket, 2015, COMPR MOB THREAT ASS
   Graves A, 2012, STUD COMPUT INTELL, V385, P37
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Li Q, 2015, 2015 INTERNATIONAL CONFERENCE ON CYBER-ENABLED DISTRIBUTED COMPUTING AND KNOWLEDGE DISCOVERY, P84, DOI 10.1109/CyberC.2015.88
   Li Y., 2015, Security and Privacy in Communication Networks-11th International Conference, SecureComm 2015, Dallas, TX, USA, October 26-29, 2015, Revised Selected Papers, volume 164 of SecureComm' 15, V164, P23, DOI 10.1007/978-3-319-28865-9_2
   Mercaldo F, 2016, FME WORKS FORM, P22, DOI [10.1145/2897667.2897673, 10.1109/FormaliSE.2016.012]
   Mercaldo F, 2016, LECT NOTES COMPUT SC, V9688, P212, DOI 10.1007/978-3-319-39570-8_14
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Rashidi B, 2017, COMPUT SECUR, V65, P90, DOI 10.1016/j.cose.2016.11.006
   Saracino Andrea, 2018, IEEE Transactions on Dependable and Secure Computing, V15, P83, DOI 10.1109/TDSC.2016.2536605
   Sundermeyer M, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P194
   Wang ZG, 2015, IEEE CONF COMM NETW, P727, DOI 10.1109/CNS.2015.7346906
   Wu Wen-Chieh, 2014, Proceedings of the 2014 Conference on Research in Adaptive and Convergent Systems, RACS 2014, Towson, Maryland, USA, October 5-8, 2014, RACS'14, P247
   Xiao X, 2017, IET INFORM SECUR, V11, P8, DOI 10.1049/iet-ifs.2015.0211
   Xu K, 2016, IEEE T INF FOREN SEC, V11, P1252, DOI 10.1109/TIFS.2016.2523912
   Yeh CW, 2016, 2016 RESEARCH IN ADAPTIVE AND CONVERGENT SYSTEMS, P130, DOI 10.1145/2987386.2987406
   Zhou Y, 2013, ANDROID MALWARE
   Zhou YJ, 2012, P IEEE S SECUR PRIV, P95, DOI 10.1109/SP.2012.16
NR 32
TC 125
Z9 138
U1 3
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 3979
EP 3999
DI 10.1007/s11042-017-5104-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200007
DA 2024-07-18
ER

PT J
AU Chen, CT
   Jang, JSR
AF Chen, Chunta
   Jang, Jyh-Shing Roger
TI An effective method for audio-to-score alignment using onsets and
   modified constant Q spectra
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music synchronization; Audio-to-score alignment; Audio onset detection;
   Score following
ID SOUND SEPARATION
AB This paper proposes an effective algorithm for polyphonic audio-to-score alignment that aligns a polyphonic music performance to its corresponding score. The proposed framework consists of three steps: onset detection, note matching, and dynamic programming. In the first step, onsets are detected and then onset features are extracted by applying the constant Q transform around each onset. A similarity matrix is computed using a note-matching function to evaluate the similarity between concurrent notes in the music score and onsets in the audio recording. Finally, dynamic programming is used to extract the optimal alignment path in the similarity matrix. We compared five onset detectors and three spectrum difference vectors at selected audio onsets. The experimental results revealed that our method achieved higher precision than did the other algorithms included for comparison. This paper also proposes an online approach based on onset detection that can detect most notes within only 10ms. Based on our experimental results, this online approach outperforms all methods included for comparison when the tolerance window is 50ms.
C1 [Chen, Chunta] Natl Tsing Hua Univ, Comp Sci Dept, Hsinchu, Taiwan.
   [Jang, Jyh-Shing Roger] Natl Taiwan Univ, Comp Sci Dept, Taipei, Taiwan.
C3 National Tsing Hua University; National Taiwan University
RP Chen, CT (corresponding author), Natl Tsing Hua Univ, Comp Sci Dept, Hsinchu, Taiwan.
EM chun-ta.chen@mirlab.org; jang@mirlab.org
FU Ministry of Science and Technology, ROC; MOST [104-2221-E-002-051-MY3]
FX This research is partially supported by Ministry of Science and
   Technology, ROC, under Grant no. MOST 104-2221-E-002-051-MY3.
CR [Anonymous], 2013, P INT SOC MUSIC INFO
   Arzt A, 2008, FRONT ARTIF INTEL AP, V178, P241, DOI 10.3233/978-1-58603-891-5-241
   Bello JP, 2005, IEEE T SPEECH AUDI P, V13, P1035, DOI 10.1109/TSA.2005.851998
   Bock S., 2013, P 16 INT C DIG AUD E, P55
   Bock S, 2016, P 2016 ACM C MULTIME, P1174, DOI 10.1145/2964284.2973795
   BROWN JC, 1991, J ACOUST SOC AM, V89, P425, DOI 10.1121/1.400476
   Cai JJ, 2014, 2014 6TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS, P672, DOI 10.1109/CICN.2014.149
   Carabias-Orti JulioJose., 2015, CONFERENCE, P742
   Chen CT, 2016, INT CONF ACOUST SPEE, P2802, DOI 10.1109/ICASSP.2016.7472188
   Chun-Ta Chen, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1365, DOI 10.1109/ICASSP.2014.6853820
   CONT A, 2006, INT CONF ACOUST SPEE, P245
   Cont A., 2007, Proc. International Conference on Music Infor- mation Retrieval (ISMIR), P315
   Dannenberg R., 2003, Proceedings of the International Computer Music Conference, P27
   Dannenberg R, 1984, P 1984 INT COMP MUS, P193
   Degara-Quintela N, 2009, P 10 INT SOC MUS INF, P117
   Dixon S., 2006, P 9 INT C DIGITAL AU, P133
   Dorfer Matthias, 2017, P INT SOC MUS INF RE, P115
   Duan ZY, 2011, IEEE J-STSP, V5, P1205, DOI 10.1109/JSTSP.2011.2159701
   Duxbury C, 2003, Digital Media: Processing Multimedia Interactive Services, P275, DOI 10.1142/9789812704337_0050
   Eyben F., 2010, Proceedings of the 11th International Society for Music Information Retrieval Conference, P589, DOI 10.5281/zenodo.1417131
   Holzapfel A, 2010, IEEE T AUDIO SPEECH, V18, P1517, DOI 10.1109/TASL.2009.2036298
   Hu N, 2003, 2003 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS PROCEEDINGS, P185, DOI 10.1109/ASPAA.2003.1285862
   Joder C, 2013, IEEE T AUDIO SPEECH, V21, P2118, DOI 10.1109/TASL.2013.2266794
   Joder C, 2011, IEEE T AUDIO SPEECH, V19, P2385, DOI 10.1109/TASL.2011.2134092
   Rodriguez-Serrano FJ, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2926717
   Lacoste A, 2005, P INT C MUS INF RETR
   Lacoste A, 2007, EURASIP J ADV SIG PR, P153
   Lerch A, 2012, INTRO AUDIO CONTENT, P148
   Muller M., 2007, Information Retrieval for Music and Motion, P85
   Ono N, 2010, STUD COMPUT INTELL, V274, P213
   Orio N, 2003, P 2003 C NEW INT MUS, P34
   Orio N., 2001, Proc. International Computer Music Conference (ICMC), P155
   Raffel C, 2016, INT CONF ACOUST SPEE, P81, DOI 10.1109/ICASSP.2016.7471641
   Sako S, 2014, LECT NOTES COMPUT SC, V8610, P134, DOI 10.1007/978-3-319-09912-5_12
   Salamon J, 2014, IEEE SIGNAL PROC MAG, V31, P118, DOI 10.1109/MSP.2013.2271648
   Schluter Jan, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6979, DOI 10.1109/ICASSP.2014.6854953
   Schluter Jan., 2013, INT WORKSHOP MACHINE, P1
   Song XM, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2832907
   Tachibana H, 2014, IEEE-ACM T AUDIO SPE, V22, P2059, DOI 10.1109/TASLP.2014.2351131
   Tian M., 2014, ISMIR, P631
   Ueda Y, 2010, INT CONF ACOUST SPEE, P5518, DOI 10.1109/ICASSP.2010.5495218
   Wang SY, 2016, IEEE-ACM T AUDIO SPE, V24, P2132, DOI 10.1109/TASLP.2016.2598318
NR 42
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 2017
EP 2044
DI 10.1007/s11042-018-6349-y
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700034
DA 2024-07-18
ER

PT J
AU Hammad, M
   Luo, GN
   Wang, KQ
AF Hammad, Mohamed
   Luo, Gongning
   Wang, Kuanquan
TI Cancelable biometric authentication system based on ECG
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ECG; Cancelable biometrics; Improved Bio-Hashing; Matrix operation; FFNN
ID CANCELLABLE BIOMETRICS
AB Biometrics are widely deployed in various security systems; however, they have drawbacks in the form of leakage or stealing, therefore numerous solutions have been proposed to secure biometric template such as cancelable biometric, which is one of the possible solutions for canceling and securing biometric template. However, this problem is still open and to the best of our knowledge, few previous studies have proposed a complete authentic system using the cancelable biometric techniques based on electrocardiogram (ECG). In this paper, we have applied two cancelable biometric techniques for developing a human authentication system based on ECG signals. The first one is an improved Bio-Hashing and the second one is matrix operation technique. The improved Bio-Hash technique solves the problem of accuracy loss, which is the main drawback of basic Bio-Hash technique. The protected feature vector (Bio-Hashed code) is generated from the inner product between the ECG features matrix and tokenize number matrix. While the matrix operation technique is applied on the ECG feature matrix to produce a transformed template which is irreversible to the original features of the ECG. In the authentication stage, Feed-Forward Neural Network (FFNN) is used to verify individuals. After applying the two cancelable techniques on three public available ECG databases, experimental results show that the proposed system performs better regarding authentication and outperforms state-of-the-art techniques considered.
C1 [Hammad, Mohamed; Luo, Gongning; Wang, Kuanquan] Harbin Inst Technol, Comp Sci & Technol, Harbin, Heilongjiang, Peoples R China.
   [Hammad, Mohamed] Menoufia Univ, Fac Comp & Informat, Informat Technol Dept, Menoufia, Egypt.
C3 Harbin Institute of Technology; Egyptian Knowledge Bank (EKB); Menofia
   University
RP Hammad, M (corresponding author), Harbin Inst Technol, Comp Sci & Technol, Harbin, Heilongjiang, Peoples R China.; Hammad, M (corresponding author), Menoufia Univ, Fac Comp & Informat, Informat Technol Dept, Menoufia, Egypt.
EM mohammed.adel@ci.menofia.edu.eg
RI Luo, Gongning/X-1929-2019; Hammad, Mohamed/U-6169-2019; Wang,
   Kuanquan/JCE-9520-2023
OI Luo, Gongning/0000-0003-3662-0335; Hammad, Mohamed/0000-0002-6506-3083; 
FU National Nature Science Foundation of China (NSFC) [61571165]
FX The authors would like to thank Dr. Loris Nanni for his helpful advice
   in implementing the improved Bio-Hash algorithm. This work was supported
   by the National Nature Science Foundation of China (NSFC) Grant No.
   61571165.
CR Albert A., 1972, Regression and the Moore-Penrose Pseudoinverse. ISSN
   Ang R, 2005, LECT NOTES COMPUT SC, V3574, P242
   [Anonymous], CANCELLABLE BIOMETRI
   Bolle RM, 2002, PATTERN RECOGN, V35, P2727, DOI 10.1016/S0031-3203(01)00247-3
   Connie T, 2005, INFORM PROCESS LETT, V93, P1, DOI 10.1016/j.ipl.2004.09.014
   da Silva HP, 2014, COMPUT METH PROG BIO, V113, P503, DOI 10.1016/j.cmpb.2013.11.017
   Damer N, 2013, LECT NOTES COMPUT SC, V8034, P68, DOI 10.1007/978-3-642-41939-3_7
   Dey Monalisa, 2014, 2014 International Conference on Electronic Systems, Signal Processing and Computing Technologies (ICESC), P300, DOI 10.1109/ICESC.2014.57
   Dey N, 2013, IEEE 3 INT ADV COMP
   El-Khamy SE, 2017, MULTIMED TOOLS APPL, V76, P24091, DOI 10.1007/s11042-016-4113-8
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Islam MS, 2017, MULTIMED TOOLS APPL, V76, P12709, DOI 10.1007/s11042-016-3694-6
   Islam MS, 2017, IEEE ACCESS, V5, P1753, DOI 10.1109/ACCESS.2017.2667224
   Jain A.K., 2003, HDB FINGERPRINT RECO
   Jin ATB, 2004, PATTERN RECOGN, V37, P2245, DOI 10.1016/j.patcog.2004.04.011
   Karegar FP, 2017, 2017 2ND CONFERENCE ON SWARM INTELLIGENCE AND EVOLUTIONARY COMPUTATION (CSIEC), P66, DOI 10.1109/CSIEC.2017.7940172
   Kaur H, 2017, MULTIMED TOOLS APPL, V76, P4673, DOI 10.1007/s11042-016-3652-3
   Kaur H, 2016, MULTIMED TOOLS APPL, V75, P16333, DOI 10.1007/s11042-015-2933-6
   Keshishzadeh S, 2015, 22 IR C EL ENG ICEE, V6, P1873
   Kim H, 2017, IEEE ENG MED BIO, P454, DOI 10.1109/EMBC.2017.8036860
   Leng L, 2011, LECT NOTES COMPUTER, V6786
   Leng L, 2015, MULTIMED TOOLS APPL, V74, P11683, DOI 10.1007/s11042-014-2255-0
   Leng L, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1705, DOI 10.1109/CISP.2013.6743951
   Leng L, 2014, NEUROCOMPUTING, V131, P377, DOI 10.1016/j.neucom.2013.10.005
   Leng L, 2011, COMM COM INF SC, V186, P122
   Li HM, 2010, IEEE T INF TECHNOL B, V14, P44, DOI 10.1109/TITB.2009.2028136
   Li L, 2018, IET BIOMETRICS, V7, P3, DOI 10.1049/iet-bmt.2017.0089
   Lu Leng, 2012, Proceedings of the 2012 International Conference on Wavelet Analysis and Pattern Recognition (ICWAPR), P164, DOI 10.1109/ICWAPR.2012.6294772
   Lumini A, 2007, PATTERN RECOGN, V40, P1057, DOI 10.1016/j.patcog.2006.05.030
   Maio D, 2005, NEUROCOMPUTING, V69, P242, DOI 10.1016/j.neucom.2005.06.003
   PAN J, 1985, IEEE T BIO-MED ENG, V32, P230, DOI 10.1109/TBME.1985.325532
   Ratha NK, 2007, IEEE T PATTERN ANAL, V29, P561, DOI 10.1109/TPAMI.2007.1004
   Sadhya D, 2018, MULTIMED TOOLS APPL, V77, P15113, DOI 10.1007/s11042-017-5095-x
   Safie SI, 2011, IEEE T INF FOREN SEC, V6, P1315, DOI 10.1109/TIFS.2011.2162408
   Salloum R, 2017, INT CONF ACOUST SPEE, P2062, DOI 10.1109/ICASSP.2017.7952519
   Singh Yogendra Narain., 2012, Journal of Information Security, V03, P39, DOI DOI 10.4236/JIS.2012.31005
   Singla S.K., 2010, International Journal of Computer Science and Communication, V1, P281
   Teoh ABJ, 2008, PATTERN RECOGN, V41, P2034, DOI 10.1016/j.patcog.2007.12.002
   Teoh ABJ, 2006, IEEE T PATTERN ANAL, V28, P1892, DOI 10.1109/TPAMI.2006.250
   Teoh ABJ, 2010, PATTERN ANAL APPL, V13, P301, DOI 10.1007/s10044-009-0158-x
   Van Driest SL, 2016, JAMA-J AM MED ASSOC, V315, P47, DOI 10.1001/jama.2015.17701
   Wyant RS., 2017, MULTIMED TOOLS APPL, V8584, P1
NR 42
TC 45
Z9 46
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1857
EP 1887
DI 10.1007/s11042-018-6300-2
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700028
DA 2024-07-18
ER

PT J
AU Revathi, A
   Jeyalakshmi, C
   Thenmozhi, K
AF Revathi, A.
   Jeyalakshmi, C.
   Thenmozhi, K.
TI Person authentication using speech as a biometric against play back
   attacks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mel frequency perceptual linear predictive cepstrum (MFPLPC);
   Probabilty; Playback attacks; Robustness; Speaker authentication; Vector
   quantization (VQ); Replay attacks; Peak signal to noise ratio (PSNR);
   Rejection rate
AB This work presents the modules for authenticating the persons by using speech as a biometric against recorded playback attacks. It involves the implementation of feature extraction, modeling technique and testing procedure for authenticating the persons. Playback attacks are simulated by recording the original speech utterances using the speakers and mikes in a laptop using Audacity software. This work mainly involves the process for distinguishing original and recorded speeches and authenticating the speakers based on voice as a biometric. Features extracted from the original and recorded speeches are used to develop models for them. Voice passwords are assigned to the speakers and features are extracted from the training speech created by fusing the password specific original speech utterances. These features are applied to the training algorithm to generate password specific speaker models. Testing procedure involves the feature extraction and application of features to the models pertaining to recorded and original speech models. If the test speech belongs to the recorded speech, it is prevented from undergoing the further process. If it is an original speech, feature vectors of the test speech are applied to the password specific speaker models and based on the classification criteria, a speaker is identified and authenticated. Our system is found to be robust against playback attacks and has given better performance in authenticating sixteen speakers considered in our work. Passwords are isolated words and digits chosen from TIMIT speech database. This work is also extended to using AVSpoof database for authenticating 44 speakers against replay attacks and the performance is analyzed in terms of rejection rate.
C1 [Revathi, A.; Thenmozhi, K.] SASTRA Deemed Univ, Dept ECE SEEE, Thanjavur, India.
   [Jeyalakshmi, C.] K Ramakrishnan Coll Engn, Dept ECE, Samayapuram, Trichy, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Jeyalakshmi, C (corresponding author), K Ramakrishnan Coll Engn, Dept ECE, Samayapuram, Trichy, India.
EM lakshmikrce.2016@gmail.com
RI chelliah, jeyalakshmi/R-7723-2019; chelliah, lakshmi/AAI-8622-2020
OI Karuppuswamy, Thenmozhi/0000-0001-9829-0189; Arunachalam,
   Revathi/0000-0001-9515-3592; chelliah, jeyalakshmi/0000-0001-5522-3306
CR Bigun J, 2003, MULTIMODAL BIOMETRIC
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Dey S, 2015, SPEECH BIOMETRIC BAS
   Duc B, 1997, FUSION AUDIO VIDEO I, P835, DOI [10. 1016/S0167-8655(97)00071-8, DOI 10.1016/S0167-8655(97)00071-8]
   Ergünay SK, 2015, INT CONF BIOMETR THE
   Hermansky H., 1986, ICASSP 86 Proceedings. IEEE-IECEJ-ASJ International Conference on Acoustics, Speech and Signal Processing (Cat. No.86CH2243-4), P1971
   HERMANSKY H, 1991, CONFERENCE RECORD OF THE TWENTY-FIFTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P800, DOI 10.1109/ACSSC.1991.186557
   Hermansky H, 1994, IEEE T SPEECH AUDI P, V2, P578, DOI 10.1109/89.326616
   Jeli S, 2016, DEV MULTILEVEL SPEEC, P1, DOI [10.1007/s11265-016-1148-z, DOI 10.1007/S11265-016-1148-Z]
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P8373, DOI 10.1007/s11042-016-3458-3
   Leng L, 2015, MULTIMED TOOLS APPL, V74, P11683, DOI 10.1007/s11042-014-2255-0
   Leng L, 2015, PATTERN RECOGN, V48, P2290, DOI 10.1016/j.patcog.2015.01.021
   Leng L, 2014, SECUR COMMUN NETW, V7, P1860, DOI 10.1002/sec.900
   Leng L, 2014, NEUROCOMPUTING, V131, P377, DOI 10.1016/j.neucom.2013.10.005
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   McCool C, 2012, IEEE INT CONF MULTI, P635, DOI 10.1109/ICMEW.2012.116
   Pal M, 2015, APPL SOFT COMPUT, V30, P214, DOI 10.1016/j.asoc.2015.01.036
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   Rani R, 2016, GENETIC ALGORITHM US, V03, P240
   Revathi A., 2011, 2011 International Conference on Communications and Signal Processing (ICCSP), P198, DOI 10.1109/ICCSP.2011.5739300
   Safavi S, 2016, INT CONF DAT MIN WOR, P1074, DOI [10.1109/ICDMW.2016.115, 10.1109/ICDMW.2016.0155]
   Sanderson C, 2004, DIGIT SIGNAL PROCESS, V14, P449, DOI 10.1016/j.dsp.2004.05.001
   Sarria-Paja M, 2015, CAN CON EL COMP EN, P1254, DOI 10.1109/CCECE.2015.7129458
NR 26
TC 9
Z9 9
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1569
EP 1582
DI 10.1007/s11042-018-6258-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700016
DA 2024-07-18
ER

PT J
AU Tavallali, P
   Yazdi, M
   Khosravi, MR
AF Tavallali, Pooya
   Yazdi, Mehran
   Khosravi, Mohammad Reza
TI Robust cascaded skin detector based on AdaBoost
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin detection; AdaBoost; Cascaded classifier; Color spaces
ID FACE DETECTION
AB Skin detection is one of the most important issues of image processing and computer vision. A big concern about skin detection algorithms is being simple while keeping a good accuracy in discriminating skin and non-skin pixels to make the skin detector robust and practicable. This paper proposes a novel and robust skin detector. In this work, statistical information of each pixel and its neighbors is taken into account in order to deal with this concern. A simple algorithm is also presented to reduce the computational complexity of computing the statistical information. In the proposed method, a cascaded classifier by using the AdaBoost algorithm is trained. Finally, two edge detectors are used to make the algorithm more accurate. Moreover, some simple algorithms are used to make the process faster (e.g. algorithms of calculating mean and variance). The performance of the proposed skin detector is evaluated using SFA skin database. In order to illustrate the robustness of the proposed method, the comparisons are made with some popular and newly published skin detectors. The experimental results show that the proposed scheme outperforms other skin detection methods due to high precision and good recall. This method uses a specific way of training AdaBoost in skin detection while having a good accuracy and simplicity compared to other methods.
C1 [Tavallali, Pooya] Univ Calif Merced, Dept Elect Engn & Comp Sci, Merced, CA 95343 USA.
   [Tavallali, Pooya; Yazdi, Mehran] Shiraz Univ, Dept Commun & Elect Engn, Shiraz, Iran.
   [Khosravi, Mohammad Reza] Shiraz Univ Technol, Dept Elect & Elect Engn, Shiraz, Iran.
C3 University of California System; University of California Merced; Shiraz
   University; Shiraz University of Technology
RP Tavallali, P (corresponding author), Univ Calif Merced, Dept Elect Engn & Comp Sci, Merced, CA 95343 USA.; Tavallali, P (corresponding author), Shiraz Univ, Dept Commun & Elect Engn, Shiraz, Iran.
EM ptavallali@ucmerced.edu; yazdi@shirazu.ac.ir; m.khosravi@sutech.ac.ir
RI Khosravi, Mohammad R./ABG-8013-2021; Khosravi, Mohamadreza (Mohammad
   Reza)/KOD-0343-2024; , Mehran/C-2776-2011
OI , Mehran/0000-0002-8889-7048
CR Abazari R, 2018, MULTIMED TOOLS APPL
   [Anonymous], 2003, PROC GRAPHICON
   Basilio Jorge Alberto Marcial, 2011, Applications of Mathematics and Computer Engineering. American Conference on Applied Mathematics (AMERICAN-MATH'11). 5th WSEAS International Conference on Computer Engineering and Applications (CEA'11), P123
   Casati J, 2013, 9 WORKSH VIS COMP AN
   Chai D, 1999, IEEE T CIRC SYST VID, V9, P551, DOI 10.1109/76.767122
   Chi MC, 2006, INT C CONS EL ICCE
   ElMaghraby A., 2013, INT J COMPUTER APPL, V71, P15
   Garcia C, 1999, IEEE T MULTIMEDIA, V1, P264, DOI 10.1109/6046.784465
   Gasparini F, 2005, PATTERN RECOGN, V38, P2204, DOI 10.1016/j.patcog.2005.04.007
   Gomez G., 2002, MICAI 2002: Advances in Artificial Intelligence.Second Mexican International Conference on Artificial Intelligence. Proceedings (Lecture Notes in Artificial Intelligence Vol. 2313), P69
   Guan Y, 2006, 6 INT C INT SYST DES
   Hg RI, 2012, 8TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS 2012), P42, DOI 10.1109/SITIS.2012.17
   Hwang I, 2013, IEEE IMAGE PROC, P2622, DOI 10.1109/ICIP.2013.6738540
   Jiang ZW, 2007, FOURTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 3, PROCEEDINGS, P366, DOI 10.1109/FSKD.2007.518
   Kakumanu P, 2007, PATTERN RECOGN, V40, P1106, DOI 10.1016/j.patcog.2006.06.010
   Kaliraj K, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.4.043007
   Kawulok M., 2014, Advances in Low-Level Color Image Processing. Lecture Notes in Computational Vision and Biomechanics, V11, P329
   Kawulok M, 2013, IEEE INT CONF AUTOMA, DOI 10.1109/FG.2013.6553733
   Kawulok M, 2014, PATTERN RECOGN LETT, V41, P3, DOI 10.1016/j.patrec.2013.08.028
   Khan R., 2012, INT J COMPUTER SCI, V9, P257
   Khosravi Mohammad Reza, 2015, 2015 2nd International Conference on Knowledge-Based Engineering and Innovation (KBEI). Proceedings, P362, DOI 10.1109/KBEI.2015.7436072
   Khosravi M. R., 2015, P 20 ANN C COMP SOC, P245
   Khosravi M.R., 2017, J GEOGR INF SYST, V9, P114, DOI [DOI 10.4236/JGIS.2017.92008, 10.4236/jgis.2017.92008]
   Khosravi MR, 2018, INT J AGRIC ENVIRON, V9, P53, DOI 10.4018/IJAEIS.2018040104
   Khosravi MR, 2018, J SUPERCOMPUT, V74, P696, DOI 10.1007/s11227-017-2148-x
   Khosravi MR, 2016, P ICAUCAE 16
   Khosravi MR, 2018, NEURAL COMPUT APPL
   Kovac J, 2003, IEEE REGION 8 EUROCON 2003, VOL B, PROCEEDINGS, P144
   Li C, 2013, C COMP VIS PATT REC
   Lu Wan, 2012, Journal of Shanghai Jiaotong University (Science), V17, P197, DOI 10.1007/s12204-012-1252-6
   Luh GC, 2014, INT CONF MACH LEARN, P364, DOI 10.1109/ICMLC.2014.7009143
   Mahmoud Tarek., 2008, INT J COMPUTER ELECT, V2, P2354
   Phung SL, 2005, IEEE T PATTERN ANAL, V27, P148, DOI 10.1109/TPAMI.2005.17
   Ruiz-del-Solar J, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P463, DOI 10.1109/AFGR.2004.1301576
   Sawicki DJ, 2015, IET IMAGE PROCESS, V9, P751, DOI 10.1049/iet-ipr.2014.0859
   Shoyaib M, 2012, INT J APPROX REASON, V53, P636, DOI 10.1016/j.ijar.2012.01.003
   Singh S.K., 2003, TAMKANG J SCI ENG, V6, P227
   Tavallali P, 2015, P IEEE ICTCK 2015 MA
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang YJ, 2001, PATTERN RECOGN, V34, P1983, DOI 10.1016/S0031-3203(00)00119-9
   Zafarifar Bahman, 2010, 2010 IEEE International Conference on Consumer Electronics (ICCE 2010), P373, DOI 10.1109/ICCE.2010.5418755
NR 41
TC 30
Z9 36
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 2599
EP 2620
DI 10.1007/s11042-018-6385-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700059
DA 2024-07-18
ER

PT J
AU Manikandan, G
   Krishnan, RB
   Kumar, NR
   Narasimhan, D
   Srinivasan, A
   Raajan, NR
AF Manikandan, G.
   Krishnan, R. Bala
   Kumar, N. Rajesh
   Narasimhan, D.
   Srinivasan, A.
   Raajan, N. R.
TI Steganographic approach to enhancing secure data communication using
   contours and clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Image steganography; Security; LSB technique; Geodesic
   active contours; K-means clustering
ID IMAGE ENCRYPTION; DIGITAL IMAGES; HILL CIPHER; INFORMATION; QUALITY;
   JPEG
AB With the increasing developments in communication technologies, there is a need for extremely robust information exchange, which is the core aim of steganography. Steganography conceals this information into a trusted media, i.e., an image, video, or audio file, thereby masking its existence. In this paper, to improve the security of implanted data, a steganographic method is proposed that uses contours and clustering. Instead of using the entire image for embedding, the proposed method embeds the data in a particular location of the image that is obtained using a contour. Similar pixels inside the contour are grouped into clusters using the K-means clustering algorithm. Least-significant bit substitution is used to embed the data in the pixels of the cluster without causing any artifacts in the image. The experimental results indicate that our proposed scheme enhances security without degrading the image quality.
C1 [Manikandan, G.] SASTRA Univ, Sch Comp, Thanjavur 613401, Tamil Nadu, India.
   [Krishnan, R. Bala; Kumar, N. Rajesh; Narasimhan, D.; Srinivasan, A.] SASTRA Univ, Srinivasa Ramanujan Ctr, Thanjavur 613401, Tamil Nadu, India.
   [Raajan, N. R.] SASTRA Univ, Sch EEE, Thanjavur 613401, Tamil Nadu, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Manikandan, G (corresponding author), SASTRA Univ, Sch Comp, Thanjavur 613401, Tamil Nadu, India.
EM manikandan@it.sastra.edu
RI KRISHNAN, Dr. R BALA/ITU-7949-2023; N R, Dr. RAAJAN/HDN-4829-2022; ,
   db/GRS-6835-2022; Kumar N, Dr Rajesh/AAC-3229-2020; D,
   NARASIMHAN/P-3572-2018; D, N/JNT-1770-2023; Renga Raajan,
   Narasimhan/IST-5582-2023; Raghupathy, Bala Krishnan/GZH-3263-2022;
   Ganesan, Manikandan/AAB-1750-2021
OI KRISHNAN, Dr. R BALA/0000-0002-4752-6400; N R, Dr.
   RAAJAN/0000-0002-9537-1140; Kumar N, Dr Rajesh/0000-0001-5394-218X; D,
   NARASIMHAN/0000-0001-9375-3754; Raghupathy, Bala
   Krishnan/0000-0002-4752-6400; Ganesan, Manikandan/0000-0002-9978-4348; ,
   balakrishnan raghupathy/0000-0001-6217-3095; A, Dr.
   SRINIVASAN/0000-0003-1171-5573
CR Afrakhteh M, 2015, MULTIMED TOOLS APPL, V74, P4833, DOI 10.1007/s11042-013-1844-7
   Amirtharajan R., 2010, INT J COMPUTER APPL, V7, P31
   Amirtharajan R, 2012, INFORM SCIENCES, V193, P115, DOI 10.1016/j.ins.2012.01.010
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Chen SK, 2011, COMPUT STAND INTER, V33, P367, DOI 10.1016/j.csi.2010.11.002
   Goel S, 2013, INT J IMAGE GRAPH SI
   Gomathymeenakshi M, 2013, INT C TREND COMPUT C, P342, DOI 10.1109/ICE-CCN.2013.6528520
   Gupta G.K., 2008, INTRO DATA MINING CA
   Hamad N, 2010, INT ARAB J INF TECHN, V7, P146
   Han J., 2006, DATA MINING CONCEPTS, DOI 10.1016/C2009-0-61819-5
   Hossain M, 2010, INT ARAB J INF TECHN, V7, P34
   Karthikeyan B, 2013, INT J ELECTRON SECUR, V5, P178, DOI 10.1504/IJESDF.2013.058652
   Karthikeyan B., 2014, International Journal of Network Security, V16, P14
   Karthikeyan B., 2012, AUST J BASIC APPL SC, P55
   Li XX, 2007, INFORM SCIENCES, V177, P3099, DOI 10.1016/j.ins.2007.02.008
   Li X, 2014, MULTIMED TOOLS APPL, V68, P1051, DOI 10.1007/s11042-012-1112-2
   Liao X, 2011, J VIS COMMUN IMAGE R, V22, P1, DOI 10.1016/j.jvcir.2010.08.007
   Lin YK, 2012, J SYST SOFTWARE, V85, P2395, DOI 10.1016/j.jss.2012.05.032
   Liu HJ, 2013, J SYST SOFTWARE, V86, P826, DOI 10.1016/j.jss.2012.11.026
   Manikandan G., 2013, INT J ENG TECHNOL, V5, P2828
   Modaghegh H, 2014, MULTIMED TOOLS APPL, V74, P5285
   Mousa H, 2011, INT ARAB J INF TECHN, V8, P147
   Por LY, 2013, INT ARAB J INF TECHN, V10, P51
   Provos N., 2003, IEEE Security & Privacy, V1, P32, DOI 10.1109/MSECP.2003.1203220
   Stallings W., 2010, Cryptography and Network Security: Principles and Practice, V5
   Vaithiyanathan V., 2013, INT J APPL ENG RES, V8, P949
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wu CC, 2011, J SYST SOFTWARE, V84, P2196, DOI 10.1016/j.jss.2011.06.021
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Yang CH, 2008, PATTERN RECOGN, V41, P2674, DOI 10.1016/j.patcog.2008.01.019
   Yang CH, 2011, INFORM SCIENCES, V181, P2218, DOI 10.1016/j.ins.2011.01.015
   Ziou D, 2014, PATTERN ANAL APPL, V17, P279, DOI 10.1007/s10044-012-0303-9
NR 34
TC 6
Z9 6
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 32257
EP 32273
DI 10.1007/s11042-018-6237-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000033
DA 2024-07-18
ER

PT J
AU Mondal, B
   Kumar, P
   Singh, S
AF Mondal, Bhaskar
   Kumar, Prabhakar
   Singh, Shrey
TI A chaotic permutation and diffusion based image encryption algorithm for
   secure communications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Baker's map; Cryptography; Image encryption; PRNG; Security
ID SCHEME; TUTORIAL; MAPS
AB In this digital era, a huge amount of digital data is being generated, transmitted, and stored over the network. Images are widely searched, shared and uploaded which make them more vulnerable to the attackers. Therefore, image encryption has become the most widespread form of secure image communication. In recent past, a range of chaotic encryption schemes have been proposed for image encryption which suffers from low key space and high computational overhead. In this paper, the authors have proposed a secure image encryption technique based on 2D Baker's map. In the proposed scheme a plain image is permuted first, based on a sequence of pseudo random number generated by 2D Baker's map followed by diffusion process based on XORing. The strength of the proposed scheme is analyzed using the most well-known security test measures like NPCR, MSE, PSNR, UACI, correlation coefficient, Entropy etc. and the results demonstrate that the proposed scheme is resistive to various types of known attacks. The scheme runs on comparatively low computational overhead. Further, the results are compared with existing schemes.
C1 [Mondal, Bhaskar; Kumar, Prabhakar; Singh, Shrey] Natl Inst Technol Jamshedpur, Dept Comp Sci & Engn, Jamshedpur, Jharkhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Jamshedpur
RP Mondal, B (corresponding author), Natl Inst Technol Jamshedpur, Dept Comp Sci & Engn, Jamshedpur, Jharkhand, India.
EM bhaskar.cse@nitjsr.ac.in
RI Mondal, Dr. Bhaskar/Q-6376-2018
OI Mondal, Dr. Bhaskar/0000-0001-6863-9183
CR Akhavan A, 2006, LECT NOTES COMPUT SC, V4263, P963
   Akhavan A, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-126
   Amigó JM, 2007, PHYS LETT A, V366, P211, DOI 10.1016/j.physleta.2007.02.021
   Arumugam AS, 2010, 2010 IEEE INT C COMP, P1
   Benrhouma O, 2015, MULTIMED TOOLS APPL, V74, P3617, DOI 10.1007/s11042-013-1790-4
   Biswas K, 2015, IEEE SENS J, V15, P2801, DOI 10.1109/JSEN.2014.2380816
   Chen JX, 2014, OPTIK, V125, P2472, DOI 10.1016/j.ijleo.2013.12.001
   Chen Zaiping, 2010, 2010 2nd International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC 2010), P188, DOI 10.1109/IHMSC.2010.147
   Fridrich J, 1997, IEEE SYS MAN CYBERN, P1105, DOI 10.1109/ICSMC.1997.638097
   Hamza R, 2018, IEEE ACCESS, V6, P60160, DOI 10.1109/ACCESS.2017.2762405
   Hamza R, 2017, PERVASIVE MOB COMPUT, V41, P436, DOI 10.1016/j.pmcj.2017.03.011
   Jun Z, 2010, 2010 INT FOR INF TEC
   Lawrence Bassham IIIE, 2010, 80022 SP NAT I STAND
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Liu JY, 2018, MULTIMED TOOLS APPL, V77, P10217, DOI 10.1007/s11042-017-5406-2
   Mondal B, 2013, INT J RES ENG TECHNO, V02, P399, DOI [10.15623/ijret.2013.0210061, DOI 10.15623/IJRET.2013.0210061]
   Mondal B., 2017, ICICCS, P261, DOI [10.15439/2017R47, DOI 10.15439/2017R47]
   Mondal B., 2013, P INT C COMP COMM AD, V3, P88
   Mondal B, 2017, J KING SAUD UNIV-COM, V29, P499, DOI 10.1016/j.jksuci.2016.02.003
   Mondal Bhaskar, 2015, P 3 INT C ADV C ADV, P227
   PARKER TS, 1987, P IEEE, V75, P982, DOI 10.1109/PROC.1987.13845
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   Stinson D. R., 2005, CRYPTOGRAPHY THEORY
   Tong XJ, 2013, NONLINEAR DYNAM, V72, P229, DOI 10.1007/s11071-012-0707-5
   Wang W, 2016, WIRELESS COMMUNICATION AND SENSOR NETWORK, P711
   Wang W, 2018, COMPUT ELECTR ENG, V65, P282, DOI 10.1016/j.compeleceng.2017.07.026
   Wang XY, 2014, NONLINEAR DYNAM, V75, P567, DOI 10.1007/s11071-013-1086-2
   Wang XY, 2013, NONLINEAR DYNAM, V73, P795, DOI 10.1007/s11071-013-0832-9
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wong KW, 2008, PHYS LETT A, V372, P2645, DOI 10.1016/j.physleta.2007.12.026
   WU CW, 1993, IEEE T CIRCUITS-I, V40, P707, DOI 10.1109/81.246147
   Zhou JT, 2014, IEEE T INF FOREN SEC, V9, P39, DOI 10.1109/TIFS.2013.2291625
NR 32
TC 44
Z9 47
U1 0
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 31177
EP 31198
DI 10.1007/s11042-018-6214-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600046
DA 2024-07-18
ER

PT J
AU Wang, Y
   Fu, FF
   Lai, FC
   Xu, WZ
   Shi, JJ
   Wang, JX
AF Wang, Yao
   Fu, Fangfa
   Lai, Fengchang
   Xu, Weizhe
   Shi, Jinjin
   Wang, Jinxiang
TI Efficient road specular reflection removal based on gradient properties
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Road segmentation; ADAS; Highlight removal; Threshold filter; Layer
   separation
ID PARALLEL FRAMEWORK; SEPARATION; COMPONENTS; COLOR
AB Highlights caused by changes in sunlight throughout any given day cause failure in stereo matching, object recognition, and road segmentation. This is a serious challenge in advanced driver assistance systems (ADAS), because local high brightness and color discontinuities generally result in noticeable blurring of the road surface or object. This paper presents a novel strategy for removing specular reflection from highlight images by gradients distribution to optimize the diffuse image. The dark channel is introduced as a prior to initially estimate and locate the highlight. The threshold filter is then adopted to divide the high-intensity highlight and the weak highlight - the weak highlight affect neither the stereo matching nor road segmentation process. Finally, gradient properties (varying smoothness of specular and diffuse reflections) are presented to optimize the layer separation. Experimental results in speed and accuracy of road segmentation show that proposed method outperforms other techniques for separating highlights from road surfaces.
C1 [Wang, Yao; Fu, Fangfa; Lai, Fengchang; Xu, Weizhe; Wang, Jinxiang] Harbin Inst Technol, Microelect Ctr, Harbin 150000, Heilongjiang, Peoples R China.
   [Shi, Jinjin] China Three Gorges Univ, Coll Mech & Power Engn, Yichang 443000, Peoples R China.
C3 Harbin Institute of Technology; China Three Gorges University
RP Wang, JX (corresponding author), Harbin Inst Technol, Microelect Ctr, Harbin 150000, Heilongjiang, Peoples R China.
EM 14B921018@hit.edu.cn; fff1984292@hit.edu.cn; fclai@hit.edu.cn;
   13B921018@hit.edu.cn; shijinjinhit@sina.com; jxwang@hit.edu.cn
FU National Natural Science Foundation of China (NSFC) [61504032]
FX This work was supported by a grant from the National Natural Science
   Foundation of China (NSFC, No. 61504032)
CR [Anonymous], 2015, IEEE C COMPUTER VISI
   [Anonymous], APPL ARTIFICIAL INTE
   [Anonymous], 2016, CORR
   [Anonymous], PATTERN RECOGN
   Chung H-S, 2008, COMPUTER VISION PATT, P1
   Everingham M, 2012, PASCAL VISUAL OBJECT
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Kim H, 2013, PROC CVPR IEEE, P1460, DOI 10.1109/CVPR.2013.192
   KLINKER GJ, 1988, INT J COMPUT VISION, V2, P7, DOI 10.1007/BF00836279
   LEE SW, 1992, IMAGE VISION COMPUT, V10, P643, DOI 10.1016/0262-8856(92)90009-R
   Levin A, 2007, IEEE T PATTERN ANAL, V29, P1647, DOI 10.1109/TPAMI.2007.1106
   Li Y, 2014, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2014.346
   Lin S, 2002, LECT NOTES COMPUT SC, V2352, P210
   Mallick SP, 2005, PROC CVPR IEEE, P619
   Nayar SK, 1997, INT J COMPUT VISION, V21, P163, DOI 10.1023/A:1007937815113
   Oliveira GL, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4885, DOI 10.1109/IROS.2016.7759717
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Shi JJ, 2016, LECT NOTES COMPUT SC, V9771, P61, DOI 10.1007/978-3-319-42291-6_7
   Simonyan K., 2014, 14091556 ARXIV
   Tan P., 2006, COMPUTER VISION PATT, V2, P1855
   Tan RT, 2005, PROC CVPR IEEE, P125
   Tan RT, 2005, IEEE T PATTERN ANAL, V27, P178, DOI 10.1109/TPAMI.2005.36
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang Y, 2016, LECT NOTES COMPUT SC, V9772, P426, DOI 10.1007/978-3-319-42294-7_38
   WOLFF LB, 1991, IEEE T PATTERN ANAL, V13, P635, DOI 10.1109/34.85655
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang QX, 2015, IEEE T PATTERN ANAL, V37, P1304, DOI 10.1109/TPAMI.2014.2360402
   Yang QX, 2010, LECT NOTES COMPUT SC, V6314, P87, DOI 10.1007/978-3-642-15561-1_7
   Yang QX, 2009, PROC CVPR IEEE, P557, DOI 10.1109/CVPRW.2009.5206542
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 33
TC 4
Z9 4
U1 1
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30615
EP 30631
DI 10.1007/s11042-018-6156-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600022
DA 2024-07-18
ER

PT J
AU Hao, SJ
   Feng, Z
   Guo, YR
AF Hao, Shijie
   Feng, Zhuang
   Guo, Yanrong
TI Low-light image enhancement with a refined illumination map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image enhancement; Low light; Illumination map; Self-guided filtering
ID CONTRAST; PHOTOGRAPH
AB It has become very popular to take photographs in everyone's daily life. However, the visual quality of a photograph is not always guaranteed due to various factors. One common factor is the low-light imaging condition, which conceals visual information and degenerates the quality of a photograph. It is preferable for a low-light image enhancement model to complete the following tasks: improving contrast, preserving details, and keeping robust to noise. To this end, we propose a simple but effective enhancing model based on the simplified Retinex theory, of which the key is to estimate a good illumination map. In our model, we apply an iterative self-guided filter to refine the initial estimation of an illumination map, making it aware of local structure of image contents. In experiments, we validate the effectiveness of our method in various aspects, and compare our model with several state-of-the-art ones. The results show that our method effectively adjusts the global image contrast, recovers the concealed details and keeps the robustness against noise.
C1 [Hao, Shijie; Feng, Zhuang; Guo, Yanrong] Hefei Univ Technol, Sch Comp & Informat, Hefei, Anhui, Peoples R China.
C3 Hefei University of Technology
RP Hao, SJ (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei, Anhui, Peoples R China.
EM hfut.hsj@gmail.com; fengzhuang1994@gmail.com; yrguo0716@gmail.com
FU National Nature Science Foundation of China [61772171, 61702156]
FX The authors sincerely appreciate the useful comments and suggestions
   from the anonymous reviewers. This work was supported by the National
   Nature Science Foundation of China under grant number 61772171, and
   grant number 61702156.
CR [Anonymous], P COMPUTER VISION PA
   [Anonymous], ACM T GRAPH
   [Anonymous], P INF PROC MED IM IP
   [Anonymous], P COMP VIS PATT REC
   [Anonymous], 2013, ACM T GRAPH
   [Anonymous], P EUR C COMP VIS
   [Anonymous], 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.123
   [Anonymous], P INT C BIG KNOWL WO
   [Anonymous], P CHIN C PATT REC CC
   [Anonymous], P INT C MULT EXP ICM
   Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   Fu XY, 2016, SIGNAL PROCESS, V129, P82, DOI 10.1016/j.sigpro.2016.05.031
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Hao Shijie, 2016, Med Image Comput Comput Assist Interv, V9900, P219, DOI 10.1007/978-3-319-46720-7_26
   Hao SJ, 2016, IEEE MULTIMEDIA, V23, P34, DOI 10.1109/MMUL.2016.17
   Hao SJ, 2016, SIGNAL PROCESS, V120, P789, DOI 10.1016/j.sigpro.2015.02.017
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hong RC, 2016, IEEE T MULTIMEDIA, V18, P1555, DOI 10.1109/TMM.2016.2567071
   Hong RC, 2016, IEEE T IMAGE PROCESS, V25, P1124, DOI 10.1109/TIP.2016.2514499
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059
   Lim J, 2017, J VIS COMMUN IMAGE R, V45, P107, DOI 10.1016/j.jvcir.2017.02.016
   Liu CX, 2014, PATTERN RECOGN, V47, P1602, DOI 10.1016/j.patcog.2013.11.001
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Ni BB, 2013, IEEE T MULTIMEDIA, V15, P1138, DOI 10.1109/TMM.2013.2241042
   Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
   Wang SQ, 2016, IEEE T MULTIMEDIA, V18, P219, DOI 10.1109/TMM.2015.2510326
   Yin WY, 2014, IEEE T MULTIMEDIA, V16, P184, DOI 10.1109/TMM.2013.2283468
   Yue HJ, 2017, IEEE T IMAGE PROCESS, V26, P3981, DOI 10.1109/TIP.2017.2703078
   Zhang H, 2017, P INT C COMPUTER VIS
   Zhang HW, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2978656
   Zhang LM, 2016, IEEE T CYBERNETICS, V46, P258, DOI 10.1109/TCYB.2015.2400821
   Zhu WW, 2015, IEEE MULTIMEDIA, V22, P96, DOI 10.1109/MMUL.2015.66
   Zhu XF, 2017, IEEE T NEUR NET LEAR, V28, P1263, DOI 10.1109/TNNLS.2016.2521602
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
   Zhu XF, 2014, IEEE T IMAGE PROCESS, V23, P3737, DOI 10.1109/TIP.2014.2332764
   Zhu YY, 2015, IEEE T PATTERN ANAL, V37, P529, DOI 10.1109/TPAMI.2013.2295311
NR 39
TC 12
Z9 12
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29639
EP 29650
DI 10.1007/s11042-017-5448-5
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800025
DA 2024-07-18
ER

PT J
AU Jamal, A
   Deodhare, D
   Namboodiri, V
   Venkatesh, KS
AF Jamal, Arshad
   Deodhare, Dipti
   Namboodiri, Vinay
   Venkatesh, K. S.
TI Eclectic domain mixing for effective adaptation in action spaces
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Domain adaptation; Subspace learning; Human action recognition
ID ACTION RECOGNITION
AB Although videos appear to be very high-dimensional in terms of duration x frame-rate x resolution, temporal smoothness constraints ensure that the intrinsic dimensionality for videos is much lower. In this paper, we use this idea for investigating Domain Adaptation (DA) in videos, an area that remains under-explored. An approach that has worked well for the image DA is based on the subspace modeling of the source and target domains, which works under the assumption that the two domains share a latent subspace where the domain shift can be reduced or eliminated. In this paper, first we extend three subspace based image DA techniques for human action recognition and then combine it with our proposed Eclectic Domain Mixing (EDM) approach to improve the effectiveness of the DA. Further, we use discrepancy measures such as Symmetrized KL Divergence and Target Density Around Source for empirical study of the proposed EDM approach. While, this work mainly focuses on Domain Adaptation in videos, for completeness of the study, we comprehensively evaluate our approach using both object and action datasets. In this paper, we have achieved consistent improvements over chosen baselines and obtained some state-of-the-art results for the datasets.
C1 [Jamal, Arshad; Namboodiri, Vinay; Venkatesh, K. S.] Indian Inst Technol, Kanpur, Uttar Pradesh, India.
   [Jamal, Arshad; Deodhare, Dipti] Ctr AI & Robot, Bangalore, Karnataka, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kanpur; Defence Research & Development Organisation
   (DRDO); Center for Artificial Intelligence & Robotics (CAIR)
RP Jamal, A (corresponding author), Indian Inst Technol, Kanpur, Uttar Pradesh, India.; Jamal, A (corresponding author), Ctr AI & Robot, Bangalore, Karnataka, India.
EM arshad@iitk.ac.in
OI Namboodiri, Vinay/0000-0001-5262-9722
CR Aljundi R., 2015, CVPR
   [Anonymous], 2015, CVPR
   [Anonymous], 2014, CVPR
   [Anonymous], ECCV
   [Anonymous], 2012, ECCV
   Baktashmotlagh M, 2013, IEEE I CONF COMP VIS, P769, DOI 10.1109/ICCV.2013.100
   Baktashmotlagh Mahsa., 2014, CVPR
   Ben-David S., 2007, ADV NEURAL INFORM PR, V19
   Bergamo Alessandro, 2010, ADV NEURAL INFORM PR, V23
   Blitzer J., 2006, PROC C EMPIRICAL MET, P120, DOI DOI 10.3115/1610075.1610094
   Bo Sun, 2015, 2015 IEEE Power & Energy Society General Meeting, P1, DOI 10.1109/PESGM.2015.7286184
   Csurka G, 2017, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-3-319-58347-1_1
   Darrell T, 2015, SIMULTANEOUS DEEP TR
   Daume H., 2010, NIPS
   Daume III Hal, 2007, ACL 2007, P256
   Daume IIIH, 2006, JAIR
   Davar N Faraji, 2011, DOM AD WORKSH CONJ N
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Duan L, 2012, SYSTEMS MAN CYBERN A
   Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114
   Duan LX, 2009, PROC CVPR IEEE, P1375, DOI [10.1109/CVPRW.2009.5206747, 10.1109/CVPR.2009.5206747]
   Duan Lixin, 2009, P 26 ANN INT C MACH, P289
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Fernando B, 2015, PROC CVPR IEEE, P5378, DOI 10.1109/CVPR.2015.7299176
   Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368
   Ganin Y., 2015, ICML
   Gong B., 2013, P INT C MACH LEARN, P222
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Gopalan R., 2014, IEEE TPAME
   Gopalan R, 2015, FDN TRENDS COMPUT GR
   Hoffman J, 2012, LECT NOTES COMPUT SC, V7573, P702, DOI 10.1007/978-3-642-33709-3_50
   Jiang F, 2015, J MACH LEARN RES, V16, P227
   Kuhne H., 2011, ICCV
   Kulis B, 2011, PROC CVPR IEEE, P1785, DOI 10.1109/CVPR.2011.5995702
   Long M., 2017, DEEP TRANSFER LEARNI
   Long M, 2016, PROCEEDINGS OF SYMPOSIUM OF POLICING DIPLOMACY AND THE BELT & ROAD INITIATIVE, 2016, P136
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Ni J., 2013, In CVPR
   Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29
   Pan S.J., 2009, IEEE Trans. Neural Nets, V99, P1
   Reddy KK, 2013, MACH VISION APPL
   Ruonan Li, 2012, CVPR
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smola A, 2007, LECT NOTES ARTIF INT, V4754, P13
   Sun B, 2016, C ART INT
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Zhang SP, 2014, INFORM SCIENCES, V281, P635, DOI 10.1016/j.ins.2013.12.052
   Zhang Z, 2013, PROC CVPR IEEE, P2690, DOI 10.1109/CVPR.2013.347
NR 50
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29949
EP 29969
DI 10.1007/s11042-018-6179-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800044
DA 2024-07-18
ER

PT J
AU Swaraja, K
AF Swaraja, K.
TI Medical image region based watermarking for secured telemedicine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical watermarking; Secrecy; Authenticity; DWT; Schur; Firefly;
   Telemedicine
ID MULTIPLE WATERMARKING; INTEGRITY CONTROL; ROBUST
AB Exchange of Medical images over public networks entail a methodology to offer secrecy for the image along with confirmation for image integrity. In this paper, a region-based Firefly optimized algorithm and hybridization of DWT and Schur transforms in conjunction with multiple watermarking is recommended to endow with security requisites such as authenticity of the ownership of medical image besides origin of source for interchange of medical images in telemedicine applications. Secrecy and authenticity are offered by inserting robust multiple watermarks in the region-of-noninterest (RONI) of the medical image by means of a blind method in the discrete wavelet transform and Schur transform (DWT-Schur). The capability of imperceptibility, robustness and payload are the main parameters for the assessment of watermarking algorithm, with MRI, Ultrasound plus X-ray gray-scale medical image modalities. Simulation results make obvious the efficacy of the projected algorithm in offering the essential security benefits for applications allied to telemedicine.
C1 [Swaraja, K.] GRIET, Dept ECE, Hyderabad, India.
C3 Gokaraju Rangaraju Institute of Engineering & Technology
RP Swaraja, K (corresponding author), GRIET, Dept ECE, Hyderabad, India.
EM kswaraja@gmail.com
RI kuraparthi, swaraja/AAY-9068-2020
OI k, swaraja/0000-0003-2638-2492
CR Ahmad R, 2008, IEEE VTS VEH TECHNOL, P1
   Al-Haj A, 2014, J DIGIT IMAGING, V27, P737, DOI 10.1007/s10278-014-9709-9
   Ali M, 2014, ENG APPL ARTIF INTEL, V31, P15, DOI 10.1016/j.engappai.2013.07.009
   Amirgholipour SK., 2009, JDCTA, V3, P42, DOI DOI 10.4156/JDCTA.VOL3.ISSUE2.AMIRGHOLIPOUR
   [Anonymous], 2 INT C E MED SYST T
   [Anonymous], J DIGIT IMAGING
   [Anonymous], J DIGIT IMAGING
   [Anonymous], ECSIS S BIOINSP LEAR
   [Anonymous], 2011, ICTACT J SOFT COMPUT
   [Anonymous], 33 ANN INT C IEEE EM
   [Anonymous], MAJLESI J MECH ENG
   [Anonymous], 2016, INT J APPL ENG RES I
   [Anonymous], INF SCI ENG ICISE 1
   [Anonymous], TECHNOLOGIES INFORM
   [Anonymous], MATRIX COMPUTATIONS
   [Anonymous], 2011, INT J COMPUT APPL
   Aslantas V, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P241, DOI 10.1109/ICME.2008.4607416
   Aslantas V, 2009, OPT COMMUN, V282, P2806, DOI 10.1016/j.optcom.2009.04.034
   Aslantas V, 2009, OPT COMMUN, V282, P769, DOI 10.1016/j.optcom.2008.11.024
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Bhatnagar G, 2013, FUTURE GENER COMP SY, V29, P182, DOI 10.1016/j.future.2012.05.021
   Chao HM, 2002, IEEE T INF TECHNOL B, V6, P46, DOI 10.1109/4233.992161
   Chauhan DS, 2019, MULTIMED TOOLS APPL, V78, P3911, DOI 10.1007/s11042-017-4886-4
   Coatrieux G, 2001, PROC SPIE, V4314, P229, DOI 10.1117/12.435403
   Davie B, 2001, IEEE INTERNET COMPUT, V5, P42, DOI 10.1109/4236.935176
   Gen M., 1997, GENETIC ALGORITHM EN
   Giakoumaki A, 2004, P ANN INT IEEE EMBS, V26, P3241
   Hong W., 2006, IEEE T SIGNAL PROCES, V12, P1
   Kumar C, 2018, MULTIMED TOOLS APPL, V77, P3597, DOI 10.1007/s11042-017-5222-8
   Kundur D, 1998, INT CONF ACOUST SPEE, P2969, DOI 10.1109/ICASSP.1998.678149
   Liew SC, 2011, COMM COM INF SC, V179, P555
   Mahajan LH, 2013, INT J ADV RES SCI EN, V2, P69
   Memon NA, 2008, INMIC: 2008 INTERNATIONAL MULTITOPIC CONFERENCE, P106, DOI 10.1109/INMIC.2008.4777717
   Mohan A., 2017, MED IMAGE WATERMARKI
   Mohan B.Chandra., 2010, INT J COMPUTER ELECT, V2, P1793
   Pan W, 2010, LECT NOTES COMPUT SC, V5939, P153
   Pandey R, 2016, MULTIMED TOOLS APPL, V75, P14381, DOI 10.1007/s11042-016-3536-6
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P10599, DOI 10.1007/s11042-015-3127-y
   Pereira S., 2001, INFORM HIDING, P340, DOI [10.1007/3-540-45496-925, DOI 10.1007/3-540-45496-925]
   Rosiyadi D., 2012, Int J Comput Theory and Eng (IJCTE), V4, P329
   Sharma A, 2017, WIRELESS PERS COMMUN, V92, P1611, DOI 10.1007/s11277-016-3625-x
   Singh A, 2012, INT J COMPUT APPL, V48, P9
   Singh Amit Kumar, 2018, Future Generation Computer Systems, V86, P926, DOI 10.1016/j.future.2016.11.023
   SINGH AK, 2016, HDB RES MODERN CRYPT, P246, DOI DOI 10.4018/978-1-5225-0105-3.CH011
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh AK, 2015, WIRELESS PERS COMMUN, V83, P2133, DOI 10.1007/s11277-015-2505-0
   Singh AK, 2015, P NATL A SCI INDIA A, V85, P295, DOI 10.1007/s40010-014-0197-6
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P406, DOI 10.1166/jmihi.2015.1407
   Singh AK, 2014, P NATL A SCI INDIA A, V84, P345, DOI 10.1007/s40010-014-0140-x
   Srivastava R, 2018, MULTIMED TOOLS APPL, V77, P16447, DOI 10.1007/s11042-017-5214-8
   Vafaei M., 2013, World Appl. Sci. J, V22, P1572
   Velumani R, 2010, IEEE INT C COMP INT, P1, DOI DOI 10.1109/ICCIC.2010.5705832)
   Wang MS, 2009, COMPUT STAND INTER, V31, P757, DOI 10.1016/j.csi.2008.09.003
   Wei ZC, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1117, DOI 10.1109/ICME.2006.262731
   Xia XG, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P548, DOI 10.1109/ICIP.1997.647971
   Yavuz E, 2007, APPLIED COMPUTING 2007, VOL 1 AND 2, P1051, DOI 10.1145/1244002.1244232
   Yen CT, 2016, MULTIMED TOOLS APPL, V75, P9745, DOI 10.1007/s11042-015-2718-y
   Zear A, 2018, J INTELL SYST, V27, P5, DOI 10.1515/jisys-2016-0036
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
NR 60
TC 24
Z9 25
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28249
EP 28280
DI 10.1007/s11042-018-6020-7
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500021
DA 2024-07-18
ER

PT J
AU Syed, FH
   Tahir, MA
AF Syed, Farrukh Hasan
   Tahir, Muhammad Atif
TI Safe semi supervised multi-target regression (MTR-SAFER) for new targets
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-target learning; Semi-supervised learning; New target learning;
   Safe multi-target semi-supervised regressor
AB Multi-target regression (MTR) is a challenging research problem which aims to predict more than one continuous variable as output in a pattern. In recent time, a number of novel applications have increased interest and research in this area. Applications include predicting brain activity from multimedia sensors, different values for stocks from continuous web data, condition of various attributes of the vegetation at a given site, etc. In contrast to conventional regression problems where each instance only belongs to single target from a set of disjoint targets, in multi-target regression, each instance may belong to more than one continuous variable as output. Multi-target regression problems are concerned with problems where there are more than one continuous variables to output. These output variables may or may not be related. A number of approaches have been proposed for this problem. However, for a dynamic multi-target learning system, a pre-trained multi-target system shall be revised as new targets emerge with very few instances. The objective of this paper is to investigate semi-supervised techniques on multi-target regression problems to predict new target using very limited amount of examples. Experiments are then conducted on real world multi-target regression (MTR) data sets. The proposed methodology is then compared with state of the art MTR methods. Promising results are obtained using proposed safe semi-supervised regressor with binary relevance.
C1 [Syed, Farrukh Hasan; Tahir, Muhammad Atif] Natl Univ Comp & Emerging Sci, Dept Comp Sci, Data Sci Res Grp, Karachi Campus, Karachi, Pakistan.
RP Syed, FH (corresponding author), Natl Univ Comp & Emerging Sci, Dept Comp Sci, Data Sci Res Grp, Karachi Campus, Karachi, Pakistan.
EM farrukh.hassan@nu.edu.pk; atif.tahir@nu.edu.pk
OI Tahir, Muhammad Atif/0000-0003-1366-8408
CR Aho T, 2012, J MACH LEARN RES, V13, P2367
   [Anonymous], 2017, IJCAI
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Borchani H, 2015, WIRES DATA MIN KNOWL, V5, P216, DOI 10.1002/widm.1157
   Chapelle O., 2010, Semi-Supervised Learning, V1st
   Goovaerts Pierre, 1997, GEOSTATISTICS NATURA
   Guo SR, 2017, MULTIMED TOOLS APPL, V76, P8677, DOI 10.1007/s11042-016-3470-7
   Guo YC, 2017, AAAI CONF ARTIF INTE, P4061
   Guo YC, 2017, IEEE T IMAGE PROCESS, V26, P3277, DOI 10.1109/TIP.2017.2696747
   Hatzikos EV, 2008, KNOWL-BASED SYST, V21, P471, DOI 10.1016/j.knosys.2008.03.005
   Kaggle, 2012, KAGGL COMP ONL PROD
   Karalic A, 1997, MACH LEARN, V26, P147, DOI 10.1023/A:1007365207130
   KIRA K, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P129
   Kocev D, 2009, ECOL MODEL, V220, P1159, DOI 10.1016/j.ecolmodel.2009.01.037
   Lewis FI, 2013, EMERG THEMES EPIDEMI, V10, DOI 10.1186/1742-7622-10-4
   Li YF, 2017, AAAI CONF ARTIF INTE, P2217
   Lucian B, 2010, ANN U CRAIOVA EC SCI, V2, P32
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Popek S, 2003, NAHRUNG, V47, P36, DOI 10.1002/food.200390006
   Schneider A, 2010, DTSCH ARZTEBL INT, V107, P776, DOI [10.3238/arztebl.2010.0776, 10.3238/arztebl.2010.0799]
   Shaikh MK, 2017, MULTIMED TOOLS APPL, V76, P4635, DOI 10.1007/s11042-016-3635-4
   Shi YA, 2009, IEEE DATA MINING, P483, DOI 10.1109/ICDM.2009.75
   Spolaór N, 2013, ELECTRON NOTES THEOR, V292, P135, DOI 10.1016/j.entcs.2013.02.010
   Spyromitros-Xioufis E, 2016, MACH LEARN, V104, P55, DOI 10.1007/s10994-016-5546-z
   Sun YX, 2017, MULTIMED TOOLS APPL, V76, P8305, DOI 10.1007/s11042-016-3487-y
   Tsanas A, 2012, ENERG BUILDINGS, V49, P560, DOI 10.1016/j.enbuild.2012.03.003
   Tsoumakas Grigorios, 2014, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2014. Proceedings: LNCS 8726, P225, DOI 10.1007/978-3-662-44845-8_15
   Wang J., 2016, P AAAI C ART INT, P1, DOI DOI 10.1609/AAAI.V30I1.10448
   Wen Z., 2016, Applied Informatics, V3, P10
   Xu S, 2013, PATTERN RECOGN LETT, V34, P1078, DOI 10.1016/j.patrec.2013.01.015
   Yarowsky D., 1995, 33 ANN M ASS COMPUTA, P189, DOI DOI 10.3115/981658.981684
   Yeh IC, 2007, CEMENT CONCRETE COMP, V29, P474, DOI 10.1016/j.cemconcomp.2007.02.001
   Zhou Z.-H., 2012, ENSEMBLE METHODS FDN, DOI DOI 10.1201/B12207
   Zhou ZH, 2016, FRONT COMPUT SCI-CHI, V10, P589, DOI 10.1007/s11704-016-6906-3
   Zhu X, 2009, Synthesis Lectures on Artificial Intelligence and Machine Learning, V3, P1, DOI 10.1007/978-3-031-01548-9
   Zhu Y, 2016, IEEE DATA MINING, P1371, DOI [10.1109/ICDM.2016.0188, 10.1109/ICDM.2016.35]
NR 36
TC 6
Z9 6
U1 3
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29971
EP 29987
DI 10.1007/s11042-018-6367-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800045
DA 2024-07-18
ER

PT J
AU Zhao, F
   Yang, Y
   Zhang, HY
   Yang, LL
   Zhang, L
AF Zhao, Fan
   Yang, Yao
   Zhang, Hai-yan
   Yang, Lin-lin
   Zhang, Lin
TI Sign text detection in street view images using an integrated feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE BoVWs model; Text detection; SGONG network; Color histogram; BRISK
   descriptors; Cascade-adaboost classifier; Integral image
ID COMPETITION; ADABOOST
AB Based on Bag of Visual Words (BoVWs) model, this paper proposes a novel method using an integrated feature to detect sign text in the street view images. BRISK features are first extracted from the street view images for dictionary learning. The Self-Growing and Self-Organized Neural Gas (SGONG) network is then used to cluster adaptively the extracted BRISK descriptors for generating visual words. The histogram of visual words is further calculated to form the appearance feature of the sign text. For eliminating the color differences and further highlighting the histogram similarity of all colors of signs, a color invariant histogram, called CIHS histogram, is presented to represent the color information of the sign text. By integrating the visual words histograms and CIHS histograms, an integrated descriptor, called Appearance and Color (A&C) descriptor, is specifically designed as the input features for cascade-Adaboost classifier. In the multi-scale sliding window text sign detection, integral image is applied to the spatial distribution map of each visual word for avoiding repeated extraction of features. Experimental results demonstrate that the proposed method outperforms the state-of-the-art methods and the detectors with the traditional descriptors.
C1 [Zhao, Fan; Yang, Yao; Zhang, Hai-yan; Yang, Lin-lin; Zhang, Lin] Xian Univ Technol, Fac Printing Packaging Engn & Digital Media Techn, Dept Informat Sci, Xian 710048, Shaanxi, Peoples R China.
C3 Xi'an University of Technology
RP Zhao, F (corresponding author), Xian Univ Technol, Fac Printing Packaging Engn & Digital Media Techn, Dept Informat Sci, Xian 710048, Shaanxi, Peoples R China.
EM vcu@xaut.edu.cn; 3120342084@stu.xaut.edu.cn; 3120342019@stu.xaut.edu.cn;
   3110342073@stu.xaut.edu.cn; 3110342021@stu.xaut.edu.cn
RI Zhang, Haiyan/GMW-7284-2022; ZHAO, Fan/AEZ-4761-2022
OI ZHAO, Fan/0000-0001-6672-7948
FU National Natural Science Foundation of China (NSFC) [61671376, 61671374]
FX This work was supported in part by the National Natural Science
   Foundation of China (NSFC) under Grant No. 61671376 and 61671374.
CR Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   [Anonymous], 2013, International Conference on Machine Learning
   [Anonymous], 2016, P 23 INT C MECH MACH, DOI DOI 10.1109/M2VIP.2016.7827292
   [Anonymous], ARXIV160309423
   [Anonymous], P 2013 INT C DIG IM
   Atsalakis A, 2006, ENG APPL ARTIF INTEL, V19, P769, DOI 10.1016/j.engappai.2006.05.004
   Bai X, 2016, IEEE T IMAGE PROCESS, V25, P2789, DOI 10.1109/TIP.2016.2555080
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Cheng WC, 2013, ENG APPL ARTIF INTEL, V26, P1016, DOI 10.1016/j.engappai.2012.08.013
   Choi S, 2014, I C INF COMM TECH CO, P575, DOI 10.1109/ICTC.2014.6983215
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Fang SC, 2017, MULTIMED TOOLS APPL, V76, P15083, DOI 10.1007/s11042-017-4538-8
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   González A, 2014, IEEE T INTELL TRANSP, V15, P228, DOI 10.1109/TITS.2013.2277662
   Greenhalgh J, 2015, IEEE T INTELL TRANSP, V16, P1360, DOI 10.1109/TITS.2014.2363167
   Guan CL, 2017, ADV SOC SCI EDUC HUM, V83, P1
   He T, 2016, IEEE T IMAGE PROCESS, V25, P2529, DOI 10.1109/TIP.2016.2547588
   Jagannathan Shyam, 2017, 2017 IEEE International Conference on Consumer Electronics (ICCE), P233, DOI 10.1109/ICCE.2017.7889296
   Juneja M, 2013, PROC CVPR IEEE, P923, DOI 10.1109/CVPR.2013.124
   Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942
   Karatzas D, 2013, PROC INT CONF DOC, P1484, DOI 10.1109/ICDAR.2013.221
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee JJ, 2011, PROC INT CONF DOC, P429, DOI 10.1109/ICDAR.2011.93
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Lim JJ, 2013, PROC CVPR IEEE, P3158, DOI 10.1109/CVPR.2013.406
   Liu ZD, 2017, IET COMPUT VIS, V11, P596, DOI 10.1049/iet-cvi.2016.0452
   Lu SJ, 2015, INT J DOC ANAL RECOG, V18, P125, DOI 10.1007/s10032-015-0237-z
   Merino-Gracia K., 2011, P 4 INT WORKSH CAM B, P29, DOI DOI 10.1007/978-3-642-29364-1_3
   Mogelmose A, 2012, IEEE T INTELL TRANSP, V13, P1484, DOI 10.1109/TITS.2012.2209421
   Neumann L, 2013, IEEE I CONF COMP VIS, P97, DOI 10.1109/ICCV.2013.19
   Neycharan JG, 2018, MULTIMED TOOLS APPL, V77, P7615, DOI 10.1007/s11042-017-4663-4
   Papadopoulos DP, 2013, EXPERT SYST APPL, V40, P5765, DOI 10.1016/j.eswa.2013.02.016
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Shahab A, 2011, PROC INT CONF DOC, P1491, DOI 10.1109/ICDAR.2011.296
   Shivakumara P, 2011, IEEE T PATTERN ANAL, V33, P412, DOI 10.1109/TPAMI.2010.166
   Stergiopoulou E, 2009, ENG APPL ARTIF INTEL, V22, P1141, DOI 10.1016/j.engappai.2009.03.008
   Viola P, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P734
   Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yao C, 2014, IEEE T IMAGE PROCESS, V23, P4737, DOI 10.1109/TIP.2014.2353813
   Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787
   Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765
   Yin XC, 2015, IEEE T PATTERN ANAL, V37, P1930, DOI 10.1109/TPAMI.2014.2388210
   Yin XC, 2014, IEEE T PATTERN ANAL, V36, P970, DOI 10.1109/TPAMI.2013.182
   Yuan J, 2015, MULTIMED TOOLS APPL, V74, P859, DOI 10.1007/s11042-013-1702-7
   Zhao X, 2011, IEEE T IMAGE PROCESS, V20, P790, DOI 10.1109/TIP.2010.2068553
   Zhu YY, 2016, FRONT COMPUT SCI-CHI, V10, P19, DOI 10.1007/s11704-015-4488-0
NR 47
TC 2
Z9 2
U1 4
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28049
EP 28076
DI 10.1007/s11042-018-5975-8
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500014
DA 2024-07-18
ER

PT J
AU Begum, AAS
   Nirmala, S
AF Begum, A. Alif Siddiqua
   Nirmala, S.
TI Secure visual cryptography for medical image using modified cuckoo
   search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gaussian function; Discrete wavelet transform; Cuckoo search; Mean
   square error and peak signal to noise ratio
AB Optimal secure visual cryptography for brain MRI medical image is proposed in this paper. Initially, the brain MRI images are selected and then discrete wavelet transform is applied to the brain MRI image for partitioning the image into blocks. Then Gaussian based cuckoo search algorithm is utilized to select the optimal position for every block. Next the proposed technique creates the dual shares from the secret image. Then the secret shares are embedded in the corresponding positions of the blocks. After embedding, the extraction operation is carried out. Here visual cryptographic design is used for the purpose of image authentication and verification. The extracted secret image has dual shares, based on that the receiver views the input image. The authentication and verification of medical image are assisted with the help of target database. All the secret images are registered previously in the target database. The performance of the proposed method is estimated by Peak Signal to Noise Ratio (PSNR), Mean square error (MSE) and normalized correlation. The implementation is done by MATLAB platform.
C1 [Begum, A. Alif Siddiqua] Anna Univ, Madras, Tamil Nadu, India.
   [Nirmala, S.] Muthayammal Engn Coll, Rasipuram, Tamil Nadu, India.
C3 Anna University; Anna University Chennai; Muthayammal Engineering
   College
RP Begum, AAS (corresponding author), Anna Univ, Madras, Tamil Nadu, India.
EM aalifsiddiquabegum0783@gmail.com
CR Aditya K, 2017, 2017 INTERNATIONAL CONFERENCE ON NETWORKS & ADVANCES IN COMPUTATIONAL TECHNOLOGIES (NETACT), P29, DOI 10.1109/NETACT.2017.8076737
   [Anonymous], 2012, INFORM KNOWLEDGE MAN
   Ansari N., 2015, INN TRENDS COMPUT CO, V3, P89
   Chiu PL, 2015, SIGNAL PROCESS, V108, P476, DOI 10.1016/j.sigpro.2014.09.032
   Durairaj M., 2015, INT J COMPUT SCI INF, V6, P4047
   Kester Q.-A., 2013, INT J EMERGING TECHN, V3, P496, DOI 10.5120/16500-5752.
   Lee CC, 2014, J VISUAL LANG COMPUT, V25, P243, DOI 10.1016/j.jvlc.2013.11.001
   Lee JS, 2015, DIGIT SIGNAL PROCESS, V40, P131, DOI 10.1016/j.dsp.2015.02.012
   Mande A, 2013, INT J EMERG TECHNOL, V3, P364
   Manimurugan S, 2012, INT J ENG INNOV TECH, V2, P135
   Mohod AA, 2014, INT J APPL INNOV ENG, V3, P210
   Nagdive PS, 2015, INT J ADV RES COMPUT, V3, P58
   Pachiappan K, 2014, INT J SCI ENG TECHNO, V3, P1642
   Pandey V., 2012, INT J ADV COMPUT SC, V2, P45
   Rakhunde SM., 2014, INT J INNOV RES COMP, V2, P2815
   Rakhunde SM, 2014, INT J ADV RES COMPUT, V3, P6951
   Surekha B., 2012, Int. J. Comput. Sci. Issues, V9, P312
   Tedmori S, 2012, INT ARAB J INF TECHN, V9, P471
   Umaamaheshvari A, 2012, INT J ADV RES COMPUT, V1, P70
   Wang DS, 2013, IEEE T INF FOREN SEC, V8, P2059, DOI 10.1109/TIFS.2013.2281108
   Wang X, 2014, IEEE SIGNAL PROC LET, V21, P853, DOI 10.1109/LSP.2014.2317706
   Wang XF, 2015, IEEE T INF FOREN SEC, V10, P1336, DOI 10.1109/TIFS.2015.2407698
   Yan XH, 2015, DIGIT SIGNAL PROCESS, V38, P53, DOI 10.1016/j.dsp.2014.12.002
NR 23
TC 7
Z9 7
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 27041
EP 27060
DI 10.1007/s11042-018-5903-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500036
OA Bronze
DA 2024-07-18
ER

PT J
AU Kavitha, P
   Vijaya, K
AF Kavitha, P.
   Vijaya, K.
TI Optimal feature-level fusion and layered k-support vector machine for
   spoofing face detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Oppositional grey wolf optimizer; Spoofing detection;
   Feature level fusion; Layered k-SVM; EDGHM-SURF
ID SCALE; ALGORITHM; SURF
AB The recognition frameworks are highly vulnerable to spoofing attacks and this vulnerability generates an effective security concerned issues in biometric domain. Moreover, some of the earlier proposed approaches have attained attractive results with intra test (i.e. by training and testing the system on same database) evaluation done to detect the face spoofing attack. Consequently, most of these techniques generate incorrect decision on the recognition of genuine faces with unseen attacks in case of inter test evaluation (i.e. the system is trained on one database and then tested on another database). However, this impact is considered as a major difficulty in the highly focused biometric anti-spoofing research domain. In this work, we propose a multimodal biometric framework for the accurate recognition of fake face from genuine face. Initially, face image features which are coupled to the color spaces HSV and YCbCr are extracted with EDGHM-SURF (Enhanced Discrete Gaussian-Hermite Moment based Speed-up Robust Feature) descriptor. Then, a newly developed method of feature-level fusion using OGWO (FLFO) is used to fuse these extracted features. This method utilized the OGWO (Oppositional Gray Wolf Optimization) algorithm due to its excellent exploitation and exploration behavior in the identification of optimal weight score from the solution space, without allowing the solutions to stick in the local optimum. Finally, the fused features are fed into the Layered k-SVM (k-support vector machine) classifier for the recognition of fake face. The experimental results of our proposed approach are evaluated on three traditional benchmark face spoofing databases, namely the Replay-Attack, the CASIA Face Anti-Spoofing, and the MSU Mobile Face Spoof database. The outcome of our proposed approach exhibited steady and robust performance across all the three datasets. More commonly, our proposed approach executes well in the inter database tests and yields high performance, even though when only operated with minimized training data.
C1 [Kavitha, P.] RMK Engn Coll, Dept Comp Sci & Engn, Kavaraipettai, India.
   [Vijaya, K.] RMK Engn Coll, Dept Informat & Technol, Kavaraipettai, India.
C3 R.M.K. Engineering College; R.M.K. Engineering College
RP Kavitha, P (corresponding author), RMK Engn Coll, Dept Comp Sci & Engn, Kavaraipettai, India.
EM pkavithaid@gmail.com
RI Kavitha, P/AAA-4939-2022; Kalavakonda, Vijaya/ABE-6435-2021; dhanendran,
   kavitha/AAE-9454-2019; Bueno, Regis Cortez/AAG-3852-2020; K,
   Vijaya/AEO-9880-2022
OI Bueno, Regis Cortez/0000-0002-2923-4930; K, Vijaya/0000-0002-1079-2449
CR Alcantarilla PF, 2013, IMAGE VISION COMPUT, V31, P103, DOI 10.1016/j.imavis.2012.11.001
   [Anonymous], 2011, 2011 INT JT C BIOM I, DOI DOI 10.1109/IJCB.2011.6117503
   [Anonymous], IEEE INT C IM PROC I
   [Anonymous], P 1 IEEE INT C BIOM, DOI [DOI 10.1109/BTAS.2007.4401919, 10.1109/BTAS.2007.4401919]
   [Anonymous], P IEEE C COMP VIS PA
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Chiang CL, 2005, IEEE T POWER SYST, V20, P1690, DOI 10.1109/TPWRS.2005.857924
   Chingovska I., 2012, 2012 BIOSIG P INT C, P1
   Cui F., 2011, Journal of Computational Information Systems, V7, P5723
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Dass SC, 2005, LECT NOTES COMPUT SC, V3546, P1049
   de Freitas Pereira Tiago, 2013, Biometrics (ICB), 2013 International Conference on, DOI DOI 10.1109/ICB.2013.6612981
   Deepak A, 2016, P INT C REC INN ENG, P237
   Feng LT, 2016, J VIS COMMUN IMAGE R, V38, P451, DOI 10.1016/j.jvcir.2016.03.019
   Galbally J, 2014, IEEE ACCESS, V2, P1530, DOI 10.1109/ACCESS.2014.2381273
   Galbally J, 2014, INT C PATT RECOG, P1173, DOI 10.1109/ICPR.2014.211
   Gao WF, 2012, J COMPUT APPL MATH, V236, P2741, DOI 10.1016/j.cam.2012.01.013
   Gragnaniello D, 2015, IEEE T INF FOREN SEC, V10, P849, DOI 10.1109/TIFS.2015.2404294
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Juan Luo, 2012, INT J IMAGE PROCESSI, V3, P143
   Karaboga D, 2011, APPL SOFT COMPUT, V11, P652, DOI 10.1016/j.asoc.2009.12.025
   Kollreider K, 2007, IEEE T INF FOREN SEC, V2, P548, DOI 10.1109/TIFS.2007.902037
   Li S. Z, 2014, Learn convolutional neural network for face anti-spoofing
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Park G, 2013, SENSORS-BASEL, V13, P2895, DOI 10.3390/s130302895
   Pereira TD, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-2
   Prabhakar S., 2003, IEEE Security & Privacy, V1, P33, DOI 10.1109/MSECP.2003.1193209
   Pradhan M, 2018, AIN SHAMS ENG J, V9, P2015, DOI 10.1016/j.asej.2016.08.023
   Rastislav Lukac KNP, 2007, COLOR IMAGE PROCESSI, V8
   Ross A., 2004, P BIOM CONS C BCC, P1
   Sánchez J, 2011, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2011.5995504
   Smith DF, 2015, IEEE T INF FOREN SEC, V10, P736, DOI 10.1109/TIFS.2015.2398819
   Srivastava Durgesh K., 2010, Journal of Theoretical and Applied Information Technology, V12, P1
   Srivastava D. K., 2009, J THEORETICAL APPL I, V12, P1
   Sundararaj, 2016, INT J INTELL ENG SYS, V9, P117, DOI [10.22266/ijies2016.0930.12, DOI 10.22266/IJIES2016.0930.12]
   Tirunagari S, 2015, IEEE T INF FOREN SEC, V10, P762, DOI 10.1109/TIFS.2015.2406533
   Tizhoosh HR, 2006, INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MODELLING, CONTROL & AUTOMATION JOINTLY WITH INTERNATIONAL CONFERENCE ON INTELLIGENT AGENTS, WEB TECHNOLOGIES & INTERNET COMMERCE, VOL 1, PROCEEDINGS, P695, DOI 10.1109/cimca.2005.1631345
   Wang T, 2013, INT CONF BIOMETR
   Wen D, 2015, IEEE T INF FOREN SEC, V10, P746, DOI 10.1109/TIFS.2015.2400395
   Yang B, 2011, SIGNAL PROCESS, V91, P2290, DOI 10.1016/j.sigpro.2011.04.012
   Yang WM, 2014, INFORM SCIENCES, V268, P20, DOI 10.1016/j.ins.2013.10.010
   Yonggang Lu, 2017, Multimedia Tools and Applications, V76, P10701, DOI 10.1007/s11042-015-3188-y
   ZHENG L, 2015, PROC CVPR IEEE, P1741, DOI DOI 10.1109/CVPR.2015.7298783
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
   Zheng L, 2014, IEEE T IMAGE PROCESS, V23, P3368, DOI 10.1109/TIP.2014.2330763
   Zhiwei Zhang, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P26, DOI 10.1109/ICB.2012.6199754
NR 54
TC 4
Z9 4
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26509
EP 26543
DI 10.1007/s11042-018-5877-9
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500014
DA 2024-07-18
ER

PT J
AU Shen, MY
   Zhang, YG
   Wang, RG
   Yang, J
   Xue, LX
   Hu, M
AF Shen, Mingyu
   Zhang, Yonggang
   Wang, Ronggui
   Yang, Juan
   Xue, Lixia
   Hu, Min
TI Robust object tracking via superpixels and keypoints
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Superpixels; Keypoints; Object tracking; Fusion vote
AB Most of the part-based methods just use the initial appearance model and feature information of the object. When the object is affected by occlusion, deformation and illumination factors, these methods can not be stable to the tracking object. In this paper, a tracking method is proposed based on keypoint matching and superpixel matching. Our method not only uses the initial feature information of the object, but also uses the feature information between adjacent frames. We use the superpixel to over-segment the candidate region which can be obtained by voting between the globally matched feature points, and then construct superpixel descriptors. The similarity between superpixels is based on the distance of the superpixel feature descriptor. Eventually, the object is selected according to the superpixel vote. Furthermore, we use qualitative and quantitative evaluations to evaluate our method on 18 challenging image sequences. Experimental results show that the proposed method outperforms 6 state-of-the-art tracking algorithms.
C1 [Shen, Mingyu; Zhang, Yonggang; Wang, Ronggui; Yang, Juan; Xue, Lixia; Hu, Min] Hefei Univ Technol, Coll Comp & Informat, Hefei 230009, Anhui, Peoples R China.
C3 Hefei University of Technology
RP Yang, J (corresponding author), Hefei Univ Technol, Coll Comp & Informat, Hefei 230009, Anhui, Peoples R China.
EM shenmy@126.com; yong_gang_zhang@outlook.com; wangrgui@foxmail.com;
   yangjuan6985@163.com; xlxzzm@163.com; jsjxhumin@hfut.edu.cn
RI Chen, YiJun/KFS-9282-2024; Hu, Min/HLH-2112-2023; Lin,
   Kuan-Yu/JXM-6653-2024
FU National Natural Science Foundation of China [61672202]
FX This work is partly supported by the National Natural Science Foundation
   of China under Project code (61672202).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bouachir W, 2015, IEEE WINT CONF APPL, P78, DOI 10.1109/WACV.2015.18
   Cai ZW, 2014, IEEE T IMAGE PROCESS, V23, P5497, DOI 10.1109/TIP.2014.2364919
   Derue F, 2016, COMPUTER VISION PATT
   Fan H, 2016, MULTIMED TOOLS APPL, V75, P8781, DOI 10.1007/s11042-015-2790-3
   Gao JY, 2017, IEEE T IMAGE PROCESS, V26, P1845, DOI 10.1109/TIP.2017.2656628
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hürst W, 2013, MULTIMED TOOLS APPL, V62, P233, DOI 10.1007/s11042-011-0983-y
   Kalal Zdenek, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2756, DOI 10.1109/ICPR.2010.675
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kwon J, 2009, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2009.5206502, DOI 10.1109/CVPR.2009.5206502]
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li AN, 2016, IEEE T PATTERN ANAL, V38, P335, DOI 10.1109/TPAMI.2015.2417577
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas BD, 1981, P IJCAI 81 P 7 INT J, V2
   Nebehay G, 2014, IEEE WINT CONF APPL, P862, DOI 10.1109/WACV.2014.6836013
   Nickels K, 2002, IMAGE VISION COMPUT, V20, P47, DOI 10.1016/S0262-8856(01)00076-2
   Ren X, 2007, IEEE C COMP VIS PATT, DOI [10. 1109/CVPR. 2007. 383177, DOI 10.1109/CVPR.2007.383177]
   Wang JQ, 2014, IEEE T CYBERNETICS, V44, P1237, DOI 10.1109/TCYB.2013.2296511
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Yang F, 2014, IEEE T IMAGE PROCESS, V23, P1639, DOI 10.1109/TIP.2014.2300823
   Yang X, 2016, IEEE T IND ELECTRON, V63, P3187, DOI 10.1109/TIE.2016.2515559
   Yang X, 2015, NEUROCOMPUTING, V159, P35, DOI 10.1016/j.neucom.2015.02.046
   Yuan Y, 2014, IEEE T CIRC SYST VID, V24, P15, DOI 10.1109/TCSVT.2013.2273631
   Zhang TZ, 2016, IEEE T CYBERNETICS, V46, P51, DOI 10.1109/TCYB.2015.2393307
   Zhang TZ, 2014, PROC CVPR IEEE, P1258, DOI 10.1109/CVPR.2014.164
NR 29
TC 4
Z9 4
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25109
EP 25129
DI 10.1007/s11042-018-5770-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400023
DA 2024-07-18
ER

PT J
AU Suresh, A
   Varatharajan, R
AF Suresh, A.
   Varatharajan, R.
TI RETRACTED: Recognition of pivotal instances from uneven set boundary
   during classification (Retracted article. See vol. 79, pg. 6915, 2020)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Classification; Feature selection; Boundary region; Rough set; Pivotal
   records
ID DISTANCE-BASED OUTLIERS; FEATURE-SELECTION; INFORMATION
AB Database may contain pivotal records-small chunks of records or instances consist of important information specific to the domain. These chunks of instances may contain crucial information which assists in decision making by assigning labels to pivotal records, unlabeled data instances and improves accuracy of the classification model. Our work suggests the heuristic Rough Set Boundary detection for approximating the boundary set efficiently from the large database to reduce the search space substantially for finding critical records. The use of Rough Set Boundary detection has the advantage of obtaining rough set from the original data set which confines the search space only to the boundary. It uses the concept of pivotal score for each instance in the boundary to isolate the critical records. The method also exploits Feature Selection technique for reduced set of attributes in order to obtain less computational time. The proposed work retrieves the pivotal records from the boundary set and also improves the classification accuracy by increasing true positive and true negative errors. Experiments are carried out for real-world medical data sets with numeric values and various classification algorithms are executed to validate the results. Result shows that the identification of pivotal records from rough boundary set helps for improved classification accuracy using less computational time and which are validated using real-world data sets.
C1 [Suresh, A.] Nehru Inst Engn & Technol, Dept Comp Sci & Engn, Coimbatore 641105, Tamil Nadu, India.
   [Varatharajan, R.] Sri Lakshmi Ammaal Engn Coll, Dept Elect & Commun Engn, Madras, Tamil Nadu, India.
RP Suresh, A (corresponding author), Nehru Inst Engn & Technol, Dept Comp Sci & Engn, Coimbatore 641105, Tamil Nadu, India.
EM prisu6esh@yahoo.com; varathu21@yahoo.com
RI Annamalai, Suresh/AAV-3631-2021; A, Suresh/X-6119-2019
OI A, Suresh/0000-0001-7439-2834
CR Angiulli F, 2013, IEEE T KNOWL DATA EN, V25, P1520, DOI 10.1109/TKDE.2012.71
   Anitha A., 2014, J THEORETICAL APPL I, V67
   Anitha A., 2014, IEEE INT C COMP INT, P1
   [Anonymous], 1998, Learning from Data: Concepts, Theory, and Methods
   [Anonymous], YUGOSLAV J OPERATION
   Balamurugan SAA, 2009, INT J AUTOM COMPUT, V6, P62, DOI 10.1007/s11633-009-0062-2
   Dantong Yu, 2002, Knowledge and Information Systems, V4, P387, DOI 10.1007/s101150200013
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Fan JY, 2017, MULTIMED TOOLS APPL, V76, P10169, DOI 10.1007/s11042-016-3604-y
   Ghoting A, 2008, DATA MIN KNOWL DISC, V16, P349, DOI 10.1007/s10618-008-0093-2
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Hu QH, 2008, INFORM SCIENCES, V178, P3577, DOI 10.1016/j.ins.2008.05.024
   Hu QH, 2007, LECT NOTES ARTIF INT, V4482, P508
   Huang CL, 2006, EXPERT SYST APPL, V31, P231, DOI 10.1016/j.eswa.2005.09.024
   Jiang MF, 2001, PATTERN RECOGN LETT, V22, P691, DOI 10.1016/S0167-8655(00)00131-8
   Knorr E. M., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P392
   Knorr EM, 2000, VLDB J, V8, P237, DOI 10.1007/s007780050006
   MITCHELL T, 1989, ANNU REV COMPUT SCI, V4, P417
   Parthaláin NM, 2010, IEEE T KNOWL DATA EN, V22, P305, DOI 10.1109/TKDE.2009.119
   PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Poulisse GJ, 2014, MULTIMED TOOLS APPL, V70, P159, DOI 10.1007/s11042-012-1086-0
   Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882
   Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344
   Sathiaraj D, 2013, IEEE T KNOWL DATA EN, V25, P1354, DOI 10.1109/TKDE.2012.112
   Song QB, 2013, IEEE T KNOWL DATA EN, V25, P1, DOI 10.1109/TKDE.2011.181
   Thivagar M. L., 2012, Information Science, V2, P33
   Ye M, 2009, EXPERT SYST APPL, V36, P7104, DOI 10.1016/j.eswa.2008.08.030
   Ye N, 2001, IEEE T SYST MAN CY A, V31, P266, DOI 10.1109/3468.935043
NR 29
TC 6
Z9 6
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 27075
EP 27088
DI 10.1007/s11042-018-5905-9
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500038
DA 2024-07-18
ER

PT J
AU Hmimid, A
   Sayyouri, M
   Qjidaa, H
AF Hmimid, Abdeslam
   Sayyouri, Mhamed
   Qjidaa, Hassan
TI Image classification using separable invariant moments of
   Charlier-Meixner and support vector machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bivariate polynomials; Charlier-Meixner invariant moments; Pattern
   recognition, classification, support vector machine
ID FAST COMPUTATION; ORTHOGONAL POLYNOMIALS; GEOMETRIC MOMENTS; SCALE
   INVARIANTS; TRANSLATION; RECOGNITION; GRADIENTS; BINARY
AB In this paper, we propose a new method for image classification by the content in heterogeneous databases. This approach is based on the use of new series of separable discrete orthogonal moments as shape descriptors and the Support Vector Machine as classifier. In fact, the proposed descriptors moments are defined from the bivariate discrete orthogonal polynomials of Charlier-Meixner which are invariant to translation, scaling and rotation of the image. We also propose a new algorithm to accelerate the image classification process. This algorithm is based on two steps: the first step is the fast computation of the values of Charlier-Meixner polynomials by using a new recurrence relationship between the values of polynomials Charlier-Meixner. The second one is the new image representation and slice blocks. The proposed method is tested on three different sets of standard data which are well known to computer vision: COIL-100, 256-CALTECH and Corel. The simulation results show the invariance of the discrete orthogonal separable moments of Charlier-Meixner against the various geometric transformations and the ability for the classification of heterogeneous images.
C1 [Hmimid, Abdeslam; Qjidaa, Hassan] Sidi Mohamed Ben Abdellah Univ, CED ST, BP 1796 Fez Atlas, Fes 30003, Morocco.
   [Hmimid, Abdeslam; Qjidaa, Hassan] Sidi Mohamed Ben Abdellah Univ, Fac Sci Dhar El Meluaz, LESSI, BP 1796 Fez Atlas, Fes 30003, Morocco.
   [Sayyouri, Mhamed] Univ Chouaib Doukkali, Ecole Natl Sci Appl El Jadida ENSAJ, Lab Sci Ingenieur Energie LapSIPE, BP 1166, El Jadida Plateau 24004, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez; Chouaib Doukkali University of El Jadida
RP Sayyouri, M (corresponding author), Univ Chouaib Doukkali, Ecole Natl Sci Appl El Jadida ENSAJ, Lab Sci Ingenieur Energie LapSIPE, BP 1166, El Jadida Plateau 24004, Morocco.
EM abdeslam_ph@yahoo.fr; mhamed.sayyouri@usmba.ac.ma; qjidah@yahoo.fr
RI Sayyouri, Mhamed/AAB-5496-2020
OI Sayyouri, Mhamed/0000-0002-1615-419X; Hassan, qjidaa/0000-0003-4505-5243
CR ABUMOSTAFA YS, 1984, IEEE T PATTERN ANAL, V6, P698, DOI 10.1109/TPAMI.1984.4767594
   [Anonymous], URBAN WATER QUALITY
   [Anonymous], ACTION2ACTIVITY RECO
   Chong CW, 2004, PATTERN RECOGN, V37, P119, DOI 10.1016/j.patcog.2003.06.003
   Chong CW, 2003, PATTERN RECOGN, V36, P1765, DOI 10.1016/S0031-3203(02)00353-9
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng C, 2015, SIGNAL PROCESS, V112, P137, DOI 10.1016/j.sigpro.2014.07.017
   Dunkl C.F., 2001, ENCYCL MATH, V81
   Fernández L, 2007, J COMPUT APPL MATH, V199, P113, DOI 10.1016/j.cam.2005.09.029
   Fernández L, 2011, J APPROX THEORY, V163, P84, DOI 10.1016/j.jat.2009.08.007
   Flusser J, 2000, IEEE T IMAGE PROCESS, V9, P1977, DOI 10.1109/83.877219
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Hmimid A, 2015, PATTERN RECOGN, V48, P509, DOI 10.1016/j.patcog.2014.08.020
   Hmimid A, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.1.013026
   Hosny KM, 2007, APPL MATH COMPUT, V189, P1214, DOI 10.1016/j.amc.2006.12.025
   Hosny KM, 2011, PATTERN RECOGN LETT, V32
   Hu HJ, 2016, NEUROCOMPUTING, V181, P86, DOI 10.1016/j.neucom.2015.05.134
   Hu HJ, 2014, MULTIMED TOOLS APPL, V69, P199, DOI 10.1007/s11042-012-1248-0
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Hu YX, 2016, J VIS COMMUN IMAGE R, V37, P53, DOI 10.1016/j.jvcir.2015.04.004
   Huang L, 2015, NEUROCOMPUTING, V149, P1573, DOI 10.1016/j.neucom.2014.08.035
   Jie X, 2017, 26 INT JOINT C ART I, DOI [10.24963/ijcai.2017/440, DOI 10.24963/IJCAI.2017/440]
   Karakasis EG, 2013, PATTERN RECOGN, V46, P1998, DOI 10.1016/j.patcog.2013.01.008
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Koekoek R, 2010, SPRINGER MONOGR MATH, P1, DOI 10.1007/978-3-642-05014-5
   Koornwinder T., 1975, THEORY APPL SPECIAL, P435
   Li ZC, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2624140
   Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035
   Li ZC, 2015, IEEE T PATTERN ANAL, V37, P2085, DOI 10.1109/TPAMI.2015.2400461
   Liao SX, 1996, IEEE T PATTERN ANAL, V18, P254, DOI 10.1109/34.485554
   Lim CL, 2011, INFORM SCIENCES, V181, P3638, DOI 10.1016/j.ins.2011.04.029
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu MF, 2017, MULTIMED TOOLS APPL, V76, P10555, DOI 10.1007/s11042-015-3093-4
   Liu MF, 2016, NEUROCOMPUTING, V208, P127, DOI 10.1016/j.neucom.2016.01.096
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Nikiforov AF, 1991, CLASSICAL ORTHOGONAL
   Papakostas GA, 2008, PATTERN RECOGN, V41, P1895, DOI 10.1016/j.patcog.2007.11.015
   Papakostas GA, 2010, IMAGE VISION COMPUT, V28, P414, DOI 10.1016/j.imavis.2009.06.011
   Preotiuc-Pietro D, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P729, DOI 10.18653/v1/P17-1068
   Sayyouri M, 2012, 2 ED IEEE C INF SCI
   Sayyouri M., 2012, IEEE INT C COMPL SYS, P1
   Sayyouri M, 2015, CIRC SYST SIGNAL PR, V34, P875, DOI 10.1007/s00034-014-9881-7
   Sayyouri M, 2013, J OPT SOC AM A, V30, P2381, DOI 10.1364/JOSAA.30.002381
   Sayyouri M, 2012, COLLOQ INF SCI TECH, P101, DOI 10.1109/CIST.2012.6388071
   Shu HZ, 2010, IEEE T IMAGE PROCESS, V19, P3171, DOI 10.1109/TIP.2010.2052276
   Spiliotis IM, 1998, IEEE T IMAGE PROCESS, V7, P1609, DOI 10.1109/83.725368
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   Tsougenis E., 2014, MULTIMED TOOLS APPL, P1
   Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640
   Xia YJ, 2017, IEEE T IMAGE PROCESS, V26, P3748, DOI 10.1109/TIP.2016.2639438
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
   Yuan X, 2004, ADV APPL MATH, V33, P615, DOI 10.1016/j.aam.2004.03.002
   Zhang H, 2010, IMAGE VISION COMPUT, V28, P38, DOI 10.1016/j.imavis.2009.04.004
   Zhang LM, 2016, IEEE T IMAGE PROCESS, V25, P553, DOI 10.1109/TIP.2015.2502147
   Zhu H, 2010, IET IMAGE PROCESS, V4, P335, DOI 10.1049/iet-ipr.2009.0195
   Zhu HQ, 2007, PATTERN RECOGN, V40, P2530, DOI 10.1016/j.patcog.2006.12.003
   Zhu HQ, 2012, PATTERN RECOGN, V45, P1540, DOI 10.1016/j.patcog.2011.10.002
   Zhu HQ, 2007, SIGNAL PROCESS, V87, P687, DOI 10.1016/j.sigpro.2006.07.007
NR 63
TC 16
Z9 16
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23607
EP 23631
DI 10.1007/s11042-018-5623-3
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900024
DA 2024-07-18
ER

PT J
AU Xue, YB
   Geng, HQ
   Zhang, H
   Xue, ZS
   Xu, GP
AF Xue, Yanbing
   Geng, Huiqiang
   Zhang, Hua
   Xue, Zhenshan
   Xu, Guangping
TI Semantic segmentation based on fusion of features and classifiers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fusion; Features; Super-pixels; Multiple classifiers; CRF
AB This paper proposes a feed forward architecture algorithm using fusion of features and classifiers for semantic segmentation. The algorithm consists of three phases: Firstly, the features from hierarchical convolutional neural network (CNN) and the features based on region are extracted and fused on super pixel level; secondly, multiple classifiers of Softmax, XGBoost and Random Forest are ensemble to compute the per-pixel class probabilities; at last, a fully connected conditional random field is employed to enhance the final performance. The hierarchical features contain more global evidence and the region features contain more local evidence. So the fusion of these two features is expected to enhance the feature representation ability. In classification phase, integrating multiple classifiers aims to improve the generalization ability of classification algorithms. Experiments are conducted on Sift-Flow datasets by our proposed methods with competitive labeling accuracy.
C1 [Xue, Yanbing; Geng, Huiqiang; Zhang, Hua; Xue, Zhenshan; Xu, Guangping] Tianjin Univ Technol, Key Lab Comp Vis & Syst, Minist Educ, Tianjin, Peoples R China.
   [Xue, Yanbing; Geng, Huiqiang; Xue, Zhenshan; Xu, Guangping] Tianjin Univ Technol, Tianjin Key Lab Intelligence Comp & Novel Softwar, Tianjin, Peoples R China.
   [Zhang, Hua] Tianjin Sinogerman Univ Appl Sci, Tianjin, Peoples R China.
C3 Tianjin University of Technology; Tianjin University of Technology;
   Tianjin Sino-German University of Applied Sciences
RP Xue, YB (corresponding author), Tianjin Univ Technol, Key Lab Comp Vis & Syst, Minist Educ, Tianjin, Peoples R China.; Xue, YB (corresponding author), Tianjin Univ Technol, Tianjin Key Lab Intelligence Comp & Novel Softwar, Tianjin, Peoples R China.
EM yanbingxue@163.com
RI Xue, Zhenshan/AAF-8591-2019
OI Xue, Zhenshan/0000-0002-7294-361X; xue, yanbing/0000-0003-2249-1480; Xu,
   Guangping/0000-0001-5221-0331
FU National Natural Science Foundation of China [U1509207, 61472278,
   61403281, 61572357]
FX This research has been supported by National Natural Science Foundation
   of China (U1509207, 61472278, 61403281 and 61572357).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], IEEE TPAMI
   [Anonymous], 2015, CVPR
   [Anonymous], NI PS
   [Anonymous], WORKSH CVPR
   [Anonymous], IEEE CVPR
   [Anonymous], ACM T MULTIMED COMPU
   [Anonymous], ARXIV150203240
   [Anonymous], 2017, ARXIV170405519V1
   [Anonymous], 2014, ECCV
   [Anonymous], 2012, ECCV
   [Anonymous], ICLRW
   [Anonymous], 2016, ARXIV160404339
   [Anonymous], CVPR 2015
   [Anonymous], 2015, P IEEE INT C COMPUTE
   [Anonymous], CVPR
   [Anonymous], 2014, ICML
   [Anonymous], ARXIV160707671
   [Anonymous], 2014, NIPS
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bertasius G, 2015, IEEE I CONF COMP VIS, P504, DOI 10.1109/ICCV.2015.65
   Bu SH, 2016, PATTERN RECOGN, V59, P188, DOI 10.1016/j.patcog.2016.01.027
   Byeon W., 2015, CVPR
   Gao Z, 2014, MULTIMED TOOLS APPL, V68, P641, DOI 10.1007/s11042-012-1071-7
   Girshick R., 2013, IEEE Comput. Soc., P580
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kokkinos I., 2015, arXiv preprint arXiv:151107386
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Plath Nils., 2009, ICML
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P572, DOI 10.1109/TMM.2012.2234731
   Zavaschi THH, 2013, EXPERT SYST APPL, V40, P646, DOI 10.1016/j.eswa.2012.07.074
NR 31
TC 3
Z9 3
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22199
EP 22211
DI 10.1007/s11042-018-5858-z
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500025
DA 2024-07-18
ER

PT J
AU Zhang, B
   Zhu, L
   Sun, JD
   Zhang, HX
AF Zhang, Bin
   Zhu, Lei
   Sun, Jiande
   Zhang, Huaxiang
TI Cross-media retrieval with collective deep semantic learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-media retrieval; Collective deep semantic learning; Deep neural
   network; Deep restricted boltzmann machines
ID IMAGES
AB Cross-media retrieval is becoming a new trend of information retrieval technique. It has been received great attentions from both academia and industry. In this paper, we propose an effective retrieval method, dubbed as Cross-media Retrieval with Collective Deep Semantic Learning (CR-CDSL), to solve the problem. Two complementary deep neural networks are first learned to collectively project image and text samples into a joint semantic representation. Based on it, weak semantic labels are then generated accordingly for unlabeled images and texts. They are exploited further with the pre-labeled training samples to retrain the retrieval model, which can discover a discriminative shared semantic space for achieving cross-media retrieval. Specifically, Deep Restricted Boltzmann Machines (DRBM) is employed to initialize the weights of two deep neural networks. With the weak labels generated from collective deep semantic learning, the discriminative capability of retrieval model can be enhanced. Thus, the retrieval performance of the model could be improved. Experiments are evaluated on several publicly available cross-media datasets. The obtained experimental results demonstrate the superior performance of the proposed approach compared with several state-of-the-art techniques.
C1 [Zhang, Bin; Zhu, Lei; Sun, Jiande; Zhang, Huaxiang] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
   [Zhang, Bin; Zhu, Lei; Sun, Jiande; Zhang, Huaxiang] Shandong Normal Univ, Inst Data Sci & Technol, Jinan 250014, Shandong, Peoples R China.
C3 Shandong Normal University; Shandong Normal University
RP Zhu, L; Sun, JD; Zhang, HX (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.; Zhu, L; Sun, JD; Zhang, HX (corresponding author), Shandong Normal Univ, Inst Data Sci & Technol, Jinan 250014, Shandong, Peoples R China.
EM leizhu0608@gmail.com; jiandesun@hotmail.com; huaxzhang@l63.com
RI Zhu, Lei/GQQ-1130-2022; Zhang, Bin/IWU-4448-2023; Zhu, Lei/AAC-6810-2019
OI Zhu, Lei/0000-0002-5348-7532; Zhang, Bin/0000-0001-9214-1588; Zhu,
   Lei/0000-0002-2993-7142
FU National Natural Science Foundation of China [61572298, 61772322,
   61601268]; Key Research and Development Foundation of Shandong Province
   [2016GGX101009]; Natural Science Foundation of Shandong China
   [2017GGX10117]
FX The work is partially supported by the National Natural Science
   Foundation of China (Nos. 61572298, 61772322, 61601268), the Key
   Research and Development Foundation of Shandong Province (No.
   2016GGX101009) and the Natural Science Foundation of Shandong China (No.
   2017GGX10117). We also gratefully acknowledge the support of NVIDIA
   Corporation with the donation of the TITAN X GPU used for this research.
CR [Anonymous], 2015, CVPR
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], 2006, Advances in Neural Information Processing Systems 19
   [Anonymous], IEEE T MULTIMEDIA
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], ADV CONDENSED MATTER, DOI DOI 10.1002/aenm.201702149
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Boureau Y.-l., 2008, ADV NEURAL INFORM PR, P1185
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chua T.-S., 2009, CIVR, P1, DOI 10.1145/1646396.1646452
   Dong X, 2018, MULTIMED TOOLS APPL, V77, P3579, DOI 10.1007/s11042-017-5164-1
   Gao Z, 2017, J VIS COMMUN IMAGE R, V48, P442, DOI 10.1016/j.jvcir.2017.03.014
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   Gao Z, 2014, MULTIMED TOOLS APPL, V68, P641, DOI 10.1007/s11042-012-1071-7
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Lee H., 2007, NIPS
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo MN, 2017, COMPUT VIS IMAGE UND, V163, P67, DOI 10.1016/j.cviu.2017.07.001
   Peng YW, 2017, INT GEOL REV, V59, P1344, DOI 10.1080/00206814.2016.1236354
   Peng YX, 2017, FRONT INFORM TECH EL, V18, P44, DOI 10.1631/FITEE.1601787
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Rosipal R, 2006, LECT NOTES COMPUT SC, V3940, P34, DOI 10.1007/11752790_2
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Sun JD, 2016, NEUROCOMPUTING, V213, P84, DOI 10.1016/j.neucom.2016.05.098
   Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349
   Wang K., 2016, ABS160706215 CORR
   Wang KY, 2016, IEEE T PATTERN ANAL, V38, P2010, DOI 10.1109/TPAMI.2015.2505311
   Wei YC, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2775109
   Xie L, 2016, MULTIMED TOOLS APPL, V75, P9185, DOI 10.1007/s11042-016-3432-0
   Xie L, 2016, SIGNAL PROCESS, V124, P81, DOI 10.1016/j.sigpro.2015.10.010
   Xu P., 2017, Neurocomputing
   Yan JH, 2018, MULTIMED TOOLS APPL, V77, P3009, DOI 10.1007/s11042-017-4918-0
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Zhang HW, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2978656
   Zhang L, 2017, IEEE T MULTIMEDIA, V19, P1220, DOI 10.1109/TMM.2016.2646219
   Zhu L., 2016, IJCAI, P3959
   Zhu L, 2017, IEEE T CYBERNETICS, V47, P3941, DOI 10.1109/TCYB.2016.2591068
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
   Zhu L, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P843, DOI 10.1145/2733373.2806345
NR 46
TC 19
Z9 19
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22247
EP 22266
DI 10.1007/s11042-018-5896-6
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500028
DA 2024-07-18
ER

PT J
AU Bose, A
   Maity, SP
AF Bose, Anirban
   Maity, Santi P.
TI Spread spectrum image watermark detection on degraded compressed sensing
   measurements with distortion minimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spread spectrum watermarking; Compressed sensing; Log-likelihood ratio
   test; Distortion minimization
ID MEDICAL IMAGES; WAVELET DOMAIN; DWT-DOMAIN; MULTIPLICATIVE NOISE;
   ENERGY-EFFICIENT; TRANSMISSION; RELIABILITY; STATISTICS; SYSTEM; MODEL
AB In the age of digital world, the wide dissemination of images need bandwidth (BW) efficient transmission as well as ownership protection during transmission over radio mobile channel. Compressed sensing (CS) nowadays finds a potential application for BW efficient transmission over wireless network while digital watermarking, more specifically, spread spectrum (SS) watermarking is found to be efficient for copyright protection. To this aim, an SS watermarking scheme on CS images is proposed in presence of both multiplicative and additive impairments that support a general framework of radio mobile channel. First a mathematical form of watermark detection threshold in log-likelihood ratio model is derived followed by an optimization framework to minimize the visual distortion that includes CS reconstruction and watermark embedding distortion while satisfying some certain detection reliability constraints. An approximate closed form solution to the optimization problem in terms of embedding strength and a set of appropriate host samples selection for a given number of CS measurements is derived. A large set of simulation results on Rayleigh distribution as multiplicative degradation and Gaussian distribution as additive noise are reported. Performance comparison with the existing works validate the efficacy of the proposed method in terms of imperceptibility and improved detection reliability against a large set of diverse signal processing operations.
C1 [Bose, Anirban; Maity, Santi P.] Indian Inst Engn Sci & Technol, Dept Informat Technol, Sibpur 711103, Howrah, India.
C3 Indian Institute of Engineering Science Technology Shibpur (IIEST)
RP Maity, SP (corresponding author), Indian Inst Engn Sci & Technol, Dept Informat Technol, Sibpur 711103, Howrah, India.
EM anirban.bose2006@gmail.com; santipmaity@it.iiests.ac.in
RI bose, anirban/AAN-8665-2021
OI bose, anirban/0000-0001-6524-0839
CR Amini M, 2017, MULTIMED TOOLS APPL, V76, P3731, DOI 10.1007/s11042-016-3975-0
   Amirmazlaghani M, 2016, INFORM SCIENCES, V370, P1, DOI 10.1016/j.ins.2016.06.037
   [Anonymous], 2016, PROC INT C SIGNAL PR
   [Anonymous], 1998, FUNDEMENTALS STAT SI
   Arsalan M, 2012, J SYST SOFTWARE, V85, P883, DOI 10.1016/j.jss.2011.11.005
   Bian Y, 2013, IET IMAGE PROCESS, V7, P281, DOI 10.1049/iet-ipr.2012.0345
   Bose A, 2017, IEEE SENSORS LETT, V1
   Bose A, 2014, PROC 5 EUROPEAN WORK, P1
   Bouslimi D, 2012, IEEE T INF TECHNOL B, V16, P891, DOI 10.1109/TITB.2012.2207730
   Bouslimi D, 2012, COMPUT METH PROG BIO, V106, P47, DOI 10.1016/j.cmpb.2011.09.015
   Catrysse PB, 2002, J OPT SOC AM A, V19, P1610, DOI 10.1364/JOSAA.19.001610
   Coatrieux G, 2013, IEEE J BIOMED HEALTH, V17, P1057, DOI 10.1109/JBHI.2013.2263533
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Davenport MA, 2010, IEEE J-STSP, V4, P445, DOI 10.1109/JSTSP.2009.2039178
   Dong L, 2017, MULTIMED TOOLS APPL, V76, P1983, DOI 10.1007/s11042-015-3115-2
   Dong YQ, 2013, SIAM J IMAGING SCI, V6, P1598, DOI 10.1137/120870621
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Hao Y, 2012, SIGNAL PROCESS, V92, P1536, DOI 10.1016/j.sigpro.2011.12.015
   Hartung F, 1999, P IEEE, V87, P1079, DOI 10.1109/5.771066
   Hsiang-Cheh Huang, 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P223, DOI 10.1109/IIH-MSP.2012.60
   Kumsawat P, 2005, IEEE T SIGNAL PROCES, V53, P4707, DOI 10.1109/TSP.2005.859323
   Kwitt R, 2011, IEEE T IMAGE PROCESS, V20, P474, DOI 10.1109/TIP.2010.2064327
   Liu LX, 2016, SIGNAL PROCESS-IMAGE, V40, P1, DOI 10.1016/j.image.2015.10.005
   Lukac R, 2009, IMAGE PROCESS SER, P1
   Ma B, 2016, IEEE T INF FOREN SEC, V11, P1914, DOI 10.1109/TIFS.2016.2566261
   Maheshkar S, 2016, P 5 INT C SOFT COMP, P105
   Maity SP, 2013, WIRELESS PERS COMMUN, V72, P1737, DOI 10.1007/s11277-013-1132-x
   Maity SP, 2013, J SYST SOFTWARE, V86, P47, DOI 10.1016/j.jss.2012.06.057
   Maity SP, 2010, ADV TECHNIQUES MULTI
   Majumdar A, 2015, INT CONF ACOUST SPEE, P837, DOI 10.1109/ICASSP.2015.7178087
   Malvar HS, 2003, IEEE T SIGNAL PROCES, V51, P898, DOI 10.1109/TSP.2003.809385
   Ng TM, 2005, IEEE SIGNAL PROC LET, V12, P285, DOI 10.1109/LSP.2005.843776
   Pantazis NA, 2013, IEEE COMMUN SURV TUT, V15, P551, DOI 10.1109/SURV.2012.062612.00084
   Phadikar A, 2012, COMPUT ELECTR ENG, V38, P1278, DOI 10.1016/j.compeleceng.2011.10.014
   Pudlewski S, 2013, IEEE COMMUN SURV TUT, V15, P754, DOI 10.1109/SURV.2012.121912.00154
   Rabizadeh M, 2016, J VIS COMMUN IMAGE R, V40, P324, DOI 10.1016/j.jvcir.2016.07.001
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Srivastava A, 2003, J MATH IMAGING VIS, V18, P17, DOI 10.1023/A:1021889010444
   Valizadeh A, 2012, IEEE T INF FOREN SEC, V7, P1127, DOI 10.1109/TIFS.2012.2199312
   Wang JW, 2017, MULTIDIM SYST SIGN P, V28, P617, DOI 10.1007/s11045-015-0363-2
   Wang Q, 2014, IEEE T IMAGE PROCESS, V23, P1317, DOI 10.1109/TIP.2014.2298980
   Xiao D, 2014, ELECTRON LETT, V50, P598, DOI 10.1049/el.2013.3806
   Xie X., 2014, Proc. of Solid-State Sensors, Actuators, P127
   Xie X, 2017, PROC IEEE MICR ELECT, P813, DOI 10.1109/MEMSYS.2017.7863532
   Xie X, 2016, PROC IEEE MICR ELECT, P75, DOI 10.1109/MEMSYS.2016.7421561
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
   Yamashita M.M., 2013, Proc. SIGGRAPH2013 Posters. Anaheim, P1
   Yuan XC, 2013, SIGNAL PROCESS, V93, P2087, DOI 10.1016/j.sigpro.2013.01.024
   Zachevsky I, 2016, IEEE T IMAGE PROCESS, V25, P2130, DOI 10.1109/TIP.2016.2539689
   Zhang M, 2013, I CONF VLSI DESIGN, P31, DOI 10.1109/VLSID.2013.158
NR 52
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 20783
EP 20808
DI 10.1007/s11042-017-5462-7
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300022
DA 2024-07-18
ER

PT J
AU Cowdrey, KWG
   Malekian, R
AF Cowdrey, Kevin William George
   Malekian, Reza
TI Home automation - an IoT based system to open security gates using
   number plate recognition and artificial neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Licence plate recognition; Home automation; Artificial neural networks;
   Feature extraction; Image edge detection; Internet of things; Mobile
   applications
ID PARALLEL FRAMEWORK; HEVC
AB This paper proposed a system that automatically opens security gates. A system is designed and implemented to automatically open security gates for vehicles using Licence Plate Recognition. Image processing is used to extract the licence plate and characters, and an Artificial Neural Network is used to perform Optical Character Recognition on licence plate characters. Internet of Things principles are introduced to the system to allow for web and mobile application integration. A proximity sensor is designed to detect vehicles and to start the recognition process. An ambient light sensor and control circuit is developed to control ambient lighting conditions using an ambient light source. The neural network achieved an accuracy of 88% on training data and 93% on licence plate characters. A unique strong point of the system is the ability to monitor and control the system using a web interface or mobile application. The system is also able to produce mobile notifications regarding security gate access attempts.
C1 [Cowdrey, Kevin William George; Malekian, Reza] Univ Pretoria, Dept Elect Elect & Comp Engn, ZA-0002 Pretoria, South Africa.
C3 University of Pretoria
RP Malekian, R (corresponding author), Univ Pretoria, Dept Elect Elect & Comp Engn, ZA-0002 Pretoria, South Africa.
EM u12066754@tuks.co.za; reza.malekian@up.ac.za
RI Malekian, Reza/F-7647-2015
OI Malekian, Reza/0000-0002-2763-8085
FU National Research Foundation, South Africa [IFR160118156967,
   RDYR160404161474]
FX This work is supported in part by the National Research Foundation,
   South Africa (grant numbers: IFR160118156967 and RDYR160404161474). The
   authors would like thank Mr. Arun Jose Cyril for editing revised version
   of this paper.
CR [Anonymous], 2012, International Journal of Machine Learning and Computing, DOI [DOI 10.7763/IJMLC.2012.V2.95, 10.7763/ijmlc.2012.v2.95]
   Bovik AC, 2011, DIGITAL IMAGE PROCES
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Neto EC, 2015, IEEE LAT AM T, V13, P272, DOI 10.1109/TLA.2015.7040658
   Chang SL, 2004, IEEE T INTELL TRANSP, V5, P42, DOI 10.1109/TITS.2004.825086
   Dedgaonkar SuruchiG., 2012, International Journal of Engineering and Innovative Technology (IJEIT), V1, P180
   Dhar P, 2016, 2016 INTERNATIONAL CONFERENCE ON AUTOMATIC CONTROL AND DYNAMIC OPTIMIZATION TECHNIQUES (ICACDOT), P30, DOI 10.1109/ICACDOT.2016.7877546
   Fowler K., 1996, Electronic Instrument Design, Vthird
   Gilli M., 2019, NUMERICAL METHODS OP, VSecond, P219
   Hagan MT, 1997, NEURAL NETWORK DESIG
   Huang HP, 2016, TSINGHUA SCI TECHNOL, V21, P385, DOI 10.1109/TST.2016.7536716
   Ibrahim NK, 2013, Int J Soft Comput Softw Eng, V3, P94, DOI [10.7321/jscse.v3.n3.15, DOI 10.7321/JSCSE.V3.N3.15]
   International Telecommunication Union, 2002, BT7095 ITUR, V5, P3
   Jayalakshmi P, 2013, INT J EMERG TRENDS E, V4, P65
   Mousa A, 2012, INT J SIGNAL PROCESS, V5, P1
   Nunes RJC, 2004, IEEE MEDITERR ELECT, P693, DOI 10.1109/MELCON.2004.1347024
   Ondrej M, 2007, ALGORITHMIC MATH PRI, P20
   Phillips D, 1994, IMAGE PROCESSING C, V2
   Prinsloo J, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16060825
   Sergio F, 2001, DESIGN OPERATIONAL A
   Tu JV, 1996, J CLIN EPIDEMIOL, V49, P1225, DOI 10.1016/S0895-4356(96)00002-9
   Uddin Ahmed Afaz, 2014, International Journal of Intelligent Systems and Applications, V6, P22, DOI 10.5815/ijisa.2014.02.03
   Van Heerden R P., 2002, Hidden Markov models for robust recognition of vehicle licence plates
   Wang CG, 2013, IEEE SENS J, V13, P3505, DOI 10.1109/JSEN.2013.2274906
   Wang ZQ, 2016, AD HOC NETW, V53, P132, DOI 10.1016/j.adhoc.2016.09.026
   Wang ZQ, 2016, ELEKTRON ELEKTROTECH, V22, P114, DOI 10.5755/j01.eie.22.2.14603
   Xu Y, 2011, IEEE T CIRC SYST VID, V21, P1255, DOI 10.1109/TCSVT.2011.2138790
   Xue ZH, 2017, IEEE T GEOSCI REMOTE, V55, P2351, DOI 10.1109/TGRS.2016.2641985
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Ye N, 2016, KSII T INTERNET INF, V10, P3150, DOI 10.3837/tiis.2016.07.016
   Zurada J.M., 1992, INTRO ARTIFICIAL NEU
NR 34
TC 3
Z9 3
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 20325
EP 20354
DI 10.1007/s11042-017-5407-1
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300003
DA 2024-07-18
ER

PT J
AU Di, FQ
   Huang, FJ
   Zhang, MQ
   Liu, J
   Yang, XY
AF Di, Fuqiang
   Huang, Fangjun
   Zhang, Minqing
   Liu, Jia
   Yang, Xiaoyuan
TI Reversible data hiding in encrypted images with high capacity by
   bitplane operations and adaptive embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Encrypted image; Bitplane operations; Adaptive
   embedding
ID DIFFERENCE; AUTHENTICATION; SCHEME
AB Reversible data hiding in encrypted images (RDHEI) is a technique that makes contributions to cloud data management in privacy preservation and data security. A novel framework of RDHEI with high embedding capacity based on bitplane operations and adaptive embedding is proposed. Three parties constitute the proposed system: the content owner, the data hider and the receiver. First, the content owner encrypts the original image for privacy protection. A data hider partitions the encrypted image into two sub images by bitplane-level operations and embeds additional data with an adaptive embedding strategy. With the encrypted image containing the embedded data, the receiver can extract the embedded data without any error and losslessly recover the original image according to specific requirements. The proposed framework can not only work for many different specific image encryption methods but also accomplish hundreds of reversible data hiding (RDH) algorithms directly in the encrypted domain. Extensive experiments demonstrate that the proposed framework can significantly increase the embedding capacity of some existing RDHEI frameworks, although it may reduce the PSNR value.
C1 [Di, Fuqiang; Zhang, Minqing; Liu, Jia; Yang, Xiaoyuan] Engn Univ Chinese Peoples Armed Police, Dept Elect Technol, Xian 710086, Shaanxi, Peoples R China.
   [Huang, Fangjun] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.
   [Huang, Fangjun] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
C3 Sun Yat Sen University; Chinese Academy of Sciences; Institute of
   Information Engineering, CAS
RP Zhang, MQ (corresponding author), Engn Univ Chinese Peoples Armed Police, Dept Elect Technol, Xian 710086, Shaanxi, Peoples R China.
EM 1054165690@qq.com
FU National Natural Science Foundation of China [61379152, 61772572,
   61403417]; Natural Science Foundation of Guangdong Province of China
   [2017A030313366]; Fundamental Research Funds for the Central
   Universities [17lgjc45]
FX This work is partially supported by National Natural Science Foundation
   of China (No. 61379152, 61772572 and 61403417), Natural Science
   Foundation of Guangdong Province of China (2017A030313366), and
   Fundamental Research Funds for the Central Universities (17lgjc45).
CR Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Haouzia A, 2008, MULTIMED TOOLS APPL, V39, P1, DOI 10.1007/s11042-007-0154-3
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   Jiang XD, 2016, MULTIMED TOOLS APPL, V75, P11801, DOI 10.1007/s11042-015-2659-5
   Kumar R, 2017, MULTIMED TOOLS APPL, V76, P979, DOI 10.1007/s11042-015-3069-4
   Lee SK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1321, DOI 10.1109/icme.2006.262782
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Lin CC, 2015, MULTIMED TOOLS APPL, V74, P3823, DOI 10.1007/s11042-013-1801-5
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Liu YL, 2016, J VIS COMMUN IMAGE R, V39, P51, DOI 10.1016/j.jvcir.2016.05.008
   Ma B, 2016, IEEE T INF FOREN SEC, V11, P1914, DOI 10.1109/TIFS.2016.2566261
   Qian ZX, 2016, MULTIMED TOOLS APPL, V75, P13749, DOI 10.1007/s11042-015-2760-9
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Qian ZX, 2013, ADV INTEL SYS RES, V84, P869
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Yang HJ, 2007, IEEE T MULTIMEDIA, V9, P475, DOI 10.1109/TMM.2006.887990
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Yin ZX, 2014, SCI WORLD J, DOI 10.1155/2014/604876
   Zhang WM, 2016, IEEE T MULTIMEDIA, V18, P1469, DOI 10.1109/TMM.2016.2569497
   Zhang XP, 2014, J VIS COMMUN IMAGE R, V25, P322, DOI 10.1016/j.jvcir.2013.11.001
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zheng SL, 2016, MULTIMED TOOLS APPL, V75, P13765, DOI 10.1007/s11042-015-2920-y
   Zhou JT, 2016, IEEE T CIRC SYST VID, V26, P441, DOI 10.1109/TCSVT.2015.2416591
NR 34
TC 15
Z9 15
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 20917
EP 20935
DI 10.1007/s11042-017-5498-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300027
DA 2024-07-18
ER

PT J
AU Gupta, R
   Mishra, A
   Jain, S
AF Gupta, Ritu
   Mishra, Anurag
   Jain, Sarika
TI A semi-blind HVS based image watermarking scheme using elliptic curve
   cryptography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human visual system; Elliptic curve cryptography; Discrete wavelet
   transform; Singular value decomposition; Image watermarking
ID ALGORITHM
AB In the present paper, an advanced encryption technique commonly known as Elliptic Curve Cryptography (ECC) is used to embed a binary image as a watermark in five grayscale host images in a semi-blind manner. The ECC algorithm is a fast encryption technique which successfully encrypts the subject with significantly less number of bits as compared to other popular encryption algorithms such as Rivest-Shamir-Adleman (RSA) and Direct Selling Association (DSA). In the proposed watermarking scheme, embedding in the grayscale host images is carried out in DWT-SVD domain. First, entropy based Human Visual System (HVS) parameters are computed block wise to identify the most appropriate blocks in spatial domain. First level DWT is computed for these selected blocks and watermark embedding is carried out by using the calculated Singular Value Decomposition (SVD) parameters. Preliminary results of this work show that proposed scheme outperforms the other similar schemes carried out in DCT-SVD domain without using any encryption method. It is concluded that the use of DWT-SVD hybrid architecture along with the fast encryption technique ECC is responsible for better performance in present case. In the second part of this simulation, an established HVS model working in DCT domain is implemented and compared with the entropy based HVS model implemented in transform domain to embed the ECC encrypted binary watermark in images. In this case also, proposed scheme performs better both in terms of visual imperceptibility and robustness as compared to other scheme. It is concluded that HVS parameters - Luminance, Contrast and Edge Sensitivity are better placed in comparison to entropy parameters to examine image features and characteristics for watermarking purpose.
C1 [Gupta, Ritu; Jain, Sarika] Amity Univ, Noida, Uttar Pradesh, India.
   [Mishra, Anurag] Univ Delhi, Deendayal Upadhyay Coll, Delhi, India.
C3 Amity University Noida; University of Delhi
RP Gupta, R (corresponding author), Amity Univ, Noida, Uttar Pradesh, India.
EM ritu4006@gmail.com; anurag_cse2003@yahoo.com; ashusarika@gmail.com
RI Gupta, Ritu/AAP-1061-2021; jain, Sarika/AAR-6016-2021; Mishra,
   Anurag/Y-3426-2019
OI Gupta, Ritu/0000-0002-9416-369X; Jain, Sarika/0000-0002-4752-339X;
   Gupta, Dr. Richa/0000-0003-1519-4824; Mishra, Anurag/0000-0003-3881-7182
CR Agarwal C., 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P102, DOI 10.1109/IIHMSP.2010.33
   Agarwal C, 2015, EGYPT INFORM J, V16, P83, DOI 10.1016/j.eij.2015.01.002
   Agarwal C, 2013, J VIS COMMUN IMAGE R, V24, P1135, DOI 10.1016/j.jvcir.2013.07.007
   Agarwal C, 2011, CAN CON EL COMP EN, P822, DOI 10.1109/CCECE.2011.6030570
   Ashino R, IMAGE COMPRESSION MU, P1
   Bakhtiari S, 2014, 2014 INTERNATIONAL SYMPOSIUM ON BIOMETRICS AND SECURITY TECHNOLOGIES (ISBAST), P144, DOI 10.1109/ISBAST.2014.7013111
   Cao L, SINGULAR VALUE DECOM, P1
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Dey N, 2014, J MED IMAG HEALTH IN, V4, P384, DOI 10.1166/jmihi.2014.1265
   Glowacz A, 2009, ANN TELECOMMUN, V65, P3
   Gonzalez RC, 2005, DIGITAL IMAGE PROCES, P406
   Gupta R, 2015, 2015 1ST INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), P46, DOI 10.1109/NGCT.2015.7375080
   Kankanhali M. S., 1998, Proceedings ACM Multimedia 98, P61, DOI 10.1145/290747.290756
   Lai CC, 2011, OPT COMMUN, V284, P938, DOI 10.1016/j.optcom.2010.10.047
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, P 30 AAAI C ART INT
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liuy Y, 2015, P 24 INT JOINT C ART
   Lou Der-Chyuan, 2008, J CCIT, V37, P151
   Maity SP, 2002, ICCVG, V2002, P1
   Maity SP, 2003, P ICAPR, P351
   Mehta R., 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P123, DOI 10.1109/IIHMSP.2010.38
   Mehta R, 2013, INT CONF CONTEMP, P163, DOI 10.1109/IC3.2013.6612183
   Mishra A., 2012, 2012 INT JOINT C NEU, P1, DOI DOI 10.1109/IJCNN.2012.6252363
   Mohan B. Chandra, 2008, Journal of Multimedia, V3, P7, DOI 10.4304/jmm.3.1.7-15
   Mohanty S. P., 1999, P 7 ACM INT C MUL OC, P49
   Motwani MC, 2009, P 2009 INT C IM PROC
   PAL NR, 1989, IEE PROC-E, V136, P284, DOI 10.1049/ip-e.1989.0039
   Piao CR, 2006, LECT NOTES COMPUT SC, V4221, P493
   Sadek RA, 2012, INT J ADV COMPUT SC, V3, P26
   Singh R, 2014, P IEEE 10 INT C INT
   Tsai HH, 2012, APPL SOFT COMPUT, V12, P2442, DOI 10.1016/j.asoc.2012.02.021
NR 34
TC 17
Z9 17
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19235
EP 19260
DI 10.1007/s11042-017-5351-0
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500016
DA 2024-07-18
ER

PT J
AU Zhang, R
   Pan, ZB
   Ku, WP
AF Zhang, Rui
   Pan, Zhibin
   Ku, Weiping
TI A novel parallel implementation of partial distortion search algorithm
   based on template search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Block matching motion estimation; Partial distortion search; Template
   search algorithm; Early terminating technique; Parallel implementation
ID BLOCK MOTION ESTIMATION; PREDICTION; HEVC
AB This paper proposes a new early terminating partial distortion search algorithm based on template search in fast motion estimation. Our algorithm accomplishes a parallel implementation technique by considering both the idea of partial distortion search and the advantage of the template search. With this technique, the proposed algorithm achieves a better performance by faster updating the current minimum distortion. The proposed parallel implementation that reduces a large amount of distortion computations between pixels outperforms the standard partial distortion search method by faster rejecting the unlikely candidate blocks. Our algorithm is embedded into the diamond search algorithm, star diamond search algorithm and three-step search algorithm respectively. According to the experiment results, it is proved that about 30% reduction of computational complexity has been obtained compared with the standard partial distortion search. Moreover, there is no degradation of the peak signal-to-noise ratio(PSNR) for motion estimation compared with the embedded block-based template search motion estimation algorithm.
C1 [Zhang, Rui; Pan, Zhibin; Ku, Weiping] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, 28 Xianning West Rd, Xian 710049, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University
RP Pan, ZB (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, 28 Xianning West Rd, Xian 710049, Shaanxi, Peoples R China.
EM zbpan@mail.xjtu.edu.cn
RI Pan, Zhibin/I-8212-2012
FU Priority Academic Program Development of Jiangsu Higher Education
   Institutions (PAPD); Key Laboratory of Spectral Imaging Technology,
   Chinese Academy of Sciences [LSIT201606D]; Key Science and Technology
   Program of Shaanxi Province [2016GY-097]; Industrial Program of Zhejiang
   Province [2016C31090]
FX This work is supported in part by the Project Funded by the Priority
   Academic Program Development of Jiangsu Higher Education Institutions
   (PAPD), the Open Research Fund of Key Laboratory of Spectral Imaging
   Technology, Chinese Academy of Sciences (Grant No. LSIT201606D), the Key
   Science and Technology Program of Shaanxi Province (Grant No.
   2016GY-097) and the Industrial Program of Zhejiang Province (Grant No.
   2016C31090).
CR Cheung CH, 2003, IEEE T CIRC SYST VID, V13, P100, DOI 10.1109/TCSVT.2002.808091
   Chok-Kwan C, 2003, IEEE T CIRCUITS SYST, V13, P417
   Jakubowski M, 2013, OPTO-ELECTRON REV, V21, P86, DOI 10.2478/s11772-013-0071-0
   Kaushik M., 2012, INT J APPL INFORM SY, V1, P16
   Kerfa D, 2016, MULTIMED TOOLS APPL, V75, P3161, DOI 10.1007/s11042-014-2428-x
   Kim Y, 2011, IEEE T CONSUM ELECTR, V57, P631, DOI 10.1109/TCE.2011.5955201
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   Luo J, 2015, MULTIMED TOOLS APPL, V74, P11821, DOI 10.1007/s11042-014-2280-z
   Ma KK, 2002, IEEE INT S CIRC SYST, V11, P1442
   Ma TH, 2016, NEUROCOMPUTING, V207, P488, DOI 10.1016/j.neucom.2016.05.020
   Nie Y, 2002, IEEE T IMAGE PROCESS, V11, P1442, DOI 10.1109/TIP.2002.806251
   Pan ZQ, 2016, J VIS COMMUN IMAGE R, V40, P516, DOI 10.1016/j.jvcir.2016.07.018
   Pan ZQ, 2016, IEEE T BROADCAST, V62, P675, DOI 10.1109/TBC.2016.2580920
   Pan ZQ, 2015, IEEE T BROADCAST, V61, P166, DOI 10.1109/TBC.2015.2419824
   Paramkusam AV, 2014, ELECTRON LETT, V50, P276, DOI 10.1049/el.2013.4032
   Po LM, 2009, IEEE T CIRC SYST VID, V19, P1189, DOI 10.1109/TCSVT.2009.2020320
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Tham JY, 1998, IEEE T CIRC SYST VID, V8, P369, DOI 10.1109/76.709403
   Tourapis AM, 2002, PROC SPIE, V4671, P1069, DOI 10.1117/12.453031
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
   Yan C, 2014, IEEE T CIRCUITS SYST, V62, P675
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang CC, 2010, IEEE T CIRC SYST VID, V20, P1150, DOI 10.1109/TCSVT.2010.2056953
   Yi XQ, 2007, IEEE T MULTIMEDIA, V9, P995, DOI 10.1109/TMM.2007.898930
   Zhou ZL, 2017, INT J DISTRIB SENS N, V13, DOI 10.1177/1550147717694172
   Zhu C, 2001, INT CONF ACOUST SPEE, P1593, DOI 10.1109/ICASSP.2001.941239
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
NR 29
TC 0
Z9 0
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 20615
EP 20628
DI 10.1007/s11042-017-5512-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300014
DA 2024-07-18
ER

PT J
AU Zhou, C
   Pan, P
   Huang, L
AF Zhou, Chao
   Pan, Ping
   Huang, Liang
TI Authenticity identification of speaker digital recording data based on
   quantum genetic algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speaker; Digital recording data; Authenticity identification; Quantum
   genetic algorithm; Phase
ID PARALLEL FRAMEWORK; HEVC; ENHANCEMENT
AB The problem we are trying to solve in this paper is the authenticity identification of speaker digital recording data. As an important basis of the judicial identification, it is crucial to ensure the authenticity of digital recording data. A large number of solutions have been proposed to address the problem. However, classic methods are usually based on logical symbol rather than the physical detection of energy or phase, and these solutions show drawbacks in terms of identification inefficiency, algorithm instability and heavy time overhead. In this paper, we propose to utilize the quantum theory to address the problem. Any tampering operation for digital recording data can lead to the change of charge in the memory, and it can utilize the subtle change to implement the identification. First, we analyze the quantum nature of storage and investigate to extract the transmittance of speech signal as the characteristic value through quantum tunneling theory. Second, aiming at the characteristics of speech signal, we utilize the transmittance to define the rotation angle step function and propose an improved quantum genetic algorithm to detect the change of phase. The proposed method achieves the authenticity identification based on phase detection. The results obtained in this research include the problem can be addressed by phase detection solution based on quantum genetic algorithm, and it shows performance benefits compared with existing solutions by simulation experiment. It is not only theoretically but also practically feasible to realize authenticity identification of speak digital recording data.
C1 [Zhou, Chao; Pan, Ping; Huang, Liang] Guizhou Univ, Coll Comp Sci & Technol, Guiyang 550025, Guizhou, Peoples R China.
C3 Guizhou University
RP Pan, P (corresponding author), Guizhou Univ, Coll Comp Sci & Technol, Guiyang 550025, Guizhou, Peoples R China.
EM zhouchao_gzu@163.com; panping_17@163.com; 441647415@qq.com
RI Shi, Yaolin/JXN-8322-2024; PAN, PAN/IWV-1122-2023
FU Natural Science Foundation of Guizhou Province of China [[2012]2132];
   Natural Science Foundation of Education Department of Guizhou Province
   of China [(2015)367]
FX This work reported in this paper is supported by the Natural Science
   Foundation of Guizhou Province of China under Grant [2012]2132 and
   Natural Science Foundation of Education Department of Guizhou Province
   of China under Grant (2015)367.
CR [Anonymous], 2007, Chinese Journal of Computers, V30, P748
   [Anonymous], 2002, P IEEE INT C EV COMP
   [Anonymous], 2003, Quantum Computation and Quantum Information
   Bao Y, 2011, TECH ACOUST, V30, P209
   Brixen E.B., 2007, P 123 AUD ENG SOC CO
   Cooper AJ, 2010, FORENSIC LINGUIST, V16, P193
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Deng F, 2016, SPEECH COMMUN, V79, P30, DOI 10.1016/j.specom.2016.02.006
   Farid H, 1999, AIM1657 MIT AI
   Feng An-hui, 2011, Computer Engineering, V37, P199, DOI 10.3969/j.issn.1000-3428.2011.05.067
   Griffiths DJ, 2011, INTRO QUANTUM MECH
   Grigoras C, 2005, INT J SPEECH LANG LA, V12, P63, DOI 10.1558/sll.2005.12.1.63
   Guo H, 2010, TELECOMMUNICATIONS S, V11, P56
   Han KH, 2000, IEEE C EVOL COMPUTAT, P1354, DOI 10.1109/CEC.2000.870809
   He Z, 2011, SCI TECHNOLOGY ENG, V11, P4215
   Kajstura M, 2005, FORENSIC SCI INT, V155, P165, DOI 10.1016/j.forsciint.2004.11.015
   Koenig BE, 2009, J AUDIO ENG SOC, V57, P662
   Lai Lianyou, 2015, Information and Control, V44, P598, DOI 10.13976/j.cnki.xk.2015.0598
   Liu F, 2014, IND CONTROL COMPUTER, V27, P89
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   [刘育明 Liu Yuming], 2013, [仪器仪表学报, Chinese Journal of Scientific Instrument], V34, P1434
   Liu Yu, 1999, Acta Electronica Sinica, V27, P126
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Ma XY, 1996, IEEE T SIGNAL PROCES, V44, P2669, DOI 10.1109/78.542175
   Maher RC, 2009, IEEE SIGNAL PROC MAG, V26, P84, DOI 10.1109/MSP.2008.931080
   Rodríguez DPN, 2010, IEEE T INF FOREN SEC, V5, P534, DOI 10.1109/TIFS.2010.2051270
   Oliva N, 2017, INT EL DEVICES MEET
   Pan P, 2012, COMPUT ENG, V39, P277
   Pan Ping, 2012, Computer Engineering and Applications, V48, P123, DOI 10.3778/j.issn.1002-8331.1105-0197
   Preotiuc-Pietro D, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P729, DOI 10.18653/v1/P17-1068
   [钱国红 Qian Guohong], 2012, [计算机科学, Computer Science], V39, P242
   Song X, 2014, INTELLIGENT COMPUTER, V4, P11
   Tian G, 2016, COMPUTER KNOWLEDGE T, V12, P197
   Wang L, 2009, ELECT MEASUREMENT TE, V32, P74
   Wang Y, 2015, SCI TECHNOLOGY ENG, V15, P267
   Xie Qing-song, 2009, Computer Engineering, V35, P246
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang R, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P21, DOI 10.1145/1411328.1411334
   Yao Qiu-ming, 2006, Journal of Computer Applications, V26, P2598
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Yu Jian-chao, 2009, Computer Engineering and Design, V30, P1189
   Zhang Xiao-feng, 2013, Computer Engineering, V39, P234, DOI 10.3969/j.issn.1000-3428.2013.04.054
   Zhang Zong-fei, 2010, Computer Engineering, V36, P181
   [周正威 ZhOU Zhengwei], 2005, [物理学进展, Progress in Physics], V25, P368
   Zhu Z, 2009, SEMICONDUCTOR INTEGR
NR 53
TC 3
Z9 3
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19399
EP 19413
DI 10.1007/s11042-017-5369-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500023
DA 2024-07-18
ER

PT J
AU Vo, DM
   Lee, SW
AF Duc My Vo
   Lee, Sang-Woong
TI Semantic image segmentation using fully convolutional neural networks
   with multi-scale images and multi-scale dilated convolutions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic image segmentation; Fully convolutional neural networks; Fully
   connected conditional random fields; Multi-scale dilated convolutions
AB In this work, we investigate the effects of the cascade architecture of dilated convolutions and the deep network architecture of multi-resolution input images on the accuracy of semantic segmentation. We show that a cascade of dilated convolutions is not only able to efficiently capture larger context without increasing computational costs, but can also improve the localization performance. In addition, the deep network architecture for multi-resolution input images increases the accuracy of semantic segmentation by aggregating multi-scale contextual information. Furthermore, our fully convolutional neural network is coupled with a model of fully connected conditional random fields to further remove isolated false positives and improve the prediction along object boundaries. We present several experiments on two challenging image segmentation datasets, showing substantial improvements over strong baselines.
C1 [Duc My Vo; Lee, Sang-Woong] Gachon Univ, Pattern Recognit & Machine Learning Lab, 1342 Seongnamdaero, Seongnam 13120, South Korea.
C3 Gachon University
RP Lee, SW (corresponding author), Gachon Univ, Pattern Recognit & Machine Learning Lab, 1342 Seongnamdaero, Seongnam 13120, South Korea.
EM slee@gachon.ac.kr
RI Lee, Sang-Woong/ABF-6191-2020
OI Lee, Sang-Woong/0000-0001-8117-6566
FU GRRC program of Gyeonggi province [GRRC-Gachon2017(B01)]
FX This work was supported by the GRRC program of Gyeonggi province
   [GRRC-Gachon2017(B01), Analysis of behavior based on senior life log].
CR [Anonymous], 2014, CORRABS14120296
   [Anonymous], 2015, ARXIV150401013
   [Anonymous], 2015, CVPR
   [Anonymous], SCENE SEGMENTATION C
   [Anonymous], 2015, ARXIV151100561
   [Anonymous], 2014, IJCV
   [Anonymous], 1998, P IEEE
   [Anonymous], 2016, ENET DEEP NEURAL NET
   [Anonymous], 2015, ICLR
   [Anonymous], ARXIV14124313
   [Anonymous], P 20 INT C NEUR INF
   [Anonymous], 2015, ARXIV150504366
   [Anonymous], 2015, ICCV
   [Anonymous], 2015, ICCV
   [Anonymous], 2013, P INT C MACHINE LEAR
   [Anonymous], 2009, P 26 INT C MACH LEAR
   [Anonymous], 2013, ARXIV PREPRINT ARXIV
   [Anonymous], 2011, INT C COMP VIS ICCV
   [Anonymous], 2015, CVPR
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Girshick R., 2013, IEEE Comput. Soc., P580
   Gutman D., 2016, SKIN LES AN MEL DET
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He XM, 2004, PROC CVPR IEEE, P695
   Hoft Nico, 2014, KI 2014: Advances in Artificial Intelligence. 37th Annual German Conference on AI. Proceedings: LNCS 8736, P80, DOI 10.1007/978-3-319-11206-0_9
   Krizhevsky A., 2013, NIPS
   Lin T.Y., Proceedings of the European Conference on Computer Vision, P740
   Long J., 2015, P IEEE C COMP VIS PA, P3431
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shotton J, 2008, PROC CVPR IEEE, P1245
   Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1
   Simonyan K., 2014, 14091556 ARXIV
   Socher R., 2011, PROC INT C MACH LEAR, P129
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
NR 36
TC 29
Z9 34
U1 2
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18689
EP 18707
DI 10.1007/s11042-018-5653-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900056
DA 2024-07-18
ER

PT J
AU Han, XF
   Jin, JS
   Wang, MJ
   Jiang, W
AF Han, Xian-Feng
   Jin, Jesse S.
   Wang, Ming-Jie
   Jiang, Wei
TI Iterative guidance normal filter for point cloud
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D point cloud; Iterative guidance normal filter; Noise reduction;
   Feature-preserving
AB 3D point clouds have become increasingly popular in recent year due to the rapid development of low-cost 3D sensors. One of the most interesting challenges is to filter point cloud, which undoubtedly becomes a crucial part of the point cloud processing pipeline. Based on normal information, this paper proposes a simple but effective point cloud filter framework. In this framework, a kd-tree structure is constructed for representing point cloud to search neighborhood and estimate normal for each point at first. Then, iteratively performing the processing that a bilateral filter is applied to the normal field obtained from the previous iteration, using the same normal field as the guidance; afterward, adjusting point positions is performed depending on the filtered normals. Experimental results indicate the effectiveness of our algorithms.
C1 [Han, Xian-Feng; Wang, Ming-Jie; Jiang, Wei] Tianjin Univ, High Dimens Informat Proc Lab, Tianjin, Peoples R China.
   [Jin, Jesse S.] Tianjin Univ, China Talent Program, Tianjin, Peoples R China.
C3 Tianjin University; Tianjin University
RP Jin, JS (corresponding author), Tianjin Univ, China Talent Program, Tianjin, Peoples R China.
EM hanxianf@163.com; jinsheng@tju.edu.cn; 18768126670@163.com;
   jiangweitju@163.com
RI wang, ming/HPC-6329-2023; Zhang, Jianjun/KEJ-3941-2024
OI Han, Xianfeng/0000-0002-4869-4537
CR Alexa M, 2003, IEEE T VIS COMPUT GR, V9, P3, DOI 10.1109/TVCG.2003.1175093
   [Anonymous], 2009, ACM T GR
   [Anonymous], 2016, 2016 INT C CONTR COM
   [Anonymous], EUR C COMP VIS
   [Anonymous], COMPUT GRAPH FORUM
   [Anonymous], 2004, P 9 ACM S SOLID MODE
   [Anonymous], 2014, ARXIV14054734
   Berger M, 2017, COMPUT GRAPH FORUM, V36, P301, DOI 10.1111/cgf.12802
   Boulch A, 2016, COMPUT GRAPH FORUM, V35, P281, DOI 10.1111/cgf.12983
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Fehr D, 2016, COMPUT VIS IMAGE UND, V142, P80, DOI 10.1016/j.cviu.2015.06.008
   Fleishman S, 2003, ACM T GRAPHIC, V22, P950, DOI 10.1145/882262.882368
   Han XF, 2017, SIGNAL PROCESS-IMAGE, V57, P103, DOI 10.1016/j.image.2017.05.009
   Hernandez M, 2015, IMAGE VISION COMPUT, V36, P61, DOI 10.1016/j.imavis.2014.12.004
   Hu GF, 2006, VISUAL COMPUT, V22, P147, DOI 10.1007/s00371-006-0372-0
   Huang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461913
   Huhle B, 2008, IEEE COMPUTER SOC C, P1
   Jolliffe I., 1986, Journel, DOI DOI 10.1007/B98835
   Jones TR, 2004, IEEE COMPUT GRAPH, V24, P53, DOI 10.1109/MCG.2004.14
   Jones TR, 2003, ACM T GRAPHIC, V22, P943, DOI 10.1145/882262.882367
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lu XQ, 2016, IEEE T VIS COMPUT GR, V22, P1181, DOI 10.1109/TVCG.2015.2500222
   Moorfield B, 2015, LECT NOTES COMPUT SC, V9257, P394, DOI 10.1007/978-3-319-23117-4_34
   Pauly M, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P163, DOI 10.1109/VISUAL.2002.1183771
   Rosman G, 2013, COMPUT GRAPH FORUM, V32, P1, DOI 10.1111/cgf.12139
   Shi BQ, 2011, COMPUT AIDED DESIGN, V43, P910, DOI 10.1016/j.cad.2011.04.001
   Sun XF, 2007, IEEE T VIS COMPUT GR, V13, P925, DOI 10.1109/TVCG.2007.1065
   Sun YJ, 2015, COMPUT AIDED GEOM D, V35-36, P2, DOI 10.1016/j.cagd.2015.03.011
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wand M, 2008, COMPUT GRAPH-UK, V32, P204, DOI 10.1016/j.cag.2008.01.010
   Wang PS, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818068
   Wasza J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1221, DOI 10.1109/ICCVW.2011.6130390
   Wei MQ, 2015, IEEE T VIS COMPUT GR, V21, P43, DOI 10.1109/TVCG.2014.2326872
   Xiao CX, 2006, VISUAL COMPUT, V22, P210, DOI 10.1007/s00371-006-0377-8
   Zhang Q, 2014, LECT NOTES COMPUT SC, V8691, P815, DOI 10.1007/978-3-319-10578-9_53
   Zhang WY, 2015, COMPUT GRAPH FORUM, V34, P23, DOI 10.1111/cgf.12742
   Zheng YY, 2011, IEEE T VIS COMPUT GR, V17, P1521, DOI 10.1109/TVCG.2010.264
NR 40
TC 8
Z9 8
U1 3
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16887
EP 16902
DI 10.1007/s11042-017-5258-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300040
DA 2024-07-18
ER

PT J
AU Hu, XX
   Hu, DH
   Zheng, SL
   Li, WW
   Chen, F
   Shu, ZP
   Wang, LN
AF Hu, Xiaoxia
   Hu, Donghui
   Zheng, Shuli
   Li, Wangwang
   Chen, Fan
   Shu, Zhaopin
   Wang, Lina
TI How people share digital images in social networks: a
   questionnaire-based study of privacy decisions and access control
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Questionnaire; Privacy decisions; Image sharing; Access control; Partial
   order; Human-computer interaction
ID MODEL
AB The blind sharing of digital images in social networks may lead to threats to privacy. Currently, privacy decision recommendations and access control mechanisms are inadequate with respect to sharing digital images in social networking systems. In this study, a questionnaire was designed to investigate the purposes, attitudes, preferences, modes and recommendations for sharing images (or making privacy decisions) based on studies of human-computer interaction. The survey results showed that first, there is a partial order based on either privacy levels or attribute tags for image sharing in social networks. Second, it is currently essential for social networks to have fine-grained access control settings. Third, online privacy calculus (utility maximization) is still valid for social network image sharing and the design of access control mechanisms. The findings of this survey may provide supporting evidence based on human-computer interaction for the design of models of privacy decisions and access control mechanisms for sharing images in social networks.
C1 [Hu, Xiaoxia; Hu, Donghui; Zheng, Shuli; Li, Wangwang; Chen, Fan; Shu, Zhaopin] Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230009, Anhui, Peoples R China.
   [Wang, Lina] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Hubei, Peoples R China.
C3 Hefei University of Technology; Wuhan University
RP Hu, DH (corresponding author), Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230009, Anhui, Peoples R China.
EM hudh@hfut.edu.cn
RI Wang, Li-Na/T-7047-2018
CR Ahern S, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P357
   [Anonymous], SECURE COMPUTER SYST
   [Anonymous], 2009, 2009 5 INT C COLLABO
   [Anonymous], WWW 2015
   [Anonymous], 2016 IEEE 1 INT C DA
   [Anonymous], AAAI SPRING S SOC SE
   [Anonymous], C HUM FACT COMP
   [Anonymous], 2011, P HT 2011
   [Anonymous], SIGIR 12
   Besmer Andrew, 2009, CHI 09 EXTENDED ABST, P4585
   Carminati B, 2009, SACMAT'09: PROCEEDINGS OF THE 14TH ACM SYMPOSIUM ON ACCESS CONTROL MODELS AND TECHNOLOGIES, P177, DOI 10.1145/1542207.1542237
   DENNING DE, 1976, COMMUN ACM, V19, P236, DOI 10.1145/360051.360056
   Dinev T, 2008, J STRATEGIC INF SYST, V17, P214, DOI 10.1016/j.jsis.2007.09.002
   Fathimal PM, 2017, MULTIMED TOOLS APPL, V76, P5489, DOI 10.1007/s11042-016-4074-y
   Fong PWL, 2009, LECT NOTES COMPUT SC, V5789, P303, DOI 10.1007/978-3-642-04444-1_19
   Hart Michael, 2009, 2009 International Conference on Computational Science and Engineering (CSE), P401, DOI 10.1109/CSE.2009.425
   Joinson AN, 2010, HUM-COMPUT INTERACT, V25, P1, DOI 10.1080/07370020903586662
   Jones S, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1777
   Li Y, 2015, COMPUT SECUR, V49, P239, DOI 10.1016/j.cose.2014.10.012
   Minkus T, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P776, DOI 10.1145/2736277.2741124
   Neustaedter C., 2006, ACM Transactions on Computer-Human Interaction, V13, P1, DOI 10.1145/1143518.1143519
   Sandhu R., 1996, IEEE Computer, V29, P38
   Wang L., 2004, P 2004 ACM WORKSHOP, P45, DOI DOI 10.1145/1029133.1029140
   Xu H, 2009, J MANAGE INFORM SYST, V26, P135, DOI 10.2753/MIS0742-1222260305
   Zhang Xinwen., 2005, Proceedings of the 2005 ACM Symposium on Applied Computing, P359
NR 25
TC 9
Z9 9
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18163
EP 18185
DI 10.1007/s11042-017-4402-x
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900032
DA 2024-07-18
ER

PT J
AU Huang, W
   Zeng, J
   Wan, CY
   Ding, HJ
   Chen, G
AF Huang, Wei
   Zeng, Jing
   Wan, Chuyu
   Ding, Huijun
   Chen, Guang
TI Image-based dementia disease diagnosis via deep low-resource pair-wise
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Disease diagnosis; Deep learning; Low-resource computing; Logistic
   regression
ID ALZHEIMERS-DISEASE; SELECTION; CLASSIFICATION; SUBSPACE; MRI
AB Medical Images data is widely acknowledged for its large volumes, high complexities and limited labels information, which makes learning-based tasks challenging to obtain promising performance based on such images data. Also, Alzheimer's disease, one of the five most severe non-communicable diseases all around the world, receives much attention in both academic research and clinical diagnosis for the time being. It is generally acknowledged that magnetic resonance imaging, a popular imaging tool because of its free of radiation exposure in terms of patients safety issues, has been vastly employed in Alzheimer's disease diagnosis in recent years. However, most contemporary clinical diagnosis efforts still heavily rely on clinicians' expertise to realize the disease diagnosis task. In this study, inspired by the recent rapid development of deep learning and low-resource learning techniques, a novel image-based disease diagnosis scheme is proposed to automatically fulfil the diagnosis of Alzheimer's disease based on arterial spin labeling magnetic resonance images. This new end-to-end low-resource learning scheme is conducted following four steps. First, raw arterial spin labeling images need to be acquired and essential pre-processing steps should be carried out on raw images. Second, the popular convolutional neural network technique is adopted to automatically extract latent trainable features from processed arterial spin labelling images, instead of traditional hand-crafted features. Third, a novel low-resource pair-wise learning method inspired by the semi-supervised learning theory is carried out based on latent trainable features for automatically determining disease similarity functions. Forth, learned outcomes are then fed into a multi-nominal logistic regression model and a regression process with the highest posterior probability is capable to reveal the corresponding disease diagnosis outcome. Extensive experiments based on a database composed of magnetic resonance images acquired from 350 real demented patients are carried out with the newly poroposed scheme being compared towards several other well-known diagnosis tools. All diagnosis results have undergone rigorous and comprehensive statistical analysis composed of analysis of variance and multiple comparison tests. The superiority of the new scheme has been demonstrated therein.
C1 [Huang, Wei; Zeng, Jing; Wan, Chuyu] Nanchang Univ, Sch Informat Engn, Nanchang, Jiangxi, Peoples R China.
   [Ding, Huijun] Shenzhen Univ, Sch Biomed Engn, Shenzhen, Peoples R China.
   [Chen, Guang] Xian Commun Inst, Xian, Shaanxi, Peoples R China.
C3 Nanchang University; Shenzhen University
RP Ding, HJ (corresponding author), Shenzhen Univ, Sch Biomed Engn, Shenzhen, Peoples R China.
EM hjding@szu.edu.cn
RI zeng, jing/JDW-4350-2023
FU National Natural Science Foundation of China [61363046, 61403182]; Young
   Talented Scientist Grant by the Jiangxi Provincial Department of Science
   and Technology [20153BCB23029]; Jiangxi Provincial Department of
   Education [JXJG-15-1-26]
FX This work is supported by Grants 61363046 and 61403182 approved by the
   National Natural Science Foundation of China, the Young Talented
   Scientist Grant 20153BCB23029 approved by the Jiangxi Provincial
   Department of Science and Technology, and the Grant JXJG-15-1-26
   approved by the Jiangxi Provincial Department of Education.
CR [Anonymous], 2004, CONVEX PPTIMIZATION
   Asllani I, 2008, MAGN RESON MED, V60, P1362, DOI 10.1002/mrm.21670
   Boureau YL, 2010, PROC CVPR IEEE, P2559, DOI 10.1109/CVPR.2010.5539963
   Chen Y, 2011, NEUROLOGY, V77, P1977, DOI 10.1212/WNL.0b013e31823a0ef7
   Davatzikos C, 2008, NEUROBIOL AGING, V29, P514, DOI 10.1016/j.neurobiolaging.2006.11.010
   Feng LN, 2016, IEEE T PATTERN ANAL, V38, P785, DOI 10.1109/TPAMI.2015.2469281
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   Hahn WE, 2015, MULTIMED TOOLS APPL, V74, P10097, DOI 10.1007/s11042-015-2808-x
   Howard AL., 1977, Bull. Amer. Math. Soc. (N.S.), V1, P521
   Huang W, 2016, MULTIMED TOOLS APPL, V75, P2067, DOI 10.1007/s11042-014-2395-2
   Joachims T., SVM LIGHT IMPLEMENTA
   Liu MH, 2012, NEUROIMAGE, V60, P1106, DOI 10.1016/j.neuroimage.2012.01.055
   Liu TL, 2017, IEEE T PATTERN ANAL, V39, P227, DOI 10.1109/TPAMI.2016.2544314
   Mahendra B, 1987, DEMENTIA, V1, P189
   Mioshi E, 2006, INT J GERIATR PSYCH, V21, P1078, DOI 10.1002/gps.1610
   Musiek ES, 2012, ALZHEIMERS DEMENT, V8, P51, DOI 10.1016/j.jalz.2011.06.003
   Rice JA., 2007, MATH STAT DATA ANAL
   Suk HI, 2015, BRAIN STRUCT FUNCT, V220, P841, DOI 10.1007/s00429-013-0687-3
   Suk HI, 2014, NEUROIMAGE, V101, P569, DOI 10.1016/j.neuroimage.2014.06.077
   Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096
   Tao DC, 2009, IEEE T PATTERN ANAL, V31, P260, DOI 10.1109/TPAMI.2008.70
   Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   un, World population prospects
   Wee CY, 2013, HUM BRAIN MAPP, V34, P3411, DOI 10.1002/hbm.22156
   who, TOP 10 CAUS DEATH, DOI DOI 11/44679/INDEX.HTM
   Xu C, 2015, IEEE T PATTERN ANAL, V37, P2531, DOI 10.1109/TPAMI.2015.2417578
   Xu C, 2014, IEEE T PATTERN ANAL, V36, P1559, DOI 10.1109/TPAMI.2013.2296528
   Zhang ST, 2015, IEEE T PATTERN ANAL, V37, P803, DOI 10.1109/TPAMI.2014.2346201
   Zhang SL, 2015, IEEE T PATTERN ANAL, V37, P2573, DOI 10.1109/TPAMI.2015.2417573
   Zhang YQ, 2015, NEUROCOMPUTING, V168, P454, DOI 10.1016/j.neucom.2015.05.082
   Zhou LP, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021935
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
NR 33
TC 2
Z9 2
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18763
EP 18780
DI 10.1007/s11042-017-4492-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900060
DA 2024-07-18
ER

PT J
AU Wu, H
   Xu, D
   Yuan, GW
AF Wu, Hao
   Xu, Dan
   Yuan, Guowu
TI Region covariance based total variation optimization for
   structure-texture decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Structure-texture decomposition; Region covariance; Total variation
   optimization; Patch shift
ID IMAGE DECOMPOSITION; VIDEO ABSTRACTION; BILATERAL FILTER; NOISE REMOVAL;
   ALGORITHMS; SELECTION
AB With conventional structure-preserving filters, it is not always easy to remove texture details and preserve important structures from images of high complexity. To enhance the performance of structure-texture decomposition, a new method based on region covariance of simple image features and total variation optimization is proposed in this paper. We first identify texture from structure by patch-based covariance, which shows highly discriminative power for textures. Then, a total variation model built on the joint covariance and gradient is used for structure-preserving smoothing. To overcome the inherent limitation of covariance descriptor in locating main structures, patch shifting based on the variation of the region covariance is introduced. We compare our approach with state-of-the-art structure-preserving decomposition methods and the results show that our approach outperforms them in removing unimportant texture details while preserving main structures. Even for images containing the mixture of high-contrast textures with obscure boarders between them, our approach still can improve the decomposition at few extra cost of computation. Besides better decomposition results and robustness for various types of images, the simplicity of our approach make it easy to implement and adaptable to other applications.
C1 [Wu, Hao; Xu, Dan; Yuan, Guowu] Yunnan Univ, Dept Comp Sci & Engn, Kunming, Yunnan, Peoples R China.
C3 Yunnan University
RP Wu, H (corresponding author), Yunnan Univ, Dept Comp Sci & Engn, Kunming, Yunnan, Peoples R China.
EM wuhao19820311@163.com
RI Xu, Dan/KPA-7396-2024; Yuan, Guowu/HJI-7569-2023
OI Xu, Dan/0000-0003-4602-3550; Yuan, Guowu/0000-0002-8449-6861
FU National Natural Science Foundation of China [61540062]; Science
   Foundation of Yunnan Provincial Department of Education [2015Y018]
FX This research was partially supported by the National Natural Science
   Foundation of China (Grant No. 61540062) and the Science Foundation of
   Yunnan Provincial Department of Education (Grant No. 2015Y018).
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.489
   Aujol JF, 2006, INT J COMPUT VISION, V67, P111, DOI 10.1007/s11263-006-4331-z
   Aujol JF, 2005, INT J COMPUT VISION, V63, P85, DOI 10.1007/s11263-005-4948-3
   Bae SM, 2006, ACM T GRAPHIC, V25, P637, DOI 10.1145/1141911.1141935
   Bao LC, 2014, IEEE T IMAGE PROCESS, V23, P555, DOI 10.1109/TIP.2013.2291328
   Bi S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766946
   Bolz J, 2003, ACM T GRAPHIC, V22, P917, DOI 10.1145/882262.882364
   Chaudhury KN, 2015, IEEE IMAGE PROC, P2005, DOI 10.1109/ICIP.2015.7351152
   Cho H, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601188
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Fadili MJ, 2010, P IEEE, V98, P983, DOI 10.1109/JPROC.2009.2024776
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   FATTAL R, 2009, ACM T GRAPHIC, V28
   Gastal ESL, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964964
   Gilles J, 2010, IEEE T IMAGE PROCESS, V19, P2793, DOI 10.1109/TIP.2010.2049946
   Gunturk BK, 2011, IEEE T IMAGE PROCESS, V20, P2690, DOI 10.1109/TIP.2011.2126585
   Guo D, 2010, PROC CVPR IEEE, P515, DOI 10.1109/CVPR.2010.5540170
   Ham B, 2015, PROC CVPR IEEE, P4823, DOI 10.1109/CVPR.2015.7299115
   Hays J., 2006, DISCOVERING TEXTURE
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hong XP, 2009, PROC CVPR IEEE, P1802, DOI 10.1109/CVPRW.2009.5206742
   Jeon J, 2016, COMPUT GRAPH FORUM, V35, P77, DOI 10.1111/cgf.13005
   Jia JY, 2006, ACM T GRAPHIC, V25, P631, DOI 10.1145/1141911.1141934
   Karacan L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508403
   Kass M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778837
   Kopf Johannes., 2007, ACM T GRAPHIC, V26
   Krishnan D, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461992
   Kyprianidis JE, 2011, COMPUT GRAPH FORUM, V30, P593, DOI 10.1111/j.1467-8659.2011.01882.x
   Lischinski D, 2006, ACM T GRAPHIC, V25, P646, DOI 10.1145/1141911.1141936
   Liu QG, 2013, IEEE I CONF COMP VIS, P1081, DOI 10.1109/ICCV.2013.138
   Liu YX, 2004, ACM T GRAPHIC, V23, P368, DOI 10.1145/1015706.1015731
   Ojala T, 2000, GRAY SCALE ROTATION
   Ono S, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2299067
   Osher S, 2003, IEEE IMAGE PROC, P689
   Paris S, 2011, ACM T GRAPHIC, V30
   Paris S, 2009, INT J COMPUT VISION, V81, P24, DOI 10.1007/s11263-007-0110-8
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Schaeffer H, 2013, SIAM J IMAGING SCI, V6, P226, DOI 10.1137/110854989
   Su Z, 2013, IEEE T MULTIMEDIA, V15, P535, DOI 10.1109/TMM.2012.2237025
   SUBR K, 2009, ACM T GRAPHIC, V28
   Szeliski R, 2006, ACM T GRAPHIC, V25, P1135, DOI 10.1145/1141911.1142005
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Tschumperlé D, 2006, INT J COMPUT VISION, V68, P65, DOI 10.1007/s11263-006-5631-z
   Winnemöller H, 2006, ACM T GRAPHIC, V25, P1221, DOI 10.1145/1141911.1142018
   Xu L, 2015, PR MACH LEARN RES, V37, P1669
   Xu L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366158
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Yang QX, 2009, PROC CVPR IEEE, P557, DOI 10.1109/CVPRW.2009.5206542
   Yin WT, 2005, LECT NOTES COMPUT SC, V3752, P73
   Zhang B, 2008, IEEE T IMAGE PROCESS, V17, P664, DOI 10.1109/TIP.2008.919949
   ZHANG Q, 2014, COMP VIS PATT REC CV, P2830
   Zhang Q, 2014, LECT NOTES COMPUT SC, V8691, P815, DOI 10.1007/978-3-319-10578-9_53
   Zhano M, 2008, IEEE T IMAGE PROCESS, V17, P2324, DOI 10.1109/TIP.2008.2006658
NR 53
TC 1
Z9 1
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16985
EP 17005
DI 10.1007/s11042-017-5266-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300045
DA 2024-07-18
ER

PT J
AU Xia, ZH
   Lv, R
   Sun, XM
AF Xia, Zhihua
   Lv, Rui
   Sun, Xingming
TI Rotation-invariant Weber pattern and Gabor feature for fingerprint
   liveness detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Fingerprint liveness detection; Weber's law; Local binary
   pattern; Gabor filter
ID SCHEME; RETRIEVAL; EFFICIENT; SCALE
AB Fingerprint recognition systems are extensively deployed for the authentication in many applications. However, this kind of recognition systems may be spoofed by artificial fingerprints made from various materials. Thus, it is necessary to add a fingerprint liveness detection module to keep this kind of recognition systems on a good level of security. The fingerprint liveness detection (FLD) aims to judge whether a given fingerprint image is captured from a real finger or a spoof one. It is a typical two-class classification problem where the feature extraction is the key step. In this paper, we propose an effective feature extraction method for the FLD problem. The proposed features consist of two components, Weber local binary pattern (WLBP) and circularly symmetric Gabor feature (CSGF), analyzing the fingerprint images in both the spatial and frequency domains. The co-occurrence probabilities of the two components are calculated as the final features. The proposed features are utilized to train SVM classifiers separately on two databases in Fingerprint Liveness Detection Competition 2011 and 2013. Experimental results demonstrate the effectiveness of the proposed method.
C1 [Xia, Zhihua; Lv, Rui; Sun, Xingming] Nanjing Univ Informat Sci & Technol, Coll Comp & Software, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Jiangsu, Peoples R China.
C3 Nanjing University of Information Science & Technology
RP Xia, ZH (corresponding author), Nanjing Univ Informat Sci & Technol, Coll Comp & Software, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Jiangsu, Peoples R China.
EM xia_zhihua@163.com; lrain_nuist@163.com
RI Xia, Zhihua/C-8581-2011; Sun, Xingming/AAD-1866-2019; lv,
   ruichan/B-9648-2017
OI Xia, Zhihua/0000-0001-6860-647X
FU NSFC [61672294, 61601236, U1536206, 61502242, 61572258, U1405254,
   61373133, 61373132, 61232016, BK20150925]; Six peak talent project of
   Jiangsu Province [R2016L13]; CICAEET; PAPD fund; BK21+ program from the
   Ministry of Education of Korea;  [NRF-2016R1D1A1B03933294]
FX This work is supported by the NSFC (61672294, 61601236, U1536206,
   61502242, 61572258, U1405254, 61373133, 61373132, 61232016), BK20150925,
   Six peak talent project of Jiangsu Province (R2016L13),
   NRF-2016R1D1A1B03933294, CICAEET, and PAPD fund. Zhihua Xia is supported
   by BK21+ program from the Ministry of Education of Korea. The authors
   would like to thank Mr. Zhaowei Liu for his contribution in this work.
CR [Anonymous], 2013 INT WORK BIOMET
   [Anonymous], OPT ENG
   [Anonymous], 2010, Computer Vision Winter Workshop
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Antonelli A., 2005, Advances in Biometrics. International Conference, ICB 2006. Proceedings (Lecture Notes in Computer Science Vol.3832), P221
   Antonelli A, 2006, IEEE T INF FOREN SEC, V1, P360, DOI 10.1109/TIFS.2006.879289
   Bhardwaj I, 2017, PATTERN RECOGN, V62, P214, DOI 10.1016/j.patcog.2016.09.003
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Coli P, 2007, 2007 IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P169, DOI 10.1109/AUTOID.2007.380614
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Dubey RK, 2016, IEEE T INF FOREN SEC, V11, P1461, DOI 10.1109/TIFS.2016.2535899
   Galbally J, 2012, FUTURE GENER COMP SY, V28, P311, DOI 10.1016/j.future.2010.11.024
   Ghiani L, 2017, IMAGE VISION COMPUT, V58, P110, DOI 10.1016/j.imavis.2016.07.002
   Ghiani L, 2013, INT CONF BIOMETR, DOI 10.1109/ICB.2013.6613027
   Ghiani L, 2012, INT C PATT RECOG, P537
   Ghiani L, 2012, LECT NOTES COMPUT SC, V7378, P210, DOI 10.1007/978-3-642-31567-1_21
   Gottschlich C, 2014, P IEEE INT JOINT C B, P1
   Gragnaniello Diego, 2013, Proceedings of the 2013 IEEE Workshop on Biometric Measurements and Systems for Security and Medical Applications (BIOMS), P46, DOI 10.1109/BIOMS.2013.6656148
   Gragnaniello D, 2015, IEEE T INF FOREN SEC, V10, P849, DOI 10.1109/TIFS.2015.2404294
   Gragnaniello D, 2015, PATTERN RECOGN, V48, P1050, DOI 10.1016/j.patcog.2014.05.021
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565
   Jia XF, 2014, INFORM SCIENCES, V268, P91, DOI 10.1016/j.ins.2013.06.041
   Kim W, 2017, IEEE SIGNAL PROC LET, V24, P51, DOI 10.1109/LSP.2016.2636158
   Li CR, 2015, IEEE T IMAGE PROCESS, V24, P2344, DOI 10.1109/TIP.2015.2422575
   Marasco E, 2012, PATTERN RECOGN LETT, V33, P1148, DOI 10.1016/j.patrec.2012.01.009
   Marcialis Gian Luca, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1289, DOI 10.1109/ICPR.2010.321
   Moon YS, 2005, ELECTRON LETT, V41, P1112, DOI 10.1049/el:20052577
   Nikam SB, 2008, LECT NOTES COMPUT SC, V5259, P1103, DOI 10.1007/978-3-540-88458-3_100
   Nogueira RF, 2016, IEEE T INF FOREN SEC, V11, P1206, DOI 10.1109/TIFS.2016.2520880
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Park Yosep, 2017, Advanced Multimedia and Ubiquitous Engineering, MUE/FutureTech 2017. LNEE 448, P43, DOI 10.1007/978-981-10-5041-1_8
   Qin C, 2016, INFORM SCIENCES, V361, P84, DOI 10.1016/j.ins.2016.04.036
   Sousedik C, 2014, IET BIOMETRICS, V3, P219, DOI 10.1049/iet-bmt.2013.0020
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Xia ZH, 2017, INFORM SCIENCES, V387, P195, DOI 10.1016/j.ins.2016.12.030
   Xia ZH, 2017, SIGNAL IMAGE VIDEO P, V11, P381, DOI 10.1007/s11760-016-0936-z
   Xia ZH, 2016, CHINA COMMUN, V13, P92, DOI 10.1109/CC.2016.7559080
   Xia ZH, 2018, IEEE T CLOUD COMPUT, V6, P276, DOI 10.1109/TCC.2015.2491933
   Yambay D., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P208, DOI 10.1109/ICB.2012.6199810
   Yuan CS, 2016, CHINA COMMUN, V13, P60, DOI 10.1109/CC.2016.7559076
NR 40
TC 13
Z9 13
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18187
EP 18200
DI 10.1007/s11042-017-5517-9
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900033
DA 2024-07-18
ER

PT J
AU Bayoudh, I
   Ben Jabra, S
   Zagrouba, E
AF Bayoudh, Ines
   Ben Jabra, Saoussen
   Zagrouba, Ezzeddine
TI Online multi-sprites based video watermarking robust to collusion and
   transcoding attacks for emerging applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind video watermarking; SURF descriptors; Dynamic multi-sprites;
   Robustness; Transcoding; Invisibility
ID RESISTANT
AB The rapid growth of network transmission of numeric videos has caused an urgent need for copyright protection against pirating. Different video watermarking techniques have been proposed to resolve this problem of ownership identification. Unfortunately, these techniques have been lacking efficiency to resist collusion attack. This paper proposes a novel dynamic approach for video watermarking using SURF (Speeded Up Robust Feature) based multi-sprite to protect the copyright of digital video. The proposed approach maximizes the compromise between invisibility, capacity, robustness against most important attacks and a reduced complexity. First, multi-sprite are generated to provide collusion and compression robustness. Then, the three YUV color space components of each sprite are marked using blind spatial algorithm that improves signature invisibility and enhances robustness. Experimental results illustrate good robustness against video transcoding, collusion and against additional several other attacks such as geometric manipulation (scaling, rotation, translation, cropping) and temporal attacks (frame dropping, frame swapping and frame rate changing). Besides, the suggested technique significantly reduces the processing time thanks to the proposed multi-sprites generation method.
C1 [Bayoudh, Ines; Ben Jabra, Saoussen; Zagrouba, Ezzeddine] Univ Tunis El Manar, Higher Inst Comp Sci, Res Lab Comp Sci Modeling & Informat & Knowledge, 2 St Abou Raihane Bayrouni, Tunis 2080, Tunisia.
C3 Universite de Tunis-El-Manar
RP Bayoudh, I (corresponding author), Univ Tunis El Manar, Higher Inst Comp Sci, Res Lab Comp Sci Modeling & Informat & Knowledge, 2 St Abou Raihane Bayrouni, Tunis 2080, Tunisia.
EM inesbayoudhia@gmail.com; saoussen.bj@laposte.net;
   ezzeddine.zagrouba@uvt.tn
RI Zagrouba, Ezzeddine/D-7896-2014
OI Zagrouba, Ezzeddine/0000-0002-2574-9080; bay, Ines/0000-0003-4282-7690
CR Barhoumi W, 2013, SIGNAL IMAGE VIDEO P, V7, P843, DOI 10.1007/s11760-011-0273-1
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Cedillo-Hernandez A, 2014, SIGNAL PROCESS, V97, P40, DOI 10.1016/j.sigpro.2013.08.019
   Cruz-Ramos C, 2010, J APPL RES TECHNOL, V8, P323
   Doërr G, 2004, PROC SPIE, V5306, P304, DOI 10.1117/12.526914
   Doerr G., 2005, Traitement du Signal, V22, P563
   He YL, 2012, AEU-INT J ELECTRON C, V66, P305, DOI 10.1016/j.aeue.2011.08.007
   Hood A, 2013, INT J COMPUTER TREND, V4128, P1148
   Houmansadr A, 2006, 8 IEEE INT S MULT IS, P343
   Karmakar A, 2016, J KING SAUD UNIV-COM, V28, P199, DOI 10.1016/j.jksuci.2014.06.019
   Koubaa M, 2012, MULTIMED TOOLS APPL, V56, P281, DOI 10.1007/s11042-010-0626-8
   Krutz Andreas, 2008, 2008 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video, P313, DOI 10.1109/3DTV.2008.4547871
   Kuo IS, 2009, INT J PATTERN RECOGN, V23, P331, DOI 10.1142/S0218001409007144
   Maity SP, 2013, J SYST SOFTWARE, V86, P47, DOI 10.1016/j.jss.2012.06.057
   Manaf AA., 2016, INT J APPL ENG RES, V11, P3484
   Preda RO, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3558734
   Su K, 2002, PROC SPIE, V4675, P491, DOI 10.1117/12.465307
   Vikas S, 2007, IAENG INT J COMPUT S, V34, P1
   Vinod P., 2006, IEE Proceedings-Information Security, V153, P61, DOI 10.1049/ip-ifs:20055088
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Zeki A, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-2371-6
   Zeng L, 2014, MACH VISION APPL, V25, P1271, DOI 10.1007/s00138-013-0551-8
NR 22
TC 17
Z9 17
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 14361
EP 14379
DI 10.1007/s11042-017-5033-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900056
DA 2024-07-18
ER

PT J
AU El Akkad, N
   Merras, M
   Baataoui, A
   Saaidi, A
   Satori, K
AF El Akkad, Nabil
   Merras, Mostafa
   Baataoui, Aziz
   Saaidi, Abderrahim
   Satori, Khalid
TI Camera self-calibration having the varying parameters and based on
   homography of the plane at infinity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Self-calibration; Varying parameters; Homography of plane at infinity;
   Nonlinear optimization
ID INTRINSIC PARAMETERS; SEQUENCES; IMAGE
AB In this approach, we will process a self-calibration problem of camera characterized by varying parameters. Our approach is based on estimating of homography of the plane at infinity and depths of interest points. This estimation is made from resolution of nonlinear equation system that is formulated from the projection of some points of the scene in the planes of different images. The relationships established between the homography of the plane at infinity and matches, between images, and those established between points of the 3D scene and their projections, in image planes, allow formulating the second nonlinear equations. This system is minimized by using the Levenberg-Marquardt algorithm to estimate the intrinsic parameters of used camera. This approach has several strong points: i) The use of any cameras (having varying parameters), ii) The use of any scenes (3D) and iii) the use of a minimum number of images (two images only). Experiments and simulations show the performance of this approach in terms of stability, accuracy and convergence.
C1 [El Akkad, Nabil; Merras, Mostafa; Baataoui, Aziz; Satori, Khalid] Univ Mohamed First, Natl Sch Appl Sci ENSA Al Hoceima, Dept Math & Comp Sci, BP 03, Ajdir, Oujda, Morocco.
   [El Akkad, Nabil; Saaidi, Abderrahim] Sidi Mohamed Ben Abdellah Univ, Dept Comp Sci, LIIAN, Fac Sci, BP 1796, Atlas, Fez, Morocco.
   [Saaidi, Abderrahim] Sidi Mohamed Ben Abdellah Univ, Polydisciplinary Fac Taza, Lab Engn Sci, LSI, BP 1223, Taza, Morocco.
C3 Mohammed First University of Oujda; Sidi Mohamed Ben Abdellah University
   of Fez; Sidi Mohamed Ben Abdellah University of Fez
RP El Akkad, N (corresponding author), Univ Mohamed First, Natl Sch Appl Sci ENSA Al Hoceima, Dept Math & Comp Sci, BP 03, Ajdir, Oujda, Morocco.; El Akkad, N (corresponding author), Sidi Mohamed Ben Abdellah Univ, Dept Comp Sci, LIIAN, Fac Sci, BP 1796, Atlas, Fez, Morocco.
EM nabil.elakkad@usmba.ac.ma; abderrahim.saaidi@usmba.ac.ma
RI Merras, Mostafa/AAJ-4405-2020; satori, khalid/GSE-3077-2022; AKKAD,
   Nabil EL/AAL-4049-2020; Saaidi, Abderrahim/R-1916-2019
OI Merras, Mostafa/0000-0002-3020-726X; AKKAD, Nabil
   EL/0000-0003-0277-8003; SATORI, khalid/0000-0001-6055-4169; Saaidi,
   Abderrahim/0000-0003-1708-0468
CR Baataoui A., 2014, INT J SOFTWARE ENG I, V8, P23
   Baataoui A., 2012, INT J COMPUT APPL, P29
   Bouda B, 2006, ICGST GVIP, P21
   Boudine B, 2016, J VIS COMMUN IMAGE R, V39, P40, DOI 10.1016/j.jvcir.2016.05.003
   Cao XC, 2006, COMPUT VIS IMAGE UND, V102, P227, DOI 10.1016/j.cviu.2006.01.004
   Chambon S, 2011, PATTERN RECOGN, V44, P2063, DOI 10.1016/j.patcog.2011.02.001
   El Akkad N, 2014, VISUAL COMPUT, V30, P519, DOI 10.1007/s00371-013-0877-2
   El Akkad N, 2012, INT CONF MULTIMED, P161, DOI 10.1109/ICMCS.2012.6320196
   Gao YY, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P537
   Gurdjos P, 2003, PROC CVPR IEEE, P491
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Jiang ZT, 2011, COMM COM INF SC, V86, P452
   Jiang ZT, 2012, J COMPUT, V7, P774, DOI 10.4304/jcp.7.3.774-778
   Liu M, 2015, CHINESE J ELECTRON, V24, P124, DOI 10.1049/cje.2015.01.020
   Liu PJ, 2003, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P262, DOI 10.1109/CGI.2003.1214479
   Liu S, 2017, J NONLINEAR SCI APPL, V10, P1148, DOI 10.22436/jnsa.010.03.24
   Liu S, 2016, MULTIMED TOOLS APPL, V75, P15525, DOI 10.1007/s11042-014-2446-8
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lui S., 2017, Multimedia Tools and Applications, V76, P5787, DOI DOI 10.1007/S11042-014-2408-1
   Manolis IAL, 2000, 3911 INRIA
   Mattoccia S, 2008, IEEE T IMAGE PROCESS, V17, P528, DOI 10.1109/TIP.2008.919362
   More J. J., 1978, Proceedings of the Biennial Conference on numerical analysis, P105
   Mori M., 2010, Proceedings 2010 IEEE International Symposium on Multimedia (ISM 2010), P196, DOI 10.1109/ISM.2010.36
   Pollefeys M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P90, DOI 10.1109/ICCV.1998.710705
   Saaidi A., 2008, WSEAS Transactions on Computers Research, V3, P295
   Saaidi A., 2009, ICGST GVIP, P41
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Sturm P, 2002, IMAGE VISION COMPUT, V20, P415, DOI 10.1016/S0262-8856(02)00012-4
   Sturm P, 2000, IEEE T PATTERN ANAL, V22, P1199, DOI 10.1109/34.879804
   Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552
   Triggs B., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P89, DOI 10.1007/BFb0055661
   Wang GH, 2009, IEEE T CIRC SYST VID, V19, P1793, DOI 10.1109/TCSVT.2009.2031380
   Yanliang Shang, 2012, Information Technology Journal, V11, P376, DOI 10.3923/itj.2012.376.379
   Yue Zhao, 2012, Information Technology Journal, V11, P926, DOI 10.3923/itj.2012.926.930
   Zhang W., 2005, GVIP 05 C
   Zhao Y., 2012, Information Technology Journal, V11, P276, DOI 10.3923/itj.2012.276.282
NR 36
TC 8
Z9 8
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 14055
EP 14075
DI 10.1007/s11042-017-5012-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900042
DA 2024-07-18
ER

PT J
AU El-Shafai, W
   El-Rabaie, S
   El-Halawany, MM
   Abd El-Samie, FE
AF El-Shafai, W.
   El-Rabaie, S.
   El-Halawany, M. M.
   Abd El-Samie, Fathi E.
TI Encoder-independent decoder-dependent depth-assisted error concealment
   algorithm for wireless 3D video communication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth maps; 3D multi-view video; Error concealment; Motion estimation;
   Directional interpolation
ID FRAME LOSS CONCEALMENT; MULTIVIEW VIDEO
AB Three-Dimensional Multi-View Video (3D MVV) contains diverse video streams taken by different cameras around an object. Thence, it is an imperative assignment to fulfill efficient compression to attain future resource bonds whilst preserving a decisive reception MVV quality. The extensive 3D MVV encoding and transmission over mobile or Internet are vulnerable to packet losses on account of the existence of severe channel faults and restricted bandwidth. In this work, we propose a new Encoder-Independent Decoder-Dependent Depth-Assisted Error Concealment (EIDD-DAEC) algorithm. It invests the depth correlations between the temporally, spatially, and inter-view adjoining Macro-Blocks (MBs) to conceal the erroneous streams. At the encoder, the existing inter-view, temporal, and spatial matching are exploited to efficiently compress the 3D MVV streams and to estimate the Disparity Vectors (DVs) and Motion Vectors (MVs). At the decoder, the gathered MVs and DVs from the received coded streams are used to calculate additional depth-assisted MVs and DVs, which are afterwards combined with the collected candidate texture color MVs and DVs groups for concealing the lost MBs of inter- and intra-encoded frames. Finally, the optimum DVs and MVs concealment candidates are selected by the Directional Interpolation Error Concealment Algorithm (DIECA) and Decoder Motion Vector Estimation Algorithm (DMVEA), respectively. Experimental results on several standardized 3D MVV sequences verified the efficacy of the proposed EIDD-DAEC algorithm by achieving ameliorated efficacious objective and subjective results without generating and transporting depth maps at the encoder. The proposed work achieves high 3D MVV quality performance with an improved average Peak Signal-to-Noise Ratio (PSNR) gain by up to 0.95 similar to 2.70 dBs compared to the state-of-the-art error concealment algorithms, which do not employ depth-assisted correlations at different Quantization Parameters (QPs) and Packet Loss Rates (PLRs) of 40%.
C1 [El-Shafai, W.; El-Rabaie, S.; El-Halawany, M. M.; Abd El-Samie, Fathi E.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University
RP El-Shafai, W (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
EM eng.waled.elshafai@gmail.com; elsayedelrabaie@gmail.com;
   mmohamedelhalawany@gmail.com; fathi_sayed@yahoo.com
RI El-Shafai, Walid/AAG-4796-2021; Sayed, Fathi/HRA-4752-2023
OI El-Shafai, Walid/0000-0001-7509-2120; Sayed, Fathi/0000-0001-8749-9518;
   EL-Rabaie, El-Sayed/0000-0001-6854-5881
CR [Anonymous], 2006, JTC1SC29WG11 ISOIEC
   Assuncao P, 2016, MULTIMED TOOLS APPL, P1
   Chen Y, 2014, IEEE MULTIMEDIA, V21, P90, DOI 10.1109/MMUL.2014.31
   Chien-Shiang Hong, 2011, 2011 Fifth International Conference on Genetic and Evolutionary Computing, P5, DOI 10.1109/ICGEC.2011.9
   Chung TY, 2011, IEEE T CONSUM ELECTR, V57, P1336, DOI 10.1109/TCE.2011.6018892
   De Abreu A, 2015, IEEE J-STSP, V9, P487, DOI 10.1109/JSTSP.2015.2407320
   Ebdelli M, 2015, IEEE T IMAGE PROCESS, V24, P3034, DOI 10.1109/TIP.2015.2437193
   El Shafai W., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2201, DOI 10.1109/ICIP.2011.6116072
   El-Shafai W., 2013, P IEEE SAUD INT EL C, P1
   El-Shafai W, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0042-y
   El-Shafai W, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0064-5
   Gadgil N, 2015, 2015 PICTURE CODING SYMPOSIUM (PCS) WITH 2015 PACKET VIDEO WORKSHOP (PV), P90, DOI 10.1109/PCS.2015.7170053
   Hewage CTER, 2013, IEEE COMMUN MAG, V51, P101, DOI 10.1109/MCOM.2013.6515053
   Huo YK, 2013, IEEE T CIRC SYST VID, V23, P1622, DOI 10.1109/TCSVT.2013.2254911
   Hwang MC, 2008, IEEE T BROADCAST, V54, P198, DOI 10.1109/TBC.2008.917274
   Khattak S, 2016, IEEE T CIRC SYST VID, V26, P829, DOI 10.1109/TCSVT.2015.2418631
   Lie WN, 2013, IEEE INT SYMP CIRC S, P2856, DOI 10.1109/ISCAS.2013.6572474
   Lie WN, 2014, IEEE T MULTIMEDIA, V16, P216, DOI 10.1109/TMM.2013.2281587
   Liu J, 2012, 2012 IEEE 23RD INTERNATIONAL SYMPOSIUM ON PERSONAL INDOOR AND MOBILE RADIO COMMUNICATIONS (PIMRC), P2566, DOI 10.1109/PIMRC.2012.6362790
   Liu YQ, 2010, IEEE T CIRC SYST VID, V20, P600, DOI 10.1109/TCSVT.2009.2035838
   Liu Z, 2013, IEEE T CIRC SYST VID, V23, P1781, DOI 10.1109/TCSVT.2013.2269019
   Ozcinar C, 2016, MULTIMED TOOLS APPL, V75, P12431, DOI 10.1007/s11042-016-3475-2
   Purica AI, 2016, IEEE T CIRC SYST VID, V26, P360, DOI 10.1109/TCSVT.2015.2389511
   Salim OH, 2013, 2013 IEEE WIRELESS COMMUNICATIONS AND NETWORKING CONFERENCE (WCNC), P4077
   Tai SC, 2016, MULTIMED TOOLS APPL, V75, P9927, DOI 10.1007/s11042-015-2899-4
   Wang H., 2016, MODELING OPTIMIZATIO, P1, DOI [10.1038/srep31509, DOI 10.1038/SREP31509]
   Xiang W, 2017, IEEE SYST J, V11, P2456, DOI 10.1109/JSYST.2015.2414662
   Xiang XG, 2014, INT CONF INSTR MEAS, P857, DOI 10.1109/IMCCC.2014.180
   Yan B, 2012, IEEE T MULTIMEDIA, V14, P936, DOI 10.1109/TMM.2012.2184743
   Zeng HQ, 2014, IEEE T CIRC SYST VID, V24, P1566, DOI 10.1109/TCSVT.2014.2310143
   Zhou Y, 2015, IEEE SENS J, V15, P1892, DOI 10.1109/JSEN.2014.2366511
NR 31
TC 25
Z9 26
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13145
EP 13172
DI 10.1007/s11042-017-4936-y
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900005
DA 2024-07-18
ER

PT J
AU Jin, X
   Yin, S
   Liu, NN
   Li, XD
   Zhao, G
   Ge, SM
AF Jin, Xin
   Yin, Sui
   Liu, Ningning
   Li, Xiaodong
   Zhao, Geng
   Ge, Shiming
TI Color image encryption in non-RGB color spaces
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image encryption; Non-RGB; Color space; Security attack
AB To protect the contents of images in the mobile internet era during image storage and transmission, image encryption has achieved a tremendous success during the last decades. Traditional color image encryption method often use the RGB color space. We have the observation that in non-RGB color spaces, the luminance channels often contain more information for content recognition than the chroma channels do. Thus, in this paper we propose to use high level encryption schemes in more informative channels and low level encryption schemes in less informative channels. The 2D Arnold's cat map followed by the 3D Lu chaotic map are conducted in the luminance channel. The less complicated DNA coding and 1D logistic map based encryption scheme is leveraged in the chroma channels. We use this strategies in 4 typical non-RGB color spaces, i.e., YCbCr, YIQ, HSV, L*a*b*. We evaluate and compare the performances and the time consumptions of the methods in the 4 Non-RGB color spaces. The experimental results reveal that the encryption methods in Non-RGB color spaces can achieve similar results as the method that conducts the same encryption level in each channel of the RBG color space, including the resistance to several attacks such as brute-force attack, statistic attack, correlation attack, while consuming less time. The method in YCbCr color space performances the best in the time consumption.
C1 [Jin, Xin; Yin, Sui; Li, Xiaodong; Zhao, Geng] Beijing Elect Sci & Technol Inst, Beijing 100070, Peoples R China.
   [Liu, Ningning] Univ Int Business & Econ, Sch Informat Technol & Management, Beijing 100029, Peoples R China.
   [Ge, Shiming] Chinese Acad Sci, Inst Informat Engn, Beijing 100093, Peoples R China.
C3 Beijing Electronic Science & Technology Institute; University of
   International Business & Economics; Chinese Academy of Sciences;
   Institute of Information Engineering, CAS
RP Ge, SM (corresponding author), Chinese Acad Sci, Inst Informat Engn, Beijing 100093, Peoples R China.
EM geshiming@iie.ac.cn
RI li, xiao/GSN-6181-2022; liang, liang/IAO-8518-2023; yuan,
   liping/JPK-7584-2023; jin, xin/GQZ-5811-2022; li,
   xiaofeng/GXF-9442-2022; Ningning, Liu/I-8438-2018
OI Ningning, Liu/0000-0001-5471-9625
FU National Natural Science Foundation of China [61402021, 61401228,
   61640216]; Science and Technology Project of the State Archives
   Administrator [2015-B-10]; open funding project of State Key Laboratory
   of Virtual Reality Technology and Systems, Beihang University
   [BUAA-VR-16KF-09]; Fundamental Research Funds for the Central
   Universities [2016LG03, 2016LG04]; China Postdoctoral Science Foundation
   [2015M581841]; Postdoctoral Science Foundation of Jiangsu Province
   [1501019A]
FX We thank all the reviewers and editors. This work is partially supported
   by the National Natural Science Foundation of China (Grant NO. 61402021,
   61401228, 61640216), the Science and Technology Project of the State
   Archives Administrator (Grant NO. 2015-B-10), the open funding project
   of State Key Laboratory of Virtual Reality Technology and Systems,
   Beihang University (Grant NO. BUAA-VR-16KF-09), the Fundamental Research
   Funds for the Central Universities (Grant NO. 2016LG03, 2016LG04), the
   China Postdoctoral Science Foundation (Grant NO. 2015M581841), and the
   Postdoctoral Science Foundation of Jiangsu Province (Grant NO.
   1501019A).
CR [Anonymous], 2016 IEEE 29 INT C M
   Fei-Fei L., 2004, CVPR WORKSH GEN MOD, V106, P178, DOI DOI 10.1109/CVPR.2004.383
   Guellier A, 2014, COMM COM INF SC, V490, P159
   Hermassi H, 2014, MULTIMED TOOLS APPL, V72, P2211, DOI 10.1007/s11042-013-1533-6
   Jin XX, 2016, IEEE PHOTONICS J, V8, DOI 10.1109/JPHOT.2016.2545648
   Jin X, 2015, LECT NOTES COMPUT SC, V9428, P160, DOI 10.1007/978-3-319-25417-3_20
   Jin X, 2015, COMM COM INF SC, V557, P74, DOI 10.1007/978-3-662-48683-2_8
   Jin X, 2015, CHIN AUTOM CONGR, P1159, DOI 10.1109/CAC.2015.7382673
   Ling B, 2010, 2ND IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER CONTROL (ICACC 2010), VOL. 5, P41, DOI 10.1109/ICACC.2010.5486998
   Mahdi A., 2014, EUR ACAD RES, V2, P4757
   Wang YZ, 2007, C IND ELECT APPL, P2558
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
   Xin Jin, 2016, Advances in Multimedia Information Processing - PCM 2016. 17th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 9916, P119, DOI 10.1007/978-3-319-48890-5_12
   Xin Jin, 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P562, DOI 10.1007/978-3-319-27671-7_47
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang Y, 2012, APPL CRYPTOGR NETW S, V357, P6303
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
NR 17
TC 21
Z9 21
U1 3
U2 48
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15851
EP 15873
DI 10.1007/s11042-017-5159-y
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200061
DA 2024-07-18
ER

PT J
AU Xia, Y
   Li, Z
AF Xia, Yong
   Li, Zhe
TI VBI-MRF model for image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Variational Bayes inference; Markov random field
   (MRF); Variational expectation-maximization (VEM)
ID GAUSSIAN MIXTURE MODEL; HEVC MOTION ESTIMATION; PARALLEL FRAMEWORK;
   ALGORITHM
AB In statistical image segmentation, the distribution of pixel values is usually assumed to be Gaussian and the optimal result is believed to be the one that has maximum a posteriori (MAP) probability. In spite of its prevalence and computational efficiency, the Gaussian assumption, however, is not always strictly followed, and hence may lead to less accurate results. Although the variational Bayes inference (VBI), in which statistical model parameters are also assumed to be random variables, has been widely used, it can hardly handle the spatial information embedded in pixels. In this paper, we incorporate spatial smoothness constraints on pixels labels interpreted by the Markov random field (MRF) model into the VBI process, and thus propose a novel statistical model called VBI-MRF for image segmentation. We evaluated our algorithm against the variational expectation-maximization (VEM) algorithm and the hidden Markov random field (HMRF) model and MAP-MRF model based algorithms on both noise-corrupted synthetic images and mosaics of natural texture. Our pilot results suggest that the proposed algorithm can segment images more accurately than other three methods and is capable of producing robust image segmentation.
C1 [Xia, Yong; Li, Zhe] Northwestern Polytech Univ, Sch Comp Sci & Engn, Shaanxi Key Lab Speech & Image Informat Proc SAII, Xian 710072, Shaanxi, Peoples R China.
   [Xia, Yong; Li, Zhe] Northwestern Polytech Univ, Sch Comp Sci & Engn, CMCC, Xian 710072, Shaanxi, Peoples R China.
C3 Northwestern Polytechnical University; Northwestern Polytechnical
   University
RP Xia, Y (corresponding author), Northwestern Polytech Univ, Sch Comp Sci & Engn, Shaanxi Key Lab Speech & Image Informat Proc SAII, Xian 710072, Shaanxi, Peoples R China.; Xia, Y (corresponding author), Northwestern Polytech Univ, Sch Comp Sci & Engn, CMCC, Xian 710072, Shaanxi, Peoples R China.
EM yxia@nwpu.edu.cn
FU National Natural Science Foundation of China [61471297]; Natural Science
   Foundation of Shaanxi Province, China [2015JM6287]; Returned Overseas
   Scholar Project of Shaanxi Province, China
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61471297, in part by the Natural
   Science Foundation of Shaanxi Province, China, under Grant 2015JM6287,
   and in part by the Returned Overseas Scholar Project of Shaanxi
   Province, China.
CR Banerjee A, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2488900
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Brodatz P, 1976, LAND SEA SKY PHOTOG
   Chen SF, 2010, IEEE T IMAGE PROCESS, V19, P2254, DOI 10.1109/TIP.2010.2047164
   Comer ML, 2000, IEEE T IMAGE PROCESS, V9, P1731, DOI 10.1109/83.869185
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Deng HW, 2004, PATTERN RECOGN, V37, P2323, DOI [10.1016/S0031-3203(04)00195-5, 10.1016/j.patcog.2004.04.015]
   Depeursinge A, 2014, IEEE T IMAGE PROCESS, V23, P898, DOI 10.1109/TIP.2013.2295755
   Donoser M, 2010, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2010.5539833
   Eches O, 2013, IEEE T IMAGE PROCESS, V22, P5, DOI 10.1109/TIP.2012.2204270
   Farag AA, 2005, IEEE T GEOSCI REMOTE, V43, P1617, DOI 10.1109/TGRS.2005.849059
   Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138
   FOGEL I, 1989, BIOL CYBERN, V61, P103, DOI 10.1007/BF00204594
   FU KS, 1981, PATTERN RECOGN, V13, P3, DOI 10.1016/0031-3203(81)90028-5
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hatt M, 2009, IEEE T MED IMAGING, V28, P881, DOI 10.1109/TMI.2008.2012036
   Huang A, 2010, IEEE T IMAGE PROCESS, V19, P2737, DOI 10.1109/TIP.2010.2048965
   Ji J, 2014, IEEE J-STARS, V7, P4929, DOI 10.1109/JSTARS.2014.2308531
   Ji ZX, 2014, NEUROCOMPUTING, V134, P60, DOI 10.1016/j.neucom.2012.12.067
   Ji ZX, 2012, COMPUT METH PROG BIO, V108, P644, DOI 10.1016/j.cmpb.2011.10.010
   Ji ZX, 2012, APPL SOFT COMPUT, V12, P1659, DOI 10.1016/j.asoc.2012.02.010
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   KRAHENBUHL P, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472
   Krinidis M, 2009, IEEE T IMAGE PROCESS, V18, P1613, DOI 10.1109/TIP.2009.2018002
   Kuusela Mikael, 2009, Proceedings 2009 International Joint Conference on Neural Networks (IJCNN 2009 - Atlanta), P1688, DOI 10.1109/IJCNN.2009.5178726
   Li L, 2010, IEEE T IMAGE PROCESS, V19, P1, DOI 10.1109/TIP.2009.2032341
   Li S. Z., 2009, Markov random field modeling in image analysis
   Li SZ, 1970, HDB STAT, V21, P473
   Li Zhang, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563097
   Liu GY, 2015, IEEE T IMAGE PROCESS, V24, P3990, DOI 10.1109/TIP.2015.2456505
   MANJUNATH BS, 1991, IEEE T PATTERN ANAL, V13, P478, DOI 10.1109/34.134046
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127
   Marroquin JL, 2003, IEEE T PATTERN ANAL, V25, P1380, DOI 10.1109/TPAMI.2003.1240112
   Nasios N, 2006, IEEE T SYST MAN CY B, V36, P849, DOI 10.1109/TSMCB.2006.872273
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   PAVLIDIS T, 1979, P IEEE, V67, P737, DOI 10.1109/PROC.1979.11323
   Ribes S, 2014, IEEE T MED IMAGING, V33, P1986, DOI 10.1109/TMI.2014.2329019
   Nguyen TM, 2013, IEEE T CIRC SYST VID, V23, P621, DOI 10.1109/TCSVT.2012.2211176
   Tzikas DG, 2008, IEEE SIGNAL PROC MAG, V25, P131, DOI 10.1109/MSP.2008.929620
   Wang W, 2016, PROC CVPR IEEE, P2378, DOI 10.1109/CVPR.2016.261
   Wang W, 2016, IEEE MULTIMEDIA, V23, P80, DOI 10.1109/MMUL.2016.69
   Wang W, 2016, IEEE T IMAGE PROCESS, V25, P1465, DOI 10.1109/TIP.2016.2523340
   Wong WCK, 2005, IEEE T IMAGE PROCESS, V14, P1512, DOI 10.1109/TIP.2005.852199
   Xia Y, 2006, IEEE T IMAGE PROCESS, V15, P614, DOI 10.1109/TIP.2005.863029
   Xia Y, 2014, 2014 INTERNATIONAL CONFERENCE ON SECURITY, PATTERN ANALYSIS, AND CYBERNETICS (SPAC), P59, DOI 10.1109/SPAC.2014.6982657
   Xiao Y, 2011, PATTERN RECOGN, V44, P1708, DOI 10.1016/j.patcog.2011.02.002
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan C, 2011, IEEE SIGNAL PROCESS, V21, P573
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
   Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 55
TC 0
Z9 0
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13343
EP 13361
DI 10.1007/s11042-017-4951-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900013
DA 2024-07-18
ER

PT J
AU Reis, M
   Almeida, C
   Rocha, RM
AF Reis, Margarida
   Almeida, Carlos
   Rocha, Rui M.
TI On the performance of surface electromyography-based onset detection
   methods with real data in assistive technologies Comparative analysis
   and enhancements via sensor fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Accelerometer; Assistive technologies; Embedded systems; Human-computer
   interaction; Sensor fusion; Surface electromyography; Onset detection
ID COMPUTER-INTERFACE; EMG
AB Assistive Technologies are used to increase the autonomy of people with motor disabilities by enhancing their functional capabilities. Surface Electromyography sensors have been explored in the scope of Assistive Technologies as an input modality, to provide greater control and flexibility. In this case, triggering signals are dependent on the detection of the moment when the user performs a voluntary muscular contraction. In the literature, various methods to determine this onset have been studied, but mainly for the non-disabled population and may not be designed to deal with the low signal-to-noise ratio, motion artifacts and spasms, frequently observed in people with motor disabilities, which may trigger false positives. The main purpose of this article is to perform a comparative analysis of different methods in multiple configurations of their parameters, with the goal of selecting one that can be implemented in an embedded system, targeting real time and wireless operation of a tool for Human-Computer Interaction. Furthermore, in this work we seek to improve the performance of existing onset detection methods, through a proposed sensor fusion approach, combining an Accelerometer with the Surface Electromyography sensor, to integrate motion analysis in the process of validating or rejecting muscle events.
C1 [Reis, Margarida] Inst Super Tecn, P-1049001 Lisbon, Portugal.
   [Almeida, Carlos; Rocha, Rui M.] IT, P-1049001 Lisbon, Portugal.
C3 Universidade de Lisboa; Instituto de Telecomunicacoes
RP Reis, M (corresponding author), Inst Super Tecn, P-1049001 Lisbon, Portugal.
EM margarida.reis@tecnico.ulisboa.pt; carlos.r.almeida@tecnico.ulisboa.pt;
   rui.rocha@lx.it.pt
RI ; Almeida, Carlos/P-1143-2014
OI Rocha, Rui M./0000-0003-1183-453X; Almeida, Carlos/0000-0003-1002-9635
CR Abbink JH, 1998, J ORAL REHABIL, V25, P365
   Andreasen D, 2005, 28 ANN C REH ENG ASS
   [Anonymous], 2013, THESIS
   [Anonymous], 2011, WORLD REP DIS
   Barea R, 2011, SENSORS, V11
   Barreto AB, 2000, J REHABIL RES DEV, V37, P53
   Bonato P, 1998, IEEE T BIO-MED ENG, V45, P287, DOI 10.1109/10.661154
   Catela Jose M., 2013, International Journal of Adaptive, Resilient and Autonomic Systems, V4, P82, DOI 10.4018/jaras.2013070105
   Chowdhury RH, 2013, SENSORS-BASEL, V13, P12431, DOI 10.3390/s130912431
   Cook A.M., 2014, Assistive Technologies: Principles and Practice
   da Silva HP, 2014, IEEE PERVAS COMPUT, V13, P64, DOI 10.1109/MPRV.2014.61
   da Silva HP, 2014, COMPUT METH PROG BIO, V115, P20, DOI 10.1016/j.cmpb.2014.03.002
   Drapala J., 2012, ARCH CONTROL SCI, V22, P427, DOI DOI 10.2478/V10170-011-0033-Z
   Encarnacao P., 2015, Tecnologias de Apoio a Pessoas com Deficiencia
   Guerreiro T, 2007, THESIS
   Hodges PW, 1996, ELECTROMYOGR MOTOR C, V101, P511, DOI 10.1016/S0013-4694(96)95190-5
   Jeong H, 2004, LECT NOTES COMPUT SC, V3101, P163
   Käthner I, 2015, J NEUROENG REHABIL, V12, DOI 10.1186/s12984-015-0071-z
   Kaminer M.S., 2009, ATLAS COSMETIC SURG
   Levis P, 2005, AMBIENT INTELLIGENCE, P115
   LIDIERTH M, 1986, ELECTROEN CLIN NEURO, V64, P378, DOI 10.1016/0013-4694(86)90163-X
   Liu J, 2015, PLOS ONE, V10
   Londral A., 2013, J ACCESSIBIL DESIGN, V3, P118, DOI [10.17411/jacces.v3i2.15, DOI 10.17411/JACCES.V3I2.15]
   Majaranta P., 2014, ADV PHYSL COMPUTING, P39, DOI DOI 10.1007/978-1-4471-6392-3_3
   Paul GM, 2014, IEEE SENS J, V14, P393, DOI 10.1109/JSEN.2013.2283424
   Penaloza C, 2013, IEEE INT CONF ROBOT, P3396, DOI 10.1109/ICRA.2013.6631051
   Pinheiro CG, 2012, IEEE ENG MED BIO, P1984, DOI 10.1109/EMBC.2012.6346345
   PLUX, 2015, OPENS REV US MAN
   Porter R.S., 2011, The Merck Manual of Diagnosis and Therapy
   Rupp R., 2014, Brain-Computer-Interfaces in their ethical, social and cultural contexts, P7, DOI [10.1007/978-94-017-8996-72, DOI 10.1007/978-94-017-8996-72]
   Rupp R, 2019, FRONT NEUROSCI, V161, P171
   Silva H, 2012, INT J HERIT STUD, P1
   Solnik S, 2010, EUR J APPL PHYSIOL, V110, P489, DOI 10.1007/s00421-010-1521-8
   Staude G., 2001, EURASIP Journal on Applied Signal Processing, V2001, P67, DOI 10.1155/S1110865701000191
   Vaisman L, 2010, J ELECTROMYOGR KINES, V20, P750, DOI 10.1016/j.jelekin.2010.02.010
NR 35
TC 1
Z9 3
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 11491
EP 11520
DI 10.1007/s11042-017-4963-8
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900061
DA 2024-07-18
ER

PT J
AU Jan, Z
   Khan, A
   Sajjad, M
   Muhammad, K
   Rho, S
   Mehmood, I
AF Jan, Zahoor
   Khan, Arshad
   Sajjad, Muhammad
   Muhammad, Khan
   Rho, Seungmin
   Mehmood, Irfan
TI A review on automated diagnosis of malaria parasite in microscopic blood
   smears images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Malaria parasite; Red blood cells; Parasite segmentation; Thin blood
   smear; Classification
ID CLASSIFICATION; SEGMENTATION
AB Malaria is a life-threatening disease caused by parasite of genus plasmodium, which is transmitted through the bite of infected Anopheles. A rapid and accurate diagnosis of malaria is demanded for proper treatment on time. Mostly, conventional microscopy is followed for diagnosis of malaria in developing countries, where pathologist visually inspects the stained slide under light microscope. However, conventional microscopy has occasionally proved inefficient since it is time consuming and results are difficult to reproduce. Alternate techniques for malaria diagnosis based on computer vision were proposed by several researchers. The aim of this paper is to review, analyze, categorize and address the recent developments in the area of computer aided diagnosis of malaria parasite. Research efforts in quantification of malaria infection include normalization of images, segmentation followed by features extraction and classification, which were reviewed in detail in this paper. At the end of review, the existent challenges as well as possible research perspectives were discussed.
C1 [Jan, Zahoor; Khan, Arshad; Sajjad, Muhammad; Muhammad, Khan] Islamia Coll Peshawar, Dept Comp Sci, Digital Image Proc Lab, Peshawar, Pakistan.
   [Muhammad, Khan] Sejong Univ, Digital Contents Res Inst, Coll Elect & Informat Engn, Intelligent Media Lab, Seoul, South Korea.
   [Rho, Seungmin] Sungkyul Univ, Dept Media Software, Anyang, South Korea.
   [Mehmood, Irfan] Sejong Univ, Dept Comp Sci & Engn, Seoul, South Korea.
C3 University of Peshawar; Sejong University; Sungkyul University; Sejong
   University
RP Mehmood, I (corresponding author), Sejong Univ, Dept Comp Sci & Engn, Seoul, South Korea.
EM irfan@sejong.ac.kr
RI Rho, Seungmin/HTP-6683-2023; Sajjad, Muhammad/GZL-4962-2022; Khan,
   Muhammad/IXN-8470-2023; Sajjad, Muhammad/L-5269-2016; Muhammad,
   Khan/L-9059-2016
OI Sajjad, Muhammad/0000-0003-0006-1156; Sajjad,
   Muhammad/0000-0001-5646-0338; Muhammad, Khan/0000-0003-4055-7412;
   Mehmood, Irfan/0000-0001-7864-957X; Muhammad, Khan/0000-0002-5302-1150
FU National Research Foundation of Korea (NRF) - Ministry of Education
   [NRF-2016R1D1A1A09919551]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (NRF-2016R1D1A1A09919551).
CR Abdul-Nasir AS, 2012, COMPUT MATH METHOD M, V2012, DOI 10.1155/2012/637360
   Aimi Salihah A.-N, 2013, WSEAS T BIOL BIOMEDI, V10
   Annaldas MS, 2014, INT J RES ADVENT TEC, V2
   [Anonymous], 2020, Feature Extraction and Image Processing
   [Anonymous], 2015, MALARIA DIS CONCEPTS
   [Anonymous], 2015, WHAT IS MALARIA
   [Anonymous], 2014, OPEN J CLIN DIAGN, DOI DOI 10.4236/OJCD.2014.42014
   [Anonymous], EL ENG INF ICEEI 201
   [Anonymous], 2007, Supervised machine learning: A review of classification techniques
   Arco JE, 2015, EXPERT SYST APPL, V42, P3041, DOI 10.1016/j.eswa.2014.11.037
   Bates I, 2004, MALARIA J, V3, DOI 10.1186/1475-2875-3-38
   Bernard Marcus PD, 2009, DEADLY DIS EPIDEMICS
   Chakrabortya K, 2015, J HLTH MED INFORM, V2015
   Chayadevi M, 2015, COMPUTATIONAL INTELL, P53
   Dallet C, 2014, IEEE INT SYMP CIRC S, P2405, DOI 10.1109/ISCAS.2014.6865657
   Damahe L.B., 2011, International Journal Computing Science and Applications, V4, P71
   Das DK, 2013, MICRON, V45, P97, DOI 10.1016/j.micron.2012.11.002
   Devi RR, 2011, ADV COMPUTING INT J, V2
   Di Ruberto C, 2002, IMAGE VISION COMPUT, V20, P133, DOI 10.1016/S0262-8856(01)00092-0
   Di Rubeto C, 2000, PATT REC P 15 INT C
   Díaz G, 2009, J BIOMED INFORM, V42, P296, DOI 10.1016/j.jbi.2008.11.005
   Gatc J, 2013, ADV COMP SCI INF SYS
   Ghosh M, 2011, IM INF PROC ICIIP 20
   Ghosh S, 2014, CSI T ICT, V2, P43
   Gual-Arnau X, 2015, MED BIOL ENG COMPUT, V53, P623, DOI 10.1007/s11517-015-1267-x
   Halim S, 2006, 2006 9 INT C CONTR A
   Hanif N, 2011, SIGN PROC ITS APPL C
   Heijmans HJAM, 1999, COMPUT VIS IMAGE UND, V73, P99, DOI 10.1006/cviu.1998.0703
   Hung YW, 2015, J MED BIOL ENG, V35, P803, DOI 10.1007/s40846-015-0101-0
   Kaewkamnerd S, 2012, BMC BIOINFORMATICS, V13, DOI 10.1186/1471-2105-13-S17-S18
   Kareem S, 2012, 2012 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS), P240, DOI 10.1109/APCCAS.2012.6419016
   Kareem S., 2012, 2012 UKSim 14th International Conference on Computer Modelling and Simulation (UKSim), P432, DOI 10.1109/UKSim.2012.108
   Kareem S, 2011, 2011 IE INT S CIRC S
   Khan M.I., 2011, Int. J. Biom. Bioinform, V5, P97
   Khan NA, 2014, COMP SCI SOFTW ENG J
   Khatri K.M., 2013, International Journal of Computer Applications®(IJCA).
   Khattak AA, 2013, MALARIA J, V12, DOI 10.1186/1475-2875-12-297
   Komagal E, 2013, INT J ENG RES TECHNO
   Kumar A, 2012, INT J LATEST RES SCI, P2278
   Kumarasamy SK, 2011, MACH VISION APPL, V22, P461, DOI 10.1007/s00138-010-0284-x
   Le MT, 2008, BMC CELL BIOL, V9, DOI 10.1186/1471-2121-9-15
   Lee H, 2014, PATTERN RECOGN LETT, V49, P155, DOI 10.1016/j.patrec.2014.06.010
   Li-hui Zou, 2010, Proceedings 2010 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2010), P172, DOI 10.1109/DICTA.2010.40
   Linder N, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0104855
   Maiseli B, 2014, 2014 INTERNATIONAL CONFERENCE ON MECHATRONICS AND CONTROL (ICMC), P2048, DOI 10.1109/ICMC.2014.7231926
   Makkapati VV, 2009, 2009 IE INT C AC SPE
   Malihi L, 2013, MACH VIS IM PROC MVI
   Mandal S, 2010, AEROSP CONF PROC
   Mas D, 2015, OPT COMMUN, V350, P13, DOI 10.1016/j.optcom.2015.03.064
   Mushabe MC, 2013, 2013 35 ANN INT C IE
   Nugroho AS, 2014, DAT SOFTW ENG ICODSE
   Okwa O. O., 2012, MALARIA PARASITES, DOI [10.5771/1477, DOI 10.5771/1477]
   Organization WH, 2009, MAL MICR QUAL ASS MA
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Prasad K, 2012, J DIGIT IMAGING, V25, P542, DOI 10.1007/s10278-011-9442-6
   Premaratne SP, 2003, METHODS CELL BIOL, V42
   Purwar Y, 2011, MALARIA J, V10, DOI 10.1186/1475-2875-10-364
   Rakshit P, 2013, IM INF PROC ICIIP 20
   Raviraja S, 2007, 3 KUAL LUMP INT C BI
   Rosado L, 2016, PROCEDIA COMPUT SCI, V90, P138, DOI 10.1016/j.procs.2016.07.024
   Ross NE, 2006, MED BIOL ENG COMPUT, V44, P427, DOI 10.1007/s11517-006-0044-2
   Sajjadl Muhammad, 2016, LEUKOCYTES CLASSIFIC, DOI [10.1109/ACCESS.2016.2636218, DOI 10.1109/ACCESS.2016.2636218]
   Savkare S, 2015, COMM INF COMP TECHN
   Savkare SS, 2012, PROC TECH, V1, P405, DOI 10.1016/j.protcy.2012.10.048
   Sheeba F., 2013, P 7 INT C BIOINSP CO
   Singh A., 2014, INT J ENG ADV TECHNO, V4, P40
   Sio SWS, 2007, J MICROBIOL METH, V68, P11, DOI 10.1016/j.mimet.2006.05.017
   Somasekar J, 2015, COMPUT ELECTR ENG, V45, P336, DOI 10.1016/j.compeleceng.2015.04.009
   Somasekar J., INT J COMPUTER APPL, P23
   Soni J., 2011, INT J ENG SCI TECHNO, V3, P5260
   Suradkar P., 2013, INT J ENG INNOV TECH, V2
   Suryawanshi M.S., 2013, International Journal of Scientific & Engineering Research, V4, P373
   Suwalka I., 2012, P 2012 INT C COMP CO, P1
   Tek F.B., 2007, Computerised diagnosis of malaria
   Tek FB, 2009, MALARIA J, V8, DOI 10.1186/1475-2875-8-153
   Tek FB, 2010, COMPUT VIS IMAGE UND, V114, P21, DOI 10.1016/j.cviu.2009.08.003
   Tek FB, 2006, BMVC
   Toha SF, 2007, 2007 INT C SIGN PROC
   Tsai MH, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0280-9
   Warhurst DC, 1996, J CLIN PATHOL, V49, P533, DOI 10.1136/jcp.49.7.533
   WHO, 2010, Basic malaria microscopy-Part I: Learner's guide
   Widodo S, 2014, TEXTURE ANAL DETECT
   Yunda L, 2012, SIST TELEMAT, V10, P9, DOI 10.18046/syt.v10i20.1151
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   2013, WORLD MALARIA REPORT, P1
NR 85
TC 27
Z9 29
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9801
EP 9826
DI 10.1007/s11042-017-4495-2
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200030
DA 2024-07-18
ER

PT J
AU Lamb, AB
   Khambete, M
AF Lamb, Anupama B.
   Khambete, Madhuri
TI No-reference perceived image quality measurement for multiple
   distortions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blur; Eigen values; Image quality; Multiple distortions; Noise
ID SIMILARITY; INDEX; BLUR
AB No-reference image quality assessment (NR-IQA) metrics play an important role in real-world multimedia applications. Accordingly, many NR-IQA metrics have been proposed in the literature. Most of these proposed metrics predict the visual quality only of images distorted with a single distortion, whereas in the real-world, digital images undergo various steps that contaminate them with multiple distortions before reaching consumers. However, only a few NR-IQA metrics have been proposed for multiple distortions. In this paper, we propose an NR-IQA metric for images distorted with blur and noise, which are added during the image acquisition and transmission process. In the proposed metric, perceived blur and noise scores are estimated separately. These scores are then mapped to the final quality score considering the perceived degree of each type of distortion, the nonlinear functions of the distortions, and the joint effects of the distortions. Weights for each mapping component are learned with subjective data input. Performance comparison of the proposed metric on the blur-noise image dataset of the LIVE multiply distorted (LIVEMD) image quality database confirm that the proposed metric is more effective than the state-of-the-art full-reference and NR IQA metrics.
C1 [Lamb, Anupama B.] Savitribai Phule Pune Univ, Dept E&TC, Coll Engn, Wellesely Rd, Pune 411005, Maharashtra, India.
   [Khambete, Madhuri] Savitribai Phule Pune Univ, Dept E&TC, Cummins Coll Engn Women, Pune 411052, Maharashtra, India.
C3 College of Engineering Pune; Savitribai Phule Pune University;
   Savitribai Phule Pune University
RP Lamb, AB (corresponding author), Savitribai Phule Pune Univ, Dept E&TC, Coll Engn, Wellesely Rd, Pune 411005, Maharashtra, India.
EM anu_lamb2000@yahoo.com
RI Khambete, Madhuri/GOE-5233-2022
OI Khambete, Madhuri/0000-0002-7323-2000
CR [Anonymous], DIGITAL IMAGE PROCES
   Chandler DM, 2006, PROC SPIE, V6057, DOI 10.1117/12.655442
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   GRANRATH DJ, 1981, P IEEE, V69, P552, DOI 10.1109/PROC.1981.12024
   Gu K, 2014, IEEE T BROADCAST, V60, P555, DOI 10.1109/TBC.2014.2344471
   Hassen R, 2013, IEEE T IMAGE PROCESS, V22, P2798, DOI 10.1109/TIP.2013.2251643
   Immerkaer J, 1996, COMPUT VIS IMAGE UND, V64, P300, DOI 10.1006/cviu.1996.0060
   Jayaraman D, 2012, CONF REC ASILOMAR C, P1693, DOI 10.1109/ACSSC.2012.6489321
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li QH, 2016, IEEE SIGNAL PROC LET, V23, P541, DOI 10.1109/LSP.2016.2537321
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Liu XH, 2013, IEEE T IMAGE PROCESS, V22, P5226, DOI 10.1109/TIP.2013.2283400
   Lu YA, 2015, IEEE SIGNAL PROC LET, V22, P1811, DOI 10.1109/LSP.2015.2436908
   Ma L, 2011, IEEE T MULTIMEDIA, V13, P824, DOI 10.1109/TMM.2011.2109701
   Marziliano P, 2004, SIGNAL PROCESS-IMAGE, V19, P163, DOI 10.1016/j.image.2003.08.003
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Narvekar ND, 2011, IEEE T IMAGE PROCESS, V20, P2678, DOI 10.1109/TIP.2011.2131660
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, LIVE IMAGE QUALITY A, DOI DOI 10.1109/CVPR.2015.7298594
   Sodhani P, 2015, PROCEDIA COMPUT SCI, V54, P549, DOI 10.1016/j.procs.2015.06.063
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Xue WF, 2013, PROC CVPR IEEE, P995, DOI 10.1109/CVPR.2013.133
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2012, IEEE IMAGE PROC, P1473, DOI 10.1109/ICIP.2012.6467149
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang L, 2010, IEEE IMAGE PROC, P321, DOI 10.1109/ICIP.2010.5649275
   Zhu X, 2010, IEEE T IMAGE PROCESS, V19, P3116, DOI 10.1109/TIP.2010.2052820
NR 34
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8653
EP 8675
DI 10.1007/s11042-017-4761-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800039
DA 2024-07-18
ER

PT J
AU Manoranjitham, R
   Deepa, P
AF Manoranjitham, R.
   Deepa, P.
TI Efficient invariant interest point detector using Bilateral-Harris
   corner detector for object recognition application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interest point detector; Bilateral filter; Scale invariant feature
   transform (SIFT); Bilateral-Harris corner interest point
ID SIFT; SCALE
AB Interest point detection plays a significant role in computer vision applications. The most commonly used interest point detector algorithm is scale invariant feature transform (SIFT). The use of Gaussian filter in the SIFT algorithm fails to match interest points on the edge and it also causes blur annoyance in the rescaling process. To overcome this failure Bilateral-Harris Corner Detector (BHCD) has been proposed in this paper. In the proposed BHCD, a Bilateral filter preserves edges by smoothening and removing noise in an image. Accuracy in localization of interest points are improved by using the proposed dynamic blur metric calculation. The Harris corner has been added to get stable and reliable interest point detection. The proposed BHCD has been simulated for the evaluation criteria such as repeatability and matching score. Extensive experimental results show that the proposed method is more robust to illumination, scaling, rotation, compression and viewpoint changes. The experimental evaluation for BHCD has been carried for the object recognition benchmark datasets COIL-100, ZuBud, Caltech-101. The proposed BHCD achieves highest recognition rate compared to the other state-of-the-art methods.
C1 [Manoranjitham, R.; Deepa, P.] Govt Coll Technol, Dept Elect & Commun Engn, Coimbatore 641013, Tamil Nadu, India.
RP Manoranjitham, R (corresponding author), Govt Coll Technol, Dept Elect & Commun Engn, Coimbatore 641013, Tamil Nadu, India.
EM manoranjane@gmail.com; deepap05@gmail.com
RI Deepa, P/ABF-9371-2021; Silva, Isac/AAQ-4462-2021; R,
   Manoranjitham/HJO-8536-2023
OI R, Manoranjitham/0000-0003-4717-0835
CR Agrawal M, 2008, LECT NOTES COMPUT SC, V5305, P102, DOI 10.1007/978-3-540-88693-8_8
   Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16
   [Anonymous], 260 SWISS FED I TECH
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218
   Chang L, 2010, LECT NOTES ARTIF INT, V6438, P56
   Crete F, 2007, PROC SPIE, V6492, DOI 10.1117/12.702790
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Huang MM, 2015, J SENSORS, V2015, DOI 10.1155/2015/685154
   Krig S., 2014, COMPUTER VISION METR, P217, DOI DOI 10.1007/978-1-4302-5930-5_6
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Nayar SK, 1996, 00696 CUCS COL U DEP
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Se S, 2001, IEEE INT CONF ROBOT, P2051, DOI 10.1109/ROBOT.2001.932909
   Sirmaçek B, 2009, IEEE T GEOSCI REMOTE, V47, P1156, DOI 10.1109/TGRS.2008.2008440
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Zhou HY, 2009, COMPUT VIS IMAGE UND, V113, P345, DOI 10.1016/j.cviu.2008.08.006
NR 24
TC 5
Z9 5
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9365
EP 9378
DI 10.1007/s11042-017-4982-5
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200011
DA 2024-07-18
ER

PT J
AU Bansal, R
   Nagpal, CK
   Gupta, S
AF Bansal, Ritesh
   Nagpal, Chander Kumar
   Gupta, Shailender
TI An efficient hybrid security mechanism based on chaos and improved BPCS
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE BPCS; Chaos theory; Cryptography; Encryption; Steganography
AB Commonly used security mechanisms such as cryptography and steganography suffer from weaknesses when used in a standalone manner. Extra efforts in the form of additional permutations/diffusions etc. result in higher ciphering/deciphering time complexity. Thus, there is a requirement for a security mechanism(s) which can provide adequate security without putting a considerable burden on ciphering/deciphering time complexity. This paper is an effort in this direction. The paper proposes a hybrid mechanism that employs chaotic based encryption scheme to encrypt data and an improved Bit-Plane Complexity Segmentation Steganography algorithm to embed the data. The proposed mechanism uses two new complexity measures to differentiate between noisy regions and simple ones appropriately. The scheme was implemented in MATLAB, and the simulation results show that the proposed mechanism has high embedding capacity, high security with a moderate decrease in PSNR value and is computationally fast.
C1 [Bansal, Ritesh; Nagpal, Chander Kumar; Gupta, Shailender] YMCA Univ Sci & Technol, Faridabad 121002, India.
   [Bansal, Ritesh] YMCA Univ Sci & Technol, Sec 6, Faridabad 121006, Faridabad, India.
C3 J.C. Bose University of Science & Technology, YMCA; J.C. Bose University
   of Science & Technology, YMCA
RP Bansal, R (corresponding author), YMCA Univ Sci & Technol, Faridabad 121002, India.; Bansal, R (corresponding author), YMCA Univ Sci & Technol, Sec 6, Faridabad 121006, Faridabad, India.
EM ritesh.bansal@hotmail.com; nagpalckumar@rediffmail.com;
   shailender81@gmail.com
RI gupta, shailender/Y-8231-2019; Nagpal, Chander Kumar/AAG-3473-2021
OI gupta, shailender/0000-0003-1383-7152; Nagpal, Chander
   Kumar/0000-0003-1518-2882
CR Alia MohammadAhmad., 2010, EUR J SCI RES, V40, P223
   Alkhraisat Habes, 2006, [Информационные процессы, Informatsionnye protsessy], V6, P1
   [Anonymous], 2010, 2010 2 INT C COMPUTI
   [Anonymous], 2012, INT J COMPUTER APPL
   [Anonymous], 2014, INT J COMPUTER ELECT
   [Anonymous], 2012, INT J COMPUTER SCI I
   [Anonymous], 2013, GLOBAL J COMP SCI TE
   [Anonymous], 2012, INT J ENG TRENDS TEC
   [Anonymous], 2016, INT J SIG PROCESS PA
   [Anonymous], 2014, 2014 INT C INFORMATI
   Bansal R, 2017, MULTIMED TOOLS APPL, V76, P16529, DOI 10.1007/s11042-016-3926-9
   Bansal R, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P933
   Chaudhary Divya, 2016, International Journal of Information Privacy, Security and Integrity, V2, P216
   François M, 2012, SIGNAL PROCESS-IMAGE, V27, P249, DOI 10.1016/j.image.2011.11.003
   Gupta S., 2012, Int. J. Mod. Educ. Comput. Sci., V4, P27
   Hanchinamani G, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0062-7
   HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898
   Kawaguchi E, 1999, P SOC PHOTO-OPT INS, V3528, P464, DOI 10.1117/12.337436
   Masud Karim S. M., 2011, 2011 14th International Conference on Computer and Information Technology (ICCIT), P286, DOI 10.1109/ICCITechn.2011.6164800
   Niimi M., 2005, Visual Content Processing and Representation. 9th International Workshop, VLBV 2005. Revised Selected Papers (Lecture Notes in Computer Science Vol. 3893), P29
   Raphael A. J., 2011, INT J COMP TECH APPL, V2, P626
   Sam IS, 2012, NONLINEAR DYNAM, V69, P1995, DOI 10.1007/s11071-012-0402-6
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
NR 23
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 6799
EP 6835
DI 10.1007/s11042-017-4600-6
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700017
DA 2024-07-18
ER

PT J
AU Mukherjee, I
   Ganguly, R
AF Mukherjee, Imon
   Ganguly, Ritam
TI Multiple video clips preservation using folded back audio-visual
   cryptography scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual cryptography; Audio cryptography; Information security; Secret
   sharing
ID AUDIO
AB Science and technology devices pose new and vibrant solutions to the day to day problems faced by the Information Technology user society, data security issues are on the rise as well. Now-a-days security concerns are directly proportional with the steep hike in amount of data handled. The greatest threat comes from individuals who try to access information stored in servers or the cloud or any other location without authorised permission. Visual Cryptography is one of such schemes that involves securing ones information and so is Audio Cryptography. We hardly find any approach that takes into consideration both audio and image files. In our paper we present an algorithm that preserves multiple audio and image files of equal length which in turn can be extended to audio-video clips, naming it Audio-Visual Cryptography. These audio-video clips are broken into equal number of dependant share clips using Folded Back Audio-Visual Cryptography Scheme (FBAVCS) such that the decryption process includes basic logical operations between the corresponding pixels and samples, in case of image and audio respectively, of the successive shares.
C1 [Mukherjee, Imon] Indian Inst Informat Technol, Dept Comp Sci & Engn, Kalyani 741235, W Bengal, India.
   [Ganguly, Ritam] St Thomas Coll Engn & Technol, Dept Comp Sci & Engn, Kolkata 700023, India.
RP Mukherjee, I (corresponding author), Indian Inst Informat Technol, Dept Comp Sci & Engn, Kalyani 741235, W Bengal, India.
EM mukherjee.imon@gmail.com; ganguly.ritam@gmail.com
RI Mukherjee, Imon/AFP-2409-2022
OI Mukherjee, Imon/0000-0002-8598-148X
CR Chettri L, 2014, INT J EMERG TECHNOL, V3, P536
   Ciptasari R.W., 2014, EURASIP J INFORM SEC, V2014, P1
   Desmedt Y, 1998, LECT NOTES COMPUT SC, V1514, P392
   Guo C, 2014, MULTIMED TOOLS APPL, V72, P2195, DOI 10.1007/s11042-013-1510-0
   Hemalatha S, 2015, PROCEDIA COMPUT SCI, V47, P272, DOI 10.1016/j.procs.2015.03.207
   Kang I, 2011, IEEE T IMAGE PROCESS, V20, P132, DOI 10.1109/TIP.2010.2056376
   Katta S, 2010, CORR
   Lee KH, 2012, IEEE T INF FOREN SEC, V7, P219, DOI 10.1109/TIFS.2011.2167611
   Lin CC, 2003, J INF SCI ENG, V19, P605
   Lin SJ, 2012, IEEE T INF FOREN SEC, V7, P197, DOI 10.1109/TIFS.2011.2167229
   Liu F, 2011, IEEE T INF FOREN SEC, V6, P307, DOI 10.1109/TIFS.2011.2116782
   Mukherjee I, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P417, DOI 10.1109/ICRCICN.2015.7434275
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Nguyen Thang-An., 2016, MANIPULATION AUTOMAT, P1
   Poonkuzhali D.S.M., 2015, International Journal of Advanced Research in Computer and Communication Engineering, V4, P440
   Shrivas B., 2015, INT J COMPUTER APPL, V117, P19
   Socek D., 2005, 2005 IEEE International Conference on Electro Information Technology (IEEE Cat. No. 05EX1098C)
   Sridhar S, 2013, MULTIMED TOOLS APPL, V72, P1
   Wang ZM, 2009, IEEE T INF FOREN SEC, V4, P383, DOI 10.1109/TIFS.2009.2024721
   Zhou Z, 2006, IEEE T IMAGE PROCESS, V15, P2441, DOI 10.1109/TIP.2006.875249
NR 20
TC 4
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5281
EP 5301
DI 10.1007/s11042-017-4431-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800009
DA 2024-07-18
ER

PT J
AU Plapous, C
   Berrani, SA
   Besset, B
   Rault, JB
AF Plapous, Cyril
   Berrani, Sid-Ahmed
   Besset, Benoit
   Rault, Jean-Bernard
TI A low-complexity audio fingerprinting technique for embedded
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio; Fingerprinting; Synchronization; Embedded; Social TV
AB This paper proposes a new optimized audio-based fingerprinting technology for embedded applications. The target use case is related to TV content synchronization and its numerous applications for Social TV and second screen applications. The proposed technology can be used for automatically identifying the program being watched by capturing the sound of the TV set. It can also be used to know which program is being watched and to precisely estimate the timestamp of the currently broadcast moment with respect to the beginning of the program. This is very useful for second screen applications where notifications (e.g. quizzes, additional information, commercials) have to be sent to viewers with a perfect synchronization relatively to the broadcast TV program. The robustness of the proposed technique is first evaluated on a large music database and then by considering a realistic use case where this technology is embedded in a smartphone.
C1 [Plapous, Cyril; Berrani, Sid-Ahmed; Besset, Benoit; Rault, Jean-Bernard] Orange Labs, 4 Rue Clos Courtel, Cesson Sevigne, France.
C3 Orange SA
RP Plapous, C (corresponding author), Orange Labs, 4 Rue Clos Courtel, Cesson Sevigne, France.
EM cyril.plapous@orange.com; sberrani@gmail.com; benoit.besset@orange.com;
   jeanbernard.rault@orange.com
CR Abduraman Alina Elma, 2013, International Conference on Computer Vision Theory and Applications (VISAPP 2013). Proceedings, P701
   [Anonymous], 2003, PROCEDURE PERFORMANC
   Balado F, 2007, IEEE T INF FOREN SEC, V2, P254, DOI 10.1109/TIFS.2007.897258
   Baluja S, 2006, P C VIS MED PROD IET
   Bellettini Carlo, 2010, Journal of Communications, V5, P409, DOI 10.4304/jcm.5.5.409-424
   Betser M., 2007, Proc. of the 8th International Conference on Music Information Retrieval, P139
   Bisio I, 2015, IEEE T MOBILE COMPUT, V14, P14, DOI 10.1109/TMC.2013.79
   BURGES C, 2005, P IEEE INT C AC SPEE
   Cano P, 2005, J VLSI SIG PROC SYST, V41, P271, DOI 10.1007/s11265-005-4151-3
   Cano P., 2007, THESIS
   Covell M, 2009, P IEEE INT C AC SPEE
   Duong NQK, 2012, P IEEE INT C CONS EL
   Haitsma J, 2003, J NEW MUSIC RES, V32, P211, DOI 10.1076/jnmr.32.2.211.16746
   Haitsma J., 2001, International Workshop on Content-Based Multimedia Indexing, V4, P117
   Haitsma J., 2002, P ISMIR 2002 3 INT C, P107
   Liu Y, 2009, P IEEE INT C AC SPEE
   Park M, 2006, ETRI J, V28, P509, DOI 10.4218/etrij.06.0205.0135
   Wang A, 2005, MAGAZINE COMMUNICATI
   Xiao Q., 2011, Proceedings of the 12th International Society for Music Information Retrieval Conference, P133
NR 19
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5929
EP 5948
DI 10.1007/s11042-017-4505-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800036
DA 2024-07-18
ER

PT J
AU Saxena, AK
   Chaurasiya, VK
AF Saxena, Aditya K.
   Chaurasiya, Vijay K.
TI Multi-resolution texture analysis for fingerprint based age-group
   estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fingerprints; Multiresolution; Texture; Age-group estimation; Child
   identification; Gabor filters
ID PERFORMANCE
AB In this paper the possibility of using digital fingerprints to estimate age-groups of human being, particularly children is investigated. To our knowledge, age-group estimation in humans, using digital fingerprints have not been addressed formally. Age-group estimation can be applied in many areas like on-line child protection, access control and customized internet services etc. Motivated by the fact that human digital fingerprint vary in texture as the person ages, a multi-resolution texture approach for automatic age-group estimation has been presented in this paper. Three standard classifiers were used to judge the accuracy of the proposed method. In the process of this research study, a novel method for digital fingerprint reference point generation was developed, which provides reference point for very poor quality images also. The proposed reference point generation method is compared with core-point method using FG-NET DB1 dataset. Experimental results proves that a digital fingerprint can be used to identify age-groups, particularly children. A classification accuracy of 80 percent was achieved for children below the age of 14 by using the aforesaid method.
C1 [Saxena, Aditya K.; Chaurasiya, Vijay K.] Indian Inst Informat Technol, Allahabad, Uttar Pradesh, India.
C3 Indian Institute of Information Technology Allahabad
RP Saxena, AK (corresponding author), Indian Inst Informat Technol, Allahabad, Uttar Pradesh, India.
EM aksaxena.research@gmail.com; vijay.chaurasiya@gmail.com
RI Saxena, Aditya/HZH-9848-2023
OI Saxena, Aditya/0000-0002-8829-0529; Chaurasiya, Vijay
   Kumar/0000-0002-6146-7128
FU Government of India, Ministry of Human Resource Development, Department
   of Higher Education, Technical Section-II, New Delhi [25-2/2010-TS.II]
FX This work is supported by grant provided by Government of India,
   Ministry of Human Resource Development, Department of Higher Education,
   Technical Section-II, New Delhi (F.No. 25-2/2010-TS.II).
CR Abhyankar A, 2006, IEEE IMAGE PROC, P321, DOI 10.1109/ICIP.2006.313158
   [Anonymous], STEP RIGHT LET COMPU
   [Anonymous], 2010, Second Generation Biometrics
   [Anonymous], 2007, P IEEE 11 INT C COMP
   [Anonymous], 2018, P IEEE WORKSH APPL C
   Arulkumaran T., 2013, International Journal of Advanced Research in Electrical, Electronics and Instrumentation Engineering, V2, P1060
   Basavaraj Patil GV, HUMAN AGE ESTIMATION, V3, P478
   BERRY DS, 1986, PSYCHOL BULL, V100, P3, DOI 10.1037/0033-2909.100.1.3
   Ceyhan EB, 2014, 2014 13TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P478, DOI 10.1109/ICMLA.2014.83
   Chikkerur S, 2006, INT C PATT RECOG, P521
   Dibeklioglu H, 2012, LECT NOTES COMPUT SC, V7574, P525, DOI 10.1007/978-3-642-33712-3_38
   Dibekliolu H., 2012, MM'2012: Proceedings of the 20th ACM International Conference on Multimedia, P209
   Feng XG, 2002, CONF REC ASILOMAR C, P478
   Francis-Lothai F, 2014, 2014 IEEE CONFERENCE ON SYSTEMS, PROCESS AND CONTROL (ICSPC 2014), P132, DOI 10.1109/SPC.2014.7086244
   Fu Y, 2008, IEEE T MULTIMEDIA, V10, P578, DOI 10.1109/TMM.2008.921847
   Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36
   Gnanasivam P., 2012, International Journal of Biometrics and Bioinformatics (IJBB), V6, P58
   Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280
   Guo GD, 2009, IEEE I CONF COMP VIS, P1986, DOI 10.1109/ICCV.2009.5459438
   Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681
   Guodong Guo, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563041
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565
   Hong L., 1999, P SCAND C IM AN, V2, P665
   Hurley DJ, 2002, IMAGE VISION COMPUT, V20, P311, DOI 10.1016/S0262-8856(02)00003-3
   Jain AK, 1999, IEEE T PATTERN ANAL, V21, P348, DOI 10.1109/34.761265
   JAIN AK, 1990, 1990 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, P14, DOI [10.1109/ICSMC.1990.142050, 10.1016/0031-3203(91)90143-S]
   Joelsson S. R., 2006, SIGNAL IMAGE PROCESS, V978, P327
   Kamp KA, 1999, AM ANTIQUITY, V64, P309, DOI 10.2307/2694281
   Karu K, 1996, PATTERN RECOGN, V29, P389, DOI 10.1016/0031-3203(95)00106-9
   Khair N. M., 2012, Int. J. Biomed. Clin. Eng., V1, P86
   KIM HJ, 1995, COMPUT SECUR, V14, P205, DOI 10.1016/0167-4048(95)97054-E
   KOVESI P., 1999, SIGNAL, V4, P1
   KWON YH, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P762, DOI 10.1109/CVPR.1994.323894
   Lanitis A, 2004, IEEE T SYST MAN CY B, V34, P621, DOI 10.1109/TSMCB.2003.817091
   Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   LIN RS, 1989, J PROSTHET ORTHOT, V2, P1, DOI 10.1097/00008526-198900210-00001
   Lu JW, 2010, IEEE T INF FOREN SEC, V5, P761, DOI 10.1109/TIFS.2010.2069560
   Makihara Y., 2011, 2011 INT JOINT C BIO, P1, DOI 10.1109/IJCB.2011.6117531
   Maltoni D., 2009, HDB FINGERPRINT RECO
   Marasco E, 2014, P SPIE, V9075
   Moses K.R., 2011, SWGFAST-The Fingerprint Sourcebook, P1
   Pankanti S, 2002, IEEE T PATTERN ANAL, V24, P1010, DOI 10.1109/TPAMI.2002.1023799
   Patterson E., 2007, BTAS, P1, DOI 10.1109/BTAS.2007.4401953
   Popa G, 2010, ROM J LEG MED, V18, P149, DOI 10.4323/rjlm.2010.149
   Prasad S, 2012, INT J WAVELETS MULTI, V10, DOI 10.1142/S0219691312500464
   Ramanathan N, 2006, IEEE T IMAGE PROCESS, V15, P3349, DOI 10.1109/TIP.2006.881993
   Ricanek Jr K, 2005, P 2005 IEEE INT JOIN, V4
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Saxena A.K., 2014, ANNU IEEE IND CONF, P1
   Saxena AK, 2015, 2015 SECOND INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING AND COMMUNICATION ENGINEERING ICACCE 2015, P610, DOI 10.1109/ICACCE.2015.116
   Sgroi A., 2013, 2013 INT C BIOM ICB, P1
   Shen LL, 2006, PATTERN ANAL APPL, V9, P273, DOI 10.1007/s10044-006-0033-y
   Spiegl W., 2009, INTERSPEECH, P2923
   Stone A, 2010, AGING PROCESS FACE
   Suo J., 2008, Automatic Face and Gesture Recognition, P1
   Tam J, 2009, 2009 IEEE THIRD INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING (ICSC 2009), P33, DOI 10.1109/ICSC.2009.37
   Tan EL, 2012, ASIAPAC SIGN INFO PR
   Ueki K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P43
   Yazdi M., 2008, WORLD ACAD SCI ENG T, P313
NR 61
TC 2
Z9 4
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 6051
EP 6077
DI 10.1007/s11042-017-4516-1
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800042
DA 2024-07-18
ER

PT J
AU Xie, WC
   Shen, LL
   Yang, M
   Jiang, JM
AF Xie, Weicheng
   Shen, Linlin
   Yang, Meng
   Jiang, Jianmin
TI Facial expression synthesis with direction field preservation based mesh
   deformation and lighting fitting based wrinkle mapping
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Expression synthesis; Face correspondence; Mesh deformation; Wrinkle
   fitting
ID FRAMEWORK
AB Nowadays, facial expression synthesis is widely used in expression simulation, recognition and animation. While a variety of works available in literature are 3D based, these algorithms usually require face matching and trimming, are thus time consuming. In this work, an automatic algorithm for expression synthesis in 2D space is proposed, which mainly consists of three stages.The optimum matching of three sets of feature points on the faces of source neutral (F (s n) ), source expression (F (s e) ) and target neutral (F (t n) ) are obtained in the first stage. Different components on the target face are deformed by learning from not only the displacements but also the geometry shape of face F (s e) in the second stage. In the last stage, the details of the source expression are mapped onto the corresponding positions on the target face by fitting of the lighting differences. Experimental results on expression synthesis with large geometry deformation and lighting difference show that the proposed algorithm is able to accurately preserve the geometry deformation, and the synthesized expressions are visually realistic.
C1 [Xie, Weicheng; Shen, Linlin; Yang, Meng] Shenzhen Univ, Comp Vis Inst, Sch Comp Sci & Software Engn, Shenzhen, Peoples R China.
   [Jiang, Jianmin] Shenzhen Univ, Res Inst Future Media Comp, Sch Comp Sci & Software Engn, Shenzhen, Peoples R China.
C3 Shenzhen University; Shenzhen University
RP Shen, LL (corresponding author), Shenzhen Univ, Comp Vis Inst, Sch Comp Sci & Software Engn, Shenzhen, Peoples R China.
EM llshen@szu.edu.cn; jianmin.jiang@szu.edu.cn
RI Shen, Linlin/AEX-9392-2022; Yang, Michael Ying/AAC-6698-2019
OI Shen, Linlin/0000-0003-1420-0815; Yang, Michael Ying/0000-0002-0649-9987
FU Natural Science Foundation of China [61672357, 61602315, 61402289,
   61272050]; China Postdoctoral Science Foundation [2015M572363]; Science
   Foundation of Guangdong Province [2014A030313556, 2014A030313558]
FX The authors thank the anonymous reviewers for their helpful comments and
   suggestions. The work was supported by Natural Science Foundation of
   China under grand no. 61672357, 61602315, 61402289 and 61272050, China
   Postdoctoral Science Foundation under grant no. 2015M572363, the Science
   Foundation of Guangdong Province under grant no. 2014A030313556 and
   2014A030313558.
CR Al-Osaimi F, 2009, INT J COMPUT VISION, V81, P302, DOI 10.1007/s11263-008-0174-0
   Bando Y, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P166, DOI 10.1109/PCCGA.2002.1167852
   BEIER T, 1992, COMP GRAPH, V26, P35, DOI 10.1145/142920.134003
   Beymer D, 1993, THESIS
   Blanz V, 2003, COMPUT GRAPH FORUM, V22, P641, DOI 10.1111/1467-8659.t01-1-00712
   Debevec P., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P189, DOI 10.1145/280814.280864
   Gibbons JD, 2014, Nonparametric Statistical Inference
   Huang D, 2010, LECT NOTES COMPUT SC, V6312, P364, DOI 10.1007/978-3-642-15552-9_27
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954
   Larboulette C, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P522, DOI 10.1109/CGI.2004.1309258
   Li K, 2014, IEEE T MULTIMEDIA, V16, P299, DOI 10.1109/TMM.2013.2293064
   Liao J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629494
   Liu ZC, 2001, COMP GRAPH, P271
   Lu XG, 2008, IEEE T PATTERN ANAL, V30, P1346, DOI 10.1109/TPAMI.2007.70784
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Matthews I, 2007, INT J COMPUT VISION, V75, P93, DOI 10.1007/s11263-007-0043-2
   Pan G, 2010, PROC CVPR IEEE, P2614, DOI 10.1109/CVPR.2010.5539974
   Qian KL, 2014, COMPUT GRAPH-UK, V45, P64, DOI 10.1016/j.cag.2014.08.001
   Raouzaiou A, 2002, EURASIP J APPL SIG P, V2002, P1021, DOI 10.1155/S1110865702206149
   Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218
   Sanchez A, 2011, NEUROCOMPUTING, V74, P1272, DOI 10.1016/j.neucom.2010.07.017
   Seitz S. M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P21, DOI 10.1145/237170.237196
   Song ML, 2007, IEEE T MULTIMEDIA, V9, P1384, DOI 10.1109/TMM.2007.906591
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Tzimiropoulos G, 2013, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2013.79
   Vlasic D, 2005, ACM T GRAPHIC, V24, P426, DOI 10.1145/1073204.1073209
   Weise T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964972
   Weng YL, 2006, VISUAL COMPUT, V22, P653, DOI 10.1007/s00371-006-0054-y
   Xie WC, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P636, DOI 10.1109/CISP.2015.7407956
   Yu H, 2015, MULTIMED TOOLS APPL, V74, P9427, DOI 10.1007/s11042-014-2125-9
   Yuencheng Lee, 1995, Computer Graphics Proceedings. SIGGRAPH 95, P55
   Zhang QS, 2006, IEEE T VIS COMPUT GR, V12, P48, DOI 10.1109/TVCG.2006.9
   Zhang YH, 2014, J VIS COMMUN IMAGE R, V25, P916, DOI 10.1016/j.jvcir.2014.02.010
NR 34
TC 11
Z9 12
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7565
EP 7593
DI 10.1007/s11042-017-4661-6
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700052
DA 2024-07-18
ER

PT J
AU Dong, X
   Sun, JD
   Duan, PY
   Meng, LL
   Tan, YY
   Wan, WB
   Wu, HC
   Zhang, B
   Zhang, HX
AF Dong, Xiao
   Sun, Jiande
   Duan, Peiyong
   Meng, Lili
   Tan, Yanyan
   Wan, Wenbo
   Wu, Hongchen
   Zhang, Bin
   Zhang, Huaxiang
TI Semi-supervised modality-dependent cross-media retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-media retrieval; Subspace learning; Semantic information;
   Semi-supervised learning
ID REPRESENTATION
AB In this paper, we propose a modality-dependent cross-media retrieval approach under semi-supervised conditions. The approach utilizes both labeled samples and unlabeled ones to obtain two couples of projection matrices and uses feature distance to represent the semantic information of unlabeled samples in the optimization process, so as to fully utilize the data structural information. Different from supervised modality-dependent cross-media retrieval approaches which use labeled samples and fixed semantic information, the proposed approach makes full use of the global data distribution property and the semantic information of both labeled and unlabeled samples. Experiments on benchmark datasets show its superiority over the compared methods.
C1 [Dong, Xiao; Sun, Jiande; Duan, Peiyong; Meng, Lili; Tan, Yanyan; Wan, Wenbo; Wu, Hongchen; Zhang, Bin; Zhang, Huaxiang] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
   [Sun, Jiande; Meng, Lili; Tan, Yanyan; Wan, Wenbo; Wu, Hongchen; Zhang, Huaxiang] Shandong Normal Univ, Inst Data Sci & Technol, Jinan 250014, Shandong, Peoples R China.
C3 Shandong Normal University; Shandong Normal University
RP Sun, JD; Zhang, HX (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.; Sun, JD; Zhang, HX (corresponding author), Shandong Normal Univ, Inst Data Sci & Technol, Jinan 250014, Shandong, Peoples R China.
EM jiandesun@hotmail.com; huaxzhang@163.com
RI meng, li/GVT-2063-2022; meng, li/HTQ-7341-2023; Zhang, Bin/IWU-4448-2023
OI Zhang, Bin/0000-0001-9214-1588; Dong, Xiao/0000-0001-9519-612X
FU National Natural Science Foundation of China [61373081, 61572298,
   61772322]; Key Research and Development Foundation of Shandong Province
   [2016GGX101009]; Natural Science Foundation of Shandong China
   [ZR2016FB12, ZR2014FM012, ZR2015PF006]; NVIDIA Corporation
FX The work is partially supported by the National Natural Science
   Foundation of China (Nos. 61373081, 61572298, 61772322), the Key
   Research and Development Foundation of Shandong Province (No.
   2016GGX101009) and the Natural Science Foundation of Shandong China
   (Nos. ZR2016FB12, ZR2014FM012, ZR2015PF006). We also gratefully
   acknowledge the support of NVIDIA Corporation with the donation of the
   TITAN X GPU used for this research.
CR Andrew G., 2013, P ICML, P1247
   [Anonymous], 2012, P INT C NEUR INF PRO
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang XJ, 2014, AAAI CONF ARTIF INTE, P1171
   Chua T-S, 2009, ACM INTERNATIONAL CO, V48
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Ke Y, 2004, PROC CVPR IEEE, P506
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Ranjan V, 2015, IEEE I CONF COMP VIS, P4094, DOI 10.1109/ICCV.2015.466
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Rasiwasia N, 2014, JMLR WORKSH CONF PRO, V33, P823
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Sharma A, 2011, PROC CVPR IEEE, P593, DOI 10.1109/CVPR.2011.5995350
   Wei YC, 2017, IEEE T CYBERNETICS, V47, P449, DOI 10.1109/TCYB.2016.2519449
   Wei YC, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2775109
   Wu F., 2013, P ACM INT C MULT, P877
   Wu F, 2006, IEEE IMAGE PROC, P1465, DOI 10.1109/ICIP.2006.312707
   Yan F, 2015, PROC CVPR IEEE, P3441, DOI 10.1109/CVPR.2015.7298966
   Zhai XH, 2014, IEEE T CIRC SYST VID, V24, P965, DOI 10.1109/TCSVT.2013.2276704
   Zhai XH, 2013, MULTIMEDIA SYST, V19, P395, DOI 10.1007/s00530-012-0297-6
   Zhang HX, 2014, PATTERN RECOGN, V47, P3168, DOI 10.1016/j.patcog.2014.04.004
   Zhang HX, 2010, FUZZY SET SYST, V161, P1790, DOI 10.1016/j.fss.2009.11.013
   Zhang HX, 2010, APPL SOFT COMPUT, V10, P490, DOI 10.1016/j.asoc.2009.08.017
   Zhang HX, 2009, KNOWL-BASED SYST, V22, P477, DOI 10.1016/j.knosys.2009.06.009
NR 26
TC 13
Z9 13
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3579
EP 3595
DI 10.1007/s11042-017-5164-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600037
DA 2024-07-18
ER

PT J
AU Jiang, B
   Meng, HQ
   Ma, XL
   Wang, L
   Zhou, Y
   Xu, PF
   Jiang, SY
   Meng, XJ
AF Jiang, Bo
   Meng, Hongqi
   Ma, Xiaolei
   Wang, Lin
   Zhou, Yan
   Xu, Pengfei
   Jiang, Siyu
   Meng, Xianjia
TI Nighttime image Dehazing with modified models of color transfer and
   guided image filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Nighttime image; Image dehazing; Color transfer; Guided image filtering
AB Taking into account of the illumination characteristics of nighttime imaging, a new method for nighttime image dehazing is proposed in this paper. In the first place, based on the color transfer theory, the illumination level of nighttime hazy image can be artificially enhanced through flexibly selecting the reference image. In contrast to the classical model of color transfer with the strategy of overall to overall transfer, the modified model focuses on the different characteristics of various regions in the original image, and it works well even though the nighttime image is interfered by various artificial light sources. In the second place, the enhancement dehazing method based on the theory of guided image filtering is adopted since the key parameters of dehazing method using the atmospheric degradation model are difficult to obtain in the conditions of nighttime imaging. In addition, the key model parameters of guided image filter are selected according to the boundary information of original image rather than the original image itself, which makes it more advantageous for dehazing image taken on the hazy night. The experimental results show that the proposed method has better performance than the classical daytime dehazing methods. Additionally, our method exhibits superior effect compared to the well-known nighttime dehazing method in the aspects of suppressing color distortion and background illumination controlling. The evaluations of the experimental results are established on both the subjective and objective aspects, so the conclusion in this paper is more convincing.
C1 [Jiang, Bo; Meng, Hongqi; Wang, Lin; Zhou, Yan; Xu, Pengfei; Meng, Xianjia] Northwest Univ, Sch Informat & Technol, Xian 710127, Shaanxi, Peoples R China.
   [Ma, Xiaolei] Emory Univ, Dept Phys, Atlanta, GA 30322 USA.
   [Jiang, Siyu] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Shaanxi, Peoples R China.
C3 Northwest University Xi'an; Emory University; Xi'an Jiaotong University
RP Meng, XJ (corresponding author), Northwest Univ, Sch Informat & Technol, Xian 710127, Shaanxi, Peoples R China.
EM xianjiam@nwu.edu.cn
RI Jiang, siyu/KJK-9483-2024; Zhou, Yan/AFN-5099-2022
FU National Natural Science Foundation of China [41601353, 61503300,
   61502387]; Foundation of Key Laboratory of Space Active Opto-Electronics
   Technology of Chinese Academy of Sciences [AOE-2016-A02]; Scientific
   Research Program - Shaanxi Provincial Education Department [16JK1765];
   Foundation of State Key Laboratory of Transient Optics and Photonics,
   Chinese Academy of Sciences [SKLST201614]; Science Basic Research Plan
   in Shaanxi Province of China [2017JQ4003]
FX This work was supported by National Natural Science Foundation of China
   (No. 41601353, 61503300 and 61502387), and Foundation of Key Laboratory
   of Space Active Opto-Electronics Technology of Chinese Academy of
   Sciences (No. AOE-2016-A02), and Scientific Research Program Funded by
   Shaanxi Provincial Education Department (No. 16JK1765), and Foundation
   of State Key Laboratory of Transient Optics and Photonics, Chinese
   Academy of Sciences (No. SKLST201614), and Natural Science Basic
   Research Plan in Shaanxi Province of China (No. 2017JQ4003).
CR Bui TM, 2014, ELECTRON LETT, V50, P516, DOI 10.1049/el.2013.3652
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chen BH, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2710024
   Cheng FC, 2012, ELECTRON LETT, V48, P1404, DOI 10.1049/el.2012.2737
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Huang SC, 2015, IEEE T IND ELECTRON, V62, P2962, DOI 10.1109/TIE.2014.2364798
   Jiang B, 2016, MATH PROBL ENG, V2016, P1
   Jiang B, 2015, INT CONF SOFTW ENG, P280, DOI 10.1109/ICSESS.2015.7339055
   Kou F, 2015, IEEE T IMAGE PROCESS, V24, P4528, DOI 10.1109/TIP.2015.2468183
   Li Y, 2015, IEEE I CONF COMP VIS, P226, DOI 10.1109/ICCV.2015.34
   Li ZG, 2015, IEEE T IMAGE PROCESS, V24, P120, DOI 10.1109/TIP.2014.2371234
   Lu HM, 2016, MULTIMED TOOLS APPL, V75, P17081, DOI 10.1007/s11042-015-2977-7
   Luo MN, 2018, IEEE T CYBERNETICS, V48, P648, DOI 10.1109/TCYB.2017.2647904
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Pei SC, 2012, IEEE IMAGE PROC, P957, DOI 10.1109/ICIP.2012.6467020
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Shi ZH, 2016, MULTIMED TOOLS APPL, V75, P12245, DOI 10.1007/s11042-016-3421-3
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Zheng X, 2016, MULTIMED TOOLS APPL, V75, P8719, DOI 10.1007/s11042-015-2788-x
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 22
TC 17
Z9 20
U1 1
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3125
EP 3141
DI 10.1007/s11042-017-4954-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600012
DA 2024-07-18
ER

PT J
AU Jun, D
   Kim, HY
AF Jun, Dongsan
   Kim, Hui Yong
TI Low complexity based ultra-high quality video compression method for
   multimedia-centric internet of things (IoT) services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; HEVC; Fast encoding; Complexity reduction; Real-time
   multimedia computing
ID IMPLEMENTATION
AB Internet of things (IoT) enables a number of embedded systems to interact for the purpose of various IoT applications such as home security, medical, smart surveillance, and etc. It is expected that the need of multimedia computing for ultra-high quality video delivery has further increased the importance of fast and complexity-awareness video compression algorithm under low-complexity and low-power IoT systems. High efficiency video coding (HEVC) is the state-of-the-art video coding technology that can provide powerful video compression performance under limited bandwidth conditions for transmission or storage. Although HEVC adopted newly advanced video coding tools to achieve a bitrate reduction of 50% with similar video quality compared to the previous method, H.264/AVC, these cause heavy computational encoding complexity resulting from inter prediction process of HEVC encoder. In this paper, we propose a complexity scalable SKIP/MERGE encoding algorithm to design a low complexity inter prediction. Experimental results show that the proposed method is much faster than those of HEVC test model (47.42%) and previous method (13.95%) in terms of total encoding time, on average.
C1 [Jun, Dongsan; Kim, Hui Yong] ETRI, Broadcasting & Media Res Lab, Daejeon, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI)
RP Jun, D (corresponding author), ETRI, Broadcasting & Media Res Lab, Daejeon, South Korea.
EM dschun@etri.re.kr
RI Kim, Hui Yong/AAK-9197-2020
OI Kim, Hui Yong/0000-0001-7308-133X
FU Institute for Information AMP; communications Technology Promotion(IITP)
   grant - Korea government(MSIP) [2016-0-00572]
FX This work was supported by Institute for Information & communications
   Technology Promotion(IITP) grant funded by the Korea government(MSIP)
   (2016-0-00572, Development and Standardization of 5th Generation
   Video/Audio Coding Technology for Ultra High Quality Media Services).
CR [Anonymous], 2001, Q6SG16 ITUT
   [Anonymous], INT J NETW MANAG
   [Anonymous], 1449610 ITUT ISOIEC
   [Anonymous], 2015, 230082 ITUT ISOIEC
   Bossen F, 2013, SG16WP3 JCTVC ITUT
   Bossen F, 2012, IEEE T CIRC SYST VID, V22, P1685, DOI 10.1109/TCSVT.2012.2221255
   Choi K, 2011, SG16WP3 JCTVC ITUT
   Corrêa G, 2012, IEEE T CIRC SYST VID, V22, P1899, DOI 10.1109/TCSVT.2012.2223411
   Gweon R, 2011, SG16WP3 JCTVC ITUT
   ITU-T, 2012, ITU-T Y.2060-Overview of the Internet of Things
   Jun D, 2017, J SUPERCOMPUT, V73, P940, DOI 10.1007/s11227-016-1807-7
   Kim IK, 2014, SG16WP3 JCTVC ITUT
   Kokkonis G, 2016, J SUPERCOMPUT, P1
   Kokkonis G, 2016, J REAL-TIME IMAGE PR, V12, P343, DOI 10.1007/s11554-015-0505-7
   Laroche G, 2012, SG16WP3 JCTVC ITUT
   Lee A, 2016, J REAL-TIME IMAGE PR, V12, P433, DOI 10.1007/s11554-015-0493-7
   Lee A, 2014, ETRI J, V36, P527, DOI 10.4218/etrij.14.0113.0087
   Lee JH, 2016, IET IMAGE PROCESS, V10, P53, DOI 10.1049/iet-ipr.2013.0631
   Memos Vasileios A., 2015, J REAL TIME IMAGE PR
   [Online] European Broadcast Union, 2013, EBU UHD 1 TEST SET
   Psannis K, 2015, J REAL TIME IMAGE PR
   Stergiou C., 2016, FUTUR GENER COMPUT S
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Yang J, 2011, SG16WP3 JCTVC ITUT
   Zhao L, 2011, SG16WP3 JCTVC ITUT
NR 26
TC 3
Z9 3
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4661
EP 4675
DI 10.1007/s11042-017-4850-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500034
DA 2024-07-18
ER

PT J
AU Li, JZ
   Yu, CY
   Gupta, BB
   Ren, XC
AF Li, Jianzhong
   Yu, Chuying
   Gupta, B. B.
   Ren, Xuechang
TI Color image watermarking scheme based on quaternion Hadamard transform
   and Schur decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image watermarking; Quaternion Hadamard transform; Schur
   decomposition; Quaternion Zernike moment; Geometric correction
ID ARM DEVICES; RECOGNITION; FIRMWARE; MOMENTS; DOMAIN
AB Based on quaternion Hadamard transform (QHT) and Schur decomposition, a novel color image watermarking scheme is presented. To consider the correlation between different color channels and the significant color information, a new color image processing tool termed as the quaternion Hadamard transform is proposed. Then an efficient method is designed to calculate the QHT of a color image which is represented by quaternion algebra, and the QHT is analyzed for color image watermarking subsequently. With QHT, the host color image is processed in a holistic manner. By use of Schur decomposition, the watermark is embedded into the host color image by modifying the Q matrix. To make the watermarking scheme resistant to geometric attacks, a geometric distortion detection method based upon quaternion Zernike moment is introduced. Thus, all the watermark embedding, the watermark extraction and the geometric distortion parameter estimation employ the color image holistically in the proposed watermarking scheme. By using the detection method, the watermark can be extracted from the geometric distorted color images. Experimental results show that the proposed color image watermarking is not only invisible but also robust against a wide variety of attacks, especially for color attacks and geometric distortions.
C1 [Li, Jianzhong] Hanshan Normal Univ, Coll Math & Stat, Chaozhou, Peoples R China.
   [Yu, Chuying] Hanshan Normal Univ, Sch Phys & Elect Engn, Chaozhou, Peoples R China.
   [Gupta, B. B.] Natl Inst Technol Kurukshetra, Kurukshetra, Haryana, India.
   [Ren, Xuechang] Xiamen Univ, Dept Phys & Mech & Elect Engn, Xiamen, Peoples R China.
C3 Hanshan Normal University; Hanshan Normal University; National Institute
   of Technology (NIT System); National Institute of Technology
   Kurukshetra; Xiamen University
RP Li, JZ (corresponding author), Hanshan Normal Univ, Coll Math & Stat, Chaozhou, Peoples R China.
EM henry_stu@163.com; chyyu@hstc.edu.cn; gupta.brij@gmail.com;
   xuechangren@xmu.edu.cn
RI Gupta, Brij B/E-9813-2011
OI Gupta, Brij B/0000-0003-4929-4698
FU Natural Science Foundation of Guangdong Province [2014A030310038];
   Educational Commission of Guangdong Province [2013KJCX0127,
   2015KTSCX089]; Fundamental Research Funds for the Central Universities
   [20720160016]
FX This work is partly supported by the Natural Science Foundation of
   Guangdong Province (No. 2014A030310038), the Educational Commission of
   Guangdong Province (No. 2013KJCX0127, No. 2015KTSCX089) and the
   Fundamental Research Funds for the Central Universities (No.
   20720160016).
CR Alsmirat MA, 2017, MULTIMED TOOLS APPL, V76, P3537, DOI 10.1007/s11042-016-3884-2
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Benhocine A, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P969, DOI 10.1109/IIH-MSP.2008.134
   Chen BJ, 2012, SIGNAL PROCESS, V92, P308, DOI 10.1016/j.sigpro.2011.07.018
   Cox IJ, 2002, EURASIP J APPL SIG P, V2002, P126, DOI 10.1155/S1110865702000525
   Fakhari P, 2011, DIGIT SIGNAL PROCESS, V21, P433, DOI 10.1016/j.dsp.2011.01.014
   Fanzhi Kong, 2010, 2010 2nd International Conference on Industrial and Information Systems (IIS 2010), P464, DOI 10.1109/INDUSIS.2010.5565754
   Findik O, 2011, EXPERT SYST APPL, V38, P1942, DOI 10.1016/j.eswa.2010.07.126
   Gunjal Baisa L., 2011, International Journal of Computer Science, Engineering and Information Technology (IJCSEIT), V1, P36
   Karybali IG, 2006, IEEE T INF FOREN SEC, V1, P256, DOI 10.1109/TIFS.2006.873652
   Lai CC, 2011, OPT COMMUN, V284, P938, DOI 10.1016/j.optcom.2010.10.047
   Maity SP, 2011, INFORM SCIENCES, V181, P450, DOI 10.1016/j.ins.2010.09.029
   Memos VA, 2016, J REAL-TIME IMAGE PR, V12, P473, DOI 10.1007/s11554-015-0509-3
   Phadikar A, 2011, COMPUT ELECTR ENG, V37, P339, DOI 10.1016/j.compeleceng.2011.02.002
   Poljicak A, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3609010
   Psannis K, 2009, IEICE ELECTRON EXPR, V6, P1497, DOI [10.1587/elex.6.1497, 10.1587/elex.6.1437]
   Psannis KE, 2016, J REAL-TIME IMAGE PR, V12, P509, DOI 10.1007/s11554-015-0514-6
   Rajab L., 2015, J Softw Eng Appl, V08, P224, DOI [10.4236/jsea.2015.84023, DOI 10.4236/JSEA.2015.84023]
   Santhi V, 2013, J INF SECUR APPL, V18, P167, DOI 10.1016/j.istr.2013.01.001
   Shao ZH, 2015, OPT COMMUN, V343, P56, DOI 10.1016/j.optcom.2015.01.002
   Su QT, 2013, OPTIK, V124, P6255, DOI 10.1016/j.ijleo.2013.05.013
   Su QT, 2012, OPT COMMUN, V285, P1792, DOI 10.1016/j.optcom.2011.12.065
   Sun JF, 2010, PROG ENERG COMBUST, V36, P677, DOI 10.1016/j.pecs.2010.02.004
   Sun ZZ, 2018, IEEE T CIRC SYST VID, V28, P193, DOI 10.1109/TCSVT.2016.2605045
   Tsui TK, 2008, IEEE T INF FOREN SEC, V3, P16, DOI 10.1109/TIFS.2007.916275
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yan F, 2016, CHINESE J ELECTRON, V25, P832, DOI 10.1049/cje.2016.06.021
   Yang HY, 2014, OPTIK, V125, P4456, DOI 10.1016/j.ijleo.2014.02.028
   Zhu RJ, 2016, IEICE T INF SYST, VE99D, P351, DOI 10.1587/transinf.2015EDP7217
   Zhu RJ, 2016, DIGIT INVEST, V16, P19, DOI 10.1016/j.diin.2016.01.002
NR 30
TC 71
Z9 72
U1 3
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4545
EP 4561
DI 10.1007/s11042-017-4452-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500029
DA 2024-07-18
ER

PT J
AU Yang, M
   Liang, YZ
   Zhao, W
   Xu, W
   Zhu, J
   Qu, Q
AF Yang, Min
   Liang, Yuzhi
   Zhao, Wei
   Xu, Wei
   Zhu, Jia
   Qu, Qiang
TI Task-oriented keyphrase extraction from social media
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Keyphrase extraction; Weakly supervised learning; Topic model
AB Keyphrase extraction from social media is a crucial and challenging task. Previous studies usually focus on extracting keyphrases that provide the summary of a corpus. However, they do not take users' specific needs into consideration. In this paper, we propose a novel three-stage model to learn a keyphrase set that represents or related to a particular topic. Firstly, a phrase mining algorithm is applied to segment the documents into human-interpretable phrases. Secondly, we propose a weakly supervised model to extract candidate keyphrases, which uses a few pre-specific seed keyphrases to guide the model. The model consequently makes the extracted keyphrases more specific and related to the seed keyphrases (which reflect the user's needs). Finally, to further identify the implicitly related phrases, the PMI-IR algorithm is employed to obtain the synonyms of the extracted candidate keyphrases. We conducted experiments on two publicly available datasets from news and Twitter. The experimental results demonstrate that our approach outperforms the state-of-the-art baselines and has the potential to extract high-quality task-oriented keyphrases.
C1 [Yang, Min; Zhu, Jia] South China Normal Univ, Sch Comp Sci, Guangzhou, Guangdong, Peoples R China.
   [Yang, Min; Qu, Qiang] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
   [Liang, Yuzhi] Univ Hong Kong, Dept Comp Sci, Pok Fu Lam, Hong Kong, Peoples R China.
   [Zhao, Wei; Xu, Wei] Tencent, Shenzhen, Peoples R China.
C3 South China Normal University; Chinese Academy of Sciences; Shenzhen
   Institute of Advanced Technology, CAS; University of Hong Kong; Tencent
RP Zhu, J (corresponding author), South China Normal Univ, Sch Comp Sci, Guangzhou, Guangdong, Peoples R China.
EM jzhu@m.scnu.edu.cn
RI Qu, Qiang/IXD-9845-2023; Liang, Yuzhi/HGU-1971-2022
OI Qu, Qiang/0000-0001-5814-8460; Liang, Yuzhi/0000-0001-6868-1971; Zhu,
   Jia/0000-0002-5959-390X
CR [Anonymous], 2001, Mining the web for synonyms-PMI-IR versus LSA on TOEFL
   [Anonymous], 1957, STUDIES LINGUISTIC
   [Anonymous], 2009, P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC P 1 SIGMM WORKSH SOC
   [Anonymous], 2009, Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing
   Arora R., 2008, 08, P91, DOI DOI 10.1145/1390749.1390764
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Chen J, 2006, DIVERSE TOPIC PHRASE
   Chien LF, 1997, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/278459.258534
   El-Kishky A, 2014, PROC VLDB ENDOW, V8, P305, DOI 10.14778/2735508.2735519
   Feng XC, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P66
   Frank Eibe., 1999, Domain-specific keyphrase extraction
   Lafferty J., 2001, CONDITIONAL RANDOM F, V2001, P282
   Li Juanzi, 2007, Wuhan University Journal of Natural Sciences, V12, P917, DOI 10.1007/s11859-007-0038-4
   Lott B., 2012, SURVEY KEYWORD EXTRA
   Ma ZG, 2017, IEEE T MULTIMEDIA, V19, P1558, DOI 10.1109/TMM.2017.2659221
   Neto JL, 2000, DOCUMENT CLUSTERING
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Tu W., 2015, PACLIC
   Turney P. D., 2000, Information Retrieval, V2, P303, DOI 10.1023/A:1009976227802
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P417
   Yang M, 2014, TOPIC MODEL BUILDING, P421
   Yang M, 2014, 21 EUR C ART INT ECA
   Yang M, 2015, AAAI CONF ARTIF INTE, P2353
   Yang M, 2015, IFIP ADV INF COMM TE, V462, P61, DOI 10.1007/978-3-319-24123-4_4
   Yihong Gong, 2001, SIGIR Forum, P19
   Zhang C, 2008, J Comput Inf Syst, V4, P1169
   Zhu J, 2016, CLUSTER COMPUT, V19, P1309, DOI 10.1007/s10586-016-0586-5
   Zhu J, 2016, DATA MIN KNOWL DISC, V30, P550, DOI 10.1007/s10618-015-0428-8
   Zhu L, 2016, IEEE T CYBERNETICS, DOI [10.1109/TCYB.2016.25910680, DOI 10.1109/TCYB.2016.25910680]
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
NR 35
TC 8
Z9 8
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3171
EP 3187
DI 10.1007/s11042-017-5041-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600014
DA 2024-07-18
ER

PT J
AU Yu, CY
   Li, JZ
   Li, X
   Ren, XC
   Gupta, BB
AF Yu, Chuying
   Li, Jianzhong
   Li, Xuan
   Ren, Xuechang
   Gupta, B. B.
TI Four-image encryption scheme based on quaternion Fresnel transform,
   chaos and computer generated hologram
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Quaternion Fresnel transform; Computer generated
   hologram; Logistic-adjusted-Sine map
ID COLOR IMAGE ENCRYPTION; DOMAIN; ALGORITHM; EFFICIENT; SHIFT
AB A novel four-image encryption scheme based on the quaternion Fresnel transforms (QFST), computer generated hologram and the two-dimensional (2D) Logistic-adjusted-Sine map (LASM) is presented. To treat the four images in a holistic manner, two types of the quaternion Fresnel transform (QFST) are defined and the corresponding calculation method for a quaternion matrix is derived. In the proposed method, the four original images, which are represented by quaternion algebra, are processed holistically in a vector manner by using QFST first. Then the input complex amplitude, which is constructed by the components of the QFST-transformed plaintext images, is encoded by Fresnel transform with two virtual independent random phase masks (RPM). In order to avoid sending entire RPMs to the receiver side for decryption, the RPMs are generated by utilizing 2D-LASM, which results that the amount of the key data is reduced dramatically. Subsequently, by using Burch's method and the phase-shifting interferometry, the encrypted computer generated hologram is fabricated. To improve the security and weaken the correlation, the encrypted hologram is scrambled base on 2D-LASM. Experiments demonstrate the validity of the proposed image encryption technique.
C1 [Yu, Chuying] Hanshan Normal Univ, Sch Phys & Elect Engn, Chaozhou, Peoples R China.
   [Li, Jianzhong] Hanshan Normal Univ, Coll Math & Stat, Chaozhou, Peoples R China.
   [Li, Xuan] Fujian Normal Univ, Sch Software, Fuzhou, Fujian, Peoples R China.
   [Ren, Xuechang] Xiamen Univ, Dept Phys & Mech & Elect Engn, Xiamen, Peoples R China.
   [Gupta, B. B.] Natl Inst Technol Kurukshetra, Kurukshetra, Haryana, India.
C3 Hanshan Normal University; Hanshan Normal University; Fujian Normal
   University; Xiamen University; National Institute of Technology (NIT
   System); National Institute of Technology Kurukshetra
RP Li, JZ (corresponding author), Hanshan Normal Univ, Coll Math & Stat, Chaozhou, Peoples R China.
EM chyyu@hstc.edu.cn; henry_stu@163.com; jessieli24@163.com;
   xuechangren@xmu.edu.cn; gupta.brij@gmail.com
RI Gupta, Brij B/E-9813-2011
OI Gupta, Brij B/0000-0003-4929-4698; Li, Jianzhong/0000-0002-9580-206X;
   yu, chuying/0000-0002-1279-6910
FU Natural Science Foundation of Guangdong Province [2014A030310038];
   Educational Commission of Guangdong Province [2013KJCX0127,
   2015KTSCX089]; Fundamental Research Funds for the Central Universities
   [20720160016]; Science and Technology Planning Project of Chaozhou
   [2013G01]; Research Fund of Hanshan Normal University [LT201201]
FX This work is partly supported by the Natural Science Foundation of
   Guangdong Province (No. 2014A030310038), the Educational Commission of
   Guangdong Province (No. 2013KJCX0127, No. 2015KTSCX089), the Fundamental
   Research Funds for the Central Universities (No. 20720160016), the
   Science and Technology Planning Project of Chaozhou (No. 2013G01), and
   the Research Fund of Hanshan Normal University (No. LT201201).
CR Akhshani A, 2010, OPT COMMUN, V283, P3259, DOI 10.1016/j.optcom.2010.04.056
   Belazi A, 2017, OPT LASER ENG, V88, P37, DOI 10.1016/j.optlaseng.2016.07.010
   Cai LZ, 2003, OPT LETT, V28, P1808, DOI 10.1364/OL.28.001808
   Chen BJ, 2015, J MATH IMAGING VIS, V51, P124, DOI 10.1007/s10851-014-0511-6
   Ell TA, 2007, IEEE T IMAGE PROCESS, V16, P22, DOI 10.1109/TIP.2006.884955
   Fu ZJ, 2019, IEEE T SERV COMPUT, V12, P813, DOI 10.1109/TSC.2016.2622697
   Gonzalez R. C., 2007, DIGITAL IMAGE PROCES
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Li J, 2015, CHEM GEOL, V406, P10, DOI 10.1016/j.chemgeo.2015.04.010
   Li J, 2015, IEEE T COMPUT, V64, P425, DOI 10.1109/TC.2013.208
   Li J, 2014, IEEE T PARALL DISTR, V25, P1615, DOI 10.1109/TPDS.2013.284
   Liu Q, 2016, SECUR COMMUN NETW, V9, P4002, DOI 10.1002/sec.1582
   Liu ZJ, 2011, OPTIK, V122, P1010, DOI 10.1016/j.ijleo.2010.06.039
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Shao ZH, 2014, OPT EXPRESS, V22, P4932, DOI 10.1364/OE.22.004932
   Shen JJ, 2010, DIGIT SIGNAL PROCESS, V20, P1408, DOI 10.1016/j.dsp.2009.10.015
   Singh N, 2008, OPT LASER ENG, V46, P117, DOI 10.1016/j.optlaseng.2007.09.001
   Situ GH, 2004, OPT LETT, V29, P1584, DOI 10.1364/OL.29.001584
   Tudela R, 2003, J OPT A-PURE APPL OP, V5, pS189, DOI 10.1088/1464-4258/5/5/363
   Wang Q, 2013, OPT LASER TECHNOL, V48, P267, DOI 10.1016/j.optlastec.2012.10.037
   Wang Y, 2015, OPT COMMUN, V344, P147, DOI 10.1016/j.optcom.2015.01.045
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Xie EY, 2017, SIGNAL PROCESS, V132, P150, DOI 10.1016/j.sigpro.2016.10.002
   Yu ZL, 1984, COMPUTER GENERATED H
   Yuan S, 2012, OPT LASER TECHNOL, V44, P51, DOI 10.1016/j.optlastec.2011.05.015
   Zhang S, 2010, OPT EXPRESS, V18, P9684, DOI 10.1364/OE.18.009684
   Zheng YH, 2015, J INTELL FUZZY SYST, V28, P961, DOI 10.3233/IFS-141378
   Zhou ZL, 2016, IEICE T INF SYST, VE99D, P1531, DOI 10.1587/transinf.2015EDP7341
NR 28
TC 197
Z9 199
U1 3
U2 95
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4585
EP 4608
DI 10.1007/s11042-017-4637-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500031
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Ling, ZG
   Fan, GL
   Liang, Y
   Zuo, JY
AF Ling, Zhigang
   Fan, Guoliang
   Liang, Yan
   Zuo, Junyi
TI Joint optimization and perceptual boosting of global and local contrast
   for efficient contrast enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contrast enhancement; Joint optimization of local and global contrast;
   Perceptual contrast boosting; Just-noticeable difference; Adaptive
   parameter regularization
ID HISTOGRAM EQUALIZATION; IMAGE-ENHANCEMENT; MULTISCALE RETINEX
AB Contrast enhancement which aims to increase the contrast of an image with low dynamic range, has been widely studied and exploited. In spite of the great success of many contrast enhancement algorithms, they still have difficulty in achieving both global and local contrast enhancement so that some over-enhancement, under-enhancement or even halo artifacts are often produced in complex images. This paper proposes a simple but efficient contrast enhancement method which may achieve both global and local contrast enhancement and perceptually suppress the above-mentioned problems. A cost function integrating global enhancement with local contrast enhancement is firstly constructed to pose image enhancement as an optimization problem. Then, two key steps are involved in solving for an optimal solution, the just-noticeable difference (JND) model is introduced to perceptually determine maximum local gains and neighbouring gray-level difference for local and global contrast enhancement, respectively, and an adaptive parameter regularization method is invoked to further suppress over-enhancement and halo artifacts. The experimental results on many images both qualitatively and quantitatively demonstrate our algorithm can robustly provide better visual quality in global and local contrast compared to a selection of other well-known state-of-the-art algorithms.
C1 [Ling, Zhigang] Hunan Univ, Coll Elect & Informat Engn, Changsha, Hunan, Peoples R China.
   [Fan, Guoliang] Oklahoma State Univ, Sch Elect & Comp Engn, Stillwater, OK 74078 USA.
   [Liang, Yan] Northwestern Polytech Univ, Sch Automat, Xian, Shaanxi, Peoples R China.
   [Zuo, Junyi] Northwestern Polytech Univ, Sch Astronaut, Xian, Shaanxi, Peoples R China.
C3 Hunan University; Oklahoma State University System; Oklahoma State
   University - Stillwater; Northwestern Polytechnical University;
   Northwestern Polytechnical University
RP Ling, ZG (corresponding author), Hunan Univ, Coll Elect & Informat Engn, Changsha, Hunan, Peoples R China.
EM zgling_hunan@126.com; guoliang.fan@okstate.edu; liangyan@nwpu.edu.cn;
   zuojunyi@163.com
RI Liang, Yan/B-1093-2012
FU National Natural Science Foundation of China [61471166, 61473227,
   61374023]; Natural Science Foundation of Hunan Province (CN) [14JJ2052]
FX This work was supported by National Natural Science Foundation of China
   (Grant No. 61471166, 61473227 and 61374023) and Natural Science
   Foundation of Hunan Province (CN) (14JJ2052).
CR [Anonymous], 2012, Journal of Information Hiding and Multimedia Signal Processing
   Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   Celik T, 2012, IEEE T IMAGE PROCESS, V21, P145, DOI 10.1109/TIP.2011.2162419
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   Corchs S, 2011, LECT NOTES COMPUT SC, V6626, P125, DOI 10.1007/978-3-642-20404-3_10
   Fu XY, 2015, IEEE T IMAGE PROCESS, V24, P4965, DOI 10.1109/TIP.2015.2474701
   Ghimire D, 2011, IEEE T CONSUM ELECTR, V57, P858, DOI 10.1109/TCE.2011.5955233
   Gonzalez R. C., 2006, PEARSON ED INDIA, V3rd
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Ilie A, 2005, INT J PATTERN RECOGN, V19, P533, DOI 10.1142/S0218001405004137
   Jang JH, 2012, IEEE T IMAGE PROCESS, V21, P3479, DOI 10.1109/TIP.2012.2197014
   Jang S., 2010, 2010 INT S OPT TECHN, P1
   Jenifer S, 2016, APPL SOFT COMPUT, V42, P167, DOI 10.1016/j.asoc.2016.01.039
   Jia Z, 2011, IEEE INT CONF ROBOT
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Karel Z., 1994, CONTRAST LTD ADAPTIV
   Kim SE, 2016, SIGNAL PROCESS, V127, P1, DOI 10.1016/j.sigpro.2016.02.016
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Lee CH, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.3.033007
   Lee E, 2013, IEEE GEOSCI REMOTE S, V10, P62, DOI 10.1109/LGRS.2012.2192412
   Mila N, 2012, J MATH IMAGING VIS, V46, P309
   Mukhopadhyay J, 2008, IEEE IMAGE PROC, P3144, DOI 10.1109/ICIP.2008.4712462
   Nam YO, 2014, IEEE T IMAGE PROCESS, V23, P3308, DOI 10.1109/TIP.2014.2324288
   Pei S-C, 2012, IEEE SIGNAL PROCESSI, V19
   Polesel A, 2000, IEEE T IMAGE PROCESS, V9, P505, DOI 10.1109/83.826787
   Rahman ZU, 2004, J ELECTRON IMAGING, V13, P100, DOI 10.1117/1.1636183
   Raimondo S, 2010, J ELECTRON IMAGING, V19
   Rao YB, 2010, OPT ENG, V49, DOI 10.1117/1.3520553
   Rivera AR, 2012, IEEE T IMAGE PROCESS, V21, P3967, DOI 10.1109/TIP.2012.2198667
   Saibabu A, 2006, 35 IEEE APPL IM PATT
   Saruchi S., 2012, Int. J. Comput. Appl, V55, P45, DOI [DOI 10.5120/8747-2634, 10.5120/8747-2634]
   Shanmugavadivu P, 2014, OPT LASER TECHNOL, V57, P243, DOI 10.1016/j.optlastec.2013.07.013
   Tsai CM, 2013, APPL MATH INFORM SCI, V7, P2019, DOI 10.12785/amis/070542
   Turgay C, 2014, PATTERN RECOGN, V45, P3810
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Zhengguo L, 2005, IEEE T IMAGE PROCESS, V24, P120
   Zhetong L, 2016, IEEE T IMAGE PROCESS, V673-686, P25
   Zhou ZG, 2014, OPTIK, V125, P1795, DOI 10.1016/j.ijleo.2013.09.051
NR 41
TC 1
Z9 1
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2467
EP 2484
DI 10.1007/s11042-017-4428-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400041
DA 2024-07-18
ER

PT J
AU Mangalraj, P
   Agrawal, A
AF Mangalraj, P.
   Agrawal, Anupam
TI Novel approach on fusion of multisensor images based on neutrosophic
   domain in consideration of regional relevance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neutrosophic sets; Regional relevance; Indeterminancy
ID NONSUBSAMPLED CONTOURLET TRANSFORM; SEGMENTATION; ALGORITHM
AB The presented work describes the fusion of multisensor (Multispectral and Panchromatic) images in remote sensing domain. The fusion of multisensor remote sensing images which utilizes neutrosophic set is introduced. The proposed approach preserves the intrinsic structural information as well as bringing the complimentary information to the supplementary information in a right proportion. Novel regional based fusion rule is introduced in the proposed work. The indeterminacy in the input data is handled to provide a comprehensive fusion result, where the compared methods fails. The proposed approach is tested against the Multi-resolution Analysis(MRA) and Multi-Geometric Analysis based techniques quantitatively and qualitatively based on the metrics. The proposed approach provides promoting results against the compared methods in terms of quality and quantity is observed through experimental results.
C1 [Mangalraj, P.; Agrawal, Anupam] Indian Inst Informat Technol Allahabad, Allahabad, Uttar Pradesh, India.
C3 Indian Institute of Information Technology Allahabad
RP Mangalraj, P (corresponding author), Indian Inst Informat Technol Allahabad, Allahabad, Uttar Pradesh, India.
EM mangal86@gmail.com
RI poobalasubramanian, mangalraj/ABD-1203-2020
OI poobalasubramanian, mangalraj/0000-0001-5682-4912; Agrawal,
   Anupam/0000-0003-3392-5045
CR [Anonymous], 2002, INFORM FUSION, DOI DOI 10.1016/S1566-2535(01)00037-9
   AUFI LOGICS, 2002, FLORENTIN SMARANDACH
   Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Chen SH, 2008, SENSORS-BASEL, V8, P520, DOI 10.3390/s8010520
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Deng CZ, 2009, 2009 INTERNATIONAL CONFERENCE ON ENVIRONMENTAL SCIENCE AND INFORMATION APPLICATION TECHNOLOGY, VOL III, PROCEEDINGS,, P451, DOI 10.1109/ESIAT.2009.222
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Guo YH, 2014, COMPUT ELECTR ENG, V40, P3, DOI 10.1016/j.compeleceng.2014.04.020
   Guo YH, 2009, PATTERN RECOGN, V42, P587, DOI 10.1016/j.patcog.2008.10.002
   Hanbay K, 2014, APPL SOFT COMPUT, V21, P433, DOI 10.1016/j.asoc.2014.04.008
   Kong WW, 2014, INFRARED PHYS TECHN, V65, P103, DOI 10.1016/j.infrared.2014.04.003
   Lewis JJ, 2007, INFORM FUSION, V8, P119, DOI 10.1016/j.inffus.2005.09.006
   Li CL, 2010, INT CONF COMP SCI, P246, DOI 10.1109/ICCSIT.2010.5563771
   Li Z, 2008, 2008 ISPRS C, V7
   Lim WQ, 2010, IEEE T IMAGE PROCESS, V19, P1166, DOI 10.1109/TIP.2010.2041410
   Liu K, 2009, CHINESE J AERONAUT, V22, P75, DOI 10.1016/S1000-9361(08)60071-0
   Liu X, 2014, AEU-INT J ELECTRON C, V68, P471, DOI 10.1016/j.aeue.2013.12.003
   Lu H.M., 2010, J COMPUTATIONAL INFO, V6, P3997
   Mangalraj Anupam A, 2014, IEEE 2014 INT S SIGN
   Mangalraj P, 2015, PROCEDIA COMPUT SCI, V54, P713, DOI 10.1016/j.procs.2015.06.084
   Mangalraj P, 2015, 2015 IEEE INT C EL C, P1
   Miao QG, 2011, OPT COMMUN, V284, P1540, DOI 10.1016/j.optcom.2010.11.048
   Miao QG, 2006, INT C COMMUN CIRCUIT, P548
   Piella G., 2003, Information Fusion, V4, P259, DOI 10.1016/S1566-2535(03)00046-0
   PohlC VGJL, 1998, INT J REMOTE SENS
   Qu XB, 2007, INT C WAVEL ANAL PAT, P1797
   Rivieccio U, 2008, FUZZY SET SYST, V159, P1860, DOI 10.1016/j.fss.2007.11.011
   Sengur A, 2011, COMPUT VIS IMAGE UND, V115, P1134, DOI 10.1016/j.cviu.2011.04.001
   Shi C, 2013, NEUROCOMPUTING, V117, P47, DOI 10.1016/j.neucom.2012.10.025
   Smarandache F., 2005, A Unifying Field in Logics: Neutrosophic Probability, Set and Logic, V4th ed.
   Yang SY, 2010, INFORM FUSION, V11, P78, DOI 10.1016/j.inffus.2009.05.001
   [YANG XiaoHui 杨晓慧], 2008, [自动化学报, Acta Automatica Sinica], V34, P274
   Zhang M., 2010, NOVEL APPROACHES IMA
   Zhang M, 2010, SIGNAL PROCESS, V90, P1510, DOI 10.1016/j.sigpro.2009.10.021
NR 35
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 1843
EP 1860
DI 10.1007/s11042-017-4366-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400016
DA 2024-07-18
ER

PT J
AU Tian, NL
   Ling, BWK
   Qing, CM
   Yang, ZJ
AF Tian, Nili
   Ling, Bingo Wing-Kuen
   Qing, Chunmei
   Yang, Zhijing
TI Camera identification based on very low bit rate videos with overall
   noise pattern having time varying statistics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Very low bit rate videos; Overall noise patterns having time varying
   statistics; Video forensics; Camera identification; Statistic moments;
   Principal component analysis; Linear discriminant analysis; Null space
   approach; Pairwisely linear separable; Bank of perceptrons
ID WEB
AB This paper proposes a method for performing the camera identification based on very low bit rate videos with the overall noise patterns having time varying statistics. First, the overall noise pattern of each frame of each video is converted to a vector. Then, the odd order statistic moments of these vectors are computed. By performing the principal component analysis, only the most major component of each statistic moment vector is attained. These components of all the frames form a feature vector for each video. To minimize the intraclass separation and maximize the interclass separation, the linear discriminant analysis is performed. As many eigenvalues of the interclass separation matrix are close to zero, the column vectors which span the null spaces of the corresponding matrices are found and the feature vector of each video is projected to these columns and forms a new vector. It is found that these new vectors are pairwisely linear separable. Hence, a bank of perceptrons can be applied to perform the camera identification. Computer numerical simulations show that our proposed method significantly outperforms the conventional correlation based method and the conventional support vector machine based method.
C1 [Tian, Nili; Ling, Bingo Wing-Kuen] Guangdong Univ Technol, Fac Informat Engn, Guangzhou 510006, Guangdong, Peoples R China.
   [Qing, Chunmei] South China Univ Technol, Fac Informat Engn, Guangzhou 510641, Guangdong, Peoples R China.
   [Yang, Zhijing] Guangdong Univ Technol, Sch Informat Engn, Guangzhou 510006, Guangdong, Peoples R China.
C3 Guangdong University of Technology; South China University of
   Technology; Guangdong University of Technology
RP Ling, BWK (corresponding author), Guangdong Univ Technol, Fac Informat Engn, Guangzhou 510006, Guangdong, Peoples R China.
EM tian_ni_li@126.com; yongquanling@gdut.edu.cn; qchm@scut.edu.cn;
   yzhj@gdut.edu.cn
FU National Nature Science Foundation of China [61372173]; Guangdong Higher
   Education Engineering Technology Research Center for Big Data on
   Manufacturing Knowledge Patent [501130144]; Hundred People Plan from
   Guangdong University of Technology; Young Thousand People Plan from
   Ministry of Education of China
FX This work was supported partly by the National Nature Science Foundation
   of China (No. 61372173), the Guangdong Higher Education Engineering
   Technology Research Center for Big Data on Manufacturing Knowledge
   Patent (No. 501130144), the Hundred People Plan from the Guangdong
   University of Technology and the Young Thousand People Plan from the
   Ministry of Education of China.
CR Chen M., 2007, P SPIE
   Elizondo D, 2006, IEEE T NEURAL NETWOR, V17, P330, DOI 10.1109/TNN.2005.860871
   Villalba LJG, 2016, EXPERT SYST APPL, V55, P59, DOI 10.1016/j.eswa.2016.01.025
   Ho CYF, 2008, IEEE T NEURAL NETWOR, V19, P938, DOI 10.1109/TNN.2007.914187
   Kagaya M, 2011, IEEE T VIS COMPUT GR, V17, P74, DOI 10.1109/TVCG.2010.25
   Kumar N, 2008, IEEE TECHNOL SOC MAG, V27, P33, DOI 10.1109/MTS.2008.924869
   Kurosawa K., 1999, P 1999 INT C IM PROC, P537
   Lee PY, 2005, IEEE T MULTIMEDIA, V7, P1183, DOI 10.1109/TMM.2005.858414
   Lotte F, 2011, IEEE T BIO-MED ENG, V58, P355, DOI 10.1109/TBME.2010.2082539
   Pang YW, 2012, IEEE T SYST MAN CY B, V42, P458, DOI 10.1109/TSMCB.2011.2167750
   Remya RS, 2015, IEEE INT C ENG TECHN, P1
   Tang CY, 2011, IEEE T INF FOREN SEC, V6, P1038, DOI 10.1109/TIFS.2011.2157821
   van Houten W, 2010, LECT NOTES COMPUT SC, V6388, P22, DOI 10.1007/978-3-642-17711-8_3
   van Houten W, 2009, DIGIT INVEST, V6, P48, DOI 10.1016/j.diin.2009.05.003
   Weitzner DJ, 2007, IEEE INTERNET COMPUT, V11, P86, DOI 10.1109/MIC.2007.54
   Werner O, 1999, IEEE T IMAGE PROCESS, V8, P179, DOI 10.1109/83.743853
   Wiegand T, 1996, IEEE T CIRC SYST VID, V6, P182, DOI 10.1109/76.488825
   YAMAMURA K, 1992, IEEE T CIRCUITS-I, V39, P694, DOI 10.1109/81.168932
   Yin H, 2012, IEEE T MULTIMEDIA, V14, P178, DOI 10.1109/TMM.2011.2170556
NR 19
TC 0
Z9 0
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 1299
EP 1322
DI 10.1007/s11042-016-4323-0
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400054
DA 2024-07-18
ER

PT J
AU Cheng, KY
   Hui, KF
   Zhan, YZ
   Li, MZ
AF Cheng, Keyang
   Hui, Kaifa
   Zhan, Yongzhao
   Li, Maozhen
TI Sparse representations based distributed attribute learning for person
   re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Sparse representations; Attribute learning;
   Deep convolutional neural network; Distributed computation
ID RECOGNITION
AB Searching for specific persons from surveillance videos captured by different cameras, known as person re-identification, is a key yet under-addressed challenge. Difficulties arise from the large variations of human appearance in different poses, and from the different camera views that may be involved, making low-level descriptor representation unreliable. In this paper, we propose a novel Sparse Representations based Distributed Attribute Learning Model (SRDAL) to encode targets into semantic topics. Compared to other models such as ELF, our model performs best by imposing semantic restrictions onto the generation of human specific attributes and employing Deep Convolutional Neural Network to generate features without supervision for attributes learning model. Experimental results show that our method achieves state-of-the-art performance.
C1 [Cheng, Keyang; Hui, Kaifa; Zhan, Yongzhao] Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
   [Li, Maozhen] Brunel Univ, Sch Engn & Design, Uxbridge UB8 3PH, Middx, England.
C3 Jiangsu University; Brunel University
RP Cheng, KY (corresponding author), Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
EM kycheng@ujs.edu.cn
FU Natural Science Foundation of China [61602215, 61672268]; science
   foundation of Jiangsu province [BK20150527, BE2015137]; science
   foundation of Zhenjiang city [SH2014017]; scientific research funds for
   senior talents of Jiangsu University [15JDG180]; China State Scholarship
   Fund [201608320098]; International Postdoctoral Exchange Fellowship
   Program [201653]
FX This research is supported by the Natural Science Foundation of China
   No. 61602215, 61672268, the science foundation of Jiangsu province No.
   BK20150527, No. BE2015137, the science foundation of Zhenjiang city No.
   SH2014017, the scientific research funds for senior talents of Jiangsu
   University No. 15JDG180, China State Scholarship Fund No. 201608320098
   and International Postdoctoral Exchange Fellowship Program No.201653.
CR [Anonymous], 2007, P IEEE INT WORKSH PE
   [Anonymous], P HUM CENTR TECHN WO
   [Anonymous], 2013, INTEGRATED RECOGNITI
   [Anonymous], 2014, PROC IEEE C COMPUTER, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]
   [Anonymous], 2015, ARXIV150804186
   [Anonymous], 2009, Applications of Computer Vision (WACV), 2009 Workshop on
   Baraniuk R, 2008, CONSTR APPROX, V28, P253, DOI 10.1007/s00365-007-9003-x
   Bazzani L, 2013, COMPUT VIS IMAGE UND, V117, P130, DOI 10.1016/j.cviu.2012.10.008
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Chen XG, 2015, LECT NOTES COMPUT SC, V9008, P354, DOI 10.1007/978-3-319-16628-5_26
   Cheng KY, 2014, NEUROCOMPUTING, V145, P416, DOI 10.1016/j.neucom.2014.05.011
   Corrado G., 2012, P 25 INT C NEUR INF, P1223
   Dantcheva A, 2011, MULTIMED TOOLS APPL, V51, P739, DOI 10.1007/s11042-010-0635-7
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Ferrari V., 2007, P 20 INT C NEUR INF, P433
   Fu YW, 2012, LECT NOTES COMPUT SC, V7575, P530, DOI 10.1007/978-3-642-33765-9_38
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Gu L, 2013, 2013 IEEE 15TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS & 2013 IEEE INTERNATIONAL CONFERENCE ON EMBEDDED AND UBIQUITOUS COMPUTING (HPCC_EUC), P721, DOI 10.1109/HPCC.and.EUC.2013.106
   Jain AK, 2004, LECT NOTES COMPUT SC, V3072, P731
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar N, 2011, IEEE T PATTERN ANAL, V33, P1962, DOI 10.1109/TPAMI.2011.48
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Layne R., 2014, ATTRIBUTES BASED REI
   Layne R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.24
   Layne R, 2012, LECT NOTES COMPUT SC, V7583, P402, DOI 10.1007/978-3-642-33863-2_40
   Li A, 2014, PERSON REIDENTIFICAT
   Ma BP, 2012, LECT NOTES COMPUT SC, V7583, P413, DOI 10.1007/978-3-642-33863-2_41
   Miura K, 2015, COMPUT SCI, V37, P82
   Nortcliffe T, 2011, HOME OFFICE CTR APPL, V2
   Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257
   Ouyang WL, 2013, PROC CVPR IEEE, P3222, DOI 10.1109/CVPR.2013.414
   Prosser B., 2010, P BRIT MACH VIS C BM, DOI DOI 10.5244/C.24.21
   Rohrbach M, 2010, PROC CVPR IEEE, P910, DOI 10.1109/CVPR.2010.5540121
   Satta R, 2012, LECT NOTES COMPUT SC, V7583, P453, DOI 10.1007/978-3-642-33863-2_45
   Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465
   Siddiquie B, 2011, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.2011.5995329
   Singh Dilpreet, 2015, J Big Data, V2, P8
   Umeda T, 2016, ATTRIBUTE DISCOVERY
   Wang W, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P25, DOI 10.1145/2733373.2806232
   Williams D., 2007, Journal of Investigative Psychology and O ender Profiling, V4, P97
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yamaguchi K, 2012, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2012.6248101
   Yang AY, 2010, IEEE IMAGE PROC, P1849, DOI 10.1109/ICIP.2010.5651522
   Ye M, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P547, DOI 10.1145/2671188.2749347
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zheng WS, 2012, IEEE T PATTERN ANAL, V34, P762, DOI 10.1109/TPAMI.2011.164
NR 53
TC 7
Z9 7
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 25015
EP 25037
DI 10.1007/s11042-017-4967-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300025
DA 2024-07-18
ER

PT J
AU Mousheimish, R
   Taher, Y
   Zeitouni, K
   Dubus, M
AF Mousheimish, Raef
   Taher, Yehia
   Zeitouni, Karine
   Dubus, Michel
TI Smart preserving of cultural heritage with PACT-ART
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cultural heritage; Prediction; Complex event processing; Early
   classification on time series; Context-awareness
ID MULTIMEDIA
AB Preserving cultural heritage is one of the most intricate jobs that need to be performed with a lot of caution. Transporting artworks on the other hand, i.e., getting them out of their home museums and exposing them in uncontrollable and dynamic environments, makes preservation even harder. So far, museums try to contend against the dynamic context during transportation by employing high-class transport cases. However, no attempts are made to exploit the science of data. In this paper, we make use of the ubiquity of sensors and IoT devices, combined with advanced predictive analytics in order to manage processes based on their context and to anticipate challenging run-time violations. Our approach is tested on real datasets and transport scenarios to prove its efficiency.
C1 [Mousheimish, Raef; Taher, Yehia; Zeitouni, Karine] Univ Versailles, David Lab, Paris Saclay, F-78000 Versailles, France.
   [Mousheimish, Raef] Fdn Sci Patrimoine, Labex PATRIMA, Versailles, France.
   [Dubus, Michel] C2RMF, F-75001 Paris, France.
C3 Universite Paris Saclay
RP Mousheimish, R (corresponding author), Univ Versailles, David Lab, Paris Saclay, F-78000 Versailles, France.; Mousheimish, R (corresponding author), Fdn Sci Patrimoine, Labex PATRIMA, Versailles, France.
EM raef.mousheimish@uvsq.fr; Yehia.Taher@uvsq.fr; Karine.Zeitouni@uvsq.fr;
   michel.dubus@culture.gouv.fr
RI Zeitouni, Karine/F-1871-2017
OI Zeitouni, Karine/0000-0002-5602-6942
CR Albanese M, 2011, IEEE INT C SEMANT CO, P403, DOI 10.1109/ICSC.2011.47
   Amato F, 2017, IEEE INT C SEMANT CO, P338, DOI 10.1109/ICSC.2017.59
   [Anonymous], 2013, INT C BUSINESS PROCE, DOI DOI 10.1007/978-3-319-06257-0
   [Anonymous], 2016, IDEAS, DOI DOI 10.1145/2938503.2938541
   [Anonymous], 2007, THEORIZING DIGITAL H
   [Anonymous], 2012, P 6 ACM INT C DISTRI
   [Anonymous], 2014, EMISA 2014
   [Anonymous], 2011, EVENT PROCESSING BUS
   Ardissono L, 2012, USER MODEL USER-ADAP, V22, P73, DOI 10.1007/s11257-011-9104-x
   Bampatzia S, 2016, LECT NOTES COMPUT SC, V10056, P331, DOI 10.1007/978-3-319-50182-6_30
   Bartolini I, 2016, MULTIMED TOOLS APPL, V75, P3813, DOI 10.1007/s11042-014-2062-7
   Baumgrass A., 2015, Proceedings of the BPM Demo Session 2015: Co-located with the 13th International Conference on Business Process Management (BPM 2015), P75
   Bulow S, 2014, P INT C BUS PROC MAN, P277, DOI DOI 10.1007/978-3-319-06257-0_22
   Cabanillas C, 2014, LECT NOTES COMPUT SC, V8659, P424, DOI 10.1007/978-3-319-10172-9_31
   Chianese A, 2017, FUTURE GENER COMP SY, V66, P187, DOI 10.1016/j.future.2016.04.015
   Chianese A, 2015, SMART INNOV SYST TEC, V40, P11, DOI 10.1007/978-3-319-19830-9_2
   Chianese A, 2015, J LOCAT BASED SERV, V9, P209, DOI 10.1080/17489725.2015.1099752
   Chianese A, 2014, 2014 EIGHTH INTERNATIONAL CONFERENCE ON NEXT GENERATION MOBILE APPS, SERVICES AND TECHNOLOGIES (NGMAST), P300, DOI 10.1109/NGMAST.2014.21
   Dim E, 2015, ACM T INTERACT INTEL, V4, DOI 10.1145/2662869
   Dumas Marlon, 2013, FUNDAMENTALS BUSINES, V1
   Engel Y., 2011, P 5 ACM INT C DISTRI
   Fu TC, 2011, ENG APPL ARTIF INTEL, V24, P164, DOI 10.1016/j.engappai.2010.09.007
   Ghalwash MF, 2013, IEEE DATA MINING, P201, DOI 10.1109/ICDM.2013.19
   Ghalwash MF, 2012, BMC BIOINFORMATICS, V13, DOI 10.1186/1471-2105-13-195
   Grana C, 2016, MULTIMED TOOLS APPL, V75, P3561, DOI 10.1007/s11042-016-3379-1
   He GL, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P1889, DOI 10.1145/2505515.2507888
   Herzberg N, 2013, IMPROVING PROCESS MO
   Herzberg N, 2013, INT C SERV OR COMP, P111
   Keller A., 2003, Journal of Network and Systems Management, V11, P57, DOI 10.1023/A:1022445108617
   Keogh E., 2006, The UCR Time Series Classification/Clustering Homepage
   Lee OJ, 2017, FUTURE GENER COMP SY, V66, P100, DOI 10.1016/j.future.2016.02.011
   Leitner Philipp, 2010, 2010 IEEE International Conference on Web Services (ICWS), P369, DOI 10.1109/ICWS.2010.21
   Lin YF, 2015, LECT NOTES ARTIF INT, V9077, P199, DOI 10.1007/978-3-319-18038-0_16
   Maggi FM, 2014, LECT NOTES COMPUT SC, V8484, P457, DOI 10.1007/978-3-319-07881-6_31
   Margara A, 2013, TECH REP
   Margara A., 2014, P 8 ACM INT C DISTRI, P47, DOI [DOI 10.1145/2611286.2611289, 10.1145/2611286.2611289]
   Metzke T, 2013, ICSOC WORKSH, P419
   Mousheimish R, 2017, P 11 ACM IN IN PRESS
   Mousheimish R., 2016, P 10 ACM INT C DISTR, P340
   Mousheimish R, 2016, LECT NOTES COMPUT SC, V9936, P586, DOI 10.1007/978-3-319-46295-0_38
   Mutschler C., 2012, Proceedings of the 2012 NASA/ESA Conference on Adaptive Hardware and Systems (AHS 2012), P159, DOI 10.1109/AHS.2012.6268645
   Piccialli F., 2017, MOB NETW APPL, V22, P1
   Sen S., 2010, P 4 ACM INT C DISTR, P196, DOI DOI 10.1145/1827418.1827459
   Siotto E, 2015, 2015 DIGITAL HERITAGE INTERNATIONAL CONGRESS, VOL 1: DIGITIZATION & ACQUISITION, COMPUTER GRAPHICS & INTERACTION, P239, DOI 10.1109/DigitalHeritage.2015.7413877
   Turchin Y., 2009, Proceedings of the Third ACM International Conference on Distributed Event-Based Systems, P10
   Xing Z., 2008, P 2008 SIAM INT C DA, P644
   Xing Z., 2011, Proceedings of SDM, P247
   Xing ZZ, 2012, KNOWL INF SYST, V31, P105, DOI 10.1007/s10115-011-0400-x
   Xing ZZ, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1297
   Ye LX, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P947
NR 50
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26077
EP 26101
DI 10.1007/s11042-017-4900-x
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500027
DA 2024-07-18
ER

PT J
AU Song, XF
   Liu, FL
   Zhang, ZG
   Yang, CF
   Luo, XY
   Chen, LJ
AF Song, Xiaofeng
   Liu, Fenlin
   Zhang, Zhengui
   Yang, Chunfang
   Luo, Xiangyang
   Chen, Liju
TI 2D Gabor filters-based steganalysis of content-adaptive JPEG
   steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganalysis; Content-adaptive; JPEG steganography; Gabor filter
ID IMAGE STEGANALYSIS; PALMPRINT RECOGNITION; FEATURES; FACE; DCT;
   CLASSIFICATION; MODEL
AB To improve the detection accuracy for content-adaptive JPEG steganography, which often constrains the embedding changes to complex texture regions, a new steganalysis feature called the GRF (Gabor Rich Feature) based on two-dimensional (2D) Gabor filters is proposed. First, the diverse 2D Gabor filters are generated and used to filter the decompressed JPEG image. Second, five types of statistical features are extracted from the filtered images and these features are merged according to their respective symmetry. Third, all the features are combined and feature selection is performed to reduce dimensionality. Last, an ensemble classifier is used to assemble the steganalysis feature as well as the final steganalyzer. The experimental results show that the proposed steganalysis feature can achieve a performance that is competitive with the state-of-the-art steganalysis features when used for the detection of the latest content-adaptive JPEG steganography algorithms.
C1 [Song, Xiaofeng; Liu, Fenlin; Yang, Chunfang; Luo, Xiangyang] Zhengzhou Sci & Technol Inst, Zhengzhou 450002, Henan, Peoples R China.
   [Song, Xiaofeng; Liu, Fenlin; Yang, Chunfang; Luo, Xiangyang] State Key Lab Math Engn & Adv Comp, Zhengzhou 450002, Henan, Peoples R China.
   [Song, Xiaofeng; Chen, Liju] Xian Commun Inst, Xian 710106, Shaanxi, Peoples R China.
   [Zhang, Zhengui] Xian Univ Posts & Telecommun, Sch Foreign Languages, Xian 710121, Shaanxi, Peoples R China.
C3 PLA Information Engineering University; PLA Information Engineering
   University; Xi'an University of Posts & Telecommunications
RP Song, XF (corresponding author), Zhengzhou Sci & Technol Inst, Zhengzhou 450002, Henan, Peoples R China.; Song, XF (corresponding author), State Key Lab Math Engn & Adv Comp, Zhengzhou 450002, Henan, Peoples R China.; Song, XF (corresponding author), Xian Commun Inst, Xian 710106, Shaanxi, Peoples R China.
EM xiaofengsong@sina.com; fenlinliu@vip.sina.com; zhangzhengui99@163.com;
   chunfangyang@126.com; xiangyangluo@126.com; chenliju0801@sina.com
FU National Natural Science Foundation of China [61272489, 61379151,
   61302159, 61602508]; Excellent Youth Foundation of Henan Province of
   China [144100510001]; Natural Science Basic Research Plan in Shaanxi
   Province of China [2014JM2-6103]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61272489, 61379151, 61302159 and 61602508), the Excellent
   Youth Foundation of Henan Province of China (No. 144100510001) and the
   Natural Science Basic Research Plan in Shaanxi Province of China(No.
   2014JM2-6103).
CR [Anonymous], 2012, IEEE T INF FORENSICS, DOI DOI 10.1109/TIFS.2011.2175919
   [Anonymous], ACM WORKSH INF HID M
   [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   [Anonymous], 2011, P 13 INF HID C PRAG
   Chai ZH, 2014, IEEE T INF FOREN SEC, V9, P14, DOI 10.1109/TIFS.2013.2290064
   Chen CH, 2008, IEEE INT SYMP CIRC S, P3029, DOI 10.1109/ISCAS.2008.4542096
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Denemark T, 2014, IEEE INT WORKS INFOR, P48, DOI 10.1109/WIFS.2014.7084302
   Filler T, 2011, P SPIE EL IM MED WAT, VXIII, p0F1
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Fridrich J, 2005, MULTIMEDIA SYST, V11, P98, DOI 10.1007/s00530-005-0194-3
   Fridrich J, 2005, IEEE T SIGNAL PROCES, V53, P3923, DOI 10.1109/TSP.2005.855393
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Fridrich J, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P3
   Grigorescu SE, 2002, IEEE T IMAGE PROCESS, V11, P1160, DOI 10.1109/TIP.2002.804262
   Guo LJ, 2014, IEEE T INF FOREN SEC, V9, P814, DOI 10.1109/TIFS.2014.2312817
   Holub V, 2015, P SPIE EL IM MED WAT, VXVII, P1
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Holub V, 2015, IEEE T INF FOREN SEC, V10, P219, DOI 10.1109/TIFS.2014.2364918
   Holub V, 2013, IEEE T INF FOREN SEC, V8, P1996, DOI 10.1109/TIFS.2013.2286682
   Huang FJ, 2012, IEEE T INF FOREN SEC, V7, P1181, DOI 10.1109/TIFS.2012.2198213
   Idrissa M, 2002, PATTERN RECOGN LETT, V23, P1095, DOI 10.1016/S0167-8655(02)00056-9
   JONES JP, 1987, J NEUROPHYSIOL, V58, P1233, DOI 10.1152/jn.1987.58.6.1233
   Kim Y, 2007, LECT NOTES COMPUT SC, V4437, P314
   Kodovsky J, 2012, P SPIE EL IM MED WAT, VXIV
   Kodovsky J, 2011, MM&SEC 11: PROCEEDINGS OF THE 2011 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P69
   Kodovsky J, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P63
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   Leng L, 2014, NEUROCOMPUTING, V131, P377, DOI 10.1016/j.neucom.2013.10.005
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Li FY, 2016, IEEE T INF FOREN SEC, V11, P344, DOI 10.1109/TIFS.2015.2496910
   Li M, 2008, PATTERN RECOGN LETT, V29, P664, DOI 10.1016/j.patrec.2007.12.001
   Liu QC, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/383671
   Liu QZ, 2008, PATTERN RECOGN, V41, P56, DOI 10.1016/j.patcog.2007.06.005
   Liu QZ, 2011, MM&SEC 11: PROCEEDINGS OF THE 2011 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P77
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Luo XY, 2008, SIGNAL PROCESS, V88, P2138, DOI 10.1016/j.sigpro.2008.03.016
   Lyu SW, 2006, IEEE T INF FOREN SEC, V1, P111, DOI 10.1109/TIFS.2005.863485
   Pevny T, 2007, PROC SPIE, V6505, DOI 10.1117/12.696774
   Provos N, 2001, USENIX ASSOCIATION PROCEEDINGS OF THE 10TH USENIX SECURITY SYMPOSIUM, P323
   Sallee P, 2004, LECT NOTES COMPUT SC, V2939, P154
   Sallee P, 2005, INT J IMAGE GRAPH, V5, P167, DOI 10.1142/S0219467805001719
   Solanki K, 2007, LECT NOTES COMPUT SC, V4567, P16
   Song XF, 2015, MULTIMED TOOLS APPL, V74, P11045, DOI 10.1007/s11042-014-2217-6
   Sun ZN, 2009, IEEE T PATTERN ANAL, V31, P2211, DOI 10.1109/TPAMI.2008.240
   Wang C, 2012, INT CONF ACOUST SPEE, P1785, DOI 10.1109/ICASSP.2012.6288246
   Zong H, 2012, DIGIT INVEST, V9, P58, DOI 10.1016/j.diin.2012.02.003
NR 48
TC 17
Z9 22
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26391
EP 26419
DI 10.1007/s11042-016-4157-9
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500040
DA 2024-07-18
ER

PT J
AU Charrière, K
   Quellec, G
   Lamard, M
   Martiano, D
   Cazuguel, G
   Coatrieux, G
   Cochener, B
AF Charriere, Katia
   Quellec, Gwenole
   Lamard, Mathieu
   Martiano, David
   Cazuguel, Guy
   Coatrieux, Gouenou
   Cochener, Beatrice
TI Real-time analysis of cataract surgery videos using statistical models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multilevel statistical model; Surgical process model; Content based
   video retrieval; Markov models; Conditional Random Fields; Bayesian
   networks
ID RECOGNITION; CLASSIFICATION
AB The automatic analysis of the surgical process, from videos recorded during surgeries, could be very useful to surgeons, both for training and for acquiring new techniques. The training process could be optimized by automatically providing some targeted recommendations or warnings, similar to the expert surgeon's guidance. In this paper, we propose to reuse videos recorded and stored during cataract surgeries to perform the analysis. The proposed system allows to automatically recognize, in real time, what the surgeon is doing: what surgical phase or, more precisely, what surgical step he or she is performing. This recognition relies on the inference of a multilevel statistical model which uses 1) the conditional relations between levels of description (steps and phases) and 2) the temporal relations among steps and among phases. The model accepts two types of inputs: 1) the presence of surgical tools, manually provided by the surgeons, or 2) motion in videos, automatically analyzed through the Content Based Video retrieval (CBVR) paradigm. Different data-driven statistical models are evaluated in this paper. For this project, a dataset of 30 cataract surgery videos was collected at Brest University hospital. The system was evaluated in terms of area under the ROC curve. Promising results were obtained using either the presence of surgical tools (A (z) = 0.983) or motion analysis (A (z) = 0.759). The generality of the method allows to adapt it to other kinds of surgeries. The proposed solution could be used in a computer assisted surgery tool to support surgeons during the surgery.
C1 [Charriere, Katia; Cazuguel, Guy; Coatrieux, Gouenou] Inst Mines Telecom, F-29200 Brest, France.
   [Charriere, Katia; Cazuguel, Guy; Coatrieux, Gouenou] Telecom Bretagne, F-29200 Brest, France.
   [Charriere, Katia; Cazuguel, Guy; Coatrieux, Gouenou] UEB, F-29200 Brest, France.
   [Charriere, Katia; Cazuguel, Guy; Coatrieux, Gouenou] Dept ITI, F-29200 Brest, France.
   [Charriere, Katia; Quellec, Gwenole; Lamard, Mathieu; Martiano, David; Cazuguel, Guy; Coatrieux, Gouenou; Cochener, Beatrice] LaTIM INSERM UMR 1101, F-29200 Brest, France.
   [Lamard, Mathieu; Cochener, Beatrice] Univ Bretagne Occidentale, F-29200 Brest, France.
   [Cochener, Beatrice] CHRU Brest, Serv Ophtalmol, F-29200 Brest, France.
C3 IMT - Institut Mines-Telecom; IMT Atlantique; IMT - Institut
   Mines-Telecom; IMT Atlantique; Universite de Bretagne Occidentale;
   Institut National de la Sante et de la Recherche Medicale (Inserm);
   Universite de Bretagne Occidentale; CHU Brest; Universite de Bretagne
   Occidentale
RP Charrière, K (corresponding author), Inst Mines Telecom, F-29200 Brest, France.; Charrière, K (corresponding author), Telecom Bretagne, F-29200 Brest, France.; Charrière, K (corresponding author), UEB, F-29200 Brest, France.; Charrière, K (corresponding author), Dept ITI, F-29200 Brest, France.; Charrière, K (corresponding author), LaTIM INSERM UMR 1101, F-29200 Brest, France.
EM katia.charriere@telecom-bretagne.eu
RI Quellec, Gwenole/L-9946-2015
OI Quellec, Gwenole/0000-0003-1669-7140
FU Urban Community of Brest (Brest Metropole Oceane); "Institut
   Mines-Telecom"
FX The authors would like to thank the Urban Community of Brest (Brest
   Metropole Oceane) and the "Institut Mines-Telecom" for funding this
   project.
CR André B, 2012, IEEE T MED IMAGING, V31, P1276, DOI 10.1109/TMI.2012.2188301
   [Anonymous], 2009, BMVC 2009
   Cao Y, 2008, IEEE INT SYM MULTIM, P266, DOI 10.1109/ISM.2008.89
   Charriere K, 2016, 2016 14 INT WORKSH C, P1
   Charrière K, 2014, IEEE ENG MED BIO, P4647, DOI 10.1109/EMBC.2014.6944660
   Chattopadhyay T., 2008, IEEE REG 10 C, V11, P1
   Fine S, 1998, MACH LEARN, V32, P41, DOI 10.1023/A:1007469218079
   Forestieri G., 2015, INT J COMPUTER ASSIS, P1
   FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030
   Lafferty J., 2001, CONDITIONAL RANDOM F, V2001, P282
   Lalys F, 2012, IEEE T BIO-MED ENG, V59, P966, DOI 10.1109/TBME.2011.2181168
   Lalys F, 2013, INT J COMPUT ASS RAD, V8, P39, DOI 10.1007/s11548-012-0685-6
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Loukas C, 2016, INT J CARS, P1
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Padoy N, 2012, MED IMAGE ANAL, V16, P632, DOI 10.1016/j.media.2010.10.001
   Pearl J., 1998, Bayesian networks
   Quellec G, 2015, IEEE T MED IMAGING, V34, P877, DOI 10.1109/TMI.2014.2366726
   Quellec G, 2014, IEEE T MED IMAGING, V33, P2352, DOI 10.1109/TMI.2014.2340473
   Quellec G, 2014, IEEE ENG MED BIO, P122, DOI 10.1109/EMBC.2014.6943544
   Quellec G, 2014, MED IMAGE ANAL, V18, P579, DOI 10.1016/j.media.2014.02.007
   Roberts CM, 2006, COMPUT SECUR, V25, P18, DOI 10.1016/j.cose.2005.12.003
   Sha F, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P213
   Singh A, 2014, SURG INNOVATION
   Stanek SR, 2012, COMPUT METH PROG BIO, V108, P524, DOI 10.1016/j.cmpb.2011.04.003
   Tao LL, 2013, LECT NOTES COMPUT SC, V8151, P339, DOI 10.1007/978-3-642-40760-4_43
   Wen Yao, 2010, 2010 IEEE International Conference on RFID-Technology and Applications (RFID-TA), P128, DOI 10.1109/RFID-TA.2010.5529874
   Zappella L, 2013, MED IMAGE ANAL, V17, P732, DOI 10.1016/j.media.2013.04.007
NR 28
TC 30
Z9 32
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22473
EP 22491
DI 10.1007/s11042-017-4793-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200031
DA 2024-07-18
ER

PT J
AU Hu, M
   Ou, B
   Xiao, Y
AF Hu, Min
   Ou, Bo
   Xiao, Yi
TI Efficient image colorization based on seed pixel selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image colorization; Seed pixel selection; Manual input alleviation;
   High-quality
AB Colorization is a technique to automatically produce color components for monochrome images and videos based on a few input colors. Generally, image colorization is initialized from a number of seed pixels whose colors are specified by users, and then the colors are gradually prorogating to the monochrome surroundings under a given optimization constraint. So, the performance of colorization is highly dependent on the selection of seed pixels. However, little attention has been paid to the selection of seed pixels, and how to improve the effectiveness of manual input remains a challenging task. To address this, an improved colorization method using seed pixel selection is proposed to assist the users in determining which pixels are highly required to be colorized for a high-quality colorized image. Specifically, the gray-scale image is first divided into non-overlapped blocks, and then, for each block, two pixels that approximate the average luminance of block are selected as the seeds. After the seed pixels are colored by users, an optimization that minimizes the difference between the seeds and their adjacent pixels is employed to propagate the colors to the other pixels. The experimental results demonstrate that, for a given amount of inputs, the proposed method can achieve a higher PSNR than the conventional colorization methods.
C1 [Hu, Min; Ou, Bo; Xiao, Yi] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
C3 Hunan University
RP Ou, B (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
EM S141000875@hnu.edu.cn; oubo@hnu.edu.cn; yixiao_csee@hnu.edu.cn
RI OU, BO/L-2212-2013
OI Ou, Bo/0000-0001-6936-9955
FU National Science Foundation of China [61502160, 61502158, 61472131,
   61572182]; Science and Technology Key Projects of Hunan Province [2015
   TP1004]; Scientific Research Plan of Hunan Provincial Science and
   Technology Department of China [2014FJ4161]
FX This work is supported by the National Science Foundation of China (Nos.
   61502160, 61502158, 61472131, 61572182), the Science and Technology Key
   Projects of Hunan Province (2015 TP1004), and the Scientific Research
   Plan of Hunan Provincial Science and Technology Department of China
   (2014FJ4161).
CR Anagnostopoulos N, 2014, IEEE CONF IMAGING SY, P381, DOI 10.1109/IST.2014.6958509
   [Anonymous], SCARF SEMIAUTOMATIC
   [Anonymous], ACM T GRAPH
   [Anonymous], INT C EM TECHN TREND
   [Anonymous], BRAZ IAN S COMP GRAP
   [Anonymous], INT C IM PROC
   [Anonymous], 2008, ACM T GRAPH
   [Anonymous], INT C PATT REC
   [Anonymous], AAAI
   Bugeau A, 2014, IEEE T IMAGE PROCESS, V23, P298, DOI 10.1109/TIP.2013.2288929
   Bugeau A, 2012, INT C PATT RECOG, P3058
   Chaumont M, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1537, DOI 10.1109/ICME.2008.4607740
   Chen XW, 2016, IEEE T IMAGE PROCESS, V25, P1688, DOI 10.1109/TIP.2016.2523429
   Dang-en Xie, 2010, Proceedings 2010 International Conference on Computing, Control and Industrial Engineering (CCIE 2010), P166, DOI 10.1109/CCIE.2010.160
   Devi MS, 2012, NIRMA UNIV INT CONF
   Drew MS, 2008, IEEE IMAGE PROC, P457, DOI 10.1109/ICIP.2008.4711790
   Günel M, 2014, SIG PROCESS COMMUN, P285, DOI 10.1109/SIU.2014.6830221
   Heu JH, 2009, IEEE IMAGE PROC, P465, DOI 10.1109/ICIP.2009.5414371
   Jacob VG, 2009, IEEE IMAGE PROC, P1653, DOI 10.1109/ICIP.2009.5413392
   Kawulok M, 2010, IEEE IMAGE PROC, P405, DOI 10.1109/ICIP.2010.5653544
   Kim TH, 2009, IEEE IMAGE PROC, P1661, DOI 10.1109/ICIP.2009.5413394
   Kumar S, 2012, STUDENTSCONFERENCE E, P1
   Lee S, 2013, IEEE T IMAGE PROCESS, V22, P2627, DOI 10.1109/TIP.2013.2253486
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Liu XP, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409105
   Luan Q., 2007, P 18 EUR C CREND TEC, P309
   Nakajima Y, 2013, CONF REC ASILOMAR C, P1990, DOI 10.1109/ACSSC.2013.6810654
   Nie DD, 2007, PATTERN RECOGN LETT, V28, P1445, DOI 10.1016/j.patrec.2007.02.018
   Pang JH, 2014, IEEE IMAGE PROC, P4687, DOI 10.1109/ICIP.2014.7025950
   Pang JH, 2013, INT CONF ACOUST SPEE, P1578, DOI 10.1109/ICASSP.2013.6637917
   Pellacini F, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1243980.1243983, 10.1145/1276377.1276444, 10.1145/1239451.1239505]
   Pierre F, 2015, SIAM J IMAGING SCI, V8, P536, DOI 10.1137/140979368
   Rusu C, 2013, INT SYMP IMAGE SIG, P564
   Ryu T, 2013, IEEE ICCE, P330, DOI 10.1109/ICCE.2013.6486915
   Sheng B, 2011, IEEE COMPUT GRAPH, V31, P24, DOI 10.1109/MCG.2011.18
   Skora D., 2004, P 3 INT S NONPH AN R, P121, DOI DOI 10.1145/987657.987677
   Thepade SD, 2015, 2015 INTERNATIONAL CONFERENCE ON INDUSTRIAL INSTRUMENTATION AND CONTROL (ICIC), P332, DOI 10.1109/IIC.2015.7150763
   Uruma Kazunori, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1215, DOI 10.1109/ICASSP.2014.6853790
   Wang HJ, 2012, INT CONF SIGN PROCES, P885, DOI 10.1109/ICoSP.2012.6491722
   Weiwei Du, 2012, 2012 Third International Conference on Intelligent Control and Information Processing (ICICIP 2012), P644, DOI 10.1109/ICICIP.2012.6391510
   Welsh T, 2002, ACM T GRAPHIC, V21, P277, DOI 10.1145/566570.566576
   Yatziv L, 2006, IEEE T IMAGE PROCESS, V15, P1120, DOI 10.1109/TIP.2005.864231
NR 42
TC 6
Z9 6
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23567
EP 23588
DI 10.1007/s11042-016-4112-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700020
DA 2024-07-18
ER

PT J
AU Hussain, A
   Habib, M
AF Hussain, Ayyaz
   Habib, Muhammad
TI RETRACTED: A new cluster based adaptive fuzzy switching median filter
   for impulse noise removal (Retracted article. See vol. 12, pg. 197,
   2018)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Impulse noise; Gradient values; Cluster based fuzzy filter;
   Computational efficiency; Non-parametric approach; Fuzzy reasoning
ID REDUCTION METHOD; PEPPER NOISE; COLOR IMAGES; DETECTOR; OPTIMIZATION;
   ENHANCEMENT; DESIGN; SALT
AB A new clustering technique based on most allied directional neighbors is proposed to suppress low and high-density impulse noise from digital images. Most allied neighbors exhibit a vital role in estimation as well restoration of appropriate gray level value of corrupted pixels. In first phase, most allied directional neighbors, i.e., pixels directly attached to central pixel and the directional pixels (horizontal, vertical and two diagonal directions) next to attached pixels in the processing window are partitioned into two equal size clusters based on gradient values. Cluster with a minimum sum of gradient values (most similar neighbors) and the one with relatively large gradient values are passed to fuzzy inference system to infer the current pixel to be noisy-free, edge or a noisy. In second phase, a switching technique opts one of the three options depending upon fuzzy membership degrees and local information to restore the corrupted pixel value. A non-parametric approach based on local information for dynamic threshold setting using fuzzy logic makes the proposed filter computationally effective and adaptive to process a large number of images without user-defined parameters. The proposed algorithm is simple to implement and simulation results based on well know quantitative measures indicate the supremacy of the proposed filter for random-valued impulse noise as well as salt and peppers noise.
C1 [Hussain, Ayyaz; Habib, Muhammad] Int Islamic Univ, Dept Comp Sci & Software Engn, Islamabad, Pakistan.
   [Hussain, Ayyaz] Saudi Elect Univ, Coll Comp & Informat, Riyadh, Saudi Arabia.
C3 International Islamic University, Pakistan; Saudi Electronic University
RP Hussain, A (corresponding author), Int Islamic Univ, Dept Comp Sci & Software Engn, Islamabad, Pakistan.; Hussain, A (corresponding author), Saudi Elect Univ, Coll Comp & Informat, Riyadh, Saudi Arabia.
EM ayyaz.hussain@iiu.edu.pk; mhabibakhtar@gmail.com
CR Arce GR, 2000, IEEE T SIGNAL PROCES, V48, P768, DOI 10.1109/78.824671
   Awad AS, 2011, IEEE SIGNAL PROC LET, V18, P407, DOI 10.1109/LSP.2011.2154330
   Bilal M, 2014, MULTIMED TOOLS APPL, V69, P1067, DOI 10.1007/s11042-012-1172-3
   BROWNRIGG DRK, 1984, COMMUN ACM, V27, P807, DOI 10.1145/358198.358222
   Chen CLP, 2014, IEEE T GEOSCI REMOTE, V52, P574, DOI 10.1109/TGRS.2013.2242477
   Chen T, 1999, IEEE T IMAGE PROCESS, V8, P1834, DOI 10.1109/83.806630
   Crnojevic V, 2004, IEEE SIGNAL PROC LET, V11, P589, DOI 10.1109/LSP.2004.830117
   Dong YQ, 2007, IEEE SIGNAL PROC LET, V14, P193, DOI 10.1109/LSP.2006.884014
   FLORENCIO DAF, 1994, P SOC PHOTO-OPT INS, V2308, P268, DOI 10.1117/12.185969
   Garnett R, 2005, IEEE T IMAGE PROCESS, V14, P1747, DOI 10.1109/TIP.2005.857261
   Ghanekar U, 2010, IEEE SIGNAL PROC LET, V17, P1, DOI 10.1109/LSP.2009.2032479
   Gonzalez R. C., 2006, PEARSON ED INDIA, V3rd
   Gui J, 2014, IEEE T IMAGE PROCESS, V23, P3126, DOI 10.1109/TIP.2014.2326001
   Gupta V, 2015, J VIS COMMUN IMAGE R, V26, P296, DOI 10.1016/j.jvcir.2014.10.004
   Habib M, 2016, AEU-INT J ELECTRON C, V70, P689, DOI 10.1016/j.aeue.2016.02.005
   Habib M, 2015, INT CONF FRONT INFO, P329, DOI 10.1109/FIT.2015.64
   Habib M, 2015, APPL SOFT COMPUT, V29, P471, DOI 10.1016/j.asoc.2015.01.010
   Hussain A, 2012, MULTIMED TOOLS APPL, V60, P551, DOI 10.1007/s11042-011-0829-7
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Kang CC, 2009, SIGNAL PROCESS, V89, P344, DOI 10.1016/j.sigpro.2008.09.003
   KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870
   Li ZY, 2014, PATTERN RECOGN LETT, V40, P113, DOI 10.1016/j.patrec.2013.12.022
   Lin CH, 2010, IEEE T IMAGE PROCESS, V19, P2307, DOI 10.1109/TIP.2010.2047906
   Liu LC, 2015, INFORM SCIENCES, V315, P1, DOI 10.1016/j.ins.2015.03.067
   Lu CT, 2012, PATTERN RECOGN LETT, V33, P1287, DOI 10.1016/j.patrec.2012.03.025
   NODES TA, 1982, IEEE T ACOUST SPEECH, V30, P739, DOI 10.1109/TASSP.1982.1163951
   Roy A, 2017, AEU-INT J ELECTRON C, V72, P114, DOI 10.1016/j.aeue.2016.12.006
   Schulte S, 2006, IEEE T IMAGE PROCESS, V15, P1153, DOI 10.1109/TIP.2005.864179
   Schulte S, 2007, FUZZY SET SYST, V158, P270, DOI 10.1016/j.fss.2006.10.010
   Schulte S, 2006, IEEE T IMAGE PROCESS, V15, P3567, DOI 10.1109/TIP.2006.877494
   Toh KKV, 2010, IEEE T CONSUM ELECTR, V56, P2560, DOI 10.1109/TCE.2010.5681141
   Turkmen I, 2013, AEU-INT J ELECTRON C, V67, P771, DOI 10.1016/j.aeue.2013.03.006
   Xiong B, 2012, IEEE T IMAGE PROCESS, V21, P1663, DOI 10.1109/TIP.2011.2172804
   Zhang JJ, 2010, DIGIT SIGNAL PROCESS, V20, P1010, DOI 10.1016/j.dsp.2009.11.003
NR 34
TC 19
Z9 21
U1 1
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22001
EP 22018
DI 10.1007/s11042-017-4757-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200008
DA 2024-07-18
ER

PT J
AU Liu, HC
   He, GJ
   Jiao, WL
   Wang, GZ
   Peng, Y
   Cheng, B
AF Liu, Huichan
   He, Guojin
   Jiao, Weili
   Wang, Guizhou
   Peng, Yan
   Cheng, Bo
TI Sequential pattern mining of land cover dynamics based on time-series
   remote sensing images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote sensing satellite; Image time series; Data mining; Sequential
   patternmining; Land cover change
ID DIGITAL CHANGE DETECTION; BIG DATA
AB Remote sensing images constitute a new type of multimedia data well suited to land cover change detection tasks, as they can repetitively provide information about the land surface and its changes over large and inaccessible areas. With plans for more missions and higher resolution earth observation systems, the challenge is increasingly going to be the efficient usability of the millions of collected images, especially the decades of remote sensing image time series, to describe land cover and/or scene evolution and dynamics. In contrast to traditional land cover change measures using pair-wise comparisons that emphasize the compositional or configurational changes between dates, this research focuses on the analysis of the temporal sequence of land cover dynamics, which refers to the succession of land cover types for a given area over more than two observational periods. The expected novel significance of this study is the generalization of the application of the sequential pattern mining method for capturing the spatial variability of landscape patterns and their trajectories of change to reveal information regarding process regularities with satellite imagery. Experimental results showed that this approach not only quantifies land cover changes in terms of the percentage area affected and maps the spatial distribution of these land cover changes but also reveals possibly interesting or useful information regarding the trajectories of change. This method is a valuable complement to existing bi-temporal change detection methods.
C1 [Liu, Huichan; He, Guojin; Jiao, Weili; Wang, Guizhou; Peng, Yan; Cheng, Bo] Chinese Acad Sci, Inst Remote Sensing & Digital Earth RADI, 9 Dengzhuang South Rd, Beijing 100094, Peoples R China.
   [Liu, Huichan] Univ Chinese Acad Sci, 19A Yuquan Rd, Beijing 100049, Peoples R China.
   [Liu, Huichan; He, Guojin; Jiao, Weili; Wang, Guizhou; Peng, Yan; Cheng, Bo] Hainan Key Lab Earth Observat, Sanya 572029, Peoples R China.
C3 Chinese Academy of Sciences; The Institute of Remote Sensing & Digital
   Earth, CAS; Chinese Academy of Sciences; University of Chinese Academy
   of Sciences, CAS
RP He, GJ (corresponding author), Chinese Acad Sci, Inst Remote Sensing & Digital Earth RADI, 9 Dengzhuang South Rd, Beijing 100094, Peoples R China.; He, GJ (corresponding author), Hainan Key Lab Earth Observat, Sanya 572029, Peoples R China.
EM hegj@radi.ac.cn
OI Jiao, Weili/0000-0003-1156-9860
FU National Natural Science Foundation of China [61271013, 61401461,
   61372189]; "135" Strategy Planning of the Institute of Remote Sensing
   and Digital Earth, Chinese Academy of Sciences; Remote Sensing Survey
   and Assessment project of the National Ecological Environment Decade of
   Change [STSN-10-03]
FX This research was supported by grants from the National Natural Science
   Foundation of China (61271013, 61401461, and 61372189), "135" Strategy
   Planning of the Institute of Remote Sensing and Digital Earth, Chinese
   Academy of Sciences, and the Remote Sensing Survey and Assessment
   project of the National Ecological Environment Decade of Change
   (STSN-10-03). The majority of the Landsat image data were obtained free
   of charge from the Open Spatial Data Sharing Project of the Institute of
   Remote Sensing and Digital Earth, Chinese Academy of Sciences
   (http://ids.ceode.ac.cn/). Additional data were downloaded from the USGS
   Landsat archive via the GloVis interface (http://glovis.usgs.gov/).
CR AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415
   Antrop M, 1998, LANDSCAPE URBAN PLAN, V41, P155, DOI 10.1016/S0169-2046(98)00068-1
   Boriah Shyam., 2010, TIME SERIES CHANGE D
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   Gueguen L, 2007, IEEE T GEOSCI REMOTE, V45, P827, DOI 10.1109/TGRS.2006.890557
   Guo HD, 2014, CHINESE SCI BULL, V59, P5066, DOI 10.1007/s11434-014-0645-3
   Han J., 2000, FREESPAN FREQUENT PA, DOI [10.1145/347090.347167, DOI 10.1145/347090.347167]
   Henebry GM, 2002, P 2002 ANN NAT C DIG
   Hidber C, 1999, P 1999 ACM SIGMOD IN
   JENSEN JR, 1981, AM CARTOGRAPHER, V8, P127, DOI 10.1559/152304081784447318
   JHA CS, 1994, INT J REMOTE SENS, V15, P2543, DOI 10.1080/01431169408954265
   Jin SM, 2006, FOREST ECOL MANAG, V228, P177, DOI 10.1016/j.foreco.2006.03.009
   Le Ber F, 2006, ECOL MODEL, V191, P170, DOI 10.1016/j.ecolmodel.2005.08.031
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Ma Y, 2015, FUTURE GENER COMP SY, V51, P47, DOI 10.1016/j.future.2014.10.029
   Ma Y, 2014, IEEE T PARALL DISTR, V25, P2126, DOI 10.1109/TPDS.2013.272
   Melgani F, 2002, OPT ENG, V41, P3288, DOI 10.1117/1.1518995
   Pei J, 2001, P 17 INT C DAT ENG W
   Piles M, 2009, IEEE T GEOSCI REMOTE, V47, P4125, DOI 10.1109/TGRS.2009.2022088
   SRIKANT R, 1996, P 1996 ACM SIGMOD IN
   Wang LZ, 2014, COMPUT SCI ENG, V16, P41, DOI 10.1109/MCSE.2014.52
   Young SS, 2001, INT J REMOTE SENS, V22, P1457, DOI 10.1080/01431160116787
   Zaki MJ, 2000, IEEE T KNOWL DATA EN, V12, P372, DOI 10.1109/69.846291
   Zhang WF, 2014, SOFTWARE PRACT EXPER, V44, P873, DOI 10.1002/spe.2229
NR 25
TC 1
Z9 1
U1 2
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22919
EP 22942
DI 10.1007/s11042-016-3730-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200053
DA 2024-07-18
ER

PT J
AU Memon, I
   Ali, Q
   Zubedi, A
   Mangi, FA
AF Memon, Imran
   Ali, Qasim
   Zubedi, Asma
   Mangi, Farman Ali
TI DPMM: dynamic pseudonym-based multiple mix-zones generation for mobile
   traveler
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Road network; Multiple mix-zones; Location privacy; Location based
   services; Dynamic pseudonym
ID PROTECTING LOCATION PRIVACY; AD-HOC NETWORKS; SOCIAL MEDIA; ATTACKS;
   SYSTEM; PLACEMENT; SERVICE; SCHEME; SECURE
C1 [Memon, Imran] Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Peoples R China.
   [Ali, Qasim] Beijing Univ Posts & Telecommun, Beijing 100876, Peoples R China.
   [Zubedi, Asma] Beijing Univ Posts & Telecommun, Sch Econ & Mangement, Beijing 100876, Peoples R China.
   [Mangi, Farman Ali] Univ Elect Sci & Technol China, Chengdu, Sichuan, Peoples R China.
C3 Zhejiang University; Beijing University of Posts & Telecommunications;
   Beijing University of Posts & Telecommunications; University of
   Electronic Science & Technology of China
RP Memon, I (corresponding author), Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Peoples R China.
EM imranmemon52@zju.edu.cn
RI memon, Imran/K-1647-2017; Ali, Qasim/AAH-3077-2021
OI memon, Imran/0000-0002-8202-6604; Ali, Qasim/0000-0003-3314-3086
CR Aad I, 2008, IEEE ACM T NETWORK, V16, P791, DOI 10.1109/TNET.2007.904002
   Adigun A, 2013, PROCEEDINGS OF THE 2013 38TH ANNUAL IEEE CONFERENCE ON LOCAL COMPUTER NETWORKS WORKSHOPS (LCN WORKSHOPS), P162, DOI 10.1109/LCNW.2013.6758514
   Ahmad J, 2017, MULTIMED TOOLS APPL, V76, P4069, DOI 10.1007/s11042-016-3450-y
   Akhtar R, 2015, WIRELESS PERS COMMUN, V80, P85, DOI 10.1007/s11277-014-1996-4
   [Anonymous], 2001, Proceedings of the Second International Conference on Web Information Systems Engineering, Web Information Systems Engineering, 2001. Proceedings of the Second International Conference on, P66
   [Anonymous], 2015, MITOCHONDRIAL DNA, DOI DOI 10.1007/S11042-015-2676-4
   [Anonymous], 2009, Proceedings of International Conference on Very Large Data Bases
   Bamba B., 2008, Proceeding of 17th International Conference on World Wide Web, P237, DOI [DOI 10.1145/1367497.1367531, 10.1145/1367497.1367531]
   Bartolini I, 2016, MULTIMED TOOLS APPL, V75, P3813, DOI 10.1007/s11042-014-2062-7
   Beresford AR, 2003, IEEE PERVAS COMPUT, V2, P46, DOI 10.1109/MPRV.2003.1186725
   Bissmeyer N, 2013, 2013 10TH ANNUAL CONFERENCE ON WIRELESS ON-DEMAND NETWORK SYSTEMS AND SERVICES (WONS), P9, DOI 10.1109/WONS.2013.6578314
   Bobek S, 2016, MULTIMED TOOLS APPL, V75, P10595, DOI 10.1007/s11042-014-2060-9
   Buttyan Levente., 2009, P IEEE VEHICULAR NET, P1, DOI DOI 10.1109/VNC.2009.5416380
   Carianha A.M., 2011, P 30 INT PERFORMANCE, P1
   Chen YS, 2013, INT CONF CONNECT VEH, P937, DOI [10.1109/ICCVE.2013.185, 10.1109/ICCVE.2013.6799933]
   Chmiel W, 2016, MULTIMED TOOLS APPL, V75, P10529, DOI 10.1007/s11042-016-3367-5
   Chow C, 2006, 43 IEEE AS SIGN SYST, P763
   Engoulou RG, 2014, COMPUT COMMUN, V44, P1, DOI 10.1016/j.comcom.2014.02.020
   Freudiger J, 2007, ACM WIN ITS
   Freudiger J, 2013, IEEE T DEPEND SECURE, V10, P84, DOI 10.1109/TDSC.2012.85
   Freudiger J, 2009, CCS'09: PROCEEDINGS OF THE 16TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P324
   Freudiger J, 2009, LECT NOTES COMPUT SC, V5672, P216, DOI 10.1007/978-3-642-03168-7_13
   Freudiger Julien., 2010, Proceedings of IEEE INFOCOM 2010, P1
   Furini M, 2015, MULTIMED TOOLS APPL, V74, P9795, DOI 10.1007/s11042-014-2151-7
   Gedik B, 2005, INT CON DISTR COMP S, P620, DOI 10.1109/ICDCS.2005.48
   Ghinita G., 2007, Proceedings of 16th International Conference on World Wide Web, P371, DOI DOI 10.1145/1242572.1242623
   Gruteser M, 2003, PROCEEDINGS OF MOBISYS 2003, P31, DOI 10.1145/1066116.1189037
   Guo S, 2014, IEEE T PARALL DISTR, V25, P2794, DOI 10.1109/TPDS.2013.277
   Gustav YH, 2013, INT CONF COMPUTAT, P433, DOI 10.1109/ICCPS.2013.6893578
   Härri J, 2009, IEEE COMMUN SURV TUT, V11, P19, DOI 10.1109/SURV.2009.090403
   Hamieh A, 2009, GLOB TELECOMM CONF, P5077
   Huang LP, 2006, LECT NOTES COMPUT SC, V3934, P165
   Humbert M., 2009, P 16 ACM C COMP COMM, P324
   Jiang DD, 2016, MULTIMED TOOLS APPL, V75, P14281, DOI 10.1007/s11042-016-3402-6
   Jiang DD, 2016, MULTIMED TOOLS APPL, V75, P14307, DOI 10.1007/s11042-015-3239-4
   Jiang DD, 2015, T EMERG TELECOMMUN T, V26, P308, DOI 10.1002/ett.2619
   Jiang DD, 2014, J NETW COMPUT APPL, V40, P292, DOI 10.1016/j.jnca.2013.09.014
   Jiang DD, 2011, COMPUT NETW, V55, P3533, DOI 10.1016/j.comnet.2011.06.027
   Jiang DD, 2010, AEU-INT J ELECTRON C, V64, P685, DOI 10.1016/j.aeue.2009.04.012
   Kamenyi D. M., 2013, J COMPUTATIONAL INFO, V9, P9857
   Li J, 2017, MULTIMED TOOLS APPL, V76, P16963, DOI 10.1007/s11042-016-3662-1
   Li M, 2006, SWING SWAP USER CTR, P19
   Liu XX, 2012, IEEE INFOCOM SER, P972, DOI 10.1109/INFCOM.2012.6195848
   Liu Y, 2016, MULTIMED TOOLS APPL, V75, P4363, DOI 10.1007/s11042-015-2479-7
   Lu RX, 2012, IEEE T VEH TECHNOL, V61, P86, DOI 10.1109/TVT.2011.2162864
   Lu Y., 2015, MATH PROBL ENG, V2015, P1, DOI DOI 10.1109/IEDM.2015.7409770
   Martinez FJ, 2011, WIREL COMMUN MOB COM, V11, P813, DOI 10.1002/wcm.859
   Mazurczyk W, 2014, MULTIMED TOOLS APPL, V70, P2139, DOI 10.1007/s11042-012-1224-8
   Memon I, 2017, WORLD WIDE WEB, V20, P639, DOI 10.1007/s11280-016-0403-3
   Memon I, 2015, WIRELESS PERS COMMUN, V85, P1167, DOI 10.1007/s11277-015-2833-0
   Memon I, 2015, WIRELESS PERS COMMUN, V84, P1487, DOI 10.1007/s11277-015-2699-1
   Memon I, 2015, WIRELESS PERS COMMUN, V82, P1585, DOI 10.1007/s11277-015-2300-y
   Memon I, 2015, WIRELESS PERS COMMUN, V80, P1347, DOI 10.1007/s11277-014-2082-7
   Memon I, 2014, WIRELESS PERS COMMUN, V79, P661, DOI 10.1007/s11277-014-1879-8
   Memon MH, 2017, MULTIMED TOOLS APPL, V76, P15377, DOI 10.1007/s11042-016-3834-z
   Meyerowitz J, 2009, FIFTEENTH ACM INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING (MOBICOM 2009), P345
   Milutinovic M, 2015, MULTIMED TOOLS APPL, V74, P903, DOI 10.1007/s11042-013-1704-5
   Mishra Tulika, 2011, Proceedings 2011 25th IEEE International Conference on Advanced Information Networking and Applications Workshops (WAINA 2011), P442, DOI 10.1109/WAINA.2011.87
   Moghraoui K., 2015, DIVANET 2015 P 5 ACM, P93, DOI [10.1145/2815347.2815355, DOI 10.1145/2815347.2815355]
   Mokbel M. F., 2006, P 32 INT C VER LARG, P763, DOI DOI 10.1145/1620585.1620591
   Muraleedharan Rajani, 2009, 2009 43rd Asilomar Conference on Signals, Systems and Computers, P288, DOI 10.1109/ACSSC.2009.5470101
   Ohta T., 2010, Proceedings of the Third International Conference on Dependability (DEPEND 2010), P1, DOI 10.1109/DEPEND.2010.8
   Palanisamy B, 2013, PROC INT CONF DATA, P1300, DOI 10.1109/ICDE.2013.6544929
   Palanisamy B, 2011, PROC INT CONF DATA, P494, DOI 10.1109/ICDE.2011.5767898
   Pan YY, 2013, J NETW COMPUT APPL, V36, P1599, DOI 10.1016/j.jnca.2013.02.003
   Park KC, 2015, MULTIMED TOOLS APPL, V74, P6509, DOI 10.1007/s11042-014-2127-7
   Park Soyoung., 2008, SARNO S 2008 IEEE, P1
   Parno B., 2005, HOT TOPICS NETWORKS
   Sadhukhan P, 2010, IMSAA, V2010, P15
   Saini M, 2014, MULTIMED TOOLS APPL, V68, P135, DOI 10.1007/s11042-012-1207-9
   Sampigethaya K, 2005, P EMB SEC CARS ESCAR, V8
   Shen J, 2015, MULTIMED TOOLS APPL, V74, P8025, DOI 10.1007/s11042-014-2036-9
   Shiode N, 2002, 50 CASA
   Sichitiu ML, 2008, IEEE COMMUN SURV TUT, V10, P88, DOI 10.1109/COMST.2008.4564481
   Sun YP, 2015, PEER PEER NETW APPL, V8, P1108, DOI 10.1007/s12083-014-0269-z
   U. S. Census Bureau, TIGER LIN TIGER REL
   Wu B, 2007, SIGNALS COMMUN TECHN, P103, DOI 10.1007/978-0-387-33112-6_5
   Ying B, 2013, IEEE COMMUN LETT, V17
   Ying BD, 2015, IEEE ICC, P7041, DOI 10.1109/ICC.2015.7249449
   Yuanyuan Pan, 2012, 2012 Proceedings of IEEE 16th International Conference on Computer Supported Cooperative Work in Design (CSCWD 2012), P251, DOI 10.1109/CSCWD.2012.6221826
NR 80
TC 49
Z9 51
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 24359
EP 24388
DI 10.1007/s11042-016-4154-z
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700055
DA 2024-07-18
ER

PT J
AU Qu, BQ
   Vallet, F
   Carrive, J
   Gravier, G
AF Qu, Bingqing
   Vallet, Felicien
   Carrive, Jean
   Gravier, Guillaume
TI Content-based unsupervised segmentation of recurrent TV programs using
   grammatical inference
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia mining; Video segmentation; Grammatical inference; Multiple
   sequence alignment; Uniform resampling; Hierarchical clustering;
   Experimental evaluations; Practical applications
ID VIDEO
AB TV program segmentation raised as a major topic in the last decade for the task of high quality indexing of multimedia content. Earlier studies of TV program segmentation are either highly supervised (e.g., event detection) or too specific to a certain type of program (e.g., cluster-based methods), which is not practically usable for indexing tasks because of the lack of generality of programs types. In this paper, we address the problem of unsupervised TV program segmentation by leveraging grammatical inference, i.e., discovering a common structural model shared by a collection of episodes of a recurrent TV program by finding an optimal alignment of structural elements across episodes. Structural elements referring to a video segment with a particular syntactic meaning with respect to the video structure. The use of symbolic representation of structural elements makes grammatical inference feasible to be applied on TV program modeling, and makes TV program segmentation possible to rely on only minimal domain knowledge. The proposed approach is operated in two phases. The first phase aims at obtaining a symbolic representation of each episode, where the elements relevant to the structure are discovered based on recurrence mining. The second phase is that of grammatical inference from the symbolic representation of episodes. We investigate two inference techniques, one based on multiple sequence alignment and one relying on uniform resampling, to infer structural grammars for TV programs. A model of the structure is derived from the structural grammars and used to predict the structure of new episodes. Comparative evaluation on two grammar inference approaches demonstrates that the models obtained can reflect the structure of the program and predict the structure of unseen episodes, which is the main application of the proposed approach in industry, i.e., to assist librarians for segmentation tasks.
C1 [Qu, Bingqing] Univ Rennes 1, 263 Ave Gen Leclerc, F-35000 Rennes, France.
   [Vallet, Felicien] CNIL, Paris, France.
   [Carrive, Jean] INA PG, Paris, France.
   [Gravier, Guillaume] CNRS, Paris, France.
C3 Universite de Rennes; AgroParisTech; Centre National de la Recherche
   Scientifique (CNRS)
RP Qu, BQ (corresponding author), Univ Rennes 1, 263 Ave Gen Leclerc, F-35000 Rennes, France.
EM bingqing.qu@unifr.ch; fvallet@cnil.fr; jcarrive@ina.fr; guig@irisa.fr
CR Abduraman Alina Elma, 2013, International Conference on Computer Vision Theory and Applications (VISAPP 2013). Proceedings, P701
   Abduraman AE, 2011, EUROITV 11, P123
   Aho A. V, 2014, ALGORITHMS COMPLEXIT, V1, P255, DOI DOI 10.1016/B978-0-444-88071-0.50010-2
   Ancona N, 2001, IEEE IJCNN, P611, DOI 10.1109/IJCNN.2001.939092
   [Anonymous], 2008, P 10 INT C MULT INT
   [Anonymous], 2014, MATH PROB ENG, DOI DOI 10.1145/2593069.2593172
   Ben M, 2011, ICME 11, P1
   Bingqing Qu, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015, January 5-7, 2015, Proceedings: LNCS 8935, P140, DOI 10.1007/978-3-319-14445-0_13
   Botev ZI, 2010, ANN STAT, V38, P2916, DOI 10.1214/10-AOS799
   Chua T.-S., 2004, PROC ACMMM, P656, DOI [10.1145/1027527.1027679, DOI 10.1145/1027527.1027679]
   Crooks GE, 2004, GENOME RES, V14, P1188, DOI 10.1101/gr.849004
   Dumont É, 2012, INT J DIGIT MULTIMED, V2012, DOI 10.1155/2012/732514
   Gupta Vishwa, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6334, DOI 10.1109/ICASSP.2014.6854823
   Hopcroft J.E., 1979, Introduction to Automata Theory, Languages, and Computation
   Jacobs A, 2006, LECT NOTES COMPUT SC, V3955, P87
   Ji P, 2014, NEUROCOMPUTING, V123, P86, DOI 10.1016/j.neucom.2013.06.003
   Kijak E, 2006, MULTIMED TOOLS APPL, V30, P289, DOI 10.1007/s11042-006-0031-5
   Lee H, 2011, MULTIMED TOOLS APPL, V51, P1127, DOI 10.1007/s11042-010-0462-x
   Letessier P., 2012, P ACM INT C MULT, P599
   Li HJ, 2010, IEEE T CIRC SYST VID, V20, P351, DOI 10.1109/TCSVT.2009.2035833
   Mocanu B, 2016, LECT NOTES COMPUT SC, V10016, P648, DOI 10.1007/978-3-319-48680-2_57
   Qu B., 2014, P IEEE INT C MULT EX, P1
   Sidiropoulos P, 2011, IEEE T CIRC SYST VID, V21, P1163, DOI 10.1109/TCSVT.2011.2138830
   Stuhlsatz A, 2011, INT CONF ACOUST SPEE, P5688
   THOMPSON JD, 1994, NUCLEIC ACIDS RES, V22, P4673, DOI 10.1093/nar/22.22.4673
   THOMPSON K, 1968, COMMUN ACM, V11, P419, DOI 10.1145/363347.363387
   Xie LX, 2004, PATTERN RECOGN LETT, V25, P767, DOI 10.1016/j.patrec.2004.01.005
   Yang XF, 2007, IEEE T MULTIMEDIA, V9, P600, DOI 10.1109/TMM.2006.889352
   Zhang DQ, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P117
   Zhang J, 2013, J ASSOC ASPHALT PAV, V82, P1, DOI 10.1080/14680629.2013.812843
   Zhu SH, 2009, MULTIMED TOOLS APPL, V42, P183, DOI 10.1007/s11042-008-0233-0
NR 31
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22569
EP 22597
DI 10.1007/s11042-017-4816-5
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200035
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, JW
   Li, T
   Shi, YQ
   Lian, SG
   Ye, JY
AF Wang, Jinwei
   Li, Ting
   Shi, Yun-Qing
   Lian, Shiguo
   Ye, Jingyu
TI Forensics feature analysis in quaternion wavelet domain for
   distinguishing photographic images and computer graphics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quaternion wavelet transform; Contourlet wavelet transform; Discrete
   wavelet transform; Feature comparison; Forensics
ID TRANSFORM
AB In this paper, a novel set of features based on Quaternion Wavelet Transform (QWT) is proposed for digital image forensics. Compared with Discrete Wavelet Transform (DWT) and Contourlet Wavelet Transform (CWT), QWT produces the parameters, i.e., one magnitude and three angles, which provide more valuable information to distinguish photographic (PG) images and computer generated (CG) images. Some theoretical analysis are done and comparative experiments are made. The corresponding results show that the proposed scheme achieves 18 percents' improvements on the detection accuracy than Farid's scheme and 12 percents than A-zparlak's scheme. It may be the first time to introduce QWT to image forensics, but the improvements are encouraging.
C1 [Wang, Jinwei; Li, Ting] Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Nanjing, Jiangsu, Peoples R China.
   [Wang, Jinwei; Li, Ting] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
   [Shi, Yun-Qing] New Jersey Inst Technol, Dept Elect & Comp Engn, Newark, NJ 07102 USA.
   [Ye, Jingyu] New Jersey Inst Technol, Newark, NJ 07102 USA.
   [Lian, Shiguo] Huawei Technol, Cent Res Inst, Beijing 100085, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology; New Jersey Institute of
   Technology; New Jersey Institute of Technology; Huawei Technologies
RP Wang, JW (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Nanjing, Jiangsu, Peoples R China.; Wang, JW (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
EM wjwei_2004@163.com
RI zhen, wang/KBA-3844-2024; Shi, Yun/JWP-3360-2024; Ye, Jingyu/Q-2990-2019
OI Ye, Jingyu/0000-0003-3202-881X
FU National Natural Science Foundation of China [61272421, 61103141,
   61232016, 61173141, 61103201, 61402235]; Natural Science Foundation of
   Jiangsu Higher Education Institutions of China [12KJB520006]; Priority
   Academic Program Development of Jiangsu Higher Education Institutions,
   Jiangsu Government Scholarship for Overseas Studies; CICAEET
FX This work was jointly supported by the National Natural Science
   Foundation of China (Grant No. 61272421, 61103141, 61232016, 61173141,
   61103201, 61402235), the Natural Science Foundation of Jiangsu Higher
   Education Institutions of China (Grant No. 12KJB520006), the Priority
   Academic Program Development of Jiangsu Higher Education Institutions,
   Jiangsu Government Scholarship for Overseas Studies and CICAEET.
CR [Anonymous], 2003, INT C COMP VIS PATT
   Buccigrossi RW, 1999, IEEE T IMAGE PROCESS, V8, P1688, DOI 10.1109/83.806616
   Bulow T, 1999, THESIS
   Chen W, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1123
   Delp E, 2009, IEEE SIGNAL PROC MAG, V26, P14, DOI 10.1109/MSP.2008.931089
   Fan S, 2012, INT J COMPUT INF SCI, V9, P2877
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Li CR, 2013, IEEE SIGNAL PROC LET, V20, P799, DOI 10.1109/LSP.2013.2247596
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li ZH, 2012, 11 IWDW INT WORKSH D
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Liu YP, 2013, PATTERN RECOGN LETT, V34, P1063, DOI 10.1016/j.patrec.2013.03.002
   Lyu S, 2005, IEEE T SIGNAL PROCES, V53, P845, DOI 10.1109/TSP.2004.839896
   Özparlak L, 2011, IEEE T INF FOREN SEC, V6, P1418, DOI 10.1109/TIFS.2011.2162830
   Pang HC, 2012, 2012 5TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P543, DOI 10.1109/CISP.2012.6469884
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Soulard R, 2010, 18 EUR SIGN PROC C E
   Soulard R, 2011, PATTERN RECOGN LETT, V32, P1669, DOI 10.1016/j.patrec.2011.06.028
   Tian-Tsong Ng, 2005, 13th Annual ACM International Conference on Multimedia, P239
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 20
TC 178
Z9 182
U1 0
U2 56
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23721
EP 23737
DI 10.1007/s11042-016-4153-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700028
DA 2024-07-18
ER

PT J
AU Byun, J
   Kim, BW
   Ko, CY
   Byun, JW
AF Byun, Jeongeun
   Kim, Byung Woon
   Ko, Chang Youl
   Byun, Jeoung-Woo
TI 4G LTE network access system and pricing model for IoT MVNOs: spreading
   smart tourism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart tourism; 4G LTE network; Internet of things (IoT); Mobile virtual
   network operator (MVNO); Wholesale pricing
ID INTERNET; TECHNOLOGY; MANAGEMENT; FRAMEWORK; SERVICE; THINGS
AB The aim of this study is to facilitate market access by Internet of things (IoT) mobile virtual network operators (MVNOs) ('M2V' hereinafter) for the purpose of providing the IoT services required to implement more advanced smart tourism in the tourism sector, which is heavily influenced not only by the Internet but also by information and communications technology (ICT) in the era of fourth generation (4G) long term evolution (LTE) networks. The study produced the following results. It established a 4G LTE network-based technological access system, which is commercially offered all over the world, and suggested business models featuring diverse interworking between network and system through M2V access to 4G LTE, as well as the resulting wholesale price calculation model according to bandwidth. Based on the research model, both the Korean government and governments of other countries can be expected to further advance smart tourism in the future by implementing policy and institutional supports that aim to enable 4G LTE network-based M2V to realize a technological access system, and by inducing M2V to make inroads into the tourism industry based on diversified business models.
C1 [Byun, Jeongeun] Univ Sci & Technol, Korea Inst Sci & Technol Informat, Dept Sci & Technol Management Policy, 66 Hoegi Ro, Seoul 02456, South Korea.
   [Kim, Byung Woon] Univ Sci & Technol, Dept Sci & Technol Management Policy, IT Law & Regulat Res Sect, Elect & Telecommun Res Inst, 218 Gajeong Ro, Daejeon 34129, South Korea.
   [Ko, Chang Youl] Jeju Natl Univ, Dept Accounting, 102 Jejudaehak Ro, Jeju Si 63243, Jeju Special Se, South Korea.
   [Byun, Jeoung-Woo] Kyung Hee Univ, Coll Hotel & Tourism Management, 26 Kyungheedae Ro, Seoul 02447, South Korea.
C3 Korea Institute of Science & Technology Information (KISTI); Electronics
   & Telecommunications Research Institute - Korea (ETRI); Jeju National
   University; Kyung Hee University
RP Kim, BW (corresponding author), Univ Sci & Technol, Dept Sci & Technol Management Policy, IT Law & Regulat Res Sect, Elect & Telecommun Res Inst, 218 Gajeong Ro, Daejeon 34129, South Korea.
EM bukim@etri.re.kr
OI Kim, Byung Woon/0000-0002-1372-6930
CR [Anonymous], 2010, MCKINSEY Q
   [Anonymous], 2013, 4G: LTE/LTE-advanced for mobile broadband
   Barnes SJ, 2002, INT J INFORM MANAGE, V22, P91, DOI 10.1016/S0268-4012(01)00047-0
   Berné C, 2015, TOURISM MANAGE, V48, P188, DOI 10.1016/j.tourman.2014.04.012
   Bloom JZ, 2005, ANN TOURISM RES, V32, P93, DOI 10.1016/j.annals.2004.05.001
   Buhalis D, 2008, TOURISM MANAGE, V29, P609, DOI 10.1016/j.tourman.2008.01.005
   Chen M, 2013, MULTIMED TOOLS APPL, V67, P167, DOI 10.1007/s11042-012-1013-4
   Choi K, 2015, ETRI J, V37, P685, DOI 10.4218/etrij.15.0114.1278
   Copeland R, 2011, P 15 IEEE INT C INT
   Costantino L, 2012, P 13 IEEE INT S WORL
   Dahlman E., 2010, 3G EVOLUTION HSPA LT
   Dal Fiore F, 2014, J TRANSP GEOGR, V41, P97, DOI 10.1016/j.jtrangeo.2014.08.014
   Ding JH, 2014, INT J INFORM MANAGE, V34, P329, DOI 10.1016/j.ijinfomgt.2013.11.006
   Gavalas D, 2014, J NETW COMPUT APPL, V39, P319, DOI 10.1016/j.jnca.2013.04.006
   Go S, 2015, ETRI J, V37, P707, DOI 10.4218/etrij.15.0114.1251
   Gronli TM, 2013, INT J INFORM MANAGE, V33, P227, DOI 10.1016/j.ijinfomgt.2012.09.005
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Guttentag DA, 2010, TOURISM MANAGE, V31, P637, DOI 10.1016/j.tourman.2009.07.003
   Haugstvedt A.C., 2012, IEEE INT S MIX AUGM
   Hazmi A, 2012, 8 IEEE GLOB WORKSH G
   Hojeghan SB, 2011, PROCD SOC BEHV, V19, P308, DOI 10.1016/j.sbspro.2011.05.136
   Hunter William C., 2015, Asia Pacific Journal of Information Systems, V25, P105
   Kang H, 2015, MULTIMED TOOLS APPL, P1
   KCC, 2012, INT CHARG LM NETW
   KCC, 2010, OB WHOL PROV SERV TA, P10
   KCC, 2010, TEL BUS ACT
   Kim BW, 2004, ETRI J, V26, P665, DOI 10.4218/etrij.04.0204.0016
   Kim BW, 2007, TELECOMMUN POLICY, V31, P290, DOI 10.1016/j.telpol.2007.03.002
   Kim Byung Woon, 2009, [International Telecommunications Policy Review, 정보통신정책연구], V16, P33
   Kim BW, 2013, TELECOMMUN POLICY, V37, P35, DOI 10.1016/j.telpol.2012.08.010
   Kim J, 2014, IEEE COMMUN SURV TUT, V16, P61, DOI 10.1109/SURV.2013.100713.00203
   Kim MJ, 2013, J HOSP TOUR RES, V37, P377, DOI 10.1177/1096348012436377
   Kim MJ, 2011, TOURISM MANAGE, V32, P256, DOI 10.1016/j.tourman.2010.01.011
   Királ'ová A, 2015, PROCD SOC BEHV, V175, P358, DOI 10.1016/j.sbspro.2015.01.1211
   Kristensson S, 2001, THESIS U STOCKHOLMD, P76
   Law R., 2000, Journal of Travel & Tourism Marketing, V9, P65, DOI 10.1300/J073v09n03_05
   Li X, 2014, INT J INFORM MANAGE, V34, P319, DOI 10.1016/j.ijinfomgt.2013.11.007
   López TS, 2012, PERS UBIQUIT COMPUT, V16, P291, DOI 10.1007/s00779-011-0399-8
   Ma JX, 2003, INT J INFORM MANAGE, V23, P451, DOI 10.1016/j.ijinfomgt.2003.09.004
   Marwat SNK, 2014, ETRI J, V36, P761, DOI 10.4218/etrij.14.0113.1034
   Mattern F, 2010, LECT NOTES COMPUT SC, V6462, P242, DOI 10.1007/978-3-642-17226-7_15
   McNair JY, 2003, HDB RF WIRELESS TECH, P23
   MIAC, 2007, GUID APPL REL TEL BU
   Ministry of Culture, 2014, 2 EXT M PROM TOUR
   Miorandi D, 2012, AD HOC NETW, V10, P1497, DOI 10.1016/j.adhoc.2012.02.016
   Mo Koo， Chul, 2015, Asia Pacific Journal of Information Systems, V25, P99
   Mo Koo， Chul, 2014, Journal of Information Technology Applications & Management, V21, P99
   Molz J.G., 2012, Travel connections: Tourism, technology, and togetherness in a mobile world
   MSIP, 2013, SPEC ACT PROM ICT CO
   MSIP, 2014, WIR COMM SERV STAT
   MSIP, 2013, VIS CREAT EC PEOPL H
   MSIP, 2014, SMART CULT ASS TOUR
   MSIP, 2013, MOT STRAT COMP MOB P
   Munar AM, 2014, TOURISM MANAGE, V43, P46, DOI 10.1016/j.tourman.2014.01.012
   NTT DoCoMo, 2014, REV PACK INT CHARG M
   Park HS, 2015, ETRI J, V37, P1065, DOI 10.4218/etrij.15.0115.0529
   Pesonen J, 2012, TOUR MANAG PERSPECT, V4, P11, DOI 10.1016/j.tmp.2012.04.001
   Porter ME, 2014, HARVARD BUS REV, V92, P64
   SKT, 2013, LTE CUST RAT PLAN
   Song PJ, 2010, ELECT TELECOMMUN TRE, V25, P38
   Stansfield M, 2003, INT J INFORM MANAGE, V23, P83, DOI 10.1016/S0268-4012(02)00072-5
   Uckelmann D, 2011, ARCHITECTING THE INTERNET OF THINGS, P1, DOI 10.1007/978-3-642-19157-2
   Wang D, 2016, J TRAVEL RES, V55, P52, DOI 10.1177/0047287514535847
NR 63
TC 17
Z9 19
U1 4
U2 83
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19665
EP 19688
DI 10.1007/s11042-016-3369-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500021
DA 2024-07-18
ER

PT J
AU Chen, J
   Zheng, S
   Hu, Q
   Kuo, YH
AF Chen, Jian
   Zheng, Shuai
   Hu, Qing
   Kuo, Yonghong
TI A frame-level encoder rate control scheme for transform domain Wyner-Ziv
   video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed video coding; Encoder rate control; Adaptive coding mode
   selection; Bit-plane rearrangement; Frame-level rate estimation
ID RATE-ADAPTIVE CODES; SIDE INFORMATION; COMPRESSION
AB Available distributed video coding codecs are mostly based on decoder rate control scheme where the parity bits for decoding can be achieved over a feedback channel. Meanwhile, the frequent requests over feedback channel increase the transmission delay. The feedback-free distributed video coding, relying on encoder rate control in literatures, has overcome the aforementioned shortcoming. However, when performing parity bitrate estimation and other operations, the feedback-free distributed video coding systems based on bit-plane usually require high precision of bitrate estimation and high quality of side information at the encoder. In this paper, we propose a frame-level distributed video coding system based on encoder rate control. The innovations include three parts: 1) an adaptive coding mode selection algorithm is proposed, which utilizes both temporal and spatial correlation and reduces the complexity of encoder; 2) a bit-plane rearrangement method is adopted, which makes the coding rate on each bit-plane homogeneous and effectively reduces the accuracy requirement of the parity bitrate prediction and improves the efficiency of rate estimation; 3) a frame-level parity bitrate estimation scheme is presented to enhance the efficiency of rate estimation on the basis of a look-up table. Numerical results verify that the proposed scheme remarkably improves the rate distortion performance of distributed video coding at low bitrate.
C1 [Chen, Jian; Zheng, Shuai; Hu, Qing; Kuo, Yonghong] Xidian Univ, Sch Telecommun Engn, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Chen, J (corresponding author), Xidian Univ, Sch Telecommun Engn, Xian 710071, Shaanxi, Peoples R China.
EM jianchen@mail.xidian.edu.cn
RI Zheng, Shuai/AAH-5647-2020; KUO, Yong-Hong/M-9078-2015; HU,
   Qing/GWQ-8711-2022
FU National Natural Science Foundation of China [61540046]; "111" project
   [B08038]
FX This work was supported by National Natural Science Foundation of China
   (Grant No. 61540046) and the "111" project (Grant No. B08038).
CR [Anonymous], P IEEE INT C MULT EX
   [Anonymous], 2005, DISCOVERR DISTRIBUTE
   Artigas X, 2005, Proceedings ELMAR-2005, P53
   Avudainayagam A, 2008, IEEE T CIRC SYST VID, V18, P557, DOI 10.1109/TCSVT.2008.918785
   Brites C, 2007, IEEE IMAGE PROC, P569
   Brites C, 2011, IEEE T CIRC SYST VID, V21, P1278, DOI 10.1109/TCSVT.2011.2147210
   Chen Jian, 2014, Journal on Communications, V35, P32, DOI 10.3969/j.issn.1000-436x.2014.06.005
   Coleman TP, 2004, IEEE DATA COMPR CONF, P282
   Du BG, 2009, THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING (MUE 2009), P9, DOI 10.1109/MUE.2009.12
   Haqqani M, 2007, P INT C EL COMP COMP, P386
   Ji W, 2014, IEEE T CIRC SYST VID, V24, P141, DOI 10.1109/TCSVT.2013.2276535
   Kumar V, 2012, IEEE INT CONF MULTI, P89, DOI 10.1109/ICMEW.2012.23
   Kuo YH, 2012, ELECTRON LETT, V48, P691, DOI 10.1049/el.2012.0838
   Ma T, 2013, IEEE COMMUN SURV TUT, V15, P963, DOI 10.1109/SURV.2012.060912.00149
   Martinez JL, 2008, IEEE IMAGE PROC, P1140, DOI 10.1109/ICIP.2008.4711961
   Micallef JJ, 2014, IEEE T CIRC SYST VID, V24, P127, DOI 10.1109/TCSVT.2013.2273630
   Puri R, 2007, IEEE T IMAGE PROCESS, V16, P2436, DOI 10.1109/TIP.2007.904949
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Song Bin, 2011, Journal on Communications, V32, P1
   Varodayan D, 2006, SIGNAL PROCESS, V86, P3123, DOI 10.1016/j.sigpro.2006.03.012
   Wang YJ, 2013, IEEE INT SYMP CIRC S, P257, DOI 10.1109/ISCAS.2013.6571831
   Weerakkody WARJ, 2007, IEEE T CONSUM ELECTR, V53, P788, DOI 10.1109/TCE.2007.381761
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   Ye F, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P217, DOI 10.1109/PCS.2012.6213331
NR 24
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 20567
EP 20585
DI 10.1007/s11042-016-3992-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400009
DA 2024-07-18
ER

PT J
AU Chen, W
   Gong, SL
   Jiang, XQ
AF Chen, Wen
   Gong, Shilin
   Jiang, Xueqin
TI Fuzzy multiple attribute decision access scheme in heterogeneous
   wireless network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Heterogeneous wireless network; Dynamic decision matrix; Multimode
   terminal
AB A lot of researches focus on access selection schemes based on decision matrix in HWN (Heterogeneous Wireless Network). For the decision matrixes do not dynamically change with the constantly changing network, they do not resolve the contradiction between the algorithm complexity and terminal process capacity. In this paper, we propose an efficient access selection solution FMADA (Fuzzy Multiple Attribute Decision Access). Our main contribution is that we use some appropriate utility functions according to different characteristics of the decision-making factors and an adaptive filtering method, so as to forecast and formulate a dynamic decision matrix in HWN. Through the optimization, it improves the accuracy of normalizing network parameters, reduces the burden of terminate in process capability, and strengths the algorithm stability of access selection. In addition, the paper builds up a HWN access selection demonstration platform based on Mini2440 development board to verify the performance. The results show that it can reasonably and efficiently access the optimal network according to types of services, the user's preference and actual network status.
C1 [Chen, Wen; Gong, Shilin; Jiang, Xueqin] Donghua Univ, Minist Educ, Coll Informat Sci & Technol, Engn Res Ctr Digitized Text & Apparel Technol, Shanghai 201620, Peoples R China.
   [Chen, Wen] Donghua Univ, Coll Informat Sci & Technol, Dept Commun & Elect Engn, Shanghai 201620, Peoples R China.
C3 Donghua University; Donghua University
RP Chen, W (corresponding author), Donghua Univ, Minist Educ, Coll Informat Sci & Technol, Engn Res Ctr Digitized Text & Apparel Technol, Shanghai 201620, Peoples R China.; Chen, W (corresponding author), Donghua Univ, Coll Informat Sci & Technol, Dept Commun & Elect Engn, Shanghai 201620, Peoples R China.
EM chenwen@dhu.edu.cn
FU National Natural Science Funds [61501108, 61201249]; Central University
   Research Fund [15D110402, 15D110427]; College of Information Science and
   Technology, Donghua University; Government of China
FX Foundation item: The National Natural Science Funds (No: 61501108 and
   No: 61201249) and the Central University Research Fund (No: 15D110402
   and No: 15D110427). Authors are grateful to the College of Information
   Science and Technology, Donghua University, and Government of China for
   financial support to carry out this work.
CR Bakmaz Bojan, 2012, IWSSIP 2012
   Chang DY, 1996, EUR J OPER RES, V95, P649, DOI 10.1016/0377-2217(95)00300-2
   Faisal Kaleem, 2012, NETW OP MAN S APNOMS
   Jia Zhu, 2011, FLOW DISTRIBUTION MU
   Kaleem F., 2012, VHITS: Vertical Handoff Initiation and Target Selection in a Heterogeneous Wireless Network
   Mehbodniya A, 2012, IV INTERNATIONAL CONGRESS ON ULTRA MODERN TELECOMMUNICATIONS AND CONTROL SYSTEMS 2012 (ICUMT), P262, DOI 10.1109/ICUMT.2012.6459676
   Rinne J, 2012, 3GPP SPECIFICATION D
   Shu T, 2012, 2 INT C INSTR, V8258, P1293
   Smaoui I, 2009, 2009 6TH INTERNATIONAL SYMPOSIUM ON WIRELESS COMMUNICATION SYSTEMS (ISWCS 2009), P338, DOI 10.1109/ISWCS.2009.5285287
   Tahir HM, 2014, INT CONF MULTIMED, P789, DOI 10.1109/ICMCS.2014.6911152
   Xiao Y, 2010, J SOFTW, V21, P1378
   Yang J, 2013, RES VERTICAL HANDOVE
   Yi S, 2010, CHIN J COMPUT, V33, P1004
NR 13
TC 2
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 20049
EP 20065
DI 10.1007/s11042-016-4132-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500042
DA 2024-07-18
ER

PT J
AU Diez, H
   Segura, A
   García-Alonso, A
   Oyarzun, D
AF Diez, Helen V.
   Segura, Alvaro
   Garcia-Alonso, Alejandro
   Oyarzun, David
TI 3D model management for e-commerce
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cad; BIM; 3D model conversion; WebGL technology
ID SIMPLIFICATION; DESIGN
AB This paper contributes to the efficient visualization and management of 3D content for e-commerce purposes. The main objective of this research is to improve the multimedia management of complex 3D models, such as CAD or BIM models, by simply dragging a CAD/BIM file into a web application. Our developments and tests show that it is possible to convert these models into web compatible formats. The platform we present performs this task requiring no extra intervention from the user. This process makes sharing 3D content on the web immediate and simple, offering users an easy way to create rich accessible multiplatform catalogues. Furthermore, the platform enables users to view and interact with the uploaded models on any WebGL compatible browser favouring collaborative environments. Despite not being the main objective of this work, an interface with search engines has also been designed and tested. It shows that users can easily search for 3D products in a catalogue. The platform stores metadata of the models and uses it to narrow the search queries. Therefore, more precise results are obtained.
C1 [Diez, Helen V.; Segura, Alvaro; Garcia-Alonso, Alejandro; Oyarzun, David] Vicomtech IK4 Res Ctr, Paseo Mikeletegui 57, San Sebastian 20009, Spain.
RP Diez, H (corresponding author), Vicomtech IK4 Res Ctr, Paseo Mikeletegui 57, San Sebastian 20009, Spain.
EM hdiez@vicomtech.org; asegura@vicomtech.org; alex.galonso@ehu.es;
   doyarzun@vicomtech.org
OI Segura, Alvaro/0000-0001-6497-8938
CR [Anonymous], 2003, LEVEL DETAIL 3D GRAP
   [Anonymous], 2014, COMPUTER GRAPHICS PR
   [Anonymous], GRABCAD HELPS MECH E
   [Anonymous], 2016, P 21 INT C WEB3D TEC
   Arnaud R., 2007, CISC VIS NETW IND GL
   Bayardo R.J., 2004, WWW2004, P345, DOI DOI 10.1145/988672.988719
   Beetz J, 2010, P CIP W78 C
   Building SMART U. K., 2010, INV BIM COMP B UILD
   Carey Rikk., 1997, The Annotated VRML 97 Reference Manual
   Chodorow Kristina, 2013, MongoDB: The Definitive Guide, V2nd
   Cignoni P, 1998, COMPUT GRAPH-UK, V22, P37, DOI 10.1016/S0097-8493(97)00082-4
   Frey PJ, 2000, APPL FINITE ELEMENT
   George P.-L., 1997, Triangulation de Delaunay et Maillage
   Han SH, 2002, CONCURRENT ENG-RES A, V10, P239, DOI 10.1106/106329302030370
   Hoppe H., 1993, Computer Graphics Proceedings, P19, DOI 10.1145/166117.166119
   ISO, 10303212002 ISO, P72
   Liebich T., 2013, BIFC4THE NEW BUILDIN
   Lindstrom P., 2000, P 27 ANN C COMP GRAP
   Luebke D., 2001, IEEE VIRT REAL C TUT, V7
   Lv ZH, 2016, IEEE ACCESS, V4, P407, DOI 10.1109/ACCESS.2016.2517076
   Martz P., 2007, PMARTZ COMPUTER GRAP
   Naylor BF, 2005, HDB DATA STRUCTURES, P20
   Posada J, 2005, APPL ONTOL, V1, P263
   Quartulli M, 2013, ISPRS J PHOTOGRAMM, V75, P11, DOI 10.1016/j.isprsjprs.2012.09.010
   Schroeder W. J., 1992, SIGGRAPH COMPUTER GR, V26
   Shamir A, 2008, COMPUT GRAPH FORUM, V27, P1539, DOI 10.1111/j.1467-8659.2007.01103.x
   Silva JL, 2015, IEEE J-STARS, V8, P2165, DOI 10.1109/JSTARS.2015.2438034
   Tay FEH, 2003, COMPUT IND, V52, P127, DOI 10.1016/S0166-3615(03)00100-3
   Thakur A, 2009, COMPUT AIDED DESIGN, V41, P65, DOI 10.1016/j.cad.2008.11.009
   *US PROD DAT ASS, 1996, IN GRAPH EXCH SPEC I
   Wei-dong WU, 2010, SCI TECHNOL INF, V23, P479
   Yang QZ, 2006, COMPUT AIDED DESIGN, V38, P1099, DOI 10.1016/j.cad.2006.06.003
   [No title captured]
NR 33
TC 3
Z9 4
U1 2
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21011
EP 21031
DI 10.1007/s11042-016-4047-1
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400031
DA 2024-07-18
ER

PT J
AU Mstafa, RJ
   Elleithy, KM
AF Mstafa, Ramadhan J.
   Elleithy, Khaled M.
TI Compressed and raw video steganography techniques: a comprehensive
   survey and analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video steganography; Compressed domain; Raw domain; Video processing;
   Smart video transmission; Smart video tracking; Imperceptibility; Hiding
   capacity
ID INTELLIGENT REVERSIBLE WATERMARKING; DATA HIDING ALGORITHM; COPYRIGHT
   PROTECTION; IMAGE STEGANOGRAPHY; EMBEDDING ALGORITHM; BPCS
   STEGANOGRAPHY; INFORMATION; VECTOR; SCHEME; SECURE
AB In the last two decades, the science of covertly concealing and communicating data has acquired tremendous significance due to the technological advancement in communication and digital content. Steganography is the art of concealing secret data in a particular interactive media transporter, e.g., text, audio, image, and video data in order to build a covert communication between authorized parties. Nowadays, video steganography techniques have become important in many video-sharing and social networking applications such as Livestreaming, YouTube, Twitter, and Facebook because of the noteworthy development of advanced video over the Internet. The performance of any steganographic method ultimately relies on the imperceptibility, hiding capacity, and robustness. In the past decade, many video steganography methods have been proposed; however, the literature lacks of sufficient survey articles that discuss all techniques. This paper presents a comprehensive study and analysis of numerous cutting edge video steganography methods and their performance evaluations from literature. Both compressed and raw video steganography methods are surveyed. In the compressed domain, video steganography techniques are categorized according to the video compression stages as venues for data hiding such as intra frame prediction, inter frame prediction, motion vectors, transformed and quantized coefficients, and entropy coding. On the other hand, raw video steganography methods are classified into spatial and transform domains. This survey suggests current research directions and recommendations to improve on existing video steganography techniques.
C1 [Mstafa, Ramadhan J.; Elleithy, Khaled M.] Univ Bridgeport, Dept Comp Sci & Engn, Bridgeport, CT 06604 USA.
C3 University of Bridgeport
RP Mstafa, RJ (corresponding author), Univ Bridgeport, Dept Comp Sci & Engn, Bridgeport, CT 06604 USA.
EM rmstafa@my.bridgeport.edu; elleithy@bridgeport.edu
RI Mstafa, Ramadhan J./G-4533-2015; Razaque, Abdul/AAC-4837-2020
OI Mstafa, Ramadhan J./0000-0002-6122-234X; Razaque,
   Abdul/0000-0003-0409-3526; Elleithy, Khaled/0000-0001-9239-5035
CR Abu-Marie W., 2010, International Journal of Signal and Image Processing, V1, P196
   Ahmad J, 2017, J REAL-TIME IMAGE PR, V13, P431, DOI 10.1007/s11554-015-0536-0
   Alavianmehr M. A., 2012, 2012 2nd International eConference on Computer and Knowledge Engineering (ICCKE 2012), P194, DOI 10.1109/ICCKE.2012.6395377
   [Anonymous], 2016, IEEE LONG ISL SYST A
   [Anonymous], 2016, MULTIMED TOOLS APPL
   Arsalan M, 2012, J SYST SOFTWARE, V85, P883, DOI 10.1016/j.jss.2011.11.005
   Barni M, 2005, IEEE T MULTIMEDIA, V7, P23, DOI 10.1109/TMM.2004.840594
   Bhole AT, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMPUTING RESEARCH (ICCIC), P189
   Chang FC, 2007, J VLSI SIG PROC SYST, V49, P443, DOI 10.1007/s11265-007-0095-0
   Chang PC, 2014, J VIS COMMUN IMAGE R, V25, P239, DOI 10.1016/j.jvcir.2013.10.007
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Cheddad A, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P905, DOI 10.1109/ICME.2008.4607582
   Cheddad A, 2009, SIGNAL PROCESS, V89, P2465, DOI 10.1016/j.sigpro.2009.04.022
   Cheddad A, 2009, SIGNAL PROCESS, V89, P2324, DOI 10.1016/j.sigpro.2009.02.001
   Das Rig, 2012, 2012 3rd National Conference on Emerging Trends and Applications in Computer Science (NCETACS), P14, DOI 10.1109/NCETACS.2012.6203290
   Dasgupta K, 2013, PROC TECH, V10, P131, DOI 10.1016/j.protcy.2013.12.345
   Diop I, 2014, INT CONF ADV COMMUN, P162, DOI 10.1109/ICACT.2014.6778941
   Egiazarian K, 2006, P 2 INT WORKSHOP VID
   Eltahir ME, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND ENGINEERING, PROCEEDINGS, P550, DOI 10.1109/ICIME.2009.13
   Farschi SMR, 2012, NONLINEAR DYNAM, V69, P1525, DOI 10.1007/s11071-012-0367-5
   Feng Pan, 2010, 2010 IEEE International Conference on Software Engineering and Service Sciences (ICSESS 2010), P592, DOI 10.1109/ICSESS.2010.5552283
   Fontaine C, 2007, LECT NOTES COMPUT SC, V4567, P130
   Guangjie Liu, 2011, 2011 3rd International Conference on Multimedia Information Networking and Security, P642, DOI 10.1109/MINES.2011.138
   Gutub A, 2008, SIGNAL PROCESSING IT
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Hanafy A., 2008, IEEE MILITARY COMMUN, P1, DOI DOI 10.1109/MILCOM.2008.4753107
   Hao Bin, 2011, 2011 IEEE 3rd International Conference on Communication Software and Networks (ICCSN 2011), P406, DOI 10.1109/ICCSN.2011.6013622
   Hasnaoui M, 2014, SIGNAL PROCESS-IMAGE, V29, P107, DOI 10.1016/j.image.2013.07.007
   He YL, 2012, AEU-INT J ELECTRON C, V66, P305, DOI 10.1016/j.aeue.2011.08.007
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P3085, DOI 10.1007/s11042-013-1579-5
   Horng SJ, 2013, J VIS COMMUN IMAGE R, V24, P1099, DOI 10.1016/j.jvcir.2013.07.008
   Hu Y, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1231
   Huang HC, 2011, INFORM SCIENCES, V181, P3379, DOI 10.1016/j.ins.2011.04.007
   Huang JW, 2002, IEEE T CIRC SYST VID, V12, P916, DOI 10.1109/TCSVT.2002.804897
   Islam S, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-8
   Kamran, 2014, INFORM SCIENCES, V256, P162, DOI 10.1016/j.ins.2013.07.035
   Kapotas SK, 2008, IEEE INT C MULT EXP
   Kawaguchi E, 1999, P SOC PHOTO-OPT INS, V3528, P464, DOI 10.1117/12.337436
   Kelash HM, 2013, 2013 INTERNATIONAL CONFERENCE ON ICT CONVERGENCE (ICTC 2013): FUTURE CREATIVE CONVERGENCE TECHNOLOGIES FOR NEW ICT ECOSYSTEMS, P353, DOI 10.1109/ICTC.2013.6675372
   Khan A, 2014, INFORM SCIENCES, V279, P251, DOI 10.1016/j.ins.2014.03.118
   Khan A, 2012, INFORM SCIENCES, V216, P155, DOI 10.1016/j.ins.2012.06.014
   Khupse S, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON ISSUES AND CHALLENGES IN INTELLIGENT COMPUTING TECHNIQUES (ICICT), P811, DOI 10.1109/ICICICT.2014.6781384
   Lan TH, 2006, IEEE T IMAGE PROCESS, V15, P2431, DOI 10.1109/TIP.2006.875238
   Li Guangzhen, 2009, EURASIP J INF SECUR, V1, P4
   Li Y, 2010, INT CONF SIGN PROCES, P1833, DOI 10.1109/ICOSP.2010.5656918
   Liao K, 2012, TELECOMMUN SYST, V49, P261, DOI 10.1007/s11235-010-9372-5
   Lie WN, 2006, IEEE T CIRC SYST VID, V16, P300, DOI 10.1109/TCSVT.2005.861948
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P11888, DOI 10.1016/j.eswa.2009.04.026
   Lin WH, 2009, EXPERT SYST APPL, V36, P11509, DOI 10.1016/j.eswa.2009.03.060
   Lin WH, 2009, EXPERT SYST APPL, V36, P9869, DOI 10.1016/j.eswa.2009.02.036
   List P, 2003, IEEE T CIRC SYST VID, V13, P614, DOI 10.1109/TCSVT.2003.815175
   Liu B, 2008, ARES 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON AVAILABILITY, SECURITY AND RELIABILITY, P1382, DOI 10.1109/ARES.2008.140
   Liu GJ, 2012, INT C MULTIMED INFO, P323, DOI 10.1109/MINES.2012.55
   Liu Y., 2012, PROC 2012 2 INT C EL, V2012, P1
   Liu Y, 2013, J SYST SOFTW
   Liu YX, 2012, PROCEEDINGS OF 2012 IEEE 14TH INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY, P824, DOI 10.1109/ICCT.2012.6511318
   Lou DC, 2012, INFORM SCIENCES, V188, P346, DOI 10.1016/j.ins.2011.06.003
   Lu CS, 2005, SIGNAL PROCESS-IMAGE, V20, P624, DOI 10.1016/j.image.2005.03.012
   Lusson F, 2013, SIGNAL PROCESS, V93, P1268, DOI 10.1016/j.sigpro.2012.10.018
   Ma XJ, 2010, IEEE T CIRC SYST VID, V20, P1320, DOI 10.1109/TCSVT.2010.2070950
   Masoumi M, 2013, AEU-INT J ELECTRON C, V67, P528, DOI 10.1016/j.aeue.2012.11.009
   Mehmood I, 2016, NEUROCOMPUTING, V174, P393, DOI 10.1016/j.neucom.2015.05.126
   Mercuri RT, 2004, COMMUN ACM, V47, P25, DOI 10.1145/1005817.1005840
   Meuel Peter, 2007, 2007 15th European Signal Processing Conference (EUSIPCO), P2301
   Mobasseri B.G., 2005, Proceedings of the 7th workshop on Multimedia and security, P91, DOI DOI 10.1145/1073170.1073187
   Moon SK, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P660, DOI 10.1109/ICIIP.2013.6707677
   Mstafa R.J., 2015, IEEE Long Island Systems, Applications and Technology Conference (LISAT), P1, DOI 10.1109/LISAT.2015.7160192
   Mstafa R.J., 2015, Wireless Telecommunications Symposium (WTS), P1
   Mstafa RJ, 2016, MULTIMED TOOLS APPL, V75, P10311, DOI 10.1007/s11042-015-3060-0
   Mstafa RJ, 2015, 2015 IEEE 14TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P335, DOI 10.1109/ICMLA.2015.117
   Muhammad K, 2015, ARXIV151002177
   Muhammad K, 2016, MULTIMED TOOLS APPL, V75, P14867, DOI 10.1007/s11042-015-2671-9
   Muhammad K, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0473-x
   Muhammad K, 2015, KSII T INTERNET INF, V9, P1938
   Mustafa RJ., 2014, SYST APPL TECHN C LI, V2014, P2014, DOI [10.1109/LISAT.2014.6845191, DOI 10.1109/LISAT.2014.6845191]
   Niu Ke, 2013, 2013 IEEE 4th International Conference on Software Engineering and Service Science (ICSESS), P447, DOI 10.1109/ICSESS.2013.6615345
   Noda H, 2004, IEEE IMAGE PROC, P2147
   Patel K, 2013, INT CONF COMM SYST, P497, DOI 10.1109/CSNT.2013.109
   Paul R., 2013, Confluence 2013: The Next Generation Information Technology Summit (4th International Conference), P337, DOI DOI 10.1049/CP.2013.2338
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Ponomarenko N., 2007, INT WORKSH VID PROC
   Qazanfari K, 2014, INFORM SCIENCES, V277, P90, DOI 10.1016/j.ins.2014.02.007
   Qian ZX, 2011, DIGIT SIGNAL PROCESS, V21, P278, DOI 10.1016/j.dsp.2010.04.006
   Ritchey PhilipC., 2012, Journal of Information Hiding and Multimedia Signal Processing, V3, P212
   Robie DL, 2002, EURASIP J APPL SIG P, V2002, P164, DOI 10.1155/S1110865702000562
   Rosiyadi D., 2012, Int J Comput Theory and Eng (IJCTE), V4, P329
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Rupa C., 2013, Journal of the Institution of Engineers (India) Series B (Electrical, Electronics & Telecommunication and Computer Engineering), V94, P147, DOI 10.1007/s40031-013-0054-z
   Sadek MM, 2015, MULTIMED TOOLS APPL, V74, P7063, DOI 10.1007/s11042-014-1952-z
   Sajjad M, 2017, MULTIMED TOOLS APPL, V76, P3519, DOI 10.1007/s11042-016-3811-6
   Shahid Z, 2013, SIGNAL IMAGE VIDEO P, V7, P75, DOI 10.1007/s11760-011-0225-9
   Shanableh T, 2012, IEEE T INF FOREN SEC, V7, P455, DOI 10.1109/TIFS.2011.2177087
   ShengDun Hu, 2011, Proceedings of the 2011 IEEE 14th International Conference on Computational Science and Engineering (CSE 2011). 11th International Symposium on Pervasive Systems, Algorithms, Networks (I-SPAN 2011). 10th IEEE International Conference on Ubiquitous Computing and Communications (IUCC 2011), P57, DOI 10.1109/CSE.2011.24
   Spaulding J, 2002, PATTERN RECOGN LETT, V23, P1579, DOI 10.1016/S0167-8655(02)00122-8
   Stanescu D, 2007, SACI 2007: 4TH INTERNATIONAL SYMPOSIUM ON APPLIED COMPUTATIONAL INTELLIGENCE AND INFORMATICS, PROCEEDINGS, P241, DOI 10.1109/SACI.2007.375518
   Subhedar MS, 2014, COMPUT SCI REV, V13-14, P95, DOI 10.1016/j.cosrev.2014.09.001
   Sun SL, 2015, ADV MULTIMED, V2015, DOI 10.1155/2015/698492
   Tadiparthi GR, 2008, DECIS SUPPORT SYST, V45, P937, DOI 10.1016/j.dss.2008.03.005
   Tew Y, 2014, IEEE T CIRC SYST VID, V24, P305, DOI 10.1109/TCSVT.2013.2276710
   Thiesse Jean-Marc, 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P217, DOI 10.1109/MMSP.2010.5662022
   Thiesse JM, 2010, IEEE IMAGE PROC, P2861, DOI 10.1109/ICIP.2010.5652005
   Thiesse JM, 2011, IEEE T CIRC SYST VID, V21, P729, DOI 10.1109/TCSVT.2011.2130330
   Wang Jue, 2011, 2011 IEEE 3rd International Conference on Communication Software and Networks (ICCSN 2011), P500, DOI 10.1109/ICCSN.2011.6013642
   WANG R., 2011, J. Comput. Inform. Syst, V7, P2132
   Wang XY, 2013, J SYST SOFTWARE, V86, P255, DOI 10.1016/j.jss.2012.08.015
   Wedi T, 2002, 2002 P INT C IM PROC
   Xu CY, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 1, PROCEEDINGS, P269
   Yang GB, 2011, AEU-INT J ELECTRON C, V65, P331, DOI 10.1016/j.aeue.2010.03.011
   Yilmaz A, 2003, 2003 P INT C IM PROC, V3
   Zhang RY, 2012, IEEE T INFORM THEORY, V58, P7272, DOI 10.1109/TIT.2012.2217072
   Zhang RY, 2009, LECT NOTES COMPUT SC, V5806, P48, DOI 10.1007/978-3-642-04431-1_4
   Zhang Wei., 2005, IEEE International Conference on Image Processing 2005, V3, pII, DOI [DOI 10.1109/ICIP.2005.1530530, 10.1109/ICIP.2005.1530530]
   Zhang X, 2012, METHOD APPARATUS INT
   Zhu H., 2010, Proc. 3rd Int.Congr. Image Signal Process., V1, P487
NR 115
TC 35
Z9 36
U1 1
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21749
EP 21786
DI 10.1007/s11042-016-4055-1
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400064
DA 2024-07-18
ER

PT J
AU Pedrosa, GV
   Traina, AJM
   Barcelos, CAZ
AF Pedrosa, Glauco V.
   Traina, Agma J. M.
   Barcelos, Celia A. Z.
TI Retrieving 2D shapes by similarity based on bag of salience points
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bag-of-words; Image features; Shape descriptor; Salient points
ID ROBUST; RECOGNITION; DESCRIPTOR; EFFICIENT
AB This paper proposes a novel shape feature description based on salient points, called Bag-of-Salience-Points (BoSP). The proposed descriptor is compact and provides a fast solution for finding the correspondences of two set of salient points, contributing to speed-up the task of shape matching. The novelty of the proposed descriptor lies in combining local sparse features (salient points) encoded in global and spatial-based histograms with a few other shape factors like eccentricity. The proposed shape descriptor retrieves the best matching, even in occlusions situations, where points in the two shapes cannot be properly matched. The BoSP is validated on several benchmark datasets for 2D shape matching algorithms, and it is observed that the BoSP maintains superior discriminative, while being invariant to geometric transformations as well as demanding a low computational cost to measure the similarity of shapes.
C1 [Pedrosa, Glauco V.] UEG, Santa Helena, Go, Brazil.
   [Traina, Agma J. M.] Univ Sao Paulo, Sao Carlos, SP, Brazil.
   [Barcelos, Celia A. Z.] Univ Fed Uberlandia, Uberlandia, MG, Brazil.
C3 Universidade de Sao Paulo; Universidade Federal de Uberlandia
RP Pedrosa, GV (corresponding author), UEG, Santa Helena, Go, Brazil.
EM glauco.pedrosa@ueg.br; agma@icmc.usp.br
RI Pedrosa, Glauco V/J-8869-2012; Traina, Agma/F-1299-2011
OI Pedrosa, Glauco Vitor/0000-0001-5573-6830; Traina,
   Agma/0000-0003-4929-7258
FU FAPESP; CNPq; CAPES; SticAMSUD; RESCUER project - European Commission
   [614154]; Brazilian National Council for Scientific and Technological
   Development CNPq/MCTI
FX This work is supported, in part, by FAPESP, CNPq, CAPES, SticAMSUD, the
   RESCUER project, funded by the European Commission (Grant 614154) and by
   the Brazilian National Council for Scientific and Technological
   Development CNPq/MCTI.
CR Alajlan N, 2008, IEEE T PATTERN ANAL, V30, P1003, DOI 10.1109/TPAMI.2008.37
   Andaló FA, 2010, PATTERN RECOGN, V43, P26, DOI 10.1016/j.patcog.2009.06.012
   [Anonymous], 2007, 2007 IEEE C COMP VIS, DOI 10.1109/CVPR.2007.383018
   Arica N, 2003, PATTERN RECOGN LETT, V24, P1627, DOI 10.1016/S0167-8655(03)00002-3
   Arulmozhi P., 2014, INT J COMP SCI ENG, V6, P14
   Bai X, 2008, IEEE T PAMI, V30
   Bai X, 2014, IEEE T IMAGE PROCESS, V23, P3935, DOI 10.1109/TIP.2014.2336542
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bicego M, 2004, IEEE T PATTERN ANAL, V26, P281, DOI 10.1109/TPAMI.2004.1262200
   Biswas S, 2010, IEEE T MULTIMEDIA, V12, P372, DOI 10.1109/TMM.2010.2050735
   Bober M, 2001, IEEE T CIRC SYST VID, V11, P716, DOI 10.1109/76.927426
   Chen Y, 2014, IEEE T MED IMAGING, V33, P2271, DOI 10.1109/TMI.2014.2336860
   Daliri MR, 2008, PATTERN RECOGN, V41, P1782, DOI 10.1016/j.patcog.2007.10.020
   Dalitz C, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-161
   Ding CX, 2015, IEEE T IMAGE PROCESS, V24, P980, DOI 10.1109/TIP.2015.2390959
   Hu R, 2010, IEEE IMAGE PROC, P1025, DOI 10.1109/ICIP.2010.5649331
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Kovács A, 2009, IEEE IMAGE PROC, P1105, DOI 10.1109/ICIP.2009.5413448
   Latecki LJ, 2000, IEEE T PATTERN ANAL, V22, P1185, DOI 10.1109/34.879802
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li ZY, 2012, INT CONF SIGN PROCES, P1096, DOI 10.1109/ICoSP.2012.6491769
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Liu J, 2015, NEUROCOMPUTING, V147, P435, DOI 10.1016/j.neucom.2014.06.041
   Liu MZ, 2010, PROC CVPR IEEE, P3463, DOI 10.1109/CVPR.2010.5539979
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mei Y, 2009, IEEE SIGNAL PROC LET, V16, P877, DOI 10.1109/LSP.2009.2026119
   Mokhtarian F, 1998, IEEE T PATTERN ANAL, V20, P1376, DOI 10.1109/34.735812
   Pedrosa GV, 2010, PATTERN RECOGN LETT, V31, P1658, DOI 10.1016/j.patrec.2010.05.013
   Qin C, 2016, INFORM SCIENCES, V361, P84, DOI 10.1016/j.ins.2016.04.036
   Qin C, 2013, DIGIT SIGNAL PROCESS, V23, P578, DOI 10.1016/j.dsp.2012.11.002
   Schmidt FR, 2009, PROC CVPR IEEE, P351, DOI 10.1109/CVPRW.2009.5206863
   Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Thakoor N, 2007, IEEE T IMAGE PROCESS, V16, P2707, DOI 10.1109/TIP.2007.908076
   Torres RD, 2004, PATTERN RECOGN, V37, P1163, DOI 10.1016/j.patcog.2003.10.007
   Tu ZW, 2004, LECT NOTES COMPUT SC, V3023, P195
   Wang JW, 2012, PATTERN RECOGN LETT, V33, P134, DOI 10.1016/j.patrec.2011.09.042
   Wang ZZ, 2010, IEEE SIGNAL PROC LET, V17, P803, DOI 10.1109/LSP.2010.2057506
   Xu CJ, 2009, IEEE T PATTERN ANAL, V31, P180, DOI 10.1109/TPAMI.2008.199
   You J, 2000, P 15 INT C PATT REC, V1
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 41
TC 2
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 20957
EP 20971
DI 10.1007/s11042-016-4046-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400028
DA 2024-07-18
ER

PT J
AU Zheng, JQ
   Feng, ZY
   Xu, C
   Hu, J
   Ge, WM
AF Zheng, Jinqing
   Feng, Zhiyong
   Xu, Chao
   Hu, Jing
   Ge, Weimin
TI Fusing shape and spatio-temporal features for depth-based dynamic hand
   gesture recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamichandgesture recognition; Depthsequences; DLEH2; Depthmotionmaps;
   DLE; HOG(2)
ID MOTION MAP; HISTOGRAMS; GRADIENTS
AB Hand gesture recognition has many practical applications including human-computer interfaces. Many depth-based features for dynamic hand gesture recognition task have been proposed. However the performance is still unsatisfactory due to the limitation that these features can't efficiently capture both effective shape information and detailed variation of hands in spatial and temporal domains. In this paper, we propose a new effective descriptor, DLEH2, for depth-based dynamic hand gesture recognition which is developed based on the characteristics of dynamic hand gesture through fusing simple shape and spatio-temporal features of depth sequences. For shape information, depth motion maps (DMMs) are first employed to obtain 3D structure and shape information of hands. To enhance critical shape cues, the local texture and edge information of three DMMs for hand gesture sequences are captured using DLE descriptor. However, DMMs compress the temporal information of the depth sequences into space domain, which loses critical discrimination for temporal sequence recognition to some degree. Simple but effective spatio-temporal features, HOG(2), are concatenated with DLE to compensate the temporal information loss during DMMs generation and capture the detailed spatial and temporal variation of hands. Experimental results on two public benchmark datasets, 99.10 % for MSRGesture3D dataset and 98.43 % for SKIG dataset, show that the proposed fusion scheme outperforms the state-of-the-art methods.
C1 [Zheng, Jinqing; Hu, Jing; Ge, Weimin] Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.
   [Feng, Zhiyong; Xu, Chao] Tianjin Univ, Sch Comp Software, Tianjin 300072, Peoples R China.
C3 Tianjin University; Tianjin University
RP Zheng, JQ (corresponding author), Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.
EM cszjq@tju.edu.cn
RI Gulliver, Aaron/K-7925-2012
OI Zheng, Jinqing/0000-0002-1772-0085
FU National Natural Science Foundation of China [61304262]
FX This work was partially supported by the National Natural Science
   Foundation of China (no. 61304262).
CR [Anonymous], 2014, P 2 INT C HUM AG INT
   [Anonymous], IJCAI
   [Anonymous], P 5 S INF COMM TECHN
   [Anonymous], PAC RIM S IM VID TEC
   [Anonymous], MULTIMED TOOLS APPL
   Bandera JP, 2009, PATTERN RECOGN LETT, V30, P1181, DOI 10.1016/j.patrec.2009.05.017
   Bulbul Mohammad Farhad, 2015, Intelligent Computing Theories and Methodologies. 11th International Conference, ICIC 2015. Proceedings: LNCS 9225, P271, DOI 10.1007/978-3-319-22180-9_27
   Bulbul MF, 2015, INT J MULTIMED DATA, V6, P23, DOI 10.4018/IJMDEM.2015100102
   Chen C, 2015, IEEE WINT CONF APPL, P1092, DOI 10.1109/WACV.2015.150
   Chen CF, 2013, ISPRS J PHOTOGRAMM, V82, P1, DOI 10.1016/j.isprsjprs.2013.05.001
   Cirujeda Pol, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P657, DOI 10.1109/3DV.2014.10
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Hong Pengyu, 2000, P 4 IEEE INT C AUT F, P410
   Kurakin A, 2012, EUR SIGNAL PR CONF, P1975
   Li W, 2015, IEEE T GEOSCI REMOTE, V53, P3681, DOI 10.1109/TGRS.2014.2381602
   Liang B, 2015, IEEE IMAGE PROC, P2070, DOI 10.1109/ICIP.2015.7351165
   Liu MY, 2016, NEUROCOMPUTING, V175, P747, DOI 10.1016/j.neucom.2015.11.005
   Madany E, 2015, MULTIMED SIGN PROCES, P1
   Ohn-Bar E, 2013, IEEE COMPUT SOC CONF, P465, DOI 10.1109/CVPRW.2013.76
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Rahmani H, 2014, IEEE WINT CONF APPL, P626, DOI 10.1109/WACV.2014.6836044
   Ramamoorthy A, 2003, PATTERN RECOGN, V36, P2069, DOI 10.1016/S0031-3203(03)00042-6
   Santos DG, 2015, SENSORS-BASEL, V15, P28646, DOI 10.3390/s151128646
   Shen XH, 2012, IMAGE VISION COMPUT, V30, P227, DOI 10.1016/j.imavis.2011.11.003
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Suk H.I., 2008, 8 IEEE INT C AUTOMAT, P1
   Tran QD, 2013, PROCEEDINGS OF 2013 IEEE RIVF INTERNATIONAL CONFERENCE ON COMPUTING AND COMMUNICATION TECHNOLOGIES: RESEARCH, INNOVATION, AND VISION FOR THE FUTURE (RIVF), P253, DOI 10.1109/RIVF.2013.6719903
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang S.B., 2006, P IEEE COMP SOC C CO
   Wang XY, 2012, MATH PROBL ENG, V2012, DOI 10.1155/2012/986134
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108
   Zhang CY, 2013, IEEE COMPUT SOC CONF, P500, DOI 10.1109/CVPRW.2013.80
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhu Y, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2629483
NR 40
TC 14
Z9 16
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 20525
EP 20544
DI 10.1007/s11042-016-3988-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400007
DA 2024-07-18
ER

PT J
AU Jeong, ES
   Kim, IS
   Lee, D
AF Jeong, Eun Su
   Kim, In Seok
   Lee, Dong Hoon
TI SafeGuard: a behavior based real-time malware detection scheme for
   mobile multimedia applications in android platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Android malware detection; Mobile multimedia application; Behavior
   detection; Android platform; Mobile security
AB SafeGuard is proposed as a solution to monitor behaviors of smartphone applications in real-time and detect and block any malicious behaviors. This solution consists of a server that manages and deploys the blocking rules and the device solution that monitors various applications in Android devices. The proposed scheme provides users with real-time malware information such as spyware detected by the SafeGuard library upon suspicious API call within the Android platform. Except for use of Rootkit at the kernel level, the scheme can detect behaviors that use the API from the platform or caused by a combination of those APIs. The database that determines any malicious behaviors can be periodically updated to block various malicious behaviors by using preemptive responses different from existing anti-virus products. For this purpose, the behaviors of smartphone applications are classified and are defined for monitoring. The architecture to apply them is also proposed in the Android framework and the proposed scheme is applied in the Android smartphone environment to verify its stability and feasibility through measuring the overhead in the environment.
C1 [Jeong, Eun Su] SK Planet Co Ltd, 264 Pangyo Ro, Seongnam Si, Gyeonggi Do, South Korea.
   [Kim, In Seok; Lee, Dong Hoon] Korea Univ, CIST, Seoul, South Korea.
C3 Korea University
RP Lee, D (corresponding author), Korea Univ, CIST, Seoul, South Korea.
EM eunsu.jeong@sk.com; iskim11@korea.ac.kr; donghlee@korea.ac.kr
FU ICT R&D program of MSIP/IITP [R0101-15-0195(10043959)]
FX This work was supported by the ICT R&D program of MSIP/IITP.
   [R0101-15-0195(10043959), Development of EAL 4 level military fusion
   security solution for protecting against unauthorized accesses and
   ensuring a trusted execution environment in mobile devices
CR [Anonymous], 2010, P 9 USENIX C OP SYST
   Blasing T, 2010, P 5 INT C MAL UNW SO, P55
   Burguera I., 2011, P 1 ACM WORKSH SEC P, P15, DOI DOI 10.1145/2046614.2046619
   Chan PPK, 2014, INT CONF MACH LEARN, P82, DOI 10.1109/ICMLC.2014.7009096
   Di Cerbo F, 2011, LECT NOTES COMPUT SC, V6540, P138, DOI 10.1007/978-3-642-19376-7_12
   Fuchs A. P., 2009, CSTR4991 U MAR DEP C
   Isohara T., 2011, Proceedings of the 2011 Seventh International Conference on Computational Intelligence and Security (CIS 2011), P1011, DOI 10.1109/CIS.2011.226
   Jang JW, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P737, DOI 10.1145/2567948.2579366
   Juniper Networks Inc, 2011, MAL MOB THREATS REP
   Kim S, 2012, COMPUTER SCI CONVERG, P529
   Manjunath V., 2011, REVERSE ENG MALWARE
   NQ Mobile's Security Lab, 2012, NQ MOB 2012 SEC REP, P1
   Rastogi V., 2013, P 3 ACM C DAT APPL S, P209
   Retina-X Studios, 2009, ANDR MOB SPY SOFTW
   Wu DJ, 2012, ASIA JT CONF INF SEC, P62, DOI 10.1109/AsiaJCIS.2012.18
   Wu LF, 2014, IEEE COMMUN MAG, V52, P80, DOI 10.1109/MCOM.2014.6766089
   Zhao M, 2011, COMM COM INF SC, V243, P158
   Zhou Y, 2012, P 19 ANN NETW SYST S
NR 18
TC 5
Z9 6
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 18153
EP 18173
DI 10.1007/s11042-016-4189-1
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800032
DA 2024-07-18
ER

PT J
AU Kuang, YT
   Singh, R
   Singh, S
   Singh, P
AF Kuang, Yuting
   Singh, Ritika
   Singh, Saumya
   Singh, Prakash
TI A novel macroeconomic forecasting model based on revised multimedia
   assisted BP neural network model and ant Colony algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Macroeconomic forecasting; Model analysis; BP neural network;
   Multimedia; Ant Colony algorithm; Numerical simulation
ID AUTOREGRESSIVE MODELS; DSGE MODEL; OPTIMIZATION; HYBRID; PREDICTION;
   SELECTION
AB In this paper, we propose a novel macroeconomic forecasting model based on the revised multimedia assisted BP neural network model and the ant colony algorithm. Macroeconomic forecasting foundation forecasts the object past and present operating law, therefore, when the operational predict that must describe the analysis and this rule. Because the limitation and forecast technique of choice fault forecast technique can create the uncertainty of the forecasting result, our model mainly focus on the following two aspects. (1) Uncertainty in forecasting method selection errors is even more evident. The probability that the wrong prediction method brings the correct prediction result is very small. (2) Limitations of the forecasting methods. Any kind of forecasting method has its applicable conditions and the environment, it is not omnipotent, nor is it immutable, therefore, more of the state-of-the-art techniques should be researched to enhance the traditional approaches. We use the ant colony algorithm to modify the BP model to make it fit for holding the character that forecasting that a point refers to forecasting a definite value, this value and actual value completely same possibility is very low, this explained that a point forecast successful probability is very low, therefore uses the forecasting result judgement forecast method the fit and unfit quality to be not very comprehensive. Forecast that a sector refers to the future reality leaving in the prediction interval, or prediction interval including the future realistic value which will hold special meaning. The experiment on the stock, gold, exchange and inflation indicate that the proposed model can predict the price well with the satisfactory result.
C1 [Kuang, Yuting] Hunan Womens Univ, Zhongyi 1st Rd, Changsha 410004, Hunan, Peoples R China.
   [Singh, Ritika] Amity Univ, Noida, India.
   [Singh, Saumya] Indian Sch Mines, Dept Management Studies, Dhanbad, Bihar, India.
   [Singh, Prakash] Cognizant, Teaneck, NJ USA.
C3 Amity University Noida; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (Indian School of Mines) Dhanbad
RP Kuang, YT (corresponding author), Hunan Womens Univ, Zhongyi 1st Rd, Changsha 410004, Hunan, Peoples R China.
EM kuangyutingchina@126.com; saumyasingh@rediffmail.com; spvatsa@gmail.com
RI Singh, Saumya/AAD-9056-2020
OI Singh, Saumya/0000-0001-7726-6104
CR Ahmed N, 2016, FRONT COMPUT NEUROSC, V10, DOI 10.3389/fncom.2016.00024
   Bui AT, 2016, STUD ECON FINANC, V33, P417, DOI 10.1108/SEF-05-2014-0089
   [Anonymous], 2012, J. Pet Environ. Biotechnol
   Athanasopoulos G, 2012, J BUS EC STAT
   Berge TJ, 2015, J FORECASTING, V34, P455, DOI 10.1002/for.2345
   Billio M, 2013, J FORECASTING, V32, P577, DOI 10.1002/for.2260
   Capecci E, 2016, 2016 INT JOINT C NEU
   Chang WY, 2013, INT J ELEC POWER, V53, P603, DOI 10.1016/j.ijepes.2013.05.038
   Chen Q, 2014, INT C LIF SYST MOD S
   Ciornei I, 2012, IEEE T SYST MAN CY B, V42, P234, DOI 10.1109/TSMCB.2011.2164245
   Clark TE, 2012, J BUS EC STAT
   Clements MP, 2013, J APPL ECONOMET, V28, P458, DOI 10.1002/jae.2274
   Cubadda G, 2012, ECON MODEL, V29, P1099, DOI 10.1016/j.econmod.2012.03.027
   D'Agostino A, 2012, OXFORD B ECON STAT, V74, P306, DOI 10.1111/j.1468-0084.2011.00642.x
   Eickmeier S, 2015, J R STAT SOC A STAT, V178, P493, DOI 10.1111/rssa.12068
   Farhana NIE, 2016, COMPOS STRUCT, V144, P96, DOI 10.1016/j.compstruct.2016.02.066
   Ferrara L, 2015, INT J FORECASTING, V31, P664, DOI 10.1016/j.ijforecast.2014.11.005
   Ferraro D, 2015, J INT MONEY FINANC, V54, P116, DOI 10.1016/j.jimonfin.2015.03.001
   Franses PH, 2012, EVALUATING MACROECON
   Groen JJJ, 2013, OXFORD B ECON STAT, V75, P37, DOI 10.1111/j.1468-0084.2012.00721.x
   Gu LZ, 2016, J MANUF SCI E-T ASME, V138, DOI 10.1115/1.4033156
   Hagenau M, 2013, DECIS SUPPORT SYST, V55, P685, DOI 10.1016/j.dss.2013.02.006
   Herbst E, 2012, J ECONOMETRICS, V171, P152, DOI 10.1016/j.jeconom.2012.06.008
   Huang T, 2014, EUR J OPER RES, V237, P738, DOI 10.1016/j.ejor.2014.02.022
   Jiang Y, 2013, RENEW ENERG, V50, P637, DOI 10.1016/j.renene.2012.07.041
   Kefayat M, 2015, ENERG CONVERS MANAGE, V92, P149, DOI 10.1016/j.enconman.2014.12.037
   Kenow KP, 2016, J GREAT LAKES RES, V42, P637, DOI 10.1016/j.jglr.2016.02.014
   Kiran MS, 2012, ENERG CONVERS MANAGE, V53, P75, DOI 10.1016/j.enconman.2011.08.004
   Knüppel M, 2015, J BUS ECON STAT, V33, P270, DOI 10.1080/07350015.2014.948175
   Kosek AM, 2016, CONTEXTUAL ANOMALY D
   Kristjanpoller W, 2015, EXPERT SYST APPL, V42, P7245, DOI 10.1016/j.eswa.2015.04.058
   Li JH, 2014, INT J FORECASTING, V30, P996, DOI 10.1016/j.ijforecast.2014.03.016
   Li YH, 2015, J ACCOUNT RES, V53, P79, DOI 10.1111/1475-679X.12068
   Li Z, 2016, BIOMED RES INT, V2016, P6
   Liao TJ, 2014, EUR J OPER RES, V234, P597, DOI 10.1016/j.ejor.2013.10.024
   Linsefors L, 2013, PHYS REV D, V87, DOI 10.1103/PhysRevD.87.123509
   Magud NE, 2014, REV DEV ECON, V18, P415, DOI 10.1111/rode.12093
   Marcellino M, 2014, J FORECASTING, V33, P315, DOI 10.1002/for.2306
   Mitra S., 2016, Computer, Electrical Communication Engineering (ICCECE), 2016 International Conference on, P1
   Nan Ye, 2015, 2015 12 INT C FUZZ S
   Orlov AA, 2013, BRAIN, V900, P100
   Pan YQ, 2013, ADV BUS MANAG FORECA, V9, P153, DOI 10.1108/S1477-4070(2013)0000009013
   Pettenuzzo D, 2016, J APPL ECONOMET, V31, P1312, DOI 10.1002/jae.2502
   Price LC, 2015, PHYS REV LETT, V114, DOI 10.1103/PhysRevLett.114.031301
   Riahi V, 2016, OPERATIONAL RES, P1
   Rossi B, 2013, J ECON LIT, V51, P1063, DOI 10.1257/jel.51.4.1063
   Saghatforoush A, 2016, ENG COMPUT-GERMANY, V32, P255, DOI 10.1007/s00366-015-0415-0
   Stock JH, 2015, HDB MACROEC IN PRESS
   Neto RFT, 2013, ENG APPL ARTIF INTEL, V26, P150, DOI 10.1016/j.engappai.2012.03.011
   Wang J, 2015, 2015 I E INT C SYST
   Wang J, 2014, ATMOS RES, V137, P245, DOI 10.1016/j.atmosres.2013.10.014
   Wang Kuo-Yan, 2016, Univ. J. Manag., V4, P223, DOI DOI 10.13189/UJM.2016.040501
   Wang T, 2016, IEEE T NEUR NET LEAR, V27, P416, DOI 10.1109/TNNLS.2015.2411671
   Wang Ya-li, 2014, Journal of China Universities of Posts and Telecommunications, V21, P43, DOI 10.1016/S1005-8885(14)60267-3
   Yan S, 2013, 2013 INT C INSTR MEA
   Yang SJ, 2014, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON TEACHING AND COMPUTATIONAL SCIENCE, P1
   Yaziz SR, 2015, AIP CONF PROC, V1643, P289, DOI 10.1063/1.4907458
   Zeng D, 2012, 2012 I E INT C ROB B
   Zhang B, 2014, J QUANT SPECTROSC RA, V133, P351, DOI 10.1016/j.jqsrt.2013.08.020
   Zhang L-P, 2016, 2016 12 C INT CONTR
   Zhang SK, 2016, INT J COMPUT INTELL, V15, DOI 10.1142/S1469026816500139
   Zhang YX, 2015, J MANUF SYST, V34, P53, DOI 10.1016/j.jmsy.2014.10.005
   Zhuo L, 2014, NEUROCOMPUTING, V134, P111, DOI 10.1016/j.neucom.2012.12.080
NR 63
TC 16
Z9 19
U1 0
U2 49
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18749
EP 18770
DI 10.1007/s11042-016-4319-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800029
DA 2024-07-18
ER

PT J
AU Li, G
   Li, CH
   Zhu, YP
   Huang, FJ
AF Li Gun
   Li Cuihua
   Zhu Yingpan
   Huang Feijiang
TI An improved speckle-reduction algorithm for SAR images based on
   anisotropic diffusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SAR images; Anisotropic diffusion; Curvature drive; Denoising
ID ENHANCEMENT
AB This paper mainly studies the algorithm of anisotropic diffusion for speckle noise removal of SAR images. Because the Gauss curvature driven diffusion method is sensitive to the noise and is of low efficiency on suppressing the speckle noise, an improved denoising algorithm is proposed. The new algorithm introduces the difference curvature as the diffusion coefficients of the function, which solves the problem that Gauss curvature driven diffusion is sensitive to the speckle noise, further, Tukey's biweight function is used to control the curvature diffusion model, which can not only better protect edges, but also automatically control the diffusion. Numerical experiments show that the improved algorithm can preserve the information of textures, edges while inhibiting the speckle of SAR images.
C1 [Li Gun; Li Cuihua; Zhu Yingpan] Univ Elect Sci & Technol China, Sch Aeronaut & Astronaut, Chengdu 611731, Sichuan, Peoples R China.
   [Huang Feijiang] Changsha Univ, Dept Elect Informat & Elect Engn, Changsha 410022, Hunan, Peoples R China.
C3 University of Electronic Science & Technology of China; Changsha
   University
RP Li, G (corresponding author), Univ Elect Sci & Technol China, Sch Aeronaut & Astronaut, Chengdu 611731, Sichuan, Peoples R China.
EM ligun@uestc.edu.cn; ccsuhfj@163.com
FU National Natural Science Foundation of People's Republic of China
   [91026005]
FX This work was supported by the National Natural Science Foundation of
   People's Republic of China (Grant No. 91026005). I wish to thank
   Professor Wang LingYan who has contributed to the paper improvement.
CR Alberto M, 1991, IEEE T GEOSCI REMOTE, V23, P534
   [Anonymous], 1998, Understanding synthetic aperture radar images
   Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192
   CATTE F, 1992, SIAM J NUMER ANAL, V29, P182, DOI 10.1137/0729012
   Chakrabarti S, 2014, INT J REMOTE SENS, V35, P1804, DOI 10.1080/01431161.2013.879346
   Charbonnier P, 1997, IEEE T IMAGE PROCESS, V6, P298, DOI 10.1109/83.551699
   Chen Q, 2010, IMAGE VISION COMPUT, V28, P298, DOI 10.1016/j.imavis.2009.04.012
   Di Martino G, 2014, IEEE T GEOSCI REMOTE, V52, P1615
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   ElFallah AI, 1997, IEEE T IMAGE PROCESS, V6, P750, DOI 10.1109/83.568931
   Fabbrini L, 2013, ELECTRON LETT, V49, P672, DOI 10.1049/el.2012.3851
   Fan H, 2014, J INF COMPUT SCI, V11, P2283
   Frost VS, IEEE T, V166
   Gao QW, 2013, SIGNAL PROCESS, V93, P1056, DOI 10.1016/j.sigpro.2012.11.028
   Gupta A, ADV INTELL SYST, V754
   Gupta A, 2013, IEEE INT ADV COMPUT, P1257
   Hua X, IEEE T GEOSCI, V2211
   Huang Qian, 2006, Acta Electronica Sinica, V34, P1553
   Jidesh P, 2014, J CHIN INST ENG, V37, P122, DOI 10.1080/02533839.2012.751332
   [金添 Jin Tian], 2008, [电子与信息学报, Journal of Electronics & Information Technology], V30, P925
   Kuan DT, IEEE T PATTERN ANAL, V177
   LEE JS, 1980, IEEE T PATTERN ANAL, V2, P165, DOI 10.1109/TPAMI.1980.4766994
   Lee SH, 2005, IEEE T IMAGE PROCESS, V14, P904, DOI 10.1109/TIP.2005.849294
   Li X, 2005, IEEE T CIRC SYST VID, V15, P108, DOI 10.1109/TCSVT.2004.836743
   Lopes A, P IGARSS 90, P2412
   Lu B, 2011, MULTIMEDIA TECHNOLOG, P5891
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Yezzi A, 1998, IEEE T IMAGE PROCESS, V7, P345, DOI 10.1109/83.661184
   Yu YJ, 2002, IEEE T IMAGE PROCESS, V11, P1260, DOI 10.1109/TIP.2002.804279
NR 30
TC 11
Z9 11
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 17615
EP 17632
DI 10.1007/s11042-015-2810-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800001
DA 2024-07-18
ER

PT J
AU Rai, A
   Singh, HV
AF Rai, Ankur
   Singh, Harsh Vikram
TI SVM based robust watermarking for enhanced medical image security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DICOM; ROI&NROI; Discrete wavelet transform; Singular value
   decomposition; Image classification; Support vector machine
ID MULTIPLE WATERMARKING; PROTECTION; SCHEME
AB Medical images are more typical than any other ordinary images, since it stores patient's information for diagnosis purpose. Such images need more security and confidentiality as total diagnosis depends on it. In telemedicine applications, transmission of medical image via open channel, demands strong security and copyright protection. In our proposed robust watermarking model, a double layer security is introduced to ensure the robustness of embedded data. The embedded data is scrambled using a unique key and then a transform domain based hybrid watermarking technique is used to embed the scrambled data into the transform coefficients of the host image. The data embedding in medical images involves more attention, so that the diagnosis part must not be affected by any modification. Therefore, Support Vector Machine (SVM) is used as a classifier, which classify a medical image into two regions i.e. Non Region of Interest (NROI) and Region of Interest (ROI) to embed watermark data into the NROI part of the medical image, using the proposed embedding algorithm. The objective of the proposed model is to avoid any quality degradation to the medical image. The simulation is performed to measure the Peak Signal to Noise Ratio (PSNR) for imperceptibility and Structural Similarity Index (SSIM) to test the robustness. The experimented result shows, robustness and imperceptibility with SSIM of more than 0.50 and PSNR of more than 35 dB for proposed watermarking model.
C1 [Rai, Ankur; Singh, Harsh Vikram] KNIT, Dept Elect Engn, Sultanpur, UP, India.
C3 Kamla Nehru Institute of Technology Sultanpur
RP Rai, A (corresponding author), KNIT, Dept Elect Engn, Sultanpur, UP, India.
EM ankur_rai@knit.ac.in; harshvikramsingh@knit.ac.in
RI Singh, Harsh Vikram/Q-9457-2019; Rai, Ankur/H-4859-2016
OI Singh, Harsh Vikram/0000-0002-8904-862X; Rai, Ankur/0000-0001-7919-1775
CR [Anonymous], TAMKANG J SCI ENG
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Cao XB, 2009, INFORM SCIENCES, V179, P1070, DOI 10.1016/j.ins.2008.10.020
   Chandra Munesh, 2010, 2010 International Conference on Electronics and Information Engineering (ICEIE 2010), P421, DOI 10.1109/ICEIE.2010.5559809
   Chiang KH, 2008, J DIGIT IMAGING, V21, P77, DOI 10.1007/s10278-007-9012-0
   Dey N, 2013, INT J COMPUTER APPL, V36
   Divecha N. H., 2012, IJCA P NAT C INN PAR
   Eswaraiah R, 2014, 4 INT C COMM SYST NE
   Fernandes F. C. A., 2002, AC SPEECH SIGN PROC
   Ganic Emir, 2004, P 2004 WORKSHOP MULT, P166, DOI DOI 10.1145/1022431.1022461
   Giakoumaki A, 2003, P ANN INT IEEE EMBS, V25, P856, DOI 10.1109/IEMBS.2003.1279900
   Giakoumaki A, 2006, IEEE T INF TECHNOL B, V10, P722, DOI 10.1109/TITB.2006.875655
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Lee HK, 2005, 2005 ASIA-PACIFIC CONFERENCE ON COMMUNICATIONS (APCC), VOLS 1& 2, P512, DOI 10.1109/APCC.2005.1554112
   Lee HK, 2005, AS PAC C COMM PERTH, P3
   Lin TC, 2009, INFORM SCIENCES, V179, P3349, DOI 10.1016/j.ins.2009.05.022
   Malvar HS, 2003, IEEE T SIGNAL PROCES, V51, P898, DOI 10.1109/TSP.2003.809385
   Memon Nisar A., 2009, 2009 3rd International Conference on Information and Communication Technologies (ICICT), P175, DOI 10.1109/ICICT.2009.5268167
   Memon N. A., 2009, 2009 IEEE 13 INT MUL, P1
   Planitz B. M., 2005, P DICTA
   Ramly S, 2011, COMM COM INF SC, V194, P372
   Rathi S., 2012, INT J HLTH INF, V1, P27, DOI DOI 10.5281/zenodo.1240669
   Raul R.-C., 2007, Electronics, Communications and Computers, P32, DOI [DOI 10.1109/CONIELECOMP.2007.14, 10.1109/CONIELECOMP.2007.14]
   Ruanaidh JJKO, 1998, SIGNAL PROCESS, V66, P303, DOI 10.1016/S0165-1684(98)00012-7
   Sang J, 2008, IEEE T INSTRUM MEAS, V57, P595, DOI 10.1109/TIM.2007.911585
   Seetha M., 2007, MAP WORLD FORUM
   Shao Y, 2008, CCDC
   Sharma A, 2016, WIREL PERS COMMUN
   Singh A K, 2015, WIREL PERS COMMUN
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P607, DOI 10.1166/jmihi.2015.1432
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P406, DOI 10.1166/jmihi.2015.1407
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Singh AP, 2011, INDIAN J COMPUT SCI
   Singh H. V., 2010, INT J INFORM SCI APP, V2, P591
   Singh HV, 2013, INT J ELECTRON SECUR, V5, P218, DOI 10.1504/IJESDF.2013.058655
   Singh HV., 2014, CSI T ICT, V2, P163
   Tiwari N, 2013, ADV COMP C IACC IEEE
   Tsai HH, 2007, INFORM SCIENCES, V177, P550, DOI 10.1016/j.ins.2006.05.002
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu HT, 2010, IEEE T INSTRUM MEAS, V59, P221, DOI 10.1109/TIM.2009.2022453
   Yadav Rajesh K, 2012, INT J ENG SCI TECHNO, P1
   Zain J.M., 2005, 3 INT C SCI EL TECHN
   Zear A, 2016, J Intell Syst
   Zear A, 2016, MULTIMEDIA TOOLS APP
   Zhou Y., 2012, INT C TECHN INF ICSA
   Zhou Z. B., 2006, P 6 WORLD C INT CONT
NR 47
TC 23
Z9 23
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18605
EP 18618
DI 10.1007/s11042-016-4215-3
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800022
DA 2024-07-18
ER

PT J
AU Singh, AK
   Baranwal, N
   Nandi, GC
AF Singh, Avinash Kumar
   Baranwal, Neha
   Nandi, G. C.
TI Development of a self reliant humanoid robot for sketch drawing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE NAO humanoid robot; Sketch drawing; Inverse kinematics; Gradient descent
AB This paper demonstrates the capability of humanoid robot in the field of sketch drawing. Sketch drawing is a complex job which requires three basic problems to be solved. The first problem is to extract prominent features (the image point) of the object shown. Second is to define the image points lying on the Humanoid's camera plane with respect to its end effector position. The third problem is to provide the inverse kinematic solution and control strategy for smooth drawing. A H25 NAO humanoid robot is used as a test-bed in this paper to conduct this experiment and illustrate the whole process. A calibration matrix is defined which transforms image points in NAO body coordinate system while inverse kinematics has been solved using a gradient descent numerical method. The analytical solution of the inverse kinematics for NAO's hands are not suitable due to its mechanical design which is not following the piper's recommendation. The Denavit-Hartenberg (DH) parameters of the system has been defined in order to measure the working envelope of the right hand as well as to avoid singularities.
C1 [Singh, Avinash Kumar; Baranwal, Neha; Nandi, G. C.] Indian Inst Informat Technol, Robot & Artificial Intelligence Lab, Allahabad 211012, Uttar Pradesh, India.
C3 Indian Institute of Information Technology Allahabad
RP Singh, AK (corresponding author), Indian Inst Informat Technol, Robot & Artificial Intelligence Lab, Allahabad 211012, Uttar Pradesh, India.
EM avinashkumarsingh1986@gmail.com
RI Nandi, G C/V-8664-2019; Singh, Avinash Kumar/AAD-1249-2020
OI Singh, Avinash Kumar/0000-0002-2706-1853
CR Alemi M, 2014, INT J HUM ROBOT, V11, DOI 10.1142/S0219843614500224
   [Anonymous], 2004, Int J Humanoid Robotics
   Behnke S., 2008, KI, V22,, P5
   Billard A, 2003, ROBOT AUTON SYST, V42, P259, DOI 10.1016/S0921-8890(02)00380-9
   Brown S, 2014, TECHNOLOGY
   Burghart C, 2005, IEEE-RAS INT C HUMAN, P357
   Buss Samuel R., 2004, TECHNICAL REPORT
   Calinon S, 2005, IEEE-RAS INT C HUMAN, P161
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cohen H., 1988, AAAI 88. Seventh National Conference on Artificial Intelligence, P846
   Collomosse JP, 2002, 20TH EUROGRAPHICS UK CONFERENCE, PROCEEDINGS, P122, DOI 10.1109/EGUK.2002.1011281
   Deussen O., 2012, P 8 ANN S COMPUTATIO, P25
   Fujita M, 2003, IEEE ASME INT C ADV, P938
   Ghedini F, 2010, 2010 IEEE RO-MAN, P731, DOI 10.1109/ROMAN.2010.5598720
   Goldenberg A. A., 1985, IEEE Journal of Robotics and Automation, VRA-1, P14
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Gouaillier D, 2009, IEEE INT CONF ROBOT, P2124, DOI 10.1109/robot.2009.5152516
   Haeberli P., 1990, P SIGGRAPH, P207
   Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246
   Hertzmann A., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P453, DOI 10.1145/280814.280951
   Kaneko K, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P2471, DOI 10.1109/IROS.2008.4650604
   Kawamura Kazuhiko., 1996, Proceedings of the First International Symposium on Humanoid Robots, P53
   Kitano H., 1997, Proceedings of the First International Conference on Autonomous Agents, P340, DOI 10.1145/267658.267738
   Kobayashi S, 2011, ACMIEEE INT CONF HUM, P417, DOI 10.1145/1957656.1957811
   Kudoh S, 2009, ROBOT AUTON SYST, V57, P279, DOI 10.1016/j.robot.2008.10.007
   Kwok KW, 2005, IEEE DECIS CONTR P, P2047
   L. Fujitsu Automation Co, HOAP 2 INSTRUCTION M
   L. Honda Motor Co, ASIMO INSTRUCTION MA
   Lin  P., 2008, TECH REP
   Lu Y, 2009, IEEE ASME INT C ADV, P578, DOI 10.1109/AIM.2009.5229949
   Marchant Gary E., 2011, COLUMBIA SCI TECHNOL, V12, P272
   Metta G., 2008, 8th Workshop on Performance Metrics for Intelligent Systems, Gaithersburg, Maryland, Association for Computing Machinery: Gaithersburg, Maryland, P50, DOI DOI 10.1145/1774674.1774683
   Moura L, 2007, X GEN ART C POL MIL
   Ogura Y, 2006, IEEE INT CONF ROBOT, P76
   Okada K, 2006, IEEE-RAS INT C HUMAN, P7, DOI 10.1109/ICHR.2006.321356
   Pechev AN, 2008, IEEE INT CONF ROBOT, P2005, DOI 10.1109/ROBOT.2008.4543501
   Robotics A, 2012, NAO DATASHEET H25COR
   Sakagami Y, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P2478, DOI 10.1109/IRDS.2002.1041641
   Schaal S, 1999, TRENDS COGN SCI, V3, P233, DOI 10.1016/S1364-6613(99)01327-3
   Shamsuddin S., 2012, 2012 IEEE 8th International Colloquium on Signal Processing & its Applications, P188, DOI 10.1109/CSPA.2012.6194716
   Singh A, 2015, TECTONOPHYSICS, V644, P1, DOI 10.1016/j.tecto.2015.01.007
   Singh AK, 2016, ROBOT AUTON SYST, V79, P108, DOI 10.1016/j.robot.2016.01.009
   SRIKAEW A, 1998, IASTED INT C ROB MAN
   Stein MR, 2005, IEEE INT CONF ROBOT, P2779
   Stein MR, 2003, AUTON ROBOT, V15, P255, DOI 10.1023/A:1026216520523
   SUZUKI S, 1985, COMPUT VISION GRAPH, V30, P32, DOI 10.1016/0734-189X(85)90016-7
   Tiwari R, 2013, ADV COMPU INTELL ROB, P1, DOI 10.4018/978-1-4666-2074-2
   Tresset P., 2005, Proc. VSMM '05, P739
   Tresset P, 2013, COMPUT GRAPH-UK, V37, P348, DOI 10.1016/j.cag.2013.01.012
   Yamauchi BM, 2004, P SOC PHOTO-OPT INS, V5422, P228, DOI 10.1117/12.538328
NR 50
TC 5
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18847
EP 18870
DI 10.1007/s11042-017-4358-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800033
DA 2024-07-18
ER

PT J
AU Tian, T
   Zhang, Y
   Choo, KKR
   Song, WS
AF Tian, Tian
   Zhang, Yun
   Choo, Kim-Kwang Raymond
   Song, Weijing
TI A biologically inspired spatio-chromatic feature for color object
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local image feature; Color; Scale invariant feature transform (SIFT);
   Object recognition
ID CORTEX; REGISTRATION
AB Color information has been acknowledged for its important role in object recognition and scene classification. How to describe the color characteristics and extract combined spatial and chromatic feature is a challenging task in computer vision. In this paper we extend the robust SIFT feature on processed opponent color channels to obtain a spatio-chromatic descriptor for color object recognition. The color information processing is implemented under a biologically inspired hierarchical framework, where cone cells, single-opponent and double-opponent cells are simulated respectively to mimic the color perception of primate visual system. The biologically inspired method is tested for object recognition task on two public datasets, and the results support the potential of our proposed approach.
C1 [Tian, Tian; Song, Weijing] China Univ Geosci, Coll Comp Sci, Hubei Key Lab Intelligent Geoinformat Proc, 388 Lumo Rd, Wuhan 430074, Peoples R China.
   [Zhang, Yun] Univ Texas San Antonio, Dept Informat Syst & Cyber Secur, San Antonio, TX USA.
   [Choo, Kim-Kwang Raymond] Beijing Electromech Engn Inst, Beijing 100074, Peoples R China.
C3 China University of Geosciences; University of Texas System; University
   of Texas at San Antonio (UTSA)
RP Song, WS (corresponding author), China Univ Geosci, Coll Comp Sci, Hubei Key Lab Intelligent Geoinformat Proc, 388 Lumo Rd, Wuhan 430074, Peoples R China.
EM songweijing_haiou@163.com
RI Choo, Kim-Kwang Raymond/A-3634-2009; Tian, Tian/AAO-6980-2021
OI Choo, Kim-Kwang Raymond/0000-0001-9208-5336; 
FU Fundamental Research Funds for the Central Universities, China
   University of Geosciences (Wuhan); Provincial Natural Science Foundation
   of Hubei [2016CFB278]; National Natural Science Foundation of China
   [61601416]
FX This work is supported by the Fundamental Research Funds for the Central
   Universities, China University of Geosciences (Wuhan), the Provincial
   Natural Science Foundation of Hubei under Grant 2016CFB278, and the
   National Natural Science Foundation of China under Grant 61601416.
CR Alexiou I, 2014, LECT NOTES COMPUT SC, V8693, P81, DOI 10.1007/978-3-319-10602-1_6
   [Anonymous], 2006, P IEEE COMPUTER SOC, DOI DOI 10.1109/CVPR.2006.95
   Baran R, 2015, MULTIMED TOOLS APPL, V74, P4269, DOI 10.1007/s11042-013-1545-2
   Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716
   Burghouts GJ, 2009, COMPUT VIS IMAGE UND, V113, P48, DOI 10.1016/j.cviu.2008.07.003
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chatterjee S, 2003, NATURE, V426, P668, DOI 10.1038/nature02163
   Conway BR, 2010, J NEUROSCI, V30, P14955, DOI 10.1523/JNEUROSCI.4348-10.2010
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Eagleman DM, 2001, NAT REV NEUROSCI, V2, P920, DOI 10.1038/35104092
   Fan C, 2016, MULTIMED TOOLS APPL, V75, P12201, DOI 10.1007/s11042-015-3004-8
   Gao SB, 2013, IEEE I CONF COMP VIS, P929, DOI 10.1109/ICCV.2013.119
   Hering E., 1964, OUTLINES THEORY LIGH
   Johnson EN, 2001, NAT NEUROSCI, V4, P409, DOI 10.1038/86061
   Khan FS, 2012, PROC CVPR IEEE, P3306, DOI 10.1109/CVPR.2012.6248068
   Khan R, 2013, PROC CVPR IEEE, P2866, DOI 10.1109/CVPR.2013.369
   Lazebnik S, 2005, IEEE I CONF COMP VIS, P832, DOI 10.1109/ICCV.2005.10
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   LENNIE P, 1990, J NEUROSCI, V10, P649
   Li YS, 2016, IEEE GEOSCI REMOTE S, V13, P157, DOI 10.1109/LGRS.2015.2503142
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lu H, 2016, MDPI REMOTE SENSING
   Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001
   Ma JY, 2016, IEEE T IMAGE PROCESS, V25, P53, DOI 10.1109/TIP.2015.2467217
   Ma JY, 2015, IEEE T GEOSCI REMOTE, V53, P6469, DOI 10.1109/TGRS.2015.2441954
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Nayar SK, 1996, INT J COMPUT VISION, V17, P219, DOI 10.1007/BF00128232
   SCHWARZ MW, 1987, ACM T GRAPHIC, V6, P123, DOI 10.1145/31336.31338
   Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Slater D, 1996, IEEE T PATTERN ANAL, V18, P206, DOI 10.1109/34.481544
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   van de Weijer J, 2006, IEEE T PATTERN ANAL, V28, P150, DOI 10.1109/TPAMI.2006.3
   van de Weijer J, 2007, IEEE IMAGE PROC, P1621
   van de Weijer J, 2006, LECT NOTES COMPUT SC, V3952, P334
   Wang LZ, 2015, IEEE GEOSCI REMOTE S, V12, P736, DOI 10.1109/LGRS.2014.2360457
   Wei JC, 2015, J NANOMATER, V2015, DOI 10.1155/2015/561742
   Wei JB, 2016, IEEE GEOSCI REMOTE S, V13, P1557, DOI 10.1109/LGRS.2016.2595863
   Yang KF, 2013, PROC CVPR IEEE, P2810, DOI 10.1109/CVPR.2013.362
   Zhang J, 2012, LECT NOTES COMPUT SC, V7576, P312, DOI 10.1007/978-3-642-33715-4_23
   Zhao HW, 2014, J BIONIC ENG, V11, P311, DOI 10.1016/S1672-6529(14)60040-8
NR 42
TC 1
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18731
EP 18747
DI 10.1007/s11042-016-4252-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800028
DA 2024-07-18
ER

PT J
AU Youm, S
   Liu, S
AF Youm, Sekyoung
   Liu, Shuai
TI Development healthcare PC and multimedia software for improvement of
   health status and exercise habits
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Perceived health status; Exercise habits; Health-improvement activities;
   Home healthcare PC; Multimedia
ID CORONARY-HEART-DISEASE; PHYSICAL-ACTIVITY; LIFE-STYLE; TELEMEDICINE;
   PREVALENCE; OUTCOMES; SYSTEM; ADULTS; COST; RISK
AB The objectives of this study were to evaluate the effectiveness of home healthcare products and multimedia software, and suggest ways to stimulate their use by analyzing the effect of a consistent awareness of one's health status on the change in one's exercise habits and health-improvement activities. To examine the difference in the level of interest in health and the amount of exercise between a group of individuals that consistently utilized a personalized health management program using a Home healthcare PC with a workstation and a group of individuals who did not, a 16-week study was conducted on 143 male and female adults residing in the Gyeonggnam region. Pedometers were provided to measure the amount of exercise, and a survey was conducted to examine the changes in the awareness of health-improvement activities. The group of individuals who regularly checked and managed their health status showed a statistically significant increase in the number of steps they took, compared to the group who did not. In addition, a group that utilized the Home healthcare PC showed an increase in the behavior of seeking health counseling and exchanging information about health. This implies that the use of the Home healthcare PC draws users' attention to their health status and increases the motivation to exercise. The use of a Home healthcare PC not only acts as a red flag for the health of the users but also provides a bio-feedback effect. Therefore this system will play an effective role in prevention and post-incidence management of metabolic syndromes by motivating the users to systemically and independently manage their health at home, and to exercise or carry out health-improvement activities.
C1 [Youm, Sekyoung] Dongguk Univ, Ind Acad Cooperat Fdn, Seoul, South Korea.
   [Liu, Shuai] Inner Mongolia Univ, Coll Comp Sci, Hothot, Peoples R China.
C3 Dongguk University; Inner Mongolia University
RP Liu, S (corresponding author), Inner Mongolia Univ, Coll Comp Sci, Hothot, Peoples R China.
EM sekyoungyoum@gmail.com; liushuaitougao@163.com
RI Liu, Shuai/AAB-1960-2019; Liu, Shuai/P-3939-2017; Liu,
   Shuai/AAX-1239-2021
OI Liu, Shuai/0000-0001-9909-0664; Liu, Shuai/0000-0001-9909-0664
CR Allison MA, 2007, SERVICE ORIENTED ARC
   Azadbakht L, 2005, DIABETES CARE, V28, P2823, DOI 10.2337/diacare.28.12.2823
   Baek MR, 2012, THESIS
   Bondmass M, 2000, TELEMED J, V6, P15, DOI 10.1089/107830200311815
   임수, 2005, Diabetes and Metabolism Journal, V29, P432
   Cleeman JI, 2001, JAMA-J AM MED ASSOC, V285, P2486, DOI 10.1001/jama.285.19.2486
   Conus F, 2004, J CLIN ENDOCR METAB, V89, P5013, DOI 10.1210/jc.2004-0265
   DAVIS FD, 1989, MANAGE SCI, V35, P982, DOI 10.1287/mnsc.35.8.982
   Deloitte, 2013, HEALTHC 3 0 HEALTHC
   Ford ES, 2002, JAMA-J AM MED ASSOC, V287, P356, DOI 10.1001/jama.287.3.356
   Giugliano D, 2006, J AM COLL CARDIOL, V48, P677, DOI 10.1016/j.jacc.2006.03.052
   Godsland IF, 1998, J INTERN MED, V244, P33
   Grundy SM, 2005, CIRCULATION, V112, P2735, DOI 10.1161/CIRCULATIONAHA.105.169404
   Hanwoolove, 2010, TIP HLTH MOB APP
   Hersh W, 2002, J TELEMED TELECARE, V8, P197, DOI 10.1258/135763302320272167
   HIRA(Health Insurance Review & Assessment Service), 2012, HIRA TREND OF POL
   Hu G, 2007, ATHEROSCLEROSIS, V194, P490, DOI 10.1016/j.atherosclerosis.2006.08.051
   Hwang SJ, 2011, ETRI J, V33, P382, DOI 10.4218/etrij.11.0110.0458
   Ichihashi F., 2006, INT J SPORT HLTH SCI, V4, P617
   Jaehyoung Cho, 2006, Diabetes and Metabolism Journal, V30, P87
   Jeong KT, 2010, U HLTTH IND TREND TA
   Jerant AF, 2001, MED CARE, V39, P1234, DOI 10.1097/00005650-200111000-00010
   Johnston B, 2000, ARCH FAM MED, V9, P40, DOI 10.1001/archfami.9.1.40
   Jung M.-L., 2009, J. Med. Mark. Device Diagn. Pharm. Mark., V9, P243
   Kang SW, 2007, CEO INFORM, V602, P1
   Kim DG, 2009, KOREAN SOC INTERNET, V10, P9
   최고다, 2011, [Korean Business Education Review, 경영교육연구], V26, P449
   Kim Young-Hae, 2005, Taehan Kanho Hakhoe Chi, V35, P858
   Kinsella A, 1998, Caring, V17, P14
   Kummervold PE, 2006, PATIENTPHYSICIAN INT
   Kwak HM, 2006, P WORLD C MED PHYS B, P4207
   Kwak HM, 2005, P IEEE 27 EMBS ANN I
   Lee Chang Won, 2012, [Journal of The Korean Operations Research and Management Science Society, 한국경영과학회지], V37, P225, DOI 10.7737/JKORMS.2012.37.4.225
   Lee CW, 2010, J KOREAN OPERATIONS, V24, P305
   Lee Hyesang, 2010, [Journal of the Korean Society of Food Science and Nutrition, 한국식품영양과학회지], V39, P511
   Lee SY, 2005, HLTH WELFARE POLICY, P25
   Lee Won Jae, 2008, [Journal of Information Technology Services, 한국IT서비스학회지], V7, P113
   Lin SS, 2012, J MED SYST, V36, P3605, DOI 10.1007/s10916-012-9836-0
   Ministry of Health & Welfare, 2011, PREV MAN SYST CHRON
   Park JS, 2012, U HLTH POLICY STATUS
   Park N, 2010, LECT NOTES COMPUT SC, V6221, P245, DOI 10.1007/978-3-642-14654-1_30
   Roglieri JL, 1997, AM J MANAG CARE, V3, P1831
   Roine R, 2001, CAN MED ASSOC J, V165, P765
   Samsung, 2013, S HLTH BUDD
   Shin SA, 2012, INTRO PROJECT MANAGE
   Steel S, 2002, J TELEMED TELECARE, V8, P290, DOI 10.1258/135763302760314261
   Tsang MW, 2001, J TELEMED TELECARE, V7, P47, DOI 10.1258/1357633011936138
   Wade VA, 2010, BMC HEALTH SERV RES, V10, DOI 10.1186/1472-6963-10-233
   Wang ZH, 2005, IEICE T INF SYST, VE88D, P1985, DOI 10.1093/ietisy/e88-d.8.1985
   Whitten P, 2000, J TELEMED TELECARE, V6, P4, DOI 10.1258/1357633001934177
   Woo KS, 2010, ETRI J
   Yoo JS, 2009, J KOREAN ACAD NURS, V39, P594, DOI 10.4040/jkan.2009.39.4.594
   Youm S, 2015, TELEMED E-HEALTH, V21, P286, DOI 10.1089/tmj.2014.0092
NR 53
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 17751
EP 17763
DI 10.1007/s11042-015-2998-2
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800009
DA 2024-07-18
ER

PT J
AU Zhong, Z
   Su, SZ
   Cao, DL
   Li, SZ
   Lv, ZH
AF Zhong, Zhun
   Su, Songzhi
   Cao, Donglin
   Li, Shaozi
   Lv, Zhihan
TI Detecting ground control points via convolutional neural network for
   stereo matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stereo matching; CNN; Ground control points; Matching confidence
AB In this paper, we present a novel approach to detect ground control points (GCPs) for stereo matching problem. First of all, we train a convolutional neural network (CNN) on a large stereo set, and compute the matching confidence of each pixel by using the trained CNN model. Secondly, we present a ground control points selection scheme according to the maximum matching confidence of each pixel. Finally, the selected GCPs are used to refine the matching costs, then we apply the new matching costs to perform optimization with semi-global matching algorithm for improving the final disparity maps. We evaluate our approach on the KITTI 2012 stereo benchmark dataset. Our experiments show that the proposed approach significantly improves the accuracy of disparity maps.
C1 [Zhong, Zhun; Su, Songzhi; Cao, Donglin; Li, Shaozi] Xiamen Univ, Dept Cognit Sci, Xiamen 361005, Fujian, Peoples R China.
   [Lv, Zhihan] Chinese Acad Sci, SIAT, Shenzhen 518055, Peoples R China.
C3 Xiamen University; Chinese Academy of Sciences; Shenzhen Institute of
   Advanced Technology, CAS
RP Li, SZ (corresponding author), Xiamen Univ, Dept Cognit Sci, Xiamen 361005, Fujian, Peoples R China.
EM zhunzhong@stu.xmu.edu.cn; szlig@xmu.edu.cn
RI Li, SZ/G-3959-2010; Lyu, Zhihan/I-3187-2014; Lv, Zhihan/GLR-6000-2022
OI Lyu, Zhihan/0000-0003-2525-3074; Lv, Zhihan/0000-0003-2525-3074
FU Nature Science Foundation of China [61202143, 61572409]; Natural Science
   Foundation of Fujian Province [2013J05100]; Fujian Provi-nce 2011
   Collaborative Innovation Center of TCM Health Management
FX We thank Wenjing Li for helpful discussions and encouragement. This work
   is supported by the Nature Science Foundation of China (No. 61202143,
   No. 61572409), the Natural Science Foundation of Fujian Province (No.
   2013J05100) and Fujian Provi-nce 2011 Collaborative Innovation Center of
   TCM Health Management.
CR [Anonymous], IEEE ROBOTICS AUTOMA
   [Anonymous], 2015, ARXIV151107247
   Bobick AF, 1999, INT J COMPUT VISION, V33, P181, DOI 10.1023/A:1008150329890
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Chen ZY, 2015, IEEE I CONF COMP VIS, P972, DOI 10.1109/ICCV.2015.117
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Haeusler R, 2013, PROC CVPR IEEE, P305, DOI 10.1109/CVPR.2013.46
   Hermann Simon, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P465, DOI 10.1007/978-3-642-37431-9_36
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kong D., 2004, BRIT MACHINE VISION, V1, P2
   Kong D, 2006, BMVC, V1, P2
   LEW MS, 1994, IEEE T PATTERN ANAL, V16, P869, DOI 10.1109/34.310682
   Li W, 2016, NEUROCOMPUTING
   Li W, 2016, ARXIV160302253
   Li WB, 2013, PROC CVPR IEEE, P2435, DOI 10.1109/CVPR.2013.315
   Liang Z, 2016, EUR C COMP VIS
   Motten A, 2012, IEEE INT CONF VLSI, P247, DOI 10.1109/VLSI-SoC.2012.6379038
   Park MG, 2015, PROC CVPR IEEE, P101, DOI 10.1109/CVPR.2015.7298605
   Peris M, 2012, INT C PATT RECOG, P1038
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Spangenberg Robert, 2013, Computer Analysis of Images and Patterns. 15th International Conference, CAIP 2013. Proceedings: LNCS 8048, P34, DOI 10.1007/978-3-642-40246-3_5
   Spyropoulos A, 2014, PROC CVPR IEEE, P1621, DOI 10.1109/CVPR.2014.210
   Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509
   Vedula S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P722, DOI 10.1109/ICCV.1999.790293
   Yamaguchi K, 2014, LECT NOTES COMPUT SC, V8693, P756, DOI 10.1007/978-3-319-10602-1_49
   Yamaguchi K, 2013, PROC CVPR IEEE, P1862, DOI 10.1109/CVPR.2013.243
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zbontar J, 2016, J MACH LEARN RES, V17
   Zbontar J, 2015, PROC CVPR IEEE, P1592, DOI 10.1109/CVPR.2015.7298767
   ZHENG L, 2015, PROC CVPR IEEE, P1741, DOI DOI 10.1109/CVPR.2015.7298783
   Zheng L, 2017, PROC CVPR IEEE, P3346, DOI 10.1109/CVPR.2017.357
   Zhong Z., 2016, ARXIV160505904
NR 35
TC 3
Z9 3
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18473
EP 18488
DI 10.1007/s11042-016-3932-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800015
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Li, JQ
   Tian, XL
AF Li, Jiaqi
   Tian, Xiaolin
TI Analysis of all-in-focus image processing in image restoration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Image restoration; Frequency enhancement; All-in-focus
AB We discuss a new deblurring problems in this paper. Focus measurements play a fundamental role in image processing techniques. Most traditional methods neglect spatial information in the frequency domain. Therefore, this study analyzed image data in the frequency domain to determine the value of spatial information. but instead misleading noise reduction results. We found that the local feature is not always a guide for noise reduction. This finding leads to a new method to measure the image edges in focus deblurring. We employed an all-infocus measure in the frequency domain, based on the energy level of frequency components. We also used a multi-circle enhancement model to analyze this spatial information to provide a more accurate method for measuring images. We compared our results with those using other methods in similar studies. Findings demonstrate the effectiveness of our new method.
C1 [Li, Jiaqi] Macao Univ Sci & Technol, Fac Informat Technol, Ave Wai Long, Taipa, Macao, Peoples R China.
   [Tian, Xiaolin] Macao Univ Sci & Technol, Macau, Macao, Peoples R China.
C3 Macau University of Science & Technology; Macau University of Science &
   Technology
RP Li, JQ (corresponding author), Macao Univ Sci & Technol, Fac Informat Technol, Ave Wai Long, Taipa, Macao, Peoples R China.
EM jiaqilimacao@163.com
RI li, jiaqi/AAX-6745-2020
OI li, jiaqi/0000-0001-6076-4350
FU Science and Technology Development Fund of Macao [059/2013/A2 -0334]
FX This work is supported by the Science and Technology Development Fund of
   Macao (No. 059/2013/A2 -0334).).
CR Cao G, 2011, SIGN PROCESS LETT
   Chen S. E., 1993, Computer Graphics Proceedings, P279, DOI 10.1145/166117.166153
   Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   Demirel H, 2011, IMAG PROCESS
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Greenspan H, 1994, IMAGE ENHANCEMENT NO
   Heideman M. T., 1984, IEEE ASSP Magazine, V1, P14, DOI 10.1109/MASSP.1984.1162257
   Hong L, 1998, PATTERN ANAL MACH
   Jia J, 2007, COMPUT VISION PATTER
   Kingsbury N, 2003, IMAG PROCESS
   Kubota A, 2004, COMPUT GRAPH FORUM
   Kubota A, 2007, IEEE SIGNAL PROC MAG, V24, P10, DOI 10.1109/MSP.2007.905873
   Mahmood MT, 2010, OPTICS LETT, V35
   Malik AS, 2007, PATTERN RECOGN, V40, P154, DOI 10.1016/j.patcog.2006.05.032
   Marton F., 2011, 3DTV C TRUE VIS CAPT, P1, DOI DOI 10.1109/3DTV.2011.5877176
   Pertuz S, 2013, IEEE T IMAG PROCESS, V22
   Polesel A, 2000, IEEE T IMAG
   Rav-Acha A, 2005, PATTERN RECOGN LETT, V26, P311, DOI 10.1016/j.patrec.2004.10.017
   Shum HY, 2003, IEEE T CIRC SYST VID, V13, P1020, DOI 10.1109/TCSVT.2003.817360
   Simonov AN, 2009, OPT LETT, V34, P2111, DOI 10.1364/OL.34.002111
   Smolic A, 2010, PATTERN RECOGN
   STRANG G, 1994, AM SCI, V82, P250
   Van Loan C., 1992, COMPUTATIONAL FRAMEW
   Xu L, 2010, COMPUT VISION ECCV
   Yuan L, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239452
NR 25
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 14733
EP 14757
DI 10.1007/s11042-016-4007-9
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400011
DA 2024-07-18
ER

PT J
AU Karpagavalli, P
   Ramprasad, AV
AF Karpagavalli, P.
   Ramprasad, A. V.
TI An adaptive hybrid GMM for multiple human detection in crowd scenario
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Background subtraction; Adaptive Gaussian mixture model; Multiple human
   detection; Computer vision; Automation
ID IMAGE
AB People gather together for myriad reasons and in an overcrowded region, human detection is a very challenging problem. Automated multiple human detection is one of the most active research fields of computer vision applications. It provides useful information for crowd monitoring and traffic controlling for human safety in public places. The conventional Gaussian mixture model, that has a fixed K values, is not enough for dynamically varying background and further foreground detection is a time consuming process. The automated multiple human detection algorithms are needed to deal with complex background and illumination change conditions of crowd scene. In this paper, an automated multiple human detection method using hybrid adaptive Gaussian mixture model is proposed to handle efficiently the complex background and illumination changes. The proposed hybrid algorithm utilizes spatiotemporal features, adaptive learning control, adaptively changing weights and an adaptive selection with number of K Gaussian components per pixel to withstand in complex background and different lighting conditions. The experimental results and performance measures demonstrate that the proposed hybrid method performs well for crowd scene. By using the proposed adaptive hybrid method, the multiple human detection rate has been improved from 90 % to 95 % and the computational time is reduced from 5s e c s to 2.5s e c s.
C1 [Karpagavalli, P.; Ramprasad, A. V.] Anna Univ, KLN Coll Engn, Madras, Tamil Nadu, India.
C3 Anna University; Anna University Chennai
RP Karpagavalli, P (corresponding author), Anna Univ, KLN Coll Engn, Madras, Tamil Nadu, India.
EM karpagavallimohan@gmail.com
CR [Anonymous], IEEE INT C COMM SIGN
   [Anonymous], 2012, CHANG DET WORKSH CDW
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], P ICPR 2004
   [Anonymous], NAT C COMP VIS PATT
   [Anonymous], COMPUTER VISION ECCV
   [Anonymous], COMPUTER VISION ACCV
   [Anonymous], IEEE P ICPS 2008
   [Anonymous], 5 IEEE GCC C
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], P 7 IEEE C COMP VIS
   Bouwmans T., 2008, Recent Patents Comput. Sci., V1, P219
   Bouwmans T, 2014, COMPUT SCI REV, V11-12, P31, DOI 10.1016/j.cosrev.2014.04.001
   Ferryman J, 2014, PATTERN RECOGN LETT, V44, P3, DOI 10.1016/j.patrec.2014.01.005
   Kertesz Csaba., 2011, International Journal of Signal Processing, Image Processing and Pattern Recognition, V4, P51
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Kim Z., 2008, CVPR, P1
   Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102
   Lin HH, 2011, IEEE T IMAGE PROCESS, V20, P822, DOI 10.1109/TIP.2010.2075938
   Mahadevan V, 2008, IEEE C COMPUTER VISI, P1
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Sun L, 2015, MULTIMED TOOLS APPL, V74, P3947, DOI 10.1007/s11042-013-1806-0
   Tan R, 2006, LECT NOTES COMPUT SC, V4153, P125
   Wu B, 2005, IEEE I CONF COMP VIS, P90
   Yao L, 2014, SCI WORLD J, DOI 10.1155/2014/424050
   Zhao L, 2005, IEEE I CONF COMP VIS, P454
   Zhipeng Hu, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3277, DOI 10.1109/ICIP.2011.6116370
NR 29
TC 8
Z9 8
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 14129
EP 14149
DI 10.1007/s11042-016-3777-4
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800022
DA 2024-07-18
ER

PT J
AU Menendez-Ortiz, A
   Feregrino-Uribe, C
   Garcia-Hernandez, JJ
   Guzman-Zavaleta, ZJ
AF Menendez-Ortiz, Alejandra
   Feregrino-Uribe, Claudia
   Juan Garcia-Hernandez, Jose
   Jezabel Guzman-Zavaleta, Zobeida
TI Self-recovery scheme for audio restoration after a content replacement
   attack
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Self-recovery; Audio; Restoration; Content replacement attack
ID FRAGILE WATERMARKING; IMAGE AUTHENTICATION; DIGITAL AUDIO
AB Self-recovery schemes have been proposed for images and videos, however schemes for audio are intended to authenticate the contents or to localize tampering, but self-recovery for audio is still an open problem. This work presents a functional self-recovery scheme for audio that uses the intDCT domain for embedding and extraction of the control bits required to restore segments of an audio attacked with content replacement. Results obtained with the scheme are promising with regard to the quality of the watermarked signals; the scheme can restore signals attacked up to 0.6 % with acceptable quality. Further efforts should improve the restoration capabilities of the scheme.
C1 [Menendez-Ortiz, Alejandra; Feregrino-Uribe, Claudia; Jezabel Guzman-Zavaleta, Zobeida] INAOE, Dept Comp Sci, Luis Enrique Erro 1, Puebla 72840, Mexico.
   [Juan Garcia-Hernandez, Jose] CINVESTAV, Informat Technol Lab, Parque Cient & Tecnol TECNOTAM, Victoria 87130, Tamps, Mexico.
C3 Instituto Nacional de Astrofisica, Optica y Electronica; CINVESTAV -
   Centro de Investigacion y de Estudios Avanzados del Instituto
   Politecnico Nacional
RP Menendez-Ortiz, A (corresponding author), INAOE, Dept Comp Sci, Luis Enrique Erro 1, Puebla 72840, Mexico.
EM m.menendez@inaoep.mx
RI Garcia-Hernandez, Jose Juan/E-8633-2010; Feregrino,
   Claudia/AAW-2607-2021; Guzmán, Zobeida/HLP-7684-2023; Guzman-Zavaleta,
   Zobeida Jezabel/X-4945-2019; Guzman Zavaleta, Zobeida
   Jezabel/D-9855-2019
OI Garcia-Hernandez, Jose Juan/0000-0002-1249-5413; Menendez-Ortiz,
   Alejandra/0000-0002-1258-9882; Guzman Zavaleta, Zobeida
   Jezabel/0000-0002-3163-8862
FU CONACyT [351601, PDCPN2013-01-216689, CB-2010-01-150910]
FX This work was partially supported by Ph.D. scolarship No. 351601 by
   CONACyT and under CONACyT grants PDCPN2013-01-216689, and
   CB-2010-01-150910.
CR [Anonymous], 2006, BALLROOM DATASET
   [Anonymous], S CONT SEC DAT HID D
   Bravo-Solorio S, 2012, IEEE IMAGE PROC, P2197, DOI 10.1109/ICIP.2012.6467330
   Bravo-Solorio S, 2012, IEEE INT WORKS INFOR, P217, DOI 10.1109/WIFS.2012.6412652
   Celik MU, 2002, PROC SPIE, V4675, P531, DOI 10.1117/12.465311
   Chen Q., 2013, Proceedings of the 11th international conference on digital forensics and watermaking, P395, DOI [DOI 10.1007/978-3, 10.1007/978-3-642-40099-5_33, DOI 10.1007/978-3-642-40099-533]
   Fan MQ, 2013, INT J COMPUT MATH, V90, P2588, DOI 10.1080/00207160.2013.805752
   Gomez E, 2002, MIXED WATERMARKING F
   Hassan A.M., 2009, WORLD ACAD SCI ENG T, V2009, P69
   He HJ, 2012, IEEE T INF FOREN SEC, V7, P185, DOI 10.1109/TIFS.2011.2162950
   Huang HB, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL IV, PROCEEDINGS, P177
   Hung KL, 2007, LECT NOTES COMPUT SC, V4610, P333
   Mobasseri B. G., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P68, DOI 10.1109/ITCC.2000.844185
   National Forensic Science Technology Center (NFSTC), 2010, NFSTC SIMPL GUID FOR
   Newton H, 2012, POINTS VIEW MUSIC CE, V1
   Shi YJ, 2013, OPTIK, V124, P3827, DOI 10.1016/j.ijleo.2012.11.078
   Steinebach M, 2003, EURASIP J APPL SIG P, V2003, P1001, DOI 10.1155/S1110865703304081
   Thiede T, 2000, J AUDIO ENG SOC, V48, P3
   Wang HX, 2010, SCI CHINA INFORM SCI, V53, P619, DOI 10.1007/s11432-010-0058-0
   Wang SS, 2008, PATTERN RECOGN, V41, P701, DOI 10.1016/j.patcog.2007.05.012
   Xu TT, 2009, LECT NOTES COMPUT SC, V5879, P1281
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
   Zhang XP, 2008, IEEE T MULTIMEDIA, V10, P1490, DOI 10.1109/TMM.2008.2007334
   Zhu X, 2007, SIGNAL PROCESS-IMAGE, V22, P515, DOI 10.1016/j.image.2007.03.004
NR 24
TC 9
Z9 9
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 14197
EP 14224
DI 10.1007/s11042-016-3783-6
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800025
DA 2024-07-18
ER

PT J
AU Shet, KS
   Aswath, AR
   Hanumantharaju, MC
   Gao, XZ
AF Shet, K. Sathish
   Aswath, A. R.
   Hanumantharaju, M. C.
   Gao, Xiao-Zhi
TI Design and development of new reconfigurable architectures for
   LSB/multi-bit image steganography system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganography; Least Significant Bit; Hiding/extraction;
   Reconfigurable architectures; Verilog; Field Programmable Gate Array
ID DATA HIDING SCHEME; PARALLEL FRAMEWORK
AB The most crucial task in real-time processing of steganography algorithms is to reduce the computational delay and increase the throughput of a system. This critical issue is effectively addressed by implementing steganography methods in reconfigurable hardware. In the proposed framework, a new high-speed reconfigurable architectures have been designed for Least Significant Bit (LSB) or multi-bit based image steganography algorithm that suits Field Programmable Gate Arrays (FPGAs) or Application Specific Integrated Circuits (ASICs) implementation. The architectures are designed and instantiated to implement the complete steganography system. The proposed system is competent enough to provide larger throughput, since high degrees of pipelining and parallel operations are incorporated at the module level. The evolved architectures are realized in Xilinx Virtex-II Pro XC2V500FG256-6 FPGA device using Register Transfer Level (RTL) compliant Verilog coding and has the capacity to work in real-time at the rate of 183.48 frames/second. Prior to the FPGA/ASIC implementation, the proposed steganography system is simulated in software to validate the concepts intended to implement. The hardware implemented algorithm is tested by varying embedding bit size as well as the resolution of a cover image. As it is clear from the results presented that the projected framework is superior in speed, area and power consumption compared to other researcher's method.
C1 [Shet, K. Sathish] JSS Acad Tech Educ, Dept Elect & Commun Engn, Bengaluru, India.
   [Aswath, A. R.] Dayananda Sagar Coll Engn, Dept Telecommun Engn, Bengaluru, India.
   [Hanumantharaju, M. C.] BMS Inst Technol & Management, Dept Elect & Commun Engn, Bengaluru, India.
   [Gao, Xiao-Zhi] Aalto Univ, Sch Elect Engn, Dept Elect Engn & Automat, Espoo, Finland.
C3 Dayananda Sagar College of Engineering; Aalto University
RP Hanumantharaju, MC (corresponding author), BMS Inst Technol & Management, Dept Elect & Commun Engn, Bengaluru, India.
EM satish.personal@gmail.com; mchanumantharaju@gmail.com
RI GAO, XIAO/JED-3257-2023; R, Aswatha A/AAZ-1107-2020; K, Dr. Sathish
   Shet/J-9718-2019; Raju, Hanumantha/N-9205-2017
OI K, Dr. Sathish Shet/0000-0001-9616-1439; Raju,
   Hanumantha/0000-0001-5549-2522
CR Al-Haj AM, 2010, ADV TECHNIQUES MULTI
   Amirtharajan R, 2012, INFORM SCIENCES, V193, P115, DOI 10.1016/j.ins.2012.01.010
   [Anonymous], INFORM TECHNOLOGY J
   [Anonymous], 2003, EFFECT ESTROGEN
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Cox IJ., 2007, DIGITAL WATERMARKING
   Crandall R., 1998, SOME NOTES STEGANOGR
   Fan L, 2013, 2013 INTERNATIONAL CONFERENCE ON SENSOR NETWORK SECURITY TECHNOLOGY AND PRIVACY COMMUNICATION SYSTEM (SNS & PCS), P156
   Fan L, 2013, COMPUT ELECTR ENG, V39, P873, DOI 10.1016/j.compeleceng.2012.06.014
   Fan L, 2011, COMPUT ELECTR ENG, V37, P973, DOI 10.1016/j.compeleceng.2011.08.006
   Genovese M, 2015, INTEGRATION, V49, P114, DOI 10.1016/j.vlsi.2014.10.004
   Gómez-Hernández E, 2008, INT CONF ELECTR COMM, P123, DOI 10.1109/CONIELECOMP.2008.24
   Hemalatha R, 2015, 2015 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION ENGINEERING SYSTEMS (SPACES), P358, DOI 10.1109/SPACES.2015.7058283
   Hines G, 2004, P SOC PHOTO-OPT INS, V5438, P13, DOI 10.1117/12.544500
   Hussain M., 2013, SURVEY IMAGE STEGANO
   Maheswaran M., 2012, Journal of Applied Sciences, V12, P920, DOI 10.3923/jas.2012.920.928
   Mohd B.J., 2012, International Conference on Computer, Information and Telecommunication Systems (CITS), P1, DOI DOI 10.1109/CITS.2012.6220393
   Ntalianis K. S., 2002, Proceedings 2002 IEEE International Conference on Multimedia and Expo (Cat. No.02TH8604), P561, DOI 10.1109/ICME.2002.1035678
   Ntalianis K, 2011, EURASIP J INF SECUR, DOI 10.1155/2011/174945
   Paul G, 2016, MULTIMEDIA TOOLS APP, P1
   Rajagopalan Sundararaman, 2014, Information Technology Journal, V13, P1945, DOI 10.3923/itj.2014.1945.1952
   Shah NP, 2018, J MANAGE, V44, P412, DOI 10.1177/0149206315584822
   Tseng YC, 2002, IEEE T COMMUN, V50, P1227, DOI 10.1109/TCOMM.2002.801488
   Wang K, 2013, J SYST SOFTWARE, V86, P1965, DOI 10.1016/j.jss.2013.03.083
   Xuan GR, 2007, LECT NOTES COMPUT SC, V4633, P715
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yun Cao, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P193, DOI 10.1007/978-3-642-24178-9_14
NR 29
TC 11
Z9 11
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13197
EP 13219
DI 10.1007/s11042-016-3736-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900012
DA 2024-07-18
ER

PT J
AU Khan, A
   Khan, A
   Khan, M
   Uzair, M
AF Khan, Aftab
   Khan, Ashfaq
   Khan, Mushtaq
   Uzair, Muhammad
TI Lossless image compression: application of Bi-level Burrows Wheeler
   Compression Algorithm (BBWCA) to 2-D data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lossless image compression; Bi-level BurrowsWheeler Compression
   Algorithm (BBWCA); Reversible Colour Transform(RCT); Colour Filter Array
   (CFA) images; 2-D ElectroEncephaloGraphy (EEG); Colour Space
ID FILTER ARRAY IMAGES; EEG COMPRESSION; EFFICIENT; SCHEME
AB This research paper demonstrates the robustness of Bi-level Burrows Wheeler Compression Algorithm (BBWCA) in terms of the compression efficiency for different types of image data. The scheme was designed to take advantage of the increased inter-pixel redundancies resulting from a two pass Burrows Wheeler Transformation (BWT) stage and the use of Reversible Colour Transform (RCT). In this research work, BBWCA was evaluated for raster map images, Colour Filter Array (CFA) images as well as 2-D ElectroEncephaloGraphy (EEG) data and compared against benchmark schemes. Validation has been carried out on various examples and they show that BBWCA is capable of compressing 2-D data effectively. The proposed method achieves marked improvement over the existing methods in terms of compression size. BBWCA is 18.8 % better at compressing images as compared to High Efficiency Video Codec (HEVC) and 21.2 % more effective than LZ4X compressor for CFA images. For the EEG data, BBWCA is 17 % better at compressing images as compared to WINRK and 25.2 % more effective than NANOZIP compressor. However, for the Raster images PAQ8 supersedes BBWCA by 11 %. Among the different schemes compared, the proposed scheme achieves overall best performance and is well suited to small and large size image data compression. The parallelization process reduces the execution time particularly for large size images. The parallelized BBWCA scheme reduces the execution time by 31.92 % on average as compared to the non-parallelized BBWCA.
C1 [Uzair, Muhammad] Univ Engn & Technol, Peshawar, Pakistan.
   [Khan, Aftab] Univ Engn & Technol, Dept Comp Syst Engn, Peshawar, Pakistan.
   [Khan, Ashfaq] Univ Engn & Technol, Dept Mech Engn, Peshawar, Pakistan.
   [Khan, Mushtaq] Natl Univ Sci & Technol, Dept Design & Mfg Engn, SMME, Islamabad, Pakistan.
C3 University of Engineering & Technology Peshawar; University of
   Engineering & Technology Peshawar; University of Engineering &
   Technology Peshawar; National University of Sciences & Technology -
   Pakistan
RP Khan, A (corresponding author), Univ Engn & Technol, Dept Comp Syst Engn, Peshawar, Pakistan.
EM aftab.khan@uetpeshawar.edu.pk
OI Khan, DR Mushtaq/0000-0002-8316-9754
CR Abel J., 2003, ACM T COMPUT SYST
   Abel J, 2007, SOFTWARE PRACT EXPER, V37, P247, DOI 10.1002/spe.763
   Abel J, 2010, SOFTWARE PRACT EXPER, V40, P751, DOI 10.1002/spe.982
   Akimov A, 2007, IEEE T IMAGE PROCESS, V16, P114, DOI 10.1109/TIP.2006.887721
   Andrzejak RG, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.061907
   [Anonymous], 2004, Color space transformations
   Antoniol G, 1997, IEEE T BIO-MED ENG, V44, P105, DOI 10.1109/10.552239
   Antony A, 2015, MULT TOOLS APPL, P1
   Arnavut Z, 2004, INT J COMPUT MATH, V81, P1213, DOI 10.1080/00207160410001712279
   Asif Ali M, 2010, 6 INT C EM TECHN ICE, P170
   Balkenhol B, 2000, IEEE T COMPUT, V49, P1043, DOI 10.1109/12.888040
   BENTLEY JL, 1986, COMMUN ACM, V29, P320, DOI 10.1145/5684.5688
   BURROWS M, 1994, 124 SRC
   Campos ASE, 1999, RUN LENGTH ENCODING
   Chou CH, 2008, IET IMAGE PROCESS, V2, P304, DOI 10.1049/iet-ipr:20080034
   Chung KH, 2008, IEEE T IMAGE PROCESS, V17, P134, DOI 10.1109/TIP.2007.914153
   Daou H, 2014, IEEE J BIOMED HEALTH, V18, P247, DOI 10.1109/JBHI.2013.2263198
   Dauwels J, 2012, INT CONF ACOUST SPEE, P637, DOI 10.1109/ICASSP.2012.6287964
   Deorowicz S, 2000, SOFTWARE PRACT EXPER, V30, P1465, DOI 10.1002/1097-024X(20001110)30:13<1465::AID-SPE345>3.0.CO;2-D
   FENWICK P, 1996, 130 U AUCKL DEP COMP
   Guo HT, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P65, DOI 10.1109/ICIP.1997.647385
   Jalumuri N., 2004, A study of scanning paths for bwt based image compression
   Karimi N, 2015, MULTIMED TOOLS APPL, V74, P11007, DOI 10.1007/s11042-014-2214-9
   Khan A, 2010, 2 INT C MACH VIS ICM
   Khan A., 2015, SIGNAL IMAGE VIDEO P, P1
   Kim S, 2014, IEEE T CIRC SYST VID, V24, P1040, DOI 10.1109/TCSVT.2014.2302546
   Koc B, COMPUT ELECT ENG
   Kolo JG, 2015, COMPUT ELECTR ENG, V41, P275, DOI 10.1016/j.compeleceng.2014.06.008
   Kumar R, 2013, COMPUT ELECTR ENG, V39, P130, DOI 10.1016/j.compeleceng.2012.04.008
   Lee D, 2012, SIGNAL PROCESS-IMAGE, V27, P637, DOI 10.1016/j.image.2012.02.017
   Lin L, 2015, BIOMED SIGNAL PROCES, V20, P45, DOI 10.1016/j.bspc.2015.04.001
   Manzini G, 2001, J ACM, V48, P407, DOI 10.1145/382780.382782
   Mao QZ, 2015, SIGNAL IMAGE VIDEO P, V9, P133, DOI 10.1007/s11760-013-0428-3
   Masoodgu Banu NM, MULTIMED TOOLS APPL, P1
   Mozammel M, 2012, INT J COMPUT SCI ISS, V9
   Mukhopadhyay SK, 2011, COMPUT ELECTR ENG, V37, P486, DOI 10.1016/j.compeleceng.2011.05.004
   Nasri M, 2011, COMPUT ELECTR ENG, V37, P798, DOI 10.1016/j.compeleceng.2011.08.001
   Nian YJ, 2014, COMPUT ELECTR ENG, V40, P1006, DOI 10.1016/j.compeleceng.2013.12.009
   Nian YJ, 2012, SCI CHINA INFORM SCI, V55, P2646, DOI 10.1007/s11432-012-4686-4
   Ouni T, 2015, SIGNAL IMAGE VIDEO P, V9, P277, DOI 10.1007/s11760-013-0435-4
   Ryabko B. Ya., 1980, Problems of Information Transmission, V16, P265
   RYABKO BY, 1987, COMMUN ACM, V30, P792
   Seyun K, 2012, VISUAL COMMUNICATION, P1
   Squeeze Chart, LOSSL DAT COMPR BENC
   Srikanth S, COMPRESSION EFFICIEN, P816
   Srinivasan K, 2011, BIOMED SIGNAL PROCES, V6, P387, DOI 10.1016/j.bspc.2011.01.004
   Starosolski R, 2014, J VIS COMMUN IMAGE R, V25, P1056, DOI 10.1016/j.jvcir.2014.03.003
   Telagarapu P., 2011, INT J SIGNAL PROCESS, V4
   Xu GW, 2015, IEEE SIGNAL PROC LET, V22, P1118, DOI 10.1109/LSP.2015.2389856
   Yerva S, LOSSLESS IMAGE COMPR, P999
   Zamora G, 1998, 11TH IEEE SYMPOSIUM ON COMPUTER-BASED MEDICAL SYSTEMS, PROCEEDINGS, P13, DOI 10.1109/CBMS.1998.701207
NR 51
TC 9
Z9 11
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12391
EP 12416
DI 10.1007/s11042-016-3629-2
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200010
DA 2024-07-18
ER

PT J
AU Li, Q
   Wang, J
   Wang, F
   Li, P
   Liu, L
   Chen, YZ
AF Li, Qing
   Wang, Jun
   Wang, Feng
   Li, Ping
   Liu, Ling
   Chen, Yuanzhu
TI The role of social sentiment in stock markets: a view from joint effects
   of multiple information sources
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social media; Stock market; Predictive model; Tensor theory; Trading
   systems
ID INVESTOR SENTIMENT; NEWS; RETURNS; MEDIA; MODEL; FORECAST; NETWORKS
AB Social sentiment reflects grassroots views regarding stock trends and has played a leading role in stock movements. Previous studies have relied predominantly on statistical models, regression models or vector-based predictive models to analyze the influence of social sentiment without considering other information sources or their intrinsic interactions. However, stock movements are in essence driven by various types of highly interrelated information sources including firm characteristics, social sentiment, and professional opinions. This paper describes the degree to which the problem arises in understanding the role of social sentiment in financial markets and proposes a novel intelligent stock analysis system to solve it. It first captures social sentiment and professional opinions from textual information in social media and financial news, respectively, and then represents the whole market information space consisting of these two information sources along with firm characteristics via tensors. Finally, a tensor-based learning algorithm is utilized to capture the interactions of these information sources on stock movements. Experiments performed on an entire year of data of China Securities Index (CSI 100) stocks demonstrate the effectiveness of the proposed intelligent system to study the role of social sentiment from the perspective of joint effects of multiple information sources compared with traditional vector-based systems.
C1 [Li, Qing; Wang, Jun; Wang, Feng; Li, Ping; Liu, Ling] Southwestern Univ Finance & Econ, Chengdu, Peoples R China.
   [Chen, Yuanzhu] Mem Univ Newfoundland, Dept Comp Sci, St John, NF, Canada.
C3 Southwestern University of Finance & Economics - China; Memorial
   University Newfoundland
RP Li, Q (corresponding author), Southwestern Univ Finance & Econ, Chengdu, Peoples R China.
EM kooliqing@gmail.com
RI Chen, Yuanzhu/AAU-6752-2020; Chen, Yuanzhu/JDC-5136-2023
OI Liu, Ling/0000-0001-6989-790X
FU National Natural Science Foundation of China (NSFC) [60803106, 61170133,
   71401139]; Sichuan National Science Foundation for Distinguished Young
   Scholars [2013JQ0004]; Fundamental Research Funds for the Central
   Universities [JBK151128]
FX This work has been supported by the National Natural Science Foundation
   of China (NSFC) (60803106, 61170133,71401139), Sichuan National Science
   Foundation for Distinguished Young Scholars (2013JQ0004), and
   Fundamental Research Funds for the Central Universities (JBK151128).
CR Alanyali M, 2013, SCI REP-UK, V3, DOI 10.1038/srep03578
   [Anonymous], J POLITICAL EC
   [Anonymous], 2013, SCI REPORTS
   [Anonymous], 2011, J COMPUT SCI-NETH, DOI DOI 10.1016/j.jocs.2010.12.007
   [Anonymous], 2007, Modelling financial time series
   Antweiler W, 2004, J FINANC, V59, P1259, DOI 10.1111/j.1540-6261.2004.00662.x
   Araújo RDA, 2015, EXPERT SYST APPL, V42, P4081, DOI 10.1016/j.eswa.2015.01.004
   Araújo RD, 2013, INFORM SCIENCES, V237, P3, DOI 10.1016/j.ins.2009.07.007
   Arslan YZ, 2012, COMPUT MATH METHOD M, V2012, DOI 10.1155/2012/803980
   Aznarte JL, 2012, EXPERT SYST APPL, V39, P12302, DOI 10.1016/j.eswa.2012.02.135
   Baeza-Yates R, 1999, MODERN INFORM RETRIE, P41
   Bagheri A, 2014, EXPERT SYST APPL, V41, P6235, DOI 10.1016/j.eswa.2014.04.003
   BOLLERSLEV T, 1992, J ECONOMETRICS, V52, P5, DOI 10.1016/0304-4076(92)90064-X
   Catanzaro B., 2008, P 25 INT C MACHINE L, P104, DOI DOI 10.1145/1390156.1390170
   Chan WS, 2003, J FINANC ECON, V70, P223, DOI 10.1016/S0304-405X(03)00146-6
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Curme C, 2014, P NATL ACAD SCI USA, V111, P11600, DOI 10.1073/pnas.1324054111
   Ding X, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2327
   Doukas JA, 2004, FINANC ANAL J, V60, P55, DOI 10.2469/faj.v60.n6.2673
   FAMA EF, 1993, J FINANC ECON, V33, P3, DOI 10.1016/0304-405X(93)90023-5
   FAMA EF, 1995, J FINANC, V50, P131, DOI 10.2307/2329241
   Francis J, 1997, J ACCOUNT ECON, V24, P363, DOI 10.1016/S0165-4101(98)00012-3
   Gidofalvi Gyozo., 2001, Using News Articles to Predict Stock Price Movements
   Ivkovic Z, 2005, J FINANC, V60, P267, DOI 10.1111/j.1540-6261.2005.00730.x
   Kim SH, 2014, J ECON BEHAV ORGAN, V107, P708, DOI 10.1016/j.jebo.2014.04.015
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Kristjanpoller W, 2014, EXPERT SYST APPL, V41, P2437, DOI 10.1016/j.eswa.2013.09.043
   Lavrenko V., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, P389, DOI 10.1145/354756.354845
   LeBaron B, 1999, J ECON DYN CONTROL, V23, P1487, DOI 10.1016/S0165-1889(98)00081-5
   Li Q, 2015, AAAI CONF ARTIF INTE, P1784
   Li Q, 2014, INFORM SCIENCES, V278, P826, DOI 10.1016/j.ins.2014.03.096
   Li Q, 2014, DECIS SUPPORT SYST, V61, P93, DOI 10.1016/j.dss.2014.01.013
   Li XD, 2014, KNOWL-BASED SYST, V69, P14, DOI 10.1016/j.knosys.2014.04.022
   Loughran T, 2011, J FINANC, V66, P35, DOI 10.1111/j.1540-6261.2010.01625.x
   Luo XM, 2013, INFORM SYST RES, V24, P146, DOI 10.1287/isre.1120.0462
   Mittermayer MA, 2006, IEEE DATA MINING, P1002
   Nassirtoussi AK, 2014, EXPERT SYST APPL, V41, P7653, DOI 10.1016/j.eswa.2014.06.009
   Qiu X, 2013, P 51 ANN M ASS COMP, P49
   Ruiz E.J., 2012, P 5 ACM INT C WEB SE, P513, DOI DOI 10.1145/2124295.2124358
   Rychetsky M., 2001, Algorithms and architectures for machine learning based on regularized neural networks and support vector approaches
   Schumaker RP, 2012, DECIS SUPPORT SYST, V53, P458, DOI 10.1016/j.dss.2012.03.001
   Schumaker RP, 2009, ACM T INFORM SYST, V27, DOI 10.1145/1462198.1462204
   Schumaker RP, 2009, INFORM PROCESS MANAG, V45, P571, DOI 10.1016/j.ipm.2009.05.001
   Shleifer A, 1997, J FINANC, V52, P35, DOI 10.2307/2329555
   Si J., 2014, EMNLP '14, P1139
   Siganos A, 2014, J ECON BEHAV ORGAN, V107, P730, DOI 10.1016/j.jebo.2014.06.004
   Tabibian S, 2014, NEURAL PROCESS LETT, V39, P195, DOI 10.1007/s11063-013-9299-4
   Tetlock PC, 2008, J FINANC, V63, P1437, DOI 10.1111/j.1540-6261.2008.01362.x
   Tetlock PC, 2007, J FINANC, V62, P1139, DOI 10.1111/j.1540-6261.2007.01232.x
   Urquhart A, 2013, INT REV FINANC ANAL, V28, P130, DOI 10.1016/j.irfa.2013.03.005
   Veronesi P, 1999, REV FINANC STUD, V12, P975, DOI 10.1093/rfs/12.5.975
   Wang BH, 2012, NEUROCOMPUTING, V83, P136, DOI 10.1016/j.neucom.2011.12.013
   Wu F, 2009, IEEE T MULTIMEDIA, V11, P868, DOI 10.1109/TMM.2009.2021724
   Wuthrich B, 1998, IEEE SYS MAN CYBERN, P2720, DOI 10.1109/ICSMC.1998.725072
   Zheludev I, 2014, SCI REP-UK, V4, DOI 10.1038/srep04213
NR 55
TC 11
Z9 11
U1 1
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12315
EP 12345
DI 10.1007/s11042-016-3643-4
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200007
DA 2024-07-18
ER

PT J
AU Ribelles, J
   Gutierrez, D
   Efros, A
AF Ribelles, Jose
   Gutierrez, Diego
   Efros, Alyosha
TI BUILDUP: interactive creation of urban scenes from large photo
   collections
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image databases; 3D scene composition; Picture generation
ID IMAGE
AB We propose a system for creating images of urban scenes composed of the large structures typical in such environments. Our system provides the user with a precomputed library of image-based 3D objects, such as roads, sidewalks and buildings, obtained from a large collection of photographs. When the user picks the 3D location of a new object to insert, the system retrieves objects that have all the required properties (location, orientation and lighting). Then, the user interface guides the user to add more objects enabling non-experts to make a new composition in a fast and intuitive way. Unlike prior work, the entire image composition process is done in the 3D space of the scene, therefore inconsistent scale or perspective distortion does not arise, and occlusions are properly handled.
C1 [Ribelles, Jose] Univ Jaume 1, Inst New Imaging Technol, Castellon de La Plana, Spain.
   [Gutierrez, Diego] Univ Zaragoza, Zaragoza, Spain.
   [Efros, Alyosha] Univ Calif Berkeley, Berkeley, CA 94720 USA.
C3 Universitat Jaume I; University of Zaragoza; University of California
   System; University of California Berkeley
RP Ribelles, J (corresponding author), Univ Jaume 1, Inst New Imaging Technol, Castellon de La Plana, Spain.
EM ribelles@uji.es; diegog@unizar.es; efros@eecs.berkeley.edu
RI Ribelles, Jose/B-1208-2017
OI Ribelles, Jose/0000-0001-8393-9758; Efros, Alexei
   A./0000-0001-5720-8070; Gutierrez Perez, Diego/0000-0002-7503-7022
CR Agarwala A, 2004, ACM T GRAPHIC, V23, P294, DOI 10.1145/1015706.1015718
   [Anonymous], 1996, USABILITY EVALUATION, DOI [10.1201/9781498710411-35, DOI 10.1201/9781498710411-35]
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Branit B., 2007, World builder
   Chen T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618470
   Diakopoulos N, 2004, LECT NOTES COMPUT SC, V3115, P299
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Eitz M, 2011, IEEE COMPUT GRAPH AP
   Hays J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239455
   Hu SM, 2013, VISUAL COMPUT, V29, P393, DOI 10.1007/s00371-013-0792-6
   Johnson M, 2006, COMPUT GRAPH FORUM, V25, P407, DOI 10.1111/j.1467-8659.2006.00960.x
   Johnson MK, 2011, IEEE T VIS COMPUT GR, V17, P1273, DOI 10.1109/TVCG.2010.233
   Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264
   Lalonde JF, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276381, 10.1145/1239451.1239454]
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Reinhard E, 2013, P IEEE, V101, P1998, DOI 10.1109/JPROC.2013.2260711
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Russell BC, 2009, PROC CVPR IEEE, P2703
NR 18
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12757
EP 12774
DI 10.1007/s11042-016-3658-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200026
OA Green Published
DA 2024-07-18
ER

PT J
AU Li, PJ
   Ma, HD
   Ming, AL
AF Li, Pengjie
   Ma, Huadong
   Ming, Anlong
TI A non-rigid 3D model retrieval method based on scale-invariant heat
   kernel signature features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-rigid 3D model retrieval; Scale-invariant; Heat Kernel Signature
   (HKS); Diffusion Wavelets transform; Histogram equalization
ID SHAPES
AB The number of non-rigid 3D models increases steadily in various areas. It is imperative to develop efficient retrieval system for 3D non-rigid models. As we know, global features fail to consistently describe the intra-class variability of non-rigid 3D models, the local features are more effective than global features for the retrieval of non-rigid 3D models. In this paper, we use Heat Kernel Signature (HKS) as the local features to represent non-rigid 3D models and further propose the retrieval method based on scale-invariant local features. Firstly, we extract key-points at multiple scales automatically. Then, the HKS local features are computed for each key-point. However, the HKS features are sensitive to scale. In order to solve this problem, we convert the scale problem into the translation problem using the diffusion Wavelets transform. To solve the translation problem, we use a kind of histogram equalization technique. Finally, we use the bipartite graph matching algorithm to compute similarity between the 3D models. Experimental results on two public benchmarks show that our method outperforms state-of-the-art methods for non-rigid 3D models retrieval.
C1 [Li, Pengjie] Beijing Univ Posts & Telecommun, Inst Sensing Technol & Business, Beijing 100876, Peoples R China.
   [Ma, Huadong; Ming, Anlong] Beijing Univ Posts & Telecommun, Beijing Key Lab Intelligent Telecommun Software &, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Beijing University of
   Posts & Telecommunications
RP Li, PJ (corresponding author), Beijing Univ Posts & Telecommun, Inst Sensing Technol & Business, Beijing 100876, Peoples R China.
EM lipj15@bupt.edu.cn
FU National Natural Science Foundation for Distinguished Young Scholars
   [60925010]; Funds for Creative Research Groups of China [61121001];
   Research Fund for the Doctoral Program of Higher Education of China
   [20120005130002]; Program for the Jiangsu Provincial Naural Science
   Fundation of China [BK2011170]
FX This work is supported by the National Natural Science Foundation for
   Distinguished Young Scholars under Grant No. 60925010; the Funds for
   Creative Research Groups of China under Grant No. 61121001; the Research
   Fund for the Doctoral Program of Higher Education of China under Grant
   No. 20120005130002; the Program for the Jiangsu Provincial Naural
   Science Fundation of China under Grant No. BK2011170.
CR Au OKC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360643
   Barra V, 2013, PATTERN RECOGN, V46, P2985, DOI 10.1016/j.patcog.2013.03.019
   Ben-Chen M., 2008, Proceedings of the 1st Eurographics Conference on 3D Object Retrieval, P1
   Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405
   Bronstein AM, 2010, INT J COMPUT VISION, V89, P266, DOI 10.1007/s11263-009-0301-6
   Bronstein AM, 2006, P NATL ACAD SCI USA, V103, P1168, DOI 10.1073/pnas.0508601103
   Bronstein MM, 2010, PROC CVPR IEEE, P1704, DOI 10.1109/CVPR.2010.5539838
   Bu SH, 2014, IEEE T MULTIMEDIA, V16, P2154, DOI 10.1109/TMM.2014.2351788
   Cao Y, 2010, PROC CVPR IEEE, P3352, DOI 10.1109/CVPR.2010.5540021
   Chazal F, 2009, COMPUT GRAPH FORUM, V28, P1393, DOI 10.1111/j.1467-8659.2009.01516.x
   Dang F, 2014, PROCEDIA COMPUT SCI, V29, P1859, DOI 10.1016/j.procs.2014.05.170
   Detrixhe M, 2013, J COMPUT PHYS, V237, P46, DOI 10.1016/j.jcp.2012.11.042
   Donoser M, 2013, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2013.174
   Gao Y, 2011, IEEE T MULTIMEDIA, V13, P1007, DOI 10.1109/TMM.2011.2160619
   Grigor'yan A., 2009, AMS IP STUD ADV MATH, V47, P1
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   Hu MQ, 2013, IEEE T EVOLUT COMPUT, V17, P705, DOI 10.1109/TEVC.2012.2232931
   Jain Varun., 2007, INT J SHAPE MODELING, V13, P101, DOI DOI 10.1142/S0218654307000968
   Jia YQ, 2012, PROC CVPR IEEE, P3370, DOI 10.1109/CVPR.2012.6248076
   Kuang ZZ, 2015, COMPUT AIDED DESIGN, V58, P13, DOI 10.1016/j.cad.2014.08.004
   Lafon S. S, 2004, DIFFUSION MAPS GEOME
   Leng B, 2015, IEEE T IMAGE PROCESS, V24, P94, DOI 10.1109/TIP.2014.2372618
   Li B, 2013, MULTIMED TOOLS APPL, V62, P821, DOI 10.1007/s11042-011-0873-3
   Li C., 2013, THESIS
   Li PJ, 2011, MM 2011 P 19 ACM INT, V11, P1425
   Lian Z, 2011, IEEE INT C 3D IM MOD, P116
   Lian ZH, 2013, PATTERN RECOGN, V46, P449, DOI 10.1016/j.patcog.2012.07.014
   Lipman Y, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531378
   Liu ZB, 2015, NEUROCOMPUTING, V151, P583, DOI 10.1016/j.neucom.2014.06.090
   Lu K, 2014, IEEE T IMAGE PROCESS, V23, P4553, DOI 10.1109/TIP.2014.2343460
   Lyu SW, 2009, IEEE T PATTERN ANAL, V31, P693, DOI 10.1109/TPAMI.2008.107
   Maggioni Mauro, 2005, Proceedings of the SPIE - The International Society for Optical Engineering, V5914, p59141M, DOI 10.1117/12.616909
   Makadia A, 2010, INT J COMPUT VISION, V89, P193, DOI 10.1007/s11263-009-0280-7
   Memoli F., 2007, EUR S POINT BAS GRAP, P81, DOI DOI 10.2312/SPBG/SPBG07/081-090
   Mian A, 2010, INT J COMPUT VISION, V89, P348, DOI 10.1007/s11263-009-0296-z
   Novotni M., 2003, P 8 ACM S SOL MOD AP, P216, DOI DOI 10.1145/781606.781639
   Ovsjanikov Maks, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P320, DOI 10.1109/ICCVW.2009.5457682
   Ovsjanikov M, 2010, COMPUT GRAPH FORUM, V29, P1555, DOI 10.1111/j.1467-8659.2010.01764.x
   Peternell M, 2005, P 21 SPRING C COMP G, P43
   Raviv D, 2010, VISUALIZATION TRANSM, P1
   Reuter M, 2009, COMPUT GRAPH-UK, V33, P381, DOI 10.1016/j.cag.2009.03.005
   Rustamov Raif M, 2007, P S GEOM PROC, V257, P225
   Rusur B, 2008, INT C INT AUT SYST
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   Tabia H, 2014, PROC CVPR IEEE, P4185, DOI 10.1109/CVPR.2014.533
   Tam GKL, 2007, IEEE T VIS COMPUT GR, V13, P470, DOI 10.1109/TVCG.2007.1011
   Wu HY, 2010, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.2010.5540180
   Zhang J., 2005, The mcgill shape benchmark
   Zou GY, 2008, COMPUT ANIMAT VIRT W, V19, P399, DOI 10.1002/cav.244
NR 49
TC 5
Z9 5
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 10207
EP 10230
DI 10.1007/s11042-016-3606-9
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300051
DA 2024-07-18
ER

PT J
AU Rao, YB
   Ding, XS
   Li, J
   Gou, JP
   Wang, QF
AF Rao, Yunbo
   Ding, XianShu
   Li, Jia
   Gou, JianPing
   Wang, Qifei
TI Anterior cruciate ligament reconstruction model based on anatomical
   position locating
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anterior cruciate ligament; Expectation maximization; Gaussian;
   Anatomical position
ID INJURIES; MOMENT
AB In the reconstruction surgery of Anterior Cruciate Ligament (ACL), how to locate the anatomical position is a very hard point to clinician occupational therapists. In this paper, we propose an Anatomical Position Locating (APL) approach based on Expectation Maximization (EM) algorithm. Firstly, the proposed intersection set operation algorithm is proposed to compute the attachment region between the injured ACL and femur or tibia. Then, the anatomical position is located by the 3D points cloud with the Gaussian spatial distribution. The last, the attachment spatial distribution and the barycenter, which are also viewed as the candidates of the anatomical position by a proposed EM algorithm, is partition. Experimental results verify our assumption and demonstrate that the located anatomical position has great serviceability.
C1 [Rao, Yunbo; Ding, XianShu] Univ Elect Sci & Technol China, Sch Informat & Software Engn, Chengdu 610054, Peoples R China.
   [Li, Jia] China West Normal Univ, Sch Comp, Nanchong 637009, Peoples R China.
   [Gou, JianPing] Jiansu Univ, Coll Sci & Engn, Yangzhou 450001, Jiangsu, Peoples R China.
   [Wang, Qifei] Univ Calif Berkeley, Dept EECS, Berkeley, CA 94720 USA.
C3 University of Electronic Science & Technology of China; China West
   Normal University; Jiangsu University; University of California System;
   University of California Berkeley
RP Rao, YB (corresponding author), Univ Elect Sci & Technol China, Sch Informat & Software Engn, Chengdu 610054, Peoples R China.
EM uestc2008@126.com
RI Gou, Jianping/JQX-2453-2023
OI Gou, Jianping/0000-0003-1413-0693
FU National Natural Science Foundation of China [61300092, 61502404,
   61502208]; Fundamental Research Funds for the Central Universities of
   China [ZYGX2013J068]; Industrialization Development Foundation of
   Chengdu Research Institute of UESTC [RWS-CYHKF-02-20150003]; Natural
   Science Foundation of Fujian Province of China [2015J05132]
FX The authors would like to thank the anonymous reviewers for their
   helpful comments. This work is partly supported by the National Natural
   Science Foundation of China(Grant No. 61300092,61502404,61502208), the
   Fundamental Research Funds for the Central Universities of China(Grant
   No. ZYGX2013J068), the Industrialization Development Foundation of
   Chengdu Research Institute of UESTC (Grant No. RWS-CYHKF-02-20150003),
   Natural Science Foundation of Fujian Province of China (Grant No.
   2015J05132).
CR Alentorn-Geli E, 2014, KNEE SURG SPORT TR A, V22, P16, DOI 10.1007/s00167-013-2739-x
   Amandeep KM, 2013, INT J SCI ENG TECHNO, V2, P803
   Bell DR, 2014, J ATHL TRAINING, V49, P154, DOI 10.4085/1062-6050-49.2.01
   Carola FV, 2010, J ARTHROSC RELAT SUR, V26, P258
   Danyal N, 2014, J ARTHOROSCOPY RELAT, V30, P11
   Hensler D, 2013, J BONE JOINT SURG AM, V95A, P2029, DOI 10.2106/JBJS.L.01315
   Herbert A, 2015, J BIOMECH, V48, P22, DOI 10.1016/j.jbiomech.2014.11.013
   Indelman V, 2014, IEEE INT CONF ROBOT, P593, DOI 10.1109/ICRA.2014.6906915
   Julie G, 2008, AM J SPORTS MED, V36, P1476, DOI DOI 10.1177/0363546508318188
   Kellis E, 2015, COMPUT METHOD BIOMEC, V18, P1083, DOI 10.1080/10255842.2013.869323
   LaBella CR, 2014, PEDIATRICS, V133, pE1437, DOI 10.1542/peds.2014-0623
   Leathers MP, 2015, J KNEE SURG, V02, P189
   Magdi SM, 2013, INF SCI, V235, P80
   Malik OA, 2015, IEEE J BIOMED HEALTH, V19, P453, DOI 10.1109/JBHI.2014.2320408
   Martina A, 2014, ORTHOPAEDIC J SPORTS, V2, P1
   Middleton KK, 2014, ARTHROSCOPY, V22, P1467
   Patil DD., 2013, IJCSMC, V2, P22
   Patterson MR, 2014, CLIN BIOMECH, V29, P138, DOI 10.1016/j.clinbiomech.2013.11.021
   Radovan M, 2011, INT ORTHOP, V35, P1093
   Rao Y, 2015, 4 INT C FRONT COMP I
   Richard F, 2015, BR MED J, V49
   Saha PK, 2011, IEEE T BIO-MED ENG, V58, DOI 10.1109/TBME.2011.2129519
   Sarah C, 2015, J ORTHOP SPORT PHYS, V50, P1
   Simon MG, 2009, J SCI MED SPORT, V12, P622
   Sugimoto D, 2014, SPORTS MED, V44, P551, DOI 10.1007/s40279-013-0135-9
   Susan M, 2011, AORN J, V93, P210
   Tomoyuki M, 2013, KNEE SURG SPORT TR A, V22, P336
   Van Ginckel A, 2013, AM J SPORT MED, V41, P550, DOI 10.1177/0363546512473568
   Vila JP, 2013, IEEE T SIGNAL PROCES, V61, P4658, DOI 10.1109/TSP.2013.2272287
   Webster KE, 2014, AM J SPORT MED, V42, P641, DOI 10.1177/0363546513517540
   Zhu WM, 2013, INT ORTHOP, V37, P233, DOI 10.1007/s00264-012-1764-6
NR 31
TC 0
Z9 0
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9943
EP 9958
DI 10.1007/s11042-016-3589-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300038
DA 2024-07-18
ER

PT J
AU De la Fuente, D
   Barba, J
   López, JC
   Peñil, P
   Posadas, H
   Sánchez, P
AF De la Fuente, D.
   Barba, J.
   Lopez, J. C.
   Penil, P.
   Posadas, H.
   Sanchez, P.
TI Synthesis of simulation and implementation code for OpenMAX multimedia
   heterogeneous systems from UML/MARTE models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE OpenMAX; UML/MARTE; SystemC; VHDL; Automatic code generation
AB The design of multimedia systems is becoming a more and more challenging task due to the combination of growing functionalities and strict performance requirements along with reduced time-to-market. In this context, the OpenMAX initiative defines a standard interface for the development and interconnection of HW and SW multimedia components. However, the simulation and implementation steps required to obtain the final prototypes of such complex systems are still a challenge. To solve these problems, this paper presents a framework which enables automatic code generation from high-level UML/MARTE models. SystemC and VHDL codes are synthesized according to the OpenMAX specification requirements and they are integrated with the application SW, derived from task-based systems models. The generation of the SystemC executable specification enables easy simulation and verification of multimedia systems. After this verification stage, the framework automatically provides the VHDL code which feeds the final implementation and synthesis stage for the target platform. To demonstrate this approach, a SOBEL-based use case has been implemented with the developed framework.
C1 [De la Fuente, D.; Barba, J.; Penil, P.; Posadas, H.; Sanchez, P.] Univ Castilla La Mancha, Ciudad Real, Spain.
   [Lopez, J. C.] Univ Castilla La Mancha, Comp Architecture, Ciudad Real, Spain.
   [Lopez, J. C.] Univ Castilla La Mancha, Sch Comp Sci, Ciudad Real, Spain.
C3 Universidad de Castilla-La Mancha; Universidad de Castilla-La Mancha;
   Universidad de Castilla-La Mancha
RP De la Fuente, D (corresponding author), Univ Castilla La Mancha, Ciudad Real, Spain.
EM David.Fuente@uclm.es; Jesus.Barba@uclm.es; JuanCarlos.Lopez@uclm.es;
   pablop@teisa.unican.es; posadash@teisa.unican.es;
   sanchez@teisa.unican.es
RI Sánchez, Paula/GXZ-5366-2022; López, Juan Carlos/ABD-6607-2020; Barba,
   Jesús/Y-8804-2019
OI López, Juan Carlos/0000-0002-7372-1568; Barba,
   Jesús/0000-0003-1931-3245; Penil, Pablo/0000-0003-3741-9764
FU Spanish Ministry of Economy and Competitiveness under the project
   REBECCA [TEC2014-58036-C4-1-R]; European Regional Development Fund;
   Regional Government of Castilla-La Mancha under the project SAND
   [PEII11-0227-0070]
FX This research was supported by the Spanish Ministry of Economy and
   Competitiveness under the project REBECCA (TEC2014-58036-C4-1-R), and by
   European Regional Development Fund and Regional Government of
   Castilla-La Mancha under the project SAND (PEII11-0227-0070).
CR Adaptive Digital Technologies Inc, 2012, AD DIG OPENMAX IL IM
   Andersson P, FDL 07
   [Anonymous], 2010, KHRON APPS SDK
   [Anonymous], 2011, TI SOFTWARE MAKES DE
   [Anonymous], 2012, 16662011 IEEE
   Barba J, EMBEDDED SYSTEMS HIG, P129
   Barba J, DCIS 12
   Barba J, 2007, DSD EUR MICR C DIG S
   Barba J, 2010, IEEE T CONSUM ELECTR, V56, P1722, DOI 10.1109/TCE.2010.5606318
   Bocchio S, DAC WORKSH UML SOCK
   Bruschi F, FOR SPEC DES LANG 02
   Cansell D, 2004, P FDL 04 LILL FRAN
   Herrera F, 2012, JCE
   Kopetz H, 11 IEEE ISORC
   Leite M, 2014, 12 IEEE INT C IND IN
   Lukas S, 2011, UPLINQ C JUN 1 2 MAN
   MARTIN G, 2007, ESL DESIGN VERIFICAT
   Monton M, 2010, ADV DESIGN METHODS M
   Muller W, 2010, IEEE ANN S VLSI ISVL
   Muller Wolfgang., 2003, SystemC: Methodologies and Applications, chapter An ASM based SystemC Simulation Semantics
   Nicolas A, DSD SEAA C 2014 08
   NVIDIA, 2006, DEM HIGH DEF PROC LA
   OMG, 2014, MARTE PROF 1 1
   OMG, 2008, MOF MOD TEXT LANG
   OMG, 2014, UML TEST PROF UTP 1
   Palojarvi J, 2010, MAEMO BASE PORT
   Penil P, 2009, GENERATING HETEROGEN
   Piel E, 2008, P DATE 08 WORKSH MOD
   Quadri IR, 2010, INT J EMBED SYST
   Rintaluoma T, ON2 TECHNOLOGIES OPT, P32
   Schmidt DC, 2006, COMPUTER, V39, P25, DOI 10.1109/MC.2006.58
   Szyperski C., 2002, Component Software: Beyond Object-Oriented Programming
   The Institution of Electronics and Telecommunications Engineers, 2011, IETE TECHNICAL REV
   Urlini G, 2007, BELLAGIO OPENMAX COM
   Vanderperren Y, 2008, J DES AUTOM EMBED SY
   Vanderperren Y, 2008, DES AUTOM EMBED SYST, V12, P261, DOI 10.1007/s10617-008-9028-9
   Vidal J, 2010, UML DESIGN DYNAMICAL
   VisualOn, 2011, ENABLING HOME ENTERT
   Yamashita K, 2010, DES AUT C ASP DAC
NR 39
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8195
EP 8226
DI 10.1007/s11042-016-3448-5
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800027
DA 2024-07-18
ER

PT J
AU Prasad, S
   Kumar, PS
   Ghosh, D
AF Prasad, Shitala
   Kumar, P. Sateesh
   Ghosh, Debashis
TI An efficient low vision plant leaf shape identification system for smart
   phones
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile plant biometric system; Low vision; Shape profile curve; Discrete
   Cosine Transform(DCT); k-NN; Angle View Projection (AVP)
ID RETRIEVAL; SCALE; REPRESENTATION; CLASSIFICATION; COMPLETION; IMAGE
AB In computer vision research, the first most important step is to represent the captured object into some mathematical transformed feature vector describing the proper shape, texture and/or color information for the classification. To understand the nature's biodiversity, together with computer vision (CV), the emerging ubiquitous mobile technologies are now used. Therefore, in this paper, a novel low computational, efficient, and accurate rotation-scaletranslation invariant shape profile transform called Angle View Projection (AVP) is proposed. The leaf images captured via mobile devices are transformed to an AVP shape profile curve (a set of four shapelets) and then compacted using Discrete Cosine Transform (DCT) to improve the performance of the system. It also reduces the energy consumption of the device. The algorithm is tested on five different types of leaf datasets: Flavia dataset, 100 plant species leaves dataset, Swedish database, Intelligent Computing Laboratory leaf dataset and Diseased leaf dataset. An 'Agent' on mobile device decides whether the module needs to offload to the Server or to compute on the device itself. The experiments carried out clearly indicates that the proposed system outperforms the state-of-the-art with a fast response time even in a low vision environment. AVP also outperforms other methods when tested over incomplete leaves caused due to the physiological or pathological phenomenon. This AVP shape profile based mobile plant biometric system is developed for general applications in our society to better understand the nature and helps in botanical studies and researches.
C1 [Prasad, Shitala] Univ Caen Normandy, CNRS, GREYC UMR6072, Caen, France.
   [Kumar, P. Sateesh] Indian Inst Technol, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.
   [Ghosh, Debashis] Indian Inst Technol, Dept Elect & Commun Engn, Roorkee, Uttar Pradesh, India.
C3 Centre National de la Recherche Scientifique (CNRS); Universite de Caen
   Normandie; Indian Institute of Technology System (IIT System); Indian
   Institute of Technology (IIT) - Roorkee; Indian Institute of Technology
   System (IIT System); Indian Institute of Technology (IIT) - Roorkee
RP Prasad, S (corresponding author), Univ Caen Normandy, CNRS, GREYC UMR6072, Caen, France.
EM sheetala.god.prasad@gmail.com
RI Prasad, Shitala/AAI-8449-2020
CR Abbasi S, 1999, MULTIMEDIA SYST, V7, P467, DOI 10.1007/s005300050147
   Adamek T, 2004, IEEE T CIRC SYST VID, V14, P742, DOI 10.1109/TCSVT.2004.826776
   Alajlan N, 2007, PATTERN RECOGN, V40, P1911, DOI 10.1016/j.patcog.2006.12.005
   Amanatiadis A, 2011, IET IMAGE PROCESS, V5, P493, DOI 10.1049/iet-ipr.2009.0246
   [Anonymous], INT J ADV SCI TECHN
   Beghin T, 2010, LECT NOTES COMPUT SC, V6475, P345, DOI 10.1007/978-3-642-17691-3_32
   Chahooki MAZ, 2012, IET IMAGE PROCESS, V6, P327, DOI 10.1049/iet-ipr.2010.0548
   Cope JS, 2012, EXPERT SYST APPL, V39, P7562, DOI 10.1016/j.eswa.2012.01.073
   Daliri MR, 2008, PATTERN RECOGN, V41, P1782, DOI 10.1016/j.patcog.2007.10.020
   Daribo I, 2014, IEEE T IMAGE PROCESS, V23, P4696, DOI 10.1109/TIP.2014.2353817
   Eggleston P, 1993, APPL OPTICAL SCI ENG, P27
   Fan JP, 2015, IEEE T IMAGE PROCESS, V24, P4172, DOI 10.1109/TIP.2015.2457337
   Fowlkes CC, SURVEYING SHAPE SPAC
   Guo G, 2013, CHINESE SCI BULL, V58, P3430, DOI 10.1007/s11434-013-5946-4
   Kurtek S, 2014, IEEE WINT CONF APPL, P293, DOI 10.1109/WACV.2014.6836086
   Laga H, 2014, J THEORETICAL BIOL
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   LESTER JM, 1978, COMPUT BIOL MED, V8, P293, DOI 10.1016/0010-4825(78)90030-6
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Mallah C, 2013, SIGNAL PROC PATTERN
   Mouine S., 2013, ICMR'13 - Proceedings of the 3rd ACM International Conference on Multimedia Retrieval, P127
   NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681
   Prasad S, 2015, SIGNAL IMAGE VIDEO P, P1
   Prasad S, 2014, IEEE WCNC, P3314, DOI 10.1109/WCNC.2014.6953083
   Rensink RA, 1998, VISION RES, V38, P2489, DOI 10.1016/S0042-6989(98)00051-0
   Soderkvist Oskar., 2001, COMPUTER VISION CLAS, P74
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Venkatesh MV, 2006, IEEE IMAGE PROC, P709, DOI 10.1109/ICIP.2006.312439
   Vretblad A., 2003, FOURIER ANAL ITAPP, V223
   Wang B, 2015, INFORM SCIENCES, V302, P132, DOI 10.1016/j.ins.2014.07.028
   Wang B, 2014, IEEE T IMAGE PROCESS, V23, P4101, DOI 10.1109/TIP.2014.2343457
   Wang Z, 2003, IEE P-VIS IMAGE SIGN, V150, P34, DOI 10.1049/ip-vis:20030160
   Wu SG, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P120
NR 35
TC 18
Z9 18
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6915
EP 6939
DI 10.1007/s11042-016-3309-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400037
DA 2024-07-18
ER

PT J
AU Rabie, T
   Kamel, I
AF Rabie, Tamer
   Kamel, Ibrahim
TI Toward optimal embedding capacity for transform domain steganography: a
   quad-tree adaptive-region approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quad tree; Adaptive region; Statistical stationarity; Fixed-block; Data
   hiding; Color steganography; Discrete cosine transform
ID IMAGE; JPEG; WATERMARKING
AB Embedding capacities of steganographic information security systems have remained relatively low due to the adverse effect on perceptibility, where researchers had to trade-off between higher capacities and reduced perceptual quality or choose higher perceptual quality albeit at the expense of lower capacities. This paper proposes a novel approach for color image steganography, in the discrete cosine transform (DCT) domain, that promotes optimal embedding capacity while improving stego image quality. The proposed approach is based on the observation that the space reserved for embedding the secret data varies with the statistical characteristics of the cover image and exploits a quadtree adaptive-region embedding scheme to individuate "good" cover image segments, in relation to the correlation of pixels, for embedding the secret information. We will demonstrate that our scheme exhibits enhanced hiding capacity and perceptibility in comparison to techniques adopting fixed-block-size adaptive-regions in the DCT domain.
C1 [Rabie, Tamer; Kamel, Ibrahim] Univ Sharjah, Dept Elect & Comp Engn, Sharjah, U Arab Emirates.
C3 University of Sharjah
RP Rabie, T (corresponding author), Univ Sharjah, Dept Elect & Comp Engn, Sharjah, U Arab Emirates.
EM trabie@sharjah.ac.ae; kamel@sharjah.ac.ae
FU College of Graduate Studies and Research at the University of Sharjah
FX The authors would like to thank the anonymous reviewers for their
   valuable suggestions that helped improve the original manuscript. This
   work was supported by the College of Graduate Studies and Research at
   the University of Sharjah.
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Anderson RJ, 1998, IEEE J SEL AREA COMM, V16, P474, DOI 10.1109/49.668971
   [Anonymous], 2003, INT J DIG EVID
   Bracamonte J, 2005, LECT NOTES COMPUT SC, V3568, P154
   BRACAMONTE J, 2000, P 6 COST, V276, P88
   Brisbane G, 2005, IEE P-VIS IMAGE SIGN, V152, P787, DOI 10.1049/ip-vis:20045047
   Castleman K. R., 1996, Digital Image Processing
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang CC, 2002, INFORM SCIENCES, V141, P123, DOI 10.1016/S0020-0255(01)00194-3
   Chang CC, 2003, PATTERN RECOGN, V36, P1583, DOI 10.1016/S0031-3203(02)00289-3
   Chang CC, 2008, SOFT COMPUT, V13, P21
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Chang CC, 2006, IEEE T CIRC SYST VID, V16, P1301, DOI 10.1109/TCSVT.2006.882380
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chen WY, 2003, OPT ENG, V42, P2886, DOI 10.1117/1.1604783
   Chung KL, 2001, PATTERN RECOGN LETT, V22, P1051, DOI 10.1016/S0167-8655(01)00044-7
   Cole Eric, 2003, Hiding in Plain Sight: Steganography and the Art of Covert Communication
   Ebrahimpour-Komleh H, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P58, DOI 10.1109/ICIP.2001.958050
   Iwata M, 2004, IEICE T FUND ELECTR, VE87A, P929
   Lee YK, 2000, IEE P-VIS IMAGE SIGN, V147, P288, DOI 10.1049/ip-vis:20000341
   Lin C.-C., 2010, J. Inf. Hiding Multimed. Signal Process, V1, P220
   Lin CH, 2009, PR ELECTROMAGN RES S, P327, DOI 10.1145/1516241.1516298
   Lin CY, 2008, IEICE T INF SYST, VE91D, P836, DOI 10.1093/ietisy/e91-d.3.836
   Mozaffari S, 2005, PROC INT CONF DOC, P819, DOI 10.1109/ICDAR.2005.72
   Pavildis G, 2003, SIGNAL PROCESS-IMAGE, V18, P497, DOI 10.1016/S0923-5965(03)00038-9
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Rabie T, 2005, IEEE T IMAGE PROCESS, V14, P1755, DOI 10.1109/TIP.2005.857276
   Rabie T., 2007, International Journal of Advanced Media and Communication, V1, P298, DOI 10.1504/IJAMC.2007.013952
   Rabie T., 2012, 4 INT C NETW DIG TEC, P217, DOI DOI 10.1007/978-3-642-30567-2_18
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P6473, DOI 10.1007/s11042-016-3301-x
   Rabie T, 2016, MULTIMED TOOLS APPL, V75, P5939, DOI 10.1007/s11042-015-2557-x
   Rabie T, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P858, DOI 10.1109/CISP.2013.6745285
   Rao K.R, 2014, DISCRETE COSINE TRAN
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   TSAI P., 2002, P PAC RIM WORKSH DIG, P54
   Wang X., 2005, IEEE INT C IMAGE PRO, V2, P1090
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Yang B, 2004, PROC SPIE, V5306, P405, DOI 10.1117/12.527216
NR 42
TC 29
Z9 29
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8627
EP 8650
DI 10.1007/s11042-016-3501-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800044
DA 2024-07-18
ER

PT J
AU Sánchez-Nielsen, E
   Chávez-Gutiérrez, F
   Lorenzo-Navarro, J
   Castrillón-Santana, M
AF Sanchez-Nielsen, Elena
   Chavez-Gutierrez, Francisco
   Lorenzo-Navarro, Javier
   Castrillon-Santana, Modesto
TI A multimedia system to produce and deliver video fragments on demand on
   parliamentary websites
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia system; Video fragments on demand; Semantic web technologies;
   Video analytics; Person re-identification
AB Parliamentary websites have become one of the most important windows for citizens and media to follow the activities of their legislatures and to hold parliaments to account. Therefore, most parliamentary institutions aim to provide new multimedia solutions capable of displaying video fragments on demand on plenary activities. This paper presents a multimedia system for parliamentary institutions to produce video fragments on demand through a website with linked information and public feedback that helps to explain the content shown in these fragments. A prototype implementation has been developed for the Canary Islands Parliament (Spain) and shows how traditional parliamentary streaming systems can be enhanced by the use of semantics and computer vision for video analytics. The semantic web technologies used make search capabilities on parliamentary websites available to users to retrieve video fragments on demand with accurate and timely information. In addition, video analytic techniques enable the automation of identifying representative keyframes to be annotated by parliamentary experts. As a result, parliaments are able to enhance citizens' access to information and ensure that these institutions are more open andaccountable on their websites and; at the same time, the labor-intensive tasks of parliamentary experts are considerably reduced.
C1 [Sanchez-Nielsen, Elena; Chavez-Gutierrez, Francisco] Univ La Laguna, Dept Ingn Informat Sistemas, Santa Cruz de Tenerife 38271, Spain.
   [Chavez-Gutierrez, Francisco] Parlamento Canarias, Teobaldo Power 7, Santa Cruz de Tenerife 38002, Spain.
   [Lorenzo-Navarro, Javier; Castrillon-Santana, Modesto] Univ Palmas Gran Canaria, SIANI, Gran Canaria 35017, Spain.
C3 Universidad de la Laguna; Universidad de Las Palmas de Gran Canaria
RP Sánchez-Nielsen, E (corresponding author), Univ La Laguna, Dept Ingn Informat Sistemas, Santa Cruz de Tenerife 38271, Spain.
EM enielsen@ull.edu.es; fchavez@parcan.es; javier.lorenzo@ulpgc.es;
   modesto.castrillon@ulpgc.es
RI Sánchez-Nielsen, Elena/HTT-2627-2023; Navarro, Javier
   Lorenzo/L-1972-2014; Castrillón-Santana, Modesto/C-6662-2008
OI Sánchez-Nielsen, Elena/0000-0003-2114-4137; Navarro, Javier
   Lorenzo/0000-0002-2834-2067; Castrillón-Santana,
   Modesto/0000-0002-8673-2725; Chavez Gutierrez,
   Francisco/0000-0002-0319-394X
FU European Union [CIP_ICT-2009-3bis]; Spanish Government [TIN 2011-24598]
FX The work presented in this paper has been funded in part by the European
   Union under the project Puzzled by Policy - CIP_ICT-2009-3bis and in
   part by the Spanish Government under the project TIN 2011-24598.
CR Abdallah S, 2007, TIMELINE ONTOLOGY
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Miro XA, 2012, IEEE T AUDIO SPEECH, V20, P356, DOI 10.1109/TASL.2011.2125954
   Barra-Chicote R, 2011, IEEE T AUDIO SPEECH, V19, P754, DOI 10.1109/TASL.2010.2062507
   Bauml M, 2012, C COMP PATT REC CVPR
   Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   Berners-Lee T, 2006, INT J SEMANT WEB INF, V4, P1, DOI DOI 10.4018/JSWIS.2009081901
   Bertot JC, 2010, GOV INFORM Q, V27, P264, DOI 10.1016/j.giq.2010.03.001
   Bizer C, 2009, INT J SEMANT WEB INF, V5, P1, DOI 10.4018/jswis.2009081901
   Bpedia D, 2014, DBPEDIA ONTOLOGY 3 9
   Breslin JG, 2005, LECT NOTES COMPUT SC, V3532, P500
   Brickley D., 2014, 099 FOAF
   Bulterman D, 2005, SYNCHRONIZED MULTIME
   Castrillon Santana M, 2011, MACH VIS APPL, V22
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Cong DNT, 2010, SIGNAL PROCESS, V90, P2362, DOI 10.1016/j.sigpro.2009.09.005
   Cover T.M., 2006, ELEMENTS INFORM THEO
   Déniz O, 2011, PATTERN RECOGN LETT, V32, P1598, DOI 10.1016/j.patrec.2011.01.004
   Dublin Core Metadata Innovation, 2006, DCMI TERM DECL REPR
   EBU/ETSI, 2008, 10282231 EBUETSI TS
   Eurovoc, 2014, EUS MULT THES
   Global Centre for ICT in Parliament United Nations Department of Economic and Social Affairs, 2012, WORLD E PARL REP 201
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Hausenblas Michael, 2010, Proceedings of the Second International Conference on Advances in Databases, Knowledge, and Data Applications (DBKDA 2010), P56, DOI 10.1109/DBKDA.2010.23
   Hausenblas M, 2009, LDOW2009
   Inter-Parliamentary Union (IPU), 2009, GUID CONT STRUCT PAR
   ISO/IEC, 2006, 2100017 ISOIEC
   ISO/IEC, 2002, 159381 ISOIEC
   Knox M, 2010, P ISCA INT MAK, P290
   Kontopoulos E, 2013, EXPERT SYST APPL, V40, P4065, DOI 10.1016/j.eswa.2013.01.001
   Kumar Neeraj, 2011, IEEE Trans Pattern Anal Mach Intell, V33, P1962, DOI 10.1109/TPAMI.2011.48
   Lefèvre S, 2007, J REAL-TIME IMAGE PR, V2, P23, DOI 10.1007/s11554-007-0033-1
   Li Y, 2011, ACM WEB SCI C 2011 K
   Li Yuan, 2012, JDCTA INT J DIGITAL, V6, P203
   Lorenzo-Navarro J, 2015, WORKSH VID AN AUD ME
   Mannens E, 2012, MULTIMED TOOLS APPL, V59, P691, DOI 10.1007/s11042-010-0683-z
   OpenLink Software, 2014, VIRT UN SERV
   Saif H., 2012, CEUR WORKSHOP P, P2
   Schandl B, 2012, MULTIMED TOOLS APPL, V59, P523, DOI 10.1007/s11042-011-0762-9
   Sikora T, 2001, IEEE T CIRC SYST VID, V11, P696, DOI 10.1109/76.927422
   Stankovic M, 2009, MALLOW2009
   Studer R, 1998, DATA KNOWL ENG, V25, P161, DOI 10.1016/S0169-023X(97)00056-6
   Vezzani R, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543596
   Vila M, 2013, SIGNAL IMAGE VIDEO P, V7, P507, DOI 10.1007/s11760-013-0452-3
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   W3C, 2012, MED FRAGM URI 1 0
   W3C, 2008, SEM WEB ACT SPARQL Q
   W3C, 2014, W3C SEM WEB ACT RFC
   W3C, 2014, W3C SEM WEB ACT RES
   W3C, 2012, ONT MED RES 1 0
   Wang T, 2014, P EUR C COMP VIS ECC
NR 51
TC 6
Z9 9
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6281
EP 6307
DI 10.1007/s11042-016-3306-5
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400011
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Tawadrous, M
   Rojas, D
   Kapralos, B
   Hogue, A
   Dubrowski, A
AF Tawadrous, Mina
   Rojas, David
   Kapralos, Bill
   Hogue, Andrew
   Dubrowski, Adam
TI The effects of stereoscopic 3D on knowledge retention within a serious
   gaming environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stereoscopic 3D; Knowledge retention; Serious games
ID VIRTUAL-REALITY; CHILDREN; SURGERY
AB We present the results of an experiment that investigated the effects of stereoscopic 3D viewing on knowledge retention with respect to a spatial interactive task within a serious game that was designed for fire safety training. Participants were trained to identify the safe distance to remain from a ( virtual) fire in both stereoscopic 3D and non-stereoscopic 3D contexts. After a 24 h period, they were then tested to determine whether they retained the information that they were taught. Contrary to prior work that suggests stereoscopic 3D has an impact on knowledge retention, our results indicate no significant difference between knowledge retention in a stereoscopic 3D versus a non-stereoscopic 3D interactive environment. Although greater work remains to be done and no firm conclusions can be made regarding the use of stereoscopic 3D, our results have shown that stereoscopic 3D does not always lead to greater performance. Our results have implications for designers of serious games; the discussion and decision to use stereoscopic 3D should be incorporated early in the design phase and there should be some consideration placed on individualized calibration of stereoscopic 3D settings.
C1 [Tawadrous, Mina; Kapralos, Bill; Hogue, Andrew] Univ Ontario, Inst Technol, Fac Business & Informat Technol, 2000 Simcoe St North, Oshawa, ON L1H 7K4, Canada.
   [Rojas, David] Univ Toronto, Inst Med Sci, Toronto, ON, Canada.
   [Dubrowski, Adam] Mem Univ, Fac Med, Div Emergency Med, St John, NF, Canada.
   [Dubrowski, Adam] Mem Univ, Fac Med, Div Pediat, St John, NF, Canada.
C3 Ontario Tech University; University of Toronto; Memorial University
   Newfoundland; Memorial University Newfoundland
RP Kapralos, B (corresponding author), Univ Ontario, Inst Technol, Fac Business & Informat Technol, 2000 Simcoe St North, Oshawa, ON L1H 7K4, Canada.
EM mina.88@gmail.com; david.rojasgualdron@uoit.ca; bill.kapralos@uoit.ca;
   Andrew.hogue@uoit.ca; adam.dubrowski@gmail.com
FU Social Sciences and Humanities Research Council of Canada (SSHRC);
   Canadian Network of Centres of Excellence (NCE); Natural Sciences and
   Engineering Research Council of Canada (NSERC); Interactive and
   Multi-Modal Experience Research Syndicate (IMMERSe) project
FX The financial support of the Social Sciences and Humanities Research
   Council of Canada (SSHRC), in support of the Interactive and Multi-Modal
   Experience Research Syndicate (IMMERSe) project, the Canadian Network of
   Centres of Excellence (NCE) in support of the Graphics, Animation, and
   New Media (GRAND) initiative, and the Natural Sciences and Engineering
   Research Council of Canada (NSERC) is gratefully acknowledged.
CR Adamo-Villani N., 2007, P ACM SIGGRAPH 2007
   Akerstrom R. A., 1988, ATTEN PERCEPT PSYCHO, V44, P421, DOI DOI 10.3758/BF03210426
   Bastanlar Y., 2007, P 3DTV C 7 9 MAY 200, P1, DOI 10.1109/3DTV.2007.4379410
   Bennett Adam., 2010, Proceedings of the 7th symposium on Applied Perception in Graphics and Visualization, P135
   COOPER J, 1979, J AM OPTOM ASSOC, V50, P821
   Corti K., 2006, GAME BASED LEARNING
   DRASCIC D, 1991, P HUM FACT ERG SOC A, P1367
   Fisch S. M., 2004, IMPACT MEDIA TECHNOL
   Fisch ShalomM., 2005, IDC 05, P56, DOI DOI 10.1145/1109540.1109548
   Fisk T, 2010, 201006MP ARC
   Galimore JJ, 1993, INT J HUM-COMPUT INT, V5, P361
   Hays RT, 2005, 2005004 US NAV AIR W
   Henn JS, 2002, J NEUROSURG, V96, P144, DOI 10.3171/jns.2002.96.1.0144
   Hollander A, 2012, P SOC PHOTO-OPT INS, V7863
   Hubona G. S., 1999, ACM Transactions on Computer-Human Interaction, V6, P214, DOI 10.1145/329693.329695
   Jones JA, 2008, APGV 2008: PROCEEDINGS OF THE SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, P9
   LaViola J, 2012, P SIGCHI C HUM FACT, P2345
   Markopoulos P, 2003, INTERACT COMPUT, V15, P141, DOI 10.1016/S0953-5438(03)00004-3
   Mather G., 2006, Foundations of Perception
   Mayer R.E., 2005, Multimedia Learning, V2nd
   Norman G, 2012, MED EDUC, V46, P636, DOI 10.1111/j.1365-2923.2012.04243.x
   Pawlik TimothyM., 2011, Annals of Surgery, V253, P846
   Reitinger B, 2006, IEEE COMPUT GRAPH, V26, P36, DOI 10.1109/MCG.2006.131
   Schertenleib S., PLAYSTATION 3 MAKING
   Schiefele J, 1999, P 3 INT IMM PROJ TEC
   SCHNELL T, 2002, TERRAIN SAMPLING DEN
   Shute VJ., 2009, Serious games, P317
   Tai YC, 2013, P SPIE, V8648
   Tavanti M, 2001, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2001, PROCEEDINGS, P139, DOI 10.1109/INFVIS.2001.963291
   Tawadrous M, INT J TECH KNOWL SOC, V8, P177
   Tawadrous M, 2013, P SPIE, V8648
   Tendick F, 2000, PRESENCE-VIRTUAL AUG, V9, P236, DOI 10.1162/105474600566772
   UCSF, 2012, MED ED POT CONTR STE
   Vasilyev NV, 2008, J THORAC CARDIOV SUR, V135, P1334, DOI 10.1016/j.jtcvs.2007.12.045
   Willemsen P, 2008, PRESENCE-TELEOP VIRT, V17, P91, DOI 10.1162/pres.17.1.91
   YEH YY, 1992, HUM FACTORS, V34, P583, DOI 10.1177/001872089203400506
   Zerebecki C, 2013, P SPIE, V8648
NR 37
TC 6
Z9 8
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 7301
EP 7319
DI 10.1007/s11042-016-3394-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400053
DA 2024-07-18
ER

PT J
AU Yang, E
   Gwak, J
   Jeon, M
AF Yang, Ehwa
   Gwak, Jeonghwan
   Jeon, Moongu
TI Multi-human tracking using part-based appearance modelling and
   grouping-based tracklet association for visual surveillance applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-human tracking; Part-based appearance model; Grouping-based
   tracklet association; Data association
ID PARTIALLY OCCLUDED HUMANS; BAYESIAN COMBINATION; MULTITARGET TRACKING;
   OBJECT DETECTION; HISTOGRAMS; FILTER; IMAGE
AB Although much progress has been made in multi-object tracking in recent decades due to its variety of applications including visual surveillance, traffic monitoring and medical image analysis, some difficult challenges such as the variation of object appearance and partial occlusion are still going on. In this work, we propose an effective multi-human tracking system called part-based appearance modelling and grouping-based tracklet association-based multi-human tracking (PAM-GTA-MHT). The proposed appearance model based on the upper body-centered multi-view human body part model can effectively resolve the drawback caused by inter-object occlusions and low camera positions. The grouping method embedded in global tracklet association can improve discriminability among targets with similar appearances when they are located sufficiently far away from each other. Thus, there is no need to compare all possible pairs of the detected targets in the tracklet association stage and thus it has the potential to enhance the tracking speed. We quantitatively evaluated the performance of our proposed approach on four challenging publicly available datasets and achieved a significant improvement compared to the state-of-the-art methods.
C1 [Yang, Ehwa; Gwak, Jeonghwan; Jeon, Moongu] Gwangju Inst Sci & Technol, Sch Informat & Commun, 123 Cheomdangwagi Ro, Gwangju 61005, South Korea.
C3 Gwangju Institute of Science & Technology (GIST)
RP Jeon, M (corresponding author), Gwangju Inst Sci & Technol, Sch Informat & Commun, 123 Cheomdangwagi Ro, Gwangju 61005, South Korea.
EM ehwa@gist.ac.kr; james.han.gwak@gmail.com; mgjeon@gist.ac.kr
RI Jeon, Moongu/A-1009-2012
OI Gwak, Jeonghwan/0000-0002-6237-0141
FU ICT R&D Program of MSIP/IITP [B0101-15-0525]; Center for Integrated
   Smart Sensors as Global Frontier [CISS-2013M3A6A6073718]
FX This work was supported by the ICT R&D Program of MSIP/IITP (Grant No.
   B0101-15-0525, Development of global multi-target tracking and event
   prediction techniques based on real-time large-scale video analysis),
   and Center for Integrated Smart Sensors as Global Frontier
   (CISS-2013M3A6A6073718).
CR Andriluka M., 2008, PROC IEEE C COMPUT V, P1
   Andriyenko A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1839, DOI 10.1109/ICCVW.2011.6130472
   Andriyenko A, 2011, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2011.5995311
   [Anonymous], P 11 EUR C COMP VIS
   [Anonymous], 2007, 2007 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2007.383197
   [Anonymous], P 11 EUR C COMP VIS
   [Anonymous], 2012, PROC ASIAN C COMPUT
   [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Berclaz J., 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, V1, P744, DOI DOI 10.1109/CVPR.2006.258
   Birchfield ST, 2005, PROC CVPR IEEE, P1158
   Breitenstein MD, 2009, IEEE I CONF COMP VIS, P1515, DOI 10.1109/ICCV.2009.5459278
   Brendel W, 2011, PROC CVPR IEEE, P1273, DOI 10.1109/CVPR.2011.5995395
   Cai YZ, 2006, LECT NOTES COMPUT SC, V3954, P107
   Cannons KJ, 2010, LECT NOTES COMPUT SC, V6314, P511, DOI 10.1007/978-3-642-15561-1_37
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ess A., 2008, COMPUTER VISION PATT, V2008, P1, DOI [10.1109/CVPR.2008.4587581, DOI 10.1109/CVPR.2008.4587581]
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Fulkerson B, 2008, LECT NOTES COMPUT SC, V5302, P179, DOI 10.1007/978-3-540-88682-2_15
   Grabner H, 2010, PROC CVPR IEEE, P1285, DOI 10.1109/CVPR.2010.5539819
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Heili A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1673, DOI 10.1109/ICCVW.2011.6130451
   Hou C, 2007, LECT NOTES COMPUT SC, V4843, P210
   Huang C, 2008, LECT NOTES COMPUT SC, V5303, P788, DOI 10.1007/978-3-540-88688-4_58
   Jian-Yu Hsieh, 2007, Proceedings of the Fifth IASTED International Conference on Circuits, Signals, and Systems, P1, DOI 10.1145/1329125.1329139
   Kuo CH, 2011, PROC CVPR IEEE, P1217, DOI 10.1109/CVPR.2011.5995384
   Kuo CH, 2010, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2010.5540148
   Leibe B, 2007, PROC IEEE INT C COMP, P1
   Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3
   Levi K, 2004, PROC CVPR IEEE, P53
   Li Y, 2008, IEEE T PATTERN ANAL, V30, P1728, DOI 10.1109/TPAMI.2008.73
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   Perera AGA, 2006, IEEE COMP SOC C COMP, P666
   Pirsiavash H, 2011, PROC CVPR IEEE, P1201, DOI 10.1109/CVPR.2011.5995604
   Tsochantaridis Ioannis., 2004, PROC 21 INT C MACHIN, P104
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Walk S, 2010, PROC CVPR IEEE, P1030, DOI 10.1109/CVPR.2010.5540102
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Wu B, 2005, IEEE I CONF COMP VIS, P90
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Xing JL, 2009, PROC CVPR IEEE, P1200, DOI 10.1109/CVPRW.2009.5206745
   Yang B, 2012, PROC CVPR IEEE, P2034, DOI 10.1109/CVPR.2012.6247907
   Yang B, 2012, PROC CVPR IEEE, P1918, DOI 10.1109/CVPR.2012.6247892
   Yang B, 2011, PROC CVPR IEEE, P1233, DOI 10.1109/CVPR.2011.5995587
   Yu Q, 2009, IEEE T PATTERN ANAL, V31, P2196, DOI 10.1109/TPAMI.2008.253
   Yuan Li, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2953, DOI 10.1109/CVPRW.2009.5206735
   Zhang LJ, 2008, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD006286.pub2
NR 50
TC 7
Z9 9
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6731
EP 6754
DI 10.1007/s11042-015-3219-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400029
DA 2024-07-18
ER

PT J
AU Zand, M
   Doraisamy, S
   Halin, AA
   Mustaffa, MR
AF Zand, Mohsen
   Doraisamy, Shyamala
   Halin, Alfian Abdul
   Mustaffa, Mas Rina
TI Visual and semantic context modeling for scene-centric image annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic image annotation; Visual diversity; Mixture model; Visual
   context; Semantic context
ID SUPPORT VECTOR MACHINES; RETRIEVAL
AB Automatic image annotation enables efficient indexing and retrieval of the images in the large-scale image collections, where manual image labeling is an expensive and labor intensive task. This paper proposes a novel approach to automatically annotate images by coherent semantic concepts learned from image contents. It exploits sub-visual distributions from each visually complex semantic class, disambiguates visual descriptors in a visual context space, and assigns image annotations by modeling image semantic context. The sub-visual distributions are discovered through a clustering algorithm, and probabilistically associated with semantic classes using mixture models. The clustering algorithm can handle the inner-category visual diversity of the semantic concepts with the curse of dimensionality of the image descriptors. Hence, mixture models that formulate the sub-visual distributions assign relevant semantic classes to local descriptors. To capture non-ambiguous and visual-consistent local descriptors, the visual context is learned by a probabilistic Latent Semantic Analysis (pLSA) model that ties up images and their visual contents. In order to maximize the annotation consistency for each image, another context model characterizes the contextual relationships between semantic concepts using a concept graph. Therefore, image labels are finally specialized for each image in a scene-centric view, where images are considered as unified entities. In this way, highly consistent annotations are probabilistically assigned to images, which are closely correlated with the visual contents and true semantics of the images. Experimental validation on several datasets shows that this method outperforms state-of-the-art annotation algorithms, while effectively captures consistent labels for each image.
C1 [Zand, Mohsen; Doraisamy, Shyamala; Halin, Alfian Abdul; Mustaffa, Mas Rina] Univ Putra Malaysia, Dept Multimedia, Fac Comp Sci & Informat Technol, Serdang, Selangor, Malaysia.
C3 Universiti Putra Malaysia
RP Zand, M (corresponding author), Univ Putra Malaysia, Dept Multimedia, Fac Comp Sci & Informat Technol, Serdang, Selangor, Malaysia.
EM m.mohsen.zand@ieee.org
RI Zand, Mohsen/ABB-9707-2020; MUSTAFFA, MAS RINA/B-1763-2017; Abdul Halin,
   Alfian/D-1502-2017
OI Zand, Mohsen/0000-0001-8177-6000; MUSTAFFA, MAS
   RINA/0000-0001-5088-2871; Abdul Halin, Alfian/0000-0002-0318-4496;
   Doraisamy, Shyamala/0000-0001-5502-8754
CR Amiri SH, 2015, PATTERN RECOGN, V48, P174, DOI 10.1016/j.patcog.2014.07.012
   Ankerst M, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P49
   [Anonymous], 2010, PROC ACM SIGMM INT C
   [Anonymous], 2008, P 7 ACM INT C IMAGE
   [Anonymous], 1996, P AAAI INT C KNOWL D
   Assari SM, 2014, PROC CVPR IEEE, P2529, DOI 10.1109/CVPR.2014.324
   Bannour H, 2014, MULTIMED TOOLS APPL, V72, P2107, DOI 10.1007/s11042-013-1491-z
   Bao BK, 2012, IEEE T MULTIMEDIA, V14, P199, DOI 10.1109/TMM.2011.2170557
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Bouveyron C, 2007, COMPUT STAT DATA AN, V52, P502, DOI 10.1016/j.csda.2007.02.009
   Nguyen CT, 2013, ACM T WEB, V7, DOI 10.1145/2516633.2516634
   Campello R, 2013, LNAI, V160-172
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646
   Chen ZH, 2012, IEEE T SYST MAN CY C, V42, P1120, DOI 10.1109/TSMCC.2011.2178831
   Chua T.-S., 2009, CIVR, P1, DOI 10.1145/1646396.1646452
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100
   Fernando B, 2012, LECT NOTES COMPUT SC, V7572, P214, DOI 10.1007/978-3-642-33718-5_16
   Gao SH, 2013, IEEE T PATTERN ANAL, V35, P92, DOI 10.1109/TPAMI.2012.63
   Gao Y, 2014, IEEE T IMAGE PROCESS, V23, P5400, DOI 10.1109/TIP.2014.2364536
   Gould S, 2008, INT J COMPUT VISION, V80, P300, DOI 10.1007/s11263-008-0140-x
   Guha S., 1998, CURE, P73, DOI DOI 10.1145/276305.276312
   He X, 2004, P 2004 IE COMP SOC C
   Izadinia H, 2012, LECT NOTES COMPUT SC, V7575, P430, DOI 10.1007/978-3-642-33765-9_31
   Escalante HJ, 2010, COMPUT VIS IMAGE UND, V114, P419, DOI 10.1016/j.cviu.2009.03.008
   Jiang W, 2007, INT CONF ACOUST SPEE, P949
   Kai He, 2014, Advances in Multimedia Information Processing - PCM 2014. 15th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 8879, P93, DOI 10.1007/978-3-319-13168-9_10
   Ladicky L, 2009, IEEE I CONF COMP VIS, P739, DOI 10.1109/ICCV.2009.5459248
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Lazebnik S, 2009, IEEE T PATTERN ANAL, V31, P1294, DOI 10.1109/TPAMI.2008.138
   Leung CHC, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168761
   Li J, 2008, IEEE T PATTERN ANAL, V30, P985, DOI 10.1109/TPAMI.2007.70847
   Li L, 2012, IEEE T MULTIMEDIA, V14, P1401, DOI 10.1109/TMM.2012.2194993
   Li ZC, 2014, COMPUT VIS IMAGE UND, V124, P71, DOI 10.1016/j.cviu.2014.02.001
   Liu WF, 2014, COMPUT VIS IMAGE UND, V118, P50, DOI 10.1016/j.cviu.2013.03.007
   Liu WF, 2013, IEEE T IMAGE PROCESS, V22, P2676, DOI 10.1109/TIP.2013.2255302
   Llorente A., 2010, P ACM INT C IM VID R, P243
   Ma ZG, 2012, IEEE T MULTIMEDIA, V14, P1021, DOI 10.1109/TMM.2012.2187179
   Makadia A, 2010, INT J COMPUT VISION, V90, P88, DOI 10.1007/s11263-010-0338-6
   Parsons L., 2004, ACM SIGKDD EXPLOR NE, V6, P90, DOI DOI 10.1145/1007730.1007731
   Rabinovich A, 2007, IEEE I CONF COMP VIS, P1237, DOI 10.1109/iccv.2007.4408986
   Rasiwasia N, 2009, PROC CVPR IEEE, P1889, DOI 10.1109/CVPRW.2009.5206826
   Russell B.C., 2006, Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on, V2, P1605, DOI DOI 10.1109/CVPR.2006.326
   Schütt M, 2004, PEPTIDE REVOLUTION: GENOMICS, PROTEOMICS & THERAPEUTICS, P41
   Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Song XH, 2015, MULTIMED TOOLS APPL, V74, P595, DOI 10.1007/s11042-014-1975-5
   Su JH, 2011, IEEE T KNOWL DATA EN, V23, P360, DOI 10.1109/TKDE.2010.124
   Tao DP, 2013, IEEE T MULTIMEDIA, V15, P833, DOI 10.1109/TMM.2013.2238909
   Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448
   van Gemert JC, 2010, COMPUT VIS IMAGE UND, V114, P450, DOI 10.1016/j.cviu.2009.08.004
   Vogel J, 2007, INT J COMPUT VISION, V72, P133, DOI 10.1007/s11263-006-8614-1
   Wang H., 2014, MODEM RHEUMATOLOGY, P1
   Wang XR, 2015, MULTIMED TOOLS APPL, V74, P2055, DOI 10.1007/s11042-013-1742-z
   Wang Y, 2009, PATTERN RECOGN, V42, P259, DOI 10.1016/j.patcog.2008.05.010
   Xiang Y, 2010, PROC CVPR IEEE, P3368, DOI 10.1109/CVPR.2010.5540015
   Xu C, 2014, IEEE T PATTERN ANAL, V36, P1559, DOI 10.1109/TPAMI.2013.2296528
   Zha Z.-J., 2008, 2008 IEEE C COMPUTER, DOI DOI 10.1109/CVPR.2008.4587384
   Zhang DS, 2013, J VIS COMMUN IMAGE R, V24, P1087, DOI 10.1016/j.jvcir.2013.07.004
   Zhang DS, 2012, PATTERN RECOGN, V45, P346, DOI 10.1016/j.patcog.2011.05.013
   Zhang SL, 2014, COMPUT VIS IMAGE UND, V118, P16, DOI 10.1016/j.cviu.2013.03.008
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1025, DOI 10.1145/2647868.2655035
   Zheng YT, 2009, VISUAL COMPUT, V25, P13, DOI 10.1007/s00371-008-0294-0
NR 65
TC 4
Z9 4
U1 8
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8547
EP 8571
DI 10.1007/s11042-016-3500-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800041
DA 2024-07-18
ER

PT J
AU Zarraonandia, T
   Diaz, P
   Aedo, I
AF Zarraonandia, Telmo
   Diaz, Paloma
   Aedo, Ignacio
TI Using combinatorial creativity to support end-user design of digital
   games
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Serious games; Digital games; Design methods; Design tools; Game based
   learning
ID PERCEIVED EASE; EDUCATION
AB To really exploit the full potential of computer games in areas other than entertainment, it will be necessary to reduce the high cost associated with their design and development and to put their production directly into the hands of the domain experts. Although these experts might be interested in integrating games in their activities, they normally do not have the required technical background to create or adapt games to their needs. We propose to tackle the complexity of game design, and thereby facilitate end user design, by defining the games as a combination of more simple games following a combinatorial creativity approach. This approach does not impose the cognitive overload of learning a new design language. In addition, it might also speed up the description of the games insofar as designers do not start from scratch, trying to match their ideas with game components, but they rely upon a set of archetypical games they can combine to reach their goals. The design technique is complemented with a game platform that offers a set of authoring tools for describing game designs that can be exported to XML files, and a game engine able to interpret such files and automatically generate a 3D virtual environment in which the games can be played. In this way, designers can envision games they will be able to design in an iterative way and play the games they design to assess their validity. The proposed combinatorial approach has been evaluated in two focus group experiences that validate its feasibility and acceptability both by technical and non-technical users.
C1 [Zarraonandia, Telmo; Diaz, Paloma; Aedo, Ignacio] Univ Carlos III Madrid, Dept Comp Sci, Madrid, Spain.
C3 Universidad Carlos III de Madrid
RP Zarraonandia, T (corresponding author), Univ Carlos III Madrid, Dept Comp Sci, Madrid, Spain.
EM tzarraon@inf.uc3m.es; pdp@inf.uc3m.es; aedo@ia.uc3m.es
RI Diaz, Paloma/E-8606-2016; Aedo, Ignacio/F-3222-2014; Zarraonandia,
   Telmo/K-7177-2012
OI DIAZ PEREZ, MARIA PALOMA/0000-0002-9493-7739; Aedo,
   Ignacio/0000-0001-5819-0511; Zarraonandia, Telmo/0000-0003-3574-0984
FU project CREAx - Spanish Ministry of Science and Innovation
   [TIN2014-56534-R]
FX This work is supported by the project CREAx funded by the Spanish
   Ministry of Science and Innovation (TIN2014-56534-R).
CR Alexander C., 1977, PATTERN LANGUAGE TOW
   Ampatzoglou A, 2007, INFORM SOFTWARE TECH, V49, P445, DOI 10.1016/j.infsof.2006.07.003
   Ampatzoglou A, 2010, INFORM SOFTWARE TECH, V52, P888, DOI 10.1016/j.infsof.2010.05.004
   [Anonymous], 2005, Learning by doing: a comprehensive guide to simulations, computer games, and pedagogy in e-learning and other educational experiences
   Bilas S, 2002, P GAM DEV C
   Bjork Staffan., 2005, Patterns in Game Design
   Boden M.A., 2004, CREATIVE MIND MYTHS
   Cho H, 2008, P 10 IEEE INT C ADV
   Collins, 2015, COLLINS ENGLISH DICT
   Davidsson O., 2004, Game design patterns for mobile games
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Dondi C, 2007, BRIT J EDUC TECHNOL, V38, P502, DOI 10.1111/j.1467-8535.2007.00713.x
   Druckman D, 1995, ED EFFECTIVENESS INT
   Folmer E, 2007, LECT NOTES COMPUT SC, V4608, P66
   Furtado AWB, 2011, IEEE SOFTWARE, V28, P30, DOI 10.1109/MS.2011.101
   Hardy S, 2015, MULTIMED TOOLS APPL, V74, P5289, DOI 10.1007/s11042-014-2009-z
   Iacovides I, 2015, HUMAN COMPUTER INTER, V30
   Katsionis G, 2008, MULTIMED TOOLS APPL, V39, P47, DOI 10.1007/s11042-007-0155-2
   Kreimeier B, 2012, CASE GAME DESIGN PAT
   Lieberman H, 2006, HUM COM INT, V9, P1
   McNaughton M, 2004, P 19 INT C AUT SOFTW
   Mehm F, 2012, P 6 EUR C GAM BAS LE
   Montero Reyno E, 2008, P GAMEON
   Moody D. L., 2003, P EUR C INF SYST ECI
   Musil J, 2010, COMM COM INF SC, V99, P83
   Onuczko C, 2005, P GAMEON N AM
   PRENSKY M, 2001, TRUE BELIEVERS DIGIT
   Salen Katie, 2004, RULES PLAY GAME DESI
   Susi T., 2007, SERIOUS GAMES OVERVI
   Takayama, 2006, P 6 C DES INT SYST D
   Torrente J, 2008, P 2008 INT C ADV COM
   Toups Zachary., 2009, P ACM 2009 INT C SUP
   Venkatesh V, 1996, DECISION SCI, V27, P451, DOI 10.1111/j.1540-5915.1996.tb01822.x
   Virvou M, 2005, EDUC TECHNOL SOC, V8, P54
   Virvou M, 2008, COMPUT EDUC, V50, P154, DOI 10.1016/j.compedu.2006.04.004
   Von Hippel Eric, 2005, Democratizing Innovation
   Westera W, 2008, J COMPUT ASSIST LEAR, V24, P420, DOI 10.1111/j.1365-2729.2008.00279.x
   Zarraonandia T, 2015, MULTIMED TOOLS APPL, V74, P4535, DOI 10.1007/s11042-013-1821-1
   Zhang W, 2005, SOFTWARE PRODUCT LIN
NR 39
TC 13
Z9 15
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 9073
EP 9098
DI 10.1007/s11042-016-3457-4
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800065
DA 2024-07-18
ER

PT J
AU Hsieh, MY
   Chou, WK
   Li, KC
AF Hsieh, Meng-Yen
   Chou, Wen-Kuang
   Li, Kuan-Ching
TI Building a mobile movie recommendation service by user rating and APP
   usage with linked data on Hadoop
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommendation; Linked data; MapReduce; Clustering; Movie
AB Movie recommendation systems are important tools that suggest films with respect to users' choices through item-based collaborative filter algorithms, and have shown positive effect on the provider's revenue. Given that mobile Apps are rapidly growing, the recommender is implemented to support web services in frontend Apps. Among those films recommended, users can give ratings and feedback, collecting film information from linked data concurrently. In order to solve cold-start problems, Cluster-based Matrix Factorization is adopted to model user implicit ratings related to Apps usage. Knowing that user rating data processing is a large-scale problem in producing high quality recommendations, MapReduce and NoSQL environments are employed in performing efficient similarity measurement algorithms whilst maintaining rating and film datasets. In this investigation, the system analyzes user feedbacks to evaluate the recommendation accuracy through metrics of precision, recall and F-score rates, while cold-start users make use the system with two Movie Lens datasets as main rating reference in the recommendation system.
C1 [Hsieh, Meng-Yen; Li, Kuan-Ching] Providence Univ, Dept Comp Sci & Informat Engn CSIE, Taichung, Taiwan.
   [Chou, Wen-Kuang] Providence Univ, Dept Comp Sci & Informat Management CSIM, Taichung, Taiwan.
C3 Providence University - Taiwan; Providence University - Taiwan
RP Li, KC (corresponding author), Providence Univ, Dept Comp Sci & Informat Engn CSIE, Taichung, Taiwan.
EM mengyen@pu.edu.tw; wkchou@pu.edu.tw; kuancli@pu.edu.tw
RI Li, Kuan-Ching/F-4966-2010; Li, K/S-4073-2019
OI Li, Kuan-Ching/0000-0003-1381-4364; Li, K/0000-0003-1381-4364
FU Ministry of Science and Technology (MOST), Taiwan
   [MOST104-2221-E-126-007-]; Providence University research grant
   [PU103-11100-E02]
FX This investigation is supported by Ministry of Science and Technology
   (MOST), Taiwan, under grant no. MOST104-2221-E-126-007- and Providence
   University research grant under grant no. PU103-11100-E02.
CR Bizer C, 2009, J WEB SEMANT, V7, P154, DOI 10.1016/j.websem.2009.07.002
   Di Noia T., 2012, P 8 INT C SEM SYST, P1, DOI [DOI 10.1145/2362499.2362501, 10.1145/2362499.2362501]
   Feng W, 2015, MULTIMED TOOLS APPL, DOI [10.1007/s11042-015-2929-2.27, DOI 10.1007/S11042-015-2929-2.27]
   Hassanzadeh O., 2009, LDOW
   Hsieh M.Y., 2012, 9 IEEE INT C UB INT
   Hsieh M-Y, 2013, LECT NOTES ELECT ENG, V234, P11
   Hsieh MY, 2011, INT J COMPUT SCI ENG, V6, P185, DOI 10.1504/IJCSE.2011.042022
   Hsieh MY, 2011, INFORMATION-TOKYO, V14, P2451
   Hsieh MY, 2014, LECT NOTES ELECTR EN, V274, P93
   Hsieh MY, 2015, LECT NOTES ELECT ENG, V329
   Jiang H, 2015, CLUSTER COMPUT, V18, P369, DOI 10.1007/s10586-014-0400-1
   Jiang H, 2014, CLUSTER COMPUT, V17, P293, DOI 10.1007/s10586-013-0276-5
   Koren Y, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1644873.1644874
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Kuelewska U, 2014, STUDIELOGIC GRAMMA, V37, P125, DOI [10.2478/slgr-2014-0021, DOI 10.2478/SLGR-2014-0021]
   Lens G., 2015, MOIVELENS
   Lin HY, 2015, TELECOMMUN SYST, V60, P303, DOI 10.1007/s11235-015-0031-8
   Mirbakhsh N, 2015, ACM T KNOWL DISCOV D, V9, DOI 10.1145/2724720
   Mirbakhsh Nima., 2013, Proceedings of the 7th ACM conference on Recommender systems, P315
   Natarajan N., 2013, P 7 ACM C REC SYST, P201, DOI [10.1145/2507157.2507186, DOI 10.1145/2507157.2507186]
   Ostuni V., 2013, LECT NOTES COMPUTER, V8127, P400, DOI DOI 10.1007/978-3-642-40511-2_29
   Owen S, 2014, MAHOUT ACTION, P55
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1
   Ristoski P, 2014, COMM COM INF SC, V475, P150, DOI 10.1007/978-3-319-12024-9_19
   Sarwt M, 2012, T KNOWL DATA ENG, V6
   Thangavel SK, 2013, INT J SCI ENG RES, V4, P279
   Zhang Z. Y., 2012, INT J DIGIT CONTENT, V6, P245, DOI DOI 10.4156/JDCTA.V0L6.ISSUE9.31
   Zhang ZY, 2015, MULTIMED TOOLS APPL, V74, P6255, DOI [10.1007/s11042-014-2135-7, 10.1007/s11042-015-2619-0]
NR 28
TC 24
Z9 24
U1 3
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3383
EP 3401
DI 10.1007/s11042-016-3833-0
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200012
DA 2024-07-18
ER

PT J
AU Meenpal, T
AF Meenpal, Toshanlal
TI A light weight and secure video conferencing scheme utilizing public
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secure video conferencing; JPEG; MPEG; RC4 stream cipher
ID SELECTIVE ENCRYPTION; DIGITAL VIDEO; IMAGE; ALGORITHM; CRYPTANALYSIS;
   CHAOS
AB Security of video encryption schemes is an issue yet to be addressed to the satisfaction of all parties concerned. In the one end of the spectrum, there are applications which require highest level of security and they use conventional encryption schemes which are neither bandwidth efficient nor format preserving. Thus limit their application to a large extent. Other end of the spectrum is occupied by selective encryption schemes which are used by most of the commercial applications. These schemes though bandwidth efficient are not secure as these schemes are designed to degrade the video quality but overall content remain intelligible. Thus a scheme which is highly secure yet bandwidth efficient is the need of the hour. In this paper, we propose a new format preserving selective encryption scheme for JPEG and MPEG which is compression friendly as well as highly secure. We choose the quantized DCT coefficients of the I-frame for encryption. The resultant image/video is completely obscure and is suitable for high end security applications. Also there is no reduction in the performance of compression algorithms applied later in the standard JPEG/MPEG pipeline. Experiments show that the encrypted image/video file is almost of the same size as that of un-encrypted version. Thus the scheme is suitable for applications like tele-medicine, on-the-go video conferencing using low bandwidth cellular networks, etc..
C1 [Meenpal, Toshanlal] NIT Raipur, Telecommun Dept NIT Raipur, Dept Elect & Telecommun, GE Rd, Raipur 492010, Madhya Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur
RP Meenpal, T (corresponding author), NIT Raipur, Telecommun Dept NIT Raipur, Dept Elect & Telecommun, GE Rd, Raipur 492010, Madhya Pradesh, India.
EM toshan.barc@gmail.com
RI Oruganti, Madhu/KIJ-9331-2024
OI Oruganti, Madhu/0000-0002-6274-3606
CR AHUMADA AJ, 1992, P SOC PHOTO-OPT INS, V1666, P365
   [Anonymous], FORMAT PRESERVING EN
   [Anonymous], 2002, TOPICS CRYPTOLGY CT, DOI DOI 10.1007/3-540-45760-7
   [Anonymous], 2001, MPEG21 4
   Chang CC, 1989, COMPUTER CRYPTOGRAPH
   Changgui Shi, 1998, Proceedings ACM Multimedia 98, P81
   Chen M, 2014, INT J MULTIMED DATA, V5, P1, DOI 10.4018/ijmdem.2014010101
   Dufaux F, 2008, IEEE T CIRC SYST VID, V18, P1168, DOI 10.1109/TCSVT.2008.928225
   Ghanbari M, 2008, STANDARD CODECS IMAG
   GOLDBURG B, 1993, IEEE J SEL AREA COMM, V11, P735, DOI 10.1109/49.223875
   Grangetto M, 2006, IEEE T MULTIMEDIA, V8, P905, DOI 10.1109/TMM.2006.879919
   Johnson M, 2004, IEEE T SIGNAL PROCES, V52, P2992, DOI 10.1109/TSP.2004.833860
   Kankanhalli MS, 2002, IEEE T CONSUM ELECTR, V48, P356, DOI 10.1109/TCE.2002.1010142
   Kundur D, 2004, P IEEE, V92, P918, DOI 10.1109/JPROC.2004.827356
   Li CQ, 2011, SIGNAL PROCESS, V91, P949, DOI 10.1016/j.sigpro.2010.09.014
   Lian S, DESIGN PARTIAL ENCYP
   Lookabaugh T, 2004, IEEE COMMUN MAG, V42, P124, DOI 10.1109/MCOM.2004.1299355
   Maniccam SS, 2004, PATTERN RECOGN, V37, P725, DOI 10.1016/j.patcog.2003.08.011
   Mao YN, 2006, IEEE T IMAGE PROCESS, V15, P2061, DOI 10.1109/TIP.2006.873426
   Maximov A, 2008, NEW STATE RECOVERY A, P297
   Ning H., 2012, ADV INTERNET THINGS, V2, P1, DOI [10.4236/ait.2012.21001, DOI 10.4236/AIT.2012.21001]
   Niu XA, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P308, DOI 10.1109/IIH-MSP.2008.207
   Ong S, FORMAT COMPLIANT ENC
   Pommer A, 2003, MULTIMEDIA SYST, V9, P279, DOI 10.1007/s00530-003-0099-y
   Qiao L, 1998, INT J COMPUT GRAPH, V22
   Ramdan A. A., 2012, 2012 7th International Conference on Telecommunications, Systems, Services, and Applications (TSSA 2012), P120, DOI 10.1109/TSSA.2012.6366035
   Schneier B., 1997, Applied Cryptography: Protocols, Algorithms, V2a
   Shen HJ, 2014, IET INFORM SECUR, V8, P199, DOI 10.1049/iet-ifs.2012.0349
   Takayama M, 2008, 2008 3RD INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS, CONTROL AND SIGNAL PROCESSING, VOLS 1-3, P1035
   Takayama M, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1349, DOI 10.1109/ICME.2006.262789
   Van Droogenbroeck M., 2002, ACIVS'2002: Advanced Concepts for Intelligent Vision Systems, P90
   Wang C, 2003, IEEE T CONSUM ELECTR, V49, P1208, DOI 10.1109/TCE.2003.1261218
   Wang C, NEW ENCRYPTION THEN
   Wang HG, 2010, IEEE T MULTIMEDIA, V12, P215, DOI 10.1109/TMM.2010.2041102
   Wang W, 2010, IEEE T MULTIMEDIA, V12, P417, DOI 10.1109/TMM.2010.2050653
   Wang YS, 2013, IEEE T CIRC SYST VID, V23, P1476, DOI 10.1109/TCSVT.2013.2248588
   Wen J, 2001, INT C MED FUT FLOR
   Wen JT, 2002, IEEE T CIRC SYST VID, V12, P545, DOI 10.1109/TCSVT.2002.800321
   WU CP, 2001, P SPIE, V4314
   Wu M, 2002, IEEE MULT SIGN PROC
   Ye GD, 2010, PATTERN RECOGN LETT, V31, P347, DOI 10.1016/j.patrec.2009.11.008
   Yuan C, 2003, IEEE INT S CIRC SYST
   Yuefa Hu, 2012, 2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet), P2315, DOI 10.1109/CECNet.2012.6201682
   Zeng W, 1999, P ACM MULT ORL
   Zeng WJ, 2003, IEEE T MULTIMEDIA, V5, P118, DOI 10.1109/TMM.2003.808817
   Zhu HG, 2013, SIGNAL PROCESS-IMAGE, V28, P670, DOI 10.1016/j.image.2013.02.004
NR 46
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3699
EP 3714
DI 10.1007/s11042-016-3973-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200025
DA 2024-07-18
ER

PT J
AU Khare, M
   Srivastava, RK
   Khare, A
AF Khare, Manish
   Srivastava, Rajneesh Kumar
   Khare, Ashish
TI Object tracking using combination of daubechies complex wavelet
   transform and Zernike moment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Daubechies complex wavelet transform; Zernike moment;
   Shift-invariance; Translation and rotation invariance
AB Moving object tracking is one of the challenging problems in computer vision and it has numerous applications in surveillance system, traffic monitoring etc. The goal of object tracking algorithm is to locate a moving object in consecutive video frames. Tracking of moving object in a video becomes difficult due to random motion of objects. This paper introduces a new algorithm for moving object tracking by exploiting the properties of Daubechies complex wavelet transform and Zernike moment. The proposed method uses combination of Daubechies complex wavelet transform and Zernike moment as a feature of object. The motivation behind using combination of these two as a feature of object, because shift invariance and better edge representation property make Daubechies complex wavelet transform suitable for locating object in consecutive frames whereas rotation invariance properties of Zernike moment is also helpful for correct object identification in consecutive frames. Therefore combination of these two as feature of object gives better results. The proposed method matches Zernike moments of Daubechies complex wavelet coefficients of object in the first frame to next consecutive frames. The experimental results and performance evaluation parameters validate that the proposed method gives better performance against other state-of-the-art methods.
C1 [Khare, Manish; Srivastava, Rajneesh Kumar; Khare, Ashish] Univ Allahabad, Dept Elect & Commun, Allahabad 211002, Uttar Pradesh, India.
C3 University of Allahabad
RP Khare, A (corresponding author), Univ Allahabad, Dept Elect & Commun, Allahabad 211002, Uttar Pradesh, India.
EM mkharejk@gmail.com; rkumarsau@gmail.com; ashishkhare@hotmail.com
RI Khare, Ashish/D-4566-2012; Prakash, Om/AAL-4460-2021; Khare,
   Manish/P-5670-2016; Khare, Manish/AAF-4582-2019
OI Prakash, Om/0000-0001-6395-9989; Khare, Manish/0000-0002-2296-2732
FU Council of Scientific and Industrial Research (CSIR), Human Resource
   Development Group, India [09/001/(0377)/2013/EMR-I]
FX This work was supported in part by Council of Scientific and Industrial
   Research (CSIR), Human Resource Development Group, India under Grant no.
   09/001/(0377)/2013/EMR-I.
CR Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Cheng FH, 2006, PATTERN RECOGN, V39, P1126, DOI 10.1016/j.patcog.2005.12.010
   Chong CW, 2003, PATTERN RECOGN, V36, P1765, DOI 10.1016/S0031-3203(02)00353-9
   Clonda D, 2004, SIGNAL PROCESS, V84, P1, DOI 10.1016/j.sigpro.2003.06.001
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Daubechies I., 1992, SIAM
   Duda R.O., 2006, PATTERN CLASSIF
   Elgamel SA, 2011, IET RADAR SONAR NAV, V5, P74, DOI 10.1049/iet-rsn.2010.0046
   Gurwicz Y, 2011, PATTERN RECOGN LETT, V32, P805, DOI 10.1016/j.patrec.2011.01.005
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Hwang SK, 2006, PATTERN RECOGN, V39, P2065, DOI 10.1016/j.patcog.2006.03.004
   Islam M. M., 2007, Proceedings of the SPIE - The International Society for Optical Engineering, V6566, P656616, DOI 10.1117/12.717921
   Khansari M, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/243534
   Khare A, 2007, 2007 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN IMAGE AND SIGNAL PROCESSING, P36, DOI 10.1109/CIISP.2007.369290
   Khare M, 2014, LECT NOTES COMPUT SC, V8960, P87, DOI 10.1007/978-3-662-45947-8_7
   Khare M, 2015, SIGNAL IMAGE VIDEO P, V9, P635, DOI 10.1007/s11760-013-0496-4
   Khare M, 2010, COMM COM INF SC, V101, P281
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Liu BY, 2013, IEEE T PATTERN ANAL, V35, P2968, DOI 10.1109/TPAMI.2012.215
   Liu TL, 2004, IEEE T PATTERN ANAL, V26, P397, DOI 10.1109/TPAMI.2004.1262335
   Ning J, 2012, IET COMPUT VIS, V6, P62, DOI 10.1049/iet-cvi.2009.0075
   Ning JF, 2009, INT J PATTERN RECOGN, V23, P1245, DOI 10.1142/S0218001409007624
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Papakostas GA, 2007, INFORM SCIENCES, V177, P2802, DOI 10.1016/j.ins.2007.01.010
   Porikli F., 2006, 2006 IEEE COMPUTER S, V1, P728, DOI [10.1109/CVPR.2006.94, DOI 10.1109/CVPR.2006.94]
   Prakash O., 2011, J SIGNAL INFORM PROC, V2, P105
   Rocha L, 2002, SIBGRAPI 2002: XV BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P99, DOI 10.1109/SIBGRA.2002.1167130
   SEFERIDIS VE, 1994, IEEE T COMMUN, V42, P1277, DOI 10.1109/TCOMM.1994.580237
   Shen CH, 2010, IEEE T CIRC SYST VID, V20, P119, DOI 10.1109/TCSVT.2009.2031393
   Soman K., 2010, Insight into Wavelets: From Theory to Practice
   Sonka Milan., 2001, IMAGE PROCESSING ANA
   Srivastava P, 2014, MOBILE NETW APPL, V19, P618, DOI 10.1007/s11036-014-0526-7
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Vorobyov M., 2011, TECHNICAL REPORT
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   Wang X, 2013, EMERGING TECHNOLOGIE, P453
   Ye B, 2002, J OPT A-PURE APPL OP, V4, P606, DOI 10.1088/1464-4258/4/6/304
   Yilmaz A, 2004, IEEE T PATTERN ANAL, V26, P1531, DOI 10.1109/TPAMI.2004.96
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang TZ, 2013, INT J COMPUT VISION, V101, P367, DOI 10.1007/s11263-012-0582-z
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zivkovic Z, 2009, COMPUT VIS IMAGE UND, V113, P743, DOI 10.1016/j.cviu.2008.12.008
NR 42
TC 19
Z9 19
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 1247
EP 1290
DI 10.1007/s11042-015-3068-5
PG 44
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000055
DA 2024-07-18
ER

PT J
AU Lin, H
   Wen, FT
   Du, CX
AF Lin, Hao
   Wen, Fengtong
   Du, Chunxia
TI An anonymous and secure authentication and key agreement scheme for
   session initiation protocol
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Authentication; Session Initiation Protocol (SIP); Security attacks;
   User anonymity; The elliptic curve discrete logarithm problem
AB In 2014, Arshad and Nikooghadam proposed an authentication and key agreement scheme for SIP to conquer the existing defects in Irshad et al.'s scheme. They claimed that their scheme resists various security attacks and has low computation cost. We found that even though Arshad et al.'s scheme achieves high efficiency, their scheme is insecure against server spoofing attacks, denial of service attacks and privilege insider attacks. Furthermore, the password change phase of their scheme is complicated and their scheme cannot provide user anonymity. To overcome the weaknesses of Arshad et al.'s scheme, we proposed an anonymous and secure authentication and key agreement protocol for SIP. Compared with Arshad et al.'s scheme, our scheme not only withstands more security attacks, but also achieves user anonymity and high efficiency.
C1 [Lin, Hao; Wen, Fengtong; Du, Chunxia] Univ Jinan, Sch Math Sci, Jinan 250022, Peoples R China.
C3 University of Jinan
RP Wen, FT (corresponding author), Univ Jinan, Sch Math Sci, Jinan 250022, Peoples R China.
EM linhao_ujn@163.com; wftwq@163.com; 15098823621@163.com
FU Natural Science Foundation of Shandong Province [ZR2013FM009]
FX The authors are grateful to the editor and anonymous reviewers for their
   valuable suggestions. This work is supported by Natural Science
   Foundation of Shandong Province (No. ZR2013FM009).
CR [Anonymous], 2617 IETF RFC
   [Anonymous], J MED SYST
   [Anonymous], 2013, INT J COMMUNICATION, DOI DOI 10.1002/dac.2499
   Arshad H, 2016, MULTIMED TOOLS APPL, V75, P181, DOI 10.1007/s11042-014-2282-x
   Arshad R, 2013, MULTIMED TOOLS APPL, V66, P165, DOI 10.1007/s11042-011-0787-0
   Guo DL, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0194-6
   Irshad A, 2015, MULTIMED TOOLS APPL, V74, P3967, DOI 10.1007/s11042-013-1807-z
   Kocher P., 1999, Advances in Cryptology - CRYPTO'99. 19th Annual International Cryptology Conference. Proceedings, P388
   Li X, 2012, J NETW COMPUT APPL, V35, P763, DOI 10.1016/j.jnca.2011.11.009
   Messerges TS, 2002, IEEE T COMPUT, V51, P541, DOI 10.1109/TC.2002.1004593
   Rosenberg J, 2002, 3261 IETF RFC
   Wen FT, 2014, SECUR COMMUN NETW, V7, P987, DOI 10.1002/sec.816
   Wood AD, 2002, COMPUTER, V35, P54, DOI 10.1109/MC.2002.1039518
   Xue KP, 2014, J COMPUT SYST SCI, V80, P195, DOI 10.1016/j.jcss.2013.07.004
   Xuefei Leng, 2009, Information Security Technical Report, V14, P36, DOI 10.1016/j.istr.2009.06.006
   Yeh HL, 2014, COMPUT STAND INTER, V36, P397, DOI 10.1016/j.csi.2013.08.010
   Zhang ZS, 2007, IEEE T CIRC SYST VID, V17, P544, DOI 10.1109/TCSVT.2006.888822
   Zhou L, 2011, IEEE J SEL AREA COMM, V29, P1358, DOI 10.1109/JSAC.2011.110803
NR 18
TC 7
Z9 9
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2315
EP 2329
DI 10.1007/s11042-015-3220-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000032
DA 2024-07-18
ER

PT J
AU Yang, YF
   Wang, YP
   Xue, XS
AF Yang, Yifang
   Wang, Yuping
   Xue, Xingsi
TI Discriminant sparse locality preserving projection for face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dimensionality reduction; Sparse representation; Feature extraction;
   Manifold learning
ID DIMENSIONALITY REDUCTION; REPRESENTATION
AB In this paper, aiming at the drawback of the popular dimensionality reduction method Discriminant Sparse Neighborhood Preserving Embedding(DSNPE), i.e. the construction of its between-class scatter is too complexity, a novel algorithm Discriminant Locality Preserving Projection (DSLPP) is proposed. Our proposal retains the local sparse reconstructive relationships of DSNPE and constructs a novel between-class scatter by using all mean faces as sparse representation dictionary. In particular, DSLPP preserves the sparse reconstructive relationship of mean face, so then it can not only efficiently reduce the between-class scatter computation complexity of DSNPE, but also increase the discriminant power. In the experiment, we compare DSLPP with classic and state-of-the-art dimensionality reduction methods on the publicly available data sets such as ORL, Yale, UMIST, and AR, and further apply the Gabor feature into DSLPP on AR face database to further improve its performance. The experimental results show that DSLPP is able to obtain a better representation of the class information and achieve much higher recognition accuracy.
C1 [Yang, Yifang] Xidian Univ, Sch Math & Stat, Xian 710071, Peoples R China.
   [Yang, Yifang] Xian Shiyou Univ, Coll Sci, Xian 710065, Peoples R China.
   [Wang, Yuping] Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Peoples R China.
   [Xue, Xingsi] Fujian Univ Technol, Sch Informat Sci & Engn, Fuzhou 350118, Peoples R China.
C3 Xidian University; Xi'an Shiyou University; Xidian University; Fujian
   University of Technology
RP Wang, YP (corresponding author), Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Peoples R China.
EM ywang@xidian.edu.cn
FU National Natural Science Foundation of China [61472297, U1404622,
   61503082]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61472297, U1404622 and 61503082.
CR [Anonymous], 2003, NIPS
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Chen HT, 2005, PROC CVPR IEEE, P846
   Cheng B, 2010, IEEE T IMAGE PROCESS, V19, P858, DOI 10.1109/TIP.2009.2038764
   Cox T. F., 2000, Multidimensional scaling
   Du C, 2013, J CENT SOUTH UNIV, V20, P3564, DOI 10.1007/s11771-013-1882-3
   Graham Daniel B, 1998, CHARACTERISING VIRTU, P446
   Gui J, 2012, PATTERN RECOGN, V45, P2884, DOI 10.1016/j.patcog.2012.02.005
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Huang P, 2014, J VIS COMMUN IMAGE R, V25, P296, DOI 10.1016/j.jvcir.2013.11.007
   Jia YQ, 2009, IEEE T NEURAL NETWOR, V20, P729, DOI 10.1109/TNN.2009.2015760
   Joia P, 2011, IEEE T VIS COMPUT GR, V17, P2563, DOI 10.1109/TVCG.2011.220
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Kong J, 2009, 2009 INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND TECHNOLOGY, VOL I, PROCEEDINGS, P419, DOI 10.1109/ICCET.2009.55
   Lai ZH, 2013, NEURAL COMPUT APPL, V23, P2231, DOI 10.1007/s00521-012-1174-0
   Li HF, 2006, IEEE T NEURAL NETWOR, V17, P157, DOI 10.1109/TNN.2005.860852
   Li W, 2014, NEUROCOMPUTING, V138, P283, DOI 10.1016/j.neucom.2014.02.005
   Lu GF, 2012, KNOWL-BASED SYST, V31, P119, DOI 10.1016/j.knosys.2012.02.014
   Martinez A.M., 1998, AR FACE DATABASE CVC
   Paulovich FV, 2008, IEEE T VIS COMPUT GR, V14, P564, DOI 10.1109/TVCG.2007.70443
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Weinberger K. Q., 2006, AAAI, P1683
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yan Shuicheng., 2009, SOC IND APPL MATH P, P792, DOI [10.1137/1.9781611972795.68, DOI 10.1137/1.9781611972795.68]
   Yang J, 2013, IEEE T NEUR NET LEAR, V24, P1023, DOI 10.1109/TNNLS.2013.2249088
   Yang M, 2014, INT J COMPUT VISION, V109, P209, DOI 10.1007/s11263-014-0722-8
   Yang M, 2013, PATTERN RECOGN, V46, P1865, DOI 10.1016/j.patcog.2012.06.022
   Yang M, 2010, LECT NOTES COMPUT SC, V6316, P448, DOI 10.1007/978-3-642-15567-3_33
   Yu WW, 2006, IMAGE VISION COMPUT, V24, P239, DOI 10.1016/j.imavis.2005.11.006
   Zang F, 2011, NEUROCOMPUTING, V74, P2176, DOI 10.1016/j.neucom.2011.02.012
   Zhang ZY, 2012, IEEE T PATTERN ANAL, V34, P253, DOI 10.1109/TPAMI.2011.115
   Zhang ZY, 2004, SIAM J SCI COMPUT, V26, P313, DOI 10.1137/S1064827502419154
   Zhao HT, 2006, PATTERN RECOGN, V39, P1546, DOI 10.1016/j.patcog.2006.02.023
   Zhao MB, 2012, PATTERN RECOGN, V45, P1482, DOI 10.1016/j.patcog.2011.10.008
   Zhong FJ, 2014, IEEE T NEUR NET LEAR, V25, P2065, DOI 10.1109/TNNLS.2014.2303798
   Zhu L, 2007, NEUROCOMPUTING, V70, P1543, DOI 10.1016/j.neucom.2006.12.004
NR 44
TC 5
Z9 5
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2697
EP 2712
DI 10.1007/s11042-015-3212-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000048
DA 2024-07-18
ER

PT J
AU Chen, HC
   Feng, HM
   Lin, TH
   Chen, CY
   Zha, YX
AF Chen, Hua-Ching
   Feng, Hsuan-Ming
   Lin, Te-Hui
   Chen, Ching-Yi
   Zha, Yu-Xiang
TI Adapt DB-PSO patterns clustering algorithms and its applications in
   image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Particle swarm optimization; DB validity; Clustering algorithm; Image
   segmentation
ID PARTICLE SWARM OPTIMIZATION; VALIDITY MEASURE; COMPRESSION
AB Clustering algorithm is a crucial step before to analysis object's feature in image applications. The adapt DB-PSO patterns clustering algorithms (ADPCA) combined the particle swarm optimization (PSO) clustering algorithm and adapt DB_index measuring methodology to efficiently decide the real number of clusters, cluster centers, and then to recognize the correct catalog even if there are exiting some cases in various shapes, multi-dimension, real life training patterns and image datasets. In general, the PSO is adapted for dealing complex and global optimization problems. The population-based evolutional PSO learning algorithm with the self-adapt mathematic index can fit the data vibration to perform the real criterion of homogeneity of neighboring pixels in many image vision and understanding cases. Owing to the purpose of generating automatic clustering algorithms, the specific fitness function contains the DB_validity measure to significantly improve resolutions of spatial information among the given training patterns. The computation of image DB_index is delivered to retrieve the specific objects by evaluating the characters of given patterns. The novel ADPCA actually indicate the homogeneity region of interesting pictures and eliminate small pieces of elements by the supports of DB index measure, which can be used to dynamically compute the maximal similarity and small difference of the discussed image patterns. Several artificial datasets include the three-dimensional dataset with five spherical clusters, two-dimensional patterns with three different sizes circles, one Chtree Fractal image patterns, one real life IRIS data and one grey level image data, which are given as training patterns to demonstrate the adaptation and efficiency of the ADPCA learning method. It presents that ADPCA determine the correct clustering number and suitable cluster position in different data clustering examples. Two image segmentation applications also show that ADPCA can achieve correct detection of subjects. In conclusion, several simulations compared with the traditional k-means algorithm demonstrate the great results of ADPCA learning machine.
C1 [Chen, Hua-Ching; Feng, Hsuan-Ming; Lin, Te-Hui; Zha, Yu-Xiang] Natl Quemoy Univ, Dept Comp Sci & Informat Engn, Kinmen 892, Taiwan.
   [Chen, Ching-Yi] Ming Chuan Univ, Dept Informat & Telecommun Engn, Taoyuan, Taiwan.
C3 Ming Chuan University
RP Feng, HM (corresponding author), Natl Quemoy Univ, Dept Comp Sci & Informat Engn, Kinmen 892, Taiwan.
EM galaxy.km@gmail.com; hmfeng@nqu.edu.tw; lin373000@gmail.com;
   chingyi@mail.mcu.edu.tw; yxzhao@nqu.edu.tw
RI 陳, 華慶/JYQ-3317-2024
OI 陳, 華慶/0009-0007-0930-1431; Feng, Hsuan-Ming/0000-0002-6498-7006
FU National Science Council of the Republic of China
   [NSC-95-2218-E-507-001, NSC 96-2221-E-507-004]
FX This research was partly supported by the National Science Council of
   the Republic of China under contract NSC-95-2218-E-507-001 and NSC
   96-2221-E-507-004.
CR Agrawal S, 2014, APPL SOFT COMPUT, V24, P522, DOI 10.1016/j.asoc.2014.08.011
   Anderberg M.R., 1973, Probability and Mathematical Statistics
   [Anonymous], INT C INF CYB SYST R
   [Anonymous], 1974, Pattern Recognition Principles, DOI DOI 10.1002/ZAMM.19770570626
   Bandyopadhyay S, 2002, PATTERN RECOGN, V35, P1197, DOI 10.1016/S0031-3203(01)00108-X
   Bezdek James C., 1981, PATTERN RECOGN
   Cheng CF, 2004, IEEE INTERNATIONAL ELECTRON DEVICES MEETING 2004, TECHNICAL DIGEST, P789, DOI 10.1109/IEDM.2004.1419292
   Chou CH, 2004, PATTERN ANAL APPL, V7, P205, DOI 10.1007/s10044-004-0218-1
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Dunn J. C., 1974, Journal of Cybernetics, V4, P95, DOI 10.1080/01969727408546059
   Fei Y, 2009, J INF PROCESS SYST, V5, P1, DOI 10.3745/JIPS.2009.5.1.001
   Feng D, 2005, PATTERN RECOGN LETT, V26, P597, DOI 10.1016/j.patrec.2004.11.002
   Feng HM, 2005, CYBERNET SYST, V36, P623, DOI 10.1080/01969720590961754
   Feng HM, 2008, CYBERNET SYST, V39, P520, DOI 10.1080/01969720802069906
   Forouzanfar M, 2010, ENG APPL ARTIF INTEL, V23, P160, DOI 10.1016/j.engappai.2009.10.002
   Gargiulo P., 2012, HUMAN CENTRIC COMPUT, V2, P2
   Huang CC, 2015, OPT LASER ENG, V66, P187, DOI 10.1016/j.optlaseng.2014.09.005
   Liu RC, 2012, INFORM SCIENCES, V204, P1, DOI 10.1016/j.ins.2012.03.021
   Ma M, 2012, J INF PROCESS SYST, V8, P653, DOI 10.3745/JIPS.2012.8.4.653
   Maulik U, 2000, PATTERN RECOGN, V33, P1455, DOI 10.1016/S0031-3203(99)00137-5
   Pan R., 2012, J CONVERGENCE, V3, P13
   Park S, 2013, J INF PROCESS SYST, V9, P205, DOI 10.3745/JIPS.2013.9.2.205
   Peng G., 2013, J CONVERGENCE, V4, P1
   RIBEIRO JL, 1994, COMPUTER, V27, P28, DOI 10.1109/2.294850
   Saba T, 2012, HUM-CENT COMPUT INFO, V2, DOI 10.1186/2192-1962-2-6
   SELIM SZ, 1984, IEEE T PATTERN ANAL, V6, P81, DOI 10.1109/TPAMI.1984.4767478
   Singh B, 2012, HUM-CENT COMPUT INFO, V2, DOI 10.1186/2192-1962-2-13
   XIE XLL, 1991, IEEE T PATTERN ANAL, V13, P841, DOI 10.1109/34.85677
   Yao H, 2013, MATH COMPUT MODEL, V58, P784, DOI 10.1016/j.mcm.2012.12.025
   Yoon M., 2013, J CONVERGENCE, V4, P15
   Zhao F, 2013, NEUROCOMPUTING, V106, P115, DOI 10.1016/j.neucom.2012.10.022
NR 31
TC 5
Z9 6
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15327
EP 15339
DI 10.1007/s11042-015-2518-4
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700013
DA 2024-07-18
ER

PT J
AU Kumari, S
   Wu, F
   Li, X
   Farash, MS
   Jiang, Q
   Khan, MK
   Das, AK
AF Kumari, Saru
   Wu, Fan
   Li, Xiong
   Farash, Mohammad Sabzinejad
   Jiang, Qi
   Khan, Muhammad Khurram
   Das, Ashok Kumar
TI Single round-trip SIP authentication scheme with provable security for
   Voice over Internet Protocol using smart card
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Session initiation protocol; Voice over internet protocol;
   Authentication; Smart card; Provable security
ID KEY AGREEMENT
AB In recent years, Voice over Internet Protocol (VoIP) has gained more and more popularity as an application of the Internet technology. For various IP applications including VoIP, the topic of Session Initiation Protocol (SIP) has attracted major concern from researchers. SIP is an advanced signaling protocol operating on Internet Telephony. SIP uses digest authentication protocols such as Simple Mail Transport Protocol (SMTP) and Hyper Text Transport Protocol (HTTP). When a user seeks SIP services, authentication plays an important role in providing secure access to the server only to the authorized access seekers. Being an insecure-channel-based protocol, a SIP authentication protocol is susceptible to adversarial threats. Therefore, security is a big concern in SIP authentication mechanisms. This paper reveals the security vulnerabilities of two recently proposed SIP authentication schemes for VoIP, Irshad et al.' s scheme [Multimed. Tools. Appl. doi: 10.1007/s11042-0131807- z] and Arshad and Nikooghadam's scheme [Multimed. Tools. Appl. DOI 10.1007/ s11042-014-2282-x], the later scheme is based on the former scheme. Irshad et al.' s scheme suffers from password guessing, user impersonation and server spoofing attacks. Arshad and Nikooghadam's scheme can be threatened with server spoofing and stolen verifier attack. None of these two schemes achieve mutual authentication. It also fails to follow the single round-trip authentication design of Irshad et al.' s scheme. To overcome these weaknesses, we propose a provable secure single round-trip SIP authentication scheme for VoIP using smart card. We formally prove the security of the scheme in random oracle and demonstrate through discussion its resistance to various attacks. The comparative analysis shows that the proposed SIP authentication scheme offers superior performance with a little extra computational cost.
C1 [Kumari, Saru] Ch Charan Singh Univ, Dept Math, Meerut, Uttar Pradesh, India.
   [Wu, Fan] Huaqiao Univ, Dept Comp Sci & Engn, Xiamen Inst Technol, Xiamen 361021, Peoples R China.
   [Li, Xiong] Hunan Univ Sci & Technol, Sch Comp Sci & Engn, Xiangtan 411201, Peoples R China.
   [Li, Xiong] Nanjing Univ Informat Sci & Technol, Nanjing 210044, Jiangsu, Peoples R China.
   [Farash, Mohammad Sabzinejad] Kharazmi Univ, Dept Math & Comp Sci, Tehran, Iran.
   [Jiang, Qi] Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
   [Khan, Muhammad Khurram] King Saud Univ, Ctr Excellence Informat Assurance, Riyadh, Saudi Arabia.
   [Das, Ashok Kumar] IIIT, Ctr Secur Theory & Algorithm Res, Hyderabad 500032, Andhra Pradesh, India.
C3 Chaudhary Charan Singh University; Xiamen Institute of Technology;
   Huaqiao University; Hunan University of Science & Technology; Nanjing
   University of Information Science & Technology; Kharazmi University;
   Xidian University; King Saud University; International Institute of
   Information Technology Hyderabad
RP Kumari, S (corresponding author), Ch Charan Singh Univ, Dept Math, Meerut, Uttar Pradesh, India.
EM saryusiirohi@gmail.com; conjurer1981@gmail.com; lixiong84@gmail.com;
   sabzinejad@khu.ac.ir; jiangqixdu@gmail.com; mkhurram@ksu.edu.sa;
   iitkgp.akdas@gmail.com
RI Das, Ashok Kumar/U-2790-2019; Khan, Muhammad/IXN-8470-2023; Nusa,
   Nuhammad/JXY-5819-2024; Wu, Fan/J-9583-2019; Farash, Mohammad
   sabzinejad/A-2667-2015; KHAN, MUHAMMAD KHURRAM/E-4836-2014; WU,
   FAN/GRX-1654-2022; Kumari, Saru/K-2038-2019; Das, Ashok Kumar
   Umar/K-7202-2017; Li, Xiong/K-7233-2012; Jiang, Qi/K-6325-2014
OI Das, Ashok Kumar/0000-0002-5196-9589; Wu, Fan/0000-0003-3615-1217;
   Farash, Mohammad sabzinejad/0000-0001-5821-4237; KHAN, MUHAMMAD
   KHURRAM/0000-0001-6636-0533; Kumari, Saru/0000-0003-4929-5383; Li,
   Xiong/0000-0001-6619-554X; Jiang, Qi/0000-0002-0894-4992
FU National Natural Science Foundation of China [61300220]; PAPD; CICAEET;
   Deanship of Scientific Research at King Saud University [PRG-1436-16]
FX The authors extend their sincere appreciations to the Deanship of
   Scientific Research at King Saud University for its funding this
   Prolific Research Group (PRG-1436-16). This research is also supported
   by the National Natural Science Foundation of China under Grant No.
   61300220, and it is also supported by PAPD and CICAEET.
CR Abdalla M, 2005, LECT NOTES COMPUT SC, V3570, P341
   [Anonymous], 2004, GUIDE ELLIPTIC CURVE, DOI DOI 10.1007/B97644
   [Anonymous], RFC3261 IETF
   [Anonymous], 2009, INT J NETW SECUR
   [Anonymous], RFC2617 IETF
   Arshad H, 2016, MULTIMED TOOLS APPL, V75, P181, DOI 10.1007/s11042-014-2282-x
   Arshad R, 2013, MULTIMED TOOLS APPL, V66, P165, DOI 10.1007/s11042-011-0787-0
   Branovic I., 2004, Computer Architecture News, V32, P27, DOI 10.1145/1024295.1024299
   Canetti R, 2001, LECT NOTES COMPUT SC, V2045, P453
   Dalgic I, 1999, P PHOT E SPIE BOST
   DENNING DE, 1981, COMMUN ACM, V24, P533, DOI 10.1145/358722.358740
   DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638
   Durlanik A, 2005, PROC WRLD ACAD SCI E, V8, P350
   Farash MS, 2013, INF TECHNOL CONTROL, V42, P333, DOI 10.5755/j01.itc.42.4.2496
   GARCIAMARTIN M, 2003, RFC3455 IETF
   Geneiatakis D, 2006, IEEE COMMUN SURV TUT, V8, P68, DOI 10.1109/COMST.2006.253270
   He DB, 2012, SECUR COMMUN NETW, V5, P1423, DOI 10.1002/sec.506
   Irshad A, 2015, MULTIMED TOOLS APPL, V74, P3967, DOI 10.1007/s11042-013-1807-z
   Jo J, 2008, KSII T INTERNET INF, V2, P171, DOI 10.3837/tiis.2008.04.001
   KOBLITZ N, 1987, MATH COMPUT, V48, P203, DOI 10.1090/S0025-5718-1987-0866109-5
   Kocher P., 1999, Advances in Cryptology - CRYPTO'99. 19th Annual International Cryptology Conference. Proceedings, P388
   Liu F, 2011, LECT NOTES COMPUT SC, V7025, P134, DOI 10.1007/978-3-642-24712-5_11
   Messerges TS, 2002, IEEE T COMPUT, V51, P541, DOI 10.1109/TC.2002.1004593
   MILLER VS, 1986, LECT NOTES COMPUT SC, V218, P417, DOI 10.1007/3-540-39799-x_31
   Pu Q, 2013, SECUR COMMUN NETW, V6, P340, DOI 10.1002/sec.568
   Salsano S, 2002, IEEE NETWORK, V16, P38, DOI 10.1109/MNET.2002.1081764
   Sisalem D, 2006, IEEE NETWORK, V20, P26, DOI 10.1109/MNET.2006.1705880
   Tang HB, 2013, MULTIMED TOOLS APPL, V65, P321, DOI 10.1007/s11042-012-1001-8
   Tsai J.L., 2009, Int J Netw Secur, V9, P12
   Wu LF, 2009, COMPUT STAND INTER, V31, P286, DOI 10.1016/j.csi.2008.01.002
   Xie Q, 2012, INT J COMMUN SYST, V25, P47, DOI 10.1002/dac.1286
   Yang CC, 2005, COMPUT SECUR, V24, P381, DOI 10.1016/j.cose.2004.10.007
   Yeh HL, 2014, COMPUT STAND INTER, V36, P397, DOI 10.1016/j.csi.2013.08.010
   Yen SM, 2000, IEEE T COMPUT, V49, P967, DOI 10.1109/12.869328
   Yoon EJ, 2010, COMPUT COMMUN, V33, P1674, DOI 10.1016/j.comcom.2010.03.026
   Yoon EJ, 2010, IETE TECH REV, V27, P203, DOI 10.4103/0256-4602.62780
   Zhang LP, 2014, INT J COMMUN SYST, V27, P2691, DOI 10.1002/dac.2499
NR 37
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 17215
EP 17245
DI 10.1007/s11042-015-2988-4
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600023
DA 2024-07-18
ER

PT J
AU Li, FL
   Gong, JF
   Liang, YY
   Zhou, JL
AF Li, Fuliang
   Gong, Junfeng
   Liang, Yunyi
   Zhou, Jiali
TI Real-time congestion prediction for urban arterials using adaptive
   data-driven methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data mining; Congestion prediction; Adaptive K-means cluster;
   Two-dimensional speed prediction; Intelligent transportation system
ID TRAFFIC VOLUME; TRAVEL; MODEL
AB Congestion prediction can support traffic departments to take effective traffic management measures, and it aids users to adopt smarter trip strategies, including route and departure time selection. This paper proposes an adaptive data-driven real-time congestion prediction method. The method framework includes a traffic pattern recognition algorithm based on the adaptive K-means clustering, a two-dimensional speed prediction model and an adaptive threshold calibration method. After the principal component analysis, the adaptive K-means cluster algorithm is conducted to obtain different traffic patterns. Congestion recognition is realized with an adaptive threshold calibration method and congestion prediction is then raised according to different traffic patterns. Parameter calibration and model evaluation are carried out on the proposed method using floating car travel speed data. The results show that the adaptive K-means cluster recognition algorithm can better recognize the traffic patterns than Gaussian Mixture model, and the proposed congestion prediction method has better real-time performance, accuracy and robustness than Autoregressive Integrated Moving Average model and Kalman Filtering method.
C1 [Li, Fuliang; Liang, Yunyi] Tongji Univ, Dept Comprehens Transportat Informat & Control En, 4800 Caoan Rd, Shanghai 201804, Peoples R China.
   [Gong, Junfeng] South China Univ Technol, Sch Civil Engn & Transportat, Guangzhou 510640, Guangdong, Peoples R China.
   [Zhou, Jiali] Carnegie Mellon Univ, Dept Civil & Environm Engn, Pittsburgh, PA 15213 USA.
C3 Tongji University; South China University of Technology; Carnegie Mellon
   University
RP Gong, JF (corresponding author), South China Univ Technol, Sch Civil Engn & Transportat, Guangzhou 510640, Guangdong, Peoples R China.
EM ctgongjf@scut.edu.cn
RI Gong, Junfeng/L-1624-2013
FU Foundation for Distinguished Young Talents in Higher Education of
   Guangdong, China; National Natural Science Foundation of China
   [61573149]; Transportation Research Program of Guangdong Province
   [201502062]
FX The work described in this paper was jointly supported by the Foundation
   for Distinguished Young Talents in Higher Education of Guangdong, China
   (Research on traffic state evolution prediction of urban road networks
   with big data), the National Natural Science Foundation of China
   (61573149) and the Transportation Research Program of Guangdong Province
   (201502062) The authors would like to appreciate Dr. Zhaocheng He from
   Sun Yat-sen University for providing the floating car travel speed data.
CR Aftabuzzaman M., 2010, Journal of Public Transportation, V13, P1, DOI [10.5038/2375-0901.13.1.1, DOI 10.5038/2375-0901.13.1.1]
   [Anonymous], 2010, Highway Capacity Manual
   [Anonymous], 2012, TRANSP RES BOARD 91
   Chan KY, 2012, IEEE T INTELL TRANSP, V13, P644, DOI 10.1109/TITS.2011.2174051
   Chang GL, 2011, TRANSPORT RES REC, P55, DOI 10.3141/2243-07
   Du LL, 2012, TRANSPORT RES B-METH, V46, P235, DOI 10.1016/j.trb.2011.09.008
   Fei X, 2011, TRANSPORT RES C-EMER, V19, P1306, DOI 10.1016/j.trc.2010.10.005
   Gu YZ, 2014, IEEE T POWER SYST, V29, P101, DOI 10.1109/TPWRS.2013.2282286
   Guo JH, 2014, TRANSPORT RES C-EMER, V43, P50, DOI 10.1016/j.trc.2014.02.006
   Kwon J, 2000, TRANSPORT RES REC, P120, DOI 10.3141/1717-15
   Li RM, 2011, TRANSPORT RES C-EMER, V19, P1006, DOI 10.1016/j.trc.2011.05.014
   Li X, 2015, INT C INTEL HUM MACH, DOI 10.1109/IHMSC.2015.121
   Li XM, 2016, ADV ENG SOFTW, V93, P1, DOI 10.1016/j.advengsoft.2015.11.003
   Lopez AJ, 2015, 2015 18TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P2078
   Lv YS, 2015, IEEE T INTELL TRANSP, V16, P865, DOI 10.1109/TITS.2014.2345663
   OKUTANI I, 1984, TRANSPORT RES B-METH, V18, P1, DOI 10.1016/0191-2615(84)90002-X
   Park B, 2002, TRANSPORT RES REC, P190, DOI 10.3141/1802-21
   Pattara-Atikom w, 2006, 2006 6TH INTERNATIONAL CONFERENCE ON ITS TELECOMMUNICATIONS PROCEEDINGS, P1001, DOI 10.1109/ITST.2006.288722
   Peng L, 2014, INT CONF COMPUT NETW, P317, DOI 10.1109/ICCNC.2014.6785353
   Qiuyuan Yang, 2015, Algorithms and Architectures for Parallel Processing. 15th International Conference, ICA3PP 2015. Proceedings: LNCS 9529, P18, DOI 10.1007/978-3-319-27122-4_2
   Quek C, 2006, IEEE T INTELL TRANSP, V7, P133, DOI 10.1109/TITS.2006.874712
   Shi W, 2010, IET INTELL TRANSP SY, V4, P113, DOI 10.1049/iet-its.2009.0053
   Stathopoulos A, 2003, TRANSPORT RES C-EMER, V11, P121, DOI 10.1016/S0968-090X(03)00004-4
   Taylor MAP, 2013, TRANSPORTMETRICA B, V1, P174, DOI 10.1080/21680566.2013.859107
   Thianniwet T, 2010, ELECTRO ENG COMPUT T, V8, P261
   van Hinsbergen CPIJ, 2008, TRANSPORT RES REC, P73, DOI 10.3141/2064-10
   van Lint JWC, 2005, TRANSPORT RES C-EMER, V13, P347, DOI 10.1016/j.trc.2005.03.001
   Van Lint J.W.C., 2012, Artificial Intelligence Applications to Critical Transportation Issues, V22, P22
   Vlahogianni EI, 2014, TRANSPORT RES C-EMER, V43, P3, DOI 10.1016/j.trc.2014.01.005
   Williams BM, 2001, TRANSPORT RES REC, P194, DOI 10.3141/1776-25
   Xiang HK, 2014, INT CONF INFO SCI, P33, DOI 10.1109/ICIST.2014.6920325
   Yang Y., 2012, Journal of Information & Computational Science, V9, P2441
   Yildirimoglu M, 2013, TRANSPORT RES B-METH, V53, P45, DOI 10.1016/j.trb.2013.03.006
   Yoon J, 2007, MOBISYS '07: PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P220
   You J, 2000, TRANSPORT RES C-EMER, V8, P231, DOI 10.1016/S0968-090X(00)00012-7
   Younes MB, 2015, AD HOC NETW, V24, P317, DOI 10.1016/j.adhoc.2014.09.005
NR 36
TC 10
Z9 11
U1 0
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 17573
EP 17592
DI 10.1007/s11042-016-3474-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600039
DA 2024-07-18
ER

PT J
AU Park, Y
   Chang, H
   Shon, T
AF Park, Yongmin
   Chang, Hyunsoo
   Shon, Taeshik
TI Data investigation based on XFS file system metadata
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital forensics; Digital investigation; Deleted file recovery; XFS
   file system; Journaling file system; File system metadata
ID DIGITAL FORENSICS; RECOVERY
AB At present, as the amount of digitized information is increasing geometrically, the importance of digitized information as critical clues from the perspective of criminal investigation is also increasing. The importance of digital forensics has also magnified accordingly. As a fundamental technique of digital forensics, recovery of data deleted to conceal information is extremely important and needs to be studied. Although file system types and versions are diversified, sufficient studies have not been performed. The XFS file system was designed to process huge files, and thus it is expected to be applied in server systems. In this paper, we analyze the XFS file system using its structure and metadata information; then, we propose a technique to recover the deleted files through previous analysis results, and verify it through testing.
C1 [Park, Yongmin; Chang, Hyunsoo; Shon, Taeshik] Ajou Univ, Div Comp Engn, Suwon, South Korea.
C3 Ajou University
RP Park, Y (corresponding author), Ajou Univ, Div Comp Engn, Suwon, South Korea.
EM Dev.Yongmin@gmail.com; ics_dant@naver.com; tsshon@ajou.ac.kr
FU Public Welfare and Safety Research Program through the National Research
   Foundation of Korea (NRF) - Ministry of Science, ICT and Future Planning
   [NRF-2012M3A2A1051116]
FX This research was supported by the Public Welfare and Safety Research
   Program through the National Research Foundation of Korea (NRF) funded
   by the Ministry of Science, ICT and Future Planning
   (NRF-2012M3A2A1051116).
CR Fairbanks KD, 2012, DIGIT INVEST, V9, pS118, DOI 10.1016/j.diin.2012.05.010
   Garfinkel SL, 2010, DIGIT INVEST, V7, pS64, DOI 10.1016/j.diin.2010.05.009
   Hellwig C., 2009, USENIX LOGIN MAGAZIN
   Lee S, 2014, J SUPERCOMPUT, V70, P20, DOI 10.1007/s11227-014-1282-y
   Majore S., 2013, Int. J. Smart Home, V7
   Narvaez G., 2007, TAKING ADVANTAGE EXT
   Pal A, 2009, IEEE SIGNAL PROC MAG, V26, P59, DOI 10.1109/MSP.2008.931081
   Silicon Graphics Inc, 2013, XFS OV
   Silicon Graphics Inc, 2006, XFS FIL STRUCT
NR 9
TC 3
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14721
EP 14743
DI 10.1007/s11042-015-2713-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500042
DA 2024-07-18
ER

PT J
AU Parra, L
   Sendra, S
   Jiménez, JM
   Lloret, J
AF Parra, Lorena
   Sendra, Sandra
   Miguel Jimenez, Jose
   Lloret, Jaime
TI Multimedia sensors embedded in smartphones for ambient assisted living
   and e-health
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia content; Smartphone; AAL; e-health; Mobile sensing
ID MOBILE; DISEASE; SYSTEM; CARE; TECHNOLOGIES; ARCHITECTURE; PROTOCOL
AB Nowadays, it is widely extended the use of smartphones to make human life more comfortable. Moreover, there is a special interest on Ambient Assisted Living (AAL) and e-Health applications. The sensor technology is growing and amount of embedded sensors in the smartphones can be very useful for AAL and e-Health. While some sensors like the accelerometer, gyroscope or light sensor are very used in applications such as motion detection or light meter, there are other ones, like the microphone and camera which can be used as multimedia sensors. This paper reviews the published papers focused on showing proposals, designs and deployments of that make use ofmultimedia sensors for AAL and e-health. We have classified them as a function of their main use. They are the sound gathered by the microphone and image recorded by the camera. We also include a comparative table and analyze the gathered information.
C1 [Parra, Lorena; Sendra, Sandra; Miguel Jimenez, Jose; Lloret, Jaime] Univ Politecn Valencia, Inst Invest Gest Integrada Zonas Costeras, Valencia 46730, Spain.
C3 Universitat Politecnica de Valencia
RP Lloret, J (corresponding author), Univ Politecn Valencia, Inst Invest Gest Integrada Zonas Costeras, Valencia 46730, Spain.
EM loparbo@upvnet.upv.es; sansenco@posgrado.upv.es; jojiher@dcom.upv.es;
   jlloret@dcom.upv.es
RI Sendra, Sandra/M-6553-2018; Herranz, Jose Miguel Jimenez/AAA-7165-2021;
   Parra, Lorena/AAB-1927-2021; Lloret, Jaime/H-3994-2013; Compte, Sandra
   Sendra/ABE-1368-2021; Jimenez, Jose Miguel/AAA-3627-2021
OI Sendra, Sandra/0000-0001-9556-9088; Parra, Lorena/0000-0001-9215-8734;
   Lloret, Jaime/0000-0002-0862-0533; Jimenez, Jose
   Miguel/0000-0002-3688-7235
CR Acampora G, 2013, P IEEE, V101, P2470, DOI 10.1109/JPROC.2013.2262913
   Al-Attas R, 2012, IEEE INT CONF MULTI, P441, DOI 10.1109/ICMEW.2012.83
   Alemdar H, 2010, COMPUT NETW, V54, P2688, DOI 10.1016/j.comnet.2010.05.003
   Alqassim S., 2012, 2012 IEEE 14th International Conference on e-Health Networking, Applications and Services (Healthcom 2012), P443, DOI 10.1109/HealthCom.2012.6379457
   Anderson G, 2004, PUBLIC HEALTH REP, V119, P263, DOI 10.1016/j.phr.2004.04.005
   Chaaraoui AA, 2012, EXPERT SYST APPL, V39, P10873, DOI 10.1016/j.eswa.2012.03.005
   [Anonymous], 2014, MULTIMED TOOL APPL
   [Anonymous], 2011, NETW PROTOC ALGORITH, DOI [DOI 10.5296/NPA.V3I1.656, 10.5296/npa.v3i1.656]
   [Anonymous], 2014, RECENT ADV COMMUN NE
   [Anonymous], 2013, PEW RES CTR
   [Anonymous], 2010, NETWORK PROTOCOLS AL
   Aquilano M, 2012, IEEE ENG MED BIO, P5823, DOI 10.1109/EMBC.2012.6347318
   Bellini P, 2012, MULTIMED TOOLS APPL, V58, P41, DOI 10.1007/s11042-010-0684-y
   Boulos MNK, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-24
   Bourouis A, 2014, DECIS SUPPORT SYST, V59, P341, DOI 10.1016/j.dss.2014.01.005
   Bourouis A, 2013, PROCEDIA COMPUT SCI, V19, P1116, DOI 10.1016/j.procs.2013.06.157
   Brault M.W., 2010, Americans with disabilities: 2010
   Cardinaux F, 2011, J AMB INTEL SMART EN, V3, P253, DOI 10.3233/AIS-2011-0110
   Chen NC, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P590
   Chiarini G, 2013, IEEE J SEL AREA COMM, V31, P6, DOI 10.1109/JSAC.2013.SUP.0513001
   Dale O, 2013, 5 INT C EHEALTH TEL, P96
   Estepa A. J., 2014, NETWORK PROTOCOLS AL, V6, P22
   Franco C, 2013, IEEE T BIO-MED ENG, V60, P211, DOI 10.1109/TBME.2012.2222640
   Garcia M, 2013, INTELLIGENT MULTIMED
   Gregoski MJ, 2012, INT J TELEMED APPL, V2012, DOI 10.1155/2012/696324
   Grimaldi D., 2011, Proceedings of the 2011 IEEE 6th International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS 2011), P488, DOI 10.1109/IDAACS.2011.6072801
   Gurrin C, 2013, AM J PREV MED, V44, P308, DOI 10.1016/j.amepre.2012.11.010
   Haché G, 2011, IEEE T INSTRUM MEAS, V60, P3153, DOI 10.1109/TIM.2011.2122490
   Heathers JAJ, 2013, INT J PSYCHOPHYSIOL, V89, P297, DOI 10.1016/j.ijpsycho.2013.05.017
   Hoseini-Tabatabaei SA, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2480741.2480744
   Illiger K, 2014, JMIR MHEALTH UHEALTH, V2, DOI 10.2196/mhealth.3799
   Kanjo E, 2012, NETWORK PROTOCOLS AL, V3, P4
   Kochanov D, 2014, BILDVERARBEITUNG MED, P186
   Kurniawan S, 2008, INT J HUM-COMPUT ST, V66, P889, DOI 10.1016/j.ijhcs.2008.03.002
   Lakens D, 2013, IEEE T AFFECT COMPUT, V4, P238, DOI 10.1109/T-AFFC.2013.3
   Larson EC, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P280, DOI 10.1145/2370216.2370261
   Lee J, 2012, IEEE ENG MED BIO, P1177, DOI 10.1109/EMBC.2012.6346146
   Lloret J, 2009, SENSORS-BASEL, V9, P10513, DOI 10.3390/s91210513
   Lu H, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P351
   Mac'ias Elsa., 2011, Network Protocols and Algorithms, V3, P64
   Macias E, 2013, SENSORS-BASEL, V13, P17292, DOI 10.3390/s131217292
   Macias E, 2012, SENSORS-BASEL, V12, P2062, DOI 10.3390/s120202062
   Monteiro DM, 2014, SECUR COMMUN NETW, V7, P325, DOI 10.1002/sec.732
   Mosa AM, 2012, BMC MED INFORM DECIS, V12, DOI 10.1186/1472-6947-12-67
   O'Grady MJ, 2010, J AMB INTEL HUM COMP, V1, P15, DOI 10.1007/s12652-009-0003-5
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Rahman MA, 2014, MULTIMED TOOLS APPL, V73, P1147, DOI 10.1007/s11042-013-1595-5
   Sendra S, 2014, MOBILE NETW APPL, V19, P287, DOI 10.1007/s11036-013-0445-z
   Smartphone Milestone, 2014, SMARTPH MIL HALF MOB
   Storf H, 2009, LECT NOTES COMPUT SC, V5859, P123, DOI 10.1007/978-3-642-05408-2_16
   Su X, 2014, TSINGHUA SCI TECHNOL, V19, P235, DOI 10.1109/TST.2014.6838194
   Tapu R, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P444, DOI 10.1109/ICCVW.2013.65
   Tobón DP, 2013, IEEE WIREL COMMUN, V20, DOI 10.1109/MWC.2013.6590048
   Tyagi A, 2012, J SKIN CANCER, V2012, DOI 10.1155/2012/437502
   Wadhawan T, 2011, IEEE ENG MED BIO, P3180, DOI 10.1109/IEMBS.2011.6090866
   Xiong HY, 2012, 2012 9TH INTERNATIONAL CONFERENCE ON UBIQUITOUS INTELLIGENCE & COMPUTING AND 9TH INTERNATIONAL CONFERENCE ON AUTONOMIC & TRUSTED COMPUTING (UIC/ATC), P164, DOI 10.1109/UIC-ATC.2012.28
   Xu X, 2014, INT J DISTRIB SENS N
   Yu W, 2012, NETW PROTOC ALGORITH, V4
   Zhang D., 2013, EEE T COMPUT, V64, P452
   Zhang DQ, 2012, ACM SIGCOMM COMP COM, V42, P295, DOI 10.1145/2377677.2377738
NR 60
TC 18
Z9 19
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13271
EP 13297
DI 10.1007/s11042-015-2745-8
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800017
DA 2024-07-18
ER

PT J
AU Qian, Q
   Wang, HX
   Hu, Y
   Zhou, LN
   Li, JF
AF Qian, Qing
   Wang, Hong-Xia
   Hu, Yi
   Zhou, Lin-Na
   Li, Jin-Feng
TI A dual fragile watermarking scheme for speech authentication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fragile watermarking; Hash function; Tamper detection; Precise location;
   Determine attack type
ID AUDIO WATERMARKING; ALGORITHM; ROBUST; BLIND
AB In order to achieve the integrity authentication of speech files, a hash-based dual fragile watermarking algorithm is proposed. In the proposed scheme, a host speech signal is firstly transformed into a matrix, then each row and column of the matrix and a sensitive hash function (MD5) are used to generate two fragile watermarks. In the process of tamper detection, extracted watermarks and reconstructed watermarks are applied to construct two verification vectors, which form a verification grid that helps to detect attacks, locate the forgery domain and determine the type of modifications. Experimental results show that the watermarking scheme has good imperceptibility and fragility. More importantly, the proposed algorithm can not only detect attacks, but also accurately locate the tamped samples, and even identify the type of counterfeits.
C1 [Qian, Qing; Wang, Hong-Xia; Li, Jin-Feng] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Peoples R China.
   [Hu, Yi] Northern Kentucky Univ, Dept Comp Sci, Highland Hts, KY 41099 USA.
   [Zhou, Lin-Na] Univ Int Relat, Beijing 100091, Peoples R China.
C3 Southwest Jiaotong University; Northern Kentucky University; University
   of International Relations
RP Wang, HX (corresponding author), Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Peoples R China.
EM qianqing_swjtu@163.com; hxwang@home.swjtu.edu.cn; huy1@nku.edu;
   zhoulinna@mail.tsinghua.edu.cn; 344795340@qq.com
RI Wang, Hongxia/AAE-2135-2022; li, jinfeng/GVS-5425-2022
OI Qian, Qing/0000-0002-8411-777X
FU National Natural Science Foundation of China (NSFC) [61170226, 61170175]
FX This work is supported in part by the National Natural Science
   Foundation of China (NSFC) under the grant No. 61170226, 61170175.
CR [Anonymous], 1992, RFC1321
   Chen F, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 5, PROCEEDINGS, P135, DOI 10.1109/CISP.2008.298
   Chen OTC, 2007, IEEE T AUDIO SPEECH, V15, P1605, DOI 10.1109/TASL.2007.896658
   Fan MQ, 2014, MULTIMED TOOLS APPL, V70, P2255, DOI 10.1007/s11042-012-1203-0
   Guo HP, 2006, INFORM SCIENCES, V176, P1350, DOI 10.1016/j.ins.2005.06.003
   Khaldi K, 2013, IEEE T AUDIO SPEECH, V21, P675, DOI 10.1109/TASL.2012.2227733
   Korus P, 2014, IEEE T INF FOREN SEC, V9, P169, DOI 10.1109/TIFS.2013.2295154
   Lei BY, 2011, SIGNAL PROCESS, V91, P1973, DOI 10.1016/j.sigpro.2011.03.001
   Lei BY, 2013, IEEE T AUDIO SPEECH, V21, P2368, DOI 10.1109/TASL.2013.2277929
   Li J, 2014, MULTIMED TOOLS APPL, V68, P571, DOI 10.1007/s11042-012-1058-4
   Liu ZH, 2014, MULTIMED TOOLS APPL, V70, P2271, DOI 10.1007/s11042-012-1235-5
   Liu ZH, 2014, DIGIT SIGNAL PROCESS, V24, P197, DOI 10.1016/j.dsp.2013.09.007
   Nematollahi MA, 2013, INT J SPEECH TECHNOL, V16, P471, DOI 10.1007/s10772-013-9192-6
   Qin C, 2012, SIGNAL PROCESS, V92, P1137, DOI 10.1016/j.sigpro.2011.11.013
   Tong XJ, 2013, SIGNAL PROCESS-IMAGE, V28, P301, DOI 10.1016/j.image.2012.12.003
   Tsougenis ED, 2012, J SYST SOFTWARE, V85, P1864, DOI 10.1016/j.jss.2012.02.045
   Wang HX, 2010, SCI CHINA INFORM SCI, V53, P619, DOI 10.1007/s11432-010-0058-0
   Wang XK, 2013, SIGNAL PROCESS, V93, P913, DOI 10.1016/j.sigpro.2012.11.003
   Zhang XP, 2009, LECT NOTES COMPUT SC, V5703, P268, DOI 10.1007/978-3-642-03688-0_24
NR 19
TC 10
Z9 10
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13431
EP 13450
DI 10.1007/s11042-015-2801-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800025
DA 2024-07-18
ER

PT J
AU Yu, J
   Kim, M
   Bang, HC
   Bae, SH
   Kim, SJ
AF Yu, Jaehak
   Kim, Marie
   Bang, Hyo-Chan
   Bae, Sang-Hyun
   Kim, Se-Jin
TI IoT as a applications: cloud-based building management systems for the
   internet of things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; Cloud; Building sensor data; Real-time building
   energy forecasting; Machine learning
ID ENERGY EFFICIENCY; SERVICES; SELECTION; NETWORKS; TIME
AB Recently, excellent by Internet of Things (IoT), the era of connected everything device is coming. However, the devices hardly show the manner to autonomous connectivity on it and the self-cooperation for applied to real-world environments. In this paper, we proposed a smart building on IoT and cloud-based technology that can perform collaboration and efficient operation with various sensing devices in building and facilities. The smart building is very important to reduce on a huge amount of building energy is consumed by the management system of buildings. The proposed system selects an optimum device feature subset from the computing resources and storages by our cloud-based building management system. The performance of our proposed system is tested via experiments which verify that its measures are satisfactory.
C1 [Yu, Jaehak; Kim, Marie; Bang, Hyo-Chan] Elect & Telecommun Res Inst, Daejeon 305700, South Korea.
   [Bae, Sang-Hyun; Kim, Se-Jin] Chosun Univ, Dept Comp Sci & Stat, Gwangju 501759, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI);
   Chosun University
RP Kim, SJ (corresponding author), Chosun Univ, Dept Comp Sci & Stat, Gwangju 501759, South Korea.
EM dbzzang@etri.re.kr; mariekim@etri.re.kr; bangs@etri.re.kr;
   shbae@chosun.ac.kr; sjkim@chosun.ac.kr
OI KIM, SE-JIN/0009-0005-8375-5955
FU Electronics and Telecommunications Research Institute (ETRI) - Korea
   government [Development of USN/WoT Convergence Platform for Internet of
   Reality Service Provision] [15ZC1310]
FX This work was supported by Electronics and Telecommunications Research
   Institute (ETRI) grant funded by the Korea government [15ZC1310,
   Development of USN/WoT Convergence Platform for Internet of Reality
   Service Provision].
CR [Anonymous], 1998, CORRELATION BASED FE
   Atzori L, 2010, COMPUT NETW, V54, P2787, DOI 10.1016/j.comnet.2010.05.010
   Buyya B, 2010, CLOUD COMPUTING PRIN
   Capehart B.L., 2008, GUIDE ENERGY MANAGEM, V6th
   Doukas C., 2012, 2012 Sixth International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing (IMIS 2012), P922, DOI 10.1109/IMIS.2012.26
   Efendigil T, 2009, EXPERT SYST APPL, V36, P6697, DOI 10.1016/j.eswa.2008.08.058
   Erl T, 2013, SERV TECH
   Fleuret F, 2004, J MACH LEARN RES, V5, P1531
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Guinard D, 2010, IEEE T SERV COMPUT, V3, P223, DOI 10.1109/TSC.2010.3
   He W, 2014, IEEE T IND INFORM, V10, P1587, DOI 10.1109/TII.2014.2299233
   International Telecommunication Union (ITU), 2012, Recommendation ITU-T Y.2060, DOI [11.1002/1000/11559, DOI 11.1002/1000/11559]
   Janggwan Im, 2013, 2013 IEEE International Conference on Services Computing (SCC), P462, DOI 10.1109/SCC.2013.68
   Ji Xunsheng, 2011, 2011 International Conference on Measuring Technology and Mechatronics Automation (ICMTMA), P640, DOI 10.1109/ICMTMA.2011.445
   Kavis MJ, 2014, ARCHITECTING CLOUD D
   Miorandi D, 2012, AD HOC NETW, V10, P1497, DOI 10.1016/j.adhoc.2012.02.016
   Moreno-Vozmediano R, 2013, IEEE INTERNET COMPUT, V17, P18, DOI 10.1109/MIC.2012.69
   Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424, DOI 10.1109/TPAMI.2004.105
   Pan JL, 2014, IEEE COMMUN SURV TUT, V16, P1709, DOI 10.1109/SURV.2014.060914.00089
   Perera C, 2014, IEEE ACCESS, V2, P1660, DOI 10.1109/ACCESS.2015.2389854
   Rao BBP, 2012, I CONF SENS TECHNOL, P374, DOI 10.1109/ICSensT.2012.6461705
   Rocha P, 2015, ENERG BUILDINGS, V88, P203, DOI 10.1016/j.enbuild.2014.11.077
   Sharifi M, 2012, ETRI J, V34, P330, DOI [10.4218/etrij.11.0111.0366, 10.4218/etrij.12.0111.0366]
   Song KB, 2005, IEEE T POWER SYST, V20, P96, DOI 10.1109/TPWRS.2004.835632
   Vouk Mladen A., 2008, Journal of Computing and Information Technology - CIT, V16, P235, DOI 10.2498/cit.1001391
   Yu J, 2013, IEEE GLOBE WORK, P896, DOI 10.1109/GLOCOMW.2013.6825103
   Yu J, 2014, MULTIMED TOOLS APPL, V71, P293, DOI 10.1007/s11042-013-1412-1
   Zhao P, 2013, IEEE T IND APPL, V49, P322, DOI 10.1109/TIA.2012.2229682
NR 28
TC 29
Z9 31
U1 1
U2 52
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14583
EP 14596
DI 10.1007/s11042-015-2785-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500035
DA 2024-07-18
ER

PT J
AU Jia, Q
   Fan, X
   Luo, ZX
   Li, HJ
   Kang, HY
   Li, ZZ
AF Jia, Qi
   Fan, Xin
   Luo, Zhongxuan
   Li, Haojie
   Kang Huyan
   Li, Zezhou
TI Cross-view action matching using a novel projective invariant on
   non-coplanar space-time points
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action matching; Projective invariance; Cross-view; Characteristic
   number
AB Existing action matching methods from the geometric respect typically assume the collinearity or coplanarity for view invariance. These assumptions curb the application to uncontrolled action patterns. In this paper, a new projective invariant named characteristic number (CN) is used, which can be used to describe 3D non-coplanar points. For motion trajectories of actions, we propose the temporal CN (TCN) for individual joint point of a human body in temporal series. This view-invariant feature can characterize an action well with limited number of joints(a single one in our experiments). In addition to TCN, we are also able to define the spatial characteristic number (SCN) on several (five in our paper) joint points in the spatial domain for one frame. SCN works complementary to temporal features, when limited snapshots of an action are available. We validate both SCN and TCN on the widely used CMU Motion Capture Database (Mocap) database, KTH Multiview Football Dataset II and IXMAS dataset. The promising recognition results indicate the invariance to varying viewpoints compared with the state-of-the-art. The results on CMU and KTH database corrupted by noise show the robustness to noise.
C1 [Jia, Qi; Fan, Xin; Luo, Zhongxuan; Li, Haojie; Kang Huyan] Dalian Univ Technol, Software Sch, Dev Area, 321 Tuqiang St, Dalian, Peoples R China.
   [Li, Zezhou] Donghua Univ, Dept Informat Sci & Technol, 2999 North Renmin Rd, Shanghai, Peoples R China.
C3 Dalian University of Technology; Donghua University
RP Fan, X (corresponding author), Dalian Univ Technol, Software Sch, Dev Area, 321 Tuqiang St, Dalian, Peoples R China.
EM xin.fan@ieee.org
FU Natural Science Foundation of China [61402077, 61033012, 11171052,
   61272371, 61003177, 61328206]; program for New Century Excellent Talents
   [NCET-11-0048]; Civil Aviation Administration of China [U1233110];
   Fundamental Research Funds for the Central Universities
FX This work is partially supported by the Natural Science Foundation of
   China under grant Nos. 61402077, 61033012, 11171052, 61272371, 61003177
   and 61328206, the program for New Century Excellent Talents
   (NCET-11-0048), Civil Aviation Administration of China (No. U1233110),
   and Fundamental Research Funds for the Central Universities.
CR Ahmad M, 2006, P ICPR
   [Anonymous], 2004, Multiple View Geometry in Computer Vision
   [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   [Anonymous], P ICCV
   Ashraf N, 2013, COMPUTER VISION IMAG
   Cuzzolin F, 2006, P CVPR
   Efros AA, 2003, P CVPR
   Farhadi A, 2008, LECT NOTES COMPUT SC, V5302, P154, DOI 10.1007/978-3-540-88682-2_13
   Gondal I, 2011, P CVPR
   Huang KQ, 2012, IEEE T IMAGE PROCESS, V21, P2187, DOI 10.1109/TIP.2011.2176346
   Iosifidis A, 2012, IEEE T NEUR NET LEAR, V23, P412, DOI 10.1109/TNNLS.2011.2181865
   Junejo I., 2008, CROSS VIEW ACTION RE
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   Li R., 2012, P CVPR
   Luo ZX, 2014, SCI CHINA MATH, V57, P2273, DOI 10.1007/s11425-014-4877-0
   Lv F., 2007, P CVPR
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   PARAMESWARAN V, 2003, P CVPR
   Ping Y., 2008, IV International Conference on Wireless Comunications, Networking and Mobile Computing, Dalian-China, 12-17 October, P1, DOI DOI 10.1109/ISABEL.2008.4712613
   Rao C, 2002, INT J COMPUT VISION, V50, P203, DOI 10.1023/A:1020350100748
   Reddy KK, 2009, IEEE I CONF COMP VIS, P1010, DOI 10.1109/ICCV.2009.5459374
   Schuldt C., 2004, P ICPR
   SHEN YP, 2008, P CVPR
   Srestasathiern P, 2011, COMPUT VIS IMAGE UND, V115, P1525, DOI 10.1016/j.cviu.2011.07.004
   Vahid K, 2013, P BMVC
   Weinland D, 2010, LECT NOTES COMPUT SC, V6313, P635
   Wu X, 2012, P ECCV
   Zhang Y, 2009, P ICIP
   Zhang Z, 2013, P CVPR
   Zhu GY, 2006, LECT NOTES COMPUT SC, V3979, P89
NR 31
TC 1
Z9 1
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 11661
EP 11682
DI 10.1007/s11042-015-2704-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200005
DA 2024-07-18
ER

PT J
AU Ke, X
   Guo, WZ
AF Ke, Xiao
   Guo, Wenzhong
TI Multi-scale salient region and relevant visual keywords based model for
   automatic image annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic image annotation; Saliency map; Multi-scale; Relevant visual
   keywords
ID RECOGNITION
AB Automatic image annotation is a vital and challenging problem in pattern recognition and image understanding areas. The existing models directly extract visual features from segmented image regions. Since segmented image regions may still have multi-objects, the extractive visual features may not effectively describe corresponding regions. In addition, existing models did not consider the visual representations of corresponding keywords, which would lead to appearing plenty of irrelevant annotations in final annotation results, and these annotations did not relate to any part of images considering visual contents. In order to overcome the above problems, an image annotation model based on multi-scale salient region and relevant visual keywords is proposed. In this model, each image is segmented by using multi-scale grid segmentation method and the global contrast based method is used to extract the saliency maps from each image region. Visual features are extracted from each salient region. In addition, each keyword is divided into two categories: abstract words or non-abstract words. Visual seeds of each non-abstract word are established, and then a new method is proposed to extract visual keyword collections by using corresponding seeds. According to the traits of abstract words, an algorithm based on subtraction regions is proposed to extract visual seeds and corresponding visual keyword collections of each abstract word. Adaptive parameter method and a fast solution algorithm are proposed to determine the similarity thresholds of each keyword. Finally, multi-scale visual features and the combinations of the above methods are used to improve the annotation performance. Our model can improve the object descriptions of images and image regions. Experimental results verify the effectiveness of the proposed model.
C1 [Ke, Xiao; Guo, Wenzhong] Fuzhou Univ, Coll Math & Comp Sci, Fuzhou 350116, Peoples R China.
   [Ke, Xiao; Guo, Wenzhong] Fuzhou Univ, Fujian Prov Key Lab Networking Comp & Intelligent, Fuzhou 350116, Peoples R China.
C3 Fuzhou University; Fuzhou University
RP Guo, WZ (corresponding author), Fuzhou Univ, Coll Math & Comp Sci, Fuzhou 350116, Peoples R China.; Guo, WZ (corresponding author), Fuzhou Univ, Fujian Prov Key Lab Networking Comp & Intelligent, Fuzhou 350116, Peoples R China.
EM fzugwz@163.com
FU National Natural Science Foundation of China [61103175]; Natural Science
   Foundation of Fujian Province [2013 J05088]; Key Project of Chinese
   Ministry of Education [212086]; Fujian Province High School Science Fund
   for Distinguished Young Scholars [JA12016]; Program for New Century
   Excellent Talents in Fujian Province University [JA13021]; Fujian
   Natural Science Funds for Distinguished Young Scholar [2014 J06017]
FX This work is partially supported by the National Natural Science
   Foundation of China under Grants No. 61103175, the Natural Science
   Foundation of Fujian Province under Grant No. 2013 J05088, the Key
   Project of Chinese Ministry of Education under Grant No. 212086, the
   Fujian Province High School Science Fund for Distinguished Young
   Scholars under Grand No. JA12016, the Program for New Century Excellent
   Talents in Fujian Province University under Grant No. JA13021, and the
   Fujian Natural Science Funds for Distinguished Young Scholar under Grant
   No. 2014 J06017.
CR [Anonymous], P ADV NEUTR INF PROC
   [Anonymous], 2007, THESIS
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Feng SL, 2004, PROC CVPR IEEE, P1002
   Feng SH, 2010, EXPERT SYST APPL, V37, P661, DOI 10.1016/j.eswa.2009.06.111
   Guan T, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098806
   Guan T, 2014, IEEE MULTIMEDIA, V21, P32, DOI 10.1109/MMUL.2013.31
   Guan T, 2013, IEEE T MULTIMEDIA, V15, P1688, DOI 10.1109/TMM.2013.2265674
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Han YH, 2012, IEEE T IMAGE PROCESS, V21, P3066, DOI 10.1109/TIP.2012.2183880
   Hu JW, 2013, PATTERN RECOGN, V46, P936, DOI 10.1016/j.patcog.2012.09.010
   Jeon J., 2003, Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P119, DOI DOI 10.1145/860435.860459
   Ji RR, 2012, INT J COMPUT VISION, V96, P290, DOI 10.1007/s11263-011-0472-9
   Ji RR, 2014, IEEE T GEOSCI REMOTE, V52, P1811, DOI 10.1109/TGRS.2013.2255297
   Ji RR, 2013, IEEE T MULTIMEDIA, V15, P153, DOI 10.1109/TMM.2012.2225035
   Ji RR, 2012, IEEE T IMAGE PROCESS, V21, P2282, DOI 10.1109/TIP.2011.2176950
   Kang F., 2006, CVPR, V2, P1719
   Li ZC, 2013, PATTERN RECOGN, V46, P2700, DOI 10.1016/j.patcog.2013.03.016
   Lindstaedt S, 2009, MULTIMED TOOLS APPL, V42, P97, DOI 10.1007/s11042-008-0247-7
   Liu J., 2006, P ACM INT WORKSHOP M, P61, DOI DOI 10.1145/1178677.1178689
   Makadia A, 2008, LECT NOTES COMPUT SC, V5304, P316, DOI 10.1007/978-3-540-88690-7_24
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Si ZZ, 2013, IEEE T PATTERN ANAL, V35, P2189, DOI 10.1109/TPAMI.2013.35
   Von Ahn L, 2004, P SIGCHI C HUM FACT, DOI DOI 10.1145/985692.985733
   Wang Y, 2009, PATTERN RECOGN, V42, P259, DOI 10.1016/j.patcog.2008.05.010
   Yang Y, 2012, IEEE T IMAGE PROCESS, V21, P1339, DOI 10.1109/TIP.2011.2169269
   Zhang DS, 2012, PATTERN RECOGN, V45, P346, DOI 10.1016/j.patcog.2011.05.013
   Zhang L, 2014, IEEE T IND ELECT
   Zhang LM, 2014, IEEE T CYBERNETICS, V44, P1408, DOI 10.1109/TCYB.2013.2285219
   Zhang LM, 2014, INFORM SCIENCES, V254, P141, DOI 10.1016/j.ins.2013.08.020
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang LM, 2013, SIGNAL PROCESS, V93, P1597, DOI 10.1016/j.sigpro.2012.05.012
   Zhang ST, 2012, IEEE T SYST MAN CY B, V42, P838, DOI 10.1109/TSMCB.2011.2179533
   Zhu JY, 2012, PROC CVPR IEEE, P3218, DOI 10.1109/CVPR.2012.6248057
NR 38
TC 3
Z9 3
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12477
EP 12498
DI 10.1007/s11042-014-2318-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700011
DA 2024-07-18
ER

PT J
AU Alvarez, A
   Mendes, C
   Raffaelli, M
   Luís, T
   Paulo, S
   Piccinini, N
   Arzelus, H
   Neto, J
   Aliprandi, C
   del Pozo, A
AF Alvarez, Aitor
   Mendes, Carlos
   Raffaelli, Matteo
   Luis, Tiago
   Paulo, Sergio
   Piccinini, Nicola
   Arzelus, Haritz
   Neto, Joao
   Aliprandi, Carlo
   del Pozo, Arantza
TI Automating live and batch subtitling of multimedia contents for several
   European languages
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia communication; Multimedia systems; Automatic speech
   recognition; Automatic subtitling; Subtitling quality; Access services
ID SPEECH RECOGNITION; BROADCAST; TRANSCRIPTION; SYSTEM
AB The subtitling demand of multimedia content has grown quickly over the last years, especially after the adoption of the new European audiovisual legislation, which forces to make multimedia content accessible to all. As a result, TV channels have been moved to produce subtitles for a high percentage of their broadcast content. Consequently, the market has been seeking subtitling alternatives more productive than the traditional manual process. The large effort dedicated by the research community to the development of Large Vocabulary Continuous Speech Recognition (LVCSR) over the last decade has resulted in significant improvements on multimedia transcription, becoming the most powerful technology for automatic intralingual subtitling. This article contains a detailed description of the live and batch automatic subtitling applications developed by the SAVAS consortium for several European languages based on proprietary LVCSR technology specifically tailored to the subtitling needs, together with results of their quality evaluation.
C1 [Alvarez, Aitor; Arzelus, Haritz; del Pozo, Arantza] Vicomtech IK4 Fdn, Dept Human Speech & Language Technol, San Sebastian, Spain.
   [Mendes, Carlos; Luis, Tiago; Paulo, Sergio; Neto, Joao] VoiceInteract Speech Proc Technol SA, Lisbon, Portugal.
   [Raffaelli, Matteo; Piccinini, Nicola; Aliprandi, Carlo] Synthema Language & Semant Technol, Pisa, Italy.
RP Alvarez, A (corresponding author), Vicomtech IK4 Fdn, Dept Human Speech & Language Technol, San Sebastian, Spain.
EM aalvarez@vicomtech.org
RI Raffaelli, Matteo/KFR-7359-2024; Paulo, Sergio/KLC-8953-2024
OI Paulo, Sergio/0000-0003-0840-4985; Arzelus, Haritz/0000-0002-0731-1317;
   Alvarez, Aitor/0000-0002-7938-4486
FU FP7-ICT-SME-DCL project [296371 - SAVAS]
FX This work was funded by the FP7-ICT-2011-SME-DCL project 296371 - SAVAS
   (Sharing Audiovisual contents for Automatic Subtitling).
   http://www.fp7-savas.eu
CR Abad A, 2007, 2011 NIST LANG REC E
   AENOR, 2003, 1530102003 AENOR UNE
   Ajot J, 2009, TECH REP
   Aliprandi C, 2003, RAI VOICE SUBTITLE L
   Alvarez A, 2014, LECT NOTES ARTIF INT, V8854, P229, DOI 10.1007/978-3-319-13623-3_24
   [Anonymous], MULTIMED TOOLS APPL
   Batista F, 2008, SPEECH COMMUN, V50, P847, DOI 10.1016/j.specom.2008.05.008
   Caseiro D, 2006, IEEE T AUDIO SPEECH, V14, P1281, DOI 10.1109/TSA.2005.860838
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Del Pozo A, 2014, LREC 2014
   Diaz-Cintas J., 2007, Media for all: subtitling for the deaf, audio description, and sign language, V30
   Fiscus J, 2006, NIST 2006 SPRING RIC
   Flanagan M, 2009, THESIS
   Galliano Sylvain, 2006, P LREC 2006, P315
   Gauvain JL, 2001, MULTIMED TOOLS APPL, V14, P187, DOI 10.1023/A:1011303401042
   Lambourne A., 2004, International Journal of Speech Technology, V7, P269, DOI 10.1023/B:IJST.0000037071.39044.cc
   Loof J., 2007, P INT C SPOK LANG PR, P2145
   Meignier S, 2010, CMU SPUD WORKSH DALL, V2010
   Meinedo H, 2003, LECT NOTES ARTIF INT, V2721, P9
   Meinedo H, 2010, P FALA, P93
   Meinedo H., 2005, INTERSPEECH, P237
   Meinedo H, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P508
   Neto J, 2008, INT CONF ACOUST SPEE, P1561, DOI 10.1109/ICASSP.2008.4517921
   Vu NT, 2014, INT CONF ACOUST SPEE, DOI 10.1109/ICASSP.2014.6855086
   Obach M, 2007, ASSIST TECHNOL RES S, V20, P286
   Screen Systems, WINCAPS Q LIV LIV NE
   Screen Systems, WINCAPS QU4NTUM SUBT
   Starfish Technologies, SUBT CLOS CAPT SYST
   Woodland PC, 2002, SPEECH COMMUN, V37, P47, DOI 10.1016/S0167-6393(01)00059-0
   Xiaohui Zhang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P215, DOI 10.1109/ICASSP.2014.6853589
   Zibert J, 2005, P INT 2005 LISB PORT, V2005, P629
NR 31
TC 10
Z9 10
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 10823
EP 10853
DI 10.1007/s11042-015-2794-z
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900002
DA 2024-07-18
ER

PT J
AU Banu, NMM
   Sujatha, S
   Pathan, ASK
AF Banu, Masoodhu N. M.
   Sujatha, S.
   Pathan, Al-Sakib Khan
TI Skip block based distributed source coding for hyperspectral image
   compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed source coding; Entropy; Hyperspectral; Rate; Spectral;
   Syndrome; Wavelet
ID LOSSLESS COMPRESSION; INFORMATION; EFFICIENT; INDEX; SPIHT
AB Due to the involvement of massive amount of information in processing and transmission operations, reduction of encoder complexity is a key requirement for lossy compression methods of hyperspectral images. Distributed Source Coding (DSC) is the enabling technology which reverses the encoder-decoder complexity and provides error resilience. In this work, for complexity reduction, the adaptability of block based design to spatially varying characteristics is exploited and combined with DSC. Blocks of size 8x8 with Mean Absolute Error (MeanAE) less than 3.0 and Maximum Absolute Error (MaxAE) less than 4 are identified and skipped from coding, and the remaining portion has been 2D (2-Dimensional) DCT (Discrete Cosine Transform)/SPIHT (Set Partitioning in Hierarchical Trees) coded. Skip block based DSC scheme results in variable source statistics and this is handled with rate adaptive Low Density Parity Check (LDPC) codes. This new block based algorithm, together with rate adaptive codes results in better compression with reduced coding complexity. Our experimental results show that skip block based DSC coded scheme, in addition to being very flexible, retains all the desirable features of compared well-known algorithms. This is also highly competitive to 3D-SPIHT, and better than 2D SPIHT both in terms of compression efficiency and classification.
C1 [Banu, Masoodhu N. M.] Sethu Inst Technol, Dept Elect & Commun Engn, Virudunagar, India.
   [Sujatha, S.] Anna Univ, Reg Engn Coll, Dept Comp Applicat, Tiruchirappalli, India.
   [Pathan, Al-Sakib Khan] Int Islamic Univ Malaysia, Dept Comp Sci, Kuala Lumpur, Malaysia.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli; Anna University; Anna University of
   Technology Tiruchirappalli; International Islamic University Malaysia
RP Banu, NMM (corresponding author), Sethu Inst Technol, Dept Elect & Commun Engn, Virudunagar, India.
EM banumobeen@yahoo.com; sujathaaut@yahoo.co.in; spathan@ieee.org
RI Pathan, Al-Sakib Khan/ABF-3399-2021; N M, Masoodhu Banu/HPG-8613-2023;
   Pathan, Al-Sakib Khan/AAA-5888-2021
OI Pathan, Al-Sakib Khan/0000-0001-6572-3451; N M, Masoodhu
   Banu/0000-0002-7954-059X; Pathan, Al-Sakib Khan/0000-0001-6572-3451; ,
   Sethu Institute of Technology/0000-0002-8835-1336
FU Networking and Distributed Computing Laboratory (NDC Lab.), KICT, IIUM,
   Malaysia
FX This work was partially supported in part by Networking and Distributed
   Computing Laboratory (NDC Lab.), KICT, IIUM, Malaysia.
CR Abrardo A, 2010, IEEE T GEOSCI REMOTE, V48, P1892, DOI 10.1109/TGRS.2009.2033470
   Ahmed T, 2013, SIMUL-T SOC MOD SIM, V89, P562, DOI 10.1177/0037549712460908
   Banu NMM, 2014, J ELECTR COMPUT ENG, V2014, DOI 10.1155/2014/467628
   Cheung NM, 2006, CONF REC ASILOMAR C, P1892
   Christophe E., 2004, P SOC PHOTO-OPT INS, V5668, P204
   Christophe E, 2008, IEEE T IMAGE PROCESS, V17, P2334, DOI 10.1109/TIP.2008.2005824
   Da-ke He, 2008, Proceedings of the SPIE - The International Society for Optical Engineering, V6822, p68221U, DOI 10.1117/12.766699
   Dragotti PL, 2000, IEEE T GEOSCI REMOTE, V38, P416, DOI 10.1109/36.823937
   Du Q, 2007, IEEE GEOSCI REMOTE S, V4, P201, DOI 10.1109/LGRS.2006.888109
   Eckford AW, 2005, RATELESS SLEPIAN WOL, P1757
   Huo CF, 2012, INT J REMOTE SENS, V33, P1586, DOI 10.1080/01431161.2011.587843
   Jiaji Wu, 2009, Proceedings of the SPIE - The International Society for Optical Engineering, V7494, DOI 10.1117/12.833599
   Jiaji Wu, 2009, Proceedings of the SPIE - The International Society for Optical Engineering, V7455, DOI 10.1117/12.825466
   Jiang J, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY PROCEEDINGS, VOLS 1-7, P1316, DOI 10.1109/ISIT.2007.4557405
   Liu LM, 2008, IEEE IMAGE PROC, P1136
   Magli E, APPLYING DIMSTRIBUTE
   Magli E, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/45493
   Martín G, 2010, J APPL REMOTE SENS, V4, DOI 10.1117/1.3474975
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P157, DOI 10.1109/LSP.2005.862604
   Mielikainen J, 2008, IEEE GEOSCI REMOTE S, V5, P474, DOI 10.1109/LGRS.2008.917598
   Nian YJ, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/825673
   Pan XZ, 2012, IEEE GEOSCI REMOTE S, V9, P224, DOI 10.1109/LGRS.2011.2165271
   Penna B, 2006, IEEE GEOSCI REMOTE S, V3, P125, DOI 10.1109/LGRS.2005.859942
   Pizzolante R, 2012, ALGORITHMS, V5, P76, DOI 10.3390/a5010076
   Qian SE, 2000, IEEE T GEOSCI REMOTE, V38, P1183, DOI 10.1109/36.843010
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Tang XL, 2003, PROC SPIE, V5022, P1037, DOI 10.1117/12.476516
   Varodayan D, 2005, RATE ADAPTIVE DISTRI, P1203
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   Xianglin Wei, 2013, International Journal of Communication Networks and Information Security, V5, P1
   Xiong ZX, 1996, IEEE SIGNAL PROC LET, V3, P289, DOI 10.1109/97.542157
   Yu C, 2013, IEEE T COMMUN, V61, P3590, DOI 10.1109/TCOMM.2013.13.120892
NR 32
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 11267
EP 11289
DI 10.1007/s11042-015-2852-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900020
DA 2024-07-18
ER

PT J
AU Baran, R
   Rusc, T
   Fornalski, P
AF Baran, Remigiusz
   Rusc, Tomasz
   Fornalski, Pawel
TI A smart camera for the surveillance of vehicles in intelligent
   transportation systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligent camera; Surveillance of vehicles; Color and make and model
   recognition; License plate recognition; Intelligent transportation
   system
ID PLATE-RECOGNITION ALGORITHM; CHARACTER SEGMENTATION; LICENSE; CONTOUR
AB The paper presents a smart camera aimed at security and law enforcement applications for intelligent transportation systems. An extended background is presented first as a scholar literature review. The smart camera components and their capabilities for automatic detection and recognition of selected parameters of cars, as well as different aspects of the system efficiency, are described and discussed in detail in subsequent sections. Smart features of make and model recognition (MMR), license plate recognition (LPR) and color recognition (CR) are highlighted as the main benefits of the system. Their implementations, flowcharts and recognition rates are described, discussed and finally reported in detail. In addition to MMR, three different approaches, referred to as bag-of-features, scalable vocabulary tree and pyramid match, are also considered. The conclusion includes a discussion of the smart camera system efficiency as a whole, with an insight into potential future improvements.
C1 [Baran, Remigiusz] Kielce Univ Technol, Fac Elect Engn Automat & Comp Sci, Al 1000 Lecia PP 7, PL-25314 Kielce, Poland.
   [Rusc, Tomasz] Jan Kochanowski Univ, Inst Phys, Ul Swietokrzyska 15, PL-25406 Kielce, Poland.
   [Fornalski, Pawel] AGH Univ Sci & Technol, Dept Telecommun, Al Mickiewicza 30, PL-30059 Krakow, Poland.
C3 Kielce University of Technology; Jan Kochanowski University; AGH
   University of Krakow
RP Baran, R (corresponding author), Kielce Univ Technol, Fac Elect Engn Automat & Comp Sci, Al 1000 Lecia PP 7, PL-25314 Kielce, Poland.
EM r.baran@tu.kielce.pl; tomasz.rusc@ujk.edu.pl; pawelf2@o2.pl
RI Baran, Remigiusz/E-5457-2014
OI Baran, Remigiusz/0000-0002-3643-5642
FU European Regional Development Fund under the Innovative Economy
   Operational Programme, INSIGMA project [POIG.01.01.02- 00-062/09]
FX This work was supported by the European Regional Development Fund under
   the Innovative Economy Operational Programme, INSIGMA project no.
   POIG.01.01.02- 00-062/09. We want also to address our special thanks to
   our colleague Mariusz Rychlik from The University of Computer
   Engineering and Telecommunications in Kielce (Poland) for his valuable
   contributions to this work.
CR Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148
   Anagnostopoulos CNE, 2006, IEEE T INTELL TRANSP, V7, P377, DOI 10.1109/TITS.2006.880641
   [Anonymous], 8 IEEE INT C ADV VID
   [Anonymous], 2005, THESIS
   [Anonymous], 2006, MATCH SETS FEAT EFF
   Anthony D, 2005, MORE LOCAL STRUCTURE
   Arulmozhi K, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMPUTING RESEARCH (ICCIC), P718
   Arulmozhi K, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMPUTING RESEARCH (ICCIC), P708
   Ashtari AH, 2014, IEEE T INTELL TRANSP, V15, P1690, DOI 10.1109/TITS.2014.2304515
   Baran R, 2000, MMET 2000: INTERNATIONAL CONFERENCE ON MATHEMATICAL METHODS IN ELECTROMAGNETIC THEORY, VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P218, DOI 10.1109/MMET.2000.888560
   Baran R, 2015, MULTIMED TOOLS APPL, V74, P4269, DOI 10.1007/s11042-013-1545-2
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bulan O, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.041109
   Bulan O, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.041116
   Caliendo C, 2012, J TRANSP ENG-ASCE, V138, P1453, DOI 10.1061/(ASCE)TE.1943-5436.0000473
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Chang SL, 2004, IEEE T INTELL TRANSP, V5, P42, DOI 10.1109/TITS.2004.825086
   Chen LH, 2013, INT J PATTERN RECOGN, V27, DOI 10.1142/S0218001413550136
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Du S, 2013, IEEE T CIRC SYST VID, V23, P322, DOI 10.1109/TCSVT.2012.2203741
   Dule E, 2010, FUZZY SYSTEMS EVOLUT
   Dziech W, 2000, MMET 2000: INTERNATIONAL CONFERENCE ON MATHEMATICAL METHODS IN ELECTROMAGNETIC THEORY, VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P224, DOI 10.1109/MMET.2000.888563
   Fathy M, 1995, PATTERN RECOGN LETT, V16, P1321, DOI 10.1016/0167-8655(95)00081-X
   Ghazal M, 2013, INT C COMM SIG PROC
   Gorzalczany MB, 2008, LECT NOTES ARTIF INT, V5097, P40, DOI 10.1007/978-3-540-69731-2_5
   Gorzalczany MB, 2006, LECT NOTES COMPUT SC, V4029, P593
   Grauman K, 2007, J MACH LEARN RES, V8, P725
   Gu HZ, 2013, MULTIMED TOOLS APPL, V65, P387, DOI 10.1007/s11042-012-0996-1
   Helinski M. KM, 2012, PCSS POZN
   Hsieh JW, 2014, IEEE T INTELL TRANSP, V15, P6, DOI 10.1109/TITS.2013.2294646
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Hu W, 2013, PROC SPIE, V9067, DOI 10.1117/12.2051976
   Huang YP, 2009, EXPERT SYST APPL, V36, P9260, DOI 10.1016/j.eswa.2008.12.006
   Janowski L, 2014, MULTIMED TOOLS APPL, V68, P23, DOI 10.1007/s11042-012-1199-5
   Jiao JB, 2009, PATTERN RECOGN, V42, P358, DOI 10.1016/j.patcog.2008.08.016
   Jin LS, 2012, SENSORS-BASEL, V12, P8355, DOI 10.3390/s120608355
   Ju Z, 2012, LICENSE PLATE IMAGE, P1
   Kazemi FM, 2007, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, PROCEEDINGS, P939
   박선미, 2008, [KIPS Transactions on Software and Data Engineering, 정보처리학회논문지. 소프트웨어 및 데이터 공학], V15, P285
   Kim KJ, 2008, 2008 IEEE ASIA-PACIFIC SERVICES COMPUTING CONFERENCE, VOLS 1-3, PROCEEDINGS, P134, DOI 10.1109/APSCC.2008.207
   Loce RP, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.041121
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Negri P, 2006, INT C PATT RECOG, P574
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Öztürk F, 2012, PROC TECH, V1, P124, DOI 10.1016/j.protcy.2012.02.024
   Pan JS, 2008, COMM COM INF SC, V15, P440
   Petrovic VS, 2004, INT C PATT RECOG, P95, DOI 10.1109/ICPR.2004.1334477
   Psyllos A, 2011, COMPUT STAND INTER, V33, P142, DOI 10.1016/j.csi.2010.06.005
   Rahati S, 2008, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS, P894, DOI 10.1109/ITNG.2008.136
   Ren C, 2013, PROC SPIE, V8878, DOI 10.1117/12.2030579
   Sanap PR, 2010, AIP CONF PROC, V1324, P255, DOI 10.1063/1.3526208
   홍원주, 2013, [Journal of the Institute of Electronics and Information Engineers, 전자공학회논문지], V50, P187
   Shapiro V, 2006, MACH VISION APPL, V17, P173, DOI 10.1007/s00138-006-0023-5
   Shi YLS, 2006, CCTV FOCUS
   Stahlschmidt C, 2013, COMM COM INF SC, V368, P213
   Szeto WY, 2014, J INTELL TRANSPORT S, V18, P323, DOI 10.1080/15472450.2013.834770
   Vishwanath N, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMPUTING RESEARCH (ICCIC), P743
   Wang AL, 2012, PROCEEDINGS OF THE 2012 SECOND INTERNATIONAL CONFERENCE ON INSTRUMENTATION & MEASUREMENT, COMPUTER, COMMUNICATION AND CONTROL (IMCCC 2012), P995, DOI 10.1109/IMCCC.2012.237
   Wang YR, 2009, LECT NOTES COMPUT SC, V5574, P408, DOI 10.1007/978-3-642-03095-6_39
   Wen Y, 2011, IEEE T INTELL TRANSP, V12, P830, DOI 10.1109/TITS.2011.2114346
   Witten I. H., 2005, DATA MINING PRACTICA
   Wu YT, 2010, LECT NOTES COMPUT SC, V6297, P369, DOI 10.1007/978-3-642-15702-8_34
   Yang J, 2013, 2013 IE INT C SERV O
   Yoon Y, 2013, ETRI J, V35, P491, DOI 10.4218/etrij.13.0112.0545
   Yoon Y, 2012, IEEE INT WORKSH MULT, P349, DOI 10.1109/MMSP.2012.6343467
   Zafar I, 2007, PROCEEDINGS OF THE SEVENTH IASTED INTERNATIONAL CONFERENCE ON VISUALIZATION, IMAGING, AND IMAGE PROCESSING, P271
   Zhai B-F, 2011, 2011 2 INT C ED SPOR
   Zhai XJ, 2013, IET CIRC DEVICE SYST, V7, P337, DOI 10.1049/iet-cds.2012.0339
   Zhang LL, 2013, 2013 NINTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION (ICNC), P702, DOI 10.1109/ICNC.2013.6818066
   Zhang Y, 2013, APPL MECH MATER, V333-335, P974, DOI 10.4028/www.scientific.net/AMM.333-335.974
   Ziólko M, 2005, ISIE 2005: PROCEEDINGS OF THE IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS 2005, VOLS 1- 4, P1167, DOI 10.1109/ISIE.2005.1529089
NR 74
TC 28
Z9 29
U1 0
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10471
EP 10493
DI 10.1007/s11042-015-3151-y
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800018
OA hybrid
DA 2024-07-18
ER

PT J
AU Lisowski, K
   Czyzewski, A
AF Lisowski, Karol
   Czyzewski, Andrzej
TI Complexity analysis of the Pawlak's flowgraph extension for
   re-identification in multi-camera surveillance system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Flowgraph; Route reconstruction; Complexity; Video surveillance
AB The idea of Pawlak's flowgraph turned out to be a useful and convenient container for a knowledge of objects' behaviour and movements within the area observed with a multi-camera surveillance system. Utilization of the flowgraph for modelling behaviour admittedly requires certain extensions and enhancements, but it allows for combining many rules into a one data structure and for obtaining parameters describing how objects tend to move through the supervised area. The main aim of this article is presentation of the complexity analysis of proposed modification of flowgraphs. This analysis contains considerations of issues such as memory efficiency and computational complexity of operations on the flowgraph. The measures related to space and time efficiency were also included.
C1 [Lisowski, Karol; Czyzewski, Andrzej] Gdansk Univ Technol, Multimedia Syst Dept, Narutowicza 11-12, PL-80952 Gdansk, Poland.
C3 Fahrenheit Universities; Gdansk University of Technology
RP Lisowski, K (corresponding author), Gdansk Univ Technol, Multimedia Syst Dept, Narutowicza 11-12, PL-80952 Gdansk, Poland.
EM lisowski@sound.eti.pg.gda.pl; andcz@sound.eti.pg.gda.pl
RI Czyzewski, Andrzej/JXN-0946-2024
OI Czyzewski, Andrzej/0000-0001-9159-8658
FU Artemis JU; Polish National Centre for Research and Development (NCBR)
   as part of the COPCAMS project [332913]
FX This work has been partially funded by the Artemis JU and by the Polish
   National Centre for Research and Development (NCBR) as part of the
   COPCAMS project (http://copcams.eu) under GA number 332913.
CR [Anonymous], 2009 3 ACM IEEE INT
   [Anonymous], P 3 INT C ROUGH SETS
   [Anonymous], INTRO COMPUTATIONAL
   [Anonymous], 2010, P 4 ACM IEEE INT C D
   Cormen T. H., 2009, Introduction to Algorithms, VSecond
   Czyzewski A, 2014, J INTELL INF SYST, V43, P521, DOI 10.1007/s10844-013-0253-8
   Czyzewski A, 2013, FUND INFORM, V127, P561, DOI 10.3233/FI-2013-927
   Ellwart D, 2013, ADV INTELL SYST COMP, V183, P45
   Hongeng S, 2000, INT C PATT RECOG, P164, DOI 10.1109/ICPR.2000.905296
   Javed O, 2005, PROC CVPR IEEE, P26
   Leung V, 2008, 2008 10TH INTERNATIONAL CONFERENCE ON CONTROL AUTOMATION ROBOTICS & VISION: ICARV 2008, VOLS 1-4, P705, DOI 10.1109/ICARCV.2008.4795604
   Pawlak Z, 2003, INTELLIGENT SYSTEMS FOR INFORMATION PROCESSING: FROM REPRESENTATION TO APPLICATIONS, P243, DOI 10.1016/B978-044451379-3/50020-0
   Pawlak Z, 2003, LECT NOTES ARTIF INT, V2639, P1
   Siek J., 2002, The Boost Graph Library: User Guide and Reference Manual
   Wang Y, 2011, 2011 IEEE INT C MULT, P1, DOI [10.1109/ICME.2011.6012163, DOI 10.1109/ICME.2011.6012163]
NR 15
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10495
EP 10511
DI 10.1007/s11042-015-2652-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800019
DA 2024-07-18
ER

PT J
AU Zeng, HQ
   Yang, AS
   Ngan, KN
   Wang, MH
AF Zeng, Huanqiang
   Yang, Aisheng
   Ngan, King Ngi
   Wang, Miaohui
TI Perceptual sensitivity-based rate control method for high efficiency
   video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Perceptual video coding; HEVC; Human visual system; Rate control;
   Perceptual sensitivity
ID QUALITY ASSESSMENT; FRAME RATE; SCHEME; H.264; ERROR
AB The newest video coding standard-high efficiency video coding (HEVC) optimizes its coding efficiency in terms of sum of square error (SSE), which does not fully consider the perceptual characteristic of the input video. Thus, the HEVC is not effective in the sense of perceptual video coding. To address this problem, an efficient perceptual sensitivity-based rate control (PSRC) method for HEVC is proposed based on the human visual system (HVS) observation that the region with less perceptual sensitivity can tolerate more distortion. In the first stage, the proposed method develops a perceptual sensitivity measurement to evaluate the perceptual sensitivity of each coding tree unit (CTU) and each frame, which is then used to guide the bit allocation so that more bits will be allocated to those regions with higher perceptual sensitivity. To meet the target bits, an improved R-lambda model is utilized to determine the quantization parameter (QP). Experimental results have shown that the proposed method is able to improve the perceptual coding performance, compared with the original rate control in HEVC.
C1 [Zeng, Huanqiang; Yang, Aisheng] Huaqiao Univ, Sch Informat Sci & Engn, Xiamen 361021, Peoples R China.
   [Ngan, King Ngi; Wang, Miaohui] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
C3 Huaqiao University; Chinese University of Hong Kong
RP Zeng, HQ (corresponding author), Huaqiao Univ, Sch Informat Sci & Engn, Xiamen 361021, Peoples R China.
EM zeng0043@e.ntu.edu.sg
RI Zeng, Huanqiang/U-2017-2018; Ngan, N/E-8240-2014
OI Ngan, N/0000-0003-1946-3235
FU Research Grants Council of the Hong Kong SAR, China [CUHK 415712];
   National Natural Science Foundation of China [61372107, 61401167];
   Xiamen Key Science and Technology Project Foundation [3502Z20133024];
   State Key Laboratory of Digital Publishing Technology [FZDP2015-B-001];
   High-Level Talent Project Foundation of Huaqiao University [14BS201,
   14BS204]
FX This work was supported in part by a grant from the Research Grants
   Council of the Hong Kong SAR, China (Project CUHK 415712), in part by
   the National Natural Science Foundation of China under the Grants
   61372107 and 61401167, in part by the Xiamen Key Science and Technology
   Project Foundation under the Grant 3502Z20133024, in part by the Opening
   Project of State Key Laboratory of Digital Publishing Technology under
   the grant FZDP2015-B-001, and in part by the High-Level Talent Project
   Foundation of Huaqiao University under the Grants 14BS201 and 14BS204.
CR An C, 2008, IEEE T IMAGE PROCESS, V17, P1605, DOI 10.1109/TIP.2008.2001046
   [Anonymous], 2010, SG16WP3 ITUT
   [Anonymous], VCEG 13 M
   Bhat A, 2012, IEEE T CIRC SYST VID, V22, P165, DOI 10.1109/TCSVT.2011.2158465
   Bossen F., 2012, JCTVCJ1100, P1
   Chen ZZ, 2007, SIGNAL PROCESS-IMAGE, V22, P19, DOI 10.1016/j.image.2006.11.002
   Chiang TH, 1997, IEEE T CIRC SYST VID, V7, P246, DOI 10.1109/76.554439
   Choi H.-J., 2012, SEMICONDUCTOR NANOST, P1, DOI DOI 10.1109/OCEANS-YEOSU.2012.6263424
   Dong JP, 2009, IEEE T CIRC SYST VID, V19, P1108, DOI 10.1109/TCSVT.2009.2020338
   Girod Bernd, 1993, P207
   Kwon DK, 2007, IEEE T CIRC SYST VID, V17, P517, DOI 10.1109/TCSVT.2007.894053
   Lee B, 2014, IEEE T CIRC SYST VID, V24, P465, DOI 10.1109/TCSVT.2013.2276880
   Li B, 2014, IEEE T IMAGE PROCESS, V23, P3841, DOI 10.1109/TIP.2014.2336550
   Li S, 2014, IEEE I C CONS ELECT, P1, DOI 10.1109/ICCE-Berlin.2014.7034294
   Li Y., 2014, MULTIMEDIA EXPO WORK, P1, DOI DOI 10.1109/ICMEW.2014.6890644
   Liu Y., 2007, IEEE T CIRC SYST VID, V17, P1152
   Oh H, 2013, IEEE T IMAGE PROCESS, V22, P1524, DOI 10.1109/TIP.2012.2233485
   Ou TS, 2011, IEEE T CIRC SYST VID, V21, P682, DOI 10.1109/TCSVT.2011.2129890
   Ou YF, 2011, IEEE T CIRC SYST VID, V21, P286, DOI 10.1109/TCSVT.2010.2087833
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tan HL, 2010, IEEE T IMAGE PROCESS, V19, P335
   Tsai WJ, 2010, IEEE T CIRC SYST VID, V20, P1882, DOI 10.1109/TCSVT.2010.2087473
   Ugur K, 2010, IEEE T CIRC SYST VID, V20, P1688, DOI 10.1109/TCSVT.2010.2092613
   Wang SS, 2013, IEEE J-STSP, V7, P1101, DOI 10.1109/JSTSP.2013.2272240
   Wang SQ, 2012, IEEE T CIRC SYST VID, V22, P516, DOI 10.1109/TCSVT.2011.2168269
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZX, 2014, C IND ELECT APPL, P1169, DOI 10.1109/ICIEA.2014.6931342
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
NR 29
TC 23
Z9 23
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10383
EP 10396
DI 10.1007/s11042-015-2997-3
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800014
DA 2024-07-18
ER

PT J
AU Ko, HC
AF Ko, Hsin Chi
TI An approach to the design of digital classic Chinese article learning
   system for undergraduate students using "the homecoming" as an example
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Undergraduate Chinese course digitalization; The Homecoming; Chinese
   course digital learning
AB The age of digitalization has come. As a result, learning has developed from the traditional way in a classroom to digital learning through multimedia. The main advantage of digital learning is a convenient learning channel for learners. Therefore, in all fields, there have been trends of digitalization of teaching content. However, the teaching materials of undergraduate Chinese courses have not been digitalized yet. And most undergraduate students find learning classical Chinese content very difficult and boring. Consequently, digitalizing the teaching material content for undergraduate Chinese courses can definitely increase undergraduate students' interest in learning Chinese and the corresponding benefits. For this reason, this study aims to explore the design method to digitalize the content of "Homecoming" using a qualitative research method. The research results include the design concept of the "Homecoming" digital teaching materials and systematic learning process. It is hoped that this study can present the design concept of digitalization of an undergraduate Chinese course for the first time as a reference.
C1 [Ko, Hsin Chi] Chang Jung Christian Univ, Dept Mass Commun, 1 Changda Rd, Tainan 71101, Taiwan.
   [Ko, Hsin Chi] Chang Jung Christian Univ, Language Educ Ctr, 1 Changda Rd, Tainan 71101, Taiwan.
C3 Chang Jung Christian University; Chang Jung Christian University
RP Ko, HC (corresponding author), Chang Jung Christian Univ, Dept Mass Commun, 1 Changda Rd, Tainan 71101, Taiwan.; Ko, HC (corresponding author), Chang Jung Christian Univ, Language Educ Ctr, 1 Changda Rd, Tainan 71101, Taiwan.
EM hsin899@gmail.com
CR [Anonymous], 2000, B I CHINESE LIT PHIL, V16, P1
   Chang Y, 2012, J XINGTAI U, V27, P82
   Chiang T, 2006, WORLD CHINESE LANG L, V254, P10
   Chou Y, 2009, J CHINESE LANG TEACH, V6, P91
   Chu C, 2007, J LANG LIT STUD, V9, P74
   Fu Y, 2014, SOOCHOW J CHINESE LI, V28, P13
   Gan B, 2011, SILK ROAD, V10, P71
   Huang P, 2012, CHINESE J CHINESE CU, V24, P19
   Jing X, 2007, SCI ED COURSE REFORM, V2006, P47
   Lee M, 2008, J NATL TAIWAN COLL A, V83, P319
   Li H, 2009, DONGJIANG J, V26, P10
   LIAO S, 2013, J INF COMMUN, V4, P45
   Liao Y, 2013, J LIBERAL ARTS SOC S, V9, P209
   Wang W. K., 2001, ED RES METHOD
   Yan C, 2010, J NINGBO U, V23, P39
   Zha G, 2008, J HUANGGANG NORMAL U, V28, P144
NR 16
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 16
BP 9991
EP 10012
DI 10.1007/s11042-015-3126-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LO
UT WOS:000382112500026
DA 2024-07-18
ER

PT J
AU Ueng, SK
   Chen, GZ
AF Ueng, Shyh-Kuang
   Chen, Guan-Zhi
TI Vision based multi-user human computer interaction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human computer interaction; Hand tracking; Finger detection; Multi-user;
   Healthcare systems
AB This paper proposes a vision-based Multi-user Human Computer Interaction (HCI) method for creating augmented reality user interfaces. In the HCI session, one of the users' hands is selected as the active hand. The fingers of the active hand are employed as input devices to trigger functionalities of the application program. To share the token of interaction among the users, the HCI session is modeled as a Finite State Machine (FSM). The FSM is composed of the initial and steady states. In the initial state, the FSM identifies the active hand by tracking the hand with the maximum moving speed. Then the FSM enters the steady state to carry out the HCI session. At the end of each individual HCI cycle, the FSM polls requests from other hands for acquiring the role of active hand. If such requests are sensed, the FSM returns to the initial state to track a new active hand. Otherwise, the HCI session is continuously carried out by the current active hand. Test results show that the resultant user interface is efficient, flexible and practical for users with problems on using ordinary input devices. In a desk-top computer equipped with a 640 x 480 resolution web-camera, the HCI session can be successfully conducted when the operation distance ranges from 30 to 90 cm.
C1 [Ueng, Shyh-Kuang; Chen, Guan-Zhi] Natl Taiwan Ocean Univ, Dept Comp Sci & Engn, Keelung 202, Taiwan.
C3 National Taiwan Ocean University
RP Ueng, SK (corresponding author), Natl Taiwan Ocean Univ, Dept Comp Sci & Engn, Keelung 202, Taiwan.
EM skueng@mail.ntou.edu.tw
CR [Anonymous], INT C TRENDS IND MEA
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Gutzeit E, 2011, INT SYMP IMAGE SIG, P241
   Hang Z, 2009, 2009 WRI WORLD CONGRESS ON SOFTWARE ENGINEERING, VOL 1, PROCEEDINGS, P190, DOI 10.1109/WCSE.2009.359
   Hasan M.M., 2012, CANADIAN J IMAGE PRO, V3, P12
   Kay Elemetric Corporation, 2003, MULT VOIC PROGR MDVP, V5105
   Lee B, 2009, P 2 INT C INTERACTIO, P1110, DOI [10.1145/1655925.1656127, DOI 10.1145/1655925.1656127]
   Lee D, 2011, ETRI J, V33, P415, DOI 10.4218/etrij.11.0110.0313
   Letessier Julien., 2004, P 17 ANN ACM S USER, P119, DOI DOI 10.1145/1029632.1029652
   Manresa C., 2005, ELECT LETT COMPUTER, V3, P96, DOI DOI 10.5565/REV/ELCVIA.109
   Rekimoto J., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P113, DOI 10.1145/503376.503397
   Ueng S. K., 2012, 2012 Sixth International Conference on Complex, Intelligent, and Software Intensive Systems (CISIS), P618, DOI 10.1109/CISIS.2012.62
   Wilson A.D., 2010, ACM International Conference on Interactive Tabletops and Surfaces, P69, DOI DOI 10.1145/1936652.1936665
   Yan-Wen Wu, 2008, 2008 Workshop on Knowledge Discovery and Data Mining (WKDD '08), P339, DOI 10.1109/WKDD.2008.148
   Zhou H, 2010, INT CONF SIGN PROCES, P1194, DOI 10.1109/ICOSP.2010.5656105
NR 16
TC 5
Z9 5
U1 0
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 16
BP 10059
EP 10076
DI 10.1007/s11042-015-3061-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LO
UT WOS:000382112500029
DA 2024-07-18
ER

PT J
AU Hamid, Z
   Hussain, FB
   Pyun, JY
AF Hamid, Zara
   Hussain, Faisal Bashir
   Pyun, Jae-Young
TI Delay and link utilization aware routing protocol for wireless
   multimedia sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless multimedia sensor networks; Cross-layer design; QoS Routing
AB Wireless Multimedia Sensor Networks (WMSNs) consist of networks of interconnected devices involved in retrieving multimedia content, such as, video, audio, acoustic, and scalar data, from the environment. The goal of these networks is optimized delivery of multimedia content based on quality of service (QoS) parameters, such as delay, jitter and distortion. In multimedia communications each packet has strict playout deadlines, thus late arriving packets and lost packets are treated equally. It is a challenging task to guarantee soft delay deadlines along with energy minimization, in resource constrained, high data rate WMSNs. Conventional layered approach does not provide optimal solution for guaranteeing soft delay deadlines due to the large amount of overhead involved at each layer. Cross layer approach is fast gaining popularity, due to its ability to exploit the interdependence between different layers, to guarantee QoS constraints like latency, distortion, reliability, throughput and error rate. The paper presents a channel utilization and delay aware routing (CUDAR) protocol for WMSNs. This protocol is based on a cross-layer approach, which provides soft end-to-end delay guarantees along with efficient utilization of resources. Extensive simulation analysis of CUDAR shows that it provides better delay guarantees than existing protocols and consequently reduces jitter and distortion in WMSN communication.
C1 [Hamid, Zara] COMSATS Inst Informat Technol, Dept Comp Sci, Pk Rd, Islamabad, Pakistan.
   [Hussain, Faisal Bashir] Bahria Univ, Dept Comp Sci, Islamabad, Pakistan.
   [Pyun, Jae-Young] Chosun Univ, Dept Informat & Commun Engn, 375 Susuk Dong, Gwangju 501759, South Korea.
C3 COMSATS University Islamabad (CUI); Chosun University
RP Hamid, Z (corresponding author), COMSATS Inst Informat Technol, Dept Comp Sci, Pk Rd, Islamabad, Pakistan.
EM zarahamid@comsats.edu.pk; faisalwn@yahoo.com; jypyun@chosun.ac.kr
RI Hussain, Faisal Bashir/HIK-3794-2022
OI Hamid, Zara/0000-0001-8182-7453
CR Akkaya K, 2003, 23RD INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOPS, P710
   Akyildiz IF, 2008, P IEEE, V96, P1588, DOI 10.1109/JPROC.2008.928756
   Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   [Anonymous], 2005, P INT WORKSH WEAR IM
   [Anonymous], 2009, ICCTP 2009 CRITICAL, DOI [10.1061/41064(358)151, DOI 10.1061/41064(358)151]
   [Anonymous], 2007, TYM SOURCE CODE REPO
   [Anonymous], 2003, P 23 INT C DISTR COM
   [Anonymous], 2003, P SOC PHOT INSTR ENG
   [Anonymous], P INT C INF TECHN MU
   Boluk PS, 2011, INT WIREL COMMUN, P394, DOI 10.1109/IWCMC.2011.5982566
   Bose R, 2009, IEEE PERVAS COMPUT, V8, P84, DOI 10.1109/MPRV.2009.55
   Cobo L, 2010, COMPUT NETW, V54, P2991, DOI 10.1016/j.comnet.2010.05.014
   Felemban E, 2006, IEEE T MOBILE COMPUT, V5, P738, DOI 10.1109/TMC.2006.79
   Fuqiang Liu, 2006, 2006 3rd Annual IEEE Communications Society Conference on Sensor and Ad Hoc Communications and Networks (IEEE Cat. No. 06EX1523), P916
   Gunasekaran R, 2008, IEEE WCNC, P2135
   Gürses E, 2005, ANN TELECOMMUN, V60, P872
   Hamid Z., 2012, 2012 Fourth International Conference on Ubiquitous and Future Networks (ICUFN 2012), P498, DOI 10.1109/ICUFN.2012.6261760
   Hamid Z., 2013, EURASIP J WIREL COMM, V2013, P1
   Holman R, 2003, IEEE PERVAS COMPUT, V2, P14, DOI 10.1109/MPRV.2003.1251165
   Information Science Institute, NS 2 NETW SIM SOFTW
   Intanagonwiwat C, 2003, IEEE ACM T NETWORK, V11, P2, DOI 10.1109/TNET.2002.808417
   Karlsson J., 2010, THESIS
   Karp B., 2000, MobiCom 2000. Proceedings of the Sixth Annual International Conference on Mobile Computing and Networking, P243, DOI 10.1145/345910.345953
   Kulkarni P, 2005, P ACM MULT SING
   Lari A. R., 2010, Proceedings of the 2010 International Conference on Broadband, Wireless Computing, Communication and Applications (BWCCA 2010), P351, DOI 10.1109/BWCCA.2010.95
   Li S, 2010, INT J MULTIMEDIA ITS
   Liu X-Y, IEEE T PARALLEL DIST, P1
   Liu Xiang, 2011, 2011 8th Annual IEEE Communications Society Conference on Sensor, Mesh and Ad Hoc Communications and Networks (SECON 2011), P46, DOI 10.1109/SAHCN.2011.5984932
   Maimour M, 2008, WMUNEP'08 : PROCEEDINGS OF THE FOURTH ACM INTERNATIONAL WORKSHOP ON WIRELESS MULTIMEDIA NETWORKING AND PERFORMANCE MODELING, P26
   Margi CB, 2006, P IEEE CREAT NET INT
   Misra S, 2008, IEEE COMMUN SURV TUT, V10, P18, DOI 10.1109/SURV.2008.080404
   Mohajerzadeh Amir Hossein, 2010, 2010 Third International Workshop on Advanced Computational Intelligence (IWACI 2010), P670, DOI 10.1109/IWACI.2010.5585166
   NATH S, 2004, IRPTR0416
   Semertzidis T, 2010, IET INTELL TRANSP SY, V4, P103, DOI 10.1049/iet-its.2008.0092
   Shu L, 2010, TELECOMMUN SYST, V44, P79, DOI 10.1007/s11235-009-9227-0
   Srivastava V, 2005, IEEE COMMUN MAG, V43, P112, DOI 10.1109/MCOM.2005.1561928
   Xin Y, 2009, P INT C WIR COMM SIG
   Yao L., 2008, P 7 WORLD C INT CONT, P3304, DOI DOI 10.1109/WCICA.2008.4594494
   Yao L, 2008, 2008 7TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-23, P3321, DOI 10.1109/WCICA.2008.4594494
   Yao YJ, 2013, IEEE INT CONF MOB, P182, DOI 10.1109/MASS.2013.44
   Zeng YY, 2013, WIREL NETW, V19, P161, DOI 10.1007/s11276-012-0457-9
NR 41
TC 13
Z9 14
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 14
BP 8195
EP 8216
DI 10.1007/s11042-015-2737-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LW
UT WOS:000382113300004
DA 2024-07-18
ER

PT J
AU Wang, HY
   Li, ZS
AF Wang, Haiying
   Li, Zhengshan
TI Accelerometer-based gesture recognition using dynamic time warping and
   sparse representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gesture recognition; Accelerometer; Sparse representation; Matching
   pursuit
AB In this paper, we propose a new accelerometer-based gesture recognition system. In this system, the start and end of the data collection process is automatically determined by acceleration waveform. In pretreatment phase, we propose a waveform compensation algorithm to solve the problems caused by the amplitude range of the accelerometer and use the coordinate transformation theory to alleviate the angle offset. In training phase, we use dynamic time warping (DTW) and affinity propagation (AP) to extract clusters and exemplars. We implement sparse representation for gesture recognition and propose a modified variable sparsity adaptive matching pursuit (MVSAMP) algorithm for signal reconstruction. This algorithm is more adapted to the characteristics of gesture recognition. In the classification stage, a method of weighted residuals is applied to improve the resolution of the best classification. To test the system's performance, a dictionary of 10 gestures is defined and a database consists of 3800 samples is created from 14 participants. Test results have shown that the proposed system achieves a good performance in a variety of experiments on Android platform.
C1 [Wang, Haiying; Li, Zhengshan] Beijing Univ Posts & Telecommun, Beijing Key Lab Network Syst & Network Culture, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Li, ZS (corresponding author), Beijing Univ Posts & Telecommun, Beijing Key Lab Network Syst & Network Culture, Beijing 100876, Peoples R China.
EM lzs1989@bupt.edu.cn
CR Akl A, 2011, IEEE T SIGNAL PROCES, V59, P6197, DOI 10.1109/TSP.2011.2165707
   Akl A, 2010, INT CONF ACOUST SPEE, P2270, DOI 10.1109/ICASSP.2010.5495895
   [Anonymous], DIG IM COMP TECHN AP
   [Anonymous], P EUR C COMPUT VIS
   [Anonymous], 2014, ARXIV150100102
   [Anonymous], COMP INT IM SIGN PRO
   [Anonymous], INTUITIVE E TEACHING
   [Anonymous], IND EL APPL ICIEA 20
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Do TT, 2008, CONF REC ASILOMAR C, P581, DOI 10.1109/ACSSC.2008.5074472
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Hartmann B, 2010, IEEE INTL CONF CONTR, P1011, DOI 10.1109/CCA.2010.5611298
   Holzinger A, 2010, COMPUT INFORM, V29, P601
   Keogh E., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases, P406
   Kettebekov S., 2000, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V9, P205, DOI 10.1142/S021821300000015X
   Mäntylä VM, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P281, DOI 10.1109/ICME.2000.869596
   Moni MA, 2009, 2009 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND INFORMATION TECHNOLOGY, VOL 4, P433, DOI 10.1109/ICCSIT.2009.5234536
   Montoliu R., 2010, P 9 INT C MOB UB MUL, P12
   Neverova N, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P484, DOI 10.1109/ICCVW.2013.69
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   Pylvänäinen T, 2005, LECT NOTES COMPUT SC, V3522, P639
   Ren Z., 2011, P 19 ACM INT C MULT, P759
   Shen XH, 2012, IMAGE VISION COMPUT, V30, P227, DOI 10.1016/j.imavis.2011.11.003
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yao A, 2014, PROC CVPR IEEE, P1923, DOI 10.1109/CVPR.2014.247
   Zhang Y, 2008, J OPER RES SOC CHINA, P1
NR 28
TC 8
Z9 8
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 14
BP 8637
EP 8655
DI 10.1007/s11042-015-2775-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LW
UT WOS:000382113300023
DA 2024-07-18
ER

PT J
AU Javed, SG
   Majid, A
   Mirza, AM
   Khan, A
AF Javed, Syed Gibran
   Majid, Abdul
   Mirza, Anwar M.
   Khan, Asifullah
TI Multi-denoising based impulse noise removal from images using robust
   statistical features and genetic programming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Genetic programming; Noise detection; Mixed impulse
   noise; Salt& pepper noise; Impulse burst noise; Statistical features;
   Robust outlyingness ratio
ID MEDIAN FILTER; DETECTOR; BURSTS
AB Recently, several interesting computational intelligence based image denoising techniques have been reported for the removal of either salt & pepper or uniform impulse noise. However, to the best of our knowledge, the difficult challenge of developing a multi denoising method that can remove mixed-impulse noise, uniform impulse, salt & pepper, and impulse-burst noise, has not been reported so far. In this regard, we propose a new noise removal approach called INDE-GP for the removal of multi types of impulse noises. The proposed approach consists of two stages: noise detection stage and removal stage. At first, the impulse noise is localized by a single stage GP detector that exploits various information-rich, rank-ordered and robust statistical features for detection. Next the noise is removed only from the detected noisy pixels by single stage GP estimator. This estimator is developed by exploiting the global learning capability of GP and local statistical measures of noise-free pixels present in the neighborhood of noisy pixels. The experimental results and comparative analysis with existing denoising techniques show that multi denoising performance of the proposed INDE-GP approach is better both quantitative and qualitative ways.
C1 [Javed, Syed Gibran; Majid, Abdul; Khan, Asifullah] Pakistan Inst Engn & Appl Sci, Dept Comp & Informat Sci, PO Nilore, Islamabad, Pakistan.
   [Mirza, Anwar M.] King Saud Univ, Coll Comp & Informat Sci, POB 51178, Riyadh 11543, Saudi Arabia.
C3 Pakistan Institute of Engineering & Applied Science; King Saud
   University
RP Javed, SG (corresponding author), Pakistan Inst Engn & Appl Sci, Dept Comp & Informat Sci, PO Nilore, Islamabad, Pakistan.
EM sgibranjaved@gmail.com
RI Mirza, Anwar M/KHW-9731-2024; Khan, ASIFULLAH/H-9617-2015; mirza, Arshad
   m/F-3016-2015
OI Mirza, Anwar M/0000-0001-7600-6247; Khan, Asifullah/0000-0003-2039-5305
FU Higher Education Commission, Government of Pakistan [117-3250-EG7-012]
FX This work was supported by Higher Education Commission, Government of
   Pakistan under Indigenous PhD Fellowship Program-Batch VII, PIN No.
   117-3250-EG7-012. The authors are also thankful to Dr. Dominic Searson
   for providing valuable information and help regarding GPTIPS.
CR [Anonymous], 2010, P INT MULTICONFERENC
   BROWNRIGG DRK, 1984, COMMUN ACM, V27, P807, DOI 10.1145/358198.358222
   Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196
   Delon J, 2013, SIAM J IMAGING SCI, V6, P1140, DOI 10.1137/120885000
   Dong YQ, 2007, IEEE T IMAGE PROCESS, V16, P1112, DOI 10.1109/TIP.2006.891348
   Garnett R, 2005, IEEE T IMAGE PROCESS, V14, P1747, DOI 10.1109/TIP.2005.857261
   Gonzalez R. C., 2006, PEARSON ED INDIA, V3rd
   Haijuan Hu, 2012, Proceedings of the International Conference on Computer Vision Theory and Applications. VISAPP 2012, P145
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Kaliraj G, 2010, IMAGE VISION COMPUT, V28, P458, DOI 10.1016/j.imavis.2009.07.007
   Khan NU, 2014, MULTIMED TOOLS APPL, V73, P573, DOI 10.1007/s11042-013-1620-8
   KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870
   Koivisto P, 2003, EURASIP J APPL SIG P, V2003, P223, DOI 10.1155/S1110865703211045
   Kong H, 1998, IEEE T CIRCUITS-II, V45, P422, DOI 10.1109/82.664255
   Koza J.R., 1992, GENETIC PROGRAMMING, VVolume 1
   Li B, 2011, SCI CHINA INFORM SCI, V54, P51, DOI 10.1007/s11432-010-4128-0
   Lin TC, 2010, INFORM SCIENCES, V180, P4892, DOI 10.1016/j.ins.2010.08.011
   Luo WB, 2006, IEEE SIGNAL PROC LET, V13, P413, DOI 10.1109/LSP.2006.873144
   Mahmood MT, 2011, INFORM SCIENCES, V181, P1249, DOI 10.1016/j.ins.2010.11.039
   Majid A, 2012, KNOWL INF SYST, V32, P505, DOI 10.1007/s10115-011-0456-7
   Petrovic NI, 2008, IEEE T IMAGE PROCESS, V17, P1109, DOI 10.1109/TIP.2008.924388
   Schowengerdt R.A., 2006, Remote Sensing
   Singaravelan S., 2013, 2013 International Conference on Advanced Computing and Communication Systems (ICACCS), P1, DOI 10.1109/ICACCS.2013.6938716
   SUN T, 1994, PATTERN RECOGN LETT, V15, P341, DOI 10.1016/0167-8655(94)90082-5
   The Math Works Inc, 2011, MATLAB 7 12
   Toprak A, 2007, DIGIT SIGNAL PROCESS, V17, P711, DOI 10.1016/j.dsp.2006.11.008
   Treiber M, 2010, ADV PATTERN RECOGNIT, P1, DOI 10.1007/978-1-84996-235-3
   Tsymbal OV, 2003, INT WORKSH INT DATA, P324
   Türkmen I, 2014, TURK J ELECTR ENG CO, V22, P637, DOI 10.3906/elk-1208-77
   Turkmen I, 2013, AEU-INT J ELECTRON C, V67, P771, DOI 10.1016/j.aeue.2013.03.006
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weber A., 1997, The usc-sipi image database
   Xiong B, 2012, IEEE T IMAGE PROCESS, V21, P1663, DOI 10.1109/TIP.2011.2172804
   Yan M, 2013, SIAM J IMAGING SCI, V6, P1227, DOI 10.1137/12087178X
   Zang Q, 2003, LECT NOTES COMPUT SC, V2756, P165
   Zhang SQ, 2002, IEEE SIGNAL PROC LET, V9, P360, DOI 10.1109/LSP.2002.805310
   Zhang Y-J, 2006, ADV IMAGE VIDEO SEGM, DOI [10.4018/978-1-59140-753-9, DOI 10.4018/978-1-59140-753-9]
NR 37
TC 11
Z9 11
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 5887
EP 5916
DI 10.1007/s11042-015-2554-0
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600025
DA 2024-07-18
ER

PT J
AU Kang, DS
   Choi, JW
   Martens, WL
AF Kang, Dong-Soo
   Choi, Jung-Woo
   Martens, William L.
TI Distance perception of a virtual sound source synthesized near the
   listener position
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sound field reproduction; Distance perception; Nearby virtual sound
   source; Focused source
ID AUDITORY LOCALIZATION; NEARBY SOURCES; FIELD; REPRODUCTION; ARRAY
AB This paper reports on the challenges faced in attempts to synthesize virtual sound sources near the listener position due to the differences between sound fields of real and virtual sound sources, especially if virtual sources reproduced by a line array of loudspeakers are to be positioned within the arm's reach of the listener. Distance perception has been described by various acoustical parameters, such as loudness, power spectrum, and direct-to-reverberant energy ratio; however, ILD has been considered as a strong distance cue when the source to be positioned near the listener and at an azimuth angle well offset from the median plane. The ILD observed in a sound field reproduced by a loudspeaker array is inevitably different from that of a real sound source due to several reproduction artifacts. Using a rigid sphere as a model of human's head within 1 m, we demonstrate how the ILD is influenced by the reproduction artifacts of a line array. Observing the ILD resulting for various virtual source locations shows that the acoustical cues to perceive distance are not well-reproduced in general; however, there are regions of virtual source locations near the listener within which correct ILDs can be provided. Some local minima in magnitude in space induce large ILD values at particular spatial positions through truncation of the array which results in virtual sources being positioned at extremely close range to the listener.
C1 [Kang, Dong-Soo] Korea Adv Inst Sci & Technol, Dept Mech Engn, Ctr Noise & Vibrat Control, 291 Daehak Ro, Daejeon 305701, South Korea.
   [Choi, Jung-Woo] Korea Adv Inst Sci & Technol, Dept Elect Engn, 291 Daehak Ro, Daejeon 305701, South Korea.
   [Martens, William L.] Univ Sydney, Fac Architecture Design & Planning, Sydney, NSW 2006, Australia.
C3 Korea Advanced Institute of Science & Technology (KAIST); Korea Advanced
   Institute of Science & Technology (KAIST); University of Sydney
RP Choi, JW (corresponding author), Korea Adv Inst Sci & Technol, Dept Elect Engn, 291 Daehak Ro, Daejeon 305701, South Korea.
EM dooly0819@kaist.ac.kr; jwoo@kaist.ac.kr; william.martens@sydney.edu.au
RI Choi, Jung-Woo/AER-1196-2022; Choi, Jung-Woo/C-7334-2015
OI Choi, Jung-Woo/0000-0002-7264-6017; Martens, William/0000-0003-3962-8965
FU Ministry of Trade, Industry and Energy (MOTIE) - Korea government
   [10037244]; BK21 (Brain Korea 21) project; Ministry of Education;
   Unmanned Technology Research Center (UTRC) at Korea Advanced Institute
   of Science and Technology (KAIST); DAPA; ADD
FX This work was supported by the Ministry of Trade, Industry and Energy
   (MOTIE) grant funded by the Korea government (No. 10037244), and the
   BK21 (Brain Korea 21) project initiated by the Ministry of Education,
   and Unmanned Technology Research Center (UTRC) at Korea Advanced
   Institute of Science and Technology (KAIST), originally funded by DAPA,
   ADD.
CR Ahrens J., 2008, P 124 AUD ENG SOC CO
   BERKHOUT AJ, 1988, J AUDIO ENG SOC, V36, P977
   Blauert J., 1997, SPATIAL HEARING PSYC
   Boone M. M., 1996, P 100 AUD ENG SOC CO
   Bronkhorst AW, 1999, NATURE, V397, P517, DOI 10.1038/17374
   Brungart DS, 1999, J ACOUST SOC AM, V106, P1465, DOI 10.1121/1.427180
   Brungart DS, 1999, J ACOUST SOC AM, V106, P1956, DOI 10.1121/1.427943
   Brungart DS, 1999, J ACOUST SOC AM, V106, P3589, DOI 10.1121/1.428212
   Brungart DS, 1996, J ACOUST SOC AM, V100, P2953
   Choi JW, 2013, IEEE T AUDIO SPEECH, V21, P247, DOI 10.1109/TASL.2012.2217131
   Choi JW, 2012, IEEE T AUDIO SPEECH, V20, P1976, DOI 10.1109/TASL.2012.2191959
   COLEMAN PD, 1963, PSYCHOL BULL, V60, P302, DOI 10.1037/h0045716
   Daniel J, 2003, P 23 AUD ENG SOC C C
   Duda RO, 1998, J ACOUST SOC AM, V104, P3048, DOI 10.1121/1.423886
   Fazi F M., 2010, Sound Field Reproduction
   Fink M, 1997, PHYS TODAY, V50, P34, DOI 10.1063/1.881692
   Geier M, 2010, P 128 AUD ENG SOC CO
   Hartley RVL, 1921, PHYS REV, V18, P431, DOI 10.1103/PhysRev.18.431
   Kang DS, 2014, P INTERNOISE2014 MEL
   Kim YH, 2013, SOUND VISUALIZATION AND MANIPULATION, P1, DOI 10.1002/9781118368480
   Kopco N, 2007, P INT C AC MADR SPAI
   Kopco N, 2011, J ACOUST SOC AM, V130, P1530, DOI 10.1121/1.3613705
   Menzies D, 2009, P AMB S GRAZ AUSTR
   MERSHON DH, 1975, PERCEPT PSYCHOPHYS, V18, P409, DOI 10.3758/BF03204113
   MOLLER H, 1995, J AUDIO ENG SOC, V43, P300
   Nielsen S, 1991, THESIS AALBORG U
   Oldfield R, 2014, P 137 AUD ENG SOC CO
   SHAW EAG, 1974, J ACOUST SOC AM, V56, P1848, DOI 10.1121/1.1903522
   Shinn-Cunningham BG, 2005, J ACOUST SOC AM, V117, P3100, DOI 10.1121/1.1872572
   SIMPSON WE, 1973, AM J PSYCHOL, V86, P151, DOI 10.2307/1421856
   Song MH, 2012, J ACOUST SOC AM, V131, pEL156, DOI 10.1121/1.3679006
   Spors S, 2010, P 4 INT S COMM CONTR
   Spors S., 2007, P 123 AUD ENG SOC CO
   Spors S., 2009, P 127 AUD ENG SOC CO
   Start E, 1997, THESIS DELFT U TECHN, P45
   Stewart G, 1911, PHYS REV, V34, P252
   Stewart GW, 1911, PHYS REV, V33, P467, DOI 10.1103/PhysRevSeriesI.33.467
   Verheijen E., 1997, Sound field reproduction by wave field synthesis
   Weyl H, 1919, ANN PHYS-BERLIN, V60, P481
   Wierstorf H, 2010, P 129 AUD ENG SOC CO
   Wierstorf H, 2013, J AUDIO ENG SOC, V61, P5
   Williams EG, 1999, FOURIER ACOUSTICS SP, P187
   Wittek H, 2004, P 116 AUD ENG SOC CO
   Zahorik P, 2002, J ACOUST SOC AM, V111, P1832, DOI 10.1121/1.1458027
NR 44
TC 4
Z9 5
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 9
BP 5161
EP 5182
DI 10.1007/s11042-015-2878-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DM8HE
UT WOS:000376601700020
DA 2024-07-18
ER

PT J
AU Lee, SW
   Seo, YH
   Yang, HS
AF Lee, Sang-Wook
   Seo, Yong-Ho
   Yang, Hyun S.
TI Efficient foreground extraction using RGB-D imaging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Foreground extraction algorithm; Structure tensor; Depth information;
   Image segmentation; RGB-Dsensor
AB Image segmentation is one of the most important topics in the field of computer vision. As a result, many image segmentation approaches have been proposed, and interactive methods based on energy minimization such as GrabCut, have shown successful results. Automating the entire segmentation process is, however, very difficult because virtually all interactive methods require a considerable amount of user interaction. We believe that if additional information is provided to users in order to guide them effectively, the amount of interaction required can be reduced. Consequently, in this paper we propose an efficient foreground extraction algorithm, which utilizes depth information from RGB-D sensors such as Microsoft Kinect and offers users guidance in the foreground extraction process. Our approach can be applied as a pre-processing step for interactive and energy-minimization-based segmentation approaches. Our proposed method is able to segment the foreground from images and give hints that reduce interaction with users. In our method, we make use of the characteristics of depth information captured by RGB-D sensors and describe them using information from the structure tensor. Further, we show experimentally that our proposed method separates foreground from background sufficiently well for real world images.
C1 [Lee, Sang-Wook] Korea Adv Inst Sci & Technol, Robot Program, Daejeon, South Korea.
   [Seo, Yong-Ho] Mokwon Univ, Dept Intelligent Robot Engn, Daejeon, South Korea.
   [Yang, Hyun S.] Korea Adv Inst Sci & Technol, Dept Comp Sci, Daejeon, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Mokwon
   University; Korea Advanced Institute of Science & Technology (KAIST)
RP Seo, YH (corresponding author), Mokwon Univ, Dept Intelligent Robot Engn, Daejeon, South Korea.
EM sangwook@paradise.kaist.ac.kr; yhseo@mokwon.ac.kr;
   yang@paradise.kaist.ac.kr
RI Yang, Hyun Seung/C-1984-2011
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Science, ICT and Future Planning
   [2013R1A1A2064233, 2011-0013776]; IT R&D program of MKE KEIT [10041610]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Science, ICT and Future Planning (2013R1A1A2064233 and 2011-0013776)
   and the IT R&D program of MKE & KEIT [10041610, The development of the
   recognition technology for user identity, behavior and location that has
   a performance approaching recognition rates of 99% on 30 people by using
   perception sensor network in the real environment].
CR [Anonymous], 1992, R. woods digital image processing
   [Anonymous], INT S 3D DAT PROC VI
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Chuang YY, 2001, PROC CVPR IEEE, P264
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Freixenet J, 2002, LECT NOTES COMPUT SC, V2352, P408, DOI 10.1007/3-540-47977-5_27
   GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x
   Hernández-Vela A, 2012, PROC CVPR IEEE, P726, DOI 10.1109/CVPR.2012.6247742
   Lee SW, 2013, 8 INT C BROADB WIR C
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P1699, DOI 10.1109/TPAMI.2008.168
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Peng B, 2013, PATTERN RECOGN, V46, P1020, DOI 10.1016/j.patcog.2012.09.015
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Wasza J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1221, DOI 10.1109/ICCVW.2011.6130390
NR 16
TC 0
Z9 0
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 9
BP 4969
EP 4980
DI 10.1007/s11042-013-1789-x
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DM8HE
UT WOS:000376601700008
DA 2024-07-18
ER

PT J
AU Wei, JG
   Wang, S
   Lu, WH
   Hou, QZ
   Fang, Q
   Dang, JW
AF Wei, Jianguo
   Wang, Song
   Lu, Wenhuan
   Hou, Qingzhi
   Fang, Qiang
   Dang, Jianwu
TI Multi-modal recording and modeling of vocal tract movements
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ultrasound images; EMA; Vocal tract; Alignment
ID ULTRASOUND IMAGES; SYSTEM
AB The complexity of vocal tract movement causes the difficult to record whole information of vocal tract during speech. Dynamic articulation has been acquired by implementing a variety of instruments, each of which has its advantages and shortcomings. However, the measurement of vocal tract movements is a difficult task to accomplish using one type of recording technique, and this has led to the simultaneous application of multiple instruments. Thus, we used an ultrasound system in combination with the electromagnetic articulography (EMA) system to record the multi-modality movement of the tongue. Data of the vocal tract movements were obtained by the ultrasound-based speech recording system developed by us, with which ultrasound images and synchronized audio signals are recorded synchronously. The EMA system is also used for the simultaneous collection of articulatory data with the audio. The EMA and ultrasound data were registered and matched to the same audio signal, after which these two sets of data were fused for each time point. In addition, a method for vocal tract shape reconstruction and modeling is proposed for the ultrasound dataset by using an active shape model. The averaged reconstruction error does not exceed 1.26 mm.
C1 [Wei, Jianguo; Wang, Song; Lu, Wenhuan] Tianjin Univ, Sch Comp Software, Tianjin 300072, Peoples R China.
   [Hou, Qingzhi; Dang, Jianwu] Tianjin Univ, Tianjin Key Lab Cognit Computat & Applicat, Tianjin 300072, Peoples R China.
   [Fang, Qiang] Chinese Acad Social Sci, Inst Linguist, Phonet Lab, Beijing, Peoples R China.
   [Dang, Jianwu] Japan Adv Inst Sci & Technol, Nomi, Japan.
C3 Tianjin University; Tianjin University; Chinese Academy of Social
   Sciences; Japan Advanced Institute of Science & Technology (JAIST)
RP Lu, WH (corresponding author), Tianjin Univ, Sch Comp Software, Tianjin 300072, Peoples R China.
EM wenhuan@tju.edu.cn
RI Wei, Jianguo/KBA-3200-2024
OI Wei, Jianguo/0000-0002-8964-9759; Wang, Song/0000-0002-3012-5715
FU National Natural Science Foundation (NSFC) of China [61,175,016,
   61,304,250]; 973 project [2013CB329305]
FX This work was supported by the National Natural Science Foundation
   (NSFC) of China (No. 61,175,016), as well as a 973 project (No.
   2013CB329305), and the National Natural Science Foundation (NSFC) of
   China (No. 61,304,250).
CR Avila-Garcia MS, 2005, WORLD ACAD SCI ENG T, V2
   Boisvert J., 2008, WORKSH SYST ARCH COM
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Florescu VM, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P450
   Hoole Philip., 1999, Coarticulation: Theory, Data and Techniques, P260, DOI DOI 10.1017/CBO9780511486395.013
   Hueber T, 2010, SPEECH COMMUN, V52, P288, DOI 10.1016/j.specom.2009.11.004
   Lee Hung Liew LHL, 2013, J CONVERGENCE, V4, P15
   Lepsoy S, 1998, SIGNAL PROCESS-IMAGE, V13, P209, DOI 10.1016/S0923-5965(98)00006-X
   LI A, 2004, ICSLT O COCOSDA
   Li M, 2005, CLIN LINGUIST PHONET, V19, P545, DOI 10.1080/02699200500113616
   Mielke J., 2005, Coyote Papers, V14, P97
   PERKELL JS, 1992, J ACOUST SOC AM, V92, P3078, DOI 10.1121/1.404204
   Shahabi C, 2014, J INF PROCESS SYST, V10, P1, DOI 10.3745/JIPS.2014.10.1.001
   SONG C, 2012, ISCSLIP, P383
   STONE M, 1983, J PHONETICS, V11, P207, DOI 10.1016/S0095-4470(19)30822-8
   Stone M, 1995, J ACOUST SOC AM, V98, P3107, DOI 10.1121/1.413799
   van Assen HC, 2006, MED IMAGE ANAL, V10, P286, DOI 10.1016/j.media.2005.12.001
   van Ginneken Bram, 2002, IEEE T MED IMAGING, V21
   Verma P, 2013, INF SCI, V3, P21
   Wang Song, 2012, ISCSLP, P393
   Wei Jianguo, 2015, GEN FINITE DIFFERENC, V2015
NR 21
TC 4
Z9 4
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 9
BP 5247
EP 5263
DI 10.1007/s11042-015-3040-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DM8HE
UT WOS:000376601700024
DA 2024-07-18
ER

PT J
AU Bai, X
   Yan, C
   Ren, P
   Bai, L
   Zhou, J
AF Bai, Xiao
   Yan, Cheng
   Ren, Peng
   Bai, Lu
   Zhou, Jun
TI Discriminative sparse neighbor coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image classification; Sparse representation; Discriminative features;
   Neighboring information
ID IMAGE CLASSIFICATION; LOW-RANK; FEATURES
AB Sparse coding has received extensive attention in the literature of image classification. Traditional sparse coding strategies tend to approximate local features in terms of a linear combination of basis vectors, without considering feature neighboring relationships. In this scenario, similar instances in the feature space may result in totally different sparse codes. To address this shortcoming, we investigate how to develop new sparse representations which preserve feature similarities. We commence by establishing two modules to improve the discriminative ability of sparse representation. The first module selects discriminative features for each class, and the second module eliminates non-informative visual words. We then explore the distribution of similar features over the dominant basis vectors for each class. We incorporate the feature distribution into the objective function, spanning a class-specific low dimensional subspace for effective sparse coding. Extensive experiments on various image classification tasks validate that the proposed approach consistently outperforms several state-of-the-art methods.
C1 [Bai, Xiao; Yan, Cheng] Beihang Univ, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
   [Ren, Peng] China Univ Petr Huadong, Coll Informat & Control Engn, Qingdao 266580, Peoples R China.
   [Bai, Lu] Cent Univ Finance & Econ, Sch Informat, Beijing 100081, Peoples R China.
   [Zhou, Jun] Griffith Univ, Sch Informat & Commun Technol, Nathan, Qld 4111, Australia.
C3 Beihang University; China University of Petroleum; Central University of
   Finance & Economics; Griffith University
RP Ren, P (corresponding author), China Univ Petr Huadong, Coll Informat & Control Engn, Qingdao 266580, Peoples R China.
EM pengren@upc.edu.cn
RI Zhou, Jun/W-2233-2019; zhou, chuyue/JOJ-9001-2023
OI Zhou, Jun/0000-0001-5822-8233; 
FU NSFC [61370123, 61503422]; Shandong Outstanding Young Scientist Fund
   [BS2013DX006]; Qingdao Fundamental Research Project [13-1-4-256-jch];
   Australian Research Council [DE120102948]; Australian Research Council
   [DE120102948] Funding Source: Australian Research Council
FX This work was supported by NSFC projects (No. 61370123 and 61503422),
   Shandong Outstanding Young Scientist Fund (No. BS2013DX006), Qingdao
   Fundamental Research Project (No. 13-1-4-256-jch), and the Australian
   Research Councils DECRA Projects funding scheme (project ID
   DE120102948).
CR [Anonymous], LEARNING GENERATIVE
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], 2008, P 7 ACM INT C IMAGE
   [Anonymous], DEVIL IS DETAILS EVA
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   [Anonymous], IJCNLP
   Bengio S., 2009, Advances in Neural Information Processing Systems, V22, P82
   Boiman Oren., 2008, In defense of nearest-neighbor based image classification. 0:1-8
   Chen XD, 2011, 2011 4TH IEEE INTERNATIONAL CONFERENCE ON BROADBAND NETWORK AND MULTIMEDIA TECHNOLOGY (4TH IEEE IC-BNMT2011), P1, DOI 10.1109/ICBNMT.2011.6155883
   Chiang CK, 2011, IEEE I CONF COMP VIS, P1519, DOI 10.1109/ICCV.2011.6126410
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943
   Guha S, 1998, ALGORITHMICA, V20, P374, DOI 10.1007/PL00009201
   Haynes T. W., 1998, CHAPMAN HALL CRC PUR
   Huang YZ, 2014, IEEE T PATTERN ANAL, V36, P493, DOI 10.1109/TPAMI.2013.113
   Kim Gunhee, 2008, CVPR
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lazebnik S, 2009, IEEE T PATTERN ANAL, V31, P1294, DOI 10.1109/TPAMI.2008.138
   Li Fei-Fei, 2007, INT C COMPUTER VISIO, P1
   Lili Hao, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P718, DOI 10.1109/CSSE.2008.829
   Liu LQ, 2011, IEEE I CONF COMP VIS, P2486, DOI 10.1109/ICCV.2011.6126534
   Liu S, 2012, PATTERN RECOGN LETT, V33, P744, DOI 10.1016/j.patrec.2011.12.008
   Liu YN, 2010, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2010.5539934
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu XQ, 2012, PROC CVPR IEEE, P1648, DOI 10.1109/CVPR.2012.6247858
   Mairal J., 2009, P 26 ANN INT C MACHI, P689, DOI 10.1145/1553374.1553463
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   Mosci Sofia., 2010, ADV NEURAL INFORM PR, P2604
   Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085
   Pele O, 2009, IEEE I CONF COMP VIS, P460, DOI 10.1109/ICCV.2009.5459199
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Peyré G, 2009, J MATH IMAGING VIS, V34, P17, DOI 10.1007/s10851-008-0120-3
   Ren XF, 2013, PROC CVPR IEEE, P3246, DOI 10.1109/CVPR.2013.417
   Shaban A, 2013, PROC CVPR IEEE, P2794, DOI 10.1109/CVPR.2013.360
   Shen L, 2013, PROC CVPR IEEE, P383, DOI 10.1109/CVPR.2013.56
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Skretting K, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/52561
   Turcot Panu, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P2109, DOI 10.1109/ICCVW.2009.5457541
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Winn J, 2005, IEEE I CONF COMP VIS, P1800
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu JX, 2009, IEEE I CONF COMP VIS, P630, DOI 10.1109/ICCV.2009.5459178
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yuan J, 2007, COMPUTER VISION PATT, P1
   Yuan M., 2006, Journal of the Royal Statistical Society, Series B, V70, P53
   Zhang CJ, 2013, J VIS COMMUN IMAGE R, V24, P786, DOI 10.1016/j.jvcir.2013.05.004
   Zhang CJ, 2011, PROC CVPR IEEE, P1673, DOI 10.1109/CVPR.2011.5995484
   Zhang LH, 2014, NEUROCOMPUTING, V135, P339, DOI 10.1016/j.neucom.2013.12.032
   Zhang T., 2012, LOW RANK SPARSE LEAR
   Zhang YMZ, 2013, PROC CVPR IEEE, P676, DOI 10.1109/CVPR.2013.93
   Zheng M, 2011, IEEE T IMAGE PROCESS, V20, P1327, DOI 10.1109/TIP.2010.2090535
   Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141, DOI 10.1007/978-3-642-15555-0_11
NR 54
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 7
BP 4013
EP 4037
DI 10.1007/s11042-015-2951-4
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DI0GB
UT WOS:000373172200022
DA 2024-07-18
ER

PT J
AU Hoque, MM
   Song, G
   Ahn, K
   Ryu, B
   Bin Iqbal, MT
   Chae, O
AF Hoque, Md. Monirul
   Song, Gihun
   Ahn, Kiok
   Ryu, Byungyong
   Bin Iqbal, Md. Tauhid
   Chae, Oksam
TI DCT statistics-based digital dropout detection in degraded archived
   media
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital dropout; Support vector machine; Degraded archived media; Human
   visual perception; Discrete cosine transform
ID IMAGE QUALITY ASSESSMENT; ERROR; VIDEO; TRANSMISSION; CONCEALMENT;
   EXTRACTION
AB With the rapid development of visual digital media, the demand for better quality of service has increased the pressure on broadcasters to automate their error detection and restoration activities for preserving their archives. Digital dropout is one of the defects that affect archived visual materials and tends to occur in block by block basis (size of 8 x 8). It is well established that human visual system (HVS) is highly adapted to the statistics of its visual natural environment. Consequently, in this paper, we have formulated digital dropout detection as a classification problem which predicts block label based on statistical features. These statistical features are indicative of perceptual quality relevant to human visual perception, and allow pristine images to be distinguished from distorted ones. Here, the idea is to extract discriminant block statistical features based on discrete cosine transform (DCT) coefficients and determine an optimal neighborhood sampling strategy to enhance the discrimination ability of block representation. Since this spatial frame based approach is free from any motion computation dependency, it works perfectly in the presence of fast moving objects. Experiments are performed on video archives to evaluate the efficacy of the proposed technique.
C1 [Hoque, Md. Monirul; Song, Gihun; Ahn, Kiok; Ryu, Byungyong; Bin Iqbal, Md. Tauhid; Chae, Oksam] Kyung Hee Univ, Dept Comp Engn, 1 Seocheon Dong, Yongin 446701, Gyeonggido, South Korea.
C3 Kyung Hee University
RP Chae, O (corresponding author), Kyung Hee Univ, Dept Comp Engn, 1 Seocheon Dong, Yongin 446701, Gyeonggido, South Korea.
EM monirul@khu.ac.kr; gihunsong@khu.ac.kr; kiokahn@daum.net;
   read100nm@khu.ac.kr; tauhidiq@khu.ac.kr; oschae@khu.ac.kr
CR Bachman R, PRESERVATION GLOSSAR
   Bae HJ, 1997, ICICS - PROCEEDINGS OF 1997 INTERNATIONAL CONFERENCE ON INFORMATION, COMMUNICATIONS AND SIGNAL PROCESSING, VOLS 1-3, P1065, DOI 10.1109/ICICS.1997.652144
   Balam S, 2006, IEEE T CIRC SYST VID, V16, P241, DOI 10.1109/TCSVT.2005.858696
   Barlow H, 2001, NETWORK-COMP NEURAL, V12, P241, DOI 10.1088/0954-898X/12/3/301
   BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384
   Brandao T, 2008, SIGNAL PROCESS, V88, P822, DOI 10.1016/j.sigpro.2007.09.017
   CHO NI, 1991, IEEE T CIRCUITS SYST, V38, P297, DOI 10.1109/31.101322
   Eom M, 2005, PROC WRLD ACAD SCI E, V9, P209
   Farrugia Reuben A., 2007, EUROCON 2007. International Conference on "Computer as a Tool", P1091, DOI 10.1109/EURCON.2007.4400260
   Farrugia RA, 2009, IEEE T MULTIMEDIA, V11, P1323, DOI 10.1109/TMM.2009.2030651
   Gabarda S, 2007, J OPT SOC AM A, V24, pB42, DOI 10.1364/JOSAA.24.000B42
   Geisler WS, 2008, ANNU REV PSYCHOL, V59, P167, DOI 10.1146/annurev.psych.58.110405.085632
   HAQUE MA, 1985, IEEE T ACOUST SPEECH, V33, P1532, DOI 10.1109/TASSP.1985.1164737
   Hoque MM, 2014, ELECTRON LETT, V50, P996, DOI 10.1049/el.2014.1055
   Hsu CW, 2002, MACH LEARN, V46, P291, DOI 10.1023/A:1012427100071
   Kaprykowsky H, 2009, IEEE IMAGE PROC, P85, DOI 10.1109/ICIP.2009.5414099
   Khan E, 2004, IEEE T CIRC SYST VID, V14, P1294, DOI 10.1109/TCSVT.2004.837018
   Kokaram AC, 2004, IEEE T IMAGE PROCESS, V13, P395, DOI 10.1109/TIP.2004.823815
   KOKARAM AC, 1995, IEEE T IMAGE PROCESS, V4, P1496, DOI 10.1109/83.469931
   Kung WY, 2006, IEEE T CIRC SYST VID, V16, P789, DOI 10.1109/TCSVT.2006.877391
   Lee SW, 2000, IEEE T MULTIMEDIA, V2, P240, DOI 10.1109/6046.890059
   Ma L, 2011, IEEE T MULTIMEDIA, V13, P824, DOI 10.1109/TMM.2011.2109701
   PELI E, 1990, J OPT SOC AM A, V7, P2032, DOI 10.1364/JOSAA.7.002032
   Saad M. A., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3093, DOI 10.1109/ICIP.2011.6116319
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Saad MA, 2010, IEEE SIGNAL PROC LET, V17, P583, DOI 10.1109/LSP.2010.2045550
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Shen B, 1996, P SOC PHOTO-OPT INS, V2670, P404, DOI 10.1117/12.234779
   Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002
   Sun S., 2010, P IEEE CHIN C PATT R, P1, DOI DOI 10.1109/CCPR.2010.5659234
   van der Schaar M, 2006, IEEE T MULTIMEDIA, V8, P1082, DOI 10.1109/TMM.2006.879827
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
NR 32
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4259
EP 4283
DI 10.1007/s11042-015-2469-9
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700005
DA 2024-07-18
ER

PT J
AU Stanco, F
   Allegra, D
   Milotta, FLM
AF Stanco, Filippo
   Allegra, Dario
   Milotta, Filippo Luigi Maria
TI Tracking error in digitized analog video: automatic detection and
   correction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mistracking; Tracking error; Analog video; Drop out
ID MISSING DATA
AB In the last half century the most used video storage devices have been the magnetic tapes, where the information are stored in analog format based on the electromagnetism principles. When the digital technique has become the most used, it was necessary to convert analog information in digital format in order to preserve these data. Unfortunately, analog videos may be affected by drops that produce some visual defect which could be acquired during the digitization process. Despite there are many hardware to perform the digitization, just few implement the automatic correction of these defects. In some cases, drop removal is possible through the analog device. However, when a damaged already-converted video is owned, a correction based on image processing technique is the unique way to enhance the videos. In this paper, the drop, also known as "Tracking Error" or "Mistracking," is analyzed. We propose an algorithm to detect the drops' visual artifacts in the converted videos, as well as a digital restoration method.
C1 [Stanco, Filippo; Allegra, Dario; Milotta, Filippo Luigi Maria] Univ Catania, Dipartimento Matemat & Informat, Viale A Doria 6, I-95125 Catania, Italy.
C3 University of Catania
RP Stanco, F (corresponding author), Univ Catania, Dipartimento Matemat & Informat, Viale A Doria 6, I-95125 Catania, Italy.
EM fstanco@dmi.unict.it; darioalltalk@gmail.com; fmilotta@gmail.com
RI Stanco, Filippo/ABE-5747-2021; Allegra, Dario/AFQ-6806-2022
OI Stanco, Filippo/0000-0003-3865-9911; Allegra, Dario/0000-0002-4819-5340
CR Buisson O, 1997, PROC CVPR IEEE, P78, DOI 10.1109/CVPR.1997.609301
   Gonzalez RC, 2008, DIGITALE IMAGE PROCE
   GUPTA R.G., 2005, TELEVISION ENG VIDEO
   KOKARAM AC, 1995, IEEE T IMAGE PROCESS, V4, P1496, DOI 10.1109/83.469931
   KOKARAM AC, 1995, IEEE T IMAGE PROCESS, V4, P1509, DOI 10.1109/83.469932
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Puglisi G, 2013, INT SYMP IMAGE SIG, P548
   Rosenthaler L, 2001, P IEEE SEM DIG REST
   Stance Filippo, 2012, Journal of Multimedia, V7, P211, DOI 10.4304/jmm.7.2.211-216
   Stanco F, 2012, VIRTUAL ARCHAEOL REV, V3, P126, DOI 10.4995/var.2012.4541
   Stanco F, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.2134696
   Stanco F, 2013, J ELECT COMPUT ENG, P1
   Stanco F, 2013, LNCS, V8158
   Stanco F., 2011, CULTURAL HERITAGE PR
   Stanco F, 2012, CGIV 2012
   Stanco F, 2012, COMM COM INF SC, V247, P126
NR 16
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 7
BP 3733
EP 3746
DI 10.1007/s11042-014-2068-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DI0GB
UT WOS:000373172200009
DA 2024-07-18
ER

PT J
AU Zhuang, Y
   Jiang, N
   Li, Q
   Chiu, DKW
   Hu, H
AF Zhuang, Yi
   Jiang, Nan
   Li, Qing
   Chiu, Dickson K. W.
   Hu, Hua
TI Personalized and efficient social image transmission scheme in mobile
   wireless network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social image; Multi-resolution; Mobile wireless network
ID DELIVERY
AB This paper presents a Personalized large Social Image Transmission method in mobile wireless network(MWN) environment, called the P-SIT. The whole transmission process of the P-SIT works as follows: first, when a social image I-S is prepared to transmit from a sender node to user UR, a preprocessing step is then conducted to obtain the optimal image fragment(IF) replica based on the users' preference model and the network bandwidth at the sender node. After that, the candidate IFs are transferred to the receiver node from the slave one according to the transmission priorities. Finally, the IFs can be recovered and displayed at the receiver node level. The proposed method includes five enabling techniques: 1) neighborhood- based tag enrichment processing, 2) user attention degree(UAD) derivation of the regions of interest(ROI), 3) an adaptive multi-resolution-based IF replica selection method, 4) a UAD-based IF replica placement method, and 5) a priority-based robust IF transmission scheme. The experimental results show that the performance of our approach is both efficient and effective, minimizing the response time by decreasing the network transmission cost while increasing the parallelism of I/ O and CPU.
C1 [Zhuang, Yi] Zhejiang Gongshang Univ, Coll Comp & Informat Engn, Hangzhou, Zhejiang, Peoples R China.
   [Jiang, Nan] Hangzhou First Peoples Hosp, Hangzhou, Zhejiang, Peoples R China.
   [Li, Qing] City Univ Hong Kong, Dept Comp Sci, Tat Chee Ave, Kowloon, Hong Kong, Peoples R China.
   [Chiu, Dickson K. W.] Univ Hong Kong, Fac Educ, Pok Fu Lam, Hong Kong, Peoples R China.
   [Hu, Hua] Hangzhou Dianzi Univ, Sch Comp, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang Gongshang University; City University of Hong Kong; University
   of Hong Kong; Hangzhou Dianzi University
RP Zhuang, Y (corresponding author), Apart 502,Unit 2,Blg 7QinchunfangHangzhou, Hangzhou, Peoples R China.
EM zy158cn@gmail.com
RI Li, Qing/JMH-1365-2023; Chiu, Dickson K. W./B-9630-2017; JIANG,
   NAN/AHB-1945-2022
OI Li, Qing/0000-0003-3370-471X; Chiu, Dickson K. W./0000-0002-7926-9568; 
FU National Natural Science Foundation of China [61003074, 61272188];
   Natural Science Foundation of Zhejiang Province [LY13F020008,
   LY13F020010]; Ministry of Education of Humanities and Social Sciences
   [14YJCZH235]; Science & Technology Innovative Team of Zhejiang Province
   [2012R10041-06]
FX This paper is partially supported by the Program of National Natural
   Science Foundation of China under Grant Nos. 61003074 and 61272188; the
   Program of Natural Science Foundation of Zhejiang Province under Grant
   Nos. LY13F020008, and LY13F020010; the Ministry of Education of
   Humanities and Social Sciences Project under Grant No. 14YJCZH235. The
   Science & Technology Innovative Team of Zhejiang Province under Grant
   No. 2012R10041-06.
CR Allcock B, 2002, PARALLEL COMPUT, V28, P749, DOI 10.1016/S0167-8191(02)00094-7
   [Anonymous], 2009, ICIVR
   Aziz SM, 2013, IEEE COMMUN LETT, V17, P1084, DOI 10.1109/LCOMM.2013.050313.121933
   Boluk PS, 2011, MOBILE NETW APPL, V16, P149, DOI 10.1007/s11036-010-0282-2
   Buyya R, 2008, LECT NOTES ELECTR EN, V9, P1, DOI 10.1007/978-3-540-77887-5
   Chang C.C., 2002, VISUAL COMPUT, P341
   Chang CC, 2003, 2003 INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY, VOL 1 AND 2, PROCEEDINGS, P1774
   Chang RC, 2008, J INF SCI ENG, V24, P691
   Chin-Chen Chang, 1999, Fifth Asia-Pacific Conference on Communications and Fourth Optoelectronics and Communications Conference. APCC/OECC'99. Proceedings. Conference - Vitality to the New Century (IEEE Cat. No.99EX379), P892, DOI 10.1109/APCC.1999.820406
   Pham DM, 2013, 2013 IEEE EIGHTH INTERNATIONAL CONFERENCE ON INTELLIGENT SENSORS, SENSOR NETWORKS AND INFORMATION PROCESSING, P260, DOI 10.1109/ISSNIP.2013.6529799
   Pham DM, 2013, COMPUT NETW, V57, P2949, DOI 10.1016/j.comnet.2013.07.001
   Gao DH, 2010, LECT NOTES ARTIF INT, V6216, P334
   John M. D., 1995, ACM INT C MULT
   Kim JH, 1996, IEE P-VIS IMAGE SIGN, V143, P132, DOI 10.1049/ip-vis:19960254
   Li XR, 2012, IEEE T MULTIMEDIA, V14, P1091, DOI 10.1109/TMM.2012.2191943
   Li XR, 2009, IEEE T MULTIMEDIA, V11, P1310, DOI 10.1109/TMM.2009.2030598
   Lin T, 2005, IEEE T IMAGE PROCESS, V14, P993, DOI 10.1109/TIP.2005.849776
   Paul S, 2001, COMPUT COMMUN, V24, P256, DOI 10.1016/S0140-3664(00)00322-4
   Rabbat R, 2010, WEB P NEW IMAGE FORM, P10
   Raman S, 2000, 2000 INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, PROCEEDINGS, P209, DOI 10.1109/ICNP.2000.896305
   Ruiz V., 2001, P 19 IASTED INT C AP, P519
   Sun Y, 2006, IEEE T MOBILE COMPUT, V5, P1016, DOI 10.1109/TMC.2006.120
   Turner C. J., 1992, Computer Communication Review, V22, P258, DOI 10.1145/144191.144296
   TZOU KH, 1987, OPT ENG, V26, P581, DOI 10.1117/12.7974121
   Vakali A, 2003, IEEE INTERNET COMPUT, V7, P68, DOI 10.1109/MIC.2003.1250586
   Wan Z, 2014, MULTIMED TOOLS APPL, V72, P541, DOI 10.1007/s11042-013-1378-z
   Yang S H, 2011, WWW 2011
   [张红兴 Zhang Hongxing], 2013, [高分子通报, Polymer Bulletin], P1
   Zhu XQ, 2008, IEEE IMAGE PROC, P3092, DOI 10.1109/ICIP.2008.4712449
   Zhuang Y, 2014, INF SCI
NR 30
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 6
BP 2931
EP 2968
DI 10.1007/s11042-014-2413-4
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DH6BI
UT WOS:000372875600002
DA 2024-07-18
ER

PT J
AU Baek, J
   Hong, S
   Kim, J
   Kim, E
AF Baek, Jeonghyun
   Hong, Sungjun
   Kim, Jisu
   Kim, Euntai
TI Bayesian learning of a search region for pedestrian detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pedestrian detection; Sliding window approach; HOG-LSVM; Haar-like
   Adaboost; Bayesian inference; Caltech pedestrian dataset
AB An efficient pedestrian detection method is proposed for intelligent vehicles in this paper. The proposed method learns the region in which pedestrians are likely to be detected and narrows down the search to the likely region. The likely region is modeled as a Gaussian distribution on the y-axis and its parameters are updated by a Bayesian approach. Thus, the proposed method starts with an exhaustive full search, but gradually narrows down the search by focusing on the likely region. The learning of the likely region is formulated as a Bayesian learning problem and the likely region is analytically derived. The proposed method is combined with two popular pedestrian detection methods, Haar-like Adaboost and HOG-LSVM, and some experiments are conducted with the Caltech pedestrian dataset. The experiments show that the proposed method not only reduces computation time, but also enhances performance by rejecting false positive results.
C1 [Baek, Jeonghyun; Hong, Sungjun; Kim, Jisu; Kim, Euntai] Yonsei Univ, Sch Elect & Elect Engn, Seoul 120749, South Korea.
C3 Yonsei University
RP Kim, E (corresponding author), Yonsei Univ, Sch Elect & Elect Engn, Seoul 120749, South Korea.
EM etkim@yonsei.ac.kr
OI Hong, Sungjun/0000-0002-0859-8006
FU Basic Science Research Program through National Research Foundation of
   Korea (NRF) - Ministry of Education, Science and Technology
   [NRF-2013R1A2A2A01015624]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education, Science and Technology (NRF-2013R1A2A2A01015624).
CR [Anonymous], IEEE COMP SOC C COMP
   Bradsk G, 2005, INTEL TECHNOLOGY J, V9
   Corinna C., 1995, MACH LEARN, V20, P273, DOI [DOI 10.1007/BF00994018, 10.1007/BF00994018. S2CID 206787478]
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ding JH, 2013, MULTIMED TOOLS APPL, V63, P791, DOI 10.1007/s11042-011-0896-9
   Dollar P, 2009, P BRIT MACH VIS C 20
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Dollár P, 2009, PROC CVPR IEEE, P304, DOI 10.1109/CVPRW.2009.5206631
   Ess A, 2009, IEEE T PATTERN ANAL, V31, P1831, DOI 10.1109/TPAMI.2009.109
   Gamerman D., 2006, MARKOV CHAIN MONTE C, DOI 10.1201/9781482296426
   Gavrila D., 2000, Pedestrian Detection from a Moving Vehicle, V1843, P37
   Gualdi G, 2012, IEEE T PATTERN ANAL, V34, P1589, DOI 10.1109/TPAMI.2011.247
   Ko B, 2013, OPTICAL ENG, V52
   Lim J, 2013, MULTIMED TOOLS APPL, V65, P161, DOI 10.1007/s11042-012-1156-3
   Martin A., 1997, Eurospeech
   Nam B, 2010, OPT ENG, V49, DOI 10.1117/1.3521254
   Sabzmeydani P., 2007, CVPR, P1, DOI DOI 10.1109/CVPR.2007.383134
   Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8
   Walk S., 2010, CVPR 2010, DOI DOI 10.1109/CVPR.2010.5540102
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Wojek C, 2008, PATTERN RECOGNTION, P82
   Zeng BB, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.7.077206
   Zhu Q, 2006, 2006 IEEE COMP SOC C, P1491, DOI [10.1109/CVPR.2006.119, DOI 10.1109/CVPR.2006.119]
NR 24
TC 2
Z9 2
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 2
BP 863
EP 885
DI 10.1007/s11042-014-2329-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB7YX
UT WOS:000368734700008
DA 2024-07-18
ER

PT J
AU Ma, XX
   Pan, ZB
   Hu, S
   Wang, LF
AF Ma, Xiaoxiao
   Pan, Zhibin
   Hu, Sen
   Wang, Lingfei
TI Large capacity and high quality reversible data hiding method based on
   enhanced side match vector quantization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Hiding capacity; Image quality; Side-match vector
   quantization (SMVQ); Enhanced side-match vector quantization (ESMVQ)
ID HISTOGRAM-MODIFICATION; SCHEME
AB In recent years, many reversible data hiding techniques have been proposed to solve information security problem. In this paper, we propose a novel reversible data hiding method based on enhanced side-match vector quantization (ESMVQ). We embed as many secret bits into the images compressed by ESMVQ which uses the very small state codebook size of 4 to achieve a large hiding capacity and meanwhile ensure the compressed image quality by introducing a complementary state codebook. The experimental results demonstrate that the proposed method has a large embedding capacity and a good image quality. The experimental results also show that our proposed method outperforms the methods of Chang et al. (IEEE Trans on Circ and Syst for Vi Techno 16(10):1301-1308, 2006), Huang et al. (The Image Sci J 61(2):195-203, 2013), Lee et al. (IEEE Trans on Inf Forensic and Secur 5(4):638-648, 2010) and Wang et al. (Inf Sci 246:69-82, 2013).
C1 [Ma, Xiaoxiao; Pan, Zhibin; Hu, Sen; Wang, Lingfei] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
   [Pan, Zhibin] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Jiangsu, Peoples R China.
C3 Xi'an Jiaotong University; Nanjing University
RP Pan, ZB (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
EM zbpan@mail.xjtu.edu.cn
RI Pan, Zhibin/I-8212-2012
FU Specialized Research Fund for the Doctoral Program of Higher Education
   [20130201110071]; Key Science and Technology Program of Shaanxi Province
   [2012GY2-30]; Open Project Program of the State Key Lab of SKL, Nanjing
   University [KFKT2013B05]
FX This work is supported in part by Specialized Research Fund for the
   Doctoral Program of Higher Education (Grant No. 20130201110071), Project
   Supported by Key Science and Technology Program of Shaanxi Province
   (Grant No. 2012GY2-30) and Open Project Program of the State Key Lab of
   SKL (Grant No. KFKT2013B05), Nanjing University.
CR Celik MU, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P157
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2006, IEEE T CIRC SYST VID, V16, P1301, DOI 10.1109/TCSVT.2006.882380
   Chang CC, 2013, J SYST SOFTWARE, V86, P389, DOI 10.1016/j.jss.2012.09.001
   Chang CC, 2009, J VIS COMMUN IMAGE R, V20, P57, DOI 10.1016/j.jvcir.2008.08.005
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   Huang CT, 2013, IMAGING SCI J, V61, P195, DOI 10.1179/1743131X11Y.0000000031
   Kim TJ, 1992, IEEE T IMAGE PROCESS, V1, P170, DOI 10.1109/83.136594
   Lan TH, 2006, IEEE T IMAGE PROCESS, V15, P2431, DOI 10.1109/TIP.2006.875238
   Lee JD, 2010, IEEE T INF FOREN SEC, V5, P638, DOI 10.1109/TIFS.2010.2066971
   NASRABADI NM, 1988, IEEE T COMMUN, V36, P957, DOI 10.1109/26.3776
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Pan ZB, 2013, J SYST SOFTWARE, V86, P2863, DOI 10.1016/j.jss.2013.06.066
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tsai P, 2009, IET IMAGE PROCESS, V3, P100, DOI 10.1049/iet-ipr.2007.0220
   Tsang PWM, 1996, IEEE T CONSUM ELECTR, V42, P112, DOI 10.1109/30.485468
   Wang JX, 2009, INFORM SCIENCES, V179, P3332, DOI 10.1016/j.ins.2009.05.021
   Wang WJ, 2013, INFORM SCIENCES, V246, P69, DOI 10.1016/j.ins.2013.05.007
   Wang WJ, 2011, IEEE SYST J, V5, P528, DOI 10.1109/JSYST.2011.2165603
NR 20
TC 2
Z9 2
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 1
BP 71
EP 91
DI 10.1007/s11042-014-2268-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5QB
UT WOS:000367856500004
DA 2024-07-18
ER

PT J
AU Rossholm, A
   Lövström, B
AF Rossholm, Andreas
   Lovstrom, Benny
TI A robust method for estimating synchronization and delay of audio and
   video for communication services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lip sync; Synchronization; Delay; QoE; Video streaming; Video
   conferencing
ID HETEROGENEOUS NETWORKS; MEDIA SYNCHRONIZATION; QUALITY ASSESSMENT;
   PERCEPTION
AB One of the main contributions to the quality of experience in streaming services or in two-way communication of audio and video applications is synchronization. This has been shown in several studies and experiments but methods to measure synchronization are less frequent, especially for situations without internal access to the application and independent of platform and device. In this paper we present a method for measuring synchronization skewness as well as delay for audio and video. The solution incorporates audio and video reference streams, where audio and video frames are marked with frame numbers which are decoded on the receiver side to enable calculation of synchronization and delay. The method has been verified in a two-way communication application in a transparent network with and without inserting known delays, as well as in a network with 5 and 10 % packet loss levels. The method can be used for both streaming and two-way communication services, both with and without access to the internal structures, and enables measurements of applications running on e.g. smartphones, tablets, and laptops under various conditions.
C1 [Rossholm, Andreas; Lovstrom, Benny] Blekinge Inst Technol, S-37179 Karlskrona, Sweden.
C3 Blekinge Institute Technology
RP Lövström, B (corresponding author), Blekinge Inst Technol, S-37179 Karlskrona, Sweden.
EM a.rossholm@gmail.com; benny.lovstrom@bth.se
RI Lövström, Benny/C-6732-2015
OI Lövström, Benny/0000-0003-3824-0942
CR [Anonymous], 1996, 297 ETSI ETR
   [Anonymous], 2001, ITU T SER G
   [Anonymous], 1999, ITU T SER H
   [Anonymous], 2003, ITU T SER G
   [Anonymous], 1990, J100 ITUT
   [Anonymous], 1998, BT13591 ITUR
   [Anonymous], 2010, 102643 ETSI TR
   Blakowski G, 1996, IEEE J SEL AREA COMM, V14, P5, DOI 10.1109/49.481691
   BOYACI O, 2009, 11 IEEE INT S MULT 2, P194
   Claesson I., 2003, International Journal of Acoustics and Vibration, V8, P159
   Hollier MP, 1999, BT TECHNOL J, V17, P35, DOI 10.1023/A:1009666623193
   Huang Z, 2013, ACM T MULTIM COMPUT, V9, P40
   *IETF RFC, 2003, 3550 IETF RFC
   Jansen J., 2013, PROCEEDING 23 ACM WO, P37, DOI [10.1145/2460782.2460789, DOI 10.1145/2460782.2460789]
   Kryczka A, 2013, IEEE INT SYM MULTIM, P271, DOI 10.1109/ISM.2013.52
   Liu Y, 2008, 10 EL PACK TECHN C, P1
   Proakis J G., 2007, DIGITAL SIGNAL PROCE
   Raake A, 2013, P INTERSPEECH 2013 L, P1549
   Radhakrishnan R, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1549, DOI 10.1109/ICME.2008.4607743
   Savage C, 1997, SIAM REV, V39, P605, DOI 10.1137/S0036144595295272
   Shen ZJ, 2011, P IEEE, V99, P2089, DOI 10.1109/JPROC.2011.2165330
   Steinmetz R, 1996, IEEE J SEL AREA COMM, V14, P61, DOI 10.1109/49.481694
   Winkler S, 2008, IEEE T BROADCAST, V54, P660, DOI 10.1109/TBC.2008.2000733
   Yamagishi K, 2005, PROC SPIE, V5666, P130, DOI 10.1117/12.586679
   You JY, 2010, SIGNAL PROCESS-IMAGE, V25, P482, DOI 10.1016/j.image.2010.02.002
   Zhou L, 2011, IEEE J SEL AREA COMM, V29, P1358, DOI 10.1109/JSAC.2011.110803
   Zhou L, 2010, IEEE INTELL SYST, V25, P40, DOI 10.1109/MIS.2010.48
NR 27
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 1
BP 527
EP 545
DI 10.1007/s11042-014-2306-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5QB
UT WOS:000367856500024
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Dubey, SR
   Singh, SK
   Singh, RK
AF Dubey, Shiv Ram
   Singh, Satish Kumar
   Singh, Rajat Kumar
TI A multi-channel based illumination compensation mechanism for brightness
   invariant image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature description; Complex illumination; Image retrieval; Brightness
   compensation
ID FACE RECOGNITION; NORMALIZATION
AB The image retrieval is still challenging to retrieve the most similar images of a given image from a huge database more accurately and robustly. It becomes more challenging for the images having drastic illumination differences. Most of feature descriptor having better retrieval performance degrades in the case of illumination change. To circumvent this problem, we compensated the varying illumination in the image using multi-channel information. We used Red, Green, Blue channel of RGB color space and Intensity channel of HSI color space to remove the intensity change in the image. Finally, we designed an illumination compensated color space to compute the feature descriptor over it. The proposed idea is generic and can be implemented with the most of the feature descriptor. We used some state-of-the-art feature descriptor to show the effectiveness and robustness of proposed color transformation towards uniform and non-uniform illumination change. The experimental results suggest that proposed brightness invariant color transformation can be applied effectively in the retrieval task.
C1 [Dubey, Shiv Ram; Singh, Satish Kumar; Singh, Rajat Kumar] Indian Inst Informat Technol Allahabad, Allahabad, Uttar Pradesh, India.
C3 Indian Institute of Information Technology Allahabad
RP Dubey, SR (corresponding author), Indian Inst Informat Technol Allahabad, Allahabad, Uttar Pradesh, India.
EM shivram1987@gmail.com; sk.singh@iiita.ac.in; rajatsingh@iiita.ac.in
RI Dubey, Shiv Ram/T-7541-2019; singh, satish/U-7158-2018; Singh, Dr Satish
   Kumar/JMP-6186-2023
OI Dubey, Shiv Ram/0000-0002-4532-8996; singh, satish/0000-0002-8536-4991;
   Singh, Dr Satish Kumar/0000-0003-1991-7727
CR Andreou I, 2007, MULTIMED TOOLS APPL, V32, P275, DOI 10.1007/s11042-006-0053-z
   [Anonymous], P 4 ACM INT C MULT C
   [Anonymous], 2013, 2013 10th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], MULTIMED TOOLS APPL
   Hernández-Gracidas CA, 2013, MULTIMED TOOLS APPL, V62, P479, DOI 10.1007/s11042-011-0911-1
   Chen H, 2013, MODERN SOLID STATE F, P1, DOI DOI 10.1109/ICME.2013.6607524
   Chen WL, 2006, IEEE T SYST MAN CY B, V36, P458, DOI 10.1109/TSMCB.2005.857353
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Daoudi I, 2014, MULTIMED TOOLS APPL, P1
   Dubey SR, 2012, 2012 THIRD INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION TECHNOLOGY (ICCCT), P346, DOI 10.1109/ICCCT.2012.76
   Gevrekci M, 2009, COMPUT VIS IMAGE UND, V113, P565, DOI 10.1016/j.cviu.2008.11.006
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Gupta R, 2008, LECT NOTES COMPUT SC, V5303, P265, DOI 10.1007/978-3-540-88688-4_20
   Gupta R, 2010, PROC CVPR IEEE, P334, DOI 10.1109/CVPR.2010.5540195
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Hu RX, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2013.2286330
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Moreno-Noguer F, 2011, PROC CVPR IEEE, P1593, DOI 10.1109/CVPR.2011.5995529
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ranganathan A, 2013, IEEE INT CONF ROBOT, P3791, DOI 10.1109/ICRA.2013.6631110
   Ruiz-Del-Solar J, 2005, IEEE T SYST MAN CY C, V35, P315, DOI 10.1109/TSMCC.2005.848201
   Ruiz-Del-Solar J, 2008, PATTERN RECOGN LETT, V29, P1966, DOI 10.1016/j.patrec.2008.06.015
   Saavedra J. M., 2013, MULTIMED TOOLS APPL, P1
   Saipullah KM, 2012, MULTIMED TOOLS APPL, V59, P717, DOI 10.1007/s11042-011-0766-5
   Shahabi C, 2007, MULTIMED TOOLS APPL, V32, P29, DOI 10.1007/s11042-006-0070-y
   Shamsi A, 2013, MULTIMED TOOLS APPL, P1
   Shi ZP, 2012, MULTIMED TOOLS APPL, V61, P263, DOI 10.1007/s11042-011-0836-8
   Singh Nishant, 2012, 2012 International Conference on Computing Sciences (ICCS), P116, DOI 10.1109/ICCS.2012.64
   Stehling R. O., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P102, DOI 10.1145/584792.584812
   Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tang F, 2009, PROC CVPR IEEE, P2623
   Tang JH, 2012, MULTIMED TOOLS APPL, V56, P1, DOI 10.1007/s11042-011-0822-1
   Vacha P., 2007, CIVR 07 P 6 ACM INT, P448, DOI [DOI 10.1145/1282280.1282346, 10.1145/1282280, DOI 10.1145/1282280]
   Wang HT, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P819
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Wang X., 2012, MATER RES LETT, P1, DOI [DOI 10.1007/S11046-011-9484-9, 10.1155/2012/460430, DOI 10.1155/2012/460430]
   Wang XY, 2010, MULTIMED TOOLS APPL, V49, P323, DOI 10.1007/s11042-009-0362-0
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Wang ZH, 2011, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2011.6126294
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
   Wu J, 2013, PATTERN RECOGN, V46, P2927, DOI 10.1016/j.patcog.2013.04.008
NR 44
TC 16
Z9 16
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11223
EP 11253
DI 10.1007/s11042-014-2226-5
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600013
DA 2024-07-18
ER

PT J
AU Huang, SY
   Kuo, KP
   Lin, YH
AF Huang, Shih-Yu
   Kuo, Kuei-Pin
   Lin, Yi-Hsuan
TI A golf swing analysis system using Wii balance board and kinect sensors
   for novice players
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Golf swing; posture movement; gravity movement; Kinect; Wii balance
   board
ID KINEMATICS; PRO
AB Golf is well known worldwide as a prestigious and enjoyable sport. However, access to golf has been limited by high training costs, such as coaching fees, equipment, and course/driving range fees. This paper proposes a cost-effective golf analysis system which is designed for novice players. This system integrates the Wii balance board the Kinect sensors to detect beginners' common swing mistakes. These sensors are combined with the algorithm proposed in this paper automatically to detect the common mistakes in posture and gravity movement when players swing. The experimental results indicate that the accuracy ratio in the detection is over 80 %. This paper provides novice golf players with a fairly priced and efficient golf swing analysis system.
C1 [Huang, Shih-Yu; Lin, Yi-Hsuan] Ming Chuan Univ, Dept Comp Sci & Informat Engn, Taoyuan 333, Taoyuan County, Taiwan.
   [Kuo, Kuei-Pin] Natl Pingtung Univ Sci & Technol, Off Phys Educ, Pingtung, Taiwan.
C3 Ming Chuan University; National Pingtung University Science & Technology
RP Huang, SY (corresponding author), Ming Chuan Univ, Dept Comp Sci & Informat Engn, 5 Ming Rd, Taoyuan 333, Taoyuan County, Taiwan.
EM syhuang@mail.mcu.edu.tw
RI liu, ting/AAA-1112-2022
FU National Science Council, Taiwan [NSC 101-2221-E130-024-MY2]
FX This research is supported in part by the National Science Council,
   Taiwan under the grant of NSC 101-2221-E130-024-MY2.
CR Blair D, 2007, UNIQUE GOLF TEACHING
   Blake A, 2008, ITI, P409, DOI 10.1109/ITI.2008.4588445
   BUDNEY DR, 1979, RES QUART, V50, P171, DOI 10.1080/10671315.1979.10615598
   Burchfield R., 2010, P 2010 INT C BOD SEN, P267, DOI [DOI 10.1109/BSN.2010.46, 10.1109/BSN.2010.46]
   DiFranco DE, 2001, PROC CVPR IEEE, P307
   Ghasemzadeh H., 2009, Environments, V1, P1
   Ghasemzadeh H, 2009, J AMB INTEL SMART EN, V1, P173, DOI 10.3233/AIS-2009-0021
   Goncalves L, 1995, ICCV 95
   Guadagnoli M, 2002, J SPORT SCI, V20, P615, DOI 10.1080/026404102320183176
   Gulgin H, 2009, J SPORT SCI MED, V8, P296
   Horan SA, 2012, SPORT BIOMECH, V11, P165, DOI 10.1080/14763141.2011.638390
   Horan SA, 2010, J BIOMECH, V43, P1456, DOI 10.1016/j.jbiomech.2010.02.005
   Howe N, 1999, NIPS 99
   Hwang J-N, 2006, IEEE ISCAS
   Karliga, 2006, IEEE ICASS
   King K, 2008, SENSOR ACTUAT A-PHYS, V141, P619, DOI 10.1016/j.sna.2007.08.028
   Lin YH, 2013, 5 FTRA INT C INF TEC
   Luo Y., 2005, IEEEICASSP
   Nesbit SM, 2005, J SPORT SCI MED, V4, P499
   RICHARDS J, 1985, RES Q EXERCISE SPORT, V56, P361, DOI 10.1080/02701367.1985.10605341
   Sappa A, 2003, IEEE ICIP
   Tinmark F, 2010, SPORT BIOMECH, V9, P236, DOI 10.1080/14763141.2010.535842
   Urtasun R, 2005, PROC CVPR IEEE, P932
   Zhang L, 2012, IMAGE SIGNAL PROCESS
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zheng N, 2008, INT J SPORTS MED, V29, P487, DOI 10.1055/s-2007-989229
   Zheng N, 2008, INT J SPORTS MED, V29, P965, DOI 10.1055/s-2008-1038732
NR 27
TC 12
Z9 14
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10679
EP 10696
DI 10.1007/s11042-014-2198-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700024
DA 2024-07-18
ER

PT J
AU Rassem, TH
   Khoo, BE
AF Rassem, Taha H.
   Khoo, Bee Ee
TI Performance evaluation of new colour histogram-based interest point
   detectors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interest point detectors; Harris-Affine; Hessian-Affine; Histogram-based
   detectors; Caltech-04; Graz-02
ID REPRESENTATION; SHAPE; SCALE; SIFT
AB Interest point detection is an active area in computer vision due to its importance in many applications. Measuring the pixel-wise difference between image pixel intensities is the mechanism of most detectors that have been proposed in literature. Recently, interest point detectors were proposed that incorporated the histogram representation instead of image pixel intensity. In this paper, research that extends histogram-based interest point detectors is introduced. Four colour-space representations were used to construct new detectors: HSV, Opponent, Transformed and Ohta colour spaces. Several experiments were performed to evaluate the new colour histogram-based detectors and compare them with previous detectors. First, the proposed detectors were evaluated in an image-matching task. Then, we studied and evaluated the performance of some of the local image descriptors that were extracted from the interest points and regions detected by the proposed detectors. Finally, the four top-ranked descriptors in the descriptor evaluation experiments were used to evaluate the new colour histogram-based detectors in an image-classification task using different object and scene image datasets. The experimental results demonstrate that our new detectors possess an increased ability to distinguish and more robust in regards to image matching, particularly with respect to textured scene images that involve transformations, such as illumination, viewpoint and blur changes. Furthermore, the descriptor performance may change depending on the detector and data set type. The image-classification results demonstrate that the proposed detectors exhibit higher classification accuracy for certain descriptors and data sets than the other detectors.
C1 [Rassem, Taha H.; Khoo, Bee Ee] Univ Sains Malaysia, Sch Elect & Elect Engn, Nibong Tebal, Penang, Malaysia.
   [Rassem, Taha H.] Univ Malaysia Pahang, Fac Comp Syst & Software Engn, Gambang 26300, Pahang, Malaysia.
C3 Universiti Sains Malaysia; Universiti Malaysia Pahang Al-Sultan Abdullah
   (UMPSA)
RP Khoo, BE (corresponding author), Univ Sains Malaysia, Sch Elect & Elect Engn, Nibong Tebal, Penang, Malaysia.
EM Tahahussein@ump.edu.my; beekhoo@usm.my
RI Silva, Isac/AAQ-4462-2021; Khoo, Bee Ee/D-8730-2011; Rassem,
   Taha/L-8250-2016
OI Khoo, Bee Ee/0000-0002-3492-2551; Rassem, Taha/0000-0001-6259-0622
CR [Anonymous], INFORM SCI REFERENCE
   [Anonymous], 2004, P BRIT MACHINE VISIO
   [Anonymous], P IEEE COMP SOC C CO
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], BRIT MACH VIS C
   [Anonymous], P INT C COMP VIS
   [Anonymous], COLOR IMAGE PROCESSI
   [Anonymous], P 9 TRECVID WORKSH
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 1995, PRENTICE HALL SIGNAL
   [Anonymous], 2006, P IEEE COMP SOC C CO
   Ashbrook AP, 1995, PROCEEDINGS OF THE 6TH BRITISH MACHINE VISION CONFERENCE 1995, VOLS 1 AND 2, P503
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Benmokhtar R., 2012, MULTIMED TOOLS APPL, P1
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Calonder Michael, 2010, Computer Vision - ECCV 2010. Proceedings 11th European Conference on Computer Vision, P778, DOI 10.1007/978-3-642-15561-1_56
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Duan XH, 2013, IEEE T MULTIMEDIA, V15, P167, DOI 10.1109/TMM.2012.2225029
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Gabor D., 1946, Journal of the Institution of Electrical Engineers-part III: radio and communication engineering, V93, P429, DOI [DOI 10.1049/JI-3-2.1946.0074, 10.1049/ji-3-2.1946.0074]
   Gijsenij A, 2012, IEEE T PATTERN ANAL, V34, P918, DOI 10.1109/TPAMI.2011.197
   Han Juan, 2013, Modular Machine Tool & Automatic Manufacturing Technique, P1
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Heinly J, 2012, LECT NOTES COMPUT SC, V7573, P759, DOI 10.1007/978-3-642-33709-3_54
   Kadir T, 2004, LECT NOTES COMPUT SC, V3021, P228
   Ke Y, 2004, PROC CVPR IEEE, P506
   Kinnunen T, 2013, LECT NOTES COMPUT SC, V7944, P85
   KOENDERINK JJ, 1987, BIOL CYBERN, V55, P367, DOI 10.1007/BF00318371
   Lazebnik S, 2003, PROC CVPR IEEE, P319
   Lee WT, 2009, PROC CVPR IEEE, P1590, DOI 10.1109/CVPRW.2009.5206521
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Lin L, 2012, PATTERN RECOGN, V45, P231, DOI 10.1016/j.patcog.2011.06.011
   Lin LA, 2010, IEEE T PATTERN ANAL, V32, P1426, DOI 10.1109/TPAMI.2009.150
   Lindeberg T, 1997, IMAGE VISION COMPUT, V15, P415, DOI 10.1016/S0262-8856(97)01144-X
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo HL, 2011, IMAGE VISION COMPUT, V29, P759, DOI 10.1016/j.imavis.2011.08.005
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Matas J., 2000, BMV2000. Proceedings of the 11th British Machine Vision Conference, P606
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561
   Miksik O, 2012, INT C PATT RECOG, P2681
   MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591
   OHTA Y, 1980, COMPUT VISION GRAPH, V13, P222, DOI 10.1016/0146-664X(80)90047-7
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2350, P414
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215
   Shen XH, 2012, IMAGE VISION COMPUT, V30, P227, DOI 10.1016/j.imavis.2011.11.003
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Tola E., 2008, P IEEE C COMPUTER VI, P1
   Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77
   Tsagaris V, 2004, P SOC PHOTO-OPT INS, V5238, P357, DOI 10.1117/12.510651
   Tuytelaars T, 1999, ICRA '99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1601, DOI 10.1109/ROBOT.1999.772588
   Tuytelaars T., 2008, LOCAL INVARIANT FEAT
   Tuytelaars T, 2010, PROC CVPR IEEE, P2281, DOI 10.1109/CVPR.2010.5539911
   van de Weijer J, 2006, IEEE T PATTERN ANAL, V28, P150, DOI 10.1109/TPAMI.2006.3
   Van Gool L., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P642, DOI 10.1007/BFb0015574
   Zhang W, 2009, THESIS
NR 63
TC 2
Z9 2
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11357
EP 11398
DI 10.1007/s11042-014-2235-4
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600018
DA 2024-07-18
ER

PT J
AU Wang, H
   Liu, XB
   Wu, XX
   Jia, YD
AF Wang, Han
   Liu, Xiabi
   Wu, Xinxiao
   Jia, Yunde
TI Cross-domain structural model for video event annotation via web images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video annotation; Knowledge transfer; Video analysis
AB Annotating events in uncontrolled videos is a challenging task. Most of the previous work focuses on obtaining concepts from numerous labeled videos. But it is extremely time consuming and labor expensive to collect a large amount of required labeled videos for modeling events under various circumstances. In this paper, we try to learn models for video event annotation by leveraging abundant Web images which contains a rich source of information with many events taken under various conditions and roughly annotated as well. Our method is based on a new discriminative structural model called Cross-Domain Structural Model (CDSM) to transfer knowledge from Web images (source domain) to consumer videos (target domain), by jointly modeling the interaction between videos and images. Specifically, under this framework we build a common feature subspace to deal with the feature distribution mismatching between the video domain and the image domain. Further, we propose to use weak semantic attributes to describe events, which can be obtained with no or little labor. Experimental results on challenging video datasets demonstrate the effectiveness of our transfer learning method.
C1 [Wang, Han; Liu, Xiabi; Wu, Xinxiao; Jia, Yunde] Beijing Inst Technol, Sch Comp Sci, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.
C3 Beijing Institute of Technology
RP Liu, XB (corresponding author), Beijing Inst Technol, Sch Comp Sci, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.
EM wanghan@bit.edu.cn; liuxiabi@bit.edu.cn; wuxinxiao@bit.edu.cn;
   jiayunde@bit.edu.cn
FU National Natural Science Foundation of China [60973059, 81171407];
   Program for New Century Excellent Talents in University of China
   [NCET-10-0044]
FX This work was partially supported by National Natural Science Foundation
   of China (Grant no. 60973059, 81171407) and Program for New Century
   Excellent Talents in University of China (Grant no. NCET-10-0044).
CR [Anonymous], 2011, P 1 INT C MULT RETR
   [Anonymous], 2012, 20 ACM INT C MULT
   [Anonymous], 2012, P 20 ACM INT C MULTI
   [Anonymous], 2009, Applications of Computer Vision (WACV), 2009 Workshop on
   [Anonymous], P CVPR
   Bel N, 2003, LECT NOTES COMPUT SC, V2769, P126
   Berg TL, 2010, LECT NOTES COMPUT SC, V6311, P663, DOI 10.1007/978-3-642-15549-9_48
   Borth D, 2012, P 20 ACM INT C MULT, P977
   Bruzzone L, 2010, IEEE T PATTERN ANAL, V32, P770, DOI 10.1109/TPAMI.2009.57
   Cao LL, 2010, PROC CVPR IEEE, P1998, DOI 10.1109/CVPR.2010.5539875
   Do Trinh-Minh-Tri., 2009, ICML '09 Proceedings of the 26th Annual International Conference on Machine Learning, P265
   Duan LX, 2010, PROC CVPR IEEE, P1959, DOI 10.1109/CVPR.2010.5539870
   Ferrari V., 2007, P 20 INT C NEUR INF, P433
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hwang SJ, 2010, P BRIT MACH VIS C BM
   Ikizler-Cinbis N, 2009, IEEE I CONF COMP VIS, P995, DOI 10.1109/ICCV.2009.5459368
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Parikh D, 2011, PROC CVPR IEEE, P1681, DOI 10.1109/CVPR.2011.5995451
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Siddiquie B, 2011, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.2011.5995329
   Torresani L, 2010, LECT NOTES COMPUT SC, V6311, P776, DOI 10.1007/978-3-642-15549-9_56
   Wang H, 2012, INT C PATT RECOG, P2801
   Wu X, 2012, ECCV, P995
NR 24
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10439
EP 10456
DI 10.1007/s11042-014-2175-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700013
DA 2024-07-18
ER

PT J
AU Chuang, TY
   Liu, EZF
   Shiu, WY
AF Chuang, Tsung-Yen
   Liu, Eric Zhi-Feng
   Shiu, Wen-Ya
TI Game-based creativity assessment system: the application of fuzzy theory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Creativity; Assessment of creativity; Game-based learning; Computerized
   assessment system; Fuzzy theory
ID INNOVATION; EDUCATION; STUDENTS; SETS
AB "Creative development" and "creativity" have become important topics in the field of education research. The assessment of creativity is a key to understanding how instructional strategies influences the creative process and the output of learners. At present, most methods of assessing creativity are paper-and-pencil tests scored by individuals. Despite the professional training of evaluators, subjectivity in scoring assessments remains inevitable. Therefore, a completely objective tool of measurement is crucial for the progress of education to eliminate the subjectivity in manual grading. This paper presents at first place a review of the literature related to the development of creativity, the assessment of creativity, and further on the means of measuring creativity, particularly in a digital game environment. Our focus is on the application of computing technologies for the assessment of creativity, while exploring the possibility of using computerized systems such as fuzzy logic and hybrid methods to produce objective measurement results. The results of Pearson correlation coefficient between the fuzzy inference scores and the Williams CAP scores is 0.805, which shows the strong construct validity. Additionally, the fuzzy inference system can eliminate subjectivity in scoring and provide analysis results to enhance creativity, unlike paper-and-pencil scores provided without explanations.
C1 [Chuang, Tsung-Yen; Shiu, Wen-Ya] Natl Univ Tainan, Dept Informat & Learning Technol, Tainan 700, Taiwan.
   [Liu, Eric Zhi-Feng] Natl Cent Univ, Grad Inst Learning & Instruct, Jhongli City 32001, Taoyuan County, Peoples R China.
C3 National University Tainan
RP Chuang, TY (corresponding author), Natl Univ Tainan, Dept Informat & Learning Technol, 33,Sec 2,Shu Lin St, Tainan 700, Taiwan.
EM chuangyen@mail.nutn.edu.tw
RI Chuang, Tsung-Yen/G-4171-2010; Liu, Eric Zhi Feng/I-5504-2013
FU National Science Council of Taiwan [NSC 98-2511-S-024-004-MY3, NSC
   99-2511-S-024-003-MY3, NSC 102-2511-S-024-006]
FX The research reported in this paper has been supported in part by the
   National Science Council of Taiwan under the research project number NSC
   98-2511-S-024-004-MY3, NSC 99-2511-S-024-003-MY3, and NSC
   102-2511-S-024-006.
CR Alessi S.M., 1991, COMPUTER BASED INSTR, V2nd
   [Anonymous], CREATIVITY RES
   [Anonymous], HDB MANAGEMENT LEARN
   [Anonymous], 2000, COMPUTERIZED ADAPTIV, DOI DOI 10.4324/9781410605931
   Basadur M, 1996, CREATIVITY RES J, V9, P21, DOI 10.1207/s15326934crj0901_3
   Besemer S.P., 1987, Frontiers of creativity research: Beyond the basics, P367
   Brown D. C., 2008, P NSF INT WORKSH STU
   Burstein J, 2003, AUTOMATED ESSAY SCORING: A CROSS-DISCIPLINARY PERSPECTIVE, P113
   Children's Welfare League Foundation, 2009, 2009 CHILDR ONL GAM
   Chou WZ, 1998, P 7 INT C COMP ASS I, P543
   Chuang TY, 2009, EDUC TECHNOL SOC, V12, P1
   Colangelo N., 1992, CREATIVITY RES J, V5, P157, DOI [10.1080/10400419209534429, DOI 10.1080/10400419209534429]
   David MW, 2004, APPL MEAS EDUC, V17, P323
   Dempsey J. V., 2002, Simulation & Gaming, V33, P157, DOI 10.1177/1046878102332003
   DOMINO G, 1994, CREATIVITY RES J, V7, P21, DOI 10.1080/10400419409534506
   Ellis S, 2009, LITERACY, V43, P3, DOI 10.1111/j.1741-4369.2009.00509.x
   Guildford J. P., 1967, NATURE HUMAN INTELLI
   Ho RG, 1997, TEST COUNS, V144, P2972
   Hocevar D., 1989, HDB CREATIVITY, P53, DOI DOI 10.1007/978-1-4757-5356-1_3
   Hong JC, 2012, TURK ONLINE J EDUC T, V11, P255
   Hung PH, 2012, TURK ONLINE J EDUC T, V11, P10
   Kazancoglu Y, 2011, TURK ONLINE J EDUC T, V10, P39
   Ke FF, 2008, COMPUT EDUC, V51, P1609, DOI 10.1016/j.compedu.2008.03.003
   Kirschenbaum R.J., 1989, Understanding the Creative Activity of Students: Including an Instruction Manual for the Creative Behavior Inventory
   Ko S., 2002, Educational Psychology, V22, P219
   Kumar VK, 1997, CREATIVITY RES J, V10, P51, DOI 10.1207/s15326934crj1001_6
   Lau S, 2010, THINK SKILLS CREAT, V5, P101, DOI 10.1016/j.tsc.2010.09.004
   Lee CS, 2010, IEEE T FUZZY SYST, V18, P374, DOI 10.1109/TFUZZ.2010.2042454
   Li LS, 2000, THESIS NATL KAOHSIUN
   Lin YJ, 2001, THESIS NATL TAICHUNG
   Liu EZF, 2012, TURK ONLINE J EDUC T, V11, P172
   Ludwig ArnoldM., 1992, CREATIVITY RES J, V5, P109, DOI DOI 10.1080/10400419209534427
   REIS SM, 1991, GIFTED CHILD QUART, V35, P128, DOI 10.1177/001698629103500304
   Rong GH, 1997, TEST GUID J, V144, P2972
   Sawyer RK, 2006, THINK SKILLS CREAT, V1, P41, DOI 10.1016/j.tsc.2005.08.001
   Segal M, 1998, YOUR CHILD PLAY CONV
   STERNBERG RJ, 1986, EDUC PSYCHOL, V21, P175, DOI 10.1207/s15326985ep2103_2
   STERNBERG RJ, 1999, CONCEPT CREATIVITY P
   Sternberg RJ, 2012, CREATIVITY RES J, V24, P3, DOI 10.1080/10400419.2012.652925
   Sun GT, 1998, P ICCAI 98 NAT KAOHS, P543
   Tayal DK, 2014, APPL INTELL, V40, P54, DOI 10.1007/s10489-013-0445-5
   Teresa AW, 2006, PSYCHOL ASSESSMENT, V18, P100
   Torrance E. P., 1966, TORRANCE TESTS CREAT
   Wagner C, 2010, IEEE T FUZZY SYST, V18, P637, DOI 10.1109/TFUZZ.2010.2045386
   Wang, 1994, CREATIVITY ASSESSMEN
   Wang BY, 1995, CURRENT ASSESSMENT T
   Williams F.E., 1980, CREATIVITY ASSESSMEN
   Williams WendyM., 1999, HDB CREATIVITY
   Wu JJ, 1999, CHINESE VERSION DIVE
   Yang JC, 2012, TURK ONLINE J EDUC T, V11, P27
   Yeh YC, 2006, CREATIVE TEACHING NO
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
NR 52
TC 5
Z9 7
U1 3
U2 75
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9141
EP 9155
DI 10.1007/s11042-014-2070-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200003
DA 2024-07-18
ER

PT J
AU Gonzalez, I
   Cartella, F
   Enescu, V
   Sahli, H
AF Gonzalez, Isabel
   Cartella, Francesco
   Enescu, Valentin
   Sahli, Hichem
TI Recognition of facial actions and their temporal segments based on
   duration models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial action units (AUs); Hidden semi-Markov models (HSMMs); Variable
   duration semi-Markov model (VDHMM)
ID FORWARD-BACKWARD ALGORITHM; SHAPE
AB Being able to automatically analyze finegrained changes in facial expression into action units (AUs), of the Facial Action Coding System (FACS), and their temporal models (i.e., sequences of temporal phases, neutral, onset, apex, and offset), in face videos would greatly benefit for facial expression recognition systems. Previous works, considered combining, per AU, a discriminative frame-based Support Vector Machine (SVM) and a dynamic generative Hidden Markov Models (HMM), to detect the presence of the AU in question and its temporal segments in an input image sequence. The major drawback of HMMs, is that they do not model well time dependent dynamics as the ones of AUs, especially when dealing with spontaneous expressions. To alleviate this problem, in this paper, we exploit efficient duration modeling of the temporal behavior of AUs, and we propose hidden semi-Markov model (HSMM) and variable duration semi-Markov model (VDHMM) to recognize the dynamics of AU's. Such models allow the parameterization and inference of the AU's state duration distributions. Within our system, geometrical and appearance based measurements, as well as their first derivatives, modeling both the dynamics and the appearance of AUs, are applied to pair-wise SVM classifiers for a frame-based classification. The output of which are then fed as evidence to the HSMM or VDHMM for inferring AUs temporal phases. A thorough investigation into the aspect of duration modeling and its application to AU recognition through extensive comparison to state-of-art SVM-HMM approaches are presented. For comparison, an average recognition rate of 64.83 % and 64.66 % is achieved for the HSMM and VDHMM respectively. Our framework has several benefits: (1) it models the AU's temporal phases duration; (2) it does not require any assumption about the underlying structure of the AU events, and (3) compared to HMM, the proposed HSMM and VDHMM duration models reduce the duration error of the temporal phases of an AU, and they are especially better in recognizing the offset ending of an AU.
C1 [Gonzalez, Isabel; Cartella, Francesco; Enescu, Valentin; Sahli, Hichem] Vrije Univ Brussel, Dept Elect & Informat, VUB NPU Joint AVSP Lab, B-1050 Brussels, Belgium.
   [Sahli, Hichem] Interuniv Microelect Ctr IMEC, Leuven, Belgium.
C3 Vrije Universiteit Brussel; IMEC
RP Gonzalez, I (corresponding author), Vrije Univ Brussel, Dept Elect & Informat, VUB NPU Joint AVSP Lab, B-1050 Brussels, Belgium.
EM igonzale@etro.vub.ac.be; fcartell@etro.vub.ac.be; hsahli@vub.ac.be
RI Gonzalez, Isabel/ABH-9489-2020
OI Sahli, Hichem/0000-0002-1774-2970
FU EU FP7 project ALIZ-E [248116]; VUB-IRP EmoApp project [VUB-IRP5]
FX The research reported in this paper has been partly supported by the EU
   FP7 project ALIZ-E (grant 248116), and the VUB-IRP EmoApp project (grant
   VUB-IRP5).
CR [Anonymous], 1999, The Nature Statist. Learn. Theory
   [Anonymous], 2010, PROC 3 INT WORKSHOP
   Asteriadis S, 2014, INT J COMPUT VISION, V107, P293, DOI 10.1007/s11263-013-0691-3
   Bartlett M.S., 2002, Advances in Neural Information Processing Systems, P1271
   Bartlett MS, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P223, DOI 10.1109/fgr.2006.55
   Bartlett MS, 2004, IEEE SYS MAN CYBERN, P592
   Bartlett MS, 1996, ADV NEUR IN, V8, P823
   Caridakis G, 2010, J MULTIMODAL USER IN, V3, P49, DOI [10.1007/s12193-009-0030, 10.1007/s12193-009-0030-8]
   Chuang CF, 2006, PATTERN RECOGN, V39, P1795, DOI 10.1016/j.patcog.2006.03.017
   Cohn JF, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P129, DOI 10.1109/AFGR.2004.1301520
   Cohn JF, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P396, DOI 10.1109/AFGR.1998.670981
   Cohn JF, 1999, PSYCHOPHYSIOLOGY, V36, P35, DOI 10.1017/S0048577299971184
   Ekman P., 2002, FACIAL ACTION CODING
   Ekman P., 2003, UNMASKING FACE GUIDE
   EL KALIOUBY R., 2005, MIND READING MACHINE
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Gonzalez I, 2011, LECT NOTES COMPUT SC, V6974, P548, DOI 10.1007/978-3-642-24600-5_58
   Hou Y, 2007, LECT NOTES COMPUT SC, V4678, P340
   Koelstra S., 2008, P IEEE INT C AUT FAC, P1
   Kovesi P.D., 1999, Videre: Journal of Computer Vision Research, V1
   Lien JJJ, 1999, J ROBOT AUTON SYST
   Mahoor Mohammad H., 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P74, DOI 10.1109/CVPR.2009.5204259
   Messinger DS, 2001, DEV PSYCHOL, V37, P642, DOI 10.1037/0012-1649.37.5.642
   Murphy K. P., 2002, Ph.D. Thesis,
   Ogbureke U., 2012, 2012 11th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA), P700, DOI 10.1109/ISSPA.2012.6310643
   Platt J., 1999, Advances in Large Margin Classifiers, P61
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Reilly Jane, 2008, Affective Computing. Focus on Emotion Expression, Synthesis and Recognition, P107
   Shi Qinfeng., 2008, COMPUTER VISION PATT, P1, DOI DOI 10.1109/CVPR.2008.4587557
   Tian YL, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P229, DOI 10.1109/AFGR.2002.1004159
   Tong Y, 2010, IEEE T PATTERN ANAL, V32, P258, DOI 10.1109/TPAMI.2008.293
   Ulukaya S, 2014, DIGIT SIGNAL PROCESS, V32, P11, DOI 10.1016/j.dsp.2014.05.013
   Valstar M., 2006, COMP VIS PATT REC WO, P149
   Valstar MF, 2012, IEEE T SYST MAN CY B, V42, P28, DOI 10.1109/TSMCB.2011.2163710
   Xianglong Liu, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P81, DOI 10.1109/ICPR.2010.28
   Yu SZ, 2010, ARTIF INTELL, V174, P215, DOI 10.1016/j.artint.2009.11.011
   Yu SZ, 2006, IEEE T SIGNAL PROCES, V54, P1947, DOI 10.1109/TSP.2006.872540
   Yu SZ, 2003, IEEE SIGNAL PROC LET, V10, P11, DOI 10.1109/LSP.2002.806705
   Zhang YM, 2005, IEEE T PATTERN ANAL, V27, P699, DOI 10.1109/TPAMI.2005.93
   Zor C, 2009, LECT NOTES COMPUT SC, V5558, P239, DOI 10.1007/978-3-642-01793-3_25
NR 42
TC 4
Z9 6
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 22
BP 10001
EP 10024
DI 10.1007/s11042-014-2320-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV1LQ
UT WOS:000364019400010
DA 2024-07-18
ER

PT J
AU Wu, DC
   Chen, MY
AF Wu, Da-Chun
   Chen, Ming-Yao
TI Reversible data hiding in Standard MIDI Files by adjusting delta time
   values
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Standard MIDI File; MIDI; Delta time;
   Steganography
ID STEGANOGRAPHY
AB In this paper, an effective method of hiding information in Standard MIDI Files (SMF) is presented. The method simultaneously shifts the binary representations of both the division value and non-zero delta time values in a MIDI file left in order to hide information, and embeds secret information in the bits of the non-zero delta time values produced by the left shifting. The number of left shift bits is in accordance with both the tolerance of beat-changing and the size of the secret information to be embedded. Experimental results show that the proposed method is not only able to embed secret information in Standard MIDI Files without influencing their playing quality, but is also able to recover the original MIDI files without distortion after the hidden data have been extracted.
C1 [Wu, Da-Chun] Natl Kaohsiung First Univ Sci & Technol, Dept Comp & Commun Engn, Kaohsiung 824, Taiwan.
   [Chen, Ming-Yao] Natl Kaohsiung First Univ Sci & Technol, Inst Engn Sci & Technol, Kaohsiung 824, Taiwan.
C3 National Kaohsiung University of Science & Technology; National
   Kaohsiung University of Science & Technology
RP Wu, DC (corresponding author), Natl Kaohsiung First Univ Sci & Technol, Dept Comp & Commun Engn, 1 Univ Rd, Kaohsiung 824, Taiwan.
EM dcwu@nkfust.edu.tw; u9315923@nkfust.edu.tw
FU National Science Council [100-2221-E-327-029]
FX This work was supported partially by National Science Council, R. O. C.
   under Grant No. 100-2221-E-327-029.
CR Adli A, 2005, Proceedings of 2005 International Conference on Machine Learning and Cybernetics, Vols 1-9, P2401
   Adli A, 2008, LECT NOTES ARTIF INT, V5178, P133, DOI 10.1007/978-3-540-85565-1_17
   Association MM, 1996, COMPL MIDI 1 0 DET S
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Dittmann J, 2000, FRAMEWORK SECURE MID, P51
   Drinkard T, 2002, MIDI MUSIC
   Fallahpour M, 2011, IET IMAGE PROCESS, V5, P190, DOI 10.1049/iet-ipr.2009.0226
   Fang Ma, 2012, 2012 International Conference on Computer Science and Service System (CSSS), P397, DOI 10.1109/CSSS.2012.106
   Guerin R, 2005, MIDI POWER COMPREHEN
   Hu Y, 2006, IEEE T CIRC SYST VID, V16, P1423, DOI 10.1109/TCSVT.2006.884011
   Huber DM, 2007, MIDI MANUAL PRACTICA
   Inoue D, 2003, IEICE T FUND ELECTR, VE86A, P2099
   Inoue D, 2002, P SOC PHOTO-OPT INS, V4675, P194, DOI 10.1117/12.465276
   John C, 2004, STEGANOGRAPHY 5 HIDI
   Lee I-Shi, 2008, INT J APPL SCI ENG, V2, P141, DOI DOI 10.17706/IJCEE.2014.V6.857
   Lee SJ, 2001, ISIE 2001: IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS PROCEEDINGS, VOLS I-III, P272, DOI 10.1109/ISIE.2001.931796
   Malcolm JW, 2004, US Patent, Patent No. [6,798,885, 6798885]
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Noda H, 2006, PATTERN RECOGN LETT, V27, P455, DOI 10.1016/j.patrec.2005.09.008
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Thanikaiselvan V, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING APPLICATIONS (IEEE ICSIPA 2013), P337, DOI 10.1109/ICSIPA.2013.6708029
   Tsung-Yuan Liu, 2007, IEEE Transactions on Information Forensics and Security, V2, P24, DOI 10.1109/TIFS.2006.890310
   Wang RZ, 2006, IEEE SIGNAL PROC LET, V13, P161, DOI 10.1109/LSP.2005.862603
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wiedemer M, 2008, US Patent, Patent No. [7,402,744, 7402744]
   Wong PHW, 2003, IEEE T CIRC SYST VID, V13, P813, DOI 10.1109/TCSVT.2003.815948
   Xu CS, 2001, FIRST INTERNATIONAL CONFERENCE ON WEB DELIVERING OF MUSIC, PROCEEDINGS, P43, DOI 10.1109/WDM.2001.990157
   Yamamoto K, 2009, YOUNGN KYUSH JOINT C
   Yamamoto K, 2009, 2009 INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY, AND SECURITY (ARES), VOLS 1 AND 2, P774, DOI 10.1109/ARES.2009.18
   Yang Y, 2009, IEEE T CIRC SYST VID, V19, P656, DOI 10.1109/TCSVT.2009.2017401
NR 30
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9827
EP 9844
DI 10.1007/s11042-014-2157-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200035
DA 2024-07-18
ER

PT J
AU Han, JS
   Chung, KY
   Kim, GJ
AF Han, Jung-Soo
   Chung, Kyung-Yong
   Kim, Gui-Jung
TI Policy on literature content based on software as service
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Software as a service; Literature content; Integration management;
   Metadata encoding and transmission specification; Metadata object
   description schema
AB Applications based on the software as a service (SaaS) platform that integrate the content of libraries across the country for personal and enterprise users are needed in the future. SaaS-based literature content integration has not yet been done in Korea. Therefore, this paper presents a SaaS application that integrates and manages the content of public organizations or libraries. This paper outlines a SaaS method and content framework for a literature content service that utilizes the metadata encoding and transmission specification and the metadata object description schema as the standard formats.
C1 [Han, Jung-Soo] Baekseok Univ, Informat & Commun Div, Cheonan, Chungnam, South Korea.
   [Chung, Kyung-Yong] Sangji Univ, Sch Comp Informat Engn, Wonju 220702, Gangwon Do, South Korea.
   [Kim, Gui-Jung] Konyang Univ, Dept Biomed Engn, Nonsan, Chungnam, South Korea.
C3 Baekseok University; Sangji University; Konyang University
RP Han, JS (corresponding author), Baekseok Univ, Informat & Commun Div, Cheonan, Chungnam, South Korea.
EM jshan@bu.ac.kr; dragonhci@hanmail.net; gjkim@konyang.ac.kr
RI Chung, Kyungyong/JAC-2276-2023
CR Baek SJ, 2013, WIRELESS PERS COMMUN, V73, P309, DOI 10.1007/s11277-013-1239-0
   Chen X, 2008, SAAS EVALUATION MODE
   Chung KY, 2014, MULTIMED TOOLS APPL, V71, P843, DOI 10.1007/s11042-013-1355-6
   Chung KY, 2014, PERS UBIQUIT COMPUT, V18, P489, DOI 10.1007/s00779-013-0682-y
   IT Essay, 2008, SAAS SOFTW SERV
   Jung YG, 2011, INFORMATION-TOKYO, V14, P3791
   Kim GH, 2015, MULTIMED TOOLS APPL, V74, P8745, DOI 10.1007/s11042-013-1536-3
   Kim H, 2009, ENERGY HARVESTING TECHNOLOGIES, P3, DOI 10.1007/978-0-387-76464-1_1
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P873, DOI 10.1007/s11042-011-0919-6
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P855, DOI 10.1007/s11042-011-0920-0
   Kim SH, 2014, MULTIMED TOOLS APPL, V68, P455, DOI 10.1007/s11042-013-1356-5
   Kim YM, 2008, 2008 SAAS KOR FOR SE
   Lee KD, 2013, MULTIMED TOOLS APPL, V63, P27, DOI 10.1007/s11042-012-1020-5
   NIPA, 2009, SAAS MARK TECHN TREN
   Oh SY, 2014, CLUSTER COMPUT, V17, P893, DOI 10.1007/s10586-013-0284-5
   Phifer G, 2006, ANN REPORT
   Song CW, 2014, MULTIMED TOOLS APPL, V71, P813, DOI 10.1007/s11042-013-1362-7
   Song C, 2011, INFORMATION-TOKYO, V14, P3591
   Vallis H, 2008, INFORM WEEK ANAL
NR 19
TC 17
Z9 17
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 20
BP 9087
EP 9096
DI 10.1007/s11042-013-1664-9
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CR6XU
UT WOS:000361492600028
DA 2024-07-18
ER

PT J
AU Han, SC
   Mirowski, L
   Kang, BH
AF Han, Soyeon Caren
   Mirowski, Luke
   Kang, Byeong Ho
TI Exploring a role for MCRDR in enhancing telehealth diagnostics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE eHealth; uHealth; Medical expert systems; MCRDR; Telehealth
ID EXPERT-SYSTEM; SMOKING; POPULATION; SUPPORT; CANCER
AB In-home telehealth devices are becoming increasingly popular when it comes to supporting the health management of home-based patients. With the devices capable of highly active monitoring, using sensors which produce large amounts of data, the deployment of telehealth devices into the home highlights the need for improved ways to collate, classify and dynamically interpret data safely and effectively. For clinicians working at a distance, the amounts of data generated by all in-home patient telematics devices poses questions on how best to intelligently filter, analyze and interpret this data to make diagnoses and respond to changes in patient conditions. In order to manage this issue, expert systems, applied for decades in other health fields, might play a role. In this paper, we explore how one type of expert system, Multiple Classification Ripple Down Rules (MCRDR), might address the issues. This paper begins by reviewing the capabilities of expert systems. Specifically, MCRDR is reviewed and its integration with an example telehealth device, MediStation, is explored. The range of potential benefits which might accrue when MCRDR and the MediStation are linked is identified as are some research and development challenges. Moving forwards, a simple simulator is introduced as one approach which is shown to be effective at exploring this exciting area of research. This paper takes the first steps towards introducing expert systems into the uHealth field and presents a simulator for this purpose.
C1 [Han, Soyeon Caren; Mirowski, Luke; Kang, Byeong Ho] Univ Tasmania, Sch Comp & Informat Syst, Hobart, Tas, Australia.
C3 University of Tasmania
RP Han, SC (corresponding author), Univ Tasmania, Sch Comp & Informat Syst, Hobart, Tas, Australia.
EM Soyeon.Han@utas.edu.au; Luke.Mirowski@utas.edu.au;
   Byeong.Kang@utas.edu.au
RI Kang, Byeong Ho/J-7907-2014; Mirowski, Luke/H-1102-2013
OI Kang, Byeong Ho/0000-0003-3476-8838; han, soyeonh/0000-0002-1948-6819;
   Mirowski, Luke/0000-0002-1847-3848
FU Korea Small and Medium Business Administration
FX This projectwas funded by Korea Small and Medium Business
   Administration.
CR Bindoff I, 2007, LECT NOTES COMPUT SC, V4830, P519
   Bindoff I, 2006, LECT NOTES COMPUT SC, V4303, P120
   Cagalaban G, 2011, IJSEIA, V5, P63
   Caytiles RD, 2012, INT J BIOSCIENCE BIO, V4, P77
   Compton P, 2006, KNOWL-BASED SYST, V19, P356, DOI 10.1016/j.knosys.2005.11.022
   Compton P., 1990, Knowledge Acquisition, V2, P241, DOI 10.1016/S1042-8143(05)80017-2
   Compton P., 1989, APPL EXPERT SYSTEMS, P366
   EDWARDS G, 1993, PATHOLOGY, V25, P27, DOI 10.3109/00313029309068898
   Han SC, 2013, COMPUTING, P1
   Han SC, 2013, P INT C UCMA SIA CCS, P67
   KANG B, 1995, 9 AAAI SPONS BANFF K
   Kim YS, 2004, ITCC 2004: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 1, PROCEEDINGS, P476
   LEDLEY RS, 1959, SCIENCE, V130, P9, DOI 10.1126/science.130.3366.9
   Lee JJ, 2008, INT J FUTUR GENER CO, V1, P83
   Liao SH, 2005, EXPERT SYST APPL, V28, P93, DOI 10.1016/j.eswa.2004.08.003
   Ling T, 2008, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS, P174, DOI 10.1109/ITNG.2008.194
   Linner T, 2011, ADV TECHNOL SOC CH, P31, DOI 10.1007/978-3-642-18167-2_3
   Marien M, 2002, FUTURES, V34, P261, DOI 10.1016/S0016-3287(01)00043-X
   Miranda-Mena TG, 2006, EXPERT SYST APPL, V31, P451, DOI 10.1016/j.eswa.2005.09.076
   Prochaska JO, 2005, PREV MED, V41, P406, DOI 10.1016/j.ypmed.2004.09.050
   Prochaska JO, 2004, HEALTH PSYCHOL, V23, P503, DOI 10.1037/0278-6133.23.5.503
   SHORTLIFFE EH, 1979, P IEEE, V67, P1207, DOI 10.1109/PROC.1979.11436
   Tolentino RS, 2010, IJAST, V18, P1
   Vazey M, 2005, P ART INT APPL
   VELICER WF, 1993, ADDICT BEHAV, V18, P269, DOI 10.1016/0306-4603(93)90029-9
NR 25
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 19
BP 8467
EP 8481
DI 10.1007/s11042-013-1613-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4HE
UT WOS:000360564600014
DA 2024-07-18
ER

PT J
AU Kim, J
   Jeong, DH
   Lee, D
   Jung, H
AF Kim, Jinhyung
   Jeong, Do-Heon
   Lee, DongHwi
   Jung, Hanmin
TI User-centered innovative technology analysis and prediction application
   in mobile environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Business intelligence; Technology intelligence; Technology analysis;
   Predictive analysis
ID DECISION TREE; INTELLIGENCE; BUSINESS
AB Business intelligence is a critical in defining the strategy and roadmap of organizations. However, business intelligence covers too much wide coverage to consider all of fields such as data analytics, text mining, predictive analytics, and so on. Among these fields, the most important is information analysis and prediction. Therefore, we suggest a business intelligence application based on the adaptive recognition of user intention and usage patterns in the mobile environment. This application is named InSciTe Adaptive and is based on text mining and semantic web technologies. It supports technology-focused analysis and predictions, such as technology trends analysis, element technology analysis, and convergence technology discovery, as well as adaptive recognition of the user's intention by using semi-automatic user modeling processes. Through adaptive user modeling, this application can provide a more dynamic service flow and more up-to-date analysis results based on the user's intention, compared to existing applications, which provide static analysis results and service flow.
C1 [Kim, Jinhyung; Jeong, Do-Heon; Jung, Hanmin] Korea Inst Sci & Technol Informat, Dept Comp Intelligence Res, Informat Software Res Ctr, Taejon, South Korea.
   [Lee, DongHwi] Kyunggi Univ, Dept Ind Secur, Suwon, South Korea.
C3 Korea Institute of Science & Technology (KIST); Korea Institute of
   Science & Technology Information (KISTI)
RP Kim, J (corresponding author), Korea Inst Sci & Technol Informat, Dept Comp Intelligence Res, Informat Software Res Ctr, 52-11 Eoeun Dong, Taejon, South Korea.
EM jinhyung@kisti.re.kr; heon@kisti.re.kr; dhclub@naver.com;
   jhm@kisti.re.kr
CR [Anonymous], 2008, COMB UN BUS INT SEM
   [Anonymous], 2009, FOR UND SCI EXP
   Azma F, 2012, PROC TECH, V1, P102, DOI 10.1016/j.protcy.2012.02.020
   Cheung CF, 2012, EXPERT SYST APPL, V39, P6279, DOI 10.1016/j.eswa.2011.10.021
   Dereli T, 2009, J SCI IND RES INDIA, V68, P674
   Du M, 2011, ADV MATER RES-SWITZ, V267, P732, DOI 10.4028/www.scientific.net/AMR.267.732
   Höferlin B, 2011, MULTIMED TOOLS APPL, V55, P127, DOI 10.1007/s11042-010-0606-z
   John H, 1995, TECHNICAL CHANGE WOR
   Kim J, 2012, ADV INF SCI SERV SCI, V4, P161
   Kim J, 2013, INF J, V16
   Kim J, 2012, EXPERT SYST APPL, V39, P12618, DOI 10.1016/j.eswa.2012.05.021
   Kim YG, 2008, EXPERT SYST APPL, V34, P1804, DOI 10.1016/j.eswa.2007.01.033
   Leary D, 2008, INT J ACCOUNT INF SY, V9, P240
   Lee M, 2013, INF J, V16, P693
   Perez C, 2007, OTHER CANON FDN TALL, V15, P32
   Prabhakaran B, 2000, MULTIMED TOOLS APPL, V12, P281, DOI 10.1023/A:1009627926302
   Ranjan Jayanthi, 2009, Journal of Theoretical and Applied Information Technology, V9, P60
   Rann A, 1998, HDB QUANTITATIVE STU
   Rey-López M, 2008, MULTIMED TOOLS APPL, V40, P409, DOI 10.1007/s11042-008-0213-4
   Richard S., 1983, WORLD PATENT INFORM, V5, P137
   Urban J, 2006, MULTIMED TOOLS APPL, V31, P1, DOI 10.1007/s11042-006-0035-1
   WEKA, 2010, DAT MIN OP SOURC MAC
   Yi WG, 2011, INT J MACH LEARN CYB, V2, P67, DOI 10.1007/s13042-011-0015-2
   Zeng L, 2012, INFORM TECHNOL MANAG, V13, P297, DOI 10.1007/s10799-012-0123-z
NR 24
TC 5
Z9 5
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 20
BP 8761
EP 8779
DI 10.1007/s11042-013-1486-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CR6XU
UT WOS:000361492600004
DA 2024-07-18
ER

PT J
AU Shin, DK
   Jung, H
   Chung, KY
   Park, RC
AF Shin, Dong-Kun
   Jung, Hoill
   Chung, Kyung-Yong
   Park, Roy C.
TI Performance analysis of advanced bus information system using LTE
   antenna
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligent transport systems; Bus information system; LTE antenna; MIMO
ID INTELLIGENT TRANSPORT-SYSTEMS
AB Improving traffics flow represents a critical situation due to recent increases in traffic volume, despite continuous construction and extension of highways and national roads. Therefore, an effective traffic control and management method using advanced technologies is required in order to relieve traffic congestion. An intelligent transportation system (ITS) applies advanced traffic, electronics, communication, and control technologies to various elements of transportation systems including roads, vehicles, and in order to collect, manage, and provide real-time traffic information. This can maximize the effectiveness of transportation facilities, implement increases in traffic convenience and safety, and reduce energy. A bus information system is an advanced transportation system that provides information, which is collected and processed in real-time, on operating city buses to users through advanced transportation networks. It provides bus operation management services, including route information bus location information to drivers. To ensure the accuracy of the bus information system, the structure of the receivers must be complex, as different base stations must account for buses in each region. This results in difficulty in obtaining real-time information due to the unsmooth hand-over between the base station and bus. In this paper, we carry out a performance analysis of an LTE antenna for use in an advanced bus information system. In the proposed design antenna, a particle swarm optimization method based on HFSS is used to design an LTE antenna. The aim of this paper is to design and fabricate a CPW-fed rectangular LTE antenna as well as study the effects of antenna length, width, substrate parameters relative dielectric constant, and substrate thickness on radiation parameters of band width. When the antenna was designed, a dual-band, dual-polarized antenna was used to secure bandwidth and improve performance.
C1 [Shin, Dong-Kun] Sahmyook Univ, Div Comp, Seoul 139742, South Korea.
   [Jung, Hoill; Chung, Kyung-Yong] Sangji Univ, Sch Comp Informat Engn, Wonju 220702, Gangwon Do, South Korea.
   [Park, Roy C.] Samsun Technol Res Co Ltd, Samsun Co Affiliated Res, Bucheon Si 420772, Gyeonggi Do, South Korea.
C3 Sahmyook University; Sangji University
RP Park, RC (corresponding author), Samsun Technol Res Co Ltd, Samsun Co Affiliated Res, 564-6 Sang Dong, Bucheon Si 420772, Gyeonggi Do, South Korea.
EM dkshin@hanmail.net; hijung1982@gmail.com; dragonhci@hanmail.net;
   roypark.asap@gmail.com
RI Chung, Kyungyong/JAC-2276-2023
FU Sahmyook University
FX This paper was supported by the Sahmyook University Research Fund in
   2012.
CR Boukour FE, 2012, P EUR WIR 2012 EW 18, V1, P1
   Cachulo L, 2012, PROC TECH, V5, P455, DOI 10.1016/j.protcy.2012.09.050
   Chen J., 2010, P 19 IND ENG RES C C, P1, DOI [10.1109/ICEEE.2010.5660103, 10.13140/RG.2.2.22863, DOI 10.13140/RG.2.2.22863]
   Elhillali Y, 2010, TRANSPORT RES C-EMER, V18, P429, DOI 10.1016/j.trc.2009.05.013
   Gotze Jana, 2010, Proceedings 2010 IEEE Spoken Language Technology Workshop (SLT 2010), P454, DOI 10.1109/SLT.2010.5700895
   Janani R, 2012, PROCEDIA ENGINEER, V38, P2754, DOI 10.1016/j.proeng.2012.06.322
   Jung YG, 2011, INFORMATION-TOKYO, V14, P3791
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kim BG, 2007, ALPIT 2007: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON ADVANCED LANGUAGE PROCESSING AND WEB INFORMATION TECHNOLOGY, P376
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P827, DOI 10.1007/s11042-012-1195-9
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P873, DOI 10.1007/s11042-011-0919-6
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P855, DOI 10.1007/s11042-011-0920-0
   KUROBE A, 1990, IEEE T CONSUM ELECTR, V36, P602, DOI 10.1109/30.103180
   Liu HT, 2012, IEEE T ANTENN PROPAG, V60, P1540, DOI 10.1109/TAP.2011.2180300
   Liu Z, 2012, TRANSPORTATION SYSTE, V11, P77
   Lu Ye, 2010, 2010 3rd IEEE International Conference on Ubi-Media Computing (U-Media 2010), P139, DOI 10.1109/UMEDIA.2010.5544483
   MURAKAMI Y, 1993, ELECTRON LETT, V29, P1906, DOI 10.1049/el:19931268
   Nwagboso C, 2004, COMPUT IND, V54, P291, DOI 10.1016/j.compind.2003.10.008
   Oki B., 1993, Operating Systems Review, V27, P58, DOI 10.1145/173668.168624
   Park CH, 2012, LNEE, V1, P325
   Ryckaert J, 2010, IEEE T ADV PACKAGING, V27, P97
   Shelokar PS, 2007, APPL MATH COMPUT, V188, P129, DOI 10.1016/j.amc.2006.09.098
   Song C, 2011, INFORMATION-TOKYO, V14, P3591
   Vaa T, 2007, IET INTELL TRANSP SY, V1, P81, DOI 10.1049/iet-its:20060081
   Velaga NR, 2009, TRANSPORT RES C-EMER, V17, P672, DOI 10.1016/j.trc.2009.05.008
   Verdone R, 1997, IEEE VTC P, P914, DOI 10.1109/VETEC.1997.600462
   Yoo ES, 2005, PROC E ASIA SOC TRAN, V5, P325
NR 27
TC 7
Z9 7
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 20
BP 9043
EP 9054
DI 10.1007/s11042-013-1539-0
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CR6XU
UT WOS:000361492600025
DA 2024-07-18
ER

PT J
AU Song, CW
   Chung, KY
   Lee, JH
AF Song, Chang-Woo
   Chung, Kyung-Yong
   Lee, Jung-Hyun
TI Catching up faster data in digital crime using mobile devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile device; Forensic; Evidence collection; Data acquisition
AB Mass storage media are becoming increasingly common due to the spread of smartphones to which new technologies are applied. Correspondingly, the amount of data collected from digital crime has considerably increased. Previously, if an investigator did not properly conduct the initial response, valuable evidence would be lost. Thus, collection of digital evidence within a short time frame is required. Further, in searches using data from the smartphones to gather evidence, evidence must be collected and analyzed quickly. Therefore, in this paper, a method is proposed for rapidly collecting data at a crime scene based on the type of criminal charge. Once implemented, our method can collect data by accounting for each feature of the software, providing rapid results through a pattern search. There is also a range of options available with parallel routines. Single or multiple options can be utilized depending on the investigator's requirements.
C1 [Song, Chang-Woo] Inha Univ, Dept Comp & Informat Engn, HCI Lab, Inchon 402751, South Korea.
   [Chung, Kyung-Yong] Sangji Univ, Sch Comp Informat Engn, Wonju 220702, Gangwon Do, South Korea.
   [Lee, Jung-Hyun] Inha Univ, Dept Comp & Informat Engn, Inchon 402751, South Korea.
C3 Inha University; Sangji University; Inha University
RP Song, CW (corresponding author), Inha Univ, Dept Comp & Informat Engn, HCI Lab, Yonghyeon 1,4 Dong, Inchon 402751, South Korea.
EM ph.d.scw@gmail.com; dragonhci@hanmail.net; jhlee@inha.ac.kr
RI Chung, Kyungyong/JAC-2276-2023
FU Basic Science Research Program through National Research Foundation of
   Korea (NRF) - Ministry of Education [2013R1A1A2059964]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (2013R1A1A2059964).
CR Akkaladevi S, 2011, SOFTW ENG RES MANAG, V377, P349
   Andrew H., 2011, ANDROID FORENSICS IN
   Andriotis P, 2012, IEEE INT WORKS INFOR, P109, DOI 10.1109/WIFS.2012.6412634
   [Anonymous], 1994, FAST ALGORITHM MULTI
   [Anonymous], SYST APPR DIG FOR EN
   Baek SJ, 2013, WIRELESS PERS COMMUN, V73, P309, DOI 10.1007/s11277-013-1239-0
   Berte R, 2009, INT J ELECT SECUR DI
   Choi J, 2011, PERS UBIQUIT COMPUT, V15, P641, DOI 10.1007/s00779-010-0343-3
   Dearman D, 2010, PERS UBIQUIT COMPUT, V14, P1, DOI 10.1007/s00779-008-0195-2
   Hourcade JP, 2012, PERS UBIQUIT COMPUT, V16, P157, DOI 10.1007/s00779-011-0383-3
   Hynes M, 2011, PERS UBIQUIT COMPUT, V15, P667, DOI 10.1007/s00779-010-0345-1
   I-Long Lin, 2011, 2011 International Conference on Broadband, Wireless Computing, Communication and Applications, P386, DOI 10.1109/BWCCA.2011.63
   Iqbal B., 2012, 2012 International Conference on Innovations in Information Technology (IIT), P238, DOI 10.1109/INNOVATIONS.2012.6207740
   Jung YG, 2011, INFORMATION-TOKYO, V14, P3791
   Katie S, 2011, IPHONE IOS FORENSICS
   Kim GH, 2015, MULTIMED TOOLS APPL, V74, P8745, DOI 10.1007/s11042-013-1536-3
   Kim H, 2013, PERS UBIQUIT COMPUT, V17, P571, DOI 10.1007/s00779-012-0516-3
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P873, DOI 10.1007/s11042-011-0919-6
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P855, DOI 10.1007/s11042-011-0920-0
   Kim SH, 2015, MULTIMED TOOLS APPL, V74, P8939, DOI 10.1007/s11042-013-1584-8
   Kim SH, 2014, MULTIMED TOOLS APPL, V68, P455, DOI 10.1007/s11042-013-1356-5
   Ko JW, 2015, MULTIMED TOOLS APPL, V74, P8907, DOI 10.1007/s11042-013-1581-y
   Koufi V, 2010, PERS UBIQUIT COMPUT, V14, P551, DOI 10.1007/s00779-009-0275-y
   Kubi A., 2011, P INT C APPL INF COM, P1
   Lee KD, 2013, MULTIMED TOOLS APPL, V63, P27, DOI 10.1007/s11042-012-1020-5
   Lim JH, 2012, LNEE, P711
   Moreland D, 2010, PERS UBIQUIT COMPUT, V14, P347, DOI 10.1007/s00779-009-0235-6
   National Institute of Justice, 2009, EL CRIM SCEN INV ON
   Oh SY, 2014, CLUSTER COMPUT, V17, P893, DOI 10.1007/s10586-013-0284-5
   Otani T, 2013, IEEE T POWER DELIVER, V28, P47, DOI 10.1109/TPWRD.2012.2222055
   Peris-Lopez P, 2012, PERS UBIQUIT COMPUT, V16, P351, DOI 10.1007/s00779-011-0396-y
   Portet F, 2013, PERS UBIQUIT COMPUT, V17, P127, DOI 10.1007/s00779-011-0470-5
   Raghav S, 2009, IEEE ST CONF RES DEV, P5, DOI 10.1109/SCORED.2009.5443431
   Said H., 2011, 2011 International Conference and Workshop on the Current Trends in Information Technology (CTIT'11), P120, DOI 10.1109/CTIT.2011.6107946
   Salmela L, 2007, P STRING PROC INF RE, P173
   Song CW, 2014, MULTIMED TOOLS APPL, V71, P813, DOI 10.1007/s11042-013-1362-7
   Song C, 2011, INFORMATION-TOKYO, V14, P3591
   Song CW, 2012, LNEE, P711
   Zareen Amjad, 2010, 2010 Fifth International Workshop on Systematic Approaches to Digital Forensic Engineering (SADFE), P47, DOI 10.1109/SADFE.2010.24
   Zhang YC, 2009, 2009 INTERNATIONAL CONFERENCE ON EDUCATION TECHNOLOGY AND COMPUTER, PROCEEDINGS, P13, DOI 10.1109/ICETC.2009.57
   Zheng K, 2013, PROC INT CONF DATA, P242, DOI 10.1109/ICDE.2013.6544829
NR 41
TC 6
Z9 8
U1 3
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 20
BP 9007
EP 9016
DI 10.1007/s11042-013-1725-0
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CR6XU
UT WOS:000361492600022
DA 2024-07-18
ER

PT J
AU Gao, PC
   Wu, JQ
   Lin, Y
   Xia, Y
   Mao, TJ
AF Gao Pengcheng
   Wu Jiangqin
   Lin Yuan
   Xia Yang
   Mao Tianjiao
TI Fast Chinese calligraphic character recognition with large-scale data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Calligraphic character; Shape context; Fast recognition
ID SHAPE
AB Chinese calligraphy draws a lot of attention for its beauty and elegance. But due to the complexity of shape and styles of calligraphic characters, it is difficult for common users to recognize them. Thus it would be great if a tool is provided to help users to recognize the unknown calligraphic characters. The well-known OCR (Optical Character Recognition) technology can hardly help people to recognize the unknown characters because of their deformation and complexity. In CADAL, a Calligraphic Character Dictionary (CalliCD) which contains character images labeled with semantic meaning has been constructed and provided to common users to use online. With the help of CalliCD, user can learn more about the unknown calligraphic character by performing similarity based searching. But as with the growth of CalliCD, it takes intolerable time to do the similarity based one-to-one searching. Strategies that can handle large scale data are needed. In this paper, a fast recognition schema based on retrieval is proposed. In addition, a novel shape descriptor, called GIST-SC, is proposed to represent calligraphic character image for efficient and effective retrieval. The schema works in three steps. Firstly approximate nearest neighbors of the character image to be recognized are found quickly. Secondly, one-to-one fine matching between approximate nearest neighbors and the character image to be recognized is performed. Finally the recognition based on semantic probability is given. Our experiments show that the GIST-SC descriptor and the recognition schema are efficient and effective for Chinese calligraphic character recognition with CalliCD.
C1 [Gao Pengcheng; Wu Jiangqin; Lin Yuan; Xia Yang; Mao Tianjiao] Zhejiang Univ, Hangzhou 310003, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Wu, JQ (corresponding author), Zhejiang Univ, Hangzhou 310003, Zhejiang, Peoples R China.
EM gaopengcheng@zju.edu.cn; wujq@zju.edu.cn
RI pengcheng, gao/HKO-0415-2023
FU National Natural Science Foundation of China [61379073]; CADAL Project
   and Research Center, Zhejiang University
FX This paper is supported by the National Natural Science Foundation of
   China under Grant No.61379073 and the CADAL Project and Research Center,
   Zhejiang University. Thank all the reviewers for helping us to improve
   our work.
CR Andoni A, 2006, ANN IEEE SYMP FOUND, P459
   [Anonymous], 2005, Learning Task-Specific Similarity
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Chen JY, 2003, PATTERN RECOGN, V36, P943, DOI 10.1016/S0031-3203(02)00128-0
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Doermann D, 1996, MACH VISION APPL, V9, P73
   Gdalyahu Y, 1999, IEEE T PATTERN ANAL, V21, P1312, DOI 10.1109/34.817410
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137
   Hailong Li, 2012, 2012 4th International Conference on Digital Home (ICDH 2012), P122, DOI 10.1109/ICDH.2012.64
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hodge V.J., 2008, P 5 IASTED INT C SIG, P81
   Klassen E, 2004, IEEE T PATTERN ANAL, V26, P372, DOI 10.1109/TPAMI.2004.1262333
   Lu WM, 2011, J ZHEJIANG U-SCI C, V12, P873, DOI 10.1631/jzus.C1100005
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Oliva A., 2005, Neurobiology of attention, V696, P64
   Porwal U., 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P322, DOI 10.1109/DAS.2012.35
   Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006
   Shen-Zheng Wang, 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P271, DOI 10.1109/ICDAR.2001.953797
   Shi Daming., 2003, ACM T ASIAN LANGUAGE, V2, P27, DOI DOI 10.1145/964161.964163
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Weiss Y., 2008, ADV NEURAL INFORM PR, V21, P1753
   Wu YF, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P2073, DOI 10.1109/ICME.2006.262642
   Xu S, 2005, AUTOMATIC GENERATION, V20
   Yu K, 2008, LECT NOTES COMPUT SC, V5353, P228
   Zhang XF, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P355, DOI 10.1109/CISP.2008.268
   Zhang Z., 2010, P 10 ANN JOINT C DIG, P99
   Zhuang YT, 2004, LECT NOTES COMPUT SC, V3331, P17
NR 28
TC 10
Z9 11
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 7221
EP 7238
DI 10.1007/s11042-014-1969-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800029
DA 2024-07-18
ER

PT J
AU Kavitha, S
   Anandhi, RJ
AF Kavitha, S.
   Anandhi, R. J.
TI A survey of image compression methods for low depth-of-field images and
   image sequences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image compression; Low DOF image; Video compression; Immersive video
ID SEGMENTATION
AB The popularity of multimedia applications has resulted in development of lossless and lossy compression techniques. Many image compression methods clustered under these two compression techniques are discussed briefly in this article. In addition to this context, the survey paper gives a study of the recent algorithms that are available for coding low Depth-of-Field (DOF) images and also covers its extension for depth map image sequence coding. Motivation behind this work is to provide a detailed analysis of these algorithms such as the methodology used, merits and demerits, and the objective and subjective comparison of these algorithms with the standard compression algorithms like JPEG, JPEG 2000, H.261/AVC etc. Further, the paper concludes with a guideline for the new researchers in this field which concerns the design of an efficient compression method for low DOF images and depth map image sequences.
C1 [Kavitha, S.; Anandhi, R. J.] Oxford Coll Engn, Dept Comp Sci & Engn, Bangalore, Karnataka, India.
C3 Oxford College of Engineering Bengaluru
RP Kavitha, S (corresponding author), Oxford Coll Engn, Dept Comp Sci & Engn, Bangalore, Karnataka, India.
EM kavi_mirudhu@yahoo.com; rjanandhi@hotmail.com
RI J, Anandhi R/ABE-5662-2020
OI J, Anandhi R/0000-0002-0117-0912
CR [Anonymous], 2012, P INT C WORKSHOP EME
   [Anonymous], 2006, INT J INNOVATIONS EN, DOI DOI 10.1038/NATURE04788
   [Anonymous], IEEE PICT COD S PCS
   [Anonymous], 2012, TELFOR J
   [Anonymous], INT J SCI ENG RES
   [Anonymous], P EUR SIGN PROC C
   [Anonymous], P COIT
   [Anonymous], 1992, R. woods digital image processing
   [Anonymous], 2011, VISUAL COMMUN-US, DOI DOI 10.1109/VCIP.2011.6115989
   [Anonymous], P INT S COMM CONTR S
   [Anonymous], CIIT INT J DIGIT IMA
   [Anonymous], P IEEE ICIP
   [Anonymous], PHOTOGRAMMETRIC WEEK
   Doulamis N, 1998, IEEE T CIRC SYST VID, V8, P928, DOI 10.1109/76.736718
   Hoffmann S., 2013, LECT NOTES COMPUTER, P319, DOI [10.1007/978-3-642-38267-3_27, DOI 10.1007/978-3-642-38267-3]
   Humphreys WM, 2002, AIAA J, V40, P1026, DOI 10.2514/2.1766
   Kang KS, 1996, J DIGIT IMAGING, V9, P11, DOI 10.1007/BF03168563
   Kavitha S, 2009, DIGIT SIGNAL PROCESS, V19, P59, DOI 10.1016/j.dsp.2008.03.003
   Kim CG, 2005, IEEE T IMAGE PROCESS, V14, P1503, DOI 10.1109/TIP.2005.846030
   Mammeri Abdelhamid, 2012, ISRN Sensor Networks, DOI 10.5402/2012/760320
   Milani S, 2011, IEEE INT CON MULTI
   Milani S, 2010, IEEE SIGNAL PROC LET, V17, P51, DOI 10.1109/LSP.2010.2051619
   Oh H, 2006, LECT NOTES COMPUT SC, V4319, P898
   Oh KJ, 2009, IEEE SIGNAL PROC LET, V16, P747, DOI 10.1109/LSP.2009.2024112
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   SALEMBIER P, 1994, IEEE T IMAGE PROCESS, V3, P639, DOI 10.1109/83.334980
   Sayood K, 2017, Introduction to data compression
   Schiopu I, 2013, IEEE SIGNAL PROC LET, V20, P1066, DOI 10.1109/LSP.2013.2280495
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   Subramanya A., 2001, IEEE Potentials, V20, P19, DOI 10.1109/45.913206
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P85, DOI 10.1109/34.899949
   Wei XH, 2006, IEEE IMAGE PROC, P549, DOI 10.1109/ICIP.2006.312484
   Won CS, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P805, DOI 10.1109/ICIP.2002.1039094
   Zanuttigh P., 2009, 3DTV C TRUE VIS CAPT, P1
   Zhu B, 2009, 2009 ASIA-PACIFIC CONFERENCE ON INFORMATION PROCESSING (APCIP 2009), VOL 2, PROCEEDINGS, P104, DOI 10.1109/APCIP.2009.162
NR 35
TC 4
Z9 5
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 7943
EP 7956
DI 10.1007/s11042-014-2032-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200024
DA 2024-07-18
ER

PT J
AU Lee, GJ
   Yoo, KY
AF Lee, Gil-Je
   Yoo, Kee-Young
TI An improved double image digital watermarking scheme using the position
   property
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; PSNR; Robustness; Multiple; Spatial
ID COPYRIGHT PROTECTION
AB In the last few years, researchers have found that the security of multiple watermarking schemes are more than single watermarking schemes. In 2007, Hu et al. proposed a robust and simple scheme that used two watermark images. However, it had an ambiguity problem that the holder can claim ownership of the others copyright holder's images. This paper solves the problem of Hu et al.'s scheme by using the position property of the original image. Although our results show that the robustness test of the proposed scheme presented a slightly lower quality than Hu et al.'s scheme, the ambiguity problem does not occur in our proposed scheme.
C1 [Lee, Gil-Je; Yoo, Kee-Young] Kyungpook Natl Univ, Sch Comp Sci & Engn, Daegu, South Korea.
C3 Kyungpook National University
RP Yoo, KY (corresponding author), Kyungpook Natl Univ, Sch Comp Sci & Engn, Daegu, South Korea.
EM vilelkj@infosec.knu.ac.kr; yook@knu.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education, Science and Technology
   [2012008348]; IT R&D program of MSIP/KEIT [10041145]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education, Science and Technology(2012008348) and the IT R&D program
   of MSIP/KEIT. [10041145, Self-Organized Software platform(SoSp) for
   Welfare Devices].
CR Agreste S, 2008, J COMPUT APPL MATH, V221, P274, DOI 10.1016/j.cam.2007.10.057
   [Anonymous], 2010, INT J COMPUT SCI INF
   [Anonymous], ERMITTELN UNAUTHORIS
   [Anonymous], 2000, Digital Watermarking
   Chang CC, 2002, IEE P-VIS IMAGE SIGN, V149, P43, DOI 10.1049/ip-vis:20020372
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Gogoi M, 2013, INT J ADV COMPUT SC, V4, P112
   Gonzalez R.C., 2018, DIGITAL IMAGE PROCES, V4th
   Guo J, 2007, OPT COMMUN, V272, P344, DOI 10.1016/j.optcom.2006.11.034
   Horng S-J, 2013, INT J MTAP SPRINGER, V19, P62
   Hsia SC, 2002, IEICE T FUND ELECTR, VE85A, P463
   Hu MC, 2007, COMPUT SECUR, V26, P319, DOI 10.1016/j.cose.2006.11.007
   Lee WB, 2002, J SYST SOFTWARE, V62, P195, DOI 10.1016/S0164-1212(01)00142-X
   Lin S. D., 2003, International Journal of Computers & Applications, V25, P130
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P11888, DOI 10.1016/j.eswa.2009.04.026
   Lin WH, 2009, EXPERT SYST APPL, V36, P11509, DOI 10.1016/j.eswa.2009.03.060
   Lin WH, 2009, EXPERT SYST APPL, V36, P9869, DOI 10.1016/j.eswa.2009.02.036
   Lou DC, 2003, 37TH ANNUAL 2003 INTERNATIONAL CARNAHAN CONFERENCE ON SECURITY TECHNOLOGY, PROCEEDINGS, P370
   Lou DC, 2007, COMPUT STAND INTER, V29, P125, DOI 10.1016/j.csi.2006.02.003
   Mohammad AA, 2008, SIGNAL PROCESS, V88, P2158, DOI 10.1016/j.sigpro.2008.02.015
   Peng ZN, 2008, CHAOS SOLITON FRACT, V36, P946, DOI 10.1016/j.chaos.2006.07.015
   Preda RO, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3558734
   Preda RO, 2011, INT J ELECTRON, V98, P393, DOI 10.1080/00207217.2010.547810
   Preda RO, 2010, MEASUREMENT, V43, P1720, DOI 10.1016/j.measurement.2010.07.009
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Tanaka K., 1990, MILCOM 90. A New Era. 1990 IEEE Military Communications Conference. Conference Record (Cat. No.90CH2831-6), P216, DOI 10.1109/MILCOM.1990.117416
   Tirkel A. Z., 1993, Conference Proceedings DICTA-93 Digital Image Computing: Techniques and Applications, P666
   Wu YT, 2007, PATTERN RECOGN, V40, P3753, DOI 10.1016/j.patcog.2007.04.013
   Yu D, 2006, PATTERN RECOGN, V39, P935, DOI 10.1016/j.patcog.2005.11.023
   Zhang XP, 2005, IEICE T FUND ELECTR, VE88A, P3663, DOI 10.1093/ietfec/e88-a.12.3663
NR 31
TC 1
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 7261
EP 7283
DI 10.1007/s11042-014-1980-8
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800031
DA 2024-07-18
ER

PT J
AU Xu, WR
   Miao, ZJ
   Zhang, Q
AF Xu, Wanru
   Miao, Zhenjiang
   Zhang, Qiang
TI Projection transform on spatio-temporal context for action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action recognition; Projection transform; Spatio-temporal interest
   points; Context; Relation-weights; Feature fusion
AB This paper discusses the task of human action recognition. This task is important to applications like video surveillance and video retrieval. Most of the existing local interest points based works on human action analysis, lost the information about spatio-temporal distribution of features and neglected the relationship between features and each defined actions. In this paper, through the analysis of feature distribution and their interactions over spatio-temporal domain, we propose a novel projection transform to take the two factors into account. A video sequence of human action in our perspective can be modeled by three types of features of spatio-temporal interest points: the global projection transform feature, the relative position distribution feature and the bag of visual words based feature. Then a new context-K-nearest-neighbor classifier is utilized to fuse them to form discriminative feature sets for action matching. In most of the case, our experiments have indicated that the novel method outperforms other previous published results on the Weizmann and KTH datasets.
C1 [Xu, Wanru; Miao, Zhenjiang; Zhang, Qiang] Beijing Jiaotong Univ, Inst Informat Sci, Beijing, Peoples R China.
C3 Beijing Jiaotong University
RP Miao, ZJ (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing, Peoples R China.
EM zjmiao@bjtu.edu.cn
FU NSFC [61273274]; 973 Program [2011CB302203]; National Key Technology R&D
   Program of China [2012BAH01F03, NSFB4123104 Z131110001913143];
   Tsinghua-Tencent Joint Lab for IIT; Beijing Jiaotong University Research
   Foundation Program [KKJB14029536]
FX This work is supported by the NSFC 61273274, 973 Program 2011CB302203,
   National Key Technology R&D Program of China 2012BAH01F03, NSFB4123104
   Z131110001913143, Tsinghua-Tencent Joint Lab for IIT and Beijing
   Jiaotong University Research Foundation Program KKJB14029536.
CR [Anonymous], 2004, INT C MACH LEARN
   [Anonymous], 2011, ICCV
   [Anonymous], 2011, CVPR
   [Anonymous], 2004, ICPR
   [Anonymous], 2012, CVPR
   [Anonymous], 2003, ICCV
   [Anonymous], CVPR
   [Anonymous], ICCV
   [Anonymous], 2005, ICCV
   [Anonymous], 2008, CVPR
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bregonzio M., 2009, CVPR
   Brendel W., 2011, ICCV
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Dollar P., 2005, Behavior recognition via sparse spatiotemporal feature
   Fathi A., 2008, CVPR
   grawal A., 1994, VLDB1994, P487
   Guo P., 2012, MULTIMED TOOLS APPL, P1
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   Lazebnik S., CVPR 2006
   Liu JG, 2009, INT CONF ACOUST SPEE, P3549, DOI 10.1109/ICASSP.2009.4960392
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491
   Savarese S., 2008, WMVC, P1
   Sun Ju., 2009, CVPR
   THI TH, 2012, STRUCTURED LEARNING, V30, P1, DOI DOI 10.1016/J.IMAVIS.2011.12.006
   Wang H., P BMVC 09
   Wang Jiang., 2011, CVPR
   Wang L., 2009, WACV
   Ye Y., 2011, PCM
   Yuan C., 2013, CVPR
NR 31
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 7711
EP 7728
DI 10.1007/s11042-014-2007-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200014
DA 2024-07-18
ER

PT J
AU Guzik, P
   Matiolanski, A
   Dziech, A
AF Guzik, Piotr
   Matiolanski, Andrzej
   Dziech, Andrzej
TI Real data performance evaluation of CAISS watermarking scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Spread spectrum; DCT domain
AB In this paper we present real data bit error rate (BER) performance evaluation of the recently proposed correlation-and-bit-aware improved spread spectrum (CAISS) watermarking scheme (Valizadeh and Wang, IEEE Trans Inf Forensics Secur 6(2):267-282, 2011). Our tests were performed in discrete cosine transform (DCT) domain. The results show significant improvement as compared with traditional spread spectrum technique. Tests performed under medium JPEG compression and fixed peak signal-to-noise ratio (PSNR) indicate that appropriate choice of CAISS parameters allows for over a three orders of magnitude smaller BER compared to spread spectrum technique without side information about correlation. CAISS also significantly outperforms traditional spread spectrum when watermarked images are subjected to additive Gaussian noise or downscaled before watermark decoding. We also compared CAISS with the improved spread spectrum (ISS) scheme and found that CAISS can perform significantly better than ISS (in terms of BER) after medium JPEG compression but gives almost the same results in presence of additive Gaussian noise and image scaling.
C1 [Guzik, Piotr; Matiolanski, Andrzej; Dziech, Andrzej] AGH Univ Sci & Technol, PL-30059 Krakow, Poland.
C3 AGH University of Krakow
RP Guzik, P (corresponding author), AGH Univ Sci & Technol, Al Mickiewicza 30, PL-30059 Krakow, Poland.
EM guzik@kt.agh.edu.pl; matiolanski@kt.agh.edu.pl; dziech@kt.agh.edu.pl
RI Dziech, Andrzej/M-4483-2016; Guzik, Piotr/B-1313-2016
OI Guzik, Piotr/0000-0002-5019-4056
FU European regional development fund; Polish State budget; 
   [POIG.02.03.03-00-008/08]
FX Research funded within the project No. POIG.02.03.03-00-008/08, entitled
   "MAYDAY EURO 2012-the supercomputer platform of context-depended
   analysis of multimedia data streams for identifying specified objects or
   safety threats". The project is subsidized by the European regional
   development fund and by the Polish State budget.
CR [Anonymous], COMMUNICATIONS IEEE
   [Anonymous], ACOUST SPEECH SIG PR
   Chen B, 2001, J VLSI SIG PROCESS S, V27, P7, DOI 10.1023/A:1008107127819
   Cheng Q, 2001, IEEE T MULTIMEDIA, V3, P273, DOI 10.1109/6046.944472
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Guzik P, 2012, COMM COM INF SC, V287, P139
   Valizadeh A., 2011, IEEE Transactions on Information Forensics and Security, V6, P267, DOI 10.1109/TIFS.2010.2103061
   Valizadeh A, 2009, IEEE GLOBECOM 2009 G, P1
NR 8
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 12
BP 4437
EP 4451
DI 10.1007/s11042-013-1544-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CK4CW
UT WOS:000356168600015
OA hybrid
DA 2024-07-18
ER

PT J
AU Kotus, J
AF Kotus, Jozef
TI Multiple sound sources localization in free field using acoustic vector
   sensor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sound detection; Sound source localization; Audio surveillance
AB Method and preliminary results of multiple sound sources localization in free field using the acoustic vector sensor were presented in this study. Direction of arrival (DOA) for considered source was determined based on sound intensity method supported by Fourier analysis. Obtained spectrum components for considered signal allowed to determine the DOA value for the particular frequency independently. The accuracy of the developed and practically implemented algorithm was evaluated on the basis of laboratory tests. Both synthetic acoustic signals (pure tones and noises) and real sounds were used during the measurements. Real signals had the same or different energy distribution both on time and frequency domain. The setup of the experiment and obtained results were described in details in the text. Taking the obtained results into consideration is important to emphasize that the localization of the multiple sound sources using single acoustic vector sensor is possible. The localization accuracy was the best for signals which spectral energy distribution was different.
C1 Gdansk Univ Technol, Multimedia Syst Dept, PL-80233 Gdansk, Poland.
C3 Fahrenheit Universities; Gdansk University of Technology
RP Kotus, J (corresponding author), Gdansk Univ Technol, Multimedia Syst Dept, Narutowicza 11-12, PL-80233 Gdansk, Poland.
EM joseph@sound.eti.pg.gda.pl
FU European Commission within FP7 project "INDECT" [218086]
FX Research is subsidized by the European Commission within FP7 project
   "INDECT" (Grant Agreement No. 218086).
CR Basten T, 2009, ICSV16 KRAK POL
   Basten T, 2007, ERF33 KAZ RUSS
   Blandin C, 2012, SIGNAL PROCESS, V92, P1950, DOI 10.1016/j.sigpro.2011.09.032
   Cengarle G, 2011, 8363 AUD ENG SOC
   CZYZEWSKI A., 2010, AUTOMATIC LOCALIZATI, P441
   de Bree H.-E., 2003, Acoustics Australia, V31, P91
   de Bree H-E, 2010, DAGA 2010 C P BERL G
   de Bree H-E, 2011, INT 2011 P OS JAP 4
   Hawkes M, 1998, IEEE T SIGNAL PROCES, V46, P2291, DOI 10.1109/78.709509
   Hawkes M, 2003, IEEE T SIGNAL PROCES, V51, P1479, DOI 10.1109/TSP.2003.811225
   Kotus J, 2010, MCSS 2010, P140
   Kotus J., 2010, INFORM TECHNOLOGIES, V18, P111
   Kotus J, 2010, 1 INT WORKSH INT MUL, P276
   Kotus J, 2011, COMM COM INF SC, V149, P55
   Lopatka K, 2011, ISSET 2011 MAY 19 21
   Pavlidi D, 2012, INT CONF ACOUST SPEE, P2625, DOI 10.1109/ICASSP.2012.6288455
   Raangs R., 2002, SOUND SOURCE LOCALIZ
   Smith S.W., 1997, SCI ENG GUIDE DIGITA
   Stanacevic M, 2005, IEEE T CIRCUITS-I, V52, P2148, DOI 10.1109/TCSI.2005.853356
   Wind J.W., 2009, SOURCE LOCALIZATION
   Wind JW, 2009, THESIS U TWENTE ENSC
NR 21
TC 18
Z9 20
U1 1
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 12
BP 4235
EP 4251
DI 10.1007/s11042-013-1549-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CK4CW
UT WOS:000356168600004
PM 26321871
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Sun, L
   Sheng, WJ
   Liu, YQ
AF Sun, Li
   Sheng, Wenjuan
   Liu, Yiqing
TI Background modeling and its evaluation for complex scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Background subtraction; Background modeling; Multiple modes
ID SUBTRACTION
AB We present a new approach for modeling background in complex scenes that contain unpredicted motions caused e.g. by wind over water surface, in tree branches, or over the grass. The background model of each pixel is defined based on the observation of its spatial neighborhood in a recent history, and includes up to modes, which defines the frequently appeared patterns at the given pixel position in the color space, ranked in decreasing order of occurrence frequency. Foreground regions can then be detected by comparing the intensity of an observed pixel to the high frequency modes of its background model. Experiments show that our spatial-temporal background model is superior to traditional related algorithms in cases for which a pixel encounters modes that are frequent in the spatial neighborhood without being frequent enough in the actual pixel position. As an additional contribution, our paper also proposes an original assessment method, which has the advantage of avoiding the use of costly handmade ground truth sequences of foreground objects silhouettes.
C1 [Sun, Li; Liu, Yiqing] E China Normal Univ, Sch Informat Sci & Technol, Shanghai 200241, Peoples R China.
   [Sheng, Wenjuan] Shanghai Univ Elect Power, Sch Automat Engn, Shanghai 200090, Peoples R China.
C3 East China Normal University; Shanghai University of Electric Power
RP Sun, L (corresponding author), E China Normal Univ, Sch Informat Sci & Technol, Shanghai 200241, Peoples R China.
EM sunli@ee.ecnu.edu.cn
FU National Natural Science Foundation of China [61302125]; Fundamental
   Research Funds for the Central Universities, China
FX The authors would like to thank all the anonymous reviewers for their
   time and valuable comments. This work was supported in part by the
   National Natural Science Foundation of China, under Project 61302125,
   and in part by the Fundamental Research Funds for the Central
   Universities, China.
CR [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Cho SH, 2011, P INT C IM PROC COMP
   Cristani M, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/343057
   Hofmann Martin., 2012, 2012 IEEE COMPUTER S, P38, DOI DOI 10.1109/CVPRW.2012.6238925
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Kim W, 2011, IEEE T CIRC SYST VID, V21, P446, DOI 10.1109/TCSVT.2011.2125450
   Ko T, 2008, LECT NOTES COMPUT SC, V5304, P276, DOI 10.1007/978-3-540-88690-7_21
   Ko T, 2010, PROC CVPR IEEE, P1331, DOI 10.1109/CVPR.2010.5539813
   Liu YZ, 2007, J VIS COMMUN IMAGE R, V18, P253, DOI 10.1016/j.jvcir.2007.01.003
   Mahadevan V, 2010, IEEE T PATTERN ANAL, V32, P171, DOI 10.1109/TPAMI.2009.112
   Mittal A, 2004, PROC CVPR IEEE, P302
   Noriega P, 2006, BRIT MACH VIS ASS BM, P567
   Pal A, 2010, INT CONF ACOUST SPEE, P1146, DOI 10.1109/ICASSP.2010.5495367
   Pless R, 2005, EURASIP J APPL SIG P, V2005, P2281, DOI 10.1155/ASP.2005.2281
   Sidibe D, 2009, IS T SPIE ELECT IMAG
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Wang HZ, 2006, LECT NOTES COMPUT SC, V3851, P328
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Wu MJ, 2010, AEU-INT J ELECTRON C, V64, P739, DOI 10.1016/j.aeue.2009.05.004
NR 21
TC 9
Z9 10
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 11
BP 3947
EP 3966
DI 10.1007/s11042-013-1806-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI6UQ
UT WOS:000354898800016
DA 2024-07-18
ER

PT J
AU Liu, Y
   Du, J
   Fan, JH
   Gong, LH
AF Liu, Ye
   Du, Juan
   Fan, Jinghui
   Gong, Lihua
TI Single-channel color image encryption algorithm based on fractional
   Hartley transform and vector operation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vector operation; Fractional Hartley transform; Image encryption;
   Information security
AB A single-channel color image encryption algorithm is proposed by combining fractional Hartley transform (FRHT) with vector operation. The original color image is decomposed into RGB components and the G and B components are encrypted into two phase-only masks theta (G) and theta (B) with vector operation, respectively. The R, theta (G) and theta (B) are transformed by FRHT and vector operation twice to obtain amplitude, random phase and decryption phase key. The new amplitude combined with the random phase is transformed by FRHT once more and then the result is scrambled by the chaotic scrambling to strengthen the security of the algorithm. The private phase key is dependent on the original image, which makes the proposed encryption algorithm more secure than the linear color image encryption algorithm based on the double random phase encoding in FRHT. Simulation results demonstrate the security and effectiveness of the proposed algorithm.
C1 [Liu, Ye; Du, Juan; Fan, Jinghui; Gong, Lihua] Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Peoples R China.
   [Gong, Lihua] Nanchang Hangkong Univ, Jiangxi Prov Key Lab Image Proc & Pattern Recogni, Nanchang 330063, Peoples R China.
C3 Nanchang University; Nanchang Hangkong University
RP Liu, Y (corresponding author), Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Peoples R China.
EM liuye@ncu.edu.cn; ncujdu@163.com; jinghuifan@163.com; ncuglh@163.com
FU National Natural Science Foundation of China [61262084, 61141007];
   Foundation for Young Scientists of Jiangxi Province (Jinggang Star)
   [20122BCB23002]; Opening Project of Key Laboratory of Image Processing
   and Pattern Recognition (Nanchang Hangkong University), Jiangxi Province
   [TX201204002]
FX The work is supported by the National Natural Science Foundation of
   China (Grant Nos. 61262084 and 61141007), the Foundation for Young
   Scientists of Jiangxi Province (Jinggang Star) (Grant No.
   20122BCB23002), and the Opening Project of Key Laboratory of Image
   Processing and Pattern Recognition (Nanchang Hangkong University),
   Jiangxi Province (Grant No. TX201204002).
CR Chen LF, 2009, OPT COMMUN, V282, P3433, DOI 10.1016/j.optcom.2009.05.044
   Chen W, 2011, OPT COMMUN, V284, P3913, DOI 10.1016/j.optcom.2011.04.005
   Deng XP, 2012, OPT LASER TECHNOL, V44, P136, DOI 10.1016/j.optlastec.2011.06.006
   Guo Q, 2010, OPT LASER ENG, V48, P1174, DOI 10.1016/j.optlaseng.2010.07.005
   Hwang HE, 2006, J OPT SOC AM A, V23, P1870, DOI 10.1364/JOSAA.23.001870
   Jimenez C., 2011, Journal of Physics: Conference Series, V274, DOI 10.1088/1742-6596/274/1/012041
   Joshi M, 2007, OPT COMMUN, V279, P35, DOI 10.1016/j.optcom.2007.07.012
   Joshi M, 2008, OPT COMMUN, V281, P5713, DOI 10.1016/j.optcom.2008.08.024
   Li XX, 2008, CHINESE PHYS LETT, V25, P2477, DOI 10.1088/0256-307X/25/7/040
   Li XX, 2010, OPTIK, V121, P673, DOI 10.1016/j.ijleo.2008.10.008
   Liu ZJ, 2010, OPT LASER ENG, V48, P800, DOI 10.1016/j.optlaseng.2010.02.005
   Pei SC, 2002, IEEE T SIGNAL PROCES, V50, P1661, DOI 10.1109/TSP.2002.1011207
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Situ GH, 2004, OPT LETT, V29, P1584, DOI 10.1364/OL.29.001584
   Tao R, 2007, OPT EXPRESS, V15, P16067, DOI 10.1364/OE.15.016067
   Unnikrishnan G, 2000, OPT LETT, V25, P887, DOI 10.1364/OL.25.000887
   Wang XG, 2011, OPT COMMUN, V284, P945, DOI 10.1016/j.optcom.2010.10.058
   Zhao DM, 2008, OPT COMMUN, V281, P5326, DOI 10.1016/j.optcom.2008.07.049
   Zhou NR, 2012, OPT LASER TECHNOL, V44, P2270, DOI 10.1016/j.optlastec.2012.02.027
   Zhou NR, 2011, OPT COMMUN, V284, P3234, DOI 10.1016/j.optcom.2011.02.065
   Zhou NR, 2011, OPT COMMUN, V284, P2789, DOI 10.1016/j.optcom.2011.02.066
NR 21
TC 20
Z9 20
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 9
BP 3171
EP 3182
DI 10.1007/s11042-013-1778-0
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CF7NI
UT WOS:000352742800016
DA 2024-07-18
ER

PT J
AU Yen, NY
   Jin, Q
   Tsai, JC
   Park, JJ
AF Yen, Neil Y.
   Jin, Qun
   Tsai, Joseph C.
   Park, James J.
TI Intelligent state machine for social ad hoc data management and reuse
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligent state machine; Social contexts; User-generated data;
   Human-centered support; Information retrieval
ID SEARCH; NETWORKS; DESIGN
AB Recent advances in information technology have turned out World Wide Web to be the main platform for interactions where participants-users and corresponding events-are triggered. Although the participants vary in accordance with scenarios, a considerable size of data will be generated. This phenomenon indeed causes the complexity in information retrieval, management, and resuse, and meanwhile, turns down the value of this data. In this research, we attempt to achieve efficient management of user-generated data and its derivative contexts (i.e., social ad hoc data) for human supports. The correlations among data, contexts, and their hybridization are specifically concentrated. An intelligent state machine is proposed to outline the relations of data and contexts, and applied to further identify their usage scenarios. The performance and feasibility can be revealed by the experiments that were conducted on the data collected from open social networks (e.g., Facebook, Twitter, etc.) in the past few years with size around 500 users and 8,000,000 shared contents from them.
C1 [Yen, Neil Y.; Tsai, Joseph C.] Univ Aizu, Scool Comp Sci & Engn, Aizu Wakamatsu, Japan.
   [Jin, Qun] China Jiliang Univ, Coll Informat Engn, Dept Comp Sci & Technol, Hangzhou, Zhejiang, Peoples R China.
   [Jin, Qun] Waseda Univ, Dept Human Informat & Cognit Sci, Fac Human Sci, Networked Informat Syst Lab, Tokyo, Japan.
   [Park, James J.] Seoul Natl Univ Sci & Technol, Dept Comp Sci & Engn, Seoul 139743, South Korea.
C3 University of Aizu; China Jiliang University; Waseda University; Seoul
   National University of Science & Technology
RP Jin, Q (corresponding author), China Jiliang Univ, Coll Informat Engn, Dept Comp Sci & Technol, 258 Xueyuan St, Hangzhou, Zhejiang, Peoples R China.
EM neilyyen@u-aizu.ac.jp; jin@acm.org; jctsai@u-aizu.ac.jp;
   parkjonghyuk1@hotmail.com
RI santana, elysmara S D/P-2636-2016
FU MSIP (Ministry of Science, ICT and Future Planning), Korea, under the
   ITRC (Information Technology Research Center) [NIPA-2014-H0301-14-4007]
FX This research was supported by the MSIP (Ministry of Science, ICT and
   Future Planning), Korea, under the ITRC (Information Technology Research
   Center) support program (NIPA-2014-H0301-14-4007) supervised by the
   NIPA(National IT Industry Promotion Agency).
CR Aarts F, 2010, LECT NOTES COMPUT SC, V6435, P188, DOI 10.1007/978-3-642-16573-3_14
   [Anonymous], P CEAS 1
   Bose I, 2001, INFORM MANAGE-AMSTER, V39, P211, DOI 10.1016/S0378-7206(01)00091-X
   Carpineto C, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1541880.1541884
   Cavalli A, 2003, INFORM SOFTWARE TECH, V45, P837, DOI 10.1016/S0950-5849(03)00063-6
   Cheng K., 1996, ACM Transactions on Design Automation of Electronic Systems, V1, P57
   Erickson T., 2000, ACM Transactions on Computer-Human Interaction, V7, P59, DOI 10.1145/344949.345004
   Esling P, 2012, ACM COMPUT SURV, V45, DOI 10.1145/2379776.2379788
   Fagni T, 2006, ACM T INFORM SYST, V24, P51, DOI 10.1145/1125857.1125859
   Faloutsos C, 2004, P ACM SIGKDD 2004
   Folstad A, 2013, HUM-CENT COMPUT INFO, V3, DOI 10.1186/2192-1962-3-18
   Gaber MM, 2005, SIGMOD REC, V34, P18, DOI 10.1145/1083784.1083789
   Guralnik V., 1999, P 5 ACM SIGKDD INT C, P33, DOI [10.1145/312129.312190, DOI 10.1145/312129.312190]
   HARADA M, 2004, P JOINT C DIG LIB JC
   Hoheisel A., 2007, Workflows for e-Science: Scientific Workflows for Grids, P190
   Hong JE, 2000, INFORM SCIENCES, V130, P133, DOI 10.1016/S0020-0255(00)00090-6
   Jensen Kurt, 2007, International Journal on Software Tools for Technology Transfer, V9, P213, DOI 10.1007/s10009-007-0038-x
   Joachims T., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P154, DOI 10.1145/1076034.1076063
   Karsai M, 2011, PHYS REV E, V83, DOI 10.1103/PhysRevE.83.025102
   Keogh E, 2003, DATA MIN KNOWL DISC, V7, P349, DOI 10.1023/A:1024988512476
   KOZLOWSKI T, 1995, IEE P-COMPUT DIG T, V142, P263, DOI 10.1049/ip-cdt:19951886
   Lee K, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P1474
   Li LX, 2008, IEEE T SYST MAN CY A, V38, P207, DOI 10.1109/TSMCA.2007.909559
   Liu BD, 2002, IEEE T FUZZY SYST, V10, P445, DOI 10.1109/TFUZZ.2002.800692
   Mandal N., 2008, J THEOR APPL INF TEC, V8, P1131
   Mangold WG, 2009, BUS HORIZONS, V52, P357, DOI 10.1016/j.bushor.2009.03.002
   MIKA P, 2005, P ISWC2005
   Milanovic N, 2004, IEEE INTERNET COMPUT, V8, P51, DOI 10.1109/MIC.2004.58
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Mitra S, 2002, IEEE T NEURAL NETWOR, V13, P3, DOI 10.1109/72.977258
   Pais R, 2011, IEEE IND ELEC, P3776
   Salimifard K, 2001, EUR J OPER RES, V134, P664, DOI 10.1016/S0377-2217(00)00292-7
   Schadt EE, 2010, NAT REV GENET, V11, P647, DOI 10.1038/nrg2857
   Shtykh RY, 2011, HUM-CENTRIC COMPUT I, V1, DOI 10.1186/2192-1962-1-2
   Steyvers M, 2005, COGNITIVE SCI, V29, P41, DOI 10.1207/s15516709cog2901_3
   Tay FEH, 2001, OMEGA-INT J MANAGE S, V29, P309, DOI 10.1016/S0305-0483(01)00026-3
   Thelwall M, 2001, J INFORM SCI, V27, P319, DOI 10.1177/016555150102700503
   van der Aalst WMP, 2004, LECT NOTES COMPUT SC, V3080, P244
   Yen NY, 2013, ACM T INTEL SYST TEC, V4, DOI [10.1145/2438653.2438668, 10.1145/2438653.2438665]
   Yixin Chen, 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases, P323
   Zhang J, 2004, IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES, PROCEEDINGS, P420, DOI 10.1109/ICWS.2004.1314766
NR 41
TC 0
Z9 0
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 10
BP 3521
EP 3541
DI 10.1007/s11042-014-1941-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI1GY
UT WOS:000354493000019
DA 2024-07-18
ER

PT J
AU Im, DH
   Park, GD
AF Im, Dong-Hyuk
   Park, Geun-Duk
TI Linked tag: image annotation using semantic relationships between image
   tags
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image annotation; Image retrieval; RDF; Ontology; SPARQL; Tag ranking
ID WEB
AB State of the art image tagging systems are limited because they allow users to annotate image tags in noun form, which cannot fully express the semantics of image content. In this paper, we propose Linked Tag, a semi-automatic image annotation system that inserts semantic relationships between tags. The proposed annotation method connects image tags using predicate words that can capture the contexts in which the image tags are used. In particular, we exploit Linked Data such as DBPedia in order to connect the image tags with a property value. Compared with tag-based annotation and ontology-based annotation systems, Linked Tag eliminates a large amount of manual labor and enhances the semantic expression of image content. We also introduce two annotation-based applications on Linked Tag. First, we propose SPARQL query processing for image retrieval, which enables us to express visual appearance as well as semantic information. Second, we propose a novel tag-ranking algorithm based on the link analysis in the RDF annotation graph. Finally, we demonstrate the operation of our proposed system and analyze its efficacy.
C1 [Im, Dong-Hyuk; Park, Geun-Duk] Hoseo Univ, Dept Comp & Informat Engn, Asan 336795, Chungnam, South Korea.
C3 Hoseo University
RP Park, GD (corresponding author), Hoseo Univ, Dept Comp & Informat Engn, 20 Hoseo Roigil, Asan 336795, Chungnam, South Korea.
EM dhim@hoseo.edu; gdpark@hoseo.edu
FU National Research Foundation of Korea (NRF) - Korea government (MEST)
   [NRF-2009-0078828]
FX This work was supported by a National Research Foundation of Korea (NRF)
   grant funded by the Korea government (MEST) (No. NRF-2009-0078828).
CR [Anonymous], 2008, W3C RECOMMENDATION
   [Anonymous], 2012, Proceedings of the 21st International Conference on World Wide Web
   Bizer C, 2009, INT J SEMANT WEB INF, V5, P1, DOI 10.4018/jswis.2009081901
   Bizer C, 2009, J WEB SEMANT, V7, P154, DOI 10.1016/j.websem.2009.07.002
   Carroll J, 2011, J WEB SEMANT, V3, P247
   Fadzli SA, 2010, LECT NOTES ARTIF INT, V6279, P240, DOI 10.1007/978-3-642-15384-6_26
   Hollink L., 2003, KNOWLEDGE CAPTURE, P41
   Im D-H, 2013, P IEEE ICISA PATT, P571
   Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418
   Jeong JW, 2013, MULTIMED TOOLS APPL, V62, P451, DOI 10.1007/s11042-011-0903-1
   Khan L, 2007, COMPUT STAND INTER, V29, P196, DOI 10.1016/j.csi.2006.03.006
   Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140
   Klyne G, 2004, Resource description framework (RDF): Concepts and abstract syntax
   Lee K., 2008, P 17 INT C WORLD WID, P1093, DOI DOI 10.1145/1367497.1367672
   Lee SH, 1997, ICICS - PROCEEDINGS OF 1997 INTERNATIONAL CONFERENCE ON INFORMATION, COMMUNICATIONS AND SIGNAL PROCESSING, VOLS 1-3, P1069, DOI 10.1109/ICICS.1997.652145
   Lindstaedt S, 2009, MULTIMED TOOLS APPL, V42, P97, DOI 10.1007/s11042-008-0247-7
   MAGESH N, 2011, INT J COMPUTER APPL, V1, P12
   Overell S., 2009, Proceedings of WSDM 2009, P64
   Sun AX, 2011, J AM SOC INF SCI TEC, V62, P2364, DOI 10.1002/asi.21659
   Toupikov N, 2009, P WWW 2009 WORKSH LI
   Van Lancker W, 2013, MULTIMED TOOLS APPL, V63, P7, DOI 10.1007/s11042-012-1032-1
   [杨健茂 YANG Jianmao], 2007, [高分子通报, Polymer Bulletin], P14
   Yeung CMA, 2009, 20TH ACM CONFERENCE ON HYPERTEXT AND HYPERMEDIA (HYPERTEXT 2009), P251
   Zhang XM, 2013, MULTIMED TOOLS APPL, V62, P601, DOI 10.1007/s11042-011-0863-5
NR 24
TC 20
Z9 23
U1 2
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 7
BP 2273
EP 2287
DI 10.1007/s11042-014-1855-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE0TU
UT WOS:000351520200006
DA 2024-07-18
ER

PT J
AU Jung, JJ
   Kim, JY
   Chung, HS
   Shin, PS
AF Jung, Jong-Jin
   Kim, Ji-Yeon
   Chung, Hyun-Sook
   Shin, Pan-Seop
TI An intuitive user interaction method using multi-sensors for pencil
   drawing filter of NPR rendering in mobile devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-photorealistic rendering; Pencil drawing filter; Enhanced LIC;
   Orientation sensor; Light sensor
AB The user interface is one of the most important factors to use various functions of mobile device easily. Recently, the importance of the user interface has been increased after Apple emphasized emotional UX(User eXperience) by applying multi-touches to iPhone. Mobile device Manufacturers have tried to apply embedded sensors to apps as user interface. Microphone was applied to execute functions combined with voice recognition and GPS sensor was used to find a location in navigation apps or game apps. Like these services, several sensors have roles of interface between user and device. In this paper, we propose an intuitive user interaction method using multi-sensors in NPR(Non-Photorealistic) rendering. The proposed method renders pencil drawing filter for a given photo image with the direction and strength of line strokes which are applied in vector fields. At this point, the method changes direction of stroke with x-coordinate values and y-coordinate values and control the strength of the stroke with z-coordinate values after catching three coordinate values in real-time from the orientation sensor on a mobile device. The method also adjusts brightness of image by transforming intensity of light from the light sensor. The light sensor updates intensity of light source continuously. If the user brings the mobile device closer to the external light source, the light sensor value will increase and the intensity of brightness becomes stronger. In addition, the user can make an attenuation effect with orientation sensor combined with light sensor for specific scope in a photo image and change the attenuation scope by moving action of his holding mobile device. This is a user interaction method for emotional image processing using sensors in mobile devices. We developed an app which generated pencil drawing filter effect for a photo image. We experimented sensor based emotional user interaction and compared various results of image processing effects using two combinatorial sensors. Finally, this paper proved efficiency through the experimental results and evaluated the effectiveness of the proposed method.
C1 [Jung, Jong-Jin; Kim, Ji-Yeon; Shin, Pan-Seop] Daejin Univ, Dept Comp Engn, Pochon, South Korea.
   [Chung, Hyun-Sook] Chosun Univ, Dept Comp Engn, Kwangju, South Korea.
C3 Daejin University; Chosun University
RP Shin, PS (corresponding author), Daejin Univ, Dept Comp Engn, Pochon, South Korea.
EM jjjung@daejin.ac.kr; jini_69@naver.com; hsch@chosun.ac.kr;
   psshin@daejin.ac.kr
OI Kim, Ji Yeon/0000-0001-7964-5060
CR [Anonymous], 2010, MOB DEV US INT
   Kim J, 2011, CHOSUNBIZ ARTICLE
   Kim Y, 2012, ETRI ELECT TELECOMMU
   KT AIT, 2010, TECHN HOT ISS
   Lee H, 2011, ETRI ELECT TELECOMMU, V26
   Lim C, 2010, EMOTION ICT IND STAT
   Ma Jang-yeol, 2005, [Journal of the Korea Computer Graphics Society, 한국컴퓨터그래픽스학회논문지], V11, P8
   Mao XY, 2001, CAD/GRAPHICS '2001: PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON COMPUTER AIDED DESIGN AND COMPUTER GRAPHICS, VOLS 1 AND 2, P240
   Morgan JP, 2010, MOBILE ADVERTISING D
   Na Y, 2012, TOUCH BASED SMART TE
   Next- Generation Interfaces, 2011, FUT UI NEEDS R D STR
   Yamamoto S, 2004, I C COMP GRAPH IM VI, P251, DOI 10.1109/CGIV.2004.1323994
   Yong H- j, 2006, P IICI SOC KOREA, P88
   김은길, 2011, [JOURNAL OF The Korean Association of information Education, 정보교육학회논문지], V15, P439
NR 14
TC 1
Z9 2
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 7
BP 2371
EP 2389
DI 10.1007/s11042-014-2054-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE0TU
UT WOS:000351520200012
DA 2024-07-18
ER

PT J
AU Kim, CK
   Chung, K
   Kim, Y
   Lee, KD
AF Kim, Chun-Kon
   Chung, Kyungyong
   Kim, Younjung
   Lee, Kang-Dae
TI The effects of transportation energy policy on fuel consumption and
   transportation safety
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Transportation energy; Policy simulation; Two-vehicle crashes; Traffic
   safety; Pay-as-you-drive (PAYD); Pay-at-the-pump (PATP); Corporate
   average fuel economy (CAFE); VMT tax; Fuel tax
ID AUTOMOBILE SAFETY; ECONOMY; TRUCKS
AB This paper examined the impact of transportation energy policies on traffic safety through policy simulations. Considering the changes in the vehicle miles traveled (VMT) and in vehicle stock composition as a result of policy changes, the impacts of these changes on traffic accidents were examined in terms of the number of traffic accidents, traffic fatalities, and total accident costs. The main focus was on the following policy alternatives: Fuel tax, mileage based a VMT tax, Pay-as-you-drive (PAYD) and Pay-at-the-pump (PATP) insurance premium policy, and the Corporate Average Fuel Economy (CAFE) standards regulations. By integrating three interrelated economic demand decisions fully (size of the vehicle stock, use of the vehicle stock, and energy efficiency), the short-run, long-run and dynamic effects of a policy change can be predicted. The results showed that the share of light trucks will keep increasing in the future in all policy alternatives and that fuel consumption will decrease compared to the baseline in every scenario except for the VMT tax policy. The results also show that the fatality rates per vehicle miles traveled will decrease, but the CAFE policy will result in more fatalities and higher fatality rates compared to the baseline scenario. The results may provide guidance as to what would reduce the energy dependency while reducing the undesirable side effects related to traffic safety. The outcomes of this research will provide a set of specific results comparing policy scenarios in a consistent manner. The results will provide guidance as to whether the policy option would improve energy dependency while reducing the undesirable side effects, such as the problems related to the environment and the safety of motor vehicle travel.
C1 [Kim, Chun-Kon] Korea Inst Ind Econ & Trade KIET, Seoul 130742, South Korea.
   [Chung, Kyungyong] Sangji Univ, Sch Comp Informat Engn, Wonju 220702, Gangwon Do, South Korea.
   [Kim, Younjung; Lee, Kang-Dae] Yonsei Univ, Dept Packaging, Wonju, Gangwon Do, South Korea.
C3 Korea Institute for Industrial Economics & Trade (KIET); Sangji
   University; Yonsei University
RP Lee, KD (corresponding author), Yonsei Univ, Dept Packaging, 1 Yonseidae Gil, Wonju, Gangwon Do, South Korea.
EM ceekay@kiet.re.kr; kyungyong.chung@gmail.com; timiotera@gmail.com;
   pimeson@yonsei.ac.kr
RI Chung, Kyungyong/JAC-2276-2023
CR Ahmad S, 2005, TRANSPORT RES REC, P1
   Brozovic N, 2005, WORKING PAPER
   Busse M, 2008, U CAL EN I UCEI
   CRANDALL RW, 1989, J LAW ECON, V32, P97, DOI 10.1086/467170
   EVANS L, 1984, ACCIDENT ANAL PREV, V16, P387, DOI 10.1016/0001-4575(84)90052-6
   Evans L., 2004, TRAFFIC SAF
   FHWA, 2004, HIGHW STAT
   Godek PE, 1997, J LAW ECON, V40, P495, DOI 10.1086/467381
   GORDON P, 1986, ENVIRON PLANN A, V18, P161, DOI 10.1068/a180161
   National Highway Traffic Safety Administration (NHTSA), 2005, TRAFF SAF FACTS 2004
   *NHTSA, 2002, EC IMP MOT VEH CRASH
   Noland RB, 2005, ENERG POLICY, V33, P2183, DOI 10.1016/j.enpol.2004.04.016
   Parry IWH, 2004, 0453 RES FUT
   Ross M, 2001, LBNL48009 ACEEE
   Small K.A., 2005, A Study to Evaluate the Effect of Reduce Greenhouse Gas Emissions on Vehicle Miles Travelled
   Small KA, 2007, ENERG J, V28, P25
   U. S. EPA, 2005, EPA420F05004
   White MJ, 2004, J LAW ECON, V47, P333, DOI 10.1086/422979
NR 18
TC 3
Z9 4
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 7
BP 2535
EP 2557
DI 10.1007/s11042-014-1974-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA CE0TU
UT WOS:000351520200022
DA 2024-07-18
ER

PT J
AU Lee, CM
AF Lee, Chang-Moo
TI Criminal profiling and industrial security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Criminal profiling; Industrial security; Information security;
   Industrial espionage; Investigation; Investigative mining
AB Criminal profiling' may provide an effective measure for industrial security. While criminal profiling has been frequently applied to support the prevention and investigation of crimes, particularly violent crimes, it has not been applied to industrial espionage. Criminal profiling such as behavioral and investigative data profiling could help to identify the criminals leaking the secrets. The application of criminal profiling may contribute to prevent and reduce industrial espionage. The purpose of this study is, therefore, to attempt to apply criminal profiling to industrial security and eventually prevent and control industrial espionage.
C1 Hannam Univ, Dept Police Adm Criminal Justice, Taejon 306791, South Korea.
C3 Hannam University
RP Lee, CM (corresponding author), Hannam Univ, Dept Police Adm Criminal Justice, Taejon 306791, South Korea.
EM jbalanced@gmail.com
CR Alison L, 2002, PSYCHOL PUBLIC POL L, V8, P115, DOI 10.1037//1076-8971.8.1.115
   Bartol CR, 2003, CRIMINAL BEHAV PSYCH
   Bumgarner J, 2004, PROFILING CRIMINAL J
   Davis BJ, 2007, CRIME SCENE SCI CRIM
   Douglas J.E., 2006, CRIME CLASSIFICATION, V2nd
   Girod R., 2004, Profiling the criminal mind - behavioral science and criminal investigative analysis
   Hicks ScotiaJ., 2006, Criminal profiling: Developing an effective science and practice
   Holmes R.M., 2002, PROFILING VIOLENT CR, V3rd
   Mena J., 2003, Investigative Data Mining for Security and Criminal Detection
   NIS (National Intelligence Service), 2009, CURR TRENDS HIGH TEC, V10
   Park Kwangbai, 2002, [Korean Journal of Psychology: General, 한국심리학회지:일반], V21, P1
   Pinzzotto AJ, 1990, LAW HUMAN BEHAV, V14, P215
   Rider A, 1980, FBI LAW ENFORCEMENT, V49, P12
   Seifert J.W., 2007, Data mining and homeland security: An overview
   Turvey B., 2005, Criminal profiling: An introduction to behavioral evidence analysis
NR 15
TC 3
Z9 6
U1 2
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 5
BP 1689
EP 1696
DI 10.1007/s11042-014-2014-2
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CC7UC
UT WOS:000350572900010
DA 2024-07-18
ER

PT J
AU Bai, C
   Zhang, JL
   Liu, Z
   Zhao, WL
AF Bai, Cong
   Zhang, Jinglin
   Liu, Zhi
   Zhao, Wan-Lei
TI K-means based histogram using multiresolution feature vectors for color
   texture database retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color texture retrieval; K-means; Discrete wavelet transform (DWT);
   Z-score normalization
ID IMAGE RETRIEVAL; CLASSIFICATION
AB Colorand texture are two important features in content-based image retrieval. It has been shown that using the combination of both could provide better performance. In this paper, a K-means based histogram (KBH) using the combination of color and texture features for image retrieval is proposed. Multiresolution feature vectors representing color and texture features are directly generated from the coefficients of Discrete Wavelet Transform (DWT), and K-means is exploited to partition the vector space with the objective to reduce the number of histogram bins. Thereafter, a fusion of z-score normalized Chi-Square distance between KBHs is employed as the similarity measure. Experiments have been conducted on four natural color texture data sets to examine the sensitivity of KBH to its parameters. The performance of the proposed approach has been compared with state-of-the-art approaches. Results evaluated in terms of Precision-Recall and Average Retrieval Rate (ARR) show that our approach outperforms the referred approaches.
C1 [Bai, Cong] Zhejiang Univ Technol, Coll Comp Sci, Hangzhou 310023, Zhejiang, Peoples R China.
   [Zhang, Jinglin] Univ Europeenne Bretagne, INSA Rennes, IETR UMR CNRS 6164, Rennes, France.
   [Liu, Zhi] Shanghai Univ, Sch Commun & Informat Engn, Shanghai, Peoples R China.
   [Liu, Zhi] IRISA INRIA Rennes, Rennes, France.
   [Zhao, Wan-Lei] INRIA Rennes, Rennes, France.
C3 Zhejiang University of Technology; Institut National des Sciences
   Appliquees de Rennes; Universite de Rennes; Universite de Bretagne
   Occidentale; Shanghai University; Universite de Rennes; Universite de
   Rennes
RP Bai, C (corresponding author), Zhejiang Univ Technol, Coll Comp Sci, Hangzhou 310023, Zhejiang, Peoples R China.
EM congbai@zjut.edu.cn
RI LIU, Zhi/D-4518-2012; Bai, Cong/T-9188-2019
OI LIU, Zhi/0000-0002-8428-1131; Bai, Cong/0000-0002-6177-3862
FU National Natural Science Foundation of China [61171144]; Chinese
   Ministry of Education [212053]; Shanghai Municipal Education Commission
   [12ZZ086]
FX This work was supported by National Natural Science Foundation of China
   under Grant No. 61171144, the Key (Key grant) Project of Chinese
   Ministry of Education (No. 212053), and the Innovation Program of
   Shanghai Municipal Education Commission (No. 12ZZ086)
CR Alajlan N, 2008, IEEE T PATTERN ANAL, V30, P1003, DOI 10.1109/TPAMI.2008.37
   Alvarez S, 2012, COMPUT VIS IMAGE UND, V116, P54, DOI 10.1016/j.cviu.2011.08.004
   [Anonymous], P SPIE
   Bai C, 2012, ELECTRON LETT, V48, P1463, DOI 10.1049/el.2012.2656
   Burghouts GJ, 2009, PATTERN RECOGN LETT, V30, P306, DOI 10.1016/j.patrec.2008.10.005
   Chen T, 1998, IEEE 2 WORKSH MULT S
   Chun YD, 2003, IEEE T CIRC SYST VID, V13, P951, DOI 10.1109/TCSVT.2003.816507
   Chun YD, 2008, IEEE T MULTIMEDIA, V10, P1073, DOI 10.1109/TMM.2008.2001357
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   James SW, 2007, PRIMER WAVELETS THEI
   Kwitt R., 2012, SALZBURG TEXTURE IMA
   Kwitt R, 2011, IEEE T IMAGE PROCESS, V20, P2063, DOI 10.1109/TIP.2011.2108663
   Kwitt R, 2010, IEEE T IMAGE PROCESS, V19, P241, DOI 10.1109/TIP.2009.2032313
   Lee YB, 2012, PATTERN RECOGN LETT, V33, P904, DOI 10.1016/j.patrec.2011.08.022
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lumini A, 2000, 15 INT C PATT REC, V4
   Mäenpää T, 2004, PATTERN RECOGN, V37, P1629, DOI 10.1016/j.patcog.2003.11.011
   MIT, 2010, VIST DAT TEXT
   Müller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   Ngo CW, 2001, PATTERN RECOGN, V34, P1841, DOI 10.1016/S0031-3203(00)00111-4
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Permuter H, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P569
   Picard R, 1993, IEEE INT C COMP VIS
   Poursistani P, 2011, MATH COMP MODEL
   Qi H, 2010, PATTERN RECOGN, V43, P2017, DOI 10.1016/j.patcog.2010.01.007
   Rafiee G, 2010, 7 INT S COMM SYST NE
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Theoharatos C, 2006, PATTERN RECOGN, V39, P1892, DOI 10.1016/j.patcog.2006.04.015
   Tian Y, 2003, 5 INT C COMP INT MUL
   Vellaikal A, 1996, P INT C IM PROC, V3
   Verdoolaege G, 2008, 15 IEEE INT C IM PRO
   Wang X., 2012, MATER RES LETT, P1, DOI [DOI 10.1007/S11046-011-9484-9, 10.1155/2012/460430, DOI 10.1155/2012/460430]
   Wang XY, 2013, COMPUT ELECTR ENG, V39, P746, DOI 10.1016/j.compeleceng.2013.01.005
   Yu H, 2002, P IEEE INT C IM PROC
   Yue J, 2011, MATH COMPUT MODEL, V54, P1121, DOI 10.1016/j.mcm.2010.11.044
   Zhong D, 2005, PATTERN RECOGN LETT, V26, P2272, DOI 10.1016/j.patrec.2005.04.012
NR 41
TC 11
Z9 11
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 4
BP 1469
EP 1488
DI 10.1007/s11042-014-2053-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZN
UT WOS:000349356300016
DA 2024-07-18
ER

PT J
AU Roy, A
   Bredin, H
   Hartmann, W
   Le, VB
   Barras, C
   Gauvain, JL
AF Roy, Anindya
   Bredin, Herve
   Hartmann, William
   Viet Bac Le
   Barras, Claude
   Gauvain, Jean-Luc
TI Lexical speaker identification in TV shows
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lexical speaker identification; Broadcast conversations; TFIDF; BM25;
   Speaker roles; Classifier fusion; Crossmedia learning; Wikipedia
AB It is possible to use lexical information extracted from speech transcripts for speaker identification (SID), either on its own or to improve the performance of standard cepstral-based SID systems upon fusion. This was established before typically using isolated speech from single speakers (NIST SRE corpora, parliamentary speeches). On the contrary, this work applies lexical approaches for SID on a different type of data. It uses the REPERE corpus consisting of unsegmented multiparty conversations, mostly debates, discussions and Q&A sessions from TV shows. It is hypothesized that people give out clues to their identity when speaking in such settings which this work aims to exploit. The impact on SID performance of the diarization front-end required to pre-process the unsegmented data is also measured. Four lexical SID approaches are studied in this work, including TFIDF, BM25 and LDA-based topic modeling. Results are analysed in terms of TV shows and speaker roles. Lexical approaches achieve low error rates for certain speaker roles such as anchors and journalists, sometimes lower than a standard cepstral-based Gaussian Supervector - Support Vector Machine (GSV-SVM) system. Also, in certain cases, the lexical system shows modest improvement over the cepstral-based system performance using score-level sum fusion. To highlight the potential of using lexical information not just to improve upon cepstral-based SID systems but as an independent approach in its own right, initial studies on crossmedia SID is briefly reported. Instead of using speech data as all cepstral systems require, this approach uses Wikipedia texts to train lexical speaker models which are then tested on speech transcripts to identify speakers.
C1 [Roy, Anindya; Bredin, Herve; Hartmann, William; Barras, Claude] LIMSI CNRS, Orsay, France.
   [Gauvain, Jean-Luc] LIMSI CNRS, Spoken Language Proc Grp, Orsay, France.
   [Viet Bac Le] Vocapia Res, Orsay, France.
C3 Universite Paris Saclay; Centre National de la Recherche Scientifique
   (CNRS); Centre National de la Recherche Scientifique (CNRS); Universite
   Paris Saclay
RP Roy, A (corresponding author), LIMSI CNRS, Orsay, France.
EM roy@limsi.fr; bredin@limsi.fr; hartmann@limsi.fr; levb@vocapia.com;
   barras@limsi.fr; gauvain@limsi.fr
OI Hartmann, William/0000-0003-1678-3399
FU OSEO (French State agency for innovation); ANR (French national research
   agency)
FX The authors would like to thank Lori Lamel for providing the alignments
   for the mmAM configuration, and Francois Yvon, Sophie Rosset, Sylvain
   Meignier and the anonymous reviewers for their helpful comments and
   advice. This work was partly realized as part of the Quaero Program and
   the QCompere project, respectively funded by OSEO (French State agency
   for innovation) and ANR (French national research agency).
CR Alam MJ, 2013, SPEECH COMMUN, V55, P237, DOI 10.1016/j.specom.2012.08.007
   [Anonymous], P INTERSPEECH
   Baker B, 2004, P OD
   Barras C, 2006, IEEE T AUDIO SPEECH, V14, P1505, DOI 10.1109/TASL.2006.878261
   Baum D, 2012, SPEECH COMMUN, V54, P1132, DOI 10.1016/j.specom.2012.06.003
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Campbell W., 2003, ADV NEURAL INFO PROC, V16, P1377
   Campbell WM, 2006, IEEE SIGNAL PROC LET, V13, P308, DOI 10.1109/LSP.2006.870086
   Canseco L, 2005, P IEEE WORKSH AUT SP
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Dehak N, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P1527
   Doddington G, 2001, P INT
   Doddington G, 2001, SOME EXPT IDEOLECTAL
   Galibert O, 2013, P WORKSH SPEECH LANG
   Gauvain J.-L., 1998, P ICSLP, P1335
   Gauvain JL, 2000, P TREC 9
   Giraudel A, 2012, P LANG RES EV C LREC
   Kajarekar SS, 2005, P IEEE INT C AC SPEE
   Khan A, 2004, P INT C SPOK LANG PR
   Kinnunen T, 2010, SPEECH COMMUN, V52, P12, DOI 10.1016/j.specom.2009.08.009
   Lamel L, 2011, P IWSLT
   Le VB, 2010, ODYSSEY 2010: THE SPEAKER AND LANGUAGE RECOGNITION WORKSHOP, P146
   Manning Christopher D., 2008, INTRO INFORM RETRIEV
   Mauclair J, 2006, P OD
   McCallum A.K., 2002, MALLET MACHINE LEARN
   Plchot O, 2013, P IEEE INT C AC SPEE
   Shriberg Elizabeth, 2007, Speaker Classification I. Fundamentals, Features, and Methods. (Lecture Notes in Artificial Intelligence vol. 4343), P241, DOI 10.1007/978-3-540-74200-5_14
   Sparck-Jones K, 2000, INFORM PROCESS MANAG, V36, P779, DOI 10.1016/S0306-4573(00)00015-7
   Tranter S, 2006, P IEEE INT C AC SPEE
   Tur G, 2007, P INT
NR 30
TC 1
Z9 1
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 4
BP 1377
EP 1396
DI 10.1007/s11042-014-1940-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZN
UT WOS:000349356300012
DA 2024-07-18
ER

PT J
AU Choi, JW
   Whangbo, TK
   Kim, CG
AF Choi, Jin Woo
   Whangbo, Taeg Keun
   Kim, Cheong Ghil
TI A contour tracking method of large motion object using optical flow and
   active contour model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object contour tracking; Optical flow; Active contour model; 2D-to-3D
AB In this study, an object contour tracking method is proposed for an object with large motion and irregular shape in image sequence. To track object contour accurately, an active contour model was used, and the initial snake point of the next frame is set by defining feature points with changing curvature in the object tracked from the previous frame and calculating an optical flow at the location. Here, any misled optical flow due to irregular changes in shape or fast motion was filtered by producing a difference edge map from the previous frame, and as a solution to the energy shortage of objects with complex contour, a method of adding snake points by partial curvature was applied. Findings from experiments with real image sequence showed that the contour of an object with large motion and irregular shapes was extracted in a relatively precise way.
C1 [Choi, Jin Woo] Gachon Univ, Culture Technol Inst, Songnam, Gyeonggi, South Korea.
   [Whangbo, Taeg Keun] Gachon Univ, Dept Interact Media, Songnam, South Korea.
   [Kim, Cheong Ghil] Namseoul Univ, Dept Comp Sci, Cheonan, Choongnam, South Korea.
C3 Gachon University; Gachon University; Namseoul University
RP Choi, JW (corresponding author), Gachon Univ, Culture Technol Inst, San 65, Songnam, Gyeonggi, South Korea.
EM cjw49@paran.com; tkwhangbo@gachon.ac.kr; cgkim@nsu.ac.kr
FU Ministry of Culture, Sports and Tourism(MCST); Korea Creative Content
   Agency(KOCCA) in the Culture Technology(CT) Research & Development
   Program
FX This research is supported by Ministry of Culture, Sports and
   Tourism(MCST) and Korea Creative Content Agency(KOCCA) in the Culture
   Technology(CT) Research & Development Program.
CR Javed O, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P952
   김대희, 2007, [Signal Processing, 전자공학회논문지 - SP], V44, P64
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   김재광, 2011, [Signal Processing, 전자공학회논문지 - SP], V48, P33
   Lee JH, 2009, THESIS PAICHAI U
   Lee JW, 2000, IEEE WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P161, DOI 10.1109/OMNVIS.2000.853824
   Lee YS, 2011, MAG I ELECT ENG KORE, V38, P37
   LEYMARIE F, 1993, IEEE T PATTERN ANAL, V15, P617, DOI 10.1109/34.216733
   Li B, 2006, P IEEE INT C SIGN PR, V2, P16, DOI [10.1109/ICOSP.2006.345658, DOI 10.1109/ICOSP.2006.345658]
   Li Y, 2005, ACM T GRAPHIC, V24, P595, DOI 10.1145/1073204.1073234
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Okino T, 1996, P SOC PHOTO-OPT INS, V2653, P96, DOI 10.1117/12.237421
   Pi L, 2007, J MATH IMAGING VIS, V27, P51, DOI 10.1007/s10851-006-9797-3
   Xiong B, 2004, P INT C IMAGE PROCES, V2, P1024, DOI [10.1109/ICIP.2004.1419475, DOI 10.1109/ICIP.2004.1419475]
   Xu CY, 1997, PROC CVPR IEEE, P66, DOI 10.1109/CVPR.1997.609299
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 16
TC 9
Z9 12
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 1
BP 199
EP 210
DI 10.1007/s11042-013-1756-6
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ6UP
UT WOS:000348356300013
DA 2024-07-18
ER

PT J
AU Jang, YT
   Chang, SE
   Chen, PA
AF Jang, Yu-Teng
   Chang, Shuchih Ernest
   Chen, Po-An
TI Exploring social networking sites for facilitating multi-channel
   retailing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social networking sites (SNS); Multi-channel retailing; Electronic
   commerce; Partial least squares (PLS)
ID E-COMMERCE; TRUST; MODEL; LOYALTY; VIEW
AB This study aims to explore how social networking sites (SNS) can be used to influence consumer behavior in the context of multi-channel retailing. A research framework with ten hypotheses was proposed to study important relationships between various consumer behaviors related to trust on physical stores, access to SNS fan pages, physical-store purchase, online information search, and online purchase. An empirical test was conducted by using PLS, a second-generation multivariate analysis tool, to analyze survey data collected from 205 SNS users. Our findings revealed that consumers' intention to online information search would significantly influence their intention to online purchase. Trust on physical stores would affect consumers' attitudes toward not only purchasing at physical-store but also joining retailers' SNS fan pages. In addition, attitude toward joining SNS fan pages was found to affect consumers' intention to online information search and physical-store purchasing. Moreover, consumers' physical-store purchasing would also affect their intention to related online information search. Based on the validated research model and corresponding findings, retail managers are suggested to use SNS fan pages to enhance consumers' purchase at physical stores and information search on their online stores, thus increasing overall sales. Retail managers should build and maintain consumer trust on their stores, since such trust significantly affects consumers' attitude to access SNS fan pages.
C1 [Jang, Yu-Teng] Natl Chung Hsing Univ, Dept Business Adm, Taichung 40227, Taiwan.
   [Chang, Shuchih Ernest; Chen, Po-An] Natl Chung Hsing Univ, Inst Technol Management, Taichung 40227, Taiwan.
C3 National Chung Hsing University; National Chung Hsing University
RP Chang, SE (corresponding author), Natl Chung Hsing Univ, Inst Technol Management, Taichung 40227, Taiwan.
EM junnbee_cheung@yahoo.com.tw; eschang@dragon.nchu.edu.tw;
   brian@dukebrian.net
RI Chang, Shuchih Ernest/ABB-8754-2020
FU National Science Council, Taiwan [NSC-99-2221-E-005-058-MY3]
FX This work was supported by the National Science Council, Taiwan, under
   contract number NSC-99-2221-E-005-058-MY3.
CR [Anonymous], SMARTPLS 2 0 M3 BETA
   [Anonymous], 2006, WEB 2 0 PRINCIPLES B
   Bagge D, 2007, EUR RETAIL DIG, V53, P57
   Barclay D., 1995, TECHNOL STUDIES, V2, P285
   Bhattacherjee A, 2002, J MANAGE INFORM SYST, V19, P211
   Boyd DM, 2007, J COMPUT-MEDIAT COMM, V13, P210, DOI 10.1111/j.1083-6101.2007.00393.x
   Checkfacebook.com, 2011, FAC MARK STAT DEM RE
   Cheung CMK, 2010, DECIS SUPPORT SYST, V49, P24, DOI 10.1016/j.dss.2009.12.006
   Chi HH., 2011, Journal of interactive advertising, V12, P44, DOI DOI 10.1080/15252019.2011.10722190
   Chin WW, 2003, INFORM SYST RES, V14, P189, DOI 10.1287/isre.14.2.189.16018
   Coelho F, 2008, J RETAIL CONSUM SERV, V15, P32, DOI 10.1016/j.jretconser.2007.03.002
   CROSBY LA, 1990, J MARKETING, V54, P68, DOI 10.2307/1251817
   Doney PM, 1998, ACAD MANAGE REV, V23, P601, DOI 10.2307/259297
   Doong HS, 2011, INT J INFORM MANAGE, V31, P210, DOI 10.1016/j.ijinfomgt.2010.06.006
   Drury G., 2008, J DIRECT DATA DIGITA, V9, P274, DOI [DOI 10.1057/PALGRAVE.DDDMP.4350096, 10.1057/palgrave.dddmp.4350096]
   Durrani A, 2010, MARKETING NEWS
   Enders Albrecht, 2008, European Management Journal, V26, P199, DOI 10.1016/j.emj.2008.02.002
   Evans PF, 2010, US W EUROPEAN ONLINE
   Facebook.com, 2011, NON IKEA FAN PAG FAC
   Fishbein Martin., 1975, Attitude, Intention and Behavior: An Introduction to Theory and Research
   FORNELL C, 1981, J MARKETING RES, V18, P39, DOI 10.2307/3151312
   Gefen D, 2003, MIS QUART, V27, P51, DOI 10.2307/30036519
   Gefen D, 2000, OMEGA-INT J MANAGE S, V28, P725, DOI 10.1016/S0305-0483(00)00021-9
   Gefen D, 2005, COMMUN ASSOC INF SYS, V16, P91, DOI 10.17705/1CAIS.01605
   Hahn KH, 2009, INT J RETAIL DISTRIB, V37, P126, DOI 10.1108/09590550910934272
   Harridge-March S, 2006, MARK INTELL PLAN, V24, P746, DOI 10.1108/02634500610711897
   Hoffman DL, 1999, COMMUN ACM, V42, P80, DOI 10.1145/299157.299175
   Hsieh JJPA, 2008, MIS QUART, V32, P97
   Kaplan AM, 2010, BUS HORIZONS, V53, P59, DOI 10.1016/j.bushor.2009.09.003
   Kassim NM, 2009, MEAS BUS EXCELL, V13, P56, DOI 10.1108/13683040910943054
   Keenan A, 2009, LIBR REV, V58, P438, DOI 10.1108/00242530910969794
   Kietzmann JH, 2011, BUS HORIZONS, V54, P241, DOI 10.1016/j.bushor.2011.01.005
   Kim J, 2005, J FASH MARK MANAG, V9, P106, DOI 10.1108/13612020510586433
   Kim S, 2010, COMMUN ACM, V53, P136, DOI 10.1145/1629175.1629208
   Kim Y, 2011, COMPUT HUM BEHAV, V27, P365, DOI 10.1016/j.chb.2010.08.015
   Lee HH, 2008, J FASH MARK MANAG, V12, P193, DOI 10.1108/13612020810874881
   Lee KC, 2007, IEEE T ENG MANAGE, V54, P729, DOI 10.1109/TEM.2007.906851
   Lu YB, 2010, ELECTRON COMMER R A, V9, P346, DOI 10.1016/j.elerap.2009.07.003
   Meyer-Waarden L, 2008, EUR J MARKETING, V42, P87, DOI 10.1108/03090560810840925
   MOORMAN C, 1992, J MARKETING RES, V29, P314, DOI 10.1177/002224379202900303
   MORGAN RM, 1994, J MARKETING, V58, P20, DOI 10.2307/1252308
   Müller-Lankenau C, 2005, INT J ELECTRON COMM, V10, P85, DOI 10.2753/JEC1086-4415100204
   Ojala Arto, 2011, Journal of Business Strategy, V32, P40, DOI 10.1108/02756661111180122
   Osarenkhoe A, 2007, BUS PROCESS MANAG J, V13, P139, DOI 10.1108/14637150710721177
   Otto JamesR., 2000, ELECTRON MARK, V10, P185, DOI DOI 10.1080/10196780050177099
   Patterson A, 2012, J BUS RES, V65, P527, DOI 10.1016/j.jbusres.2011.02.032
   Pavlou PA, 2004, INFORM SYST RES, V15, P37, DOI 10.1287/isre.1040.0015
   Riegelsberger J, 2003, INT J HUM-COMPUT ST, V58, P759, DOI 10.1016/S1071-5819(03)00042-9
   Rousseau DM, 1998, ACAD MANAGE REV, V23, P393, DOI 10.5465/AMR.1998.926617
   Schröder H, 2008, J RETAIL CONSUM SERV, V15, P452, DOI 10.1016/j.jretconser.2008.01.001
   Shea B, 2008, AIIM E DOC MAGAZINE, V22
   Shim S, 2001, J RETAILING, V77, P397, DOI 10.1016/S0022-4359(01)00051-3
   Smith T., 2009, International Journal of Market Research, V51, P559
   Starbucks, 2011, STARB FAN PAG FAC
   Tenenhaus M, 2005, COMPUT STAT DATA AN, V48, P159, DOI 10.1016/j.csda.2004.03.005
   Venkatesan R, 2007, J MARKETING, V71, P114, DOI 10.1509/jmkg.71.2.114
   Wallace DW, 2004, J RETAILING, V80, P249, DOI 10.1016/j.jretai.2004.10.002
   Zhou T, 2011, INTERNET RES, V21, P67, DOI 10.1108/10662241111104884
   Zimmer Michael., 2008, First Monday
NR 59
TC 19
Z9 21
U1 1
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 1
BP 159
EP 178
DI 10.1007/s11042-013-1430-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA AZ6UP
UT WOS:000348356300010
DA 2024-07-18
ER

PT J
AU Li, DD
   Jin, H
   Liao, XF
   Yu, J
AF Li, Dingding
   Jin, Hai
   Liao, Xiaofei
   Yu, Jia
TI Improving write amplification in a virtualized and multimedia SSD system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Solid state drive; Virtualization; Write amplification
AB Due to offering fast random-access disk I/O, it appears that solid-state drives (SSD), which is based on NAND flash memory, can suit well with the environment of cloud computing, especially for the cloud providing video streaming services. However, by investigating a practical virtual desktop system, where runs video streaming workloads, we find that importing this kind of SSDs into a virtualized system is not as simple as merely a mechanical replacement. Because a large proportion of disk I/O being included in the video streaming workload is write I/O, the inherent weaknesses of NAND flash memory, write amplification (WA), will be magnified in a guest operating system (OS). Worse, some useful remedies in a native OS become disabled or inefficient due to the interposition of hypervisor layer. This paper describes and analyzes these problems based on a practical virtual desktop system, and then proposes a tailor-made method to relieve them. By evaluating realistic user workloads and several typical benchmarks, the result shows that our method can effectively improve these problems in our virtualized SSD system.
C1 [Li, Dingding; Jin, Hai; Liao, Xiaofei; Yu, Jia] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Serv Comp Technol & Syst Lab, Cluster & Grid Comp Lab, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Li, DD (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Serv Comp Technol & Syst Lab, Cluster & Grid Comp Lab, Wuhan 430074, Peoples R China.
EM dingly.hust@gmail.com
FU China National Natural Science Foundation (NSFC) [61272408, 61133006];
   National High-tech R and D Program of China (863 Program)
   [2012AA010905]; Hubei Funds for Distinguished Young Scientists
   [2012FFA007]
FX This work is supported by China National Natural Science Foundation
   (NSFC) under grants 61272408, 61133006, National High-tech R and D
   Program of China (863 Program) under grant No. 2012AA010905 and Hubei
   Funds for Distinguished Young Scientists under grant No. 2012FFA007.
CR Agrawal Nitin, 2008, P USENIX ANN TECHN C, P57
   [Anonymous], 2011, PROC 9 USENIX C FILE
   [Anonymous], 2010, P 9 USENIX S OP SYST
   [Anonymous], 2012, OPEN SOURCE P2P VIDE
   [Anonymous], 2012, APPL ACCELERATION EN
   [Anonymous], 2009, INTEL SOLID STATE DR
   [Anonymous], 2012, FAST
   Gal E, 2005, ACM COMPUT SURV, V37, P138, DOI 10.1145/1089733.1089735
   Ganger Greg., 2011, The disksim simulation environment
   Ghemawat S., 2003, ACM SIGOPS OPERATING, V37, P29, DOI [DOI 10.1145/945445.945450, DOI 10.1145/1165389.945450, 10.1145/1165389.945450]
   Harter T, 2011, SOSP 11: PROCEEDINGS OF THE TWENTY-THIRD ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P71
   Heeseung Jo, 2009, Euro-Par 2009 Parallel Processing Workshops. HPPC, HeteroPar, PROPER, ROIA, UNICORE, VHPC. Revised Selected Papers, P375
   Hildebrand D, 2011, P 3 C I O VIRT WIOV
   Hu X.-Y., 2009, System and Storage Conference (SYSTOR), DOI DOI 10.1145/1534530.1534544
   Kim S, 2012, P RUNT ENV SYST LAYE
   Le D., 2012, P USENIX C FIL STOR
   Liao XF, 2010, CONCURR COMP-PRACT E, V22, P419, DOI 10.1002/cpe.1500
   Narayanan D, 2009, EUROSYS'09: PROCEEDINGS OF THE FOURTH EUROSYS CONFERENCE, P145
   Rosenblum M., 2011, ACM QUEUE, V9, P30
   Shimpi A, 2010, KINGSTON SSDNOW V 10
   Warfield A, 2005, USENIX ASSOCIATION PROCEEDINGS OF THE GENERAL TRACK: 2005 UNENIX ANNUAL TECHNICAL CONFERENCE, P379
NR 21
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 1
BP 63
EP 83
DI 10.1007/s11042-013-1497-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ6UP
UT WOS:000348356300005
DA 2024-07-18
ER

PT J
AU Soh, J
   Han, B
   Choi, Y
   Park, Y
   Seo, YH
   Yang, HS
AF Soh, Jaemin
   Han, ByungOk
   Choi, Yeongjae
   Park, Youngmin
   Seo, Yong-Ho
   Yang, Hyun S.
TI Automatic registration of a virtual experience space with Kinect
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic registration; Camera calibration; Virtual spaces; Kinect
ID CAMERA CALIBRATION
AB The popularization of virtual experience spaces involves several difficulties, and this paper focuses on part of them-additional equipment removal and cumbersome initialization process lightening. In this paper, a new automated initialization method to replace the traditional initialization process is proposed using the Kinect sensor, an affordable three-dimensional video capture device. Although the accuracy of this method is lower than that of other methods owing to the limitations of the Kinect sensor, it shows comparable performance under certain assumptions and offers users the opportunity to experience virtual space in a simple, low-cost manner.
C1 [Soh, Jaemin; Han, ByungOk; Choi, Yeongjae; Park, Youngmin; Yang, Hyun S.] Korea Adv Inst Sci & Technol, Dept Comp Sci, Taejon 305701, South Korea.
   [Soh, Jaemin; Han, ByungOk; Choi, Yeongjae; Park, Youngmin; Yang, Hyun S.] Korea Adv Inst Sci & Technol, AIM & Media Lab, Taejon 305701, South Korea.
   [Seo, Yong-Ho] Mokwon Univ, Dept Intelligent Robot Engn, Taejon, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Korea Advanced
   Institute of Science & Technology (KAIST); Mokwon University
RP Seo, YH (corresponding author), Mokwon Univ, Dept Intelligent Robot Engn, Taejon, South Korea.
EM yhseo@mokwon.ac.kr; hsyang@kaist.ac.kr
RI Yang, Hyun Seung/C-1984-2011
FU IT R&D program of MKE KEIT [10041610]; KUSTAR-KAIST Institute, Korea
FX This work was supported by the IT R&D program of MKE & KEIT [10041610,
   The development of the recognition technology for user identity,
   behavior and location that has a performance approaching recognition
   rates of 99% on 30 people by using perception sensor network in the real
   environment]. This research was supported by the KUSTAR-KAIST Institute,
   Korea, under the R&D program supervised by the KAIST.
CR CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   Hartley R, 2004, MULTIPLE VIEW GEOMET, P65
   Herrera CD, 2012, IEEE T PATTERN ANAL, V34, P2058, DOI 10.1109/TPAMI.2012.125
   Khoshelham K, 2011, INT ARCH PHOTOGRAMM, V38-5, P133
   Khoshelham K., 2010, 2010 INT C INDOOR PO, P1
   Scaramuzza D, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P4170, DOI 10.1109/iros.2007.4399276
   SuWoong Lee, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P249, DOI 10.1109/ISMAR.2010.5643591
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   Zhang XG, 2011, PROCEEDINGS OF THE 2011 INTERNATIONAL CONFERENCE ON ENGINEERING AND RISK MANAGEMENT, P1
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 10
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 1
BP 211
EP 226
DI 10.1007/s11042-013-1757-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ6UP
UT WOS:000348356300014
DA 2024-07-18
ER

PT J
AU Lee, SH
   Hwang, WJ
   Kwon, KR
AF Lee, Suk-Hwan
   Hwang, Won-Joo
   Kwon, Ki-Ryong
TI Perceptual 3D model hashing using key-dependent shape feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D model hashing; Authentication; Copy detection; Shape feature
ID WATERMARKING; ROBUST; GEOMETRY
AB With the rapid growth of three-dimensional (3D) content, perceptual 3D model hashing will become a solution for the authentication, reliability, and copy detection of 3D content and will continue to be an important aspect of multimedia security in the future. However, perceptual 3D model hashing has not been used as widely as perceptual image or video hashing. In this study, a robust and secure perceptual 3D model hashing function is developed based on a key-dependent shape feature. The main objectives of our hashing function are to exhibit robustness against content-preserved attacks and to enable blind-detection without the use of preprocessing techniques for these types of attacks. In order to achieve these objectives, our hashing projects all of the vertices to the shape coordinates of the shape spectrum descriptor and the curvedness, and then, it segments the shape coordinates into irregular cells and computes the shape features of the cells using a permutation key and a random key. A perceptual hash is generated by binarizing the shape features. Experimental results confirm that the proposed hashing scheme shows robustness against geometrical and topological attacks and provides a unique and secure hash for each model and key.
C1 [Lee, Suk-Hwan] Tongmyong Univ, Dept Informat Secur, Pusan, South Korea.
   [Hwang, Won-Joo] Inje Univ, Dept Informat Commun Engn, Kimhae, Kyungnam, South Korea.
   [Kwon, Ki-Ryong] Pukyong Natl Univ, Dept IT Convergence & Applicat Engn, Pusan, South Korea.
C3 Tongmyong University; Inje University; Pukyong National University
RP Lee, SH (corresponding author), Tongmyong Univ, Dept Informat Secur, 428 Shinseon Ro, Pusan, South Korea.
EM skylee@tu.ac.kr; ichwang@inje.ac.kr; krkwon@pknu.ac.kr
OI Lee, Suk-Hwan/0000-0003-4779-2888
FU Korea Research Foundation Grant - Korean Government (MEST)
   [KRF-2009-0071269, KRF-2011-0023118]; Brain Busan (BB21) project
FX This work was supported by the Korea Research Foundation Grant funded by
   the Korean Government (MEST) (KRF-2009-0071269 and KRF-2011-0023118) and
   by Brain Busan (BB21) project.
CR Addabbo T, 2007, IEEE T CIRCUITS-I, V54, P816, DOI 10.1109/TCSI.2007.890622
   [Anonymous], 2001, Probability, Random Variables, and Stochas- tic Processes
   Benedens O, 1999, IEEE COMPUT GRAPH, V19, P46, DOI 10.1109/38.736468
   Bober M, 2001, IEEE T CIRC SYST VID, V11, P716, DOI 10.1109/76.927426
   Bustos B, 2005, ACM COMPUT SURV, V37, P345, DOI 10.1145/1118890.1118893
   Bustos B, 2007, IEEE COMPUT GRAPH, V27, P22, DOI 10.1109/MCG.2007.80
   Choi YS, 2012, MULTIMED TOOLS APPL, V61, P181, DOI 10.1007/s11042-010-0724-7
   Coskun B, 2006, IEEE T MULTIMEDIA, V8, P1190, DOI 10.1109/TMM.2006.884614
   De Roover C, 2005, IEEE T SIGNAL PROCES, V53, P4020, DOI 10.1109/TSP.2005.855414
   Delp EJ, 2005, MULTIMEDIA SYST, V11, P95, DOI 10.1007/s00530-005-0193-4
   DURSTENFELD R, 1964, COMMUN ACM, V7, P420, DOI 10.1145/364520.364540
   DYN N, 2000, MATH METHODS CURVES, P135
   Eskizara Omer, 2009, 2009 IEEE 17th Signal Processing and Communications Applications Conference (SIU), P932, DOI 10.1109/SIU.2009.5136550
   Fernandes E, 2004, PROC SPIE, V5306, P784, DOI 10.1117/12.526523
   Ghaderpanah M, 2008, IEEE IMAGE PROC, P3104, DOI 10.1109/ICIP.2008.4712452
   Gu XG, 2013, SIGNAL PROCESS, V93, P2244, DOI 10.1016/j.sigpro.2012.07.014
   Jagannathan A, 2007, IEEE T PATTERN ANAL, V29, P2195, DOI 10.1109/TPAMI.2007.1125
   Kanai S., 1998, IFIP WG, P296
   Lee SH, 2008, MULTIMEDIA SYST, V13, P323, DOI 10.1007/s00530-007-0095-8
   Lee SH, 2007, DIGIT SIGNAL PROCESS, V17, P396, DOI 10.1016/j.dsp.2005.04.014
   Lee SH, 2013, DIGIT SIGNAL PROCESS, V23, P1505, DOI 10.1016/j.dsp.2013.04.012
   Lee SH, 2012, DIGIT SIGNAL PROCESS, V22, P744, DOI 10.1016/j.dsp.2012.04.015
   Lee SH, 2011, COMPUT AIDED DESIGN, V43, P1056, DOI 10.1016/j.cad.2011.03.003
   Liu F, 2012, OPT COMMUN, V285, P5008, DOI 10.1016/j.optcom.2012.08.007
   Matei B, 2006, IEEE T PATTERN ANAL, V28, P1111, DOI 10.1109/TPAMI.2006.148
   Monga V, 2007, IEEE T INF FOREN SEC, V2, P376, DOI 10.1109/TIFS.2007.902670
   Monga V, 2006, IEEE T INF FOREN SEC, V1, P68, DOI 10.1109/TIFS.2005.863502
   National Institute of Standards and Technology, 2010, STAT TEST SUITE RAND
   Ohbuchi R., 2001, Graphics Interface, P9
   Praun E, 1999, COMP GRAPH, P49, DOI 10.1145/311535.311540
   Sehgal A, 2003, PATTERN RECOGN, V36, P765, DOI 10.1016/S0031-3203(02)00102-4
   Sun R, 2014, MULTIMED TOOLS APPL, V70, P1651, DOI 10.1007/s11042-012-1188-8
   Swaminathan A, 2006, IEEE T INF FOREN SEC, V1, P215, DOI 10.1109/TIFS.2006.873601
   Tarmissi K, 2009, EXPERT SYST APPL, V36, P9409, DOI 10.1016/j.eswa.2008.12.062
   Wu Y, 2012, ARXIV12111654V1CSCR
   Zaharia T, 2001, PROC SPIE, V4304, P133, DOI 10.1117/12.424969
   Zhe C, 2006, 8 INT C SIGN PROC, V2
NR 37
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1723
EP 1755
DI 10.1007/s11042-013-1643-1
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200028
DA 2024-07-18
ER

PT J
AU Rahman, MA
   Hossain, MS
   El Saddik, A
AF Rahman, Md. Abdur
   Hossain, M. Shamim
   El Saddik, Abdulmotaleb
TI Context-aware multimedia services modeling: an e-Health perspective
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Body sensor network; e-Health; Sensor networks; Internet-based services;
   User context; Context modeling
ID SENSOR; NETWORK
AB In this paper we present an e-Health framework model that can dynamically provide context-aware multimedia services to a user. The framework collects live user context by analyzing sensory data obtained from a body sensor network and multimedia content available from live heterogeneous Internet-based services. Finally, we share the implementation details and test results.
C1 [Rahman, Md. Abdur] Umm Al Qura Univ, Dept Comp Sci, Mecca, Saudi Arabia.
   [Hossain, M. Shamim] King Saud Univ, CCIS, Riyadh, Saudi Arabia.
   [El Saddik, Abdulmotaleb] Univ Ottawa, Multimedia Commun Res Lab MCRLab SITE, Ottawa, ON K1N 6N5, Canada.
C3 Umm Al Qura University; King Saud University; University of Ottawa
RP Rahman, MA (corresponding author), Umm Al Qura Univ, Dept Comp Sci, Mecca, Saudi Arabia.
EM marahman@uqu.edu.sa; mshossain@ksu.edu.sa; abed@mcrlab.uottawa.ca
RI Rahman, Abdur/AAG-9302-2019; Hossain, M. Shamim/K-1362-2014; Guizani,
   Mohsen/AAX-4534-2021; /D-4159-2009
OI Rahman, Abdur/0000-0002-4105-0368; Hossain, M.
   Shamim/0000-0001-5906-9422; Guizani, Mohsen/0000-0002-8972-8094;
   /0000-0002-7690-8547
FU Natural Sciences and Engineering Research Council of Canada; NSTIP
   strategic technologies program in the Kingdom of Saudi Arabia
   [11-INF1703-10]
FX The authors would like to thank Multimedia Communications Lab at the
   Department of Electrical Engineering and Information Technology of the
   Technische Universitat Darmstadt, Germany for collecting sensory data.
   The authors would also like to acknowledge the financial support of
   Natural Sciences and Engineering Research Council of Canada. The authors
   would like to thank Dr. Heung Nam Kim and Dr. Wail Gueaieb of MCRLab of
   University of Ottawa for their assistance. This research was supported
   by the NSTIP strategic technologies program (11-INF1703-10) in the
   Kingdom of Saudi Arabia.
CR An J, 2009, 11TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS I-III, PROCEEDINGS,, P554
   An X., 2006, ACM REALMAN, Florence, Italy, P47
   Aziz O, 2007, SURG INNOV, V14, P83, DOI 10.1177/1553350607302326
   Bardram JE, 2005, PERS UBIQUIT COMPUT, V9, P312, DOI 10.1007/s00779-004-0335-2
   Beutel Jan., 2003, 1 INT C EMBEDDED NET, P292
   Bhardwaj S., 2008, Sensors Transducers Journal, V90, P87
   Bottazzi D, 2006, IEEE COMMUN MAG, V44, P82, DOI 10.1109/MCOM.2006.1632653
   Dey AK, 2001, PERS UBIQUIT COMPUT, V5, P4, DOI 10.1007/s007790170019
   Eisenman SB, 2007, SENSYS'07: PROCEEDINGS OF THE 5TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P87
   El Helou S., 2009, Proc. of the 3rd ACM Conf. on Recommender Systems, New York, USA, P373
   Ganti RK, 2008, 2008 INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS, PROCEEDINGS, P563, DOI 10.1109/IPSN.2008.48
   GAO T, 2005, P INT C INF COMM TEC
   Gaonkar S, 2008, MOBISYS'08: PROCEEDINGS OF THE SIXTH INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P174
   Gartrell CM, THESIS U COLORADO
   Joly A., 2009, Int. Journal of Computer Science and Applications, V6, P50
   Jovanov E, 2003, IEEE ENG MED BIOL, V22, P49, DOI 10.1109/MEMB.2003.1213626
   Kawahara Y., 2007, 2007 IEEE International Conference on Portable Information Devices, P1, DOI DOI 10.1109/PORTABLE/2007.12
   KILLWORTH PD, 1990, SOC NETWORKS, V12, P289, DOI 10.1016/0378-8733(90)90012-X
   Koolwaaij J, 2009, PROCEEDINGS OF THE IEEE VIRTUAL WORLDS FOR SERIOUS APPLICATIONS, P61, DOI 10.1109/VS-GAMES.2009.21
   Krco S, 2004, AD HOW SENSOR WIREL, V1, P1
   Lam THW, 2008, IEEE INT CONF FUZZY, P414, DOI 10.1109/FUZZY.2008.4630401
   Lee CS, 2009, IA 2009: IEEE SYMPOSIUM ON INTELLIGENT AGENTS, P16
   NURMI P, BETELGEUSE TOOL BLUE
   Ocampo R., 2008, 2nd Int. Conf. on Communications and Networking in China, P98
   Park S, 2002, SIXTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P231, DOI 10.1109/ISWC.2002.1167252
   Phung D., 2009, P IEEE INT C PERV CO, P1
   Quan TT, 2006, IEEE T IND INFORM, V2, P155, DOI 10.1109/TII.2006.873363
   Rahman Md A, 2010, P IEEE INT INSTR MEA
   Rahman MA, 2011, IEEE T INSTRUM MEAS, V60, P345, DOI 10.1109/TIM.2010.2084190
   Rahman MA, 2010, IEEE T INSTRUM MEAS, V59, P1327, DOI 10.1109/TIM.2009.2038307
   Ryu H, 2007, LECT NOTES COMPUT SC, V4761, P20
   Santana P.C., 2005, CHI '05 Extended Abstracts on Human Factors in Computing Systems, P2099, DOI DOI 10.1145/1056808
   Sarikaya S., 2006, ACM IWCMC, Vancouver, British Columbia, Canada, P1369
   Schmitt L, 2007, 2007 JOINT WORKSHOP ON HIGH CONFIDENCE MEDICAL DEVICES, SOFTWARE AND SYSTEMS AND MEDICAL DEVICE PLUG-AND PLAY INTEROPERABILITY, P146, DOI 10.1109/HCMDSS-MDPnP.2007.9
   Upendra R., 2008, Proc. of the 5th Annual Int. Conf. on Mobile and Ubiquitous Systems, P1
   Wu WH, 2008, ARTIF INTELL MED, V42, P137, DOI 10.1016/j.artmed.2007.11.006
   Wyatt D., 2008, PROC UBICOMP, P168
   Yang BH, 2000, ROBOT AUTON SYST, V30, P273, DOI 10.1016/S0921-8890(99)00092-5
   Yao Jianchu, 2005, J Clin Monit Comput, V19, P427, DOI 10.1007/s10877-005-2033-7
NR 39
TC 6
Z9 6
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1147
EP 1176
DI 10.1007/s11042-013-1595-5
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200005
DA 2024-07-18
ER

PT J
AU Guo, CS
   Liu, D
   Guo, YF
   Sun, Y
AF Guo, Chunsheng
   Liu, Dan
   Guo, YunFei
   Sun, Yao
TI An adaptive graph cut algorithm for video moving objects detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Moving objects detection; Graph cut; Region of interest; Markov random
   field; Kalman prediction
ID SEGMENTATION
AB The algorithms based on graph cut have the advantage to detect the moving objects effectively and robustly. The main trouble of the algorithm based on graph cut is that its model parameters will be determined empirically. In this paper, a novel algorithm of adaptive graph cut is proposed to detect video moving objects. Based on Markov random field model, the proposed algorithm uses the numbers of moving objects pixels and objectives-background pixel-pairs to describe the geometric features of the moving objects. And the relationship between the geometric features of the moving objects and the model parameters are set up. In this paper, the model parameters are adaptively optimized through the extraction and prediction of the geometric features of moving objects. Then the detection based on the graph cut is preformed on ROI, which well achieves the balance between the computation and accuracy. Finally, the experimental results show the proposed algorithm can hold the details of moving objects more effectively compared with other algorithms, and improve the detection performance of moving object in the video surveillance.
C1 [Guo, Chunsheng; Liu, Dan] Hangzhou Dianzi Univ, Coll Commun Engn, Hangzhou, Zhejiang, Peoples R China.
   [Guo, YunFei; Sun, Yao] Hangzhou Dianzi Univ, Coll Automat Engn, Hangzhou, Zhejiang, Peoples R China.
C3 Hangzhou Dianzi University; Hangzhou Dianzi University
RP Guo, CS (corresponding author), Hangzhou Dianzi Univ, Coll Commun Engn, Hangzhou, Zhejiang, Peoples R China.
EM guo.chsh@gmail.com; liu123456dan@126.com; gyf@hdu.edu.cn;
   sunyao@hdu.edu.cn
RI Guo, Chunsheng/AAA-1181-2020
OI Guo, Chunsheng/0000-0003-1633-3507
FU Zhejiang Provincial Natural Science Foundation of China [LY12F01003,
   LQ13F010014]; National Natural Science Foundation of China [61172134]
FX This work is supported by Zhejiang Provincial Natural Science Foundation
   of China (No. LY12F01003, LQ13F010014), and partial supported by the
   National Natural Science Foundation of China (No. 61172134).
CR Amato A, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/901205
   [Anonymous], P IEEE COMP SOC C CO
   [Anonymous], 2008, P 2008 IEEE C COMPUT
   [Anonymous], P IEEE INT C MULT EX
   Bouttefroy PLM, 2010, INT CONF ACOUST SPEE, P4042, DOI 10.1109/ICASSP.2010.5495760
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Freedman D, 2005, PROC CVPR IEEE, P755
   Fukuchi K, 2009, IEEE INT CON MULTI, P638, DOI 10.1109/ICME.2009.5202577
   Garrett Z, 2008, IEEE IMAGE PROC, P1576, DOI 10.1109/ICIP.2008.4712070
   GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x
   Kohli P, 2005, IEEE I CONF COMP VIS, P922
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Li Y, 2005, ACM T GRAPHIC, V24, P595, DOI 10.1145/1073204.1073234
   Lombaert H, 2005, IEEE I CONF COMP VIS, P259
   Nagahashi T, 2007, LECT NOTES COMPUT SC, V4844, P806
   Nagahashi T, 2010, LECT NOTES COMPUT SC, V5995, P655
   Pal A, 2010, INT CONF ACOUST SPEE, P1146, DOI 10.1109/ICASSP.2010.5495367
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Vosters L. P. J., 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P384, DOI 10.1109/AVSS.2010.72
   Wang CH, 2008, IEEE INT SYMP CIRC S, P2590, DOI 10.1109/ISCAS.2008.4541986
   Wang L, 2010, IEEE T INTELL TRANSP, V11, P40, DOI 10.1109/TITS.2009.2026674
NR 21
TC 6
Z9 7
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2633
EP 2652
DI 10.1007/s11042-013-1566-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300025
DA 2024-07-18
ER

PT J
AU Hou, SJ
   Zhou, SB
   Siddique, MA
AF Hou, Sujuan
   Zhou, Shangbo
   Siddique, Muhammad Abubakar
TI A compressed sensing approach for query by example video retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video retrieval; Video signal processing; Compressed sensing; Similarity
   measure
ID IMAGE
AB Recently, compressed Sensing (CS) has theoretically been proposed for more efficient signal compression and recovery. In this paper, the CS based algorithms are investigated for Query by Example Video Retrieval (QEVR) and a novel similarity measure approach is proposed. Combining CS theory with the traditional discrete cosine transform (DCT), better compression efficiency for spatially sparse is achieved. The similarity measure from three levels (frame level, shot level and video level, respectively) is also discussed. For several different kinds of natural videos, the experimental results demonstrate the effectiveness of system by the proposed method.
C1 [Hou, Sujuan; Zhou, Shangbo; Siddique, Muhammad Abubakar] Chongqing Univ, Coll Comp Sci, Chongqing 400030, Peoples R China.
   [Hou, Sujuan; Zhou, Shangbo] Chongqing Univ, Key Lab Dependable Serv Comp Cyber Phys Soc, Minist Educ, Chongqing 400030, Peoples R China.
C3 Chongqing University; Chongqing University
RP Zhou, SB (corresponding author), Chongqing Univ, Coll Comp Sci, Chongqing 400030, Peoples R China.
EM shbzhou@cqu.edu.cn
RI Siddique, Muhammad Abubakar/AAO-9279-2021
OI Siddique, Muhammad Abubakar/0000-0001-9721-3034
FU National Natural Science Foundation of China [61103114, 61004112]
FX This work was supported by National Natural Science Foundation of China
   (Grant No. 61103114 and 61004112).
CR [Anonymous], P IEEE INT C IM PROC
   Borgnat P, 2008, INT CONF ACOUST SPEE, P3785, DOI 10.1109/ICASSP.2008.4518477
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Chan WL, 2008, OPT LETT, V33, P974, DOI 10.1364/OL.33.000974
   Chen X, 2012, IEEE T MULTIMEDIA, V14, P3, DOI 10.1109/TMM.2011.2167223
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Feng GC, 2003, J ELECTRON IMAGING, V12, P390, DOI 10.1117/1.1579699
   Gan L., 2008, P EUSIPCO
   Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943
   Haupt J, 2008, IEEE SIGNAL PROC MAG, V25, P92, DOI 10.1109/MSP.2007.914732
   Hou SJ, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.4.047405
   Karpenko A, 2011, IEEE T PATTERN ANAL, V33, P618, DOI 10.1109/TPAMI.2010.118
   Kekre Dr.H.B., 2010, INT J ENG SCI TECHNO, V2, P362
   Kekre HB., 2009, ICGST Int J Gr Vision Image Process (GVIP), V9, P1
   Kompatsiaris I, 2011, MULTIMED TOOLS APPL, V55, P1, DOI 10.1007/s11042-010-0618-8
   Kong J, 2010, INT CONF COMP SCI, P701, DOI 10.1109/ICCSIT.2010.5565041
   Lazebnik S, 2003, PROC CVPR IEEE, P319
   Lienhart R, 1997, P SOC PHOTO-OPT INS, V3312, P271, DOI 10.1117/12.298460
   Liu Z, 2010, P 17 INT C IM PROC
   Lu J, 2011, IEEE MULTIMEDIA, V18, P8, DOI 10.1109/MMUL.2011.52
   Mandal MK, 1999, IMAGE VISION COMPUT, V17, P513, DOI 10.1016/S0262-8856(98)00143-7
   Miao J, 2013, MAGN RESON IMAGING, V31, P75, DOI 10.1016/j.mri.2012.06.028
   Obdrzálek S, 2003, LECT NOTES COMPUT SC, V2781, P490
   Pang L, 2011, MULTIMED TOOLS APPL, V55, P151, DOI 10.1007/s11042-010-0605-0
   Praks P, 2008, IEEE IMAGE PROC, P25, DOI 10.1109/ICIP.2008.4711682
   Willett RM, 2007, ELECT IMAGING 2007
   Wu J, 2012, IEEE T MULTIMEDIA, V14, P291, DOI 10.1109/TMM.2011.2174969
   Yeh MC, 2011, IEEE T MULTIMEDIA, V13, P320, DOI 10.1109/TMM.2010.2094999
   Yuso Y, 2000, P BRIT MACH VID C BR
   ZHANG Y, 2008, IEEE INT C AC SPEECH
   Zhang Y, 2008, IEEE INT S CIRC SYST
   Zhao SJ, 2011, MULTIMED TOOLS APPL, V55, P105, DOI 10.1007/s11042-010-0602-3
   Zhao X, 2011, IEEE T IMAGE PROCESS, V20, P790, DOI 10.1109/TIP.2010.2068553
NR 34
TC 4
Z9 5
U1 0
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 3031
EP 3044
DI 10.1007/s11042-013-1573-y
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300040
DA 2024-07-18
ER

PT J
AU Hashemzadeh, M
   Pan, G
   Yao, M
AF Hashemzadeh, Mahdi
   Pan, Gang
   Yao, Min
TI Counting moving people in crowds using motion statistics of
   feature-points
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE People counting; Crowd counting; Feature point; Feature tracking;
   Occlusion; Video surveillance
ID SEGMENTATION
AB Reliable people counting is a crucial task in video surveillances. Among the available techniques, map-based approaches have shown a good performance in estimating the number of people in crowds. These approaches generally subtract the background, and then map the number of people to some features such as foreground area, texture features or edge count. However, in complex scenes, they suffer from inaccurate foreground/background segmentations, erroneous image features, and require large amount of training data to capture the wide variations in crowd distribution. This paper proposes a method using motion statistics of feature-points to estimate the number of moving people in a crowd. Simple feature-points are tracked within the scene. Then moving feature-points are partitioned into clusters corresponding to separate groups of people. For each group, three statistical features are calculated from related feature-points. The amount of moving feature-points is used to provide a rough estimate of group size. Furthermore, motion trajectories of feature-points are utilized to extract two other features related with the amount of occlusions present in groups. The extracted data are used to estimate the number of people in each group, so that the total crowd size is the sum of all group estimates. The experimental results show that the proposed method outperforms the state of the art approaches, e.g., with MSE of 2.357 and MAE of 1.093 for the benchmark video clip "Peds1". The proposed approach is good for estimating the number of people in public places, such as pedestrian walkways and parks, where people are moving and partial occlusions present in the scene.
C1 [Hashemzadeh, Mahdi; Pan, Gang; Yao, Min] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310003, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Hashemzadeh, M (corresponding author), Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310003, Zhejiang, Peoples R China.
EM hashemzadeh@zju.edu.cn; gpan@zju.edu.cn; myao@zju.edu.cn
RI Hashemzadeh, Mahdi/ABD-1813-2020; Pan, Gang/B-5978-2013
OI Hashemzadeh, Mahdi/0000-0003-0506-3513; 
FU 973 Program [2013CB329504]; NSF of China [61070067]; Qianjiang Talent
   Program of Zhejiang [2011R10078]
FX This work was partly supported by the 973 Program (2013CB329504), NSF of
   China (No. 61070067), and Qianjiang Talent Program of Zhejiang
   (2011R10078).
CR Albiol A., 2009, 3International_Workshop_on Performance_Evaluation_of_Tracking_and_Surveillance, P31
   [Anonymous], 1997, Image Processing for Security Applications, DOI DOI 10.1049/IC:19970387
   [Anonymous], 2005, BMVC 2005 P BRIT MAC
   [Anonymous], PETS PERF EV TRACK S
   [Anonymous], 2006, COMPUTER VISION PATT, DOI 10.1109/CVPR.2006.92
   Benfold B., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3457, DOI 10.1109/CVPR.2011.5995667
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   Brostow G.J., 2006, CVPR, P594, DOI DOI 10.1109/CVPR.2006.320
   Çelik H, 2006, IEEE IMAGE PROC, P2401, DOI 10.1109/ICIP.2006.312946
   Chan AB, 2008, P INT C COMP VIS PAT
   Cheriyadat AM, 2008, P 6 IEEE WORKSH PERC
   Cho SY, 1999, IEEE T SYST MAN CY B, V29, P535, DOI 10.1109/3477.775269
   DAVIES AC, 1995, ELECTRON COMMUN ENG, V7, P37, DOI 10.1049/ecej:19950106
   Doulamis AD, 2000, IEEE T NEURAL NETWOR, V11, P137, DOI 10.1109/72.822517
   Doulamis N, 2009, P 16 INT C SIGN IM P, P1
   ELLIS A, 2009, P 12 IEEE INT WORKSH
   Haibo W, 2010, P INT C MULT TECHN, P1
   Haritaoglu I., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P280, DOI 10.1109/ICIAP.1999.797608
   Harris C., 1988, ALVEY VISION C, P147151
   Hou YL, 2011, IEEE T SYST MAN CY A, V41, P24, DOI 10.1109/TSMCA.2010.2064299
   Kilambi P, 2008, COMPUT VIS IMAGE UND, V110, P43, DOI 10.1016/j.cviu.2007.02.003
   Kong D, 2006, INT C PATT RECOG, P1187
   Krahnstoever N, 2005, IEEE I CONF COMP VIS, P1858
   Krausz B, 2012, COMPUT VIS IMAGE UND, V116, P307, DOI 10.1016/j.cviu.2011.08.006
   Leibe B, 2005, PROC CVPR IEEE, P878
   Lempitsky V., 2010, P ADV NEUR INF PROC, V23, P1, DOI DOI 10.5555/2997189.2997337
   Lim J, 2013, MULTIMED TOOLS APPL, V65, P161, DOI 10.1007/s11042-012-1156-3
   Lin Z, 2010, IEEE T PATTERN ANAL, V32, P604, DOI 10.1109/TPAMI.2009.204
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Ma HD, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2089094.2089107
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Marana AN, 1999, INT CONF ACOUST SPEE, P3521, DOI 10.1109/ICASSP.1999.757602
   Paragios N, 2001, PROC CVPR IEEE, P1034
   Rahmalan H., 2006, Institution of Engineering and Technology Conference on Crime and Security, P540
   Rittscher J, 2005, PROC CVPR IEEE, P486
   Ryan D, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P81, DOI 10.1109/DICTA.2009.22
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Sugimura D, 2009, IEEE I CONF COMP VIS, P1467, DOI 10.1109/ICCV.2009.5459286
   Tomasi C, 1991, DETECTION TRACKING P
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Zeng CB, 2010, IEEE IMAGE PROC, P3845, DOI 10.1109/ICIP.2010.5654100
   Zhao T, 2003, PROC CVPR IEEE, P459, DOI 10.1109/NSSMIC.2003.1352083
   Zhiyong Lin, 2011, 2011 International Conference on Multimedia Technology, P3570
NR 43
TC 22
Z9 23
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 453
EP 487
DI 10.1007/s11042-013-1367-2
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800021
DA 2024-07-18
ER

PT J
AU Zia, S
   Jaffar, MA
   Mirza, AM
   Choi, TS
AF Zia, Sultan
   Jaffar, M. Arfan
   Mirza, Anwar M.
   Choi, Tae-Sun
TI Rician noise removal from MR images using novel adapted selective
   non-local means filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE De-noising; Magnetic resonance image; Adapted nonlocal means;
   Morphological gradients
ID MAXIMUM-LIKELIHOOD-ESTIMATION; ALGORITHM
AB The reduction of rician noise from MR images without degradation of the underlying image features has attracted much attention and has a strong potential in several application domains including medical image processing. Interpretation of MR images is difficult due to their tendency to gain rician noise during acquisition. In this work, we proposed a novel selective non-local means algorithm for noise suppression of MR images while preserving the image features as much as possible. We have used morphological gradient operators that separate the image high frequency areas from smooth areas. Later, we have applied novel selective NLM filter with optimal parameter values for different frequency regions of image to remove the noise. A method of selective weight matrix is also proposed to preserve the image features against smoothing. The results of experimentation performed using proposed adapted selective filter prove the soundness of the method. We compared results with the results of many well known techniques presented in literature like NLM with optimized parameters, wavelet based de-noising and anisotropic diffusion filter and discussed the improvements achieved.
C1 [Zia, Sultan; Jaffar, M. Arfan] Natl Univ Comp & Emerging Sci, Islamabad, Pakistan.
   [Jaffar, M. Arfan; Choi, Tae-Sun] Gwangju Inst Sci & Technol, Kwangju, South Korea.
   [Mirza, Anwar M.] King Saud Univ, Riyadh, Saudi Arabia.
C3 Gwangju Institute of Science & Technology (GIST); King Saud University
RP Jaffar, MA (corresponding author), Gwangju Inst Sci & Technol, Kwangju, South Korea.
EM ziactn@gmail.com; arfanjaffar@gist.ac.kr; ammirza@ksu.edu.sa;
   tschoi@gist.ac.kr
RI Jaffar, Arfan/GQB-2768-2022; mirza, Arshad m/F-3016-2015; Mirza, Anwar
   M/KHW-9731-2024
OI Mirza, Anwar M/0000-0001-7600-6247; Choi, Tae-Sun/0000-0001-7496-2438
FU Higher Education Commission (HEC), Govt. of Pakistan; Bio Imaging
   Research Center at GIST, Korea
FX The authors would like to thank Higher Education Commission (HEC), Govt.
   of Pakistan and Bio Imaging Research Center at GIST, Korea for providing
   funds and required resources to complete this work.
CR Aelterman J, 2008, MAGNETIC RESONANCE I
   Alhosainy AM, 2009, PROCEEDINGS INT CONF
   Angelino CV, 2010, IEEE IMAGE PROC, P1129, DOI 10.1109/ICIP.2010.5651316
   Awate SP, 2007, IEEE T MED IMAGING, V26, P1242, DOI 10.1109/TMI.2007.900319
   Bilcu RC, 2007, PROC SPIE DIGIT PHOT, VIII, P6502
   Brox T, 2007, LECT NOTES COMPUT SC, V4485, P13
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Coifman R. R., 1995, LECT NOTES STAT, V103, P125, DOI [DOI 10.1007/978-1-4612-2544-7_9, 10.1002/cpa.3160410705, DOI 10.1002/CPA.3160410705]
   Coupé P, 2008, IEEE T MED IMAGING, V27, P425, DOI 10.1109/TMI.2007.906087
   Coupé P, 2006, LECT NOTES COMPUT SC, V4191, P33
   Coupé P, 2008, INT J BIOMED IMAGING, V2008, DOI 10.1155/2008/590183
   Dauwe A, 2008, PROC SPIE, V6812, DOI 10.1117/12.765505
   Delakis I, 2007, PHYS MED BIOL, V52, P3741, DOI 10.1088/0031-9155/52/13/006
   Goossens B, 2008, INTERNATIONAL WORKSH
   Jean S, 1982, IMAGE ANALYSIS AND M
   Kervrann C, 2007, LECT NOTES COMPUT SC, V4485, P520
   Kervrann C, 2006, IEEE T IMAGE PROCESS, V15, P2866, DOI 10.1109/TIP.2006.877529
   Mahmoudi M, 2005, IEEE SIGNAL PROC LET, V12, P839, DOI 10.1109/LSP.2005.859509
   Manjón JV, 2008, MED IMAGE ANAL, V12, P514, DOI 10.1016/j.media.2008.02.004
   Murase K, 2001, PHYS MED BIOL, V46, P2713, DOI 10.1088/0031-9155/46/10/313
   Nowak RD, 1999, IEEE T IMAGE PROCESS, V8, P1408, DOI 10.1109/83.791966
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Petersson KM, 1999, PHILOS T R SOC B, V354, P1239, DOI 10.1098/rstb.1999.0477
   Pizurica A, 2003, IEEE T MED IMAGING, V22, P323, DOI 10.1109/TMI.2003.809588
   Rivest J.-F., 1993, Journal of Electronic Imaging, V2, P326, DOI 10.1117/12.159642
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Salmon J, 2010, IEEE INTERNATIONAL C
   Samsonov AA, 2004, MAGN RESON MED, V52, P798, DOI 10.1002/mrm.20207
   Shechtman E, 2007, IEEE CONFERENCE ON C
   Sijbers J, 1998, IEEE T MED IMAGING, V17, P357, DOI 10.1109/42.712125
   Sijbers J, 2004, MAGNET RESON MED, V51, P586, DOI 10.1002/mrm.10728
   Wink AM, 2004, IEEE T MED IMAGING, V23, P374, DOI 10.1109/TMI.2004.824234
   Yaroslavsky L.P., 1985, Digital Picture Processing: An Introduction
NR 35
TC 8
Z9 8
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 1
EP 19
DI 10.1007/s11042-012-1253-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800001
DA 2024-07-18
ER

PT J
AU Soroushmehr, SMR
   Samavi, S
   Shirani, S
AF Soroushmehr, S. M. Reza
   Samavi, Shadrokh
   Shirani, Shahram
TI Simple and efficient motion estimation algorithm by continuum search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Block motion estimation; Search area; Temporal correlation; Spatial
   correlation; Motion vector
ID ARCHITECTURE; VECTORS; DIAMOND
AB Motion estimation plays a vital role in reducing temporal correlation in video codecs but it requires high computational complexity. Different algorithms have tried to reduce this complexity. However these reduced-complexity routines are not as regular as the full search algorithm (FSA). Also, regularity of an algorithm is very important in order to have a hardware implementation of that algorithm even if it leads to more complexity burden. The goal of this paper is to develop an efficient and regular algorithm which mimics FSA by searching a small area exhaustively. Our proposed algorithm is designed based on two observations. The first observation is that the motion vector of a block falls within a specific rectangular area designated by the prediction vectors. The second observation is that in most cases, this rectangular area is smaller than one fourth of the FSA's search area. Therefore, the search area of the proposed method is adaptively found for each block of a frame. To find the search area, the temporal and spatial correlations among motion vectors of blocks are exploited. Based on these correlations, a rectangular search area is determined and the best matching block in this area is selected. The proposed algorithm is similar to FSA in terms of regularity but requires less computational complexity due to its smaller search area. Also, the suggested algorithm is as simple as FSA in terms of implementation and is comparable with many of the existing fast search algorithms. Simulation results show the claimed performance and efficiency of the algorithm.
C1 [Soroushmehr, S. M. Reza; Samavi, Shadrokh] Isfahan Univ Technol, Esfahan, Iran.
   [Soroushmehr, S. M. Reza; Samavi, Shadrokh; Shirani, Shahram] McMaster Univ, Hamilton, ON, Canada.
C3 Isfahan University of Technology; McMaster University
RP Soroushmehr, SMR (corresponding author), Isfahan Univ Technol, Esfahan, Iran.
EM soroush@ec.iut.ac.ir
CR Ahmad I, 2006, IEEE T CIRC SYST VID, V16, P420, DOI 10.1109/TCSVT.2006.870022
   [Anonymous], 1981, P NAT TEL C NEW ORL
   Chimienti A, 2002, IEEE T IMAGE PROCESS, V11, P387, DOI 10.1109/TIP.2002.999673
   Chiper D.F., 2009, ISSCSS09, P1
   Dikbas S, 2010, IEEE T CIRC SYST VID, V20, P1047, DOI 10.1109/TCSVT.2010.2051283
   Frimout ED, 1992, IEEE T CIRC SYST VID, V2, P159, DOI 10.1109/76.143415
   Goswami K, 2009, IEEE T CONSUM ELECTR, V55, P1690, DOI 10.1109/TCE.2009.5278044
   Ho H, 2011, IEEE T CONSUM ELECTR, V57, P794, DOI 10.1109/TCE.2011.5955224
   Hsieh LL, 2011, EXPERT SYST APPL, V38, P11608, DOI 10.1016/j.eswa.2011.03.039
   Huang YS, 2011, MULTIMED TOOLS APPL, V54, P527, DOI 10.1007/s11042-010-0550-y
   JAIN JR, 1981, IEEE T COMMUN, V29, P1799, DOI 10.1109/TCOM.1981.1094950
   Jing X, 2004, IEEE T MULTIMEDIA, V6, P435, DOI 10.1109/TMM.2004.827517
   Kordasiewicz RC, 2007, IEEE T CIRC SYST VID, V17, P1388, DOI 10.1109/TCSVT.2007.903777
   Kossentini F, 1997, IEEE J SEL AREA COMM, V15, P1752, DOI 10.1109/49.650048
   Lee J, 2006, IEEE T CIRC SYST VID, V16, P191, DOI 10.1109/TCSVT.2005.857780
   Lin CC, 2009, IET IMAGE PROCESS, V3, P88, DOI 10.1049/iet-ipr.2008.0042
   Ma K, 2000, ISOIECJTC1SC29WG11M5
   Mecklenbrauker C, 2006, D211 EUR UN
   Mehra R, 1996, IEEE IC CAD, P166, DOI 10.1109/ICCAD.1996.569540
   Metkar SP, 2010, SIGNAL IMAGE VIDEO P, V4, P123, DOI 10.1007/s11760-009-0104-9
   Momcilovic S, 2011, J SIGNAL PROCESS SYS, V62, P301, DOI 10.1007/s11265-010-0463-z
   Nie Y, 2002, IEEE T IMAGE PROCESS, V11, P1442, DOI 10.1109/TIP.2002.806251
   Po LM, 2009, IEEE T CIRC SYST VID, V19, P1189, DOI 10.1109/TCSVT.2009.2020320
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Shi ZR, 2011, IEEE T CONSUM ELECTR, V57, P1354, DOI 10.1109/TCE.2011.6018894
   Soroushmehr SMR, 2010, CAN J ELECT COMPUT E, V35, P25, DOI 10.1109/CJECE.2010.5783381
   Soroushmehr SMR, 2009, IEEE INT CON MULTI, P201, DOI 10.1109/ICME.2009.5202471
   Tham JY, 1998, IEEE T CIRC SYST VID, V8, P369, DOI 10.1109/76.709403
   Tian XH, 2011, SIGNALS COMMUN TECHN, P3, DOI 10.1007/978-3-642-14703-6
   Tourapis A, 2000, JTC1SC29WG11MPEG99M5
   Zheng W, 2001, IEEE IMAGE PROC, P377, DOI 10.1109/ICIP.2001.959032
NR 31
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1615
EP 1633
DI 10.1007/s11042-012-1298-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000029
DA 2024-07-18
ER

PT J
AU Chung, KY
   Lee, D
   Kim, KJ
AF Chung, Kyung-Yong
   Lee, Daesung
   Kim, Kuinam J.
TI Categorization for grouping associative items using data mining in
   item-based collaborative filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Collaborative filtering; Categorization; Associative items;
   Recommendation system; Data mining
ID ALGORITHM
AB Recommendation systems have been investigated and implemented in many ways. In particular, in the case of a collaborative filtering system, the most important issue is how to manipulate the personalized recommendation results for better user understandability and satisfaction. A collaborative filtering system predicts items of interest for users based on predictive relationships discovered between each item and others. This paper proposes a categorization for grouping associative items discovered by mining, for the purpose of improving the accuracy and performance of item-based collaborative filtering. It is possible that, if an associative item is required to be simultaneously associated with all other groups in which it occurs, the proposed method can collect associative items into relevant groups. In addition, the proposed method can result in improved predictive performance under circumstances of sparse data and cold-start initiation of collaborative filtering starting from a small number of items. In addition, this method can increase prediction accuracy and scalability because it removes the noise generated by ratings on items of dissimilar content or level of interest. The approach is empirically evaluated by comparison with k-means, average link, and robust, using the MovieLens dataset. The method was found to outperform existing methods significantly.
C1 [Chung, Kyung-Yong] Sangji Univ, Sch Comp Informat Engn, Wonju, South Korea.
   [Lee, Daesung; Kim, Kuinam J.] Kyonggi Univ, Dept Convergence Secur, Suwon, South Korea.
C3 Sangji University; Kyonggi University
RP Chung, KY (corresponding author), Sangji Univ, Sch Comp Informat Engn, Wonju, South Korea.
EM dragonhci@hanmail.net; xdilemma@naver.com; harap123@hanmail.net
RI Lee, Daesung/P-7946-2018; Chung, Kyungyong/JAC-2276-2023
OI Lee, Daesung/0000-0002-2435-6867; 
FU Basic Science Research Program through the National Research Foundation
   of Korea - Ministry of Education, Science and Technology [2011-0008934]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea funded by the Ministry of
   Education, Science and Technology. (No. 2011-0008934)
CR [Anonymous], 1997, Proceedings of the ACM SIGMOD Workshop on Research Issues on Data Mining and Knowledge Discovery
   Connor M., 1999, P ACM SIGIR WORKSH R
   Ding C., 2004, P 21 INT C MACH LEAR, P29, DOI DOI 10.1145/1015330.1015408
   Gose E., 1996, PATTERN RECOGNITION
   Guha S, 2000, INFORM SYST, V25, P345, DOI 10.1016/S0306-4379(00)00022-3
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   Jalali M, 2010, EXPERT SYST APPL, V37, P6201, DOI 10.1016/j.eswa.2010.02.105
   Jung KY, 2004, IEICE T INF SYST, VE87D, P2781
   Jung KY, 2006, LECT NOTES ARTIF INT, V4251, P310
   KANGAS S, 2001, TTE4200135 VTT INF T
   Kim HN, 2010, ELECTRON COMMER R A, V9, P73, DOI 10.1016/j.elerap.2009.08.004
   Kim TH, 2005, LECT NOTES ARTIF INT, V3809, P1150
   Ko S, 2002, LECT NOTES COMPUT SC, V2455, P244
   Li Q, 2003, IEEE/WIC INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, PROCEEDINGS, P33
   MICHAEL T, 1997, MACHING LEARNING, P154
   Wang J, 2006, LECT NOTES COMPUT SC, V3936, P37
NR 16
TC 20
Z9 21
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 889
EP 904
DI 10.1007/s11042-011-0885-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400031
DA 2024-07-18
ER

PT J
AU Kim, KY
   Kim, HT
AF Kim, Ki Youn
   Kim, Hyeon Tae
TI Android application that provides information on the foot and mouth
   disease in Korea
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Foot and mouth disease (FMD); Applications; Smartphone; Tablet PCs
AB The foot and mouth disease is one of the most infectious diseases among artiodactyla. This occurred in and caused great damage to Korea in 2010. The effect was spread all over the country since it was not dealt with effectively at the early stages of the outbreak. Thus, this study aims to develop an application with the menu items such as the outbreak areas, and symptoms, and prompt reports of the foot and mouth disease so that stock farmers can download it through Smartphone and tablet PC web markets. The developed application enables stock farmers to get realtime information on the foot and mouth disease anywhere anytime, and to cope with this disease promptly when it occurs around their farming areas. It is expected that this application will be of help in preventing the foot and mouth disease from spreading further.
C1 [Kim, Ki Youn] Catholic Univ Pusan, Dept Ind Hlth, Pusan, South Korea.
   [Kim, Hyeon Tae] Gyeongsang Natl Univ, Dept Bioind Machinery Engn, Inst Agr & Life Sci, Jinju, South Korea.
C3 Catholic University Pusan; Gyeongsang National University
RP Kim, HT (corresponding author), Gyeongsang Natl Univ, Dept Bioind Machinery Engn, Inst Agr & Life Sci, Jinju, South Korea.
EM kky5@cup.ac.kr; bioani@gnu.ac.kr
FU Korea Institute of Planning and Evaluation for Technology of Food,
   Agriculture, Forestry and Fisheries
FX The research expresses sincere gratitude toward the Korea Institute of
   Planning and Evaluation for Technology of Food, Agriculture, Forestry
   and Fisheries for its support for the life industry technology
   development project in 2011.
CR Choi Seokkeun, 2012, [journal of Korean Society for Geospatial Information Science, 대한공간정보학회지], V20, P101, DOI 10.7319/kogsis.2012.20.2.101
   Hua G, 2012, INT J COMPUT VISION, V96, P277, DOI 10.1007/s11263-011-0506-3
   오범교, 2010, [The Journal of The Institute of Internet, Broadcasting and Communication, 한국인터넷방송통신학회 논문지], V10, P53
   RDA, 2011, FOOD MOUTH DIS EM AC
   Yang Gi Geun, 2012, Crisisonomy, V8, P72
   이수철, 2012, Crisisonomy, V8, P90
   Lee Hyunju, 2011, [Korean Journal of Art Therapy, 미술치료연구], V18, P245
   김정수, 2011, ECO, V15, P85
NR 8
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 657
EP 666
DI 10.1007/s11042-013-1629-z
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400017
DA 2024-07-18
ER

PT J
AU Lee, SW
AF Lee, Seok-Won
TI Evidence-driven decision support in critical infrastructure management
   through enhanced domain knowledge modeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Infrastructure management; Remote Sensing; Visual analytics; Ontological
   engineering; Service-oriented architecture
AB Effective critical infrastructure management in dynamically changing service environments requires understanding and inferring unknown knowledge from complex heterogeneous dataset to reason about multi-dimensional complex problem solving activities by aggregating supporting evidences. While the attributes of the database table only describe data and certain notions from the database relational schema, they do not describe the higher-level concepts or the knowledge from the domain that are commonly thought of and referred by engineers who need to inspect and manage the infrastructure with a holistic viewpoint. Thus, engineers have to work with rudimentary data-level attributes that, further, complicates the critical infrastructure management, which essentially needs efficient, effective, and informed decision making. Ontology enables to solve a complex problem where the underlying domain concept provides collective understanding of the data based on the domain knowledge from multi-dimensional resources. Enhanced domain knowledge modeling is applied for transportation infrastructure asset management that requires bridge inspectors to make decisions based on complex multi-layered heterogeneous data, such as, infrared image data, aerial photo data, ground-mounted LIDAR data, etc. The ontological concepts represent the process knowledge and assessment knowledge and it will be further used to support the bridge inspectors and their inspection process, whereas data are the ground facts. This process knowledge plays an important role to bridge the ground facts and the high-level concept space and provides the mapping of the complex data space to the easily comprehensible conceptual space. In making critical decisions, these become crucial evidences in justifying decisions made as well as in making uniform decisions among different subject matter experts through the common understanding.
C1 Ajou Univ, Div Informat & Comp Engn, Knowledge Intens Software Engn NiSE Res Grp, Suwon 441749, South Korea.
C3 Ajou University
RP Lee, SW (corresponding author), Ajou Univ, Div Informat & Comp Engn, Knowledge Intens Software Engn NiSE Res Grp, San 5, Suwon 441749, South Korea.
EM leesw@ajou.ac.kr
FU Next-Generation Information Computing Development Program through the
   National Research Foundation of Korea (NRF) - Ministry of Education,
   Science and Technology [2012M3C4A7033343, 2012M3C4A7033346]
FX This research was supported by Next-Generation Information Computing
   Development Program through the National Research Foundation of Korea
   (NRF) funded by the Ministry of Education, Science and Technology (No.
   2012M3C4A7033343 & No. 2012M3C4A7033346).
CR Alonso G., 2004, DAT SYS APP, DOI 10.1007/978-3-662-10876-5_5
   Das Souripriya, SUPPORTING ONTOLOGY
   GANDHI RA, 2006, P 2 INT WORKSH SERV
   Lee SW, 2006, INT J SOFTW ENG KNOW, V16, P851, DOI 10.1142/S0218194006003051
   Lee SW, 2009, INT J SOFTW ENG KNOW, V19, P791, DOI 10.1142/S0218194009004386
   Lee SW, 2005, 12TH ASIA-PACIFIC SOFTWARE ENGINEERING CONFERENCE, PROCEEDINGS, P481
   LEE SW, 2007, P 15 IEEE INT REQ EN
   LEE SW, 2005, TRNISE0505 UNC
   Lim L, 2007, P 23 INT C DAT ENG I
   Lim L, 2007, P IEEE 23 INT C DAT
   McNally RK, 2007, ENVIRON PLANN B, V34, P1103, DOI 10.1068/b32078
   PAPAZOGLOU M, 2003, COMMUNICATIONS ACM, V46
   Perrey R, 2003, 2003 SYMPOSIUM ON APPLICATIONS AND THE INTERNET WORKSHOPS, PROCEEDINGS, P116, DOI 10.1109/SAINTW.2003.1210138
   Vatcha R, 2009, P VIS AN HOM DEF SEC
   Wang X, 2009, P VISUAL AN HOM DEF
   Wong PC, 2004, IEEE COMPUT GRAPH, V24, P20
NR 16
TC 2
Z9 2
U1 3
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 1
BP 309
EP 330
DI 10.1007/s11042-013-1469-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK0QX
UT WOS:000338120700018
DA 2024-07-18
ER

PT J
AU Li, Q
   Lee, S
   Jung, H
   Lee, YS
   Cho, JH
   Song, SK
AF Li, Qing
   Lee, Seungwoo
   Jung, Hanmin
   Lee, Yeong Su
   Cho, Jae-Hyun
   Song, Sa-kwang
TI Term weighting for information retrieval based on term's discrimination
   power
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information retrieval; Term weighting; Discrimination power; Difference
   based DP; Evidential weight
AB One of the most important research topics in Information Retrieval is term weighting for document ranking and retrieval, such as TFIDF, BM25, etc. We propose a term weighting method that utilizes past retrieval results consisting of the queries that contain a particular term, retrieval documents, and their relevance judgments. A term's Discrimination Power(DP) is based on the difference degree of the term's average weights obtained from between relevant and non-relevant retrieved document sets. The difference based DP performs better compared to ratio based DP introduced in the previous research. Our experimental result shows that a term weighting scheme based on the discrimination power method outperforms a TF*IDF based scheme.
C1 [Li, Qing] Southwestern Univ Finance & Econ, Chengdu, Peoples R China.
   [Lee, Seungwoo] Korea Inst Sci & Technol Informat, Platform Res Grp, Taejon, South Korea.
   [Jung, Hanmin] Korea Inst Sci & Technol Informat, Dept SW Res, Taejon, South Korea.
   [Song, Sa-kwang] Korea Inst Sci & Technol Informat, Taejon, South Korea.
   [Lee, Yeong Su] Univ Munich, Munich, Germany.
   [Cho, Jae-Hyun] Pusan Chatol Univ, Pusan, South Korea.
C3 Southwestern University of Finance & Economics - China; Korea Institute
   of Science & Technology Information (KISTI); Korea Institute of Science
   & Technology Information (KISTI); Korea Institute of Science &
   Technology Information (KISTI); University of Munich
RP Song, SK (corresponding author), Korea Inst Sci & Technol Informat, Taejon, South Korea.
EM liq_t@swufe.edu.cn; swlee@kisti.re.kr; jhm@kisti.re.kr;
   yeong@cis.uni-muenchen.de; jhcho@cup.ac.kr; esmallj@kisti.re.kr
RI Li, Qing/JMH-1365-2023
OI Li, Qing/0000-0003-3370-471X
CR Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   Broglio J, 1994, P 3 TEXT RETRIEVAL C
   Cao G., 2007, P ACM C RES DEV INF
   Chun H-W, 2011, UNESST 2011
   Craswell N., 2005, P 14 TEXT RETRIEVAL
   Cummins R, 2006, INFORM RETRIEVAL, V9, P311, DOI 10.1007/s10791-006-1682-6
   Hong-Woo Chun, 2011, Active Media Technology. Proceedings 7th International Conference, AMT 2011, P324, DOI 10.1007/978-3-642-23620-4_34
   Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140
   Pahikkala T, 2007, P ACM C RES DEV INF
   Robertson S, 2004, J DOC, V60, P503, DOI 10.1108/00220410410560582
   ROBERTSON SE, 1996, P 4 TEXT RETRIEVAL C
   SALTON G, 1990, J AM SOC INFORM SCI, V41, P288, DOI 10.1002/(SICI)1097-4571(199006)41:4<288::AID-ASI8>3.0.CO;2-H
   Song SK, 2012, INFORM PROCESS MANAG, V48, P921, DOI 10.1016/j.ipm.2012.03.004
   TURTLE H, 1991, ACM T INFORM SYST, V9, P187, DOI 10.1145/125187.125188
   Yeh J.-Y., 2007, P ACM C RES DEV INF
NR 15
TC 0
Z9 0
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 769
EP 781
DI 10.1007/s11042-013-1420-1
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400023
DA 2024-07-18
ER

PT J
AU Yoon, CP
   Moon, SJ
   Hwang, CG
AF Yoon, Chang-Pyo
   Moon, Seok-Jae
   Hwang, Chi-Gon
TI MCSOSA: multimedia content share using ontology and secure access agent
   in mobile cloud
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile cloud; Intent; Multimedia content; Ontology; Vulnerability
ID INTEGRATION
AB Mobile cloud is not just a traditional cloud, but a concept of virtualization that has expanded into mobile technology. It provides access to the data created and used by a user and content service by cloud platform. A feature of mobile cloud is supported that is the convenience of multimedia content sharing by mobile devices. However, there is a problem of inaccuracy of information retrieval in the process of sharing as well as personal information leakage and service inability status due to the malicious access to the mobile terminal in the retrieval process. This paper suggests the model to which the protective technique of multimedia content retrieval & access in mobile cloud is applied. The model stores and manages the individually different forms of content, and constructs the multimedia ontology in order to enhance the reliability in mismatched problems occurring in the retrieval process, and also suggests the response technique to security vulnerability occurring in the content access.
C1 [Yoon, Chang-Pyo] Gyeonggi Collage Sci & Technol, Dept Mobile Informat Convergence Technol, Gyeonggi, South Korea.
   [Moon, Seok-Jae; Hwang, Chi-Gon] Kwangwoon Univ, Dept Comp Sci, Seoul, South Korea.
C3 Kwangwoon University
RP Moon, SJ (corresponding author), Kwangwoon Univ, Dept Comp Sci, Seoul, South Korea.
EM cpyoon@gtec.ac.kr; msj8086@kw.ac.kr; duck1052@kw.ac.kr
RI Yoon, Chang Pyo/AAC-4712-2022
CR [Anonymous], 2008, P 2008 GRID COMP ENV, DOI DOI 10.1109/GCE.2008.4738443
   [Anonymous], SPECIAL PUBLICATION
   임재완, 2012, [Journal of convergence security, 융합보안 논문지], V12, P61
   Dinh HT, 2013, WIREL COMMUN MOB COM, V13, P1587, DOI 10.1002/wcm.1203
   Dong Jung Kye, 2013, [Journal of the Korea Institute Of Information and Communication Engineering, 한국정보통신학회논문지], V17, P453, DOI 10.6109/jkiice.2013.17.2.453
   Enrique Ortiz C, 2010, UNDERSTANDING SECURI, P1
   GRUBER TR, 1993, KNOWL ACQUIS, V5, P199, DOI 10.1006/knac.1993.1008
   Guarino N, 1998, FR ART INT, V46, P3
   Hammiche S, 2004, 2 ACM INT WORKSH MUL, P36, DOI DOI 10.1145/1032604.1032612
   Hunter J, 2003, IEEE T CIRC SYST VID, V13, P49, DOI 10.1109/TCSVT.2002.808088
   Hwang C, 2011, COMM COM INF SC, V195, P36
   Lagoze C., 2001, PROC INT C DUBLIN CO, P160
   Mohiuddin K, 2012, CLOUD COMPUTING, P88
   Paliouras G, 2011, LECT NOTES ARTIF INT, V6050, P1, DOI 10.1007/978-3-642-20795-2_1
   Rmakrishnan R, 2007, SHERPA CLOUD COMPUTI, P33
   Tsinaraki C, 2004, BIOMED SCI INSTRUM, V3084, P398
NR 16
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 667
EP 684
DI 10.1007/s11042-013-1648-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400018
DA 2024-07-18
ER

PT J
AU Candela, ES
   Pérez, MO
   Romero, CM
   López, DCP
   Herranz, GS
   Contero, M
   Raya, MA
AF Soto Candela, Emilio
   Ortega Perez, Mario
   Marin Romero, Clemente
   Perez Lopez, David C.
   Salvador Herranz, Gustavo
   Contero, Manuel
   Alcaniz Raya, Mariano
TI <i>HumanTop</i>: a multi-object tracking tabletop
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tabletop; Multitouch; Markerless tracking; Finger detection;
   Camera-projector system; Technology enhanced learning
AB In this paper, a computer vision based interactive multi-touch tabletop system called HumanTop is introduced. HumanTop implements a stereo camera vision subsystem which allows not only an accurate fingertip tracking algorithm but also a precise touch-over-the-working surface detection method. Based on a pair of visible spectra cameras, a novel synchronization circuit makes the camera caption and the image projection independent from each other, providing the minimum basis for the development of computer vision analysis based on visible spectrum cameras without any interference coming from the projector. The assembly of both cameras and the synchronization circuit is not only capable of performing an ad-hoc version of a depth camera, but it also introduces the recognition and tracking of textured planar objects, even when contents are projected over them. On the other hand HumanTop supports the tracking of sheets of paper and ID-code markers. This set of features makes the HumanTop a comprehensive, intuitive and versatile augmented tabletop that provides multitouch interaction with projective augmented reality on any flat surface. As an example to exploit all the capabilities of HumanTop, an educational application has been developed using an augmented book as a launcher to different didactic contents. A pilot study in which 28 fifth graders participated is presented. Results about efficiency, usability/satisfaction and motivation are provided. These results suggest that HumanTop is an interesting platform for the development of educational contents.
C1 [Soto Candela, Emilio; Ortega Perez, Mario; Marin Romero, Clemente; Perez Lopez, David C.; Contero, Manuel; Alcaniz Raya, Mariano] Univ Politecn Valencia, Valencia 46022, Spain.
   [Salvador Herranz, Gustavo] Univ Cardenal Herrera CEU, Moncada 46113, Spain.
C3 Universitat Politecnica de Valencia; Universidad CEU Cardenal Herrera
RP Candela, ES (corresponding author), Univ Politecn Valencia, Camino Vera S-N, Valencia 46022, Spain.
EM emsocan@labhuman.i3bh.es
RI Perez, David/HMV-6566-2023; Pérez López, David/HJZ-1289-2023; Contero,
   Manuel/F-4276-2010; Alcañiz, Mariano/CAG-6569-2022; Salvador-Herranz,
   Gustavo/L-5391-2017
OI Perez, David/0000-0001-7188-4921; Pérez López,
   David/0000-0002-9293-4892; Contero, Manuel/0000-0002-6081-9988; Alcañiz,
   Mariano/0000-0001-9207-0636; Salvador-Herranz,
   Gustavo/0000-0002-3082-0312; Ortega Perez, Mario/0000-0002-4467-7094
FU Ministerio de Educacion y Ciencia Spain [TIN2010-21296-C02-01,
   TIN2010-20187]; project Consolider-C "CIBER of Physiopathology of
   Obesity and Nutrition, an initiative of ISCIII" [SEJ2006-14301/PSIC];
   project Excellence Research Program PROMETEO (Generalitat Valenciana.
   Conselleria de Educacio) [2008-157]
FX This study was funded by Ministerio de Educacion y Ciencia Spain,
   Project SALTET (TIN2010-21296-C02-01), Project Game Teen (TIN2010-20187)
   projects Consolider-C (SEJ2006-14301/PSIC), "CIBER of Physiopathology of
   Obesity and Nutrition, an initiative of ISCIII" and Excellence Research
   Program PROMETEO (Generalitat Valenciana. Conselleria de Educacio,
   2008-157).
CR Agarwal A, 2007, SECOND ANNUAL IEEE INTERNATIONAL WORKSHOP ON HORIZONTAL INTERACTIVE HUMAN-COMPUTER SYSTEMS, PROCEEDINGS, P197, DOI 10.1109/TABLETOP.2007.29
   Alexa M, 2008, ACM SIGGRAGH POST AC, P49
   [Anonymous], 1991, CMUCS91132
   [Anonymous], 2005, P 18 ANN ACM S US IN, DOI [10.1145/1095034.1095054, DOI 10.1145/1095034.1095054]
   Argyros AA, 2006, LECT NOTES COMPUT SC, V3979, P40
   Barnes C, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409077
   Bradski G., 2008, LEARNING OPENCV
   Campbell DT., 1963, EXPT QUASIEXPERIMENT
   Chen D, 2005, 13 INT C CENT EUR CO
   Dietz P., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P219, DOI 10.1145/502348.502389
   Do-Lenh S., 2009, Proceedings of the 3rd international Conference on Tangible and Embedded interaction (Cambridge, United Kingdom, February 16 - 18, P267, DOI [10.1145/1517664.1517720, DOI 10.1145/1517664.1517720]
   Dung L, 2009, J ROBOT MECHATRON, V21, P726, DOI 10.20965/jrm.2009.p0726
   Echtler F., 2009, P 3 INT C TANGIBLE E, P393
   Echtler F, 2010, TEI 2010, P227
   Holman David, 2005, CHI '05, P591, DOI 10.1145/1054972.1055054
   Izadi S, 2007, SECOND ANNUAL IEEE INTERNATIONAL WORKSHOP ON HORIZONTAL INTERACTIVE HUMAN-COMPUTER SYSTEMS, PROCEEDINGS, P3, DOI 10.1109/TABLETOP.2007.34
   Kaltenbrunner M., 2009, Proceedings of the ACM International Conference on Interactive Tabletops and Surfaces, P9
   Katz I, 2007, LECT NOTES COMPUT SC, V4678, P97
   Kim K, 2010, VISUAL COMPUT, V26, P1145, DOI 10.1007/s00371-010-0490-6
   Launius R., 2005, Arkham Horror
   Lee T, 2007, ELEVENTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P83
   Letessier Julien., 2004, P 17 ANN ACM S USER, P119, DOI DOI 10.1145/1029632.1029652
   Likert R., 1932, TECHNIQUE MEASUREMEN, DOI 1933-01885-001
   Lucchese L, 2002, APCCAS 2002: ASIA-PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS, VOL 2, PROCEEDINGS, P191, DOI 10.1109/APCCAS.2002.1115151
   Malik S., 2004, ACM INT C MULTIMODAL, P289, DOI DOI 10.1145/1027933.1027980
   Manresa C., 2000, Electronic Letters on Computer Vision and Image Analysis, P1
   Martín-Gutiérrez J, 2010, COMPUT GRAPH-UK, V34, P77, DOI 10.1016/j.cag.2009.11.003
   McNaughton J, 2010, UTILISING EMERGING M
   Microsoft, 2011, MICR SURF
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Nister David, 2006, CVPR
   Oka K, 2002, IEEE COMPUT GRAPH, V22, P64, DOI 10.1109/MCG.2002.1046630
   OpenSource, 2011, FAST SIFT IM FEAT LI
   Peer P, 2003, HUMAN SKIN COLOR CLU, V2
   Pilet J, 2010, P IEEE VIRT REAL ANN, P71, DOI 10.1109/VR.2010.5444811
   Rekimoto J., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P113, DOI 10.1145/503376.503397
   Sergi a, 2007, Proceedings of the 1st international conference on Tangible and embedded interaction-TEI'07, P139, DOI [10.1145/1226969.1226998, DOI 10.1145/1226969.1226998]
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Verdie Y, 2008, EVOLUTION HAND TRACK
   Vos N, 2011, COMPUT EDUC, V56, P127, DOI 10.1016/j.compedu.2010.08.013
   Wagner D, 2010, IEEE T VIS COMPUT GR, V16, P355, DOI 10.1109/TVCG.2009.99
   Welch Greg., 2004, INTRO KALMAN FILTER
   Wilson A.C., 2004, INDIGENIZING ACAD, P69, DOI [10.1145/1027933.1027946, DOI 10.1145/1027933.1027946]
   Wilson A.D., 2010, ACM International Conference on Interactive Tabletops and Surfaces, P69, DOI DOI 10.1145/1936652.1936665
   Zerofrog, 2011, LIBSIFTFAST
   Zhang Zhengyou., 2001, WORKSHOP PERCEPTIVE, P1, DOI DOI 10.1145/971478.971522
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 47
TC 5
Z9 5
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 1837
EP 1868
DI 10.1007/s11042-012-1193-y
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500022
DA 2024-07-18
ER

PT J
AU Giró-i-Nieto, X
   Martos, M
   Mohedano, E
   Pont-Tuset, J
AF Giro-i-Nieto, Xavier
   Martos, Manuel
   Mohedano, Eva
   Pont-Tuset, Jordi
TI From global image annotation to interactive object segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interaction; Segmentation; Multiscale; Annotation; Hierarchical
ID ONTOLOGY
AB This paper presents a graphical environment for the annotation of still images that works both at the global and local scales. At the global scale, each image can be tagged with positive, negative and neutral labels referred to a semantic class from an ontology. These annotations can be used to train and evaluate an image classifier. A finer annotation at a local scale is also available for interactive segmentation of objects. This process is formulated as a selection of regions from a precomputed hierarchical partition called Binary Partition Tree. Three different semi-supervised methods have been presented and evaluated: bounding boxes, scribbles and hierarchical navigation. The implemented Java source code is published under a free software license.
RP Giró-i-Nieto, X (corresponding author), Campus Nord UPC,Modul D5,Jordi Girona 1-3, Barcelona 08034, Catalonia, Spain.
EM xavier.giro@upc.edu
RI Giró-i-Nieto, Xavier/M-5834-2013
OI Giró-i-Nieto, Xavier/0000-0002-9935-5332
FU Catalan Broadcasting Corporation [CENIT-2009-1026 BuscaMedia];
   Multicamera Video Processing using Scene Information: Applications to
   Sports Events, Visual Interaction and 3DTV [TEC2010-18094 MuViPro]
FX This work was partially founded by the Catalan Broadcasting Corporation
   through the Spanish project CENIT-2009-1026 BuscaMedia, and by Spanish
   project TEC2010-18094 MuViPro: "Multicamera Video Processing using Scene
   Information: Applications to Sports Events, Visual Interaction and
   3DTV."
CR [Anonymous], 2002, Introduction to MPEG- 7: Multimedia content description interface
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bishop Christopher M, 2006, PATTERN RECOGNITION, DOI DOI 10.1117/1.2819119
   Carcel E, 2011, MUSCLE INT WORKSH PI
   Cardoso J, 2007, IEEE INTELL SYST, V22, P84, DOI 10.1109/MIS.2007.4338499
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Dasiopoulou S, 2011, LECT NOTES ARTIF INT, V6050, P196, DOI 10.1007/978-3-642-20795-2_8
   Fellbaum C, 2010, THEORY AND APPLICATIONS OF ONTOLOGY: COMPUTER APPLICATIONS, P231, DOI 10.1007/978-90-481-8847-5_10
   Giro X, 2010, ACM INT C IM VID RET, P358, DOI DOI 10.1145/1816041.1816093
   Giro-i-Nieto X, 2010, MULTIMED TOOLS APPL, V46, P155, DOI 10.1007/s11042-009-0389-2
   Gulshan V, 2010, PROC CVPR IEEE, P3129, DOI 10.1109/CVPR.2010.5540073
   Hanbury A, 2008, J VISUAL LANG COMPUT, V19, P617, DOI 10.1016/j.jvlc.2008.01.002
   Lempitsky V, 2009, IEEE I CONF COMP VIS, P277, DOI 10.1109/ICCV.2009.5459262
   McGuinness K, 2010, PATTERN RECOGN, V43, P434, DOI 10.1016/j.patcog.2009.03.008
   Mezaris V, 2004, EURASIP J APPL SIG P, V2004, P886, DOI 10.1155/S1110865704401188
   Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63
   Noma A, 2012, PATTERN RECOGN, V45, P1159, DOI 10.1016/j.patcog.2011.08.017
   Petridis K, 2006, INT C KNOWL BAS INT
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Salembier P, 2000, IEEE T IMAGE PROCESS, V9, P561, DOI 10.1109/83.841934
   Steggink J, 2011, MULTIMEDIA SYST, V17, P367, DOI 10.1007/s00530-010-0220-y
   Volkmer T., 2005, 13th Annual ACM International Conference on Multimedia, P892, DOI 10.1145/1101149.1101341
   Von Ahn L, 2004, P SIGCHI C HUM FACT, DOI DOI 10.1145/985692.985733
NR 24
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 1
BP 475
EP 493
DI 10.1007/s11042-013-1374-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI4AK
UT WOS:000336807300022
DA 2024-07-18
ER

PT J
AU Isaza, C
   Salas, J
   Raducanu, B
AF Isaza, Cesar
   Salas, Joaquin
   Raducanu, Bogdan
TI Rendering ground truth data sets to detect shadows cast by static
   objects in outdoors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Synthetic ground truth data set; Sun position; Shadow detection; Static
   objects shadow detection
ID SOLAR; ALGORITHM; TRACKING; POSITION; IMAGES
AB In our work, we are particularly interested in studying the shadows cast by static objects in outdoor environments, during daytime. To assess the accuracy of a shadow detection algorithm, we need ground truth information. The collection of such information is a very tedious task because it is a process that requires manual annotation. To overcome this severe limitation, we propose in this paper a methodology to automatically render ground truth using a virtual environment. To increase the degree of realism and usefulness of the simulated environment, we incorporate in the scenario the precise longitude, latitude and elevation of the actual location of the object, as well as the sun's position for a given time and day. To evaluate our method, we consider a qualitative and a quantitative comparison. In the quantitative one, we analyze the shadow cast by a real object in a particular geographical location and its corresponding rendered model. To evaluate qualitatively the methodology, we use some ground truth images obtained both manually and automatically.
C1 [Isaza, Cesar; Salas, Joaquin] Inst Politecn Nacl, Mexico City, DF, Mexico.
   [Raducanu, Bogdan] Comp Vis Ctr, Barcelona, Spain.
C3 Instituto Politecnico Nacional - Mexico; Centre de Visio per Computador
   (CVC)
RP Isaza, C (corresponding author), Inst Politecn Nacl, Mexico City, DF, Mexico.
EM cesarisazab@gmail.com; jsalasr@ipn.mx; bogdan@cvc.uab.es
RI Salas, Joaquin/L-8912-2019; Isaza, Cesar/AGQ-5228-2022
OI Isaza, Cesar/0000-0002-0995-6231; salas, joaquin/0000-0002-0012-7963
FU IPN-SIP [20121642]
FX This research was partially supported by IPN-SIP under grant contract
   20121642.
CR Albin S, 2002, IEEE T IMAGE PROCESS, V11, P961, DOI 10.1109/TIP.2002.802544
   Blanco-Muriel M, 2001, SOL ENERGY, V70, P431, DOI 10.1016/S0038-092X(00)00156-0
   Bouguet J-Y., 2009, Camera calibration toolbox
   Dong X, 2005, PATTERN RECOGN LETT, V26, P91, DOI 10.1016/j.patrec.2004.09.005
   Foresti GL, 1999, IEEE T CIRC SYST VID, V9, P1045, DOI 10.1109/76.795058
   Gibson S., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P219
   Grena R, 2008, SOL ENERGY, V82, P462, DOI 10.1016/j.solener.2007.10.001
   Hsieh JW, 2003, IMAGE VISION COMPUT, V21, P505, DOI 10.1016/S0262-8856(03)00030-1
   Kaneva B, 2011, IEEE I CONF COMP VIS, P2282, DOI 10.1109/ICCV.2011.6126508
   Martel-Brisson N, 2005, PROC CVPR IEEE, P643
   Matsushita Y, 2004, IEEE T PATTERN ANAL, V26, P1336, DOI 10.1109/TPAMI.2004.86
   Mei X, 2009, IEEE I CONF COMP VIS, P583, DOI 10.1109/ICCV.2009.5459185
   Meister S, 2011, 2011 14 ITG C EL MED, P1
   Melamed ID, 2003, C N AM CHAPT ASS COM, V2, P505
   Mousazadeh H, 2009, RENEW SUST ENERG REV, V13, P1800, DOI 10.1016/j.rser.2009.01.022
   Nadimi S, 2004, IEEE T PATTERN ANAL, V26, P1079, DOI 10.1109/TPAMI.2004.51
   Prati A, 2003, IEEE T PATTERN ANAL, V25, P918, DOI 10.1109/TPAMI.2003.1206520
   Reda I, 2004, SOL ENERGY, V76, P577, DOI 10.1016/j.solener.2003.12.003
   Roy V, 2012, SUN POSITION
   Salvador E, 2004, COMPUT VIS IMAGE UND, V95, P238, DOI 10.1016/j.cviu.2004.03.008
   Santuari A, 2003, P 3 IASTED INT C VIS, P1
   Stauder J, 1999, IEEE T MULTIMEDIA, V1, P65, DOI 10.1109/6046.748172
   WALRAVEN R, 1978, SOL ENERGY, V20, P393, DOI 10.1016/0038-092X(78)90155-X
   Weiss Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P68, DOI 10.1109/ICCV.2001.937606
   Woodward A, 2005, C IM VIS COMP NZ
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 26
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 1
BP 557
EP 571
DI 10.1007/s11042-013-1409-9
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI4AK
UT WOS:000336807300026
DA 2024-07-18
ER

PT J
AU Tang, JH
   Hua, XS
AF Tang, Jinhui
   Hua, Xian-Sheng
TI Typicality ranking: beyond accuracy for video semantic annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video Annotation; Typicality Ranking; Average Typicality Precision
AB In video annotation, the typicalities or relevancy degrees of relevant samples to a certain concept are generally different. Thus we argue that it is more reasonable to rank typical relevant samples higher than non-typical ones. However, generally the labels of the training data only differentiate relevant of irrelevant; that is to say, typical or non-typical training samples have the same contribution to the learning process. Therefore, the learned scores of the unlabeled data cannot well measure the typicality. Accordingly, three preprocessing approaches are proposed to relax the labels of the training data to real-valued typicality scores. Then the typicality scores of the training data are propagated to unlabeled data using manifold ranking. Meanwhile, we propose to use a novel criterion, Average Typicality Precision (ATP), to replace the frequently used one, Average Precision (AP), for evaluating the performance of video typicality ranking algorithms. Though AP cares the number of relevant samples at the top of the annotation rank list, it actually does not care the typicality order of these samples, while which was taken into consideration of the evaluation strategy ATP. Experiments conducted on the TRECVID data set demonstrate that this typicality ranking scheme is more consistent with human perception than normal accuracy based ranking schemes.
C1 [Tang, Jinhui] Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Jiangsu, Peoples R China.
   [Hua, Xian-Sheng] Microsoft Bing Media Search, Redmond, WA USA.
C3 Nanjing University of Science & Technology
RP Tang, JH (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Jiangsu, Peoples R China.
EM jinhuitang@mail.njust.edu.cn; xshua@microsoft.com
RI Tang, Jinhui/KBR-0891-2024
OI Tang, Jinhui/0000-0001-9008-222X
FU National Nature Science Foundation of China (NSFC) [61103059, 61173104];
   Jiangsu Nature Science Foundation [BK2011700]
FX The work presented in this paper was partially supported by National
   Nature Science Foundation of China (NSFC) under grants 61103059 and
   61173104, and Jiangsu Nature Science Foundation under grant BK2011700.
CR [Anonymous], ACM INT C MULT
   [Anonymous], ACM MULTIMEDIA
   Duda R., 1973, Pattern Classification and Scene Analysis
   FENG SL, 2004, IEEE C COMP VIS PATT
   GHOSHAL A, 2005, ACM C RES DEV INF RE
   He J, 2006, IEEE T IMAGE PRO OCT
   Li X, 2009, IEEE T MULTIMED, V11
   Liu D, 2009, 18 INT C WORLD WID W
   Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63
   Rui Y, 1998, IEEE T CIRCUIT SYST
   SCHEIN AI, 2005, THESIS U PENNSYLVANI
   SCHOHN G, 2000, P 17 INT C MACH LEAR
   Schwaninger A, 2006, ACM T APPL PERCEPT, V3
   Seung HS, 1992, C COMP LEARN THEOR
   Shen J, 2011, MULTIMEDIA SYSTEMS
   Shen J, 2008, IEEE T CIRC SYST VID, V18, P11
   Smith JR, 2006, IEEE MULTIMEDIA, V13, P2
   Song Y, 2006, ACM INT WORKSH MULT
   SONG Y, 2005, ACM INT WORKSH MULT
   Tang J, 2011, MULTIMED TOOL APPL
   Tang J, 2006, ACM INT C MULT
   Tang J., 2008, IEEE T MULTIMEDIA, V10, P4
   Tang J, 2009, IEEE T SYST MAN CY B, V39, P2
   Tang J, 2007, IEEE INT C MULT EXP
   Tang J, 2007, ACM MULT AUGSB GERM
   Tang J., 2007, ELECT LETT, V43
   Tong H, 2005, ACM MULTIMEDIA
   Wang F, 2008, IEEE T KNOWL DATA EN, V20, P55, DOI 10.1109/TKDE.2007.190672
   Wang M., 2006, ACM INT C MULT
   Wu Y., 2004, ACM INT C MULT
   YAN R, 2005, IEEE C COMP VIS PATT
   Yan R, 2003, ACM INT C MULT
   YANG J, 2007, SIAM C DAT MIN
   Yuan X, 2006, ACM INT C MULT
   ZHOU D, 2003, 17 ANN C NEUR INF PR
NR 35
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 2
BP 647
EP 660
DI 10.1007/s11042-011-0892-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI6OW
UT WOS:000336995900004
DA 2024-07-18
ER

PT J
AU Wang, HD
   Liu, GZ
AF Wang, Haidong
   Liu, Guizhong
TI Priority and delay aware packet management framework for real-time video
   transport over 802.11e WLANs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real-time; Video; QoS; 802.11e; EDCA; Priority; Deadline
ID IEEE 802.11E; SCHEDULING ALGORITHM; PERFORMANCE ANALYSIS; IMAGE QUALITY;
   QOS SUPPORT; WIRELESS; TRANSMISSION; IEEE-802.11; STREAMS; SCHEME
AB The rigid delay constraint is one of the most challenging issues in real-time video delivery over wireless networks. The expired video packets will become useless for the decoding and display even if they are received correctly at the receiver. Because the significance of each video packet is different, the schedulers have to take into account not only the urgency of the packet but also its importance in the real-time video applications. However, the existing QoS-based IEEE 802.11e MAC protocol leaves the urgency and the importance of video packets out of consideration. This paper proposes a Priority and Delay Aware Packet Management Framework (PDA-PMF) to improve the transmission quality of real-time video streaming over IEEE 802.11e WLANs. In the MAC layer, this framework estimates the delay of each video packet. Subsequently, video packets are sent or dropped according to both the significance of the video packets and the estimation value of the delay. Simulation results show that the proposed scheme can not only reduce the packet losses, but also protect the more important video packets, so as to improve the received video quality effectively.
C1 [Wang, Haidong; Liu, Guizhong] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
   [Wang, Haidong] Taiyuan Univ Sci & Technol, Sch Elect & Informat Engn, Taiyuan, Peoples R China.
C3 Xi'an Jiaotong University; Taiyuan University of Science & Technology
RP Liu, GZ (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
EM whd.ty@stu.xjtu.edu.cn; liugz@xjtu.edu.cn
CR Abeysekera BAHS, 2008, IEEE T WIREL COMMUN, V7, P3517, DOI 10.1109/TWC.2008.070304
   Ansel P, 2006, MOBILE NETW APPL, V11, P391, DOI 10.1007/s11036-006-5191-z
   Bianchi G, 2000, IEEE J SEL AREA COMM, V18, P535, DOI 10.1109/49.840210
   Cerqueira E, 2011, MULTIMED TOOLS APPL, V54, P635, DOI 10.1007/s11042-010-0578-z
   Chakareski J, 2006, IEEE T MULTIMEDIA, V8, P207, DOI 10.1109/TMM.2005.864284
   Chen CM, 2010, IEEE T CIRC SYST VID, V20, P1448, DOI 10.1109/TCSVT.2010.2077475
   Chen YS, 2008, IEEE T VEH TECHNOL, V57, P1126, DOI 10.1109/TVT.2007.907027
   Chilamkurti N, 2010, MULTIMED TOOLS APPL, V47, P189, DOI 10.1007/s11042-009-0413-6
   Chou PA, 2006, IEEE T MULTIMEDIA, V8, P390, DOI 10.1109/TMM.2005.864313
   Du JC, 2010, PROC SPIE, V7744, DOI 10.1117/12.863501
   Dua A, 2010, IEEE T WIREL COMMUN, V9, P1001, DOI 10.1109/TWC.2010.03.070120
   Fiandrotti A, 2010, SIGNAL PROCESS-IMAGE, V25, P438, DOI 10.1016/j.image.2010.04.006
   Grilo A, 2003, IEEE WIREL COMMUN, V10, P36, DOI 10.1109/MWC.2003.1209594
   Jain R, 2004, IEEE MULTIMEDIA, V11, P96, DOI 10.1109/MMUL.2004.1261114
   Karamad E, 2009, IET COMMUN, V3, P871, DOI 10.1049/iet-com.2008.0676
   Kerry S., 2007, IEEE STD 80211 2007, P1
   Krishna PV, 2010, IEEE T VEH TECHNOL, V59, P1068, DOI 10.1109/TVT.2009.2031180
   Ksentini A, 2006, IEEE COMMUN MAG, V44, P107, DOI 10.1109/MCOM.2006.1580940
   Kuo WK, 2008, IET COMMUN, V2, P92, DOI 10.1049/iet-com:20060575
   Latré S, 2009, COMPUT NETW, V53, P1587, DOI 10.1016/j.comnet.2008.11.004
   Li F, 2010, IET COMMUN, V4, P1012, DOI 10.1049/iet-com.2009.0618
   Li F, 2009, IEEE T CIRC SYST VID, V19, P1908, DOI 10.1109/TCSVT.2009.2031457
   Liang YJ, 2008, IEEE T CIRC SYST VID, V18, P861, DOI 10.1109/TCSVT.2008.923139
   Liebl G., 2005, IEEE INT C MULT EXP
   Lin CH, 2009, TELECOMMUN SYST, V42, P223, DOI 10.1007/s11235-009-9182-9
   Liu H, 2006, INT C WIR MOB COMM 2
   Lu MH, 2007, WIREL COMMUN MOB COM, V7, P187, DOI 10.1002/wcm.473
   Mangold S, 2003, IEEE WIREL COMMUN, V10, P40, DOI 10.1109/MWC.2003.1265851
   Mohr AE, 2000, IEEE J SEL AREA COMM, V18, P819, DOI 10.1109/49.848236
   ROMANIAK P, 2008, 18 ITC SPEC SEM QUAL
   Ryu S, 2005, IEEE ICC, P2779
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Stuhlmüller K, 2000, IEEE J SEL AREA COMM, V18, P1012, DOI 10.1109/49.848253
   Takahashi A, 2008, IEEE COMMUN MAG, V46, P78, DOI 10.1109/MCOM.2008.4473087
   Tsai MF, 2010, MULTIMED TOOLS APPL, V47, P49, DOI 10.1007/s11042-009-0406-5
   van der Schaar M, 2006, IEEE T MOBILE COMPUT, V5, P755, DOI 10.1109/TMC.2006.81
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiao Y, 2005, IEEE T WIREL COMMUN, V4, P1506, DOI 10.1109/TWC.2005.850328
   Zhang R, 2000, IEEE J SEL AREA COMM, V18, P966, DOI 10.1109/49.848250
   Zorzi M, 1997, IEEE T VEH TECHNOL, V46, P445, DOI 10.1109/25.580783
NR 40
TC 8
Z9 8
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2014
VL 69
IS 3
BP 621
EP 641
DI 10.1007/s11042-012-1131-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4HM
UT WOS:000333209300004
DA 2024-07-18
ER

PT J
AU Verstockt, S
   Van Hoecke, S
   De Potter, P
   Lambert, P
   Hollemeersch, C
   Sette, B
   Merci, B
   Van de Walle, R
AF Verstockt, Steven
   Van Hoecke, Sofie
   De Potter, Pieterjan
   Lambert, Peter
   Hollemeersch, Charles
   Sette, Bart
   Merci, Bart
   Van de Walle, Rik
TI Multi-modal time-of-flight based fire detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video surveillance; Multi-modal; Multi-sensor; Time of flight imaging;
   Image registration; Flame features; Fire detection
ID VIDEO; REGISTRATION; RECOGNITION; STEREO; COLOR
AB This paper proposes two novel time-of-flight based fire detection methods for indoor and outdoor fire detection. The indoor detector is based on the depth and amplitude image of a time-of-flight camera. Using this multi-modal information, flames can be detected very accurately by fast changing depth and amplitude disorder detection. In order to detect the fast changing depth, depth differences between consecutive frames are accumulated over time. Regions which have multiple pixels with a high accumulated depth difference are labeled as candidate flame regions. Simultaneously, the amplitude disorder is also investigated. Regions with high accumulative amplitude differences and high values in all detail images of the amplitude image its discrete wavelet transform, are also labeled as candidate flame regions. Finally, if one of the depth and amplitude candidate flame regions overlap, fire alarm is given. The outdoor detector, on the other hand, only differs from the indoor detector in one of its multi-modal inputs. As depth maps are unreliable in outdoor environments, the outdoor detector uses a visual flame detector instead of the fast changing depth detection. Experiments show that the proposed detectors have an average flame detection rate of 94% with no false positive detections.
C1 [Verstockt, Steven; De Potter, Pieterjan; Lambert, Peter; Hollemeersch, Charles; Van de Walle, Rik] Ghent Univ IBBT, ELIS Dept, Multimedia Lab, B-9050 Ledeberg Ghent, Belgium.
   [Verstockt, Steven; Van Hoecke, Sofie] Ghent Univ Assoc, Univ Coll West Flanders, ELIT Lab, B-8500 Kortrijk, Belgium.
   [Sette, Bart] Warringtonfiregent WFRGent NV, B-9000 Ghent, Belgium.
   [Merci, Bart] Univ Ghent, Dept Flow Heat & Combust Mech, B-9000 Ghent, Belgium.
C3 Ghent University; Ghent University; HOWEST University of Applied
   Sciences; Ghent University
RP Verstockt, S (corresponding author), Ghent Univ IBBT, ELIS Dept, Multimedia Lab, Gaston Crommenlaan 8,Bus 201, B-9050 Ledeberg Ghent, Belgium.
EM steven.verstockt@elis.ugent.be
RI Van Hoecke, Sofie/KAM-3603-2024; Lambert, Peter/D-7776-2016
OI Lambert, Peter/0000-0001-5313-4158; De Potter,
   Pieterjan/0000-0002-1289-6575
FU Ghent University; Interdisciplinary Institute for Broadband Technology
   (IBBT); University College West Flanders (HOWEST); Warringtonfiregent
   (WFRGent NV); Institute for the Promotion of Innovation by Science and
   Technology in Flanders (IWT); Fund for Scientific Research-Flanders;
   Belgian Federal Science Policy Office (BFSPO); European Union
FX The research activities as described in this paper were funded by Ghent
   University, the Interdisciplinary Institute for Broadband Technology
   (IBBT), University College West Flanders (HOWEST), Warringtonfiregent
   (WFRGent NV), the Institute for the Promotion of Innovation by Science
   and Technology in Flanders (IWT), the Fund for Scientific
   Research-Flanders, the Belgian Federal Science Policy Office (BFSPO) and
   the European Union.
CR Alatan AA, 1998, IEEE T CIRC SYST VID, V8, P802, DOI 10.1109/76.735378
   [Anonymous], 2009, P 14 INT C AUTOMATIC
   [Anonymous], 2007, OPT ENG
   [Anonymous], 2007, P IFPA FIR SUPPR DET
   [Anonymous], 2011, PROT CULT HER
   [Anonymous], 2006 IEEE INT C VIDE, DOI DOI 10.1109/AVSS.2006.92
   Beder C., 2007, COMP VIS PATT REC 20, P1, DOI 10.1109/CVPR.2007.383348
   Bleiweiss A, 2009, LECT NOTES COMPUT SC, V5742, P58, DOI 10.1007/978-3-642-03778-8_5
   Borges PVK, 2008, EUR SIGN PROC C
   Bosch I, 2009, LECT NOTES COMPUT SC, V5602, P30, DOI 10.1007/978-3-642-02267-8_4
   Breuer P, 2007, LECT NOTES COMPUT SC, V4418, P247, DOI 10.1007/978-3-540-71457-6_23
   Calderara S, 2008, LECT NOTES COMPUT SC, V5008, P119
   Çelik T, 2009, FIRE SAFETY J, V44, P147, DOI 10.1016/j.firesaf.2008.05.005
   Chen HM, 2005, IEEE SIGNAL PROC MAG, V22, P52, DOI 10.1109/MSP.2005.1406480
   Chen TH, 2004, IEEE IMAGE PROC, P1707
   Dal Mutto C, 2010, P GRUPP TEL TECN INF
   Dorrington A A., 2009, The 16th Electronics New Zealand Conference (ENZCon), P95
   Doulamis A, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P684, DOI 10.1109/ICIP.2001.958211
   DOULAMIS A, 2000, J ARTIFICIAL INTELLI, V9, P277
   Grassi A, 2010, INFORM FUSION, P1
   Günay O, 2009, FIRE SAFETY J, V44, P860, DOI 10.1016/j.firesaf.2009.04.003
   Hamici Z, 2006, INT J ROBOT AUTOM, V21, P174, DOI 10.2316/Journal.206.2006.3.206-2724
   Han J, 2007, PATTERN RECOGN, V40, P1771, DOI 10.1016/j.patcog.2006.11.010
   Hansen DW, 2007, ISSCS 2007: INTERNATIONAL SYMPOSIUM ON SIGNALS, CIRCUITS AND SYSTEMS, VOLS 1 AND 2, P225
   Hugli Heinz, 2007, VISAPP 2007. Proceedings of the Second International Conference on Computer Vision Theory and Applications, P18
   Irani M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P959, DOI 10.1109/ICCV.1998.710832
   Krotosky SJ, 2007, COMPUT VIS IMAGE UND, V106, P270, DOI 10.1016/j.cviu.2006.10.008
   Leone A., 2008, P WORKSH MULT MULT S, P1
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Marbach G, 2006, FIRE SAFETY J, V41, P285, DOI 10.1016/j.firesaf.2006.02.001
   Meers S, 2008, P AUSTR C ROB AUT, P1
   Merci B, 2011, FIRE SAFETY EXPLOSIO
   Optrima, 2010, 3D TIM OF FLIGHT CAM
   Owrutsky JC, 2006, FIRE SAFETY J, V41, P315, DOI 10.1016/j.firesaf.2005.11.011
   Qi Xiaojun., 2009, Int J Imag, V2, P22
   Sabeti Leila, 2008, Journal of Multimedia, V3, P28, DOI 10.4304/jmm.3.2.28-36
   Schatzki T., 2009, P 2009 INT C ADV ROB, P1
   Shah Mubarak., 2003, VIDEO REGISTRATION
   Tanner Rudolf, 2008, 2008 IEEE Fifth International Conference on Advanced Video and Signal Based Surveillance, P356, DOI 10.1109/AVSS.2008.18
   Tombari F, 2008, LECT NOTES COMPUT SC, V5259, P645, DOI 10.1007/978-3-540-88458-3_58
   Toreyin B. Ugur, 2006, 2006 14th European Signal Processing Conference. Proceedings
   Töreyin BU, 2006, PATTERN RECOGN LETT, V27, P49, DOI 10.1016/j.patrec.2005.06.015
   Triantafyllidis GA, 2000, IEEE T CIRC SYST VID, V10, P563, DOI 10.1109/76.845001
   Vacek S, 2007, P EUR C MOB ROB FREI, P1
   Verstockt S, 2010, 6 INT SEM FIR EXPL H
   Verstockt S, 2010, 29 PROGR EL RES S PI, P1
   Verstockt S, 2012, MACH VISION APPL, V23, P1243, DOI 10.1007/s00138-011-0359-3
   Verstockt S, 2011, FIRE SAFETY J, V46, P262, DOI 10.1016/j.firesaf.2011.03.001
   Verstockt S, 2010, LECT NOTES COMPUT SC, V6134, P333, DOI 10.1007/978-3-642-13681-8_39
   Vescoukis V, 2012, FUTURE GENER COMP SY, V28, P593, DOI 10.1016/j.future.2011.03.010
   Wilson A.D., 2010, ACM International Conference on Interactive Tabletops and Surfaces, P69, DOI DOI 10.1145/1936652.1936665
   Zhan BB, 2008, MACH VISION APPL, V19, P345, DOI 10.1007/s00138-008-0132-4
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 53
TC 8
Z9 8
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2014
VL 69
IS 2
BP 313
EP 338
DI 10.1007/s11042-012-0991-6
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4FN
UT WOS:000333203400005
OA Green Published
DA 2024-07-18
ER

PT J
AU Gao, Z
   Zhang, LF
   Chen, MY
   Hauptmann, A
   Zhang, H
   Cai, AN
AF Gao, Zan
   Zhang, Long-fei
   Chen, Ming-yu
   Hauptmann, Alexander
   Zhang, Hua
   Cai, An-Ni
TI Enhanced and hierarchical structure algorithm for data imbalance problem
   in semantic extraction under massive video dataset
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data imbalance; Enhanced and hierarchical structure (EHS); Semantic
   indexing; Surveillance event detection; Massive video dataset; TRECVID
ID CLASSIFICATION; SMOTE
AB Data imbalance problem often exists in our real life dataset, especial for massive video dataset, however, the balanced data distribution and the same misclassification cost are assumed in traditional machine learning algorithms, thus, it will be difficult for them to accurately describe the true data distribution, and resulting in misclassification. In this paper, the data imbalance problem in semantic extraction under massive video dataset is exploited, and enhanced and hierarchical structure (called EHS) algorithm is proposed. In proposed algorithm, data sampling, filtering and model training are considered and integrated together compactly via hierarchical structure algorithm, thus, the performance of model can be improved step by step, and is robust and stability with the change of features and datasets. Experiments on TRECVID2010 Semantic Indexing demonstrate that our proposed algorithm has much more powerful performance than that of traditional machine learning algorithms, and keeps stable and robust when different kinds of features are employed. Extended experiments on TRECVID2010 Surveillance Event Detection also prove that our EHS algorithm is efficient and effective, and reaches top performance in four of seven events.
C1 [Gao, Zan; Zhang, Hua] Tianjin Univ Technol, Minist Educ, Key Lab Comp Vis & Syst, Tianjin 300384, Peoples R China.
   [Gao, Zan; Zhang, Hua] Tianjin Univ Technol, Tianjin Key Lab Intelligence Comp & Novel Softwar, Tianjin 300384, Peoples R China.
   [Zhang, Long-fei] Beijing Inst Technol, Sch Software, Beijing 100081, Peoples R China.
   [Gao, Zan; Zhang, Long-fei; Chen, Ming-yu; Hauptmann, Alexander] Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA.
   [Gao, Zan; Cai, An-Ni] Beijing Univ Posts & Telecommun, Sch Informat & Telecommun Engn, Beijing 100876, Peoples R China.
C3 Tianjin University of Technology; Tianjin University of Technology;
   Beijing Institute of Technology; Carnegie Mellon University; Beijing
   University of Posts & Telecommunications
RP Gao, Z (corresponding author), Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA.
EM zangaonsh4522@gmail.com
RI Chen, Mingyu/KUD-1670-2024
FU National Science Foundation [0624236, 0751185]; NSFC [90920001]; Key
   project in Science and Technology Pillar Program of Tianjin, P.R. China
   [10ZCKFGX00400]; Direct For Computer & Info Scie & Enginr; Div Of
   Information & Intelligent Systems [0624236] Funding Source: National
   Science Foundation; Division Of Computer and Network Systems; Direct For
   Computer & Info Scie & Enginr [0751185] Funding Source: National Science
   Foundation
FX This material is based in part upon work supported by the National
   Science Foundation under Grants No. 0624236 and 0751185. Zan Gao is
   partially supported by the NSFC (No. 90920001), and Key project in
   Science and Technology Pillar Program of Tianjin, P.R. China
   (10ZCKFGX00400). We also thank the anonymous reviewers for their
   valuable suggestions.
CR Abe N., 2004, P 10 ACM SIGKDD INT, P3
   Akbani R, 2004, LECT NOTES COMPUT SC, V3201, P39, DOI 10.1007/978-3-540-30115-8_7
   [Anonymous], P INT C MACH LEARN W
   [Anonymous], 2006, ACM SIGKDD Explor Newsl, DOI DOI 10.1145/1147234.1147236
   [Anonymous], 2007, MIR
   [Anonymous], 2004, ADV NEURAL INFORM PR
   [Anonymous], 2001, IEEE COMP SOC C COMP
   Batista G. E., 2004, ACM SIGKDD EXPL NEWS, V6, P20, DOI DOI 10.1145/1007730.1007735
   Chan PhilipK., 1998, KNOWLEDGE DISCOVERY, P164
   Chan PK, 1999, IEEE INTELL SYST APP, V14, P67, DOI 10.1109/5254.809570
   Chang S-F, 2006, TRECVID WORKSH
   Chawla N, 2003, P INT C MACH LEARN
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen K, 2006, IEEE IJCNN, P1770
   Chen M.-Y., 2009, Tech. Rep. CMU-CS- 09-161
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6
   Drucker H, 1997, ADV NEUR IN, V9, P155
   Drummond C., 2003, P INT C MACH LEARN W
   Elkan C., 2001, P INT JOINT C ART IN
   Estabrooks A, 2004, COMPUT INTELL-US, V20, P18, DOI 10.1111/j.0824-7935.2004.t01-1-00228.x
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Guo H., 2004, SIGKDD EXPLORATIONS, V6, P30, DOI DOI 10.1145/1007730.1007736
   Haibo He, 2007, Proceedings of the 2007 International Conference on Artificial Intelligence. ICAI 2007, P358
   Han H, 2005, LECT NOTES COMPUT SC, V3644, P878, DOI 10.1007/11538059_91
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   He HB, 2008, IEEE IJCNN, P1322, DOI 10.1109/IJCNN.2008.4633969
   Holte R. C., 1989, IJCAI-89 Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, P813
   Hong X, 2007, IEEE T NEURAL NETWOR, V18, P28, DOI 10.1109/TNN.2006.882812
   Japkowicz N., 2002, Intelligent Data Analysis, V6, P429
   Japkowicz N, 2000, P AAAI 2000 WORKSH L
   Japkowicz N., 2004, P IRIS MACH LEARN WO
   Jiang YG, 2010, IEEE T MULTIMEDIA, V12, P42, DOI 10.1109/TMM.2009.2036235
   Kolcz A., 2004, ACM SIGKDD EXPLORATI, V6, P1, DOI [10.2973/odp.proc.ir.207.2004, DOI 10.1145/1007730.1007733]
   Kubat M, 1998, MACH LEARN, V30, P195, DOI 10.1023/A:1007452223027
   Laurikkala J, 2001, LECT NOTES ARTIF INT, V2101, P63, DOI 10.1007/3-540-48229-6_9
   Liu XY, 2006, IEEE DATA MINING, P965
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Maloof M.A., 2003, LEARNING DATA SETS A, V2, P2
   Mease D, 2007, J MACH LEARN RES, V8, P409
   MEHROTRA R, 1992, PATTERN RECOGN, V25, P1479, DOI 10.1016/0031-3203(92)90121-X
   Peng Y, 2008, TRECVID WORKSH
   Phua C, 2004, SIGKDD Explorations, V6, P50, DOI DOI 10.1145/1007730.1007738
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Sun YM, 2006, IEEE DATA MINING, P592, DOI 10.1109/icdm.2006.29
   Tan Aik Choon, 2003, Genome Inform, V14, P206
   Ting KM, 2002, IEEE T KNOWL DATA EN, V14, P659, DOI 10.1109/TKDE.2002.1000348
   TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P769, DOI 10.1109/tsmc.1976.4309452
   Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Weiss G., 2001, EFFECT CLASS DISTRIB, DOI DOI 10.7282/T3-VPFW-SF95
   Weiss G.M., 2004, SIGKDD Explor. Newsl., V6, P7, DOI [10.1145/1007730.1007734, DOI 10.1145/1007730.1007734]
   Woods K. S., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P1417, DOI 10.1142/S0218001493000698
   WU G, 2003, ICML WORKSH LEARN IM
   YILMAZ E, 2006, P 15 ACM INT C INF K
   Zhang JMI, 2003, P ICML 2003 WORKSH L
   Zhou Z., 2006, AAAI Conference on Artificial Intelligence, P567
   Zhou ZH, 2006, IEEE T KNOWL DATA EN, V18, P63, DOI 10.1109/TKDE.2006.17
NR 58
TC 32
Z9 35
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2014
VL 68
IS 3
BP 641
EP 657
DI 10.1007/s11042-012-1071-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RO
UT WOS:000331084000007
DA 2024-07-18
ER

PT J
AU Lin, WY
   Chen, MY
AF Lin, Wei-Yang
   Chen, Ming-Yang
TI A novel framework for automatic 3D face recognition using quality
   assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric authentication; 3D face recognition; Quality assessment
ID FUSION
AB The quality of biometric samples plays an important role in biometric authentication systems because it has a direct impact on verification or identification performance. In this paper, we present a novel 3D face recognition system which performs quality assessment on input images prior to recognition. More specifically, a reject option is provided to allow the system operator to eliminate the incoming images of poor quality, e.g. failure acquisition of 3D image, exaggerated facial expressions, etc.. Furthermore, an automated approach for preprocessing is presented to reduce the number of failure cases in that stage. The experimental results show that the 3D face recognition performance is significantly improved by taking the quality of 3D facial images into account. The proposed system achieves the verification rate of 97.09% at the False Acceptance Rate (FAR) of 0.1% on the FRGC v2.0 data set.
C1 [Lin, Wei-Yang; Chen, Ming-Yang] Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi, Taiwan.
C3 National Chung Cheng University
RP Lin, WY (corresponding author), Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi, Taiwan.
EM wylin@cs.ccu.edu.tw
CR [Anonymous], P OD TOL SPAIN MAY
   [Anonymous], 2006, PROC 6 ICRASC
   [Anonymous], 2003, Handbook of fingerprint recognition
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bowyer K.W., 2005, IEEE WORKSHOP FACE R, P157
   Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005
   Chang KI, 2005, IEEE T PATTERN ANAL, V27, P619, DOI 10.1109/TPAMI.2005.70
   Cook J., 2006, P BRIT MACH VIS C
   Duda R., 1973, Pattern Classification and Scene Analysis
   Faltemier TC, 2008, IEEE T INF FOREN SEC, V3, P62, DOI 10.1109/TIFS.2007.916287
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Husken M., 2005, IEEE WORKSHOP FACE R, P174
   KALKA ND, 2005, THESIS W VIRGINIA U
   Lin W.-Y., 2006, P 2006 IEEE COMPUTER, V2, P1369
   Lin WY, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/240309
   Lu XG, 2006, IEEE T PATTERN ANAL, V28, P31, DOI 10.1109/TPAMI.2006.15
   Maurer T., 2005, P FACE RECOGNITION G, P154, DOI DOI 10.1109/CVPR.2005.581
   Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105
   Nandakumar K, 2006, INT C PATT RECOG, P473
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5
   Russ T, 2005, IEEE C COMP VIS PATT
   Shen L, 2001, LECT NOTES COMPUT SC, V2091, P266
   Simon-Zorita D, 2003, IEE P-VIS IMAGE SIGN, V150, P402, DOI 10.1049/ip-vis:20031037
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
   Wong KC, 2007, IEEE T SYST MAN CY B, V37, P1138, DOI 10.1109/TSMCB.2007.895325
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 29
TC 8
Z9 8
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2014
VL 68
IS 3
BP 877
EP 893
DI 10.1007/s11042-012-1092-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RO
UT WOS:000331084000018
DA 2024-07-18
ER

PT J
AU Okade, M
   Biswas, PK
AF Okade, Manish
   Biswas, Prabir Kumar
TI Video stabilization using maximally stable extremal region features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video stabilization; MSER; Camera motion estimation; Feature matching
ID DIGITAL IMAGE STABILIZATION
AB Video stabilization is an important technique in present day digital cameras as most of the cameras are hand-held, mounted on moving platforms or subjected to atmospheric vibrations. In this paper we propose a novel video stabilization scheme based on estimating the camera motion using maximally stable extremal region features. These features traditionally used in wide baseline stereo problems were never explored for video stabilization purposes. Through our extensive experiments show we how some properties of these region features are suitable for the stabilization task. After estimating the global camera motion parameters using these region features, we smooth the motion parameters using a gaussian filter to retain the desired motion. Finally, motion compensation is carried out to obtain a stabilized video sequence. A number of examples on real and synthetic videos demonstrate the effectiveness of our proposed approach. We compare our results to existing techniques and show how our proposed approach compares favorably to them. Interframe Transformation Fidelity is used for objective evaluation of our proposed approach.
C1 [Okade, Manish; Biswas, Prabir Kumar] IIT Kharagpur, Dept E & ECE, Kharagpur, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur
RP Okade, M (corresponding author), IIT Kharagpur, Dept E & ECE, Kharagpur, W Bengal, India.
EM okade.manish@ece.iitkgp.ernet.in; pkb@ece.iitkgp.ernet.in
RI Biswas, Prabir Kumar/AAV-4935-2021; Okade, Manish/AAT-1658-2020; Biswas,
   Prabir Kumar/AAY-5904-2021
CR [Anonymous], IEEE C COMP VIS PATT
   Auberger S, 2005, ISPA 2005: PROCEEDINGS OF THE 4TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P474, DOI 10.1109/ISPA.2005.195458
   Battiato S, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P373, DOI 10.1109/ICME.2008.4607449
   Battiato S, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P825, DOI 10.1109/ICIAP.2007.4362878
   Cenci A., 1999, Proc. 10th International Conference on Image Analysis and Processing, P665
   Chang JY, 2002, IEEE T CONSUM ELECTR, V48, P108, DOI 10.1109/TCE.2002.1010098
   Chen BY, 2008, COMPUT GRAPH FORUM, V27, P1805, DOI 10.1111/j.1467-8659.2008.01326.x
   Ertürk S, 2003, IEEE T CONSUM ELECTR, V49, P1320, DOI 10.1109/TCE.2003.1261235
   Ertürk S, 2000, IEE P-VIS IMAGE SIGN, V147, P95, DOI 10.1049/ip-vis:20000222
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fraundorfer F, 2005, WORKSH P CVPR
   Hong W, 2010, IEEE IMAGE PROC, P3501, DOI 10.1109/ICIP.2010.5649595
   Huang KY, 2010, IEEE IMAGE PROC, P3517, DOI 10.1109/ICIP.2010.5653052
   Jin JS, 2001, REAL-TIME IMAGING, V7, P357, DOI 10.1006/rtim.2000.0243
   Ko SJ, 1999, IEEE T CONSUM ELECTR, V45, P598, DOI 10.1109/30.793546
   Kumar S, 2011, IEEE T IMAGE PROCESS, V20, P3406, DOI 10.1109/TIP.2011.2156420
   Lee KY, 2009, IEEE I CONF COMP VIS, P1397
   Liang YM, 2004, IEEE T VEH TECHNOL, V53, P1636, DOI 10.1109/TVT.2004.836923
   Litvin A, 2003, PROC SPIE, V5022, P663, DOI 10.1117/12.476436
   Liu F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899408
   Liu F, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531350
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo QM, 2007, IRI 2007: PROCEEDINGS OF THE 2007 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION, P360
   Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384
   Matsushita Y, 2006, IEEE T PATTERN ANAL, V28, P1150, DOI 10.1109/TPAMI.2006.141
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Morimoto C, 1996, REAL-TIME IMAGING, V2, P285, DOI 10.1006/rtim.1996.0030
   Morimoto C, 1998, INT CONF ACOUST SPEE, P2789, DOI 10.1109/ICASSP.1998.678102
   Morimoto C, 1997, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.1997.609396
   OBDRZALEK S., 2002, BRIT MACHINE VISION, P113
   Okade M., 2011, Proceedings of the 2011 Third National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics (NCVPRIPG 2011), P78, DOI 10.1109/NCVPRIPG.2011.25
   PAIK JK, 1992, IEEE T CONSUM ELECTR, V38, P607, DOI 10.1109/30.156744
   Pang D. Huizhong, 2010, EFFICIENT VIDEO STAB
   Piva S, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P299, DOI 10.1109/AVSS.2003.1217935
   Puglisi G, 2011, IEEE T CIRC SYST VID, V21, P1390, DOI 10.1109/TCSVT.2011.2162689
   Qin C, 2012, MULTIMED TOOLS APPL, V56, P469, DOI 10.1007/s11042-010-0601-4
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Tuytelaars T, 2004, INT J COMPUT VISION, V59, P61, DOI 10.1023/B:VISI.0000020671.28016.e8
   UOMORI K, 1992, SMPTE J, V101, P66, DOI 10.5594/J02339
   Yang JL, 2009, IEEE T CIRC SYST VID, V19, P945, DOI 10.1109/TCSVT.2009.2020252
   Yu GS, 2009, INT CONF ACOUST SPEE, P1597, DOI 10.1109/ICASSP.2009.4959904
   Zhou J, 2011, IEEE T CIRC SYST VID, V21, P1879, DOI 10.1109/TCSVT.2011.2154810
NR 42
TC 26
Z9 27
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2014
VL 68
IS 3
BP 947
EP 968
DI 10.1007/s11042-012-1095-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RO
UT WOS:000331084000021
DA 2024-07-18
ER

PT J
AU Choi, H
   Im, K
   Kim, J
AF Choi, Hun
   Im, Kunshin
   Kim, Jinwoo
TI A comparative study of the motivational orientation type on users'
   behavior: focusing on ubiquitous computing services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information quality; System quality; Motivational orientation; Mobile
   data service; Contribution to quality of life
ID INFORMATION-SYSTEMS; MODEL; DETERMINANTS; SATISFACTION; VALIDATION;
   ACCEPTANCE; USAGE
AB One of the main problems of today's ubiquitous computing systems is that they do not meet their quality requirements. Ubiquitous computing services such as mobile data services (MDS) are fundamentally different from traditional information systems (IS) in terms of important quality factors such as information or system quality because it has been used in various life contexts. We identify important quality factors on various contexts in Korea MDS market. Using the results of qualitative study, we propose research model. To identify the effect of motivational orientation type on users' behavior, we classified users according to their propensities into intrinsic and extrinsic motivational orientation groups. The results show that the impact of quality factors on user satisfaction is differentiated depending on motivational orientation types. The paper concludes with a discussion of the study's limitations and implications.
C1 [Choi, Hun] Catholic Univ Pusan, Dept Management Informat Syst, Pusan, South Korea.
   [Im, Kunshin; Kim, Jinwoo] Yonsei Univ, Sch Business, Seoul 120749, South Korea.
C3 Catholic University Pusan; Yonsei University
RP Kim, J (corresponding author), Yonsei Univ, Sch Business, 613,134 Shinchon Dong, Seoul 120749, South Korea.
EM jinwoo@yonsei.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF); Ministry of Education, Science and Technology
   [2011-0012490]
FX The authors appreciate comments from editors and reviewers of Multimedia
   Tools and Applications. This research was supported by Basic Science
   Research Program through the National Research Foundation of Korea (NRF)
   funded by the Ministry of Education, Science and Technology
   (#2011-0012490).
CR AMABILE TM, 1988, RES ORGAN BEHAV, V10, P123
   AMABILE TM, 1994, J PERS SOC PSYCHOL, V66, P950, DOI 10.1037/0022-3514.66.5.950
   Ambrose PJ, 2006, IEEE T ENG MANAGE, V53, P112, DOI 10.1109/TEM.2005.861810
   Andrew F., 1976, SOCIAL INDICATORS WE
   Bhattacherjee A, 2004, MIS QUART, V28, P229
   BOLLEN K, 1991, PSYCHOL BULL, V110, P305, DOI 10.1037/0033-2909.110.2.305
   Bruseberg A, 2001, INT J HUM-COMPUT ST, V55, P435, DOI 10.1006/ijhc.2001.0479
   Buchanan G, 2001, P INT WWW C HONG KON
   Campbell A., 1976, QUALITY AM LIFE PERC
   Chin WW, 1998, QUANT METH SER, P295
   Choi M, 2003, P DIGIT SEATTL
   DAVIS FD, 1992, J APPL SOC PSYCHOL, V22, P1111, DOI 10.1111/j.1559-1816.1992.tb00945.x
   DeLone WH, 1992, INFORM SYST RES, V3, P60, DOI 10.1287/isre.3.1.60
   Diamantopoulos A, 2001, J MARKETING RES, V38, P269, DOI 10.1509/jmkr.38.2.269.18845
   DIENER E, 1984, PSYCHOL BULL, V95, P542, DOI 10.1037/0033-2909.95.3.542
   Federal Trade Commission, 2002, MOB WIR WEB DAT SERV
   Folmer E., 2003, ICSE Workshop on SE-HCI, P61
   FORNELL C, 1981, J MARKETING RES, V18, P39, DOI 10.2307/3151312
   Gefen D, 2003, MIS QUART, V27, P51, DOI 10.2307/30036519
   Hulland J, 1999, STRATEGIC MANAGE J, V20, P195, DOI 10.1002/(SICI)1097-0266(199902)20:2<195::AID-SMJ13>3.3.CO;2-Z
   IVES B, 1983, COMMUN ACM, V26, P785, DOI 10.1145/358413.358430
   Keil M, 2000, MIS QUART, V24, P299, DOI 10.2307/3250940
   Kim H, 2003, P HCI MIS 03 WORKSH
   Konkka K, 2005, P HCI INT LAS VEG
   Lee DJ, 1995, DEV QUALITY LIFE STU, V5, P13
   Lee MKO, 2005, INFORM MANAGE-AMSTER, V42, P1095, DOI 10.1016/j.im.2003.10.007
   Maguire M, 2005, P IFIP 17 WORLD COMP, P25
   Mankoff J, 2005, CHI2005 WORKSH PORTL
   McKinney V, 2002, INFORM SYST RES, V13, P296, DOI 10.1287/isre.13.3.296.76
   Minhee Chae, 2002, Electronic Markets, V12, P38, DOI 10.1080/101967802753433254
   Pavot W, 2009, SOC INDIC RES SER, V39, P101, DOI 10.1007/978-90-481-2354-4_5
   Ryan C., 2005, P 28 AUSTRALASIAN C, V38, P115
   Ryan RM, 2000, CONTEMP EDUC PSYCHOL, V25, P54, DOI 10.1006/ceps.1999.1020
   Seddon PB, 1997, INFORM SYST RES, V8, P240, DOI 10.1287/isre.8.3.240
   Shang RA, 2005, INFORM MANAGE-AMSTER, V42, P401, DOI 10.1016/j.im.2004.01.009
   Sirgy M.J., 2002, The psychology of quality of life
   Sirgy M.J., 1994, J MACROMARKETING, V14, P36, DOI DOI 10.1177/027614679401400204
   Sirgy MJ, 2001, SOC INDIC RES, V56, P125, DOI 10.1023/A:1012254826324
   Spreng RA, 1996, J MARKETING, V60, P15, DOI 10.2307/1251839
   Straub DW, 2001, INFORM SYST RES, V12, P337, DOI 10.1287/isre.12.4.337.9706
   Sun X., 2002, International Journal of Consumer Studies, V26, P34, DOI DOI 10.1046/J.1470-6431.2002.00208.X
   Venkatesh V, 2001, MIS QUART, V25, P71, DOI 10.2307/3250959
   WEISER M, 1991, SCI AM, V265, P94, DOI 10.1038/scientificamerican0991-94
   White JC, 2003, J MARKETING, V67, P63, DOI 10.1509/jmkg.67.3.63.18654
   Wixom BH, 2001, MIS QUART, V25, P17, DOI 10.2307/3250957
   Wixom BH, 2005, INFORM SYST RES, V16, P85, DOI 10.1287/isre.1050.0042
   Yi MY, 2003, INT J HUM-COMPUT ST, V59, P431, DOI 10.1016/S1071-5819(03)00114-9
NR 47
TC 7
Z9 10
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2014
VL 68
IS 2
BP 321
EP 336
DI 10.1007/s11042-012-1118-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA AA4RI
UT WOS:000331083400009
DA 2024-07-18
ER

PT J
AU Hamzaoui, A
   Letessier, P
   Joly, A
   Buisson, O
   Boujemaa, N
AF Hamzaoui, Amel
   Letessier, Pierre
   Joly, Alexis
   Buisson, Olivier
   Boujemaa, Nozha
TI Object-based visual query suggestion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual object; Object mining; Query suggestion; Shared neighbours;
   Clustering
AB State-of-the-art visual search systems allow to retrieve efficiently small rigid objects in very large datasets. They are usually based on the query-by-window paradigm: a user selects any image region containing an object of interest and the system returns a ranked list of images that are likely to contain other instances of the query object. User's perception of these tools is however affected by the fact that many submitted queries actually return nothing or only junk results (complex non-rigid objects, higher-level visual concepts, etc.). In this paper, we address the problem of suggesting only the object's queries that actually contain relevant matches in the dataset. This requires to first discover accurate object's clusters in the dataset (as an offline process); and then to select the most relevant objects according to user's intent (as an on-line process). We therefore introduce a new object's instances clustering framework based on a major contribution: a bipartite shared-neighbours clustering algorithm that is used to gather object's seeds discovered by matching adaptive and weighted sampling. Shared nearest neighbours methods were not studied beforehand in the case of bipartite graphs and never used in the context of object discovery. Experiments show that this new method outperforms state-of-the-art object mining and retrieval results on the Oxford Building dataset. We finally describe two object-based visual query suggestion scenarios using the proposed framework and show examples of suggested object queries.
C1 [Hamzaoui, Amel; Joly, Alexis] INRIA Rocquencourt, Team Project IMEDIA, F-78153 Le Chesnay, France.
   [Letessier, Pierre; Buisson, Olivier] INA, F-94366 Bry Sur Marne, France.
   [Boujemaa, Nozha] Inria Saclay, F-91893 Orsay, France.
RP Hamzaoui, A (corresponding author), INRIA Rocquencourt, Team Project IMEDIA, BP 105, F-78153 Le Chesnay, France.
EM amel.hamzaoui@inria.fr; pierre.letessier@ina.fr; Alexis.joly@inria.fr;
   obuisson@ina.fr; Nozha.boujemaa@inria.fr
RI joly, alexis/AAV-3101-2021
OI joly, alexis/0000-0002-2161-9940
FU EU FP7 project I-SEARCH
FX A part of this work has been supported by the EU FP7 project I-SEARCH.
CR Anjulan A, 2009, IEEE T CIRC SYST VID, V19, P63, DOI 10.1109/TCSVT.2008.2005801
   [Anonymous], 2007, NIPS
   [Anonymous], 2009, P 17 ACM INT C MULTI
   [Anonymous], THESIS U OXFORD
   [Anonymous], 2008, P IEEE C COMP VIS PA
   [Anonymous], 2007, CVPR
   [Anonymous], 2009, P 17 ACM INT C MULTI, DOI DOI 10.1145/1631272.1631361
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Broder AZ, 1998, COMPRESSION AND COMPLEXITY OF SEQUENCES 1997 - PROCEEDINGS, P21, DOI 10.1109/SEQUEN.1997.666900
   Chum O., 2008, P BRIT MACH VIS C, P493
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Chum O, 2009, PROC CVPR IEEE, P17, DOI 10.1109/CVPRW.2009.5206531
   Chum O, 2010, IEEE T PATTERN ANAL, V32, P371, DOI 10.1109/TPAMI.2009.166
   Devroye L., 1986, Non-Uniform Random Variate Generation
   Grauman K., 2006, CVPR 1, P19
   Guha S, 1999, PROC INT CONF DATA, P512, DOI 10.1109/ICDE.1999.754967
   Hamzaoui A, 2011, MULTIMED TOOLS APPL, V51, P479, DOI 10.1007/s11042-010-0637-5
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Hongyuan Zha, 2001, Proceedings of the 2001 ACM CIKM. Tenth International Conference on Information and Knowledge Management, P25
   Houle M., 2008, Statistical Analysis and Data Mining, V1, P157, DOI DOI 10.1002/sam.10013
   Jégou H, 2010, INT J COMPUT VISION, V87, P316, DOI 10.1007/s11263-009-0285-2
   Joly Alexis., 2008, PROCEEDING 16 ACM IN, P209
   Kuo Yin-Hsi., 2009, ACM Multimedia, P65
   Letessier Letessier P, 2011, P 1 ACM INT C MULT R
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Olken Frank., 1993, THESIS U CALIFORNIA
   PHILBIN J, 2008, P BRIT MACH VIS C LE
   Philbin J, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P738, DOI 10.1109/ICVGIP.2008.103
   Seber G.A.F, 1995, SURVEY STAT, V32, P13
   Sivic J, 2008, PROC CVPR IEEE, P1, DOI 10.1109/CVPRW.2008.4562950
   Tang Jiayu., 2008, International Conference on Content-based Image and Video Retrieval, P105
   Tuytelaars T, 2010, INT J COMPUT VISION, V88, P284, DOI 10.1007/s11263-009-0271-8
   Xu GD, 2010, LECT NOTES ARTIF INT, V6278, P398
NR 33
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2014
VL 68
IS 2
BP 429
EP 454
DI 10.1007/s11042-012-1340-5
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RI
UT WOS:000331083400016
DA 2024-07-18
ER

PT J
AU Kotus, J
   Lopatka, K
   Czyzewski, A
AF Kotus, Jozef
   Lopatka, Kuba
   Czyzewski, Andrzej
TI Detection and localization of selected acoustic events in acoustic field
   for smart surveillance applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Acoustic event detection; Sound localization; Audio surveillance
AB A method for automatic determination of position of chosen sound events such as speech signals and impulse sounds in 3-dimensional space is presented. The events are localized in the presence of sound reflections employing acoustic vector sensors. Human voice and impulsive sounds are detected using adaptive detectors based on modified peak-valley difference (PVD) parameter and sound pressure level. Localization based on signals from the multichannel acoustic vector probe is performed upon the detection. The described algorithms can be employed in surveillance systems to monitor behavior of public events participants. The results can be used to detect sound source position in real time or to calculate the spatial distribution of sound energy in the environment. Moreover, the spatial filtration can be performed to separate sounds arriving from a chosen direction.
C1 [Kotus, Jozef; Lopatka, Kuba; Czyzewski, Andrzej] Gdansk Univ Technol, Multimedia Syst Dept, PL-80233 Gdansk, Poland.
C3 Fahrenheit Universities; Gdansk University of Technology
RP Kotus, J (corresponding author), Gdansk Univ Technol, Multimedia Syst Dept, Narutowicza 11-12, PL-80233 Gdansk, Poland.
EM joseph@sound.eti.pg.gda.pl; klopatka@sound.eti.pg.gda.pl;
   andcz@sound.eti.pg.gda.pl
RI Czyzewski, Andrzej/JXN-0946-2024
OI Czyzewski, Andrzej/0000-0001-9159-8658
FU European Commission [218086]
FX The presented research is subsidized by the European Commission within
   FP7 project "INDECT" (Grant Agreement No. 218086).
CR Basten T, 2007, ERF33
   CZYZEWSKI A., 2010, AUTOMATIC LOCALIZATI, P441
   de Bree H.-E., 2009, The Microflown e-book
   de Bree HE, 2011, INT 2011 P OS
   de Bree HE, 2010, P DAGA 2010 BERL
   deBree HE, 1996, SENSOR ACTUAT A-PHYS, V54, P552, DOI 10.1016/S0924-4247(97)80013-1
   Fahy F.J., 1995, SOUND INTENSITY, V2nd
   Hawkes M, 2003, IEEE T SIGNAL PROCES, V51, P1479, DOI 10.1109/TSP.2003.811225
   Kotus Jozef, 2010, 2010 2nd International Conference on Information Technology (ICIT 2010), P67
   KOTUS J., 2010, IEEE INT C MULT COMM, P140
   Lehmann EL., 1998, THEORY POINT ESTIMAT, DOI 10.1007/b98854
   Lopatka K, 2011, ARCH ACOUST, V36, P851, DOI 10.2478/v10168-011-0056-2
   Smith S.W., 1997, SCI ENG GUIDE DIGITA
   Valenzise G, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P21, DOI 10.1109/AVSS.2007.4425280
   Yoo IC, 2009, ETRI J, V31, P451, DOI 10.4218/etrij.09.0209.0104
   Zhuang XD, 2010, PATTERN RECOGN LETT, V31, P1543, DOI 10.1016/j.patrec.2010.02.005
NR 16
TC 30
Z9 44
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2014
VL 68
IS 1
BP 5
EP 21
DI 10.1007/s11042-012-1183-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 283JZ
UT WOS:000329243600002
OA hybrid
DA 2024-07-18
ER

PT J
AU Saini, M
   Atrey, PK
   Mehrotra, S
   Kankanhalli, M
AF Saini, Mukesh
   Atrey, Pradeep K.
   Mehrotra, Sharad
   Kankanhalli, Mohan
TI W<SUP>3</SUP>-privacy: understanding <i>what, when</i>, and <i>where</i>
   inference channels in multi-camera surveillance video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Privacy; Surveillance; Video; Modeling; Events; Anonymity
ID EVENT DETECTION; PRIVACY; MODEL
AB Huge amounts of video are being recorded every day by surveillance systems. Since video is capable of recording and preserving an enormous amount of information which can be used in many applications, it is worth examining the degree of privacy loss that might occur due to public access to the recorded video. A fundamental requirement of privacy solutions is an understanding and analysis of the inference channels than can lead to a breach of privacy. Though inference channels and privacy risks are well studied in traditional data sharing applications (e.g., hospitals sharing patient records for data analysis), privacy assessments of video data have been limited to the direct identifiers such as people's faces in the video. Other important inference channels such as location (Where), time (When), and activities (What) are generally overlooked. In this paper we propose a privacy loss model that highlights and incorporates identity leakage through multiple inference channels that exist in a video due to what, when, and where information. We model the identity leakage and the sensitive information separately and combine them to calculate the privacy loss. The proposed identity leakage model is able to consolidate the identity leakage through multiple events and multiple cameras. The experimental results are provided to demonstrate the proposed privacy analysis framework.
C1 [Saini, Mukesh; Kankanhalli, Mohan] Natl Univ Singapore, Sch Comp, Singapore 117548, Singapore.
   [Atrey, Pradeep K.] Univ Winnipeg, Dept Appl Comp Sci, Winnipeg, MB R3B 2E9, Canada.
   [Mehrotra, Sharad] Univ Calif Irvine, Informat & Comp Sci Dept, Irvine, CA USA.
C3 National University of Singapore; University of Winnipeg; University of
   California System; University of California Irvine
RP Saini, M (corresponding author), Natl Univ Singapore, Sch Comp, Singapore 117548, Singapore.
EM mksaini@comp.nus.edu.sg; p.atrey@uwinnipeg.ca; sharad@ics.uci.edu;
   mohan@comp.nus.edu.sg
RI Kankanhalli, Mohan/Q-9284-2019
OI Kankanhalli, Mohan/0000-0002-4846-2015; mehrotra,
   sharad/0000-0003-1667-5435
FU Direct For Computer & Info Scie & Enginr [1118127] Funding Source:
   National Science Foundation; Direct For Computer & Info Scie & Enginr;
   Division Of Computer and Network Systems [1212943] Funding Source:
   National Science Foundation; Division Of Computer and Network Systems
   [1118127] Funding Source: National Science Foundation
CR Aggarwal JK, 1997, IEEE NONRIGID AND ARTICULATED MOTION WORKSHOP, PROCEEDINGS, P90, DOI 10.1109/NAMW.1997.609859
   Akyildiz IF, 2002, IEEE COMMUN MAG, V40, P102, DOI 10.1109/MCOM.2002.1024422
   [Anonymous], SPIE NEWSROOM
   [Anonymous], ACM INT C PRIV SEC T
   [Anonymous], ACM INT C MULT
   Atrey PK, 2006, MULTIMEDIA SYST, V12, P239, DOI 10.1007/s00530-006-0063-8
   Boyle M., 2000, CSCW 2000. ACM 2000 Conference on Computer Supported Cooperative Work, P1, DOI 10.1145/358916.358935
   Carrillo P, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P273, DOI 10.1109/ICME.2008.4607424
   Chinomi K, 2008, LECT NOTES COMPUT SC, V4903, P144
   Chong CY, 2003, P IEEE, V91, P1247, DOI 10.1109/JPROC.2003.814918
   Dwork C, 2006, LECT NOTES COMPUT SC, V4052, P1
   Fernández C, 2011, EXPERT SYST APPL, V38, P4068, DOI 10.1016/j.eswa.2010.09.070
   Ferrucci D, 2010, PACT 2010: PROCEEDINGS OF THE NINETEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P1, DOI 10.1145/1854273.1854275
   Fidaleo D.-A., 2004, VSSN '04: Proceedings of the ACM 2nd international workshop on Video surveillance sensor networks, P46
   Fung BCM, 2010, ACM COMPUT SURV, V42, DOI 10.1145/1749603.1749605
   Hayes-Roth F., 1984, Building expert systems
   Hendler J, 2008, FOUND ARTIF INTELL, P821, DOI 10.1016/S1574-6526(07)03021-0
   Koshimizu T., 2006, P 3 ACM WORKSHOP CON, P35
   Langheinrich Marc, 2001, Ubicomp 2001: Ubiquitous Computing, P273
   Lu Y, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, PROCEEDINGS, P807
   McBratney Alex, 2005, Precision Agriculture, V6, P7, DOI 10.1007/s11119-005-0681-8
   Moncrieff S, 2008, ACM T MULTIM COMPUT, V5, DOI 10.1145/1413862.1413863
   Piciarelli C, 2011, IEEE INTELL SYST, V26, P32, DOI 10.1109/MIS.2010.38
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Qureshi FZ, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P442, DOI 10.1109/AVSS.2009.97
   Saini M, 2010, IEEE INT CON MULTI, P60, DOI 10.1109/ICME.2010.5583334
   Senior A, 2005, IEEE SECUR PRIV, V3, P50, DOI 10.1109/MSP.2005.65
   Septian H, 2006, INT C CONTROL AUTOMA, P1
   Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648
   Thuraisingham B., 2006, SACMAT 2006. Proceedings of Eleventh ACM Symposium on Access Control Models and Technologies, P1
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   Westermann U, 2007, IEEE MULTIMEDIA, V14, P19, DOI 10.1109/MMUL.2007.23
   Wickramasuriya J., 2004, MULTIMEDIA '04, P48, DOI DOI 10.1145/1027527.1027537
   Wildes RP, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P343, DOI 10.1109/ICCV.2001.937646
   ZHU Z., 2007, IEEE Conference on Computer Vision and Pattern Recognition, P1
   Zhu Z.Q., 2008, VEHICLE POWER PROPUL, P1
NR 36
TC 37
Z9 40
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2014
VL 68
IS 1
BP 135
EP 158
DI 10.1007/s11042-012-1207-9
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 283JZ
UT WOS:000329243600009
DA 2024-07-18
ER

PT J
AU Wang, ZY
   Guan, GL
   Qiu, Y
   Zhuo, L
   Feng, DG
AF Wang, Zhiyong
   Guan, Genliang
   Qiu, Yu
   Zhuo, Li
   Feng, Dagan
TI Semantic context based refinement for news video annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video annotation; News video; Semantic context; Semantic similarity;
   Random walk
ID DRIVEN IMAGE INTERPRETATION; CONCEPT ONTOLOGY; SIMILARITY; RETRIEVAL
AB Automatic video annotation is to bridge the semantic gap and facilitate concept based video retrieval by detecting high level concepts from video data. Recently, utilizing context information has emerged as an important direction in such domain. In this paper, we present a novel video annotation refinement approach by utilizing extrinsic semantic context extracted from video subtitles and intrinsic context among candidate annotation concepts. The extrinsic semantic context is formed by identifying a set of key terms from video subtitles. The semantic similarity between those key terms and the candidate annotation concepts is then exploited to refine initial annotation results, while most existing approaches utilize textual information heuristically. Similarity measurements including Google distance and WordNet distance have been investigated for such a refinement purpose, which is different with approaches deriving semantic relationship among concepts from given training datasets. Visualness is also utilized to discriminate individual terms for further refinement. In addition, Random Walk with Restarts (RWR) technique is employed to perform final refinement of the annotation results by exploring the inter-relationship among annotation concepts. Comprehensive experiments on TRECVID 2005 dataset have been conducted to demonstrate the effectiveness of the proposed annotation approach and to investigate the impact of various factors.
C1 [Wang, Zhiyong; Qiu, Yu; Feng, Dagan] Univ Sydney, Sch Informat Technol, Sydney, NSW 2006, Australia.
   [Guan, Genliang] Univ Sydney, Sch Informat Technol, Biomed & Multimedia Informat Technol BMIT Res Grp, Sydney, NSW 2006, Australia.
   [Zhuo, Li] Beijing Univ Technol, Signal & Informat Proc Lab, Beijing, Peoples R China.
   [Feng, Dagan] Hong Kong Polytech Univ, Dept Elect & Informat Engn, Kowloon, Hong Kong, Peoples R China.
C3 University of Sydney; University of Sydney; Beijing University of
   Technology; Hong Kong Polytechnic University
RP Wang, ZY (corresponding author), Univ Sydney, Sch Informat Technol, Sydney, NSW 2006, Australia.
EM zhiyong.wang@sydney.edu.au
OI Feng, Dagan/0000-0002-3381-214X; Wang, Zhiyong/0000-0002-8043-0312
FU ARC; Hong Kong Polytechnic University; Nature Science Foundation of
   China [60772069]; 863 High-Tech Project [2009AA12Z111]; Nature Science
   Foundation of Beijing [4102008]
FX We would like to thank the anonymous reviewers for their constructive
   comments. The work presented in this paper is partially supported by
   grants from ARC, Hong Kong Polytechnic University, Nature Science
   Foundation of China (60772069), 863 High-Tech Project (2009AA12Z111),
   and Nature Science Foundation of Beijing (4102008).
CR [Anonymous], ACM INT C IM VID RET
   [Anonymous], NIST TRECVID WORKSH
   [Anonymous], ACM INT C MULT
   [Anonymous], ACM INT C IM VID RET
   [Anonymous], IEEE INT WORKSH MULT
   [Anonymous], INT C KNOWL CAPT BAN
   [Anonymous], MACHINE LEARNING TEC
   [Anonymous], 2010, P INT C MULT
   [Anonymous], INT C DIG IM COMP TE
   [Anonymous], P INT WORKSH MULT IN
   Ballan L, 2010, IEEE MULTIMEDIA, V17, P80, DOI 10.1109/MMUL.2010.4
   Benitez AB, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P613
   Bertini M., 2006, PROC 14 ANN ACM INT, P679
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Chen ZN, 2011, MULTIMED TOOLS APPL, V55, P53, DOI 10.1007/s11042-010-0604-1
   Cilibrasi RL, 2007, IEEE T KNOWL DATA EN, V19, P370, DOI 10.1109/TKDE.2007.48
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   DESCHACHT K, 2007, P 45 ANN M ASS COMP, P1000
   Fan J, 2007, IEEE T MULTIMEDIA, V9, P939, DOI 10.1109/TMM.2007.900143
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   Feng D., 2003, Multimedia Information Retrieval and Management: Technological Fundamentals and Applications
   Feng Yansong., 2008, P ACL 08 HLT, P272
   Fu H, 2004, I C CONT AUTOMAT ROB, P681
   Fu H, 2009, PATTERN RECOGN, V42, P126, DOI 10.1016/j.patcog.2008.06.021
   Fu H, 2006, PATTERN RECOGN, V39, P1604, DOI 10.1016/j.patcog.2005.12.015
   Fu H, 2010, PATTERN RECOGN, V43, P3539, DOI 10.1016/j.patcog.2010.04.009
   Hanbury A, 2008, J VISUAL LANG COMPUT, V19, P617, DOI 10.1016/j.jvlc.2008.01.002
   Hoogs A, 2003, PROC CVPR IEEE, P327
   Jain R., 2010, INT C MULTIMEDIA, P1259, DOI DOI 10.1145/1873951.1874199
   Jiang W, 2009, INT CONF ACOUST SPEE, P1765, DOI 10.1109/ICASSP.2009.4959946
   Jiang YG, 2009, IEEE I CONF COMP VIS, P1420, DOI 10.1109/ICCV.2009.5459295
   Jiang YG, 2010, IEEE T MULTIMEDIA, V12, P42, DOI 10.1109/TMM.2009.2036235
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li XR, 2009, IEEE T MULTIMEDIA, V11, P1310, DOI 10.1109/TMM.2009.2030598
   Lin D., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P296
   Liu Dong., 2010, Proceedings of the International Conference on Multimedia, P491
   Manning C.D., 1999, FDN STAT NATURAL LAN
   Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63
   Naphade MR, 2002, IEEE T CIRC SYST VID, V12, P40
   Page L., 1999, PAGERANK CITATION RA
   Qi G.J., 2007, P 15 ACM INT C MULTI, P17, DOI DOI 10.1145/1291233.1291245
   Schreiber AT, 2001, IEEE INTELL SYST APP, V16, P66, DOI 10.1109/5254.940028
   Shi R, 2006, LECT NOTES COMPUT SC, V4071, P102
   Snoek CGM, 2007, IEEE T MULTIMEDIA, V9, P975, DOI 10.1109/TMM.2007.900156
   Velivelli A., 2006, P IEEE C COMPUTER VI, P115
   Wang CB, 2006, LECT NOTES COMPUT SC, V4035, P647, DOI 10.1145/1180639.1180774
   Wang G, 2009, SIGNALS COMMUN TECHN, P125, DOI 10.1007/978-0-387-76569-3_5
   Wang M, 2009, IEEE T MULTIMEDIA, V11, P465, DOI 10.1109/TMM.2009.2012919
   Wang M, 2009, COMPUT VIS IMAGE UND, V113, P384, DOI 10.1016/j.cviu.2008.08.003
   Wang M, 2009, IEEE T CIRC SYST VID, V19, P733, DOI 10.1109/TCSVT.2009.2017400
   Wang XJ, 2008, IEEE T PATTERN ANAL, V30, P1919, DOI 10.1109/TPAMI.2008.127
   Wu Y, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1003, DOI 10.1109/ICME.2004.1394372
   Xu HX, 2009, PROCEEDINGS OF THE 2009 WRI GLOBAL CONGRESS ON INTELLIGENT SYSTEMS, VOL III, P573, DOI 10.1109/GCIS.2009.320
   Yan R, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P301, DOI 10.1109/ICME.2006.262458
   Yohan Jin, 2005, 13th Annual ACM International Conference on Multimedia, P706
   Zhang DS, 2012, PATTERN RECOGN, V45, P346, DOI 10.1016/j.patcog.2011.05.013
   Zhuang Jinfeng., 2011, WSDM, P625
NR 58
TC 9
Z9 10
U1 0
U2 80
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2013
VL 67
IS 3
BP 607
EP 627
DI 10.1007/s11042-012-1060-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 209JD
UT WOS:000323750900005
DA 2024-07-18
ER

PT J
AU Febiansyah, H
   Kwon, JB
AF Febiansyah, Hidayat
   Kwon, Jin Baek
TI Dynamic proxy-assisted scalable broadcasting of videos for heterogeneous
   environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia systems; Video-on-demand; Video broadcasting; Scheduling;
   Heterogeneous clients
ID PERIODIC BROADCAST; SCHEME
AB Periodic broadcasting (PB) is a scalable technique for providing video-on-demand services. It significantly reduces server I/O and backbone network bandwidth requirements at the expense of high storage space and high network bandwidth requirements for clients. Traditional protocols assume homogeneous clients with identical resources. Unfortunately, in practice clients have very different bandwidths, and these are usually insufficient to provide video-on-demand (VoD) service from a PB server. Existing work on heterogeneous clients has focused on devising broadcast schedules to cater to low-bandwidth clients, which inevitably requires an extra backbone network bandwidth between the server and the clients. In our previous work, we proposed to use proxies residing at the edge of backbone network to accommodate low bandwidth clients for PB-based VoD services. The server broadcasts a video using a PB protocol while the proxy receives and stores the data in its local buffer and broadcasts the stored data to the clients in its local network. It significantly reduces the waiting time of low-bandwidth clients without requiring any extra backbone bandwidth by using a proxy buffer and channels. However, although lots of PB protocols have been proposed, the scheme can be applied only to some old PB protocols based on a pyramid protocol. In this paper, we propose a proxy-assisted PB system that can be generally applied to almost all the existing PB protocols, by dynamically managing buffer space and channels in proxy servers. Thus, with our proposed system, PB VoD system can be optimized in terms of the resource usages in backbone networks, proxy servers, and clients, by adopting more suitable PB protocols.
C1 [Febiansyah, Hidayat; Kwon, Jin Baek] Sun Moon Univ, Asan 336708, Chungnam, South Korea.
C3 Sun Moon University
RP Kwon, JB (corresponding author), Sun Moon Univ, Kalsan 100, Asan 336708, Chungnam, South Korea.
EM havban@gmail.com; jbkwon@sunmoon.ac.kr
OI FEBIANSYAH, HIDAYAT/0000-0003-0255-0762
FU Sun Moon University
FX This work was supported by the Sun Moon University Research Grant of
   2010.
CR AGGARWAL C, 1996, IEEE INT C MULT COMP
   Aggarwal CC, 2001, IEEE T COMPUT, V50, P97, DOI 10.1109/12.908987
   AGGARWAL CC, 1996, IEEE P INT C MULT CO, P118
   Anderson N, 1996, INTRO IPTV
   Asahiro Y, 2008, P IEEE S FDN COMP SC
   BAGOUET O, 2003, P MULT COMP NETW SAN
   Carter SW, 1997, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATIONS AND NETWORKS, PROCEEDINGS, P200, DOI 10.1109/ICCCN.1997.623313
   Chan HL, 2010, SORTING BUFFER PROBL
   Dan A., 1994, Proceedings ACM Multimedia '94, P15, DOI 10.1145/192593.192614
   Ding JW, 2008, IEEE T BROADCAST, V54, P14, DOI 10.1109/TBC.2007.914722
   Eager D, 2001, IEEE T KNOWL DATA EN, V13, P742, DOI 10.1109/69.956098
   Eager D, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P199, DOI 10.1145/319463.319601
   Englert DO M., 2008, P IEEE S FDN COMP SC
   GAO L, 1998, P 8 INT WORKSH NETW
   Gao LX, 2003, IEEE ACM T NETWORK, V11, P884, DOI 10.1109/TNET.2003.820423
   Gill P, 2008, ACM T MULTIM COMPUT, V5, DOI 10.1145/1404880.1404888
   HUA K, 1998, IEEE ICCCN 98 LAF LA
   Hua K. A., 1998, Proceedings ACM Multimedia 98, P191, DOI 10.1145/290747.290771
   Hua K. A., 1997, Computer Communication Review, V27, P89, DOI 10.1145/263109.263144
   Juhn LS, 1998, IEEE T BROADCAST, V44, P100, DOI 10.1109/11.713059
   Kusmierek E., 2004, Journal of Internet Technology, V5, P289
   Kusmierek E, 2008, MULTIMED TOOLS APPL, V36, P243, DOI 10.1007/s11042-007-0135-6
   Kwon JB, 2011, MULTIMED TOOLS APPL, V51, P1105, DOI 10.1007/s11042-010-0461-y
   Mahanti A, 2003, IEEE ACM T NETWORK, V11, P195, DOI 10.1109/TNET.2003.810311
   PARIS JF, 1999, P 1999 MULT COMP NET, P317
   SHI L, 2006, P ACM MULT SANT BAB
   Stalling W, 2010, DATA COMPUTER COMMUN
   Tantaoui MA, 2004, IEEE T BROADCAST, V50, P289, DOI 10.1109/TBC.2004.834202
   Tseng YC, 2002, IEEE T COMMUN, V50, P1348, DOI 10.1109/TCOMM.2002.801466
   Viswanathan S, 1996, MULTIMEDIA SYST, V4, P197, DOI 10.1007/s005300050023
NR 30
TC 2
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2013
VL 66
IS 3
BP 517
EP 543
DI 10.1007/s11042-012-1044-x
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 179TX
UT WOS:000321545300008
DA 2024-07-18
ER

PT J
AU Wu, HT
   Hsieh, WS
AF Wu, Hsin-Te
   Hsieh, Wen-Shyong
TI RSU-based message authentication for vehicular ad-hoc networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VANET; Privacy; Security; Vehicular communications
ID PRIVACY; EFFICIENT; SECURE
AB Message authentication that ensures a message is genuine and verifies the source of the sender is a key issue in vehicular ad hoc networks (VANETs). Because messages may provide life-critical traffic information or emergency messages transmitted by unfamiliar sources. Because the vehicle in a VANET transmits messages in real-time in a high-mobility environment, traditional PKI security schemes are not suitable for VANET. The use of roadside units (RSUs) makes message authentication in VANET easy, but it also causes two problems and needed to be solved: how to authenticate messages transmitted between two different RSU ranges, and how to hand off messages for the vehicles moving across different RSU communication ranges. This paper proposes a comprehensive message authentication scheme that enables the message authentication within intra and between inter RSU ranges and hand-off between different RSUs. The proposed scheme balances the overhead for computation and communication with security against attacks. Efficiency analysis and comparison with related works demonstrate that the proposed scheme is a superior message authentication method for VANET.
C1 [Wu, Hsin-Te; Hsieh, Wen-Shyong] Natl Sun Yat Sen Univ, Dept Comp Sci & Engn, Kaohsiung 80424, Taiwan.
   [Hsieh, Wen-Shyong] Shu Te Univ, Dept Comp Sci Engn, Kaohsiung, Taiwan.
C3 National Sun Yat Sen University; Shu-Te University
RP Wu, HT (corresponding author), Natl Sun Yat Sen Univ, Dept Comp Sci & Engn, Kaohsiung 80424, Taiwan.
EM pllo0304@mail2000.com.tw; wshsieh@mail.stu.edu.tw
OI Wu, Hsin-Te/0000-0002-3221-9037
CR [Anonymous], P80211PD6 IEEE
   [Anonymous], VEH SAF COMM PROJ
   [Anonymous], 2008, P IEEE INFOCOM 2008
   [Anonymous], 2002, FIPS PUB
   [Anonymous], P 3 INT WORKSH INT T
   Choi J.Y., 2005, The 1st ACM international workshop on Quality of service security in wireless and mobile networks, P79
   Hartenstein H, 2008, IEEE COMMUN MAG, V46, P164, DOI 10.1109/MCOM.2008.4539481
   Hubaux JP, 2004, IEEE SECUR PRIV, V2, P49, DOI 10.1109/MSP.2004.26
   Kounga G, 2009, IEEE T VEH TECHNOL, V58, P2977, DOI 10.1109/TVT.2008.2010325
   Lee SB, 2007, MOBIHOC'07: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL SYMPOSIUM ON MOBILE AD HOC NETWORKING AND COMPUTING, P150
   Lin XD, 2007, IEEE T VEH TECHNOL, V56, P3442, DOI 10.1109/TVT.2007.906878
   Lin XD, 2008, IEEE T WIREL COMMUN, V7, P4987, DOI 10.1109/T-WC.2008.070773
   Lu RX, 2008, IEEE INFOCOM SER, P1903
   Perrig Adrian, 2002, CryptoBytes, V5, P2
   Plössl K, 2006, FIRST INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY, PROCEEDINGS, P374
   Raya M., 2005, P 3 ACM WORKSH SEC A, P11, DOI DOI 10.1145/1102219.1102223
   Stingson DR, 2005, CRYPTOGRAPHY THEORY
   Toor Y, 2008, IEEE COMMUN SURV TUT, V10, P74, DOI 10.1109/COMST.2008.4625806
   TUNG B, 1999, KERBEROS NETWORK AUT
   Zhang CX, 2008, IEEE T VEH TECHNOL, V57, P3357, DOI 10.1109/TVT.2008.928581
NR 20
TC 7
Z9 7
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2013
VL 66
IS 2
BP 215
EP 227
DI 10.1007/s11042-011-0792-3
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 170PJ
UT WOS:000320865000005
DA 2024-07-18
ER

PT J
AU Bao, ZH
   Xu, C
   Wang, C
AF Bao, Zhihua
   Xu, Chen
   Wang, Chong
TI Perceptual auto-regressive texture synthesis for video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Perceptual video coding; HVS; Texture synthesis; JND; Auto-regressive
   model
ID QUANTIZATION; MODEL
AB Traditional video compression methods consider the statistical redundancy among pixels as the only adversary of compression, with the perceptual redundancy totally neglected. However, it is well-known that none criterion is as eloquent as the visual quality of an image. To reach higher compression ratios without perceptually degrading the reconstructed signal, the properties of the human visual system (HVS) need to be better exploited. Recent research indicates that HVS has different sensitivities towards different image content, based on which a novel perceptual video coding method is explored in this paper to achieve better perceptual coding quality while spending fewer bits. A new texture segmentation method exploiting just noticeable distortion (JND) profile is first devised to detect and classify texture regions in video scenes. To effectively remove temporal redundancies while preserving high visual quality, an auto-regressive (AR) model is then applied to synthesize the texture regions and combine with other regions which are encoded by the traditional hybrid coding scheme. To demonstrate the performance, the proposed scheme is integrated into the H.264/AVC video coding system. Experimental results show that on various sequences with different types of texture regions, we can reduce the bit-rate for 15% to 58% while maintaining good perceptual quality.
C1 [Bao, Zhihua; Xu, Chen; Wang, Chong] Nantong Univ, Sch Elect & Informat, Nantong, Jiangsu, Peoples R China.
C3 Nantong University
RP Wang, C (corresponding author), Nantong Univ, Sch Elect & Informat, Nantong, Jiangsu, Peoples R China.
EM wangchong219@163.com
FU National Hi-Tech Development 863 Program of China [2007AA01Z330]; open
   project of Jiangsu Provincial Key Lab of ASIC Design [JSICK0910]
FX This work is supported by the National Hi-Tech Development 863 Program
   of China under grant No. 2007AA01Z330 and the open project of Jiangsu
   Provincial Key Lab of ASIC Design under grant No. JSICK0910.
CR [Anonymous], 2000, 154441 ISOIEC
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   Chou CH, 1996, IEEE T CIRC SYST VID, V6, P143, DOI 10.1109/76.488822
   *ITU R, BT50011 ITUR
   [Joint Video Team (JVT) of ISO/IEC MPEG ITU-T VCEG], 2003, JVTG050 ISOIEC MPEG
   Lubin J., 1995, Vision Models for Target Detection and Recognition, P245
   NdjikiNya P., 2003, P PICT COD S SAINT M
   NETRAVALI AN, 1977, P IEEE, V65, P536, DOI 10.1109/PROC.1977.10515
   Paul M, 2011, IEEE T CIRC SYST VID, V21, P1242, DOI 10.1109/TCSVT.2011.2138750
   Safranek R. J., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P1945, DOI 10.1109/ICASSP.1989.266837
   Sun XH, 2009, IEEE NANOTECHNOL MAT, P1, DOI 10.1109/NMDC.2009.5167547
   Tugnait J. K., 1993, IEEE Signal Processing Workshop on Higher-Order Statistics (Cat. No.93TH0539-7), P71, DOI 10.1109/HOST.1993.264594
   Vatis Y, 2009, IEEE T CIRC SYST VID, V19, P179, DOI 10.1109/TCSVT.2008.2009259
   Watson A.B., 1993, SID INT S, V24, P946
   Watson AB, 1997, IEEE T IMAGE PROCESS, V6, P1164, DOI 10.1109/83.605413
   Wu XL, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P901, DOI 10.1109/ICIP.1998.727397
   Yang XK, 2005, SIGNAL PROCESS-IMAGE, V20, P662, DOI 10.1016/j.image.2005.04.001
   Yang XK, 2005, IEEE T CIRC SYST VID, V15, P742, DOI 10.1109/TCSVT.2005.848313
   Zhang YB, 2006, LECT NOTES COMPUT SC, V4261, P582
   Zhu CB, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P112
   Zhu CB, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P813, DOI 10.1109/ICME.2008.4607559
NR 21
TC 2
Z9 2
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2013
VL 64
IS 3
BP 535
EP 547
DI 10.1007/s11042-011-0962-3
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 126IV
UT WOS:000317608600002
DA 2024-07-18
ER

PT J
AU Beltran, A
   Abargues, C
   Granell, C
   Núñez, M
   Díaz, L
   Huerta, J
AF Beltran, Arturo
   Abargues, Carlos
   Granell, Carlos
   Nunez, Manuela
   Diaz, Laura
   Huerta, Joaquin
TI A virtual globe tool for searching and visualizing geo-referenced media
   resources in social networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User-generated content retrieval; Social networks; Geo-referenced media
   resources; Virtual globes; OpenSearch; KML; MIMEXT
ID SPATIAL DATA; EXPLORATION; INTEGRATION; EARTH; GIS
AB The current collaborative context and resource sharing that drives Web 2.0 is gaining importance within academia and industry, which is stimulating the development of new techniques for content retrieval, sharing and analysis over user-generated media content. This poses new challenges and research opportunities in spatial-based discovery media resources over varied sources, since location context is being increasingly supported in most of these social networks and services. In this paper, we present a virtual globe tool for searching and visualizing geo-referenced media resources. Our approach is based on the integration of search technologies, description languages for annotating collections of geo-referenced media resources and visualization techniques. The combination of these techniques is materialized in a virtual globe-based tool to facilitate searching and presentation of geo-referenced media resources available in different social networks.
C1 [Beltran, Arturo; Abargues, Carlos; Granell, Carlos; Nunez, Manuela; Diaz, Laura; Huerta, Joaquin] Univ Jaume 1, Inst New Imaging Technol, Castellon de La Plana, Spain.
C3 Universitat Jaume I
RP Granell, C (corresponding author), Univ Jaume 1, Inst New Imaging Technol, Castellon de La Plana, Spain.
EM arturo.beltran@uji.es; carlos.granell@uji.es; nunezm@uji.es;
   laura.diaz@uji.es; huerta@uji.es
RI Granell, Carlos/A-4374-2008; Huerta, Joaquin/L-6103-2018
OI Granell, Carlos/0000-0003-1004-9695; Huerta, Joaquin/0000-0002-8625-441X
FU "Espana Virtual" project through the Instituto Geografico Nacional
   [CENIT 2008-1030]
FX This work has been partially supported by the "Espana Virtual" project
   (ref. CENIT 2008-1030) through the Instituto Geografico Nacional. The
   authors wish to thank Dori Apanewicz for proofreading the manuscript.
CR Abargues C, 2010, LECT NOTES GEOINF CA, P315, DOI 10.1007/978-3-642-12326-9_17
   [Anonymous], 2008, NATURE, V453, P2, DOI 10.1038/453002a
   [Anonymous], 2011, GSTREAMER OP SOURC M
   [Anonymous], 2011, YAH MAPS WEB SERV GE
   [Anonymous], 2007, EXT MET PLATF XMP
   [Anonymous], 2011, JAV SCRIPT OBJ NOT
   [Anonymous], 2011, JOGL JAV BIND OPENGL
   [Anonymous], 2005, 4287 RFC
   [Anonymous], 2046 RFC
   [Anonymous], 2011, LIBKML KML LIB
   [Anonymous], 2011, JAK JAV API KML
   [Anonymous], 2011, WORLD WIND JAVA SDK
   [Anonymous], 1996, 2045 RFC
   [Anonymous], 1999, OpenGL programming guide: the official guide to learning OpenGL
   [Anonymous], 2002, CP3451 JEITA
   [Anonymous], 2011, VRML VIRTUAL REALITY
   [Anonymous], IPTC PHOT MET STAND
   Bailey JE, 2011, COMPUT GEOSCI-UK, V37, P1, DOI 10.1016/j.cageo.2010.06.001
   Ballagh LM, 2011, COMPUT GEOSCI-UK, V37, P57, DOI 10.1016/j.cageo.2010.05.004
   Belimpasakis P, 2010, MULTIMEDIA SYST, V16, P399, DOI 10.1007/s00530-010-0200-2
   Boll S, 2007, IEEE MULTIMEDIA, V14, P9, DOI 10.1109/MMUL.2007.17
   BORENSTEIN N, 1993, 1521 RFC
   Bultennan DCA, 2008, SMIL 3 0 INTERACTIVE
   Butler D, 2006, NATURE, V439, P776, DOI 10.1038/439776a
   Chien NQ, 2011, COMPUT GEOSCI-UK, V37, P38, DOI 10.1016/j.cageo.2010.03.006
   Clinton D, 2010, OPENSEARCH 1 1 DRAFT
   Craglia M, 2008, INT J SPAT DATA INFR, V3, P146, DOI 10.2902/1725-0463.2008.03.art9
   De Paor DG, 2011, COMPUT GEOSCI-UK, V37, P100, DOI 10.1016/j.cageo.2010.05.003
   Fonts O, 2009, P 4 JORN SIG LIBR
   Geonetwork Developers, 2009, GEONETWORK OP COMPL
   Hobona G, 2006, IEEE COMPUT GRAPH, V26, P28, DOI 10.1109/MCG.2006.94
   Huang B, 2001, INT J GEOGR INF SCI, V15, P439, DOI 10.1080/13658810110046574
   *ISO, 2003, ISO 19115 GEOGR INF
   Ivanov I, 2012, MULTIMED TOOLS APPL, V56, P155, DOI 10.1007/s11042-010-0570-7
   Joshi D, 2012, MULTIMED TOOLS APPL, V56, P131, DOI 10.1007/s11042-010-0553-8
   Luo JB, 2011, MULTIMED TOOLS APPL, V51, P187, DOI 10.1007/s11042-010-0623-y
   Naaman M, 2012, MULTIMED TOOLS APPL, V56, P9, DOI 10.1007/s11042-010-0538-7
   Nogueras-Iso J, 2005, COMPUT GEOSCI-UK, V31, P199, DOI 10.1016/j.cageo.2004.05.015
   Nu┐ez M, 2011, EUROPEAN GE IN PRESS
   OGC KML, 2008, OPENGIS KEYH MARK LA
   OGC WMS, 2006, OPENGIS WEB MAP SERV
   Russell MatthewA., 2011, Mining the Social Web
   Schreer O, 2010, MULTIMED TOOLS APPL, V48, P23, DOI 10.1007/s11042-009-0375-8
   Sheppard SRJ, 2009, J ENVIRON MANAGE, V90, P2102, DOI 10.1016/j.jenvman.2007.09.012
   Tomaszewski B, 2011, COMPUT GEOSCI-UK, V37, P86, DOI 10.1016/j.cageo.2010.03.009
   Tsai FS, 2011, EXPERT SYST APPL, V38, P1011, DOI 10.1016/j.eswa.2010.07.129
   Turner A, 2010, OPENSEARCH GEO EXT D
   Walsh J, 2007, SPATIAL DATA SEARCH
   Wood J, 2007, IEEE T VIS COMPUT GR, V13, P1176, DOI 10.1109/TVCG.2007.70570
   Wright R., 2004, OpenGL superbible
   Wu HY, 2010, COMPUT ENVIRON URBAN, V34, P291, DOI 10.1016/j.compenvurbsys.2009.12.001
   Yamagishi Y, 2010, COMPUT GEOSCI-UK, V36, P373, DOI 10.1016/j.cageo.2009.08.007
   Zhang JQ, 2007, INFORM SCIENCES, V177, P3968, DOI 10.1016/j.ins.2007.02.049
   Zhu Q, 2002, PHOTOGRAMM ENG REM S, V68, P361
NR 54
TC 3
Z9 4
U1 1
U2 49
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2013
VL 64
IS 1
BP 171
EP 195
DI 10.1007/s11042-012-1025-0
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 114SU
UT WOS:000316763600009
DA 2024-07-18
ER

PT J
AU Chen, CN
   Chen, JZ
   Ouyang, K
   Xia, T
   Zhou, JL
AF Chen, Changnian
   Chen, Jiazhong
   Ouyang, Kun
   Xia, Tao
   Zhou, Jingli
TI A hybrid fast mode decision method for H.264/AVC intra prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hybrid; Mode decision; H.264/AVC; Intra prediction
ID ALGORITHM
AB It has been well demonstrated that edge information can be utilized for intra mode decision in H.264/AVC to reduce the computational complexity. In spite of the remarkable speedup for mode decision, the existing edge detection based solution always shows relatively high coding loss due to inaccurate mode selection. In this work, a novel fast intra mode decision based on a more precise direction representation scheme is proposed, which exploits the gradation along the prediction direction as well as the differential between the original pixels and their predicted ones. Extensive experimental results show that the proposed method can averagely achieve about 0.05 dB peak signal-to-noise ratio (PSNR) gain and 1.1% bit rate (BR) decrease with negligible computational complexity increase, compared with the state-of-the-art edge detection method.
C1 [Chen, Changnian; Chen, Jiazhong; Ouyang, Kun; Xia, Tao; Zhou, Jingli] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Zhou, JL (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM jlzhou@hust.edu.cn
CR [Anonymous], 2001, ITU T VCEG M
   Bharanitharan K, 2008, IEEE T MULTIMEDIA, V10, P1250, DOI 10.1109/TMM.2008.2004904
   de-Frutos-López M, 2010, SIGNAL PROCESS-IMAGE, V25, P709, DOI 10.1016/j.image.2010.10.005
   Huang YH, 2010, IEEE T CIRC SYST VID, V20, P1122, DOI 10.1109/TCSVT.2010.2057018
   ITU-T JVT, 2003, JVTG050 ITUT JVT ISO
   Lin YY, 2010, IEEE T CIRC SYST VID, V20, P1367, DOI 10.1109/TCSVT.2010.2077482
   Pan F, 2005, IEEE T CIRC SYST VID, V15, P813, DOI 10.1109/TCSVT.2005.848356
   Su XQ, 2011, MULTIMED TOOLS APPL, V52, P65, DOI 10.1007/s11042-009-0452-z
   Tsai AC, 2008, IEEE T CIRC SYST VID, V18, P694, DOI 10.1109/TCSVT.2008.919113
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zeng HQ, 2010, IEEE T CIRC SYST VID, V20, P907, DOI 10.1109/TCSVT.2010.2045802
NR 11
TC 9
Z9 10
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2013
VL 62
IS 3
BP 719
EP 731
DI 10.1007/s11042-011-0862-6
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 086VF
UT WOS:000314715500009
DA 2024-07-18
ER

PT J
AU Jeong, JW
   Hong, HK
   Lee, DH
AF Jeong, Jin-Woo
   Hong, Hyun-Ki
   Lee, Dong-Ho
TI i-TagRanker: an efficient tag ranking system for image sharing and
   retrieval using the semantic relationships between tags
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tag ranking; Tag-based image retrieval; Semantic relationship;
   Folksonomy; WordNet
AB Folksonomy, considered a core component for Web 2.0 user-participation architecture, is a classification system made by user's tags on the web resources. Recently, various approaches for image retrieval exploiting folksonomy have been proposed to improve the result of image search. However, the characteristics of the tags such as semantic ambiguity and non-controlledness limit the effectiveness of tags on image retrieval. Especially, tags associated with images in a random order do not provide any information about the relevance between a tag and an image. In this paper, we propose a novel image tag ranking system called i-TagRanker which exploits the semantic relationships between tags for re-ordering the tags according to the relevance with an image. The proposed system consists of two phases: 1) tag propagation phase, 2) tag ranking phase. In tag propagation phase, we first collect the most relevant tags from similar images, and then propagate them to an untagged image. In tag ranking phase, tags are ranked according to their semantic relevance to the image. From the experimental results on a Flickr photo collection about over 30,000 images, we show the effectiveness of the proposed system.
C1 [Jeong, Jin-Woo; Hong, Hyun-Ki; Lee, Dong-Ho] Hanyang Univ, Dept Comp Sci & Engn, KDE Lab, Ansan 426791, Kyunggi Do, South Korea.
C3 Hanyang University
RP Lee, DH (corresponding author), Hanyang Univ, Dept Comp Sci & Engn, KDE Lab, Sa-3 Dong, Ansan 426791, Kyunggi Do, South Korea.
EM selphyr@hanyang.ac.kr; route@hanyang.ac.kr; dhlee72@hanyang.ac.kr
FU MKE(The Ministry of Knowledge Economy), Korea; Microsoft Research, under
   IT/SW Creative research program [NIPA-2010-C1810-1002-0012]
FX This research was supported by the MKE(The Ministry of Knowledge
   Economy), Korea and Microsoft Research, under IT/SW Creative research
   program supervised by the NIPA(National IT Industry Promotion Agency)
   (NIPA-2010-C1810-1002-0012)
CR [Anonymous], 2009, P ACM INT C IM VID R
   Baziz M, 2005, LECT NOTES COMPUTER, V3507, P2021, DOI [10.1007/11495222_14, DOI 10.1007/11495222_14]
   Benevenuto F, 2008, P 16 ACM INT C MULT
   Budanitsky A., 2001, WORKSH WORDN OTH LEX
   Chatzichristofis Savvas A., 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P191, DOI 10.1109/WIAMIS.2008.24
   Chatzichristofis SA, 2010, INT J PATTERN RECOGN, V24, P207, DOI 10.1142/S0218001410007890
   Chi Zheru., 1996, Advances in fuzzy systems. Applications and theory, V10
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Fellbaum C, 1998, LANG SPEECH & COMMUN, P1
   Flickr-Pool, 2010, FLICKR POOL
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Hirst Graeme., 1998, LEXICAL CHAINS REPRE
   Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418
   JWNL, 2010, JWNL
   JWordNetSim, 2010, JWORDNETSIM
   Kasutani E, 2001, IEEE IMAGE PROC, P674, DOI 10.1109/ICIP.2001.959135
   Leachok C, 1998, WORDNET ELECT LEXICA
   Lee DH, 2001, J SYST SOFTWARE, V56, P165, DOI 10.1016/S0164-1212(00)00095-9
   Li X, 2010, P ACM INT C IM VID R
   LI XD, 2008, P 1 ACM INT C MULTIM
   Lin D., 1998, P 36 ANN M ASS COMP, V2, P768, DOI DOI 10.3115/980432.980696
   Lindstaedt S, 2009, MULTIMED TOOLS APPL, V42, P97, DOI 10.1007/s11042-008-0247-7
   Liu D, 2010, PROCEEDINGS OF THE 17TH INTERNATIONAL CONGRESS ON SOUND AND VIBRATION
   Liu Dong., 2009, P 18 INT C WORLD WID, P351
   Mackay W. E., 1989, SIGCHI Bulletin, V21, P68, DOI 10.1145/70609.70617
   Monay F, 2004, P 12 ANN ACM INT C M
   Ooi BC, 1998, VLDB J, V7, P115, DOI 10.1007/s007780050057
   OOMOTO E, 1993, IEEE T KNOWL DATA EN, V5, P629, DOI 10.1109/69.234775
   Park KW, 2007, LECT NOTES COMPUT SC, V4443, P485
   Pedersen T, 2004, HLT NAACL 2004 BOST
   Raykar VC, 2006, SIAM INT C DAT MIN
   Resnik P, 1999, J ARTIF INTELL RES, V11, P95, DOI 10.1613/jair.514
   Rijsbergen CJV, 1980, NEW MODELS PROBABILI
   Sánchez D, 2008, DATA KNOWL ENG, V64, P600, DOI 10.1016/j.datak.2007.10.001
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   WU ZB, 1994, 32ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P133
   Xu HX, 2009, PROCEEDINGS OF THE 2009 WRI GLOBAL CONGRESS ON INTELLIGENT SYSTEMS, VOL III, P573, DOI 10.1109/GCIS.2009.320
NR 38
TC 14
Z9 14
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2013
VL 62
IS 2
BP 451
EP 478
DI 10.1007/s11042-011-0903-1
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 076OM
UT WOS:000313965900008
DA 2024-07-18
ER

PT J
AU Johansen, D
   Halvorsen, P
   Johansen, H
   Riiser, H
   Gurrin, C
   Olstad, B
   Griwodz, C
   Kvalnes, Å
   Hurley, J
   Kupka, T
AF Johansen, Dag
   Halvorsen, Pal
   Johansen, Havard
   Riiser, Hakon
   Gurrin, Cathal
   Olstad, Bjorn
   Griwodz, Carsten
   Kvalnes, Age
   Hurley, Joseph
   Kupka, Tomas
TI Search-based composition, streaming and playback of video archive
   content
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video search engines; Personalized composition; Segmented adaptive HTTP
   streaming
ID FRAMEWORK; LESSONS
AB Locating content in existing video archives is both a time and bandwidth consuming process since users might have to download and manually watch large portions of superfluous videos. In this paper, we present two novel prototypes using an Internet based video composition and streaming system with a keyword-based search interface that collects, converts, analyses, indexes, and ranks video content. At user requests, the system can automatically sequence out portions of single videos or aggregate content from multiple videos to produce a single, personalized video stream on-the-fly.
C1 [Halvorsen, Pal; Griwodz, Carsten; Kupka, Tomas] Univ Oslo, Dept Informat, N-0316 Oslo, Norway.
   [Johansen, Dag; Johansen, Havard; Kvalnes, Age; Hurley, Joseph] Univ Tromso, Dept Comp Sci, Tromso, Norway.
   [Halvorsen, Pal; Griwodz, Carsten; Kupka, Tomas] Simula Res Lab, Lysaker, Norway.
   [Riiser, Hakon] NetView Technol, Oslo, Norway.
   [Olstad, Bjorn] Microsoft Corp, Oslo, Norway.
   [Gurrin, Cathal] Dublin City Univ, Dublin 9, Ireland.
C3 University of Oslo; UiT The Arctic University of Tromso; Dublin City
   University
RP Halvorsen, P (corresponding author), Univ Oslo, Dept Informat, N-0316 Oslo, Norway.
EM dag@cs.uit.no; paalh@ifi.uio.no; haavardj@cs.uit.no;
   haakon.riiser@netview.no; cgurrin@computing.dcu.ie;
   bjornol@microsoft.com; griff@ifi.uio.no; aage@cs.uit.no;
   joseph.hurley@cs.uit.no; tomasku@ifi.uio.no
RI Gurrin, Cathal/Q-4442-2019
OI Gurrin, Cathal/0000-0003-2903-3968; Halvorsen, Pal/0000-0003-2073-7029
FU Research Council of Norway [174867]
FX This work has been performed in the context of the iAD (Information
   Access Disruptions) Centre for Research-based Innovation, project number
   174867 -funded by the Research Council of Norway. We are particularly
   grateful for contributions by Erik Aaberg, former Schibsted principal
   investigator on this project. Feedback from the Cornell professors
   Kenneth P. Birman, Johannes Gehrke and Fred B. Schneider clearly
   improved the quality of this paper.
CR Akamai Technologies Inc., 2011, AK LEAD WEB APPL ACC
   Albanese M, 2006, INFORM SYST, V31, P679, DOI 10.1016/j.is.2005.12.003
   Altus Inc., 2010, EAS ENT VID TOOLS AL
   Ames G, 2010, APACHE HTTP SERVER P
   ANIL RD, 2003, P IEEE C AC SPEECH S, P561
   [Anonymous], 2010, HTTP DYNAM STREAM AD
   [Anonymous], 2010, BBC
   [Anonymous], 2004, TRECVID 2004 TEXT RE
   Au B, 2010, SOLR SOFTWARE VERSIO
   Chang P, 2002, IEEE IMAGE PROC, P609
   Cisco Systems Inc., 2010, VIS NETW IND
   Cohen Bram, 2008, The BitTorrent protocol specification
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Evans S, 2010, SCRAPY OPEN SOURCE W
   Ferguson P, 2009, P INT WORKSH CONT BA
   Goyal VK, 2001, IEEE SIGNAL PROC MAG, V18, P74, DOI 10.1109/79.952806
   Halvorsen Pal, 2010, Proceedings of the 2010 Fourth International Conference on Network and System Security (NSS 2010), P534, DOI 10.1109/NSS.2010.9
   Halvorsen P., 2010, P ACM INT MULT C ACM, P1603
   Hauptmann AG, 2005, LECT NOTES COMPUT SC, V3568, P1
   Herranz L, 2010, IEEE T CIRC SYST VID, V20, P1265, DOI 10.1109/TCSVT.2010.2057020
   ITU-T Study Group 12 (1997-2000), 1999, 12 ITU T STUD GROUP, P910
   Jie H, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P342, DOI 10.1109/AVSS.2003.1217941
   Johansen D., 2009, P 17 ACM INT C MULTI, P989
   KOICHI OU, 2002, P IEEE INT C MULT EX, P45
   Level 3 Communications LLC, 2011, CONT DEL NETW CDN
   LI B, 2001, SOC PHOTOOPTICAL INS, V4676, P202
   Microsoft Corporation, 2010, ENT SEARCH FAST
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Nett VG, 2010, VG NETT
   Ngo CW, 2005, IEEE T CIRC SYST VID, V15, P296, DOI 10.1109/TCSVT.2004.841694
   NI PP, 2009, P INT WORKSH NETW OP
   Niedermayer M, 2011, FFMPEG SOFTWARE VERS
   Pantos R., 2010, HTTP LIVE STREAMING
   RIISER H, 2010, P MULT SYST C MMSYS
   RTE Sport, 2009, RUGBY NEWS
   Sadlier DA, 2005, IEEE T CIRC SYST VID, V15, P1225, DOI 10.1109/TCSVT.2005.854237
   Schierl T, 2011, MULTIMED TOOLS APPL, V55, P227, DOI 10.1007/s11042-010-0572-5
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   SMEATON AF, 2004, INT J DIGIT LIB, V4, P42
   Stockhammer T., 2011, P 2 ANN ACM C MULTIM, P133
   TV2 AS, 2010, TV2 SUM SPORT
   VOJKAN MP, 2002, P IEEE INT C MULT EX, P817
   Wactlar HD, 1999, COMPUTER, V32, P66, DOI 10.1109/2.745722
   Wang B, 2008, ACM T MULTIM COMPUT, V4, DOI 10.1145/1352012.1352020
   Xu C., 2006, PROC 14 ANN ACM INT, P221, DOI DOI 10.1145/1180639.1180699
   Yahoo!, 2010, EUR PREM LEAG FOOTB
   Yahoo!, 2011, EUR LIV V BIRM CIT R
   Yeung MM, 1997, IEEE T CIRC SYST VID, V7, P771, DOI 10.1109/76.633496
   YOW D, 1995, P ACCV, P499
   Yu X., 2008, P 19 INT C PATT REC
   Zhou W., 2000, ACM Workshops on Multimedia, P213
NR 51
TC 9
Z9 12
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2012
VL 61
IS 2
BP 419
EP 445
DI 10.1007/s11042-011-0847-5
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 985MK
UT WOS:000307270600007
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Taneja, N
   Raman, B
   Gupta, I
AF Taneja, Nidhi
   Raman, Balasubramanian
   Gupta, Indra
TI Chaos based cryptosystem for still visual data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Arnold cat map; Chaotic system free property; Error function attack
ID ENCRYPTION ALGORITHM; CRYPTANALYSIS; MAP; COMPRESSION; SEQUENCES;
   SYSTEMS
AB Recent years have witnessed a strong relationship between chaos and cryptography. Owing to this relationship, development in one field directly impacts the other field. High computational resources are consumed in re-designing of the complete cryptosystem due to a newly developed chaotic map. Also, the tools developed to discern chaos leads to easy cryptanalysis of chaotic cryptosystems. To save resources and overcome easy cryptanalysis, this paper proposes a spatial domain based chaotic cryptosystem that employs different chaotic maps during permutation-substitution process. Multiple iterations have been performed to achieve resistance against various cryptanalytic and error function attacks, that are specifically designed for chaos based cryptosystems. The proposed technique has been generalized and verified for different chaotic maps. A significant benefit of the proposed cryptosystem is its support for chaotic system free property, which allows replacement of an existing chaotic map with a different map at a later stage. Thorough performance, security and comparative analysis ascertains efficacy of the proposed technique.
C1 [Taneja, Nidhi; Gupta, Indra] Indian Inst Technol, Dept Elect Engn, Roorkee 247667, Uttar Pradesh, India.
   [Raman, Balasubramanian] Indian Inst Technol, Dept Math, Roorkee 247667, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Roorkee
RP Taneja, N (corresponding author), Indian Inst Technol, Dept Elect Engn, Roorkee 247667, Uttar Pradesh, India.
EM nidhi.iitr@gmail.com; balarfma@iitr.ernet.in; indrafee@iitr.ernet.in
CR Alvarez G, 2000, PHYS LETT A, V276, P191, DOI 10.1016/S0375-9601(00)00642-3
   Alvarez G, 2003, PHYS LETT A, V319, P334, DOI 10.1016/j.physleta.2003.10.044
   Alvarez G, 2009, COMMUN NONLINEAR SCI, V14, P3743, DOI 10.1016/j.cnsns.2009.02.033
   Behnia S, 2007, PHYS LETT A, V366, P391, DOI 10.1016/j.physleta.2007.01.081
   Bose R, 2006, IEEE T CIRCUITS-I, V53, P848, DOI 10.1109/TCSI.2005.859617
   Chang WD, 2009, DIGIT SIGNAL PROCESS, V19, P693, DOI 10.1016/j.dsp.2008.03.004
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Dachselt F, 2001, IEEE T CIRCUITS-I, V48, P1498, DOI 10.1109/TCSI.2001.972857
   DACHSELT F, 1998, P INT S CIRC SYST IS, V4, P518
   El-Bakary E. M., 2009, International Journal of Communication Networks and Information Security, V1, P54
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   HENON M, 1976, COMMUN MATH PHYS, V50, P69, DOI 10.1007/BF01608556
   Johnson M, 2004, IEEE T SIGNAL PROCES, V52, P2992, DOI 10.1109/TSP.2004.833860
   Li SJ, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2360697
   Li SJ, 2008, SIGNAL PROCESS-IMAGE, V23, P212, DOI 10.1016/j.image.2008.01.003
   Li SJ, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, PROCEEDINGS, P708
   Li SJ, 2001, PHYS LETT A, V290, P127, DOI 10.1016/S0375-9601(01)00612-0
   Marion A., 1991, INTRO IMAGE PROCESSI
   Norcen R, 2003, COMPUT BIOL MED, V33, P277, DOI 10.1016/S0010-4825(02)00094-X
   Peterson G, 1997, ARNOLDS CAT MAP
   POMMER A, 2002, MULT SEC WORKSH ACM, P71
   Schonberg D, 2008, IEEE T INF FOREN SEC, V3, P749, DOI 10.1109/TIFS.2008.2007244
   Sun FY, 2008, CHAOS SOLITON FRACT, V38, P631, DOI 10.1016/j.chaos.2008.01.028
   Uhl A., 2005, ADV INFORM SECURITY, V15, P31
   Wang XG, 2004, CHAOS, V14, P128, DOI 10.1063/1.1633492
   Wang XY, 2009, COMMUN NONLINEAR SCI, V14, P574, DOI 10.1016/j.cnsns.2007.10.011
   Wong KW, 2008, PHYS LETT A, V372, P2645, DOI 10.1016/j.physleta.2007.12.026
   Yang HQ, 2009, CHAOS SOLITON FRACT, V40, P2520, DOI 10.1016/j.chaos.2007.10.046
NR 28
TC 9
Z9 9
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2012
VL 61
IS 2
BP 281
EP 298
DI 10.1007/s11042-011-0837-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 985MK
UT WOS:000307270600002
DA 2024-07-18
ER

PT J
AU Rotter, P
AF Rotter, Pawel
TI Multimedia information retrieval based on pairwise comparison and its
   application to visual search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia information retrieval; Pairwise comparison; AHP; CBIR;
   Preference elicitation
AB Finding a way to elicit user preferences in the context of multimedia information retrieval is an important issue that remains to be solved. Users are not usually able to find a sought after image or provide an example of what they want. One of several possible methods that might be used to solve this problem involves reasoning about user queries through the assessment of several samples. In this article we propose a method by which user queries are retrieved based on the pairwise comparison of sample alternatives. Pairwise comparison was originally designed for the ranking of alternatives. In our method we rank criteria according to their importance for the user and then use this information to retrieve relevant records from the database. The method was implemented in Matlab and tested on the Microsoft Research Cambridge Image Database.
C1 AGH Univ Sci & Technol Krakow, Automat Dept, PL-30059 Krakow, Poland.
C3 AGH University of Krakow
RP Rotter, P (corresponding author), AGH Univ Sci & Technol Krakow, Automat Dept, Al Mickiewicza 30, PL-30059 Krakow, Poland.
EM rotter@agh.edu.pl
RI Rotter, Pawel/F-5858-2011
OI Rotter, Pawel/0000-0002-1556-6539
FU Polish Ministry of Science and Higher Education under SIMPOZ project
   [0128/R/t00/2010/12]
FX This work was supported by the Polish Ministry of Science and Higher
   Education under SIMPOZ project, no. 0128/R/t00/2010/12.
CR BELTON V, 1983, OMEGA-INT J MANAGE S, V11, P228, DOI 10.1016/0305-0483(83)90047-6
   Bozoki S, 2010, CENTRAL EURO IN RESS
   Bozóki S, 2008, J GLOBAL OPTIM, V42, P157, DOI 10.1007/s10898-007-9236-z
   De Condorcet Nicolas., 1785, Essai sur l'application de l'analyse a la probabilite des decisions rendues a la pluralite des voix
   Dong YC, 2008, EUR J OPER RES, V186, P229, DOI 10.1016/j.ejor.2007.01.044
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Koczkodaj W. W., 1997, Proceedings of the Sixth International Conference on Information and Knowledge Management. CIKM'97, P91, DOI 10.1145/266714.266867
   Koczkodaj Waldemar W., 2009, Machine Graphics & Vision, V18, P143
   KOCZKODAJ WW, 1993, MATH COMPUT MODEL, V18, P79, DOI 10.1016/0895-7177(93)90059-8
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Marszalek M, 2006, JOURN GDR ISIS PAR O
   Rotter P, 2009, ARTIF INTELL, P235
   Saaty T.L, 1980, Advanced Optimization and Decision-Making Techniques in Textile Manufacturing, DOI DOI 10.1201/9780429504419-2
   SAATY TL, 1977, J MATH PSYCHOL, V15, P234, DOI 10.1016/0022-2496(77)90033-5
   Saaty TL, 2006, INT SER OPER RES MAN, V95, P1
   Saaty TL, 1994, Fundamentals of decision making and priority theory with the analytic hierarchy process, DOI DOI 10.1016/J.JCLEPRO.2019.118324
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Thurstone LL, 1927, PSYCHOL REV, V34, P273, DOI 10.1037/h0070288
   Tjondronegoro D, 2008, INFORM PROCESS MANAG, V44, P340, DOI 10.1016/j.ipm.2007.03.004
   Triantaphyllou E., 1995, International Journal of Industrial Engineering: Applications and Practice, V2, P35
   Vogel J, 2006, PATTERN RECOGN, V39, P897, DOI 10.1016/j.patcog.2005.10.024
   Wang X, 2008, CONTR DEC C CCDC YAN
   Xiaoling W., 2008, INT J INFORM TECHNOL, V11, P25
NR 23
TC 5
Z9 5
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2012
VL 60
IS 3
BP 573
EP 587
DI 10.1007/s11042-011-0828-8
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 965ZC
UT WOS:000305805300006
DA 2024-07-18
ER

PT J
AU Saipullah, KM
   Kim, DH
AF Saipullah, Khairul Muzzammil
   Kim, Deok-Hwan
TI A robust texture feature extraction using the localized angular phase
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texture descriptor; Robust texture feature extraction; Local angular
   phase
ID IMAGE; CLASSIFICATION; TRANSFORMS
AB This paper proposes a novel descriptor, referred to as the localized angular phase (LAP), which is robust to illumination, scaling, and image blurring. LAP utilizes the phase information from the Fourier transform of the pixels in localized polar space with a fixed radius. The application examples of LAP are presented in terms of content-based image retrieval, classification, and feature extraction of real-world degraded images and computer-aided diagnosis using medical images. The experimental results show that the classification performance of LAP in terms of the latter application examples are better than those of local phase quantization (LPQ), local binary patterns (LBP), and local Fourier histogram (LFH). Specially, the capability of LAP to analyze degraded images and classify abnormal regions in medical images are superior to those of other methods since the best overall classification accuracy of LAP, LPQ, LBP, and LFH using degraded textures are 91.26, 61.23, 35.79, and 33.47%, respectively, while the sensitivity of LAP, LBP, and spatial gray level dependent method (SGLDM) in classifying abnormal lung regions in CT images are 100, 95.5, and 93.75%, respectively.
C1 [Saipullah, Khairul Muzzammil; Kim, Deok-Hwan] Inha Univ, Dept Elect Engn, Inchon, South Korea.
C3 Inha University
RP Kim, DH (corresponding author), Inha Univ, Dept Elect Engn, Inchon, South Korea.
EM mellore@hotmail.com; deokhwan@inha.ac.kr
RI Saipullah, Khairul Muzzammil/E-5550-2017
OI Saipullah, Khairul Muzzammil/0000-0003-1543-1543
FU Key Research Institute through the National Research Foundation of Korea
   (NRF); Ministry of Education, Science and Technology [2010-0020163,
   2010-0008355]; Ministry of Knowledge Economy (MKE); Korea Institute for
   Advancement in Technology (KIAT); Defense Acquisition Program
   Administration; National Research Foundation of Korea (NRF); Agency for
   Defence Development, Korea, through the Image Information Research
   Center at Korea Advanced Institute of Science and Technology
   [UD100006CD]
FX This work was supported in part by Key Research Institute Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education, Science and Technology (2010-0020163) and in part
   by Basic Science Research Program through the National Research
   Foundation of Korea (NRF) funded by the Ministry of Education, Science
   and Technology (2010-0008355) and in part by the Ministry of Knowledge
   Economy (MKE) and Korea Institute for Advancement in Technology (KIAT)
   through the Workforce Development Program in Strategic Technology and in
   part by the Defense Acquisition Program Administration and Agency for
   Defence Development, Korea, through the Image Information Research
   Center at Korea Advanced Institute of Science and Technology under the
   contract UD100006CD.
CR Ahmad UA, 2007, INTERNATIONAL CONFERENCE ON MACHINE VISION 2007, PROCEEDINGS, P67
   Ahsan Ahmad U, 2008, J ELECTRON IMAGING, V17
   Baddour N, 2009, J OPT SOC AM A, V26, P1767, DOI 10.1364/JOSAA.26.001767
   Banham MR, 1997, IEEE SIGNAL PROC MAG, V14, P24, DOI 10.1109/79.581363
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   CHEN QS, 1994, IEEE T PATTERN ANAL, V16, P1156
   Flusser J, 1998, IEEE T PATTERN ANAL, V20, P590, DOI 10.1109/34.683773
   Fritz M., 2004, The kth-tips database
   Galloway MM., 1975, COMPUTER GRAPHICS IM, V4, P172, DOI DOI 10.1016/S0146-664X(75)80008-6
   Gonzalez R. C., 2002, DIGITAL IMAGE PROCES
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   HORNER JL, 1984, APPL OPTICS, V23, P812, DOI 10.1364/AO.23.000812
   JULESZ B, 1983, BELL SYST TECH J, V62, P1619, DOI 10.1002/j.1538-7305.1983.tb03502.x
   Kalra MK, 2003, RADIOLOGY, V228, P251, DOI 10.1148/radiol.2281020693
   Kovesi P., 1999, Videre, V1
   Lim FL, 1997, IEE P-VIS IMAGE SIGN, V144, P323, DOI 10.1049/ip-vis:19971457
   Liu J, 2005, PATTERN RECOGN LETT, V26, P1128, DOI 10.1016/j.patrec.2004.10.007
   Liu X, 2000, OSUCISRC72000TR17
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Materka A, 1998, B11 COST U LODZ
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Moreels P, 2007, INT J COMPUT VISION, V73, P263, DOI 10.1007/s11263-006-9967-1
   Muzzammil K., 2009, P KIPS SPRING C 2009, V16, P106
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojala T, 2001, PATTERN RECOGN, V34, P727, DOI 10.1016/S0031-3203(00)00010-8
   Ojansivu V, 2009, ACTA U OULUENSIS C, V339, P53
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Ojansivu V, 2008, INT C PATT RECOG, P3596
   OPPENHEIM AV, 1981, P IEEE, V69, P529, DOI 10.1109/PROC.1981.12022
   Peng S-H, 2009, IFMI 2009, P319
   Peng S-H, 2009, INT C CONV CONT, P129
   Pratt W. K., 1978, DIGITAL IMAGE PROCES, P526
   Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261
   Saipullah K. M., 2010, P IWAIT 2010 KUAL LU, P74
   Shapiro L.G., 2001, COMPUTER VISION, P137
   Skarbnik Nikolay, 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P1542
   Sorensen L, 2010, IEEE T MED IMAGING, V29, P559, DOI 10.1109/TMI.2009.2038575
   Tuceryan M., 1993, Handbook of Pattern Recognition and Computer Vision, P235, DOI [DOI 10.1142/9789814343138_0010, 10.1142/97898143431380010, DOI 10.1142/97898143431380010]
   Van De Weijer J, 1976, P ICIP, P993
   Wang LZ, 1998, IEEE T IMAGE PROCESS, V7, P196, DOI 10.1109/83.660996
   WESZKA JS, 1976, IEEE T SYST MAN CYB, V6, P269, DOI 10.1109/TSMC.1976.5408777
   Witkin A.P., 1983, P INT JOINT C ART IN, P1019, DOI DOI 10.1007/978-3-8348-9190-729
   Zhou F, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P610, DOI 10.1109/ICIP.2001.958567
NR 46
TC 15
Z9 16
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2012
VL 59
IS 3
BP 717
EP 747
DI 10.1007/s11042-011-0766-5
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 950AF
UT WOS:000304619900001
DA 2024-07-18
ER

PT J
AU Vatavu, RD
AF Vatavu, Radu-Daniel
TI Point & click mediated interactions for large home entertainment
   displays
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Home entertainment; TV; Point and click; HCI; WIMP; Large displays;
   Video projectors; Shared interfaces; Wii; Remote control; Home scenario;
   Computer vision
AB This work introduces and discusses the implementation details of a novel concept for a home entertainment system together with an affordable controlling interface that uses point & click interactions in order to create, mix and manipulate media screens within the same projection-based display. Scenarios for single and multiple viewers are discussed with users being able to create, reposition, resize, and control their own-defined media screens. The standard and familiar WIMP interaction techniques are transferred from PCs to home entertainment using a motion-sensing remote controller. An optional system feature is described for the automatic configuration of such media screens by analyzing the home environment using computer vision techniques. Observations from initial user studies are reported with regards to the perceived usefulness and acceptability of the proposed system. The main benefit introduced by this work is that of a large entertainment display that becomes shared and personalized while it is being adapted and fit into the home environment.
C1 Univ Stefan Cel Mare Suceava, Suceava 720229, Romania.
C3 Stefan cel Mare University of Suceava
RP Vatavu, RD (corresponding author), Univ Stefan Cel Mare Suceava, 13 Univ, Suceava 720229, Romania.
EM vatavu@eed.usv.ro
RI Vatavu, Radu-Daniel/AAA-3282-2022; Vatavu, Radu-Daniel/F-1820-2017
OI Vatavu, Radu-Daniel/0000-0002-7631-6445
FU project Progress and development through post-doctoral research and
   innovation in engineering and applied sciences- PRiDE
   [POSDRU/89/1.5/S/57083]; European Social Fund through Sectorial
   Operational Program Human Resources
FX This paper was supported by the project Progress and development through
   post-doctoral research and innovation in engineering and applied
   sciences- PRiDE - Contract no. POSDRU/89/1.5/S/57083, project co-funded
   from European Social Fund through Sectorial Operational Program Human
   Resources 2007-2013.
CR [Anonymous], 2005, ACM S US INT SOFTW T
   [Anonymous], VRST 05, DOI DOI 10.1145/1101616.1101637
   [Anonymous], 2005, P UIST 05, DOI DOI 10.1145/1095034.1095046
   [Anonymous], 2005, Proceedings of the 18th annual ACM symposium on User interface software and technology
   Bernhaupt R, 2007, LECT NOTES COMPUT SC, V4471, P146
   Bolt R. A., 1980, Computer Graphics, V14, P262, DOI 10.1145/965105.807503
   Cao Xiang., 2003, P 16 ANN AC M S USER, P173
   Cotting D., 2006, P 19 ANN ACM S USER, P245, DOI DOI 10.1145/1166253.1166291
   Crow F. C., 1984, Computers & Graphics, V18, P207
   Cui YQ, 2007, LECT NOTES COMPUT SC, V4471, P195
   Eronen L., 2003, P 1 EUR C INT TEL BR, P5
   Freeman W. T., 1995, IEEE INT WORKSH AUT
   Kahn A., 2004, P ACM S USER INTERFA, P127, DOI DOI 10.1145/1029632.1029655
   Lee JC, 2008, IEEE PERVAS COMPUT, V7, P39, DOI 10.1109/MPRV.2008.53
   Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521
   McArthur V, 2009, EICS'09: PROCEEDINGS OF THE ACM SIGCHI SYMPOSIUM ON ENGINEERING INTERACTIVE COMPUTING SYSTEMS, P203
   Myers B. A., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P33, DOI 10.1145/503376.503383
   Natapov D., 2009, Proceedings of Graphics Interface 2009, P223
   Oksman V, 2007, LECT NOTES COMPUT SC, V4471, P215
   Pinhanez Claudio., 2001, CHI 01, P369, DOI DOI 10.1145/634067.634285
   Pratt W.K., 1977, DIGITAL IMAGE PROCES
   Rehm M., 2008, P 22 BRIT HCI GROUP, V1, P13
   Schlmer T., 2008, Second International Conference on Tangible and Embedded Interaction, P11, DOI [DOI 10.1145/1347390.1347395, 10.1145/1347390.1347395]
   Shoemaker G, 2007, UIST 2007: PROCEEDINGS OF THE 20TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P53
   Vatavu RD, 2008, LECT NOTES COMPUT SC, V5066, P183, DOI 10.1007/978-3-540-69478-6_24
   Vogel D., 2005, P 18 ANN ACM S US IN, DOI [10.1145/1095034.1095041, DOI 10.1145/1095034.1095041]
   Wilson Andrew., 2003, CHI, P545, DOI [DOI 10.1145/642611.642706, 10.1145/642611.642706]
   Xiaojun Bi, 2005, 13th Annual ACM International Conference on Multimedia, P1049
   Yang RG, 2001, IEEE VISUAL, P167, DOI 10.1109/VISUAL.2001.964508
NR 30
TC 25
Z9 27
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2012
VL 59
IS 1
BP 113
EP 128
DI 10.1007/s11042-010-0698-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 940DI
UT WOS:000303869800007
DA 2024-07-18
ER

PT J
AU Bellini, P
   Bruno, I
   Cenni, D
   Fuzier, A
   Nesi, P
   Paolucci, M
AF Bellini, Pierfrancesco
   Bruno, Ivan
   Cenni, Daniele
   Fuzier, Alice
   Nesi, Paolo
   Paolucci, Michela
TI Mobile Medicine: semantic computing management for health care
   applications on desktop and mobile devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile Medicine; Content distribution; Cross media content; Automated
   production; mpeg-21; pda; iphone; Semantic computing; DRM
ID MPEG-21
AB In many health care situations, powerful mobile tools may help to make decisions and provide support for continuous education and training. They can be useful in emergency conditions and for the supervised application of protocols and procedures. To this end, content models and formats with semantic and intelligence have more flexibility to provide medical personnel (both in off-line and on-line conditions) with more powerful tools than those currently on the market. In this paper, we are presenting Mobile Medicine solution, which exploits a collection of semantic computing technologies together with intelligent content model and tools to provide innovative services for medical personnel. Most of the activities of semantic computing are performed on the back office on a cloud computing architecture for: clustering, recommendations, intelligent content production and adaptation. The mobile devices have been endowed with a content organizer to collect local data, provide local suggestions, while supporting taxonomical searches and local queries on PDA and iPhone. The proposed solution is under usage at the main hospital in Florence. The smart content has been produced by medical personnel, with the adoption of the new ADF-Design authoring tool, which produces content in MPEG-21 format. The mobile content distribution service is integrated with a collaborative networking portal, for discussion on procedures and content, thus suggestions are provided on both PC and Mobiles (PDA and iPhone).
C1 [Bellini, Pierfrancesco; Bruno, Ivan; Cenni, Daniele; Fuzier, Alice; Nesi, Paolo; Paolucci, Michela] Univ Florence, Dept Syst & Informat, Distributed Syst & Internet Technol Lab, Florence, Italy.
C3 University of Florence
RP Nesi, P (corresponding author), Univ Florence, Dept Syst & Informat, Distributed Syst & Internet Technol Lab, Florence, Italy.
EM pbellini@dsi.unifi.it; ivanb@dsi.unifi.it; cenni@dsi.unifi.it;
   nesi@dsi.unifi.it; paolucci@dsi.unifi.it
RI paolucci, michela/J-1539-2016; Cenni, Daniele/E-1571-2016; Bruno,
   Ivan/H-4527-2012; Bellini, Pierfrancesco/D-5923-2015
OI paolucci, michela/0000-0003-0643-171X; Cenni,
   Daniele/0000-0002-9761-9111; nesi, paolo/0000-0003-1044-3107; Bellini,
   Pierfrancesco/0000-0002-8167-1003
FU Vodafone mobile operator
FX The authors would like to thank all the colleagues of the Medical area
   and in particular Prof. G. Gensini, Prof. L. Corbetta, and Dr. M. Dal
   Canto. A sincere thank to all the people involved, including Vodafone
   mobile operator for their support and collaboration.
CR Anagnostopoulos A, 2007, CIKM 07 NOV 6 8 LISB
   Bartz K, 2006, EC 06 JUN 11 15 ANN
   Behrendt W, 2005, LECT NOTES COMPUT SC, V3532, P257
   Bellini P, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P577, DOI 10.1109/ICME.2006.262474
   Bellini P, 2005, First International Conference on Automated Production of Cross Media Content for Multi-channel Distribution, Proceedings, P134, DOI 10.1109/AXMEDIS.2005.1
   Bellini P, 2006, P IEEE INT C MULT EX
   Bellini P, 2009, P 2009 NEM SUMM FUT
   Bellini P, 2007, 13 INT C DISTR MULT
   Bellini P., 2007, P INT BROADC C IBC 2
   Bellini P., 2008, P 14 INT C DISTR MUL, P71
   Bellini P, 2008, FOURTH INTERNATIONAL CONFERENCE ON AUTOMATED SOLUTIONS FOR CROSS MEDIA CONTENT AND MULTI-CHANNEL DISTRIBUTION, PROCEEDINGS, P41, DOI 10.1109/AXMEDIS.2008.23
   Broder A., 2007, P 30 ANN INT ACM SIG
   Burnett I, 2003, IEEE MULTIMEDIA, V10, P60, DOI 10.1109/MMUL.2003.1237551
   Burnett IS, 2005, IEEE T MULTIMEDIA, V7, P400, DOI 10.1109/TMM.2005.846789
   Ciaramita M, 2008, J ELECTRON COMMER RE, V9, P1
   Everitt B., 2001, Cluster analysis
   Fioravanti F, 2001, IEEE T SOFTWARE ENG
   Hart J, 2008, NORDICHI 2008 US BRI
   Kruitbosch G, 2008, HCC 08 OCT 31 2008 V
   Lee J, 2003, ETRI J, V25, P423, DOI 10.4218/etrij.03.0103.0024
   Michalowski W, 2003, DECIS SUPPORT SYST, V36, P161, DOI 10.1016/S0167-9236(02)00140-9
   Mourad M, 2005, COMPUTER IEEE, P58
   Nazir A, 2008, IMC 08 OCT 20 22 VOU
   Nesi P, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1357, DOI 10.1109/ICME.2006.262790
   Pereira F., 2002, IMSC Press multimedia series
   Protogerakis M., 2009, 3 INT C BIOINF BIOM, P1, DOI [10.1109/ICBBE.2009.5162255, DOI 10.1109/ICBBE.2009.5162255]
   Rousseeuw P.J., 1987, ROBUST REGRESSION OU
   Schellner K, 2003, DMS 2003
   Xui R, 2009, CLUSTERING
   Yih W, 2006, WWW 2006 MAY 23 26 E
   Zhang Y, 2008, KDD 08 AUG 24 27 LAS
NR 31
TC 12
Z9 12
U1 1
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2012
VL 58
IS 1
BP 41
EP 79
DI 10.1007/s11042-010-0684-y
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 917BS
UT WOS:000302147600003
DA 2024-07-18
ER

PT J
AU Poppe, C
   Martens, G
   De Potter, P
   Van de Walle, R
AF Poppe, Chris
   Martens, Gaetan
   De Potter, Pieterjan
   Van de Walle, Rik
TI Semantic web technologies for video surveillance metadata
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video surveillance system; Semantic web technologies; Multimedia
   standards; Reasoning; Video analytics
ID ONTOLOGY
AB Video surveillance systems are growing in size and complexity. Such systems typically consist of integrated modules of different vendors to cope with the increasing demands on network and storage capacity, intelligent video analytics, picture quality, and enhanced visual interfaces. Within a surveillance system, relevant information (like technical details on the video sequences, or analysis results of the monitored environment) is described using metadata standards. However, different modules typically use different standards, resulting in metadata interoperability problems. In this paper, we introduce the application of Semantic Web Technologies to overcome such problems. We present a semantic, layered metadata model and integrate it within a video surveillance system. Besides dealing with the metadata interoperability problem, the advantages of using Semantic Web Technologies and the inherent rule support are shown. A practical use case scenario is presented to illustrate the benefits of our novel approach.
C1 [Poppe, Chris; Martens, Gaetan; De Potter, Pieterjan; Van de Walle, Rik] Ghent State Univ IBBT, Dept Elect & Informat Syst, Multimedia Lab, B-9050 Ledeberg Ghent, Belgium.
RP Poppe, C (corresponding author), Ghent State Univ IBBT, Dept Elect & Informat Syst, Multimedia Lab, Gaston Crommenlaan 8,Bus 201, B-9050 Ledeberg Ghent, Belgium.
EM chris.poppe@ugent.be; gaetan.martens@ugent.be;
   pieterjan.depotter@ugent.be; rik.vandewalle@ugent.be
OI De Potter, Pieterjan/0000-0002-1289-6575
FU Ghent University; Interdisciplinary Institute for Broadband Technology
   (IBBT); Institute for the Promotion of Innovation by Science and
   Technology in Flanders (IWT-Flanders); Fund for Scientific
   Research-Flanders (FWO-Flanders); European Union
FX The research activities that have been described in this paper were
   funded by Ghent University, the Interdisciplinary Institute for
   Broadband Technology (IBBT), the Institute for the Promotion of
   Innovation by Science and Technology in Flanders (IWT-Flanders), the
   Fund for Scientific Research-Flanders (FWO-Flanders), and the European
   Union.
CR Annesley J, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P482, DOI 10.1109/AVSS.2007.4425358
   [Anonymous], P 4 INT C AUT SOL CR
   [Anonymous], P INT WORKSH KNOWL R
   [Anonymous], 2004, W3C MEMB SUBMISS
   [Anonymous], P IEEE INT WORKSH PE
   [Anonymous], GOOD SCHEMA MANAGEME
   [Anonymous], OVREADY OBJECTVIDEOS
   [Anonymous], OP NETW VID INT FOR
   [Anonymous], ISOIECJTC1SC29WG11
   [Anonymous], INTELLIGENT SYSTEMS
   [Anonymous], 2006, P JENA USER C BRIST
   [Anonymous], P SPIE ELECT IMAGING
   [Anonymous], P ADV VIDEO SIGNAL B
   [Anonymous], VIDEO SEMANTIC CONTE
   [Anonymous], SOCIETAL SECURITY VI
   [Anonymous], DESIGN DISTRIBUTED R
   [Anonymous], SPARQL QUER LANG RDF
   [Anonymous], ENABLING VIDEO ANAL
   Arndt R, 2007, LECT NOTES COMPUT SC, V4825, P30
   Black J, 2005, PATTERN ANAL APPL, V7, P430, DOI 10.1007/s10044-005-0243-8
   SanMiguel JC, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P220, DOI 10.1109/AVSS.2009.28
   Clark James, 1999, Xsl transformations (xslt)
   Fallside D., 2004, XML SCHEMA PART 0 PR, Vsecond
   Ferdinand M, 2004, LECT NOTES COMPUT SC, V3140, P354
   François ARJ, 2005, IEEE MULTIMEDIA, V12, P76, DOI 10.1109/MMUL.2005.87
   Fuentes LM, 2006, IMAGE VISION COMPUT, V24, P1165, DOI 10.1016/j.imavis.2005.06.006
   Garcia R., 2006, Proc 5th Knowledge Markup and Semantic Annotation Workshop CEUR Workshop Proceeding, P69
   Hunter J., 2001, First International Semantic Web Working Symposium (SWWS'01), P261
   Klein M, 2002, 13TH INTERNATIONAL WORKSHOP ON DATABASE AND EXPERT SYSTEMS APPLICATIONS, PROCEEDINGS, P889
   List T, 2004, INT C PATT RECOG, P789, DOI 10.1109/ICPR.2004.1334335
   Ma YQ, 2009, COMPUT VIS IMAGE UND, V113, P580, DOI 10.1016/j.cviu.2009.01.002
   Mariano VY, 2002, INT C PATT RECOG, P965, DOI 10.1109/ICPR.2002.1048198
   Miller E., 2004, RDF primer
   Nevatia R., 2004, Computer Vision and Pattern Recognition Workshop, P119
   Patel-Schneider P.F., 2004, OWL Web Ontology Lan-guage semantics and abstract syntax
   Poppe C, 2008, PROC SPIE, V6978, DOI 10.1117/12.777034
   Poppe C, 2009, J VIS COMMUN IMAGE R, V20, P428, DOI 10.1016/j.jvcir.2009.05.001
   Senior A., 2009, INTRO AUTOMATIC VIDE, P1
   Shan Y, 2006, OPT ENG, V45, DOI 10.1117/1.2213962
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Tian YL, 2008, MACH VISION APPL, V19, P315, DOI 10.1007/s00138-008-0153-z
   Troncy R, 2006, LECT NOTES COMPUT SC, V4306, P41
   Vezzani R, 2010, MULTIMED TOOLS APPL, V50, P359, DOI 10.1007/s11042-009-0402-9
   Xu LQ, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P10, DOI 10.1109/AVSS.2007.4425278
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Young D. P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P317
NR 46
TC 8
Z9 9
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2012
VL 56
IS 3
BP 439
EP 467
DI 10.1007/s11042-010-0600-5
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 891AX
UT WOS:000300189700003
OA Green Published
DA 2024-07-18
ER

PT J
AU Zhang, XP
   Wang, SZ
   Qian, ZX
   Feng, GR
AF Zhang, Xinpeng
   Wang, Shuozhong
   Qian, Zhenxing
   Feng, Guorui
TI Self-embedding watermark with flexible restoration quality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fragile watermarking; Self-embedding; Image quality
ID FRAGILE IMAGE WATERMARKING; SCHEMES
AB A novel self-embedding watermarking scheme is proposed, in which the reference data derived from the most significant bits (MSB) of host image and the localization data derived from MSB and reference data are embedded into the least significant bits (LSB) of the cover. At authentication side, while the localization data are used to detect the blocks containing substitute information, the reference data extracted from other regions and the spatial correlation are exploited to recover the principal content in tampered area by a pixel-by-pixel manner. In this scheme, the narrower the tampered area is, the higher quality of recovered content can be obtained.
C1 [Zhang, Xinpeng; Wang, Shuozhong; Qian, Zhenxing; Feng, Guorui] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200072, Peoples R China.
C3 Shanghai University
RP Zhang, XP (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200072, Peoples R China.
EM xzhang@shu.edu.cn; shuowang@shu.edu.cn; zxqian@shu.edu.cn;
   grfeng@shu.edu.cn
RI Qian, Zhenxing/AHC-9176-2022; Feng, Guorui/E-6895-2012
FU Natural Science Foundation of China [60872116, 60832010, 60773079];
   Shanghai Rising-Star Program [10QH14011]; Shanghai Education Committee
   [10ZZ59]
FX This work was supported by the Natural Science Foundation of China
   (60872116, 60832010, and 60773079), the Shanghai Rising-Star Program
   (10QH14011), and the Key Scientific Research Project of Shanghai
   Education Committee (10ZZ59).
CR Fridrich J., 1999, P 1999 INT C IM PROC, P792, DOI [10.1109/ICIP.1999.817228, DOI 10.1109/ICIP.1999.817228]
   He HJ, 2009, SIGNAL PROCESS, V89, P1557, DOI 10.1016/j.sigpro.2009.02.009
   Holliman M, 2000, IEEE T IMAGE PROCESS, V9, P432, DOI 10.1109/83.826780
   Suthaharan S, 2004, PATTERN RECOGN LETT, V25, P1893, DOI 10.1016/j.patrec.2004.08.017
   Wong PW, 2001, IEEE T IMAGE PROCESS, V10, P1593, DOI 10.1109/83.951543
   Zhang X, 2007, IEEE SIGNAL PROC LET, V14, P727, DOI 10.1109/LSP.2007.896436
   Zhang XP, 2009, SIGNAL PROCESS, V89, P675, DOI 10.1016/j.sigpro.2008.10.001
   Zhu X, 2007, SIGNAL PROCESS-IMAGE, V22, P515, DOI 10.1016/j.image.2007.03.004
NR 8
TC 40
Z9 44
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2011
VL 54
IS 2
BP 385
EP 395
DI 10.1007/s11042-010-0541-z
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 781SK
UT WOS:000291953700009
DA 2024-07-18
ER

PT J
AU Mirri, S
   Muratori, LA
   Roccetti, M
   Salomoni, P
AF Mirri, Silvia
   Muratori, Ludovico A.
   Roccetti, Marco
   Salomoni, Paola
TI The Directors' cut: a solution to collaborative multimedia management
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia systems; Multimedia computing; Multimedia accessibility;
   Multimedia collaborative editing
ID OBSCURE OBJECT; METADATA; DESIRE; WEB
AB Web 2.0 applications allow rich media contents to be exposed and shared by users. Nevertheless, usually, a multimedia is provided as an unicum, made by synchronized media items. Sound tracks, video sequences, captions, cannot be customized "on-the-fly" by users. Managing multimedia in a deep way would meet the expectations of nowadays Web prosumers (i.e. producers and consumers), and it would widen the audience. Describing and synchronizing each medium, as well as specifying different alternative contents for it, are the keystones of multimedia customization and of audience widening. This paper presents a multimedia collaborative system, which provides support to the arrangement of medium into a multi-views composed multimedia. Each prosumer can add medium by juxtaposition or by defining it as an alternative (audio, video, textual) version of an existing one. The implementation of such a system is based on SMIL 3.0 specification but implements a new and compact syntax to let users manipulate the original multimedia synchronization and their alternatives. The proposed approach has been put to test in two different scenarios.
C1 [Mirri, Silvia; Muratori, Ludovico A.; Roccetti, Marco; Salomoni, Paola] Univ Bologna, Dept Comp Sci, Bologna, Italy.
C3 University of Bologna
RP Mirri, S (corresponding author), Univ Bologna, Dept Comp Sci, Bologna, Italy.
EM silvia.mirri@unibo.it; muratori@cs.unibo.it; roccetti@cs.unibo.it;
   paola.salomoni@unibo.it
RI ; Mirri, Silvia/I-7983-2016
OI ROCCETTI, MARCO/0000-0003-1264-8595; Mirri, Silvia/0000-0002-5385-4734
CR [Anonymous], 2004, IMS ACCESSFORALL MET
   BULTERMAN DCA, 2006, 14 ANN ACM INT C MUL, P651
   Cattelan RG, 2008, ACM T MULTIM COMPUT, V4, DOI 10.1145/1412196.1412201
   CESAR P, 2008, 16 ACM INT C MULT MM, P11
   COSTA RMD, 2006, 6 ACM S DOC ENG DOCE, P165
   DESILETS A, 2006, 2006 ACM INT S WIK W
   FERRETTI S, 2008, 2008 W4A INT CROSS D
   FOLL S, 2006, 8 IEEE INT S MULT IS
   HOSSAIN MA, 2006, 8 IEEE INT S MULT IS
   *IMS GLOB LEARN CO, 2006, GUID DEV ACC LEARN A
   *IT PARL, 2004, OFFICIAL J       JAN
   JANSENS J, 2008, 8 ACM S DOC ENG DOCE, P18
   Kosch H, 2005, IEEE MULTIMEDIA, V12, P80, DOI 10.1109/MMUL.2005.13
   *MPEG REQ GROUP, 2002, N4991 ISOMPEG REQ GR
   Nack F, 2005, IEEE MULTIMEDIA, V12, P54, DOI 10.1109/MMUL.2005.12
   Pea R, 2004, IEEE MULTIMEDIA, V11, P54, DOI 10.1109/MMUL.2004.1261108
   SGOUROS NM, 2007, INT WORKSH HUM CTR M, P41
   SHAW R, 2006, 1 ACM INT WORKSH HUM, P89
   Tang CW, 2007, IEEE T MULTIMEDIA, V9, P231, DOI 10.1109/TMM.2006.886328
   van Ossenbruggen J, 2004, IEEE MULTIMEDIA, V11, P38, DOI 10.1109/MMUL.2004.36
   WC3, 2008, WEB CONTENT ACCESSIB
   *WORLD WID WEB CON, 2008, SYNCH MULT INT LANG
   *WORLD WID WEB CON, 2008, SMIL 2 1 TIM SYNCH M
   *WORLD WID WEB CON, 2008, SMIL 3 0 CUSTOMTESTA
   *WORLD WID WEB CON, 1999, ACC FEAT SMIL
   2009, AMBULANT OPEN SOURCE
   2009, SMIL 3 0 DAISY PROFI
NR 27
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2011
VL 53
IS 1
BP 319
EP 344
DI 10.1007/s11042-010-0533-z
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 746AZ
UT WOS:000289214700015
DA 2024-07-18
ER

PT J
AU Yan, DQ
   Wang, RD
AF Yan, Diqun
   Wang, Rangding
TI Huffman table swapping-based steganograpy for MP3 audio
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; MP3; Huffman coding
AB Raw audios contain significant amount of redundancy which can be used for steganographic purposes. But practically most audios are stored and transmitted in the compressed formats. In this paper, we present a MPEG-1 Layer III (MP3) audio CODEC based steganographic method to embed secret message during encoding. The Huffman tables in MP3 standard are first partitioned into three groups. The secret message is then embedded by Huffman table swapping strategy. Instead of fully decoding the stego-audio, the extraction of the secret message can be done just by parsing the side information. The proposed method is designed under the restrictions of the MP3 compression standard without any modifications or additions to the existing standard. Experimental results show that the proposed method can provide much higher capacity than other approaches, while satisfying the low distortion and security requirements for steganography on MP3 audios.
C1 [Yan, Diqun; Wang, Rangding] Ningbo Univ, Coll Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
C3 Ningbo University
RP Yan, DQ (corresponding author), Ningbo Univ, Coll Informat Sci & Engn, 818 Feng Hua Rd, Ningbo 315211, Zhejiang, Peoples R China.
EM yandiqun@nbu.edu.cn; wangrangding@nbu.edu.cn
RI Yan, Diqun/AAY-6775-2021
OI Yan, Diqun/0000-0002-5241-7276
FU National Natural Science Foundation of China [60873220]; Ningbo Natural
   Science Foundation [2009A610085]; Zhejiang Provincial Education
   Department [20070974]
FX This work is supported by the National Natural Science Foundation of
   China under Grant No. 60873220, Ningbo Natural Science Foundation under
   Grant No. 2009A610085 and also supported by the Scientific Research Fund
   of Zhejiang Provincial Education Department under Grant No. 20070974.
CR Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Cachin C, 1998, LECT NOTES COMPUT SC, V1525, P306
   Cvejic N, 2004, ITCC 2004: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 2, PROCEEDINGS, P533, DOI 10.1109/ITCC.2004.1286709
   *ISO IEC, 1993, 111723 IS ISOIEC
   Kim DH, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL IV, PROCEEDINGS, P181
   KOUKOPOULOS D, 2005, INT ENF C ENF CAN TU, P154
   MOGHADAM N, 2005, INT ENF C, P348
   NAHRSTEDT N, 1998, 6 ACM INT MULT C BRI, P93
   Neubauer C, 1998, LECT NOTES COMPUT SC, V1525, P208
   [Perceptual Evaluation of Audio Quality ( PEAQ) ITU- R Recommendation], 1998, BS1387 ITUR
   Petitcolas F. A. P., 2002, MP3STEGO
   Provos N., 2003, IEEE Security & Privacy, V1, P32, DOI 10.1109/MSECP.2003.1203220
   TAKAGI K, 2005, IEICE T FUND ELECTR, P2546
   Torrubia A, 2002, IEEE T CONSUM ELECTR, V48, P1046, DOI 10.1109/TCE.2003.1196437
   Viswanathan V, 2008, APPL MATH COMPUT, V201, P121, DOI 10.1016/j.amc.2007.12.003
   Wang SZ, 2003, LECT NOTES COMPUT SC, V2776, P383
   Westfeld A, 2003, LECT NOTES COMPUT SC, V2578, P324
NR 17
TC 13
Z9 15
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2011
VL 52
IS 2-3
SI SI
BP 291
EP 305
DI 10.1007/s11042-009-0430-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 732IA
UT WOS:000288177000004
DA 2024-07-18
ER

PT J
AU Albanese, M
   Chianese, A
   d'Acierno, A
   Moscato, V
   Picariello, A
AF Albanese, Massimiliano
   Chianese, Angelo
   d'Acierno, Antonio
   Moscato, Vincenzo
   Picariello, Antonio
TI A multimedia recommender integrating object features and user behavior
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender systems; Browsing; Information retrieval; Multimedia
   databases
ID OF-THE-ART; RETRIEVAL; VIDEO
AB Despite the great amount of work done in the last decade, retrieving information of interest from a large multimedia repository still remains an open issue. In this paper, we propose an intelligent browsing system based on a novel recommendation paradigm. Our approach combines usage patters with low-level features and semantic descriptors in order to predict users' behavior and provide effective recommendations. The proposed paradigm is very general and can be applied to any type of multimedia data. In order to make the recommender system even more flexible, we introduce the concept of multichannel browser, i.e. a browser that allows concurrent browsing of multiple media channels. We implemented a prototype of the proposed system and tested the effectiveness of our approach in a virtual museum scenario. Experimental results have proved that the system greatly enhances users' experience, thus encouraging further research in this direction.
C1 [Albanese, Massimiliano] Univ Maryland, UMIACS, College Pk, MD 20742 USA.
   [Chianese, Angelo; Moscato, Vincenzo; Picariello, Antonio] Univ Naples Federico II, DIS, I-80125 Naples, Italy.
   [d'Acierno, Antonio] CNR, ISA, I-83100 Avellino, Italy.
C3 University System of Maryland; University of Maryland College Park;
   University of Naples Federico II; Consiglio Nazionale delle Ricerche
   (CNR); Istituto di Scienze dell' Alimentazione (ISA-CNR)
RP Albanese, M (corresponding author), Univ Maryland, UMIACS, College Pk, MD 20742 USA.
EM albanese@umiacs.umd.edu; angelo.chianese@unina.it;
   dacierno.a@isa.cnr.it; vmoscato@unina.it; antonio.picariello@unina.it
RI Picariello, Antonio/G-9062-2012; Albanese, Massimiliano/H-5093-2019;
   d'Acierno, Antonio/A-4228-2009; Moscato, Vincenzo/H-2526-2012;
   d'acierno, Antonio/AAW-5467-2020; PICARIELLO, Antonio/L-6820-2015
OI Albanese, Massimiliano/0000-0002-2675-5810; Moscato,
   Vincenzo/0000-0002-0754-7696; PICARIELLO, Antonio/0000-0003-4804-1007;
   d'Acierno, Antonio/0000-0003-0516-0794
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   ALBANESE M, 2009, SAC 09, P1771
   Anand SS, 2007, ACM T INTERNET TECHN, V7, DOI 10.1145/1278366.1278371
   [Anonymous], 1995, PROC ICJAI, DOI DOI 10.1145/217279.215068
   [Anonymous], SAC 06
   BASILICO J, 2004, ICML 04
   Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426
   Eirinaki M., 2003, ACM T INTERNET TECHN, V3, P1, DOI [10.1145/643477.643478, DOI 10.1145/643477.643478]
   Fayzullin M, 2007, MULTIMED TOOLS APPL, V33, P351, DOI 10.1007/s11042-007-0100-4
   HART S G, 1988, P139
   Lam Xuan Nhat, 2008, ICUIMC, P208
   Lekakos G, 2008, MULTIMED TOOLS APPL, V36, P55, DOI 10.1007/s11042-006-0082-7
   Levenshtein V. I., 1966, SOV PHYS DOKL, V10, P707
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li YH, 2003, IEEE T KNOWL DATA EN, V15, P871, DOI 10.1109/TKDE.2003.1209005
   Maidel V, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P91
   Park ST, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P550
   PASI G, 2007, SIGIR 07, P775
   Pazzani M. J., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P325
   Santini S, 2000, PROC SPIE, V3972, P132
   Si L., 2004, Proc. of the 13th ACM Int. Conf. on Information and Knowledge Management, P156
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Tso-Sutter KHL, 2008, APPLIED COMPUTING 2008, VOLS 1-3, P1995
   Wang J, 2008, ACM T INFORM SYST, V26, DOI 10.1145/1361684.1361689
   Yeung MM, 1997, IEEE T CIRC SYST VID, V7, P771, DOI 10.1109/76.633496
   Zhu XQ, 2005, IEEE T MULTIMEDIA, V7, P648, DOI 10.1109/TMM.2005.850977
NR 26
TC 34
Z9 34
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2010
VL 50
IS 3
SI SI
BP 563
EP 585
DI 10.1007/s11042-010-0480-8
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 630CC
UT WOS:000280248100007
DA 2024-07-18
ER

PT J
AU Mansoorizadeh, M
   Charkari, NM
AF Mansoorizadeh, Muharram
   Charkari, Nasrollah Moghaddam
TI Multimodal information fusion application to human emotion recognition
   from face and speech
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal feature extraction; Multimodal information fusion; Human
   computer interaction; Multimodal emotion recognition
ID CLASSIFICATION; FEATURES; MODELS
AB A multimedia content is composed of several streams that carry information in audio, video or textual channels. Classification and clustering multimedia contents require extraction and combination of information from these streams. The streams constituting a multimedia content are naturally different in terms of scale, dynamics and temporal patterns. These differences make combining the information sources using classic combination techniques difficult. We propose an asynchronous feature level fusion approach that creates a unified hybrid feature space out of the individual signal measurements. The target space can be used for clustering or classification of the multimedia content. As a representative application, we used the proposed approach to recognize basic affective states from speech prosody and facial expressions. Experimental results over two audiovisual emotion databases with 42 and 12 subjects revealed that the performance of the proposed system is significantly higher than the unimodal face based and speech based systems, as well as synchronous feature level and decision level fusion approaches.
C1 [Mansoorizadeh, Muharram; Charkari, Nasrollah Moghaddam] Tarbiat Modares Univ, Parallel & Image Proc Lab, Fac Elect & Comp Engn, Tehran, Iran.
C3 Tarbiat Modares University
RP Mansoorizadeh, M (corresponding author), Tarbiat Modares Univ, Parallel & Image Proc Lab, Fac Elect & Comp Engn, Tehran, Iran.
EM mansoorm@modares.ac.ir
RI Mansoorizadeh, Muharram/C-4575-2018
OI Mansoorizadeh, Muharram/0000-0002-7131-1047; moghaddam charkari,
   nasrollah/0000-0003-1871-7977
FU Iran Telecommunication Research Center (ITRC) [T500/20592]
FX This project has been supported in part by the Iran Telecommunication
   Research Center (ITRC) under grant no. T500/20592.
CR BASSILI JN, 1979, J PERS SOC PSYCHOL, V37, P2049, DOI 10.1037/0022-3514.37.11.2049
   Black MJ, 1997, INT J COMPUT VISION, V25, P23, DOI 10.1023/A:1007977618277
   Boehner K, 2007, INT J HUM-COMPUT ST, V65, P275, DOI 10.1016/j.ijhcs.2006.11.016
   Boersma P., 2007, PRAAT: doing phonetics by computer
   Busso C, 2007, IEEE T AUDIO SPEECH, V15, P2331, DOI 10.1109/TASL.2007.905145
   Castellano G, 2008, LECT NOTES COMPUT SC, V4868, P92, DOI 10.1007/978-3-540-85099-1_8
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   De Silva L. C., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P332, DOI 10.1109/AFGR.2000.840655
   Dupont S, 2000, IEEE T MULTIMEDIA, V2, P141, DOI 10.1109/6046.865479
   Ekman P., 2002, FACIAL ACTION CODING
   FASEL B, 1999, AUTOMATIC FACIAL EXP, V36
   Fragopanagos N, 2005, NEURAL NETWORKS, V18, P389, DOI 10.1016/j.neunet.2005.03.006
   Gunes Hatice, 2008, Affective Computing. Focus on Emotion Expression, Synthesis and Recognition, P185
   Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606
   Hall D.L., 2001, HDB MULTISENSOR DATA
   Jimenez LO, 1999, IEEE T GEOSCI REMOTE, V37, P1360, DOI 10.1109/36.763300
   Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491, DOI 10.1109/TKDE.2005.66
   MANSOORIZADEH M, 2009, CSI NAT C CSICC 2009
   MANSOORIZADEH M, 2008, HCI HRI WORKSH PETRA
   Martin AR, 2006, TAPPI J, V5, P22
   MEHRABIAN A, 1968, PSYCHOL TODAY, V2, P53
   PALEARI M, 2006, P 1 ACM INT WORKSH H, P99
   PANTIC M, 2000, PAMI, V22, P124
   Pierre-Yves O, 2003, INT J HUM-COMPUT ST, V59, P157, DOI 10.1016/S1071-5819(03)00141-6
   Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5
   Sadlier DA, 2005, IEEE T CIRC SYST VID, V15, P1225, DOI 10.1109/TCSVT.2005.854237
   Sobottka K, 1998, SIGNAL PROCESS-IMAGE, V12, P263, DOI 10.1016/S0923-5965(97)00042-8
   Song M, 1920, NEUROCOMPUTING, V71, P1913
   Webb A.R., 2003, Statistical Pattern Recognition
   Welch Greg., 2004, INTRO KALMAN FILTER
   Wu Y., 2004, ACM INT C MULTIMEDIA, P572, DOI DOI 10.1145/1027527.1027665
   Yang J, 2003, PATTERN RECOGN, V36, P1369, DOI 10.1016/S0031-3203(02)00262-5
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhou ZH, 2004, PATTERN RECOGN, V37, P1049, DOI 10.1016/j.patcog.2003.09.006
NR 35
TC 95
Z9 102
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2010
VL 49
IS 2
BP 277
EP 297
DI 10.1007/s11042-009-0344-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 604OB
UT WOS:000278287300002
DA 2024-07-18
ER

PT J
AU Tous, R
   Delgado, J
AF Tous, Ruben
   Delgado, Jaime
TI Semantic-driven multimedia retrieval with the MPEG Query Format
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MPEG Query Format; MPQF; Semantics; Multimedia retrieval; Semantic web;
   SPARQL; RDF
AB The MPEG Query Format (MPQF) is a new standard from the MPEG standardization committee which provides a standardized interface to multimedia document repositories. The purpose of this paper is describing the necessary extensions which will allow MPQF to manage metadata modelled with Semantic Web languages like RDF and OWL, and query constructs based on SPARQL. The suggested modifications include the definition of a new MPQF query type, and a generalization of the MPQF metadata processing model. As far as we know, this is the first work to apply the MPEG Query Format to semantic-driven search and retrieval of multimedia contents.
C1 [Tous, Ruben; Delgado, Jaime] Univ Politecn Cataluna, Dpt Arquitectura Computadors, DMAG, Barcelona, Spain.
C3 Universitat Politecnica de Catalunya
RP Tous, R (corresponding author), Univ Politecn Cataluna, Dpt Arquitectura Computadors, DMAG, Barcelona, Spain.
EM rtous@ac.upc.edu; jaime.delgado@ac.upc.edu
RI Delgado, Jaime/AAA-8489-2019
OI Delgado, Jaime/0000-0003-1366-663X; Tous, Ruben/0000-0002-1409-5843
FU Spanish government [TEC2008-06692-C02-01]; European Network of
   Excellence VISNET-II [IST-2005-2.41.6]; European Commission
FX This work has been partly supported by the Spanish government
   (TEC2008-06692-C02-01) and the European Network of Excellence VISNET-II
   (IST-2005-2.41.6), co-funded under the European Commission IST 6th
   Framework Program.
CR Adistambha K, 2007, 2007 INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES, VOLS 1-3, P479, DOI 10.1109/ISCIT.2007.4392066
   [Anonymous], RES DESCR FRAM RDF C
   [Anonymous], 2004, 15938 ISOIEC
   [Anonymous], 2004, W3C RECOMMENDATION 1
   Benedikt Michael., 2005, PODS, P25, DOI DOI 10.1145/1065167.1065172
   Döller M, 2008, IEEE MULTIMEDIA, V15, P82, DOI 10.1109/MMUL.2008.96
   DOLLER M, 2008, OUTP DOC 86 MPEG M O
   DOLLER M, 2008, 45 ISO IEC JTC 1 SC
   FATEMI N, 2003, P XML C EXP 2003 DEE
   GRUHNE M, 2007, P 3 INT C AUT PROD C
   HORROCKS I, 2000, J INTEREST GROUP PUR
   *INKL, REF QUERY US SQ QL
   *ISO IEC WD, 2008, 2480022008 ISOIEC WD
   KANG J, 2003, P 3 ACM IEEE CS JOIN
   Melton J, 2001, SIGMOD RECORD, V30, P97, DOI 10.1145/604264.604280
   PORTWIN K, 2006, XTECH BUILDING WEB 2
   Tjondronegoro D., 2002, World Wide Web, V5, P207, DOI 10.1023/A:1020988713878
   TOUS R, 2009, 47 ISO IEC JTC 1 SC
   TOUS R, 2008, 46 ISO IEC JTC 1 SC
   *W3C, 2004, SPARQL QUERY LANG RD
   *W3C, 2003, RDF VOC DESCR LANG 1
   *W3C, 2004, RDQL QUERY LAN UNPUB
   *W3C, 2006, XQUERY 1 0 XML QUERY
   YOON K, 2008, 15938122008 ISOIEC
   YOON K, 2008, 45 ISO IEC JTC 1 SC
NR 25
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2010
VL 49
IS 1
SI SI
BP 213
EP 233
DI 10.1007/s11042-009-0390-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 595WF
UT WOS:000277643600011
DA 2024-07-18
ER

PT J
AU Chilamkurti, N
   Zeadally, S
   Soni, R
   Giambene, G
AF Chilamkurti, Naveen
   Zeadally, Sherali
   Soni, Robin
   Giambene, Giovanni
TI Wireless multimedia delivery over 802.11e with cross-layer optimization
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compression; Cross-layer; H.264; Multimedia; Network; 802.11e; Video;
   Wireless
AB The use of wireless networks has spread further than simple data transfer to delay sensitive and loss tolerant multimedia applications. Over the past few years, wireless multimedia transmission across Wireless Local area Networks (WLANs) has gained a lot of attention because of the introduction of technologies such as Bluetooth, IEEE 802.11, 3G, and WiMAX. The IEEE 802.11 WLAN has become a dominating technology due to its low cost and ease of implementation. But, transmitting video over WLANs in real time remains a challenge because it imposes strong demands on video codec, the underlying network, and the Media Access Control (MAC) layer. This paper presents a cross-layer mapping algorithm to improve the quality of transmission of H.264 (a recently-developed video coding standard of the ITU-T Video Coding Experts Group) video stream over IEEE 802.11e-based wireless networks. The major goals of H.264 standard were on improving the rate distortion and the enhanced compression performance. Our proposed cross-layer design involves the mapping of H.264 video slices (packets) to appropriate access categories of IEEE 802.11e according to their information significance. We evaluate the performance of our proposed cross-layer design and the results obtained demonstrate its effectiveness in exploiting characteristics of the MAC and application layers to improve the video transmission quality.
C1 [Chilamkurti, Naveen; Soni, Robin] La Trobe Univ, Dept Comp Sci & Comp Engn, Melbourne, Vic 3086, Australia.
   [Giambene, Giovanni] Univ Siena, I-53100 Siena, Italy.
   [Zeadally, Sherali] Univ Dist Columbia, Dept Comp Sci & Informat Technol, Washington, DC 20008 USA.
C3 La Trobe University; University of Siena; University of the District of
   Columbia
RP Chilamkurti, N (corresponding author), La Trobe Univ, Dept Comp Sci & Comp Engn, Melbourne, Vic 3086, Australia.
EM n.chilamkurti@latrobe.edu.au; szeadally@udc.edu;
   rsoni@students.latrobe.edu.au; giambene@unisi.it
RI Chilamkurti, Naveen/S-9636-2019; Giambene, Giovanni/AAW-7243-2021;
   Zeadally, Sherali/AAY-9504-2020
OI Chilamkurti, Naveen/0000-0002-5396-8897; Giambene,
   Giovanni/0000-0002-5756-4603; 
CR [Anonymous], 1998, An Architecture for Differentiated Services, RFC 2475 Informational
   [Anonymous], H264ISOIEC ITUT
   Crow BP, 1997, IEEE COMMUN MAG, V35, P116, DOI 10.1109/35.620533
   Floyd S, 1993, IEEE ACM T NETWORK, V1, P397, DOI 10.1109/90.251892
   Kawadia V, 2005, IEEE WIREL COMMUN, V12, P3, DOI 10.1109/MWC.2005.1404568
   KE CH, 2008, SPECIAL ISSUE INT J, V42
   Khan S, 2006, IEEE COMMUN MAG, V44, P122, DOI 10.1109/MCOM.2006.1580942
   Ksentini A, 2006, IEEE COMMUN MAG, V44, P107, DOI 10.1109/MCOM.2006.1580940
   KSENTINI A, 2004, 15 IEEE INT S PIMRC, V2, P1466
   Marpe D, 2006, IEEE COMMUN MAG, V44, P134, DOI 10.1109/MCOM.2006.1678121
   Shakkottai S, 2003, IEEE COMMUN MAG, V41, P74, DOI 10.1109/MCOM.2003.1235598
   SHIEH CK, 2001, ICC2001, V9, P2897
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
NR 13
TC 31
Z9 37
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2010
VL 47
IS 1
BP 189
EP 205
DI 10.1007/s11042-009-0413-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 554LV
UT WOS:000274437400011
DA 2024-07-18
ER

PT J
AU Chan, MC
   Hu, SY
   Jiang, JR
AF Chan, Mo-Che
   Hu, Shun-Yun
   Jiang, Jehn-Ruey
TI Secure peer-to-peer 3D streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Peer-to-peer; Virtual environments; Nonlinear media; 3D streaming;
   Security; Online games
ID NETWORK
AB In recent years, interactive virtual environments such as Second Life, and virtual globe applications such as Google Earth, have become very popular. However, delivering massive amounts of interactive content to millions of potential users brings enormous challenges to content providers. Distributed peer-to-peer (P2P) approaches have thus been proposed to increase the system scalability in affordable ways. Building content delivery systems based on P2P approaches nevertheless creates security concerns for commercial vendors. This paper presents a generic system model for subscription-based service providers to adopt P2P-based, non-linear streaming for interactive content. We also propose solutions to the issue of content authentication, such that paying customers can be sure of the authenticity of the content retrieved from other users. Other practical security issues in an extended system model are also identified to allow further investigations in this problem space.
C1 [Chan, Mo-Che; Hu, Shun-Yun; Jiang, Jehn-Ruey] Natl Cent Univ, Dept Comp Sci & Informat Engn, Jhongli, Taiwan.
C3 National Central University
RP Jiang, JR (corresponding author), Natl Cent Univ, Dept Comp Sci & Informat Engn, Jhongli, Taiwan.
EM chrysler@acnlab.csie.ncu.edu.tw; syhu@csie.ncu.edu.tw;
   jrjiang@csie.ncu.edu.tw
RI Jiang, JR/JED-9391-2023
CR [Anonymous], P SIGCOMM 01, DOI DOI 10.1145/383059.383071
   BERGADANO F, 2000, LECT NOTES COMPUTER, V2012, P144
   BHARAMBE A, 2008, P SIGCOMM
   Bharambe A., 2006, Proceedings of the 3rd conference on Networked Systems Design Implementation - Volume 3, NSDI'06, V3, P12
   BOTEV J, 2008, P MMVE
   Burton D. M, 2005, Elementary number theory, V6th
   CHENG W, 2008, P NOSSDAV
   FREY D, 2008, P MMVE
   Gennaro R, 1997, LECT NOTES COMPUT SC, V1294, P180
   Guo YH, 2007, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON HEALTH MONITORING OF STRUCTURE, MATERIALS AND ENVIRONMENT, VOLS 1 AND 2, P738
   Hoppe H., 1996, P SIGGRAPH
   Hu S.-Y., 2006, P 11 INT C 3D WEB TE, P57
   Hu SY, 2006, IEEE NETWORK, V20, P22, DOI 10.1109/MNET.2006.1668400
   HU SY, 2008, P IEEE INFOCOM
   HU SY, 2008, P NIME
   HUANG GY, 2008, P MMVE
   JOSEPHSON WK, 2004, P INT WORKSH PEER TO
   Knutsson B., 2004, P IEEE INFOCOM
   LI ZT, 2006, P 3 INT C AUT TRUST, P398
   LIN NS, 2007, IEEE T CONSUM ELECT, V53
   LO V, 2005, P HOT P2P
   *MIT KERB TEAM, 1980, NETW AUTH PROT
   O'Gorman L, 2003, P IEEE, V91, P2021, DOI 10.1109/JPROC.2003.819611
   Pathak V, 2006, COMPUT NETW, V50, P579, DOI 10.1016/j.comnet.2005.07.007
   Pauly M, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P163, DOI 10.1109/VISUAL.2002.1183771
   Pointcheval D, 1996, LECT NOTES COMPUT SC, V1070, P387
   Rabin M.O., 1979, Digitalized Signatures and Public-Key Functions as Intractable as Factorization
   Rey C., 2002, EURASIP Journal on Applied Signal Processing, V2002, P613, DOI 10.1155/S1110865702204047
   ROSEDALE P, 2003, GAMASUTRA RESOURCE G
   Royan J, 2007, IEEE COMPUT GRAPH, V27, P70, DOI 10.1109/MCG.2007.155
   SCHIELE G, 2008, P IEEE VIRT REAL IEE
   SCHNEIER B, 1996, APPL CRYPTOGRAPHY, pCH7
   Singhal S., 1999, Networked Virtual Environments
   SMIT G, 1996, P EUR
   Soriano E, 2007, FIFTH ANNUAL IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS, PROCEEDINGS, P272, DOI 10.1109/PERCOM.2007.31
   Steiner J.G., 1988, Proceedings of USENIX, P191
   SUNG WL, 2008, P NOSSDAV
   TELER E, 2001, STREAMING COMPLEX 3D, V20
   Wong PW, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P455, DOI 10.1109/ICIP.1998.723526
   Wu HT, 2006, 2006 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, (WI 2006 MAIN CONFERENCE PROCEEDINGS), P940, DOI 10.1109/WI.2006.140
NR 40
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2009
VL 45
IS 1-3
SI SI
BP 369
EP 384
DI 10.1007/s11042-009-0294-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 490VE
UT WOS:000269534900016
DA 2024-07-18
ER

PT J
AU Chen, JR
   Sun, SW
   Lu, CS
   Chang, PC
AF Chen, Jian-Ru
   Sun, Shih-Wei
   Lu, Chun-Shien
   Chang, Pao-Chi
TI Video JET: packet loss-resilient video joint encryption and transmission
   based on media-hash-embedded residual data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE (Selective) Encryption; Embedding; Error concealment; Error resilience;
   Media hashing; Motion estimation/compensation; Packet loss
ID ERROR CONCEALMENT; IMAGE AUTHENTICATION; COMPRESSION; RECOVERY; SCHEME
AB Media encryption technologies actively play the first line of defense in securing the access of multimedia data. Traditional cryptographic encryption can achieve provable security but is unfortunately sensitive to a single bit error, which will cause an unreliable packet to be dropped creating packet loss. In order to achieve robust media encryption, the requirement of error resilience can be achieved with error-resilient media transmission. This study proposes a video joint encryption and transmission (video JET) scheme by exploiting media hash-embedded residual data to achieve motion estimation and compensation for recovering lost packets, while maintaining format compliance and cryptographic provable security. Interestingly, since video block hash preserves the condensed content to facilitate search of similar blocks, motion estimation is implicitly performed through robust media hash matching - which is the unique characteristic of our method. We analyze and compare the performance of resilience to (bursty) packet loss between the proposed method and forward error correction (FEC), which has been extensively employed to protect video packets over error-prone networks. The feasibility of our packet loss-resilient video JET approach is further demonstrated through experimental results.
C1 [Chen, Jian-Ru; Sun, Shih-Wei; Lu, Chun-Shien] Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan.
   [Chang, Pao-Chi] Natl Cent Univ, Dept Commun Engn, Chungli 320, Taiwan.
C3 Academia Sinica - Taiwan; National Central University
RP Lu, CS (corresponding author), Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan.
EM lcs@iis.sinica.edu.tw
OI Sun, Shih-Wei/0000-0003-2761-7484
CR Aaron A, 2004, IEEE IMAGE PROC, P3097
   AYANOGLU E, 1996, ACM BALTZER MOBILE N, V1, P245
   Changgui Shi, 1998, Proceedings ACM Multimedia 98, P81
   Chen MH, 2005, IEEE T MULTIMEDIA, V7, P201, DOI 10.1109/TMM.2005.843367
   Fridrich J, 2000, PROC SPIE, V3971, P286, DOI 10.1117/12.384982
   *IEEE, 2004, IEEE INT C MULT EXP
   *IEEE, 2002, IEEE INT WORKSH MULT
   *ITU T, 2003, 264ISOIEC ITU T
   KANG LW, 2006, P IEEE INT C IM PROC
   KANG LW, 2006, P IEEE INT WORKSH MU
   LEE M, 2003, P ACS C RES PRACT IN, V22, P59
   Li BT, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P597
   LIANG YJ, 2003, P IEEE INT C AC SPEE
   Lin CY, 2001, P SOC PHOTO-OPT INS, V4518, P267, DOI 10.1117/12.448212
   Lin CY, 2001, IEEE T CIRC SYST VID, V11, P153, DOI 10.1109/76.905982
   Lu CS, 2005, MULTIMEDIA SYST, V11, P159, DOI 10.1007/s00530-005-0199-y
   Lu CS, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P316
   Lu CS, 2003, IEEE T MULTIMEDIA, V5, P161, DOI 10.1109/TMM.2003.811621
   Moccagatta I, 2000, IEEE J SEL AREA COMM, V18, P899, DOI 10.1109/49.848245
   Ortega A, 1998, IEEE SIGNAL PROC MAG, V15, P23, DOI 10.1109/79.733495
   Pongpadpinit W, 2006, IEE P-VIS IMAGE SIGN, V153, P63, DOI 10.1049/ip-vis:20045225
   Puri R, 2001, SIGNAL PROCESS-IMAGE, V16, P745, DOI 10.1016/S0923-5965(01)00005-4
   Roh KC, 2002, SIGNAL PROCESS-IMAGE, V17, P573, DOI 10.1016/S0923-5965(02)00045-0
   Sehgal A, 2004, IEEE T MULTIMEDIA, V6, P249, DOI 10.1109/TMM.2003.822995
   Shanableh T, 2003, IEEE T MULTIMEDIA, V5, P257, DOI 10.1109/TMM.2003.811624
   Shirani S, 2000, IEEE J SEL AREA COMM, V18, P1122, DOI 10.1109/49.848261
   SONG J, 2001, IEEE T MULTIMEDIA, V3, P415
   SUN SW, 2006, P IS T SPIE VISUAL C, V6077, P452
   Tosun A. S., 2001, P ACM INT MULT C EXH, P302
   Tsekeridou S, 2000, IEEE T CIRC SYST VID, V10, P646, DOI 10.1109/76.845010
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wen JT, 2002, IEEE T CIRC SYST VID, V12, P545, DOI 10.1109/TCSVT.2002.800321
   Xu XW, 2004, PROC SPIE, V5306, P725, DOI 10.1117/12.527514
   Yin P, 2002, P SOC PHOTO-OPT INS, V4671, P103, DOI 10.1117/12.453035
   Zeng WJ, 2004, IEEE IMAGE PROC, P565
   Zeng WJ, 2003, IEEE T MULTIMEDIA, V5, P118, DOI 10.1109/TMM.2003.808817
   Zhu BB, 2005, IEEE T MULTIMEDIA, V7, P222, DOI 10.1109/TMM.2005.843340
   Ziviani A, 2005, MULTIMED TOOLS APPL, V26, P59, DOI 10.1007/s11042-005-6849-4
NR 38
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2009
VL 44
IS 2
BP 249
EP 278
DI 10.1007/s11042-009-0295-7
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 464ED
UT WOS:000267487100005
DA 2024-07-18
ER

PT J
AU Farhad, SM
   Akbar, MM
   Kabir, MH
AF Farhad, S. M.
   Akbar, Md. Mostofa
   Kabir, Md. Humayun
TI Multicast video-on-demand service in an enterprise network with
   client-assisted patching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic multicast; Video-on-demand; Batching; Patching
AB Multicast Video-on-Demand (VoD) systems are scalable and cheap-to-operate. In such systems, a single stream is shared by a batch of common user requests. In this research, we propose multicast communication technique in an Enterprise Network where multimedia data are stored in distributed servers. We consider a novel patching scheme called Client-Assisted Patching where clients' buffer of a multicast group can be used to patch the missing portion of the clients who will request the same movie shortly. This scheme significantly reduces the server load without requiring larger client cache space than conventional patching schemes. Clients can join an existing multicast session without waiting for the next available server stream which reduces service latency. Moreover, the system is more scalable and cost effective than similar existing systems. Our simulation experiment confirms all these claims.
C1 [Farhad, S. M.; Akbar, Md. Mostofa; Kabir, Md. Humayun] Bangladesh Univ Engn & Technol, Dept Comp Sci & Engn, Dhaka, Bangladesh.
C3 Bangladesh University of Engineering & Technology (BUET)
RP Farhad, SM (corresponding author), Bangladesh Univ Engn & Technol, Dept Comp Sci & Engn, Dhaka, Bangladesh.
EM smfarhad@cse.buet.ac.bd; mostofa@cse.buet.ac.bd; mhkabir@cse.buet.ac.bd
CR Almeroth KC, 1996, IEEE J SEL AREA COMM, V14, P1110, DOI 10.1109/49.508282
   BAGRODIA R, 1997, PARSEC PARALLEL SIMU
   Boggia G, 2005, IEEE T MULTIMEDIA, V7, P920, DOI 10.1109/TMM.2005.854383
   Cai Y, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P211
   Carter SW, 1997, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATIONS AND NETWORKS, PROCEEDINGS, P200, DOI 10.1109/ICCCN.1997.623313
   Cormen T.H., 1990, Introduction to Algorithms
   DAN A, 1994, ACM C MULT OCT, P391
   Gao LX, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P117, DOI 10.1109/MMCS.1999.778179
   Hua KA, 2005, MULTIMED TOOLS APPL, V27, P367, DOI 10.1007/s11042-005-3819-9
   Hua KA, 1997, ACM SIGCOMM
   Islam M, 2005, IEEE PACIF, P157
   Ma HD, 2005, MULTIMED TOOLS APPL, V26, P101, DOI 10.1007/s11042-005-6851-x
   Ma HD, 2002, ACM SIGCOMM COMP COM, V32, P31, DOI 10.1145/510726.510729
   Ma HD, 2001, LECT NOTES COMPUT SC, V2195, P708
   Sarhan NJ, 2003, PROC ANNU SIMUL SYMP, P183, DOI 10.1109/SIMSYM.2003.1192812
   Sen S, 1999, INFOCOM 99, V3, P1310
   Tanenbaum A. S., 2003, Computer networks
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 33
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2009
VL 43
IS 1
BP 63
EP 90
DI 10.1007/s11042-008-0257-5
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 425HF
UT WOS:000264626900004
DA 2024-07-18
ER

PT J
AU Liu, DZ
   Hua, K
   Yu, N
AF Liu, Danzhou
   Hua, Kien A.
   Yu, Ning
TI Efficiently support concurrent queries in multiuser CBIR systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval; Relevance feedback; Target search;
   Category search; Index structures
ID IMAGE RETRIEVAL; RELEVANCE FEEDBACK; PERFORMANCE
AB Various techniques have been developed for different query types in content-based image retrieval systems such as sampling queries, constrained sampling queries, multiple constrained sampling queries, k-NN queries, constrained k-NN queries, and multiple localized k-NN queries. In this paper, we propose a generalized query model suitable for expressing queries of different types, and investigate efficient processing techniques for this new framework. We exploit sequential access and data sharing by developing new storage and query processing techniques to leverage inter-query concurrency. Our experimental results, based on the Corel dataset, indicate that the proposed optimization can significantly reduce average response time in a multiuser environment, and achieve better retrieval precision and recall compared to two recent techniques.
C1 [Liu, Danzhou; Hua, Kien A.; Yu, Ning] Univ Cent Florida, Sch Elect Engn & Comp Sci, Orlando, FL 32816 USA.
C3 State University System of Florida; University of Central Florida
RP Liu, DZ (corresponding author), Univ Cent Florida, Sch Elect Engn & Comp Sci, Orlando, FL 32816 USA.
EM dzliu@cs.ucf.edu; kienhua@cs.ucf.edu; nyu@cs.ucf.edu
CR [Anonymous], 2003, PROC ACM SPECIAL INT, DOI [10.1145/872757.872829, DOI 10.1145/872757.872829]
   BAEZAYATES RA, 2004, CIVR, P189
   BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93605.98741
   Berretti S, 2004, MULTIMED TOOLS APPL, V24, P215, DOI 10.1023/B:MTAP.0000039388.63801.67
   Böhm C, 2001, ACM COMPUT SURV, V33, P322, DOI 10.1145/502807.502809
   Cai Y, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MOBILE DATA MANAGEMENT, P27
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Chakrabarti K, 2004, IEEE T KNOWL DATA EN, V16, P256, DOI 10.1109/TKDE.2004.1269602
   Chen J., 2000, SIGMOD 00, P379, DOI DOI 10.1145/342009.335432
   Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596
   Flicher, 1995, IEEE COMPUT, V28, P23
   French JC, 2004, LECT NOTES COMPUT SC, V3115, P252
   Gevers T., 2004, EMERGING TOPICS COMP
   Hsu W, 2000, MULTIMED TOOLS APPL, V12, P59, DOI 10.1023/A:1009692213403
   HUA KA, 2006, P INT C DAT ENG ICDE
   Huijsmans DP, 2005, IEEE T PATTERN ANAL, V27, P245, DOI 10.1109/TPAMI.2005.30
   Ishikawa Y., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P218
   LIU D, 2007, P INT C DATA ENG ICD
   Liu DZ, 2006, LECT NOTES COMPUT SC, V3896, P700
   Ortega-Binderberger M, 2004, MULTIMEDIA SYST, V9, P535, DOI 10.1007/s00530-003-0126-z
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Sagan H., 1994, SPACE FILLING CURVES
   SELLIS TK, 1988, ACM T DATABASE SYST, V13, P23, DOI 10.1145/42201.42203
   Si L, 2006, MULTIMEDIA SYST, V12, P34, DOI 10.1007/s00530-006-0033-1
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Torres R.S., 2005, P ACM INT C INFORM K, P335
   Vu K., 2006, P ACM SIGMOD INT C M, P527, DOI DOI 10.1145/1142473.1142532
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wang XJ, 2006, MULTIMEDIA SYST, V11, P340, DOI 10.1007/s00530-006-0013-5
   Xiong W., 2005, P ACM INT C MULTIMED, P1023
NR 31
TC 0
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2009
VL 42
IS 3
BP 273
EP 293
DI 10.1007/s11042-008-0244-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 423HN
UT WOS:000264487500001
DA 2024-07-18
ER

PT J
AU Sousa Santos, B
   Dias, P
   Pimentel, A
   Baggerman, JW
   Ferreira, C
   Silva, S
   Madeira, J
AF Sousa Santos, Beatriz
   Dias, Paulo
   Pimentel, Angela
   Baggerman, Jan-Willem
   Ferreira, Carlos
   Silva, Samuel
   Madeira, Joaquim
TI Head-mounted display versus desktop for 3D navigation in virtual
   reality: a user study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality (VR); Virtual environments (VE); Headmounted display
   (HMD); User study; Navigation
ID CENTERED DESIGN; ENVIRONMENTS; ORIENTATION
AB Virtual Reality (VR) has been constantly evolving since its early days, and is now a fundamental technology in different application areas. User evaluation is a crucial step in the design and development of VR systems that do respond to users' needs, as well as for identifying applications that indeed gain from the use of such technology. Yet, there is not much work reported concerning usability evaluation and validation of VR systems, when compared with the traditional desktop setup. The paper presents a user study performed, as a first step, for the evaluation of a low-cost VR system using a Head-Mounted Display (HMD). That system was compared to a traditional desktop setup through an experiment that assessed user performance, when carrying out navigation tasks in a game scenario for a short period. The results show that, although users were generally satisfied with the VR system, and found the HMD interaction intuitive and natural, most performed better with the desktop setup.
C1 [Sousa Santos, Beatriz; Dias, Paulo; Silva, Samuel; Madeira, Joaquim] Univ Aveiro, Dept Elect Telecomun & Informat, P-3800 Aveiro, Portugal.
   [Sousa Santos, Beatriz; Dias, Paulo; Silva, Samuel; Madeira, Joaquim] IEETA, Aveiro, Portugal.
   [Pimentel, Angela; Ferreira, Carlos] Univ Aveiro, Dept Econ Gestao & Engn Ind, P-3800 Aveiro, Portugal.
   [Baggerman, Jan-Willem] Delft Univ Technol, Fac EEMCS, Delft, Netherlands.
   [Ferreira, Carlos] Univ Lisbon, CIO, P-1699 Lisbon, Portugal.
C3 Universidade de Aveiro; Universidade de Aveiro; Universidade de Aveiro;
   Delft University of Technology; Universidade de Lisboa
RP Sousa Santos, B (corresponding author), Univ Aveiro, Dept Elect Telecomun & Informat, P-3800 Aveiro, Portugal.
EM bss@ua.pt
RI FCUL, CIO/D-3663-2015; Dias, Paulo PMD/G-3681-2013; Madeira,
   Joaquim/A-6467-2012
OI Dias, Paulo PMD/0000-0002-3754-2749; Madeira,
   Joaquim/0000-0003-1740-1604; Ferreira, Carlos/0000-0002-2799-643X;
   Silva, Samuel/0000-0002-9858-8249; Sousa Santos,
   Beatriz/0000-0002-2219-2731
CR [Anonymous], 2006, Proceedings of the 3rd Symposium on Applied Perception in Graphics and Visualization, APGV'06, DOI 10.1145/1140491.1140495
   Ardito C, 2007, MULTIMED TOOLS APPL, V33, P201, DOI 10.1007/s11042-006-0060-0
   BOWMAN D, 2001, TR0117 VIRG TECH
   Bowman D. A., 2002, Proceedings of the Human Factors and Ergonomics Society 46th Annual Meeting, P2134
   Bowman D.A., 2005, 3D User Interfaces: Theory and Practice
   Bowman DA, 1999, PRESENCE-TELEOP VIRT, V8, P618, DOI 10.1162/105474699566521
   Bowman DA, 2001, PRESENCE-TELEOP VIRT, V10, P96, DOI 10.1162/105474601750182342
   Brooks FP, 1999, IEEE COMPUT GRAPH, V19, P16, DOI 10.1109/38.799723
   Demiralp Ç, 2006, IEEE T VIS COMPUT GR, V12, P323, DOI 10.1109/TVCG.2006.42
   Dix A., 2004, Human-computer interaction
   FIELD M, 2004, INTERACTION, V11, P11, DOI DOI 10.1145/1029036.1029044
   Gabbard JL, 1999, IEEE COMPUT GRAPH, V19, P51, DOI 10.1109/38.799740
   GABBARD JL, 1998, THESIS VIRGINIA POLY
   Griffiths G, 2006, INT J HUM-COMPUT ST, V64, P240, DOI 10.1016/j.ijhcs.2005.08.008
   Gruchalla K, 2004, P IEEE VIRT REAL ANN, P157, DOI 10.1109/VR.2004.1310069
   Hettmansperger T.P., 1998, KENDALLS LIB STAT, V5
   Hix D, 1999, P IEEE VIRT REAL ANN, P96, DOI 10.1109/VR.1999.756939
   Hoaglin D. C., 1983, Understanding Robust and Exploratory Data Analysis
   ISRAEL J, 2007, MMI INTERAKT, V12, P1
   Karaseltanidis I, 2006, INT J HUM-COMPUT ST, V64, P251, DOI 10.1016/j.ijhcs.2005.08.013
   Mizell D.W., 2002, COMP IMMERSIVE VIRTU
   NARAYAN M, 2005, S VIRTUAL REAL SOFTW, V5, P78, DOI DOI 10.1145/1101616.1101632
   Parush A, 2004, INT J HUM-COMPUT ST, V61, P375, DOI 10.1016/j.ijhcs.2003.12.018
   Patel H, 2006, INT J HUM-COMPUT ST, V64, P207, DOI 10.1016/j.ijhcs.2005.08.010
   Pausch R., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P13, DOI 10.1145/258734.258744
   Polys N.F., 2005, Proceedings of ACM Symposium on Virtual Reality Software and Technology (VRST), P46, DOI 10.1145/1101616.1101626
   Prabhat, 2008, IEEE T VIS COMPUT GR, V14, P551, DOI 10.1109/TVCG.2007.70433
   Qi W., 2006, Proc. Symp. on Applied Perception in Graphics and Visualization (APGV), P51, DOI DOI 10.1145/1140491.1140502
   Raja D., 2004, P IMM PROJ TECHN WOR
   Robertson G., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P11, DOI 10.1145/263407.263409
   Robinson G, 2007, COMPUT AIDED DESIGN, V39, P245, DOI 10.1016/j.cad.2006.12.001
   Ruddle RA, 1999, PRESENCE-TELEOP VIRT, V8, P157, DOI 10.1162/105474699566143
   Ruddle RA, 2004, INT J HUM-COMPUT ST, V60, P299, DOI 10.1016/j.ijhcs.2003.10.001
   Sebok A., 2004, Virtual Reality, V8, P26, DOI 10.1007/s10055-004-0133-1
   Smith RC, 2005, P IEEE VIRT REAL ANN, P301, DOI 10.1109/VR.2005.1492806
   Steed A, 2005, PRESENCE-TELEOP VIRT, V14, P511, DOI 10.1162/105474605774918750
   USOH M, 1999, P SIGGRAPH, V99, P359
   Waller D, 1998, PRESENCE-TELEOP VIRT, V7, P129, DOI 10.1162/105474698565631
   Wilson JR, 2006, INT J HUM-COMPUT ST, V64, P158, DOI 10.1016/j.ijhcs.2005.08.007
   Wilson JR, 2006, INT J HUM-COMPUT ST, V64, P157, DOI 10.1016/j.ijhcs.2005.08.002
   Witmer BG, 1996, INT J HUM-COMPUT ST, V45, P413, DOI 10.1006/ijhc.1996.0060
   STATISTICA 6 0
NR 42
TC 160
Z9 188
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2009
VL 41
IS 1
BP 161
EP 181
DI 10.1007/s11042-008-0223-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 387LJ
UT WOS:000261953400007
DA 2024-07-18
ER

PT J
AU Berrani, SA
   Garcia, C
AF Berrani, Sid-Ahmed
   Garcia, Christophe
TI Robust detection of outliers for projection-based face recognition
   methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 2nd International Workshop on Computer Vision Meets Databases
CY JUN 17, 2005
CL Baltimore, MD
DE high-dimensional data analysis; outliers face recognition;
   dimensionality curse
ID EIGENFACES; ALGORITHMS
AB In this paper, the impact of outliers on the performance of high-dimensional data analysis methods is studied in the context of face recognition. Most of the existing face recognition methods are based on PCA-like methods: faces are projected into a lower dimensional space in which similarity between faces is supposed to be more easily evaluated. These methods are, however, very sensitive to the quality of the face images used in the training and in the recognition phases. Their performance significantly drops when face images are not well centered or taken under variable illumination conditions. In this paper, we study this phenomenon for two face recognition methods, namely PCA and LDA2D, and we propose a filtering process that allows the automatic selection of noisy face images which are responsible for the performance degradation. This process uses two techniques. The first one is based on the recently proposed robust high-dimensional data analysis method called RobPCA. It is specific to the case of recognition from video sequences. The second technique is based on a novel and effective face classification technique. It allows isolating still face images that are not very precisely cropped, not well-centered or in a non-frontal pose. Experiments show that this filtering process significantly improves recognition rates by 10 to 30%.
C1 [Berrani, Sid-Ahmed; Garcia, Christophe] Orange France Telecom Div R&D TECH IRIS, F-35512 Cesson Sevigne, France.
C3 Orange SA
RP Berrani, SA (corresponding author), Orange France Telecom Div R&D TECH IRIS, 4 Rue Clos Courtel,BP 91226, F-35512 Cesson Sevigne, France.
EM sidahmed.berrani@orange-ftgroup.com;
   christophe.garcia@orange-ftgroup.com
OI Garcia, christophe/0000-0001-7997-9837
CR AGGARWAL CC, 2001, P ACM SIGM INT C MAN
   AGGRAWAL CC, 2001, S PRINC DAT SYST SAN
   [Anonymous], 1961, Adaptive control processes: a guided tour, DOI DOI 10.1515/9781400874668
   [Anonymous], P 5 INT C AUT FAC GE
   Barnett V., 1984, OUTLIERS STAT DATA
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   BERRANI SA, 2003, P 12 ACM INT C INF K
   BERRANI SA, 2005, P IEEE INT C VID SIG
   BERRANI SA, 2005, P INT WORKSH COMP VI
   Blackburn DuaneM., 2001, FACE RECOGNITION VEN
   Garcia C, 2004, IEEE T PATTERN ANAL, V26, P1408, DOI 10.1109/TPAMI.2004.97
   Hjelmås E, 2001, COMPUT VIS IMAGE UND, V83, P236, DOI 10.1006/cviu.2001.0921
   Hodge VJ, 2004, ARTIF INTELL REV, V22, P85, DOI 10.1023/B:AIRE.0000045502.10941.a9
   Hubert M, 2005, TECHNOMETRICS, V47, P64, DOI 10.1198/004017004000000563
   JOHN GH, 1995, P 1 INT C KNOWL DISC
   Lin CS, 2003, PATTERN RECOGN LETT, V24, P1857, DOI 10.1016/S0167-8655(03)00009-6
   Messer K., 1999, 2 INT C AUD VID BAS
   PENTLAND A, 1994, P 13 IEEE C COMP VIS
   PHILLIPS JP, 2003, 6965 NIST IR
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Rousseeuw PJ, 1999, TECHNOMETRICS, V41, P212, DOI 10.2307/1270566
   SEO K, 2004, P AS C COMP VIS JEJ
   SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Verleysen M, 2003, NATO SC S SS III C S, V186, P141
   VERLEYSEN M, 2003, P 7 INT WORK C ART N
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Visani M., 2004, P INT C COMP VIS GRA
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   YAO P, 2001, P 12 SCAND C IM AN B
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 33
TC 5
Z9 6
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2008
VL 38
IS 2
BP 271
EP 291
DI 10.1007/s11042-007-0176-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 301NV
UT WOS:000255903800006
DA 2024-07-18
ER

PT J
AU Jung, S
   Chang, A
   Gerla, M
AF Jung, Sewook
   Chang, Alexander
   Gerla, Mario
TI Peer to peer video streaming in Bluetooth overlays
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bluetooth; overlay; peer to peer; video streaming
ID MULTIHOP SCATTERNET FORMATION; NETWORKS
AB As Bluetooth is available in most personal and portable terminals (eg, cellular phone, PDA, videocamera, laptop, etc) Peer-to-peer video streaming through Bluetooth networks is now a reality. Camera equipped Bluetooth phones capture video and broadcast it to other Bluetooth devices and to the infrastructure. Tra ditionally, large scale Bluetooth networks were designed using scatternet concepts. However, many Bluetooth devices do not support Scatternet connections and, even if they support it, they provide only very limited features suitable mostly for static environments. In high mobility situations, a traditional Scatternet design is not useful because of frequent disconnections and reconnections. To overcome these problems, we propose overlaid Bluetooth Piconets (OBP) and simplified overlaid Bluetooth Piconets (SOBP) that interconnect Piconets forming virtual Scatternets. In OBP, every Piconet dynamically reconfigures to collect metadata from neighboring Piconets. If metadata shows the existence of useful data to transfer, an inter-Piconet connection is made to carry out the transfer. SOBP can be used instead of OBP once neighbor Piconets have already discovered each other. In this paper, we compare via analysis and simulation the throughput and efficiency of OBP, SOBP and Scatternet for video applications. We demonstrate the feasibility of video over OBP and SOBP for a representative application.
C1 [Jung, Sewook; Chang, Alexander; Gerla, Mario] Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90024 USA.
C3 University of California System; University of California Los Angeles
RP Jung, S (corresponding author), Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90024 USA.
EM sewookj@cs.ucla.edu; acmchang@cs.ucla.edu; gerla@cs.ucla.edu
CR Basagni S, 2002, IEEE VTS VEH TECHNOL, P424, DOI 10.1109/VTC.2002.1002750
   *BLUET SIG, 2004, BT BLUET SPEC V2 0
   Camp Tracy., 2002, IEEE MOBICOM
   CHEN LJ, 2004, ENHANCING BLUETOOTH
   *COMVU, 2007, LIV MOB VID BROADC U
   FALLS K, 2003, ACM SIGCOMM NEW YORK
   HUI P, 2005, ACM SIGCOMM NEW YORK
   *ISI, 2004, NETW SIM NS 2
   JUANG P, 2002, ASPLOS SAN JOS 5 9 O
   JUNG S, 2006, IEEE WIR COMM NETW C
   JUNG S, 2006, 2 INT WORKSH WIR NET
   Jung Sewook, 2005, P 2 ANN INT C MOB UB
   Kallo Casaba Kiss, 2005, IEEE INT C COMM ICC
   Law C, 2003, MOBILE NETW APPL, V8, P485, DOI 10.1023/A:1025133710426
   *MPLAYER, 2007, MPLAYER MOV PLAY
   Nandan  A., 2005, P IEEE IFIP INT C WI
   Petrioli C, 2004, MOBILE NETW APPL, V9, P33, DOI 10.1023/A:1027317722864
   SHAH R, 2003, IEEE SNPA WORKSH IEE
   *SOPCAST, 2006, FREE INT IPTV
   STOJMENOBIC I, 2002, P 16 INT PAR DISTR P
   *U CINC, 2004, UCBT SIM
NR 21
TC 5
Z9 6
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2008
VL 37
IS 3
BP 263
EP 292
DI 10.1007/s11042-007-0159-y
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 274BI
UT WOS:000253976400002
DA 2024-07-18
ER

PT J
AU Lekakos, G
   Caravelas, P
AF Lekakos, George
   Caravelas, Petros
TI A hybrid approach for movie recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE recommender systems; collaborative filtering; content-based filtering;
   hybrid methods
AB Collaborative and content-based filtering are the major methods in recommender systems that predict new items that users would find interesting. Each method has advantages and shortcomings of its own and is best applied in specific situations. Hybrid approaches use elements of both methods to improve performance and overcome shortcomings. In this paper, we propose a hybrid approach based on content-based and collaborative filtering, implemented in MoRe, a movie recommendation system. We also provide empirical comparison of the hybrid approach to the base methods of collaborative and content-based filtering and draw useful conclusions upon their performance.
C1 [Lekakos, George; Caravelas, Petros] Athens Univ Econ & Business, Dept Management Sci & Technol, ELTRUN eBusiness Ctr, Athens 11362, Greece.
C3 Athens University of Economics & Business
RP Lekakos, G (corresponding author), Univ Cyprus, Dept Comp Sci, Nicosia, Cyprus.
EM glekakos@aueb.gr; pcaravel@aueb.gr
RI Lekakos, George/AAK-7008-2020
CR Alspector J, 1997, USER MODEL USER-ADAP, V7, P279, DOI 10.1023/A:1008286413827
   Balabanovic M., 1997, Proceedings of the First International Conference on Autonomous Agents, P378, DOI 10.1145/267658.267744
   Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124
   Basu C, 1998, FIFTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-98) AND TENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICAL INTELLIGENCE (IAAI-98) - PROCEEDINGS, P714
   Billsus D, 2000, USER MODEL USER-ADAP, V10, P147, DOI 10.1023/A:1026501525781
   Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564
   CLAYPOOL M, 1999, P ACM SIGIR WORKS RE
   Cosley Dan, 2003, P SIGCHI C HUM FACT, P585
   Goldberg K, 2001, INFORM RETRIEVAL, V4, P133, DOI 10.1023/A:1011419012209
   Gutta S, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P1121
   Herlocker J, 2002, INFORM RETRIEVAL, V5, P287, DOI 10.1023/A:1020443909834
   Herlocker JL, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P230, DOI 10.1145/312624.312682
   Karypis G., 2001, Proceedings of the 2001 ACM CIKM. Tenth International Conference on Information and Knowledge Management, P247, DOI 10.1145/502585.502627
   Kobsa A., 2000, P ASS ADV ART INT AA, P241
   LEKAKOS G, 2004, J COMPUT MEDIAT COMM, V9
   Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344
   MILLER B, 2003, P INT C INT US INT
   Mooney R.J., 2000, Proceedings of the fifth ACM conference on Digital libraries', DL'00, P195
   O'Sullivan D, 2004, USER MODEL USER-ADAP, V14, P5, DOI 10.1023/B:USER.0000010131.72217.12
   Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943
   Pazzani MJ, 1999, ARTIF INTELL REV, V13, P393, DOI 10.1023/A:1006544522159
   RASHID A, 2002, P P INT C INT US INT
   Resnick P., 1994, P ACM C COMP SUPP CO, P175
   Shardanand U., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P210, DOI 10.1145/223904.223931
   Smyth B, 2000, COMMUN ACM, V43, P107, DOI 10.1145/345124.345161
   Tran T., 2000, Knowledge-Based Electronic Markets. Papers from the AAAI Workshop (Technical Report WS-00-04), P78
   Yu ZW, 2004, IEEE T CONSUM ELECTR, V50, P393, DOI 10.1109/TCE.2004.1277889
NR 27
TC 88
Z9 102
U1 4
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2008
VL 36
IS 1-2
BP 55
EP 70
DI 10.1007/s11042-006-0082-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 241LT
UT WOS:000251658600004
DA 2024-07-18
ER

PT J
AU Liew, PY
   Armand, MA
AF Liew, P. Y.
   Armand, M. A.
TI Inaudible watermarking via phase manipulation of random frequencies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE audio watermarking; error-correcting codes; phase coding;
   synchronization
AB Watermarking technology can be beneficial in digital rights protection. However, the industry's acceptance of the technology has been lukewarm as experts have been able to hear audible artifacts introduced during the watermarking process. In this paper, we present what we believe to be a truly inaudible solution to this problem. Our proposed watermarking technique embeds the watermark signal in the phase of an audio signal, with secrecy as to which frequency components carry the watermark bits, achieved via a pseudorandom generator. Inaudibility is realized by exploiting the human auditory system's insensitivity to absolute phase. Further, our algorithm includes a novel mechanism for segmenting an audio signal into variable frame-lengths to provide robustness against de-synchronization attacks such as jitter and time-scaling. It uses a short-time Fourier transform to first characterize local changes in the frequency content of an audio signal, from which, pairs of frequencies satisfying specified conditions are identified, to mark the start and end of a segment. The insertion of synchronization marks adds further robustness against such attacks. Robustness against other common attacks may be further enhanced through the use of concatenated error-control codes which enable the correction of random and/or burst errors, which may be introduced during an attack.
C1 Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore.
C3 National University of Singapore
RP Liew, PY (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, 4 Engn Dr 3, Singapore 117576, Singapore.
EM engp1799@nus.edu.sg; eleama@nus.edu.sg
CR Arnold M, 2002, SECOND INTERNATIONAL CONFERENCE ON WEB DELIVERING OF MUSIC, PROCEEDINGS, P161, DOI 10.1109/WDM.2002.1176207
   BYEONGSEOB K, 2002, P IEEE INT C AC SPEE, V2, P2001
   Craver SA, 2001, PROCEEDINGS OF THE 2001 IEEE WORKSHOP ON THE APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS, P223, DOI 10.1109/ASPAA.2001.969583
   ELEN R, 1999, DVD AUDIO WATERMARKI
   GORDY JD, 2000, P 43 MIDW S CIRC SYS
   Horvatic P, 2000, INT FED INFO PROC, V47, P181
   Kirovski D, 2001, INT CONF ACOUST SPEE, P1345, DOI 10.1109/ICASSP.2001.941177
   KIROVSKI D, 2002, AUDIO WATERMARK ROBU
   KIROVSKI D, 2002, P IEEE INT S INF THE, P446
   Kirovski Darko., 2001, LECT NOTES COMPUTER, V2137, P354
   Kuo S, 2002, INT CONF ACOUST SPEE, P1753
   Mansour MF, 2001, INT CONF ACOUST SPEE, P1353, DOI 10.1109/ICASSP.2001.941179
   PAN D, 1995, IEEE MULTIMEDIA, V2, P60, DOI 10.1109/93.388209
   POWELL D, 2001, WHAT IS DVD AUDO DVD
   ROCHLIN SR, 2000, DVD AUDIO INTERNET
   WU M, 2001, P IEEE INT C AC SPEE, V3, P1369
   XU C, 2000, CONTENT BASED DIGITA
NR 17
TC 9
Z9 9
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2007
VL 35
IS 3
BP 357
EP 377
DI 10.1007/s11042-007-0133-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 228XS
UT WOS:000250766500006
DA 2024-07-18
ER

PT J
AU Meire, AP
   Borges, MRS
   de Araujo, RM
AF Meire, Alexandre Pereira
   Borges, Marcos R. S.
   de Araujo, Renata Mendes
TI Supporting multiple viewpoints in collaborative graphical editing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 9th International Workshop on Groupware
CY SEP 28-OCT 02, 2003
CL AUTRANS, FRANCE
SP CNRS, Inst Informat & Math Appl Grenoble, Conseil Reg Rhone Alpes, Mairie Grenoble, Conseil Gen Savoie, Inst Natl Polytech Grenoble, Univ Savoie, Univ Joseph Fourier, CINVESTAV IPAN, CICESE
DE collaborative editors; awareness mechanisms; viewpoint support; mask
   metaphor
ID AWARENESS; FRAMEWORK; GROUPWARE
AB This work presents a proposal for a collaborative editor, CO2DE, that deals with the representation and awareness of different viewpoints of participants over an artifact. The underlying CO2DE concept is the mask metaphor. This concept uses a versioning mechanism for collaborative graphic editing in which changes on the artifact can be created independently from the overall work, and in which different viewpoints can be identified and discussed. Studies conducted with the tool demonstrate that CO2DE allows the use of different editing strategies as a resource to provide participants with awareness of the discussion flow and of different viewpoints concerning the artifacts.
C1 Univ Fed Rio de Janeiro, NCE&IM, Grad Program Informat, Rio De Janeiro, Brazil.
   Univ Fed Estado Rio de Janeiro, UNIRIO, Dept Appl Informat, Rio De Janeiro, Brazil.
C3 Universidade Federal do Rio de Janeiro; Universidade Federal do Estado
   do Rio de Janeiro
RP Meire, AP (corresponding author), Univ Fed Rio de Janeiro, NCE&IM, Grad Program Informat, Rio De Janeiro, Brazil.
EM apmeire@gmail.com; mborges@nce.ufrj.br; renata.araujo@uniriotec.br
RI de Araujo, Renata Mendes/M-1155-2013; Borges, Marcos/P-5773-2019; de
   Araujo, Renata Mendes/X-6380-2019
OI de Araujo, Renata Mendes/0000-0002-8674-1728; Borges,
   Marcos/0000-0002-2992-3429; de Araujo, Renata Mendes/0000-0002-8674-1728
CR [Anonymous], 1992, Proceedings of the 1992 ACM Conference on Computer Supported Cooperative Work (CSCW'92), DOI DOI 10.1145/143457.143468
   APPERLEY M, 2003, P 4 AUSTR US INT C A, V18, P81
   BOGER M, 2005, POSEIDON UML USER GU
   Booch Grady, 1999, UNIFIED MODELING LAN, DOI DOI 10.1007/3-540-40011-7_10
   BORGES MRS, 2003, P 10 INT C HUM COMP, P849
   BORGES MRS, 2000, P 10 ANN WORKSH INF, P211
   *CANYON BLUE INC, 2005, HURW REP COLL UML DE
   Greenberg S, 1996, PROC GRAPH INTERF, P28
   GREENBERG S, 2000, 200066921 U CALG DEP
   Gutwin C., 1999, ACM Transactions on Computer-Human Interaction, V6, P243, DOI 10.1145/329693.329696
   HAAKE A, 1993, P C HUM FACT COMP SY, P406
   *HCI CSCW LAB, 2004, GROUPLAB
   ISHII H, 1999, TRENDS SOFTWARE, V7, P83
   Jehn KA, 2001, ACAD MANAGE J, V44, P238, DOI 10.5465/3069453
   Mangan MAS, 2002, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON CSCW IN DESIGN, P49, DOI 10.1109/CSCWD.2002.1047647
   NEUWIRTH CM, 1990, P C COMPUTER SUPPORT, P183, DOI DOI 10.1145/99332.99354
   Pinelle D, 2000, IEEE 9TH INTERNATIONAL WORKSHOPS ON ENABLING TECHNOLOGIES: INFRASTRUCTURE FOR COLLABORATIVE ENTERPRISES, PROCEEDINGS, P86, DOI 10.1109/ENABL.2000.883709
   Pino JA, 1996, INTERACT COMPUT, V8, P299, DOI 10.1016/S0953-5438(97)83775-7
   PINO JA, 2001, P 7 INT WORKSH GROUP, P26
   Rosa MGP, 2003, LECT NOTES COMPUT SC, V2806, P300
   ROSA MGP, 2004, THESIS FEDERAL U RIO
   ROSEMAN M, 1992, P C COMPUTER SUPPORT, P43
   SHIOZAWA H, 1999, P INT ACM SIGGROUP C, P71
   Tam J, 2004, LECT NOTES COMPUT SC, V3198, P67
   TAM J, 2000, 200067022 U CALG DEP
   Turner ME, 1998, ORGAN BEHAV HUM DEC, V73, P105, DOI 10.1006/obhd.1998.2756
NR 26
TC 6
Z9 8
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2007
VL 32
IS 2
BP 185
EP 208
DI 10.1007/s11042-006-0064-9
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 129ZR
UT WOS:000243769100004
DA 2024-07-18
ER

PT J
AU Yamane, Y
   Hoshiai, T
   Tsuda, H
   Ohta, M
   Katayama, K
   Ishikawa, H
AF Yamane, Yasuo
   Hoshiai, Tadashi
   Tsuda, Hiroshi
   Ohta, Manabu
   Katayama, Kaoru
   Ishikawa, Hiroshi
TI Multi-vector feature space based on pseudo-Euclidean space and oblique
   basis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 1st International Workshop on Computer Vision Meets Databases
CY JUN 13, 2004
CL Paris, FRANCE
DE similarity search; feature space; pseudo-Euclidean space; oblique basis;
   quadratic-form distance; Earth mover's distance; multi-vector feature
   space
AB The Earth Mover's Distance (EMD) and the quadratic-form distance (QFD) are representative distances used in similarity searches of images. Although the QFD greatly outperforms the EMD in speed, the EMD outperform the QFD in performance. The EMD, however, has almost no theoretical justification and requires high computation costs. We propose a feature space model we call a "multi-vector feature space based on pseudo-Euclidean space and an oblique basis (MVPO)." In MVPO, an object such as an image is represented by a vector set ( roughly speaking, a solid) and the EMD is reinterpreted as the distance between vector sets while the QFD is reinterpreted as the distance between the centroids of vector sets. Therefore MVPO gives a common geometrical view to these distances. We hypothesized that in MVPO the entity of an image is represented by a vector set ( solid) and geometrical reasoning is applicable to MVPO. Our hypothesis explains well that the EMD outperforms the QFD in performance because the centroid of a solid is the simplest approximation of it. Our hypothesis implies that the performance of the QFD should be good when solids are far apart but bad when they are close together. We conjectured that discriminability would decline - that is, dissimilar images would be judged to be similar - when the centroids of solids are very close. Our experiment supported this conjecture. And from our hypothesis we conjectured that by making an original solid simpler, we can make an approximation method that has better performance than the QFD and faster than the EMD. The results of our experiment with this method supported our conjecture and consequently our hypothesis.
C1 Fujitsu Labs Ltd, Intelligent Syst Lab, Nakahara Ku, Kawasaki, Kanagawa 2118588, Japan.
   Okayama Univ, Grad Sch Nat Sci & Technol, Okayama 7008530, Japan.
   Tokyo Metropolitan Univ, Grad Sch Engn, Tokyo 1920397, Japan.
C3 Fujitsu Ltd; Fujitsu Laboratories Ltd; Okayama University; Tokyo
   Metropolitan University
RP Yamane, Y (corresponding author), Fujitsu Labs Ltd, Intelligent Syst Lab, Nakahara Ku, 4-1-1 Kamikodanaka, Kawasaki, Kanagawa 2118588, Japan.
EM yamane.yasuo@jp.fujitsu.com; hoshiai@jp.fujitsu.com;
   htsuda@jp.fujitsu.com; ohta@suri.it.okayama-u.ac.jp;
   katayama@comp.metro-u.ac.jp; ishikawa@eei.metro-u.ac.jp
CR Castelli V., 2002, Image Databases: Search and Retrieval of Digital Imagery
   Gaede V, 1998, ACM COMPUT SURV, V30, P170, DOI 10.1145/280277.280279
   HAFNER J, 1995, IEEE T PATTERN ANAL, V17, P729, DOI 10.1109/34.391417
   JEAN JSN, 1990, P IEEE ICASSP 90, P3
   Katayama N., 1997, P ACM SIGMOD, P369
   LEE D, 1994, IEEE IMAGE PROC, P76, DOI 10.1109/ICIP.1994.413534
   Levina E, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P251, DOI 10.1109/ICCV.2001.937632
   Rubner Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P59, DOI 10.1109/ICCV.1998.710701
   Rubner Y., 2001, Perceptual metrics for image database navigation
   Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P194
NR 10
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2006
VL 31
IS 3
BP 287
EP 308
DI 10.1007/s11042-006-0045-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 119XW
UT WOS:000243048800004
DA 2024-07-18
ER

PT J
AU Assfalg, J
   Del Bimbo, A
   Pala, P
AF Assfalg, Juergen
   Del Bimbo, Alberto
   Pala, Pietro
TI Content-based retrieval of 3D models through curvature maps: a CBR
   approach exploiting media conversion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE content-based retrieval; 3D models; curvature maps; media conversion
ID IMAGE RETRIEVAL; SYSTEM
AB Multimedia digital libraries are gaining an increasing relevance, and are growing in both number and size. Moreover, advancements in acquisition and authoring technologies have also caused new media types to be added to these libraries. For instance, animations and 3D models have recently come alongside more traditional media such as text, images, audio and video. In particular, even if 3D objects were initially included in multimedia digital libraries in the form of images (i.e., views of the objects), they are now also available in the form of 3D models. These allow to overcome the inherent limitations of an image-based representation of a three-dimensional reality. In this paper we present a novel method for description and retrieval of 3D models that relies on curvature maps: after an initial pre-processing of the model, differential properties of points on the surface of the 3D object are evaluated; the model surface is then deformed into an ellipsoid, and is mapped onto a 2D image retaining curvature information of the original model. Through this media conversion from 3D model to image map, we enable application of analysis, description, and matching techniques which have been originally conceived for the image medium. In particular, the two approaches described in this paper rely on histograms for a coarse but efficient description of tiles of the curvature map, and on weighted walkthroughs for a more precise description of homogeneous regions of the map, taking into account their spatial arrangement and areas. Experimental results reveal that both techniques can be successfully applied to curvature maps. The two approaches have been compared against other solutions presented in literature, and have shown a good retrieval performance (particularly in the case of region-based description).
C1 Univ Florence, Dipartimento Sistemi & Informat, I-50139 Florence, Italy.
C3 University of Florence
RP Assfalg, J (corresponding author), Univ Florence, Dipartimento Sistemi & Informat, Via S Marta 3, I-50139 Florence, Italy.
EM assfalg@dsi.unifi.it; delbimbo@dsi.unifi.it; pala@dsi.unifi.it
OI DEL BIMBO, ALBERTO/0000-0002-1052-8322; PALA, PIETRO/0000-0001-5670-3774
CR ANKERST M., 1999, P 6 INT S SPAT DAT S
   [Anonymous], IEEE COMPUT
   [Anonymous], P IEEE INT C COMP VI
   Assfalg J, 2002, IEEE MULTIMEDIA, V9, P52, DOI 10.1109/93.998060
   Balakrishnan R, 2001, COMPUTER, V34, P37, DOI 10.1109/2.910892
   BELYAEV AG, 2000, P GEOM MOD PROC 2000, P229
   Berchtold S., 1997, PROC SIGMOD 97, P564
   Berretti S, 2001, IEEE T PATTERN ANAL, V23, P1089, DOI 10.1109/34.954600
   Brunelli R, 2001, PATTERN RECOGN, V34, P1625, DOI 10.1016/S0031-3203(00)00054-6
   CHALMERS A, 2002, IEEE COMPUT GRAPH AP, V22
   Colombo C, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P277, DOI 10.1109/TDPVT.2002.1024072
   Courtney JD, 1997, PATTERN RECOGN, V30, P607, DOI 10.1016/S0031-3203(96)00107-0
   Dagtas S, 2000, IEEE T IMAGE PROCESS, V9, P88, DOI 10.1109/83.817601
   Del Bimbo A, 1998, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES - PROCEEDINGS, P35, DOI 10.1109/IVL.1998.694485
   DELBIMBO A, 1999, VISUAL INFORMATION R
   Elad M., 2001, PROC EG MULTIMEDIA, P97, DOI DOI 10.2312/EGMM/EGMM01/107-118
   ELVINS TT, 1995, P VRML 95 1 ANN C VI
   ESHERA MA, 1984, IEEE T SYST MAN CYB, V14, P398, DOI 10.1109/TSMC.1984.6313232
   GAREY MR, 1979, COMPTUER INTRACTABIL
   GARLAND M, 1999, P EUR 99
   HUANG J, 1997, P INT C COMP VIS PAT
   Jain AK, 1996, PATTERN RECOGN, V29, P1233, DOI 10.1016/0031-3203(95)00160-3
   KOLONIAS I, 2001, P INT WORKSH CONT BA
   Kriegel H.-P., 1998, GeoInformatica, V2, P113, DOI 10.1023/A:1009760031965
   Lamdan Y., 1988, PROC 2 INT C COMPUTE, P238
   LEVOY M, 2000, P C COMP GRAPH SIGGR
   Mokhtarian F, 2001, IMAGE VISION COMPUT, V19, P271, DOI 10.1016/S0262-8856(00)00076-7
   MSITH JR, 1996, P ACM MULT 96 BOST M
   OSADA R, 1999, P SHAP MOD INT GEN
   PAGE DL, 2001, P INT C COMP VIS PAT, V1, P162
   Paquet E, 1999, IMAGE VISION COMPUT, V17, P157, DOI 10.1016/S0262-8856(98)00119-X
   Roth V, 1999, IMAGE VISION COMPUT, V17, P531, DOI 10.1016/S0262-8856(98)00144-9
   Santini S, 1999, IEEE T PATTERN ANAL, V21, P871, DOI 10.1109/34.790428
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   SNYDER JP, 1995, MAPPROJECTIONS REFER
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   TAUBIN G, 1995, 5 INT C COMP VIS ICC
   TAUBIN G., 2000, P EUR
   TAUBIN G, 1991, GEOMETRIC METHODS CO, V1570, P175
   TAUBIN G, 1995, COMPUTER GRAPHICS, V29, P351
   TSAI WH, 1979, IEEE T SYST MAN CYB, V12, P657
   van der Lee AM, 2001, NEW J PHYS, V3, P21, DOI 10.1088/1367-2630/3/1/302
   Wong KYK, 2003, IEEE T PATTERN ANAL, V25, P147, DOI 10.1109/TPAMI.2003.1177148
   Zhang HJ, 1997, PATTERN RECOGN, V30, P643, DOI 10.1016/S0031-3203(96)00109-4
NR 44
TC 9
Z9 10
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2006
VL 31
IS 1
BP 29
EP 50
DI 10.1007/s11042-006-0034-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 092QK
UT WOS:000241112200002
DA 2024-07-18
ER

PT J
AU Veltkamp, RC
AF Veltkamp, RC
TI Multimedia algorithmics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia; algorithmics; perception
AB If perceptually relevant multimedia methods with guaranteed performance are not developed soon, there is no hope that the problem of multimedia information overload is effectively solved. Research is needed to handle images, music, video, and 3D models, with methods that guarantee robustness, invariance, efficiency, etc., and are also perceptually and cognitively relevant. The invention of algorithms that provably satisfy such properties is a new field of research: multimedia algorithmics.
C1 Univ Utrecht, Inst Comp & Informat Sci, NL-3584 CH Utrecht, Netherlands.
C3 Utrecht University
RP Veltkamp, RC (corresponding author), Univ Utrecht, Inst Comp & Informat Sci, Padualaan 14, NL-3584 CH Utrecht, Netherlands.
EM Remco.Veltkamp@cs.uu.nl
CR Moret B. M. E., 2002, Data structures, near neighbor searches, and methodology: Fifth and sixth DIMACS implementation challenges. Papers related to the DIMACS challenge on dictionaries and priority queues (1995-1996) and the DIMACS challenge on near neighbor searches (1998-1999), P197
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Veltkamp R., 2002, MU SYS APPL, P47
NR 3
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2005
VL 27
IS 2
BP 187
EP 193
DI 10.1007/s11042-005-2578-y
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 961OP
UT WOS:000231672000001
DA 2024-07-18
ER

PT J
AU Cha, HJ
   Oh, JH
   Ha, R
AF Cha, HJ
   Oh, JH
   Ha, R
TI Dynamic frame dropping for bandwidth control in MPEG streaming system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MPEG streaming; bandwidth control; frame dropping; experiments
AB In a network environment where the available bandwidth changes dynamically, it is desirable for a streaming system to control the media quality in an adaptive way according to the dynamics of underlying network resource. This paper presents the implementation of a real-time MPEG filtering system which uses the concept of dynamic frame-drop. The filtering system drops video frames in a controlled way and reconstructs a valid MPEG system stream in real-time. The system consists of a sequence of filtering modules and each module is carefully designed to maintain the synchronization characteristics of real-time streaming. A special effort is given to the correct implementation of video and audio synchronization after frame-drop. The experiments show that the implemented system produces a valid MPEG system stream after filtering as well as the media bandwidth of a filtered stream is dynamically controlled by a given frame-drop policy.
C1 Yonsei Univ, Dept Comp Sci, Seoul 120749, South Korea.
   Hongik Univ, Dept Comp Engn, Seoul 121791, South Korea.
C3 Yonsei University; Hongik University
RP Yonsei Univ, Dept Comp Sci, Seoul 120749, South Korea.
EM hjcha@cs.yonsei.ac.kr; ojh@cs.yonsei.ac.kr; rhanha@cs.hongik.ac.kr
RI Cha, Hojung/G-8084-2012
CR AMIR E, 1995, P ACM MULT 95 SAN FR, P255
   [Anonymous], 1996, Techniques and standards for image, video, and audio coding
   Aurrecoechea C, 1998, MULTIMEDIA SYST, V6, P138, DOI 10.1007/s005300050083
   CEN S, 1995, P NOSSDAV 95 DURH NE, P18
   HEHMANN D, 1991, P 2 INT WORKSH NET O, P33
   HOFFMAN D, 1993, P 4 INT WORKSH NETW, P240
   *ISO IEC JTC, 1993, 1 ISO IEC JTC
   Kuhmünch C, 1999, LECT NOTES COMPUT SC, V1629, P441
   NAHRSTEDT K, 1995, IEEE COMPUT, V28, P52
   PASQUALE J, 1992, P 3 NOSSDAV 92 SAN D, P185
   SCHULZRINNE H, 1996, 1889 RFC
   SONG M, 1999, P 13 INT C INF NETW
   WALPOLE J, 1997, P 26 APPL IM PATT WO, P270
   YEADON N, 1996, THESIS LANCASTER U
   YEADON N, 1996, IEEE J SEL AREA COMM, V14, P1246
   ZHANG L, 1995, RESOURCE RESERVATION
NR 16
TC 11
Z9 13
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2003
VL 19
IS 2
BP 155
EP 178
DI 10.1023/A:1022195128444
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 640KE
UT WOS:000180687400003
DA 2024-07-18
ER

PT J
AU Nayak, R
   Pati, UC
   Das, SK
AF Nayak, Rashmiranjan
   Pati, Umesh Chandra
   Das, Santos Kumar
TI A comprehensive review of datasets for detection and localization of
   video anomalies: a step towards data-centric artificial
   intelligence-based video anomaly detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Deep learning; Data-centric approach; Model-centric approach; Video
   anomaly detection; Video anomaly localization; Video anomaly datasets
ID ABNORMAL EVENT DETECTION; REAL-TIME; BEHAVIOR RECOGNITION; SURVEILLANCE
   VIDEO; NEURAL-NETWORKS; SEGMENTATION; AUGMENTATION; EXPLORATION;
   CHALLENGES; SYSTEMS
AB Video anomaly detection and localization is one of the key components of the intelligent video surveillance system. Video anomaly detection refers to the process of spatiotemporal localization of the abnormal or anomalous pattern present in the video. The performance of the deep learning-based video anomaly detector depends on the quality and quantity of the video anomaly datasets used for training. However, there is a scarcity of effective video anomaly datasets due to inherent natures such as rareness, context-dependency, and equivocal nature. Further, state-of-the-art lacks a review that presents a comprehensive study of video anomaly datasets, including issues associated with the existing datasets, comparative analysis of the available datasets, potential solutions using both model-centric and data-centric approaches. Hence, a comprehensive review of the publicly available video anomaly datasets for video anomaly detection and localization is presented in this article. Further, a comparative study of the existing video anomaly datasets at qualitative and quantitative levels is presented to decide the right strategies for the desired application. Subsequently, model-centric and data-centric approaches required to solve various problems associated with the video anomaly datasets are presented. Finally, current research trends, research challenges, potential applications, and future research directions are outlined.
C1 [Nayak, Rashmiranjan; Pati, Umesh Chandra; Das, Santos Kumar] Natl Inst Technol Rourkela, Dept Elect & Commun Engn, Sect 1, Rourkela 769008, Odisha, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela
RP Nayak, R (corresponding author), Natl Inst Technol Rourkela, Dept Elect & Commun Engn, Sect 1, Rourkela 769008, Odisha, India.
EM rashmiranjan.et@gmail.com; ucpati@nitrkl.ac.in; dassk@nitrkl.ac.in
RI Das, Santos Kumar/M-5844-2019
OI Das, Santos Kumar/0000-0002-8788-6152; Nayak,
   Rashmiranjan/0000-0002-1380-701X
FU IMPACTING RESEARCH INNOVATION AND TECHNOLOGY (IMPRINT) INDIA
   [No.-7794/2016]; Ministry of Human Resource Development, Government of
   India; Ministry of Housing and Urban Affairs, Government of India
FX This work is supported by the IMPACTING RESEARCH INNOVATION AND
   TECHNOLOGY (IMPRINT) INDIA (Grant No.-7794/2016), an initiative of
   Ministry of Human Resource Development, Government of India and Ministry
   of Housing and Urban Affairs, Government of India.
CR Abati D, 2019, PROC CVPR IEEE, P481, DOI 10.1109/CVPR.2019.00057
   Acsintoae A, 2022, PROC CVPR IEEE, P20111, DOI 10.1109/CVPR52688.2022.01951
   Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   Aggarwal CC, 2014, CH CRC DATA MIN KNOW, P1
   Ali S, 2007, PROC CVPR IEEE, P65
   [Anonymous], 2009, Advances in neural information processing systems
   [Anonymous], 2009, PERFORMANCE EVALUATI
   [Anonymous], 2004, P 6 IEEE INT WORKSH
   Apat HK, 2023, INTERNET THINGS-NETH, V23, DOI 10.1016/j.iot.2023.100866
   Asad M, 2021, J VIS COMMUN IMAGE R, V75, DOI 10.1016/j.jvcir.2021.103047
   Badrinarayanan V, 2013, IEEE T PATTERN ANAL, V35, P2751, DOI 10.1109/TPAMI.2013.54
   Bawarith R, 2017, INT J ADV COMPUT SC, V8, P176
   Ben Mabrouk A, 2018, EXPERT SYST APPL, V91, P480, DOI 10.1016/j.eswa.2017.09.029
   Benezeth Y., 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2458, DOI 10.1109/CVPRW.2009.5206686
   Bengio Y., 2009, P 26 ANN INT C MACH, V60, P6, DOI [DOI 10.1145/1553374.1553380, 10.1145/1553374.1553380]
   Bhambani K, 2020, 2020 IEEE BANG HUM T, P1
   Bird N, 2006, IEEE INT CONF ROBOT, P3775, DOI 10.1109/ROBOT.2006.1642279
   Blunsden S., 2010, ANN BMVA, V4, P4, DOI DOI 10.5465/19416521003654160
   Bowles C., 2018, arXiv
   Budvytis I, 2017, IEEE INT CONF COMP V, P230, DOI 10.1109/ICCVW.2017.36
   Camacho J, 2017, J COMPUT GRAPH STAT, V26, P501, DOI 10.1080/10618600.2016.1265527
   Castellani A, 2021, IEEE T IND INFORM, V17, P4733, DOI 10.1109/TII.2020.3019788
   Chalapathy R, 2019, arXiv
   Chen DY, 2021, PATTERN RECOGN, V116, DOI 10.1016/j.patcog.2021.107969
   Chilimbi T., 2014, 11 USENIX S OPERATIN, P571
   Chong YS, 2017, LECT NOTES COMPUT SC, V10262, P189, DOI 10.1007/978-3-319-59081-3_23
   Cox M.A., 2008, HDB DATA VIS, P315
   Cox V., 2017, Translating Statistics to Make Decisions, P47
   Cubuk ED, 2019, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2019.00020
   de Oliveira MCF, 2003, IEEE T VIS COMPUT GR, V9, P378, DOI 10.1109/TVCG.2003.1207445
   Derpanis KG, 2005, IEEE IMAGE PROC, P2777
   Derpanis KG, 2010, PROC CVPR IEEE, P191, DOI 10.1109/CVPR.2010.5540213
   DeVries T, 2017, PREPRINT
   El-Wakeel AS, 2020, IEEE SENS J, V20, P3182, DOI 10.1109/JSEN.2019.2958791
   Erhan D, 2010, J MACH LEARN RES, V11, P625
   Fan YX, 2020, COMPUT VIS IMAGE UND, V195, DOI 10.1016/j.cviu.2020.102920
   Feng Z., 2018, EVA EFFICIENT SYSTEM, P1
   Fernandez A., 2018, LEARNING IMBALANCED
   Ferryman J., 2009, P 12 IEEE INT WORKSH, P1
   Ganokratanaa T, 2022, PATTERN RECOGN LETT, V155, P143, DOI 10.1016/j.patrec.2021.11.001
   Gatys L. A., 2015, arXiv
   Gong D, 2019, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2019.00179
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Griffin BA, 2019, PROC CVPR IEEE, P8906, DOI 10.1109/CVPR.2019.00912
   Guansong Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12170, DOI 10.1109/CVPR42600.2020.01219
   Hacohen G, 2019, PR MACH LEARN RES, V97
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   Hassner T., 2012, 2012 IEEE COMP SOC C, P1, DOI [DOI 10.1109/CVPRW.2012.6239348, 10.1109/CVPRW.2012.6239348]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Y, 2018, IEEE SIGNAL PROC MAG, V35, P120, DOI 10.1109/MSP.2018.2842228
   Hernandez-Lopez FJ, 2015, J REAL-TIME IMAGE PR, V10, P453, DOI 10.1007/s11554-013-0375-9
   Hosmer P, 2007, IEEE INT C ADV VID I
   Hospedales T, 2012, INT J COMPUT VISION, V98, P303, DOI 10.1007/s11263-011-0510-7
   Hospedales T, 2009, IEEE I CONF COMP VIS, P1165, DOI 10.1109/ICCV.2009.5459342
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325
   Hou YC, 2021, 2020 8 INT C INF TEC, P334
   Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang HY, 2021, J MANUF SYST, V59, P138, DOI 10.1016/j.jmsy.2021.02.010
   Hyunjong Park, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14360, DOI 10.1109/CVPR42600.2020.01438
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Ionescu RT, 2019, PROC CVPR IEEE, P7834, DOI 10.1109/CVPR.2019.00803
   Jabbar H., 2015, Comput. Sci., Commun. Instrument. Devices, V70, P978, DOI DOI 10.3850/978-981-09-5247-1_017
   Jacobs H., 1967, COLUMBIA JOURNAL REV, V5, P37
   Jayashri S, 2021, TURKISH J COMPUT MAT, V12, P2916
   Jian Li, 2010, Computer Vision - ACCV 2010. 10th Asian Conference on Computer Vision. Revised Selected Papers, P293, DOI 10.1007/978-3-642-19309-5_23
   Jiang F, 2008, INT CONF ACOUST SPEE, P2129
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Jolliffe IT, 2016, PHILOS T R SOC A, V374, DOI 10.1098/rsta.2015.0202
   Joshi A, 2019, IEEE IJCNN, DOI 10.1109/ijcnn.2019.8852035
   Jouneau E, 2011, IEEE IMAGE PROC, P513, DOI 10.1109/ICIP.2011.6116394
   Kaltsa V, 2015, IEEE T IMAGE PROCESS, V24, P2153, DOI 10.1109/TIP.2015.2409559
   Kiran BR, 2018, J IMAGING, V4, DOI 10.3390/jimaging4020036
   Ko KE, 2018, ENG APPL ARTIF INTEL, V67, P226, DOI 10.1016/j.engappai.2017.10.001
   Koch G., 2015, ICML DEEP LEARNING W, V2
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuettel D, 2010, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2010.5539869
   Kukaka J., 2017, ARXIV
   Kumaran S.K., 2019, ARXIV
   Kwak YH, 2023, IEEE T ENG MANAGE, V70, P740, DOI 10.1109/TEM.2021.3060956
   Lawrence S., 1997, P AAAI IAAI, P540
   Leach MJV, 2014, PATTERN RECOGN LETT, V44, P71, DOI 10.1016/j.patrec.2013.11.018
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lemley J, 2017, IEEE ACCESS, V5, P5858, DOI 10.1109/ACCESS.2017.2696121
   Leyva R, 2017, I W BIOMETRIC FORENS
   Leyva R, 2017, IEEE T IMAGE PROCESS, V26, P3463, DOI 10.1109/TIP.2017.2695105
   Li B, 2021, COMPUT VIS IMAGE UND, V210, DOI 10.1016/j.cviu.2021.103249
   Li NJ, 2021, IEEE T MULTIMEDIA, V23, P203, DOI 10.1109/TMM.2020.2984093
   Li T, 2021, NEUROCOMPUTING, V439, P256, DOI 10.1016/j.neucom.2021.01.097
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Lim SK, 2018, IEEE DATA MINING, P1122, DOI 10.1109/ICDM.2018.00146
   Lin W., 2011, VIDEO SURVEILLANCE, P281, DOI [10.5772/15302, DOI 10.5772/15302]
   Liu MJ, 2022, MULTIMED TOOLS APPL, V81, P21939, DOI 10.1007/s11042-022-12510-1
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Liu YZ, 2020, IEEE T KNOWL DATA EN, V32, P1517, DOI 10.1109/TKDE.2019.2905606
   Loy CC, 2009, BRIT MACH VIS C BMVC, P1
   Loy CC, 2012, PROC CVPR IEEE, P1560, DOI 10.1109/CVPR.2012.6247847
   Loy CC, 2011, LECT NOTES COMPUT SC, V6492, P161, DOI 10.1007/978-3-642-19315-6_13
   Loy CC, 2011, PATTERN RECOGN, V44, P117, DOI 10.1016/j.patcog.2010.07.023
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Luo WX, 2021, IEEE T PATTERN ANAL, V43, P1070, DOI 10.1109/TPAMI.2019.2944377
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Mansour RF, 2021, IMAGE VISION COMPUT, V112, DOI 10.1016/j.imavis.2021.104229
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Markovitz Amir, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10536, DOI 10.1109/CVPR42600.2020.01055
   Matejka J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173943
   Medel J. R., 2016, Anomaly detection in video using predictive convolutional long short-term memory networks
   Meghdadi AH, 2013, IEEE T VIS COMPUT GR, V19, P2119, DOI 10.1109/TVCG.2013.168
   Meher C. K., 2022, P 2 OD INT C EL POW, P1, DOI DOI 10.1109/ODICON54453.2022.10010086
   Meher CK, 2022, 2022 IEEE 2 INT S SU, P1, DOI [10.1109/iSSSC56467.2022.10051511, DOI 10.1109/ISSSC56467.2022.10051511]
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Meng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3401, DOI 10.1109/CVPR.2011.5995698
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Morais R, 2019, PROC CVPR IEEE, P11988, DOI 10.1109/CVPR.2019.01227
   Narasimhan MG, 2018, MULTIMED TOOLS APPL, V77, P13173, DOI 10.1007/s11042-017-4940-2
   Nayak Rashmiranjan, 2020, 2020 International Conference on Contemporary Computing and Applications (IC3A), P175, DOI 10.1109/IC3A48958.2020.233292
   Nayak R, 2019, IEEE I C ADV NETW TE, DOI 10.1109/ants47819.2019.9117960
   Nayak R, 2021, IMAGE VISION COMPUT, V106, DOI 10.1016/j.imavis.2020.104078
   Nayak R, 2019, 2019 IEEE INTERNATIONAL SYMPOSIUM ON SMART ELECTRONIC SYSTEMS (ISES 2019), P215, DOI 10.1109/iSES47678.2019.00055
   Ng A., 2021, A chat with andrew on mlops: from model-centric to data-centric AI
   Nguyen TN, 2022, IEEE T NEUR NET LEAR, V33, P2287, DOI 10.1109/TNNLS.2021.3116212
   Nogami R, 2012, PROC INT C TOOLS ART, P32, DOI 10.1109/ICTAI.2012.185
   Oh S, 2011, Anomaly detection from videos under sparse data and partial observations
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pandya S, 2018, APPL SYST INNOV, V1, DOI 10.3390/asi1040042
   Pang GS, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3439950
   Pareek P, 2021, ARTIF INTELL REV, V54, P2259, DOI 10.1007/s10462-020-09904-8
   Patil N, 2016, 2016 SIXTH INTERNATIONAL SYMPOSIUM ON EMBEDDED COMPUTING AND SYSTEM DESIGN (ISED 2016), P43, DOI 10.1109/ISED.2016.7977052
   Patrikar DR, 2022, INT J MULTIMED INF R, V11, P85, DOI 10.1007/s13735-022-00227-8
   Pawar K, 2019, WORLD WIDE WEB, V22, P571, DOI 10.1007/s11280-018-0582-1
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Pimentel T, 2018, ARXIV
   Popoola OP, 2012, IEEE T SYST MAN CY C, V42, P865, DOI 10.1109/TSMCC.2011.2178594
   Pranav M., 2020, P AS C COMP VIS, P1
   Radosavovic I, 2018, PROC CVPR IEEE, P4119, DOI 10.1109/CVPR.2018.00433
   Ramachandra B, 2020, IEEE WINT CONF APPL, P2558, DOI [10.1109/WACV45572.2020.9093457, 10.1109/wacv45572.2020.9093457]
   Refaat M., 2010, Data Preparation for Data Mining Using SAS
   Ren J, 2021, arXiv
   Ribnick E, 2006, P IEEE INT C VID SIG, P10
   Rivera AR, 2022, IEEE T NEUR NET LEAR, V33, P281, DOI 10.1109/TNNLS.2020.3027667
   Roshtkhari MJ, 2013, PROC CVPR IEEE, P2611, DOI 10.1109/CVPR.2013.337
   Ruppert D, 2000, AUST NZ J STAT, V42, P205, DOI 10.1111/1467-842X.00119
   Sabokrou M, 2018, PROC CVPR IEEE, P3379, DOI 10.1109/CVPR.2018.00356
   Sabokrou M, 2018, COMPUT VIS IMAGE UND, V172, P88, DOI 10.1016/j.cviu.2018.02.006
   Sabokrou M, 2017, MACH VISION APPL, V28, P965, DOI 10.1007/s00138-017-0869-8
   Sabokrou M, 2017, IEEE T IMAGE PROCESS, V26, P1992, DOI 10.1109/TIP.2017.2670780
   Saligrama V, 2012, PROC CVPR IEEE, P2112, DOI 10.1109/CVPR.2012.6247917
   Santhosh KK, 2021, ACM COMPUT SURV, V53, DOI 10.1145/3417989
   Saponara S, 2021, J REAL-TIME IMAGE PR, V18, P1937, DOI 10.1007/s11554-021-01070-6
   Seo Y, 1998, INT C PATT RECOG, P1694, DOI 10.1109/ICPR.1998.712048
   Shao L, 2015, IEEE T NEUR NET LEAR, V26, P1019, DOI 10.1109/TNNLS.2014.2330900
   Shen JL, 2008, IEEE T CIRC SYST VID, V18, P1587, DOI 10.1109/TCSVT.2008.2005607
   Shi YX, 2021, IEEE T MULTIMEDIA, V23, P4376, DOI 10.1109/TMM.2020.3042068
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Slavic G, 2021, IEEE IMAGE PROC, P1569, DOI 10.1109/ICIP42928.2021.9506049
   Sodemann AA, 2012, IEEE T SYST MAN CY C, V42, P1257, DOI 10.1109/TSMCC.2012.2215319
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stapleton Patriel, 2021, SIGCSE '21: Proceedings of the 52nd ACM Technical Symposium on Computer Science Education, DOI 10.1145/3408877.3439671
   Stieglitz S, 2018, INT J INFORM MANAGE, V39, P156, DOI 10.1016/j.ijinfomgt.2017.12.002
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tiong L. C. O., 2021, ARXIV
   Tompson J, 2015, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.2015.7298664
   Tran TM, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3544014
   Tripathi RK, 2018, ARTIF INTELL REV, V50, P283, DOI 10.1007/s10462-017-9545-7
   Tukey J.W., 1977, EXPLORATORY DATA ANA, V2
   UCF, Abnormal Crowd Behavior Detection Using Social Force Model by UCF Center for Reserch in Computer Vision
   Ullah A, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207595
   UMN, Unusual Crowd Activity Dataset of University of Minnesota
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Varadarajan J, 2017, IEEE WINT CONF APPL, P615, DOI 10.1109/WACV.2017.74
   Velastin Sergio A., 2017, Advances in Visual Informatics. 5th International Visual Informatics Conference, IVIC 2017. Proceedings: LNCS 10645, P319, DOI 10.1007/978-3-319-70010-6_30
   Vu H., 2017, Energy-based models for video anomaly detection
   Wan BY, 2021, IET IMAGE PROCESS, V15, P3454, DOI 10.1049/ipr2.12258
   Wang J., 2017, Convolutional Neural Networks vis. Recognit, V2017, P1
   Wang J, 2016, COMPUT VIS IMAGE UND, V144, P177, DOI 10.1016/j.cviu.2015.08.010
   Wang T, 2019, IEEE T INF FOREN SEC, V14, P1390, DOI 10.1109/TIFS.2018.2878538
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P539, DOI 10.1109/TPAMI.2008.87
   Wei DL, 2022, IEEE SIGNAL PROC LET, V29, P2178, DOI 10.1109/LSP.2022.3216500
   Wu JC, 2021, COMPUT VIS IMAGE UND, V210, DOI 10.1016/j.cviu.2021.103226
   Wu P, 2020, IEEE T NEUR NET LEAR, V31, P2609, DOI 10.1109/TNNLS.2019.2933554
   Wu R, 2015, Arxiv, DOI [arXiv:1501.02876, 10.48550/arXiv.1501.02876]
   Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768
   Xiang T, 2008, COMPUT VIS IMAGE UND, V111, P59, DOI 10.1016/j.cviu.2007.06.004
   Xu K, 2020, IEEE T MULTIMEDIA, V22, P394, DOI 10.1109/TMM.2019.2929931
   Xu K, 2018, IEEE T MULTIMEDIA, V20, P1062, DOI 10.1109/TMM.2018.2818942
   Xu X, 2017, COMPUT VIS PATT REC, P341, DOI 10.1016/B978-0-12-809276-7.00018-7
   Yahaya SW, 2021, PATTERN RECOGN LETT, V145, P200, DOI 10.1016/j.patrec.2021.02.006
   Yazdani M, 2016, PyData Chicago
   Yosinski J, 2014, ADV NEUR IN, V27
   Yu S, 2021, IEEE T COMPUT SOC SY, V8, P134, DOI 10.1109/TCSS.2020.2977958
   Yuan HC, 2021, IEEE ACCESS, V9, P123977, DOI 10.1109/ACCESS.2021.3109102
   Yun S., 2020, arXiv
   Zaharescu A, 2018, ANOMALOUS BEHAV DATA
   Zaharescu A, 2010, LECT NOTES COMPUT SC, V6311, P563, DOI 10.1007/978-3-642-15549-9_41
   Zendel O, 2017, INT J COMPUT VISION, V125, P95, DOI 10.1007/s11263-017-1020-z
   Zhang D, 2005, PROC CVPR IEEE, P611
   Zhang Q, 2022, Multimedia Tools and Applications, P1
   Zhang WC, 2021, IEEE ACCESS, V9, P124847, DOI 10.1109/ACCESS.2021.3110798
   Zhang Y., 2019, arXiv
   Zhang Y, 2021, IEEE T CIRC SYST VID, V31, P3694, DOI 10.1109/TCSVT.2020.3039798
   Zhao A, 2019, PROC CVPR IEEE, P8535, DOI 10.1109/CVPR.2019.00874
   Zhao YR, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1933, DOI 10.1145/3123266.3123451
   Zhong H, 2004, PROC CVPR IEEE, P819
   Zhong JX, 2019, PROC CVPR IEEE, P1237, DOI 10.1109/CVPR.2019.00133
   Zhou JT, 2019, IEEE T INF FOREN SEC, V14, P2537, DOI 10.1109/TIFS.2019.2900907
   Zhou JT, 2019, IEEE T NEUR NET LEAR, V30, P2794, DOI 10.1109/TNNLS.2018.2885854
   Zhu L, 2019, IEEE T INTELL TRANSP, V20, P383, DOI 10.1109/TITS.2018.2815678
   Zhu YY, 2013, IEEE J-STSP, V7, P91, DOI 10.1109/JSTSP.2012.2234722
   Zuo F, 2021, J TRANSP HEALTH, V21, DOI 10.1016/j.jth.2021.101032
NR 214
TC 0
Z9 0
U1 19
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 29
PY 2023
DI 10.1007/s11042-023-17889-z
EA DEC 2023
PG 58
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DL1O1
UT WOS:001132108500011
DA 2024-07-18
ER

PT J
AU Safiya, KM
   Pandian, R
AF Safiya, K. M.
   Pandian, R.
TI A real-time image captioning framework using computer vision to help the
   visually impaired
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Artificial intelligence; Computer Vision; Text-to-Speech; Image
   Captioning; LSTM; VGG16; Visually impaired
ID LSTM
AB Advancements in image captioning technology have played a pivotal role in enhancing the quality of life for those with visual impairments, fostering greater social inclusivity. The computer vision and natural language processing methods enhances the accessibility and comprehensibility of pictures via the addition of textual descriptions. Significant advancements have been achieved in photo captioning, specifically tailored for those with visual impairments. Nevertheless, some challenges must be addressed, like ensuring the precision of automatically generated captions and effectively handling pictures that include many objects or settings. This research presents a ground breaking architecture for real-time picture captioning using a VGG16-LSTM deep learning model with computer vision assistance. The framework has been developed and deployed in a Raspberry Pi 4B single-board computer, with graphics processing unit capabilities. This implementation allows for the automated generation of relevant captions for photographs captured in real time by a NoIR camera module. This characteristic makes it a portable and uncomplicated choice for those with visual impairments. The efficacy of the VGG16-LSTM deep learning model is evaluated via comprehensive testing, including both sighted and visually impaired participants in diverse settingsThe experimental findings demonstrate that the proposed framework effectively operates as intended, generating real-time picture captions that are accurate and contextually appropriate. The analysis of user feedback indicates a significant improvement in the understanding of visual content, hence facilitating the mobility and interaction of individuals with visual impairments in their environment. We have used multiple dataset including Flicke8k, Flickr30k, VizWiz captioning and custom dataset for the model training, validation and testing process. During the training phase, the ResNet-50 and VGG-16 models achieve 80.84% and 84.13% accuracy, respectively. Similarly, during the validation phase, the ResNet-50 and VGG-16 models acquire accuracies of 80.04% and 83.88%, respectively. The text-to-speech API is analyzed with MOS and WER matrices and achieved an exceptional accuracy and performance is verifying on a GPU system using a custom dataset. The efficacy of the VGG16-LSTM deep-learning model is evaluated using six metrics: accuracy, precision, recall, F1 score, BLEU, and ROUGE. Individuals with visual impairments may benefit from this deep learning architecture, as it endeavors to facilitate their comprehension and engagement with visual content.
C1 [Safiya, K. M.] Sathyabama Inst Sci & Technol Deemed to Be Univ, Dept Comp Sci & Engn, Chennai, India.
   [Pandian, R.] Sathyabama Inst Sci & Technol Deemed to be Univ, Dept Elect & Commun Engn, Chennai, India.
RP Safiya, KM (corresponding author), Sathyabama Inst Sci & Technol Deemed to Be Univ, Dept Comp Sci & Engn, Chennai, India.
EM mailtosafiya786@gmail.com; pandian.eni@sathyabama.ac.in
RI K M, Safiya/JZE-1986-2024
CR Abubeker KM, 2023, IEEE SENS J, V23, P7608, DOI 10.1109/JSEN.2023.3244582
   Abubeker KM, 2023, MACH LEARN-SCI TECHN, V4, DOI 10.1088/2632-2153/acc30f
   Afzal Muhammad Kashif, 2023, Journal of Ambient Intelligence and Humanized Computing, P7719, DOI 10.1007/s12652-023-04584-y
   [Anonymous], 2020, KAGGLE
   [Anonymous], 2018, Kaggle
   Ben Atitallah A, 2023, COMPUT ELECTR ENG, V108, DOI 10.1016/j.compeleceng.2023.108714
   Chang JC, 2023, MULTIMEDIA SYST, V29, P3891, DOI 10.1007/s00530-023-01166-y
   Chu Y, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8909458
   Das R, 2022, MULTIMED TOOLS APPL, V81, P10051, DOI 10.1007/s11042-022-12042-8
   de Freitas MP, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22218531
   Deorukhkar KP, 2022, SENS IMAGING, V23, DOI 10.1007/s11220-022-00400-7
   Ding GG, 2019, COGN COMPUT, V11, P763, DOI 10.1007/s12559-018-9581-x
   Due BL, 2023, MOBILITIES-UK, V18, P148, DOI 10.1080/17450101.2022.2086059
   Feng JL, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/9743123
   Ganesan J, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11203335
   Jaiswal T., 2021, Turkish J Comput Math Educ, V12L, P333
   Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494
   Kim DJ, 2022, IEEE T PATTERN ANAL, V44, P7348, DOI 10.1109/TPAMI.2021.3119754
   Kiziltepe RS, 2023, NEURAL COMPUT APPL, V35, P24513, DOI 10.1007/s00521-021-06322-x
   Kumar D, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12136733
   Liu AA, 2019, MULTIMED TOOLS APPL, V78, P677, DOI 10.1007/s11042-017-5532-x
   Liu HQ, 2023, NEUROCOMPUTING, V552, DOI 10.1016/j.neucom.2023.126486
   Liu Xingjian, 2021, Journal of Physics: Conference Series, V1976, DOI [10.1088/1742-6596/1976/1/012004, DOI 10.1088/1742-6596/1976/1/012004]
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Lu FF, 2023, DISPLAYS, V79, DOI 10.1016/j.displa.2023.102482
   Lv G, 2023, IMAGE VISION COMPUT, V136, DOI 10.1016/j.imavis.2023.104751
   Ma YA, 2023, FUTURE GENER COMP SY, V140, P117, DOI 10.1016/j.future.2022.09.017
   Martin AD, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10162859
   Mohith SS., 2020, Visual World to an Audible Experience: Visual Assistance for the Blind And Visually Impaired," 2020 IEEE 17th India Council International Conference (INDICON), V2020, P1, DOI [10.1109/INDICON49873.2020.9342481, DOI 10.1109/INDICON49873.2020.9342481]
   P. G. H. M. B. P. R Sneha, 2022, Deep image captioning system using attention two-layer LSTM network, V6, P6621
   Poddar Ayush Kumar, 2023, Procedia Computer Science, P686, DOI 10.1016/j.procs.2023.01.049
   Poongodi M, 2023, MULTIMEDIA SYST, V29, P2951, DOI 10.1007/s00530-022-00902-0
   Praveen RG, 2013, PROCEDIA ENGINEER, V64, P351, DOI 10.1016/j.proeng.2013.09.107
   Rane C., 2021, 2021 INT C COMM INF, P1, DOI [10.1109/ICCICT50803.2021.9510102, DOI 10.1109/ICCICT50803.2021.9510102]
   Rickly JM, 2022, TOURISM MANAGE, V93, DOI 10.1016/j.tourman.2022.104617
   Said Y, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11051127
   Saleem S, 2019, COMPUT ELECTR ENG, V78, P108, DOI 10.1016/j.compeleceng.2019.07.009
   Samundeswari S., 2022, 2022 INT VIRTUAL C P, P1, DOI [10.1109/PECCON55017.2022.9851037, DOI 10.1109/PECCON55017.2022.9851037]
   Shao Zhuang, 2022, IEEE Trans Neural Netw Learn Syst, VPP, DOI 10.1109/TNNLS.2022.3152990
   Singh Yajush Pratap, 2020, INT C FUT ENG SYST T, V854, DOI [10.1088/1742-6596/1854/1/012048, DOI 10.1088/1742-6596/1854/1/012048]
   Tiwary T, 2023, MULTIMED TOOLS APPL, V82, P3801, DOI 10.1007/s11042-022-13443-5
   VizWiz, Image Captioning
   Wang JJ, 2023, DISPLAYS, V77, DOI 10.1016/j.displa.2023.102391
NR 43
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 22
PY 2023
DI 10.1007/s11042-023-17849-7
EA DEC 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB8U4
UT WOS:001129672000007
DA 2024-07-18
ER

PT J
AU Abdulsattar, FS
   Zaghar, DR
   Khalaf, WM
AF Abdulsattar, Fatimah Shamsulddin
   Zaghar, Dhafer R.
   Khalaf, Walaa M.
TI Self-encoded chimera transform for digital image representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Mathematical expression; Self-encoded; Codebook; Image transform; DCT;
   DWT
AB During the last decade, there has been an increased focus on representing images using mathematical expressions. The initial stages towards achieving this process have already been accomplished in the literature. However, several efforts are still required to convert the image into fully mathematical expressions. The majority of the work involved transforming the image into simplified representations using a codebook, which poses a challenge to achieving the main goal. In this work, a new transformation has been introduced to represent an image as small units. This approach enables direct manipulation of image blocks rather than individual pixels. The transformation is denoted as the self-encoded chimera transform (SECT). Being different from traditional transforms such as discrete cosine transform (DCT), and discrete wavelet transform (DWT), the image representation via the SECT remains in the time domain. The SECT can be calculated across multiple layers to enhance the quality of reconstruction. Each layer is represented by three encoded arrays. The encoding arrays are calculated using simple statistics. The SECT is applied to several standard images and achieved better quality in compare to both State-of-the-art and Standard transforms. Further analysis indicates that quality of the reconstruction improves when number of layers of the SECT has increased.
C1 [Abdulsattar, Fatimah Shamsulddin; Zaghar, Dhafer R.; Khalaf, Walaa M.] Mustansiriyah Univ, Comp Engn Dept, Baghdad 46049, Iraq.
C3 Mustansiriya University
RP Abdulsattar, FS (corresponding author), Mustansiriyah Univ, Comp Engn Dept, Baghdad 46049, Iraq.
EM fsa.abdulsattar@uomustansiriyah.edu.iq; drz.raw@uomustansiriyah.edu.iq;
   w.khalaf@uomustansiriyah.edu.iq
RI Abdulsattar, Fatimah Shamsulddin/N-8671-2017
OI Abdulsattar, Fatimah Shamsulddin/0000-0001-8918-6777
FU Baghdad, Iraq
FX The authors would like to thank Mustansiriyah University, Baghdad, Iraq
   for its support in the present work.
CR Abdulsattar FS, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14030516
   Abdulsattar FS, 2021, MULTIMED TOOLS APPL, V80, P18821, DOI 10.1007/s11042-021-10608-6
   [Anonymous], 1981, The USC-SIPI Image Database
   Chen GY, 2021, PATTERN ANAL APPL, V24, P1367, DOI 10.1007/s10044-021-00996-8
   Chen MM, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2020.106026
   Deng QL, 2018, CAAI T INTELL TECHNO, V3, P33, DOI 10.1049/trit.2018.0003
   Deng YL, 2023, RESULTS ENG, V17, DOI 10.1016/j.rineng.2022.100837
   Durmus D, 2020, IEEE ACCESS, V8, P100111, DOI 10.1109/ACCESS.2020.2998292
   Khalaf W, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12030378
   Khalaf W, 2019, ALGORITHMS, V12, DOI 10.3390/a12120255
   Khalaf W, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11020291
   Krishnan P, 2019, INT J DOC ANAL RECOG, V22, P387, DOI 10.1007/s10032-019-00336-x
   Mohammad AS, 2021, INFORMATION, V12, DOI 10.3390/info12030115
   Nash C, 2021, Arxiv, DOI arXiv:2103.03841
   Starosolski R, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22070751
   Tian CW, 2023, PATTERN RECOGN, V134, DOI 10.1016/j.patcog.2022.109050
   Wang MN, 2020, IEEE SIGNAL PROC LET, V27, P990, DOI 10.1109/LSP.2020.2999788
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZY, 2021, EXPERT SYST APPL, V171, DOI 10.1016/j.eswa.2021.114574
   Wu X, 2018, IEEE T INF FOREN SEC, V13, P2884, DOI 10.1109/TIFS.2018.2833032
   Zafar B, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8112242
   Zhang LP, 2021, DISPLAYS, V68, DOI 10.1016/j.displa.2021.102022
NR 22
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 19
PY 2023
DI 10.1007/s11042-023-17623-9
EA DEC 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7T2
UT WOS:001126521200013
DA 2024-07-18
ER

PT J
AU Chakraborty, S
   Kumar, K
   Tadepalli, K
   Pailla, BR
   Roy, S
AF Chakraborty, Snehashis
   Kumar, Komal
   Tadepalli, Kalyan
   Pailla, Balakrishna Reddy
   Roy, Sudipta
TI Unleashing the power of explainable AI: sepsis sentinel's clinical
   assistant for early sepsis identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Precision medicine; Machine learning; Deep learning; Sepsis sentinel;
   Informative bottleneck; Transparent AI
AB Sepsis is a severe and potentially life-threatening condition that occurs when the body's immune response becomes excessively intense in reaction to an infection. If not promptly treated, it can result in organ failure and even death. So, early identification of patients at risk for sepsis is crucial to improve the patient's outcome in critical care. The main objective of this work is to create a highly accurate model named XAutoNet that utilizes optimal number of clinical features to predict sepsis 6 h before its onset, also providing diagnostic map behind its prediction that will help health workers in better treatment. The importance of this work is heightened in resource-scarce settings, where not all tests are available, or the turnaround time is excessive. A novel convolutional neural network based autoencoder architecture is also implemented to augment the performance of XAutoNet by reducing the input dimensions into an optimal number of dimensions. For explaining the participation of features in feature extraction, Gradient-based Class Activation Map is used to visualize the gradients in individual layers of the encoder block via heatmaps. For the explainability of XAutoNet, a visualization tool named SHapley Additive exPlanations (is used to interpret the features' contribution in the model's global and local prediction. The proposed XAutoNet model has an accuracy of 93%, Precision of 90%, F1 score of 92%, and Recall of 94%. The performance of the convolutional neural network -based autoencoder was also compared with its other variants, including Principal Component Analysis, which showed its high feature extraction power. The XAutoNet has also outperformed other comparable method by a significant margin. The performance of XAutoNet is instrumental in predicting sepsis in advance by understanding the non-linearity and complexity of the data of Intensive Care Unit patients with the help of the proposed autoencoder.
C1 [Chakraborty, Snehashis; Kumar, Komal; Roy, Sudipta] Jio Inst, Artificial Intelligence & Data Sci, Navi Mumbai 410206, India.
   [Tadepalli, Kalyan] Sir HN Reliance Fdn Hosp & Res Ctr, Mumbai 400004, India.
   [Pailla, Balakrishna Reddy] Reliance Jio Artificial Intelligence Ctr Excellenc, Hyderabad 500081, India.
RP Roy, S (corresponding author), Jio Inst, Artificial Intelligence & Data Sci, Navi Mumbai 410206, India.
EM Snehashis1.C@jioinstitute.edu.in; komal2.Kumar@jioinstitute.edu.in;
   Kalyan.Tadepalli@rfhospital.org; balakrishna.pailla@ril.com;
   sudipta1.roy@jioinstitute.edu.in
FU RFIER-Jio Institute; Department of Critical Care; Sir H. N. Reliance
   Foundation Hospital and Research Centre
FX The authors express their deep gratitude to Dr. Ketan Kargirwar,
   Department of Critical Care, Sir H. N. Reliance Foundation Hospital and
   Research Centre, Mumbai-400004, India for his invaluable guidance and
   insight in understanding the critical-care nuances of this article's
   subject matter.
CR Calvert JS, 2016, COMPUT BIOL MED, V74, P69, DOI 10.1016/j.compbiomed.2016.05.003
   Chakraborty RK, 2022, StatPearls
   Chakraborty S, 2023, IEEE 24 INT C INF RE
   Chakravarty S, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106535
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Cynthia P. Caroline, 2021, Intelligence in Big Data Technologies-beyond the Hype, P125, DOI [10.1007/978-981-15-5285-4_12, DOI 10.1007/978-981-15-5285-4_12]
   Debie E, 2019, PATTERN ANAL APPL, V22, P519, DOI 10.1007/s10044-017-0649-0
   El-Rashidy N, 2023, NEURAL COMPUT APPL, V35, P7423, DOI 10.1007/s00521-022-08007-5
   Fryer D, 2021, IEEE ACCESS, V9, P144352, DOI 10.1109/ACCESS.2021.3119110
   Fu M, 2019, 2019 COMPUTING CARDI, P1
   Goh KH, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-20910-4
   Islam MM, 2019, COMPUT METH PROG BIO, V170, P1, DOI 10.1016/j.cmpb.2018.12.027
   KIM JO, 1977, SOCIOL METHOD RES, V6, P215, DOI 10.1177/004912417700600206
   Lauritsen SM, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00529-x
   Liu R, 2019, IEEE ENG MED BIO, P6103, DOI [10.1109/EMBC.2019.8857819, 10.1109/embc.2019.8857819]
   Lundberg SM, 2017, ADV NEUR IN, V30
   Mohamed Ahmed, 2020, 2020 International Conference on Contemporary Computing and Applications (IC3A), P336, DOI 10.1109/IC3A48958.2020.233670
   Nedee J.A., 2017, Early Identification of Sepsis Risk through the Prediction of Positive Blood Cultures Using Temporal Models in Tensorflow
   Nemati S, 2018, CRIT CARE MED, V46, P547, DOI [10.1097/CCM.0000000000002936, 10.1097/ccm.0000000000002936]
   Raaijmakers QAW, 1999, EDUC PSYCHOL MEAS, V59, P725, DOI 10.1177/00131649921970116
   Reyna MA, 2020, CRIT CARE MED, V48, P210, DOI 10.1097/CCM.0000000000004145
   Rodelo JR, 2012, AM J EMERG MED, V30, P1991, DOI 10.1016/j.ajem.2012.04.033
   Roy S, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12102549
   Roy S, 2022, EUR J NUCL MED MOL I, V49, P550, DOI 10.1007/s00259-021-05489-8
   Roy S, 2020, EBIOMEDICINE, V59, DOI 10.1016/j.ebiom.2020.102963
   Rudd KE, 2020, LANCET, V395, P200, DOI 10.1016/S0140-6736(19)32989-7
   Scherpf M, 2019, COMPUT BIOL MED, V113, DOI 10.1016/j.compbiomed.2019.103395
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Shankar A, 2021, 2021 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2021), P837, DOI 10.1109/Confluence51648.2021.9377090
   Shrikumar A, 2017, PR MACH LEARN RES, V70
   Shrikumar Avanti, 2016, arXiv, DOI DOI 10.48550/ARXIV.1605.01713
   Singh YV, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/9263391
   Taneja I, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-09766-1
   Teng AK, 2020, APPL CLIN INFORM, V11, P387, DOI 10.1055/s-0040-1710525
   van Buuren S, 2011, J STAT SOFTW, V45, P1
   Wang XC, 2018, IEEE ACCESS, V6, P48300, DOI 10.1109/ACCESS.2018.2867728
   Weiss SJ, 2019, AM J EMERG MED, V37, P1505, DOI 10.1016/j.ajem.2018.11.009
   Yan MY, 2022, J AM MED INFORM ASSN, V29, P559, DOI 10.1093/jamia/ocab236
   Yen SJ, 2009, EXPERT SYST APPL, V36, P5718, DOI 10.1016/j.eswa.2008.06.108
   Zargoush M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-00220-x
   Zhao X, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/6522633
NR 41
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 16
PY 2023
DI 10.1007/s11042-023-17828-y
EA DEC 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA4V1
UT WOS:001129308400001
DA 2024-07-18
ER

PT J
AU Kuznetsov, O
   Zakharov, D
   Frontoni, E
AF Kuznetsov, Oleksandr
   Zakharov, Dmytro
   Frontoni, Emanuele
TI Deep learning-based biometric cryptographic key generation with
   post-quantum security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cryptographic keys; Deep learning models; Convolutional neural networks;
   Fuzzy extractor; Biometric face images; Code-based cryptosystems
ID FUZZY VAULT; SCHEME
AB In contemporary digital security systems, the generation and management of cryptographic keys, such as passwords and pin codes, often rely on stochastic random processes and intricate mathematical transformations. While these keys ensure robust security, their storage and distribution necessitate sophisticated and costly mechanisms. This study explores an alternative approach that leverages biometric data for generating cryptographic keys, thereby eliminating the need for complex storage and distribution processes. The paper investigates biometric key generation technologies based on deep learning models, specifically utilizing convolutional neural networks to extract biometric features from human facial images. Subsequently, code-based cryptographic extractors are employed to process the primary extracted features. The performance of various deep learning models and the extractor is evaluated by considering Type 1 and Type 2 errors. The optimized algorithm parameters yield an error rate of less than 10%, rendering the generated keys suitable for biometric authentication. Additionally, this study demonstrates that the application of code-based cryptographic extractors provides a post-quantum level of security, further enhancing the practicality and effectiveness of biometric key generation technologies in modern information security systems. This research contributes to the ongoing efforts towards secure, efficient, and user-friendly authentication and encryption methods, harnessing the power of biometric data and deep learning techniques.
C1 [Kuznetsov, Oleksandr; Frontoni, Emanuele] Univ Macerata, Dept Polit Sci Commun & Int Relat, Via Crescimbeni,30-32, I-62100 Macerata, MC, Italy.
   [Kuznetsov, Oleksandr] Comenius Univ, Dept Informat Syst, Fac Management, Odbojarov 10, Bratislava 25, Slovakia.
   [Kuznetsov, Oleksandr] Kharkov Natl Univ, Dept Informat & Commun Syst Secur, 4 Svobody Sq, UA-61022 Kharkiv, Ukraine.
   [Zakharov, Dmytro] Kharkov Natl Univ, Dept Appl Math, 4 Svobody Sq, UA-61022 Kharkiv, Ukraine.
   [Frontoni, Emanuele] Marche Polytech Univ, Dept Informat Engn, Via Brecce Bianche 12, I-60131 Ancona, AN, Italy.
C3 University of Macerata; Comenius University Bratislava; Ministry of
   Education & Science of Ukraine; VN Karazin Kharkiv National University;
   Ministry of Education & Science of Ukraine; VN Karazin Kharkiv National
   University; Marche Polytechnic University
RP Kuznetsov, O (corresponding author), Univ Macerata, Dept Polit Sci Commun & Int Relat, Via Crescimbeni,30-32, I-62100 Macerata, MC, Italy.; Kuznetsov, O (corresponding author), Comenius Univ, Dept Informat Syst, Fac Management, Odbojarov 10, Bratislava 25, Slovakia.; Kuznetsov, O (corresponding author), Kharkov Natl Univ, Dept Informat & Commun Syst Secur, 4 Svobody Sq, UA-61022 Kharkiv, Ukraine.
EM kuznetsov@karazin.ua; zamdmytro@gmail.com; emanuele.frontoni@unimc.it
RI Kuznetsov, Oleksandr/M-9769-2016; Frontoni, Emanuele/D-9838-2013
OI Kuznetsov, Oleksandr/0000-0003-2331-6326; Frontoni,
   Emanuele/0000-0002-8893-9244; Zakharov, Dmytro/0000-0001-9519-2444
FU HORIZON EUROPE Marie Sklodowska-Curie Actions
FX No Statement Available
CR Mariño RA, 2012, INFORM SCIENCES, V195, P91, DOI 10.1016/j.ins.2012.01.042
   [Anonymous], 2023, Classic McEliece: Intro
   [Anonymous], 2008, LABELED FACES WILD D
   [Anonymous], 2009, Post-Quantum Cryptography, DOI [10.1007/978-3-540-88702-7, DOI 10.1007/978-3-540-88702-7]
   [Anonymous], 2023, Machine Learning is Fun! Part 4: Modern Face Recognition with Deep Learning-by Adam Geitgey-Medium
   Banerjee S, 2019, IEEE INTERNET THINGS, V6, P8739, DOI 10.1109/JIOT.2019.2923373
   Bardet M, 2016, LECT NOTES COMPUT SC, V9606, P118, DOI 10.1007/978-3-319-29360-8_9
   Chakraborty S, 2014, Arxiv, DOI arXiv:1405.2227
   Chauhan Sonam, 2019, Journal of Cyber Security Technology, V3, P189, DOI 10.1080/23742917.2019.1631429
   Chuang CW, 2020, IEEE INT C ELECTR TA, DOI 10.1109/icce-taiwan49838.2020.9258253
   Classic McEliece, 2023, NIST submission
   Delfs H., 2015, Introduction to Cryptography, V3, DOI [10.1007/978-3-662-47974-2, DOI 10.1007/978-3-662-47974-2]
   Dong XB, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3442198
   Franssen T, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P1069, DOI 10.1109/IIH-MSP.2008.315
   Fuller B, 2014, When Are Fuzzy Extractors Possible?, V961
   Gates K.A., 2011, OUR BIOMETRIC FUTURE
   Grother PJ, 2018, ONGOING FACE RECOGNI
   hamme TV, 2022, Lecture Notes in Computer Science, P156, DOI [10.1007/978-3-030-98795-4_8, DOI 10.1007/978-3-030-98795-4_8]
   Alvarez FH, 2009, ADV INTEL SOFT COMPU, V63, P163
   Hsiao CS, 2021, 2021 IEEE 3RD GLOBAL CONFERENCE ON LIFE SCIENCES AND TECHNOLOGIES (IEEE LIFETECH 2021), P144, DOI [10.1109/LIFETECH52111.2021.9391787, 10.1109/LifeTech52111.2021.9391787]
   Hua G, 2022, Facial Recognition Technologies, P475, DOI [10.1007/978-3-319-32010-6_93, DOI 10.1007/978-3-319-32010-6_93]
   Jakobsson M, 2013, SpringerBriefs in Computer Science, P25, DOI [10.1007/978-1-4614-4878-5_3, DOI 10.1007/978-1-4614-4878-5_3]
   Jana A, 2023, Arxiv, DOI arXiv:2003.08433
   Jin Z, 2016, PATTERN RECOGN, V56, P50, DOI 10.1016/j.patcog.2016.02.024
   Jirik P, 2021, The Future of Multi-Factor Biometric Authentication
   Juels A, 2006, DESIGN CODE CRYPTOGR, V38, P237, DOI 10.1007/s10623-005-6343-z
   Juels A, 1999, 6TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P28, DOI 10.1145/319709.319714
   Juels A, 2007, Fuzzy Commitment, P45, DOI [10.1007/978-1-84628-984-2_3, DOI 10.1007/978-1-84628-984-2_3]
   Kinkiri S, 2020, PROCEEDINGS OF THE 2020 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING AND COMMUNICATION ENGINEERING (ICACCE-2020)
   Kirss JM, 2022, Cybernetica AS Maealuse 2/1 12618
   Klima RE, 2018, Cryptology: Classical and Modern, DOI [10.1201/9781315170664, DOI 10.1201/9781315170664]
   Kuznetsov A, 2022, 2022 INT SCI PRACTIC
   Kuznetsov A, 2020, 2020 IEEE 11TH INTERNATIONAL CONFERENCE ON DEPENDABLE SYSTEMS, SERVICES AND TECHNOLOGIES (DESSERT): IOT, BIG DATA AND AI FOR A SAFE & SECURE WORLD AND INDUSTRY 4.0, P172, DOI [10.1109/dessert50317.2020.9125045, 10.1109/DESSERT50317.2020.9125045]
   Kuznetsov A, 2018, 2018 INTERNATIONAL SCIENTIFIC-PRACTICAL CONFERENCE: PROBLEMS OF INFOCOMMUNICATIONS SCIENCE AND TECHNOLOGY (PIC S&T), P119, DOI 10.1109/INFOCOMMST.2018.8632040
   Kuznetsova AA, 2021, IEEE NW RUSS YOUNG, P494, DOI 10.1109/ElConRus51938.2021.9396336
   Li N, 2017, INT CON DISTR COMP S, P667, DOI 10.1109/ICDCS.2017.107
   Libby C, 2021, J MED SYST, V45, DOI 10.1007/s10916-021-01723-w
   Lint JH, 1988, CLASSICAL GOPPA CODE, P22, DOI [10.1007/978-3-0348-9286-5_5, DOI 10.1007/978-3-0348-9286-5_5]
   Liu ZW, 2015, Arxiv, DOI [arXiv:1411.7766, 10.48550/arXiv.1411.7766]
   Lutsenko M., 2021, C MATH CONTR THEOR, P66, DOI [10.1007/978-3-030-58359-0_5, DOI 10.1007/978-3-030-58359-0_5]
   Lutsenko M, 2019, 2019 INT C INFORM TE, P1, DOI [10.1109/UkrMiCo47782.2019.9165457, DOI 10.1109/UKRMICO47782.2019.9165457]
   McEliece R. J., 1978, DGN Progres Report 42-44, P114, DOI 10.1109/JPHOT.2021.3069510
   Menezes A. J., 2018, HDB APPL CRYPTOGRAPH, DOI DOI 10.1201/9780429466335
   Moody D, 2016, LECT NOTES COMPUT SC, V9606, P104, DOI 10.1007/978-3-319-29360-8_8
   Nunes IDO, 2022, Report Number: 1030
   Overbeck R., 2009, Code-based cryptography, P95
   Pane A, 2022, Biometric Cryptography, P3, DOI [10.1007/978-3-031-10706-1_1, DOI 10.1007/978-3-031-10706-1_1]
   Post-Quantum Cryptography, 2016, Lecture Notes in Computer Science, V9606, DOI [10.1007/978-3-319-29360-8http://link.springer.com/10.1007/978-3-319-29360-8, DOI 10.1007/978-3-319-29360-8HTTP://LINK.SPRINGER.COM/10.1007/978-3-319-29360-8]
   Qin Z, 2021, IEEE T FUZZY SYST, V29, P549, DOI 10.1109/TFUZZ.2019.2956896
   Rathgeb C, 2021, Arxiv, DOI arXiv:2102.02458
   Rathgeb C, 2011, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2011-3
   Rubinstein-Salzedo S., 2018, Cryptography, DOI DOI 10.1007/978-3-319-94818-8
   Rui Z, 2019, IEEE ACCESS, V7, P5994, DOI 10.1109/ACCESS.2018.2889996
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sendrier N, 2011, Niederreiter Encryption Scheme, P842, DOI [10.1007/978-1-4419-5906-5_385, DOI 10.1007/978-1-4419-5906-5_385]
   Shafkat I, 2019, Inverting Facial Recognition Models
   Sutcu Y, 2009, PROC SPIE, V7306, DOI 10.1117/12.820571
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Uludag U, 2005, LECT NOTES COMPUT SC, V3546, P310
   Uludag U, 2004, P IEEE, V92, P948, DOI 10.1109/JPROC.2004.827372
   Valderrama W, 2022, IEEE LAT AM T, V20, P875, DOI 10.1109/TLA.2022.9757369
   von Maurich I, 2016, LECT NOTES COMPUT SC, V9606, P1, DOI 10.1007/978-3-319-29360-8_1
   Wang GC, 2021, NEUROCOMPUTING, V458, P416, DOI 10.1016/j.neucom.2021.06.033
   Wang W, 2018, LECT NOTES COMPUT SC, V10786, P77, DOI 10.1007/978-3-319-79063-3_4
   Zhang K, 2021, Report Number: 1559
NR 65
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 14
PY 2023
DI 10.1007/s11042-023-17714-7
EA DEC 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ4D9
UT WOS:001122246300003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ranasinghe, N
AF Ranasinghe, Nimesha
TI Virtual taste: digital simulation of taste sensations via electric,
   thermal, and hybrid stimulations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Gustation; Taste; Virtual taste; Taste media; Digital media; Virtual
   reality
ID EXPERIENCE-INDUCED CHANGES; TONGUE; IDENTIFICATION; SENSITIVITY; SYSTEM
AB This paper introduces the Virtual Taste Interface, a digital control system that simulates the sensation of taste (gustation) on humans. Our approach studies electrical and thermal stimulation on the tip of the human tongue to produce different taste sensations. It consists of two modules: a control system and a specially designed separate module to attach to a user's tongue. Several experimental studies were conducted with human participants based on 1) different properties of electrical stimulation such as the magnitude of current and frequency, 2) temperature change (heating and cooling), and 3) hybrid stimulation by combining both electrical and thermal stimulation. Experimental results show that the system successfully generates salty, sour, and bitter tastes among the five basic taste sensations (i.e., salty, sour, sweet, bitter, and umami). This approach deserves future investigation as the reported sensations show subjective results on a few occasions and to further study the evidence of actuating sweet taste through thermal stimulation. The novelty of this work primarily has three aspects: 1) studying the simulation and control of taste sensations achievable through the Virtual Taste Interface against the properties of electric current and change in temperature, 2) the methods of actuating taste sensations by electrical and thermal stimulation methods, either individually or in combination, and 3) the aim of introducing the human sense of taste as a digitally controllable media.
C1 [Ranasinghe, Nimesha] Univ Maine, Sch Comp & Informat Sci, 5711 Boardman Hall, Orono, ME 04469 USA.
C3 University of Maine System; University of Maine Orono
RP Ranasinghe, N (corresponding author), Univ Maine, Sch Comp & Informat Sci, 5711 Boardman Hall, Orono, ME 04469 USA.
EM r.ranasinghe@maine.edu
OI Ranasinghe, Nimesha/0000-0003-3962-8084
CR [Anonymous], Technical data sheets: LR white embedding medium
   AVIV JE, 1992, OTOLARYNG HEAD NECK, V107, P418, DOI 10.1177/019459989210700313
   Breslin PAS, 2006, ADV OTO-RHINO-LARYNG, V63, P152, DOI 10.1159/000093760
   Cruz A, 2000, NATURE, V403, P889, DOI 10.1038/35002581
   Delwiche J, 1996, TRENDS FOOD SCI TECH, V7, P411, DOI 10.1016/S0924-2244(96)20010-X
   DePuy V., 2014, Counterbalancing
   Derbyshire D, 2009, Revealed: The headset that will mimic all five senses and make the virtual world as convincing as real life
   Eisenstein M, 2010, NATURE, V468, pS18, DOI 10.1038/468S18a
   Erickson RP, 2008, BEHAV BRAIN SCI, V31, P59, DOI 10.1017/S0140525X08003348
   Firestein S, 2001, NATURE, V413, P211, DOI 10.1038/35093026
   Fischer U., 1994, Food Quality and Preference, V5, P55, DOI 10.1016/0950-3293(94)90008-6
   Frank GKW, 2008, NEUROIMAGE, V39, P1559, DOI 10.1016/j.neuroimage.2007.10.061
   FRANK RA, 1989, CHEM SENSES, V14, P371, DOI 10.1093/chemse/14.3.371
   Grabenhorst F, 2008, EUR J NEUROSCI, V27, P723, DOI 10.1111/j.1460-9568.2008.06033.x
   Hai ZG, 2005, COMPUTER, V38, P27, DOI 10.1109/MC.2005.142
   Jain R, 2001, COMMUN ACM, V44, P38, DOI 10.1145/365181.365186
   Khot RA, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6593, DOI 10.1145/3025453.3025980
   Khot RA, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2933, DOI 10.1145/2702123.2702197
   Kobayashi C, 2006, CHEM SENSES, V31, P301, DOI 10.1093/chemse/bjj033
   Kobayashi C, 2002, PHYSIOL BEHAV, V75, P57, DOI 10.1016/S0031-9384(01)00634-5
   KOCHER EC, 1969, PERCEPT MOTOR SKILL, V28, P735, DOI 10.2466/pms.1969.28.3.735
   Kortum P, 2008, HCI beyond the GUI: design for haptic, speech, olfactory and other nontraditional interfaces, P291
   Kundu PK., 2011, Instrumentation and Measurement, IEEE Transactions on, V99, P1
   Lackovic I, 2007, IFMBE PROC, V17, P154
   Lawless H.T., 2010, SENSORY EVALUATION F, V2nd, P19, DOI [10.1007/978-1-4419-6488-5_2, DOI 10.1007/978-1-4419-6488-5_2]
   Lawless HT, 2005, CHEM SENSES, V30, P185, DOI 10.1093/chemse/bji014
   Lindemann B, 2001, NATURE, V413, P219, DOI 10.1038/35093032
   Loucks CA, 2004, PHYSIOL BEHAV, V81, P1, DOI 10.1016/j.physbeh.2003.12.014
   Maynes-aminzade D, 2005, P 2005 ACM C HUM FAC
   MCBURNEY DH, 1979, PSYCHOL BULL, V86, P151, DOI 10.1037/0033-2909.86.1.151
   Mojet J, 2004, CHEM SENSES, V29, P671, DOI 10.1093/chemse/bjh070
   Moriguchi M, 2004, IEEE T APPL SUPERCON, V14, P1786, DOI 10.1109/TASC.2004.831096
   Nakamura H., 2012, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P517, DOI DOI 10.1145/2207676.2207747
   Nakamura H, 2021, IEEE ACCESS, V9, P47603, DOI 10.1109/ACCESS.2021.3068263
   Nakamura Hiromi, 2013, P 5 INT WORKSH MULT, P9, DOI [DOI 10.1145/2506023.2506026, 10.1145/2506023.2506026]
   Nakamura Hiromi., 2011, Proceedings of the 2Nd Augmented Human International Conference, V34, P1, DOI [DOI 10.1145/1959826.1959860, 10.1145/1959826.1959860]
   O'Mahony M., 1986, J Sens Stud, V1, P237, DOI DOI 10.1111/J.1745-459X.1986.TB00176.X
   Palit M, 2010, IEEE T INSTRUM MEAS, V59, P2230, DOI 10.1109/TIM.2009.2032883
   PLATTIG KH, 1976, PFLUG ARCH EUR J PHY, V361, P115, DOI 10.1007/BF00583454
   PLEASONT.AK, 1970, J SPEECH HEAR RES, V13, P635, DOI 10.1044/jshr.1303.635
   Ranasinghe Nimesha, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P296, DOI 10.1145/3382507.3418862
   Ranasinghe N., 2014, Proceedings of the 2nd ACM International Workshop on Immersive Media Experiences, P7, DOI [10.1145/2660579, DOI 10.1145/2660579]
   Ranasinghe N, 2019, FOOD RES INT, V117, P60, DOI 10.1016/j.foodres.2018.05.030
   Ranasinghe N, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2996462
   Ranasinghe N, 2016, MULTIMED TOOLS APPL, V75, P12291, DOI 10.1007/s11042-015-3162-8
   Ratner BD, 2009, Biomedical Engineering e-Mega Reference, P377
   SALATA JA, 1991, CHEM SENSES, V16, P483, DOI 10.1093/chemse/16.5.483
   Shepherd GM, 2006, NATURE, V444, P316, DOI 10.1038/nature05405
   Simner J, 2010, PERCEPTION, V39, P553, DOI 10.1068/p6591
   Simonelli M, 2019, NEUROREHABILITATION, V44, P103, DOI 10.3233/NRE-182526
   Smith D., 2006, Making sense of taste. Special Editions, V16, P84
   Snyder GJ, 2006, P IEEE SEMICOND THER, P135, DOI 10.1109/STHERM.2006.1625219
   Stillman JA, 2003, CLIN OTOLARYNGOL, V28, P406, DOI 10.1046/j.1365-2273.2003.00729.x
   Suzuki C., 2014, ACM International Conference Proceeding Series, V2014-November, P1, DOI [10.1145/2663806.2663825, DOI 10.1145/2663806.2663825]
   Talavera K, 2005, NATURE, V438, P1022, DOI 10.1038/nature04248
   Tanaka S, 2022, IEEE INT SYMP M AU R, P704, DOI 10.1109/ISMAR-Adjunct57072.2022.00147
   Teh J. K. S., 2008, P 7 INT C INT DES CH, P250, DOI DOI 10.1145/1463689.1463763
   Tomita H, 1986, Auris Nasus Larynx, V13 Suppl 1, pS1
   Trivedi B.P., 2012, Nature, V486
   Volta A., 1800, Phil. Mag, V8, P289
   Wang W, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6123, DOI 10.1145/3025453.3026019
   Ziccardi VB, 2012, J ORAL MAXIL SURG, V70, P289, DOI 10.1016/j.joms.2011.08.019
NR 62
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 12
PY 2023
DI 10.1007/s11042-023-17690-y
EA DEC 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CG2W2
UT WOS:001124043200007
DA 2024-07-18
ER

PT J
AU Li, Y
   Xia, GE
   Wang, S
   Li, Y
AF Li, Yun
   Xia, Guoen
   Wang, Su
   Li, Ying
TI A deep multimodal autoencoder-decoder framework for customer churn
   prediction incorporating chat-GPT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Customer churn prediction; Deep learning; Multimodal fusion;
   Encoder-decoder
AB Accurate customer churn prediction are increasingly crucial in improving customer retention and corporate revenue. The collected customer churn data generally exhibits the classical multimodal property, i.e., different types of user behaviors. However, existing customer churn prediction methods fail to capture more meaningful details of multimodal interaction resulting in unideal customer churn prediction accuracy. Specifically, to better deal with the heterogeneity and consistency problems in the acquired multimodal data, in this paper we propose a multimodal autoencoder-decoder framework for customer churn prediction model, which is referred to as MFCCP. By using Chat-GPT to analyze detailed data predicted as lost customers, we aim to customize targeted solutions to recover customers.First, the features under numerical and textual characteristics that reflect user behavior cues are characterized by a feature encoding network (FE-Net) module to condense the most relevant information for each modality. We then construct a multimodal fusion network (MF-Net) that effectively captures the cross-modal interactions to integrate modality-specific representations. Finally, the multimodal feature reconstruction network (MFR-Net) is selected to decode the fused representations into target modalities, ensuring that the reconstructed results closely resemble the original ones. The experimental results show that the proposed method has higher accuracy and better generalization compared with current customer prediction methods.Incorporating Chat-GPT into the MFCCP framework enables businesses to make informed decisions and take proactive measures to retain valuable customers, ultimately driving revenue growth.
C1 [Li, Yun; Li, Ying] Guangxi Univ Finance & Econ, Sch Big Data & Artificial Intelligence, Mingxiu West Road, Nanning 530000, Guangxi, Peoples R China.
   [Xia, Guoen] Guangxi Univ, Business Sch, Univ East Rd, Nanning 530000, Guangxi, Peoples R China.
   [Wang, Su] Guangxi Minzu Univ, Coll Elect Informat, Univ East Rd, Nanning 530000, Guangxi, Peoples R China.
C3 Guangxi University of Finance & Economics; Guangxi University; Guangxi
   Minzu University
RP Xia, GE (corresponding author), Guangxi Univ, Business Sch, Univ East Rd, Nanning 530000, Guangxi, Peoples R China.
EM iyun@guat.edu.cn; xia2022guoen@163.com; ws13773458384@163.com;
   lilyannO@1utar.my
FU National Natural Science Foundation of China [71862003]; National
   Natural Science Foundation of China [BS2021025]; Doctoral Initiation
   Fund
FX We acknowledge the assistance of Guangxi Big Data Analysis of Taxation
   Research Center of Engineering in performing the experiments. This work
   was supported by the National Natural Science Foundation of
   China(71862003) and Doctoral Initiation Fund (BS2021025).
CR Acharya UK, 2021, OPTIK, V230, DOI 10.1016/j.ijleo.2021.166273
   Aggarwal S, 2022, SCI PROGRAMMING-NETH, V2022, DOI 10.1155/2022/1757888
   Ahmad F, 2023, OPT MEMORY NEURAL, V32, P126, DOI 10.3103/S1060992X23020091
   Banerjee I., 2022, Internet of Things and Analytics for Agriculture, P165, DOI [10.1007/978-981-16-6210-2_8, DOI 10.1007/978-981-16-6210-2_8]
   Bhushanamu MB., 2020, Eur J Mol Clin Med, V7, P2020
   Demir A, 2019, 2019 MEDICAL TECHNOLOGIES CONGRESS (TIPTEKNO), P533, DOI [10.1109/tiptekno47231.2019.8972045, 10.1109/CLEOE-EQEC.2019.8871518]
   Feng LW, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12122028
   Islam M, 2023, J AGR FOOD RES, V14, DOI 10.1016/j.jafr.2023.100764
   kaggle, US
   Kakarla SC., 2022, Unmanned aerial systems in precision agriculture, P1
   Karthick S, 2024, NATL ACAD SCI LETT, V47, P279, DOI 10.1007/s40009-023-01353-5
   Katta S, 2022, AI, Edge and IoT-based smart agriculture: Intelligent data-centric systems, P143, DOI [10.1016/B978-0-12-823694-9.00019-0, DOI 10.1016/B978-0-12-823694-9.00019-0]
   Kaur S., 2022, Synthesis and applications of nanoparticles, P319
   Lu YZ, 2022, COMPUT ELECTRON AGR, V200, DOI 10.1016/j.compag.2022.107208
   Mithra S, 2024, APPL GEOMAT, V16, P315, DOI 10.1007/s12518-022-00425-3
   Muangprathub J, 2019, COMPUT ELECTRON AGR, V156, P467, DOI 10.1016/j.compag.2018.12.011
   Park CR, 2020, NUCL ENG TECHNOL, V52, P2328, DOI 10.1016/j.net.2020.03.022
   Parvathi S, 2021, BIOSYST ENG, V202, P119, DOI 10.1016/j.biosystemseng.2020.12.002
   Patil MA, 2022, ECOL INFORM, V70, DOI 10.1016/j.ecoinf.2022.101752
   Qu Z, 2020, IEEE ACCESS, V8, P54564, DOI 10.1109/ACCESS.2020.2981561
   Raghuvanshi A, 2022, J FOOD QUALITY, V2022, DOI 10.1155/2022/3955514
   Razfar N, 2022, J AGR FOOD RES, V8, DOI 10.1016/j.jafr.2022.100308
   Rehman ZU, 2021, IET IMAGE PROCESS, V15, P2157, DOI 10.1049/ipr2.12183
   Saha HN, 2021, Smart agriculture automation using advanced technologies. Transactions on computer systems and networks, DOI [10.1007/978-981-16-6124-2_5, DOI 10.1007/978-981-16-6124-2_5]
   Singh G., 2022, 2022 IEEE DELH SECT, P1, DOI [10.1109/DELCON54057.2022.9753021, DOI 10.1109/DELCON54057.2022.9753021]
   Singh P, 2021, J REAL-TIME IMAGE PR, V18, P1711, DOI 10.1007/s11554-020-01060-0
   Thirukkumaran R, 2022, 2022 IEEE INT C ADV, P1, DOI [10.1109/ICONAT53423.2022.9726043, DOI 10.1109/ICONAT53423.2022.9726043]
   Waheed H, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12060742
   Wei YY, 2021, IEEE ACCESS, V9, P146810, DOI 10.1109/ACCESS.2021.3123791
   Zhang ZC, 2022, COMPUT ELECTRON AGR, V193, DOI 10.1016/j.compag.2021.106682
NR 30
TC 0
Z9 0
U1 10
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 11
PY 2023
DI 10.1007/s11042-023-17715-6
EA DEC 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ2A4
UT WOS:001122190800011
DA 2024-07-18
ER

PT J
AU Zhang, RZ
   Wang, XH
AF Zhang, Rongze
   Wang, Xiuhui
TI Commodity classification in livestreaming marketing based on a
   conv-transformer network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Commodity classification; Convolutional neural network; Layered
   transformer network; Parallel feature extraction network
ID QUERY EXPANSION; RETRIEVAL; FEEDBACK
AB To obtain category information of goods in livestreaming marketing, we designed a recognition algorithm based on an improved transformer network that obtains the category of goods in live broadcast marketing via real-time detection of video images. First, based on the proposed parallel network structure, the local characteristics of the convolution module and global characteristics of the transformer module were merged, enriching the overall characteristics of the backbone network. Second, two different levels of global attention modules were used to calculate the feature map in groups to optimize the transfer module structure. The experimental results demonstrated that, under the same detector conditions, the detection accuracy and network parameters of the feature extraction network proposed in this paper was significantly improved. Furthermore, the detection effect on the commodity detection task in livestreaming marketing scene was significant.
C1 [Zhang, Rongze; Wang, Xiuhui] China Jiliang Univ, Coll Informat Engn, Hangzhou 310018, Peoples R China.
C3 China Jiliang University
RP Wang, XH (corresponding author), China Jiliang Univ, Coll Informat Engn, Hangzhou 310018, Peoples R China.
EM wangxiuhui@cjlu.edu.cn
RI Sharaff, Aakanksha/L-9995-2016
OI Sharaff, Aakanksha/0000-0001-5499-7289; Wang, Xiuhui/0000-0003-1773-9760
FU National Key Research and Development Program; Natural Science
   Foundation of Zhejiang Province [LY20F020018];  [2021YFC3340402]
FX This work was supported by National Key Research and Development Program
   (No.2021YFC3340402) and Natural Science Foundation of Zhejiang Province
   (No. LY20F020018).
CR Abacha A.B., 2016, TREC
   Balaneshin-Kordan S, 2015, TREC
   Balaneshinkordan S, 2019, J BIOMED INFORM, V98, DOI 10.1016/j.jbi.2019.103238
   Bhopale AP, 2020, EXPERT SYST APPL, V154, DOI 10.1016/j.eswa.2020.113441
   Bouadjenek MR, 2017, DATABASE-OXFORD, DOI 10.1093/database/bax062
   Cohen T, 2017, DATABASE-OXFORD, DOI 10.1093/database/bax061
   Djenouri Y, 2018, EXPERT SYST APPL, V94, P126, DOI 10.1016/j.eswa.2017.10.042
   El Mahdaouy A, 2018, INT J SPEECH TECHNOL, V21, P121, DOI 10.1007/s10772-018-9492-y
   Gurulingappa H., 2016, Text Retrieval Conference
   Khennak I, 2017, APPL INTELL, V47, P793, DOI 10.1007/s10489-017-0924-1
   Kroll H, 2023, Int J Digital Libraries
   Maia J.E.B., 2019, J DIGITAL INFORM MAN, V17, P313, DOI DOI 10.6025/JDIM/2019/17/6/313-320
   Mao J, 2015, INFORM RETRIEVAL J, V18, P413, DOI 10.1007/s10791-015-9264-0
   Marchesin S, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102109
   Milliken LK, 2019, J BIOMED INFORM, V95, DOI 10.1016/j.jbi.2019.103224
   Oh HS, 2015, J BIOMED INFORM, V58, P70, DOI 10.1016/j.jbi.2015.09.017
   Sankhavara J., 2018, P ACL 2018 MELB AUST, P84
   Sankhavara J, 2020, SN Computer Science, V1, DOI [10.1007/s42979-020-0069-x,1:75, DOI 10.1007/S42979-020-0069-X,1:75]
   Sankhavara J, 2020, J BIOMED INFORM, V108, DOI 10.1016/j.jbi.2020.103493
   Sarrouti M, 2017, J BIOMED INFORM, V68, P96, DOI 10.1016/j.jbi.2017.03.001
   Shirzad MB, 2018, INT J INF RETR RES, V8, P46, DOI 10.4018/IJIRR.2018070104
   Soldaini L, 2017, J ASSOC INF SCI TECH, V68, P2602, DOI 10.1002/asi.23924
   Sondhi P, 2012, J AM MED INFORM ASSN, V19, P851, DOI 10.1136/amiajnl-2011-000293
   Tamine L, 2015, J ASSOC INF SCI TECH, V66, P2626, DOI 10.1002/asi.23351
   Thakur N., 2019, Int J Recent Technol Eng, V8, P1723
   Torjmen-Khemakhem M, 2019, J BIOMED INFORM, V95, DOI 10.1016/j.jbi.2019.103210
   Vikram M, 2018, 32 C NEUR INF PROC S
   Xu B, 2018, IEEE ACM T COMPUT BI, V15, P1797, DOI 10.1109/TCBB.2016.2578337
   Xu B, 2016, J ASSOC INF SCI TECH, V67, P1345, DOI 10.1002/asi.23476
   Yang CH, 2017, DATA SCI ENG, V2, P316, DOI 10.1007/s41019-017-0052-2
   Yang JL, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9183658
   Yu ZG, 2016, J BIOMED INFORM, V61, P77, DOI 10.1016/j.jbi.2016.03.013
   Zhao YQ, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0954-1
NR 33
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 11
PY 2023
DI 10.1007/s11042-023-17786-5
EA DEC 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ2A4
UT WOS:001122190800013
DA 2024-07-18
ER

PT J
AU An, Y
   Jing, JF
   Li, XW
   Zhang, JQ
   Bao, JM
AF An, Ying
   Jing, Junfeng
   Li, Xuewei
   Zhang, Jiaqi
   Bao, Junmin
TI An exclusive U-net for fine and crisp edge detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Edge detection; Convolution neural networks; Edge stretching effect;
   Attention mechanism
AB Edge detection is a fundamental task in digital image processing, in this paper, we propose an algorithm specifically for fine and sharp edge detection, which can provide more valuable information and expand the application area of detectors. Existing edge detectors based on Convolution Neural Networks (CNNs) commonly suffer from edge stretching effects, and the over-penalization on edges, feature mixing, and similar response of pixels all cause the thick edges. In this paper, we use two approaches to access crisper edges, one mitigates the penalty of traditional loss function on edges, and the other considers the difference characteristics between deep and shallow layers using a customized loss function, which focus on suppressing backgrounds at shallow layers and tracking contours at deep layers. We insert distinctive attention mechanism and multi-scale enhancement modules in skip-connection to keep the network focusing on edges while reducing computational costs. Moreover, we propose the bottom-up architecture and attention-based feature fusion to facilitate feature flow in both vertical and horizontal, the dependency and complementarity of edges in different layers are also enhanced. In experiments, training our detection network with only the BIPED dataset and achieving the best results (ODS F-score of 0.861), the visual results on the BSDS500 dataset and the NYUDv2 dataset show complete crisp edges, which is consistent with our goal.
C1 [An, Ying; Jing, Junfeng; Li, Xuewei; Zhang, Jiaqi; Bao, Junmin] Xian Polytech Univ, Sch Elect Informat, 19 Jinhua South Rd, Xian 710048, Shaanxi, Peoples R China.
   [Jing, Junfeng] Xian Polytech Univ, Branch Shaanxi Artificial Intelligence Joint Lab, Xian 710048, Shaanxi, Peoples R China.
C3 Xi'an Polytechnic University; Xi'an Polytechnic University
RP Jing, JF (corresponding author), Xian Polytech Univ, Sch Elect Informat, 19 Jinhua South Rd, Xian 710048, Shaanxi, Peoples R China.; Jing, JF (corresponding author), Xian Polytech Univ, Branch Shaanxi Artificial Intelligence Joint Lab, Xian 710048, Shaanxi, Peoples R China.
EM yingan3356@163.com; jingjunfeng0718@sina.com; lxuewei1210@163.com;
   n_zhangjiaqi@163.com; sunshine6126@163.com
RI zhang, jiaqi/JNR-7443-2023
OI zhang, jiaqi/0000-0001-8888-9542; Jing, Junfeng/0000-0001-6646-3698
FU Innovation Capability Support Program of Shaanxi; Youth Innovation Team
   of Shaanxi Universities; National Natural Science Foundation of China
   [62176204]; Key Research and Development Plan of Shaanxi Province
FX This work was supported in part by Innovation Capability Support Program
   of Shaanxi (No.2021TD-29), in part by the Youth Innovation Team of
   Shaanxi Universities, in part by the National Natural Science Foundation
   of China (No.62176204) and in part by the Key Research and Development
   Plan of Shaanxi Province(No.2022GY-066).
CR Akbarinia A, 2018, INT J COMPUT VISION, V126, P1367, DOI 10.1007/s11263-017-1035-5
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bao SS, 2022, IEEE ACCESS, V10, P26282, DOI 10.1109/ACCESS.2022.3146339
   Bertasius G, 2015, IEEE I CONF COMP VIS, P504, DOI 10.1109/ICCV.2015.65
   Bertasius G, 2015, PROC CVPR IEEE, P4380, DOI 10.1109/CVPR.2015.7299067
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Deng RX, 2018, LECT NOTES COMPUT SC, V11210, P570, DOI 10.1007/978-3-030-01231-1_35
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Dollár P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715
   Fang T, 2021, MULTIMED TOOLS APPL, V80, P1611, DOI 10.1007/s11042-020-09800-x
   Florindo JB, 2021, MULTIMED TOOLS APPL, V80, P29177, DOI 10.1007/s11042-021-10959-0
   Ganin Y, 2015, LECT NOTES COMPUT SC, V9004, P536, DOI 10.1007/978-3-319-16808-1_36
   Gupta S, 2013, PROC CVPR IEEE, P564, DOI 10.1109/CVPR.2013.79
   Hallman S, 2015, PROC CVPR IEEE, P1732, DOI 10.1109/CVPR.2015.7298782
   He JZ, 2019, PROC CVPR IEEE, P3823, DOI 10.1109/CVPR.2019.00395
   Huan L., 2021, IEEE Trans Pattern Anal Mach Intell
   Jeevitha S, 2021, J AMB INTEL HUM COMP, V12, P3373, DOI 10.1007/s12652-020-02399-9
   Kokkinos I, 2016, Arxiv, DOI arXiv:1511.07386
   Li K, 2018, J COMPUT SCI TECH-CH, V33, P223, DOI 10.1007/s11390-017-1764-5
   Lim JJ, 2013, PROC CVPR IEEE, P3158, DOI 10.1109/CVPR.2013.406
   Liu Y, 2016, PROC CVPR IEEE, P231, DOI 10.1109/CVPR.2016.32
   Liu Y, 2022, INT J COMPUT VISION, V130, P179, DOI 10.1007/s11263-021-01539-8
   Liu Y, 2019, IEEE T PATTERN ANAL, V41, P1939, DOI 10.1109/TPAMI.2018.2878849
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Mishra SK, 2021, MULTIMED TOOLS APPL, V80, P29965, DOI 10.1007/s11042-021-11187-2
   Mottaghi R, 2014, PROC CVPR IEEE, P891, DOI 10.1109/CVPR.2014.119
   Pu MY, 2022, PROC CVPR IEEE, P1392, DOI 10.1109/CVPR52688.2022.00146
   Rao SN, 2024, MULTIMED TOOLS APPL, V83, P15267, DOI 10.1007/s11042-021-11502-x
   Ren X, 2012, ADV NEURAL INFORM PR, P584, DOI DOI 10.1634/THEONCOLOGIST.8-3-252
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shen W, 2015, PROC CVPR IEEE, P3982, DOI 10.1109/CVPR.2015.7299024
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Soria X, 2020, IEEE WINT CONF APPL, P1912, DOI 10.1109/WACV45572.2020.9093290
   Su Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5097, DOI 10.1109/ICCV48922.2021.00507
   Wang R, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13060921
   Wang Y, 2021, SIGNAL IMAGE VIDEO P, V15, P1635, DOI 10.1007/s11760-021-01899-1
   Wang YP, 2017, PROC CVPR IEEE, P1724, DOI 10.1109/CVPR.2017.187
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yang JM, 2016, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.2016.28
   Zhang YF, 2020, MULTIMED TOOLS APPL, V79, P9543, DOI 10.1007/s11042-019-08035-9
NR 42
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 7
PY 2023
DI 10.1007/s11042-023-17706-7
EA DEC 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AC0T4
UT WOS:001116150800005
DA 2024-07-18
ER

PT J
AU Bansal, A
   Garg, NK
AF Bansal, Anam
   Garg, Naresh Kumar
TI Robust technique for environmental sound classification using
   convolutional recurrent neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Environmental sound classification; Feature extraction; Machine
   learning; Deep learning; Convolutional recurrent neural networks
ID RECOGNITION; IMAGE
AB Environmental sound classification(ESC) is one of the challenging issues in the area of audio recognition. Classifying the sounds such as glass breaking, gunshots, dog barking can aid in a variety of applications like audio surveillance, smart homes, robotic navigation, and other crime investigation systems. Environmental sounds are more complicated as compared to speech and music due to their unstructured nature. Environ- mental sounds are classified using machine learning algorithms such as Support Vector Machines, K-Nearest Neighbour, and various deep learn- ing algorithms such as Convolutional Neural Networks, Recurrent Neural Networks, Long Short Term Memory Neural Networks. In this paper, a robust approach is proposed for ESC on the UrbanSound8k dataset. Cep- stral features Mel Frequency Cepstral Coefficients are extracted from the audios and fed to the Convolutional Recurrent Neural Network (CRNN). The effect of varying various hyperparameters such as the number of layers, batch size, and filter count are analyzed to determine the ade- quate combination of parameters that can give considerable accuracy for ESC. The proposed approach is compared to the baseline models and it attains the best accuracy of 93.58% which is higher than the previ- ous research results of ESC. The proposed model gives the best results using one LSTM layer, 0.3 momentum value, 512 number of filters, 512 neurons in LSTM layer and 256 batch size. The proposed framework can be ameliorated by using novel neural networks and combinations.
C1 [Bansal, Anam; Garg, Naresh Kumar] Maharaja Ranjit Singh Punjab Tech Univ, GZS Campus Coll Engn & Technol, Comp Sci & Engn, Bathinda 151001, Punjab, India.
RP Bansal, A (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, GZS Campus Coll Engn & Technol, Comp Sci & Engn, Bathinda 151001, Punjab, India.
EM anambansal19@gmail.com
RI Bansal, Anam/ADZ-7763-2022
OI Bansal, Anam/0000-0001-5875-5113
CR Ahmed M.R., 2020, International Journal of Modern Education & Computer Science, V12, P41, DOI [10.5815/ijmecs.2020.05.04, DOI 10.5815/IJMECS.2020.05.04]
   Al-Hattab YA, 2021, NEURAL COMPUT APPL, V33, P14495, DOI 10.1007/s00521-021-06091-7
   Arslan Y., 2017, ASTES J, V2, P145, DOI [10.25046/aj020618, DOI 10.25046/AJ020618]
   Barchiesi D, 2015, IEEE SIGNAL PROC MAG, V32, P16, DOI 10.1109/MSP.2014.2326181
   Boddapati V, 2017, PROCEDIA COMPUT SCI, V112, P2048, DOI 10.1016/j.procs.2017.08.250
   Bountourakis V, 2015, PROCEEDINGS OF THE 10TH AUDIO MOSTLY: A CONFERENCE ON INTERACTION WITH SOUND, AM'15, DOI 10.1145/2814895.2814905
   Brodie S, 2020, ECOL INDIC, V119, DOI 10.1016/j.ecolind.2020.106852
   BROWNING E., 2017, PASSIVE ACOUSTIC MON
   Bubashait Mohamed, 2021, 2021 International Conference on Innovation and Intelligence for Informatics, Computing, and Technologies (3ICT), P46, DOI 10.1109/3ICT53449.2021.9581339
   Chandrakala S, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3322240
   Chen Y, 2019, APPL ACOUST, V148, P123, DOI 10.1016/j.apacoust.2018.12.019
   Chi ZJ, 2019, PROCEEDINGS OF 2019 IEEE 7TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT 2019), P251, DOI [10.1109/iccsnt47585.2019.8962462, 10.1109/ICCSNT47585.2019.8962462]
   Chu S, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P885, DOI 10.1109/ICME.2006.262661
   Dai W, 2017, INT CONF ACOUST SPEE, P421, DOI 10.1109/ICASSP.2017.7952190
   Demir F, 2020, IEEE ACCESS, V8, P66529, DOI 10.1109/ACCESS.2020.2984903
   Fan XQ, 2020, MEASUREMENT, V159, DOI 10.1016/j.measurement.2020.107790
   Font F., 2013, P 2013 ACM MULTIMEDI, P411, DOI 10.1145/2502081.2502245
   Gencoglu O, 2014, EUR SIGNAL PR CONF, P506
   Inik O, 2023, APPL ACOUST, V202, DOI 10.1016/j.apacoust.2022.109168
   Karbasi M., 2011, 2011 8th International Conference on Information, Communications Signal Processing, P1
   Khamparia A, 2019, IEEE ACCESS, V7, P7717, DOI 10.1109/ACCESS.2018.2888882
   Küçüktopcu O, 2019, APPL ACOUST, V148, P194, DOI 10.1016/j.apacoust.2018.12.028
   Kun Yao, 2019, 2019 IEEE 19th International Conference on Communication Technology (ICCT), P198, DOI 10.1109/ICCT46805.2019.8947252
   Lezhenin I, 2019, FED CONF COMPUT SCI, P57, DOI 10.15439/2019F185
   Li SB, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8071152
   Mac Aodha O, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1005995
   Madhu A, 2023, IEEE Trans Multimedia
   Mendoza Jose Marie, 2019, Wireless Internet. 11th EAI International Conference, WiCON 2018. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 264), P105, DOI 10.1007/978-3-030-06158-6_11
   Mnasri Z, 2022, MULTIMED TOOLS APPL, V81, P5537, DOI 10.1007/s11042-021-11817-9
   Mohaimenuzzaman M, 2023, PATTERN RECOGN, V133, DOI 10.1016/j.patcog.2022.109025
   Mu WJ, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-01045-4
   Muhammad G., 2010, Proceedings of the Fifth International Conference on Digital Telecommunications (ICDT 2010), P11, DOI 10.1109/ICDT.2010.10
   Mushtaq Z, 2020, APPL ACOUST, V167, DOI 10.1016/j.apacoust.2020.107389
   Ntalampiras S, 2010, Automatic recognition of urban environmental sounds events
   Olvera M, 2021, EUR SIGNAL PR CONF, P281, DOI 10.23919/Eusipco47968.2020.9287436
   Owens A, 2016, LECT NOTES COMPUT SC, V9905, P801, DOI 10.1007/978-3-319-46448-0_48
   Pal D, 2017, IEEE INT SYM MULTIM, P413, DOI 10.1109/ISM.2017.83
   Piczak Karol J., 2015, 2015 IEEE 25th International Workshop on Machine Learning for Signal Processing (MLSP). Proceedings, DOI 10.1109/MLSP.2015.7324337
   Piczak KJ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1015, DOI 10.1145/2733373.2806390
   Raponi S, 2022, MULTIMED TOOLS APPL, V81, P30387, DOI 10.1007/s11042-022-12612-w
   Salamon J, 2017, IEEE SIGNAL PROC LET, V24, P279, DOI 10.1109/LSP.2017.2657381
   Salamon J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1041, DOI 10.1145/2647868.2655045
   Salamon J, 2015, INT CONF ACOUST SPEE, P171, DOI 10.1109/ICASSP.2015.7177954
   Sang J, 2018, EUR SIGNAL PR CONF, P2444, DOI 10.23919/EUSIPCO.2018.8553247
   Sharan RV, 2019, APPL ACOUST, V148, P62, DOI 10.1016/j.apacoust.2018.12.006
   Shen J., 2016, P INT C MULT MOD, P231
   Siderius M., 2021, J. Acoustical Soc. Amer, V150, pA314, DOI [10.1121/10.0008412, DOI 10.1121/10.0008412]
   Sigtia S, 2016, IEEE-ACM T AUDIO SPE, V24, P2096, DOI 10.1109/TASLP.2016.2592698
   Silva B, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9183885
   Singh J., 2019, 2019 INT C SPEECH TE, P1
   SU F., 2011, Proceedings of the 19th ACM international conference on Multimedia, P1389, DOI DOI 10.1145/2072298.2072022
   Tak RN, 2017, LECT NOTES COMPUT SC, V10597, P317, DOI 10.1007/978-3-319-69900-4_40
   Theodorou T, 2015, LECT NOTES ARTIF INT, V9319, P129, DOI 10.1007/978-3-319-23132-7_16
   Ullo SL, 2020, IEEE ACCESS, V8, P124055, DOI 10.1109/ACCESS.2020.3006082
   Uzkent B, 2012, INT J INNOV COMPUT I, V8, P3511
   Valero X., 2012, 2012 P 20 EUROPEAN S
   Van Der Maaten Laurens, 2009, Journal of Machine Learning Research, V10, P13
   Wang JC, 2008, IEEE T AUTOM SCI ENG, V5, P25, DOI 10.1109/TASE.2007.911680
   Wang JC, 2006, IEEE IJCNN, P1731
   Zhan Y, 2014, J AMB INTEL HUM COMP, V5, P77, DOI 10.1007/s12652-012-0122-2
   Zhang HM, 2015, INT CONF ACOUST SPEE, P559, DOI 10.1109/ICASSP.2015.7178031
   Zhang XH, 2017, INT CONF DIGIT SIG
   Zhang ZC, 2021, NEUROCOMPUTING, V453, P896, DOI 10.1016/j.neucom.2020.08.069
   Zhang ZC, 2018, LECT NOTES COMPUT SC, V11257, P356, DOI 10.1007/978-3-030-03335-4_31
NR 64
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 7
PY 2023
DI 10.1007/s11042-023-17066-2
EA DEC 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AC0T4
UT WOS:001116150800002
DA 2024-07-18
ER

PT J
AU Garg, S
   Krishnamurthi, R
AF Garg, Sherry
   Krishnamurthi, Rajalakshmi
TI Transfer learning: a cross domain LSTM way towards sustainable power
   predictive analytics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sustainable energy; Predictive analytics; LSTM; Wind power prediction;
   Solar panel; Transfer learning
ID ACTIVITY RECOGNITION; FAULT-DIAGNOSIS; FRAMEWORK
AB The most prevalent sustainable power generating resource that is reliable and widely installed for household or smaller localities is solar panels. With government subsidies and grants it has much more monetary benefits than rising cost of electricity generated by fossil fuels. However, with very basic working of solar power the power generation and consumption peaks are quite contrasting. Power is generated at peak in the afternoon time and hit its low in the evening and night; but, the usage is at the peak after sun sets. To boot, they can minimize and eventually eliminate the need for electric grid connectivity and create isolated off-grid systems. However, this needs a strong analytics system both pre and post installation of renewable power generation system. Data driven predictive modelling is a prevalent and effective technique but requires sufficient amount of data for training. Furthermore, with the new ventures under consideration for installation this history is either not available or insufficient for training the deep learning (DL) model. Nevertheless, history is available in abundance for older plants or farms with same or similar domains.This paper proposes a novel cross domain LSTM based parameterized transfer learning (TL) model for short term predictive analytics. The model is trained using temporal and uncertain characteristics of wind power NREL data available in sufficiency for training LSTM and used for the predictive analytics of newly built ventures with insufficient data availability. A parameterized transfer technique is applied to two different domains. One has characteristics related to source wind power domain i.e. solar plant and second one is completely unrelated i.e. Electric Vehicle charging station (EVCS). Both the target domains have unrelated tasks from source domain to make predictions using knowledge gained from the source domain. Quantitative analysis of experiments show Root mean square error (RMSE) for solar power domain is improved as high as 517% using TL and for EV domain upto 133%. The results show TL can be a new effective power analytics method across domains with this improved RMSE for cross domain predictive analytics having a target with insufficient historic data.
C1 [Garg, Sherry; Krishnamurthi, Rajalakshmi] Jaypee Inst Informat Technol, Dept Comp Sci Engn & Informat Technol, Sect 62, Noida 201309, Uttar Pradesh, India.
C3 Jaypee Institute of Information Technology (JIIT)
RP Garg, S (corresponding author), Jaypee Inst Informat Technol, Dept Comp Sci Engn & Informat Technol, Sect 62, Noida 201309, Uttar Pradesh, India.
EM garg.sherry@gmail.com; k.rajalakshmi@mail.jiit.ac.in
RI Krishnamurthi, Rajalakshmi/J-3315-2019
OI Krishnamurthi, Rajalakshmi/0000-0001-9661-782X
CR Almonacid-Olleros G, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14053092
   Arief-Ang IB, 2018, ACM T SENSOR NETWORK, V14, DOI 10.1145/3217214
   Bagnall A, 2017, DATA MIN KNOWL DISC, V31, P606, DOI 10.1007/s10618-016-0483-9
   Banda Paul, 2021, Computational Science - ICCS 2021. 21st International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12746), P259, DOI 10.1007/978-3-030-77977-1_20
   Banerjee D, 2019, KNOWL INF SYST, V60, P1693, DOI 10.1007/s10115-019-01337-2
   Benchaira K, 2019, P 4 INT C BIG DAT IN, P1
   Buffelli D, 2021, IEEE SENS J, V21, P13474, DOI 10.1109/JSEN.2021.3067690
   Cama-Pinto D, 2020, DATA BRIEF, V31, DOI 10.1016/j.dib.2020.105823
   Chen HY, 2019, IEEE INT C INTELL TR, P407, DOI [10.1109/itsc.2019.8917098, 10.1109/ITSC.2019.8917098]
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chen YQ, 2019, PERVASIVE MOB COMPUT, V57, P1, DOI 10.1016/j.pmcj.2019.04.004
   Deng J, 2013, INT CONF AFFECT, P511, DOI 10.1109/ACII.2013.90
   Di ZY, 2021, SCI CHINA TECHNOL SC, V64, P481, DOI 10.1007/s11431-020-1679-x
   Fahimi F, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/aaf3f6
   Fan C, 2020, APPL ENERG, V262, DOI 10.1016/j.apenergy.2020.114499
   Fawaz HI, 2018, IEEE INT CONF BIG DA, P1367, DOI 10.1109/BigData.2018.8621990
   Ganin Y, 2016, J MACH LEARN RES, V17
   Genovese A, 2022, IEEE IMTC P, DOI 10.1109/I2MTC48687.2022.9806492
   Goswami S, 2022, NEURAL COMPUT APPL, V34, P16829, DOI 10.1007/s00521-022-07328-9
   Guarino A, 2022, NEURAL COMPUT APPL, V34, P20715, DOI 10.1007/s00521-022-07543-4
   Guo L, 2019, IEEE T IND ELECTRON, V66, P7316, DOI 10.1109/TIE.2018.2877090
   Hasan MJ, 2019, MEASUREMENT, V138, P620, DOI 10.1016/j.measurement.2019.02.075
   Hasan MJ, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8122357
   He Q-Q, 2022, Appl Intell, P1
   Hooshmand A, 2019, E-ENERGY'19: PROCEEDINGS OF THE 10TH ACM INTERNATIONAL CONFERENCE ON FUTURE ENERGY SYSTEMS, P12, DOI 10.1145/3307772.3328284
   Hu QH, 2016, RENEW ENERG, V85, P83, DOI 10.1016/j.renene.2015.06.034
   Jiang WJ, 2018, MOBICOM'18: PROCEEDINGS OF THE 24TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P289, DOI 10.1145/3241539.3241548
   Kearney D., 2019, 2019 30 IR SIGN, P1, DOI DOI 10.1109/issc.2019.8904960
   Kimura N, 2020, WATER-SUI, V12, DOI 10.3390/w12010096
   Li JP, 2020, IEEE T CYBERNETICS, V50, P3281, DOI [10.1109/TPAMI.2019.2929036, 10.1109/TCYB.2019.2904052]
   Li X, 2019, SIGNAL PROCESS, V157, P180, DOI 10.1016/j.sigpro.2018.12.005
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Long MS, 2014, IEEE T KNOWL DATA EN, V26, P1076, DOI 10.1109/TKDE.2013.111
   Lu K, 2018, IOP C SER EARTH ENV, V186, DOI 10.1088/1755-1315/186/5/012020
   Lu WN, 2017, IEEE T IND ELECTRON, V64, P2296, DOI 10.1109/TIE.2016.2627020
   Luo X, 2022, RENEW ENERG, V185, DOI 10.1016/j.renene.2021.12.104
   Marcelino P., 2020, Int. J. Pavement Res. Technol, V13, P154, DOI DOI 10.1007/S42947-019-0096-Z
   Marczewski A, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P529, DOI 10.1145/3126686.3126735
   Martinez M, 2020, IEEE J BIOMED HEALTH, V24, P144, DOI 10.1109/JBHI.2019.2906499
   Matsui S, 2017, EUR SIGNAL PR CONF, P753, DOI 10.23919/EUSIPCO.2017.8081308
   Meiseles A, 2020, IEEE ACCESS, V8, P6190, DOI 10.1109/ACCESS.2019.2963742
   Molina-Cabanillas MA, 2022, KNOWL-BASED SYST, V254, DOI 10.1016/j.knosys.2022.109644
   Mun S, 2017, INT CONF ACOUST SPEE, P796, DOI 10.1109/ICASSP.2017.7952265
   Osband I., 2012, Technical Report
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Qian XY, 2021, IEEE INT CONF BIG DA, P1900, DOI 10.1109/BigData52589.2021.9671850
   Rokni SA, 2021, ACM T DES AUTOMAT EL, V26, DOI 10.1145/3414062
   Sarmas E, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-18516-x
   Shang JC, 2017, IEEE INT CONF MOB, P99, DOI 10.1109/MASS.2017.41
   Shen S, 2020, APPL ENERG, V260, DOI 10.1016/j.apenergy.2019.114296
   Solar Energy Industries Association, 2021, SOL IND RES DAT
   Strodthoff N, 2021, IEEE J BIOMED HEALTH, V25, P1519, DOI 10.1109/JBHI.2020.3022989
   Taleb C, 2023, EVOL INTELL, V16, P1813, DOI 10.1007/s12065-020-00470-0
   U.S. Department of Energy, 2021, Installing and maintaining a small wind electric system
   Ullah S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185030
   van Kasteren TLM, 2010, LECT NOTES COMPUT SC, V6030, P283, DOI 10.1007/978-3-642-12654-3_17
   Vercruyssen V, 2020, AAAI CONF ARTIF INTE, V34, P6054
   Wang JD, 2018, INT CONF PERVAS COMP, P115
   Wang K, 2023, APPL ENERG, V343, DOI 10.1016/j.apenergy.2023.121186
   Wang TY, 2019, IEEE WINT CONF APPL, P367, DOI 10.1109/WACV.2019.00045
   Wen TL, 2019, Arxiv, DOI arXiv:1905.13628
   Wilson G, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1768, DOI 10.1145/3394486.3403228
   Xiao J, 2014, J SYST SCI COMPLEX, V27, P181, DOI 10.1007/s11424-014-3296-1
   Xie JY, 2016, IEEE INT C PROGNOSTI
   Xin Qin, 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3369818
   Xu XZ, 2020, ELECTR ENG, V102, P1371, DOI 10.1007/s00202-020-00930-x
   Xun L, 2022, CATENA, V213, DOI 10.1016/j.catena.2022.106130
   Yang B, 2019, MECH SYST SIGNAL PR, V122, P692, DOI 10.1016/j.ymssp.2018.12.051
   Zhang R, 2017, IEEE ACCESS, V5, P14347, DOI 10.1109/ACCESS.2017.2720965
   Zhu J, 2020, IEEE SENS J, V20, P8394, DOI 10.1109/JSEN.2019.2936932
NR 71
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 30
PY 2023
DI 10.1007/s11042-023-17635-5
EA NOV 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z2YV8
UT WOS:001110791700008
DA 2024-07-18
ER

PT J
AU Bitit, R
   Derhab, A
   Guerroumi, M
   Khan, FA
AF Bitit, Rahmoune
   Derhab, Abdelouahid
   Guerroumi, Mohamed
   Khan, Farrukh Aslam
TI DDoS attack forecasting based on online multiple change points detection
   and time series analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cyber-attack; DDoS; Forecasting; Time series; Change point detection
AB Attack forecasting is a proactive approach to defend against cyber-attacks, as it helps in predicting future threats beforehand. In this paper, we propose a Distributed Denial of Service (DDoS) forecasting system, which is composed of two main components: the forecaster and the forecasting decision-making. The forecaster component uses a novel concept in cyber-attack forecasting, which combines time series forecasting analysis and multiple change points detection. The proposed concept improves forecasting accuracy compared to conventional statistical forecasting techniques, as it considers the abrupt and multiple changes in time series, where the multiple change points detection approach can help with auto-updating the forecasting models. Based on the proposed concept, we combine three time series analysis models and two change point detection algorithms to provide six forecasting method variants. Moreover, we propose an improved forecasting model named Ensemble Forecasting based on Time Series Analysis and Multiple Change Point Detection, which selects at each forecasting step the time series analysis model that exhibits the best accuracy and combines it with the change point detection algorithm. The proposed forecasting methods allow online learning as they can dynamically adapt to new observations. The forecasting decision-making component uses the output of the forecaster component, which is the number of forecasted attack flows and forecasting accuracy, and performs a risk assessment to alert the system administrator and take appropriate countermeasure decisions in advance. Experimentation results on CICDDoS2019 dataset show that the proposed methods significantly improve DDoS forecasting accuracy compared to traditional statistical forecasting models, such as Autoregressive, Exponential Smoothing, and Moving Average.
C1 [Bitit, Rahmoune; Guerroumi, Mohamed] USTHB Univ, Fac Comp Sci, Algiers, Algeria.
   [Derhab, Abdelouahid; Khan, Farrukh Aslam] King Saud Univ, Ctr Excellence Informat Assurance CoEIA, Riyadh, Saudi Arabia.
C3 University Science & Technology Houari Boumediene; King Saud University
RP Bitit, R (corresponding author), USTHB Univ, Fac Comp Sci, Algiers, Algeria.; Derhab, A (corresponding author), King Saud Univ, Ctr Excellence Informat Assurance CoEIA, Riyadh, Saudi Arabia.
EM r_bitit@esi.dz; abderhab@ksu.edu.sa; guerroumi@gmail.com;
   fakhan@ksu.edu.sa
RI Khan, Farrukh Aslam/J-8358-2019; Derhab, Abdelouahid/HHS-1059-2022
OI Khan, Farrukh Aslam/0000-0002-7023-7172; Derhab,
   Abdelouahid/0000-0002-6498-1528
FU Deanship of Scientific Research, King Saud University
FX No Statement Available
CR Ahmed M, 2016, J NETW COMPUT APPL, V60, P19, DOI 10.1016/j.jnca.2015.11.016
   Aihara S, changefinder 0.03
   Almutairi AZ., 2015, Int J Inf Secur Res, V5, P582
   Aminikhanghahi S, 2017, KNOWL INF SYST, V51, P339, DOI 10.1007/s10115-016-0987-z
   [Anonymous], 2020, Cisco annual Internet report (2018-2023) white paper
   [Anonymous], 2021, DIGITAL AROUND THE WORLD
   Downey AB, 2008, Arxiv, DOI arXiv:0812.1237
   Brodsky E., 1993, Nonparametric Methods in Change Point Problems, DOI [10.1007/978-94-015-8163-9, DOI 10.1007/978-94-015-8163-9]
   Brodsky Z, 2020, The Psychology Behind DDoS: Motivations and Methods
   Canadian Institute for Cybersecurity, 2019, DDoS evaluation dataset (CICDDoS2019)
   Chen Y., 2007, DETER
   Cisar P, 2007, INT C INTELL ENG SYS, P51, DOI 10.1109/INES.2007.4283671
   Cox Business, 2019, 12 DDoS Statistics That Should Concern Business Leaders
   Dongwoo Kwon, 2017, 2017 IFIP/IEEE Symposium on Integrated Network and Service Management (IM), P1083, DOI 10.23919/INM.2017.7987432
   Fachkha Claude, 2013, 2013 IEEE 12th International Symposium on Network Computing and Applications (NCA), P110, DOI 10.1109/NCA.2013.13
   Fearnhead P, 2006, STAT COMPUT, V16, P203, DOI 10.1007/s11222-006-8450-8
   Galov Nick, 2021, 39 Jaw-Dropping DDoS Statistics to Keep in Mind for 2021
   GARDNER ES, 1985, J FORECASTING, V4, P1, DOI 10.1002/for.3980040103
   GEURTS M, 1977, J MARKETING RES, V14, P269, DOI 10.2307/3150485
   Gurevich G, SOR 17 P, P314
   Husák M, 2019, IEEE COMMUN SURV TUT, V21, P640, DOI 10.1109/COMST.2018.2871866
   Hyndman Rob J., 2018, Forecasting: principles and practice
   Ilascu I, 2020, Food Delivery Service in Germany Under DDoS Attack
   Jieren Cheng, 2017, International Journal of Autonomous and Adaptive Communications Systems, V10, P38
   Kapitaniak T., 1992, Chaotic Oscillators: Theory and Applications, DOI [10.1142/1402, DOI 10.1142/1402]
   Kott A., 2014, NETWORK SCI CYBERSEC, P1, DOI DOI 10.1007/978-1-4614-7597-2_1
   Kotu V., 2014, Predictive Analytics and Data Mining: Concepts and Practice with RapidMiner, DOI DOI 10.1016/C2014-0-00329-2
   Kulick J., Bayesian changepoint detection
   Kupreev Oleg, 2020, DDoS attacks in Q1 2020
   Kurt B, 2018, DIGIT SIGNAL PROCESS, V77, P48, DOI 10.1016/j.dsp.2017.10.009
   Kwon D, 2012, 2012 14 AS PAC NETW, P1
   LINCOLN LABORATORY MASSACHUSETTS INSTITUTE OF TECHNOLOGY, 2000, 2000 DARPA INTRUSION DETECTION SCENARIO SPECIFIC DATASETS
   Merran Evans BP., 2000, Statistical Distributions, V3
   Mutzbauer J, 2020, Bavarian learning platform Mebis paralyzed by DDoS attack
   Navarro J, 2018, COMPUT SECUR, V76, P214, DOI 10.1016/j.cose.2018.03.001
   Nichols S, 2020, US Health and Human Services targeted by DDoS scum at just the time it's needed to be up and running
   NS3 Team, 2020, Network Simulator
   Okutan A, 2018, CYBERSECURITY, V1, DOI 10.1186/s42400-018-0016-5
   Olabelurin A, 2015, IEEE INT C NETW SENS, P315, DOI 10.1109/ICNSC.2015.7116055
   Pollak M, 2009, STAT SINICA, V19, P1729
   Polunchenko AS, 2012, SEQUENTIAL ANAL, V31, P409, DOI 10.1080/07474946.2012.694351
   Adams RP, 2007, Arxiv, DOI arXiv:0710.3742
   Procopiou A, 2019, WIREL COMMUN MOB COM, DOI 10.1155/2019/8469410
   Qingbo Yin, 2004, Fifth World Congress on Intelligent Control and Automation (IEEE Cat. No.04EX788), P4370, DOI 10.1109/WCICA.2004.1342339
   Rege A, 2018, IEEE INTELL SYST, V33, P29, DOI 10.1109/MIS.2018.111145153
   Rojas I, 2016, CONTRIB STAT, P1, DOI 10.1007/978-3-319-28725-6
   scikit learn, scikit-learn: Tuning the hyper-parameters of an estimator
   Sendi Alireza Shameli, 2012, Journal of Networks, V7, P311, DOI 10.4304/jnw.7.2.311-321
   Sharafaldin I, 2019, INT CARN CONF SECU
   Silva A, 2014, 2014 NINTH INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION MANAGEMENT (ICDIM), P194
   statsmodels, statsmodels: statsmodels v0.11.1
   Takeuchi J, 2006, IEEE T KNOWL DATA EN, V18, P482, DOI 10.1109/TKDE.2006.1599387
   Teller Report Team, 2020, Hospital systems Paris inaccessible for hours on end due to DDOS attack
   The USC Information Sciences Institute, The Network Simulator
   Wang HN, 2004, IEEE T DEPEND SECURE, V1, P193, DOI 10.1109/TDSC.2004.34
   Zhan ZX, 2015, IEEE T INF FOREN SEC, V10, P1666, DOI 10.1109/TIFS.2015.2422261
   Zhang G., 2009, P 2009 INT C WIR COM, P106
NR 57
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 23
PY 2023
DI 10.1007/s11042-023-17637-3
EA NOV 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AX8H4
UT WOS:001121833800001
DA 2024-07-18
ER

PT J
AU Liu, YL
   Wu, JH
   Sheng, XL
AF Liu, Yalei
   Wu, Jinghua
   Sheng, Xueliang
TI Pyramid Scale-aware and Soft-channel spatial attention for traffic sign
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Traffic sign detection; Attention mechanism; Feature fusion; Atrous
   convolution; Scale-aware; Small object detection
ID FEATURE AGGREGATION; NETWORK
AB Accurately detecting small traffic signs in complex and changing environments is challenging. Although the detection accuracy of traffic signs has been improved with the development of deep learning, it is not effective in detecting small traffic signs. We propose soft-channel spatial attention to solve this problem. Specifically, redundant information is suppressed while maintaining the high and low dimensional feature information, and the traffic sign region is enhanced. In addition, a pyramid scale-aware module is designed to dynamically generate different size receptive fields according to the regional context of the input image and construct a feature-rich feature pyramid to detect the diversity of object scales. Our approach is tested on public transportation sign detection datasets. A large number of experimental results have proved the superiority and effectiveness of the proposed approach compared to other state-of-the-art methods.
C1 [Liu, Yalei; Wu, Jinghua] Chinese Acad Sci, Hefei Inst Phys Sci, Hefei, Peoples R China.
   [Liu, Yalei] Univ Sci & Technol China, Sci Isl Branch, Grad Sch, Hefei, Peoples R China.
   [Sheng, Xueliang] Univ Sci & Technol China, Dept Automat, Hefei, Peoples R China.
C3 Chinese Academy of Sciences; Hefei Institutes of Physical Science, CAS;
   Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences; University of Science &
   Technology of China, CAS
RP Wu, JH (corresponding author), Chinese Acad Sci, Hefei Inst Phys Sci, Hefei, Peoples R China.
EM liuyalei@mail.ustc.edu.cn; wjh@iamt.ac.cn; sxl0909@mail.ustc.edu.cn
CR Bengio Y, 2013, Arxiv, DOI arXiv:1305.0445
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Cai ZW, 2016, Arxiv, DOI arXiv:1607.07155
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen Q, 2019, Arxiv, DOI [arXiv:1909.06459, DOI 10.48550/ARXIV.1909.06459]
   Dai JF, 2023, Arxiv, DOI [arXiv:1605.06409, DOI 10.48550/ARXIV.1605.06409]
   Duan KW, 2019, Arxiv, DOI arXiv:1904.08189
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Han C, 2019, MULTIMED TOOLS APPL, V78, P13263, DOI 10.1007/s11042-018-6428-0
   He KM, 2018, Arxiv, DOI [arXiv:1703.06870, 10.48550/arXiv.1703.06870, DOI 10.48550/ARXIV.1703.06870]
   He KM, 2015, Arxiv, DOI [arXiv:1512.03385, 10.48550/arxiv.1512.03385]
   Hu PY, 2017, Arxiv, DOI arXiv:1612.04402
   Huval B, 2015, Arxiv, DOI arXiv:1504.01716
   Jeong J, 2017, Arxiv, DOI [arXiv:1705.09587, DOI 10.5244/C.31.76]
   Jiang BR, 2018, Arxiv, DOI arXiv:1807.11590
   Li GF, 2020, IEEE ACCESS, V8, P211164, DOI 10.1109/ACCESS.2020.3036620
   Li J, 2019, IEEE T INTELL TRANSP, V20, P975, DOI 10.1109/TITS.2018.2843815
   Li JA, 2017, Arxiv, DOI arXiv:1706.05274
   Lin TY, 2018, Arxiv, DOI [arXiv:1708.02002, DOI 10.48550/ARXIV.1708.02002]
   Lin TY, 2017, Arxiv, DOI [arXiv:1612.03144, DOI 10.48550/ARXIV.1612.03144]
   Lin TY, 2015, Arxiv, DOI [arXiv:1405.0312, DOI 10.48550/ARXIV.1405.0312]
   Liu LM, 2020, IEEE ACCESS, V8, P171170, DOI 10.1109/ACCESS.2020.3024583
   Liu S, 2018, RECEPTIVE FIELD BLOC, P385
   Liu S, 2018, Arxiv, DOI [arXiv:1803.01534, DOI 10.48550/ARXIV.1803.01534, 10.48550/arXiv.1803.01534]
   Liu W, 2018, LECT NOTES COMPUT SC, V11218, P643, DOI 10.1007/978-3-030-01264-9_38
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu YY, 2021, NEUROCOMPUTING, V447, P10, DOI 10.1016/j.neucom.2021.03.049
   Liu ZG, 2020, APPL INTELL, V50, P1, DOI 10.1007/s10489-019-01511-7
   Liu ZG, 2019, IEEE ACCESS, V7, P57120, DOI 10.1109/ACCESS.2019.2913882
   Meng ZB, 2017, Arxiv, DOI arXiv:1706.08574
   Misra D, 2020, Arxiv, DOI arXiv:1908.08681
   Mnih V, 2014, Arxiv, DOI [arXiv:1406.6247, DOI 10.48550/ARXIV.1406.6247, 10.48550/arXiv.1406.6247]
   Ou ZH, 2019, IEEE ACCESS, V7, P178798, DOI 10.1109/ACCESS.2019.2959015
   Rahman Md Atiqur, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P234, DOI 10.1007/978-3-319-50835-1_22
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Redmon J, 2016, Arxiv, DOI [arXiv:1612.08242, 10.48550/arXiv.1612.08242, DOI 10.48550/ARXIV.1612.08242]
   Redmon J, 2016, Arxiv, DOI arXiv:1506.02640
   Ren SQ, 2016, Arxiv, DOI [arXiv:1506.01497, DOI 10.1109/TPAMI.2016.2577031]
   Rezatofighi H, 2019, Arxiv, DOI [arXiv:1902.09630, DOI 10.48550/ARXIV.1902.09630]
   Ruta A, 2008, Detection, tracking and recognition of traffic signs from video input, P55
   Saadna Y, 2017, INT J MULTIMED INF R, V6, P193, DOI 10.1007/s13735-017-0129-8
   Sermanet P, 2014, Arxiv, DOI arXiv:1312.6229
   Shen LL, 2021, NEUROCOMPUTING, V452, P1, DOI 10.1016/j.neucom.2021.04.083
   Shrivastava A, 2016, LECT NOTES COMPUT SC, V9905, P330, DOI 10.1007/978-3-319-46448-0_20
   Sun C, 2021, MULTIMED TOOLS APPL, V80, P33593, DOI 10.1007/s11042-021-11413-x
   Tang Q, 2021, IEEE ACCESS, V9, P117784, DOI 10.1109/ACCESS.2021.3106350
   Tian Z, 2019, Arxiv, DOI arXiv:1904.01355
   Wan JX, 2021, J SIGNAL PROCESS SYS, V93, P899, DOI 10.1007/s11265-020-01614-2
   Wang DD, 2017, IEEE T INTELL TRANSP, V18, P3290, DOI 10.1109/TITS.2017.2682181
   Wang GY, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI [10.1145/3173574.3174143, 10.1145/3173574.3173624]
   Wang QL, 2020, Arxiv, DOI arXiv:1910.03151
   Wu YQ, 2020, MULTIMED TOOLS APPL, V79, P18201, DOI 10.1007/s11042-020-08722-y
   Xu KL, 2016, Arxiv, DOI [arXiv:1502.03044, DOI 10.48550/ARXIV.1502.03044]
   Yang TT, 2018, COMPUT NETW, V136, P95, DOI 10.1016/j.comnet.2018.02.026
   Yifan Lu, 2018, Computational Visual Media, V4, P253, DOI 10.1007/s41095-018-0116-x
   Ying XY, 2020, IEEE SIGNAL PROC LET, V27, P496, DOI 10.1109/LSP.2020.2973813
   Yu JH, 2018, Arxiv, DOI arXiv:1801.07892
   Zhang HB, 2020, IEEE ACCESS, V8, P64145, DOI 10.1109/ACCESS.2020.2984554
   Zhang S., 2017, arXiv
   Zheng ZH, 2021, Arxiv, DOI arXiv:2005.03572
   Zhu Z, 2016, Traffic-sign detection and classification in the wild, P2110
NR 61
TC 0
Z9 0
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 16
PY 2023
DI 10.1007/s11042-023-17585-y
EA NOV 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X9GJ6
UT WOS:001101450500007
DA 2024-07-18
ER

PT J
AU Alhakamy, A
AF Alhakamy, A'aeshah
TI Digital vaccination passport and administrative burden of COVID-19
   official application based on Twitter(X) discourse: <i>public interest
   vs democracy</i>
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sentiment analysis; Vaccination passport; Health code; Twitter(X);
   Trust; Administrative burden; Applications; Natural Language Processing
   (NLP); Machine learning; Human behavior
ID SOCIAL MEDIA; HEALTH; TRUST
AB The Coronavirus disease 2019 (COVID-19) outbreak increased the scrutiny and burden on administrative officials to manage the pandemic rules and regulations. Social media platforms allow people to express their opinions, provide information on global events, and offer diverse perspectives and feedback. Throughout the pandemic, people have used Twitter(X) to spontaneously share sentiments and emotions about 35 official applications worldwide that address policies and regulations concerning vaccination passports installed by government agencies. Thus, this work conducts a sentiment analysis of 12,976 tweets-a popular form of natural language processing (NLP)-to capture what people are tweeting about these applications. The study attempts to answer the following research questions: (R.Q.1) Does embracing COVID-19 regulations through official applications have a positive impact? (R.Q.2) Are people trusting the official application? (R.Q.3) What topics get the most retweets? Explicitly, what is the relationship between the application and the number of retweets? (R.Q.4) What challenges may arise from the interpretation of app functionality based on tweets? Each sentiment analysis is reinforced by statistical evaluation to discover underlying patterns and trends in the collected big data.
C1 [Alhakamy, A'aeshah] Univ Tabuk, Fac Comp & Informat Technol, King Faisal Rd, Tabuk 47512, Saudi Arabia.
   [Alhakamy, A'aeshah] Univ Tabuk, Artificial Intelligence & Sensing Technol AIST Res, King Faisal Rd, Tabuk 47512, Saudi Arabia.
C3 University of Tabuk; University of Tabuk
RP Alhakamy, A (corresponding author), Univ Tabuk, Fac Comp & Informat Technol, King Faisal Rd, Tabuk 47512, Saudi Arabia.; Alhakamy, A (corresponding author), Univ Tabuk, Artificial Intelligence & Sensing Technol AIST Res, King Faisal Rd, Tabuk 47512, Saudi Arabia.
EM aalhakami@ut.edu.sa
RI Alhakamy, A'aeshah/AAG-2273-2019
OI Alhakamy, A'aeshah/0000-0002-0662-0185
FU Artificial Intelligence and Sensing Technologies (AIST)Research Center,
   University of Tabuk, Saudi Arabia
FX This work was partially funded by the Artificial Intelligence and
   Sensing Technologies (AIST)Research Center, University of Tabuk, 47731,
   Saudi Arabia.
CR Adali Sibel, 2010, 2010 IEEE International Conference on Intelligence and Security Informatics (ISI 2010), P150, DOI 10.1109/ISI.2010.5484757
   Alowisheq A, 2017, LECT NOTES COMPUT SC, V10283, P236, DOI 10.1007/978-3-319-58562-8_19
   Atkinson C. L., 2021, KNOWLEDGE, V1, P25, DOI [10.3390/knowledge1010004, DOI 10.3390/KNOWLEDGE1010004, https://doi.org/10.3390/knowledge1010004]
   Awwalu J, 2019, NEURAL COMPUT APPL, V31, P9207, DOI 10.1007/s00521-019-04248-z
   Boertjes E, 2012, IF INT C HUM CHOIC C, P250, DOI [10.1007/978-3-642-33332-3_23, DOI 10.1007/978-3-642-33332-3_23]
   Bonifazi G, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.103095
   Bonifazi G, 2022, INT J INF TECH DECIS, V21, P1385, DOI 10.1142/S0219622022500213
   Bose D., 2021, Int J Manag Technol Soc Sci (IJMTS), V6, P110, DOI 10.47992/IJMTS.2581.6012.0132
   Botchway RaphaelKwaku., 2019, Proceedings of the 3rd international conference on business and information Management, P74
   Bozeman B., 2000, BUREAUCRACY RED TAPE
   Burden BC, 2012, PUBLIC ADMIN REV, V72, P741, DOI 10.1111/j.1540-6210.2012.02600.x
   Coccia M, 2021, Maximum level of covid-19 vaccination in rich and democratic countries, and in other political systems, DOI [10.21203/rs.3.rs-1131026/v1, DOI 10.21203/RS.3.RS-1131026/V1]
   Dye C, 2021, SCIENCE, V371, P1184, DOI 10.1126/science.abi5245
   Saire JEC, 2020, Arxiv, DOI [arXiv:2003.11159, 10.48550/arXiv.2003.11159, DOI 10.48550/ARXIV.2003.11159]
   Lopez CE, 2020, Arxiv, DOI arXiv:2003.10359
   Elbagir S., 2020, Lecture Notes in Engineering and Computer Science, V2239, P63, DOI [DOI 10.1142/9789811215094_0005, 10.1142/9789811215094_0005]
   Ericson R., 2002, The policing of risk, P238
   Forman L, 2020, J HUM RIGHTS, V19, P547, DOI 10.1080/14754835.2020.1818556
   Georgiev D, 2022, 67+ revealing smartphone statistics for 2022
   Gstrein O.J., 2021, A terrible great idea? COVID-19 'vaccination passports' in the spotlight'
   Gstrein OJ, 2020, INTERNET POLICY REV, V9, DOI 10.14763/2020.3.1497
   Haggerty K. D., 2017, Surveillance, crime and social control, P61
   Hansen JM, 2018, COMPUT HUM BEHAV, V80, P197, DOI 10.1016/j.chb.2017.11.010
   Hine E, 2021, Covid-19 vaccine passports: Human rights and the need for pro-ethical design, DOI [10.2139/ssrn.3885252, DOI 10.2139/SSRN.3885252]
   Hutto C., 2014, P INT AAAI C WEB SOC, V8, P216, DOI [DOI 10.1609/ICWSM.V8I1.14550, 10.1609/icwsm.v8i1.14550]
   Ienca M, 2020, NAT MED, V26, P463, DOI 10.1038/s41591-020-0832-5
   Janssen M, 2020, INT J INFORM MANAGE, V55, DOI 10.1016/j.ijinfomgt.2020.102180
   Kaur H, 2017, 2017 INTERNATIONAL CONFERENCE ON I-SMAC (IOT IN SOCIAL, MOBILE, ANALYTICS AND CLOUD) (I-SMAC), P921, DOI 10.1109/I-SMAC.2017.8058315
   Lai A. Y., 2012, ASEAS AUSTRIAN J S E, V5, P74
   Lavazza A, 2020, FRONT PUBLIC HEALTH, V8, DOI 10.3389/fpubh.2020.00356
   Lumbreras A, 2012, 2012 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P1159, DOI 10.1109/ASONAM.2012.200
   Mackey TK, 2012, J PUBLIC HEALTH POL, V33, P119, DOI 10.1057/jphp.2011.51
   Maier D, 2018, COMMUN METHODS MEAS, V12, P93, DOI 10.1080/19312458.2018.1430754
   Moynihan D, 2010, AM REV PUBLIC ADM, V40, P654, DOI 10.1177/0275074010366732
   Nair Anu J., 2021, Proceedings of 5th International Conference on Computing Methodologies and Communication (ICCMC 2021), P1773, DOI 10.1109/ICCMC51019.2021.9418320
   Naseem U, 2021, IEEE T COMPUT SOC SY, V8, P1003, DOI 10.1109/TCSS.2021.3051189
   Pano T, 2020, BIG DATA COGN COMPUT, V4, DOI 10.3390/bdcc4040033
   Ravikumar S, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P2345, DOI 10.1145/2505515.2505667
   Schlagenhauf P, 2021, TRAVEL MED INFECT DI, V40, DOI 10.1016/j.tmaid.2021.101996
   Seglow J., 2005, Political Studies Review, V3, P317, DOI DOI 10.1111/J.1478-9299.2005.00026.X
   Shelar Amrita., 2018, 2018 INT C COMPUTATI, P1301, DOI [10.1109/CSCI46756.2018.00252, DOI 10.1109/CSCI46756.2018.00252]
   Sittar A, 2022, IEEE ACCESS, V10, P40036, DOI 10.1109/ACCESS.2022.3164692
   Sohail MS, 2020, INT J ONLINE MARKET, V10, P15, DOI 10.4018/IJOM.2020010102
   Trajkova M, 2020, INFORMATICS-BASEL, V7, DOI 10.3390/informatics7030035
   Veena G, 2021, 2021 2 GLOB C ADV TE, P1, DOI [10.1109/GCAT52182.2021.9587829, DOI 10.1109/GCAT52182.2021.9587829]
   Wang HL, 2001, AM J SOCIOL, V106, P1836, DOI 10.1086/338186
   Wen HH, 2020, L N INST COMP SCI SO, V335, P297, DOI 10.1007/978-3-030-63086-7_17
   Zwitter Andrej, 2020, J Int Humanit Action, V5, P4, DOI 10.1186/s41018-020-00072-6
NR 48
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 9
PY 2023
DI 10.1007/s11042-023-17598-7
EA NOV 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X9MX6
UT WOS:001101620700006
DA 2024-07-18
ER

PT J
AU Hu, LY
   Yang, Z
   Dou, YM
   Li, JH
AF Hu, Luyu
   Yang, Zhao
   Dou, Yamei
   Li, Jiahao
TI Balanced complement loss for long-tailed image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Long-tailed distribution; Class imbalance; Complement classes learning;
   Image classificationIntroduction
AB Long-tailed image classification is a significant research direction in the computer vision community, since many real-world image datasets exhibit an obvious long-tailed distribution. For a long-tailed dataset, head classes have most training samples, while tail classes occupy few training samples. In this scenario, samples of the head classes are treated as complement samples (all samples except the ground-truth class samples) of the tail classes, which generate overwhelmingly discouraging gradients on the tail classes. Consequently, the samples of tail classes are easily misclassified as the head classes. In view of this issue, we present a balanced complement (BACL) loss by introducing an adaptive weight for complement classes in the softmax cross-entropy loss. The adaptive weight helps to mitigate the overwhelming suppression of gradients from the complement samples for the tail classes, thereby balancing the gradient ratios between complement classes and ground-truth class. After that, we further propose a joint training framework by combining our method with normalized complement entropy (NCE) via a novel double-angle sine decay strategy. The proposed decay strategy is applied to adjust the contribution between the BACL and NCE losses at the different training stages. With our joint training framework, the model first learns useful information from the complement samples and then gradually turns its attention to the classification task. Experiments on long-tailed versions of CIFAR-10/100, SVHN and ImageNet-2012 datasets are conducted to reveal the significant effectiveness of the proposed methods.
C1 [Hu, Luyu; Yang, Zhao; Dou, Yamei; Li, Jiahao] Guangzhou Univ, Sch Elect & Commun Engn, Guangzhou 510006, Peoples R China.
   [Hu, Luyu; Yang, Zhao; Dou, Yamei; Li, Jiahao] Guangzhou Univ, Huangpu Res & Grad Sch, Guangzhou 510555, Peoples R China.
C3 Guangzhou University; Guangzhou University
RP Yang, Z (corresponding author), Guangzhou Univ, Sch Elect & Commun Engn, Guangzhou 510006, Peoples R China.; Yang, Z (corresponding author), Guangzhou Univ, Huangpu Res & Grad Sch, Guangzhou 510555, Peoples R China.
EM yangzhao@gzhu.edu.cn
RI li, jiahao/HZH-6826-2023
FU This research was supported by Guangzhou University's training program
   for excellent new-recruited doctors (No. YB201712). [YB201712];
   Guangzhou University's training program for excellent new-recruited
   doctors
FX This research was supported by Guangzhou University's training program
   for excellent new-recruited doctors (No. YB201712).
CR ANAND R, 1993, IEEE T NEURAL NETWOR, V4, P962, DOI 10.1109/72.286891
   Barandela R, 2003, LECT NOTES COMPUT SC, V2905, P424
   Boyan Zhou, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9716, DOI 10.1109/CVPR42600.2020.00974
   Buda M, 2018, NEURAL NETWORKS, V106, P249, DOI 10.1016/j.neunet.2018.07.011
   Cao KD, 2019, ADV NEUR IN, V32
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen H.-Y., 2019, INT C LEARN REPR
   Cui Y, 2019, PROC CVPR IEEE, P9260, DOI 10.1109/CVPR.2019.00949
   Cui Y, 2018, PROC CVPR IEEE, P4109, DOI 10.1109/CVPR.2018.00432
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Drummond C., 2003, INT C MACH LEARN WOR
   Duan YQ, 2019, PROC CVPR IEEE, P3410, DOI 10.1109/CVPR.2019.00353
   Feng CJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3397, DOI 10.1109/ICCV48922.2021.00340
   Fernando KRM, 2022, IEEE T NEUR NET LEAR, V33, P2940, DOI 10.1109/TNNLS.2020.3047335
   Guyon I., 2017, Advances in Neural Information Processing Systems, P7029
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hsin-Ping Chou, 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12540), P95, DOI 10.1007/978-3-030-65414-6_9
   Huang C, 2020, IEEE T PATTERN ANAL, V42, P2781, DOI 10.1109/TPAMI.2019.2914680
   Huang C, 2016, PROC CVPR IEEE, P5375, DOI 10.1109/CVPR.2016.580
   Jamal M. A., 2020, P IEEECVF C COMPUTER, P7610, DOI DOI 10.1109/CVPR42600.2020.00763
   Jingru Tan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11659, DOI 10.1109/CVPR42600.2020.01168
   Kang Bingyi, 2020, 8 INT C LEARN REPR I
   Kim Y, 2021, PATTERN RECOGN LETT, V151, P33, DOI 10.1016/j.patrec.2021.07.017
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Kubat M., 1997, ICML, P179
   Li BY, 2019, AAAI CONF ARTIF INTE, P8577
   Li MK, 2023, IEEE T PATTERN ANAL, V45, P4812, DOI 10.1109/TPAMI.2022.3196044
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu ZW, 2019, PROC CVPR IEEE, P2532, DOI 10.1109/CVPR.2019.00264
   Netzer Yuval, 2011, ADV NEUR INF PROC SY
   Ouyang WL, 2016, PROC CVPR IEEE, P864, DOI 10.1109/CVPR.2016.100
   Peng Chu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12374), P694, DOI 10.1007/978-3-030-58526-6_41
   Ren J., 2020, ADV NEURAL INFORM PR
   Ren M., 2018, INT C MACHINE LEARNI, P4334
   Shen L, 2016, LECT NOTES COMPUT SC, V9911, P467, DOI 10.1007/978-3-319-46478-7_29
   Shu Jun, 2019, ADV NEURAL INFORM PR, P1917
   Sinha S., 2020, P ASIAN C COMPUTER V, DOI [10.1007/978-3-030-69544-6_33, DOI 10.1007/978-3-030-69544-6_33]
   Tiong AMH, 2023, PATTERN RECOGN LETT, V168, P123, DOI 10.1016/j.patrec.2023.03.010
   Wang JQ, 2021, PROC CVPR IEEE, P9690, DOI 10.1109/CVPR46437.2021.00957
   Wang YR, 2019, IEEE I CONF COMP VIS, P5016, DOI 10.1109/ICCV.2019.00512
   Yan HL, 2017, PROC CVPR IEEE, P945, DOI 10.1109/CVPR.2017.107
   Yang Yuzhe, 2020, NEURIPS, V33, P19290
   Yin X, 2019, PROC CVPR IEEE, P5697, DOI 10.1109/CVPR.2019.00585
   Zhang Hongyi, 2018, MIXUP EMPIRICAL RISK, DOI DOI 10.48550/ARXIV.1710.09412
   Zhao Y., 2021, arXiv
   Zhu ZH, 2022, KNOWL-BASED SYST, V248, DOI 10.1016/j.knosys.2022.108816
NR 47
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 8
PY 2023
DI 10.1007/s11042-023-17583-0
EA NOV 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X8TR3
UT WOS:001101114600008
DA 2024-07-18
ER

PT J
AU Kaur, J
   Khehra, BS
   Singh, A
   Walia, M
AF Kaur, Jagmohan
   Khehra, Baljit S.
   Singh, Amarinder
   Walia, Mohit
TI Soft computing based intelligent system for identifying risk level of
   the heart disease
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fuzzy Logic; Cardiac risk; Computer-aided; Serum creatinine;
   Echocardiogram (LVEF)
ID FUZZY EXPERT-SYSTEM; RECOMMENDATION; LOGIC
AB This paper presents a fuzzy logic based heart disease risk prediction system. The system collects patient medical data using a user-friendly GUI and processes the same with fuzzy logic soft computing technique. The prediction model also introduces three supreme attributes, viz., Serum creatinine, Echocardiogram (LVEF) and Breathlessness that inform about the diminished blood flow, deteriorated heart muscles and severity while breathing respectively. The proposed system works on 47 logical operations processed over 10 clinical inputs. The study reveals 5 distinct levels of heart risks as output and final results matches with probable cardiac risk. The study yielded an accuracy of 96% along with specificity and sensitivity of 94.73 and 96.67% respectively. Comparison with previous research papers and presentation of ROC and PR-curves highlights the effectiveness of fuzzy logic in the medical science.
C1 [Kaur, Jagmohan] IKG Punjab Tech Univ, Jalandhar, Punjab, India.
   [Khehra, Baljit S.] BBSB Engn Coll, Comp Sci & Engn, Fatehgarh Sahib, Punjab, India.
   [Singh, Amarinder] BBSB Engn Coll, Dept Appl Sci, Fatehgarh Sahib, Punjab, India.
   [Walia, Mohit] SGHS Hosp, Cardiol Dept, Mohali, Punjab, India.
C3 I. K. Gujral Punjab Technical University
RP Singh, A (corresponding author), BBSB Engn Coll, Dept Appl Sci, Fatehgarh Sahib, Punjab, India.
EM mohnideep1234@gmail.com; baljitkhehra74@gmail.com;
   amarinder77@gmail.com; drmohitwalia33@yahoo.co.in
RI Singh, Amarinder/GSN-7229-2022
OI Singh, Amarinder/0000-0001-7218-9197
CR Adeli A, 2010, LECT NOTES ENG COMP, P134
   Alqudah AM, 2017, HEALTH TECHNOL-GER, V7, P215, DOI 10.1007/s12553-017-0178-2
   [Anonymous], 2016, WHO Technical report
   [Anonymous], 2019, CDCreports CDC Technical report
   Anooj PK, 2012, J KING SAUD UNIV-COM, V24, P27, DOI 10.1016/j.jksuci.2011.09.002
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2022, ENVIRON SCI POLLUT R, V29, P14780, DOI 10.1007/s11356-021-16627-y
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bohacik J, 2015, INT WORKSH INT DATA, P177, DOI 10.1109/IDAACS.2015.7340724
   Bozkurt B, 2003, CIRCULATION, V108, pE11, DOI 10.1161/01.CIR.0000075956.36340.78
   Duisenbayeva A, 2016, P 10 INT C APPL INFO, P1
   Ephzibah EP, 2011, COMM COM INF SC, V198, P115
   Hasnain A, 2022, Front Environ Sci, V1044
   Iancu I, 2018, ARTIF INTELL MED, V89, P51, DOI 10.1016/j.artmed.2018.05.004
   Ibrahim D, 2016, PROCEDIA COMPUT SCI, V102, P34, DOI 10.1016/j.procs.2016.09.366
   Islam Md Milon, 2020, SN Comput Sci, V1, P185, DOI 10.1007/s42979-020-00195-y
   Jain P, 2016, P 3 INT C ADV INF CO, P1
   Kasbe Tanmay, 2017, 2017 International Conference on Energy, Communication, Data Analytics and Soft Computing (ICECDS), P3183, DOI 10.1109/ICECDS.2017.8390044
   Kaur Jagmohan, 2022, Journal of the Institution of Engineers (India): Series B (Electrical, Electronics & Telecommunication and Computer Engineering), V103, P681, DOI 10.1007/s40031-021-00644-z
   Kim JK, 2014, CLUSTER COMPUT, V17, P881, DOI 10.1007/s10586-013-0308-1
   Krishnan P, 2020, IEEE ICCE, P534
   Kumar S., 2013, Int J Eng Trends Technol, V4, P2694
   Li TF, 2022, EURASIP J WIREL COMM, V2022, DOI 10.1186/s13638-022-02106-6
   Madaan Vishu, 2018, 2018 International Conference on Advances in Computing, Communication Control and Networking (ICACCCN). Proceedings, P1049, DOI 10.1109/ICACCCN.2018.8748342
   Mazhar T, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11233989
   Muhammad LJ, 2021, HEALTH TECHNOL-GER, V11, P319, DOI 10.1007/s12553-021-00531-z
   Nasr M, 2021, IEEE ACCESS, V9, P145248, DOI 10.1109/ACCESS.2021.3118960
   Nawaz SA, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0256971
   Paul AK, 2016, 2016 5TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS AND VISION (ICIEV), P145, DOI 10.1109/ICIEV.2016.7759984
   Perret-Guillaume C, 2009, PROG CARDIOVASC DIS, V52, P6, DOI 10.1016/j.pcad.2009.05.003
   Sadollah A, 2018, Fuzzy Logic Based in Optimization Methods and Control Systems and its Applications, P3, DOI DOI 10.5772/INTECHOPEN.79552
   Terrada O, 2018, 2018 INTERNATIONAL CONFERENCE ON ELECTRONICS, CONTROL, OPTIMIZATION AND COMPUTER SCIENCE (ICECOCS)
   Thukral S, 2019, MED HYPOTHESES, V122, P150, DOI 10.1016/j.mehy.2018.11.017
   Wang C., 2015, STUDY MEMBERSHIP FUN
   Wannamethee SG, 1997, STROKE, V28, P557, DOI 10.1161/01.STR.28.3.557
NR 36
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 6
PY 2023
DI 10.1007/s11042-023-17452-w
EA NOV 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X6AZ8
UT WOS:001099271500001
DA 2024-07-18
ER

PT J
AU Wu, R
   Chen, SB
   Luo, B
AF Wu, Rui
   Chen, Si-Bao
   Luo, Bin
TI DLAReID: double-layer attention network for object re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Object re-identification; Double-layer attention; Convolutional neural
   network; Self-attention; Multi-layer perceptron
ID PERSON REIDENTIFICATION
AB Improving feature representations is a crucial task in object re-identification (Re-ID). Enhancement of discriminative features and suppression of irrelevant features have become standard approaches through the use of attentions. Long-range dependencies and more comprehensive image information can be considered by self-attentions. Additionally, the importance of pixels can be calibrated by multi-layer perceptrons. In this paper, Double-Layer Attention network for object re-identification (DLAReID) is proposed. Self-attentions and multi-layer perceptrons are combined in the convolutional neural network, which are the main structures in transformers. The limitations of capturing local dependencies in convolutional neural networks and the excessive parameters in transformers are addressed. 3x3 filters are replaced by the proposed double-layer self-attentions in the bottleneck blocks of the last layer of the network. The ability to capture global information is enhanced by the cooperation of the double-branch self-attention of the outer layer and the attention acting on the relative position encoding module of the inner layer. Good performance is achieved by the proposed method, as demonstrated by comprehensive experiments on multiple datasets.
C1 [Wu, Rui; Chen, Si-Bao; Luo, Bin] Anhui Univ, IMIS Lab Anhui Prov, Anhui Prov Key Lab Multimodal Cognit Computat, MOE Key Lab ICSP,Sch Comp Sci & Technol, Hefei 230601, Peoples R China.
C3 Anhui University
RP Chen, SB (corresponding author), Anhui Univ, IMIS Lab Anhui Prov, Anhui Prov Key Lab Multimodal Cognit Computat, MOE Key Lab ICSP,Sch Comp Sci & Technol, Hefei 230601, Peoples R China.
EM sbchen@ahu.edu.cn
OI Chen, Si-Bao/0000-0003-1481-0162
FU NSFC Key Project of International (Regional) Cooperation and Exchanges
   [61860206004]; National Natural Science Foundation of China [61976004];
   University Synergy Innovation Program of Anhui Province [GXXT-2019-025]
FX This work was supported by NSFC Key Project of International (Regional)
   Cooperation and Exchanges (No.61860206004), National Natural Science
   Foundation of China (No.61976004) and University Synergy Innovation
   Program of Anhui Province (No.GXXT-2019-025).
CR Bello I, 2019, IEEE I CONF COMP VIS, P3285, DOI 10.1109/ICCV.2019.00338
   Chen GY, 2021, IEEE T IMAGE PROCESS, V30, P7663, DOI 10.1109/TIP.2021.3107211
   Chen TL, 2019, IEEE I CONF COMP VIS, P8350, DOI 10.1109/ICCV.2019.00844
   Cheng DS, 2014, ADV COMPUT VIS PATT, P139, DOI 10.1007/978-1-4471-6296-4_7
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dong YH, 2021, PR MACH LEARN RES, V139
   Dosovitskiy Alexey, 2020, ABS201011929 CORR
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8295
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Han K, 2023, IEEE T PATTERN ANAL, V45, P87, DOI 10.1109/TPAMI.2022.3152247
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ST, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14993, DOI 10.1109/ICCV48922.2021.01474
   Hou RB, 2019, PROC CVPR IEEE, P7176, DOI 10.1109/CVPR.2019.00735
   Hou RB, 2019, PROC CVPR IEEE, P9309, DOI 10.1109/CVPR.2019.00954
   Huynh SV, 2021, IEEE COMPUT SOC CONF, P4142, DOI 10.1109/CVPRW53098.2021.00468
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Khan S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3505244
   Li S, 2018, PROC CVPR IEEE, P369, DOI 10.1109/CVPR.2018.00046
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Liu JX, 2018, PROC CVPR IEEE, P4099, DOI 10.1109/CVPR.2018.00431
   Liu XC, 2016, IEEE INT CON MULTI
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Miao JX, 2019, IEEE I CONF COMP VIS, P542, DOI 10.1109/ICCV.2019.00063
   Ramachandran P, 2019, ADV NEUR IN, V32
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Srinivas A, 2021, PROC CVPR IEEE, P16514, DOI 10.1109/CVPR46437.2021.01625
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tang CX, 2022, AAAI CONF ARTIF INTE, P2344
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wu K, 2021, 2021 IEEE CVF INT C, Vpp10, P021
   Yang WJ, 2019, PROC CVPR IEEE, P1389, DOI 10.1109/CVPR.2019.00148
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Zhai S., 2021, arXiv
   Zhang H, 2022, IEEE COMPUT SOC CONF, P2735, DOI 10.1109/CVPRW56347.2022.00309
   Zhang ZZ, 2019, PROC CVPR IEEE, P667, DOI 10.1109/CVPR.2019.00076
   Zheng L, 2019, IEEE T IMAGE PROCESS, V28, P4500, DOI 10.1109/TIP.2019.2910414
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng M, 2019, PROC CVPR IEEE, P5728, DOI 10.1109/CVPR.2019.00588
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
NR 43
TC 0
Z9 0
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 2
PY 2023
DI 10.1007/s11042-023-17309-2
EA NOV 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X1LQ6
UT WOS:001096134900006
DA 2024-07-18
ER

PT J
AU Amiriebrahimabadi, M
   Mansouri, N
AF Amiriebrahimabadi, Mohammad
   Mansouri, Najme
TI A comprehensive survey of feature selection techniques based on whale
   optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Feature selection; Whale optimization; Metaheuristic; Survey
ID SEGMENTATION
AB Machine learning and data mining rely on feature selection to reduce the dimension of data and increase the performance of algorithms. As a result of such a large search space, feature selection is a challenging task. Recently, evolutionary techniques have been gaining a lot of attention and showing some promise for solving feature selection problems. Recent studies have shown that Whale Optimization Algorithm (WOA) is widely used in various fields (e.g., data mining, machine learning, and cloud computing). Motivated by the extensive research efforts in the feature selection and WOA, we present a review of high-quality articles related to WOA-based feature selection algorithms published between 2017 and 2023. This paper discusses and compares WOA-based feature selection schemes based on merits and demerits, evaluation techniques, simulation environments, and important parameters. We begin by introducing feature selection process, and concepts of metaheuristic followed by their surveys. This study summarizes several domains where WOA is used and explains different types of features. Moreover, it categorizes the variants of WOA based on their learning process, parameter tuning, binary/discrete, and hybridization. According to the investigation results, few variations of WOA add new parameters or operators to the original. In addition, 60% of feature selection algorithms based on WOA focus on improving learning process. Finally, current issues and challenges are also discussed to identify future research areas.
C1 [Amiriebrahimabadi, Mohammad; Mansouri, Najme] Shahid Bahonar Univ Kerman, Dept Comp Sci, Kerman, Iran.
C3 Shahid Bahonar University of Kerman (SBUK)
RP Mansouri, N (corresponding author), Shahid Bahonar Univ Kerman, Dept Comp Sci, Kerman, Iran.
EM najme.mansouri@gmail.com
CR Abd Elaziz M, 2019, KNOWL-BASED SYST, V172, P42, DOI 10.1016/j.knosys.2019.02.010
   Abdollahzadeh B, 2022, ENG COMPUT-GERMANY, V38, P1845, DOI 10.1007/s00366-021-01369-9
   Abdullah AS, 2017, 2017 CONFERENCE ON EMERGING DEVICES AND SMART SYSTEMS (ICEDSS), P58, DOI 10.1109/ICEDSS.2017.8073659
   Agrawal RK, 2020, APPL SOFT COMPUT, V89, DOI 10.1016/j.asoc.2020.106092
   Al-Tashi Q, 2020, IEEE ACCESS, V8, P125076, DOI 10.1109/ACCESS.2020.3007291
   Alamri HS, 2018, ADV SCI LETT, V24, P7461, DOI 10.1166/asl.2018.12959
   Almufti S.M., 2019, Int. J. Sci. World, V7, P1, DOI [10.14419/ijsw.v7i1.29497, DOI 10.14419/IJSW.V7I1.29497]
   Alsahaf A, 2022, EXPERT SYST APPL, V187, DOI 10.1016/j.eswa.2021.115895
   Alsawadi M S, 2023, INT C CONTR AUT DIAG, P1, DOI [10.1109/ICCAD57653.2023.10152320, DOI 10.1109/ICCAD57653.2023.10152320]
   Alwajih R, 2022, NEURAL COMPUT APPL, V34, P19377, DOI 10.1007/s00521-022-07522-9
   Assegie T. A., 2023, International Journal of Electrical and Computer Engineering, V13, P3359, DOI [10.11591/ijece.v13i3.pp3359-3366, DOI 10.11591/IJECE.V13I3.PP3359-3366]
   Nguyen BH, 2020, SWARM EVOL COMPUT, V54, DOI 10.1016/j.swevo.2020.100663
   Bai Ll, 2020, APPL SOFT COMPUT, V92, DOI 10.1016/j.asoc.2020.106245
   Bhattacharya A, 2023, BIOMED SIGNAL PROCES, V83, DOI 10.1016/j.bspc.2023.104692
   BHESDADIYA RH, 2016, INDIAN J SCI TECHNOL, V9, pNI893, DOI DOI 10.17485/ijst/2016/v9i(S1)/101941
   Bolón-Canedo V, 2020, ARTIF INTELL REV, V53, P2905, DOI 10.1007/s10462-019-09750-3
   Borenstein Y, 2005, GECCO 2005: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOLS 1 AND 2, P1515
   Brindha S, 2016, INT CONF ADVAN COMPU
   Chen CW, 2020, EXPERT SYST, V37, DOI 10.1111/exsy.12553
   Chen HW, 2019, INT WORKSH INT DATA, P70, DOI [10.1109/IDAACS.2019.8924334, 10.1109/idaacs.2019.8924334]
   Chen H, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113612
   Chen X, 2020, IEEE SYST J, V14, P3117, DOI 10.1109/JSYST.2019.2960088
   Chen X, 2020, IEEE ACCESS, V8, P90165, DOI 10.1109/ACCESS.2020.2993580
   Cherrington M, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCIS), P252, DOI 10.1109/iccisci.2019.8716478
   Cieslak MC, 2020, MAR GENOM, V51, DOI 10.1016/j.margen.2019.100723
   Dao K, 2016, INT CONF SIGN PROCES, P337, DOI 10.1109/ICSP.2016.7877851
   Detect Malware Types, 2019, UCI Machine Learning Repository, DOI [10.24432/C57S5W, DOI 10.24432/C57S5W]
   Dey Souvik, 2023, Journal of Electrical Systems and Information Technology, DOI 10.1186/s43067-023-00102-4
   Dhal P, 2022, APPL INTELL, V52, P4543, DOI 10.1007/s10489-021-02550-9
   Dokeroglu T, 2022, NEUROCOMPUTING, V494, P269, DOI 10.1016/j.neucom.2022.04.083
   Dornaika F, 2021, KNOWL INF SYST, V63, P1029, DOI 10.1007/s10115-020-01535-3
   Dutta Subhrajit, 2020, HandBook of Probabilistic Models, P369, DOI DOI 10.1016/B978-0-12-816514-0.00015-1
   Eid MM, 2021, 2021 IEEE NATIONAL COMPUTING COLLEGES CONFERENCE (NCCC 2021), P1133, DOI 10.1109/NCCC49330.2021.9428794
   Fan Q, 2021, ENG COMPUT-GERMANY, V37, P1851, DOI 10.1007/s00366-019-00917-8
   Fang LL, 2023, J BIONIC ENG, V20, P237, DOI 10.1007/s42235-022-00253-6
   Fauvel M, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/783194
   Forsyth R., 1990, UCI Machine Learning Repository, DOI [10.24432/C5R59V, DOI 10.24432/C5R59V]
   Gharehchopogh FS, 2019, SWARM EVOL COMPUT, V48, P1, DOI 10.1016/j.swevo.2019.03.004
   Ghojogh B, 2020, Arxiv, DOI arXiv:2011.10925
   Ghosh M, 2020, NEURAL COMPUT APPL, V32, P7839, DOI 10.1007/s00521-019-04171-3
   Got A, 2021, EXPERT SYST APPL, V183, DOI 10.1016/j.eswa.2021.115312
   Guha R, 2020, SOFT COMPUT, V24, P12821, DOI 10.1007/s00500-020-05183-1
   Guo SS, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/6502807
   Hancer E, 2020, ARTIF INTELL REV, V53, P4519, DOI 10.1007/s10462-019-09800-w
   Hassan G, 2018, SIGNAL IMAGE VIDEO P, V12, P263, DOI 10.1007/s11760-017-1154-z
   Hassan MR, 2022, INFORM FUSION, V77, P70, DOI 10.1016/j.inffus.2021.07.010
   Hassanien AE, 2016, IEEE SYS MAN CYBERN, P3842, DOI 10.1109/SMC.2016.7844833
   Hongping Hu, 2016, WSEAS Transactions on Computers, V15, P319
   Hu XG, 2018, FRONT COMPUT SCI-CHI, V12, P479, DOI 10.1007/s11704-016-5489-3
   Huang XG, 2017, CHIN CONTR CONF, P11437, DOI 10.23919/ChiCC.2017.8029182
   Hussien Abdelazim G., 2019, Recent Trends in Signal and Image Processing. ISSIP 2017. Advances in Intelligent Systems and Computing (AISC 727), P79, DOI 10.1007/978-981-10-8863-6_9
   Hussien Abdelazim G., 2017, 2017 Eighth International Conference on Intelligent Computing and Information Systems (ICICIS). Proceedings, P166, DOI 10.1109/INTELCIS.2017.8260031
   Jadhav AN, 2018, ALEX ENG J, V57, P1569, DOI 10.1016/j.aej.2017.04.013
   Jain S, 2019, COGENT ENG, V6, DOI 10.1080/23311916.2019.1599537
   Jiang RY, 2018, PROCEEDINGS OF 2018 TENTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P97, DOI 10.1109/ICACI.2018.8377588
   Jin QB, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13020238
   Kaur G, 2018, J COMPUT DES ENG, V5, P275, DOI 10.1016/j.jcde.2017.12.006
   Kothari V, 2012, COMM COM INF SC, V270, P192
   Krithiga R., 2020, MICROPROCESSORS, DOI [10.1016/j.micpro.2020.103451, DOI 10.1016/J.MICPRO.2020.103451]
   Kumar RA, 2022, MATER TODAY-PROC, V64, P435, DOI 10.1016/j.matpr.2022.04.803
   Kundu R, 2022, COMPUT BIOL MED, V144, DOI 10.1016/j.compbiomed.2022.105349
   Lebichot B, 2020, KNOWL INF SYST, V62, P4337, DOI 10.1007/s10115-020-01500-0
   Li AD, 2020, COMPUT IND ENG, V149, DOI 10.1016/j.cie.2020.106852
   Liu W, 2019, IEEE INT C NETW SENS, P424, DOI [10.1109/ICNSC.2019.8743245, 10.1109/icnsc.2019.8743245]
   Morillo-Salas JL, 2021, KNOWL INF SYST, V63, P233, DOI 10.1007/s10115-020-01526-4
   MACKIEWICZ A, 1993, COMPUT GEOSCI, V19, P303, DOI 10.1016/0098-3004(93)90090-R
   Mafarja M, 2018, 5 INT S INN INF COMM, DOI [10.1109/ISIICT.2018.8613293, DOI 10.1109/ISIICT.2018.8613293]
   Mafarja M, 2023, APPL INTELL, V53, P18715, DOI 10.1007/s10489-022-04427-x
   Mafarja M, 2020, FUTURE GENER COMP SY, V112, P18, DOI 10.1016/j.future.2020.05.020
   Mafarja M, 2018, KNOWL-BASED SYST, V161, P185, DOI 10.1016/j.knosys.2018.08.003
   Mafarja M, 2018, APPL SOFT COMPUT, V62, P441, DOI 10.1016/j.asoc.2017.11.006
   Mafarja MM, 2017, NEUROCOMPUTING, V260, P302, DOI 10.1016/j.neucom.2017.04.053
   Mahmood S., 2023, Indonesian J. Electr. Eng. Comput. Sci., V29, P899, DOI [10.11591/ijeecs.v29.i2.pp899-910, DOI 10.11591/IJEECS.V29.I2.PP899-910]
   Mansouri N, 2022, NEURAL COMPUT APPL, V34, P7749, DOI 10.1007/s00521-021-06881-z
   Matsuno K, 2003, Parallel computational fluid dynamics 2002, DOI [10.1016/B978-0-444-50680-1.X5000-1, DOI 10.1016/B978-0-444-50680-1.X5000-1]
   Mehne HH, 2018, KNOWL-BASED SYST, V151, P114, DOI 10.1016/j.knosys.2018.03.024
   Miljkovic D, 2017, 2017 40TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1061, DOI 10.23919/MIPRO.2017.7973581
   Mirjalili Seyedehzahra, 2020, Soft Computing for Problem Solving 2019. Proceedings of SocProS 2019. Advances in Intelligent Systems and Computing (AISC 1138), P241, DOI 10.1007/978-981-15-3290-0_19
   Mirjalili S., 2020, Nature-inspired optimizers theories, literature reviews and applications, P219, DOI DOI 10.1007/978-3-030-12127-3_13
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2013, SWARM EVOL COMPUT, V9, P1, DOI 10.1016/j.swevo.2012.09.002
   Mitchell T., 1999, UCI Machine Learning Repository, DOI DOI 10.24432/C5C323
   MNIST Database of Handwritten Digits, 2021, UCI Machine Learning Repository, DOI [10.24432/C53K8Q, DOI 10.24432/C53K8Q]
   Mohammadzadeh H, 2021, INT J INF TECH DECIS, V20, P469, DOI 10.1142/S0219622020500546
   Mohammadzadeh H, 2021, COMPUT INTELL-US, V37, P176, DOI 10.1111/coin.12397
   Mohmmadzadeh H, 2021, J SUPERCOMPUT, V77, P9102, DOI 10.1007/s11227-021-03626-6
   Moorthy U, 2021, J AMB INTEL HUM COMP, V12, P3527, DOI 10.1007/s12652-020-02592-w
   Mostafa A, 2017, MULTIMED TOOLS APPL, V76, P24931, DOI 10.1007/s11042-017-4638-5
   Nadimi-Shahraki MH, 2022, COMPUT BIOL MED, V148, DOI 10.1016/j.compbiomed.2022.105858
   Naik R.B., 2024, Ann. Data Sci, V11, P25, DOI DOI 10.1007/S40745-021-00364-7
   Naseri TS, 2022, J NETW SYST MANAG, V30, DOI 10.1007/s10922-022-09653-9
   Nematzadeh H, 2019, GENOMICS, V111, P1946, DOI 10.1016/j.ygeno.2019.01.006
   Ng KKH, 2018, APPL SOFT COMPUT, V66, P104, DOI 10.1016/j.asoc.2018.02.013
   Ning GY, 2021, DISCRETE DYN NAT SOC, V2021, DOI 10.1155/2021/8832251
   Nssibi M, 2023, COMPUT SCI REV, V49, DOI 10.1016/j.cosrev.2023.100559
   Pandey G, 2018, INFORM RETRIEVAL J, V21, P481, DOI 10.1007/s10791-018-9330-5
   Qian YG, 2015, REMOTE SENS-BASEL, V7, P153, DOI 10.3390/rs70100153
   Rahnema N, 2020, MULTIMED TOOLS APPL, V79, P32169, DOI 10.1007/s11042-020-09639-2
   Rana N, 2020, NEURAL COMPUT APPL, V32, P16245, DOI 10.1007/s00521-020-04849-z
   Ray Susmita, 2019, 2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon), P35, DOI 10.1109/COMITCon.2019.8862451
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Rosyadi A, 2017, 2017 INTERNATIONAL SEMINAR ON INTELLIGENT TECHNOLOGY AND ITS APPLICATIONS (ISITIA), P87, DOI 10.1109/ISITIA.2017.8124060
   Rothlauf F, 2011, NAT COMPUT SER, P1, DOI 10.1007/978-3-540-72962-4
   Saidala RK, 2017, 2017 2ND INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT), P626, DOI 10.1109/I2CT.2017.8226205
   Salau Ayodeji Olalekan, 2019, 2019 International Conference on Signal Processing and Communication (ICSC), P158
   Bonab MS, 2020, INT J COMMUN SYST, V33, DOI 10.1002/dac.4434
   Sayed GI, 2018, J CLASSIF, V35, P300, DOI 10.1007/s00357-018-9261-2
   Shahana AH, 2016, PROCEEDINGS OF IEEE INTERNATIONAL CONFERENCE ON CIRCUIT, POWER AND COMPUTING TECHNOLOGIES (ICCPCT 2016)
   Sharawi M, 2017, 2017 NINTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P163, DOI 10.1109/ICACI.2017.7974502
   Shuaib M, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-0394-7
   Simhadri KS, 2019, OPTIM CONTR APPL MET, V40, P24, DOI 10.1002/oca.2462
   Solorio-Fernández S, 2022, ARTIF INTELL REV, V55, P2821, DOI 10.1007/s10462-021-10072-6
   Sreenu K, 2019, CLUSTER COMPUT, V22, P1087, DOI 10.1007/s10586-017-1055-5
   Sun L, 2023, INFORM FUSION, V95, P91, DOI 10.1016/j.inffus.2023.02.016
   Syed EU, 2021, 2021 29TH TELECOMMUNICATIONS FORUM (TELFOR), DOI 10.1109/TELFOR52709.2021.9653166
   Syed S. A., 2020, International Journal of Scientific and Engineering Research, V11, P469
   Tawhid MA, 2020, INT J MACH LEARN CYB, V11, P573, DOI 10.1007/s13042-019-00996-5
   Thakkar A, 2022, ARTIF INTELL REV, V55, P453, DOI 10.1007/s10462-021-10037-9
   Too JW, 2021, NEURAL COMPUT APPL, V33, P16229, DOI 10.1007/s00521-021-06224-y
   Tubishat M, 2019, APPL INTELL, V49, P1688, DOI 10.1007/s10489-018-1334-8
   Uzer MS, 2023, J SUPERCOMPUT, V79, P10020, DOI 10.1007/s11227-023-05067-9
   Vanaja S., 2014, International Journal of Computer Applications, V96, P29, DOI DOI 10.5120/16888-6910
   Velmurugan T., 2021, J Computer Commun, V9, P66, DOI [10.4236/jcc.2021.91007, DOI 10.4236/JCC.2021.91007]
   Viharos ZJ, 2021, PATTERN RECOGN, V116, DOI 10.1016/j.patcog.2021.107932
   Vijayanand R, 2020, IEEE ACCESS, V8, P56847, DOI 10.1109/ACCESS.2020.2978035
   Wang G., 2020, ADV SIGNAL PROCESSIN, P237
   Wang Jianhao, 2021, 2021 International Conference on Computer Communication and Artificial Intelligence (CCAI), P180, DOI 10.1109/CCAI50917.2021.9447541
   Wang JX, 2021, IEEE J-STARS, V14, P2473, DOI 10.1109/JSTARS.2021.3056593
   Wang J, 2006, IEEE T GEOSCI REMOTE, V44, P1586, DOI 10.1109/TGRS.2005.863297
   Wang LP, 2016, METHODS, V111, P21, DOI 10.1016/j.ymeth.2016.08.014
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Xing J, 2023, J BIONIC ENG, V20, P797, DOI 10.1007/s42235-022-00297-8
   Xu H, 2018, PROCEEDINGS OF THE 2018 IEEE 4TH INTERNATIONAL SYMPOSIUM ON WIRELESS SYSTEMS WITHIN THE INTERNATIONAL CONFERENCES ON INTELLIGENT DATA ACQUISITION AND ADVANCED COMPUTING SYSTEMS (IDAACS-SWS), P10, DOI 10.1109/IDAACS-SWS.2018.8525539
   Xu JQ, 2014, CHIN CONTR CONF, P8633, DOI 10.1109/ChiCC.2014.6896450
   Xue B, 2016, IEEE T EVOLUT COMPUT, V20, P606, DOI 10.1109/TEVC.2015.2504420
   Yan XQ, 2021, NEUROCOMPUTING, V448, P106, DOI 10.1016/j.neucom.2021.03.090
   Yanai H, 2007, HANDB STAT, V26, P257, DOI 10.1016/S0169-7161(06)26009-7
   Yang XS, 2018, STUD COMPUT INTELL, V744, P1, DOI 10.1007/978-3-319-67669-2_1
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   Yin B, 2020, BIOMED SIGNAL PROCES, V56, DOI 10.1016/j.bspc.2019.101728
   Yuan HL, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON CYBERNETICS (CYBCONF), DOI 10.1109/CYBConf.2013.6617430
   Zhang Q, 2019, IEEE ACCESS, V7, P36642, DOI 10.1109/ACCESS.2019.2905009
   Zhang X, 2018, MECH SYST SIGNAL PR, V107, P29, DOI 10.1016/j.ymssp.2018.01.027
   Zheng YF, 2019, IEEE ACCESS, V7, P14908, DOI 10.1109/ACCESS.2018.2879848
NR 144
TC 3
Z9 3
U1 10
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 28
PY 2023
DI 10.1007/s11042-023-17329-y
EA OCT 2023
PG 72
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W7FP7
UT WOS:001093249700005
DA 2024-07-18
ER

PT J
AU Abhadiomhen, SE
   Ezeora, NJ
   Ganaa, ED
   Nzeh, RC
   Adeyemo, I
   Uzo, IU
   Oguike, O
AF Abhadiomhen, Stanley Ebhohimhen
   Ezeora, Nnamdi Johnson
   Ganaa, Ernest Domanaanmwi
   Nzeh, Royransom Chiemela
   Adeyemo, Isiaka
   Uzo, Izuchukwu Uchenna
   Oguike, Osondu
TI Spectral type subspace clustering methods: multi-perspective analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Subspace clustering; Low-rank representation; Sparse subspace
   clustering; Multiview clustering
ID NONNEGATIVE MATRIX FACTORIZATION; LOW-RANK REPRESENTATION; SCRNA-SEQ
   DATA; GRAPH; SEGMENTATION; CONSENSUS; ENSEMBLE
AB Founded on the premise that high-dimensional data can be characterized as data drawn from a union of several low-dimensional subspaces, subspace clustering has become famous due to the limitations of traditional clustering techniques such as k-means. Among the subspace clustering methods, spectral-based techniques have become increasingly popular in the last decade due to their potential to handle corrupt samples through the self-expressiveness property of data. It is, therefore, crucial to compare the spectral-based methods with each other. However, previous studies often analyze them from a single perspective, which does not tell the whole story. This paper presents an analysis of existing spectral-based methods from two perspectives: single-view and multi-view. Firstly, a detailed fundamental of subspace clustering is presented. Afterward, an overview of available techniques is provided from the two perspectives. Furthermore, we evaluate the clustering performances of current techniques on four datasets: UCI-Digits, Yale, COIL20 and Caltech101-07. In each paradigm, we first compare some existing approaches against each other and then investigate the improvement of the multi-view approaches over the single-view methods. From the results of different experiments, it was evident that not all multi-view methods outperform their single-view counterparts consistently. Surprisingly, in certain datasets, some single-view methods even outperformed some multi-view methods. To strengthen this comparison, we compare the similarity matrices of the different techniques. Finally, we highlight the challenges and recommend future research.
C1 [Abhadiomhen, Stanley Ebhohimhen; Nzeh, Royransom Chiemela] Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
   [Abhadiomhen, Stanley Ebhohimhen; Ezeora, Nnamdi Johnson; Nzeh, Royransom Chiemela; Uzo, Izuchukwu Uchenna; Oguike, Osondu] Univ Nigeria, Dept Comp Sci, Nsukka, Nigeria.
   [Ganaa, Ernest Domanaanmwi] Hilla Limann Tech Univ, Sch Appl Sci & Technol, Wa, Ghana.
   [Adeyemo, Isiaka] Ladoke Akintola Univ Technol, Dept Comp Sci, Ogbomosho, Nigeria.
C3 Jiangsu University; University of Nigeria
RP Ezeora, NJ (corresponding author), Univ Nigeria, Dept Comp Sci, Nsukka, Nigeria.
EM stanley.abhadiomhen@unn.edu.ng; nnamdi.ezeora@unn.edu.ng
RI Abhadiomhen, Stanley Ebhohimhen/AAH-5788-2021; Ganaa, Ernest
   Domanaanmwi/O-5746-2019
OI Abhadiomhen, Stanley Ebhohimhen/0000-0002-9509-1915; Ganaa, Ernest
   Domanaanmwi/0000-0002-2161-7435; Ezeora, Nnamdi
   Johnson/0000-0002-1379-2313
CR Abhadiomhen SE, 2021, ACM T INTEL SYST TEC, V12, DOI 10.1145/3465056
   Abhadiomhen SE, 2022, APPL INTELL, V52, P530, DOI 10.1007/s10489-021-02409-z
   Bai L., 2020, P 37 INT C MACH LEAR, P561
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Brbic M, 2018, PATTERN RECOGN, V73, P247, DOI 10.1016/j.patcog.2017.08.024
   Cai XS, 2023, INFORM FUSION, V91, P364, DOI 10.1016/j.inffus.2022.10.020
   Cai XS, 2020, LECT NOTES ARTIF INT, V12084, P330, DOI 10.1007/978-3-030-47426-3_26
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Chen J, 2021, KNOWL-BASED SYST, V223, DOI 10.1016/j.knosys.2021.107053
   Chen JH, 2014, IEEE T CYBERNETICS, V44, P1432, DOI 10.1109/TCYB.2013.2286106
   Chen Y, 2020, PROC CVPR IEEE, P4154, DOI 10.1109/CVPR42600.2020.00421
   Chen YY, 2022, IEEE T CIRC SYST VID, V32, P92, DOI 10.1109/TCSVT.2021.3055625
   ChenJ WangZ, IEEE Trans Knowl Data Eng
   ChenJ YangS, IEEE Trans Neural Netw Learn Syst
   Ding ZM, 2019, IEEE T NEUR NET LEAR, V30, P1768, DOI 10.1109/TNNLS.2018.2874567
   Ding ZM, 2016, AAAI CONF ARTIF INTE, P1181
   Ding ZM, 2014, IEEE DATA MINING, P110, DOI 10.1109/ICDM.2014.29
   Ding ZM, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3453
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Elhamifar E, 2010, INT CONF ACOUST SPEE, P1926, DOI 10.1109/ICASSP.2010.5495317
   Fan JC, 2020, IEEE T NEUR NET LEAR, V31, P749, DOI 10.1109/TNNLS.2019.2909686
   Fred ALN, 2005, IEEE T PATTERN ANAL, V27, P835, DOI 10.1109/TPAMI.2005.113
   Fu Zhiqiang, 2022, MM '22: Proceedings of the 30th ACM International Conference on Multimedia, P2220, DOI 10.1145/3503161.3548293
   FuL YangJ, Inf Sci
   Gao HC, 2015, IEEE I CONF COMP VIS, P4238, DOI 10.1109/ICCV.2015.482
   Gao W, 2021, Sci Program
   GaoW LiX, 2021, J Math
   Guo JP, 2019, IEEE ACCESS, V7, P84829, DOI 10.1109/ACCESS.2019.2923614
   Guo W, 2023, KNOWL-BASED SYST, V259, DOI 10.1016/j.knosys.2022.110092
   GuoL ZhangX, 2022, Appl Intell, P1
   Hu H, 2014, PROC CVPR IEEE, P3834, DOI 10.1109/CVPR.2014.484
   Hu Y, 2013, IEEE T PATTERN ANAL, V35, P2117, DOI 10.1109/TPAMI.2012.271
   Hu ZX, 2021, NEURAL NETWORKS, V136, P218, DOI 10.1016/j.neunet.2020.09.021
   Hui KF, 2022, KNOWL-BASED SYST, V241, DOI 10.1016/j.knosys.2022.108230
   Ji GY, 2022, INFORM SCIENCES, V615, P209, DOI 10.1016/j.ins.2022.10.026
   Jia HJ, 2023, INFORM SCIENCES, V638, DOI 10.1016/j.ins.2023.118981
   Khan GA, 2022, INT J MACH LEARN CYB, V13, P233, DOI 10.1007/s13042-021-01394-6
   Kodirov E, 2016, LECT NOTES COMPUT SC, V9905, P178, DOI 10.1007/978-3-319-46448-0_11
   Kumar A., 2011, P 28 INT C MACHINE L, P393
   KumarA RaiP, Advances in neural information processing systems, V24
   Li AL, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S0218001419550036
   Li A, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0215450
   Li CG, 2017, IEEE T IMAGE PROCESS, V26, P2988, DOI 10.1109/TIP.2017.2691557
   Li RH, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2916
   LiangH GuanH-T, 2022, Appl Computat Intell Soft Comput
   Lin Li, 2022, 2022 5th International Conference on Pattern Recognition and Artificial Intelligence (PRAI), P94, DOI 10.1109/PRAI55851.2022.9904099
   Lin Z., 2016, BIG DATA INF ANAL, V1, P139, DOI [DOI 10.3934/BDIA.2016001, 10.3934/bdia.2016001]
   LiS Y, 2014, P AAAI C ART INT
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu Q, 2019, IEEE J-STARS, V12, P1920, DOI 10.1109/JSTARS.2019.2915842
   LiuC WuZ, IEEE Trans Multimedia
   LiuG LinZ, 2010, ICML
   LiX YouC, 2022, SPIE, V12256, P95
   Lu CY, 2019, IEEE T PATTERN ANAL, V41, P487, DOI 10.1109/TPAMI.2018.2794348
   Lu CY, 2013, IEEE I CONF COMP VIS, P1345, DOI 10.1109/ICCV.2013.170
   Lu GF, 2022, APPL INTELL, V52, P5830, DOI 10.1007/s10489-021-02749-w
   Luo SR, 2018, AAAI CONF ARTIF INTE, P3730
   MatsushimaS BrbicM, Advances in neural information processing systems, V32
   NgA, Advances in neural information processing systems, V14
   Nie FP, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2564
   Parsons L., 2004, SIGKDD Explor Newsl, V6, P90, DOI 10.1145/1007730.1007731
   Patel VM, 2014, IEEE IMAGE PROC, P2849, DOI 10.1109/ICIP.2014.7025576
   Peng X, 2013, PROC CVPR IEEE, P430, DOI 10.1109/CVPR.2013.62
   Piao XL, 2021, INT C PATT RECOG, P9392, DOI 10.1109/ICPR48806.2021.9412987
   Piao XL, 2019, PROC CVPR IEEE, P12067, DOI 10.1109/CVPR.2019.01235
   Rong WT, 2021, INFORM SCIENCES, V547, P68, DOI 10.1016/j.ins.2020.07.059
   ShenX J, IEEE Trans Multimedia
   Shetta O, 2020, ROY SOC OPEN SCI, V7, DOI 10.1098/rsos.190714
   Strehl A, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P93, DOI 10.1162/153244303321897735
   Su HJ, 2021, ISPRS J PHOTOGRAMM, V171, P238, DOI 10.1016/j.isprsjprs.2020.11.018
   Sui Y, 2019, PATTERN RECOGN, V95, P261, DOI 10.1016/j.patcog.2019.06.019
   SuiJ LiuZ, IEEE Trans Cybern
   Tang C, 2020, IEEE T KNOWL DATA EN, V32, P1747, DOI 10.1109/TKDE.2019.2911946
   Tang C, 2019, IEEE T MULTIMEDIA, V21, P1724, DOI 10.1109/TMM.2018.2889560
   Tang KW, 2014, IEEE T NEUR NET LEAR, V25, P2167, DOI 10.1109/TNNLS.2014.2306063
   TangC ZhengX, IEEE Trans Knowl Data Eng
   Tao H, 2021, IEEE T CYBERNETICS, V51, P1690, DOI 10.1109/TCYB.2019.2953564
   Tao ZQ, 2020, IEEE T NEUR NET LEAR, V31, P600, DOI 10.1109/TNNLS.2019.2906867
   TaoH HouC, 2018, P AAAI C ART INT
   Tian L, 2018, INT GEOSCI REMOTE SE, P8488
   Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728
   Tolic D, 2018, PATTERN RECOGN, V82, P40, DOI 10.1016/j.patcog.2018.04.029
   Topchy A, 2005, IEEE T PATTERN ANAL, V27, P1866, DOI 10.1109/TPAMI.2005.237
   Tsakiris MC, 2018, IEEE T PATTERN ANAL, V40, P482, DOI 10.1109/TPAMI.2017.2678477
   Vidal R, 2005, IEEE T PATTERN ANAL, V27, P1945, DOI 10.1109/TPAMI.2005.244
   Vidal R, 2014, PATTERN RECOGN LETT, V43, P47, DOI 10.1016/j.patrec.2013.08.006
   Vidal R, 2011, IEEE SIGNAL PROC MAG, V28, P52, DOI 10.1109/MSP.2010.939739
   Wang LB, 2023, PATTERN RECOGN, V139, DOI 10.1016/j.patcog.2023.109438
   Wang LW, 2005, IEEE T PATTERN ANAL, V27, P1334, DOI 10.1109/TPAMI.2005.165
   Wang QQ, 2018, IEEE DATA MINING, P1290, DOI 10.1109/ICDM.2018.00174
   [王应德 Wang Yingde], 2013, [高分子通报, Polymer Bulletin], P89
   Wang ZY, 2021, IET IMAGE PROCESS, V15, P3573, DOI 10.1049/ipr2.12232
   Wei D, 2021, INFORM SCIENCES, V576, P725, DOI 10.1016/j.ins.2021.08.040
   Wen J, 2018, NEURAL NETWORKS, V108, P83, DOI 10.1016/j.neunet.2018.08.007
   Wen J, 2018, PATTERN RECOGN, V81, P326, DOI 10.1016/j.patcog.2018.04.004
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Wong WK, 2017, IEEE T IMAGE PROCESS, V26, P2905, DOI 10.1109/TIP.2017.2691543
   Wu JL, 2020, AAAI CONF ARTIF INTE, V34, P6388
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2149
   Xiao SJ, 2016, IEEE T NEUR NET LEAR, V27, P2268, DOI 10.1109/TNNLS.2015.2472284
   Xiaobo Wang, 2017, 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P1, DOI 10.1109/CVPR.2017.8
   Xie XY, 2018, IEEE T IMAGE PROCESS, V27, P477, DOI 10.1109/TIP.2017.2764262
   Xu X, 2018, PROC CVPR IEEE, P2859, DOI 10.1109/CVPR.2018.00302
   Xu YS, 2023, PATTERN RECOGN, V135, DOI 10.1016/j.patcog.2022.109152
   Xue Z, 2019, INFORM SCIENCES, V482, P210, DOI 10.1016/j.ins.2019.01.018
   Yan XQ, 2021, NEUROCOMPUTING, V448, P106, DOI 10.1016/j.neucom.2021.03.090
   Yang CY, 2015, PR MACH LEARN RES, V37, P2463
   Yang Y, 2018, BIG DATA MIN ANAL, V1, P83, DOI 10.26599/BDMA.2018.9020003
   Yang ZY, 2019, IEEE T IMAGE PROCESS, V28, P5147, DOI 10.1109/TIP.2019.2913096
   Yang ZY, 2021, IEEE T CYBERNETICS, V51, P3249, DOI 10.1109/TCYB.2020.2984552
   Yin QY, 2015, NEUROCOMPUTING, V156, P12, DOI 10.1016/j.neucom.2015.01.017
   Zhan K, 2019, IEEE T IMAGE PROCESS, V28, P1261, DOI 10.1109/TIP.2018.2877335
   Zhang CQ, 2017, PROC CVPR IEEE, P4333, DOI 10.1109/CVPR.2017.461
   Zhang CQ, 2015, IEEE I CONF COMP VIS, P1582, DOI 10.1109/ICCV.2015.185
   Zhang C, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4156, DOI 10.1145/3474085.3475548
   Zhang P, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20205755
   Zhang W, 2022, IEEE J BIOMED HEALTH, V26, P1394, DOI 10.1109/JBHI.2021.3099127
   Zhang XB, 2021, COMPUT METH PROG BIO, V199, DOI 10.1016/j.cmpb.2020.105895
   ZhangC LiH, IEEE Trans Neural Netw Learn Syst
   Zhao HD, 2017, AAAI CONF ARTIF INTE, P2921
   ZhaoL ZhangJ, 2022, Appl Intell, P1
   Zheng RQ, 2020, FRONT GENET, V11, DOI 10.3389/fgene.2020.00407
   Zheng RQ, 2019, BIOINFORMATICS, V35, P3642, DOI 10.1093/bioinformatics/btz139
   Zhou T, 2020, IEEE T CYBERNETICS, V50, P3517, DOI 10.1109/TCYB.2019.2918495
   Zhu WJ, 2020, KNOWL-BASED SYST, V204, DOI 10.1016/j.knosys.2020.106199
   Zhuang JJ, 2021, IEEE ACCESS, V9, P9719, DOI 10.1109/ACCESS.2021.3049807
NR 126
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 27
PY 2023
DI 10.1007/s11042-023-16846-0
EA OCT 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0GO3
UT WOS:001088502300012
DA 2024-07-18
ER

PT J
AU Singh, MK
   Ahmed, J
   Alam, MA
   Raghuvanshi, KK
   Kumar, S
AF Singh, Manish Kumar
   Ahmed, Jawed
   Alam, Mohammad Afshar
   Raghuvanshi, Kamlesh Kumar
   Kumar, Sachin
TI A comprehensive review on automatic detection of fake news on social
   media
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Social media; Fake news; Detection methods; Machine learning; Datasets
ID FALSE NEWS; FEATURES
AB Social media sites are now quite popular among internet users for sharing news and opinions. This has become possible due to the inexpensive Internet, easy availability of digital devices, and the no-cost policy to create a user account on social media platforms. People are fascinated by social media sites because they can easily connect with others to share their interests, news, and opinions. According to studies, someone who lacks credibility is more likely to spread false information in order to achieve goals of any kind, be it influencing political opinions, earning attention, or making money. The automatic detection of social media related fake news has thus emerged as a highly anticipated research area in recent years. This paper offers a comprehensive review of the automatic detection of fake news on social media platforms. It contains details of the key models or techniques related to machine/deep learning proposed (or developed) during the period of the year 2011 to the year 2022 along with the performance metrics of each model or technique. The paper discusses (a). the key challenges faced during the development of an effective and efficient fake news detection system, (b). some popular datasets for carrying out fake news detection related research, and (c). the major research gaps, and future research directions in the area of automatic fake news detection on social media.
C1 [Singh, Manish Kumar; Ahmed, Jawed; Alam, Mohammad Afshar] Jamia Hamdard, Sch Engn Sci & Technol, Dept Comp Sci & Engn, New Delhi 110062, India.
   [Raghuvanshi, Kamlesh Kumar] Univ Delhi, Dept Comp Sci, Ramanujan Coll, New Delhi 110019, India.
   [Kumar, Sachin] Univ Delhi, Cluster Innovat Ctr, GC Narang Rd, Delhi 110007, India.
C3 Jamia Hamdard University; University of Delhi; University of Delhi
RP Singh, MK (corresponding author), Jamia Hamdard, Sch Engn Sci & Technol, Dept Comp Sci & Engn, New Delhi 110062, India.
EM manish.kumar2191989@gmail.com; jahmed2047@jamiahamdard.ac.in;
   aalam@jamiahamdard.ac.in; kamlesh@ramanujan.du.ac.in;
   skumar@cic.du.ac.in
RI kumar, sachin/JXY-1719-2024
OI Kumar Singh, Dr. Manish/0000-0002-4216-7920; Raghuvanshi, Dr. Kamlesh
   Kumar/0000-0001-9887-3392
CR Ahmed U., 2022, ACM T ASIAN LOW-RESO
   Ahmed U, 2023, ACM Trans Asian Low-Resour Lang Inf Process
   Ajao O, 2018, SMSOCIETY'18: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON SOCIAL MEDIA AND SOCIETY, P226, DOI 10.1145/3217804.3217917
   Al-Rubaie A, 2019, P 2019 3 INT C COMP, ppp201
   Aldwairi M, 2018, PROCEDIA COMPUT SCI, V141, P215, DOI 10.1016/j.procs.2018.10.171
   Alkhodair SA, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.02.016
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   [Anonymous], 2017, Independent10-Sept
   [Anonymous], 2013, WEF Report, MTR-3, Rev.
   Assiroj P, 2018, 2018 INDONESIAN ASSOCIATION FOR PATTERN RECOGNITION INTERNATIONAL CONFERENCE (INAPR), P186, DOI 10.1109/INAPR.2018.8627053
   Atanasova P, 2019, ACM J DATA INF QUAL, V11, DOI 10.1145/3297722
   Atodiresei CS, 2018, PROCEDIA COMPUT SCI, V126, P451, DOI 10.1016/j.procs.2018.07.279
   Bani-Hani A, 2022, Combating Fake News with Computational Intelligence Techniques, ppp91
   Beauvais C, 2022, JOINT BONE SPINE, V89, DOI 10.1016/j.jbspin.2022.105371
   Bharadwaj P, 2019, Int J Nat Lang Comput8
   Buntain C, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SMART CLOUD (SMARTCLOUD), P208, DOI 10.1109/SmartCloud.2017.40
   Cardoso Durier da Silva F, 2019, HAW INT C SYST SCI, DOI [10.24251/HICSS.2019.332, DOI 10.24251/HICSS.2019.332]
   Castillo C., 2011, P 20 INT C WORLD WID, P675, DOI DOI 10.1145/1963405.1963500
   Castillo C, 2013, INTERNET RES, V23, P560, DOI 10.1108/IntR-05-2012-0095
   Chen Y., 2015, Proceedings of the 2015 ACM on Workshop on Multimodal Deception Detection, P15, DOI 10.1145/2823465.2823467
   Chi HX, 2022, KNOWL-BASED SYST, V242, DOI 10.1016/j.knosys.2022.108378
   Choudhury D, 2023, MULTIMED TOOLS APPL, V82, P9029, DOI 10.1007/s11042-022-12788-1
   Cohen S, 2011, COMMUN ACM, V54, P66, DOI 10.1145/2001269.2001288
   Della Vedova ML, 2018, PROC CONF OPEN INNOV, P272, DOI 10.23919/FRUCT.2018.8468301
   Djenouri Y., 2023, IEEE Trans Comput Soc Syst
   Dong MQ, 2018, LECT NOTES COMPUT SC, V11233, P199, DOI 10.1007/978-3-030-02922-7_14
   Dou YT, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2051, DOI 10.1145/3404835.3462990
   Elhadad MK, 2019, IEEE PAC RIM CONF CO, DOI 10.1109/pacrim47961.2019.8985062
   Ferrara E, 2016, COMMUN ACM, V59, P96, DOI 10.1145/2818717
   Ferreira W., 2016, P 2016 C N AM CHAPT, DOI DOI 10.18653/V1/N16-1138
   Fleming C, 2010, PARALLAX, V16, P45, DOI 10.1080/13534645.2010.508648
   Galli A, 2022, J INTELL INF SYST, V59, P237, DOI 10.1007/s10844-021-00646-9
   Guacho GB, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P322, DOI 10.1109/ASONAM.2018.8508241
   Gupta S, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P278, DOI 10.1109/ASONAM.2018.8508408
   Helmstetter S, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P274, DOI 10.1109/ASONAM.2018.8508520
   Howard Philip N., 2016, Bots, #Strongerin, and #Brexit: Computational Propaganda During the UK-EU Referendum
   Iwendi C, 2022, COMPUT ELECTR ENG, V101, DOI 10.1016/j.compeleceng.2022.107967
   Janze C., 2017, Automatic detection of fake news on social media platforms
   Jin ZW, 2016, AAAI CONF ARTIF INTE, P2972
   Jin ZW, 2017, IEEE T MULTIMEDIA, V19, P598, DOI 10.1109/TMM.2016.2617078
   Jin ZW, 2014, IEEE DATA MINING, P230, DOI 10.1109/ICDM.2014.91
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Kaliyar RK, 2021, MULTIMED TOOLS APPL, V80, P11765, DOI 10.1007/s11042-020-10183-2
   Karimi H, 2018, P 27 INT C COMP LING, ppp1546
   Kesarwani A, 2020, PROCEEDINGS OF THE 2020 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING AND COMMUNICATION ENGINEERING (ICACCE-2020), DOI 10.1109/icacce49060.2020.9154997
   Kietzmann JH, 2011, BUS HORIZONS, V54, P241, DOI 10.1016/j.bushor.2011.01.005
   Kotteti CMM, 2018, 2018 16TH IEEE INT CONF ON DEPENDABLE, AUTONOM AND SECURE COMP, 16TH IEEE INT CONF ON PERVAS INTELLIGENCE AND COMP, 4TH IEEE INT CONF ON BIG DATA INTELLIGENCE AND COMP, 3RD IEEE CYBER SCI AND TECHNOL CONGRESS (DASC/PICOM/DATACOM/CYBERSCITECH), P187, DOI 10.1109/DASC/PiCom/DataCom/CyberSciTec.2018.00042
   Kshetri N, 2017, IT PROF, V19, P8, DOI 10.1109/MITP.2017.4241459
   Kucharski A, 2016, NATURE, V540, P525, DOI 10.1038/540525a
   Kumar S, 2018, Arxiv, DOI [arXiv:1804.08559, 10.48550/arXiv.1804.08559]
   Kwon S, 2013, IEEE DATA MINING, P1103, DOI 10.1109/ICDM.2013.61
   Liu Y, 2018, AAAI CONF ARTIF INTE, P354
   Lu YJ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P505
   Ma J., 2015, P 24 ACM INT C INF K, P1751, DOI DOI 10.1145/2806416.2806607
   Magnini B, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P43
   Meinert J, 2018, LECT NOTES COMPUT SC, V10913, P484, DOI 10.1007/978-3-319-91521-0_35
   Min EX, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P1148, DOI 10.1145/3485447.3512163
   Mohammad SM, 2017, ACM T INTERNET TECHN, V17, DOI 10.1145/3003433
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   Mridha MF, 2021, IEEE ACCESS, V9, P156151, DOI 10.1109/ACCESS.2021.3129329
   Nasir J.A., 2021, International Journal of Information Management Data Insights, V1, P100007, DOI [10.1016/j.jjimei.2020.100007, DOI 10.1016/J.JJIMEI.2020.100007]
   Ni SW, 2021, IEEE ACCESS, V9, P106907, DOI 10.1109/ACCESS.2021.3100245
   Niklewicz Konrad., 2017, European View, V16, P335, DOI DOI 10.1007/S12290-017-0468-0
   Olivieri AC, 2019, PROCEEDINGS OF THE 52ND ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P5196
   Ozbay FA, 2021, MULTIMED TOOLS APPL, V80, P34333, DOI 10.1007/s11042-021-11006-8
   Ozgobek O, 2017, CEUR WORKSHOP PROC
   Pan JZ, 2018, LECT NOTES COMPUT SC, V11136, P669, DOI 10.1007/978-3-030-00671-6_39
   Parikh SB, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P436, DOI 10.1109/MIPR.2018.00093
   Perez-Rosas Perez-Rosas V. V., P 27 INT C COMP LING, P3391
   Perrin A., 2015, Pew research center, V125, P52
   Pierri F, 2019, SIGMOD REC, V48, P18, DOI 10.1145/3377330.3377334
   PTI, 2022, Govt orders blocking of 18 indian four pakistani youtube-based news channels
   Raponi S, 2022, ACM T WEB, V16, DOI 10.1145/3522756
   Rapoza K., 2017, FORBES
   Rasool T, 2019, INT CONF COMPUT AUTO, P73, DOI 10.1145/3313991.3314008
   Rastogi S, 2022, MULTIMED TOOLS APPL, V81, P40675, DOI 10.1007/s11042-022-13129-y
   Raza S, 2022, INT J DATA SCI ANAL, V13, P335, DOI 10.1007/s41060-021-00302-z
   Reis JCS, 2019, IEEE INTELL SYST, V34, P76, DOI 10.1109/MIS.2019.2899143
   Rousidis D, 2020, MULTIMED TOOLS APPL, V79, P6279, DOI 10.1007/s11042-019-08291-9
   Rubin V.L., 2015, P HAW INT C SYST SCI, P5
   Rubin VL, 2015, J ASSOC INF SCI TECH, V66, P905, DOI 10.1002/asi.23216
   Rubin Victoria L., 2015, Proceedings of the Association for Information Science and Technology, V52, P1, DOI [10.1002/pra2.2015.145052010083, DOI 10.1002/PRA2.2015.145052010083]
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Sadeghi F, 2022, MULTIMED TOOLS APPL, V81, P33801, DOI 10.1007/s11042-022-12428-8
   Sahoo SR, 2021, APPL SOFT COMPUT, V100, DOI 10.1016/j.asoc.2020.106983
   Sailunaz K, 2022, MULTIMED TOOLS APPL, V81, P31907, DOI 10.1007/s11042-022-12616-6
   Salve P, 2020, Manipulative fake news on the rise in india under lockdown
   Seddari N., 2022, IEEE Access
   Shao CC, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-06930-7
   Shao CC, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196087
   Sharma K, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3305260
   Shayan Sardarizadeh OR, 2022, BBC Monitoring
   Shelke S, 2022, MULTIMED TOOLS APPL, V81, P17347, DOI 10.1007/s11042-022-12761-y
   Shu K., 2020, P INT AAAI C WEB SOC, P626, DOI DOI 10.1609/ICWSM.V14I1.7329
   Shu K, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P436, DOI 10.1145/3341161.3342927
   Shu K, 2019, COMPUT MATH ORGAN TH, V25, P60, DOI 10.1007/s10588-018-09280-3
   Singh MK, 2023, INT C SMART COMP COM, ppp277
   Spohr Dominic, 2017, Business Information Review, V34, P150, DOI 10.1177/0266382117722446
   Tandoc EC, 2018, DIGIT JOURNAL, V6, P137, DOI 10.1080/21670811.2017.1360143
   Traylor T, 2019, IEEE INT C SEMANT CO, P445, DOI [10.1109/ICSC.2019.00086, 10.1109/ICOSC.2019.8665593]
   Upadhyay R, 2023, MULTIMED TOOLS APPL, V82, P5271, DOI 10.1007/s11042-022-13368-z
   Verma PK, 2021, IEEE T COMPUT SOC SY, V8, P881, DOI 10.1109/TCSS.2021.3068519
   Vlachos A., 2014, P ACL 2014 WORKSH LA, P18, DOI [DOI 10.3115/V1/W14-2508, 10.3115/v1/W14-2508]
   Volkova S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P647, DOI 10.18653/v1/P17-2102
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Wang C., 2020, CONT MANAG RES, V16, P145, DOI [DOI 10.7903/CMR.20677, 10.7903/cmr.20677]
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Wardle C, 2018, Journalism,'fake news'& disinformation, P43
   Wu L, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P637, DOI 10.1145/3159652.3159677
   Yang S, 2019, AAAI CONF ARTIF INTE, P5644
   Zhang XC, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.03.004
   Zhou X., 2020, DIGITAL THREATS RES, V1, P1
   Zhou XY, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3395046
NR 114
TC 0
Z9 0
U1 14
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 26
PY 2023
DI 10.1007/s11042-023-17377-4
EA OCT 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2WU9
UT WOS:001090292500003
DA 2024-07-18
ER

PT J
AU Lyle, M
   Sarosh, P
   Parah, SA
AF Lyle, Munazah
   Sarosh, Parsa
   Parah, Shabir A.
TI Selective medical image encryption based on 3D Lorenz and Logistic
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Selective medical image encryption; 3-D Lorenz map; 1-D Logistic map;
   e-healthcare
ID CHAOTIC MAPS; DNA; EFFICIENT
AB Medical images contain very sensitive and confidential information about the patient and are huge in terms of size. Therefore, there is a need to develop encryption schemes that reduce computational time without compromising the security level. Selective image encryption is one such technique that can reduce time and complexity. In this paper, we propose a selective image encryption scheme that can be used to encrypt medical images. The medical image is first decomposed into non-overlapping blocks, and then the variance of each block is calculated and compared to a preset threshold value. The blocks for which variance is greater than the threshold value are considered significant and encrypted. The pixels within each significant block are permutated with a hybrid sequence (which is different for each block) obtained from Logistic maps. The diffusion operation is performed using a different hybrid sequence obtained from a 1-D Logistic map and a 3-D Lorenz map, which also is different for every block. Finally, the cipher image is formed by concatenating the encrypted significant and insignificant blocks. The proposed encryption scheme has been tested on several grayscale and color medical images to validate its performance in terms of security provided and computational time. It has been found resilient to differential cryptanalysis, as the NPCR and UACI values are greater than 99.60% and 33.20%, respectively besides having a large key space of the order of 10(108). The PSNR values for all encrypted images are less than 12 dB even though the images are selectively encrypted, and the entropy of the Region of Interest (ROI), i.e., encrypted blocks, is nearly equal to 8, which signifies a better security of our system. The computational time required to encrypt an image of sizes 225 x 225 and 512 x 512 is 0.06 and 0.10 s respectively making it suit-able for real time applications. The experimental results show that the proposed encryption scheme provides high security with less complexity and computational time
C1 [Lyle, Munazah; Sarosh, Parsa; Parah, Shabir A.] Univ Kashmir, Post Grad Dept Elect & Instrumentat Technol, Srinagar 190006, India.
C3 University of Kashmir
RP Parah, SA (corresponding author), Univ Kashmir, Post Grad Dept Elect & Instrumentat Technol, Srinagar 190006, India.
EM shabireltr@gmail.com
OI Parah, Shabir/0000-0001-5983-0912
CR Abdmouleh MK, 2017, I C COMP GRAPH IM VI, P79, DOI 10.1109/CGiV.2017.10
   Akkasaligar PT, 2020, INF SECUR J, V29, P91, DOI 10.1080/19393555.2020.1718248
   Bhatnagar G, 2012, DIGIT SIGNAL PROCESS, V22, P648, DOI 10.1016/j.dsp.2012.02.005
   Cao WJ, 2017, SIGNAL PROCESS, V132, P96, DOI 10.1016/j.sigpro.2016.10.003
   Chen L, 2015, COMPUT BIOL MED, V65, P69, DOI 10.1016/j.compbiomed.2015.07.024
   Darwish SM, 2019, MULTIMED TOOLS APPL, V78, P19229, DOI 10.1007/s11042-019-7256-6
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gayathri J., 2016, International Journal of Information and Computer Security, V8, P347
   Gupta MD, 2021, INTEGRATION, V81, P137, DOI 10.1016/j.vlsi.2021.07.002
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hosny KM, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10091066
   Ibrahim S, 2020, IEEE ACCESS, V8, P160433, DOI 10.1109/ACCESS.2020.3020746
   Jan AM, 2022, MULTIMED TOOLS APPL, V81, P18829, DOI 10.1007/s11042-022-12653-1
   Kanso A, 2009, CHAOS SOLITON FRACT, V40, P2557, DOI 10.1016/j.chaos.2007.10.049
   Khan JS, 2020, IEEE ACCESS, V8, P159732, DOI 10.1109/ACCESS.2020.3020917
   Khan JS, 2019, MULTIDIM SYST SIGN P, V30, P943, DOI 10.1007/s11045-018-0589-x
   Khan M, 2019, MULTIMED TOOLS APPL, V78, P26203, DOI 10.1007/s11042-019-07818-4
   Khan MA, 2017, J MOD OPTIC, V64, P531, DOI 10.1080/09500340.2016.1246680
   Khashan OA, 2020, MULTIMED TOOLS APPL, V79, P26369, DOI 10.1007/s11042-020-09264-z
   Kiran, 2020, BIOSCI BIOTECH RES C, V13, P194, DOI 10.21786/bbrc/13.13/27
   Kiran P, 2022, MICROPROCESS MICROSY, V91, DOI 10.1016/j.micpro.2022.104546
   Krishnamoorthi R, 2017, MULTIMED TOOLS APPL, V76, P1217, DOI 10.1007/s11042-015-3027-1
   Kulsoom A, 2016, MULTIMED TOOLS APPL, V75, P1, DOI 10.1007/s11042-014-2221-x
   Kumar A, 2021, Communication, Networks, and Computing. Communications in Computer and Information Science, V1502, P198, DOI [10.1007/978-981-16-8896-6_16, DOI 10.1007/978-981-16-8896-6_16]
   Kumar A., 2019, Eng Appl Sci Res, V47, P66
   Liu HJ, 2023, MULTIMED TOOLS APPL, V82, P23899, DOI 10.1007/s11042-022-12069-x
   Liu HJ, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420501734
   Liu HJ, 2019, OPT LASER ENG, V122, P123, DOI 10.1016/j.optlaseng.2019.05.027
   Lyle M, 2022, MULTIMED TOOLS APPL, V81, P8179, DOI 10.1007/s11042-022-11917-0
   Mansoor S, 2023, MULTIMED TOOLS APPL, V82, P28769, DOI 10.1007/s11042-023-14542-7
   Massoudi A, 2008, EURASIP J INF SECUR, DOI 10.1155/2008/179290
   Mirjalili S, 2020, Chaotic Biogeography based Optimisation (CBBO) algorithm
   Nazeh Abdul Wahid MN., 2018, J COMPUT SCI APPL IN, V3, P1, DOI DOI 10.15226/2474-9257/3/2/00132
   Ott E, 1994, Chaos in dynamical systems, V47, P45, DOI [10.1063/1.2808369, DOI 10.1063/1.2808369]
   Ravichandran D, 2017, IEEE T NANOBIOSCI, V16, P850, DOI 10.1109/TNB.2017.2780881
   Rehman AU, 2015, MULTIMED TOOLS APPL, V74, P4655, DOI 10.1007/s11042-013-1828-7
   Sahi MA, 2018, IEEE ACCESS, V6, P464, DOI 10.1109/ACCESS.2017.2767561
   Sarosh P, 2023, IEEE T IND INFORM, V19, P8137, DOI 10.1109/TII.2022.3217039
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Sharma N, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0149-4
   Som S, 2019, MULTIMED TOOLS APPL, V78, P10373, DOI 10.1007/s11042-018-6539-7
   Song W., 2013, International Journal of Pure and Applied Mathematics, V83, P101
   Tresor LO, 2019, IEEE ACCESS, V7, P103463, DOI 10.1109/ACCESS.2019.2929244
   Ullah I, 2013, 2013 2ND NATIONAL CONFERENCE ON INFORMATION ASSURANCE (NCIA), P125, DOI 10.1109/NCIA.2013.6725336
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Zhu SQ, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22070772
NR 46
TC 0
Z9 0
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 24
PY 2023
DI 10.1007/s11042-023-16996-1
EA OCT 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0VW7
UT WOS:001088903700015
DA 2024-07-18
ER

PT J
AU Sekarputri, JA
   Fitriani, WR
   Hidayanto, AN
   Kurnia, S
AF Sekarputri, Janitra Ariena
   Fitriani, Widia Resti
   Hidayanto, Achmad Nizar
   Kurnia, Sherah
TI The roles of privacy, security, and dissatisfaction in affecting
   switching intention on messenger applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Messenger application; Switching intention; Push-pull-mooring; Inertia;
   Privacy; Security; Dissatisfaction
ID UNDERSTANDING USERS INTENTION; BEHAVIOR; PULL; PUSH; PERSPECTIVE;
   CONTINUANCE; COMMITMENT; MIGRATION; COSTS; MODEL
AB The emergence of privacy issues in messenger applications influences people to switch to an alternative application. This research investigates the users' intention to switch from the old messenger application to the new one using push, pull, and mooring factors. This study applies a quantitative approach by distributing online questionnaires. The data of 1,022 respondents were processed and analyzed by the Covariance Based Structural Equation Model. The study found that among the three push factors, namely perceived privacy risk, dissatisfaction, and perceived security risk, only dissatisfaction significantly influences switching intentions. Dissatisfaction was also significant as a mediator between perceived privacy and security risks. Pull factors of network externalities, subjective norms, and alternatives attractiveness significantly influence switching intention. As mooring factors, inertia, affective commitment, and habit influenced switching intention. Findings from this study indicate that the switching intention variable has a strong R square of 67.5%. This research contributes to the literature regarding the impact of privacy and security on the intention to switch messenger applications. This research is expected to benefit industry players to implement appropriate features, keep current users, and attract new users based on alternative attractiveness factors.
C1 [Sekarputri, Janitra Ariena; Fitriani, Widia Resti; Hidayanto, Achmad Nizar] Univ Indonesia, Fac Comp Sci, Depok, Indonesia.
   [Kurnia, Sherah] Univ Melbourne, Sch Comp & Informat Syst, Melbourne, Australia.
C3 University of Indonesia; University of Melbourne
RP Fitriani, WR (corresponding author), Univ Indonesia, Fac Comp Sci, Depok, Indonesia.
EM widiaresti@cs.ui.ac.id
OI Resti Fitriani, Widia/0000-0002-1022-6754
FU This work is supported by Penelitian Dasar Unggulan Perguruan Tinggi
   (PDUPT) Grant from Ministry of Education, Culture, Research, and
   Technology, Republic of Indonesia with contract number:
   NKB-869/UN2.RST/HKP.05.00/2023. [NKB-869/UN2.RST/HKP.05.00/2023];
   Penelitian Dasar Unggulan Perguruan Tinggi (PDUPT) Grant from Ministry
   of Education, Culture, Research, and Technology, Republic of Indonesia
FX This work is supported by Penelitian Dasar Unggulan Perguruan Tinggi
   (PDUPT) Grant from Ministry of Education, Culture, Research, and
   Technology, Republic of Indonesia with contract number:
   NKB-869/UN2.RST/HKP.05.00/2023.
CR AJZEN I, 1991, ORGAN BEHAV HUM DEC, V50, P179, DOI 10.1016/0749-5978(91)90020-T
   Al-Mashraie M, 2020, COMPUT IND ENG, V144, DOI 10.1016/j.cie.2020.106476
   [Anonymous], 1988, J RISK UNCERTAIN, DOI [DOI 10.1007/BF00055564, 10.1007/BF00055564]
   Asosiasi Penyedia Jaringan Internet Indonesia, 2021, Laporan Survei Internet APJII 2019-2020 (Q2)
   Bansal HS, 2005, J ACAD MARKET SCI, V33, P96, DOI 10.1177/0092070304267928
   Bateman PJ, 2011, INFORM SYST RES, V22, P841, DOI 10.1287/isre.1090.0265
   Belanger F, 2002, J STRATEGIC INF SYST, V11, P245, DOI 10.1016/S0963-8687(02)00018-5
   BOGUSLAW R, 1968, AM SOCIOL REV, V33, P173, DOI 10.2307/2092293
   Bölen MC, 2020, TECHNOL SOC, V63, DOI 10.1016/j.techsoc.2020.101439
   Calvo-Porral C, 2017, TELEMAT INFORM, V34, P717, DOI 10.1016/j.tele.2016.08.022
   Cerruto F, 2022, J BIG DATA-GER, V9, DOI 10.1186/s40537-022-00566-7
   Chang IC, 2014, INFORM SYST J, V24, P323, DOI 10.1111/isj.12030
   Chen LY, 2023, J RETAIL CONSUM SERV, V74, DOI 10.1016/j.jretconser.2023.103414
   Cheng S, 2019, COMPUT HUM BEHAV, V92, P198, DOI 10.1016/j.chb.2018.10.035
   Dixit P, 2021, WhatsApp Fueled A Global Misinformation Crisis. Now, It's Stuck In One
   Fei L, 2014, P ANN HICSS, P551, DOI 10.1109/HICSS.2014.76
   Gaskin J, 2021, Causal Models
   Hair JF, 2010, Multivariate data analysis
   Hashim KF, 2015, INT J INFORM MANAGE, V35, P145, DOI 10.1016/j.ijinfomgt.2014.11.001
   Hou A., 2014, PACIS 2014 P, V64
   Hsieh JK, 2012, COMPUT HUM BEHAV, V28, P1912, DOI 10.1016/j.chb.2012.05.010
   Hsu CL, 2004, INFORM MANAGE-AMSTER, V41, P853, DOI 10.1016/j.im.2003.08.014
   Jin XL, 2010, BEHAV INFORM TECHNOL, V29, P383, DOI 10.1080/01449290903398190
   Jones MA, 2000, J RETAILING, V76, P259, DOI 10.1016/S0022-4359(00)00024-5
   Jung J, 2017, TOURISM MANAGE, V59, P139, DOI 10.1016/j.tourman.2016.07.018
   Kim D, 2018, TELEMAT INFORM, V35, P1643, DOI 10.1016/j.tele.2018.04.010
   Kothari CR, 2004, NEW AGE INT
   Kuo RZ, 2020, TECHNOL SOC, V62, DOI 10.1016/j.techsoc.2020.101312
   Li CY, 2018, COMPUT HUM BEHAV, V84, P171, DOI 10.1016/j.chb.2017.12.042
   Li J, 2020, ENVIRON HEALTH PREV, V25, DOI 10.1186/s12199-020-00896-z
   Lin CN, 2017, ASLIB J INFORM MANAG, V69, P201, DOI 10.1108/AJIM-08-2016-0127
   Ming-Chien Hung, 2007, International Journal of Mobile Communications, V5, P409, DOI 10.1504/IJMC.2007.012788
   Moon B, 1995, PROG HUM GEOG, V19, P504, DOI 10.1177/030913259501900404
   Nurhayati-Wolff H, 2021, Number of smartphone users in Indonesia from 2015 to 2025
   Oghuma AP, 2016, TELEMAT INFORM, V33, P34, DOI 10.1016/j.tele.2015.05.006
   Peng XX, 2016, COMPUT HUM BEHAV, V64, P206, DOI 10.1016/j.chb.2016.06.054
   Polites GL, 2012, MIS QUART, V36, P21
   Santoso S., 2018, Konsep Dasar dan Aplikasi SEM dengan Amos 24
   Singh M, 2020, Telegram, nearing 500 million users, to begin monetizing the app
   Singh R, 2020, J RETAIL CONSUM SERV, V53, DOI 10.1016/j.jretconser.2019.101962
   Sun YQ, 2017, COMPUT HUM BEHAV, V75, P727, DOI 10.1016/j.chb.2017.06.014
   Verplanken B., 1999, EUR REV SOC PSYCHOL, V10, P101, DOI DOI 10.1080/14792779943000035
   Wang L, 2019, INFORM MANAGE-AMSTER, V56, DOI 10.1016/j.im.2019.02.005
   We Are Social, 2021, Digital in 2021
   WhatsApp, 2021, We're updating our Terms of Service and Privacy Policy
   Wu CH, 2019, J RETAIL CONSUM SERV, V49, P219, DOI 10.1016/j.jretconser.2019.03.024
   Wu KW, 2017, COMPUT HUM BEHAV, V68, P300, DOI 10.1016/j.chb.2016.11.039
   Ye C, 2011, COMMUN ASSOC INF SYS, V28, P585
   Ye DY, 2022, HELIYON, V8, DOI 10.1016/j.heliyon.2022.e11145
   Zengyan C., 2009, Proceedings of the 42nd Hawaii International Conference on System Sciences, P1, DOI DOI 10.1109/HICSS.2009.140
   Zhang K. Z. K., 2008, 41 ANN HAW INT C SYS, P269, DOI DOI 10.1109/HICSS.2008.478
   Zhou T, 2011, COMPUT HUM BEHAV, V27, P883, DOI 10.1016/j.chb.2010.11.013
NR 52
TC 0
Z9 0
U1 11
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 24
PY 2023
DI 10.1007/s11042-023-17466-4
EA OCT 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0VW7
UT WOS:001088903700007
DA 2024-07-18
ER

PT J
AU Xing, W
   Qi-liang, W
   Gui-rong, T
   Dai-li, Q
   Ke, Z
AF Xing, Wang
   Qi-liang, Wu
   Gui-rong, Tan
   Dai-li, Qian
   Ke, Zhou
TI A forecast model of short-term wind speed based on the attention
   mechanism and long short-term memory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Wind speed forecasting; Attention mechanism; Encoder-decoder; Long
   short-term memory; Deep learning; Dynamic weight
ID PREDICTION; LSTM
AB Gale is a kind of disaster weather, and the forecast of wind speed is a difficult point in operational weather forecast. In this study, we propose a method to forecast the time series of wind speed in the future period at the target station by using the time series of wind speed in the past period at the target station and its adjacent stations. This method is established by using deep learning technology. Based on the infrastructure of encoder-decoder, the driving series at the adjacent stations and the target series at the target station are taken as the input of the encoder module and the decoder module, respectively. There are two attention layers in the encoder module. One is used to strengthen the contribution of each influence factor in the input driving series to the hidden state in the long short-term memory (LSTM) layer. The other is used to enable the encoder to adaptively select the hidden state output by the LSTM layer. The loss function based on the Gaussian kernel function is adopted in the forecast model of this study, and the dynamic weight is designed to optimize the attention to the errors of the output results at different forecast leading times in the training process of the neural network model, thus improving the model forecast performance for longer forecast leading times. The results show that the performance of this method is excellent in the wind speed forecast from T+1 to T+24. The mean absolute error and root mean squared error of the forecast results at T+24 are 0.796 m <middle dot> s-1 and 1.029 m <middle dot> s-1, respectively, which are better than those of the other two models in the experiment. It is proved that the method proposed in this study can not only be applied to the wind speed forecast but also can provide technical support for operational applications such as early-warning of gale disaster and wind power prediction.
C1 [Xing, Wang; Gui-rong, Tan; Dai-li, Qian] Nanjing Univ Informat Sci & Technol, Natl Demonstrat Ctr Expt Atmospher Sci & Environm, Nanjing, Jiangsu, Peoples R China.
   [Xing, Wang; Qi-liang, Wu] Nanjing Univ Informat Sci & Technol, Sch Artificial Intelligence, Nanjing, Jiangsu, Peoples R China.
   [Ke, Zhou] Nanjing Univ Aeronaut & Astronaut, Coll Civil Aviat, Nanjing, Jiangsu, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology; Nanjing University of
   Aeronautics & Astronautics
RP Xing, W (corresponding author), Nanjing Univ Informat Sci & Technol, Natl Demonstrat Ctr Expt Atmospher Sci & Environm, Nanjing, Jiangsu, Peoples R China.; Xing, W (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Artificial Intelligence, Nanjing, Jiangsu, Peoples R China.
EM wx@nuist.edu.cn
OI Xing, Wang/0000-0002-7300-9677
FU This work is financially supported by the National Natural Science
   Foundation of China (Grand No. 41805033) and the Natural Science
   Foundation of Jiangsu Province of China (Grand No. BK20221344). We thank
   Nanjing Hurricane Translation for reviewing the Eng [41805033]; National
   Natural Science Foundation of China [BK20221344]; Natural Science
   Foundation of Jiangsu Province of China
FX This work is financially supported by the National Natural Science
   Foundation of China (Grand No. 41805033) and the Natural Science
   Foundation of Jiangsu Province of China (Grand No. BK20221344). We thank
   Nanjing Hurricane Translation for reviewing the English language quality
   of this paper.
CR Aasim, 2019, RENEW ENERG, V136, P758, DOI 10.1016/j.renene.2019.01.031
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Cao Y, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14148562
   Chen X, 2022, ENERGY, V238, DOI 10.1016/j.energy.2021.121808
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   HUANG Z, 1995, J WIND ENG IND AEROD, V56, P311, DOI 10.1016/0167-6105(94)00093-S
   Jacondino WD, 2021, ENERGY, V230, DOI 10.1016/j.energy.2021.120841
   Liang T, 2021, ENERGY, V230, DOI 10.1016/j.energy.2021.120904
   Liangyou H., 2002, IEEE Trans Energy Convers, V11, P32
   Lin GC, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114443
   Liu BC, 2021, ATMOS POLLUT RES, V12, DOI 10.1016/j.apr.2021.101144
   Liu H, 2018, ENERG CONVERS MANAGE, V159, P54, DOI 10.1016/j.enconman.2018.01.010
   Liu W, 2019, ATMOS POLLUT RES, V10, P1482, DOI 10.1016/j.apr.2019.04.005
   Luong MT, 2015, Arxiv, DOI arXiv:1508.04025
   Ma ZS, 2021, GEOSCI MODEL DEV, V14, P205, DOI 10.5194/gmd-14-205-2021
   Mohandes MA, 1998, RENEW ENERG, V13, P345, DOI 10.1016/S0960-1481(98)00001-9
   Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114
   Qin Y, 2017, Arxiv, DOI [arXiv:1704.02971, DOI 10.48550/ARXIV.1704.02971]
   Sfetsos A, 2002, RENEW ENERG, V27, P163, DOI 10.1016/S0960-1481(01)00193-8
   Shang Y, 2022, WEATHER FORECAST, V37, P415, DOI 10.1175/WAF-D-21-0047.1
   Song SL, 2019, MULTIMED TOOLS APPL, V78, P857, DOI 10.1007/s11042-018-5749-3
   Soni K, 2014, ATMOS RES, V149, P174, DOI 10.1016/j.atmosres.2014.05.025
   Varatharajan R, 2018, MULTIMED TOOLS APPL, V77, P17573, DOI [10.1007/s11042-017-4768-9, 10.1007/s11042-017-5318-1]
   Vassallo D, 2020, ENERGIES, V13, DOI 10.3390/en13205488
   Vaswani A, 2017, ADV NEUR IN, V30
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Xu WF, 2021, RENEW ENERG, V163, P772, DOI 10.1016/j.renene.2020.09.032
   Xu XN, 2022, MULTIMED TOOLS APPL, V81, P10819, DOI 10.1007/s11042-022-12215-5
   Xue H, 2021, MULTIMED TOOLS APPL, V80, P19057, DOI 10.1007/s11042-021-10611-x
   Yao WY, 2018, CHIN CONTR CONF, P7493, DOI 10.23919/ChiCC.2018.8484017
   Zhao X, 2017, MULTIMED TOOLS APPL, V76, P13739, DOI 10.1007/s11042-016-3887-z
   Zuluaga CD, 2015, APPL ENERG, V156, P321, DOI 10.1016/j.apenergy.2015.07.043
NR 32
TC 0
Z9 0
U1 4
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 24
PY 2023
DI 10.1007/s11042-023-17307-4
EA OCT 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0VW7
UT WOS:001088903700012
DA 2024-07-18
ER

PT J
AU Banerjee, A
   Banik, D
AF Banerjee, Anasua
   Banik, Debajyoty
TI Resnet based hybrid convolution LSTM for hyperspectral image
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Hyperspectral imaging (HSI); Feature extraction; Classification;
   Dimension reduction
AB There are many spectral bands of different wavelengths present in Hyperspectral Image containing a huge amount of information that helps to detect and identify various objects. Many challenges are faced at the time of analyzing a hyperspectral image like information loss, hindrances posed by redundant information lingering on input data and the presence of high dimensions, etc. In this paper, we proposed a Resnet ConvLSTM model which is composed of a 2D Convolution Neural Network together with Batch Normalization and it helps to minimize the computational complexity and to extract features from Hyperspectral Image. At the same time, we added skip connections to eliminate the vanishing gradient problem, being followed by the Long Short Term Memory layer to remove redundant information from an input image. We implemented our model on three different types of hyperspectral data sets and also on three different types of time series data sets. Our model produced better accuracy than others' proposed models reaching the levels of 0.07%, 0.01%, and 0.56% more in the "Indian Pines", "Pavia University", and "Botswana" data sets respectively. The commitment of our errors decreased in time series datasets by 0.44, 0.08, and 0.5 in "Electricity production", "International Airline Passenger" and "Production of shampoo over three years" respectively. The source code is available at https://github.com/Anasua-coding/HSI-Classification/tree/main.
C1 [Banerjee, Anasua] Natl Inst Technol, Sch Comp Engn, Adityapur 831014, Jharkhand, India.
   [Banik, Debajyoty] SR Univ, Sch Comp Sci & Artificial Intelligence, Hasanparthy 506371, Telangana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Jamshedpur
RP Banik, D (corresponding author), SR Univ, Sch Comp Sci & Artificial Intelligence, Hasanparthy 506371, Telangana, India.
EM anasua123.banerjee@gmail.com; debajyoty.banik@gmail.com
OI Banik, Dr. Debajyoty/0000-0002-3756-864X
CR Alam FI, 2019, IEEE T GEOSCI REMOTE, V57, P1612, DOI 10.1109/TGRS.2018.2867679
   [Anonymous], 2009, ISPRS J Photo Remote Sen
   Audebert N, 2019, IEEE GEOSC REM SEN M, V7, P159, DOI 10.1109/MGRS.2019.2912563
   Banik D, 2019, APPL SOFT COMPUT, V78, P230, DOI 10.1016/j.asoc.2019.02.031
   Banik D, 2019, IEEE ACCESS, V7, P1736, DOI 10.1109/ACCESS.2018.2883738
   Ben Hamida A, 2018, IEEE T GEOSCI REMOTE, V56, P4420, DOI 10.1109/TGRS.2018.2818945
   Cai YM, 2020, IEEE J-STARS, V13, P4869, DOI 10.1109/JSTARS.2020.3018229
   Cai YM, 2020, IEEE T GEOSCI REMOTE, V58, P1969, DOI 10.1109/TGRS.2019.2951433
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Fejjari A, 2021, Chapter 12 feature extraction techniques for hyperspectral images classification
   Gao PC, 2020, IEEE ACCESS, V8, P92552, DOI 10.1109/ACCESS.2020.2994345
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu WS, 2022, Arxiv, DOI arXiv:1905.03577
   Liu QS, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9121330
   Lowe A, 2017, PLANT METHODS, V13, DOI 10.1186/s13007-017-0233-z
   Makantasis K, 2015, INT GEOSCI REMOTE SE, P4959, DOI 10.1109/IGARSS.2015.7326945
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   Mou LC, 2017, IEEE T GEOSCI REMOTE, V55, P3639, DOI 10.1109/TGRS.2016.2636241
   Paoletti ME, 2018, ISPRS J PHOTOGRAMM, V145, P120, DOI 10.1016/j.isprsjprs.2017.11.021
   Peeples Joshua, 2022, IEEE Transactions on Artificial Intelligence, V3, P541, DOI 10.1109/TAI.2021.3135804
   Lorenzo PR, 2020, Arxiv, DOI arXiv:1811.02667
   Roy SK, 2020, IEEE T GEOSCI REMOTE, V58, P5277, DOI 10.1109/TGRS.2019.2961681
   Roy SK, 2020, IEEE GEOSCI REMOTE S, V17, P277, DOI 10.1109/LGRS.2019.2918719
   Signoroni A, 2019, J IMAGING, V5, DOI 10.3390/jimaging5050052
   Wang WJ, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11151794
   Waske B, 2010, IEEE T GEOSCI REMOTE, V48, P2880, DOI 10.1109/TGRS.2010.2041784
   Weinmann M., 2019, TP Kersten (Hrsg.), V39, P138
   Yan LY, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12157825
   Yan LY, 2021, MULTIMED TOOLS APPL, V80, P14363, DOI 10.1007/s11042-020-10310-z
   Yang XF, 2018, IEEE T GEOSCI REMOTE, V56, P5408, DOI 10.1109/TGRS.2018.2815613
   Zhong ZL, 2018, IEEE T GEOSCI REMOTE, V56, P847, DOI 10.1109/TGRS.2017.2755542
NR 31
TC 2
Z9 2
U1 4
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 20
PY 2023
DI 10.1007/s11042-023-16241-9
EA OCT 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6NT6
UT WOS:001085957900002
DA 2024-07-18
ER

PT J
AU Chen, Y
   Zhang, HP
   Long, J
   Xie, YN
AF Chen, Yu
   Zhang, Haopeng
   Long, Jun
   Xie, Yining
TI Temporal shift residual network for EEG-based emotion recognition: A 3D
   feature image sequence approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE EEG; emotion recognition; robust representation; DEAP
ID MUSIC
AB In EEG-based emotion recognition, finding EEG representations that maintain both temporal and spatial features is crucial. This study aims to identify robust representations from EEG independent of subject differences and discriminative. We convert EEG data into feature image sequences with 3D representation, which fully preserve the spatial, spectral and temporal structure of the EEG signal. However, existing models ignore the complementarity between spatial-spectral-temporal features, which limits the classification ability of the models to some extent. Therefore, this paper proposes the Temporal Shift Residual Network(TSM-ResNet) based on feature image sequences for EEG emotion recognition. The Temporal Shift Module(TSM), a highly efficient and high-performance temporal modeling module, is utilized. It shifts certain channels of the feature map along the time dimension, facilitating information exchange between adjacent frames. In summary, the integration of feature image sequences, encompassing multi-domain information, and the powerful temporal modeling of TSM-ResNet enable the unified integration of spatial and spectral features while adequately considering temporal sequence features, all without increasing computational costs. The effectiveness of the proposed method is validated on the internationally recognized DEAP dataset, utilizing evaluation metrics such as accuracy, F1 score, and confusion matrix. The results from subject-dependent experiments (ten-fold cross-validation) demonstrate TSM-ResNet's average accuracy of 93.43% for valence and 93.26% for arousal. Additionally, excellent performance is achieved in subject-independent experiments (leave-one-subject-out cross-validation), with accuracy rates of 64.91% for valence and 62.52% for arousal. These findings highlight the advantages of the proposed method in cross-subject and within-subject emotion recognition.
C1 [Chen, Yu; Zhang, Haopeng] Northeast Forestry Univ, Coll Comp & Control Engn, Harbin 150040, Peoples R China.
   [Long, Jun; Xie, Yining] Northeast Forestry Univ, Coll Mechean & Elect Engn, Harbin 150040, Peoples R China.
C3 Northeast Forestry University - China; Northeast Forestry University -
   China
RP Xie, YN (corresponding author), Northeast Forestry Univ, Coll Mechean & Elect Engn, Harbin 150040, Peoples R China.
EM yiningxie@nefu.edu.cn
FU National Natural Science Foundation of China [61300098]; Natural Science
   Foundation of Heilongjiang Province [F201347]; Fundamental Research
   Funds for the Central Universities [2572015DY07]
FX This work was supported by the National Natural Science Foundation of
   China (61300098), the Natural Science Foundation of Heilongjiang
   Province (F201347), and the Fundamental Research Funds for the Central
   Universities (2572015DY07).
CR Algarni M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22082976
   Arjun, 2022, BIOMED SIGNAL PROCES, V75, DOI 10.1016/j.bspc.2022.103547
   Atkinson J, 2016, EXPERT SYST APPL, V47, P35, DOI 10.1016/j.eswa.2015.10.049
   Bhatti AM, 2016, COMPUT HUM BEHAV, V65, P267, DOI 10.1016/j.chb.2016.08.029
   Chao H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092212
   Chen DW, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071631
   Chen JX, 2019, IEEE ACCESS, V7, P118530, DOI 10.1109/ACCESS.2019.2936817
   Cui H, 2020, KNOWL-BASED SYST, V205, DOI 10.1016/j.knosys.2020.106243
   Doma V, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00289-7
   Grobbelaar M, 2022, SIGNALS-BASEL, V3, P577, DOI 10.3390/signals3030035
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hernandez-Pavon JC, 2022, J NEUROSCI METH, V376, DOI 10.1016/j.jneumeth.2022.109591
   Huang DM, 2021, NEUROCOMPUTING, V448, P140, DOI 10.1016/j.neucom.2021.03.105
   Jia ZY, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2909, DOI 10.1145/3394171.3413724
   Kim BH, 2020, IEEE T AFFECT COMPUT, V11, P230, DOI 10.1109/TAFFC.2018.2790939
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Kunjan S, 2021, LECT NOTES ARTIF INT, V12960, P558, DOI 10.1007/978-3-030-86993-9_50
   Liang Z, 2019, NEURAL NETWORKS, V116, P257, DOI 10.1016/j.neunet.2019.04.003
   Lin J, 2019, IEEE I CONF COMP VIS, P7082, DOI 10.1109/ICCV.2019.00718
   Liu JM, 2018, LECT NOTES COMPUT SC, V10735, P194, DOI 10.1007/978-3-319-77380-3_19
   Liu SQ, 2022, IEEE J BIOMED HEALTH, V26, P5321, DOI 10.1109/JBHI.2021.3083525
   Liu SQ, 2023, KNOWL-BASED SYST, V265, DOI 10.1016/j.knosys.2023.110372
   Ma JX, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P176, DOI 10.1145/3343031.3350871
   Maria E, 2019, ELECTRON NOTES THEOR, V343, P35, DOI 10.1016/j.entcs.2019.04.009
   Nath Debarshi, 2020, ICCDA 2020: Proceedings of the 2020 4th International Conference on Compute and Data Analysis, P142, DOI 10.1145/3388142.3388167
   Ozerdem Mehmet Sirac, 2017, Brain Inform, V4, P241, DOI 10.1007/s40708-017-0069-3
   Pan C, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10051619
   Pandey P, 2022, J KING SAUD UNIV-COM, V34, P1730, DOI 10.1016/j.jksuci.2019.11.003
   Rayatdoost S, 2018, IEEE INT WORKS MACH
   Roy Y, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/ab260c
   Salama ES, 2018, INT J ADV COMPUT SC, V9, P329
   Sarma P, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.102991
   Shahabi H, 2016, COMPUT HUM BEHAV, V58, P231, DOI 10.1016/j.chb.2016.01.005
   Shi LC, 2013, IEEE ENG MED BIO, P6627, DOI 10.1109/EMBC.2013.6611075
   Singh U, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104060
   Soroush MZ, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101918
   Wang YX, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107626
   Yang YL, 2018, IEEE IJCNN, P793
   Yin YQ, 2021, APPL SOFT COMPUT, V100, DOI 10.1016/j.asoc.2020.106954
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P26697, DOI 10.1007/s11042-018-5885-9
   Zheng B.-L., 2016, P 25 JOINT C ART INT, P2732
   Zheng WL, 2015, IEEE T AUTON MENT DE, V7, P162, DOI 10.1109/TAMD.2015.2431497
   Zheng WL, 2014, IEEE ENG MED BIO, P5040, DOI 10.1109/EMBC.2014.6944757
NR 43
TC 1
Z9 1
U1 12
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-17142-7
EA OCT 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY6P9
UT WOS:001142539400025
DA 2024-07-18
ER

PT J
AU Malhotra, P
   Malik, SK
AF Malhotra, Pooja
   Malik, S. K.
TI Fake news detection using ensemble techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fake news; Ensemble learning models; Tokenization; Auto_ViML; Matthews
   Correlation Coefficient
AB Spreading false information or distorted news on social media with the intention of harming a person, group, or governmental entity is known as fake news. Gathering information from an online platform is an effortless process due to its speed, user-friendliness, and continuous updates. Nevertheless, this data is susceptible to personal biases or preferences, posing potential drawbacks for individuals or organizations involved. Consequently, it becomes crucial to employ computational techniques for identifying the dissemination of misinformation. Therefore, this study explored different machine learning models to classify the veracity of information by utilizing a dataset consisting of fake and real news. The analysis encompassed approximately 40,000 items, with roughly 20,000 items from each dataset category. The study utilized a combination of ensemble learning models, such as support vector machine, logistic regression, catboost, Xgboost, multinomial, naive Bayes, and random forest. The performance of these models was assessed using diverse evaluation metrics, including recall, accuracy, false rejection rate, F1 score, precision, negative predictive value, false discovery rate, and Matthews' correlation coefficient. Following these analyses, the deep auto_ViML model and passive-aggressive classifier were calculated alongside the best learning models. After calculations, the deep Auto_ViML model was found to have the highest accuracy, precision, recall, and F1 score of 99%. On the other hand, the hybrid learning model achieved the most favorable false rejection rate at 71%. In terms of computational efficiency, the support vector machine proved to be the fastest, taking only 0.245 ms to compute.
C1 [Malhotra, Pooja; Malik, S. K.] GGS Indraprastha Univ, Univ Sch Informat Commun & Technol USIC&T, New Delhi, India.
C3 GGS Indraprastha University
RP Malhotra, P (corresponding author), GGS Indraprastha Univ, Univ Sch Informat Commun & Technol USIC&T, New Delhi, India.
EM poojajind@gmail.com; skmalik@ipu.ac.in
OI Malhotra, Pooja/0000-0003-4664-3506
CR Agarwal A., 2020, SN Comput Sci, V1, P1, DOI [10.1007/s42979-020-00165-4, DOI 10.1007/S42979-020-00165-4]
   Agarwala V, 2019, PROCEDIA COMPUT SCI, V165, P377, DOI 10.1016/j.procs.2020.01.035
   Ahmad I, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/8812019
   Ahmed H, 2018, SECUR PRIVACY, V1, DOI 10.1002/spy2.9
   Ahmed S., 2022, Development of fake news model using machine learning through natural language processing
   Ali M, 2022, INT J STRATEG COMMUN, V16, P1, DOI 10.1080/1553118X.2021.1988616
   Antony Vijay J, 2020, Computational methods and data engineering, V2, P331, DOI DOI 10.1007/978-981-15-7907-3_25
   Bakir V, 2018, DIGIT JOURNAL, V6, P154, DOI 10.1080/21670811.2017.1345645
   Bezdan T, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9161929
   Brasoveanu AMP, 2019, LECT NOTES COMPUT SC, V11506, P656, DOI 10.1007/978-3-030-20521-8_54
   Braun JA, 2019, DIGIT JOURNAL, V7, P1, DOI 10.1080/21670811.2018.1556314
   Chauhan T., 2021, INT J INFORM MANAGE, V1, DOI [10.1016/j.jjimei.2021.100051, DOI 10.1016/J.JJIMEI.2021.100051]
   Choras M, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.107050
   Christensen AB, 2019, INFECT CONT HOSP EP, V40, P269, DOI 10.1017/ice.2018.336
   Della Vedova ML, 2018, PROC CONF OPEN INNOV, P272, DOI 10.23919/FRUCT.2018.8468301
   Grinberg N, 2019, SCIENCE, V363, P374, DOI 10.1126/science.aau2706
   Guo H, 2020, MediaEval', V20, P1
   Hannah Nithya S, 2023, Data Knowl Eng, V144
   Hieu TN, 2020, P 7 INT WORKSHOP VIE, P1
   Hiramath Chaitra K., 2019, 2019 1st International Conference on Advances in Information Technology (ICAIT). Proceedings, P411, DOI 10.1109/ICAIT47043.2019.8987258
   Kaliyar RohitKumar., 2018, 4 INT C COMPUTING CO, P1, DOI 10.1109/CCAA.2018.8777343
   Khan JS, 2019, ADV MAR BIOL, V82, P1, DOI 10.1016/bs.amb.2019.02.001
   Khanam Z., 2021, IOP Conference Series: Materials Science and Engineering, V1099, DOI 10.1088/1757-899X/1099/1/012040
   Kong SH, 2020, IEEE 10TH SYMPOSIUM ON COMPUTER APPLICATIONS AND INDUSTRIAL ELECTRONICS (ISCAIE 2020), P102, DOI [10.1109/ISCAIE47305.2020.9108841, 10.1109/iscaie47305.2020.9108841]
   Kumar S, 2020, T EMERG TELECOMMUN T, V31, DOI 10.1002/ett.3767
   Kumar Y., 2019, International Journal of Scientific and Technology Research, V8, P722
   Kumar Y, 2021, SOFT COMPUT, V25, P1617, DOI 10.1007/s00500-020-05248-1
   Lewis J, 2021, SEP PURIF REV, V50, P1, DOI 10.1080/15422119.2019.1609986
   Long Q., 2017, P INT JOINT C NAT LA, P252
   Madani M, 2024, INT J INF TECH DECIS, V23, P1063, DOI 10.1142/S0219622023500347
   Najar F, 2019, 2019 IEEE 20TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION FOR DATA SCIENCE (IRI 2019), P389, DOI 10.1109/IRI.2019.00066
   Nasir J.A., 2021, International Journal of Information Management Data Insights, V1, P100007, DOI [10.1016/j.jjimei.2020.100007, DOI 10.1016/J.JJIMEI.2020.100007]
   Ozbay FA, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123174
   Pinnaparaju N, 2020, CLEF, P1
   Poonam Narang, 2022, Int J Performability Eng, V18
   Reis JCS, 2019, IEEE INTELL SYST, V34, P76, DOI 10.1109/MIS.2019.2899143
   Rocha YM, 2023, J PUBLIC HEALTH-HEID, V31, P1007, DOI 10.1007/s10389-021-01658-z
   Saikh T, 2020, P 16 INT C NATURAL L, P230
   Schuster T, 2020, COMPUT LINGUIST, V46, P499, DOI [10.1162/COLI_a_00380, 10.1162/coli_a_00380]
   Shu K., 2019, Synthesis Lectures Data Min. Knowl. Discov., V11, P1, DOI [10.2200/S00926ED1V01Y201906DMK018, DOI 10.2200/S00926ED1V01Y201906DMK018]
   Shu K, 2019, COMPUT MATH ORGAN TH, V25, P60, DOI 10.1007/s10588-018-09280-3
   Singh V, 2017, INT C SOCIAL COMPUTI, P1
   Torky M, 2019, INT J ADV COMPUT SC, V10, P321
   Wu S., 2022, P ACM WEB C 2022
   Yang S, 2019, AAAI CONF ARTIF INTE, P5644
   Yazdi KM, 2020, INT J ELECT COMMUN E, V14, P38, DOI 10.5281/zenodo.3669287
   Zhou ZX, 2019, Arxiv, DOI arXiv:1901.09657
NR 47
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 13
PY 2023
DI 10.1007/s11042-023-17301-w
EA OCT 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW2V2
UT WOS:001155653100003
DA 2024-07-18
ER

PT J
AU Jorvekar, PP
   Wagh, SK
   Prasad, JR
AF Jorvekar, Priti Prakash
   Wagh, Sharmila Kishor
   Prasad, Jayashree Rajesh
TI Crop yield predictive modeling using optimized deep convolutional neural
   network: An automated crop management system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Crop Yield; Soil parameters; Statistical features; DCNN; SA-WOA
   algorithm
AB In agriculture, AI devices have developed tools that help farmers in achieving exact and controlled cultivation. Besides, it helps farmers with suitable assistance in auspicious harvesting, frequent change of crops, water management, kind of crops to be grown-up, optimum plantation, pest attack, and nourishment. To meet the requirements of the farmers, enhance yield production, and administration of agricultural activities, the proper method to predict crop yield is more significant. This paper proposes a new crop yield prediction method as part of the crop management system using deep learning (DL) models. The suggested model has three stages: "pre-processing, feature extraction, and yield prediction". Initially, data cleaning is done in the pre-processing stage and then the features like "soil parameters, Metrological Parameters and statistical and higher order statistical features" are determined. Here the soil parameters include "Soil Temperature (Morning, Afternoon, and Evening), Soil Moisture (Morning, Afternoon, Evening), Nitrogen (N) Phosphorus (P), Potassium (K), Water Holding capacity of the soil, Bulk density, Porosity. The Metrological Parameters include Air Temperature (Morning, Afternoon, Evening), Humidity (Morning, Afternoon, Evening), Light (Temperature (Morning, Afternoon, Evening), Precipitation (Morning, Afternoon, Evening), Wind speed (Morning, Afternoon, Evening), Dew point (Morning, Afternoon, Evening), Air pressure (Morning, Afternoon, Evening). maximum temperature and minimum temperature". Later these features are specified to an "Optimized Deep Convolutional Neural Network (DCNN)" that gives the prediction of crop yield results with known information. Especially, to enhance the prediction accuracy of the classifier, the weights of DCNN are fine-tuned via Self Adaptive Whale Optimization Algorithm (SA-WOA). Finally, the proposed model is observed as superior to the traditional modellingerror analysis. However, the MAE value of the proposed model is 0.247, when the learning rate is 70.
C1 [Jorvekar, Priti Prakash] STESs Smt Kashibai Navale Coll Engn, Dept Comp Engn, Pune, India.
   [Wagh, Sharmila Kishor] Modern Educ Soc Coll Engn, Dept Comp Engn, Pune, India.
   [Prasad, Jayashree Rajesh] MIT Art Design & Technol Univ, Dept Comp Engn, Pune, India.
RP Jorvekar, PP (corresponding author), STESs Smt Kashibai Navale Coll Engn, Dept Comp Engn, Pune, India.
EM pritiprakashj11@gmail.com
NR 0
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 12
PY 2023
DI 10.1007/s11042-023-16754-3
EA OCT 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ4S3
UT WOS:001142752200016
DA 2024-07-18
ER

PT J
AU Ghosh, S
   Roy, P
   Bhattacharya, S
   Pal, U
   Blumenstein, M
AF Ghosh, Subhankar
   Roy, Prasun
   Bhattacharya, Saumik
   Pal, Umapada
   Blumenstein, Michael
TI TIC: text-guided image colorization using conditional generative model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image colorization; Text-guided generation; GAN
AB Image colorization is a well-known problem in computer vision. However, due to the ill-posed nature of the task, image colorization is inherently challenging. Though several attempts have been made by researchers to make the colorization pipeline automatic, these processes often produce unrealistic results due to a lack of conditioning. In this work, we attempt to integrate textual descriptions as an auxiliary condition, along with the grayscale image that is to be colorized, to improve the fidelity of the colorization process. To the best of our knowledge, this is one of the first attempts to incorporate textual conditioning in the colorization pipeline. To do so, a novel deep network has been proposed that takes two inputs (the grayscale image and the respective encoded text description) and tries to predict the relevant color gamut. As the respective textual descriptions contain color information of the objects present in the scene, the text encoding helps to improve the overall quality of the predicted colors. The proposed model has been evaluated using different metrics like SSIM, PSNR, LPISPS and achieved scores of 0.917, 23.27,0.223, respectively. These quantitative metrics have shown that the proposed method outperforms the SOTA techniques in most of the cases.
C1 [Ghosh, Subhankar; Roy, Prasun; Blumenstein, Michael] Univ Technol Sydney, Fac Engn & IT, Ultimo, NSW, Australia.
   [Bhattacharya, Saumik] Indian Inst Technol Kharagpur, E&ECE Dept, Kharagpur, India.
   [Pal, Umapada] Indian Stat Inst, CVPR Unit, Kolkata, India.
C3 University of Technology Sydney; Indian Institute of Technology System
   (IIT System); Indian Institute of Technology (IIT) - Kharagpur; Indian
   Statistical Institute; Indian Statistical Institute Kolkata
RP Ghosh, S (corresponding author), Univ Technol Sydney, Fac Engn & IT, Ultimo, NSW, Australia.
EM subhankar.ghosh@student.uts.edu.au; prasun.roy@student.uts.edu.au;
   saumik@ece.iitkgp.ac.in; umapada@isical.ac.in;
   Michael.Blumenstein@uts.edu.au
CR Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Anwar S, 2022, Arxiv, DOI [arXiv:2008.10774, DOI 10.48550/ARXIV.2008.10774]
   Bahng Hyojin, 2018, ECCV
   Bastos R, 2013, Run-time glossy surface self-transfer processing
   Caesar H, 2018, PROC CVPR IEEE, P1209, DOI 10.1109/CVPR.2018.00132
   Carlucci F M, 2018, IEEE Robotics and Automation Letters
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Cheng ZZ, 2015, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2015.55
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deora P, 2020, IEEE COMPUT SOC CONF, P2211, DOI 10.1109/CVPRW50498.2020.00269
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Huang SS, 2022, ENG APPL ARTIF INTEL, V114, DOI 10.1016/j.engappai.2022.105006
   Kingma D. P., 2014, arXiv
   Kumar M, 2021, Arxiv, DOI [arXiv:2102.04432, 10.48550/arXiv.2102.04432]
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Luo FY, 2022, IEEE T INTELL TRANSP, V23, P15808, DOI 10.1109/TITS.2022.3145476
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Iandola FN, 2016, Arxiv, DOI arXiv:1602.07360
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tola E, 2008, PROC CVPR IEEE, P2578
   Treneska S, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22041599
   Wang P, 2018, IEEE RAD CONF, P570, DOI 10.1109/RADAR.2018.8378622
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Welinder P., 2010, Technical Report CNS-TR-2010-001
   Wu D, 2022, INT J INTELL SYST, V37, P2952, DOI 10.1002/int.22726
   Wu YZ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14357, DOI 10.1109/ICCV48922.2021.01411
   Xiao YX, 2022, INT J INTELL SYST, V37, P1222, DOI 10.1002/int.22667
   Yi-Chin Huang, 2005, 13th Annual ACM International Conference on Multimedia, P351, DOI 10.1145/1101149.1101223
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang R, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073703
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
NR 37
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 11
PY 2023
DI 10.1007/s11042-023-15330-z
EA OCT 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0RX8
UT WOS:001088800700001
OA hybrid
DA 2024-07-18
ER

PT J
AU Kaur, R
   Singh, B
AF Kaur, Rajwinder
   Singh, Butta
TI Robust image encryption algorithm in dwt domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE DWT; Image encryption; Chaotic maps; NPCR; UACI
ID WAVELET TRANSFORM; ARNOLD TRANSFORM; CHAOTIC SYSTEM; SCHEME; MAP
AB Over the past few years, the use of chaotic maps have surfaced to become an important topic in the field of image encryption. The majority of chaos-based algorithms employed single or multiple rounds of confusion and diffusion. However, such algorithms increase the security and computational cost of the encryption process. On the other hand,a higher computational process is required to maintain security. To overcome this issue, a robust image encryption method using the features of two dimensional coupling map (2D-CM) and Discret Wavelet Transform(DWT) is proposed. Additionally, low-frequency component of DWT used for encryption can significantly save storage space thereby reducing computational overheads without compromising the security of the encryption. Finally, the cover image is combined with higher frequency coefficients to obtain the whole image, which will be totally secure against external attacks. The proposed encryption technique undergoes various security analyses, including Information Entropy ( I-en), Correlation Coefficients (CC), Number of Pixel Change Rate (NPCR), Unified Average Change Intensity (UACI) and computational complexity and histogram analysis. The NPCR value and UACI obtained for all the images under simulation are greater than 99% and 33, respectively. Furthermore, results show that the proposed method has low correlation, high key sensitivity and sufficient key space (2256) to withstand against external attacks.
C1 [Kaur, Rajwinder; Singh, Butta] Guru Nanak Dev Univ, Dept Elect & Commun Engn, Reg Campus, Jalandhar, India.
C3 Guru Nanak Dev University
RP Kaur, R (corresponding author), Guru Nanak Dev Univ, Dept Elect & Commun Engn, Reg Campus, Jalandhar, India.
EM rajwinder086@gmail.com
OI Singh, Butta/0000-0002-0170-6270
CR Abdmouleh MK, 2017, I C COMP GRAPH IM VI, P79, DOI 10.1109/CGiV.2017.10
   Alawida M, 2023, J KING SAUD UNIV-COM, V35, DOI 10.1016/j.jksuci.2023.101595
   [Anonymous], 1999, FIPS PUB 46
   [Anonymous], 2012, Special Publication
   Bansal R, 2016, Multimed Tools Appl
   Baptista MS, 1998, PHYS LETT A, V240, P50, DOI 10.1016/S0375-9601(98)00086-3
   Basu Sandipan., 2011, Journal of global research in Computer Science, V2, P116
   Brindha M, 2016, APPL SOFT COMPUT, V40, P379, DOI 10.1016/j.asoc.2015.09.055
   Chen LF, 2013, OPT COMMUN, V291, P98, DOI 10.1016/j.optcom.2012.10.080
   Dang PP, 2000, IEEE T CONSUM ELECTR, V46, P395, DOI 10.1109/30.883383
   Dhall S, 2018, SIGNAL PROCESS, V146, P22, DOI 10.1016/j.sigpro.2017.12.021
   Dong CE, 2014, SIGNAL PROCESS-IMAGE, V29, P628, DOI 10.1016/j.image.2013.09.006
   François M, 2012, SIGNAL PROCESS-IMAGE, V27, P249, DOI 10.1016/j.image.2011.11.003
   Ge X., 2010, 2010 2 IEEE INT C IN
   Ghadirli HM, 2019, SIGNAL PROCESS, V164, P163, DOI 10.1016/j.sigpro.2019.06.010
   Hosny KM, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10091066
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Kaur M, 2022, SOFT COMPUT, V26, P2689, DOI 10.1007/s00500-021-06423-8
   Kaur M, 2020, ARCH COMPUT METHOD E, V27, P15, DOI 10.1007/s11831-018-9298-8
   Kong DZ, 2014, OPT LASER TECHNOL, V57, P343, DOI 10.1016/j.optlastec.2013.08.013
   Kong DZ, 2013, APPL OPTICS, V52, P2619, DOI 10.1364/AO.52.002619
   Lian SG, 2005, CHAOS SOLITON FRACT, V26, P117, DOI 10.1016/j.chaos.2004.11.096
   Lian SG, 2009, CHAOS SOLITON FRACT, V40, P2509, DOI 10.1016/j.chaos.2007.10.054
   Liu ZJ, 2011, OPT COMMUN, V284, P123, DOI 10.1016/j.optcom.2010.09.013
   Lu Q, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13122317
   Lu Q, 2020, IEEE ACCESS, V8, P25664, DOI 10.1109/ACCESS.2020.2970806
   Luo YL, 2018, NONLINEAR DYNAM, V93, P1165, DOI 10.1007/s11071-018-4251-9
   Luo YL, 2015, COMMUN NONLINEAR SCI, V20, P447, DOI 10.1016/j.cnsns.2014.05.022
   Mousa A., 2006, Int. J. Comput. Sci. Appl., V3, P44
   Murillo-Escobar MA, 2015, SIGNAL PROCESS, V109, P119, DOI 10.1016/j.sigpro.2014.10.033
   Nayak DR, 2016, NEUROCOMPUTING, V177, P188, DOI 10.1016/j.neucom.2015.11.034
   Nazari K, 2022, J SCI FOOD AGR, V102, P6907, DOI 10.1002/jsfa.12052
   Norouzi B, 2014, MULTIMEDIA SYST, V20, P45, DOI 10.1007/s00530-013-0314-4
   Pak C, 2019, MULTIMED TOOLS APPL, V78, P12027, DOI 10.1007/s11042-018-6739-1
   Patidar V, 2011, OPT COMMUN, V284, P4331, DOI 10.1016/j.optcom.2011.05.028
   Ramahrishnan S., 2014, Int J Commun Comput Technol, V2, P74
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Taneja N, 2011, AEU-INT J ELECTRON C, V65, P338, DOI 10.1016/j.aeue.2010.04.011
   Wang B, 2014, OPTIK, V125, P6117, DOI 10.1016/j.ijleo.2014.06.107
   Wang W, 2016, J SENSORS, V2016, DOI 10.1155/2016/2646205
   Wong KW, 2008, PHYS LETT A, V372, P2645, DOI 10.1016/j.physleta.2007.12.026
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xiang HY, 2020, MULTIMED TOOLS APPL, V79, P30329, DOI 10.1007/s11042-020-09595-x
   Yu SS, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105816
   Zarebnia M, 2020, OPTIK, V219, DOI 10.1016/j.ijleo.2020.165148
   Zhang YS, 2014, NONLINEAR DYNAM, V76, P1645, DOI 10.1007/s11071-014-1235-2
   Zhou YC, 2013, SIGNAL PROCESS, V93, P3039, DOI 10.1016/j.sigpro.2013.04.021
   Zhu BH, 2000, OPT LETT, V25, P1159, DOI 10.1364/OL.25.001159
   Zhu LY, 2022, SIGNAL PROCESS, V195, DOI 10.1016/j.sigpro.2022.108489
   Zhu SQ, 2019, MULTIMED TOOLS APPL, V78, P20855, DOI 10.1007/s11042-019-7405-y
   Zhu Y, 2010, 2ND IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER CONTROL (ICACC 2010), VOL. 2, P217, DOI 10.1109/ICACC.2010.5486684
NR 51
TC 0
Z9 0
U1 11
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 7
PY 2023
DI 10.1007/s11042-023-16985-4
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2OY9
UT WOS:001096913600018
DA 2024-07-18
ER

PT J
AU Ravi, V
AF Ravi, Vinayakumar
TI Deep learning-based network intrusion detection in smart healthcare
   enterprise systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Healthcare; IoT; Cybersecurity; Cyberattacks; Intrusion detection; Deep
   learning
ID DETECTION FRAMEWORK; ATTACK DETECTION; MODEL; INTERNET
AB Network-based intrusion detection (N-IDS) is an essential system inside an organization in a smart healthcare enterprise system to prevent the system and its networks from network attacks. A survey of the literature shows that in recent days deep learning approaches are employed successfully for N-IDS using network connections. However, finding the right features from a network connection is a daunting task. This work proposes a multidimensional attention-based deep learning approach for N-IDS that extracts the optimal features for intrusion detection using network payload. The proposed approach includes an embedding that transforms every word in the payload into a 100-dimensional feature vector representation and embedding follows deep learning layers such as a convolutional neural network (CNN) and long short-term memory (LSTM) with attention to extracting optimal features for attack classification. Next, the features of CNN and LSTM layers are concatenated and passed into fully connected layers for intrusion detection. The proposed approach showed 99% accuracy on the KISTI enterprise network payload dataset. In addition, the proposed approach showed 98% accuracy and 99% accuracy on network-based datasets such as KDDCup-99, CICIDS-2017, and WSN-DS and UNSW-NB15 respectively. The good experimental results on various network-based datasets suggest that the proposed N-IDS in smart healthcare enterprise systems is robust and generalizable to detect attacks from different network environments. The proposed approach performed better in all the experiments than the other deep learning-based methods. The model showed a 5% accuracy performance improvement compared to the existing study using the KISTI dataset. In addition, the proposed model has shown similar performances on the other intrusion datasets. The proposed approach serves as a network monitoring tool for efficient and accurate detection of attacks inside an organization on a healthcare enterprise network system.
C1 [Ravi, Vinayakumar] Prince Mohammad Bin Fahd Univ, Ctr Artificial Intelligence, Khobar, Saudi Arabia.
C3 Prince Mohammad Bin Fahd University
RP Ravi, V (corresponding author), Prince Mohammad Bin Fahd Univ, Ctr Artificial Intelligence, Khobar, Saudi Arabia.
EM vravi@pmu.edu.sa
RI Ravi, Vinayakumar/L-4202-2018
OI Ravi, Vinayakumar/0000-0001-6873-6469
CR Al S, 2021, COMPUT SECUR, V110, DOI 10.1016/j.cose.2021.102435
   Al-Hawawreh M, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101889
   Binbusayyis A, 2022, J SUPERCOMPUT, V78, P17403, DOI 10.1007/s11227-022-04568-3
   Bohara A, 2016, SYMPOSIUM AND BOOTCAMP ON THE SCIENCE OF SECURITY, P7, DOI 10.1145/2898375.2898400
   Chen JM, 2022, IEEE T DEPEND SECURE, V19, P1810, DOI 10.1109/TDSC.2020.3037500
   Coutinho B, 2023, COMPUT SECUR, V129, DOI 10.1016/j.cose.2023.103189
   Das S, 2021, I C NETWORK PROTOCOL, DOI 10.1109/ICNP52444.2021.9651920
   Di Mauro M, 2020, IEEE T NETW SERV MAN, V17, P2480, DOI 10.1109/TNSM.2020.3024225
   Gao XW, 2019, IEEE ACCESS, V7, P82512, DOI 10.1109/ACCESS.2019.2923640
   Ghourabi A, 2022, IEEE ACCESS, V10, P48890, DOI 10.1109/ACCESS.2022.3172432
   Gu ZY, 2023, ARAB J SCI ENG, V48, P2061, DOI 10.1007/s13369-022-07079-8
   Hassan M, 2022, IEEE ACCESS, V10, P4015, DOI 10.1109/ACCESS.2021.3139835
   Injadat MN, 2021, IEEE T NETW SERV MAN, V18, P1803, DOI 10.1109/TNSM.2020.3014929
   Iwendi C, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10121375
   Khan F, 2023, IEEE Trans Ind Inform
   Khan S, 2021, COMPUT COMMUN, V170, P209, DOI 10.1016/j.comcom.2021.01.013
   Kilincer IF, 2023, BIOCYBERN BIOMED ENG, V43, P30, DOI 10.1016/j.bbe.2022.11.005
   Kumaar M., 2021, Front. Public Health, V9
   Kumar P, 2021, COMPUT COMMUN, V166, P110, DOI 10.1016/j.comcom.2020.12.003
   Latif S, 2022, IEEE T IND INFORM, V18, P6435, DOI 10.1109/TII.2021.3130248
   Lei SW, 2021, IEEE T NETW SCI ENG, V8, P3257, DOI 10.1109/TNSE.2021.3109644
   Liu Y, 2021, IEEE INFOCOM 2021, P1
   Luong MT, 2015, Arxiv, DOI arXiv:1508.04025
   Mishra P, 2019, IEEE COMMUN SURV TUT, V21, P686, DOI 10.1109/COMST.2018.2847722
   Nandy S, 2022, IEEE J BIOMED HEALTH, V26, P1969, DOI 10.1109/JBHI.2021.3101686
   Nayak J, 2022, J SUPERCOMPUT, V78, P14866, DOI 10.1007/s11227-022-04453-z
   Kunang YN, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2021.102804
   Otoum S, 2021, ACM T INTERNET TECHN, V21, DOI 10.1145/3406093
   Priya RMS, 2020, COMPUT COMMUN, V160, P139, DOI 10.1016/j.comcom.2020.05.048
   Rao KN, 2021, COMPUT COMMUN, V180, P77, DOI 10.1016/j.comcom.2021.08.026
   Rasool RU, 2022, J NETW COMPUT APPL, V201, DOI 10.1016/j.jnca.2022.103332
   Ravi Vinayakumar, 2023, IEEE Internet of Things Magazine, P50, DOI 10.1109/IOTM.001.2300021
   Ravi V, 2022, COMPUT COMMUN, V195, P73, DOI 10.1016/j.comcom.2022.08.015
   Ravi V, 2022, COMPUT ELECTR ENG, V102, DOI 10.1016/j.compeleceng.2022.108156
   Saif S, 2023, INT J SYST ASSUR ENG, V14, P512, DOI 10.1007/s13198-023-01883-7
   Saracevic M.H., 2022, Research anthology on securing medical systems and records, P644
   Saracevic M, 2021, J INF SCI ENG, V37, P469, DOI 10.6688/JISE.202103_37(2).0012
   Saracevic M, 2018, COMPUT SCI-AGH, V19, P243, DOI 10.7494/csci.2018.19.3.2749
   Saracevic Muzafer., 2021, Biometric Identification Technologies Based on Modern Data Mining Methods . s.l
   Sharaff Aakanksha, 2022, International Journal of Information Technology, V14, P2057, DOI 10.1007/s41870-021-00853-1
   Sharaff A, 2016, J INF SCI, V42, P200, DOI 10.1177/0165551515587854
   Shone N, 2018, IEEE T EM TOP COMP I, V2, P41, DOI 10.1109/TETCI.2017.2772792
   Si-Ahmed A, 2023, APPL SOFT COMPUT, V140, DOI 10.1016/j.asoc.2023.110227
   Singla Ankush, 2020, ASIA CCS '20: Proceedings of the 15th ACM Asia Conference on Computer and Communications Security, P127, DOI 10.1145/3320269.3384718
   Srinivasarao U, 2022, EXPERT SYST APPL, V193, DOI 10.1016/j.eswa.2021.116475
   Thamilarasu G, 2020, IEEE ACCESS, V8, P181560, DOI 10.1109/ACCESS.2020.3026260
   Thulasi T, 2023, EXPERT SYST APPL, V232, DOI 10.1016/j.eswa.2023.120772
   Viegas E, 2021, IEEE T NETW SCI ENG, V8, P366, DOI 10.1109/TNSE.2020.3038618
   Wu ZJ, 2022, IEEE T NETW SERV MAN, V19, P671, DOI 10.1109/TNSM.2021.3102388
   Xu CY, 2020, IEEE T INF FOREN SEC, V15, P3540, DOI 10.1109/TIFS.2020.2991876
   Yu L, 2021, COMPUT NETW, V194, DOI 10.1016/j.comnet.2021.108117
NR 51
TC 0
Z9 0
U1 6
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 7
PY 2023
DI 10.1007/s11042-023-17300-x
EA OCT 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2OY9
UT WOS:001096913600005
DA 2024-07-18
ER

PT J
AU Laishram, D
   Tuithung, T
AF Laishram, Debina
   Tuithung, Themrichon
TI A secure adaptive Hidden Markov Model-based JPEG steganography method
   (J-HMMSteg)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Adaptive image steganography; Intra-inter block correlations; Hidden
   Markov Model (HMM); Least Significant Bit Matching (LSBM); Maximum
   likelihood; Kullback-Leibler Divergence (KLD)
ID STEGANALYSIS
AB This study introduces J-HMMSteg, an adaptive and secure JPEG image steganography technique designed for data embedding with minimal distortion. J-HMMSteg employed a block-wise analysis approach to detect shifts in image statistics and was performed in three phases. Firstly, it constructed statistical features of the images by analyzing intra-interblock correlations of quantized Discrete Cosine Transform (DCT) coefficients. Secondly, it utilized these features to create the Hidden Markov Model (HMM) of the images to capture complex characteristics such as smoothness, regularity, continuity, consistency, and periodicity. Finally, JHMMSteg utilized a maximum likelihood embedder driven by a threshold using Kullback-Leibler Divergence (KLD). The embedder maintained an optimal correlation by limiting the number of coefficients changed within a block according to its threshold; this ensured that only permissible distortions were introduced. This resulted in a stego image with minimal deviation from the HMM of the cover image's statistical distribution. The experimental analysis of J-HMMSteg was conducted on a database of 85000 JPEG images against four state-of-the-art approaches; the results demonstrated that J-HMMSteg was highly imperceptible, robust against RS steganalysis, and enhanced security against ensemble steganalysis.
C1 [Laishram, Debina] Manipur Tech Univ, Comp Sci & Engn, Imphal 795001, Manipur, India.
   [Tuithung, Themrichon] Natl Inst Technol, Comp Sci & Engn, Dimapur 797103, Nagaland, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Nagaland
RP Laishram, D (corresponding author), Manipur Tech Univ, Comp Sci & Engn, Imphal 795001, Manipur, India.
EM debinalaishram@gmail.com; t_tuithung@yahoo.com
CR Butora Jan, 2020, IH&MMSec '20: Proceedings of the 2020 ACM Workshop on Information Hiding and Multimedia Security, P151, DOI 10.1145/3369412.3395065
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen CH, 2008, IEEE INT SYMP CIRC S, P3029, DOI 10.1109/ISCAS.2008.4542096
   Fawcett T., 2004, MACH LEARN, V31, P1
   Fridrich J, 2002, PROC SPIE, V4675, P1, DOI 10.1117/12.465263
   Fridrich J, 2013, INT CONF ACOUST SPEE, P2949, DOI 10.1109/ICASSP.2013.6638198
   Guo LJ, 2015, IEEE T INF FOREN SEC, V10, P2669, DOI 10.1109/TIFS.2015.2473815
   Guo LJ, 2014, IEEE T INF FOREN SEC, V9, P814, DOI 10.1109/TIFS.2014.2312817
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Holub V, 2015, IEEE T INF FOREN SEC, V10, P219, DOI 10.1109/TIFS.2014.2364918
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Kontorovich A., 2013, INT C MACHINE LEARNI, P702
   Laishram D., 2018, SSRN Electron J, V10, P2139, DOI [10.2139/ssrn.3171494, DOI 10.2139/SSRN.3171494]
   Laishram D., 2021, Springer Adv Intell Sys Comp, V1382, P249, DOI [10.1007/978-3-030-76736-5_23, DOI 10.1007/978-3-030-76736-5_23]
   Laishram D, 2021, MULTIMED TOOLS APPL, V80, P831, DOI 10.1007/s11042-020-09519-9
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Pan YF, 2016, LECT NOTES COMPUT SC, V10039, P125, DOI 10.1007/978-3-319-48671-0_12
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Piyathilaka L, 2013, C IND ELECT APPL, P567
   Rabee AM, 2018, MULTIMED TOOLS APPL, V77, P7763, DOI 10.1007/s11042-017-4676-z
   Sallee P, 2004, LECT NOTES COMPUT SC, V2939, P154
   Sallee P, 2005, INT J IMAGE GRAPH, V5, P167, DOI 10.1142/S0219467805001719
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Sedighi V, 2015, PROC SPIE, V9409, DOI 10.1117/12.2080272
   Setiadi DIM, 2021, MULTIMED TOOLS APPL, V80, P8423, DOI 10.1007/s11042-020-10035-z
   Su AT, 2020, IEEE SIGNAL PROC LET, V27, P221, DOI 10.1109/LSP.2020.2964485
   Tang WX, 2022, IEEE T CIRC SYST VID, V32, P4081, DOI 10.1109/TCSVT.2021.3115600
   Wang YF, 2021, IEEE T INF FOREN SEC, V16, P1117, DOI 10.1109/TIFS.2020.3029908
   Wang ZC, 2018, IETE TECH REV, V35, P351, DOI 10.1080/02564602.2017.1304289
   Wang ZC, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.5.050501
   Wei QD, 2018, MULTIMED TOOLS APPL, V77, P17875, DOI 10.1007/s11042-017-5053-7
NR 33
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 6
PY 2023
DI 10.1007/s11042-023-17152-5
EA OCT 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U0GP6
UT WOS:001081680200005
DA 2024-07-18
ER

PT J
AU Sriwastawa, A
   Jothi, JAA
AF Sriwastawa, Asmi
   Jothi, J. Angel Arul
TI Vision transformer and its variants for image classification in digital
   breast cancer histopathology: a comparative study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Vision transformer; Attention mechanism; Image classification; Digital
   histopathology; Breast cancer detection
AB Convolutional Neural Networks (CNNs) have been the most popular image classification tool for a long time. Inspired by the greater success of the transformer structure in natural language processing, the Vision Transformer (ViT) was recently proposed as a more efficient image classification tool based on the attention mechanism. Several newer models, such as Pooling-based Vision Transformer (PiT), Convolutional Vision Transformer (CvT), CrossFormer, CrossViT, NesT, MaxViT and Separable Vision Transformer (SepViT), have since been developed to improve upon the accuracy and generalization ability of ViT. This study aims to perform a comprehensive comparison between the performances of these eight models. They are employed for image classification on the BreakHis and IDC datasets for the purpose of digital breast cancer histopathology. After training on BreakHis they are fine tuned on IDC in order to test their generalization ability. Their performance is also compared to the existing state-of-the-art. MaxViT is found to be the best transformer based classifier, achieving a test accuracy of 91.57% on BreakHis, 91.8% on IDC, and 92.12% when pre-trained on BreakHis and then fine tuned on IDC. However, none of the chosen models exhibit a significantly improved performance in comparison to existing works. Thus, the common characteristics of the best performing models are highlighted, and structural suggestions for further improvement in their accuracy and generalization ability are made. Finally, our findings are summarized, and the future scope is laid out. Source codes are available at https://github.com/itsParmesan/vit-comparative-study.
C1 [Sriwastawa, Asmi; Jothi, J. Angel Arul] Birla Inst Technol & Sci Pilani, Dept Comp Sci, Dubai Int Acad City, Dubai Campus, Dubai, U Arab Emirates.
RP Jothi, JAA (corresponding author), Birla Inst Technol & Sci Pilani, Dept Comp Sci, Dubai Int Acad City, Dubai Campus, Dubai, U Arab Emirates.
EM asmisriwastwa@gmail.com; angeljothi@dubai.bits-pilani.ac.in
CR Abbood A.A., 2021, Indones. J. Electr. Eng. Comput. Sci, V22, P252, DOI [10.11591/ijeecs.v22.i1.pp252-259, DOI 10.11591/IJEECS.V22.I1.PP252-259]
   Alkhaldi E, 2022, IEEE ACCESS, V10, P128790, DOI 10.1109/ACCESS.2022.3228176
   Arnold M, 2022, BREAST, V66, P15, DOI 10.1016/j.breast.2022.08.010
   Basyal GP, 2021, AMCIS 2021 P
   Bose S, 2022, IEEE Xplore
   Chattopadhyay S, 2022, COMPUT BIOL MED, V145, DOI 10.1016/j.compbiomed.2022.105437
   Chen C.-F., 2021, arXiv
   Cruz-Roa A, 2014, PROC SPIE, V9041, DOI 10.1117/12.2043872
   Dika E, 2022, PATHOL RES PRACT, V237, DOI 10.1016/j.prp.2022.154014
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   El Shawi R, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-20268-7
   Esi Nyarko BN, 2022, IEEE Xplore
   Fu Q, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/8369368
   Gamare Vrushabh, 2022, ITM Web of Conferences, V44, DOI 10.1051/itmconf/20224403041
   Gupta I, 2022, MULTIMED TOOLS APPL, V81, P36309, DOI 10.1007/s11042-021-11853-5
   Haris M, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10161932
   Heo B., 2021, arXiv
   Ikechukwu Victor, 2021, Global Transitions Proceedings, V2, P375
   Janowczyk Andrew, 2016, J Pathol Inform, V7, P29, DOI 10.4103/2153-3539.186902
   Joseph A.A., 2022, Intelligent Syst Appl, V14, P200066, DOI [10.1016/j.iswa.2022.200066, DOI 10.1016/J.ISWA.2022.200066]
   Kulkarni S, 2021, IEEE Xplore
   Li W, 2022, Arxiv, DOI arXiv:2203.15380
   Liu M, 2022, IEEE J BIOMED HEALTH, V26, P5025, DOI 10.1109/JBHI.2022.3187765
   Liu M, 2022, INFORMATION, V13, DOI 10.3390/info13030107
   Loddo A, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105032
   Naseer I, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22124426
   Praveen SP, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-25089-2
   Roy SD, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113628
   Sepahvand M, 2022, COMPUT BIOL MED, V145, DOI 10.1016/j.compbiomed.2022.105413
   Sha MZ, 2022, AD HOC NETW, V128, DOI 10.1016/j.adhoc.2022.102784
   Singh A, 2021, Advances in intelligent systems and computing, P375, DOI [10.1007/978-981-16-2594-7_31, DOI 10.1007/978-981-16-2594-7_31]
   Spanhol FA, 2016, IEEE T BIO-MED ENG, V63, P1455, DOI 10.1109/TBME.2015.2496264
   Springenberg M, 2023, Arxiv, DOI arXiv:2204.05044
   Tu Z., 2022, arXiv, DOI DOI 10.48550/ARXIV.2204.01697
   Wang P, 2022, GitHub
   Wang P, 2022, DIGIT SIGNAL PROCESS, V123, DOI 10.1016/j.dsp.2022.103400
   Wang WX, 2021, Arxiv, DOI [arXiv:2108.00154, DOI 10.48550/ARXIV.2108.00154]
   Wu HP, 2021, Arxiv, DOI [arXiv:2103.15808, DOI 10.48550/ARXIV.2103.15808]
   Xu YZ, 2022, IET IMAGE PROCESS, V16, P2875, DOI 10.1049/ipr2.12449
   Zeid MA-E, 2021, IEEE Xplore
   Zerouaoui H, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103226
   Zhang ZZ, 2022, AAAI CONF ARTIF INTE, P3417
   Zhou YP, 2022, IEEE ACCESS, V10, P35977, DOI 10.1109/ACCESS.2022.3163822
   Zou Y, 2022, INT J IMAG SYST TECH, V32, P266, DOI 10.1002/ima.22628
NR 44
TC 2
Z9 2
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 5
PY 2023
DI 10.1007/s11042-023-16954-x
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ4I6
UT WOS:001156484900017
DA 2024-07-18
ER

PT J
AU Shi, WM
   Zhuang, QT
   Zhou, YH
   Yang, YG
AF Shi, Wei-Min
   Zhuang, Qing-Tian
   Zhou, Yi-Hua
   Yang, Yu-Guang
TI An image reranking algorithm based on discrete-time quantum walk
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Discrete-time quantum walk; Image retrieval; Image reranking algorithm;
   Weighted complete graph
AB In order to further improve the performance of image retrieval, a novel image reranking algorithm based on discrete-time quantum walk is proposed. In this algorithm, a discrete-time quantum walk model based on a weighted undirected complete graph is first constructed, in which the nodes of the graph represent the images and the weighted values of these edges are the similarity value between the images. Then the average probability values of the walker reaching the node of the graph is used as the relevance scores of the image and the images are reranked according to the relevance scores. Finally, our experimental results show that our proposed reranking algorithm has a significant improvement compared with the initial ranking algorithm from the comparison of visual and relevance scores. Furthermore, the effectiveness of our algorithm is evaluated by the average precision (AP) and the mean average precision (MAP), where the AP of our algorithm is increased by 18.23% and 37.61% for two types of the query image in randomly selected image group respectively, and the MAP of our algorithm is increased by 22.24% for all image groups compared with the initial ranking algorithm.
C1 [Shi, Wei-Min; Zhuang, Qing-Tian; Zhou, Yi-Hua; Yang, Yu-Guang] Beijing Univ Technol, Coll Comp Sci & Technol, Beijing 100124, Peoples R China.
   [Shi, Wei-Min; Zhuang, Qing-Tian; Zhou, Yi-Hua; Yang, Yu-Guang] Beijing Key Lab Trusted Comp, Beijing 100124, Peoples R China.
C3 Beijing University of Technology
RP Shi, WM (corresponding author), Beijing Univ Technol, Coll Comp Sci & Technol, Beijing 100124, Peoples R China.; Shi, WM (corresponding author), Beijing Key Lab Trusted Comp, Beijing 100124, Peoples R China.
EM shiweimin@bjut.edu.cn; qtzhuang@163.com; S201961161@emails.bjut.edu.cn;
   yangyang7357@bjut.edu.cn
FU This work is supported by The National Natural Science Foundation of
   China (No. 61602019); Beijing Natural Science Foundation (Grant
   No.4182006). [61602019]; National Natural Science Foundation of China
   [4182006]; Beijing Natural Science Foundation
FX This work is supported by The National Natural Science Foundation of
   China (No. 61602019); Beijing Natural Science Foundation (Grant
   No.4182006).
CR Bai X, 2010, IEEE T PATTERN ANAL, V32, P861, DOI 10.1109/TPAMI.2009.85
   Baluja Shumeet, 2008, P 17 INT C WORLD WID, P895, DOI DOI 10.1145/1367497.1367618
   Berg TamaraL., 2006, CVPR, DOI DOI 10.1109/CVPR.2006.57
   Deng C, 2014, IEEE T MULTIMEDIA, V16, P785, DOI 10.1109/TMM.2014.2298841
   Di Molfetta G, 2020, QUANTUM INF PROCESS, V19, DOI 10.1007/s11128-019-2549-2
   Gao SH, 2009, IEEE IMAGE PROC, P793, DOI 10.1109/ICIP.2009.5414251
   He X, 2003, INT C MULT EXP ICME, V1, pI
   Hou HM, 2015, MULTIMED TOOLS APPL, V74, P1423, DOI 10.1007/s11042-014-1962-x
   Hsu WinstonH., 2007, ACM MM
   Jing Y, 2008, IEEE T PATTERN ANAL, V30, P1877, DOI 10.1109/TPAMI.2008.121
   Kamvar Sepandar D., 2003, P 12 INT C WORLD WID, P261, DOI DOI 10.1145/775152.775190
   Li Xirong., 2007, P 6 ACM INT C IMAGE, P603
   Li ZC, 2020, INT J COMPUT VISION, V128, P2265, DOI 10.1007/s11263-020-01331-0
   Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750
   Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035
   Lu JY, 2012, PROC CVPR IEEE, P3029, DOI 10.1109/CVPR.2012.6248033
   Montanaro A, 2016, NPJ QUANTUM INFORM, V2, DOI 10.1038/npjqi.2015.23
   Moore C., 2002, Randomization and Approximation Techniques in Computer Science. 6th International Workshop, RANDOM 2002. Proceedings (Lecture Notes in Computer Science Vol.2483), P164
   Ng AY, 2002, ADV NEUR IN, V14, P849
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Page L., 1999, PAGERANK CITATION RA, DOI DOI 10.1109/IISWC.2012.6402911
   Pan JY, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1987, DOI 10.1109/ICME.2004.1394652
   Paparo GD, 2012, SCI REP-UK, V2, DOI 10.1038/srep00444
   Portugal R., 2013, Quantum Walks and Search Algorithms, DOI 10.1007/978-1-4614-6336-8
   Sansoni L, 2010, PHYS REV LETT, V105, DOI 10.1103/PhysRevLett.105.200503
   Santos RAM, 2016, QUANTUM INF PROCESS, V15, P4461, DOI 10.1007/s11128-016-1427-4
   STRICKER M, 1995, P SOC PHOTO-OPT INS, V2410, P381, DOI 10.1117/12.205308
   Szegedy M, 2004, ANN IEEE SYMP FOUND, P32, DOI 10.1109/FOCS.2004.53
   Tian X., 2008, ACM INT C MULTIMEDIA, P131, DOI DOI 10.1145/1459359.1459378.ISBN
   Travaglione BC, 2002, PHYS REV A, V65, DOI 10.1103/PhysRevA.65.032310
   Wang M, 2012, IEEE T IMAGE PROCESS, V21, P4649, DOI 10.1109/TIP.2012.2207397
   Wong TG, 2017, J PHYS A-MATH THEOR, V50, DOI 10.1088/1751-8121/aa8c17
   www.wang.ist.psu.edu, Wang database
   Yan R, 2004, LECT NOTES COMPUT SC, V3115, P60
NR 34
TC 1
Z9 1
U1 4
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 28
PY 2023
DI 10.1007/s11042-023-16916-3
EA SEP 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM7
UT WOS:001076639200007
DA 2024-07-18
ER

PT J
AU Chugh, G
   Kumar, S
   Singh, N
AF Chugh, Gunjan
   Kumar, Shailender
   Singh, Nanhay
TI TransNet: a comparative study on breast carcinoma diagnosis with
   classical machine learning and transfer learning paradigm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast Carcinoma; Computer-Aided diagnosis; Deep Convolutional Neural
   Network; Deep-learning
ID CLASSIFICATION; IMAGES; SEGMENTATION; MAMMOGRAMS
AB Breast Carcinoma is a deadly disease; therefore, timely diagnosis is one of the most critical concerns that must be addressed globally since it can significantly enhance overall survival rates. Currently, Medical Imaging relies on Machine Learning(ML) and Deep Learning(DL) for accurate and early identification of diseases. In this article, a framework is proposed for diagnosing & classifying breast tumors using deep learning approaches. We have performed two experiments on the CBIS-DDSM (Curated Breast Imaging Subset of Digital Database for Screening Mammography) dataset. In the first approach, i.e., Deep feature extraction with ML classifier head, Deep Convolutional Neural Network(DCNN) models such as VGG16, VGG19, Res Net 50, and Res Net 152 are deployed as feature extractors, and the obtained features are utilized for training conventional machine learning classifiers. The second approach, called Deep Learning feature extraction with a neural network classifier, exploits Mobile Net, VGG16, VGG19, ResNet50, Res Net 152, and, Dense Net 169 for feature extraction and categorization. The results show that in the first case, Random Forest (RF) and XG Boost (XGB) Classifier perform best with 100% accuracy on the training set, whereas Support Vector Machine (SVM) and XGB exhibit 95%(+-5%) on the Test dataset for all the models. In the second approach, Mobile Net, ResNet50, and Dense Net 169 outperform the other models with an accuracy of 97%(+-2%) for both the Training and Test sets. The evaluated results have shown that the second approach depicts an increase in accuracy by 4%.
C1 [Chugh, Gunjan; Kumar, Shailender] Delhi Technol Univ, Dept Comp Sci & Engn, Delhi, India.
   [Singh, Nanhay] Netaji Subhas Univ Technol, Dept Comp Sci & Engn, East Campus, Delhi, India.
C3 Delhi Technological University; Netaji Subhas University of Technology
RP Chugh, G (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, Delhi, India.
EM chugh.gunjan8917@gmail.com
CR Abdullah-Al Nahid, 2018, BIOMED RES INT, V2018, DOI 10.1155/2018/2362108
   Agarwal Pinky, 2022, Data Engineering for Smart Systems: Proceedings of SSIC 2021. Lecture Notes in Networks and Systems (238), P77, DOI 10.1007/978-981-16-2641-8_8
   Al-antari MA, 2018, INT J MED INFORM, V117, P44, DOI 10.1016/j.ijmedinf.2018.06.003
   Al-masni MA, 2018, COMPUT METH PROG BIO, V157, P85, DOI 10.1016/j.cmpb.2018.01.017
   Alruwaili M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22030876
   [Anonymous], DEEP VIEW TRANSFER L
   [Anonymous], 2015, Breast Cancer
   [Anonymous], BREAST CANC FACTS ST
   [Anonymous], CONVOLUTIONAL NEURAL
   [Anonymous], MOBILENET CONVOLUTIO
   Antropova N, 2017, MED PHYS, V44, P5162, DOI 10.1002/mp.12453
   Bai YJ, 2023, MULTIMED TOOLS APPL, V82, P27989, DOI 10.1007/s11042-023-14708-3
   Bevilacqua V, 2019, COGN SYST RES, V53, P3, DOI 10.1016/j.cogsys.2018.04.011
   Choudhary T, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104432
   Chugh G, 2021, COGN COMPUT, V13, P1451, DOI 10.1007/s12559-020-09813-6
   GLOBOCAN, 2020, New Global Cancer Data
   Gu SH, 2019, MACH VISION APPL, V30, P1111, DOI 10.1007/s00138-019-01020-0
   Hassan NM, 2022, MULTIMED TOOLS APPL, V81, P20043, DOI 10.1007/s11042-022-12332-1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Khalil S, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13074255
   Khan HN., 2019, IEEE Access, VPP, P1
   Krithiga R, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01122-0
   Lai XB, 2020, COMPUT MATH METHOD M, V2020, DOI 10.1155/2020/7156165
   Lee RS, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.177
   Li H, 2019, BIOMED SIGNAL PROCES, V51, P347, DOI 10.1016/j.bspc.2019.02.017
   Mobark N, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12147080
   Pang T, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113501
   Ragab DA, 2021, COMPUT BIOL MED, V131, DOI 10.1016/j.compbiomed.2021.104245
   Ragab DA, 2019, PEERJ, V7, DOI 10.7717/peerj.6201
   Rahimeto S, 2021, EVOL SYST-GER, V12, P519, DOI 10.1007/s12530-019-09310-8
   Rana M, 2023, MULTIMED TOOLS APPL, V82, P26731, DOI 10.1007/s11042-022-14305-w
   Sahiner B, 2019, MED PHYS, V46, pe1, DOI 10.1002/mp.13264
   Sahu Y, 2023, MULTIMED TOOLS APPL, V82, P14055, DOI 10.1007/s11042-022-13807-x
   Samala RK, 2016, MED PHYS, V43, P6654, DOI 10.1118/1.4967345
   Senan EM, 2021, J APPL SCI ENG, V24, P323, DOI 10.6180/jase.202106_24(3).0007
   Shaikh TA, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01058-5
   Sharma S, 2020, J DIGIT IMAGING, V33, P632, DOI 10.1007/s10278-019-00307-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song RY, 2020, IEEE ACCESS, V8, P75011, DOI 10.1109/ACCESS.2020.2986546
   Steen M, 2018, ARXIV
   Sujatha R, 2023, IET IMAGE PROCESS, V17, P1979, DOI 10.1049/ipr2.12660
   Tan Y.J., 2018, P 2017 INT C ROB AUT, P1, DOI [10.1109/ICORAS.2017.8308076, DOI 10.1109/ICORAS.2017.8308076]
   Vijayakumar K, 2021, CONCURRENT ENG-RES A, V29, P275, DOI 10.1177/1063293X211025105
   Yadavendra, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01094-1
   Zhang H, 2020, DE ADA NOVEL MODEL B
NR 45
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33855
EP 33877
DI 10.1007/s11042-023-16938-x
EA SEP 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001075272400016
DA 2024-07-18
ER

PT J
AU Mohiddin, SK
   Midhunchakkaravarthy, D
   Hussain, MA
AF Mohiddin, Shaik Khaja
   Midhunchakkaravarthy, Divya
   Hussain, Mohammed Ali
TI TSWA: a unique approach to overcome interest flooding attacks in the
   cloud using a combination of TSW and attack detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anomaly-based Real-Time Prevention (ARTP); Collusive Interest Flooding
   Attacks (CIFA); Continuous Wavelet Transforms (CWT); Discrete Wavelet
   Transforms (DWT); Interest Flooding Attack (IFA); Pending Interest Table
   (PIT); Named Data Network Simulator (ndnSIM); Time Skimming Window (TSW)
ID DETECTION SYSTEM; DDOS ATTACKS; NETWORK
AB The prevalence of distributed denial of service (DDoS) attacks poses a significant challenge to the Internet and cloud environments, including emerging architectures like Named Data Networking (NDN). Among the threats faced by NDN, interest flooding attacks (IFAs) have emerged as a prominent issue. This study presents a novel method for detecting IFAs in NDN by analyzing data name prefix distribution in network traffic to determine the appropriate detection window size. IFAs involve adding a random suffix to a prefix in network traffic, leading to a barrage of interest packets that overwhelm the target without receiving responses. Building upon this observation, a new type of DoS attack called Collaborative Interest Flooding Attack (CIFA) has been identified, which evades existing detection and protection systems using a low-rate attack mode facilitated by collusive manufacturers. To address these challenges, a detection approach combining a rolling time window algorithm and attack detection methodology is proposed. This method evaluates the impact of CIFA attacks on network traffic and examines relevant properties of Pending Interest Table (PIT) entries. Furthermore, the analysis extends to the examination of prefixes in interest packets, providing comprehensive detection of interest flooding attacks. Additionally, the proposed approach effectively restricts the attacker's port by leveraging the PIT routing character entry to discourage IFA attacks. Experimental results obtained from real-world and simulated scenarios demonstrate the efficacy of the proposed algorithms in detecting DoS attacks. Comparative analysis with existing state-of-the-art methodologies reveals that the proposed approach outperforms them in terms of accuracy, precision, F-Score, GMean, specificity, and sensitivity. By enhancing the detection and mitigation capabilities against interest flooding attacks, this research contributes to the ongoing efforts in securing NDN and future Internet architectures, enabling a more robust and resilient network infrastructure.
C1 [Mohiddin, Shaik Khaja] Lincoln Univ Coll, Kota Baharu, Malaysia.
   [Midhunchakkaravarthy, Divya] Lincoln Univ Coll, Comp Sci & Multimedia, Kota Baharu, Selangor, Malaysia.
   [Hussain, Mohammed Ali] Deemed Univ, R&D Koneru Lakshmaiah Educ Fdn, Vaddeswaram 522302, Andhra Pradesh, India.
C3 Lincoln University College; Lincoln University College
RP Mohiddin, SK (corresponding author), Lincoln Univ Coll, Kota Baharu, Malaysia.
EM pdf.kmshaik@lincoln.edu.my
CR Aborujilah A, 2017, J COMPUT NETW COMMUN, V2017, DOI 10.1155/2017/7674594
   Afanasyev Alexander, 2013, IFIP NETWORKING C, P1
   Alsowail S, 2016, ARAB J SCI ENG, V41, P5037, DOI 10.1007/s13369-016-2210-7
   Barki L, 2016, ADV COMPUTING COMMUN
   Benmoussa A, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3539730
   Chen Z., 2022, J NETW SYST MANAG, V30, P729
   Compagno A, 2013, C LOCAL COMPUT NETW, P630, DOI 10.1109/LCN.2013.6761300
   Dong JQ, 2020, COMPUT SECUR, V88, DOI 10.1016/j.cose.2019.101628
   Gong M., 2022, IEEE ACCESS, V10, P15298
   Guptha NS, 2022, PATTERN RECOGN LETT, V159, P16, DOI 10.1016/j.patrec.2022.04.038
   Guptha NS, 2017, INT J SIGNAL IMAGING, V10, P39, DOI 10.1504/IJSISE.2017.084568
   Hameed S, 2015, NETWORK OPERATIONS M
   Javanmardi S, 2014, J SUPERCOMPUT, V69, P955, DOI 10.1007/s11227-014-1221-y
   Kumar M. N., 2012, 2012 4th International Conference on Computational Intelligence and Communication Networks (CICN 2012), P535, DOI 10.1109/CICN.2012.149
   Li WS, 2016, COMPLEX INTELL SYST, V2, P293, DOI 10.1007/s40747-016-0028-2
   Liu L, 2020, IEEE ACCESS, V8, P128005, DOI 10.1109/ACCESS.2020.3008723
   Liu Y., 2022, COMPUT COMMUN, V186, P72
   Mary IM, 2014, INT J COMPUT SCI INF, V5, P1803
   Meti N, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1366, DOI 10.1109/ICACCI.2017.8126031
   Modi CN, 2013, IEEE SYM COMPUT INTE, P23, DOI 10.1109/CICYBS.2013.6597201
   Praveena HD, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/3297316
   Pu C, 2019, 2019 INTERNATIONAL CONFERENCE ON INTERNET OF THINGS (ITHINGS) AND IEEE GREEN COMPUTING AND COMMUNICATIONS (GREENCOM) AND IEEE CYBER, PHYSICAL AND SOCIAL COMPUTING (CPSCOM) AND IEEE SMART DATA (SMARTDATA), P142, DOI 10.1109/iThings/GreenCom/CPSCom/SmartData.2019.00045
   Qi LT, 2019, CHINA COMMUN, V16, P112, DOI 10.23919/JCC.2019.10.008
   Sreeram Indraneel., 2019, Applied computing and informatics, V15, P59, DOI DOI 10.1016/J.ACI.2017.10.003
   Virupakshar KB, 2020, PROCEDIA COMPUT SCI, V167, P2297, DOI 10.1016/j.procs.2020.03.282
   Wang H., 2022, IEEE T DEPEND SECURE, V19, P199
   Wu ZJ, 2020, COMPUT SECUR, V97, DOI 10.1016/j.cose.2020.101971
   Xin YH, 2017, IEEE MILIT COMMUN C, P557, DOI 10.1109/MILCOM.2017.8170763
   Yan Q, 2016, IEEE COMMUN SURV TUT, V18, P602, DOI 10.1109/COMST.2015.2487361
NR 29
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32673
EP 32713
DI 10.1007/s11042-023-16660-8
EA SEP 2023
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069966300004
DA 2024-07-18
ER

PT J
AU Liu, J
   Lu, SP
   Yang, YL
AF Liu, Jiao
   Lu, Shao-Ping
   Yang, Yulu
TI A transferability-aware covariance alignment network for image
   steganalysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganalysis; Domain adaptation; Transferability; Covariance
   alignment; Texture complexity
AB Image steganalysis seeks to detect whether the secret information is hidden in images. Recently, to alleviate the distribution discrepancy between the training and test data, domain adaptation-based image steganalysis approaches have attracted much attention. However, existing methods ignore the evaluation of the transferability between datasets and inevitably lead to negative transfer. In this paper, we propose a Transferability-Aware Covariance Alignment Network (TA-CAN) for image steganalysis. This new solution consists of two key strategies: the transferable-aware module (TAM) and the covariance alignment loss (CAL). In TAM, we introduce a texture estimator and design a match query strategy based on texture pools, determining whether data sets can be transferred from one to another. Furthermore, to reduce the discrepancies between datasets with transferability, we leverage CAL to align second-order statistics in different domains. Extensive experiments demonstrate that our proposed algorithm can effectively handle distributional differences between training and test sets.
C1 [Liu, Jiao; Lu, Shao-Ping; Yang, Yulu] Nankai Univ, TKLNDST, CS, Tianjin 300071, Peoples R China.
C3 Nankai University
RP Liu, J (corresponding author), Nankai Univ, TKLNDST, CS, Tianjin 300071, Peoples R China.
EM jiaoliu@mail.nankai.edu.cn
RI Liu, Jiao/JOK-4441-2023
OI Liu, Jiao/0000-0001-9931-6918
CR Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Chen H, 2023, MULTIMED TOOLS APPL, V82, P22009, DOI 10.1007/s11042-021-11611-7
   Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461
   Denemark T, 2014, IEEE INT WORKS INFOR, P48, DOI 10.1109/WIFS.2014.7084302
   Deng XQ, 2019, IH&MMSEC '19: PROCEEDINGS OF THE ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P230, DOI 10.1145/3335203.3335739
   Feng CY, 2017, IEEE IMAGE PROC, P500, DOI 10.1109/ICIP.2017.8296331
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Fridrich J, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P3
   Fu T, 2022, J VIS COMMUN IMAGE R, V88, DOI 10.1016/j.jvcir.2022.103633
   Guo LJ, 2015, IEEE T INF FOREN SEC, V10, P2669, DOI 10.1109/TIFS.2015.2473815
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Holub V, 2013, IEEE T INF FOREN SEC, V8, P1996, DOI 10.1109/TIFS.2013.2286682
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Jia J, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107105
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Li QJ, 2021, IEEE SIGNAL PROC LET, V28, P1095, DOI 10.1109/LSP.2021.3083546
   Lu SP, 2021, PROC CVPR IEEE, P10811, DOI 10.1109/CVPR46437.2021.01067
   Luo G, 2022, INT CONF ACOUST SPEE, P3089, DOI 10.1109/ICASSP43922.2022.9747091
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Tsang CF., 2018, ELECT IMAG, V2018, p121, DOI [DOI 10.2352/ISSN.2470-1173.2018.07.MWSF-121, 10.2352/ISSN.2470-1173.2018.07.MWSF-121]
   Weng SW, 2022, IEEE SIGNAL PROC LET, V29, P1888, DOI 10.1109/LSP.2022.3201727
   Wu ST, 2018, MULTIMED TOOLS APPL, V77, P10437, DOI 10.1007/s11042-017-4440-4
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Xu YM, 2022, PROC CVPR IEEE, P7865, DOI 10.1109/CVPR52688.2022.00772
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Yedroudj M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2092, DOI 10.1109/ICASSP.2018.8461438
   You WK, 2021, IEEE T INF FOREN SEC, V16, P291, DOI 10.1109/TIFS.2020.3013204
   You WK, 2019, MULTIMED TOOLS APPL, V78, P22711, DOI 10.1007/s11042-019-7601-9
   Zhang L, 2022, TELECOMMUN SYST, V80, P263, DOI 10.1007/s11235-022-00901-6
   Zhang R, 2020, IEEE T INF FOREN SEC, V15, P1138, DOI 10.1109/TIFS.2019.2936913
   Zhang X, 2019, P INT WORKSH DIG WAT, P71, DOI 10.1007/978-3-030-43575-2_6
NR 35
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33999
EP 34013
DI 10.1007/s11042-023-16901-w
EA SEP 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069968300007
DA 2024-07-18
ER

PT J
AU Liang, MQ
   Wu, XD
   Tang, SM
   Zhu, ZY
   Wang, YA
   Zhang, Q
   Cao, BH
AF Liang, Mengquan
   Wu, Xuedong
   Tang, Siming
   Zhu, Zhiyu
   Wang, Yaonan
   Zhang, Qiang
   Cao, Baiheng
TI Visual tracking via confidence template updating spatial-temporal
   regularized correlation filters
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Discriminative correlation filter; Boundary effect; Spatial-temporal
   regularizer; Response aberrance; Model templates
ID OBJECT TRACKING
AB As an accurate and robust method for visual object tracking task, discriminative correlation filter (DCF) framework has received significant popularity from various researchers. For a given tracking sequence, the DCF formulates the target appearance model and tracking model according to the target information of the first frame, and then predicts the location and the scale of tracking target via specific tracking strategy while the tracking model and appearance model are updated via model learning strategy. However, the tracking performance of DCF tracker is limited by the undesirable impact of boundary effect caused by algorithm deficiency and response aberrance arisen from complex tracking environment. Aiming at tackling the above difficulties, a visual tracking method based on spatial-temporal regularized correlation filter with confidence template updating is developed, in which spatial-temporal regulariziers are formulated for tracking model learning process to tackle the spawning noises in the model learning process and an adaptive model template updating strategy for tracking strategy process is adopted to repress the response aberrance effect. The main findings and scientific contributions of our method (Ours) includes: 1) a novel spatial regularization method is introduced to restrain the boundary effect and to improve the overall tracking performance by penalizing the edge coefficient of correlation filter; 2) aiming at addressing the appearance variation of tracking target, a novel temporal regularizer is suggested to formulate a more stable learning process for the tracking model and further surmount the model noise caused by deficient model learning; 3) a novel adaptive updating strategy of model template is provided to alleviate the aberrances of response representations and obtain more accurate target prediction results. Extensive experimental results with 351 challenging videos on various datasets OTB2013, OTB2015, Temple-Color and UAV123 have proven that Ours can achieve favorable performances against other state-of-the-art trackers and efficiently adapt to a variety of complex scenarios in the tracking task.
C1 [Liang, Mengquan; Wu, Xuedong; Tang, Siming; Zhu, Zhiyu; Zhang, Qiang; Cao, Baiheng] Jiangsu Univ Sci & Technol, Sch Elect & Informat, Zhenjiang 212100, Peoples R China.
   [Wang, Yaonan] Hunan Univ, Coll Elect & Informat Engn, Changsha 410082, Peoples R China.
C3 Jiangsu University of Science & Technology; Hunan University
RP Wu, XD (corresponding author), Jiangsu Univ Sci & Technol, Sch Elect & Informat, Zhenjiang 212100, Peoples R China.
EM woolcn@163.com
RI chen, zhuo/JXX-1337-2024; yan, xu/KCY-8174-2024; Liu, Zhe/KEJ-5299-2024;
   Liu, Donghua/KEJ-1974-2024; wei, wang/KHY-7669-2024; Liu,
   min/JXW-8493-2024; Wang, Bo/KEH-0105-2024; zhong, jing/KBP-7800-2024
OI Liu, Donghua/0000-0002-5830-9540; Wu, Xuedong/0000-0001-6852-2276
FU This work is supported by the National Natural Science Foundation of
   China (No. 61671222, No. 61903162), the Postgraduate Research amp;amp;
   Practice Innovation Program of Jiangsu Province (KYCX22_3822) and the
   Postgraduate Research amp;amp; Practice Inno [61671222, 61903162];
   National Natural Science Foundation of China [KYCX21_3484]; Postgraduate
   Research amp;amp; Practice Innovation Program of Jiangsu Province
FX This work is supported by the National Natural Science Foundation of
   China (No. 61671222, No. 61903162), the Postgraduate Research & Practice
   Innovation Program of Jiangsu Province (KYCX22_3822) and the
   Postgraduate Research & Practice Innovation Program of Jiangsu Province
   (KYCX21_3484).
CR An ZY, 2023, APPL INTELL, V53, P3836, DOI 10.1007/s10489-022-03719-6
   Aslam N, 2022, P 2022 2 INT C EM FR
   Aslam N, 2024, VISUAL COMPUT, V40, P1729, DOI 10.1007/s00371-023-02882-2
   Aslam N, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P1071, DOI 10.1109/ICCSP.2017.8286540
   Bao H, 2023, IEEE T CIRC SYST VID, V33, P847, DOI 10.1109/TCSVT.2022.3207202
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chen L, 2023, APPL INTELL, V53, P4415, DOI 10.1007/s10489-022-03727-6
   Choi J, 2017, IEEE Conf Comput Vis Patt Recog, P6931
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan Martin, 2014, BRIT MACH VIS C
   Elayaperumal D, 2023, INFORM SCIENCES, V629, P502, DOI 10.1016/j.ins.2023.02.009
   Fan NN, 2023, INFORM SCIENCES, V624, P606, DOI 10.1016/j.ins.2022.12.082
   Feng ZG, 2023, ENG APPL ARTIF INTEL, V123, DOI 10.1016/j.engappai.2023.106250
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Huang Z., 2017, P IEEE C COMP VIS PA, P4021, DOI DOI 10.1109/CVPR.2017.510
   Huang ZY, 2019, IEEE I CONF COMP VIS, P2891, DOI 10.1109/ICCV.2019.00298
   Javed S, 2023, IEEE T PATTERN ANAL, V45, P6552, DOI [10.1109/IECON49645.2022.9969084, 10.1109/TPAMI.2022.3212594]
   Kristan M, 2018, P EUR C COMP VIS WOR, V3, P8
   Li BW, 2021, IEEE INT CONF ROBOT, P496, DOI 10.1109/ICRA48506.2021.9561564
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Lin FL, 2022, IEEE T INTELL TRANSP, V23, P10469, DOI 10.1109/TITS.2021.3094654
   Marvasti-Zadeh SM, 2022, IEEE T INTELL TRANSP, V23, P3943, DOI 10.1109/TITS.2020.3046478
   Meng FY, 2023, PATTERN RECOGN, V141, DOI 10.1016/j.patcog.2023.109630
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Nai K, 2023, IEEE T NEUR NET LEAR, V34, P502, DOI 10.1109/TNNLS.2021.3097498
   Saeedi-Hosseiny MS, 2023, IEEE ROBOT AUTOM LET, V8, P2438, DOI 10.1109/LRA.2023.3251198
   Wei BB, 2023, NEUROCOMPUTING, V527, P13, DOI 10.1016/j.neucom.2023.01.041
   Wei BB, 2023, KNOWL-BASED SYST, V263, DOI 10.1016/j.knosys.2023.110286
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xu TY, 2023, IEEE T IMAGE PROCESS, V32, P1541, DOI 10.1109/TIP.2023.3246800
   Xu TY, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2919201
   Yang YJ, 2023, IEEE T IMAGE PROCESS, V32, P1705, DOI 10.1109/TIP.2023.3251027
   Yiming Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11920, DOI 10.1109/CVPR42600.2020.01194
   Yuan XR, 2023, IEEE GEOSCI REMOTE S, V20, DOI 10.1109/LGRS.2023.3276790
   Zhang JM, 2023, IEEE SIGNAL PROC LET, V30, P11, DOI 10.1109/LSP.2023.3238277
   Zhou LF, 2023, IEEE T CIRC SYST VID, V33, P118, DOI 10.1109/TCSVT.2022.3199325
   Zhu WJ, 2022, KNOWL-BASED SYST, V251, DOI 10.1016/j.knosys.2022.109318
NR 43
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 19
PY 2023
DI 10.1007/s11042-023-16707-w
EA SEP 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA S1WZ2
UT WOS:001069156900007
DA 2024-07-18
ER

PT J
AU Rezaimehr, F
   Dadkhah, C
AF Rezaimehr, Fatemeh
   Dadkhah, Chitra
TI T&TRS: robust collaborative filtering recommender systems against
   attacks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender systems; Collaborative filtering; Attacks; Time; Trust;
   Community detection; Graph
AB In recent years, the Internet has had a main and important contribution to human life and the amount of data on the World Wide Web such as books, movies, videos and, etc. increase rapidly. Recommender systems allow users to quickly access items that are closer to their interests. One of the most popular and easiest models of recommender systems is the Collaborative Filtering (CF) model, which uses the items ratings given by users. The important challenge of CF is robust against the attacks which manipulated by fake users to reduce the efficiency of the system. Therefore, the impact of attacks on the item recommendations will increase and fake items will be easily recommended to users. The purpose of this paper is to design a robust CF recommender system, T&TRS, Time and Trust Recommender System, against user attacks. Our proposed system improves the performance of users clustering for detecting the fake users based on a novel community detection algorithm that is introduced in this paper. Our proposed system calculates the reliably value for all items ratings and tags them as suspicious or correct. T&TRS considered the rating time and implicit and explicit trust among users for constructing the weighted user-user network and detects communities as the nearest neighbors of the users to predict unknown items ratings. After detecting the suspect users and items using a novel community detection method, our proposed system removes them from rating matrix and predict the rating of unobserved items and generate the Top@k items according to the user interests. We inject the random and average attacks into the Epinion data set and evaluate our proposed systems based on Precision, Recall, F1, MAE, RMSE, and RC measures before and after attacks. The experimental results indicated that the precision of items recommendations increase after attack detection and show the effectiveness of T&TRS in comparison to the two base K-means methods such as KMCF-U, KMCF-I and graph-based methods such as TRACCF, and TOTAR.
C1 [Rezaimehr, Fatemeh; Dadkhah, Chitra] KN Toosi Univ Technol, Comp Engn Fac, Tehran, Iran.
C3 K. N. Toosi University of Technology
RP Dadkhah, C (corresponding author), KN Toosi Univ Technol, Comp Engn Fac, Tehran, Iran.
EM F.rezaimehr@email.kntu.ac.ir; Dadkhah@kntu.ac.ir
RI Rezaimehr, Fatemeh/AHD-5312-2022
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   Aggarwal C. C., 2016, RECOMMENDER SYSTEMS, P139, DOI DOI 10.1007/978-3-319-29659-3
   Ahmadian M, 2022, EXPERT SYST APPL, V197, DOI 10.1016/j.eswa.2022.116697
   Ahmadian S, 2020, KNOWL-BASED SYST, V192, DOI 10.1016/j.knosys.2019.105371
   Al-Ghobari M, 2021, CMC-COMPUT MATER CON, V69, P1553, DOI 10.32604/cmc.2021.016348
   Alamoodi AH, 2022, COMPLEX INTELL SYST, V8, P3479, DOI 10.1007/s40747-022-00689-7
   Alenezi T, 2022, IEEE ACCESS, V10, P56493, DOI 10.1109/ACCESS.2022.3178439
   Alok N, 2021, Mach. Learn. Healthc. Appl., P187, DOI DOI 10.1002/9781119792611.CH12
   Alone V, 2022, Travel recommender system for social media, DOI [10.2139/ssrn.4114101, DOI 10.2139/SSRN.4114101]
   Beg S, 2021, J NETW COMPUT APPL, V174, DOI 10.1016/j.jnca.2020.102874
   Birtolo C, 2013, EXPERT SYST APPL, V40, P6997, DOI 10.1016/j.eswa.2013.06.022
   Caruccio L, 2018, IEEE INT CONF BIG DA, P5078, DOI 10.1109/BigData.2018.8622011
   Cerruto F, 2022, J BIG DATA-GER, V9, DOI 10.1186/s40537-022-00566-7
   Chawla S., 2021, Research Anthology on Multi-Industry Uses of Genetic Programming and Algorithms, P656, DOI [10.4018/978-1-7998-8048-6.ch034, DOI 10.4018/978-1-7998-8048-6.CH034]
   Cirillo S, 2023, A visual privacy tool to help users in preserving social network data, DOI [10.1007/s10462-020-09898-3, DOI 10.1007/S10462-020-09898-3]
   Daneshmand SM, 2015, COMPUT J, V58, P1955, DOI 10.1093/comjnl/bxu115
   Feng HY, 2015, INFORM MANAGE-AMSTER, V52, P789, DOI 10.1016/j.im.2015.02.004
   Forouzandeh S, 2022, FUZZY INF ENG, V14, P26, DOI 10.1080/16168658.2021.2019430
   Francia M, 2022, INFORM SYST, V104, DOI 10.1016/j.is.2021.101752
   Gasparetti F, 2021, APPL INTELL, V51, P3975, DOI 10.1007/s10489-020-01962-3
   Islek I, 2022, ELECTRON COMMER R A, V52, DOI 10.1016/j.elerap.2022.101131
   Jiang L, 2022, WIREL NETW, V28, P1177, DOI 10.1007/s11276-021-02826-5
   Jinghua Piao, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3479583
   Khalaji M, 2021, Arxiv, DOI arXiv:2105.11678
   Khan MTR, Pop-Vndn: Proactive on-path content prefetching in vehicular named data networks, P1, DOI [10.2139/ssrn.4058929, DOI 10.2139/SSRN.4058929]
   Koren Y., 2021, Recommender systems handbook, P91
   Kumar Avanish, 2021, International Conference on Deep Learning, Artificial Intelligence and Robotics ICDLAIR 2019. Proceedings. Lecture Notes in Networks and Systems (LNNS 175), P153, DOI 10.1007/978-3-030-67187-7_17
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P26635, DOI 10.1007/s11042-018-5882-z
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Kumar KP, 2017, ADV BUS STRATEGY COM, P1, DOI 10.4018/978-1-5225-1008-6.ch001
   Kumar S, 2018, 2018 4 INT C REC ADV, P1
   Kumari Shreya, 2021, International Conference on Deep Learning, Artificial Intelligence and Robotics ICDLAIR 2019. Proceedings. Lecture Notes in Networks and Systems (LNNS 175), P339, DOI 10.1007/978-3-030-67187-7_35
   Lam S. K., 2004, P 13 INT C WORLD WID, P393, DOI DOI 10.1145/988672.988726
   Lee S, 2010, DECIS SUPPORT SYST, V49, P486, DOI 10.1016/j.dss.2010.06.002
   Li Y, 2014, IEEE T IND INFORM, V10, P502, DOI 10.1109/TII.2013.2258677
   Massa P, 2004, LECT NOTES COMPUT SC, V3290, P492, DOI 10.1007/978-3-540-30468-5_31
   Moradi P, 2016, INT CONF ADV ICT, P162, DOI 10.1109/ICTER.2016.7829914
   Moradi P, 2015, EXPERT SYST APPL, V42, P7386, DOI 10.1016/j.eswa.2015.05.027
   Narayanan P., 2022, Inf Syst, V9, pe6, DOI [10.4108/eai.2-11-2021.171754, DOI 10.4108/EAI.2-11-2021.171754]
   Negi A., 2021, INT C BIG DATA ANALY, P296, DOI DOI 10.1007/978-3-030-93620-4_21
   Negi A., 2021, Agricultural Informatics: Automation using the IoT and Machine Learning, P117, DOI [10.1002/9781119769231.ch6, DOI 10.1002/9781119769231.CH6]
   Negi A., 2021, Computational Intelligence and Healthcare Informatics, P255
   Negi A., 2021, Data Science and Its Applications, P63
   Negi A, 2020, 2020 5TH IEEE INTERNATIONAL CONFERENCE ON RECENT ADVANCES AND INNOVATIONS IN ENGINEERING (IEEE - ICRAIE-2020), DOI 10.1109/ICRAIE51050.2020.9358337
   Ormel I, 2021, JMIR FORM RES, V5, DOI 10.2196/22970
   Ovaisi Z, 2022, WSDM'22: PROCEEDINGS OF THE FIFTEENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P1597, DOI 10.1145/3488560.3502192
   Ran X, 2022, NEUROCOMPUTING, V483, P32, DOI 10.1016/j.neucom.2022.01.079
   Reusens M, 2017, DECIS SUPPORT SYST, V98, P26, DOI 10.1016/j.dss.2017.04.002
   Rezaeimehr F, 2018, FUTURE GENER COMP SY, V78, P419, DOI 10.1016/j.future.2017.04.003
   Rezaimehr F, 2021, 2021 26TH INTERNATIONAL COMPUTER CONFERENCE, COMPUTER SOCIETY OF IRAN (CSICC), DOI 10.1109/CSICC52343.2021.9420553
   Rezaimehr F, 2021, ARTIF INTELL REV, V54, P2011, DOI 10.1007/s10462-020-09898-3
   Ricci F., 2010, Information Technology and Tourism, V12, P205, DOI 10.3727/109830511X12978702284390
   Salehi M, 2013, IEEE T LEARN TECHNOL, V6, P350, DOI 10.1109/TLT.2013.28
   Sharma S, 2017, 2017 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT)
   Sharma S, 2017, LECT NOTES COMPUT SC, V10597, P373, DOI 10.1007/978-3-319-69900-4_47
   Tahmasebi F, 2021, MULTIMED TOOLS APPL, V80, P2339, DOI 10.1007/s11042-020-09768-8
   Tohidi N, 2020, INT J NONLINEAR ANAL, V11, P483, DOI 10.22075/ijnaa.2020.19127.2058
   Vijayvergia A, 2018, 2018 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT'18)
   Wahab OA, 2022, INFORM SCIENCES, V601, P189, DOI 10.1016/j.ins.2022.04.027
NR 59
TC 1
Z9 1
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 31701
EP 31731
DI 10.1007/s11042-023-16641-x
EA SEP 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001067934200002
DA 2024-07-18
ER

PT J
AU Yue, T
   Li, Y
   Qin, JD
   Hu, ZH
AF Yue, Tan
   Li, Yong
   Qin, Jiedong
   Hu, Zonghai
TI Multi-modal hierarchical fusion network for fine-grained paper
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information fusion; Multi-modal information processing; Natural language
   processing application; Paper classification
AB Because huge amount of scientific papers have been published at an accelerating rate, it is beneficial to do intelligent paper classification, especially fine-grained classification. However, existing natural language processing techniques are mostly coarse-grained. Some characteristics of fine-grained scientific paper classification needs special attention. One is that the number of data may well be quite limited. Number of papers in the lower level sub-fields inevitably becomes less. Meanwhile, emerging sub-fields with new discoveries will have few papers, nevertheless these sub-fields can be important. Furthermore, fine-grained labeling of scientific papers requires high expertise and is time consuming. Another aspect of scientific papers is that they contain multi-modal information. To address the above two issues, we propose a multi-modal hierarchical fusion network (MHFNet) for fine-grained paper classification. We treat paper abstract features, image features, and paper title features as three modalities. The MobileNetV2 model and the ALBERT model are combined in the proposed model to encode multi-modal information. Comparison results with baseline methods on both sufficiently large datasets and number-limited datasets show improvements, even more on number-limited datasets.
C1 [Yue, Tan; Li, Yong; Qin, Jiedong; Hu, Zonghai] Beijing Univ Posts & Telecommun, Sch Elect Engn, Beijing Key Lab Work Safety Intelligent Monitorin, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Hu, ZH (corresponding author), Beijing Univ Posts & Telecommun, Sch Elect Engn, Beijing Key Lab Work Safety Intelligent Monitorin, Beijing 100876, Peoples R China.
EM zhhu@bupt.edu.cn
FU The BUPT innovation and entrepreneurship support program
FX The work described in this paper was supported by the BUPT innovation
   and entrepreneurship support program (2022-YC-S002) and the Beijing Key
   Laboratory of Work Safety and Intelligent Monitoring Foundation.
CR Adhikari Ashutosh, 2019, DocBERT: BERT for document classification
   Brown T., 2020, P ADV NEUR INF PROC, V33, P1877
   Cadene R, 2019, PROC CVPR IEEE, P1989, DOI 10.1109/CVPR.2019.00209
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chen Y.-C., 2020, ECCV
   Devlin J., 2018, BERT PRE TRAINING DE
   Dhaliwal SS, 2018, INFORMATION, V9, DOI 10.3390/info9070149
   Gallo I., 2018, Digital image computing: techniques and applications (DICTA), P1
   Gallo I, 2017, PROC INT CONF DOC, P36, DOI 10.1109/ICDAR.2017.326
   Hu XW, 2021, AAAI CONF ARTIF INTE, V35, P1575
   Ke GL, 2017, ADV NEUR IN, V30
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Kingma D. P., 2014, arXiv
   Kipf TN, 2017, INT C LEARN REPR
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lan Z., 2019, INT C LEARNING REPRE
   Li LJ, 2019, IEEE I CONF COMP VIS, P10312, DOI 10.1109/ICCV.2019.01041
   Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167
   Ma X, 2019, IEEE ACCESS, V7, P79887, DOI 10.1109/ACCESS.2019.2923293
   Malik Manuj, 2023, Natural Language Processing and Information Systems: 28th International Conference on Applications of Natural Language to Information Systems, NLDB 2023, Proceedings. Lecture Notes in Computer Science (13913), P18, DOI 10.1007/978-3-031-35320-8_2
   Morvant E, 2014, LECT NOTES COMPUT SC, V8621, P153, DOI 10.1007/978-3-662-44415-3_16
   Pan HL, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1383
   Qian SS, 2016, IEEE T MULTIMEDIA, V18, P233, DOI 10.1109/TMM.2015.2510329
   Quan JH, 2014, LECT NOTES COMPUT SC, V8699, P34, DOI 10.1007/978-3-319-13296-9_4
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Schifanella R., 2016, P 24 ACM INT C MULT, P1136
   Shi CK, 2013, INT CONF CLOUD SERV, P69, DOI 10.1109/CSC.2013.19
   Su W, 2019, INT C LEARN REPR, DOI [10.48550/arXiv.1908.08530, DOI 10.48550/ARXIV.1908.08530]
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tan H, 2019, ARXIV, DOI DOI 10.48550/ARXIV.1908.07490
   Tomas David, 2023, Journal of Ambient Intelligence and Humanized Computing, P7399, DOI 10.1007/s12652-022-04447-y
   Touvron Hugo, 2023, Llama: Open and efficient foundation language models
   van Aken B, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2011.04507
   Xia YJ, 2017, IEEE T IMAGE PROCESS, V26, P3748, DOI 10.1109/TIP.2016.2639438
   Yue T, 2022, J INTELL FUZZY SYST, V43, P5709, DOI 10.3233/JIFS-213022
   Yue T, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10192443
   Zadeh A., 2017, P 2017 C EMP METH NA, P1103, DOI 10.18653/v1/D17-1115
   Zhu JN, 2020, AAAI CONF ARTIF INTE, V34, P9749
NR 40
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 31527
EP 31543
DI 10.1007/s11042-023-16626-w
EA SEP 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001067934200007
DA 2024-07-18
ER

PT J
AU Kumar, J
   Patra, BK
   Sahoo, B
   Babu, KS
AF Kumar, Jitendra
   Patra, Bidyut Kumar
   Sahoo, Bibhudatta
   Babu, Korra Sathya
TI Group recommendation exploiting characteristics of user-item and
   collaborative rating of users
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Group recommender system (GRS); Aggregation function; Demographic
   information; Cluster; Content-based filtering (CBF); Group profile
ID SYSTEM
AB Recommender Systems have gained popularity in recent years due to their ability to expedite users' selection processes quickly. Traditional recommender systems mainly focus on providing recommendations to a user. However, It is not a suitable recommendation technique for groups of users. A group recommendation system (GRS) addresses this issue of recommendation. GRS is popular in domain, such as health, tourism, movies, etc. A few research is reported in the GRS domain that satisfy each user requirement in a group. The task of GRS can be divided into three subtasks: the formation of the group, rating prediction of individual members in a group, and aggregating them. The state of art technique can not adequately address the issue of group satisfaction. To maximize member satisfaction, we exploit the cluster validation metrics to form suitable groups of users in this paper. We propose a novel technique for rating the prediction of individual members in a group on an item considering the user's characteristics, such as age, gender, and occupation. A Novel aggregation function named Tendency-based Aggregation (TA) is proposed for aggregating the predicted rating of an individual in a group. We conducted the experiments on datasets ML-1M-I, ML-1M-II, and ML-100k to show the efficiency of the proposed method. To validate the proposed approach, we utilize popular evaluation methods used in GRS, such as MAE, RMSE, and group satisfaction metric (GSM). We also report the result of proposed GRS utilizing the newly introduced group satisafction error (SEG). The experimental outcomes show that the proposed method outperforms all the existing methods. The proposed approach improves the GSM by at most 35% compared to the state-of-the-art.
C1 [Kumar, Jitendra; Sahoo, Bibhudatta] Natl Inst Technol Rourkela, Comp Sci & Engn, Sect 1, Rourkela 769008, Odisha, India.
   [Patra, Bidyut Kumar] Indian Inst Technol BHU Varanasi, Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India.
   [Babu, Korra Sathya] Indian Inst Informat Technol Design & Mfg Kurnool, Comp Sci & Engn, Kurnool 518007, Andhra Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela; Indian Institute of Technology System (IIT System);
   Indian Institute of Technology BHU Varanasi (IIT BHU Varanasi)
RP Kumar, J (corresponding author), Natl Inst Technol Rourkela, Comp Sci & Engn, Sect 1, Rourkela 769008, Odisha, India.
EM 520cs1001@nitrkl.ac.in; bidyut76@gmail.com; bdsahu@nitrkl.ac.in;
   ksb@iiitk.ac.in
CR Agarwal A, 2017, EXPERT SYST APPL, V82, P115, DOI 10.1016/j.eswa.2017.03.069
   [Anonymous], 2015, Preference-oriented social networks: Group recommendation and inference, DOI DOI 10.1145/2792838.2800190
   Baltrunas L., 2010, P 4 ACM C REC SYST, P119, DOI DOI 10.1145/1864708.1864733
   Belhadi A, 2022, IEEE T INTELL TRANSP, V23, P9346, DOI 10.1109/TITS.2021.3114064
   Belhadi A, 2022, IEEE T CYBERNETICS, V52, P4508, DOI 10.1109/TCYB.2020.3029338
   Boratto L, 2016, FUTURE GENER COMP SY, V64, P165, DOI 10.1016/j.future.2015.10.007
   Boratto L, 2015, INT J MACH LEARN CYB, V6, P953, DOI 10.1007/s13042-015-0371-4
   Cacheda F, 2011, ACM T WEB, V5, DOI 10.1145/1921591.1921593
   Cao D, 2018, ACM/SIGIR PROCEEDINGS 2018, P645, DOI 10.1145/3209978.3209998
   Ceh-Varela E, 2022, ACM T INTEL SYST TEC, V13, DOI 10.1145/3542804
   Christensen I, 2016, J INTELL INF SYST, V47, P209, DOI 10.1007/s10844-016-0400-0
   Christensen IA, 2011, EXPERT SYST APPL, V38, P14127, DOI 10.1016/j.eswa.2011.04.221
   Crossen A., 2002, IUI 02. 2002 International Conference on Intelligent User Interfaces, P184
   Dara S, 2020, J INTELL INF SYST, V54, P271, DOI 10.1007/s10844-018-0542-3
   De Pessemier T, 2014, MULTIMED TOOLS APPL, V72, P2497, DOI 10.1007/s11042-013-1563-0
   Delic A, 2019, 2019 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2019), P403, DOI 10.1145/3350546.3352556
   Gazdar A, 2020, KNOWL-BASED SYST, V188, DOI 10.1016/j.knosys.2019.105058
   Guo JP, 2016, IEEE INTELL SYST, V31, P40, DOI 10.1109/MIS.2016.28
   Guo ZW, 2022, IEEE T NETW SCI ENG, V9, P1067, DOI 10.1109/TNSE.2021.3049262
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Ismail F, 2023, DISASTER MED PUBLIC, V16, P2331, DOI 10.1017/dmp.2021.123
   Kim KJ, 2008, EXPERT SYST APPL, V34, P1200, DOI 10.1016/j.eswa.2006.12.025
   Liao J, 2022, INFORM SCIENCES, V589, P595, DOI 10.1016/j.ins.2022.01.001
   Liu SW, 2017, MACH LEARN, V106, P523, DOI 10.1007/s10994-016-5603-7
   Mahyar H, 2017, P 26 INT C WORLD WID, P1187, DOI [10.1145/3041021.3055363, DOI 10.1145/3041021.3055363]
   Masthoff J., 2015, recommender systems handbook, P743, DOI 10.1007/978-1-4899-7637-6_22
   McCarthy J. F., 1998, ACM 1998 Conference on Computer Supported Cooperative Work. Proceedings. CSCW 98, P363, DOI 10.1145/289444.289511
   McCarthy K., 2006, FLAIRS Conference, P86
   Nozari RB, 2021, EXPERT SYST APPL, V186, DOI 10.1016/j.eswa.2021.115709
   Nozari RB, 2020, KNOWL-BASED SYST, V205, DOI 10.1016/j.knosys.2020.106296
   O'Connor M, 2001, ECSCW 2001: PROCEEDINGS OF THE SEVENTH EUROPEAN CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P199
   Park J, 2019, DATA MIN KNOWL DISC, V33, P204, DOI 10.1007/s10618-018-0600-z
   Patra BK, 2015, KNOWL-BASED SYST, V82, P163, DOI 10.1016/j.knosys.2015.03.001
   Pujahari A, 2015, 2015 14TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY (ICIT 2015), P148, DOI 10.1109/ICIT.2015.36
   Qian XM, 2014, IEEE T KNOWL DATA EN, V26, P1763, DOI 10.1109/TKDE.2013.168
   Qin D, 2020, IEEE T KNOWL DATA EN, V32, P453, DOI 10.1109/TKDE.2018.2879658
   Quijano-Sanchez Lara, 2012, Case-Based Reasoning Research and Development. Proceedings of the 20th International Conference, ICCBR 2012, P342, DOI 10.1007/978-3-642-32986-9_26
   Sacharidis D, 2019, SAC '19: PROCEEDINGS OF THE 34TH ACM/SIGAPP SYMPOSIUM ON APPLIED COMPUTING, P1663, DOI 10.1145/3297280.3297442
   Seo YD, 2021, EXPERT SYST APPL, V183, DOI 10.1016/j.eswa.2021.115396
   Seo YD, 2018, EXPERT SYST APPL, V93, P299, DOI 10.1016/j.eswa.2017.10.027
   Villegas NM, 2018, KNOWL-BASED SYST, V140, P173, DOI 10.1016/j.knosys.2017.11.003
   Wang X, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P165, DOI 10.1145/3331184.3331267
   Wang YF, 2023, ACM T INFORM SYST, V41, DOI 10.1145/3547333
   Yalcin E, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102608
   Yalcin E, 2021, EXPERT SYST APPL, V174, DOI 10.1016/j.eswa.2021.114709
   Yalcin E, 2021, EXPERT SYST APPL, V166, DOI 10.1016/j.eswa.2020.114111
   Yin HZ, 2019, PROC INT CONF DATA, P566, DOI 10.1109/ICDE.2019.00057
   Yu L, 2023, DECIS SUPPORT SYST, V165, DOI 10.1016/j.dss.2022.113894
   Zhang Q, 2019, IEEE T NEUR NET LEAR, V30, P1998, DOI 10.1109/TNNLS.2018.2875144
NR 49
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29289
EP 29309
DI 10.1007/s11042-023-16799-4
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066976400014
DA 2024-07-18
ER

PT J
AU Reddy, GK
   Sheeba, GM
AF Reddy, G. Krishna
   Sheeba, G. Merlin
TI Enhancing PAPR performance in MIMO-OFDM system using hybrid optimal
   MMSE-MLSE equalizers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE PAPR reduction; Hybrid equalizer; MMSE-MLSE; Optimization technique;
   Equalizer selection
ID REDUCTION; INFORMATION; SIGNAL
AB Wireless communication technologies are playing a very important role in the modern world. The use of multiple antennas with orthogonal frequency division multiple access (MIMO-OFDM) has enhanced spectral efficiency and coverage area. The transmission channel in MIMO-OFDM systems changes with time, creating Inter Symbol Interference (ISI) and Channel Impulse Response (CIR). Modern MIMO-OFDM systems have a high Peak-to-Average Power Ratio (PAPR). Recently, numerous strategies have been developed to minimize PAPR by increasing phase factors. Due to nonlinear effects, high PAPR causes system deterioration. In this paper, we propose hybrid optimal MMSE-MLSE equalizers to enhance PAPR performance in MIMO-OFDM system. First, we introduce hybrid channel equalizer called MMSE and MLSE at the receiver end to improve the performance and to achieve a maximum diversity order. After that, we develop an Adaptive Fruit fly based Deep Neural Network (AF-DNN) by Adaptive Fruit fly Optimization (FOA) to optimally select the equalizer by using the design metrics. Finally, the performance of proposed PAPR reduction using hybrid optimal MMSE-MLSE equalizer is evaluated and their simulation results are compared with the existing state-of-art PAPR reduction techniques in terms of data rate loss, PAPR, BLER, BER and SER.
C1 [Reddy, G. Krishna] Sathyabama Inst Sci & Technol, Chennai, India.
   [Reddy, G. Krishna] G Narayanamma Inst Technol & Sci, Hyderabad, India.
   [Sheeba, G. Merlin] Jerusalem Coll Engn, Dept ECE, Chennai, India.
C3 Sathyabama Institute of Science & Technology
RP Reddy, GK (corresponding author), Sathyabama Inst Sci & Technol, Chennai, India.; Reddy, GK (corresponding author), G Narayanamma Inst Technol & Sci, Hyderabad, India.
EM gkr999gkr@gmail.com
RI Reddy, G.Krishna/ACR-8276-2022; Sheeba, Merlin/AEX-3086-2022
OI Reddy, G.Krishna/0000-0002-4101-2994; Sheeba, Merlin/0000-0002-4403-6238
CR Arbi T, 2021, IEEE T BROADCAST, V67, P491, DOI 10.1109/TBC.2021.3056232
   Banoori F, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4335
   Cho L, 2021, IEEE ACCESS, V9, P15659, DOI 10.1109/ACCESS.2021.3051664
   Goodarzian F, 2021, SOFT COMPUT, V25, P7527, DOI 10.1007/s00500-021-05711-7
   Gu K, 2021, IEEE T NEUR NET LEAR, V32, P4278, DOI 10.1109/TNNLS.2021.3105394
   Gu K, 2021, IEEE T IND INFORM, V17, P2261, DOI 10.1109/TII.2020.2991208
   Gu K, 2020, IEEE T MULTIMEDIA, V22, P311, DOI 10.1109/TMM.2019.2929009
   Hu SC, 2022, J SIGNAL PROCESS SYS, V94, P837, DOI 10.1007/s11265-022-01750-x
   Hu WW, 2019, IEEE T BROADCAST, V65, P316, DOI 10.1109/TBC.2018.2828610
   Jawhar YA, 2019, IEEE ACCESS, V7, P18021, DOI 10.1109/ACCESS.2019.2894527
   Kageyama T, 2020, IEEE ACCESS, V8, P73420, DOI 10.1109/ACCESS.2020.2986280
   Kalinov A, 2021, IEEE WIREL COMMUN LE, V10, P537, DOI 10.1109/LWC.2020.3036909
   Khan MSA, 2020, EURASIP J WIREL COMM, V2020, DOI 10.1186/s13638-020-01787-1
   Khwandah SA, 2021, WIRELESS PERS COMMUN, V120, P2101, DOI 10.1007/s11277-021-08550-9
   Kotade AB, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMMUNICATION AND COMPUTING TECHNOLOGY (ICACCT), P319, DOI 10.1109/ICACCT.2018.8529645
   Le HA, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144861
   Lee BM, 2021, IEEE T IND INFORM, V17, P4669, DOI 10.1109/TII.2020.3019049
   Li TT, 2022, WIRELESS PERS COMMUN, V122, P861, DOI 10.1007/s11277-021-08929-8
   Lim SC, 2020, IEEE COMMUN LETT, V24, P1621, DOI 10.1109/LCOMM.2020.2989205
   Masood B, 2021, IET GENER TRANSM DIS, V15, P321, DOI 10.1049/gtd2.12023
   Moerman A, 2022, IEEE COMMUN MAG, V60, P27, DOI 10.1109/MCOM.001.2100550
   Odeyemi KO, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4206
   Oh S, 2021, IEEE J SOLID-ST CIRC, V56, P3424, DOI 10.1109/JSSC.2021.3086853
   Omar MS, 2021, IEEE T WIREL COMMUN, V20, P4032, DOI 10.1109/TWC.2021.3055070
   Rakshit M., 2020, SN COMPUT SCI, V1, P1, DOI [10.1007/s42979-020-00309-6, DOI 10.1007/S42979-020-00309-6]
   Sanadhya Gayatri, 2018, 2018 2nd International Conference on Micro-Electronics and Telecommunication Engineering (ICMETE), P168, DOI 10.1109/ICMETE.2018.00046
   Sandoval F, 2019, IEEE ACCESS, V7, P24132, DOI 10.1109/ACCESS.2019.2899965
   Stralka JP, 2008, APPL ORTHOGONAL FREQ
   Tang B, 2020, IEEE ACCESS, V8, P18984, DOI 10.1109/ACCESS.2020.2968560
   Thota S, 2020, IEEE ACCESS, V8, P22780, DOI 10.1109/ACCESS.2020.2970022
   Vijayalakshmi M, 2020, ANALOG INTEGR CIRC S, V102, P145, DOI 10.1007/s10470-019-01475-1
   Wu WH, 2018, DIGIT SIGNAL PROCESS, V80, P27, DOI 10.1016/j.dsp.2018.05.008
   Xu YH, 2019, FRONT INFORM TECH EL, V20, P1587, DOI 10.1631/FITEE.1800438
   Zayani R, 2019, IEEE ACCESS, V7, P25474, DOI 10.1109/ACCESS.2019.2900128
   Zhang YJ, 2021, IEEE T VEH TECHNOL, V70, P8453, DOI 10.1109/TVT.2021.3101687
NR 35
TC 0
Z9 0
U1 5
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28993
EP 29013
DI 10.1007/s11042-023-16489-1
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001061572400001
DA 2024-07-18
ER

PT J
AU Khodaverdian, Z
   Sadr, H
   Edalatpanah, SA
   Nazari, M
AF Khodaverdian, Zeinab
   Sadr, Hossein
   Edalatpanah, Seyed Ahmad
   Nazari, Mojdeh
TI An energy aware resource allocation based on combination of CNN and GRU
   for virtual machine selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Resource allocation; Virtual machine selection; Cloud data centers;
   Convolution Neural Network (CNN); Gated Recurrent Unit (GRU)
ID NEURAL-NETWORK; CONSOLIDATION; EFFICIENCY
AB The use of cloud computing service models is rapidly increasing, but inefficient resource usage in cloud data centers can lead to great energy consumption and costs. To address this issue, plans have been made to allocate resources more efficiently by utilizing live migration of virtual machines (VMs) and consolidating them into a smaller number of physical machines (PMs). Although, selecting a suitable VM for migration is still a significant challenge. One solution is to classify VMs into Delay-Sensitive (Interactive) or Delay-Insensitive classes based on user request patterns, and then select suitable VMs for migration. This selection process can be enabled through workload prediction, which involves predicting and analyzing the workload of VMs as a pre-migration process. A hybrid model based on Convolutional Neural Network (CNN) and Gated Recurrent Unit (GRU) combination is introduced in this paper for classifying VMs in the Microsoft Azure cloud service. Microsoft Azure Dataset is a labeled dataset and virtual machine workload in this dataset is categorized as Delay-Insensitive or Delay-sensitive (Interactive). However, the samples distribution in this dataset is unbalanced and majority samples are classified as Delay-Insensitive. To address the challenge, Synthetic Minority Oversampling Technique (SMOTE) method is leveraged in this paper. The empirical results showed that their proposed model achieved an accuracy of 95.18%, indicating that it outperformed other existing models.
C1 [Khodaverdian, Zeinab] Islamic Azad Univ, Dept Comp Engn, Sci & Res Branch, Tehran, Iran.
   [Sadr, Hossein] Guilan Univ Med Sci, Rasht, Iran.
   [Edalatpanah, Seyed Ahmad] Ayandegan Inst Higher Educ, Dept Comp Engn, Tonekabon, Iran.
   [Nazari, Mojdeh] Shahid Beheshti Univ Med Sci, Sch Allied Med Sci, Dept Med Informat, Tehran, Iran.
C3 Islamic Azad University; Guilan University of Medical Sciences; Shahid
   Beheshti University Medical Sciences
RP Sadr, H (corresponding author), Guilan Univ Med Sci, Rasht, Iran.
EM Zeinab.khodaverdian@srbiau.ac.ir; Sadr@qiau.ac.ir;
   s.a.edalatpanah@aihe.ac.ir; Mojdeh.nazari@sbmu.ac.ir
RI Edalatpanah, S. A/M-1336-2014; Sadr, Hossein/AAC-6722-2019
OI Edalatpanah, S. A/0000-0001-9349-5695; Sadr,
   Hossein/0000-0003-4728-8278; Nazari, Mojdeh/0000-0003-3897-0208
CR Akhtar N, 2020, NEUR COMPUT APPL, P1
   [Anonymous], 2014, WORKSHOP INT C LEARN
   Aslam AM, 2019, LECT NOTE NETW SYST, V39, P139, DOI 10.1007/978-981-13-0277-0_12
   Beloglazov A, 2012, FUTURE GENER COMP SY, V28, P755, DOI 10.1016/j.future.2011.04.017
   Bi J, 2021, NEUROCOMPUTING, V424, P35, DOI 10.1016/j.neucom.2020.11.011
   Chaurasia N, 2021, J SUPERCOMPUT, V77, P11682, DOI 10.1007/s11227-021-03760-1
   Chen ZY, 2020, IEEE T PARALL DISTR, V31, P923, DOI 10.1109/TPDS.2019.2953745
   Chung Junyoung, 2014, ARXIV14123555
   Cortez E, 2017, PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '17), P153, DOI 10.1145/3132747.3132772
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Habashi FS, 2021, CLUSTER COMPUT, V24, P2407, DOI 10.1007/s10586-021-03262-y
   Hamzaoui I., 2020, SN Computer Science, V1, P1, DOI [10.1007/s42979-020-0078-9, DOI 10.1007/S42979-020-0078-9]
   Hariharasubramanian M, 2018, IMPROVING APPL INFRA
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hebbar R, 2021, COMPANION OF THE ACM/SPEC INTERNATIONAL CONFERENCE ON PERFORMANCE ENGINEERING, ICPE 2021, P95, DOI 10.1145/3447545.3451192
   Houssein EH, 2021, SWARM EVOL COMPUT
   Iftikhar S, 2023, INTERNET THINGS-NETH, V21, DOI 10.1016/j.iot.2022.100667
   Jayasena K. P. N., 2021, Advances in Computer, Communication and Computational Sciences. Proceedings of IC4S 2019. Advances in Intelligent Systems and Computing (AISC 1158), P893, DOI 10.1007/978-981-15-4409-5_79
   Kalashami MP, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/7028517
   Kaur Gursharanjit, 2021, Advances in Information Communication Technology and Computing. Proceedings of AICTC 2019. Lecture Notes in Networks and Systems (LNNS 135), P195, DOI 10.1007/978-981-15-5421-6_20
   Khan T, 2021, ARXIV
   Khodaverdian Zeinab, 2021, 2021 7th International Conference on Web Research (ICWR), P191, DOI 10.1109/ICWR51868.2021.9443133
   Kumari A, 2020, J PARALLEL DISTR COM, V143, P148, DOI 10.1016/j.jpdc.2020.05.004
   Madhumala RB, 2021, INT J MATH COMPUT SC, V16, P677
   Mc Donnell N, 2020, FUTURE GENER COMP SY, V108, P288, DOI 10.1016/j.future.2020.02.036
   Medara R, 2021, SIMUL MODEL PRACT TH, V110, DOI 10.1016/j.simpat.2021.102323
   Meyer V, 2021, J SYST ARCHITECT, V116, DOI 10.1016/j.sysarc.2021.102064
   Moreno-Vozmediano R, 2019, J CLOUD COMPUT-ADV S, V8, DOI 10.1186/s13677-019-0128-9
   Ouhame S., 2019, P NEW CHALL DAT SCI, P1
   Patel E, 2018, 2018 5TH IEEE UTTAR PRADESH SECTION INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS AND COMPUTER ENGINEERING (UPCON), P80
   Patterson J., 2017, Deep Learning: A Practitioners Approach
   Piotr N, 2021, J GRID COMPUT, V19
   Plebe A, 2019, MIND MACH, V29, P515, DOI 10.1007/s11023-019-09512-8
   Potdar K., 2017, International journal of computer applications, V175, P7, DOI 10.5120/ijca2017915495
   Prabha B, 2021, DATA INTELLIGENCE CO, P761
   Praveenchandar J, 2021, J AMB INTEL HUM COMP, V12, P4147, DOI 10.1007/s12652-020-01794-6
   Rajnikant PN, 2021, SPRINGER DATA SCI IN, P391, DOI DOI 10.1007/978-981-15-4474-3_43
   Sadr H, 2021, J INF COMMUN TECHNOL, V47
   Sadr H., 2019, J ADV COMPU RES, V10, P17
   Sadr H, 2021, ARXIV
   Sadr H, 2021, J AI DATA MINING
   Sadr H, 2022, J SUPERCOMPUT, V78, P10149, DOI 10.1007/s11227-021-04208-2
   Sadr H, 2020, IEEE ACCESS, V8, P86984, DOI 10.1109/ACCESS.2020.2992063
   Sadr H, 2019, NEURAL PROCESS LETT, V50, P2745, DOI 10.1007/s11063-019-10049-1
   Saeedi P, 2021, SOFT COMPUT, V25, P5233, DOI 10.1007/s00500-020-05523-1
   Sayadnavard MH, 2021, ENG SCI TECHNOL INT
   Sayadnavard MH, 2019, J SUPERCOMPUT, V75, P2126, DOI 10.1007/s11227-018-2709-7
   Shaw R, 2020, SIMUL MODEL PRACT TH, V102, DOI 10.1016/j.simpat.2019.101992
   Singh S, 2016, J GRID COMPUT, V14, P217, DOI 10.1007/s10723-015-9359-2
   Soleymanpour S, 2021, NEURAL PROCESS LETT, V53, P3497, DOI 10.1007/s11063-021-10534-6
   Soleymanpour S, 2020, 2020 6TH INTERNATIONAL CONFERENCE ON WEB RESEARCH (ICWR), P209, DOI [10.1109/ICWR49608.2020.9122299, 10.1109/icwr49608.2020.9122299]
   Teshnelab, 2019, INT J INF COMMUN TEC, V11, P57
   Tsakalidou VN, 2021, ARXIV
   Verma N, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON COMMUNICATION SYSTEMS, COMPUTING AND IT APPLICATIONS (CSCITA), P66, DOI 10.1109/CSCITA.2017.8066526
   Wang YX, 2018, ENERGIES, V11, DOI 10.3390/en11051138
   Wani M.A., 2020, Advances in deep learning
   Witanto JN, 2018, FUTURE GENER COMP SY, V87, P35, DOI 10.1016/j.future.2018.04.075
   Yazdanian P, 2021, J SUPERCOMPUT, V77, P11052, DOI 10.1007/s11227-021-03723-6
   Yazdanian P, 2018, 2018 4TH IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS), P83, DOI 10.1109/ICSPIS.2018.8700546
   Zhang A., 2019, Dive into deep learning
   Zhang WS, 2016, 2016 INTERNATIONAL CONFERENCE ON IDENTIFICATION, INFORMATION AND KNOWLEDGE IN THE INTERNET OF THINGS (IIKI), P104, DOI 10.1109/IIKI.2016.39
   Zhang Y., 2015, arXiv
   Zhang YQ, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P167, DOI 10.1145/3445814.3446693
   Zhu YH, 2019, EURASIP J WIREL COMM, V2019, DOI 10.1186/s13638-019-1605-z
   Zolfaghari R, 2021, SUSTAIN COMPUT-INFOR, V30, DOI 10.1016/j.suscom.2021.100524
NR 65
TC 5
Z9 5
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25769
EP 25796
DI 10.1007/s11042-023-16488-2
EA AUG 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001060108100005
DA 2024-07-18
ER

EF