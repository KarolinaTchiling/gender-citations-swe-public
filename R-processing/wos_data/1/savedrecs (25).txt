FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Maheswari, SU
   Vasanthanayaki, C
AF Maheswari, Uma S.
   Vasanthanayaki, C.
TI Secure medical health care content protection system (SMCPS) with
   watermark detection for multi cloud computing environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud computing (CC); Secure watermark detection; Secure multiparty
   computation; Privacy preserving; Compressive sensing (CS); Cryptography
   algorithms
ID EFFICIENT
AB The aim of this work is to introduce a new secure system for Medical Healthcare records. The proposed design influences cloud infrastructures to give cost competence, fast exploitation, scalability, and flexibility to have room for unstable workloads. The research system could be utilized to safeguard diverse medical health care records. The proposed Secure Medical Healthcare Content Protection System (SMCPS) system contains of two major steps: (i) Hybrid Key Generation (HKG) and (ii) storage management. In the initial step of the work, keys values are created for medical healthcare records by using two encryption techniques such as Advanced Encoding Standard (AES) cryptography and Message Digest (MD5) algorithm for safe multiparty computation. This proposed HKG algorithm is different from usual key generation algorithm, since the proposed HKG algorithm adds the key values of AES and MD5. New key value is created from these two algorithms, thus increases the security level of the system. The HKG algorithm creates dynamic and representative keys of medical healthcare records, it is computationally resourceful to calculate and contrast in addition it needs small storage. In the second step of the work, Compressive Sensing (CS) based framework for storage management of medical healthcare records. The distributed matching engine achieves greater adaptability and it is created to among different healthcare records gathered from UCI machine learning vault for 100 patients. The applicability is further examined for the applicability of sparse coding-based frameworks including the various numbers of medical healthcare records which influences the ability of Multi Cloud Computing (MCC) environment. The experimentation work are performed by using Miscellaneous database for watermark pattern and any medical healthcare records are taken as input in MCC environment results outcomes prove that safe watermark recognition in the CS domain is possible for medical healthcare records are implemented in JAVA environment. The proposed work provides a CS based watermark recognition which influences safe MCC environment. The results are measured as in terms of Peak Signal to Noise Ratio (PSNR), the Mean Square Error (MSE) and the Structural Similarity Index (SSIM), security and communication cost.
C1 [Maheswari, Uma S.] Kumaraguru Coll Technol, Dept CSE, Coimbatore, Tamil Nadu, India.
   [Vasanthanayaki, C.] Govt Coll Engn, Dept ECE, Salem, India.
C3 Kumaraguru College of Technology
RP Maheswari, SU (corresponding author), Kumaraguru Coll Technol, Dept CSE, Coimbatore, Tamil Nadu, India.
EM umashanmugam.me@gmail.com; vasanthi@gct.ac.in
RI C, Vasanthanayaki/JYQ-2173-2024
OI MAHESWARI S, UMA/0000-0002-9458-9201
CR Alqahtani HS, 2016, INT CONF DIGIT INFO, P63, DOI 10.1109/DICTAP.2016.7544002
   [Anonymous], DESIGN RIJNDAEL AES
   [Anonymous], 2009, DEP ELECT ENG COMPUT
   [Anonymous], 2010, IJ NETWORK SECURITY
   Ashokkumar S., 2010, International Journal of Computer Applications, V2, P21, DOI [10.5120/616-867./, DOI 10.5120/616-867]
   Ateniese G, 2007, CCS'07: PROCEEDINGS OF THE 14TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P598
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Jarvinen K., 2005, SYSTEM SCI, p298a
   Kim D, 2016, MULTIMED TOOLS APPL, V75, P13077, DOI 10.1007/s11042-015-2594-5
   Liu XM, 2016, FUTURE GENER COMP SY, V62, P161, DOI 10.1016/j.future.2015.10.005
   Mell P., 2010, NIST DEFINITION CLOU
   Nan XF, 2010, IEEE INT C BIOINFORM, P520, DOI 10.1109/BIBM.2010.5706621
   Qin Z, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P497, DOI 10.1145/2647868.2654941
   Ren K, 2012, IEEE INTERNET COMPUT, V16, P69, DOI 10.1109/MIC.2012.14
   Rudelson M, 2006, 2006 40TH ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS, VOLS 1-4, P207, DOI 10.1109/CISS.2006.286463
   Shahinpoor M., 2008, Intelligent materials, P1
   TRONCOSOPASTORI.JR, 2006, 8 ACM MULT SEC WORKS, P97
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Voloshynovskiy S, 2015, IEEE INT CONF MULTI
   Wang Q, 2014, IEEE T IMAGE PROCESS, V23, P1317, DOI 10.1109/TIP.2014.2298980
   Wang QA, 2011, IEEE T PARALL DISTR, V22, P847, DOI 10.1109/TPDS.2010.183
   Zeghid M, 2007, PROC WRLD ACAD SCI E, V21, P206
   Zeng WJ, 1999, IEEE T IMAGE PROCESS, V8, P1534, DOI 10.1109/83.799882
   Zhang QC, 2016, IEEE T COMPUT, V65, P1351, DOI 10.1109/TC.2015.2470255
   Zheng XQ, 2012, IEEE INT SYMP CIRC S, P2167, DOI 10.1109/ISCAS.2012.6271717
NR 25
TC 4
Z9 4
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 4075
EP 4097
DI 10.1007/s11042-019-7724-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700055
DA 2024-07-18
ER

PT J
AU Pan, ZQ
   Yi, XK
   Chen, LM
AF Pan, Zhaoqing
   Yi, Xiaokai
   Chen, Liming
TI Motion and disparity vectors early determination for texture video in
   3D-HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D-HEVC; High efficiency computing; Motion vector; Disparity vector;
   Texture video coding
ID MERGE MODE DECISION; INTER-VIEW; PREDICTION
AB 3D-HEVC is the state-of-the-art video coding standard for 3D video, and it is an extension of high efficiency video coding (HEVC) standard. Besides the original HEVC coding tools, 3D-HEVC adopts some advanced coding tools, such as disparity vector (DV), inter-view prediction and inter-component prediction. However, these advanced tools lead to extremely high encoding complexity at the same time, thus it cannot be well applied in real-time multimedia systems. In this paper, we propose a motion and disparity vectors early determination algorithm to reduce 3D-HEVC computational complexity. First, based on the statistical analyses, the spatial and temporal motion vector (MV) candidates are adaptively reduced for the prediction unit (PU) with the Merge mode. Then, for the PU with the Inter mode, the combination of spatial and temporal candidates is used to early determine the final MV. Finally, an adaptive optimization algorithm is adopted to select the valid inter-view disparity vectors (DV) candidates. Moreover, if the difference between candidate vectors is within a conditional range, current PU will be encoded with the Merge mode to skip unnecessary coding process. Experimental results show that for the texture views encoding, the proposed algorithm achieves an average of 33.03% encoding time saving, and an average of 0.47% BD-Rate increases.
C1 [Pan, Zhaoqing] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Peoples R China.
   [Pan, Zhaoqing] Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher, Nanjing 210044, Peoples R China.
   [Yi, Xiaokai; Chen, Liming] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology; Nanjing University of
   Information Science & Technology
RP Pan, ZQ (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Peoples R China.; Pan, ZQ (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher, Nanjing 210044, Peoples R China.
EM zqpan3-c@my.cityu.edu.hk; xyi@nuist.edu.cn; leegendchen@outlook.com
CR Ahn S, 2015, IEEE T CIRC SYST VID, V25, P422, DOI 10.1109/TCSVT.2014.2360031
   [Anonymous], 2014, 2014 IEEE 5 LATIN AM
   Ayad M, 2016, INT J SENS NETW, V20, P70, DOI 10.1504/IJSNET.2016.074695
   BjOntegaard G, 2008, SG16Q6B ITUT
   Chang WK, 2015, 2015 15TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES (ISCIT), P65, DOI 10.1109/ISCIT.2015.7458308
   Chen Y, 2015, JCTVCK1003
   Chen Y, 2016, IEEE T MULTIMEDIA, V18, P576, DOI 10.1109/TMM.2016.2525010
   Chew LW, 2012, INT J SENS NETW, V11, P33, DOI 10.1504/IJSNET.2012.045033
   Choi H, 2014, MULTIMED TOOLS APPL, V6, P1
   da Silva TL, 2016, J REAL-TIME IMAGE PR, V12, P357, DOI 10.1007/s11554-015-0533-3
   Hannuksela Miska M., 2015, 2015 IEEE International Conference on Image Processing (ICIP). Proceedings, P2154, DOI 10.1109/ICIP.2015.7351182
   Huang YP, 2015, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND INDUSTRIAL AUTOMATION (ICITIA 2015), P402
   Jeong J, 2016, ADV SCI TECH LETT, V139, P287, DOI [10.14257/astl.2016.139.60, DOI 10.14257/ASTL.2016.139.60]
   Jun D, 2018, MULTIMED TOOLS APPL, V77, P4661, DOI 10.1007/s11042-017-4850-3
   Kaur J, 2017, CMC-COMPUT MATER CON, V53, P23
   Lin JY, 2011, DIR DEV, P1
   Le Dinh M, 2016, PROC INT CONF ADV, P312, DOI 10.1109/ATC.2016.7764796
   Mora EG, 2013, IEEE INT WORKSH MULT, P206, DOI 10.1109/MMSP.2013.6659289
   Nie QK, 2018, CMC-COMPUT MATER CON, V55, P59, DOI 10.3970/cmc.2018.055.059
   Pan ZQ, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3159170
   Pan ZQ, 2016, IEEE T BROADCAST, V62, P675, DOI 10.1109/TBC.2016.2580920
   Pan ZQ, 2014, IEEE T BROADCAST, V60, P405, DOI 10.1109/TBC.2014.2321682
   Qi XL, 2012, INT CONF ACOUST SPEE, P1217, DOI 10.1109/ICASSP.2012.6288107
   Rusanovskyy D., 2013, document JCT3V-E1100
   Schwarz H, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P101, DOI 10.1109/PCS.2012.6213296
   Smolic A, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P2161, DOI 10.1109/ICME.2006.262683
   Song YX, 2015, J VIS COMMUN IMAGE R, V33, P60, DOI 10.1016/j.jvcir.2015.07.001
   Vanne J, 2014, IEEE T CIRC SYST VID, V24, P1579, DOI 10.1109/TCSVT.2014.2308453
   Xiong J, 2014, IEEE T MULTIMEDIA, V16, P559, DOI 10.1109/TMM.2013.2291958
   Zhang L, 2013, IEEE INT SYMP CIRC S, P1632, DOI 10.1109/ISCAS.2013.6572175
   Zhang N., 2014, IEEE INT S BIOEL BIO, P1
   Zhang QW, 2016, AEU-INT J ELECTRON C, V70, P727, DOI 10.1016/j.aeue.2016.02.008
   Zhang Y, 2017, MULTIMED TOOLS APPL, V76, P1101, DOI 10.1007/s11042-015-3109-0
   Zheng A, 2015, IEEE INT C IM PROC, P3724
NR 34
TC 28
Z9 28
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4297
EP 4314
DI 10.1007/s11042-018-6830-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500004
DA 2024-07-18
ER

PT J
AU Prabhu, V
   Kuppusamy, PG
   Karthikeyan, A
   Sucharitha, M
AF Prabhu, V.
   Kuppusamy, P. G.
   Karthikeyan, A.
   Sucharitha, M.
TI A novel approach for non-invasive measurement of mean arterial pressure
   using pulse transit time
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blood pressure (BP); Electrocardiography (ECG); Mean arterial pressure
   (MAP); Pulse transit time (PTT)
ID LESS ROUTING ARCHITECTURE; BLOOD
AB Recent days many researches are carried out related to the heart of the human. As a result many remedies are found for the various heart disorders. Electrocardiography (ECG) is the exertion of the electrical response from heart by placing the electrodes over the chest. The Einthoven triangle is an imaginary formation of the three leads in the triangle used in electrocardiography; by that technique of placement of electrode we can analysis the electrocardiogram of the heart. The waveform is also known as PQR waveform which contains the information of arterial repolarization, arterial polarization, ventricular repolarization and ventricular polarization. In general the BP monitor is carried out using oscillometry. In the existing system separate techniques and devices are used to measure electrocardiography and BP. The proposed system is to integrate both electrocardiography and blood pressure measurement by means adopting transit pulse time. It is defined as the systematic time lay off betwixt oscillometric pulses and peaks of ECG especially R peaks of it. The major advantage of the system is to exhibit non-zero crossing and gives more accurate result. The mean arterial pressure estimation is done by using MatLab which is the unique estimation method for measuring pulse transit time interval. Thus the non invasive system designed which reduce the cuff deviations and errors in electrocardiography. It can be applied in detecting the arterial disorders at most efficient manner.
C1 [Prabhu, V.; Kuppusamy, P. G.; Karthikeyan, A.] Vel Tech Multi Tech Dr Rangarajan Dr Sakunthala E, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
   [Sucharitha, M.] Malla Reddy Coll Engn & Technol, Dept Elect & Commun Engn, Hyderabad, Telangana, India.
C3 Vel Tech Multi Tech Dr.Rangarajan Dr.Sakunthala Engineering College;
   Malla Reddy College of Engineering & Technology
RP Prabhu, V (corresponding author), Vel Tech Multi Tech Dr Rangarajan Dr Sakunthala E, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
EM prabhu.cvj@gmail.com; kuppusamy.1975@gmail.com; a.karthik1982@gmail.com;
   sucharitha_m2002@yahoo.co.in
RI M, Sucharitha/K-6504-2019; v, prabhu/HNQ-9213-2023
OI M, Sucharitha/0000-0002-2744-4117; v, prabhu/0000-0002-8083-0156; A,
   Karthikeyan/0000-0001-6290-6770
CR Ahmed S, 2012, IEEE T BIOMED ENG, V59
   Amoore JN, 2008, J HYPERTENS, V26, P35, DOI 10.1097/HJH.0b013e3282f06ec7
   Balasingam B, 2011, P IEEE INT WORKSH ME
   Dhanalakshmi K, 2013, INT J IMAG SYST TECH, V23, P194, DOI 10.1002/ima.22052
   Dhiravidachelvi E., 2015, Journal of Computer Science, V11, P262, DOI 10.3844/jcssp.2015.262.269
   Forouzanfar M, 2014, IEEE T INSTRUMENT ME, V63
   Forouzanfar M, 2012, COEFFICIENT FREE BLO
   Frouzanfar M, 2013, COEFFICIENT FREE BLO, P60
   Karthikeyan A, 2018, CLUSTER COMPUT, V21, P177, DOI 10.1007/s10586-017-0979-0
   Karthikeyan A, 2017, COMPUT ELECTR ENG, V59, P39, DOI 10.1016/j.compeleceng.2017.03.006
   Lee S, 2013, IEEE T INSTRUM MEAS, V62, P3387, DOI 10.1109/TIM.2013.2273612
   Lin C-T, 2003, IEEE T BIOMED ENG, V50
   Mafi M, 2011, P ANN INT C IEEE ENG
   Nichols W.W., 2005, McDonald's Blood Flow in Arteries
   Nitzan M, 2011, IEEE INSTRU MEAS MAG, V14, P32, DOI 10.1109/MIM.2011.5704808
   Prabhu V, 2018, MULTIMED TOOLS APPL, V77, P10375, DOI 10.1007/s11042-018-5792-0
   Prabhu V, 2016, INDIAN J SCI TECHNOL, V9, P1
   Ramaat R, 2010, MED BIOL ENG COMPUT, V37
   Serna JAD, 2013, IEEE T INSTRUM MEAS, V62, P2621, DOI 10.1109/TIM.2013.2258765
   Serna JAD, 2013, IEEE T INSTRUM MEAS, V62, P2511, DOI 10.1109/TIM.2013.2258245
   Song SH, 2009, P IEEE C COMP CARD U
   van Montfrans GA, 2001, BLOOD PRESS MONIT, V6, P287, DOI 10.1097/00126097-200112000-00004
   Zheng D, 2008, COMPUTERS IN CARDIOLOGY 2008, VOLS 1 AND 2, P941, DOI 10.1109/CIC.2008.4749198
   Zheng D, 2011, MED BIOL ENG COMPUT
   Zheng LQ, 2008, STROKE, V39, P1932, DOI 10.1161/STROKEAHA.107.510677
NR 25
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3775
EP 3789
DI 10.1007/s11042-018-6971-8
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700037
DA 2024-07-18
ER

PT J
AU Ye, ZJ
   Ye, HX
AF Ye, Zhijing
   Ye, Haixiong
TI Particle filter algorithm based spatial motion tracking of football
   landing location
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Particle filter; Football tracking; Movement locus; Tracing algorithm
AB In order to improve the accuracy of the tracking of football landing location, a football landing location and spatial motion tracking system based on APRBA multi-camera was proposed. First of all, the study of football movement locus model was conducted. Without considering the speed limit and direction restriction, Bayesian state evolution model was constructed, and based on path loss model, the moving target positioning observation model was established. Secondly, by using the ultrasonic food source localization of the proposed APRBA algorithm and the next target prediction, the particle filter algorithm was improved to realize the effective improvement of target tracking accuracy. Finally, the effectiveness of the proposed target tracking algorithm was verified in the tracking experiment of the moving target model.
C1 [Ye, Zhijing] Shanghai Univ Sport, Dept Phys Educ & Training, Shanghai 200438, Peoples R China.
   [Ye, Haixiong] Shanghai Ocean Univ, Coll Engn Sci & Technol, Shanghai 201306, Peoples R China.
C3 Shanghai University of Sport; Shanghai Ocean University
RP Ye, HX (corresponding author), Shanghai Ocean Univ, Coll Engn Sci & Technol, Shanghai 201306, Peoples R China.
EM qiangyuanlianlyq@163.com
CR Arunkumar N, 2017, PATTERN RECOGN LETT, V94, P112, DOI 10.1016/j.patrec.2017.05.007
   Chan JW, 2015, BIOCONJUGATE CHEM, V26, P1359, DOI 10.1021/acs.bioconjchem.5b00208
   Du XL, 2017, CELL PHYSIOL BIOCHEM, V43, P568, DOI 10.1159/000480529
   Malarkodi M. P, 2013, INT J APPL ENG RES, V8, P1831
   Pan WS, 2013, APPL MATH INFORM SCI, V7, P675, DOI 10.12785/amis/070235
   Stephygraph LR, 2016, ADV INTELL SYST, V397, P537, DOI 10.1007/978-81-322-2671-0_52
   Stephygraph LR, 2015, 2015 INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES AND MANAGEMENT FOR COMPUTING, COMMUNICATION, CONTROLS, ENERGY AND MATERIALS (ICSTM), P596, DOI 10.1109/ICSTM.2015.7225484
   Zhang YY, 2016, BIOMATERIALS, V84, P230, DOI 10.1016/j.biomaterials.2015.12.028
   Zhao YJ, 2017, IEEE T INSTRUM MEAS, V66, P1789, DOI 10.1109/TIM.2017.2665983
NR 9
TC 6
Z9 6
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 5053
EP 5063
DI 10.1007/s11042-018-6307-8
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500046
DA 2024-07-18
ER

PT J
AU Nizami, IF
   Majid, M
   Rehman, MU
   Anwar, SM
   Nasim, A
   Khurshid, K
AF Nizami, Imran Fareed
   Majid, Muhammad
   Rehman, Mobeen ur
   Anwar, Syed Muhammad
   Nasim, Ammara
   Khurshid, Khawar
TI No-reference image quality assessment using bag-of-features with feature
   selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bag-of-features; No-reference image quality assessment; Mean observer
   score; Harris affine detector; Scale invariant feature transform
ID NATURAL SCENE STATISTICS; SUPPORT VECTOR MACHINES; GRADIENT MAGNITUDE;
   JOINT STATISTICS; PATTERN; ALGORITHMS; EFFICIENT; PSNR
AB The aim of no-reference image quality assessment (NR-IQA) is to assess the quality of an image, which is consistent with the mean opinion score, without any prior knowledge about the reference image. This work proposes a new NR-IQA technique based on natural scene statistics properties of the bag-of-features representation and feature selection algorithms. The proposed bag-of-features technique utilizes Harris affine detector and scale invariant feature transform to compute points, which are clustered using the k-means clustering algorithm to extract features for IQA. The extracted features are utilized with a support vector regression model to assess the quality of the image. The proposed technique outperforms state-of-the-art NR-IQA techniques, when tested on three commonly used subjective image quality assessment databases. The experimental results have shown that the features extracted using the proposed technique are database independent and shows high correlation with the mean opinion score.
C1 [Nizami, Imran Fareed; Nasim, Ammara] Bahria Univ, Dept Elect Engn, Islamabad 44000, Pakistan.
   [Majid, Muhammad] Univ Engn & Technol Taxila, Dept Comp Engn, Rawalpindi 47050, Pakistan.
   [Rehman, Mobeen ur] Air Univ, Dept Avion Engn, Islamabad 44000, Pakistan.
   [Anwar, Syed Muhammad] Univ Engn & Technol Taxila, Dept Software Engn, Rawalpindi 47050, Pakistan.
   [Khurshid, Khawar] Natl Univ Sci & Technol, Sch Elect Engn & Comp Sci, Islamabad 44000, Pakistan.
C3 Air University Islamabad; National University of Sciences & Technology -
   Pakistan
RP Nizami, IF (corresponding author), Bahria Univ, Dept Elect Engn, Islamabad 44000, Pakistan.
EM imran2k2@gmail.com; m.majid@uettaxila.edu.pk; cmobeenrahman@gmail.com;
   s.anwar@uettaxila.edu.pk; ammara.nasim@bui.edu.pk;
   khawar.khurshid@seecs.edu.pk
RI anwar, syed/AGY-3965-2022; Majid, Muhammad/Z-5667-2019; Rehman, Mobeen
   Ur/AAR-2944-2021
OI anwar, syed/0000-0002-8179-3959; Majid, Muhammad/0000-0003-3662-2525;
   Rehman, Mobeen Ur/0000-0003-0914-7132
CR Attar A, 2016, MULTIMED TOOLS APPL, V75, P7407, DOI 10.1007/s11042-015-2663-9
   BANITALEBIDEHKO.M, 2018, MULTIMED TOOLS APPL, P1
   Bermejo P, 2014, KNOWL-BASED SYST, V55, P140, DOI 10.1016/j.knosys.2013.10.016
   Bianco S, 2018, SIGNAL IMAGE VIDEO P, V12, P355, DOI 10.1007/s11760-017-1166-8
   Bosse S, 2016, IEEE IMAGE PROC, P2052, DOI 10.1109/ICIP.2016.7532719
   Bovik AC, 2013, P IEEE, V101, P2008, DOI 10.1109/JPROC.2013.2257632
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Fang YM, 2018, IEEE T IMAGE PROCESS, V27, P1600, DOI 10.1109/TIP.2017.2781307
   Ghadiyaram D, 2017, J VISION, V17, DOI 10.1167/17.1.32
   Golestaneh S, 2016, IEEE T IMAGE PROCESS, V25, P5293, DOI 10.1109/TIP.2016.2601821
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Gütlein M, 2009, 2009 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DATA MINING, P332, DOI 10.1109/CIDM.2009.4938668
   He LH, 2012, PROC CVPR IEEE, P1146, DOI 10.1109/CVPR.2012.6247795
   Huan Liu, 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P319
   Huang Y, 2016, MULTIMED TOOLS APPL, V75, P2769, DOI 10.1007/s11042-015-2620-7
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Jenadeleh M, 2017, MULTIMED TOOLS APPL, V76, P13859, DOI 10.1007/s11042-016-3785-4
   Jiang QP, 2015, J VIS COMMUN IMAGE R, V33, P123, DOI 10.1016/j.jvcir.2015.09.009
   Khan M, 2019, MULTIMED TOOLS APPL, V78, P14485, DOI 10.1007/s11042-018-6797-4
   Khosravi MH, 2017, MULTIMED TOOLS APPL, V76, P2733, DOI 10.1007/s11042-015-3149-5
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li CF, 2011, IEEE T NEURAL NETWOR, V22, P793, DOI 10.1109/TNN.2011.2120620
   Li LD, 2017, IEEE ACCESS, V5, P2163, DOI 10.1109/ACCESS.2017.2661858
   Li QH, 2017, NEUROCOMPUTING, V236, P93, DOI 10.1016/j.neucom.2016.09.105
   Li QH, 2016, IEEE T MULTIMEDIA, V18, P2457, DOI 10.1109/TMM.2016.2601028
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Liu Anan, 2018, MULTIMEDIA TOOLS APP, V78, P1
   Liu LX, 2016, SIGNAL PROCESS-IMAGE, V40, P1, DOI 10.1016/j.image.2015.10.005
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P494, DOI 10.1016/j.image.2014.02.004
   Lu W, 2016, MULTIMED TOOLS APPL, V75, P14417, DOI 10.1007/s11042-016-3519-7
   Lu YA, 2015, IEEE SIGNAL PROC LET, V22, P1811, DOI 10.1109/LSP.2015.2436908
   Ma L, 2016, IEEE T MULTIMEDIA, V18, P2228, DOI 10.1109/TMM.2016.2614187
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk Krystian., 2002, European conference on computer vision, P128
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, CONF REC ASILOMAR C, P1718, DOI 10.1109/ACSSC.2012.6489326
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Nafchi HZ, 2016, IEEE ACCESS, V4, P5579, DOI 10.1109/ACCESS.2016.2604042
   NIZAMI IF, 2017, ARAB J SCI ENG, P1
   Nizami IF, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0392-5
   Nizami IF, 2018, TURK J ELECTR ENG CO, V26, P2163, DOI 10.3906/elk-1804-116
   Nizami IF, 2018, APPL INTELL, V48, P3482, DOI 10.1007/s10489-018-1151-0
   Nizami IF, 2017, INT BHURBAN C APPL S, P318, DOI 10.1109/IBCAST.2017.7868071
   Omari M, 2015, MULTIMED TOOLS APPL, V74, P8685, DOI 10.1007/s11042-014-2353-z
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Rezaie F, 2018, MULTIMED TOOLS APPL, V77, P2529, DOI 10.1007/s11042-017-4432-4
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Saha A, 2016, SIGNAL PROCESS, V128, P186, DOI 10.1016/j.sigpro.2016.03.026
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2005, LIVE IMAGE QUALITY A, DOI DOI 10.1109/CVPR.2015.7298594
   SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8
   Sun TF, 2014, APPL MATH INFORM SCI, V8, P1925, DOI 10.12785/amis/080451
   Tanchenko A, 2014, J VIS COMMUN IMAGE R, V25, P874, DOI 10.1016/j.jvcir.2014.01.008
   Tang LJ, 2016, J VIS COMMUN IMAGE R, V40, P335, DOI 10.1016/j.jvcir.2016.07.007
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WEI D, INT J SIMULATION SYS, V17
   Wen Y, 2017, J VIS COMMUN IMAGE R, V43, P119, DOI 10.1016/j.jvcir.2016.12.005
   WU J, 2017, MULTIMED TOOLS APPL, P1
   Wu JJ, 2016, SIGNAL PROCESS-IMAGE, V47, P16, DOI 10.1016/j.image.2016.05.008
   Wu JJ, 2016, INFORM SCIENCES, V351, P18, DOI 10.1016/j.ins.2016.02.043
   Wu QB, 2018, IEEE T IMAGE PROCESS, V27, P2499, DOI 10.1109/TIP.2018.2799331
   Wu QB, 2017, IEEE T MULTIMEDIA, V19, P2490, DOI 10.1109/TMM.2017.2700206
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Yang XC, 2018, MULTIMED TOOLS APPL, V77, P24185, DOI 10.1007/s11042-018-5740-z
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang M, 2015, IEEE SIGNAL PROC LET, V22, P207, DOI 10.1109/LSP.2014.2326399
   Zhang YZ, 2016, DIGIT SIGNAL PROCESS, V57, P56, DOI 10.1016/j.dsp.2016.05.012
   Zhang Y, 2014, SIGNAL PROCESS-IMAGE, V29, P725, DOI 10.1016/j.image.2014.05.004
NR 74
TC 15
Z9 16
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7811
EP 7836
DI 10.1007/s11042-019-08465-5
EA JAN 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000505356600009
DA 2024-07-18
ER

PT J
AU Hojati, S
   Kazemi, M
   Moallem, P
AF Hojati, Sahar
   Kazemi, Mohammad
   Moallem, Payman
TI Error concealment with parallelogram partitioning of the lost area
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Error concealment; Dynamic programming; Parallelogram partitioning
ID IMAGE QUALITY ASSESSMENT; RECOVERY
AB In this paper, we proposed a video error concealment algorithm using Motion Vector (MV) recovery for parallelogram partitions in the lost area. Error concealment is inevitable when some video packets are lost during transmission and correction or retransmission is not feasible. In conventional methods, MVs are recovered for the square shaped blocks which are then used for motion compensated temporal replacement. But in our proposed method, by parallelogram partitioning of the lost area, the MVs are found for more general shaped blocks. The parallelograms with various sizes and angles are examined, and then the best combination (size and angle) is selected with the assist of a border matching algorithm and a blind quality assessment method. Experimental results show that our method outperforms the other error concealment algorithms, both subjectively and objectively.
C1 [Hojati, Sahar; Kazemi, Mohammad; Moallem, Payman] Univ Isfahan, Dept Elect Engn, Esfahan 8174673441, Iran.
C3 University of Isfahan
RP Kazemi, M (corresponding author), Univ Isfahan, Dept Elect Engn, Esfahan 8174673441, Iran.
EM m.kazemi@eng.ui.ac.ir
RI Kazemi, Mohammad/G-7733-2017
OI Hojati, Sahar/0000-0001-5450-1626
CR Akbari A, 2017, IEEE T MULTIMEDIA, V19, P1339, DOI 10.1109/TMM.2017.2662203
   Bellman R, 1954, B AM MATH SOC
   Byongsu H, 2017, MULTIMED TOOLS APPL, V76, P397, DOI [10.1007/s11042-015-3056-9, DOI 10.1007/S11042-015-3056-9]
   Carreira JFM, 2019, IEEE T BROADCAST, V65, P282, DOI 10.1109/TBC.2018.2865644
   Chang YL, 2013, INT PACK VID WORKSH
   Choe G, 2018, MULTIMED TOOLS APPL, V77, P31953, DOI 10.1007/s11042-018-6184-1
   Chung B, 2020, IEEE T CIRC SYST VID, V30, P1535, DOI 10.1109/TCSVT.2019.2909564
   DUFAUX F, 1995, P IEEE, V83, P858, DOI 10.1109/5.387089
   Huang Z, 2018, IEEE 18 INT C COMM T
   Hwang MC, 2008, IEEE T BROADCAST, V54, P198, DOI 10.1109/TBC.2008.917274
   Lam W. M., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P417, DOI 10.1109/ICASSP.1993.319836
   Li YF, 2017, MULTIMED TOOLS APPL, V76, P14993, DOI 10.1007/s11042-017-4407-5
   Lie WN, 2014, IEEE T MULTIMEDIA, V16, P216, DOI 10.1109/TMM.2013.2281587
   Lin TL, 2017, MULTIMED TOOLS APPL, V76, P397, DOI 10.1007/s11042-015-3056-9
   Lin TL, 2016, J DISP TECHNOL, V12, P1451, DOI 10.1109/JDT.2016.2595640
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Liu XM, 2017, IEEE T IMAGE PROCESS, V26, P782, DOI 10.1109/TIP.2016.2623481
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Oztas B, 2012, IEEE I C ELECT CIRC, P785, DOI 10.1109/ICECS.2012.6463542
   Qian XM, 2009, IEEE T MULTIMEDIA, V11, P683, DOI 10.1109/TMM.2009.2017609
   Radmehr A, 2016, SIGNAL IMAGE VIDEO P, V10, P311, DOI 10.1007/s11760-014-0743-3
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sankisa A, 2018, IEEE IMAGE PROC, P380, DOI 10.1109/ICIP.2018.8451090
   Shih HC, 2018, IEEE ACCESS, V6, P6370, DOI 10.1109/ACCESS.2018.2789862
   Soundararajan R, 2013, IEEE T CIRC SYST VID, V23, P684, DOI 10.1109/TCSVT.2012.2214933
   Suh JW, 2002, IEEE T BROADCAST, V48, P299, DOI 10.1109/TBC.2002.806797
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Usman M, 2015, 2015 PICTURE CODING SYMPOSIUM (PCS) WITH 2015 PACKET VIDEO WORKSHOP (PV), P233, DOI 10.1109/PCS.2015.7170081
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Xiang C, 2019, IEEE INTERNATIONAL C
   Yang SH, 2015, MULTIMED TOOLS APPL, V74, P10785, DOI 10.1007/s11042-014-2206-9
   Zhang J, 2000, IEEE T CIRC SYST VID, V10, P659, DOI 10.1109/76.845011
   Zhang Y., 2012, IEEE Transactions on Circuits and Systems for Video Technology, V22, P12, DOI DOI 10.1109/TCSVT.2011.2130450
   Zhou ZH, 2017, MULTIMED TOOLS APPL, V76, P16045, DOI 10.1007/s11042-016-3894-0
NR 34
TC 6
Z9 6
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7449
EP 7469
DI 10.1007/s11042-019-08538-5
EA DEC 2019
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000504164600007
DA 2024-07-18
ER

PT J
AU Mengarelli, L
   Kostiuk, B
   Vitório, JG
   Tibola, MA
   Wolff, W
   Silla, CN
AF Mengarelli, Luciano
   Kostiuk, Bruno
   Vitorio, Joao G.
   Tibola, Maicon A.
   Wolff, William
   Silla, Carlos N., Jr.
TI OMR metrics and evaluation: a systematic review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE OMR; Metrics; Evaluation; Review; Optical music recognition; Music
   scores; image processing
ID OPTICAL MUSIC RECOGNITION; STAFF REMOVAL; SCORES; MODEL
AB Music is rhythm, timbre, tones, intensity and performance. Conventional Western Music Notation (CWMN) is used to generate Music Scores in order to register music on paper. Optical Music Recognition (OMR) studies techniques and algorithms for converting music scores into a readable format for computers. This work presents a systematic literature review (SLR) searching for metrics and methods of evaluation and comparing for OMR systems and algorithms. The most commonly used metrics on OMR works are described. A research protocol is elaborated and executed. From 802 publications found, 94 are evaluated. All results are organized and classified focusing on metrics, stages, comparisons, OMR datasets and related works. Although there is still no standard methodology for evaluating OMR systems, a good number of datasets and metrics are already available and apply to all the stages of OMR. Some of the analyzed works can give good directions for future works.
C1 [Mengarelli, Luciano; Kostiuk, Bruno; Vitorio, Joao G.; Tibola, Maicon A.; Wolff, William; Silla, Carlos N., Jr.] Pontificia Univ Catolica Parana PUCPR, Polytech Sch, PPGIa, Postgrad Program Comp Sci, Ave Imaculada Conceicao,1155 Prado Velho, BR-80215901 Curitiba, Parana, Brazil.
C3 Pontificia Universidade Catolica do Parana
RP Mengarelli, L (corresponding author), Pontificia Univ Catolica Parana PUCPR, Polytech Sch, PPGIa, Postgrad Program Comp Sci, Ave Imaculada Conceicao,1155 Prado Velho, BR-80215901 Curitiba, Parana, Brazil.
EM luciano.mengarelli@gmail.com; brunokostiuk@hotmail.com;
   joaobracaioli@gmail.com; maicoaugusto@yahoo.com.br; wolff@wdw.com.br;
   carlos.sillajr@gmail.com
RI Silla Jr., Carlos/F-7227-2012
OI Silla Jr., Carlos/0000-0002-1603-9378
FU CAPES (Coordination for the Improvement of Higher Level Personnel); CNPq
   (National Council for Scientific and Technological Development) from the
   Brazilian government; Fundacao Araucaria
FX We would like to thank CAPES (Coordination for the Improvement of Higher
   Level Personnel) and CNPq (National Council for Scientific and
   Technological Development) from the Brazilian government and Fundacao
   Araucaria for their financial support on the project.
CR A. for Computing Machinery, 2017, COMP MACH
   Adamska J, 2015, LECT NOTES COMPUT SC, V9339, P571, DOI 10.1007/978-3-319-24369-6_48
   [Anonymous], MUSESCORE BVBA
   Bainbridge D, 1997, P 6 INT C IM PROC IT
   Baró A, 2016, INT CONF FRONT HAND, P465, DOI [10.1109/ICFHR.2016.116, 10.1109/ICFHR.2016.0092]
   Baumann S., 1995, P 3 INT C DOC AN REC, V2, P1080
   Bellini P, 2007, COMPUT MUSIC J, V31, P68, DOI 10.1162/comj.2007.31.1.68
   Bolan Su, 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P160, DOI 10.1109/DAS.2012.16
   Bosch V, 2016, INT CONF FRONT HAND, P313, DOI [10.1109/ICFHR.2016.0066, 10.1109/ICFHR.2016.61]
   Bruder I, 2004, LECT NOTES COMPUT SC, V3232, P304
   Bugge EP, 2011, P 12 INT SOC MUS INF
   Burgoyne J.A., 2007, P C INT SOC MUSIC IN, P509
   Byrd D., 2006, 7 INT SOC MUSIC INFO, P41
   Byrd D, 2015, J NEW MUSIC RES, V44, P169, DOI 10.1080/09298215.2015.1045424
   Calvo-Zaragoza J, 2017, MACH VISION APPL, V28, P665, DOI 10.1007/s00138-017-0844-4
   Calvo-Zaragoza J, 2017, LECT NOTES COMPUT SC, V10255, P279, DOI 10.1007/978-3-319-58838-4_31
   Calvo-Zaragoza J, 2017, EXPERT SYST APPL, V72, P395, DOI 10.1016/j.eswa.2016.10.041
   Calvo-Zaragoza J, 2016, INT J DOC ANAL RECOG, V19, P211, DOI 10.1007/s10032-016-0266-2
   Calvo-Zaragoza J, 2015, PATTERN ANAL APPL, V18, P933, DOI 10.1007/s10044-014-0415-5
   Cardoso J. S., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1856, DOI 10.1109/ICPR.2010.458
   Chen YS, 2013, INT J PATTERN RECOGN, V27, DOI 10.1142/S0218001413530054
   Cheng LC, 2016, PROCEEDINGS OF CHIUXID 2016: BRIDGING THE GAPS IN THE HCI & UX WORLD, P1, DOI 10.1145/2898459.2898460
   Chin-Shyurng Fahn, 2014, 2014 International Conference on Information Science, Electronics and Electrical Engineering (ISEEE), P1397, DOI 10.1109/InfoSEEE.2014.6946149
   Dalitz C, 2008, IEEE T PATTERN ANAL, V30, P753, DOI [10.1109/TPAMI.2007.70749, 10.1109/TPAM1.2007.70749]
   Dalitz C, 2008, INT J DOC ANAL RECOG, V11, P143, DOI 10.1007/s10032-008-0074-4
   Davis JJ., 2006, PROC INT C MACHINE L, DOI DOI 10.1145/1143844.1143874
   Dinh CM, 2016, IEICE T INF SYST, VE99D, P1576, DOI 10.1587/transinf.2015EDP7296
   Dutta Anjan, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1965, DOI 10.1109/ICPR.2010.484
   Fang Y, 2015, INT J MACH LEARN CYB, V6, P277, DOI 10.1007/s13042-014-0260-2
   Fornes Alicia, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P996, DOI 10.1109/ICDAR.2009.100
   Fornes A., 2005, Graphics Recognition. Ten Years Review and Future Perspectives. 6th International Workshop. GREC 2005. Revised Selected Papers (Lecture Notes in Computer Science Vol. 3926), P279
   Fornes A, 2014, HDB DOCUMENT IMAGE P, P749, DOI DOI 10.1007/978-0-85729-859-1_24
   Fornes A., 2007, Graphics Recognition, V5046, P51
   Fornes A, 2013, GRAPHICS RECOGNITION, P173, DOI [10.1007/978-3-642-36824-017, DOI 10.1007/978-3-642-36824-017]
   Fornés A, 2012, INT J DOC ANAL RECOG, V15, P243, DOI 10.1007/s10032-011-0168-2
   Fornés A, 2013, PROC INT CONF DOC, P200, DOI 10.1109/ICDAR.2013.47
   Fornés A, 2011, PROC INT CONF DOC, P1511, DOI 10.1109/ICDAR.2011.300
   Fornes A, 2005, FRONT ARTIF INTEL AP, V131, P83
   Fornes Alicia, 2013, LNCS, V7423, P173
   Google, 2017, GOOGL SCHOL
   IEEE, 2017, IEEE XPL DIG LIB
   Izmirli Ozgur, 2012, P INT SOC MUS INF RE, P61
   Jastrzebska A, 2016, ADV INTELL SYST COMP, V364, P493, DOI 10.1007/978-3-319-19090-7_37
   Kato H, 1992, STRUCTURED DOCUMENT, P435
   Kitchenham Barbara, 2004, Joint Technical Report, V2004, P1
   Kodirov E, 2014, P 8 INT C UB INF MAN, P50
   Lesinski W, 2015, IFIP INT C COMP INF, P601
   Liu XX, 2015, INT C COMP AID DES C, P212, DOI 10.1109/CADGRAPHICS.2015.34
   Liu XX, 2012, LECT NOTES ARTIF INT, V7197, P263, DOI 10.1007/978-3-642-28490-8_28
   Luangnapa N, 2012, COMM COM INF SC, V344, P106
   Luckner M, 2006, ISDA 2006: Sixth International Conference on Intelligent Systems Design and Applications, Vol 1, P557
   Malik R, 2013, PROC INT CONF DOC, P832, DOI 10.1109/ICDAR.2013.170
   Margner V, 2014, HDB DOCUMENT IMAGE P, P1011
   Mehta AA, 2015, INT C COMP COMM INF, P1
   Miyao H., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P1074, DOI 10.1109/ICDAR.1995.602095
   Modayur B. R., 1993, Machine Vision and Applications, V6, P140, DOI 10.1007/BF01211937
   Montagner ID, 2014, INT C PATT RECOG, P3162, DOI 10.1109/ICPR.2014.545
   Montagner IS, 2017, PATTERN RECOGN, V63, P310, DOI 10.1016/j.patcog.2016.10.002
   Montagner IS, 2014, IEEE IMAGE PROC, P2614, DOI 10.1109/ICIP.2014.7025529
   Na IS, 2017, MULTIMED TOOLS APPL, V76, P25563, DOI 10.1007/s11042-016-4170-z
   Nhat VQ, 2014, P 8 INT C UB INF MAN, P99
   Novotny J., 2015, CEUR Workshop Proceedings, V1343, P65
   Oh J, 2017, INT J DOC ANAL RECOG, V20, P79, DOI 10.1007/s10032-017-0281-y
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Padilla V, 2014, P 1 INT WORKSH DIG L, P1
   Pedersoli F, 2016, INT J DOC ANAL RECOG, V19, P289, DOI 10.1007/s10032-016-0271-5
   Piatkowska W, 2012, LECT NOTES COMPUT SC, V7594, P557, DOI 10.1007/978-3-642-33564-8_67
   Pinheiro Pereira RM, 2016, P 22 BRAZ S MULT WEB, P191
   Pinto H, 1978, INICIACAO AO VIOLAO, V1
   Pinto T, 2011, LECT NOTES COMPUT SC, V6669, P700
   Pugin L, 2008, P INT SOC MUS INF RE
   Pugin L, 2007, LECT NOTES COMPUT SC, V4675, P471
   Pugin L, 2007, ACM-IEEE J CONF DIG, P303, DOI 10.1145/1255175.1255233
   Vo QN, 2016, PATTERN RECOGN LETT, V69, P88, DOI 10.1016/j.patrec.2015.10.017
   Ramirez C., 2010, P C INT SOC MUSIC IN, P549
   Raphael C, 2014, P DOC REC TREIEV DDR
   Raphael C., 2011, 12 INT SOC MUSIC INF, P305, DOI DOI 10.5281/ZENODO.1414856
   Rebelo A, 2010, INT J DOC ANAL RECOG, V13, P19, DOI 10.1007/s10032-009-0100-1
   Rebelo A, 2007, AXMEDIS 2007: THIRD INTERNATIONAL CONFERENCE ON AUTOMATED PRODUCTION OF CROSS MEDIA CONTENT FOR MULTI-CHANNEL DISTRIBUTION, PROCEEDINGS, P79, DOI 10.1109/AXMEDIS.2007.16
   Rebelo A, 2012, INT J MULTIMED INF R, V1, P173, DOI 10.1007/s13735-012-0004-6
   Rebelo A, 2013, LECT NOTES COMPUT SC, V7950, P734, DOI 10.1007/978-3-642-39094-4_84
   Riba P, 2015, INT WORKSH GRAPH REC, P103
   Rossant F, 2004, FUZZY SET SYST, V141, P165, DOI 10.1016/S0165-0114(03)00094-0
   Rossant F., 2005, P IEEE INT C IM PROC, V2, P538
   Rossant F., 2007, EURASIP J ADV SIG PR, V2007, P160
   Schmucker M, 2002, SECOND INTERNATIONAL CONFERENCE ON WEB DELIVERING OF MUSIC, PROCEEDINGS, P168, DOI 10.1109/WDM.2002.1176208
   Sharif M, 2009, P 7 INT C FRONT INF, P34
   Su MC, 2001, JOINT 9TH IFSA WORLD CONGRESS AND 20TH NAFIPS INTERNATIONAL CONFERENCE, PROCEEDINGS, VOLS. 1-5, P2150, DOI 10.1109/NAFIPS.2001.944402
   Szwoch M, 2005, LECT NOTES COMPUT SC, V3691, P701
   Szwoch M, 2008, LECT NOTES ARTIF INT, V5223, P419, DOI 10.1007/978-3-540-87730-1_53
   Tambouratzis T, 2013, INT J INTELL SYST, V28, P474, DOI 10.1002/int.21586
   Tambouratzis T, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P1935, DOI 10.1109/IJCNN.2011.6033461
   Thomas V, 2011, P INT SOC MUS INF RE, P411
   Timofte R, 2012, P AS C COMP VIS, P510
   Todd Reed K., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P803, DOI 10.1109/ICPR.1996.547279
   Viera AJ, 2005, FAM MED, V37, P360
   Vigliensoni G, 2011, P INT SOC MUS INF RE
   Visani M, 2013, PROC INT CONF DOC, P1407, DOI 10.1109/ICDAR.2013.284
   Wen CH, 2015, PATTERN RECOGN LETT, V58, P1, DOI 10.1016/j.patrec.2015.02.002
   Wijaya K, 1999, P 7 INT C IM PROC IT
   Wu F, 2014, 2014 IEEE PES AS PAC, P1, DOI DOI 10.1109/APPEEC.2014.7066173
   Wu F, 2014, P INT C INT MULT COM, P241
   Wu FHF, 2016, IEEE INT SYM MULTIM, P626, DOI [10.1109/ISM.2016.0134, 10.1109/ISM.2016.48]
   YadidPecht O, 1996, MACH VISION APPL, V9, P65
   Yoo J, 2008, IEEE INT SYMP SIGNAL, P223, DOI 10.1109/ISSPIT.2008.4775718
NR 105
TC 3
Z9 3
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6383
EP 6408
DI 10.1007/s11042-019-08200-0
EA DEC 2019
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000510371500001
DA 2024-07-18
ER

PT J
AU Boussif, M
   Aloui, N
   Cherif, A
AF Boussif, Mohamed
   Aloui, Noureddine
   Cherif, Adnene
TI Images encryption algorithm based on the quaternion multiplication and
   the XOR operation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Security; Images processing; Encryption; Quaternion multiplication; XOR
ID CHAOS; SCHEME
AB In this paper, we propose an images encryption algorithm based on the quaternion multiplication and the XOR function. The proposed algorithm processes the image in 32 quaternions i.e. block of 32 x 4. For each quaternion, the algorithm exor the ith image quaternion and the ith key quaternion. The key quaternion is changed in each block using the quaternion multiplication. The randomness of the proposed algorithm is evaluated by diehard package. Several other analyses are provided to evaluate the performances of this encryption scheme. These analyses demonstrate that the proposed algorithm is with high security level and fast run speed and can be competitive with some other recently proposed image encryption schemes.
C1 [Boussif, Mohamed; Cherif, Adnene] Univ Tunis El Manar, Lab Anal & Proc Elect & Energy Syst, Fac Sci Tunis, Dept Phys, El Manar 2092, PB, Tunisia.
   [Aloui, Noureddine] Sousse Technol Pk, Ctr Res Microelect & Nanotechnol, Sousse, Tunisia.
C3 Universite de Tunis-El-Manar; Faculte des Sciences de Tunis (FST);
   Centre de Recherche en Microelectronique et Nanotechnologie
RP Boussif, M (corresponding author), Univ Tunis El Manar, Lab Anal & Proc Elect & Energy Syst, Fac Sci Tunis, Dept Phys, El Manar 2092, PB, Tunisia.
EM boussifmohamed1989@gmail.com
RI cherif, Adnen/AAP-1112-2020; cherif, adnen/A-4366-2018
OI Boussif, Mohamed/0000-0003-3198-7605; cherif, adnen/0000-0003-2116-5763
CR Abanda Y, 2016, IET IMAGE PROCESS, V10, P742, DOI 10.1049/iet-ipr.2015.0244
   Aslam MN, 2019, IEEE ACCESS, V7, P66395, DOI 10.1109/ACCESS.2019.2911559
   Çavusoglu Ü, 2017, CHAOS SOLITON FRACT, V95, P92, DOI 10.1016/j.chaos.2016.12.018
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Chen H, 2018, OPT LASER ENG, V107, P62, DOI 10.1016/j.optlaseng.2018.03.011
   Chen JX, 2018, OPT LASER TECHNOL, V99, P238, DOI 10.1016/j.optlastec.2017.09.008
   DZWONKOWSKI M, 2013, TELECOM OVERV TELECO, V8, P2
   Dzwonkowski M, 2015, IEEE T IMAGE PROCESS, V24, P4614, DOI 10.1109/TIP.2015.2467317
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   Gan ZH, 2018, MULTIMED TOOLS APPL, V77, P27919, DOI 10.1007/s11042-018-5974-9
   Gao ZG, 2018, IET IMAGE PROCESS, V12, P472, DOI 10.1049/iet-ipr.2017.0383
   Laiphrakpam DS, 2018, MULTIMED TOOLS APPL, P1
   Li PY, 2017, J VIS COMMUN IMAGE R, V44, P61, DOI 10.1016/j.jvcir.2017.01.021
   Lin ZH, 2019, MULTIMED TOOLS APPL, V78, P20511, DOI 10.1007/s11042-018-6824-5
   Liu HJ, 2017, IET IMAGE PROCESS, V11, P324, DOI 10.1049/iet-ipr.2016.0040
   Liu J, 2017, OPT COMMUN, V396, P174, DOI 10.1016/j.optcom.2017.03.049
   Mostafa S, 2017, 2017 6 INT C INF EL
   Mozaffari S, 2018, MULTIMED TOOLS APPL, V77, P25799, DOI 10.1007/s11042-018-5817-8
   Norouzi B, 2015, MULTIMED TOOLS APPL, V74, P781, DOI 10.1007/s11042-013-1699-y
   Özkaynak F, 2016, OPTIK, V127, P5190, DOI 10.1016/j.ijleo.2016.03.018
   Ping P, 2018, SIGNAL PROCESS, V150, P233, DOI 10.1016/j.sigpro.2018.04.018
   Ping P, 2018, NEUROCOMPUTING, V283, P53, DOI 10.1016/j.neucom.2017.12.048
   Shukla P, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIONS IN INFORMATION, EMBEDDED AND COMMUNICATION SYSTEMS (ICIIECS)
   Silva-García VM, 2018, APPL MATH COMPUT, V332, P123, DOI 10.1016/j.amc.2018.03.019
   Tao R, 2010, IEEE T INF FOREN SEC, V5, P734, DOI 10.1109/TIFS.2010.2068289
   Wadi SM, 2015, IET IMAGE PROCESS, V9, P413, DOI 10.1049/iet-ipr.2014.0514
   Wang HL, 2019, MOBILE NETW APPL, V24, P1947, DOI 10.1007/s11036-019-01336-1
   XIANYE L, 2018, OPT LASER ENG, V102, P106
   Yavuz E, 2016, COMPUT ELECTR ENG, V54, P471, DOI 10.1016/j.compeleceng.2015.11.008
   Zhang XQ, 2017, COMPUT ELECTR ENG, V62, P401, DOI 10.1016/j.compeleceng.2016.12.025
   Zhang XQ, 2017, OPT LASER ENG, V92, P6, DOI 10.1016/j.optlaseng.2016.12.005
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zhu SQ, 2018, MULTIMED TOOLS APPL, V77, P29119, DOI 10.1007/s11042-018-6078-2
NR 33
TC 10
Z9 10
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35493
EP 35510
DI 10.1007/s11042-019-08108-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800056
DA 2024-07-18
ER

PT J
AU Enginoglu, S
   Erkan, U
   Memis, S
AF Enginoglu, Serdar
   Erkan, Ugur
   Memis, Samet
TI Pixel similarity-based adaptive Riesz mean filter for salt-and-pepper
   noise removal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salt-and-pepper noise; Non-linear functions; Noise removal; Matrix
   algebra; Image denoising; Riesz mean
ID SWITCHING MEDIAN FILTER; ALGORITHM; DENSITY
AB In this study, we propose a new method, i.e. Adaptive Riesz Mean Filter (ARmF), by operationalizing pixel similarity for salt-and-pepper noise (SPN) removal. Afterwards, we compare the results of ARmF, A New Adaptive Weighted Mean Filter (AWMF), Different Applied Median Filter (DAMF), Noise Adaptive Fuzzy Switching Median Filter (NAFSMF), Based on Pixel Density Filter (BPDF), Modified Decision-Based Unsymmetric Trimmed Median Filter (MDBUTMF) and Decision-Based Algorithm (DBA) by using Peak Signal-to-Noise Ratio (PSNR), Structural Similarity (SSIM), Image Enhancement Factor (IEF), and Visual Information Fidelity (VIF) for 20 traditional test images (Lena, Cameraman, Barbara, Baboon, Peppers, Living Room, Lake, Plane, Hill, Pirate, Boat, House, Bridge, Elaine, Flintstones, Flower, Parrot, Dark-Haired Woman, Blonde Woman, and Einstein), 40 test images in the TESTIMAGES Database, and 200 RGB test images from the UC Berkeley Dataset ranging in noise density from 10% to 90%. Moreover, we compare the running time of these algorithms. These results show that ARmF outperforms the methods mentioned above. We finally discuss the need for further research.
C1 [Enginoglu, Serdar; Memis, Samet] Canakkale Onsekiz Mart Univ, Fac Arts & Sci, Dept Math, TR-17100 Canakkale, Turkey.
   [Erkan, Ugur] Karamanoglu Mehmetbey Univ, Fac Engn, Dept Comp Engn, TR-70100 Karaman, Turkey.
C3 Canakkale Onsekiz Mart University; Karamanoglu Mehmetbey University
RP Enginoglu, S (corresponding author), Canakkale Onsekiz Mart Univ, Fac Arts & Sci, Dept Math, TR-17100 Canakkale, Turkey.
EM serdarenginoglu@gmail.com
RI Memiş, Samet/AAA-6139-2020; Enginoğlu, Serdar/K-1181-2012; Erkan,
   Ugur/ABH-7309-2020
OI Memiş, Samet/0000-0002-0958-5872; Enginoğlu, Serdar/0000-0002-7188-9893;
   Erkan, Ugur/0000-0002-2481-0230
FU Office of Scientific Research Projects Coordination at Canakkale Onsekiz
   Mart University [FHD-2018-1409]
FX This work was supported by the Office of Scientific Research Projects
   Coordination at Canakkale Onsekiz Mart University, Grant number:
   FHD-2018-1409.
CR [Anonymous], 2014, P EUR IT CHAPT C
   Bai T, 2014, SIGNAL PROCESS, V102, P247, DOI 10.1016/j.sigpro.2014.03.023
   Chen CLP, 2015, IEEE T IMAGE PROCESS, V24, P4014, DOI 10.1109/TIP.2015.2456432
   Chen JY, 2018, IET IMAGE PROCESS, V12, P863, DOI 10.1049/iet-ipr.2017.0910
   Chen QQ, 2017, IET IMAGE PROCESS, V11, P709, DOI 10.1049/iet-ipr.2016.0692
   Deng XY, 2016, PATTERN RECOGN LETT, V79, P8, DOI 10.1016/j.patrec.2016.04.019
   Enginoglu S, 2015, 4 INT FUZZ SYST S 5, P416
   Erkan U, 2018, COMPUT ELECTR ENG, V70, P789, DOI 10.1016/j.compeleceng.2018.01.019
   Erkan U, 2018, TURK J ELECTR ENG CO, V26, P162, DOI 10.3906/elk-1705-256
   Erkan U, 2016, SCIENCEASIA, V42, P28, DOI 10.2306/scienceasia1513-1874.2016.42.028
   ESAKKIRAJAN S, 2012, 2012 INT C INF EL VI, V18, P565, DOI DOI 10.1109/ICIEV.2012.6317448
   Filipovic M, 2014, EUR SIGNAL PR CONF, P1637
   González-Hidalgo M, 2018, APPL SOFT COMPUT, V63, P167, DOI 10.1016/j.asoc.2017.11.030
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Li YY, 2008, APPL SOFT COMPUT, V8, P872, DOI 10.1016/j.asoc.2007.07.006
   Lu CT, 2016, PATTERN RECOGN LETT, V80, P188, DOI 10.1016/j.patrec.2016.06.026
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Nair MS, 2011, COMPUT ELECTR ENG, V37, P644, DOI 10.1016/j.compeleceng.2011.06.001
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Pratt WK, 1975, SEMIANNUAL TECHNICAL
   Roy A, 2016, SIGNAL PROCESS, V128, P262, DOI 10.1016/j.sigpro.2016.04.007
   Russ J.C., 2008, Introduction to image processing and analysis
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   Tang ZY, 2016, PROC SPIE, V10033, DOI 10.1117/12.2243838
   Toh KKV, 2010, IEEE SIGNAL PROC LET, V17, P281, DOI 10.1109/LSP.2009.2038769
   Tukey J.W., 1977, EXPLORATORY DATA ANA, V2
   Varatharajan R, 2018, COMPUT ELECTR ENG, V70, P447, DOI 10.1016/j.compeleceng.2017.05.035
   Wang GH, 2010, SIGNAL PROCESS, V90, P3213, DOI 10.1016/j.sigpro.2010.05.026
   Wang SS, 2013, SIGNAL PROCESS, V93, P2696, DOI 10.1016/j.sigpro.2013.03.005
   Wang Y, 2016, IEEE SIGNAL PROC LET, V23, P1582, DOI 10.1109/LSP.2016.2607785
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang Z, 2018, SIGNAL PROCESS, V147, P173, DOI 10.1016/j.sigpro.2018.01.027
NR 33
TC 35
Z9 36
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35401
EP 35418
DI 10.1007/s11042-019-08110-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800052
DA 2024-07-18
ER

PT J
AU Mohapatra, D
   Patra, MR
AF Mohapatra, Debasis
   Patra, Manas Ranjan
TI LBS based framework to obstruct linking attack in data releases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data privacy; Anonymization; Local beamsearch; Privacy; Utility
ID K-ANONYMITY; PRIVACY
AB Big data repository is a myriad collection of data that needs enormous processing for data analysis to extract interesting patterns. It involves third party to do the data analysis that endangers the privacy of the data. Hence, along with efficient real time analysis of data, privacy of the data also needs a careful attention. In this paper, we discuss the problem of linking attack in the data releases. We show the attack due to the linking of social media data with relational sensitive database discloses the sensitive information about a social entity. Though the data releases don't contain Identifiers (IDs) information like Name, Social Security Number (SSN), etc., linking attack is still possible through the combination of background knowledge with Quasi-Identifiers (QIDs) information like age, sex, etc. The solution encourages the release of anonymized relational sensitive database that obstruct the linking with other databases like social media data. Anonymization is a way to transform the original data to an anonymized version, such that the linkage between the sensitive information of an entity is dissociated from his/her identity. Most of the anonymity models are based on the concept of k-anonymity and l-diversity. In this paper, we present an extensive study on Greedy based heuristics. We propose Local Beam Search (LBS) based global generalization approach to achieve k-anonymity with l-diversity. The experimental evaluation confirms that the proposed method outperforms the existing Greedy based heuristics. The proposed method guarantees a faster convergence than existing Greedy based heuristics. Also, the proposed method performs better than the existing (t, k) Hypergraph Anonymization.
C1 [Mohapatra, Debasis] Parala Maharaja Engn Coll, Brahmapur 761003, Odisha, India.
   [Patra, Manas Ranjan] Berhampur Univ, Brahmapur 760007, Odisha, India.
C3 Berhampur University
RP Mohapatra, D (corresponding author), Parala Maharaja Engn Coll, Brahmapur 761003, Odisha, India.
EM devdisha@gmail.com; mrpatra12@gmail.com
CR [Anonymous], 2010, P 2010 ACM SIGMOD IN
   Asayesh A, 2015, SECUR COMMUN NETW, V8, P1306, DOI 10.1002/sec.1084
   Babu KS, 2013, TRANS DATA PRIV, V6, P1
   Casas-Roma J, 2017, KNOWL INF SYST, V50, P447, DOI 10.1007/s10115-016-0947-7
   El Emam K, 2009, J AM MED INFORM ASSN, V16, P670, DOI 10.1197/jamia.M3144
   Fung Benjamin C. M., 2010, Introduction to Privacy-Preserving Data Publishing: Concepts and Techniques
   Goldberger J, 2010, TRANS DATA PRIV, V3, P149
   Jang SB, 2017, MULTIMED TOOLS APPL, V76, P17855, DOI 10.1007/s11042-015-3123-2
   Khoshgoftaar TM, 2006, TWELFTH ISSAT INTERNATIONAL CONFERENCE RELIABILITY AND QUALITY IN DESIGN, PROCEEDINGS, P139
   Lee H, 2017, BMC MED INFORM DECIS, V17, DOI 10.1186/s12911-017-0499-0
   LeFevre K., 2006, P 22 INT C DAT ENG I, P25, DOI DOI 10.1109/ICDE.2006.101
   LeFevre Kristen., 2005, Incognito: Efficient full-domain k-anonymity
   Li HN, 2017, IEEE MULTIMEDIA, V24, P14
   Li N, 2007, INT CONF NANO MICRO, P692, DOI 10.1109/icde.2007.367856
   Li T., 2012, TKDE, V24, P561
   Machanavajjhala A, 2007, ACM T KNOWL DISCOV D, V1, P1, DOI DOI 10.1145/1217299.1217302
   Murakami K, 2017, INT J INF SECUR
   Russell Stuart, 2008, ARTIF INTELL, P115
   Samarati P, 2001, IEEE T KNOWL DATA EN, V13, P1010, DOI 10.1109/69.971193
   Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648
   Sweeney L, 1997, COMPUTATIONAL DISCLO
   Thuraisingham B, 2007, MULTIMED TOOLS APPL, V33, P13, DOI 10.1007/s11042-006-0096-1
   Wong R.C., 2006, ACM SIGKDD INT C KNO
NR 23
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33805
EP 33835
DI 10.1007/s11042-019-08068-0
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600055
DA 2024-07-18
ER

PT J
AU Majumder, A
   Babu, RV
   Chakraborty, A
AF Majumder, Avishek
   Babu, R. Venkatesh
   Chakraborty, Anirban
TI PerSeg : segmenting salient objects from bag of single image
   perturbations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Segmentation; Salient object detection; Convolutional neural networks;
   Gated recurrent units; Feature aggregation; Image segmentation; Video
   segmentation
ID MODEL
AB Salient object segmentation is an important computer vision problem having applications in numerous areas such as video surveillance, scene parsing, autonomous navigation etc. For images, this task is quite challenging due to clutter/texture present in the background, low resolution and/or low contrast of the object(s) of interest etc. In case of videos, additional issues such as object deformation, camera motion and presence of multiple moving objects make the foreground object segmentation a significantly difficult and open problem. However, motion pattern can also act as an important cue to identify the foreground objects against the background. This is exploited by the recent approaches via aggregation of temporally perturbed information from a series of consecutive frames. Unfortunately for images, this additional cue is not available. In this paper, we propose to emulate the effect of such perturbations by constructing a bag of multiple augmentations applied on a single input image. Saliency features are estimated independently from each perturbed image in this bag, which are further combined using a novel aggregation strategy based on a convolutional gated recurrent encoder-decoder unit. Through extensive experiments on the benchmark datasets, we show better or very competitive performance when compared with the state-of-the-art methods. We further observe that even with a bag constructed using simple affine transformations, we achieve impressive performances, proving the robustness of the proposed framework.
C1 [Majumder, Avishek] Indian Inst Sci, Bengaluru 560012, India.
   [Babu, R. Venkatesh; Chakraborty, Anirban] Indian Inst Sci, Dept Computat & Data Sci, Bengaluru 560012, India.
C3 Indian Institute of Science (IISC) - Bangalore; Indian Institute of
   Science (IISC) - Bangalore
RP Majumder, A (corresponding author), Indian Inst Sci, Bengaluru 560012, India.
EM avishekm@iisc.ac.in; venky@iisc.ac.in; anirban@iisc.ac.in
RI Radhakrishnan, Venkatesh Babu/D-5313-2009
OI Radhakrishnan, Venkatesh Babu/0000-0002-1926-1804
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], P IEEE C COMP VIS PA
   Baradel F, 2018, PROC CVPR IEEE, P469, DOI 10.1109/CVPR.2018.00056
   Batra D, 2010, PROC CVPR IEEE, P3169, DOI 10.1109/CVPR.2010.5540080
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Cheng JC, 2017, IEEE I CONF COMP VIS, P686, DOI 10.1109/ICCV.2017.81
   Cheng MM, 2017, J COMPUT SCI TECH-CH, V32, P110, DOI 10.1007/s11390-017-1681-7
   Cheng MM, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778820
   Craye C, 2016, IEEE INT CONF ROBOT, P2303, DOI 10.1109/ICRA.2016.7487379
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Everingham M, 2012, PASCAL VISUAL OBJECT
   Faktor Alon, 2014, BMVC
   Gao D., 2005, P ADV NEUR INF PROC, P481
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   He JF, 2012, PROC CVPR IEEE, P3005, DOI 10.1109/CVPR.2012.6248030
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Jain SD, 2017, PROC CVPR IEEE, P2117, DOI 10.1109/CVPR.2017.228
   Jampani V, 2017, PROC CVPR IEEE, P3154, DOI 10.1109/CVPR.2017.336
   Jang WD, 2017, PROC CVPR IEEE, P7474, DOI 10.1109/CVPR.2017.790
   JIANG M, 2015, PROC CVPR IEEE, P1072, DOI DOI 10.1109/CVPR.2015.7298710
   Keuper M, 2015, IEEE I CONF COMP VIS, P3271, DOI 10.1109/ICCV.2015.374
   Koh YJ, 2017, PROC CVPR IEEE, P7417, DOI 10.1109/CVPR.2017.784
   KRAHENBUHL P, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kruthiventi SSS, 2016, PROC CVPR IEEE, P5781, DOI 10.1109/CVPR.2016.623
   Kuen J, 2016, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2016.399
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Liu N, 2015, PROC CVPR IEEE, P362, DOI 10.1109/CVPR.2015.7298633
   Luo ZM, 2017, PROC CVPR IEEE, P6593, DOI 10.1109/CVPR.2017.698
   Märki N, 2016, PROC CVPR IEEE, P743, DOI 10.1109/CVPR.2016.87
   Pan JT, 2016, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2016.71
   Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Perazzi F, 2017, PROC CVPR IEEE, P3491, DOI 10.1109/CVPR.2017.372
   Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Setlur Vidya., 2005, MUM, V154, P59, DOI DOI 10.1145/1149488.1149499
   Simonyan K., 2014, CORR
   Tokmakov P, 2017, PROC CVPR IEEE, P531, DOI 10.1109/CVPR.2017.64
   Tsai YH, 2016, PROC CVPR IEEE, P3899, DOI 10.1109/CVPR.2016.423
   Voigtlaender P., 2017, BMVC, P1000
   Wang L, 2018, IEEE IPCCC
   WANG Q, 2016, IEEE T NEUR NET LEAR, V27, P1279, DOI DOI 10.1109/TNNLS.2015.2477537
   Wang Q, 2019, IEEE T IMAGE PROCESS, V28, P4376, DOI 10.1109/TIP.2019.2910667
   Wang TT, 2017, IEEE I CONF COMP VIS, P4039, DOI 10.1109/ICCV.2017.433
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Yu J, 2017, IEEE T INF FOREN SEC, V12, P1005, DOI 10.1109/TIFS.2016.2636090
   Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31
   Zhao Q., 2018, M2det: A single-shot object detector based on multi-level feature pyramid network
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
NR 60
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2473
EP 2493
DI 10.1007/s11042-019-08388-1
EA NOV 2019
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000498031400002
DA 2024-07-18
ER

PT J
AU Ferreira, FABS
   Lima, JB
AF Ferreira, Felipe A. B. S.
   Lima, Juliano B.
TI A robust 3D point cloud watermarking method based on the graph Fourier
   transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Point cloud; 3D models; Graph signal processing; Graph
   Fourier transform
ID BLIND WATERMARKING; LIDAR; ALGORITHM
AB Many modern applications make use of 3D modeling and / or reconstruction of complex objects, such as historical monuments and entire urban centers. One of the most common representations of these 3D models is by point clouds, which are a dense set of points irregularly organized in a 3D coordinate system. Usually, the acquisition methods are highly expensive due to the necessary equipment and size of these models. This factor motivates the proposal of watermarking techniques to guarantee the copyright protection as well as to detect illegal copies. This paper presents a non-blind watermarking method for 3D point clouds. The method is based on the graph Fourier transform, a recently introduced signal processing tool which has been applied to signals lying over arbitrarily irregular domains. Unlike other published works regarding point cloud watermarking, instead of inserting the bit sequence in the models' spatial coordinates, in this work the bits are embedded in the color information attributed in each point of a cloud. Simulation results show high imperceptibility and robustness against several attacks, such as affine transformations, reordering, noise addition and cropping.
C1 [Ferreira, Felipe A. B. S.; Lima, Juliano B.] Univ Fed Pernambuco, Dept Elect & Syst, Recife, PE, Brazil.
C3 Universidade Federal de Pernambuco
RP Lima, JB (corresponding author), Univ Fed Pernambuco, Dept Elect & Syst, Recife, PE, Brazil.
EM felipe.bsferreira@ufpe.br; juliano_bandeira@ieee.org
RI B. S. Ferreira, Felipe A./ABG-6034-2021; Lima, Juliano/D-8770-2014
OI B. S. Ferreira, Felipe A./0000-0003-0105-3721; Lima,
   Juliano/0000-0002-1474-1147
FU Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPq)
   [309598/2017-6, 409543/2018-7]; Fundacao de Amparo a Ciencia e
   Tecnologia do Estado de Pernambuco (FACEPE) [IBPG-1275-3.04/16]
FX This work was supported in part by Conselho Nacional de Desenvolvimento
   Cientifico e Tecnologico (CNPq) under Grants 309598/2017-6 and
   409543/2018-7, and by Fundacao de Amparo a Ciencia e Tecnologia do
   Estado de Pernambuco (FACEPE) under Grant IBPG-1275-3.04/16.
CR Agarwal P, 2009, IEEE T INF FOREN SEC, V4, P36, DOI 10.1109/TIFS.2008.2011081
   Alface Patrice Rondao, 2007, Transactions on Data Hiding and Multimedia Security II. (Lecture Notes in Computer Science vol. 4499), P91
   Asikuzzaman M, 2018, IEEE T CIRC SYST VID, V28, P2131, DOI 10.1109/TCSVT.2017.2712162
   Asikuzzaman M, 2016, IEEE T MULTIMEDIA, V18, P1733, DOI 10.1109/TMM.2016.2589208
   Bhowmik D, 2016, IEEE ACCESS, V4, P8002, DOI 10.1109/ACCESS.2016.2627241
   Bors AG, 2013, IEEE T IMAGE PROCESS, V22, P1822, DOI 10.1109/TIP.2012.2236345
   Cai ZP, 2019, ISPRS J PHOTOGRAMM, V147, P118, DOI 10.1016/j.isprsjprs.2018.11.016
   Chan HT, 2015, J DISP TECHNOL, V11, P193, DOI 10.1109/JDT.2014.2367528
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chen SH, 2015, IEEE T SIGNAL PROCES, V63, P6510, DOI 10.1109/TSP.2015.2469645
   Cheng CJ, 2014, J DISP TECHNOL, V10, P263, DOI 10.1109/JDT.2013.2295619
   Cotting D, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P233, DOI 10.1109/SMI.2004.1314510
   Cox IJ., 2007, DIGITAL WATERMARKING
   Fedorenko R, 2018, 2018 3RD IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION ENGINEERING (ICITE), P253, DOI 10.1109/ICITE.2018.8492584
   Feng XQ, 2015, PROCEEDINGS OF 2015 4TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT 2015), P1449, DOI 10.1109/ICCSNT.2015.7491001
   Garg H, 2013, INT CONF CONTEMP, P313, DOI 10.1109/IC3.2013.6612211
   Golubski AJ, 2016, TRENDS ECOL EVOL, V31, P344, DOI 10.1016/j.tree.2016.02.006
   Huang C.C., 2013, INT C IND ENG OTH AP, P566
   Itier V, 2017, MULTIMED TOOLS APPL, V76, P26421, DOI 10.1007/s11042-016-4163-y
   Jain RK, 2014, IEEE SIGNAL PROC MAG, V31, P130, DOI 10.1109/MSP.2014.2330357
   Karni Z, 2000, COMP GRAPH, P279, DOI 10.1145/344779.344924
   Klyuzhin IS, 2017, IEEE T MED IMAGING, V36, P1263, DOI 10.1109/TMI.2017.2675989
   Koz A, 2008, SIGNALS COMMUN TECHN, P427, DOI 10.1007/978-3-540-72532-9_12
   Lie WN, 2006, IEEE T INF FOREN SEC, V1, P330, DOI 10.1109/TIFS.2006.879297
   Liu J, 2018, LECT NOTES COMPUT SC, V10790, P56, DOI 10.1007/978-3-662-56689-3_5
   Liu Y, 2012, IEEE T INF FOREN SEC, V7, P1459, DOI 10.1109/TIFS.2012.2204251
   Luo H, 2006, 2006 IEEE International Symposium on Signal Processing and Information Technology, Vols 1 and 2, P863, DOI 10.1109/ISSPIT.2006.270919
   Luo M, 2011, IEEE T IMAGE PROCESS, V20, P2813, DOI 10.1109/TIP.2011.2142004
   Mei J, 2017, IEEE T SIGNAL PROCES, V65, P2077, DOI 10.1109/TSP.2016.2634543
   Mekarsari Yudit Arum, 2018, 2018 International Conference on Information and Communications Technology (ICOIACT), P623, DOI 10.1109/ICOIACT.2018.8350793
   Meyer M., 2002, VISUALIZATION MATH, V6, P35, DOI DOI 10.1007/978-3-662-05105-4_2
   Nocerino E, 2016, INT ARCH PHOTOGRAMM, V41, P99, DOI 10.5194/isprsarchives-XLI-B5-99-2016
   Ohbuchi R, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P392, DOI 10.1109/CW.2004.70
   Ortega A, 2018, P IEEE, V106, P808, DOI 10.1109/JPROC.2018.2820126
   Qi K, 2010, 2010 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, NETWORKING AND INFORMATION SECURITY (WCNIS), VOL 1, P287, DOI 10.1109/WCINS.2010.5541785
   Ribeiro G., 2018, J COMMUN INF SYST, V33
   Rolland-Neviere Xavier, 2014, IEEE Transactions on Information Forensics and Security, V9, P1491, DOI 10.1109/TIFS.2014.2336376
   Sandryhaila A, 2014, IEEE SIGNAL PROC MAG, V31, P80, DOI 10.1109/MSP.2014.2329213
   Sandryhaila A, 2014, IEEE T SIGNAL PROCES, V62, P3042, DOI 10.1109/TSP.2014.2321121
   Shao J, 2018, J CULTURAL HERITAGE
   Shuman DI, 2013, IEEE SIGNAL PROC MAG, V30, P83, DOI 10.1109/MSP.2012.2235192
   Shuman DI, 2012, 2012 IEEE STATISTICAL SIGNAL PROCESSING WORKSHOP (SSP), P133, DOI 10.1109/SSP.2012.6319640
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Toschi I, 2017, INT ARCH PHOTOGRAMM, V42-1, P519, DOI 10.5194/isprs-archives-XLII-1-W1-519-2017
   Tsai YY, 2016, MULTIMED TOOLS APPL, V75, P7891, DOI 10.1007/s11042-015-2707-1
   Wang CT, 2012, IEEE T INF FOREN SEC, V7, P853, DOI 10.1109/TIFS.2012.2188797
   Wang CM, 2005, IEICE T COMMUN, VE88B, P190, DOI 10.1093/ietcom/E88-B.1.190
   Wang H, 2017, ROBOT AUTON SYST, V88, P71, DOI 10.1016/j.robot.2016.11.014
   Wang J, 2018, COMPUT AIDED DESIGN, V94, P1, DOI 10.1016/j.cad.2017.09.001
   Yang Y, 2017, IEEE T VIS COMPUT GR, V23, P1002, DOI 10.1109/TVCG.2016.2525771
   Zeng YM, 2018, IEEE ROBOT AUTOM LET, V3, P3434, DOI 10.1109/LRA.2018.2852843
NR 51
TC 13
Z9 14
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 1921
EP 1950
DI 10.1007/s11042-019-08296-4
EA NOV 2019
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000496214300001
DA 2024-07-18
ER

PT J
AU Singh, A
   Singh, J
AF Singh, Amanjot
   Singh, Jagroop
TI Survey on Single Image based Super-resolution - <i>Implementation
   Challenges and Solutions</i>
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; Low-resolution (LR); High-resolution(HR)
ID EFFICIENT SUPERRESOLUTION; SUPER RESOLUTION; IMPULSE NOISE; DIGITAL
   IMAGES; MAP APPROACH; INTERPOLATION; ROBUST; SEGMENTATION; REGISTRATION;
   CLASSIFICATION
AB Super-resolution includes the techniques which deal with the methods of converting the low-resolution image into the high-resolution image. In this paper, various challenges affecting the implementation of Super-Resolution (SR) along with the detailed survey of SR implementation methods have been presented. Different issues related to the SR have been explored from literature which are limiting the SR implementations. Besides, there are also various techniques to implement the SR, detailed survey of these techniques along with comparison, have been included in this paper. In this work main focus has been given to a single image based super-resolution as it is the more practical type of super-resolution. The basic purpose of the paper is exploring the various possibilities of SR along with practical constraints.
C1 [Singh, Amanjot] IKG PTU, Jalandhar 144603, Punjab, India.
   [Singh, Amanjot] Lovely Profess Univ, Sch Elect & Elect Engn, Phagwara 144411, Punjab, India.
   [Singh, Jagroop] DAVIET, Dept Elect & Commun Engn, Jalandhar 144008, Punjab, India.
C3 I. K. Gujral Punjab Technical University; Lovely Professional
   University; DAV Institute of Engineering & Technology
RP Singh, A (corresponding author), IKG PTU, Jalandhar 144603, Punjab, India.; Singh, A (corresponding author), Lovely Profess Univ, Sch Elect & Elect Engn, Phagwara 144411, Punjab, India.
EM er.ajotsingh@gmail.com; roopasidhu@yahoo.com
OI singh, Jagroop/0000-0002-2090-2891
CR Acharya M, 2007, BMC MOL BIOL, V8, DOI 10.1186/1471-2199-8-21
   Al-falluji R.A.A., 2017, Int. J. Adv. Res. Comput. Eng. Technol, V6, P1445
   Alam MS, 2000, IEEE T INSTRUM MEAS, V49, P915, DOI 10.1109/19.872908
   Aly HA, 2005, IEEE T IMAGE PROCESS, V14, P1647, DOI 10.1109/TIP.2005.851684
   Amanatiadis A, 2009, MEAS SCI TECHNOL, V20, DOI 10.1088/0957-0233/20/10/104015
   [Anonymous], 2016, International Journal of Computer Applications, DOI DOI 10.5120/IJCA2016911458
   [Anonymous], STUDIES FUZZINESS SO
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Barabadi B, 2012, PROCEEDINGS OF THE ASME PACIFIC RIM TECHNICAL CONFERENCE AND EXHIBITION ON PACKAGING AND INTEGRATION OF ELECTRONIC AND PHOTONIC SYSTEMS, MEMS AND NEMS 2011, VOL 1, P213
   Borman S., 1998, MIDW S SYST CIRC, P374, DOI DOI 10.1109/MWSCAS.1998.759509
   Boskovitz V, 2002, IEEE T FUZZY SYST, V10, P247, DOI 10.1109/91.995125
   Bowen O, 2008, I C FIELD PROG LOGIC, P89, DOI 10.1109/FPL.2008.4629913
   BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374
   CARCENAC M, 2009, APPL INTELL
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P231, DOI 10.1109/83.902288
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chang JY, 2004, IEEE T INSTRUM MEAS, V53, P351, DOI 10.1109/TIM.2003.822716
   Chen HC, 2010, EXPERT SYST APPL, V37, P288, DOI 10.1016/j.eswa.2009.05.069
   Chen JL, 2000, FUZZY SET SYST, V114, P225, DOI 10.1016/S0165-0114(98)00090-6
   Chiang MC, 2000, IMAGE VISION COMPUT, V18, P761, DOI 10.1016/S0262-8856(99)00044-X
   Dai S., 2007, CVPR, P1, DOI DOI 10.1109/CVPR.2007.383028
   Datsenko D, 2007, MULTIDIM SYST SIGN P, V18, P103, DOI 10.1007/s11045-007-0018-z
   Dong C., 2014, LECT NOTES COMPUTER
   Dong C, 2015, IEEE IJCNN
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1382, DOI 10.1109/TIP.2012.2231086
   Dong WS, 2011, IEEE T IMAGE PROCESS, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Dong YQ, 2007, IEEE T IMAGE PROCESS, V16, P1112, DOI 10.1109/TIP.2006.891348
   DUBEY S, 2018, INT J TREND SCI RES, P1618
   Eisemann M., 2010, Proceedings of Graphics Interface 2010, GI'10, P71
   EISEMANN M., 2011, P GRAPH INT 2011 CAN, P191
   Elad M, 2001, IEEE T IMAGE PROCESS, V10, P1187, DOI 10.1109/83.935034
   Farsiu S, 2004, INT J IMAG SYST TECH, V14, P47, DOI 10.1002/ima.20007
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Fattal R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239546, 10.1145/1276377.1276496]
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Gajjar PP, 2010, IEEE T IMAGE PROCESS, V19, P1201, DOI 10.1109/TIP.2010.2041408
   Goldlücke B, 2014, INT J COMPUT VISION, V106, P172, DOI 10.1007/s11263-013-0654-8
   Goldluecke B, 2009, IEEE I CONF COMP VIS, P1677, DOI 10.1109/ICCV.2009.5459378
   Gou SP, 2016, IET IMAGE PROCESS, V10, P101, DOI 10.1049/iet-ipr.2015.0046
   Hardie RC, 1997, IEEE T IMAGE PROCESS, V6, P1621, DOI 10.1109/83.650116
   Hardie R, 2007, IEEE T IMAGE PROCESS, V16, P2953, DOI 10.1109/TIP.2007.909416
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   HAYAT K, 2017, DIGIT SIGNAL PROCESS
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   HERZOG R, 2010, SPATIO TEMPORAL UPSA, V1, P212
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   Huang T.S., 1984, ADV COMPUTER VISION, V1, P317
   Hudelot C, 2008, FUZZY SET SYST, V159, P1929, DOI 10.1016/j.fss.2008.02.011
   Hung K.W., 2009, ICIP
   Hwang JW, 2004, IEEE SIGNAL PROC LET, V11, P359, DOI 10.1109/LSP.2003.821718
   Irani M., 1993, Journal of Visual Communication and Image Representation, V4, P324, DOI 10.1006/jvci.1993.1030
   ISHAQUE SF, 2016, INT J ADV RES COMPUT, V6, P120
   JIA K, 2005, IEEE I CONF COMP VIS, V2, P1683
   Kappeler A, 2016, IEEE T COMPUT IMAG, V2, P109, DOI 10.1109/TCI.2016.2532323
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kim H, 2011, IEEE T IMAGE PROCESS, V20, P1895, DOI 10.1109/TIP.2011.2107523
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   KIM K, 2008, 173 M PLANCK I
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Kumar N, 2016, IEEE T MULTIMEDIA, V18, P1504, DOI 10.1109/TMM.2016.2571625
   Lee SJ, 2016, IEEE T CONSUM ELECTR, V62, P159, DOI 10.1109/TCE.2016.7514715
   Lee SJ, 2003, IEEE T SYST MAN CY B, V33, P420, DOI 10.1109/TSMCB.2003.811765
   LEE XB, 1995, IEEE T IMAGE PROCESS, V4, P259, DOI 10.1109/83.366475
   Lee YJ, 2010, IEEE T IMAGE PROCESS, V19, P2682, DOI 10.1109/TIP.2010.2050108
   Li F, 2008, IEEE IMAGE PROC, P333, DOI 10.1109/ICIP.2008.4711759
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Lin CT, 2000, IEEE T GEOSCI REMOTE, V38, P1033, DOI 10.1109/36.841983
   Lin ZC, 2004, IEEE T PATTERN ANAL, V26, P83, DOI 10.1109/TPAMI.2004.1261081
   Liu C, 2011, IET IMAGE PROCESS, V5, P567, DOI 10.1049/iet-ipr.2010.0223
   Liu C, 2007, INT J COMPUT VISION, V75, P115, DOI 10.1007/s11263-006-0029-5
   Liu ZS, 2015, ASIAPAC SIGN INFO PR, P1131, DOI 10.1109/APSIPA.2015.7415447
   MAKWANA RR, 2013, IOSR J ELECT COMMUN, V5, P23, DOI DOI 10.9790/2834-0552333
   Mallat S, 2010, IEEE T IMAGE PROCESS, V19, P2889, DOI 10.1109/TIP.2010.2049927
   Haut JM, 2018, IEEE T GEOSCI REMOTE, V56, P6792, DOI 10.1109/TGRS.2018.2843525
   Moitra S., 2017, IJSART, V3
   Morse BS, 2001, PROC CVPR IEEE, P333
   Mousavi HS, 2017, IEEE T IMAGE PROCESS, V26, P5094, DOI 10.1109/TIP.2017.2704443
   NEDELJKOVIC I, 2004, INT ARCH PHOTOGRAMME, V34, P1
   Nejiya AK, 2013, 2013 IEEE RECENT ADVANCES IN INTELLIGENT COMPUTATIONAL SYSTEMS (RAICS), P251, DOI 10.1109/RAICS.2013.6745482
   Neki NS, 2017, J KRISHNA INST MED S, V6, P3
   Nguyen N, 2000, CIRC SYST SIGNAL PR, V19, P321, DOI 10.1007/BF01200891
   Man NT, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING AND APPLICATIONS (ACOMP), P164, DOI [10.1109/ACOMP.2016.22, 10.1109/ACOMP.2016.032]
   Pham DL, 1999, IEEE T MED IMAGING, V18, P737, DOI 10.1109/42.802752
   Pham TQ, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/83268
   Pickup L.C., 2006, British Machine Vision Conference, V2, P439
   Purkait Pulak, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P284, DOI 10.1007/978-3-642-37431-9_22
   Purkait P, 2014, IEEE T IMAGE PROCESS, V23, P2277, DOI 10.1109/TIP.2014.2312289
   Rahiman A, 2016, 2016 3rd International Conference on Recent Advances in Information Technology (RAIT), P473, DOI 10.1109/RAIT.2016.7507947
   Raju VB, 2015, 2015 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P263, DOI 10.1109/ICCSP.2015.7322882
   Rhee S, 1999, OPT ENG, V38, P1348, DOI 10.1117/1.602177
   Robinson D, 2004, IEEE T IMAGE PROCESS, V13, P1185, DOI 10.1109/TIP.2004.832923
   Robinson D, 2006, IEEE T IMAGE PROCESS, V15, P1413, DOI 10.1109/TIP.2006.871079
   Robinson M. D., 2010, Super-Resolution Imaging, P384
   Russo F, 1999, FUZZY SET SYST, V103, P265, DOI 10.1016/S0165-0114(98)00226-7
   Sajjad M, 2014, MULTIMED TOOLS APPL, V72, P2063, DOI 10.1007/s11042-012-1325-4
   Sajjad M, 2015, MULTIMED TOOLS APPL, V74, P8961, DOI 10.1007/s11042-013-1570-1
   Salvador J, 2014, IEEE IMAGE PROC, P2135, DOI 10.1109/ICIP.2014.7025428
   Schulte S, 2006, IEEE T IMAGE PROCESS, V15, P1153, DOI 10.1109/TIP.2005.864179
   Schulte S, 2007, FUZZY SET SYST, V158, P270, DOI 10.1016/j.fss.2006.10.010
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672
   Shen HF, 2007, IEEE T IMAGE PROCESS, V16, P479, DOI 10.1109/TIP.2006.888334
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   SINGH A, 2016, INDIAN J SCI TECHNOL, V9
   Stathakis D, 2006, IEEE T GEOSCI REMOTE, V44, P2305, DOI 10.1109/TGRS.2006.872903
   Sun DG, 2016, IET SIGNAL PROCESS, V10, P63, DOI 10.1049/iet-spr.2014.0508
   Sun J, 2008, PROC CVPR IEEE, P2471, DOI 10.1109/CVPR.2008.4587659
   Sun J, 2011, IEEE T IMAGE PROCESS, V20, P1529, DOI 10.1109/TIP.2010.2095871
   Suresh KV, 2007, J OPT SOC AM A, V24, P984, DOI 10.1364/JOSAA.24.000984
   Suresha D, 2016, PROCEEDINGS OF THE 2016 2ND INTERNATIONAL CONFERENCE ON APPLIED AND THEORETICAL COMPUTING AND COMMUNICATION TECHNOLOGY (ICATCCT), P387, DOI 10.1109/ICATCCT.2016.7912029
   Suzuki J, 2000, MULTIMED TOOLS APPL, V12, P7, DOI 10.1023/A:1009631927516
   Tai YW, 2010, PROC CVPR IEEE, P2400, DOI 10.1109/CVPR.2010.5539933
   Tam WS, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3358372
   Tang Y, 2017, IEEE T IMAGE PROCESS, V26, P994, DOI [10.1109/TIP.2016.2639440, 10.1109/TIP.2017.2656474]
   Tang Y, 2014, IEEE T CYBERNETICS, V44, P2143, DOI 10.1109/TCYB.2014.2301732
   Tatem AJ, 2001, IEEE T GEOSCI REMOTE, V39, P781, DOI 10.1109/36.917895
   Tian J., 2007, 2007 European Conference on Power Electronics and Applications, P1
   Tian J, 2010, J VIS COMMUN IMAGE R, V21, P232, DOI 10.1016/j.jvcir.2010.01.001
   Tian YP, 2016, IEEE IMAGE PROC, P2827, DOI 10.1109/ICIP.2016.7532875
   Ting HC, 1997, J VIS COMMUN IMAGE R, V8, P338, DOI 10.1006/jvci.1997.0364
   Tom B.C., 1995, P IEEE INT C IMAGE P, P2539
   UNSER M, 1991, IEEE T PATTERN ANAL, V13, P277, DOI 10.1109/34.75515
   Van de Ville D, 2003, IEEE T FUZZY SYST, V11, P429, DOI 10.1109/TFUZZ.2003.814830
   van Eekeren AWM, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/43953
   Wang JJ, 2010, PATTERN RECOGN LETT, V31, P1, DOI 10.1016/j.patrec.2009.09.004
   Wang LF, 2013, IEEE T CIRC SYST VID, V23, P1289, DOI 10.1109/TCSVT.2013.2240915
   WANG Q, 2010, CVPR
   Wang SL, 2012, PROC CVPR IEEE, P2216, DOI 10.1109/CVPR.2012.6247930
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiong ZW, 2010, IEEE T IMAGE PROCESS, V19, P2017, DOI 10.1109/TIP.2010.2045707
   Xu HX, 2004, 2004 INTERNATIONAL CONFERENCE ON COMMUNICATION, CIRCUITS, AND SYSTEMS, VOLS 1 AND 2, P792, DOI 10.1109/ICCCAS.2004.1346299
   YAMANAKA J, 2017, ICONIPS, P1
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang Z, 2017, LECT NOTES COMPUT SC, V10132, P353, DOI 10.1007/978-3-319-51811-4_29
   Yoon Y, 2017, IEEE SIGNAL PROC LET, V24, P848, DOI 10.1109/LSP.2017.2669333
   Yue HJ, 2013, IEEE T IMAGE PROCESS, V22, P4865, DOI 10.1109/TIP.2013.2279315
   Yüksel ME, 2003, AEU-INT J ELECTRON C, V57, P214, DOI 10.1078/1434-8411-54100164
   Zhang KB, 2013, IEEE T NEUR NET LEAR, V24, P1648, DOI 10.1109/TNNLS.2013.2262001
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhu FZ, 2010, J SYST ENG ELECTRON, V21, P934, DOI 10.3969/j.issn.1004-4132.2010.06.002
   Zhu SY, 2016, IEEE T MULTIMEDIA, V18, P1707, DOI 10.1109/TMM.2016.2593039
   Zibetti MVW, 2006, IEEE IMAGE PROC, P1741
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
   Zomet A, 2001, PROC CVPR IEEE, P645
   Zomet A, 2000, INT C PATT RECOG, P579, DOI 10.1109/ICPR.2000.905404
NR 146
TC 12
Z9 14
U1 0
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 1641
EP 1672
DI 10.1007/s11042-019-08254-0
EA NOV 2019
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000495055800001
DA 2024-07-18
ER

PT J
AU Adeliyi, T
   Olugbara, O
AF Adeliyi, Timothy
   Olugbara, Oludayo
TI Detecting salient objects in non-stationary video image sequence for
   analyzing user perceptions of digital video contents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Salient object; Sparse reconstruction; User
   perception; Video image; Video sequence
ID DETECTION MODEL; SEGMENTATION; EXPERIENCE; EFFICIENT; QUALITY
AB The ubiquitous utilization of video applications in recent years has made research on video quality of experience paramount. Lack of sufficient bandwidth deters the effective transmission of raw video contents to users. This bandwidth challenge has given rise to encoders for compressing digital video contents for transmission over an internet protocol infrastructure. However, transmitting compressed video color images still has an intrinsic limitation of high bandwidth consumption. Simple linear iterative clustering algorithm was applied for binary segmentation of video color images to circumvent the challenge of efficiently transmitting video contents. Compressed binary segmented images are generally fast to transmit and require lower bandwidth consumption as opposed to compressed video color images. However, since color images contain more useful information than binary image counterparts, evaluation of binary segmentation results was performed using the mean opinion score metric to determine user quality of experience of the transmitted video contents. The practical application of our method will lead to the development of a novel encoder that can deliver binary video contents faster, hence solving the bandwidth hiccup.
C1 [Adeliyi, Timothy; Olugbara, Oludayo] Durban Univ Technol, ICT & Soc Res Grp, Durban, South Africa.
C3 Durban University of Technology
RP Adeliyi, T (corresponding author), Durban Univ Technol, ICT & Soc Res Grp, Durban, South Africa.
EM tim.adeliyi@gmail.com
RI Adeliyi, Timothy T/JNE-8803-2023
OI Adeliyi, Timothy T./0000-0002-8034-1045
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Achanta Radhakrishna, 2010, Tech. Rep.
   Ahn E, 2017, IEEE J BIOMED HEALTH, V21, P1685, DOI 10.1109/JBHI.2017.2653179
   Ahn E, 2015, IEEE ENG MED BIO, P3009, DOI 10.1109/EMBC.2015.7319025
   [Anonymous], TECHNICAL REPORT
   [Anonymous], 2014 IEEE C EV COMP
   [Anonymous], MOTION COHERENT TRAC
   [Anonymous], 2014, PROC IEEE C COMPUTER, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]
   [Anonymous], AM J INTELLIGENT SYS
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P8707, DOI 10.1016/j.eswa.2015.07.025
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833
   Brooks P, 2010, IEEE NETWORK, V24, P8, DOI 10.1109/MNET.2010.5430138
   Bylinskii Z, 2016, LECT NOTES COMPUT SC, V9909, P809, DOI 10.1007/978-3-319-46454-1_49
   Chen CZ, 2017, IEEE T IMAGE PROCESS, V26, P3156, DOI 10.1109/TIP.2017.2670143
   Corrêa G, 2012, IEEE T CIRC SYST VID, V22, P1899, DOI 10.1109/TCSVT.2012.2223411
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Duanmu ZF, 2017, IEEE J-STSP, V11, P154, DOI 10.1109/JSTSP.2016.2608329
   El Abbadi Nidhal Khdhair, 2014, Journal of Computer Science, V10, P632, DOI 10.3844/jcssp.2014.632.639
   Eng ET, 2018, IMPACT DATA REDUCTIO, P451427
   Engelke Ulrich, 2010, Proceedings of the 2010 Second International Workshop on Quality of Multimedia Experience (QoMEX 2010), P212, DOI 10.1109/QOMEX.2010.5516159
   Fang YM, 2014, IEEE T CIRC SYST VID, V24, P27, DOI 10.1109/TCSVT.2013.2273613
   Fei L., 2015, J LATEX CLASS FILES, V13, P1
   Fu HZ, 2013, IEEE T IMAGE PROCESS, V22, P3766, DOI 10.1109/TIP.2013.2260166
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Guo LJ, 2017, MULTIMED TOOLS APPL, V76, P1037, DOI 10.1007/s11042-015-3100-9
   Gygli M, 2013, IEEE I CONF COMP VIS, P1633, DOI 10.1109/ICCV.2013.205
   Hadizadeh H, 2014, IEEE T IMAGE PROCESS, V23, P19, DOI 10.1109/TIP.2013.2282897
   Han JW, 2014, ISPRS J PHOTOGRAMM, V89, P37, DOI 10.1016/j.isprsjprs.2013.12.011
   Helin Henrik, 2018, J PATHOLOGY INFORN, V9
   HUANG LK, 1995, PATTERN RECOGN, V28, P41, DOI 10.1016/0031-3203(94)E0043-K
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Kou G, 2014, INFORM SCIENCES, V275, P1, DOI 10.1016/j.ins.2014.02.137
   Kumar V, 2016, ARXIV160402035
   Lee SH, 2016, J VIS COMMUN IMAGE R, V35, P169, DOI 10.1016/j.jvcir.2015.12.011
   Li B, 2012, JCTVCH0360
   Li FX, 2013, IEEE I CONF COMP VIS, P2192, DOI 10.1109/ICCV.2013.273
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Li YJ, 2015, IEEE SIGNAL PROC LET, V22, P588, DOI 10.1109/LSP.2014.2364896
   Liu YB, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/973069
   Lu HC, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2524198
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Podder PK, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0150673
   Pont-Tuset J, 2016, IEEE T PATTERN ANAL, V38, DOI [10.1109/TPAMI.2015.2481406, 10.1109/TPAMI.2016.2537320]
   Popovic A, 2007, INT J COMPUT ASS RAD, V2, P169, DOI 10.1007/s11548-007-0125-1
   Potapov D, 2014, P EUR C COMP VIS
   Qin CC, 2014, NEUROCOMPUTING, V129, P378, DOI 10.1016/j.neucom.2013.09.021
   RABBANI T., 2006, The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, V36, P248
   Samanthula BK, 2016, IEEE T DEPEND SECURE, V13, P591, DOI 10.1109/TDSC.2015.2415482
   Scharr H, 2016, MACH VISION APPL, V27, P585, DOI 10.1007/s00138-015-0737-3
   Shattuck DW, 2009, NEUROIMAGE, V45, P431, DOI 10.1016/j.neuroimage.2008.10.066
   Shen JB, 2014, IEEE T IMAGE PROCESS, V23, P1451, DOI 10.1109/TIP.2014.2302892
   Souly N, 2016, INT J COMPUT VISION, V117, P93, DOI 10.1007/s11263-015-0853-6
   Taha AA, 2015, BMC MED IMAGING, V15, DOI 10.1186/s12880-015-0068-x
   Tasse Flora Ponjou., 2016, Proceedings of SIGGRAPH ASIA 2016 Technical Briefs, p19:1
   Udupa JK, 2006, COMPUT MED IMAG GRAP, V30, P75, DOI 10.1016/j.compmedimag.2005.12.001
   Wang W, 2015, IEEE T IMAGE PROCESS, V24, P41854196
   Wei L, 2018, APPL LINGUIST, V39, P9, DOI 10.1093/applin/amx039
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang J, 2016, IEEE T PATTERN ANAL, V38, P889902
   Zhang LH, 2017, IEEE T PATTERN ANAL, V39, P1892, DOI 10.1109/TPAMI.2016.2609426
   Zheng K, 2015, IEEE WIREL COMMUN, V22, P70, DOI 10.1109/MWC.2015.7054721
NR 66
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31807
EP 31821
DI 10.1007/s11042-019-08008-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000037
DA 2024-07-18
ER

PT J
AU Fan, Q
   Luo, W
   Xia, Y
   Li, GZ
   He, DJ
AF Fan, Qiang
   Luo, Wang
   Xia, Yuan
   Li, Guozhi
   He, Daojing
TI metrics and methods of video quality assessment: a brief review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Quality assessment; Assessment metrics; Assessment method; Video query
ID PREDICTION; RETRIEVAL; SYSTEM
AB With rapid development of video acquisition devices and wide applications of video data, more and more requirements are established to use video data query. video quality assessment and improvement become popular and important research issues which attract lots of researchers. The video quality can influence technique application, user experience, and application results. This paper firstly reviews research work on video query based applications. Then, various metrics of video quality assessment are reviewed according to the requirement of reference video, including full-reference metrics, no-reference metrics and reduced-reference metrics. In addition, methods of video quality assessment are reviewed by the features, which include visual features, bitstream-based or packet-based features, data features. Finally, a number of video quality improvement methods are briefly introduced.
C1 [Fan, Qiang; Luo, Wang; Xia, Yuan; Li, Guozhi] NARI Grp Corp, State Grid Elect Power Res Inst, Nanjing, Jiangsu, Peoples R China.
   [He, Daojing] East China Normal Univ, Sch Comp Sci & Software Engn, Shanghai, Peoples R China.
C3 State Grid Corporation of China; Nari Group Corp; East China Normal
   University
RP Luo, W (corresponding author), NARI Grp Corp, State Grid Elect Power Res Inst, Nanjing, Jiangsu, Peoples R China.
EM luowang@163.com
OI He, Daojing/0000-0002-3820-8128
FU state grid corporation science and technology project "The pilot
   application on network access security for patrol data captured by
   unmanned planes and robots and intelligent recognition base on big data
   platform"
FX This research is supported by state grid corporation science and
   technology project "The pilot application on network access security for
   patrol data captured by unmanned planes and robots and intelligent
   recognition base on big data platform".
CR Agrawal R., 1993, EFFICIENT SIMILARITY
   Andrade H, 2004, IEEE T PARALL DISTR, V15, P520, DOI 10.1109/TPDS.2004.11
   Anegekuh L, 2015, IEEE T MULTIMEDIA, V17, P1323, DOI 10.1109/TMM.2015.2444098
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], IEEE T INTELL TRANSP
   [Anonymous], P 3 INT C ADV COMP T
   [Anonymous], IEEE T MULTIMED
   [Anonymous], P IEEE 17 INT C COMP
   [Anonymous], IST SPIE ELECT IMAGI
   [Anonymous], P IEEE C GLOB TEL C
   [Anonymous], 2012, TEL ICT 2012 19 INT
   [Anonymous], P 1 INT WORKSH INT S
   [Anonymous], P ANN IEEE C IND C I
   [Anonymous], IEEE T IMAGE PROCESS
   Atenas Marcelo, 2010, 2010 Sixth International Conference on Networking and Services (ICNS), P49, DOI 10.1109/ICNS.2010.15
   Bhat A, 2012, IEEE T CIRC SYST VID, V22, P165, DOI 10.1109/TCSVT.2011.2158465
   Boujut H, 2011, IEEE INT CON MULTI
   Chan SSM, 2002, IEEE T MULTIMEDIA, V4, P146, DOI 10.1109/TMM.2002.1017730
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   Choudary C, 2007, IEEE INT SYM MULTIM, P277, DOI 10.1109/ISM.Workshops.2007.54
   Culibrk D, 2011, IEEE T IMAGE PROCESS, V20, P948, DOI 10.1109/TIP.2010.2080279
   Feng X, 2011, IEEE T BROADCAST, V57, P81, DOI 10.1109/TBC.2010.2092150
   Gunawan IP, 2008, IEEE T CIRC SYST VID, V18, P71, DOI 10.1109/TCSVT.2007.913755
   Hewage CTER, 2010, IEEE IMAGE PROC, P4017, DOI 10.1109/ICIP.2010.5653741
   Hirai K, 2010, IEICE T INF SYST, VE93D, P1253, DOI 10.1587/transinf.E93.D.1253
   Huynh-Thu Q, 2010, SIGNAL PROCESS-IMAGE, V25, P535, DOI 10.1016/j.image.2010.03.006
   Jain A., 2011, Communication and Industrial Application (ICCIA), 2011 International Conference on, P1, DOI [10.1109/ICCIndA.2011.6146668, DOI 10.1109/ICCINDA.2011.6146668]
   Jenkins C, 2000, 2000 KYOTO INTERNATIONAL CONFERENCE ON DIGITAL LIBRARIES: RESEARCH AND PRACTICE, PROCEEDINGS, P262, DOI 10.1109/DLRP.2000.942183
   Keimel C, 2011, IEEE IMAGE PROC
   Kim D, 2012, P IEEE INT S BROADBA, P1
   Kriegel HP, 2006, 12TH INTERNATIONAL MULTI-MEDIA MODELLING CONFERENCE PROCEEDINGS, P389
   Kwangsung Ha, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2525, DOI 10.1109/ICIP.2011.6116176
   Kwok SH, 2006, DECIS SUPPORT SYST, V42, P1901, DOI 10.1016/j.dss.2006.04.013
   Lee SO, 2010, IEEE T CONSUM ELECTR, V56, P1071, DOI 10.1109/TCE.2010.5506041
   Leszczuk M, 2015, SIGNAL PROCESS-IMAGE, V39, P457, DOI 10.1016/j.image.2015.05.003
   Leszczuk M, 2013, SIGNAL PROCESS-IMAGE, V28, P903, DOI 10.1016/j.image.2012.09.006
   Li CF, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267087
   Li JY, 2015, IEEE T KNOWL DATA EN, V27, P589, DOI 10.1109/TKDE.2014.2356471
   Ma Q, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3302129
   Maalouf Aldo, 2010, Proceedings of the 2010 Second International Workshop on Quality of Multimedia Experience (QoMEX 2010), P11, DOI 10.1109/QOMEX.2010.5518301
   Martínez JM, 2002, IEEE MULTIMEDIA, V9, P78, DOI 10.1109/93.998074
   Matsubara FM, 2009, IEEE T CONSUM ELECTR, V55, P873, DOI 10.1109/TCE.2009.5174468
   Mi Hee, 1999, Proceedings Third International Conference on Computational Intelligence and Multimedia Applications. ICCIMA'99 (Cat. No.PR00300), P258, DOI 10.1109/ICCIMA.1999.798539
   Narvekar ND, 2009, INT WORK QUAL MULTIM, P87, DOI 10.1109/QOMEX.2009.5246972
   Narwaria M, 2012, IEEE T MULTIMEDIA, V14, P525, DOI 10.1109/TMM.2012.2190589
   Nezhadarya E, 2013, DIGIT SIGNAL PROCESS, V23, P1483, DOI 10.1016/j.dsp.2013.04.009
   Ribeiro C, 2004, 2004 IEEE 6TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P430
   Sadat ABMRI, 2009, 2009 INTERNATIONAL WORKSHOP ON HIGH PERFORMANCE COMPUTATIONAL SYSTEMS BIOLOGY, PROCEEDINGS, P113, DOI 10.1109/HiBi.2009.25
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Shan ZY, 2016, IEEE MULTIMEDIA, V23, P56, DOI 10.1109/MMUL.2016.37
   Shen H.T., 2005, P ACM SIGMOD INT C M, P730
   Shenoy S. T., 1989, IEEE Transactions on Knowledge and Data Engineering, V1, P344, DOI 10.1109/69.87980
   Wang SH, 2007, J CHIN INST ENG, V30, P1059, DOI 10.1080/02533839.2007.9671332
   Steinacker A., 2001, IEEE Multimedia, V8, P70, DOI 10.1109/93.923956
   Tagliasacchi M, 2010, MULTIMED TOOLS APPL, V48, P471, DOI 10.1007/s11042-010-0473-7
   Torkamani-Azar F, 2015, J VIS COMMUN IMAGE R, V27, P1, DOI 10.1016/j.jvcir.2014.12.004
   Vranjes M, 2013, SIGNAL PROCESS-IMAGE, V28, P1, DOI 10.1016/j.image.2012.10.003
   Wang J, 2009, INT C ELECTR MACH SY, P17
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   Weibel S, 1997, B AM SOC INFORM INF, V24, P9, DOI 10.1002/bult.70
   Wichterich M., 2008, SIGMOD, P199
   Xia T, 2010, J VIS COMMUN IMAGE R, V21, P826, DOI 10.1016/j.jvcir.2010.06.005
   Xia YJ, 2017, IEEE T CYBERNETICS, V47, P566, DOI 10.1109/TCYB.2016.2520959
   Xia YJ, 2016, IEEE T CYBERNETICS, V46, P3220, DOI 10.1109/TCYB.2015.2501385
   Xia YJ, 2016, INFORM SCIENCES, V374, P164, DOI 10.1016/j.ins.2016.09.043
   Xia YJ, 2016, MULTIMED TOOLS APPL, V75, P8829, DOI 10.1007/s11042-014-2256-z
   Xia YJ, 2016, MULTIMEDIA SYST, V22, P497, DOI 10.1007/s00530-014-0412-y
   Xia YJ, 2016, NEUROCOMPUTING, V181, P139, DOI 10.1016/j.neucom.2015.07.140
   Xia YJ, 2016, SIGNAL PROCESS, V120, P672, DOI 10.1016/j.sigpro.2014.10.035
   Xia YJ, 2015, INFORM SCIENCES, V320, P333, DOI 10.1016/j.ins.2015.01.038
   Xiang X, 2003, 3RD IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P288, DOI 10.1109/ICALT.2003.1215087
   Xin F, 2008, IEEE IMAGE PROC, P2560, DOI 10.1109/ICIP.2008.4712316
   Yamamura Y, 2013, IEEE ICCE, P494, DOI 10.1109/ICCE.2013.6486991
   Yao J, 2012, PROCEDIA ENGINEER, V29, P947, DOI 10.1016/j.proeng.2012.01.069
   Yoon JH, 2001, IEEE IMAGE PROC, P42, DOI 10.1109/ICIP.2001.958948
   You JY, 2011, IEEE T MULTIMEDIA, V13, P1269, DOI 10.1109/TMM.2011.2172591
   You JY, 2010, INT CONF ACOUST SPEE, P1002, DOI 10.1109/ICASSP.2010.5495313
   Zeng K, 2010, INT CONF ACOUST SPEE, P1010, DOI 10.1109/ICASSP.2010.5495316
   Zhang LM, 2016, IEEE T CYBERNETICS, V46, P258, DOI 10.1109/TCYB.2015.2400821
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1309, DOI 10.1109/TIE.2014.2336639
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P2235, DOI 10.1109/TIP.2014.2311658
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhou WS, 2002, INFORM SYST, V27, P559, DOI 10.1016/S0306-4379(02)00018-2
NR 85
TC 10
Z9 12
U1 1
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31019
EP 31033
DI 10.1007/s11042-017-4848-x
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000002
DA 2024-07-18
ER

PT J
AU Ahmed, HM
   Youssef, BAB
   Elkorany, AS
   Elsharkawy, ZF
   Saleeb, AA
   Abd El-Samie, F
AF Ahmed, Heba M.
   Youssef, Bayumy A. B.
   Elkorany, Ahmed S.
   Elsharkawy, Zeinab F.
   Saleeb, Adel A.
   Abd El-Samie, Fathi
TI Hybridized classification approach for magnetic resonance brain images
   using gray wolf optimizer and support vector machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MR images; Gray wolf optimizer; Support vector machine; Classification
ID TUMOR DETECTION; MR-IMAGES; SEGMENTATION; ENTROPY
AB Automated abnormal brain discovery is an extremely crucial task for clinical diagnosis. Over a decade ago, various techniques had been displayed to improve this technology. This paper presents a hybrid system based on a combination of Gray Wolf Optimizer (GWO) and Support Vector Machine (SVM) with Radial Basis Function (RBF) kernel to classify a given Magnetic Resonance (MR) brain image as benign or malignant. 5-fold cross validation was used to enhance generalization. We applied the hybrid system on 80 images (20 benign and 60 malignant), and found out that the classification accuracy was as high as 98.750%.
C1 [Ahmed, Heba M.; Youssef, Bayumy A. B.] City Sci Res & Technol Applicat, Informat Res Inst, Alexandria 21934, Egypt.
   [Elkorany, Ahmed S.; Saleeb, Adel A.; Abd El-Samie, Fathi] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
   [Elsharkawy, Zeinab F.] Atom Energy Author, Nucl Res Ctr, Engn Dept, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); City of Scientific Research &
   Technological Applications (SRTA-City); Egyptian Knowledge Bank (EKB);
   Menofia University; Egyptian Knowledge Bank (EKB); Egyptian Atomic
   Energy Authority (EAEA)
RP Ahmed, HM (corresponding author), City Sci Res & Technol Applicat, Informat Res Inst, Alexandria 21934, Egypt.
EM elkoranyahmed@yahoo.com
RI Elkorany, Ahmed S./HNI-8465-2023; KHALIFA, AHMED khalifa/HKF-2246-2023;
   Elkorany, Ahmed S./AFS-0613-2022; Sayed, Fathi/HRA-4752-2023
OI Elkorany, Ahmed S./0000-0003-3400-2971; KHALIFA, AHMED
   khalifa/0000-0002-2918-7572; Elkorany, Ahmed S./0000-0003-3400-2971;
   Sayed, Fathi/0000-0001-8749-9518; Elsharkawy, Zeinab/0000-0002-6167-8435
CR Abd-Ellah MK, 2016, INT C MICROELECTRON, P73, DOI 10.1109/ICM.2016.7847911
   Abdullah HN, 2015, 2015 8TH INTERNATIONAL CONFERENCE ON INTELLIGENT NETWORKS AND INTELLIGENT SYSTEMS (ICINIS), P21, DOI 10.1109/ICINIS.2015.29
   Ahmed HM, 2018, APPL OPTICS, V57, pB25, DOI 10.1364/AO.57.000B25
   Ahmmed R, 2017, 2017 INTERNATIONAL CONFERENCE ON ELECTRICAL, COMPUTER AND COMMUNICATION ENGINEERING (ECCE), P229, DOI 10.1109/ECACE.2017.7912909
   Amin J, 2018, FUTURE GENER COMP SY, V87, P290, DOI 10.1016/j.future.2018.04.065
   Anitha R, 2017, INT J IMAG SYST TECH, V27, P354, DOI 10.1002/ima.22238
   [Anonymous], 2010, Leonardo J Sci, DOI DOI 10.4018/JSSCI.2011040102
   [Anonymous], 2017, PAT RECOG LETT
   [Anonymous], ELECT INSTRUMENTATIO
   [Anonymous], 2017, P 2017 IEEE INT C EL, DOI DOI 10.1109/ICEICE.2017.8191888
   [Anonymous], 2015, BRATS DATABASE
   [Anonymous], 2013, INT J ENG RES APPL
   [Anonymous], 5 NAT IEEE C COMP VI
   [Anonymous], 2017, INT C COMP INT DAT S, DOI DOI 10.1109/ICCIDS.2017.8272635
   [Anonymous], 2015, 2015 INT C COMP COMM
   [Anonymous], 2016, FIRE ICE
   Bahadure NB, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9749108
   Benson CC, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P187, DOI 10.1109/ICACCI.2016.7732045
   Devkota B, 2018, PROCEDIA COMPUT SCI, V125, P115, DOI 10.1016/j.procs.2017.12.017
   Fink JR, 2015, J NUCL MED, V56, P1554, DOI 10.2967/jnumed.113.131516
   Gupta T, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P2560
   Halder A, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1919, DOI 10.1109/ICACCI.2016.7732331
   He X, 2015, IEEE INT WORK SIGN P, P685, DOI 10.1109/SPAWC.2015.7227125
   Jahanavi MS, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P546, DOI 10.1109/RTEICT.2016.7807881
   Kharrat A, 2015, INT CONF INTELL SYST, P446, DOI 10.1109/ISDA.2015.7489271
   Kumar S, 2017, PROCEDIA COMPUT SCI, V122, P510, DOI 10.1016/j.procs.2017.11.400
   Lakshmi A., 2014, Journal of Theoretical and Applied Information Technology, V64, P561
   Machhale K, 2015, 2015 INTERNATIONAL CONFERENCE ON INDUSTRIAL INSTRUMENTATION AND CONTROL (ICIC), P60, DOI 10.1109/IIC.2015.7150592
   Ming-Chi Wu, 2016, 2016 2nd International Conference on Information Management (ICIM), P47, DOI 10.1109/INFOMAN.2016.7477532
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Nandpuru HB, 2014, 2014 IEEE STUDENTS' CONFERENCE ON ELECTRICAL, ELECTRONICS AND COMPUTER SCIENCE (SCEECS)
   Preethi A, 2014, 2014 IEEE NATIONAL CONFERENCE ON EMERGING TRENDS IN NEW & RENEWABLE ENERGY SOURCES AND ENERGY MANAGEMENT (NCET NRES EM), P1, DOI 10.1109/NCETNRESEM.2014.7088730
   Rajinikanth V, 2017, PATTERN RECOGN LETT, V94, P87, DOI 10.1016/j.patrec.2017.05.028
   Saha C, 2017, 2017 4TH IEEE UTTAR PRADESH SECTION INTERNATIONAL CONFERENCE ON ELECTRICAL, COMPUTER AND ELECTRONICS (UPCON), P329, DOI 10.1109/UPCON.2017.8251069
   Selvapandian A, 2018, COMPUT METH PROG BIO, V166, P33, DOI 10.1016/j.cmpb.2018.09.006
   Thara KS, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P1504, DOI 10.1109/WiSPNET.2016.7566388
   Urban G., 2014, P MICCAI BRATS BRAIN, P31, DOI DOI 10.1007/978-3-319-12057-3_4
   Varuna Shree N, 2018, Brain Inform, V5, P23, DOI 10.1007/s40708-017-0075-5
   Wang SH, 2017, FUND INFORM, V151, P275, DOI 10.3233/FI-2017-1492
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Zhang GS, 2015, 2015 SEVENTH INTERNATIONAL SYMPOSIUM ON PARALLEL ARCHITECTURES, ALGORITHMS AND PROGRAMMING (PAAP), P87, DOI 10.1109/PAAP.2015.26
   Zhang GS, 2015, AER ADV ENG RES, V8, P683
   Zhang YD, 2017, J EXP THEOR ARTIF IN, V29, P299, DOI 10.1080/0952813X.2015.1132274
NR 44
TC 9
Z9 9
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27983
EP 28002
DI 10.1007/s11042-019-07876-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000054
DA 2024-07-18
ER

PT J
AU Chu, HF
   Qi, MB
   Liu, H
   Jiang, JG
AF Chu, Huifang
   Qi, Meibin
   Liu, Hao
   Jiang, Jianguo
TI Local region partition for person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Damaged region; Partition; Directional
   enlargement
AB Due to the different posture and view angle, the image will appear some objects that do not exist in another image of the same person captured by another camera. The region covered by new items adversely improved the difficulty of person re-identification. Therefore, we named these regions as Damaged Region (DR). To overcome the influence of DR, we propose a new way to extract feature based on the local region that divides both in the horizontal and vertical directions. Before splitting the image, we enlarge it with direction to increase the useful information, potentially reducing the impact of different viewing angles. Then each divided region is a separated part, and the results of the adjacent regions will be compared. As a result the region that gets a higher score is selected as the valid one, and which gets the lower score caused by pose variation and items occlusion will be invalid. Extensive experiments carried out on three person re-identification benchmarks, including VIPeR, PRID2011, CUHK01, clearly show the significant and consistent improvements over the state-of-the-art methods.
C1 [Chu, Huifang; Qi, Meibin; Liu, Hao; Jiang, Jianguo] Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.
C3 Hefei University of Technology
RP Qi, MB (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.
EM hfchu_hfut@163.com; qimeibin@163.com; hfut.haoliu@gmail.com;
   jgjiang@hfut.edu.cn
FU National Natural Science Foundation of China [61371155]
FX This work was supported by the National Natural Science Foundation of
   China Grant 61371155.
CR [Anonymous], P CVPR
   [Anonymous], 2016, TOMCCAP, DOI DOI 10.1016/J.YMPEV.2016.12.037
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], IEEE INT WORKSH PETS
   [Anonymous], PERSON REIDENTIFICAT
   [Anonymous], 2014, EUR C COMP VIS
   [Anonymous], 2012, RELAXED PAIRWISE LEA
   [Anonymous], 2016, AAAI C ART INT
   [Anonymous], 2016, PERSON REIDENTIFICAT
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247939
   [Anonymous], FEATURE RELATIONSHIP
   [Anonymous], PREDICTING URBAN WAT
   [Anonymous], P 1 INT WORKSH INT S
   [Anonymous], AAAI C ART INT
   [Anonymous], P CVPR
   [Anonymous], IEEE T IMAGE PROCESS
   Chen DP, 2016, PROC CVPR IEEE, P1268, DOI 10.1109/CVPR.2016.142
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Gupta P, 2016, ATMOS MEAS TECH, V9, P3293, DOI 10.5194/amt-9-3293-2016
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463
   Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lisanti G., 2014, Proceedings of the International Conference on Distributed Smart Cameras, p10:1
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lu Y, 2016, Multimedia Tools and Applications, P1
   Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152
   Ning JF, 2016, PROC CVPR IEEE, P4266, DOI 10.1109/CVPR.2016.462
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Shan ZY, 2016, IEEE MULTIMEDIA, V23, P56, DOI 10.1109/MMUL.2016.37
   Shen Y, 2015, IEEE I CONF COMP VIS, P3200, DOI 10.1109/ICCV.2015.366
   Shi ZY, 2015, PROC CVPR IEEE, P4184, DOI 10.1109/CVPR.2015.7299046
   Su C, 2016, LECT NOTES COMPUT SC, V9906, P475, DOI 10.1007/978-3-319-46475-6_30
   Sun XB, 2010, 2ND INTERNATIONAL SYMPOSIUM ON COMPUTER NETWORK AND MULTIMEDIA TECHNOLOGY (CNMT 2010), VOLS 1 AND 2, P438
   Tao DP, 2013, IEEE T CIRC SYST VID, V23, P1675, DOI 10.1109/TCSVT.2013.2255413
   Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144
   Wang W, 2016, IEEE MULTIMEDIA, V23, P80, DOI 10.1109/MMUL.2016.69
   Xia YJ, 2016, IEEE T CYBERNETICS, V46, P3220, DOI 10.1109/TCYB.2015.2501385
   Xia YJ, 2016, MULTIMEDIA SYST, V22, P497, DOI 10.1007/s00530-014-0412-y
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   You JJ, 2016, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2016.150
   Zhang LM, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P107, DOI 10.1145/2671188.2749299
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2016, IEEE T CYBERNETICS, V46, P535, DOI 10.1109/TCYB.2015.2408592
   Zhang LM, 2016, IEEE T IMAGE PROCESS, V25, P553, DOI 10.1109/TIP.2015.2502147
   Zhang LM, 2016, IEEE T CYBERNETICS, V46, P258, DOI 10.1109/TCYB.2015.2400821
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2012, INT C PATT RECOG, P2813
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T CYBERNETICS, V44, P1408, DOI 10.1109/TCYB.2013.2285219
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P2235, DOI 10.1109/TIP.2014.2311658
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P802, DOI 10.1109/TIP.2012.2223226
   Zhang Y, 2016, PROC CVPR IEEE, P1278, DOI 10.1109/CVPR.2016.143
   Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26
NR 64
TC 7
Z9 7
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27067
EP 27083
DI 10.1007/s11042-017-4817-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000013
DA 2024-07-18
ER

PT J
AU Kumar, M
   Sathish, G
   Alphonse, M
   Lahcen, RAM
AF Kumar, Manish
   Sathish, G.
   Alphonse, Michael
   Lahcen, Rachid Ait Maalem
TI A new RGB image encryption using generalized heat equation associated
   with generalized Vigenere-type table over symmetric group
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Generalized heat equation; Generalized Vigenre-type table on S-n group;
   Random key sequence; Image encryption
ID CHAOTIC SYSTEM; ALGORITHM; SCHEME; CRYPTANALYSIS; MAP; PERMUTATION
AB The primary aim of this paper is to provide an efficient encryption algorithm for RGB images. A new, fast and secure RGB image encryption using Generalized Heat Equation (GHE) associated with Generalized re-type Table over Symmetric Group S-n (GVTSG) is proposed. Encryption keys are obtained from Random Key Sequence (RKS). We have generated RKS and GVTSG with the help of GHE. By using this GHE, we are able to test the randomness over the generated key sequence by applying National Institute of Standards and Technology (NIST) statistical test suite. A formula for the keyspace has also been obtained and it is shown that this keyspace resists brute force attack. The proposed encryption algorithm provides high security and a larger key space. The keys for encryption or decryption consume less storage to store it on both sender and receiver ends. Robustness of the proposed algorithm has been analyzed and compared with other competing existing algorithms.
C1 [Kumar, Manish; Sathish, G.; Alphonse, Michael] Birla Inst Technol & Sci Pilani, Dept Math, Hyderabad Campus, Hyderabad 500078, Telangana, India.
   [Lahcen, Rachid Ait Maalem] Univ Cent Florida, Dept Math, Orlando, FL 32816 USA.
C3 Birla Institute of Technology & Science Pilani (BITS Pilani); State
   University System of Florida; University of Central Florida
RP Kumar, M (corresponding author), Birla Inst Technol & Sci Pilani, Dept Math, Hyderabad Campus, Hyderabad 500078, Telangana, India.
EM manish.math.bhu@gmail.com; rachid@ucf.edu
RI Kumar, Manish/C-9163-2012
OI Kumar, Manish/0000-0003-2925-4218
FU Science AMP; Engineering Research Board, Government of India
   [YSS/2015/000930]
FX We thank the two anonymous referees for their valuable and insightful
   comments. The first author is grateful to the Science & Engineering
   Research Board, Government of India for providing financial support
   through project file no. YSS/2015/000930.
CR Alvarez G, 2009, COMMUN NONLINEAR SCI, V14, P3743, DOI 10.1016/j.cnsns.2009.02.033
   Arroyo D, 2008, CHAOS, V18, DOI 10.1063/1.2959102
   Bassham L. E., 2010, SPECIAL PUBLICATION
   Biham E., 1991, Proceedings of the 10th Annual International Cryptology Conference on Advances in Cryptology, CRYPTO'90, P2
   Biham E, 1993, P 12 ANN INT CRYPT C
   Boriga R, 2014, SIGNAL PROCESS-IMAGE, V29, P887, DOI 10.1016/j.image.2014.04.001
   Chang CC, 2001, J SYST SOFTWARE, V58, P83, DOI 10.1016/S0164-1212(01)00029-2
   Chen AM, 2006, PHYSICA A, V364, P103, DOI 10.1016/j.physa.2005.09.039
   Chen JY, 2011, IEEE T CIRCUITS-II, V58, P110, DOI 10.1109/TCSII.2011.2106316
   De Cannière C, 2005, EURASIP J APPL SIG P, V2005, P1923, DOI 10.1155/ASP.2005.1923
   Diaconu AV, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/932875
   El Assad S, 2016, SIGNAL PROCESS-IMAGE, V41, P144, DOI 10.1016/j.image.2015.10.004
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Huang CK, 2009, OPT COMMUN, V282, P2123, DOI 10.1016/j.optcom.2009.02.044
   Kadir A, 2014, OPTIK, V125, P1671, DOI 10.1016/j.ijleo.2013.09.040
   Kumar M, 2019, MULTIMED TOOLS APPL, V78, P10227, DOI 10.1007/s11042-018-6586-0
   Kumar M, 2016, SIGNAL PROCESS, V125, P187, DOI 10.1016/j.sigpro.2016.01.017
   Li CQ, 2017, IEEE MULTIMEDIA, V24, P64, DOI 10.1109/MMUL.2017.3051512
   Li CQ, 2010, INT J BIFURCAT CHAOS, V20, P2561, DOI 10.1142/S0218127410027192
   Li CQ, 2009, IMAGE VISION COMPUT, V27, P1035, DOI 10.1016/j.imavis.2008.09.004
   Li S., 2002, P 2002 IEEE INT C IM, V2, P925
   Li SJ, 2008, J SYST SOFTWARE, V81, P1130, DOI 10.1016/j.jss.2007.07.037
   Li SJ, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, PROCEEDINGS, P708
   Liu HJ, 2013, OPTIK, V124, P3527, DOI 10.1016/j.ijleo.2012.10.068
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu Y, 2013, SIGNAL PROCESS-IMAGE, V28, P1548, DOI 10.1016/j.image.2013.07.009
   Pathak RS, 2012, J PSEUDO-DIFFER OPER, V3, P239, DOI 10.1007/s11868-012-0047-8
   Rhouma R, 2009, CHAOS SOLITON FRACT, V40, P309, DOI 10.1016/j.chaos.2007.07.083
   Rhouma R, 2008, PHYS LETT A, V372, P5973, DOI 10.1016/j.physleta.2008.07.057
   Rhouma R, 2008, PHYS LETT A, V372, P5790, DOI 10.1016/j.physleta.2008.07.042
   Rhouma R, 2010, COMMUN NONLINEAR SCI, V15, P1887, DOI 10.1016/j.cnsns.2009.07.007
   Solak E, 2010, INT J BIFURCAT CHAOS, V20, P1405, DOI 10.1142/S0218127410026563
   Som S, 2019, MULTIMED TOOLS APPL, V78, P10373, DOI 10.1007/s11042-018-6539-7
   Tong XJ, 2015, NONLINEAR DYNAM, V80, P1493, DOI 10.1007/s11071-015-1957-9
   Wang K, 2005, PHYS LETT A, V343, P432, DOI 10.1016/j.physleta.2005.05.040
   Wang XY, 2019, MULTIMED TOOLS APPL, V78, P6191, DOI 10.1007/s11042-018-6326-5
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xie EY, 2017, SIGNAL PROCESS, V132, P150, DOI 10.1016/j.sigpro.2016.10.002
   Xiong ZG, 2019, MULTIMED TOOLS APPL, V78, P31035, DOI 10.1007/s11042-018-7081-3
   Ye GD, 2013, NONLINEAR DYNAM, V71, P259, DOI 10.1007/s11071-012-0658-x
   Ye RS, 2011, OPT COMMUN, V284, P5290, DOI 10.1016/j.optcom.2011.07.070
   Yuan HM, 2017, SIGNAL PROCESS-IMAGE, V52, P87, DOI 10.1016/j.image.2017.01.002
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhang YS, 2013, SIGNAL PROCESS-IMAGE, V28, P292, DOI 10.1016/j.image.2012.12.009
NR 46
TC 17
Z9 17
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 28025
EP 28061
DI 10.1007/s11042-019-07893-7
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000056
DA 2024-07-18
ER

PT J
AU Mathivanan, A
   Palaniswamy, S
AF Mathivanan, Anbuselvi
   Palaniswamy, Saravanan
TI Efficient fuzzy feature matching and optimal feature points for multiple
   objects tracking in fixed and active camera models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fuzzy-based matching region; SIFT; Optimal feature points; Multiple
   target tracking; Fixed and active camera
AB In computer vision, the multiple objects tracking play a vital challenging role. To solve the issues in this research field, various traditional techniques had been developed. In this paper, we consider the problem of tracking multiple persons in a dynamic environment (background) such as illumination changes and shadow moving. Notably, i) Estimating camera motion and ii) Multiple persons tracking are the two main phases involved in our proposed approach. In the first phase, the good features were extracted using both the SIFT features extraction steps and Gaussian noise elimination method. Instead of using the conventional SIFT-based matching method, we have introduced a new fuzzy matching method to create an adaptive matching zone (region). Using this, the two corresponding features from different frames can be matched perfectly. The brightness of a matching feature of interest indicates its size. Additionally, we use the magnitude and direction of the motion for accurate elimination of camera motion. In the second phase, the persons are tracked from the moving object by finding the optimal feature points and clustering of final points are made as the moving persons (objects). Experimental validation was performed on different challenging datasets and promising results are achieved by our proposed method compared to other existing methods.
C1 [Mathivanan, Anbuselvi] SSN Coll Engn, Dept ECE, Kalavakkam, Tamil Nadu, India.
   [Palaniswamy, Saravanan] SSN Coll Engn, Dept EEE, Kalavakkam, Tamil Nadu, India.
C3 SSN College of Engineering; SSN College of Engineering
RP Mathivanan, A (corresponding author), SSN Coll Engn, Dept ECE, Kalavakkam, Tamil Nadu, India.
EM manhuselviphd@gmail.com
RI Mathivanan, Anbuselvi/AFU-7646-2022; Palaniswamy,
   Saravanan/JUH-8808-2023
OI Mathivanan, Anbuselvi/0000-0001-9541-9856; 
CR Andriyenko A, 2012, PROC CVPR IEEE, P1926, DOI 10.1109/CVPR.2012.6247893
   [Anonymous], INT J ADV SCI TECHNO
   Bae SH, 2018, IEEE T PATTERN ANAL, V40, P595, DOI 10.1109/TPAMI.2017.2691769
   Bae SH, 2014, PROC CVPR IEEE, P1218, DOI 10.1109/CVPR.2014.159
   Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Beyan C, 2012, IET COMPUT VIS, V6, P1, DOI 10.1049/iet-cvi.2011.0054
   Breitenstein MD, 2011, IEEE T PATTERN ANAL, V33, P1820, DOI 10.1109/TPAMI.2010.232
   Brendel W, 2011, PROC CVPR IEEE, P1273, DOI 10.1109/CVPR.2011.5995395
   Chen Q, 2018, MULTIMED TOOLS APPL, V77, P18601, DOI 10.1007/s11042-017-5299-0
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Doyle DD, 2014, MEASUREMENT, V48, P195, DOI 10.1016/j.measurement.2013.10.025
   Fagot-Bouquet L, 2016, LECT NOTES COMPUT SC, V9912, P774, DOI 10.1007/978-3-319-46484-8_47
   Feng P, 2018, NEUROCOMPUTING, V308, P245, DOI 10.1016/j.neucom.2018.05.007
   Harland J, 2008, IEEE INT SYMP ELECTR, P1, DOI 10.1109/ISEE.2008.4562886
   He SF, 2013, PROC CVPR IEEE, P2427, DOI 10.1109/CVPR.2013.314
   Horbert E, 2011, IEEE I CONF COMP VIS, P1871, DOI 10.1109/ICCV.2011.6126455
   Hsieh YS, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE), P696, DOI 10.1109/ICCE.2012.6162066
   Hu HW, 2018, IEEE T NEUR NET LEAR, V29, P1786, DOI 10.1109/TNNLS.2017.2688448
   Hu QY, 2017, IEEE ACCESS, V5, P8568, DOI 10.1109/ACCESS.2017.2692242
   Huang C, 2013, IEEE T PATTERN ANAL, V35, P898, DOI 10.1109/TPAMI.2012.159
   Jian-Yu Hsieh, 2007, Proceedings of the Fifth IASTED International Conference on Circuits, Signals, and Systems, P1, DOI 10.1145/1329125.1329139
   Jung B., 2004, International Conference on Intelligent Autonomous Systems, P980
   Kuo CH, 2010, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2010.5540148
   Leal-Taixé L, 2016, IEEE COMPUT SOC CONF, P418, DOI 10.1109/CVPRW.2016.59
   Leibe B, 2008, IEEE T PATTERN ANAL, V30, P1683, DOI 10.1109/TPAMI.2008.170
   Li K, 2018, J COMPUT SCI TECH-CH, V33, P223, DOI 10.1007/s11390-017-1764-5
   Li LQ, 2018, NEUROCOMPUTING, V281, P139, DOI 10.1016/j.neucom.2017.11.060
   Lim J, 2013, MULTIMED TOOLS APPL, V65, P161, DOI 10.1007/s11042-012-1156-3
   Lim JS, 2005, LECT NOTES COMPUT SC, V3804, P527
   Lin Y., 2018, Advances in Computer and Computational Sciences, P487
   Linlin Yang, 2016, Advances in Multimedia Information Processing - PCM 2016. 17th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 9917, P680, DOI 10.1007/978-3-319-48896-7_67
   Liu JY, 2018, IEEE T INTELL TRANSP, V19, P151, DOI 10.1109/TITS.2017.2750058
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Milan A, 2017, AAAI CONF ARTIF INTE, P4225
   Milan A, 2015, PROC CVPR IEEE, P5397, DOI 10.1109/CVPR.2015.7299178
   Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103
   Pirsiavash H, 2011, PROC CVPR IEEE, P1201, DOI 10.1109/CVPR.2011.5995604
   Siam M., 2012, Proceedings of the 2012 IEEE International Conference on Robotics and Biomimetics (ROBIO), P2399, DOI 10.1109/ROBIO.2012.6491329
   Son J, 2017, PROC CVPR IEEE, P3786, DOI 10.1109/CVPR.2017.403
   Stolkin R., 2012, 2012 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI 2012), P192, DOI 10.1109/MFI.2012.6343021
   Sundararaj V, INT J INTELLIGENT EN, V9, P117
   Sundararaj V, 2019, WIRELESS PERS COMMUN, V104, P173, DOI 10.1007/s11277-018-6014-9
   Sundararaj V, 2018, COMPUT SECUR, V77, P277, DOI 10.1016/j.cose.2018.04.009
   Tang SY, 2013, IEEE I CONF COMP VIS, P1049, DOI 10.1109/ICCV.2013.134
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Vicente TFY, 2018, IEEE T PATTERN ANAL, V40, P682, DOI 10.1109/TPAMI.2017.2691703
   Wang B, 2017, IEEE T PATTERN ANAL, V39, P589, DOI 10.1109/TPAMI.2016.2551245
   Wen JM, 2017, IEEE T SIGNAL PROCES, V65, P5347, DOI 10.1109/TSP.2017.2728502
   Yang M, 2017, IEEE T IMAGE PROCESS, V26, P5667, DOI 10.1109/TIP.2017.2745103
   Yilmaz A, 2004, IEEE T PATTERN ANAL, V26, P1531, DOI 10.1109/TPAMI.2004.96
   Yoon JH, 2016, PROC CVPR IEEE, P1392, DOI 10.1109/CVPR.2016.155
   Yoon JH, 2015, IEEE WINT CONF APPL, P33, DOI 10.1109/WACV.2015.12
   Yu FW, 2016, LECT NOTES COMPUT SC, V9914, P36, DOI 10.1007/978-3-319-48881-3_3
   Zhang BC, 2018, IEEE T IMAGE PROCESS, V27, P1038, DOI 10.1109/TIP.2017.2775060
   Zhang BC, 2017, IEEE T SYST MAN CY-S, V47, P693, DOI 10.1109/TSMC.2016.2629509
NR 56
TC 1
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27245
EP 27270
DI 10.1007/s11042-019-07825-5
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000021
DA 2024-07-18
ER

PT J
AU Yousefi, MHN
   Kavian, YS
   Mahmoudi, A
AF Yousefi, Mehdi Hadadian Nejad
   Kavian, Yousef S.
   Mahmoudi, Alimorad
TI On the processing architecture in wireless video sensor networks: node
   and network level performance evaluation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless video sensor networks; Performance evaluation; Processing
   architectures; FPGA measurement
ID SYSTEM; ROBOT
AB The architecture of a wireless video sensor network node has an impact on the performance of a wireless sensor network. Due to nature of WVSN applications, the node should be capable of potentially performing image processing algorithms while simultaneously has high networking capabilities. Providing an optimum architecture in which both parameters are addressed is the main challenge in WVSN. This paper reviews suggested architectures for the node and based on that three base architectures are proposed and implemented. The performance of the nodes is then evaluated at node and network level and the results are included in the paper. Based on the results, an optimized architecture is introduced. This architecture separates the node to a network and an application part. This brings the flexibility of implementing the optimized solution for each part, without considering the other. The network part is implemented using a microcontroller. It is capable of adopting operating systems that are widely used in Wireless Sensor Networks. On the other hand, the application part is implemented using FPGA, that provides a power-optimized and stand-alone solution for the node with high computation capabilities.
C1 [Yousefi, Mehdi Hadadian Nejad; Kavian, Yousef S.; Mahmoudi, Alimorad] Shahid Chamran Univ Ahvaz, Fac Engn, Golestan Blvd, Ahvaz, Khouzestan, Iran.
C3 Shahid Chamran University of Ahvaz
RP Kavian, YS (corresponding author), Shahid Chamran Univ Ahvaz, Fac Engn, Golestan Blvd, Ahvaz, Khouzestan, Iran.
EM y.s.kavian@scu.ac.ir
RI Mahmoudi, Alimorad/Q-6999-2019
OI Mahmoudi, Alimorad/0000-0002-4621-5117
CR Ahn HS, 2009, IEEE T CONSUM ELECTR, V55, P1487, DOI 10.1109/TCE.2009.5278017
   Al Najjar M, 2014, VIDEO SURVEILLANCE S
   Alanazi A, 2015, SENSORS-BASEL, V15, P22209, DOI 10.3390/s150922209
   [Anonymous], P COGNITIVE SYST INT
   Arth C., 2006, P IEEE COMP SOC C CO
   Aziz SM, 2013, IEEE COMMUN LETT, V17, P1084, DOI 10.1109/LCOMM.2013.050313.121933
   Braeken A, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010032
   Bramberger M, 2004, RTAS 2004: 10TH IEEE REAL-TIME AND EMBEDDED TECHNOLOGY AND APPLICATIONS SYMPOSIUM, PROCEEDINGS, P174, DOI 10.1109/RTTAS.2004.1317262
   Cao NY, 2017, IEEE T CIRCUITS-I, V64, P2470, DOI 10.1109/TCSI.2017.2716358
   Chapman K., 2003, Xilinx Application Notes
   Chen P, 2013, ACM T SENSOR NETWORK, V9, DOI 10.1145/2422966.2422978
   Civelek M, 2017, IEEE SENS J, V17, P1116, DOI 10.1109/JSEN.2016.2638853
   Pham C, 2013, IEEE CONF WIREL MOB, P477, DOI 10.1109/WiMOB.2013.6673402
   Conti M, 2009, LECT NOTES ELECTR EN, V38, P3
   Garcia-Sanchez AJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16050643
   Hengstler S, 2007, PROCEEDINGS OF THE SIXTH INTERNATIONAL SYMPOSIUM ON INFORMATION PROCESSING IN SENSOR NETWORKS, P360, DOI 10.1109/IPSN.2007.4379696
   Imran M, 2012, IEEE T CIRC SYST VID, V22, P1634, DOI 10.1109/TCSVT.2012.2202189
   Jelicic V, 2014, IEEE SENS J, V14, P3210, DOI 10.1109/JSEN.2014.2326799
   Ko JH, 2015, IEEE T MULTI-SCALE C, V1, P7, DOI 10.1109/TMSCS.2015.2478469
   Kulkarni P., 2005, 13th Annual ACM International Conference on Multimedia, P229, DOI 10.1145/1101149.1101191
   Libelium, 2014, VID CAM TECHN GUID, P1
   Magno M, 2013, IEEE J EM SEL TOP C, V3, P223, DOI 10.1109/JETCAS.2013.2256833
   Mekonnen T, 2017, IEEE ACCESS, V5, P15848, DOI 10.1109/ACCESS.2017.2737078
   Nachman Lama, 2008, 2008 International Wireless Communications and Mobile Computing Conference Conference, P1118, DOI 10.1109/IWCMC.2008.194
   Norem J, 2015, MAKING SENSE OUT 8 B
   Rahimi Mohammad., 2005, SENSYS 05, P192
   Seema A, 2011, IEEE COMMUN SURV TUT, V13, P462, DOI 10.1109/SURV.2011.102910.00098
   Texas Instruments, 2004, CC2420 2 4 GHZ IEEE
   Xie D, 2008, 2008 INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS, PROCEEDINGS, P469, DOI 10.1109/IPSN.2008.57
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Zhang J, 2011, IEEE T CONSUM ELECTR, V57, P1774, DOI 10.1109/TCE.2011.6131153
NR 31
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24789
EP 24807
DI 10.1007/s11042-019-7709-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900051
DA 2024-07-18
ER

PT J
AU Aghamaleki, JA
   Chenarlogh, VA
AF Aghamaleki, Javad Abbasi
   Chenarlogh, Vahid Ashkani
TI Multi-stream CNN for facial expression recognition in limited training
   data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression recognition; Convolutional neural network; Limited
   data; Multi-stream structure
ID FACE
AB Limited data is a challenging problem to train Convolutional Neural Networks. On the other hand, acquiring a database in a demanded scale is not a straightforward task. In this paper, handcrafted features along with a multi-stream structure are proposed as a solution to improve performance of limited data via CNN. Three handcrafted features using local binary pattern code extractor and Sobel edge detection operator in horizontal and vertical directions of images have been extracted to apply to the multi-stream CNN model. Our model is based on two distinct structures including three-stream and single-stream structures. The three-stream structure can be employed to improve the recognition rate in facial expression classifiers when the training data is limited. In three-stream structure, each of information channels will be added to distinct streams separately. Furthermore, the transfer learning technique employed and behaviour of VGG16 architecture trained with limited data have been studied to be compared with the proposed method. In addition, input data is expanded by means of rotation, cropping, and flipping. Next, three-stream and single-stream structures are examined while using limited and also expanded training data. We have evaluated the mentioned system in order to compare it with state of the arts for CK+ and MUG databases in both limited-data and expanded-data. The results indicate that by using limited-data, recognition accuracy will be improved through the mentioned strategy. (92.19 to 88.95 in CK+ database and 85.4 to 82.5 in MUG database). Additionally, the performance was improved in comparison with benchmark methods.
C1 [Aghamaleki, Javad Abbasi] Damgham Univ, Fac Engn Dept, Damghan, Iran.
   [Chenarlogh, Vahid Ashkani] Islamic Azad Univ, Sci & Res Branch, ECE Dept, Tehran, Iran.
C3 Islamic Azad University
RP Aghamaleki, JA (corresponding author), Damgham Univ, Fac Engn Dept, Damghan, Iran.
EM J.a.aghamaleki@du.ac.ir
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Aifanti N., 2010, P 11 INT WORKSH IM A, DOI DOI 10.1371/JOURNAL.PONE.0009715
   Alam M.N., 2019, IEEE Trans. Ind. Informatics, V15, P64, DOI DOI 10.1109/TII.2018.2834474
   [Anonymous], 2017, MULTIMED TOOLS APPL
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], P 18 INT C PATT REC
   [Anonymous], IET COMPUT VIS
   [Anonymous], P 2015 INT JOINT C N
   [Anonymous], IET 6 INT C WIR MOB
   [Anonymous], 2016, ARXIV150905371V2
   [Anonymous], 2017, ELECTRON LETT, DOI DOI 10.1049/el.2016.4328
   [Anonymous], DEEP TEMPORAL APPEAR
   Byeon YH, 2014, INT J ADV COMPUT SC, V5, P107, DOI 10.14569/ijacsa.2014.051215
   Dahl GE, 2013, INT CONF ACOUST SPEE, P8609, DOI 10.1109/ICASSP.2013.6639346
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Gao WS, 2010, INT CONF COMP SCI, P67, DOI 10.1109/ICCSIT.2010.5563693
   Ghasemzadeh A, 2018, IET BIOMETRICS, V7, P49, DOI 10.1049/iet-bmt.2017.0082
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   He T, 2017, NEURAL COMPUT APPL, V28, P3827, DOI 10.1007/s00521-016-2277-9
   Ng HW, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P443, DOI 10.1145/2818346.2830593
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Khan AS, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P623, DOI 10.1145/3242969.3264987
   Khorrami P, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P19, DOI 10.1109/ICCVW.2015.12
   Kumar S, 2016, IET COMPUT VIS, V10, P567, DOI 10.1049/iet-cvi.2015.0273
   Lajevardi Seyed Mehdi, 2008, 2008 Digital Image Computing: Techniques and Applications, P77, DOI 10.1109/DICTA.2008.13
   Levi G, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P503, DOI 10.1145/2823327.2823333
   Liu P, 2014, LECT NOTES COMPUT SC, V8692, P151, DOI 10.1007/978-3-319-10593-2_11
   Liu Y, 2016, ADVANCES OF ATOMS AND MOLECULES IN STRONG LASER FIELDS, P1
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   Lopes AT, 2015, SIBGRAPI, P273, DOI 10.1109/SIBGRAPI.2015.14
   Lucey P., 2010, ieee computer society conference on computer vision and pattern recognition-workshops, P94
   Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4
   Mayer C., 2014, Pattern Recognition and Image Analysis, V24, P124, DOI 10.1134/S1054661814010106
   Meng ZB, 2017, IEEE INT CONF AUTOMA, P558, DOI 10.1109/FG.2017.140
   Mollaeian Aida, 2016, 2016 IEEE Conference on Electromagnetic Field Computation (CEFC), DOI 10.1109/CEFC.2016.7816397
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Sajjad M, 2017, CLUSTER COMPUT, P1
   Simons KA, 2014, ADV ACC EDUC-TEACH, V15, P1, DOI 10.1108/S1085-462220140000015001
   Sun Z, 2018, SIGNAL IMAGE VIDEO P, V12, P835, DOI 10.1007/s11760-017-1226-0
   Yacoob Y, 1996, IEEE T PATTERN ANAL, V18, P636, DOI 10.1109/34.506414
   Yu ZD, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P435
   Zhan YZ, 2006, INT J IMAGE GRAPH, V6, P125, DOI 10.1142/S0219467806002112
   Zhang MW, 2018, MULTIMED TOOLS APPL, V77, P3303, DOI 10.1007/s11042-017-5116-9
NR 45
TC 22
Z9 23
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22861
EP 22882
DI 10.1007/s11042-019-7530-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400031
DA 2024-07-18
ER

PT J
AU Ahmadi, M
   Kazemi, K
   Aarabi, A
   Niknam, T
   Helfroush, MS
AF Ahmadi, Maliheh
   Kazemi, Kamran
   Aarabi, Ardalan
   Niknam, Taher
   Helfroush, Mohammad Sadegh
TI Image segmentation using multilevel thresholding based on modified bird
   mating optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Multilevel thresholding; Bird mating optimization;
   Differential evolutionary
ID PARTICLE SWARM OPTIMIZATION; DIFFERENTIAL EVOLUTION; GENETIC ALGORITHM;
   ENTROPY; PERFORMANCE; KAPURS
AB Multilevel thresholding using Otsu or Kapur methods is widely used in the context of image segmentation. These methods select optimal thresholds in gray level images by maximizing between-class variance or entropy criterion. These methods become time consuming and less efficient with increasing number of thresholds. To increase the efficiency of the image segmentation using multilevel thresholding based on Kapur and Otsu methods, we developed a hybrid optimization algorithm named BMO-DE based on bird mating optimization (BMO) and differential evolutionary (DE) algorithms. The efficiency of the proposed method was evaluated on eight standard benchmark images. The proposed method achieved better segmentation results in term of solution quality and stability in comparison with other well-known techniques including bacterial foraging (BF), modified bacterial foraging (MBF), particle swarm optimization (PSO), genetic algorithm (GA) and hybrid algorithm named PSO-DE.
C1 [Ahmadi, Maliheh; Kazemi, Kamran; Niknam, Taher; Helfroush, Mohammad Sadegh] Shiraz Univ Technol, Dept Elect & Elect Engn, Shiraz, Iran.
   [Aarabi, Ardalan] CHU AMIENS SITE SUD, Univ Res Ctr, CURS, LFNP,EA4559, Ave Laennec, F-80420 Salouel, France.
   [Aarabi, Ardalan] Univ Picardie Jules Verne, Fac Med, F-80036 Amiens, France.
C3 Shiraz University of Technology; Universite de Picardie Jules Verne
   (UPJV); CHU Amiens; Universite de Picardie Jules Verne (UPJV)
RP Kazemi, K (corresponding author), Shiraz Univ Technol, Dept Elect & Elect Engn, Shiraz, Iran.
EM kazemi@sutech.ac.ir
RI Aarabi, Ardalan/ABA-8108-2020; Niknam, Taher/HGD-8028-2022; Niknam,
   Taher/L-8826-2017; Helfroush, Sadegh/ABE-9961-2021
OI Aarabi, Ardalan/0000-0001-5141-9248; Niknam, Taher/0000-0002-9391-6901; 
CR Abd El Aziz M, 2017, EXPERT SYST APPL, V83, P242, DOI 10.1016/j.eswa.2017.04.023
   Agrawal S, 2013, SWARM EVOL COMPUT, V11, P16, DOI 10.1016/j.swevo.2013.02.001
   Akay B, 2013, APPL SOFT COMPUT, V13, P3066, DOI 10.1016/j.asoc.2012.03.072
   Ali M, 2014, APPL SOFT COMPUT, V17, P1, DOI 10.1016/j.asoc.2013.11.018
   [Anonymous], 2015, STATIST OPTIM INF CO
   [Anonymous], 2017, IJCAI
   [Anonymous], 1981, TJCG P PROCESSING I, V16, P210
   Askarzadeh A, 2014, COMMUN NONLINEAR SCI, V19, P1213, DOI 10.1016/j.cnsns.2013.08.027
   Bayraktar Z, 2013, IEEE T ANTENN PROPAG, V61, P2745, DOI 10.1109/TAP.2013.2238654
   Ben Ishak A, 2017, APPL SOFT COMPUT, V52, P306, DOI 10.1016/j.asoc.2016.10.034
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P1573, DOI 10.1016/j.eswa.2014.09.049
   Bhandari AK, 2014, EXPERT SYST APPL, V41, P3538, DOI 10.1016/j.eswa.2013.10.059
   Chen C., 2011, International Journal ofBiomedical Imaging, V2011, P8
   Cruz-Aceves I, 2013, MULTIPLE ACTIVE CONT, V2013
   Elsayed SM, 2014, ENG APPL ARTIF INTEL, V27, P57, DOI 10.1016/j.engappai.2013.09.013
   Freixenet J, 2002, LECT NOTES COMPUT SC, V2352, P408, DOI 10.1007/3-540-47977-5_27
   Hamdaoui F, 2016, INT J SIGNAL IMAGING, V9, P218, DOI 10.1504/IJSISE.2016.078261
   Hammouche K, 2008, COMPUT VIS IMAGE UND, V109, P163, DOI 10.1016/j.cviu.2007.09.001
   Horng MH, 2011, EXPERT SYST APPL, V38, P13785, DOI 10.1016/j.eswa.2011.04.180
   Horng MH, 2010, APPL MATH COMPUT, V215, P3302, DOI 10.1016/j.amc.2009.10.018
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Khairuzzaman AKM, 2017, EXPERT SYST APPL, V86, P64, DOI 10.1016/j.eswa.2017.04.029
   Khorram B, 2018, NEW OPTIMIZED THRESH, P1
   LEE SU, 1990, COMPUT VISION GRAPH, V52, P171, DOI 10.1016/0734-189X(90)90053-X
   Li G, 2013, SELF ADAPTIVE PARAME, V2013
   Magudeeswaran V, 2013, FUZZY LOGIC BASED HI, V2013
   Maitra M, 2008, MEASUREMENT, V41, P1124, DOI 10.1016/j.measurement.2008.03.002
   Manikantan K, 2012, PROCEDIA ENGINEER, V30, P364, DOI 10.1016/j.proeng.2012.01.873
   Niknam T, 2011, ELECTR POW COMPO SYS, V39, P158, DOI 10.1080/15325008.2010.526990
   NJItos Otsu, 1979, THRESHOLD SELECTION, V9, P62
   Nouri F, 2018, APPL SALIENT OBJECT, P1
   Nyma A, 2012, HYBRID TECHNIQUE MED, V2012
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Panda R, 2013, EXPERT SYST APPL, V40, P7617, DOI 10.1016/j.eswa.2013.07.060
   Raja NSM, 2012, LECT NOTES COMPUT SC, V7677, P380, DOI 10.1007/978-3-642-35380-2_45
   Sarkar S, 2016, EXPERT SYST APPL, V50, P120, DOI 10.1016/j.eswa.2015.11.016
   Sarkar S, 2012, LECT NOTES COMPUT SC, V7677, P17, DOI 10.1007/978-3-642-35380-2_3
   Sathya P., 2010, International Journal of Computer Science Issues, V7, P336
   Sathya PD, 2011, MEASUREMENT, V44, P1828, DOI 10.1016/j.measurement.2011.09.005
   Sathya PD, 2011, ENG APPL ARTIF INTEL, V24, P595, DOI 10.1016/j.engappai.2010.12.001
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Shahvaran Z, 2012, J NEUROSCI METH, V209, P280, DOI 10.1016/j.jneumeth.2012.06.012
   Shi Z, 2016, MANY IS BETTER ONE I, V2016
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Su Q., 2013, COMPUTATIONAL INTELL, V2013, P3
   Su X, 2013, IMAGE ENHANCEMENT ME, V2013
   Yahya AA, 2013, NOVEL MODEL IMAGE SE, V2013, P5
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhao JJ, 2015, INT J BIO-INSPIR COM, V7, P62, DOI 10.1504/IJBIC.2015.067999
NR 49
TC 29
Z9 29
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23003
EP 23027
DI 10.1007/s11042-019-7515-6
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400037
DA 2024-07-18
ER

PT J
AU Kumar, R
   Chand, S
   Singh, S
AF Kumar, Rajeev
   Chand, Satish
   Singh, Samayveer
TI An optimal high capacity reversible data hiding scheme using move to
   front coding for LZW codes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Move to front; LZW codes; Data hiding;
   Compression
ID PERFORMANCE
AB Reversible Data hiding techniques reduce transmission cost as secret data is embedded into a cover image without increasing its size in such a way that at the receiving end, both secret data and the cover image can be extracted and recovered, respectively, to their original form. To further reduce the transmission cost, the secret data can be embedded in the compression codes by some popular reversible data hiding schemes. One of the popular and important reversible data hiding method is high- performance data-hiding Lempel-Ziv-Welch (HPDH-LZW) scheme which hides the secret data in LZW codes. In this paper, the HPDH-LZW scheme is modified in order to increase its hiding capacity and compression ratio. First, the proposed work modifies the Move to Front (MTF) encoding technique to hide the secret data and also to increase the similarity among the element of the cover media. Then, LZW encoding technique is applied on the resultant cover data to obtain LZW codes, which are used to hide further secret data. Experimental results show that the proposed scheme has significantly increased the data hiding capacity and have good embedding and extraction speed in comparison to other state of the art schemes.
C1 [Kumar, Rajeev] Kyungil Univ, Dept Cyber Secur, Gyongsan, South Korea.
   [Chand, Satish] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi, India.
   [Singh, Samayveer] Natl Inst Technol, Dept Comp Sci & Engn, Jalandhar, Punjab, India.
C3 Kyungil University; Jawaharlal Nehru University, New Delhi; National
   Institute of Technology (NIT System); Dr B R Ambedkar National Institute
   of Technology Jalandhar
RP Singh, S (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Jalandhar, Punjab, India.
EM rajeevgargnsit@gmail.com; schand20@gmail.com; samayveersingh@gmail.com
RI Singh, Samayveer/X-8119-2019; Kumar, Rajeev/IUP-5006-2023
OI Singh, Samayveer/0000-0002-4199-721X; Kumar, Rajeev/0000-0002-5000-7644
CR Aabed MA, 2007, ICSPC: 2007 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATIONS, VOLS 1-3, PROCEEDINGS, P756
   BENTLEY JL, 1986, COMMUN ACM, V29, P320, DOI 10.1145/5684.5688
   Chang C. C., 2009, INT J COMPUTER SCI E, V3, P55
   Chang C-C., 2018, INT J NETWORK SECUR, V20, P478
   Chang CC, 2006, IEEE T CIRC SYST VID, V16, P1301, DOI 10.1109/TCSVT.2006.882380
   Chang CC, 2006, J SYST SOFTWARE, V79, P1120, DOI 10.1016/j.jss.2005.11.576
   Chang CC, 2010, INFORM SCIENCES, V180, P3045, DOI 10.1016/j.ins.2010.03.027
   Chang-Chu Chen, 2010, Proceedings 2010 Second International Conference on Computer Modeling and Simulation (ICCMS), P3, DOI 10.1109/ICCMS.2010.346
   Chang CC, 2007, INFORM SCIENCES, V177, P1796, DOI 10.1016/j.ins.2006.09.014
   Guo JM, 2012, DIGIT SIGNAL PROCESS, V22, P776, DOI 10.1016/j.dsp.2012.04.004
   Gutub AAA, 2007, PROC WRLD ACAD SCI E, V21, P28
   Hong W, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10020036
   Kumar A., 2010, Int. J Comput. Appl., V9, P19
   Kumar R., 2018, INT J MULTIMED INTEL, V3, P146, DOI [10.1504/IJMIS.2018.096356, DOI 10.1504/IJMIS.2018.096356]
   Kumar R, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P1399, DOI 10.1109/CCAA.2016.7813937
   Kumar R, 2017, MULTIMED TOOLS APPL, V76, P979, DOI 10.1007/s11042-015-3069-4
   Li B., 2011, P 2011 INT C MULTIME, VVolume 1, P37, DOI [10.1109/CMSP.2011.16, DOI 10.1109/CMSP.2011.16]
   Malik A, 2016, AICTC 16, P1
   Malik A, 2017, MULTIMED TOOLS APPL, V76, P14151, DOI 10.1007/s11042-016-3815-2
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Salah K, 2008, I C COMP SYST APPLIC, P392, DOI 10.1109/AICCSA.2008.4493563
   Shim HJ, 2004, IEEE IMAGE PROC, P2195
   Sindhuja J, 2016, INT J EMERGING TECHN, V20, P172
   Wang ZH, 2013, J SYST SOFTWARE, V86, P2771, DOI 10.1016/j.jss.2013.06.024
   Xue Y, 2018, SOFT COMPUT, V22, P4445, DOI 10.1007/s00500-017-2651-2
   Yang B, 2011, P INT J ELECT COMMUN, V65, P814, DOI DOI 10.1016/J.AEUE.2011.01.014
   Zhao WQ, 2016, ACSR ADV COMPUT, V56, P150
NR 27
TC 14
Z9 15
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22977
EP 23001
DI 10.1007/s11042-019-7640-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400036
DA 2024-07-18
ER

PT J
AU Li, M
   Xiao, D
   Zhu, Y
   Zhang, YS
   Sun, L
AF Li, Ming
   Xiao, Di
   Zhu, Ye
   Zhang, Yushu
   Sun, Lin
TI Commutative fragile zero-watermarking and encryption for image integrity
   protection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Commutative; Zero-watermarking; Encryption; Integrity protection;
   Fragile
ID ALGORITHM; SCHEME
AB With the increasing demands of privacy protection and integrity protection of digital images, attention has been drawn to the commutativity of watermarking and encryption. In some of the existing works, watermarking and image encryption are commutative, but watermark detection and image decryption are not commutative. Meanwhile, in some other schemes, watermark detection and image decryption are commutative, but the order of watermarking and image encryption is fixed. The existing schemes cannot meet the requirement of commutativity. Therefore, we propose a novel commutative zero-watermarking and encryption scheme, in which the commutativity is equipped in both the phases of watermarking and image encryption and the phases of watermark detection and image decryption. The proposed scheme is fragile, and the zero-watermarking will not cause any modification of the image. Experiments show that the proposed scheme is effective and feasible. The illegal tampered area of the zero-watermarked image can be accurately detected and located.
C1 [Li, Ming; Sun, Lin] Henan Normal Univ, Coll Comp & Informat Engn, Xinxiang 453007, Henan, Peoples R China.
   [Xiao, Di] Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
   [Zhu, Ye; Zhang, Yushu] Deakin Univ, Sch Informat Technol, Burwood, Vic 3125, Australia.
   [Zhang, Yushu] Guilin Univ Elect Technol, Guangxi Key Lab Trusted Software, Guilin 541004, Peoples R China.
C3 Henan Normal University; Chongqing University; Deakin University; Guilin
   University of Electronic Technology
RP Xiao, D (corresponding author), Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
EM xiaodi_cqu@hotmail.com
RI Li, Ming/Q-6532-2016
OI zhu, ye/0000-0003-4776-4932
FU National Natural Science Foundation of China [61602158, 61572089,
   61502399, 61772176]; Natural Science Foundation of Chongqing Science and
   Technology Commission [cstc2017jcyjBX0008]; Guangxi Key Laboratory of
   Trusted Software; Science and Technology Research Project of Henan
   Province [182102210374]; Science Foundation for the Excellent Youth
   Scholars of Henan Normal University [YQ201607]; Chongqing Postgraduate
   Education Reform Project [yjg183018]
FX The work was funded by the National Natural Science Foundation of China
   (Grant Nos. 61602158, 61572089, 61502399, 61772176), the Natural Science
   Foundation of Chongqing Science and Technology Commission (Grant No.
   cstc2017jcyjBX0008), the Guangxi Key Laboratory of Trusted Software, the
   Science and Technology Research Project of Henan Province
   (182102210374), the Science Foundation for the Excellent Youth Scholars
   of Henan Normal University (YQ201607) and the Chongqing Postgraduate
   Education Reform Project (Grant No. yjg183018).
CR Bravo-Solorio S, 2018, DIGIT SIGNAL PROCESS, V73, P83, DOI 10.1016/j.dsp.2017.11.005
   Cancellaro M, 2011, SIGNAL PROCESS-IMAGE, V26, P1, DOI 10.1016/j.image.2010.11.001
   Fan MQ, 2018, SIGNAL PROCESS-IMAGE, V66, P19, DOI 10.1016/j.image.2018.04.003
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Jiang L, 2014, MULTIMED TOOLS APPL, V70, P1617, DOI 10.1007/s11042-012-1181-2
   Khan A, 2013, SCI WORLD J, DOI 10.1155/2013/796726
   Lian SG, 2009, MULTIMED TOOLS APPL, V43, P91, DOI 10.1007/s11042-008-0258-4
   Liu S, 2015, SIGNAL PROCESS, V109, P345, DOI 10.1016/j.sigpro.2014.06.024
   Liu XY, 2017, SIGNAL PROCESS-IMAGE, V54, P140, DOI 10.1016/j.image.2017.03.002
   Liu YB, 2012, COMMUN NONLINEAR SCI, V17, P3267, DOI 10.1016/j.cnsns.2011.11.040
   Liu YL, 2015, J CHIN INST ENG, V38, P391, DOI 10.1080/02533839.2014.981210
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Mondal B, 2018, MULTIMED TOOLS APPL, V77, P31177, DOI 10.1007/s11042-018-6214-z
   Nazari M, 2017, MULTIMED TOOLS APPL, V76, P16107, DOI 10.1007/s11042-016-3897-x
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Savelonas MA, 2010, SIGNAL PROCESS, V90, P2521, DOI 10.1016/j.sigpro.2010.02.021
   Simitopoulos D, 2003, MULTIMEDIA SYST, V9, P217, DOI 10.1007/s00530-003-0093-4
   Subramanyam AV, 2012, IEEE T MULTIMEDIA, V14, P703, DOI 10.1109/TMM.2011.2181342
   Thanh TM, 2017, MULTIMED TOOLS APPL, V76, P13455, DOI 10.1007/s11042-016-3750-2
   Tang X, 2015, CHINESE J ELECTRON, V24, P492, DOI 10.1049/cje.2015.07.009
   Wang CP, 2017, MULTIMED TOOLS APPL, V76, P26355, DOI 10.1007/s11042-016-4130-7
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Xiang LY, 2018, CMC-COMPUT MATER CON, V55, P541, DOI 10.3970/cmc.2018.03510
   Yang CF, 2018, SCI CHINA INFORM SCI, V61, DOI 10.1007/s11432-017-9328-2
   Yang Y, 2016, CHINA COMMUN, V13, P122, DOI 10.1109/CC.2016.7559084
   Zhang XP, 2013, SECUR COMMUN NETW, V6, P1396, DOI 10.1002/sec.742
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
NR 28
TC 17
Z9 18
U1 1
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22727
EP 22742
DI 10.1007/s11042-019-7560-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400025
DA 2024-07-18
ER

PT J
AU Poon, G
   Kwan, KC
   Pang, WM
AF Poon, Geoffrey
   Kwan, Kin Chung
   Pang, Wai-Man
TI Occlusion-robust bimanual gesture recognition by fusing multi-views
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gesture recognition; Bimanual gesture; Multiview; Learning based
   recognition; Occlusion; Ensemble of classifiers
AB Human hands are dexterous and always be an intuitive way to instruct or communicate with peers. In recent years, hand gesture is widely used as a novel way for human computer interaction as well. However, existing approaches target solely to recognize single-handed gesture, but not gestures with two hands in close proximity (bimanual gesture). Thus, this paper tries to tackle the problems in bimanual gestures recognition which are not well studied from the literature. To overcome the critical issue of hand-hand self-occlusion problem in bimanual gestures, multiple cameras from different view points are used. A tailored multi-camera system is constructed to acquire multi-views bimanual gesture data. By employing both shape and color features, classifiers are trained with our bimanual gestures dataset. A weighted sum fusion scheme is employed to ensemble results predicted from different classifiers. While, the weightings in the fusion are optimized according to how well the recognition performed on a particular view. Our experiments show that multiple-view results outperform single-view results. The proposed method is especially suitable to interactive multimedia applications, such as our two demo programs: a video game and a sign language learner.
C1 [Poon, Geoffrey; Kwan, Kin Chung; Pang, Wai-Man] Caritas Inst Higher Educ, Sch Comp & Informat Sci, Tseung Kwan O, Hong Kong, Peoples R China.
C3 Saint Francis University Hong Kong
RP Pang, WM (corresponding author), Caritas Inst Higher Educ, Sch Comp & Informat Sci, Tseung Kwan O, Hong Kong, Peoples R China.
EM wmpang@ieee.org
OI Pang, Wai Man/0000-0002-4554-4517
FU Research Grants Council of the Hong Kong SAR, China [UGC/FDS11/E03/15]
FX The work described in this paper was fully supported by a grant from the
   Research Grants Council of the Hong Kong SAR, China (Ref. No.
   UGC/FDS11/E03/15).
CR [Anonymous], P ICCV
   [Anonymous], P CVPR
   [Anonymous], 2011, P 5 IEEE INT C AUTOM
   [Anonymous], MULTICHANNEL CONVOLU
   [Anonymous], P CVPR
   Bengio Yann Le Cunand Yoshua, 1998, HDB BRAIN THEORY NEU, P255
   Bulugu I, 2016, INT J COMPUT APPL, V135, P1
   Chen MY, 2013, IEEE T MULTIMEDIA, V15, P561, DOI 10.1109/TMM.2012.2237024
   Chen Z. H., 2014, SCI WORLD J, V2014
   Cheng H, 2016, IEEE T CIRC SYST VID, V26, P1659, DOI 10.1109/TCSVT.2015.2469551
   Deng X., 2017, CORR
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   FOGEL I, 1989, BIOL CYBERN, V61, P103, DOI 10.1007/BF00204594
   HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871
   Joshi P, 2015, WATER ECON POLICY, V1, DOI 10.1142/S2382624X15500010
   Karime A, 2011, IEEE INT C MULT EXP
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Kristensson P.O., 2012, P 2012 ACM INT C INT, P89
   Leite DQ, 2016, MULTIMED TOOLS APPL, P1
   Li M, 2016, IEEE T MULTIMEDIA, V18, P2293, DOI 10.1109/TMM.2016.2614228
   Molchanov Pavlo, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P1, DOI 10.1109/CVPRW.2015.7301342
   Molchanov P., 2016, Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, P4207, DOI DOI 10.1109/CVPR.2016.456
   Oikonomidis I, 2012, PROC CVPR IEEE, P1862, DOI 10.1109/CVPR.2012.6247885
   Parvini F, 2009, LECT NOTES COMPUT SC, V5611, P236, DOI 10.1007/978-3-642-02577-8_26
   Potter L.E., 2013, P 25 AUSTR COMPUTER, P175, DOI [10.1145/2541016.2541072, DOI 10.1145/2541016.2541072]
   Poularakis Stergios, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P4329, DOI 10.1109/ICASSP.2014.6854419
   Rahman N., 2006, MMU INT S INF COMM T
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   Saeed A., 2011, 2011 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2011), P238, DOI 10.1109/ICSIPA.2011.6144134
   Sarkar A.R., 2013, Int. J. Comput. Appl, V71
   Schramm R, 2015, IEEE T MULTIMEDIA, V17, P243, DOI 10.1109/TMM.2014.2377553
   Singha J, 2017, MULTIMEDIA SYST, V23, P499, DOI 10.1007/s00530-016-0510-0
   Tang A, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2735952
   Tax DMJ, 2000, PATTERN RECOGN, V33, P1475, DOI 10.1016/S0031-3203(99)00138-7
   Tzionas D, 2016, INT J COMPUT VISION, V118, P172, DOI 10.1007/s11263-016-0895-4
   Wang C, 2015, IEEE T MULTIMEDIA, V17, P29, DOI 10.1109/TMM.2014.2374357
   Wang R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531397
   Wu GL, 2016, IEEE T MULTIMEDIA, V18, P978, DOI 10.1109/TMM.2016.2545401
   Zen G, 2016, IEEE T MULTIMEDIA, V18, P775, DOI 10.1109/TMM.2016.2523421
NR 41
TC 8
Z9 10
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23469
EP 23488
DI 10.1007/s11042-019-7660-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400056
DA 2024-07-18
ER

PT J
AU Verma, VS
   Bhardwaj, A
   Jha, RK
AF Verma, Vivek Singh
   Bhardwaj, Anuj
   Jha, Rajib Kumar
TI A new scheme for watermark extraction using combined noise-induced
   resonance and support vector machine with PCA based feature reduction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Noise-induced resonance; Support vector machine; Features reduction;
   Print attack; Lifting wavelet transform
ID IMAGE WATERMARKING; WAVELET TRANSFORM; INTERPOLATION; DIFFERENCE;
   ALGORITHM
AB This manuscript presents a new scheme for binary watermark extraction using the combined application of noise-induced resonance (NIR) and support vector machine (SVM). The principal component analysis (PCA) is incorporated to minimize the dimension of the feature set obtained from the attacked watermarked image. The scheme utilizes lifting wavelet transform to decompose the original image into three levels, and blocks of low frequency sub-band coefficients are used for embedding purpose. Reference and signature information is embedded by quantizing the maximum and minimum coefficients of the corresponding block. Whereas, to extract the watermark, NIR-based tuning operation is performed. The transformed coefficients of the attacked watermarked image are tuned using iterative procedure of NIR in such a way that the transformed coefficients change their state from low signal-to-noise ratio (SNR) to maximum SNR or enhanced state. Finally, the tuned coefficients are fed into the machine i.e. SVM to classify as binary classes (0 or 1) which result in the corresponding watermark extraction. Experimental results of the proposed algorithm demonstrate noteworthy robustness against various signal processing attacks and remarkable improvements comparing with some of the recent techniques. Also, the scheme fulfills the requirements of image integrity in case of new strategic attack (i.e. print attack).
C1 [Verma, Vivek Singh] Ajay Kumar Garg Engn Coll, Ghaziabad 201009, India.
   [Bhardwaj, Anuj] Jaypee Inst Informat Technol, Noida 201307, India.
   [Jha, Rajib Kumar] Indian Inst Technol, Patna 800013, Bihar, India.
C3 Jaypee Institute of Information Technology (JIIT); Indian Institute of
   Technology System (IIT System); Indian Institute of Technology (IIT) -
   Patna
RP Bhardwaj, A (corresponding author), Jaypee Inst Informat Technol, Noida 201307, India.
EM viveksv10@gmail.com; anujbhardwaj8@gmail.com; jharajib@gmail.com
RI Verma, Vivek/AAE-4391-2020; Bhardwaj, Anuj/KIE-2095-2024; Verma, Vivek
   Singh/HLH-7169-2023
OI Bhardwaj, Anuj/0000-0003-0866-2618; Verma, Vivek
   Singh/0000-0002-1497-2754
CR BENZI R, 1981, J PHYS A-MATH GEN, V14, pL453, DOI 10.1088/0305-4470/14/11/006
   Bhardwaj A, 2018, MULTIMED TOOLS APPL, V77, P19659, DOI 10.1007/s11042-017-5340-3
   Bulsara AR, 1996, PHYS TODAY, V49, P39, DOI 10.1063/1.881491
   Claypoole RL, 1998, INT CONF ACOUST SPEE, P1513, DOI 10.1109/ICASSP.1998.681737
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Gammaitoni L, 1998, REV MOD PHYS, V70, P223, DOI 10.1103/RevModPhys.70.223
   Gard T. C., 1988, Introduction to stochastic differential equations
   Gu QL, 2013, DIGIT SIGNAL PROCESS, V23, P213, DOI 10.1016/j.dsp.2012.07.013
   Jackson J. E., 2005, USERS GUIDE PRINCIPA
   Jha RK, 2014, J FRANKLIN I, V351, P2938, DOI 10.1016/j.jfranklin.2014.01.017
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   JUNG P, 1991, PHYS REV A, V44, P8032, DOI 10.1103/PhysRevA.44.8032
   Lei BY, 2012, SIGNAL PROCESS, V92, P1985, DOI 10.1016/j.sigpro.2011.12.021
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Luo H, 2011, INFORM SCIENCES, V181, P308, DOI 10.1016/j.ins.2010.09.022
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Makbol NM, 2017, INFORM SCIENCES, V417, P381, DOI 10.1016/j.ins.2017.07.026
   Mardia KV, 1979, MULTIVARIATE ANAL
   MCNAMARA B, 1989, PHYS REV A, V39, P4854, DOI 10.1103/PhysRevA.39.4854
   Peng H, 2010, J SYST SOFTWARE, V83, P1470, DOI 10.1016/j.jss.2010.03.006
   PETITCOLAS FAP, 1997, WEAKNESS EXISTING WA
   Risken H., 1984, The Fokker-Planck Equation
   Singh SP, 2018, J VIS COMMUN IMAGE R, V53, P86, DOI 10.1016/j.jvcir.2018.03.006
   Sun SF, 2008, SIGNAL PROCESS, V88, P2085, DOI 10.1016/j.sigpro.2008.02.010
   Sweldens W, 1996, APPL COMPUT HARMON A, V3, P186, DOI 10.1006/acha.1996.0015
   Tsai HH, 2007, INFORM SCIENCES, V177, P550, DOI 10.1016/j.ins.2006.05.002
   Verma VS, 2015, IETE TECH REV, V32, P479, DOI 10.1080/02564602.2015.1042927
   Verma VS, 2015, EXPERT SYST APPL, V42, P8184, DOI 10.1016/j.eswa.2015.06.041
   Verma VS, 2015, SIGNAL IMAGE VIDEO P, V9, P1443, DOI 10.1007/s11760-013-0603-6
   Verma VS, 2015, J VIS COMMUN IMAGE R, V31, P75, DOI 10.1016/j.jvcir.2015.06.001
   Wang SH, 2004, IEEE T IMAGE PROCESS, V13, P154, DOI 10.1109/TIP.2004.823822
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   Wang XY, 2008, SIGNAL PROCESS, V88, P2193, DOI 10.1016/j.sigpro.2008.03.005
   Wang XY, 2012, APPL SOFT COMPUT, V12, P887, DOI 10.1016/j.asoc.2011.10.003
   Wang XT, 2013, DIGIT SIGNAL PROCESS, V23, P569, DOI 10.1016/j.dsp.2012.06.015
   Wu G, 2006, P IEEE 8 INT C SIGN, V2, P1
   Yang HY, 2013, COMPUT ELECTR ENG, V39, P893, DOI 10.1016/j.compeleceng.2012.07.009
   Ye QH, 2003, IEEE IMAGE PROC, P849
NR 38
TC 12
Z9 13
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23203
EP 23224
DI 10.1007/s11042-019-7599-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400046
DA 2024-07-18
ER

PT J
AU Wan, MH
   Lai, ZH
   Ming, Z
   Yang, GW
AF Wan, Minghua
   Lai, Zhihui
   Ming, Zhong
   Yang, Guowei
TI An improve face representation and recognition method based on graph
   regularized non-negative matrix factorization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-negative matrix factorization (NMF); Graph embedded (GE); Face
   recognition; Discriminant criterion (DC)
ID NONLINEAR DIMENSIONALITY REDUCTION; LAPLACIAN EIGENMAPS; COMPONENT
   ANALYSIS; ALGORITHM
AB Based on recently proposed Non-negative Matrix Factorization (NMF) and Graph Embedded (GE) techniques with Discriminant Criterion (DC), we present in this paper a new algorithm of Face Representation and Recognition (FRR) called Discriminant Graph Regularized Non-negative Matrix Factorization (DGNMF) for dimensionality reduction (DR). Here, we firstly encode the geometrical class information by constructing an affinity graph using the DGNMF algorithm. After this, we determine a matrix factorization which adequately represents the graph structure. Finally, we conduct experiments to prove that DGNMF provides a better representation and achieves higher face recognition rates than previous approaches.
C1 [Wan, Minghua; Yang, Guowei] Nanjing Audit Univ, Sch Informat Engn, Nanjing 211815, Jiangsu, Peoples R China.
   [Wan, Minghua; Lai, Zhihui; Ming, Zhong] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.
C3 Nanjing Audit University; Shenzhen University
RP Wan, MH (corresponding author), Nanjing Audit Univ, Sch Informat Engn, Nanjing 211815, Jiangsu, Peoples R China.; Wan, MH (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.
EM wmh36@sina.com
RI Yang, Jacky/HKE-6819-2023; Lai, Zhihui/R-1000-2019
OI Lai, Zhihui/0000-0002-4388-3080
FU National Key RD Program [2017YFC0804002]; National Science Foundation of
   China [61876213, 61462064, 6177227, 61861033, 61603192]; China
   Postdoctoral Science Foundation [2016 M600674]; Natural Science Fund of
   Jiangsu Province [BK20161580, BK20171494]; China's Jiangxi Province
   Natural Science Foundation [20181BAB202022]; Fund of China's Jiangxi
   Provincial Department of Education [GJJ170599]
FX This work is partially supported by National Key R&D Program Grant No.
   2017YFC0804002, the National Science Foundation of China under Grant
   Nos. 61876213, 61462064, 6177227, 61861033, 61603192, the China
   Postdoctoral Science Foundation under Grant No. 2016 M600674, the
   Natural Science Fund of Jiangsu Province under Grants BK20161580,
   BK20171494 and China's Jiangxi Province Natural Science Foundation (No.
   20181BAB202022), and the Fund of China's Jiangxi Provincial Department
   of Education (No. GJJ170599).
CR [Anonymous], 2004, AS C COMP VIS
   [Anonymous], 1997, YALE DATABASE
   AT&T Laboratories Cambridge, ORL DAT FAC
   Baek K, 2002, PROCEEDINGS OF THE 6TH JOINT CONFERENCE ON INFORMATION SCIENCES, P824
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Buciu I, 2004, MACHINE LEARN SIGN P, P539
   Cai D, 2008, IEEE DATA MINING, P63, DOI 10.1109/ICDM.2008.57
   COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9
   He XF, 2004, ADV NEUR IN, V16, P153
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Kiby M, 2010, IEEE T PATTERN ANAL, V98, P1031
   Lai ZH, 2018, IEEE T CYBERNETICS, V48, P2472, DOI 10.1109/TCYB.2017.2740949
   Lai ZH, 2017, IEEE T CYBERNETICS, V47, P3733, DOI 10.1109/TCYB.2016.2578642
   Lai ZH, 2016, IEEE T NEUR NET LEAR, V27, P723, DOI 10.1109/TNNLS.2015.2422994
   Lai ZH, 2014, IEEE T NEUR NET LEAR, V25, P1942, DOI 10.1109/TNNLS.2013.2297381
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Lee J. M., 2006, RIEMANNIAN MANIFOLDS
   Li P, 2014, EXPERT SYST APPL, V41, P1283, DOI 10.1016/j.eswa.2013.08.026
   Liu GH, 2019, IEEE T IMAGE PROCESS, V28, P6, DOI 10.1109/TIP.2018.2847422
   Liu GH, 2015, PATTERN RECOGN, V48, P2554, DOI 10.1016/j.patcog.2015.02.005
   Liu W, 2003, P 2003 IEEE INT C AC, V3, P3
   Mika S, 2003, IEEE T PATTERN ANAL, V25, P623, DOI 10.1109/TPAMI.2003.1195996
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Saul LK, 2004, J MACH LEARN RES, V4, P119, DOI 10.1162/153244304322972667
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Shen FM, 2018, IEEE T PATTERN ANAL, V40, P3034, DOI 10.1109/TPAMI.2018.2789887
   Shen FM, 2017, IEEE T MULTIMEDIA, V19, P2022, DOI 10.1109/TMM.2017.2699863
   Shen FM, 2016, IEEE T IMAGE PROCESS, V25, P5610, DOI 10.1109/TIP.2016.2612883
   Shi XS, 2014, PATTERN RECOGN, V47, P2447, DOI 10.1016/j.patcog.2014.01.007
   Tao DP, 2018, IEEE T CIRC SYST VID, V28, P2657, DOI 10.1109/TCSVT.2017.2726580
   Tao DP, 2018, IEEE T IMAGE PROCESS, V27, P325, DOI 10.1109/TIP.2017.2762588
   Tao DP, 2016, IEEE T NEUR NET LEAR, V27, P1122, DOI 10.1109/TNNLS.2015.2461554
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Wang XD, 2018, PATTERN RECOGN LETT, V102, P89, DOI 10.1016/j.patrec.2017.12.022
   Wang XD, 2016, NEUROCOMPUTING, V200, P47, DOI 10.1016/j.neucom.2016.03.017
   Xu BW, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION, P273, DOI 10.1109/IRI.2003.1251424
   Xue Y, 2006, INT C PATT RECOG, P495
   Yang J, 2007, IEEE T PATTERN ANAL, V29, P650, DOI 10.1109/TPAMI.2007.1008
   Yang YJ, 2007, PROCEEDINGS OF THE IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, P250, DOI 10.1109/WI.2007.66
   Zhang ZY, 2004, SIAM J SCI COMPUT, V26, P313, DOI 10.1137/S1064827502419154
NR 44
TC 2
Z9 4
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 22109
EP 22126
DI 10.1007/s11042-019-7454-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400069
DA 2024-07-18
ER

PT J
AU Wang, P
   Ni, C
   Li, Z
   Zhang, GY
AF Wang, Peng
   Ni, Cui
   Li, Zhe
   Zhang, Guangyuan
TI Optimal CTU-level bit allocation in HEVC for low bit-rate applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; CTU-level; Motion-region extraction; Bit allocation
ID RATE CONTROL ALGORITHM; MULTIVIEW VIDEO
AB The coding efficiency of High Efficiency Video Coding (HEVC) outperforms all the past video coding standards. But for low bit-rate video applications, fewer bits cannot guarantee the reconstructed quality of each coding frame. Rate control is used to get better quality with fewer bits, while the bit allocation is the key of rate control. This paper proposes an optimal CTU-level bit allocation based on region classification in HEVC for low bit-rate applications. The motion regions are extracted in each frame from the CTU-level. The bits allocated to the CTUs belong to the motion regions will be calculated according to the motion vectors of CTUs and the overall frames to improve the quality of these CTUs. Finally, the R-lambda model rate control adopted in HM16.0 will be used to calculate QP of each CTU. Experimental results demonstrate that the proposed bit allocation approach can achieve an average improvement of 0.32 dB in objective quality compared with the conventional rate control adapted in HM16.0, and the subjective quality improves obviously and the accuracy of rate control is also good.
C1 [Wang, Peng; Ni, Cui; Zhang, Guangyuan] Shandong Jiao Tong Univ, Sch Informat Sci & Elect Engn, Jinan 250357, Shandong, Peoples R China.
   [Li, Zhe] Shandong Univ Sci & Technol, Shandong Prov Key Lab Wisdom Mine Informat Techno, Qingdao 266590, Shandong, Peoples R China.
C3 Shandong Jiaotong University; Shandong University of Science &
   Technology
RP Ni, C (corresponding author), Shandong Jiao Tong Univ, Sch Informat Sci & Elect Engn, Jinan 250357, Shandong, Peoples R China.
EM knightwp@126.com; emilync@126.com; lizhe@sdust.edu.cn; xdzhanggy@163.com
FU National Science Fund for Distinguished Young Scholars [61502277,
   61502278]
FX This work was supported by the National Science Fund for Distinguished
   Young Scholars, under Grant 61502277 and 61502278.
CR [Anonymous], JCTVC ISO IEC ITU T
   Boyce JM, 2016, IEEE T CIRC SYST VID, V26, P20, DOI 10.1109/TCSVT.2015.2461951
   Choi H, 2012, JCTVC ISO IEC ITU T
   Doulamis N, 1998, IEEE T CIRC SYST VID, V8, P928, DOI 10.1109/76.736718
   Elkapelli S. S., 2016, PROC 2016 ONLINE INT, P1
   Kim I, 2012, JCTVCK1002 ISOIEC IT
   Kuo CH, 2016, IEEE T CIRC SYST VID, V26, P2069, DOI 10.1109/TCSVT.2015.2501921
   Lan XY, 2019, IEEE T IND ELECTRON, V66, P9887, DOI 10.1109/TIE.2019.2898618
   Lan XY, 2020, PATTERN RECOGN LETT, V130, P12, DOI 10.1016/j.patrec.2018.10.002
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Lan XY, 2014, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2014.156
   Lei JJ, 2014, MULTIMED TOOLS APPL, V72, P825, DOI 10.1007/s11042-013-1386-z
   Li B, 2014, IEEE T IMAGE PROCESS, V23, P3841, DOI 10.1109/TIP.2014.2336550
   Li L, 2016, IEEE T MULTIMEDIA, V18, P2023, DOI 10.1109/TMM.2016.2595264
   Li SX, 2017, IEEE T CIRC SYST VID, V27, P2409, DOI 10.1109/TCSVT.2016.2589878
   Lu ZK, 2005, IEEE T IMAGE PROCESS, V14, P1928, DOI 10.1109/TIP.2005.854478
   Park S, 2011, JCTVCD181 ISOIEC ITU
   Shao F, 2013, IEEE T MULTIMEDIA, V15, P1843, DOI 10.1109/TMM.2013.2269897
   Si JJ, 2013, PICT COD SYMP, P89, DOI 10.1109/PCS.2013.6737690
   Tian L, 2014, IEEE INT C COMP NETW
   Wang H, 2006, IEEE INT C AC SPEECH, V2, P14
   Won CS, 2011, IEEE T IMAGE PROCESS, V20, P1273, DOI 10.1109/TIP.2010.2090534
   Zeng HQ, 2016, MULTIMED TOOLS APPL, V75, P10383, DOI 10.1007/s11042-015-2997-3
   Zhang ZW, 2017, IEEE ACCESS, V5, P13677, DOI 10.1109/ACCESS.2017.2676125
   Zhou YM, 2013, INT CONF COMPUT NETW
NR 26
TC 6
Z9 6
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23733
EP 23747
DI 10.1007/s11042-019-7680-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400068
DA 2024-07-18
ER

PT J
AU Yang, YL
   Liu, QG
   Zhang, MH
   Wang, YH
AF Yang, Yalin
   Liu, Qiegen
   Zhang, Minghui
   Wang, Yuhao
TI Bi-path network coupling for single image super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single-image super-resolution; Deep convolutional neural networks;
   Bi-path network; Residual network; Dense network; Coupling
AB Recent researches have shown that deep convolutional neural networks can significantly boost the performance of single-image super-resolution (SISR). In particular, residual network and densely convolutional network can improve performance remarkably. The residual network enables feature re-usage and the dense skip connections enables new features exploration, which are both favor for feature extraction. In order to alleviate the vanishing-gradient problem in very deep convolution networks. In this paper, a bi-path network coupling is presented for SISR by combining the residual network and the dense skip connections in a very deep network. More specifically, the feature maps in the proposed network are split into two paths, one path is propagated in the form of residual connections, and another is propagated by dense skip connections. In addition, we input the feature maps obtained from the two paths into the coupling layer for feature fusion. Finally, the deconvolution layers are integrated into the network to upscale the feature map for significantly accelerating the network, that the mapping is learned from the low-resolution image to the high-resolution image directly. The proposed network was evaluated on four benchmark datasets and has achieved competing or even higher peak signal-to-noise ratio (PSNR) than most of state-of-the-art methods.
C1 [Yang, Yalin; Liu, Qiegen; Zhang, Minghui; Wang, Yuhao] Nanchang Univ, Sch Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
C3 Nanchang University
RP Wang, YH (corresponding author), Nanchang Univ, Sch Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
EM wangyuhao@ncu.edu.cn
RI Li, Yuanyuan/J-3539-2014; wen, Wen/KBB-1727-2024; Wang,
   Guanhua/JXM-6373-2024; WANG, Yuhao/O-9322-2019
OI Li, Yuanyuan/0000-0001-6151-9306; WANG, Yuhao/0000-0002-8445-0361
FU National Natural Science Foundation of China [61661028, 61871206,
   61661031, 61463035]; Natural Science Foundation of Jiangxi Province
   [20181BAB202003]
FX The authors sincerely thank the anonymous reviewers for their valuable
   comments and constructive suggestions that are very helpful in the
   improvement of this paper. This work was supported in part by the
   National Natural Science Foundation of China under 61661028, 61871206,
   61661031, 61463035, and the Natural Science Foundation of Jiangxi
   Province (20181BAB202003).
CR Agustsson E., 2017, CVPRW
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], 2010, P INT C CURV SURF
   [Anonymous], ICLR 2018 UNPUB
   [Anonymous], 2012, BMVC
   [Anonymous], 2015, P IEEE C COMP VIS PA
   [Anonymous], 2010, J HARBIN I TECHNOL
   [Anonymous], 2018, P IEEE C COMP VIS PA
   [Anonymous], 2016, P IEEE C COMPUTER VI
   [Anonymous], 2013, MICCAI
   [Anonymous], 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.123
   [Anonymous], NIPS 2016
   [Anonymous], 2017, DUAL PATH NETWORKS
   Bevilacqua M, 2014, IEEE T IMAGE PROCESS, V23, P5334, DOI 10.1109/TIP.2014.2364116
   Blu T, 2004, IEEE T IMAGE PROCESS, V13, P710, DOI 10.1109/TIP.2004.826093
   Dai SY, 2009, IEEE T IMAGE PROCESS, V18, P969, DOI 10.1109/TIP.2009.2012908
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hung KW, 2012, INT CONF ACOUST SPEE, P1269, DOI 10.1109/ICASSP.2012.6288120
   Hung KW, 2012, IEEE T IMAGE PROCESS, V21, P1061, DOI 10.1109/TIP.2011.2168416
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   King DB, 2015, ACS SYM SER, V1214, P1
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Lim B., 2017, IEEE C COMP VIS PATT, V1, P4
   Marquina A, 2008, J SCI COMPUT, V37, P367, DOI 10.1007/s10915-008-9214-8
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schulter S, 2015, PROC CVPR IEEE, P3791, DOI 10.1109/CVPR.2015.7299003
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Wang YK, 2018, J VIS COMMUN IMAGE R, V57, P152, DOI 10.1016/j.jvcir.2018.10.028
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   [徐冉 Xu Ran], 2016, [中国图象图形学报, Journal of Image and Graphics], V21, P556
   Yang CY, 2013, IEEE I CONF COMP VIS, P561, DOI 10.1109/ICCV.2013.75
   Yang JH, 2008, CRYST RES TECHNOL, V43, P999, DOI 10.1002/crat.200800010
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zhao Y, 2017, NEUROCOMPUTING, V226, P200, DOI 10.1016/j.neucom.2016.11.049
   Zou WWW, 2012, IEEE T IMAGE PROCESS, V21, P327, DOI 10.1109/TIP.2011.2162423
NR 42
TC 2
Z9 2
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21981
EP 21998
DI 10.1007/s11042-019-7511-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400063
DA 2024-07-18
ER

PT J
AU Yiu, KFC
AF Yiu, K. F. C.
TI A parallel beamforming system with real-time implementation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Signal enhancement; Beamforming; FPGA
ID MICROPHONE ARRAYS; ENHANCEMENT; DESIGN; RECOGNITION; NOISE
AB For voice control applications, it is common to employ a microphone array to enhance received signals via beamforming techniques. In designing beamformers, different criteria will lead to different signal performance. It is known that speech recognition accuracy relies heavily on the trade-off between signal distortion and noise reduction. In this paper, we propose a novel beamformer structure which can give a continuous profile in signal distortion and noise reduction. The proposed structure combines two existing optimal beamformers to form the final filter. Moreover, since both optimal beamforming filters can be executed in parallel, a method is proposed to implement the noise reduction algorithm in the frequency domain. By studying the accuracy and efficiency of different modules, a hybrid fixed-floating point arithmetic is proposed within an FPGA hardware architecture to form an embedded system for industrial applications.
C1 [Yiu, K. F. C.] Hong Kong Polytech Univ, Dept Appl Math, Hunghom, Kowloon, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University
RP Yiu, KFC (corresponding author), Hong Kong Polytech Univ, Dept Appl Math, Hunghom, Kowloon, Hong Kong, Peoples R China.
EM cedric.yiu@polyu.edu.hk
RI Yiu, Cedric Ka Fai/C-1784-2009
OI Yiu, K.F.C./0000-0002-7523-4069
FU RGC [PolyU. 152200/14E]; PolyU Grant [4-ZZGS, G-YBVQ]
FX This paper is supported by RGC Grant PolyU. 152200/14E and PolyU Grant
   4-ZZGS and G-YBVQ. The author would like to thank Dr. Chun-Hok Ho, Mr.
   Yao Lu, Mr. Xiaoxiang Shi for carrying out the implementation on FPGA.
   The author would also like to thank the support of Prof Sven Nordholm
   and Dr Nedelko Grbic.
CR Andersson B, 2008, 4 INT C DISTR COMP S
   [Anonymous], ARXIV161101872
   Brandstein M.S., 2001, Microphone Arrays: Techniques and Applications
   Chan KY, 2012, IEEE T IND INFORM, V8, P869, DOI 10.1109/TII.2012.2187910
   Constantinides GA, 2003, ACM T DES AUTOMAT EL, V8, P334, DOI 10.1145/785411.785415
   Dahl M, 1999, IEEE T VEH TECHNOL, V48, P1518, DOI 10.1109/25.790527
   de Burgwal MDV, 2010, 13TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN: ARCHITECTURES, METHODS AND TOOLS, P301, DOI 10.1109/DSD.2010.13
   Duchon M, 2011, 3 INT C ADV MULT MME
   Feng ZG, 2012, IEEE T SIGNAL PROCES, V60, P1195, DOI 10.1109/TSP.2011.2178491
   Feng ZG, 2011, IEEE T SIGNAL PROCES, V59, P3647, DOI 10.1109/TSP.2011.2133490
   Feng ZG, 2012, EURASIP J ADV SIG PR, P1, DOI 10.1186/1687-6180-2012-62
   Gannot S, 2001, IEEE T SIGNAL PROCES, V49, P1614, DOI 10.1109/78.934132
   Golub G.H., 2013, Matrix Computations, DOI DOI 10.56021/9781421407944
   Graham P., 1998, FPGA'98. ACM/SIGDA International Symposium on Field Programmable Gate Arrays, P201, DOI 10.1145/275107.275140
   Grbi N, 2002, ICASSP02
   Grbi N, 2001, THESIS
   Healy G, 2009, 10 INT C MOB DAT MAN
   Hoshuyama O, 1999, IEEE T SIGNAL PROCES, V47, P2677, DOI 10.1109/78.790650
   HUDSON JE, 1991, ADAPTIVE ARRAY PRINC
   Johnson D. H., 1993, ARRAY SIGNAL PROCESS
   KELLERMANN W, 1991, INT CONF ACOUST SPEE, P3581, DOI 10.1109/ICASSP.1991.150249
   Li J, 2006, ROBUST ADAPTIVE BEAMFORMING, P1
   Liu Y, 2016, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING AND INFORMATION TECHNOLOGY (SEIT2015), P12
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Nordholm S, 1999, IEEE T SPEECH AUDI P, V7, P241, DOI 10.1109/89.759030
   Nordholm S, 2001, DIGITAL SIGNAL PROC, P307
   Pires JN, 2005, INT J IND ROBOT, V32, P1159
   Qian YM, 2009, IEEE T CONSUM ELECTR, V55, P1496, DOI 10.1109/TCE.2009.5278018
   Ranasinghe S, 2016, INT J DISTRIB SENS N, V12, DOI 10.1177/1550147716665520
   Roy N, 2016, J AMB INTEL HUM COMP, V7, P1, DOI 10.1007/s12652-015-0294-7
   Shoaib M, 2015, SENSORS-BASEL, V15, P2059, DOI 10.3390/s150102059
   Theodoropoulos D, 2009, 2009 IEEE 7TH SYMPOSIUM ON APPLICATION SPECIFIC PROCESSORS (SASP 2009), P80, DOI 10.1109/SASP.2009.5226341
   Thramboulidis K, 2005, IEEE T IND INFORM, V1, P54, DOI 10.1109/TII.2005.844427
   Tomov BG, 2001, ULTRASON, P1529, DOI 10.1109/ULTSYM.2001.992011
   Van Veen B. D., 1988, IEEE ASSP Magazine, V5, P4, DOI 10.1109/53.665
   Wu JX, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18114029
   Yiu KFC, 2012, PAC J OPTIM, V8, P533
   Yiu KFC, 2009, J IND MANAG OPTIM, V5, P671, DOI 10.3934/jimo.2009.5.671
   Yiu KFC, 2012, DIGIT SIGNAL PROCESS, V22, P376, DOI 10.1016/j.dsp.2011.10.008
   Yiu KFC, 2002, IEEE SIGNAL PROC LET, V9, P222, DOI 10.1109/LSP.2002.802109
NR 40
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23581
EP 23595
DI 10.1007/s11042-019-7590-8
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400061
OA Green Accepted
DA 2024-07-18
ER

PT J
AU El Rahman, SA
AF El Rahman, Sahar A.
TI Biometric human recognition system based on ECG
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ECG; Human recognition; ECG biometrics; QRS complex; QRS detection;
   Individual identification
ID CLASSIFICATION; FUSION
AB The ECG (electrocardiogram) is an emerging technology for biometric human identification. In this paper, the performance of an ECG biometric recognition system is evaluated. Signal processing techniques are utilized to extract the ECG features. In preprocessing stage, digital filters eliminate the noises and hence improve the signal to noise ratio. The process of ventricular complex (QRS Complex) detection depends on Pan and Tompkins approach that achieves an efficient QRS detection, and hence enhancing the feature extraction process. The main classifiers applied to the extracted features are Neural Network (NN), Fuzzy Logic (FL), Nearest Mean Classifier (NMC), Linear Discriminant Analysis (LDA), and Euclidean Distance (ED) are utilized to classify QRS fragments. ECG of an unknown subject is acquired; the classifiers are applied to wavelet coefficient features set between the unknown subject and all enrolled subjects. The Performance of the different approaches is evaluated by utilizing Sensitivity, Specificity, and efficiency, EER (Equal Error Rate) and ROC (Receiver Operating Characteristic) curve. The experiments are conducted on 112 individuals MIT-BIH database and the accuracy is up to 98.99%.
C1 [El Rahman, Sahar A.] Benha Univ, Fac Engn Shoubra, Dept Elect Engn, Cairo, Egypt.
   [El Rahman, Sahar A.] Princess Nourah Bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Comp Sci, Riyadh, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Benha University; Princess Nourah bint
   Abdulrahman University
RP El Rahman, SA (corresponding author), Benha Univ, Fac Engn Shoubra, Dept Elect Engn, Cairo, Egypt.; El Rahman, SA (corresponding author), Princess Nourah Bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Comp Sci, Riyadh, Saudi Arabia.
EM sahr_ar@yahoo.com
CR Alvarado M, 2009, HIMA: 2009 IEEE WORKSHOP ON HYBRID INTELLIGENT MODELS AND APPLICATIONS, P19
   Barra S, 2017, MULTIMED TOOLS APPL, V76, P4835, DOI 10.1007/s11042-016-3796-1
   Belgacem N., 2012, International Journal on Cryptography and Information Security, V2, P1, DOI [DOI 10.5121/IJCIS.2012.2201, 10.5121/ijcis .2012.2201]
   Biel L, 2001, IEEE T INSTRUM MEAS, V50, P808, DOI 10.1109/19.930458
   Castro B, 2000, 21ST IEEE CONVENTION OF THE ELECTRICAL AND ELECTRONIC ENGINEERS IN ISRAEL - IEEE PROCEEDINGS, P346, DOI 10.1109/EEEI.2000.924422
   Chan ADC, 2008, IEEE T INSTRUM MEAS, V57, P248, DOI 10.1109/TIM.2007.909996
   Chen ST, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0054-9
   ChenXing Zhao, 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P150, DOI 10.1109/BTAS.2012.6374570
   Falconi JSA, 2013, THESIS
   Gawande P., 2015, INT J COMPUT APPL, V109, P6
   Halici U, 1996, P IEEE, V84, P1497, DOI 10.1109/5.537114
   Karpagachelvi S., 2010, Int J Comput Sci Inf Secur, V8, P76
   Lourenco A, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/720971
   Nawal M., 2014, INT J EMERG ENG RES, V2, P178
   Nemirko A.P., 2005, PROC 12 RUSSIAN C MA, P387
   Pal A., 2018, INT C MATH COMPUTING, P61, DOI DOI 10.1007/978-981-13-0023-37
   PAN J, 1985, IEEE T BIO-MED ENG, V32, P230, DOI 10.1109/TBME.1985.325532
   Sedghamiz H., 2014, MATLAB IMPLEMENTATIO
   Singh YN, 2014, APPL COMPUT INTELL S, V2014, DOI 10.1155/2014/602813
   Singh YN, 2013, J ENG-NY, V2013, DOI 10.1155/2013/539284
   Singh YN, 2012, PATTERN RECOGN LETT, V33, P1932, DOI 10.1016/j.patrec.2012.03.010
   Singh YN, 2011, SOFT COMPUT, V15, P449, DOI 10.1007/s00500-009-0525-y
   Singh YN, 2009, LECT NOTES COMPUT SC, V5558, P1270, DOI 10.1007/978-3-642-01793-3_128
   Singh YN, 2008, 2008 IEEE SECOND INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS (BTAS), P72
   Singh Yogendra Narain., 2012, Journal of Information Security, V03, P39, DOI DOI 10.4236/JIS.2012.31005
   Sugeno M., 1974, PhD thesis
   Tun HM., 2015, INT J BIOMED SCI ENG, V3, P49, DOI [10.11648/j.ijbse.20150304.11, DOI 10.11648/J.IJBSE.20150304.11]
   Varatharajan R, 2018, MULTIMED TOOLS APPL, V77, P17573, DOI [10.1007/s11042-017-4768-9, 10.1007/s11042-017-5318-1]
   Venkatesh N., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3838, DOI 10.1109/ICPR.2010.935
   Wang YJ, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/148658
   Zokaee S., 2012, Int. J. Electr. Comput. Eng., V2, P261
NR 31
TC 13
Z9 13
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 17555
EP 17572
DI 10.1007/s11042-019-7152-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200011
DA 2024-07-18
ER

PT J
AU Khan, A
   Khusro, S
AF Khan, Akif
   Khusro, Shah
TI Blind-friendly user interfaces - a pilot study on improving the
   accessibility of touchscreen interfaces
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HCI; Usability; Accessibility; User interfaces; Blind-friendly; U X
ID USABILITY; SMARTPHONES
AB Touchscreen devices such as a smartphone, smartwatch, and tablets are essential assistive devices for visually impaired and blind people in performing activities of daily living. The vision alternative accessibility services such as screen readers, multimodal interactions, vibro-tactical, haptic feedback, and gestures are helping blind people in operating touchscreen interfaces. Part of usability problem with today touchscreen user interfaces contributes to a trade-off in discoverability, navigational complexity, cognitive overload, layout persistency, a cumbersome input mechanism, accessibility, and cross-device interactions. One solution to these problems is to design an accessibility-inclusive blind-friendly user interface framework for performing common activities on a smartphone. This framework re-organizes/re-generates the interface components into a simplified blind-friendly user interface based on user profile and contextual recommendations. The paper reports an improvement in the user experience of blind people in performing activities on a smartphone. Forty-one blind people have participated in this empirical study, resulting in improved users and interaction experience in an operating smartphone.
C1 [Khan, Akif; Khusro, Shah] Univ Peshawar, Dept Comp Sci, Peshawar, Pakistan.
C3 University of Peshawar
RP Khan, A (corresponding author), Univ Peshawar, Dept Comp Sci, Peshawar, Pakistan.
EM akif@uop.edu.pk
RI Khusro, Shah/C-1661-2014
OI Khusro, Shah/0000-0002-7734-7243; Khan, Akif/0000-0002-7162-0931
FU Higher Education Commission (HEC) of Pakistan
FX This research work has been undertaken by the first author as partial
   fulfillment of Ph.D. degree with the support of the Higher Education
   Commission (HEC) of Pakistan.
CR Akiki P., 2014, Engineering Adaptive Model-Driven User Interfaces for Enterprise Applications
   Akiki PA, 2014, ACM COMPUT SURV, V47, DOI 10.1145/2597999
   [Anonymous], 2017, NUMB APPS AV LEAD AP
   [Anonymous], USABILITY CHALLENGES
   [Anonymous], 2003, CONSTRUCTING ACCESSI
   [Anonymous], 2010, DESIGNING USER INTER
   Boren MT, 2000, IEEE T PROF COMMUN, V43, P261, DOI 10.1109/47.867942
   Brewster S, 2002, PERS UBIQUIT COMPUT, V6, P188, DOI 10.1007/s007790200019
   Brewster S, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P159
   Buxton W., 1985, Computer Graphics, V19, P215, DOI 10.1145/325165.325239
   Buzzi M, 2016, MULTIMED TOOLS APPL, P1
   Buzzi Maria Claudia., 2015, Proceedings of the 11th Biannual Conference on Italian SIGCHI Chapter, P94, DOI DOI 10.1145/2808435.2808448
   Damaceno RJP, U ACCESS INF SOC, P1
   DIS I, 2006, 9241171 DIS I ISO
   Dorigo Martin Lukas, 2013, Universal Access in Human-Computer Interaction. Applications and Services for Quality of Life. 7th International Conference, UAHCI 2013 Held as Part of HCI International 2013. Proceedings. LNCS 8011, P311, DOI 10.1007/978-3-642-39194-1_37
   Elias M, 2016, COMM COM INF SC, V649, P241, DOI 10.1007/978-3-319-45880-9_19
   Fruchterman J.R., 2003, J VISUAL IMPAIR BLIN, V97, P585, DOI DOI 10.1177/0145482X0309701003
   Gajos KrzysztofZ., 2006, ASSETS 06, P243
   Gamecho B, 2015, IEEE T HUM-MACH SYST, V45, P612, DOI 10.1109/THMS.2014.2384452
   Guerreiro T, 2008, IEEE MULTIMEDIA, V15, P48, DOI 10.1109/MMUL.2008.88
   Guerreiro Tiago., 2015, Proceedings of the 2015 International Conference on Interactive Tabletops Surfaces, P25
   Hakobyan L, 2013, SURV OPHTHALMOL, V58, P513, DOI 10.1016/j.survophthal.2012.10.004
   Hussain J, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18051622
   Hussain J, 2018, J MULTIMODAL USER IN, V12, P1, DOI 10.1007/s12193-018-0258-2
   KAISER HF, 1974, PSYCHOMETRIKA, V39, P31, DOI 10.1007/BF02291575
   Kane SK, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P413
   Kane SK, 2009, ASSETS'09: PROCEEDINGS OF THE 11TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P115
   Kane Shaun K., 2008, Proceedings of the 10th international ACM SIGACCESS confer- ence on Computers and accessibility, Assets '08, P73, DOI DOI 10.1145/1414471.1414487
   Khan A, 2018, UNIVERSAL ACCESS INF, P1
   Khan A, 2018, ENG TECHNOL APPL SCI, V8, P2775
   Kientz J.A., 2006, P 8 INT ACM SIGACCES, P103, DOI [10.1145/1168987.1169006, DOI 10.1145/1168987.1169006]
   Kieras D., 2001, USING KEYSTROKE LEVE
   Krainz E, 2018, LECT NOTES COMPUT SC, V10896, P64, DOI 10.1007/978-3-319-94277-3_12
   Kuber R., 2012, P IASTED HCI
   Kurakata K., 2008, JPN J ERGON, V44, P22
   Legge GE, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0076783
   Leporini B, 2008, INT J HUM-COMPUT INT, V24, P17, DOI 10.1080/10447310701771472
   Lewis JR, 2009, LECT NOTES COMPUT SC, V5619, P94, DOI 10.1007/978-3-642-02806-9_12
   McCarthy J., 2004, interactions, V11, P42, DOI [DOI 10.1145/1015530.1015549, 10.1145/1015530.1015549]
   McGookin D., 2008, P 5 NORD C HUM COMP, P298, DOI DOI 10.1145/1463160.1463193
   Mi N, 2014, UNIVERSAL ACCESS INF, V13, pCP4, DOI 10.1007/s10209-013-0321-4
   Miñón R, 2016, UNIVERSAL ACCESS INF, V15, P153, DOI 10.1007/s10209-015-0406-3
   Nah FF-H, 2017, EDITORIAL MOBILE HUM
   Nesbat SaiedB., 2003, Proceedings of the 5th International Conference on Multimodal Interfaces, ICMI '03, P4
   Niazi B, 2016, ADV INTELL SYST, V464, P427, DOI 10.1007/978-3-319-33625-1_38
   Nicolau Hugo., 2015, P 12 WEB ALL C 301 3, DOI [DOI 10.1145/2745555.27466439, 10.1145/2745555.2746643, DOI 10.1145/2745555.2746643]
   Oliveira J, 2011, ASSETS 11: PROCEEDINGS OF THE 13TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P179
   Paek T, 2007, USER MODEL USER-ADAP, V17, P93, DOI 10.1007/s11257-006-9021-6
   Park D, 2011, INT J HUM-COMPUT ST, V69, P839, DOI 10.1016/j.ijhcs.2011.06.006
   Park YS, 2010, INT J IND ERGONOM, V40, P68, DOI 10.1016/j.ergon.2009.08.002
   Petrie Helen, 2009, UNIVERSAL ACCESS HDB, P1
   Pirhonen A., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P291, DOI 10.1145/503376.503428
   Plos O., 2006, Human factors in computing systems (CHI), P1229, DOI DOI 10.1145/1125451.1125681
   Rodriguez-Sanchez MC, 2014, EXPERT SYST APPL, V41, P7210, DOI 10.1016/j.eswa.2014.05.031
   Romero M., 2011, Proceedings of the 13th International Conference on Human Computer Interaction with Mobile Devices and Services, P707, DOI DOI 10.1145/2037373.2037491
   Sandnes FE, 2012, UNIVERSAL ACCESS INF, V11, P421, DOI 10.1007/s10209-011-0258-4
   Shahzad SK, 2009, ICCIT: 2009 FOURTH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCES AND CONVERGENCE INFORMATION TECHNOLOGY, VOLS 1 AND 2, P99, DOI 10.1109/ICCIT.2009.330
   Shneiderman B., 1986, DESIGNING USER INTER
   Smith B.W., 2004, FOREST RESOURCES US, P1
   Soui M, 2007, P 1 INT C ICT ACC IC, P219
   Southern C, 2012, MOBILEHCI '12: COMPANION PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON HUMAN COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES, P155
   Story MF, 1998, ASSIST TECHNOL, V10, P4, DOI 10.1080/10400435.1998.10131955
   Strumillo P, 2009, ADV INTEL SOFT COMPU, V65, P129
   Wall StevenA., 2006, Proceedings of the 4th Nordic conference on Human-computer interaction: changing roles, P9, DOI DOI 10.1145/1182475.1182477
   Wu Mike, 2003, P 16 ANN ACM S US IN, P193, DOI [10.1145/964696.964718, DOI 10.1145/964696.964718]
   Yargin GT, 2015, AI EDAM, V29, P203, DOI 10.1017/S0890060415000074
   Yu W., 2006, Virtual Reality, V9, P133
NR 67
TC 23
Z9 24
U1 1
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 17495
EP 17519
DI 10.1007/s11042-018-7094-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200008
DA 2024-07-18
ER

PT J
AU de Diego, IM
   San Roman, I
   Montero, JC
   Conde, C
   Cabello, E
AF Martin de Diego, Isaac
   San Roman, Ignacio
   Cano Montero, Javier
   Conde, Cristina
   Cabello, Enrique
TI Scalable and flexible wireless distributed architecture for intelligent
   video surveillance systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligent video surveillance architecture; Distributed system; Robot
   operating system; Wireless multimedia sensor network
ID RECOGNITION
AB This paper presents a novel distributed intelligent video surveillance architecture based on Wireless Multimedia Sensor Networks (WMSNs). This architecture is part of a video surveillance project and has been built using the Robot Operating System (ROS). ROS allows to develop and connect (through wireless TCP-IP) several modules to process and manage multimedia data in an easy way. The real-time intelligent surveillance system has been trained for detecting, tracking and monitoring people and vehicles in an indoor-outdoor real environment. The test process shows the reliability of the developed system as a tool for the identification of security incidents. Besides, using wireless connections and a distributed architecture together, we have achieved a really flexible, easy to install and lower-maintenance system that supports many different devices. Thus, the proposed architecture can be applied in distributed locations such as smart cities.
C1 [Martin de Diego, Isaac; San Roman, Ignacio; Cano Montero, Javier; Conde, Cristina; Cabello, Enrique] Univ Rey Juan Carlos, Face Recognit & Artificial Vis Grp, Mostoles, Spain.
C3 Universidad Rey Juan Carlos
RP de Diego, IM (corresponding author), Univ Rey Juan Carlos, Face Recognit & Artificial Vis Grp, Mostoles, Spain.
EM isaac.martin@urjc.es; ignacio.sanroman@urjc.es;
   javier.cano.motero@urjc.es; cristina.conde@urjc.es;
   enrique.cabello@urjc.es
RI DE DIEGO, Isaac MARTÍN/AAP-5144-2021
OI DE DIEGO, Isaac MARTÍN/0000-0001-5197-2932; Cabello,
   Enrique/0000-0002-2361-8247; Conde, Cristina/0000-0003-3548-0297
FU Ministerio de Economia y Competitividad from Spain INVISUM
   [RTC-2014-2346-8]
FX This work is supported by the Ministerio de Economia y Competitividad
   from Spain INVISUM (RTC-2014-2346-8). The authors would like to thank
   Cesar Benavente Peces, professor at 'Universidad Politecnica de Madrid,
   for his time and effort in the form of review and feedback'.
CR [Anonymous], 2014, VIDEO SURVEILLANCE S
   [Anonymous], 2018, P 2018 ACM INT JOINT
   Babu RV, 2004, IMAGE VISION COMPUT, V22, P597, DOI 10.1016/j.imavis.2003.11.004
   Cheikh Faouzi Alaya, 2012, International Journal of New Computer Architectures and their Applications, V2, P23
   Chua JL, 2015, SIGNAL IMAGE VIDEO P, V9, P623, DOI 10.1007/s11760-013-0493-7
   Du S, 2013, IEEE T CIRC SYST VID, V23, P322, DOI 10.1109/TCSVT.2012.2203741
   Huynh T., 2015, THERMAL SENSORS
   Ju J, 2015, I SYMP CONSUM ELECTR, P345, DOI 10.1109/ICCE.2015.7066438
   Kadhm MS, 2015, INT J EMERGING TENDR, V4
   Kalantar-Zadeh K., 2013, SENSORS INTRO COURSE
   Maltoni D., 2009, HDB FINGERPRINT RECO
   Martin de Diego I, 2017, SIGMAP 14 INT C SIGN
   de Diego IM, 2013, TRANSPORT RES C-EMER, V26, P380, DOI 10.1016/j.trc.2012.10.006
   de Diego IM, 2010, PATTERN RECOGN LETT, V31, P837, DOI 10.1016/j.patrec.2009.12.030
   de Diego IM, 2010, MACH LEARN, V78, P137, DOI 10.1007/s10994-009-5135-5
   Moctezuma D, 2015, EURASIP J IMAGE VIDE, P1, DOI 10.1186/s13640-015-0078-1
   Moctezuma D, 2013, 2013 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES & APPLICATIONS (DICTA), P1
   Morris Brendan T., 2008, 2008 IEEE Fifth International Conference on Advanced Video and Signal Based Surveillance, P154, DOI 10.1109/AVSS.2008.65
   Nam Y, 2012, MULTIMED TOOLS APPL, V57, P315, DOI 10.1007/s11042-010-0677-x
   Nuppeney M, 2014, NIST INT BIOM PERF C, P1
   Oh JM, 2014, ADV MULTIMEDIA, V2014, P15
   Quigley Morgan, 2009, ICRA WORKSH OP SOURC, P3
   Rho S, 2015, INFORM FUSION, V24, P1, DOI 10.1016/j.inffus.2014.11.002
   Ribnick E, 2006, P IEEE INT C VID SIG, P10
   Rougier C, 2007, 21ST INTERNATIONAL CONFERENCE ON ADVANCED NETWORKING AND APPLICATIONS WORKSHOPS/SYMPOSIA, VOL 2, PROCEEDINGS, P875, DOI 10.1109/ainaw.2007.181
   San Roman I, 2017, IBPRIA 2017 8 IB C P
   del Río JS, 2015, ANN IEEE SYST CONF, P340, DOI 10.1109/SYSCON.2015.7116774
   Serrano A, 2007, LECT NOTES COMPUT SC, V4881, P219
   Siordia OS, 2014, IEEE T INTELL TRANSP, V15, P1823, DOI 10.1109/TITS.2014.2330576
   Tian YL, 2011, IEEE T SYST MAN CY C, V41, P565, DOI 10.1109/TSMCC.2010.2065803
   Tung F, 2011, IMAGE VISION COMPUT, V29, P230, DOI 10.1016/j.imavis.2010.11.003
   Valera M, 2005, IEE P-VIS IMAGE SIGN, V152, P192, DOI 10.1049/ip-vis:20041147
   Wang XG, 2013, PATTERN RECOGN LETT, V34, P3, DOI 10.1016/j.patrec.2012.07.005
   Zhan BB, 2008, MACH VISION APPL, V19, P345, DOI 10.1007/s00138-008-0132-4
   Zhang T, 2015, MOBICOM '15: PROCEEDINGS OF THE 21ST ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P426, DOI 10.1145/2789168.2790123
   Zhang Z, 2015, P 8 ACM INT C PERVAS
NR 36
TC 3
Z9 3
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 17437
EP 17459
DI 10.1007/s11042-018-7065-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200006
DA 2024-07-18
ER

PT J
AU Yu, WQ
   Liu, Y
   Gong, LH
   Tian, MM
   Tu, LQ
AF Yu, Wenqian
   Liu, Ye
   Gong, Lihua
   Tian, Miaomiao
   Tu, Liangqiang
TI Double-image encryption based on spatiotemporal chaos and DNA operations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Double-image encryption; DNA insertion and deletion;
   Spatiotemporal-chaos; DNA-level confusion and diffusion
ID HYPER-CHAOS; ALGORITHM; CRYPTANALYSIS; SYSTEM; CML
AB A double-image encryption algorithm combining DNA insertion and deletion operations with spatiotemporal chaos is proposed. The technology of DNA sequence insertion and deletion is employed in both confusion and diffusion to encrypt two images simultaneously. In the proposed image encryption scheme, the key streams to control DNA operations are obtained by means of iterating the system of non-adjacent coupled map lattices (NCML). The original key streams are related to the plain-image, which increases the sensitivity of the proposed algorithm. Two confused images are served as keys to encrypt each other. The confused image is associated with another through the DNA insertion and deletion, which not only improves the security of image encryption system but also enhances the encryption speed. It is demonstrated that the proposed image encryption algorithm has the characteristics of large key space, high sensitivities of key and plain-image, and high entropy. Also, the proposed algorithm is robust to occlusion-attack and noise-attack. Therefore, the proposed double-image encryption algorithm is heuristic for the DNA computing applications into the multi-image encryption.
C1 [Yu, Wenqian; Liu, Ye; Gong, Lihua; Tian, Miaomiao; Tu, Liangqiang] Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
   [Gong, Lihua] Shanghai Jiao Tong Univ, Shanghai Key Lab Integrate Adm Technol Informat S, Shanghai 200240, Peoples R China.
C3 Nanchang University; Shanghai Jiao Tong University
RP Liu, Y (corresponding author), Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
EM liuye@ncu.edu.cn
FU National Natural Science Foundation of China [61861029, 61462061,
   61262084]; Major Academic Discipline and Technical Leader of Jiangxi
   Province [20162BCB22011]; Cultivation Project of Applied Research of
   Jiangxi Province [20181BBE58022]; Opening Project of Shanghai Key
   Laboratory of Integrate Administration Technologies for Information
   Security [AGK2018002, AGK201602]; Innovation Fund for graduates of
   Nanchang University [CX2017194]
FX This work is supported by the National Natural Science Foundation of
   China (Grant Nos. 61861029, 61462061 and 61262084), the Major Academic
   Discipline and Technical Leader of Jiangxi Province (Grant No.
   20162BCB22011), Cultivation Project of Applied Research of Jiangxi
   Province (Grant Nos. 20181BBE58022), the Opening Project of Shanghai Key
   Laboratory of Integrate Administration Technologies for Information
   Security (Grant Nos. AGK2018002 and AGK201602) and the Innovation Fund
   for graduates of Nanchang University (Grant No. CX2017194).
CR Ahmad M, 2018, J INTELL FUZZY SYST, V34, P1323, DOI 10.3233/JIFS-169428
   Akhavan A, 2017, OPT LASER TECHNOL, V95, P94, DOI 10.1016/j.optlastec.2017.04.022
   Chai XL, 2017, INT J MOD PHYS C, V28, DOI 10.1142/S0129183117500693
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   El Assad S, 2016, SIGNAL PROCESS-IMAGE, V41, P144, DOI 10.1016/j.image.2015.10.004
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Guo SF, 2018, MULTIMED TOOLS APPL, V77, P21109, DOI 10.1007/s11042-017-5570-4
   Herzog A, 2007, INT J INF SECUR PRIV, V1, P1, DOI 10.4018/jisp.2007100101
   Hu T, 2017, SIGNAL PROCESS, V134, P234, DOI 10.1016/j.sigpro.2016.12.008
   Hu T, 2017, NONLINEAR DYNAM, V87, P51, DOI 10.1007/s11071-016-3024-6
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Liu HJ, 2018, MULTIMED TOOLS APPL, V77, P1391, DOI 10.1007/s11042-016-4288-z
   Ma LH, 2018, OPT COMMUN, V407, P51, DOI 10.1016/j.optcom.2017.08.047
   Mousa A, 2013, JAP EGY CONF ELECTR, P154, DOI 10.1109/JEC-ECC.2013.6766404
   Norouzi B, 2017, MULTIMED TOOLS APPL, V76, P13681, DOI 10.1007/s11042-016-3769-4
   Tong XJ, 2015, IMAGING SCI J, V63, P263, DOI 10.1179/1743131X15Y.0000000006
   Wang XY, 2016, BIOSYSTEMS, V144, P18, DOI 10.1016/j.biosystems.2016.03.011
   Wang XY, 2015, NONLINEAR DYNAM, V82, P1269, DOI 10.1007/s11071-015-2234-7
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wheeler DD., 1989, CRYPTOLOGIA, V13, P243, DOI DOI 10.1080/0161-118991863934
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Wu XJ, 2017, NONLINEAR DYNAM, V90, P855, DOI 10.1007/s11071-017-3698-4
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Xiong Y, 2018, OPT LASER ENG, V101, P113, DOI 10.1016/j.optlaseng.2017.10.010
   Yuan HM, 2017, MULTIMED TOOLS APPL, V76, P8087, DOI 10.1007/s11042-016-3454-7
   Zeng L, 2015, OPTIK, V126, P5022, DOI 10.1016/j.ijleo.2015.09.219
   Zhang Q, 2014, AEU-INT J ELECTRON C, V68, P186, DOI 10.1016/j.aeue.2013.08.007
   Zhang XQ, 2017, COMPUT ELECTR ENG, V62, P401, DOI 10.1016/j.compeleceng.2016.12.025
   Zhang YQ, 2016, OPT LASER ENG, V82, P95, DOI 10.1016/j.optlaseng.2016.02.002
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P21589, DOI 10.1007/s11042-017-5585-x
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P6647, DOI 10.1007/s11042-017-4577-1
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
NR 36
TC 39
Z9 40
U1 6
U2 107
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 20037
EP 20064
DI 10.1007/s11042-018-7110-2
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800051
DA 2024-07-18
ER

PT J
AU Cevik, N
   Cevik, T
AF Cevik, Nazife
   Cevik, Taner
TI DLGBD: A directional local gradient based descriptor for face
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Local descriptor; Local pattern; Gradient;
   Classification; Rotation invariant
ID INVARIANT TEXTURE CLASSIFICATION; BINARY PATTERNS; REPRESENTATION;
   HISTOGRAM; SPACE; SCALE
AB This paper proposes a novel high-performance gradient-based local descriptor that handles the prominent challenges of face recognition such as resistance against rotational, illuminative changes as well as noise effects. One of the novelties this study poses is that, while processing the gradient for each direction, an analysis is done by considering the predecessors of the corresponding pixel as well as the successors at that direction. Furthermore, earlier studies represent these local relationships by encoding them in binary because they consider only the positive and negative intensity changes. However, we propose an alternative way of representation that encodes the relationships between each pixel and its neighbors in a multi-valued logic manner called Directional Local Gradient Based Descriptor (DLGBD). Our method not only considers the variations but also uniformity. A threshold value is defined to identify whether an intensity variation is present in the specified direction. If the intensity change exceeds the threshold value, then it is evaluated as a variation either in positively or negatively depending on the direction of the change. Three states of the relationship between multiple pixels at each direction yield a more discriminative descriptor for face retrieval. Ternary logic is applied to express three states. Ternary values that are calculated at each direction are concatenated and the resulting compound ternary value is replaced with the reference pixel. By this way, a more discriminative face descriptor is achieved which is resistant to noise and challenges in unconstrained environments. Extensive simulations are conducted over benchmark datasets and the performance of DLGBD is compared to the other state-of-the-art methods. As presented by the simulation results, the DLGBD achieves very high discriminating performance as well as providing resistance against rotation and illumination variations.
C1 [Cevik, Nazife] Istanbul Arel Univ, Dept Comp Engn, Istanbul, Turkey.
   [Cevik, Taner] Istanbul Aydin Univ, Dept Software Engn, Istanbul, Turkey.
C3 Istanbul Arel University; Istanbul Aydin University
RP Cevik, T (corresponding author), Istanbul Aydin Univ, Dept Software Engn, Istanbul, Turkey.
EM nazifecevik@arel.edu.tr; tanercevik@aydin.edu.tr
RI ÇEVİK, TANER/AAD-9934-2022; ÇEVİK, TANER/AAD-9997-2022
OI ÇEVİK, TANER/0000-0001-9653-5832; ÇEVİK, TANER/0000-0001-9653-5832
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Bo Y, NEUROCOMPUTING, V120, P365
   Chakraborty S, 2016, TRENDS EXPT BIOL, P1
   Chakraborty S, 2017, MULTIMED TOOLS APPL, V76, P1201, DOI 10.1007/s11042-015-3111-6
   Chen J, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.122
   Chen X, 2010, INT J PATTERN RECOGN, V24, P1047, DOI 10.1142/S0218001410008299
   Dahmane M., 2011, IEEE INT C AUT FAC G, P884, DOI DOI 10.1109/FG.2011.5771368
   Dan ZP, 2014, OPTIK, V125, P6320, DOI 10.1016/j.ijleo.2014.08.003
   Doshi NP, 2012, INT C PATT RECOG, P2760
   Dubey SR, 2017, ARXIV170909518CSCV
   Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724
   Fan KC, 2014, IEEE T IMAGE PROCESS, V23, P2877, DOI 10.1109/TIP.2014.2321495
   Fernández A, 2013, J MATH IMAGING VIS, V45, P76, DOI 10.1007/s10851-012-0349-8
   Guan ZY, 2010, NEUROCOMPUTING, V73, P2744, DOI 10.1016/j.neucom.2010.04.010
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Jabid T, 2010, ETRI J, V32, P784, DOI 10.4218/etrij.10.1510.0132
   Jafari-Khouzani K, 2005, IEEE T PATTERN ANAL, V27, P1004, DOI 10.1109/TPAMI.2005.126
   Jafri R, 2009, J INF PROCESS SYST, V5, P41, DOI 10.3745/JIPS.2009.5.2.041
   Jain A, 2000, COMMUN ACM, V43, P90, DOI 10.1145/328236.328110
   KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Lee JE, 2008, PROC CVPR IEEE, P373
   Lei Z, 2011, IEEE T IMAGE PROCESS, V20, P247, DOI 10.1109/TIP.2010.2060207
   Libor S, 2000, FACE RECOGNITION DAT
   Liu L, 2014, IEEE T IMAGE PROCESS, V23, P3071, DOI 10.1109/TIP.2014.2325777
   Liu L, 2017, PATTERN RECOGN, V62, P135, DOI 10.1016/j.patcog.2016.08.032
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Melendez J, 2008, PATTERN ANAL APPL, V11, P365, DOI 10.1007/s10044-007-0097-3
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Nanni L, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0083554
   Nanni L, 2012, EXPERT SYST APPL, V39, P3634, DOI 10.1016/j.eswa.2011.09.054
   Nanni L, 2010, EXPERT SYST APPL, V37, P7888, DOI 10.1016/j.eswa.2010.04.048
   Nanni L, 2010, ARTIF INTELL MED, V49, P117, DOI 10.1016/j.artmed.2010.02.006
   Nisenson M, 2003, LECT NOTES ARTIF INT, V2838, P363
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1
   Pietikäinen M, 2000, PATTERN RECOGN, V33, P43, DOI 10.1016/S0031-3203(99)00032-1
   Qi XB, 2014, IEEE T PATTERN ANAL, V36, P2199, DOI 10.1109/TPAMI.2014.2316826
   Qian XM, 2011, PATTERN RECOGN, V44, P2502, DOI 10.1016/j.patcog.2011.03.029
   Rivera AR, 2015, IEEE T PATTERN ANAL, V37, P2146, DOI 10.1109/TPAMI.2015.2392774
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Sarasota FL, 1994, P 2 IEEE WORKSH APPL
   Satpathy A, 2014, IEEE T IMAGE PROCESS, V24, P1953, DOI 10.1109/TIP.2014.2310123
   Saul LK, 2004, J MACH LEARN RES, V4, P119, DOI 10.1162/153244304322972667
   Silvén I, 2003, MACH VISION APPL, V13, P275, DOI 10.1007/s00138-002-0084-z
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Trefn J., 2010, COMP VIS WINT WORKSH, P1
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yang S, 2011, IEEE INT SYMP INFO, P2866, DOI 10.1109/ISIT.2011.6034099
   Yin QB, 2008, CHINESE J ELECTRON, V17, P646
   Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhong FJ, 2013, NEUROCOMPUTING, V119, P375, DOI 10.1016/j.neucom.2013.03.020
NR 63
TC 9
Z9 10
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 15909
EP 15928
DI 10.1007/s11042-018-6967-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500009
DA 2024-07-18
ER

PT J
AU Lin, L
   Ding, YZ
   Wang, LH
   Zhang, M
   Li, DX
AF Lin, Lu
   Ding, Yinzhang
   Wang, Lianghao
   Zhang, Ming
   Li, Dongxiao
TI Line-preserving video stitching for asymmetric cameras
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video stitching; Line-preserving; Seam finding; Asymmetric cameras
ID IMAGE
AB The narrow FOV on mobile phones is becoming unsatisfying with the development of video live broadcast. Fast and stable video stitching algorithm is urgently needed with the advent of multi-device bracket and other equipment. In this paper, we propose a novel stitching method to stitch multiple synchronized video streams which are captured from different fixed cameras. This procedure can be divided into two stages: initial template construction and seam updating. In the stage of initialization, we align the extracted background with proposed line-preserving alignment, and save the mesh for future stitching. Especially, scale estimation allows the algorithm to be applied to videos from asymmetric cameras of different resolutions and scales. In the seam updating stage, we propose a last-frame-guided seam updating method to find a smooth transition on spatial-temporal volumes. Experimental results demonstrate that our method can efficiently stitch videos without ghosting and artifacts.
C1 [Lin, Lu; Ding, Yinzhang; Wang, Lianghao; Zhang, Ming; Li, Dongxiao] Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou 310027, Zhejiang, Peoples R China.
   [Lin, Lu; Ding, Yinzhang; Wang, Lianghao; Zhang, Ming; Li, Dongxiao] Zhejiang Prov Key Lab Informat Proc Commun & Netw, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Wang, LH (corresponding author), Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou 310027, Zhejiang, Peoples R China.; Wang, LH (corresponding author), Zhejiang Prov Key Lab Informat Proc Commun & Netw, Hangzhou 310027, Zhejiang, Peoples R China.
EM wanglianghao@zju.edu.cn
FU Zhejiang Provincial Natural Science Foundation of China [LY18F010004]
FX This work was supported in part by Zhejiang Provincial Natural Science
   Foundation of China (Grant No. LY18F010004).
CR [Anonymous], 2013, EUROGRAPHICS
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Chang CH, 2014, PROC CVPR IEEE, P3254, DOI 10.1109/CVPR.2014.422
   Chen YS, 2016, LECT NOTES COMPUT SC, V9909, P186, DOI 10.1007/978-3-319-46454-1_12
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   El-Saban M, 2011, IEEE IMAGE PROC, P1481, DOI 10.1109/ICIP.2011.6115723
   El-Saban M, 2010, IEEE IMAGE PROC, P1193, DOI 10.1109/ICIP.2010.5651811
   Gao JH, 2011, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2011.5995433
   Guo H, 2016, IEEE T IMAGE PROCESS, V25, P5491, DOI 10.1109/TIP.2016.2607419
   He BT, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010007
   Hu J., 2015, MULTIMEDIA EXPO ICME, P1, DOI DOI 10.1109/ICME.2015.7177506
   Igarashi Takeo, 2009, Journal of Graphics Tools, V14, P17
   Jiang W, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301374
   Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264
   Li N, 2018, SIGNAL IMAGE VIDEO P, V12, P967, DOI 10.1007/s11760-018-1241-9
   Li N, 2018, IEEE T MULTIMEDIA, V20, P1365, DOI 10.1109/TMM.2017.2771566
   Lin CC, 2015, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2015.7298719
   Lin KM, 2016, COMPUT GRAPH FORUM, V35, P479, DOI 10.1111/cgf.12848
   Nomura Yoshikuni., 2007, P 18 EUROGRAPHICS C, P127
   Peleg S, 2000, IEEE T PATTERN ANAL, V22, P1144, DOI 10.1109/34.879794
   Perazzi F, 2015, COMPUT GRAPH FORUM, V34, P57, DOI 10.1111/cgf.12541
   Szeliski R., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P251, DOI 10.1145/258734.258861
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   von Gioi RG, 2012, IMAGE PROCESS ON LIN, V2, P35, DOI 10.5201/ipol.2012.gjmr-lsd
   Zaragoza J, 2014, IEEE T PATTERN ANAL, V36, P1285, DOI 10.1109/TPAMI.2013.247
   Zaragoza J, 2013, PROC CVPR IEEE, P2339, DOI 10.1109/CVPR.2013.303
   Zhang F, 2015, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2015.7298811
   Zhang F, 2014, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2014.423
NR 28
TC 2
Z9 2
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14591
EP 14611
DI 10.1007/s11042-018-6848-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700021
DA 2024-07-18
ER

PT J
AU Lv, TL
   Yang, GY
   Zhang, YD
   Yang, J
   Chen, Y
   Shu, HZ
   Luo, LM
AF Lv, Tianling
   Yang, Guanyu
   Zhang, Yudong
   Yang, Jian
   Chen, Yang
   Shu, Huazhong
   Luo, Limin
TI Vessel segmentation using centerline constrained level set method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vessel segmentation; Centerline; Minimal path tracking; Level set
ID PARALLEL FRAMEWORK; ACTIVE CONTOURS; EVOLUTION; SNAKES
AB Vascular related diseases have become one of the most common diseases with high mortality, high morbidity and high medical risk in the world. Level set is a kind of active contour model, and can be used to extract vessel structures. However, the applications of level set methods in vessel segmentation suffer from two problems. The first problem is the error caused by the false inclusion of some non-vessel structures. The second one is the sensitivity of the level set evolution to the initialization condition. In this paper, we propose an algorithm termed Centerline constrained level set (CC-LS) for vessel segmentation which utilizes centerline information to improve the evolution of level set. Using centerline information as the initial level set condition leads to improved evolution efficiency and extraction accuracy. Additionally, a new centerline modulated velocity term can be used in the level set evolution function to avoid the wrong inclusion of non-vessel structures. Performance of the proposed CC-LS algorithm is well validated using both 2D and 3D coronary images in different types. The proposed method is able to attain satisfactory results on both 2D and 3D coronary data.
C1 [Lv, Tianling; Yang, Guanyu; Chen, Yang; Shu, Huazhong; Luo, Limin] Southeast Univ, Key Lab Comp Network & Informat Integrat, Minist Educ, Lab Image Sci & Technol, Nanjing, Jiangsu, Peoples R China.
   [Lv, Tianling; Yang, Guanyu; Chen, Yang; Shu, Huazhong; Luo, Limin] Ctr Rech Informat Biomed Sino Francais LIA CRIBs, Rennes, France.
   [Zhang, Yudong] Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing 210097, Jiangsu, Peoples R China.
   [Yang, Jian] Minist Educ, Key Lab Photoelect Imaging Technol & Syst, Nanjing, Jiangsu, Peoples R China.
C3 Southeast University - China; Universite de Rennes; Nanjing Normal
   University
RP Chen, Y (corresponding author), Southeast Univ, Key Lab Comp Network & Informat Integrat, Minist Educ, Lab Image Sci & Technol, Nanjing, Jiangsu, Peoples R China.; Chen, Y (corresponding author), Ctr Rech Informat Biomed Sino Francais LIA CRIBs, Rennes, France.
EM chenyang.list@seu.edu.cn
RI Zhang, Yudong/I-7633-2013
OI Zhang, Yudong/0000-0002-4870-1493
FU State's Key Project of Research and Development Plan [2017YFA0104302,
   2017YFC0109202, 2017YFC0107900]; National Natural Science Foundation
   [81530060, 61871117]; Natural Science Foundation of Jiangsu Province
   [BK20150647]; Science Technology Foundation of Zhejiang province
   [2015C33199]
FX This work was supported in part by the State's Key Project of Research
   and Development Plan under Grant 2017YFA0104302, Grant 2017YFC0109202
   and 2017YFC0107900, the National Natural Science Foundation under Grant
   81530060 and 61871117, Natural Science Foundation of Jiangsu Province
   under Grant BK20150647 and by Science Technology Foundation of Zhejiang
   province under Grant 2015C33199.
CR ADALSTEINSSON D, 1995, J COMPUT PHYS, V118, P269, DOI 10.1006/jcph.1995.1098
   [Anonymous], COMPUTATIONAL MATH M
   [Anonymous], 2014, BIOMED RES INT
   [Anonymous], COMPUT MATH METHODS
   [Anonymous], IEEE 11 INT S BIOM I
   [Anonymous], ENG MED BIOL 2002 C
   [Anonymous], P SPIE INT SOC OPT E
   Boskamp T, 2004, RADIOGRAPHICS, V24, P287, DOI 10.1148/rg.241035073
   Brieval J, 2005, P ANN INT IEEE EMBS, P6348, DOI 10.1109/IEMBS.2005.1615949
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen L.-C., 2017, IEEE C COMP VIS PATT
   Chen Y, 2016, IEEE T IMAGE PROCESS, V25, P988, DOI 10.1109/TIP.2015.2496279
   CHOPP DL, 1993, J COMPUT PHYS, V106, P77, DOI 10.1006/jcph.1993.1092
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Lesage D, 2009, MED IMAGE ANAL, V13, P819, DOI 10.1016/j.media.2009.07.011
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li CM, 2010, IEEE T IMAGE PROCESS, V19, P3243, DOI 10.1109/TIP.2010.2069690
   Li CM, 2005, PROC CVPR IEEE, P430
   Li H, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT, INNOVATION MANAGEMENT AND INDUSTRIAL ENGINEERING, VOL 4, PROCEEDINGS, P410, DOI 10.1109/ICIII.2009.558
   Lorigo LM, 2001, MED IMAGE ANAL, V5, P195, DOI 10.1016/S1361-8415(01)00040-8
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   Nain D, 2004, LECT NOTES COMPUT SC, V3216, P51
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Rochery M, 2005, IEEE I CONF COMP VIS, P970
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sum KW, 2008, IEEE T BIO-MED ENG, V55, P358, DOI 10.1109/TBME.2007.896587
   Toledo R., 2000, IEEE C CVPR, V1, P1157
   Wesarg S, 2004, P SOC PHOTO-OPT INS, V5370, P1609, DOI 10.1117/12.535125
   Wink O, 2004, IEEE T MED IMAGING, V23, P130, DOI 10.1109/TMI.2003.819920
   World Health Organisation, 2018, TOP 10 CAUS DEATH
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yi J, 2003, INT J IMAG SYST TECH, V13, P208, DOI 10.1002/ima.10059
   Yim PJ, 2001, IEEE T MED IMAGING, V20, P1411, DOI 10.1109/42.974935
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
NR 41
TC 17
Z9 17
U1 1
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 17051
EP 17075
DI 10.1007/s11042-018-7087-x
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500059
DA 2024-07-18
ER

PT J
AU Zhang, J
   Huo, D
AF Zhang, Jian
   Huo, Da
TI Image encryption algorithm based on quantum chaotic map and DNA coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quantum chaotic map; DNA coding; Lorenz chaotic map; Image encryption
ID SYSTEM
AB With the rapid development of network and information technology, people are paying more attention to the security of information, particularly digital image protection, and numerous image encryption algorithms have been proposed. Because of the non-periodicity and sensitivity to the initial value, chaotic map seems to be a tool that can be used for image encryption. Recent work has shown that the quantum chaotic map is very sensitive to a slight change in the initial conditions. The sensitivity of the quantum chaotic map can extremely increase the complexity of the encryption algorithms. At present, a wide variety of image encryption algorithms based on DNA encoding have been proposed, where the image pixel values are encoded by four base pairs of DNA to achieve image pixel diffusion, but most of the methods in selecting the DNA encoding rules are fixed. In this paper, we present a new image encryption algorithm with the quantum chaotic map, the Lorenz chaotic map and DNA coding, which uses four base pairs of DNA dynamically select eight types of DNA encoding rules and eight types of DNA addition and XOR rules. This strategy has led to a significant enhancement in reliability and security. Through simulation experiments, the results of the histograms, correlations and the number of pixels change rate (NPCR) analyses indicate that the proposed algorithm possesses a high level of security and can successfully resist different attacks such as brute-force attacks and statistical attacks.
C1 [Zhang, Jian; Huo, Da] Northeast Forestry Univ, Coll Informat & Comp Engn, Harbin 150040, Heilongjiang, Peoples R China.
C3 Northeast Forestry University - China
RP Zhang, J (corresponding author), Northeast Forestry Univ, Coll Informat & Comp Engn, Harbin 150040, Heilongjiang, Peoples R China.
EM zhangjianok00@163.com; 547642616@qq.com
FU Fundamental Research Funds for the Central Universities [2572017CB35];
   Science and Technology Innovation Talent Research Fund of Harbin
   [2017RAQXJ098]
FX The work is supported by the Fundamental Research Funds for the Central
   Universities (No. 2572017CB35) and the Science and Technology Innovation
   Talent Research Fund of Harbin (No. 2017RAQXJ098).
CR Ahmed F, 2014, WIRELESS PERS COMMUN, V77, P2771, DOI 10.1007/s11277-014-1667-5
   Akhshani A, 2014, COMMUN NONLINEAR SCI, V19, P101, DOI 10.1016/j.cnsns.2013.06.017
   Akhshani A, 2012, COMMUN NONLINEAR SCI, V17, P4653, DOI 10.1016/j.cnsns.2012.05.033
   Axenides M, 2018, EUR PHYS J C, V78, DOI 10.1140/epjc/s10052-018-5850-9
   Bakhshandeh A, 2013, OPT LASER ENG, V51, P665, DOI 10.1016/j.optlaseng.2013.01.001
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   GOGGIN ME, 1990, PHYS REV A, V41, P5705, DOI 10.1103/PhysRevA.41.5705
   Hermassi H, 2013, TELECOMMUN SYST, V52, P539, DOI 10.1007/s11235-011-9459-7
   Hu T, 2017, NONLINEAR DYNAM, V87, P51, DOI 10.1007/s11071-016-3024-6
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Inoue K, 2009, OPEN SYST INF DYN, V16, P179, DOI 10.1142/S123016120900013X
   Kadir A, 2017, OPTIK, V129, P231, DOI 10.1016/j.ijleo.2016.10.036
   Kalpana J, 2015, OPTIK, V126, P5703, DOI 10.1016/j.ijleo.2015.09.091
   Kulsoom A, 2016, MULTIMED TOOLS APPL, V75, P1, DOI 10.1007/s11042-014-2221-x
   Li CQ, 2012, NONLINEAR DYNAM, V70, P2383, DOI 10.1007/s11071-012-0626-5
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Mazloom S, 2009, CHAOS SOLITON FRACT, V42, P1745, DOI 10.1016/j.chaos.2009.03.084
   Rehman AU, 2015, MULTIMED TOOLS APPL, V74, P4655, DOI 10.1007/s11042-013-1828-7
   Sharma N, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0149-4
   Tang Z, 2014, MULTIMED TOOLS APPL, P1, DOI 10.1007/s11042-014-1861-1
   Tian Y, 2017, AIP ADV, V7, DOI 10.1063/1.4994860
   Wang H, 2016, ADV MANUF, V4, P348, DOI 10.1007/s40436-016-0159-0
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P6229, DOI 10.1007/s11042-016-3311-8
   Wang XY, 2014, NONLINEAR DYNAM, V75, P567, DOI 10.1007/s11071-013-1086-2
   Wang Y, 2015, COMPUT ELECTR ENG, V46, P433, DOI 10.1016/j.compeleceng.2015.03.011
   [徐光宪 Xu Guangxian], 2014, [激光杂志, Laser Journal], V35, P23
   Zhang J., 2016, MATH PROBL ENG, V2016, P1, DOI [10.1155/2016/6408741, DOI 10.1155/2016/6408741]
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhao JF, 2015, NONLINEAR DYNAM, V80, P1721, DOI 10.1007/s11071-015-1911-x
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 32
TC 33
Z9 35
U1 6
U2 61
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 15605
EP 15621
DI 10.1007/s11042-018-6973-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700064
OA Bronze
DA 2024-07-18
ER

PT J
AU Aruanno, B
   Garzotto, F
AF Aruanno, Beatrice
   Garzotto, Franca
TI MemHolo: mixed reality experiences for subjects with Alzheimer's disease
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mixed reality; Augmented reality; HoloLens; Elderly; Alzheimer disease
   (AD); Cognitive training
ID SPATIAL MEMORY IMPAIRMENTS; MINI-MENTAL-STATE; METAANALYSIS;
   SUPERMARKET; TECHNOLOGY; DESIGN
AB HoloLens is the most recent and advanced forms of wearable Mixed Reality (MR) technology. It enables the user wearing a head-mounted device to experience 3D holographic objects inside the visualization of the real environment where he or she is located. Existing HoloLens applications have been developed in domains such as data visualization, entertainment, industrial training, education, and tourism, but the use of this technology in the arena of mental health is largely unexplored. The paper presents a HoloLens-based system called MemHolo that addresses persons with mild Alzheimer's Disease (AD). AD is associated to a chronic progressive neurodegenerative process that severely affects cognitive functioning (especially memory) and some motor functions. MemHolo is intended to be used as a cognitive training tool to practice short-term and spatial memory in a safe and controlled virtual environment, and to mitigate the effects of mental decline. The paper discusses the design process of MemHolo, and describes three evaluation studies on progressive prototypes. To our knowledge, MemHolo is the first HoloLens application designed natively for persons with AD. Our empirical work sheds a light on how these people experience HoloLens applications, highlights some challenges and potential benefits of using MR technology in the AD arena, and may pave the ground towards new forms of treatment.
C1 [Aruanno, Beatrice] Politecn Milan, Dept Mech Engn, Milan, Italy.
   [Garzotto, Franca] Politecn Milan, Dept Elect Informat & Bioengn, Comp Engn, Milan, Italy.
C3 Polytechnic University of Milan; Polytechnic University of Milan
RP Aruanno, B (corresponding author), Politecn Milan, Dept Mech Engn, Milan, Italy.
EM beatrice.aruanno@polimi.it; franca.garzotto@polimi.it
RI Aruanno, Beatrice/HGT-6981-2022; Garzotto, Franca/AAQ-7886-2020
OI Aruanno, Beatrice/0000-0002-8643-5915; 
CR Abe M, 2005, J FOREST RES-JPN, V10, P189, DOI 10.1007/s10310-004-0131-x
   Alzheimer's Association, 2016, Alzheimers Dement, V12, P459
   APA, 2013, DIAGNOSTIC STAT MANU, V5th ed.
   Aruanno B, 2018, ASSETS 2018
   Astur RS, 2002, BEHAV BRAIN RES, V132, P77, DOI 10.1016/S0166-4328(01)00399-0
   Blaschke CM, 2009, BRIT J SOC WORK, V39, P641, DOI 10.1093/bjsw/bcp025
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Burgess N, 2006, TRENDS COGN SCI, V10, P551, DOI 10.1016/j.tics.2006.10.005
   Byagowi A, 2014, J EXP NEUROSCI, V8, P7, DOI 10.4137/JEN.S13448
   Cushman LA, 2008, NEUROLOGY, V71, P888, DOI 10.1212/01.wnl.0000326262.67613.fe
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   Garzotto F, 2017, P 2017 C INT DES CHI
   Garzotto F, 2016, P INT WORK C ADV VIS, P196, DOI DOI 10.1145/2909132.2909256
   Klinger E, 2004, CYBERPSYCHOL BEHAV, V7, P292
   Lancu Iulian, 2006, Harefuah, V145, P687
   Lee JY, 2014, NEUROPSYCH DIS TREAT, V10, P653, DOI 10.2147/NDT.S58185
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Mitchell AJ, 2009, J PSYCHIATR RES, V43, P411, DOI 10.1016/j.jpsychires.2008.04.014
   MUNGAS D, 1991, GERIATRICS, V46, P54
   NHS, 2015, IS DEM TREAT
   Ohyama S, 2007, AURIS NASUS LARYNX, V34, P303, DOI 10.1016/j.anl.2007.01.002
   Prince, 2016, WORLD ALZHEIMER REPO
   Sitzer DI, 2006, ACTA PSYCHIAT SCAND, V114, P75, DOI 10.1111/j.1600-0447.2006.00789.x
   Tamura H, 2001, IEEE COMPUT GRAPH, V21, P64, DOI 10.1109/38.963462
   Werner P, 2009, DEMENT GERIATR COGN, V27, P301, DOI 10.1159/000204915
NR 25
TC 19
Z9 20
U1 3
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13517
EP 13537
DI 10.1007/s11042-018-7089-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900041
DA 2024-07-18
ER

PT J
AU Geng, SZ
   Yu, M
   Liu, Y
   Yu, Y
   Bai, J
AF Geng, Shuze
   Yu, Ming
   Liu, Yi
   Yu, Yang
   Bai, Jian
TI Re-ranking pedestrian re-identification with multiple Metrics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Re-ranking; Pedestrian re-identification; Perspective distance model;
   Kernel-local fisher discriminant analysis; Marginal fisher analysis
ID PERSON REIDENTIFICATION
AB Pedestrian re-identification (re-ID) is a video surveillance technology for specific pedestrians in non-overlapping multi-camera scenes. However, due to the influence of dramatic changes in perspectives and pedestrian occasions, it is still a huge challenge to find a stable, reliable algorithm in high accuracy rate. In this paper, to increase the robustness and performance of re-ID, we proposed a re-ID method by re-ranking the refined re-ID results (i.e. initial lists) gotten from the kernel-Local Fisher Discriminant Analysis (kLFDA) and Marginal Fisher Analysis (MFA) metrics, which can improve the probability of the correct target on the initial result lists and also enhance the robustness. During the process of re-ranking, in order to distinguish pedestrians in high similarity, a rigorous distance constraint model named Perspective Distance Model (PDM) is designed to further reduce the intra-class variations and increase the distance of inter-class variations. By using the PDM, the concise results gotten from the kLFDA and MFA metrics are re-ranked in order to further recognize different individuals in high similarity and improve the re-ID rate. Experimental results on seven challenging re-ID datasets (VIPeR, CUHK01, Prid2011, iLIDS, CUHK03, Market-1501and DukeReID) show that the performance of proposed method is high and effective.
C1 [Geng, Shuze; Yu, Ming] Hebei Univ Technol, Sch Elect Informat Engn, Tianjin 300401, Peoples R China.
   [Yu, Ming; Liu, Yi; Yu, Yang; Bai, Jian] Hebei Univ Technol, Sch Comp Sci & Engn, Tianjin 300401, Peoples R China.
C3 Hebei University of Technology; Hebei University of Technology
RP Yu, M (corresponding author), Hebei Univ Technol, Sch Elect Informat Engn, Tianjin 300401, Peoples R China.; Yu, M (corresponding author), Hebei Univ Technol, Sch Comp Sci & Engn, Tianjin 300401, Peoples R China.
EM yuming@hebut.edu.cn
RI Ming, Yu/KEH-1529-2024; Yu, Ming/AAY-8416-2021; Yu, Yang/ABG-3128-2021
FU Tianjin Sci-tech Planning Projects [15ZCZDNC00130]; Natural Science
   Foundation of Hebei Province, China [F2015202239]; Joint Doctoral
   Training Foundation of HEBUT [2017GN0009]
FX This work was granted by Tianjin Sci-tech Planning Projects (Grant No.
   14RCGFGX00846), the Natural Science Foundation of Hebei Province, China
   (Grant No. F2015202239), Tianjin Sci-tech Planning Projects (Grant No.
   15ZCZDNC00130) and Joint Doctoral Training Foundation of HEBUT (Grant
   No. 2017GN0009).
CR [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247939
   Bai S, 2016, IEEE T IMAGE PROCESS, V25, P1056, DOI 10.1109/TIP.2016.2514498
   Bazzani L., 2010, INT C PATT REC, P1413, DOI [DOI 10.1109/ICPR.2010.349, 10.1109/ICPR.2010.349]
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Chen YC, 2017, IEEE T CIRC SYST VID, V27, P1661, DOI 10.1109/TCSVT.2016.2515309
   Cheng D, 2018, PATTERN RECOGN, V82, P94, DOI 10.1016/j.patcog.2018.05.007
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Cheng KY, 2017, MULTIMED TOOLS APPL, V76, P25015, DOI 10.1007/s11042-017-4967-4
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Fedorov I, 2017, COMPUTER VISION AND
   Gou MR, 2017, IEEE COMPUT SOC CONF, P1425, DOI 10.1109/CVPRW.2017.185
   Hu HM, 2016, MULTIMED TOOLS APPL, V76, P1, DOI [10.1007/s11042-016-4070-2, DOI 10.1007/S11042-016-4070-2]
   Huo ZH, 2015, LECT NOTES COMPUT SC, V9163, P45, DOI 10.1007/978-3-319-20904-3_5
   Jiang MY, 2017, INT CONF ACOUST SPEE, P1228, DOI 10.1109/ICASSP.2017.7952352
   Karanam S, 2017, COMPUTER VISION PATT
   Kuo CH, 2013, IEEE WORK APP COMP, P281, DOI 10.1109/WACV.2013.6475030
   Leng QM, 2015, MULTIMED TOOLS APPL, V74, P6989, DOI 10.1007/s11042-014-1949-7
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463
   Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lisanti G, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3038916
   Lisanti G, 2015, IEEE T PATTERN ANAL, V37, P1629, DOI 10.1109/TPAMI.2014.2369055
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Ma XL, 2017, PATTERN RECOGN, V65, P197, DOI 10.1016/j.patcog.2016.11.018
   Mang Ye, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015, January 5-7, 2015, Proceedings: LNCS 8935, P105, DOI 10.1007/978-3-319-14445-0_10
   Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Paisitkriangkrai S, 2017, COMPUT VIS IMAGE UND, V156, P51, DOI 10.1016/j.cviu.2016.10.015
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Prates R, 2016, INT C PATT REC, V21, P1061, DOI [10.1109/ICPR.2016.7899944, DOI 10.1109/ICPR.2016.7899944]
   Prosser B., 2010, P BRIT MACH VIS C BM, DOI DOI 10.5244/C.24.21
   Qin DF, 2011, PROC CVPR IEEE, P777, DOI 10.1109/CVPR.2011.5995373
   SI J, 2018, IEEE TRANSACTIONS ON, V48, P1140, DOI DOI 10.1109/TSMC.2016.2645660
   SU C, 2018, TPAMI, V40, P1167, DOI DOI 10.1109/TPAMI.2017.2679002
   Su C, 2015, IEEE I CONF COMP VIS, P3739, DOI 10.1109/ICCV.2015.426
   Ustinova E., 2017, AVSS, P1
   Varior RR, 2016, LECT NOTES COMPUT SC, V9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wang G, 2016, COMPUTER VISION PATT
   Wang Q, 2018, PATTERN RECOGN, V75, P272, DOI 10.1016/j.patcog.2017.03.030
   Wang Q, 2018, IEEE T CIRC SYST VID, V28, P2633, DOI 10.1109/TCSVT.2017.2703920
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Xie Y, 2017, IEEE SIGNAL PROC LET, V24, P853, DOI 10.1109/LSP.2017.2679208
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Xu XX, 2015, IEEE T NEUR NET LEAR, V26, P3150, DOI 10.1109/TNNLS.2015.2405574
   Xue ML, 2013, NEURAL COMPUT APPL, V22, P1531, DOI 10.1007/s00521-012-0962-x
   Yang X, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3089249
   Yang Y, 2017, ARXIV170702319
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   YE M, 2016, TMM, V18, P2553, DOI DOI 10.1109/TMM.2016.2605058
   Ye M, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1239, DOI 10.1145/2733373.2806326
   You JJ, 2016, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2016.150
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhao R, 2017, IEEE T PATTERN ANAL, V39, P356, DOI 10.1109/TPAMI.2016.2544310
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
NR 66
TC 3
Z9 3
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11631
EP 11653
DI 10.1007/s11042-018-6654-5
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900024
DA 2024-07-18
ER

PT J
AU Liu, JP
   He, JZ
   Zhang, WX
   Tang, ZH
   Xu, PF
   Gui, WH
AF Liu, Jinping
   He, Jiezhou
   Zhang, Wuxia
   Tang, Zhaohui
   Xu, Pengfei
   Gui, Weiha
TI Texture pattern classification based on probability density function
   estimation of the image spatial structure feature with symmetrical
   weibull distribution model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Symmetric weibull distribution model (SWDM); Steerable isotropic
   Gaussian derivative filter (SIGDF); Oriented anisotropic Gaussian
   derivative filter (OAGDF); Texture image spatial structure feature
   (TISSF); Automatic texture pattern classification (ATPC)
ID DEFECT DETECTION; RECOGNITION; SEGMENTATION; DESIGN
AB Automatic texture pattern classification (ATPC) has long been an essential issue in computer vision. However, ATPC is still a challenging task since texture is a subjective conception, which is difficult to be expressed concisely by the existing computational models. The visual appearance of the imaged texture pattern (TP) visually depends on the random organization of local homogeneous fragments (LHFs) in it. Hence, it is essential to investigate the latent statistical distribution (LSD) behavior of LHFs for the texture image spatial structural feature (TISSF) characterization and expression to achieve a good performance of ATPC. We presented a probability density function estimation (PDFE)-based ATPC scheme, termed PDFE-ATPC. We demonstrated the Weibull distribution (WD) behavior of LHFs by the sequential fragmentation theory to explain the LSD of the TISSFs. To obtain the multiscale and multi-orientation detail expression of the TISSFs, we introduced an oriented Gaussian derivative filter (OGDF)-based TISSF characterization method, including the steerable isotropic Gaussian derivative filters (SIGDFs) and the oriented anisotropic Gaussian Derivative filters (OAGDFs). Successively, the LSDs of the filter responses were characterized omnidirectionally by a symmetrical WD model (SWDM) and the SWDM-based TISSF parameters, demonstrated to be directly related to the human vision perception (HVP) system, were extracted and applied to the ATPC with a spline regression-based classifier. Effectiveness of the proposed PDFE-ATPC method was verified by extensive experiments on three different texture image databases and compared with four commonly-used statistics-based texture classification methods.
C1 [Liu, Jinping; He, Jiezhou; Zhang, Wuxia; Xu, Pengfei] Hunan Normal Univ, Coll Informat Sci & Engn, Changsha 410081, Hunan, Peoples R China.
   [Liu, Jinping] Hunan Normal Univ, Coll Math & Comp Sci, Minist Educ China, Key Lab High Performance Comp & Stochast Informat, Changsha 410081, Hunan, Peoples R China.
   [Tang, Zhaohui; Gui, Weiha] Cent South Univ, Sch Informat Sci & Engn, Changsha 410083, Hunan, Peoples R China.
C3 Hunan Normal University; Hunan Normal University; Central South
   University
RP Liu, JP (corresponding author), Hunan Normal Univ, Coll Informat Sci & Engn, Changsha 410081, Hunan, Peoples R China.; Liu, JP (corresponding author), Hunan Normal Univ, Coll Math & Comp Sci, Minist Educ China, Key Lab High Performance Comp & Stochast Informat, Changsha 410081, Hunan, Peoples R China.
EM ljp202518@163.com; xupf@hunnu.edu.cn
RI liu, jinping/AAM-7723-2021
OI liu, jinping/0000-0002-8669-882X
FU National Natural Science Foundation of China (NSFC) [U1701261];
   Guangdong Provincial Government [U1701261]; NSFC [61501183, 61771492];
   Young Teacher Foundation of Hunan Normal University [11405]; MOE key
   laboratory of image processing and intelligence control [IPIC2017-03]
FX This work is supported by the Joint Fund of National Natural Science
   Foundation of China (NSFC) and Guangdong Provincial Government under
   grant U1701261, NSFC nos. 61501183, 61771492, the Young Teacher
   Foundation of Hunan Normal University under grant no. 11405 and
   partially supported by the MOE key laboratory of image processing and
   intelligence control under grant IPIC2017-03.
CR Abdelmounaime S., 2013, ISRN MACHINE VISION, V2013
   BROWN WK, 1989, J ASTROPHYS ASTRON, V10, P89, DOI 10.1007/BF02714980
   BROWN WK, 1995, J APPL PHYS, V78, P2758, DOI 10.1063/1.360073
   Chan CH, 2000, IEEE T IND APPL, V36, P1267, DOI 10.1109/28.871274
   Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1
   Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778
   Dash JK, 2017, MULTIMED TOOLS APPL, V76, P2535, DOI 10.1007/s11042-015-3231-z
   Debure K, 2008, MULTI RESOLUTION TEX
   Durgamahanthi V, 2017, J MED IMAG HEALTH IN, V7, P1188, DOI 10.1166/jmihi.2017.2255
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Fujii K, 2003, PSYCHOL RES-PSYCH FO, V67, P197, DOI 10.1007/s00426-002-0113-6
   Geusebroek JM, 2005, INT J COMPUT VISION, V62, P7, DOI 10.1007/s11263-005-4632-7
   Geusebroek JM, 2003, IEEE T IMAGE PROCESS, V12, P938, DOI 10.1109/TIP.2003.812429
   Geusebroek JM, 2002, A PHYSICAL EXPLANATI
   GUO Z, 1971, TIP, V19, P1657, DOI DOI 10.1109/TIP.2010.2044957
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hou XD, 2014, MULTIMED TOOLS APPL, V72, P1681, DOI 10.1007/s11042-013-1466-0
   Jacob M, 2004, IEEE T PATTERN ANAL, V26, P1007, DOI 10.1109/TPAMI.2004.44
   Jiang XH, 2011, MULTIMED TOOLS APPL, V52, P105, DOI 10.1007/s11042-010-0463-9
   Kiechle M, 2018, IEEE TRANS IMAGE PRO, P1
   Kuffer M, 2016, IEEE J-STARS, V9, P1830, DOI 10.1109/JSTARS.2016.2538563
   Lagrange A, 2017, IEEE T COMPUT IMAG, V3, P230, DOI 10.1109/TCI.2017.2666551
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Liu JP, 2016, J PROCESS CONTR, V44, P23, DOI 10.1016/j.jprocont.2016.04.014
   Liu JP, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16070998
   Liu JP, 2016, INT J COMPUT INT SYS, V9, P120, DOI 10.1080/18756891.2016.1144158
   Liu JP, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146484
   Liu JP, 2013, INT J COMPUT INT SYS, V6, P969, DOI 10.1080/18756891.2013.809938
   Liu JP, 2013, MINER ENG, V45, P128, DOI 10.1016/j.mineng.2013.02.003
   LIU L, 2012, TPAMI, V34, P574, DOI DOI 10.1109/TPAMI.2011.145
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lopez-Molina C, 2015, SIGNAL PROCESS, V116, P55, DOI 10.1016/j.sigpro.2015.03.024
   Muhammad G, 2014, MACH VISION APPL, V25, P985, DOI 10.1007/s00138-013-0547-4
   Prats-Montalbán JM, 2014, COMPUT CHEM ENG, V71, P501, DOI 10.1016/j.compchemeng.2014.09.014
   Qi XB, 2016, NEUROCOMPUTING, V171, P1230, DOI 10.1016/j.neucom.2015.07.071
   Seetharaman K, 2015, ENG APPL ARTIF INTEL, V40, P103, DOI 10.1016/j.engappai.2015.01.008
   Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1
   Shui PL, 2012, PATTERN RECOGN, V45, P806, DOI 10.1016/j.patcog.2011.07.020
   Susan S, 2017, NEUROCOMPUTING, V239, P232, DOI 10.1016/j.neucom.2017.02.021
   UNSER M, 1986, IEEE T PATTERN ANAL, V8, P118, DOI 10.1109/TPAMI.1986.4767760
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Xiang SM, 2010, IEEE T PATTERN ANAL, V32, P2039, DOI 10.1109/TPAMI.2010.35
   Xiang SM, 2009, IEEE T IMAGE PROCESS, V18, P1623, DOI 10.1109/TIP.2009.2018570
   Yang GL, 2016, MULTIMED TOOLS APPL, V75, P15601, DOI [10.1007/s11042-015-2649-7, 10.1155/2015/932029]
   Zhang J, 2016, MINER ENG, V86, P116, DOI 10.1016/j.mineng.2015.12.008
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
NR 46
TC 1
Z9 1
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 12251
EP 12279
DI 10.1007/s11042-018-6704-z
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900053
DA 2024-07-18
ER

PT J
AU Raheel, A
   Anwar, SM
   Majid, M
AF Raheel, Aasim
   Anwar, Syed Muhammad
   Majid, Muhammad
TI Emotion recognition in response to traditional and tactile enhanced
   multimedia using electroencephalography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion recognition; Multimedia; Tactile enhanced multimedia;
   Classification; Electroencephalography
ID FACIAL EXPRESSIONS; BRAIN; ASYMMETRY; SYSTEM; POWER
AB The goal of this study is to enhance the emotional experience of a viewer by using enriched multimedia content, which entices tactile sensation in addition to vision and auditory senses. A user-independent method of emotion recognition using electroencephalography (EEG) in response to tactile enhanced multimedia (TEM) is presented with an aim of enriching the human experience of viewing digital content. The selected traditional multimedia clips are converted into TEM clips by synchronizing them with an electric fan and a heater to add cold and hot air effect. This would give realistic feel to a viewer by engaging three human senses including vision, auditory, and tactile. The EEG data is recorded from 21 participants in response to traditional multimedia clips and their TEM versions. Self assessment manikin (SAM) scale is used to collect valence and arousal score in response to each clip to validate the evoked emotions. A t-test is applied on the valence and arousal values to measure any significant difference between multimedia and TEM clips. The resulting p-values show that traditional multimedia and TEM content are significantly different in terms of valence and arousal scores, which shows TEM clips have enhanced evoked emotions. For emotion recognition, twelve time domain features are extracted from the preprocessed EEG signal and a support vector machine is applied to classify four human emotions i.e., happy, angry, sad, and relaxed. An accuracy of 43.90% and 63.41% against traditional multimedia and TEM clips is achieved respectively, which shows that EEG based emotion recognition performs better by engaging tactile sense.
C1 [Raheel, Aasim; Anwar, Syed Muhammad; Majid, Muhammad] Univ Engn & Technol, Dept Comp Engn, Taxila, Pakistan.
C3 University of Engineering & Technology Taxila
RP Majid, M (corresponding author), Univ Engn & Technol, Dept Comp Engn, Taxila, Pakistan.
EM asim.raheel@uettaxila.edu.pk; s.anwar@uettaxila.edu.pk;
   m.majid@uettaxila.edu.pk
RI anwar, syed/AGY-3965-2022; Majid, Muhammad/Z-5667-2019
OI anwar, syed/0000-0002-8179-3959; Majid, Muhammad/0000-0003-3662-2525
CR Aftanas L I, 2004, Neurosci Behav Physiol, V34, P859, DOI 10.1023/B:NEAB.0000038139.39812.eb
   Alarcao S. M., 2017, IEEE T AFFECT COMPUT, DOI [DOI 10.1109/TAFFC.2017.2714671, 10.1109/ TAFFC.2017.2714671, 10.1109/TAFFC.2017.2714671]
   Allen JJB, 2004, BIOL PSYCHOL, V67, P183, DOI 10.1016/j.biopsycho.2004.03.007
   Anagnostopoulos CN, 2015, ARTIF INTELL REV, V43, P155, DOI 10.1007/s10462-012-9368-5
   [Anonymous], 2016, P STUD RES C INF INF
   Balconi M, 2008, INT J PSYCHOPHYSIOL, V67, P41, DOI 10.1016/j.ijpsycho.2007.10.002
   Basar E, 1999, IEEE ENG MED BIOL, V18, P56, DOI 10.1109/51.765190
   Bethel CL, 2007, 2007 RO-MAN: 16TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, VOLS 1-3, P727
   Bhatti AM, 2016, COMPUT HUM BEHAV, V65, P267, DOI 10.1016/j.chb.2016.08.029
   Chanel G, 2011, IEEE T SYST MAN CY A, V41, P1052, DOI 10.1109/TSMCA.2011.2116000
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   de Gelder B, 2015, WIRES COGN SCI, V6, P149, DOI 10.1002/wcs.1335
   Du YY, 2016, VISION RES, V128, P19, DOI 10.1016/j.visres.2016.08.005
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Gao Y, 2015, 2015 IEEE INT C MULT, P1, DOI DOI 10.1109/ICMEW.2015.7169796
   Ghinea G, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2617994
   Graziotin D, 2015, 7TH INTERNATIONAL WORKSHOP ON SOCIAL SOFTWARE ENGINEERING (SSE 2015), P25, DOI 10.1145/2804381.2804386
   Heller W., 1993, NEUROPSYCHOLOGY, V7, P476, DOI DOI 10.1037/0894-4105.7.4.476
   Jalilifard A, 2016, IEEE ENG MED BIO, P845, DOI 10.1109/EMBC.2016.7590833
   Kalsum T, 2018, IET IMAGE PROCESS, V12, P1004, DOI 10.1049/iet-ipr.2017.0499
   Kim J, 2008, IEEE T PATTERN ANAL, V30, P2067, DOI 10.1109/TPAMI.2008.26
   Kim KH, 2004, MED BIOL ENG COMPUT, V42, P419, DOI 10.1007/BF02344719
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Kroupi E, 2016, IEEE T AFFECT COMPUT, V7, P422, DOI 10.1109/TAFFC.2015.2496310
   Lahane P, 2015, PROCEDIA COMPUT SCI, V48, P574, DOI 10.1016/j.procs.2015.04.138
   Lin HY, 2016, BIOL PSYCHOL, V120, P126, DOI 10.1016/j.biopsycho.2016.09.006
   Lin YP, 2010, IEEE T BIO-MED ENG, V57, P1798, DOI 10.1109/TBME.2010.2048568
   Liu S, 2016, IEEE ENG MED BIO, P841, DOI 10.1109/EMBC.2016.7590832
   Murray N, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2637293
   Murray Niall., 2013, Proceedings of the 4th ACM Multimedia Systems Conference, MMSys'13, P162, DOI [https://doi.org/10.1145/2483977.2483999, DOI 10.1145/2483977.2483999]
   Pan JH, 2016, IEEE IJCNN, P2063, DOI 10.1109/IJCNN.2016.7727453
   Park C, 2006, EMB SYST REAL TIME M, P53
   Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607
   Qayyum H, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/9854050
   Sanei S., 2007, EEG Signal Processing, DOI [10.1002/9780470511923, DOI 10.1002/9780470511923]
   Sarlo M, 2005, NEUROSCI LETT, V382, P291, DOI 10.1016/j.neulet.2005.03.037
   Schmidt LA, 2001, COGNITION EMOTION, V15, P487, DOI 10.1080/0269993004200187
   Schutter DJL, 2001, NEUROSCI LETT, V314, P13, DOI 10.1016/S0304-3940(01)02246-7
   Sen B, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0018-0
   Singh H, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00893
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P211, DOI 10.1109/T-AFFC.2011.37
   Subramanian R, 2018, IEEE T AFFECT COMPUT, V9, P147, DOI 10.1109/TAFFC.2016.2625250
   Sulema Y, 2016, INT CONF SYST SIGNAL, P19
   Yuan ZH, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2661329
   Zhuang N, 2017, BIOMED RES INT-UK, V2017, DOI 10.1155/2017/8317357
NR 45
TC 26
Z9 26
U1 0
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13971
EP 13985
DI 10.1007/s11042-018-6907-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900061
DA 2024-07-18
ER

PT J
AU Sayahi, I
   Elkefi, A
   Ben Amar, C
AF Sayahi, Ikbel
   Elkefi, Akram
   Ben Amar, Chokri
TI Crypto-watermarking system for safe transmission of 3D multiresolution
   meshes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D watermarking; Spiral scanning; Wavelet transform; SHA1 algorithm; AES
   algorithm; Robustness
ID COMPRESSION; SCHEME; OBJECT
AB The idea of digitizing documents to be archived or shared has given rise to a variety of new data types such as 3D meshes. The sharing of this data type between remote users, using high-speed computer networks and remote multimedia databases, poses great security problems. As a solution, we propose, in this paper, a new crypto watermarking algorithm. The originality of this work lies in joining cryptography with digital watermarking to secure 3D multiresolution meshes. To this end, three steps should be executed. The first is the watermark preparation. It consists, firstly, in applying the Secure Hash Algorithm 1 algorithm to generate an electronic signature of the mesh source. Secondly, the logo undergoes an encryption using Advanced Encryption Standard algorithm. To end this step, the signature and the encrypted logo pass through a convolutional encoder to obtain a codeword. As for the second step, it is called mesh preparation and it consists in applying a spiral scanning method to the mesh to split it into Groups Of Triangles. For each Group Of Triangles, a wavelet transform is applied to generate the corresponding Wavelet coefficients vector. Finally, embedding data occurs using the cylindrical coordinate system, a modulation and the least Significant Bit method. The experiment of our algorithm proves that it allows a very high insertion rate without influencing the mesh quality. Our algorithm also minimizes the amount of memory used. Moreover, it is robust against the most popular attacks. Our results show that our algorithm presents an improvement in comparison with recently published results.
C1 [Sayahi, Ikbel; Elkefi, Akram; Ben Amar, Chokri] Univ Sfax, Res Grp Intelligent Machines REGIM, ENIS, Sfax, Tunisia.
   [Ben Amar, Chokri] Taif Univ, Coll Comp & Informat Technol, At Taif, Saudi Arabia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS); Taif
   University
RP Sayahi, I (corresponding author), Univ Sfax, Res Grp Intelligent Machines REGIM, ENIS, Sfax, Tunisia.
EM phd.ikbel.sayahi@ieee.org; elkefi@gmail.com; chokri.benamar@ieee.org
RI Chokri, BEN AMAR/K-5237-2012
CR [Anonymous], 2011, IJCA
   Basyoni Lamiaa, 2015, 7th International Conference on Information Technology, P612, DOI 10.15849/icit.2015.0107
   Benyamin N., 2014, MULTIMEDIA TOOLS APP, V71, P1469, DOI [10.1007/s11042-012-1292-9, DOI 10.1007/s11042-012-1292-9]
   Bo GR, 2015, AER ADV ENG RES, V21, P1105
   Charfeddine M, 2014, MULTIMED TOOLS APPL, V70, P1521, DOI 10.1007/s11042-012-1167-0
   Che XJ, 2012, INT J PARALLEL EMERG, V27, P133, DOI 10.1080/17445760.2011.574631
   Cho DJ, 2015, INT J SECUR APPL, V9, P305, DOI 10.14257/ijsia.2015.9.1.29
   Chrysafis C, 2000, IEEE T IMAGE PROCESS, V9, P378, DOI 10.1109/83.826776
   Dang QH, 2002, SECURE HASH STANDARD, P180
   Ding GG, 2016, IEEE T IMAGE PROCESS, V25, P5427, DOI 10.1109/TIP.2016.2607421
   Elkefi A, 2011, COMPRESSION MAILLAGE
   Garg H, 2014, INT CONF COMM SYST, P788, DOI 10.1109/CSNT.2014.165
   Guedri B, 2011, 2011 INT C HIGH PERF, DOI [10. 1109/HPCSim. 2011. 5999848, DOI 10.1109/HPCSIM.2011.5999848]
   Isenburg M, 2003, ACM T GRAPHIC, V22, P935, DOI 10.1145/882262.882366
   Koubaa M, 2012, MULTIMED TOOLS APPL, V56, P281, DOI 10.1007/s11042-010-0626-8
   Lu K, 2014, IEEE T IMAGE PROCESS, V23, P4553, DOI 10.1109/TIP.2014.2343460
   Mahajan P., 2013, GLOBAL J COMPUTER SC, V13
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Othmani M, 2010, INT J WAVELETS MULTI, V8, P149, DOI 10.1142/S0219691310003353
   Pancholi V.R., 2016, International Journal for Innovative Research in Science and Technology, V2, P18
   Parisot C, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P403, DOI 10.1109/MMSP.2001.962767
   Roland H., 2014, MATH PROBL ENG, V2014, P27
   Rolland-Neviere X, 2014, ROBUST 3D WATERMARKI
   Sayahi Ikbel, 2015, 10th International Conference on Computer Vision Theory and Applications (VISAPP 2015). Proceedings, P150
   Sayahi I., 2016, INT J COMPUT SCI INF, V14, P331
   Sayahi I, 2006, INT C COMP INT SEC I, P526
   Sayahi I., 2016, INT J MULTIMEDIA TOO, P1
   Su ZY, 2013, COMPUT AIDED DESIGN, V45, P1042, DOI 10.1016/j.cad.2013.04.001
   Sweldens W, 1998, SIAM J MATH ANAL, V29, P511, DOI 10.1137/S0036141095289051
   Tamane Sharvari C., 2012, International Journal of Computer Science & Information Technology, V4, P117, DOI 10.5121/ijcsit.2012.4110
   Tariq S., 2016, INT J COMPUT SCI INF, V14, P440
   Tsai YY, 2016, 3D RES, V7, DOI 10.1007/s13319-015-0078-z
   Tsai YY, 2016, MULTIMED TOOLS APPL, V75, P7891, DOI 10.1007/s11042-015-2707-1
   Umamageswari A., 2014, INT J APPL ENG RES, V9, P12163
   VITERBI AJ, 1971, IEEE T COMMUN TECHN, VCO19, P751, DOI 10.1109/TCOM.1971.1090700
   Wadi SM, 2014, WIRELESS PERS COMMUN, V79, P811, DOI 10.1007/s11277-014-1888-7
   Wali A, 2010, LECT NOTES COMPUT SC, V6475, P110, DOI 10.1007/978-3-642-17691-3_11
   Wang D, 2017, NEUROCOMPUTING, V252, P58, DOI 10.1016/j.neucom.2016.06.095
   Wang JT, 2014, 2014 INTERNATIONAL SYMPOSIUM ON COMPUTER, CONSUMER AND CONTROL (IS3C 2014), P1095, DOI 10.1109/IS3C.2014.285
   Xiao Zhou, 2012, 2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet), P1509, DOI 10.1109/CECNet.2012.6201895
   Ying Y, 2016, IEEE T VISUALIZATION
   Zaid AO, 2015, MULTIMED TOOLS APPL, V74, P5897, DOI 10.1007/s11042-014-1896-3
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zhao S, 2015, SIGNAL PROCESS, V112, P110, DOI 10.1016/j.sigpro.2014.09.038
   Zhao SC, 2015, NEUROCOMPUTING, V151, P533, DOI 10.1016/j.neucom.2014.03.092
NR 45
TC 8
Z9 8
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13877
EP 13903
DI 10.1007/s11042-018-6721-y
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900057
DA 2024-07-18
ER

PT J
AU Wang, XY
   Feng, SH
   Lang, CY
AF Wang, Xiaoying
   Feng, Songhe
   Lang, Congyan
TI Semi-supervised dual low-rank feature mapping for multi-label image
   annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic image annotation; Multi-label learning; Semi-supervised
   learning; Self-recovery model; Graph Laplacian regularization; Dual
   low-rank regularization
AB Automatic image annotation as a typical multi-label learning problem, has gained extensive attention in recent years owing to its application in image semantic understanding and relevant disciplines. Nevertheless, existing annotation methods share the same challenge that labels annotated on the training images are usually incomplete and unclean, while the need for adequate training data is costly and unrealistic. Being aware of this, we propose a dual low-rank regularized multi-label learning model under a graph regularized semi-supervised learning framework, which can effectively capture the label correlations in the learned feature space, and enforce the label matrix be self-recovered in label space as well. To be specific, the proposed approach firstly puts forward a label matrix refinement approach, by introducing a label coefficient matrix to build a linear self-recovery model. Then, graph Laplacian regularization is introduced to make use of a large number of unlabeled images by enforcing the local geometric structure on both labeled and unlabeled images. Lastly, we exploit dual trace norm regularization on both feature mapping matrix and self-recovery coefficient matrix to capture the correlations among different labels in both feature space and label space, and control the model complexity as well. Empirical studies on four real-world image datasets demonstrate the effectiveness and efficiency of the proposed framework.
C1 [Wang, Xiaoying; Feng, Songhe; Lang, Congyan] Beijing Jiaotong Univ, Beijing Key Lab Traff Data Anal & Min, Beijing, Peoples R China.
   [Wang, Xiaoying; Feng, Songhe; Lang, Congyan] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University
RP Feng, SH (corresponding author), Beijing Jiaotong Univ, Beijing Key Lab Traff Data Anal & Min, Beijing, Peoples R China.; Feng, SH (corresponding author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.
EM 15120444@bjtu.edu.cn; shfeng@bjtu.edu.cn; cylang@bjtu.edu.cn
FU National Natural Science Foundation of China [61472028, 61502026,
   61673048]; Fundamental Research Funds for the Central Universities
   [2017JBZ108]; Beijing Natural Science Foundation [4162048]; Joint
   Research Fund for The Ministry of Education of China; China Mobile
   [MCM20160206]
FX This work is supported in part by National Natural Science Foundation of
   China (61472028, 61502026, 61673048), the Fundamental Research Funds for
   the Central Universities (2017JBZ108), Beijing Natural Science
   Foundation (4162048) and the Joint Research Fund for The Ministry of
   Education of China and China Mobile (MCM20160206).
CR [Anonymous], 2004, P 12 ANN ACM INT C M, DOI [10.1145/1027527.1027608, DOI 10.1145/1027527.1027608]
   [Anonymous], 2009, P ACM INT C IM VID R
   BAO B, 2000, IEEE T IMAGE PROCESS, V21, P3794
   Bao BK, 2013, IEEE T IMAGE PROCESS, V22, P860, DOI 10.1109/TIP.2012.2219543
   Bucak S. S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2801, DOI 10.1109/CVPR.2011.5995734
   Cai D., 2010, KDD, P333
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Chen WF, 2013, IEEE INT CONF CON AU, P1274
   FAN J, 1954, IEEE T IMAGE PROCESS, V20, P837
   Feng S H, 2017, MULTIDIMENSIONAL SYS, V11, P1
   Feng SH, 2015, IEEE T IMAGE PROCESS, V24, P1223, DOI 10.1109/TIP.2015.2395816
   Feng ZY, 2013, IEEE I CONF COMP VIS, P1609, DOI 10.1109/ICCV.2013.203
   Goldberg A. B., 2010, Advances in Neural Information Processing Systems, P757
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Huang S.J., 2012, 26 AAAI C ART INT, P949
   Hwang SJ, 2012, INT J COMPUT VISION, V100, P134, DOI 10.1007/s11263-011-0494-3
   Jeon J., 2003, P 26 ANN INT ACM SIG
   Ji S., 2009, An accelerated gradient method for trace norm minimization, P457
   Jian L., 2016, P 25 INT JOINT C ART, P1627
   Jing LP, 2015, PROC CVPR IEEE, P1483, DOI 10.1109/CVPR.2015.7298755
   Li B, 2017, IEEE T PATTERN ANAL, V39, P2554, DOI 10.1109/TPAMI.2017.2669303
   Li B, 2015, IEEE T IMAGE PROCESS, V24, P5193, DOI 10.1109/TIP.2015.2479400
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Li X, 2016, IEEE T IMAGE PROCESS, V25, P484, DOI 10.1109/TIP.2015.2503700
   Lin ZJ, 2014, PR MACH LEARN RES, V32, P325
   Makadia A, 2010, INT J COMPUT VISION, V90, P88, DOI 10.1007/s11263-010-0338-6
   Nesterov Y., 1983, SOV MATH DOKL, V27, P372
   Peng HW, 2017, IEEE T PATTERN ANAL, V39, P818, DOI 10.1109/TPAMI.2016.2562626
   Putthividhya D, 2010, PROC CVPR IEEE, P3408, DOI 10.1109/CVPR.2010.5540000
   Sang JT, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/3001594
   Sang JT, 2012, IEEE T MULTIMEDIA, V14, P883, DOI 10.1109/TMM.2012.2188782
   Toh KC, 2010, PAC J OPTIM, V6, P615
   Wang H, 2009, IEEE I CONF COMP VIS, P2029, DOI 10.1109/ICCV.2009.5459447
   Wang XJ, 2008, IEEE T PATTERN ANAL, V30, P1919, DOI 10.1109/TPAMI.2008.127
   Wu L, 2013, IEEE T PATTERN ANAL, V35, P716, DOI 10.1109/TPAMI.2012.124
   Xu LL, 2014, IEEE DATA MINING, P1067, DOI 10.1109/ICDM.2014.125
   Xu Miao, 2013, ADV NEURAL INFORM PR, P2301, DOI DOI 10.5555/2999792.2999869
   Yang Y, 2012, IEEE T IMAGE PROCESS, V21, P1339, DOI 10.1109/TIP.2011.2169269
   Yuan ZQ, 2014, IEEE T MULTIMEDIA, V16, P1624, DOI 10.1109/TMM.2014.2322338
   Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019
   Zhang ML, 2015, IEEE T PATTERN ANAL, V37, P107, DOI 10.1109/TPAMI.2014.2339815
   Zhao F, 2016, P 25 INT JOINT C ART, P2378
   Zhao FP, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P4062
NR 43
TC 8
Z9 8
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13149
EP 13168
DI 10.1007/s11042-018-5719-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900023
DA 2024-07-18
ER

PT J
AU He, JW
   Pei, JL
AF He Jianwei
   Pei Jiali
TI Image segmentation method based on improved fuzzy Chan-Vese model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Level set; Chan-Vese model; Medical image segmentation; Fuzzy c-means;
   OTSU
ID ALGORITHMS
AB Medical image segmentation is a hot topic in the field medical image processing. The segmentation methods based on level set and the ones based on fuzzy set are currently very popular in the field of medical image segmentation. But these methods do not balance between global and local features of the image. This paper combines the advantages of these two methods, proposes a fuzzy Chan-Vese model, which introduces fuzzy clustering into Chan-Vese model. This model extends the regional energy part of Chan-Vese model to regional energy based on fuzzy clustering, meanwhile adds fuzzy cluster objects as the constraint of the model, so it can take account of global and local features of the image. In the medical image segmentation experiments, this paper uses OTSU method to execute initial segmentation for getting the initial segmentation curve, and then uses fuzzy Chan-Vese model to realize image segmentation. Experimental results show that, with the help of prior knowledge of segmentation prototypes of medical images, the proposed method has achieved very good segmentation results.
C1 [He Jianwei; Pei Jiali] Ningbo Dahongying Univ, Sch Informat Engn, Ningbo 315175, Zhejiang, Peoples R China.
C3 Ningbo University of Finance & Economics
RP He, JW (corresponding author), Ningbo Dahongying Univ, Sch Informat Engn, Ningbo 315175, Zhejiang, Peoples R China.
EM 47770752@qq.com; 157968222@qq.com
CR Al-Ayyoub M, 2015, J SUPERCOMPUT, V71, P3149, DOI 10.1007/s11227-015-1431-y
   [Anonymous], 2015, INT J SIGNAL PROCESS, DOI DOI 10.14257/ijsip.2015.8.7.21
   [Anonymous], 2013, INT J ADV RES COMPUT
   Cheng L, 2005, BIENNIAL INT C INFOR, P418
   Gong MG, 2013, IEEE T IMAGE PROCESS, V22, P573, DOI 10.1109/TIP.2012.2219547
   Lee SH, 2006, IEEE T IMAGE PROCESS, V15, P2843, DOI 10.1109/TIP.2006.877308
   Li YY, 2015, INFORM SCIENCES, V294, P408, DOI 10.1016/j.ins.2014.10.005
   Marquina A, 2000, SIAM J SCI COMPUT, V22, P387, DOI 10.1137/S1064827599351751
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Narkhede H.P., 2013, International Journal of Science and Modern Engineering, V1, P54
   Norouzi A, 2014, IETE TECH REV, V31, P199, DOI 10.1080/02564602.2014.906861
   Patil DD., 2013, IJCSMC, V2, P22
   Peng B, 2013, PATTERN RECOGN, V46, P1020, DOI 10.1016/j.patcog.2012.09.015
   Torbati N, 2014, COMPUT BIOL MED, V44, P76, DOI 10.1016/j.compbiomed.2013.10.029
   Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046
   Wang XF, 2010, PATTERN RECOGN, V43, P603, DOI 10.1016/j.patcog.2009.08.002
   Yang X, 2015, IEEE T IMAGE PROCESS, V24, P9, DOI 10.1109/TIP.2014.2372615
   Zhang WL, 2015, NEUROIMAGE, V108, P214, DOI 10.1016/j.neuroimage.2014.12.061
   Zheng Y, J INTELLIGENT
NR 19
TC 4
Z9 4
U1 4
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8669
EP 8681
DI 10.1007/s11042-018-5952-2
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800043
DA 2024-07-18
ER

PT J
AU Wang, BJ
   Chen, TS
   Jeng, FG
   Chen, TH
AF Wang, Bing-Jian
   Chen, Tzer-Shyong
   Jeng, Fuh-Gwo
   Chen, Tzung-Her
TI On the security of threshold random grid-based visual secret sharing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual secret sharing; Visual cryptography; Random grid; Cheating
   prevention
ID CHEATING PREVENTION; CRYPTOGRAPHY; ENCRYPTION; SCHEMES
AB Visual secret sharing (VSS) technology encodes a secret image into some share images for sharing some classified information. Only when the participants gather and stack their share pictures the secret image would be reconstructed and recognizable by the human visual system. Two well-known encoding ways of VSS, visual cryptography (VC) and random grid (RG), have been developed in recent years. As both VC and RG have been considered as a secure way for communicating with high security, they have been pointed out with cheating problems. In this paper, we propose two RG-based VSS schemes with fraud prevention for the cases of (2,n) and (k,n). The experimental results and the analysis of security and contrast show that the proposed method is efficient and practical.
C1 [Wang, Bing-Jian; Chen, Tzung-Her] Natl Chiayi Univ, Dept Comp Sci & Informat Engn, Chiayi 60004, Taiwan.
   [Chen, Tzer-Shyong] Tunghai Univ, Dept Informat Management, Taichung 40704, Taiwan.
   [Jeng, Fuh-Gwo] Natl Chiayi Univ, Dept Appl Math, Chiayi 60004, Taiwan.
C3 National Chiayi University; Tunghai University; National Chiayi
   University
RP Chen, TH (corresponding author), Natl Chiayi Univ, Dept Comp Sci & Informat Engn, Chiayi 60004, Taiwan.
EM thchen@mail.ncyu.edu.tw
OI Chen, Tzung-Her/0000-0001-5775-6034; Chen,
   Tzer-Shyong/0000-0001-8915-5057
CR Blundo C, 2001, DESIGN CODE CRYPTOGR, V24, P255, DOI 10.1023/A:1011271120274
   Chang CC, 2005, 11th International Conference on Parallel and Distributed Systems Workshops, Vol II, Proceedings,, P300
   Chen T., 2008, P 18 INF SEC C HUAL
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Chen TH, 2009, PATTERN RECOGN, V42, P2203, DOI 10.1016/j.patcog.2008.11.015
   Eisen PA, 2002, DESIGN CODE CRYPTOGR, V25, P15, DOI 10.1023/A:1012504516447
   Fang WP, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2193912
   Fang WP, 2009, INT J COMPUT SCI NET, V9, P204
   Horng G, 2006, DESIGN CODE CRYPTOGR, V38, P219, DOI 10.1007/s10623-005-6342-0
   Hu CM, 2007, IEEE T IMAGE PROCESS, V16, P36, DOI 10.1109/TIP.2006.884916
   Huang JC, 2017, MULTIMED TOOLS APPL, V76, P9667, DOI 10.1007/s11042-016-3573-1
   Ito R, 1999, IEICE T FUNDAMENTALS, VE82-A
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Lee YS, 2012, SIGNAL PROCESS, V92, P727, DOI 10.1016/j.sigpro.2011.09.015
   Lin CH, 2015, J VIS COMMUN IMAGE R, V33, P31, DOI 10.1016/j.jvcir.2015.08.018
   Lin KS, 2014, INFORM SCIENCES, V288, P330, DOI 10.1016/j.ins.2014.07.016
   Lukac R, 2005, PATTERN RECOGN, V38, P767, DOI 10.1016/j.patcog.2004.11.010
   Naor M, 1997, LECT NOTES COMPUT SC, V1294, P322
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Prisco R.D., 2006, LECT NOTES COMPUTER, V4116
   Shu-Fen Tu, 2009, 2009 Symposia and Workshops on Ubiquitous, Autonomic and Trusted Computing in conjunction with the UIC 2009 and ATC 2009 Conferences, P362, DOI 10.1109/UIC-ATC.2009.33
   Shyu SH, 2007, PATTERN RECOGN, V40, P1014, DOI 10.1016/j.patcog.2006.02.025
   Tsai D. S., 2007, P 17 INF SEC C, P769
   Tsai DS, 2007, PATTERN RECOGN, V40, P2356, DOI 10.1016/j.patcog.2007.01.013
   Vashistha A, 2010, IEEE INT CON MULTI, P1641, DOI 10.1109/ICME.2010.5583256
   Wu XT, 2012, J SYST SOFTWARE, V85, P1119, DOI 10.1016/j.jss.2011.12.041
NR 26
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10157
EP 10180
DI 10.1007/s11042-018-6478-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400031
DA 2024-07-18
ER

PT J
AU Xing, M
   Hu, J
   Feng, ZY
   Su, Y
   Peng, WL
   Zheng, JQ
AF Xing, Meng
   Hu, Jing
   Feng, Zhiyong
   Su, Yong
   Peng, Weilong
   Zheng, Jinqing
TI Dynamic hand gesture recognition using motion pattern and shape
   descriptors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic hand gesture recognition; Hand configuration; Spatial-temporal
   variability; Motion pattern descriptor; Shape descriptor
ID DEPTH; HISTOGRAMS; GRADIENTS
AB The key problems of dynamic hand gesture recognition are large intra-class (gesture types, without considering hand configuration) spatial-temporal variability and similar inter-class (gesture types, only considering hand configuration) motion pattern. Firstly, for intra-class spatial-temporal variability, the key is to reduce the spatial-temporal variability. Due to the average operation can improve the robustness very well, we propose a motion pattern descriptor, Time-Wise Histograms of Oriented Gradients (TWHOG), which extracts the average spatial-temporal information in the space-time domain from three orthogonal projection views (XY, YT, XT). Secondly, for similar inter-class motion pattern, accurate representation of hand configuration is especially important. Therefore, the difference in detail needs to be fully captured, and the shape descriptor can amplify subtle differences. Specifically, we introduce Depth Motion Maps-based Histograms of Oriented Gradients (DMM-HOG) to capture subtle differences in hand configurations between different types of gestures with similar motion patterns. Finally, we concatenate TWHOG and DMM-HOG to form the final feature vector Time-Shape Histograms of Oriented Gradients (TSHOG) and verify the effectiveness of the connection from quantitative and qualitative perspective. Comparison study with the state-of-the-art approaches are conducted on two challenge depth gesture datasets (MSRGesture3D, SKIG). The experiment result shows that TSHOG can achieve satisfactory performance while keeping a relative simple model with lower complexity as well as higher generality.
C1 [Xing, Meng; Hu, Jing; Su, Yong; Peng, Weilong] Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.
   [Feng, Zhiyong] Tianjin Univ, Sch Comp Software, Tianjin 300072, Peoples R China.
   [Zheng, Jinqing] Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.
C3 Tianjin University; Tianjin University; Chinese Academy of Sciences;
   Institute of Automation, CAS
RP Feng, ZY (corresponding author), Tianjin Univ, Sch Comp Software, Tianjin 300072, Peoples R China.
EM zyfeng@tju.edu.cn
RI su, yong/JEO-5411-2023; Peng, Weilong/GVS-5360-2022; Gulliver,
   Aaron/K-7925-2012
OI su, yong/0000-0002-6851-4142; Peng, Weilong/0000-0001-5820-889X; Feng,
   Zhiyong/0000-0001-8158-7453; Zheng, Jinqing/0000-0002-1772-0085; Meng,
   Xing/0000-0001-6082-4675
CR Ahmed W, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE (ICIS), P120, DOI 10.1109/INFOSCI.2016.7845312
   [Anonymous], 2014, P 2 INT C HUM AG INT
   [Anonymous], 2017, ARXIV170502953
   [Anonymous], J MATH PROBLEMS ENG
   [Anonymous], ONLINE DETECTION CLA
   [Anonymous], PAC RIM S IM VID TEC
   [Anonymous], IEEE COMP SOC C COMP
   [Anonymous], 2013, IJCAI
   Chen C, 2017, MULTIMED TOOLS APPL, V76, P4651, DOI 10.1007/s11042-016-3284-7
   Chen C, 2015, IEEE WINT CONF APPL, P1092, DOI 10.1109/WACV.2015.150
   Chen C, 2016, J REAL-TIME IMAGE PR, V12, P155, DOI 10.1007/s11554-013-0370-1
   Cirujeda Pol, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P657, DOI 10.1109/3DV.2014.10
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Derpanis KG, 2013, IEEE T PATTERN ANAL, V35, P527, DOI 10.1109/TPAMI.2012.141
   Dominio F, 2014, PATTERN RECOGN LETT, V50, P101, DOI 10.1016/j.patrec.2013.10.010
   El Madany N. E. D., 2015, MULTIMEDIA SIGNAL PR, P1
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Hasan H, 2014, ARTIF INTELL REV, V41, P147, DOI 10.1007/s10462-011-9303-1
   Jiang M, 2018, PROCEEDINGS OF 2018 INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS PROCESSING (ICIGP 2018), P8, DOI 10.1145/3191442.3191462
   Kim Y, 2016, IEEE ACCESS, V4, P7125, DOI 10.1109/ACCESS.2016.2617282
   Kraskov A, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.066138
   Kurakin A, 2012, EUR SIGNAL PR CONF, P1975
   Liang B, 2015, IEEE IMAGE PROC, P2070, DOI 10.1109/ICIP.2015.7351165
   Liu MY, 2016, NEUROCOMPUTING, V175, P747, DOI 10.1016/j.neucom.2015.11.005
   Molchanov Pavlo, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163132
   Ohn-Bar E, 2013, IEEE COMPUT SOC CONF, P465, DOI 10.1109/CVPRW.2013.76
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Rahmani H, 2014, IEEE WINT CONF APPL, P626, DOI 10.1109/WACV.2014.6836044
   Santos DG, 2015, SENSORS-BASEL, V15, P28646, DOI 10.3390/s151128646
   Shen XH, 2012, IMAGE VISION COMPUT, V30, P227, DOI 10.1016/j.imavis.2011.11.003
   Tang B, 2013, IEEE SYS MAN CYBERN, P1, DOI 10.1109/SMC.2013.8
   Tran QD, 2013, PROCEEDINGS OF 2013 IEEE RIVF INTERNATIONAL CONFERENCE ON COMPUTING AND COMMUNICATION TECHNOLOGIES: RESEARCH, INNOVATION, AND VISION FOR THE FUTURE (RIVF), P253, DOI 10.1109/RIVF.2013.6719903
   Tung PT, 2014, P 5 S INF COMM TECHN, P186
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108
   Yuan JS, 2011, IEEE T PATTERN ANAL, V33, P1728, DOI 10.1109/TPAMI.2011.38
   Zhang CY, 2013, IEEE COMPUT SOC CONF, P500, DOI 10.1109/CVPRW.2013.80
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zheng JQ, 2017, MULTIMED TOOLS APPL, V76, P20525, DOI 10.1007/s11042-016-3988-8
   Zhu Y, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2629483
NR 42
TC 5
Z9 5
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10649
EP 10672
DI 10.1007/s11042-018-6553-9
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400050
DA 2024-07-18
ER

PT J
AU Yang, YL
   Wang, LJ
   Wang, Y
   Mei, XZ
AF Yang, Yanli
   Wang, Lijuan
   Wang, Ying
   Mei, Xiuzhuang
TI Insulator self-shattering detection: a deep convolutional neural network
   approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Insulators; Flaw detection; Pattern recognition;
   Convolutional neural network
ID AERIAL INSPECTION; SEGMENTATION; MODEL
AB The fault detection of insulators is very important because these insulators, as insulation controls, play an important role in transmission lines. Under the background that the unmanned aerial vehicle (UAV) instead of manual inspection has become the trend for power line inspection, the automatic recognition of insulator faults from big data of aerial images is undoubtedly a key issue that must be solved. In this paper, a method using the deep convolutional neural network (DCNN) to detect insulator self-shattering is proposed. Compared with the traditional method, the proposed method can extract fault features from aerial images automatically and can recognize insulator self-shattering under the big data condition. The experiments of a testing set with 341 real-world images captured from a UAV show that the correct identification rate can reach 98.53%, which suggests that the model outperforms existing methods in detecting insulator self-shattering. The proposed method can be further improved when the training dataset is supplemented and updated in applications.
C1 [Yang, Yanli; Wang, Lijuan; Wang, Ying; Mei, Xiuzhuang] Tianjin Polytech Univ, Tianjin Key Lab Optoelect Detect Technol & Syst, Binshuixi Rd 399, Tianjin 300387, Peoples R China.
C3 Tiangong University
RP Yang, YL (corresponding author), Tianjin Polytech Univ, Tianjin Key Lab Optoelect Detect Technol & Syst, Binshuixi Rd 399, Tianjin 300387, Peoples R China.
EM yyl070805@163.com
RI Yang, Ya-Li/GYU-4320-2022; yang, yang/HGT-7999-2022; Wang,
   Lijuan/GMX-3295-2022; Lang, Ming/HIK-0758-2022
OI Yang, Yanli/0000-0003-1919-8857
CR Aggarwal RK, 2000, ELECTR POW SYST RES, V53, P15, DOI 10.1016/S0378-7796(99)00037-1
   Barat C, 2016, PATTERN RECOGN, V54, P104, DOI 10.1016/j.patcog.2016.01.007
   Chen GB, 2014, IEEE IMAGE PROC, P858, DOI 10.1109/ICIP.2014.7025172
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Cui KB, 2014, APPL MATH INFORM SCI, V8, P2997, DOI 10.12785/amis/080638
   Dahl GE, 2013, INT CONF ACOUST SPEE, P8609, DOI 10.1109/ICASSP.2013.6639346
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Iruansi U., 2015, AFRICON IEEE, P1, DOI 10.1109/AFRCON.2015.7331976
   Jones DI, 2000, IEE P-VIS IMAGE SIGN, V147, P157, DOI 10.1049/ip-vis:20000226
   Jones DI, 2001, ELECTR POW SYST RES, V57, P73, DOI 10.1016/S0378-7796(01)00100-6
   Katrasnik J, 2010, IEEE T POWER DELIVER, V25, P485, DOI 10.1109/TPWRD.2009.2035427
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liao SL, 2015, IEEE GEOSCI REMOTE S, V12, P963, DOI 10.1109/LGRS.2014.2369525
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Matikainen L, 2016, ISPRS J PHOTOGRAMM, V119, P10, DOI 10.1016/j.isprsjprs.2016.04.011
   Murthy VS, 2011, IET IMAGE PROCESS, V5, P171, DOI 10.1049/iet-ipr.2009.0293
   Murthy VS, 2010, IEEE T DIELECT EL IN, V17, P89, DOI 10.1109/TDEI.2010.5412006
   Oberweger M., 2014, Comput. Vis. Winter Work
   Prasad P. Surya, 2016, J. Eng. Sci. Technol. Rev, V9, P135, DOI DOI 10.25103/JESTR.095.21
   Reddy MJB, 2013, IEEE T DIELECT EL IN, V20, P664, DOI 10.1109/TDEI.2013.6508770
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sainath TN, 2015, NEURAL NETWORKS, V64, P39, DOI 10.1016/j.neunet.2014.08.005
   Sampedro C, 2014, IEEE IJCNN, P1970, DOI 10.1109/IJCNN.2014.6889836
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Wu QG, 2012, IEEE J-STARS, V5, P1509, DOI 10.1109/JSTARS.2012.2197672
   Xinye Zhang, 2010, Proceedings of the 2010 Second Global Congress on Intelligent Systems (GCIS 2010), P200, DOI 10.1109/GCIS.2010.74
   Zhai YJ, 2017, MULTIMED TOOLS APPL, V76, P12051, DOI 10.1007/s11042-016-3981-2
   Zhao ZB, 2016, IEEE IJCNN, P3187, DOI 10.1109/IJCNN.2016.7727606
   Zhao ZB, 2015, IEEE T DIELECT EL IN, V22, P3421, DOI 10.1109/TDEI.2015.004741
   Zhou XP, 2016, INT J GEOMECH, V16, P1
NR 31
TC 18
Z9 18
U1 1
U2 52
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10097
EP 10112
DI 10.1007/s11042-018-6610-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400028
DA 2024-07-18
ER

PT J
AU Al-Hazaimeh, OM
   Al-Nawashi, M
   Saraee, M
AF Al-Hazaimeh, Obaida M.
   Al-Nawashi, Malek
   Saraee, Mohamad
TI Geometrical-based approach for robust human image detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human classification; Geometrical model; INRIA; Machine learning; SVM;
   ANN; Random forest
ID ORIENTED GRADIENTS; HISTOGRAMS; TRACKING; CLASSIFICATION; SUBSPACE; POSE
AB In recent years, object detection and classification has been gaining more attention, thus, there are several human object detection algorithms being used to locate and recognize human objects in images. The research of image processing and analyzing based on human shape is one of the hot topic due to the wide applicability in real applications. In this paper, we present a new object classification approach. The new approach will use a simple and robust geometrical model to classify the detected object as human or non-human in the images. In the proposed approach, the object is detected. Then the detected object under different conditions can be accurately classified (i.e. human, non-human) by combining the features that are extracted from the upper portion of the contour and the proposed geometrical model parameters. A software-based simulation using Matlab was performed using INRIA dataset and the obtained results are validated by comparing with five state-of-art approaches in literature and some of the machine learning approaches such as artificial neural networks (ANN), support vector machine (SVM), and random forest (RF). The experimental results show that the proposed object classification approach is efficient and achieved a comparable accuracy to other machine learning approaches and other state-of-art approaches.
C1 [Al-Hazaimeh, Obaida M.] Al Balqa Appl Univ, Al Huson Univ Coll, Dept Comp Sci, Irbid, Jordan.
   [Al-Nawashi, Malek; Saraee, Mohamad] Univ Salford Manchester, Sch Comp Sci & Engn, Manchester, Lancs, England.
C3 Al-Balqa Applied University; University of Salford
RP Al-Hazaimeh, OM (corresponding author), Al Balqa Appl Univ, Al Huson Univ Coll, Dept Comp Sci, Irbid, Jordan.
EM dr_obaida@bau.edu.jo; m.m.al-nawashi@edu.salford.ac.uk;
   m.saraee@salford.ac.uk
RI Al-Hazaimeh, Obaida M./U-6661-2017; Al-nawashi, malek/CAG-4689-2022
OI Al-Hazaimeh, Obaida M./0000-0001-5641-4892; Al-nawashi,
   malek/0000-0002-5231-8155
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Al-Abri M, 2008, CHEM ENG J, V141, P27, DOI 10.1016/j.cej.2007.10.005
   Al-Hazaimeh O. M, 2015, INDIAN J SCI TECHNOL, V8, P940, DOI 10.17485/ijst/2015/v8i10/53149
   Al-hazaimeh O.M., 2012, IJCSI, V9
   Al-Nawashi M, 2016, NEURAL COMPUT APPL, V28, P1
   [Anonymous], 2018, INRIA PERSON DATASET
   [Anonymous], PATTERN RECOGNIT
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   BAO P, 2005, TPAMI, V27, P1485, DOI DOI 10.1109/TPAMI.2005.173
   Benayed Y., 2003, 2003 IEEE INT C ACOU, V1, pI
   Broggi A, 2000, PROCEEDINGS OF THE IEEE INTELLIGENT VEHICLES SYMPOSIUM 2000, P215, DOI 10.1109/IVS.2000.898344
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Desa SM, 2004, I C COMP GRAPH IM VI, P41, DOI 10.1109/CGIV.2004.1323958
   Drayer B, 2014, LECT NOTES COMPUT SC, V8693, P406, DOI 10.1007/978-3-319-10602-1_27
   Gall J, 2011, IEEE T PATTERN ANAL, V33, P2188, DOI 10.1109/TPAMI.2011.70
   Guan P, 2009, IEEE I CONF COMP VIS, P1381, DOI 10.1109/iccv.2009.5459300
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Hjelmås E, 2001, COMPUT VIS IMAGE UND, V83, P236, DOI 10.1006/cviu.2001.0921
   Huang J, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P553
   Jain A, 2011, HOW TO BE SOUTH ASIAN IN AMERICA: NARRATIVES OF AMBIVALENCE AND BELONGING, P227
   Kampmann M, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P876, DOI 10.1109/ICIP.1998.723696
   Li HL, 2008, J VIS COMMUN IMAGE R, V19, P320, DOI 10.1016/j.jvcir.2008.04.001
   Liu Y, 2012, INT C PATT RECOG, P898
   Liu ZY, 2011, INTERNATIONAL CONFERENCE ON ENGINEERING AND BUSINESS MANAGEMENT (EBM2011), VOLS 1-6, P3001
   Lu D, 2007, INT J REMOTE SENS, V28, P823, DOI 10.1080/01431160600746456
   Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800
   Marín J, 2014, IEEE T CYBERNETICS, V44, P342, DOI 10.1109/TCYB.2013.2255271
   Modi RV, 2011, INT J COMPUTER APPL
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Mukherjee S, 2013, ARXIV13075591
   MURRAY D, 1994, IEEE T PATTERN ANAL, V16, P449, DOI 10.1109/34.291452
   Obaida M. A., 2014, COMPUT INF SCI, V7, P65
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   Satpathy A, 2014, IEEE T IMAGE PROCESS, V23, P287, DOI 10.1109/TIP.2013.2264677
   Jacques JCS, 2015, SIBGRAPI, P329, DOI 10.1109/SIBGRAPI.2015.17
   STEFIK MJ, 1985, ARTIF INTELL, V25, P236, DOI 10.1016/0004-3702(85)90005-0
   Sugandi Budi., 2007, INNOVATIVE COMPUTING, P408
   Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013
   TSAI DM, 1995, PATTERN RECOGN LETT, V16, P653, DOI 10.1016/0167-8655(95)80011-H
   Wang G, 2008, CHINA POLICY SER, V1, P1
   Watanabe T, 2009, LECT NOTES COMPUT SC, V5414, P37, DOI 10.1007/978-3-540-92957-4_4
   Xie X, 2016, PROC IEEE MICR ELECT, P75, DOI 10.1109/MEMSYS.2016.7421561
   Yao C, 2014, LECT NOTES COMPUT SC, V8693, P251, DOI 10.1007/978-3-319-10602-1_17
   Zeng ZQ, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEM AND KNOWLEDGE ENGINEERING, VOLS 1 AND 2, P997, DOI 10.1109/ISKE.2008.4731075
   Zhong Y, 2000, IEEE T PATTERN ANAL, V22, P544, DOI 10.1109/34.857008
   Ziou D, 2010, IJCA COMPUTER AIDED, P35, DOI 10.5120/993-25
NR 48
TC 19
Z9 19
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7029
EP 7053
DI 10.1007/s11042-018-6401-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700028
DA 2024-07-18
ER

PT J
AU Choe, G
   Choe, C
   Wang, TJ
   So, H
   Nam, C
   Yuan, C
AF Choe, Gwangmin
   Choe, Chunhwa
   Wang, Tianjiang
   So, Hyoson
   Nam, Cholman
   Yuan, Caihong
TI Deep learning with particle filter for person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Non-convex objective function; Global optimum; Particle
   filter; Back-propagation; Person re-identification
ID REPRESENTATION; RECOGNITION; NETWORKS
AB Person re-identification, having attracted much attention in the multimedia community, is still challenged by the accuracy and the robustness, as the images for the verification contain such variations as light, pose, noise and ambiguity etc. Such practical challenges require relatively robust and accurate feature learning technologies. We introduced a novel deep neural network with PF-BP(Particle Filter-Back Propagation) to achieve relatively global and robust performances of person re-identification. The local optima in the deep networks themselves are still the main difficulty in the learning, in despite of several advanced approaches. A novel neural network learning, or PF-BP, was first proposed to solve the local optima problem in the non-convex objective function of the deep networks. When considering final deep network to learn using BP, the overall neural network with the particle filter will behave as the PF-BP neural network. Also, a max-min value searching was proposed by considering two assumptions about shapes of the non-convex objective function to learn on. Finally, a salience learning based on the deep neural network with PF-BP was proposed to achieve an advanced person re-identification. We test our neural network learning with particle filter aimed to the non-convex optimization problem, and then evaluate the performances of the proposed system in a person re-identification scenario. Experimental results demonstrate that the corresponding performances of the proposed deep network have promising discriminative capability in comparison with other ones.
C1 [Choe, Gwangmin; Choe, Chunhwa; So, Hyoson] Kim Il Sung Univ, Sch Comp Sci & Technol, Visual Informat Proc Lab, Pyongyang, North Korea.
   [Wang, Tianjiang; Yuan, Caihong] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Intelligent & Distributed Comp Lab, Wuhan 430074, Peoples R China.
   [Nam, Cholman] Kim Il Sung Univ, Sch Comp Sci & Technol, Informat & Commun Lab, Pyongyang, North Korea.
C3 Huazhong University of Science & Technology
RP Choe, G (corresponding author), Kim Il Sung Univ, Sch Comp Sci & Technol, Visual Informat Proc Lab, Pyongyang, North Korea.; Wang, TJ (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Intelligent & Distributed Comp Lab, Wuhan 430074, Peoples R China.
EM ryongnam21@yahoo.com; tjwang@hust.edu.cn; 36151795@qq.com
CR [Anonymous], 2011, P ICASSP
   [Anonymous], GEOSCIENCE AND REMOT
   [Anonymous], P NIPS 2004
   [Anonymous], 2010, Advances in neural information processing systems
   [Anonymous], DISCRIMINATIVE PRETR
   [Anonymous], ACM MULTIMEDIA MM
   [Anonymous], 2007, P NIPS
   [Anonymous], 2011, P INT C FLOR IT 27 3, DOI DOI 10.5555/3042573.3042574
   [Anonymous], P INTERSPEECH
   [Anonymous], 2013, P CVPR
   [Anonymous], P AISTAT
   [Anonymous], TMM
   [Anonymous], TIP
   [Anonymous], NAT C ART INT AAAI
   [Anonymous], TPAMI
   [Anonymous], 2014, CVPR
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Choe GM, 2016, MULTIMED TOOLS APPL, V75, P11447, DOI 10.1007/s11042-015-2862-4
   Choe GM, 2015, MULTIMED TOOLS APPL, V74, P7595, DOI 10.1007/s11042-014-1993-3
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Gao Y, 2017, IEEE T IMAGE PROCESS, V26, P2545, DOI 10.1109/TIP.2017.2675341
   Getoor, 2011, P 28 INT C MACH LEAR, P833
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Layne R, 2012, LECT NOTES COMPUT SC, V7583, P402, DOI 10.1007/978-3-642-33863-2_40
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li Wei, 2012, AS C COMP VIS ACCV 2, P31
   Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463
   Lin L, 2015, IEEE T CIRC SYST VID, V25, P251, DOI 10.1109/TCSVT.2014.2313897
   Lin L, 2009, PATTERN RECOGN, V42, P1297, DOI 10.1016/j.patcog.2008.10.033
   Liu H, 2015, NEUROCOMPUTING, V151, P1283, DOI 10.1016/j.neucom.2014.11.002
   Liu WF, 2018, INFORM FUSION, V41, P119, DOI 10.1016/j.inffus.2017.09.001
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Ma JY, 2015, PATTERN RECOGN, V48, P772, DOI 10.1016/j.patcog.2014.09.005
   Martens R, 2010, PROCEEDINGS OF THE FOURTH EUROPEAN CONFERENCE ON ANTENNAS AND PROPAGATION
   Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382
   Seide F., 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P24, DOI 10.1109/ASRU.2011.6163899
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010
   Wang Z, 2016, IEEE T MULTIMEDIA, V18, P260, DOI 10.1109/TMM.2015.2505083
   Yang XH, 2017, INFORM SCIENCES, V385, P338, DOI 10.1016/j.ins.2017.01.011
   Zhao ZQ, 2017, MULTIMED TOOLS APPL, V76, P835, DOI 10.1007/s11042-015-3075-6
NR 47
TC 2
Z9 2
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 6607
EP 6636
DI 10.1007/s11042-018-6415-5
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700009
DA 2024-07-18
ER

PT J
AU Sun, B
   Kong, DH
   Wang, SF
   Wang, LC
   Wang, YP
   Yin, BC
AF Sun, Bin
   Kong, Dehui
   Wang, Shaofan
   Wang, Lichun
   Wang, Yuping
   Yin, Baocai
TI Effective human action recognition using global and local offsets of
   skeleton joints
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Skeleton joints; Offsets; Histogram representation;
   Naive-Bayes-Nearest-Neighbor
ID ENSEMBLE; FEATURES; SPACE
AB Human action recognition based on 3D skeleton joints is an important yet challenging task. While many research work are devoted to 3D action recognition, they mainly suffer from two problems: complex model representation and low implementation efficiency. To tackle these problems, we propose an effective and efficient framework for 3D action recognition using a global-and-local histogram representation model. Our method consists of a global-and-local featuring phase, a saturation based histogram representation phase, and a classification phase. The global-and-local featuring phase captures the global feature and local feature of each action sequence using the joint displacement between the current frame and the first frame, and the joint displacement between pairwise fixed-skip frames, respectively. The saturation based histogram representation phase captures the histogram representation of each joint considering the motion independence of joints and saturation of each histogram bin. The classification phase measures the distance of each joint histogram-to-class. Besides, we produce a novel action dataset called BJUT Kinect dataset, which consists of multi-period motion clips and intra-class variations. We compare our method with many state-of-the-art methods on BJUT Kinect dataset, UCF Kinect dataset, Florence 3D action dataset, MSR-Action3D dataset, and NTU RGB+D Dataset. The results show that our method achieves both higher accuracy and efficiency for 3D action recognition.
C1 [Sun, Bin; Kong, Dehui; Wang, Shaofan; Wang, Lichun; Wang, Yuping] Beijing Univ Technol, BJUT Fac Informat Technol, Beijing Adv Innovat Ctr Future Internet Technol, Beijing Key Lab Multimedia & Intelligent Software, Beijing 100124, Peoples R China.
   [Yin, Baocai] Dalian Univ Technol, Coll Comp Sci & Technol, Fac Elect Informat & Elect Engn, Dalian 116024, Peoples R China.
C3 Beijing University of Technology; Dalian University of Technology
RP Kong, DH (corresponding author), Beijing Univ Technol, BJUT Fac Informat Technol, Beijing Adv Innovat Ctr Future Internet Technol, Beijing Key Lab Multimedia & Intelligent Software, Beijing 100124, Peoples R China.
EM sunbin1357@emails.bjut.edu.cn; kdh@bjut.edu.cn
RI Sun, Bin/ABG-4247-2020
FU National Natural Science Foundation of China [61772048, 61632006];
   Beijing Natural Science Foundation [4162009]; Beijing Municipal Science
   and Technology Project [Z161100001116072, Z171100004417023]
FX This work was supported by National Natural Science Foundation of China
   (No. 61772048, 61632006), Beijing Natural Science Foundation (No.
   4162009), Beijing Municipal Science and Technology Project(No.
   Z161100001116072, Z171100004417023).
CR Agahian S, 2019, VISUAL COMPUT, V35, P591, DOI 10.1007/s00371-018-1489-7
   Chaaraoui AA, 2014, EXPERT SYST APPL, V41, P786, DOI 10.1016/j.eswa.2013.08.009
   Anirudh R, 2017, IEEE T PATTERN ANAL, V39, P922, DOI 10.1109/TPAMI.2016.2564409
   [Anonymous], 2008, P 2008 IEEE C COMPUT, DOI DOI 10.1109/CVPR.2008.4587735
   [Anonymous], 2015, PROC CVPR IEEE
   Beh J, 2014, PATTERN RECOGN LETT, V36, P144, DOI 10.1016/j.patrec.2013.10.007
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598
   Chen HZ, 2016, PATTERN RECOGN, V55, P148, DOI 10.1016/j.patcog.2016.01.020
   Chen WB, 2015, J VIS COMMUN IMAGE R, V26, P182, DOI 10.1016/j.jvcir.2014.11.008
   Cheng HY, 2011, J VIS COMMUN IMAGE R, V22, P673, DOI 10.1016/j.jvcir.2011.07.001
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Devanne M, 2015, IEEE T CYBERNETICS, V45, P1340, DOI 10.1109/TCYB.2014.2350774
   Dong J, 2015, NEUROCOMPUTING, V158, P246, DOI 10.1016/j.neucom.2015.01.024
   Ellis C, 2013, INT J COMPUT VISION, V101, P420, DOI 10.1007/s11263-012-0550-7
   Evangelidis G, 2014, INT C PATT RECOG, P4513, DOI 10.1109/ICPR.2014.772
   Eweiwi A, 2015, LECT NOTES COMPUT SC, V9007, P428, DOI 10.1007/978-3-319-16814-2_28
   Jiang XB, 2016, MULTIMED TOOLS APPL, V75, P11019, DOI 10.1007/s11042-015-2829-5
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Li M, 2017, PATTERN RECOGN LETT, V87, P195, DOI 10.1016/j.patrec.2016.07.021
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lu GL, 2016, MULTIMED TOOLS APPL, V75, P3479, DOI 10.1007/s11042-015-2448-1
   Lu GL, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P96, DOI 10.1109/CISP.2013.6744073
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Luo JJ, 2014, PATTERN RECOGN LETT, V50, P139, DOI 10.1016/j.patrec.2014.03.024
   Luvizon DC, 2017, PATTERN RECOGN LETT, V99, P13, DOI 10.1016/j.patrec.2017.02.001
   Matikainen Pyry, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P514, DOI 10.1109/ICCVW.2009.5457659
   Negin F, 2013, LECT NOTES COMPUT SC, V7950, P648, DOI 10.1007/978-3-642-39094-4_74
   Ohn-Bar E, 2013, IEEE COMPUT SOC CONF, P465, DOI 10.1109/CVPRW.2013.76
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Pirsiavash H, 2012, PROC CVPR IEEE, P2847, DOI 10.1109/CVPR.2012.6248010
   Qiao RZ, 2017, PATTERN RECOGN, V66, P202, DOI 10.1016/j.patcog.2017.01.015
   Roccetti M, 2012, J VIS COMMUN IMAGE R, V23, P426, DOI 10.1016/j.jvcir.2011.12.006
   Seidenari L, 2013, IEEE COMPUT SOC CONF, P479, DOI 10.1109/CVPRW.2013.77
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Sheng BY, 2015, NEUROCOMPUTING, V158, P73, DOI 10.1016/j.neucom.2015.01.064
   Slama R, 2015, PATTERN RECOGN, V48, P556, DOI 10.1016/j.patcog.2014.08.011
   Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591
   Veeriah V, 2015, IEEE I CONF COMP VIS, P4041, DOI 10.1109/ICCV.2015.460
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Vieira A. W., 2012, PROGR PATTERN RECOGN, P252, DOI [DOI 10.1007/978-3-642-33275-3, DOI 10.1007/978-3-642-33275]
   Vieira AW, 2014, PATTERN RECOGN LETT, V36, P221, DOI 10.1016/j.patrec.2013.07.011
   Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang P, 2016, LECT NOTES COMPUT SC, V9911, P370, DOI 10.1007/978-3-319-46478-7_23
   Xia L., 2012, IEEE COMP SOC C COMP, P20, DOI DOI 10.1109/CVPRW.2012.6239233
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108
   Yang XD, 2014, J VIS COMMUN IMAGE R, V25, P2, DOI 10.1016/j.jvcir.2013.03.001
   Yang YH, 2017, IEEE T CYBERNETICS, V47, P439, DOI 10.1109/TCYB.2016.2519448
   Zhang SY, 2017, IEEE WINT CONF APPL, P148, DOI 10.1109/WACV.2017.24
   ZHOU Y, 2016, PATTERN RECOGN LET 3, V83, P261, DOI DOI 10.1016/j.patrec.2016.07.025
   Zhu YD, 2010, COMPUT VIS IMAGE UND, V114, P1362, DOI 10.1016/j.cviu.2009.11.005
   Zhu Y, 2013, IEEE COMPUT SOC CONF, P486, DOI 10.1109/CVPRW.2013.78
NR 58
TC 12
Z9 13
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 6329
EP 6353
DI 10.1007/s11042-018-6370-1
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100062
DA 2024-07-18
ER

PT J
AU Youm, S
   Kim, C
   Choi, S
   Kang, YS
AF Youm, Sekyoung
   Kim, Changgyun
   Choi, Seunghyun
   Kang, Yong-Shin
TI Development of a methodology to predict and monitor emergency situations
   of the elderly based on object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE TensorFlow; Pose recognition; The elderly; Emergency situation
   recognition; Object-detection
AB Because on the increase in the number of the elderly living alone and accidents occurring to them, the demand for a monitoring system capable of supporting fast response in case of an emergency situation by monitoring their everyday life in their residential spaces has been increasing. A framework and a system are presented to monitor the emergency situations of the elderly living alone using a low-cost device and open-source software. First, human pose recognition and emergency situations according to the pose change were defined using object recognition, and a procedure capable of detecting such situations was proposed. In addition, a pose recognition model was created using the TensorFlow Object Detection application programming interface (API) of Google to implement the procedure. Using a data preprocessing process and the created model, a system capable of detecting emergency situations and sounding an alarm was implemented. To verify the proposed system, the pose recognition success rate was examined, and an experiment on emergency situation recognition was performed while the angle and distance of the camera were varied in a setup similar to the residential environment. It is expected that the proposed framework for the emergency notification system for the elderly will be utilized for the analysis of various behavior patterns, such as the sudden abnormal behavior of the elderly, people with disabilities, and children.
C1 [Youm, Sekyoung; Kim, Changgyun; Choi, Seunghyun] Dongguk Univ, Dept Ind & Syst Engn, Seoul, South Korea.
   [Kang, Yong-Shin] Sungkyunkwan Univ, Dept Syst Management Engn, 2066 Seobu Ro, Suwon 16419, Gyeonggi Do, South Korea.
C3 Dongguk University; Sungkyunkwan University (SKKU)
RP Kang, YS (corresponding author), Sungkyunkwan Univ, Dept Syst Management Engn, 2066 Seobu Ro, Suwon 16419, Gyeonggi Do, South Korea.
EM yskang7867@skku.edu
RI changgyun, Kim/GZG-8751-2022
OI changgyun, Kim/0000-0002-8392-9055
FU Ministry of Land, Infrastructure and Transport in Korea
   [17CTAP-C114867-02]
FX This work was supported by the Ministry of Land, Infrastructure and
   Transport in Korea. (17CTAP-C114867-02)
CR Anderson D, 2009, COMPUT VIS IMAGE UND, V113, P80, DOI 10.1016/j.cviu.2008.07.006
   [Anonymous], 2018, ARXIV180300455
   [Anonymous], 2015, ARXIV, DOI DOI 10.48550/ARXIV.1504.08083
   [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   [Anonymous], 2018, ARXIV180310842
   [Anonymous], 2004, Proceedings of the Pan-Sydney area workshop on Visual information processing
   Bourke AK, 2007, GAIT POSTURE, V26, P194, DOI 10.1016/j.gaitpost.2006.09.012
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Choi K-S, 2015, J KOREA I INFORM ELE, V9, P9, DOI [10.17661/jkiiect.2016.9.1.009, DOI 10.17661/JKIIECT.2016.9.1.009]
   Chung WY., 2008, 30 ANN INT IEEE EMBS
   CUTLER DM, 1990, BROOKINGS PAP ECO AC, P1
   Fougère M, 1999, ECON MODEL, V16, P411, DOI 10.1016/S0264-9993(99)00008-5
   Gkioxari G, 2015, IEEE I CONF COMP VIS, P1080, DOI 10.1109/ICCV.2015.129
   Jang I-H, 2007, J KOREAN I INTELLIGE, V17
   Kim N, 2010, COMMUNICATIONS KOREA, V8
   Kim Taehan, 2013, [InHa Law Review, 법학연구], V16, P167
   김윤신, 2011, [Journal of Social Science, 사회과학연구], V50, P143
   Lee TK, 2016, P KOR SOC PREC ENG C, P217
   Mastorakis G., 2012, J REAL TIME IMAGE PR, P1
   Mehta R, 2017, INT J CURRENT ENG TE
   Otto C., 2006, J MOBILE MULTIMEDIA, V1, P307
   Paradiso R, 2005, J TELECOMMUNICATIONS, V4
   Pfister T, 2015, IEEE I CONF COMP VIS, P1913, DOI 10.1109/ICCV.2015.222
   Planinc Rainer, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P121, DOI 10.1007/978-3-642-37484-5_11
   [任明武 Ren Mingwu], 2005, [计算机工程, Computer Engineering], V31, P33
   Rougier C, 2011, LECT NOTES COMPUT SC, V6719, P121, DOI 10.1007/978-3-642-21535-3_16
   Sonka M., 2003, IMAGE PROCESSING ANA, V2nd
   Stone EE, 2015, IEEE J BIOMED HEALTH, V19, P290, DOI 10.1109/JBHI.2014.2312180
   We-Duke C., 2014, J KOREAN I COMMUN SC, V35, P17
   Yang Y, 2013, ARTICULATED HUMAN PO
   Zeng Andy, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1386, DOI 10.1109/ICRA.2017.7989165
   Zhan CH, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P519, DOI 10.1109/ICIG.2007.153
   [张运楚 Zhang Yunchu], 2006, [计算机工程与应用, Computer Engineering and Application], V42, P45
   Zhu LC, 2017, IEEE ACCESS, V5, P11364, DOI 10.1109/ACCESS.2017.2716359
NR 34
TC 4
Z9 4
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5427
EP 5444
DI 10.1007/s11042-018-6660-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100020
DA 2024-07-18
ER

PT J
AU Zhu, N
   Shen, JG
AF Zhu, Nan
   Shen, Junge
TI Image phylogeny tree construction based on local inheritance
   relationship correction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image phylogeny tree; Image forensics; Multimedia phylogeny; Near
   duplicated images; Optimum branching
ID CONTENT DELIVERY
AB With the popularization of image editing software and social networks, digital images can be easily downloaded, re-edited and re-distributed on the Internet, which brings a large amount of near-duplicate images (NDIs) whose content are slightly different. The underlying transformation history within a group of NDIs is a powerful tool to determine both the image originality and authenticity. Recent works have focus on the construction of image phylogeny tree (IPT), i.e., a directed acyclic graph to describe the genealogical relationship within NDIs. State-of-the-art approaches for IPT construction share a common two-step pipeline: i) dissimilarity matrix estimation with a dissimilarity function; and ii) tree structure construction with a tree-building algorithm. Many approaches addressed on dissimilarity matrix estimation as the accuracy of the tree-building algorithms are significantly impaired by this step. Different from these methods, in this paper, instead of proposing a novel dissimilarity matrix estimation method, we design an IPT construction framework based on local inheritance relationship correction. The motivation among our proposed framework is that the negative influence of an inaccurate dissimilarity matrix can be suppressed by a subsequent correction. Extensive experimental results show that our proposed approach can achieve better performance for IPT construction under various challenging scenarios when compared with the state-of-the-art IPT construction algorithms.
C1 [Zhu, Nan] Xian Technol Univ, Dept Elect Informat Engn, Xian 710021, Shaanxi, Peoples R China.
   [Shen, Junge] Northwestern Polytech Univ, Unmanned Syst Res Inst, Xian 710072, Shaanxi, Peoples R China.
C3 Xi'an Technological University; Northwestern Polytechnical University
RP Shen, JG (corresponding author), Northwestern Polytech Univ, Unmanned Syst Res Inst, Xian 710072, Shaanxi, Peoples R China.
EM nanzhu.xatu@foxmail.com; shenjunge@gmail.com
RI Zhu, Nan/L-8741-2019
OI Zhu, Nan/0000-0002-8073-149X
CR Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bestagini P, 2016, INT CONF ACOUST SPEE, P2059, DOI 10.1109/ICASSP.2016.7472039
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Bock F., 1971, Developments in operations research, P29
   CHU YJ, 1965, SCI SINICA, V14, P1396
   Costa F, 2017, PATTERN ANAL APPL, V20, P1289, DOI 10.1007/s10044-017-0616-9
   Costa FD, 2014, IEEE T INF FOREN SEC, V9, P1533, DOI 10.1109/TIFS.2014.2340017
   de Oliveira AA, 2016, IEEE T INF FOREN SEC, V11, P328, DOI 10.1109/TIFS.2015.2493989
   De Rosa A, 2010, PROC SPIE, V7541, DOI 10.1117/12.840235
   Dias Z., 2011, IEEE INT WORKSH INF, P1
   Dias Z, 2010, IEEE INT WORKS INFOR
   Dias Z, 2013, J VIS COMMUN IMAGE R, V24, P1124, DOI 10.1016/j.jvcir.2013.07.011
   Dias Z, 2013, IEEE MULTIMEDIA, V20, P58, DOI 10.1109/MMUL.2013.17
   Dias Z, 2013, FORENSIC SCI INT, V231, P178, DOI 10.1016/j.forsciint.2013.05.002
   Dias Z, 2012, IEEE T INF FOREN SEC, V7, P774, DOI 10.1109/TIFS.2011.2169959
   EDMONDS J, 1967, J RES NBS B MATH SCI, VB 71, P233, DOI 10.6028/jres.071B.032
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Kennedy L., 2008, ACM International Conference on Multimedia (MM), P349
   Korus P, 2017, DIGIT SIGNAL PROCESS, V71, P1, DOI 10.1016/j.dsp.2017.08.009
   Kruskal J. B., 1956, Proceedings of the American Mathematical Society, V7, P48
   Li LD, 2016, IEEE T CYBERNETICS, V46, P39, DOI 10.1109/TCYB.2015.2392129
   Milani S, 2016, INT CONF ACOUST SPEE, P2054, DOI 10.1109/ICASSP.2016.7472038
   Milani S., 2014, 2014 5 EUR WORKSH
   Nucci M, 2013, IEEE INT WORKSH MULT, P99, DOI 10.1109/MMSP.2013.6659271
   PRIM RC, 1957, AT&T TECH J, V36, P1389, DOI 10.1002/j.1538-7305.1957.tb01515.x
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Shen JE, 2013, MULTIMED TOOLS APPL, V63, P461, DOI 10.1007/s11042-011-0922-y
   Stamm MC, 2013, IEEE ACCESS, V1, P167, DOI 10.1109/ACCESS.2013.2260814
   Zhou L, 2018, IEEE T IND INFORM, V14, P1626, DOI 10.1109/TII.2017.2784100
   Zhou L, 2017, IEEE COMMUN MAG, V55, P91, DOI 10.1109/MCOM.2017.1700481
NR 32
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 6119
EP 6138
DI 10.1007/s11042-018-6352-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100053
DA 2024-07-18
ER

PT J
AU Jia, WJ
   Muhammad, K
   Wang, SH
   Zhang, YD
AF Jia, Wenjuan
   Muhammad, Khan
   Wang, Shui-Hua
   Zhang, Yu-Dong
TI Five-category classification of pathological brain images based on deep
   stacked sparse autoencoder
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data augmentation; Stacked sparse autoencoder; Minibatch scaled gradient
   descent
ID KULLBACK-LEIBLER; DETECTION SYSTEM
AB Magnetic resonance imaging (MRI) is employed in medical treatment broadly, due to the quick development of computer technology. It is beneficial to classify the pathological brain images into healthy or other different categories automatically and accurately. This work aims to generate a pathological brain detecting system to classify the pathological brain images into five different categories of healthy; cerebrovascular disease; neoplastic disease; degenerative disease; and inflammatory disease. Our proposed method can be composed of the following several steps: First, we used data augmentation technology to deal with unbalanced distribution of the dataset. Then, we used deep stacked sparse autoencoder with minibatch scaled conjugate gradient to train the network, and the softmax layer is used as the classifier. As a result, the accuracy of our deep stacked sparse autoencoder over the test set is 98.6%. The prediction time of each image in test stage is only 0.070s. Our experiment will be a powerful proof of the effectiveness of our proposed method that based on deep stacked sparse autoencoder.
C1 [Jia, Wenjuan; Wang, Shui-Hua; Zhang, Yu-Dong] Nanjing Normal Univ, Sch Comp Sci & Engn, 1 Wenyuan, Nanjing 210023, Jiangsu, Peoples R China.
   [Muhammad, Khan] Sejong Univ, Coll Software Convergence, Dept Software, Intelligent Media Lab, Seoul, South Korea.
   [Zhang, Yu-Dong] Univ Leicester, Dept Informat, Leicester LE1 7RH, Leics, England.
C3 Nanjing Normal University; Sejong University; University of Leicester
RP Zhang, YD (corresponding author), Nanjing Normal Univ, Sch Comp Sci & Engn, 1 Wenyuan, Nanjing 210023, Jiangsu, Peoples R China.; Zhang, YD (corresponding author), Univ Leicester, Dept Informat, Leicester LE1 7RH, Leics, England.
EM 1286741985@qq.com; khan.muhammad.sju@gmail.com; shuihuawang@ieee.org;
   yudongzhang@ieee.org
RI Muhammad, Khan/L-9059-2016; Wang, shuihua/G-7326-2016; Zhang,
   Yudong/I-7633-2013
OI Muhammad, Khan/0000-0003-4055-7412; Wang, shuihua/0000-0003-4713-2791;
   Muhammad, Khan/0000-0002-5302-1150; Zhang, Yudong/0000-0002-4870-1493
FU Natural Science Foundation of China [61602250]; Natural Science
   Foundation of Jiangsu Province [BK20150983]
FX This paper is supported by Natural Science Foundation of China
   (61602250) and Natural Science Foundation of Jiangsu Province
   (BK20150983).
CR Ahmad I, 2017, CHINA COMMUN, V14, P146, DOI 10.1109/CC.2017.7839765
   Al Hage J, 2017, INFORM FUSION, V37, P61, DOI 10.1016/j.inffus.2017.01.005
   Al-Otaibi NA, 2014, LECT NOTES INFORM TH
   Alharthi N., 2017, Scientific Modelling and Research, V2, P9, DOI 10.20448/808.2.1.9.18
   Andrei N, 2017, OPTIM METHOD SOFTW, V32, P534, DOI 10.1080/10556788.2016.1225211
   [Anonymous], 2014, INT C ADV ENG TECHN
   Arzuka I, 2016, J INEQUAL APPL, DOI 10.1186/s13660-016-1239-1
   Chen P., 2017, FUNDAMENTA INFORMATI, V151, P275
   Chen Y, 2017, CNS NEUROL DISORD-DR, V16, P5, DOI 10.2174/1871527314666161124115531
   Grozdic DT, 2017, ENG APPL ARTIF INTEL, V59, P15, DOI 10.1016/j.engappai.2016.12.012
   Gutub A, 2015, 3 ANN DIGITAL GRIDS
   Gutub A. A. -A, 2016, HAJJ FOR 2016 16 SCI
   Gutub AA.-A, 2010, J EMERG TECHNOL WEB, V2
   Kang M, 2017, SENSORS, V17, P16, DOI [10.3390/s17010088, DOI 10.3390/S17010088]
   Khan F, 2007, 4 IEEE GCC C EXH GUL, P11
   Lu SY, 2018, MULTIMED TOOLS APPL, V77, P3715, DOI 10.1007/s11042-016-3559-z
   Lu ZH, 2016, J MED IMAG HEALTH IN, V6, P1218, DOI 10.1166/jmihi.2016.1901
   Nafisi-Moghadam R, 2017, IRAN J CHILD NEUROL, V11, P13
   Norah A, 2017, J RES ENG APPL SCI J, V2, P50, DOI DOI 10.46565/JREAS.2017.V02I02.002
   Ohno H, 2017, APPL SOFT COMPUT, V55, P566, DOI 10.1016/j.asoc.2017.02.019
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Radi, 2016, J CIRCUIT SYST COMP, V25, DOI 10.1142/S0218126616501164
   Ramakrishnan N, 2017, IET SYST BIOL, V11, P99, DOI 10.1049/iet-syb.2016.0052
   Sankaran A, 2017, IMAGE VISION COMPUT, V60, P64, DOI 10.1016/j.imavis.2017.01.005
   Shimobaba T, 2017, APPL OPTICS, V56, pF27, DOI 10.1364/AO.56.000F27
   Tsianos KI, 2016, IEEE T SIGNAL INF PR, V2, P489, DOI 10.1109/TSIPN.2016.2620440
   Woodward RB, 2016, IEEE ENG MED BIO, P6405, DOI 10.1109/EMBC.2016.7592194
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P10521, DOI 10.1007/s11042-017-4554-8
   Zhou XX, 2016, IEEJ T ELECTR ELECTR, V11, P364, DOI 10.1002/tee.22226
NR 29
TC 37
Z9 38
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4045
EP 4064
DI 10.1007/s11042-017-5174-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200010
DA 2024-07-18
ER

PT J
AU Jiang, LP
   Wang, JJ
   Jiang, H
   Feng, XJ
AF Jiang, Liupeng
   Wang, Jiaojiao
   Jiang, He
   Feng, Xuejun
TI RETRACTED: Prediction model of port throughput based on game theory and
   multimedia Bayesian regression (Retracted article. See SEP, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Game theory; Multimedia theory; Bayesian regression; Port throughput;
   Forecasting model
AB In order to simulate the situation of freight flow in overlapping hinterland, we forecast the throughput of port and introduce the game theory to improve it. On the basis of this, a multimedia Bayesian regression model is established. On the basis of the existing port throughput prediction theory and actual situation of ports in China, through the analysis of China's coastal port cargo and impact, a coastal port cluster cargo throughput prediction model, improve China's coastal port throughput prediction precision and accuracy, which provides more reliable reference for China's coastal areas port investment planning. The main features of this model are as follows. For the first time, we analyze and predict the throughput of coastal ports from the point of view of the composition of port throughput. Considering the coordination relationship between major coastal port cargo throughput under, we use game theory, to deal with the port cargo throughput index, the maximum information is retained to ensure the accuracy of prediction model. The model is convenient and flexible, and can be extended to the throughput prediction of a single port or port group. It can be extended to the prediction problem with more time series indexes under multimedia environment.
C1 [Jiang, Liupeng; Wang, Jiaojiao; Jiang, He; Feng, Xuejun] Hohai Univ, Coll Harbour Coastal & Offshore Engn, Nanjing 210098, Jiangsu, Peoples R China.
C3 Hohai University
RP Jiang, LP (corresponding author), Hohai Univ, Coll Harbour Coastal & Offshore Engn, Nanjing 210098, Jiangsu, Peoples R China.
EM jiangliupeng@yahoo.com
RI Feng, Xuejun/JNT-1954-2023
OI Feng, Xuejun/0000-0003-1544-3069
FU National Natural Science Foundation of China [41401120, 51409088];
   Fundamental Research Funds for the Central Universities [2014B00214]
FX Research for this paper was funded by the National Natural Science
   Foundation of China (NO.41401120, 51409088) and Fundamental Research
   Funds for the Central Universities (Project No. 2014B00214). The authors
   thank every teacher of research institute, for their comments and
   suggestions.
CR [Anonymous], 2015, INT J SOFTW ENG ITS, DOI DOI 10.14257/IJSEIA.2015.9.9.22
   Chen H, 2015, IEEE T WIREL COMMUN, V14, P410, DOI 10.1109/TWC.2014.2349892
   Cui K., 2017, NEURAL COMPUT APPL, P1
   Cui YH, 2017, PHYS LIFE REV, V20, P161, DOI 10.1016/j.plrev.2017.01.028
   EID MS, 2015, ASCE, V31, DOI DOI 10.1061/(ASCE)ME.1943-5479.0000357
   Greiner D, 2017, ARCH COMPUT METHOD E, V24, P703, DOI 10.1007/s11831-016-9187-y
   Haibin Duan, 2015, IEEE/CAA Journal of Automatica Sinica, V2, P11, DOI 10.1109/JAS.2015.7032901
   Khan Y, 2014, NEURAL COMPUT APPL, V25, P889, DOI 10.1007/s00521-014-1576-2
   Mekonnen T, 2017, IEEE ACCESS, V5, P15848, DOI 10.1109/ACCESS.2017.2737078
   Mohamad ET, 2017, NEURAL COMPUT APPL, V28, pS393, DOI 10.1007/s00521-016-2359-8
   Wang T, 2016, PATTERN RECOGN, V55, P28, DOI 10.1016/j.patcog.2016.01.018
   Yang XS, 2014, NEURAL COMPUT APPL, V24, P169, DOI 10.1007/s00521-013-1367-1
   Zhang A, 2018, MULTIMED TOOLS APPL, V77, P24459, DOI 10.1007/s11042-018-5707-0
NR 13
TC 7
Z9 9
U1 1
U2 61
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4397
EP 4416
DI 10.1007/s11042-018-5766-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200026
DA 2024-07-18
ER

PT J
AU Kong, F
   Wang, YM
AF Kong, Fei
   Wang, Yumin
TI RETRACTED: Multimodal interface interaction design model based on
   dynamic augmented reality (Retracted article. See SEP, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Multimodal data; Analyzing paradigm; Internet of things; Intelligent
   system; Pattern recognition
ID SPECTRAL-SPATIAL CLASSIFICATION; RANDOM-FOREST; INTERNET; THINGS;
   ALGORITHM; SVM
AB New channels, new carriers continue to produce new data types, how to deal with complex and volatile multi-source data under IoT big data environment has become an important issue. Information perception is the basic content of the development of things, but also an important means to achieve information perception. Information interaction is the basic condition for the realization of Internet of things, but also the basic technology of interconnection. The information sensing of the Internet of Things is mainly the source of information provided by it, which is also the application base of the Internet of Things itself. To effectively process the IoT data, this paper proposes the multimodal intelligent data analyzing paradigm for Internet of things systems. Our proposed multiple game theory based data analyzing paradigm will guarantee the optimal combination of the mentioned model to construct the effect and robust analyzing pattern. We construct the optimal combination of Bayesian model, Decision Tree, Random Forest, Logistic Regression, SVM, Adaboost, Markov and Neural Network under the multiple game framework. Several new ideas are proposed to enhance the traditional Nash Equilibrium. Performance of the proposed method is validated through the simulation compared with the other state-of-the-art algorithms.
C1 [Kong, Fei] Qingdao Univ, Sch Electromech Engn, Dept Ind Design, Qingdao 266071, Peoples R China.
   [Wang, Yumin] Qingdao Univ Technol, Sch Sci, Qingdao 266071, Peoples R China.
C3 Qingdao University; Qingdao University of Technology
RP Kong, F (corresponding author), Qingdao Univ, Sch Electromech Engn, Dept Ind Design, Qingdao 266071, Peoples R China.
EM feikong@mail.com
CR [Anonymous], ARXIV170607157
   [Anonymous], INTERNET THINGS FINL
   [Anonymous], 2016, GEOSCIENCE
   Aziz A, 2015, I SYMPOS LOW POWER E, P1, DOI 10.1109/ISLPED.2015.7273481
   Bei ZD, 2016, IEEE T PARALL DISTR, V27, P1470, DOI 10.1109/TPDS.2015.2449299
   Binabaj FB, 2014, IRAN J APPL ANIM SCI, V4, P269
   Chen Y, 2014, IEEE INTERNET THINGS, V1, P81, DOI 10.1109/JIOT.2014.2308838
   Chen YS, 2015, IEEE J-STARS, V8, P2381, DOI 10.1109/JSTARS.2015.2388577
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Cho K, 2014, ELECTRON LETT, V50, P173, DOI 10.1049/el.2013.2761
   Conoscenti C, 2015, GEOMORPHOLOGY, V242, P49, DOI 10.1016/j.geomorph.2014.09.020
   del Río S, 2014, INFORM SCIENCES, V285, P112, DOI 10.1016/j.ins.2014.03.043
   Dergachyova O, 2016, IEEE Trans. on Medical Imaging
   Dilrukshi I, 2013, PROCEEDINGS OF THE 2013 8TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE & EDUCATION (ICCSE 2013), P287
   Nieto PJG, 2016, J COMPUT APPL MATH, V291, P293, DOI 10.1016/j.cam.2015.01.009
   Geng RB, 2015, EUR J OPER RES, V241, P236, DOI 10.1016/j.ejor.2014.08.016
   Gligorov VV, 2013, J INSTRUM, V8, DOI 10.1088/1748-0221/8/02/P02013
   Guo HX, 2016, ENG APPL ARTIF INTEL, V49, P176, DOI 10.1016/j.engappai.2015.09.011
   Heung B, 2014, GEODERMA, V214, P141, DOI 10.1016/j.geoderma.2013.09.016
   Islam T, 2015, IEEE SENS J, V15, P2186, DOI 10.1109/JSEN.2014.2372814
   Jing Q, 2014, WIREL NETW, V20, P2481, DOI 10.1007/s11276-014-0761-7
   Kalles D, 2015, 2015 6 INT C INF INT, P1
   Kim JE, 2016, IEEE INT CONF EMBED, P202, DOI 10.1109/RTCSA.2016.47
   Kim MJ, 2015, EXPERT SYST APPL, V42, P1074, DOI 10.1016/j.eswa.2014.08.025
   Li J, 2013, IEEE T GEOSCI REMOTE, V51, P844, DOI 10.1109/TGRS.2012.2205263
   Liang JM, 2013, IEEE J EM SEL TOP C, V3, P13, DOI 10.1109/JETCAS.2013.2243631
   Liang RZ, 2016, INT C PATT RECOG, P2954, DOI 10.1109/ICPR.2016.7900086
   Lin GS, 2014, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2014.253
   Lin KB, 2014, INT CONF COMP SCI ED, P544, DOI 10.1109/ICCSE.2014.6926521
   Liu D, 2014, INT J APPROX REASON, V55, P197, DOI 10.1016/j.ijar.2013.02.013
   Luong NC, 2016, IEEE COMMUN SURV TUT, V18, P2546, DOI 10.1109/COMST.2016.2582841
   Patil T. R., 2013, International Journal Of Computer Science And Applications, V6, P256
   Peng Cao, 2013, Advances in Knowledge Discovery and Data Mining. 17th Pacific-Asia Conference (PAKDD 2013). Proceedings, P280, DOI 10.1007/978-3-642-37456-2_24
   Rahmati O, 2016, CATENA, V137, P360, DOI 10.1016/j.catena.2015.10.010
   Reddy S.V. G., 2014, INT J COMPUTER SCI I, V5, P5901
   Rutkowski L, 2014, INFORM SCIENCES, V266, P1, DOI 10.1016/j.ins.2013.12.060
   Rutkowski L, 2014, IEEE T KNOWL DATA EN, V26, P108, DOI 10.1109/TKDE.2013.34
   Salimi-Khorshidi G, 2014, NEUROIMAGE, V90, P449, DOI 10.1016/j.neuroimage.2013.11.046
   Shafagh H, 2015, MOBICOM '15: PROCEEDINGS OF THE 21ST ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P251, DOI 10.1145/2789168.2795172
   Shang FH, 2015, INT J COMPUT SCI NET, V15, P58
   Strassner J, 2016, 2016 IEEE 3RD WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P609, DOI 10.1109/WF-IoT.2016.7845422
   Suciu G, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0327-y
   Tsai CW, 2014, WIREL NETW, V20, P2201, DOI 10.1007/s11276-014-0731-0
   Vaidya J, 2014, IEEE T DEPEND SECURE, V11, P399, DOI 10.1109/TDSC.2013.43
   Wang HX, 2014, PROC INT C TOOLS ART, P853, DOI 10.1109/ICTAI.2014.131
   Wang JB, 2015, IEEE SYS MAN CYBERN, P1870, DOI 10.1109/SMC.2015.327
   Wang JY, 2015, LECT NOTES COMPUT SC, V9377, P232, DOI 10.1007/978-3-319-25393-0_26
   Wang Q, 2014, ABSTR APPL AN, V2014
   Wang WZ, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND BIG DATA ANALYSIS (ICCCBDA 2017), P311, DOI 10.1109/ICCCBDA.2017.7951930
   Wong KS, 2014, J APPL MATH, DOI 10.1155/2014/827959
   Xu JS, 2014, IMAGE VISION COMPUT, V32, P550, DOI 10.1016/j.imavis.2014.04.009
   Xu L., 2014, INFORMAT, P1, DOI [DOI 10.1109/TII.2014.2300753, 10.1109/TII.2014.2300753]
   Zhang SC, 2018, IEEE T NEUR NET LEAR, V29, P1774, DOI 10.1109/TNNLS.2017.2673241
   Zhuang Y, 2015, LECT NOTES ARTIF INT, V9078, P690, DOI 10.1007/978-3-319-18032-8_54
NR 54
TC 12
Z9 12
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4623
EP 4653
DI 10.1007/s11042-018-6423-5
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200037
DA 2024-07-18
ER

PT J
AU Lee, JH
   Park, SO
AF Lee, Jae Hwan
   Park, Sang Oh
TI Machine learning-based automatic reinforcing bar image analysis system
   in the internet of things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reinforcing bar; Machine learning; Image analysis; Internet of things;
   Quantity management
AB Research on the analysis of reinforcing bar images has been conducted to count reinforcing bars moving along a conveyor belt at a bar production plant. It is relatively easy to analyze images at the plant, where the environment and light sources can be tightly controlled. At construction sites, the characteristics of images vary greatly depending on the environment, time of image acquisition, and weather conditions. Therefore, a method for correctly segregating the reinforcing bar area is needed. In this paper, we propose an automatic reinforcing bar image analysis system based on machine learning. Our proposed system accurately separates the bar area from the background and counts the number of bars in the image. Compared with existing method, the proposed system performs better on detection of reinforcing bars.
C1 [Lee, Jae Hwan; Park, Sang Oh] Chung Ang Univ, Sch Comp Sci & Engn, 84 Heukseok Ro, Seoul 06974, South Korea.
C3 Chung Ang University
RP Park, SO (corresponding author), Chung Ang Univ, Sch Comp Sci & Engn, 84 Heukseok Ro, Seoul 06974, South Korea.
EM jhlee@cslab.cau.ac.kr; sopark@cau.ac.kr
FU National Research Foundation of Korea(NRF) - Korea government(MSIT)
   [NRF-2017R1C1B5075856]
FX This work was supported by the National Research Foundation of
   Korea(NRF) grant funded by the Korea government(MSIT) (No.
   NRF-2017R1C1B5075856).
CR Achanta R., 2010, EPFL Technical Report 149300, V6, P15
   Bahaa-Eldeen A. M., 2000, U AIN SHAMS FACULTY, V35, P349
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Brunelli R., 2009, Template matching techniques in computer vision: theory and practice, DOI DOI 10.1002/9780470744055
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   DAVIES ER, 1988, PATTERN RECOGN LETT, V7, P37, DOI 10.1016/0167-8655(88)90042-6
   Dietterich T., 2002, The handbook of brain theory and neural networks
   Ellahyani A, 2016, APPL SOFT COMPUT, V46, P805, DOI 10.1016/j.asoc.2015.12.041
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Gonzalez R. C., 2002, DIGITAL IMAGE PROCES, P572
   Joshi A, 2015, IEEE INT CONF AUTOMA
   Liu G, 2015, INT J SIGN PROCESS I, V8, P363
   Liu XD, 2016, INT C ELECTR MACH SY
   Mistry P, 2016, SOFT COMPUT, V20, P2967, DOI 10.1007/s00500-015-1925-9
   Nie Z., 2016, THE J, V7, P425
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Parvin B, 2007, IEEE T IMAGE PROCESS, V16, P615, DOI 10.1109/TIP.2007.891154
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Shapiro L. G., 2001, COMPUTER VISION
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   Zhang D, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P319, DOI 10.1109/CISP.2008.664
NR 21
TC 6
Z9 6
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3171
EP 3180
DI 10.1007/s11042-018-5984-7
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600026
DA 2024-07-18
ER

PT J
AU Wang, ML
   Yang, LY
   Li, TT
   Guo, SH
   Jiang, JC
   Zhang, HM
   Chang, J
AF Wang, Meili
   Yang, Liying
   Li, Tingting
   Guo, Shihui
   Jiang, Jincen
   Zhang, Hongming
   Chang, Jian
TI 3D sunken relief generation from a single image by feature line
   enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sunken relief; Unsharp Masking (USM); Triangularization
AB Sunken relief is an art form whereby the depicted shapes are sunk into a given flat plane with a shallow overall depth. In this paper, we propose an efficient sunken relief generation algorithm based on a single image by the technique of feature line enhancement. Our method starts from a single image. First, we smoothen the image with morphological operations such as opening and closing operations and extract the feature lines by comparing the values of adjacent pixels. Then we apply unsharp masking to sharpen the feature lines. After that, we enhance and smoothen the local information to obtain an image with less burrs and jaggies. Differential operations are applied to produce the perceptive relief-like images. Finally, we construct the sunken relief surface by triangularization which transforms two-dimensional information into a three-dimensional model. The experimental results demonstrate that our method is simple and efficient.
C1 [Wang, Meili; Yang, Liying; Li, Tingting; Jiang, Jincen; Zhang, Hongming] Northwest A&F Univ, Xianyang, Shaanxi, Peoples R China.
   [Wang, Meili] Minist Agr, Key Lab Agr Internet Things, Yangling 712100, Shaanxi, Peoples R China.
   [Wang, Meili] Shaanxi Key Lab Agr Informat Percept & Intelligen, Yangling 712100, Shaanxi, Peoples R China.
   [Guo, Shihui] Xiamen Univ, Xiamen, Peoples R China.
   [Chang, Jian] Bournemouth Univ, Poole, Dorset, England.
C3 Northwest A&F University - China; Ministry of Agriculture & Rural
   Affairs; Xiamen University; Bournemouth University
RP Guo, SH (corresponding author), Xiamen Univ, Xiamen, Peoples R China.
EM guoshihui@xmu.edu.cn
RI Li, Tingting/HKE-0812-2023; zhang, ting/IYT-0642-2023; Ting,
   Zhang/KGM-5479-2024; L, J/JEF-9564-2023
OI Jiang, Jincen/0000-0002-0150-4644
FU National Natural Science Foundation of China [61402374, 61702433,
   61661146002]
FX This work was funded by the National Natural Science Foundation of China
   (61402374, 61702433, 61661146002). We thank all reviewers for editing
   the English of this manuscript.
CR Arpa S, 2015, COMPUT GRAPH FORUM, V34, P253, DOI 10.1111/cgf.12557
   Cignoni P., 1997, Journal of Graphics Tools, V2, P15, DOI 10.1080/10867651.1997.10487476
   DeCarlo D, 2003, ACM T GRAPHIC, V22, P848, DOI 10.1145/882262.882354
   Deng G, 2011, IEEE T IMAGE PROCESS, V20, P1249, DOI 10.1109/TIP.2010.2092441
   To HT, 2017, MULTIMED TOOLS APPL, V76, P10407, DOI 10.1007/s11042-016-3924-y
   Kerber J, 2012, COMPUT GRAPH FORUM, V31, P2363, DOI 10.1111/j.1467-8659.2012.03185.x
   Lee Y, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239469
   Liu Sheng-lan, 2011, Journal of Chinese Computer Systems, V32, P2088
   Lu Qiao, 2015, Journal of Computer Aided Design & Computer Graphics, V27, P1172
   [缪永伟 Miao Yongwei], 2016, [计算机辅助设计与图形学学报, Journal of Computer-Aided Design & Computer Graphics], V28, P50
   Ramponi G, 1998, SIGNAL PROCESS, V67, P211, DOI 10.1016/S0165-1684(98)00038-3
   Raskar Ramesh., 2001, Proceedings of the ACM SIGGRAPH/EUROGRAPHICS workshop on Graphics hardware, HWWS '01, P41, DOI DOI 10.1145/383507.383525
   Sohn BS, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030572
   Song WH, 2007, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2007, PROCEEDINGS, P211, DOI 10.1109/SMI.2007.9
   Wang M., 2010, PRACTICE THEORY, P33
   Wang M., 2013, P 27 SPRING C COMP G, P37, DOI [10.1145/2461217.2461226, DOI 10.1145/2461217.2461226]
   Wang M, 2017, COMP GRAPH INT C, P31
   Wang ML, 2016, CHIN J MECH ENG-EN, V29, P1128, DOI 10.3901/CJME.2016.0720.084
   Wang ML, 2012, VISUAL COMPUT, V28, P1127, DOI 10.1007/s00371-011-0663-y
   Wu J, 2013, COMPUT AIDED DESIGN, V45, P671, DOI 10.1016/j.cad.2012.11.002
   Wu W, 2016, COLL MATH, V32, P1
   Zeng Q, 2014, GRAPH MODELS, V76, P140, DOI 10.1016/j.gmod.2013.10.001
   Zhang Long., 2009, Proceedings of the 2009 symposium on Interactive 3D graphics and games, I3D '09, P129, DOI DOI 10.1145/1507149.1507170]
   Zhang YW, 2016, COMPUT GRAPH FORUM, V35, P311, DOI 10.1111/cgf.13028
   Zhang YW, 2013, GRAPH MODELS, V75, P297, DOI 10.1016/j.gmod.2013.07.002
NR 25
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4989
EP 5002
DI 10.1007/s11042-018-5826-7
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200055
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhang, YQ
   Chen, JH
AF Zhang, Yaqi
   Chen, Juhong
TI Supply chain coordination of incomplete preventive maintenance service
   based on multimedia remote monitoring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Incomplete preventive maintenance service; Two-stage maintenance service
   supply chain; Remote monitoring technology; Decentralized
   decision-making; Centralized decision-making
AB Manufacturing relies on the Internet of things and intelligent internet technology to provide users with remote monitoring services and early warning of failure, to ensure the smooth operation of the equipment. Based on this background, this paper takes equipment user (customer) and maintenance service provider (agent) consist of the two-stage maintenance service supply chain as the research object. A model is proposed for the maintenance service contracts design, optimization under decentralized decision-making and centralized decision-making. The model is developed under the assumption that there is one customer and one unique service provider who is the Original Equipment Manufacturer (OEM) and is called the agent in this paper. Besides, an extensive sensitivity analysis is performed to examine the impact on the improvement factor of the model output. Under the selective maintenance service outsourcing strategy, the agent makes the price of incomplete preventive maintenance, and the customer decides the incomplete preventive maintenance cycle and the times according to the price. Confronting the equipment failure, customer self-repair service and commitments for the loss of equipment downtime, the customer decides the optimal maintenance services prices, and the agent decides the optimal numbers and the cycles of the preventive maintenance service (equipment life).
C1 [Zhang, Yaqi; Chen, Juhong] Xian Univ Technol, Fac Econ & Management, Xian 710064, Shaanxi, Peoples R China.
C3 Xi'an University of Technology
RP Zhang, YQ (corresponding author), Xian Univ Technol, Fac Econ & Management, Xian 710064, Shaanxi, Peoples R China.
EM mier0_1963@yeah.net
RI Zhang, Yaqi/AAR-9163-2020
FU Humanities and Social Sciences Foundation of Ministry of Education
   Program [16YJC630170]; Scientific Research Project of Shaanxi Province
   Education Office [15JK1548]
FX This work was supported by the Humanities and Social Sciences Foundation
   of Ministry of Education Program (No.16YJC630170); the Scientific
   Research Project of Shaanxi Province Education Office (No.15JK1548).
CR Alam Ian., 2002, Journal of Services Marketing, V16, P515, DOI [DOI 10.1108/08876040210443391, 10.1108/08876040210443391]
   Allmendinger G, 2005, HARVARD BUS REV, V83, P131
   Bian JS, 2017, ANN OPER RES, V248, P123, DOI 10.1007/s10479-016-2228-y
   Chronaki CE, 2013, EUROPACE, V15, P59, DOI 10.1093/europace/eut110
   Cohen MA, 1997, IIE TRANS, V29, P627, DOI 10.1023/A:1018513900264
   Díaz VGP, 2012, INT J QUAL RELIAB MA, V29, P320, DOI 10.1108/02656711211216162
   Garg A, 2006, J QUAL MAINT ENG, V12, P205, DOI 10.1108/13552510610685075
   Hong S, 2015, APPL MATH MODEL, V1, P1
   Hung MH, 2003, ADV ENG INFORM, V17, P165, DOI 10.1016/j.aei.2004.07.004
   Jackson C, 2008, EUR J OPER RES, V189, P387, DOI 10.1016/j.ejor.2007.05.039
   Jardine AKS, 2006, MECH SYST SIGNAL PR, V20, P1483, DOI 10.1016/j.ymssp.2005.09.012
   Jin TD, 2015, INT J PROD ECON, V161, P31, DOI 10.1016/j.ijpe.2014.11.010
   Öhman M, 2015, INT J PROD ECON, V170, P457, DOI 10.1016/j.ijpe.2015.06.020
   Park M, 2017, APPL MATH MODEL, V43, P498, DOI 10.1016/j.apm.2016.11.015
   Pham H, 1996, EUR J OPER RES, V94, P425, DOI 10.1016/0377-2217(96)00099-9
   Ren G., 2007, CRANF PROD SERV SYST, P4
   Shah N, 2007, ADV ENG INFORM, V21, P183, DOI 10.1016/j.aei.2006.05.007
   Sun X., 2016, CURR CONTENTS, V2016, P1, DOI [10.1155/2016/1505817, DOI 10.1155/2016/1505817]
   Wang HZ, 2002, EUR J OPER RES, V139, P469, DOI 10.1016/S0377-2217(01)00197-7
   Wang WB, 2010, EUR J OPER RES, V201, P239, DOI 10.1016/j.ejor.2009.02.018
   Wei YH, 2013, INT J PROD ECON, V144, P590, DOI 10.1016/j.ijpe.2013.04.022
   Yan Y, 2014, EURASIP J WIREL COMM, V2014, P211, DOI [10.1186/1687-1499-2014-127, DOI 10.1186/1687-1499-2014-127]
NR 22
TC 2
Z9 3
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4463
EP 4479
DI 10.1007/s11042-018-5977-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200029
DA 2024-07-18
ER

PT J
AU Datta, B
   Roy, S
   Roy, S
   Bandyopadhyay, SK
AF Datta, Biswajita
   Roy, Sudipta
   Roy, Subhranil
   Bandyopadhyay, Samir Kumar
TI Multi-bit robust image steganography based on modular arithmetic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganography; Radix conversion; Modulo operator; Multi-bit
   steganography; Embedding capacity; Robustness
AB The main objective is to design a robust algorithm which can hide multiple target bits without direct replacement of the bits of cover image and at the same time maintain perceptibility of carrier medium by reducing the distortion rate by intensity adjustment. The method uses the strength of modular arithmetic for embedding target data and at the same time able to solve the overlapping problem. In this double layer security technique first the target bits are converted into another number system and then these converted digits are embedded by adjusting the pixel intensities in such a way so that modulo operation retrieve data correctly at the receiver side. The proposed technique is tested on different class of images and analyzed based on different parameters. The histograms are distorted significantly for more than four bit insertion and the average PSNR is 34.7 for four multi-bit insertion with 100% payload. Different standard LSB detectors like SP, WS etc. are fail to detect hidden bits and at the same time the statistical attack on stego media unable to get success on stego images. The performance of the proposed technique is measured by Stirmark Benchmark 4.0 whereas the security strength is calculated through KL divergence which establishes it as a more secure algorithm. The Average Embedding Capacity of this technique is four. The work shows better performances than many state-of-the-art-works. The method reduces the distortion rate to half of the standard multi-bit LSB technique. This helps to retain imperceptibility with the increase of capacity through multi-bit insertion. The robustness is introduced in this spatial domain technique by embedding target data without direct replacement of cover bits. This algorithm uses the NP-complete nature of modulo operation to increase security and at the same time introduces parallelism to reduce time complexity.
C1 [Datta, Biswajita; Roy, Subhranil] St Thomas Coll Engn & Technol, Dept Comp Sci & Engn, Kolkata 700023, India.
   [Roy, Sudipta] Univ Calcutta, Dept Comp Sci & Engn, Kolkata, W Bengal, India.
   [Roy, Sudipta; Bandyopadhyay, Samir Kumar] Calcutta Univ, Dept Comp Sci & Engn, Calcutta Univ Technol Campus,JD-2,Sect 3, Kolkata 700098, India.
C3 University of Calcutta; University of Calcutta
RP Datta, B (corresponding author), St Thomas Coll Engn & Technol, Dept Comp Sci & Engn, Kolkata 700023, India.
EM biswa.jita@gmail.com; sudiptaroy01@yahoo.com; subhranilroy5@gmail.com;
   1954samir@gmail.com
RI Roy, Sudipta/T-5231-2019; Bandyopadhyay, Samir Kumar/AAR-8919-2020
OI Roy, Sudipta/0000-0001-5161-9311; Bandyopadhyay, Samir
   Kumar/0000-0002-4868-3459
CR [Anonymous], 2015, INT J SIGNAL PROCESS, DOI DOI 10.14257/IJSIP.2015.8.7.15
   [Anonymous], P SPIE SEC FOR STEG
   [Anonymous], TEST IMAGES DECSAI I
   [Anonymous], INFORM HIDING HOMEPA
   [Anonymous], INT J SIGNAL PROCESS
   Aryal A, 2015, LECT NOTES COMPUTER, V9290
   Asai H., 1976, Computers & Mathematics with Applications, V2, P255, DOI 10.1016/0898-1221(76)90018-3
   Bailey K, 2006, MULTIMED TOOLS APPL, V30, P55, DOI 10.1007/s11042-006-0008-4
   Bergman M, 2016, IEEE CONSUM ELECTR M, V5, P132, DOI 10.1109/MCE.2016.2556778
   BOUTE RT, 1992, ACM T PROGR LANG SYS, V14, P127, DOI 10.1145/128861.128862
   Brent RP, 2010, CAMBRIDGE MONOGRAPHS, V18, P236
   Cachin C, 2004, INFORM COMPUT, V192, P41, DOI 10.1016/j.ic.2004.02.003
   Cha SH, 2002, PATTERN RECOGN, V35, P1355, DOI 10.1016/S0031-3203(01)00118-2
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Dumitrescu D, 2017, STEGANOGRAPHY TECHNI
   Dumitrescu S, 2003, LECT NOTES COMPUT SC, V2578, P355
   Feng BW, 2015, IEEE T INF FOREN SEC, V10, P243, DOI 10.1109/TIFS.2014.2368364
   Gonzalez RC, 2002, DIGITAL IMAGE PROCES
   Hussain M, 2018, IETE TECH REV, V35, P53, DOI 10.1080/02564602.2016.1244496
   Islam S, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-8
   Ker AD, 2007, P SPIE, V6505, P16, DOI 10. 1117/12. 704606
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Kuo WC, 2015, APPL SCI-BASEL, V5, P1033, DOI 10.3390/app5041033
   Kutter M., 1999, P SOC PHOTO-OPT INS, V3657, P219
   Lin YT, 2017, IEEE T MULTIMEDIA, V19, P196, DOI 10.1109/TMM.2016.2605499
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Mukherjee Imon, 2013, Information Systems Security. 9th International Conference, ICISS 2013. Proceedings: LNCS 8303, P270, DOI 10.1007/978-3-642-45204-8_21
   Nguyen BC, 2006, LECT NOTES COMPUT SC, V4283, P61
   Paul G, 2017, MULTIMED TOOLS APPL, V76, P7445, DOI 10.1007/s11042-016-3319-0
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Prashanti G, 2015, ADV INTELL SYST, V338, P423, DOI 10.1007/978-3-319-13731-5_46
   PUNDDANGE S, 2017, INDIAN J SCI TECHNOL, V10
   Rajopadhye S, NUMBER SYSTEMS RADIX
   Sedighi V., 2015, P SPIE ELECT IMAGING, V9409
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Shu XK, 2016, IEEE T INF FOREN SEC, V11, P528, DOI 10.1109/TIFS.2015.2503271
   Stanley CA, PAIRS VALUES CHI SQU
   Valandar MY, 2017, J INF SECUR APPL, V34, P142, DOI 10.1016/j.jisa.2017.04.004
   Vatai E, DISCRETE MATH
   Wang CM, 2008, J SYST SOFTWARE, V81, P150, DOI 10.1016/j.jss.2007.01.049
   Wang SJ, 2005, APPL MATH COMPUT, V164, P99, DOI 10.1016/j.amc.2004.04.059
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
   Wong KS, 2007, SIGNAL PROCESS, V87, P1251, DOI 10.1016/j.sigpro.2006.10.014
   Xie L, 2016, MULTIMED TOOLS APPL, V75, P9185, DOI 10.1007/s11042-016-3432-0
   Yang CY, 2015, ADV INTELL SYST COMP, V329, P145, DOI 10.1007/978-3-319-12286-1_15
   Zhu L, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P843, DOI 10.1145/2733373.2806345
   Zhu L, 2014, J SUPERCOMPUT, V68, P820, DOI 10.1007/s11227-013-1068-7
   USC SIPI IM DAT, V3
NR 49
TC 10
Z9 11
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1511
EP 1546
DI 10.1007/s11042-018-6195-y
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700014
DA 2024-07-18
ER

PT J
AU Pan, ZB
   Zhang, R
   Ku, WP
   Wang, YD
AF Pan, Zhibin
   Zhang, Rui
   Ku, Weiping
   Wang, Yidi
TI Adaptive pattern selection strategy for diamond search algorithm in fast
   motion estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion estimation; Adaptive pattern selection; Diamond search algorithm;
   Block-based matching algorithm
ID EFFICIENT MOTION
AB In this paper, an adaptive pattern selection strategy for diamond search (DS) algorithm is proposed. DS is one of state-of-the-art motion estimation algorithms, while the fixed search strategy and the singular termination strategy lead to lots of redundancy of search points. The proposed search strategy is based on the observation that more than 75% motion vector differences are around the initial predicted search centre in the range of 1. In our search strategy, small diamond search pattern and large diamond search pattern are adaptively used according to the distribution of motion vector differences and the matching error information of initial search centre. Our search strategy focuses on how to use small diamond search pattern and large diamond search pattern more efficiently than diamond search algorithm without introducing additional search patterns. Experimental results show that the proposed algorithm can save about 10.81 search points and achieve 0.12dB higher PSNR on average compared to DS.
C1 [Pan, Zhibin; Zhang, Rui; Ku, Weiping; Wang, Yidi] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University
RP Pan, ZB (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Shaanxi, Peoples R China.
EM zbpan@mail.xjtu.edu.cn
RI Pan, Zhibin/I-8212-2012
FU Open Project Program of the State Key Lab of Novel Software Technology,
   Nanjing University [KFKT2016B14]; Open Research Fund of CAS Key
   Laboratory of Spectral Imaging Technology [LSIT201606D]; Open Project
   Program of the National Laboratory of Pattern Recognition (NLPR)
   [201800030]
FX This work is supported in part by the Open Project Program of the State
   Key Lab of Novel Software Technology (Grant No. KFKT2016B14), Nanjing
   University, the Open Research Fund of CAS Key Laboratory of Spectral
   Imaging Technology (Grant No. LSIT201606D) and the Open Project Program
   of the National Laboratory of Pattern Recognition (NLPR) (Grant No.
   201800030).
CR Al-Najdawi N, 2014, INFORM SCIENCES, V268, P425, DOI 10.1016/j.ins.2013.08.009
   Amirpour H, 2016, SIGNAL IMAGE VIDEO P, V10, P1393, DOI 10.1007/s11760-016-0906-5
   Arora SM, 2016, J REAL TIME IMAGE PR, P1
   Cheung CH, 2002, IEEE T CIRC SYST VID, V12, P1168, DOI 10.1109/TCSVT.2002.806815
   Choi C, 2014, IEEE SIGNAL PROC LET, V21, P1260, DOI 10.1109/LSP.2014.2328992
   González-Díaz I, 2008, IEEE T CIRC SYST VID, V18, P1369, DOI 10.1109/TCSVT.2008.2004917
   Ismail Y, 2012, IEEE T CIRC SYST VID, V22, P28, DOI 10.1109/TCSVT.2011.2148450
   Jia LH, 2013, IEEE INT CONF MULTI
   Kerfa D, 2016, MULTIMED TOOLS APPL, V75, P3161, DOI 10.1007/s11042-014-2428-x
   Ko YH, 2011, IEEE T CONSUM ELECTR, V57, P726, DOI 10.1109/TCE.2011.5955214
   Lam CW, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P1262
   Lee S, 2010, IET IMAGE PROCESS, V4, P1, DOI 10.1049/iet-ipr.2009.0069
   Li C, 2014, WIT TRANS INFO COMM, V46, P1379, DOI 10.2495/ISME20131782
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   Luo J, 2015, MULTIMED TOOLS APPL, V74, P11821, DOI 10.1007/s11042-014-2280-z
   Ma TH, 2016, NEUROCOMPUTING, V207, P488, DOI 10.1016/j.neucom.2016.05.020
   Medhat A, 2016, IET IMAGE PROCESS, V10, P438, DOI 10.1049/iet-ipr.2015.0666
   Nalluri P, 2015, SIGNAL PROCESS-IMAGE, V39, P280, DOI 10.1016/j.image.2015.09.015
   Nie Y, 2002, IEEE T IMAGE PROCESS, V11, P1442, DOI 10.1109/TIP.2002.806251
   Pan ZQ, 2016, J VIS COMMUN IMAGE R, V40, P516, DOI 10.1016/j.jvcir.2016.07.018
   Pan ZQ, 2016, IEEE T BROADCAST, V62, P675, DOI 10.1109/TBC.2016.2580920
   Pan ZQ, 2015, IEEE T BROADCAST, V61, P166, DOI 10.1109/TBC.2015.2419824
   Paramkusam AV, 2014, ELECTRON LETT, V50, P276, DOI 10.1049/el.2013.4032
   Po LM, 2007, IEEE T MULTIMEDIA, V9, P9, DOI 10.1109/TMM.2006.886330
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Purnachand N., 2012, 2012 IEEE Second International Conference on Consumer Electronics - Berlin (ICCE-Berlin), P34, DOI 10.1109/ICCE-Berlin.2012.6336494
   Purwar RK, 2013, SIGNAL IMAGE VIDEO P, V7, P151, DOI 10.1007/s11760-011-0283-z
   Shi ZR, 2011, IEEE T CONSUM ELECTR, V57, P1354, DOI 10.1109/TCE.2011.6018894
   Singh K, 2013, ANNU IEEE IND CONF
   So H, 2005, ELECTRON LETT, V41, P62, DOI 10.1049/el:20056342
   Soroushmehr SMR, 2014, MULTIMED TOOLS APPL, V71, P1615, DOI 10.1007/s11042-012-1298-3
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zhou ZL, 2017, INT J DISTRIB SENS N, V13, DOI 10.1177/1550147717694172
   Zhu C, 2002, IEEE T CIRC SYST VID, V12, P349, DOI 10.1109/TCSVT.2002.1003474
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
   Zhu SP, 2009, IEEE IMAGE PROC, P1581, DOI 10.1109/ICIP.2009.5413397
NR 36
TC 8
Z9 8
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 2447
EP 2464
DI 10.1007/s11042-018-6353-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700051
DA 2024-07-18
ER

PT J
AU Su, YT
   Li, Y
   Liu, AA
AF Su, Yuting
   Li, Yang
   Liu, Anan
TI Open-view human action recognition based on linear discriminant analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Open-view; Dataset
ID ALGORITHM
AB In the last decades, action recognition task has evolved from single view recording to unconstrained environment. Recently, multi-view action recognition has become a hot topic in computer vision. However, we notice that only a few works have focused on the open-view action recognition, which is a common problem in the real world. Open-view action recognition focus on doing action recognition in unseen view without using any information from it. To address this issue, we firstly introduce a novel multi-view surveillance action dataset and benchmark several state-of-the-art algorithms. From the results, we observe that the performance of the state-of-the-art algorithms would drop a lot under open-view constraints. Then, we propose a novel open-view action recognition method based on the linear discriminant analysis. This method can learn a common space for action samples under different view by using their category information, which can achieve a good result in open-view action recognition.
C1 [Su, Yuting; Li, Yang; Liu, Anan] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
C3 Tianjin University
RP Liu, AA (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
EM ytsu@tju.edu.cn; usaliiyang@gmail.com; anan0422@gmail.com
FU National Natural Science Foundation of China [61772359, 61472275,
   61572356]; Tianjin Research Program of Application Foundation and
   Advanced Technology [15JCYBJC16200]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61772359 and Grant 61472275 and Grant
   61572356 and in part by the Tianjin Research Program of Application
   Foundation and Advanced Technology under Grant 15JCYBJC16200.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2009, BMVC
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Cai D, 2008, IEEE T KNOWL DATA EN, V20, P1, DOI 10.1109/TKDE.2007.190669
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2016, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2016.208
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Faraki M, 2015, IET COMPUT VIS, V9, P331, DOI 10.1049/iet-cvi.2014.0018
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Hao T, 2016, INT J MOL SCI, V17, DOI 10.3390/ijms17060907
   Hao T, 2016, NEUROCOMPUTING, V195, P6, DOI 10.1016/j.neucom.2015.06.106
   He XN, 2017, IEEE T KNOWL DATA EN, V29, P57, DOI 10.1109/TKDE.2016.2611584
   Ke Y, 2007, IEEE I CONF COMP VIS, P1424
   Kliper-Gross O, 2012, IEEE T PATTERN ANAL, V34, P615, DOI 10.1109/TPAMI.2011.209
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Kuehne H, 2014, PROC CVPR IEEE, P780, DOI 10.1109/CVPR.2014.105
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Liu AA, 2017, IEEE T CYBERNETICS, V47, P1781, DOI 10.1109/TCYB.2016.2582918
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu AA, 2015, IEEE T CYBERNETICS, V45, P1194, DOI 10.1109/TCYB.2014.2347057
   Liu JG, 2009, PROC CVPR IEEE, P1996
   Luo MN, 2018, IEEE T CYBERNETICS, V48, P648, DOI 10.1109/TCYB.2017.2647904
   Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557
   Messing R, 2009, IEEE I CONF COMP VIS, P104, DOI 10.1109/ICCV.2009.5459154
   Nie LQ, 2017, IEEE T NEUR NET LEAR, V28, P1508, DOI 10.1109/TNNLS.2016.2520964
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Nie WZ, 2016, IMAGE VISION COMPUT, V55, P109, DOI 10.1016/j.imavis.2016.04.011
   Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29
   Over P., 2014, Proceedings of TRECVID, P52
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   Ryoo MS, 2009, IEEE I CONF COMP VIS, P1593, DOI 10.1109/ICCV.2009.5459361
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Singh Sanchit, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P48, DOI 10.1109/AVSS.2010.63
   Soomro K., 2012, CoRR, V2
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Weinland D, 2007, IEEE I CONF COMP VIS, P170
   Yao BP, 2011, IEEE I CONF COMP VIS, P1331, DOI 10.1109/ICCV.2011.6126386
   Zhang HW, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2978656
NR 44
TC 5
Z9 5
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 767
EP 782
DI 10.1007/s11042-018-5657-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500043
DA 2024-07-18
ER

PT J
AU Tian, P
   Duan, HX
AF Tian, Peng
   Duan, Huixian
TI A discriminant method of single-optical-axis omnidirectional vision
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single-optical-axis; Omnidirectional vision system; Cross ratio;
   Projective invariance
ID PARACATADIOPTRIC CAMERA; CALIBRATION METHOD
AB Generally, due to the instrumental error of omnidirectional camera, it is very difficult to satisfy the standard single-optical-axis request. Thus, it is necessary to evaluate whether a single-optical-axis camera lens is aligned or has tangent distortion. In this paper, we propose a discriminant function of single-optical-axis omnidirectional vision system based on checkerboard, which is only related to the image points and does not involve any camera parameters. Firstly, under single-optical-axis omnidirectional camera, the geometric invariance among image points of collinear and equidistant space points is derived. Next, based on the derived geometric invariance in a single image, we construct the object function to discriminate the standard single-optical-axis omnidirectional camera. Finally, a discriminant method of single-optical-axis omnidirectional vision system is proposed based on the checkerboard. Experimental results on both simulated and real data have demonstrated the usefulness and effectiveness of our method.
C1 [Tian, Peng] East China Univ Sci & Technol, Sci Coll, Shanghai, Peoples R China.
   [Duan, Huixian] Cyber Phys Syst R & D Ctr, Res Inst 3, Minist Publ Secur, Shanghai, Peoples R China.
   [Duan, Huixian] Shanghai Int Technol & Trade United Co Ltd, Shanghai, Peoples R China.
   [Duan, Huixian] Chinese Acad Sci, Shanghai Inst Appl Phys, Shanghai, Peoples R China.
C3 East China University of Science & Technology; Ministry of Public
   Security (China); Chinese Academy of Sciences; Shanghai Institute of
   Applied Physics, CAS
RP Duan, HX (corresponding author), Cyber Phys Syst R & D Ctr, Res Inst 3, Minist Publ Secur, Shanghai, Peoples R China.; Duan, HX (corresponding author), Shanghai Int Technol & Trade United Co Ltd, Shanghai, Peoples R China.; Duan, HX (corresponding author), Chinese Acad Sci, Shanghai Inst Appl Phys, Shanghai, Peoples R China.
EM tianpeng135@163.com; hxduan005@163.com
FU Shanghai Rising-Star Program [17QB1401000]; Shanghai science and
   technology innovation action plan [17511108200]; National Natural
   Science Foundation of China [61403084, 61402116]; Application Innovation
   Plan of Ministry of Public Security [2017YYCXSXST030]
FX This work is sponsored by the Shanghai Rising-Star Program
   (17QB1401000); and by Shanghai science and technology innovation action
   plan(17511108200); and by the National Natural Science Foundation of
   China (61403084, 61402116); and by the Application Innovation Plan of
   Ministry of Public Security (2017YYCXSXST030).
CR Baker S, 1999, INT J COMPUT VISION, V35, P175, DOI 10.1023/A:1008128724364
   Barreto JP, 2005, IEEE T PATTERN ANAL, V27, P1327, DOI 10.1109/TPAMI.2005.163
   Deng Xiao-Ming, 2007, Acta Automatica Sinica, V33, P801, DOI 10.1360/aas-007-0801
   DRESS A, 1991, ADV MATH, V86, P68, DOI 10.1016/0001-8708(91)90036-7
   Duan HM, 2017, COMPLEXITY, P1, DOI 10.1155/2017/3515272
   Duan HX, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS (VISAPP), VOL 1, P56
   Duan HX, 2012, PATTERN RECOGN LETT, V33, P677, DOI 10.1016/j.patrec.2011.12.012
   Duan HX, 2011, IEEE IMAGE PROC, P641, DOI 10.1109/ICIP.2011.6116633
   Duan Huixian, 2011, Journal of Computer Aided Design & Computer Graphics, V23, P891
   Fuqing Duan, 2010, 2010 IEEE International Conference on Systems, Man and Cybernetics (SMC 2010), P2088, DOI 10.1109/ICSMC.2010.5641708
   Geyer C, 2002, IEEE T PATTERN ANAL, V24, P687, DOI 10.1109/34.1000241
   Geyer C, 2001, INT J COMPUT VISION, V45, P223, DOI 10.1023/A:1013610201135
   Geyer C., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P398, DOI 10.1109/ICCV.1999.791248
   Habib A, 2006, PHOTOGRAMM REC, V21, P29, DOI 10.1111/j.1477-9730.2006.00352.x
   Hartley RI, 2005, IEEE I CONF COMP VIS, P1834
   Harvey JE, 2003, APPL OPTICS, V42, P1167, DOI 10.1364/AO.42.001167
   Maeda PY, 2005, SPIE ELECT IMAGING
   Mashita T, 2005, WORKSH OMNIDIRECTION
   Semple J., 1998, ALGEBRAIC PROJECTIVE
   Svoboda T, 1997, K33597147 CZECH TU C
   Vandeportaele B, 2006, INT C PATT RECOG, P647
   White N, 1994, INVARIANT METHODS DI, P93
   Wu FC, 2008, PATTERN RECOGN, V41, P3166, DOI 10.1016/j.patcog.2008.03.010
   Wu YH, 2014, COMPUT VIS IMAGE UND, V126, P11, DOI 10.1016/j.cviu.2014.05.001
   Xianghua Ying, 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P412, DOI 10.1109/IROS.2005.1545166
   Ying XH, 2004, IEEE T PATTERN ANAL, V26, P1260, DOI 10.1109/TPAMI.2004.79
NR 26
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 1117
EP 1130
DI 10.1007/s11042-018-6397-3
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500063
OA Bronze
DA 2024-07-18
ER

PT J
AU Wang, XH
   Dai, F
   Ma, YK
   Gao, K
   Zhang, YD
AF Wang, Xuehui
   Dai, Feng
   Ma, Yike
   Gao, Ke
   Zhang, Yong Dong
TI Scene-adaptive coded aperture imaging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computational imaging; Coded-aperture; Depth-from-defocus
ID DEPTH
AB Coded aperture imaging systems have recently shown great success in recovering scene depth and extending the depth-of-field. Tremendous efforts have been focused on designing good coded patterns. The ideal pattern, however, would have to serve two conflicting purposes: 1) it should be broadband to ensure robust deconvolution and 2) it should have sufficient zero-crossings for a high depth discrepancy. This paper presents a simple but effective scene-adaptive coded aperture solution to bridge this gap. We observe that natural scenes often exhibit a dominant edge direction that can be caused by structure, texture, shading, etc. We therefore apply depth-discriminative codes along the dominant direction and broadband codes along its orthogonal direction. To physically implement this scheme, we adopt a two-shot scheme. Firstly, we capture a scene image with a pinhole aperture and analyze image content to determine the dominant direction. Secondly, we apply the proposed coding scheme using the programmable Liquid Crystal on Silicon (LCoS). Experiments on a broad range of synthetic and real scenes show that our technique is able to combine advantages of the state-of-the-art patterns for recovering better quality depth map and all-focus images.
C1 [Wang, Xuehui; Dai, Feng; Ma, Yike; Gao, Ke; Zhang, Yong Dong] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
   [Wang, Xuehui] Chinese Acad Sci, Grad Univ, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Dai, F (corresponding author), Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
EM wangxuehui@ict.ac.cn; fdai@ict.ac.cn; ykma@ict.ac.cn; kegao@ict.ac.cn;
   zhyd@ict.ac.cn
RI Dai, Qionghai/ABD-5298-2021
OI Dai, Qionghai/0000-0001-7043-3061
CR [Anonymous], ICCV
   [Anonymous], ECCV
   Bando Y, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409087
   Ding Y, 2010, ECCV
   DOWSKI ER, 1995, APPL OPTICS, V34, P1859, DOI 10.1364/AO.34.001859
   GROSSMANN P, 1987, PATTERN RECOGN LETT, V5, P63, DOI 10.1016/0167-8655(87)90026-2
   HASINOFF SW, 2009, ICCV
   Hiura S, 1998, CVPR
   Krishnan D., 2009, P ADV NEURAL INFORM, V22, P1033
   Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521
   Mannami H, 2007, ICCV
   Nagahara Hajime., 2010, ECCV
   Raskar R, 2006, ACM T GRAPHIC, V25, P795, DOI 10.1145/1141911.1141957
   Takeda Yuichi, 2013, CVPR
   Veeraraghavan A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239520
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yuan L, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239452
   Zhou Changyin, 2009, ICCP
NR 18
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 697
EP 711
DI 10.1007/s11042-017-5520-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500039
DA 2024-07-18
ER

PT J
AU Yang, YY
   Tian, YH
   Huang, TJ
AF Yang, Yuanyuan
   Tian, Yonghong
   Huang, Tiejun
TI Multiscale video sequence matching for near-duplicate detection and
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Near-duplicate video detection; Video sequence matching; Multiscale
   matching; Constrained longest ascending matching subsequence;
   Bi-directional scanning
ID LOCALIZATION
AB As one of key technologies in content-based near-duplicate detection and video retrieval, video sequence matching can be used to judge whether two videos exist duplicate or near-duplicate segments or not. Despite a lot of research efforts devoted in recent years, how to precisely and efficiently perform sequence matching among videos (which may be subject to complex audio-visual transformations) from a large-scale database still remains a pretty challenging task. To address this problem, this paper proposes a multiscale video sequence matching (MS-VSM) method, which can gradually detect and locate the similar segments between videos from coarse to fine scales. At the coarse scale, it makes use of the Maximum Weight Matching (MWM) algorithm to rapidly select several candidate reference videos from the database for a given query. Then for each candidate video, its most similar segment with respect to the given query is obtained at the middle scale by the Constrained Longest Ascending Matching Subsequence (CLAMS) algorithm, and then can be used to judge whether that candidate exists near-duplicate or not. If so, the precise locations of the near-duplicate segments in both query and reference videos are determined at the fine scale by using bi-directional scanning to check the matching similarity at the segments' boundaries. As such, the MS-VSM method can achieve excellent near-duplicate detection accuracy and localization precision with a very high processing efficiency. Extensive experiments show that it outperforms several state-of-the-art methods remarkably on several benchmarks.
C1 [Yang, Yuanyuan] Beijing Univ Posts & Telecommun, Beijing, Peoples R China.
   [Tian, Yonghong] Peking Univ, Natl Engn Lab Video Technol, Beijing, Peoples R China.
   [Tian, Yonghong] Peking Univ, Cooperat Medianet Innovat Ctr, Sch Elect Engn & Comp Sci, Beijing, Peoples R China.
   [Huang, Tiejun] Peking Univ, Sch Elect Engn & Comp Sci, Beijing, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Peking University;
   Peking University; Peking University
RP Yang, YY (corresponding author), Beijing Univ Posts & Telecommun, Beijing, Peoples R China.
EM yyyang0518@126.com; yhtian@pku.edu.cn
RI yang, yuanyuan/HPG-2020-2023; Huang, Tiejun/D-6161-2011
FU National Key R&D Program of China [2017YFB1002401]; National Natural
   Science Foundation of China [U1611461, 61390515, 61425025]
FX This work is partially supported by grants from the National Key R&D
   Program of China under grant 2017YFB1002401, the National Natural
   Science Foundation of China under contract No. U1611461, No. 61390515,
   and No. 61425025.
CR [Anonymous], P 1 SIGMM WORKSH SOC
   [Anonymous], P 2 ACM INT C MULT R
   [Anonymous], 2009, P ACM INT C MULT, DOI DOI 10.1145/1631272.1631295
   Cai Y., 2012, P ACM INT C MULT RET, P16
   Chen T., 2011, P 19 ACM INT C MULT, P1173
   Chiu CY, 2014, IEEE T MULTIMEDIA, V16, P1952, DOI 10.1109/TMM.2014.2342668
   Chiu CY, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1671962.1671966
   Coskun B, 2006, IEEE T MULTIMEDIA, V8, P1190, DOI 10.1109/TMM.2006.884614
   Cui P, 2010, IEEE INT CON MULTI, P1236, DOI 10.1109/ICME.2010.5583815
   Diego F, 2013, IEEE T MULTIMEDIA, V15, P1377, DOI 10.1109/TMM.2013.2247390
   Dong W., 2008, PROCEEDING ACM MULTI, P179, DOI DOI 10.1145/1459359.1459384
   Douze M, 2010, IEEE T MULTIMEDIA, V12, P257, DOI 10.1109/TMM.2010.2046265
   Douze Matthijs, 2008, TREC VID RETR EV TRE
   GENGEMBRE N, 2008, P ACM INT C CONT BAS, P211
   Haitsma Jaap, 2012, P INT S MUS INF RETR, P107
   Huang TJ, 2010, COMPUTER, V43, P28, DOI 10.1109/MC.2010.356
   Huang Z, 2010, IEEE T MULTIMEDIA, V12, P386, DOI 10.1109/TMM.2010.2050737
   Kim C, 2005, IEEE T CIRC SYST VID, V15, P127
   Kim S, 2014, SIGNAL PROCESS-IMAGE, V29, P788, DOI 10.1016/j.image.2014.05.002
   Law-To J., 2007, Muscle-VCD-2007: a live benchmark for video copy detection
   Law-To Julien., 2007, P 6 ACM INT C IMAGE, P371
   Ligang Zheng, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2537, DOI 10.1109/ICIP.2011.6116179
   Lin J, 2017, IEEE T MULTIMEDIA, V19, P1968, DOI 10.1109/TMM.2017.2713410
   Liu B, 2011, IEEE MULTIMEDIA, V18, P22, DOI 10.1109/MMUL.2011.37
   Liu H, 2016, MULTIMEDIA TOOLS APP
   Liu H, 2013, IEEE T KNOWL DATA EN, V25, P1706, DOI 10.1109/TKDE.2012.92
   Liu JJ, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2501654.2501658
   Liu JJ, 2011, ACM T INFORM SYST, V29, DOI 10.1145/2037661.2037666
   Liu Y., 2010, Proc. ACM International Conference on Image and Video Re- trieval, P89, DOI DOI 10.1145/1816041.1816057
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Malekesmaeili M, 2009, EIGHTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS, P69, DOI 10.1109/ICMLA.2009.32
   Mou LT, 2013, ACM T MULTIM COMPUT, V10, DOI 10.1145/2542205.2542208
   Ngoc P, 2008, 2008 INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS, VOLS 1-4, P2038
   Peng YX, 2006, IEEE T CIRC SYST VID, V16, P612, DOI 10.1109/TCSVT.2006.873157
   Qian Mengren, 2014, P ICME 2014 WORKSH E
   Roopalakshmi R, 2013, SIGNAL PROCESS, V93, P2339, DOI 10.1016/j.sigpro.2012.06.004
   Shang L., 2010, Proceedings of the International Conference on Multimedia, P531
   Shen HT, 2009, IEEE T KNOWL DATA EN, V21, P321, DOI 10.1109/TKDE.2008.168
   Song JK, 2013, IEEE T MULTIMEDIA, V15, P1997, DOI 10.1109/TMM.2013.2271746
   Tian YH, 2013, IEEE MULTIMEDIA, V20, P72, DOI 10.1109/MMUL.2012.62
   Wei SK, 2011, IEEE T CIRC SYST VID, V21, P15, DOI 10.1109/TCSVT.2011.2105554
   Wu A. G., 2007, P ACM MM, P218
   Wu ZP, 2014, INT J MULTIMED INF R, V3, P1, DOI 10.1007/s13735-013-0049-1
   Yeh M.-C., 2009, Proceedings of the ACM International Conference on Image and Video Retrieval, P45
   Yeh MC, 2011, IEEE T MULTIMEDIA, V13, P320, DOI 10.1109/TMM.2010.2094999
   Zhang L, 2014, QUOTIENT SPACE BASED PROBLEM SOLVING: A THEORETICAL FOUNDATION OF GRANULAR COMPUTING, P1
   Zhou XM, 2012, IEEE T MULTIMEDIA, V14, P1220, DOI 10.1109/TMM.2012.2194481
   Zhou XM, 2012, VLDB J, V21, P489, DOI 10.1007/s00778-011-0255-5
   Zhou XM, 2009, IEEE T MULTIMEDIA, V11, P879, DOI 10.1109/TMM.2009.2021794
NR 50
TC 6
Z9 6
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 311
EP 336
DI 10.1007/s11042-018-5862-3
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500017
DA 2024-07-18
ER

PT J
AU Zhao, YB
AF Zhao, Yibo
TI Estimating critical path analysis on digital topology of the
   connectivity of pore media
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Permeability; Euler number; Percolation theory; Critical path analysis
ID POROUS-MEDIA; ELECTRICAL-CONDUCTIVITY; PERMEABILITY PREDICTION;
   HYDRAULIC CONDUCTIVITY; TRANSPORT-PROPERTIES; ROCK; RECONSTRUCTION;
   POROSITY; IMAGES; MODEL
AB The relationship between pore media microstructure and permeability has been a hot topic in the field of geosciences. However, there are still significant technical challenges in accurately estimating permeability, especially in spatially complex pore media. Here we introduce morphological of porous media, expressed by Euler-Poincare Characteristic (Euler Number) which is a key parameter in the digital topology that describes the connectivity of pore media. In this short communication, the connectivity function of porous media is established by Euler number and used to determine the critical pore size in the theory of percolation. Then the critical path analysis (CPA) and percolation theory are combined to study the relationship between the Euler number and the permeability of porous media. Using twelve digital core samples, the empirical formula and the theoretical estimations of CPA-based model (Friedman and Seaton, 1998) are compared respectively with the experimental measurement data. The results show that the permeability estimation under the Euler number factor model is more accurate than the CPA-basedmodel. Some possible sources of uncertainty are also discussed. The relationship between permeability and morphological (Euler Number) of porous media makes it possible to predict permeability of porous media accurately and reasonably.
C1 [Zhao, Yibo] Univ Elect Sci & Technol China, Sch Math Sci, Chengdu 611731, Sichuan, Peoples R China.
   [Zhao, Yibo] Shandong Womens Univ, Sch Data & Comp Sci, Jinan 250300, Shandong, Peoples R China.
C3 University of Electronic Science & Technology of China; Shandong Womens
   University
RP Zhao, YB (corresponding author), Univ Elect Sci & Technol China, Sch Math Sci, Chengdu 611731, Sichuan, Peoples R China.; Zhao, YB (corresponding author), Shandong Womens Univ, Sch Data & Comp Sci, Jinan 250300, Shandong, Peoples R China.
EM zhaoyb678@163.com
CR AMBEGAOKAR V, 1971, PHYS REV B-SOLID ST, V4, P2612, DOI 10.1103/PhysRevB.4.2612
   BANAVAR JR, 1987, PHYS REV LETT, V58, P1411, DOI 10.1103/PhysRevLett.58.1411
   Bauget F., 2005, P INT S SOC COR AN T
   Bauget F., 2005, SPE ANN TECHN C EXH, DOI [10.2118/95950-MS, DOI 10.2118/95950-MS]
   Bernabe Y, 1998, J GEOPHYS RES-SOL EA, V103, P513, DOI 10.1029/97JB02486
   Carman P.C., 1937, Trans. Inst. Chem. Eng., V15, P150, DOI DOI 10.1016/S0263-8762(97)80003-2
   Daigle H, 2016, ADV WATER RESOUR, V96, P43, DOI 10.1016/j.advwatres.2016.06.016
   Davudov D, 2018, INT J COAL GEOL, V187, P98, DOI 10.1016/j.coal.2018.01.008
   Dullien FA, 1992, POROUS MEDIA FLUID T
   Friedman SP, 1998, WATER RESOUR RES, V34, P1703, DOI 10.1029/98WR00939
   Ghanbarian B, 2017, ADV WATER RESOUR, V104, P105, DOI 10.1016/j.advwatres.2017.03.016
   Glover PWJ, 2006, GEOPHYSICS, V71, pF49, DOI 10.1190/1.2216930
   HALAMICKOVA P, 1995, CEMENT CONCRETE RES, V25, P790, DOI 10.1016/0008-8846(95)00069-O
   Hunt A., 2014, PERCOLATION THEORY F
   Hunt AG, 2002, ADV WATER RESOUR, V25, P129, DOI 10.1016/S0309-1708(01)00057-4
   Hunt AG, 2001, ADV WATER RESOUR, V24, P279, DOI 10.1016/S0309-1708(00)00058-0
   Hunt AG, 2009, LECT NOT PHYS
   Jiang Z, 2013, WATER RESOUR RES, V49, P5437, DOI 10.1002/wrcr.20304
   Jiang Z, 2012, TRANSPORT POROUS MED, V94, P571, DOI 10.1007/s11242-011-9792-z
   Jiang Z, 2007, WATER RESOUR RES, V43, DOI 10.1029/2006WR005780
   Jiang Z, 2011, CHARACTERISATION POR
   KATZ AJ, 1986, PHYS REV B, V34, P8179, DOI 10.1103/PhysRevB.34.8179
   KATZ AJ, 1987, J GEOPHYS RES-SOLID, V92, P599, DOI 10.1029/JB092iB01p00599
   Kendall W. S., 2013, Stochastic geometry and its applications
   Knackstedt M.A., 2006, ADV XRAY ANAL, V49, P92
   Koltermann CE, 1995, WATER RESOUR RES, V31, P3283, DOI 10.1029/95WR02020
   KONG TY, 1992, TOPOL APPL, V46, P219, DOI 10.1016/0166-8641(92)90016-S
   KONG TY, 1989, COMPUT VISION GRAPH, V48, P357, DOI 10.1016/0734-189X(89)90147-3
   Kozeny J., 1927, Klasse
   KWIECIEN MJ, 1990, J MICROSC-OXFORD, V159, P343, DOI 10.1111/j.1365-2818.1990.tb03039.x
   Lindquist WB, 2000, J GEOPHYS RES-SOL EA, V105, P21509, DOI 10.1029/2000JB900208
   Mecke K, 2005, J PHYS-CONDENS MAT, V17, pS503, DOI 10.1088/0953-8984/17/9/014
   MORROW NR, 1969, J SEDIMENT PETROL, V39, P312
   PATERSON MS, 1983, MECH MATER, V2, P345, DOI 10.1016/0167-6636(83)90025-X
   Pollak M., 1972, Journal of Non-Crystalline Solids, V11, P1, DOI 10.1016/0022-3093(72)90304-3
   Porter LB, 2013, GROUND WATER, V51, P92, DOI 10.1111/j.1745-6584.2012.00930.x
   Robins V, 2016, WATER RESOUR RES, V52, P315, DOI 10.1002/2015WR017937
   Saha PK, 1995, PATTERN RECOGN, V28, P1955, DOI 10.1016/0031-3203(95)00058-5
   Scholz C, 2012, PHYS REV LETT, V109, DOI 10.1103/PhysRevLett.109.264504
   Skaggs TH, 2011, ADV WATER RESOUR, V34, P1335, DOI 10.1016/j.advwatres.2011.06.010
   Stauffer D., 1992, INTRO PERCOLATION TH
   TIMUR A, 1968, GEOPHYSICS, V33, P584, DOI 10.1190/1.1439954
   TYLER SW, 1990, WATER RESOUR RES, V26, P1047, DOI 10.1029/WR026i005p01047
   Vogel HJ, 2010, COMPUT GEOSCI-UK, V36, P1236, DOI 10.1016/j.cageo.2010.03.007
   Vogel HJ, 2001, ADV WATER RESOUR, V24, P233, DOI 10.1016/S0309-1708(00)00055-5
   WALSH JB, 1984, J GEOPHYS RES, V89, P9425, DOI 10.1029/JB089iB11p09425
   Yu BM, 2002, INT J HEAT MASS TRAN, V45, P2983, DOI 10.1016/S0017-9310(02)00014-5
   ZHAO HQ, 1994, J COLLOID INTERF SCI, V162, P390, DOI 10.1006/jcis.1994.1053
NR 48
TC 3
Z9 3
U1 3
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 1165
EP 1180
DI 10.1007/s11042-018-6587-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500066
DA 2024-07-18
ER

PT J
AU Li, N
   Xia, Y
AF Li, Na
   Xia, Yong
TI Affective image classification via semi-supervised learning from web
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Affective image classification; Label propagate; Support vector machine;
   Adaboost; Content-based image retrieval
ID OBJECTIVE EVALUATION; RETRIEVAL; SEMANTICS; EMOTIONS
AB Affective image classification has drawn increasing research attentions in the affective computing and multimedia communities. Despite many solutions proposed in the literature, it remains a major challenge to bridge the semantic gap between visual features of images and their affective characteristics, partly due to the lack of adequate training samples, which can be largely ascribed to the all-consuming nature of affective image annotation. In this paper, we propose a novel affective image classification algorithm based on semi-supervised learning from web images (SSL-WI). This algorithm consists of four major steps, including color and texture feature extraction, baseline classifier construction, feature selection, and jointly using training images and retrieved web images to re-train the classifier. We have applied this algorithm, the baseline classifier that is not trained by web images, and two state-of-the-art algorithms to differentiating color images in a three-dimensional discrete emotional space. Our results suggest that, with the scheme of semi-supervised learning from web images, the proposed algorithm is able to produce more accurate affective image classification than other three approaches.
C1 [Li, Na; Xia, Yong] Northwestern Polytech Univ, Sch Comp Sci & Engn, Shaanxi Key Lab Speech & Image Informat Proc SAII, Xian 710072, Peoples R China.
   [Xia, Yong] Northwestern Polytech Univ, Sch Comp Sci & Engn, CMCC, Xian 710072, Peoples R China.
C3 Northwestern Polytechnical University; Northwestern Polytechnical
   University
RP Xia, Y (corresponding author), Northwestern Polytech Univ, Sch Comp Sci & Engn, Shaanxi Key Lab Speech & Image Informat Proc SAII, Xian 710072, Peoples R China.; Xia, Y (corresponding author), Northwestern Polytech Univ, Sch Comp Sci & Engn, CMCC, Xian 710072, Peoples R China.
EM yxia@nwpu.edu.cn
FU National Natural Science Foundation of China [61771397, 61471297]; Seed
   Foundation of Innovation and Creation for Graduate Students in
   Northwestern Polytechnical University [Z2016150]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61771397 and 61471297, and in part by
   the Seed Foundation of Innovation and Creation for Graduate Students in
   Northwestern Polytechnical University under Grants Z2016150.
CR [Anonymous], ART COLOR CHINESE VE
   [Anonymous], DESIGN FORM THE BASI
   [Anonymous], P INT C MULTIMEDIA M
   [Anonymous], JTC1SC29WG11N4063 IS
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI [10.1145/1899412.1899418, DOI 10.1145/1899412.1899418]
   [Anonymous], TEXT ISO IEC 15938 3
   [Anonymous], ACM MULTIMED
   Bleschke M, 2009, MIXDES 2009: PROCEEDINGS OF THE 16TH INTERNATIONAL CONFERENCE MIXED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, P635
   Bosse T, 2014, IEEE T AFFECT COMPUT, V5, P17, DOI 10.1109/T-AFFC.2013.30
   BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384
   Chen H, 2008, 2008 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND INFORMATION TECHNOLOGY, PROCEEDINGS, P365, DOI 10.1109/MMIT.2008.199
   Chen YY, 2015, IEEE T AFFECT COMPUT, V6, P298, DOI 10.1109/TAFFC.2014.2388370
   Cho SB, 2004, P IEEE, V92, P702, DOI 10.1109/JPROC.2004.825900
   Colombo C, 1999, IEEE MULTIMEDIA, V6, P38, DOI 10.1109/93.790610
   Cozman F.G., 2003, P 20 INT C MACHINE L, P99
   Dai DX, 2013, IEEE I CONF COMP VIS, P2072, DOI 10.1109/ICCV.2013.259
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Duan R, 2006, IEEE IMAGE PROC, P957, DOI 10.1109/ICIP.2006.312634
   Geusebroek Jan -Mark, 2006, BMVC, P1029
   Guangjian Tian, 2008, 5th International Conference on Information Technology and Applications in Biomedicine (ITAB 2008) in conjunction with 2nd International Symposium & Summer School on Biomedical and Health Engineering (IS3BHE 2008), P51, DOI 10.1109/ITAB.2008.4570523
   Houle ME, 2013, ACM T MULTIM COMPUT, V10, DOI 10.1145/2487736
   Jijun Wang, 2010, Proceedings of the 2010 International Conference of Information Science and Management Engineering. ISME 2010, P100, DOI 10.1109/ISME.2010.154
   Joshi D, 2011, IEEE SIGNAL PROC MAG, V28, P94, DOI 10.1109/MSP.2011.941851
   KAWAMOTO N, 1993, COLOR RES APPL, V18, P260, DOI 10.1002/col.5080180409
   Kun H, 2008, ISISE 2008: INTERNATIONAL SYMPOSIUM ON INFORMATION SCIENCE AND ENGINEERING, VOL 2, P183, DOI 10.1109/ISISE.2008.142
   Le THN, 2013, IEEE T IMAGE PROCESS, V22, P3097, DOI 10.1109/TIP.2013.2259835
   Lee J, 2011, IEEE T MULTIMEDIA, V13, P1031, DOI 10.1109/TMM.2011.2158530
   Lee PM, 2014, 2014 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC), P1690, DOI 10.1109/CEC.2014.6900620
   Li HF, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P612
   Li HF, 2008, FBIE: 2008 INTERNATIONAL SEMINAR ON FUTURE BIOMEDICAL INFORMATION ENGINEERING, PROCEEDINGS, P148, DOI 10.1109/FBIE.2008.99
   Li HF, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION WORKSHOP: IITA 2008 WORKSHOPS, PROCEEDINGS, P455, DOI 10.1109/IITA.Workshops.2008.200
   Li N, 2015, INT CONF AFFECT, P84, DOI 10.1109/ACII.2015.7344555
   Li YF, 2015, IEEE T PATTERN ANAL, V37, P175, DOI 10.1109/TPAMI.2014.2299812
   Liu W, 2011, PROC CVPR IEEE, P849, DOI 10.1109/CVPR.2011.5995315
   Liu Z, 2012, 2011 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT), VOLS 1-4, P23
   Merdassi H, 2014, 2014 INTERNATIONAL WORKSHOP ON COMPUTATIONAL INTELLIGENCE FOR MULTIMEDIA UNDERSTANDING (IWCIM)
   Ou LC, 2004, COLOR RES APPL, V29, P232, DOI 10.1002/col.20010
   Park TS, 2015, IEEE T AFFECT COMPUT, V6, P272, DOI 10.1109/TAFFC.2015.2400151
   SOEN T, 1987, COLOR RES APPL, V12, P187, DOI 10.1002/col.5080120406
   Solli M, 2011, COLOR RES APPL, V36, P210, DOI 10.1002/col.20604
   Song XD, 2014, IEEE IMAGE PROC, P4802, DOI 10.1109/ICIP.2014.7025973
   Tang JH, 2012, IEEE T IMAGE PROCESS, V21, P2354, DOI 10.1109/TIP.2011.2180916
   Tkalcic M, 2013, IEEE T MULTIMEDIA, V15, P391, DOI 10.1109/TMM.2012.2229970
   Wang Q, 2018, PATTERN RECOGN, V75, P272, DOI 10.1016/j.patcog.2017.03.030
   Wang Q, 2017, IEEE GEOSCI REMOTE S, V14, P2077, DOI 10.1109/LGRS.2017.2751559
   Wang Q, 2017, IEEE T VEH TECHNOL, V66, P8001, DOI 10.1109/TVT.2017.2685526
   Wang SF, 2005, LECT NOTES COMPUT SC, V3784, P490
   Wang WN, 2008, IEEE IMAGE PROC, P117, DOI 10.1109/ICIP.2008.4711705
   Wang WN, 2005, Proceedings of 2005 International Conference on Machine Learning and Cybernetics, Vols 1-9, P4571
   Wang WN, 2004, IEEE SYS MAN CYBERN, P6407
   Wang XH, 2013, IEEE IMAGE PROC, P3230, DOI 10.1109/ICIP.2013.6738665
   Wei-Ning W, 2006, IEEE SYS MAN CYBERN, P3534, DOI 10.1109/ICSMC.2006.384667
   Xie WX, 2013, IEEE IMAGE PROC, P4307, DOI 10.1109/ICIP.2013.6738887
   Yannakakis GN, 2014, IEEE T AFFECT COMPUT, V5, P1, DOI 10.1109/TAFFC.2014.2313816
   Yanulevskaya V, 2008, IEEE IMAGE PROC, P101, DOI 10.1109/ICIP.2008.4711701
   Zhang XL, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 3, PROCEEDINGS, P221, DOI 10.1109/ICNC.2008.841
   Zhao Juanjuan, 2012, 2012 International Conference on Computing, Measurement, Control and Sensor Network (CMCS), P167, DOI 10.1109/CMCSN.2012.43
   Zhao MB, 2015, IEEE SIGNAL PROC LET, V22, P1666, DOI 10.1109/LSP.2015.2421971
   Zhao S, 2016, NEUROCOMPUTING, V214, P86, DOI 10.1016/j.neucom.2016.05.072
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P47, DOI 10.1145/2647868.2654930
   Zhao Yanhong, 2009, 2009 International Conference on Test and Measurement (ICTM 2009), P127, DOI 10.1109/ICTM.2009.5412982
   Zhu SH, 2016, NEUROCOMPUTING, V208, P136, DOI 10.1016/j.neucom.2016.02.072
NR 62
TC 2
Z9 2
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30633
EP 30650
DI 10.1007/s11042-018-6131-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600023
DA 2024-07-18
ER

PT J
AU Grogna, D
   Stojmenova, K
   Jakus, G
   Barreda-Angeles, M
   Verly, JG
   Sodnik, J
AF Grogna, David
   Stojmenova, Kristina
   Jakus, Grega
   Barreda-Angeles, Miguel
   Verly, Jacques G.
   Sodnik, Jaka
TI The impact of drowsiness on in-vehicle human-machine interaction with
   head-up and head-down displays
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Drowsiness; Fatigue; HUD; HDD; Driving performance; EEG
ID DRIVING PERFORMANCE; SLEEP-DEPRIVATION; DRIVER SLEEPINESS; CAR DRIVERS;
   SYMPTOMS; FATIGUE; DURATION; ROAD
AB Various studies show that drowsiness reduces driver alertness and can significantly affect driver performance. In this paper, we investigate the effect of drowsiness on the interaction with the in-vehicle infotainment system (IVIS) while driving. The motivation was to investigate whether a specific type of user interface can provide better performance and lower distraction when the driver is drowsy. The users were asked to navigate a vehicle in a driving simulator and simultaneously perform a set of tasks of varying complexity first when they were rested and alert and then when they were drowsy, after 7 h without sleep. A hierarchical, list-based menu was presented using a stereoscopic head-up display (HUD) and a head-down display (HDD). Based on the results, no general and statistically significant connection was found between drowsiness and driving performance. Surprisingly, the secondary task performance was even better when participants were drowsy, which was evident from the faster task completion times. This could be attributed to extra efforts invested in executing tasks as a result of the participants being aware of their drowsiness. However, when comparing the participants' performance using HUD and HDD displays, the results showed that using HUD introduces less mental fatigue than using HDD but only in rested and alert condition. No significant difference between the displays was found in the drowsy state.
C1 [Grogna, David; Verly, Jacques G.] Univ Liege, Dept Elect Engn & Comp Sci, Quartier Polytech 1,Allee Decouverte 10, B-4000 Liege, Belgium.
   [Stojmenova, Kristina; Jakus, Grega; Sodnik, Jaka] Univ Ljubljana, Fac Elect Engn, Trzaska Cesta 25, Ljubljana 1000, Slovenia.
   [Barreda-Angeles, Miguel] Eurecat Technol Ctr Catalonia, Av Diagonal 177,Planta 9, Barcelona 08018, Spain.
C3 University of Liege; University of Ljubljana
RP Grogna, D (corresponding author), Univ Liege, Dept Elect Engn & Comp Sci, Quartier Polytech 1,Allee Decouverte 10, B-4000 Liege, Belgium.
EM dgrogna@ulg.ac.be; kristina.stojmenova@fe.uni-lj.si;
   grega.jakus@fe.uni-lj.si; miguel.barreda@eurecat.org;
   jacques.verly@ulg.ac.be; jaka.sodnik@fe.uni-lj.si
RI Barreda-Ángeles, Miguel/AAX-4359-2020
OI Barreda-Ángeles, Miguel/0000-0002-5056-7633; Stojmenova,
   Kristina/0000-0001-6584-7147
CR Ablassmeier M, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P2250
   Borghini G, 2014, NEUROSCI BIOBEHAV R, V44, P58, DOI 10.1016/j.neubiorev.2012.10.003
   Boyle LN, 2008, TRANSPORT RES F-TRAF, V11, P126, DOI 10.1016/j.trf.2007.08.001
   BUCK L, 1966, PSYCHOL BULL, V65, P291, DOI 10.1037/h0023207
   Cao T, 2014, BIOMED ENG ONLINE, V13, DOI 10.1186/1475-925X-13-28
   CARSKADON MA, 1986, SLEEP, V9, P519, DOI 10.1093/sleep/9.4.519
   Charissis V, 2010, COGN TECHNOL WORK, V12, P41, DOI 10.1007/s10111-008-0117-0
   Connor J, 2002, BRIT MED J, V324, P1125, DOI 10.1136/bmj.324.7346.1125
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   DEWAARD D, 1991, ACCIDENT ANAL PREV, V23, P297, DOI 10.1016/0001-4575(91)90007-R
   Doshi A, 2009, IEEE T SYST MAN CY B, V39, P85, DOI 10.1109/TSMCB.2008.923527
   Eoh HJ, 2005, INT J IND ERGONOM, V35, P307, DOI 10.1016/j.ergon.2004.09.006
   Ferraz M, 2000, US Patent, Patent No. [6,087,941, 6087941]
   Gish KW, 1995, 145402LR NHTSA
   HART S G, 1988, P139
   Horne JA, 1995, J SLEEP RES, V4, P23, DOI 10.1111/j.1365-2869.1995.tb00222.x
   Ingre M, 2006, J SLEEP RES, V15, P47, DOI 10.1111/j.1365-2869.2006.00504.x
   Jakus G, 2015, APPL ERGON, V46, P184, DOI 10.1016/j.apergo.2014.08.008
   JOHNS MW, 1991, SLEEP, V14, P540, DOI 10.1093/sleep/14.6.540
   Kaptein NA, 1994, 1994B20 TNOTM HFRI
   Kim H., 2013, P 5 INT C AUT US INT, P224
   Lal SKL, 2001, BIOL PSYCHOL, V55, P173, DOI 10.1016/S0301-0511(00)00085-5
   Liu YC, 2004, INT J HUM-COMPUT ST, V61, P679, DOI 10.1016/j.ijhcs.2004.06.002
   Liu YC, 2009, SAFETY SCI, V47, P1083, DOI 10.1016/j.ssci.2008.11.009
   Lyznicki JM, 1998, JAMA-J AM MED ASSOC, V279, P1908, DOI 10.1001/jama.279.23.1908
   National Center for Statistics and Analysis, 2011, 811449 DOT HS NAT HI
   Nordbakke S, 2007, TRANSPORT RES F-TRAF, V10, P1, DOI 10.1016/j.trf.2006.03.003
   Otmani S, 2005, PHYSIOL BEHAV, V84, P715, DOI 10.1016/j.physbeh.2005.02.021
   Park HS, 2013, ETRI J, V35, P1038, DOI 10.4218/etrij.13.2013.0041
   Poitschke T, 2008, PROCEEDINGS OF THE EYE TRACKING RESEARCH AND APPLICATIONS SYMPOSIUM (ETRA 2008), P119, DOI 10.1145/1344471.1344502
   Rimini-Doering M., 2005, P 3 INT DRIVING S HU, P88
   Risser MR, 1999, P ANN C ASS, P317
   Shahid A., 2011, KAROLINSKA SLEEPINES, P209, DOI 10.1007/9781-44199893-4_47
   Summala H, 1999, ERGONOMICS, V42, P798, DOI 10.1080/001401399185298
   Tefft BC., 2014, Prevalence of motor vehicle crashes involving drowsy drivers, United States, 2009-2013
   Thiffault P, 2003, ACCIDENT ANAL PREV, V35, P381, DOI 10.1016/S0001-4575(02)00014-3
   Tran C., 2013, P 5 INT C AUT US INT, P300, DOI [DOI 10.1145/2516540.2516581, 10.1145/2516540.2516581]
   van den Berg J, 2006, TRANSPORT RES F-TRAF, V9, P207, DOI 10.1016/j.trf.2006.01.001
   Vurall E, 2007, LECT NOTES COMPUT SC, V4796, P6
   Warwick B, 2015, IEEE INT CONF MOB, P585, DOI 10.1109/MASS.2015.22
NR 40
TC 1
Z9 1
U1 1
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 27807
EP 27827
DI 10.1007/s11042-018-5966-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500004
DA 2024-07-18
ER

PT J
AU Liu, X
   Li, A
   Du, JX
   Peng, SJ
   Fan, WT
AF Liu, Xin
   Li, An
   Du, Ji-Xiang
   Peng, Shu-Juan
   Fan, Wentao
TI Efficient cross-modal retrieval via flexible supervised collective
   matrix factorization hashing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-modal retrieval; Flexible collective matrix factorization; Latent
   semantic space; Joint graph regularization
ID RECOGNITION
AB Cross-modal retrieval has recently drawn much attention in multimedia analysis, and it is still a challenging topic mainly attributes to its heterogeneous nature. In this paper, we propose a flexible supervised collective matrix factorization hashing (FS-CMFH) to efficient cross-modal retrieval. First, we exploit a flexible collective matrix factorization framework to jointly learn the individual latent space of similar semantic with respected to each modality. Meanwhile, the label consistency across different modalities is simultaneously exploited to preserve both intra-modal and inter-modal semantics within these similar latent semantic spaces. Accordingly, these two ingredients are formulated as a joint graph regularization term in an overall objective function, through which the similar hash codes of different modalities in an instance can be discriminatively obtained to flexibly characterize such instance. As a result, these derived hash codes incorporating higher discrimination power are able to improve the cross-modal searching accuracy significantly. The extensive experiments tested on three popular benchmark datasets show that the proposed approach performs favorably compared to the state-of-the-art competing approaches.
C1 [Liu, Xin; Li, An; Du, Ji-Xiang] Huaqiao Univ, Dept Comp Sci & Technol, Jimei Rd 668, Xiamen, Fujian, Peoples R China.
   [Peng, Shu-Juan; Fan, Wentao] Key Lab Pattern Recognit & Comp Vis, Jimei Rd 668, Xiamen, Fujian, Peoples R China.
C3 Huaqiao University
RP Liu, X (corresponding author), Huaqiao Univ, Dept Comp Sci & Technol, Jimei Rd 668, Xiamen, Fujian, Peoples R China.
EM xliu@hqu.edu.cn
RI Fan, Wentao/AAO-9378-2020; Liu, Xin/JVN-3263-2024; Fan,
   Wentao/JUU-7543-2023
OI Fan, Wentao/0000-0001-6694-7289; Liu, Xin/0000-0002-0011-6260; Fan,
   Wentao/0000-0001-6694-7289
FU National Science Foundation of China [61673185, 61572205, 61673186];
   National Science Foundation of Fujian Province [2017J01112]; Promotion
   Program for Young and Middle-aged Teacher in Science and Technology
   Research [ZQN-PY309]
FX The work was supported by the National Science Foundation of China under
   Grants 61673185, 61572205 and 61673186, National Science Foundation of
   Fujian Province (No. 2017J01112), Promotion Program for Young and
   Middle-aged Teacher in Science and Technology Research (No. ZQN-PY309).
CR [Anonymous], 2012, NEURIPS
   [Anonymous], 2008, Proceedings of the 21st International Conference on Neural Information Processing Systems
   [Anonymous], 2013, IEEE T PATTERN ANAL
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247923
   Bronstein MM, 2010, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2010.5539928
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Ding GG, 2016, IEEE T IMAGE PROCESS, V25, P5427, DOI 10.1109/TIP.2016.2607421
   Ding GG, 2014, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2014.267
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Kim S, 2012, LECT NOTES COMPUT SC, V7576, P538, DOI 10.1007/978-3-642-33715-4_39
   Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037
   Lee SG, 2011, LINEAR ALGEBRA APPL, V435, P2097, DOI 10.1016/j.laa.2010.09.034
   Li AN, 2009, PROC CVPR IEEE, P605, DOI 10.1109/CVPRW.2009.5206659
   Lin ZJ, 2015, PROC CVPR IEEE, P3864, DOI 10.1109/CVPR.2015.7299011
   Pauleve L, 2010, PATTERN RECOGN LETT, V31, P1348, DOI 10.1016/j.patrec.2010.04.004
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Sharma A, 2011, PROC CVPR IEEE, P593, DOI 10.1109/CVPR.2011.5995350
   Singh A. P., 2008, P 14 ACM SIGKDD INT, P650
   Song J., 2013, P ACM SIGMOD INT C M, P785, DOI DOI 10.1145/2463676.2465274
   Tang J, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2564638
   Wu BT, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3946
   Xie L, 2016, MULTIMED TOOLS APPL, V75, P9185, DOI 10.1007/s11042-016-3432-0
   Xu C, 2015, IEEE T PATTERN ANAL, V37, P2531, DOI 10.1109/TPAMI.2015.2417578
   You XG, 2015, IEEE T NEUR NET LEAR, V26, P2760, DOI 10.1109/TNNLS.2015.2393886
   You XG, 2014, IEEE T CIRC SYST VID, V24, P1265, DOI 10.1109/TCSVT.2014.2306031
   Yu Z, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P395, DOI 10.1145/2600428.2609563
   Zhang D, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P225
   Zhang DQ, 2014, AAAI CONF ARTIF INTE, P2177
   Zhou JL, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P415
NR 31
TC 17
Z9 19
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28665
EP 28683
DI 10.1007/s11042-018-6006-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500036
DA 2024-07-18
ER

PT J
AU Alajarmeh, A
   Zaidan, AA
AF Alajarmeh, Ahmad
   Zaidan, A. A.
TI A real-time framework for video Dehazing using bounded transmission and
   controlled Gaussian filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single-image dehazing; Real-time video dehazing; Atmospheric light
   scattering model; Bounded transmission; Image integrals; Airlight
   estimation
ID IMAGE
AB The haze phenomenon exerts a degrading effect that decreases contrast and causes color shifts in outdoor images and videos. The presence of haze in outdoor images and videos is bothersome, unpleasant, and occasionally, even dangerous. Atmospheric light scattering (ALS) model is widely used to restore hazy images. In this model, two unknown parameters should be estimated: airlight and scene transmission. The quality of dehazed images and video frames considerably depends on those two parameters as well as on the speed and accuracy of the refinement process of the approximated scene transmission, this refinement is necessary to ensure spatial coherency of the output dehazed video. Spatial coherency should be accounted for in order to eliminate flickering artifacts usually noticed when extending single-image dehazing methods to the video scenario. Classic methods typically require high computation capacity in order to dehaze videos in real time. However, when the driver assistance context is considered, these approaches are inappropriate due to the limited resources mobile environments usually have. To address this issue, this study proposes a framework for real-time video dehazing. This framework consists of two stages: single-image dehazing using the bounded transmission (BT) method, which is utilized to dehaze single video frame in real time with high accuracy; and transmission refinement stage using a filter we call controlled Gaussian filter (CGF), which is proposed for the linear and simplified refinement of the scene transmission. To evaluate the proposed framework, three image datasets in addition to two video streams are employed. Experimental results show that the single-image stage in the proposed framework is at least seven times faster than existing methods. In addition, the analysis of variance (ANOVA) test proves that the quality of dehazed images in this stage is statistically similar to or better than those obtained using existing methods. Also, experiments show that the video stage in the proposed framework is capable of real-time video dehazing with better quality than the existing methods.
C1 [Alajarmeh, Ahmad] USIM, Fac Sci & Technol, Negeri Sembilan 71800, Malaysia.
   [Zaidan, A. A.] Univ Pendidikan Sultan Idris Tanjong Malim, Fac Arts Comp & Creat Ind, Dept Comp, Perak, Malaysia.
C3 Universiti Sains Islam Malaysia
RP Zaidan, AA (corresponding author), Univ Pendidikan Sultan Idris Tanjong Malim, Fac Arts Comp & Creat Ind, Dept Comp, Perak, Malaysia.
EM aws.alaa@gmail.com
RI Albahri,, A. S./F-7289-2010
OI Alajarmeh, Ahmad/0009-0000-7042-5491
CR [Anonymous], 2014 WORLD S COMP AP
   [Anonymous], 1952, VISION ATMOSPHERE
   [Anonymous], 10821 ITU BT
   [Anonymous], 2012, ITUR Recommendation BT. 500-13
   [Anonymous], REDUCED VISIBILITY D
   [Anonymous], P WORLD C ENG
   [Anonymous], INT J COMPUT VIS
   [Anonymous], 2011 I E COMP SOC C
   [Anonymous], GEOPHYSICS
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Gibson KB, 2012, IEEE T IMAGE PROCESS, V21, P662, DOI 10.1109/TIP.2011.2166968
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He K., 2015, Proceedings of the 1st ACM SIGCOMM Symposium on Software Defined Networking Research, P25
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hu YT, 2016, IEEE T IMAGE PROCESS, V25, P4091, DOI 10.1109/TIP.2016.2580942
   Jisha J, 2008, 7 IEEE INT C CYBEMET, P1
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   Koschmieder H., 1924, PHYS FREIEN ATM, P171
   Lee S, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0104-y
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Shiau YH, 2013, IEEE T CIRC SYST VID, V23, P1369, DOI 10.1109/TCSVT.2013.2243650
   Tan R, 2008, IEEE C COMPUTER VISI, P1
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Tarel JP, 2010, IEEE INT VEH SYM, P478, DOI 10.1109/IVS.2010.5548128
   Thien Phan, 2012, Proceedings of the 2012 IEEE Southwest Symposium on Image Analysis & Interpretation (SSIAI 2012), P81, DOI 10.1109/SSIAI.2012.6202458
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   Wang NN, 2018, IEEE T CIRC SYST VID, V28, P2154, DOI 10.1109/TCSVT.2017.2709465
   Wang NN, 2017, IEEE T IMAGE PROCESS, V26, P1264, DOI 10.1109/TIP.2017.2651375
   Winnemoeller H, 2012, COMPUT GRAPH-UK, V36, P740, DOI 10.1016/j.cag.2012.03.004
   Zhang Q, 2014, PROC CVPR IEEE, P2830, DOI 10.1109/CVPR.2014.362
NR 33
TC 6
Z9 6
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26315
EP 26350
DI 10.1007/s11042-018-5861-4
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500007
DA 2024-07-18
ER

PT J
AU Becheikh, R
   Omrani, T
   Rhouma, R
   Belghith, S
AF Becheikh, Rabei
   Omrani, Tasnime
   Rhouma, Rhouma
   Belghith, Safya
TI RISC: a robust image symmetric cryptosystem
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image cryptosystem; Outer-phase; Inner-phase; Real time transmission
ID ENCRYPTION SCHEME; CHAOTIC MAPS
AB In recent years, AES is known as the excellent choice between the existing symmetric cryptosystems to encrypt binary or text data. However, this standard encryption algorithm is unsuitable for images regarding the particular features of these kinds of data such as high correlation, high redundancy, and voluminosity. Based on this fact, we have designed a new cryptosystem taking into account the aforementioned characteristics which provides high performance and security level. Actually, the cryposystem adopts a new structure named Outer-Inner structure. This new structure consists of two phases: Outer phase and Inner phase. In the former phase, the image is treated as a single block. The purpose of this phase is to address the correlation and the redundancy issue of images. In order to ensure the efficiency and to avoid the problem of treating an image as a single block where several image encryption algorithms suffer from it, this phase only involves lightweight operations. In the later phase the image is treated as a set of fixed blocks. The aim of this phase is to address the voluminosity issue. In fact, during this phase each block can be encrypted independently through an iterative function. The experiment results show that 7 rounds are sufficient to reach an acceptable security level.
C1 [Becheikh, Rabei; Omrani, Tasnime; Rhouma, Rhouma; Belghith, Safya] Univ Tunis El Manar, ENIT, RISC Lab, Tunis, Tunisia.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT)
RP Omrani, T (corresponding author), Univ Tunis El Manar, ENIT, RISC Lab, Tunis, Tunisia.
EM tasnim.omrani@gmail.com
RI Rhouma, Rhouma/B-8018-2010
OI Rhouma, Rhouma/0000-0002-5715-4110; Belghith, Safya/0000-0001-7408-7848
CR Abdullah Hikmat N., 2017, 2017 International Conference on Current Research in Computer Science and Information Technology (ICCIT), P121, DOI 10.1109/CRCSIT.2017.7965545
   Bao JH, 2012, NONLINEAR DYNAM, V70, P1365, DOI 10.1007/s11071-012-0539-3
   Belazi A, 2015, INT WIREL COMMUN, P611, DOI 10.1109/IWCMC.2015.7289153
   Cheng PG, 2015, NONLINEAR DYNAM, V79, P2121, DOI 10.1007/s11071-014-1798-y
   Feldhofer M., 2005, IEE Proceedings-Information Security, V152, P13, DOI 10.1049/ip-ifs:20055006
   Feldhofer M., 2004, STRONG AUTHENTICATIO, P357
   François M, 2012, SIGNAL PROCESS-IMAGE, V27, P249, DOI 10.1016/j.image.2011.11.003
   Hämäläinen P, 2006, DSD 2006: 9TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN: ARCHITECTURES, METHODS AND TOOLS, PROCEEDINGS, P577
   Mandal MK, 2014, SECUR COMMUN NETW, V7, P2145, DOI 10.1002/sec.927
   Sam IS, 2012, NONLINEAR DYNAM, V69, P1995, DOI 10.1007/s11071-012-0402-6
   Sam IS, 2012, MULTIMED TOOLS APPL, V56, P315, DOI 10.1007/s11042-010-0652-6
   Song CY, 2015, ENTROPY-SWITZ, V17, P6954, DOI 10.3390/e17106954
   Wang XY, 2010, COMMUN NONLINEAR SCI, V15, P2479, DOI 10.1016/j.cnsns.2009.10.001
   Xu L, 2017, OPT LASER ENG, V91, P41, DOI 10.1016/j.optlaseng.2016.10.012
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Ye GD, 2012, NONLINEAR DYNAM, V69, P2079, DOI 10.1007/s11071-012-0409-z
NR 16
TC 6
Z9 6
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 24615
EP 24642
DI 10.1007/s11042-017-5575-z
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400003
DA 2024-07-18
ER

PT J
AU Momennezhad, A
AF Momennezhad, Ali
TI EEG-based emotion recognition utilizing wavelet coefficients
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion recognition; EEG; BCI; Detail Coefficients; Approximation
   coefficients; MAHNOB-HCI; LIBSVM
AB This paper focuses on EEG (Electroencephalography) signals as a robust method for emotion recognition. In emotion recognition, researchers usually use features such as eye pupil diameter, facial features, EEG signals and physiological signals like: respiration amplitude, heart rate, skin temperature, blood volume pulse, respiration rate etc. In this paper we use just EEG signals as we believe that a human being may suffer from some physical disabilities and impairments like visual disorders, motor impairment or some other common disorders. So, the use of EEG signal, in some aspects, can be more useful and utilizable in real life. In this paper, we use a combination of some existent techniques on this theme, such as wavelet coefficients and an 8-number electrode configuration, which makes our approach really convenient and comfortable to use, and some other methods that may seem minor; But the way we employ and combine them, make a novel, productive, high efficient and reliable algorithm that highly can help people with some special disorders. To have a brief overview of the results of our work: the average Arousal F-Score and Valence F-Score for our algorithm are, respectively, 0.73 and 0.77. These values for a corresponding work are, 0.60 and 0.50, respectively. As it is seen the results have improved by 0.13 and 0.27. The results of our EEG-based algorithm are even better than the fusion of facial and EEG signals or physiological signals presented in the corresponding works. Beside this better performance, the ease and comfort that our method provides for users, is far beyond description.
C1 [Momennezhad, Ali] Sahand Univ Technol, Sahand, Tabriz, Iran.
C3 Sahand University of Technology
RP Momennezhad, A (corresponding author), Sahand Univ Technol, Sahand, Tabriz, Iran.
EM a_momennezhad@sut.ac.ir
RI Momennezhad, Ali/AAK-6515-2020
OI Momennezhad, Ali/0000-0002-8046-4387
CR [Anonymous], INT J INTELLIGENT CO
   [Anonymous], THESIS
   ERWIN RJ, 1992, PSYCHIAT RES, V42, P231, DOI 10.1016/0165-1781(92)90115-J
   Fontaine JRJ, 2007, PSYCHOL SCI, V18, P1050, DOI 10.1111/j.1467-9280.2007.02024.x
   Graimann B, 2010, FRONT COLLECT, P1, DOI 10.1007/978-3-642-02091-9_1
   Gray E.K., 2007, HDB EMOTION ELICITAT
   Hoffmann U, 2008, J NEUROSCI METH, V167, P115, DOI 10.1016/j.jneumeth.2007.03.005
   Hoffmann Ulrich., 2007, BAYESIAN MACHINE LEA
   Isbister K, 2007, INT J HUM-COMPUT ST, V65, P273, DOI 10.1016/j.ijhcs.2006.11.004
   Khosrowabadi R, 2014, IEEE T NEUR NET LEAR, V25, P609, DOI 10.1109/TNNLS.2013.2280271
   Lantz G, 2003, CLIN NEUROPHYSIOL, V114, P63, DOI 10.1016/S1388-2457(02)00337-1
   Lee G, 2014, NEUROCOMPUTING, V144, P560, DOI 10.1016/j.neucom.2014.04.008
   Lin Y.-P., 2007, TENCON 20072007 IEEE, P1
   Lin YP, 2010, IEEE T BIO-MED ENG, V57, P1798, DOI 10.1109/TBME.2010.2048568
   Mitra S., 2004, P 2004 IEEE COMPUTER, V2, pII
   Mohammadi Z, 2017, NEURAL COMPUT APPL, V28, P1985, DOI 10.1007/s00521-015-2149-8
   Momennezhad A., 2014, Applied Medical Informatics, V34, P23
   Nguyen TT, 2017, J INTELL FUZZY SYST, V32, P1437, DOI 10.3233/JIFS-169140
   Petrantonakis PC, 2012, IEEE T SIGNAL PROCES, V60, P2604, DOI 10.1109/TSP.2012.2187647
   Petrantonakis PC, 2011, IEEE T INF TECHNOL B, V15, P737, DOI 10.1109/TITB.2011.2157933
   RUSSELL JA, 1977, J RES PERS, V11, P273, DOI 10.1016/0092-6566(77)90037-X
   RUSSELL JA, 1991, PSYCHOL BULL, V110, P426, DOI 10.1037/0033-2909.110.3.426
   SCHERER KR, 1993, COGNITION EMOTION, V7, P325, DOI 10.1080/02699939308409192
   Soleymani M, 2016, IEEE T AFFECT COMPUT, V7, P17, DOI 10.1109/TAFFC.2015.2436926
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P211, DOI 10.1109/T-AFFC.2011.37
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P42, DOI 10.1109/T-AFFC.2011.25
   Subramanian R, 2018, IEEE T AFFECT COMPUT, V9, P147, DOI 10.1109/TAFFC.2016.2625250
   Wang SH, 2017, LECT NOTES COMPUT SC, V10559, P203, DOI 10.1007/978-3-319-67777-4_18
   Wang YJ, 2008, IEEE ENG MED BIOL, V27, P64, DOI 10.1109/MEMB.2008.923958
   Yoon HJ, 2013, COMPUT BIOL MED, V43, P2230, DOI 10.1016/j.compbiomed.2013.10.017
   Zheng Z., 2004, ACM Sigkdd Explorations Newsletter, V6, P80, DOI DOI 10.1145/1007730.1007741
NR 31
TC 15
Z9 15
U1 0
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 27089
EP 27106
DI 10.1007/s11042-018-5906-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500039
DA 2024-07-18
ER

PT J
AU Terchi, Y
   Bouguezel, S
AF Terchi, Younes
   Bouguezel, Saad
TI A blind audio watermarking technique based on a parametric quantization
   index modulation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind audio watermarking; Method of Lagrange multipliers; Particle swarm
   optimization; Quantization index modulation
ID PARTICLE SWARM; ROBUST; SCHEME; SECURE
AB In this paper, we propose an efficient transform-based blind audio watermarking technique by introducing a parametric quantization index modulation (QIM). Theoretical expressions for the signal to watermark ratio and probability of error are derived and then used in an optimization technique based on the Lagrange multipliers method to find the optimal values for the parameters of the parametric QIM that ensure the imperceptibility while maximizing the robustness under an additive white Gaussian noise (AWGN) attack. Moreover, a fast scheme for the implementation of the proposed watermarking technique is developed and an efficient procedure is suggested to find the interval for the best selection of the watermark embedding positions that provide a good trade-off between the effects of high and low pass filtering attacks. The parameters of the resulting optimal parametric QIM coupled with the embedding positions constitute a highly robust secret key for the proposed watermarking technique. We also carry out several experiments to show the usefulness of the theoretical analysis presented in the paper and compare the proposed technique with other existing QIM-based watermarking techniques by considering known attacks such as AWGN, re-quantization, resampling, low/high pass filtering, amplitude scaling and common lossy compressions.
C1 [Terchi, Younes; Bouguezel, Saad] Univ Ferhat Abbas Setif 1, Fac Technol, Dept Elect, Lab Croissance & Caracterisat Nouveaux Semicond, Setif 19000, Algeria.
C3 Universite Ferhat Abbas Setif
RP Bouguezel, S (corresponding author), Univ Ferhat Abbas Setif 1, Fac Technol, Dept Elect, Lab Croissance & Caracterisat Nouveaux Semicond, Setif 19000, Algeria.
EM terchi.younes@gmail.com; bouguezel_saad@yahoo.com
RI Terchi, Younes/J-9707-2019
OI Terchi, Younes/0000-0002-8136-5890; Bouguezel, Saad/0000-0001-5041-7961
CR Al-Haj A, 2014, MULTIMED TOOLS APPL, V73, P1897, DOI 10.1007/s11042-013-1645-z
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen B, 1998, 1998 IEEE SECOND WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P273, DOI 10.1109/MMSP.1998.738946
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chen B, 2000, P SOC PHOTO-OPT INS, V3971, P48, DOI 10.1117/12.384995
   Chen B, 1999, P SOC PHOTO-OPT INS, V3845, P43, DOI 10.1117/12.371232
   Chen OTC, 2008, IEEE T AUDIO SPEECH, V16, P629, DOI 10.1109/TASL.2007.913022
   Chen ST, 2010, IET SIGNAL PROCESS, V4, P720, DOI 10.1049/iet-spr.2009.0187
   Chen ST, 2016, MULTIMED TOOLS APPL, V75, P4735, DOI 10.1007/s11042-015-2500-1
   Chen ST, 2015, IET SIGNAL PROCESS, V9, P166, DOI 10.1049/iet-spr.2013.0399
   Clerc M, 2002, IEEE T EVOLUT COMPUT, V6, P58, DOI 10.1109/4235.985692
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Eberhart RC, 2001, IEEE C EVOL COMPUTAT, P81, DOI 10.1109/CEC.2001.934374
   Hemis M, 2015, 2015 4 INT C EL ENG, P0
   Hu HT, 2015, SIGNAL PROCESS, V109, P226, DOI 10.1016/j.sigpro.2014.11.011
   Hua G, 2016, SIGNAL PROCESS, V128, P222, DOI 10.1016/j.sigpro.2016.04.005
   Jahnke T, 2005, J ELECTRON COMMER OR, V3, P72, DOI 10.4018/jeco.2005010105
   Kalantari NK, 2010, IEEE T IMAGE PROCESS, V19, P1504, DOI 10.1109/TIP.2010.2042646
   Lei BY, 2011, SIGNAL PROCESS, V91, P1973, DOI 10.1016/j.sigpro.2011.03.001
   Li Q, 2007, IEEE T INF FOREN SEC, V2, P127, DOI 10.1109/TIFS.2007.897266
   Li Z, 2006, IEEE T SIGNAL PROCES, V54, P3064, DOI 10.1109/TSP.2006.875393
   Lie WN, 2006, IEEE T MULTIMEDIA, V8, P46, DOI 10.1109/TMM.2005.861292
   Liu N., 2006, Book Chapter in Multimedia Security Technologies for Digital RightsManagement, P167
   Marini F, 2015, CHEMOMETR INTELL LAB, V149, P153, DOI 10.1016/j.chemolab.2015.08.020
   Puschel M, 2003, 2003 I E INT C AC SP
   Renza D, 2016, IEEE LAT AM T, V14, P1206, DOI 10.1109/TLA.2016.7459600
   Wah B, 1999, J GLOBAL OPTIM, P1, DOI [10. 1023/A. 1008203422124, DOI 10.1023/A.1008203422124]
   Wang YG, 2015, INFORM SCIENCES, V316, P40, DOI 10.1016/j.ins.2015.04.029
   Wu SQ, 2005, IEEE T BROADCAST, V51, P69, DOI 10.1109/TBC.2004.838265
   Xiang SJ, 2008, SIGNAL PROCESS, V88, P2372, DOI 10.1016/j.sigpro.2008.03.019
   Xiang Y, 2012, IEEE T INF FOREN SEC, V7, P383, DOI 10.1109/TIFS.2011.2173678
   Xiang Y, 2011, IEEE T MULTIMEDIA, V13, P2, DOI 10.1109/TMM.2010.2080668
   Yubao Bai, 2010, Proceedings of the 2010 International Conference on Artificial Intelligence and Education (ICAIE 2010), P529, DOI 10.1109/ICAIE.2010.5640958
   Zareian M, 2013, IET IMAGE PROCESS, V7, P432, DOI 10.1049/iet-ipr.2013.0048
NR 34
TC 4
Z9 7
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25681
EP 25708
DI 10.1007/s11042-018-5813-z
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400047
DA 2024-07-18
ER

PT J
AU Ahmad, H
   Saxena, N
   Roy, A
   De, P
AF Ahmad, Hasnah
   Saxena, Navrati
   Roy, Abhishek
   De, Pradipta
TI Battery-aware rate adaptation for extending video streaming playback
   time
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rate adaptation; Battery consumption; Mobile devices; Video streaming;
   Wireless networks; Quality of experience
AB Multimedia streaming applications are computation and network intensive that put a high demand on battery usage of mobile devices. Battery usage forms an important metric in user satisfaction, as increased battery consumption results in faster battery depletion and eventually leads to battery outage. In this paper, we propose an adaptation technique, referred as Battery-Aware Rate Adaptation (BARA) scheme, which adapts to the appropriate bit rate to prolong the battery lifetime. BARA considers both the wireless channel conditions, as well as the device's battery level, to determine the best transmission rate for optimizing the mobile battery consumption. Actual experiment and simulation results corroborate that compared to the conventional techniques, BARA can save more than 40% of battery power, while extending the video playback time by 20%.
C1 [Ahmad, Hasnah; Saxena, Navrati] Sungkyunkwan Univ, Dept Software, Suwon 440746, South Korea.
   [Roy, Abhishek] Samsung Elect, Syst Design Lab, Networks Div, Suwon 440600, South Korea.
   [De, Pradipta] Georgia Southern Univ, Dept Comp Sci, Statesboro, GA 30458 USA.
C3 Sungkyunkwan University (SKKU); Samsung; Samsung Electronics; University
   System of Georgia; Georgia Southern University
RP Saxena, N (corresponding author), Sungkyunkwan Univ, Dept Software, Suwon 440746, South Korea.
EM navrati@skku.edu
RI Saxena, Navrati/AAY-2493-2021
OI Saxena, Navrati/0000-0002-4875-0420; , Hasnah/0000-0001-5098-7040
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2016R1D1A1B03935633]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (NRF-2016R1D1A1B03935633).
CR Abu Alsheikh M, 2015, IEEE COMMUN SURV TUT, V17, P1239, DOI 10.1109/COMST.2015.2420686
   Ahmad H, 2016, IEEE COMMUN LETT, V20, P1659, DOI 10.1109/LCOMM.2016.2581798
   Akamai Technologies Inc, 2012, CISC VIS NETW IND GL
   [Anonymous], 2016, AK PLAY VERS 2 0
   [Anonymous], 2014, BBC News
   [Anonymous], LTE ADV DEPLOYMENT H
   [Anonymous], 2003, MAPPING FUNCTION TRA
   Biermann VK, 2011, DATA PROTECTION BETR
   Blender Foundation, 2012, TEARS STEEL BLEND VF
   Blender Foundation, 2008, BIG BUCK BUNN
   Bokani A, 2015, IEEE T MULTIMEDIA, V17, P2297, DOI 10.1109/TMM.2015.2494458
   Bui DH, 2013, REAL TIM SYST SYMP P, P57, DOI 10.1109/RTSS.2013.14
   Cao Y, 2016, IEEE T MOBILE COMPUT, V15, P1528, DOI 10.1109/TMC.2015.2461214
   Claeys Maxim., 2013, Design of a q-learning-based client quality selection algorithm for http adaptive video streaming. pages, P30
   De Cicco L., 2011, P 2 ANN ACM C MULTIM, P145
   Ding RQ, 2013, 2013 IEEE WIRELESS COMMUNICATIONS AND NETWORKING CONFERENCE (WCNC), P4588
   Dinh HT, 2013, WIREL COMMUN MOB COM, V13, P1587, DOI 10.1002/wcm.1203
   Ejembi O, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P427, DOI 10.1145/2647868.2654897
   Farahbakhsh R, 2015, IEEE COMMUN MAG, V53, P134, DOI 10.1109/MCOM.2015.7263357
   Grant AE, 2006, COMMUNICATION TECH U, P126
   Guruprasad R, 2015, IEEE T MULTIMEDIA, V17, P1630, DOI 10.1109/TMM.2015.2436821
   Hoque MA, 2014, IEEE COMMUN SURV TUT, V16, P579, DOI 10.1109/SURV.2012.111412.00051
   Kennedy M, 2010, C LOCAL COMPUT NETW, P843, DOI 10.1109/LCN.2010.5735821
   Khan S, 2014, IEEE WCNC, P2354, DOI 10.1109/WCNC.2014.6952717
   Lauridsen Mads, 2014, Intel Technology Journal, V18, P172
   Lee H, 2009, IEEE T CONSUM ELECTR, V55, P1682, DOI 10.1109/TCE.2009.5278043
   Li Y, 2008, IEEE T MULTIMEDIA, V10, P885, DOI 10.1109/TMM.2008.922860
   Liberal F, 2013, J COMPUT NETW COMM, V2013, P1
   Mkwawa I, 2013, J ZTE COMMUN, V11, P44
   Networking C. V, 2016, White Paper
   PowerTutor, 2013, OP SOURC APPL SOFTW
   Ronen A, 2014, AKAMAI EXPANDS CDN R
   Roy A, 2015, IEEE COMMUN MAG, V53, P136, DOI 10.1109/MCOM.2015.7295475
   Saw LH, 2014, J POWER SOURCES, V249, P231, DOI 10.1016/j.jpowsour.2013.10.052
   Saxena N, 2015, IEEE ICC, P3155, DOI 10.1109/ICC.2015.7248809
   Sun Y, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '16), P272, DOI 10.1145/2934872.2934898
   Wang XF, 2013, IEEE T MULTIMEDIA, V15, P811, DOI 10.1109/TMM.2013.2239630
   Wenjie Hu, 2015, 2015 IEEE Conference on Computer Communications (INFOCOM). Proceedings, P1185, DOI 10.1109/INFOCOM.2015.7218493
   Xing M, 2014, IEEE J SEL AREA COMM, V32, P795, DOI 10.1109/JSAC.2014.140411
   Yan ZS, 2016, MOBICOM'16: PROCEEDINGS OF THE 22ND ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P308, DOI 10.1145/2973750.2973780
   Yin XQ, 2015, ACM SIGCOMM COMP COM, V45, P325, DOI 10.1145/2785956.2787486
   Zhou C, 2016, IEEE T MULTIMEDIA, V18, P738, DOI 10.1109/TMM.2016.2522650
   Zhu H, 2015, IEEE NETWORK, V29, P6, DOI 10.1109/MNET.2015.7340418
   Zhu TX, 2012, PROCEEDINGS OF THE 4TH (2012) INTERNATIONAL CONFERENCE ON FINANCIAL RISK AND CORPORATE FINANCE MANAGEMENT, VOLS I AND II, P279
NR 44
TC 4
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23877
EP 23908
DI 10.1007/s11042-017-5603-z
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900035
DA 2024-07-18
ER

PT J
AU De Pessemier, T
   Martens, L
AF De Pessemier, Toon
   Martens, Luc
TI Heart rate monitoring, activity recognition, and recommendation for
   e-coaching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Heart rate; Activity recognition; Recommendation; E-coaching; Health;
   Mobile
ID PRIMARY-CARE; MESSAGES
AB Equipped with hardware, such as accelerometer and heart rate sensor, wearables enable measuring physical activities and heart rate. However, the accuracy of these heart rate measurements is still unclear and the coupling with activity recognition is often missing in health apps. This study evaluates heart rate monitoring with four different device types: a specialized sports device with chest strap, a fitness tracker, a smart watch, and a smartphone using photoplethysmography. In a state of rest, similar measurement results are obtained with the four devices. During physical activities, the fitness tracker, smart watch, and smartphone measure sudden variations in heart rate with a delay, due to movements of the wrist. Moreover, this study showed that physical activities, such as squats and dumbbell curl, can be recognized with fitness trackers. By combining heart rate monitoring and activity recognition, personal suggestions for physical activities are generated using a tag-based recommender and rule-based filter.
C1 [De Pessemier, Toon; Martens, Luc] Univ Ghent, Imec, WAVES, iGent Technol Pk 15, B-9052 Ghent, Belgium.
C3 Ghent University; IMEC
RP De Pessemier, T (corresponding author), Univ Ghent, Imec, WAVES, iGent Technol Pk 15, B-9052 Ghent, Belgium.
EM toon.depessemier@ugent.be; luc1.martens@ugent.be
CR Altini M, 2013, Heart Rate Variability Logger App version 4.6.1
   Andoh H, 2003, SICE 2003 ANNUAL CONFERENCE, VOLS 1-3, P1223
   [Anonymous], WEARABLE HEART RATE
   [Anonymous], REL CREAT REACT MOB
   [Anonymous], GENERATING PERSONALI
   [Anonymous], P 4 ACM C REC SYST R
   [Anonymous], PERSONALISATION E HL
   [Anonymous], DROOLS BUS RUL MAN S
   [Anonymous], IST200132434
   [Anonymous], AUT BLOOD PRESS MON
   [Anonymous], URR WEATH FOR
   [Anonymous], P 8 ACM INT C PERVAS
   Bodenheimer T, 2002, JAMA-J AM MED ASSOC, V288, P1775, DOI 10.1001/jama.288.14.1775
   Booth FW, 2012, COMPR PHYSIOL, V2, P1143, DOI 10.1002/cphy.c110025
   Boulos Maged N Kamel, 2014, Online J Public Health Inform, V5, P229, DOI 10.5210/ojphi.v5i3.4814
   CAMPBELL MK, 1994, AM J PUBLIC HEALTH, V84, P783, DOI 10.2105/AJPH.84.5.783
   Chen SB, 2013, 2013 INTERNATIONAL CONFERENCE ON INDUSTRIAL ENGINEERING AND MANAGEMENT SCIENCE (ICIEMS 2013), P1
   Cline RJW, 2001, HEALTH EDUC RES, V16, P671, DOI 10.1093/her/16.6.671
   Dadashi F, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON BODY SENSOR NETWORKS (BSN)
   de Vries H, 1999, PATIENT EDUC COUNS, V36, P99
   Ekstrand MichaelD., 2011, P 5 ACM C RECOMMENDE, P349
   Eysenbach G, 2000, BMJ-BRIT MED J, V320, P1713, DOI 10.1136/bmj.320.7251.1713
   Felfernig A, 2011, RECOMMENDER SYSTEMS HANDBOOK, P187, DOI 10.1007/978-0-387-85820-3_6
   Fernandez-Luque L, 2009, STUD HEALTH TECHNOL, V150, P903, DOI 10.3233/978-1-60750-044-5-903
   Freedson PS, 2000, RES Q EXERCISE SPORT, V71, pS21, DOI 10.1080/02701367.2000.11082782
   Handel MJ, 2011, EXPLORE-NY, V7, P256, DOI 10.1016/j.explore.2011.04.011
   Hayes TL, 2008, ALZHEIMERS DEMENT, V4, P395, DOI 10.1016/j.jalz.2008.07.004
   KATZ LN, 1956, CLIN ELECTROCARDIOGR
   Khan Sharib A, 2009, AMIA Annu Symp Proc, V2009, P317
   Kroll RR, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.6025
   Lester J, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P766
   Liu Y, 2016, INTERNATIONAL SYMPOSIUM 2016 - COMMON DEVELOPMENT OF SPORTS AND MODERN SOCIETY, P181
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Megret R., 2008, 2008 International Workshop on Content-based Multimedia Indexing - CBMI 2008, P101, DOI 10.1109/CBMI.2008.4564934
   Mubashir M, 2013, NEUROCOMPUTING, V100, P144, DOI 10.1016/j.neucom.2011.09.037
   Pharm FEAB, 2015, HEALTHC INFORM RES, V21, P315, DOI 10.4258/hir.2015.21.4.315
   Plasqui G, 2013, OBES REV, V14, P451, DOI 10.1111/obr.12021
   Reisner A, 2008, ANESTHESIOLOGY, V108, P950, DOI 10.1097/ALN.0b013e31816c89e1
   STRECHER VJ, 1994, J FAM PRACTICE, V39, P262
   van Velsen L, 2013, BMC MED INFORM DECIS, V13, DOI 10.1186/1472-6947-13-23
   Weippert M, 2010, EUR J APPL PHYSIOL, V109, P779, DOI 10.1007/s00421-010-1415-9
   Wu G, 2008, IEEE T NEUR SYS REH, V16, P178, DOI 10.1109/TNSRE.2007.916282
   Wu W., 2008, P ICST 3 INT C BODY, P1, DOI DOI 10.1109/WICOM.2008.629
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
NR 45
TC 14
Z9 18
U1 1
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23317
EP 23334
DI 10.1007/s11042-018-5640-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900011
OA Green Published
DA 2024-07-18
ER

PT J
AU Sakkos, D
   Liu, H
   Han, JG
   Shao, L
AF Sakkos, Dimitrios
   Liu, Heng
   Han, Jungong
   Shao, Ling
TI End-to-end video background subtraction with 3d convolutional neural
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Deep learning; Fully convolutional networks; Background
   subtraction; Video segmentation; 3D convolutional networks
ID DENSITY-ESTIMATION; OBJECT RETRIEVAL
AB Background subtraction in videos is a highly challenging task by definition, as it lays on a pixel-wise classification level. Therefore, great attention to detail is essential. In this paper, we follow the success of Deep Learning in Computer Vision and present an end-to-end system for background subtraction in videos. Our model is able to track temporal changes in a video sequence by applying 3D convolutions to the most recent frames of the video. Thus, no background model is needed to be retained and updated. In addition, it can handle multiple scenes without further fine-tuning on each scene individually. We evaluate our system on the largest dataset for change detection, CDnet, with over 50 videos which span across 11 categories. Further evaluation is performed in the ESI dataset which features extreme and sudden illumination changes. Our model surpasses the state-of-the-art on both datasets according to the average ranking of the models over a wide range of metrics.
C1 [Sakkos, Dimitrios] Northumbria Univ, Dept Comp & Informat Sci, Newcastle Upon Tyne NE1 8ST, Tyne & Wear, England.
   [Liu, Heng] Anhui Univ Technol, Sch Comp Sci & Technol, Anhui Sheng 243032, Peoples R China.
   [Han, Jungong] Univ Lancaster, Sch Comp & Commun, Lancaster LA1 4YW, England.
   [Shao, Ling] Univ East Anglia, Sch Comp Sci, Norwich NR4 7TJ, Norfolk, England.
C3 Northumbria University; Anhui University of Technology; Lancaster
   University; University of East Anglia
RP Han, JG (corresponding author), Univ Lancaster, Sch Comp & Commun, Lancaster LA1 4YW, England.
EM dimitrios.sakkos@northumbria.ac.uk; hengliusky@aliyun.com;
   jungonghan77@gmail.com; ling.shao@ieee.org
RI Sakkos, Dimitrios/AAG-8322-2019; Shao, Ling/D-3535-2011; Han,
   Jungong/ABE-6812-2020
OI Sakkos, Dimitrios/0000-0002-2382-8244; Shao, Ling/0000-0002-8264-6117
CR Allebosch G, 2016, COMM COM INF SC, V598, P433, DOI 10.1007/978-3-319-29971-6_23
   [Anonymous], 2016, P 25 INT JOINT C ART
   [Anonymous], 2014, CoRR
   [Anonymous], INT WORKSH MULT MULT
   [Anonymous], 2017, AAAI
   [Anonymous], 2011, ARXIV11085359
   [Anonymous], 2016, INT CONF SYST SIGNAL, DOI DOI 10.1109/IWSSIP.2016.7502717
   Babaee M., 2017, CoRR
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Bianco S, 2015, LNCS, P96
   Bouwmans T, 2014, COMPUT VIS IMAGE UND, V122, P22, DOI 10.1016/j.cviu.2013.11.009
   Brutzer S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1937, DOI 10.1109/CVPR.2011.5995508
   Caelles S., 2016, ARXIV161105198
   Candes E. J., 2009, J ASSOC COMPUT MACH, V21, DOI [10.1162/neco.2009.02-08-706, DOI 10.1162/NECO.2009.02-08-706]
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cheng G, 2017, IEEE GEOSCI REMOTE S, V14, P1735, DOI 10.1109/LGRS.2017.2731997
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Cheung SCS, 2005, EURASIP J APPL SIG P, V2005, P2330, DOI 10.1155/ASP.2005.2330
   De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986
   Eigen D, 2013, IEEE I CONF COMP VIS, P633, DOI 10.1109/ICCV.2013.84
   Elgammal A, 2000, EUR C COMP VIS, P751, DOI DOI 10.1007/3-540-45053-X_48
   Friedman N., 1997, PROC UNCERTAINTY ART, P175
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   Han BH, 2007, LECT NOTES COMPUT SC, V4842, P162
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jeeva S, 2015, PROCEDIA COMPUT SCI, V50, P566, DOI 10.1016/j.procs.2015.04.085
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jia Yangqing, 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Jiang S., 2017, IEEE T CIRC SYST VID, V99, P1, DOI DOI 10.1109/TCSVT.2017.2711659.HTTP://IEEEXPL0RE.IEEE.0RG/D0CUMENT/7938679/
   KaewTraKulPong P., 2001, Proc. European Workshop Advanced Video Based Surveillance Systems, V1, P1
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kim WJ, 2017, IEEE ACCESS, V5, P8369, DOI 10.1109/ACCESS.2017.2699227
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Lan XY, 2014, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2014.156
   Liu RF, 2016, EUR SIGNAL PR CONF, P2166, DOI 10.1109/EUSIPCO.2016.7760632
   Liu ZW, 2015, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2015.162
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mittal A, 2004, PROC CVPR IEEE, P302
   Oliver N, 1999, LECT NOTES COMPUTER, V1542, P255, DOI [10.1007/3-540-49256-916, DOI 10.1007/3-540-49256-916]
   Pedro O.P., 2013, P ICML, P82
   Pilet J, 2008, MAKING BACKGROUND SU, DOI [10.1007/978-3-540-88693-8-42, DOI 10.1007/978-3-540-88693-8-42]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sajid H, 2017, IEEE T IMAGE PROCESS, V26, P3249, DOI 10.1109/TIP.2017.2695882
   Sermanet P., 2014, INT C LEARN REPR
   Shengping Zhang, 2008, 19th International Conference on Pattern Recognition, ICPR 2008, DOI 10.1109/ICPR.2008.4761162
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005
   St-Charles PL, 2015, IEEE WINT CONF APPL, P990, DOI 10.1109/WACV.2015.137
   St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053
   Tuzel O, 2005, IEEE I CONF COMP VIS, P18
   Vosters L, 2012, IMAGE VISION COMPUT, V30, P1004, DOI 10.1016/j.imavis.2012.08.017
   Wang D, 2017, NEUROCOMPUTING, V252, P58, DOI 10.1016/j.neucom.2016.06.095
   Wang R, 2014, IEEE COMPUT SOC CONF, P420, DOI 10.1109/CVPRW.2014.68
   Wang Y, 2017, PATTERN RECOGN LETT, V96, P66, DOI 10.1016/j.patrec.2016.09.014
   Wang Y, 2014, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2014.126
   Xu Y, 2015, IEEE INT CONF RFID, P1, DOI 10.1109/RFID.2015.7113066
   Yao C, 2017, IEEE T IMAGE PROCESS, V26, P5257, DOI 10.1109/TIP.2017.2733200
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Yao XW, 2016, IEEE T GEOSCI REMOTE, V54, P3660, DOI 10.1109/TGRS.2016.2523563
   Zhang SP, 2009, INT J PATTERN RECOGN, V23, P1397, DOI 10.1142/S0218001409007569
   Zhang SP, 2008, IEEE IMAGE PROC, P1556, DOI 10.1109/ICIP.2008.4712065
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zhao S, 2015, SIGNAL PROCESS, V112, P110, DOI 10.1016/j.sigpro.2014.09.038
   Zhao SC, 2015, NEUROCOMPUTING, V151, P533, DOI 10.1016/j.neucom.2014.03.092
   Zhao Sicheng, 2016, P 24 ACM INT C MULT, P1385, DOI DOI 10.1145/2964284.2964289
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zhou T, 2011, ICML, P8, DOI [10.1109/TPAMI.2012.88, DOI 10.1109/TPAMI.2012.88]
   Zhu QS, 2013, INT CONF ACOUST SPEE, P1769, DOI 10.1109/ICASSP.2013.6637956
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 72
TC 71
Z9 74
U1 2
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 23023
EP 23041
DI 10.1007/s11042-017-5460-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500067
DA 2024-07-18
ER

PT J
AU Zhang, YD
   Jiang, YY
   Zhu, WG
   Lu, SY
   Zhao, GH
AF Zhang, Yu-Dong
   Jiang, Yongyan
   Zhu, Weiguo
   Lu, Siyuan
   Zhao, Guihu
TI Exploring a smart pathological brain detection method on pseudo Zernike
   moment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pathological brain detection; Pseudo Zernike moment
ID STATIONARY WAVELET TRANSFORM; SUPPORT VECTOR MACHINES; IMAGE
   CLASSIFICATION; ENTROPY; RECONSTRUCTION; DIAGNOSIS
AB Pathological brain detection by computer vision is now attracting intense attentions from academic fields. Nevertheless, most of recent methods suffer from low-accuracy. This study combined two successful techniques: pseudo Zernike moment and kernel support vector machine. Three open datasets were downloaded and used. The 10 times of K-fold stratified cross validation showed our method using 19-order pseudo Zernike moments achieved perfect classification on the first dataset. It achieved a sensitivity of 99.93 +/- 0.23%, a specificity of 98.50 +/- 2.42%, and an accuracy of 99.75 +/- 0.32% on the second dataset. It achieved a sensitivity of 99.64 +/- 0.42%, a specificity of 98.29 +/- 2.76%, and an accuracy of 99.45 +/- 0.38% on the third dataset. This approach performs better than eleven state-of-the-art smart pathological brain detection methods.
C1 [Zhang, Yu-Dong; Zhu, Weiguo] Jiangsu Key Lab Adv Mfg Technol, Huaiyin 223003, Jiangsu, Peoples R China.
   [Zhang, Yu-Dong] Hunan Policy Acad, Hunan Prov Key Lab Network Invest Technol, Changsha 410138, Hunan, Peoples R China.
   [Zhang, Yu-Dong; Lu, Siyuan] Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing 210023, Jiangsu, Peoples R China.
   [Jiang, Yongyan] Zhongyuan Univ Technol, Coll Sci, Zhengzhou 450007, Henan, Peoples R China.
   [Zhao, Guihu] Cent South Univ, Sch Informat Sci & Engn, Changsha 410083, Hunan, Peoples R China.
C3 Nanjing Normal University; Zhongyuan University of Technology; Central
   South University
RP Lu, SY (corresponding author), Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing 210023, Jiangsu, Peoples R China.; Zhao, GH (corresponding author), Cent South Univ, Sch Informat Sci & Engn, Changsha 410083, Hunan, Peoples R China.
EM zhangyudong@njnu.edu.cn; jiangyongyan@126.com; bobweiguo@sohu.com;
   siyuan_lu@foxmail.com; ghzhao@csu.edu.cn
RI Lu, Siyuan/ABE-7949-2020; Zhang, Yudong/I-7633-2013
OI Lu, Siyuan/0000-0001-6720-1323; Zhang, Yudong/0000-0002-4870-1493
FU National Natural Science Foundation of China [61602250]; Open fund for
   Jiangsu Key Laboratory of Advanced Manufacturing Technology
   [HGAMTL1601]; Key Laboratory of Guangxi High Schools Complex System and
   Computational Intelligence [2016CSCI01]; Leading Initiative for
   Excellent Young Researcher (LEADER) of Ministry of Education, Culture,
   Sports, Science and Technology-Japan [16809746]; Natural Science
   Foundation of Jiangsu Province [BK20150983]; State Key Laboratory of
   Digital Publishing Technology
FX This work was supported by National Natural Science Foundation of China
   (61602250), Open fund for Jiangsu Key Laboratory of Advanced
   Manufacturing Technology (HGAMTL1601), Open fund of Key Laboratory of
   Guangxi High Schools Complex System and Computational Intelligence
   (2016CSCI01), Leading Initiative for Excellent Young Researcher (LEADER)
   of Ministry of Education, Culture, Sports, Science and Technology-Japan
   (16809746), Natural Science Foundation of Jiangsu Province (BK20150983),
   Open fund of Key Laboratory of Guangxi High Schools Complex System and
   Computational Intelligence (2016CSCI01), Opening Project of State Key
   Laboratory of Digital Publishing Technology.
CR Abdillah AA, 2016, INT J TECHNOL, V7, P849, DOI 10.14716/ijtech.v7i5.1370
   [Anonymous], EXP SYST, DOI DOI 10.1111/EXSY.12146
   Pham BT, 2017, CATENA, V149, P52, DOI 10.1016/j.catena.2016.09.007
   Chen Y, 2018, MULTIMED TOOLS APPL, V77, P3813, DOI 10.1007/s11042-016-4161-0
   Das S, 2013, PROG ELECTROMAGN RES, V137, P1, DOI 10.2528/PIER13010105
   Deng AW, 2016, PATTERN RECOGN, V56, P16, DOI 10.1016/j.patcog.2016.02.014
   Douglass S, 2016, PLANT J, V86, P481, DOI 10.1111/tpj.13180
   Gajovic S, 2014, PROG BRAIN RES, V214, pXIX, DOI 10.1016/B978-0-444-63486-3.09999-0
   Ghasemi F, 2017, J COMPUT CHEM, V38, P195, DOI 10.1002/jcc.24671
   Gorji HT, 2015, NEUROSCIENCE, V305, P361, DOI 10.1016/j.neuroscience.2015.08.013
   Huo YK, 2017, HUM BRAIN MAPP, V38, P599, DOI 10.1002/hbm.23432
   Huo Y, 2016, NEUROIMAGE, V138, P197, DOI 10.1016/j.neuroimage.2016.05.030
   Johnson KA, 2016, WHOLE BRAIN ATLAS
   Kahyaei S, 2016, 2016 4TH INTERNATIONAL CONFERENCE ON CONTROL, INSTRUMENTATION, AND AUTOMATION (ICCIA), P116, DOI 10.1109/ICCIAutom.2016.7483146
   Liu YH, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6050142
   Marathe Ashutosh S., 2016, 2016 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC). Proceedings, DOI 10.1109/ICSPCC.2016.7753703
   Nayak DR, 2016, NEUROCOMPUTING, V177, P188, DOI 10.1016/j.neucom.2015.11.034
   Nayak R, 2016, AEU-INT J ELECTRON C, V70, P1496, DOI 10.1016/j.aeue.2016.09.001
   Scott J, 2017, J AFFECT DISORDERS, V208, P62, DOI 10.1016/j.jad.2016.08.069
   Singh C, 2017, AEU-INT J ELECTRON C, V72, P104, DOI 10.1016/j.aeue.2016.11.014
   Singh SP, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0454-0
   Soman Karthik, 2014, 2014 International Conference on Information Communication and Embedded Systems (ICICES), DOI 10.1109/ICICES.2014.7034000
   Wang HN, 2018, MULTIMED TOOLS APPL, V77, P3871, DOI 10.1007/s11042-016-4242-0
   Wang SH, 2018, MULTIMED TOOLS APPL, V77, P10393, DOI 10.1007/s11042-016-4222-4
   Wang SH, 2016, IEEE ACCESS, V4, DOI 10.1109/ACCESS.2016.2620996
   Wang SH, 2018, MULTIMED TOOLS APPL, V77, P3701, DOI 10.1007/s11042-016-3401-7
   Wang SH, 2016, FRONT COMPUT NEUROSC, V10, DOI 10.3389/fncom.2016.00106
   Wang SH, 2016, BIOMED ENG-BIOMED TE, V61, P431, DOI 10.1515/bmt-2015-0152
   Wang SH, 2016, PEERJ, V4, DOI 10.7717/peerj.2207
   Wang SH, 2016, J ALZHEIMERS DIS, V50, P233, DOI 10.3233/JAD-150848
   Wang SH, 2015, ENTROPY-SWITZ, V17, P8278, DOI 10.3390/e17127877
   Wang SH, 2015, ENTROPY-SWITZ, V17, P6663, DOI 10.3390/e17106663
   Wang SH, 2015, ENTROPY-SWITZ, V17, P5711, DOI 10.3390/e17085711
   Wang SH, 2015, INT J IMAG SYST TECH, V25, P153, DOI 10.1002/ima.22132
   Zhang Y, 2012, PROG ELECTROMAGN RES, V130, P369, DOI 10.2528/PIER12061410
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P10521, DOI 10.1007/s11042-017-4554-8
   Zhang YD, 2016, IEEE ACCESS, V4, P8375, DOI 10.1109/ACCESS.2016.2628407
   Zhang YD, 2016, IEEE ACCESS, V4, P5937, DOI 10.1109/ACCESS.2016.2611530
   Zhang YD, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1523-4
   Zhang YD, 2015, INT J IMAG SYST TECH, V25, P317, DOI 10.1002/ima.22144
   Zhang YD, 2014, J FOOD ENG, V143, P167, DOI 10.1016/j.jfoodeng.2014.07.001
   Zhang YD, 2017, CNS NEUROL DISORD-DR, V16, P122, DOI 10.2174/1871527315666161026115046
   Zhang YD, 2017, J EXP THEOR ARTIF IN, V29, P299, DOI 10.1080/0952813X.2015.1132274
   Zhang YD, 2016, SIMUL-T SOC MOD SIM, V92, P873, DOI 10.1177/0037549716667834
   Zhang YD, 2016, SIMUL-T SOC MOD SIM, V92, P861, DOI 10.1177/0037549716666962
   Zhang YD, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0525-2
   Zhang YD, 2016, J ALZHEIMERS DIS, V50, P1163, DOI 10.3233/JAD-150988
   Zhang YD, 2015, J MED IMAG HEALTH IN, V5, P1395, DOI 10.1166/jmihi.2015.1542
   Zhang YD, 2015, PROG ELECTROMAGN RES, V152, P41, DOI 10.2528/PIER15040602
   Zhang YD, 2015, BIO-MED MATER ENG, V26, pS1283, DOI 10.3233/BME-151426
   Zhang YD, 2015, ENTROPY-SWITZ, V17, P1795, DOI 10.3390/e17041795
   Zhang YD, 2014, KNOWL-BASED SYST, V64, P22, DOI 10.1016/j.knosys.2014.03.015
   Zhang YD, 2014, PROG ELECTROMAGN RES, V144, P171, DOI 10.2528/PIER13121310
   Zhang YD, 2011, EXPERT SYST APPL, V38, P10049, DOI 10.1016/j.eswa.2011.02.012
   Zhou XX, 2016, SIMUL-T SOC MOD SIM, V92, P827, DOI 10.1177/0037549716629227
   Zhou XX, 2016, IEEJ T ELECTR ELECTR, V11, P364, DOI 10.1002/tee.22226
NR 56
TC 42
Z9 43
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22589
EP 22604
DI 10.1007/s11042-017-4703-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500044
DA 2024-07-18
ER

PT J
AU Evans, A
   Agenjo, J
   Blat, J
AF Evans, Alun
   Agenjo, Javi
   Blat, Josep
TI A pipeline for the creation of progressively rendered web 3D scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D; Web; Graphics; Pipeline; Compression; Mesh
AB We present an end-to-end pipeline for the export of 3D scenes from content creation tools to a real-time rendering engine in an embeddable web-page, including a novel system for compression/decompression of textured polygonal meshes. We show that the compression/decompression outperforms the best state-of-the-art non-progressive alternative, especially as bandwidth increases, showing that web-specific techniques should consider the whole user pipeline. Our pipeline also includes progressivity, which is paramount for a good interactive user experience, and permits full user interaction with lower resolution versions of the 3D scenes, while progressively higher resolution data is downloaded. Finally, we discuss how our method may be used in the future to facilitate the transfer of animated meshes.
C1 [Evans, Alun] La Salle Univ Ramon Llull, GTM Grp Recerca Tecnol Media, Quatre Camins 30, Barcelona 08022, Spain.
   [Agenjo, Javi; Blat, Josep] Univ Pompeu Fabra, Grp Tecnol Interact, Roc Boronat 138, Barcelona 08018, Spain.
C3 Universitat Ramon Llull; Pompeu Fabra University
RP Evans, A (corresponding author), La Salle Univ Ramon Llull, GTM Grp Recerca Tecnol Media, Quatre Camins 30, Barcelona 08022, Spain.
EM aevans@salleurl.edu; javier.agenjo@upf.edu; josep.blat@upf.edu
RI Evans, Alun/D-3839-2014; Blat, Josep/J-2178-2015
OI Evans, Alun/0000-0002-5713-0282; Blat, Josep/0000-0002-5308-475X
FU European Commision [H2020-645012]
FX This work has been partially funded by the European Commision
   Horizon2020 project KRISTINA (grant number: H2020-645012).
CR Agenjo J, 2013, WEB3D 2013: 18TH INTERNATIONAL CONFERENCE ON 3D WEB TECHNOLOGY, P79
   Alliez P, 2001, COMP GRAPH, P195, DOI 10.1145/383259.383281
   [Anonymous], 2018, Real-Time Rendering
   [Anonymous], 2014, P 11 EUR C VIS MED P, DOI DOI 10.1145/2668904.2668937
   [Anonymous], 1999, Designing Web Usability: The Practice of Simplicity
   Behr J., 2009, WEB3D 09 P 14 INT C, P127, DOI [DOI 10.1145/1559764.1559784, 10.1145/1559764.1559784]
   Behr J, 2012, WEB3D 2012, P17
   Blat J, 2016, P IEEE, V104, P2085, DOI 10.1109/JPROC.2015.2496111
   Blume A., 2011, ACM SIGGRAPH 2011 TA, P19
   Brauchart JS, 2012, NUMER MATH, V121, P473, DOI 10.1007/s00211-011-0444-6
   Cavalcanti MGP, 2004, DENTOMAXILLOFAC RAD, V33, P170, DOI 10.1259/dmfr/13603271
   Chim J, 2003, IEEE T MULTIMEDIA, V5, P503, DOI 10.1109/TMM.2003.819094
   Chun W, 2012, OPENGL INSIGHTS, P431
   Cigolle Zina H., 2014, Journal of Computer Graphics Techniques (JCGT), V3, P1
   Evans A, 2014, COMPUT GRAPH-UK, V41, P43, DOI 10.1016/j.cag.2014.02.002
   Forsyth T., 2006, LINEAR SPEED VERTEX
   Geelnard Marcus, 2010, OpenCTM, the open compressed triangle mesh file format
   González A, 2010, MATH GEOSCI, V42, P49, DOI 10.1007/s11004-009-9257-x
   Google, 2017, GOOGL OP SOURC BLOG
   Gregory Jason., 2009, GAME ENGINE ARCHITEC
   Guimaraes MD, 2018, MULTIMED TOOLS APPL, V77, P347, DOI 10.1007/s11042-016-4256-7
   Hannay JH, 2004, J PHYS A-MATH GEN, V37, P11591, DOI 10.1088/0305-4470/37/48/005
   Hoppe H., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P99, DOI 10.1145/237170.237216
   Ioannidou A, 2017, MULTIMED TOOLS APPL, V76, P1735, DOI 10.1007/s11042-015-3125-0
   Keinert B, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818131
   Kim H, 2018, IEEE T CIRC SYST VID, V28, P863, DOI 10.1109/TCSVT.2016.2642825
   Lavoué G, 2013, WEB3D 2013: 18TH INTERNATIONAL CONFERENCE ON 3D WEB TECHNOLOGY, P19
   Limper M, 2013, COMPUT GRAPH FORUM, V32, P197, DOI 10.1111/cgf.12227
   Limper M, 2013, WEB3D 2013: 18TH INTERNATIONAL CONFERENCE ON 3D WEB TECHNOLOGY, P11
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Maglo A, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2693443
   Marques R, 2013, COMPUT GRAPH FORUM, V32, P134, DOI 10.1111/cgf.12190
   McGuire M., 2017, Computer Graphics Archive
   McIntyre L, 2010, J DIGIT ASSET MANAG, V6, P344, DOI [10.1057/dam.2010.41, DOI 10.1057/DAM.2010.41]
   Mellado J, 2014, JS OPENCTM
   Nielsen, 1994, USABILITY ENG
   Ponchio F, 2015, WEB3D 2015, P199, DOI 10.1145/2775292.2775308
   Potenziani M, 2015, COMPUT GRAPH-UK, V52, P129, DOI 10.1016/j.cag.2015.07.001
   Praun E, 2003, ACM T GRAPHIC, V22, P340, DOI 10.1145/882262.882274
   Quax P, 2016, MULTIMED TOOLS APPL, V75, P4383, DOI 10.1007/s11042-015-2481-0
   Sander PV, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239540, 10.1145/1276377.1276489]
   Sons K, 2010, P 15 INT C WEB 3D TE, P175
   Swinbank R, 2006, Q J ROY METEOR SOC, V132, P1769, DOI 10.1256/qj.05.227
   Zampoglou M, 2018, MULTIMED TOOLS APPL, V77, P125, DOI 10.1007/s11042-016-4255-8
NR 47
TC 2
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 20355
EP 20383
DI 10.1007/s11042-017-5463-6
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300004
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Guo, C
   Zhang, H
   Fu, ZJ
   Feng, B
   Li, MC
AF Guo, Cheng
   Zhang, Huan
   Fu, Zhangjie
   Feng, Bin
   Li, Mingchu
TI A novel proactive secret image sharing scheme based on LISS
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Proactive secret sharing; LISS; Distortion-free; Secret image sharing
ID COVER IMAGES; STEGANOGRAPHY
AB In the traditional secret image sharing schemes, a dealer shares a secret image among a group of participants and an authorized subset of the participants with their shadow images can cooperate to retrieve the secret image. However, for a long live secret image, the intruders may have adequate time to gain enough amounts of the shadow images. In this paper, we propose a proactive secret image sharing scheme based on LISS. In the scheme, shadow images are updated periodically by the shareholders without changing the original secret image such that the previous shares are invalid and the secret image can be reconstructed only by the shadow images in the current period. The experimental results demonstrate that the proposed scheme can recover the secret image losslessly and the embedding capacity is acceptable. The quality of the shadow images may reduce after every refreshing operation. Nevertheless, the scheme is still applicable when the number of updating times is less than ten.
C1 [Guo, Cheng; Zhang, Huan; Feng, Bin; Li, Mingchu] Dalian Univ Technol, Sch Software Technol, Dev Zone, Dalian 116620, Peoples R China.
   [Guo, Cheng; Zhang, Huan; Feng, Bin; Li, Mingchu] Key Lab Ubiquitous Network & Serv Sofiware Liaoni, Dalian 116620, Peoples R China.
   [Fu, Zhangjie] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
C3 Dalian University of Technology; Nanjing University of Information
   Science & Technology
RP Guo, C (corresponding author), Dalian Univ Technol, Sch Software Technol, Dev Zone, Dalian 116620, Peoples R China.; Guo, C (corresponding author), Key Lab Ubiquitous Network & Serv Sofiware Liaoni, Dalian 116620, Peoples R China.
EM guocheng@dlut.edu.cn
OI Li, Mingchu/0000-0001-8280-2936; Guo, Cheng/0000-0001-7489-7381
FU National Science Foundation of China [61501080, 61572095]; Fundamental
   Research Funds for the Central Universities [DUT16QY09]
FX This paper is supported by the National Science Foundation of China
   under grant No. 61501080 and 61572095, and the Fundamental Research
   Funds for the Central Universities' under No. DUT16QY09.
CR Blakley G. R., 1979, 1979 International Workshop on Managing Requirements Knowledge (MARK), P313, DOI 10.1109/MARK.1979.8817296
   Cachin Christian, 2002, ACM C COMP COMM SEC, P88
   Chang JC, 2017, SIGNAL PROCESS, V133, P135, DOI 10.1016/j.sigpro.2016.11.003
   Chen XY, 2017, J INTERNET TECHNOL, V18, P313, DOI 10.6138/JIT.2017.18.2.20160815
   Chiu PL, 2015, SIGNAL PROCESS, V108, P476, DOI 10.1016/j.sigpro.2014.09.032
   Cramer R, 2002, LECT NOTES COMPUT SC, V2442, P272
   Damgård I, 2006, LECT NOTES COMPUT SC, V3958, P75
   Fu ZJ, 2017, IEEE T INF FOREN SEC, V12, P1874, DOI 10.1109/TIFS.2017.2692728
   Fu ZJ, 2016, IEEE T PARALL DISTR, V27, P2546, DOI 10.1109/TPDS.2015.2506573
   Guo C, 2017, MULTIMED TOOLS APPL, V76, P21193, DOI 10.1007/s11042-016-4065-z
   Guo C, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0588-0
   Guo C, 2016, MULTIMED TOOLS APPL, V75, P11577, DOI 10.1007/s11042-015-2885-x
   Guo C, 2012, PATTERN RECOGN LETT, V33, P83, DOI 10.1016/j.patrec.2011.09.030
   Herzberg A, 1995, LECT NOTES COMPUT SC, V963, P339
   Kumar S, 2014, SECUR COMMUN NETW, V7, P653, DOI 10.1002/sec.769
   Kyriakopoulos K, 2007, LECT NOTES COMPUT SC, V4427, P241
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li P, 2016, DIGIT SIGNAL PROCESS, V50, P51, DOI 10.1016/j.dsp.2015.12.004
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin PY, 2010, PATTERN RECOGN LETT, V31, P1887, DOI 10.1016/j.patrec.2010.01.019
   Lin PY, 2009, PATTERN RECOGN, V42, P886, DOI 10.1016/j.patcog.2008.09.014
   Lizhi Xiong, 2018, Multidimensional Systems and Signal Processing, V29, P1191, DOI 10.1007/s11045-017-0497-5
   Ma CG, 2009, LECT NOTES COMPUT SC, V5927, P439
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Nikov V, 2004, 11 INT WORKSH SEL AR, P308
   Ostrovsky R., 1991, Proceedings of the Tenth Annual ACM Symposium on Principles of Distributed Computing, P51, DOI 10.1145/112600.112605
   Pakniat N, 2014, J VIS COMMUN IMAGE R, V25, P1093, DOI 10.1016/j.jvcir.2014.03.004
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Schultz D, 2010, ACM T INFORM SYST SE, V13, P293
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shen J, 2017, IEEE T INF FOREN SEC, V12, P2402, DOI 10.1109/TIFS.2017.2705620
   Shyu SJ, 2015, THEOR COMPUT SCI, V565, P30, DOI 10.1016/j.tcs.2014.10.048
   Stinson DouglasR., 1999, International Workshop on Selected Areas in Cryptography, P200
   Ulutas M, 2013, J SYST SOFTWARE, V86, P485, DOI 10.1016/j.jss.2012.09.027
   Wang X, 2013, INT NETW COLL SYST I, P511
   Wu XT, 2013, J VIS COMMUN IMAGE R, V24, P48, DOI 10.1016/j.jvcir.2012.11.001
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Xia ZH, 2016, IEEE T PARALL DISTR, V27, P340, DOI 10.1109/TPDS.2015.2401003
   Yuan CS, 2017, J INTERNET TECHNOL, V18, P435, DOI 10.6138/JIT.2017.18.2.20160624c
   Zarepour-Ahmadabadi J, 2016, INFORM SCIENCES, V369, P467, DOI 10.1016/j.ins.2016.07.001
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
   Zhou ZL, 2016, IEICE T INF SYST, VE99D, P1531, DOI 10.1587/transinf.2015EDP7341
NR 43
TC 5
Z9 5
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19569
EP 19590
DI 10.1007/s11042-017-5412-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500031
DA 2024-07-18
ER

PT J
AU Koushkaki, HR
   Salehi, MR
   Abiri, E
AF Koushkaki, Hassan Rahmanian
   Salehi, Mohammad Reza
   Abiri, Ebrahim
TI Automatic colourization of grayscale images based on tensor
   decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic Colourizing; Block matching; Tensor decomposition; Tensor
   space
ID COLORIZATION; REPRESENTATION; COLOR
AB In this paper a colourizing technique based on some tensor properties is proposed. Toward this goal, it is clarified that tensor decomposition possesses the ability of extracting and gathering overall colour information. The methodology considers a grayscale pixel as a balanced vector in RGB colour space. Any deviation to unbalance the colour coordinates means adding colour information to the initial pixel. For finding the appropriate direction of deviation, the proposed technique uses tensor decomposition to extract colour information from a block divided exemplar colour image called reference. Then apply this direction to the best matched block of the grayscale image based on a similarity criterion while its basic structure is preserved. Finally by retrieving from tensor space into spatial domain the conversion is fulfilled. The similarity criteria for block matching and the plausibility of the system output are the most challenging problems. Both images blocks are considered as 3D tensors and Tucker3 with its unique properties is utilized for transferring the colour information. The novelty, simplicity, accuracy, and the conversion speed are some parameters which are introduced and developed by the proposed algorithm. This approach proves that in comparison with spatial or frequency domain, transforming the colour information into tensor space make it more clear and give us better ability of rendering. The results show that the proposed algorithm is able to present the average structural similarity up to 94%.
C1 [Koushkaki, Hassan Rahmanian; Salehi, Mohammad Reza; Abiri, Ebrahim] Shiraz Univ Technol, Elect & Elect Engn Dept, Shiraz, Iran.
   [Salehi, Mohammad Reza] RICeST, Jam E Jam Ave, Shiraz, Iran.
C3 Shiraz University of Technology
RP Salehi, MR (corresponding author), Shiraz Univ Technol, Elect & Elect Engn Dept, Shiraz, Iran.; Salehi, MR (corresponding author), RICeST, Jam E Jam Ave, Shiraz, Iran.
EM h.rahmanian@sutech.ac.ir; salehi@sutech.ac.ir; abiri@sutech.ac.ir
RI Rahmanian'Koushkaki, Hassan/KRX-7812-2024
OI Rahmanian'Koushkaki, Hassan/0000-0002-4545-1476
CR [Anonymous], 2015, ACM MULTIMEDIA SYSTE
   [Anonymous], 2005, EUROGRAPHICS S RENDE
   BADER BW, MATLAB TENSOR TOOLBO
   Bugeau A, 2014, IEEE T IMAGE PROCESS, V23, P298, DOI 10.1109/TIP.2013.2288929
   Burger W, 2009, PRINCIPAL DIGITAL SI
   Casaca W, 2012, 25 SIBGRAPI C GRAPH
   Charpiat G, 2008, LECT NOTES COMPUT SC, V5304, P126, DOI 10.1007/978-3-540-88690-7_10
   Chatzichristofis SA, 2008, IM AN MULT INT SERV
   Cheng ZZ, 2015, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2015.55
   Chia AY-S, 2011, P 2011 SIGGRAPH AS C, V30
   Cichocki A, 2014, IEEE SINGNAL PROCESS, P1053
   De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696
   Deshpande A, 2015, IEEE I CONF COMP VIS, P567, DOI 10.1109/ICCV.2015.72
   Doulamis AD, 2000, SIGNAL PROCESS, V80, P1049, DOI 10.1016/S0165-1684(00)00019-0
   Drew MS, 2008, ICIP
   Dunlavy DM, 2006, SAND20062079
   Gupta R. K., 2012, P 20 ACM INT C MULT, P369, DOI DOI 10.1145/2393347.2393402
   Hu M, 2017, MULTIMED TOOLS APPL, V76, P23567, DOI 10.1007/s11042-016-4112-9
   Huang H, 2015, MULTIMED TOOLS APPL, V74, P7555, DOI 10.1007/s11042-014-1991-5
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Li B, 2017, IEEE T IMAGE PROCESS, V26, P5188, DOI 10.1109/TIP.2017.2732239
   Lu H, 2014, MACHINE LEARNING PAT
   Lu HP, 2011, PATTERN RECOGN, V44, P1540, DOI 10.1016/j.patcog.2011.01.004
   Morup Morten, 2011, APPL TENSOR MULTIWAY, V1
   Peter P, 2017, IEEE T IMAGE PROCESS, V26, P860, DOI 10.1109/TIP.2016.2627800
   Pierre F, 2015, SIAM J IMAGING SCI, V8, P536, DOI 10.1137/140979368
   Pierre F., 2014, IETF INTERNETDRAFT, P1
   Saravanan C, 2010, COMP ENG APPL ICCEA
   Sivalingam R, 2014, IEEE T PATTERN ANAL, V36, P592, DOI 10.1109/TPAMI.2013.143
   VERTAN C, 2000, USING FUZZY HISTOGRA
   Vervliet N, 2017, TENSORLAB 3 0
   Wan Y, 2016, INT HUM MACH SYST CY
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Welsh T, 2002, ACM T GRAPHIC, V21, P277, DOI 10.1145/566570.566576
NR 36
TC 0
Z9 0
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 20043
EP 20063
DI 10.1007/s11042-017-5419-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500051
DA 2024-07-18
ER

PT J
AU Rajput, AS
   Raman, B
AF Rajput, Amitesh Singh
   Raman, Balasubramanian
TI Cloud based image color transfer and storage in encrypted domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color transfer; Encrypted domain processing; Cloud computing
AB Cloud infrastructures are developed and maintained by third parties and users are always concerned about processing and storing their data over the cloud. Recent technologies such as high definition and 360-degree images/videos require efficient color processing, and current trend towards the cloud computing has initiated a necessity of performing color transfer remotely by untrusted third party servers. Nowadays, this field is emerging fast due to its inherent potential and research work in this direction is highly demanded. To address this necessity, we present a system that addresses the challenge of performing privacy preserving color transfer over third party servers. We use a one-dimensional chaotic logistic map coupled with ramp secret sharing scheme in a manner that secret images can be stored and processed for color transfer in the encrypted domain. Experimental results and security analysis demonstrate effectiveness of the approach against existing techniques of color transfer as well as image encryption.
C1 [Rajput, Amitesh Singh; Raman, Balasubramanian] Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee
RP Rajput, AS (corresponding author), Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.
EM asr88.dcs2015@iitr.ac.in
FU Information Security Education and Awareness (ISEA) Project (phase II),
   Deity, Government of INDIA
FX This work was supported by Information Security Education and Awareness
   (ISEA) Project (phase II), Deity, Government of INDIA.
CR Al-Otaibi Nouf A., 2014, Lecture Notes on Information Theory, V2, P151, DOI 10.12720/lnit.2.2.151-157
   Alassaf N., 2003, ARABIA
   Amini A., 2015, Journal of Applied Sciences, V15, P953, DOI 10.3923/jas.2015.953.967
   [Anonymous], 2001, CVPR Tech. Sketch
   [Anonymous], 2015, 12 LEARN TECHN C WEA
   [Anonymous], 2015, PAC RIM S IM VID TEC
   [Anonymous], 2014, INT C ADV ENG TECHN
   [Anonymous], PERF COMP COMM C IPC
   Finlayson GD, 2015, IEEE T IMAGE PROCESS, V24, P1460, DOI 10.1109/TIP.2015.2405336
   Fu C, 2012, OPT EXPRESS, V20, P2363, DOI 10.1364/OE.20.002363
   Gutub A, 2008, INT C ADV COMP SCI A
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Gutub AAA, 2012, INT CONF ADV COMPUT, P116, DOI 10.1109/ACSAT.2012.44
   Hsu CY, 2012, IEEE T IMAGE PROCESS, V21, P4593, DOI 10.1109/TIP.2012.2204272
   Khan F, 2007, MESSAGE CONCEALMENT
   Lathey A, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2656205
   Lu HM, 2013, IEEE IMAGE PROC, P3412, DOI 10.1109/ICIP.2013.6738704
   Ly DS, 2014, IEEE IMAGE PROC, P640, DOI 10.1109/ICIP.2014.7025128
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Mohanty M, 2013, IEEE INT CON MULTI
   Pareek NK, 2013, DIGIT SIGNAL PROCESS, V23, P894, DOI 10.1016/j.dsp.2013.01.005
   Pitié F, 2007, COMPUT VIS IMAGE UND, V107, P123, DOI 10.1016/j.cviu.2006.11.011
   Rahulamathavan Y, 2013, IEEE T AFFECT COMPUT, V4, P83, DOI 10.1109/T-AFFC.2012.33
   Rajput AS, 2017, IEEE INT CONF MULTI
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Tai YW, 2005, PROC CVPR IEEE, P747
   Teng L, 2012, OPT COMMUN, V285, P4048, DOI 10.1016/j.optcom.2012.06.004
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Uyttendaele Matthew, 2001, P 2001 IEEE COMP SOC, V2, pII
   Wang XY, 2012, OPT COMMUN, V285, P412, DOI 10.1016/j.optcom.2011.10.010
   Wu Y, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.1.013014
   Xiang Y, 2009, PATTERN RECOGN LETT, V30, P682, DOI 10.1016/j.patrec.2009.01.004
   Xu W, 2010, PROC CVPR IEEE, P263, DOI 10.1109/CVPR.2010.5540202
   Zafar F, 2017, COMPUT SECUR, V65, P29, DOI 10.1016/j.cose.2016.10.006
NR 35
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21509
EP 21537
DI 10.1007/s11042-017-5580-2
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300052
DA 2024-07-18
ER

PT J
AU Shakoor, MH
   Boostani, R
AF Shakoor, Mohammad Hossein
   Boostani, Reza
TI Radial mean local binary pattern for noisy texture classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local binary pattern; Texture classification; Radial mean local binary
   pattern; Noise robust
ID FACE RECOGNITION; GRAY-SCALE; ROTATION; FEATURES
AB Local Binary Pattern (LBP) is one of the best descriptors of texture images; however, it elicits information from the pixels' value over each locality and therefore its value is highly sensitive to additive noise. In this research, a robust-to-noise LBP version is proposed, termed Radial Mean Local Binary Pattern (RMLBP), to enhance the quality of extracted features in noisy images. The main trick of RMLBP is to define the mean of points over each radial instead of using angular neighbor points (over a circle). This changing strategy enables RMLBP to extract robust features by removing the effect of noisy neighbors over each radial local patch. To make a fair comparison, the proposed method along with known mean filters, including circular and square mean, were applied to noisy textures. Applying RMLBP and the compared LBP variants to the Outex, CUReT and UIUC datasets demonstrated a significant superiority of the proposed method to its counterparts.
C1 [Shakoor, Mohammad Hossein] Islamic Azad Univ, Shiraz Branch, Dept Comp Engn, Shiraz, Iran.
   [Boostani, Reza] Shiraz Univ, Sch Elect & Comp Engn, Comp Engn Dept, Shiraz, Iran.
C3 Islamic Azad University; Shiraz University
RP Shakoor, MH (corresponding author), Islamic Azad Univ, Shiraz Branch, Dept Comp Engn, Shiraz, Iran.
EM mhshakoor@gmail.com; boostani@shirazu.ac.ir
RI Boostani, Reza/ABC-5999-2021
OI Boostani, Reza/0000-0003-0055-4452
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Ahonen Timo., 2007, Proceedings of the Finnish Signal Processing Symposium, FINSIG, P1
   ANYS H, 1995, IEEE T GEOSCI REMOTE, V33, P1170, DOI 10.1109/36.469481
   Arof H, 1998, IEE P-VIS IMAGE SIGN, V145, P167, DOI 10.1049/ip-vis:19981688
   Campisi P, 2004, IEEE T IMAGE PROCESS, V13, P782, DOI 10.1109/TIP.2003.822607
   CHEN JL, 1994, IEEE T PATTERN ANAL, V16, P208, DOI 10.1109/34.273730
   COHEN FS, 1991, IEEE T PATTERN ANAL, V13, P803, DOI 10.1109/34.85670
   Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778
   EICHMANN G, 1988, COMPUT VISION GRAPH, V41, P267, DOI 10.1016/0734-189X(88)90102-8
   Fathi A, 2012, PATTERN RECOGN LETT, V33, P1093, DOI 10.1016/j.patrec.2012.01.017
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Hafiane A, 2007, LECT NOTES COMPUT SC, V4633, P387
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Huang D, 2007, LECT NOTES COMPUT SC, V4842, P437
   Huang X., 2004, Proc. Inter. Conf. Image and Graphics, P184
   Huang Y., 2006, BMVC, P879
   Iakovidis DK, 2008, LECT NOTES COMPUT SC, V5112, P750, DOI 10.1007/978-3-540-69812-8_74
   Ji Q, 2000, IEEE T MED IMAGING, V19, P1144, DOI 10.1109/42.896790
   Jin H, 2004, FACE DETECTION USING, P306, DOI 10.1109/ICIG.2004.62
   KASHYAP RL, 1986, IEEE T PATTERN ANAL, V8, P472, DOI 10.1109/TPAMI.1986.4767811
   Kim ND, 2000, IEEE T SYST MAN CY A, V30, P847, DOI 10.1109/3468.895915
   Kokare M, 2006, IEEE T SYST MAN CY B, V36, P1273, DOI 10.1109/TSMCB.2006.874692
   Kylberg G, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-17
   Lam WK, 1997, IEE P-VIS IMAGE SIGN, V144, P171, DOI 10.1049/ip-vis:19971198
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liu L, 2014, IEEE T IMAGE PROCESS, V23, P3071, DOI 10.1109/TIP.2014.2325777
   Liu L, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.123
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojala T, 1997, ACTA UNIVERSITATIS O, P105
   Pietikäinen M, 2000, PATTERN RECOGN, V33, P43, DOI 10.1016/S0031-3203(99)00032-1
   Ren JF, 2013, IEEE T IMAGE PROCESS, V22, P4049, DOI 10.1109/TIP.2013.2268976
   Shakoor M. H., 2015, IRANIAN J ELECT ELEC, V11, P195
   Shakoor MH, 2017, SCI IRAN, V24, P1
   Shakoor MH, 2017, MULTIMED TOOLS APPL, V76, P8031, DOI 10.1007/s11042-016-3455-6
   Shakoor MH, 2018, MULTIMED TOOLS APPL, V77, P2561, DOI 10.1007/s11042-017-4394-6
   Shakoor MH, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S0218001417500197
   Tajeripour F, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/783898
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168
   Topi M, 2000, TEXTURE CLASSIFICATI
   Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang Z, 2017, PATTERN RECOGN, V67, P263, DOI 10.1016/j.patcog.2017.02.021
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao Y, 2013, NEUROCOMPUTING, V106, P68, DOI 10.1016/j.neucom.2012.10.017
   Zhao Y, 2012, IEEE T IMAGE PROCESS, V21, P4492, DOI 10.1109/TIP.2012.2204271
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
NR 50
TC 21
Z9 21
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21481
EP 21508
DI 10.1007/s11042-017-5440-0
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300051
DA 2024-07-18
ER

PT J
AU Xu, L
   Yan, YH
   Ma, L
   Zhang, Y
AF Xu, Long
   Yan, Yihua
   Ma, Lin
   Zhang, Yun
TI Image processing for synthesis imaging of mingantu spectral
   radioheliograph (MUSER)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed sensing; Solar radio astronomy; Image reconstruction;
   Aperture synthesis
ID UNCERTAINTY PRINCIPLES; SPARSE; DECONVOLUTION
AB MingantU SpEctral Radioheliograph (MUSER) can generate the images of the Sun with high time, frequency and spatial resolutions. It employs the aperture synthesis (AS) principle to image the Sun with plentiful solar radio activities. Different from general imaging system, AS records sparse Fourier components of the spatial image of the Sun by recurring to electromagnetic interference imaging principle. However, due to the limited number of antennas, the recorded Fourier components is extremely sparse, which results in very blurring images. This problem is equivalent to convoluting an image with a Gaussian smoothing filter in spatial domain. Accordingly, one can recover an image from its burred version by inverse operation of convolution, namely deconvolution, which was widely known as CLEAN algorithm. This algorithm however does not perform well on solar images characterized by extended source instead point source. In this paper, a new method based on compressed sensing (CS) is proposed to replace CLEAN for imaging or preceded by CLEAN. It describes itself a standard optimization function constrained by sparseness. Specifically, it adopts structural group dictionary to represent solar images for exploring both local sparsity and non local self-similarity. We also investigate image reconstruction of MUSER in a wider range by employing several state-of-the-art image deburring methods. The performance analysis reveals that the proposed method contributes image quality improvement of MUSER markedly beyond the other methods.
C1 [Xu, Long; Yan, Yihua] Chinese Acad Sci, Key Lab Solar Act, Natl Astron Observ, Beijing, Peoples R China.
   [Ma, Lin] Tencent AI Lab, Shenzhen, Peoples R China.
   [Zhang, Yun] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
C3 Chinese Academy of Sciences; National Astronomical Observatory, CAS;
   Tencent; Chinese Academy of Sciences; Shenzhen Institute of Advanced
   Technology, CAS
RP Xu, L (corresponding author), Chinese Acad Sci, Key Lab Solar Act, Natl Astron Observ, Beijing, Peoples R China.
EM lxu@nao.cas.cn
RI Zhang, Yun/V-7261-2019; Xu, Long/AAH-9908-2019; Yan, Yihua/AGY-9819-2022
OI Zhang, Yun/0000-0001-9457-7801; Xu, Long/0000-0002-9286-2876; Yan,
   Yihua/0000-0002-7106-6029
FU National Natural Science Foundation of China [61572461, 11790300,
   11790305, 11433006]; CAS; Guangdong Natural Science Foundation for
   Distinguished Young Scholar [2016A030306022]; Shenzhen Science and
   Technology Development Project [JSGG20160229202345378]
FX This work was partially supported by the National Natural Science
   Foundation of China under grants 61572461, 11790300, 11790305 and
   11433006, CAS 100-Talents (Dr. Xu Long), Guangdong Natural Science
   Foundation for Distinguished Young Scholar under Grant 2016A030306022,
   Shenzhen Science and Technology Development Project under Grant
   JSGG20160229202345378.
CR Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250
   Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P2992, DOI 10.1109/TIP.2007.909319
   Bobin J, 2002, IEEE J SEL TOP QUANT, V2, P718
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Cornwell TJ, 2008, IEEE J-STSP, V2, P793, DOI 10.1109/JSTSP.2008.2006388
   CORNWELL TJ, 1985, ASTRON ASTROPHYS, V143, P77
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Donoho DL, 2001, IEEE T INFORM THEORY, V47, P2845, DOI 10.1109/18.959265
   Du J., 2013, IAU S, P501
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Hogbom J. A., 1974, Astronomy and Astrophysics Supplement Series, V15, P417
   Li F, 2012, ASTRON ASTROPHYS, V531, P8
   Li F., 2011, A A, V528, P10
   Ma S., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587391
   Rubinstein R, 2013, IEEE T SIGNAL PROCES, V61, DOI 10.1109/TSP.2012.2226445
   Rubinstein R, 2010, IEEE T SIGNAL PROCES, V58, P1553, DOI 10.1109/TSP.2009.2036477
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Starck JL, 2002, PUBL ASTRON SOC PAC, V114, P1051, DOI 10.1086/342606
   Su M, 2002, PATTERN RECOGN, V35, P2881, DOI 10.1016/S0031-3203(01)00239-4
   WAKKER BP, 1988, ASTRON ASTROPHYS, V200, P312
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WEIR N, 1992, ASTR SOC P, V25, P186
   Wen YW, 2012, IEEE T IMAGE PROCESS, V21, P106, DOI 10.1109/TIP.2011.2159983
   Wenger S, 2010, PUBL ASTRON SOC PAC, V122, P1367, DOI 10.1086/657252
   Wiaux Y, 2009, MON NOT R ASTRON SOC, V395, P1733, DOI 10.1111/j.1365-2966.2009.14665.x
   Xiang SM, 2015, INT J COMPUT VISION, V114, P248, DOI 10.1007/s11263-014-0755-z
   Yan Y, 2009, EARTH MOON PLANETS, V104, P97, DOI 10.1007/s11038-008-9254-y
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zhang J, 2014, IEEE T IMAGE PROCESS, V23, P3336, DOI 10.1109/TIP.2014.2323127
   Zhang J, 2014, IEEE T CIRC SYST VID, V24, P915, DOI 10.1109/TCSVT.2014.2302380
NR 32
TC 1
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 20937
EP 20954
DI 10.1007/s11042-017-5545-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300028
DA 2024-07-18
ER

PT J
AU Zhang, P
   Zheng, LH
   Jiang, Y
   Mao, LJ
   Li, Z
   Sheng, B
AF Zhang, Pei
   Zheng, Linghan
   Jiang, Yan
   Mao, Lijuan
   Li, Zhen
   Sheng, Bin
TI Tracking soccer players using spatio-temporal context learning under
   multiple views
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Soccer players tracking; Spatio-temporal context; Multi-views;
   Multi-objects
AB With the popularity of soccer games and rapid development of computer technology, automatic soccer analysis systems have been studied a lot these years. Tracking soccer players, as the fundamental step in an analysis system, is of great research value and draws attention from researchers all over the world. In this paper, we propose an effective method which makes an improvement on spatiotemporal context learning and increases the accuracy by combining information from multiple views. At the same time, a two-dimensional plane graph is displayed to show the players' movements correspondingly. Experiments are conducted on several video fragments and the results have shown that the proposed method reaches a relatively high accuracy even when there are heavy occlusions and pose variations.
C1 [Zhang, Pei; Zheng, Linghan; Jiang, Yan; Sheng, Bin] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China.
   [Mao, Lijuan; Li, Zhen] Shanghai Univ Sports, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University; Shanghai University of Sport
RP Sheng, B (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China.
EM shengbin@cs.sjtu.edu.cn
FU STCSM of Shanghai, China [15490503200]; National Natural Science
   Foundation of China [61572316, 61671290]; National High-tech R&D Program
   of China (863 Program) [2015AA015904]; Key Program for International S&T
   Cooperation Project of China [2016YFE0129500]; Science and Technology
   Commission of Shanghai Municipality [16DZ0501100, 17411952600];
   interdisciplinary Program of Shanghai Jiao Tong University [14JCY10];
   Research Grants Council of Hong Kong [28200215]
FX The authors would like to thank Yuchen Xia for participating program
   testing and helpful discussion. The work is supported by the STCSM of
   Shanghai, China (grant number: 15490503200, the National Natural Science
   Foundation of China (No. 61572316, 61671290), National High-tech R&D
   Program of China (863 Program) (No. 2015AA015904), the Key Program for
   International S&T Cooperation Project (No. 2016YFE0129500) of China, the
   Science and Technology Commission of Shanghai Municipality (No.
   16DZ0501100, 17411952600), the interdisciplinary Program of Shanghai
   Jiao Tong University (No. 14JCY10), and a grant from the Research Grants
   Council of Hong Kong (No. 28200215).
CR [Anonymous], 2006, 2006 IEEE COMP SOC C, DOI DOI 10.1109/CVPR.2006.198
   [Anonymous], 2012, EUR C COMP VIS
   Bar-Shalom Y., 1987, J ACOUST SOC AM, V87, P918
   Baysal S, 2016, IEEE T CIRC SYST VID, V26, P1350, DOI 10.1109/TCSVT.2015.2455713
   Bebie T, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P898, DOI 10.1109/ICIP.1998.723665
   Boyle, 2014, CENGAGE LEARNING
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cuevas E, 1986, IEEE T PATTERN ANAL, V9, P679
   Grabner H., 2006, BMVC, P47
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Herrmann M, 2014, SECS
   Hue C, 2002, IEEE T AERO ELEC SYS, V38, P791, DOI 10.1109/TAES.2002.1039400
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Luo W, 2014, CVPR
   Najafzadeh N, 2015, AISP
   Oh S, 2005, C DEC CONTR
   Sullivan J, 2006, LECT NOTES COMPUT SC, V3953, P619, DOI 10.1007/11744078_48
   Zhang K, 2013, COMPUT SCI, DOI DOI 10.48550/ARXIV.1311.1939
NR 18
TC 12
Z9 13
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 18935
EP 18955
DI 10.1007/s11042-017-5316-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500003
DA 2024-07-18
ER

PT J
AU Joshi, VB
   Raval, MS
   Kuribayashi, M
AF Joshi, Vaibhav B.
   Raval, Mehul S.
   Kuribayashi, Minoru
TI Reversible data hiding based compressible privacy preserving system for
   color image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Entropy; Lossless compression; Privacy-preservation; Reversible data
   hiding
ID PREDICTION-ERROR EXPANSION; HISTOGRAM-MODIFICATION; DIFFERENCE
   EXPANSION; SCHEME; WATERMARK
AB In digital era, privacy preservation and data size reduction are important issues and many applications handle them simultaneously. In this paper, authors introduce a novel application of reversible data hiding to protect privacy sensitive region in a color image while reducing its file size. The proposed work introduces entropy as a new performance criterion along with distortion, capacity for reversible data hiding. Evaluation metric of the proposed method is a file size of watermarked and losslessly compressed image. The proposed method preserves privacy and controls rise in image entropy by reversible data hiding.
C1 [Joshi, Vaibhav B.; Raval, Mehul S.] Ahmedabad Univ, Sch Engn & Appl Sci, Ahmadabad, Gujarat, India.
   [Kuribayashi, Minoru] Okayama Univ, Grad Sch Nat Sci & Technol, Okayama, Japan.
C3 Ahmedabad University; Okayama University
RP Joshi, VB (corresponding author), Ahmedabad Univ, Sch Engn & Appl Sci, Ahmadabad, Gujarat, India.
EM vaibhav.joshi@ahduni.edu.in; mehul.raval@ahduni.edu.in;
   kminoru@okayama-u.ac.jp
RI Raval, Mehul S/Y-7493-2019; Kuribayashi, Minoru/AAL-4149-2020; Raval,
   Mehul S/IWM-4799-2023
OI Raval, Mehul S/0000-0002-3895-1448; Kuribayashi,
   Minoru/0000-0003-4844-2652; Raval, Mehul S/0000-0002-3895-1448
FU Grants-in-Aid for Scientific Research [16K00185] Funding Source: KAKEN
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], 1993, 244 U SO CAL DEP EL
   [Anonymous], 2016, ARXIV161009462
   Boult TE, 2006, COMPUTER VISION FOR INTERACTIVE AND INTELLIGENT ENVIRONMENTS, P27
   Chen YH, 2016, MULTIMED TOOLS APPL, V75, P13679, DOI 10.1007/s11042-015-2825-9
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Daemen J., 2013, AES ADV ENCRYPTION S
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Dufaux F, 2010, IEEE INT CON MULTI, P66, DOI 10.1109/ICME.2010.5583552
   Dufaux F, 2008, IEEE IMAGE PROC, P1688, DOI 10.1109/ICIP.2008.4712098
   Farrugia RA, 2014, 2014 37TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1258, DOI 10.1109/MIPRO.2014.6859760
   Huang HC, 2011, SENSORS-BASEL, V11, P9717, DOI 10.3390/s111009717
   Joshi Madhuri A, 2014, Image and video compression: Fundamentals, Techniques, and Applications
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Knudsen LR, 1998, LECT NOTES COMPUT SC, V1528, P18
   Kuribayashi M, 2008, IEICE T FUND ELECTR, VE91A, P1780, DOI 10.1093/ietfec/e91-a.7.1780
   Li J, 2013, SIGNAL PROCESS, V93, P2748, DOI 10.1016/j.sigpro.2013.01.020
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Liu Y, 2012, INT C PATT RECOG, P898
   Nelson M., 1996, DATA COMPRESSION BOO, V2
   Niimi M, 2012, I S INTELL SIG PROC
   Ou B, 2015, SIGNAL PROCESS, V108, P642, DOI 10.1016/j.sigpro.2014.10.012
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Pan Qu J., 2016, J. Inf. Hiding Multim. Signal Process., V7, P1194
   Parmar C, 2011, P CENT C EL ENG IISC, P415
   Qin C, 2013, IMAGING SCI J, V61, P509, DOI 10.1179/1743131X12Y.0000000015
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Thodi DM, 2004, IEEE IMAGE PROC, P1549
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Westin A. F., 1967, PRIVACY FREEDOM
   Wu HT, 2015, IEEE SIGNAL PROC LET, V22, P81, DOI 10.1109/LSP.2014.2346989
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Yu J, 2017, IEEE T INF FOREN SEC, V12, P1005, DOI 10.1109/TIFS.2016.2636090
   Zhang Q.Y., 2017, J INFORM HIDING MULT, V8, P392
   Zhang WM, 2013, IEEE T IMAGE PROCESS, V22, P2775, DOI 10.1109/TIP.2013.2257814
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zhang YS, 2014, COMMUN NONLINEAR SCI, V19, P74, DOI 10.1016/j.cnsns.2013.06.031
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 44
TC 1
Z9 1
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16597
EP 16622
DI 10.1007/s11042-017-5230-8
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300028
DA 2024-07-18
ER

PT J
AU Linda, CH
   Jiji, GW
AF Linda, C. Harriet
   Jiji, G. Wiselin
TI Hairline breakage detection in X-ray images using data fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anisotropic diffusion; Maximum likelihood estimation; Discretewavelet
   transform; Expectation-maximization (EM) algorithm
ID WATERSHED TRANSFORM; SEGMENTATION; SPECIFICITY; SENSITIVITY
AB This paper deals with identification of hairline breakage in the X-Ray images. The crack in the X-Ray images can be missed due to absence of sharp edges and the intensity inhomogeneity. This work is carried out in two phases. In the first phase the preprocessing step is done using anisotropic diffusion filter and wavelet to preserve the edges and fine details. In the second phase Expectation Maximization (EM) algorithm is used for segmenting the image. The mask produced from the EM algorithm separates the bone region. The intensity variation calculation is performed over the selected region to detect the cracks. The performance of the proposed work is calculated using the parameters sensitivity and accuracy. This new approach is experimented with ten patient's data and validated by Radiologists. The performance of the proposed work is compared with recent works. This work greatly improves the accuracy of the segmentation on medical images and the overall accuracy is about 98%.
C1 [Linda, C. Harriet] CSI Inst Technol, Dept Comp Sci & Engn, Thovalai 629302, Tamil Nadu, India.
   [Jiji, G. Wiselin] Dr Sivanthi Aditanar Coll Engn, Dept Comp Sci & Engn, Tiruchendur, Tamil Nadu, India.
RP Linda, CH (corresponding author), CSI Inst Technol, Dept Comp Sci & Engn, Thovalai 629302, Tamil Nadu, India.
EM harriet_linda@yahoo.com; jijivevin@yahoo.co.in
RI Linda, Harriet/AAE-6915-2019
CR [Anonymous], P INT C IM PROC ICIP
   [Anonymous], 2006, INT C COMP GRAPH IM, DOI DOI 10.1109/CGIV.2006.16
   Bilmes J., GENTLE TUTORIAL EM A
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Cakiroglu M., 2012, P SIGN PROC COMM APP, P1
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chowdhury AS, 2006, I S BIOMED IMAGING, P1320
   Chowdhury A.S., 2007, IEEE INT WKSHP APPL, P56
   Grau V, 2004, IEEE T MED IMAGING, V23, P447, DOI 10.1109/TMI.2004.824224
   He JC, 2007, LECT NOTES COMPUT SC, V4673, P962
   Houssami N, 2003, AM J ROENTGENOL, V180, P935, DOI 10.2214/ajr.180.4.1800935
   Jacob N.E., 2013, Int. J. Comput. Appl., V71
   Knowles G, 2008, LNCS, V5099, P153
   Krupinski E.A., 2017, FRONTLINE LEARNING R, V5, P31, DOI [10.14786/flr.v5i2.250, DOI 10.14786/FLR.V5I2.250]
   Kwon GR, 2016, INT J IMAG SYST TECH, V26, P225, DOI 10.1002/ima.22181
   Lim S.E., 2004, P 2 INT C ADV MED SI, VVolume 65
   Linda CH, 2011, APPL SOFT COMPUT, V11, P3571, DOI 10.1016/j.asoc.2011.01.029
   Mahendran SK., 2011, Glob J. Comput. Sci. Technol, V11, P22
   Mahmoodi S, 2011, SIGNAL PROCESS, V91, P1298, DOI 10.1016/j.sigpro.2010.12.018
   Mansoory M. S., 2012, World Applied Sciences Journal, V18, P1602
   McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7
   Mendrik AM, 2009, IEEE T MED IMAGING, V28, P1585, DOI 10.1109/TMI.2009.2022368
   Panchasara C., 2015, INT J COMPUTER SCI I, V6, P2931
   Reitsma JB, 2005, J CLIN EPIDEMIOL, V58, P982, DOI 10.1016/j.jclinepi.2005.02.022
   Rogowska J, 2000, BIOMED EN S, P69
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Sharan V, 2014, INT J INNOVATIVE SCI, V2, P9
   Thakare Punam., 2011, International Journal on Computer Science and Engineering (IJCSE), V3, P899
   Tian TP, 2003, LECT NOTES COMPUT SC, V2756, P82
   Yap DWH, 2004, INT C PATT RECOG, P730
   Yogeswara Rao K, 2012, IJCST, V3, P658
NR 31
TC 4
Z9 4
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 17207
EP 17222
DI 10.1007/s11042-017-5286-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300054
DA 2024-07-18
ER

PT J
AU Singh, KM
AF Singh, Kh. Manglem
TI A robust rotation resilient video watermarking scheme based on the SIFT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Copyright protection; Discrete wavelet transform;
   Restoration; Rotation attack; Robust
ID IMAGE WATERMARKING; SECURE; SYSTEM
AB This paper proposes a blind and robust video watermarking algorithm for copyright protection of the video in the wavelet transform. The watermark bit is embedded by modifying two random high frequency coefficients in the first level discrete wavelet transform of the frames of the video. The watermark is encrypted before embedding by using the cat map for better security. During the watermark extraction phase, it is verified whether the video is attacked by rotation attack. Frame restoration against rotation attack is done based on matching at least two feature points each generated by the scale invariant feature transform in the original video frame and the watermarked one. The angle between the two lines formed by joining these feature points is used to restore the video frames to the original position. Experimental results show the imperceptibility and robustness of the proposed method against variety of attacks. It is especially robust against rotation attack in comparison with other popular watermarking methods. Normalized Correlation, Structural Similarity Index and Peak Signal-to-Noise-Ratio are nearly 100%, 1, above 48 dB respectively against the various attacks.
C1 [Singh, Kh. Manglem] Natl Inst Technol Manipur, Dept Comp Sci & Engn, Imphal, Manipur, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Manipur
RP Singh, KM (corresponding author), Natl Inst Technol Manipur, Dept Comp Sci & Engn, Imphal, Manipur, India.
EM manglem@gmail.com
RI Singh, Khumanthem/AFZ-2177-2022
OI Singh, Khumanthem/0000-0002-6698-1185
CR Al-Taweel FAP., 2009, TENCON IEEE REGION 1, P1
   Arab F, 2016, MULTIMED TOOLS APPL, V75, P10855, DOI 10.1007/s11042-015-2800-5
   Asikuzzaman Md, 2014, IEEE Transactions on Information Forensics and Security, V9, P1502, DOI 10.1109/TIFS.2014.2338274
   Cedillo-Hernandez M, 2013, RADIOENGINEERING, V22, P1057
   Choi D, 2010, SIGNAL PROCESS, V90, P1327, DOI 10.1016/j.sigpro.2009.10.009
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Deng Cheng, 2009, Acta Photonica Sinica, V38, P1005
   Devi BP, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-2733-0
   Do H, 2008, IEEE INT SYMP SIGNAL, P330, DOI 10.1109/ISSPIT.2008.4775680
   Gaj S, 2016, MULTIMED TOOLS APPL, V75, P3053, DOI 10.1007/s11042-014-2422-3
   Goel B, 2014, ADV COMPUTING NETWOR, P295
   Hartung F, 1999, P IEEE, V87, P1079, DOI 10.1109/5.771066
   Hartung F, 1998, SIGNAL PROCESS, V66, P283, DOI 10.1016/S0165-1684(98)00011-5
   Huang HY, 2010, IEEE T INF FOREN SEC, V5, P625, DOI 10.1109/TIFS.2010.2080675
   Jung HS, 2004, EURASIP J APPL SIG P, V2004, P2113, DOI 10.1155/S1110865704405046
   Kalker T, 1999, PROC SPIE, V3657, P103, DOI 10.1117/12.344661
   Karmakar A, 2016, J KING SAUD UNIV-COM, V28, P199, DOI 10.1016/j.jksuci.2014.06.019
   Keshavarzian R, 2016, AEU-INT J ELECTRON C, V70, P278, DOI 10.1016/j.aeue.2015.12.003
   Kohda T., 1990, Transactions of the Institute of Electronics, Information and Communication Engineers E, VE73, P793
   Lancini R, 2002, PROCEEDINGS VIPROMCOM-2002, P251, DOI 10.1109/VIPROM.2002.1026664
   Lee MJ, 2012, DIGIT SIGNAL PROCESS, V22, P190, DOI 10.1016/j.dsp.2011.08.001
   Lee SJ, 2001, ISIE 2001: IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS PROCEEDINGS, VOLS I-III, P272, DOI 10.1109/ISIE.2001.931796
   Lee YP, 2012, INFORM SCIENCES, V191, P214, DOI 10.1016/j.ins.2012.01.002
   Li D, 2016, MULTIMED TOOLS APPL, V75, P13093, DOI 10.1007/s11042-015-2733-z
   Liu Y, 2010, SIGNAL PROCESS, V90, P626, DOI 10.1016/j.sigpro.2009.08.001
   Loganathan A, 2016, EXPERT SYST APPL, V63, P412, DOI 10.1016/j.eswa.2016.05.019
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo HJ, 2011, RADIOENGINEERING, V20, P525
   Masoumi M, 2015, AEU-INT J ELECTRON C, V69, P138, DOI 10.1016/j.aeue.2015.09.015
   Masoumi M, 2013, AEU-INT J ELECTRON C, V67, P528, DOI 10.1016/j.aeue.2012.11.009
   Matsumoto M., 1998, ACM Transactions on Modeling and Computer Simulation, V8, P3, DOI 10.1145/272991.272995
   Mohammadi S., 2015, CIENCIA NATURA, V37, P364
   Narkedamilly L, 2015, ETRI J, V37, P595, DOI 10.4218/etrij.15.0114.0012
   Nasir I, 2012, IET IMAGE PROCESS, V6, P354, DOI 10.1049/iet-ipr.2010.0421
   Patra JC, 2010, DIGIT SIGNAL PROCESS, V20, P1597, DOI 10.1016/j.dsp.2010.03.010
   Petticolas F, 2000, INFORM HIDING TECHNI
   Preda RO, 2010, MEASUREMENT, V43, P1720, DOI 10.1016/j.measurement.2010.07.009
   Preda RO, 2012, 7 INT C DIG TEL, P78
   Qi XJ, 2007, SIGNAL PROCESS, V87, P1264, DOI 10.1016/j.sigpro.2006.11.002
   Rajab L., 2015, J Softw Eng Appl, V08, P224, DOI [10.4236/jsea.2015.84023, DOI 10.4236/JSEA.2015.84023]
   Rey-Otero I, 2014, IMAGE PROCESS ON LIN, V4, P370, DOI 10.5201/ipol.2014.82
   Singh TR, 2013, AEU-INT J ELECTRON C, V67, P645, DOI 10.1016/j.aeue.2013.01.008
   Sun QB, 2006, IEEE T CIRC SYST VID, V16, P1232, DOI 10.1109/TCSVT.2006.882540
   Thanh TM, 2014, AEU-INT J ELECTRON C, V68, P1007, DOI 10.1016/j.aeue.2014.05.004
   Thounaojam DM, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/8469428
   Wang YL, 2006, IEEE T IMAGE PROCESS, V15, P1536, DOI 10.1109/TIP.2006.873476
   Wu D, 2009, SOFT COMPUT, V13, P375, DOI 10.1007/s00500-008-0328-6
   Xu DW, 2011, SIGNAL PROCESS-IMAGE, V26, P267, DOI 10.1016/j.image.2011.04.008
   Xue JX, 2011, PROCEDIA ENGINEER, V24, P90, DOI 10.1016/j.proeng.2011.11.2607
   Yassin NI, 2014, ALEX ENG J, V53, P833, DOI 10.1016/j.aej.2014.07.008
   Zhaofeng MA, 2016, CHINESE J ELECTRON, V25, P641
NR 51
TC 18
Z9 18
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16419
EP 16444
DI 10.1007/s11042-017-5213-9
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300019
DA 2024-07-18
ER

PT J
AU Xu, T
   Liu, F
   Wu, CK
AF Xu, Tao
   Liu, Feng
   Wu, Chuankun
TI A white-box AES-like implementation based on key-dependent
   substitution-linear transformations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE White-box cryptography; AES-like; MDS matrix; Key-dependent; Key
   extraction; Malware
AB It is becoming increasingly common to deploy cryptographic algorithms within software applications which are executed in untrusted environments owned and controlled by a possibly malicious party. White-box cryptography aims to protect the secret key in such an environment. Chow et al. developed a white-box AES implementation in 2002 by hiding secret keys into lookup tables. Afterwards, some improvements were proposed. However, all the published schemes have been shown to be insecure. AES was originally designed without consideration of execution in a white-box attack context. Because of the fixed confusion and diffusion operations, it is easy to break AES's white-box version. In this paper, we propose an AES-like cipher by replacing AES's S-boxes and MixColumn matrices with key-dependent components while keeping their good cryptographic properties. We show that the white-box implementation of our AES-like cipher can resist current known attacks.
C1 [Xu, Tao; Liu, Feng] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing, Peoples R China.
   [Xu, Tao; Liu, Feng] Univ Chinese Acad Sci, Sch Cyber Secur, Beijing, Peoples R China.
   [Liu, Feng] Guizhou Normal Univ, Sch Big Data & Comp Sci, Guiyang, Guizhou, Peoples R China.
   [Wu, Chuankun] Beijing Kuangen Network Technol Co Ltd, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Information Engineering, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Guizhou Normal University
RP Liu, F (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing, Peoples R China.; Liu, F (corresponding author), Univ Chinese Acad Sci, Sch Cyber Secur, Beijing, Peoples R China.; Liu, F (corresponding author), Guizhou Normal Univ, Sch Big Data & Comp Sci, Guiyang, Guizhou, Peoples R China.
EM xutao@iie.ac.cn; liufeng@iie.ac.cn; chuankun.wu@gmail.com
RI liu, feng/B-3050-2019
FU National Key R&D Program of China [2016YFB0800100]; CAS Strategic
   Priority Research Program [XDA06010701]; National Natural Science
   Foundation of China [61671448, U1636101]
FX This work was supported in part by the National Key R&D Program of China
   with No. 2016YFB0800100, in part by the CAS Strategic Priority Research
   Program with No. XDA06010701, and in part by the National Natural
   Science Foundation of China with No. 61671448 and No. U1636101.
CR [Anonymous], P 9 WORKSH SEL AR CR
   [Anonymous], 2009, REV REMOTE SENSING A, DOI DOI 10.1109/CSA.2009.5404239
   [Anonymous], 2014, LNCS
   [Anonymous], 2013, LNCS, DOI DOI 10.1007/978-3-662-43414-7_14
   Bai KP, 2016, COMPUT J, V59, P1054, DOI 10.1093/comjnl/bxv119
   Billet O., 2004, Selected Areas in Cryptography. 11th International Workshop, SAC 2004. Revised Selected Papers (Lecture Notes in Computer Science Vol.3357), P227
   Biryukov A, 2003, LECT NOTES COMPUT SC, V2656, P33
   Biryukov A, 2010, J CRYPTOL, V23, P505, DOI 10.1007/s00145-010-9062-1
   Bogdanov A, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1058, DOI 10.1145/2810103.2813699
   Chow S, 2002, LECT NOTES COMPUT SC, V2696, P1
   Daemen J., 2013, DESIGN RIJNDAEL AES
   De Mulder Yoni., 2013, Selected Areas in Cryptography, P34, DOI 10.1007/978-3-642-35999-6_3
   Goubin L, 2007, LECT NOTES COMPUT SC, V4876, P278
   Jacob M, 2002, LECT NOTES COMPUT SC, V2696, P16
   Karroumi Mohamed, 2010, Information Security and Cryptology - ICISC 2010. 13th International Conference. Revised Selected Papers, P278, DOI 10.1007/978-3-642-24209-0_19
   Link HE, 2005, ITCC 2005: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 1, P679, DOI 10.1109/ITCC.2005.100
   MacWilliams F. J., 1978, The Theory of Error-Correcting Codes
   Michiels W, 2008, LNCS, P414
   Muir JA, 2012, ADV NETWORK ANAL ITS, P209
   Pub NF, 2001, FEDERAL INFORM PROCE, V197
   Shi Y, 2013, J APPL MATH, DOI 10.1155/2013/431794
   Wyseur B, 2007, LECT NOTES COMPUT SC, V4876, P264
   Youssef AM, 2006, DISCRETE MATH, V306, P2016, DOI 10.1016/j.disc.2006.03.055
NR 23
TC 5
Z9 8
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18117
EP 18137
DI 10.1007/s11042-017-4562-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900030
DA 2024-07-18
ER

PT J
AU Al-Otum, H
   Al-Shalabi, NE
AF Al-Otum, Hazem
   Al-Shalabi, Nour Emad
TI Copyright protection of color images for android-based smartphones using
   watermarking with quick-response code
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Android; DWT; SHA-256; Characteristic regions
ID SCHEME; ROBUST
AB In this paper, a color image watermarking scheme for copyright protection is proposed and designed to be implemented for Android-based smartphones. Characteristic-based image watermarking techniques were modified and made suitable for power limited smartphones. The security features were improved through implementing image scrambling on the watermark prior to embedding into the DWT domain. The features of the QR codes, including the high capacity and error correction capabilities, were exploited and employed. The QR codes were used as the watermarks to carry the ownership information. The proposed scheme was robust against JPEG compression with about 60-70% compression ratio and it resists noise attacks at noisy image quality with PSNR = 15-35 dB. Moreover, robustness against various malicious attacks was achieved including image cropping, object replacement, etc. An Android application has been developed, based on the proposed scheme, to demonstrate the capabilities of this study.
C1 [Al-Otum, Hazem; Al-Shalabi, Nour Emad] Jordan Univ Sci & Technol, EE Dept, POB 3030, Irbid 22110, Jordan.
C3 Jordan University of Science & Technology
RP Al-Otum, H (corresponding author), Jordan Univ Sci & Technol, EE Dept, POB 3030, Irbid 22110, Jordan.
EM hazem-ot@just.edu.jo
OI Al-Otum, Hazem/0000-0002-3628-3191
CR Andreucetti R, 2014, INT WIREL COMMUN, P1147, DOI 10.1109/IWCMC.2014.6906516
   Anitha J., 2010, IJCSI INT J COMPUTER, V7, P302
   [Anonymous], IS ENERGY SPENT INSI
   [Anonymous], 2000, 180042006 BS ISOIEC
   AREEPONGSA S, 2000, P IEEE TENCON KUAL L, V3, P250
   Chen JH, 2014, APPL MATH INFORM SCI, V8, P585, DOI 10.12785/amis/080216
   Denso A., 2011, QR CODE ESSENTIALS D, V900
   Dewangan Ravi Prakash, 2015, INT J SCI ENG TECHNO, V4, P3531
   Gilbert H., 2003, INT WORKSH SEL AR CR
   Hamid N., 2012, 2012 International Conference on Future Communication Networks (ICFCN), P141, DOI 10.1109/ICFCN.2012.6206858
   Hashmi MF, 2015, PROCEDIA COMPUT SCI, V46, P1626, DOI 10.1016/j.procs.2015.02.096
   Huang HC, 2010, SIMUL MODEL PRACT TH, V18, P436, DOI 10.1016/j.simpat.2009.09.004
   JIN C, 2007, IJCSES INT J COMPUTE, V1, P119
   Keissarian Farhad, 2007, Innovations'07. 4th International Conference on Innovations in Information Technology, P665
   Khan AA, 2011, CSECS 11 MECHANICS 1, P168
   [李昌刚 Li Changgang], 2002, [计算机研究与发展, Computer Research and Development], V39, P1317
   Li LD, 2011, AEU-INT J ELECTRON C, V65, P435, DOI 10.1016/j.aeue.2010.06.001
   Miao N., 2012, P INT C ONWIRELESS N, P348
   Muhle F, 2014, M K MEDIEN KOMMUNIKA, V62, P662
   Owen S., 2013, Zxing
   Patidar V, 2011, OPT COMMUN, V284, P4331, DOI 10.1016/j.optcom.2011.05.028
   Swanson MD, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P211, DOI 10.1109/ICIP.1996.560421
   Wang SH, 2004, IEEE T IMAGE PROCESS, V13, P154, DOI 10.1109/TIP.2004.823822
   Wang XY, 2013, J SYST SOFTWARE, V86, P255, DOI 10.1016/j.jss.2012.08.015
   Yueh-Hong Chen, 2011, 2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing, P21, DOI 10.1109/IIHMSP.2011.94
NR 25
TC 6
Z9 6
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15625
EP 15655
DI 10.1007/s11042-017-5138-3
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200052
DA 2024-07-18
ER

PT J
AU Laaroussi, K
   Saaidi, A
   Masrar, M
   Satori, K
AF Laaroussi, Khadija
   Saaidi, Abderrahim
   Masrar, Mohamed
   Satori, Khalid
TI Human tracking using joint color-texture features and
   foreground-weighted histogram
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human tracking; Mean shift algorithm; Color-texture histogram;
   Foreground-weighted histogram
ID ROBUST OBJECT TRACKING; MEAN-SHIFT TRACKING; VISUAL TRACKING;
   CLASSIFICATION
AB This paper proposes a new appearance model for human tracking based on Mean Shift framework. The proposed method uses a novel target representation by using joint Color-Texture features and Foreground-Weighted Histogram (CTFWH) for a more distinctive and effective target representation. Our contribution is threefold: firstly, to exploit the texture information of the target, we have used joint color-texture histogram to represent the target. Local Binary Pattern (LBP) technique is employed to identify texture features in the target region. Secondly, we have proposed a representation model of the foreground region named Foreground-Weighted Histogram (FWH), in order to exploit the significant features of the foreground region and to use it for selecting only the salient parts from the target model. Thirdly, we propose a simple method to update the foreground model due to the important foreground changes over the tracking process. Hence, by combining these concepts we generate new features for target representation and human tracking. The proposed method is designed for human tracking in complex scenarios and tested for comparative results with existing state-of-the-art algorithms. Experimental results on numerous challenging video sequences verify the significance of the proposed approach in terms of robustness and performance to complex background, illumination and appearance changes, similar target and background appearance, presence of distractors, target and camera motion, occlusions and large background variation.
C1 [Laaroussi, Khadija; Saaidi, Abderrahim; Masrar, Mohamed; Satori, Khalid] Sidi Mohamed Ben Abdellah Univ, Dept Math & Comp Sci, Fac Sci, LIIAN, BP 1796, Fes, Atlas, Morocco.
   [Saaidi, Abderrahim] Sidi Mohamed Ben Abdellah Univ, Polydisciplinary Fac Taza, Dept Math Phys & Comp Sci, LSI, BP 1223, Taza, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP Laaroussi, K (corresponding author), Sidi Mohamed Ben Abdellah Univ, Dept Math & Comp Sci, Fac Sci, LIIAN, BP 1796, Fes, Atlas, Morocco.
EM khadija.laaroussi3@usmba.ac.ma; abderrahim.saaidi@usmba.ac.ma;
   masrar.m@hotmail.com; khalidsatorim3i@yahoo.fr
RI Saaidi, Abderrahim/R-1916-2019; satori, khalid/GSE-3077-2022
OI SATORI, khalid/0000-0001-6055-4169; Saaidi,
   Abderrahim/0000-0003-1708-0468
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   Birchfield ST, 2005, PROC CVPR IEEE, P1158
   Bouachir W, 2015, COMPUT VIS IMAGE UND, V137, P88, DOI 10.1016/j.cviu.2015.03.010
   Bousetouane F, 2013, VISUAL COMPUT, V29, P155, DOI 10.1007/s00371-012-0677-0
   Bradski G.R., 1998, INTEL TECHNOLOGY J, V2, P12
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330
   Georgescu B, 2004, IEEE T PATTERN ANAL, V26, P674, DOI 10.1109/TPAMI.2004.2
   Guo QC, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS I-V, CONFERENCE PROCEEDINGS, P2314, DOI 10.1109/ICMA.2007.4303914
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   Haritaoglu I, 2001, PROC CVPR IEEE, P431
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Huchuan Lu, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P539, DOI 10.1109/FG.2011.5771455
   ITO Y, 1991, NEURAL NETWORKS, V4, P385, DOI 10.1016/0893-6080(91)90075-G
   Jeyakar J, 2008, COMPUT VIS IMAGE UND, V112, P296, DOI 10.1016/j.cviu.2008.05.005
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Jodoin JP, 2014, IEEE WINT CONF APPL, P885, DOI 10.1109/WACV.2014.6836010
   KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532
   Kettnaker V., 1999, Proceedings of Computer Vision and Pattern Recognition, V2, P259
   Laaroussi K., 2014, Journal of Emerging Technologies in Web Intelligence, V6, P94, DOI 10.4304/jetwi.6.1.94-100
   Laaroussi K., 2014, WORLD APPL SCI J, V32, P289, DOI DOI 10.5829/ID0SI.WASJ.2014.32.02.343
   Laaroussi K, 2016, 3D RES, V7, DOI 10.1007/s13319-016-0097-4
   Laaroussi K, 2016, LECT NOTES ELECTR EN, V380, P297, DOI 10.1007/978-3-319-30301-7_31
   Lei BJ, 2006, PATTERN RECOGN LETT, V27, P1816, DOI 10.1016/j.patrec.2006.02.017
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Li X, 2013, PROC CVPR IEEE, P2419, DOI 10.1109/CVPR.2013.313
   Liu XL, 2016, IEEE T CYBERNETICS, V46, P2252, DOI 10.1109/TCYB.2015.2474742
   Liu XL, 2016, IEEE T IMAGE PROCESS, V25, P907, DOI 10.1109/TIP.2015.2505180
   Ma YH, 2011, IEEE T MAGN, V47, P970, DOI 10.1109/TMAG.2010.2076401
   Ning JF, 2009, INT J PATTERN RECOGN, V23, P1245, DOI 10.1142/S0218001409007624
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pan Z, 2017, MULTIMED TOOLS APPL, V76, P16989, DOI 10.1007/s11042-016-3647-0
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1
   Polat E, 2006, IEEE T MULTIMEDIA, V8, P1156, DOI 10.1109/TMM.2006.884624
   Porikli F, 2005, PROC CVPR IEEE, P829, DOI 10.1109/CVPR.2005.188
   Pu Xiaorong, 2012, International Journal of Image, Graphics and Signal Processing, V4, P34, DOI 10.5815/ijigsp.2012.12.05
   Qiu-Hong Zhou, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P545, DOI 10.1109/FG.2011.5771456
   Senior A, 2006, IMAGE VISION COMPUT, V24, P1233, DOI 10.1016/j.imavis.2005.06.007
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Wang DJ, 2016, MULTIMED TOOLS APPL, V75, P10271, DOI 10.1007/s11042-015-3078-3
   Wang D, 2015, IEEE T CYBERNETICS, V45, P1838, DOI 10.1109/TCYB.2014.2360924
   Wang JQ, 2008, IEEE T IMAGE PROCESS, V17, P235, DOI 10.1109/TIP.2007.914150
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Yang C, 2005, PROC CVPR IEEE, P176
   Yilmaz A, 2004, IEEE T PATTERN ANAL, V26, P1531, DOI 10.1109/TPAMI.2004.96
   Zhang K, 2013, 13111939 ARXIV
   Zhang XA, 2010, INT C WAVEL ANAL PAT, P38, DOI 10.1109/ICWAPR.2010.5576453
   Zhao Q, 2010, IEEE T PATTERN ANAL, V32, P274, DOI 10.1109/TPAMI.2008.299
   Zhong W, 2014, IEEE T IMAGE PROCESS, V23, P2356, DOI 10.1109/TIP.2014.2313227
NR 56
TC 2
Z9 2
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13947
EP 13981
DI 10.1007/s11042-017-5000-7
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900038
DA 2024-07-18
ER

PT J
AU Lin, C
   Lu, W
   Sun, W
   Zeng, JH
   Xu, TH
   Lai, JH
AF Lin, Cong
   Lu, Wei
   Sun, Wei
   Zeng, Jinhua
   Xu, Tianhua
   Lai, Jian-Huang
TI Region duplication detection based on image segmentation and keypoint
   contexts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image forensics; Region duplication detection; Copy-move
   forgery; Image segmentation; Keypoint contexts
ID COPY-MOVE FORGERY
AB In this paper, a novel region duplication detection method is proposed based on image segmentation and keypoint contexts. The proposed method includes the primary region duplication detection based on keypoints and the supplementary region duplication detection based on blocks. In the primary region duplication detection, an image is divided into non-overlapped patches by using SLIC. Furthermore, the keypoints are matched and clustered within the same patch as patch feature. Then the patches are matched and an affine transformation is tried to be estimated from a pair of patches. When the estimation fails, in the supplementary region duplication detection, a transformation matrix is tried to be estimated from a pair of keypoints by the proposed Keypoint Contexts (KC) approach. The experimental results indicate that the proposed method can achieve much better comprehensive performances than the state-of-the-art methods on the public databases, even under various challenging conditions.
C1 [Lin, Cong; Lu, Wei; Lai, Jian-Huang] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangdong Key Lab Informat Secur Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Lin, Cong] Guangdong Univ Finance & Econ, Educ Technol Ctr, Guangzhou 510320, Guangdong, Peoples R China.
   [Lu, Wei] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
   [Sun, Wei] Sun Yat Sen Univ, Sch Elect & Informat Technol, Key Lab Informat Technol, Minist Educ, Guangzhou 510006, Guangdong, Peoples R China.
   [Sun, Wei; Xu, Tianhua] Beijing Jiaotong Univ, State Key Lab Rail Traff Control & Safety, Beijing 100044, Peoples R China.
   [Zeng, Jinhua] Minist Justice, Inst Forens Sci, Shanghai 200063, Peoples R China.
C3 Sun Yat Sen University; Guangdong University of Finance & Economics;
   Chinese Academy of Sciences; Institute of Information Engineering, CAS;
   Sun Yat Sen University; Beijing Jiaotong University; Institute of
   Forensic Science Ministry of Justice PRC
RP Lu, W (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangdong Key Lab Informat Secur Technol, Guangzhou 510006, Guangdong, Peoples R China.; Lu, W (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
EM lincong0310@gmail.com; luwei3@mail.sysu.edu.cn; sunwei@mail.sysu.edu.cn;
   zengjh@ssfjd.cn; thxu@bjtu.edu.cn; stsljh@mail.sysu.edu.cn
RI Silva, Isac/AAQ-4462-2021
OI lin, cong/0000-0002-5667-5037
FU Natural Science Foundation of Guangdong [2016A030313350]; Special Funds
   for Science and Technology Development of Guangdong [2016KZ010103];
   Fundamental Research Funds for the Central Universities [16lgjc83];
   Scientific and Technological Achievements Transformation Plan of Sun
   Yat-sen University; Research Project of Guangdong University of Finance
   and Economics [10GL52001]; Shanghai Sailing Program [17YF1420000]; State
   Key Laboratory of Rail Traffic Control and Safety, Beijing Jiaotong
   University [RCS2016K007]; Science and Technology Development Fund of
   Macao SAR [097/2013/A3]
FX This work is supported by the Natural Science Foundation of Guangdong
   (No. 2016A030313350), the Special Funds for Science and Technology
   Development of Guangdong (No. 2016KZ010103), the Fundamental Research
   Funds for the Central Universities (No. 16lgjc83), Scientific and
   Technological Achievements Transformation Plan of Sun Yat-sen
   University, the Research Project of Guangdong University of Finance and
   Economics (No. 10GL52001), Shanghai Sailing Program (No. 17YF1420000),
   the State Key Laboratory of Rail Traffic Control and Safety, Beijing
   Jiaotong University (Contract No. RCS2016K007), and the Science and
   Technology Development Fund of Macao SAR (No. 097/2013/A3).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Farid H, 2009, ADV COMPUT, V77, P1, DOI 10.1016/S0065-2458(09)01201-7
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Hastie T., 2009, ELEMENTS STAT LEARNI
   Huang HL, 2008, PACIIA: 2008 PACIFIC-ASIA WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION, VOLS 1-3, PROCEEDINGS, P1241
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Khan S., 2010, International Journal of Computer Applications, V6, P31
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Popescu A.C., 2004, Comput. Sci. Tech. Rep, P1
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Shivakumar B., 2011, Int J Comput Sci Issues (IJCSI), V8, P199
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
NR 22
TC 16
Z9 16
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 14241
EP 14258
DI 10.1007/s11042-017-5027-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900050
DA 2024-07-18
ER

PT J
AU Wu, WH
   Zhu, H
   Zhang, Q
AF Wu, Wenhuan
   Zhu, Hong
   Zhang, Qian
TI Epipolar Rectification by Singular Value Decomposition of Essential
   Matrix
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Epipolar rectification; Projective transformation; Essential matrix; SVD
ID IMAGE RECTIFICATION; ALGORITHM
AB Image rectification is an important stage of applying a pair of projective transformations, or homographies, to a pair of stereo images, so that epipolar lines in the original images map to horizontally aligned lines in the rectified images. Considering that for some stereo rigs the intrinsic parameters of the cameras are known but their external parameters are unknown, in this paper, we present a novel method for stereo rectification based on the essential matrix which is derived from the fundamental matrix. Without any optimization process, closed-form analytical solutions of the projective transformations for epipolar rectification can be directly obtained by conducting SVD on the essential matrix. Experimental results show the proposed rectification method not only has higher efficiency and rectification precision, but also its scale invariance and robustness are superior to existing methods.
C1 [Wu, Wenhuan; Zhu, Hong] Xian Univ Technol, Sch Automat & Informat Engn, Xian 710048, Shaanxi, Peoples R China.
   [Wu, Wenhuan] Hubei Univ Automot Technol, Sch Elect & Informat Engn, Shiyan 442002, Peoples R China.
   [Zhang, Qian] Taishan Univ, Dept Informat Sci & Technol, Tai An 271021, Shandong, Peoples R China.
C3 Xi'an University of Technology; Hubei University of Automotive
   Technology; Taishan University
RP Zhu, H (corresponding author), Xian Univ Technol, Sch Automat & Informat Engn, Xian 710048, Shaanxi, Peoples R China.
EM wuwenhuan5@163.com; zhuhong@xaut.edu.cn; aazhqg@hotmail.com
RI Zhang, Qian/AAB-1715-2020
FU National Natural Science Foundation of China [61332015, 61402320];
   Research project of Hubei Provincial Department of Education, China
   [B2017080]
FX This research was supported by National Natural Science Foundation of
   China (No. 61332015, No. 61402320); by Research project of Hubei
   Provincial Department of Education (B2017080), China.
CR Al-Zahrani A, 2004, INFORM SCIENCES, V160, P53, DOI 10.1016/j.ins.2003.07.012
   [Anonymous], IMAGE VIS COMPUT
   Bae KR, 2017, MULTIMED TOOLS APPL, V76, P17907, DOI 10.1007/s11042-016-3248-y
   Banno A, 2012, INFORM SCIENCES, V183, P140, DOI 10.1016/j.ins.2011.08.019
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Bouguet J., 2000, Matlab Camera Calibration Toolbox Internet
   Chen X, 2015, MULTIMED TOOLS APPL, V74, P5709, DOI 10.1007/s11042-014-1879-4
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fusiello A, 2000, MACH VISION APPL, V12, P16, DOI 10.1007/s001380050120
   Fusiello A, 2011, MACH VISION APPL, V22, P663, DOI 10.1007/s00138-010-0270-3
   Gluckman J, 2001, PROC CVPR IEEE, P111
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Hartley RI, 1999, INT J COMPUT VISION, V35, P115, DOI 10.1023/A:1008115206617
   Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246
   Heyden A., 2005, Emerging topics in computer vision, P45
   Hirschmüller H, 2007, PROC CVPR IEEE, P2134
   Isgro F., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P94, DOI 10.1109/CVPR.1999.786923
   Kang YS, 2011, IEEE T CONSUM ELECTR, V57, P1041, DOI 10.1109/TCE.2011.6018853
   Ko H, 2017, IMAGE VISION COMPUT, V60, P98, DOI 10.1016/j.imavis.2017.01.001
   Kumar S, 2010, PATTERN RECOGN LETT, V31, P1445, DOI 10.1016/j.patrec.2010.03.019
   Liu HB, 2016, OPT LASER ENG, V83, P99, DOI 10.1016/j.optlaseng.2016.03.008
   Loop C., 1999, Comput. Vision Pattern Recognit, V1, P1125, DOI [10.1109/CVPR.1999.786928, DOI 10.1109/CVPR.1999.786928]
   Papadimitriou DV, 1996, IEEE T IMAGE PROCESS, V5, P672, DOI 10.1109/83.491345
   Pollefeys M, 2004, INT J COMPUT VISION, V59, P207, DOI 10.1023/B:VISI.0000025798.50602.3a
   Slama C.C., 1980, MANUAL PHOTOGRAMMETR, Vfourth
   Sun CM, 2003, IMAGE VISION COMPUT, V21, P259, DOI 10.1016/S0262-8856(02)00157-9
   Yang QX, 2009, IEEE T PATTERN ANAL, V31, P492, DOI 10.1109/TPAMI.2008.99
   Yuan YX, 2000, ICIAM, V99, P271
   Zhang HB, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3877
   Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561
   Zhengyou Zhang, 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P666, DOI 10.1109/ICCV.1999.791289
NR 31
TC 6
Z9 7
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15747
EP 15771
DI 10.1007/s11042-017-5149-0
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200057
DA 2024-07-18
ER

PT J
AU Jang, JW
   Heo, H
   Bang, JW
   Hong, HG
   Naqvi, RA
   Nguyen, PH
   Nguyen, DT
   Lee, MB
   Park, KR
AF Jang, Jae Woong
   Heo, Hwan
   Bang, Jae Won
   Hong, Hyung Gil
   Naqvi, Rizwan Ali
   Phong Ha Nguyen
   Dat Tien Nguyen
   Lee, Min Beom
   Park, Kang Ryoung
TI Fuzzy-based estimation of continuous Z-distances and discrete directions
   of home appliances for NIR camera-based gaze tracking system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gaze tracking; Interfaces with home appliances for the severely
   disabled; Continuous Z-distances and discrete directions of home
   appliances; NIR web camera; Fuzzy system
ID MOTION; FACE
AB With the development of eye gaze tracking technology, much research has been performed to adopt this technology for interfacing with home appliances by severely disabled and wheelchair-bound users. For this purpose, two cameras are usually required, one for calculating the gaze position of the user, and the other for detecting and recognizing the home appliance. In order to accurately calculate the gaze position on the home appliance that the user looks at, the Z-distance and direction of the home appliance from the user should be correctly measured. Therefore, stereo cameras or depth-measuring devices such as Kinect are necessary, but they have limitations such as the need for additional camera calibration, and low acquisition speed for two cameras or a large-size of Kinect device. To overcome this problem, we propose a new method for estimating the continuous Z-distances and discrete directions of home appliances using one (small-sized) near-infrared (NIR) web camera and a fuzzy system. Experimental results show that the proposed method can accurately estimate the Z-distances and directions to home appliances.
C1 [Jang, Jae Woong; Heo, Hwan; Bang, Jae Won; Hong, Hyung Gil; Naqvi, Rizwan Ali; Phong Ha Nguyen; Dat Tien Nguyen; Lee, Min Beom; Park, Kang Ryoung] Dongguk Univ, Div Elect & Elect Engn, 30,Pildong Ro 1 Gil, Seoul 100715, South Korea.
C3 Dongguk University
RP Park, KR (corresponding author), Dongguk Univ, Div Elect & Elect Engn, 30,Pildong Ro 1 Gil, Seoul 100715, South Korea.
EM toshinya@dongguk.edu; gjghks@dongguk.edu; bangjw@dgu.edu;
   hell@dongguk.edu; rizwanali@dongguk.edu; phongnhhn92@gmail.com;
   nguyentiendat@dongguk.edu; mblee@dongguk.edu; parkgr@dgu.edu
RI Naqvi, Rizwan Ali/AAW-9242-2020; Nguyen, Phong H/HHN-2723-2022; Nguyen,
   Phong/ABC-4713-2020
OI Naqvi, Rizwan Ali/0000-0002-7473-8441
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - the Ministry of Education [NRF-2015R1D1A1A01056761];
   Bio & Medical Technology Development Program of the NRF - the Korean
   government, MSIP [NRF-2016M3A9E1915855]
FX This research was supported by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education (NRF-2015R1D1A1A01056761), and in part by the Bio
   & Medical Technology Development Program of the NRF funded by the Korean
   government, MSIP (NRF-2016M3A9E1915855).
CR Adeli H., 2006, COST OPTIMIZATION ST
   Al-Rahayfeh A, 2013, IEEE J TRANSL ENG HE, V1, DOI 10.1109/JTEHM.2013.2289879
   [Anonymous], P C HUM SYST INT KRA
   [Anonymous], SCI WORLD J
   [Anonymous], P C NOV GAZ CONTR AP
   [Anonymous], 2013, Computational intelligence: synergies of fuzzy logic, neural networks and evolutionary computing
   [Anonymous], 1992, R. woods digital image processing
   [Anonymous], LOGIC ENG APPL
   Barea R, 2012, EXPERT SYST APPL, V39, P2677, DOI 10.1016/j.eswa.2011.08.123
   Barua A., 2014, J UNCERTAIN SYST, V8, P164
   Bayu DBS, 2013, IEEE WORK ADV ROBOT, P131, DOI 10.1109/ARSO.2013.6705518
   Chao CH, 2009, INT J FUZZY SYST, V11, P183
   Choi C, 2007, INT C REHAB ROBOT, P459, DOI 10.1109/ICORR.2007.4428465
   COHEN J, 1992, PSYCHOL BULL, V112, P155, DOI 10.1037/0033-2909.112.1.155
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Deng LY, 2010, EXPERT SYST APPL, V37, P3337, DOI 10.1016/j.eswa.2009.10.017
   Galdi C, 2016, PATTERN RECOGN LETT, V84, P272, DOI 10.1016/j.patrec.2016.11.002
   Hales J., 2013, P 3 INT WORKSH PERV, V6
   Jacob RJK, 2003, MIND'S EYE: COGNITIVE AND APPLIED ASPECTS OF EYE MOVEMENT RESEARCH, P573, DOI 10.1016/B978-044451020-4/50031-1
   Joglekar A., 2011, IJCSIT, V2, P1758
   Klir G., 1995, Fuzzy sets and fuzzy logic, V4
   Ko E., 2009, Digest of Technical Papers International Conference on Consumer Electronics, P1, DOI DOI 10.1109/ICCE.2009.5012249
   Lankford Chris., 2000, P 2000 S EYE TRACKIN, P23, DOI DOI 10.1145/355017.355021
   Lin CS, 2006, OPT APPL, V36, P401
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2016, GASTROENT RES PRACT, V15, P2016, DOI DOI 10.1177/1533034615587616
   Liu Y.-S., 2015, Sci. World J, V2015, P2, DOI DOI 10.1016/J.LINDIF.2015.02.002
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Liu YJ, 2016, J CHEM-NY, V2016, DOI 10.1155/2016/6903524
   Lu Y.W., 2017, Multimedia Tools and Applications
   Majaranta P., 2014, ADV PHYSL COMPUTING, P39, DOI DOI 10.1007/978-1-4471-6392-3_3
   Mauri C., 2006, HUMAN TECHNOLOGY, V2, P38, DOI DOI 10.17011/HT/URN.2006158
   Medeiros MD, 2010, SENSORS-BASEL, V10, P1093, DOI 10.3390/100201093
   Mrovlje J., 2008, 9th International PhD Workshop on Systems and Control, V2, P1
   Nilsson S, 2009, PSYCHNOLOGY J, V7, P175
   Pinheiro CG, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-31
   Rebsamen B, 2007, IEEE INTELL SYST, V22, P18, DOI 10.1109/MIS.2007.26
   Ren Y- Y, 2015, DISCRETE DYN NAT SOC, V462792, P1
   Shi F, 2007, LECT NOTES COMPUT SC, V4555, P996
   Su MC, 2006, BIOMED ENG-APP BAS C, V18, DOI 10.4015/S1016237206000476
   Suh IH, 2000, MECHATRONICS, V10, P1, DOI 10.1016/S0957-4158(99)00050-1
   Tu JL, 2007, COMPUT VIS IMAGE UND, V108, P35, DOI 10.1016/j.cviu.2006.11.007
   Turner J., 2012, P S EYE TRACK RES AP, P269, DOI [10.1145/2168556.2168613, DOI 10.1145/2168556.2168613]
   Van Broekhoven E, 2006, FUZZY SET SYST, V157, P904, DOI 10.1016/j.fss.2005.11.005
   Van Leekwijck W, 1999, FUZZY SET SYST, V108, P159, DOI 10.1016/S0165-0114(97)00337-0
   VERNON D, 1990, IEEE T ROBOTIC AUTOM, V6, P509, DOI 10.1109/70.62040
   Weibel Nadir., 2012, P S EYE TRACKING RES, P107, DOI DOI 10.1145/2168556.2168573
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Young-Chul Lim, 2008, 2008 IEEE Intelligent Vehicles Symposium (IV), P841, DOI 10.1109/IVS.2008.4621190
   Zhao J, 2002, IEEE IND ELEC, P229, DOI 10.1109/IECON.2002.1187512
NR 52
TC 1
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 11925
EP 11955
DI 10.1007/s11042-017-4842-3
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100015
DA 2024-07-18
ER

PT J
AU Ou, WH
   Yuan, D
   Liu, Q
   Cao, YF
AF Ou, Weihua
   Yuan, Di
   Liu, Qiao
   Cao, Yongfeng
TI Object tracking based on online representative sample selection via
   non-negative least square
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Template update; Sample selection; Non-negative least
   square
ID VISUAL TRACKING; WRITER IDENTIFICATION
AB In the most tracking approaches, a score function is utilized to determine which candidate is the optimal one by measuring the similarity between the candidate and the template. However, the representative samples selection in the template update is challenging. To address this problem, in this paper, we treat the template as a linear combination of representative samples and propose a novel approach to select representative samples based on the coefficient constrained model. We formulate the objective function into a non-negative least square problem and obtain the solution utilizing standard non-negative least square. The experimental results show that the observation module of our approach outperforms several other observation modules under the same feature and motion module, such as support vector machine, logistic regression, ridge regression and structured outputs support vector machine.
C1 [Ou, Weihua; Cao, Yongfeng] Guizhou Normal Univ, Sch Big Data & Comp Sci, Guiyang, Guizhou, Peoples R China.
   [Yuan, Di; Liu, Qiao] Harbin Inst Technol, Shenzhen Grad Sch, Sch Comp Sci, Shenzhen, Peoples R China.
C3 Guizhou Normal University; Harbin Institute of Technology
RP Ou, WH (corresponding author), Guizhou Normal Univ, Sch Big Data & Comp Sci, Guiyang, Guizhou, Peoples R China.
EM ouweihuahust@gmail.com; yuandi@stmail.hit.edu.cn; liuqiao.hit@gmail.com
RI Ou, Weihua/AAD-9887-2020; Liu, Qiao/AAL-5654-2021; Ou,
   Weihua/T-9156-2019; Yuan, Di/Q-6521-2019
OI Liu, Qiao/0000-0003-0885-7976; Ou, Weihua/0000-0001-5241-7703; Yuan,
   Di/0000-0001-9403-1112
FU National Nature Science Foundation of China [61402122, 61461008,
   61672183, 61272252]; Guizhou Normal University; Outstanding Innovation
   Talents of Science and Technology Award Scheme of Education Department
   in Guizhou Province [[2015]487]; Fund of Guizhou educational department
   [KY[2016]027]; China Scholarship Council [201508525007]; Natural Science
   Foundation of Guangdong Province [2015A030313544]; Shenzhen Research
   Council [JCYJ20160406161948211, JCYJ20160226201453085]
FX We sincerely thank Xiao Ma and Quan Zhou for their good suggestions and
   discussion for the improvement of this paper. This work was supported by
   the National Nature Science Foundation of China (No. 61402122, 61461008,
   61672183, 61272252), the 2014 Ph.D. Recruitment Program of Guizhou
   Normal University, the Outstanding Innovation Talents of Science and
   Technology Award Scheme of Education Department in Guizhou Province
   (Qianjiao KY word [2015]487), Fund of Guizhou educational department
   (KY[2016]027), the China Scholarship Council (No. 201508525007), the
   Natural Science Foundation of Guangdong Province (Grant No.
   2015A030313544), and the Shenzhen Research Council (Grant No.
   JCYJ20160406161948211, JCYJ20160226201453085).
CR [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247881
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Bordes A., 2007, Proceedings of the Twentyfourth International Conference on Machine Learning (ICML'07), P89
   Chen L, 2011, IEEE T SYST MAN CY B, V41, P1263, DOI 10.1109/TSMCB.2011.2124455
   Chen WS, 2016, NEUROCOMPUTING, V205, P165, DOI 10.1016/j.neucom.2016.04.014
   Chen WS, 2015, INT J WAVELETS MULTI, V13, DOI 10.1142/S0219691315500496
   Chen ZJ, 2017, IEEE T CYBERNETICS, V47, P3706, DOI 10.1109/TCYB.2016.2577718
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Gao J, 2014, LECT NOTES COMPUT SC, V8691, P188, DOI 10.1007/978-3-319-10578-9_13
   Ge Q, 2017, IEEE T IMAGE PROCESS, V26, P3098, DOI 10.1109/TIP.2016.2639781
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Hanson RJ., 1974, SOLVING LEAST SQUARE
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   He ZY, 2008, PATTERN RECOGN, V41, P1295, DOI 10.1016/j.patcog.2007.08.017
   He ZY, 2017, IEEE T CYBERNETICS, V47, P354, DOI 10.1109/TCYB.2016.2514714
   He ZY, 2016, IEEE T IMAGE PROCESS, V25, P3698, DOI 10.1109/TIP.2016.2570553
   He ZY, 2010, INTEGR COMPUT-AID E, V17, P157, DOI 10.3233/ICA-2010-0338
   He ZY, 2010, INT J COMPUT VISION, V87, P235, DOI 10.1007/s11263-009-0256-7
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hongyi Su, 2015, Intelligent Computing Theories and Methodologies. 11th International Conference, ICIC 2015. Proceedings: LNCS 9225, P1, DOI 10.1007/978-3-319-22180-9_1
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Jing XY, 2016, PATTERN RECOGN, V59, P14, DOI 10.1016/j.patcog.2016.01.023
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Lai ZH, 2014, IEEE T CIRC SYST VID, V24, P1651, DOI 10.1109/TCSVT.2014.2305495
   Leistner C., 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1362, DOI 10.1109/ICCVW.2009.5457451
   Li HX, 2011, PROC CVPR IEEE, P1305, DOI 10.1109/CVPR.2011.5995483
   Li X, 2013, PROC CVPR IEEE, P2419, DOI 10.1109/CVPR.2013.313
   Li X, 2016, KNOWL-BASED SYST, V113, P88, DOI 10.1016/j.knosys.2016.09.014
   Li Y, 2015, PROC CVPR IEEE, P353, DOI 10.1109/CVPR.2015.7298632
   Li YJ, 2016, COMPUT ELECTR ENG, V54, P68, DOI 10.1016/j.compeleceng.2016.08.008
   Liu L, WEIGHTED JOINT SPARS
   Liu Q, 2017, SIGNAL IMAGE VIDEO P, V11, P881, DOI 10.1007/s11760-016-1035-x
   Liu RZ, 2014, IEEE T CYBERNETICS, V44, P2155, DOI 10.1109/TCYB.2014.2301797
   Lu HM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3927
   Ma X, 2016, KNOWL-BASED SYST, V106, P26, DOI 10.1016/j.knosys.2016.05.028
   Masnadi-Shirazi H, 2010, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2010.5540136
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Ou WH, 2016, NEUROCOMPUTING, V204, P116, DOI 10.1016/j.neucom.2015.09.133
   Ou WH, 2014, PATTERN RECOGN, V47, P1559, DOI 10.1016/j.patcog.2013.10.017
   Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466
   Qian JY, 2011, IEEE SENS J, V11, P2301, DOI 10.1109/JSEN.2011.2121058
   Qing Wang, 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P425, DOI 10.1109/WACV.2012.6162999
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Saffari A, 2010, LECT NOTES COMPUT SC, V6313, P776
   Wang N, ARXIV150406055
   Wong WK, 2015, IEEE T CYBERNETICS, V45, P2425, DOI 10.1109/TCYB.2014.2374452
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2014, IEEE T CIRC SYST VID, V24, P374, DOI 10.1109/TCSVT.2013.2278199
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xu X, 2016, NEUROCOMPUTING, V213, P191, DOI 10.1016/j.neucom.2015.11.133
   Yi SY, 2017, PATTERN RECOGN, V61, P524, DOI 10.1016/j.patcog.2016.08.025
   Zeisl B, 2010, PROC CVPR IEEE, P1879, DOI 10.1109/CVPR.2010.5539860
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   Zhang TZ, 2012, LECT NOTES COMPUT SC, V7577, P470, DOI 10.1007/978-3-642-33783-3_34
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zhu G., 2015, J CHEM, V2015, P1, DOI DOI 10.1016/J.JM0LDX.2015.01.004
NR 64
TC 19
Z9 19
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10569
EP 10587
DI 10.1007/s11042-017-4672-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900012
DA 2024-07-18
ER

PT J
AU Shen, SY
   Huang, LH
   Yu, SS
AF Shen, Shu-yuan
   Huang, Li-hong
   Yu, Song-sen
TI A novel adaptive data hiding based on improved EMD and interpolation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; EMD; Interpolation; Pixel value difference; Human vision
   sensitivity
ID EXPLOITING MODIFICATION DIRECTION; IMAGE INTERPOLATION; STEGANOGRAPHY;
   SCHEME; PIXEL
AB Hiding data on grayscale images has been drawing much attention in recent years. High capacity and better image quality are the two foremost research contents of data hiding. The traditional EMD which concealed an equal amount of data into each pixel and cause equal degree of distortion. Meanwhile due to being only an approximation, an interpolated image will always lose some quality each time interpolation is performed. In view of the problems existing in the two above method, we propose a novel data hiding scheme that employs human vision sensitivity to hide a large amount of secret bits into a original image with a high imperceptibility and low computational complexity. Experimental results reveal that the proposed method performs better than several state-of-the-art methods. It can resist the RS steganalysis attack and it is statistically invisible for the attack of PVD histogram attack.
C1 [Shen, Shu-yuan; Yu, Song-sen] South China Normal Univ, Sch Software, Foshan 528225, Guangdong, Peoples R China.
   [Huang, Li-hong] Changsha Univ Sci & Technol, Changsha 410076, Hunan, Peoples R China.
C3 South China Normal University; Changsha University of Science &
   Technology
RP Huang, LH (corresponding author), Changsha Univ Sci & Technol, Changsha 410076, Hunan, Peoples R China.
EM ssyuan02@126.com; lhhuang@csust.edu.cn
FU Natural Science Foundation of P.R. China [11371127, 11571124, 61572028];
   Guangdong Applied Science and Technology Research Foundation of P.R.
   China [2016B020244003]; major Guangzhou University-industry
   Collaboration Innovation Project [201604016002, 201704020203]; Young
   Teachers Scientific Research and Cultivating Foundation of South China
   Normal University [15KJ06]
FX This work was supported by the Natural Science Foundation of P.R. China
   (11371127,11571124, 61572028), the Guangdong Applied Science and
   Technology Research Foundation of P.R. China (2016B020244003), the major
   Guangzhou University-industry Collaboration Innovation Project
   (201604016002,201704020203), and Young Teachers Scientific Research and
   Cultivating Foundation of South China Normal University (15KJ06).
CR Abu-Marie W., 2010, International Journal of Signal and Image Processing, V1, P196
   Allebach J, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P707, DOI 10.1109/ICIP.1996.560768
   [Anonymous], 2009, International Journal of Signal processing, Image processing and pattern
   [Anonymous], WOSPA 2008 5 IEEE IN
   Byun JY, 2008, INTERNATIONAL SYMPOSIUM ON UBIQUITOUS MULTIMEDIA COMPUTING, PROCEEDINGS, P264, DOI 10.1109/UMC.2008.63
   Chang CC, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P489
   Chang CC, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P473
   Chao RM, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/658047
   Fridrich J., 2001, P ACM WORKSH MULT SE, P27
   Gutub A, 2009, 2009 IEEE/ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS, VOLS 1 AND 2, P400, DOI 10.1109/AICCSA.2009.5069356
   Hong W, 2017, MULTIMED TOOLS APPL, V76, P3761, DOI 10.1007/s11042-016-3977-y
   Hong WE, 2011, J VIS COMMUN IMAGE R, V22, P131, DOI 10.1016/j.jvcir.2010.11.004
   Hu J, 2015, COMPUT ELECTR ENG, V46, P447, DOI 10.1016/j.compeleceng.2015.04.014
   Jung KH, 2015, MULTIMED TOOLS APPL, V74, P2143, DOI 10.1007/s11042-013-1832-y
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Khan F, 2007, 4 IEEE GCC C EXH GUL, P11
   Lee CF, 2008, IMAGE VISION COMPUT, V26, P1670, DOI 10.1016/j.imavis.2008.05.005
   Lee CF, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P497
   Lee CF, 2017, MULTIMED TOOLS APPL, V76, P9993, DOI 10.1007/s11042-016-3591-z
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Lehmann TM, 1999, IEEE T MED IMAGING, V18, P1049, DOI 10.1109/42.816070
   Lu TC, 2014, MULTIMED TOOLS APPL, V72, P417, DOI 10.1007/s11042-013-1369-0
   Malik A, 2017, MULTIMED TOOLS APPL, V76, P24107, DOI 10.1007/s11042-016-4186-4
   Parvez M. T., 2008, APSCC 2008 P 3 IEEE, P9
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Tang MW, 2015, AEU-INT J ELECTRON C, V69, P15, DOI 10.1016/j.aeue.2015.08.011
   Tang MW, 2014, OPTIK, V125, P3972, DOI 10.1016/j.ijleo.2014.01.149
   Kieu TD, 2011, EXPERT SYST APPL, V38, P10648, DOI 10.1016/j.eswa.2011.02.122
   Wang JJ, 2010, SIGNAL PROCESS, V90, P2954, DOI 10.1016/j.sigpro.2010.04.022
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Yang CH, 2017, MULTIMED TOOLS APPL, V76, P23699, DOI 10.1007/s11042-016-4133-4
   Yang CH, 2011, J SYST SOFTWARE, V84, P669, DOI 10.1016/j.jss.2010.11.889
   Yang Cll., 2008, J INF MANAG, V15, P29
   Zeng XT, 2012, AEU-INT J ELECTRON C, V66, P532, DOI 10.1016/j.aeue.2011.11.004
   Zhang WM, 2007, IEEE SIGNAL PROC LET, V14, P848, DOI 10.1109/LSP.2007.903255
   Zhang WM, 2007, IEEE COMMUN LETT, V11, P680, DOI 10.1109/LCOMM.2007.070438
   Zhang X, 2007, ELECTRON LETT, V43, P482, DOI 10.1049/el:20070248
   Zhang XQ, 2017, MULTIMED TOOLS APPL, V76, P9195, DOI 10.1007/s11042-016-3521-0
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   Zhang XP, 2004, PATTERN RECOGN LETT, V25, P331, DOI 10.1016/j.patrec.2003.10.014
NR 40
TC 21
Z9 21
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12563
EP 12579
DI 10.1007/s11042-017-4905-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100041
DA 2024-07-18
ER

PT J
AU Tabejamaat, M
   Mousavi, A
AF Tabejamaat, Mohsen
   Mousavi, Abdolmajid
TI Manifold sparsity preserving projection for face and palmprint
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sparsity preserving projection; Sparse representation; Palmprint
   recognition; Face recognition
ID REPRESENTATION BASED CLASSIFICATION; NONLINEAR DIMENSIONALITY REDUCTION;
   DISCRIMINANT-ANALYSIS
AB Sparsity Preserving Projection (SPP) has been recently successfully applied on pattern recognition applications and is the basis for a series of follow up extensions. However, being unsupervised for dimensionality reduction, SPP does not employ the discriminative information of class labels when projecting data into a smaller subspace. This paper proposes a manifold sparsity learning method called Manifold Sparsity Preserving Projection (MSPP) for the face and palmprint recognition. Our method employs the manifold structure for better preserving the sparsity of data in the embedding space. Differing from recent localized sparsity learning methods such as Local Sparse Representation Projections (LSRP) and Local Sparse Preserving Projections (LSPP), which enforce a one-to-one matching between a sample and its sparsely reconstructed model, our method employs manifold data structure to ensure that a sample and all its classmate's sparsely reconstructed models remain as close as possible in the new space. We show that when manifold and sparsity information are simultaneously accounted for, their discriminative power is significantly leveraged. An immediate bonus of our approach is that there is no tuning parameter whatsoever for performance variation. We analytically demonstrate the aforementioned features of our approach and then, using a series of experiments on ORL, Yale, IIT Delhi near infrared facial, and NIR set of PolyU Multispectral palmprint databases its pragmatic consequences will be pictured.
C1 [Tabejamaat, Mohsen; Mousavi, Abdolmajid] Lorestan Univ, Fac Engn, Dept Elect Engn, Khorramabad, Iran.
C3 Lorestan University
RP Mousavi, A (corresponding author), Lorestan Univ, Fac Engn, Dept Elect Engn, Khorramabad, Iran.
EM tabejammat.m@fe.lu.ac.ir; mousavi.m@lu.ac.ir
CR [Anonymous], IIT DELH NEAR IR FAC
   [Anonymous], ORL FAC DAT
   [Anonymous], POLYU MULT PALMPR DA
   [Anonymous], 2008, 2008 19 INT C PATTER, DOI DOI 10.1109/ICPR.2008.4761695
   Asif MS, 2014, IEEE T SIGNAL PROCES, V62, P4209, DOI 10.1109/TSP.2014.2328981
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945
   Cai D, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P714
   Cheng B, 2010, IEEE T IMAGE PROCESS, V19, P858, DOI 10.1109/TIP.2009.2038764
   Cheng H, 2015, ADV COMPUTER VISION
   Cui JR, 2015, MULTIMED TOOLS APPL, V74, P10989, DOI 10.1007/s11042-014-1887-4
   Feng GY, 2008, NEURAL PROCESS LETT, V27, P247, DOI 10.1007/s11063-008-9073-1
   Gao QX, 2015, PATTERN RECOGN, V48, P2543, DOI 10.1016/j.patcog.2015.02.015
   Gong Pinghua, 2013, JMLR Workshop Conf Proc, V28, P37
   Gui J, 2012, PATTERN RECOGN, V45, P2884, DOI 10.1016/j.patcog.2012.02.005
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Ibrahim S, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM COMPUTING AND ENGINEERING, P202, DOI 10.1109/ICCSCE.2014.7072715
   Jing XY, 2011, 2011 FIRST ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P555, DOI 10.1109/ACPR.2011.6166662
   Joliffe I.T., 1986, Principal Component Analysis
   Lai ZH, 2013, NEURAL COMPUT APPL, V23, P2231, DOI 10.1007/s00521-012-1174-0
   Lou SJ, 2016, NEUROCOMPUTING, V173, P290, DOI 10.1016/j.neucom.2015.04.116
   Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P117, DOI 10.1109/TNN.2002.806629
   Mika S., 1999, NNSP, V1999, P41, DOI DOI 10.1109/NNSP.1999.788121
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   Radovanovic M, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P186
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Saxena DK, 2007, LECT NOTES COMPUT SC, V4403, P772
   Schölkopf B, 1999, ADVANCES IN KERNEL METHODS, P327
   Sugiyama M, 2007, J MACH LEARN RES, V8, P1027
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   Wang SJ, 2011, NEUROCOMPUTING, V74, P3654, DOI 10.1016/j.neucom.2011.07.007
   Wang YX, 2006, INT C PATT RECOG, P457
   Waqas J, 2013, PATTERN RECOGN LETT, V34, P201, DOI 10.1016/j.patrec.2012.09.024
   Wei L, 2014, KNOWL-BASED SYST, V70, P212, DOI 10.1016/j.knosys.2014.06.027
   Wong WK, 2012, PATTERN RECOGN, V45, P186, DOI 10.1016/j.patcog.2011.05.014
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu Y, 2015, PATTERN RECOGN LETT, V68, P9, DOI 10.1016/j.patrec.2015.07.032
   Xu Y, 2015, NEUROCOMPUTING, V147, P307, DOI 10.1016/j.neucom.2014.06.058
   Xu Y, 2013, PATTERN RECOGN, V46, P1151, DOI 10.1016/j.patcog.2012.11.003
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang J, 2007, IEEE T PATTERN ANAL, V29, P650, DOI 10.1109/TPAMI.2007.1008
   Yang J, 2013, IEEE T NEUR NET LEAR, V24, P1023, DOI 10.1109/TNNLS.2013.2249088
   Yang YF, 2017, MULTIMED TOOLS APPL, V76, P2697, DOI 10.1007/s11042-015-3212-2
   Yin F, 2013, NEURAL COMPUT APPL, V23, P691, DOI 10.1007/s00521-012-0978-2
   Yu GX, 2011, NEUROCOMPUTING, V74, P598, DOI 10.1016/j.neucom.2010.09.005
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang LM, 2012, PATTERN RECOGN, V45, P1205, DOI 10.1016/j.patcog.2011.08.015
   Zhang YP, 2016, NEUROCOMPUTING, V173, P518, DOI 10.1016/j.neucom.2015.07.011
   Zheng ZL, 2007, SIGNAL PROCESS, V87, P2473, DOI 10.1016/j.sigpro.2007.03.006
NR 53
TC 7
Z9 7
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12233
EP 12258
DI 10.1007/s11042-017-4881-9
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100028
DA 2024-07-18
ER

PT J
AU Balas, C
   Epitropou, G
   Tsapras, A
   Hadjinicolaou, N
AF Balas, Costas
   Epitropou, George
   Tsapras, Athanasios
   Hadjinicolaou, Nicos
TI Hyperspectral imaging and spectral classification for pigment
   identification and mapping in paintings by El Greco and his workshop
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyper spectral imaging; Pigment identification; Thematic map;
   Classification; Spectral library; El Greco
AB The identification of painting materials is of essential importance for artistic and scientific analysis of objects of artistic and historic value. In this paper we report a new method and technology comprising a) hyperspectral imaging, b) development of spectral libraries corresponding to target materials and c) proper classification strategies with (a) and (b) as inputs. Our findings advocate that the method improves radically the diagnostic potential of visible-near infrared imaging spectroscopy. A system's approach is implemented by combining a novel hyperspectral camera integrating an innovative electro-optic tunable filter solution with spectral analysis and classification algorithms. A series of pigment material replicas was developed using original methods covering almost the entire palette of Renaissance painters. Hyperspectral acquisition of the constructed pigment panels provided millions of spectra, which were used for both training and validation of a series of spectral classification algorithms, namely: Maximum Likelihood (ML), Spectral Angle Mapper (SAM), Normalized Euclidean Distance (NEUC), Spectral Information Divergence (SID), Spectral Correlation Mapper (SCM) and Spectral Gradient Mapper (SGM). It was found that the best performing algorithm in identifying and differentiating pigments with similar hue but different chemical composition was the ML algorithm. This algorithm displayed accuracies within the range 80.3%-99.7% in identifying and mapping materials used by El Greco and his workshop. The high accuracy achieved in identifying pigments strongly suggest that the new method and technology has great potential for the scientific analysis of artwork and for assisting conservation and authentication tasks.
C1 [Balas, Costas; Epitropou, George; Tsapras, Athanasios] Tech Univ Crete, Sch Elect & Comp Engn, Khania, Crete, Greece.
   [Balas, Costas] Holopt PC, Khania, Crete, Greece.
   [Hadjinicolaou, Nicos] Univ Crete, Dept Hist & Archaeol, Rethimnon, Crete, Greece.
   [Hadjinicolaou, Nicos] Fdn Res & Technol Hellas, Inst Mediterranean Studies, Rethimnon, Crete, Greece.
C3 Technical University of Crete; University of Crete; Foundation for
   Research & Technology - Hellas (FORTH)
RP Balas, C (corresponding author), Tech Univ Crete, Sch Elect & Comp Engn, Khania, Crete, Greece.; Balas, C (corresponding author), Holopt PC, Khania, Crete, Greece.
EM balas@electronics.tuc.gr
RI Li, Mengqi/AAG-6804-2021
CR Alexopoulou AA, 2013, J ARCHAEOL SCI, V40, P1242, DOI 10.1016/j.jas.2012.09.013
   [Anonymous], 1974, Pattern Recognition Principles, DOI DOI 10.1002/ZAMM.19770570626
   Balas C, 2012, HDB BIOMEDICAL OPTIC, P131
   Balas C, 2003, J CULT HERIT, V4, p330S
   Daniel F, 2016, MICROCHEM J, V126, P113, DOI 10.1016/j.microc.2015.11.044
   Delaney JK, 2014, STUD CONSERV, V59, P91, DOI 10.1179/2047058412Y.0000000078
   Girouard G., 2004, 20 ISPRS C GEOIM BRI, P23
   Kriznar A., 2011, E PRESERVATION SCI, V8, P49
   Legrand S, 2014, HERIT SCI, V2, DOI 10.1186/2050-7445-2-13
   Melessanaki K, 2001, SPECTROCHIM ACTA B, V56, P2337, DOI 10.1016/S0584-8547(01)00302-0
   Mosca S, 2016, APPL PHYS A-MATER, V122, DOI 10.1007/s00339-016-0345-8
   Richards J.A., 2006, Remote Sensing Digital Image Analysis: An Introduction, Vfourth
   Zafiropulos V, 2003, J CULT HERIT, V4, p249S
NR 13
TC 31
Z9 35
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9737
EP 9751
DI 10.1007/s11042-017-5564-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200026
DA 2024-07-18
ER

PT J
AU Chen, TH
   Lin, KS
   Lin, CH
AF Chen, Tzung-Her
   Lin, Kai-Siang
   Lin, Chih-Hung
TI On the design of a two-decoding-option image secret sharing scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual cryptography; Image secret sharing; Polynomial-based secret
   sharing; Lagrange interpolation; Random grids
ID ENCRYPTION
AB In an image secret sharing scheme (ISSS), two main categories are discussed. One is the polynomial-style image secret sharing scheme (PISSS), and the other is the visual secret sharing (VSS). It is interesting to combine the main properties of these two schemes. When the encoded secret images are received, we can decode them by combining these two schemes' properties, utilizing the VSS property to seek the secret immediately by human visual system (HVS) and the PISSS property to recover the secret perfectly with a decoding machine. This paper combines PISSS and random grids-based VSS to remove all the drawbacks existing in the previous works including 1) distortion by compressing a secret image, 2) non-perfect reconstructed image, 3) distortion of pixel expansion, and 4) size-reduced halftone image. The experimental results demonstrate the proposed scheme does work well.
C1 [Chen, Tzung-Her; Lin, Kai-Siang] Natl Chiayi Univ, Dept Comp Sci & Informat Engn, 300 Univ Rd, Chiayi 60004, Taiwan.
   [Lin, Chih-Hung] Natl Chiayi Univ, Grad Inst Math & Sci Educ, 85 Wenlong Vil, Minxiong Township 62103, Chiayi County, Taiwan.
C3 National Chiayi University
RP Chen, TH (corresponding author), Natl Chiayi Univ, Dept Comp Sci & Informat Engn, 300 Univ Rd, Chiayi 60004, Taiwan.
EM thchen@mail.ncyu.edu.tw
OI Chen, Tzung-Her/0000-0001-5775-6034
FU Ministry of Science and Technology, Taiwan, R.O.C. [MOST 105-2221-E-415
   -012]
FX The authors would like to thank the anonymous referees for their
   valuable discussions and comments. This research was partially supported
   by Ministry of Science and Technology, Taiwan, R.O.C., under contract
   no. MOST 105-2221-E-415 -012 -.
CR [Anonymous], 2009, PATTERN RECOGN
   [Anonymous], COLORED VISUAL CRYPT
   Ateniese G, 2001, THEOR COMPUT SCI, V250, P143, DOI 10.1016/S0304-3975(99)00127-9
   Chen TH, 2016, SIGNAL PROCESS-IMAGE, V44, P101, DOI 10.1016/j.image.2016.03.006
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Chen TH, 2009, PATTERN RECOGN, V42, P2203, DOI 10.1016/j.patcog.2008.11.015
   Cimato S, 2006, COMPUT J, V49, P97, DOI 10.1093/comjnl/bxh152
   Devi E. Sangeetha, 2010, 2010 International Conference on Communication Control and Computing Technologies, P769
   Elsheh E, 2011, EXPERT SYST APPL, V38, P13906, DOI 10.1016/j.eswa.2011.04.197
   Feng JB, 2005, J SYST SOFTWARE, V76, P327, DOI 10.1016/j.jss.2004.07.250
   Jin D, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.1993625
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Lee YS, 2013, IET IMAGE PROCESS, V7, P137, DOI 10.1049/iet-ipr.2012.0338
   Li P, 2018, J REAL-TIME IMAGE PR, V14, P41, DOI 10.1007/s11554-016-0621-z
   Li P, 2013, J VIS COMMUN IMAGE R, V24, P1380, DOI 10.1016/j.jvcir.2013.09.010
   Li P, 2012, J VIS COMMUN IMAGE R, V23, P441, DOI 10.1016/j.jvcir.2012.01.003
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin CH, 2015, J VIS COMMUN IMAGE R, V33, P31, DOI 10.1016/j.jvcir.2015.08.018
   Lin SJ, 2007, PATTERN RECOGN, V40, P3652, DOI 10.1016/j.patcog.2007.04.001
   Liu F, 2008, IET INFORM SECUR, V2, P151, DOI 10.1049/iet-ifs:20080066
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shyu SH, 2007, PATTERN RECOGN, V40, P1014, DOI 10.1016/j.patcog.2006.02.025
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Thien CC, 2003, IEEE T CIRC SYST VID, V13, P1161, DOI 10.1109/TCSVT.2003.819176
   Yang CN, 2010, IMAGE VISION COMPUT, V28, P1600, DOI 10.1016/j.imavis.2010.04.003
   Yang CN, 2005, LECT NOTES COMPUT SC, V3480, P19
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
NR 28
TC 11
Z9 11
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 7865
EP 7881
DI 10.1007/s11042-017-4680-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800004
DA 2024-07-18
ER

PT J
AU Magnier, B
AF Magnier, Baptiste
TI Edge detection: a review of dissimilarity evaluations and a proposed
   normalized measure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Edge detection; Supervised evaluation; Distance measures
ID ERROR MEASURES; SEGMENTATION; PERFORMANCE; DISTANCE; QUALITY; DESIGN
AB In digital images, edges characterize object boundaries, so edge detection remains a crucial stage in numerous applications. To achieve this task, many edge detectors have been designed, producing different results, with various qualities of segmentation. Indeed, optimizing the response obtained by these detectors has become a crucial issue, and effective contour assessment assists performance evaluation. In this paper, several referenced-based boundary detection evaluations are detailed, pointing out their advantages and disadvantages, theoretically and through concrete examples of image edges. Then, a new normalized supervised edge map quality measure is proposed, comparing a ground truth contour image, the candidate contour image and their associated spatial nearness. The effectiveness of the proposed distance measure is demonstrated theoretically and through several experiments, comparing the results with the methods detailed in the state-of-the-art. In summary, compared to other boundary detection assessments, this new method proved to be a more reliable edge map quality measure.
C1 [Magnier, Baptiste] Ecole Mines Ales, LGI2P, 69 Ave Parc Sci Georges Besse, F-30000 Nimes, France.
C3 IMT - Institut Mines-Telecom; IMT Mines Ales
RP Magnier, B (corresponding author), Ecole Mines Ales, LGI2P, 69 Ave Parc Sci Georges Besse, F-30000 Nimes, France.
EM baptiste.magnier@mines-ales.fr
OI Magnier, Baptiste/0000-0003-3458-0552
CR ABDOU IE, 1979, P IEEE, V67, P753, DOI 10.1109/PROC.1979.11325
   [Anonymous], EURASIP J APPL SIGNA
   Baddeley A., 1992, Proceedings of the IEEE Workshop on Robust Computer Vision, P59
   BASSEVILLE M, 1989, SIGNAL PROCESS, V18, P349, DOI 10.1016/0165-1684(89)90079-0
   Baudrier É, 2008, PATTERN RECOGN, V41, P1461, DOI 10.1016/j.patcog.2007.07.011
   Boaventura IAG, 2009, BRAZ S COMP GRAPH IM
   Bourennane E, 2002, SIGNAL PROCESS, V82, P1317, DOI 10.1016/S0165-1684(02)00283-9
   Bowyer K, 2001, COMPUT VIS IMAGE UND, V84, P77, DOI 10.1006/cviu.2001.0931
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chabrier S., 2008, EURASIP J IMAGE VIDE, V2008, P10, DOI DOI 10.1155/2008/693053
   Demigny D, 2002, IEEE T IMAGE PROCESS, V11, P728, DOI 10.1109/TIP.2002.800887
   DERICHE R, 1987, INT J COMPUT VISION, V1, P167, DOI 10.1007/BF00123164
   DEUTSCH ES, 1978, IEEE T COMPUT, V27, P205, DOI 10.1109/TC.1978.1675073
   DUBUISSON MP, 1994, INT C PATT RECOG, P566, DOI 10.1109/ICPR.1994.576361
   FALAH RK, 1994, IEEE IMAGE PROC, P470, DOI 10.1109/ICIP.1994.413762
   Fernández-García NL, 2004, PATTERN RECOGN LETT, V25, P35, DOI 10.1016/j.patrec.2003.08.011
   Freeman WT, 1991, IEEE TPAMI, V13, P89
   Geusebroek JM, 2002, LECT NOTES COMPUT SC, V2350, P99
   Gimenez J, 2014, COMPUT VIS IMAGE UND, V122, P131, DOI 10.1016/j.cviu.2014.02.005
   Goumeidane AB, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P411
   Grigorescu C, 2003, IEEE T IMAGE PROCESS, V12, P729, DOI 10.1109/TIP.2003.814250
   HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475
   Heath MD, 1997, IEEE T PATTERN ANAL, V19, P1338, DOI 10.1109/34.643893
   Hemery B, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3446803
   Hou XD, 2013, PROC CVPR IEEE, P2123, DOI 10.1109/CVPR.2013.276
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Jacob M, 2004, IEEE T PATTERN ANAL, V26, P1007, DOI 10.1109/TPAMI.2004.44
   Kothe U, 2007, THESIS
   Laligant O, 2007, IEEE SIGNAL PROC LET, V14, P185, DOI 10.1109/LSP.2006.884030
   LEE SU, 1990, COMPUT VISION GRAPH, V52, P171, DOI 10.1016/0734-189X(90)90053-X
   Lopez-Molina C, 2014, PATTERN RECOGN, V47, P270, DOI 10.1016/j.patcog.2013.07.009
   Lopez-Molina C, 2013, PATTERN RECOGN, V46, P1125, DOI 10.1016/j.patcog.2012.10.027
   Lopez-Molina C, 2010, PATTERN RECOGN, V43, P3730, DOI 10.1016/j.patcog.2010.05.035
   Magnier Baptiste, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5105, DOI 10.1109/ICASSP.2014.6854575
   Magnier B., 2011, IEEE ISPA, P212
   Magnier B., 2010, IEEE INT C IM SYST T, P229
   Magnier B, 2016, IEEE CONF IMAGING SY, P429, DOI 10.1109/IST.2016.7738264
   Magnier B, 2011, INT CONF ACOUST SPEE, P1097
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Odet C, 2002, IEEE IMAGE PROC, P785
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Panetta A., 2014, J. Biomed.Imag., V2014, P1
   Panetta K, 2016, IEEE T SYST MAN CY-S, V46, P1505, DOI 10.1109/TSMC.2015.2503386
   Papari G, 2011, IMAGE VISION COMPUT, V29, P79, DOI 10.1016/j.imavis.2010.08.009
   Paumard J, 1997, PATTERN RECOGN LETT, V18, P1057, DOI 10.1016/S0167-8655(97)80002-5
   PELI T, 1982, COMPUT VISION GRAPH, V20, P1, DOI 10.1016/0146-664X(82)90070-3
   Pinho A. J., 1995, Image Analysis and Processing. 8th International Conference, ICIAP '95. Proceedings, P159
   Román-Roldán R, 2001, PATTERN RECOGN, V34, P969, DOI 10.1016/S0031-3203(00)00052-2
   ROSENFELD A, 1971, IEEE T COMPUT, VC 20, P562, DOI 10.1109/T-C.1971.223290
   Shen J., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P109
   Sneath P. H. A., 1973, Numerical Taxonomy: The Principles and Practice of Numerical Classification
   Sobel I. E., 1970, CAMERA MODELS MACHIN
   STRASTERS KC, 1991, PATTERN RECOGN LETT, V12, P307, DOI 10.1016/0167-8655(91)90414-H
   TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769
   VENKATESH S, 1995, GRAPH MODEL IM PROC, V57, P146, DOI 10.1006/gmip.1995.1015
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wilson DL, 1997, INT J COMPUT VISION, V24, P5, DOI 10.1023/A:1007978107063
   YASNOFF WA, 1979, ANAL QUANT CYTOL, V1, P107
   Yitzhaky Y, 2003, IEEE T PATTERN ANAL, V25, P1027, DOI 10.1109/TPAMI.2003.1217608
   Zhao CJ, 2005, PATTERN RECOGN LETT, V26, P581, DOI 10.1016/j.patrec.2004.09.022
NR 61
TC 18
Z9 18
U1 2
U2 54
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9489
EP 9533
DI 10.1007/s11042-017-5127-6
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200018
DA 2024-07-18
ER

PT J
AU Reta, C
   Solis-Moreno, I
   Cantoral-Ceballos, JA
   Alvarez-Vargas, R
   Townend, P
AF Reta, Carolina
   Solis-Moreno, Ismael
   Cantoral-Ceballos, Jose A.
   Alvarez-Vargas, Rogelio
   Townend, Paul
TI Improving content-based image retrieval for heterogeneous datasets using
   histogram-based descriptors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Visual features; Lab color descriptor; Gabor wavelets;
   Local binary patterns; Histograms
AB Image content analysis plays a key role in areas such as image classification, clustering, indexing, retrieving, and object and scene recognition. However, although several image content descriptors have been proposed in the literature, their low performance score or high computational cost makes them unsuitable for content-based image retrieval on large datasets. This paper presents an efficient content-based image retrieval approach that uses histogram-based descriptors to represent color, edge, and texture features, and a k-nearest neighbor classifier to retrieve the best matches for query images. The compactness and speed of the proposed descriptors allow their application in heterogeneous photographic collections whilst showing strong image discrimination in the presence of significant content variation. Experimentation was conducted on four different image collections using four distance metrics. The results show that the proposed approach consistently achieves noteworthy mean average precision, recall, and precision measures. It outperforms state-of-the-art approaches based on the MPEG 7 descriptors (SCD, CLD, and EHD), whilst producing comparable results to those achieved by novel SIFT-based and SURF-based approaches that require more complex data manipulation.
C1 [Reta, Carolina] CONACYT CIATEQ, Div IT Elect & Control, Ave Diesel Nacl 1, Ciudad Sahagun 43990, Hidalgo, Mexico.
   [Solis-Moreno, Ismael] IBM Corp, Mexico Software Lab, Guadalajara, Jalisco, Mexico.
   [Cantoral-Ceballos, Jose A.; Alvarez-Vargas, Rogelio] CIATEQ, Div IT Elect & Control, El Marques, Queretaro, Mexico.
   [Townend, Paul] Univ Leeds, Sch Comp, Leeds, W Yorkshire, England.
C3 CIATEQ; University of Leeds
RP Reta, C (corresponding author), CONACYT CIATEQ, Div IT Elect & Control, Ave Diesel Nacl 1, Ciudad Sahagun 43990, Hidalgo, Mexico.
EM carolina.reta@ciateq.mx; ismael@mx1.ibm.com; jose.cantoral@ciateq.mx;
   ralvarez@ciateq.mx; p.m.townend@leeds.ac.uk
RI Townend, Paul/JEO-6559-2023; Reta, Carolina/M-3167-2018
OI Townend, Paul/0000-0002-9698-8361; Reta, Carolina/0000-0002-0843-129X;
   Cantoral-Ceballos, Dr. Jose A./0000-0001-5597-939X
CR Agrawal R, 2010, HDB MPEG APPL, P221
   [Anonymous], 2015, MATL R2015B
   Beaubouef T, 2007, APPL SOFT COMPUT, V7, P425, DOI 10.1016/j.asoc.2004.11.003
   Bober M, 2001, IEEE T CIRC SYST VID, V11, P716, DOI 10.1109/76.927426
   Castelli V., 2002, Image Databases: Search and Retrieval of Digital Imagery
   Chatzichristofis SA, 2014, MULTIMED TOOLS APPL, V70, P1767, DOI 10.1007/s11042-012-1192-z
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deselaers T, 2008, INFORM RETRIEVAL, V11, P77, DOI 10.1007/s10791-007-9039-3
   Feng D, 2003, MULTIMEDIA INFORM RE, DOI [10.1007/978-3-662-05300-3, DOI 10.1007/978-3-662-05300-3]
   FRANCOS JM, 1993, IEEE T SIGNAL PROCES, V41, P2665, DOI 10.1109/78.229897
   Gevers T, 2004, IEEE T PATTERN ANAL, V26, P113, DOI 10.1109/TPAMI.2004.1261083
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Iakovidou C, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0262-6
   Jain M, 2011, ACM I C MULT, DOI [10.1145/2072298.2072035, DOI 10.1145/2072298.2072035]
   Jegou H, 2008, EUR C COMP VIS, DOI [10.1007/978-3-540-88682-224, DOI 10.1007/978-3-540-88682-224]
   Jégou H, 2010, INT J COMPUT VISION, V87, P316, DOI 10.1007/s11263-009-0285-2
   Juneja K, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION TECHNOLOGY CICT 2015, P67, DOI 10.1109/CICT.2015.92
   KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532
   Kumar G, 2014, INT C ADV COMPUT COM, P5, DOI 10.1109/ACCT.2014.74
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Nie LQ, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P695
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Paschos G, 2001, IEEE T IMAGE PROCESS, V10, P932, DOI 10.1109/83.923289
   Pass G., 1996, P 4 ACM INT C MULT, V96, P65, DOI DOI 10.1145/244130.244148
   Rao AR, 1996, VISION RES, V36, P1649, DOI 10.1016/0042-6989(95)00202-2
   Roy AJ, 2001, INT J APPROX REASON, V27, P205, DOI 10.1016/S0888-613X(01)00033-0
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Shao H, 2003, LECT NOTES COMPUT SC, DOI [10.1007/3-540-45113-78, DOI 10.1007/3-540-45113-78]
   Shereena V. B., 2014, INT J MULTIMED APPL, V6, P31, DOI DOI 10.5121/IJMA.2014.6503
   Sikora T, 2001, IEEE T CIRC SYST VID, V11, P696, DOI 10.1109/76.927422
   Tamura H., 1978, IEEE Transactions on Systems, Man and Cybernetics, VSMC-8, P460, DOI 10.1109/TSMC.1978.4309999
   Vegad SP, 2015, 2015 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, SIGNALS, COMMUNICATION AND OPTIMIZATION (EESCO)
   Wong KM, 2007, IEEE I C MULT EXP, DOI [10.1109/ICME.2007.4284724, DOI 10.1109/ICME.2007.4284724]
   Wu YN, 2010, INT J COMPUT VISION, V90, P198, DOI 10.1007/s11263-009-0287-0
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
   Zhang SL, 2013, IEEE I CONF COMP VIS, P1673, DOI 10.1109/ICCV.2013.210
   Zheng L, 2014, IEEE T IMAGE PROCESS, V23, P3368, DOI 10.1109/TIP.2014.2330763
NR 43
TC 7
Z9 7
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8163
EP 8193
DI 10.1007/s11042-017-4708-8
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800018
DA 2024-07-18
ER

PT J
AU Vourvoulakis, J
   Kalomiros, J
   Lygouras, J
AF Vourvoulakis, John
   Kalomiros, John
   Lygouras, John
TI FPGA-based architecture of a real-time SIFT matcher and RANSAC algorithm
   for robotic vision applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scale-Invariant Feature Transform (SIFT); Random sample consencus
   (RANSAC); Field Programmable Gate Array (FPGA); Robotic vision;
   Real-time; Robust fitting
ID IMPLEMENTATION
AB A fundamental problem in computer vision is finding correspondences between features in pairs of similar images. By comparing feature descriptors instead of pixel intensities, the matching capability is significantly increased. Keypoints extracted by Scale-Invariant Feature Transform (SIFT) provide superior matching ability, however, a small proportion of false corresponcences is always inevitable. The exemption of false matches is achieved using robust fitting algorithms, with RANSAC (random sample consensus) being a popular one. SIFT and RANSAC are computationally demanding and time consuming algorithms. When the target application operates in real-time, conventional approaches based on personal computers usually fail to meet the requirements. In this paper, an FPGA-based architecture for real-time SIFT matching and RANSAC algorithm is presented. The proposed scheme is applied to identify the correspondences between point features across consecutive video frames and reject the false matches. The architecture is verified using the DE2i-150 development board. Using Cyclone IV technology, the system supports a processing rate of 40fps for VGA resolution and therefore meets real-time requirements.
C1 [Vourvoulakis, John; Lygouras, John] Democritus Univ Thrace, Sect Elect & Informat Syst Technol, Dept Elect & Comp Engn, Polytech Sch Xanthi, Xanthi 67100, Greece.
   [Kalomiros, John] Technol & Educ Inst Cent Macedonia, Dept Informat Engn, Terma Magnisias 62124, Serres, Greece.
C3 Democritus University of Thrace
RP Vourvoulakis, J (corresponding author), Democritus Univ Thrace, Sect Elect & Informat Syst Technol, Dept Elect & Comp Engn, Polytech Sch Xanthi, Xanthi 67100, Greece.
EM jvourv@ee.duth.gr
RI Kalomiros, John/AAA-2997-2020
OI Kalomiros, John/0000-0002-1790-0975; Vourvoulakis,
   John/0000-0003-3709-6395
CR Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   [Anonymous], 2007, MATRIX ALGEBRA THEOR, DOI [10.1007/978-0-387-70873-7, DOI 10.1007/978-0-387-70873-7]
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Boulekchour M, 2014, Robotica, P1, DOI [10.1017/S0263574714001829, DOI 10.1017/S0263574714001829]
   Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222
   Condello G, 2013, SIGNAL PROCESS-IMAGE, V28, P345, DOI 10.1016/j.image.2012.06.002
   Di Carlo S, 2015, IEEE T VLSI SYST, V23, P2198, DOI 10.1109/TVLSI.2014.2357181
   Dohi K., 2012, 2012 22nd International Conference on Field Programmable Logic and Applications (FPL), P458, DOI 10.1109/FPL.2012.6339144
   Dung L.-R., 2013, J. Comput. Commun, V1, P46, DOI [10.4236/jcc.2013.16009, DOI 10.4236/JCC.2013.16009]
   Fassold H, 2015, PROC SPIE, V9400, DOI 10.1117/12.2083201
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Furntratt H, 2013, GPU TECHN C
   Hartley R., 2004, Multiple view geometry in computer vision, V2nd, P87, DOI DOI 10.2277/0521540518
   Hidalgo-Paniagua A, 2015, INT J PARALLEL PROG, V43, P703, DOI 10.1007/s10766-014-0316-7
   Jiang J, 2014, IEEE T CIRC SYST VID, V24, P1209, DOI 10.1109/TCSVT.2014.2302535
   Kapela R, 2015, APPL MATH COMPUT, V267, P419, DOI 10.1016/j.amc.2015.02.029
   Ke Y., 2004, P IEEE COMP SOC C CO, V2
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li Haiyang, 2013, Information Technology Journal, V12, P1449, DOI 10.3923/itj.2013.1449.1453
   [刘辉 Liu Hui], 2014, [半导体光电, Semiconductor Optoelectronics], V35, P108
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Scharstein D, 2003, P IEEE COMP SOC C CO, V1
   Song HT, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (ICMA), P1743, DOI 10.1109/ICMA.2013.6618179
   Tang JW, 2013, IEEE ST CONF RES DEV, P290, DOI 10.1109/SCOReD.2013.7002592
   Vourvoulakis John, 2016, 2016 IEEE International Conference on Imaging Systems and Techniques (IST), P60, DOI 10.1109/IST.2016.7738198
   Vourvoulakis J, 2017, MICROPROCESS MICROSY, V49, P105, DOI 10.1016/j.micpro.2016.11.011
   Vourvoulakis J, 2016, MICROPROCESS MICROSY, V40, P53, DOI 10.1016/j.micpro.2015.11.013
   Wang JH, 2014, IEEE T CIRC SYST VID, V24, P525, DOI 10.1109/TCSVT.2013.2280040
NR 30
TC 13
Z9 14
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9393
EP 9415
DI 10.1007/s11042-017-5042-x
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200013
DA 2024-07-18
ER

PT J
AU Zhang, SH
   Li, X
   He, H
   Miao, YX
AF Zhang, Shihui
   Li, Xin
   He, Huan
   Miao, Yuxia
TI A next best view method based on self-occlusion information in depth
   images for moving object
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Moving object; Depth image; Self-occlusion avoidance; 3D motion
   estimation; Next best view
ID RECONSTRUCTION; ENTROPY
AB The determination of next best view of a camera for moving object has wide application in dynamic object scenario, such as unmanned aerial vehicle and automatic recognition. The major challenge of this problem is how to determine the next best view while the visual object is moving. In this work, a novel next best view method based on self-occlusion information in depth images of moving object is proposed. Firstly, a depth image of moving object is acquired and self-occlusion detection is utilized in the acquired image. On this basis, the self-occlusion regions are modeled by utilizing space quadrilateral subdivision. Secondly, according to the modeling result, a method based on the idea of mean shift is proposed to calculate the result of self-occlusion avoidance corresponding to the current object. Thirdly, the second depth image of moving object is acquired, and the feature points in two images are detected and matched, then the 3D motion estimation is accomplished by the 3D coordinates of feature points which are matched. Finally, the next best view is determined by combining the result of self-occlusion avoidance and 3D motion estimation. Experimental results validate that the proposed method is feasible and has relatively high real-time performance.
C1 [Zhang, Shihui; Li, Xin; He, Huan; Miao, Yuxia] Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao 066004, Peoples R China.
   [Zhang, Shihui] Key Lab Comp Virtual Technol & Syst Integrat HeBe, Qinhuangdao 066004, Peoples R China.
C3 Yanshan University
RP Zhang, SH (corresponding author), Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao 066004, Peoples R China.; Zhang, SH (corresponding author), Key Lab Comp Virtual Technol & Syst Integrat HeBe, Qinhuangdao 066004, Peoples R China.
EM sshhzz@ysu.edu.cn; woai508305@163.com; hih8928@stumail.ysu.edu.cn;
   yuxia_miao@163.com
RI Zhang, Shihui/HHS-1779-2022; Zhang, Shihui/KFB-3255-2024
FU National Natural Science Foundation of China [61379065]; Natural Science
   Foundation of Hebei province in China [F2014203119]
FX This work is supported by the National Natural Science Foundation of
   China under Grant No. 61379065 and the Natural Science Foundation of
   Hebei province in China under Grant No. F2014203119.
CR Adler B, 2013, IEEE INT C INT ROBOT, P1056, DOI 10.1109/IROS.2013.6696481
   Alexiadis D.S., 2011, ACM international conference on Multimedia, P659
   [Anonymous], INT S 3D DAT PROC VI
   Banta JE, 2000, IEEE T SYST MAN CY A, V30, P589, DOI 10.1109/3468.867866
   Blaer Paul S., 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P417, DOI 10.1109/IROS.2007.4399581
   Chen F., 2012, LECT NOTES I COMPUTE, P113, DOI [10.1007/978-3-642-35145-7_15, DOI 10.1007/978-3-642-35145-7_15]
   Chen F, 2014, IEEE T MULTIMEDIA, V16, P455, DOI 10.1109/TMM.2013.2291967
   Connolly C., 1985, PROC IEEE INT C ROBO, V2, P432
   Daniyal F., 2011, 2011 Conference for Visual Media Production, P11, DOI 10.1109/CVMP.2011.8
   Delannay D., 2009, Distributed Smart Cameras, P1
   Dimitropoulos K, 2015, INT C COMP VIS THEOR, P773
   Doulamis N., 2017, Mixed reality and gamification for cultural heritage, P567, DOI DOI 10.1007/978-3-319-49607-8_23
   Dunn E., 2009, BRIT MACH VIS C BMVC
   Freundlich C, 2013, IEEE INT CONF ROBOT, P4493, DOI 10.1109/ICRA.2013.6631215
   Giorgi D, 2010, P ACM WORKSH 3D OBJ, P9
   Haner S, 2012, COMPUTER VISION ECCV
   Vasquez-Gomez JI, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P181, DOI 10.1109/CRV.2013.42
   Kriegel S, 2011, IEEE INT CONF ROBOT, P4869
   Li C., 2013, P 6 INT S VIS INF CO, P107
   Li YF, 2005, IEEE T ROBOT, V21, P324, DOI 10.1109/TRO.2004.837239
   Makantasis K, 2016, MULTIMED TOOLS APPL, V75, P3593, DOI 10.1007/s11042-014-2191-z
   Mason J, 2012, IEEE INT C INT ROBOT, P2836, DOI 10.1109/IROS.2012.6386219
   Mauro M., 2014, BMVC
   MAVER J, 1993, IEEE T PATTERN ANAL, V15, P417, DOI 10.1109/34.211463
   Munkelt C, 2014, PLOS ONE, V9, P1
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Niessner M., 2014, P EUR CIT, P13
   Papaoulakis N., 2008, AREA 08 OCT 2008 VAN, P105
   Pito R, 1999, IEEE T PATTERN ANAL, V21, P1016, DOI 10.1109/34.799908
   Potthast C, 2014, J VIS COMMUN IMAGE R, V25, P148, DOI 10.1016/j.jvcir.2013.07.006
   Roy SD, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P276, DOI 10.1109/ICCV.2001.937636
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Trummer Michael, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1642, DOI 10.1109/ICPR.2010.406
   Trummer M, 2009, LECT NOTES COMPUT SC, V5748, P161, DOI 10.1007/978-3-642-03798-6_17
   Vázquez PP, 2003, COMPUT GRAPH FORUM, V22, P689, DOI 10.1111/j.1467-8659.2003.00717.x
   Wenhardt S, 2006, INT C PATT RECOG, P103
   Wu B, 2015, IEEE GEOSCI REMOTE S, V12, P855, DOI 10.1109/LGRS.2014.2364309
   Yang T, 2016, MULTIMED TOOLS APPL, V75, P6925, DOI 10.1007/s11042-015-2618-1
   Yiakoumettis C, 2014, GEOINFORMATICA, V18, P27, DOI 10.1007/s10707-013-0176-0
   Zhang S, 2012, INT J ADV ROBOTIC SY
   Zhaoyin Jia, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P641, DOI 10.1109/ICCVW.2009.5457643
NR 41
TC 3
Z9 3
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9753
EP 9777
DI 10.1007/s11042-018-5822-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200027
OA hybrid
DA 2024-07-18
ER

PT J
AU Jang, HU
   Choi, HY
   Son, J
   Kim, D
   Hou, JU
   Choi, S
   Lee, HK
AF Jang, Han-Ul
   Choi, Hak-Yeol
   Son, Jeongho
   Kim, Dongkyu
   Hou, Jong-Uk
   Choi, Sunghee
   Lee, Heung-Kyu
TI Cropping-resilient 3D mesh watermarking based on consistent segmentation
   and mesh steganalysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D mesh watermarking; Segmentation; Steganalysis; Cropping
ID SPECTRAL WATERMARKING; ROBUST; ALGORITHM
AB This paper presents a new approach to 3D mesh watermarking using consistent segmentation and mesh steganalysis. The method is blind, statistical, and highly robust to cropping attack. The primary watermarking domain is calculated by shape diameter function and the outliers of segments are eliminated by computing the consistency interval of vertex norms. In the watermark embedding process, the mesh is divided into several segments and the same watermark is inserted in each segment. In the watermark extraction process, the final watermark among watermark candidates extracted from multiple segments is determined through watermark trace analysis that is kind of mesh steganalysis. We analyze the watermark trace energy of multiple segments of a mesh and detect the final watermark in the segment with the highest watermark trace energy. To analyze the watermark trace energy, we employ nonlinear least-squares fitting. The experimental results show that the proposed method not only achieves significantly high robustness against cropping attack, but also resists common signal processing attacks such as additive noise, quantization, smoothing and simplification.
C1 [Jang, Han-Ul; Choi, Hak-Yeol; Son, Jeongho; Kim, Dongkyu; Hou, Jong-Uk; Choi, Sunghee; Lee, Heung-Kyu] Korea Adv Inst Sci & Technol, Sch Comp, 291 Daehak Ro, Daejeon 34141, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Lee, HK (corresponding author), Korea Adv Inst Sci & Technol, Sch Comp, 291 Daehak Ro, Daejeon 34141, South Korea.
EM hanulj@kaist.ac.kr; hychoi@mmc.kaist.ac.kr; sonjh@kaist.ac.kr;
   dkim@mmc.kaist.ac.kr; juheo@mmc.kaist.ac.kr; sunghee@kaist.edu;
   heunglee@kaist.ac.kr
RI Lee, Heung Kyu/C-1941-2011
OI Hou, Jong-Uk/0000-0002-7101-0244
FU Ministry of Culture, Sports and Tourism (MCST); Korea Copyright
   Commission
FX This research project was supported by Ministry of Culture, Sports and
   Tourism ( MCST) and from Korea Copyright Commission in 2016.
CR Abu-Marie W., 2010, International Journal of Signal and Image Processing, V1, P196
   Alface PR, 2007, IEEE IMAGE PROC, P2717
   [Anonymous], APSCC 2008 P 3 IEEE
   [Anonymous], COMMUNICATIONS COMPU
   Bilmes JA., 1998, INTCOMPUT SCIINST, V4, P126
   Bors AG, 2013, IEEE T IMAGE PROCESS, V22, P1822, DOI 10.1109/TIP.2012.2236345
   Chen HK, 2016, MULTIMED TOOLS APPL, V75, P10077, DOI 10.1007/s11042-015-3062-y
   Cho JW, 2007, IEEE T SIGNAL PROCES, V55, P142, DOI 10.1109/TSP.2006.882111
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   Coleman TF, 1996, SIAM J OPTIMIZ, V6, P418, DOI 10.1137/0806023
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Gutub A, 2009, 2009 IEEE/ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS, VOLS 1 AND 2, P400, DOI 10.1109/AICCSA.2009.5069356
   Kai Wang, 2010, Proceedings of the Shape Modeling International (SMI 2010), P231, DOI 10.1109/SMI.2010.33
   Kanai S., 1998, IFIP WG, P296
   Konstantinides JM, 2009, IEEE T MULTIMEDIA, V11, P23, DOI 10.1109/TMM.2008.2008913
   Lavoué G, 2006, PROC SPIE, V6312, DOI 10.1117/12.686964
   Lavoué G, 2009, ACM T APPL PERCEPT, V5, DOI 10.1145/1462048.1462052
   Li ZY, 2016, INT CONF ACOUST SPEE, P2144, DOI 10.1109/ICASSP.2016.7472056
   Liu Y, 2012, IEEE T INF FOREN SEC, V7, P1459, DOI 10.1109/TIFS.2012.2204251
   Liu Y, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P43
   Luo M, 2011, IEEE T IMAGE PROCESS, V20, P2813, DOI 10.1109/TIP.2011.2142004
   Marvel LM, 1999, IEEE T IMAGE PROCESS, V8, P1075, DOI 10.1109/83.777088
   Mun SM, 2015, INT CONF 3D IMAG
   Ohbuchi R, 2002, COMPUT GRAPH FORUM, V21, P373, DOI 10.1111/1467-8659.t01-1-00597
   Ohbuchi R., 2001, Graphics Interface, P9
   Praun E, 1999, COMP GRAPH, P49, DOI 10.1145/311535.311540
   Rolland-Neviere Xavier, 2014, IEEE Transactions on Information Forensics and Security, V9, P1491, DOI 10.1109/TIFS.2014.2336376
   Shamir A, 2008, COMPUT GRAPH FORUM, V27, P1539, DOI 10.1111/j.1467-8659.2007.01103.x
   Shapira L, 2008, VISUAL COMPUT, V24, P249, DOI 10.1007/s00371-007-0197-5
   Taubin G., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P351, DOI 10.1145/218380.218473
   Wang K, 2011, COMPUT GRAPH-UK, V35, P1, DOI 10.1016/j.cag.2010.09.010
   Wang K, 2008, IEEE T MULTIMEDIA, V10, P1513, DOI 10.1109/TMM.2008.2007350
   Wu JH, 2005, VISUAL COMPUT, V21, P848, DOI 10.1007/s00371-005-0311-5
   Yang Y, 2017, IEEE T VIS COMPUT GR, V23, P1002, DOI 10.1109/TVCG.2016.2525771
   Yang Y, 2014, IEEE IMAGE PROC, P4782, DOI 10.1109/ICIP.2014.7025969
   Yin KK, 2001, COMPUT GRAPH-UK, V25, P409, DOI 10.1016/S0097-8493(01)00065-6
   Yu ZQ, 2003, PATTERN RECOGN, V36, P2603, DOI 10.1016/S0031-3203(03)00086-4
   Zabih R, 2004, PROC CVPR IEEE, P437
   Zafeiriou S, 2005, IEEE T VIS COMPUT GR, V11, P596, DOI 10.1109/TVCG.2005.71
   Zaid AO, 2015, MULTIMED TOOLS APPL, V74, P5897, DOI 10.1007/s11042-014-1896-3
   Zhan YZ, 2014, J ZHEJIANG U-SCI C, V15, P351, DOI 10.1631/jzus.C1300306
NR 42
TC 16
Z9 18
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5685
EP 5712
DI 10.1007/s11042-017-4483-6
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800025
DA 2024-07-18
ER

PT J
AU Liu, YN
   Zhong, Q
   Xie, M
   Chen, ZB
AF Liu, Yi-Ning
   Zhong, Qi
   Xie, Ming
   Chen, Zu-Bin
TI A novel multiple-level secret image sharing scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple-level; Secret image; Progressive; Authentication; Secret
   sharing
ID AUTHENTICATION; STEGANOGRAPHY; THRESHOLD; QUALITY
AB In this paper, a novel multiple-level secret image sharing scheme is proposed, which achieves the additional steganography, the authentication, and the scalable abilities. The key idea is that the secret image is revealed at different quality levels with the different priorities. Specifically, based on the weight function and Shamir's secret sharing, the meaningful shadow images are distributed among the different level participants, and the participants with the higher priority are capable of revealing more information about the secret image. Meanwhile, the proposed scheme enables the cover images to be losslessly restored. Besides, the secret image can be progressively revealed when more participants of the different levels cooperate together. Moreover, the verifiable correctness of the shadow images prevents from cheating among the participants before the recovery of the secret image.
C1 [Liu, Yi-Ning; Zhong, Qi] Guilin Univ Elect Technol, Guangxi Key Lab Trusted Software, Guilin 541004, Peoples R China.
   [Liu, Yi-Ning] Guilin Univ Elect Technol, Guangxi Coll & Univ Key Lab Intelligent Proc Comp, Guilin 541004, Peoples R China.
   [Xie, Ming; Chen, Zu-Bin] Guangxi Power Grid Co, Nanning 530023, Peoples R China.
C3 Guilin University of Electronic Technology; Guilin University of
   Electronic Technology; China Southern Power Grid
RP Liu, YN (corresponding author), Guilin Univ Elect Technol, Guangxi Key Lab Trusted Software, Guilin 541004, Peoples R China.; Liu, YN (corresponding author), Guilin Univ Elect Technol, Guangxi Coll & Univ Key Lab Intelligent Proc Comp, Guilin 541004, Peoples R China.
EM ynliu2011@gmail.com
OI Zhong, Qi/0000-0002-3736-7135; Liu, Yining/0000-0002-6487-7595
FU Guangxi Colleges and Universities Key Laboratory of Intelligent
   Processing of Computer Images and Graphics [GIIP201604]; Natural Science
   Foundation of China [61672029, 61363069, 61662016, 61301166]; High Level
   Innovation Team of Guangxi Colleges and Universities; Foundation of
   Guangxi Bureau of Education [ky2016YB155]; Innovation Project of Guangxi
   Graduate Education [YCSZ2015149]
FX Project supported by the Natural Science Foundation of China (Nos.
   61363069, 61662016, 61301166, 61672029 ), Guangxi Colleges and
   Universities Key Laboratory of Intelligent Processing of Computer Images
   and Graphics (No. GIIP201604), Foundation of Guangxi Bureau of
   Education(ky2016YB155), High Level Innovation Team of Guangxi Colleges
   and Universities, and the Innovation Project of Guangxi Graduate
   Education (No. YCSZ2015149).
CR [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], INFORM KNOWLEDGE TEC
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], LNCS
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Chang CC, 2009, PATTERN RECOGN, V42, P3097, DOI 10.1016/j.patcog.2009.04.012
   Guo C, 2012, PATTERN RECOGN LETT, V33, P83, DOI 10.1016/j.patrec.2011.09.030
   Huang CP, 2010, J SYST SOFTWARE, V83, P517, DOI 10.1016/j.jss.2009.10.012
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin SJ, 2009, OPT ENG, V48, DOI 10.1117/1.3168644
   Pakniat N, 2014, J VIS COMMUN IMAGE R, V25, P1093, DOI 10.1016/j.jvcir.2014.03.004
   Pan XM, 2014, J MOD OPTIC, V61, P1470, DOI 10.1080/09500340.2014.941430
   Patil S, 2014, 2014 INTERNATIONAL CONFERENCE ON CIRCUITS, SYSTEMS, COMMUNICATION AND INFORMATION TECHNOLOGY APPLICATIONS (CSCITA), P225, DOI 10.1109/CSCITA.2014.6839263
   Rose AA, 2015, PROCEDIA COMPUT SCI, V58, P140, DOI 10.1016/j.procs.2015.08.042
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Tassa T, 2004, LECT NOTES COMPUT SC, V2951, P473
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Ulutas M, 2011, IMAGING SCI J, V59, P154, DOI 10.1179/136821910X12863757400240
   Wang RZ, 2007, SIGNAL PROCESS-IMAGE, V22, P363, DOI 10.1016/j.image.2006.12.012
   Wu CC, 2011, J SYST SOFTWARE, V84, P2196, DOI 10.1016/j.jss.2011.06.021
   Xia Z, 2016, IEEE T INF FOREN SEC, P1
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CN, 2012, OPT COMMUN, V285, P1725, DOI 10.1016/j.optcom.2011.12.003
   Yang CN, 2011, J SYST SOFTWARE, V84, P1726, DOI 10.1016/j.jss.2011.05.008
   Yang CN, 2010, OPT COMMUN, V283, P1750, DOI 10.1016/j.optcom.2009.12.077
NR 25
TC 20
Z9 20
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 6017
EP 6031
DI 10.1007/s11042-017-4512-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800040
DA 2024-07-18
ER

PT J
AU Rani, PI
   Prasath, TH
AF Rani, P. Ithaya
   Prasath, T. Hari
TI Ranking, clustering and fusing the normalized LBP temporal facial
   features for face recognition in video sequences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Normalized local binary patterns; Clustering; Re-ranking; Kendall tau
   distance
AB This paper proposes a novel approach for recognizing faces in videos with high recognition rate. Initially, the feature vector based on Normalized Local Binary Patterns is obtained for the face region. A set of training and testing videos are used in this face recognition procedure. Each frame in the query video is matched with the signature of the faces in the database using Euclidean distance and a rank list is formed. Each ranked list is clustered and its reliability is analyzed for re-ranking. Multiple re-ranked lists of the query video is fused together to form a video signature. This video signature embeds diverse intra-personal variations such as poses, expressions and facilitates in matching two videos with large variations. For matching two videos, their composite ranked lists are compared using a Kendall Tau distance measure. The developed methods are deployed on the YouTube and ChokePoint videos, and they exhibit significant performance improvement owing to their novel approach when compared with the existing techniques.
C1 [Rani, P. Ithaya] Mepco Schlenk Engn Coll, Dept Comp Sci & Engn, Amathur Post 626005, Sivakasi, India.
   [Prasath, T. Hari] Kalasalingam Univ, Dept Elect & Elect Engn, Anand Nagar 626126, Krishnankoil, India.
C3 Mepco Schlenk Engineering College; Kalasalingam Academy of Research &
   Education
RP Rani, PI (corresponding author), Mepco Schlenk Engn Coll, Dept Comp Sci & Engn, Amathur Post 626005, Sivakasi, India.
EM muhilrani@gmail.com; hariprasath1992@gmail.com
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Alexandrov P.S., 2011, COMPUTER VISION PATT, P1
   [Anonymous], P INT C IM PROC
   [Anonymous], IEEE BIOM WORKSH COM
   [Anonymous], J COMPUT LINGUIST CH
   Barr JR, 2012, INT J PATTERN RECOGN, V26, DOI 10.1142/S0218001412660024
   Borgi MA, 2015, MULTIMED TOOLS APPL, V74, P11281, DOI 10.1007/s11042-014-2228-3
   Chen YC, 2012, LECT NOTES COMPUT SC, V7577, P766, DOI 10.1007/978-3-642-33783-3_55
   Chen YH, 2013, PROCEEDINGS OF THE 2013 6TH IEEE CONFERENCE ON ROBOTICS, AUTOMATION AND MECHATRONICS (RAM), P1, DOI 10.1109/RAM.2013.6758550
   Cui Z, 2013, PROC CVPR IEEE, P3554, DOI 10.1109/CVPR.2013.456
   Cui Z, 2012, PROC CVPR IEEE, P2626, DOI 10.1109/CVPR.2012.6247982
   Hu CH, 2015, MULTIMED TOOLS APPL, V74, P10313, DOI 10.1007/s11042-014-2168-y
   Hu Y., 2011, Proc. CVPR, P27
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Jiang XD, 2016, MULTIMED TOOLS APPL, V75, P11801, DOI 10.1007/s11042-015-2659-5
   Jin Y, 2016, MULTIMED TOOLS APPL, V75, P11831, DOI 10.1007/s11042-015-2650-1
   Kim M, 2008, PROCEED INT C COMPUT, P1
   Liu XM, 2003, PROC CVPR IEEE, P340
   O'Toole AJ, 2002, TRENDS COGN SCI, V6, P261, DOI 10.1016/S1364-6613(02)01908-3
   Sculley D, 2007, PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING, P587
   Shen FM, 2016, MULTIMED TOOLS APPL, V75, P12535, DOI 10.1007/s11042-014-2340-4
   Sun YF, 2014, MULTIMED TOOLS APPL, V73, P2063, DOI 10.1007/s11042-013-1638-y
   Tie Y, 2009, PATTERN RECOGN, V42, P1859, DOI 10.1016/j.patcog.2008.11.026
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang RP, 2012, IEEE T IMAGE PROCESS, V21, P4466, DOI 10.1109/TIP.2012.2206039
   Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566
   Zhou SH, 2003, COMPUT VIS IMAGE UND, V91, P214, DOI 10.1016/S1077-3142(03)00080-8
   Zhu PF, 2014, IEEE T INF FOREN SEC, V9, P1120, DOI 10.1109/TIFS.2014.2324277
NR 28
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5785
EP 5802
DI 10.1007/s11042-017-4491-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800029
DA 2024-07-18
ER

PT J
AU Stankovic, I
   Orovic, I
   Dakovic, M
   Stankovic, S
AF Stankovic, Isidora
   Orovic, Irena
   Dakovic, Milos
   Stankovic, Srdjan
TI Denoising of sparse images in impulsive disturbance environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gradient algorithm; Compressive sensing; Denoising; Image processing;
   Reconstruction
ID SIGNAL RECONSTRUCTION; RECOVERY; REMOVAL; NOISE
AB The paper presents a method for denoising and reconstruction of sparse images based on a gradient-descent algorithm. It is assumed that the original (non-noisy) image is sparse in the two-dimensional Discrete Cosine Transform (2D-DCT) domain. It is also assumed that a number of image pixels is corrupted by a salt and pepper noise. In addition, we assume that there are pixels corrupted by a noise of any value. In this paper we introduce a method to find the positions of the corrupted pixels when the noise is not of the salt and pepper form. The proposed algorithm for noisy pixels detection and reconstruction works blindly. It does not require the knowledge about the positions of corrupted pixels. The only assumption is that the image is sparse and that the noise degrades this property. The advantage of this reconstruction algorithm is that we do not change the uncorrupted pixels in the process of the reconstruction, unlike common reconstruction methods. Corrupted pixels are detected and removed iteratively using the gradient of sparsity measure as a criterion for detection. After the corrupted pixels are detected and removed, the gradient algorithm is employed to reconstruct the image. The algorithm is tested on both grayscale and color images. Additionally, the case when both salt and pepper noise and a random noise, within the pixel values range, are combined is considered. The proposed method can be used without explicitly imposing the image sparsity in a strict sense. Quality of the reconstructed image is measured for different sparsity and noise levels using the structural similarity index, the mean absolute error, mean-square error and peak signal-to-noise ratio and compared to the traditional median filter and recent algorithms, one based on the total-variations reconstruction and a two-stage adaptive algorithm.
C1 [Stankovic, Isidora; Orovic, Irena; Dakovic, Milos; Stankovic, Srdjan] Univ Montenegro, Fac Elect Engn, Podgorica 20000, Montenegro.
C3 University of Montenegro
RP Stankovic, I (corresponding author), Univ Montenegro, Fac Elect Engn, Podgorica 20000, Montenegro.
EM isidoras@ac.me; irenao@ac.me; milos@ac.me; srdjan@ac.me
RI Stankovic, Isidora/AAL-4037-2020; Stankovic, Srdjan/AAH-2804-2019;
   Orovic, Irena/U-9175-2018; Dakovic, Milos/C-1319-2010
OI Stankovic, Isidora/0000-0003-3942-7194; Stankovic,
   Srdjan/0000-0002-4795-494X; Orovic, Irena/0000-0002-1752-9053; Dakovic,
   Milos/0000-0002-3317-3632
FU Montenegrin Ministry of Science - World Bank loan: CS-ICT "New ICT
   Compressive sensing based trends applied to: multimedia, biomedicine and
   communications"
FX This work is supported by the Montenegrin Ministry of Science, project
   grant funded by the World Bank loan: CS-ICT "New ICT Compressive sensing
   based trends applied to: multimedia, biomedicine and communications".
CR [Anonymous], TELECOMMUNICATIONS R
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P118, DOI 10.1109/MSP.2007.4286571
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candès EJ, 2008, CR MATH, V346, P589, DOI 10.1016/j.crma.2008.03.014
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Caselles Vicent., 2011, Hand- book of Mathematical Methods in Imaging, 1016-1057
   Djurovic I, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0113-x
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430
   Elad M, 2010, SPARSE AND REDUNDANT REPRESENTATIONS, P3, DOI 10.1007/978-1-4419-7011-4_1
   Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281
   Fornasier M, 2008, APPL COMPUT HARMON A, V25, P187, DOI 10.1016/j.acha.2007.10.005
   Guo D, 2014, ADV MULTIMED, V2014, DOI 10.1155/2014/682747
   Huang S, 2010, ELECTRON LETT, V46, P1198, DOI 10.1049/el.2010.0833
   Koivisto P, 2003, G EURASIP J ADV SIGN
   Lourakis M, 2016, TV L1 IMAGE DENOISIN
   Luo WB, 2006, IEEE SIGNAL PROC LET, V13, P413, DOI 10.1109/LSP.2006.873144
   Ponomarenko NN, 2008, PROC SPIE, V6812, DOI 10.1117/12.764893
   Ramadan ZM, 2012, CIRC SYST SIGNAL PR, V31, P1397, DOI 10.1007/s00034-011-9380-z
   Rauhut H, 2008, IEEE T INFORM THEORY, V54, P2210, DOI 10.1109/TIT.2008.920190
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   Stankovic I, 2016, 39 INT CONV INF COMM
   Stankovic I, 2014, IMAGE RECONSTRUCTION
   Stankovic L, 2016, CIRCUITS SY IN PRESS, V35
   Stankovic L, 2015, DIGITAL SIGNAL PROCE
   Stankovic L, 2014, IET SIGNAL PROCESS, V8, P246, DOI 10.1049/iet-spr.2013.0385
   Stankovic L, 2014, SIGNAL PROCESS, V94, P401, DOI 10.1016/j.sigpro.2013.07.002
   Stankovic S, 2014, SIGNAL PROCESS, V104, P43, DOI 10.1016/j.sigpro.2014.03.049
   Stankovic Srdjan., 2012, Multimedia signals and systems
   Studer C, 2012, IEEE T INFORM THEORY, V58, P3115, DOI 10.1109/TIT.2011.2179701
   Wang XL, 2011, OPT ENG, V50, DOI 10.1117/1.3625416
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang BX, 2016, J VIS COMMUN IMAGE R, V38, P814, DOI 10.1016/j.jvcir.2016.04.025
NR 33
TC 16
Z9 17
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5885
EP 5905
DI 10.1007/s11042-017-4502-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800034
DA 2024-07-18
ER

PT J
AU Xu, QZ
   Wang, ZT
   Wang, FY
   Li, JJ
AF Xu, Qingzhen
   Wang, Zhoutao
   Wang, Fengyun
   Li, Jiajia
TI Thermal comfort research on human CT data modeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Heat and moisture exchange; L-W surface; Functional garment CAD
ID HIGHLY PARALLEL FRAMEWORK; HEVC MOTION ESTIMATION; MANY-CORE PROCESSORS;
   RECURRENCE SURFACES; MOVEMENT; POSTURE; WIND
AB This paper presented a modeling method based on L-W Surface. We obtained our body CT data by CT scan, and get simulation manikin through the 3D reconstruction. We gridded manikin by thermal environment of the digital home, then build multi-scale coupling calculated model based on three-dimensional grid manikins and 25-node physiological model. At last, this paper described the body's adjustment process from the physical point of view, and experimental results showed that the performance of clothing's heat and moisture transfer could be dynamically simulated by computer. It also could get simulation effect of human heat and moisture feeling.
C1 [Xu, Qingzhen; Wang, Zhoutao; Wang, Fengyun; Li, Jiajia] South China Normal Univ, Sch Comp Sci, Guangzhou 510631, Guangdong, Peoples R China.
C3 South China Normal University
RP Xu, QZ (corresponding author), South China Normal Univ, Sch Comp Sci, Guangzhou 510631, Guangdong, Peoples R China.
EM xqz1997@163.com
RI wong, fereen/ABH-9852-2022
FU Guangdong Provincial Public Research and Capacity Building Foundation
   [2016A020223012]; National Natural Science Foundation of China
   [61402185]; Natural Science Foundation of Guangdong Province
   [2015A030313382]
FX The Project was supported by the National Natural Science Foundation of
   China (No. 61402185), Natural Science Foundation of Guangdong Province
   (No. 2015A030313382), and Guangdong Provincial Public Research and
   Capacity Building Foundation funded project (Nos. 2016A020223012).
CR [Anonymous], THESIS
   Cheng YD, 2012, BUILD ENVIRON, V47, P13, DOI 10.1016/j.buildenv.2011.05.011
   HAVENITH G, 1990, ERGONOMICS, V33, P67, DOI 10.1080/00140139008927094
   HAVENITH G, 1990, ERGONOMICS, V33, P989, DOI 10.1080/00140139008925308
   Jia N, 2016, MOB INF SYST, V2016, DOI 10.1155/2016/8586493
   LI Y, 2001, 6 AS TEXT C HONG KON
   Li Y, 1999, SEM ANN C INT THEOR
   Luo XN, 2004, J COMPUT APPL MATH, V163, P189, DOI 10.1016/j.cam.2003.08.064
   Luo XN, 2002, J COMPUT APPL MATH, V144, P221, DOI 10.1016/S0377-0427(01)00561-1
   Murakami S., 1998, ROOMVENT, V98b, P141
   Tanabe S, 2002, ENERG BUILDINGS, V34, P637, DOI 10.1016/S0378-7788(02)00014-2
   Wang RM, 2004, J COMPUT APPL MATH, V163, P277, DOI 10.1016/j.cam.2003.08.073
   Wang RM, 2014, MULTIMED TOOLS APPL, V71, P395, DOI 10.1007/s11042-013-1519-4
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
   Zhu FL, 2013, PHYS LETT A, V377, P2324, DOI 10.1016/j.physleta.2013.06.038
NR 19
TC 26
Z9 26
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 6311
EP 6326
DI 10.1007/s11042-017-4537-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800055
DA 2024-07-18
ER

PT J
AU Yang, YQ
   Chen, N
   Jiang, SL
AF Yang, Yongquan
   Chen, Ning
   Jiang, Shenlu
TI Collaborative strategy for visual object tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Collaborative strategy; Visual object tracking; Human-robot interaction
AB Adaptively learning the difference between object and background, discriminative trackers are able to overcome the complex background problem in visual object tracking. However, they are not robust enough to handle the out-of-plane rotation of object, which reduces recall performance. Meanwhile, allowing individual parts certain criterion of freedom, part-based trackers can better handle the out-of-plane rotation problem. However, they are prone to be affected by complex background, leading to low precision performance. To simultaneously address both issues, we propose a collaborative strategy that makes mutual enhancement between a discriminative tracker and a part-based tracker possible to obtain better overall performance. On one hand, we use validated results from the part-based tracker to update the discriminative tracker for recall performance improvement. On the other hand, based on confident results from the discriminative tracker we adaptively update the part-based tracker for simultaneous precision performance improvement. Experiments on various challenge sequences show that our approach achieved the state-of-the-art performance, which demonstrated the effectiveness of mutual collaboration between the two trackers.
C1 [Yang, Yongquan] Xian Polytech Univ, Xian, Shaanxi, Peoples R China.
   [Chen, Ning] Xian Polytech Univ, Sch Comp Sci, Xian, Shaanxi, Peoples R China.
   [Jiang, Shenlu] Beijing Qfeel Technol Co Ltd, Beijing, Peoples R China.
C3 Xi'an Polytechnic University; Xi'an Polytechnic University
RP Yang, YQ (corresponding author), Xian Polytech Univ, Xian, Shaanxi, Peoples R China.
EM remy_yang@foxmail.com; chennvictor@gmail.com; jestshen@hotmail.com
RI Chen, Ning/GRF-4454-2022; Ning, Chen/JCP-4416-2023; Yang,
   Yongquan/ABH-8736-2022
OI Chen, Ning/0000-0002-0056-0337; Yang, Yongquan/0000-0002-3965-4816
FU Xi'an Polytechnic University Innovation Fund for Graduate Students
   [CX201622]; Beijing Qfeel Technology Co., Ltd., China
FX This work was supported by Xi'an Polytechnic University Innovation Fund
   for Graduate Students (CX201622) and Beijing Qfeel Technology Co., Ltd.,
   China. We gratefully acknowledge Intel Labs China for technical support.
CR [Anonymous], AITDSSTR0279
   [Anonymous], RRIV
   [Anonymous], 2012, CVPR
   [Anonymous], 2015, Computer Vision and Pattern Recognition
   [Anonymous], 2005, TNN
   [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], COMPUTER VISION PATT
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], 2005, 2005 IEEE COMPUTER S, DOI DOI 10.1109/CVPR.2005.288
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2016, CVPR
   [Anonymous], 2009, CVPR
   [Anonymous], 2015, ICCV
   [Anonymous], 1981, IJCAI
   [Anonymous], 2009, CVPR
   [Anonymous], 2016, CVPR
   [Anonymous], 2015, ICCV
   [Anonymous], 2012, ECCV
   [Anonymous], TPAMI
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Bradski G.R., 1998, INTEL TECHNOLOGY J, V2, P12
   Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Kalal Zdenek, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2756, DOI 10.1109/ICPR.2010.675
   Kalal Z, 2010, 23 IEEE C COMP VIS P
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Klein DA, 2010, IEEE INT C INT ROBOT, P772, DOI 10.1109/IROS.2010.5650583
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma C., 2015, CVPR
   Nebehay G, 2014, IEEE T PATTERN ANAL, V27, DOI [10. 1109/WACV. 2014. 6836013, DOI 10.1109/WACV.2014.6836013]
   Ozuysal M., 2007, CVPR
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Simonyan K., 2014, 14091556 ARXIV
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tu FW, 2016, LECT NOTES ARTIF INT, V9979, P413, DOI 10.1007/978-3-319-47437-3_40
   Viola P., 2001, P 2001 IEEE COMP SOC, DOI [10.1109/CVPR.2001.990517, DOI 10.1109/CVPR.2001.990517]
   Wu Y., 2013, CVPR
   Zhang K., 2014, ECCV
NR 42
TC 5
Z9 5
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7283
EP 7303
DI 10.1007/s11042-017-4633-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700040
DA 2024-07-18
ER

PT J
AU Kumar, C
   Singh, A
   Kumar, P
AF Kumar, Chandan
   Singh, Amit Kumar
   Kumar, Pardeep
TI A recent survey on image watermarking techniques and its application in
   e-governance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ICT; Spatial and transform domain techniques; Image watermarking;
   Embedding and extraction
ID IMPERCEPTIBLE DUAL WATERMARKING; DISCRETE WAVELET TRANSFORM; COPYRIGHT
   PROTECTION; DIGITAL WATERMARKING; MULTIPLE WATERMARKING; FRAGILE
   WATERMARKING; MEDICAL IMAGES; ROBUST; SCHEME; ALGORITHM
AB This survey presents a brief discussion of different aspects of digital image watermarking. Included in the present discussion are these general concepts: major characteristics of digital watermark, novel and recent applications of watermarking, different kinds of watermarking techniques and common watermark embedding and extraction process. In addition, recent state-of-art watermarking techniques, potential issues and available solutions are discussed in brief. Further, the performance summary of the various state-of-art watermarking techniques is presented in tabular format. This survey contribution will be useful for the researchers to implement efficient watermarking techniques for secure e-governance applications.
C1 [Kumar, Chandan; Singh, Amit Kumar; Kumar, Pardeep] Jaypee Univ Informat Technol, Dept CSE & IT, Solan, Himachal Prades, India.
C3 Jaypee University of Information Technology
RP Singh, A (corresponding author), Jaypee Univ Informat Technol, Dept CSE & IT, Solan, Himachal Prades, India.
EM chandansharmahmr@gmail.com; amit_245singh@yahoo.com;
   pardeepkumarkhokhar@gmail.com
RI Kumar, Chandan/ACB-0720-2022; India, Career Point University Hamirpur
   Himachal Pradesh/HLX-5948-2023; Singh, Amit Kumar/D-1300-2015
OI Kumar, Chandan/0000-0001-9163-3206; India, Career Point University
   Hamirpur Himachal Pradesh/0000-0002-4828-4458; Kumar,
   Pardeep/0000-0001-5303-7219; Singh, Amit Kumar/0000-0001-7359-2068
CR Abbas NH, 2016, INT C MULT IT COMM S
   Aherrahrou N, 2013, 2013 ACS INT C, P1
   Akhaee A., 2010, IEEE T IMAGE PROCESS, V19, P700
   Akhaee MA, 2011, IEEE T INF FOREN SEC, V6, P883, DOI 10.1109/TIFS.2011.2146250
   Amini M, 2017, MULTIMED TOOLS APPL, V76, P3731, DOI 10.1007/s11042-016-3975-0
   [Anonymous], 2016, MULTIMEDIA TOOLS APP
   [Anonymous], 2013, IOSR J COMPUTER ENG
   [Anonymous], MITIGATION SUBSYNCHR
   [Anonymous], 1999, DIGITAL WATERMARKING
   Ansari IA, 2016, INT J MACH LEARN CYB, V7, P1225, DOI 10.1007/s13042-015-0455-1
   Ansari IA, 2017, PATTERN RECOGN LETT, V94, P228, DOI 10.1016/j.patrec.2016.12.010
   Badshah G, 2016, J DIGIT IMAGING, V29, P216, DOI 10.1007/s10278-015-9822-4
   Baiying Lei, 2019, Multimedia Tools and Applications, V78, P27085, DOI 10.1007/s11042-017-4743-5
   Bas P, 2002, IEEE T IMAGE PROCESS, V11, P1014, DOI 10.1109/TIP.2002.801587
   Bhatnagar G, 2013, ACM T MULTIM COMPUT, V10, DOI 10.1145/2542205.2542207
   Cao XY, 2016, J ELECTR COMPUT ENG, V2016, DOI 10.1155/2016/3219042
   Chang CS, 2017, IEEE T IMAGE PROCESS, V26, P3921, DOI 10.1109/TIP.2017.2706502
   Chang CC, 2008, PATTERN RECOGN, V41, P654, DOI 10.1016/j.patcog.2007.06.003
   Chen CH, 2014, OPTIK, V125, P1134, DOI 10.1016/j.ijleo.2013.07.126
   Chen F, 2014, MULTIMED TOOLS APPL, V72, P41, DOI 10.1007/s11042-012-1332-5
   Cox IJ., 2007, DIGITAL WATERMARKING
   Deng Cheng, 2010, Acta Automatica Sinica, V36, P221, DOI 10.3724/SP.J.1004.2010.00221
   Deng C, 2009, SIGNAL PROCESS, V89, P1531, DOI 10.1016/j.sigpro.2009.02.005
   Dorairangaswamy MA, 2009, INT J COMPUT SCI NET, V9, P71
   Eggers JJ, 2001, INT CONF ACOUST SPEE, P1977, DOI 10.1109/ICASSP.2001.941335
   Gao XB, 2010, IEEE T SYST MAN CY C, V40, P278, DOI 10.1109/TSMCC.2009.2037512
   Ghazvini M, 2017, J APPL SEC RES, V12, P260, DOI 10.1080/19361610.2017.1277878
   Ghebleh M, 2014, SECUR COMMUN NETW, V7, P800, DOI 10.1002/sec.783
   Gunjal BL, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-0904-z
   Hamghalam M, 2013, IET IMAGE PROCESS, V7, P451, DOI 10.1049/iet-ipr.2012.0693
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P3085, DOI 10.1007/s11042-013-1579-5
   Horng SJ, 2013, J VIS COMMUN IMAGE R, V24, P1099, DOI 10.1016/j.jvcir.2013.07.008
   Hsia SC, 2002, COMMUN COMPUT PHYS, V85, P436
   Hu YJ, 2006, IEEE T CIRC SYST VID, V16, P129, DOI 10.1109/TCSVT.2005.858742
   Huo YR, 2012, OPT COMMUN, V285, P1759, DOI 10.1016/j.optcom.2011.12.044
   Jamal SS, 2016, WIRELESS PERS COMMUN, V90, P2033, DOI 10.1007/s11277-016-3436-0
   Ji F, 2013, NEUROCOMPUTING, V106, P42, DOI 10.1016/j.neucom.2012.09.032
   Kalantari NK, 2010, IEEE T IMAGE PROCESS, V19, P1504, DOI 10.1109/TIP.2010.2042646
   Kang SI, 2006, 2006 INTERNATIONAL CONFERENCE ON HYBRID INFORMATION TECHNOLOGY, VOL 2, PROCEEDINGS, P660
   Kumar B, 2008, TELEMED J E-HEALTH, V14, P1063, DOI 10.1089/tmj.2008.0033
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Lee WB, 2002, J SYST SOFTWARE, V62, P195, DOI 10.1016/S0164-1212(01)00142-X
   Liu N, 2009, PROCEEDINGS OF THE 2009 WRI GLOBAL CONGRESS ON INTELLIGENT SYSTEMS, VOL III, P411, DOI 10.1109/GCIS.2009.256
   Liu NS, 2015, NONLINEAR DYNAM, V80, P1329, DOI 10.1007/s11071-015-1946-z
   Liu XL, 2017, IEEE INT SYMP CIRC S
   Lu CS, 2001, IMAGE PROC SER, P507
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Lusson F, 2013, SIGNAL PROCESS, V93, P1268, DOI 10.1016/j.sigpro.2012.10.018
   Maheswari S, 2015, RES J APPL SCI ENG T, V9, P507, DOI DOI 10.19026/RJASET.9.1433
   Mingzhi C., 2013, J MULTIMED, V8, P299
   Mohanty SP, 2017, IEEE CONSUM ELECTR M, V6, P83, DOI 10.1109/MCE.2017.2684980
   Mostafa Salwa A K, 2010, Open Biomed Eng J, V4, P93, DOI 10.2174/1874120701004010093
   Mousavi SM, 2014, J DIGIT IMAGING, V27, P714, DOI 10.1007/s10278-014-9700-5
   Naheed T, 2014, OPTIK, V125, P2515, DOI 10.1016/j.ijleo.2013.10.124
   Nazari M, 2017, MULTIMED TOOLS APPL, V76, P16107, DOI 10.1007/s11042-016-3897-x
   Neena PM, 2015, 2015 FIFTH INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING AND COMMUNICATIONS (ICACC), P447, DOI 10.1109/ICACC.2015.74
   Nezhadarya E, 2011, IEEE T INF FOREN SEC, V6, P1200, DOI 10.1109/TIFS.2011.2163627
   Niu PP, 2017, MULTIMED TOOLS APPL, V76, P3403, DOI 10.1007/s11042-016-3935-8
   Niu XM, 2000, IEEE T CONSUM ELECTR, V46, P137, DOI 10.1109/30.826391
   Patra JC, 2010, DIGIT SIGNAL PROCESS, V20, P1597, DOI 10.1016/j.dsp.2010.03.010
   Rahman MM, 2017, GLOB J RES ENG, V16, P1
   Rawat S, 2012, SIGNAL PROCESS, V92, P1480, DOI 10.1016/j.sigpro.2011.12.006
   Ren Y., 2014, International Journal of Multimedia and Ubiquitous Engineering, V9, P231, DOI DOI 10.14257/IJMUE.2014.9.9.24
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Run RS, 2012, EXPERT SYST APPL, V39, P673, DOI 10.1016/j.eswa.2011.07.059
   Sadreazami H, 2016, IEEE T MULTIMEDIA, V18, P196, DOI 10.1109/TMM.2015.2508147
   Sayahi I, 2017, MULTIMED TOOLS APPL, V76, P16439, DOI 10.1007/s11042-016-3920-2
   Seo JS, 2006, IEEE T SIGNAL PROCES, V54, P1537, DOI 10.1109/TSP.2006.870581
   Seo JS, 2004, PATTERN RECOGN, V37, P1365, DOI 10.1016/j.patcog.2003.12.013
   Sharma A, 2017, J INTELL SYST
   Shieh JM, 2006, COMPUT STAND INTER, V28, P428, DOI 10.1016/j.csi.2005.03.006
   SINGH AK, 2016, HDB RES MODERN CRYPT, P246, DOI DOI 10.4018/978-1-5225-0105-3.CH011
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P607, DOI 10.1166/jmihi.2015.1432
   Singh AK, 2014, INT J ELECTRON SECUR, V6, P285, DOI 10.1504/IJESDF.2014.065739
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P406, DOI 10.1166/jmihi.2015.1407
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Singh AK, 2014, P NATL A SCI INDIA A, V84, P345, DOI 10.1007/s40010-014-0140-x
   Singh HV, 2011, COMPUT ELECTR ENG, V37, P714, DOI 10.1016/j.compeleceng.2011.04.006
   Singh HV., 2014, CSI T ICT, V2, P163
   Singh S, 2017, MULTIMED TOOLS APPL, V76, P19113, DOI 10.1007/s11042-017-4570-8
   Singh S, 2017, MULTIMED TOOLS APPL, V76, P3557, DOI 10.1007/s11042-016-3885-1
   Su QT, 2013, OPTIK, V124, P6255, DOI 10.1016/j.ijleo.2013.05.013
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Su QT, 2013, APPL MATH COMPUT, V219, P8455, DOI 10.1016/j.amc.2013.03.013
   Tang CW, 2003, IEEE T SIGNAL PROCES, V51, P950, DOI 10.1109/TSP.2003.809367
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P15191, DOI 10.1007/s11042-016-3744-0
   Tong XJ, 2013, SIGNAL PROCESS-IMAGE, V28, P301, DOI 10.1016/j.image.2012.12.003
   Wang CY, 2017, MULTIMED TOOLS APPL, V76, P16291, DOI 10.1007/s11042-016-3909-x
   Wang JW, 2017, MULTIDIM SYST SIGN P, V28, P617, DOI 10.1007/s11045-015-0363-2
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wang SH, 2004, IEEE T IMAGE PROCESS, V13, P154, DOI 10.1109/TIP.2004.823822
   Wang S, 2014, IEEE T MULTIMEDIA, V16, P311, DOI 10.1109/TMM.2013.2291658
   Wang XY, 2012, J VIS COMMUN IMAGE R, V23, P892, DOI 10.1016/j.jvcir.2012.05.008
   Wang YW, 2002, IEEE T IMAGE PROCESS, V11, P77, DOI 10.1109/83.982816
   Wu X., 2005, Proceedings of the Australasian Information security workshop (AISW 2005) on Grid computing and e-research, V44, P75
   Xiao D, 2015, MULTIMED TOOLS APPL, V74, P7729, DOI 10.1007/s11042-014-2017-z
   Yang HF, 2015, MULTIMED TOOLS APPL, V74, P1725, DOI 10.1007/s11042-013-1714-3
   Yang Y, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2952843
   Yin Zhaoxia, 2014, ScientificWorldJournal, V2014, P604876, DOI 10.1155/2014/604876
   Yuan Y, 2006, FIRST INTERNATIONAL MULTI-SYMPOSIUMS ON COMPUTER AND COMPUTATIONAL SCIENCES (IMSCCS 2006), PROCEEDINGS, VOL 2, P175, DOI 10.1109/IMSCCS.2006.187
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
   Zhu XS, 2016, EURASIP J ADV SIG PR, P1, DOI 10.1186/s13634-016-0373-8
   Zhu XS, 2014, IEEE T MULTIMEDIA, V16, P1888, DOI 10.1109/TMM.2014.2340695
NR 106
TC 89
Z9 90
U1 3
U2 56
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3597
EP 3622
DI 10.1007/s11042-017-5222-8
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600038
DA 2024-07-18
ER

PT J
AU Wu, XC
   Zhu, J
   Xiao, DY
   Lin, XQ
   Ding, R
AF Wu, Xingcheng
   Zhu, Jia
   Xiao, Danyang
   Lin, Xueqin
   Ding, Rui
TI GA-ADE: a novel approach based on graph algorithm to improves the
   detection of adverse drug events
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adverse drug events detection; Personal Rank; Deep Walk; Graph
   algorithm; Clustering
ID PROTEIN-INTERACTION NETWORKS; HOSPITALIZED-PATIENTS; PHARMACOVIGILANCE;
   WARFARIN; RISK
AB The adverse drug event (ADE) is an unexpected and harmful consequence of drug usege. Identifying the association between the use of drugs and adverse events from biomedical literature can contribute a lot to drug safety supervision. Such identification can not only assist drug safety monitoring, but also correct known dependencies among events. In this paper,we propose a novel approach based on graph algorithm to detect adverse drug events(GA-ADE). In our approach, we first construct a graph using candidate ADE extracted from biomedical literature. We then propose a method to select important vertices from the graph as core vertices, and design a Personal Rank algorithm using the core vertices for clustering to build subgraphs. Lastly, the correlation between the drug and the event is calculated based on the subgraphs. Experiments show that our approach is feasible.
C1 [Wu, Xingcheng; Zhu, Jia; Xiao, Danyang; Lin, Xueqin; Ding, Rui] South China Normal Univ, Sch Comp Sci, Guangzhou, Guangdong, Peoples R China.
C3 South China Normal University
RP Zhu, J (corresponding author), South China Normal Univ, Sch Comp Sci, Guangzhou, Guangdong, Peoples R China.
EM xingchengwu@m.scnu.edu.cn; jzhu@m.scnu.edu.cn;
   XiaoDanyang@m.scnu.edu.cn; xqLinv@m.scnu.edu.cn; ding@m.scnu.edu.cn
RI DING, RUI/P-3018-2019; Ding, Rui/JSL-0652-2023
OI DING, RUI/0000-0002-3542-3965; Zhu, Jia/0000-0002-5959-390X
FU Scientfic Research Foundation of Graduate School of South China Normal
   University; Natural Science Foundation of Guangdong Province, China
   [2015A030310509]; Public Research and Capacity Building in Guangdong
   Province, China [2016A030303055]; Major Science and Technology projects
   of Guangdong Province, China [2016B030305004, 2016B010109008,
   2016B010124008]; National Natural Science Foundation of China [61272067]
FX This research was partially supported by the Scientfic Research
   Foundation of Graduate School of South China Normal University, the
   Natural Science Foundation of Guangdong Province, China(2015A030310509),
   the Public Research and Capacity Building in Guangdong Province,
   China(2016A030303055), the Major Science and Technology projects of
   Guangdong Province, China(2016B030305004, 2016B010109008,
   2016B010124008) and the National Natural Science Foundation of
   China(61272067).
CR Ahmad SR, 2003, J GEN INTERN MED, V18, P57, DOI 10.1046/j.1525-1497.2003.20130.x
   Almenoff J, 2005, DRUG SAFETY, V28, P981, DOI 10.2165/00002018-200528110-00002
   [Anonymous], 2012, P 12 ACM IEEE CS JOI
   [Anonymous], 2015, INTR HCUP NAT EM DEP, V2012
   Bader GD, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-2
   Bate A, 2009, PHARMACOEPIDEM DR S, V18, P427, DOI 10.1002/pds.1742
   Bate A, 1998, EUR J CLIN PHARMACOL, V54, P315, DOI 10.1007/s002280050466
   Bianchini M., 2005, ACM Transactions on Internet Technology, V5, P92, DOI 10.1145/1052934.1052938
   Cao S, 2015, GRAREP LEARNING GRAP, P891
   Center for Drug Evaluation and Research, DRUG SAF AV FDA DRUG
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chen Y, 2016, INFORM SYST, V9371, P179
   Classen DC, 1997, JAMA-J AM MED ASSOC, V277, P301, DOI 10.1001/jama.277.4.301
   Ding Y, 2012, J COMPUTER APPL
   Dore DD, 2009, CURR MED RES OPIN, V25, P1019, DOI [10.1185/03007990902820519, 10.1185/03007990902820519 ]
   DuMouchel W, 1999, AM STAT, V53, P177, DOI 10.2307/2686093
   García E, 2013, LINEAR ALGEBRA APPL, V439, P640, DOI 10.1016/j.laa.2012.10.051
   Grover A, 2016, NODE2VEC SCALABLE FE, V2016
   Harpaz R, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-S9-S7
   Haveliwala TH, 2003, INT C WORLD WID WEB, P517
   Lazarou J, 1998, JAMA-J AM MED ASSOC, V279, P1200, DOI 10.1001/jama.279.15.1200
   Luo Zhihui, 2013, AMIA Jt Summits Transl Sci Proc, V2013, P112
   Ma ZG, 2017, IEEE T MULTIMEDIA, V19, P1558, DOI 10.1109/TMM.2017.2659221
   Metlay JP, 2008, J GEN INTERN MED, V23, P1589, DOI 10.1007/s11606-008-0708-8
   Moore TJ, 2012, SEMIN THROMB HEMOST, V38, P905, DOI 10.1055/s-0032-1328890
   Nadimi MH, 2015, MORE ACCURATE CLUSTE, V1
   Newman MEJ, 2006, P NATL ACAD SCI USA, V103, P8577, DOI 10.1073/pnas.0601602103
   Nie FP, 2016, AAAI CONF ARTIF INTE, P1969
   Nikfarjam A, 2015, J AM MED INFORM ASSN, V22, P671, DOI 10.1093/jamia/ocu041
   Ochieng PJ, 2017, INT S BIOINF CHEM ME, P1
   On BW, 2008, THIRD 2008 INTERNATIONAL CONFERENCE ON CONVERGENCE AND HYBRID INFORMATION TECHNOLOGY, VOL 2, PROCEEDINGS, P1081, DOI 10.1109/ICCIT.2008.210
   Ouyang HF, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0062192
   Pan SR, 2015, PATTERN RECOGN, V48, P3783, DOI 10.1016/j.patcog.2015.05.019
   Perozzi B., 2014, KDD, P701, DOI DOI 10.1145/2623330.2623732
   Phan HTT, 2012, BIOINFORMATICS, V28, P1239, DOI 10.1093/bioinformatics/bts119
   Ryan PB, 2013, DRUG SAFETY, V36, pS33, DOI 10.1007/s40264-013-0097-8
   Saless F, 2005, GENET ENG NEWS, V25, P10
   Schneeweiss S, 2010, PHARMACOEPIDEM DR S, V19, P858, DOI 10.1002/pds.1926
   Shen B, 2016, IET NETW, V5, P8, DOI 10.1049/iet-net.2014.0103
   Shetty KD, 2011, J AM MED INFORM ASSN, V18, P668, DOI 10.1136/amiajnl-2011-000096
   Szarfman A, 2002, DRUG SAFETY, V25, P381, DOI 10.2165/00002018-200225060-00001
   Szarfman A, 2006, PHARMACOTHERAPY, V26, P748, DOI 10.1592/phco.26.6.748
   Tatonetti NP, 2012, J AM MED INFORM ASSN, V19, P79, DOI 10.1136/amiajnl-2011-000214
   Thakrar BT, 2007, BRIT J CLIN PHARMACO, V64, P489, DOI 10.1111/j.1365-2125.2007.02900.x
   Van Manen RP, 2007, EXPERT OPIN DRUG SAF, V6, P451, DOI 10.1517/14740338.6.4.451
   van Puijenbroek EP, 1999, BRIT J CLIN PHARMACO, V47, P689, DOI 10.1046/j.1365-2125.1999.00957.x
   Wang XY, 2009, J AM MED INFORM ASSN, V16, P328, DOI 10.1197/jamia.M3028
   Winnenburg R, 2015, J BIOMED INFORM, V57, P425, DOI 10.1016/j.jbi.2015.08.022
   Winnenburg R, 2015, J BIOMED SEMANT, V6, DOI 10.1186/s13326-015-0017-1
   Wu M, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-169
   Yang C, 2015, COMPUTER SCI
   Yang C, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2111
   Zhang L, 2009, AAPS J, V11, P300, DOI 10.1208/s12248-009-9106-3
   Zhu J, 2015, INFORM SCIENCES, V292, P1, DOI 10.1016/j.ins.2014.08.056
NR 57
TC 3
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3493
EP 3507
DI 10.1007/s11042-017-5162-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600032
DA 2024-07-18
ER

PT J
AU Yang, H
   Qing, LB
   He, XH
   Ou, XF
   Liu, XJ
AF Yang, Hong
   Qing, Linbo
   He, Xiaohai
   Ou, Xianfeng
   Liu, Xiaojuan
TI Robust distributed video coding for wireless multimedia sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless multimedia sensor networks; Distributed video coding;
   Distributed joint source-channel coding; Wyner-ziv coding
ID SIDE-INFORMATION; JOINT SOURCE; CHANNEL; CODES; DECODER
AB Coding complexity and error-resilience are the two key factors for video streaming in Wireless Multimedia Sensor Networks (WMSNs). Towards this objective, this paper proposes a Robust Distributed Video Coding (RDVC) framework to optimize the quality of video transmission for WMSNs. A new error-resilient Key frame coding scheme is proposed based on the protection of Wyner-Ziv Coding (WZC), in which additional Wyner-Ziv bits play a significant role for better error resilience and better Rate/Distortion (RD) performance. In addition, following the theoretical background of Distributed Joint Source Channel Coding (DJSCC), a novel distributed source channel codec based on Group Puncture Rate Adaptive IRA code (GPRA-IRA) is proposed, upon which the error-resilient Wyner-Ziv codec is designed. These experimental results show that the proposed RDVC scheme outperforms the relevant coding in terms of RD performance, notably by up to 1-3 dB, while achieving a lower encoding complexity.
C1 [Yang, Hong; Qing, Linbo; He, Xiaohai; Liu, Xiaojuan] Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610064, Sichuan, Peoples R China.
   [Yang, Hong] Univ Elect Sci & Technol China, Chengdu Coll, Chengdu 611731, Sichuan, Peoples R China.
   [Ou, Xianfeng] Hunan Inst Sci & Technol, Yueyang 414006, Peoples R China.
C3 Sichuan University; University of Electronic Science & Technology of
   China; Hunan Institute of Science & Technology
RP Qing, LB (corresponding author), Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610064, Sichuan, Peoples R China.
EM qing_lb@scu.edu.cn; ouxf@hnist.edu.cn
FU Fundamental Research Funds for the Central Universities [2015SCU04A11];
   National Natural Science Foundation of China [61471248]
FX This work was supported by the Fundamental Research Funds for the
   Central Universities (2015SCU04A11) and the National Natural Science
   Foundation of China Grant No. 61471248.
CR Aaron A, 2004, PROC SPIE, V5308, P520, DOI 10.1117/12.527204
   AIGN S, 1995, ICC '95 - 1995 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, CONFERENCE RECORD, VOLS 1-3, P1778, DOI 10.1109/ICC.1995.524505
   Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   Akyildiz IF, 2002, P 2008 INT C COMP SC, V38, P1
   Almalkawi IT, 2010, SENSORS-BASEL, V10, P6662, DOI 10.3390/s100706662
   [Anonymous], 2007, PICT COD S PCS 07
   Brites C, 2015, SIGNAL PROCESS-IMAGE, V32, P81, DOI 10.1016/j.image.2015.01.003
   Cen F, 2014, IET COMMUN, V8, P1325, DOI 10.1049/iet-com.2013.1005
   Cover TM, 2005, ELEMENTS INFORM THEO, P188
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   Hall R.D., 2010, FORENSIC ENTOMOLOGY, P1
   Jacobs M, 2011, 5 ACM IEEE INT C DIS, V47, P1
   KASPI AH, 1994, IEEE T INFORM THEORY, V40, P2031, DOI 10.1109/18.340475
   Liu RK, 2007, P SOC PHOTO-OPT INS, V6508
   Liveris AD, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P53
   Majumder S, 2011, COMM COM INF SC, V147, P207
   Nikzad M, 2014, INT J INFORM TECHNOL, V7, P1
   Park Jongbin, 2011, [JOURNAL OF BROADCAST ENGINEERING, 방송공학회 논문지], V16, P144
   Puri R, 2003, IEEE T IMAGE PROCESS, P1
   Qing L, 2013, OPT ENG, V52, P2131
   Shahid I, 2011, WIR COMM SYST ISWCS, P236
   SHAMAI S, 1995, EUR T TELECOMMUN, V6, P587, DOI 10.1002/ett.4460060514
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Tervo V, 2013, WIRELESS PERS COMMUN, V69, P387, DOI 10.1007/s11277-012-0579-5
   Tonoli C, 2009, EURASIP J IMAGE VIDE, V7238, P347
   Xiao F., 2012, IJACT, V4, P320
   Xiong ZX, 2004, IEEE SIGNAL PROC MAG, V21, P80, DOI 10.1109/MSP.2004.1328091
   Xu Q, 2006, SIGNAL PROCESS, V86, P3212, DOI 10.1016/j.sigpro.2006.03.017
   Xue Z, 2008, WSEAS T COMMUNICATIO, V7, P337
   Xue Z, 2010, IEEE T BROADCAST, V56, P481, DOI 10.1109/TBC.2010.2058371
   You X, 2012, P 2012 INT C EL COMM, P2747
   Yue GS, 2007, IEEE T COMMUN, V55, P1153, DOI 10.1109/TCOMM.2007.898834
   Zhong W, 2003, CONF REC ASILOMAR C, P840
   Zhu XQ, 2009, SENSORS-BASEL, V9, P4901, DOI 10.3390/s90604901
NR 34
TC 17
Z9 18
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4453
EP 4475
DI 10.1007/s11042-016-4245-x
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500024
DA 2024-07-18
ER

PT J
AU Chaker, A
   Kaaniche, M
   Benazza-Benyahia, A
   Antonini, M
AF Chaker, Amani
   Kaaniche, Mounir
   Benazza-Benyahia, Amel
   Antonini, Marc
TI Efficient transform-based texture image retrieval techniques under
   quantization effects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval; Image compression; Transform domain;
   Moment preserving quantization; Distribution preserving quantization;
   Feature extraction
ID GENERALIZED GAUSSIAN DISTRIBUTIONS; JPEG; DISCRIMINATION
AB With the great demand for storing and transmitting images as well as their managing, the retrieval of compressed images is a field of intensive research. While most of the works have been devoted to the case of losslessly encoded images (by extracting features from the unquantized transform coefficients), new studies have shown that lossy compression has a negative impact on the performance of conventional retrieval systems. In this work, we investigate three different quantization schemes and propose for each one an efficient retrieval approach. More precisely, the uniform quantizer, the moment preserving quantizer and the distribution preserving quantizer are considered. The inherent properties of each quantizer are then exploited to design an efficient retrieval strategy, and hence, to reduce the drop of retrieval performances resulting from the quantization effect. Experimental results, carried out on three standard texture databases and a color dataset, show the benefits which can be drawn from the proposed retrieval approaches.
C1 [Chaker, Amani; Benazza-Benyahia, Amel] Univ Carthage, Higher Sch Commun Tunis SUPCOM, COSIM Res Lab, Ariana, Tunisia.
   [Kaaniche, Mounir] Univ Paris 13, Sorbonne Paris Cite, Inst Galilee, L2TI, Villetaneuse, France.
   [Antonini, Marc] Univ Nice Sophia Antipolis, CNRS, UMR I3S 7271, Sophia Antipolis, France.
C3 Universite de Carthage; Universite Paris 13; Centre National de la
   Recherche Scientifique (CNRS); Universite Cote d'Azur
RP Chaker, A (corresponding author), Univ Carthage, Higher Sch Commun Tunis SUPCOM, COSIM Res Lab, Ariana, Tunisia.
EM amani.chaker@supcom.tn; mounir.kaaniche@univ-paris13.fr;
   benazza.amel@supcom.rnu.tn; am@i3s.unice.fr
CR Agarwal S, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS AND COMPUTER NETWORKS (ISCON), P19, DOI 10.1109/ICISCON.2013.6524166
   Allili MS, 2012, IEEE T IMAGE PROCESS, V21, P1452, DOI 10.1109/TIP.2011.2170701
   [Anonymous], 2011, THESIS
   [Anonymous], VIS TEXT
   [Anonymous], 2004, FOURIER SERIES ORTHO
   Au KM, 2007, PATTERN RECOGN, V40, P2049, DOI 10.1016/j.patcog.2006.11.009
   Belalia A, 2015, MULTIMEDIA TOOLS APP, V1-25
   Calderbank AR, 1998, APPL COMPUT HARMON A, V5, P332, DOI 10.1006/acha.1997.0238
   Chaker A, 2013, INT CONF ACOUST SPEE, P1493, DOI 10.1109/ICASSP.2013.6637900
   Chaker A., 2012, IEEE INT S SIGN PROC, P1
   Chang CC, 2004, IMAGE VISION COMPUT, V22, P471, DOI 10.1016/j.imavis.2003.11.008
   CHEN TH, 1994, IEEE IMAGE PROC, P874, DOI 10.1109/ICIP.1994.413480
   Chengyou Wang, 2015, Journal of Communications, V10, P64, DOI 10.12720/jcm.10.1.64-73
   Choy SK, 2010, IEEE T IMAGE PROCESS, V19, P281, DOI 10.1109/TIP.2009.2033400
   Climer S, 2002, PATTERN RECOGN, V35, P2479, DOI 10.1016/S0031-3203(01)00182-0
   Datta R., 2006, ACM COMPUT SURV, V39, P2007
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   DELP EJ, 1991, IEEE T COMMUN, V39, P1549, DOI 10.1109/26.111432
   Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822
   Dongbo Liu, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P536, DOI 10.1109/CSSE.2008.510
   Edmundson D, 2012, IEEE INT C AC SPEECH
   Edmundson D, 2012, IEEE IMAGE PROC, P2421, DOI 10.1109/ICIP.2012.6467386
   Edmundson D, 2012, INT C PATT RECOG, P3188
   Feng GC, 2003, PATTERN RECOGN, V36, P977, DOI 10.1016/S0031-3203(02)00114-0
   Guldogan E, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P9
   Klejsa J, 2013, IEEE T SIGNAL PROCES, V61, P6410, DOI 10.1109/TSP.2013.2286773
   Kuo YH, 2012, IEEE T MULTIMEDIA, V14, P1079, DOI 10.1109/TMM.2012.2190386
   Kwitt R., SALZBURG TEXTURE IMA
   Kwitt R, 2010, IEEE T IMAGE PROCESS, V19, P241, DOI 10.1109/TIP.2009.2032313
   Lasmar NE, 2014, IEEE T IMAGE PROCESS, V23, P2246, DOI 10.1109/TIP.2014.2313232
   Lay JA, 1999, INT CONF ACOUST SPEE, P3009, DOI 10.1109/ICASSP.1999.757474
   Li MY, 2010, IEEE SIGNAL PROC LET, V17, P1014, DOI 10.1109/LSP.2010.2087749
   Mandal MK, 1996, IEEE T CONSUM ELECTR, V42, P557, DOI 10.1109/30.536156
   Mandal MK, 2004, J ELECTRON IMAGING, V13, P182, DOI 10.1117/1.1633286
   Mathiassen JR, 2002, LECT NOTES COMPUT SC, V2352, P133
   Mezaris V, 2004, IEEE T CIRC SYST VID, V14, P606, DOI 10.1109/TCSVT.2004.826768
   MULLER F, 1993, ELECTRON LETT, V29, P1935, DOI 10.1049/el:19931288
   Nadarajah S, 2005, J APPL STAT, V32, P685, DOI 10.1080/02664760500079464
   Ngo CW, 2001, PATTERN RECOGN, V34, P1841, DOI 10.1016/S0031-3203(00)00111-4
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Rabbani M, 2002, SIGNAL PROCESS-IMAGE, V17, P3, DOI 10.1016/S0923-5965(01)00024-8
   Rao K.R, 2014, DISCRETE COSINE TRAN
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Sakji-Nsibi S, 2009, IEEE IMAGE PROC, P253, DOI 10.1109/ICIP.2009.5413483
   SAKJINSIBI S, 2008, IEEE INT C COMM TECH, P1
   Schaefer G, 2008, INT J IMAG SYST TECH, V18, P101, DOI 10.1002/ima.20152
   SCHUCHMAN L, 1964, IEEE T COMMUN TECHN, VCO12, P162, DOI 10.1109/TCOM.1964.1088973
   Sengur A, 2008, EXPERT SYST APPL, V34, P2120, DOI 10.1016/j.eswa.2007.02.032
   SHOHAM Y, 1988, IEEE T ACOUST SPEECH, V36, P1445, DOI 10.1109/29.90373
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   SMITH JR, 1994, IEEE IMAGE PROC, P407, DOI 10.1109/ICIP.1994.413817
   Sweldens W, 1996, APPL COMPUT HARMON A, V3, P186, DOI 10.1006/acha.1996.0015
   Szego G., 1939, AM MATH SOC COLLOQ P, V23
   Taubman D., 2012, JPEG2000: image compression fundamentals, standards and practice, V642
   Van de Wouwer G, 1999, IEEE T IMAGE PROCESS, V8, P592, DOI 10.1109/83.753747
   Verdoolaege G, 2011, INT J COMPUT VISION, V95, P265, DOI 10.1007/s11263-011-0448-9
   Verdoolaege G, 2008, IEEE IMAGE PROC, P169, DOI 10.1109/ICIP.2008.4711718
   Voulgaris G, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P125, DOI 10.1109/ICIP.2001.958440
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Zargari F, 2008, IEEE T CONSUM ELECTR, V54, P1886, DOI 10.1109/TCE.2008.4711250
NR 60
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 1
EP 25
DI 10.1007/s11042-016-4205-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400001
DA 2024-07-18
ER

PT J
AU Feng, L
   Zhou, FQ
   Yu, P
   Li, WJ
AF Feng, Lei
   Zhou, Fanqin
   Yu, Peng
   Li, Wenjing
TI Benders Decomposition-based video bandwidth allocation in mobile media
   cloud network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile media cloud network; Mobile access edge; Video bandwidth
   allocation; Quadratic programming; Benders Decomposition
ID POWER ALLOCATION
AB Due to the fast growth of wireless multimedia applications, mobile media cloud network is getting more and more popular. In the architecture of mobile media cloud network, the wireless access points are placed on edge of the cloud to provide media services for the mobile users. The video bandwidth allocation managed by a centralized media cloud directly affect the user's experiences. In this paper, the problem of the video bandwidth allocation in the mobile media cloud access network is explored. Firstly, this paper formulates the problems in bandwidth allocation in the form of quadratic programming in order to maximize the system revenue on the basis of video bitrates capacity between the user and the Mobile Access Edge Point (MAEP). The optimization model could more vividly explicate the trade-off between the expected bitrates capacity and the allocation fairness of User Equipment (UE). Then this paper subdivides the problem into major and minor ones and proposes an algorithm based on Benders' Decomposition to deal with it. The optimality of the solution is proved by both theoretical and experimental investigations. The error tolerance is analyzed as the algorithm disavows the trade-off between the convergence time and the system performance. The experiments show that the average computing time and confidence interval of the proposed algorithm are lower than Simplex algorithm by 68% and 94% and Barrier algorithm by 46% and 75% respectively at most. Finally, some conclusions are derived from evaluations on the system performance against various network topologies and different values for parameters of the proposed algorithms.
C1 [Feng, Lei; Zhou, Fanqin; Yu, Peng; Li, Wenjing] Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, 10 XiTuCheng Rd, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Feng, L (corresponding author), Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, 10 XiTuCheng Rd, Beijing 100876, Peoples R China.
EM leifeng4mm@aliyun.com
RI Yu, Peng/K-6654-2013; Feng, Lei/AAV-7856-2020; peng, yu/GXW-2071-2022;
   Chen, John/GPW-8839-2022; Zhou, Fanqin/X-8113-2019
OI Yu, Peng/0000-0002-0402-5390; 
FU 863 Program [2015AA01A705]; NSFC [61271187]
FX This paper is supported by the 863 Program (2015AA01A705) and NSFC
   (61271187).
CR Aazam Mohammad, 2014, 2014 43rd International Conference on Parallel Processing Workshops (ICCPW). Proceedings, P361, DOI 10.1109/ICPPW.2014.54
   Ahmed I, 2013, IEEE WIREL COMMUN LE, V2, P239, DOI 10.1109/WCL.2013.012513.130007
   Benders JF, 2005, COMPUT MANAG SCI, V2, P3, DOI 10.1007/s10287-004-0020-y
   Boyd S, 2004, CON VEX OPTIMIZATION, DOI [10.1017/cbo9780511804441, DOI 10.1017/CBO9780511804441]
   Chuah SP, 2015, IEEE T MULTIMEDIA, V17, P687, DOI 10.1109/TMM.2015.2413354
   Dey S., 2012, 2012 International Conference on Computing, Networking and Communications (ICNC), P929, DOI 10.1109/ICCNC.2012.6167561
   Dong Y, 2015, 2015 PICTURE CODING SYMPOSIUM (PCS) WITH 2015 PACKET VIDEO WORKSHOP (PV), P248, DOI 10.1109/PCS.2015.7170084
   I CL, 2014, IEEE COMMUN MAG, V52, P66, DOI 10.1109/MCOM.2014.6736745
   Kosta S, 2012, IEEE INFOCOM SER, P945, DOI 10.1109/INFCOM.2012.6195845
   MCDANIEL D, 1977, MANAGE SCI, V24, P312, DOI 10.1287/mnsc.24.3.312
   Miao Dan., 2011, Proceedings of the 19th ACM international conference on Multimedia, P1237
   Nan XM, 2011, IEEE INT WORKSH MULT
   Pan ZQ, 2015, IEEE T BROADCAST, V61, P166, DOI 10.1109/TBC.2015.2419824
   Qian LP, 2013, IEEE T WIREL COMMUN, V12, P1651, DOI 10.1109/TWC.2013.022113.120470
   Sardis F, 2013, IEEE T MULTIMEDIA, V15, P769, DOI 10.1109/TMM.2013.2240286
   Wang CX, 2014, IEEE COMMUN MAG, V52, P122, DOI 10.1109/MCOM.2014.6736752
   Wen YG, 2014, IEEE T MULTIMEDIA, V16, P885, DOI 10.1109/TMM.2014.2315596
   Xu Y, 2013, IEEE WIREL COMMUN, V20, P46, DOI 10.1109/MWC.2013.6549282
   Zhang XW, 2011, MOBILE NETW APPL, V16, P270, DOI 10.1007/s11036-011-0305-7
NR 19
TC 5
Z9 5
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 877
EP 895
DI 10.1007/s11042-016-4299-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400037
DA 2024-07-18
ER

PT J
AU Jana, B
   Giri, D
   Mondal, SK
AF Jana, Biswapati
   Giri, Debasis
   Mondal, Shyamal Kumar
TI Dual image based reversible data hiding scheme using (7,4) hamming code
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dual image; Hamming error correcting code; Least significant bit;
   Reversible data hiding; Steganalysis; Steganographic attacks
ID WATERMARKING
AB In this paper, we propose a new dual-image based reversible data hiding scheme through (7,4) Hamming code (RDHHC) using shared secret key. A block of seven pixels are collected from cover image and copied into two arrays then it is adjusted redundant Least Significant Bits (LSBs) using odd parity such that any error creation is encountered at the sender end and recovered at the receiver end. Before data embedding, we first complement the bit at shared secret position. After that, secret message bit is embedded by error creation caused by tamper in any suitable position except secret position and that error is detected as well as corrected at the receiver end using Hamming error correcting code. One shared secret position kappa and one shared secret key xi help to perform data embedding, data extraction and recovery of the original image. The secret data and original cover image are successfully recovered at the receiver end from dual stego image. Finally, we compare our scheme with other state-of-the-art methods and obtain reasonably better performance in terms of PSNR.
C1 [Jana, Biswapati] Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, W Bengal, India.
   [Giri, Debasis] Haldia Inst Technol, Dept Comp Sci & Engn, Haldia 721657, W Bengal, India.
   [Mondal, Shyamal Kumar] Vidyasagar Univ, Dept Appl Math Oceanol & Comp Programming, Midnapore 721102, India.
C3 Vidyasagar University; Haldia Institute of Technology; Vidyasagar
   University
RP Jana, B (corresponding author), Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, W Bengal, India.
EM biswapatijana@gmail.com; debasis_giri@hotmail.com;
   shyamal_260180@yahoo.com
RI Jana, Prof. Biswapati/AAA-2154-2019; Giri, Debasis/W-7417-2019
OI Jana, Prof. Biswapati/0000-0003-4476-3459; Giri,
   Debasis/0000-0003-3033-3036
CR [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   Chang CJ, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/526806
   Chang CC, 2008, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, P16, DOI 10.1109/ISECS.2008.222
   Chang CC, 2009, THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING (MUE 2009), P145, DOI 10.1109/MUE.2009.35
   Chang T. Duc, 2007, P IEEE REG 10 C NOV, P1, DOI [10.1109/TENCON.2007.4483783, DOI 10.1109/TENCON.2007.4483783]
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Fu MS, 2001, SIGNAL PROCESS-IMAGE, V16, P909, DOI 10.1016/S0923-5965(00)00052-7
   Kim C, 2011, LECT NOTES ARTIF INT, V6592, P372, DOI 10.1007/978-3-642-20042-7_38
   Kim HJ, 2010, COMPUT MATH APPL, V60, P319, DOI 10.1016/j.camwa.2010.01.006
   Lee CF, 2013, TELECOMMUN SYST, V52, P2237, DOI 10.1007/s11235-011-9529-x
   Lee CF, 2012, DIGIT SIGNAL PROCESS, V22, P941, DOI 10.1016/j.dsp.2012.05.015
   Lee CF, 2010, J SYST SOFTWARE, V83, P1864, DOI 10.1016/j.jss.2010.05.078
   Lee K.-H., 2009, P 3 INT C UB INF MAN, P228, DOI [10.1145/1516241.1516281.11T.-C, DOI 10.1145/1516241.1516281.11T.-C]
   Liao PS, 2005, LECT NOTES ARTIF INT, V3682, P593
   Lien BK, 2015, ADV INTELL SYST, V329, P179, DOI 10.1007/978-3-319-12286-1_18
   Lien BK, 2011, MULTIMED TOOLS APPL, V52, P499, DOI 10.1007/s11042-010-0497-z
   Lu TC, 2015, SIGNAL PROCESS, V108, P77, DOI 10.1016/j.sigpro.2014.08.022
   Lu ZM, 2006, LECT NOTES COMPUT SC, V4283, P71
   MA ZP, 2013, J SHANGHAI U NAT SCI, V2
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Pan JS, 2006, INT J COMPUT SCI NET, V6, P147
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Kieu TD, 2011, EXPERT SYST APPL, V38, P10648, DOI 10.1016/j.eswa.2011.02.122
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tseng HW, 2009, INFORM SCIENCES, V179, P2460, DOI 10.1016/j.ins.2009.03.014
   Yu FX, 2009, STUD COMPUT INTELL, V227, P181
NR 26
TC 30
Z9 31
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 763
EP 785
DI 10.1007/s11042-016-4230-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400032
DA 2024-07-18
ER

PT J
AU Liu, DY
   An, P
   Ma, R
   Yang, C
   Shen, LQ
   Li, K
AF Liu, Deyang
   An, Ping
   Ma, Ran
   Yang, Chao
   Shen, Liquan
   Li, Kai
TI Scalable coding of 3D holoscopic image by using a sparse interlaced view
   image set and disparity map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D holoscopic image; Image coding; Scalable coding; HEVC
ID COMPRESSION METHOD; HEVC; PREDICTION
AB 3D holoscopic imaging, also known as integral imaging, light field imaging or plenoptic imaging, can provide natural and fatigue-free 3D visualization. Holoscopic contents captured by the plenoptic camera contain both spatial and angular information of a 3D scene. Therefore, view images with different perspectives can be rendered from the holoscopic contents. A coding scheme to compress the 3D holoscopic image by exploiting the high spatial correlation among the rendered view images will be advantageous. Therefore, in this paper, an efficient scalable coding scheme is proposed to compress the 3D holoscopic image by utilizing such high spatial correlation. We firstly re-arrange the holoscopic contents to form an interlaced view image. A sparse format is then proposed to express the interlaced view image. With the reconstructed image derived by disparity map based sifting and interpolation, the full interlaced view image is coded by using the reconstructed image as a reference frame. As an outcome of the representation, a scalable structure with three layers can be provided by the proposed scheme. Experimental results demonstrate that the 3D holoscopic image can be compressed efficiently with over 44 percent bit rate reduction compared with HEVC. Meanwhile, the proposed scheme can also surpass several other prediction schemes in this field.
C1 [Liu, Deyang; An, Ping; Ma, Ran; Yang, Chao; Shen, Liquan; Li, Kai] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200072, Peoples R China.
   [Liu, Deyang] Anqing Normal Univ, Sch Comp & Informat, Anqing 246133, Peoples R China.
C3 Shanghai University; Anqing Normal University
RP An, P (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200072, Peoples R China.
EM anping@shu.edu.cn
RI Liu, Deyang/AAB-1184-2020; Liu, Deyang/ABG-2705-2020; Liu,
   Deyang/AAX-5429-2020; Shen, Liquan/D-4832-2012
OI Liu, Deyang/0000-0001-7991-8735; 
FU National Natural Science Foundation of China [61571285, U1301257,
   61422111, 61301112]
FX This work was supported in part by the National Natural Science
   Foundation of China, under Grants 61571285, U1301257, 61422111, and
   61301112.
CR Adedoyin S, 2007, IEEE T CONSUM ELECTR, V53, P1768, DOI 10.1109/TCE.2007.4429282
   Adelson E.H., 1991, Computational Models of Visual Processing, P3
   Aggoun A., 2006, 2006 IEEE INT C AC S
   Aggoun A, 2013, IEEE MULTIMEDIA, V20, P28, DOI 10.1109/MMUL.2012.42
   Aggoun A, 2011, J DISP TECHNOL, V7, P586, DOI 10.1109/JDT.2011.2159359
   [Anonymous], HM 16 2 SCM 3 0 REF
   [Anonymous], 2013, Technical Report JCTVC-L1100
   Conti C., 2012, Proceedings of the 18th Brazilian Symposium on Multimedia and the Web, P131
   Conti C, 2016, SIGNAL PROCESS-IMAGE, V42, P59, DOI 10.1016/j.image.2016.01.008
   Conti C, 2013, IEEE SIGNAL PROC LET, V20, P819, DOI 10.1109/LSP.2013.2267234
   Conti C, 2012, IEEE IMAGE PROC, P1325, DOI 10.1109/ICIP.2012.6467112
   Dick J., 2011, 2011 IEEE EUROCON IN, P1
   Elharar E, 2007, J DISP TECHNOL, V3, P321, DOI 10.1109/JDT.2007.900915
   Flynn D., 2013, JCTVCN1005
   Forman MC, 1997, IEE CONF PUBL, P32, DOI 10.1049/cp:19970848
   Georgiev T, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3442712
   Gortler S.J., 1996, ACM T GRAPH, V23, P43
   LAMBOOIJ MTM, 2007, P SPIE IS T ELECT IM, V6490
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Li Y, 2016, IEEE T CIRC SYST VID, V26, P1308, DOI 10.1109/TCSVT.2015.2450333
   Li Y, 2016, IEEE T IMAGE PROCESS, V25, P80, DOI 10.1109/TIP.2015.2498406
   Liu D, 2016, J ELECTRON IMAGING, V25
   Liu DY, 2016, SIGNAL PROCESS-IMAGE, V47, P438, DOI 10.1016/j.image.2016.08.004
   Liu DY, 2015, 2015 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING, P201, DOI 10.1109/ChinaSIP.2015.7230391
   Lucas LER, 2014, EUR SIGNAL PR CONF, P11
   Shi S, 2011, IEEE IMAGE PROC, P137, DOI 10.1109/ICIP.2011.6115695
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tan TK, 2006, IEEE IMAGE PROC, P1693, DOI 10.1109/ICIP.2006.312685
   Türkan M, 2012, IEEE T IMAGE PROCESS, V21, P1885, DOI 10.1109/TIP.2011.2170700
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yeom S, 2004, OPT EXPRESS, V12, P1632, DOI 10.1364/OPEX.12.001632
   Yu H., 2014, Committee Input Doc. JCTVC-S1015
   Yun Li, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P539, DOI 10.1109/ICASSP.2014.6853654
   Zaharia R, 2002, SIGNAL PROCESS-IMAGE, V17, P231, DOI 10.1016/S0923-5965(01)00020-0
NR 34
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 1261
EP 1283
DI 10.1007/s11042-016-4293-2
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400052
DA 2024-07-18
ER

PT J
AU Tang, H
   Chen, CB
   Pei, XB
AF Tang, He
   Chen, Chuanbo
   Pei, Xiaobing
TI Saliency detection from one time sampling for eye fixation prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency detection; Fixation prediction; Outlier detection; Sampling
ID VISUAL-ATTENTION; MOVEMENTS
AB Saliency modeling has become one of the most popular studies in computer vision. Many previous works adopted distinctness to compute saliency score of an image element, which usually need point-to-point distances calculation and it is quadratic complexity. In this paper, a visual saliency model based on one time sampling outlier detection is proposed, and the time complexity is linear to image size, further analyses and experiments demonstrate that our model is robust and efficient. This model is parameter insensitive, without learning, and easy to implement. Extensive experiments on four benchmark datasets show that our model is competitive compare with state-of-the-art models under shuffled AUC metric.
C1 [Tang, He; Chen, Chuanbo; Pei, Xiaobing] Huazhong Univ Sci & Technol, Sch Software Engn, Wuhan, Hubei, Peoples R China.
C3 Huazhong University of Science & Technology
RP Tang, H (corresponding author), Huazhong Univ Sci & Technol, Sch Software Engn, Wuhan, Hubei, Peoples R China.
EM hetang@hust.edu.cn
RI Tang, He/AAN-7118-2020
OI Tang, He/0000-0002-8454-1407
CR [Anonymous], 2008, BRIT MACHINE VISION
   [Anonymous], 2009, ADV NEURAL INFORM PR
   Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711
   Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5
   CARREIRA J, 2010, PROC CVPR IEEE, P3241, DOI DOI 10.1109/CVPR.2010.5540063
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   Frintrop S, 2015, PROC CVPR IEEE, P82, DOI 10.1109/CVPR.2015.7298603
   Garcia-Diaz A, 2012, IMAGE VISION COMPUT, V30, P51, DOI 10.1016/j.imavis.2011.11.007
   Guo CL, 2008, PROC CVPR IEEE, P2908
   Hadizadeh H, 2014, IEEE T IMAGE PROCESS, V23, P19, DOI 10.1109/TIP.2013.2282897
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hawkins D. M, 1980, IDENTIFICATION OUTLI, V11
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Huang LQ, 2007, PSYCHOL REV, V114, P599, DOI 10.1037/0033-295X.114.3.599
   Huang X, 2015, IEEE I CONF COMP VIS, P262, DOI 10.1109/ICCV.2015.38
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2009, Advances in neural information processing systems, V49, P1295, DOI [10.1016/j.visres.2008.09.007, DOI 10.1016/J.VISRES.2008.09.007]
   Jie Niu, 2016, MULTIMED TOOLS APPL, P1
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Klein DA, 2011, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2011.6126499
   Knorr EM, 2000, VLDB J, V8, P237, DOI 10.1007/s007780050006
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Kriegel HP, 2009, LECT NOTES ARTIF INT, V5476, P831, DOI 10.1007/978-3-642-01307-2_86
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liang M, 2015, IEEE T IMAGE PROCESS, V24, P1178, DOI 10.1109/TIP.2015.2395713
   Liu N, 2015, PROC CVPR IEEE, P362, DOI 10.1109/CVPR.2015.7298633
   Liu RS, 2014, PROC CVPR IEEE, P3866, DOI 10.1109/CVPR.2014.494
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Lu SJ, 2014, IEEE T PATTERN ANAL, V36, P195, DOI 10.1109/TPAMI.2013.158
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Riche N, 2013, SIGNAL PROCESS-IMAGE, V28, P642, DOI 10.1016/j.image.2013.03.009
   Rutishauser U., 2004, P IEEE COMP SOC C CO, DOI DOI 10.1109/CVPR.2004.1315142
   Schauerte B, 2012, LECT NOTES COMPUT SC, V7573, P116, DOI 10.1007/978-3-642-33709-3_9
   Sugiyama M., 2013, NIPS, V26, P467
   Sultani W, 2014, PROC CVPR IEEE, P764, DOI 10.1109/CVPR.2014.103
   Sun XS, 2012, PROC CVPR IEEE, P1552, DOI 10.1109/CVPR.2012.6247846
   Torralba A, 2006, PSYCHOL REV, V113, P766, DOI 10.1037/0033-295X.113.4.766
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Yang B, 2014, MULTIMED TOOLS APPL, V69, P877, DOI 10.1007/s11042-012-1148-3
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zhang G, 2010, LECT NOTES COMPUT SC, V5995, P193
   Zhang JM, 2013, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2013.26
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhu WH, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.4.043006
   Zhu ZF, 2014, IMAGE VISION COMPUT, V32, P180, DOI 10.1016/j.imavis.2013.12.015
NR 50
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 165
EP 184
DI 10.1007/s11042-016-4248-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400008
DA 2024-07-18
ER

PT J
AU Amato, A
   Jung, JJ
   Venticinque, S
AF Amato, Alba
   Jung, Jason J.
   Venticinque, Salvatore
TI Extending the internet of energy by a social networking of human users
   and autonomous agents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-agent systems; E-cars; Multi-criteria optimization
ID VEHICLES
AB The spread of IoT technologies fostered the integration of smart devices in cyber physical systems, where the interactions among devices and with human users become more and more complex and intense. Software agents are a programming paradigm that allows for providing intelligence to devices leveraging context awarness, reasoning techniques and communication mechanisms. In this paper we present the design and development of a social network of intelligent agents, which interact with the users and among them using common services and P2P overlay. The emergent behavior of users and agents, that is the optimal charging schedule of e-cars, is achieved recommending the cheapest charging station that does not affect the global distance to be covered for recharging. It optimizes the waiting time reducing the length of the queue at the charging station and global distance covered by all e-cars.
C1 [Amato, Alba] CNR, Inst High Performance Comp & Networking, Via Pietro Castellino, Naples, Italy.
   [Jung, Jason J.] Chung Ang Univ, Dept Comp Engn, 84 Heukseok, Seoul 156756, South Korea.
   [Venticinque, Salvatore] Univ Campania Luigi Vanvitelli, Dept Ind & Informat Engn, Via Roma 29, I-81031 Aversa, Italy.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Calcolo e Reti ad
   Alte Prestazioni (ICAR-CNR); Chung Ang University; Universita della
   Campania Vanvitelli
RP Venticinque, S (corresponding author), Univ Campania Luigi Vanvitelli, Dept Ind & Informat Engn, Via Roma 29, I-81031 Aversa, Italy.
EM alba.amator@icar.cnr.it; j2jung@gmail.com;
   salvatore.venticinque@unicampania.it
RI Jung, Jason J./B-9622-2012; Venticinque, Salvatore/E-4005-2015; Amato,
   Alba/E-4014-2015
OI Jung, Jason J./0000-0003-0050-7445; Venticinque,
   Salvatore/0000-0001-5042-3384; Amato, Alba/0000-0002-5196-8148
FU National Research Foundation of Korea (NRF) - Korea government (MSIP)
   [NRF-2017R1A2B4010774]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIP)
   (NRF-2017R1A2B4010774).
CR Alam KM, 2015, IEEE ACCESS, V3, P343, DOI 10.1109/ACCESS.2015.2416657
   Amato A., 2012, 2012 IEEE 10th International Symposium on Parallel and Distributed Processing with Applications (ISPA), P807, DOI 10.1109/ISPA.2012.118
   Amato Alba, 2012, Proceedings of the 2nd International Conference on Cloud Computing and Services Science (CLOSER 2012), P611
   Baum M, 2015, 23RD ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2015), DOI 10.1145/2820783.2820826
   Baumann C, 2012, 4 ACM WORKSH EMB SEN
   Bessel FW, 2010, ASTRON NACHR, V331, P852, DOI [10.1002/asna.201011352, DOI 10.1002/ASNA.201011352]
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Fazio M, 2015, PROCEDIA COMPUT SCI, V52, P500, DOI 10.1016/j.procs.2015.05.023
   Jaradat M, 2015, PROCEDIA COMPUT SCI, V56, P592, DOI 10.1016/j.procs.2015.07.250
   Maglaras LA, 2016, J SENS ACTUAT NETW, V5, DOI 10.3390/jsan5010003
   Mysore Divakar., 2013, Big Data Architecture and Patterns
   Pandey MK, 2016, SOCIAL NETWORKING BI, P149, DOI [10.1007/978-3-319-51969-2_13, DOI 10.1007/978-3-319-51969-2_13]
   Rathore MM, 2016, COMPUT NETW, V101, P63, DOI 10.1016/j.comnet.2015.12.023
   Saint-Andre P, 2009, XMPP DEFINITIVE GUID
   Stillwater T., 2013, HUMAN COMPUTER INTER, P640, DOI [10.1007/978-3-642-39262-7_72, DOI 10.1007/978-3-642-39262-7_72]
   Voutyras O, 2015, INT CONF INTELL NEXT, P244
NR 16
TC 1
Z9 1
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26057
EP 26076
DI 10.1007/s11042-017-4888-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500026
DA 2024-07-18
ER

PT J
AU Lee, J
AF Lee, Jooheung
TI Energy efficient processing of motion estimation for embedded multimedia
   systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Partial reconfiguration; Variable block size motion estimation;
   Reconfigurable computing; Visual sensor network
ID VLSI ARCHITECTURE; HEVC
AB Visual sensor networks require low power compression techniques of large amount of video data in each camera node due to the energy-constrained and bandwidth-limited environments. In this paper, energy-efficient architecture for Variable Block Size Motion Estimation is proposed to fully utilize dynamic partial reconfiguration capability of programmable hardware fabric in distributed embedded vision processing nodes. Partial reconfiguration of FPGA is exploited to support run-time reconfiguration of the proposed modular hardware architecture for motion estimation. According to the required search range, hardware reconfiguration is performed adaptively to reduce the hardware resources and power consumption. A reconfigurable ME ranging from simple 1-D to a complex 2-D Sum of Absolute Differences (SAD) array to perform full search block matching is selected in order to support different search window size. The implemented scalable SAD array can provide different resolutions and frame rates for real time applications with multiple reconfigurable regions.
C1 [Lee, Jooheung] Hongik Univ, Dept Elect & Elect Engn, Sejong, South Korea.
C3 Hongik University
RP Lee, J (corresponding author), Hongik Univ, Dept Elect & Elect Engn, Sejong, South Korea.
EM joolee@hongik.ac.kr
FU Hongik University Research Fund
FX This work was supported by 2016 Hongik University Research Fund.
   Additionally, the author would like to acknowledge Xilinx and the Xilinx
   University Program for its generous donation of S/W design tools and H/W
   boards.
CR Babionitakis K, 2008, J REAL-TIME IMAGE PR, V3, P3, DOI 10.1007/s11554-007-0070-9
   Chen CY, 2006, IEEE T CIRCUITS-I, V53, P578, DOI 10.1109/TCSI.2005.858488
   DEVOS L, 1989, IEEE T CIRCUITS SYST, V36, P1309, DOI 10.1109/31.44347
   Dias T, 2007, EURASIP J EMBED SYST, DOI 10.1155/2007/57234
   Goel S, 2005, P 48 MIDW S CIRC SYS, P7
   Gupta S. K., 2009, P INT C ENG REC SYST
   He G, 2015, IEEE T VLSI SYST, V23, P3138, DOI 10.1109/TVLSI.2014.2386897
   Huang YW, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P796
   Kim M, 2005, P AS S PAC DES AUT C, P18
   Liu ZY, 2006, IEICE T ELECTRON, VE89C, P1928, DOI 10.1093/ietele/e89-c.12.1928
   Radicke S, 2014, IEEE T CONSUM ELECTR, V60, P728, DOI 10.1109/TCE.2014.7027349
   Song Y, 2006, IEICE T FUND ELECTR, VE89A, P979, DOI 10.1093/ietfec/e89-a.4.979
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   YANG KM, 1989, IEEE T CIRCUITS SYST, V36, P1317, DOI 10.1109/31.44348
NR 14
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 24749
EP 24765
DI 10.1007/s11042-017-4645-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300010
DA 2024-07-18
ER

PT J
AU Zeng, H
   Wang, HJ
   Dong, JY
AF Zeng, Hui
   Wang, Huijuan
   Dong, Jiyuan
TI Robust 3D keypoint detection method based on double Gaussian weighted
   dissimilarity measure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shape index; Dissimilarity measure; Keypoint detection; 3D model;
   Multiscale
ID REPRESENTATION; RECOGNITION
AB This paper proposes a novel multiscale 3D keypoint detection method via the double Gaussian weighted dissimilarity measure. At each scale, the shape index value and the double Gaussian weighted dissimilarity measure value of each 3D point are firstly computed. Then the candidate keypoints with local maximum dissimilarity measure values are determined. Finally the final 3D keypoints are detected under our proposed multiscale detection scheme. As the dissimilarity measure used in this paper has better robust descriptive ability and is rotation and translation transformation invariant, the proposed detection method is robust to noise, rotation and translation transformation. Extensive experimental results have shown that using our proposed multiscale detection method, we can detect the keypoints with higher repeatability under different noise levels.
C1 [Zeng, Hui; Wang, Huijuan; Dong, Jiyuan] Univ Sci & Technol Beijing, Sch Automat & Elect Engn, 30 Xueyuan Rd, Beijing 100083, Peoples R China.
C3 University of Science & Technology Beijing
RP Zeng, H (corresponding author), Univ Sci & Technol Beijing, Sch Automat & Elect Engn, 30 Xueyuan Rd, Beijing 100083, Peoples R China.
EM hzeng@ustb.edu.cn
RI wang, hao/HSE-7975-2023; wang, huimin/HDM-8421-2022; WANG,
   HUIYUAN/IXX-2427-2023; wang, hui/GRS-4730-2022; wang, hui/HSG-6135-2023;
   Silva, Isac/AAQ-4462-2021; Wang, Hui/HMU-9512-2023
FU National Natural Science Foundation of China [61375010, 61005009]
FX This article is supported by the National Natural Science Foundation of
   China (Grant No. 61375010 and No. 61005009).
CR [Anonymous], EUR S GEOM PROC
   Campbell RJ, 2001, COMPUT VIS IMAGE UND, V81, P166, DOI 10.1006/cviu.2000.0889
   Castellani U, 2008, COMPUT GRAPH FORUM, V27, P643, DOI 10.1111/j.1467-8659.2008.01162.x
   Chen H, 2007, IEEE T PATTERN ANAL, V29, P718, DOI 10.1109/TPAMI.2007.1005
   Dong M, 2008, P IEEE INT C IM PROC
   Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1115, DOI 10.1109/34.625113
   Dutagaci H., 2011, Proceedings of the 4th Eurographics Conference on 3D Object Retrieval, 3DOR'11, P57
   Dutagaci H, 2012, VISUAL COMPUT, V28, P901, DOI 10.1007/s00371-012-0746-4
   Glomb P, 2009, ADV INTEL SOFT COMPU, V57, P103
   Ho H.T., 2008, Image and Vision Computing New Zealand, P1, DOI DOI 10.1016/J.INDMARMAN.2013.01.004
   Huang QX, 2006, ACM T GRAPHIC, V25, P569, DOI 10.1145/1141911.1141925
   Hui Zeng, 2013, 2013 Seventh International Conference on Image and Graphics (ICIG), P302, DOI 10.1109/ICIG.2013.66
   Huy Tho Ho, 2008, 2008 Digital Image Computing: Techniques and Applications, P16, DOI 10.1109/DICTA.2008.64
   KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mian A, 2010, INT J COMPUT VISION, V89, P348, DOI 10.1007/s11263-009-0296-z
   Mian AS, 2008, INT J COMPUT VISION, V79, P1, DOI 10.1007/s11263-007-0085-5
   Salti S., 2011, 2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission (3DIMPVT), P236, DOI 10.1109/3DIMPVT.2011.37
   Viksten F, 2008, INT C PATT RECOG, P3205
   Yu TH, 2013, INT J COMPUT VISION, V102, P180, DOI 10.1007/s11263-012-0563-2
NR 20
TC 4
Z9 5
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26377
EP 26389
DI 10.1007/s11042-016-4139-y
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500039
DA 2024-07-18
ER

PT J
AU Zhang, JM
   Shen, YX
AF Zhang, Jing Mao
   Shen, Yan Xia
TI Spectral segmentation via minimum barrier distance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spectral segmentation; Minimum barrier distance; Affinity model; Image
   segmentation
ID IMAGE SEGMENTATION; SUPERPIXELS; CUTS
AB Constructing a reliable affinity matrix is crucial for spectral segmentation. In this paper, we define a technique to create a reliable affinity matrix for the application to spectral segmentation. We propose an affinity model based on the minimum barrier distance (MBD). First, the image is over-segmented into superpixels; then the subset of the pixels, located in the center of these superpixels, is used to compute the MBD-based affinities of the original image, with particular care taken to avoid a strong boundary, as described in the classical model. To deal with images with faint object and random or "clutter" background, we present gradient data that are integrated with the MBD data. To capture different perceptual grouping cues, the completed affinity model includes MBD, color, and spatial cues of the image. Finally, spectral segmentation is implemented at the superpixel level to provide an image segmentation result with pixel granularity. Experiments using the Berkeley image segmentation database validate the effectiveness of the proposed method. Covering, PRI, VOI, and the F-measure are used to evaluate the results relative to several state-of-the-art algorithms.
C1 [Zhang, Jing Mao; Shen, Yan Xia] Jiangnan Univ, Engn Res Ctr IoT Technol & Applicat, Minist Educ, Wuxi 214122, Peoples R China.
C3 Jiangnan University
RP Shen, YX (corresponding author), Jiangnan Univ, Engn Res Ctr IoT Technol & Applicat, Minist Educ, Wuxi 214122, Peoples R China.
EM shenyx@jiangnan.edu.cn
FU National Nature Science Foundation [61573167, 61572237]; Fundamental
   Research Funds for the Central Universities [JUSRP31106, JUSRP51510]
FX The work was supported by National Nature Science Foundation (Grant No.
   61573167, 61572237). the Fundamental Research Funds for the Central
   Universities (Grant No. JUSRP31106, JUSRP51510).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2006, Conference on Computer Vision Pattern Recognition Workshop, DOI [DOI 10.1109/CVPRW.2006.48, 10.1109/CVPRW.2006.48]
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Aytekin C, 2017, MULTIMED TOOLS APPL, V76, P10443, DOI 10.1007/s11042-016-3431-1
   Aytekin Ç, 2014, INT C PATT RECOG, P112, DOI 10.1109/ICPR.2014.29
   Belongie S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P675, DOI 10.1109/ICCV.1998.710790
   Chen L, 2014, INT J FUZZY SYST, V16, P46
   Chung CH, 2010, PATTERN RECOGN, V43, P3219, DOI 10.1016/j.patcog.2010.04.022
   Ciesielski KC, 2014, COMPUT VIS IMAGE UND, V123, P53, DOI 10.1016/j.cviu.2014.03.007
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cour T, 2005, PROC CVPR IEEE, P1124
   Dollár P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715
   Dougherty, 2003, HANDS MORPHOLOGICAL
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Karadag OO, 2014, PATTERN RECOGN LETT, V46, P75, DOI 10.1016/j.patrec.2014.05.010
   Kim S, 2014, IEEE T PATTERN ANAL, V36, P1761, DOI 10.1109/TPAMI.2014.2303095
   Kim TH, 2013, IEEE T PATTERN ANAL, V35, P1690, DOI 10.1109/TPAMI.2012.237
   Kumar MP, 2010, PROC CVPR IEEE, P3217, DOI 10.1109/CVPR.2010.5540072
   Lee YJ, 2010, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2010.5540237
   Li ZG, 2012, PROC CVPR IEEE, P789, DOI [10.1109/CVPR.2012.6247750, 10.1109/ISRA.2012.6219309]
   Liu Q, 2013, MULTIMED TOOLS APPL, V67, P231, DOI 10.1007/s11042-012-1077-1
   Lu HC, 2013, IEEE T CYBERNETICS, V43, P2170, DOI 10.1109/TCYB.2013.2243432
   Meila M., 2005, P 22 INT C MACHINE L, P577
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Ponttuset J, 2015, IEEE T PATTERN ANAL, P1
   Price BL, 2010, PROC CVPR IEEE, P3161, DOI 10.1109/CVPR.2010.5540079
   RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239
   Rohkohl C, 2007, LECT NOTES COMPUT SC, V4713, P254
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Strand R, 2013, COMPUT VIS IMAGE UND, V117, P429, DOI 10.1016/j.cviu.2012.10.011
   Sumengen B., 2006, P CVPRW, P179
   Tang C, 2016, MULTIMED TOOLS APPL, V75, P6963, DOI 10.1007/s11042-015-2622-5
   Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046
   Wang XF, 2015, IEEE T IMAGE PROCESS, V24, P1399, DOI 10.1109/TIP.2015.2397313
   Yang KY, 2011, IEEE T MULTIMEDIA, V13, P662, DOI 10.1109/TMM.2011.2147777
   Yu ZD, 2012, PROC CVPR IEEE, P781, DOI 10.1109/CVPR.2012.6247749
   Zhou DY, 2004, ADV NEUR IN, V16, P321
NR 37
TC 3
Z9 3
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 25713
EP 25729
DI 10.1007/s11042-017-4473-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500011
DA 2024-07-18
ER

PT J
AU Balakrishnan, SM
   Sangaiah, AK
AF Balakrishnan, Senthil Murugan
   Sangaiah, Arun Kumar
TI Integrated QoUE and QoS approach for optimal service composition
   selection in internet of services (IoS)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE QoS (quality of service); QoUE (quality of user experience); Composite
   web service; DAG (directed acyclic graph); PSO (particle swarm
   optimization); Fuzzy approach
ID PARTICLE SWARM; ALGORITHM
AB Service Oriented Architecture (SOA) approaches are presently getting to be appropriate to embedded devices that feature embedded processing and communication. As a result these services get the ability to be hosted on high end machines to wireless resource constrained devices and on any physical object supported with communication ability. This creates the Internet of Services (IoS) environment. Services from multiple owners can be assembled into a composite service irrespective of their specific Quality of Service (QoS) and related properties for implementing a complex business process. In this context service consumer comes against the problem of selecting best service and for which providing QoS relevant guarantees leads to many challenging issues. One among them is determining a feasible service composition that fulfils a set of conditions while maintaining a good Quality of User Experience (QoUE). The last goal suggests the requirement to enforce an extra optimality prerequisite on the feasibility problem. In this paper, an optimization strategy oriented to efficient composite service selection for IoS model is designed through use of Particle Swarm Optimization (PSO) technique. Furthermore, prior to optimization, the services are assured of rich QoUE, especially trustworthiness in terms of reputation. The proposed work evaluates QoUE using the fuzzy based inference algorithm for identifying QoUE satisfied composite service. Experimental evaluation on a set of real world web services demonstrates the effectiveness of our proposed methodology.
C1 [Balakrishnan, Senthil Murugan] VIT Univ, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
   [Sangaiah, Arun Kumar] VIT Univ, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Vellore Institute of
   Technology (VIT); VIT Vellore
RP Sangaiah, AK (corresponding author), VIT Univ, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
EM senthilmurugan.b@vit.ac.in; arunkumarsangaiah@gmail.com
RI Sangaiah, Arun Kumar/U-6785-2019; BALAKRISHNAN, SENTHIL
   MURUGAN/U-6399-2019
OI Sangaiah, Arun Kumar/0000-0002-0229-2460; Balakrishnan, Senthil
   Murugan/0000-0003-4070-1074
CR A-Masri E, 2007, IEEE IC COMP COM NET, P529
   AHMED AN, 2014, INT J SOFTWARE ENG I, V8, P169
   Al-Masri E., 2007, P 16 INT C WORLD WID, P1257, DOI DOI 10.1145/1242572.1242795
   Alreshoodi M., 2013, International Journal of Distributed and Parallel Systems, V4, P53
   [Anonymous], INFORM SOC MEDIA J
   [Anonymous], 2003, SIGECOM EXCH
   [Anonymous], 2008, P 17 INT C WORLD WID, DOI DOI 10.1145/1367497.1367605
   Benouaret K., 2012, Proceedings of the 2012 IEEE 19th International Conference on Web Services (ICWS), P635, DOI 10.1109/ICWS.2012.108
   Calyam P, 2012, INT J DIGIT MULTIMED, V2012, DOI 10.1155/2012/904072
   Canfora G, 2004, 10TH INTERNATIONAL SYMPOSIUM ON SOFTWARE METRICS, PROCEEDINGS, P36, DOI 10.1109/METRIC.2004.1357889
   Canfora G, 2005, GECCO 2005: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOLS 1 AND 2, P1069
   Caporuscio M, 2015, J SYST SOFTWARE, V106, P9, DOI 10.1016/j.jss.2015.03.102
   Chen SZ, 2014, IEEE INTERNET THINGS, V1, P349, DOI 10.1109/JIOT.2014.2337336
   CLARO DB, 2005, P INT WORKSH SEM DYN
   Clerc M, 2002, IEEE T EVOLUT COMPUT, V6, P58, DOI 10.1109/4235.985692
   Comerio M, 2010, INT J WEB SERV RES, V4, P33
   D'Mello D. A., 2009, INT J SIMULATION SYS, V10, P25
   de Weck O., 2005, 46 AIAA ASME ASCE AH, P1, DOI DOI 10.2514/6.2005-1897
   Feng XZ, 2007, ICCTA 2007: INTERNATIONAL CONFERENCE ON COMPUTING: THEORY AND APPLICATIONS, PROCEEDINGS, P208
   Gallard J, 2012, FUTURE GENER COMP SY, V28, P136, DOI 10.1016/j.future.2011.06.003
   Georgios T, 2010, FUTURE INTERNET EMER
   Huang AFM, 2009, INFORM SCIENCES, V179, P3309, DOI 10.1016/j.ins.2009.05.018
   Issarny V, 2011, J INTERNET SERV APPL, V2, P23, DOI 10.1007/s13174-011-0021-3
   Ji-Moon C, 2015, INDIAN J SCI TECHNOL, V8, P1
   Li Z, 2007, LECT NOTES ARTIF INT, V4496, P199
   Liu M, 2010, INT J NONLIN SCI NUM, V11, P13
   Mardukhi F, 2013, APPL SOFT COMPUT, V13, P3409, DOI 10.1016/j.asoc.2012.12.033
   Mecella M, 2002, LECT NOTES COMPUT SC, V2519, P486
   Papadopoulou E, 2013, L N INST COMP SCI SO, V109, P10
   Papazoglou MP, 2007, COMPUTER, V40, P38, DOI 10.1109/MC.2007.400
   Pernici Barbara, 2011, Advanced Information Systems Engineering. Proceedings 23rd International Conference, CAiSE 2011, P48, DOI 10.1007/978-3-642-21640-4_6
   Schantz R.E., 2002, MIDDLEWARE DISTRIBUT
   Shangguang Wang, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P666, DOI 10.1109/INFCOMW.2011.5928896
   Shao LS, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES, PROCEEDINGS, P439
   Shenghui Zhao, 2011, Journal of Networks, V6, P950, DOI 10.4304/jnw.6.7.950-957
   Shi YH, 1998, IEEE C EVOL COMPUTAT, P69, DOI 10.1109/ICEC.1998.699146
   Singh RP, 2013, PROCEDIA COMPUT SCI, V19, P470, DOI 10.1016/j.procs.2013.06.063
   Stelmach P, 2013, IFIP ADV INF COMM TE, V394, P53
   Tang M., 2010, Evolutionary Computation (CEC), 2010 IEEE Congress on, P1
   Teixeira T, 2011, LECT NOTES COMPUT SC, V6994, P220, DOI 10.1007/978-3-642-24755-2_21
   Terzidis O., 2012, Handbook of service description, P1
   Tongguang Zhang, 2014, Journal of Networks, V9, P565, DOI 10.4304/jnw.9.3.565-570
   Tran VX, 2009, SIMUL MODEL PRACT TH, V17, P1378, DOI 10.1016/j.simpat.2009.06.010
   Wang P, 2010, EXPERT SYST APPL, V37, P440, DOI 10.1016/j.eswa.2009.05.070
   Wang WB, 2010, INT J COMPUT INT SYS, V3, P18
   Wang ZJ, 2011, INT J ADV MANUF TECH, V56, P1167, DOI 10.1007/s00170-011-3230-9
   Wu B, 2007, P 2007 IEEE C SERV S, P270
   WU Q, 2013, MATH PROBL ENG, V2013, P1
   Yu HQ, 2008, IEEE CONGRESS ON SERVICES 2008, PT I, PROCEEDINGS, P513, DOI 10.1109/SERVICES-1.2008.8
   Yu Q, 2012, WORLD WIDE WEB, V15, P1, DOI 10.1007/s11280-011-0121-9
   Yu T., 2005, Information Systems and Ebusiness Management, V3, P103, DOI DOI 10.1007/S10257-005-0052-Z
   Zeng L., 2003, Proceedings of the 12th International Conference on World Wide Web, P411, DOI [DOI 10.1145/775152.775211, 10.1145/775152.775211]
   Zeng LZ, 2004, IEEE T SOFTWARE ENG, V30, P311, DOI 10.1109/TSE.2004.11
   Zheng ZB, 2014, IEEE T SERV COMPUT, V7, P32, DOI 10.1109/TSC.2012.34
   Zheng ZB, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES, VOLS 1 AND 2, P437, DOI 10.1109/ICWS.2009.30
NR 55
TC 7
Z9 7
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22889
EP 22916
DI 10.1007/s11042-016-3837-9
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200051
DA 2024-07-18
ER

PT J
AU Chandran, SN
   Gangodkar, D
   Mittal, A
AF Chandran, S. Nisha
   Gangodkar, Durgaprasad
   Mittal, Ankush
TI A semi-supervised probabilistic model for clustering large databases of
   complex images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image clustering; Kullback-Leibler distance; Gaussian mixture modeling
AB Image content clustering is an effective way to organize large databases thereby making the content based image retrieval process much easier. However, clustering of images with varied background and foreground is quite challenging. In this paper, we propose a novel image content clustering paradigm suitable for clustering large and diverse image databases. In our approach images are represented in a continuous domain based on a probabilistic Gaussian Mixture Model (GMM) with the images modeled as mixture of Gaussian distributions in the selected feature space. The distance metric between the Gaussian distributions is defined in the sense of Kullback-Leibler (KL) divergence. The clustering is done using a semi-supervised learning framework where labeled data in the form of cluster templates is used to classify the unlabelled data. The clusters are formed around initially chosen seeds and are updated in the due course based on user inputs. In our clustering approach the user interaction is done in a structured way as to get maximum inputs from the user in a limited time. We propose two methods to carry out the structured user interaction using which the cluster templates are updated to improve the quality of the clusters formed. The proposed method is experimentally evaluated on benchmark datasets that are specifically chosen to include a wide variation of images around a common theme that is typically encountered in applications like photo-summarization and poses a major semantic gap challenge to conventional clustering approaches. The experimental results presented demonstrate the effectiveness of the proposed approach.
C1 [Chandran, S. Nisha; Gangodkar, Durgaprasad; Mittal, Ankush] Graph Era Univ, Dept CSE, Bell Rd, Dehra Dun 248001, Uttar Pradesh, India.
C3 Graphic Era University
RP Chandran, SN (corresponding author), Graph Era Univ, Dept CSE, Bell Rd, Dehra Dun 248001, Uttar Pradesh, India.
EM nisha.unnikrishnan@gmail.com; dgangodkar@yahoo.com;
   dr.ankush.mittal@gmail.com
RI Chandran, Nisha/AAY-4967-2021
OI Chandran, Nisha/0000-0002-0558-5496
CR [Anonymous], 2007, FACE DATABASE
   [Anonymous], 2005, CLUSTERING METHODS D, DOI [DOI 10.1007/0-387-25465-X, DOI 10.1007/0-387-25465-X.15]
   [Anonymous], 1999, ARTIFICIAL NEURAL NE
   [Anonymous], 2001, P 18 INT C MACH LEAR
   [Anonymous], 2002, ICML
   [Anonymous], 2017, WANG IMAGE DATABASES
   [Anonymous], 2003, P ICML2003 WORKSHOP
   [Anonymous], 2007, 2007 IEEE Conference on Computer Vision and Pattern Recognition, DOI DOI 10.1109/CVPR.2007.383282
   Bade K, 2006, 2006 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, (WI 2006 MAIN CONFERENCE PROCEEDINGS), P181, DOI 10.1109/WI.2006.131
   Bair E, 2004, PLOS BIOL, V2, P511, DOI 10.1371/journal.pbio.0020108
   Bair E, 2013, WIRES COMPUT STAT, V5, P349, DOI 10.1002/wics.1270
   Basu S., 2004, Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, P59
   Bhatt CA, 2011, MULTIMED TOOLS APPL, V51, P35, DOI 10.1007/s11042-010-0645-5
   Chen Yixin, 2003, P 5 ACM SIGMM INT WO, P193
   Chuang J, 2013, HUMAN CTR INTERACTIV
   Eick CF, 2004, PROC INT C TOOLS ART, P774
   Gao K, 2012, PROC CVPR IEEE, P3234, DOI 10.1109/CVPR.2012.6248059
   Goldberger J., 2002, Pattern Recognition. 24th DAGM Symposium. Proceedings (Lecture Notes in Computr Science Vol.2449), P158
   Goldberger J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P487
   Greenspan H, 2001, COMPUT VIS IMAGE UND, V84, P384, DOI 10.1006/cviu.2001.0946
   Hamasuna Y, 2010, LECT NOTES ARTIF INT, V6408, P152, DOI 10.1007/978-3-642-16292-3_16
   Hu W, 2015, MULTIMED TOOLS APPL, V74, P8495, DOI 10.1007/s11042-013-1611-9
   Jain A. K., 1988, Algorithms for Clustering Data, P446
   Kestler HA, 2006, LECT NOTES ARTIF INT, V4087, P57
   Lande M.V., 2014, INTELLIGENT COMPUTIN, V243, P1163, DOI [10.1007/978-81-322-1665-0_119, DOI 10.1007/978-81-322-1665-0_119]
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Miyamoto S, 2010, P IEEE INT C FUZZ SY, P1, DOI DOI 10.1109/FUZZY.2010.5584625
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085
   Silvén I, 2003, MACH VISION APPL, V13, P275, DOI 10.1007/s00138-002-0084-z
   Wang M, 2012, PATTERN RECOGN LETT, V33, P462, DOI 10.1016/j.patrec.2011.02.012
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Zeng S, 2014, NEUROCOMPUTING, V144, P346, DOI 10.1016/j.neucom.2014.04.037
   Zhang HW, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2978656
   Zhao HF, 2010, THIRD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING: WKDD 2010, PROCEEDINGS, P195, DOI 10.1109/WKDD.2010.123
   Zhao Y., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P515, DOI 10.1145/584792.584877
NR 36
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 21937
EP 21959
DI 10.1007/s11042-017-4664-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200006
DA 2024-07-18
ER

PT J
AU Mustapha, A
   Oulefki, A
   Bengherabi, M
   Boutellaa, E
   Algaet, MA
AF Mustapha, Aouache
   Oulefki, Adel
   Bengherabi, Messaoud
   Boutellaa, Elhocine
   Algaet, Mustafa Almahdi
TI Towards nonuniform illumination face enhancement via adaptive contrast
   stretching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face image; Contrast-stretching; DL descriptor; VTM; ROC; Quality
   measurement
ID HISTOGRAM EQUALIZATION; RECOGNITION; ALGORITHMS; TRANSFORM; RETINEX;
   MODELS
AB A face enhancement has the potential to play an important part in providing satisfactory and vast information to the face recognition performance. Therefore, a new approach for nonuniform illumination face enhancements (NIFE) was proposed by designing an adaptive contrast-stretching (ACS) filter. In a more objective manner of achieving this, an investigation usage of CS function with adjustable factors value to summarise its influence on the NIFE is examined firstly. Secondly, describe a new strategy to cater for CS adaptive factors prediction using training and testing phases. A dispersion versus location (DL) descriptor was examined in the training phase to generate the faces feature vectors. Subsequently, a frame differencing module (FDM) was developed for faces label generations. In the testing phase, the approach was examined to recognise the DL descriptor and predict face label based vocabulary tree model (VTM). Thirdly, the VTM performance was examined by referring to the area under curve (AUC) score from the receiver operating characteristic (ROC). The face quality measurement was evaluated via blind reference based statistical measures (BR-SM), blind reference based DL-descriptors (BR-DL) and visual interpretation of the resulting images. The BR-SM performed through calculating the EME (Measure of Enhancement), EEME (Measure of Enhancement by Entropy), SDME (Second Derivative like Measure of Enhancement), SHP (Coefficient of Sharpness) and CPP (Contrast per Pixel). In addition, by using DL scatter, the BR-DL handles the specific relationship with regards to the local contrast to local brightness within the resulting face images. Four face image databases, namely Extended Yale B, Mobio, Feret and CMU-PIE were used. The final results attained prove that compared to the state-of-the-art methods, the proposed ACS filter implementation is the most excellent choice in terms of contrast and nonuniform illumination adjustment as well as providing images of satisfactory quality. In short, the benefits attained proves that ACS is driven with a profitable enhancement rate in providing tremendous detail concerning face recognition systems.
C1 [Mustapha, Aouache; Oulefki, Adel; Bengherabi, Messaoud; Boutellaa, Elhocine] CDTA, Div Telecom, Algiers 16303, Algeria.
   [Algaet, Mustafa Almahdi] Univ Tekn Malaysia Melaka, Fac Informat & Commun, Dept Comp Syst & Commun, Durian Tunggal 76100, Melaka, Malaysia.
C3 Centre for the Development of Advanced Technologies (CDTA); University
   Teknikal Malaysia Melaka
RP Mustapha, A (corresponding author), CDTA, Div Telecom, Algiers 16303, Algeria.
EM maouache@cdta.dz; aoulefki@cdta.dz; mbengherabi@cdta.dz;
   eboutellaa@cdta.dz; malgaet@gmail.com
RI oulefki, adel/M-5513-2019; Mustapha, AOUACHE/AFK-0820-2022; Oulefki,
   Adel/AAE-9017-2022; bengherabi, messaoud/AAZ-2734-2020; Mustapha,
   AOUACHE/AAF-7777-2022
OI oulefki, adel/0000-0003-2930-9215; Mustapha,
   AOUACHE/0000-0003-1629-1183; Boutellaa, Elhocine/0000-0003-4140-6130;
   bengherabi, messaoud/0000-0001-8679-2093
FU Ministry of Higher Education and Scientific Research (MHESR); Centre de
   Developpement des Technologies Avancees (CDTA)-Algeria, under the
   Science Fund Project (FNR)
FX This research received funding from Ministry of Higher Education and
   Scientific Research (MHESR) and Centre de Developpement des Technologies
   Avancees (CDTA)-Algeria, under the Science Fund Project (FNR-2013-2016).
CR Agaian Sos, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2779, DOI 10.1109/ICASSP.2014.6854106
   Agaian S.S., 2000, IASTED INT C SIGNAL, P19
   Agaian SS, 2001, IEEE T IMAGE PROCESS, V10, P367, DOI 10.1109/83.908502
   Agaiani S, 2014, IEEE CONF IMAGING SY, P73, DOI 10.1109/IST.2014.6958449
   [Anonymous], 2012, P IEEE INT C MULT EX
   [Anonymous], 2014, INTRO SECTS SOCIAL D
   [Anonymous], 2010 2 INT C IM PROC
   [Anonymous], 2001, P IEEE C COMP VIS PA
   [Anonymous], 2000, Fuzzy image enhancement: an overview, fuzzy techniques in image processing
   Arriaga-Garcia EF, 2014, INT CONF ELECTR COMM, P28, DOI 10.1109/CONIELECOMP.2014.6808563
   Brown CD, 2006, CHEMOMETR INTELL LAB, V80, P24, DOI 10.1016/j.chemolab.2005.05.004
   Chang SJ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0127855
   Chen WL, 2006, IEEE T SYST MAN CY B, V36, P458, DOI 10.1109/TSMCB.2005.857353
   Choi YJ, 2016, BIOMED RES INT, V2016, DOI 10.1155/2016/3286191
   Eramian M, 2005, 2nd Canadian Conference on Computer and Robot Vision, Proceedings, P397, DOI 10.1109/CRV.2005.47
   Faraji MR, 2015, IET COMPUT VIS, V9, P390, DOI 10.1049/iet-cvi.2014.0200
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Gross R, 2003, LECT NOTES COMPUT SC, V2688, P10
   Hasikin K, 2012, UKSIM 14 INT C, P371
   Heusch G, 2005, TECH REP
   Hu HF, 2015, IET COMPUT VIS, V9, P163, DOI 10.1049/iet-cvi.2013.0342
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Kryszczuk K, 2006, SIGN PROC C 2006 14, P1
   La Cascia M, 2000, IEEE T PATTERN ANAL, V22, P322, DOI 10.1109/34.845375
   Lai ZR, 2015, IEEE T IMAGE PROCESS, V24, P1735, DOI 10.1109/TIP.2015.2409988
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Liang HY, 2016, IEEE T IMAGE PROCESS, V25, P5118, DOI 10.1109/TIP.2016.2601783
   Nikan S, 2015, IET IMAGE PROCESS, V9, P12, DOI 10.1049/iet-ipr.2013.0792
   Nister David, 2006, CVPR
   OPPENHEI.AV, 1968, IEEE T ACOUST SPEECH, VAU16, P437, DOI 10.1109/TAU.1968.1161990
   Park YK, 2008, SIGNAL PROCESS, V88, P1929, DOI 10.1016/j.sigpro.2008.01.028
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Poddar S, 2013, IET IMAGE PROCESS, V7, P641, DOI 10.1049/iet-ipr.2012.0507
   Restrepo A, 2008, SIGN PROC C 2008 16, P1
   Roopaei M, 2014, IEEE SYS MAN CYBERN, P158, DOI 10.1109/SMC.2014.6973900
   Sheet D, 2010, IEEE T CONSUM ELECTR, V56, P2475, DOI 10.1109/TCE.2010.5681130
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130
   Sovierzoski MA, 2008, INT CONF BIOMED, P274, DOI 10.1109/BMEI.2008.251
   Struc V, 2009, LECT NOTES COMPUT SC, V5707, P1, DOI 10.1007/978-3-642-04391-8_1
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Thamizharasi A, 2016, ICTACT J IMAGE VIDEO, V6
   Tilbury JB, 2000, IEEE T BIO-MED ENG, V47, P952, DOI 10.1109/10.846690
   Venkateshwarlu K., 2010, THESIS
   Yongkang Wong, 2011, 2011 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops 2011), P74, DOI 10.1109/CVPRW.2011.5981881
   Zuiderveld K., 1994, CONTRAST LTD ADAPTIV, P474
NR 47
TC 12
Z9 13
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 21961
EP 21999
DI 10.1007/s11042-017-4665-2
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200007
DA 2024-07-18
ER

PT J
AU Nedjah, N
   SoaresWyant, R
   Mourelle, LD
AF Nedjah, Nadia
   SoaresWyant, Rafael
   Mourelle, Luiza de Macedo
TI Efficient biometric palm-print matching on smart-cards for high security
   and privacy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Palm-print; Palm-code; Smart-card; Health-care; Security;
   Privacy
ID PALMPRINT IDENTIFICATION; PERSONAL IDENTIFICATION; RECOGNITION
AB Smart control access to any service is at the very basis of any smart city project. Biometrics have been used as a solution for system access control, for many years now. However, the simple use of biometrics can not be considered as final and perfect solution. Most problems are related to the data transmission way between the medias, where the users require access and the servers where the biometric data, captured upon registration, are stored. In this paper, the use smart-cards is adopted as a possible effective yet efficient solution to this problem. Palm-prints have been used as a human identifier for a long time now. This biometric is considered one of the most reliable to distinguish a person from another as its unique yet stable over time. In this work, we propose an efficient implementation of palm-print verification on smart-cards. For this implementation, the matching is done on-card. Thus, the biometric characteristics are always kept in the owner's card, guaranteeing the maximum security and privacy. In a first approach, the False Acceptance Rate (FAR) and False Rejection Rate (FRR) are improved using upward, downward, leftward and rightward translations of the matched palm-codes. However, after thorough analysis of the achieved results, we show that the proposed method introduces a significant increase in terms of execution time of the matching operation. In order to mitigate this impact, we augmented the proposed technique with an acceptance threshold verification, thus decreasing drastically the execution time of the matching operation, and yet achieving considerably low FAR and FRR. It is noteworthy to point out that these characteristics are at the basis of any access control successful usage.
C1 [Nedjah, Nadia; SoaresWyant, Rafael] Univ Estado Rio De Janeiro, Dept Elect Engn & Telecommun, Fac Engn, Rio De Janeiro, Brazil.
   [Mourelle, Luiza de Macedo] Univ Estado Rio De Janeiro, Dept Syst Engn & Computat, Fac Engn, Rio De Janeiro, Brazil.
C3 Universidade do Estado do Rio de Janeiro; Universidade Federal de Juiz
   de Fora; Universidade do Estado do Rio de Janeiro; Universidade Federal
   de Juiz de Fora
RP Nedjah, N (corresponding author), Univ Estado Rio De Janeiro, Dept Elect Engn & Telecommun, Fac Engn, Rio De Janeiro, Brazil.
EM nadia@eng.uerj.br; wyant@eng.uerj.br; ldmm@eng.uerj.br
RI de Macedo Mourelle, Luiza/AAG-8935-2019; Nedjah, Nadia/AAE-7320-2019; de
   Macedo Mourelle, Luiza/GVS-4735-2022
OI de Macedo Mourelle, Luiza/0000-0002-4680-2047; de Macedo Mourelle,
   Luiza/0000-0002-4680-2047; Nedjah, Nadia/0000-0002-1656-6397
CR Alsmirat MA, 2016, J REAL TIME IMAGE PR
   [Anonymous], MULTIMEDIA TOOLS APP
   Ashbaugh D.R., 1999, CRC SER PR CRIM, DOI 10.1201/9781420048810
   Atawneh S, 2016, MULTIMEDIA TOOLS APP
   DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Emerich S, 2016, STUD COMPUT INTELL, V630, P281, DOI 10.1007/978-3-319-28854-3_11
   Gabor D., 1946, Journal of the Institution of Electrical Engineers-part III: radio and communication engineering, V93, P429, DOI [DOI 10.1049/JI-3-2.1946.0074, 10.1049/ji-3-2.1946.0074]
   Hachez G, 2000, INT FED INFO PROC, V52, P273
   Han CC, 2003, PATTERN RECOGN, V36, P371, DOI 10.1016/S0031-3203(02)00037-7
   Han YF, 2007, LECT NOTES COMPUT SC, V4642, P1164
   Healthcare Council, 2012, SMART CARDS BIOM HEA
   Hu DW, 2007, PATTERN RECOGN, V40, P339, DOI 10.1016/j.patcog.2006.06.022
   HUBEL DH, 1977, PROC R SOC SER B-BIO, V198, P1, DOI 10.1098/rspb.1977.0085
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jain AK, 2007, IEEE T PATTERN ANAL, V29, P15, DOI 10.1109/TPAMI.2007.250596
   Jain AK, 2009, IEEE T PATTERN ANAL, V31, P1032, DOI 10.1109/TPAMI.2008.242
   Jing XY, 2005, PATTERN RECOGN, V38, P453, DOI 10.1016/j.patcog.2003.09.020
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Kong A, 2006, PATTERN RECOGN, V39, P478, DOI 10.1016/j.patcog.2005.08.014
   Kong AWK, 2004, INT C PATT RECOG, P520, DOI 10.1109/ICPR.2004.1334184
   Kumar A, 2005, PATTERN RECOGN, V38, P1695, DOI 10.1016/j.patcog.2005.03.012
   Kumar A, 2006, IEEE T IMAGE PROCESS, V15, P2454, DOI 10.1109/TIP.2006.875214
   Li W, 2012, IEEE T SYST MAN CY C, V42, P1491, DOI 10.1109/TSMCC.2012.2195653
   Li WX, 2002, INT J PATTERN RECOGN, V16, P417, DOI 10.1142/S0218001402001757
   Li YL, 2005, LECT NOTES COMPUT SC, V3497, P177
   Lu GM, 2003, PATTERN RECOGN LETT, V24, P1463, DOI 10.1016/S0167-8655(02)00386-0
   PolyU, 2013, POLYU 3D PALMPR DAT
   Poon C, 2004, LECT NOTES COMPUT SC, V3072, P782
   Pudzs M, 2013, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE OF THE BIOMETRICS SPECIAL INTEREST GROUP (BIOSIG 2013)
   Shu W, 1998, OPT ENG, V37, P2359, DOI 10.1117/1.601756
   Sun ZN, 2005, PROC CVPR IEEE, P279
   Wang XJ, 2006, INT C PATT RECOG, P503
   Wu XQ, 2006, PATTERN ANAL APPL, V9, P103, DOI 10.1007/s10044-005-0006-6
   Wu XQ, 2006, IEEE T SYST MAN CY A, V36, P978, DOI 10.1109/TSMCA.2006.871797
   Wu XQ, 2003, PATTERN RECOGN LETT, V24, P2829, DOI 10.1016/S0167-8655(03)00141-7
   Wu XQ, 2002, INT C PATT RECOG, P95, DOI 10.1109/ICPR.2002.1044621
   Wyant RS, 2014, LECT NOTES COMPUT SC, V8584, P236, DOI 10.1007/978-3-319-09153-2_18
   Yang J, 2007, IEEE T PATTERN ANAL, V29, P650, DOI 10.1109/TPAMI.2007.1008
   You J, 2004, IEEE T CIRC SYST VID, V14, P234, DOI 10.1109/TCSVT.2003.821978
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang D, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2071389.2071391
   Zhang D, 2009, IEEE T SYST MAN CY C, V39, P505, DOI 10.1109/TSMCC.2009.2020790
   Zuo W., 2005, Proceeding of IEEE International Conference on Image Processing, V2, P958, DOI DOI 10.1109/ICIP.2005.1530216
NR 45
TC 4
Z9 4
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22671
EP 22701
DI 10.1007/s11042-016-4271-8
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200040
DA 2024-07-18
ER

PT J
AU Semwal, VB
   Singha, J
   Sharma, PK
   Chauhan, A
   Behera, B
AF Semwal, Vijay Bhaskar
   Singha, Joyeeta
   Sharma, Pinki Kumari
   Chauhan, Arun
   Behera, Basudeba
TI An optimized feature selection technique based on incremental feature
   analysis for bio-metric gait data classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gait; Biometric identification; Feature selection; Bipedal locomotion;
   Incremental feature selection (IFA)
ID RECOGNITION; PATTERN
AB The classification of humanoid locomotion is a troublesome exercise because of non-linearity associate with gait signals. The classification using the different machine learning technique leads for over fitting and under fitting. To select the optimized feature is a difficult task. The high dimension feature vector requires a high computational cost. The hand craft feature selection machine learning techniques performed poor. We have used the incremental feature selection strategy for feature selection. In this paper we first selected the feature and identify the principle feature then we classify gait data using different machine learning technique (KNN, ANN, SVM, DNN and classifier fusion) and shown the performance comparison. Experimental result on real time datasets propose method is better than previous method as far as humanoid locomotion classification is concerned and the generalization accuracy provided by new feature selection method i.e. incremental feature selection (IFS) with analysis of variance (ANOVA) (Zhang et al., 20). During the feature extraction, 17 features were selected from the existing literatures (Wang et al. in IEEE Trans Circ Syst Video Technol 14(2):149-158, 15). Using all the features could lead to over fitting, information redundancy and dimension disaster. Thus, a system with optimal features was selected using ANOVA combined with IFA. These selected features were then fed as an input to the ANN, SVM, KNN and DNN model. These individual classifiers were combined to produce classifier fusion model. The 5-fold cross-validation was used to evaluate the performance of the proposed model. Based on the empirical results it may be concluded that classifier fusion provides satisfactory results (92.23 %) compared to other individual classifiers. One-way analysis of variance test, Friedman's test and Kruskal-Wallis test has also been conducted to validate the statistical significance of the results. The proposed system can be used as recommender system based on behavioral gait pattern about the performance of player of Indian cricket team, Biometric and help to diagnosis Parkinson disease.
C1 [Semwal, Vijay Bhaskar; Chauhan, Arun; Behera, Basudeba] Indian Inst Informat Technol Dharwad, Hubali Dharwad, India.
   [Singha, Joyeeta] LNM Inst Informat Technol, Jaipur, Rajasthan, India.
   [Sharma, Pinki Kumari] CSIR, Cybernet Lab, Kolkata, W Bengal, India.
C3 LNM Institute of Information Technology; Council of Scientific &
   Industrial Research (CSIR) - India
RP Semwal, VB (corresponding author), Indian Inst Informat Technol Dharwad, Hubali Dharwad, India.
EM vsemwal@iiitdwd.ac.in
RI Semwal, Vijay Bhaskar/B-5628-2017; Behera, Basudeba/M-2421-2016
OI Semwal, Vijay Bhaskar/0000-0003-0767-6057; Behera,
   Basudeba/0000-0001-5326-8017
CR Boyd JE, 2005, LECT NOTES COMPUT SC, V3161, P19
   Iqbal S, 2014, ROBOT AUTON SYST, V62, P889, DOI 10.1016/j.robot.2014.01.006
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Kale A, 2004, IEEE T IMAGE PROCESS, V13, P1163, DOI 10.1109/TIP.2004.832865
   Katoh K., 2011, 2011 4 INT C BIOM EN
   Kobayashi H, 2007, P 2007 I E INT C MEC
   Lai D. T. H., 2007, P INT JOINT C NEUR N
   Ogata M., 2006, SICE ICASE INT JOINT
   Ojo SO, 2015, IEEE INT C COMP COMM
   Singha J, 2017, MULTIMEDIA SYST, V23, P499, DOI 10.1007/s00530-016-0510-0
   Singha J, 2016, NEUROCOMPUTING, V208, P269, DOI 10.1016/j.neucom.2016.05.049
   Singha J, 2016, IET COMPUT VIS, V10, P143, DOI 10.1049/iet-cvi.2014.0432
   Steele KM, 2013, GAIT POSTURE
   Wang C, 2012, IEEE T PATTERN ANAL, V34, P2164, DOI 10.1109/TPAMI.2011.260
   Wang L, 2004, IEEE T CIRC SYST VID, V14, P149, DOI 10.1109/TCSVT.2003.821972
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Wang L, 2003, IEEE T IMAGE PROCESS, V12, P1120, DOI 10.1109/TIP.2003.815251
   Watelain E, 2000, ARCH PHYS MED REHAB, V81, P579, DOI 10.1016/S0003-9993(00)90038-8
   Yoneyama M, 2013, IEEE T NEURAL SYST R, V21
   Zhang ZX, 2011, LECT NOTES COMPUT SC, V7098, P150, DOI 10.1007/978-3-642-25449-9_19
NR 20
TC 53
Z9 54
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 24457
EP 24475
DI 10.1007/s11042-016-4110-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700059
DA 2024-07-18
ER

PT J
AU Alsaffar, A
   Aazam, M
   Hong, CS
   Huh, EN
AF Alsaffar, Aymen
   Aazam, Mohammad
   Hong, Choong Seon
   Huh, Eui-Nam
TI An architecture of IPTV service based on PVR-Micro data center and
   PMIPv6 in cloud computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IPTV service; PMIPv6; Micro data center; Mega data center; Multimedia
   content delivery protocol; Personal video recorder
ID PROXY MOBILE IPV6; MANAGEMENT; MODEL
AB This paper proposes An Architecture of IPTV Services based on PVR-Micro Data Center and PMIPv6 in Cloud Computing. The proposed architecture addresses important problems exist in normal PMIPv6 (Proxy mobile IPv6) environment which is not today addressed by normal PMIPv6. The first issue is user devices secure authentication, registration and fast handover in both inter-domain/intra-domain of PMIPv6. The second issues is multimedia delivery in inter-domain/intra-domain of PMIPv6. The third issue is tunneling overhead in inter-domain/intra. Today smart devices are mobile and user use them to access the internet from anywhere at any time using different connection method while they are traveling. Providing security measures such as user device authentication, registration as well as hand over requires different security measures and configuration in inter-domain/intra-domain of PMIPv6. Furthermore we provide new method to reduce tunneling overhead by allowing multimedia content to be delivered from many different Micro data center as well as Mega data center by using their own unique addresses to create tunneling to transfer multimedia content. Our goal is not only to reduce authentication delay, handover delay and reduce signaling cost using the intelligent utilization of AAA server (Authentication, Authorization, and Accounting Server), binding cache entry (BCE), and proxy notification update (PNU) and proxy notification acknowledgment (PNA) but also to provide fast delivery of multimedia content. Our result shows better performance when compare with normal PMIPv6. We used network simulator 3 (NS3) to generate our experiment result.
C1 [Alsaffar, Aymen; Aazam, Mohammad; Hong, Choong Seon; Huh, Eui-Nam] Dept Comp Sci & Engn, 1732 Deogyeong Daero, Yongin 446701, Gyeonggi Do, South Korea.
RP Huh, EN (corresponding author), Dept Comp Sci & Engn, 1732 Deogyeong Daero, Yongin 446701, Gyeonggi Do, South Korea.
EM aymen@khu.ac.kr; aazam@khu.ac.kr; cshong@khu.ac.kr; johnhuh@khu.ac.kr
RI Hong, Choong Seon/ABF-5527-2020; Aazam, Mohammad/T-3898-2017
OI Aazam, Mohammad/0000-0002-5473-6684; Hong, Choong
   Seon/0000-0003-3484-7333
FU MSIP (Ministry of Science, ICT and Future Planning), Korea, under the
   ITRC (Information Technology Research Center) support program
   [IITP-2016( H8501-16-1015]; Korea government (MSIP) [R7117-16-0202]
FX This research was supported by the MSIP (Ministry of Science, ICT and
   Future Planning), Korea, under the ITRC (Information Technology Research
   Center) support program (IITP-2016( H8501-16-1015) and also the Korea
   government (MSIP) (No. R7117-16-0202, The Development of Cloud Edge
   Computing Technology for Real-time IoT/CPS) supervised by the IITP
   (Institute for Information & communications Technology Promotion)).
   Corresponding author is Prof. Eui-Nam Huh.
CR Aazam M., 2011, 2011 IEEE Symposium on Computers & Informatics (ISCI), P46, DOI 10.1109/ISCI.2011.5958881
   Aazam M., 2010, P INT C MAN EM DIG E, P229
   Aazam M, 2010, IEEE INT C INF EM TE, V14-16, P1
   Aazam M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATION WORKSHOPS (PERCOM WORKSHOPS), P518, DOI 10.1109/PERCOMW.2015.7134091
   Aazam M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATION WORKSHOPS (PERCOM WORKSHOPS), P105, DOI 10.1109/PERCOMW.2015.7134002
   Aazam M, 2015, INT CON ADV INFO NET, P687, DOI 10.1109/AINA.2015.254
   Aazam M, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/108286
   Aazam M, 2014, ANN TELECOMMUN, V69, P485, DOI 10.1007/s12243-013-0391-6
   Akyildiz IF, 2000, IEEE J SEL AREA COMM, V18, P1254, DOI 10.1109/49.857925
   Alsaffar AA, 2014, KOR SMART MED I C AP, P243
   Alsaffar AA, 2013, P 7 INT C UB MAN COM, P1
   Alsaffar AA, 2015, INT CONF UBIQ FUTUR, P839, DOI 10.1109/ICUFN.2015.7182661
   [Anonymous], IPTV SECURITY PROTEC
   Chiang KH, 2004, IEEE T VEH TECHNOL, V53, P413, DOI 10.1109/TVT.2004.823544
   Gantz D, 2010, DIGITAL UNIVERSE DEC
   GUNDAVELLI S, 2008, PROXY MOBILE IPV6, P1
   Jae-Min Lee, 2008, 2008 3rd International Conference on Systems and Networks Communications, P280, DOI 10.1109/ICSNC.2008.20
   Jeon S, 2009, IEEE T CONSUM ELECTR, V55, P1227, DOI 10.1109/TCE.2009.5277980
   Johnson D., 2004, 3775 IETF RFC
   Krishnan S, 2013, IETF RFC, V7077, P5
   Lu HH, 2012, IEEE INT C INTELL TR, P921, DOI 10.1109/ITSC.2012.6338715
   McGrath D, 2012, CISC VIS NETW IND GL, P110
   Ming-Chin Chuang, 2011, 2011 International Conference on Consumer Electronics, Communications and Networks (CECNet), P1297, DOI 10.1109/CECNET.2011.5768193
   Momtaz A, 2010, INT C INF NETW AUT I, p[1, 1]
   Narten T., 2007, NEIGHBOR DISCOVERY I
   O'Neill J, 2015, 2020 VISION GLOBAL I, P1
   Sidhu B, 2007, PROC WRLD ACAD SCI E, V19, P314
   Yeh LY, 2012, IEEE INT C COMM ICC, P993
   Zeadally S, 2011, IEEE SYST J, V5, P518, DOI 10.1109/JSYST.2011.2165601
NR 29
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21579
EP 21612
DI 10.1007/s11042-016-4082-y
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400056
DA 2024-07-18
ER

PT J
AU Dhibi, N
   Elkefi, A
   Bellil, W
   Ben Amar, C
AF Dhibi, Naziha
   Elkefi, Akram
   Bellil, Wajdi
   Ben Amar, Chokri
TI Multi-layer compression algorithm for 3D deformed mesh based on multi
   library wavelet neural network architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deformations; Trust region spherical parameterization; Multi-layer
   compression; Wavelet neural network; Remeshing
ID TRANSMISSION
AB We propose in this paper a 3D mesh compression algorithm for 3D deformation objects to facilitate the transmission of deformed object to another. This algorithm allows eliminating an object in the sequence of deformed objects and reducing the information needed to represent the geometry of a mesh sequence. In our approach, we used Multi Library Wavelet Neural Network architecture (MLWNN) to align features of mesh and minimize distortion with fixed features. The introduced method minimizes the sum of the distances between all the corresponding vertices. It computes deformed ROI (Region Of Interest), updates and optimizes it to align the mesh features. First, our compression was performed using spherical geometrical image obtained by our trust region spherical parameterization. Geometrical images also facilitate compression and level-of-detail control. Second, the spherical wavelet transformation was used to decompose the geometrical image into multi-resolution sub-images characterizing the underlying functions in a local fashion in both spatial and frequency domains. Experimental results show that the progressive compression algorithm yields efficient compression capabilities with minimal set of features used to have good deformation scheme.
C1 [Dhibi, Naziha; Elkefi, Akram; Bellil, Wajdi; Ben Amar, Chokri] Univ Sfax, Natl Sch Engineers ENIS, REGIM Res Groups Intelligent Machines, Sfax 3038, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS)
RP Dhibi, N (corresponding author), Univ Sfax, Natl Sch Engineers ENIS, REGIM Res Groups Intelligent Machines, Sfax 3038, Tunisia.
EM dhibi.naziha@gmail.com
RI Chokri, BEN AMAR/K-5237-2012
CR Alexa M, 2000, COMPUT GRAPH FORUM, V19, pC411, DOI 10.1111/1467-8659.00433
   Bellil W, 2007, INT REV COMPUTERS SO, V2, P520
   Chen R, 2008, COMPUT MATH APPL, V56, P1597, DOI 10.1016/j.camwa.2008.03.023
   Chourou A, 2008, INT CONF ACOUST SPEE, P1381, DOI 10.1109/ICASSP.2008.4517876
   Denis L, 2010, IEEE T MULTIMEDIA, V12, P773, DOI 10.1109/TMM.2010.2058094
   Gu X., 2003, P S GEOM PROC
   Guskov I, 2000, COMP GRAPH, P95, DOI 10.1145/344779.344831
   Guskov I., 2004, P 2004 ACM SIGGRAPH, P183
   Hoppe H, 2003, ADV MULTIRESOLUTION
   Ibarria L, 2003, ACM SIG EUR S COMP A
   Kammoun A, 2012, COMPUT GRAPH-UK, V36, P272, DOI 10.1016/j.cag.2012.02.004
   Karni Z, 2004, COMPUT GRAPH-UK, V28, P25, DOI 10.1016/j.cag.2003.10.002
   Khodakovsky A, 2004, MATH VISUAL, P189
   Khodakovsky A, 2000, COMP GRAPH, P271, DOI 10.1145/344779.344922
   Lengyel JE, 1999, P ACM S INT 3D GRAPH
   Luo XN, 2008, WIREL NETW, V14, P47, DOI 10.1007/s11276-006-7603-1
   Ma JP, 2009, INT C COMP AID DES C, P357, DOI 10.1109/CADCG.2009.5246876
   Maglo A, 2013, ACM COMPUT SURV, V9, P39
   Müller K, 2005, IEEE IMAGE PROC, P1197
   Naziha D, 2015, ADV CONCEPTS INTELLI
   NEALEN A, 2005, P ACM SIGGRAPH2005, P1142
   Othmani M, 2010, IEEE INT S IM VID CO
   Othmani M, 2012, MULTIMED TOOLS APPL, V59, P7, DOI 10.1007/s11042-010-0697-6
   Payan F, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P391, DOI 10.1109/TDPVT.2002.1024089
   Payan F, 2005, P IEEE ACIDCA ICMI 2
   Praun HH, 2003, ACM T GRAPHICS
   Ramadan RM, 2012, INT J ADV COMPUT SCI, V3
   Sander P. V., 2002, Rendering Techniques 2002. Eurographics Workshop Proceedings, P87
   Sattler M., 2005, P 2005 ACM SIGGRAPH, P209
   Shenghua Wan, 2012, Computational Visual Media. Proceedings First International Conference, CVM 2012, P170, DOI 10.1007/978-3-642-34263-9_22
   Sorking O, 2004, LAPLCIAN SURFACE EDI
   Tang L-L, 2011, INT J INNOVATIVE COM, V7
   Yang JH, 2002, IEEE T CIRC SYST VID, V12, P1178, DOI 10.1109/TCSVT.2002.806814
   Zayer R, 2006, P IEEE INT C SHAP MO
   Zhang JH, 2004, IEEE DATA COMPR CONF, P508
   Zhao C, 2011, COMPUT ANIMAT VIRT W, V22, P307, DOI 10.1002/cav.410
NR 36
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 20869
EP 20887
DI 10.1007/s11042-016-3996-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400023
DA 2024-07-18
ER

PT J
AU Kwon, H
   Kim, D
   Hahn, C
   Hur, J
AF Kwon, Hyunsoo
   Kim, Daeyeong
   Hahn, Changhee
   Hur, Junbeom
TI Secure authentication using ciphertext policy attribute-based encryption
   in mobile multi-hop networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE D2D communication; Mobile multi-hop networks; CP-ABE; Authentication
AB With the dramatic increase of the number of mobile devices such as smartphones and tablet PCs, mobile traffic has increased enormously. Especially, the multimedia data accounts for bulk of the traffic transmitted in mobile networks. To accommodate this growth, device-to-device connection (D2D), which provides infra-connection off-loading, is receiving significant attention. However, we have observed that the majority of the current D2D protocols including Bluetooth and Wi-Fi Direct are vulnerable to man-in-the-middle (MITM) and replay attacks in mobile multi-hop networks. To resolve this problem, in this paper, we propose a novel D2D authentication protocol with a secure initial key establishment using ciphertext-policy attribute-based encryption (CP-ABE). By leveraging CP-ABE, the proposed scheme allows the communicating parties to mutually authenticate and derive the link key in an expressive and secure manner in a multi-hop network environment. We also propose several variations of the proposed scheme for different scenarios in a multi-hop networks without network infrastructure. We prove that the proposed scheme is secure against MITM and replay attack in D2D mobile multi-hop networks. Experimental results indicate that the proposed scheme incurs reasonable computation cost in the real world.
C1 [Kwon, Hyunsoo; Kim, Daeyeong; Hahn, Changhee; Hur, Junbeom] Korea Univ, Dept Comp Sci & Engn, 145 Anam Ro, Seoul 136701, South Korea.
C3 Korea University
RP Hur, J (corresponding author), Korea Univ, Dept Comp Sci & Engn, 145 Anam Ro, Seoul 136701, South Korea.
EM hs_kwon@korea.ac.kr; rlaeod@korea.ac.kr; manjungs@gmail.com;
   jbhur@korea.ac.kr
RI 권, 현수/HPG-4730-2023; Hahn, Changhee/HTR-0677-2023
OI Hahn, Changhee/0000-0003-4334-0411
FU National Research Foundation of Korea(NRF) grant - Korea
   government(MSIP) [2013R1A2A2A01005559]; Institute for Information &
   communications Technology Promotion(IITP) - Korea government(MSIP)
   [B0190-15-2028, R0190-15-2011]
FX This work was supported by the National Research Foundation of
   Korea(NRF) grant funded by the Korea government(MSIP) (No.
   2013R1A2A2A01005559). This work was also supported by Institute for
   Information & communications Technology Promotion(IITP) grant funded by
   the Korea government(MSIP) (No. B0190-15-2028 and No. R0190-15-2011)
CR [Anonymous], IEEE 802.15
   [Anonymous], TECHNICAL REPORT
   [Anonymous], IEEE INT C COMM ICC
   [Anonymous], 2012, TECHNICAL REPORT
   [Anonymous], 2014, Cisco visual networking index: Global mobile data traffic forecast update
   Bethencourt J, 2007, P IEEE S SECUR PRIV, P321, DOI 10.1109/sp.2007.11
   Boneh D, 2003, SIAM J COMPUT, V32, P586, DOI 10.1137/S0097539701398521
   Bruno R, 2005, IEEE COMMUN MAG, V43, P123, DOI 10.1109/MCOM.2005.1404606
   Camps-Mur D, 2013, IEEE WIREL COMMUN, V20, P96, DOI 10.1109/MWC.2013.6549288
   Cocks C., 2001, CRYPTOGRAPHY CODING, V2260, P360, DOI DOI 10.1007/3-540-45325-3
   Corson S., 1999, 2501 IETF RFC
   Estrin D, 2001, INT CONF ACOUST SPEE, P2033, DOI 10.1109/ICASSP.2001.940390
   Khalil I, 2013, INT CONF COMP SCI, P106, DOI 10.1109/CSIT.2013.6588766
   Kügler D, 2003, LECT NOTES COMPUT SC, V2742, P149
   Kwon H., 2003, ELECT TELECOMMUNICAT, V18, P11
   Kwon H, 2014, LECT NOTES COMPUT SC, V8491, P267, DOI 10.1007/978-3-319-07782-6_25
   Lee C, 2006, THESIS
   Lee Y., 2009, PRINCIPLES TERAHERTZ, P12
   Mishin S., 2011, 2011 Joint Conference of the IEEE International Frequency Control and the European Frequency and Time Forum (FCS), P1
   Perkins C.E., 2008, AD HOC NETWORKING
   Sahai A, 2005, LECT NOTES COMPUT SC, V3494, P457, DOI 10.1007/11426639_27
   Sahai A, 1985, ADV CRYPTOLOGY CRYPT, P47
   Wi-Fi Alliance, 2005, QUAL SERV QOS TASK G
   Wi-Fi Alliance, 2007, WI FI PROT SET SPEC
   Xingliang Z, 2012, INNOV MANAG IND ENG, V2, P312
NR 25
TC 10
Z9 11
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19507
EP 19521
DI 10.1007/s11042-015-3187-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500011
DA 2024-07-18
ER

PT J
AU Liao, XPL
   Zhang, CC
AF Liao, Xinpeng L.
   Zhang, Chengcui
TI Toward situation awareness: a survey on adaptive learning for model-free
   tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Machine learning; Model-free tracking; Semi-supervised
   online learning; Video surveillance
ID VISUAL TRACKING; OBJECT TRACKING; MEAN-SHIFT; COMPUTER VISION; ROBUST;
   MOTION
AB Visual tracking estimates the trajectory of an object of interest in non-stationary image streams that change over time. Recently, approaches for model-free tracking have received increased interest since manually annotating sufficient examples of all objects in the world is prohibitively expensive. By definition, a model-free tracker has only one labeled instance in the form of an identified object in the first frame. In the subsequent frames, it has to learn variations of the tracked object with only unlabeled data available. There exists a dilemma for model-free trackers, i.e., whether the tracker would shift the focus to clutters (i.e., adaptivity) or result in very short tracks (i.e., stability) largely depends on how sensitive the appearance model is. In contrast to recent survey efforts with data-driven approaches focusing on the performance on benchmarks, this article aims to provide an in-depth survey on solutions to the dilemma between adaptivity and stability in model-free tracking focusing on the ability of achieving situation awareness, i.e., learning the object appearance adaptively in a non-stationary environment. The survey results show that, regardless of visual representations and statistical models involved, the way of exploiting unlabeled data in the changing environment and the extent of how rapidly the appearance model need be updated accordingly with selected example(s) of estimated labels are the key to many, if not all, evaluation measures for tracking. Such conceptual consensuses, despite the diversity of approaches in this field, for the first time capture the essence of model-free tracking and facilitate the design of visual tracking systems.
C1 [Liao, Xinpeng L.; Zhang, Chengcui] Univ Alabama Birmingham, Dept Comp & Informat Sci, 127 Campbell Hall,1300 Univ Blvd, Birmingham, AL 35294 USA.
C3 University of Alabama System; University of Alabama Birmingham
RP Liao, XPL (corresponding author), Univ Alabama Birmingham, Dept Comp & Informat Sci, 127 Campbell Hall,1300 Univ Blvd, Birmingham, AL 35294 USA.
EM xinpeng@uab.edu; czhang02@uab.edu
OI Liao, Xinpeng/0000-0002-0719-2346
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], ADV KERNEL METHODS S
   [Anonymous], 2014, REGISTRATION RECOGNI, DOI DOI 10.1007/978-3-642-44907-9_6
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247881
   [Anonymous], 2014, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2013.230
   [Anonymous], P EUR C COMPUT VIS
   [Anonymous], COMPUTER VISION ECCV
   [Anonymous], ARXIV150104587
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Bai QX, 2013, IEEE I CONF COMP VIS, P2040, DOI 10.1109/ICCV.2013.255
   Bertinetto MO, 2015, PREPRINT
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Cai ZW, 2014, IEEE T IMAGE PROCESS, V23, P5497, DOI 10.1109/TIP.2014.2364919
   Cehovin L., 2015, ARXIV150205803
   Cehovin L, 2013, IEEE T PATTERN ANAL, V35, P941, DOI 10.1109/TPAMI.2012.145
   Chapelle O., 2006, SEMISUPERVISED LEARN
   Chapelle O, 2007, NEURAL COMPUT, V19, P1155, DOI 10.1162/neco.2007.19.5.1155
   Chen WH, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P129, DOI 10.1109/ICCVW.2013.23
   Collins RT, 2003, PROC CVPR IEEE, P234
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Du W, 2008, LECT NOTES COMPUT SC, V5303, P225, DOI 10.1007/978-3-540-88688-4_17
   Duffner S, 2014, EUR C COMP VIS, P232
   Duffner S, 2013, IEEE I CONF COMP VIS, P2480, DOI 10.1109/ICCV.2013.308
   Fan ZM, 2005, PROC CVPR IEEE, P502
   Felsberg M, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P121, DOI 10.1109/ICCVW.2013.22
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Gabriel Pierre F, 2003, Advanced Concepts for Intelligent Vision Systems, P166
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   Godec M, 2013, COMPUT VIS IMAGE UND, V117, P1245, DOI 10.1016/j.cviu.2012.11.005
   Grabner H., 2006, BMVC, P47
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Grabner H, 2010, PROC CVPR IEEE, P1285, DOI 10.1109/CVPR.2010.5539819
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Hua Y, 2015, IEEE I CONF COMP VIS, P3092, DOI 10.1109/ICCV.2015.354
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jae-Yeong Lee, 2011, 2011 IEEE International Conference on Robotics and Biomimetics (ROBIO), P2860, DOI 10.1109/ROBIO.2011.6181739
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/S10994-009-5108-8, 10.1007/s10994-009-5108-8]
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Kim SJ, 2007, IEEE J-STSP, V1, P606, DOI 10.1109/JSTSP.2007.910971
   Kristan M, 2013, WORKSH VIS OBJ TRACK
   Kristan M., 2015, ARXIV150301313
   Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Lebeda K, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P153, DOI 10.1109/ICCVW.2013.26
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730
   Louppe G., 2015, Understanding Random Forests: From Theory to Practice | Enhanced Reader
   Mallapragada PK, 2009, IEEE T PATTERN ANAL, V31, P2000, DOI 10.1109/TPAMI.2008.235
   Maresca MarioEdoardo., 2014, European Conference on Computer Vision (ECCV), P244
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Nam H., 2015, Learning multi-domain convolutional neural networks for visual tracking
   Nam H, 2014, LECT NOTES COMPUT SC, V8693, P112, DOI 10.1007/978-3-319-10602-1_8
   Nebehay G, 2014, IEEE WINT CONF APPL, P862, DOI 10.1109/WACV.2014.6836013
   Ofjall K., 2014, P WORKSH VIS OBJ TRA, P218
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   Oron S, 2012, PROC CVPR IEEE, P1940, DOI 10.1109/CVPR.2012.6247895
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Sevilla-Lara L, 2012, PROC CVPR IEEE, P1910, DOI 10.1109/CVPR.2012.6247891
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Sinha S., 2004, Graph Cut Algorithms in Vision, Graphics and Machine Learning An Integrative Paper
   Stalder Severin, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1409, DOI 10.1109/ICCVW.2009.5457445
   Tang F, 2007, IEEE I CONF COMP VIS, P992
   Tang M, 2015, IEEE I CONF COMP VIS, P3038, DOI 10.1109/ICCV.2015.348
   Tian M, 2007, LECT NOTES COMPUT SC, V4843, P355
   Vermaak J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1110
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Vojir T, 2013, LECT NOTES COMPUT SC, V7944, P652
   Wang N., 2013, Advances in Neural Information Processing Systems, P809
   Wang XM, 2015, IEEE I CONF COMP VIS, P4337, DOI 10.1109/ICCV.2015.493
   Wendel A, 2011, ROBUSTIFYING FLOCK T, P91
   Williams O, 2005, IEEE T PATTERN ANAL, V27, P1292, DOI 10.1109/TPAMI.2005.167
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Wu Y, 2012, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2012.6247878
   Xiao JJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P137, DOI 10.1109/ICCVW.2013.24
   Yang M, 2009, IEEE T PATTERN ANAL, V31, P1195, DOI 10.1109/TPAMI.2008.146
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yu Q, 2008, LECT NOTES COMPUT SC, V5303, P678
   Zeisl B, 2010, PROC CVPR IEEE, P1879, DOI 10.1109/CVPR.2010.5539860
   ZHANG K, 2012, ECCV, P864
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zhang L, 2014, IEEE T PATTERN ANAL, V36, P756, DOI 10.1109/TPAMI.2013.221
   Zhang TZ, 2012, LECT NOTES COMPUT SC, V7577, P470, DOI 10.1007/978-3-642-33783-3_34
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zhu G., 2015, ARXIV150708085
NR 104
TC 6
Z9 6
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21073
EP 21115
DI 10.1007/s11042-016-4001-2
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400034
DA 2024-07-18
ER

PT J
AU Wu, YP
   Peng, XQ
   Ruan, K
   Hu, ZK
AF Wu, Yanpeng
   Peng, Xiaoqi
   Ruan, Kai
   Hu, Zhikun
TI Improved image segmentation method based on morphological reconstruction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Morphological reconstruction; Watershed transformation; Image
   segmentation; Top-bottom hat transformation; Marker shaping
ID GENERALIZED M-SET; BUBBLE-SIZE
AB Image segmentation is a key step in linking up of image processing and image analysis and a big problem in computer vision. Morphological reconstruction is an important method of image edge segmentation. Watershed transformation is a widely used image segmentation tool base on morphological reconstruction. The traditional watershed transformation method was poor in divide objects in different size because single threshold value can't eliminate noises in large object on top and enhance the edges of small object simultaneously. This paper proposed an improved image segmentation method based on morphological reconstruction. Using erosion operation, dilation operation, catchment basins for all size of objects were morphologically marked and re-shaped, which ensure watershed transformation in the final step segmentation the image accurately. The Experiment results showed the proposed method is more accurate in segmentation of complex images than traditional methods.
C1 [Wu, Yanpeng; Peng, Xiaoqi] Hunan First Normal Coll, Dept Informat Sci & Engn, Changsha 410205, Hunan, Peoples R China.
   [Wu, Yanpeng; Peng, Xiaoqi; Hu, Zhikun] Cent S Univ, Sch Energy Sci & Engn, Changsha 410083, Hunan, Peoples R China.
   [Wu, Yanpeng; Ruan, Kai] Shaoyang Univ, Dept Informat & Engn, Shaoyang Hunan 422000, Hunan, Peoples R China.
C3 Hunan First Normal University; Central South University; Shaoyang
   University
RP Peng, XQ (corresponding author), Hunan First Normal Coll, Dept Informat Sci & Engn, Changsha 410205, Hunan, Peoples R China.; Peng, XQ (corresponding author), Cent S Univ, Sch Energy Sci & Engn, Changsha 410083, Hunan, Peoples R China.
EM pengxq126@126.com
FU Natural Science Foundation of China [61134006, 61273169, 61273159];
   Shaoyang Science and technology of China [2015JH40]; Hunan Province
   Science Foundation of China
FX This work is supported by the project of Natural Science Foundation of
   China with No. 61134006 entitled "Modeling and optimization control of
   mineral flotation process based on machine vision", the project of
   Natural Science Foundation of China with No. 61273169 entitled "Research
   on production conditions anomaly detection and fault prediction method
   based on multidimensional differences perception", and the project of
   Natural Science Foundation of China with No. 61273159 entitled "On the
   methods of fault diagnosis based on incomplete data for alumina
   evaporation process", the project of Shaoyang Science and technology of
   China with No. 2015JH40 entitled "Research on flotation reagent system
   and technology", and the project of Hunan Province Science Foundation of
   China entitled "Research on key technology of floatation froth image
   processing".
CR [Anonymous], APPL MATH INF SCI
   Cai Cai, 2014, Acta Scientiarum Naturalium Universitatis Pekinensis, V50, P323
   Chai YN, 2012, LECT NOTES COMPUT SC, V7572, P794, DOI 10.1007/978-3-642-33718-5_57
   Chen WL, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/829589
   Gu Y, 2007, J BEIJING I PETRO CH, V15, P61
   Guoying Z., 2011, Mining Science and Technology, V21, P239, DOI DOI 10.1016/J.MSTC.2011.02.013
   Hao W., 2011, PROCEDIA ENG, P2798
   [郝颖明 Hao Yingming], 2005, [中国图象图形学报. A, Journal of image and graphics], V10, P484
   He G, 2011, NONFERROUS METALS SC, V2, P57
   [胡敏 Hu Min], 2011, [电子测量与仪器学报, Journal of Electronic Measurement and Instrument], V25, P864
   Levner I, 2007, IEEE T IMAGE PROCESS, V16, P1437, DOI 10.1109/TIP.2007.894239
   Lézoray O, 2009, PATTERN RECOGN LETT, V30, P397, DOI 10.1016/j.patrec.2008.11.005
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   [李厚杰 Li Houjie], 2014, [大连理工大学学报, Journal of Dalian University of Technology], V54, P100
   Li J, 2012, IEEE T GEOSCI REMOTE, V50, P809, DOI 10.1109/TGRS.2011.2162649
   Liu JP, 2013, MINER ENG, V45, P128, DOI 10.1016/j.mineng.2013.02.003
   Liu S., 2013, MATH PROBL ENG, V2013, P1
   Liu S, 2014, APPL MATH COMPUT, V243, P767, DOI 10.1016/j.amc.2014.06.016
   Liu S, 2013, APPL MATH COMPUT, V220, P668, DOI 10.1016/j.amc.2013.06.096
   [刘永学 LIU Yongxue], 2006, [遥感学报, Journal of Remote Sensing], V10, P350
   Liu Yu-qin, 2011, Application Research of Computers, V28, P2355, DOI 10.3969/j.issn.1001-3695.2011.06.098
   SadrKazemi N, 1997, MINER ENG, V10, P1075, DOI 10.1016/S0892-6875(97)00094-0
   Shao Jianbin, 2011, Journal of Xi'an University of Technology, V27, P185
   [吴涛 Wu Tao], 2014, [中国图象图形学报, Journal of Image and Graphics], V19, P1
   [阳春华 Yang Chunhua], 2009, [仪器仪表学报, Chinese Journal of Scientific Instrument], V30, P717
   Yao BP, 2011, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR.2011.5995368
   Yu Wang-sheng, 2011, Acta Electronica Sinica, V39, P825
   Zhou KJ, 2010, J CENT SOUTH UNIV T, V17, P1049, DOI 10.1007/s11771-010-0597-y
NR 28
TC 20
Z9 23
U1 3
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19781
EP 19793
DI 10.1007/s11042-015-3192-2
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500027
DA 2024-07-18
ER

PT J
AU Jang, SB
   Ko, YW
AF Jang, Sung-Bong
   Ko, Young-Woong
TI Efficient multimedia big data anonymization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia security; Data anonymization; Multimedia big data;
   k-anonymity; l-diversity
ID PRIVACY; SECURITY; CLASSIFICATION
AB So far, the data anonymization approaches based on k-anonymity and l-diversity has contributed much to privacy protection from record and attributes linkage attacks. However, the existing solutions are not efficient when applied to multimedia Big Data anonymization. This paper analyzes this problem in detail in terms of the processing time, memory space, and usability, and presents two schemes to overcome such inefficiency. The first one is to reduce the processing time and space by minimizing the temporary buffer usage during anonymization process. The second is to construct an early taxonomy during the database design. The idea behind this approach is that database designers should take preliminary actions for anonymization during the early stage of a database design to alleviate the burden placed on data publishers. To evaluate the effectiveness and feasibility of these schemes, specific application tools based on the proposed approaches were implemented and experiments were conducted.
C1 [Jang, Sung-Bong] Kumoh Natl Inst Technol, Dept Comp Software Engn, 61 Daehak ro, Gumi 730701, Kyoung Buk, South Korea.
   [Ko, Young-Woong] Hallym Univ, Dept Comp Engn, Chunchon 200702, Gangwon, South Korea.
C3 Kumoh National University Technology; Hallym University
RP Ko, YW (corresponding author), Hallym Univ, Dept Comp Engn, Chunchon 200702, Gangwon, South Korea.
EM yuko@hallym.ac.kr
FU Kumoh National Institute of Technology; NRF - MEST [2014R1A2A1A11054160]
FX This paper was supported by Research Fund, Kumoh National Institute of
   Technology. And this research was also supported by Basic Science
   Research Program through the NRF funded by the MEST
   (2014R1A2A1A11054160).
CR [Anonymous], 2005, P SIGMOD
   Bayardo RJ, 2005, PROC INT CONF DATA, P217
   Fung BCM, 2006, ANONYMIZING SEQUENTI
   Fung BCM, 2007, IEEE T KNOWL DATA EN, V19, P711, DOI 10.1109/TKDE.2007.1015
   Fung BCM, 2010, ACM COMPUT SURV, V42, DOI 10.1145/1749603.1749605
   Iyengar VS, 2002, TRANSFORMING DATA SA, P279
   Jang S-B, 2014, SERSC ASTL, V65, P57
   Li J., 2008, P ACM C MAN DAT SIGM, P437
   Li Ninghui., 2007, t-Closeness: Privacy Beyond k-Anonymity and l- Diversity
   Liu YB, 2013, KNOWL INF SYST, V36, P23, DOI 10.1007/s10115-012-0527-4
   Machanavajjhala A, 2007, ACM T KNOWL DISCOV D, V1, P1, DOI DOI 10.1145/1217299.1217302
   Motani R, 2007, VLDB 2007
   Nergiz ME, 2009, IEEE T KNOWL DATA EN, V21, P1104, DOI 10.1109/TKDE.2008.210
   Ridzon R, 2009, ELMAR PROC, P105
   Samarati P., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, DOI 10.1145/275487.275508
   Samarati P, 2001, IEEE T KNOWL DATA EN, V13, P1010, DOI 10.1109/69.971193
   Samarati P, 1998, IEEE SRS P
   Sergey V, 2012, P INT C ADV DAT KNOW, P163
   Susanto H., 2010, Future Information Technology (FutureTech), 2010 5th International Conference on, P1
   Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648
   Thuraisingham B, 2007, MULTIMED TOOLS APPL, V33, P13, DOI 10.1007/s11042-006-0096-1
   Truta Traian Marius, 2006, PRIVACY PROTECTION P
   Wang K, 2007, KNOWL INF SYST, V11, P345, DOI 10.1007/s10115-006-0035-5
   Wernke M, 2014, PERS UBIQUIT COMPUT, V18, P163, DOI 10.1007/s00779-012-0633-z
   Wong R. C.-W., 2006, 12 ACM SIGKDD INT C, P754, DOI DOI 10.1145/1150402.1150499
   Xiao X., 2006, P ACM SIGMOD INT C M, P229
   Xu L, 2014, IEEE ACCESS, V2, P1149, DOI 10.1109/ACCESS.2014.2362522
   Zhang Q, 2007, AGGREGATE QUERY ANSW
NR 28
TC 2
Z9 2
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 17855
EP 17872
DI 10.1007/s11042-015-3123-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800015
DA 2024-07-18
ER

PT J
AU Yang, JC
   He, SD
   Lin, YC
   Lv, ZH
AF Yang, Jiachen
   He, Shudong
   Lin, Yancong
   Lv, Zhihan
TI Multimedia cloud transmission and storage system based on internet of
   things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; Multimedia; Security of cloud storage; Role access
   control; Multimedia data state
ID ACCESS-CONTROL; SECURE
AB For the issues of large space and storage security of multimedia files, we analyzed the impact of access control and cloud storage on multimedia file, and proposed a mixed security cloud storage framework based on Internet of Things. This paper introduced the concept of multimedia protection into the method based on role access control. Moreover, we also adopted a scheme based on the combination of multimedia data state and role access control. At the same time, all input and output devices were connected to this system. Internet of Things is used to judge whether circuits are connected and whether the devices are normally operated, so as to improve the access efficiency. On this basis, we also described in detail the complete process of registration, role assignment, multimedia file owner's request for data encryption, and user login and access to multimedia file. According to the result, this scheme can be used to resist the known attacks. It guarantees security of multimedia files.
C1 [Yang, Jiachen; He, Shudong; Lin, Yancong] Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
   [Lv, Zhihan] Chinese Acad Sci, SIAT, Beijing, Peoples R China.
C3 Tianjin University; Chinese Academy of Sciences; Shenzhen Institute of
   Advanced Technology, CAS
RP Lin, YC (corresponding author), Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
EM yangjiachen@tju.edu.cn; shudonghe@tju.edu.cn; yclin@tju.edu.cn;
   lvzhihan@gmail.com
RI Yang, Jiachen/ABH-5032-2020; Lyu, Zhihan/I-3187-2014; Lv,
   Zhihan/GLR-6000-2022
OI Yang, Jiachen/0000-0003-2558-552X; Lyu, Zhihan/0000-0003-2525-3074; Lv,
   Zhihan/0000-0003-2525-3074
FU National Natural Science Foundation of China [61471260]
FX This research is partially supported by the National Natural Science
   Foundation of China (No. 61471260).
CR Altamimi M., 2012, 2012 IEEE 5th International Conference on Cloud Computing (CLOUD), P764, DOI 10.1109/CLOUD.2012.72
   [Anonymous], ARXIV150406359
   [Anonymous], 2014, J MED SYST
   [Anonymous], [No title captured]
   Benrhouma O, 2013, MULTIMEDIA TOOLS APP
   Chen CL, 2014, J SUPERCOMPUT, V70, P54, DOI 10.1007/s11227-013-1066-9
   Dias R, 2013, MULTIMED TOOLS APPL, V74, P3691
   Forouzan B.A., 2007, Cryptography and Network Security
   Kim SK, 2015, MULTIMED TOOLS APPL, V74, P3273, DOI 10.1007/s11042-015-2459-y
   Li YF, 2014, APPL MATH INFORM SCI, V8, P3159, DOI 10.12785/amis/080657
   Lv Z, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2645860
   Lv ZY, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0061249
   Nan GF, 2014, IEEE NETWORK, V28, P74, DOI 10.1109/MNET.2014.6863135
   Nan XM, 2014, J VIS COMMUN IMAGE R, V25, P928, DOI 10.1016/j.jvcir.2014.02.008
   Nan XM, 2011, IEEE INT WORKSH MULT
   Needleman Mark, 2000, Ser. Rev., V26, P69
   Pohl D, 2013, MULTIMED TOOLS APPL, V74, P3901
   Rosário D, 2014, COMPUT COMMUN, V45, P21, DOI 10.1016/j.comcom.2014.04.002
   Yang JC, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.3.033001
   Zhang Q, 2010, J INTERNET SERV APPL, V1, P7, DOI 10.1007/s13174-010-0007-6
   Zhou L, 2014, J COMPUT SYST SCI, V80, P1518, DOI 10.1016/j.jcss.2014.04.019
   Zhou L, 2013, IEEE T INF FOREN SEC, V8, P1947, DOI 10.1109/TIFS.2013.2286456
   Zhou L, 2011, IEEE NETWORK, V25, P35, DOI 10.1109/MNET.2011.5772059
   Zhu WW, 2011, IEEE SIGNAL PROC MAG, V28, DOI 10.1109/MSP.2011.940269
NR 24
TC 110
Z9 111
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 17735
EP 17750
DI 10.1007/s11042-015-2967-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800008
DA 2024-07-18
ER

PT J
AU Hu, RY
   Cheng, DB
   He, W
   Wen, GQ
   Zhu, YH
   Zhang, JL
   Zhang, SC
AF Hu, Rongyao
   Cheng, Debo
   He, Wei
   Wen, Guoqiu
   Zhu, Yonghua
   Zhang, Jilian
   Zhang, Shichao
TI Low-rank feature selection for multi-view regression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature selection; Subspace learning; Multi-view dataset; Low-rank
   selection; Sparse coding technology
ID UNSUPERVISED FEATURE-SELECTION; CLASSIFICATION
AB Real life data and information often have different ways to obtain. For example, in computer vision, we can describe an objective by different types, such as text, video and picture. And even from variety of angles. These different descriptors of the same object are usually called multi-view data. In ordinarily, dimensional reduction methods usually include feature selection and subspace learning, respectively, can have better interpretative capability and stabilizing performance, and now are very prevalent method for high-dimensional data. However, it is usually not considering the relationship among class indicators, so the performance of regression model is not very ideal. In this paper, we simultaneously consider feature selection, low-rank selection, and subspace learning into a unified framework. Specifically, under the framework of linear regression model, we first use the low-rank constraint to feature selection which considers two aspects of information inherent in data. The low-rank constraint takes the correlation of response variables into account, then embed an a"" (2, p) -norm regularizer to consider the correlation among variety of class indicators, and feature vectors and their corresponding response variables. Meanwhile, we take LDA algorithm which belong to the subspace learning to further adjust relevant feature selection results into account. Lastly, we conducted experiments on several real multi-views image sets and corresponding experimental consequences also validated the furnished method outperformed all comparison algorithms.
C1 [Hu, Rongyao; Cheng, Debo; He, Wei; Wen, Guoqiu; Zhang, Shichao] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Guangxi, Peoples R China.
   [Zhu, Yonghua] Guangxi Univ, Nanning 530004, Guangxi, Peoples R China.
   [Zhang, Jilian] Guangxi Univ Finance & Econ, Nanning 530003, Guangxi, Peoples R China.
C3 Guangxi Normal University; Guangxi University; Guangxi University of
   Finance & Economics
RP Zhang, SC (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Guangxi, Peoples R China.
EM hu_No1@126.com; 15676209686@163.com; risehnhew@163.com;
   wenguoqiu2008@163.com; 1293234987@qq.com;
   jilian.z.2007@phdis.smu.edu.sg; zhangsc@mailbox.gxnu.edu.cn
RI Zhang, Shichao/JXW-9650-2024; Zhang, Shichao/AAA-7608-2020; Cheng,
   Debo/T-9106-2019; zhang, jiliang/AAJ-7800-2020; zhang,
   jiliang/N-5659-2015; Cheng, Debo/Y-5226-2019; Hu, Rongyao/AAH-3834-2020
OI zhang, jiliang/0000-0002-9372-7510; Cheng, Debo/0000-0002-0383-1462; Hu,
   Rongyao/0000-0001-9989-1103
FU China "1000-Plan" National Distinguished Professorship; Nation Natural
   Science Foundation of China [61263035, 61363009, 61573270, 61672177];
   China 973 Program [2013CB329404]; China Key Research Program
   [2016YFB1000905]; Guangxi Natural Science Foundation [2012GXNSFGA060004,
   2015GXNSFCB139011]; China Postdoctoral Science Foundation [2015M570837];
   Innovation Project of Guangxi Graduate Education [YCSZ2016046]; Guangxi
   High Institutions' Program of Introducing 100 High-Level Overseas
   Talents; Guangxi Collaborative Innovation Center of Multi-Source
   Information Integration and Intelligent Processing; Guangxi "Bagui"
   Teams for Innovation and Research
FX This work was supported in part by the China "1000-Plan" National
   Distinguished Professorship; the Nation Natural Science Foundation of
   China (Grant No: 61263035, 61363009, 61573270 and 61672177), the China
   973 Program (Grant No: 2013CB329404); the China Key Research Program
   (Grant No: 2016YFB1000905); the Guangxi Natural Science Foundation
   (Grant No: 2012GXNSFGA060004 and 2015GXNSFCB139011); the China
   Postdoctoral Science Foundation (Grant No: 2015M570837); the Innovation
   Project of Guangxi Graduate Education under grant YCSZ2016046; the
   Guangxi High Institutions' Program of Introducing 100 High-Level
   Overseas Talents; the Guangxi Collaborative Innovation Center of
   Multi-Source Information Integration and Intelligent Processing; and the
   Guangxi "Bagui" Teams for Innovation and Research.
CR [Anonymous], 2007, P AAAI C ART INT
   [Anonymous], COMPUTER SPEECH LANG
   [Anonymous], CVPR
   [Anonymous], P 19 ACM SIGKDD C KN
   Cao J, 2014, INFORM SCIENCES, V266, P31, DOI 10.1016/j.ins.2013.12.062
   Cao J, 2013, IEEE T CYBERNETICS, V43, P570, DOI 10.1109/TSMCB.2012.2212430
   Cao ZB, 2015, INT J DATA MIN BIOIN, V12, P363, DOI 10.1504/IJDMB.2015.070071
   Chyzhyk D, 2014, NEUROCOMPUTING, V128, P73, DOI 10.1016/j.neucom.2013.01.065
   Gao LL, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P487, DOI 10.1145/2671188.2749309
   Hoerl AE, 2000, TECHNOMETRICS, V42, P80, DOI 10.2307/1271436
   Liu HW, 2015, PATTERN RECOGN, V48, P1724, DOI 10.1016/j.patcog.2014.11.007
   Liu XL, 2015, IEEE T IMAGE PROCESS, V24, P1825, DOI 10.1109/TIP.2015.2403235
   Luo D, 2011, P AAAI C ART INT, V25
   Maugis C, 2009, BIOMETRICS, V65, P701, DOI 10.1111/j.1541-0420.2008.01160.x
   Özuysal M, 2009, PROC CVPR IEEE, P778, DOI 10.1109/CVPRW.2009.5206633
   Qin YS, 2007, APPL INTELL, V27, P79, DOI 10.1007/s10489-006-0032-0
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Seitz S. M., 2006, 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06), V1, P519
   Shi XS, 2015, IEEE T IMAGE PROCESS, V24, P1341, DOI 10.1109/TIP.2015.2405474
   Tabakhi S, 2014, ENG APPL ARTIF INTEL, V32, P112, DOI 10.1016/j.engappai.2014.03.007
   Tang ZJ, 2016, IEEE T INF FOREN SEC, V11, P200, DOI 10.1109/TIFS.2015.2485163
   Unler A, 2011, INFORM SCIENCES, V181, P4625, DOI 10.1016/j.ins.2010.05.037
   Wang DQ, 2016, NEUROCOMPUTING, V173, P845, DOI 10.1016/j.neucom.2015.08.038
   Wang T, 2012, INFORM SYST, V37, P508, DOI 10.1016/j.is.2011.10.009
   Weinland D, 2007, IEEE I CONF COMP VIS, P170
   You MY, 2012, INT J COMPUT INT SYS, V5, P668, DOI 10.1080/18756891.2012.718113
   Zhang S, 2016, ACM T INTEL IN PRESS
   Zhang SC, 2016, NEUROCOMPUTING, V195, P137, DOI 10.1016/j.neucom.2015.08.115
   Zhang SC, 2012, J SYST SOFTWARE, V85, P2541, DOI 10.1016/j.jss.2012.05.073
   Zhang SC, 2012, J SYST SOFTWARE, V85, P771, DOI 10.1016/j.jss.2011.10.007
   Zheng ZW, 2006, PROCEEDINGS OF THE FIFTH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS, VOLS 1 AND 2, P810
   Zhu PF, 2015, PATTERN RECOGN, V48, P438, DOI 10.1016/j.patcog.2014.08.006
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
   Zhu XF, 2014, NEUROIMAGE, V100, P91, DOI 10.1016/j.neuroimage.2014.05.078
   Zhu XF, 2014, IEEE T IMAGE PROCESS, V23, P3737, DOI 10.1109/TIP.2014.2332764
   Zhu XF, 2013, ACM T INFORM SYST, V31, DOI 10.1145/2457465.2457469
   Zhu XF, 2013, IEEE T MULTIMEDIA, V15, P633, DOI 10.1109/TMM.2012.2233723
   Zhu XF, 2013, PATTERN RECOGN, V46, P215, DOI 10.1016/j.patcog.2012.07.018
   Zhu XF, 2012, PATTERN RECOGN, V45, P3003, DOI 10.1016/j.patcog.2012.02.007
   Zhu XF, 2011, IEEE T KNOWL DATA EN, V23, P110, DOI 10.1109/TKDE.2010.99
   Zhu YY, 2015, IEEE T PATTERN ANAL, V37, P529, DOI 10.1109/TPAMI.2013.2295311
NR 41
TC 15
Z9 16
U1 4
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17479
EP 17495
DI 10.1007/s11042-016-4119-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500033
DA 2024-07-18
ER

PT J
AU Jang, SB
   Kim, YG
   Ko, YW
AF Jang, Sung Bong
   Kim, Young Gab
   Ko, Young-Woong
TI Mobile video communication based on augmented reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile video communication; Augmented reality; 3G-324M; Real-time object
   detection
ID FACE; APPEARANCE
AB Augmented Reality (AR)-based video telephony service can allow mobile users a better user experience (UX) since it allows participants to place and transmit augmented objects on video frames to a peer. However, there are quite a few AR-based mobile video communication models today, yet the existing models are limited and insufficient in supporting technical service such as real-time object detection, dynamic data selection, and discrimination between local data augmentation and remote data augmentation. This paper presents an enhanced AR-based mobile video telephony scheme, in which the object of interest can be dynamically combined with a video frame through real-time object detection, and users can immediately share their experience with their friend during a video call. In order to evaluate the effectiveness and feasibility of the proposed scheme, an application has been implemented on the mobile system and the computational time has been measured. Experimental results show that the proposed system can give customers better UX with small increase of computational time.
C1 [Jang, Sung Bong] Kumoh Natl Inst Technol, Dept Software Engn, Gumi, Gyeong Buk, South Korea.
   [Kim, Young Gab] Sejong Univ, Dept Comp & Informat Secur, 209 Neungdong Ro, Seoul 143747, South Korea.
   [Ko, Young-Woong] Hallym Univ, Dept Comp Engn, 39 HallymDaehakgil, Chunchon 200702, Gangwondo, South Korea.
C3 Kumoh National University Technology; Sejong University; Hallym
   University
RP Ko, YW (corresponding author), Hallym Univ, Dept Comp Engn, 39 HallymDaehakgil, Chunchon 200702, Gangwondo, South Korea.
EM yuko@hallym.ac.kr
RI Kim, Young-Gab/AIE-4008-2022
OI Kim, Young-Gab/0000-0001-9585-8808
FU Research Fund, Kumoh National Institute of Technology
FX This paper was supported by Research Fund, Kumoh National Institute of
   Technology.
CR [Anonymous], 2002, 3261 RFC INT ENG TAS
   [Anonymous], P INT C UT EXH GREEN
   Chillet D, 2011, J SYST ARCHITECT, V57, P340, DOI 10.1016/j.sysarc.2011.01.004
   Duanggate C, 2011, J VIS COMMUN IMAGE R, V22, P345, DOI 10.1016/j.jvcir.2011.02.004
   Dunko GA, 2009, US Patent, Patent No. [20090231413 A1, 20090231413]
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Fukayama A., 2011, 2011 15th International Conference on Intelligence in Next Generation Networks (ICIN): "From Bits to Data, from Pipes to Clouds", P80, DOI 10.1109/ICIN.2011.6081108
   Hu WC, 2012, J VIS COMMUN IMAGE R, V23, P303, DOI 10.1016/j.jvcir.2011.10.008
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Jana S, 2014, IEEE INT CONF SENS, P495, DOI 10.1109/SAHCN.2014.6990388
   Kaur M, 2011, INT J ADV COMPUT SC, V2, P137
   LANITIS A, 1995, IMAGE VISION COMPUT, V13, P393, DOI 10.1016/0262-8856(95)99726-H
   Lee DH, 2007, SECOND WORKSHOP ON DIGITAL MEDIA AND ITS APPLICATION IN MUSEUM & HERITAGE, PROCEEDINGS, P379, DOI 10.1109/DMAMH.2007.57
   Lee DW, 2011, IEICE T INF SYST, VE94D, P1130, DOI 10.1587/transinf.E94.D.1130
   Lin CH, 2010, J VIS COMMUN IMAGE R, V21, P707, DOI 10.1016/j.jvcir.2010.05.005
   McKenna SJ, 1998, PATTERN RECOGN, V31, P1883, DOI 10.1016/S0031-3203(98)00066-1
   Mirzaei MR, 2014, VISUAL COMPUT, V30, P245, DOI 10.1007/s00371-013-0841-1
   Oskiper T, 2015, IEEE T VIS COMPUT GR, V21, P611, DOI 10.1109/TVCG.2015.2408612
   Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310
   Popov A, 2008, P 4 INT C INT SYST, P1233
   Rajagopalan AN, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P640, DOI 10.1109/ICCV.1998.710785
   Schneiderman H, 1998, PROC CVPR IEEE, P45, DOI 10.1109/CVPR.1998.698586
   Sirawongphatsara P, 2015, 2015 INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN), P205, DOI 10.1109/ICOIN.2015.7057883
   Smith JR, 2004, IEEE MULTIMEDIA, V11, P102
   Su GM, 2011, INT J COMMUN SYST, V24, P1261, DOI 10.1002/dac.1190
   Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang DP, 2012, IEEE COMMUN MAG, V50, P26, DOI 10.1109/MCOM.2012.6163579
   Yuan-Chih Yu, 2013, 2013 IEEE International Conference on Green Computing and Communications (GreenCom) and IEEE Internet of Things (iThings) and IEEE Cyber, Physical and Social Computing (CPSCom), P1006, DOI 10.1109/GreenCom-iThings-CPSCom.2013.172
NR 30
TC 4
Z9 4
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 16893
EP 16909
DI 10.1007/s11042-016-3627-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500002
DA 2024-07-18
ER

PT J
AU Hafeezallah, A
   Abu-Bakar, S
AF Hafeezallah, Adel
   Abu-Bakar, Syed
TI Crowd counting using statistical features based on curvelet frame change
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Curvelet transform; Crowd counting; Frame difference; Statistical
   features
ID TEXTURE CLASSIFICATION; RIDGELETS
AB Automatic counting for moving crowds in digital images is an important application in computer artificial intelligence, especially for safety and management purposes. This paper presents a new method to estimate the size of a crowd. The new algorithm depends on sequential frame differences to estimate the crowd size in a scene. However, relying only on these simple differences adds more constraints for extracting sufficient crowd descriptors. A curvelet transform is employed to achieve that goal. Every two sequential frames are transformed into multi-resolution and multi-direction formats, and then the frame differences are detected at every subband in the curvelet domain. Statistical features out of each subband are then calculated, and the collected features from all subbands are considered as a descriptor vector for the crowd in the scene. Finally, a neural network is manipulated to map the descriptor vectors into predicted counts. The experimental results show that the proposed curvelet statistical features are more robust and provide crowd counting with higher accuracy than previous approaches.
C1 [Hafeezallah, Adel; Abu-Bakar, Syed] Univ Teknol Malaysia, Dept Elect & Comp Engn, Johor Baharu, Johor, Malaysia.
   [Hafeezallah, Adel] Taibah Univ, Dept Elect Engn, Madinah, Saudi Arabia.
C3 Universiti Teknologi Malaysia; Taibah University
RP Hafeezallah, A (corresponding author), Univ Teknol Malaysia, Dept Elect & Comp Engn, Johor Baharu, Johor, Malaysia.; Hafeezallah, A (corresponding author), Taibah Univ, Dept Elect Engn, Madinah, Saudi Arabia.
EM cdadel@hotmail.com
RI HafeezAllah, Adel/HPG-8753-2023
OI HafeezAllah, Adel/0000-0002-0057-1706
CR Albiol A., 2009, 3International_Workshop_on Performance_Evaluation_of_Tracking_and_Surveillance, P31
   Ali S., 2013, Modeling, Simulation and Visual Analysis of Crowds, P1, DOI DOI 10.1007/978-1-4614-8483-7
   Allah AAH, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM COMPUTING AND ENGINEERING, P502, DOI 10.1109/ICCSCE.2014.7072770
   [Anonymous], 11 IEEE INT WORKSH P
   [Anonymous], PEOPLE COUNTING DATA
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2013, Modeling, Simulation and Visual Analysis of Crowds: A Multidisciplinary Perspective
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 1997, IEEE C IM PROC SEC A
   [Anonymous], 1995, Wavelets and Operators
   [Anonymous], 2008, IEEE C COMP VIS PATT
   [Anonymous], SAINT MALO P
   [Anonymous], ELECT ELECT ENG
   Arivazhagan S, 2006, INT C PATT RECOG, P938
   Candès EJ, 1999, PHILOS T R SOC A, V357, P2495, DOI 10.1098/rsta.1999.0444
   Candès EJ, 2002, SIGNAL PROCESS, V82, P1519, DOI 10.1016/S0165-1684(02)00300-6
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Conte D., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1743, DOI 10.1109/ICPR.2010.431
   Cord A, 2010, J MICROSC-OXFORD, V239, P159, DOI 10.1111/j.1365-2818.2010.03365.x
   DAVIES AC, 1995, ELECTRON COMMUN ENG, V7, P37, DOI 10.1049/ecej:19950106
   Donoho DL, 2000, SIAM J MATH ANAL, V31, P1062, DOI 10.1137/S0036141098344403
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Kingsbury N, 2001, APPL COMPUT HARMON A, V10, P234, DOI 10.1006/acha.2000.0343
   Kingsbury N, 1999, PHILOS T R SOC A, V357, P2543, DOI 10.1098/rsta.1999.0447
   Kong D, 2006, INT C PATT RECOG, P1187
   Li XH, 2006, T I MEAS CONTROL, V28, P299, DOI 10.1191/0142331206tim178oa
   Liang RH, 2014, NEUROCOMPUTING, V133, P377, DOI 10.1016/j.neucom.2013.12.040
   Ma JW, 2010, IEEE SIGNAL PROC MAG, V27, P118, DOI 10.1109/MSP.2009.935453
   Masoud O, 2001, IEEE T VEH TECHNOL, V50, P1267, DOI 10.1109/25.950328
   Paragios N, 2001, PROC CVPR IEEE, P1034
   Po DDY, 2006, IEEE T IMAGE PROCESS, V15, P1610, DOI 10.1109/TIP.2006.873450
   RODGERS JL, 1988, AM STAT, V42, P59, DOI 10.2307/2685263
   Ryan D, 2015, COMPUT VIS IMAGE UND, V130, P1, DOI 10.1016/j.cviu.2014.07.008
   Ryan D, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P81, DOI 10.1109/DICTA.2009.22
   Shamshiri A, 2013, INT GEOSCI REMOTE SE, P1610, DOI 10.1109/IGARSS.2013.6723099
   Starck JL., 2010, SPARSE IMAGE SIGNAL
   Wakin M, 2003, P SOC PHOTO-OPT INS, V5207, P507, DOI 10.1117/12.506155
   Wenhua Ma, 2008, 2008 Pacific-Asia Workshop on Computational Intelligence and Industrial Application. PACIIA 2008, P958, DOI 10.1109/PACIIA.2008.258
   Yang H., 2011, IEEE INT CON MULTI, P1
NR 40
TC 4
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15777
EP 15799
DI 10.1007/s11042-016-3869-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900025
DA 2024-07-18
ER

PT J
AU Huangpeng, QZ
   Zeng, XR
   Sun, Q
   Fan, J
   Feng, J
   Pan, ZQ
AF Huangpeng, Qizi
   Zeng, Xiangrong
   Sun, Quan
   Fan, Jun
   Feng, Jing
   Pan, Zhengqiang
TI Super-resolving blurry multiframe images through multiframe blind
   deblurring using ADMM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiframe super resolution; Multiframe blind deconvolution;
   Regularization; ADMM
ID HIGH-RESOLUTION IMAGE; SUPERRESOLUTION; RECONSTRUCTION; REGISTRATION;
   RECOVERY; SPARSE
AB Multiframe super resolution (MFSR) aims to reconstruct a high resolution (HR) image from a set of low resolution (LR) images. However, the MFSR is an ill-posed problem and typically computational costly. In this paper, we propose to super-resolve multiple degraded LR frames of the original scene through multiframe blind deblurring (MFDB). First, we propose a new MFSR forward model and reformulate the MFSR problem into a MFDB problem which is easier to be solved than the former. We further solve the MFBD problem in which, the optimization problems with respect to the unknown image and with respect to the unknown blur are efficiently addressed by the alternating direction method of multipliers (ADMM). Our approach bridges the gap between MFSR and MFBD, taking advantages of existing MFBD methods to handle MFSR. Experiments on synthetic andreal images show that the proposed method is competitive and effective in terms of speed and restoratio n quality.
C1 [Huangpeng, Qizi; Zeng, Xiangrong; Sun, Quan; Fan, Jun; Feng, Jing; Pan, Zhengqiang] Natl Univ Def Technol, Coll Informat Syst & Management, Changsha, Hunan, Peoples R China.
C3 National University of Defense Technology - China
RP Huangpeng, QZ (corresponding author), Natl Univ Def Technol, Coll Informat Syst & Management, Changsha, Hunan, Peoples R China.
EM hpqz19911215@163.com
CR Afonso MV, 2010, IEEE T IMAGE PROCESS, V19, P2345, DOI 10.1109/TIP.2010.2047910
   [Anonymous], 2004, DISTINGUISHED DISSER
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], FAST IMAGE DECONVOLU
   Baker Simon., 2007, ICCV
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Carles G, 2014, OPT LETT, V39, P1889, DOI 10.1364/OL.39.001889
   Chaudhuri S., 2001, SUPER RESOLUTION IMA
   Chiang MC, 2000, IMAGE VISION COMPUT, V18, P761, DOI 10.1016/S0262-8856(99)00044-X
   Combettes PL, 2011, SPRINGER SER OPTIM A, V49, P185, DOI 10.1007/978-1-4419-9569-8_10
   Dong WS, 2014, IEEE T IMAGE PROCESS, V23, P4527, DOI 10.1109/TIP.2014.2352497
   Duchi J., 2008, P 25 INT C MACH LEAR, P272
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Ferreira RU, 2015, IEEE INT SYMP CIRC S, P1202, DOI 10.1109/ISCAS.2015.7168855
   Gabay D., 1976, Computers & Mathematics with Applications, V2, P17, DOI 10.1016/0898-1221(76)90003-1
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Hardie RC, 1997, IEEE T IMAGE PROCESS, V6, P1621, DOI 10.1109/83.650116
   He Y, 2007, IEEE T IMAGE PROCESS, V16, P2830, DOI 10.1109/TIP.2007.908074
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Huang T.S., 1984, ADV COMPUTER VISION, V1, P317
   Huangpeng QZ, 2015, PR IEEE I C PROGR IN, P281, DOI 10.1109/PIC.2015.7489854
   Irani M., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P115, DOI 10.1109/ICPR.1990.119340
   Katsaggelos AggelosK., 2007, SUPER RESOLUTION IMA
   Keren D., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P742, DOI 10.1109/CVPR.1988.196317
   KIM SP, 1990, IEEE T ACOUST SPEECH, V38, P1013, DOI 10.1109/29.56062
   Kotera Jan, 2013, Computer Analysis of Images and Patterns. 15th International Conference, CAIP 2013. Proceedings: LNCS 8048, P59, DOI 10.1007/978-3-642-40246-3_8
   Lee ES, 2003, IEEE T IMAGE PROCESS, V12, P826, DOI 10.1109/TIP.2003.811488
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Liu Lixiong., 2014, Sseq software release
   Mitzel D, 2009, LECT NOTES COMPUT SC, V5748, P432, DOI 10.1007/978-3-642-03798-6_44
   Robinson M. D., 2010, Super-Resolution Imaging, P384
   Shen HF, 2007, IEEE T IMAGE PROCESS, V16, P479, DOI 10.1109/TIP.2006.888334
   Sroubek F, BLIND IMAGE DECONVOL, P317
   Sroubek F, 2007, IEEE T IMAGE PROCESS, V16, P2322, DOI 10.1109/TIP.2007.903256
   STARK H, 1989, J OPT SOC AM A, V6, P1715, DOI 10.1364/JOSAA.6.001715
   Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330
   TOM BC, 1994, IEEE IMAGE PROC, P553, DOI 10.1109/ICIP.1994.413745
   Villena S, 2013, DIGIT SIGNAL PROCESS, V23, P530, DOI 10.1016/j.dsp.2012.10.002
   WEDEL A., 2009, ICCV
   Zhao WY, 2002, LECT NOTES COMPUT SC, V2350, P599
NR 40
TC 3
Z9 3
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13563
EP 13579
DI 10.1007/s11042-016-3770-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900029
DA 2024-07-18
ER

PT J
AU Yao, R
   Sun, JL
   Zhou, Y
   Chen, D
AF Yao, Rui
   Sun, Jinliang
   Zhou, Yong
   Chen, Dai
TI Video stitching based on iterative hashing and dynamic seam-line with
   local context
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video stitching; Image registration; Iterative hashing; Dynamic
   seam-line; Local context
AB Video stitching fuses multi-camera videos with differing centers of projection into a single panoramic video. Image registration and video fusion is the key of video stitching. In this paper, a robust and real-time video stitching method based on iterative hashing and best dynamic seam-line with local context model is proposed, which can eliminate ghosting and ensure real-time in video stitching. Firstly, the iterative hashing algorithm is proposed to improve the speed and precision of image registration. Image feature points are matched by constructing a multi-table, extracting candidates and refining candidates with iteration, which enhances the local sensitivity of hashing and speeds up the process of feature points matching. Secondly, the method of finding the best seam-line dynamically and blending with local context is proposed to improve the quality of video fusion. The proposed video fusion method is able to eliminate ghosting and illumination variation during video stitching. In addition, the speed of video stitching can be enhanced. Experimental results on several scenes show the efficiency and effectiveness of the proposed video stitching method.
C1 [Yao, Rui; Sun, Jinliang; Zhou, Yong; Chen, Dai] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Peoples R China.
C3 China University of Mining & Technology
RP Yao, R (corresponding author), China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Peoples R China.
EM ruiyao@cumt.edu.cn; sjl@cumt.edu.cn; yzhou@cumt.edu.cn;
   chend@cumt.edu.cn
FU National Natural Science Foundation of China [61402483, 61572505]; China
   Postdoctoral Science Foundation [2014M551696]; Post-doctoral Science
   Foundation of Jiangsu Province [1402057C]; Prospective Integration of
   Industry, Education and Research Foundation of Jiangsu Province
   [BY2015023-05]
FX The work is partially supported by National Natural Science Foundation
   of China (Grant No. 61402483, 61572505), China Postdoctoral Science
   Foundation (Grant No. 2014M551696), Post-doctoral Science Foundation of
   Jiangsu Province (Grant No. 1402057C), and the Prospective Integration
   of Industry, Education and Research Foundation of Jiangsu Province
   (Grant No. BY2015023-05).
CR [Anonymous], PROC CVPR IEEE
   [Anonymous], 2009, NIPS
   [Anonymous], INT C MACH LEARN
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Cui JT, 2010, PATTERN RECOGN LETT, V31, P1740, DOI 10.1016/j.patrec.2010.05.026
   Duplaquet ML, 1998, P SOC PHOTO-OPT INS, V3387, P369, DOI 10.1117/12.316427
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Ivanov Y, 2000, INT J COMPUT VISION, V37, P199, DOI 10.1023/A:1008107805263
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Moran S, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P1009
   Mu YD, 2010, PROC CVPR IEEE, P3344, DOI 10.1109/CVPR.2010.5540024
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Pan J., 2011, Proceedings of the 19th ACM SIGSPATIAL Interna- tional Conference on Advances in Geographic Information Systems, P211
   Pan P, 2011, US Patent, Patent No. [7,978, 931, 7978931]
   Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006
   Slaney M, 2008, IEEE SIGNAL PROC MAG, V25, P128, DOI 10.1109/MSP.2007.914237
   Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103
   Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Weiss Yair, 2009, Advances in Neural Information Processing Systems, P1753, DOI DOI 10.5555/2981780.2981999
   Xu Wang, 2012, THESIS
   Xu W, 2010, PROC CVPR IEEE, P263, DOI 10.1109/CVPR.2010.5540202
   Zaragoza J, 2014, IEEE T PATTERN ANAL, V36, P1285, DOI 10.1109/TPAMI.2013.247
   Zeng YY, 2009, ICWMC: 2009 FIFTH INTERNATIONAL CONFERENCE ON WIRELESS AND MOBILE COMMUNICATIONS, P1, DOI 10.1109/ICWMC.2009.8
   Zhang F, 2014, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2014.423
NR 29
TC 5
Z9 5
U1 2
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13615
EP 13631
DI 10.1007/s11042-016-3738-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900032
DA 2024-07-18
ER

PT J
AU Zhao, H
   Chen, YF
   Wang, R
   Malik, H
AF Zhao, Hong
   Chen, Yifan
   Wang, Rui
   Malik, Hafiz
TI Audio splicing detection and localization using environmental signature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio forensics; Acoustic environmental signature; Splicing detection
ID REVERBERATION MODEL; IDENTIFICATION; ENHANCEMENT; NOISE
AB Audio splicing is one of the most common manipulation techniques in the area of audio forensics. In this paper, the magnitudes of acoustic channel impulse response and ambient noise are proposed as the environmental signature. Specifically, the spliced audio segments are detected according to the magnitude correlation between the query frames and reference frames via a statically optimal threshold. The detection accuracy is further refined by comparing the adjacent frames. The effectiveness of the proposed method is tested on two data sets. One is generated from TIMIT database, the second is made in four acoustic environments using a commercial grade microphones. Experimental results show that the proposed method not only detects the presence of spliced frames, but also localizes the forgery segments with near perfect accuracy. Comparison results illustrate that the identification accuracy of the proposed scheme is higher than the previous schemes. In addition, experimental results also show that the proposed scheme is also superior to the previous works. A real-world meeting recording database (AMI corpus) is also used to verify the effectiveness of the proposed method for practical applications.
C1 [Zhao, Hong; Chen, Yifan; Wang, Rui] South Univ Sci & Technol China, Dept Elect & Elect Engn, Shenzhen 518055, Guangdong, Peoples R China.
   [Malik, Hafiz] Univ Michigan, Dept Elect & Comp Engn, Dearborn, MI 48128 USA.
C3 Southern University of Science & Technology; University of Michigan
   System; University of Michigan
RP Zhao, H (corresponding author), South Univ Sci & Technol China, Dept Elect & Elect Engn, Shenzhen 518055, Guangdong, Peoples R China.
EM zh1985444@gmail.com; chen.yf@sustc.edu.cn; wang.r@sustc.edu.cn;
   hafiz@umich.edu
RI chen, ye Xiao/HSF-9650-2023; Chen, Yi/HIR-2608-2022; Chen,
   Yi/HPD-0595-2023; Malik, Hafiz/AAE-6141-2020; Chen, yf/JMR-4435-2023;
   Chen, Yuxuan/IWL-8267-2023; ruirui, WANG/KCY-0880-2024; Wang,
   Rui/A-2043-2013; Chen, Yi/JBR-7728-2023
OI Wang, Rui/0000-0003-0044-8932; Malik, Hafiz/0000-0001-6006-3888
FU National Natural Science Foundation of China [61402219]; Guangdong
   Natural Science Funds for Distinguished Young Scholar [S2013050014223];
   King Saud University [12-INF2634-02]; National Science Foundation
   [CNS-1440929]
FX This work is supported by the National Natural Science Foundation of
   China (Grant No. 61402219), 2013 Guangdong Natural Science Funds for
   Distinguished Young Scholar (S2013050014223), the NPST program by the
   King Saud University under grant number 12-INF2634-02 and a grant from
   the National Science Foundation (CNS-1440929).
CR Borgström BJ, 2012, INT CONF ACOUST SPEE, P4065, DOI 10.1109/ICASSP.2012.6288811
   Brixen E, 2009, P AUD ENG SOC 126 CO
   Cheng JT, 2013, KEY ENG MATER, V567, P149, DOI 10.4028/www.scientific.net/KEM.567.149
   Cooper A. J., 2010, P AES INT C AUD FOR
   Doclo S., 2001, International Workshop on Acoustic Echo and Noise Control, P31
   Dominguez-Molina J.A., 2001, A practical procedure to estimate the shape parameter in the generalized Gaussian distribution
   Garg R, 2013, INT CONF ACOUST SPEE, P2862, DOI 10.1109/ICASSP.2013.6638180
   Garofolo John, 1993, TIMIT ACOUSTIC PHONE
   Gaubitch ND, 2013, IEEE T AUDIO SPEECH, V21, P2162, DOI 10.1109/TASL.2013.2270406
   Grigoras, 2010, P AUD ENG SOC 39 C A, P27
   Hajj-Ahmad A, 2013, IEEE SIGNAL PROC LET, V20, P883, DOI 10.1109/LSP.2013.2272523
   Ikram S, 2012, P 46 INT C AUD FOR
   Koenig BE, 2007, J AUDIO ENG SOC, V55, P352
   Korycki R, 2013, FORENSIC SCI INT, V230, P117, DOI 10.1016/j.forsciint.2013.02.020
   Kotz S., 2000, Extreme Value Distributions: Theory and Applications
   Lehmann EA, 2008, J ACOUST SOC AM, V124, P269, DOI 10.1121/1.2936367
   Lehmann EA, 2010, IEEE T AUDIO SPEECH, V18, P1429, DOI 10.1109/TASL.2009.2035038
   Liu QZ, 2010, COGN COMPUT, V2, P291, DOI 10.1007/s12559-010-9045-4
   Malik H, 2012, P AES 46 C AUD FOR
   Malik H, 2013, IEEE T INF FOREN SEC, V8, P1827, DOI 10.1109/TIFS.2013.2280888
   Malik H, 2012, INT CONF ACOUST SPEE, P1833, DOI 10.1109/ICASSP.2012.6288258
   Malik H, 2010, INT CONF ACOUST SPEE, P1710, DOI 10.1109/ICASSP.2010.5495479
   Pan XY, 2012, INT CONF ACOUST SPEE, P1841, DOI 10.1109/ICASSP.2012.6288260
   Panagakis Y, 2012, IEEE INT WORKS INFOR, P73, DOI 10.1109/WIFS.2012.6412628
   Qiao M., 2013, Signal Processing, Communication and Computing (ICSPCC), 2013 IEEE International Conference on, P1
   Sehr A, 2010, IEEE T AUDIO SPEECH, V18, P1676, DOI 10.1109/TASL.2010.2050511
   Su H, 2013, INT CONF ACOUST SPEE, P3018, DOI 10.1109/ICASSP.2013.6638212
   Wölfel M, 2009, IEEE T AUDIO SPEECH, V17, P312, DOI 10.1109/TASL.2008.2009161
   Zhao H, 2013, IEEE T INF FOREN SEC, V8, P1746, DOI 10.1109/TIFS.2013.2278843
   Zhao H, 2012, 2012 IEEE STATISTICAL SIGNAL PROCESSING WORKSHOP (SSP), P373, DOI 10.1109/SSP.2012.6319707
NR 30
TC 20
Z9 21
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 13897
EP 13927
DI 10.1007/s11042-016-3758-7
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800010
DA 2024-07-18
ER

PT J
AU Kim, B
   Ryu, S
   Lee, GG
AF Kim, Byeongchang
   Ryu, Seonghan
   Lee, Gary Geunbae
TI Two-stage multi-intent detection for spoken language understanding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spoken dialog system; Spoken language understanding; Multi-intent
   detection
ID DIALOG; MANAGEMENT
AB This paper presents a system to detect multiple intents (MIs) in an input sentence when only single-intent (SI)-labeled training data are available. To solve the problem, this paper categorizes input sentences into three types and uses a two-stage approach in which each stage attempts to detect MIs in different types of sentences. In the first stage, the system generates MI hypotheses based on conjunctions in the input sentence, then evaluates the hypotheses and then selects the best one that satisfies specified conditions. In the second stage, the system applies sequence labeling to mark intents on the input sentence. The sequence labeling model is trained based on SI-labeled training data. In experiments, the proposed two-stage MI detection method reduced errors for written and spoken input by 20.54 and 17.34 % respectively.
C1 [Kim, Byeongchang] Catholic Univ Daegu, Gyongsan, Gyeongbuk, South Korea.
   [Ryu, Seonghan; Lee, Gary Geunbae] Pohang Univ Sci & Technol, Pohang, South Korea.
C3 Catholic University of Daegu; Pohang University of Science & Technology
   (POSTECH)
RP Kim, B (corresponding author), Catholic Univ Daegu, Gyongsan, Gyeongbuk, South Korea.
EM bckim@cu.ac.kr; ryush@postech.ac.kr; gblee@postech.ac.kr
FU ATC(Advanced Technology Center) Program - "Development of Conversational
   Q&A Search Framework Based On Linked Data" [10048448]
FX This paper is supported by ATC(Advanced Technology Center) Program -
   "Development of Conversational Q&A Search Framework Based On Linked
   Data: Project No. 10048448"
CR [Anonymous], THESIS
   한동조, 2007, [The Journal of The Korea Institute of Intelligent Transportation Systems, 한국ITS학회 논문지], V6, P77
   Elmir Y, 2014, J INF PROCESS SYST, V10, P555, DOI 10.3745/JIPS.02.0007
   Hakkani-Tur D, 2012, P INTERSPEECH
   Lafferty J., 2001, CONDITIONAL RANDOM F
   Lee C., 2010, J COMPUTING SCI ENG, V4, P1, DOI DOI 10.5626/JCSE.2010.4.1.001
   Lee C, 2010, COMPUT SPEECH LANG, V24, P609, DOI 10.1016/j.csl.2009.08.003
   Liu J, 2011, P ICASSP
   Liu J, 2013, P ASRU
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Noh H, 2012, IEEE J-STSP, V6, P943, DOI 10.1109/JSTSP.2012.2229692
   O'Neill I, 2005, SCI COMPUT PROGRAM, V54, P99, DOI 10.1016/j.scico.2004.05.006
   Ram VS, 2008, P CICLING
   ROARK B, 2006, P ICASSP
   Rosenfeld R, 1996, COMPUT SPEECH LANG, V10, P187, DOI 10.1006/csla.1996.0011
   Sang EFTK, 2001, P CONLL
   Seo H., 2013, THESIS
   Vanus J, 2015, HUM-CENT COMPUT INFO, V5, DOI 10.1186/s13673-015-0035-0
   Verma P, 2013, INF SCI, V3, P21
   Walker D, 2001, P MT SUMM
   Williams JD, 2007, IEEE T AUDIO SPEECH, V15, P2116, DOI 10.1109/TASL.2007.902050
   Wu J., 2002, THESIS THESIS
   Xy P, 2013, P INTERSPEECH
   Yang ZJ, 2012, IEEE J-STSP, V6, P971, DOI 10.1109/JSTSP.2012.2229965
NR 24
TC 21
Z9 24
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11377
EP 11390
DI 10.1007/s11042-016-3724-4
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000015
DA 2024-07-18
ER

PT J
AU Liu, TH
   Yin, SL
AF Liu, Tianhua
   Yin, Shoulin
TI An improved particle swarm optimization algorithm used for BP neural
   network and multimedia course-ware evaluation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE BP neural network; PSO; Adaptive acceleration factor; Adaptive inertia
   weight; Multimedia evaluation model
AB The original BP neural network has some disadvantages, such as slow convergence speed, low precision, which is easy to fall into local minimum value. So this paper proposes an improved particle swarm optimization (PSO) algorithm to optimize BP neural network. In this new algorithm, PSO uses improved adaptive acceleration factor and improved adaptive inertia weight to improve the initial weight value and threshold value of BP neural network. And we give the detailed improved process. At the end, simulation results show that the new algorithm can improve convergence rate and precision of prediction of BP neural network, which reduces the error of prediction. At the end, we use multimedia evaluation model to verify the new method's performance.
C1 [Liu, Tianhua; Yin, Shoulin] Shenyang Normal Univ, Software Coll, 253 HuangHe Bei St, Shenyang 110034, Peoples R China.
C3 Shenyang Normal University
RP Yin, SL (corresponding author), Shenyang Normal Univ, Software Coll, 253 HuangHe Bei St, Shenyang 110034, Peoples R China.
EM liutianhua@sina.com; 352720214@qq.com
RI Yin, Shoulin/AAQ-6430-2021; liu, th/KBQ-0635-2024; Yin,
   Shoulin/IZE-4876-2023
OI Yin, Shoulin/0000-0002-5367-1372; 
FU National Nature Science Foundation of China [6097011]; Software College
   Shenyang Normal University, Government of China
FX Foundation item: The National Nature Science Foundation of China (No.:
   6097011). Authors are grateful to the Software College Shenyang Normal
   University, Government of China for financial support to carry out this
   work.
CR Chatzinakos C, 2015, SIMUL MODEL PRACT TH, V51, P149, DOI 10.1016/j.simpat.2014.11.005
   Du W., 2015, INT C AUT MECH CONTR
   Han L, 2015, RENEW ENERG, V81, P737, DOI 10.1016/j.renene.2015.03.037
   Jiang Y.L., 2014, VIBRO ENG PROCEDIA, V4, P211
   Kun She, 2015, Applied Mechanics and Materials, V734, P548, DOI 10.4028/www.scientific.net/AMM.734.548
   Liu B, 2015, 2015 INT S COMP INF
   Liu JK, 2014, CHIN CONTR CONF, P8764, DOI 10.1109/ChiCC.2014.6896473
   Tang XL, 2014, INT T ELECTR ENERGY, V24, P609, DOI 10.1002/etep.1717
   Wan L, 2015, ANALYSIS, V5, P6
   Wang MH, 2014, ENERGIES, V7, P6340, DOI 10.3390/en7106340
   Wang Z, 2014, T COMPUTER SCI TECHN, V3
   Yoshida H, 2015, FRONT ARTIF INTEL AP, V276, P224, DOI 10.3233/978-1-61499-522-7-224
   Zhang YX, 2015, J MANUF SYST, V34, P53, DOI 10.1016/j.jmsy.2014.10.005
NR 13
TC 63
Z9 66
U1 3
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11961
EP 11974
DI 10.1007/s11042-016-3776-5
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000045
OA hybrid
DA 2024-07-18
ER

PT J
AU Sim, S
   Cho, S
   Song, W
   Fong, S
   Park, YW
   Cho, K
AF Sim, Sohyun
   Cho, Seoungjae
   Song, Wei
   Fong, Simon
   Park, Yong Woon
   Cho, Kyungeun
TI Development of simulator for invoked reality environmental design
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Invoked reality; Natural user interface; Virtual simulation
AB Invoked Reality (IR) research uses a variety of sensors and projection equipment for Natural User Interface (NUI) interaction. Such equipment requires an appropriate action region, which needs to be considered when implementing an IR environment. Accordingly, the implementation of an IR environment is problematic because of the arrangement of this equipment. The research presented in this paper overcomes this difficulty by proposing the "IR Simulator." This simulator facilitates the design of and experimentation within the IR environment in a virtual environment. IR Simulator comprises an "experimental space editor" and "simulation manager." IR Simulator enables design in diverse kinds of IR environments using its GUI-based experimental space editor. It also provides interaction with external IR libraries through the external IR library-interworking interface. Moreover, it enables simulation on the library connected on the basis of the virtual sensor data generated by the implementation of the proposed simulator. In accordance with experiments using the proposed simulator, a variety of IR environments could be generated and an arm motion recognition library could be simulated. Furthermore, the same environment generated by the simulator was easily implemented in the actual environment on the basis of the design results from the simulator. The experiment on the arm motion recognition library used in the simulator in the real environment was similar to the results obtained by the simulation.
C1 [Sim, Sohyun; Cho, Seoungjae; Cho, Kyungeun] Dongguk Univ Seoul, Dept Multimedia Engn, Seoul, South Korea.
   [Song, Wei] North China Univ Technol, Dept Digital Media Technol, Coll Informat Engn, Beijing, Peoples R China.
   [Fong, Simon] Univ Macau, Dept Comp & Informat Sci, Macau, Peoples R China.
   [Park, Yong Woon] Agcy Def Dev, Unmanned Technol Directorate, Daejeon, South Korea.
C3 Dongguk University; North China University of Technology; University of
   Macau; Agency of Defense Development (ADD), Republic of Korea
RP Cho, K (corresponding author), Dongguk Univ Seoul, Dept Multimedia Engn, Seoul, South Korea.
EM cke@dongguk.edu
RI Fong, Simon/C-9388-2009
FU MSIP(Ministry of Science, ICT and Future Planning), Korea, under the
   ITRC(Information Technology Research Center) [IITP-2016-H8501-16-1014]
FX This research was supported by the MSIP(Ministry of Science, ICT and
   Future Planning), Korea, under the ITRC(Information Technology Research
   Center) support program (IITP-2016-H8501-16-1014) supervised by the
   IITP(Institute for Information & communications Technology Promotion).
CR [Anonymous], J CONVERGE
   [Anonymous], 2013, P SIGCHI C HUMAN FAC, DOI DOI 10.1145/2470654.2466112
   [Anonymous], 2011, P VIRT REAL INT C
   Armac I, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE SERVICES, P257
   Benko H., 2010, ACM International Conference on Interactive Tabletops and Surfaces, P19, DOI DOI 10.1145/1936652.1936657
   Benko Hrvoje., 2012, P SIGCHI C HUMAN FAC, P199, DOI DOI 10.1145/2207676.2207704
   Blanco-Gonzalo R, 2015, HUM-CENT COMPUT INFO, V5, DOI 10.1186/s13673-015-0043-0
   Gao Y, 2015, J INF PROCESS SYST, V11, P643, DOI 10.3745/JIPS.02.0027
   Ghimire D, 2013, J INF PROCESS SYST, V9, P141, DOI 10.3745/JIPS.2013.9.1.141
   Helal A, 2009, IEEE SYMP COMP COMMU, P920, DOI 10.1109/ISCC.2009.5202263
   나민영, 2012, [The Journal of Korean Institute of Next Generation Computing, 한국차세대컴퓨팅학회 논문지], V8, P27
   Marner MR, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P155, DOI 10.1109/3DUI.2013.6550225
   Mistry P., 2009, SIGGRAPH ASIA Art Gallery Emerging Technologies, page, P85, DOI [10.1145/1667146.1667160, DOI 10.1145/1667146.1667160]
   Sunyoung Cho, 2012, Journal of KIISE: Software and Applications, V39, P796
   Van Krevelen D. W. F., 2010, INT J VIRTUAL REALIT, V9, P1, DOI 10/ggxxt5
   Wilson Andrew D., 2007, Proceedings Graphics Interface 2007, P119, DOI 10.1145/1268517.1268539
   Wilson A.D., 2010, Proc. UIST, P273
   Wilson AD, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P413
   Xi Y, 2014, 6 FTRA INT C COMP SC, P20
   Xiao R., 2013, P SIGCHI C HUM FACT, P879, DOI DOI 10.1145/2470654.2466113
NR 20
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11407
EP 11428
DI 10.1007/s11042-016-4116-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000017
DA 2024-07-18
ER

PT J
AU Aminikhanghahi, S
   Shin, S
   Wang, W
   Jeon, SI
   Son, SH
AF Aminikhanghahi, Samaneh
   Shin, Sung
   Wang, Wei
   Jeon, Soon I.
   Son, Seong H.
TI A new fuzzy Gaussian mixture model (FGMM) based algorithm for
   mammography tumor image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fuzzy; Gaussian mixture model; Mammography; Classification
ID COMPUTER-AIDED DIAGNOSIS; SYSTEM
AB Computer aided diagnosis systems are recently introduced to increase the accuracy of mammography interpretation. This paper introduces a new classification algorithm based on Fuzzy Gaussian Mixture Model (FGMM) by combining the power of Gaussian Mixture Model (GMM) and Fuzzy Logic System (FLS) for computer aided diagnosis system, to classify the detected regions in mammogram images into malignant or benign categories. The experimental results are obtained from a data set of 300 images taken from the Digital Database for Screening Mammography (DDSM, University of South Florida) for different classes. Confusion matrix analysis is used to measure the performance of the proposed FGMM system. The results show that the proposed FGMM classifier has achieved an overall Matthews Correlation Coefficient (MCC) classification quality of 86.16 %, with 93 % accuracy, 90 % sensitivity and 96 % specificity, and outperformed other classifiers in all aspects. The experimental results obtained from the developed classifier prove that the proposed technique will improve the diagnostic accuracy and reliability of radiologists' image interpretation in the diagnosis of breast cancer. The resulting breast cancer Computer Aided Diagnosis (CAD) detection system is a promising tool to provide preliminary decision support information to physicians for further diagnosis.
C1 [Aminikhanghahi, Samaneh; Shin, Sung] South Dakota State Univ, Dept Elect Engn & Comp Sci, Brookings, SD 57006 USA.
   [Wang, Wei] San Diego State Univ, Dept Comp Sci, San Diego, CA 92182 USA.
   [Jeon, Soon I.; Son, Seong H.] ETRI, Daejeon 305700, South Korea.
C3 South Dakota State University; California State University System; San
   Diego State University; Electronics & Telecommunications Research
   Institute - Korea (ETRI)
RP Shin, S (corresponding author), South Dakota State Univ, Dept Elect Engn & Comp Sci, Brookings, SD 57006 USA.
EM Sung.Shin@sdstate.edu
OI Son, Seong-Ho/0000-0003-1343-1806; Aminikhanghahi,
   Samaneh/0000-0002-0670-8996
FU ICT R&D program of MSIP/IITP [11-911-01-108]
FX This work was supported by ICT R&D program of MSIP/IITP. [11-911-01-108,
   Development of Precision MT System].
CR Abdel-Qader I, 2008, MODELING SIMULATION, P1
   Aminikhanghahi S, 2015, RACS
   [Anonymous], 2008, 2008 NAT RAD SCI C, DOI DOI 10.1109/NRSC.2008.4542383
   Cheng HD, 2006, PATTERN RECOGN, V39, P646, DOI 10.1016/j.patcog.2005.07.006
   Deserno TM, 2012, PROC SPIE, V8315, DOI 10.1117/12.912392
   Doi K, 2005, BRIT J RADIOL, V78, pS3, DOI 10.1259/bjr/82933343
   Doi K, 2007, COMPUT MED IMAG GRAP, V31, P198, DOI 10.1016/j.compmedimag.2007.02.002
   Elfarra B.K., 2012, INT J SIGNAL PROCESS, V5
   de Oliveira JEE, 2011, WORLD J RADIOL, V3, P24, DOI 10.4329/wjr.v3.i1.24
   Giulia Rabottino AM, 2008, IMEKO TC 4 INT S
   Görgel P, 2015, EXPERT SYST, V32, P155, DOI 10.1111/exsy.12073
   Heath M, 2000, MED PHYS
   Jain R., 2004, Australasian Physical & Engineering Sciences in Medicine, V27, P213, DOI 10.1007/BF03178651
   Lee KJ, 2012, MON NOT R ASTRON SOC, V424, P2832, DOI 10.1111/j.1365-2966.2012.21413.x
   Masala GL, 2008, WORLD ACAD SCI ENG T, V2
   Ming Zhang, 2011, Proceedings of the 2011 3rd International Conference on Advanced Computer Control (ICACC 2011), P214, DOI 10.1109/ICACC.2011.6016400
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Nie LQ, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1245, DOI 10.1145/2600428.2611176
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P396, DOI 10.1109/TKDE.2014.2330813
   Oliver A, 2012, KNOWL-BASED SYST, V28, P68, DOI 10.1016/j.knosys.2011.11.021
   Polat K, 2007, DIGIT SIGNAL PROCESS, V17, P694, DOI 10.1016/j.dsp.2006.10.008
   Press W. H., 2007, NUM REC ART SCI COMP
   Rejani Y.I.A., 2009, International Journal on Computer Science and Engineering, V1, P127, DOI DOI 10.48550/ARXIV.0912.2314
   Sampat MP, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, P1195, DOI 10.1016/B978-012119792-6/50130-3
   Schaefer G, 2009, PATTERN RECOGN, V42, P1133, DOI 10.1016/j.patcog.2008.08.007
   Sharma S, 2015, J DIGIT IMAGING, V28, P77, DOI 10.1007/s10278-014-9719-7
   Subashini TS, 2010, COMPUT VIS IMAGE UND, V114, P33, DOI 10.1016/j.cviu.2009.09.009
   Suzuki K, 2012, QUANT IMAG MED SURG, V2, P163, DOI 10.3978/j.issn.2223-4292.2012.09.02
   Tang JS, 2009, IEEE T INF TECHNOL B, V13, P236, DOI 10.1109/TITB.2008.2009441
   U. F. and D. A. (FDA), 2013, SUMM SAF EFF DAT SSE
   U. F. and D. A. (FDA), 2012, SUMM SAF EFF DAT SSE
   Verma B, 2001, IEEE T INF TECHNOL B, V5, P46, DOI 10.1109/4233.908389
   Wadhwani M., 2013, Eng. Sci. Technol, V1, P85
   WINSBERG F, 1967, RADIOLOGY, V89, P211, DOI 10.1148/89.2.211
   Yu SY, 2000, IEEE T MED IMAGING, V19, P115, DOI 10.1109/42.836371
   Zhiyong Li, 2013, 2013 International Conference on Optoelectronics and Microelectronics (ICOM), P177, DOI 10.1109/ICoOM.2013.6626521
NR 37
TC 32
Z9 32
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 10191
EP 10205
DI 10.1007/s11042-016-3605-x
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300050
DA 2024-07-18
ER

PT J
AU Santacruz, JL
   Tardón, LJ
   Barbancho, I
   Barbancho, AM
   Molina, E
AF Santacruz, Jose L.
   Tardon, Lorenzo J.
   Barbancho, Isabel
   Barbancho, Ana M.
   Molina, Emilio
TI VOICE2TUBA: transforming singing voice into a musical instrument
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Voice transformation; Sound synthesis; Music application
ID TRANSCRIPTION
AB In this paper, a scheme to synthesize and convert singing voice into tuba sound is presented. First, our method estimates the fundamental frequency (F (0)) and the aperiodicity of a monophonic audio signal, in order to obtain the pitch and volume variations of human voice. Then, the parameters extracted are used to generate a musical excerpt emulating a certain musical instrument (tuba) in such a way that the melody resembles the original sung song. To this end, two different generation approaches are devised. One of them is based on additive signal synthesis from harmonic amplitudes. The other one converts the F (0) curve into a MIDI stream, in order to allow the play back with a virtual tuba.
C1 [Santacruz, Jose L.; Tardon, Lorenzo J.; Barbancho, Isabel; Barbancho, Ana M.; Molina, Emilio] Univ Malaga, ATIC Res Grp, Andalucia Tech, ETSI Telecomunicac,Dept Ingn Comunicac, Campus Univ Teatinos S-N, E-29071 Malaga, Spain.
C3 Universidad de Malaga
RP Barbancho, AM (corresponding author), Univ Malaga, ATIC Res Grp, Andalucia Tech, ETSI Telecomunicac,Dept Ingn Comunicac, Campus Univ Teatinos S-N, E-29071 Malaga, Spain.
EM abp@ic.uma.es
RI Tardon, Lorenzo J./M-4492-2014; Barbancho, Isabel/L-7244-2014
OI Tardon, Lorenzo J./0000-0002-5441-225X; Barbancho,
   Isabel/0000-0001-7002-9106; Santacruz, Jose L./0000-0003-0038-289X
FU Ministerio de Economia y Competitividad of the Spanish Government
   [TIN2013-47276-C6-2-R]
FX This work has been funded by the Ministerio de Economia y Competitividad
   of the Spanish Government under Project No. TIN2013-47276-C6-2-R. This
   work has been done at Universidad de Malaga, Campus de Excelencia
   Internacional (CEI) Andalucia TECH.
CR Bonada J, 2011, DAFX DIGITAL AUDIO E, P393
   de Cheveigné A, 2002, J ACOUST SOC AM, V111, P1917, DOI 10.1121/1.1458024
   Dittmar C, 2011, LECT NOTES COMPUT SC, V6684, P259, DOI 10.1007/978-3-642-23126-1_17
   Downie JS, 2013, MIREX CONTEST
   Haus G, 2011, 2 ANN INT SOC MUS IN, P65
   Horner A, 1998, J AUDIO ENG SOC, V46, P868
   Horner A, 2002, COOKING CSOUND 1
   Howard David M, 2004, Logoped Phoniatr Vocol, V29, P135, DOI 10.1080/14015430410000728
   Krige W, 2008, J NEW MUSIC RES, V37, P311, DOI 10.1080/09298210902890299
   Lesaffre M., 2004, P 5 INT C MUSIC INFO, P64
   Mayor O., 2009, P 35 AES C AUD GAM, P1
   Mayor O, 2011, P 41 AES C AUD GAM, P1
   Molina E, 2015, IEEE-ACM T AUDIO SPE, V23, P252, DOI 10.1109/TASLP.2014.2331102
   Molina Emilio, 2014, P 15 INT SOC MUS INF, P567
   MOORER JA, 1977, P IEEE, V65, P1108, DOI 10.1109/PROC.1977.10660
   Poliner GE, 2007, IEEE T AUDIO SPEECH, V15, P1247, DOI 10.1109/TASL.2006.889797
   Risset J.-C., 1999, PSYCHOL MUSIC, P113, DOI [10.1016/B978-012213564-4/50006-8, DOI 10.1016/B978-012213564-4/50006-8]
   Ryynanen M., 2006, SIGNAL PROCESSING ME, P361
   Salamon J, 2013, INT J MULTIMED INF R, V2, P45, DOI 10.1007/s13735-012-0026-0
   Schafer RW, 1990, DIGITAL REPRESENTATI, P49
   Schutte K, 2012, MIDI TOOLKIT MATLAB
   Serra X, 1997, MUSICAL SIGNAL PROCE, P1
   Stylianou Y, 2009, INT CONF ACOUST SPEE, P3585, DOI 10.1109/ICASSP.2009.4960401
   Viitaniemi T., 2003, PROC FINNISH SIGNAL, P5963
NR 24
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9855
EP 9875
DI 10.1007/s11042-016-3582-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300033
DA 2024-07-18
ER

PT J
AU Zhang, CY
   Wang, XY
   Feng, J
   Cheng, Y
   Guo, C
AF Zhang, Changyou
   Wang, Xiaoya
   Feng, Jun
   Cheng, Yu
   Guo, Cheng
TI A car-face region-based image retrieval method with attention of SIFT
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Car-face image; Region-based retrieval; Attention; SIFT features;
   Similarity
ID VISUAL-ATTENTION; ALGORITHM
AB A traffic still image captured by the high-definition camera located in traffic block port often contains several vehicles. It provides an important clue to solve vehicle crime cases to retrieve all these images that contain the given type of car. To enhance the performance of image retrieval, we proposed a car-face region-based image retrieval method with the attention of SIFT features. In our method, the first step is to find all the car-face regions from an original traffic image, and this original image is represented as a set of car-face regions. Secondly, a similarity measure metrics is proposed with a light intense training of the attention value of SIFT key points on a very small identified images set. Finally, according to the similarity between the input region and the target region, all the images with at least one similar region are retrieved. We carry out this method on a training set of 100 positive car-face region-images. Compared with the famous training-based SVM method, our method achieved higher precision at the same recall with lower training intensity.
C1 [Zhang, Changyou] Chinese Acad Sci, Inst Software, Lab Parallel Software & Computat Sci, Beijing 100190, Peoples R China.
   [Zhang, Changyou; Wang, Xiaoya; Feng, Jun] Shijiazhuang Tiedao Univ, Sch Infomat Sci & Technol, Shijiazhuang 050043, Peoples R China.
   [Cheng, Yu] Hebei Acad Sci, Inst Appl Math, Shijiazhuang 050081, Peoples R China.
   [Guo, Cheng] Yunnan Power Grid Co Ltd, Yunnan Elect Power Res Inst, Kunming 650217, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Software, CAS; Shijiazhuang
   Tiedao University; Hebei Academy of Sciences; China Southern Power Grid
RP Zhang, CY (corresponding author), Chinese Acad Sci, Inst Software, Lab Parallel Software & Computat Sci, Beijing 100190, Peoples R China.; Zhang, CY (corresponding author), Shijiazhuang Tiedao Univ, Sch Infomat Sci & Technol, Shijiazhuang 050043, Peoples R China.
EM changyou@iscas.ac.cn
FU Natural Science Foundation of China [61379048]; Hebei Province Natural
   Science Foundation [F2013210109]
FX This paper is supported by the Natural Science Foundation of China
   (61379048), Hebei Province Natural Science Foundation (F2013210109).
   Special Project of National CAS Union - "The High Performance Cloud
   Service Platform for Enterprise Creative Computing", Special Project of
   National CAS Union - "Car Image Retrieval on Many-core platforms",
   Project of "Research and development of data mining technology in the
   operation of the wind turbine". The authors also would like to express
   appreciation to the anonymous reviewers for their helpful comments on
   improving the paper.
CR Bagarinao E, 2010, LECT NOTES COMPUT SC, V5996, P363
   Budiharto W, 2014, INT C ADV MECH SYST, P448, DOI 10.1109/ICAMechS.2014.6911587
   Chen ZZ, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTELLIGENT SYSTEMS, PROCEEDINGS, VOL 4, P214, DOI 10.1109/ICICISYS.2009.5357707
   Feng SH, 2005, LECT NOTES COMPUT SC, V3708, P235
   Ferencz A, 2005, IEEE I CONF COMP VIS, P286
   Gao H., 2013, 2013 9th Asian Control Conference, P1
   GEVERS T, 1997, P INT C VIS INF SYST, P93
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   [华莉琴 Hua Liqin], 2013, [西安交通大学学报. 自然科学版, Journal of Xi'an Jiaotong University. Natural Science Edition], V47, P92
   [黄凯奇 Huang Kaiqi], 2014, [计算机学报, Chinese Journal of Computers], V37, P1225
   Huang W, 2010, J SIGNAL PROCESS SYS, V59, P143, DOI 10.1007/s11265-008-0294-3
   Inoue M., 2004, P ACM SIGIR WORKSHOP, P44
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Jang D.M., 2011, IEEE WORKSHOP APPL C, P599
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu Jian-wei, 2014, Application Research of Computers, V31, P1921, DOI 10.3969/j.issn.1001-3695.2014.07.001
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manipoonchelvi P, 2015, SIGNAL IMAGE VIDEO P, V9, P1795, DOI 10.1007/s11760-014-0657-0
   Miao QG, 2011, OPT COMMUN, V284, P1540, DOI 10.1016/j.optcom.2010.11.048
   Miao QG, 2016, IEEE T NEUR NET LEAR, V27, P2216, DOI 10.1109/TNNLS.2015.2475750
   Miao QG, 2013, IEEE T IMAGE PROCESS, V22, P1546, DOI 10.1109/TIP.2012.2233487
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173
   OGLE VE, 1995, COMPUTER, V28, P40, DOI 10.1109/2.410150
   Pearce G., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P373, DOI 10.1109/AVSS.2011.6027353
   Quan Wang, 2013, 2013 XXVI Conference on Graphics, Patterns and Images (SIBGRAPI 2013), P8, DOI 10.1109/SIBGRAPI.2013.11
   Raveaux R, 2013, J VIS COMMUN IMAGE R, V24, P1252, DOI 10.1016/j.jvcir.2013.08.010
   Santhanam T., 2010, Journal of Computer Sciences, V6, P506, DOI 10.3844/jcssp.2010.506.510
   Santos D, 2009, 2009 10TH INTERNATIONAL WORKSHOP ON IMAGE ANALYSIS FOR MULTIMEDIA INTERACTIVE SERVICES, P137, DOI 10.1109/WIAMIS.2009.5031451
   Sclaroff S, 1997, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P2
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Sun ZH, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P171, DOI 10.1109/ACV.2002.1182177
   Wang Z, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P136, DOI 10.1109/CRV.2013.36
   Wei Zheng, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2703, DOI 10.1109/CVPRW.2009.5206642
   Yu G, P IEEE COMP SOC C CO, P865
   Zhang CY, 2015, P 15 INT C ALG ARCH
NR 37
TC 4
Z9 5
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10939
EP 10958
DI 10.1007/s11042-016-3372-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400035
DA 2024-07-18
ER

PT J
AU Tiwari, D
   Tyagi, V
AF Tiwari, Deepshika
   Tyagi, Vipin
TI Improved Weber's law based local binary pattern for dynamic texture
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic texture; Local binary pattern; Uniform pattern; Noise
   resistance; Weber law
ID CLASSIFICATION; SCALE; VIDEO
AB Dynamic texture is the moving sequence of images that shows some form of temporal regularity. Various static texture descriptors have been extended to spatiotemporal domain for dynamic texture classification. Local Binary Pattern (LBP) is a simple descriptor computationally but sensitive to noise and sometimes fails to capture different patterns. In view of this, a novel approach for dynamic texture classification is introduced that maintains the advantageous characteristics of uniform LBP. Inspired by theWeber's law, a simple yet very powerful, robust texture descriptor, i. e., Weber's law based LBP with center pixel (WLBPC) is proposed from the local patches based on the conventional Local Binary Pattern approach. A noise resistant variant of Weber's law based LBP with center pixel (NR-WLBPC) is also proposed. To do this, WLBPC is extended to a 3-valued code based on a new threshold. Proposed noise resistant variant of WLBPC descriptor makes use of the indecisive bit and the uniform pattern to compute the feature vector. Center pixel information is fused with both the dynamic texture descriptors to improve the discriminative power. Extensive experimental evaluations on representative dynamic texture databases (DynTex++ and UCLA) show that the proposed descriptors show better performance in comparison to recent state-of-the-art LBP variants and other methods under both normal and noisy conditions. Noise invariant of the proposed descriptor also performs better in the presence of noise due to its robustness and discriminating capabilities.
C1 [Tiwari, Deepshika] Jaypee Univ Engn & Technol, Dept Comp Sci & Engn, Guna, MP, India.
   [Tiwari, Deepshika] Jaypee Univ Engn & Technol, Comp Sci & Engn, Guna, MP, India.
   [Tyagi, Vipin] Jaypee Univ Engn & Technol, Deparment CSE, Guna, MP, India.
RP Tyagi, V (corresponding author), Jaypee Univ Engn & Technol, Deparment CSE, Guna, MP, India.
EM dr.vipin.tyagi@gmail.com
RI tiwari, Deepshikha/C-9942-2017; Tyagi, Vipin/I-2451-2013
OI Tyagi, Vipin/0000-0003-4994-3686
CR Baktashmotlagh M, 2014, IEEE T PATTERN ANAL, V36, P2353, DOI 10.1109/TPAMI.2014.2339851
   Chan AB, 2005, PROC CVPR IEEE, P846
   Chan AB, 2007, PROC CVPR IEEE, P208
   Chan AB, 2010, PROC CVPR IEEE, P2022, DOI 10.1109/CVPR.2010.5539878
   Chan CH, 2012, IEEE T INF FOREN SEC, V7, P602, DOI 10.1109/TIFS.2011.2175920
   Chen J, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.122
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Chetverikov D, 2005, ADV SOFT COMP, P17
   Derpanis KG, 2012, IEEE T PATTERN ANAL, V34, P1193, DOI 10.1109/TPAMI.2011.221
   Derpanis KG, 2010, PROC CVPR IEEE, P191, DOI 10.1109/CVPR.2010.5540213
   Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132
   Ghanem B, 2010, LECT NOTES COMPUT SC, V6312, P223
   Goncalves WN, CORR
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Liu F, 2013, NEUROCOMPUTING, V120, P325, DOI 10.1016/j.neucom.2012.06.061
   Liu L, 2013, IEEE IMAGE PROC, P255, DOI 10.1109/ICIP.2013.6738053
   Liu L, 2012, IMAGE VISION COMPUT, V30, P86, DOI 10.1016/j.imavis.2012.01.001
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Péteri R, 2010, PATTERN RECOGN LETT, V31, P1627, DOI 10.1016/j.patrec.2010.05.009
   Rivera AR, 2015, IEEE T PATTERN ANAL, V37, P2146, DOI 10.1109/TPAMI.2015.2392774
   Ravichandran A, 2009, PROC CVPR IEEE, P1651, DOI 10.1109/CVPRW.2009.5206847
   Ren JF, 2013, INT CONF ACOUST SPEE, P2400, DOI 10.1109/ICASSP.2013.6638085
   Ren JF, 2013, IEEE T IMAGE PROCESS, V22, P4049, DOI 10.1109/TIP.2013.2268976
   Saisan P, 2001, PROC CVPR IEEE, P58
   Shrivastava N, 2014, VISUAL COMPUT, V30, P1223, DOI 10.1007/s00371-013-0887-0
   Song TC, 2014, IEEE SIGNAL PROC LET, V21, P93, DOI 10.1109/LSP.2013.2293335
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tiwari D, 2016, ADV INTELL SYST COMP, V434, P365, DOI 10.1007/978-81-322-2752-6_36
   Tiwari D, 2016, MULTIDIM SYST SIGN P, V27, P563, DOI 10.1007/s11045-015-0319-6
   VARMA M, 2003, PROC CVPR IEEE, P691, DOI DOI 10.1109/CVPR.2003.1211534
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   Wang Y, 2016, SOFT COMPUT, V20, P1977, DOI 10.1007/s00500-015-1618-4
   Wang Y, 2015, NEUROCOMPUTING, V154, P217, DOI 10.1016/j.neucom.2014.12.001
   Xu Y, 2012, COMPUT VIS IMAGE UND, V116, P999, DOI 10.1016/j.cviu.2012.05.003
   Xu Y, 2011, IEEE I CONF COMP VIS, P1219, DOI 10.1109/ICCV.2011.6126372
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao G, 2007, LECT NOTES COMPUT SC, V4358, P165
   Zhao GY, 2012, IEEE T IMAGE PROCESS, V21, P1465, DOI 10.1109/TIP.2011.2175739
NR 40
TC 26
Z9 26
U1 4
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6623
EP 6640
DI 10.1007/s11042-016-3362-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400024
DA 2024-07-18
ER

PT J
AU Ahmad, J
   Sajjad, M
   Jan, Z
   Mehmood, I
   Rho, S
   Baik, SW
AF Ahmad, Jamil
   Sajjad, Muhammad
   Jan, Zahoor
   Mehmood, Irfan
   Rho, Seungmin
   Baik, Sung Wook
TI Analysis of interaction trace maps for active authentication on smart
   devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Active authentication; Edge orientation; Interaction trace maps; Shape
   features; Visual analysis
ID IDENTIFICATION
AB The availability and affordability of handheld smart devices have made life easier by enabling us to do work on the go. Their widespread use brings with it concerns relating to data security and privacy. The rising demand to secure private and highly confidential data found on smart devices has motivated researchers to devise means for ensuring privacy and security at all times. This kind of continuous user authentication scheme would add an additional layer of much needed security to smart devices. In this context, touch screen interactions have recently been studied as an effective modality to perform active user authentication on mobile devices. In this paper, a visual analysis based active authentication framework has been presented. Considering the touch screen as a canvas, interaction trace maps are constructed as a result of user interactions within various applications. The user touch gestures are captured and represented as drawing strokes on the canvas. The behavioral and physiological characteristics of users are modeled as signatures by combining texture and shape features from the interaction trace maps. A two-step mechanism with support vector machines exploit this signature to perform active user authentication. Experiments conducted with various datasets show that the proposed framework compares favorably with other state-of-the-art methods.
C1 [Ahmad, Jamil; Mehmood, Irfan; Baik, Sung Wook] Sejong Univ, Coll Elect & Informat Engn, Seoul, South Korea.
   [Sajjad, Muhammad; Jan, Zahoor] Islamia Coll, Dept Comp Sci, Peshawar, Pakistan.
   [Rho, Seungmin] Sungkyul Univ, Dept Multimedia, Anyang, South Korea.
C3 Sejong University; University of Peshawar; Sungkyul University
RP Baik, SW (corresponding author), Sejong Univ, Coll Elect & Informat Engn, Seoul, South Korea.
EM jamilahmad@sju.ac.kr; muhammad.sajjad@icp.edu.pk; zahoor.jan@icp.edu.pk;
   irfan@sejong.ac.kr; smrho@sungkyul.edu; sbaik@sejong.ac.kr
RI Sajjad, Muhammad/L-5269-2016; Rho, Seungmin/HTP-6683-2023; Baik, Sung
   Wook/AAR-8236-2020; Ahmad, Jamil/H-6264-2019
OI Sajjad, Muhammad/0000-0001-5646-0338; Ahmad, Jamil/0000-0001-8407-5971;
   Mehmood, Irfan/0000-0001-7864-957X; Baik, Sung Wook/0000-0002-6678-7788
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2013R1A1A2012904]
FX This research is supported by the Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (2013R1A1A2012904).
CR [Anonymous], HELLO ANDROID INTRO
   [Anonymous], ITC CSCC 2005 P
   [Anonymous], STYLOMETRY SYSTEMFOR
   [Anonymous], 2005, BIOMETRIC USER AUTHE
   Bevan C, 2016, INT J HUM-COMPUT ST, V88, P51, DOI 10.1016/j.ijhcs.2016.01.001
   Budulan S, 2015, LECT NOTES COMPUT SC, V9489, P591, DOI 10.1007/978-3-319-26532-2_65
   Calix K., 2008, Proceedings of CSIS Research Day, Pace University, P1048
   Chao Shen, 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P61, DOI 10.1109/BTAS.2012.6374551
   Chen BW, 2016, J SUPERCOMPUT, V72, P3297, DOI 10.1007/s11227-015-1404-1
   Chen BW, 2013, IEEE T SYST MAN CY-S, V43, P1279, DOI 10.1109/TSMC.2013.2244211
   Fathy ME, 2014, PATTERN RECOGN LETT, V42, P122, DOI 10.1016/j.patrec.2014.02.007
   Feng T, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON TECHNOLOGIES FOR HOMELAND SECURITY, P451, DOI 10.1109/THS.2012.6459891
   Frank M, 2013, IEEE T INF FOREN SEC, V8, P136, DOI 10.1109/TIFS.2012.2225048
   Furnell S, 2008, COMPUT FRAUD SECUR, P12, DOI 10.1016/S1361-3723(08)70127-1
   Guidorizzi RP, 2013, IT PROF, V15, P4, DOI 10.1109/MITP.2013.73
   Guna J, 2014, MULTIMED TOOLS APPL, V71, P179, DOI 10.1007/s11042-013-1635-1
   Hazen TJ, 2007, SIGNALS COMMUN TECHN, P123, DOI 10.1007/978-3-540-49346-4_9
   Li FD, 2014, INT J INF SECUR, V13, P229, DOI 10.1007/s10207-013-0209-6
   Lin CL, 2003, COMPUT SECUR, V22, P68, DOI 10.1016/S0167-4048(03)00114-7
   Matsumiya K, 2003, LECT NOTES COMPUT SC, V2609, P28
   Parhi P., 2006, P 8 C HUMAN COMPUTER, P203, DOI [DOI 10.1145/1152215.1152260, 10.1145/1152215.1152260]
   Rice RE, 2003, TELECOMMUN POLICY, V27, P597, DOI 10.1016/S0308-5961(03)00068-5
   Saravanan P, 2014, PROCEEDINGS OF CHINESE CHI 2014: SECOND INTERNATIONAL SYMPOSIUM OF CHINESE CHI (CHINESE CHI 2014), P110, DOI 10.1145/2592235.2592252
   Serwadda A, 2013, 2013 IEEE SIXTH INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS (BTAS)
   Serwadda A, 2013, IT PROF, V15, P20, DOI 10.1109/MITP.2013.51
   Shen C, 2016, IEEE T INF FOREN SEC, V11, P498, DOI 10.1109/TIFS.2015.2503258
   Sim T, 2007, COMPUTER VISION PATT, P1
   Traore I, 2014, MULTIMED TOOLS APPL, V71, P575, DOI 10.1007/s11042-013-1518-5
   Vapnik VladimirNaumovich., 1998, STAT LEARNING THEORY, V2
   Wang F, 2009, OPTO-ELECTRON REV, V17, P59, DOI 10.2478/s11772-008-0054-8
   Zhang H, 2015, IEEE WINT CONF APPL, P207, DOI 10.1109/WACV.2015.35
NR 31
TC 15
Z9 17
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 4069
EP 4087
DI 10.1007/s11042-016-3450-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200042
DA 2024-07-18
ER

PT J
AU de la Fuente, YS
   Skupin, R
   Schierl, T
AF de la Fuente, Y. Sanchez
   Skupin, R.
   Schierl, T.
TI Video processing for panoramic streaming using HEVC and its scalable
   extensions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Panoramic streaming; HEVC; SHVC; MV-HEVC; Tiles; Stitching
AB Panoramic streaming is a particular way of video streaming where an arbitrary Region-of-Interest (RoI) is transmitted from a high-spatial resolution video, i.e. a video covering a very ''wide-angle'' (much larger than the human field-of- view-e.g.360 degrees). Some transport schemes for panoramic video delivery have been proposed and demonstrated within the past decade, which allow users to navigate interactively within the high-resolution videos. With the recent advances of head mounted displays, consumers may soon have immersive and sufficiently convenient end devices at reach, which could lead to an increasing demand for panoramic video experiences.The solution proposed within this paper is built upon tile-based panoramic streaming, where users receive a set of tiles that match their RoI, and consists in a low- complexity compressed domain video processing technique for using H.265/HEVC and its scalable extensions (H. 265/SHVC and H.265/MV-HEVC). The proposed technique generates a single video bitstream out of the selected tiles so that a single hardware decoder can be used. It overcomes the scalability issue of previous solutions not using tiles and the battery consumption issue inherent of tile-based panorama streaming, where multiple parallel software decoders are used. In addition, the described technique is capable of reducing peak streaming bitrate during changes of the RoI, which is crucial for allowing a truly immersive and low latency video experience. Besides, it makes it possible to use Open GOP structures without incurring any playback interruption at switching events, which provides a better compression efficiency compared to closed GOP structures.
C1 [de la Fuente, Y. Sanchez; Skupin, R.; Schierl, T.] Fraunhofer HHI, Video Coding & Analyt Dept, Multimedia Commun Grp, Einsteinufer 37, D-10587 Berlin, Germany.
   [de la Fuente, Y. Sanchez] Tech Univ Berlin, Dept Telecommun Syst, Image Commun Grp, D-10587 Berlin, Germany.
C3 Technical University of Berlin
RP de la Fuente, YS (corresponding author), Fraunhofer HHI, Video Coding & Analyt Dept, Multimedia Commun Grp, Einsteinufer 37, D-10587 Berlin, Germany.; de la Fuente, YS (corresponding author), Tech Univ Berlin, Dept Telecommun Syst, Image Commun Grp, D-10587 Berlin, Germany.
EM yago.sanchez@hhi.fraunhofer.de
CR [Anonymous], P 15 EUR SIGN PROC C
   [Anonymous], 2010, P 18 ACM INT C MULT
   [Anonymous], 2015, 2300912014AMD2 ISOIE
   Bjontegaard G, 2001, VCEGM33
   Fujibayashi A, 2011, 4 JCT VC M DAEG
   Gaddam V Reddy, 2015, PICT CODING SYM PCS, P204
   Gaddam VR, 2014, P NOSSDAV, P19
   Gaddam VR, 2014, P 5 ACM MULT SYST C, P68
   Lin JL, 2013, IEEE J-STSP, V7, P957, DOI 10.1109/JSTSP.2013.2271975
   Mavlankar A, 2010, P 18 INT PACK VID WO
   Quang N, 2011, MMSYS 2011
   Ravindra G, 2012, P NOSSDAV 12 22 INT
   Sanchez Y., 2015, P IMM MED EXP 2015 W
   Sanchez Y, 2014, P IEEE CONS COMMM NE
   Sanchez Y, 2015, IM PROC ICIP 2015 22
   Seo D, 2014, MULTIMEDIA SYST, V20, P707, DOI 10.1007/s00530-013-0333-1
   Skupin R, 2015, PICT COD S PCS 2015
   Skupin R., 2015, P IEEE INT C CONS EL
   Stockhammer T., 2011, P 2 ANN ACM C MULTI
   Sullivan G. J., 2012, IEEE T CIRC SYST VID
   Sullivan GJ, 2013, IEEE J-STSP, V7, P1001, DOI 10.1109/JSTSP.2013.2283657
   van Brandenburg R, 2011, 15 INT C INT NEXT GE
   Weissig C, 2012, LECT NOTES COMPUT SC, V7131, P671
NR 23
TC 19
Z9 25
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5631
EP 5659
DI 10.1007/s11042-016-4097-4
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500042
OA hybrid
DA 2024-07-18
ER

PT J
AU Lei, JJ
   Li, ZZ
   Zhu, T
   He, XX
   You, L
   Hou, CP
AF Lei, Jianjun
   Li, Zhenzhen
   Zhu, Tao
   He, Xiaoxu
   You, Lei
   Hou, Chunping
TI Region-based bit allocation and rate control for depth video in HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bit allocation; Rate control; Depth video; Video coding; HEVC
ID VIEW SYNTHESIS; DISTORTION MODEL; MULTIVIEW VIDEO; PLUS DEPTH; TEXTURE;
   MAPS
AB In this paper, we present a novel rate control method with optimized region-based bit allocation for depth video coding. First, a synthetic view distortion oriented segmentation method is proposed to divide depth video into different regions, including texture areas and smooth areas. Then, the expanded exponential distortion-rate (D-R) models and power quantization parameter-rate (QP-R) models are investigated to simulate rate-distortion (RD) characteristics of different regions. Finally, an optimal bit allocation scheme is developed to adaptively allocate target bit with the division. Experimental results on various video sequences demonstrate that the proposed algorithm achieves excellent R-D efficiency and bit rate accuracy compared with benchmark algorithms.
C1 [Lei, Jianjun; Li, Zhenzhen; Zhu, Tao; He, Xiaoxu; You, Lei; Hou, Chunping] Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
C3 Tianjin University
RP He, XX (corresponding author), Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
EM hexiaoxu828@163.com
RI Zhu, Tao/JEF-1129-2023; Lei, Jianjun/P-2539-2018; zhu,
   tao/KHY-3114-2024; Li, Zhenzhen/KGV-0193-2024
OI Zhu, Tao/0009-0001-1499-8700; 
FU Natural Science Foundation of China [61271324, 61471262, 61520106002,
   91320201, 61202266]; International Science and Technology Cooperation
   Program [2010DFA12780]; Natural Science Foundation of Tianjin
   [12JCYBJC10400]
FX This research was partially supported by the Natural Science Foundation
   of China (No. 61271324, 61471262, 61520106002, 91320201, 61202266),
   International Science and Technology Cooperation Program
   (No.2010DFA12780), and Natural Science Foundation of Tianjin
   (No.12JCYBJC10400).
CR Alatan AA, 2007, IEEE T CIRC SYST VID, V17, P1587, DOI 10.1109/TCSVT.2007.909974
   [Anonymous], 2010, EE2 3DVFTV JTC1SC29W
   [Anonymous], 2013, JCTVCL1100 ISOIEC JT
   Bjontegaard G., 2001, Document VCEG-M33
   Choi Hyomin, 2012, 8 JCTVC M SAN JOS
   Hu SD, 2013, IEEE T IMAGE PROCESS, V22, P585, DOI 10.1109/TIP.2012.2219549
   Lee B, 2014, IEEE T CIRC SYST VID, V24, P465, DOI 10.1109/TCSVT.2013.2276880
   Lei JJ, 2015, IEEE T CIRC SYST VID, V25, P275, DOI 10.1109/TCSVT.2014.2335471
   Li  B., 2013, 13 JCTVC M INCH
   Liu SJ, 2011, IEEE T BROADCAST, V57, P551, DOI 10.1109/TBC.2011.2120750
   Liu YW, 2011, IEEE T BROADCAST, V57, P562, DOI 10.1109/TBC.2011.2105652
   Loghman M, 2015, MULTIMED TOOLS APPL, V74, P1611, DOI 10.1007/s11042-013-1747-7
   Lu K, 2015, IEEE T IMAGE PROCESS, V24, P1449, DOI 10.1109/TIP.2015.2395961
   Min DB, 2012, IEEE T IMAGE PROCESS, V21, P1176, DOI 10.1109/TIP.2011.2163164
   Oh BT, 2011, IEEE J-STSP, V5, P1344, DOI 10.1109/JSTSP.2011.2164893
   Oh KJ, 2011, IEEE T CIRC SYST VID, V21, P350, DOI 10.1109/TCSVT.2011.2116590
   Shao F, 2014, IEEE J EM SEL TOP C, V4, P106, DOI 10.1109/JETCAS.2014.2298314
   Shao F, 2013, IEEE T MULTIMEDIA, V15, P1843, DOI 10.1109/TMM.2013.2269897
   Stefanoski N, 2013, IEEE T IMAGE PROCESS, V22, P3329, DOI 10.1109/TIP.2013.2264817
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Nguyen VA, 2013, IEEE T CIRC SYST VID, V23, P189, DOI 10.1109/TCSVT.2012.2203212
   Yang J., 2014, J ELECTRON IMAGING, V23, P118
   Yuan H, 2014, IEEE T CIRC SYST VID, V24, P443, DOI 10.1109/TCSVT.2013.2280071
   Yuan H, 2011, IEEE T CIRC SYST VID, V21, P485, DOI 10.1109/TCSVT.2011.2125610
   Zhang R, 2012, J APPL MATH, DOI 10.1155/2012/623230
   Zhang Y, 2013, IEEE T IMAGE PROCESS, V22, P3497, DOI 10.1109/TIP.2013.2265883
   Zhao Y, 2011, IEEE T IMAGE PROCESS, V20, P2221, DOI 10.1109/TIP.2011.2118218
   Zhu C., 2013, 3D-TV System with Depth-Image-Based Rendering - Architectures, Techniques and Challenges
NR 28
TC 1
Z9 1
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 4179
EP 4195
DI 10.1007/s11042-016-3336-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200048
DA 2024-07-18
ER

PT J
AU Lin, YP
   Song, YH
   Li, YY
   Wang, F
   He, K
AF Lin, Yuping
   Song, Yonghong
   Li, Yingyu
   Wang, Fang
   He, Kai
TI Multilingual corpus construction based on printed and handwritten
   character separation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multilingual corpus; Machine printed character; Handwritten character;
   Character extraction; AdaBoost
ID SCRIPT IDENTIFICATION; TEXTURE; CLASSIFICATION
AB This paper proposes an effective method to extract printed and handwritten characters from multilingual document images to build corpus. To extract the characters from the document images, a connected component analysis method is used to remove the graphics. After that, multiple types of features and AdaBoost algorithm are introduced to classify printed and handwritten characters in a more versatile and robust way. Firstly, the content of the image is divided into several text patches which are then used to distinguish different languages. Secondly, we use the multiple types of features and AdaBoost algorithm to train the classifiers based on the segmented patches. Finally, we can separate printed and handwritten parts of new image set by the trained classifiers. The proposed method improves the precision of the extraction of written materials in text images of different languages. Experimental results demonstrate that the proposed method is more accurate in terms of precision and recall rate compared with the state-of the-art methods.
C1 [Lin, Yuping; Li, Yingyu; Wang, Fang] Xi An Jiao Tong Univ, Sch Foreign Studies, Xian 710049, Shaanxi, Peoples R China.
   [Song, Yonghong; He, Kai] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University; Xi'an Jiaotong University
RP Song, YH (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Shaanxi, Peoples R China.
EM songyh@mail.xjtu.edu.cn
RI Song, YongHong/AEL-0628-2022
OI LI, Yingyu/0000-0003-3324-4450
FU Shaanxi Social Science Foundation of China [13 K093, 2015 K014];
   National Social Science Foundation of China [12BYY055]; Shaanxi Twelfth
   Year Planning Foundation of China [SGH13015]; Social Science Foundation
   of Ministry of Education of China [15YJA740016]; Fundamental Research
   Funds for the Central Universities [Sk2013008]
FX This work was supported by Shaanxi Social Science Foundation of China
   under Grant Nos. 13 K093 and 2015 K014, National Social Science
   Foundation of China under Grant No. 12BYY055, Shaanxi Twelfth Year
   Planning Foundation of China under Grant No. SGH13015, Social Science
   Foundation of Ministry of Education of China under Grant No.15YJA740016
   and the Fundamental Research Funds for the Central Universities under
   Grant No. Sk2013008.
CR Agam G., 2006, COMPLEX DOCUMENT IMA
   Anthony L, 2013, LINGUIST RES, V30, P141
   Busch A, 2005, IEEE T PATTERN ANAL, V27, P1720, DOI 10.1109/TPAMI.2005.227
   CHELLAPPA R, 1985, IEEE T ACOUST SPEECH, V33, P959, DOI 10.1109/TASSP.1985.1164641
   Drivas D., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P610, DOI 10.1109/ICDAR.1995.601970
   Fan KC, 1998, PATTERN RECOGN, V31, P1275, DOI 10.1016/S0031-3203(97)00143-X
   Franke J., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P581, DOI 10.1109/ICDAR.1993.395668
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Gatos B, 2011, INT J DOC ANAL RECOG, V14, P25, DOI 10.1007/s10032-010-0122-8
   Guo JHK, 2001, PROC INT CONF DOC, P439, DOI 10.1109/ICDAR.2001.953828
   Hochberg J., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P378, DOI 10.1109/ICDAR.1995.599017
   Jain AK, 1996, PATTERN RECOGN, V29, P743, DOI 10.1016/0031-3203(95)00131-X
   Johansson S, 2002, LANG COMPUT, P47
   Koyama J, 2008, LECT NOTES COMPUT SC, V4984, P1031
   Kuhnke K., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P811, DOI 10.1109/ICDAR.1995.602025
   Kundu A., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P457, DOI 10.1109/CVPR.1988.196275
   Lewis D., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P665, DOI 10.1145/1148170.1148307
   Liu Q, 2014, INFORM SCIENCES, V281, P750, DOI 10.1016/j.ins.2014.04.053
   Maguire P, 2010, CORPUS LINGUIST LING, V6, P49, DOI 10.1515/CLLT.2010.003
   Pal U, 2001, PATTERN RECOGN LETT, V22, P431, DOI 10.1016/S0167-8655(00)00126-4
   Soffer A, 1997, PROC INT CONF DOC, P233, DOI 10.1109/ICDAR.1997.619847
   Srihari SN, 1996, P IEEE, V84, P1038, DOI 10.1109/5.503302
   Tan TN, 1998, IEEE T PATTERN ANAL, V20, P751, DOI 10.1109/34.689305
   Vyatkina N, 2014, LANG LEARN TECHNOL, V18, P70
   Yefeng Zheng, 2001, Proceedings of the SPIE - The International Society for Optical Engineering, V4670, P49, DOI 10.1117/12.450738
   Zheng YF, 2002, LECT NOTES COMPUT SC, V2423, P95
   Zheng YF, 2004, IEEE T PATTERN ANAL, V26, P337, DOI 10.1109/TPAMI.2004.1262324
NR 28
TC 5
Z9 5
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 4123
EP 4139
DI 10.1007/s11042-015-2995-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200045
DA 2024-07-18
ER

PT J
AU Parah, SA
   Ahad, F
   Sheikh, JA
   Loan, NA
   Bhat, GM
AF Parah, Shabir A.
   Ahad, Farhana
   Sheikh, Javaid A.
   Loan, Nazir A.
   Bhat, G. M.
TI A New Reversible and high capacity data hiding technique for
   E-healthcare applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fragile Watermarking; Embedding; Electronic Healthcare; Reversibility
ID MULTIPLE WATERMARKING; ROBUST
AB A high capacity and reversible data hiding technique capable of tamper detection and localisation of medical images has been proposed in this paper. Image interpolation has been used to scale up the original image to obtain the cover image. The cover image is divided into n(x)n non-overlapping blocks. In every block pixels are classified into two types: Seed pixels and non-seed pixels. The Electronic Patient Record (EPR) is embedded only in non-seed pixels while as no embedding is carried out in seed pixels to facilitate reversibility. A fragile watermark coupled with Block Checksum has been embedded in addition to EPR for detecting any tamper to the patient data during its transit from transmitter to receiver. Embedding has been carried out using Intermediate Significant Bit Substitution (ISBS) to prevent the scheme from LSB removal/replacement attack. The scheme has been evaluated for perceptual imperceptibility and content authentication by subjecting it to various image processing and geometric attacks. Experimental results reveal that the proposed system is capable of providing high quality watermarked images for fairly high payload while maintaining reversibility. Further it has been observed that the proposed technique is able to detect tamper for all the image processing and geometric attacks carried out on it. A comparison of the observed results with that of some state-of-art schemes show that our scheme performs better and as such is an ideal candidate for content authentication of EPR in a typical e-healthcare system.
C1 [Parah, Shabir A.; Ahad, Farhana; Sheikh, Javaid A.; Loan, Nazir A.; Bhat, G. M.] Univ Kashmir, Post Grad Dept Elect & Instrumentat Technol, Srinagar 190006, J&K, India.
C3 University of Kashmir
RP Parah, SA (corresponding author), Univ Kashmir, Post Grad Dept Elect & Instrumentat Technol, Srinagar 190006, J&K, India.
EM shabireltr@gmail.com
RI Parah, Shabir/AAB-7603-2021
OI Parah, Shabir/0000-0001-5983-0912; Bhat, Ghulam
   Mohiuddin/0000-0001-9106-4699; Sheikh, Javaid A/0000-0003-3113-3802
FU University Grants Commission (UGC); Department of Science and Technology
   (DST), Government of India
FX The authors duly acknowledge University Grants Commission (UGC) and
   Department of Science and Technology (DST), Government of India for the
   supporting this research under Special Assistance Package (SAP)
   Programme and Inspire Fellowship respectively.
CR Abd-Eldayem MM, 2013, EGYPT INFORM J, V14, P1, DOI 10.1016/j.eij.2012.11.002
   [Anonymous], J INFORM HIDING MULT
   [Anonymous], MULTIMEDIA IN PRESS
   [Anonymous], OPTIK ELSEVIER
   [Anonymous], 2015, MULTIDIMENS SYST SIG, DOI DOI 10.1007/S11045-015-0358-Z
   [Anonymous], IEEE INT C MED IM M
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 17 IEEE INT C COMP I
   [Anonymous], NATL ACAD SCI LETT
   [Anonymous], INT J SOFT COMPUTING
   [Anonymous], IEEE INT C COMP INT
   Arsalan M, 2012, J SYST SOFTWARE, V85, P883, DOI 10.1016/j.jss.2011.11.005
   Guo XT, 2009, J DIGIT IMAGING, V22, P620, DOI 10.1007/s10278-008-9120-5
   Hu J, 2015, COMPUT ELECTR ENG, V46, P447, DOI 10.1016/j.compeleceng.2015.04.014
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Kundu M. K., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1457, DOI 10.1109/ICPR.2010.360
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Lei BY, 2014, EXPERT SYST APPL, V41, P3178, DOI 10.1016/j.eswa.2013.11.019
   Maity HK, 2012, PROC TECH, V1, P275, DOI 10.1016/j.protcy.2012.10.033
   Parah SA, 2015, INT J ELECTRON, V102, P1253, DOI 10.1080/00207217.2014.954635
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P10599, DOI 10.1007/s11042-015-3127-y
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Parah SA, 2014, COMPUT ELECTR ENG, V40, P70, DOI 10.1016/j.compeleceng.2013.11.006
   Rahimi F, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-53
   Singh AK, 2016, MULTIMED TOOLS APPL, P1
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P607, DOI 10.1166/jmihi.2015.1432
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P406, DOI 10.1166/jmihi.2015.1407
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Singh AK, 2014, P NATL A SCI INDIA A, V84, P345, DOI 10.1007/s40010-014-0140-x
   Solanki Neha, 2014, International Journal of Modern Education and Computer Science, V6, P40, DOI 10.5815/ijmecs.2014.10.06
   Tan CK, 2011, J DIGIT IMAGING, V24, P528, DOI 10.1007/s10278-010-9295-4
   Tang MW, 2014, OPTIK, V125, P3972, DOI 10.1016/j.ijleo.2014.01.149
   Wang XT, 2013, DIGIT SIGNAL PROCESS, V23, P569, DOI 10.1016/j.dsp.2012.06.015
NR 33
TC 42
Z9 43
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3943
EP 3975
DI 10.1007/s11042-016-4196-2
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200037
DA 2024-07-18
ER

PT J
AU Rout, JK
   Singh, S
   Jena, SK
   Bakshi, S
AF Rout, Jitendra Kumar
   Singh, Smriti
   Jena, Sanjay Kumar
   Bakshi, Sambit
TI Deceptive review detection using labeled and unlabeled
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Review spam; Spam detection techniques; Review analysis; Opinion spam;
   Sentiment analysis; Social networking
AB Availability of millions of products and services on e-commerce sites makes it difficult to search the best suitable product according to the requirements because of existence of many alternatives. To get rid of this the most popular and useful approach is to follow reviews of others in opinionated social medias, who have already tried them. Almost all e-commerce sites provide facility to the users for giving views and experience of the product and services they experienced. The customers reviews are increasingly used by individuals, manufacturers and retailers for purchase and business decisions. As there is no scrutiny over the reviews received, anybody can write anything unanimously which conclusively leads to review spam. Moreover, driven by the desire of profit and/or publicity, spammers produce synthesized reviews to promote some products/brand and demote competitors products/brand. Deceptive review spam has seen a considerable growth overtime. In this work, we have applied supervised as well as unsupervised techniques to identify review spam. Most effective feature sets have been assembled for model building. Sentiment analysis has also been incorporated in the detection process. In order to get best performance some well-known classifiers were applied on labeled dataset. Further, for the unlabeled data, clustering is used after desired attributes were computed for spam detection. Additionally, there is a high chance that spam reviewers may also be held responsible for content pollution in multimedia social networks, because nowadays many users are giving the reviews using their social network logins. Finally, the work can be extended to find suspicious accounts responsible for posting fake multimedia contents into respective social networks.
C1 [Rout, Jitendra Kumar; Jena, Sanjay Kumar; Bakshi, Sambit] Natl Inst Technol, Rourkela 769008, Odisha, India.
   [Singh, Smriti] Teradata Corp, Telangana 500081, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela
RP Bakshi, S (corresponding author), Natl Inst Technol, Rourkela 769008, Odisha, India.
EM jitu2rout@gmail.com; sambitbaksi@gmail.com; smritisingh22@gmail.com;
   skjena@nitrkl.ac.in
RI Bakshi, Sambit/I-5013-2018; Bakshi, Sambit/JDC-3355-2023; Rout, Jitendra
   Kumar/ABB-9631-2021
OI Bakshi, Sambit/0000-0002-6107-114X; Bakshi, Sambit/0000-0002-6107-114X;
   Rout, Jitendra Kumar/0000-0002-5295-1110
FU Information Security Education & Awareness Project (Phase II), Ministry
   of Communications and Information Technology, Government of India; Fund
   for Improvement of S&T Infrastructure in Universities and Higher
   Educational Institutions (FIST) Program, Department of Science and
   Technology, Government of India
FX The work presented in this article is partially funded by the following
   two projects:; 1. Information Security Education & Awareness Project
   (Phase II), Ministry of Communications and Information Technology,
   Government of India, and; 2. Fund for Improvement of S&T Infrastructure
   in Universities and Higher Educational Institutions (FIST) Program,
   Department of Science and Technology, Government of India.
CR Akoglu L, 2013, ICWSM, P2
   Algur S. P., 2010, 2010 International Conference on Signal and Image Processing (ICSIP 2010), P416, DOI 10.1109/ICSIP.2010.5697509
   [Anonymous], 2013, P 4 WORKSH COMP APPR
   [Anonymous], 2014, P INT C MULT RETR
   [Anonymous], 2013, UICCS032013
   [Anonymous], WORKSH AAAI ART INT
   Bing L, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P179, DOI 10.1109/icdm.2003.1250918
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Crawford M., 2015, J BIG DATA, V2, P23, DOI [10.1186/s40537-015-0029-9, DOI 10.1186/S40537-015-0029-9]
   Fei Geli., 2013, ICWSM
   Günnemann S, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P841, DOI 10.1145/2623330.2623721
   Jindal N., 2008, Proceedings of the 2008 International Conference on Web Search and Data Mining: ACM, DOI DOI 10.1145/1341531.1341560
   Jindal N., 2007, P 16 INT WORLD WID W, P1189, DOI DOI 10.1145/1242572.1242759
   Jindal N, 2007, IEEE DATA MINING, P547, DOI 10.1109/ICDM.2007.68
   Lai C. L., 2010, Proceedings 2010 IEEE 7th International Conference on e-Business Engineering (ICEBE 2010), P1, DOI 10.1109/ICEBE.2010.47
   Lee K, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P199, DOI 10.1145/2567948.2577270
   Li Fangtao., 2011, P 22 INT JOINT C ART
   Lim E.P., 2010, P ACM INT C INFORM K, P939, DOI DOI 10.1145/1871437.1871557
   Long N., 2014, T.p chI Khoa H.c, V61, P44
   Mukherjee A, 2012, P 21 INT C WORLD WID, P191
   Mukherjee A., 2013, P 7 INT AAAI C WEBL
   Mukherjee A, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P632
   Mukherjee Arjun., 2011, P 20 INT C COMPANION, P93
   Ott M., 2011, ACL HLT 2011 P 49 AN, V1, P309, DOI DOI 10.1145/2567948.2577293
   Ott M., 2013, P 2013 C N AM CHAPT, P497
   Qi SH, 2015, NEUROCOMPUTING, V158, P225, DOI 10.1016/j.neucom.2015.01.041
   Qingxi Peng, 2014, Journal of Software, V9, P2065, DOI 10.4304/jsw.9.8.2065-2072
   Rayson Paul., 2001, LANGUAGE COMPUTERS, V36, P295
   Ren Y., 2014, P 2014 C EMP METH NA, P488, DOI DOI 10.3115/V1/D14-1055
   Shojaee S, 2013, INT CONF INTELL SYST, P53, DOI 10.1109/ISDA.2013.6920707
   Wang FL, 2016, MULTIMEDIA SYST, V22, P63, DOI 10.1007/s00530-014-0393-x
   Wu Guangyu., 2010, Proceedings of the First Workshop on Social Media Analytics, P10
   Yan X, 2011, ACM T INFORM SYST, V29, DOI 10.1145/1993036.1993039
   Yue Gao, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015, January 5-7, 2015, Proceedings: LNCS 8935, P269, DOI 10.1007/978-3-319-14445-0_24
   Zhang ZY, 2013, SOC NETW ANAL MIN, V3, P969, DOI 10.1007/s13278-012-0078-4
   Zhao SC, 2016, MULTIMED TOOLS APPL, V75, P8921, DOI 10.1007/s11042-014-2342-2
NR 36
TC 47
Z9 47
U1 2
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3187
EP 3211
DI 10.1007/s11042-016-3819-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200003
OA Bronze
DA 2024-07-18
ER

PT J
AU Soleymani, SH
   Taherinia, AH
AF Soleymani, Seyyed Hossein
   Taherinia, Amir Hossein
TI Double expanding robust image watermarking based on Spread Spectrum
   technique and BCH coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Robust watermarking; Spread spectrum; BCH coding; Region attention; DWT;
   DCT
ID WAVELET TRANSFORM; E-GOVERNMENT; SCHEME; DOMAIN; DCT
AB This paper presents a new algorithm for blind image watermarking which has a high robustness against common image processing attacks such as noise addition (Gaussian noise, Salt & Pepper noise, Speckle noise and etc.), JPEG and JPEG2000 compressions, Histogram Equalization, Average and Gaussian filters, Scaling and Cropping. According to this fact that a watermark with about 70 bits is enough for copyright protection, consequently in this paper a small watermark (64 bits) have been double expanded into multi larger meaningful bits with applying BCH error correction code and Spread Spectrum technique in order to reduce errors in extraction phase. Approximation subband of two levels DWT transform is divided into non-overlapping blocks and high frequency coefficients of DCT transform of each block is used for embedding the watermark. Embedding technique, which is used in this paper, is Spread Spectrum. Correlation between some coefficients of each embedded block and two predefined groups of random bits is used for watermark extraction, so this method is blind and does not need to the original image or additional information in extraction phase. Another idea, which is used in this paper, is calculating different gain factors for each block of approximation subband according to the texture of each block. Consequently this method allocates smaller gain factors to smooth blocks and larger gain factors to texture and rough blocks. So, manipulating in image will be more robust and imperceptible.
C1 [Soleymani, Seyyed Hossein; Taherinia, Amir Hossein] Ferdowsi Univ Mashhad, Dept Comp Engn, Fac Engn, Mashhad, Iran.
C3 Ferdowsi University Mashhad
RP Taherinia, AH (corresponding author), Ferdowsi Univ Mashhad, Dept Comp Engn, Fac Engn, Mashhad, Iran.
EM seyyedhosein.soleymani@stu.um.ac.ir; taherinia@um.ac.ir
RI Taherinia, Amir Hossein/AAC-9575-2020; Taherinia, Amir
   Hossein/HTP-1792-2023
OI Taherinia, Amir Hossein/0000-0002-5103-4812; 
CR [Anonymous], 2013, IOSR J COMPUTER ENG
   Benoraira A, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0239-5
   Cedillo-Hernandez A, 2014, SIGNAL PROCESS, V97, P40, DOI 10.1016/j.sigpro.2013.08.019
   Chu CC, 2012, INT CONF ACOUST SPEE, P1605, DOI 10.1109/ICASSP.2012.6288201
   Chugh G, 2013, INT J ADV RES COMPUT, V4, P1
   Cox I, 2007, DIGITAL WATERMARKING, P23
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Ghosh S, 2009, 2009 IEEE INTERNATIONAL ADVANCE COMPUTING CONFERENCE, VOLS 1-3, P868, DOI 10.1109/IADCC.2009.4809129
   Hai T, 2014, J APPL RES TECHNOL, V12, P122, DOI 10.1016/S1665-6423(14)71612-8
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P3085, DOI 10.1007/s11042-013-1579-5
   Horng SJ, 2013, J VIS COMMUN IMAGE R, V24, P1099, DOI 10.1016/j.jvcir.2013.07.008
   Khalili M, 2015, OPTIK, V126, P4367, DOI 10.1016/j.ijleo.2015.08.042
   Khan A, 2014, INFORM SCIENCES, V279, P251, DOI 10.1016/j.ins.2014.03.118
   Lagzian S., 2011, International Journal of Intelligent Information Processing, V2, P22, DOI DOI 10.4156/IJIIP
   Li CL, 2015, NEUROCOMPUTING, V166, P404, DOI 10.1016/j.neucom.2015.03.039
   Makbol NM, 2013, AEU-INT J ELECTRON C, V67, P102, DOI 10.1016/j.aeue.2012.06.008
   Moreira JC, 2006, ESSENTIALS ERROR CON, P4
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Ramaraj M., 2011, 2011 Proceedings of International Conference on Computer, Communication and Electrical Technology (ICCCET 2011), P109, DOI 10.1109/ICCCET.2011.5762449
   Rosiyadi Didi, 2015, 2015 49th Annual International Carnahan Conference on Security Technology (ICCST), P1, DOI 10.1109/CCST.2015.7389701
   Rosiyadi D, 2014, 2014 2ND INTERNATIONAL CONFERENCE ON TECHNOLOGY, INFORMATICS, MANAGEMENT, ENGINEERING, AND ENVIRONMENT (TIME-E 2014), P7, DOI 10.1109/TIME-E.2014.7011582
   Sadreazami H, 2012, AEU-INT J ELECTRON C, V66, P364, DOI 10.1016/j.aeue.2011.09.001
   Soleymani SH, 2015, 2015 5TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P18, DOI 10.1109/ICCKE.2015.7365856
   Taherinia AH, 2012, SECUR COMMUN NETW, V5, P625, DOI 10.1002/sec.357
   Taherinia AH, 2011, OPT ENG, V50, DOI 10.1117/1.3581116
   Verma VS, 2015, EXPERT SYST APPL, V42, P8184, DOI 10.1016/j.eswa.2015.06.041
   Yuliani AR, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTER, CONTROL, INFORMATICS AND ITS APPLICATIONS (IC3INA), P165, DOI 10.1109/IC3INA.2015.7377766
NR 28
TC 6
Z9 6
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3485
EP 3503
DI 10.1007/s11042-016-3734-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200016
DA 2024-07-18
ER

PT J
AU Wang, YL
   Yang, J
   Qiu, G
   Feng, WN
AF Wang, Yulei
   Yang, Jie
   Qiu, Gang
   Feng, Weining
TI A formalized delegation model for multimedia social networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia social networks; Delegation model; Formalism; Security
   policy; Revocation
AB In response to the issues of second-hand sharing and repeat delegation of the digital content in existing multimedia social networks, this paper proposed a novel formalized delegation model for multimedia social network. In accordance with this model, delegators can independently lay down delegation policies. Further, related delegation constraints and strategies were identified to solve delegation conflicts. When a conflict arises among several delegations, strategies could be used to solve the conflict. This delegation model can control the authorities and are delegated consistently until the authorization expires or is revoked. And also, the paper presented essential security policies that lead to revoking different authorities. A use case of real multimedia social network further verified the efficiency and effectiveness of the proposed model.
C1 [Wang, Yulei; Yang, Jie] Wuhan Univ Technol, Sch Informat Engn, Wuhan 430063, Peoples R China.
   [Wang, Yulei] Nanyang Inst Technol, Network Informat Ctr, Nanyang 473009, Peoples R China.
   [Qiu, Gang] Nanyang Inst Technol, Sch Software, Nanyang 473009, Peoples R China.
   [Feng, Weining] Henan Univ Sci & Technol, Informat Engn Coll, Luoyang 471023, Peoples R China.
C3 Wuhan University of Technology; Nanyang Institute of Technology; Nanyang
   Institute of Technology; Henan University of Science & Technology
RP Wang, YL (corresponding author), Wuhan Univ Technol, Sch Informat Engn, Wuhan 430063, Peoples R China.; Wang, YL (corresponding author), Nanyang Inst Technol, Network Informat Ctr, Nanyang 473009, Peoples R China.
EM wyvlei@163.com
RI liu, zhao/GXV-6141-2022; Wang, Yulei/I-7703-2013; Yang,
   Jie/JCD-9867-2023
FU Program for Henan Province Science and Technology [152102210218]
FX The work was sponsored by Program for Henan Province Science and
   Technology Grant No. 152102210218. We would like to thank the reviewers
   and editor for their valuable comments, questions, and suggestions.
CR Donick M, 2011, 2011 14TH INTERNATIONAL CONFERENCE ON INTERACTIVE COLLABORATIVE LEARNING (ICL), P290, DOI 10.1109/ICL.2011.6059593
   Feng WN, 2016, MULTIMED TOOLS APPL, V75, P13995, DOI 10.1007/s11042-015-2929-2
   Gomi H., 2011, Proceedings of the 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and IEEE Third International Conference on Social Computing (PASSAT/SocialCom 2011), P1239, DOI 10.1109/PASSAT/SocialCom.2011.124
   Hur J, 2013, IEEE T KNOWL DATA EN, V25, P2271, DOI 10.1109/TKDE.2011.78
   Hur J, 2011, IEEE T PARALL DISTR, V22, P1214, DOI 10.1109/TPDS.2010.203
   Lei J, 2013, J NETW, V8
   Sun D, 2011, IEEE INT C AUT LOG I, P371
   Toahchoodee M, 2011, J COMPUT SECUR, V19, P399, DOI 10.3233/JCS-2010-0418
   Wang FY, 2009, WISM: 2009 INTERNATIONAL CONFERENCE ON WEB INFORMATION SYSTEMS AND MINING, PROCEEDINGS, P557, DOI 10.1109/WISM.2009.119
   Ye CX, 2008, PROCEEDINGS OF THE 2008 IEEE INTERNATIONAL CONFERENCE ON NETWORKING, ARCHITECTURE, AND STORAGE, P171, DOI 10.1109/NAS.2008.39
   Zhang M, 2013, ELECTRON NOTES THEOR, V294, P12, DOI 10.1016/j.entcs.2013.02.013
   Zhang ZY, 2015, MULTIMED TOOLS APPL, V74, P6255, DOI [10.1007/s11042-014-2135-7, 10.1007/s11042-015-2619-0]
   Zhang ZY, 2015, COMPUT J, V58, P668, DOI 10.1093/comjnl/bxu035
NR 13
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3279
EP 3291
DI 10.1007/s11042-016-3715-5
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200007
DA 2024-07-18
ER

PT J
AU Yang, YT
   Xu, Z
   Liu, LY
   Sun, GZ
AF Yang, Yitao
   Xu, Zheng
   Liu, Liying
   Sun, Guozi
TI A security carving approach for AVI video based on frame size and index
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video carving; Fragmentation; Frame size; Index; AVI
AB Recovery of fragmented files is an important part of digital forensics. Video files are more likely to be fragmented since their sizes are relatively large that recovering video files without the file system information is meaningful. This paper presents a video recovery technique of a fragmented video file using the frame size information in every frame and the index. Many existing video recovery techniques attempt to recover videos using file system information or header/footer flag. These approaches may fail in the situations which the file system information is unknown or videos are fragmented. The proposed method addresses how to extract AVI file fragments from data images and map all the extracted fragments into original order. Experiments result show that mapping the AVI fragments according to the frame size information in every fragment and index is credible and the non-overwritten part of the fragmented video can be recovered using the method.
C1 [Yang, Yitao; Liu, Liying; Sun, Guozi] Nanjing Univ Posts & Telecommun, Sch Comp Sci & Technol, Sch Software, Nanjing, Jiangsu, Peoples R China.
   [Xu, Zheng] Minist Publ Secur, Res Inst 3, Shanghai, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Ministry of Public
   Security (China)
RP Sun, GZ (corresponding author), Nanjing Univ Posts & Telecommun, Sch Comp Sci & Technol, Sch Software, Nanjing, Jiangsu, Peoples R China.; Xu, Z (corresponding author), Minist Publ Secur, Res Inst 3, Shanghai, Peoples R China.
EM youngyt@njupt.edu.cn; xuzheng@shu.edu.cn; 1212042926@njupt.edu.cn;
   sun@njupt.edu.cn
CR [Anonymous], 2005, DFRWS
   [Anonymous], 2012, ACM Transactions on Storage (TOS), DOI DOI 10.1145/2078861.2078864
   [Anonymous], IEEE T NEURAL NETWOR
   Aronson L., 2011, Proceedings of the 2011 IEEE 35th IEEE Annual Computer Software and Applications Conference Workshops (COMPSACW 2011). Volume II: Workshops, P368, DOI 10.1109/COMPSACW.2011.68
   Billard D., 2010, P ACM S APPL COMP, P1579
   Carrier B., 2005, FILE SYSTEM FORENSIC, V3
   Fu ZJ, 2015, IEICE T COMMUN, VE98B, P190, DOI 10.1587/transcom.E98.B.190
   Garfinkel SL, 2007, DIGIT INVEST, V4, pS2, DOI 10.1016/j.diin.2007.06.017
   Hu CP, 2014, IEEE T EMERG TOP COM, V2, P376, DOI 10.1109/TETC.2014.2316525
   Memon N, 2006, IEEE T IMAGE PROCESS, V15, P385, DOI 10.1109/TIP.2005.863054
   Na GH, 2014, IEEE T IMAGE PROCESS, V23, P517, DOI 10.1109/TIP.2013.2285625
   Pal A, 2009, IEEE SIGNAL PROC MAG, V26, P59, DOI 10.1109/MSP.2008.931081
   Poisel Rainer, 2013, 2013 International Conference on Availability, Reliability and Security (ARES), P475, DOI 10.1109/ARES.2013.62
   Poisel R., 2011, Proceedings of the 2011 6th International Conference on IT Security Incident Management and IT Forensics (IMF 2011), P48, DOI 10.1109/IMF.2011.14
   Poisel R., 2011, Journal of Wireless Mobile Networks, Ubiquitous Computing, and Dependable Applications, V2, P42
   Richard G, 2007, INT FED INFO PROC, V242, P217
   Sencar HT, 2009, STAT SCI INTERDISC R, V3, P325
   Steinebach M, 2015, ADV MULTIMEDIA FILE
   Thing V. L. L., 2011, Proceedings of the 2011 Seventh International Conference on Computational Intelligence and Security (CIS 2011), P793, DOI 10.1109/CIS.2011.180
   Xu Z, 2015, J SYST SOFTWARE, V102, P217, DOI 10.1016/j.jss.2014.07.024
   Zhang Z, 2012, INT J DIGIT CONTENT, V6
   Zhang Z., 2011, INT J DIGIT CONTENT, V5, P255, DOI DOI 10.4156/JDCTA.VOL5.ISSUE3.26
NR 22
TC 12
Z9 12
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3293
EP 3312
DI 10.1007/s11042-016-3716-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200008
DA 2024-07-18
ER

PT J
AU Ali, HH
   Kolivand, H
   Sunar, MS
AF Ali, Hatam H.
   Kolivand, Hoshang
   Sunar, Mohd Shahrizal
TI Soft bilateral filtering shadows using multiple image-based algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Soft shadows; Antialiasing shadow maps; Bilateral filtering; Multiple
   image-based shadows
AB This study introduces Soft Bilateral Filtering Shadows method of dynamic scenes, which uses multi-matrices of the light sample points due to lack realism in soft shadows generation in real time. While geometry-based shadow algorithm requires one pass per polygon for rendering shadow that requires time-consuming, the adopted shadow map algorithm needs a single rendering pass for each sample point of the light source to generate shadow at low cost. This method renders a complex scenes and accurately eliminating the inherent deficiencies in shadow maps. In order to compute shadow maps, view matrices were used for each sample point of the extended light source. Then penumbra region was used for interpolation based on bilateral filtering to create the soft shadows. They depend on multiple shadow maps which provide antialiasing shadow maps. The method uses fragment shader for rendering multiple shadow maps with penumbra and umbra regions. The main contribution of this article is introducing interpolation bilaterally of image-based shadows. This method makes the most effect of the computation significantly appear at the edges of the penumbra region. Furthermore, the filtering allows to obtain on the soft shadow marvelously at the lowest number possible of the light sample points. The generated soft shadows have good performance and high quality therefore, they are suitable for interactive applications.
C1 [Ali, Hatam H.; Kolivand, Hoshang; Sunar, Mohd Shahrizal] UTM IRDA Digital Media Ctr Univ Teknol Malaysia, MaGIC X Media & Games Innovat Ctr Excellence, Skudai 81310, Johor, Malaysia.
C3 Universiti Teknologi Malaysia
RP Kolivand, H (corresponding author), UTM IRDA Digital Media Ctr Univ Teknol Malaysia, MaGIC X Media & Games Innovat Ctr Excellence, Skudai 81310, Johor, Malaysia.
EM ali_hattem@yahoo.com; hoshang@utm.my
RI Sunar, Mohd Shahrizal/AFQ-7366-2022; Kolivand, Hoshang/F-4736-2011; ali,
   hatem/ABB-4403-2020; Kolivand, Hoshang/B-2501-2016
OI Sunar, Mohd Shahrizal/0000-0002-0244-1622; Kolivand,
   Hoshang/0000-0001-5460-5679; Ali, Hatem Salama/0000-0002-7306-3454
FU MaGIC-X (Media and Games In-novation Centre of Excellence) UTM-IRDA
   Digital Media Centre Universiti Teknologi Malaysia [Vot.
   Q.J130000.2528.12H18 RUG, 81310]
FX This research was supported by Vot. Q.J130000.2528.12H18 RUG grant at
   MaGIC-X (Media and Games In-novation Centre of Excellence) UTM-IRDA
   Digital Media Centre Universiti Teknologi Malaysia 81310 Skudai Johor
   MALAYSIA.
CR Aila T., 2004, ALIAS FREE SHADOW MA
   Arvo J., 2007, Journal of Graphics Tools, V12, P47
   Arvo J, 2004, COMPUT GRAPH FORUM, V23, P271, DOI 10.1111/j.1467-8659.2004.00758.x
   Atty L, 2006, COMPUT GRAPH FORUM, V25, P725, DOI 10.1111/j.1467-8659.2006.00995.x
   Cai XH, 2006, COMPUT GRAPH FORUM, V25, P15, DOI 10.1111/j.1467-8659.2006.00915.x
   Chan E., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P208
   Crow F.C., 1977, ACM SIGGRAPH COMPUT, V11, P242, DOI [DOI 10.1145/965141.563901, DOI 10.1145/563858.563901]
   de Boer WillemH., 2006, J GRAPHICS TOOLS, V11, P59
   Eisemann E, 2006, SIBGRAPI, P155
   Fernando Randima., 2005, SIGGRAPH 05, P35
   Guennebaud Gael., 2006, Proceedings of the Eurographics Symposium on Rendering, P227
   JOHNSON GS, 2004, IRREGULAR Z BUFFER I
   Kolivand Hoshang, 2011, International Journal of New Computer Architectures and their Applications, V1, P275
   Kolivand H, 2015, MULTIMED TOOLS APPL, V74, P7461, DOI 10.1007/s11042-014-1987-1
   Kolivand H, 2012, INT J INNOV COMPUT I, V8, P7169
   Lauritzen Andrew., 2008, P GRAPHICS INTERFACE, P139
   Lawlor OS, 2006, CGVR, P111
   Lefohn AE, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1289603.1289611
   Lili W, 2010, ED INF TECHN ICEIT 2, V1, pV1
   Reeves W. T., 1987, SIGGRAPH Comput. Graph., P283
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang LL, 2014, COMPUT GRAPH FORUM, V33, P264, DOI 10.1111/cgf.12348
   Williams L., 1978, P ANN C COMP GRAPH I, P270
   Wimmer Michael, 2004, RENDERING TECHNIQUES
   Wyman C., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P202
NR 25
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2591
EP 2608
DI 10.1007/s11042-016-3254-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000044
DA 2024-07-18
ER

PT J
AU Bashir, S
AF Bashir, Shariq
TI Ranking entities on the basis of users' opinions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Opinion-Based Entity ranking; Social web; Opinion analysis; Machine
   learning; Information retrieval
AB Online opinions are one of the most important sources of information on which users base their purchasing decisions. Unfortunately, the large quantity of opinions makes it difficult for an individual to consume in a reasonable amount of time. Unlike standard information retrieval problems, the task here is to retrieve entities whose relevance is dependent upon other people's opinions regarding the entities and how well those sentiments match the user's own preferences. We propose novel techniques that incorporate aspect subjectivity measures into weighting the relevance of opinions of entities based on a user's query keywords. We calculate these weights using sentiment polarity of terms found proximity close to keywords in opinion text. We have implemented our techniques, and we show that these improve the overall effectiveness of the baseline retrieval task. Our results indicate that on entities with long opinions our techniques can perform as good as state-of-the-art query expansion approaches.
C1 [Bashir, Shariq] Bahria Univ, Dept Comp Sci, Islamabad, Pakistan.
   [Bashir, Shariq] MA Jinnah Univ, Fac Comp, Dept Comp Sci, Islamabad, Pakistan.
C3 Mohammad Ali Jinnah University
RP Bashir, S (corresponding author), Bahria Univ, Dept Comp Sci, Islamabad, Pakistan.; Bashir, S (corresponding author), MA Jinnah Univ, Fac Comp, Dept Comp Sci, Islamabad, Pakistan.
EM shariq.bashir@bui.edu.pk
RI Bashir, Shariq/ABD-4472-2021
OI Bashir, Shariq/0000-0002-0789-4962; Bashir, Shariq/0009-0004-6558-3427
CR Amati G, 2002, ACM T INFORM SYST, V20, P357, DOI 10.1145/582415.582416
   [Anonymous], 2011, P 4 ACM INT C WEB SE, DOI DOI 10.1145/1935826.1935884
   [Anonymous], 2008, Proceedings of ACL-08: HLT
   [Anonymous], 2009, P IT T
   [Anonymous], 2004, COLING
   [Anonymous], 2004, 20 INT C COMP LING G
   [Anonymous], 2009, Faceted Search
   Baccianella S, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION
   Baccianella S, 2009, LECT NOTES COMPUT SC, V5478, P461, DOI 10.1007/978-3-642-00958-7_41
   Balog K, 2012, FOUND TRENDS INF RET, V6, P127, DOI 10.1561/1500000024
   Bo Pang, 2008, Foundations and Trends in Information Retrieval, V2, P1, DOI 10.1561/1500000001
   Bobicev Victoria, 2012, Advances in Artificial Intelligence. Proceedings 25th Canadian Conference on Artificial Intelligence, Canadian AI 2012, P37, DOI 10.1007/978-3-642-30353-1_4
   Choi Jaehoon., 2012, CIKM, P1935
   Fang H, 2007, LECT NOTES COMPUT SC, V4425, P418
   Ganesan K., 2012, P 21 INT C COMPANION, P345
   Ganesan K., 2013, THESIS
   Ganesan K, 2012, INFORM RETRIEVAL, V15, P116, DOI 10.1007/s10791-011-9174-8
   Goeuriot L., 2012, Proceedings of the 2nd ACM SIGHIT International Health Informatics Symposium, P219, DOI [10.1145/2110363.2110390, DOI 10.1145/2110363.2110390]
   Hamouda A., 2012, ONLINE J COMPUT SCI, V2
   Heerschop B, 2011, LECT NOTES BUS INF P, V87, P185
   Koren Jonathan, 2008, P 17 INT C WORLD WID, P477, DOI DOI 10.1145/1367497.1367562
   Lee L, P 42 ANN M ASS COMP, P271, DOI 10.3115/1218955.1218990
   Liu B, 2010, CH CRC MACH LEARN PA, P627
   Liu J., 2007, P 2007 JOINT C EMP M, P334
   Mullen T., 2004, P 2004 C EMP METH NA
   Ounis I., 2006, P TREC 06
   Pan SinnoJialin., 2010, P 19 INT C WORLD WID, P751, DOI DOI 10.1145/1772690.1772767
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Popescu A.-M., 2005, P C HUM LANG TECHN E, P339, DOI DOI 10.3115/1220575.1220618
   Robertson S. E., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P232
   Saggion H, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION
   Snyder B., 2007, proceedings of the Joint Conference of the North American Chapter of the Association for Computational Linguistics and Human Language Technologies, P300
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Turney PD, 2003, ACM T INFORM SYST, V21, P315, DOI 10.1145/944012.944013
   Wang H, 2010, Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P783, DOI [DOI 10.1145/1835804.1835903, 10.1145/1835804.1835903]
   Ye Q, 2009, EXPERT SYST APPL, V36, P6527, DOI 10.1016/j.eswa.2008.07.035
   Yi JH, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P427, DOI 10.1109/ICDM.2003.1250949
   Yu J, 2011, P 49 ANN M ASS COMP, P1496, DOI DOI 10.1109/CC.2013.6488828
   Zhai C, 2002, THESIS
NR 39
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 59
EP 81
DI 10.1007/s11042-015-3022-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000004
DA 2024-07-18
ER

PT J
AU Hsieh, CW
   Liu, HC
   Jong, TL
   Chen, CY
AF Hsieh, Chi-Wen
   Liu, Hsian-Chuan
   Jong, Tai-Lang
   Chen, Chih-Yen
TI A hierarchical algorithm for phalangeal and epiphyseal/metaphyseal
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bone age; Greulich and Pyle (GP); Tanner-Whitehouse (TW);
   Epiphyseal/metaphyseal region of interest (EMROI); Sum-variance (SV)
ID BONE-AGE ASSESSMENT; CARPAL
AB Computerized bone age assessment was widely studied for the physicians and radiologists to evaluate children with endocrinological disorders, growth retardation and treatment monitoring. Unfortunately, the morphological assessment of phalanges and epiphyseal/metaphyseal region (EMROIs) in hand radiogram with non-uniform intensity or full of the noise is intricacies and hardly to be segmented, and which was also time-consuming. So, a new segmentation technique for handy skeleton was proposed. The first step, the properties of position and brightness on phalanges and EMORIs are analyzed by a series of image preprocessing procedures. Next, 14 EMORIs of five phalanges were examined by the sum-variance (SV) scheme for the 100 boys and 100 girls. Last, four statistical indices are used to evaluate the segmentation. The experiment performance is shown the better result than the gradient vector flow (GVF) snake, and the approximation of adaptive two-means clustering. The study showed the proposed hierarchical algorithm for the extraction and segmentation of phalangeal bone regions of interests (PROIs) and EMROIs are effective, especially for the EMROIs segmentation by using the proposed algorithm.
C1 [Hsieh, Chi-Wen] Natl Chiayi Univ, Dept Elect Engn, 300 Syuefu Rd, Chiayi 60004, Taiwan.
   [Liu, Hsian-Chuan] Taipei Vet Gen Hosp, Dept Radiol, 201,Sec 2,Shih Pai Rd, Taipei 112, Taiwan.
   [Jong, Tai-Lang] Natl Tsing Hua Univ, Dept Elect Engn, 101,Sect 2,Kuang Fu Rd, Hsinchu 30013, Taiwan.
   [Chen, Chih-Yen] Instrument Technol Res Ctr, Natl Appl Res Labs, 20 R&D Rd 6,Hsinchu Sci Pk, Hsinchu 300, Taiwan.
C3 National Chiayi University; Taipei Veterans General Hospital; National
   Tsing Hua University; National Applied Research Laboratories - Taiwan
RP Chen, CY (corresponding author), Instrument Technol Res Ctr, Natl Appl Res Labs, 20 R&D Rd 6,Hsinchu Sci Pk, Hsinchu 300, Taiwan.
EM chiwen@mail.ncyu.edu.tw; tcliu0615@gmail.com; tljong@mx.nthu.edu.tw;
   chihyenorama@gmail.com
CR [Anonymous], 2001, GOVT OPPOSITION
   Bhan A, 2014, 2014 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P711, DOI 10.1109/SPIN.2014.6777047
   BUCKLER JMH, 1983, ARCH DIS CHILD, V58, P761, DOI 10.1136/adc.58.10.761
   Chai HY, 2013, BIOMED ENG ONLINE, V12, DOI 10.1186/1475-925X-12-27
   Davis LM, 2012, INT J NEURAL SYST, V22, DOI 10.1142/S0129065712500207
   Ferdinand H, 2014, BILDVERARBEITUNG MED
   Giordano D, 2010, IEEE T INSTRUM MEAS, V59, P2539, DOI 10.1109/TIM.2010.2058210
   Greulich WW., 1971, RADIOGRAPHIC ATLAS S
   Hahmann F, 2013, LECT NOTES COMPUT SC, V8142, P313, DOI 10.1007/978-3-642-40602-7_34
   Harmsen M, 2013, IEEE J BIOMED HEALTH, V17, P190, DOI 10.1109/TITB.2012.2228211
   Hsieh CW, 2012, MEAS SCI REV, V12, P21, DOI 10.2478/v10048-012-0003-z
   Hsieh CW, 2007, MED BIOL ENG COMPUT, V45, P283, DOI 10.1007/s11517-006-0155-9
   Hsieh CW, 2011, OPT ENG, V50, DOI 10.1117/1.3613940
   LEE JS, 1981, COMPUT VISION GRAPH, V15, P380, DOI 10.1016/S0146-664X(81)80018-4
   Lehmann TM, 2005, PROC SPIE, V5747, P546, DOI 10.1117/12.595468
   Lin HH, 2012, PATTERN RECOGN, V45, P322, DOI 10.1016/j.patcog.2011.06.003
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pietka E, 2001, IEEE T MED IMAGING, V20, P715, DOI 10.1109/42.938240
   POZNANSKI AK, 1978, RADIOLOGY, V129, P661, DOI 10.1148/129.3.661
   Ruppertshofen H., 2013, BOD BOOKS DEMAND
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Thangam P, 2013, INT J COMPUT COMMUN, V8, P153
   Thodberg HH, 2009, IEEE T MED IMAGING, V28, P52, DOI 10.1109/TMI.2008.926067
NR 23
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 3047
EP 3063
DI 10.1007/s11042-016-3278-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000065
DA 2024-07-18
ER

PT J
AU Thabit, R
   Khoo, BE
AF Thabit, Rasha
   Khoo, Bee Ee
TI Medical image authentication using SLT and IWT schemes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image authentication; ROI-based watermarking; Slantlet transform
   (SLT); Integer wavelet transform (IWT)
ID ROBUST REVERSIBLE WATERMARKING; TAMPER DETECTION; REGION
AB Over the years, different watermarking techniques have been used for medical image authentication purposes. Some techniques have been presented to detect tampering in the medical image while others can also recover the tampered region after the tamper detection. Many of the previous medical image authentication schemes have successfully achieved their aims; however, the robustness of the authentication scheme against unintentional attacks has not been highlighted sufficiently. This paper presents a new medical image authentication scheme in which the medical image is divided into two regions (i.e., region of interest (ROI) and region of non-interest (RONI)). Then two watermarking methods based on Slantlet transform (SLT) are used to embed data in the ROI and the RONI. The proposed scheme can be used for tamper detection, localization, and recovery in addition to the data hiding. To generate the recovery information of the ROI, a new method has been proposed based on the integer wavelet transform (IWT) coefficients. The experiments that have been conducted to evaluate the proposed authentication scheme proved that it is efficient not only in achieving its main tasks that have been mentioned above but also in having robustness against unintentional attacks (i.e., JPEG compression, additive Gaussian noise (AGN), and salt-and-pepper noise) and that makes it more suitable for the practical applications.
C1 [Thabit, Rasha; Khoo, Bee Ee] Univ Sains Malaysia, Sch Elect & Elect Engn, Engn Campus, Perai 14300, Pulau Pinang, Malaysia.
C3 Universiti Sains Malaysia
RP Khoo, BE (corresponding author), Univ Sains Malaysia, Sch Elect & Elect Engn, Engn Campus, Perai 14300, Pulau Pinang, Malaysia.
EM beekhoo@usm.my
RI Thabit, Rasha/R-6766-2019; Thabit, Rasha/AGY-7754-2022; Khoo, Bee
   Ee/D-8730-2011
OI Thabit, Rasha/0000-0003-4141-5723; Khoo, Bee Ee/0000-0002-3492-2551
CR Abokhdair NO, 2013, 6 INT C INF TECHN IC
   Al-Qershi OM, 2011, J DIGIT IMAGING, V24, P114, DOI 10.1007/s10278-009-9253-1
   An LL, 2012, IEEE T IMAGE PROCESS, V21, P3598, DOI 10.1109/TIP.2012.2191564
   An LL, 2012, NEUROCOMPUTING, V77, P1, DOI 10.1016/j.neucom.2011.06.012
   [Anonymous], 2012, INT J EMERG TECHNOL
   [Anonymous], 2009, P INT C MED SYST ENG
   Chiang KH, 2008, J DIGIT IMAGING, V21, P77, DOI 10.1007/s10278-007-9012-0
   Giakoumaki A, 2006, MED BIOL ENG COMPUT, V44, P619, DOI 10.1007/s11517-006-0081-x
   Giakoumaki A, 2006, IEEE T INF TECHNOL B, V10, P722, DOI 10.1109/TITB.2006.875655
   Guo XT, 2009, J DIGIT IMAGING, V22, P53, DOI 10.1007/s10278-007-9043-6
   Kundur D., 1999, P IEEE
   Memon N., 2010, THESIS
   Memon NA, 2009, INT CONF INF COMMUN, P134
   Memon NA, 2011, INT J COMPUT MATH, V88, P265, DOI 10.1080/00207161003596690
   Mohammed R. T., 2012, 2012 IEEE Symposium on Industrial Electronics and Applications (ISIEA 2012), P281, DOI 10.1109/ISIEA.2012.6496644
   Mostafa Salwa A K, 2010, Open Biomed Eng J, V4, P93, DOI 10.2174/1874120701004010093
   Naseem MT., 2013, J BASIC APPL SCI RES, V3, P488
   Nayak J, 2004, Proceedings of the IEEE INDICON 2004, P147, DOI 10.1109/INDICO.2004.1497726
   Thabit R, 2015, DIGIT SIGNAL PROCESS, V38, P77, DOI 10.1016/j.dsp.2014.12.005
   Thabit R, 2014, J SYST SOFTWARE, V88, P74, DOI 10.1016/j.jss.2013.09.033
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Woo C.- S., 2005, APRS WORKSH DIG IM C, P43
   Wu JHK, 2008, J DIGIT IMAGING, V21, P59, DOI 10.1007/s10278-007-9011-1
   Zain JM, 2007, P ANN INT IEEE EMBS, P5662
   Zain Jasni M, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P3270
   Zain JM, 2007, INT J COMPUT SCI NET, V7, P19
NR 26
TC 31
Z9 31
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 309
EP 332
DI 10.1007/s11042-015-3055-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000014
DA 2024-07-18
ER

PT J
AU Tong, M
   Wang, HY
   Tian, WJ
   Yang, SL
AF Tong, Ming
   Wang, Houyi
   Tian, Weijuan
   Yang, Shulin
TI Action recognition new framework with robust 3D-TCCHOGAC and 3D-HOOFGAC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Dense trajectory; Optical flow; Dynamic descriptor;
   Static descriptor
ID MOTION
AB Action recognition has very high academic research value, potential commercial value and wide market application prospect in computer vision. In order to improve the action recognition accuracy, two kinds of dynamic descriptors based on dense trajectories are proposed in this paper. Firstly, to capture the local position information that action occurs, dense sampling in motion regions is done by constraining and clustering of optical flow. Secondly, the motion corners of object are selected as feature points which are then tracked to obtain motion trajectories. Finally, the gradient information and optical flow gradient information are extracted respectively in the video cube centered at the trajectories, then the auto-correlation and normalization processing are carried out on the two above information to obtain two dynamic descriptors named 3D histograms of oriented gradients in trajectory centered cube auto-correlation and 3D histograms of oriented optical flow gradients auto-correlation, which can resist a certain degree of interferences caused by camera motion and complex background. However, the diversity of realistic videos makes dynamic or static descriptors alone unable to achieve accurate action classification. A new framework is proposed, which makes the dynamic descriptors and static descriptors fuse and supplement mutually to further improve the action recognition accuracy. This paper adopts the leave-one-out cross validation on datasets of Weizmann and UCF-Sports with action recognition accuracy of 100 % and 96.00 %, and adopts the four-fold cross validation on datasets of KTH and YouTube with action recognition accuracy of 97.17 % and 88.23 %, which has the better performance over the references.
C1 [Tong, Ming; Wang, Houyi; Tian, Weijuan; Yang, Shulin] Xidian Univ, Sch Elect Engn, Xian, Peoples R China.
C3 Xidian University
RP Tong, M (corresponding author), Xidian Univ, Sch Elect Engn, Xian, Peoples R China.
EM mtong@xidian.edu.cn; wanghouyi_why@163.com; stayrealtian501@163.com;
   yang_shulin@163.com
RI Tian, Weijuan/ABC-3902-2021; Yang, Shulin/K-7072-2017
FU National Natural Science Foundation of China [61072110]; Science and
   Technology Overall Innovation Project of Shaanxi Province
   [2013KTZB03-03-03]
FX This work was supported in part by National Natural Science Foundation
   of China (Grant No. 61072110) and Science and Technology Overall
   Innovation Project of Shaanxi Province (Grant 2013KTZB03-03-03).
CR Harbi N, 2015, NEUROCOMPUTING, V161, P56, DOI 10.1016/j.neucom.2014.11.072
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], ARXIV150306917
   [Anonymous], ACS INT C COMP SYST
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Chaquet JM, 2013, COMPUT VIS IMAGE UND, V117, P633, DOI 10.1016/j.cviu.2013.01.013
   Cho J, 2014, PATTERN RECOGN, V47, P1813, DOI 10.1016/j.patcog.2013.12.004
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P226
   Everts I, 2013, PROC CVPR IEEE, P2850, DOI 10.1109/CVPR.2013.367
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Kliper-Gross O, 2012, LECT NOTES COMPUT SC, V7577, P256, DOI 10.1007/978-3-642-33783-3_19
   Knopp J, 2010, LECT NOTES COMPUT SC, V6316, P589, DOI 10.1007/978-3-642-15567-3_43
   Kobayashi T, 2012, PATTERN RECOGN LETT, V33, P1188, DOI 10.1016/j.patrec.2012.01.007
   Lee H, 2014, IEEE COMPUT SOC CONF, P365, DOI 10.1109/CVPRW.2014.60
   Liu JG, 2009, PROC CVPR IEEE, P1996
   Ma SG, 2015, PROC CVPR IEEE, P5024, DOI 10.1109/CVPR.2015.7299137
   Rodriguez M., 2008, P IEEE C COMPUTER VI
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang L, 2006, INT C PATT RECOG, P1266
   Xing D., 2014, Computer Vision - ACCV 2014 Workshops - Singapore, Singapore, November 1-2, 2014, Revised Selected Papers, Part I, V9008, P99, DOI DOI 10.1007/978-3-319-16628-58
   Yilmaz A, 2008, COMPUT VIS IMAGE UND, V109, P335, DOI 10.1016/j.cviu.2007.09.006
   Zhang H, 2014, PROC CVPR IEEE, P2067, DOI 10.1109/CVPR.2014.265
   Zhang ZM, 2008, LECT NOTES COMPUT SC, V5305, P817, DOI 10.1007/978-3-540-88693-8_60
NR 28
TC 6
Z9 7
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 3011
EP 3030
DI 10.1007/s11042-016-3279-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000063
DA 2024-07-18
ER

PT J
AU Chen, CH
   Wang, CC
   Yan, MC
AF Chen, Ching-Han
   Wang, Chien-Chun
   Yan, Miao-Chun
TI Robust tracking of multiple persons in real-time video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Background segmentation; PSO; Optimization
AB In this paper, we present a robust person tracking method that the particle swarm optimization (PSO) algorithm is used as the tracking strategy. The method is divided into two procedures: object/background segmentation and tracking. For object/background segmentation, we use the temporal differencing to detect the regions of interest. For tracking, the PSO algorithm is used for overcome the robustness problem in the high noisy background and multiple moving persons and/or under occlusion. The particles in PSO represent the position, width and height of the search window, and the fitness function is calculated by the distance of the color feature vector and the histogram intersection. When occluded, we add the motion vector plus the previous position of the tracking model. The particles fly around the search region to obtain an optimal match of the target. The experiments show that the proposed method can track the single person, multiple people even when occluded, and is more efficient and accurate than the conventional particle filter method.
C1 [Chen, Ching-Han; Wang, Chien-Chun; Yan, Miao-Chun] Natl Cent Univ, Dept CSIE, Taoyuan 320, Taiwan.
C3 National Central University
RP Chen, CH (corresponding author), Natl Cent Univ, Dept CSIE, Taoyuan 320, Taiwan.
EM pierre@csie.ncu.edu.tw
RI Chien-Chun, Wang/U-4568-2019
OI Chien-Chun, Wang/0000-0002-6602-2048; Chen,
   Ching-Han/0000-0003-4560-0889
FU Ministry of Science and Technology of Taiwan (R.O.C.) [NSC
   103-2220-E-008 -003]
FX The authors are also grateful for the funding supported by the Ministry
   of Science and Technology of Taiwan (R.O.C.) under Grant No. NSC
   103-2220-E-008 -003.
CR [Anonymous], 2014, ADV TRENDS SOFT COMP
   Chan KL, 2015, MACH VISION APPL, V26, P723, DOI 10.1007/s00138-015-0696-8
   Chen CH, 2011, COMM COM INF SC, V166, P267
   Cuevas EV, 2005, TECHNICAL REPORT
   Djaghloul H, 2010, LECT NOTES ARTIF INT, V6076, P48, DOI 10.1007/978-3-642-13769-3_6
   Hayashi Y, 2008, LECT NOTES COMPUT SC, V5001, P302
   Hu M, 2004, INT C PATT RECOG, P724, DOI 10.1109/ICPR.2004.1334361
   Jalal AS, 2011, COMM COM INF SC, V191, P516
   Liu YWWZJ, 2008, P 11 JOINT C INF SCI
   Pan I, 2013, MEMET COMPUT, V5, P141, DOI 10.1007/s12293-013-0107-5
   Rymut B, 2014, LECT NOTES COMPUT SC, V8384, P458, DOI 10.1007/978-3-642-55224-3_43
   Sulistijono Indra Adji, 2007, SICE '07. 46th SICE Annual Conference, P604
   Sulistijono IAaNK, 2007, CEC 2007, V2007, P1535
   Sulistijono IA, 2007, J ADV COMPUT INTELL, V11, P681, DOI 10.20965/jaciii.2007.p0681
NR 14
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16683
EP 16697
DI 10.1007/s11042-016-3890-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700080
DA 2024-07-18
ER

PT J
AU Choi, J
   Kim, C
AF Choi, Jiwon
   Kim, Changick
TI A framework for automatic static and dynamic video thumbnail extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video thumbnail; Video keyframe extraction; Thumbnail sequence
   extraction; Content-aware video thumbnailing
AB Video thumbnails enable users to see quick snapshots of video collections. To display the video thumbnails, the first frame or a frame selected by using simple low level features in each video clip has been set to the default thumbnail for the sake of computational efficiency and implementation simplicity. However, such methods often fail to represent the gist of the clip. To overcome this limitation, we present a new framework for both static and dynamic video thumbnail extraction. First, we formulate energy functions using the features which incorporate mid-level information to obtain superior thumbnailing. Since it is considered that frames whose layouts are similar to others in the clip are relevant in video thumbnail extraction, scene layouts are also considered in computing overall energy. For dynamic thumbnail generation, a time slot is determined by finding the duration showing the minimum energy. Experimental results show that the proposed method achieves comparable performance on a variety of challenging videos, and the subjective evaluation demonstrates the effectiveness of our method.
C1 [Choi, Jiwon; Kim, Changick] Korea Adv Inst Sci & Technol, Dept Elect Engn, Daejeon 305701, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Kim, C (corresponding author), Korea Adv Inst Sci & Technol, Dept Elect Engn, Daejeon 305701, South Korea.
EM g1choi@kaist.ac.kr; changick@kaist.ac.kr
RI Kim, Changick/C-1779-2011
CR Al-Hajri A, 2014, P 2014 GRAPH INT C, P123
   Almeida J, 2012, PATTERN RECOGN LETT, V33, P397, DOI 10.1016/j.patrec.2011.08.007
   Benini S., 2007, P 8 INT WORKSH IM AN, P6
   Choi J, 2014, IEEE SIGNAL PROC LET, V21, P957, DOI 10.1109/LSP.2014.2321751
   Christel MG, 2006, EL IM 2006 INT SOC O
   Chunxi Liu, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2449, DOI 10.1109/ICIP.2011.6116155
   Cotsaces C, 2006, IEEE SIGNAL PROC MAG, V23, P28, DOI 10.1109/MSP.2006.1621446
   Craggs B, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1217
   Gao YL, 2009, IEEE IMAGE PROC, P4333
   Gong YH, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1559, DOI 10.1109/ICME.2000.871066
   Jiang J, 2010, P 3 INT WORKSH AUT I, P9
   Jiang JF, 2011, INT CONF ACOUST SPEE, P1417
   Lee KJ, 2014, IEEE I C NETW INFRAS, P236, DOI 10.1109/ICNIDC.2014.7000301
   Li HL, 2007, IEEE T CIRC SYST VID, V17, P1742, DOI 10.1109/TCSVT.2007.903326
   Ma Y.-F., 2002, ACM MULTIMEDIA, P533
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Ngo CW, 2005, IEEE T CIRC SYST VID, V15, P296, DOI 10.1109/TCSVT.2004.841694
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Sundaramurthy S. C., 2011, SAM 11, P1
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P975, DOI 10.1109/TMM.2012.2185041
   Wang T, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1479
   Wang YZ, 2013, J NANOMATER, V2013, DOI 10.1155/2013/169405
   Weigang Zhang, 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P343, DOI 10.1109/IIH-MSP.2012.89
   Yong SP, 2013, MULTIMED TOOLS APPL, V62, P359, DOI 10.1007/s11042-011-0902-2
   Zhang W, 2013, MULTIMED TOOLS APPL, P1
NR 28
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15975
EP 15991
DI 10.1007/s11042-015-2909-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700049
DA 2024-07-18
ER

PT J
AU Choros, K
AF Choros, Kazimierz
TI Weighted indexing of TV sports news videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based video indexing; Sports videos; Video retrieval; Video
   structures; Video structural units; Weighted indexing; Weighting
   measures; Temporal aggregation; TV sports news; TV broadcast news;
   Sports news categorization
ID CLASSIFICATION
AB The paper proposes measures for weighted indexing of sports news videos. The content-based analyses of sports news videos lead to the classification of frames or shots into sports categories. A set of sports categories reported in a given news video can be used as a video representation in visual information retrieval system. However, such an approach does not take into account how many sports events of a given category have been reported and how long these events have been presented in news for televiewers. Weighting of sports categories in a video representation reflecting their importance in a given video or in a whole video data base would be desirable. The effects of applying the proposed measures have been demonstrated in a test video collection. The experiments and evaluations performed on this collection have also shown that we do not need to apply perfect content-based analyses to ensure proper weighted indexing of sports news videos. It is sufficient to recognize the content of only some frames and to determine the number of shots, scenes or pseudo-scenes detected in temporal aggregation process, or even only the number of events of a given sports category in a sports news video being indexed.
C1 [Choros, Kazimierz] Wrocaw Univ Technol, Dept Informat Syst, Wyb Wyspianskiego 27, PL-50370 Wroclaw, Poland.
RP Choros, K (corresponding author), Wrocaw Univ Technol, Dept Informat Syst, Wyb Wyspianskiego 27, PL-50370 Wroclaw, Poland.
EM kazimierz.choros@pwr.edu.pl
RI Choroś, Kazimierz/ABH-9115-2022
CR Albertson D, 2012, J INF SCI, V38, P501, DOI 10.1177/0165551512461886
   [Anonymous], J REAL TIME IMAGE PR
   [Anonymous], P 1 INT WORKSH INT M
   [Anonymous], MACH VIS IM PROC MVI
   Asghar Muhammad Nabeel, 2014, International Journal of Computer and Information Technology, V3, P148
   Ballan L, 2011, MULTIMED TOOLS APPL, V51, P279, DOI 10.1007/s11042-010-0643-7
   Bouchekif Abdessalam, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P7113, DOI 10.1109/ICASSP.2014.6854980
   Brezeale D, 2008, IEEE T SYST MAN CY C, V38, P416, DOI 10.1109/TSMCC.2008.919173
   Choi J., 2008, ACM ICMR, P291
   Choros Kazimierz, 2012, International Journal of Intelligent Information and Database Systems, V6, P451, DOI 10.1504/IJIIDS.2012.049306
   Choros K, 2013, LECT NOTES ARTIF INT, V8083, P487
   Choros K, 2013, INT SYMP IMAGE SIG, P147
   Choros K, 2010, LECT NOTES ARTIF INT, V6086, P120, DOI 10.1007/978-3-642-13529-3_14
   Duan LY, 2005, IEEE T MULTIMEDIA, V7, P1066, DOI 10.1109/TMM.2005.858395
   Hopfgartner F, 2012, MULTIMEDIA COMPUT CO, P309
   Hopfgartner F, 2010, LECT NOTES COMPUT SC, V5916, P336, DOI 10.1007/978-3-642-11301-7_35
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   Jang S, 2006, 2006 INTERNATIONAL CONFERENCE ON HYBRID INFORMATION TECHNOLOGY, VOL 2, PROCEEDINGS, P745
   Lang CY, 2009, PROCEEDINGS OF THE 2009 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND NATURAL COMPUTING, VOL I, P336, DOI 10.1109/CINC.2009.220
   Manning C. D., 2008, INTRO INFORM RETRIEV
   Panagiotakis C, 2008, INT J PATTERN RECOGN, V22, P1187, DOI 10.1142/S0218001408006752
   Robertson S, 2004, J DOC, V60, P503, DOI 10.1108/00220410410560582
   Wang ZY, 2013, MULTIMED TOOLS APPL, V67, P607, DOI 10.1007/s11042-012-1060-x
   Yan R, 2007, INFORM RETRIEVAL, V10, P445, DOI 10.1007/s10791-007-9031-y
NR 24
TC 2
Z9 2
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 16923
EP 16942
DI 10.1007/s11042-015-2964-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600010
DA 2024-07-18
ER

PT J
AU Jeong, CW
   Kim, WH
   Lypengleang, S
   Jeong, YS
   Joo, SC
   Yoon, KH
AF Jeong, Chang-Won
   Kim, Woo-Hong
   Lypengleang, Seang
   Jeong, Young-Sik
   Joo, Su-Chong
   Yoon, Kwon-Ha
TI The development of a medical image information system environment using
   data synchronization based on cloud computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud computing; Mobile computing; Medical image synchronization;
   Wireless communication
ID MANAGEMENT
AB This paper describes the medical image information system environment for medical image share. The external interface of this system used a cloud service and we adapted the devices for connections with PACS and smart devices. One problem with this type of approach is the accumulated network latency that can arise from such a deployment. For this reason, we suggested a medical image information system environment using data synchronization methods. Our approach is designed as synchronization methods using detection of creation image data on components of system. Also, we used the cloud computing environment, which reduced the number of high-latency image transmissions. Finally, we show the data synchronization process of the system with imaging application services based on a cloud-computing service. Also, we evaluated the response time to compare to mobile PACS. The experimental results show that our system outperforms mobile PACS. As results, our approach is shown to deliver on par or even better results.
C1 [Jeong, Chang-Won] Wonkwang Univ, Imaging Sci Based Lung & Bone Dis Res Ctr, 460 Iksandeaero, Iksan 570749, Jeonbuk, South Korea.
   [Kim, Woo-Hong; Lypengleang, Seang] Wonkwang Univ, Dept Comp Engn, 460 Iksandeaero, Iksan, Jeonbuk, South Korea.
   [Jeong, Young-Sik] Dongguk Univ, Dept Multimedia Engn, Seoul, South Korea.
   [Joo, Su-Chong] Wonkwang Univ, Dept Comp Engn, 460 Iksandeaero, Iksan 570749, Jeonbuk, South Korea.
   [Yoon, Kwon-Ha] Wonkwang Univ, Sch Med, Dept Radiol, 460 Iksandeaero, Iksan 570749, Jeonbuk, South Korea.
   [Joo, Su-Chong; Yoon, Kwon-Ha] Wonkwang Univ, Grad Sch, Program BK21plus, 460 Iksandeaero, Iksan 570749, Jeonbuk, South Korea.
   [Joo, Su-Chong; Yoon, Kwon-Ha] Wonkwang Univ, Grad Sch, Dept Smart Life Care Convergence, 460 Iksandeaero, Iksan 570749, Jeonbuk, South Korea.
C3 Wonkwang University; Wonkwang University; Dongguk University; Wonkwang
   University; Wonkwang University; Wonkwang University; Wonkwang
   University
RP Joo, SC (corresponding author), Wonkwang Univ, Dept Comp Engn, 460 Iksandeaero, Iksan 570749, Jeonbuk, South Korea.; Yoon, KH (corresponding author), Wonkwang Univ, Sch Med, Dept Radiol, 460 Iksandeaero, Iksan 570749, Jeonbuk, South Korea.
EM mediblue@wku.ac.kr; akiba_r@wku.ac.kr; pengleang@wku.ac.kr;
   ysjeong2k@gmail.com; scjoo@wku.ac.kr; khy1646@wku.ac.kr
FU Korean Health Technology R & D Project, Ministry of Health & Welfare,
   Republic of Korea [A120152]
FX This study was supported by a grant of the Korean Health Technology R &
   D Project, Ministry of Health & Welfare, Republic of Korea (A120152).
CR Silva LAB, 2012, INT J COMPUT ASS RAD, V7, P349, DOI 10.1007/s11548-011-0625-x
   Bellini P, 2012, MULTIMED TOOLS APPL, V58, P41, DOI 10.1007/s11042-010-0684-y
   Chun SM, 2014, J HEALTHC ENG, V5, P185, DOI 10.1260/2040-2295.5.2.185
   Das S, 2013, COMPUT METH PROG BIO, V111, P662, DOI 10.1016/j.cmpb.2013.05.027
   Della Vecchia G, 2012, MULTIMED TOOLS APPL, V59, P341, DOI 10.1007/s11042-010-0695-8
   Hussain R, 2014, J INF PROCESS SYST, V10, P103, DOI 10.3745/JIPS.2014.10.1.103
   Jeong CW, 2014, J DIGIT IMAGING, V27, P443, DOI 10.1007/s10278-013-9659-7
   Joo SC, 2013, TELECOMMUN SYST, V52, P2375, DOI 10.1007/s11235-011-9550-0
   Kovachev D, 2014, MULTIMED TOOLS APPL, V70, P977, DOI 10.1007/s11042-012-1100-6
   Lee HJ, 2010, J DIGIT IMAGING, V23, P185, DOI 10.1007/s10278-008-9174-4
   Lee SH, 2013, J INF PROCESS SYST, V9, P287, DOI 10.3745/JIPS.2013.9.2.287
   Lee WJ, 2005, J DIGIT IMAGING, V18, P169, DOI 10.1007/s10278-005-5171-z
   Nagy PG, 2003, RADIOGRAPHICS, V23, P795, DOI 10.1148/rg.233025114
   O'Sullivan D, 2011, MULTIMED TOOLS APPL, V54, P473, DOI 10.1007/s11042-010-0548-5
   Pan MS, 2014, MULTIMED TOOLS APPL, V70, P1585, DOI 10.1007/s11042-012-1180-3
   Patapoutian A, 2006, IEEE T SIGNAL PROCES, V54, P1494, DOI 10.1109/TSP.2006.870587
   Randhawa S, 2008, NEW ENGL J MED, V358, P970, DOI 10.1056/NEJMc086018
   Rosenthal A, 2010, J BIOMED INFORM, V43, P342, DOI 10.1016/j.jbi.2009.08.014
   Sanderson R, 2013, D LIB MAGAZINE, V19, P4
   Seenivasagam V, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/516465
   Siddiqui Z, 2014, J MED SYST, V38, DOI 10.1007/s10916-013-9997-5
   Stantchev V, 2014, SCI WORLD J, DOI 10.1155/2014/692619
   Tartarisco G, 2012, COMPUT COMMUN, V35, P1296, DOI 10.1016/j.comcom.2011.11.015
   Volpe G, 2014, AM J HEALTH-SYST PH, V71, P675, DOI 10.2146/ajhp130286
   Westbrook JI, 2013, J AM MED INFORM ASSN, V20, P1150, DOI 10.1136/amiajnl-2012-001414
   Yang CT, 2010, FUTURE GENER COMP SY, V26, P1127, DOI 10.1016/j.future.2010.05.013
NR 26
TC 9
Z9 9
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15479
EP 15492
DI 10.1007/s11042-015-2506-8
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700022
DA 2024-07-18
ER

PT J
AU Paudyal, P
   Battisti, F
   Carli, M
AF Paudyal, Pradip
   Battisti, Federica
   Carli, Marco
TI Impact of video content and transmission impairments on quality of
   experience
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quality of Experience (QoE); Video content information; Transmission
   impairments; Mean Opinion Score (MOS); Video transmission
ID QOE; MODEL
AB The analysis of the impact of video content and transmission impairments on Quality of Experience (QoE) is a relevant topic for the robust design and adaptation of multimedia infrastructures, services, and applications. The goal of this paper is to study the impact of video content on QoE for different levels of impairments. In more details, this contribution aims at i) the study of the impact of delay, jitter, packet loss, and bandwidth on QoE, ii) the analysis of the impact of video content on QoE, and iii) the evaluation of the relationship between content related parameters (spatial-temporal perceptual information, motion, and data rate) and the QoE for different levels of impairments.
C1 [Paudyal, Pradip; Battisti, Federica; Carli, Marco] Univ Rome Tre, Dept Engn, Via Vito Volterra,62, I-00146 Rome, Italy.
C3 Roma Tre University
RP Paudyal, P (corresponding author), Univ Rome Tre, Dept Engn, Via Vito Volterra,62, I-00146 Rome, Italy.
EM pradip.paudyal@uniroma3.it; federica.battisti@uniroma3.it;
   marco.carli@uniroma3.it
RI Carli, Marco/B-7111-2013
OI Paudyal, Pradip/0000-0003-4685-6712; Battisti,
   Federica/0000-0002-0846-5879; Carli, Marco/0000-0002-7489-3767
CR [Anonymous], 2006, ITU-T Recommendation H.323 in Packet-based multimedia communications systems
   [Anonymous], IMPACT JITTER JERKIN
   [Anonymous], IEEE NETWORKS
   [Anonymous], 2012, P SPIE HUMAN VISION
   [Anonymous], MULTIM TOOLS APPL
   [Anonymous], ITU T STUD GROUP 2 R
   [Anonymous], SUBJECTIVE EVALUATIO
   [Anonymous], 2012, EUROPEAN NETWORK QUA
   [Anonymous], 2014, M22900 ITUR
   [Anonymous], ITU T STUD GROUP 9 R
   [Anonymous], ASSESSING IMPACT LAT
   [Anonymous], 2004, P IEEE PACK VID IRV
   [Anonymous], 2012, METH SUBJ ASS QUAL T
   [Anonymous], FOR METH 2012 2017
   [Anonymous], MED PLAYER
   [Anonymous], 103210 ETSI TR
   [Anonymous], GLOB MOB DAT TRAFF
   [Anonymous], 2014, Multimedia and Expo (ICME), 2014 IEEE International Conference on
   Battisti F, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-13
   Cermak G., 2005, Proceedings of the First International Workshop on Video Processing and Quality Metrics for Consumer Electronics, P1
   Chen YJ, 2015, IEEE COMMUN SURV TUT, V17, P1126, DOI 10.1109/COMST.2014.2363139
   Claypool M., 1999, ACM INT C MULTIMEDIA, P115
   Culibrk D, 2011, IEEE T IMAGE PROCESS, V20, P948, DOI 10.1109/TIP.2010.2080279
   de la Cruz Ramos Pedro, 2010, Proceedings of the Fifth International Conference on Digital Telecommunications (ICDT 2010), P128, DOI 10.1109/ICDT.2010.31
   De Simone F, 2011, EURASIP J IMAGE VIDE, DOI 10.1155/2011/190431
   Espina F, 2014, MULTIMED TOOLS APPL, V72, P361, DOI 10.1007/s11042-012-1344-1
   Fliegel K., 2014, Qualinet multimedia databases v5. 5
   Gulliver SR, 2007, IEEE T BROADCAST, V53, P449, DOI 10.1109/TBC.2007.896955
   Hemminger Stephen., 2005, LINUX C, P18
   Hogg R. V., 1987, ENG STAT
   Hussain S, 2013, UKSIM EURO SYMP COMP, P629, DOI 10.1109/EMS.2013.105
   Kang YQ, 2013, IEEE INT CONF COMMUN, P264, DOI 10.1109/ICCChina.2013.6671126
   Minhas T. Nawaz, 2012, 2012 Proceedings of the 19th International Packet Video Workshop (PV 2012), P83, DOI 10.1109/PV.2012.6229747
   Nightingale J, 2014, IEEE T CONSUM ELECTR, V60, P242, DOI 10.1109/TCE.2014.6852000
   Paudyal Pradip, 2014, 2014 5 EUR WORKSH VI, P1
   Rodríguez DZ, 2012, IEEE T CONSUM ELECTR, V58, P985, DOI 10.1109/TCE.2012.6311346
   Saad MA, 2014, IEEE T IMAGE PROCESS, V23, P1352, DOI 10.1109/TIP.2014.2299154
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Wan Z, 2014, MULTIMED TOOLS APPL, V72, P541, DOI 10.1007/s11042-013-1378-z
   Wang ZX, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/586284
   Zhang L, 2014, IEEE MULTIMEDIA, V21, P67, DOI 10.1109/MMUL.2014.50
   Zhang M, 2015, IEEE SIGNAL PROC LET, V22, P207, DOI 10.1109/LSP.2014.2326399
   Zhou L, 2014, IEEE T CIRC SYST VID, V24, P889, DOI 10.1109/TCSVT.2013.2291311
   Zhou L, 2013, IEEE T WIREL COMMUN, V12, P3733, DOI 10.1109/TWC.2013.051413.120597
NR 44
TC 29
Z9 32
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16461
EP 16485
DI 10.1007/s11042-015-3214-0
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700070
DA 2024-07-18
ER

PT J
AU Zhang, K
   Jia, HT
   Lv, HB
AF Zhang, Ke
   Jia, Haitao
   Lv, Haibin
TI Coverage-enhancing approach in multimedia directional sensor networks
   for smart transportation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Directional sensor networks; Coverage-enhancing; Artificial fish-swarm
   algorithm; Smart transportation
ID ROUTING ALGORITHM
AB Smart transportation has a significantly impact on city management and city planning, which has received extensive attentions from academic and industrial communities. Different from omni-directional sensing system, as a directional sensing system, the multimedia-directional sensor network holds the special coverage scheme, which is usually used for smart cities, smart transportation, and harsh environment surveillance, for instance, nuclear-pollution regions where are inhospitable for people. This paper advances Virtual Stream Artificial Fish-swarm based Coverage-Enhancing Algorithm (VSAFCEA) as a coverage-enhancing means in multimedia directional sensor networks. Firstly, a concept of virtual streams, based on traditional artificial fish-swarm algorithm, is proposed. Then, the traditional behaviors of fishes in artificial fish-swarm algorithm are modified and expanded with several new behaviors. Finally, the presented VSAFCEA is adopted for coverage-enhancing issue in the situation of directional sensor networks with rotational direction-adjustable model. With a sequence of steps of artificial fishes in virtual stream, the presented VSAFCEA can figure out the approximation to the highest area coverage rate. Based on comparison of these simulation results (results of presented VSAFCEA and that of other typical coverage-enhancing ways in directional sensor networks), the conclusion can be drawn that VSAFCEA could attain higher area coverage rate of directional sensor networks with fewer iterative computing times.
C1 [Zhang, Ke; Jia, Haitao] UESTC, Sch Commun & Informat Engn, Chengdu 611731, Peoples R China.
   [Lv, Haibin] Qingdao Huanhai Marine Engn Prospecting Inst, Qingdao 266033, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Zhang, K (corresponding author), UESTC, Sch Commun & Informat Engn, Chengdu 611731, Peoples R China.
EM kezhang@uestc.edu.cn
RI Zhang, Ke/G-6923-2011; Lv, Haibin/AAX-7696-2020
OI Zhang, Ke/0000-0001-9696-4944; Lv, Haibin/0000-0003-1059-4765
FU Fundamental Research Funds for the Central Universities [ZYGX2014J099];
   National Natural Science Foundation of China [61571104, 61071124];
   General Project of Scientific Research of the Education Department of
   Liaoning Province [L20150174]; Program for New Century Excellent Talents
   in University [NCET-11-0075]
FX The paper is partially supported by Fundamental Research Funds for the
   Central Universities (ZYGX2014J099), the National Natural Science
   Foundation of China (Nos. 61571104, 61071124), the General Project of
   Scientific Research of the Education Department of Liaoning Province
   (No. L20150174), and the Program for New Century Excellent Talents in
   University (No. NCET-11-0075),.
CR Akyildiz IF, 2008, P IEEE, V96, P1588, DOI 10.1109/JPROC.2008.928756
   Akyildiz IF, 2002, IEEE COMMUN MAG, V40, P102, DOI 10.1109/MCOM.2002.1024422
   [Anonymous], TELECOMMUNICATION SY
   [Anonymous], DARS 2002
   Dingde Jiang, 2015, WIRELESS PERSONAL CO
   Guo C, 2015, RES OPTIMIZATION AUT
   Guo CX, 2015, DISCRETE CONT DYN-S, V8, P1139, DOI 10.3934/dcdss.2015.8.1139
   Jiang D, 2014, INT J COMMUNICATION
   Jiang DD, 2015, J NETW COMPUT APPL, V57, P182, DOI 10.1016/j.jnca.2015.06.010
   Jiang DD, 2015, ANN TELECOMMUN, V70, P427, DOI 10.1007/s12243-015-0465-8
   Jiang DD, 2015, COMPUT NETW, V84, P1, DOI 10.1016/j.comnet.2015.04.003
   Jiang DD, 2015, J SYST SOFTWARE, V104, P152, DOI 10.1016/j.jss.2015.03.006
   Jiang DD, 2015, T EMERG TELECOMMUN T, V26, P308, DOI 10.1002/ett.2619
   Jiang DD, 2014, J NETW COMPUT APPL, V40, P292, DOI 10.1016/j.jnca.2013.09.014
   Jiang DD, 2011, COMPUT NETW, V55, P3533, DOI 10.1016/j.comnet.2011.06.027
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Kumar S, 2013, WIRELESS PERS COMMUN, V71, P1365, DOI 10.1007/s11277-012-0880-3
   Li XL, 2002, SYST ENG THEORY PRAC, V11, P34
   Lin YC, 2015, SENSORS-BASEL, V15, P20925, DOI 10.3390/s150820925
   Liu CB, 2009, PROCEEDINGS OF THE FIRST INTERNATIONAL WORKSHOP ON EDUCATION TECHNOLOGY AND COMPUTER SCIENCE, VOL II, P814, DOI 10.1109/ETCS.2009.443
   Lv ZH, 2015, PERS UBIQUIT COMPUT, V19, P551, DOI 10.1007/s00779-015-0844-1
   Lv ZH, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057990
   Ma HD, 2009, IEEE INFOCOM SER, P2791, DOI 10.1109/INFCOM.2009.5062233
   Mostafaei H, 2013, WIRELESS PERS COMMUN, V71, P1461, DOI 10.1007/s11277-012-0885-y
   Poduri S, 2004, IEEE INT CONF ROBOT, P165, DOI 10.1109/ROBOT.2004.1307146
   Shan XJ, 2006, WCICA 2006: SIXTH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-12, CONFERENCE PROCEEDINGS, P3658
   Sheng G, 2015, COMM COM INF SC, V557, P280, DOI 10.1007/978-3-662-48683-2_25
   SRINIVAS M, 1994, COMPUTER, V27, P17, DOI 10.1109/2.294849
   Tao Dan, 2007, Journal of Software, V18, P1152, DOI 10.1360/jos181152
   Tengfei Yin, 2011, Journal of Networks, V6, P990, DOI 10.4304/jnw.6.7.990-998
   Wang JW, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, VOLS 1 AND 2, PROCEEDINGS, P56, DOI 10.1109/CIS.2008.162
   Wang K, 2015, IEEE INT C CL COMP, P236, DOI 10.1109/CLUSTER.2015.42
   Wang LG, 2008, 2008 7TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-23, P3161, DOI 10.1109/WCICA.2008.4593427
   Wang Yi, 2015, P 27 INT C SCI STAT
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P1867, DOI 10.1109/TIP.2015.2413294
   Yang JC, 2017, MULTIMED TOOLS APPL, V76, P17735, DOI 10.1007/s11042-015-2967-9
   Yang JC, 2015, SENSORS-BASEL, V15, P29535, DOI 10.3390/s151129535
   Yang JC, 2015, SENSORS-BASEL, V15, P19618, DOI 10.3390/s150819618
   Zhang BL, 2010, IEEE T CONSUM ELECTR, V56, P2208, DOI 10.1109/TCE.2010.5681092
   Zhang K, 2010, OPTOELECTRON LETT, V6, P229, DOI 10.1007/s11801-010-9262-9
   Zhang XL, 2015, LECT NOTES COMPUT SC, V9492, P647, DOI 10.1007/978-3-319-26561-2_76
NR 41
TC 7
Z9 7
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 17593
EP 17615
DI 10.1007/s11042-016-3586-9
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600040
DA 2024-07-18
ER

PT J
AU Chen, XJ
   Zhan, YZ
   Ke, J
   Chen, XB
AF Chen, Xiao-jun
   Zhan, Yong-zhao
   Ke, Jia
   Chen, Xiao-bo
TI Complex video event detection via pairwise fusion of trajectory and
   multi-label hypergraphs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hypergraph; Trajectory; Multi-label; Pairwise fusion; Spectral
   segmentation
ID REPRESENTATION
AB The video data is rich in motion event information. Detecting complex events and analyzing the inherent high-level semantics information have been a hot topic in video analysis and understanding. Detecting complex events in the video involves detecting multiple semantic concepts, describing features of multiple moving targets and discovering the relationship between low-level features and high-level semantic concepts. It can extract semantic concept patterns from various video features and original video data, thus bridging the semantic gap. Based on the hypergraph theory, this paper proposes to construct trajectory and multi-label hypergraphs considering the features of moving targets. The two hypergraphs are fused to detect complex events. The experimental results show that in comparison with other methods including ordinary graph based method and hypergraph based multi-label semi-supervised learning method, our method achieves better average precision and average recall when detecting complex events.
C1 [Chen, Xiao-jun] Jiangsu Univ, Dept Informat, Affiliated Hosp, Jiefang Rd 438, Zhenjiang 212001, Jiangsu, Peoples R China.
   [Chen, Xiao-jun; Zhan, Yong-zhao; Ke, Jia] Jiangsu Univ, Sch Comp Sci & Telecommun Engn, Dept Engn, Xuefu Rd 301, Zhenjiang 212013, Jiangsu, Peoples R China.
   [Ke, Jia] Jiangsu Univ, Sch Management, Informat Management Dept, Xuefu Rd 301, Zhenjiang 212013, Jiangsu, Peoples R China.
   [Chen, Xiao-bo] Jiangsu Univ, Automot Engn Res Inst, Dept Informat, Xuefu Rd 301, Zhenjiang 212013, Jiangsu, Peoples R China.
C3 Jiangsu University; Jiangsu University; Jiangsu University; Jiangsu
   University
RP Chen, XJ (corresponding author), Jiangsu Univ, Dept Informat, Affiliated Hosp, Jiefang Rd 438, Zhenjiang 212001, Jiangsu, Peoples R China.
EM cxj@ujs.edu.cn; yzzhan@ujs.edu.cn; kejia@ujs.edu.cn; xbchen82@gmail.com
OI Chen, Xiaobo/0000-0001-9940-1637; chen, xiaojun/0009-0007-9101-3024
FU National Natural Science Foundation of China [41374129, 60673190,
   61203244]; College Natural Science Research of Jiangsu Province
   [14KJB520008]; Senior Technical Personnel of Scientific Research Fund of
   Jiangsu University [13JDG126]
FX This research has partially been supported by National Natural Science
   Foundation of China under Grant No. 41374129, 60673190 and 61203244,
   College Natural Science Research of Jiangsu Province under Grant No.
   14KJB520008, Senior Technical Personnel of Scientific Research Fund of
   Jiangsu University under Grant No. 13JDG126.
CR Assfalg E, 2003, COMPUT VIS IMAGE UND, V92, P285, DOI 10.1016/j.cviu.2003.06.004
   [陈丹雯 Chen Danwen], 2011, [计算机科学, Computer Science], V38, P244
   [陈祖爵 CHEN Zujue], 2007, [中国图象图形学报, Journal of Image and Graphics], V12, P1585
   Doulamis ND, 2010, MULTIMED TOOLS APPL, V50, P173, DOI 10.1007/s11042-009-0370-0
   Gao Y, 2009, MULTIMED TOOLS APPL, V42, P233, DOI 10.1007/s11042-008-0236-x
   Hakeem A, 2007, ARTIF INTELL, V171, P586, DOI 10.1016/j.artint.2007.04.002
   Han YH, 2010, J ZHEJIANG U-SCI C, V11, P525, DOI 10.1631/jzus.C0910453
   Hongeng S, 2004, COMPUT VIS IMAGE UND, V96, P129, DOI 10.1016/j.cviu.2004.02.005
   Huang CL, 2006, IEEE T MULTIMEDIA, V8, P749, DOI 10.1109/TMM.2006.876289
   Huang YC, 2009, PROC CVPR IEEE, P1738, DOI 10.1109/CVPRW.2009.5206795
   [姜远 Jiang Yuan], 2008, [计算机研究与发展, Journal of Computer Research and Development], V45, P1817
   Kalman R.E., 1961, J BASIC ENG-T ASME, V83, P95, DOI 10.1115/1.3658902
   Ke J, 2013, FUTURE GENER COMP SY, V29, P442, DOI 10.1016/j.future.2011.06.004
   Ke J, 2009, LECT NOTES COMPUT SC, V5754, P615
   Lan ZZ, 2014, MULTIMED TOOLS APPL, V71, P333, DOI 10.1007/s11042-013-1391-2
   Lu H, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P45, DOI 10.1109/MMSP.2001.962710
   Lu Han-Qing, 2008, Chinese Journal of Computers, V31, P1629
   Maggio E, 2005, INT CONF ACOUST SPEE, P221
   Mezaris V, 2014, MULTIMED TOOLS APPL, V70, P1, DOI 10.1007/s11042-013-1426-8
   Piciarelli C, 2006, PATTERN RECOGN LETT, V27, P1835, DOI 10.1016/j.patrec.2006.02.004
   Qian XM, 2012, MULTIMED TOOLS APPL, V60, P233, DOI 10.1007/s11042-011-0817-y
   Ruocco M, 2014, MULTIMED TOOLS APPL, V70, P55, DOI 10.1007/s11042-012-1087-z
   Suk HI, 2010, PATTERN RECOGN, V43, P3059, DOI 10.1016/j.patcog.2010.03.016
   Talukder A, 2014, MULTIMED TOOLS APPL, V70, P237, DOI 10.1007/s11042-012-1088-y
   Voulodimos AS, 2014, MULTIMED TOOLS APPL, V69, P293, DOI 10.1007/s11042-012-0993-4
NR 25
TC 9
Z9 9
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 15079
EP 15100
DI 10.1007/s11042-015-2514-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500061
DA 2024-07-18
ER

PT J
AU Cho, SM
   Gwak, SG
   Kim, CH
   Hong, S
AF Cho, Sung Min
   Gwak, Seung Gyu
   Kim, Chang Han
   Hong, Seokhie
TI Faster elliptic curve arithmetic for triple-base chain by reordering
   sequences of field operations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Elliptic curve cryptography; Triple-base chain; Reordering; 5P operation
ID NUMBER SYSTEM; CRYPTOGRAPHY; FORMULAS
AB In this work, we propose an algorithm to produce the Triple-base chain that optimize the time usage for computing an elliptic curve cryptosystem. Triple-base Chain is a scalar multiplication algorithm, which represents an integer k using three bases {2,3,5}. This paper provides a faster scalar multiplication method of elliptic curve based on {2,3,5} Triple-base Chain. The method proposed by this research speeds up the existing Triple-base Chain algorithm by optimizing the 5P operation of elliptic curve and reordering the operation order of base {2,3,5}. This method can improve the speed of operation from 4 to 6 % compared to the existing {2,3,5} Triple-base Chain.
C1 [Cho, Sung Min; Hong, Seokhie] Korea Univ, Ctr Informat Secur Technol, Seoul, South Korea.
   [Gwak, Seung Gyu] Korea Inst Energy Technol Evaluat & Planning, Seoul, South Korea.
   [Kim, Chang Han] Semyung Univ, Dept Informat & Secur, Jecheon, South Korea.
C3 Korea University; Semyung University
RP Hong, S (corresponding author), Korea Univ, Ctr Informat Secur Technol, Seoul, South Korea.
EM muji0828@korea.ac.kr; ashash04@ketep.re.kr; chkim@semyung.ac.kr;
   shhong@korea.ac.kr
FU Next-Generation Information Computing Development Program through the
   National Research Foundation of Korea (NRF) - Ministry of Science, ICT &
   Future Planning [NRF-2014M3C4A7030648]
FX This research was supported by Next-Generation Information Computing
   Development Program through the National Research Foundation of Korea
   (NRF) funded by the Ministry of Science, ICT & Future Planning (No.
   NRF-2014M3C4A7030648)
CR Byrne Andrew, 2007, International Journal of High Performance Systems Architecture, V1, P133, DOI 10.1504/IJHPSA.2007.015399
   Chuengsatiansup C, 2012, 2012 INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY AND ITS APPLICATIONS (ISITA 2012), P411
   Cohen H, 1998, LECT NOTES COMPUT SC, V1514, P51
   Dimitrov V, 2008, MATH COMPUT, V77, P1075, DOI 10.1090/S0025-5718-07-02048-0
   Doche C, 2006, LECT NOTES COMPUT SC, V4329, P335
   Fong K, 2004, IEEE T COMPUT, V53, P1047, DOI 10.1109/TC.2004.43
   Joye M, 2002, LECT NOTES COMPUT SC, V2523, P291
   KOBLITZ N, 1987, MATH COMPUT, V48, P203, DOI 10.1090/S0025-5718-1987-0866109-5
   Longa P, 2008, IEEE T COMPUT, V57, P289, DOI 10.1109/TC.2007.70815
   Meloni N, 2007, LECT NOTES COMPUT SC, V4547, P189
   MILLER VS, 1986, LECT NOTES COMPUT SC, V218, P417, DOI 10.1007/3-540-39799-x_31
   Mishra PK, 2007, LECT NOTES COMPUT SC, V4779, P390
NR 12
TC 3
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14819
EP 14831
DI 10.1007/s11042-016-3272-y
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500048
DA 2024-07-18
ER

PT J
AU Ju, SH
   Seo, HS
   Kwak, J
AF Ju, Seung-hwan
   Seo, Hee-suk
   Kwak, Jin
TI Research on android malware permission pattern using permission
   monitoring system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile security; Application permission; Application analysis
AB Mobile anti-viruses used mainly are the reverse engineering-based analysis and the sandbox-based analysis. There methods can analyze in detail. But, they take a lot of time and have a one-time payout.
   This study investigates the permissions requested by Android applications, and the possibility of identifying suspicious applications based only on information presented to the user before an application is downloaded
   The pattern analysis is based on a smaller data set consisting of confirmed malicious applications. The method is evaluated based on its ability to recognize malicious potential in the analyzed applications. This study is a service-based malware analysis, it will be based on the mobile security study.
C1 [Ju, Seung-hwan] Korea Univ Technol & Educ, Dept Comp Engn, Cheonan Si, Chungcheongnam, South Korea.
   [Seo, Hee-suk] Korea Univ Technol & Educ, Interdisciplinary Program Creat Engn, Cheonan Si, Chungcheongnam, South Korea.
   [Kwak, Jin] Ajou Univ, Dept Informat & Comp Engn, Coll Informat Technol, Suwon, South Korea.
C3 Korea University of Technology & Education; Korea University of
   Technology & Education; Ajou University
RP Kwak, J (corresponding author), Ajou Univ, Dept Informat & Comp Engn, Coll Informat Technol, Suwon, South Korea.
EM judeng@koreatech.ac.kr; histone@koreatech.ac.kr;
   jkwak.security@gmail.com
OI Kwak, Jin/0000-0001-6931-2705
FU ICT R&D program of MSIP/IITP, Republic of Korea [13-912-06-003]
FX This work was supported by the ICT R&D program of MSIP/IITP, Republic of
   Korea. [13-912-06-003, Development of Mobile S/W Security Testing Tools
   for Detecting New Vulnerabilities of Android]
CR [Anonymous], P 18 ACM C COMP COMM
   [Anonymous], 2011, USENIX SEC S
   [Anonymous], P 17 ACM C COMP COMM
   [Anonymous], 2012, P 33 IEEE S SEC PRIV
   Arxan, 2012, STAT SEC APP EC MOB
   Chandramohan M, 2012, COMPUTER, V45, P65, DOI 10.1109/MC.2012.36
   Enck W, 2009, IEEE SECUR PRIV, V7, P50, DOI 10.1109/MSP.2009.26
   F-Secure, 2014, MOB THREAT REP
   McAfee, 2012, MCAFEE THREATS REP 1
   Moser A, 2007, P IEEE S SECUR PRIV, P231, DOI 10.1109/SP.2007.17
   Shabtai A, 2009, TECHNICAL REPORT
   Xu R., 2012, 21 USENIX SEC S USEN 21 USENIX SEC S USEN
   YAN L K, 2012, USENIX SECURITY
NR 13
TC 3
Z9 3
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14807
EP 14817
DI 10.1007/s11042-016-3273-x
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500047
DA 2024-07-18
ER

PT J
AU Kim, BH
   Kim, KC
   Oh, SY
   Hong, SE
AF Kim, Bong-Hyun
   Kim, Ki-Chan
   Oh, Sang-Young
   Hong, Sung-Eon
TI Implementation of English word learning system using Smartphone TTS
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE English word learning; Smartphone TTS; Text to speech; English education
AB English educational software was developed and applied a variety of techniques are utilized. To reflect the current social conditions that emphasize English, time and place without constraints, simple, and are continually developed at the purpose of helping the fun of English study. Therefore, in this paper, we have implemented a system that focuses on learning the word of English. From this, by utilizing the TTS of smartphone was applied vocal training method. In other words, the system design and implementation of inducing an interest in learning English through the TTS. In addition, we implemented a system to store and manage the environment the learning progress through the personal accounts.
C1 [Kim, Bong-Hyun] Chungbuk Prov Univ, Dept Med Elect, 15 Daehak Ro, Okcheon Gun, Chungcheongbuk, South Korea.
   [Kim, Ki-Chan] Hanbat Natl Univ, Dept Eletr Engn, 125 Dongseodaero, Yusung Gu, Daejeon Si, South Korea.
   [Oh, Sang-Young] Youngdong Univ, Dept Business Adm, 310 Daehak Ro, Youngdong Gun, Chungcheongbuk, South Korea.
   [Hong, Sung-Eon] Cheongju Univ, Dept Land Management, 298 Daedeong Ro, Cheongwon Gu, Chungcheongbuk, South Korea.
C3 Hanbat National University; Cheongju University
RP Hong, SE (corresponding author), Cheongju Univ, Dept Land Management, 298 Daedeong Ro, Cheongwon Gu, Chungcheongbuk, South Korea.
EM hongsu2005@hanmail.net
RI Kim, Bong-Hyun/GWM-5912-2022
OI Kim, Bong-Hyun/0000-0002-7514-1268
CR Altbach P.G., 2007, J STUD INT EDUC, V11, P290, DOI DOI 10.1177/1028315307303542
   Barr R., 1995, Change, V27, P13, DOI DOI 10.1080/00091383.1995.10544672
   Bowman M, 1999, NEWS ADVICE TECHNOLO, V2, P3
   Cha Kyung-Whan, 2004, [Multimedia-Assisted Language Learning, 멀티미디어 언어교육], V7, P9
   Godwin-Jones R, 2003, LANG LEARN TECHNOL, V7, P18
   Hong YH, 2003, J KOREAN INF ED SOC, V8, P469
   Hwang YS, 2014, J KOREAN SOC AM HIST, V40, P201
   Kasper L.F., 2000, LANGUAGE LEARNING TE, V4, P105
   Kim Y., 2002, EDUC REV, V9, P56
   Kim Young-Suh, 2004, [Multimedia-Assisted Language Learning, 멀티미디어 언어교육], V7, P123
   Krashen S.D., 2003, Selected Papers from the Twelfth International Symposium on English Teaching and Learning, P100
   Lee DW, 2015, ANAL EARLY ENGLISH E
   Lee HR, 2011, J KOREAN INF ED SOC, V15, P137
   Lee JE, 2012, STUD ENGL LANG LIT, V38, P267
   Lee SJ, 2004, DESIGN IMPLEMENTATIO
   Lim JR, 2013, STUDY CURRENT STATE
   Richards C., 2000, Language Learning and Technology, V4, P59
   Yuah CHON, 2004, [Multimedia-Assisted Language Learning, 멀티미디어 언어교육], V7, P9
NR 18
TC 1
Z9 1
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13179
EP 13192
DI 10.1007/s11042-016-3277-6
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800013
DA 2024-07-18
ER

PT J
AU Luo, JN
   Yang, MH
AF Luo, Jia-Ning
   Yang, Ming-Hour
TI A mobile authentication system resists to shoulder-surfing attacks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shoulder surfing; Password authentication scheme; Graphical password
ID SCHEME
AB Traditional password-based authentication schemes are vulnerable to shoulder-surfing attacks. Attackers may steal user's sensitive information through direct observation, particularly at crowded places. In this paper, we propose a novel mobile authentication mechanism to prevent shoulder-surfing attacks. Even though an attacker can capture a user's input, he cannot derive the original password from his observation. Our authentication mechanism can be applied in various systems, especially on mobile devices. In the security analysis section, we prove that our scheme is secure against shoulder-surfing attacks, phishing attacks, and other malicious software attacks.
C1 [Luo, Jia-Ning] Ming Chuan Univ, Informat & Telecommun Engn, Taoyuan 333, Taiwan.
   [Yang, Ming-Hour] Chung Yuan Christian Univ, Informat & Comp Engn, Taoyuan 320, Taiwan.
C3 Ming Chuan University; Chung Yuan Christian University
RP Yang, MH (corresponding author), Chung Yuan Christian Univ, Informat & Comp Engn, Taoyuan 320, Taiwan.
EM deer@mail.mcu.edu.tw; mhyang@cycu.edu.tw
OI Luo, Jia-Ning/0000-0003-1395-5810
FU National Science Council of Taiwan [NSC101-2221-E-033-016-MY2]
FX This research was supported by the National Science Council of Taiwan
   under grant no. NSC101-2221-E-033-016-MY2.
CR Bai X, 2008, ANN COMPUT SECURITY, P433, DOI 10.1109/ACSAC.2008.23
   Chagnaadorj O, 2014, J INF PROCESS SYST, V10, P92, DOI 10.3745/JIPS.2014.10.1.092
   Chakraborty N, 2014, IEEE STUDENT TECHNOL, P13, DOI 10.1109/TechSym.2014.6807906
   Chung Y., 2013, J CONVERG, V4, P23
   De Luca Alexander., 2007, P 19 AUSTRALASIAN C, P199, DOI [10.1145/1324892.1324932, 10.1145/1324892.1324932doi.org/10.1145/1324892.1324932, DOI 10.1145/1324892.1324932DOI.ORG/10.1145/1324892.1324932]
   Dhamija R, 2000, USENIX ASSOCIATION PROCEEDINGS OF THE NINTH USENIX SECURITY SYMPOSIUM, P45
   Dhamija Rachna, 2006, P SIGCHI C HUM FACT, P581, DOI 10.1145/1124772.1124861
   Florencio D, 2006, P 2 S US PRIV SEC SO
   Gnanaraj JWK, 2013, HUM-CENTRIC COMPUT I, V3, DOI 10.1186/2192-1962-3-16
   Hallsteinsen S, 2007, P COMM NETW ICSCN 07, V68
   JERMYN I, 1999, P 8 USENIX SEC S
   Lei M, 2008, IEEE ICC, P1536, DOI 10.1109/ICC.2008.297
   Luo JN, 2006, J INF SCI ENG, V22, P1125
   Nocetti FG, 2002, IEEE T PARALL DISTR, V13, P963, DOI 10.1109/TPDS.2002.1036069
   Perkovic T, 2009, 2009 INTERNATIONAL CONFERENCE ON SOFTWARE, TELECOMMUNICATIONS AND COMPUTER NETWORKS, P270
   SHEPARD RN, 1967, J VERB LEARN VERB BE, V6, P156, DOI 10.1016/S0022-5371(67)80067-7
   Sobrado L., 2002, RUTGERS SCHOLAR ELEC, V4
   Suo XY, 2005, 21ST ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE, PROCEEDINGS, P419
   Wiedenbeck S, 2005, INT J HUM-COMPUT ST, V63, P102, DOI 10.1016/j.ijhcs.2005.04.010
   Yi-Lun Chen, 2013, 2013 2nd International Symposium on Next-Generation Electronics (ISNE 2013), P161, DOI 10.1109/ISNE.2013.6512317
   Zhao HY, 2007, 21ST INTERNATIONAL CONFERENCE ON ADVANCED NETWORKING AND APPLICATIONS WORKSHOPS/SYMPOSIA, VOL 2, PROCEEDINGS, P467
NR 21
TC 9
Z9 10
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14075
EP 14087
DI 10.1007/s11042-015-3129-9
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500005
DA 2024-07-18
ER

PT J
AU Pandey, R
   Singh, AK
   Kumar, B
   Mohan, A
AF Pandey, Richa
   Singh, Amit Kumar
   Kumar, Basant
   Mohan, Anand
TI Iris based secure NROI multiple eye image watermarking for
   teleophthalmology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electronic patient record (EPR); Region of interest (ROI) and non-region
   of interest (NROI); Discrete Wavelet Transform(DWT); Singular value
   decomposition (SVD); SHA-512; Checkmark Attacks
ID DISCRETE WAVELET TRANSFORM; MEDICAL IMAGES; ROBUST; AUTHENTICATION;
   INFORMATION; REGION
AB This paper presents a new secure multiple text and image watermarking scheme on cover eye image using fusion of discrete wavelet transforms (DWT) and singular value decomposition (SVD) for Teleophthalmology. Secure Hash Algorithm (SHA-512) is used for generating hash corresponding to iris part of the cover digital eye image and this unique hash parameter is used for enhancing the security feature of the proposed watermarking technique. Simultaneous embedding of four different watermarks (i.e. Signature, index, caption and reference watermark) in form of image and text using fusion of discrete wavelet transforms (DWT) and singular value decomposition (SVD) is achieved in this paper. The suggested technique initially divides the digital eye image into Region of interest (ROI) containing iris and Non-Region of interest (NROI) part where the text and image watermarks are embedded into the Non-Region of interest (NROI) part of the DWT cover image. The selection of DWT decomposition level for embedding the text and image watermarks depends on size, different characteristics and robustness requirements of medical watermark. The performance in terms of Normalized Correlation (NC) and bit error rate (BER) of the developed scheme is evaluated and analyzed against known signal processing attacks and 'Checkmark' attacks. The method is found to be robust against all the considered attacks. The proposed multilevel watermarking method correctly extracts the embedded watermarks without error and is robust against the all considered attacks without significant degradation of the medical image quality of the watermarked image. Therefore the proposed method may find potential application in secure and compact medical data transmission for teleophthalmology applications.
C1 [Pandey, Richa; Kumar, Basant] Motilal Nehru Natl Inst Technol, Dept Elect & Commun Engn, Allahabad, Uttar Pradesh, India.
   [Singh, Amit Kumar] Jaypee Univ Informat Technol Waknaghat, Dept Comp Sci & Engn, Solan, Himachal Prades, India.
   [Mohan, Anand] Indian Inst Technol BHU, Dept Elect Engn, Varanasi, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology; Jaypee University of Information Technology;
   Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi)
RP Singh, AK (corresponding author), Jaypee Univ Informat Technol Waknaghat, Dept Comp Sci & Engn, Solan, Himachal Prades, India.
EM richa8704@gmail.com; amit_245singh@yahoo.com; singhbasant@yahoo.com;
   profanandmohan@gmail.com
RI PANDEY, RICHA/JXL-7432-2024; Singh, Amit Kumar/D-1300-2015
OI Singh, Amit Kumar/0000-0001-7359-2068
CR Ahmed F, 2010, SIGNAL PROCESS, V90, P1456, DOI 10.1016/j.sigpro.2009.05.024
   Al-Haj A, 2014, J DIGIT IMAGING, V27, P737, DOI 10.1007/s10278-014-9709-9
   [Anonymous], 2014, INT J TELEMED APPL
   [Anonymous], 2012, AM J BIOMEDICAL ENG, DOI DOI 10.5923/J.AJBE.20120202.06
   [Anonymous], 2012, INT J COMPUT COMMUN, DOI 10.5281/zenodo.1331913
   [Anonymous], 2015, THESIS
   [Anonymous], 2010, INT J COMPUT SCI INF
   Badshah G., 2015, J DIGIT IMAGING, V28, P1
   Bouslimi D, 2012, IEEE T INF TECHNOL B, V16, P891, DOI 10.1109/TITB.2012.2207730
   Das S, 2013, COMPUT METH PROG BIO, V111, P662, DOI 10.1016/j.cmpb.2013.05.027
   Giakoumaki A, 2006, MED BIOL ENG COMPUT, V44, P619, DOI 10.1007/s11517-006-0081-x
   Guo JM, 2014, J VIS COMMUN IMAGE R, V25, P1149, DOI 10.1016/j.jvcir.2014.03.012
   Hajjaji MA, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/313078
   KAHATE A., 2013, Cryptography and network security
   Kannammal A, 2014, INT J IMAG SYST TECH, V24, P111, DOI 10.1002/ima.22086
   Kundu M. K., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1457, DOI 10.1109/ICPR.2010.360
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P11509, DOI 10.1016/j.eswa.2009.03.060
   Lin WH, 2009, EXPERT SYST APPL, V36, P9869, DOI 10.1016/j.eswa.2009.02.036
   Lu J., 2015, J. Inf. Hiding Multimedia Signal Process, V6, P458
   Mahajan LH, 2013, INT J ADV RES SCI EN, V2, P69
   Memon NA, 2008, INMIC: 2008 INTERNATIONAL MULTITOPIC CONFERENCE, P106, DOI 10.1109/INMIC.2008.4777717
   Mousavi SM, 2014, J DIGIT IMAGING, V27, P714, DOI 10.1007/s10278-014-9700-5
   Paar C., 2009, UNDERSTANDING CRYPTO, P29
   Pal K, 2010, INT J TOMOGR SIMUL, V14, P109
   Pereira S., 2001, INFORM HIDING, P340, DOI [10.1007/3-540-45496-925, DOI 10.1007/3-540-45496-925]
   Rey C, 2002, EURASIP J APPL SIG P, V2002, P613, DOI 10.1155/S1110865702204047
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh AK, 2015, WIRELESS PERS COMMUN, V83, P2133, DOI 10.1007/s11277-015-2505-0
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P607, DOI 10.1166/jmihi.2015.1432
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P406, DOI 10.1166/jmihi.2015.1407
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Singh AK, 2014, P NATL A SCI INDIA A, V84, P345, DOI 10.1007/s40010-014-0140-x
   SU PC, 1999, P 1999 PICS 52 ANN C, P295
   Wong PW, 2001, IEEE T IMAGE PROCESS, V10, P1593, DOI 10.1109/83.951543
   YANG CY, 2010, INT J IMAGE PROCESS, V3, P373
   Zain Jasni, 2005, P 3 INT C SCI EL TEC
   Zain JM, 2007, INT J COMPUT SCI NET, V7, P19
   Zhang L, 2010, TELECOMMUN SYST, V44, P205, DOI 10.1007/s11235-009-9260-z
NR 40
TC 45
Z9 46
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14381
EP 14397
DI 10.1007/s11042-016-3536-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500022
DA 2024-07-18
ER

PT J
AU Shin, SH
   Jung, KH
AF Shin, Sang-Ho
   Jung, Ki-Hyun
TI Reversible secret image sharing scheme in encrypted images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret image sharing; Encrypted image; Data hiding; Steganography;
   Watermarking
ID STEGANOGRAPHY
AB The previous secret image sharing schemes did not provide a copyright and privacy for cover images. The reason is that a dealer selects a cover image by itself and embeds directly the secret data into the cover image. In this paper, a reversible secret image sharing scheme in encrypted images is proposed in order to provide the copyright and privacy of the cover image. We divide a role of the dealer into an image provider and a data hider. The image provider encrypts the cover image and transmits the encrypted image to the data hider, and the standard stream cipher as one-time pad (OTP) with a random secret key is used. The data hider embeds the secret data into the encrypted image, and the encrypted shadow images are transmitted to the corresponding participant. We utilize the polynomial arithmetic operation over GF(28) during the sharing of the encrypted shadow images, and the coefficient of the highest-order term is fixed to one in order to prevent the overflow and the security problem. In the reconstruction procedure, the secret data can be extracted and the cover image can be reconstructed exactly from t or more encrypted shadow images with Lagrange interpolation. In experimental results, the proposed method shows that the PSNR is sustained close to 44 dB regardless of the embedding capacity, where the embedding capacity is 524,288 bits on average.
C1 [Shin, Sang-Ho] Dongguk Univ Gyeongju Campus, Realist Media Ind Prod Promot Grp, 23 Dongdae Ro, Gyeongju Si 38066, Gyeongbuk, South Korea.
   [Jung, Ki-Hyun] Kyungil Univ, Dept Cyber Secur, 50 Gamasil Gil, Gyongsan 38428, Gyeongbuk, South Korea.
C3 Dongguk University; Kyungil University
RP Jung, KH (corresponding author), Kyungil Univ, Dept Cyber Secur, 50 Gamasil Gil, Gyongsan 38428, Gyeongbuk, South Korea.
EM khanny.jung@gmail.com
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2015R1D1A1A01058019]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education(No. 2015R1D1A1A01058019).
CR Beimel A, 1998, IEEE T INFORM THEORY, V44, P1887, DOI 10.1109/18.705567
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Feldman P., 1987, 28th Annual Symposium on Foundations of Computer Science (Cat. No.87CH2471-1), P427, DOI 10.1109/SFCS.1987.4
   Harn L, 2014, INFORM PROCESS LETT, V114, P504, DOI 10.1016/j.ipl.2014.04.006
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Josh B, 1990, LNCS, V403, P27
   Katzenbeisser S., 2000, INFORM HIDHING TECHN
   Lin C-C, 2012, REVERSIBLE SECRET IM, P1
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin PY, 2010, PATTERN RECOGN LETT, V31, P1887, DOI 10.1016/j.patrec.2010.01.019
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   del Rey AM, 2015, EXPERT SYST APPL, V42, P2114, DOI 10.1016/j.eswa.2014.10.035
   Menezes A. J., 1996, HDB APPL CRYPTOGRAPH, V1st
   Mitsuru I., 1989, ELECTR COMMUN 3, V72, P1520
   Naor M, 1997, VISUAL CRYPTOGRAPHY
   Naor M., 1995, ADV CRYPTOLOGY EUROC
   Pakniat N, 2014, J VIS COMMUN IMAGE R, V25, P1093, DOI 10.1016/j.jvcir.2014.03.004
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Schoenmakers B., 1999, Advances in Cryptology - CRYPTO'99. 19th Annual International Cryptology Conference. Proceedings, P148
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Stallings W., 2006, Cryptography and Network Security, V4th
   Stinson D. R., 2006, Cryptography Theory and Practice, V3rd
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Thien CC, 2003, IEEE T CIRC SYST VID, V13, P1161, DOI 10.1109/TCSVT.2003.819176
   Ulutas M, 2013, J SYST SOFTWARE, V86, P485, DOI 10.1016/j.jss.2012.09.027
   Van Schyndel RG, 1994, DIGITAL WATERMARK, V2
   Wang RZ, 2007, SIGNAL PROCESS-IMAGE, V22, P363, DOI 10.1016/j.image.2006.12.012
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yuan HD, 2014, INFORM SCIENCES, V254, P197, DOI 10.1016/j.ins.2013.08.012
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 33
TC 5
Z9 5
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13931
EP 13949
DI 10.1007/s11042-016-3844-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800049
DA 2024-07-18
ER

PT J
AU Zhang, H
   Cao, Y
   Zhao, XF
AF Zhang, Hong
   Cao, Yun
   Zhao, Xianfeng
TI Motion vector-based video steganography with preserved local optimality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Video; Motion estimation; Motion vector; Local optimality
ID STEGANALYSIS
AB Current motion vector based video steganography is unable to preserve the local optimality of modified motion vectors. Thus they are vulnerable to the attack of steganalysis. In this paper, we have proposed a novel method to guarantee the local optimality of modified motion vectors. To modify a motion vector, firstly designate a search area which consists of candidate motion vectors. Second, evaluate the local optimality of each motion vector in the search area to locate all local optimum ones, from which finally select the one contributing least to video compression efficiency degradation as the modified motion vector. Highly undetectable motion vector based video steganography can be developed by combining the proposed method with steganographic codes and reasonable cost assignment. Comparative experimental results have demonstrated that video steganography based on the proposed method is capable of withstanding current best steganalysis while keeping the video compression performance.
C1 [Zhang, Hong; Cao, Yun; Zhao, Xianfeng] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, 89A Minzhuang Rd, Beijing 100093, Peoples R China.
   [Zhang, Hong] Univ Chinese Acad Sci, 19A Yuquan Rd, Beijing 100049, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Information Engineering, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Zhang, H (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, 89A Minzhuang Rd, Beijing 100093, Peoples R China.; Zhang, H (corresponding author), Univ Chinese Acad Sci, 19A Yuquan Rd, Beijing 100049, Peoples R China.
EM zhanghong@iie.ac.cn; caoyun@iie.ac.cn; zhaoxianfeng@iie.ac.cn
RI Zhang, Hong/Y-8004-2019; Zhao, Xianfeng/AAE-7278-2021
OI Zhang, Hong/0000-0003-3480-0244; Zhao, Xianfeng/0000-0002-5617-8399
CR Aly HA, 2011, IEEE T INF FOREN SEC, V6, P14, DOI 10.1109/TIFS.2010.2090520
   Cao Y, 2012, IEEE SIGNAL PROC LET, V19, P35, DOI 10.1109/LSP.2011.2176116
   Chen ZB, 2006, J VIS COMMUN IMAGE R, V17, P264, DOI 10.1016/j.jvcir.2004.12.002
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Fridrich J, 2005, IEEE T SIGNAL PROCES, V53, P3923, DOI 10.1109/TSP.2005.855393
   Fridrich J, 2004, LECT NOTES COMPUT SC, V3200, P67
   Hao Bin, 2011, 2011 IEEE 3rd International Conference on Communication Software and Networks (ICCSN 2011), P406, DOI 10.1109/ICCSN.2011.6013622
   Kutter M, 1997, M2281 ISOIEC JTC1SC2
   Ren Yanzhen, 2014, P 2 ACM WORKSHOP INF, P83, DOI DOI 10.1145/2600918.2600938
   Su YT, 2011, SIGNAL PROCESS, V91, P1901, DOI 10.1016/j.sigpro.2011.02.012
   Wang KR, 2014, IEEE T INF FOREN SEC, V9, P741, DOI 10.1109/TIFS.2014.2308633
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xu CY, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 1, PROCEEDINGS, P269
   Yao Y, 2014, MULTIMED TO IN PRESS
   Yun Cao, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P193, DOI 10.1007/978-3-642-24178-9_14
   Zhu C, 2002, IEEE T CIRC SYST VID, V12, P349, DOI 10.1109/TCSVT.2002.1003474
NR 16
TC 47
Z9 53
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13503
EP 13519
DI 10.1007/s11042-015-2743-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800028
DA 2024-07-18
ER

PT J
AU Liu, D
   Wu, ZG
   Lin, XM
   Ji, RR
AF Liu, Di
   Wu, Zhaogai
   Lin, Xianming
   Ji, Rongrong
TI Towards perceptual video cropping with curve fitting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video cropping; Curve fitting; Interesting region score
AB Coming with the proliferation of mobile devices, the issue of displaying videos with varying resolutions and aspect ratios has become emerging. To this end, state-of-the-art works typically resort to video retargeting or cropping, i.e. adaptively adjusting the display regions and contents within each video frame to fit for the mobile device screens. However, most existing approaches retain on evaluating the objective visual statistics to select salient parts to be cropped within each frame, with time-consuming constraints to ensure the temporal consistency, which is indeed unsuitable to cope with the massive videos uploaded daily from user-contributed platforms. In this paper, we propose an efficient yet robust video cropping algorithm which merits in two-fold: First, a perceptual Region of Interest selection approach is proposed by employing a novel Interesting Region Score, which is a linear combination of Rate of Focused Attention, Total Saliency Score, and Bias from Center Penalty. Second, we adopt fast curve fitting to seek for an optimal cropping sequence over a set of consecutive video frames within a shot, which avoids the complex optimization with temporal constraints among adjacent frames. Experiments on video sequences from Backkom cartoon and Iron Man II with comparisons against several alternative approaches demonstrate the efficiency and robustness of the proposed algorithm.
C1 [Liu, Di; Wu, Zhaogai; Lin, Xianming; Ji, Rongrong] Xiamen Univ, Sch Informat Sci & Engn, Dept Cognit Sci, Xiamen, Peoples R China.
C3 Xiamen University
RP Ji, RR (corresponding author), Xiamen Univ, Sch Informat Sci & Engn, Dept Cognit Sci, Xiamen, Peoples R China.
EM jirongrong@gmail.com
FU National Natural Science Foundation of China [61422210, 61373076];
   Fundamental Research Funds for the Central Universities [2013121026];
   Xiamen University 985 Project
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61422210 and Grant 61373076, the Fundamental Research
   Funds for the Central Universities under Grant 2013121026, and Xiamen
   University 985 Project.
CR [Anonymous], AS PAC SIGN INF PROC
   [Anonymous], 2009, P 17 ACM INT C MULT
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2006, P 14 ACM INT C MULT
   [Anonymous], 2007, 2007 IEEE 11 INT C C, DOI DOI 10.1109/ICCV.2007.4409010
   [Anonymous], J MULTIMED
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Deselaers T, 2008, IEEE C COMPUTER VISI, P1
   Gao L, 2011, ELECTRON LETT, V47, P694, DOI 10.1049/el.2011.0544
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Nie YW, 2013, VISUAL COMPUT, V29, P785, DOI 10.1007/s00371-013-0830-4
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wu HS, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866185
   Yan B, 2013, IEEE T CIRC SYST VID, V23, P313, DOI 10.1109/TCSVT.2012.2203740
   Yang Y, 2014, IEEE T MULTIMEDIA, V16, P1677, DOI 10.1109/TMM.2014.2323014
   Yang Y, 2013, IEEE T KNOWL DATA EN, V25, P1760, DOI 10.1109/TKDE.2012.118
   Yang Y, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2457450.2457456
   Yang Y, 2013, PATTERN RECOGN, V46, P1358, DOI 10.1016/j.patcog.2012.10.026
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T CYBERNETICS, V44, P1408, DOI 10.1109/TCYB.2013.2285219
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2014, INFORM SCIENCES, V254, P141, DOI 10.1016/j.ins.2013.08.020
   Zhang LM, 2013, SIGNAL PROCESS, V93, P1597, DOI 10.1016/j.sigpro.2012.05.012
NR 24
TC 7
Z9 7
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12465
EP 12475
DI 10.1007/s11042-014-2304-8
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700010
DA 2024-07-18
ER

PT J
AU Wang, D
   Kang, JS
   Qin, SF
   Birringer, J
AF Wang, Ding
   Kang, Jinsheng
   Qin, Sheng-Feng
   Birringer, Johannes
TI Cultural-based visual expression: emotional analysis of human face via
   Peking Opera Painted Faces (POPF)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression; Facial motion; Emotion; Motion capture; Visual
   information; POPF
AB Peking Opera as a branch of Chinese traditional cultures and arts has a very distinct colourful facial make-up for all actors in the stage performance. Such make-up is stylised in nonverbal symbolic semantics which all combined together to form the painted faces to describe and symbolise the background, the characteristic and the emotional status of specific roles. A study of Peking Opera Painted Faces (POPF) was taken as an example to see how information and meanings can be effectively expressed through the change of facial expressions based on the facial motion within natural and emotional aspects. The study found that POPF provides exaggerated features of facial motion through images, and the symbolic semantics of POPF provides a high-level expression of human facial information. The study has presented and proved a creative structure of information analysis and expression based on POPF to improve the understanding of human facial motion and emotion.
C1 [Wang, Ding; Kang, Jinsheng] Brunel Univ London, Dept Design, Coll Engn Design & Phys Sci, Uxbridge UB8 3PH, Middx, England.
   [Qin, Sheng-Feng] Northumbria Univ, Northumbria Sch Design, Prod Ind Design, Newcastle Upon Tyne NE1 8ST, Tyne & Wear, England.
   [Birringer, Johannes] Brunel Univ London, Dept Arts & Humanities, Coll Business Arts & Social Sci, Uxbridge, Middx, England.
C3 Brunel University; Northumbria University; Brunel University
RP Wang, D (corresponding author), Brunel Univ London, Dept Design, Coll Engn Design & Phys Sci, Uxbridge UB8 3PH, Middx, England.
EM Ding.Wang@brunel.ac.uk
OI Kang, Jinsheng/0000-0002-0050-1062; Qin, Shengfeng/0000-0001-8538-8136
CR [Anonymous], PEKING OPERA PAINTED
   [Anonymous], ICAC 14
   [Anonymous], CCSE ASIAN SOC SCI
   [Anonymous], IASP 2011
   [Anonymous], CVPRW 10
   [Anonymous], CULTURE BASED KNOWLE
   [Anonymous], PEKING OPERA PAINTED
   [Anonymous], J SHU TE U
   [Anonymous], MITT ANTHR GES WIEN
   Baron-Cohen S, 1998, NATURE, V392, P459, DOI 10.1038/33076
   EKMAN P, 1986, MOTIV EMOTION, V10, P159, DOI 10.1007/BF00992253
   Ekman P, 1978, FACIAL ACTION CODING
   Horton W., 1994, ICON BOOK VISUAL SYM
   Jin Hui, 2003, Journal of Software, V14, P2098
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Razzaghi M, 2009, DESIGN STUD, V30, P438, DOI 10.1016/j.destud.2008.11.006
   Shen ST, 2006, INTERACT COMPUT, V18, P820, DOI 10.1016/j.intcom.2005.11.014
   Wang L, 2014, INT J CONTROL AUTOM, V12, P459, DOI 10.1007/s12555-013-0361-9
   Yang CK, 2008, MULTIMED TOOLS APPL, V40, P41, DOI 10.1007/s11042-007-0184-x
NR 19
TC 2
Z9 2
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 11865
EP 11891
DI 10.1007/s11042-015-2665-7
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200016
OA Green Accepted, hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Lim, JG
   Kim, J
   Kwon, DS
AF Lim, Jong Gwan
   Kim, Jaehong
   Kwon, Dong-Soo
TI Multidimensional evaluation and analysis of motion segmentation for
   inertial measurement unit applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion segmentation; Motion interaction; Acceleration; End point
   detection; IMU; Accelerometer
ID MEMS ACCELEROMETER; RECOGNITION; NAVIGATION; PEN
AB Despite various Inertial Measurement Unit (IMU) applications and their technological advances, the process of motion segmentation performed by accelerometers continues to be essential for finding the points at which motion starts and ends. In contrast to the fast growing and diverse requirements of IMU applications for motion segmentation, the evaluation of its accuracy is in need of improvement. Accuracy-oriented evaluation is unable to directly indicate motion discontinuity in the estimated results, and present enough information satisfying various requirements. To complement conventional evaluation methods, we propose a multidimensional evaluation based on new additional evaluation criteria, and justify their availability by assessing nine conventional algorithms. Through an experiment based on 462 handwriting measurements from 19 subjects, we show that algorithms with high accuracy are sensitive to movements that are unintentional and fine, but are unable to specify unexpected motion partitioning. On the other hand, we verify that our proposed metrics describe the status of both energy smoothness and parameter tuning for the motion discontinuity suppression. It also appears that a minimum time delay of 150 ms is required to reliably suppress the motion discontinuity, and algorithms with longer time delay do not always assure sufficient motion discontinuity suppression. Additionally, axial information integration performed only after securing reliable energy smoothness along each axis can guarantee significant performance improvements. As a result, it turns out that a key factor for reliable motion segmentation is how to generate well smoothed energy with minimum time delay, and the deliberate selection of algorithms with smoother energy and less time delay is a better strategy than the delicate parameter adjustment in a fixed algorithm with poorer energy status under the same condition. Using the analysis based on the proposed criteria, the selection of motion segmentation and the adjustment of the parameters for a given purpose are finally introduced as an application of the proposed multidimensional evaluation.
C1 [Lim, Jong Gwan; Kwon, Dong-Soo] Korea Adv Inst Sci & Technol, Human Robot Interact Res Ctr, 291 Daehak Ro, Daejeon 305701, South Korea.
   [Kim, Jaehong] Elect & Telecommun Res Inst, Human Robot Interact Res Lab, 218 Gajeong Ro, Daejeon 305700, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Electronics &
   Telecommunications Research Institute - Korea (ETRI)
RP Kwon, DS (corresponding author), Korea Adv Inst Sci & Technol, Human Robot Interact Res Ctr, 291 Daehak Ro, Daejeon 305701, South Korea.
EM jonggwanlim@gmail.com; jhkim504@etri.re.kr; kwonds@kaist.ac.kr
RI Kwon, Dong-Soo/C-1540-2011
OI Lim, Jong Gwan/0000-0003-1223-0279
FU National Research Foundation of Korea (NRF) - Korea government
   [2010-0028680]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (2010-0028680). We are
   grateful to Lee, Kyoung-koo and No, Seung-dae for graphic illustration,
   and Elmira Yadollahi for proof-reading.
CR Allen RL, 1996, J VAC SCI TECHNOL B, V14, P498, DOI 10.1116/1.588503
   [Anonymous], 5 INT C UB ROB AMB I
   [Anonymous], MEDIATORS INFLAMMATI
   [Anonymous], MULTIMEDIA TOOLS APP
   Baek J, 2004, LECT NOTES ARTIF INT, V3215, P610
   Bang WC, SELF CONTAINED SPATI, P26
   Bao L, 2004, LECT NOTES COMPUT SC, V3001, P1, DOI 10.1007/978-3-540-24646-6_1
   Barger TS, 2005, IEEE T SYST MAN CY A, V35, P22, DOI 10.1109/TSMCA.2004.838474
   BARON R, 1989, IEEE T INSTRUM MEAS, V38, P1132, DOI 10.1109/19.46414
   Benbasat A. Y., 2002, Gesture and Sign Language in Human-Computer Interaction. International Gesture Workshop, GW 2001. Revised Papers (Lecture Notes in Artificial Intelligence Vol.2298), P9
   Borza PV, 2008, THESIS
   Bulling A, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2499621
   Choi ES, 2005, INT C INF TECHN ICIT
   Choi SD, 2012, IEEE T CONSUM ELECTR, V58, P661, DOI 10.1109/TCE.2012.6227474
   Choi SD, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON INFORMATION ACQUISITION, VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P845
   Deng Y, 2003, MAGN RESON MED, V50, P5
   DeVaul R., 2001, REAL TIME MOTION CLA
   Dong Z, 2007, P 2 IEEE INT C NAN M
   Duda R. O., 2012, PATTERN CLASSIFICATI, DOI DOI 10.1007/978-3-319-57027-3_4
   FLASH T, 1985, J NEUROSCI, V5, P1688, DOI 10.1523/jneurosci.05-07-01688.1985
   Gao KL, 2008, HONG KONG PHYSIOTHER, V26, P18, DOI 10.1016/S1013-7025(09)70004-1
   Ge X, 2001, IEEE T SEMICOND ENG
   Godfrey A, 2008, MED ENG PHYS, V30, P1364, DOI 10.1016/j.medengphy.2008.09.005
   Guenterberg E., 2009, Dans Proceedings of the 4th International ICST Conference on Body Area Networks, P21, DOI DOI 10.4108/ICST.BODYNETS2009
   Guo T., 2012, Proceedings of the Eleventh ACM International Workshop on Data Engineering for Wireless and Mobile Access, P7
   Harvey N, 2009, IEEE ENG MED BIO, P7236, DOI 10.1109/IEMBS.2009.5335248
   Hsu YL, 2015, IEEE SENS J, V15, P154, DOI 10.1109/JSEN.2014.2339843
   Huddle JR, 1998, PROCEEDINGS OF THE 1998 WORKSHOP ON AUTONOMOUS UNDERWATER VEHICLES, (AUV '98), P63, DOI 10.1109/AUV.1998.744442
   Junker H, 2008, PATTERN RECOGN, V41, P2010, DOI 10.1016/j.patcog.2007.11.016
   Kahol K, 2003, P 2003 INT C IM PROC, V3, pII
   Kim S, 2009, IEEE T CONSUM ELECTR, V55, P1169, DOI 10.1109/TCE.2009.5277972
   King AD, 1998, GEC REV, V13, P140
   Li Q, 2002, IEEE T SPEECH AUDI P, V10, P146, DOI 10.1109/TSA.2002.1001979
   Liang RH, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P558, DOI 10.1109/AFGR.1998.671007
   Lim JG, 2007, P IEEE FED AUT CONTR, P4
   Lim JG, 2009, IEEE ASME INT C ADV, P203, DOI 10.1109/AIM.2009.5230013
   Liu J, 2008, UWAVE ACCELEROMETER
   Liu JY, 2009, PERVASIVE MOB COMPUT, V5, P657, DOI 10.1016/j.pmcj.2009.07.007
   Milner B, 1999, IEE C DOC PROC MULT
   Nittono H, 2007, LECT NOTES ARTIF INT, V4562, P575
   Ojeda L, 2007, J NAVIGATION, V60, P391, DOI 10.1017/S0373463307004286
   Oppenheim A. V., 1989, Discrete -Time Signal Processing
   Pang G, 2001, J INTELL ROBOT SYST, V30, P249, DOI 10.1023/A:1008113324758
   Smith S. L., 1986, GUIDELINES DESIGNING
   STARNER T, 1994, INT CONF ACOUST SPEE, P125
   Suh YS, 2006, IEEE T IND ELECTRON, V53, P1386, DOI 10.1109/TIE.2006.878292
   Tan CW, 2005, IEEE T INSTRUM MEAS, V54, P2520, DOI 10.1109/TIM.2005.858129
   Thong YK, 2004, MEASUREMENT, V36, P73, DOI 10.1016/j.measurement.2004.04.005
   Wang JS, 2012, IEEE T IND ELECTRON, V59, P2998, DOI 10.1109/TIE.2011.2167895
   Woodman O.J., 2007, University of Cam- bridge, Computer Laboratory, V14, P15
   Wu JH, 2009, LECT NOTES COMPUT SC, V5585, P25
   Zhang G, 2005, IEEE ASME P ADV INTE, P24
   Zhou Y, 2012, ADV INF NETW APPL WO, P25
   Zumer J, 2012, MEASUREMENT, V45, P459, DOI 10.1016/j.measurement.2011.10.027
NR 54
TC 2
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 10907
EP 10934
DI 10.1007/s11042-015-2812-1
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900005
DA 2024-07-18
ER

PT J
AU Parvin, Z
   Seyedarabi, H
   Shamsi, M
AF Parvin, Zahra
   Seyedarabi, Hadi
   Shamsi, Mousa
TI A new secure and sensitive image encryption scheme based on new
   substitution with chaotic function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Security; Image encryption; Chaotic function; Substitution; Sensitivity;
   NPCR
AB In this paper, a new image encryption scheme is proposed with high sensitivity to the plain image. In proposed scheme, two chaotic functions and logical operator xor are used. Image encryption process includes substitution of pixels and permutation. Using the new method of substitution, algorithm sensitivity somewhat has elevated to changes in the plain image that by changing a single pixel of the plain image, amount of NPCR reaches 100 %. Results of tests show that the cipher image does not give any information of statistical such as entropy, histogram and correlation of adjacent pixels to attackers. Also the proposed scheme has the wide key space and is so safe to the noise ratio and compression.
C1 [Parvin, Zahra] Islamic Azad Univ, East Azarbaijan Sci & Res Branch, Dept Commun Engn, Tabriz, Iran.
   [Seyedarabi, Hadi] Univ Tabriz, Fac Elect & Comp Engn, Tabriz, Iran.
   [Shamsi, Mousa] Sahand Univ Technol, Fac Elect Engn, Tabriz, Iran.
C3 Islamic Azad University; University of Tabriz; Sahand University of
   Technology
RP Seyedarabi, H (corresponding author), Univ Tabriz, Fac Elect & Comp Engn, Tabriz, Iran.
EM z.p.parvin@gmail.com; seyedarabi@tabrizu.ac.ir; shamsi@sut.ac.ir
RI Seyedarabi, Hadi/ABD-4603-2021
OI Seyedarabi, Hadi/0000-0001-6652-2467
CR Abd El-Latif AA, 2013, AEU-INT J ELECTRON C, V67, P136, DOI 10.1016/j.aeue.2012.07.004
   Abdullah AH, 2012, AEU-INT J ELECTRON C, V66, P806, DOI 10.1016/j.aeue.2012.01.015
   Bakhshandeh A, 2013, OPT LASER ENG, V51, P665, DOI 10.1016/j.optlaseng.2013.01.001
   Behnia S, 2007, PHYS LETT A, V366, P391, DOI 10.1016/j.physleta.2007.01.081
   Bigdeli N, 2012, ENG APPL ARTIF INTEL, V25, P753, DOI 10.1016/j.engappai.2012.01.007
   François M, 2012, SIGNAL PROCESS-IMAGE, V27, P249, DOI 10.1016/j.image.2011.11.003
   Jiang J, 2004, MULTIMEDIA SYST, V9, P424, DOI 10.1007/s00530-003-0115-2
   Norouzi B, 2014, MULTIMEDIA SYST, V20, P45, DOI 10.1007/s00530-013-0314-4
   Pareek NK, 2013, DIGIT SIGNAL PROCESS, V23, P894, DOI 10.1016/j.dsp.2013.01.005
   Patidar V, 2009, COMMUN NONLINEAR SCI, V14, P3056, DOI 10.1016/j.cnsns.2008.11.005
   Song CY, 2013, OPTIK, V124, P3329, DOI 10.1016/j.ijleo.2012.11.002
   Tong XJ, 2008, IMAGE VISION COMPUT, V26, P843, DOI 10.1016/j.imavis.2007.09.005
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Yang HQ, 2010, COMMUN NONLINEAR SCI, V15, P3507, DOI 10.1016/j.cnsns.2010.01.004
   Zhou YC, 2012, OPT COMMUN, V285, P594, DOI 10.1016/j.optcom.2011.11.044
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
NR 17
TC 85
Z9 86
U1 0
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10631
EP 10648
DI 10.1007/s11042-014-2115-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800026
DA 2024-07-18
ER

PT J
AU Chen, WT
   Chang, KT
   Ko, CP
AF Chen, Wen-Tzu
   Chang, Ku-Tung
   Ko, Chung-Pao
TI Spectrum monitoring for wireless TV and FM broadcast using
   software-defined radio
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless digital TV; FM broadcast; Software-defined radio; Remote
   control; Spectrum monitoring; GNU radio
AB In this paper, the deployment of a radio monitoring system using software-defined radio (SDR) technologies is addressed. The main advantage of using software-defined radio is its reconfigurable ability and flexibility to set the communication parameters when monitoring radio signals. We propose a feasible architecture of spectrum monitoring in which a control center is built using GNU Radio platform; some remote monitoring stations are built with SDR devices. At each remote station, an SDR dongle embedded with Realtek RTL2832U chip and a USRP (universal software radio peripheral) device are used to measure radio signals. Through TCP/IP network, measurement results or complex sampled data from the SDR devices can be sent to the monitoring center. Some key measurement tools for radio monitoring such as spectrum analyzer and audio/video player are also implemented in the proposed system. The major benefit of the proposed architecture is the cost-effective and flexible platform as compared with traditional spectrum monitoring systems. Moreover, both the radio signals and demodulated audio/video content can be remotely monitored at the control center.
C1 [Chen, Wen-Tzu; Chang, Ku-Tung; Ko, Chung-Pao] Natl Cheng Kung Univ, Inst Telecommun Management, Tainan 70101, Taiwan.
C3 National Cheng Kung University
RP Chen, WT (corresponding author), Natl Cheng Kung Univ, Inst Telecommun Management, Tainan 70101, Taiwan.
EM wtchen@mail.ncku.edu.tw
CR Ammar M, 2014, COMPUT IND ENG, P13
   [Anonymous], 2001, Communication Systems
   [Anonymous], 1992, P NAT TEL C
   Crocioni P, 2011, TELECOMMUN POLICY, V35, P568, DOI 10.1016/j.telpol.2011.04.003
   De Donno D, 2013, IEEE T INSTRUM MEAS, V62, P109, DOI 10.1109/TIM.2012.2212513
   ETSI, 2009, 300744 ETSI EN
   Gandhiraj R, 2014, TELECOMMUN SYST, V56, P367, DOI 10.1007/s11235-013-9850-7
   Iacobucci M. S., 2013, RECONFIGURABLE RADIO
   International Telecommunication Union, 2011, HDB SPECTR MON
   Johnson C.R., 2004, Telecommunication Breakdown
   Leszczuk M, 2016, MULTIMED TOOLS APPL, V75, P10745, DOI 10.1007/s11042-014-2229-2
   Mitola J., 2000, SOFTWARE RADIO ARCHI
   Panda AR, 2015, IEEE T IND INFORM, V11, P74, DOI 10.1109/TII.2014.2364557
   Pirazzi G., 2012, P 2012 IEEE 1 AESS E, P1, DOI [10.1109/ESTEL.2012.6400060, DOI 10.1109/ESTEL.2012.6400060]
   Shoaib M, 2014, MULTIMED TOOLS APPL, V73, P2081, DOI 10.1007/s11042-013-1631-5
   Thompson EA, 2012, J NETW COMPUT APPL, V35, P1352, DOI 10.1016/j.jnca.2012.01.020
   Webb W, 2009, TELECOMMUN POLICY, V33, P230, DOI 10.1016/j.telpol.2008.12.007
NR 17
TC 4
Z9 5
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 16
BP 9819
EP 9836
DI 10.1007/s11042-015-2764-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LO
UT WOS:000382112500018
DA 2024-07-18
ER

PT J
AU Santos, MEC
   Almeida, ID
   Yamamoto, G
   Taketomi, T
   Sandor, C
   Kato, H
AF Santos, Marc Ericson C.
   Almeida, Igor de Souza
   Yamamoto, Goshiro
   Taketomi, Takafumi
   Sandor, Christian
   Kato, Hirokazu
TI Exploring legibility of augmented reality X-ray
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Augmented reality X-ray; Empirical study; Legibility;
   Visualization
AB Virtual objects can be visualized inside real objects using augmented reality (AR). This visualization is called AR X-ray because it gives the impression of seeing through the real object. In standard AR, virtual information is overlaid on top of the real world. To position a virtual object inside an object, AR X-ray requires partially occluding the virtual object with visually important regions of the real object. In effect, the virtual object becomes less legible compared to when it is completely unoccluded. Legibility is an important consideration for various applications of AR X-ray. In this research, we explored legibility in two implementations of AR X-ray, namely, edge-based and saliency-based. In our first experiment, we explored on the tolerable amounts of occlusion to comfortably distinguish small virtual objects. In our second experiment, we compared edge-based and saliency-based AR X-ray methods when visualizing virtual objects inside various real objects. Moreover, we benchmarked the legibility of these two methods against alpha blending. From our experiments, we observed that users have varied preferences for proper amounts of occlusion cues for both methods. The partial occlusions generated by the edge-based and saliency-based methods need to be adjusted depending on the lighting condition and the texture complexity of the occluding object. In most cases, users identify objects faster with saliency-based AR X-ray than with edge-based AR X-ray. Insights from this research can be directly applied to the development of AR X-ray applications.
C1 [Santos, Marc Ericson C.; Almeida, Igor de Souza; Yamamoto, Goshiro; Taketomi, Takafumi; Sandor, Christian; Kato, Hirokazu] Nara Inst Sci & Technol, Grad Sch Informat Sci, Interact Media Design Lab, 8916-5 Takayama, Nara 6300192, Japan.
C3 Nara Institute of Science & Technology
RP Santos, MEC (corresponding author), Nara Inst Sci & Technol, Grad Sch Informat Sci, Interact Media Design Lab, 8916-5 Takayama, Nara 6300192, Japan.
EM chavez-s@is.naist.jp
RI Taketomi, Takafumi/AAE-7546-2021; Santos, Marc Ericson/H-6586-2019
OI Santos, Marc Ericson/0000-0002-3735-967X; Kato,
   Hirokazu/0000-0003-3921-2871; SANDOR, Christian/0000-0002-3990-2728
FU JSPS [15J10186]; Grants-in-Aid for Scientific Research [15J10186]
   Funding Source: KAKEN
FX This work was supported by the Grant-in-Aid for JSPS Fellows, Grant
   Number 15J10186.
CR [Anonymous], 2006, INTERACTIONS VISUAL
   [Anonymous], 1993, Usability Engineering
   Avery B, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P79
   BAJURA M, 1992, COMP GRAPH, V26, P203, DOI 10.1145/142920.134061
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Dey A, 2014, INT J HUM-COMPUT ST, V72, P704, DOI 10.1016/j.ijhcs.2014.04.001
   Dey A, 2012, INT SYM MIX AUGMENT, P187, DOI 10.1109/ISMAR.2012.6402556
   Furness T. A.  III, 1986, Proceedings of the Human Factors Society 30th Annual Meeting, P48
   Gabbard JL, 2008, IEEE T VIS COMPUT GR, V14, P513, DOI 10.1109/TVCG.2008.24
   Gabbard JL, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P35
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kalkofen D., 2007, P INT S MIXED AUGMEN, P191, DOI [10.1109/ISMAR.2007.4538846, DOI 10.1109/ISMAR.2007.4538846]
   Kalkofen D, 2013, INT SYM MIX AUGMENT, P1
   Kalkofen D, 2009, IEEE T VIS COMPUT GR, V15, P193, DOI 10.1109/TVCG.2008.96
   Kameda Y, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P151, DOI 10.1109/ISMAR.2004.45
   Kourouthanassis P. E., 2013, MULTIMED TOOLS APPL, P1
   Livingston M. A., 2013, HUMAN FACTORS AUGMEN, P67, DOI DOI 10.1007/978-1-4614-4205-9_4
   Livingston MA, 2005, IEEE COMPUT GRAPH, V25, P6, DOI 10.1109/MCG.2005.130
   Livingston MA, 2013, P IEEE VIRT REAL ANN, P107, DOI 10.1109/VR.2013.6549385
   Peterson SD, 2009, 3DUI : IEEE SYMPOSIUM ON 3D USER INTERFACES 2009, PROCEEDINGS, P111, DOI 10.1109/3DUI.2009.4811215
   Sandor C., 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P27, DOI 10.1109/ISMAR.2010.5643547
   Santos MEC, 2014, IEEE T LEARN TECHNOL, V7, P38, DOI 10.1109/TLT.2013.37
   Santos MEC, 2013, IEEE INT CONF ADV LE, P141, DOI 10.1109/ICALT.2013.45
   Santos MEC, 2015, LECT NOTES ED TECHNO
   Santos MEC, 2014, ACM S VIRT REAL SOFT
   Zollmann Stefanie, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P19, DOI 10.1109/ISMAR.2010.5643546
NR 26
TC 6
Z9 7
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 16
BP 9563
EP 9585
DI 10.1007/s11042-015-2954-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LO
UT WOS:000382112500004
DA 2024-07-18
ER

PT J
AU Sargent, G
   Perez-Daniel, KR
   Stoian, A
   Benois-Pineau, J
   Maabout, S
   Nicolas, H
   Miyatake, MN
   Carrive, J
AF Sargent, Gabriel
   Perez-Daniel, Karina R.
   Stoian, Andrei
   Benois-Pineau, Jenny
   Maabout, Sofian
   Nicolas, Henri
   Nakano Miyatake, Mariko
   Carrive, Jean
TI A scalable summary generation method based on cross-modal consensus
   clustering and OLAP cube modeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video summarization; Scalability; Cross-media space; Consensus
   clustering; Data cube; Drill down
AB Video summarization has been a core problem to manage the growing amount of content in multimedia databases. An efficient video summary should display an overview of the video content and most existing approaches fulfill this goal. However, such an overview does not allow the user to reach all details of interest selectively and progressively. This paper proposes a novel scalable summary generation approach based on the On-Line Analytical Processing data cube. Such a structure integrates tools like the drill down operation allowing to browse efficiently multiple descriptions of a dataset according to increased levels of detail. We adapt this model to video summary generation by expressing a video within a cross-media feature space and by performing clusterings according to particular subspaces. Consensus clustering is used to guide the subspace selection strategy at small dimensions, as the novelty brought by the least consensual subspaces is interesting for the refinements of a summary. Our approach is designed for weakly-structured contents such as cultural documentaries. We perform its evaluation on a corpus of cultural archives provided by the French Audiovisual National Institute (INA) using information retrieval metrics handling single and multiple reference annotations. The performances obtained overall improved results compared to two baseline systems performing random and arbitrary segmentations, showing a better balance between Precision and Recall.
C1 [Sargent, Gabriel; Stoian, Andrei] CNAM, Vertigo CEDRIC, 292 Rue St Martin, F-75141 Paris 03, France.
   [Perez-Daniel, Karina R.; Nakano Miyatake, Mariko] ESIME Culhuacan Natl Polytech Inst IPN, Unidad Profes Adolfo Lopez Mateos, SEPI, Edificio 7, Mexico City 07738, DF, Mexico.
   [Benois-Pineau, Jenny; Maabout, Sofian; Nicolas, Henri] Univ Bordeaux, LaBRI, Domaine Univ,351 Cours Liberat, F-33405 Talence, France.
   [Carrive, Jean] Inst Natl Audiovisuel INA Expert, 4 Ave Europe, F-94366 Bry Sur Marne, France.
C3 heSam Universite; Conservatoire National Arts & Metiers (CNAM);
   Universite de Bordeaux; Communaute Universite Grenoble Alpes; Universite
   Grenoble Alpes (UGA); Centre National de la Recherche Scientifique
   (CNRS)
RP Sargent, G (corresponding author), CNAM, Vertigo CEDRIC, 292 Rue St Martin, F-75141 Paris 03, France.
EM gabriel.sargent@yahoo.fr; krperezd@gmail.com; andrei.stoian@gmail.com;
   benois-p@labri.fr; sofian.maabout@labri.fr; henri.nicolas@labri.fr;
   mnakano@ipn.mx; jcarrive@ina.fr
RI Perez, Karina/AAH-6740-2019; Benois-Pineau, Jenny/ABG-6325-2020; Nakano,
   Mariko/O-2954-2017
OI Perez, Karina/0000-0003-2852-8387; Benois-Pineau,
   Jenny/0000-0003-0659-8894; Nakano, Mariko/0000-0003-1346-7825; Nicolas,
   Henri/0000-0003-2179-4965
FU French National Research Agency [ANR-11-IS02-001]
FX This work is supported by the French National Research Agency grant
   ANR-11-IS02-001 within the joint French-Mexican project Mex-Culture. We
   are grateful to the Institut National de l'Audiovisuel (INA, France) for
   providing us the video content we employed for setting up the
   evaluation. The authors thank Michel Crucianu and Marin Ferecatu for
   valuable discussions and master student Elie Genard for his efficient
   help in conducting computational experiments.
CR Almeida J, 2013, J VIS COMMUN IMAGE R, V24, P729, DOI 10.1016/j.jvcir.2012.01.009
   [Anonymous], 2010, P CIKM
   Bartolini Ilaria, 2011, Proceedings of the International Conference on Signal Processing and Multimedia Applications. SIGMAP 2011, P139
   Bartsch MA, 2005, IEEE T MULTIMEDIA, V7, P96, DOI 10.1109/TMM.2004.840597
   Ben Abdelali A, 2009, INT J SCI TECHNIQUES, V3, P956
   Benini S, 2006, IEEE IMAGE PROC, P133, DOI 10.1109/ICIP.2006.312377
   Benois-Pineau J, 2001, P EUSFLAT 2001, P385
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Goder A, 2008, SIAM PROC S, P109
   GONG B, 2014, ADV NEURAL INFORM PR, P2069
   Gray J, 1997, DATA MIN KNOWL DISC, V1, P29, DOI 10.1023/A:1009726021843
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Kompatsiaris Y., 2012, TV content analysis: Techniques and applications, DOI DOI 10.1201/B11723
   Li YS, 2010, PROCEEDINGS OF THE ASME PRESSURE VESSELS AND PIPING CONFERENCE 2010, VOL 1: CODES AND STANDARDS, P851, DOI 10.1145/1873951.1874095
   Mathieu B., 2010, P 11 INT C MUS INF R, P441
   Messing DS, 2001, IEEE IMAGE PROC, P670, DOI 10.1109/ICIP.2001.959134
   Naci U, 2008, P 2 ACM TRECVID VID, P40
   Peltonen V, 2002, INT CONF ACOUST SPEE, P1941
   PEREIRA Rui Alves., 2014, PLMJ Sociedade de Advogados, P1
   Pinquier J, 2012, INT C PATT RECOG, P3192
   Quenot G., 2008, Proceedings of the TRECVID BBC Rushes Summarization Workshop (TVS 2008) at ACM Multimedia, P80
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang J, 2011, P 2011 IEEE INT C SY, P2449
   Yeung M., 1996, P 13 INT C PATT REC, V3, P375
   Yong-ge W., 2012, ADV CONTROL COMMUNIC, P91
NR 25
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 9073
EP 9094
DI 10.1007/s11042-015-2863-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500014
DA 2024-07-18
ER

PT J
AU Yen, CT
   Huang, YJ
AF Yen, Chih-Ta
   Huang, Yi-Jie
TI Frequency domain digital watermark recognition using image code
   sequences with a back-propagation neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Discrete cosine transform (DCT); Salt-and-pepper
   noise; Gaussian noise; Clipping and rotation; Back-propagation neural
   network (BPNN)
AB Digital watermarking is an encryption technique commonly used to protect intellectual property and copyright. Although watermarks are a robust method of protecting property rights, environmental interference in image propagation through the Internet is inevitable, and human-based image modification can also destroy watermarks. In this study, watermarks (affected by noise interference) were embedded in a 256 x 256 pixel host image by using the discrete cosine transform (DCT) technique, which transfers the spatial domain of the host image into the frequency domain. Subsequently, 32 x 32 pixel watermarked images were embedded as watermark identification codes in the transferred frequency-domain-based host image. The inverse discrete cosine transform (IDCT) technique was used to alter the frequency of the spatial domain, thereby allowing the host image to be visible to the human eye. Several common interferences, such as salt-and-pepper noise, Gaussian noise, clipping, and rotation, were used to destroy the watermarked image. After the destruction process, the watermark was almost discernible in a slightly damaged state, but difficult to identify in a seriously damaged state after using the DCT watermarking scheme. In this study, a back-propagation neural network (BPNN) algorithm combined with a DCT watermarking scheme was used to suppress the interference affecting watermarks. The simulation results of using the proposed DCT-BPNN method indicated that the original watermarked image was restored considerably after being subjected to environmental interference during image propagation.
C1 [Yen, Chih-Ta; Huang, Yi-Jie] Natl Formosa Univ, Dept Elect Engn, Huwei Township 632, Yunlin, Taiwan.
C3 National Formosa University
RP Yen, CT (corresponding author), Natl Formosa Univ, Dept Elect Engn, Huwei Township 632, Yunlin, Taiwan.
EM chihtayen@gmail.com
FU National Science Council [102-2622-E-150-016-CC3]
FX This study was partially supported by the National Science Council under
   Grant No. 102-2622-E-150-016-CC3.
CR Ahmed KA, 2009, CURRENT TRENDS INFOR, P1
   Bhatnagar G, 2012, IET IMAGE PROCESS, V6, P386, DOI 10.1049/iet-ipr.2010.0400
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Cox IJ, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P243, DOI 10.1109/ICIP.1996.560429
   Dongyang Teng, 2010, 2010 IEEE International Conference on Information Theory and Information Security, P826, DOI 10.1109/ICITIS.2010.5689707
   Kalker T, 2004, P IEEE, V92, P961, DOI 10.1109/JPROC.2004.827368
   Kaur R, 2013, INT CONF EMERG TR, P19, DOI 10.1109/ICETET.2013.5
   Mohananthini N., 2012, 2012 International Conference on Advances in Engineering, Science and Management (ICAESM), P100
   Nikolaidis N, 1996, INT CONF ACOUST SPEE, P2168, DOI 10.1109/ICASSP.1996.545849
   Piva A, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P520, DOI 10.1109/ICIP.1997.647964
   Raval MS, 2013, IEEE SYS MAN CYBERN, P328, DOI 10.1109/SMC.2013.62
   Seddik H, 2013, 2013 INT C EL ENG SO, P1
   Xuelong Hu, 2008, 2008 International Conference on Neural Networks and Signal Processing, P430, DOI 10.1109/ICNNSP.2008.4590387
   Yonghong Chen, 2010, 2010 IEEE International Conference on Information Theory and Information Security, P548, DOI 10.1109/ICITIS.2010.5689534
NR 14
TC 20
Z9 20
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 16
BP 9745
EP 9755
DI 10.1007/s11042-015-2718-y
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LO
UT WOS:000382112500014
DA 2024-07-18
ER

PT J
AU Pan, ZB
   Wang, LF
   Hu, S
   Ma, XX
AF Pan, Zhibin
   Wang, Lingfei
   Hu, Sen
   Ma, Xiaoxiao
TI Reversible data hiding in encrypted image using new embedding pattern
   and multiple judgments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data embedding; Encrypted image; Embedding pattern; Error rate
ID HISTOGRAM-MODIFICATION
AB This work proposes a data embedding method in encrypted images. The proposed method introduces a new embedding pattern which using the pixel spatial correlation in a block and border pixels on the block sides to achieve a low error rate effectively. In the extraction end, the neighboring blocks are also adopted to predict the current block to calculate the smoothness more accurately. Experimental results show our proposed method performs better than Zhang's method and Hong's method. In the case of the block size is 8x8, the error rate for the cover image Lena in Zhang's method is 1.25 % and the error rate of Hong's method is 0.34 %, while the error rate in our proposed embedding method reduces to 0.2 %.
C1 [Pan, Zhibin; Wang, Lingfei; Hu, Sen; Ma, Xiaoxiao] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
   [Pan, Zhibin] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Jiangsu, Peoples R China.
C3 Xi'an Jiaotong University; Nanjing University
RP Pan, ZB (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.; Pan, ZB (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Jiangsu, Peoples R China.
EM zbpan@mail.xjtu.edu.cn; Wang.lingfei@stu.xjtu.edu.cn;
   husen.xjtu@gmail.com; xiao.77@stu.xjtu.edu.cn
RI Pan, Zhibin/I-8212-2012
FU Specialized Research Fund for the Doctoral Program of Higher Education
   [20130201110071]; Key Science and Technology Program of Shaanxi Province
   [2012GY2-30]; Open Project Program of the State Key Lab of SKL, Nanjing
   University [KFKT2013B05]
FX This work is supported in part by Specialized Research Fund for the
   Doctoral Program of Higher Education (Grant No. 20130201110071), Project
   Supported by Key Science and Technology Program of Shaanxi Province
   (Grant No. 2012GY2-30) and Open Project Program of the State Key Lab of
   SKL (Grant No. KFKT2013B05), Nanjing University.
CR Chang CC, 2006, IEEE T CIRC SYST VID, V16, P1301, DOI 10.1109/TCSVT.2006.882380
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Lee JD, 2010, IEEE T INF FOREN SEC, V5, P638, DOI 10.1109/TIFS.2010.2066971
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 9
TC 9
Z9 9
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 14
BP 8595
EP 8607
DI 10.1007/s11042-015-2773-4
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LW
UT WOS:000382113300021
DA 2024-07-18
ER

PT J
AU Son, J
   Kang, MS
   Min, D
   Sohn, K
AF Son, Jongin
   Kang, Minsung
   Min, Dongbo
   Sohn, Kwanghoon
TI EMCCD color correction based on spectral sensitivity analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color correction; EMCCD; Spectral sensitivity
AB The sensor response function of a color camera is very essential to understand an overall camera imaging pipeline and to process captured images. It is also true when we characterize underlying imaging behaviors of the electron multiplying charge coupled device (EMCCD) camera, which was recently proposed to acquire color images in low-light-level conditions. Unlike existing CCD cameras, the EMCCD camera contains partially uni-modal spectral sensitivity functions (SSFs), some of which consists of two base (bi-modal) functions, thus often leading to a serious color distortion in existing characterization techniques. To address this problem, we propose a novel method that corrects output colors of the EMCCD camera by analyzing its partially uni-modal characteristics. Specifically, our goal is to correct such color distortion by adjusting bi-modal SSFs to be uni-modal. We remove the secondary region of bi-modal channels using a pre-calculated spectral sensitivity of the EMCCD camera. Experimental results demonstrate that the proposed method reduces the color distortion as well as enlarges a color gamut, which is crucial to color reproduction.
C1 [Son, Jongin; Kang, Minsung; Min, Dongbo; Sohn, Kwanghoon] Yonsei Univ, Dept Elect & Elect Engn, Seoul 120749, South Korea.
   [Min, Dongbo] Chungnam Natl Univ, Dept Comp Sci & Engn, Daejeon 305764, South Korea.
C3 Yonsei University; Chungnam National University
RP Sohn, K (corresponding author), Yonsei Univ, Dept Elect & Elect Engn, Seoul 120749, South Korea.
EM go3son@yonsei.ac.kr; mskang83@gmail.com; dbmin@cnu.ac.kr;
   khsohn@yonsei.ac.kr
FU National Research Foundation of Korea (NRF) - Korea government (MSIP)
   [NRF-2013R1A2A2A01068338]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIP)
   (NRF-2013R1A2A2A01068338).
CR [Anonymous], 2007, CMOS/ CCD sensors and camera systems
   Barnard K, 2002, COLOR RES APPL, V27, P152, DOI 10.1002/col.10050
   Coates CG, 2003, PROC SPIE, V5139, P56, DOI 10.1117/12.500583
   Denvir D. J., 2002, P SOC PHOTO-OPT INS, V4796, P167
   Fairchild M.D., 2005, Color Appearance Models, V2nd
   Finlayson GD, 2006, IEEE T PATTERN ANAL, V28, P59, DOI 10.1109/TPAMI.2006.18
   Finlayson GD, 2001, J OPT SOC AM A, V18, P253, DOI 10.1364/JOSAA.18.000253
   Finlayson GD, 1998, SIXTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P90
   Francisco G, 2004, INT SOC OPT PHOTONIC, P811
   Hong GW, 2001, COLOR RES APPL, V26, P76, DOI 10.1002/1520-6378(200102)26:1<76::AID-COL8>3.0.CO;2-3
   Jerram P, 2001, P SOC PHOTO-OPT INS, V4306, P178, DOI 10.1117/12.426953
   Jerram P.A., 2006, SNIC S, P1
   Johnson CB, 1998, P SOC PHOTO-OPT INS, V3434, P45, DOI 10.1117/12.331220
   Kang H. R., 1992, Journal of Electronic Imaging, V1, P125, DOI 10.1117/12.57526
   Kang M, 2011, ELECTRON LETT, V47, P1369, DOI 10.1049/el.2011.2501
   Kang M, 2009, OPT ENG, V48, DOI 10.1117/1.3191785
   KRIESEL J, 2006, MIL SENS S MSS SPEC
   Kriesel JM, 2010, PROC SPIE, V7697, DOI 10.1117/12.849575
   Luo MR, 2006, COLOR RES APPL, V31, P320, DOI 10.1002/col.20227
   Morovic J, 2001, COLOR RES APPL, V26, P85, DOI 10.1002/1520-6378(200102)26:1<85::AID-COL9>3.0.CO;2-2
   Robbins MS, 2003, IEEE T ELECTRON DEV, V50, P1227, DOI 10.1109/TED.2003.813462
   Sharma G, 2005, COLOR RES APPL, V30, P21, DOI 10.1002/col.20070
   Shen HL, 2004, J OPT SOC AM A, V21, P1125, DOI 10.1364/JOSAA.21.001125
   Trussell H., 1993, 1 SIDS COLOR IMAGING, P103
   Zhang WF, 2008, J OPT SOC AM A, V25, P2286, DOI 10.1364/JOSAA.25.002286
NR 25
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 13
BP 7589
EP 7604
DI 10.1007/s11042-015-2682-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DR5EA
UT WOS:000379924600007
DA 2024-07-18
ER

PT J
AU Hatim, A
   Belkouch, S
   Benslimane, A
   Hassani, MM
   Sadiki, T
AF Hatim, Anas
   Belkouch, Said
   Benslimane, Abderrahim
   Hassani, Moha M'Rabet
   Sadiki, Tayeb
TI Efficient architecture for direct 8x8 2D DCTcomputations with earlier
   zigzag ordering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DCT; Zigzag; Quantification; FPGA; Image compression; Video and image
   processing
ID DISCRETE; ALGORITHM; TRANSFORM
AB In this paper, we propose a low complexity architecture for direct 2D DCT zigzag reordering and quantization merged architecture. The architecture will transform the pixels from spatial to spectral domain with the required quality constraints of the compression standards. We developed a new architecture to achieve the computations of the 2D DCT directly without any transposition memory. The coefficients are quantized and approximated using shift operations. We defined Sk functions blocks to build the 2D DCT architecture. The Sk block performs 8 functions depending on the control signals of the system. The number of additions/subtractions used is 63. Moreover, no multiplications and no transposition memory are needed. The sequence of the 2D DCT coefficients is computed with respect to the zigzag reordering. This allows us to produce zigzag ordered 2D DCT coefficients. The architecture is suitable for usage with statistical rules to predict the zero quantized coefficients, which can considerably reduce the video processing computations. The architecture is easily extensible to increase its performances. We implemented the design using an FPGA Cyclone 3. The design can reach up to 244 MHz and uses 1188 logic elements, and respects the real time HDTV video requirements with low power consumption.
C1 [Hatim, Anas; Belkouch, Said] Univ Cadi Ayyad, Ecole Natl Sci Appl, Embedded Syst & Digital Control Lab, PB 575,Av Abdelkarim Khattabi, Marrakech, Morocco.
   [Benslimane, Abderrahim] Univ Avignon, LIA CERI, BP 9122884911, Avignon 9, France.
   [Hassani, Moha M'Rabet] Cadi Ayyad Univ, Fac Sci Semlalia, Marrakech, Morocco.
   [Sadiki, Tayeb] Int Univ Rabat UIR, ELIT Dept, Rabat, Morocco.
C3 Cadi Ayyad University of Marrakech; Avignon Universite; Cadi Ayyad
   University of Marrakech; Universite Internationale de Rabat
RP Benslimane, A (corresponding author), Univ Avignon, LIA CERI, BP 9122884911, Avignon 9, France.
EM hatim.anas@gmail.com; s.belcouch@uca.ma;
   abderrahim.benslimane@univ-avignon.fr; hassani@ucam.ac.ma;
   tayeb.sadiki@uir.ma
RI Benslimane, Abderrahim/AFL-0418-2022
OI Benslimane, Abderrahim/0000-0001-9307-6132; Hatim,
   Anas/0000-0002-3540-8036
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Al-Azawi S, 2012, IET C IM PROC, DOI [10.1049/cp.2012.0460, DOI 10.1049/CP.2012.0460]
   [Anonymous], 2009, 2009 INT C MICR ICM
   [Anonymous], 2010, P 2010 INT S INFORM
   Bi GA, 2000, IEEE T CIRCUITS-II, V47, P893, DOI 10.1109/82.868457
   Chan Y-H, 1991, IEEE PAC RIM C COMM
   Chen CH, 2004, IEEE T CIRCUITS-I, V51, P2017, DOI [10.1109/TCSI.2004.835685, 10.1109/tcsi.2004.835685]
   CHO NI, 1992, IEEE T SIGNAL PROCES, V40, P2166, DOI 10.1109/78.157217
   Geetha S, 2012, INT J COMPUT ELECT E, V4
   Gonzalez RC., Digital image processing third edition Pearson international edition prepared by Pearson Education
   Hallapuro A, 2003, IEEE T CIRC SYST VID, V13
   Hatim A, 2012, MULTIMEDIA TOOL APPL
   HOU HS, 1987, IEEE T ACOUST SPEECH, V35, P1455
   Hsia SC, 2010, J SIGNAL PROCESS SYS, V58, P161, DOI 10.1007/s11265-009-0344-5
   HSU CY, 1987, ELECTRON LETT, V23, P466, DOI 10.1049/el:19870336
   Huang YM, 1999, IEEE T ACOUST SPEECH, V47
   Huang YS, 2015, MULTIMED TOOLS APPL, V74, P4927, DOI 10.1007/s11042-014-1856-y
   Jridi M, 2013, PROC SPIE, V8656, DOI 10.1117/12.2006174
   Jridi M, 2012, VLSI DES, DOI 10.1155/2012/209208
   Kim CG, 2013, MULTIMED TOOLS APPL, V64, P475, DOI 10.1007/s11042-012-1028-x
   Kishore B, 2015, J REAL-TIME IMAGE PR, V10, P551, DOI 10.1007/s11554-012-0282-5
   Kitsos P, 2013, P 18 INT C DIG SIGN, V1, P1, DOI [10.1109/icdsp.2013.6622742, DOI 10.1109/ICDSP.2013.6622742]
   Kok CW, 1997, IEEE T SIGNAL PROCES, V45, P757, DOI 10.1109/78.558495
   Mahmood F, 2011, AL RAFADAIN ENG J, V19, P55
   MALVAR HS, 1987, IEEE T ACOUST SPEECH, V35, P1484, DOI 10.1109/TASSP.1987.1165043
   Parfieniuk M, 2013, IET CIRC DEVICE SYST, V7, P150, DOI 10.1049/iet-cds.2012.0233
   Pereira F., 2002, IMSC Press multimedia series
   Pradeepthi T., 2011, INT J VLSI DESIGN CO, V2, P99, DOI DOI 10.5121/vlsic.2011.2308
   Rajapaksha N, 2013, J ELECTR COMPUT ENG, V2013, DOI 10.1155/2013/834793
   Rao KR, 1990, DISCREATE COSINE TRA
   Saponara S, 2003, PROCEEDINGS OF THE 46TH IEEE INTERNATIONAL MIDWEST SYMPOSIUM ON CIRCUITS & SYSTEMS, VOLS 1-3, P1567, DOI 10.1109/MWSCAS.2003.1562597
   Shu H, 2007, IEEE SIGNAL PROCESS, V14
   Siddiqui MF, 2014, SCI WORLD J, DOI 10.1155/2014/620868
   Tumeo A, 2007, PIPELINED FAST 2D DC
   Wu ZG, 2009, IEEE T CONSUM ELECTR, V55, P685, DOI 10.1109/TCE.2009.5174440
   Xiuhua J, 2011, MULTIMED TOOLS APPL, V63, P1
NR 36
TC 7
Z9 7
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 11
BP 6121
EP 6141
DI 10.1007/s11042-015-2562-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP5QZ
UT WOS:000378553700005
DA 2024-07-18
ER

PT J
AU Ignatov, AD
   Strijov, VV
AF Ignatov, Andrey D.
   Strijov, Vadim V.
TI Human activity recognition using quasiperiodic time series collected
   from a single tri-axial accelerometer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; k-nearest neighbor method; Neural network;
   Segmentation; Physical activity recognition; Singular value
   decomposition
ID PHYSICAL-ACTIVITY; PATTERN; POSTURE; SYSTEM
AB The current generation of portable mobile devices incorporates various types of sensors that open up new areas for the analysis of human behavior. In this paper, we propose a method for human physical activity recognition using time series, collected from a single tri-axial accelerometer of a smartphone. Primarily, the method solves a problem of online time series segmentation, assuming that each meaningful segment corresponds to one fundamental period of motion. To extract the fundamental period we construct the phase trajectory matrix, applying the technique of principal component analysis. The obtained segments refer to various types of human physical activity. To recognize these activities we use the k-nearest neighbor algorithm and neural network as an alternative. We verify the accuracy of the proposed algorithms by testing them on the WISDM dataset of labeled accelerometer time series from thirteen users. The results show that our method achieves high precision, ensuring nearly 96 % recognition accuracy when using the bunch of segmentation and k-nearest neighbor algorithms.
C1 [Ignatov, Andrey D.; Strijov, Vadim V.] Moscow Inst Phys & Technol, Inst Skii Per 9, Dolgoprudnyi 141700, Moscow Region, Russia.
C3 Moscow Institute of Physics & Technology
RP Ignatov, AD (corresponding author), Moscow Inst Phys & Technol, Inst Skii Per 9, Dolgoprudnyi 141700, Moscow Region, Russia.
EM andrey.ignatoff@gmail.com; strijov@ccas.ru
RI Strijov, Vadim Victor/A-4786-2011
OI Strijov, Vadim/0000-0002-2194-8859
FU Russian Foundation for Basic Research (RFBR) [14-07-31326]; Ministry of
   Education and Science of the Russian Federation [RFMEFI60414X0041]
FX This work is supported by the Russian Foundation for Basic Research
   (RFBR) under grant number 14-07-31326 and by the Ministry of Education
   and Science of the Russian Federation, RFMEFI60414X0041.
CR Altun K, 2010, LECT NOTES COMPUT SC, V6219, P38, DOI 10.1007/978-3-642-14715-9_5
   [Anonymous], MEDIATORS INFLAMMATI
   [Anonymous], 2012, WISDMS ACTIVITY PRED
   Bao L, 2004, LECT NOTES COMPUT SC, V3001, P1, DOI 10.1007/978-3-540-24646-6_1
   Barralon Pierre, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P1711
   BELLMAN R, 1961, COMMUN ACM, V4, P284, DOI 10.1145/366573.366611
   Brajdic A, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P225, DOI 10.1145/2493432.2493449
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chiang SY, 2012, SMART INNOV SYST TEC, V16, P191
   Chin T-J, 2007, 2007 IEEE INT C IM P, V1, P383
   Chung FL, 2004, IEEE T EVOLUT COMPUT, V8, P471, DOI 10.1109/TEVC.2004.832863
   Foerster F, 2000, BEHAV RES METH INS C, V32, P450, DOI 10.3758/BF03200815
   Goyal P., 2011, 2011 INT C INDOOR PO, P1
   Kai K, 2013, CLASSIFICATION MOBIL
   Keogh E, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P289, DOI 10.1109/ICDM.2001.989531
   Keogh E., 1993, DATA MINING TIME SER, P1
   Khan AM, 2008, IEEE ENG MED BIO, P5172, DOI 10.1109/IEMBS.2008.4650379
   Kwapisz JR., 2011, ACM SIGKDD EXPLORATI, V12, P74, DOI [DOI 10.1145/1964897.1964918, 10.1145/1964897.1964918]
   Liu W, 2016, MULTIMED TOOLS APPL, V75, P1481, DOI 10.1007/s11042-014-2004-4
   Liu W, 2014, SIGNAL PROCESSING
   Liu WF, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0108474
   Lockhart J, 2011, FORDHAM UNDERGRADUAT, V1, P67
   Lockhart JW, 2014, PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP'14 ADJUNCT), P747, DOI 10.1145/2638728.2641306
   Loudon J, 2008, HUMAN KINETICS, V2, P395
   Mannini A, 2010, SENSORS-BASEL, V10, P1154, DOI 10.3390/s100201154
   Mi Zhang, 2011, Proceedings of the 2011 Tenth International Conference on Machine Learning and Applications (ICMLA 2011), P7, DOI 10.1109/ICMLA.2011.92
   Mo LFF, 2012, IEEE T BIO-MED ENG, V59, P3230, DOI 10.1109/TBME.2012.2208458
   Mysore P., 2005, AAAI, V5, P1541
   Nyan MN, 2006, J BIOMECH, V39, P2647, DOI 10.1016/j.jbiomech.2005.08.014
   Olivares A, 2012, SENSORS-BASEL, V12, P5791, DOI 10.3390/s120505791
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Shultz SJ, 2005, HUMAN KINETICS, V2, P55
   Tapia EM, 2007, ELEVENTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P37
   Thuer G, 2008, THESIS
   Wang SQ, 2005, PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS AND BRAIN, VOLS 1-3, P1212
   Wen-Ming Cao, 2010, Natural Science, V2, P49, DOI 10.4236/ns.2010.21007
   Ying H, 2007, IFMBE PROC, V13, P80
   Yurur O, 2013, ELECTRON LETT, V49, DOI 10.1049/el.2013.0592
   Zhang M, 2013, IEEE J BIOMED HEALTH, V17, P553, DOI 10.1109/JBHI.2013.2253613
NR 39
TC 55
Z9 56
U1 1
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 7257
EP 7270
DI 10.1007/s11042-015-2643-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400026
DA 2024-07-18
ER

PT J
AU Gupta, S
   Phung, D
   Venkatesh, S
AF Gupta, Sunil
   Dinh Phung
   Venkatesh, Svetha
TI Modelling multilevel data in multimedia: A hierarchical factor analysis
   approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Multilevel data; Beta process; Dirichlet process; Semantic
   gap; Bayesian nonparametrics
AB Multimedia content understanding research requires rigorous approach to deal with the complexity of the data. At the crux of this problem is the method to deal with multilevel data whose structure exists at multiple scales and across data sources. A common example is modeling tags jointly with images to improve retrieval, classification and tag recommendation. Associated contextual observation, such as metadata, is rich that can be exploited for content analysis. A major challenge is the need for a principal approach to systematically incorporate associated media with the primary data source of interest. Taking a factor modeling approach, we propose a framework that can discover low-dimensional structures for a primary data source together with other associated information. We cast this task as a subspace learning problem under the framework of Bayesian nonparametrics and thus the subspace dimensionality and the number of clusters are automatically learnt from data instead of setting these parameters a priori. Using Beta processes as the building block, we construct random measures in a hierarchical structure to generate multiple data sources and capture their shared statistical at the same time. The model parameters are inferred efficiently using a novel combination of Gibbs and slice sampling. We demonstrate the applicability of the proposed model in three applications: image retrieval, automatic tag recommendation and image classification. Experiments using two real-world datasets show that our approach outperforms various state-of-the-art related methods.
C1 [Gupta, Sunil; Dinh Phung; Venkatesh, Svetha] Deakin Univ, Ctr Pattern Recognit & Data Analyt, Waurn Ponds, Australia.
C3 Deakin University
RP Phung, D (corresponding author), Deakin Univ, Ctr Pattern Recognit & Data Analyt, Waurn Ponds, Australia.
EM sunil.gupta@deakin.edu.au; dinh.phung@deakin.edu.au;
   svetha.venkatesh@deakin.edu.au
RI Phung, Dinh Q/D-1328-2012
OI Phung, Dinh/0000-0002-9977-8247; gupta, sunil/0000-0002-4669-9940;
   Venkatesh, Svetha/0000-0001-8675-6631
CR [Anonymous], 2012, P 2012 SIAM INT C DA
   [Anonymous], P 28 C UNC ART INT U
   [Anonymous], 2007, Artificial Intelligence and Statistics, P564
   [Anonymous], 2007, P MACH LEARN RES
   [Anonymous], 2006, P INT C WORLD WIDE W
   [Anonymous], 2009, CIVR
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   Cao Bin, 2010, P 24 AAAI C ART INT
   Chen N, 2012, IEEE T PATTERN ANAL
   Wang C, 2009, PROC CVPR IEEE, P1903, DOI [10.1109/CVPR.2009.5206800, 10.1109/CVPRW.2009.5206800]
   Dunson DB, 2008, BIOMETRIKA, V95, P307, DOI 10.1093/biomet/asn012
   FERGUSON TS, 1973, ANN STAT, V1, P209, DOI 10.1214/aos/1176342360
   Ferrari V, 2004, PROC CVPR IEEE, P105
   Gilks W.R., 1995, Markov Chain Monte Carlo in practice: interdisciplinary statistics, V2
   HJORT NL, 1990, ANN STAT, V18, P1259, DOI 10.1214/aos/1176347749
   Mcauliffe Jon, 2007, Advances in Neural Information Processing Systems, V20
   Nikolopoulos S, 2012, SIGNAL PROCESS
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Shengli Yuan, 2010, Proceedings 2010 IEEE Global Communications Conference (GLOBECOM 2010), DOI 10.1109/GLOCOM.2010.5683786
   Vidal R, 2011, IEEE SIGNAL PROC MAG, V28, P52, DOI 10.1109/MSP.2010.939739
   Xing E.P., 2005, P C UNCERTAINTY ARTI, P633
   Yang J., 2007, SIAM C DAT MIN, P1
NR 26
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 9
BP 4933
EP 4955
DI 10.1007/s11042-014-2394-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DM8HE
UT WOS:000376601700006
DA 2024-07-18
ER

PT J
AU Wu, ZZ
   Li, HZ
AF Wu, Zhizheng
   Li, Haizhou
TI On the study of replay and voice conversion attacks to text-dependent
   speaker verification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speaker verification; Spoofing attack; Replay; Voice conversion;
   Security
ID RECOGNITION; SECURITY; ADAPTATION
AB Automatic speaker verification (ASV) is to automatically accept or reject a claimed identity based on a speech sample. Recently, individual studies have confirmed the vulnerability of state-of-the-art text-independent ASV systems under replay, speech synthesis and voice conversion attacks on various databases. However, the behaviours of text-dependent ASV systems have not been systematically assessed in the face of various spoofing attacks. In this work, we first conduct a systematic analysis of text-dependent ASV systems to replay and voice conversion attacks using the same protocol and database, in particular the RSR2015 database which represents mobile device quality speech. We then analyse the interplay of voice conversion and speaker verification by linking the voice conversion objective evaluation measures with the speaker verification error rates to take a look at the vulnerabilities from the perspective of voice conversion.
C1 [Wu, Zhizheng] Univ Edinburgh, CSTR, Edinburgh, Midlothian, Scotland.
   [Li, Haizhou] Inst Infocomm Res, Human Language Technol Dept, Singapore, Singapore.
C3 University of Edinburgh; Agency for Science Technology & Research
   (A*STAR); A*STAR - Institute for Infocomm Research (I2R)
RP Wu, ZZ (corresponding author), Univ Edinburgh, CSTR, Edinburgh, Midlothian, Scotland.
EM zhizheng.wu@ed.ac.uk; hli@i2r.a-star.edu.sg
RI Li, Haizhou/Q-6438-2019
OI Li, Haizhou/0000-0001-9158-9401
CR Alegre F., 2013, P INT C BIOM THEOR A
   [Anonymous], P IEEE INT C AC SPEE
   [Anonymous], P INT
   [Anonymous], P INT
   [Anonymous], P INT
   [Anonymous], P INT
   [Anonymous], P IEEE INT C AC SPEE
   [Anonymous], P IEEE INT C AC SPEE
   Bonastre J.-F., 2007, P INT
   Bonastre JF, 2006, P OD SPEAK LANG REC
   Campbell JP, 1997, P IEEE, V85, P1437, DOI 10.1109/5.628714
   Center ST, RT SOPH DISTR SOL RE
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   De Leon PL, 2012, IEEE T AUDIO SPEECH, V20, P2280, DOI 10.1109/TASL.2012.2201472
   Dehak N, 2007, IEEE T AUDIO SPEECH, V15, P2095, DOI 10.1109/TASL.2007.902758
   Farrus M, 2008, P OD SPEAK LANG REC
   Faundez-Zanuy M, 2006, SPEECH COMMUN, V48, P1608, DOI 10.1016/j.specom.2006.06.010
   Hautamaki RG, 2013, P INT
   Hebert Matthieu, 2008, Springer handbook of speech processing, P743
   Hunt AJ, 1996, P IEEE INT C AC SPEE
   Jin Q, 2008, P IEEE INT C AC SPEE
   Kinnunen T, 2010, SPEECH COMMUN, V52, P12, DOI 10.1016/j.specom.2009.08.009
   Kockmann M, 2010, P IEEE INT C AC SPEE
   Kons Z., 2013, P INT
   Larcher A, 2014, SPEECH COMMUN, V60, P56, DOI 10.1016/j.specom.2014.03.001
   Larcher A, 2013, DIGIT SIGNAL PROCESS, V23, P1910, DOI 10.1016/j.dsp.2013.07.007
   Lau YW, 2004, P IEEE INT S INT MUL
   Lee CH, 2000, P IEEE, V88, P1241, DOI 10.1109/5.880082
   Lee K.A., 2013, IEEE Signal Processing Society Speech and language Technical Committee Newsletter
   Lee KA, 2011, P INT
   Li HZ, 2013, P IEEE, V101, P1136, DOI 10.1109/JPROC.2012.2237151
   Li HZ, 2010, IEEE SIGNAL PROC MAG, V27, P139, DOI 10.1109/MSP.2010.938083
   Lindberg J., 1999, 6 EUR C SPEECH COMM
   Masuko T, 2000, P INT C SPOK LANG PR
   Masuko T., 1999, P EUR C SPEECH COMM
   Qian Y, 2013, IEEE T AUDIO SPEECH, V21, P280, DOI 10.1109/TASL.2012.2221460
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Satoh T, 2001, P EUR C SPEECH COMM
   Shriberg E, 2005, SPEECH COMMUN, V46, P455, DOI 10.1016/j.specom.2005.02.018
   Stafylakis T, 2013, P INT
   Stylianou Y, 1998, IEEE T SPEECH AUDI P, V6, P131, DOI 10.1109/89.661472
   Toda T, 2007, IEEE T AUDIO SPEECH, V15, P2222, DOI 10.1109/TASL.2007.907344
   Villalba J, 2010, P FALA 10 WORKSH
   Wu Z, 2012, P AS PAC SIGN INF PR, P1
   Wu Z, 2013, P IEEE INT C AC SPEE
   Wu Z., 2013, P INT
   Wu Z., 2014, AS PAC SIGN INF PROC
   Wu ZZ, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P879
   Wu ZZ, 2014, APSIPA TRANS SIGNAL, V3, DOI 10.1017/ATSIP.2014.17
   Wu ZZ, 2015, SPEECH COMMUN, V66, P130, DOI 10.1016/j.specom.2014.10.005
   Yamagishi J, 2009, IEEE T AUDIO SPEECH, V17, P66, DOI 10.1109/TASL.2008.2006647
   Zen H, 2009, SPEECH COMMUN, V51, P1039, DOI 10.1016/j.specom.2009.04.004
NR 53
TC 36
Z9 37
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 9
BP 5311
EP 5327
DI 10.1007/s11042-015-3080-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DM8HE
UT WOS:000376601700027
DA 2024-07-18
ER

PT J
AU Cappelletto, E
   Zanuttigh, P
   Cortelazzo, GM
AF Cappelletto, Enrico
   Zanuttigh, Pietro
   Cortelazzo, Guido M.
TI 3D scanning of cultural heritage with consumer depth cameras
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D reconstruction; Kinect; ICP; Depth map
AB Three dimensional reconstruction of cultural heritage objects is an expensive and time-consuming process. Recent consumer real-time depth acquisition devices, like Microsoft Kinect, allow very fast and simple acquisition of 3D views. However 3D scanning with such devices is a challenging task due to the limited accuracy and reliability of the acquired data. This paper introduces a 3D reconstruction pipeline suited to use consumer depth cameras as hand-held scanners for cultural heritage objects. Several new contributions have been made to achieve this result. They include an ad-hoc filtering scheme that exploits the model of the error on the acquired data and a novel algorithm for the extraction of salient points exploiting both depth and color data. Then the salient points are used within a modified version of the ICP algorithm that exploits both geometry and color distances to precisely align the views even when geometry information is not sufficient to constrain the registration. The proposed method, although applicable to generic scenes, has been tuned to the acquisition of sculptures and in this connection its performance is rather interesting as the experimental results indicate.
C1 [Cappelletto, Enrico; Zanuttigh, Pietro; Cortelazzo, Guido M.] Univ Padua, Dept Informat Engn, Padua, Italy.
C3 University of Padua
RP Zanuttigh, P (corresponding author), Univ Padua, Dept Informat Engn, Padua, Italy.
EM enrico.cappelletto@dei.unipd.it; zanuttigh@dei.unipd.it;
   corte@dei.unipd.it
RI Zanuttigh, Pietro/AAB-9555-2019
OI Zanuttigh, Pietro/0000-0002-9502-2389
CR Andreetto M, 2004, IEEE T IMAGE PROCESS, V13, P352, DOI 10.1109/TIP.2003.821351
   [Anonymous], 2011, P CVPR
   [Anonymous], 2010, 3DPVT
   [Anonymous], ADV COMPUTER VISION
   [Anonymous], 1998, P ICCV
   Argan GC, 2001, 2 NOVECENTO ARTE MOD
   Bernardini F, 2002, COMPUT GRAPH FORUM, V21, P149, DOI 10.1111/1467-8659.00574
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Cappelletto E, 2013, IEEE INT WORKSH MULT, P367, DOI 10.1109/MMSP.2013.6659316
   Cui Y, 2010, P CVPR 2010
   Cui Y, 2013, IEEE T PATTERN ANAL, V35, P1039, DOI 10.1109/TPAMI.2012.190
   DalMutto C, 2012, SPRBRIEF ELECT, P1, DOI 10.1007/978-1-4614-3807-6
   El-Hakim SF, 2004, IEEE COMPUT GRAPH, V24, P21, DOI 10.1109/MCG.2004.1297007
   Henry P, 2012, INT J ROBOT RES, V31, P647, DOI 10.1177/0278364911434148
   Herrera CD, 2012, IEEE T PATTERN ANAL, V34, P2058, DOI 10.1109/TPAMI.2012.125
   Holzer S, 2012, IEEE INT C INT ROBOT, P2684, DOI 10.1109/IROS.2012.6385999
   Khoshelham K, 2011, P ISPRS WORKSH LAS S, P38
   Khoshelham K, 2012, SENSORS-BASEL, V12, P1437, DOI 10.3390/s120201437
   Khosravani A., 2012, P LC3D WORKSH
   LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735
   Levoy M, 2000, COMP GRAPH, P131, DOI 10.1145/344779.344849
   Mara H., 2007, P 2 ISPRS INT WORKSH, P10
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Pavlidis G, 2007, J CULT HERIT, V8, P93, DOI 10.1016/j.culher.2006.10.007
   Pollefeys M, 2008, VIRTUAL REALITY ARCH, P71
   Remondino F, 2011, REMOTE SENS-BASEL, V3, P1104, DOI 10.3390/rs3061104
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Seitz S. M., 2006, 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06), V1, P519
   Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3
   Sprickerhof J, 2009, P ECMR
   Tong J, 2012, IEEE T VIS COMPUT GR, V18, P643, DOI 10.1109/TVCG.2012.56
   Torsello A, 2011, P 3DIMPVT 2011
   Whelan T., 2012, Robust tracking for real-time dense RGB-D mapping with kintinuous
   Young Min Kim, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1542, DOI 10.1109/ICCVW.2009.5457430
NR 34
TC 15
Z9 16
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 7
BP 3631
EP 3654
DI 10.1007/s11042-014-2065-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DI0GB
UT WOS:000373172200004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Nogueira, K
   Veloso, AA
   dos Santos, JA
AF Nogueira, Keiller
   Veloso, Adriano Alonso
   dos Santos, Jefersson Alex
TI Pointwise and pairwise clothing annotation: combining features from
   social media
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image annotation; Clothing annotation; Bag of visual words; Machine
   learning; Multi-modal; Multi-instance; Multi-label
ID IMAGE FEATURES; RETRIEVAL; COLOR
AB In this paper, we present effective algorithms to automatically annotate clothes from social media data, such as Facebook and Instagram. Clothing annotation can be informally stated as recognizing, as accurately as possible, the garment items appearing in the query photo. This task brings huge opportunities for recommender and e-commerce systems, such as capturing new fashion trends based on which clothes have been used more recently. It also poses interesting challenges for existing vision and recognition algorithms, such as distinguishing between similar but different types of clothes or identifying a pattern of a cloth even if it has different colors and shapes. We formulate the annotation task as a multi-label and multi-modal classification problem: (i) both image and textual content (i. e., tags about the image) are available for learning classifiers, (ii) the classifiers must recognize a set of labels (i. e., a set of garment items), and (iii) the decision on which labels to assign to the query photo comes from a set of instances that is used to build a function, which separates labels that should be assigned to the query photo, from those that should not be assigned. Using this configuration, we propose two approaches: (i) the pointwise one, called MMCA, which receives a single image as input, and (ii) a multi-instance classification, called M3CA, also known as pairwise approach, which uses pair of images to create the classifiers. We conducted a systematic evaluation of the proposed algorithms using everyday photos collected from two major fashion-related social media, namely pose. com and chictopia. com. Our results show that the proposed approaches provide improvements when compared to popular first choice multi-label, multi-modal, multi-instance algorithms that range from 20 % to 30 % in terms of accuracy.
C1 [Nogueira, Keiller; Veloso, Adriano Alonso; dos Santos, Jefersson Alex] Univ Fed Minas Gerais, Dept Comp Sci, Ave Presidente Antonio Carlos 6627, BR-31270901 Belo Horizonte, MG, Brazil.
C3 Universidade Federal de Minas Gerais
RP Nogueira, K (corresponding author), Univ Fed Minas Gerais, Dept Comp Sci, Ave Presidente Antonio Carlos 6627, BR-31270901 Belo Horizonte, MG, Brazil.
EM keiller.nogueira@dcc.ufmg.br; adrianov@dcc.ufmg.br;
   jefersson@dcc.ufmg.br
RI dos Santos, Jefersson/HKW-4282-2023
OI dos Santos, Jefersson/0000-0002-8889-1586
FU CNPq [449638/2014-6]; CAPES; Fundacao de Apoio a Pesquisa do Estado de
   Minas Gerais (Fapemig) [APQ-00768-14]; PRPq/Universidade Federal de
   Minas Gerais; Finep; InWeb - the Brazilian National Institute of Science
   and Technology for the Web
FX The authors would like to acknowledge grants from CNPq (grant
   449638/2014-6), CAPES, Fundacao de Apoio a Pesquisa do Estado de Minas
   Gerais (Fapemig, under the grant APQ-00768-14), PRPq/Universidade
   Federal de Minas Gerais, Finep, and InWeb - the Brazilian National
   Institute of Science and Technology for the Web.
CR Agrawal R., 1993, SIGMOD Record, V22, P207, DOI 10.1145/170036.170072
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   [Anonymous], 2013, ICMR
   [Anonymous], C COMP VIS PATT REC
   [Anonymous], 2008, J COMPUT APPL MATH
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Avila S., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2909, DOI 10.1109/ICIP.2011.6116268
   Baeza-Yates R A, 2011, MODERN INFORM RETRIE
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bekele D, 2013, IEEE IMAGE PROC, P3652, DOI 10.1109/ICIP.2013.6738753
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   BOUREAU YL, 2010, PROC CVPR IEEE, P2559, DOI DOI 10.1109/CVPR.2010.5539963
   Briggs F, 2012, P 18 ACM SIGKDD INT, P534, DOI [DOI 10.1145/2339530.2339616, 10.1145/2339530.2339616]
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   dos Santos JA, 2012, INT C PATT RECOG, P3078
   dos Santos JA, 2010, VISAPP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P203
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Escalante HJ, 2012, INFORM RETRIEVAL, V15, P1, DOI 10.1007/s10791-011-9170-z
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   FAYYAD UM, 1993, IJCAI-93, VOLS 1 AND 2, P1022
   Feng SH, 2010, EXPERT SYST APPL, V37, P661, DOI 10.1016/j.eswa.2009.06.111
   Gallagher AC, 2008, C COMP VIS PATT REC
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   GUILLAUMIN M, 2010, PROC CVPR IEEE, P902, DOI DOI 10.1109/CVPR.2010.5540120
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Huang CB, 2007, INT C COMMUN CIRCUIT, P772
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li R, 2010, KNOWL-BASED SYST, V23, P195, DOI 10.1016/j.knosys.2009.11.020
   Liu S, 2012, PROC CVPR IEEE, P3330, DOI 10.1109/CVPR.2012.6248071
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu Zhaolao, 2013, Human-Computer Interaction. Towards Intelligent and Implicit Interaction. 15th International Conference, HCI International 2013. Proceedings: LNCS 8008, P289, DOI 10.1007/978-3-642-39342-6_32
   Mahmoudi F, 2003, PATTERN RECOGN, V36, P1725, DOI [10.1016/S0031-3203(03)00010-4, 10.1016/S0031-3203(03)000104]
   Makadia A, 2008, LECT NOTES COMPUT SC, V5304, P316, DOI 10.1007/978-3-540-88690-7_24
   Maron O, 1998, ADV NEUR IN, V10, P570
   Ming Yang, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2937, DOI 10.1109/ICIP.2011.6116276
   Moran S., 2014, P INT C MULTIMEDIA R, P113
   Nguyen C, 2013, INT JOINT C ART INT
   Nogueira K, 2014, 2014 27TH SIBGRAPI CONFERENCE ON GRAPHICS, PATTERNS AND IMAGES (SIBGRAPI), P327, DOI 10.1109/SIBGRAPI.2014.37
   Ntalianis K, 2014, MULTIMED TOOLS APPL, V69, P397, DOI 10.1007/s11042-012-0995-2
   Oliva A, 2006, PROG BRAIN RES, V155, P23, DOI 10.1016/S0079-6123(06)55002-2
   Pass G., 1996, P 4 ACM INT C MULT, V96, P65, DOI DOI 10.1145/244130.244148
   Penatti OAB, 2012, J VIS COMMUN IMAGE R, V23, P359, DOI 10.1016/j.jvcir.2011.11.002
   PHILBIN J, 2008, C COMP VIS PATT REC
   Read J, 2008, IEEE DATA MINING, P995, DOI 10.1109/ICDM.2008.74
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Shen E, 2007, 2007 INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P365
   Simo-Serra E, 2014, AS C COMP VIS
   Sivic J, 2006, LECT NOTES COMPUT SC, V4170, P127
   Snow R, 2008, P 2008 C EMP METH NA, P254, DOI DOI 10.3115/1613715.1613751
   Socher R., 2011, PROC INT C MACH LEAR, P129
   Stehling R. O., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P102, DOI 10.1145/584792.584812
   Suh B, 2007, INTERACT COMPUT, V19, P524, DOI 10.1016/j.intcom.2007.02.002
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tang JH, 2010, IEEE T MULTIMEDIA, V12, P131, DOI 10.1109/TMM.2009.2037373
   Tao B, 2000, J VIS COMMUN IMAGE R, V11, P327, DOI 10.1006/jvci.1999.0448
   Tie-Yan Liu, 2009, Foundations and Trends in Information Retrieval, V3, P225, DOI 10.1561/1500000016
   Tokumaru M, 2002, INT C FUZZ SYST KNOW, P207
   Torres R. S. D., 2006, RITA, V13, P161
   Tsoumakas G., 2006, Multi-label classification: An overview
   Tsoumakas G., 2007, INT J DATA WAREHOUS, V3, P1, DOI DOI 10.4018/JDWM.2007070101
   Tuytelaars T, 2010, PROC CVPR IEEE, P2281, DOI 10.1109/CVPR.2010.5539911
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
   UNSER M, 1986, IEEE T PATTERN ANAL, V8, P118, DOI 10.1109/TPAMI.1986.4767760
   van Gemert JC, 2008, LECT NOTES COMPUT SC, V5304, P696
   Veloso A, 2007, LECT NOTES ARTIF INT, V4702, P605
   Veloso A, 2006, IEEE DATA MINING, P645
   Vens C, 2008, MACH LEARN, V73, P185, DOI 10.1007/s10994-008-5077-3
   Vogiatzis D, 2012, EXPERT SYST APPL, V39, P10647, DOI 10.1016/j.eswa.2012.02.178
   Weber M., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P361, DOI 10.1109/AVSS.2011.6027351
   Xie L, 2015, MULTIMED TOOLS APPL, V74, P613, DOI 10.1007/s11042-014-2018-y
   Yamaguchi K, 2013, IEEE I CONF COMP VIS, P3519, DOI 10.1109/ICCV.2013.437
   Yamaguchi K, 2012, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2012.6248101
   Yang S.-H., 2009, P ADV NEURAL INFORM, P2143
   Yang Y., 2011, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, page, V1385-1392, P2011, DOI DOI 10.1109/CVPR.2011.5995741
   Zhang DS, 2012, PATTERN RECOGN, V45, P346, DOI 10.1016/j.patcog.2011.05.013
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   Zhou ZH, 2012, ARTIF INTELL, V176, P2291, DOI 10.1016/j.artint.2011.10.002
NR 79
TC 8
Z9 8
U1 1
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 7
BP 4083
EP 4113
DI 10.1007/s11042-015-3087-2
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DI0GB
UT WOS:000373172200025
DA 2024-07-18
ER

PT J
AU Wang, SF
   Wu, S
   Gao, Z
   Ji, Q
AF Wang, Shangfei
   Wu, Shan
   Gao, Zhen
   Ji, Qiang
TI Facial expression recognition through modeling age-related spatial
   patterns
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Expression recognition; Age-related spatial patterns; Privileged
   information; Bayesian networks
ID DATABASE; YOUNG
AB In this paper we tackle the problem of expression recognition by exploiting age-related spatial facial expression patterns, which carry crucial information that have not been thoroughly exploited. First, we conduct two statistic hypothesis tests to investigate age effect on the spatial patterns of expressions and on facial expression recognition respectively. Second, we propose two methods to recognize expressions by modeling age-related spatial facial expression patterns. One is a three-node Bayesian Network to classify expressions with the help of age from person-independent geometric features. The other is to construct multiple Bayesian networks to explicitly capture the spatial facial expression patterns for different ages. For both methods, age information is used as privileged information, which is only available during training, and is exploited during training to construct a better classifier. Statistic analyses on two benchmark databases, i.e. the Lifespan and the FACES, verify the age effect on spatial patterns of expressions and on facial expression recognition. Experimental results of expression recognition demonstrate the effectiveness of the proposed methods in modelling age-related spatial patterns as well as their superior expression recognition performance to existing approaches.
C1 [Wang, Shangfei; Wu, Shan; Gao, Zhen] Univ Sci & Technol China, Sch Comp Sci & Technol, Key Lab Comp & Commun Software Anhui Prov, Hefei 230027, Anhui, Peoples R China.
   [Ji, Qiang] Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Rensselaer Polytechnic Institute
RP Wang, SF (corresponding author), Univ Sci & Technol China, Sch Comp Sci & Technol, Key Lab Comp & Commun Software Anhui Prov, Hefei 230027, Anhui, Peoples R China.
EM sfwang@ustc.edu.cn; sa14ws@mail.ustc.edu.cn; gzgqllxh@mail.ustc.edu.cn;
   qji@ecse.rpi.edu
CR Alnajar F, EXPRESSION INVARIANT
   [Anonymous], STAT METHODS EXPT DE
   Bayramoglu N., 2013, INT CONF BIOMETR, P1
   COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dethlefsen, DEAL PACKAGE LEARNIN
   Dibeklioglu H, 2015, IEEE T MULTIMEDIA, V17, P279, DOI 10.1109/TMM.2015.2394777
   Ebner NC, 2010, COGNITION EMOTION, V24, P1095, DOI 10.1080/02699930903128395
   Ebner NC, 2010, BEHAV RES METHODS, V42, P351, DOI 10.3758/BRM.42.1.351
   Fölster M, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00030
   Guo G, 2013, FACIAL EXPRESSION RE
   Heckerman D, 2008, STUD COMPUT INTELL, V156, P33
   Hess U, 2012, J EXP SOC PSYCHOL, V48, P1377, DOI 10.1016/j.jesp.2012.05.018
   Houstis O, 2009, EUR J ORTHODONT, V31, P459, DOI 10.1093/ejo/cjp019
   John P.W. M., 1971, Statistical design and analysis of experiments
   Koller D., 2009, Probabilistic graphical models: principles and techniques
   Lee Y., 2001, P 33 S INT CIT
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Minear M, 2004, BEHAV RES METH INS C, V36, P630, DOI 10.3758/BF03206543
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Shan W, 2015, FG2015 IN PRESS
   Siegel S., 1956, Nonparametric statistics for the behavioral sciences
   Vapnik V, 2009, NEURAL NETWORKS, V22, P544, DOI 10.1016/j.neunet.2009.06.042
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
NR 24
TC 5
Z9 5
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 7
BP 3937
EP 3954
DI 10.1007/s11042-015-3107-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DI0GB
UT WOS:000373172200018
DA 2024-07-18
ER

PT J
AU Zheng, XW
   Li, Y
   Liu, H
   Duan, HC
AF Zheng, Xiang-wei
   Li, Yan
   Liu, Hong
   Duan, Hui-chuan
TI A study on a cooperative character modeling based on an improved NSGA II
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Character modeling; Multi-objective; NSGA II; ACIS rules; Cooperative
   evaluation
ID DESIGN
AB Different animation characters are loved by people at different ages, in different countries and from different background, which implies the difficulties of designing characters that might be loved by many. Grouping different designers together by computer networks or the Internet is surely a good solution to design a character with expected popularity. This paper presents a character modeling method based on an improved non-dominated sorting genetic algorithm II (CMIN). CMIN borrows ideas from biological evolution, especially from multi-objective genetic algorithm (MOGA) and is formalized as a procedure for character modeling. CMIN adopts binary tree data structure to express transformation rules which are used to diversify character models and uses crossover and mutation operators of genetic algorithm to generate new rules. CMIN also adopts cooperative multi-objective evaluation on generated characters. The objectives are designed to embody both qualitative and quantitative aspects of character personalities, which are assigned by different cooperative designers and calculated automatically by computers respectively. The incorporation of qualitative and quantitative evaluation is formally realized by introducing a MOGA framwork. A multi-objective evaluation-based cooperative character modeling system (MOCMS) was developed to verify the proposed CMIN. Representative case studies demonstrate that the proposed method can evolve character models according to the designers' intentions and preferences and generate creative character models far beyond man's own imagination.
C1 [Zheng, Xiang-wei; Li, Yan; Liu, Hong; Duan, Hui-chuan] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Peoples R China.
   [Zheng, Xiang-wei; Li, Yan; Liu, Hong; Duan, Hui-chuan] Shandong Prov Key Lab Distributed Comp Software N, Jinan 250014, Peoples R China.
C3 Shandong Normal University
RP Zheng, XW (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Peoples R China.
EM sdnuzxw@126.com
RI Liu, Hong/W-8431-2019
FU national natural science foundation of China [61373149, 61272094,
   61202225]; promotive research fund for excellent young and middle-aged
   scientists of Shandong province [BS2010DX033]; Shandong province higher
   educational science and technology program [J10LG08]
FX We are grateful to anonymous reviewers for their valuable comments and
   suggestions. This research was supported by national natural science
   foundation of China (61373149, 61272094, 61202225), the promotive
   research fund for excellent young and middle-aged scientists of Shandong
   province (BS2010DX033) and a project of Shandong province higher
   educational science and technology program (J10LG08).
CR Basori AH, 2014, COMPUT HUM BEHAV, V35, P307, DOI 10.1016/j.chb.2014.03.013
   Brintrup AM, 2008, IEEE T EVOLUT COMPUT, V12, P343, DOI 10.1109/TEVC.2007.904343
   Coello CAC, 2006, IEEE COMPUT INTELL M, V1, P28, DOI 10.1109/MCI.2006.1597059
   Corne D., 2003, IEEE Connect. Newslett, V1, P9
   Deb K, 2001, LECT NOTES COMPUT SC, V1993, P385
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Ecemis MI, 2008, IEEE T EVOLUT COMPUT, V12, P591, DOI 10.1109/TEVC.2007.913131
   Hanchao Yu, 2011, Proceedings of the 2011 15th International Conference on Computer Supported Cooperative Work in Design (CSCWD), P296, DOI 10.1109/CSCWD.2011.5960089
   Herrera F, 2004, EUR J OPER RES, V153, P90
   Kim JH, 2008, IEEE COMPUT INTELL M, V3, P43, DOI 10.1109/MCI.2008.913368
   Laumanns M, 2005, APPL INTELL, V23, P55, DOI 10.1007/s10489-005-2372-6
   Liu H, 2006, APPL SOFT COMPUT, V6, P207, DOI 10.1016/j.asoc.2005.01.003
   Liu H, 2006, COMPUT INTEGR MANUF
   Magnenat-Thalmann N, 2005, VISUAL COMPUT, V21, P997, DOI 10.1007/s00371-005-0363-6
   Maïm J, 2009, IEEE COMPUT GRAPH, V29, P82, DOI 10.1109/MCG.2009.129
   Srinivas N., 1994, Evolutionary Computation, V2, P221, DOI 10.1162/evco.1994.2.3.221
   Thalmann D, 2013, CROWD SIMULATION, P31
   [徐江 XU Jiang], 2007, [计算机集成制造系统, Computer Integrated Manufacturing Systems], V13, P1470
   Xu QL, 2006, RES ENG DES, V17, P27, DOI 10.1007/s00163-006-0015-5
   young chu hye, 2014, [Archives of Design Research, 디자인학연구], V27, P117, DOI 10.15187/adr.2014.02.109.1.117
NR 20
TC 13
Z9 13
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4305
EP 4320
DI 10.1007/s11042-015-2476-x
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700007
DA 2024-07-18
ER

PT J
AU Ghadi, M
   Laouamer, L
   Moulahi, T
AF Ghadi, Musab
   Laouamer, Lamri
   Moulahi, Tarek
TI Securing data exchange in wireless multimedia sensor networks:
   perspectives and challenges
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Security; Wireless multimedia sensor networks; QoS; Secure routing
   protocol; Fault tolerance; Robustness; Recovery process
ID ENERGY-EFFICIENT; TRUST MANAGEMENT; PROTOCOL; AWARE; AUTHENTICATION;
   TRANSMISSION; COVERAGE; INTERNET
AB The emerging use of Wireless Multimedia Sensor Networks (WMSNs) and communication facilities have increased the need for network security measures to protect different types of multimedia data either real time or non-real time during the transmission period. A lot of researchers are becoming more interested on secure WMSNs due to the broad application necessities which can be range over smart environment, security surveillance and smart health-care; so requirements on secure aggregation of multimedia data, Quality of Service (QoS) and privacy should be satisfied. Current technologies vs. proposed security techniques in WMSNs and its pros and cons from a security point of view are explored in details. In addition to promising future trends of this research area by giving more attention for new challenging problems including secure routing protocol, fault tolerant, robustness and recovery process. We believe that this paper will add significantly a valuable discussion among the researchers and promote them to fetch new research ideas to design approximately best model by combining the most important security issues in order to reach secure WMSNs.
C1 [Ghadi, Musab] Qassim Univ, COC, Dept Comp Sci, POB 6633, Buridah 51452, Saudi Arabia.
   [Laouamer, Lamri; Moulahi, Tarek] Qassim Univ, CBE, Dept Management Informat Syst, POB 6633, Buridah 51452, Saudi Arabia.
   [Laouamer, Lamri] Univ Bretagne Occidentale, Lab STICC, 20 Ave Victor Le Gorgeu,BP 817-CS 93837, F-29238 Brest, France.
C3 Qassim University; Qassim University; Universite de Bretagne Occidentale
RP Ghadi, M (corresponding author), Qassim Univ, COC, Dept Comp Sci, POB 6633, Buridah 51452, Saudi Arabia.
EM mqalghadi7@gmail.com; laoamr@qu.edu.sa; tarek.moulahi@femto-st.fr
RI Moulahi, Tarek/AAE-8665-2022
OI Moulahi, Tarek/0000-0002-5173-3656
CR Akan ÖB, 2005, IEEE ACM T NETWORK, V13, P1003, DOI 10.1109/TNET.2005.857076
   Akyildiz IF, 2007, IEEE WIREL COMMUN, V14, P32, DOI 10.1109/MWC.2007.4407225
   Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   Almalkawi IT, 2010, SENSORS-BASEL, V10, P6662, DOI 10.3390/s100706662
   AlNuaimi M., 2011, 2011 International Conference on Innovations in Information Technology (IIT), P191, DOI 10.1109/INNOVATIONS.2011.5893815
   [Anonymous], P 53 IEEE GLOB COMM
   [Anonymous], IEEE INT C COMM ICC
   [Anonymous], INT J COMPUT NETW WI
   [Anonymous], 12 IEEE S ISCC
   [Anonymous], BROADBAND COMMUN NET
   [Anonymous], 8 INT C SEM KNOWL GR
   [Anonymous], 2002, P 1 ACM INT WORKSH W, DOI DOI 10.1145/570738.570744
   [Anonymous], 2012, P 10 INT C ADV MOB C
   [Anonymous], 2010, WIRELESS SENSOR NETW
   [Anonymous], INT J ADV TECHNOLOGY
   [Anonymous], 2005, Ad Hoc & Sensor Wirel. Netw., DOI DOI 10.1155/2012/720734
   [Anonymous], 2013, WOMEN EXITING PRISON
   [Anonymous], P ACM MULT SEC WORKS
   [Anonymous], 2012, P 2012 6 INT C APPL
   [Anonymous], P ICACT 2006, DOI DOI 10.1109/ICACT.2006.206151
   [Anonymous], 1999, P NETW DISTR SYST SE
   [Anonymous], BROADBAND COMMUNICAT
   [Anonymous], IEEE INT C COMPL SYS
   [Anonymous], IEEE INT C COMM ICC
   [Anonymous], 2007, SECURITY SENSOR NETW
   [Anonymous], SECURE WIRELESS MULT
   Batalin MA, 2004, TELECOMMUN SYST, V26, P181, DOI 10.1023/B:TELS.0000029038.31947.d1
   Boukerche A, 2010, Q2SWINET 2010: PROCEEDINGS OF THE SIXTH ACM SYMPOSIUM ON QOS AND SECURITY FOR WIRELESS AND MOBILE NETWORKS, P33
   Chilamkurti N., 2009, Journal of Sensors, DOI 10.1155/2009/134165
   Cobo L, 2010, COMPUT NETW, V54, P2991, DOI 10.1016/j.comnet.2010.05.014
   Dam T., 2003, the 1st International Conference on Embedded Networked Sensor Systems, P171, DOI DOI 10.1145/958491.958512
   Du XJ, 2006, WIREL COMMUN MOB COM, V6, P375, DOI 10.1002/wcm.402
   Ehsan S, 2012, IEEE COMMUN SURV TUT, V14, P265, DOI 10.1109/SURV.2011.020211.00058
   Ganeriwal S, 2004, IEEE INT CONF ROBOT, P5244, DOI 10.1109/ROBOT.2004.1302550
   Guerrero-Zapata M, 2010, TELECOMMUN SYST, V45, P77, DOI 10.1007/s11235-009-9235-0
   Hamid MA, 2008, GLOB TELECOMM CONF, DOI 10.1109/GLOCOM.2008.ECP.159
   Han K, 2013, IEEE COMMUN MAG, V51, P107, DOI 10.1109/MCOM.2013.6553686
   Harjito B., 2010, Proceedings of the 2010 International Conference on Broadband, Wireless Computing, Communication and Applications (BWCCA 2010), P842, DOI 10.1109/BWCCA.2010.182
   Harjito Bambang, 2010, 2010 4th IEEE International Conference on Digital Ecosystems and Technologies (DEST 2010), P640, DOI 10.1109/DEST.2010.5610580
   He DJ, 2012, IEEE T INF TECHNOL B, V16, P1164, DOI 10.1109/TITB.2012.2199996
   He DJ, 2012, IEEE T INF TECHNOL B, V16, P623, DOI 10.1109/TITB.2012.2194788
   Josang A, 2007, DECIS SUPPORT SYST, V43, P618, DOI 10.1016/j.dss.2005.05.019
   Kandris D, 2011, AD HOC NETW, V9, P591, DOI 10.1016/j.adhoc.2010.09.001
   Khalifeh A, 2008, IEEE WCNC, P3191
   Vu K, 2011, IEEE INFOCOM SER, P2015, DOI 10.1109/INFCOM.2011.5935008
   Kondo Shinya, 2010, Proceedings of the 13th International Conference on Network-Based Information Systems (NBiS 2010), P62, DOI 10.1109/NBiS.2010.58
   Kundur D, 2008, P IEEE, V96, P112, DOI 10.1109/JPROC.2007.909914
   Li M, 2013, P IEEE, V101, P2538, DOI 10.1109/JPROC.2013.2257631
   Lin K, 2012, COMPUT COMMUN, V35, P1902, DOI 10.1016/j.comcom.2012.03.010
   Liu FC, 2012, IEEE I C EMBED SOFTW, P1368, DOI 10.1109/HPCC.2012.201
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Liu Xiang, 2011, 2011 8th Annual IEEE Communications Society Conference on Sensor, Mesh and Ad Hoc Communications and Networks (SECON 2011), P46, DOI 10.1109/SAHCN.2011.5984932
   Madria S, 2009, AD HOC NETW, V7, P1051, DOI 10.1016/j.adhoc.2008.09.005
   Masood Haris, 2010, 2010 International Conference on Information, Networking and Automation (ICINA 2010), P37, DOI 10.1109/ICINA.2010.5636438
   Nagarathna K., 2012, 2012 4th International Conference on Computational Intelligence, Communication Systems and Networks (CICSyN 2012), P53, DOI 10.1109/CICSyN.2012.20
   Poojary S., 2010, Proceedings of the 2010 International Conference on Broadband, Wireless Computing, Communication and Applications (BWCCA 2010), P379, DOI 10.1109/BWCCA.2010.100
   Sarisaray P, 2007, I S MOD ANAL SIM COM, P73
   Saxena N, 2008, COMPUT NETW, V52, P2532, DOI 10.1016/j.comnet.2008.05.009
   Sharif A, 2009, IEEE INTL CONF IND I, P606, DOI 10.1109/INDIN.2009.5195872
   Sheng ZG, 2013, IEEE WIREL COMMUN, V20, P91, DOI 10.1109/MWC.2013.6704479
   Shin J, 2013, IEEE CONF WIREL MOB, P253, DOI 10.1109/WiMOB.2013.6673369
   Shu L, 2010, TELECOMMUN SYST, V44, P79, DOI 10.1007/s11235-009-9227-0
   Song SS, 2006, IEEE T COMPUT, V55, P703, DOI 10.1109/TC.2006.89
   Sun Y, 2012, IEEE T DEPEND SECURE, V9, P785, DOI 10.1109/TDSC.2012.68
   Tsitsipis D., 2011, 2011 19th Mediterranean Conference on Control & Automation (MED 2011), P1160
   Vasilakos A, 2012, WIREL NETW MOB COMMU, P1
   Venkatasubramanian KK, 2010, IEEE T INF TECHNOL B, V14, P60, DOI 10.1109/TITB.2009.2037617
   Wang GL, 2006, IEEE T MOBILE COMPUT, V5, P640, DOI 10.1109/TMC.2006.80
   Wang GL, 2003, 11TH IEEE INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, PROCEEDINGS, P315
   Wang HG, 2013, J SUPERCOMPUT, V64, P883, DOI 10.1007/s11227-010-0500-5
   Wang HG, 2010, IEEE T MULTIMEDIA, V12, P215, DOI 10.1109/TMM.2010.2041102
   Wang HX, 2013, INT J DISTRIB SENS N, DOI 10.1155/2013/791814
   Xie T, 2008, IEEE T PARALL DISTR, V19, P682, DOI 10.1109/TPDS.2007.70776
   Yaghmaee MH, 2009, COMPUT NETW, V53, P1798, DOI 10.1016/j.comnet.2009.02.011
   Yan Z, 2014, J NETW COMPUT APPL, V42, P120, DOI 10.1016/j.jnca.2014.01.014
   Yang Yang, 2010, IET International Conference on Wireless Sensor Network 2010 (IET-WSN 2010), P380, DOI 10.1049/cp.2010.1083
   Yao YJ, 2013, IEEE INT CONF MOB, P182, DOI 10.1109/MASS.2013.44
   Ye W, 2002, IEEE INFOCOM SER, P1567, DOI 10.1109/INFCOM.2002.1019408
   Yigitel MA, 2011, COMPUT COMMUN, V34, P1991, DOI 10.1016/j.comcom.2011.06.006
   Yin J, 2006, 20TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 1, PROCEEDINGS, P393
   You L, 2011, COMM COM INF SC, V158, P410
   Zeng YY, 2013, WIREL NETW, V19, P161, DOI 10.1007/s11276-012-0457-9
   Zhang ZY, 2012, IEEE T INF TECHNOL B, V16, P1070, DOI 10.1109/TITB.2012.2206115
   Zhe-yuan Xiong, 2011, 2011 International Conference on Information Science and Technology (ICIST 2011), P665, DOI 10.1109/ICIST.2011.5765335
   Zhe-yuan Xiong, 2010, 2010 Third International Workshop on Advanced Computational Intelligence (IWACI 2010), P618, DOI 10.1109/IWACI.2010.5585161
   Zhou L, 2011, IEEE J SEL AREA COMM, V29, P1358, DOI 10.1109/JSAC.2011.110803
NR 86
TC 29
Z9 29
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 6
BP 3425
EP 3451
DI 10.1007/s11042-014-2443-y
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DH6BI
UT WOS:000372875600024
DA 2024-07-18
ER

PT J
AU Kang, K
   Cao, Y
   Zhang, J
   Wang, ZF
AF Kang, Kai
   Cao, Yang
   Zhang, Jing
   Wang, Zengfu
TI Salient object detection and classification for stereoscopic images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stereoscopic saliency; Object detection; Object classification
ID VISUAL-ATTENTION; SELECTION
AB Stereoscopic images have become more and more prevalent following the rapid advances in 3D capturing and display techniques. However, there has been little research on visual content analysis for stereoscopic images. In this paper, we address the challenging problem of object detection and classification for stereoscopic images. An iterative method that can mutually boost salient object detection and object classification is proposed for stereoscopic images. This method includes two steps. In the first step, a 3D saliency detection method, which includes the contrastive and occlusion cues contained in each stereoscopic image pair along with the discriminative features provided by the SVM classifier, is proposed to localize object of interest in the stereoscopic images. In the second step, the bag of word features of foreground and background is pooled by using the localization information, and then is applied to train the SVM classifier. Each of the two steps benefits from the gradual improvement result in the other, no matter in the training or the testing process. To evaluate the performance of our approach, a 6-object class dataset of stereoscopic images real objects viewed under general lighting conditions, poses and viewpoints is set up. Our experimental results on the dataset, for object localization and object classification, demonstrate the effectiveness of the method.
C1 [Kang, Kai; Cao, Yang; Zhang, Jing; Wang, Zengfu] Univ Sci & Technol China, Dept Automat, Hefei 230026, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Cao, Y (corresponding author), Univ Sci & Technol China, Dept Automat, Hefei 230026, Anhui, Peoples R China.
EM forrest@ustc.edu.cn
RI Cao, Yang/HGD-6463-2022
CR [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2003, P IEEE INT C COMP VI
   [Anonymous], BRIT MACH VIS C BMVC
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2006, PROC IEEE C COMPUTER
   [Anonymous], P SPIE
   [Anonymous], 2009, P IEEE C COMP VIS PA
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2010, P IEEE C COMP VIS PA
   [Anonymous], 2007, P IEEE C COMP VIS PA
   [Anonymous], 2009, P IEEE C COMP VIS PA
   Bilen H, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.17
   Bruce N, 2005, P CAN C COMP ROB VIS
   Bruce N., 2006, P ADV NEUR INF PROC, P155
   Chai Y, 2011, IEEE INT C COMP VIS
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Gao DS, 2009, IEEE T PATTERN ANAL, V31, P989, DOI 10.1109/TPAMI.2009.27
   He K., 2010, EUR C COMP VIS ECCV
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Liu WF, 2014, COMPUT VIS IMAGE UND, V118, P50, DOI 10.1016/j.cviu.2013.03.007
   Liu WF, 2013, IEEE T IMAGE PROCESS, V22, P2676, DOI 10.1109/TIP.2013.2255302
   Mai L, 2013, P IEEE C COMP VIS PA
   Maki A, 1996, P INT C PATT REC
   Nguyen MH, 2009, IEEE I CONF COMP VIS, P1925, DOI 10.1109/ICCV.2009.5459426
   Murphy KevinP., 2006, CATEGORY LEVEL OBJEC
   Murray N., 2011, P IEEE C COMP VIS PA
   Niu Y., 2012, P IEEE C COMP VIS PA
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Ouerhani N, 2000, P INT C PATT REC
   Potapova Ekaterina, 2011, Computer Vision Systems. Proceedings 8th International Conference (ICVS 2011), P132, DOI 10.1007/978-3-642-23968-7_14
   Reynolds JH, 2003, NEURON, V37, P853, DOI 10.1016/S0896-6273(03)00097-7
   Rhemann C, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995372
   Russakovsky O, 2012, THE EUROPEAN CONFERE
   Tatler BW, 2005, VISION RES, V45, P643, DOI 10.1016/j.visres.2004.09.017
   van Zoest W, 2004, PERCEPTION, V33, P927, DOI 10.1068/p5158
   Wolfe JM, 2004, NAT REV NEUROSCI, V5, P495, DOI 10.1038/nrn1411
   Zha Z-J, 2014, ACM T INTELLIGENT SY
   Zha ZJ, 2013, IEEE T CIRC SYST VID, V23, P856, DOI 10.1109/TCSVT.2012.2226526
   Zha ZJ, 2012, IEEE T MULTIMEDIA, V14, P17, DOI 10.1109/TMM.2011.2174782
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhang Y, 2010, LECT NOTES COMPUT SC, V5916, P314, DOI 10.1007/978-3-642-11301-7_33
NR 43
TC 6
Z9 7
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 3
BP 1443
EP 1457
DI 10.1007/s11042-014-2142-8
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HW
UT WOS:000371309600006
DA 2024-07-18
ER

PT J
AU Chen, SL
   Sun, ZX
   Zhang, Y
   Li, Q
AF Chen, Songle
   Sun, Zhengxing
   Zhang, Yan
   Li, Qian
TI Relevance feedback for human motion retrieval using a boosting approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion capture data; Motion retrieval; Relevance feedback; RankBoost;
   Ranking loss
ID IMAGE RETRIEVAL; FEATURE-SELECTION; KERNEL
AB Content-based human motion retrieval (CBMR) has been more and more important with the rapid growth of motion capture data, but the gap between high-level semantic concepts and low-level features hinders further performance improvement. Relevance feedback is an effective tool to narrow the semantic gap and enhance the retrieval performance. However, as a type of variable-length multivariate time series (VLMTS), motion capture data has its own characteristics including high-dimensionality, demand for elastic matching, and difficulty representing different movements in a uniform feature space, which make it much more challenging to design an effective relevance feedback approach. This paper presents a novel boosting approach for CBMR and the main contributions include three aspects. First, to fit in with the characteristics of VLMTS data and meet the real-time requirement of relevance feedback, the ensemble learning framework RankBoost is introduced and k-nearest neighbors combining with dynamic time warping (KNN-DTW) is employed as its weak ranker. Second, the set of extended Boolean geometry features containing much richer geometry elements and measures is used to represent motion content, and it provides a comparatively complete feature set for designing the weak ranker of RankBoost. Third, to solve the over-fitting problem caused by the small-sample training of relevance feedback, a novel learning objective composed of minimizing empirical ranking loss and minimizing the maximum generalization loss is proposed for RankBoost ensemble learning. Experimental results on CMU database and its extended database verify the effectiveness of the proposed approach.
C1 [Chen, Songle; Sun, Zhengxing; Zhang, Yan; Li, Qian] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.
C3 Nanjing University
RP Sun, ZX (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.
EM chensongle@hotmail.com; szx@nju.edu.cn; zhangyannju@nju.edu.cn;
   public_liqian@163.com
RI Sun, Zhengxing/A-7411-2011
OI Sun, Zhengxing/0000-0001-7137-6169; Qian, Li/0000-0002-9530-4925
FU National Natural Science Foundation of China [61272219, 61100110,
   61321491]; Program for New Century Excellent Talents of Ministry of
   Education of China [NCET-04-0460]; Science and Technology Plan of
   Jiangsu Province [BE2010072, BE2011058, BY2012190, BY2013072-04];
   Innovation Foundation of State Key Lab for Novel Software Technology of
   China [ZZKT2013A12]
FX We would like to thank the anonymous reviewers for their valuable
   comments. This work is supported by National Natural Science Foundation
   of China (61272219, 61100110 and 61321491), Program for New Century
   Excellent Talents of Ministry of Education of China (NCET-04-0460),
   Science and Technology Plan of Jiangsu Province (BE2010072, BE2011058,
   BY2012190 and BY2013072-04), Innovation Foundation of State Key Lab for
   Novel Software Technology of China (ZZKT2013A12).
CR [Anonymous], 2003, Journal of machine learning research
   [Anonymous], 2009, Proceedings of the 2009 Symposium on Interactive 3D Graphics and Games, I3D'09, DOI DOI 10.1145/1507149.1507181
   [Anonymous], 2005, P ACM SIGGRAPH EUR S, DOI [10.1145/1073368.1073377, DOI 10.1145/1073368.1073377]
   [Anonymous], MOT CAPT DAT
   [Anonymous], 2013, Proceedings of the ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games, I3D'13
   Bahlmann C, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P49, DOI 10.1109/IWFHR.2002.1030883
   Barbic J, 2004, PROC GRAPH INTERF, P185
   Chao MW, 2012, IEEE T VIS COMPUT GR, V18, P729, DOI 10.1109/TVCG.2011.53
   Crucianu M., 2004, STATE ART AUDIOVISUA
   Cuturi M, 2007, INT CONF ACOUST SPEE, P413
   Demuth B, 2006, LECT NOTES COMPUT SC, V3936, P373
   Dongyu Zhang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P29, DOI 10.1109/ICPR.2010.16
   Ferreira CD, 2011, PATTERN RECOGN LETT, V32, P27, DOI 10.1016/j.patrec.2010.05.015
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Gudmundsson S, 2008, IEEE IJCNN, P2772, DOI 10.1109/IJCNN.2008.4634188
   Guyon I., 2003, Journal of Machine Learning Research, V3, P1157, DOI 10.1162/153244303322753616
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Huang SH, 2006, MULTIMEDIA SYST, V12, P14, DOI 10.1007/s00530-006-0028-y
   Huang TS, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P2, DOI 10.1109/ICIP.2001.958036
   Huang W, 2010, J SIGNAL PROCESS SYS, V59, P143, DOI 10.1007/s11265-008-0294-3
   Jiang W, 2006, IEEE T IMAGE PROCESS, V15, P702, DOI 10.1109/TIP.2005.863105
   Kim TH, 2003, ACM T GRAPHIC, V22, P392, DOI 10.1145/882262.882283
   Kohavi R., 1995, KDD-95 Proceedings. First International Conference on Knowledge Discovery and Data Mining, P192
   Kovar L, 2004, ACM T GRAPHIC, V23, P559, DOI 10.1145/1015706.1015760
   Lei HS, 2008, SITIS 2007: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGIES & INTERNET BASED SYSTEMS, P839, DOI 10.1109/SITIS.2007.112
   Li CJ, 2006, KNOWL INF SYST, V10, P163, DOI 10.1007/s10115-005-0223-8
   Liu F, 2003, COMPUT VIS IMAGE UND, V92, P265, DOI 10.1016/j.cviu.2003.06.001
   Müller M, 2005, ACM T GRAPHIC, V24, P677, DOI 10.1145/1073204.1073247
   Pradhan GN, 2009, IEEE T INF TECHNOL B, V13, P802, DOI 10.1109/TITB.2009.2021262
   Reyes M., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1182, DOI 10.1109/ICCVW.2011.6130384
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   Shen L, 2006, P 3 INT S 3D DAT PRO, P294, DOI DOI 10.1109/3DPVT.2006.86
   Shimodaira H, 2002, ADV NEUR IN, V14, P921
   Songle Chen, 2012, 2012 4th International Conference on Digital Home (ICDH 2012), P298, DOI 10.1109/ICDH.2012.91
   Stejic Z, 2003, INFORM PROCESS MANAG, V39, P1, DOI 10.1016/S0306-4573(02)00024-9
   Tang JKT, 2012, PATTERN RECOGN LETT, V33, P420, DOI 10.1016/j.patrec.2011.06.005
   Tie-Yan Liu, 2009, Foundations and Trends in Information Retrieval, V3, P225, DOI 10.1561/1500000016
   Wu K, 2006, IEEE COMPUT INTELL M, V1, P10
   Wu SY, 2009, VISUAL COMPUT, V25, P499, DOI 10.1007/s00371-009-0345-1
   Xia L., 2012, CVPR 2012 HAU3D Workshop, P20
   Xing Z., 2010, ACM SIGKDD EXPLOR NE, V12, P40, DOI [DOI 10.1145/1882471.1882478, 10.1145/1882471.1882478]
   Yang XD, 2014, J VIS COMMUN IMAGE R, V25, P2, DOI 10.1016/j.jvcir.2013.03.001
   Yoon H, 2005, IEEE T KNOWL DATA EN, V17, P1186, DOI 10.1109/TKDE.2005.144
   Zhou XS, 2005, IEE P-VIS IMAGE SIGN, V152, P927, DOI 10.1049/ip-vis:20045190
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
NR 45
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 2
BP 787
EP 817
DI 10.1007/s11042-014-2325-3
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB7YX
UT WOS:000368734700005
DA 2024-07-18
ER

PT J
AU Dinh, DL
   Lee, S
   Kim, TS
AF Dinh, Dong-Luong
   Lee, Sungyoung
   Kim, Tae-Seong
TI Hand number gesture recognition using recognized hand parts in depth
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand parts recognition; Hand number gesture recognition; Hand depth
   silhouette; Random forests
ID SYSTEM
AB In this paper, we present a novel approach of recognizing hand number gestures using the recognized hand parts in a depth image. Our proposed approach is divided into two stages: (i) hand parts recognition by random forests (RFs) and (ii) rule-based hand number gestures recognition. In the first stage, we create a database (DB) of synthetic hand depth silhouettes and their corresponding hand parts-labeled maps and then train RFs with the DB. Via the trained RFs, we recognize or label the hand parts in a depth silhouette. In the second stage, based on the information of the recognized or labeled hand parts, hand number gestures are recognized according to our derived rules. In our experiments, we quantitatively and qualitatively evaluated our hand parts recognition system with synthetic and real data. Then, we tested our hand number gesture recognition system with real data. Our results show the average recognition rate of 97.80 % over the ten hand number gestures from five different subjects.
C1 [Dinh, Dong-Luong; Lee, Sungyoung] Kyung Hee Univ, Dept Comp Engn, 1 Seocheon Dong, Yongin, Gyeonggi Do, South Korea.
   [Kim, Tae-Seong] Kyung Hee Univ, Dept Biomed Engn, 1 Seocheon Dong, Yongin, Gyeonggi Do, South Korea.
C3 Kyung Hee University; Kyung Hee University
RP Lee, S (corresponding author), Kyung Hee Univ, Dept Comp Engn, 1 Seocheon Dong, Yongin, Gyeonggi Do, South Korea.; Kim, TS (corresponding author), Kyung Hee Univ, Dept Biomed Engn, 1 Seocheon Dong, Yongin, Gyeonggi Do, South Korea.
EM luongdd@oslab.khu.ac.kr; sylee@oslab.khu.ac.kr; tskim@khu.ac.kr
RI Lee, Sungyoung/AAK-7257-2020
FU MSIP (Ministry of Science, ICT & Future Planning), Korea under ITRC
   (Information Technology Research Center) [NIPA-2013-(H0301-13-2001];
   Industrial Strategic Technology Development Program - Ministry of
   Knowledge Economy(MKE, Korea) [10035348]; Industrial Core Technology
   Development Program - Ministry of Trade, Industry and Energy (MOTIE,
   Korea) [10049079]
FX This research was supported by the MSIP (Ministry of Science, ICT &
   Future Planning), Korea, under the ITRC (Information Technology Research
   Center) support program supervised by the NIPA (National IT Industry
   Promotion Agency (NIPA-2013-(H0301-13-2001)). This work was also
   supported by the Industrial Strategic Technology Development Program
   (10035348, Development of a Cognitive Planning and Learning Model for
   Mobile Platforms) funded by the Ministry of Knowledge Economy(MKE,
   Korea) and the Industrial Core Technology Development Program (10049079,
   Development of Mining core technology exploiting personal big data)
   funded by the Ministry of Trade, Industry and Energy (MOTIE, Korea)"
CR [Anonymous], 2012, INT C DIS VIRT REAL
   [Anonymous], 2012, 2012 International Conference on Image Processing, Computer Vision, and Pattern Recognition
   [Anonymous], AUTODESK 3DS MAX
   Barkoky Alaa, 2011, 2011 International Conference on Multimedia Technology, P6548
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Bui TD, 2007, IEEE SENS J, V7, P707, DOI 10.1109/JSEN.2007.894132
   Cabrera ME, 2012, ADAPTIVE MOBILE ROBOTICS, P747
   Dipietro L, 2008, IEEE T SYST MAN CY C, V38, P461, DOI 10.1109/TSMCC.2008.923862
   Dominio Fabio., 2013, Proceedings of the 4th ACM/IEEE international workshop on Analysis and retrieval of tracked events and motion in imagery stream, P9
   Elmezain Mahmoud, 2009, 2009 Proceedings of 6th International Symposium on Image and Signal Processing and Analysis, P254
   Hasan H, 2014, NEURAL COMPUT APPL, V25, P251, DOI 10.1007/s00521-013-1481-0
   Lamberti L, 2012, EXPERT SYST APPL, V39, P10489, DOI 10.1016/j.eswa.2012.02.081
   Lepetit V, 2005, PROC CVPR IEEE, P775
   Liu X, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P529
   Murthy G.R.S., 2009, International Journal of Information Technology and Knowledge Management, V2, P405
   Oh J. K., 2004, Proceedings. Ninth International Workshop on Frontiers in Handwriting Recognition, P112
   Priyal S.P., 2010, P INT C SIGN PROC CO, P1
   Priyal SP, 2013, PATTERN RECOGN, V46, P2202, DOI 10.1016/j.patcog.2013.01.033
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   Shimada A, 2013, KOR-JPN JT WORKS FR, P121, DOI 10.1109/FCV.2013.6485473
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Suarez J., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P411, DOI 10.1109/ROMAN.2012.6343787
   Swapna B, 2011, COMM COM INF SC, V250, P782
   Trevor H., 2009, The Elements of Statistical Learning: Data Mining, Inference, and Prediction
   Vieriu RL, 2011, 2011 10TH INTERNATIONAL SYMPOSIUM ON SIGNALS, CIRCUITS AND SYSTEMS (ISSCS)
   Wu CH, 2013, I SYMP CONSUM ELECTR, P279
NR 26
TC 16
Z9 17
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 2
BP 1333
EP 1348
DI 10.1007/s11042-014-2370-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB7YX
UT WOS:000368734700029
DA 2024-07-18
ER

PT J
AU Wang, GY
   Liu, F
   Yan, WQ
AF Wang, Guangyu
   Liu, Feng
   Yan, Wei Qi
TI 2D Barcodes for visual cryptography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 2D barcode; Visual cryptography; Authentication
ID CHEATING PREVENTION; AUTHENTICATION; SCHEME
AB The basic idea of Visual Cryptography (VC) is to divide a secret image into several partitions which are called VC shares. With various categories of VC schemes having been developed to enhance the maturity of VC since its emergence, one of obsessions in current investigations of VC is that each VC share lacks authentication. In this paper, we analyze VC authentication methods using 2D barcodes and embed binary codes into VC shares for authentication purpose. The objective of this paper is to present a method of improving the authentication of traditional VC scheme. Our contribution of this paper is to propose a scheme of embedding 2D barcodes into given VC shares to prevent cheating, we search the best region of a given share where the 2D barcode could be embedded into so as to keep the visual quality of the revealed secret.
C1 [Wang, Guangyu; Yan, Wei Qi] Auckland Univ Technol, Sch Comp & Math Sci, CBD, 2-14 Wakefield St, Auckland 1010, New Zealand.
   [Liu, Feng; Yan, Wei Qi] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Room 3217,B2 Res Bldg,89A Minzhuang Rd, Beijing 100093, Peoples R China.
C3 Auckland University of Technology; Chinese Academy of Sciences;
   Institute of Information Engineering, CAS
RP Yan, WQ (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Room 3217,B2 Res Bldg,89A Minzhuang Rd, Beijing 100093, Peoples R China.
EM qrf3710@aut.ac.nz; liufeng@iie.ac.cn; wyan@aut.ac.nz
RI liu, feng/B-3050-2019
CR [Anonymous], 2011, DENSO ADC QR CODE ES
   Ateniese G, 2001, THEOR COMPUT SCI, V250, P143, DOI 10.1016/S0304-3975(99)00127-9
   CAMPBELL A, 2000, DESIGNERS LEXICON
   Chen S., 2010, 2010 IEEE Congress on Evolutionary Computation, DOI 10.1109/CEC.2010.5586423
   Chen YC, 2012, J VIS COMMUN IMAGE R, V23, P1225, DOI 10.1016/j.jvcir.2012.08.006
   Chen YC, 2012, IEEE T IMAGE PROCESS, V21, P3319, DOI 10.1109/TIP.2012.2190082
   Chen YF, 2007, INFORM SCIENCES, V177, P4696, DOI 10.1016/j.ins.2007.05.011
   Dobbertin H, 1998, J CRYPTOL, V11, P253, DOI 10.1007/s001459900047
   Gao M., 2012, FDN INTELLIGENT SYST, P457
   Guo T, 2013, J SYST SOFTWARE, V86, P2094, DOI 10.1016/j.jss.2013.03.062
   Hahn HI, 2006, INFORMATICS IN CONTROL, AUTOMATION AND ROBOTICS I, P233, DOI 10.1007/1-4020-4543-3_28
   Hegde C, 2008, ADCOM: 2008 16TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING AND COMMUNICATIONS, P65, DOI 10.1109/ADCOM.2008.4760429
   Horng G, 2006, DESIGN CODE CRYPTOGR, V38, P219, DOI 10.1007/s10623-005-6342-0
   Hou YC, 2003, PATTERN RECOGN, V36, P1619, DOI 10.1016/S0031-3203(02)00258-3
   Hu CM, 2007, IEEE T IMAGE PROCESS, V16, P36, DOI 10.1109/TIP.2006.884916
   International Organization for Standardization ISO, 2004, 160222000 ISOIEC, V1, P67
   Jiang F, 2012, ADV MECH ENG, DOI 10.1155/2012/518468
   Kuo D, 2010, LECT NOTES COMPUT SC, V6104, P150, DOI 10.1007/978-3-642-13067-0_19
   Lau D. L., 2011, MODERN DIGITAL HALFT
   Lee YS, 2012, SIGNAL PROCESS, V92, P727, DOI 10.1016/j.sigpro.2011.09.015
   Liu F, 2011, IET INFORM SECUR, V5, P51, DOI 10.1049/iet-ifs.2008.0064
   Liu F, 2008, IET INFORM SECUR, V2, P151, DOI 10.1049/iet-ifs:20080066
   Liu F, 2010, COMPUT J, V53, P107, DOI 10.1093/comjnl/bxn072
   Memon N., 1998, Communications of the ACM, V41, P34, DOI 10.1145/278476.278485
   Metz C, 1999, IEEE INTERNET COMPUT, V3, P75, DOI 10.1109/4236.807015
   Myodo E, 2006, IEEE IMAGE PROC, P97, DOI 10.1109/ICIP.2006.312371
   Myodo E, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P2114
   Nakajima M, 2002, WSCG'2002, VOLS I AND II, CONFERENCE PROCEEDINGS, P303
   Naor M, 1997, LECT NOTES COMPUT SC, V1294, P322
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Revenkar PS, 2010, INT J SECUR APPL, V4, P49
   ROMPAY BV, 2004, THESIS KATHOLIEKE U
   Rouillard Jose, 2008, 2008 3rd International Multi-Conference on Computing in the Global Information Thechnology (ICCGI 2008), P50, DOI 10.1109/ICCGI.2008.25
   Shyu SJ, 2007, PATTERN RECOGN, V40, P3633, DOI 10.1016/j.patcog.2007.03.012
   Sobti R., 2012, INT J COMPUTER SCI I, V9, P461
   Solms S.H., 2009, INFORM TECHNOLOGY GO, P1
   Stoleru D, 2005, DR DOBBS J, V30, P36
   Touch Joseph D., 1995, Proceedings of the conference on Applications, technologies, architectures, and protocols for computer communication (SIGCOMM'95), P77, DOI DOI 10.1145/217382.217414
   Tuyls P, 2005, DESIGN CODE CRYPTOGR, V37, P169, DOI 10.1007/s10623-004-3816-4
   Vincent E, 2005, J VIS COMMUN IMAGE R, V16, P38, DOI 10.1016/j.jvcir.2004.05.001
   Wang G, 2014, THESIS AUCKLAND U TE
   Wang ZM, 2006, IEEE IMAGE PROC, P109, DOI 10.1109/ICIP.2006.312384
   Weir J, 2012, DIGITAL FORENSICS WA, V7128, P196, DOI DOI 10.1007/978-3-642-32205-1_17
   Weir J, 2010, LECT NOTES COMPUT SC, V6010, P70, DOI 10.1007/978-3-642-14298-7_5
   Weir J, 2009, IEEE INT SYMP CIRC S, P509, DOI 10.1109/ISCAS.2009.5117797
   Weir J, 2009, LECT NOTES COMPUT SC, V5703, P136, DOI 10.1007/978-3-642-03688-0_14
   Yan WQ, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 5, PROCEEDINGS, P572
   Yan Y., 2013, P 2012 INT C INFORM, P71
   Yang C.-N., 1999, NATL COMPUTER S, V3, P260
   Yang CN, 2006, INTEGR COMPUT-AID E, V13, P189
   Zhang C., 2011, ELECT ENG CONTROL, V1, P683
   Zhou Z, 2003, IEEE IMAGE PROC, P521
NR 52
TC 15
Z9 15
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 2
BP 1223
EP 1241
DI 10.1007/s11042-014-2365-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB7YX
UT WOS:000368734700024
DA 2024-07-18
ER

PT J
AU Yen, SH
   Wang, CH
   Chien, JC
AF Yen, Shwu-Huey
   Wang, Chun-Hui
   Chien, Jui-Chen
TI Accurate and robust ROI localization in a camshift tracking application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Camshift; Mean shift; Tracking; Surveillance; Flood-fill
ID MEAN-SHIFT; OBJECT TRACKING
AB Camshift has been well accepted as one of the most popular methods for object tracking. However, it fails to address complex situations, such as similar color interference, object occlusion, and illumination changes. In this paper, we enhance Camshift to enable it to handle the above-mentioned problems. A two-dimensional (2D) histogram of the hue and luminance is used for the color features of the target. To reduce the influence from irrelevant background pixels, a Flood-fill operation is implemented. The obtained 2D target model can precisely describe the target as well as achromatic points. A similarity score is evaluated to prevent similar color interference. When a target's colors are not distinguishable from the background colors, motion information will contribute to the tracking task. Finally, an average rate change is adopted to maintain progressive but not abrupt changes in the window size. The proposed algorithm has been extensively tested. The results are satisfactory while maintaining the processing in real time.
C1 [Yen, Shwu-Huey; Wang, Chun-Hui; Chien, Jui-Chen] Tamkang Univ, Dept Comp Sci & Informat Engn, PRIA Lab, New Taipei 25137, Taiwan.
C3 Tamkang University
RP Yen, SH (corresponding author), Tamkang Univ, Dept Comp Sci & Informat Engn, PRIA Lab, 151 Yingzhuan Rd, New Taipei 25137, Taiwan.
EM 105390@mail.tku.edu.tw
RI Wang, Chunhui/GQR-1652-2022
OI Wang, Chunhui/0000-0002-3551-4226
FU National Science Council of Taiwan, R.O.C. [NSC 101-2221-E-032-054]
FX The authors would like to express their gratitude for the anonymous
   reviewers for the careful reading of the original manuscript. Their
   comments and suggestions have led to a much better presentation of the
   paper. This research is supported in part by the National Science
   Council (NSC 101-2221-E-032-054) of Taiwan, R.O.C.
CR [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   [Anonymous], 2004, Proceedings of the Pan-Sydney area workshop on Visual information processing
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bhattacharyya Anil, 1943, B CALCUTTA MATH SOC, V35, P99
   Birchfield ST, 2005, PROC CVPR IEEE, P1158
   Bradski G R, 1998, INTEL TECHNOLOGY J, P13
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Collins RT, 2003, PROC CVPR IEEE, P234
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Leichter I, 2012, IEEE T PATTERN ANAL, V34, P695, DOI 10.1109/TPAMI.2011.167
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Ning JF, 2009, INT J PATTERN RECOGN, V23, P1245, DOI 10.1142/S0218001409007624
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Salti S, 2012, IEEE T IMAGE PROCESS, V21, P4334, DOI 10.1109/TIP.2012.2206035
   Stalder S, 2010, LECT NOTES COMPUT SC, V6311, P369, DOI 10.1007/978-3-642-15549-9_27
   Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yang HX, 2011, NEUROCOMPUTING, V74, P3823, DOI 10.1016/j.neucom.2011.07.024
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
NR 28
TC 7
Z9 7
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10291
EP 10312
DI 10.1007/s11042-014-2167-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700007
DA 2024-07-18
ER

PT J
AU Zhou, ZG
   Tao, YB
   Lin, H
   Dong, F
   Clapworthy, G
AF Zhou, Zhiguang
   Tao, Yubo
   Lin, Hai
   Dong, Feng
   Clapworthy, Gordon
TI Occlusion-free feature exploration for volume visualization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Volume visualization; Direct volume rendering; Occlusion; Transfer
   function
AB Direct volume rendering is one of the most effective ways to visualize volume data sets, which employs intuitive 2D images to display internal structures in 3D space. However, opaque features always occlude other parts of the volume, and make some features of interest invisible in the final rendered images. Although a class of highly transparent transfer functions are capable of revealing all features at once, it is still laborious and time-consuming to specify appropriate transfer functions to reduce occlusions on less important structures and highlight features of interest, even for experts. Thus, the research on simpler volume visualization techniques which do not rely on complex transfer functions has been a hotspot in many practical applications. In this paper, an occlusion-free feature exploration approach that consists of modifying the traditional volume rendering integral is proposed, which can achieve better visibility of all internal features of interest with simple linear transfer functions. During the ray casting, a modulation parameter is derived to reduce the contributions of previous samples along the viewing ray, whenever the accumulated opacity value is close to overflow. In addition, several relevant functions are introduced to refine the modulation parameter and highlight the features of interest identified according to the attributes such as scalar, gradient module, occurrence and depth. Thereby, the proposed approach is capable of generating informative rendered images and enhancing the visual perception of features of interest without resorting to complex transfer functions.
C1 [Zhou, Zhiguang] Zhejiang Univ Finance & Econ, Sch Informat, Hangzhou, Zhejiang, Peoples R China.
   [Tao, Yubo; Lin, Hai] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310003, Zhejiang, Peoples R China.
   [Dong, Feng; Clapworthy, Gordon] Univ Bedfordshire, Luton, Beds, England.
C3 Zhejiang University of Finance & Economics; Zhejiang University;
   University of Bedfordshire
RP Zhou, ZG (corresponding author), Zhejiang Univ Finance & Econ, Sch Informat, Hangzhou, Zhejiang, Peoples R China.
EM zhgzhou1983@163.com; tao@cad.zju.edu.cn; lin@cad.zju.edu.cn
FU NFS of China Project [61303133, 61100084]; Zhejiang Science & Technology
   Plan of China [2014C31057]; 863 Program Project [2012AA12A404]; Open
   Project Program of State Key Lab of CAD&CG, Zhejiang University [A1417]
FX The authors would like to thank the anonymous reviewers for their
   valuable comments. This work was supported by NFS of China Project (No.
   61303133, 61100084), Zhejiang Science & Technology Plan of China (No.
   2014C31057), 863 Program Project (No. 2012AA12A404) and the Open Project
   Program of the State Key Lab of CAD&CG (Grant No. A1417), Zhejiang
   University. The data sets are courtesy of VoreenPub, The Visible Human
   Project, General Electric, and Philips Research.
CR Bruckner S, 2006, IEEE T VIS COMPUT GR, V12, P1559, DOI 10.1109/TVCG.2006.96
   Bruckner S, 2009, COMPUT GRAPH FORUM, V28, P775, DOI 10.1111/j.1467-8659.2009.01474.x
   Correa CD, 2008, IEEE T VIS COMPUT GR, V14, P1380, DOI 10.1109/TVCG.2008.162
   Correa CD, 2011, IEEE T VIS COMPUT GR, V17, P192, DOI 10.1109/TVCG.2010.35
   Diaz J, 2010, IEEE EG S VOL GRAPH, DOI [10.2312/VG/VG10/093-100, DOI 10.2312/VG/VG10/093-100]
   Guo HQ, 2011, IEEE T VIS COMPUT GR, V17, P2106, DOI 10.1109/TVCG.2011.261
   Haidacher M, 2011, IEEE T VIS COMPUT GR, V17, P1969, DOI 10.1109/TVCG.2011.258
   Haidacher M, 2010, IEEE PAC VIS SYMP, P17, DOI 10.1109/PACIFICVIS.2010.5429615
   Heidrich W, 1995, VISUALIZATION '95 - PROCEEDINGS, P11, DOI 10.1109/VISUAL.1995.480790
   Ip CY, 2012, IEEE T VIS COMPUT GR, V18, P2355, DOI 10.1109/TVCG.2012.231
   Kindlmann G, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P513, DOI 10.1109/VISUAL.2003.1250414
   Kniss J, 2002, IEEE T VIS COMPUT GR, V8, P270, DOI 10.1109/TVCG.2002.1021579
   LEVOY M, 1988, IEEE COMPUT GRAPH, V8, P29, DOI 10.1109/38.511
   Liang RH, 2012, VISUAL COMPUT, V28, P625, DOI 10.1007/s00371-012-0680-5
   Marchesin S, 2010, IEEE T VIS COMPUT GR, V16, P560, DOI 10.1109/TVCG.2010.30
   MAX N, 1995, IEEE T VIS COMPUT GR, V1, P99, DOI 10.1109/2945.468400
   Prassni JS, 2010, IEEE PAC VIS SYMP, P9, DOI 10.1109/PACIFICVIS.2010.5429624
   Roettger S., 2005, Eurographics IEEE VGTC Symposium on Visualization, P271, DOI DOI 10.2312/VISSYM/EUROVIS05/271-278
   Ropinski Timo., 2008, IEEEEG INT S VOLUME, P41
   Ruiz M, 2011, IEEE T VIS COMPUT GR, V17, P1932, DOI 10.1109/TVCG.2011.173
   SCHREINER S, 1993, IEEE T MED IMAGING, V12, P50, DOI 10.1109/42.222666
   Sereda P, 2006, IEEE T VIS COMPUT GR, V12, P208, DOI 10.1109/TVCG.2006.39
   Wang YH, 2011, IEEE T VIS COMPUT GR, V17, P1560, DOI 10.1109/TVCG.2011.97
   Wu YC, 2007, IEEE T VIS COMPUT GR, V13, P1027, DOI 10.1109/TVCG.2007.1051
   Zhou ZG, 2011, VISUAL COMPUT, V27, P677, DOI 10.1007/s00371-011-0570-2
NR 25
TC 2
Z9 2
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10243
EP 10258
DI 10.1007/s11042-014-2162-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700004
DA 2024-07-18
ER

PT J
AU Gao, P
   Peng, Q
   Xiang, W
AF Gao, Pan
   Peng, Qiang
   Xiang, Wei
TI Error-resilient multi-view video coding using Wyner-Ziv techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-view video coding; Wyner-Ziv coding; Error resilience;
   Transmission distortion estimation; Bit rate estimation
ID RATE-DISTORTION ANALYSIS; SCHEME; TRANSMISSION; INFORMATION
AB In this paper, a Wyner-Ziv (WZ) coding based error-resilient scheme is proposed for multi-view video transmission over error-prone channels. At the encoder, the key frames of the odd views are protected by WZ encoding to generate the auxiliary bit-stream alongside the multi-view video coded bit-stream. At the decoder, error-concealed multi-view decoded frames are used as the side information (SI) for WZ decoding. Based on the study on the characteristics of multi-view video coding (MVC) and the propagating behavior of channel errors, a recursive model to estimate the transmission distortion is developed in the transform domain, in which the channel-induced distortion takes into consideration both motion and disparity compensation. With the proposed model, we propose a rate control strategy for WZ encoding to infer the minimum bit rate so as to correct the SI errors. The WZ bit rate estimation method exploits the correlation between the original bit-planes and the SI bit-planes as well as the bit-plane interdependency. Extensive experimental results show that the proposed error-resilient scheme outperforms Reed Solomon based forward error correction method by about 1.1 dB and outperforms the adaptive intra refresh algorithm by approximately 1.6 dB at the packet loss rate 10 %.
C1 [Gao, Pan; Peng, Qiang] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Sichuan, Peoples R China.
   [Gao, Pan; Xiang, Wei] Univ So Queensland, Sch Mech & Elect Engn, Toowoomba, Qld 4350, Australia.
C3 Southwest Jiaotong University; University of Southern Queensland
RP Gao, P (corresponding author), Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Sichuan, Peoples R China.
EM gaopan.1005@gmail.com; qpeng@home.swjtu.edu.cn; xiangwei@usq.edu.au
RI Xiang, Wei/C-6765-2009; Xiang, Weidong/AAA-2883-2020
OI Xiang, Wei/0000-0002-0608-065X
FU Natural Science Foundation of China [61036008]; Queensland Government's
   Smart Futures Fellowship
FX This work was partially supported by the Natural Science Foundation of
   China (No. 61036008), and Queensland Government's Smart Futures
   Fellowship.
CR Aarion A, 2004, P VIS COMM IM PROC S
   [Anonymous], JTC1SC29WG11 ISOIEC
   [Anonymous], 2006, JTC1SC29WG11 ISOIEC
   [Anonymous], 2012, 1 ISOIEC JTC
   Brites C, 2008, IEEE T CIRC SYST VID, V18, P1177, DOI 10.1109/TCSVT.2008.924107
   Brites C, 2011, IEEE T CIRC SYST VID, V21, P1278, DOI 10.1109/TCSVT.2011.2147210
   Crave O, 2010, IEEE T CIRC SYST VID, V20, P769, DOI 10.1109/TCSVT.2010.2045805
   Dissanayake MB, 2010, IEEE INT CON MULTI, P1712, DOI 10.1109/ICME.2010.5583188
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   Guillemot C, 2007, IEEE SIGNAL PROC MAG, V24, P67, DOI 10.1109/MSP.2007.904808
   Guo X, 2008, IEEE T CIRC SYST VID, V18, P713, DOI 10.1109/TCSVT.2008.920970
   He ZH, 2002, IEEE T CIRC SYST VID, V12, P511, DOI 10.1109/TCSVT.2002.800313
   He ZH, 2005, IEEE T CIRC SYST VID, V15, P645, DOI 10.1109/TCSVT.2005.846433
   He ZH, 2006, IEEE T CIRC SYST VID, V16, P1051, DOI 10.1109/TCSVT.2006.881198
   Kubasov D, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P183, DOI 10.1109/MMSP.2007.4412848
   Kubota A, 2007, IEEE SIGNAL PROC MAG, V24, P10, DOI 10.1109/MSP.2007.905873
   Li YP, 2009, IEEE INT SYMP CIRC S, P2597, DOI 10.1109/ISCAS.2009.5118333
   Liu SJ, 2008, IEEE INT SYMP CIRC S, P3470, DOI 10.1109/ISCAS.2008.4542206
   Merkle P, 2007, IEEE T CIRC SYST VID, V17, P1461, DOI 10.1109/TCSVT.2007.903665
   Puri R, 2006, IEEE SIGNAL PROC MAG, V23, P94, DOI 10.1109/MSP.2006.1657820
   Qing LB, 2013, OPT ENG, V52, DOI 10.1117/1.OE.52.7.071506
   Rane S, 2008, IEEE T CIRC SYST VID, V18, P1347, DOI 10.1109/TCSVT.2008.929135
   Schier M, 2012, IEEE T MULTIMEDIA, V14, P415, DOI 10.1109/TMM.2011.2178235
   Sehgal A, 2004, IEEE T MULTIMEDIA, V6, P249, DOI 10.1109/TMM.2003.822995
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Song K, 2009, J VIS COMMUN IMAGE R, V20, P281, DOI 10.1016/j.jvcir.2009.02.002
   Tan AS, 2009, EURASIP J ADV SIG PR, P14
   Varodayan D, 2006, SIGNAL PROCESS, V86, P3123, DOI 10.1016/j.sigpro.2006.03.012
   Vetro A, 2011, P IEEE, V99, P626, DOI 10.1109/JPROC.2010.2098830
   Wang JJ, 2009, IEEE T IMAGE PROCESS, V18, P2695, DOI 10.1109/TIP.2009.2029990
   Wenger S., 2001, VCEGN79R1 ITUT
   Wenger S, 1999, Q15116R1 ITUT VCEG
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   Xiang W, 2009, IEEE T CIRC SYST VID, V19, P1730, DOI 10.1109/TCSVT.2009.2022787
   Xiang X, 2009, P SPIE VIS COMM IM P
   Xue Z, 2010, IEEE T BROADCAST, V56, P481, DOI 10.1109/TBC.2010.2058371
   Yajnik M, 1999, IEEE INFOCOM SER, P345, DOI 10.1109/INFCOM.1999.749301
   Yang H, 2010, IEEE T IMAGE PROCESS, V19, P108, DOI 10.1109/TIP.2009.2032895
   Yeo C, 2010, IEEE T IMAGE PROCESS, V19, P995, DOI 10.1109/TIP.2009.2036715
   Zhang R, 2000, IEEE J SEL AREA COMM, V18, P966, DOI 10.1109/49.848250
   Zhang YX, 2008, IEEE T MULTIMEDIA, V10, P1648, DOI 10.1109/TMM.2008.2007324
   Zhang YS, 2011, IEEE T CIRC SYST VID, V21, P498, DOI 10.1109/TCSVT.2011.2129050
   Zhang Y, 2007, IEEE T MULTIMEDIA, V9, P445, DOI 10.1109/TMM.2006.887989
   Zhou Y, 2011, IEEE T CIRC SYST VID, V21, P1679, DOI 10.1109/TCSVT.2011.2133390
   Zhu CB, 2009, IEEE T CIRC SYST VID, V19, P3, DOI 10.1109/TCSVT.2008.2005802
NR 45
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 7957
EP 7982
DI 10.1007/s11042-014-2033-z
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200025
DA 2024-07-18
ER

PT J
AU Leng, QM
   Hu, RM
   Liang, C
   Wang, YM
   Chen, J
AF Leng, Qingming
   Hu, Ruimin
   Liang, Chao
   Wang, Yimin
   Chen, Jun
TI Person re-identification with content and context re-ranking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Content and context similarities;
   Bidirectional ranking; Re-ranking
AB This paper proposes a novel and efficient re-ranking technque to solve the person re-identification problem in the surveillance application. Previous methods treat person re-identification as a special object retrieval problem, and compute the retrieval result purely based on a unidirectional matching between the probe and all gallery images. However, the correct matching may be not included in the top-k ranking result due to appearance changes caused by variations in illumination, pose, viewpoint and occlusion. To obtain more accurate re-identification results, we propose to reversely query every gallery person image in a new gallery composed of the original probe person image and other gallery person images, and revise the initial query result according to bidirectional ranking lists. The behind philosophy of our method is that images of the same person should not only have similar visual content, refer to content similarity, but also possess similar k-nearest neighbors, refer to context similarity. Furthermore, the proposed bidirectional re-ranking method can be divided into offline and online parts, where the majority of computation load is accomplished by the offline part and the online computation complexity is only proportional to the size of the gallery data set, which is especially suited to the real-time required video investigation task. Extensive experiments conducted on a series of standard data sets have validated the effectiveness and efficiency of our proposed method.
C1 [Leng, Qingming; Hu, Ruimin; Liang, Chao; Wang, Yimin; Chen, Jun] Wuhan Univ, Sch Comp, Natl Engn Res Ctr Multimedia Software, Wuhan 430072, Peoples R China.
C3 Wuhan University
RP Hu, RM (corresponding author), Wuhan Univ, Sch Comp, Natl Engn Res Ctr Multimedia Software, Wuhan 430072, Peoples R China.
EM lengqm@whu.edu.cn; hurm1964@gmail.com
RI Chen, Jun/AAD-8167-2022
FU National Nature Science Foundation of China [61231015, 61172173,
   61303114]; Major Science and Technology Innovation Plan of Hubei
   Province [2013AAA020]; Guangdong-Hongkong Key Domain Breakthrough
   Project of China [2012A090200007]; China Postdoctoral Science Foundation
   [2013M530350]; Specialized Research Fund for the Doctoral Program of
   Higher Education [20130141120024]; Key Technology R&D Program of Wuhan
   [2013030409020109]; UCAS; National Laboratory of Pattern Recognition
   (NLPR)
FX This work was supported by the National Nature Science Foundation of
   China (61231015, 61172173, 61303114), the Major Science and Technology
   Innovation Plan of Hubei Province (2013AAA020), the Guangdong-Hongkong
   Key Domain Breakthrough Project of China (2012A090200007), the China
   Postdoctoral Science Foundation funded project (2013M530350), the
   Specialized Research Fund for the Doctoral Program of Higher Education
   (20130141120024), the Key Technology R&D Program of Wuhan
   (2013030409020109) and the President Fund of UCAS, and the Open Project
   Program of the National Laboratory of Pattern Recognition (NLPR).
CR Ali S., 2010, ACM Multimedia Conference (ACM MM), P895
   [Anonymous], 2007, IEEE INT WORKSH PERF
   Baltieri D, 2011, MM 11 P 2011 ACM MUL
   Dikmen M., 2010, ACCV
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Friedkin NoahE., 1998, A Structural Theory of Social Influence
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Gong S., 2011, Visual Analysis of Humans: Looking at People, P455, DOI [10.1007/978-0-85729-997-0_23, DOI 10.1007/978-0-85729-997-0_23]
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Huang J, 2011, IEEE T MULTIMEDIA, V13, P653, DOI 10.1109/TMM.2011.2127463
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Leng Q, 2013, P IEEE COMP SOC C MU
   Li W, 2012, IEEE IMAGE PROC, P1621, DOI 10.1109/ICIP.2012.6467186
   Pedronette DCG, 2011, P 1 ACM INT C MULT R, P41
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Shen XH, 2012, PROC CVPR IEEE, P3013, DOI 10.1109/CVPR.2012.6248031
   Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010
   Weinberger K.Q., 2008, ICML
   Wu Z, 2011, IEEE T PATTERN ANAL, V33, P1991, DOI 10.1109/TPAMI.2011.111
   Xiang ZJ, 2014, MULTIMED TOOLS APPL, V73, P91, DOI 10.1007/s11042-012-1286-7
   You H., 2001, PROC IEEE INT C MULT, P245
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
   Zhi CH, 2011, PROC CVPR IEEE, P481, DOI 10.1109/CVPR.2011.5995680
NR 25
TC 57
Z9 65
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 6989
EP 7014
DI 10.1007/s11042-014-1949-7
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800019
DA 2024-07-18
ER

PT J
AU Mostafa, AM
   Youssef, AE
AF Mostafa, Almetwally M.
   Youssef, Ahmed E.
TI PRP: A primary replacement protocol based on early discovery of battery
   power failure in MANETs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Primary backup approach; Replication; MANETs; Power failure awarness;
   Primary election
ID LEADER ELECTION; ALGORITHM
AB In cooperative Mobile Ad-hoc Networks (MANETs), copies of data are replicated on different mobile devices to improve system's availability. A primary or authoritative control node is assigned to act as a coordinator for the shared data copies, when this primary fails, another node has to be elected to replace the failed one. Since mobile devices have a limited battery power, the primary may fail at any time. Moreover, current primary election protocols in MANETs employ a notable wireless communication overhead which consumes a considerable amount of battery power. In this paper, we propose a novel protocol, called Primary Replacement Protocol (PRP), to replace an exhausted primary in MANETs based on the measurement of its remaining battery power early before it dies. More specifically, PRP replaces the exhausted primary with a healthy node when its remaining battery power reaches a predefined threshold. This replacement can be accomplished with much less communication overhead. Hence, our approach has two contributions: 1) reducing the chance of primary outage by early detection of potential power failure, 2) saving the power that is consumed in traditional primary election approaches due to communication overhead.
C1 [Mostafa, Almetwally M.; Youssef, Ahmed E.] King Saud Univ, CCIS, Riyadh, Ksa, Saudi Arabia.
   [Mostafa, Almetwally M.] Al Azhar Univ, Fac Engn, Syst & Comp Dept, Cairo, Egypt.
   [Youssef, Ahmed E.] Helwan Univ, Dept Elect Commun & Comp Engn, Fac Engn, Cairo, Egypt.
C3 King Saud University; Egyptian Knowledge Bank (EKB); Al Azhar
   University; Egyptian Knowledge Bank (EKB); Helwan University
RP Mostafa, AM (corresponding author), King Saud Univ, CCIS, Riyadh, Ksa, Saudi Arabia.
EM almetwaly@ksu.edu.sa; ahyoussef@ksu.edu.sa
RI Mostafa, Almetwally Mohamad/GYJ-3055-2022; Youssef, Ahmed
   E./AAC-7449-2019
OI Mostafa, Almetwally Mohamad/0000-0002-0976-239X; Youssef, Ahmed
   E./0000-0003-3102-0891
FU Research Center of College of Computer and Information Sciences (CRC) at
   King Saud University [RC130393]
FX This work is supported by the Research Center of College of Computer and
   Information Sciences (CRC) at King Saud University, Grant Number
   RC130393. The authors are grateful for this support.
CR Derhab A, 2008, IEEE T PARALL DISTR, V19, P926, DOI 10.1109/TPDS.2007.70792
   DIJKSTRA EW, 1980, INFORM PROCESS LETT, V11, P1, DOI 10.1016/0020-0190(80)90021-6
   EffatParvar M, 2010, COMP ENG TECHN ICCET, V2, pV2
   Fernando N, 2013, FUTURE GENER COMP SY, V29, P84, DOI 10.1016/j.future.2012.05.023
   FREDERICKSON GN, 1987, J ACM, V34, P98, DOI 10.1145/7531.7919
   GARCIAMOLINA H, 1982, IEEE T COMPUT, V31, P48, DOI 10.1109/TC.1982.1675885
   Guerraoui R, 2006, RELIABLE DISTRIBUTED, V138
   Hatzis K. P., 1999, SPAA'99. Eleventh Annual ACM Sympsoium on Parallel Algorithms and Architectures, P251, DOI 10.1145/305619.305649
   Hirsch D, 2011, COLLABORATECOM, P115, DOI 10.4108/icst.collaboratecom.2011.247120
   Malpani N., 2000, DIALM 00 P 4 INT WOR, P96, DOI DOI 10.1145/345848.345871
   Masum SM, 2006, ADV INF NETW APPL 20, V2, p[5, 18]
   Melit L., 2011, 2011 10th International Symposium on Programming and Systems, P54, DOI 10.1109/ISPS.2011.5898893
   Mostafa A. M., 2013, INT J COMPUT APPL, V72, P37
   Mostafa Almetwally, 2013, IT CONV SEC ICITCS 2, P1
   Park VD, 1997, IEEE INFOCOM SER, P1405, DOI 10.1109/INFCOM.1997.631180
   Pering Trevor., 2006, P 4 INT C MOBILE SYS, P220, DOI DOI 10.1145/1134680.1134704
   Shinohara M., 2007, Mobile Data Management, 2007 International Conference on, P118
   Shirali M, 2008, THIRD 2008 INTERNATIONAL CONFERENCE ON CONVERGENCE AND HYBRID INFORMATION TECHNOLOGY, VOL 1, PROCEEDINGS, P1001, DOI 10.1109/ICCIT.2008.57
   SINGH S, 1994, J PARALLEL DISTR COM, V21, P184, DOI 10.1006/jpdc.1994.1051
   Stoller SD, 2000, IEEE T COMPUT, V49, P283, DOI 10.1109/12.841132
   Vasudevan S, 2004, 12TH IEEE INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS - PROCEEDINGS, P350, DOI 10.1109/ICNP.2004.1348124
   Vasudevan S, 2003, DARPA INFORMATION SURVIVABILITY CONFERENCE AND EXPOSITION, VOL I, PROCEEDINGS, P261, DOI 10.1109/DISCEX.2003.1194890
NR 22
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2015
VL 74
IS 16
BP 6243
EP 6254
DI 10.1007/s11042-014-2091-2
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP4PN
UT WOS:000359864700008
DA 2024-07-18
ER

PT J
AU Yang, HB
   Hou, X
AF Yang, Hongbo
   Hou, Xia
TI Texture segmentation using image decomposition and local self-similarity
   of different features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texture segmentation; Local self-similarity; Image decomposition
ID TOTAL VARIATION MINIMIZATION; MATRIX ANALYSIS; NUCLEIC-ACID
AB In this paper, we propose a new two channels feature space active contours model for texture segmentation by using image decomposition and local self-similarity descriptor of textures. The piece-wise smooth component of image decomposition is regarded as one channel of feature space for segmentation. Defined as a symmetry matrix and a kind of features fusion tool, the local self-similarity descriptor SSM captures the internal geometric layout of local repetitive pattern regions and is computed on different features of textures including oscillatory component of image decomposition, phase congruency and log-Gabor filters responses. A distance map dSSM can measure the similarities between the descriptor of template and the local windows surrounding every pixel on the texture image. And then dSSM is set as another channel of feature space for segmentation. Based on the space, texture segmentation is performed by using active contours and level set technology. In addition, the accuracy of texture boundary localization and the template searching inside initial contour are also concerned in this paper. Compared with some recent approaches, our method is more convincing and works well for synthetic textured images and ones in the real world.
C1 [Yang, Hongbo] Beijing Informat Sci & Technol Univ, Sch Automat, Expt Teaching Ctr Elect Informat & Control, Beijing 100192, Peoples R China.
   [Hou, Xia] Beijing Informat Sci & Technol Univ, Sch Comp, Beijing 100192, Peoples R China.
C3 Beijing Information Science & Technology University; Beijing Information
   Science & Technology University
RP Yang, HB (corresponding author), Beijing Informat Sci & Technol Univ, Sch Automat, Expt Teaching Ctr Elect Informat & Control, 12 Qing He Xiao Ying Dong Lu, Beijing 100192, Peoples R China.
EM anonbo@bistu.edu.cn; houxia@bistu.edu.cn
FU Importation and Development of High-Caliber Talents Project of Beijing
   Municipal Institutions [CITTCD201304115]
FX This work was financially supported by The Importation and Development
   of High-Caliber Talents Project of Beijing Municipal Institutions
   (CIT&TCD201304115).
CR [Anonymous], 2007, 2007 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2007.383198
   Arsenault E, 2010, J VISION, V10, P1354
   Aujol J.-F., 2003, 4704 INRIA
   Awate SP, 2005, PROC CVPR IEEE, P44
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Brox T, 2004, LECT NOTES COMPUT SC, V3022, P578
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Clausi DA, 2005, IEEE T IMAGE PROCESS, V14, P925, DOI 10.1109/TIP.2005.849319
   Clausi DA, 1998, IEEE T GEOSCI REMOTE, V36, P298, DOI 10.1109/36.655338
   Cutler R, 2000, IEEE T PATTERN ANAL, V22, P781, DOI 10.1109/34.868681
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   De Grandi GD, 2007, IEEE T GEOSCI REMOTE, V45, P3437, DOI 10.1109/TGRS.2007.905103
   Deselaers T, 2010, PROC CVPR IEEE, P1633, DOI 10.1109/CVPR.2010.5539775
   DUNN D, 1995, IEEE T IMAGE PROCESS, V4, P947, DOI 10.1109/83.392336
   ECKMANN JP, 1987, EUROPHYS LETT, V4, P973, DOI 10.1209/0295-5075/4/9/004
   Foote JT, 2003, PROC SPIE, V5021, P167, DOI 10.1117/12.476302
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P3866, DOI 10.1109/TIP.2013.2263147
   Kovesi P.D., 1999, Videre: Journal of Computer Vision Research, V1
   LELE S, 1993, MATH GEOL, V25, P573, DOI 10.1007/BF00890247
   Lifei Z, 2002, THESIS CHINESE ACAD
   Liu XW, 2006, IEEE T IMAGE PROCESS, V15, P3066, DOI 10.1109/TIP.2006.877511
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MAIZEL JV, 1981, P NATL ACAD SCI-BIOL, V78, P7665, DOI 10.1073/pnas.78.12.7665
   MALIK J, 1990, J OPT SOC AM A, V7, P923, DOI 10.1364/JOSAA.7.000923
   MANJUNATH BS, 1991, IEEE T PATTERN ANAL, V13, P478, DOI 10.1109/34.134046
   MEYER Y, 2001, U LECT SER AM MATH S, V22
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Osher S, 2003, MULTISCALE MODEL SIM, V1, P349, DOI 10.1137/S1540345902416247
   Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068
   ROUSSON M, 2003, P IEEE C COMP VIS PA, V2, P669
   Sanders BCS, 2002, INT C PATT RECOG, P1, DOI 10.1109/ICPR.2002.1047781
   SHAPIRO BA, 1987, J BIOMOL STRUCT DYN, V4, P697, DOI 10.1080/07391102.1987.10507673
   UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936
   Vese LA, 2003, J SCI COMPUT, V19, P553, DOI 10.1023/A:1025384832106
   Wilscy M, 2010, P IEEE INT C COMP IN, P1
   Zhang JG, 2002, INT C PATT RECOG, P901, DOI 10.1109/ICPR.2002.1048450
NR 36
TC 3
Z9 3
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 6069
EP 6089
DI 10.1007/s11042-014-1909-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100034
DA 2024-07-18
ER

PT J
AU Zhou, XK
   Wang, W
   Jin, Q
AF Zhou, Xiaokang
   Wang, Wei
   Jin, Qun
TI Multi-dimensional attributes and measures for dynamical user profiling
   in social networking environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User attribute description; User profiling; Social network analysis;
   Information behavior analysis; Social media; Information seeking
ID BEHAVIOR
AB In this study, we concentrate on analyzing and building the dynamical user profiling to describe users' multi-dimensional features and properties, in order to assist the individualized information seeking and recommendation process in social networking environments. A set of user attributes are introduced and defined to describe the basic user profiling in accordance with the analysis of information behaviors, and several centrality based measures are proposed and developed to describe the users' importance and contributions with regards to a group of users based on their social connections in the DSUN (Dynamically Socialized User Networking) model. The experimental results are discussed to demonstrate the feasibility and effectiveness of our proposed methods.
C1 [Zhou, Xiaokang; Wang, Wei; Jin, Qun] Waseda Univ, Grad Sch Human Sci, Tokorozawa, Saitama, Japan.
C3 Waseda University
RP Jin, Q (corresponding author), Waseda Univ, Grad Sch Human Sci, Tokorozawa, Saitama, Japan.
EM xkzhou@ruri.waseda.jp; ougi@ruri.waseda.jp; jin@waseda.jp
RI Bennis, Mehdi/ABE-5838-2020
OI Bennis, Mehdi/0000-0003-0261-0171
FU Waseda University Grants for Special Research [2013A-6395, 2013B-207,
   2014K-6214]
FX The work has been partly supported by 2013 and 2014 Waseda University
   Grants for Special Research Project No. 2013A-6395, No. 2013B-207, and
   No. 2014K-6214.
CR Achananuparp P, 2012, ACM TRANS MANAG INF, V3, DOI 10.1145/2361256.2361258
   Agarwal NareshKumar., 2011, Proceedings of the ASIST Annual Meeting, P48
   Allen SM, 2010, ACM T AUTON ADAP SYS, V5, DOI 10.1145/1671948.1671952
   [Anonymous], P CIKM 12 21 ACM INT
   [Anonymous], P ASIS T 10 3 ASIS T
   [Anonymous], 2011, PROCESSES FACTORS CO
   [Anonymous], 2013, PROC 8 ACM SIGSAC S
   [Anonymous], 2013, PROC 16 INT C EXTEND
   [Anonymous], ACM T INTERNET TECHN
   Asur S, 2009, ACM T KNOWL DISCOV D, V3, DOI 10.1145/1631162.1631164
   Black A, 2012, PROCEEDINGS OF THE 17TH ACM INTERNATIONAL CONFERENCE ON SUPPORTING GROUP WORK, P229
   Bonchi F, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961194
   Chang Y, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2414425.2414429
   Fire M, 2013, ACM T INTEL SYST TEC, V5, DOI 10.1145/2542182.2542192
   Juihsiang Lee, 2013, Human Interface and the Management of Information. Information and Interaction Design. 15th International Conference, HCI International 2013. Proceedings: LNCS 8016, P456, DOI 10.1007/978-3-642-39209-2_52
   Kendall L., 2011, CHI'11 Extended Abstracts on Human Factors in Computing Systems, P1555
   Li R, 2012, PROC VLDB ENDOW, V5, P1603
   Li Rui., 2012, P 18 ACM SIGKDD INT, P1023
   Lou TC, 2013, ACM T KNOWL DISCOV D, V7, DOI 10.1145/2499907.2499908
   Middleton SE, 2004, ACM T INFORM SYST, V22, P54, DOI 10.1145/963770.963773
   Ouanaim M., 2010, Proceedings of the 6th IWC MC Conference, P550
   Park JY, 2012, PROCEEDINGS OF THE 3RD ANNUAL ACM WEB SCIENCE CONFERENCE, 2012, P233
   Radinsky K, 2013, ACM T INFORM SYST, V31, DOI 10.1145/2493175.2493181
   Reddy MC, 2008, INFORM PROCESS MANAG, V44, P256, DOI 10.1016/j.ipm.2006.12.010
   Smyth B., 2013, P 2013 INT C INT US, V13, P25, DOI DOI 10.1145/2449396.2449402
   Tang J, 2011, PROC MSM 11 2011 INT, P1
   Tang J, 2010, ACM T KNOWL DISCOV D, V5, DOI 10.1145/1870096.1870098
   Wang J., 2010, ACM Transactions on Management Information Systems TMIS, V1, P3
   Xiaokang Zhou, 2012, Active Media Technology. 8th International Conference, AMT 2012. Proceedings, P53, DOI 10.1007/978-3-642-35236-2_6
   Zeb M. A., 2011, 2011 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies, P357, DOI 10.1109/WI-IAT.2011.234
   Zhou XK, 2013, MULTIMED TOOLS APPL, V63, P129, DOI 10.1007/s11042-012-1069-1
NR 31
TC 24
Z9 25
U1 2
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 14
BP 5015
EP 5028
DI 10.1007/s11042-014-2230-9
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XU
UT WOS:000358214900002
DA 2024-07-18
ER

PT J
AU Kim, H
   Lim, S
   Yu, S
AF Kim, Hyungwook
   Lim, Sojeong
   Yu, Sungwook
TI Fast intra-mode decision method for luma and chroma blocks for H.264/AVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intra-prediction; Mode decision; Spatial correlation; H.264/AVC
ID MODE DECISION; PREDICTION; ALGORITHM
AB This paper presents a fast and efficient intra-mode decision method for H.264/AVC. The proposed method makes use of several directional measures that are based not only on the pixels in an image block but also on the neighboring pixels. As a result, the proposed method can predict the dominant direction of an image block more accurately than the other methods. It also considers various kinds of candidate modes, while efficiently controlling the number of modes to be examined. In the chroma mode decision, the proposed method uses the correlation between the chroma mode and the 16 x 16 luma mode to reduce the encoding complexity. By combining all these techniques in an efficient way, the proposed method not only improves the coding performance, but also reduces the encoding time significantly compared to conventional intra-mode decision methods.
C1 [Kim, Hyungwook; Lim, Sojeong; Yu, Sungwook] Chung Ang Univ, Sch Elect & Elect Engn, Seoul 156756, South Korea.
C3 Chung Ang University
RP Yu, S (corresponding author), Chung Ang Univ, Sch Elect & Elect Engn, 221 HeukSeok Dong, Seoul 156756, South Korea.
EM sungwook@cau.ac.kr
FU Basic Science Research Program through the NRF of Korea - Ministry of
   Education [2010-0013163]; Human Resources Development program of the
   KETEP grant - Korea government Ministry of Trade, Industry and Energy
   [20124030200060]; MSIP, Korea, under the ITRC support program
   [NIPA-2013-H0301-13-1002]
FX This research was supported by Basic Science Research Program through
   the NRF of Korea funded by the Ministry of Education (No. 2010-0013163),
   by the Human Resources Development program (No. 20124030200060) of the
   KETEP grant funded by the Korea government Ministry of Trade, Industry
   and Energy, and by the MSIP, Korea, under the ITRC support program
   (NIPA-2013-H0301-13-1002) supervised by the NIPA.
CR [Anonymous], 2010, The H.264 Advanced Video Compression Standard
   Bjontegaard G., 2001, ITU T 13 VCEG M
   Chen CN, 2013, MULTIMED TOOLS APPL, V62, P719, DOI 10.1007/s11042-011-0862-6
   Chen W, 2013, P 18 INT C DIG SIGN
   Huang YH, 2010, IEEE T CIRC SYST VID, V20, P1122, DOI 10.1109/TCSVT.2010.2057018
   Kuo Y, 2013, MULTIMED TOOLS APPL, P1
   Kwon SK, 2012, IEEE T BROADCAST, V58, P125, DOI 10.1109/TBC.2011.2174894
   Pan F, 2005, IEEE T CIRC SYST VID, V15, P813, DOI 10.1109/TCSVT.2005.848356
   Pejman H, 2012, IEEE T CONSUM ELECTR, V58, P1345
   Quan D, 2010, IEEE T CONSUM ELECTR, V56, P1049, DOI 10.1109/TCE.2010.5506038
   Su XQ, 2011, MULTIMED TOOLS APPL, V52, P65, DOI 10.1007/s11042-009-0452-z
   Tsai AC, 2008, IEEE T CIRC SYST VID, V18, P975, DOI 10.1109/TCSVT.2008.920742
   Tsai AC, 2008, IEEE T CIRC SYST VID, V18, P694, DOI 10.1109/TCSVT.2008.919113
   Wang JC, 2007, IEEE T CIRC SYST VID, V17, P1414, DOI 10.1109/TCSVT.2007.903786
   Wang P, 2012, MULTIMED TOOLS APPL, V60, P139, DOI 10.1007/s11042-011-0807-0
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zeng HQ, 2010, IEEE T CIRC SYST VID, V20, P907, DOI 10.1109/TCSVT.2010.2045802
NR 17
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 13
BP 4641
EP 4653
DI 10.1007/s11042-013-1827-8
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CL7DG
UT WOS:000357130400009
DA 2024-07-18
ER

PT J
AU Choi, MH
   Wilber, SC
   Hong, M
AF Choi, Min-Hyung
   Wilber, Steven C.
   Hong, Min
TI Estimating material properties of deformable objects by considering
   global object behavior in video streams
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Global deformation; Computer vision; Material property estimation;
   Data-driven animation; Physically-based simulation
ID PARAMETERS
AB One of the crucial components in improving simulation quality in physics-based animation of deformable object is finding proper material properties that define the movement upon external excitation. Most work in the estimation of material properties for highly deformable objects involves applying localized force to a point on the object's surface with mechanical devices and measuring the displacement of the surface at the contact point and surrounding points. While understanding this localized behavior provides a step towards accurately simulating objects with known material properties, an understanding of the global behavior of the object undergoing deformation is more important for many practical applications. This paper describes both the computer vision based techniques for tracking global position information of moving deformable objects from a video stream and the optimization routine for estimating the elasticity parameters of a mass-spring simulation. The collected data is the object's surface node position of object over time which is used to a data-driven simulation of that object to match the behavior of a virtual object to the corresponding real one. This paper demonstrates that estimating material properties of highly elastic objects by matching the global behavior of the object in a video is possible with the proposed method and the experimental results show that the captured and simulated motions are well matched each other.
C1 [Choi, Min-Hyung; Wilber, Steven C.] Univ Colorado, Dept Comp Sci, Denver, CO 80202 USA.
   [Hong, Min] Soonchunhyang Univ, Dept Comp Software Engn, Asan, South Korea.
C3 University of Colorado System; University of Colorado Denver;
   Soonchunhyang University
RP Hong, M (corresponding author), Soonchunhyang Univ, Dept Comp Software Engn, Asan, South Korea.
EM min.choi@ucdenver.edu; steven.wilber@ucdnever.edu; mhong@sch.ac.kr
FU Soonchunhyang University [20130575]
FX This work was partially supported by the Soonchunhyang University
   Research Fund (No. 20130575).
CR [Anonymous], 2011, ACM T GRAPHICS PROC
   Becker M, 2007, P SIM VIS, V15-28
   Bhat K. S., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P37
   Bickel B., 2008, Proceedings of the 2008 ACM SIGGRAPH/Eurographics Symposium on Computer Animation (SCA '08), P57
   Bickel B, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239484
   Bradley D, 2008, IEEE C COMP VIS PATT, V1-8, P2008
   Bradski G., 2000, Opencv. Dr. Dobb's journal of software tools
   Chaudhary A, 2012, J INF PROCESS SYST, V8, P399, DOI 10.3745/JIPS.2012.8.3.399
   Erwin C, BULLET PHYS LIB
   Frank B, 2010, IEEE INT C INT ROBOT, P1877, DOI 10.1109/IROS.2010.5653949
   Gilles B, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1944846.1944855
   Jeon J, 2012, J INF PROCESS SYST, V8, P713, DOI 10.3745/JIPS.2012.8.4.713
   Kim J, 2014, J INF PROCESS SYST, V10, P23, DOI 10.3745/JIPS.2014.10.1.023
   Kunitomo S., 2010, ACM SIGGRAPH 2010 PO, P15
   Lang J, 2001, THESIS U BRIT COLUMB
   Miguel E, 2012, COMPUT GRAPH FORUM, V31, P519, DOI 10.1111/j.1467-8659.2012.03031.x
   Otaduy M, 2012, ACM SIGGRAPH 2012 CO
   Sebastian Patrick, 2010, International Journal on Electrical Engineering and Informatics, V2, P298, DOI [10.15676/ijeei.2010.2.4.5, DOI 10.15676/IJEEI.2010.2.4.5]
   Shah M., 1997, Fundamentals of Computer Vision
   Si H., 2004, TETGEN QUALITY TETRA
   Syllebranque C, 2008, VISUAL COMPUT, V24, P963, DOI 10.1007/s00371-008-0273-5
NR 21
TC 3
Z9 3
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 10
BP 3361
EP 3375
DI 10.1007/s11042-014-1995-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI1GY
UT WOS:000354493000008
DA 2024-07-18
ER

PT J
AU Jung, EY
   Kim, JT
   Soh, J
   Park, DK
AF Jung, Eun-Young
   Kim, Jong Tak
   Soh, Jaeyoung
   Park, Dong Kyun
TI Development of U-healthcare monitoring system based on context-aware for
   knowledge service
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE U-healthcare; Monitoring system; Context-aware; Knowledge service;
   Chronic diseases
AB Due to the recently increased standard of living and the aging population, concerns for health management are increasing. In particular, with the development of IT, the increase in the number of hypertension patients has caused a rise in the number of services that offer monitoring and intelligent analysis regardless of the patient's location. This paper develops a u-healthcare monitoring system that offers an alarm service for measurement, and notification in case of unusual levels of patient indicators, based on the user's bio-signal data and context-aware. This system provides a more accurate measurement value than the previous monitoring services because it considers each user's condition, and therefore can reduce the user's health risks, using the patient's life management and lifestyle measurement values. This enables the provision of accurate and specific, and more personalized services to each user. It also includes a portable user terminal to increase the accuracy of context-aware and enhance user convenience.
C1 [Jung, Eun-Young; Park, Dong Kyun] Gachon Univ, Gil Med Ctr, U Healthcare Ctr, Inchon 405760, South Korea.
   [Kim, Jong Tak; Soh, Jaeyoung] BIT Comp Co Ltd, U Healthcare Dept, Seoul, South Korea.
C3 Gachon University
RP Park, DK (corresponding author), Gachon Univ, Gil Med Ctr, U Healthcare Ctr, 1198 Guwol Dong, Inchon 405760, South Korea.
EM eyjung@gilhospital.com; jtkim@bit.kr; jysoh@bit.co.kr;
   pdk66@gilhospital.com
FU Industrial Strategic Technology Development Program - Ministry of
   Knowledge Economy [10037283]; Korean Health Technology R&D Project,
   Ministry of Health & Welfare, Republic of Korea [A112020]
FX This research supported by Grant No. 10037283 from the Industrial
   Strategic Technology Development Program funded by the Ministry of
   Knowledge Economy. This study was supported by a grant of the Korean
   Health Technology R&D Project, Ministry of Health & Welfare, Republic of
   Korea (A112020).
CR Baek SJ, 2013, WIRELESS PERS COMMUN, V73, P309, DOI 10.1007/s11277-013-1239-0
   Chen H, 2004, PROCEEDINGS OF MOBIQUITOUS 2004, P258
   Chung KY, 2014, PERS UBIQUIT COMPUT, V18, P1291, DOI 10.1007/s00779-013-0743-2
   Chung KY, 2013, WIRELESS PERS COMMUN, V73, P243, DOI 10.1007/s11277-013-1234-5
   Dey AK, 2001, HUM-COMPUT INTERACT, V16, P97, DOI 10.1207/S15327051HCI16234_02
   Ha OK, 2014, PERS UBIQUIT COMPUT, V18, P553, DOI 10.1007/s00779-013-0675-x
   Hadzic M, 2004, IEEE IND ELEC, P480
   Han JS, 2013, POLICY LIT CONTENT B, DOI [10. 1007/ s11042- 013- 1664- 9, DOI 10.1007/S11042-013-1664-9]
   Jung EY, 2013, WIRELESS PERS COMMUN, V73, P207, DOI 10.1007/s11277-013-1231-8
   Jung H, 2014, CLUSTER COMPUT, V17, P767, DOI 10.1007/s10586-013-0318-z
   Jung H, 2014, PERS UBIQUIT COMPUT, V18, P1363, DOI 10.1007/s00779-013-0738-z
   Jung YG, 2011, INFORMATION-TOKYO, V14, P3791
   Kang SK, 2014, PERS UBIQUIT COMPUT, V18, P515, DOI 10.1007/s00779-013-0668-9
   Kang SK, 2013, WIRELESS PERS COMMUN, V73, P341, DOI 10.1007/s11277-013-1242-5
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P873, DOI 10.1007/s11042-011-0919-6
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P855, DOI 10.1007/s11042-011-0920-0
   Lee KD, 2013, MULTIMED TOOLS APPL, V63, P27, DOI 10.1007/s11042-012-1020-5
   Lorig KR, 2003, ANN BEHAV MED, V26, P1, DOI 10.1207/S15324796ABM2601_01
   Minchin R, 2006, COMP MED SY, P593, DOI 10.1109/CBMS.2006.152
   Song CW, 2014, MULTIMED TOOLS APPL, V71, P813, DOI 10.1007/s11042-013-1362-7
   United States Department of Health and Human Services, 2004, 7 US DEP HLTH HUM SE
   Wang XH, 2004, SECOND IEEE ANNUAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS WORKSHOPS, PROCEEDINGS, P18
   Yoon KH, 2006, LANCET, V368, P1681, DOI 10.1016/S0140-6736(06)69703-1
NR 23
TC 5
Z9 5
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 7
BP 2467
EP 2482
DI 10.1007/s11042-014-2037-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE0TU
UT WOS:000351520200018
DA 2024-07-18
ER

PT J
AU Bakhtiari, AS
   Bouguila, N
AF Bakhtiari, Ali Shojaee
   Bouguila, Nizar
TI Semisupervised online learning of hierarchical structures for visual
   object classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dirichlet distribution; Generalized Dirichlet distribution;
   Beta-Liouville distribution; Online learning; Hierarchical
   classification; Statistical modeling; Visual words; EM algorithm; Count
   data analysis
ID MIXTURE MODEL; IMAGE; CATEGORIZATION; RETRIEVAL
AB One of the main challenges in hierarchical object classification is the derivation of the correct hierarchical structure. The classic way around the problem is assuming prior knowledge about the hierarchical structure itself. Two major drawbacks result from the former assumption. Firstly it has been shown that the hierarchies tend to reduce the differences between adjacent nodes. It has been observed that this trait of hierarchical models results in a less accurate classification. Secondly the mere assumption of prior knowledge about the form of the hierarchy requires an extra amount of information about the dataset that in many real world scenarios may not be available. In this work we address the mentioned problems by introducing online learning of hierarchical models. Our models start from a crude guess of the hierarchy and proceed to figure out the detailed version progressively. We show the merits of the proposed work via extensive simulations and experiments on a real objects database.
C1 [Bakhtiari, Ali Shojaee] Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ H3G 1M8, Canada.
   [Bouguila, Nizar] Concordia Univ, Concordia Inst Informat Syst Engn, Montreal, PQ, Canada.
C3 Concordia University - Canada; Concordia University - Canada
RP Bouguila, N (corresponding author), Concordia Univ, Concordia Inst Informat Syst Engn, Montreal, PQ, Canada.
EM al_sho@encs.concordia.ca; nizar.bouguila@concordia.ca
RI Bouguila, Nizar/AGN-5929-2022; Bakhtiari, Ali Shojaee/L-1104-2019;
   Bouguila, Nizar/AAJ-2518-2020
CR Bakhtiari A. S., 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P493, DOI 10.1109/MMSP.2010.5662071
   Bakhtiari AS, 2012, LECT NOTES COMPUT SC, V7664, P332, DOI 10.1007/978-3-642-34481-7_41
   Bakhtiari AS, 2011, PROC INT C TOOLS ART, P817, DOI 10.1109/ICTAI.2011.128
   Bar M, 2004, NAT REV NEUROSCI, V5, P617, DOI 10.1038/nrn1476
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bouguila N, 2004, MACHINE LEARNING FOR SIGNAL PROCESSING XIV, P23
   Bouguila N, 2004, IEEE T IMAGE PROCESS, V13, P1533, DOI 10.1109/TIP.2004.834664
   Bouguila N, 2009, PATTERN RECOGN, V42, P33, DOI 10.1016/j.patcog.2008.06.022
   Bouguila N, 2008, INT CONF ACOUST SPEE, P821, DOI 10.1109/ICASSP.2008.4517736
   Bouguila N, 2008, LECT NOTES ARTIF INT, V5012, P503, DOI 10.1007/978-3-540-68125-0_44
   Bouguila N, 2007, INT CONF ACOUST SPEE, P953
   Bouguila N, 2007, J VIS COMMUN IMAGE R, V18, P295, DOI 10.1016/j.jvcir.2007.02.005
   Bouguila N, 2006, IEEE T KNOWL DATA EN, V18, P993, DOI 10.1109/TKDE.2006.133
   Bouguila N, 2006, IEEE T IMAGE PROCESS, V15, P2657, DOI 10.1109/TIP.2006.877379
   Bouguila N, 2010, IEEE T NEURAL NETWOR, V21, P107, DOI 10.1109/TNN.2009.2034851
   Brunelli R, 2000, IEEE T MULTIMEDIA, V2, P164, DOI 10.1109/6046.865481
   Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646
   CONNOR RJ, 1969, J AM STAT ASSOC, V64, P194, DOI 10.2307/2283728
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Durett R, 2008, PROBABILITY MODELS D
   FANG K.- T., 2018, Symmetric multivariate and related distributions
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Greenspan H, 2007, IEEE T INF TECHNOL B, V11, P190, DOI 10.1109/TITB.2006.874191
   Hartigan John A., 1975, Clustering Algorithms
   Hofmann T, 1998, P C AUT LEARN DISC C
   Kwok Leung Yu, 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, P156
   Lee J., 2008, LIBPMK PYRAMID MATCH
   Li FF, 2002, P NATL ACAD SCI USA, V99, P9596, DOI 10.1073/pnas.092277599
   López-Rubio E, 2011, IEEE T NEURAL NETWOR, V22, P997, DOI 10.1109/TNN.2011.2138159
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Peelen MV, 2009, NATURE, V460, P94, DOI 10.1038/nature08103
   Sivic J, 2008, PROC CVPR IEEE, P2182
   Veeramachaneni Sriharsha, 2005, P 22 INT C MACH LEAR, P928
NR 35
TC 0
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 6
BP 1805
EP 1822
DI 10.1007/s11042-013-1719-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CD9CN
UT WOS:000351394500005
DA 2024-07-18
ER

PT J
AU Chang, YT
   Huang, CT
   Huang, CL
   Wang, SJ
AF Chang, Ya Ting
   Huang, Cheng-Ta
   Huang, Chia-Ling
   Wang, Shiuh-Jeng
TI Data hiding of high compression ratio in VQ indices with neighboring
   correlations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vector quantization; Information hiding; Reversible data hiding; Image
   compression
ID IMAGES
AB As the progressive development of information and communication technology, the security and integrity of data transmission through public network have become important issues. Thus information hiding for images is one of the main research issues to maintain the data security and integrity. This paper proposed a data hiding method on the indices of VQ compression. For an index table of VQ compression, neighboring indices have similar index values in a great chance. Exploiting neighboring correlation among VQ indices, the proposed data hiding can enhance the embedding capacity and bit rate of encoding. In addition, our method can use the output bit stream to reconstruct the cover image. Experimental results show the proposed scheme performs better in average comparing with Lee et al.' smethod [9] in 2013.
C1 [Chang, Ya Ting; Wang, Shiuh-Jeng] Cent Police Univ, Dept Informat Management, Taoyuan, Taiwan.
   [Huang, Cheng-Ta] Natl Taiwan Univ Sci & Technol, Grad Inst Biomed Engn, Taipei, Taiwan.
   [Huang, Chia-Ling] Kainan Univ, Dept Logist & Shipping Management, Taipei, Taiwan.
C3 National Taiwan University of Science & Technology; Nan Kai University
   Technology
RP Wang, SJ (corresponding author), Cent Police Univ, Dept Informat Management, Taoyuan, Taiwan.
EM sjwang@mail.cpu.edu.tw
RI Wang, Suhang/AAH-1378-2019
FU National Science Council of the Republic of China [NSC
   100-2221-E-015-001-MY2-, NSC 102-2221-E-015-001-]
FX This research was partially supported by the National Science Council of
   the Republic of China under the Grant NSC 100-2221-E-015-001-MY2- and
   NSC 102-2221-E-015-001-.
CR Al-Qershi OM, 2011, J SYST SOFTWARE, V84, P105, DOI 10.1016/j.jss.2010.08.055
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2006, IEEE T CIRC SYST VID, V16, P1301, DOI 10.1109/TCSVT.2006.882380
   Chen SK, 2011, COMPUT STAND INTER, V33, P367, DOI 10.1016/j.csi.2010.11.002
   Hu YC, 2006, PATTERN RECOGN, V39, P1715, DOI 10.1016/j.patcog.2006.02.005
   Hu-Yu Huang, 2010, Proceedings of the 2010 IEEE 10th International Conference on Computer and Information Technology (CIT 2010), P1554, DOI 10.1109/CIT.2010.276
   Huang CT, 2013, IMAGING SCI J, V61, P195, DOI 10.1179/1743131X11Y.0000000031
   Lee JD, 2013, INFORM SCIENCES, V221, P419, DOI 10.1016/j.ins.2012.09.020
   Lin YK, 2012, J SYST SOFTWARE, V85, P2395, DOI 10.1016/j.jss.2012.05.032
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Pawar PH, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION CONTROL AND COMPUTING TECHNOLOGIES (ICACCCT), P295, DOI 10.1109/ICACCCT.2012.6320790
   Sencar HT, 2006, SIGNAL PROCESS, V86, P893, DOI 10.1016/j.sigpro.2005.07.018
   Singh S., 2011, 2011 International Conference on Multimedia, Signal Processing and Communication Technologies (IMPACT 2011), P300, DOI 10.1109/MSPCT.2011.6150499
NR 14
TC 8
Z9 8
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 5
BP 1645
EP 1666
DI 10.1007/s11042-014-2019-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CC7UC
UT WOS:000350572900008
DA 2024-07-18
ER

PT J
AU Jia, Y
   Wang, YL
   Song, R
   Li, JD
AF Jia, Yuan
   Wang, Yangli
   Song, Rui
   Li, Jiandong
TI Decoder side information generation techniques in Wyner-Ziv video
   coding: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wyner-Ziv video coding; Slepian-Wolf theorem; Side information; Motion
   compensated extrapolation; Motion compensated interpolation; Decoder
   motion estimation
ID MOTION ESTIMATION; DOMAIN; INTERPOLATION; COMPENSATION; REDUNDANCY
AB In Wyner-Ziv (WZ) video coding, decoder side information (SI) takes a key role in a WZ video codec among other building blocks. In this paper, we review the decoder SI generation techniques according to the information utilized in the SI generation process. Specifically, motion compensated extrapolation based approaches, motion compensated interpolation based approaches, and hash-based decoder motion estimation approaches in which auxiliary information is sent by the encoder side. We also review the approaches for decoder SI refinement. The review will help us get insight in the current development of the topic and understand how new and better decoder SI generation approaches can be designed.
C1 [Jia, Yuan; Wang, Yangli; Song, Rui; Li, Jiandong] Xidian Univ, State Key Lab ISN, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Jia, Y (corresponding author), Xidian Univ, State Key Lab ISN, Xian 710071, Shaanxi, Peoples R China.
EM jiayuan@xidian.edu.cn
RI chen, bin/KBQ-8114-2024
OI chen, bin/0000-0002-3398-1314
FU National Science and Technology Major Project of China
   [2011ZX03001-007-01]; National Basic Research Program of China
   [2009CB320404]; Fundamental Research Funds for the Central Universities
   [72115046]; 111 Project [B08038]
FX This work was supported in part by the National Science and Technology
   Major Project of China (2011ZX03001-007-01), the National Basic Research
   Program of China (2009CB320404), the Fundamental Research Funds for the
   Central Universities (72115046), and the 111 Project (B08038).
CR Aaron A, 2004, IEEE IMAGE PROC, P3097
   Aaron A, 2002, CONF REC ASILOMAR C, P240
   AARON A, 2004, PICT COD S, P429
   Abou-Elailah A, 2013, IEEE T CIRC SYST VID, V23, P158, DOI 10.1109/TCSVT.2012.2203211
   Adikari ABB, 2006, ELECTRON LETT, V42, P398, DOI 10.1049/el:20060302
   Anbu A, 2005, HASH AIDED MOTION ES
   Argyropoulos S, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P159, DOI 10.1109/MMSP.2007.4412842
   Artigas X, 2005, IEEE IMAGE PROC, P1133
   Artigas X, 2006, IEEE IMAGE PROC, P281, DOI 10.1109/ICIP.2006.313180
   Ascenso C., 2005, 5th EURASIP Conference on Speech and Image Processing, Multimedia Communications and Services, P1
   Ascenso J, 2005, AVSS 2005: Advanced Video and Signal Based Surveillance, Proceedings, P593
   Ascenso J, 2006, IEEE INT C IM PROC I, V3, pIII29
   Badem MB, 2008, ELECTRON LETT, V44, P965, DOI 10.1049/el:20081659
   Badem MB, 2009, IEEE INT CON MULTI, P177, DOI 10.1109/ICME.2009.5202465
   Cafforio C., 1983, IMAGE SEQUENCE PROCE, P104
   Cagnazzo M, 2009, INT CONF ACOUST SPEE, P1861, DOI 10.1109/ICASSP.2009.4959970
   Chien WJ, 2006, IEEE INT SYMP CIRC S, P5415
   Choi BT, 2000, IEEE T CONSUM ELECTR, V46, P603, DOI 10.1109/30.883418
   Dehy R, 2005, HASH CODES MOTION ES
   Deligiannis N, 2012, EURASIP J WIREL COMM, P1, DOI 10.1186/1687-1499-2012-106
   Deligiannis N, 2009, IEEE SIGNAL PROC LET, V16, P743, DOI 10.1109/LSP.2009.2024111
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   Guillemot C, 2007, IEEE SIGNAL PROC MAG, V24, P67, DOI 10.1109/MSP.2007.904808
   Guo M, 2007, IEEE INT SYMP CIRC S, P41, DOI 10.1109/ISCAS.2007.378177
   Huang XD, 2011, PROCEEDINGS OF THE 4TH CONFERENCE ON SYSTEMS SCIENCE, MANAGEMENT SCIENCE AND SYSTEMS DYNAMICS, SSMSSD10, VOL 2, P1
   Huang X, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P223, DOI 10.1109/MMSP.2008.4665079
   Kaul S, 2004, WYNER ZIV VIDEO CODI
   Kubasov D, 2006, IEEE IMAGE PROC, P261, DOI 10.1109/ICIP.2006.313175
   Lagendijk R. L., 1992, ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech and Signal Processing (Cat. No.92CH3103-9), P453, DOI 10.1109/ICASSP.1992.226178
   LEE JW, 2005, HASH AIDED MOTION ES
   Lee SH, 2002, ELECTRON LETT, V38, P451, DOI 10.1049/el:20020306
   Li Z, 2007, IEEE T IMAGE PROCESS, V16, P98, DOI 10.1109/TIP.2006.884934
   Li Zheng., 2005, PROBABILISTIC ADAPTI
   Lin Y, 2005, SCALABLE FEATURE EXT
   Liu W, 2008, P SOC PHOTO-OPT INS, V6822, pW8221, DOI 10.1117/12.769320
   Liu W, 2010, IEEE T CIRC SYST VID, V20, P1863, DOI 10.1109/TCSVT.2010.2090424
   Macchiavello B, 2006, IEEE INT C IM PROC I, V6, pVI413
   Martins R, 2010, IET IMAGE PROCESS, V4, P28, DOI 10.1049/iet-ipr.2008.0133
   Martins R, 2009, IEEE T CIRC SYST VID, V19, P1327, DOI 10.1109/TCSVT.2009.2022783
   Natário L, 2006, LECT NOTES COMPUT SC, V3893, P16
   Petrazzuoli Giovanni, 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P309, DOI 10.1109/MMSP.2010.5662038
   Petrazzuoli G., 2010, Proceedings 2010 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP 2010, P2342, DOI 10.1109/ICASSP.2010.5496075
   Pradhan SS, 2003, IEEE T INFORM THEORY, V49, P626, DOI 10.1109/TIT.2002.808103
   Puri R., 2002, P ANN ALLERTON C COM, V40, P586
   Puri R, 2007, IEEE T IMAGE PROCESS, V16, P2436, DOI 10.1109/TIP.2007.904949
   Puri R, 2006, IEEE SIGNAL PROC MAG, V23, P94, DOI 10.1109/MSP.2006.1657820
   QUAZI AH, 1981, IEEE T ACOUST SPEECH, V29, P527, DOI 10.1109/TASSP.1981.1163618
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Tagliasacchi M, 2006, IEEE IMAGE PROC, P253, DOI 10.1109/ICIP.2006.313173
   Tagliasacchi M, 2007, INT CONF ACOUST SPEE, P509
   Varodayan D, 2008, SIGNAL PROCESS-IMAGE, V23, P369, DOI 10.1016/j.image.2008.04.009
   Varodayan D, 2005, 2005 39th Asilomar Conference on Signals, Systems and Computers, Vols 1 and 2, P1203
   Verbist F, 2013, MULTIMED TOOLS APPL, V66, P405, DOI 10.1007/s11042-012-1050-z
   Wang DM, 2010, IEEE T BROADCAST, V56, P142, DOI 10.1109/TBC.2010.2043895
   Wang YL, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P405, DOI 10.1109/CISP.2008.291
   Wang YL, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P132
   Weerakkody WARJ, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P164
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   WYNER AD, 1974, IEEE T INFORM THEORY, V20, P2, DOI 10.1109/TIT.1974.1055171
   Xiong ZX, 2004, IEEE SIGNAL PROC MAG, V21, P80, DOI 10.1109/MSP.2004.1328091
   Zhang Y, 2009, VISUAL COMMUNICATION, V7257, P18
   Zhang YX, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P246, DOI 10.1109/ICIG.2007.110
   Zhen L., 2005, IEEE C INT C IM PROC, P825
NR 63
TC 5
Z9 5
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 6
BP 1777
EP 1803
DI 10.1007/s11042-013-1718-z
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CD9CN
UT WOS:000351394500004
DA 2024-07-18
ER

PT J
AU Gao, GY
   Jiang, GP
AF Gao, Guangyong
   Jiang, Guoping
TI Bessel-Fourier moment-based robust image zero-watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Zero-watermarking; Bessel-Fourier moments; Feature image; Robustness
ID REVERSIBLE WATERMARKING; AUTHENTICATION; ALGORITHM; MACHINE
AB Aiming to resist various signal processing operations and geometric transformations, this paper proposes a robust zero-watermarking algorithm based on a new image moment called Bessel-Fourier moment. First, image normalization is used for the invariance of translation and scaling, then the magnitudes of Bessel-Fourier moments of normalized image are computed, which have rotation invariance and are used to construct the feature image regarded as watermarking. Experimental results and analyses show that the proposed method has strong robustness to various attacks, such as blurring, JPEG compression, Gaussian noise, rotation, scaling, Stirmark and print_photocopy_scan. Compared to the congener zero-watermarking schemes and Zernike moment, the developed method has better performance.
C1 [Gao, Guangyong; Jiang, Guoping] Nanjing Univ Posts & Telecommun, Coll Automat, Nanjing 210003, Peoples R China.
   [Gao, Guangyong] Jiujiang Univ, Sch Informat Sci & Technol, Jiujiang 332005, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Jiujiang University
RP Jiang, GP (corresponding author), Nanjing Univ Posts & Telecommun, Coll Automat, Nanjing 210003, Peoples R China.
EM gaoguangyong@163.com; jianggp@njupt.edu.cn
RI Jiang, Guo/ISR-9858-2023
FU National Natural Science Foundation of China [61362032, 61374180]; Six
   Projects Sponsoring Talent Summits of Jiangsu Province, China
   [SJ209006]; Research Fund for the Doctoral Program of Higher Education
   of China [20103223110003]; Natural Science Foundation of Jiangsu
   Province, China [BK2010526]; Natural Science Foundation of Educational
   Commission of Jiangxi Province, China [GJJ12614, GJJ13716]; Natural
   Science Foundation of Jiangxi Province, China [20132BAB211025]; Humanity
   and Social Science Youth foundation of Ministry of Education, China
   [13YJC870007]
FX This work is supported in part by the National Natural Science
   Foundation of China (Grant No. 61362032, 61374180), the Six Projects
   Sponsoring Talent Summits of Jiangsu Province, China (Grant No.
   SJ209006), the Research Fund for the Doctoral Program of Higher
   Education of China(20103223110003), the Natural Science Foundation of
   Jiangsu Province, China (Grant No. BK2010526), the Natural Science
   Foundation of Educational Commission of Jiangxi Province, China (Grant
   No. GJJ12614, GJJ13716), the Natural Science Foundation of Jiangxi
   Province, China (Grant No. 20132BAB211025) and the Humanity and Social
   Science Youth foundation of Ministry of Education, China (Grant No.
   13YJC870007).
CR Akhaee MA, 2010, IEEE T IMAGE PROCESS, V19, P967, DOI 10.1109/TIP.2009.2038774
   AMOS DE, 1986, ACM T MATH SOFTWARE, V12, P265, DOI 10.1145/7921.214331
   Chang CC, 2008, J SYST SOFTWARE, V81, P1118, DOI 10.1016/j.jss.2007.07.036
   Chen TH, 2005, IEEE T IND ELECTRON, V52, P327, DOI 10.1109/TIE.2004.841083
   Coatrieux G, 2009, IEEE T INF TECHNOL B, V13, P158, DOI 10.1109/TITB.2008.2007199
   Cui LH, 2011, IEEE T IMAGE PROCESS, V20, P1047, DOI 10.1109/TIP.2010.2079551
   Dong P, 2005, IEEE T IMAGE PROCESS, V14, P2140, DOI 10.1109/TIP.2005.857263
   Fan L, 2010, WUHAN U J NATURAL SC, V15, P408
   Feng GR, 2012, NEUROCOMPUTING, V82, P62, DOI 10.1016/j.neucom.2011.10.028
   Gao GY, 2013, MULTIMED TOOLS APPL, V63, P947, DOI 10.1007/s11042-012-1329-0
   Nasir I, 2010, SIGNAL IMAGE VIDEO P, V4, P145, DOI 10.1007/s11760-009-0106-7
   Rawat S, 2012, SIGNAL PROCESS, V92, P1480, DOI 10.1016/j.sigpro.2011.12.006
   SHENG YL, 1994, J OPT SOC AM A, V11, P1748, DOI 10.1364/JOSAA.11.001748
   Stankovic S, 2001, IEEE T IMAGE PROCESS, V10, P650, DOI 10.1109/83.913599
   Stankovic S, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013014
   Stankovic S, 2010, MULTIMED TOOLS APPL, V49, P529, DOI 10.1007/s11042-009-0446-x
   Stankovic S, 2010, IEEE T IMAGE PROCESS, V19, P736, DOI 10.1109/TIP.2009.2033624
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Tsai HH, 2010, J SYST SOFTWARE, V83, P1015, DOI 10.1016/j.jss.2009.12.026
   Wen Quan, 2003, Acta Electronica Sinica, V31, P214
   Xiao B, 2010, PATTERN RECOGN, V43, P2620, DOI 10.1016/j.patcog.2010.03.013
   Yang L, 2012, SECUR COMMUN NETW, V5, P353, DOI 10.1002/sec.319
   Zhang WY, 2011, OPT COMMUN, V284, P3904, DOI 10.1016/j.optcom.2011.04.004
NR 23
TC 56
Z9 58
U1 0
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 3
BP 841
EP 858
DI 10.1007/s11042-013-1701-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZO
UT WOS:000349356400009
DA 2024-07-18
ER

PT J
AU Al-Hadrusi, MS
   Sarhan, NJ
AF Al-Hadrusi, Musab S.
   Sarhan, Nabil J.
TI A scalable delivery solution and a pricing model for commercial
   video-on-demand systems with video advertisements
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Periodic broadcasting; Pricing; Scheduling; Stream merging; Supporting
   advertisements; Targeted advertisements; Video streaming
ID DESIGN; TIME
AB This paper presents a scalable delivery solution for commercial near on-demand video streaming systems with an associated pricing model. The proposed delivery solution combines the benefits of periodic broadcasting and stream merging, thereby enabling scalable video delivery. Video advertisements are delivered to the clients prior to viewing the requested videos. The revenues generated from the ads are used to subsidize the price of the requested videos. The pricing is determined based on the total ad viewing time. The proposed solution includes an efficient ad allocation scheme and a new constraint-based scheduling approach. In addition, the paper investigates how targeted advertisements can be efficiently supported. Furthermore, we investigate the effectiveness of the overall solutions and analyze and compare the effectiveness of various scheduling policies and ad allocation alternatives in terms of several metrics, including client defection probability, average number of viewed ads per client, price, channel utilization, revenue, and profit.
C1 [Al-Hadrusi, Musab S.; Sarhan, Nabil J.] Wayne State Univ, Dept Elect & Comp Engn, Multimedia Comp & Networking Res Lab, Detroit, MI 48202 USA.
C3 Wayne State University
RP Al-Hadrusi, MS (corresponding author), Wayne State Univ, Dept Elect & Comp Engn, Multimedia Comp & Networking Res Lab, 5050 Anthony Wayne Dr, Detroit, MI 48202 USA.
EM hadrusi@wayne.edu; nabil@wayne.edu
OI Sarhan, Nabil/0000-0002-0527-5666
CR Aggarwal V., 2009, Proceedings of the 17th ACM International Conference on Multimedia, P421, DOI DOI 10.1145/1631272.1631330
   Al-Hadrusi M, 2008, P SPIE ACM MULT COMP
   Al-Hadrusi MS, 2012, P IEEE INT MULT MOD
   [Anonymous], RFC2326 IETF
   Basu P., 1999, Proceedings Eight International Conference on Computer Communications and Networks (Cat. No.99EX370), P104, DOI 10.1109/ICCCN.1999.805503
   Basu P., 2000, Proceedings ACM Multimedia 2000, P359, DOI 10.1145/354384.354531
   Bruner RE, 2007, VIDEO BENCHMARKS AVE
   Cai Y, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P211
   Carlsson N, 2006, PERFORM EVALUATION, V63, P864, DOI 10.1016/j.peva.2005.09.005
   Cheng X, 2008, P IEEE 16 INT WORKSH
   Chien WD, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1843, DOI 10.1109/ICME.2004.1394616
   Dan Asit, 1994, P ACM MULT, P391
   DEERING S, 1999, RFC2710 IETF
   Eager D, 2001, IEEE T KNOWL DATA EN, V13, P742, DOI 10.1109/69.956098
   Eager D, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P199, DOI 10.1145/319463.319601
   GAO L, 1998, P INT WORKSH NETW OP
   Ge ZH, 2007, MULTIMEDIA SYST, V13, P235, DOI 10.1007/s00530-007-0092-y
   Gill P, 2008, ACM T MULTIM COMPUT, V5, DOI 10.1145/1404880.1404888
   Hua K., 1997, PROC SIGCOMM, P89
   Hua K. A., 1998, Proceedings ACM Multimedia 98, P191, DOI 10.1145/290747.290771
   Huang C., 2004, MULTIMEDIA '04, P152
   Jagannathan S, 2001, P IFIP IEEE INT C MA, P39
   Juhn LS, 1997, IEEE T BROADCAST, V43, P268, DOI 10.1109/11.632927
   Ma HD, 2005, MULTIMED TOOLS APPL, V26, P101, DOI 10.1007/s11042-005-6851-x
   Ma HD, 2002, ACM SIGCOMM COMP COM, V32, P31, DOI 10.1145/510726.510729
   Mei T, 2009, IEEE T CIRC SYST VID, V19, P1866, DOI 10.1109/TCSVT.2009.2026949
   O'Neill JP, 2009, INTENSIVE: 2009 FIRST INTERNATIONAL CONFERENCE ON INTENSIVE APPLICATIONS AND SERVICES, P39, DOI 10.1109/INTENSIVE.2009.14
   Ostrowski JR, 2009, P SPIE ACM MULT COMP
   Pallis G, 2006, COMMUN ACM, V49, P101, DOI 10.1145/1107458.1107462
   Paris JF, 1998, SIXTH INTERNATIONAL SYMPOSIUM ON MODELING, ANALYSIS AND SIMULATION OF COMPUTER AND TELECOMMUNICATION SYSTEMS, PROCEEDINGS, P127, DOI 10.1109/MASCOT.1998.693685
   Rayburn D., 2007, STREAMING DIGITAL ME
   Rayburn D., 2007, CDN PRICING DATA WHA
   Rocha M., 2005, 13th Annual ACM International Conference on Multimedia, P966, DOI 10.1145/1101149.1101351
   Rodrigues CKD, 2007, COMPUT NETW, V51, P569, DOI 10.1016/j.comnet.2006.05.004
   Sarhan NJ, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1671962.1671967
   Sarhan NJ, 2004, LECT NOTES COMPUT SC, V3271, P127
   Sarhan NJ, 2010, P IEEE INT S MULT IS
   Sarhan NJ, 2007, P MULT COMP NETW C M, P327
   Thouin F, 2007, IEEE NETWORK, V21, P42, DOI 10.1109/MNET.2007.334311
   Tsiolis A. K., 1997, Performance Evaluation Review, V25, P285, DOI 10.1145/258623.258697
   Wu CA, 2009, IEEE INFOCOM SER, P2731, DOI 10.1109/INFCOM.2009.5062221
NR 41
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1417
EP 1443
DI 10.1007/s11042-013-1597-3
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200015
DA 2024-07-18
ER

PT J
AU Ben Youssef, B
AF Ben Youssef, Belgacem
TI A visualization tool of 3-D time-varying data for the simulation of
   tissue growth
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visualization; Tissue growth; Time-varying data; 3-D simulation model;
   Cellular automata
ID ENDOTHELIAL-CELL LOCOMOTION; CHALLENGES
AB Data Visualization affords us the ability to explore the spatial and temporal domains of many time-varying phenomena. In this article, we describe our application of visualization to a three-dimensional simulation model for tissue growth. We review the different components of the model where cellular automata is used to model populations of cells that execute persistent random walks, collide, and proliferate until they reach confluence. We then describe the system architecture of the developed visualization tool, the employed rendering techniques, and the related prototyping interfaces. We also discuss some of the visualization results obtained thus far that are pertinent to enhancing the validity of the computational model. This visualization tool could be useful in facilitating the research of scientists by providing them with meaningful means to interpret and analyze simulation data and to compare them to experimental results. Our objective in this work is to develop computer-aided design solutions that support the simulation of tissue growth and its design exploration.
C1 King Saud Univ, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
C3 King Saud University
RP Ben Youssef, B (corresponding author), King Saud Univ, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
EM bbenyoussef@ksu.edu.sa
RI Youssef, Belgacem Ben/AAO-6326-2021
OI Youssef, Belgacem Ben/0000-0002-6618-3845
FU Research Centre in the College of Computer & Information Sciences at
   King Saud University [RC120920]; King Saud University
FX The author would like to acknowledge the support for this research
   provided by the Research Centre in the College of Computer & Information
   Sciences (under project number: RC120920) and the Deanship of Scientific
   Research, both at King Saud University. Early contribution to this work
   from Haris Widjaya is also acknowledged. Finally, comments received from
   the anonymous reviewers are acknowledged for helping to improve this
   article.
CR [Anonymous], MULTIDIMENSIONAL SUP
   [Anonymous], 2006, Simulation Modeling and Analysis
   [Anonymous], 1987, A Guide to Simulation
   Ben Youssef B, 2005, IEEE INT SYM MULTIM, P128
   Ben Youssef B, 2004, LECT NOTES COMPUT SC, V3305, P561
   Ben Youssef Belgacem, 2010, International Journal of Natural Computing Research, V1, P1, DOI 10.4018/jncr.2010070101
   Biddiscombe J, 2012, IEEE T VIS COMPUT GR, V18, P852, DOI 10.1109/TVCG.2012.63
   Burgess BT, 2000, ANN BIOMED ENG, V28, P110, DOI 10.1114/1.259
   Cheng G, 2006, BIOPHYS J, V90, P713, DOI 10.1529/biophysj.105.063701
   Childs H, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P191
   Deussen O., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P275, DOI 10.1145/280814.280898
   Earnshaw R., 1992, An introductory guide to scientific visualization
   ELLSWORTH D., 2000, VOLUME VISUALIZATION, P119
   Engel Klaus, 2001, P ACM SIGGRAPH EUROG, P9, DOI [DOI 10.1145/383507.383515, 10.1145/383507.383515]
   Fishwick P. A., 1995, Simulation model design and execution: Building digital worlds
   GAIL MH, 1970, BIOPHYS J, V10, P980, DOI 10.1016/S0006-3495(70)86347-0
   GRULER H, 1984, BLOOD CELLS, V10, P61
   HAGEDORN J, 2006, BIOMATERIALS FORUM, V28, P6
   Hagedorn JG, 2007, J RES NATL INST STAN, V112, P257, DOI 10.6028/jres.112.019
   Johnson C, 1999, COMPUTER, V32, P59, DOI 10.1109/2.809252
   Johnson C.R., 2006, 20 9 AUSTRALASIAN CO, V48, P3
   Kitware Inc, 2010, THE VTK USERS GUIDE, V11
   Lacroute P., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P451, DOI 10.1145/192161.192283
   LANGER R, 1993, SCIENCE, V260, P920, DOI 10.1126/science.8493529
   Lauffenburger D.A., 1993, Receptors: models for binding, trafficking, and signaling (no. Book
   LEE Y, 1994, BIOTECHNOL BIOENG, V43, P622, DOI 10.1002/bit.260430712
   Lee Y, 1995, BIOCHEM CELL BIOL, V73, P461, DOI 10.1139/o95-052
   Levin SA, 1997, SCIENCE, V275, P334, DOI 10.1126/science.275.5298.334
   Levine JA, 2012, IEEE COMPUT GRAPH, V32, P22, DOI 10.1109/MCG.2012.91
   LEVOY M, 1990, ACM T GRAPHIC, V9, P245, DOI 10.1145/78964.78965
   Linsen L, 2002, P 10 PAC C COMP GRAP, V346
   Lorensen W. E., 1987, COMPUTER GRAPHICS, V21, P163, DOI 10.1145/37401.37422
   Lum EB, 2001, IEEE VISUAL, P263, DOI 10.1109/VISUAL.2001.964520
   Lysaght MJ, 2004, TISSUE ENG, V10, P309, DOI 10.1089/107632704322791943
   Ma KL, 2003, COMPUT SCI ENG, V5, P34, DOI 10.1109/MCISE.2003.1182960
   Ma KL, 2007, J PHYS CONF SER, V78, DOI 10.1088/1742-6596/78/1/012043
   Ma KL, 2009, IEEE COMPUT GRAPH, V29, P14, DOI 10.1109/MCG.2009.120
   Ma KwanLiu., 2005, VISUALIZATION HDB, P511, DOI DOI 10.1016/B978-012387582-2/50028-9
   Majno G., 2004, Cells, tissues, and disease: principles of general pathology
   Marée AFM, 2001, P NATL ACAD SCI USA, V98, P3879, DOI 10.1073/pnas.061535198
   Martin P, 1997, SCIENCE, V276, P75, DOI 10.1126/science.276.5309.75
   Mech R., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P397, DOI 10.1145/237170.237279
   Mooney DJ, 1999, SCI AM, V280, P60, DOI 10.1038/scientificamerican0499-60
   Morris D, 2006, IEEE COMPUT GRAPH, V26, P48, DOI 10.1109/MCG.2006.140
   National Institute of Standards and Technology, VIS TISS ENG
   Palsson BB., 2004, TISSUE ENG
   Pieper S., 2004, 2004 2nd IEEE international symposium on biomedical imaging: nano to macro (IEEE Cat No. 04EX821), V1, P632
   Post FH, 2003, COMPUT GRAPH FORUM, V22, P775, DOI 10.1111/j.1467-8659.2003.00723.x
   Prusinkiewicz P., 1993, Computer Graphics Proceedings, P351, DOI 10.1145/166117.166161
   Rosenblum L., 1994, SCI VISUALIZATION AD
   Schroeder C., 2003, P 8 ACM S SOLID MODE, P254
   Sewell C, 2008, COMPUT AIDED SURG, V13, P63, DOI 10.3109/10929080801957712
   Shen H.-W., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P371, DOI 10.1109/VISUAL.1999.809910
   Silver D, 1997, IEEE T VIS COMPUT GR, V3, P129, DOI 10.1109/2945.597796
   Soll DR, 1998, MOTION ANAL LIVING C
   Squillacote A.Henderson., 2008, The ParaView Guide: A Parallel visualization application, Vthird
   Sun W, 2002, COMPUT METH PROG BIO, V67, P85, DOI 10.1016/S0169-2607(01)00116-X
   Sutton P., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P147, DOI 10.1109/VISUAL.1999.809879
   Tchuente M., 1987, AUTOMATA NETWORKS CO
   Telea A.C., 2008, DATA VISUALIZATION P, V1st
   Terrill J, 2009, ADV INFORM KNOWL PRO, P287, DOI 10.1007/978-1-84800-269-2_13
   Tory M, 2001, IEEE VISUAL, P473, DOI 10.1109/VISUAL.2001.964554
   Totsuka T., 1993, Computer Graphics Proceedings, P271, DOI 10.1145/166117.166152
   Tzeng Fan-Yin., 2005, SC 05, P6, DOI DOI 10.1109/SC.2005.37
   VACANTI JP, 1997, PRINCIPLES TISSUE EN
   WANG X, 2004, P 11 ACM C COMP COMM, P257
   Westover L., 1990, Computer Graphics, V24, P367, DOI 10.1145/97880.97919
   Whitlock Brad, 2011, P 11 EUR C PAR GRAPH, DOI [10.2312/EGPGV/EGPGV11/101-109, DOI 10.2312/EGPGV/EGPGV11/101-109]
   Wolfram S, 1994, COLLECTED PAPERS
   Woodring J, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P417, DOI 10.1109/VISUAL.2003.1250402
   Wright H, 2010, FUTURE GENER COMP SY, V26, P506, DOI 10.1016/j.future.2008.06.015
   Younesy H, 2005, VOLUME GRAPHICS 2005, P21
   Zhang KM, 2004, NINTH INTERNATIONAL WORKSHOP ON HIGH-LEVEL PARALLEL PROGRAMMING MODELS AND SUPPORTIVE ENVIRONMENTS, PROCEEDINGS, P72
   Zhang L, 2003, DISTRIB PARALLEL DAT, V13, P73, DOI 10.1023/A:1021517806825
   ZYGOURAKIS K, 1991, BIOTECHNOL BIOENG, V38, P459, DOI 10.1002/bit.260380504
NR 75
TC 8
Z9 8
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1795
EP 1817
DI 10.1007/s11042-013-1657-8
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200031
DA 2024-07-18
ER

PT J
AU Shoaib, M
   Ahmad, U
   Al-Amri, A
AF Shoaib, Muhammad
   Ahmad, Uzair
   Al-Amri, Atif
TI Multimedia framework to support eHealth applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE eHealth; Heterogeneous network; Medical imaging; Multimedia framework;
   Scalable extension of MPEC-4 AVC/H.264
ID VIDEO; DECISION
AB Limited bandwidth resources lead to a number of challenges especially for eHealth applications, which are communicated over IP and wireless networks. These multimedia services include high-resolution videos and have very large file sizes that require a high level of compression to overcome this limitation. Therefore, there is an acute demand for the research community to provide an efficient multimedia framework to encode medical videos with high quality specifically under the conditions of an error-prone environment. Both an affordable delivery framework and effective coding techniques are extremely desirable for the delivery of high-quality eHealth video applications for transmission over heterogeneous networks and devices. In this paper, we propose and demonstrate a multimedia framework to support eHealth applications, which has an improved coding scheme that uses an SVC-scalable extension of MPEC-4 AVC/H.264. Simulation results show that the proposed scheme achieves a significant improvement in terms of the PSNR-Y gain and reduces the picture quality degradation caused by artifacts and distortions, compared to the existing scheme.
C1 [Shoaib, Muhammad] King Saud Univ, Coll Comp & Informat Sci, Dept Informat Syst, CPMC, Riyadh, Saudi Arabia.
   [Ahmad, Uzair] King Saud Univ, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
   [Al-Amri, Atif] King Saud Univ, Coll Comp & Informat Sci, Dept Informat Syst, Riyadh, Saudi Arabia.
C3 King Saud University; King Saud University; King Saud University
RP Shoaib, M (corresponding author), King Saud Univ, Coll Comp & Informat Sci, Dept Informat Syst, CPMC, Riyadh, Saudi Arabia.
EM muhshoaib@ksu.edu.sa; uahmad@ksu.edu.sa; atif@ksu.edu.sa
RI Shoaib, Muhammad/F-8861-2011; Alamri, Atif/KFQ-0028-2024
OI Shoaib, Muhammad/0000-0002-0051-6803; Alamri, Atif/0000-0002-1887-5193
FU Research Center in College of Computer and information Sciences at King
   Saud University [RC121233]
FX The authors extend their appreciation to the Research Center in College
   of Computer and information Sciences at King Saud University for funding
   this work through Proposal No.: RC121233.
CR Amon P, 2007, IEEE T CIRC SYST VID, V17, P1174, DOI 10.1109/TCSVT.2007.905521
   [Anonymous], MRI LUNG ECH SEQ SPR
   [Anonymous], JVT H 264 SVC REF SO
   [Anonymous], WORLD WIR MOB MULT N
   BOYCE JM, 1998, P ACM MULT 98 BRIST
   Cui Yu-'bin, 2007, Journal of Beijing University of Posts and Telecommunications, V30, P55
   DICOM, 2011, MPEC 4 AVC H 264 TRA
   Digital Imaging and Communications in Medicine (DICOM), 2008, NEMA PUBL
   Huang YM, 2009, IEEE J SEL AREA COMM, V27, P400, DOI 10.1109/JSAC.2009.090505
   ISTEPANIAN RSH, 2003, P 25 ANN INT C IEEE
   Kim DK, 2009, J TELEMED TELECARE, V15, P102, DOI 10.1258/jtt.2008.080713
   Li H, 2006, IEEE T CIRC SYST VID, V16, P889, DOI 10.1109/TCSVT.2006.877404
   Nazir F, 2012, H 264 SVC MED VIDEOS
   Nkosi M. T., 2010, Proceedings of the 2010 IEEE 2nd International Conference on Cloud Computing Technology and Science (CloudCom 2010), P629, DOI 10.1109/CloudCom.2010.31
   Onguru O, 2000, PATHOL ONCOL RES, V6
   Pattichis CS, 2002, IEEE ANTENN PROPAG M, V44, P143, DOI 10.1109/MAP.2002.1003651
   PEREDNIA DA, 1995, JAMA-J AM MED ASSOC, V273, P483, DOI 10.1001/jama.273.6.483
   Pereira O, 2011, MOBILE NETW APPL, V16, P713, DOI 10.1007/s11036-010-0278-y
   Reichel J, 2006, P ISO IEC JTCI SC29
   Schierl T, 2006, IEEE WIREL COMMUN, V13, P96, DOI 10.1109/WC-M.2006.250365
   Schierl Thomas., 2007, IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY, V17
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Shoaib M, 2010, I C WIREL COMM NETW
   Singh IP, 2008, 2008 10TH IEEE INTERNATIONAL CONFERENCE ON E-HEALTH NETWORKING, APPLICATIONS AND SERVICES, P1, DOI 10.1109/HEALTH.2008.4600098
   Soomro A., 2011, 2011 IEEE 13th International Conference on e-Health Networking, Applications and Services (Healthcom 2011), P70, DOI 10.1109/HEALTH.2011.6026789
   Su MJ, 2008, TELEMED J E-HEALTH, V14, P816, DOI 10.1089/tmj.2008.0076
   Tachakra S, 2003, TELEMED J E-HEALTH, V9, P247, DOI 10.1089/153056203322502632
   Wang X, 2007, P ISO IEC JTC1 SC29
   Wang X, 2006, P ISO IEC JTC1 SC29
   Wang Y-K, 2007, IEEE T CIRC SYST VID, V17
   Wenger S., 1999, VCEGQ15I16R1 TU BERL
   Wien M, 2007, IEEE T CIRC SYST VID, V17
   Wu D, 2005, IEEE T CIRC SYST VID, V15, P953, DOI 10.1109/TCSVT.2005.848304
   Yao WB, 2002, 6TH WORLD MULTICONFERENCE ON SYSTEMICS, CYBERNETICS AND INFORMATICS, VOL XV, PROCEEDINGS, P138
   Yu SS, 2008, 2008 10TH IEEE INTERNATIONAL CONFERENCE ON E-HEALTH NETWORKING, APPLICATIONS AND SERVICES, P51, DOI 10.1109/HEALTH.2008.4600109
   Zhou L, 2010, IEEE J SEL AREA COMM, V28, P409, DOI 10.1109/JSAC.2010.100412
   Ziviani A, 2005, MULTIMED TOOLS APPL, V26, P59, DOI 10.1007/s11042-005-6849-4
NR 38
TC 5
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 2081
EP 2101
DI 10.1007/s11042-013-1631-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200044
DA 2024-07-18
ER

PT J
AU Fu, HY
   Ma, HD
   Xiao, HT
AF Fu, Huiyuan
   Ma, Huadong
   Xiao, Hongtian
TI Scene-adaptive accurate and fast vertical crowd counting via joint using
   depth and color information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal joint multimedia processing; Crowd counting; Ordinary depth
   camera; Scene-adaptive scheme; Real time system
ID PEDESTRIAN DETECTION
AB Reliable and real-time crowd counting is one of the most important tasks in intelligent visual surveillance systems. Most previous works only count passing people based on color information. Owing to the restrictions of color information influences themselves for multimedia processing, they will be affected inevitably by the unpredictable complex environments (e.g. illumination, occlusion, and shadow). To overcome this bottleneck, we propose a new algorithm by multimodal joint information processing for crowd counting. In our method, we use color and depth information together with a ordinary depth camera (e.g. Microsoft Kinect). Specifically, we first detect each head of the passing or still person in the surveillance region with adaptive modulation ability to varying scenes on depth information. Then, we track and count each detected head on color information. The characteristic advantage of our algorithm is that it is scene adaptive, which means the algorithm can be applied into all kinds of different scenes directly without additional conditions. Based on the proposed approach, we have built a practical system for robust and fast crowd counting facing complicated scenes. Extensive experimental results show the effectiveness of our proposed method.
C1 [Fu, Huiyuan; Ma, Huadong; Xiao, Hongtian] Beijing Univ Posts & Telecommun, Beijing Key Lab Intelligent Telecommun Software &, Beijing 100088, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Ma, HD (corresponding author), Beijing Univ Posts & Telecommun, Beijing Key Lab Intelligent Telecommun Software &, Beijing 100088, Peoples R China.
EM mhd@bupt.edu.cn
FU China National Funds for Distinguished Young Scientists [60925010];
   Natural Science Foundation of China [61272517]; Research Fund for the
   Doctoral Program of Higher Education of China [20120005130002]; Beijing
   Committee of Education; Funds for Creative Research Groups of China
   [61121001]; Program for Changjiang Scholars and Innovative Research Team
   in University [IRT1049]
FX This work was supported by the China National Funds for Distinguished
   Young Scientists under Grant No.60925010, Natural Science Foundation of
   China under Grant No.61272517, The Research Fund for the Doctoral
   Program of Higher Education of China under Grant No.20120005130002, the
   Co-sponsored Project of Beijing Committee of Education, the Funds for
   Creative Research Groups of China under Grant No. 61121001, and the
   Program for Changjiang Scholars and Innovative Research Team in
   University under Grant No. IRT1049.
CR [Anonymous], IEEE INTERNATIONAL C
   Antic B, 2009, IEEE IMAGE PROC, P2565, DOI 10.1109/ICIP.2009.5414001
   Antoniou C, 2007, IEEE T INTELL TRANSP, V8, P661, DOI 10.1109/TITS.2007.908569
   Bouaynaya N, 2009, IEEE T CIRC SYST VID, V19, P1068, DOI 10.1109/TCSVT.2009.2020477
   Chateau T., 2006, WORKSHOP DYNAMICAL V, P218
   Cong Y, 2009, PROC CVPR IEEE, P1093, DOI 10.1109/CVPRW.2009.5206648
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollár P, 2009, PROC CVPR IEEE, P304, DOI 10.1109/CVPRW.2009.5206631
   Gavrila DM, 2007, INT J COMPUT VISION, V73, P41, DOI 10.1007/s11263-006-9038-7
   Huiyuan Fu, 2011, Proceedings of the 2011 Seventh International Conference on Mobile Ad-hoc and Sensor Networks (MSN 2011), P91, DOI 10.1109/MSN.2011.84
   Kai X, 2010, IEEE T SYST MAN CY A, V40, P399, DOI 10.1109/TSMCA.2009.2034836
   Kilambi P, 2008, COMPUT VIS IMAGE UND, V110, P43, DOI 10.1016/j.cviu.2007.02.003
   Ma HD, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2089094.2089107
   Mikolajczyk K, 2004, LECT NOTES COMPUT SC, V3021, P69
   Mu Y., 2008, IEEE C COMPUTER VISI, P1
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75
   Velipasalar S, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1265, DOI 10.1109/ICME.2006.262768
NR 18
TC 17
Z9 22
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 1
BP 273
EP 289
DI 10.1007/s11042-013-1608-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AP9RX
UT WOS:000342418700014
DA 2024-07-18
ER

PT J
AU Kusama, K
   Itoh, T
AF Kusama, Kaori
   Itoh, Takayuki
TI Abstract picture generation and zooming user interface for intuitive
   music browsing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Musical feature; Clustering; Abstract picture; Zooming user interface
AB Today many people store music media files in personal computers or portable audio players, thanks to recent evolution of multimedia technologies. The more music media files these devices store, the messier it is to search for tunes that users want to listen to. We propose MusCat, a music browser to interactively search for the tunes according to features, not according to metadata (e. g. title, artist name). The technique firstly calculates features of tunes, and then hierarchically clusters the tunes according to the features. It then automatically generates abstract pictures, so that users can recognize characteristics of tunes more instantly and intuitionally. It finally visualizes the tunes by using abstract pictures. MusCat enables intuitive music selection with the zooming user interface.
C1 [Kusama, Kaori; Itoh, Takayuki] Ochanomizu Univ, Bunkyo Ku, Tokyo 1128610, Japan.
C3 Ochanomizu University
RP Itoh, T (corresponding author), Ochanomizu Univ, Bunkyo Ku, 2-1-1 Ohtsuka, Tokyo 1128610, Japan.
EM itot@is.ocha.ac.jp; kaori@itolab.is.ocha.ac.jp
CR Gomi A, 2008, IEEE INT CONF INF VI, P82, DOI 10.1109/IV.2008.8
   Goto M., 2005, P ISMIR, P404
   Kobayashi S, 2001, COLOR SYSTEM
   Kolhoff P, 2006, SIBGRAPI, P289
   Lamere P., 2007, Proceedings of the International Conference on Music Information Retrieval, P173
   Lartillot O, 2011, MIRTOOLBOX
   Oda M., 2007, MIST MUSIC ICON SELE
   Shiizuka H., 2008, J KANSEI ENG, V7, P659
NR 8
TC 1
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 2
BP 995
EP 1010
DI 10.1007/s11042-012-1108-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AQ8MX
UT WOS:000343080700023
DA 2024-07-18
ER

PT J
AU Sun, L
   Song, ML
   Tao, DP
   Bu, JJ
   Chen, C
AF Sun, Li
   Song, Mingli
   Tao, Dapeng
   Bu, Jiajun
   Chen, Chun
TI Motionlet LLC coding for discriminative human pose estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pose estimation; Multimodality; Motionlet; LLC coding; Multiview
ID TRACKING
AB 3D human pose estimation is a challenging but important research topic with abundant applications. As for discriminative human pose estimation, the main goal is to learn a nonlinear mapping from image descriptors to 3D human pose configurations, which is difficult due to the high-dimensionality of human pose space and the multimodality of the distribution. To address these problems, we propose a novel motionlet LLC coding in a discriminative framework. A motionlet consists of training examples covering a local area in terms of image space, pose space and time stream. We first group most informative and helpful training examples into motionlets, then perform LLC Coding to learn the nonlinear mapping and get candidate poses, and finally choose the most appropriate pose as the result estimate. To further eliminate ambiguities and improve robustness, we extend our framework to incorporate multiviews. We conduct qualitative evaluation on our Taichi data set and quantitative evaluation on HumanEva data set, which show that our approach has gained the-state-of-the-art performance and significant improvement against previous approaches.
C1 [Sun, Li; Song, Mingli; Bu, Jiajun; Chen, Chun] Zhejiang Univ, Coll Comp Sci, Zhejiang Prov Key Lab Serv Robot, Hangzhou 310027, Zhejiang, Peoples R China.
   [Tao, Dapeng] S China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510640, Guangdong, Peoples R China.
C3 Zhejiang University; South China University of Technology
RP Sun, L (corresponding author), Zhejiang Univ, Coll Comp Sci, Zhejiang Prov Key Lab Serv Robot, Hangzhou 310027, Zhejiang, Peoples R China.
EM lsun@zju.edu.cn; brooksong@zju.edu.cn; dapeng.tao@gmail.com;
   bjj@zju.edu.cn; chenc@zju.edu.cn
RI Tao, Dapeng/E-8649-2013
OI Tao, Dapeng/0000-0003-0783-5273
FU National Natural Science Foundation of China [61170142]; National Key
   Technology RD Program [2011BAG05B04]; International Science & Technology
   Cooperation Program of China [2013DFG12840]; Fundamental Research Funds
   for the Central Universities
FX This work was supported in part by National Natural Science Foundation
   of China (61170142), National Key Technology R&D Program (2011BAG05B04),
   International Science & Technology Cooperation Program of China
   (2013DFG12840), and the Fundamental Research Funds for the Central
   Universities.
CR Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21
   Agarwal A., 2004, CVPR
   [Anonymous], NIPS
   [Anonymous], 2005, CVPR
   [Anonymous], 2003, ICCV
   [Anonymous], 2006, 2006 IEEE COMP SOC C
   [Anonymous], 2006, CS0608 BROWN U
   [Anonymous], 2011, CVPR
   [Anonymous], CVPR
   [Anonymous], ACCV
   [Anonymous], 2005, CVPR
   [Anonymous], 2004, CVPR
   Bo L, 2010, CVPR
   Duan K, 2012, MULTILAYER COMPOSITE
   Elgammal A, 2007, COMPUT VIS IMAGE UND, V106, P31, DOI 10.1016/j.cviu.2005.09.010
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   FERGIE M, 2010, BMVC
   Grauman K., 2003, ICCV
   Howe NR, 2007, IMAGE VISION COMPUT, V25, P331, DOI 10.1016/j.imavis.2005.10.006
   Jinjun W, 2010, CVPR
   Kanaujia A., 2007, CVPR
   Lee M.W., 2004, ECCV
   Ning H., 2008, CVPR, P1
   Ong EJ, 2006, COMPUT VIS IMAGE UND, V104, P178, DOI 10.1016/j.cviu.2006.08.004
   Poppe RW, 2007, TRCTIT0772 U TWENT
   Rosales R., 2002, NIPS
   Sapp B., 2010, ECCV
   Song ML, 2010, IEEE T SYST MAN CY B, V40, P1460, DOI 10.1109/TSMCB.2010.2040078
   Song ML, 2010, IEEE T SYST MAN CY B, V40, P779, DOI 10.1109/TSMCB.2009.2029076
   Stenger B, 2006, IEEE T PATTERN ANAL, V28, P1372, DOI 10.1109/TPAMI.2006.189
   Sun L, 2012, PCM
   Zhao X, 2009, ACCV
   Zhao X, 2008, CVPR
   Zhao X, 2011, IEEE T IMAGE PROCESS, V20, P1141, DOI 10.1109/TIP.2010.2076820
NR 34
TC 5
Z9 5
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 1
BP 327
EP 344
DI 10.1007/s11042-013-1617-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AP9RX
UT WOS:000342418700017
DA 2024-07-18
ER

PT J
AU Ivankovic, Z
   Rackovic, M
   Ivkovic, M
AF Ivankovic, Zdravko
   Rackovic, Milos
   Ivkovic, Miodrag
TI Automatic player position detection in basketball games
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Player detection; Position estimation; Latent SVM; Pictorial structures
AB This paper presents us with a framework for the automatic player position detection (APPD) in the game of basketball. Court players are detected in the images broadcasted via television stations. In them, at any point of time, the view is from only one camera. This makes the detection process much more difficult. The player detection is based on the mixture of non-oriented pictorial structures. The detection of body parts is performed by the Support Vector Machine (SVM) algorithm. The results of these detections are combined together with constraints on their locations, which specify the position of one body part with respect to the parent body part. In order to train the whole model, we used a latent form of SVM called the latent SVM (LSVM). Such approach generated the statistical accuracy of about 82 %, which represents one of the best results in basketball player detection framework. Beside players, the algorithm detected a certain number of false positive objects. These are mostly people from the audience and the referees as well. This paper contains a simple and robust solution to remove them all, based on the play court boundaries and the histogram comparison. Separating players in different teams is done by k-means clustering. The inputs to this algorithm are saturation histograms calculated on the jerseys. A spatial transformation is determined by the detected play court boundaries and the actual court measures. Using this transformation, points representing the location of detected players in TV images are mapped to the actual location of players on the court, which was the main goal of our research. The proposed solution is sound and efficient. In addition, it is backed up by the experimental results obtained using the model of the actual footage of basketball games.
C1 [Ivankovic, Zdravko; Ivkovic, Miodrag] Univ Novi Sad, Tech Fac Mihajlo Pupin, Djure Djakovica BB, Zrenjanin 23000, Serbia.
   [Rackovic, Milos] Univ Novi Sad, Dept Math & Informat, Fac Sci, Novi Sad 21000, Serbia.
C3 University of Novi Sad; University of Novi Sad
RP Ivankovic, Z (corresponding author), Univ Novi Sad, Tech Fac Mihajlo Pupin, Djure Djakovica BB, Zrenjanin 23000, Serbia.
EM zdravko.ivankovic@tfzr.rs; milos.rackovic@dmi.uns.ac.rs;
   mivkovic@tfzr.uns.ac.rs
RI Racković, Miloš/IQT-3885-2023
OI Racković, Miloš/0000-0002-0111-5059
FU Ministry of Science and Technological Development of Republic of Serbia
   [171039]; project "Infrastructure for technology enhanced learning in
   Serbia" [III47003]
FX Research was partially supported by the Ministry of Science and
   Technological Development of Republic of Serbia by Grant 171039 and
   through project no. III47003 "Infrastructure for technology enhanced
   learning in Serbia".
CR Alahi Alexandre., 2009, Third ACM/IEEE International Conference on Distributed Smart Cameras, P1, DOI DOI 10.1109/ICDSC.2009.5289406
   Amit Y, 2007, INT J COMPUT VISION, V75, P267, DOI 10.1007/s11263-006-0033-9
   Andrews Stuart, 2002, PROC 25 ANN C NEURAL, P561
   [Anonymous], 2005, Proc._Neural_Information_Processing_System
   [Anonymous], 2006, COMPUTER VISION PATT, DOI 10.1109/CVPR.2006.92
   [Anonymous], P ACM INT C MULT
   [Anonymous], EUR C COMP VIS ECCV
   Bar-Hillel A, 2008, INT J COMPUT VISION, V77, P175, DOI 10.1007/s11263-007-0091
   Bernstein E, 2005, IEEE C COMP VIS PATT
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303
   Cai Y, 2006, EUR C COMP VIS ECCV
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Coughlan J, 2000, COMPUT VIS IMAGE UND, V78, P303, DOI 10.1006/cviu.2000.0842
   Crandall D, 2005, PROC CVPR IEEE, P10
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Daniyal F, 2010, MULTIMED TOOLS APPL, V46, P235, DOI 10.1007/s11042-009-0355-z
   Ekin A, 2003, INT C IM PROC
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Fergus V, 2003, IEEE COMP SOC C COMP
   Holub A, 2005, IEEE C COMP VIS PATT
   Huang CL, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1885, DOI 10.1109/ICME.2006.262923
   Ivankovic Z, 2010, ACTA POLYTECH HUNG, V7, P167
   Jiang XH, 2011, COMPUT SCI INF SYST, V8, P931, DOI 10.2298/CSIS100423035J
   Ke Y, 2004, PROC CVPR IEEE, P506
   Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3
   Markoski B, 2011, ACTA POLYTECH HUNG, V8, P111
   Panagiotakis C, 2008, INT J PATTERN RECOGN, V22, P1187, DOI 10.1142/S0218001408006752
   Pele O, 2010, LECT NOTES COMPUT SC, V6312, P749, DOI 10.1007/978-3-642-15552-9_54
   Perse M, 2009, COMPUT VIS IMAGE UND, V113, P612, DOI 10.1016/j.cviu.2008.03.001
   Quattoni A, 2007, IEEE T PATTERN ANAL, V29, P1848, DOI 10.1109/TPAMI.2007.1124
   Schumaker RP, 2010, INTEGR SER INFORM SY, V26, P1, DOI 10.1007/978-1-4419-6730-5
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Therón R, 2010, LECT NOTES COMPUT SC, V6133, P196, DOI 10.1007/978-3-642-13544-6_19
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wei-Lwun Lu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3249, DOI 10.1109/CVPR.2011.5995562
   Wu LF, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL II, PROCEEDINGS, P539
   Wu LF, 2014, MULTIMED TOOLS APPL, V70, P721, DOI 10.1007/s11042-012-1002-7
   Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741
   Zhu XQ, 2005, IEEE T KNOWL DATA EN, V17, P665, DOI 10.1109/TKDE.2005.83
NR 40
TC 14
Z9 16
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2741
EP 2767
DI 10.1007/s11042-013-1580-z
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300030
DA 2024-07-18
ER

PT J
AU Yang, ZF
   Chiou, SS
   Lee, JT
AF Yang, Zhi-Fang
   Chiou, Shyh-Shin
   Lee, Jun-Ting
TI Watermark design based on Steiner triple systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermark design; Steiner triple system
ID LDPC CODES; EMBEDDINGS
AB Constructing a set of watermarks of a specific structure may be one requirement for robust watermarking. This study aims to use the structure of Steiner triple systems to generate new watermarks. That is, the new watermark is a Steiner triple system built by using two smaller ones. The structure properties are examined to recognize watermarks at the receiver site. The main advantage is no information other than the mathematical structure has to be known for watermark recognition.Theoretical proof is given to verify the proposed watermark design method, and the experiment is conducted to confirm the theoretical behavior of the generated watermarks under random noise.
C1 [Yang, Zhi-Fang; Chiou, Shyh-Shin; Lee, Jun-Ting] Natl Taipei Univ, Dept Comp Sci & Informat Engn, Taipei 237, Taiwan.
C3 National Taipei University
RP Yang, ZF (corresponding author), Natl Taipei Univ, Dept Comp Sci & Informat Engn, Taipei 237, Taiwan.
EM zfyang@mail.ntpu.edu.tw
RI Yin, Jing/KDO-6274-2024
CR [Anonymous], 1996, The CRC Handbook of Combinatorial Designs, CRC Press Series on Discrete Mathematics and its Applications
   [Anonymous], 1963, Combinatorial Mathematics
   Basu A, 2005, IEEE INT C IM PROC 2
   Bryant D, 2012, J COMB THEORY A, V119, P283, DOI 10.1016/j.jcta.2011.09.008
   Bryant D, 2009, J COMB DES, V17, P63, DOI 10.1002/jcd.20189
   Çamtepe SA, 2007, IEEE ACM T NETWORK, V15, P346, DOI 10.1109/TNET.2007.892879
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Dinitz J, 1992, CONT DESIGN THEORY C, P1
   Djordjevic IB, 2008, IEEE COMMUN LETT, V12, P389, DOI 10.1109/LCOMM.2008.080083
   Donovan DM, 2011, J COMB DES, V19, P16, DOI 10.1002/jcd.20258
   Gersting JL, 2006, MATH STRUCTURES COMP
   Guerrini F, 2011, IEEE T INF FOREN SEC, V6, P283, DOI 10.1109/TIFS.2011.2109383
   Hu HT, 2012, SIGNAL PROCESS, V92, P1109, DOI 10.1016/j.sigpro.2011.11.001
   Kang IK, 2005, IEEE INT SYMP CIRC S, P5529
   Kovalevskaya DI, 2013, J APPL IND MATH, V7, P68
   Lan L, 2008, IEEE T COMMUN, V56, P39, DOI 10.1109/TCOMM.2008.050483
   Liutkus A, 2012, SIGNAL PROCESS, V92, P1937, DOI 10.1016/j.sigpro.2011.09.016
   Östergård PRJ, 2010, IEEE T INFORM THEORY, V56, P2571, DOI 10.1109/TIT.2010.2046197
   Patel A, 2011, IEEE T SIGNAL PROCES, V59, P488, DOI 10.1109/TSP.2010.2091409
   Petitcolas FAP, 1998, LECT NOTES COMPUT SC, V1525, P218
   Sadasivam S, 2011, IEEE T INF FOREN SEC, V6, P894, DOI 10.1109/TIFS.2011.2129511
   Trappe W, 2003, IEEE T SIGNAL PROCES, V51, P1069, DOI 10.1109/TSP.2003.809378
   Tsai JS, 2012, SIGNAL PROCESS, V92, P1431, DOI 10.1016/j.sigpro.2011.11.033
   Wang JW, 2012, SIGNAL PROCESS, V92, P893, DOI 10.1016/j.sigpro.2011.09.029
   Wang KH, 2012, SIGNAL PROCESS, V92, P2888, DOI 10.1016/j.sigpro.2012.05.020
   Yang J, 2004, 2004 7TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS 1-3, P2600
   Yang J, 2006, 8 INT C SIGN PROC GU, P16
   Yang ZF, 2006, 2006 INT COMP S TAW
   Yang ZF, 2006, 9 INT S WIR PERS MUL
   Yang ZF, 2008, ISDA 2008: EIGHTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 3, PROCEEDINGS, P179, DOI 10.1109/ISDA.2008.169
   Yeh BC, 2010, J OPT COMMUN NETW, V2, P653, DOI 10.1364/JOCN.2.000653
   Zhang H, 2011, IEEE T IMAGE PROCESS, V20, P2189, DOI 10.1109/TIP.2011.2118216
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P1223, DOI 10.1109/TIFS.2011.2159208
   Zhi-Fang Yang, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P332, DOI 10.1109/IIH-MSP.2009.254
NR 34
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2177
EP 2194
DI 10.1007/s11042-013-1513-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300006
DA 2024-07-18
ER

PT J
AU González, C
   Sotoca, JM
   Pla, F
   Chover, M
AF Gonzalez, Carlos
   Martinez Sotoca, Jose
   Pla, Filiberto
   Chover, Miguel
TI Synthetic content generation for auto-stereoscopic displays
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Auto-stereoscopic displays; Virtual reality; Interactive visualization;
   Multimedia applications
AB Due to the appearance of auto-stereoscopic visualization as one of the most emerging tendencies used in displays, new content generation techniques for this kind of visualization are required. In this paper we present a study for the generation of multi-view synthetic content, studying several camera setups (planar, cylindrical and hyperbolic) and their configurations. We discuss the different effects obtained varying the parameters of these setups. A study with several users was made to analyze visual perceptions, asking them for their optimal visualization. To create the virtual content, a multi-view system has been integrated in a powerful game engine, which allows us to use the latest graphics hardware advances. This integration is detailed and several demos and videos are attached with this paper, which represent a virtual world for auto-stereoscopic displays and the same scenario in a two-view anaglyph representation for being visualized in any conventional display. In all these demos, the parameters studied can be modified offering the possibility of easily appreciate their effects in a virtual scene.
C1 [Gonzalez, Carlos; Martinez Sotoca, Jose; Pla, Filiberto; Chover, Miguel] Univ Jaume 1, Inst New Imaging Technol, Castellon de La Plana 12071, Spain.
C3 Universitat Jaume I
RP González, C (corresponding author), Univ Jaume 1, Inst New Imaging Technol, Avda Sos Baynat S-N, Castellon de La Plana 12071, Spain.
EM carlos.gonzalez@uji.es; sotoca@uji.es; pla@uji.es; chover@uji.es
RI Pla, Filiberto/AAD-1208-2022; Sotoca, José JMS Martínez/T-3663-2017;
   Chover Sellés, Miguel/P-9933-2018
OI Pla, Filiberto/0000-0003-0054-3489; Chover Sellés,
   Miguel/0000-0002-0525-7038
FU Spanish Ministry of Education and Science [TIN2009-14103-C03-01]; Caja
   Castellon-Bancaja Foundation [P1.1B2009-45]; Generalitat Valenciana
   [PROMETEO/2010/028, BEST/2011]; Consolider Ingenio [CSD2007-00018]
FX This work has been supported by the Spanish Ministry of Education and
   Science (TIN2009-14103-C03-01), Caja Castellon-Bancaja Foundation
   (P1.1B2009-45), Generalitat Valenciana (Project PROMETEO/2010/028,
   BEST/2011) and Consolider Ingenio 2010 (CSD2007-00018).
CR [Anonymous], P VIIP 03 BEN SPAIN
   [Anonymous], 2012, AUT 3D TV
   [Anonymous], 2012, UNITY GAME DEV TOOL
   Chen HJ, 2010, IEEE INT SYMP CIRC S, P1165, DOI 10.1109/ISCAS.2010.5537312
   Cheng X, 2007, IEEE INT C IM PROC I, P225
   DeCoro C, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P161
   Dodgson NA, 2002, P SOC PHOTO-OPT INS, V4660, P254, DOI 10.1117/12.468040
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   Gumbau J, 2010, GPU PRO 7
   Gumbau J, 2008, GRAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS, P62
   Hang Fu, 2012, 2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet), P1569, DOI 10.1109/CECNet.2012.6201711
   Horn DR, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P121
   Hubner Thomas, 2007, IADIS International Conference. Computer Graphics and Visualization 2007, P50
   Järvenpää T, 2008, J SOC INF DISPLAY, V16, P825, DOI 10.1889/1.2966444
   Jin ZX, 2007, LECT NOTES COMPUT SC, V4551, P605
   Juan MC, 2010, COMPUT GRAPH-UK, V34, P756, DOI 10.1016/j.cag.2010.08.001
   Lambooij M, 2009, J IMAGING SCI TECHN, V53, DOI 10.2352/J.ImagingSci.Technol.2009.53.3.030201
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Luo JL, 2010, INT CONF COMP SCI, P28, DOI 10.1109/ICCSIT.2010.5564554
   Luo JL, 2010, VISUAL COMPUT, V26, P457, DOI 10.1007/s00371-010-0479-1
   Marbach J, 2009, 16 ACM S VIRT REAL S, P103
   Matusik W, 2004, ACM T GRAPHIC, V23, P814, DOI 10.1145/1015706.1015805
   Mendiburu Bernard., 2009, 3D Movie Making: Stereoscopic Digital Cinema From Scrip to Screen
   Miksicek F, 2006, DCSETR200604 U W BOH
   Okoshi T, 2010, 3 DIMENSIONAL IMAGIN
   Park JU, 2006, IDW '06: PROCEEDINGS OF THE 13TH INTERNATIONAL DISPLAY WORKSHOPS, VOLS 1-3, P1365
   Salmimala M, 2008, SID INT SYMP DIG TEC, V39, P267, DOI 10.1889/1.3069642
   Saygili G, 2009, IEEE IMAGE PROC, P717, DOI 10.1109/ICIP.2009.5414317
   Shum H., 2007, IMAGE BASED RENDERIN
   Son JY, 2004, APPL OPTICS, V43, P4985, DOI 10.1364/AO.43.004985
   Sorbier F, 2008, 4 INT S 3D DAT PROC
   Sorbier F, 2008, 16 INT C CENTR EUR C
   Stendel D, 2009, COORP 2009 COMPETENE
   Stendel D, 2009, COORP 2009 COMPETENC
   Strecha C., 2008, 2008 IEEE Conference on Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2008.4587706
   van Berkel C, 1999, P SOC PHOTO-OPT INS, V3639, P84, DOI 10.1117/12.349368
   Zhang L, 2005, IEEE T BROADCAST, V51, P191, DOI 10.1109/TBC.2005.846190
NR 38
TC 2
Z9 2
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 385
EP 415
DI 10.1007/s11042-012-1348-x
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800018
OA Green Published
DA 2024-07-18
ER

PT J
AU Li, ZM
   Wu, ZJ
   Kuang, ZZ
   Chen, K
   Gan, YZ
   Fan, JP
AF Li, Zongmin
   Wu, Zijian
   Kuang, Zhenzhong
   Chen, Kai
   Gan, Yongzhou
   Fan, Jianping
TI Evidence-based SVM fusion for 3D model retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D model retrieval; Evidence theory; Classifier fusion; Classification
AB Many existing 3D model retrieval use KNN (k-nearest neighbor) method for similarity search, but it is inefficient in high-dimension space search. In this paper, the classification tools are integrated for supporting more effective 3D model search in the high-dimensional feature space. Our proposed algorithm used multiple SVM classifiers to predict 3D models for a given query and D-S Evidence theory is used to fuse all the prediction results. Experimental results show that our proposed 3D model retrieval algorithm can improve the accuracy significantly compared with the traditional kNN method.
C1 [Li, Zongmin; Wu, Zijian; Kuang, Zhenzhong; Chen, Kai; Gan, Yongzhou] China Univ Petr, Coll Comp & Commun Engn, Qingdao 266555, Shandong, Peoples R China.
   [Fan, Jianping] UNC Charlotte, Dept Comp Sci, Charlotte, NC 28223 USA.
C3 China University of Petroleum; University of North Carolina; University
   of North Carolina Charlotte
RP Kuang, ZZ (corresponding author), China Univ Petr, Coll Comp & Commun Engn, Qingdao 266555, Shandong, Peoples R China.
EM 459679143@qq.com
FU National Natural Science Foundation of China [60873164]; National
   High-Tech RD Plan [2009AA062802]; Shandong Provincial Natural Science
   Foundation [ZR2009GL014]; Scientific Research Foundation for the
   Excellent Middle-Aged and Youth Scientists of Shandong Province of China
   [BS2010DX037]; Ministry of Culture Science and Technology Innovation
   Project [46-2010]; Fundamental Research Funds for the Central
   Universities [09CX04044A, 10CX04043A, 10CX04014B]
FX This work is partly supported by National Natural Science Foundation of
   China (Grant No.60873164), National High-Tech R&D Plan (Grant No.
   2009AA062802), the Shandong Provincial Natural Science Foundation(Grant
   No.ZR2009GL014), the Scientific Research Foundation for the Excellent
   Middle-Aged and Youth Scientists of Shandong Province of China (Grant
   No.BS2010DX037), Ministry of Culture Science and Technology Innovation
   Project(Grant No. 46-2010), the Fundamental Research Funds for the
   Central Universities(Grant No. 09CX04044A, 10CX04043A, 10CX04014B)
CR Agathos A., 2009, 3DOR, P29
   [Anonymous], 2003, INT J IMAGE GRAPH
   [Anonymous], ADV LARGE MARGIN CLA
   [Anonymous], 2008, EUR WORKSH 3D OBJ RE
   Basir O, 2005, IEEE T NEURAL NETWOR, V16, P1513, DOI 10.1109/TNN.2005.853337
   Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361
   Dutagaci H., 2011, 4 EUR WORKSH 3D OBJ
   Elad M, 2001, EUR WORKSH MULT
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169
   Kazhdan M., 2003, Symposium on Geometry Processing, P156
   Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27
   Lian ZH, 2010, INT C SHAP MOD
   Mémoli F, 2005, FOUND COMPUT MATH, V5, P313, DOI 10.1007/s10208-004-0145-y
   Novotni M., 2003, P 8 ACM S SOL MOD AP, P216, DOI DOI 10.1145/781606.781639
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Paquet E, 2000, SIGNAL PROCESS-IMAGE, V16, P103, DOI 10.1016/S0923-5965(00)00020-5
   Pu JT, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P95, DOI 10.1109/TDPVT.2004.1335181
   Qu DC, 2004, 2004 7TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS 1-3, P46
   Rodríguez JJ, 2006, IEEE T PATTERN ANAL, V28, P1619, DOI 10.1109/TPAMI.2006.211
   Rustemeyer R., 2009, ENZYKLOPADIE ERZIEHU, P1
   SATISH L, 1993, IEEE T ELECTR INSUL, V28, P172, DOI 10.1109/14.212242
   Suziki M.T., 2001, Proc. International World Wide Web Conference Poster, P182
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Vranic DV, 2003, INT C IM PROC
   Zhang C, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P935, DOI 10.1109/ICIP.2001.958278
   Zhang X.G., 2000, ACTA AUTOMATICA SINICA, V26, P32, DOI DOI 10.16383/J.AAS.2000.01.005
NR 30
TC 5
Z9 8
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1731
EP 1749
DI 10.1007/s11042-013-1475-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300031
DA 2024-07-18
ER

PT J
AU Pei, LS
   Ye, M
   Xu, P
   Zhao, XZ
   Guo, GJ
AF Pei, Lishen
   Ye, Mao
   Xu, Pei
   Zhao, Xuezhuan
   Guo, Guanjun
TI One example based action detection in hough space
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action detection; Hough voting; Displacement histogram; Matrix cosine
   similarity
AB Given a short action query video, to detect the same category action in a target video is a very important research topic. We propose a fast action detection method motivated by the idea of Hough Transformation. First, we extract the HOG features at the corner points from the query video. The corner points are referred to as interest points. Then, video clips are formed by sliding a window on the query video. For each T frames of a clip, in the displacement Hough space, the interest points in all of the frames are matched with the interest points in the first frame. We count the matched pairs in the cells of the Hough space to form a 2d displacement histogram. The query video is represented by a 2d displacement histogram sequence. After that, we divide the target video with motion into video cubes. These video cubes are similarly represented by displacement histogram sequences. The matrix cosine similarity is used to compute the similarities between the query video and the video cubes. This process is referred to as action matching. In the end, with the action matching results, we precisely localize the action using the locations of the matched interest points. Our key contribution is that we propose a very simple and fast algorithm that represents the actions as the displacement histogram sequences. Experiments on the challenging datasets containing both of the simple and realistic backgrounds confirm the effectiveness and efficiency of our method.
C1 [Pei, Lishen; Ye, Mao; Xu, Pei; Guo, Guanjun] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Peoples R China.
   [Zhao, Xuezhuan] Chinese Acad Sci, Chengdu Inst Comp Applicat, Chengdu 610041, Peoples R China.
C3 University of Electronic Science & Technology of China; Chengdu
   Institute of Computer Application, CAS; Chinese Academy of Sciences
RP Pei, LS (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Peoples R China.
EM pls.cvlab@gmail.com; yem_mei29@hotmail.com; xupei268@gmail.com;
   samkuok87@gmail.com; xuezhuanscience@gmail.com
RI Ye, Mao/K-3012-2019
OI Ye, Mao/0000-0001-9253-1332; Ye, Mao/0000-0003-4760-8702
FU 973 National Basic Research Program of China [2010CB732501]; Fundation
   of Sichuan Excellent Young Talents [09ZQ026-035]; Fundamental Research
   Funds for the Central University
FX This work is supported in part by the 973 National Basic Research
   Program of China (2010CB732501), Fundation of Sichuan Excellent Young
   Talents (09ZQ026-035) and the Fundamental Research Funds for the Central
   University.
CR Ali S, 2010, IEEE T PATTERN ANAL, V32, P288, DOI 10.1109/TPAMI.2008.284
   [Anonymous], P ACM MULT C
   [Anonymous], 2008, P IEEE C COMP VIS PA
   [Anonymous], 2008, P IEEE C COMP VIS PA
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 1998, J COMPUT VIS RES
   [Anonymous], 2005, P IEEE C COMP VIS PA
   [Anonymous], 2009, P IEEE C COMP VIS PA
   [Anonymous], 2008, IEEE C COMP VIS PATT
   Bobick AF, 2007, IEEE T PATTERN ANAL, V23, P1257
   CHEUNG KM, 2003, P IEEE C COMP VIS PA
   Dalal N., CVPR, P886, DOI [DOI 10.1109/CVPR.2005.177, 10.1109/CVPR.2005.177]
   Fu Y, 2008, IEEE T IMAGE PROCESS, V17, P226, DOI 10.1109/TIP.2007.914203
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Ikizler-Cinbis N, 2009, P IEEE C COMP VIS
   Jiang ZL, 2012, IEEE T PATTERN ANAL, V34, P533, DOI 10.1109/TPAMI.2011.147
   Ke Y., 2005, P IEEE C COMP VIS PA
   Kim TK, 2009, IEEE T PATTERN ANAL, V31, P1415, DOI 10.1109/TPAMI.2008.167
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Laptev I., 2007, P IEEE C COMP VIS
   Liu J., 2008, P IEEE C COMP VIS PA
   MAHMOOD TS, 2001, P IEEE WORKSH DET RE
   MN Y, 2007, P IEEE C COMP VIS
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Ning HZ, 2009, IEEE T CIRC SYST VID, V19, P808, DOI 10.1109/TCSVT.2009.2017399
   Oikonomopoulous A, 2005, P IEEE C MULT EXP
   Seo HJ, 2011, IEEE T PATTERN ANAL, V33, P867, DOI 10.1109/TPAMI.2010.156
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Shechtman E, 2007, IEEE T PATTERN ANAL, V29, P2045, DOI 10.1109/TPAMI.2007.1119
   Yu G, 2011, PROC CVPR IEEE, P865, DOI 10.1109/CVPR.2011.5995488
   Yuan JS, 2009, PROC CVPR IEEE, P2442, DOI [10.1109/CVPRW.2009.5206671, 10.1109/CVPR.2009.5206671]
NR 32
TC 2
Z9 3
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1751
EP 1772
DI 10.1007/s11042-013-1478-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300032
DA 2024-07-18
ER

PT J
AU Bayraktar, DM
   Altun, A
AF Bayraktar, Duygu Mutlu
   Altun, Arif
TI The effect of multimedia design types on learners' recall performances
   with varying short term memory spans
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia learning environment; Short term memory; Split attention;
   Focused attention; Recall
ID SPLIT-ATTENTION; COGNITIVE LOAD
AB In this study, the effect of multimedia learning environment designed with two different attention types (focused - split) was investigated on recall performances of learners with different short term memory spans (high - medium - low). The participants were 60 undergraduate students who were presented with either focused attention or split attention multimedia learning materials. First, participants' short term memory spans were determined by Visual - Aural Digit Span Test-Revised (VADS-B) test. Second, they were separated to three groups as high, medium and low. In 3 x 2 nested ANOVA design, one of the groups studied the multimedia designed in split attention type whereas the other had focused attention type design. As they finished the study task, they were given a recall task, which produced their recall performances. Data were analyzed by Nested ANOVA, t-Test and ANCOVA tests. The findings indicated that multimedia instructional designs were effective on recall performances. Learners showed higher recall performances in the multimedia learning environment in focused attention design. However, no significant difference was observed in learners' recall performances when their STM spans were taken into account. Significant differences were observed between time spent in studying multimedia.
C1 [Bayraktar, Duygu Mutlu] Istanbul Univ, Fac Educ, TR-34452 Beyazit, Turkey.
   [Altun, Arif] Hacettepe Univ, Fac Educ, TR-06800 Ankara, Turkey.
C3 Istanbul University; Hacettepe University
RP Bayraktar, DM (corresponding author), Istanbul Univ, Fac Educ, Besim Omer Pasa Cd 11, TR-34452 Beyazit, Turkey.
EM dmutlu@istanbul.edu.tr
RI Mutlu Bayraktar, Duygu/D-4701-2019; Altun, Arif/AAX-9539-2021; Altun,
   Arif/B-3468-2008
OI Mutlu Bayraktar, Duygu/0000-0002-2276-3768; Altun,
   Arif/0000-0003-4060-6157
CR [Anonymous], HACETTEPE U J ED
   [Anonymous], CAMBRIDGE HDB MULTIM
   Ayres P., 2005, The Cambridge Handbook Of Multimedia Learning, Ed
   Ayres P, 2007, APPL COGNITIVE PSYCH, V21, P695, DOI 10.1002/acp.1343
   Betrancourt M., 2005, The Cambridge handbook of multimedia learning, P287, DOI [DOI 10.1017/CBO9780511816819.019, 10.1017/CBO9780511816819.019]
   Cierniak G, 2009, COMPUT HUM BEHAV, V25, P315, DOI 10.1016/j.chb.2008.12.020
   Dutke S, 2006, LEARN INSTR, V16, P526, DOI 10.1016/j.learninstruc.2006.10.002
   Fletcher J.D., 2005, CAMBRIDGE HDB MULTIM, P117, DOI DOI 10.1017/CBO9780511816819.008
   Kalyuga S, 1999, APPL COGNITIVE PSYCH, V13, P351, DOI 10.1002/(SICI)1099-0720(199908)13:4<351::AID-ACP589>3.0.CO;2-6
   KARAKAS S, 1995, TURK PSIKOL DERG, V10, P20
   Kemp JE, 1998, DESIGN EFFECTIVE INS
   Malinowski P, 2007, NEUROSCI LETT, V414, P65, DOI 10.1016/j.neulet.2006.12.001
   Mayer R. E., 2020, Multimedia Learning, V3rd
   Mayer RE, 2002, LEARN INSTR, V12, P107, DOI 10.1016/S0959-4752(01)00018-4
   Mayer RE, 1998, J EDUC PSYCHOL, V90, P312, DOI 10.1037/0022-0663.90.2.312
   Mayer RE, 2005, PSYCHOLOGY, V91, P358
   Montgomery D., 2010, Design and Analysis of Experiments
   Muller A, 2008, J COMPUT ASSIST LEAR, V24, P144, DOI 10.1111/j.1365-2729.2007.00248.x
   Norhayati AM, 2004, ED TECHNOLOGY SOC, V7, P143
   Siranovic Z, 2007, GUIDELINES DESIGNING
   Solso R., 2007, Cognitive psychology, V8
   Sorden SD, 2005, INF SCI J, V8
   Summerviller J, 1999, INT J ED TECHNOL, V1
   Sweller J, 2004, INSTR SCI, V32, P9, DOI 10.1023/B:TRUC.0000021808.72598.4d
   Sweller J., 1994, Learning and instruction, P295, DOI DOI 10.1016/0959-4752(94)90003-5
   Weinstein C.E., 1988, LEARNING STUDY STRAT
NR 26
TC 5
Z9 8
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1201
EP 1213
DI 10.1007/s11042-012-1257-z
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000011
DA 2024-07-18
ER

PT J
AU Eid, M
   El Issawi, A
   El Saddik, A
AF Eid, Mohamad
   El Issawi, Ahmad
   El Saddik, Abdulmotaleb
TI Slingshot 3D: A synchronous haptic-audio-video game
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Haptic video gaming; Multimedia haptics; Tele-haptic; Interpersonal
   communication; Human computer interaction; Natural computer interaction
AB Recent advances in multimedia and human computer interaction technologies have paved the way for rich contents across multiple media such as haptics, audio, and video. This paper introduces a multimodal game named the Slingshot 3D Game: an interactive and synchronous haptic-audio-video shooter game over the Internet network. The game incorporates two types of haptic feedback: tactile feedback using a haptic jacket and kinesthetic feedback using the Novint Falcon haptic interface. Furthermore, the game utilizes a depth camera to track the player's (upper) body movements and detect collisions between the player's body and the shot projectile. To promote availability and cost, the game uses the Internet network as the communication medium between the players, by utilizing the Admux communication framework [10]. The game design and implementation are detailed in this paper. Both the player performance analysis and the user satisfaction analysis have shown that the incorporation of synchronous haptic-video multimedia has enhanced the perception of player presence and the overall quality of performance.
C1 [Eid, Mohamad] NYUAD, Div Engn, Abu Dhabi, U Arab Emirates.
   [El Issawi, Ahmad] Lebanese Univ, Nabatieh, Lebanon.
   [El Saddik, Abdulmotaleb] Univ Ottawa, Ottawa, ON, Canada.
C3 Lebanese University; University of Ottawa
RP Eid, M (corresponding author), NYUAD, Div Engn, Abu Dhabi, U Arab Emirates.
EM mohamad.eid@nyu.edu; ahmadissawi@email.com; elsaddik@uottawa.ca
RI /D-4159-2009
OI /0000-0002-7690-8547
CR Andrews S, 2006, P FUT PLAY
   [Anonymous], 2011, Reuters
   BAILENSON JN, 2008, MULTIMEDIA TOOLS APP, V37
   Caporusso N, 2010, IEEE T INF TECHNOL B, V14, P248, DOI 10.1109/TITB.2009.2034739
   Cha J, 2009, ACM ITN C MULT MUTL
   Cha J, 2008, LECT NOTES COMPUT SC, V5024, P640
   De Paolis LT, 2007, DS-RT 2007: 11TH IEEE INTERNATIONAL SYMPOSIUM ON DISTRIBUTED SIMULATION AND REAL-TIME APPLICATIONS, PROCEEDINGS, P64
   Eid M, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON VIRTUAL ENVIRONMENTS, HUMAN-COMPUTER INTERFACES AND MEASUREMENT SYSTEMS, P5, DOI 10.1109/VECIMS.2008.4592743
   Eid M, 2011, IEEE T INSTRUM MEAS, V60, P21, DOI 10.1109/TIM.2010.2065530
   Faust M, 2006, 3 INT WORKSH EPRV GA
   Frati V., 2011, 2011 IEEE World Haptics Conference (WHC 2011), P317, DOI 10.1109/WHC.2011.5945505
   Giles Jim., 2010, New Scientist, V208, P22, DOI DOI 10.1016/S0262-4079(10)62989-2
   Gvili R., 2003, DEPTH KEYING
   Hamam A, 2008, P HPAT AMB SYST HAS
   Heo H, 2010, IEEE T CONSUM ELECTR, V56, P1364, DOI 10.1109/TCE.2010.5606271
   Jovanovic M, 2011, IEEE T SYST MAN CY A, V41, P817, DOI 10.1109/TSMCA.2011.2132711
   Khoshelham K, 2012, SENSORS-BASEL, V12, P1437, DOI 10.3390/s120201437
   MacLaverty R., 1994, proceedings of the IEEE First Workshop on Multimedia Signal Processing, P25
   Neviarouskaya Alena, 2009, 2009 ICROS-SICE International Joint Conference. ICCAS-SICE 2009, P3376
   Nilsen T., 2004, P NZGDC FUSE, V4, P86
   Park W, 2009, 2009 IEEE INTERNATIONAL WORKSHOP ON HAPTIC AUDIO VISUAL ENVIRONMENT AND GAMES, P64, DOI 10.1109/HAVE.2009.5356137
   Ryden F, 2011, ROB SCI SYST RSS WOR
   Rydén F, 2012, IEEE POTENTIALS, V31, P34, DOI 10.1109/MPOT.2012.2187110
   Teh Keng Soon, 2006, CHI 06 HUM FACT COMP, P251, DOI [10.1145/1125451.1125505, DOI 10.1145/1125451.1125505]
   Yuanqiang Dong, 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P3887, DOI 10.1109/ICRA.2011.5980310
NR 25
TC 4
Z9 5
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1635
EP 1649
DI 10.1007/s11042-012-1297-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000030
DA 2024-07-18
ER

PT J
AU Huang, ZP
   Gong, GH
   Han, L
AF Huang, Zhanpeng
   Gong, Guanghong
   Han, Liang
TI Physically-based modeling, simulation and rendering of fire for computer
   animation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fire; Physically-based simulation; Navier-Stokes equations; Chemical
   reaction; Blackbody radiation; Visual adaption
ID VISUAL SIMULATION; SMOKE; FLAMES; EQUATIONS; WATER
AB We give an up-to-date survey on techniques and methods for fire simulation in computer graphics. Physically-based method prevails over traditional non-physical methods for realistic visual effect. In this paper, we explore visual simulation of fire-related phenomena in terms of physically modeling, numerical simulation and visual rendering. Firstly, we introduce a physical and chemical coupled mathematical model to explain fire behavior and motion. Several assumptions and constrains are put forward to simplify their implementations in computer graphics. We then give an overview of present methods to solve the most complicated processes in numerical simulation: velocity advection and pressure projection. In addition, comparisons of these methods are also presented respectively. Since fire is a participating medium as well as a visual radiator, we discuss techniques and problems of these issues as well. We conclude by addressing several open challenges and possible future research directions in fire simulation.
C1 [Huang, Zhanpeng; Gong, Guanghong; Han, Liang] Beijing Univ Aeronaut & Astronaut, Sch Automat Sci & Elect Engn, Beijing 100083, Peoples R China.
C3 Beihang University
RP Huang, ZP (corresponding author), Beijing Univ Aeronaut & Astronaut, Sch Automat Sci & Elect Engn, Beijing 100083, Peoples R China.
EM soaroc@asee.buaa.edu.cn; ggh@buaa.edu.cn; hanliang@buaa.edu.cn
RI Han, Liang/KFR-6745-2024
CR [Anonymous], EUROGRAPHICS
   [Anonymous], ACM T GRAPH
   [Anonymous], THESIS
   [Anonymous], THESIS
   [Anonymous], PROCEEDINGS OF PARCF
   [Anonymous], P 2008 INT C MULT UB
   [Anonymous], FLUID SIMULATION FO
   [Anonymous], PROCEEDINGS OF ACM
   [Anonymous], CHAR CHEM PHYS FIR 5
   [Anonymous], 2005, Technical report
   [Anonymous], EUR 2000 WORKSH AN
   [Anonymous], AIAA J
   [Anonymous], COMPUT GRAPH
   [Anonymous], P ACM SIGGRAPH EUR S
   [Anonymous], 1990, COMBUSTION STUDY THE
   [Anonymous], TECH REP NISTIR 6783
   [Anonymous], ACM SIGGRAPH EUROGR
   [Anonymous], 2004, GPU gems
   Beaudoin P., 2001, P GRAPH INTERFACE, P159
   BRIDAULT F., 2006, Afrigraph, P31, DOI DOI 10.1145/1108590.1108596
   Bukowski R., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P35, DOI 10.1145/258734.258757
   Chadwick JN, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964979
   CHIBA N, 1994, J VISUAL COMP ANIMAT, V5, P37, DOI 10.1002/vis.4340050104
   Dursi LJ, 2004, ASTROPHYS J, V606, P1039, DOI 10.1086/383125
   Enright D, 2002, ACM T GRAPHIC, V21, P736, DOI [10.1145/566570.566581, 10.1145/566570.566645]
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Feldman BE, 2003, ACM T GRAPHIC, V22, P708, DOI 10.1145/882262.882336
   Foster N, 1996, GRAPH MODEL IM PROC, V58, P471, DOI 10.1006/gmip.1996.0039
   Foster N, 2001, COMP GRAPH, P23, DOI 10.1145/383259.383261
   Hasinoff SW, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1184
   Henyey LG, 1941, ASTROPHYS J, V93, P70, DOI 10.1086/144246
   Holman J.P., 2010, HEAT TRANSF, V10
   Horvath C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531347
   Hottel HC, 1984, COMBUST SCI TECHNOL, V39, P1, DOI 10.1080/00102208408923781
   Ihrke Ivo, 2004, P ACM SIGGRAPHEUROGR, P365, DOI DOI 10.1145/1028523.1028572
   INAKAGE M, 1990, CG INTERNATIONAL 90, P71
   Kim D, 2008, COMPUT GRAPH FORUM, V27, P467, DOI 10.1111/j.1467-8659.2008.01144.x
   Lamorlette A, 2002, ACM T GRAPHIC, V21, P729, DOI 10.1145/566570.566644
   Lentine M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778851
   LEONARD BP, 1979, COMPUT METHOD APPL M, V19, P59, DOI 10.1016/0045-7825(79)90034-3
   Liu Shiguang., 2012, Transactions on Edutainment VII, volume 7145 of Lecture Notes in Computer Science, V7145, P110
   Losasso F, 2006, IEEE T VIS COMPUT GR, V12, P343, DOI 10.1109/TVCG.2006.51
   Losasso F, 2004, ACM T GRAPHIC, V23, P457, DOI 10.1145/1015706.1015745
   Losasso F, 2006, ACM T GRAPHIC, V25, P812, DOI 10.1145/1141911.1141960
   Markstein G.H., 1964, Non-steady Flame Propagation
   Martins C, 2002, J VISUAL COMP ANIMAT, V13, P133, DOI 10.1002/vis.286
   Melek Z, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P431, DOI 10.1109/PCCGA.2002.1167889
   Melek Zeki., 2005, SPM '05: Proceedings of the 2005 ACM symposium on Solid and physical modeling, P187
   NAKA KI, 1966, J PHYSIOL-LONDON, V185, P587, DOI 10.1113/jphysiol.1966.sp008003
   Neff M, 1999, PROC GRAPH INTERF, P193
   O'Brien JF, 1999, COMP GRAPH, P137, DOI 10.1145/311535.311550
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Pegoraro V., 2006, Eurographics Workshop on Natural Phenomena, P237
   Perlin K., 1985, Computer Graphics, V19, P287, DOI 10.1145/325165.325247
   Perlin K.H., 1989, 16 ANN C COMP GRAPH, P253, DOI 10.1145/74333.74359
   Perry C.H., 1994, P 5 EUROGRAPHICS WOR, P105
   Poinsot T., 2012, Theoretical and Numerical Combustion, P287
   Rasmussen N, 2003, ACM T GRAPHIC, V22, P703, DOI 10.1145/882262.882335
   REEVES WT, 1983, ACM T GRAPHIC, V2, P91, DOI 10.1145/964967.801167
   REHM RG, 1978, J RES NAT BUR STAND, V83, P297, DOI 10.6028/jres.083.019
   RUSHMEIER H, 1995, IEEE COMPUT GRAPH, V15, P62, DOI 10.1109/38.391493
   Selle A, 2008, J SCI COMPUT, V35, P350, DOI 10.1007/s10915-007-9166-4
   Siegel R., 1981, Thermal Radiation Heat Transfer, V2nd
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Stam J, 2000, COMMUN ACM, V43, P76, DOI 10.1145/341852.341866
   Stam J., 2001, Journal of Graphics Tools, V6, P43, DOI 10.1080/10867651.2001.10487540
   Stam J., 1993, Computer Graphics Proceedings, P369, DOI 10.1145/166117.166163
   Stam J., 2003, P GAM DEV C
   Stam Jos., 1995, Proceedings of the 22nd annual conference on Computer graphics and interactive techniques, SIGGRAPH '95, P129
   STEINHOFF J, 1994, PHYS FLUIDS, V6, P2738, DOI 10.1063/1.868164
   Sussman M, 1999, J COMPUT PHYS, V148, P81, DOI 10.1006/jcph.1998.6106
   Takahashi JY, 1997, IEICE T INF SYST, VE80D, P1102
   Yao J, 1996, J FLUID MECH, V309, P225, DOI 10.1017/S0022112096001620
   Yngve GD, 2000, COMP GRAPH, P29, DOI 10.1145/344779.344801
   Zhao Y, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P271
   [No title captured]
   [No title captured]
NR 77
TC 5
Z9 5
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1283
EP 1309
DI 10.1007/s11042-012-1273-z
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000015
DA 2024-07-18
ER

PT J
AU Zorrilla, M
   Martin, A
   Sanchez, JR
   Tamayo, I
   Olaizola, IG
AF Zorrilla, Mikel
   Martin, Angel
   Sanchez, Jairo R.
   Tamayo, Inigo
   Olaizola, Igor G.
TI HTML5-based system for interoperable 3D digital home applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Home device interoperability; Digital home applications; Computer
   graphics; 3D virtual environments; Interactivity; Hybrid rendering
   system
ID GRAPHICS; CLUSTERS
AB Digital home application market shifts just about every month. This means risk for developers struggling to adapt their applications to several platforms and marketplaces while changing how people experience and use their TVs, smartphones and tablets. New ubiquitous and context-aware experiences through interactive 3D applications on these devices engage users to interact with virtual applications with complex 3D scenes. Interactive 3D applications are boosted by emerging standards such as HTML5 and WebGL removing limitations, and transforming the Web into a real application framework to tackle interoperability over the heterogeneous digital home platforms. Developers can apply their knowledge of web-based solutions to design digital home applications, removing learning curve barriers related to platform-specific APIs. However, constraints to render complex 3D environments are still present especially in home media devices. This paper provides a state-of-the-art survey of current capabilities and limitations of the digital home devices and describes a latency-driven system design based on hybrid remote and local rendering architecture, enhancing the interactive experience of 3D graphics on these thin devices. It supports interactive navigation of high complexity 3D scenes while provides an interoperable solution that can be deployed over the wide digital home device landscape.
C1 [Zorrilla, Mikel; Martin, Angel; Sanchez, Jairo R.; Tamayo, Inigo; Olaizola, Igor G.] Vicomtech IK4, Donostia San Sebastian 20009, Spain.
RP Martin, A (corresponding author), Vicomtech IK4, Mikeletegi Pasealekua 57, Donostia San Sebastian 20009, Spain.
EM mzorrilla@vicomtech.org; amartin@vicomtech.org; jrsanchez@vicomtech.org;
   itamayo@vicomtech.org; iolaizola@vicomtech.org
RI Olaizola, Igor García/C-2957-2009; Tamayo, Iñigo/AAC-7340-2019; Martin,
   Angel/I-8049-2017
OI Olaizola, Igor García/0000-0002-9965-2038; Sanchez,
   Jairo/0000-0001-9680-4676; Martin, Angel/0000-0002-1213-6787
FU Spanish Ministry for Industry, Tourism and Commerce; European FEDER
   funds
FX The authors would like to thank the Spanish Ministry for Industry,
   Tourism and Commerce, and the European FEDER funds for supporting the
   research activities involved in this paper.
CR [Anonymous], 37 EUROMICRO C
   Anttonen M., 2011, P 2011 ACM S APPL CO, P800, DOI DOI 10.1145/1982185.1982357
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Butler M, 2011, IEEE PERVAS COMPUT, V10, P4, DOI 10.1109/MPRV.2011.1
   Daras P, 2009, TOWARDS THE FUTURE INTERNET: A EUROPEAN RESEARCH PERSPECTIVE, P303, DOI 10.3233/978-1-60750-007-0-303
   Fechteler P, 2010, IEEE IMAGE PROC, P2033, DOI 10.1109/ICIP.2010.5651183
   Hofmann I, 2011, BMSB 2011 IEEE INT S
   Humphreys G, 2001, COMP GRAPH, P129, DOI 10.1145/383259.383272
   Humphreys G, 2002, ACM T GRAPHIC, V21, P693, DOI 10.1145/566570.566639
   Laikari A, 2009, P ICST PERS MED DEL, P4
   Lamberti F, 2007, IEEE T VIS COMPUT GR, V13, P247, DOI 10.1109/TVCG.2007.29
   Lu Y, 2011, IEEE MULTIMEDIA, V18, P4, DOI 10.1109/MMUL.2011.33
   Marino G, 2010, P IEEE VIRT REAL ANN, P285, DOI 10.1109/VR.2010.5444762
   Moreno C, 2012, HAW INT C SYST SCI, P1344
   Nadalutti D, 2006, P 11 INT C 3D WEB TE, P19, DOI DOI 10.1145/1122591.1122594
   ORTIZ S, 2011, COMPUTER, V44, P11
   Ortiz S, 2010, COMPUTER, V43, P14, DOI 10.1109/MC.2010.15
   Rainer B, 2012, P 20 EUR SIGN PROC C
   Shi W, 2010, IEEE 3 INT C CLOUD C, P8
   Simoens P, 2011, COMPUTER, V44, P46, DOI 10.1109/MC.2011.70
   Taivalsaari A, 2011, 9 INT C CREAT CONN C, P17
   Tarkoma S, 2011, COMPUTER, V44, P22, DOI 10.1109/MC.2010.272
   Zahariadis T, 2008, NEM SUMM 2008 ST MAL
   Zorrilla M, 2012, IGI GLOBAL, DOI [10.4018/978-1-61350-150-4.ch011, DOI 10.4018/978-1-61350-150-4.CH011]
   Zorrilla ME, 2012, BUSINESS INTELLIGENCE APPLICATIONS AND THE WEB: MODELS, SYSTEMS AND TECHNOLOGIES, P1, DOI 10.4018/978-1-61350-038-5
NR 25
TC 7
Z9 7
U1 0
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 533
EP 553
DI 10.1007/s11042-013-1516-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400010
DA 2024-07-18
ER

PT J
AU Abd El-Latif, AA
   Li, L
   Niu, XM
AF Abd El-Latif, Ahmed A.
   Li, Li
   Niu, Xiamu
TI A new image encryption scheme based on cyclic elliptic curve and chaotic
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Chaotic system; Cryptographic primitive operations;
   Cyclic elliptic curve
ID ALGORITHM; STANDARD; CRYPTANALYSIS
AB Recently, several cryptosystems based on chaos have been proposed. Nevertheless, most of them hinder the system performance, security, and suffer from the small key space problem. This paper introduces an efficient symmetric encryption scheme for secure digital images based on a cyclic elliptic curve and chaotic system that can overcome these disadvantages. The cipher encrypts 256-bit of plainimage to 256-bit of cipherimage within eight 32-bit registers. The scheme generates pseudorandom bit sequences for round keys based on a piecewise nonlinear chaotic map. Then, the generated sequences are mixed with the key sequences derived from the cyclic elliptic curve points. Results of statistical and differential analysis demonstrate that the proposed algorithm has adequate security for the confidentiality of digital images. Furthermore, it has key sensitivity together with a large key space and the encryption is fast compared to other competitive algorithms.
C1 [Abd El-Latif, Ahmed A.; Niu, Xiamu] Harbin Inst Technolog, Sch Comp Sci & Technol, Harbin 150080, Peoples R China.
   [Li, Li] Harbin Inst Technol, Shenzhen Grad Sch, Sch Comp Sci & Technol, Shenzhen 518055, Peoples R China.
   [Abd El-Latif, Ahmed A.] Menoufia Univ, Dept Math, Fac Sci, Shibin Al Kawm 32511, Egypt.
C3 Harbin Institute of Technology; Harbin Institute of Technology; Egyptian
   Knowledge Bank (EKB); Menofia University
RP Abd El-Latif, AA (corresponding author), Harbin Inst Technolog, Sch Comp Sci & Technol, Harbin 150080, Peoples R China.
EM ahmed_rahiem@yahoo.com
RI Abd El-Latif, Ahmed A. A./GRO-1613-2022
OI Abd El-Latif, Ahmed A. A./0000-0002-5068-2033
FU National Natural Science Foundation of China [60832010, 61100187];
   Fundamental Research Funds for the Central Universities [HIT. NSRIF.
   2010046]; China Postdoctoral Science Foundation [2011M500666]; Higher
   Education Commission of Egypt
FX The authors wish to thank all the anonymous reviewers for their
   suggestions to improve this paper. This work is supported by the
   National Natural Science Foundation of China (60832010, 61100187), the
   Fundamental Research Funds for the Central Universities (Grant No. HIT.
   NSRIF. 2010046), the China Postdoctoral Science Foundation (2011M500666)
   and Higher Education Commission of Egypt.
CR Akhavan A, 2011, J FRANKLIN I, V348, P1797, DOI 10.1016/j.jfranklin.2011.05.001
   Amin M, 2010, COMMUN NONLINEAR SCI, V15, P3484, DOI 10.1016/j.cnsns.2009.12.025
   Amin M, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3360179
   Behnia S, 2009, CHAOS SOLITON FRACT, V40, P505, DOI 10.1016/j.chaos.2007.08.013
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Deepthi PP, 2009, COMPUT COMMUN, V32, P25, DOI 10.1016/j.comcom.2008.09.002
   ELGAMAL T, 1985, IEEE T INFORM THEORY, V31, P469, DOI 10.1109/TIT.1985.1057074
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   HANSEN T, 1992, MATH COMPUT, V59, P639, DOI 10.2307/2153081
   Jafarizadeh MA, 2002, J NONLINEAR MATH PHY, V9, P26, DOI 10.2991/jnmp.2002.9.1.4
   Li CQ, 2011, COMMUN NONLINEAR SCI, V16, P837, DOI 10.1016/j.cnsns.2010.05.008
   Li CQ, 2009, IMAGE VISION COMPUT, V27, P1371, DOI 10.1016/j.imavis.2008.12.008
   Lian S., 2008, Multimedia Content Encryption: Techniques And Applications
   Lian SG, 2009, CHAOS SOLITON FRACT, V40, P2509, DOI 10.1016/j.chaos.2007.10.054
   Mao YB, 2005, HANDBOOK OF GEOMETRIC COMPUTING: APPLICATIONS IN PATTERN RECOGNITION, COMPUTER VISION, NEURALCOMPUTING, AND ROBOTICS, P231, DOI 10.1007/3-540-28247-5_8
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Morain F, 1990, LECT NOTES COMPUTER, V547, P328
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Patidar V, 2010, COMMUN NONLINEAR SCI, V15, P2755, DOI 10.1016/j.cnsns.2009.11.010
   Patidar V, 2009, COMMUN NONLINEAR SCI, V14, P3056, DOI 10.1016/j.cnsns.2008.11.005
   Pisarchik AN, 2008, PHYSICA D, V237, P2638, DOI 10.1016/j.physd.2008.03.049
   Rhouma R, 2008, PHYS LETT A, V372, P5973, DOI 10.1016/j.physleta.2008.07.057
   Rhouma R, 2008, PHYS LETT A, V372, P5790, DOI 10.1016/j.physleta.2008.07.042
   Rhouma R, 2010, COMMUN NONLINEAR SCI, V15, P1887, DOI 10.1016/j.cnsns.2009.07.007
   Sathyanarayana SV, 2010, INF SECUR J, V19, P84, DOI 10.1080/19393550903482759
   Sathyanarayana S. V., 2011, INT J NETWORK SECURI, V12, P137
   Schneier B., 1996, Applied Cryptography: Protocols, Algorithms, and Source Code in C
   Sun FY, 2008, CHAOS SOLITON FRACT, V38, P631, DOI 10.1016/j.chaos.2008.01.028
   Wang K, 2005, PHYS LETT A, V343, P432, DOI 10.1016/j.physleta.2005.05.040
   Wong KW, 2008, PHYS LETT A, V372, P2645, DOI 10.1016/j.physleta.2007.12.026
   Zhou Q, 2008, CHAOS SOLITON FRACT, V38, P1081, DOI 10.1016/j.chaos.2007.01.034
   [No title captured]
NR 34
TC 56
Z9 58
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 1559
EP 1584
DI 10.1007/s11042-012-1173-2
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500009
DA 2024-07-18
ER

PT J
AU Dong, LX
   Lu, SF
   Jin, XG
AF Dong, Lixing
   Lu, Shufang
   Jin, Xiaogang
TI Real-time image-based chinese ink painting rendering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chinese ink painting; Non-photorealistic rendering; Saliency map; Ink
   diffusion
ID ATTENTION
AB Chinese ink painting, also known as ink and wash painting, is a technically demanding art form. Creating Chinese ink paintings usually requires great skill, concentration, and years of training. This paper presents a novel real-time, automatic framework to convert images into Chinese ink painting style. Given an input image, we first construct its saliency map which captures the visual contents in perceptually salient regions. Next, the image is abstracted and its salient edges are calculated with the help of the saliency map. Then, the abstracted image is diffused by a non-physical ink diffusion process. After that, we combine the diffused image and the salient edges to obtain a composition image. Finally, the composition image is decolorized and texture advected to synthesize the resulting image with Chinese ink painting style. The whole pipeline is implemented on the GPU, enabling a real-time performance. We also propose some optional steps (foreground segmentation and image inversion) to improve the rendering quality. Experimental results show that our model is two to three orders of magnitude faster, while producing results comparable the ones obtained with the current image-based Chinese ink painting rendering method.
C1 [Dong, Lixing; Lu, Shufang; Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Jin, XG (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Peoples R China.
EM cee.xingweimian@gmail.com; shufanglu@gmail.com; jin@cad.zju.edu.cn
RI Li, Mengqi/AAG-6804-2021
FU NSFC-MSRA [60970159]; National Natural Science Foundation of China
   [60933007, 60833007]; Zhejiang Provincial Natural Science Foundation of
   China [Z1110154]; National Key Basic Research Foundation of China
   [2009CB320801]
FX We would like to thank the anonymous reviewers for their constructive
   comments. This work was supported by the NSFC-MSRA Joint Funding (Grant
   No. 60970159), the National Natural Science Foundation of China (Grant
   Nos. 60933007 and 60833007), Zhejiang Provincial Natural Science
   Foundation of China (Grant no. Z1110154), and the National Key Basic
   Research Foundation of China (Grant No. 2009CB320801).
CR [Anonymous], 1986, P 13 ANN C COMP GRAP, DOI DOI 10.1145/15922.15911
   Bousseau A., 2006, P NPAR, P141, DOI [DOI 10.1145/1124728.1124751, 10.1145/1124728.1124751]
   Bousseau A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276507
   Chu NSH, 2005, ACM T GRAPHIC, V24, P504, DOI 10.1145/1073204.1073221
   Chu NSH, 2004, IEEE COMPUT GRAPH, V24, P76, DOI 10.1109/MCG.2004.37
   Curtis C. J., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P421, DOI 10.1145/258734.258896
   Guo QL, 2003, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P152, DOI 10.1109/CGI.2003.1214460
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hays J., 2004, PROC NPAR 01, P113
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kang H, 2009, IEEE T VIS COMPUT GR, V15, P62, DOI 10.1109/TVCG.2008.81
   Kunii T. L., 1995, Proceedings. Computer Animation '95, P98, DOI 10.1109/CA.1995.393542
   Lee CH, 2005, ACM T GRAPHIC, V24, P659, DOI 10.1145/1073204.1073244
   Lee J, 2001, COMPUT GRAPH-UK, V25, P295, DOI 10.1016/S0097-8493(00)00132-1
   McGuire M, 2008, SHADERXL ADV RENDERI, P165
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Saito Suguru., 1999, SIGGRAPH conference abstracts and applications, P226
   Siu Chi Hsu, 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P109
   SMALL D, 1991, P SOC PHOTO-OPT INS, V1460, P140, DOI 10.1117/12.44417
   Torralba A, 2006, PSYCHOL REV, V113, P766, DOI 10.1037/0033-295X.113.4.766
   Wang CM, 2007, IEEE T VIS COMPUT GR, V13, P235, DOI 10.1109/TVCG.2007.41
   WEN SZ, 1999, P NAT COMP S NCS 99, P461
   Yu JH, 2003, J COMPUT SCI TECH-CH, V18, P22, DOI 10.1007/BF02946647
   Zhang Q, 1999, J VISUAL COMP ANIMAT, V10, P27, DOI 10.1002/(SICI)1099-1778(199901/03)10:1<27::AID-VIS194>3.0.CO;2-C
   Zhao HL, 2009, VISUAL COMPUT, V25, P973, DOI 10.1007/s00371-008-0308-y
NR 25
TC 15
Z9 20
U1 2
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2014
VL 69
IS 3
BP 605
EP 620
DI 10.1007/s11042-012-1126-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4HM
UT WOS:000333209300003
DA 2024-07-18
ER

PT J
AU Roccetti, M
   Marfia, G
   Bertuccioli, C
AF Roccetti, Marco
   Marfia, Gustavo
   Bertuccioli, Cristian
TI Day and night at the museum: intangible computer interfaces for public
   exhibitions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital technologies for museums; Intangible interfaces; Gestural
   interfaces; Design interaction; Image processing; Immersive environments
ID GESTURE RECOGNITION; LOCATION-AWARE; TRACKING; REALITY; VISITOR; VISION;
   GUIDE
AB Computer technologies have been adopted in many different venues, including public exhibitions and museums, as they can easily support the exchange of natural interactions and provide unimaginable exploration tools of masterpieces and exhibits. This has led many to design and implement a plethora of different technologies for the detection, tracking and action recognition of visitors within a museum. Nonetheless, no single approach has been firmly accepted so far, as it typically suffers from the limitation of adopting separate techniques for detecting, tracking and recognizing the actions of visitors. The contribution of this paper is that of filling this gap: we propose a unifying methodology through which all of the abovementioned services can be handled within a museum. Furthermore, such methodology results being: (a) simple to implement, (b) non-invasive and (c) requiring minimal hardware resources. As significant evidence, we present the experimental results drawn from two relevant implementations: Mercator Atlas Robot exhibited at the Poggi Palace Museum of Bologna and Tortellino X-Perience at the World Expo held in Shanghai. Finally, we indicate how the presented approach can be extended to efficiently support any interaction with several visitors simultaneously.
C1 [Roccetti, Marco; Marfia, Gustavo; Bertuccioli, Cristian] Univ Bologna, I-40127 Bologna, Italy.
C3 University of Bologna
RP Roccetti, M (corresponding author), Univ Bologna, Mura Anteo Zamboni 7, I-40127 Bologna, Italy.
EM roccetti@cs.unibo.it
RI Marfia, Gustavo/D-1347-2010
OI MARFIA, GUSTAVO/0000-0003-3058-8004; ROCCETTI, MARCO/0000-0003-1264-8595
FU Miur PRIN ALTERNET Project
FX The authors acknowledge the Miur PRIN ALTERNET Project for supporting
   this work.
CR Albaum G, 1997, J MARKET RES SOC, V39, P331
   [Anonymous], 2009, UNIVERSAL ACCESS HDB
   [Anonymous], 2006, P 1 INT WORKSH MOB V
   Arnab S., 2011, SERIOUS GAMES EDUTAI, P149
   Bergamasco M, 1999, P 8 IEEE INT WORKSH
   Brave S., 1997, Human Factors in Computing Systems. CHI 97 Extended Abstracts, P363
   Cameron F, 2006, THEORIZING DIGITAL C
   Carrozzino M, 2010, J CULT HERIT, V11, P452, DOI 10.1016/j.culher.2010.04.001
   Chen FS, 2003, IMAGE VISION COMPUT, V21, P745, DOI 10.1016/S0262-8856(03)00070-2
   Ciavarella C, 2004, PERS UBIQUIT COMPUT, V8, P82, DOI 10.1007/s00779-004-0265-z
   COHEN E, 1985, ANN TOURISM RES, V12, P5, DOI 10.1016/0160-7383(85)90037-4
   El Rhalibi A, 2008, CONSUM COMM NETWORK, P1059, DOI 10.1109/ccnc08.2007.241
   Freeman WT, 1998, IEEE COMPUT GRAPH, V18, P42, DOI 10.1109/38.674971
   Fujiyoshi H, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P15, DOI 10.1109/ACV.1998.732852
   Ghiani G, 2009, INTERACT COMPUT, V21, P288, DOI 10.1016/j.intcom.2009.06.001
   Giles J., 2011, NEW SCI
   Han B., 2004, P AS C COMP VIS
   Ishi H, 2008, P ACM 2 INT C TANG E
   Kehl R, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P577, DOI 10.1109/AFGR.2004.1301595
   Linge N, 2012, MUS MANAGE CURATOR, V27, P67, DOI 10.1080/09647775.2012.644697
   Malerczyk C, 2004, P 12 INT C CENTR EUR, P165
   Manresa C., 2005, ELECT LETT COMPUTER, V3, P96, DOI DOI 10.5565/REV/ELCVIA.109
   Marfia G, 2012, P 21 IEEE INT C COMP
   Milosevic B, 2010, P INT C MOB UB COMP
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Mitzman D, 2011, BBC NEWS
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Papagiannakis G, 2008, COMPUT ANIMAT VIRT W, V19, P3, DOI 10.1002/cav.221
   Pasch M, 2009, ENTERTAIN COMPUT, V1, P49, DOI 10.1016/j.entcom.2009.09.004
   Pietroni E., 2010, P 11 INT S VIRT REAL, P171
   Reis Tiago, 2008, 2008 Third International Conference on Pervasive Computing and Applications (ICPCA08), P570, DOI 10.1109/ICPCA.2008.4783677
   Robertson J, 2011, COMPUTERS CREATIVITY
   Roccetti M, 2012, P 4 IEEE INT WORKSH
   Roccetti M, 2011, P 3 IEEE INT WORKSH
   Roccetti M., 2010, ACM COMPUTERS ENTERT, V8
   Rubegni E, 2011, P 29 ACM INT C DES C
   Simpson Z, 2002, SIGGRAPH 2002 EL ART
   Snibbe SS, 2009, P 27 INT C HUM FACT
   Sridhar A, 2008, LECT NOTES COMPUT SC, V5358, P508, DOI 10.1007/978-3-540-89639-5_49
   Stock O, 2007, USER MODEL USER-ADAP, V17, P257, DOI 10.1007/s11257-007-9029-6
   Vicario L, 2003, URBAN STUD, V40, P2383, DOI 10.1080/0042098032000136129
   Wang RY., 2009, ACM transactions on graphics (TOG), V28, P1, DOI DOI 10.1145/1531326.1531369
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Yu Elden, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPR.2009.5204242
NR 44
TC 5
Z9 5
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2014
VL 69
IS 3
BP 1131
EP 1157
DI 10.1007/s11042-013-1512-y
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA AD4HM
UT WOS:000333209300025
DA 2024-07-18
ER

PT J
AU Hsu, FS
   Lin, WY
AF Hsu, Fu-Song
   Lin, Wei-Yang
TI A multimedia presentation system using a 3D gesture interface in museums
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive system design; Interactive multimedia presentation; Depth
   image
ID RECOGNITION; CAMERA
AB Multimedia presentations have become an indispensable feature of museum exhibits in recent years. Advances in technology have increased the relevance of studying digital communication using computational devices. Devices, such as multi-touch screens and cameras, are essential for natural communication, and obvious applications involve entertainment to attract users. This study focused on the use of cameras to support natural interaction of visitors during museum presentations. We first outlined a platform called the "U-Garden," comprising a set of tools to assist application designers in developing movement-based projects that employ camera tracking. We then established a rationale with which to base the design of such presentation tools. This system supplies interactive power to natural interaction based on depth image streams, and provides tracking results to designers for producing numerous fascinating applications that appeal to more diverse interactive imaginations.
C1 [Hsu, Fu-Song; Lin, Wei-Yang] Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi, Taiwan.
C3 National Chung Cheng University
RP Lin, WY (corresponding author), Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi, Taiwan.
EM hfs95p@cs.ccu.edu.tw; wylin@cs.ccu.edu.tw
FU National Taiwan Museum of Fine Arts; Interactive Media Art Workshop
FX This work was partially supported by the National Taiwan Museum of Fine
   Arts and funded by the Interactive Media Art Workshop. A number of
   individuals made substantial contributions to improving this paper. The
   authors would like to express our gratitude for the many interesting
   discussions provided by Professor Tzu-Wei Tsai. We would also like to
   thank Professor Geeng-Neng You and Hsiu-Mei Huang for their useful
   suggestions and assistance on the previous version. The development work
   for motion sensing, we thank Jia-Fen Hung.
CR [Anonymous], 2005, Computer Vision and Pattern Recognition-Workshops
   Aran O, 2010, PATTERN RECOGN, V43, P1776, DOI 10.1016/j.patcog.2009.12.002
   Aran O, 2008, INT C PATT RECOG, P2312
   Aran O, 2009, IEEE MULTIMEDIA, V16, P81, DOI 10.1109/MMUL.2009.17
   Baker M, 2009, LECT NOTES COMPUT SC, V5742, P142, DOI 10.1007/978-3-642-03778-8_11
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Bohme Martin, 2008, International Journal of Intelligent Systems Technologies and Applications, V5, P264, DOI 10.1504/IJISTA.2008.021289
   Bordegoni M, 1997, COMP STAND INTER, V18, P477, DOI 10.1016/S0920-5489(97)00013-5
   Chai D, 1999, IEEE T CIRC SYST VID, V9, P551, DOI 10.1109/76.767122
   CHEN PY, 2008, INT MED ART WORKSH A
   Chiu CC, 2010, IEEE T CIRC SYST VID, V20, P518, DOI 10.1109/TCSVT.2009.2035843
   Chu WT, 2008, MULTIMED TOOLS APPL, V38, P27, DOI 10.1007/s11042-007-0145-4
   Chu WT, 2010, MULTIMED TOOLS APPL, V50, P149, DOI 10.1007/s11042-009-0363-z
   de la Hamette P, 2008, PERS UBIQUIT COMPUT, V12, P97, DOI 10.1007/s00779-006-0109-0
   Dumas B, 2009, LECT NOTES COMPUT SC, V5440, P3, DOI 10.1007/978-3-642-00437-7_1
   Eisenberg M., 2005, P 5 C CREAT COGN LON, P13
   Eriksson E, 2007, PERS UBIQUIT COMPUT, V11, P621, DOI 10.1007/s00779-006-0134-z
   Grammenos D, 2010, P 6 INT C UN ACC H 3, P173
   Haker M, 2009, LNCS, P110, DOI 10.1007/978-3-642-12553-9_10
   Haque Mahfuzul, 2008, 2008 IEEE Fifth International Conference on Advanced Video and Signal Based Surveillance, P41, DOI 10.1109/AVSS.2008.12
   Ho K. I.-J., 2002, Machine Graphics & Vision, V11, P241
   Hornecker E., 2006, P 18 AUSTR C COMPUTE, P135, DOI DOI 10.1145/1228175.1228201
   Hsu FS, 2010, IEEE INT CON MULTI, P1016, DOI 10.1109/ICME.2010.5583029
   Huang CR, 2005, IEEE COMPUT GRAPH, V25, P15, DOI 10.1109/MCG.2005.22
   Huang H-M, 2008, P INT C BUS INF MAN
   Huang H-M, 2007, P WORLD C ED MULT HY, P951
   Huei-Hung Liao, 2008, 2008 IEEE Fifth International Conference on Advanced Video and Signal Based Surveillance, P132, DOI 10.1109/AVSS.2008.9
   Ivanov YA, 2000, IEEE T PATTERN ANAL, V22, P852, DOI 10.1109/34.868686
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   KU WY, 2008, INT MED ART WORKSH A
   Licsar A., 2006, Proceedings of the 1st ACM international workshop on Human-centered multimedia, P81
   Licsár A, 2009, IEEE MULTIMEDIA, V16, P48, DOI 10.1109/MMUL.2009.41
   LU CS, 2008, INT MED ART WORKSH A
   Menon V, 2010, PERS UBIQUIT COMPUT, V14, P685, DOI 10.1007/s00779-010-0288-6
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   Oviatt S, 1999, COMMUN ACM, V42, P74, DOI 10.1145/319382.319398
   Rousseau C, 2006, SIGNAL PROCESS, V86, P3696, DOI 10.1016/j.sigpro.2006.02.041
   Screven C.G., 1999, Information design, P131
   Singh A, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P352, DOI 10.1109/AVSS.2009.74
   Tennenhouse D, 2000, COMMUN ACM, V43, P43, DOI 10.1145/332833.332837
   Tsai T-W, 2006, P INT C UN DES KYOT
   Tsai TW, 2009, INT J ARTS TECHNOL, V2, P94, DOI 10.1504/IJART.2009.024060
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Weiming H, 2004, IEEE T SYST MAN CY C, V34, P334
   Zabulis X, 2010, P INT S VIRT REAL AR, P155
   Ziani A, 2008, IET COMPUT VIS, V2, P99, DOI 10.1049/iet-cvi:20070074
NR 47
TC 5
Z9 5
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2014
VL 69
IS 1
BP 53
EP 77
DI 10.1007/s11042-012-1205-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AB3UH
UT WOS:000331715200004
DA 2024-07-18
ER

PT J
AU Lugmayr, A
   Zou, YN
   Stockleben, B
   Lindfors, K
   Melakoski, C
AF Lugmayr, Artur
   Zou, Yaning
   Stockleben, Bjoern
   Lindfors, Kirsi
   Melakoski, Cai
TI Categorization of ambient media projects on their business models,
   innovativeness, and characteristics-evaluation of Nokia Ubimedia
   MindTrek Award Projects of 2010
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ambient media; Ubimedia; Ubiqutious media; Tangible user-interfaces;
   Characteristics of ubqituous media; MindTrek
AB Ambient Media describe media environments, where the medium is embedded within the natural environment. They follow the anytime, anywhere, and anyhow principle for media access. The Nokia Ubimedia MindTreks Awards have been established a few years ago to explore the potential of ambient media. In this article we analyze the total project portfolio submitted to the 4th Nokia Ubimedia MindTrek Awards in 2010 according to their business value, innovativeness, and use of ambient media. The aim of this article is to gain insights into the general characteristics of ambient media, their properties, and business functions. The article rounds up in providing a substantial framework and guidelines for ambient media developers in their product designs.
C1 [Lugmayr, Artur] Tampere Univ Technol, Dept Business Informat Management & Logist, EMMi Entertainment & Media Prod Management, FIN-33101 Tampere, Finland.
   [Zou, Yaning] Tampere Univ Technol, Dept Commun Engn, FIN-33101 Tampere, Finland.
   [Stockleben, Bjoern] Univ Appl Sci Magdeburg Stendal, New Master Program Cross Media, Magdeburg, Germany.
   [Lindfors, Kirsi] Tampere Univ Technol, FIN-33101 Tampere, Finland.
   [Melakoski, Cai] Tampere Univ Appl Sci, Degree Programme Media, Tampere, Finland.
C3 Tampere University; Tampere University; Tampere University; Tampere
   University; Tampere University of Applied Sciences TAMK
RP Lugmayr, A (corresponding author), Tampere Univ Technol, Dept Business Informat Management & Logist, EMMi Entertainment & Media Prod Management, FIN-33101 Tampere, Finland.
EM artur.lugmayr@tut.fi
RI Lugmayr, Artur/G-4357-2014; Lugmayr, Artur/AAY-7738-2020
OI Lugmayr, Artur/0000-0001-6994-4470; Aalto, Kirsi/0000-0002-1514-8222
CR [Anonymous], NOVATICA
   [Anonymous], 32 HAW INT C SYST SC
   [Anonymous], 2015, Merriam-Webster online. Web
   Forget P, 2008, CIRRELT200854
   Ishii H., 1997, P ACM SIGCHI C HUM F, P234, DOI DOI 10.1145/258549.258715
   Jeon NJ, 2007, WIRELESS PERS COMMUN, V43, P1229, DOI 10.1007/s11277-007-9297-9
   Koleva B., 2003, PROC MOBILE HCI 03, P257
   Kwon O, 2005, EXPERT SYST APPL, V28, P149, DOI 10.1016/j.eswa.2004.08.007
   Lietsala K, 2008, UBIMEDIA 2008 TECHNI
   Lugmayr A, 2010, LECT NOTES COMPUTER, P46
   Lugmayr A, 2010, MULTIMED TOOLS APPL, P1
   Lugmayr A, 2010, LECT NOTES COMPUT SC, V6439, P342
   Nomura Research Institute (NRI), UB NETW MARK CREAT
   Ogden C.K., 1923, MEANING MEANING
   Pousman Z., 2006, P WORK C ADV VIS INT, DOI [https://doi.org/10.1145/1133265.1133277, DOI 10.1145/1133265.1133277]
   Schumpeter J, 1997, KAPITAL KREDIT KINZ
   Schumpeter J.A., 1912, THEORY EC DEV
   Schumpeter Joseph A., 1942, CAPITALISM SOCIALISM
   Tagg Philip., 1999, Introductory notes to the Semiotics of Music
   Tien JM, 2003, IEEE T SYST MAN CY C, V33, P102, DOI 10.1109/TSMCC.2003.809345
   Wright P, 2008, ACM T COMPUT-HUM INT, V15, DOI 10.1145/1460355.1460360
NR 21
TC 13
Z9 13
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2013
VL 66
IS 1
BP 33
EP 57
DI 10.1007/s11042-012-1143-8
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 163DZ
UT WOS:000320317200003
DA 2024-07-18
ER

PT J
AU Tran, TH
   Nguyen, NT
   Vo, QB
AF Trong Hieu Tran
   Ngoc Thanh Nguyen
   Quoc Bao Vo
TI Axiomatic characterization of belief merging by negotiation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Belief merging; Belief negotiation
ID KNOWLEDGE BASES; INFORMATION; ARBITRATION; INTEGRATION; CONSENSUS;
   FUSION
AB Belief merging has been an active research field with many important applications. The major approaches for the belief merging problems, considered as arbitration processes, are based on the construction of the total pre-orders of alternatives using distance functions and aggregation functions. However, these approaches require that all belief bases are provided explicitly and the role of agents, who provide the belief bases, are not adequately considered. Therefore, the results are merely ideal and difficult to apply in the multi-agent systems. In this paper, we approach the merging problems from other point of view. Namely, we treat a belief merging problem as a game, in which rational agents participate in a negotiation process to find out a jointly consistent consensus trying to preserve as many important original beliefs as possible. To this end, a model of negotiation for belief merging is presented, a set of rational and intuitive postulates to characterize the belief merging operators are proposed, and a representation theorem is presented.
C1 [Trong Hieu Tran; Ngoc Thanh Nguyen] Wroclaw Univ Technol, PL-50370 Wroclaw, Poland.
   [Quoc Bao Vo] Swinburne Univ Technol, Hawthorn, Vic 3122, Australia.
C3 Wroclaw University of Science & Technology; Swinburne University of
   Technology
RP Tran, TH (corresponding author), Wroclaw Univ Technol, 27 Wybrzeze Wyspianskiego, PL-50370 Wroclaw, Poland.
EM trong.hieu.tran@pwr.wroc.pl; ngoc-thanh.nguyen@pwr.wroc.pl;
   bvo@swin.edu.au
RI Nguyen, Ngoc/HHZ-0886-2022; Nguyen, Ngoc Thanh/A-5855-2008; YIP, LOK
   WUNG/AEK-1107-2022
OI Tran, Trong Hieu/0000-0002-5741-690X
FU Polish Ministry of Science and Higher Education [N N519 407437]
FX This research was partially supported by Polish Ministry of Science and
   Higher Education under grant no. N N519 407437 (2009-2012).
CR [Anonymous], 1982, IMAGE ANAL MATH MORP
   Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   Baral C., 1991, IEEE Transactions on Knowledge and Data Engineering, V3, P208, DOI 10.1109/69.88001
   BARAL C, 1991, P ISMIS C, P92
   Benferhat S, 2002, ANN MATH ARTIF INTEL, V34, P217, DOI 10.1023/A:1014446411602
   Bloch I, 2002, STUD FUZZ SOFT COMP, V90, P367
   BOOTH R, 2001, P 8 C THEOR ASP RAT, P137
   Booth R, 2006, INFORM FUSION, V7, P19, DOI 10.1016/j.inffus.2005.01.002
   DEAMO S, 2002, LNCS, V2284, P67
   Delgrande J, 2012, ARTIF INTELL, V176, P2223, DOI 10.1016/j.artint.2011.10.001
   Everaere P., 2008, P 11 INT C PRINC KNO, P348
   Konieczny Pino, 1999, LECT NOTES ARTIF INT, V1638, P233
   Konieczny S, 2004, ARTIF INTELL, V157, P49, DOI 10.1016/j.artint.2004.04.008
   Konieczny S, 2002, J LOGIC COMPUT, V12, P773, DOI 10.1093/logcom/12.5.773
   KONIECZNY S, 2000, P KR 2000, P135
   KONIECZNY S, 2004, J APPL NONCLASSICAL, V14, P275
   Konieczny S, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P484
   LEVI I, 1977, SYNTHESE, V34, P423, DOI 10.1007/BF00485649
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Liberatore P, 1998, IEEE T KNOWL DATA EN, V10, P76, DOI 10.1109/69.667090
   Lin JX, 1996, ARTIF INTELL, V83, P363, DOI 10.1016/0004-3702(95)00019-4
   Olfati-Saber R, 2007, P IEEE, V95, P215, DOI 10.1109/JPROC.2006.887293
   Pattichis CS, 2001, CONF REC ASILOMAR C, P1263, DOI 10.1109/ACSSC.2001.987693
   Qi G, 2006, P 21 NAT C ART INT, V1, P281
   REDDY MP, 1994, IEEE T KNOWL DATA EN, V6, P920, DOI 10.1109/69.334882
   Ren W, 2005, P AMER CONTR CONF, P1859, DOI 10.1109/ACC.2005.1470239
   Revesz PZ, 1997, INT J ALGEBR COMPUT, V7, P133, DOI 10.1142/S0218196797000095
   Sliwko Leszek, 2007, International Journal of Intelligent Information and Database Systems, V1, P181, DOI 10.1504/IJIIDS.2007.014949
   Tran TH, 2011, LECT NOTES COMPUT SC, V6881, P200, DOI 10.1007/978-3-642-23851-2_21
   Zhang DM, 2010, ARTIF INTELL, V174, P1307, DOI 10.1016/j.artint.2010.08.003
NR 30
TC 5
Z9 5
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2013
VL 65
IS 1
BP 133
EP 159
DI 10.1007/s11042-012-1136-7
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 126OI
UT WOS:000317626800009
DA 2024-07-18
ER

PT J
AU Bartolini, I
   Patella, M
   Romani, C
AF Bartolini, Ilaria
   Patella, Marco
   Romani, Corrado
TI SHIATSU: tagging and retrieving videos without worries
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based video annotation; Video segmentation; Hierarchical
   semantic video annotation; Visual features
ID ANNOTATION; GAP
AB The dramatic growth of video content over modern media channels (such as the Internet and mobile phone platforms) directs the interest of media broadcasters towards the topics of video retrieval and content browsing. Several video retrieval systems benefit from the use of semantic indexing based on content, since it allows an intuitive categorization of videos. However, indexing is usually performed through manual annotation, thus introducing potential problems such as ambiguity, lack of information, and non-relevance of index terms. In this paper, we present SHIATSU, a complete system for video retrieval which is based on the (semi-)automatic hierarchical semantic annotation of videos exploiting the analysis of visual content; videos can then be searched by means of attached tags and/or visual features. We experimentally evaluate the performance of SHIATSU on two different real video benchmarks, proving its accuracy and efficiency.
C1 [Bartolini, Ilaria; Patella, Marco; Romani, Corrado] Univ Bologna, DEIS, Bologna, Italy.
   [Bartolini, Ilaria] Univ Bologna, DEIS Dept, Bologna, Italy.
C3 University of Bologna; University of Bologna
RP Bartolini, I (corresponding author), Univ Bologna, DEIS, Bologna, Italy.
EM i.bartolini@unibo.it; marco.patella@unibo.it; corrado.romani@unibo.it
RI BARTOLINI, ILARIA/AAA-9455-2019
OI BARTOLINI, ILARIA/0000-0002-8074-1129
FU CoOPERARE MIUR Project
FX This work is partially supported by the CoOPERARE MIUR Project.
CR [Anonymous], AIEMPRO 2010 FLOR IT
   Ardizzoni S., 1999, Proceedings. Tenth International Workshop on Database and Expert Systems Applications. DEXA 99, P167, DOI 10.1109/DEXA.1999.795161
   Barbu T, 2009, COMPUT ELECTR ENG, V35, P712, DOI 10.1016/j.compeleceng.2009.02.003
   Bartolini I, 2008, LECT NOTES COMPUT SC, V4918, P32, DOI 10.1007/978-3-540-79860-6_3
   Bartolini I, 2010, KNOWL INF SYST, V25, P389, DOI 10.1007/s10115-009-0257-4
   Bartolini I, 2009, INT WORK CONTENT MUL, P237, DOI 10.1109/CBMI.2009.23
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chasanis V, 2009, PATTERN RECOGN LETT, V30, P55, DOI 10.1016/j.patrec.2008.08.015
   Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426
   Dakka W., 2005, CIKM, P768, DOI DOI 10.1145/1099554.1099738
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Datta R, 2007, IEEE MULTIMEDIA, V14, P24, DOI 10.1109/MMUL.2007.67
   Dimitrou N, 2009, TRECVID 2009 GAITH M, P16
   Dorado A, 2004, IEEE T CIRC SYST VID, V14, P622, DOI 10.1109/TCSVT.2004.826764
   Fagin Ronald, 2005, P 24 ACM SIGACT SIGM, P184
   Geetha P., 2008, Journal of Computer Sciences, V4, P474, DOI 10.3844/jcssp.2008.474.486
   Haffner P, 2007, AT T RES TRECVID 200
   Hauptmann A, 2007, IEEE T MULTIMEDIA, V9, P958, DOI 10.1109/TMM.2007.900150
   Hauptmann AG, 2008, P IEEE, V96, P602, DOI 10.1109/JPROC.2008.916355
   Hearst MA, 2006, COMMUN ACM, V49, P59, DOI 10.1145/1121949.1121983
   Hjaltason GR, 2003, ACM T DATABASE SYST, V28, P517, DOI 10.1145/958942.958948
   Jacobs A., 2004, TRECVID, V2004, P197
   Kasturi R., 1996, INT WORKSH IM DAT MU, P75
   Kleban J, 2009, CIVR 2009 SANT ISL G
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Liu Y, 2002, MULTIMED TOOLS APPL, V17, P5, DOI 10.1023/A:1014614221234
   Navigli R, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1459352.1459355
   Ngo C-W, 2009, TRECVID 2009 GAITH M, P16
   Qu ZY, 2009, 2009 1ST IEEE SYMPOSIUM ON WEB SOCIETY, PROCEEDINGS, P1, DOI [10.1109/WMWA.2009.20, 10.1109/SWS.2009.5271731]
   Rasiwasia N, 2007, IEEE T MULTIMEDIA, V9, P923, DOI 10.1109/TMM.2007.900138
   Shanmugam T. N., 2009, INT J RES REV APPL S, V1, P236
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Su CW, 2007, IEEE T MULTIMEDIA, V9, P1193, DOI 10.1109/TMM.2007.902875
   TRECVID, 2001, GUID TREC 2001 VID T
   TRECVID, 2008, GUID TRECVID 2008 EV
   Wang L, 2006, MULTIMED TOOLS APPL, V29, P55, DOI 10.1007/s11042-006-7813-7
   Wu CJ, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1785, DOI 10.1109/ICME.2006.262898
   Yee Ka-Ping, 2003, P SIGCHI C HUM FACT, P401, DOI DOI 10.1145/642611.642681
   Yohan Jin, 2005, 13th Annual ACM International Conference on Multimedia, P706
   Yuan JH, 2007, IEEE T CIRC SYST VID, V17, P168, DOI 10.1109/TCSVT.2006.888023
   Zavrel V., 2010, P INT C SIMILARITY S, P125, DOI [DOI 10.1145/1862344, 10.1145/1862344.1862367, DOI 10.1145/1862344.1862367]
   Zhang B, 2008, IDAR 2007 BEIJ CHIN, P81
   Zhao H, 2009, J COMMUN COMPUT, V6, P17
NR 43
TC 20
Z9 20
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2013
VL 63
IS 2
BP 357
EP 385
DI 10.1007/s11042-011-0948-1
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 105MH
UT WOS:000316074200004
DA 2024-07-18
ER

PT J
AU Kim, JC
   Ban, KJ
   Park, D
   Lee, Y
AF Kim, Jong-Chan
   Ban, Kyeong-Jin
   Park, DaeHeon
   Lee, YangSun
TI An object expression system using depth-maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented Reality; Depth-map; Difference Image; Projection; Mapping;
   Vanishing point
AB The current of Augmented Reality are data gloves or markers used for interactions between object and background. But, this results in the inconvenience in use and reduced immersiveness. To reinforce immersiveness in AR, added input devices should be removed. To this end, spatial coordinates should be accurately perceived even when a marker has been attached. In this paper, an object expression system was proposed that uses depth-maps for interactions without any additional input devices in order to improve immersiveness. Immersiveness was improved by projecting obtained images on 2D spaces, extracting vanishing lines, calculating the virtual spatial coordinates of the projected images, and varying the sizes of the inserted objects in accordance with the sizes of the areas of virtual coordinates, based on the images projected on the 2D coordinates. By using this system, the use of 3D modelers could be excluded when 3D objects were created; thus, the efficiency of object creation could be improved.
C1 [Kim, Jong-Chan; Ban, Kyeong-Jin] Sunchon Natl Univ, Dept Comp Engn, Suncheon Si, South Korea.
   [Park, DaeHeon] ETRI, RFID USN Res Div, Taejon, South Korea.
   [Lee, YangSun] Chosun Univ, Dept Informat & Commun Engn, Kwangju, South Korea.
C3 Sunchon National University; Electronics & Telecommunications Research
   Institute - Korea (ETRI); Chosun University
RP Lee, Y (corresponding author), Chosun Univ, Dept Informat & Commun Engn, Kwangju, South Korea.
EM seaghost@sunchon.ac.kr; multwave@sunchon.ac.kr; dhpark82@etri.re.kr;
   yslee48@gmail.com
RI Lee, Yangsun/Q-9948-2019
OI Lee, Yang Sun/0000-0002-1268-2016
FU Industrial Strategic technology development program [10040125]; Ministry
   of Knowledge Economy (MKE, Korea)
FX This work was supported by the Industrial Strategic technology
   development program, 10040125, Development of the Integrated Environment
   Control S/W Platform for Constructing an Urbanized Vertical Farm funded
   by the Ministry of Knowledge Economy (MKE, Korea).
CR [Anonymous], 2006, CVPR WORKSH
   [Anonymous], J CONVERGENCE
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Battiato S, 2004, P SPIE ELECT IMAGING, V5302-13
   Bin Xie, 2010, International Journal of Information Technology, Communications and Convergence, V1, P4, DOI 10.1504/IJITCC.2010.035224
   Khedhiri C., 2011, J CONVERGENCE, V2, P17
   반경진, 2010, Journal of Information and Communication Convergence Engineering, V8, P411
   Kong H, 2009, PROC CVPR IEEE, P96, DOI 10.1109/CVPRW.2009.5206787
   Kosecká J, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P223, DOI 10.1109/ROBOT.2002.1013365
   Kryvinska Natalia, 2010, International Journal of Information Technology, Communications and Convergence, V1, P77, DOI 10.1504/IJITCC.2010.035228
   Liu BY, 2010, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2010.5539823
   Nedovic V, 2007, IEEE I CONF COMP VIS, P1783
   Rasmussen C, 2004, P BRIT MACH VIS C, V1, p[47, 5]
   Rother C, 2002, IMAGE VISION COMPUT, V20, P647, DOI 10.1016/S0262-8856(02)00054-9
   SAXENA A, 2005, P 19 ANN C NEUR INF, V18
   Saxena A, 2008, INT J COMPUT VISION, V76, P53, DOI 10.1007/s11263-007-0071-y
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Schmalstieg D, 2001, 27 SIGGRAPH, V27
   Shufelt JA, 1996, IMAGE UNDERSTANDING WORKSHOP, 1996 PROCEEDINGS, VOLS I AND II, P1113
   Surendran D., 2011, International Journal of Information Technology, Communications and Convergence, V1, P159, DOI 10.1504/IJITCC.2011.039283
   Torralba A, 2002, IEEE T PATTERN ANAL, V24, P1226, DOI 10.1109/TPAMI.2002.1033214
   Yi-Min Tsai, 2006, 2006 International Symposium on Intelligent Signal Processing and Communications, P586
NR 22
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2013
VL 63
IS 1
BP 247
EP 263
DI 10.1007/s11042-011-0955-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 105KY
UT WOS:000316069400016
DA 2024-07-18
ER

PT J
AU Park, SO
   Kim, JS
   Kim, SJ
AF Park, Sang Oh
   Kim, Jin Sung
   Kim, Sung Jo
TI An object-based middleware supporting efficient interoperability on a
   smart home network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart home network; Interoperability; Object-based middleware; Smart
   grid; Energy management
ID SECURITY
AB This paper proposes a novel object-based home network middleware for supporting the interoperability among home devices and smart grid devices. This middleware provides various types of abstract objects for flexible representation of heterogeneous home devices, which are classified based on their characteristics. It is also flexible enough to allow addition of new protocols and message conversion between different protocols through an abstraction layer, which are not supported by existing home network middlewares so that various protocols can be supported. As a result, it can be utilized to provide the interoperability among a variety of devices from sensors to typical home appliances as well as smart grid devices such as a home electric generator and a battery, which adopt different protocols. In order to demonstrate that home devices and smart grid devices are interoperable through the proposed middleware, we implement applications based on the middleware on a target platform consisting of embedded boards, sensors and laptops for emulation purposes of a home network. According to our emulation, this middleware can provide efficient interoperability among home devices and smart grid devices for future energy efficient home.
C1 [Park, Sang Oh; Kim, Jin Sung; Kim, Sung Jo] Chung Ang Univ, Sch Comp Sci & Engn, Seoul 156756, South Korea.
C3 Chung Ang University
RP Kim, SJ (corresponding author), Chung Ang Univ, Sch Comp Sci & Engn, Seoul 156756, South Korea.
EM sj1st@cs.cau.ac.kr; kimjsung@cs.cau.ac.kr; sjkim@cau.ac.kr
OI Kim, Jinsung/0000-0003-3751-8869
FU MKE (The Ministry of Knowledge Economy), Korea, under the HNRC (Home
   Network Research Center)-ITRC (Information Technology Research Center)
   [NIPA-2010-C1090-1011-0010]; Basic Science Research Program through the
   National Research Foundation of Korea (NRF); Ministry of Education,
   Science and Technology [2010-0000414]
FX This research was supported by the MKE (The Ministry of Knowledge
   Economy), Korea, under the HNRC (Home Network Research Center)-ITRC
   (Information Technology Research Center) support program supervised by
   the NIPA (National IT Industry Promotion Agency)
   (NIPA-2010-C1090-1011-0010). This research was also supported by Basic
   Science Research Program through the National Research Foundation of
   Korea (NRF) funded by the Ministry of Education, Science and Technology
   (No. 2010-0000414).
CR [Anonymous], 1997, LAN-MAN Standards Committee of the IEEE Computer Society. Wireless LAN Medium Access Control (MAC) and Physical Layer(PHY) Specification
   [Anonymous], 2008, Power and Energy Society General Meeting-Conversion and Delivery of Electrical Energy in the 21st Century
   [Anonymous], 2006, P 7 INT C MOB DAT MA
   [Anonymous], 2006, ZIGBEE SPEC
   [Anonymous], 2011, P 2011 WORKSH ORG CO
   Bae YS, 2010, IEEE T CONSUM ELECTR, V56, P620, DOI 10.1109/TCE.2010.5505979
   Bluetooth Special Interest Group (SIG), 2003, RFCOMM TS 07 10 BLUE
   Das A, 2009, P 2 INT C INT SCI IN, P1212
   Febiansyah H, 2010, J INF PROCESS SYST, V6, P575, DOI 10.3745/JIPS.2010.6.4.575
   Geller T, 2010, COMMUN ACM, V53, P16, DOI [10.1145/174354B.1743554, 10.1145/1743546.1743554]
   Haartsen J, 1998, ERICSSON REV, V75, P110
   HAVi Consortium, 2001, HAVI SPEC VER 1 1 SP
   Intel Corporation, 2003, INT PXA255 PROC DEV
   Intel Corporation, 2006, INT PXA27X PROC FAM
   Konidala DM, 2011, J INF PROCESS SYST, V7, P111, DOI 10.3745/JIPS.2011.7.1.111
   Leach P. J., 2005, 4122 RFC
   Liang W. Y., 2010, J CONVERGENCE, V1, P93
   McDaniel P, 2009, IEEE SECUR PRIV, V7, P75, DOI 10.1109/MSP.2009.76
   Poh Ai Ling A., 2011, J CONVERGENCE, V2, P39
   Ricquebourg V, 2006, 2006 1ST IEEE INTERNATIONAL CONFERENCE ON E-LEARNING IN INDUSTRIAL ELECTRONICS, P23, DOI 10.1109/ICELIE.2006.347206
   Saguan M, 2009, SMART METERING SUMMA
   Sathappan O. L., 2011, International Journal of Information Technology, Communications and Convergence, V1, P146, DOI 10.1504/IJITCC.2011.039282
   Sun Z, 2009, 1 INT S COMP NETW MU, P1
   Surendran D., 2011, International Journal of Information Technology, Communications and Convergence, V1, P159, DOI 10.1504/IJITCC.2011.039283
   Texas Instruments, 2007, CC2420 2 4 GHZ IEEE
   Texas Instruments, 2003, MSP430X13X MSP430X 1
NR 26
TC 9
Z9 10
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2013
VL 63
IS 1
BP 227
EP 246
DI 10.1007/s11042-011-0926-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 105KY
UT WOS:000316069400015
DA 2024-07-18
ER

PT J
AU Chandrasekaran, V
   Dantu, R
   Subbu, KP
AF Chandrasekaran, Vikram
   Dantu, Ram
   Subbu, Kalyan Pathapati
TI Socio-technical aspects of remote media control for a NG9-1-1 system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Media control; Remote; SIP; VoIP; Voice quality; Image transmission;
   PSAP; NG9-1-1
AB 9-1-1 emergency calls mostly involve distress situations that cause people to panic while trying to answer questions or follow instructions given by a dispatcher. To obtain precious information with the least user intervention and reduced stress on the user, there is a need for the dispatcher to have a better control and understanding of the condition or situation at the other end. The increasing growth of smartphones embedded with camera, speaker phone, GPS, microphone and various other sensors, extends their usage from merely making calls to life saving gadgets during critical situations. By integrating these sensor rich smartphones and the rapidly growing VoIP technology, we propose a VoIP based Next Generation 9-1-1 (NG9-1-1) system for remote media control. Specifically, we use Session Initiation Protocol (SIP) in the implementation of the system using a mobile and a PC client. The proposed system on the mobile client accounted for less than 25% of CPU utilization even with video transmission. The average network utilization was about 10 and 72 kbps for audio and video, respectively. With these encouraging results, we believe the proposed remote media control system will facilitate information acquisition and decision making in emergency situations.
C1 [Chandrasekaran, Vikram; Dantu, Ram; Subbu, Kalyan Pathapati] Univ N Texas, Denton, TX 76203 USA.
C3 University of North Texas System; University of North Texas Denton
RP Dantu, R (corresponding author), MIT, Cambridge, MA 02139 USA.
EM vc0063@unt.edu; rdantu@unt.edu; kp0124@unt.edu
FU National Science Foundation [CNS-0751205, CNS-0821736]
FX This work is partially supported by the National Science Foundation
   under grants CNS-0751205 and CNS-0821736.
CR [Anonymous], 2007, JPG QUALITY COMP CHA
   Azimi-Sadjadi B, 2003, PROCEEDINGS OF IEEE
   Baillieul J., 2007, P IEEE
   Bergstra J. A., 2003, TECH REP
   Bergstrand F, 2009, P 6 INT ISCRAM C
   Biernacki A, 2006, PROC WRLD ACAD SCI E, V11, P202
   Caesar MC, 2002, 10TH INTERNATIONAL W
   Campbell B, 2002, 3428 RFC INT ENG TAS
   Casilari E, 2002, MODELLING VOICE TRAF
   Chandra S, 1999, 2 S INT TECHN SYST U
   Chiu CW, 2007, IEEE T MAGN, V43, P2582, DOI 10.1109/TMAG.2007.893320
   Dantu R, 2009, COMPUTER SECURITY
   De Cicco L, 2010, IEEE T AUTOMAT CONTR, V55, P790, DOI 10.1109/TAC.2010.2040502
   Empirix, 2009, HAMM CALL AN
   GUPTA P, 2007, 20 IEEE COMP SEC FDN
   I-P-tel GmbH, 2009, SIPDR FREE SIP VOIP
   Jennings C, 2007, 4976 RFC INT ENG TAS
   Kevin S, 1996, MBONE MULTICASTING T
   Kim J., 2006, Information Systems for Crisis Response and Management (ISCRAM)
   Kraut RE, 2003, HUMAN COMPUTER INTER
   Langle L, 2002, IEEE INT C EMB PERV
   Lin YJ, 2009, ICCE 09
   Luca V, 2005, MJSIP MINITUTORIAL
   Nahrstedt K, 2011, MULTIMED TOOLS APPL, V51, P593, DOI 10.1007/s11042-010-0629-5
   NSF Workshop Report, 2002, NETW RES TESTB
   NSF Workshop Report, 2005, OV BARR DISR INN NET
   Ranjan A., 2006, P ACM C COMP SUPP CO
   Reynolds B, 2002, IEEE COMMUN MAG SECU
   Schooler E., 2002, 3261 RFC
   Schulzrinne H, 2008, 5031 RFC
   Schulzrinne H, 2002, IEEE INTERNET COMPUT
   Song W, 2009, IPTCOMM 09
   Vikram C, 2010, THESIS
   WHITE B, 2002, P 5 S OP SYST DES IM
   Wild Packets, 2009, OMNIPEAK NETW AN
   Xi BW, 2010, ELECTRON J STAT, V4, P58, DOI 10.1214/09-EJS473
NR 36
TC 1
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2013
VL 62
IS 3
BP 733
EP 759
DI 10.1007/s11042-011-0875-1
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 086VF
UT WOS:000314715500010
DA 2024-07-18
ER

PT J
AU Lin, CS
AF Lin, Chow-Sing
TI Balanced dynamic buffering for scalable video-on-demand streaming on
   peer-to-peer networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Streaming; Video-on-demand; Peer-to-peer; Multiple description coding;
   Load balancing
AB In peer-to-peer video-on-demand streaming networks, the alleviation of server load depends on reciprocal stream sharing among peers. In general, on-demand video services enable clients to watch videos from beginning to the end in a pipeline fashion. As long as a client still caches the initial part of the video, it can provide on-demand service to the subsequent clients without intervention of a server. Therefore, the key challenge is how to maximize the availability of a video for stream relay by keeping the initial part of a video in a peer's buffer as long as possible. In addition, to address the issues of delivering data on lossy network and providing scalable video quality of services for clients, the adoption of multiple description coding has been proven as a feasible resolution by much research work. In this paper, we propose a novel caching scheme for P2P on-demand streaming called Balanced Dynamic Buffering with multiple description coding. The proposed balanced dynamic buffering gradually reduces the number of buffered descriptions once the buffer of a peer gets full. In addition, peers are grouped based on the number of descriptions cached in their buffer. The intra-group balancing and inter-group balancing are applied for well distributing descriptions and balancing their forwarding bandwidth on peer-to-peer on-demand streaming networks. In the paper, we also propose the failure recovery for the balanced dynamic buffering scheme. Simulation results showed that the balanced dynamic buffering significantly outperformed other dynamic buffering schemes and the CoopNet in server bandwidth utilization, and a longer buffer in a peer did favor the failure recovery on peer-to-peer on-demand streaming networks.
C1 Natl Univ Tainan, Dept Comp Sci & Informat Engn, Tainan 70005, Taiwan.
C3 National University Tainan
RP Lin, CS (corresponding author), Natl Univ Tainan, Dept Comp Sci & Informat Engn, 33,Sec 2,Shu Lin St, Tainan 70005, Taiwan.
EM mikelin@mail.nutn.edu.tw
RI Lin, Chow-Sing/JPX-6621-2023
FU National Science Council [NSC 100-2221-E-024-006]
FX This work was partially supported by National Science Council under
   contract NSC 100-2221-E-024-006.
CR Akyol E, 2007, IEEE J-STSP, V1, P231, DOI 10.1109/JSTSP.2007.901527
   Androutsellis-Theotokis S, 2004, ACM COMPUT SURV, V36, P335, DOI 10.1145/1041680.1041681
   Apostolopoulos JG, 2004, IEEE COMMUN MAG, V42, P80, DOI 10.1109/MCOM.2004.1321395
   Apostolopoulos JG, 2001, PROC SPIE, V4310, P392
   Ardestani MR, 2010, IEEE INT CON MULTI, P255, DOI 10.1109/ICME.2010.5583053
   Bernardini R, 2004, IEEE IMAGE PROC, P3213
   Campana O, 2004, P INT C TEL COMP NET, P191
   Castro M., 2003, Operating Systems Review, V37, P298, DOI 10.1145/1165389.945474
   Cui Y, 2004, IEEE J SEL AREA COMM, V22, P91, DOI 10.1109/JSAC.2003.818799
   Cui Y., 2003, Proceedings of the 13th international workshop on Network and operating systems support for digital audio and video, NOSSDAV '03, P162
   Do TT, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-7, P1467, DOI 10.1109/ICC.2004.1312755
   Frossard P, 2008, P IEEE, V96, P39, DOI 10.1109/JPROC.2007.909876
   Goyal VK, 2001, IEEE SIGNAL PROC MAG, V18, P74, DOI 10.1109/79.952806
   Guo Y., 2003, Proceedings of the 12th International Conference on World Wide Web, P301, DOI DOI 10.1145/775152.775195
   JIN S, 2002, P INT WORKSH NETW GR
   Kusmierek E, 2006, IEEE T MULTIMEDIA, V8, P233, DOI 10.1109/TMM.2005.864277
   Lin CS, 2011, INT J COMMUN SYST, V24, P568, DOI 10.1002/dac.1173
   Lin CS, 2010, KSII T INTERNET INF, V4, P491, DOI 10.3837/tiis.2010.08.003
   Lin CS, 2010, MULTIMED TOOLS APPL, V46, P71, DOI 10.1007/s11042-009-0308-6
   Lin CS, 2011, INT J COMMUN SYST, V23, P553
   Padmanabhan V.N., 2002, P 12 INT WORKSHOP NE, P177
   Pradipta D, 2014, J NETW COMPUT APPL, V37, P2, DOI 10.1016/j.jnca.2011.03.032
   Schollmeier R., 2001, P 1 INT C PEER TO PE, P101
   Wang Y, 2005, P IEEE, V93, P57, DOI 10.1109/JPROC.2004.839618
   Zandon'a N, 2005, P IADAT INT C MULT I, P290
NR 25
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2013
VL 62
IS 3
BP 701
EP 718
DI 10.1007/s11042-011-0872-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 086VF
UT WOS:000314715500008
DA 2024-07-18
ER

PT J
AU Barrios, JM
   Bustos, B
AF Manuel Barrios, Juan
   Bustos, Benjamin
TI Competitive content-based video copy detection using global descriptors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video copy detection; Metric spaces; Automatic weighting; Approximate
   search; Multimedia information retrieval
ID IMAGE RETRIEVAL
AB Content-Based Video Copy Detection (CBVCD) consists of detecting whether or not a video document is a copy of some known original and to retrieve the original video. CBVCD systems rely on two different tasks: Feature Extraction task, that calculates many representative descriptors for a video sequence, and Similarity Search task, that is the algorithm for finding videos in an indexed collection that match a query video. This work details a CBVCD approach based on a combination of global descriptors, an automatic weighting algorithm, a pivot-based index structure, an approximate similarity search, and a voting algorithm for copy localization. This approach is analyzed using MUSCLE-VCD-2007 corpus, and it was tested at the TRECVID 2010 evaluation together with other state-of-the-art CBVCD systems. The results show that this approach enables global descriptors to achieve competitive results and even outperforms systems based on combination of local descriptors and audio information. This approach has a potential of achieving even higher effectiveness due to its seamless ability of combining descriptors from different sources at the similarity search level.
C1 [Manuel Barrios, Juan; Bustos, Benjamin] Univ Chile, PRISMA Res Grp, Dept Comp Sci, Santiago 8370459, Chile.
C3 Universidad de Chile
RP Barrios, JM (corresponding author), Univ Chile, PRISMA Res Grp, Dept Comp Sci, Av Blanco Encalada 2120 3Er Piso, Santiago 8370459, Chile.
EM jbarrios@dcc.uchile.cl; bebustos@dcc.uchile.cl
RI Bustos, Benjamin/G-1170-2010
OI Bustos, Benjamin/0000-0002-3955-361X
CR [Anonymous], P 1 SIGMM WORKSH SOC
   [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], TRECVID
   [Anonymous], TRECVID
   [Anonymous], TRECVID
   [Anonymous], P INT WORKSH CONT BA
   [Anonymous], TRECVID
   Batko M, 2009, SISAP 2009: 2009 SECOND INTERNATIONAL WORKSHOP ON SIMILARITY SEARCH AND APPLICATIONS, PROCEEDINGS, P47, DOI 10.1109/SISAP.2009.25
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Brin S., 1995, VLDB '95. Proceedings of the 21st International Conference on Very Large Data Bases, P574
   Bustos B., 2006, P 8 ACM SIGMM INT WO, P137
   Bustos B, 2008, SISAP 2008: FIRST INTERNATIONAL WORKSHOP ON SIMILARITY SEARCH AND APPLICATIONS, PROCEEDINGS, P105, DOI 10.1109/SISAP.2008.12
   Chávez E, 2001, ACM COMPUT SURV, V33, P273, DOI 10.1145/502807.502808
   Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426
   Deselaers T, 2007, LECT NOTES COMPUT SC, V4730, P725
   Hampapur A., 2001, P IEEE INT C MULT EX, P737, DOI DOI 10.1109/ICME.2001.1237827
   Joly A, 2007, IEEE T MULTIMEDIA, V9, P293, DOI 10.1109/TMM.2006.886278
   Kim C, 2005, IEEE T CIRC SYST VID, V15, P127
   Law-To J., 2006, P ACM INT C MULTIMED, P835
   Law-To J., 2007, Muscle-VCD-2007: a live benchmark for video copy detection
   Law-To Julien., 2007, P 6 ACM INT C IMAGE, P371
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Barrios JM, 2011, IEEE INT CON MULTI
   Poullot S., 2008, Proceedings of the ACM International Conference on Multimedia, P61
   Poullot S., 2007, Proceedings of the ACM International Conference on Image and Video Retrieval, P348
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Skopal T, 2007, ACM T DATABASE SYST, V32, DOI 10.1145/1292609.1292619
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Younessian Ehsan., 2010, TRECVID
   Zezula P., 2005, ADV DATABASE SYSTEMS
NR 32
TC 11
Z9 15
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2013
VL 62
IS 1
BP 75
EP 110
DI 10.1007/s11042-011-0915-x
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 076OL
UT WOS:000313965800005
DA 2024-07-18
ER

PT J
AU Teixeira, CAC
   Melo, EL
   Freitas, GB
   Santos, CAS
   Pimentel, MDC
AF Teixeira, Cesar A. C.
   Melo, Erick L.
   Freitas, Giliard B.
   Santos, Celso A. S.
   Pimentel, Maria da Graca C.
TI Discrimination of media moments and media intervals: sticker-based
   watch-and-comment annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive multimedia; Interactive video; Digital TV; Sticker; TV; NCL;
   Authoring; Annotation; Watch-and-Comment; Interactive TV
AB In this paper we discuss the problem of how to discriminate moments of interest on videos or live broadcast shows. The primary contribution is a system which allows users to personalize their programs with previously created media stickers-pieces of content that may be temporarily attached to the original video. We present the system's architecture and implementation, which offer users operators to transparently annotate videos while watching them. We offered a soccer fan the opportunity to add stickers to the video while watching a live match: the user reported both enjoying and being comfortable using the stickers during the match-relevant results even though the experience was not fully representative.
C1 [Pimentel, Maria da Graca C.] Univ Sao Paulo, Dept Ciencias Comp, Inst Ciencias Matemat & Comp, Sao Paulo, Brazil.
   [Teixeira, Cesar A. C.; Melo, Erick L.; Freitas, Giliard B.] Univ Fed Sao Carlos, Dept Comp, BR-13560 Sao Carlos, SP, Brazil.
   [Santos, Celso A. S.] Univ Fed Bahia, Dept Ciencias Comp, Salvador, BA, Brazil.
   [Teixeira, Cesar A. C.] Univ Fed Sao Carlos, Dept Comp Sci, BR-13560 Sao Carlos, SP, Brazil.
C3 Universidade de Sao Paulo; Universidade Federal de Sao Carlos;
   Universidade Federal da Bahia; Universidade Federal de Sao Carlos
RP Pimentel, MDC (corresponding author), Univ Sao Paulo, Dept Ciencias Comp, Inst Ciencias Matemat & Comp, Sao Paulo, Brazil.
EM cesar@dc.ufscar.br; erick_melo@dc.ufscar.br;
   giliard_freitas@dc.ufscar.br; saibel@dcc.ufba.br; mgp@icmc.usp.br
RI Pimentel, Maria G C/D-2875-2009; SANTOS, CELSO Alberto
   Saibel/M-9733-2014
OI Pimentel, Maria G C/0000-0001-8264-5811; SANTOS, CELSO Alberto
   Saibel/0000-0002-3287-5843
FU CAPES; CNPq; FAPESP; FINEP; MCT; MCT/CTIC
FX This work has been supported in Brazil by grants from CAPES, CNPq,
   FAPESP, FINEP and MCT.; We thank the several agencies which provide
   funds to our research: FAPESP, CAPES, CNPq, FINEP, and MCT/CTIC. We also
   thank Rudinei Goularte, Renan G. Cattelan, Luiz F. G. Soares, Dick C. A.
   Bulterman and Pablo S. Cesar for many suggestions and challenging
   questions. We also thank the anonymous reviewers for their suggestions
   and advice.
CR Allen J. F., 1989, Computational Intelligence, V5, P225, DOI 10.1111/j.1467-8640.1989.tb00329.x
   [Anonymous], 2007, J BRAZ COMPUT SOC
   [Anonymous], 2007, 156062 ABNT NBR
   Athanasiadis E, 2010, J SYST SOFTWARE, V83, P1453, DOI 10.1016/j.jss.2010.02.040
   Blanco-Fernández Y, 2008, LECT NOTES COMPUT SC, V5066, P193, DOI 10.1007/978-3-540-69478-6_26
   Blanco-Fernández Y, 2008, SOFTWARE PRACT EXPER, V38, P925, DOI 10.1002/spe.855
   Bulterman Dick., 2008, SYNCHRONIZED MULTIME, p3.0
   Cattelan RG, 2008, ACM T MULTIM COMPUT, V4, DOI 10.1145/1412196.1412201
   CESAR P, 2006, P ACM S DOC ENG DOCE, P186, DOI DOI 10.1145/1166160.1166209
   Cesar P, 2008, LECT NOTES COMPUT SC, V5066, P168, DOI 10.1007/978-3-540-69478-6_22
   Cesar P, 2009, ACM T MULTIM COMPUT, V5, DOI 10.1145/1556134.1556136
   Cesar P, 2009, MULTIMEDIA SYST, V15, P127, DOI 10.1007/s00530-009-0159-z
   Chi MC, 2009, IEEE T CIRC SYST VID, V19, P1025, DOI 10.1109/TCSVT.2009.2022822
   Coppens T, 2004, P EUR C INT TEL EURO
   da Graca Campos Pimentel Maria, 2010, International Journal of Advanced Media and Communication, V4, P78, DOI 10.1504/IJAMC.2010.030007
   de Avila PM, 2009, SIGMAP 2009: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND MULTIMEDIA APPLICATIONS, P149
   de Freitas GB, 2009, P 2009 ACM S APPL CO, P1834, DOI 10.1145/1529282.1529691
   de Lucena VF, 2009, IEEE T CONSUM ELECTR, V55, P1254, DOI 10.1109/TCE.2009.5277985
   Deigmoeller J, 2010, P ACM S APPL COMP SA, P1911, DOI [10.1145/1774088.1774493, DOI 10.1145/1774088.1774493]
   Di Massa R, 2010, P 3 INT WORKSH AUT I, P33, DOI [10.1145/1877850.1877861, DOI 10.1145/1877850.1877861]
   Dimitrova N., 2003, Proceedings of the ACM SIGMM workshop on experiential telepresence (ETP'03), P76, DOI DOI 10.1145/982484.982499
   Drucker S. M., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P219, DOI 10.1145/503376.503416
   Furini M, 2010, MULTIMED TOOLS APPL, V46, P47, DOI 10.1007/s11042-009-0307-7
   Gao Y, 2008, P 2008 ACM INT C CON, P135, DOI [10.1145/1386352.1386375, DOI 10.1145/1386352.1386375]
   Goularte Rudinei., 2004, Proceedings o f the 2004 ACM symposium on Document engineering, Milwaukee, Wisconsin, USA, P84, DOI DOI 10.1145/1030397.1030414
   Guimaraes N., 2002, ACM MULTIMEDIA, P283, DOI DOI 10.1145/641007.641065
   Guimaraes RL, 2010, DOCENG2010: PROCEEDINGS OF THE 2010 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P27
   Hickson I., 2011, HTML5: A vocabulary and associated APIs for HTML and XHTML
   Hölbling G, 2008, IEEE MULTIMEDIA, V15, P72, DOI 10.1109/MMUL.2008.34
   Hsu SH, 2007, LECT NOTES COMPUT SC, V4471, P166
   Huang EM, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P585
   Huet B., 2005, 2005 IEEE International Conference on Multimedia and Expo
   ISO, 1996, 138186 ISOIEC
   Jansen J, 2010, DOCENG2010: PROCEEDINGS OF THE 2010 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P87
   Liu Z, 2008, P ACM TRECVID VID SU, P21, DOI [10.1145/1463563.1463565, DOI 10.1145/1463563.1463565]
   Liu Z, 2008, P 2008 INT C CONT BA, P635, DOI [10.1145/1386352.1386444, DOI 10.1145/1386352.1386444]
   Lynn SG, 2009, EUROITV'09: PROCEEDINGS OF THE SEVENTH EUROPEAN INTERACTIVE TELEVISION CONFERENCE, P77
   Miyahara M, 2008, LECT NOTES COMPUT SC, V4903, P210
   Moreno MF, 2006, P 2006 ACM S DOC ENG, P165, DOI [10.1145/1166160.1166202, DOI 10.1145/1166160.1166202]
   Motti VG, 2009, EUROITV'09: PROCEEDINGS OF THE SEVENTH EUROPEAN INTERACTIVE TELEVISION CONFERENCE, P67
   Nathan M., 2008, P INT C DESIGNING IN, P85, DOI DOI 10.1145/1453805.1453824
   Nitta N, 2009, MULTIMED TOOLS APPL, V41, P1, DOI 10.1007/s11042-008-0217-0
   Patel M, 2008, P INT C DES INT US E, P95, DOI [10.1145/1453805.1453826, DOI 10.1145/1453805.1453826]
   Petersen MK, 2008, P INT C DES INT US E, P63, DOI [10.1145/1453805.1453819, DOI 10.1145/1453805.1453819]
   Pimentel MDC, 2010, HUM-COMPUT INT-SPRIN, P349, DOI 10.1007/978-1-84882-701-1_23
   Pimentel MDC, 2008, DOCENG'08: PROCEEDINGS OF THE EIGHTH ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P298
   Ramos G., 2003, Proceedings of the UIST '03 Symposium on User Interface Software and Technology, P105, DOI DOI 10.1145/964696.964708
   Rogge B, 2004, IEEE T MULTIMEDIA, V6, P910, DOI 10.1109/TMM.2004.835213
   Schulzrinne H., 1998, Real time streaming protocol (rtsp)
   Soares LFG, 2007, LNCS, V4417, P41
   Soares LFG, 2010, MULTIMED TOOLS APPL, V50, P465, DOI 10.1007/s11042-010-0478-2
   Teixeira CAC, 2010, ACM SAC 10, P1929
   Tjondronegoro D, 2004, IEEE MULTIMEDIA, V11, P22, DOI 10.1109/MMUL.2004.28
   Troney R., 2010, MEDIA FRAGMENTS URI
   Vandermolen H, 2009, US Patent, Patent No. 7624416
   VUORIMAA P, 2008, SMIL TIMESHEETS 1 0
   Wei Y, 2009, ACM T MULTIM COMPUT, V5, DOI 10.1145/1556134.1556139
   Xie LX, 2008, P IEEE, V96, P623, DOI 10.1109/JPROC.2008.916362
   Yamamoto M, 2006, LECT NOTES COMPUT SC, V4261, P615
NR 59
TC 0
Z9 1
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2012
VL 61
IS 3
BP 675
EP 696
DI 10.1007/s11042-011-0846-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 021CA
UT WOS:000309861700008
DA 2024-07-18
ER

PT J
AU Lugmayr, A
AF Lugmayr, Artur
TI Connecting the real world with the digital overlay with smart ambient
   media-applying Peirce's categories in the context of ambient media
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ambient media; Ubiquitous computation; Smart media; Creativity;
   Intelligent systems; Media studies; Theory of computation
AB This article is based on the keynote held at the workshop on Events in Multimedia (EiMM09) that took place in conjunction with the ACM Multimedia conference in Beijing in October 2009. The idea of the keynote was to develop and explain the idea of ambient media in general, it is principles, and additionally relate ambient media to information theoretical approaches such as Peirce's categories, to the theories of decision making, and to theories discussing how smart objects can be made 'smart' by simulating the human mind. This article rounds up with practical examples underlining the presented ideas and theories.
C1 Tampere Univ Technol, EMMi Lab, Dept Business Informat Management & Logist, FIN-33101 Tampere, Finland.
C3 Tampere University
RP Lugmayr, A (corresponding author), Tampere Univ Technol, EMMi Lab, Dept Business Informat Management & Logist, FIN-33101 Tampere, Finland.
EM lartur@acm.org
RI Lugmayr, Artur/G-4357-2014; Lugmayr, Artur/AAY-7738-2020
OI Lugmayr, Artur/0000-0001-6994-4470; 
CR [Anonymous], 2009, NEW MEDIA CRITICAL I
   [Anonymous], P 1 ACM INT WORKSH S
   [Anonymous], UNDERSTADING MEDIA E
   [Anonymous], NOVATICA
   [Anonymous], ARTIFICIAL SAPIENCE
   [Anonymous], 32 HAW INT C SYST SC
   [Anonymous], 1868, Proceedings of the American Academy of Arts and Sciences, DOI DOI 10.2307/20179567
   [Anonymous], P 5 INT C KNOWL CAPT
   Brown B., 2002, Cinematography: Theory and practice: Image making for cinematographers, directors, and videographers
   Lugmayr A, 2008, HIGH PERFORMANCE MUL, P7
   Mayorga R.V., 2007, ARTIFICIAL SAPIENCE
   Meystel AM, 2003, IEEE T SYST MAN CY C, V33, P86, DOI 10.1109/TSMCC.2003.809866
   Tien JM, 2003, IEEE T SYST MAN CY C, V33, P102, DOI 10.1109/TSMCC.2003.809345
NR 13
TC 14
Z9 15
U1 4
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2012
VL 58
IS 2
BP 385
EP 398
DI 10.1007/s11042-010-0671-3
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 921NO
UT WOS:000302484500006
DA 2024-07-18
ER

PT J
AU Kalavathy, GM
   Rathinam, NE
   Seethalakshmi, P
AF Kalavathy, G. Maria
   Rathinam, N. Edison
   Seethalakshmi, P.
TI Self-adaptable media service architecture for guaranteeing reliable
   multimedia services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive multimedia service; Dynamic multimedia service composition;
   Reliability; SAMSA; Self-Adaptable architecture; Video-on-demand
AB The main objective of this paper is to design and develop a Self-Adaptable Media Service Architecture (SAMSA) for providing reliable dynamic composite multimedia service through policy-based actions. The multimedia services such as media retrieval, transcoding, scaling and display services are combined based on the preferences of the user to create a dynamic composite multimedia service called as Video-on-Demand service. Such distributed multimedia services deployed using Service Oriented Architecture (SOA) can be accessed in heterogeneous environments that are prone to changes during run-time. To provide reliable and adaptive multimedia services, a powerful self-adaptable architecture with dynamic compositions of multimedia services is necessary to adapt during run-time and react to the environment. The adaptability in this proposed architecture is achieved by enabling the service providers to Monitor, Analyze and Act on the defined policies that support customization of compositions of multimedia services and guarantee the Quality of Service (QoS) provisioning. The Media Service Monitor (MSM) observes the business and quality metrics associated with the multimedia services during run-time. The monitored results are analyzed by Monitored Results Analyzer (MRA) which identifies the type and location of the fault. The Adaptive Media Service Manager (AMSM) takes corrective actions based on the monitored results, through the policies defined as an extension of WS-Policy (Web Service-Policy framework). The effectiveness of the proposed Self-Adaptable Media Service Architecture (SAMSA) has been evaluated on Dynamic Composite Real-time Video-on-Demand Web Service (DCRVoDWS) for a maximum of 200 simultaneous client's requests. The analysis of results shows that the proposed architecture provides better improvement on reliability, response time and user satisfaction.
C1 [Kalavathy, G. Maria] Sathyabama Univ, Madras, Tamil Nadu, India.
   [Rathinam, N. Edison] Univ Madras, KCS Kasi Nadar Coll Arts & Sci, Chennai, Tamil Nadu, India.
   [Seethalakshmi, P.] Anna Univ Technol Tiruchirappalli, Ctr Acad Excellence, Tiruchirappalli, Tamil Nadu, India.
C3 Sathyabama Institute of Science & Technology; University of Madras; Anna
   University
RP Kalavathy, GM (corresponding author), Sathyabama Univ, Madras, Tamil Nadu, India.
EM maria_kalavathy@yahoo.co.in; edison_rath@yahoo.com;
   auropansee@yahoo.co.in
RI G, Mariakalavathy/L-2264-2013
OI G, Mariakalavathy/0000-0002-1826-8166
CR [Anonymous], ENTERPRISE SERVICE O
   [Anonymous], MSU VID QUALIT MEAS
   Baresi L, 2006, LECT NOTES COMPUT SC, V3811, P72
   Bhattacharyya R, PHYS REV A, V71
   Birman K, 2004, PROC INT CONF SOFTW, P17, DOI 10.1109/ICSE.2004.1317410
   CHARFI A, 2005, P 1 WORKSH ASP OR MI
   Ezenwoye Onyeka, 2008, Journal of Networks, V3, P42, DOI 10.4304/jnw.3.5.42-53
   Ezenwoye O, FIUSCIS20060601
   EZENWOYE O, 2006, P 8 INT C ENT INF SY
   Hamadi R, 2004, LECT NOTES COMPUT SC, V3306, P439
   *IBM, 2004, WEB SERV POL FRAM WS
   Kalavathy G. Maria, 2009, Journal of Computer Sciences, V5, P487, DOI 10.3844/jcssp.2009.487.492
   Kalavathy GM, 2008, HPCC 2008: 10TH IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS, PROCEEDINGS, P1001, DOI 10.1109/HPCC.2008.143
   Khitrin AK, 2002, PHYS REV LETT, V89, DOI 10.1103/PhysRevLett.89.277902
   Koschel A, 2008, P WORLD ACAD SCI ENG, V33, P50
   Liguo Yu, 2007, J COMPUT SCI, V6, P1
   Mahbub K, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES, VOLS 1 AND 2, PROCEEDINGS, P257
   Robinson WN, 2003, 11TH IEEE INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE, PROCEEDINGS, P65
   Sloman M., 1994, Journal of Network and Systems Management, V2, P333, DOI 10.1007/BF02283186
   Verma K, 2005, LECT NOTES COMPUT SC, V3826, P1
   Wile DS, 2004, FOURTH WORKING IEEE/IFIP CONFERENCE ON SOFTWARE ARCHITECTURE (WICSA 2004), PROCEEDINGS, P285, DOI 10.1109/WICSA.2004.1310711
   WS-I-Web Services Interoperability Organization, 2003, SUPPL CHAIN MAN SAMP
NR 22
TC 4
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2012
VL 57
IS 3
BP 633
EP 650
DI 10.1007/s11042-010-0664-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 904HS
UT WOS:000301185900009
DA 2024-07-18
ER

PT J
AU Ivanov, I
   Vajda, P
   Lee, JS
   Goldmann, L
   Ebrahimi, T
AF Ivanov, Ivan
   Vajda, Peter
   Lee, Jong-Seok
   Goldmann, Lutz
   Ebrahimi, Touradj
TI Geotag propagation in social networks based on user trust model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tag propagation; Social networks; Object duplicate detection; Geotags;
   User trust model; IPTC
AB In the past few years sharing photos within social networks has become very popular. In order to make these huge collections easier to explore, images are usually tagged with representative keywords such as persons, events, objects, and locations. In order to speed up the time consuming tag annotation process, tags can be propagated based on the similarity between image content and context. In this paper, we present a system for efficient geotag propagation based on a combination of object duplicate detection and user trust modeling. The geotags are propagated by training a graph based object model for each of the landmarks on a small tagged image set and finding its duplicates within a large untagged image set. Based on the established correspondences between these two image sets and the reliability of the user, tags are propagated from the tagged to the untagged images. The user trust modeling reduces the risk of propagating wrong tags caused by spamming or faulty annotation. The effectiveness of the proposed method is demonstrated through a set of experiments on an image database containing various landmarks.
C1 [Ivanov, Ivan; Vajda, Peter; Lee, Jong-Seok; Goldmann, Lutz; Ebrahimi, Touradj] Ecole Polytech Fed Lausanne EPFL, Multimedia Signal Proc Grp MMSPG, Inst Elect Engn IEL, CH-1015 Lausanne, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne
RP Ivanov, I (corresponding author), Ecole Polytech Fed Lausanne EPFL, Multimedia Signal Proc Grp MMSPG, Inst Elect Engn IEL, CH-1015 Lausanne, Switzerland.
EM ivan.ivanov@epfl.ch; peter.vajda@epfl.ch; jong-seok.lee@epfl.ch;
   lutz.goldmann@epfl.ch; touradj.ebrahimi@epfl.ch
RI Lee, Jong-Seok/AAF-5197-2020; Ivanov, Ivan/KHE-5360-2024
OI Lee, Jong-Seok/0000-0001-5255-4425; Ebrahimi,
   Touradj/0000-0002-9900-3687
FU Swiss National Foundation [IM2, 200020-113709]; European Network of
   Excellence PetaMedia
FX This work was supported by the Swiss National Foundation for Scientific
   Research in the framework of NCCR Interactive Multimodal Information
   Management (IM2), the Swiss National Science Foundation Grant
   "Multimedia Security" (number 200020-113709), and partially supported by
   the European Network of Excellence PetaMedia (FP7/2007-2011).
CR [Anonymous], 2008, P 17 INT C WORLD WID
   [Anonymous], 2009, P 18 INT C WORLD WID
   [Anonymous], Facebook statistics
   [Anonymous], 1998, AAAI 98 WORKSH LEARN
   [Anonymous], J SPATIAL INF SCI
   [Anonymous], 2009, Proceedings of the 18th international conference on World wide web, DOI [10.1145/1526709.1526758, DOI 10.1145/1526709.1526758]
   [Anonymous], WIK FLICKR
   [Anonymous], CP3451 JEITA TECHN S
   [Anonymous], P 20 INT C COMP VIS
   [Anonymous], IPTC PHOT MET STAND
   [Anonymous], P 8 ACM INT C HUM CO
   BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Cao L., 2008, Proc. ACM Multimedia, P121
   Cao L., 2009, P 17 ACM INT C MULTI, P125
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   Hays J, 2008, PROC CVPR IEEE, P3436
   Josang A, 2007, DECIS SUPPORT SYST, V43, P618, DOI 10.1016/j.dss.2005.05.019
   Kennedy L.S., 2008, P ACM INT C WORLD WI, P297
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Marti S, 2006, COMPUT NETW, V50, P472, DOI 10.1016/j.comnet.2005.07.011
   Massa Paolo, 2005, AAAI, V1, P121
   Mikolajczyk K, 2002, LECT NOTES COMPUT SC, V2350, P128, DOI 10.1007/3-540-47969-4_9
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Quack Till., 2008, P 2008 INT C CONTENT, P47
   Vajda P, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P600, DOI 10.1109/ISM.2009.119
   Vajda P, 2009, 2009 10TH INTERNATIONAL WORKSHOP ON IMAGE ANALYSIS FOR MULTIMEDIA INTERACTIVE SERVICES, P254, DOI 10.1109/WIAMIS.2009.5031481
   Zheng YT, 2009, PROC CVPR IEEE, P1085, DOI 10.1109/CVPRW.2009.5206749
NR 28
TC 13
Z9 13
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2012
VL 56
IS 1
SI SI
BP 155
EP 177
DI 10.1007/s11042-010-0570-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 876SH
UT WOS:000299127500008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Pang, L
   Cao, J
   Bao, L
   Zhang, YD
   Lin, SX
AF Pang, Lin
   Cao, Juan
   Bao, Lei
   Zhang, Yongdong
   Lin, Shouxun
TI Towards hierarchical context: unfolding visual community potential for
   interactive video retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive video retrieval; Visual community; Hierarchical
   community-based feedback; Active annotation
ID NETWORKS; LINKS
AB Community structure as an interesting property of network has attracted wide attention from many research fields. In this paper, we exploit the visual community structure in visual-temporal correlation network and utilize it to improve interactive video retrieval. Firstly, we propose a hierarchical community-based feedback algorithm. By re-ranking the video shots through diffusion processes respectively on the inter-community and intra-community level, the feedback algorithm can make full use of the limited user feedback. Furthermore, since it avoids entire graph computation, the feedback algorithm can make quick responses to user feedback, which is particularly important for the large video collections. Secondly, we propose a community-based visualization interface called VideoMap. By organizing the video shots following the community structure, the VideoMap presents a comprehensive and informative view of the whole dataset to facilitate users' access. Moreover, the VideoMap can help users to quickly locate the potential relevant regions and make active annotation according to the distribution of labeled samples on the VideoMap. Experiments on TRECVID 2009 search dataset demonstrate the efficiency of the feedback algorithm and the effectiveness of the visualization interface.
C1 [Pang, Lin; Cao, Juan; Bao, Lei; Zhang, Yongdong; Lin, Shouxun] Chinese Acad Sci, Lab Adv Comp Res, Inst Comp Technol, Beijing 100190, Peoples R China.
   [Pang, Lin] Chinese Acad Sci, Grad Univ, Beijing 100039, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Pang, L (corresponding author), Chinese Acad Sci, Lab Adv Comp Res, Inst Comp Technol, Beijing 100190, Peoples R China.
EM panglin@ict.ac.cn; caojuan@ict.ac.cn; baolei@ict.ac.cn; zhyd@ict.ac.cn;
   sxlin@ict.ac.cn
FU National Basic Research Program of China (973 Program) [2007CB311100];
   National Nature Science Foundation of China [60902090]; Beijing New Star
   Project on Science Technology [2007B071]; Beijing Municipal Education
   Commission
FX This work was supported by the National Basic Research Program of China
   (973 Program, 2007CB311100), National Nature Science Foundation of China
   (60902090), Beijing New Star Project on Science & Technology (2007B071),
   Co-building Program of Beijing Municipal Education Commission.
CR [Anonymous], P SNAKDD 2008
   [Anonymous], NOTICES AM MATH SOC
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], IEEE ICME
   [Anonymous], P TRECVID
   [Anonymous], THESIS U COLLEGE LON
   [Anonymous], 2007, P IEEE INT C AC SPEE
   [Anonymous], TREC VIDEO RETRIEVAL
   [Anonymous], P ADV CONC INT VIS S
   [Anonymous], ACM INT C IM VID RET
   [Anonymous], INT WWW C
   [Anonymous], ICIP 2010
   [Anonymous], CIVR 07
   [Anonymous], T PATTERN ANAL MACHI
   [Anonymous], INT WORKSH MULT DAT
   [Anonymous], P ACM INT C MULT
   [Anonymous], BELL SYSTEM TECHNICA
   [Anonymous], 2009, ARXIV09033178
   [Anonymous], ACM INT C MULT MM
   [Anonymous], Learning from labeled and unlabeled data with label propagation
   [Anonymous], P TRECVID WORKSH
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Chen YQ, 2001, IEEE IMAGE PROC, P34, DOI 10.1109/ICIP.2001.958946
   Cheng X, 2008, INT WORKSH QUAL SERV, P249
   Clauset A, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.066111
   Clauset A, 2008, NATURE, V453, P98, DOI 10.1038/nature06830
   Eckmann JP, 2002, P NATL ACAD SCI USA, V99, P5825, DOI 10.1073/pnas.032093399
   Flake G. W., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P150, DOI 10.1145/347090.347121
   Flake GW, 2002, COMPUTER, V35, P66, DOI 10.1109/2.989932
   Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002
   Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799
   González MC, 2008, NATURE, V453, P779, DOI 10.1038/nature06958
   Guo GD, 2002, IEEE T NEURAL NETWOR, V13, P811, DOI 10.1109/TNN.2002.1021882
   Hauptmann A.G., 2006, Proceedings of the 14th annual ACM international conference on Multimedia, P385, DOI DOI 10.1145/1180639.1180721
   He J., 2004, P 12 ANN ACM INT C M, P9, DOI DOI 10.1145/1027527.1027531
   Hsu WH, 2007, IEEE MULTIMEDIA, V14, P14, DOI 10.1109/MMUL.2007.61
   Leskovec J, 2009, INTERNET MATH, V6, P29, DOI 10.1080/15427951.2009.10129177
   Manevitz LM, 2002, J MACH LEARN RES, V2, P139, DOI 10.1162/15324430260185574
   Newman MEJ, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.036104
   Newman MEJ, 2006, P NATL ACAD SCI USA, V103, P8577, DOI 10.1073/pnas.0601602103
   Newman MEJ, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.066133
   Onnela JP, 2007, P NATL ACAD SCI USA, V104, P7332, DOI 10.1073/pnas.0610245104
   Palla G, 2005, NATURE, V435, P814, DOI 10.1038/nature03607
   Palla G, 2007, NATURE, V446, P664, DOI 10.1038/nature05670
   Papadopoulos S, 2010, LECT NOTES COMPUT SC, V6263, P65, DOI 10.1007/978-3-642-15105-7_6
   Pons P, 2005, LECT NOTES COMPUT SC, V3733, P284
   Tong S, 2001, P 9 ACM INT C MULT, P107, DOI DOI 10.1145/500141.500159
   White S, 2005, SIAM PROC S, P274
   Zhou HJ, 2004, LECT NOTES COMPUT SC, V3038, P1062
   Zhu X., 2005, Time-sensitive Dirichlet process mixture models
NR 51
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2011
VL 55
IS 1
SI SI
BP 151
EP 178
DI 10.1007/s11042-010-0605-0
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 797PS
UT WOS:000293140400008
DA 2024-07-18
ER

PT J
AU Huang, YS
   Chieu, BC
AF Huang, Yung-Sung
   Chieu, Bin-Chang
TI Architecture for video coding on a processor with an ARM and DSP cores
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dual-core processors
AB This paper aims to describe architecture for video coding on a processor with an ARM and DSP cores. The proposed platform has been designed for MPEG-4 Visual Simple Profile. The obtained results are optimized if compared with these of single-core. The dual-core processors, composed of RISC and DSP, are widely used as the based-band processors of cell phones. The RISC suits for IO control, while DSP is useful for computation. The operational efficiency of the integration of RISC and DSP is outstanding. Video compression requires a great deal of computation, so we take both the feature of coding algorithm and the hardware platform into consideration. We analyze features of key components in video codec and propose the framework, which adopts DMA to shorten the time needed. It is the result of the communication between the dual-cores. The experimental results indicate that during the inter-frame processing, dual-core with DMA can cut down the processing time by 1/4 more than that of single-use of ARM or DSP. Moreover, it can save 3/4 of the time for encode/decode processing in inter-frame. Especially, in respect of motion estimation, the performance rating can be improved by 4 times.
C1 [Huang, Yung-Sung; Chieu, Bin-Chang] Natl Taiwan Univ Sci & Technol, Taipei, Taiwan.
C3 National Taiwan University of Science & Technology
RP Huang, YS (corresponding author), Natl Taiwan Univ Sci & Technol, Taipei, Taiwan.
EM d9502205@mail.ntust.edu.tw
CR CHAOUI J, 2001, P ICASSP 2001, P1009
   CHOI BD, 2003, EFFICIENT REAL TIME
   HATABU A, 2002, QVGA CIF RESOLUTION
   LEE KH, 2001, IEEE T CONSUNER ELEC, V47
   Lehtoranta O, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL I, P583, DOI 10.1109/ISCAS.2000.857162
   LI P, 2006, IMACS MULT COMP ENG
   RADER S, MOBILE EXTREME CONVE
   SHEN TF, 2008, THESIS NCTU
   STOLBERG HJ, 2003, P DES AUT TEST EUR C
   *TX INSTR INC, TMS320C55X DSP PROGR
   *TX INSTR INC, TMS320C55X IM VID PR
NR 11
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2011
VL 54
IS 2
BP 527
EP 543
DI 10.1007/s11042-010-0550-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 781SK
UT WOS:000291953700015
DA 2024-07-18
ER

PT J
AU Ranathunga, L
   Zainuddin, R
   Abdullah, NA
AF Ranathunga, Lochandaka
   Zainuddin, Roziati
   Abdullah, Nor Aniza
TI Performance evaluation of the combination of Compacted Dither Pattern
   Codes with Bhattacharyya classifier in video visual concept depiction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D colour histogram; Bhattacharyya measure; Compacted Dither Pattern
   Code (CDPC); Support Vector Machines; Video content analysis; Visual
   concept depiction
ID FRAMEWORK; RETRIEVAL
AB High dimensionality and multi-feature combinations can have negative effect on visual concept classification. In our research, we formulated a new compacted form which is Compacted Dither Pattern Code (CDPC) as a chromatic syntactic feature for visual feature extraction. The effectiveness of CDPC with Bhattacharyya classifier for irregular shapes based visual concepts depiction is reported in this paper. The proposed technique can reduce feature space and computational complexity while maintaining visual data mining and retrieval accuracy in high standard. Our system was empowered with Bhattacharyya classifier which has improved efficiency by considering one numeric value which is the Bhattacharyya coefficient. Experiments were conducted on various combinations and compared with different visual descriptors and classifiers. The first experiment illustrates the comparison of the CDPC based results with well known feature space reduction classes. The second and third experiments demonstrate the effectiveness of our approach with multiple perspectives of performance measures including various concepts.
C1 [Ranathunga, Lochandaka; Zainuddin, Roziati; Abdullah, Nor Aniza] Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur 50603, Malaysia.
C3 Universiti Malaya
RP Ranathunga, L (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur 50603, Malaysia.
EM lochandaka@perdana.um.edu.my; roziati@um.edu.my; noraniza@um.edu.my
RI Ranathunga, Lochandaka/K-2894-2019; Abdullah, Nor Aniza/B-2768-2010
OI Ranathunga, Lochandaka/0000-0002-9854-0317; Abdullah, Nor
   Aniza/0000-0001-6218-8772
CR [Anonymous], BRIT MACH VIS C
   BADJIO FE, 2005, INT S APPL STOCH MOD
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   BHATTACHARYYA A, 1946, INDIAN J STAT 1933 1, V7
   Chattopadhyay A, 2004, J BIOSCIENCES, V29, P135, DOI 10.1007/BF02703410
   CURRIER B, 1995, DIGITAL VIDEO CODEC
   Datta R, 2005, P 7 ACM SIGMM INT WO, P153, DOI [DOI 10.1145/1101826.1101866, 10.1145/1101826.1101866]
   GAO S, 2007, ICASSP, V1, P981
   Gao Yuli., 2005, ACM SIGMM Int'l workshop on Multimedia information retrieval (MIR), P135
   Halkos D, 2009, MULTIMED TOOLS APPL, V42, P343, DOI 10.1007/s11042-008-0234-z
   HELLER AK, 2006, P 2006 IEEE COMP SOC, V2, P2110
   Hsu C.-W., 2003, PRACTICAL GUIDE SUPP
   ISRAEL M, 2004, P 5 INT WORKSH MULT, P38
   JIANG YG, 2006, AS PAC WORKSH VIS IN
   Ke Y, 2004, PROC CVPR IEEE, P506
   Konstantinou N, 2010, MULTIMED TOOLS APPL, V46, P425, DOI 10.1007/s11042-009-0361-1
   Lavee G, 2007, MULTIMED TOOLS APPL, V35, P109, DOI 10.1007/s11042-007-0117-8
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   LEW MS, 2000, IEEE COMPUTER    NOV, P46
   LIN L, 2008, IEEE INT C SENS NETW, P262
   Lindstaedt S, 2009, MULTIMED TOOLS APPL, V42, P97, DOI 10.1007/s11042-008-0247-7
   Mikolajczyk K, 2005, IEEE I CONF COMP VIS, P1792
   Mittal A, 2006, INFORM-J COMPUT INFO, V30, P347
   Mrówka E, 2004, IEEE INFOR VIS, P435, DOI 10.1109/IV.2004.1320180
   Nguyen GP, 2008, ACM T MULTIM COMPUT, V4, DOI 10.1145/1324287.1324294
   *NIST, 2008, GUID TRECVID 2008 EV
   SEBE N, 2003, P 5 ACM SIGMM INT WO
   SMEULDERS AWM, 2006, ADAPTIVE HIGH PERFOR
   SNOEK C, 2005, P 3 TRECVID WORKSH N
   Snoek CGM, 2006, ACM T MULTIM COMPUT, V2, P91, DOI 10.1145/1142020.1142021
   SPYROU E, 2007, SERIES FRONTIERS ART
   Srinivasan U, 2005, MULTIMED TOOLS APPL, V27, P105, DOI 10.1007/s11042-005-2716-6
   Xiong ZY, 2006, IEEE SIGNAL PROC MAG, V23, P18
   Zheng WJ, 2006, LECT NOTES COMPUT SC, V4071, P370
   Zhu SH, 2009, MULTIMED TOOLS APPL, V42, P183, DOI 10.1007/s11042-008-0233-0
NR 35
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2011
VL 54
IS 2
BP 263
EP 289
DI 10.1007/s11042-010-0522-2
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 781SK
UT WOS:000291953700004
DA 2024-07-18
ER

PT J
AU Avramova, Z
   De Vleeschauwer, D
   Debevere, P
   Wittevrongel, S
   Lambert, P
   Van de Walle, R
   Bruneel, H
AF Avramova, Zlatka
   De Vleeschauwer, Danny
   Debevere, Pedro
   Wittevrongel, Sabine
   Lambert, Peter
   Van de Walle, Rik
   Bruneel, Herwig
TI On the performance of scalable video coding for VBR TV channels
   transport in multiple resolutions and qualities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE H.264; SVC; Network design; Capacity estimation; TV; Multi-resolution
AB Video broadcast operators target a variety of receiving devices of different resolutions and processing capabilities. In such a heterogeneous TV network, the transport resource consumption is likely to increase. In this paper we estimate the required capacity for a broadcast TV network taking into account parameters as currently proposed in standardization bodies. We target constant video quality, hence the TV channel has variable bit rate (VBR). We consider a multicast-based transport system where only the required versions of a TV channel are transported. This leads to fluctuation of the consumed transport capacity over time. In order to characterize the fluctuations of the bit rate associated with one channel, we encoded a representative set of video clips. We compare a simulcast and a scalable video coding (SVC) transport scheme in several realistic examples with different encoding modes. We explore under what conditions one or the other transport scheme is more efficient.
C1 [Avramova, Zlatka; Wittevrongel, Sabine; Bruneel, Herwig] Univ Ghent, Fac Engn, SMACS Res Grp, TELIN, St Pietersnieuwstr 41, B-9000 Ghent, Belgium.
   [De Vleeschauwer, Danny] Alcatel Lucent Bell, Bell Labs, B-2018 Antwerp, Belgium.
   [Debevere, Pedro; Lambert, Peter; Van de Walle, Rik] Univ Ghent, IBBT, Multimedia Lab Res Grp, B-9050 Ghent, Belgium.
C3 Ghent University; Alcatel-Lucent; Ghent University
RP Avramova, Z (corresponding author), Univ Ghent, Fac Engn, SMACS Res Grp, TELIN, St Pietersnieuwstr 41, B-9000 Ghent, Belgium.
EM zlatka.avramova@telin.ugent.be
RI De Vleeschauwer, Danny/J-6432-2019; Lambert, Peter/D-7776-2016
OI De Vleeschauwer, Danny/0000-0002-0718-8048; Lambert,
   Peter/0000-0001-5313-4158
CR *ADV VID COD GEN A, 2007, H264 ITUT
   [Anonymous], P 16 INT PACK VID WO
   [Anonymous], JOINT SCALABLE VIDEO
   Avramova Z, 2008, TELECOMMUN SYST, V39, P91, DOI 10.1007/s11235-008-9114-0
   AVRAMOVA Z, 2009, P INT C COMM ICC09
   Avramova Z, 2009, IEEE T MULTIMEDIA, V11, P918, DOI 10.1109/TMM.2009.2021806
   *DVB H, DESCR DVB H MOB TV T
   Jarnikov D, 2005, LECT NOTES COMPUT SC, V3824, P930
   Lotfallah OA, 2007, SIGNAL PROCESS-IMAGE, V22, P809, DOI 10.1016/j.image.2007.06.002
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   MCCANNE S, 1996, P ACM SIGCOMM 96 STA, P117
   SUN S, 2006, 18 M JOINT VID TEAM
   Zipf J. K., 1932, SELECTIVE STUDIES PR
   2007, CMAVC0128
NR 14
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2011
VL 53
IS 3
SI SI
BP 487
EP 517
DI 10.1007/s11042-010-0506-2
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 758OK
UT WOS:000290174100002
DA 2024-07-18
ER

PT J
AU Seitner, FH
   Bleyer, M
   Gelautz, M
   Beuschel, RM
AF Seitner, Florian H.
   Bleyer, Michael
   Gelautz, Margrit
   Beuschel, Ralf M.
TI Evaluation of data-parallel H.264 decoding approaches for strongly
   resource-restricted architectures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT International Conference on Advances in Mobile Computing and Multimedia
CY NOV 24-26, 2008
CL Linz, AUSTRIA
SP ACM SIGMM
DE Video decoding; H.264/AVC; Multimedia; Multi-core; Embedded
   architectures
ID DESIGN
AB Decoding of an H.264 video stream is a computationally demanding multimedia application which poses serious challenges on current processor architectures. For processors with strongly limited computational resources, a natural way to tackle this problem is the use of multi-core systems. The contribution of this paper lies in a systematic overview and performance evaluation of parallel video decoding approaches. We focus on decoder splittings for strongly resource-restricted environments inherent to mobile devices. For the evaluation, we introduce a high-level methodology which can estimate the runtime behaviour of multi-core decoding architectures. We use this methodology to investigate six methods for accomplishing data-parallel splitting of an H.264 decoder. These methods are compared against each other in terms of runtime complexity, core usage, inter-communication and bus transfers. We present benchmark results using different numbers of processor cores. Our results shall aid in finding the splitting strategy that is best-suited for the targeted hardware-architecture.
C1 [Seitner, Florian H.; Bleyer, Michael; Gelautz, Margrit; Beuschel, Ralf M.] Vienna Univ Technol, Inst Software Technol & Interact Syst, A-1040 Vienna, Austria.
C3 Technische Universitat Wien
RP Seitner, FH (corresponding author), Vienna Univ Technol, Inst Software Technol & Interact Syst, Favoritenstr 9-11-188-2, A-1040 Vienna, Austria.
EM seitner@ims.tuwien.ac.at; bleyer@ims.tuwien.ac.at;
   gelautz@ims.tuwien.ac.at; schreier@ims.tuwien.ac.at
OI Gelautz, Margrit/0000-0002-9476-0865
CR [Anonymous], P INT C MEAS MOD COM
   BALL T, 1994, ACM T PROGR LANG SYS, V16, P1319, DOI 10.1145/183432.183527
   Cesário WO, 2002, IEEE DES TEST COMPUT, V19, P52, DOI 10.1109/MDT.2002.1047744
   Chen TW, 2005, IEEE INT SYMP CIRC S, P2931
   CHEN YK, 2004, P 18 INT PAR DISTR P, V1, P63
   Faichney J, 2001, MULTIMED TOOLS APPL, V13, P165, DOI 10.1023/A:1009689110306
   Graham S. L., 1982, SIGPLAN Notices, V17, P120, DOI 10.1145/872726.806987
   Gulliver SR, 2007, MOB INF SYST, V3, P71, DOI 10.1155/2007/975892
   *ITU T, 264 ITUT
   Jeon JH, 2000, MULTIMED TOOLS APPL, V11, P197, DOI 10.1023/A:1009699705607
   Knudsen PV, 1996, FOURTH INTERNATIONAL WORKSHOP ON HARDWARE/SOFTWARE CO-DESIGN (CODES/CASHE '96), PROCEEDINGS, P85, DOI 10.1109/HCS.1996.492230
   Meenderinck C, 2009, J SIGNAL PROCESS SYS, V57, P173, DOI 10.1007/s11265-008-0256-9
   MORIYOSHI T, 2008, IEEE INT C CONS EL, P63
   Nachtergaele L, 1996, VLSI SIGNAL PROCESSING, IX, P115, DOI 10.1109/VLSISP.1996.558310
   Paver NC, 2006, MULTIMED TOOLS APPL, V28, P221, DOI 10.1007/s11042-006-6144-z
   PUSCHNER P, 1989, J REAL TIME SYSTEMS, V1, P159
   Ravasi M, 2005, IEEE T CIRC SYST VID, V15, P673, DOI 10.1109/TCSVT.2005.846414
   Ravasi M, 2003, J SYST ARCHITECT, V48, P403, DOI 10.1016/S1383-7621(03)00038-9
   Rodríguez A, 2006, PAR ELEC 2006: INTERNATIONAL SYMPOSIUM ON PARALLEL COMPUTING IN ELECTRICAL ENGINEERING, PROCEEDINGS, P363
   SCHOFFMANN K, 2007, P EURO PAR 2007, P782
   SEITNER F, 2008, P AUSTR 2008
   SEITNER FH, 2008, P SPIE MULTIMEDIA MO, V6821, P5
   Sun SW, 2007, LECT NOTES COMPUT SC, V4782, P577
   van der Tol EB, 2003, PROC SPIE, V5022, P707, DOI 10.1117/12.476234
   Wang SH, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P51
   Witchel Emmett., 1996, SIGMETRICS '96, P68
   Zhao Z., 2006, IEEE International Conference on Acoustics, Speech and Signal Processing, V5, P489
NR 27
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2011
VL 53
IS 2
BP 431
EP 457
DI 10.1007/s11042-010-0501-7
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 753BS
UT WOS:000289739800005
DA 2024-07-18
ER

PT J
AU He, HJ
   Zhang, JS
   Tai, HM
AF He, Hongjie
   Zhang, Jiashu
   Tai, Heng-Ming
TI A neighborhood-characteristic-based detection model for statistical
   fragile watermarking with localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Statistical fragile watermarking; Statistical detection model;
   Neighborhood characteristic; Tamper localization
ID IMAGE TAMPER DETECTION; AUTHENTICATION; SCHEME
AB Statistical fragile watermarking is capable of accurately locating tampered pixels and resisting the collage attack. However, the constraint of the tamper ratio may be too stringent. This paper proposes a neighborhood characteristic based detection model for statistical fragile watermarking to lift the constraints of the tampered area from 4% to 14% of the host image. The neighborhood characteristic is used to effectively decrease the probability of false rejection, while the low probability of false acceptance is guaranteed by selecting proper threshold. The tamper detection performance of the proposed detection model is analytical analyzed in the different conditions. Analytical and experimental results demonstrate that the neighborhood characteristic based detection model effectively reduce the total number of false decisions and detect the tampered pixels with high probability.
C1 [He, Hongjie; Zhang, Jiashu] SW Jiaotong Univ, Sichuan Key Lab Signal & Informat Proc, Chengdu 610031, Peoples R China.
   [Tai, Heng-Ming] Univ Tulsa, Dept Elect Engn, Tulsa, OK 74104 USA.
C3 Southwest Jiaotong University; University of Tulsa
RP He, HJ (corresponding author), SW Jiaotong Univ, Sichuan Key Lab Signal & Informat Proc, Chengdu 610031, Peoples R China.
EM hehojie@126.com
RI he, hongjie/K-2902-2012; Tai, Heng-Ming/A-9267-2009
OI Tai, Heng-Ming/0000-0002-0162-7492
FU National Natural Science Foundation of China [60970122, 60772084,
   60702025]; National S & T Major Project of China [2008ZX05046-01];
   Research Fund for the Doctoral Program of Higher Education
   [20090184120021, 20070613024]
FX This work is supported in part by the National Natural Science
   Foundation of China (Grant No. 60970122, 60772084, 60702025), the
   National S & T Major Project of China (Grant No. 2008ZX05046-01), and by
   the Research Fund for the Doctoral Program of Higher Education (Grant
   No. 20090184120021, 20070613024)
CR [Anonymous], P IEEE INT C IM PROC
   Barreto PSLM, 2002, IEE P-VIS IMAGE SIGN, V149, P57, DOI 10.1049/ip-vis:20020168
   Celik MU, 2002, IEEE T IMAGE PROCESS, V11, P585, DOI 10.1109/TIP.2002.1014990
   Deguillaume F, 2003, SIGNAL PROCESS, V83, P2133, DOI 10.1016/S0165-1684(03)00172-5
   Fridrich J, 2002, PROC SPIE, V4675, P691, DOI 10.1117/12.465330
   Fridrich J, 2002, J ELECTRON IMAGING, V11, P262, DOI 10.1117/1.1459449
   HE H, 2009, 11 INT WORKSH IH 200
   He HJ, 2009, SIGNAL PROCESS, V89, P1557, DOI 10.1016/j.sigpro.2009.02.009
   He HJ, 2006, LECT NOTES COMPUT SC, V4283, P422
   He HJ, 2007, 2007 SECOND INTERNATIONAL CONFERENCE ON BIO-INSPIRED COMPUTING: THEORIES AND APPLICATIONS, P216, DOI 10.1109/BICTA.2007.4806454
   Ho ATS, 2008, IEEE T INF FOREN SEC, V3, P567, DOI 10.1109/TIFS.2008.926994
   Holliman M, 2000, IEEE T IMAGE PROCESS, V9, P432, DOI 10.1109/83.826780
   Lee S, 2007, IEEE T INF FOREN SEC, V2, P321, DOI 10.1109/TIFS.2007.905146
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Liu SH, 2007, APPL MATH COMPUT, V185, P869, DOI 10.1016/j.amc.2006.07.036
   Ohkita K, 2009, LECT NOTES COMPUT SC, V5703, P279, DOI 10.1007/978-3-642-03688-0_25
   Suthaharan S, 2004, PATTERN RECOGN LETT, V25, P1893, DOI 10.1016/j.patrec.2004.08.017
   Wang MS, 2007, COMPUT STAND INTER, V29, P561, DOI 10.1016/j.csi.2006.11.009
   Wong PW, 2001, IEEE T IMAGE PROCESS, V10, P1593, DOI 10.1109/83.951543
   WONG PW, 1998, P IEEE INT C IM PROC, P425, DOI DOI 10.1109/ICIP.1998.723526
   WU J, 2004, P IEEE INT C IM PROC
   Zhang X, 2007, IEEE SIGNAL PROC LET, V14, P727, DOI 10.1109/LSP.2007.896436
   Zhang XP, 2009, SIGNAL PROCESS, V89, P675, DOI 10.1016/j.sigpro.2008.10.001
NR 23
TC 5
Z9 5
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2011
VL 52
IS 2-3
SI SI
BP 307
EP 324
DI 10.1007/s11042-010-0474-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 732IA
UT WOS:000288177000005
DA 2024-07-18
ER

PT J
AU Carmigniani, J
   Furht, B
   Anisetti, M
   Ceravolo, P
   Damiani, E
   Ivkovic, M
AF Carmigniani, Julie
   Furht, Borko
   Anisetti, Marco
   Ceravolo, Paolo
   Damiani, Ernesto
   Ivkovic, Misa
TI Augmented reality technologies, systems and applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Augmented reality technologies; Augmented reality
   systems; Augmented reality applications; Augmented reality iphone4; AR;
   Augmented reality on mobile devices
ID MOBILE
AB This paper surveys the current state-of-the-art of technology, systems and applications in Augmented Reality. It describes work performed by many different research groups, the purpose behind each new Augmented Reality system, and the difficulties and problems encountered when building some Augmented Reality applications. It surveys mobile augmented reality systems challenges and requirements for successful mobile systems. This paper summarizes the current applications of Augmented Reality and speculates on future applications and where current research will lead Augmented Reality's development. Challenges augmented reality is facing in each of these applications to go from the laboratories to the industry, as well as the future challenges we can forecast are also discussed in this paper. Section 1 gives an introduction to what Augmented Reality is and the motivations for developing this technology. Section 2 discusses Augmented Reality Technologies with computer vision methods, AR devices, interfaces and systems, and visualization tools. The mobile and wireless systems for Augmented Reality are discussed in Section 3. Four classes of current applications that have been explored are described in Section 4. These applications were chosen as they are the most famous type of applications encountered when researching AR apps. The future of augmented reality and the challenges they will be facing are discussed in Section 5.
C1 [Carmigniani, Julie; Furht, Borko] Florida Atlantic Univ, Dept Comp & Elect Engn & Comp Sci, Boca Raton, FL 33431 USA.
   [Anisetti, Marco; Ceravolo, Paolo; Damiani, Ernesto] Univ Milan, Dipartimento Tecnol Informaz, Milan, Italy.
   [Ivkovic, Misa] Univ Novi Sad, Novi Sad, Serbia.
C3 State University System of Florida; Florida Atlantic University;
   University of Milan; University of Novi Sad
RP Carmigniani, J (corresponding author), Florida Atlantic Univ, Dept Comp & Elect Engn & Comp Sci, Boca Raton, FL 33431 USA.
EM jcarmign@gmail.com
RI damiani, ernesto/AAI-5709-2020; Anisetti, Marco/AAC-9656-2021; damiani,
   ernesto/J-6060-2012; Ceravolo, Paolo/AAT-5121-2020
OI damiani, ernesto/0000-0002-9557-6496; Anisetti,
   Marco/0000-0002-5438-9467; Ceravolo, Paolo/0000-0002-4519-0173
FU National Science Foundation [OISE-0730065]
FX This material is based upon work supported by the National Science
   Foundation under Grant No. OISE-0730065.
CR Ababsa F., 2008, 2008 IEEE International Symposium on Industrial Electronics (ISIE 2008), P774, DOI 10.1109/ISIE.2008.4676964
   AKINBIYI T, 2006, EMBS 06, P567
   Arvanitis TN, 2009, PERS UBIQUIT COMPUT, V13, P243, DOI 10.1007/s00779-007-0187-7
   Azuma R, 2001, RECENT ADV AUGMENTED
   BABAK A, 2009, AUGMENTED REALITY CO
   Barakonyi I, 2004, PROC GRAPH INTERF, P89
   Bethea BT, 2004, J LAPAROENDOSC ADV A, V14, P191, DOI 10.1089/1092642041255441
   Bichlmeier Christop, 2007, CONTEXTUAL ANATOMIC
   Bimber Oliver, 2007, SIGGRAPH 2007 COURSE
   Brown D, 2003, P IEEE VIRT REAL ANN, P23, DOI 10.1109/VR.2003.1191117
   Bruns E, 2007, IEEE MULTIMEDIA, V14, P16, DOI 10.1109/MMUL.2007.33
   Byungsung Lee, 2010, Proceedings of the Seventh International Conference on Information Technology: New Generations (ITNG 2010), P398, DOI 10.1109/ITNG.2010.36
   Caruso G, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P99, DOI 10.1109/3DUI.2010.5444714
   Chen IYH, 2008, LECT NOTES COMPUT SC, V4931, P125
   Cooper N., 2004, The Australasian Computing Education Conference, V74, P117, DOI DOI 10.1145/1067343.1067357
   COSTANZA E, 2006, MOB HCI 2006 SEP 13
   Dähne P, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P263, DOI 10.1109/ISMAR.2002.1115103
   DiVerdi S, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P75
   Feldman A, 2005, NINTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P52, DOI 10.1109/ISWC.2005.44
   *FLUID INT GROUP, 2010, 6 SENS WEAR GEST INT
   Gallo L, 2010, COMPUT BIOL MED, V40, P350, DOI 10.1016/j.compbiomed.2010.01.006
   HUANG Y, 2009, IEEE I S MIX AUGM RE
   Johnson L. F., 2005, Horizon Report
   Juan MC, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P256, DOI 10.1109/ISMAR.2004.14
   Kato H, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P111, DOI 10.1109/ISAR.2000.880934
   Lee JY., 2010, Proceedings of the 2010 Digest of Technical Papers International Conference on Consumer Electronics (ICCE), P185, DOI [DOI 10.1109/ICCE.2010.5418832, 10.1109/ICCE.2010.5418832]
   LEPETIT V, 2008, 2008 ISUVR 2008 INT, P13
   Li YH, 2008, 2008 THIRD INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND NETWORKING IN CHINA, VOLS 1-3, P69, DOI 10.1109/ISCID.2008.120
   Luo X, 2005, P ANN INT IEEE EMBS, P6855
   Malaka R, 2004, LECT NOTES COMPUT SC, V3031, P54
   MERRILL D, 2007, P 5 INT C PERV COMP
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   MISTRY P, 2008, AMBISYS 08
   Mistry Pranav, 2009, ACM CHI 2009 BOST AP
   Miyashita T, 2008, INT SYM MIX AUGMENT, P103, DOI 10.1109/ISMAR.2008.4637334
   Nilsson J, 2010, P IEEE VIRT REAL ANN, P19, DOI 10.1109/VR.2010.5444821
   Papagiannakis G, 2008, COMPUT ANIMAT VIRT W, V19, P3, DOI 10.1002/cav.221
   Reitmayr G., 2003, AUIC2003
   Sandor C, 2005, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P110
   Schmalstieg D, 2002, PRESENCE-VIRTUAL AUG, V11, P33, DOI 10.1162/105474602317343640
   Schmalstieg Dieter, 2000, BRIDGING MULTIPLE US
   STUTZMAN B, 2009, COMP SCI INF ENG 200, V5, P425
   Takahashi H, 2007, LECT NOTES COMPUT SC, V4563, P564
   Wagner D., 2007, Handheld augmented reality
   Wang P. P., 2009, INT MULT C P 17 ACM, P1025
   White Sean, 2007, MIXED AUGMENTED REAL, P47, DOI [10.1109/ISMAR.2007.4538824, DOI 10.1109/ISMAR.2007.4538824]
   Zhou F., 2008, TRENDS AUGMENTED REA
NR 47
TC 679
Z9 803
U1 69
U2 792
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2011
VL 51
IS 1
BP 341
EP 377
DI 10.1007/s11042-010-0660-6
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 705BO
UT WOS:000286103800013
DA 2024-07-18
ER

PT J
AU Nahrstedt, K
   Yang, ZY
   Wu, WM
   Arefin, A
   Rivas, R
AF Nahrstedt, Klara
   Yang, Zhenyu
   Wu, Wanmin
   Arefin, Ahsan
   Rivas, Raoul
TI Next generation session management for 3D teleimmersive interactive
   environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Session management; 3D teleimmersive environments; Interactive
   multimedia systems
AB In the recent past we have seen a boom of distributed interactive multimedia environments which use multiple correlated media sensors, multi-view displays, and advanced haptic-audio-visual user interfaces for teleimmersive gaming, business meetings and other collaborative activities. However, when we investigate the emerging teleimmersive environments closer, we realize that their overall session management, including end-to-end session setup, establishment and run-time management are not appropriate for the new demands that these environments present. These environments are cyber-physical rooms that demand (a) large scale of multi-sensory devices across geographically-distributed locations and (b) interaction with each other in synchronous and real-time manner. To deal with the new teleimmersive demands, we present a new session management design with (a) session initiation protocol(s) that understand media correlations, (b) view-based multi-stream topology establishment among multiple parties, (c) efficient, light-weight and distributed session monitoring with querying and debugging capabilities, (d) flexible view-based session adaptation with efficient topology adjustments, and (e) light-weighted and consistent session tear-down protocols. The presented design of the next generation session management protocols, services, algorithms and data structures is based on our extensive experiences with building 3D teleimmersive interactive systems, experimenting with high impact teleimmersive applications and deploying such environments at various venues.
C1 [Yang, Zhenyu] Florida Int Univ, Sch Comp & Informat Sci, Miami, FL 33199 USA.
   [Nahrstedt, Klara; Wu, Wanmin; Arefin, Ahsan; Rivas, Raoul] Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA.
C3 State University System of Florida; Florida International University;
   University of Illinois System; University of Illinois Urbana-Champaign
RP Yang, ZY (corresponding author), Florida Int Univ, Sch Comp & Informat Sci, 11200 SW 8th St, Miami, FL 33199 USA.
EM klara@cs.uiuc.edu; yangz@cis.fiu.edu; wwu23@cs.uiuc.edu;
   marefin2@cs.uiuc.edu; trivas@uiuc.edu
FU Division Of Computer and Network Systems; Direct For Computer & Info
   Scie & Enginr [0834480] Funding Source: National Science Foundation
CR Agrawal M, 2002, INT J COMPUT VISION, V47, P43, DOI 10.1023/A:1017478504047
   AREFIN A, 2009, IEEE INT C DISTR COM
   Bajcsy P., 2009, P ACM INT C MULT BEI
   Baker H., 2005, ACM T MULTIMEDIA COM
   CORRADI A, 1999, P IEEE CONC, V7
   DABEK F, 2004, P ACM SIGCOMM 04 C
   DANIILIDIS F, 1999, ACM SIGGRAPH
   GOEMANS M, 2003, P IEEE S FDN COMP SC, P273
   Gross M., 2003, ACM T GRAPH
   *INT TEL UN, 2003, H323 INT TEL UN
   JAIN M, 2002, P ACM SIGCOMM AUG, P295
   KURILLO G, 2008, P 10 IEEE INT S MULT
   *MICR CORP, 2010, MICR NETMEETING PROT
   OTT DE, 2004, P 12 ANN ACM INT C M
   SAT B, 2007, P IEEE INT S MULT
   Schooler E., 2002, 3261 RFC
   Schulzrinne H., 2003, RTP TRANSPORT PROTOC
   Schulzrinne H., 1998, 2326 RFC
   SHEPPARD R, 2008, P ACM INT C MULT VAN
   SHI S, 2008, P ACM INT C MULT
   Svoboda T, 2005, PRESENCE-VIRTUAL AUG, V14, P407, DOI 10.1162/105474605774785325
   Wang Z, 1996, IEEE J SEL AREA COMM, V14, P1228, DOI 10.1109/49.536364
   WU W, 2008, IEEE INT C DISTR COM
   WU W, 2008, P 10 IEEE INT S MULT
   WU W, 2008, AACE WORLD C ED MULT
   YANG Z, 2005, P 7 IEEE INT S MULT
   Yang Z., 2006, P 16 INT WORKSH NETW
   YANG Z, 2007, P 15 ACM INT C MULT
   YANG Z, 2006, IEEE INT S MULT ISM
   Yang ZY, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1671962.1671963
NR 30
TC 4
Z9 5
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2011
VL 51
IS 2
SI SI
BP 593
EP 623
DI 10.1007/s11042-010-0629-5
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 709WO
UT WOS:000286472300008
DA 2024-07-18
ER

PT J
AU Lucena, M
   Fuertes, JM
   de la Blanca, NP
   Marín-Jiménez, MJ
AF Lucena, Manuel
   Fuertes, Jose M.
   Perez de la Blanca, Nicolas
   Marin-Jimenez, Manuel J.
TI Tracking people in video sequences using multiple models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-rigid object tracking; Target representation and localization
ID MEAN-SHIFT; LOCALIZATION
AB This paper presents a multiple model real-time tracking technique for video sequences, based on the mean-shift algorithm. The proposed approach incorporates spatial information from several connected regions into the histogram-based representation model of the target, and enables multiple models to be used to represent the same object. The use of several regions to capture the color spatial information into a single combined model, allow us to increase the object tracking efficiency. By using multiple models, we can make the tracking scheme more robust in order to work with sequences with illumination and pose changes. We define a model selection function that takes into account both the similarity of the model with the information present in the image, and the target dynamics. In the tracking experiments presented, our method successfully coped with lighting changes, occlusion, and clutter.
C1 [Lucena, Manuel; Fuertes, Jose M.] Univ Jaen, Dept Comp Sci, Jaen 23071, Spain.
   [Perez de la Blanca, Nicolas] Univ Granada, Dept Comp Sci & AI, E-18071 Granada, Spain.
   [Marin-Jimenez, Manuel J.] Univ Cordoba, Dept Comp Sci & Numer Anal, E-14071 Cordoba, Spain.
C3 Universidad de Jaen; University of Granada; Universidad de Cordoba
RP Lucena, M (corresponding author), Univ Jaen, Dept Comp Sci, Jaen 23071, Spain.
EM mlucena@ujaen.es; jmf@ujaen.es; nicolas@ugr.es; mjmarin@uco.es
RI Lucena, Manuel/I-6467-2018; Marin-Jimenez, Manuel J./AAS-9152-2020;
   Fuertes Garcia, Jose Manuel/I-8008-2018
OI Lucena, Manuel/0000-0002-5546-3745; Marin-Jimenez, Manuel
   J./0000-0001-9294-6714; Fuertes Garcia, Jose Manuel/0000-0001-6624-4102
FU Spanish Ministry of Science and Technology [TIC-2001-3316,
   TIC-2005-1665]
FX This work has been financed by Grant TIC-2001-3316 and TIC-2005-1665
   from the Spanish Ministry of Science and Technology.
CR [Anonymous], P 2 JOINT IEEE INT W
   Arnaud É, 2005, IEEE T IMAGE PROCESS, V14, P63, DOI 10.1109/TIP.2004.838707
   Birchfield ST, 2005, PROC CVPR IEEE, P1158
   Bradski GR, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P214, DOI 10.1109/ACV.1998.732882
   BRADSKI GR, 1998, INTEL TECHNOL J, V2
   Collins RT, 2003, PROC CVPR IEEE, P234
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   DEUTSCHER J, 1999, P INT C COMP VIS, V2, P1144
   Felzenszwalb PF, 2000, PROC CVPR IEEE, P66, DOI 10.1109/CVPR.2000.854739
   Fleuret F, 2008, IEEE T PATTERN ANAL, V30, P267, DOI 10.1109/TPAMI.2007.1174
   GUALDI G, 2008, P 8 INT WORKSH VIS S
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Liu TL, 2004, IEEE T PATTERN ANAL, V26, P397, DOI 10.1109/TPAMI.2004.1262335
   Lucena MJ, 2005, LECT NOTES COMPUT SC, V3522, P20
   MAGGIO E, 2007, P IEEE INT C AC SPEE
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Muñoz-Salinas R, 2008, J VIS COMMUN IMAGE R, V19, P75, DOI 10.1016/j.jvcir.2007.07.004
   Peng NS, 2006, SOFT COMPUT, V10, P1127, DOI 10.1007/s00500-005-0035-5
   PORIKLI F, 2003, HUMAN BODY TRACKING
   Ramanan D, 2007, IEEE T PATTERN ANAL, V29, P65, DOI 10.1109/TPAMI.2007.250600
   Shen CH, 2007, IEEE T IMAGE PROCESS, V16, P1457, DOI 10.1109/TIP.2007.894233
   Sullivan J, 2001, INT J COMPUT VISION, V44, P111, DOI 10.1023/A:1011818912717
   Yang M, 2009, IEEE T PATTERN ANAL, V31, P1195, DOI 10.1109/TPAMI.2008.146
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152
NR 28
TC 7
Z9 8
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2010
VL 49
IS 2
BP 371
EP 403
DI 10.1007/s11042-009-0376-7
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 604OB
UT WOS:000278287300006
DA 2024-07-18
ER

PT J
AU Kolekar, MH
   Sengupta, S
AF Kolekar, Maheshkumar H.
   Sengupta, Somnath
TI Semantic concept mining in cricket videos for automated highlight
   generation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Event detection; Association rule; Semantic concept; Cricket; Sports
   video highlights
ID SEGMENTATION; FRAMEWORK; CLASSIFICATION; ANNOTATION; EXTRACTION; AUDIO
AB This paper presents a novel approach towards automated highlight generation of broadcast sports video sequences from its extracted events and semantic concepts. A sports video is hierarchically divided into temporal partitions namely, megaslots, slots, and semantic entities, namely concepts, and events. The proposed method extracts event sequence from video and classifies each sequence into a concept by sequential association mining. The extracted concepts and events within the concepts are selected according to their degree of importance to include those in the highlights. A parameter degree of abstraction is proposed, which gives a choice to the user about how concisely the extracted concepts should be produced for a specified highlight duration. We have successfully extracted highlights from recorded video of cricket match and compared our results with the manually-generated highlights by sports television channel.
C1 [Kolekar, Maheshkumar H.] Univ Missouri, Dept Comp Sci, Columbia, MO 65211 USA.
   [Sengupta, Somnath] Indian Inst Technol, Dept Elect & Elect Commun Engn, Kharagpur, W Bengal, India.
C3 University of Missouri System; University of Missouri Columbia; Indian
   Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur
RP Kolekar, MH (corresponding author), Univ Missouri, Dept Comp Sci, Columbia, MO 65211 USA.
EM mkolekar@gmail.com; ssg@ece.iitkgp.ernet.in
RI Kolekar, Maheshkumar/ABF-8942-2020
OI Kolekar, Maheshkumar/0000-0002-4272-3528
CR Aigrain P, 1996, MULTIMED TOOLS APPL, V3, P179, DOI 10.1007/BF00393937
   [Anonymous], IEEE INT C IM PROC G
   Assfalg J, 2002, IEEE MULTIMEDIA, V9, P52, DOI 10.1109/93.998060
   Babaguchi N, 2004, IEEE T MULTIMEDIA, V6, P575, DOI [10.1109/TMM.2004.830811, 10.1109/tmm.2004.830811]
   Baillie M, 2003, LECT NOTES COMPUT SC, V2728, P300
   Bao P, 2005, IEEE T PATTERN ANAL, V27, P1485, DOI 10.1109/TPAMI.2005.173
   Bertini M, 2005, MULTIMED TOOLS APPL, V26, P345, DOI 10.1007/s11042-005-0893-y
   Chang P, 2002, IEEE IMAGE PROC, P609
   Cheng CC, 2006, IEEE T MULTIMEDIA, V8, P585, DOI 10.1109/TMM.2006.870726
   CHRISTEL M, 1995, MULTIMED TOOLS APPL, V2
   Dimitrova N, 2002, IEEE MULTIMEDIA, V9, P42, DOI 10.1109/MMUL.2002.1022858
   Duan LY, 2005, IEEE T MULTIMEDIA, V7, P1066, DOI 10.1109/TMM.2005.858395
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P1114, DOI 10.1109/TMM.2005.858397
   HAUPTMANN AG, 1995, IJCAI WORKSH INT MUL, P17
   Hua W, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P821, DOI 10.1109/ICME.2002.1035908
   Hua XS, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P149
   Huang JC, 2005, IEEE T MULTIMEDIA, V7, P538, DOI 10.1109/TMM.2005.843346
   Kijak E, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P309
   Kokaram A, 2006, IEEE SIGNAL PROC MAG, V23, P47, DOI 10.1109/MSP.2006.1621448
   Kolekar MH, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1617, DOI 10.1109/ICME.2006.262856
   Kolekar MH, 2006, LECT NOTES COMPUT SC, V3852, P633
   Kolekar MH, 2004, PROCEEDINGS OF THE IEEE INDICON 2004, P157, DOI 10.1109/INDICO.2004.1497728
   Kolekar MH, 2000, IETE J RES, V46, P319, DOI 10.1080/03772063.2000.11416172
   KOLEKAR MH, 2006, P ACM INT C MOB MULT, V324
   KOLEKAR MH, 2005, P IEEE INT REG 10 C, P1
   LEONARDI R, 2004, IEEE T CIRCUITS SYST, V14
   Li BX, 2003, IEEE IMAGE PROC, P17
   Li BX, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P169
   Mei T, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P107
   NAPHADE MR, 2004, 12 ANN ACM INT C MUL, P660
   Otsuka I, 2005, IEEE T CONSUM ELECTR, V51, P112, DOI 10.1109/TCE.2005.1405707
   Peker KA, 2002, P SOC PHOTO-OPT INS, V4676, P318
   Rui Y., 2000, Proceedings ACM Multimedia 2000, P105, DOI 10.1145/354384.354443
   Sankar P, 2006, LECT NOTES COMPUT SC, V4338, P433
   Takahashi Y, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P1171
   Utsumi O, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P45, DOI 10.1109/ICME.2002.1035714
   Wan K, 2004, INT C PATT RECOG, P973, DOI 10.1109/ICPR.2004.1334691
   Wang JJ, 2007, IEEE T MULTIMEDIA, V9, P576, DOI 10.1109/TMM.2006.888013
   Xiong ZY, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P632
   XU H, 2004, ACM SIGMM INT MULT W, P127
   XU P, 2001, IEEE INT C MULT EXP
   Zhang ZF, 2008, IEEE T MULTIMEDIA, V10, P165, DOI 10.1109/TMM.2007.915372
   Zhou W., 2000, ACM Workshops on Multimedia, P213
   Zhu GY, 2007, IEEE T MULTIMEDIA, V9, P1167, DOI 10.1109/TMM.2007.902847
   Zhu XQ, 2005, IEEE T KNOWL DATA EN, V17, P665, DOI 10.1109/TKDE.2005.83
NR 46
TC 18
Z9 19
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2010
VL 47
IS 3
SI SI
BP 545
EP 579
DI 10.1007/s11042-009-0337-1
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 572BC
UT WOS:000275800200010
DA 2024-07-18
ER

PT J
AU Schreer, O
   Feldmann, I
   Mediavilla, IA
   Concejero, P
   Sadka, AH
   Swash, MR
   Benini, S
   Leonardi, R
   Janjusevic, T
   Izquierdo, E
AF Schreer, Oliver
   Feldmann, Ingo
   Alonso Mediavilla, Isabel
   Concejero, Pedro
   Sadka, Abdul H.
   Swash, Mohammad Rafiq
   Benini, Sergio
   Leonardi, Riccardo
   Janjusevic, Tijana
   Izquierdo, Ebroul
TI RUSHES-an annotation and retrieval engine for multimedia semantic units
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rushes; Video retrieval; Annotation; Visualisation
AB Multimedia analysis and reuse of raw un-edited audio visual content known as rushes is gaining acceptance by a large number of research labs and companies. A set of research projects are considering multimedia indexing, annotation, search and retrieval in the context of European funded research, but only the FP6 project RUSHES is focusing on automatic semantic annotation, indexing and retrieval of raw and un-edited audio-visual content. Even professional content creators and providers as well as home-users are dealing with this type of content and therefore novel technologies for semantic search and retrieval are required. In this paper, we present a summary of the most relevant achievements of the RUSHES `project, focusing on specific approaches for automatic annotation as well as the main features of the final RUSHES search engine.
C1 [Benini, Sergio] Univ Brescia, Telecommun Grp DEA, Brescia, Italy.
   [Janjusevic, Tijana; Izquierdo, Ebroul] Univ London, Multimedia & Vis Grp, London, England.
   [Schreer, Oliver; Feldmann, Ingo] Heinrich Hertz Inst Nachrichtentech Berlin GmbH, Fraunhofer Inst Telecommun, Immers Media & 3D Video Grp, Image Proc Dept, Berlin, Germany.
   [Alonso Mediavilla, Isabel; Concejero, Pedro] Telefonica I D, Madrid, Spain.
   [Sadka, Abdul H.; Swash, Mohammad Rafiq] Brunel Univ, CMCR, London, England.
C3 University of Brescia; University of London; Fraunhofer Gesellschaft;
   Telefonica SA; Brunel University
RP Benini, S (corresponding author), Univ Brescia, Telecommun Grp DEA, Brescia, Italy.
EM oliver.schreer@hhi.fraunhofer.de; ingo.feldmann@hhi.fraunhofer.de;
   iam@tid.es; pedroc@tid.es; abdul.sadka@brunel.ac.uk;
   rafiq.swash@brunel.ac.uk; sergio.benini@ing.unibs.it;
   riccardo.leonardi@ing.unibs.it; tijana.janjusevic@elec.qmul.ac.uk;
   ebroul.izquierdo@elec.qmul.ac.uk
RI Leonardi, Riccardo/F-5666-2010
OI Leonardi, Riccardo/0000-0003-0755-1924; Swash,
   Rafiq/0000-0003-4242-7478; Schreer, Oliver/0000-0001-6900-8287
FU European Commission [FP6-045189]
FX This work is a result of the FP6 project "RUSHES" Proposal no.:
   FP6-045189, which is funded by the European Commission. We would also
   like to thank Leticia Fuentes Ardeo, Mikel Frutos Hernandez and
   journalists at EiTB for priceless help during the experimental
   evaluation.
CR Adcock John., 2008, CIVR 08, P465
   ALLEN JF, 1984, ARTIF INTELL, V23, P123, DOI 10.1016/0004-3702(84)90008-0
   [Anonymous], EUR C COMP VIS ECCV9
   [Anonymous], 2005, Proceedings of the SIGCHI conference on Human factors in computing systems
   ARDEO LF, 2008, REQUIREMENT ANAL USE
   Bederson BenjaminB., 2001, P ACM S USER INTERFA, P71
   BENINI S, 2006, P INT C IM PROC ICIP
   BENINI S, 2009, D21 REPORT FINAL DEV
   BENMOKHTAR R, 2006, TRECVID 2006
   Borth D, 2008, LECT NOTES ARTIF INT, V5243, P22, DOI 10.1007/978-3-540-85845-4_3
   Cho JW, 2004, LECT NOTES COMPUT SC, V2945, P498
   Duda R. O., 2000, PATTERN CLASSIFICATI
   FELDMANN I, 2008, IEEE 10 WORKSH MULT, P82
   Hearst MA, 1997, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P246, DOI 10.1145/278459.258582
   JANJUSEVIC T, 2009, J MULTIMEDI IN PRESS
   Jeannin S, 2001, IEEE T CIRC SYST VID, V11, P720, DOI 10.1109/76.927428
   Johnson B., 1991, Proceedings Visualization '91 (Cat. No.91CH3046-0), P284, DOI 10.1109/VISUAL.1991.175815
   Lamping J., 1994, UIST '94. Seventh Annual Symposium on User Interface Software and Technology. Proceedings of the ACM Symposium on User Interface Software and Technology, P13, DOI 10.1145/192426.192430
   LOZANO A, 2007, 8 INT WORKSH IM AN M
   Munzner T, 1998, IEEE COMPUT GRAPH, V18, P18, DOI 10.1109/38.689657
   OVER P, 2008, TVS 08, P1
   *PHAROS, IST45035 PHAROS
   Robertson G., 1998, UIST 98, P153, DOI DOI 10.1145/288392.288596
   ROBERTSON G.G., 1991, CHI 91, P189, DOI DOI 10.1145/108844.108883
   *RUSHES, FP6045189 RUSHES
   RUTLEDGE L, 1999, MOD MULT INF SYST C, P1
   Shade J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P231, DOI 10.1145/280814.280882
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Snoek CGM, 2005, MULTIMED TOOLS APPL, V25, P5, DOI 10.1023/B:MTAP.0000046380.27575.a5
   VILLA R, 2008, P 16 ACM INT C MULT, P489
   W3C, SYNCHR MULT INT LANG
NR 31
TC 5
Z9 5
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2010
VL 48
IS 1
SI SI
BP 23
EP 49
DI 10.1007/s11042-009-0375-8
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 575PM
UT WOS:000276079400003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Hölbling, G
   Pleschgatternig, M
   Kosch, H
AF Hoelbling, Guenther
   Pleschgatternig, Michael
   Kosch, Harald
TI PersonalTV - A TV recommendation system using program metadata for
   content filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE TV recommendation system; Content filtering; Metadata-based filtering;
   Bayesian classifier; Bayes; MPEG-7 profile; Metadata; Personalization;
   Recommendation system
AB This paper presents an approach to build a TV recommendation system called PersonalTV that enables the use of multiple classifiers, each one specialized on selected attributes of detailed program information. For generating adequate recommendations, the system makes use of content filtering and the preferences directly specified by the user within an MPEG-7 profile. By tracking user actions and interpreting their semantics, the system is able to individually weight these actions and dynamically adjusts the process to the user's evolving preferences. We show how specialized spam fighting methods can successfully be transferred to the area of recommendation systems and adapted accordingly. Being lightweight, these methods are especially applicable in resource-constrained environments such as TV set-top boxes or mobile devices. Moreover, the use of the variance of the beta-distribution as a confidence value for each recommendation is presented.
C1 [Hoelbling, Guenther; Pleschgatternig, Michael; Kosch, Harald] Univ Passau, Chair Distributed Informat Syst, Passau, Germany.
C3 University of Passau
RP Hölbling, G (corresponding author), Univ Passau, Chair Distributed Informat Syst, Passau, Germany.
EM hoelblin@fim.uni-passau.de; pleschga@fim.uni-passau.de;
   kosch@fim.uni-passau.de
OI Kosch, Harald/0000-0002-7090-1133
CR Ali K, 2004, KDD 04, P394, DOI DOI 10.1145/1014052.1014097
   [Anonymous], 2002, WALL STREET J
   [Anonymous], SPAM DETECTION
   [Anonymous], 2004, Hackers and Painters, Big Ideas from the Computer Age
   Bär A, 2008, LECT NOTES COMPUT SC, V5066, P143, DOI 10.1007/978-3-540-69478-6_18
   BERNHAUPT R, 2008, EUROITV, P92
   CLELANDHUANG J, 2008, USING DATA MINING RE, P3
   diaeresis>tze Hinrich Schu<spacing, 2008, INTRO INFORM RETRIEV, V39
   *EUR TEL STAND I, 2006, 10282231 ETSI TS
   *EUR TEL STAND I, 2008, 300468 ETS ES
   Fisher RA, 1970, STAT METHODS RES WOR, P66, DOI DOI 10.1007/978-1-4612-4380-9_6
   Garfinkel R, 2008, DECIS SUPPORT SYST, V46, P61, DOI 10.1016/j.dss.2008.05.006
   GOTARDO RA, 2008, COMPSAC 08, P460
   Graham P., 2003, BETTER BAYESIAN FILT
   Graham Paul., 2002, A PLAN FOR SPAM
   GUDE M, 2008, EUROITV, P117
   *ISO IEC, 2004, INF TECHN MULT CONT
   Leino J, 2007, RECSYS 07: PROCEEDINGS OF THE 2007 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P137
   LOUIS G, 2003, BOGOFILTER CALCULATI
   LOUIS G, 2003, TESTING BOGOFILTERS
   Martinez JM, 2003, JTC1SC29WG11 ISOIEC
   MELVILLE P, 2001, P 2001 SIGIR WORKSH
   Papanikolaou KA, 2006, INTERACT COMPUT, V18, P356, DOI 10.1016/j.intcom.2005.11.003
   REIMERS U, 2008, DVB DIGITALE FERNSEH
   ROBINSON G, 2004, HANDLING REDUNDANCY
   ROBINSON G, 2003, LINUX J, P3
   SALEMBIER P, 2002, INTRO MPEG 7, P83
   Segaran T., 2007, PROGRAMMING COLLECTI
   STUMPF S, 2007, IUI 07, P82
   WEISS D, 2008, DIMEA 08, P281
   ZDZIARSKI JA, 2005, NO STARCH SAN FRANCI
NR 31
TC 3
Z9 4
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2010
VL 46
IS 2-3
SI SI
BP 259
EP 288
DI 10.1007/s11042-009-0352-2
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 542GF
UT WOS:000273480300006
DA 2024-07-18
ER

PT J
AU Xiao, ZZ
   Dellandrea, E
   Dou, WB
   Chen, LM
AF Xiao, Zhongzhe
   Dellandrea, Emmanuel
   Dou, Weibei
   Chen, Liming
TI Multi-stage classification of emotional speech motivated by a
   dimensional emotion model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotional speech; Harmonic feature; Zipf feature; Dimensional emotion
   model; Multi-stage classification
AB This paper deals with speech emotion analysis within the context of increasing awareness of the wide application potential of affective computing. Unlike most works in the literature which mainly rely on classical frequency and energy based features along with a single global classifier for emotion recognition, we propose in this paper some new harmonic and Zipf based features for better speech emotion characterization in the valence dimension and a multi-stage classification scheme driven by a dimensional emotion model for better emotional class discrimination. Experimented on the Berlin dataset with 68 features and six emotion states, our approach shows its effectiveness, displaying a 68.60% classification rate and reaching a 71.52% classification rate when a gender classification is first applied. Using the DES dataset with five emotion states, our approach achieves an 81% recognition rate when the best performance in the literature to our knowledge is 76.15% on the same dataset.
C1 [Xiao, Zhongzhe; Dellandrea, Emmanuel; Chen, Liming] Univ Lyon, LIRIS Lab, UMR5205, CNRS,Ecole Cent Lyon, F-69134 Ecully, France.
   [Dou, Weibei] Tsinghua Univ, Tsinghua Natl Lab Informat Sci & Technol, Dept Elect Engn, Beijing 100084, Peoples R China.
C3 Ecole Centrale de Lyon; Institut National des Sciences Appliquees de
   Lyon - INSA Lyon; Centre National de la Recherche Scientifique (CNRS);
   Tsinghua University
RP Dellandrea, E (corresponding author), Univ Lyon, LIRIS Lab, UMR5205, CNRS,Ecole Cent Lyon, 36 Av Guy Collongue, F-69134 Ecully, France.
EM zhongzhe.xiao@ec-lyon.fr; emmanuel.dellandrea@ec-lyon.fr;
   douwb@mail.tsinghua.edu.cn; liming.chen@ec-lyon.fr
RI Dou, Weibei/K-6044-2012; Xiao, Zhongzhe/HJG-9564-2022
FU French government; PRA project Apollo [SI04-02]; CNRS [3597]
FX This work has received a scholarship awarded by the French government
   from 2004 to 2007 and was partly supported by a PRA project Apollo under
   the number SI04-02 and a PICS grant by CNRS under the number 3597.
CR [Anonymous], 2000, ENGLISHAND JAPANESE
   [Anonymous], P EUR SIGN PROC C
   [Anonymous], 2000, Proc. of the Speech-Emotion-2000
   [Anonymous], P ISCA WORKSH SPEECH
   [Anonymous], P ISCA WORKSH SPEECH
   [Anonymous], 2000, Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations
   ATAL BS, 1976, IEEE T ACOUST SPEECH, V24, P201, DOI 10.1109/TASSP.1976.1162800
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Bellman R. E., 1961, ADAPTIVE CONTROL PRO
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Breazeal C., 2001, DESIGNING SOCIAL ROB
   BRIAN CJ, 1997, INTRO PSYCHOL HEARIN
   BURKHARDT F, 2005, DAT GERM EM SPEECH P
   CHILDERS DG, 1989, IEEE T ACOUST SPEECH, V37, P1771, DOI 10.1109/29.46561
   Cohen A, 1997, FRACTALS, V5, P95, DOI 10.1142/S0218348X97000103
   Dellandréa E, 2004, FRACTALS, V12, P73, DOI 10.1142/S0218348X04002380
   Devillers L, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P549
   DRUIN A, 2000, ROBOTS FIDS EXPLORIN
   Ekman P., 1982, EMOTION HUMAN FACE
   Engberg I., 1996, DOCUMENTATION DANISH
   Harb H, 2005, J INTELL INF SYST, V24, P179, DOI 10.1007/s10844-005-0322-8
   HAVLIN S, 1995, PHYSICA A, V216, P148, DOI 10.1016/0378-4371(95)00069-J
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   KUSAHARA M, 2001, ARTIFICIAL LIFE 7 WO, P141
   McGilloway S., 2000, SpeechEmotion-2000, P207
   Morrison D, 2007, J NETW COMPUT APPL, V30, P1356, DOI 10.1016/j.jnca.2006.09.005
   Oudeyer P., 2003, INT J HUM-COMPUT ST, V59, P157, DOI DOI 10.1016/S1071-581(02)00141-6
   Picard R. W., 1997, AFFECTIVE COMPUTING
   Polzin T.S., 2000, P ISCA WORKSHOP SPEE, P201
   *PRAAT, 2001, GLOT INT, V5, P341
   Rakotomalala R., 2005, P EGC 2005 RNTI E 3, V2, P697
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Scherer K.R., 1988, P171
   Scherer K. R., 2001, Appraisal processes in emotion: Theory, methods, research, P92
   Scherer K.R., 1989, Handbook of Psychophysiology, P165
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   SCHERER KR, 2000, P ICSLP2000
   Schuller B, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P865
   SCHULLER B, 2003, P ICASSP, V1
   Schuller B., 2004, Proceedings of ICASSP, V1, pI
   Schuller B, 2008, INT CONF ACOUST SPEE, P4501, DOI 10.1109/ICASSP.2008.4518656
   Schuller B, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P5, DOI 10.1109/ICME.2006.262500
   SLANEY M, 1998, P ICASSP 1998 SEATTL
   Spence C, 1998, P SOC PHOTO-OPT INS, V3338, P1434, DOI 10.1117/12.310875
   Thayer Robert E., 1990, The Biopsychology of Mood and Arousal
   Ververidis D, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P1501
   Ververidis D, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P593
   VOGHT T, 2005, P MULT EXP ICME 2005, P474
   WATSON D, 1985, PSYCHOL BULL, V98, P219, DOI 10.1037/0033-2909.98.2.219
   Wieezorkowska A, 2005, LECT NOTES COMPUT SC, V3488, P456
   XIAO Z, 2007, RRLIRIS2007006 UMR C
   Xiao Z., 2006, INT C DIGITAL TELECO, P32
   Xiao ZZ, 2007, IEEE INT SYM MULTIM, P291, DOI 10.1109/ISM.Workshops.2007.56
   Xiao ZZ, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P411
   Zipf GK, 1950, J CLIN PSYCHOL, V6, P306
NR 55
TC 22
Z9 23
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2010
VL 46
IS 1
BP 119
EP 145
DI 10.1007/s11042-009-0319-3
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 537DQ
UT WOS:000273093600006
DA 2024-07-18
ER

PT J
AU Ahmed, DT
   Shirmohammadi, S
   de Oliveira, JC
AF Ahmed, Dewan Tanvir
   Shirmohammadi, Shervin
   de Oliveira, Jauvane C.
TI A hybrid P2P communications architecture for zonal MMOGs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MMOG; Area of interest management; Fault tolerance; Multi-user
   interaction; Networked games
ID NETWORK
AB Distributed Virtual Environments are becoming more popular in today's computing and communications among people. Perhaps the most widely used form of such environments is Massively Multiplayer Online Games (MMOG), which are in the form of client/server architecture that requires considerable server resources to manage a large number of distributed players. Peer-to-peer communication can achieve scalability at lower cost but may introduce other difficulties. Synchronous communication is a prime concern for multi-user collaborative applications like MMOGs where players need frequently interaction with each other to share their game states. In this article, we present a hybrid MMOG architecture called MM-VISA (Massively Multiuser VIrtual Simulation Architecture). In this architecture, servers and peers are coupled together to take the inherent advantages of the centralized architecture and the scalability of distributed systems. As the virtual world is decomposed into smaller manageable zones, the players' random movement causes reorganization at the P2P overlay structure. The frequent nature of movements along with unintelligent zone crossing approaches, currently implemented in MMOGs, breaks synchronous communication. To limit such problem, we consider players' gaming characteristics to intelligently define routing paths. A graph-theoretic framework is incorporated for overlay oriented real-time distributed virtual environments. We shall show that interest-driven zone crossing, dynamic shared region between adjacent zones, and clustering of entities based on their attributes significantly decrease unstable overlay situations. The effectiveness of the presented system is justified through simulation.
C1 [Ahmed, Dewan Tanvir; Shirmohammadi, Shervin] Univ Ottawa, Sch Informat Technol & Engn, Distributed & Collaborat Virtual Environm Res Lab, Ottawa, ON, Canada.
   [de Oliveira, Jauvane C.] Natl Lab Sci Comp, Dept Comp Sci, ACiMA Lab, Rio De Janeiro, Brazil.
C3 University of Ottawa; Laboratorio Nacional de Computacao Cientifica
   (LNCC)
RP Ahmed, DT (corresponding author), Univ Ottawa, Sch Informat Technol & Engn, Distributed & Collaborat Virtual Environm Res Lab, Ottawa, ON, Canada.
EM dahmed@discover.uottawa.ca; shervin@discover.uottawa.ca; jauvane@acm.org
RI de Oliveira, Jauvane C./Q-8242-2019; Macc, Inct/K-3440-2013;
   Shirmohammadi, Shervin/E-6945-2012
OI de Oliveira, Jauvane C./0000-0002-7522-7846; Shirmohammadi,
   Shervin/0000-0002-3973-4445
CR Ahmed DT, 2006, IEEE INT WORKSH HAPT, P165
   AHMED DT, 2007, MULTIMEDIA 07 P 15 I, P581
   ASSIOTIS M, 2006, NETGAMES 06, P4
   Banerjee S, 2002, ACM SIGCOMM COMP COM, V32, P205, DOI 10.1145/964725.633045
   Borella MS, 2000, COMPUT COMMUN, V23, P403, DOI 10.1016/S0140-3664(99)00197-8
   CHAMBERS C, 2005, IMC 05, P1
   Claypool M, 2006, COMMUN ACM, V49, P40, DOI 10.1145/1167838.1167860
   *DFC INT, 2003, CHALL OPP ONL GAM MA
   Diot C, 2000, IEEE NETWORK, V14, P78, DOI 10.1109/65.819174
   El-Sayed A, 2003, IEEE NETWORK, V17, P46, DOI 10.1109/MNET.2003.1174177
   Guizzo E, 2008, IEEE SPECTRUM, V45, P44, DOI 10.1109/MSPEC.2008.4586287
   Hosseini M, 2007, IEEE COMMUN SURV TUT, V9, P58, DOI 10.1109/COMST.2007.4317616
   Hu SY, 2006, IEEE NETWORK, V20, P22, DOI 10.1109/MNET.2006.1668400
   *IEEE, 1998, IEEE STAND DISTR INT
   Iimura T., 2004, P 3 ACM SIGCOMM WORK, P116, DOI DOI 10.1145/1016540.1016549
   Knutsson B., 2004, PEER TO PEER SUPPORT
   LANG T, 2004, ACE 04, P233
   Léty E, 2004, IEEE ACM T NETWORK, V12, P247, DOI 10.1109/TNET.2004.826276
   Oliveira J.C., 2003, Presence, V12, P555
   Park KS, 1999, P IEEE VIRT REAL ANN, P104, DOI 10.1109/VR.1999.756940
   PULLEN JM, 1999, DIS RT 99, P59
   Shirmohammadi S, 2001, COMPUT NETW, V35, P351, DOI 10.1016/S1389-1286(00)00186-9
   SMED J, 2001, INT C APPL DEV COMP, P74
   Sun Q, 2005, PROCEEDINGS OF THE EIGHTH IASTED INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND CONTROL, P19
   VARVELLO M, 2007, NETGAMES 07, P105
   Wu J., 1999, DIAL M 99, P7
   Yu A., 2005, Proceedings of the 15th International Workshop on Network and Operating Systems Support for Digital Audio and Video. NOSSDAV 2005, P99, DOI 10.1145/1065983.1066007
NR 27
TC 7
Z9 11
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2009
VL 45
IS 1-3
SI SI
BP 313
EP 345
DI 10.1007/s11042-009-0311-y
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 490VE
UT WOS:000269534900014
DA 2024-07-18
ER

PT J
AU Gao, Y
   Wang, WB
   Yong, JH
   Gu, HJ
AF Gao, Yue
   Wang, Wei-Bo
   Yong, Jun-Hai
   Gu, He-Jin
TI Dynamic video summarization using two-level redundancy detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video summarization; Redundancy detection; Cast indexing; Important
   factor
ID SCENE DETECTION; REPRESENTATION; ALGORITHM; QUERY
AB The mushroom growth of video information, consequently, necessitates the progress of content-based video analysis techniques. Video summarization, aiming to provide a short video summary of the original video document, has drawn much attention these years. In this paper, we propose an algorithm for video summarization with a two-level redundancy detection procedure. By video segmentation and cast indexing, the algorithm first constructs story boards to let users know main scenes and cast (when this is a video with cast) in the video. Then it removes redundant video content using hierarchical agglomerative clustering in the key frame level. The impact factors of scenes and key frames are defined, and parts of key frames are selected to generate the initial video summary. Finally, a repetitive frame segment detection procedure is designed to remove redundant information in the initial video summary. Results of experimental applications on TV series, movies and cartoons are given to illustrate the proposed algorithm.
C1 [Gao, Yue] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.
   [Wang, Wei-Bo; Yong, Jun-Hai] Tsinghua Univ, Sch Software, Beijing 100084, Peoples R China.
   [Gu, He-Jin] Jiangxi Acad Sci, Nanchang, Peoples R China.
C3 Tsinghua University; Tsinghua University; Jiangxi Academy of Sciences
RP Gao, Y (corresponding author), Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.
EM kevin.gaoy@gmail.com
RI Gao, Yue/B-3376-2012
CR [Anonymous], 2007, P IEEE MILCOM 2007
   [Anonymous], P 6 ACM INT C IM VID
   Benini S, 2006, IEEE IMAGE PROC, P133, DOI 10.1109/ICIP.2006.312377
   Calic J, 2007, IEEE T CIRC SYST VID, V17, P931, DOI 10.1109/TCSVT.2007.897466
   Cerneková Z, 2006, IEEE T CIRC SYST VID, V16, P82, DOI 10.1109/TCSVT.2005.856896
   CHENG W, 2003, P 2 IEEE INT C MACH, V5, P2896
   Ciocca G, 2006, IEEE T CONSUM ELECTR, V52, P630, DOI 10.1109/TCE.2006.1649689
   Ferman AM, 2003, IEEE T MULTIMEDIA, V5, P244, DOI 10.1109/TMM.2003.811617
   Gong YH, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P362, DOI 10.1109/ICIP.2001.958126
   Jain AK, 1999, MULTIMEDIA SYST, V7, P369, DOI 10.1007/s005300050139
   Kim SH, 2002, IEEE T CIRC SYST VID, V12, P592, DOI 10.1109/TCSVT.2002.800512
   Koprinska I, 2001, SIGNAL PROCESS-IMAGE, V16, P477, DOI 10.1016/S0923-5965(00)00011-4
   LEE J, 2005, P ACM INT C MULT ACM, P810
   Li Y, 2006, LECT NOTES COMPUT SC, V3979, P29
   Li Z, 2005, IEEE T IMAGE PROCESS, V14, P1550, DOI 10.1109/TIP.2005.854477
   Liu TC, 2006, IEEE IMAGE PROC, P145, DOI 10.1109/ICIP.2006.312380
   Lu S, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 2, PROCEEDINGS, P197
   Ngo CW, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P104, DOI 10.1109/ICCV.2003.1238320
   Otsuka I, 2005, IEEE T CONSUM ELECTR, V51, P112, DOI 10.1109/TCE.2005.1405707
   Peker KA, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1053, DOI 10.1109/ICME.2006.262715
   Peng YX, 2006, IEEE T CIRC SYST VID, V16, P612, DOI 10.1109/TCSVT.2006.873157
   Porter SV, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P460, DOI 10.1109/ICIAP.2003.1234093
   Rasheed Z, 2005, IEEE T MULTIMEDIA, V7, P1097, DOI 10.1109/TMM.2005.858392
   Rasheed Z, 2003, PROC CVPR IEEE, P343
   Schaefer K, 2006, AM J PHYS ANTHROPOL, V129, P132, DOI 10.1002/ajpa.20224
   SHIPMAN S, 2006, P INT C CONS EL IEEE, P201
   SMITH TF, 1981, J MOL BIOL, V147, P195, DOI 10.1016/0022-2836(81)90087-5
   Song B, 2006, IEEE IMAGE PROC, P2925, DOI 10.1109/ICIP.2006.313131
   Sze KW, 2005, IEEE T CIRC SYST VID, V15, P1148, DOI 10.1109/TCSVT.2005.852623
   Uchihashi S, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P383, DOI 10.1145/319463.319654
   You JY, 2007, IEEE T CIRC SYST VID, V17, P273, DOI 10.1109/TCSVT.2007.890857
   Zabih R, 1999, MULTIMEDIA SYST, V7, P119, DOI 10.1007/s005300050115
   Zhu XQ, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P333
NR 33
TC 35
Z9 36
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2009
VL 42
IS 2
BP 233
EP 250
DI 10.1007/s11042-008-0236-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 415EY
UT WOS:000263918300005
DA 2024-07-18
ER

PT J
AU Lindstaedt, S
   Mörzinger, R
   Sorschag, R
   Pammer, V
   Thallinger, G
AF Lindstaedt, Stefanie
   Moerzinger, Roland
   Sorschag, Robert
   Pammer, Viktoria
   Thallinger, Georg
TI Automatic image annotation using visual content and folksonomies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Auto-annotation; Tagging; Image retrieval; Classification
AB Automatic image annotation is an important and challenging task, and becomes increasingly necessary when managing large image collections. This paper describes techniques for automatic image annotation that take advantage of collaboratively annotated image databases, so called visual folksonomies. Our approach applies two techniques based on image analysis: First, classification annotates images with a controlled vocabulary and second tag propagation along visually similar images. The latter propagates user generated, folksonomic annotations and is therefore capable of dealing with an unlimited vocabulary. Experiments with a pool of Flickr images demonstrate the high accuracy and efficiency of the proposed methods in the task of automatic image annotation. Both techniques were applied in the prototypical tag recommender "tagr".
C1 [Moerzinger, Roland; Sorschag, Robert; Thallinger, Georg] Inst Informat Syst & Informat Management, Joanneum Res, A-8010 Graz, Austria.
   [Lindstaedt, Stefanie; Pammer, Viktoria] Know Ctr KMI TU Graz, Graz, Austria.
C3 Graz University of Technology
RP Mörzinger, R (corresponding author), Inst Informat Syst & Informat Management, Joanneum Res, Steyrergasse 17, A-8010 Graz, Austria.
EM slind@know-center.at; roland.moerzinger@joanneum.at;
   robert.sorschag@joanneum.at; vpammer@know-center.at;
   georg.thallinger@joanneum.at
OI Pammer-Schindler, Viktoria/0000-0001-7061-8947
CR AURNHAMMER M, 2006, P WWW2006 COLL WEB T
   AYACHE S, 2007, EUR C INF RETR ROM 2
   Breese J., 1998, P 14 C UNC ART INT, P43
   CHAKRABARTI K, 1999, P 15 INT C DAT ENG W
   Chang C. C., 2008, LIBSVM LIB SUPPORT V
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   CUSANO C, 2003, P INT IM, V4
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DATTA R, 2005, MIR 05
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   Golder SA, 2006, J INF SCI, V32, P198, DOI 10.1177/0165551506062337
   HARDOON DR, 2006, SPRINGER LNAI, V4093, P681
   Jeon J., 2003, Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P119, DOI DOI 10.1145/860435.860459
   KERN R, 2008, 9 INT WORKSH IM AN M
   LI X, 2006, P ACM INT C MULT SAN
   LINDSTAEDT S, 2008, P 3 INT C INT WEB AP
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   MORZINGER R, 2007, P TRECVID WORKSH GAI
   PAMMER V, 2008, W VERLAG CHAP TAGR U
   Ponce J, 2002, COMPUTER VISION MODE, DOI 10.5555/580035
   SHAW B, 2006, LEARNING VISUAL FOLK
   Sigurbjornsson B., 2008, P 17 INT C WORLD WID
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   WANG X, 2006, P INT C COMP VIS PAT
   Yavlinsky A, 2005, LECT NOTES COMPUT SC, V3568, P507
   Young IT, 2002, IEEE T SIGNAL PROCES, V50, P2798, DOI 10.1109/TSP.2002.804095
NR 27
TC 35
Z9 44
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2009
VL 42
IS 1
SI SI
BP 97
EP 113
DI 10.1007/s11042-008-0247-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 403XX
UT WOS:000263116400006
DA 2024-07-18
ER

PT J
AU Yoon, JC
   Lee, IK
   Byun, S
AF Yoon, Jong-Chul
   Lee, In-Kwon
   Byun, Siwoo
TI Automated music video generation using multi-level feature-based
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music video generation; Multi-media analysis; Music and video
   synchronization
AB We show how to create a music video automatically, using computable characteristics of the video and music to promote coherent matching. We analyze the flow of both music and video, and then segment them into sequences of near-uniform flow. We extract features from the both video and music segments, and then find matching pairs. The granularity of the matching process can be adapted by extending the segmentation process to several levels. Our approach drastically reduces the skill required to make simple music videos.
C1 [Yoon, Jong-Chul; Lee, In-Kwon] Yonsei Univ, Dept Comp Sci, Seoul 120749, South Korea.
   [Byun, Siwoo] Anyang Univ, Dept Digital Media, Anyang, South Korea.
C3 Yonsei University; Anyang University
RP Lee, IK (corresponding author), Yonsei Univ, Dept Comp Sci, Seoul 120749, South Korea.
EM media19@cs.yonsei.ac.kr; iklee@yonsei.ac.kr; swbyun@anyang.ac.kr
RI Lee, In-Kwon/AGP-6124-2022
OI Lee, In-Kwon/0000-0002-1534-1882
FU Korea Culture & Content Agency (KOCCA)
FX This research is accomplished as the result of the promotion project for
   culture contents technology research center supported by Korea Culture &
   Content Agency (KOCCA).
CR [Anonymous], 2003, P 11 ACM INT C MULTI, DOI DOI 10.1145/957013.957094
   *AV TECHN INC, 2007, US GUID PINN STUD 11
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Foote J., 2002, P ACM MULTIMEDIA 200, P553, DOI DOI 10.1145/641007.641119
   Gose E., 1996, PATTERN RECOGNITION
   Goto M, 2001, J NEW MUSIC RES, V30, P159, DOI 10.1076/jnmr.30.2.159.7114
   Helmholtz H, 1954, SENSATION TONE PHYSL
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Hua X.S., 2003, P 11 ACM INT C MULTI, P490
   HUA XS, 2004, 12 ACM INT C MULT AC, P472
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   JEHAN T, 2003, SIGGRAPH C ABSTR APP, P27
   LAN DJ, 2003, P IEEE INT C MULT EX, P6
   LEE HC, 2005, P EUROGRAPHICS 2005, P353
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Mulhem P, 2003, IEEE MULTIMEDIA, V10, P28, DOI 10.1109/MMUL.2003.1195159
   Scheirer ED, 1998, J ACOUST SOC AM, V103, P588, DOI 10.1121/1.421129
   Tekalp A.M., 1995, DIGITAL VIDEO PROCES
NR 18
TC 15
Z9 15
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2009
VL 41
IS 2
BP 197
EP 214
DI 10.1007/s11042-008-0225-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Engineering
GA 387NI
UT WOS:000261958500002
DA 2024-07-18
ER

PT J
AU Shan, MK
   Chiang, MF
   Kuo, FF
AF Shan, Man-Kwan
   Chiang, Meng-Fen
   Kuo, Fang-Fei
TI Relevance feedback for category search in music retrieval based on
   semantic concept learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE category search; music retrieval; relevance feedback; semantic concept
   learning
ID IMAGE RETRIEVAL
AB Traditional content-based music retrieval systems retrieve a specific music object which is similar to what a user has requested. However, the need exists for the development of category search for the retrieval of a specific category of music objects which share a common semantic concept. The concept of category search in content-based music retrieval is subjective and dynamic. Therefore, this paper investigates a relevance feedback mechanism for category search of polyphonic symbolic music based on semantic concept learning. For the consideration of both global and local properties of music objects, a segment-based music object modeling approach is presented. Furthermore, in order to discover the user semantic concept in terms of discriminative features of discriminative segments, a concept learning mechanism based on data mining techniques is proposed to find the discriminative characteristics between relevant and irrelevant objects. Moreover, three strategies, the Most-Positive, the Most-Informative, and the Hybrid, to return music objects concerning user relevance judgments are investigated. Finally, comparative experiments are conducted to evaluate the effectiveness of the proposed relevance feedback mechanism. Experimental results show that, for a database of 215 polyphonic music objects, 60% average precision can be achieved through the use of the proposed relevance feedback mechanism.
C1 [Shan, Man-Kwan; Chiang, Meng-Fen] Natl Chengchi Univ, Dept Comp Sci, Taipei 11623, Taiwan.
   [Kuo, Fang-Fei] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
C3 National Chengchi University; National Yang Ming Chiao Tung University
RP Shan, MK (corresponding author), Natl Chengchi Univ, Dept Comp Sci, 64 Chihnan Rd,Sec 2 Wenshan, Taipei 11623, Taiwan.
EM mkshan@cs.nccu.edu.tw; g9309@cs.nccu.edu.tw; ffkuo@csie.nctu.edu.tw
CR Agrawal R., 1994, P INT VLDB C VLDB 94, P487, DOI DOI 10.5555/645920.672836
   [Anonymous], 1998, P 4 INT C KNOWLEDGE
   Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   Chai W, 2006, IEEE SIGNAL PROC MAG, V23, P124
   Doulamis ND, 2003, IEEE MULTIMEDIA, V10, P38, DOI 10.1109/MMUL.2003.1237549
   Foote JT, 1997, P SOC PHOTO-OPT INS, V3229, P138, DOI 10.1117/12.290336
   GONDRA HDR, 2004, P IEEE COMP VIS PATT
   He XF, 2003, IEEE T CIRC SYST VID, V13, P39, DOI 10.1109/TCSVT.2002.808087
   Hoashi K., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P385
   HOASHI K, 2003, P 11 ACM INT C MULT, P110
   Hsu JL, 2001, IEEE T MULTIMEDIA, V3, P311, DOI 10.1109/6046.944475
   Jing F, 2004, IEEE T IMAGE PROCESS, V13, P699, DOI 10.1109/TIP.2004.826125
   Jing F, 2004, IEEE T CIRC SYST VID, V14, P672, DOI 10.1109/TCSVT.2004.826775
   KUO FF, 2002, P IEEE INT C MULT EX
   Liu CC, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P451, DOI 10.1109/MMCS.1999.779244
   Mandel MI, 2006, MULTIMEDIA SYST, V12, P3, DOI 10.1007/s00530-006-0032-2
   Mandl T, 2003, J NEW MUSIC RES, V32, P133, DOI 10.1076/jnmr.32.2.133.16747
   MANDL T, 2002, P INT C MUS INF RETR
   MERMELSTEIN D, 1980, IEEE T ACOUSTICS SPE, V28
   Pardo B, 2006, COMMUN ACM, V49, P28, DOI 10.1145/1145287.1145309
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   SHAN MK, 2007, IEEE MULTIMEDI UNPUB
   Stein Leon., 1979, STRUCTURE STYLE
   Tong S, 2001, P 9 ACM INT C MULT, P107, DOI DOI 10.1145/500141.500159
   UITDENBGERD ZJ, 1999, P ACM INT C MULT OCT, P57
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
NR 26
TC 5
Z9 5
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2008
VL 39
IS 2
BP 243
EP 262
DI 10.1007/s11042-008-0201-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 322NA
UT WOS:000257381400006
DA 2024-07-18
ER

PT J
AU Gançarski, P
   Wemmert, C
AF Gancarski, Pierre
   Wemmert, Cedric
TI Collaborative multi-step mono-level multi-strategy classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE complex data; collaborative clustering; classification combining;
   per-pixel image analysis
ID ALGORITHMS
AB This article deals with the description of a new way to learn from multiple and heterogeneous data sets, and with the integration of this method in a multi-agent hybrid learning system. This system integrates different kinds of unsupervised classification methods and gives a set of clusterings as the result and a unifying result, representing all the other one. In this new approach, the method occurrences compare their results and automatically refine them to try to make them converge towards a unique clustering that unifies all the results. Thus, the data are not really merged but the results from their classification are compared and refined according to the results from all the other data sets. This enables to produce a set of classification hierarchies which classes are very similar, although these hierarchies were extracted from different data sets. Then it is easy to build a unifying result from all of them.
C1 Univ Louis Pasteur Strasbourg 1, LSIIT, AFD, UMR,CNRS,ULP, Strasbourg, France.
C3 Universites de Strasbourg Etablissements Associes; Universite de
   Strasbourg; Centre National de la Recherche Scientifique (CNRS)
RP Gançarski, P (corresponding author), Univ Louis Pasteur Strasbourg 1, LSIIT, AFD, UMR,CNRS,ULP, Strasbourg, France.
EM gancarski@lsiit.u-strasbg.fr; wemmert@lsiit.u-strasbg.fr
RI Gançarski, Pierre/D-1346-2009; WEMMERT, Cédric/B-6836-2009
OI WEMMERT, Cédric/0000-0002-4360-4918
CR Alpaydin E, 1998, KYBERNETIKA, V34, P369
   Alpaydin E., 1998, Proceedings of Engineering of Intelligent Systems, V2, P6
   Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169
   Binaghi E, 1997, P SOC PHOTO-OPT INS, V3217, P306, DOI 10.1117/12.295616
   Breiman L, 1998, ANN STAT, V26, P801
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655
   Fisher D. H., 1987, Machine Learning, V2, P139, DOI 10.1007/BF00114265
   Frigui H, 2004, PATTERN RECOGN, V37, P567, DOI 10.1016/j.patcog.2003.08.002
   GAMA J, 1998, P ECML 98, V1398, P178
   Grabmeier J, 2002, DATA MIN KNOWL DISC, V6, P303, DOI 10.1023/A:1016308404627
   Halkidi M, 2002, SIGMOD RECORD, V31, P40, DOI 10.1145/565117.565124
   Halkidi M, 2001, J INTELL INF SYST, V17, P107, DOI 10.1023/A:1012801612483
   HAMMADMESMOUDI F, 1995, P INT C IMAG PROC
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   He J., 2002, INFORM RETRIEVAL CLU
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   KORCZAK JJ, 1994, P EUR S SAT REM SENS
   KORCZAK JJ, 1993, APPL CLASSICAL CLUST
   PAREDIS J, 1997, 7 INT C GEN ALG ICGA, P393
   QUINLAN J, 1996, P 7 INT WORKSH ALG L, V1160, P143
   Roli Fabio., 2001, LECT NOTES COMPUTER, V2096
   Schapire RE, 1999, LECT NOTES ARTIF INT, V1572, P1
   Ting K., 1999, KNOWL INF SYST, V1, P83
   Ting KM, 1999, J ARTIF INTELL RES, V10, P271, DOI 10.1613/jair.594
   Wemmert C., 2002, Proceedings of the Second IASTED International Conference. Artificial Intelligence and Applications, P447
   Wemmert C., 2000, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V9, P59, DOI 10.1142/S0218213000000069
   WEMMERT C, 2002, P 23 URB DAT MAN S U
   WOLPERT DH, 1990, LAUR903460
   XIE XLL, 1991, IEEE T PATTERN ANAL, V13, P841, DOI 10.1109/34.85677
NR 31
TC 8
Z9 8
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2007
VL 35
IS 1
BP 1
EP 27
DI 10.1007/s11042-007-0115-x
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 209RY
UT WOS:000249406900001
DA 2024-07-18
ER

PT J
AU Varde, A
   Rundensteiner, E
   Ruiz, C
   Maniruzzaman, M
   Sisson, R
AF Varde, Aparna
   Rundensteiner, Elke
   Ruiz, Carolina
   Maniruzzaman, Mohammed
   Sisson, Richard, Jr.
TI LearnMet: learning domain-specific distance metrics for plots of
   scientific functions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE distance metrics; clustering; domain semantics; parameter learning;
   curve comparison
AB Scientific experimental results are often depicted as plots of functions to aid their visual analysis and comparison. In computationally comparing these plots using techniques such as similarity search and clustering, the notion of similarity is typically distance. However, it is seldom known which distance metric(s) best preserve(s) semantics in the respective domain. It is thus desirable to learn such domain-specific distance metrics for the comparison of plots. This paper describes a technique called LearnMet proposed to learn such metrics. The input to LearnMet is a training set with actual clusters of plots. These are iteratively compared with clusters over the same plots predicted using an arbitrary but fixed clustering algorithm. Using a guessed initial metric for clustering, adjustments are made to the metric in each epoch based on the error between the predicted and actual clusters until the error is minimal or below a given threshold. The metric giving the lowest error is output as the learned metric. The proposed LearnMet technique and its enhancements are discussed in detail in this paper. The primary application of LearnMet is clustering plots in the Heat Treating domain. Hence it is rigorously evaluated using Heat Treating data. Given distinct test sets for evaluation, clusters of plots predicted using the learned metrics are compared with given actual clusters over the same plots. The extent to which the predicted and actual clusters match each other denotes the accuracy of the learned metrics.
C1 Virginia State Univ, Petersburg, VA 23806 USA.
   Worcester Polytech Inst, Dept Comp Sci, Worcester, MA 01609 USA.
   Ctr Heart Treat Excellence, Metal Process Inst, Worcester, MA 01609 USA.
C3 Virginia State University; Worcester Polytechnic Institute
RP Varde, A (corresponding author), Virginia State Univ, Petersburg, VA 23806 USA.
EM avarde@vsu.edu; rundenst@cs.wpi.edu; ruiz@cs.wpi.edu; maniruzz@wpi.edu;
   sisson@wpi.edu
RI Maniruzzaman, Mohammed/AAC-8248-2019
CR [Anonymous], 2000, Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations
   BISHOP C, 1909, NEURLA NETWORKS PATT
   FRIEDBERG RM, 1958, IBM J RES DEV, V2, P2, DOI 10.1147/rd.21.0002
   Han J., 2012, Data Mining, P393, DOI [DOI 10.1016/B978-0-12-381479-1.00009-5, 10.1016/B978-0-12-381479-1.00009-5]
   KAUFMAN L, 1988, FINDING GROUPS DATA
   KEIM D, 2004, ICDE, P873
   MacQueen J, 1967, MATH STAT PROBABILIT, V1, P281
   MANIRUZZAMAN M, 2002, ICFDM
   PETTRUCELLI J, 1999, APPL STAT ENG SCI
   TRAINA A, 2001, ACM KDD, P184
   VARDE A, 2006, THESIS WORCESTER POL
   VARDE A, 2005, ACM SIGARTS ICICIS, P603
   XING E, 2003, NIPS, P503
   Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X
NR 14
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2007
VL 35
IS 1
BP 29
EP 53
DI 10.1007/s11042-007-0120-0
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 209RY
UT WOS:000249406900002
DA 2024-07-18
ER

PT J
AU Tran, M
   Tavanapong, W
   Putthividhya, W
AF Tran, Minh
   Tavanapong, Wallapak
   Putthividhya, Wanida
TI OCS: An effective caching scheme for video streaming on overlay networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video streaming; video caching; overlay networks; cache collaboration
AB Video streaming is vital for many important applications such as distance learning, digital video libraries, and movie-on-demand. Since video streaming requires significant server and networking resources, caching has been used to reduce the demand on these resources. In this paper, we propose a novel collaboration scheme for video caching on overlay networks, called Overlay Caching Scheme (OCS), to further minimize service delays and loads placed on an overlay network for video streaming applications. OCS is not a centralized nor a hierarchical collaborative scheme. Despite its design simplicity, OCS effectively uses an aggregate storage space and capability of distributed overlay nodes to cache popular videos and serve nearby clients. Moreover, OCS is light-weight and adaptive to clients' locations and request patterns. We also investigate other video caching techniques for overlay networks including both collaborative and non-collaborative ones. Compared with these techniques on topologies inspired from actual networks, OCS offers extremely low average service delays and approximately half the server load. OCS also offers smaller network load in most cases in our study.
C1 Iowa State Univ, Dept Comp Sci, Ames, IA 50011 USA.
C3 Iowa State University
RP Tavanapong, W (corresponding author), Iowa State Univ, Dept Comp Sci, Ames, IA 50011 USA.
EM ttminh@cs.iastate.edu; tavanapo@cs.iastate.edu; wanidap@cs.iastate.edu
RI Tran, Minh Xuan/HDN-2680-2022
CR Acharya S., 2000, FAKIR MOHANKRUTA RAM
   [Anonymous], P SIGCOMM 01, DOI DOI 10.1145/383059.383071
   Antony I., 2001, LECT NOTES COMPUTER, P329, DOI DOI 10.1007/3-540-45518-3_18
   Banerjee S., 2002, P ACM SIGCOMM 2002 P
   Castro M., 2003, Operating Systems Review, V37, P298, DOI 10.1145/1165389.945474
   CHAWATHE Y, 2000, THESIS U CALIFORNIA
   Chu YH, 2000, PERF E R SI, V28, P1, DOI 10.1145/345063.339337
   Chun B, 2003, ACM SIGCOMM COMP COM, V33, P3, DOI 10.1145/956993.956995
   CLARKE I, 2000, P WORKSH DES ISS AN, P46
   DABEK F, 2001, P 18 ACM S OP SYST P, P202
   Dan A, 1996, MULTIMEDIA SYST, V4, P112, DOI 10.1007/s005300050016
   Dykes SG, 2001, IEEE INFOCOM SER, P1205, DOI 10.1109/INFCOM.2001.916614
   EAGER DL, 1999, P IS T SPIE C MULT C, P301
   FAN L, 1998, P ACM SIGCOMM, P254
   Hua KA, 2000, P SOC PHOTO-OPT INS, V3969, P2
   Jannotti J, 2000, USENIX ASSOCIATION PROCEEDINGS OF THE FOURTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P197
   Kangasharju J, 2001, IEEE INFOCOM SER, P1791, DOI 10.1109/INFCOM.2001.916677
   KARGER D, 1999, P 8 INT WORLD WID WE
   Kim M.S., 2003, PROC INT C DISTRIBUT, P116
   Kostic D., 2003, Operating Systems Review, V37, P282, DOI 10.1145/1165389.945473
   *LETSQOS, 2004, AT T POP LEV NETW TO
   LIEBEHERR J, 2001, P IEEE GLOBECOM SAN
   MILLER GJ, 1998, P INT 98 ENG C
   Nguyen TP, 2002, PROC SPIE, V4673, P186
   Paknikar S., 2000, Proceedings ACM Multimedia 2000, P13, DOI 10.1145/354384.354397
   Park YW, 2000, P INT COMP SOFTW APP, V24, P389, DOI 10.1109/CMPSAC.2000.884754
   Pendarakis D, 2001, USENIX ASSOCIATION PROCEEDINGS OF THE 3RD USENIX SYMPOSIUM ON INTERNET TECHNOLOGIES AND SYSTEMS, P49
   Ramesh S, 2001, IEEE INFOCOM SER, P85, DOI 10.1109/INFCOM.2001.916690
   Ratnasamy S., 2001, Proceedings of the 2001 conference on applications, technologies, architectures, and protocols for computer communications, P161
   RATNASAMY S, 2001, P 3 INT WORKSH NETW, P14
   Rejaie R., 2000, Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064), P980, DOI 10.1109/INFCOM.2000.832273
   ROWSTRON A, 2001, P 18 ACM S OP SYST P, P188
   Sen S, 1999, IEEE INFOCOM SER, P1310, DOI 10.1109/INFCOM.1999.752149
   SYSTEMS C, 2003, CISCO CCS 11500 SERI
   TRAN M, 2002, TR0211 IOW STAT U DE
   *UCB LBNL VINT, 2000, NETW SIM NS
   Wang B, 2002, IEEE INFOCOM SER, P1726, DOI 10.1109/INFCOM.2002.1019426
   WANG J, 1999, COMPUT COMMUN, V29, P36
   WOLMAN A, 1999, P 17 ACM S OP SYST P
   Xu DY, 2002, P SOC PHOTO-OPT INS, V4673, P171
   ZHANG B, 2002, P IEEE INFOCOM 2002
   Zhang ZL, 2000, IEEE ACM T NETWORK, V8, P429, DOI 10.1109/90.865072
   ZHAO Y, 2002, P ACM SPIE C MULT CO, P142
   ZHUANG S, 2001, P 11 INT WORKSH NETW
   Zipf GK, 1950, J CLIN PSYCHOL, V6, P306
NR 45
TC 2
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2007
VL 34
IS 1
BP 25
EP 56
DI 10.1007/s11042-006-0071-x
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 169VE
UT WOS:000246619400002
DA 2024-07-18
ER

PT J
AU Thuraisingham, B
AF Thuraisingham, Bhavani
TI Security and privacy for multimedia database management systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 9th International Conference on Distributed Multimedia Systems (DMS
   03)/6th International Conference on Visual Information Systems (VIS
   2003)
CY SEP 24-26, 2003-2006
CL Miami, FL
DE multimedia data management; multimedia data security; privacy; security
   architecture; secure data model; security policy; dependability; data
   mining; secure distributed multimedia data management
AB This paper describes security and privacy issues for multimedia database management systems. Multimedia data includes text, images, audio and video. It describes access control for multimedia database management systems and describes security policies and security architectures for such systems. Privacy problems that result from multimedia data mining are also discussed.
C1 Natl Sci Fdn, Cyber Trust & Data & Applicat Secur, Arlington, VA 22230 USA.
   Mitre Corp, Div Informat Technol, Data & Informat Management, Bedford, MA 01730 USA.
C3 National Science Foundation (NSF); MITRE Corporation
RP Thuraisingham, B (corresponding author), Natl Sci Fdn, Cyber Trust & Data & Applicat Secur, 4201 Wilson Blvd, Arlington, VA 22230 USA.
EM bthurais@nsf.gov
CR AGRAWAL R, 2000, P ACM SIGMOD C DALL
   *AM NAT STAND I, 1992, SQL3
   BANERJEE J, 1987, ACM T OFFIC INFORM S, P3
   BAYARD H, 1994, P MASS DIG DAT SYST
   BERRA B, 1994, P ACM MULT C WORKSH
   Bertino E, 2004, IEEE T KNOWL DATA EN, V16, P1263, DOI 10.1109/TKDE.2004.63
   BERTINO E, 2003, P IEEE POLICY WORKSH
   CLIFTON C, 2002, NEXT GEN DAT MIN WOR
   DOBRA A, 2002, P 2002 ACM SIGM INT
   Evfimievski A., 2002, P 8 ACM SIGKDD INT C
   FERRARI E, 2000, DATABASE SECURITY, P160
   GEHRKE J, 2002, P NEXT GEN DAT MIN W
   GHAFOOR A, 1993, IEEE T KNOWL DAT APR
   GHOSH A.K., 1998, E COMMERCE SECURITY
   LEE TB, SCI AM           MAY, P28
   Perrig A., 2003, SIA SECURE INFORM AG
   Prabhakaran B., 1997, Multimedia Database Management Systems
   THURAISINGHAM B, 1995, IEEE T KNOWL DATA EN, V7, P274, DOI 10.1109/69.382297
   THURAISINGHAM B, 2003, CRC              JUN
   THURAISINGHAM B, 2004, CRC              DEC
   THURAISINGHAM B, 1993, DATA KNOWL ENG   DEC, P271
   THURAISINGHAM B, 2003, INT J TOOLS ARTIFICI, V13, P730
   THURAISINGHAM B, 2003, SIGKDD EXPLORATI JAN
   THURAISINGHAM B, 1990, P IFIP DAT SEC C HAL
   THURAISINGHAM B, 1998, CRC              DEC
   THURAISINGHAM B, 2002, P IEEE COMPSAC C OXF
   THURAISINGHAM B, 2003, IN PRESS DATA KNOWL
   THURAISINGHAM B, 2001, CRC              JUN
   THURAISINGHAM B, 1994, COMPUTERS SECURI DEC
   THURAISINGHAM B, 2005, IEEE SIGNAL PROC MAY, P14
   Thuraisingham BM, 1999, IEEE T KNOWL DATA EN, V11, P228, DOI 10.1109/69.755631
   THURAISINGHAM N, 1996, P 1 IEEE MET C SILV
   WOELK D, 1986, P ACM SIGMOD C WASH
NR 33
TC 19
Z9 20
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2007
VL 33
IS 1
BP 13
EP 29
DI 10.1007/s11042-006-0096-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 149FZ
UT WOS:000245133800003
DA 2024-07-18
ER

PT J
AU Heisterkamp, DR
   Peng, J
AF Heisterkamp, DR
   Peng, J
TI Kernel vector approximation files for relevance feedback retrieval in
   large image databases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 1st ACM International Workshop on Multimedia Databases
CY NOV 07, 2003
CL New Orleans, LA
SP ACM
DE kernel methods; VA-File; content-based image retrieval; relevance
   feedback; indexing
AB Many data partitioning index methods perform poorly in high dimensional space and do not support relevance feedback retrieval. The vector approximation file (VA-File) approach overcomes some of the difficulties of high dimensional vector spaces, but cannot be applied to relevance feedback retrieval using kernel distances in the data measurement space. This paper introduces a novel KVA-File (kernel VA-File) that extends VA-File to kernel-based retrieval methods. An efficient approach to approximating vectors in an induced feature space is presented with the corresponding upper and lower distance bounds. Thus an effective indexing method is provided for kernel-based relevance feedback image retrieval methods. Experimental results using large image data sets (approximately 100,000 images with 463 dimensions of measurement) validate the efficacy of our method.
C1 Oklahoma State Univ, Dept Comp Sci, Stillwater, OK 74078 USA.
   Tulane Univ, New Orleans, LA 70118 USA.
C3 Oklahoma State University System; Oklahoma State University -
   Stillwater; Tulane University
RP Heisterkamp, DR (corresponding author), Oklahoma State Univ, Dept Comp Sci, Stillwater, OK 74078 USA.
EM drh@ieee.org; jp@eecs.tulane.edu
CR Amari S, 1999, NEURAL NETWORKS, V12, P783, DOI 10.1016/S0893-6080(99)00032-5
   [Anonymous], 1998, STAT LEARNING THEORY
   Bach F. R., 2002, Journal of machine learning research, V3, P1
   Chen Y., 2001, P IEEE INT C IM PROC, P815
   Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426
   Cristianini N., 2001, P 18 INT C MACH LEAR, P66
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Ferhatosmanoglu H., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, P202, DOI 10.1145/354756.354820
   Guttman A., 1984, SIGMOD Record, V14, P47, DOI 10.1145/971697.602266
   HEISTERKAMP D, 2001, P IEEE C COMP VIS PA, P236
   Ishikawa Y., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P218
   MANEVITZ LM, 2001, J MACHINE LEARNING R, V2, P139
   Müller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517
   Murphy P.M., UCI REPOSITORY MACHI
   Peng J, 1999, COMPUT VIS IMAGE UND, V75, P150, DOI 10.1006/cviu.1999.0770
   PENG J, 2002, 9 INT C NEUR INF PRO
   Peng J, 2002, P IEEE INT C PATT RE
   Rui Y, 2000, PROC CVPR IEEE, P236, DOI 10.1109/CVPR.2000.855825
   Schölkopf B, 1999, IEEE T NEURAL NETWOR, V10, P1000, DOI 10.1109/72.788641
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   SCHOLKOPF B, 2000, LEARNING KERNELS SUP
   Tax D.M. J., 1999, Proceedings ESANN, P251
   TESIC J, 2003, P IEEE COMP SOC C CO, V2, P643
   Tipping ME, 2001, ADV NEUR IN, V13, P633
   WEBBER R, 1998, P INT C VER LARG DAT, P194
   Weber R., 1997, 24 ESPRIT PROJ HERME
   WU P, 2000, P ACM MULT NOV, P202
   YIANILOS P, 1992, 3 ANN ACM SIAM S DIS, P311
   Zhou XS, 2001, PROC CVPR IEEE, P11
NR 29
TC 7
Z9 7
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2005
VL 26
IS 2
BP 175
EP 189
DI 10.1007/s11042-005-0454-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 931TJ
UT WOS:000229508100003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Rodríguez, A
   Guil, N
   Shotton, DM
   Trelles, O
AF Rodríguez, A
   Guil, N
   Shotton, DM
   Trelles, O
TI Analysis and description of the semantic content of cell biological
   videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video content recognition; semantic content analysis; content
   description; metadata database; biological videos
ID GUEST EDITORS INTRODUCTION; DATABASE; IMAGES; MPEG-7
AB We present a system for extracting and organizing semantic content metadata from biological microscopy videos featuring living cells. The system uses image processing and understanding procedures to identify objects and events automatically within the digitized videos, thus leading to the generation of content information ( semantic metadata) of high information value by automated analysis of their visual content. When such metadata are properly organized in a searchable database conformed with our proposed model, a content-based video query and retrieval system may be developed to locate particular objects, events or behaviours. Furthermore these metadata can be applied to find hidden semantic relationships such as correlations between behavioural alterations and changes in environmental conditions of cells. The suitability and functionality of the proposed metadata organizational model is demonstrated by the automated analysis of five different types of biological experiments, recording epithelial wound healing, bacterial multiplication, the rotations of tethered bacteria, and the swimming of motile bacteria and of human sperm. We have named our prototype analytical system VAMPORT ( video automated metadata production by object recognition and tracking). We conclude that the use of an audiovisual content description standard such as MPEG7 will contribute valuably towards the interoperability of the system.
C1 Univ Malaga, ETSI Informat, Comp Architecture Dept, Malaga 29017, Spain.
   Univ Oxford, Dept Zool, Image Bioinformat Lab, Oxford OX1 3PS, England.
C3 Universidad de Malaga; University of Oxford
RP Univ Malaga, ETSI Informat, Comp Architecture Dept, Campus Teatinos, Malaga 29017, Spain.
EM andresr@ac.uma.es; nico@ac.uma.es; david.shotton@zoo.ox.ac.uk;
   ots@ac.uma.es
RI Moreno, Andrés Rodríguez/AAB-5176-2020; Guil, Nicolas/AAM-6160-2020
OI Moreno, Andrés Rodríguez/0000-0002-0431-2322; Guil,
   Nicolas/0000-0003-3431-6516; Trelles Salazar,
   Oswaldo/0000-0003-1554-8987
CR BALLARD DH, 1982, COMPUTER VISION, P143
   Boudier T, 1999, J STRUCT BIOL, V125, P133, DOI 10.1006/jsbi.1999.4097
   Carazo JM, 1999, J STRUCT BIOL, V125, P97, DOI 10.1006/jsbi.1999.4103
   DAY N, 2002, INTRO MPEG 7 V4 0
   DAY N, 2002, JTC1SC29WG11N4676 IS
   Del Bimbo A, 1999, COMPUT VIS IMAGE UND, V75, P1, DOI 10.1006/cviu.1999.0775
   *GLAXOWELLCOME EXP, GLOB IM DAT
   Guil N, 1999, PATTERN RECOGN, V32, P1025, DOI 10.1016/S0031-3203(98)00127-7
   Hampapur A, 1997, P SOC PHOTO-OPT INS, V3022, P188, DOI 10.1117/12.263407
   Hobson G., 1996, HOBSON TRACKER USER
   LEWIS JW, 1994, THESIS U OXFORD
   LEWIS JW, 1995, P ROY MICROSC SOC, V30, P134
   LEWIS JW, 1994, P 4 ANN M EUR TISS R, P230
   Machtynger J, 2002, J MICROSC-OXFORD, V205, P43, DOI 10.1046/j.0022-2720.2001.00967.x
   Manson MD, 1998, J BACTERIOL, V180, P1009, DOI 10.1128/JB.180.5.1009-1022.1998
   Martinez J.M., 2002, MPEG-7: the generic Multimedia Content Description Standard
   Martinez J. M., 2003, JTC1SC29WG11N5525 IS
   Nack F, 1999, IEEE MULTIMEDIA, V6, P65, DOI 10.1109/93.790612
   *NAT CTR GEOGR INF, 2000, CART PUBL SERV CAT
   Panchanathan S, 1996, J VIS COMMUN IMAGE R, V7, P305, DOI 10.1006/jvci.1996.0026
   Paskin N, 1999, P IEEE, V87, P1208, DOI 10.1109/5.771073
   PASKIN N, 2000, DOI HDB
   RODRIGUEZ A, 2000, P RIAO 2000 6 C CONT
   RUST G, 1998, D LIB MAGAZINE   JUL
   Rust G., 2000, WP1A00620
   Salembier P, 2002, PATTERN RECOGN, V35, P563, DOI 10.1016/S0031-3203(01)00060-7
   SALEMBIER PS, 2000, IEEE INT C IM PROC I
   SANFELIU A, 2000, PATTERN RECOGN, V2, P1
   SANFELIU A, 2000, COMPUTER VISION IMAG, V1, P1
   SANFELIU A, 2000, IMAGE SPEECH SIGNAL, V3, P1
   SANFELIU A, 2000, APPL ROBOTIC SYSTEMS, V4, P1
   Shotton DM, 1998, P NATL ACAD SCI USA, V95, P15571, DOI 10.1073/pnas.95.26.15571
   Shotton DM, 2002, J MICROSC-OXFORD, V205, P33, DOI 10.1046/j.0022-2720.2001.00966.x
   SHOTTON DM, 2000, P ICPR2000 15 INT C
   Sussman JL, 1998, ACTA CRYSTALLOGR D, V54, P1078, DOI 10.1107/S0907444998009378
NR 35
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2005
VL 25
IS 1
BP 37
EP 58
DI 10.1023/B:MTAP.0000046381.73660.64
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 866VY
UT WOS:000224802700002
DA 2024-07-18
ER

PT J
AU Ding, JW
   Tseng, SY
   Huang, YM
AF Ding, JW
   Tseng, SY
   Huang, YM
TI Packet permutation: A robust transmission technique for continuous media
   streaming over the Internet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE continuous media streaming; video-on-demand; robust delivery scheme;
   bursty packet losses; packet permutation
AB With the growing popularity of the Internet, there is an increasing demand to deliver continuous media (CM) streams over the Internet. However, packets may be damaged or lost during transmission over the current Internet. In particular, periodic network overloads often result in bursty packet losses, degrading the perceptual quality of CM streaming. In this paper, we focus on reducing the impact of this bursty loss behavior. We propose a novel robust end-to-end transmission scheme, referred to as packet permutation ( PP), to deliver pre-compressed continuous media streams over the Internet. At the server side, PP permutes, prior to transmission, the normal packet delivery sequence of CM streams in a specific way. The packets are then re-permuted at the receiver side before they are presented to the application. In this way, the probability of losing a large number of packets within each CM frame can be significantly reduced. To validate the effectiveness of PP, a series of trace-driven simulations are conducted. Our results show that for a given quality of service (QoS) requirement of CM streaming, PP greatly reduces the overhead required by traditional error control schemes, such as forward error correction (FEC) and feedback/retransmission-based schemes.
C1 Natl Cheng Kung Univ, Dept Engn Sci, Tainan 701, Taiwan.
C3 National Cheng Kung University
RP Natl Cheng Kung Univ, Dept Engn Sci, Tainan 701, Taiwan.
EM jwding@mail.ksut.edu.tw; tsy@mail.ksut.edu.tw; raymond@mail.ncku.edu.tw
RI Ding, Jen-Wen/B-4860-2009; Huang, Yueh-Min/B-4563-2009
CR [Anonymous], P ACM SIGCOMM CANN F
   [Anonymous], P ACM SIGCOMM 90
   Bolot JC, 1999, IEEE INFOCOM SER, P1453, DOI 10.1109/INFCOM.1999.752166
   BOLOT JC, IN PRESS ACM MULTIME
   BOLOT JC, 1998, COMPUTER COMMUNICATI, V28
   BOLOT JC, 1994, P ACM SIGCOMM 94 LON, P58
   CLARK DD, 1990, P ACM S COMM ARCH PR, P200
   Comer D.E., 1995, INTERNETWORKING TCP, V1
   DING JW, 2002, MULTIMEDIA TOOLS APP, V18
   Floyd S, 1993, IEEE ACM T NETWORK, V1, P397, DOI 10.1109/90.251892
   FURTH B, 1995, VIDEO IMAGE PROCESSI
   Ghanbari M, 1993, IEEE T CIRC SYST VID, V3, P238, DOI 10.1109/76.224234
   Huang YM, 1999, VLDB J, V8, P44, DOI 10.1007/s007780050073
   Kuo F., 1998, MULTIMEDIA COMMUNICA
   Manber Udi., 1989, Introduction to algorithms-a creative approach
   MCDYSAN D, 1995, ATM THEORY APPL
   Metz C, 1999, IEEE INTERNET COMPUT, V3, P84, DOI 10.1109/4236.761658
   Ngo HQ, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P314, DOI 10.1109/MMCS.1999.779223
   PADHYE J, 1998, P ACM SIGCOMM 98 VAN
   PAXSON V, 1997, P ACM SIGCOMM 97 CAN
   PERKINS C, 1998, RTP PAYLOAD FORMAT I
   Postel J., 1983, 879 RFC INT ENG TASK
   RAMANATHAN S, 1993, COMPUT J, V36, P19, DOI 10.1093/comjnl/36.1.19
   RIZZO L, 1997, COMPUTER COMMUNI APR
   SHEU TL, 2000, P IEEE INT C COMM TE, V2, P1641
   SITARAM D., 2000, Multimedia servers: applications, environments, and design
   STEVENS WR, 1994, PROTOCOLS, V1
   THOMAS SA, 1996, IPNG TCP IP PROTOCOL
   Varadarajan S, 2002, IEEE ACM T NETWORK, V10, P139, DOI 10.1109/90.986585
   Varadarajan S., 2000, Proceedings 20th IEEE International Conference on Distributed Computing Systems, P475, DOI 10.1109/ICDCS.2000.840960
   WANG H, 1999, P IEEE GLOBECOM 99 B, V1, P769
   Yajnik M, 1999, IEEE INFOCOM SER, P345, DOI 10.1109/INFCOM.1999.749301
   Zhu QF, 1993, IEEE T CIRC SYST VID, V3, P248, DOI 10.1109/76.224235
   [No title captured]
NR 34
TC 16
Z9 17
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2003
VL 21
IS 3
BP 281
EP 305
DI 10.1023/A:1025727002272
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 721VY
UT WOS:000185340200005
DA 2024-07-18
ER

PT J
AU Cai, Y
   Hua, KA
AF Cai, Y
   Hua, KA
TI Sharing multicast videos using patching streams
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia communications; multicast; patching; video on demand; service
   latency; performance study
AB The access patterns of most information systems follow the 80/20 rules. That is, 80% of the requests are for 20% of the data. A video server can take advantage of this property by waiting for requests and serving them together in one multicast. This simple strategy, however, incurs service delay. We address this drawback in this paper by allowing clients to receive the leading portion of a video on demand, and the rest of the video from an ongoing multicast. Since clients do not have to wait for the next multicast, the service latency is essentially zero. Furthermore, since most services require the server to deliver only a small leading portion of the video, the server can serve many more clients per time unit. We analyze the performance of this approach, and determine the optimal condition for when to use this strategy. We compare its performance to a hardware solution called Piggybacking. The results indicate that more than 200% improvement is achievable.
C1 Iowa State Univ, Dept Comp Sci, Ames, IA 50011 USA.
   Univ Cent Florida, Sch Elect Engn & Comp Sci, Orlando, FL 32816 USA.
C3 Iowa State University; State University System of Florida; University of
   Central Florida
RP Iowa State Univ, Dept Comp Sci, Ames, IA 50011 USA.
EM cai@cs.ucf.edu; kienhua@cs.ucf.edu
CR AGGARWAL CC, 1996, P IEEE INT C MULT SY
   Almeroth KC, 1996, IEEE J SEL AREA COMM, V14, P1110, DOI 10.1109/49.508282
   Chen MS, 1996, IEEE MULTIMEDIA, V3, P51, DOI 10.1109/93.502294
   Dan A., 1994, Proceedings ACM Multimedia '94, P15, DOI 10.1145/192593.192614
   Dan A, 1996, MULTIMEDIA SYST, V4, P112, DOI 10.1007/s005300050016
   FENG W, 1996, P IEEE INT C MULT SY
   Golubchik L, 1996, MULTIMEDIA SYST, V4, P140, DOI 10.1007/s005300050019
   Hua K. A., 1998, Proceedings ACM Multimedia 98, P191, DOI 10.1145/290747.290771
   Hua KA, 2000, P SOC PHOTO-OPT INS, V3969, P2
   HUA KA, 1997, P ACM SIGCOMM 97 CAN
   KHUA KA, IN PRESS ACM MULTIME
   Lau SW, 1998, MULTIMEDIA SYST, V6, P29, DOI 10.1007/s005300050074
   Little T D., 1995, Multimedia Systems, V2, P280
   PARIS JF, 1999, P SPIES C MULT COMP, P3147
   SEN S, 1999, P IEEE NOSSDAV 99 BA
   Sheu S, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P110, DOI 10.1109/MMCS.1997.609583
   VIN H, 1992, IEEE COMMUN MAG, V30, P56
   Viswanathan S, 1996, MULTIMEDIA SYST, V4, P197, DOI 10.1007/s005300050023
   WRIGHT LK, 2000, P ACM MULT LOS ANG C
   [No title captured]
NR 20
TC 16
Z9 21
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2003
VL 21
IS 2
BP 125
EP 146
DI 10.1023/A:1025516608573
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 718BJ
UT WOS:000185125000002
DA 2024-07-18
ER

PT J
AU Lee, BJ
   Shin, BS
AF Lee, Byeong-Joon
   Shin, Byeong-Seok
TI Template-based scattering illumination for volumetric dataset
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Volume rendering; Ray-casting; Global illumination; Scattering;
   Rasterization
ID INTERACTIVE GLOBAL ILLUMINATION; AMBIENT OCCLUSION; VISUALIZATION;
   SURFACE
AB Volume data encompasses the intricate internal details of objects, offering a canvas for rendering translucent aspects. However, pursuing realistic lighting in volume rendering requires substantial computational resources. We propose a method that capitalizes on the shared scattering patterns found in similar materials, allowing us to create templates that store these patterns for specific materials, facilitating efficient rendering. Derived from material properties, these templates enable the faithful representation of scattered light without imposing a significant computational burden, regardless of the volume data's scale. This approach ensures a clear depiction of material characteristics and light scattering in the resulting images. The swift generation of templates, achievable within 30 milliseconds, empowers real-time adaptation to changes in lighting and materials, making them a valuable asset for exploring data from multiple perspectives.
C1 [Lee, Byeong-Joon; Shin, Byeong-Seok] Inha Univ, Dept Comp Engn, Incheon, South Korea.
C3 Inha University
RP Shin, BS (corresponding author), Inha Univ, Dept Comp Engn, Incheon, South Korea.
EM Bjl34@inha.edu; bsshin@inha.ac.kr
FU National Research Foundationof Korea (NRF); National Research Foundation
   of Korea (NRF) - Korea government
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (No.NRF-2022R1A2B5B01001553).
CR Ament M, 2014, IEEE T VIS COMPUT GR, V20, P2437, DOI 10.1109/TVCG.2014.2346333
   Aoi D, 2021, J ADV SIMUL SCI ENG, V8, P128, DOI 10.15748/jasse.8.128
   Atty L, 2006, COMPUT GRAPH FORUM, V25, P725, DOI 10.1111/j.1467-8659.2006.00995.x
   Chen JT, 2011, COMPUT GRAPH FORUM, V30, P1205, DOI 10.1111/j.1467-8659.2011.01979.x
   Díaz J, 2010, COMPUT GRAPH-UK, V34, P337, DOI 10.1016/j.cag.2010.03.005
   Engel D, 2021, IEEE T VIS COMPUT GR, V27, P1268, DOI 10.1109/TVCG.2020.3030344
   Hachisuka T., 2008, ACM T GRAPHIC, V27, P1, DOI [DOI 10.1145/1457515.1409083, DOI 10.1145/1360612.1360632]
   Hernell F, 2010, IEEE T VIS COMPUT GR, V16, P548, DOI 10.1109/TVCG.2009.45
   Jönsson D, 2017, IEEE T VIS COMPUT GR, V23, P901, DOI 10.1109/TVCG.2016.2598430
   Jönsson D, 2012, IEEE T VIS COMPUT GR, V18, P2364, DOI 10.1109/TVCG.2012.232
   Kaplanyan AS, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2451236.2451242
   Kniss J, 2003, IEEE T VIS COMPUT GR, V9, P150, DOI 10.1109/TVCG.2003.1196003
   Kroes T, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0038586
   Krüger J, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P287, DOI 10.1109/VISUAL.2003.1250384
   Lokovic T, 2000, COMP GRAPH, P385, DOI 10.1145/344779.344958
   Lundström C, 2007, IEEE T VIS COMPUT GR, V13, P1648, DOI 10.1109/TVCG.2007.70518
   Maisano J., 2003, Digital Morphology
   Patel D, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2492684
   Perez F., 1997, Rendering Techniques '97. Proceedings of the Eurographics Workshop. Eurographics, P309
   Preim B, 2016, COMPUT GRAPH FORUM, V35, P501, DOI 10.1111/cgf.12927
   Ropinski T, 2008, COMPUT GRAPH FORUM, V27, P567, DOI 10.1111/j.1467-8659.2008.01154.x
   Salama CR, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P411, DOI 10.1109/PG.2007.27
   Schott M, 2012, IEEE PAC VIS SYMP, P169, DOI 10.1109/PacificVis.2012.6183588
   Shih M, 2016, SYMP LARG DATA ANAL, P47, DOI 10.1109/LDAV.2016.7874309
   Spencer B, 2015, COMPUT GRAPH FORUM, V34, P127, DOI 10.1111/cgf.12464
   Tewari A, 2022, COMPUT GRAPH FORUM, V41, P703, DOI 10.1111/cgf.14507
   Xu CQ, 2021, VIS INFORM, V5, P70, DOI 10.1016/j.visinf.2021.08.001
   Yuan YL, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15075-9
   Zhang Y., 2013, P ACM SIGGRAPH S INT, P55, DOI [DOI 10.1145/2448196.2448205, 10.1145/2448196.2448205]
   Zhang YB, 2013, IEEE T VIS COMPUT GR, V19, P1317, DOI 10.1109/TVCG.2013.17
NR 30
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 22
PY 2023
DI 10.1007/s11042-023-17859-5
EA DEC 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB8U4
UT WOS:001129672000002
DA 2024-07-18
ER

PT J
AU Dohare, S
   Rajput, RS
AF Dohare, Sunil
   Rajput, R. S.
TI FHAWS: fuzzy hybrid arithmetic war strategy for parametric optimization
   of toughened glass on toughening machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Toughened glass; Arithmetic optimization algorithm; War strategy
   optimization algorithm; Fuzzy rules; Tensile strength; Compressive
   strength; Durability
ID MECHANICAL-PROPERTIES
AB In recent years, toughened glass has become widely used in architectural applications due to its high structural strength, shatter resistance, soundproofing, heat resistance, and durability. However, despite its strong capabilities, toughened glass can explode completely when subjected to heavy impact, causing security-related constraints in areas prone to smash-and-grab attempts. This issue can only be prevented by enhancing the quality of toughened glass, particularly its tensile strength, compressive strength, and durability. To achieve this goal, a novel technique called the "fuzzy hybrid arithmetic war strategy" (FHAWS) approach is proposed in this paper. The approach utilizes the "hybrid arithmetic war strategy" (HAWS) algorithm to determine the optimal solution with a faster convergence rate. The HAWS algorithm integrates the standard Arithmetic Optimization (AO) algorithm and War Strategy Optimization (WSO) algorithm. The fuzzy rule concept is introduced for regulating the improper searching algorithm. The proposed FHAWS approach optimizes toughened glass characteristics such as splitting strength, flexural strength, tensile strength, compressive strength, stress, temperature, fragmentation, heating time, cooling time, visual light, durability, and production cost. The experimental analysis illustrates that the proposed FHAWS approach is more efficient and robust in enhancing the quality of toughened glass than other compared state-of-the-art approaches. Overall, the paper proposes a novel approach to optimize the characteristics of toughened glass, addressing a critical issue in the architectural industry. However, the specific details of the approach and experimental results should be examined in the paper to assess the method's effectiveness comprehensively.
C1 [Dohare, Sunil; Rajput, R. S.] Rajiv Gandhi Proudyogiki Vishwavidyalaya, Univ Inst Technol, Dept Mech Engn, Bhopal, India.
C3 Rajiv Gandhi Technological University
RP Dohare, S (corresponding author), Rajiv Gandhi Proudyogiki Vishwavidyalaya, Univ Inst Technol, Dept Mech Engn, Bhopal, India.
EM sunildohare85@gmail.com
CR Abualigah L, 2021, COMPUT METHOD APPL M, V376, DOI 10.1016/j.cma.2020.113609
   Alfakeeh AS, 2022, CMC-COMPUT MATER CON, V70, P2297, DOI 10.32604/cmc.2022.020146
   Awang Ngah S, 2018, COMPOS PART A-APPL S, V109, P239, DOI 10.1016/j.compositesa.2018.02.028
   Ayyarao TSLV, 2022, IEEE ACCESS, V10, P25073, DOI 10.1109/ACCESS.2022.3153493
   Biswas RK, 2020, MATERIALIA, V12, DOI 10.1016/j.mtla.2020.100776
   Çetinbas I, 2022, IEEE ACCESS, V10, P19254, DOI 10.1109/ACCESS.2022.3151119
   de Santos H, 2021, ELECTR POW SYST RES, V191, DOI 10.1016/j.epsr.2020.106863
   Deng BH, 2020, MATERIALIA, V9, DOI 10.1016/j.mtla.2019.100548
   Dhilipkumar T, 2021, POLYM COMPOSITE, V42, P3758, DOI 10.1002/pc.26091
   Dohare S, 2022, CERAM INT, V48, P22799, DOI 10.1016/j.ceramint.2022.04.109
   Gali S, 2018, DENT MATER, V34, pE36, DOI 10.1016/j.dental.2018.01.009
   Guo Z, 2020, COMPOS STRUCT, V252, DOI 10.1016/j.compstruct.2020.112738
   Irshad K, 2020, IEEE ACCESS, V8, P99709, DOI 10.1109/ACCESS.2020.2985036
   Jesthi DK, 2019, COMPOS PART B-ENG, V174, DOI 10.1016/j.compositesb.2019.106980
   Kasper A, 2019, GLASS STRUCT ENG, V4, P279, DOI 10.1007/s40940-018-0083-8
   Kasper A, 2019, GLASS STRUCT ENG, V4, P345, DOI 10.1007/s40940-018-00093-z
   Kozlowski M, 2021, MATERIALS, V14, DOI 10.3390/ma14247658
   Kumar R, 2020, IEEE ACCESS, V8, P48870, DOI 10.1109/ACCESS.2020.2978038
   Obaid N, 2018, COMPOS SCI TECHNOL, V161, P85, DOI 10.1016/j.compscitech.2018.04.004
   Raj VR, 2022, SILICON-NETH, V14, P4129, DOI 10.1007/s12633-021-01198-x
   Raj VR, 2021, SILICON-NETH, V13, P1925, DOI 10.1007/s12633-020-00580-5
   Ricciardi MR, 2018, COMPOS PART B-ENG, V139, P259, DOI 10.1016/j.compositesb.2017.11.056
   Sanya OT, 2018, J NON-CRYST SOLIDS, V494, P9, DOI 10.1016/j.jnoncrysol.2018.04.059
   Sun XZ, 2022, INT J FATIGUE, V156, DOI 10.1016/j.ijfatigue.2021.106647
   Suresh K, 2023, COMPUT J, V66, P1126, DOI 10.1093/comjnl/bxac002
NR 25
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 21
PY 2023
DI 10.1007/s11042-023-17293-7
EA DEC 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5U7
UT WOS:001129334000007
DA 2024-07-18
ER

PT J
AU Sudhakar, K
   Naganjaneyulu, S
AF Sudhakar, Kalva
   Naganjaneyulu, Satuluri
TI Enhancing stock market forecasting using sequential training network
   empowered by tunicate swarm optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Tunicate Swarm optimization; Rate of change; Relative strength index;
   Long-short term memory; Black widow optimization
ID PREDICTION; DEEP
AB Owing to the dynamic nature of the financial industry, determining accurate stock market forecasts remains a significant challenge. Traditional forecasting methods often struggle to capture the intricate and volatile dynamics of stock price movements. Similarly numerous strategies for stock market prediction have been presented, precise prediction in this field still requires attention. Based on this insight, a novel sequential training model is proposed by adopting the optimal feature selection procedure. In order to determine stock price predictions, primarily financial Nifty data is obtained from the corresponding source. After acquiring financial data, the feature extraction phase is used to extract features from fundamental analysis, such as the Relative Strength Index, Rate of Change, Average True Range, and Exponential Moving Average. Additionally, statistical characteristics such as mean, standard deviation, variance, skewness, and kurtosis are derived from the stock market data. In order to select parameters, the fitness dependent randomised tunicate swarm optimization technique is utilized after the features have been retrieved. Feature selection improves the deep learning process and increases prediction capability by selecting the most important variables and eliminating irrelevant features. A novel sequential training technique is introduced aimed at forecasting stock market trends by leveraging the chosen features. The suggested approach undergoes comprehensive testing, evaluating its predictive capability using accuracy, precision, and recall metrics, implemented towards enhancing future stock price forecasts.
C1 [Sudhakar, Kalva] Jawaharlal Nehru Technol Univ Kakinada, Dept Comp Sci & Engn, Kakinada, India.
   [Naganjaneyulu, Satuluri] Lakireddy Bali Reddy Coll Engn Autonomous, Dept Informat Technol, Mylavaram 521230, Andhra Pradesh, India.
C3 Jawaharlal Nehru Technological University - Kakinada
RP Sudhakar, K (corresponding author), Jawaharlal Nehru Technol Univ Kakinada, Dept Comp Sci & Engn, Kakinada, India.
EM sudhakarkalva484@gmail.com
CR Alotaibi SS, 2021, IEEE ACCESS, V9, P64929, DOI 10.1109/ACCESS.2021.3073507
   Bouktif S, 2020, IEEE ACCESS, V8, P40269, DOI 10.1109/ACCESS.2020.2976725
   Chatzis SP, 2018, EXPERT SYST APPL, V112, P353, DOI 10.1016/j.eswa.2018.06.032
   Chen YX, 2019, IEEE ACCESS, V7, P148047, DOI 10.1109/ACCESS.2019.2946223
   Chung H, 2020, NEURAL COMPUT APPL, V32, P7897, DOI 10.1007/s00521-019-04236-3
   Gurav Uma, 2018, Intelligent Computing and Information and Communication. Proceedings of 2nd International Conference, ICICC 2017. Advances in Intelligent Systems and Computing (AISC 673), P383, DOI 10.1007/978-981-10-7245-1_38
   Gurjar M., 2018, Int. Res. J. Eng. Technol, V5, P2758
   Hou XR, 2021, IEEE-CAA J AUTOMATIC, V8, P1015, DOI 10.1109/JAS.2021.1003976
   Jiang WW, 2021, EXPERT SYST APPL, V184, DOI 10.1016/j.eswa.2021.115537
   kaggle.com, About us
   Khan W, 2020, SOFT COMPUT, V24, P11019, DOI 10.1007/s00500-019-04347-y
   Khan W, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01839-w
   Lee J, 2019, IEEE ACCESS, V7, P167260, DOI 10.1109/ACCESS.2019.2953542
   Lee TK, 2019, EXPERT SYST APPL, V117, P228, DOI 10.1016/j.eswa.2018.09.005
   Liu JT, 2020, IEEE ACCESS, V8, P143114, DOI 10.1109/ACCESS.2020.3014506
   Liu Y, 2019, EXPERT SYST APPL, V132, P99, DOI 10.1016/j.eswa.2019.04.038
   Long JW, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106205
   Mehtab S, 2019, Arxiv, DOI [arXiv:1912.07700, DOI arXiv:1912.07700.v1]
   Moghar A, 2020, PROCEDIA COMPUT SCI, V170, P1168, DOI 10.1016/j.procs.2020.03.049
   Nabipour M, 2020, IEEE ACCESS, V8, P150199, DOI 10.1109/ACCESS.2020.3015966
   Naik N, 2021, IEEE ACCESS, V9, P86230, DOI 10.1109/ACCESS.2021.3088999
   Nam K, 2019, DECIS SUPPORT SYST, V117, P100, DOI 10.1016/j.dss.2018.11.004
   Nikou M, 2019, INTELL SYST ACCOUNT, V26, P164, DOI 10.1002/isaf.1459
   Nti IK, 2020, ARTIF INTELL REV, V53, P3007, DOI 10.1007/s10462-019-09754-z
   Parray IR, 2020, SOFT COMPUT, V24, P16509, DOI 10.1007/s00500-020-04957-x
   Pathak A, 2019, ADV INTELL SYST, V711, P595, DOI 10.1007/978-981-10-8055-5_53
   Valencia F, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21060589
   Vijh M, 2020, PROCEDIA COMPUT SCI, V167, P599, DOI 10.1016/j.procs.2020.03.326
   Wang YJ, 2019, IEEE ACCESS, V7, P154524, DOI 10.1109/ACCESS.2019.2949074
   Wen M, 2019, IEEE ACCESS, V7, P28299, DOI 10.1109/ACCESS.2019.2901842
   Yuan XH, 2020, IEEE ACCESS, V8, P22672, DOI 10.1109/ACCESS.2020.2969293
   Zhong X, 2019, FINANC INNOV, V5, DOI 10.1186/s40854-019-0138-0
NR 32
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 5
PY 2023
DI 10.1007/s11042-023-17686-8
EA DEC 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AW8R0
UT WOS:001121582900002
DA 2024-07-18
ER

PT J
AU Zouhri, A
   Kririm, S
   El Mallahi, M
   Hmamed, A
AF Zouhri, Amal
   Kririm, Said
   El Mallahi, Mostafa
   Hmamed, Abdelaziz
TI Optimal design of three-dimensional filter for transmission channel
   represented by state-space model with uncertain parameters and
   orthogonal descriptor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Polytopic uncertainties; Roesser state-space model; Transmission
   channel; Features extraction; Orthogonal descriptor; 3D Racah moment;
   MSE; PSNR
ID DELAYED SYSTEMS; STABILIZATION; STABILITY; 2D; CONSTRUCTION;
   RESTORATION; REALIZATION
AB The proposed work focuses on a new set of robust H-infinity deconvolution filtering of 3-D objects using feature extraction from Orthogonal Descriptor such as Racah moment, and Roesser local state-space model with uncertain parameters. The time-invariant uncertain parameters are supposed to belong to a polytope with known vertices. The main idea is to design robust H-infinity deconvolution filter to reconstruct the noisy 3D object from the feature extractions of Racah moments. Furthermore, the filtering error system is asymptotically stable and satisfies the H-infinity performance index for all admissible uncertainties. The sufficient condition is given to ensure the H-infinity performance of the filtering error system through the parameter-dependent linear matrix inequalities (LMIs) constraints, and the Racah moment to give the feature extraction according to the order defined in advance instead of the global 3-D object. Moreover, the robust 3-D deconvolution filter is designed to achieve the H8 performance index which the robust filter parameters are determined with certain optimization resolution. Finally, simulation result is shown to demonstrate the usefulness of the suggested design
C1 [Zouhri, Amal] Sidi Mohammed Ben Abdellah Univ, Fac Sci Dhar el Mahraz, Fes, Morocco.
   [Kririm, Said] Ibn Zohr Univ, Higher Sch Technol Guelmim, Agadir, Morocco.
   [El Mallahi, Mostafa] Sidi Mohammed Ben Abdellah Univ, High Normal Sch, Fes, Morocco.
   [Hmamed, Abdelaziz] Campus Private Univ Fez, Fes 30040, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Ibn Zohr University of
   Agadir; Sidi Mohamed Ben Abdellah University of Fez
RP Kririm, S (corresponding author), Ibn Zohr Univ, Higher Sch Technol Guelmim, Agadir, Morocco.
EM amal.zouhri@usmba.ac.ma; saidkririm@hotmail.com;
   mostafa.elmallahi@usmba.ac.ma; hmamed@upf.ac.ma
CR Amakdouf H, 2021, MULTIMED TOOLS APPL, V80, P3173, DOI 10.1007/s11042-020-09781-x
   Amakdouf H, 2020, MULTIMED TOOLS APPL, V79, P26571, DOI 10.1007/s11042-020-09120-0
   Amakdouf H, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV2018)
   Anderson B. D. O., 1979, OPTIMAL FILTERING
   Bioucas-Dias JM, 2009, P IEEE INT C IM PROC, P1849
   Boyd S., 1994, LINEAR MATRIX INEQUA, DOI [10.1137/1.9781611970777, DOI 10.1137/1.9781611970777]
   BRAILEAN JC, 1995, P IEEE, V83, P1272, DOI 10.1109/5.406412
   Chang XH, 2014, STUD SYST DECIS CONT, V7, P1, DOI 10.1007/978-3-642-55107-9
   Chen Y, 2020, J BIOMAT SCI-POLYM E, V31, P1770, DOI 10.1080/09205063.2020.1775760
   Chen Y, 2017, COMPUT STRUCT, V191, P153, DOI 10.1016/j.compstruc.2017.06.013
   CHO ZH, 1977, IEEE T NUCL SCI, V24, P886, DOI 10.1109/TNS.1977.4328803
   Criminisi A., 2011, IEEE Transactions on Pattern Analysis and Machine Intelligence, V33, P294
   Dabkowski P, 2010, ASIAN J CONTROL, V12, P136, DOI 10.1002/asjc.171
   El Mallahi M., 2017, Pattern Recognition and Image Analysis, V27, P810
   El Mallahi M, 2017, PATTERN RECOGNITION
   El Mallahi M, 2018, NEURAL COMPUT APPL, V30, P2283, DOI 10.1007/s00521-016-2782-x
   El Mallahi M, 2018, INT J AUTOM COMPUT, V15, P169, DOI 10.1007/s11633-017-1105-8
   El Mallahi M, 2018, MULTIMED TOOLS APPL, V77, P6583, DOI 10.1007/s11042-017-4573-5
   Elad M., 2006, IEEE Transactions on Signal Processing, V54, P3895
   Feng ZY, 2012, MULTIDIM SYST SIGN P, V23, P381, DOI 10.1007/s11045-011-0148-1
   Gahinet P, 1996, IEEE T AUTOMAT CONTR, V41, P436, DOI 10.1109/9.486646
   Galkowski K., 2003, International Journal of Applied Mathematics and Computer Science, V13, P87
   Galkowski K, 2003, IEEE T CIRCUITS-II, V50, P662, DOI 10.1109/TCSII.2003.816909
   Galkowski K, 2003, INT J CONTROL, V76, P1428, DOI 10.1080/00207170310001599113
   Gao CY, 2008, INT J AUTOM COMPUT, V5, P413, DOI 10.1007/s11633-008-0413-4
   Geromel JC, 2006, IEEE T AUTOMAT CONTR, V51, P1984, DOI 10.1109/TAC.2006.884958
   Griffa A., 2010, GIT Imaging Microscopy, V12, P43
   Haykin S.O., 1996, Adaptive Filter Theory, V4th
   Hmamed A, 2016, INT J SYST SCI, V47, P3004, DOI 10.1080/00207721.2015.1063172
   Koohestani K, 2011, INT J SOLIDS STRUCT, V48, P227, DOI 10.1016/j.ijsolstr.2010.09.023
   Kririm Said, 2015, WSEAS Transactions on Systems and Control, V10, P396
   Kririm S, 2019, 8 INT C SYST CONTR I
   Kririm S, 2023, MULTIMED TOOLS APPL, V82, P47425, DOI 10.1007/s11042-023-14719-0
   Kririm S, 2021, NEURAL COMPUT APPL, V33, P16865, DOI 10.1007/s00521-021-06533-2
   Kririm S, 2017, INT J AUTOM CONTROL, V11, P207
   Kririm S, 2016, INT CONF SYST CONTRO, P319, DOI 10.1109/ICoSC.2016.7507035
   Kririm S, 2016, CIRC SYST SIGNAL PR, V35, P1579, DOI 10.1007/s00034-015-0139-9
   Kririm S, 2015, CIRC SYST SIGNAL PR, V34, P2213, DOI 10.1007/s00034-015-9967-x
   Li ZC, 2020, AUTOMATICA, V113, DOI 10.1016/j.automatica.2019.108756
   Lofb J., 2004, P CACSD C, P284, DOI DOI 10.1109/CACSD.2004.1393890
   McNally JG, 1999, METHODS, V19, P373, DOI 10.1006/meth.1999.0873
   Mesbah A, 2017, 3D RES, V8, DOI 10.1007/s13319-016-0113-8
   Miraut D, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-100
   Oliveira RCLF, 2007, IEEE T AUTOMAT CONTR, V52, P1334, DOI 10.1109/TAC.2007.900848
   Patwary N, 2015, BIOMED OPT EXPRESS, V6, P3826, DOI 10.1364/BOE.6.003826
   PETERSEN IR, 1994, IEEE T AUTOMAT CONTR, V39, P1971, DOI 10.1109/9.317138
   Poczekajlo P, 2018, IET SIGNAL PROCESS, V12, P857, DOI 10.1049/iet-spr.2017.0450
   Ponti MP, 2013, SIGNAL IMAGE VIDEO P, V7, P1, DOI 10.1007/s11760-011-0216-x
   ROESSER RP, 1975, IEEE T AUTOMAT CONTR, VAC20, P1, DOI 10.1109/TAC.1975.1100844
   Sarder P, 2006, IEEE SIGNAL PROC MAG, V23, P32, DOI 10.1109/MSP.2006.1628876
   Sharma DK., 2002, IEEE Signal Processing Magazine, V19, P17
   SHEPPARD CJR, 1994, J OPT SOC AM A, V11, P593, DOI 10.1364/JOSAA.11.000593
   Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766
   TSUI ET, 1979, IEEE T NUCL SCI, V26, P2687, DOI 10.1109/TNS.1979.4330513
   TZAFESTAS SG, 1982, INT J SYST SCI, V13, P1171, DOI 10.1080/00207728208926421
   van den Berg TL., 2007, SIAM J Sci Comput, V30, P183
   van der Meer FD., 2005, Remote Sens Environ, V94, P324
   Wu LG, 2008, INT J ADAPT CONTROL, V22, P243, DOI 10.1002/acs.966
   Xiao GQ, 2020, J PARALLEL DISTR COM, V141, P49, DOI 10.1016/j.jpdc.2020.03.012
   Xu HL, 2010, MULTIDIM SYST SIGN P, V21, P255, DOI 10.1007/s11045-010-0104-5
   Xu L, 2008, MULTIDIM SYST SIGN P, V19, P323, DOI 10.1007/s11045-008-0057-0
   Xu Li, 2014, P ANN C NEUR INF PRO, P1790
   Yan HC, 2019, AUTOMATICA, V104, P82, DOI 10.1016/j.automatica.2019.02.024
   Yang J., 2008, Sig Process, V88, P2554
   Zhang H., 2010, J Appl Geophys, V70, P48
   Zhou JT., 2018, IEEE Transactions on Neural Networks and Learning Systems, V29, P4781
NR 66
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 28
PY 2023
DI 10.1007/s11042-023-16409-3
EA NOV 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY2E0
UT WOS:001142422400002
DA 2024-07-18
ER

PT J
AU Singh, MK
   Verma, YK
AF Singh, Manish Kumar
   Verma, Yogendra Kumar
TI Refraction reverse learning based hybrid Namib Antenna Beetle
   Optimization for resource allocation in NB-IoT platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE NB-IoT; Resource allocation; Refraction Reverse Learning; Hybrid Namib
   Antenna Beetle optimization; Satellite communication
AB The efficient allocation of resources is a critical challenge in the context of Narrowband IoT(NB-IoT) networks. This paper presents the Hybrid Namib Antenna Beetle optimization with Refraction Reverse Learning (HNAB-RRL) algorithm, which combines the Namib Antenna Beetle Optimization (NAB) and Beetle Antenna Search (BAS) Optimization algorithms with the Refraction Reverse Learning (RRL) algorithm to optimize resource allocation. The HNAB-RRL algorithm is designed to allocate available resources to multiple users efficiently and optimally. The algorithm takes into account factors such as signal-to-noise ratio, data rate, and available bandwidth to allocate resources to each user. The NAB and BAS algorithms are used to explore the search space and identify candidate solutions. These algorithms use a combination of local and global search strategies to find optimal solutions. The NAB algorithm focuses on finding the best combination of subcarriers and timeslots, while the BAS algorithm optimizes the allocation of power to the subcarriers. The RRL algorithm refines and optimizes the candidate solutions identified by the NAB and BAS algorithms. This machine learning technique learns from previous resource allocation decisions to improve future allocations. The algorithm takes into account factors such as user requirements, available resources, and previous allocation decisions to make optimal resource allocation decisions. The HNAB-RRL algorithm continuously updates the RRL algorithm with new resource allocation decisions to improve future allocations, leading to higher network throughput and better performance overall. The experimentation results revealed that the proposed HNAB-RRL model requires less time to run, provides better group fairness, and enhances performance while reducing high complexity. The achieved throughput is 105 Kbit/s, which is higher than existing methods such as E-CORA, fusion, and greedy algorithms. Overall, the HNAB-RRL algorithm provides a powerful and effective approach to resource allocation in NB-IoT networks, combining the strengths of multiple optimization techniques to find the best possible solutions.
C1 [Singh, Manish Kumar; Verma, Yogendra Kumar] Bharat Sanchar Nigam Ltd, New Delhi, India.
RP Singh, MK (corresponding author), Bharat Sanchar Nigam Ltd, New Delhi, India.
EM bsnl007@gmail.com
CR [Anonymous], WHAT IS INTERNET THI
   BBC, 2020, BBC News
   Chahardoli M, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6524
   Chen J, 2022, IEEE T NETW SCI ENG, V9, P4297, DOI 10.1109/TNSE.2022.3197888
   Chen ZY, 2019, IEEE ACCESS, V7, P145124, DOI 10.1109/ACCESS.2019.2943908
   Chougrani H, 2021, arXiv
   Cluzel S, 2018, VEH TECHNOL CONFE
   Duan S, 2022, Math Probl Eng, V2022
   Dwivedi A.K., 2020, UEEE INT SYM PERS IN, P1, DOI DOI 10.1109/pimrc48278.2020.9217207
   Ge HB, 2022, GEO-SPAT INF SCI, V25, P1, DOI 10.1080/10095020.2021.1978277
   Hassan MB, 2021, WIRELESS PERS COMMUN, V120, P2387, DOI 10.1007/s11277-021-08241-5
   Huang HW, 2019, IEEE T GREEN COMMUN, V3, P806, DOI 10.1109/TGCN.2019.2909140
   Jiang N, 2019, IEEE J SEL AREA COMM, V37, P1424, DOI 10.1109/JSAC.2019.2904366
   Kavuri S, 2020, IEEE INTERNET THINGS, V7, P2928, DOI 10.1109/JIOT.2020.2964245
   Kim MG, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22187097
   Kodhel O, 2021, IEEE Internet Things J
   Kodheli O, 2021, IEEE Internet of Things J.
   Kodheli O, 2022, IEEE INTERNET THINGS, V9, P5094, DOI 10.1109/JIOT.2021.3109456
   Lee W, 2018, IEEE COMMUN LETT, V22, P1942, DOI 10.1109/LCOMM.2018.2859392
   Liberg Olof, 2020, IEEE Communications Standards Magazine, V4, P49, DOI 10.1109/MCOMSTD.001.2000004
   Liu XY, 2020, FUTURE GENER COMP SY, V108, P390, DOI 10.1016/j.future.2019.12.032
   Migabo EM, 2020, IEEE ACCESS, V8, P97658, DOI 10.1109/ACCESS.2020.2995938
   Narrowband-internet of things (NB-IOT), 2020, Internet of Things
   NB-IOT explained, 2022, A Complete Guide to narrowband-IOT. i
   Salva-Garcia P, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/9291506
   Xu J, 2018, IEEE INTERNET THINGS, V5, P1449, DOI 10.1109/JIOT.2017.2783374
   Yang XW, 2018, IEEE INTERNET THINGS, V5, P1516, DOI 10.1109/JIOT.2017.2779820
   Yu YJ, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21237948
   Zhou L, 2021, IEEE ACCESS, V9, P5296, DOI 10.1109/ACCESS.2020.3047816
NR 29
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 23
PY 2023
DI 10.1007/s11042-023-17451-x
EA NOV 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AX8H4
UT WOS:001121833800003
DA 2024-07-18
ER

PT J
AU Sharma, P
   Kumar, M
   Sharma, HK
AF Sharma, Preeti
   Kumar, Manoj
   Sharma, Hitesh Kumar
TI A generalized novel image forgery detection method using generative
   adversarial network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Digital forensics; Image vision; Deep learning; Generative adversarial
   network; Deep fakes
AB GANs (Generative Adversarial Networks) are widely employed in many domains of science and technology. They have produced high-resolution, photo-realistic faces that appear real to the human eye. However, recognizing these images is becoming increasingly difficult. This study introduces a new GAN ensemble model that is intended to improve GAN training issues (Mode Collapse and Convergence) and generate knowledge from diverse input samples. The proposed model is built using multiple CNN discriminators architecture based on the voting ensemble technique. It utilizes a modified diversity loss function designed with the goal of minimizing the distance between the generated and original distributions. It is proven as a robust technique for forgery detection, achieving 98.31% accuracy values. One of the major findings of the study is that the novel method outperforms existing GAN models based on a small dataset of "Face Mask Lite"(193 Unmasked images), using quantifiable parameters such as Inception score (IS), Frechet Inception distance (FID), SSIM (Structural Similarity Index Metric) and Total Computational Time Function.
C1 [Sharma, Preeti; Sharma, Hitesh Kumar] Univ Petr & Energy Studies UPES, Sch Comp Sci, Dehra Dun 248007, India.
   [Kumar, Manoj] Univ Wollongong Dubai, Sch Comp Sci, Dubai Knowledge Pk, Dubai, U Arab Emirates.
   [Kumar, Manoj] Middle East Univ, MEU Res Unit, Amman 11831, Jordan.
C3 University of Petroleum & Energy Studies (UPES); University of
   Wollongong; Middle East University
RP Sharma, P (corresponding author), Univ Petr & Energy Studies UPES, Sch Comp Sci, Dehra Dun 248007, India.; Kumar, M (corresponding author), Univ Wollongong Dubai, Sch Comp Sci, Dubai Knowledge Pk, Dubai, U Arab Emirates.; Kumar, M (corresponding author), Middle East Univ, MEU Res Unit, Amman 11831, Jordan.
EM preetiii.kashyup@gmail.com; wss.manojkumar@gmail.com;
   hkshitesh@gmail.com
RI Kumar, Manoj/AFS-0700-2022
OI Kumar, Manoj/0000-0001-9598-0280
CR Battery L, IEEE/CAA J Autom Sin PP, P1, DOI [10.1109/JAS.2022.106001, DOI 10.1109/JAS.2022.106001]
   Cai GY, 2020, IEEE T NEUR NET LEAR, V31, P3073, DOI 10.1109/TNNLS.2019.2935384
   Feng D., 2020, ICONIP, P316
   Hudson D.A., 2021, INT C MACH LEARN, P4487
   Jay F., 2010, PROC IEEE INT C COMP, DOI [10.1007/978-1-60327-005-2_13, DOI 10.1007/978-1-60327-005-2_13]
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Karras Tero, 2020, IEEE C COMP VIS PATT
   Kingma D. P., 2014, arXiv
   Korshunov P., 2018, Assessment and Detection, P1
   Li RH, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459766
   Liu KH, 2021, IEEE-CAA J AUTOMATIC, V8, P1428, DOI 10.1109/JAS.2021.1004057
   Longpeng Xu, 2021, Journal of Physics: Conference Series, V1848, DOI 10.1088/1742-6596/1848/1/012081
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Miyato T, 2018, Arxiv, DOI arXiv:1802.05957
   Ohata EF, 2021, IEEE-CAA J AUTOMATIC, V8, P239, DOI 10.1109/JAS.2020.1003393
   Simonyan K, 2019, Large scale GAN training for high fidelity natural image synthesis, ICLR (2019). Input RGB synthesized RGB ground-truth RGB input red-edge synthesized red-edge ground-truth red-edge
   v d Oord A., 2016, Advances in neural information processing systems, P29
   Wang GM, 2019, IEEE T AUTOM SCI ENG, V16, P874, DOI 10.1109/TASE.2018.2865663
   Wang YX, 2022, IEEE-CAA J AUTOMATIC, V9, P1612, DOI 10.1109/JAS.2022.105515
   Wang ZP, 2021, MOL ECOL RESOUR, V21, P2689, DOI 10.1111/1755-0998.13386
   Yang N, 2022, IEEE-CAA J AUTOMATIC, V9, P1886, DOI 10.1109/JAS.2022.105887
   Yang N, 2021, IEEE T IMAGE PROCESS, V30, P6198, DOI 10.1109/TIP.2021.3089905
   Yang N, 2021, IEEE SIGNAL PROC LET, V28, P553, DOI 10.1109/LSP.2021.3059371
   Yao SY, 2023, ARTIF INTELL REV, V56, P2871, DOI 10.1007/s10462-022-10230-4
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhang K, 2021, IEEE-CAA J AUTOMATIC, V8, P1614, DOI 10.1109/JAS.2020.1003390
NR 26
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 21
PY 2023
DI 10.1007/s11042-023-17588-9
EA NOV 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Y6BH9
UT WOS:001106086000005
DA 2024-07-18
ER

PT J
AU Albouchi, A
   Messaoud, S
   Bouaafia, S
   Hajjaji, MA
   Mtibaa, A
AF Albouchi, Adnen
   Messaoud, Seifeddine
   Bouaafia, Soulef
   Hajjaji, Mohamed Ali
   Mtibaa, Abdellatif
TI Implementation of an improved multi-object detection, tracking, and
   counting for autonomous driving
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Autonomous vehicles; Deep learning; Intelligent vision; Improved
   one-stage YOLOv4; Deep SORT algorithm
AB Autonomous vehicles are a family of complex systems permanently connected to the rest of the world and communicating autonomously with other systems. It has a certain on-board intelligence and good decision-making autonomy. Among the challenges faced by autonomous vehicles are the detection and tracking of multi-objects in the path of the vehicle in urban areas. In this type of complex environment, one of the major issues is the ability to distinguish pedestrians from the many other objects located on the roadway. Another essential point is to be able to follow them to plan their movements and thus, if necessary, avoid contact. To solve these problems, deep learning, in particular convolutional neural networks (CNN), are considered promising solutions and give the possibility of seeing everything artificially via one or more connected cameras. To become increasingly autonomous and ensure the safe movement of high-speed vehicles, the vehicle must better perceive its environment, to reliably detect and interpret the road, vehicles, pedestrians, and traffic signs. However, accurate and real-time detection of all objects on the road is highly recommended. In this context, the aim of this paper is to propose an intelligent computer vision system for multi-object detection, tracking, and counting. An improved one-stage YOLOv4 is proposed for accurate multi-object detection and real-time support. The deep simple online real time tracker (SORT) algorithm is adopted to track and count the detected object. Numerical results show that the proposed framework outperforms other works, proving its effectiveness as an intelligent vision-based system for autonomous vehicles.
C1 [Albouchi, Adnen; Messaoud, Seifeddine; Bouaafia, Soulef; Hajjaji, Mohamed Ali] Univ Monastir, Fac Sci Monastir, Elect & Microelect Lab, Monastir, Tunisia.
   [Bouaafia, Soulef] Univ Kairouan, Higher Inst Appl Sci & Technol Kairouan, Kairouan, Tunisia.
   [Hajjaji, Mohamed Ali] Univ Sousse, Higher Inst Appl Sci & Technol Sousse, Sousse, Tunisia.
   [Mtibaa, Abdellatif] Univ Sfax, Natl Engn Sch Sfax, Syst Integrat & Emerging Energies Lab LR21ES14, Sfax, Tunisia.
C3 Universite de Monastir; Universite de Kairouan; Universite de Sousse;
   Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS)
RP Bouaafia, S (corresponding author), Univ Monastir, Fac Sci Monastir, Elect & Microelect Lab, Monastir, Tunisia.; Bouaafia, S (corresponding author), Univ Kairouan, Higher Inst Appl Sci & Technol Kairouan, Kairouan, Tunisia.
EM adnen_alb@yahoo.fr; seifeddine.messaoud@fsm.rnu.tn;
   soulefbouaafia@gmail.com; mohamedali.hajjaji.issats@gmail.com;
   abdellatif.mtibaa@enim.rnu.tn
RI Ali, HAJJAJI Mohamed/AAQ-2344-2021
OI Ali, HAJJAJI Mohamed/0000-0002-6372-2831; Bouaafia,
   Soulef/0000-0003-0657-6900
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Alaba SY, 2023, IEEESensors J
   Alfred Daniel J, 2023, Multimedia Tools Appl, P1
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Chao P, 2019, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2019.00365
   Chen GD, 2013, SENSOR REV, V33, P25, DOI 10.1108/02602281311294324
   Choi JD, 2023, ICT EXPRESS, V9, P222, DOI 10.1016/j.icte.2021.12.016
   Ding L, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2019.115764
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gong CY, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942147
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   Gupta A, 2021, ARRAY-NY, V10, DOI 10.1016/j.array.2021.100057
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Hou SQ, 2020, IEEE ACCESS, V8, P30682, DOI 10.1109/ACCESS.2020.2973071
   Hou XY, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI 10.1109/avss.2019.8909903
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Inoue H, 2018, Arxiv, DOI arXiv:1801.02929
   Kalman R.E., 1960, J BASIC ENG-T ASME, V82, P35, DOI [DOI 10.1115/1.3662552, 10.1115/1.3662552]
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kun Qiao, 2017, 2017 International Conference on Computer Technology, Electronics and Communication (ICCTEC). Proceedings, P608, DOI 10.1109/ICCTEC.2017.00137
   Kyriakos A, 2019, INT WORKS POW TIM, P135, DOI [10.1109/PATMOS.2019.8862166, 10.1109/patmos.2019.8862166]
   Lahmye R, 2022, Soft Comput, P1
   Lin M, 2014, Arxiv, DOI [arXiv:1312.4400, DOI 10.48550/ARXIV.1312.4400]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu ZL, 2020, AAAI CONF ARTIF INTE, V34, P11685
   Martinez-Alpiste I, 2021, NEURAL COMPUT APPL, V33, P9961, DOI 10.1007/s00521-021-05764-7
   Moussawi A, 2018, Arxiv, DOI arXiv:1809.05879
   Pereira R, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12031319
   Rahman T, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10093233
   Redmon J, 2016, Arxiv, DOI [arXiv:1612.08242, 10.48550/arXiv.1612.08242, DOI 10.48550/ARXIV.1612.08242]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Shi SS, 2023, INT J COMPUT VISION, V131, P531, DOI 10.1007/s11263-022-01710-9
   Singh D, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3155765
   Singh S., 2012, IOSR Journal of Engineering (IOSRJEN), V2, P01, DOI [10.9790/3021-02810115, DOI 10.9790/3021-02810115]
   Soon FC, 2018, IET INTELL TRANSP SY, V12, P939, DOI 10.1049/iet-its.2018.5127
   Szegedy C, arXiv
   Tang R, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13031506
   Tang SY, 2013, IEEE I CONF COMP VIS, P1049, DOI 10.1109/ICCV.2013.134
   Uchiyama H., 2012, 18 KOR JAP JOINT WOR
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang C, 2017, ASIA S PACIF DES AUT, P105, DOI 10.1109/ASPDAC.2017.7858304
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang H, 2021, UCTransNet: Rethinking the Skip Connections in U-Net from a Channel-wise Perspective with Transformer
   Wang L, 2023, KNOWL-BASED SYST, V259, DOI 10.1016/j.knosys.2022.110080
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xia DW, 2021, PHYSICA A, V578, DOI 10.1016/j.physa.2021.126056
   Xie SN, 2017, Arxiv, DOI [arXiv:1611.05431, 10.48550/arXiv.1611.05431]
   Xu Y, 2017, Proc AAAI Conf Artif Intell, V31
   Zhang SL, 2020, TRANSPORT RES REC, V2674, P57, DOI 10.1177/0361198120912422
NR 57
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 20
PY 2023
DI 10.1007/s11042-023-17444-w
EA NOV 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Y2LV7
UT WOS:001103642400004
DA 2024-07-18
ER

PT J
AU Yang, M
   Zhang, XY
   Dong, GN
   Wu, KY
   Cheng, Y
   Zhu, AC
AF Yang, Min
   Zhang, Xiangyun
   Dong, Guan-Nan
   Wu, Kunyu
   Cheng, Yong
   Zhu, Aichun
TI Potential source-information dominated learning for composed cross-modal
   person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Person re-identification; Image search; Deep learning
ID NETWORK
AB Recent years Person Re-identification(ReID) has attracted attention in industry and acade-mia. Previous works ignore the impact of appearance changes, such as clothing changes, leading to inferior performance in information retrieval under textual descriptions. Hence, we present a novel task called Composed Cross-modal Person Re-identification (CCM-ReID). Notably, there is currently no available dataset containing descriptions of appearance changes. Therefore, we construct a new dataset named CCMReid which is collected from published datasets. Meanwhile, in this paper, we propose a Potential Source-Information Dominated Learning (PSDL) model to excavate underlying essential information and clothing-changing representation by color-grey space contrastive training on source images for robust person ReID. Specifically, we introduce a source-information extraction module to tackle different color gamuts to explore real and abundant source information. To cope with the appearance variations in the open world, we also design potential information-dominated contrastive learning, which leverages different gamut information to greatly explore the latent changes expressed by related captions. The experimental results indicate that our PSDL has achieved excellent performance, and CCMReid dataset will be publicly available to support future research.
C1 [Yang, Min; Zhang, Xiangyun; Dong, Guan-Nan; Zhu, Aichun] Nanjing Tech Univ, Coll Comp & Informat Engn, Nanjing 211816, Peoples R China.
   [Wu, Kunyu] Nanjing Tech Univ, Sch Mech & Power Engn, Nanjing 211816, Peoples R China.
   [Cheng, Yong] Jiangsu Open Univ, Sch Informat & Engn, Nanjing 210003, Peoples R China.
C3 Nanjing Tech University; Nanjing Tech University; Jiangsu Open
   University
RP Dong, GN (corresponding author), Nanjing Tech Univ, Coll Comp & Informat Engn, Nanjing 211816, Peoples R China.
EM ym927927@126.com; auspiciouszxy@outlook.com; guannandong@outlook.com;
   kennyorn9@126.com; chyo_200908@hotmail.com; aichun.zhu@njtech.edu.cn
OI Dong, Guan-Nan/0000-0002-1919-3258
FU This work is partially supported by the National Natural Science
   Foundation of China (Grant No.62101245), and Natural Science Research of
   Jiangsu Higher Education Institutions of China (21KJB520008), and Future
   Network Scientific Research Fund Project (Gra [62101245]; National
   Natural Science Foundation of China [21KJB520008]; Natural Science
   Research of Jiangsu Higher Education Institutions of China
   [FNSRFP-2021-YB-21]; Future Network Scientific Research Fund Project
FX This work is partially supported by the National Natural Science
   Foundation of China (Grant No.62101245), and Natural Science Research of
   Jiangsu Higher Education Institutions of China (21KJB520008), and Future
   Network Scientific Research Fund Project (Grant No. FNSRFP-2021-YB-21).
CR Barbosa IB, 2012, LECT NOTES COMPUT SC, V7583, P433, DOI 10.1007/978-3-642-33863-2_43
   Chen BH, 2019, IEEE I CONF COMP VIS, P371, DOI 10.1109/ICCV.2019.00046
   Chen DP, 2016, PROC CVPR IEEE, P1268, DOI 10.1109/CVPR.2016.142
   Ding ZF, 2021, Arxiv, DOI arXiv:2107.12666
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Fangbin Wan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). Proceedings, P3620, DOI 10.1109/CVPRW50498.2020.00423
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ST, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14993, DOI 10.1109/ICCV48922.2021.01474
   Hong PX, 2021, PROC CVPR IEEE, P10508, DOI 10.1109/CVPR46437.2021.01037
   Jin X., 2022, P IEEE CVF C COMP VI, P14278
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Li S, 2017, PROC CVPR IEEE, P5187, DOI 10.1109/CVPR.2017.551
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu YL, 2019, Arxiv, DOI arXiv:1811.07548
   Ma BP, 2012, LECT NOTES COMPUT SC, V7583, P413, DOI 10.1007/978-3-642-33863-2_41
   Ning X, 2021, IEEE T CIRC SYST VID, V31, P3391, DOI 10.1109/TCSVT.2020.3043026
   Niu K, 2020, IEEE T IMAGE PROCESS, V29, P5542, DOI 10.1109/TIP.2020.2984883
   Paszke A, 2019, ADV NEUR IN, V32
   Radford A, 2021, PR MACH LEARN RES, V139
   Sarafianos N, 2019, IEEE I CONF COMP VIS, P5813, DOI 10.1109/ICCV.2019.00591
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Wang ZJ, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.4.043028
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Xia B, 2019, IEEE I CONF COMP VIS, P3759, DOI 10.1109/ICCV.2019.00386
   Xue J, 2018, IEEE COMPUT SOC CONF, P2193, DOI 10.1109/CVPRW.2018.00285
   Yang QZ, 2021, IEEE T PATTERN ANAL, V43, P2029, DOI 10.1109/TPAMI.2019.2960509
   Yu SJ, 2020, Arxiv, DOI [arXiv:2005.07862, 10.48550/arXiv.2005.07862, DOI 10.48550/ARXIV.2005.07862]
   Zhang FF, 2022, IEEE T IMAGE PROCESS, V31, P1000, DOI 10.1109/TIP.2021.3138302
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
NR 33
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 20
PY 2023
DI 10.1007/s11042-023-17665-z
EA NOV 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Y2LV7
UT WOS:001103642400001
DA 2024-07-18
ER

PT J
AU Middya, AI
   Roy, S
AF Middya, Asif Iqbal
   Roy, Sarbani
TI IoT-cloud based traffic honk monitoring system: empowering participatory
   sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Participatory sensing; Deep learning; Traffic honk monitoring; IoT;
   Cloud
ID ENERGY-EFFICIENT; NEURAL-NETWORKS; MOBILE; RECOGNITION; FRAMEWORK
AB The honking events' density reflects the level of traffic noise pollution, road congestion, etc in the urban areas. In this paper, we propose a participatory sensing based traffic honk monitoring system called HonkSense that uses smartphone equipped sensors (e.g. microphone, GPS, etc.). Citizens can take part in monitoring traffic noise pollution due to honking by recording ambient noise on the road. Application running on users' smartphones is used to extract features in real time from recorded audio and then send to the cloud for honk detection and decision making tasks. Here, Mel-Frequency Cepstral Coefficients (MFCCs) are utilized as feature for presenting audio signals in honk detection. This paper uses a deep Convolutional Neural Network (CNN) model that is deployed to cloud for detecting traffic honking events. The end-to-end system provides a privacy-preserving (anonymous data collection), low-power and low-cost solution for participatory sensing based traffic honk monitoring. We evaluate our proposed system on real world participatory sensing based road sound dataset collected by participants. It achieves a classification accuracy of 96.3%. The deep CNN is also evaluated on different benchmark datasets (namely ESC-50 and UrbanSound8K). The results are also compared with the baseline support vector machine (SVM) and k-nearest neighbors (KNN) classification models. Besides, state-of-the-art visualization techniques are used to explore spatial and temporal variability of honking events in urban areas using two case studies.
C1 [Middya, Asif Iqbal; Roy, Sarbani] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
C3 Jadavpur University
RP Middya, AI (corresponding author), Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
EM asifim.rs@jadavpuruniversity.in; sarbani.roy@jadavpuruniversity.in
RI MIDDYA, ASIF IQBAL/HSH-9366-2023; Roy, Sarbani/J-1997-2018
OI MIDDYA, ASIF IQBAL/0000-0001-6558-4930; Roy, Sarbani/0000-0002-7598-8266
FU The research work of Asif Iqbal Middya is supported by UGC-NET Junior
   Research Fellowship (UGC-Ref. No.: 3684/(NET-JULY 2018)) provided by the
   University Grants Commission, Government of India. We thank Mr. Kaushal
   Agarwal, Mr. Harsh Manish Modi, Mr. Rohit [3684/(NET-JULY 2018)];
   UGC-NET Junior Research Fellowship; University Grants Commission,
   Government of India
FX The research work of Asif Iqbal Middya is supported by UGC-NET Junior
   Research Fellowship (UGC-Ref. No.: 3684/(NET-JULY 2018)) provided by the
   University Grants Commission, Government of India. We thank Mr. Kaushal
   Agarwal, Mr. Harsh Manish Modi, Mr. Rohit Lakhotia and the volunteers
   from Jadavpur University for their assistance.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Ahmed Md Rayhan., 2020, International Journal of Modern Education Computer Science, V12
   Albawi S, 2017, I C ENG TECHNOL
   Amazon Web Services, About us
   Amiriparian S, 2017, INTERSPEECH, P3512, DOI 10.21437/Interspeech.2017-434
   Amoh J, 2016, IEEE T BIOMED CIRC S, V10, P1003, DOI 10.1109/TBCAS.2016.2598794
   Boddapati V, 2017, PROCEDIA COMPUT SCI, V112, P2048, DOI 10.1016/j.procs.2017.08.250
   Chen BH, 2017, PROC CVPR IEEE, P4021, DOI 10.1109/CVPR.2017.428
   Choudhary J., 2015, Identification of road accidents hot spots in Varanasi using qgis
   Corradini E, 2022, COMPUT COMMUN, V181, P338, DOI 10.1016/j.comcom.2021.10.028
   Demir F, 2020, IEEE ACCESS, V8, P66529, DOI 10.1109/ACCESS.2020.2984903
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Flask API, ABOUT US
   Ganti R. K., 2010, P 8 INT C MOB SYST A, P151, DOI DOI 10.1145/1814433.1814450
   Google Maps Platform, About us
   Gramacki A, 2018, STUD BIG DATA, V37, P25, DOI 10.1007/978-3-319-71688-6_3
   Heroku Dev Center, ABOUT US
   IMAN RL, 1980, COMMUN STAT A-THEOR, V9, P571, DOI 10.1080/03610928008827904
   Jana S, 2023, MOBILE NETW APPL, DOI 10.1007/s11036-023-02118-6
   Kar D, 2019, IEEE I C ADV NETW TE, DOI 10.1109/ants47819.2019.9118073
   keralabiodiversity, US
   keras, Usage of loss functions
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li CH, 1998, PATTERN RECOGN LETT, V19, P771, DOI 10.1016/S0167-8655(98)00057-9
   Li ZW, 2022, IEEE T NEUR NET LEAR, V33, P6999, DOI 10.1109/TNNLS.2021.3084827
   Lu H, 2009, MOBISYS'09: PROCEEDINGS OF THE 7TH ACM INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P165
   Lu JZ, 2021, AGRICULTURE-BASEL, V11, DOI 10.3390/agriculture11080707
   Maisonneuve N, 2009, ENVIRON SCI ENG, P215, DOI 10.1007/978-3-540-88351-7_16
   McFee B., 2015, P 14 PYTH SCI C, P18, DOI [DOI 10.25080/MAJORA-7B98E3ED-003, 10.25080/Majora-7b98e3ed-003]
   Mellouli D, 2019, IEEE Trans Neural Netw Learn Syst
   Middya AI, 2022, INTERNET THINGS SMAR, P33
   Middya AI, 2021, ACM TRANS SPAT ALGOR, V7, DOI 10.1145/3457609
   Middya AI, 2021, NEURAL COMPUT APPL, V33, P17303, DOI 10.1007/s00521-021-06319-6
   Middya AI, 2020, MOBILE NETW APPL, V25, P1249, DOI 10.1007/s11036-020-01539-x
   Mohan P, 2008, SENSYS'08: PROCEEDINGS OF THE 6TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P323
   Nguyen TN, 2022, ACM T INTERNET TECHN, V22, DOI 10.1145/3431502
   Patra S, 2021, MULTIMED TOOLS APPL, V80, P25171, DOI 10.1007/s11042-021-10874-4
   Pereira DG, 2015, COMMUN STAT-SIMUL C, V44, P2636, DOI 10.1080/03610918.2014.931971
   Piczak Karol J., 2015, 2015 IEEE 25th International Workshop on Machine Learning for Signal Processing (MLSP). Proceedings, DOI 10.1109/MLSP.2015.7324337
   Piczak Karol J, 2015, MM 15 P 2015 ACM MUL, P1015, DOI DOI 10.1145/2733373.2806390
   QGIS, ABOUT US
   Salamon J, 2017, IEEE SIGNAL PROC LET, V24, P279, DOI 10.1109/LSP.2017.2657381
   Salamon J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1041, DOI 10.1145/2647868.2655045
   Sen R., 2011, 2011 8th Annual IEEE Communications Society Conference on Sensor, Mesh and Ad Hoc Communications and Networks (SECON 2011), P125, DOI 10.1109/SAHCN.2011.5984883
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Vijay R, 2015, J ENVIRON HEALTH SCI, V13, DOI 10.1186/s40201-015-0164-4
   Wang LY, 2015, IEEE T SYST MAN CY-S, V45, P1549, DOI 10.1109/TSMC.2015.2418283
   Wang XL, 2013, IEEE INFOCOM SER, P2517
   who, About us
   Yan ZX, 2012, IEEE INT SYM WRBL CO, P17, DOI 10.1109/ISWC.2012.23
   Zar J. H., 1984, BIOSTATISTICAL ANAL
   Zhang XH, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114185
   Zhao Z, 2019, IEEE T VEH TECHNOL, V68, P3257, DOI 10.1109/TVT.2019.2893777
   Zhou H, 2017, TENCON IEEE REGION, P3089, DOI 10.1109/TENCON.2017.8228392
   Zhou PF, 2014, IEEE T MOBILE COMPUT, V13, P1228, DOI 10.1109/TMC.2013.136
NR 55
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 16
PY 2023
DI 10.1007/s11042-023-17419-x
EA NOV 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X9GJ6
UT WOS:001101450500006
DA 2024-07-18
ER

PT J
AU Hu, WJ
   Yang, XW
   Wang, N
   Zhang, X
   Cui, YN
   Yu, J
   Zheng, HY
   Zheng, B
AF Hu, Wenjie
   Yang, Xuewen
   Wang, Nan
   Zhang, Xing
   Cui, Yanni
   Yu, Jia
   Zheng, Haiyong
   Zheng, Bing
TI Multi-object reconstruction of plankton digital holograms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Ocean observation; Digital in-line holograms; Plankton; Reconstruction
   algorithm; Holo-Net
ID UNDERWATER IMAGE-ENHANCEMENT; SYSTEM; RESOLUTION
AB Plankton is the base of the ocean ecosystem and is very sensitive to changes in their environment. Thus, monitoring the status of plankton in-situ has incredible importance for environmental study. Hologram is one of the most effective methods to record the plankton's living status underwater. However, the reconstruction of holograms, conventionally achieved by numerical calculation, costs high both in computation and memory. Moreover, the plankton holograms are heavily noised, and useful information is sparsely distributed. To obtain high-speed visual image reconstruction from plankton holograms with good performance, in this paper, an efficient, low-redundant, and multi-object reconstruction network for plankton holograms, that is Holo-Net, is proposed. The Holo-Net includes a plankton detection unit and a reconstruction unit. It can first detect the plankton region and then map it to a visual image. A plankton hologram dataset is produced to verify the efficiency of the proposed method. Experiments show that the Holo-Net achieves PSNR and SSIM up to 20.61 and 0.65, respectively. More important, the Holo-Net is faster than the numerical method at least 100 times. We believe this work will facilitate the development of a compact in-situ plankton holographic monitoring system and help the research of the marine biosystem.
C1 [Hu, Wenjie; Yang, Xuewen; Wang, Nan; Zhang, Xing; Cui, Yanni; Zheng, Haiyong; Zheng, Bing] Ocean Univ China, Coll Elect Engn, Qingdao 266100, Peoples R China.
   [Yu, Jia] Ocean Univ China, Coll Phys & Optoelect Engn, Qingdao 266100, Peoples R China.
C3 Ocean University of China; Ocean University of China
RP Wang, N (corresponding author), Ocean Univ China, Coll Elect Engn, Qingdao 266100, Peoples R China.
EM wangnan@ouc.edu.cn
FU This work is supported by the National Natural Science Foundation of
   China (No. U2006228 and No. 61703381), and the Major Program of the
   National Science Foundation of China (No. 41527901) [U2006228,
   61703381]; National Natural Science Foundation of China [41527901];
   Major Program of the National Science Foundation of China
FX This work is supported by the National Natural Science Foundation of
   China (No. U2006228 and No. 61703381), and the Major Program of the
   National Science Foundation of China (No. 41527901)
CR Alloqmani A, 2021, INT J ADV COMPUT SC, V12, P205
   Benfield M, 2001, P AM SOC LIMNOL OCEA, P12
   Bianco V, 2020, ADV INTELL SYST-GER, V2, DOI 10.1002/aisy.201900153
   Bianco V, 2018, LIGHT-SCI APPL, V7, DOI 10.1038/s41377-018-0050-9
   Burns NM, 2014, OPT ENG, V53, DOI 10.1117/1.OE.53.11.112212
   Chen YS, 2018, PROC CVPR IEEE, P6306, DOI 10.1109/CVPR.2018.00660
   Cheremkhin PA, 2019, OPT LASER ENG, V115, P119, DOI 10.1016/j.optlaseng.2018.11.019
   Cowen RK, 2008, LIMNOL OCEANOGR-METH, V6, P126, DOI 10.4319/lom.2008.6.126
   Davis C.S., 1992, Advances in Limnology, V36, P67
   de Moraes PC, 2014, J EXP MAR BIOL ECOL, V461, P257, DOI 10.1016/j.jembe.2014.08.017
   Dongwon Park, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P327, DOI 10.1007/978-3-030-58539-6_20
   Dyomin V, 2020, FRONT MAR SCI, V7, DOI 10.3389/fmars.2020.00653
   Ghosh A, 2021, APPL OPTICS, V60, P1031, DOI 10.1364/AO.414672
   Guo BY, 2018, PROC SPIE, V10821, DOI 10.1117/12.2500788
   Huggins E., 2007, Phys. Teacher, V45, P364
   Islam MJ, 2020, IEEE ROBOT AUTOM LET, V5, P3227, DOI 10.1109/LRA.2020.2974710
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kui Jiang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8343, DOI 10.1109/CVPR42600.2020.00837
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li CY, 2022, Arxiv, DOI [arXiv:2209.02976, 10.48550/arXiv.2209.02976]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu XD, 2020, IEEE GEOSCI REMOTE S, V17, P1488, DOI 10.1109/LGRS.2019.2950056
   Lyu M, 2017, APPL OPTICS, V56, pF152, DOI 10.1364/AO.56.00F152
   Ma X, 2019, AOPC 2019 OPTICAL SE, V11338, P113
   MacNeil L, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-17313-w
   Malkiel E, 2004, MEAS SCI TECHNOL, V15, P601, DOI 10.1088/0957-0233/15/4/001
   Naik A, 2021, AAAI CONF ARTIF INTE, V35, P15853
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Picart P, 2008, J OPT SOC AM A, V25, P1744, DOI 10.1364/JOSAA.25.001744
   Picheral M, 2010, LIMNOL OCEANOGR-METH, V8, P462, DOI 10.4319/lom.2010.8.462
   Rahman Md Atiqur, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P234, DOI 10.1007/978-3-319-50835-1_22
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren Z, 2015, Digital Holography and Three-Dimensional Imaging, P4
   Ren ZB, 2019, IEEE T IND INFORM, V15, P6179, DOI 10.1109/TII.2019.2913853
   Rivenson Y, 2019, LIGHT-SCI APPL, V8, DOI 10.1038/s41377-019-0196-0
   Rivenson Y, 2018, LIGHT-SCI APPL, V7, DOI 10.1038/lsa.2017.141
   Samson S, 2001, IEEE J OCEANIC ENG, V26, P671, DOI 10.1109/48.972110
   Sarker IH, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12050754
   Schanars U, 2015, Digital holography and wavefront sensing: Principles, techniques and applications
   Shen FB, 2006, APPL OPTICS, V45, P1102, DOI 10.1364/AO.45.001102
   Shimobaba T., 2022, Front. Photonics., V3, P8
   Shimobaba T, 2019, APPL OPTICS, V58, P1900, DOI 10.1364/AO.58.001900
   Shin JW, 2005, IEEE SIGNAL PROC LET, V12, P258, DOI 10.1109/LSP.2004.840869
   Sieracki CK, 1998, MAR ECOL PROG SER, V168, P285, DOI 10.3354/meps168285
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Situ G., 2022, Adv Manuf, V3, P1
   Tang M, 2020, APPL OPTICS, V59, P333, DOI 10.1364/AO.59.000333
   Valiela I, 1995, Marine Ecological Processes, V686
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang KQ, 2020, OPT LETT, V45, P4220, DOI 10.1364/OL.395445
   Wang KQ, 2019, OPT LETT, V44, P4765, DOI 10.1364/OL.44.004765
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Watson J, 2004, OCEANS '04 MTS/IEEE TECHNO-OCEAN '04, VOLS 1- 2, CONFERENCE PROCEEDINGS, VOLS. 1-4, P1248
   Wu YC, 2018, OPTICA, V5, P704, DOI 10.1364/OPTICA.5.000704
   Xu ZM, 2018, PROC SPIE, V10505, DOI 10.1117/12.2288141
   Zamir SW, 2021, PROC CVPR IEEE, P14816, DOI 10.1109/CVPR46437.2021.01458
   Zeng TJ, 2021, OPT EXPRESS, V29, P40572, DOI 10.1364/OE.443367
   Zhang YL, 2021, OPT LASER TECHNOL, V139, DOI 10.1016/j.optlastec.2021.106979
   Zhang YP, 2022, APPL OPTICS, V61, pB111, DOI 10.1364/AO.444856
   Zhou R, 2018, Real-time Photonic Measurements, Data Management, and Processing III, V10822, P108
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 63
TC 0
Z9 0
U1 5
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 11
PY 2023
DI 10.1007/s11042-023-17631-9
EA NOV 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Y0ZQ9
UT WOS:001102641900001
DA 2024-07-18
ER

PT J
AU Yadav, A
   Kumar, E
AF Yadav, Anu
   Kumar, Ela
TI Instance segmentation of real time video for object detection using
   hybrid Mask RCNN-SVM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Instance segmentation; Hybrid Mask RCNN-SVM; Object detection; Bi-FPN;
   RoI align
AB Detection of real-world factors in digital photos and videos is one of the most important challenges in computer recognition for object detection. The main goal of generic object detection is to identify and locate specific objects. Despite abundant benefits, there exist some problems, such as the accuracy and extraction of lower and higher-level features. In order to obtain the low and high level characteristics of an image for precise classification using Bi-directional Feature Pyramid Network (Bi-FPN) and Mask Regional based Convolutional Neural Network (Mask RCNN) with Support Vector Machine (SVM) are utilised. In this proposed model, the features are extracted with the Bi-FPN model and are pooled with the adaptive feature polling technique. These features are aligned with the ROI alignment and separated into convoluted and fully connected layers. The SVM replaces the fully connected layer for classification and the convoluted layer is used for masking and bounding the object with the box. This combined model with Mask RCNN and SVM represents the Hybrid Mask RCNN-SVM. The proposed model has been implemented in Python for calculating and comparing performance metrics such as the accuracy, error, precision and recall etc., for the proposed and existing model. The resultant values for accuracy, recall, error and precision for real-time object detection utilizing hybrid Mask RCNN-SVM are 0.98, 0.96, 0.027 and 0.98. Thus, the evaluation of performance metrics results that the values of the proposed model being better compared to the existing techniques. As a result, the proposed hybrid Mask RCNN-SVM model effectively segments the object from the real-time video.
C1 [Yadav, Anu] Indira Gandhi Delhi Tech Univ Women, Dept Comp Sci & Engn, Delhi, India.
   [Kumar, Ela] Indira Gandhi Delhi Tech Univ Women, Dept Comp Sci & Engn, Delhi, India.
C3 Indira Gandhi Delhi Technical University for Women (IGDTUW); Indira
   Gandhi Delhi Technical University for Women (IGDTUW)
RP Yadav, A (corresponding author), Indira Gandhi Delhi Tech Univ Women, Dept Comp Sci & Engn, Delhi, India.
EM anuyadavcse@gmail.com
CR Ahmad F, 2023, OPT MEMORY NEURAL, V32, P126, DOI 10.3103/S1060992X23020091
   Ahmed B, 2020, SIGNAL IMAGE VIDEO P, V14, P1035, DOI 10.1007/s11760-020-01636-0
   Ahn H, 2019, IEEE C ELECTR PERFOR, DOI [10.1109/epeps47316.2019.193195, 10.1007/s00779-019-01296-z]
   Akhtar MJ, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11213425
   Ammirato Phil, 2019, arXiv, DOI DOI 10.48550/ARXIV.1908.03621
   Bhuvaneswari R, 2018, COGN SYST RES, V52, P985, DOI 10.1016/j.cogsys.2018.09.022
   Cai LQ, 2020, IEEE ACCESS, V8, P44400, DOI 10.1109/ACCESS.2020.2976432
   Cao CQ, 2019, IEEE ACCESS, V7, P106838, DOI 10.1109/ACCESS.2019.2932731
   COCO Datasets, About us
   Karthick S, 2024, NATL ACAD SCI LETT, V47, P279, DOI 10.1007/s40009-023-01353-5
   Li W, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-67529-x
   [彭秋辰 Peng Qiuchen], 2019, [清华大学学报. 自然科学版, Journal of Tsinghua University. Science and Technology], V59, P135
   Roccetti M., 2010, Comput Entertain (CIE), V8, P1, DOI [10.1145/1921141.1921148, DOI 10.1145/1921141.1921148]
   Roccetti M, 2012, J VIS COMMUN IMAGE R, V23, P426, DOI 10.1016/j.jvcir.2011.12.006
   Sankar SP, 2017, CURR MED IMAGING REV, V13, P223, DOI 10.2174/1573405612666160617082639
   Syazwany NS, 2021, IEEE ACCESS, V9, P160708, DOI 10.1109/ACCESS.2021.3132050
   Tianheng Cheng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P660, DOI 10.1007/978-3-030-58568-6_39
   Ullo SL, 2021, IEEE J-STARS, V14, P3799, DOI 10.1109/JSTARS.2021.3064981
   Wang TC, 2020, Arxiv, DOI arXiv:2012.13563
   Wu ZT, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13132582
   Xiong HT, 2020, INT J ADV ROBOT SYST, V17, DOI 10.1177/1729881420925287
   Xu RJ, 2021, FORESTS, V12, DOI 10.3390/f12020217
   Zhang LB, 2014, IEEE GEOSCI REMOTE S, V11, P916, DOI 10.1109/LGRS.2013.2281827
NR 23
TC 0
Z9 0
U1 7
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 8
PY 2023
DI 10.1007/s11042-023-17402-6
EA NOV 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X8TR3
UT WOS:001101114600015
DA 2024-07-18
ER

PT J
AU Ayala-Niño, F
   Fabila-Bustos, DA
   Cortés-Caballero, JM
   Pérez-Martínez, AA
   López-Galindo, F
   Hernández-Chávez, M
AF Ayala-Nino, Fernando
   Fabila-Bustos, Diego A.
   Cortes-Caballero, Jose M.
   Perez-Martinez, Angel A.
   Lopez-Galindo, Francisco
   Hernandez-Chavez, Macaria
TI Augmented reality to the creation of hybrid maps applied in soil
   sciences: a study case in Ixmiquilpan Hidalgo, Mexico
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Augmented reality; Hybrid maps; Edaphology; Cartography; Interactive
   educational application
AB The combination or mixture of methodologies offers so-called hybrid results, whose benefits can be focused on all areas of knowledge. In the present study, the creation of an Interactive Hybrid Maps Augmented Reality (AR) Application focused on teaching earth sciences was combined with edaphological, geographical, and cartographic information as a complement to online teaching due to the pandemic caused by COVID-19. Information was collected by studies carried out in the municipalities of Ixmiquilpan, Tasquillo, and Cardonal located at Mezquital Valley in Hidalgo, Mexico. The application was developed under evolutionary development models in combination with 2D maps, and Geographic Information Systems through the software Unity 3D graphics engine and AR Foundation SDK. In addition, laboratory results, information from historical databases, as well as field information, and pictures showing soil profiles of the study region were incorporated. The Interactive Hybrid Maps AR Application was installed and evaluated by Bachelor ' s students of Biology with a specialty in soil sciences from the National Autonomous University of Mexico through a survey quiz that included items such as a learning tool, graphic 3D maps quality in augmented reality, easy handling, interaction and recommendable. Our results obtained a value of 0.90 Cronbach Alpha Coefficient indicating excellent reliability of the instrument. Moreover, an analysis of the last 10 years shows an incipient development of applications based on Augmented Reality for teaching earth sciences for university education. However, it is shown a wide development of AR applications in several fields since mathematics to museums.
C1 [Ayala-Nino, Fernando; Lopez-Galindo, Francisco] Univ Nacl Autonoma Mexico, Fac Estudios Super Iztacala, Lab Edafol Aplicada & Serv Ambientales, UBIPRO, Tlalnepantla De Baz 54090, Mexico, Mexico.
   [Fabila-Bustos, Diego A.; Cortes-Caballero, Jose M.; Perez-Martinez, Angel A.; Hernandez-Chavez, Macaria] Inst Politecn Nacl IPN, Lab Optomecatron, UPIIH, Dist Educ Salud Ciencia Tecnol & Innovac, San Agustin Tlaxiaca 42162, Hidalgo, Mexico.
C3 Universidad Nacional Autonoma de Mexico
RP Hernández-Chávez, M (corresponding author), Inst Politecn Nacl IPN, Lab Optomecatron, UPIIH, Dist Educ Salud Ciencia Tecnol & Innovac, San Agustin Tlaxiaca 42162, Hidalgo, Mexico.
RI Fabila Bustos, Diego Adrian/R-1576-2018
OI Fabila Bustos, Diego Adrian/0000-0002-6383-1675; Hernandez Chavez,
   Macaria/0000-0002-8164-2835; Ayala-Nino, Fernando/0000-0002-4715-4109
FU Instituto Politecnico Nacional [SIP-20232108]; Laboratorio de Edafologia
   Aplicada y Servicios Ambientales, Unidad de Biotecnologia y Prototipos
   (UBIPRO) UNAM; Programa Institucional de Formacion de Investigadores
   BEIFI-IPN
FX This work was supported by a grant from the Instituto Politecnico
   Nacional (SIP-20232108) to Macaria Hernandez Chavez and by the
   Laboratorio de Edafologia Aplicada y Servicios Ambientales, Unidad de
   Biotecnologia y Prototipos (UBIPRO) UNAM. Jose M. Cortes-Caballero has a
   scholarship from the Programa Institucional de Formacion de
   Investigadores BEIFI-IPN.
CR Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Berumen E., 2021, RIDE Rev Iberoam para la Investig y el Desarro Educ, V11, P040, DOI [10.23913/ride.v11i22.890, DOI 10.23913/RIDE.V11I22.890]
   Bruno F, 2019, INT J ADV MANUF TECH, V105, P875, DOI 10.1007/s00170-019-04254-4
   Burbano-Orjuela H., 2010, Suelos Ecuatoriales, V40, P13
   Cabero AJ., 2020, AULA Rev Humanidadesy Ciencias Soc, V66, P35, DOI [10.33413/aulahcs.2020.66i2.138, DOI 10.33413/AULAHCS.2020.66I2.138]
   Cambridge University Press, 2022, Cambridge Dictionary
   Carrera CC, 2017, J GEOGR HIGHER EDUC, V41, P119, DOI 10.1080/03098265.2016.1260530
   Clarke KC, 1996, EMERG INFECT DIS, V2, P85, DOI 10.3201/eid0202.960202
   Cupial M., 2011, V International Scientific Symposium: Farm machinery and process management in sustainable agriculture, Lublin, Poland, 23-24 November 2011, P23
   de Bruyn LL, 2017, SOIL SCI SOC AM J, V81, P427, DOI 10.2136/sssaj2016.12.0403
   Dobbs TL, 2004, REV AGR ECON, V26, P220, DOI 10.1111/j.1467-9353.2004.00172.x
   Dorta Pina Duniesky, 2021, Rev cuba cienc informat, V15, P146
   Eckert M, 2019, JMIR MHEALTH UHEALTH, V7, DOI 10.2196/10967
   Ericcson, 2019, Ericcson Mobile Suscriptions Q1 Mobilit-report
   Fombona J., 2012, PIXEL-BIT, V41, P197
   Fridhi A., 2019, Journal of Soft Computing in Civil Engineering, V3, P78
   G. e I. INEGI. Instituto Nacional de Estadistica, 1976, Topographic Map Tasquillo, Scale 1:50 000
   Gallina-Tessaro S., 2014, Manual de tecnicas del estudio de la fauna, INECOL
   Google, 2022, Google Maps Platform
   Gurevych R, 2021, POSTMOD OPEN, V12, P109, DOI 10.18662/po/12.2/299
   Hernández-Chávez M, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13179776
   Huang KJ, 2022, ISPRS INT J GEO-INF, V11, DOI 10.3390/ijgi11010069
   Hugues O, 2011, HANDBOOK OF AUGMENTED REALITY, P721, DOI 10.1007/978-1-4614-0064-6_33
   Huuskonen J, 2018, COMPUT ELECTRON AGR, V154, P25, DOI 10.1016/j.compag.2018.08.039
   Ibanez JJ., 2010, Suelos Ecuatoriales, V40, P2
   IUSS Working Group WRB, 2015, International soil classification system for naming soils and creating legends for soil maps
   Jerez Mesquida, 2017, Edutec. Revista Electronica de Tecnologia Educativa, V62, P19, DOI [10.21556/edutec.2017.62.1017, DOI 10.21556/EDUTEC.2017.62.1017]
   Ibáñez JJ, 2022, SPAN J SOIL SCI, V12, DOI 10.3389/sjss.2022.10456
   Katyal JC., 2015, J Indian Soc Soil Sci, V63, P1, DOI [10.5958/0974-0228.2015.00001.8, DOI 10.5958/0974-0228.2015.00001.8]
   Kerlinger F, 1988, Metodol la Investig, VII, P827
   Klopfer E, 2008, ETR&D-EDUC TECH RES, V56, P203, DOI 10.1007/s11423-007-9037-6
   Leo B, 2017, History of Cartography, DOI [10.4324/9780203790007, DOI 10.4324/9780203790007]
   Li Z.L., 1993, CARTOGR GEOGR INF SC, V20, P19, DOI [https://doi.org/10.1559/152304093782616779, DOI 10.1559/152304093782616779]
   Liarokapis F, 2005, NINTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P745, DOI 10.1109/IV.2005.79
   Loaiza JC., 2010, Suelos Ecuatoriales, V41, P6
   Lobo M.-J., 2020, ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences, pV, DOI [10.5194/isprs-annals-V-4-2020-163-2020, DOI 10.5194/ISPRS-ANNALS-V-4-2020-163-2020]
   López-Castañeda A, 2022, BOL SOC GEOL MEX, V74, DOI [10.18268/bsgm2022v74n2a100122, 10.18268/BSGM2022v74n2a100122]
   Martínez-Graña A, 2021, LAND-BASEL, V10, DOI 10.3390/land10090918
   Martínez-Graña A, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10124616
   Mata F, 2011, P 19 ACM SIGSPATIAL, P497, DOI [10.1145/2093973.2094058, DOI 10.1145/2093973.2094058]
   McBratney AB, 2003, GEODERMA, V117, P3, DOI 10.1016/S0016-7061(03)00223-4
   Mena-Vargas YA., 2019, Sci Tech, V24, P479, DOI [10.22517/23447214.21371, DOI 10.22517/23447214.21371]
   Montece-Mosquera F., 2017, European Scientific Journal, V13, P129
   Nordin Noradila, 2021, Journal of Physics: Conference Series, DOI 10.1088/1742-6596/1997/1/012038
   Obando FH., 2012, Suelos Ecuatoriales, V42, P28
   Olson J.M., 2001, International Encyclopedia of the Social Behavioral Sciences, P1495, DOI [10.1016/B0-08-043076-7/02530-4, DOI 10.1016/B0-08-043076-7/02530-4]
   Paelke V, 2010, ISPRS J PHOTOGRAMM, V65, P256, DOI 10.1016/j.isprsjprs.2009.05.006
   Panagiotopoulos T, 2017, Generation and Authoring of Augmented Reality Terrains through Real-Time Analysis of Map Images, P480, DOI [10.1007/978-3-319-59126-1_40, DOI 10.1007/978-3-319-59126-1_40]
   Parekh P, 2020, VIS COMPUT IND BIOME, V3, DOI 10.1186/s42492-020-00057-7
   Pereira GHD, 2017, CARTOGR J, V54, P313, DOI 10.1080/00087041.2017.1411417
   Prado Aragones J., 2001, Comunicar, V9, P21, DOI [10.3916/C17-2001-04, DOI 10.3916/C17-2001-04]
   QGIS, 2022, QGIS Development Team. Geographic Information System
   Rivadulla Lopez JC, 2020, Context Educ Rev Educ, P237, DOI [10.18172/con.3865, DOI 10.18172/CON.3865]
   Rodriguez Vizzuett L., 2020, Elementos, V119, P27
   Ruiz Rivera Naxhelli, 2016, Invest. Geog, P137, DOI 10.14350/rig.47515
   Schmalstieg e D., 2007, Multimedia Cartography, P267
   Schnürer R, 2020, MULTIMODAL TECHNOLOG, V4, DOI 10.3390/mti4020023
   Siltanen S, 2017, VISUAL COMPUT, V33, P193, DOI 10.1007/s00371-015-1174-z
   Soltis NA, 2020, J GEOGR HIGHER EDUC, V44, P512, DOI 10.1080/03098265.2020.1771547
   Sorani V., 1996, GEOCARTO INT, V11, P17
   TILLOTSON PM, 1984, SOIL SCI SOC AM J, V48, P953, DOI 10.2136/sssaj1984.03615995004800050001x
   Trevino-Espinoza F, 2006, Comunicacion e Xuventude
   Tsinakos A.A., 2013, GLOBAL MOBILE LEARNI
   Vaughan Karen L., 2017, Natural Sciences Education, V46, P160031, DOI 10.4195/nse2016.11.0031
   Von Itzstein GS., 2017, Encyclopedia of Computer Graphics and Games, P1, DOI DOI 10.1007/978-3-319-08234-9_81-1
   Wright E, 2022, International Comparative Legal Guides
   Yu LJ, 2012, CARTOGR GEOGR INF SC, V39, P140, DOI 10.1559/15230406393140
   Zinck J. A., 2015, GEOPEDOLOGY INTEGRAT, DOI DOI 10.1007/978-3-319-19159-1
NR 68
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17491-3
EA NOV 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500029
DA 2024-07-18
ER

PT J
AU Ahire, NK
   Awale, RN
   Wagh, A
AF Ahire, Nitin Kisan
   Awale, R. N.
   Wagh, Abhay
TI Attention module-based fused deep cnn for learning disabilities
   identification using EEG signal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Attention module; Fused Deep CNN; EEG Signal; Learning Disabilities
   Identification; Channel Attention Module
ID CONNECTIVITY; IMPACT
AB Learning disabilities (LDs) are analyzed in children whose educational capabilities of understanding, inscription, or arithmetic are harmed as well as lagging under their age, schooling, as well as cleverness, which have a predictable occurrence among the percentage from 5 to 9 in the pediatric population. Preceding research regarding electroencephalography (EEG) signal havestated a delay in the growth of alpha-band at precise phenotypes of LD, which appears to provide a feasible clarification for differences in the maturation of EEG. Thus, EEG signals of children with reading disorders (RDs) are depicted through an advanced theta as well as a lesser alpha than those of characteristically raising children. Thus, an attention module based fused Deep CNN is developed for identifying learning disabilities using EEG signals. The main point of the proposed research is to predict the learning disabilities of children depending on EEG. The accuracy of the proposed method attains the values of 97.60% and 95.12% in terms of training percentage as well as k-fold.
C1 [Ahire, Nitin Kisan; Awale, R. N.] VJTI, Elect Dept, Mumbai, India.
   [Ahire, Nitin Kisan] Xavier Inst Engn, Mahim Causeway Mahim, Mumbai 400016, Maharashtra, India.
   [Wagh, Abhay] DTE, Mumbai, India.
C3 Veermata Jijabai Technological Institute (VJTI)
RP Ahire, NK (corresponding author), VJTI, Elect Dept, Mumbai, India.; Ahire, NK (corresponding author), Xavier Inst Engn, Mahim Causeway Mahim, Mumbai 400016, Maharashtra, India.
EM nitin.a@xavier.ac.in
RI Ahire, Nitin/HSG-1728-2023
OI Ahire, Nitin/0000-0001-7140-2814
CR Al-Barhamtoshy HM, 2017, 2017 INT C INF HLTH, P1
   Albarrán-Cárdenas L, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13052825
   Atkar G, 2020, Int J Sci Technol Res (IJSTR), V9, P1655
   Bosch-Bayard J, 2020, INT J PSYCHOPHYSIOL, V153, P135, DOI 10.1016/j.ijpsycho.2020.04.021
   Capotosto P, 2009, BEHAV BRAIN RES, V205, P468, DOI 10.1016/j.bbr.2009.07.032
   Casanova MF, 2010, J AUTISM DEV DISORD, V40, P21, DOI 10.1007/s10803-009-0817-1
   Chan RYY, 2020, IEEE SYST J, V14, P208, DOI 10.1109/JSYST.2019.2911671
   Chen TT, 2019, IEEE ACCESS, V7, P150960, DOI 10.1109/ACCESS.2019.2946980
   Dutt S, 2022, EDUC INF TECHNOL, V27, P2613, DOI 10.1007/s10639-021-10713-x
   Gallego-Molina NJ, 2022, KNOWL-BASED SYST, V240, DOI 10.1016/j.knosys.2021.108098
   Groeneveld KM, 2019, APPL PSYCHOPHYS BIOF, V44, P291, DOI 10.1007/s10484-019-09439-x
   ieee, Eeg Data for ADHD / Control Children
   Keshavarzi M, 2022, BRAIN LANG, V235, DOI [10.1016/j.bandl.2022.105198, 10.1016/j.bl.2022.105198]
   Khan R.U., 2018, International Journal of Engineering & Technology, V7, P97, DOI DOI 10.14419/IJET.V7I3.18.19022
   Khare SK, 2023, COMPUT BIOL MED, V155, DOI 10.1016/j.compbiomed.2023.106676
   Madanan M., 2022, Int. J. Biol. Biomed. Eng, V16, P207, DOI 10.46300/91011.2022.16.27
   Martínez-Briones BJ, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10110817
   Medeiros AG, 2023, IEEE IJCNN, DOI 10.1109/IJCNN54540.2023.10191535
   Milligan K, 2019, MINDFULNESS, V10, P2152, DOI 10.1007/s12671-019-01161-3
   Modak Masooda, 2020, 2020 IEEE 5th International Conference on Computing Communication and Automation (ICCCA), P414, DOI 10.1109/ICCCA49541.2020.9250761
   Moghaddari M, 2020, COMPUT METH PROG BIO, V197, DOI 10.1016/j.cmpb.2020.105738
   Nussbaumer D, 2015, INTELLIGENCE, V50, P196, DOI 10.1016/j.intell.2015.04.004
   Pérez-Elvira R, 2021, BRAIN SCI, V11, DOI 10.3390/brainsci11020167
   Poornappriya T.S., 2020, Int. J. Elect. Eng. Technol., V11, P392, DOI [10.34218/IJEET.11.10.2020.050, DOI 10.34218/IJEET.11.10.2020.050]
   Sekaran K, 2019, Int J Sci Technol Res, V8, P21
   Seshadri NPG, 2023, BIOMED SIGNAL PROCES, V82, DOI 10.1016/j.bspc.2022.104553
   Sharma G, 2023, IEEE ACCESS, V11, P52327, DOI 10.1109/ACCESS.2023.3275024
   Singer G, 2020, EUR J ENG EDUC, V45, P614, DOI 10.1080/03043797.2019.1677560
   Tsai ML, 2022, BIOMEDICINES, V10, DOI 10.3390/biomedicines10071553
   Zare M, 2016, CLIN NEUROPHYSIOL, V127, P2695, DOI 10.1016/j.clinph.2016.03.025
NR 30
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 2
PY 2023
DI 10.1007/s11042-023-17277-7
EA NOV 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2PW2
UT WOS:001096936900005
DA 2024-07-18
ER

PT J
AU Alsaidi, M
   Jan, MT
   Altaher, A
   Zhuang, HQ
   Zhu, XQ
AF Alsaidi, Mostapha
   Jan, Muhammad Tanveer
   Altaher, Ahmed
   Zhuang, Hanqi
   Zhu, Xingquan
TI Tackling the class imbalanced dermoscopic image classification using
   data augmentation and GAN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Dermoscopic image classification; Class imbalance; Data augmentation;
   Generative adversarial networks; Deep learning; Transfer learning
ID SEGMENTATION; NETWORK
AB Dermoscopy is a noninvasive way to examine and diagnose skin lesions, e.g. nevus and melanoma, and is a critical step for skin cancer detection. Accurate classification of dermoscopic images can detect skin cancer at an early stage and bring social and economic impact to patients and communities. Using deep learning methods to classify dermoscopic images has shown superior performance, but existing research often overlooks the class imbalance in the data. In addition, although a handful of public datasets are available for skin cancer research, these datasets are generally not large enough for deep learning algorithms to produce accurate results. In this paper, we propose to use data augmentation and generative adversarial networks (GAN) to tackle class-imbalanced dermoscopic image classification. Our main objectives are to determine (1) how state-of-the-art fine-tuned deep learning models perform on class-imbalanced dermoscopic images, (2) whether data augmentation and GAN can help alleviate class imbalances to improve classification accuracy, and (3) which method is more effective in addressing the class imbalance. By using public datasets and a carefully designed framework to generate augmented images and synthetic images, our research provides clear answers to these questions. Code and data used in the study are available at: https://github.com/mjan2021/Dermoscopic-image-classification.git
C1 [Alsaidi, Mostapha; Jan, Muhammad Tanveer; Altaher, Ahmed; Zhuang, Hanqi; Zhu, Xingquan] Florida Atlantic Univ, Dept Elect Engn & Comp Sci, Boca Raton, FL 33431 USA.
C3 State University System of Florida; Florida Atlantic University
RP Jan, MT (corresponding author), Florida Atlantic Univ, Dept Elect Engn & Comp Sci, Boca Raton, FL 33431 USA.
EM mjan2021@fau.edu
RI Jan, Muhammad Tanveer/HPF-1907-2023
OI Jan, Muhammad Tanveer/0000-0002-3870-0526; Altaher,
   Ahmed/0000-0003-4728-1340
FU This research is partially sponsored by the U.S. National Science
   Foundation under grant No. IIS-2302786. Special thanks to Zahra
   Salekshahrezae, Rahmi Alagoz, Ali Salem Altaher, and Nathan Guan for
   their contributions to the reformatting and proofreading [IIS-2302786];
   U.S. National Science Foundation
FX This research is partially sponsored by the U.S. National Science
   Foundation under grant No. IIS-2302786. Special thanks to Zahra
   Salekshahrezae, Rahmi Alagoz, Ali Salem Altaher, and Nathan Guan for
   their contributions to the reformatting and proofreading of the
   manuscript.
CR Abidalkareem AJ, 2020, IEEE ENG MED BIO, P1404, DOI 10.1109/EMBC44109.2020.9175606
   Alenezi F, 2023, EXPERT SYST APPL, V215, DOI 10.1016/j.eswa.2022.119352
   Alsaidi M, 2022, arXiv, DOI DOI 10.48550/ARXIV.2211.15817
   Altaher A, 2020, Journal of Bioengineering Research, V3, P1
   [Anonymous], 2016, Official Journal of the European Union, V119
   Milton MAA, 2019, Arxiv, DOI [arXiv:1901.10802, 10.48550/arXiv.1901.10802]
   Atila Ü, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2020.101182
   Khan MA, 2022, INT J INTELL SYST, V37, P10621, DOI 10.1002/int.22691
   Baur C, 2018, Arxiv, DOI arXiv:1804.04338
   Bisla D, 2019, IEEE COMPUT SOC CONF, P2720, DOI 10.1109/CVPRW.2019.00330
   Brinker TJ, 2018, J MED INTERNET RES, V20, DOI 10.2196/11936
   Canalini L, 2019, LECT NOTES COMPUT SC, V11678, P89, DOI 10.1007/978-3-030-29888-3_8
   Chaturvedi SS, 2020, MULTIMED TOOLS APPL, V79, P28477, DOI 10.1007/s11042-020-09388-2
   Chen KY, 2022, Arxiv, DOI [arXiv:2202.05685, DOI 10.48550/ARXIV.2202.05685]
   Diallo Papa Abdou Karim Karou, 2020, 2020 IEEE 6th International Conference on Computer and Communications (ICCC), P1527, DOI 10.1109/ICCC51575.2020.9344949
   Du MN, 2020, COMMUN ACM, V63, P68, DOI 10.1145/3359786
   Emara Taha, 2019, 2019 14th International Conference on Computer Engineering and Systems (ICCES). Proceedings, P28, DOI 10.1109/ICCES48960.2019.9068110
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Gajera HK, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104186
   Gangwani D, 2021, 2021 IEEE INT C BIG, P38
   Gessert N, 2020, METHODSX, V7, DOI 10.1016/j.mex.2020.100864
   Gilani SQ, 2023, MULTIMED TOOLS APPL, V82, P30065, DOI 10.1007/s11042-022-14267-z
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gulzar Y, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12125990
   Harangi B, 2018, J BIOMED INFORM, V86, P25, DOI 10.1016/j.jbi.2018.08.006
   Hasan HA, 2020, 2020 4 INT S MULT ST, P1
   Hasan MK, 2020, COMPUT BIOL MED, V120, DOI 10.1016/j.compbiomed.2020.103738
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Iqbal SMA, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-23680-1
   Iqbal SMA, 2023, Emerging Technologies for Diagnostics, V3, P317
   Murdoch WJ, 2019, Arxiv, DOI [arXiv:1901.04592, 10.48550/arXiv.1901.04592]
   Jan MT, 2023, Arxiv, DOI arXiv:2301.12269
   Jan Muhammad Tanveer, 2023, Proc Future Technol Conf Vol 2 (2022), V560, P776, DOI 10.1007/978-3-031-18458-1_53
   Jasil SPG, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03062-7
   Jha D, 2020, COMP MED SY, P558, DOI 10.1109/CBMS49503.2020.00111
   Jin QG, 2021, APPL SOFT COMPUT, V99, DOI 10.1016/j.asoc.2020.106881
   Karakheti Ashwin, 2022, Nepal Journal of Health Sciences, V2, P34, DOI 10.3126/njhs.v2i2.56791
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lei BY, 2020, MED IMAGE ANAL, V64, DOI 10.1016/j.media.2020.101716
   Limeros SC, 2022, Arxiv, DOI arXiv:2208.11702
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lucieri A, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9206946
   Menegola A, 2017, I S BIOMED IMAGING, P297, DOI 10.1109/ISBI.2017.7950523
   Mirikharaji Z, 2023, MED IMAGE ANAL, V88, DOI 10.1016/j.media.2023.102863
   Mukti IZ, 2019, INT CONF ELECTR ENG, DOI 10.1109/eict48899.2019.9068805
   Naqvi M, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13111911
   Nyíri T, 2018, LECT NOTES COMPUT SC, V11324, P438, DOI 10.1007/978-3-030-04070-3_34
   Odena A, 2017, PR MACH LEARN RES, V70
   Öztürk S, 2022, IEEE J BIOMED HEALTH, V26, P4679, DOI 10.1109/JBHI.2022.3187215
   Pollastri F, 2020, MULTIMED TOOLS APPL, V79, P15575, DOI 10.1007/s11042-019-7717-y
   Pomponiu V, 2016, IEEE IMAGE PROC, P2623, DOI 10.1109/ICIP.2016.7532834
   Qasim Gilani S, 2023, J Digit Imaging, P1
   Qian SY, 2022, COMPUT METH PROG BIO, V226, DOI 10.1016/j.cmpb.2022.107166
   Qin ZW, 2020, COMPUT METH PROG BIO, V195, DOI 10.1016/j.cmpb.2020.105568
   Ray S, 2018, Arxiv, DOI [arXiv:1807.05711, 10.48550/arXiv.1807.05711, DOI 10.48550/ARXIV.1807.05711]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Salekshahrezaee Z, 2021, PROC INT C TOOLS ART, P217, DOI 10.1109/ICTAI52525.2021.00037
   Seifallahi M, 2022, IEEE T NEUR SYS REH, V30, P1589, DOI 10.1109/TNSRE.2022.3181252
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Shabbir A, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/5843816
   Shahin AH, 2018, CAIRO INT BIOM ENG, P150, DOI 10.1109/CIBEC.2018.8641815
   Shen SW, 2022, BME FRONT, V2022, DOI 10.34133/2022/9765307
   Soudani A, 2019, EXPERT SYST APPL, V118, P400, DOI 10.1016/j.eswa.2018.10.029
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   Tu WL, 2019, IEEE ACCESS, V7, P77037, DOI 10.1109/ACCESS.2019.2921815
   Ulus C, 2022, 2022 IEEE INTERNATIONAL CONFERENCE ON KNOWLEDGE GRAPH (ICKG), P275, DOI 10.1109/ICKG55886.2022.00042
   Vasconcelos CN, 2017, Arxiv, DOI arXiv:1702.07025
   Wu M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-02687-0
   Xiang Alec, 2019, AMIA Annu Symp Proc, V2019, P1246
   Xie YT, 2020, IEEE T MED IMAGING, V39, P2482, DOI 10.1109/TMI.2020.2972964
   Sikkandar MY, 2021, J AMB INTEL HUM COMP, V12, P3245, DOI 10.1007/s12652-020-02537-3
   Yao P, 2022, IEEE T MED IMAGING, V41, P1242, DOI 10.1109/TMI.2021.3136682
   Yosinski J, 2014, ADV NEUR IN, V27
   Yu Q., 2021, arXiv
   Yu Y, 2017, LECT NOTES COMPUT SC, V10667, P97, DOI 10.1007/978-3-319-71589-6_9
   Zhou BL, 2019, INT J COMPUT VISION, V127, P302, DOI 10.1007/s11263-018-1140-0
NR 80
TC 3
Z9 3
U1 8
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 27
PY 2023
DI 10.1007/s11042-023-17067-1
EA OCT 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0GO3
UT WOS:001088502300001
DA 2024-07-18
ER

PT J
AU Gomez-Krä, P
   Rouis, K
   Diallo, AO
   Coustaty, M
AF Gomez-Kramer, Petra
   Rouis, Kais
   Diallo, Azise Oumar
   Coustaty, Mickael
TI Printed and scanned document authentication using robust layout
   descriptor matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Layout descriptor; Layout matching; Perceptual hashing; Document
   authentication
ID SEGMENTATION; SIMILARITY; RETRIEVAL; IMAGES
AB Automatic document authentication is a complex task. The aim is to prove that the document at hand is not a fraudulent one. This can be achieved through a fingerprint that is based on the document's content. To this end, it is necessary to analyze and describe the different constituent elements of the document: graphics, text, tables, as well as the layout. In this context, this article focuses on layout description and authentication. The Delaunay layout descriptor Eskenazi et al. 2015 is a robust descriptor allowing the fast comparison and authentication of layouts based on the spatial relationships of the regions composing the document. As the page layout description needs a segmentation of the document into regions, the Delaunay layout descriptor does not allow to match an authentic copy with the original when the number of segmented regions is different for both documents. This is mainly due to the use of a global matching approach. To overcome this drawback, we present a new refined matching algorithm for the Delaunay layout descriptor, which combines global and local matching. Furthermore, we present a storage and retrieval scheme to match a Delaunay layout descriptor efficiently with a layout database. In addition to its ability of comparing layouts with a different number of segmented regions, the proposed method outperforms related work. We obtain respectively a false negative and false positive rate of 0.011 and 0.0 for a data set of printed and scanned layouts, and of 0.3978 and 0.0029 for a data set of real documents.
C1 [Gomez-Kramer, Petra; Rouis, Kais; Diallo, Azise Oumar; Coustaty, Mickael] La Rochelle Univ, Lab L3i, Ave Michel Crepeau, F-17042 La Rochelle, France.
RP Gomez-Krä, P; Rouis, K (corresponding author), La Rochelle Univ, Lab L3i, Ave Michel Crepeau, F-17042 La Rochelle, France.
EM petra.gomez@univ-lr.fr; kais.rouis@univ-lr.fr
RI Diallo, Azise Oumar/JXX-0161-2024
FU This work was financed by the French National Research Agency (ANR) --
   projects SHADES (ANR-14-CE28-0022), CHIST-ERA SPIRIT (ANR-16-CHR2-0004)
   and LabCom IDEAS (ANR-18-LCV3-0008) -- as well as the Region
   Nouvelle-Aquitaine (SVP-IoT project). [ANR-14-CE28-0022]; French
   National Research Agency (ANR) [ANR-16-CHR2-0004]; CHIST-ERA SPIRIT
   [ANR-18-LCV3-0008]; LabCom IDEAS; Region Nouvelle-Aquitaine; Agence
   Nationale de la Recherche (ANR) [ANR-16-CHR2-0004, ANR-18-LCV3-0008]
   Funding Source: Agence Nationale de la Recherche (ANR)
FX This work was financed by the French National Research Agency (ANR) --
   projects SHADES (ANR-14-CE28-0022), CHIST-ERA SPIRIT (ANR-16-CHR2-0004)
   and LabCom IDEAS (ANR-18-LCV3-0008) -- as well as the Region
   Nouvelle-Aquitaine (SVP-IoT project).
CR Ahmed S, 2021, INT C PATT RECOG, P6282, DOI 10.1109/ICPR48806.2021.9412619
   Al-Ghadi M, 2021, LECT NOTES COMPUT SC, V12916, P466, DOI 10.1007/978-3-030-86198-8_33
   [Anonymous], 2006, IPCV
   Antonacopoulos Apostolos, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P296, DOI 10.1109/ICDAR.2009.271
   ANTS, 2020, Technical report
   Cesarini F, 2002, LECT NOTES COMPUT SC, V2423, P353
   Chaieb R, 2017, PATTERN RECOGN, V72, P266, DOI 10.1016/j.patcog.2017.07.030
   Chen K, 2013, PROC INT CONF DOC, P958, DOI 10.1109/ICDAR.2013.194
   Coüasnon B, 2006, INT J DOC ANAL RECOG, V8, P111, DOI 10.1007/s10032-005-0148-5
   Dang QB, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P1, DOI 10.1109/DAS.2016.66
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   Du L, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115713
   Eskenazi S, 2016, On the stability of document analysis algorithms: application to hybrid document hashing technologies
   Eskenazi S, 2016, INT WORKSH DOC AN SY, P1
   Eskenazi S, 2017, PROC INT CONF DOC, P3, DOI 10.1109/ICDAR.2017.388
   Eskenazi S, 2017, PROC INT CONF DOC, P741, DOI 10.1109/ICDAR.2017.126
   Eskenazi Sebastien, 2015, ACM S DOC ENG DOCENG, P167
   ESPOSITO F, 1994, APPL ARTIF INTELL, V8, P33, DOI 10.1080/08839519408945432
   Gordo Albert, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P481, DOI 10.1109/ICDAR.2009.110
   Hu J., 2000, Information Retrieval, V2, P227, DOI 10.1023/A:1009910911387
   Kise K, 1998, COMPUT VIS IMAGE UND, V70, P370, DOI 10.1006/cviu.1998.0684
   Kumar J, 2014, PATTERN RECOGN LETT, V43, P119, DOI 10.1016/j.patrec.2013.10.030
   Lei YQ, 2011, SIGNAL PROCESS-IMAGE, V26, P280, DOI 10.1016/j.image.2011.04.007
   Li XR, 2022, IEEE T INF FOREN SEC, V17, P1404, DOI 10.1109/TIFS.2022.3161149
   Liang J, 2002, INT C PATT RECOG, P477
   Luo B, 2001, IEEE T PATTERN ANAL, V23, P1120, DOI 10.1109/34.954602
   Malvido Garcia A., 2013, Secure imprint generated for paper documents (SIGNED)
   Nakai T, 2006, LECT NOTES COMPUT SC, V3872, P541
   Pirlo G, 2013, LECT NOTES COMPUT SC, V8156, P61
   Dang QB, 2018, PATTERN RECOGN LETT, V112, P153, DOI 10.1016/j.patrec.2018.07.009
   Rouis K, 2020, IEEE IMAGE PROC, P2551, DOI 10.1109/ICIP40778.2020.9190762
   Sarlin PE, 2020, PROC CVPR IEEE, P4937, DOI 10.1109/CVPR42600.2020.00499
   Shafait F, 2008, PROCEEDINGS OF THE 8TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, P415, DOI 10.1109/DAS.2008.61
   Shimizu DM, 2007, INT S MATH MORPH, P77
   Smoaca A, 2011, ID photograph hashing: a global approach
   Tan L., 2011, Adv Inf Sci Serv Sci, V3, P1
   Tang J, 2016, IEEE T CYBERNETICS, V46, P410, DOI 10.1109/TCYB.2015.2402751
   UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778
   Van Beusekom J, 2006, SECOND INTERNATIONAL CONFERENCE ON DOCUMENT IMAGE ANALYSIS FOR LIBRARIES, PROCEEDINGS, P232, DOI 10.1109/DIAL.2006.16
   Villan R, 2007, PROC SPIE, V6505
   Zanfir A, 2018, PROC CVPR IEEE, P2684, DOI 10.1109/CVPR.2018.00284
   Zhu GP, 2010, IEEE T INF FOREN SEC, V5, P133, DOI 10.1109/TIFS.2009.2038742
NR 42
TC 1
Z9 1
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 27
PY 2023
DI 10.1007/s11042-023-17021-1
EA OCT 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0GO3
UT WOS:001088502300008
DA 2024-07-18
ER

PT J
AU Sukhavasi, V
   Dondeti, V
AF Sukhavasi, Vidyullatha
   Dondeti, Venkatesulu
TI Effective Automated Transformer Model based Sarcasm Detection Using
   Multilingual Data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Text; Emoji; Deep Neural Network; Feature extraction; Feature
   concatenation; Average based Term Frequency; Emoji to vector model;
   Sarcasm identification
ID IDENTIFICATION
AB Sarcasm detection is crucial for social media users to understand more about the underlying facts. However, determining the sarcasm only from text is not appropriate for recently updated social networks. It can be overcome by analyzing both the emoji and text data. Therefore, bilingual data in Hindi and English with emojis are offered as input to the proposed model. Traditionally, different transformer models were developed for efficient sarcasm detection, but such models haven't reached a satisfactory position in the performance enhancement chart. Therefore, in this proposed model, the attention based transformer model is developed, which shows effective performance in analyzing both the emoji and text data. Using raw data in the transformer model will reduce the accuracy rate, therefore, to overcome such an issue, the pre-processing steps like stop word removal, case folding, filtering, lemmatization, stemming, and tokenization are initially performed over the input data. After pre-processing, the Average based Term Frequency-Inverse Document Frequency (ATF-IDF) approach is used to extract the textual features. The Gated Temporal Bidirectional Convolution Network (GT-BiCNet) is used to create the text model. The emoji-to-vector model (E-VM) is used to construct the Emoji model and express the features as vectors. The produced models obtained TexMoJ features concatenated using a deep feature fusion method. The resultant vectors are used to classify the feature vectors using the deep learning model Attention LSTM based on Amended Bidirectional Encoder Representation from Transformers (ALABerT). The network model's losses are reduced by using the Enhanced Pelican Optimization Algorithm (EpoA). The softmax layer efficiently separates the data into sarcasm and non-sarcasm. The proposed method is compared to many current methodologies regarding various performances. The English Twitter dataset has attained 99.1% accuracy, 99.2% precision, 99.1% recall, 99.1% F-measure, an execution time of 56.66 s, and an average threshold of 12364.365 s. The accuracy, recall, precision, and F-measure of the Hindi Twitter dataset are 98.1%, 98.41%, 98.2%, and 69.6%, respectively.
C1 [Sukhavasi, Vidyullatha] Vignans Fdn Sci Technol & Res, Dept Biomed Engn, Guntur 522213, Andhra Pradesh, India.
   [Sukhavasi, Vidyullatha] BVRIT HYDERABAD Coll Engn Women, Dept CSE, Bachupally 500090, Telangana, India.
   [Dondeti, Venkatesulu] Vignans Fdn Sci Technol & Res, Dept Adv CSE, Guntur 522213, Andhra Pradesh, India.
C3 Vignan's Foundation for Science, Technology & Research (VFSTR); Vignan's
   Foundation for Science, Technology & Research (VFSTR)
RP Sukhavasi, V (corresponding author), Vignans Fdn Sci Technol & Res, Dept Biomed Engn, Guntur 522213, Andhra Pradesh, India.; Sukhavasi, V (corresponding author), BVRIT HYDERABAD Coll Engn Women, Dept CSE, Bachupally 500090, Telangana, India.
EM vidyullatha.1988@gmail.com
RI Sukhavasi, Vidyullatha/KCJ-9811-2024
CR Abdullah M, 2022, 2022 13 INT C INF CO
   Ali R, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13095586
   Bharti SK, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/1653696
   Bonifazi G, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.103095
   Das S, 2023, LANG RESOUR EVAL, V57, P765, DOI 10.1007/s10579-022-09622-3
   Du Y, 2022, COGN COMPUT, V14, P78, DOI 10.1007/s12559-021-09832-x
   Eke CI, 2021, IEEE ACCESS, V9, P48501, DOI 10.1109/ACCESS.2021.3068323
   Eke CI, 2020, ARTIF INTELL REV, V53, P4215, DOI 10.1007/s10462-019-09791-8
   El Mahdaouy A, 2022, Arxiv, DOI arXiv:2206.08415
   Gupta V, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3450447
   Herodotou H, 2020, IEEE INT CONF BIG DA, P5056, DOI 10.1109/BigData50022.2020.9377980
   Jain D, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106198
   Jain DK, 2022, PATTERN RECOGN LETT, V160, P11, DOI 10.1016/j.patrec.2022.05.026
   Kamath Anirudh, 2021, Advances in Computer, Communication and Computational Sciences. Proceedings of IC4S 2019. Advances in Intelligent Systems and Computing (AISC 1158), P593, DOI 10.1007/978-981-15-4409-5_54
   Keerthika P., 2023, Computer Networks and Inventive Communication Technologies, P77, DOI [10.1007/978-981-19-3035-5_6, DOI 10.1007/978-981-19-3035-5_6]
   Kotsakis R, 2023, HELIYON, V9, DOI 10.1016/j.heliyon.2023.e16084
   Kumar Akshi, 2022, Trans. Asian Low-Resour. Lang. Inf. Process., V22, P1
   Misra R, 2022, Arxiv, DOI arXiv:1908.07414
   Nayak DK, 2022, SMART INNOV SYST TEC, V269, P371, DOI 10.1007/978-981-16-7996-4_26
   Nayel H., 2021, P 6 AR NAT LANG PROC, P386
   Omran TM, 2023, DATA KNOWL ENG, V143, DOI 10.1016/j.datak.2022.102106
   Rao Rachana P., 2022, High Performance Computing and Networking: Select Proceedings of CHSN 2021. Lecture Notes in Electrical Engineering (853), P47, DOI 10.1007/978-981-16-9885-9_4
   Ren L, 2020, NEUROCOMPUTING, V401, P320, DOI 10.1016/j.neucom.2020.03.081
   Sahoo D, 2021, 2021 19 OITS INT C I, P331, DOI [10.1109/OCIT53463.2021.00072, DOI 10.1109/OCIT53463.2021.00072]
   Sahu GA, 2023, INT J IMAGE GRAPH, V23, DOI 10.1142/S0219467823500614
   Sayeedunnisa S., 2022, ECS Transactions, V107, P2419, DOI 10.1149/10701.2419ecst
   Sharma DK, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12040937
   Sharma DK, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11182844
   Shrivastava M, 2021, TECHNOL SOC, V64, DOI 10.1016/j.techsoc.2020.101489
   Vinoth D, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.13107
   Yin WP, 2017, Arxiv, DOI [arXiv:1702.01923, DOI 10.48550/ARXIV.1702.01923]
NR 31
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 27
PY 2023
DI 10.1007/s11042-023-17302-9
EA OCT 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0GO3
UT WOS:001088502300013
DA 2024-07-18
ER

PT J
AU Zhang, D
   Dong, YW
   Yang, HJ
AF Zhang, Dian
   Dong, Yunwei
   Yang, Hongji
TI An adversarial defense algorithm based on robust U-net
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Neural networks; Vulnerability; Robust U-net; Adversarial generative
   network; Adversarial robustness
AB Due to the continuous development of neural network technology, it has been widely applied in fields such as autonomous driving and biomedicine. However, adversarial attacks can significantly degrade the performance and reliability of neural networks, making defending against such attacks a crucial research area. In this paper, we propose a robust U-Net and adversarial generative network-based defense method, training the target model on a clean training set without adversarial samples. Firstly, we train the target neural network on a clean training set. Then, we train the robust U-Net using the clean training set, employing reparameterization and random noise to resist adversarial perturbations. To supervise the quality of transformed images, we employ the adversarial generative network, utilizing the RU-Net as the generator and a discriminator to ensure the quality of generated images. Finally, we use the transformed images to retrain the target neural network, obtaining a robust neural network model capable of defending against adversarial attacks. Experimental evaluations on CIFAR-10 and Tiny Image Net demonstrate the effectiveness of our method in countering adversarial attacks and enhancing neural network robustness.
C1 [Zhang, Dian; Dong, Yunwei] Northwestern Polytech Univ, Sch Comp Sci, Xian 710129, Shaanxi, Peoples R China.
   [Yang, Hongji] Univ Leicester, Sch Comp & Math Sci, Leicester LE17RH, England.
C3 Northwestern Polytechnical University; University of Leicester
RP Zhang, D (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710129, Shaanxi, Peoples R China.
EM dianzhang@mail.nwpu.edu.cn; yunweidong@nwpu.edu.cn;
   hongji.yang@leicester.ac.uk
OI Zhang, Dian/0000-0002-9079-3889
FU This research was supported by the Major Program of the National Natural
   Science Foundation of China (Grant Nos. 62192730 and 62192733).
   [62192730, 62192733]; Major Program of the National Natural Science
   Foundation of China
FX This research was supported by the Major Program of the National Natural
   Science Foundation of China (Grant Nos. 62192730 and 62192733).
CR Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Chakraborty A, 2021, CAAI T INTELL TECHNO, V6, P25, DOI 10.1049/cit2.12028
   Chen T., 2022, ICLR
   Croce F, 2020, PR MACH LEARN RES, V119
   Esmaeili B, 2021, ELECTRON LETT, V57, P116, DOI 10.1049/ell2.12070
   Fan L., 2021, ADV NEURAL INF PROCE, V34, P21480
   Fu C., 2021, IEEE Trans. Multimedia, early access, P1, DOI [10.1109/tmm.2021.3118891, DOI 10.1109/TMM.2021.3118891]
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Goodfellow IJ, 2015, Arxiv, DOI [arXiv:1412.6572, DOI 10.48550/ARXIV.1412.6572]
   Jin GQ, 2019, INT CONF ACOUST SPEE, P3842, DOI [10.1109/ICASSP.2019.8683044, 10.1109/icassp.2019.8683044]
   Kabiraj A, 2022, LECT NOTES COMPUT SC, V13598, P444, DOI 10.1007/978-3-031-20713-6_34
   Kabiraj A, 2023, MULTIMED TOOLS APPL, V82, P13837, DOI 10.1007/s11042-022-14018-0
   Khamaiseh SY, 2022, IEEE ACCESS, V10, P102266, DOI 10.1109/ACCESS.2022.3208131
   Kim Hoki, 2020, arXiv
   Kim M., 2020, NEURIPS, VVolume 33, P2983
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Krizhevsky A, 2014, Arxiv, DOI arXiv:1404.5997
   Kurakin Alexey, 2017, INT C LEARN REPR
   Liang Q, 2022, SIGNAL PROCESS-IMAGE, V103, DOI 10.1016/j.image.2022.116659
   Liu AS, 2021, IEEE T IMAGE PROCESS, V30, P5769, DOI 10.1109/TIP.2021.3082317
   Liu S, 2023, COMPUT COMMUN, V209, P230, DOI 10.1016/j.comcom.2023.07.001
   Liu XQ, 2018, LECT NOTES COMPUT SC, V11211, P381, DOI 10.1007/978-3-030-01234-2_23
   Liu XQ, 2019, PROC CVPR IEEE, P11226, DOI 10.1109/CVPR.2019.01149
   Meng DY, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P135, DOI 10.1145/3133956.3134057
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Nicolae MI, 2019, Arxiv, DOI arXiv:1807.01069
   Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114
   Pal D, 2022, COMPUT BIOL MED, V150, DOI 10.1016/j.compbiomed.2022.106083
   Papernot N, 2016, P IEEE S SECUR PRIV, P582, DOI 10.1109/SP.2016.41
   Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sahay KB, 2022, COMPUT ELECTR ENG, V103, DOI 10.1016/j.compeleceng.2022.108319
   Shen SW, 2017, Arxiv, DOI arXiv:1707.05474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Vladu Adrian, 2018, PROC 6 INT C LEARN R
   Vysogorets A., 2023, J Mach Learn Res, V24, P99
   Wang C., 2020, 8 INT C LEARN REPR
   Wang D, 2023, Appl Intell, P1
   Wong E., 2020, 8 INT C LEARN REPR
   Wu X, 2023, IEEE T IMAGE PROCESS, V32, P364, DOI 10.1109/TIP.2022.3228497
   Xu WL, 2018, 25TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2018), DOI 10.14722/ndss.2018.23198
   Zantedeschi V, 2017, P 10 ACM WORKSH ART, P39
   Zheng S, 2016, PROC CVPR IEEE, P4480, DOI 10.1109/CVPR.2016.485
NR 47
TC 0
Z9 0
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 24
PY 2023
DI 10.1007/s11042-023-17355-w
EA OCT 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0VW7
UT WOS:001088903700005
DA 2024-07-18
ER

PT J
AU Mahalingam, N
   Sharma, P
AF Mahalingam, Nagarajan
   Sharma, Priyanka
TI Secure monitoring model for smart agriculture using an optimized
   attribute-based access control centralized authority system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Chimp optimization; Elliptical curve cryptosystem; User authorization;
   Homomorphism; Crypt analysis
ID BLOCKCHAIN; CHALLENGES; PRIVACY
AB An attribute-based authority system helps in providing file/system access to only authorized users. However, they face specific challenges in securing the dataset from attacks. Hence, a novel hybrid Chimp Optimization -based Elliptical Curve Cryptosystem Model (CbECCM) was designed in this article. The main objective of this model is to overcome these demerits of the existing system and to provide file access to the authorized user. The chimp fitness in the user authorization module improves the system's confidentiality. The presented work was validated with a crop-recommendation dataset, and the outcomes are estimated. Moreover, the homomorphism algorithm increases the data integrity and reduces the time complexity. Finally, the robustness of the developed model was checked by launching the Denial of Service (DoS) attack on the cloud servers. The performance of the designed model is estimated and validated with a comparative analysis. The performance analysis shows that the developed model attained a high confidential rate of 100%. The comparative analysis proves that the developed model achieved better outcomes than others.
C1 [Mahalingam, Nagarajan; Sharma, Priyanka] Rashtriya Raksha Univ, Sch IT AI & Cyber Secur, Gandhinagar 382305, Gujarat, India.
RP Mahalingam, N (corresponding author), Rashtriya Raksha Univ, Sch IT AI & Cyber Secur, Gandhinagar 382305, Gujarat, India.
EM mnagarajan@gujgov.edu.in; Priyanka.sharma@rru.ac.in
CR Alashhab Ziyad R., 2021, Journal of Electronic Science and Technology, P1, DOI 10.1016/j.jnlest.2020.100059
   Denis R, 2021, MULTIMED TOOLS APPL, V80, P21165, DOI 10.1007/s11042-021-10723-4
   Dogru CE., 2022, The Palgrave Encyclopedia of Interest Groups, Lobbying and Public Affairs, P669, DOI [10.1007/978-3-030-44556-0_99, DOI 10.1007/978-3-030-44556-0_99]
   Farooq MS, 2022, IEEE ACCESS, V10, P9483, DOI 10.1109/ACCESS.2022.3142848
   Farooq MS, 2019, IEEE ACCESS, V7, P156237, DOI 10.1109/ACCESS.2019.2949703
   Ferrag MA, 2020, IEEE ACCESS, V8, P32031, DOI 10.1109/ACCESS.2020.2973178
   Gupta M, 2020, IEEE ACCESS, V8, P34564, DOI 10.1109/ACCESS.2020.2975142
   Haque M A., 2021, Mater. Today, DOI DOI 10.1016/J.MATPR.2020.12.452
   Jew EKK, 2020, LAND USE POLICY, V95, DOI 10.1016/j.landusepol.2020.104612
   Jin XB, 2023, ENTROPY-SWITZ, V25, DOI 10.3390/e25020247
   Khaoula T., 2021, Procedia Comput. Sci., V191, P493
   Kong J., 2021, Comput Intell Neurosci, V2021, P1
   Kong JL, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12040500
   Krishnapriya S., 2020, Procedia Computer Science, V171, P1708, DOI 10.1016/j.procs.2020.04.183
   Laroiya C., 2020, Handbook of Research on Blockchain Technology, P213, DOI DOI 10.1016/B978-0-12-819816-2.00009-5
   Li HZ, 2019, IEEE ACCESS, V7, P179273, DOI 10.1109/ACCESS.2019.2956157
   Majumdar P., 2021, Agricultural Informatics: Automation Using the IoT and Machine Learning, P89
   Mat Razali NA., 2021, International Visual Informatics Conference, P399
   Mishra B, 2022, IEEE ACCESS, V10, P7973, DOI 10.1109/ACCESS.2022.3142345
   Mohanta BK, 2021, IEEE INTERNET THINGS, V8, P881, DOI 10.1109/JIOT.2020.3008906
   Mthunzi SN, 2020, FUTURE GENER COMP SY, V107, P620, DOI 10.1016/j.future.2019.11.013
   Onyeaka H, 2022, TRENDS FOOD SCI TECH, V125, P26, DOI 10.1016/j.tifs.2022.04.017
   Patil P, 2021, WIRELESS PERS COMMUN, V117, P1815, DOI 10.1007/s11277-020-07947-2
   Pourvahab M, 2019, IEEE ACCESS, V7, P153349, DOI 10.1109/ACCESS.2019.2946978
   PutraDR, 2019, 2019 INT C ICT SMART, V7
   Saha HN, 2021, AGR INFORMATICS AUTO, P147, DOI DOI 10.1002/9781119769231.CH8
   Shi CH, 2021, MULTIMED TOOLS APPL, V80, P25773, DOI 10.1007/s11042-021-10896-y
   Suciu G, 2019, 2019 GLOBAL IOT SUMMIT (GIOTS), DOI 10.1109/giots.2019.8766433
   Sun LF, 2020, IEEE ACCESS, V8, P101079, DOI 10.1109/ACCESS.2020.2997831
   Vangala A, 2023, CLUSTER COMPUT, V26, P879, DOI 10.1007/s10586-022-03566-7
   Vangala A, 2021, IEEE SENS J, V21, P17591, DOI 10.1109/JSEN.2020.3012294
   Velmurugadass P, 2021, MATER TODAY-PROC, V37, P2653, DOI 10.1016/j.matpr.2020.08.519
   Xu XL, 2020, MULTIMED TOOLS APPL, V79, P9819, DOI 10.1007/s11042-019-07900-x
   Yaacoub JPA, 2020, MICROPROCESS MICROSY, V77, DOI 10.1016/j.micpro.2020.103201
   Yuan HR, 2020, INFORM SCIENCES, V541, P409, DOI 10.1016/j.ins.2020.07.005
   Zhang G, 2022, LECT NOTES ELECT ENG, V813
NR 36
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 19
PY 2023
DI 10.1007/s11042-023-17052-8
EA OCT 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6OE7
UT WOS:001085969000012
DA 2024-07-18
ER

PT J
AU Wu, CM
   Wang, ZR
AF Wu, Chengmao
   Wang, Zeren
TI Quadratic surface center-based possibilistic fuzzy clustering with
   kernel metric and local information for image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image segmentation; Possibilistic fuzzy clustering; Kernel function;
   Quadratic polynomial surface; Local information
ID ALGORITHM
AB Kernel fuzzy weighted local information c-means (KWFLICM) algorithm has good segmentation effect in segmenting noisy images, but it can not effectively segment images with low contrast or high noise. The improved algorithm of KWFLICM is a kernel possibilistic fuzzy c-means clustering with local information (KWPFLICM), which has better anti-noise performance. However, this algorithm loses more details of original image when segmenting the image. In this paper, a kernel-based possibilistic fuzzy local information clustering algorithm based on quadratic polynomial is proposed to overcome the shortcomings of KWPFLICM algorithm. At the same time, the local membership information of neighborhood pixels is introduced as the penalty factor to update the local information, so as to further improve the robustness of the algorithm. By optimizing the objective function of modified possibilistic fuzzy local information clustering with quadratic surface centers, the formulas of fuzzy membership, possibilistic typicality, and the coefficients of quadratic polynomial center are derived theoretically, and the convergence of the proposed algorithm is strictly proved by Zangwill theorem and bordered Hessian matrix. Experimental results show that compared with existing state-of-the-art fuzzy clustering-related algorithms, the proposed algorithm has better segmentation performance and stronger anti-noise robustness, and can effectively suppress noise and retain details. It will have far-reaching significance for the development of robust fuzzy clustering segmentation theory.
C1 [Wu, Chengmao; Wang, Zeren] Xian Univ Posts & Telecommun, Sch Elect Engn, Xian 710121, Peoples R China.
C3 Xi'an University of Posts & Telecommunications
RP Wang, ZR (corresponding author), Xian Univ Posts & Telecommun, Sch Elect Engn, Xian 710121, Peoples R China.
EM wangze_ren@foxmail.com
FU This work was supported by the National Natural Science Foundation of
   China (grant numbers 61671377), and the Natural Science Foundation of
   Shaanxi Province (2022JM-370). Wu and Liu would like to thank the
   anonymous reviewers for their constructive suggest [61671377]; National
   Natural Science Foundation of China [2022JM-370]; Natural Science
   Foundation of Shaanxi Province
FX This work was supported by the National Natural Science Foundation of
   China (grant numbers 61671377), and the Natural Science Foundation of
   Shaanxi Province (2022JM-370). Wu and Liu would like to thank the
   anonymous reviewers for their constructive suggestions to improve the
   overall quality of the paper.
CR Abu MS, 2015, AIP CONF PROC, V1660, DOI 10.1063/1.4915677
   [Anonymous], 1969, Nonlinear Programming, A Unified Approach
   Bennai MT, 2020, ARTIF INTELL MED, V110, DOI 10.1016/j.artmed.2020.101980
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Chang-Chien SJ, 2021, SOFT COMPUT, V25, P1699, DOI 10.1007/s00500-020-04924-6
   Chen GP, 2022, DIGIT SIGNAL PROCESS, V130, DOI 10.1016/j.dsp.2022.103742
   Chen L, 2022, ENG APPL ARTIF INTEL, V116, DOI 10.1016/j.engappai.2022.105335
   Dhar Soumyadip, 2021, Applied Soft Computing, V112, DOI 10.1016/j.asoc.2021.107759
   Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046
   Eelbode T, 2020, IEEE T MED IMAGING, V39, P3679, DOI 10.1109/TMI.2020.3002417
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2013, IEEE T IMAGE PROCESS, V22, P573, DOI 10.1109/TIP.2012.2219547
   Güven SA, 2023, BIOMED SIGNAL PROCES, V80, DOI 10.1016/j.bspc.2022.104246
   Jha P, 2021, COMPUT BIOL CHEM, V92, DOI 10.1016/j.compbiolchem.2021.107454
   Jin DR, 2021, IEEE T SYST MAN CY-S, V51, P4365, DOI 10.1109/TSMC.2019.2931699
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, P98, DOI 10.1109/91.227387
   Liu B, 2019, IEEE ACCESS, V7, P42169, DOI 10.1109/ACCESS.2019.2907573
   Memon KH, 2019, INT J FUZZY SYST, V21, P321, DOI 10.1007/s40815-018-0537-9
   Montero D, 2022, ENG APPL ARTIF INTEL, V114, DOI 10.1016/j.engappai.2022.105079
   Pham NV, 2021, KNOWL-BASED SYST, V216, DOI 10.1016/j.knosys.2020.106549
   Ogohara K, 2022, COMPUT GEOSCI-UK, V160, DOI 10.1016/j.cageo.2022.105043
   Oskouei AG, 2021, APPL SOFT COMPUT, V113, DOI 10.1016/j.asoc.2021.108005
   Pal NR, 2005, IEEE T FUZZY SYST, V13, P517, DOI 10.1109/TFUZZ.2004.840099
   Pal NR, 1997, PROCEEDINGS OF THE SIXTH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS I - III, P11, DOI 10.1109/FUZZY.1997.616338
   Saha A, 2019, IEEE T CYBERNETICS, V49, P4229, DOI 10.1109/TCYB.2018.2861211
   Shu X, 2021, SIGNAL PROCESS, V189, DOI 10.1016/j.sigpro.2021.108293
   Singh A, 2021, EGYPT J REMOTE SENS, V24, P151, DOI 10.1016/j.ejrs.2020.06.001
   Szilágyi L, 2020, ACTA U SAPIEN INFORM, V12, P302, DOI 10.2478/ausi-2020-0018
   Szilágyi L, 2011, LECT NOTES ARTIF INT, V6820, P150, DOI 10.1007/978-3-642-22589-5_15
   Tan XW, 2021, IEEE GEOSCI REMOTE S, V18, P533, DOI 10.1109/LGRS.2020.2976551
   Ullmann T, 2022, WIRES DATA MIN KNOWL, V12, DOI 10.1002/widm.1444
   Umirzakova S, 2022, KNOWL-BASED SYST, V250, DOI 10.1016/j.knosys.2022.109036
   Wang HY, 2022, INFORM SCIENCES, V618, P270, DOI 10.1016/j.ins.2022.11.010
   Weng GR, 2021, ENG APPL ARTIF INTEL, V104, DOI 10.1016/j.engappai.2021.104299
   Wu CM, 2023, ADV ENG SOFTW, V176, DOI 10.1016/j.advengsoft.2022.103377
   Wu CM, 2022, EXPERT SYST APPL, V201, DOI 10.1016/j.eswa.2022.117019
   Wu CM, 2022, PATTERN RECOGN, V128, DOI 10.1016/j.patcog.2022.108686
   Wu CM, 2021, DIGIT SIGNAL PROCESS, V118, DOI 10.1016/j.dsp.2021.103200
   Wu CM, 2022, INT J MACH LEARN CYB, V13, P963, DOI 10.1007/s13042-021-01429-y
   Wu CM, 2021, SOFT COMPUT, V25, P3751, DOI 10.1007/s00500-020-05403-8
   Wu WL, 2020, IEEE INT CONF FUZZY, DOI 10.1109/fuzz48607.2020.9177576
   Wu XH, 2006, INT C COMMUN CIRCUIT, P2062, DOI 10.1109/ICCCAS.2006.285084
   Wu ZD, 2003, ICCIMA 2003: FIFTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, PROCEEDINGS, P49
   Xie YK, 2020, IEEE J-STARS, V13, P1842, DOI 10.1109/JSTARS.2020.2991391
   Yadav NK, 2022, ENG APPL ARTIF INTEL, V111, DOI 10.1016/j.engappai.2022.104709
   Yang MS, 2015, INFORM SCIENCES, V309, P138, DOI 10.1016/j.ins.2015.03.006
   YANG MS, 1993, COMPUT MATH APPL, V25, P3, DOI 10.1016/0898-1221(93)90181-T
   Zare A, 2017, 2017 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI)
   Zhang JP, 2021, IEEE T MED IMAGING, V40, P661, DOI 10.1109/TMI.2020.3034995
   Zhang XF, 2021, COMPUT VIS MEDIA, V7, P513, DOI 10.1007/s41095-021-0239-3
   Zhang XL, 2020, IEEE ACCESS, V8, P95681, DOI 10.1109/ACCESS.2020.2995660
   Zhang XJ, 2021, SIGNAL PROCESS, V178, DOI 10.1016/j.sigpro.2020.107767
   Zhao F, 2013, DIGIT SIGNAL PROCESS, V23, P184, DOI 10.1016/j.dsp.2012.09.016
NR 54
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 17
PY 2023
DI 10.1007/s11042-023-15267-3
EA OCT 2023
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U5AL0
UT WOS:001084922000017
DA 2024-07-18
ER

PT J
AU Miao, XA
   Liu, T
AF Miao, Xiao-Ai
   Liu, Tao
TI Blockchain transaction model based on malicious node detection network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Blockchain; Neural Networks; Malicious node detection; Attention
   mechanism; Hierarchical network model
AB In this day and age, blockchain technology has become very popular. More and more transactions have been completed through the blockchain platform. The blockchain trading platform is fast, low-cost and high security. Many companies use blockchain for online transactions. However, with the increase in transaction volume and transaction scale, malicious users (nodes) appear, and malicious nodes participate in the blockchain network to carry out improper transactions, which brings huge losses to the transaction party. This paper proposes a Blockchain transaction model based on a malicious node detection network to ensure the safety of transaction users and enable the blockchain transaction to be traded in a safe environment. Aiming at the problem of malicious nodes deliberately submitting malicious information or obtaining Bitcoin through malicious behaviors on the blockchain, a malicious node detection model (MNDM) based on a hierarchical neural network is proposed. The hierarchical network model can calculate the key attributes according to the behavior of the nodes to detect abnormal nodes and kick them out of the blockchain system. The proposed model can avoid unnecessary losses caused by malicious nodes participating in data transmission and transactions and stop losses in time. The constructed model is called a hierarchical network model because it has two significant levels and realizes the reduction of parameter volume and the calculation of key information on the levels. Comparative tests are given in this paper. The validity of the model is proved by calculating the accuracy, precision, recall rate, and F1 score of the malicious node detection model.
C1 [Miao, Xiao-Ai] Qingdao Vocat & Tech Coll Hotel Management, Qingdao 266100, Peoples R China.
   [Liu, Tao] Shandong Univ Sci & Technol, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology
RP Liu, T (corresponding author), Shandong Univ Sci & Technol, Qingdao 266590, Peoples R China.
EM 2756332639@qq.com; taoliu0201@sdust.edu.cn
CR Atzei N, 2017, LECT NOTES COMPUT SC, V10204, P164, DOI 10.1007/978-3-662-54455-6_8
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Cho KYHY, 2014, Arxiv, DOI [arXiv:1406.1078, DOI 10.3115/V1/D14-1179, 10.48550/ARXIV.1406.1078, DOI 10.48550/ARXIV.1406.1078]
   Christidis K, 2016, IEEE ACCESS, V4, P2292, DOI 10.1109/ACCESS.2016.2566339
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Gao X, 2020, PROC CVPR IEEE, P7161, DOI 10.1109/CVPR42600.2020.00719
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hssayeni MD, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00491-1
   Hu T, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102462
   Kingma D. P., 2014, arXiv
   Kosba A, 2016, P IEEE S SECUR PRIV, P839, DOI 10.1109/SP.2016.55
   Lee D, 2021, MULTIMED TOOLS APPL, V80, P34517, DOI 10.1007/s11042-020-08776-y
   Leng XL, 2021, MULTIMED TOOLS APPL, V80, P12581, DOI 10.1007/s11042-020-10336-3
   Lin D, 2020, IEEE T CIRCUITS-II, V67, P2737, DOI 10.1109/TCSII.2020.2968376
   Lin D, 2020, FRONT PHYS-LAUSANNE, V8, DOI 10.3389/fphy.2020.00204
   Liu JX, 2021, MULTIMED TOOLS APPL, V80, P30691, DOI 10.1007/s11042-021-10513-y
   Liu YH, 2019, Arxiv, DOI arXiv:1907.11692
   Liu Y, 2021, MULTIMED TOOLS APPL, V80, P30707, DOI 10.1007/s11042-021-10558-z
   Luu L, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P254, DOI 10.1145/2976749.2978309
   Merity S, 2019, Arxiv, DOI arXiv:1911.11423
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, 10.48550/arXiv.1301.3781]
   Peyvandi A, 2022, Multimed Tools Appl, P1
   Raj A, 2021, MULTIMED TOOLS APPL, V80, P18901, DOI 10.1007/s11042-021-10715-4
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762, 10.48550/arXiv.1706.03762]
   Wood G., 2014, Ethereum project yellow paper, V151, P1
   Wu JJ, 2022, IEEE T SYST MAN CY-S, V52, P1156, DOI 10.1109/TSMC.2020.3016821
   Xiong W, 2021, INFORM SCIENCES, V555, P386, DOI 10.1016/j.ins.2020.10.053
   Yang J., 2020, IEEE Trans Ind Inform
   Yang Q, 2020, IEEE Trans Ind Inform
   Yang ZL, 2020, Arxiv, DOI arXiv:1906.08237
   Zhang F, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P270, DOI 10.1145/2976749.2978326
   Zhaofeng M, 2020, IEEE Internet Things J
   Zheng PL, 2020, IEEE OPEN J COMP SOC, V1, P95, DOI 10.1109/OJCS.2020.2990458
   Zheng ZB, 2017, IEEE INT CONGR BIG, P557, DOI 10.1109/BigDataCongress.2017.85
NR 35
TC 0
Z9 0
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 11
PY 2023
DI 10.1007/s11042-023-17241-5
EA OCT 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U3QO4
UT WOS:001083978800008
DA 2024-07-18
ER

PT J
AU Zhu, ZW
   Liu, LF
AF Zhu, Ziwen
   Liu, Lingfeng
TI TPE-C: Thumbnail-preserving encryption based on chaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Balance privacy and usability; Cloud storage; Image encryption; Chaotic
   system
ID IMAGE ENCRYPTION; CRYPTANALYSIS
AB Expandable storage capacity and support for cross-device access have led to an increasing number of people uploading images to the cloud. However, currently mainstream cloud service providers either pursue extreme privacy or extreme usability for images storage, which is obviously not ideal. In order to balance the privacy and usability of images in the cloud, we take advantage of the good dynamic properties of chaotic systems and propose a thumbnail-preserving scheme based on chaotic systems (TPE-C). The core of TPE-C is to design a digital exchange rule based on decimal pixel values, and an effective method based on linear feedback and parameter perturbation with previous variables to improve the dynamics of chaotic systems. Various experimental results show that the performance of logistic map has been effectively improved, and compared with other TPE schemes, TPE-C has the advantages of lossless decryption, low time complexity, and the same thumbnail, which is an ideal TPE scheme.
C1 [Zhu, Ziwen; Liu, Lingfeng] Nanchang Univ, Sch Software, Nanchang 330029, Peoples R China.
C3 Nanchang University
RP Liu, LF (corresponding author), Nanchang Univ, Sch Software, Nanchang 330029, Peoples R China.
EM vatanoilcy@163.com
RI Liu, Lingfeng/W-7547-2018
FU This work is supported by National Natural Science Foundation of China
   (62262039); Outstanding Youth Foundation of Jiangxi Province
   (20212ACB212006); Key Project of Jiangxi Provincial Natural Science
   Foundation (20232ACB202009). [62262039]; National Natural Science
   Foundation of China [20212ACB212006]; Outstanding Youth Foundation of
   Jiangxi Province [20232ACB202009]; Key Project of Jiangxi Provincial
   Natural Science Foundation
FX This work is supported by National Natural Science Foundation of China
   (62262039); Outstanding Youth Foundation of Jiangxi Province
   (20212ACB212006); Key Project of Jiangxi Provincial Natural Science
   Foundation (20232ACB202009).
CR Bandt C, 2002, PHYS REV LETT, V88, DOI 10.1103/PhysRevLett.88.174102
   Bellarc M, 2009, LECT NOTES COMPUT SC, V5867, P295, DOI 10.1007/978-3-642-05445-7_19
   Chen JX, 2021, IEEE T CIRC SYST VID, V31, P2494, DOI 10.1109/TCSVT.2020.3021908
   Chen JX, 2021, IEEE T MULTIMEDIA, V23, P2372, DOI 10.1109/TMM.2020.3011315
   Cohen S, 2020, 1 second-internet live stats
   Demir K, 2020, IET CIRC DEVICE SYST, V14, P569, DOI 10.1049/iet-cds.2019.0356
   Denning T, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2615
   Enfield S, 2020, How Many Photos Will be Taken in 2022?
   Fallon R, 2015, LECT NOTES COMPUT SC, V9089, P49, DOI 10.1007/978-3-319-18609-2_4
   Gregory RL, 1997, PHILOS T ROY SOC B, V352, P1121, DOI 10.1098/rstb.1997.0095
   Harada A., 2005, IPSJ J, V46, P1997
   Hua ZY, 2021, IEEE T SYST MAN CY-S, V51, P3713, DOI 10.1109/TSMC.2019.2932616
   Jolfaei A, 2016, IEEE T INF FOREN SEC, V11, P235, DOI 10.1109/TIFS.2015.2489178
   Kang XJ, 2019, IEEE T CIRC SYST VID, V29, P1919, DOI 10.1109/TCSVT.2018.2859253
   Kinjo H, 2000, AM J PSYCHOL, V113, P95, DOI 10.2307/1423462
   Kok P, 2013, J NEUROSCI, V33, P16275, DOI 10.1523/JNEUROSCI.0742-13.2013
   Li M, 2019, NONLINEAR DYNAM, V96, P31, DOI 10.1007/s11071-019-04771-7
   Liu HJ, 2019, APPL MATH COMPUT, V360, P83, DOI 10.1016/j.amc.2019.04.078
   Marohn B, 2017, PROCEEDINGS OF THE 2017 WORKSHOP ON MULTIMEDIA PRIVACY AND SECURITY (MPS'17), P33, DOI 10.1145/3137616.3137621
   Mokhnache A, 2020, TRAIT SIGNAL, V37, P95, DOI 10.18280/ts.370112
   Musanna F, 2020, IMAGING SCI J, V68, P24, DOI 10.1080/13682199.2020.1732116
   PINCUS S, 1995, CHAOS, V5, P110, DOI 10.1063/1.166092
   Puteaux P, 2021, IEEE T CIRC SYST VID, V31, P3338, DOI 10.1109/TCSVT.2020.3039112
   Qin C, 2019, IEEE T CIRC SYST VID, V29, P3341, DOI 10.1109/TCSVT.2018.2878026
   Rousselet GA, 2004, VISION RES, V44, P877, DOI 10.1016/j.visres.2003.11.014
   Tencent Technology, 2018, Facebook is caught in another privacy leak scandal, 6.8 million users' private photos were shared
   Vidhya R, 2020, MULTIMED TOOLS APPL, V79, P30281, DOI 10.1007/s11042-020-09462-9
   Wang QX, 2016, IEEE T CIRCUITS-I, V63, P401, DOI 10.1109/TCSI.2016.2515398
   Wang XY, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106501
   Wright C.V., 2015, P 3 ACM WORKSH INF H, P141, DOI 10.1145/2756601.2756618
   Yang R., 2019, Comput Netw, V45, P2
   Zhang LY, 2018, INFORM SCIENCES, V430, P228, DOI 10.1016/j.ins.2017.11.021
   Zhang YS, 2022, IEEE T CIRC SYST VID, V32, P947, DOI 10.1109/TCSVT.2021.3070348
   Zhao RY, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.108019
   Zhu ZW, 2022, J KING SAUD UNIV-COM, V34, P10167, DOI 10.1016/j.jksuci.2022.10.014
NR 35
TC 1
Z9 1
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 11
PY 2023
DI 10.1007/s11042-023-17117-8
EA OCT 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U3QO4
UT WOS:001083978800012
DA 2024-07-18
ER

PT J
AU Ahmadsaraei, MF
   Bastanfard, A
   Amini, A
AF Ahmadsaraei, Maryam Fathi
   Bastanfard, Azam
   Amini, Amineh
TI Child psychological drawing pattern detection on OBGET dataset, a case
   study on accuracy based on MYOLO v5 and MResNet 50
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Pattern detection; Deep Learning; MResNet 50; MYOLO v5; Original Bender
   Gestalt Drawing Test Dataset; OBGET for children
ID CONVOLUTIONAL NEURAL-NETWORKS; OBJECT DETECTION; DEEP; CLASSIFICATION;
   MODELS; IMAGE; RECOGNITION; SYSTEM
AB The interpretation of drawing psychological data is amazing, and they behave differently in various situations like age. This research compares different deep learning methods and behaviors on children's data. Therefore, after presenting the collected dataset and statistical analysis, two methods, the proposed modified YOLO V5 as MYOLO V5 and ResNet 50 as MresNet 50, are compared and discussed on the OBGET dataset for children. The classification accuracy of the two proposed methods, the proposed MYOLO V5 and MResNet 50 on the OBGET database for children, has been measured. To prepare conditions for comparing these two algorithms for the first time, necessary preprocessing and the proposed semi-automatic labeling were performed on children's OBGET samples. Children's OBGET contains 386 Original Bender Gestalt Drawing Test samples for children. The proposed MResNet 50 and MYOLO V5 classify patterns in children's OBGET samples as single-stage deep learning methods to obtain acceptable pattern detection accuracy. After deploying the proposed methods on the proposed collected dataset, results show that the proposed MYOLO V5 presents higher accuracy.
C1 [Ahmadsaraei, Maryam Fathi; Bastanfard, Azam; Amini, Amineh] Islamic Azad Univ, Dept Comp Engn, Karaj Branch, Karaj, Iran.
C3 Islamic Azad University
RP Bastanfard, A (corresponding author), Islamic Azad Univ, Dept Comp Engn, Karaj Branch, Karaj, Iran.
EM Maryam.fathi@kiau.ac.ir; bastanfard@kiau.ac.ir; aamini@kiau.ac.ir
FU We gratefully acknowledge Dr. Narges Fathi Ahmadsaraei for her
   cooperation as a psychologist for participating in running and
   interpretation of Original Bender Gestalt Drawing Test.
FX We gratefully acknowledge Dr. Narges Fathi Ahmadsaraei for her
   cooperation as a psychologist for participating in running and
   interpretation of Original Bender Gestalt Drawing Test.
CR Acharya UR, 2018, COMPUT BIOL MED, V100, P270, DOI 10.1016/j.compbiomed.2017.09.017
   Ahamed P, 2020, J AMB INTEL HUM COMP, V11, P5445, DOI 10.1007/s12652-020-01901-7
   Akhlaq F, 2017, A survey of Automated Scoring of the Minicog Psychological test, DOI [10.13140/RG.2.2.29390.97601, DOI 10.13140/RG.2.2.29390.97601]
   Aldape-Pérez M, 2015, COMPUT HUM BEHAV, V51, P771, DOI 10.1016/j.chb.2014.11.091
   Alenazy WM, 2021, J AMB INTEL HUM COMP, V12, P1631, DOI 10.1007/s12652-020-02235-0
   Alissa M, 2022, NEURAL COMPUT APPL, V34, P1433, DOI 10.1007/s00521-021-06469-7
   Ashraf A, 2021, MULTIMED TOOLS APPL, V80, P30117, DOI 10.1007/s11042-020-10331-8
   Awal AM, 2011, PROC SPIE, V7874, DOI 10.1117/12.876624
   Bahrami H., 2006, Psychological Tests (Foundations & Practical Techniques), V3rd
   Bastanfard A, 2010, Advances in Multimedia Information Processing-PCM 2010. PCM 2010. Lecture Notes in Computer Science, V6298, DOI [10.1007/978-3-642-15696, DOI 10.1007/978-3-642-15696]
   Bastanfard A, 2020, 2020 25 INT COMP C, P1, DOI [10.1109/CSICC49403.2020.9050082, DOI 10.1109/CSICC49403.2020.9050082]
   Bastanfard A, 2023, MULTIMED TOOLS APPL, V82, P36413, DOI 10.1007/s11042-023-15132-3
   Bastanfard A, 2022, MULTIMED TOOLS APPL, V81, P23473, DOI 10.1007/s11042-022-12584-x
   Bastanfard A, 2020, 2020 6TH IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS), DOI 10.1109/ICSPIS51611.2020.9349583
   Bastanfard A, 2009, IEEE SYS MAN CYBERN, P169, DOI 10.1109/ICSMC.2009.5346591
   Bentoumi M, 2022, MULTIMED TOOLS APPL, V81, P29887, DOI 10.1007/s11042-022-12058-0
   Cabrera-Quiros L, 2021, IEEE T AFFECT COMPUT, V12, P113, DOI 10.1109/TAFFC.2018.2848914
   Chatterjee A, 2019, COMPUT HUM BEHAV, V93, P309, DOI 10.1016/j.chb.2018.12.029
   Cheah WT, 2022, JMIR MED INF, V10, DOI 10.2196/31106
   Chen SQ, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-74710-9
   Colace F, 2014, COMPUT HUM BEHAV, V30, P689, DOI 10.1016/j.chb.2013.07.043
   Davis W.S., 1998, The Information System Consultant's Handbook: Systems Analysis and Design, V1st, DOI [10.1201/9781420049107, DOI 10.1201/9781420049107]
   Davison AK, 2018, IEEE T AFFECT COMPUT, V9, P116, DOI 10.1109/TAFFC.2016.2573832
   de Myttenaere A, 2016, NEUROCOMPUTING, V192, P38, DOI 10.1016/j.neucom.2015.12.114
   Delavar A, 2001, Applied probabilities and statistics in psychology and educational sciences
   Demisse GG, 2018, IEEE T PATTERN ANAL, V40, P1338, DOI 10.1109/TPAMI.2017.2711607
   Estella-Nonay E, 2022, IWINAC-Lect Notes Comput Sci, V13258, DOI [10.1007/978-3-031-06242-1_41, DOI 10.1007/978-3-031-06242-1_41]
   Fathi Ahmadsaraei M, 2021, An Official Publication of the Iranian Society of Machine Vision and Image Processing
   Garcia-Garcia A, 2018, APPL SOFT COMPUT, V70, P41, DOI 10.1016/j.asoc.2018.05.018
   Gauthier B, 2016, CHILD NEUROPSYCHOL, V22, P238, DOI 10.1080/09297049.2014.988606
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Guha A, 2010, P 16 INT CONFERENCEO
   Harbi Z, 2017, PROCEDIA COMPUT SCI, V112, P1641, DOI 10.1016/j.procs.2017.08.259
   Harbi Z, 2016, PROCEDIA COMPUT SCI, V96, P1221, DOI 10.1016/j.procs.2016.08.166
   Harbi Z, 2015, PROCEDIA COMPUT SCI, V60, P1640, DOI 10.1016/j.procs.2015.08.274
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang SC, 2021, IEEE T PATTERN ANAL, V43, P2623, DOI 10.1109/TPAMI.2020.2977911
   Huang Z, 2021, PROCEDIA COMPUT SCI, V183, P107, DOI 10.1016/j.procs.2021.02.037
   Im YH, 2010, ART PSYCHOTHER, V37, P163, DOI 10.1016/j.aip.2010.03.001
   Kaur J, 2022, MULTIMED TOOLS APPL, V81, P38297, DOI 10.1007/s11042-022-13153-y
   Keshtkar M, 2015, 2015 7TH CONFERENCE ON INFORMATION AND KNOWLEDGE TECHNOLOGY (IKT)
   Kim H, 2014, WORKSHOPS 24 AAAI C, P1, DOI [10.1145/2668883.2668889, DOI 10.1145/2668883.2668889]
   Kim H, 2011, ACM T P 5 INT C TANG, P22
   Kim H, 2012, J AMB INTEL SMART EN, V4, P429, DOI 10.3233/AIS-2012-0165
   Kim SI, 2008, ART PSYCHOTHER, V35, P49, DOI 10.1016/j.aip.2007.09.004
   Kim S, 2007, ART PSYCHOTHER, V34, P223, DOI 10.1016/j.aip.2007.02.002
   Kim SI, 2009, ART PSYCHOTHER, V36, P19, DOI 10.1016/j.aip.2008.09.002
   Kim SI, 2006, ART PSYCHOTHER, V33, P59, DOI 10.1016/j.aip.2005.07.004
   Koppitz EM, 1989, The bender gestalt test for young children
   Leutner D, 2009, COMPUT HUM BEHAV, V25, P284, DOI 10.1016/j.chb.2008.12.010
   Liang YQ, 2010, IEEE T NEUR SYS REH, V18, P560, DOI 10.1109/TNSRE.2010.2047605
   Likforman-Sulem L, 2017, IEEE T HUM-MACH SYST, V47, P273, DOI 10.1109/THMS.2016.2635441
   Lin HJ, 2017, IEEE T KNOWL DATA EN, V29, P1820, DOI 10.1109/TKDE.2017.2686382
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P494, DOI 10.1016/j.image.2014.02.004
   Liu SQ, 2021, IEEE T NEUR SYS REH, V29, P1, DOI 10.1109/TNSRE.2020.3019063
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Luo YH, 2022, MULTIMED TOOLS APPL, V81, P30685, DOI 10.1007/s11042-022-11940-1
   Mahdavi R, 2020, 25 INT COMPUTER C
   Martínez HP, 2013, IEEE COMPUT INTELL M, V8, P20, DOI 10.1109/MCI.2013.2247823
   Minoofam SAH, 2022, MULTIMED TOOLS APPL, V81, P6389, DOI 10.1007/s11042-021-11806-y
   Minoofam SAH, 2012, J CELL AUTOM, V7, P321
   Miranda-Correa JA, 2021, IEEE T AFFECT COMPUT, V12, P479, DOI 10.1109/TAFFC.2018.2884461
   MirMashhouri A, 2022, MULTIMED TOOLS APPL, V81, P18935, DOI 10.1007/s11042-022-11966-5
   Modhej N, 2022, Computational pattern separation models of dentate gyrus neural subpopulation in the hippocampus, V8, P244
   Moetesum M, 2020, NEURAL COMPUT APPL, V32, P12909, DOI 10.1007/s00521-020-04735-8
   Moetesum M, 2019, PATTERN RECOGN LETT, V121, P19, DOI 10.1016/j.patrec.2018.04.008
   Moetesum M, 2017, INT CONF FRONT INFO, P258, DOI 10.1109/FIT.2017.00053
   Moetesum M, 2015, PROC INT CONF DOC, P666, DOI 10.1109/ICDAR.2015.7333845
   Mohammadi SM, 2021, IEEE T NEUR SYS REH, V29, P290, DOI 10.1109/TNSRE.2020.3048121
   Murthy CB, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10093280
   Najafabadi MK, 2017, COMPUT HUM BEHAV, V67, P113, DOI 10.1016/j.chb.2016.11.010
   Nazar HB, 2018, 14 IAPR INT C DOCUME, P432
   Nirjon S, 2014, P WIRELESS HLTH NATL, P1
   Ong DC, 2021, IEEE T AFFECT COMPUT, V12, P579, DOI [10.1109/TAFFC.2019.2955949, 10.1109/taffc.2019.2955949]
   Quiniou S, 2011, PROC INT CONF DOC, P452, DOI 10.1109/ICDAR.2011.97
   Rawassizadeh R, 2016, IEEE T KNOWL DATA EN, V28, P3098, DOI 10.1109/TKDE.2016.2592527
   Rehman A, 2014, ARTIF INTELL REV, V42, P253, DOI 10.1007/s10462-012-9337-z
   Ruengchaijatuporn N, 2022, ALZHEIMERS RES THER, V14, DOI 10.1186/s13195-022-01043-2
   Vazquez DR, 2020, COMPUT SIST, V24, P1483, DOI [10.13053/CyS-24-4-3359, 10.13053/cys-24-4-3359]
   Sangkloy P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925954
   Sarvadevabhatla RK, 2020, IEEE T PATTERN ANAL, V42, P221, DOI 10.1109/TPAMI.2018.2877996
   Savargiv M., 2014, Journal of Computer & Robotics, V7, P19
   Savargiv M, 2016, 2016 ARTIFICIAL INTELLIGENCE AND ROBOTICS (IRANOPEN), P72, DOI 10.1109/RIOS.2016.7529493
   Savargiv M, 2013, 2013 INTERNATIONAL CONFERENCE ON FUZZY THEORY AND ITS APPLICATIONS (IFUZZY 2013), P380, DOI 10.1109/iFuzzy.2013.6825469
   Schouten K, 2016, IEEE T KNOWL DATA EN, V28, P813, DOI 10.1109/TKDE.2015.2485209
   Shi SS, 2021, IEEE T PATTERN ANAL, V43, P2647, DOI 10.1109/TPAMI.2020.2977026
   Siddan G, 2022, MULTIMED TOOLS APPL, V81, P2393, DOI 10.1007/s11042-021-11543-2
   Sindagi VA, 2018, PATTERN RECOGN LETT, V107, P3, DOI 10.1016/j.patrec.2017.07.007
   Souillard-Mandar W, 2016, Arxiv, DOI [arXiv:1606.07163, 10.48550/arXiv.1606.07163, DOI 10.48550/ARXIV.1606.07163]
   Souillard-Mandar W, 2016, MACH LEARN, V102, P393, DOI 10.1007/s10994-015-5529-5
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Takbiri Y, 2023, MULTIMED TOOLS APPL, V82, P20683, DOI 10.1007/s11042-023-14356-7
   Thangakrishnan MS, 2021, J AMB INTEL HUM COMP, V12, P6407, DOI 10.1007/s12652-020-02248-9
   Trotzek M, 2020, IEEE T KNOWL DATA EN, V32, P588, DOI 10.1109/TKDE.2018.2885515
   Valenzuela SE, 2020, 2020 IEEE ANDESCON, P1, DOI [10.1109/ANDESCON50619.2020.9272066, DOI 10.1109/ANDESCON50619.2020.9272066]
   Vargas A, 2020, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2020, DOI 10.1145/3399715.3399916
   Vishwakarma R, 2020, IEEE INT CONF BIG DA, P5609, DOI 10.1109/BigData50022.2020.9377902
   Wan SH, 2018, COMPUT ELECTR ENG, V72, P274, DOI 10.1016/j.compeleceng.2018.07.042
   Wang F, 2017, COMPUT GRAPH FORUM, V36, P157, DOI 10.1111/cgf.13281
   Wohlfahrt-Laymann J, 2019, J AMB INTEL HUM COMP, V10, P2143, DOI 10.1007/s12652-018-0827-y
   Xiao YZ, 2020, MULTIMED TOOLS APPL, V79, P23729, DOI 10.1007/s11042-020-08976-6
   Xiao ZZ, 2022, IEEE T AFFECT COMPUT, V13, P408, DOI 10.1109/TAFFC.2019.2945322
   Xue T, 2021, MULTIMED TOOLS APPL, V80, P27855, DOI 10.1007/s11042-021-10893-1
   Yan B, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13091619
   Youn YC, 2021, ALZHEIMERS RES THER, V13, DOI 10.1186/s13195-021-00821-8
   Zeeshan MO, 2021, LECT NOTES COMPUT SC, V12822, P321, DOI 10.1007/978-3-030-86331-9_21
   Zhang H, 2019, MULTIMED TOOLS APPL, V78, P27809, DOI 10.1007/s11042-019-07898-2
   Zhang QC, 2018, INFORM FUSION, V42, P146, DOI 10.1016/j.inffus.2017.10.006
   Zhao X, 2017, COMM COM INF SC, V773, P233, DOI 10.1007/978-981-10-7305-2_21
NR 109
TC 1
Z9 1
U1 9
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 7
PY 2023
DI 10.1007/s11042-023-17112-z
EA OCT 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2OY9
UT WOS:001096913600020
DA 2024-07-18
ER

PT J
AU Gupta, S
   Thakur, S
   Gupta, A
AF Gupta, Shubhi
   Thakur, Sanjeev
   Gupta, Ashutosh
TI Comparative study of different machine learning models for automatic
   diabetic retinopathy detection using fundus image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Diabetic retinopathy detection; Machine learning (ML); Haralick
   features; Wavelet transforms
ID CLASSIFICATION; SEGMENTATION; SYSTEM
AB Diabetics suffer from an eye condition called diabetic retinopathy (DR), which can lead to vision loss. The main region affected is the blood vessels in the retina. A large proportion of the world's population is suffering from the harmful effects of diabetes, and most of them are not recognized early. Severe vision loss can be reduced through early detection, diagnosis, and treatment efficiency. The manual errors and tedious work of ophthalmologists can be reduced by using computer-assisted automatic diagnosis of DR. This paper provides a comparative study and analysis of different segmentation, feature extraction and classification methods used for the automatic detection of DR. The fundus images from the Kaggle data set will be used to evaluate these techniques. The best results were obtained when Watershed Transform (WT) and Triplet Half Band Filter Bank (THFB) based segmentation and Haralick, and ADTCWT (Anisotropic Dual Tree Complex Wavelet Transform) based feature extraction together with machine learning based SVM (Support Vector Machine) classifier. The performance of the classifiers was evaluated in terms of accuracy, precision, F-Score, TPR (True Positive Rate), TNR (True Negative Rate), Kappa, FPR (False Positive Rate), FNR (False Negative rate), pixel accuracy, Jaccard similarity, cube coefficient, VOE (volumetric overlap error) and SVD (symmetric volume difference). The SVM model obtained a training accuracy of (98.42%).
C1 [Gupta, Shubhi] Amity Univ, Dept Comp Sci, Noida, Uttar Pradesh, India.
   [Thakur, Sanjeev] Amity Univ, Noida, Uttar Pradesh, India.
   [Gupta, Ashutosh] UP Rajarshi Tandon Open Univ, Noida, Uttar Pradesh, India.
C3 Amity University Noida; Amity University Noida
RP Gupta, S (corresponding author), Amity Univ, Dept Comp Sci, Noida, Uttar Pradesh, India.
EM sr23.shubhi@gmail.com
CR Abdelmaksoud E, 2021, IEEE ACCESS, V9, P15939, DOI 10.1109/ACCESS.2021.3052870
   Abirami A, 2023, SIGNAL IMAGE VIDEO P, V17, P1945, DOI 10.1007/s11760-022-02407-9
   Adem K, 2018, EXPERT SYST APPL, V114, P289, DOI 10.1016/j.eswa.2018.07.053
   Ahmadieh H, 2021, DOC OPHTHALMOL, V142, P305, DOI 10.1007/s10633-020-09805-9
   Amin J, 2018, MICROSC RES TECHNIQ, V81, P990, DOI 10.1002/jemt.23063
   Asiri N, 2019, ARTIF INTELL MED, V99, DOI 10.1016/j.artmed.2019.07.009
   Barmparis GD, 2020, CHAOS SOLITON FRACT, V135, DOI 10.1016/j.chaos.2020.109842
   Bellemo V, 2019, CURR DIABETES REP, V19, DOI 10.1007/s11892-019-1189-3
   Berbar MA, 2022, HEALTH INF SCI SYST, V10, DOI 10.1007/s13755-022-00181-z
   Bhardwaj C, 2021, NEURAL COMPUT APPL, V33, P13999, DOI 10.1007/s00521-021-06042-2
   Bhardwaj C, 2021, J AMB INTEL HUM COMP, V12, P2649, DOI 10.1007/s12652-020-02426-9
   Das D, 2022, MULTIMED TOOLS APPL, V81, P25613, DOI 10.1007/s11042-022-12642-4
   Derwin DJ., 2020, Biomed Signal Process Control, V58, P1
   Fraz MM, 2019, ARCH COMPUT METHOD E, V26, P1193, DOI 10.1007/s11831-018-9281-4
   Gadekallu TR, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01963-7
   Gayathri S, 2020, BIOMED SIGNAL PROCES, V62, DOI 10.1016/j.bspc.2020.102115
   Gayathri S, 2020, IEEE ACCESS, V8, P57497, DOI 10.1109/ACCESS.2020.2979753
   Graham PS, 2018, BMC MED GENET, V19, DOI [10.1186/s12881-018-0587-8, 10.1186/S12881-018-0587-8]
   Gundluru N, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/8512469
   Herliana A, 2018, 2018 6TH INTERNATIONAL CONFERENCE ON CYBER AND IT SERVICE MANAGEMENT (CITSM), P128
   Jadhav AS, 2021, EVOL INTELL, V14, P1431, DOI 10.1007/s12065-020-00400-0
   Kandhasamy JP, 2020, MULTIMED TOOLS APPL, V79, P10581, DOI 10.1007/s11042-019-7485-8
   Kausu TR, 2018, BIOCYBERN BIOMED ENG, V38, P329, DOI 10.1016/j.bbe.2018.02.003
   Koh JEW, 2018, APPL INTELL, V48, P1379, DOI 10.1007/s10489-017-1048-3
   Kumar SD, 2020, MICROPROCESS MICROSY, V76, DOI 10.1016/j.micpro.2020.103090
   Kumar S, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105815
   Lawrenson JG, 2021, DIABETIC MED, V38, DOI 10.1111/dme.14425
   Mayyaa V, 2021, COMPUT METH PROG BIO, V1, P1, DOI 10.1016/j.cmpbup.2021.100013
   Mazlan N, 2019, COMP M BIO BIO E-IV, V7, P52, DOI 10.1080/21681163.2017.1402711
   Nazir T, 2019, ARTIF INTELL MED, V99, DOI 10.1016/j.artmed.2019.07.003
   Nisha KL, 2019, COMPUT MED IMAG GRAP, V74, P72, DOI 10.1016/j.compmedimag.2019.04.003
   Priya RP, 2022, INT J NUMER METH BIO, V38, DOI 10.1002/cnm.3560
   Raevis Joseph, 2020, Am J Ophthalmol Case Rep, V20, P100993, DOI 10.1016/j.ajoc.2020.100993
   Rahim T, 2020, COMPUT MED IMAG GRAP, V85, DOI 10.1016/j.compmedimag.2020.101767
   Ramani RG, 2020, BIOMED SIGNAL PROCES, V58, DOI 10.1016/j.bspc.2019.101832
   Randive SN, 2018, EVOL INTELL, V11, P117, DOI 10.1007/s12065-018-0158-0
   Remeseiro B, 2021, VISUAL COMPUT, V37, P1247, DOI 10.1007/s00371-020-01863-z
   Rundo Leonardo, 2019, Parallel Computing Technologies. 15th International Conference, PaCT 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11657), P304, DOI 10.1007/978-3-030-25636-4_24
   Salamat N, 2019, ARTIF INTELL MED, V97, P168, DOI 10.1016/j.artmed.2018.10.009
   Sankaran S, 2021, InElectronic Devices, Circuits, and Systems for Biomedical Applications, Academic Press,Elsevier, V17, P365
   Saygili A, 2021, APPL SOFT COMPUT, V105, DOI 10.1016/j.asoc.2021.107323
   Shankar K, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-2568-8
   Shinde A, 2019, MULTIMED TOOLS APPL, V78, P23489, DOI 10.1007/s11042-019-7697-y
   Stolte S, 2020, MED IMAGE ANAL, V64, DOI 10.1016/j.media.2020.101742
   Subramanian B., 2019, Int J Eng Adv Technol, V9, P618
   Tavakoli M, 2021, IET IMAGE PROCESS, V15, P1484, DOI 10.1049/ipr2.12119
   Tönnies T, 2019, DIABETIC MED, V36, P1217, DOI 10.1111/dme.13902
   Uysal E, 2021, MULTIMED TOOLS APPL, V80, P3505, DOI 10.1007/s11042-020-09372-w
   Vinayaki V. Desika, 2022, 2022 IEEE International Conference on Signal Processing, Informatics, Communication and Energy Systems (SPICES), P55, DOI 10.1109/SPICES52834.2022.9774065
   Vinayaki VD, 2022, NEURAL PROCESS LETT, V54, P2363, DOI 10.1007/s11063-021-10734-0
   Washburn PS, 2020, MATER TODAY-PROC, V33, P3037, DOI 10.1016/j.matpr.2020.03.199
   Wu Z, 2020, ARTIF INTELL MED, V108, DOI 10.1016/j.artmed.2020.101936
   Yanase J, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.112821
NR 53
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 26
PY 2023
DI 10.1007/s11042-023-16813-9
EA SEP 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA S8YJ1
UT WOS:001073965700014
DA 2024-07-18
ER

PT J
AU Lu, JY
   Chai, YK
   Hu, ZR
   Sun, Y
AF Lu, Jingyi
   Chai, Yongkang
   Hu, Zhongrui
   Sun, Ying
TI A novel image denoising algorithm and its application in UAV inspection
   of oil and gas pipelines
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Particle swarm optimization; Two-dimensional variational modal
   decomposition; Bhattacharyy distance; Image denoising
ID VARIATIONAL MODE DECOMPOSITION; FAULT-DIAGNOSIS; OPTIMIZATION; VMD
AB For the problem of blurred images in the process of UAV video inspection of oil and gas pipelines, a PSO-2D-VMD-BD denoising algorithm is proposed in this paper. The procedure of the developed algorithm is that: (1) the particle swarm optimization (PSO) is used to optimize K and & alpha; of the two-dimensional variational modal decomposition (2D-VMD); (2) use the 2D-VMD to decompose the oil and gas pipelines image into K intrinsic mode functions (IMFs); (3) use the Bhattacharyy Distance (BD) and the probability density function (PDF) to distinguish the signal-dominant IMFs (S-D IMFs) and the noise-dominant IMFs (N-D IMFs), and then use the wavelet threshold denoising method to eliminate the noise in the N-D IMFs; and (4) finally, the oil and gas pipelines image is reconstructed using the denoised N-D IMFs and S-D IMFs to obtain the denoised image. Compared to median filtering, wavelet threshold filtering, the Rudin Osher Fatemi (ROF), the 2D-VMD-BD, and the PSO-2D-VMD-KLD, theoretical analysis and simulation results indicate that the solution presented in this paper achieved a decent denoising effect, which can provide a solid foundation for the subsequent recognition of oil and gas pipelines by UAV inspection.
C1 [Lu, Jingyi; Chai, Yongkang; Hu, Zhongrui] Northeast Petr Univ, SANYA Offshore Oil & Gas Res Inst, Daqing, Peoples R China.
   [Lu, Jingyi; Chai, Yongkang; Sun, Ying] Northeast Petr Univ, Coll Elect & Lnformat Engn, Daqing 163318, Peoples R China.
   [Lu, Jingyi] Northeast Petr Univ, Heilongjiang Prov Key Lab Networking & Intelligent, Daqing 163318, Heilongjiang, Peoples R China.
C3 Northeast Petroleum University; Northeast Petroleum University;
   Northeast Petroleum University
RP Chai, YK; Hu, ZR (corresponding author), Northeast Petr Univ, SANYA Offshore Oil & Gas Res Inst, Daqing, Peoples R China.; Chai, YK (corresponding author), Northeast Petr Univ, Coll Elect & Lnformat Engn, Daqing 163318, Peoples R China.
EM tj_cyk1998@126.com; zhong_rui_hu@163.com
OI Hu, Zhongrui/0000-0001-6631-7826
FU National Natural Science Foundation of China [61873058]; Natural Science
   Foundation of Heilongjiang Province [LH2022F009, LH2020F005]; Hainan
   Province Science and Technology Special Fund [ZDYF2022SHFZ105]
FX & nbsp;The National Natural Science Foundation of China (61873058), The
   Natural Science Foundation of Heilongjiang Province (LH2022F009), The
   Natural Science Foundation of Heilongjiang Province (LH2020F005), Hainan
   Province Science and Technology Special Fund (ZDYF2022SHFZ105).
CR Deng HY, 2020, INFORM SCIENCES, V528, P246, DOI 10.1016/j.ins.2020.04.028
   Gao HY, 2020, SYST SCI CONTROL ENG, V8, P297, DOI 10.1080/21642583.2020.1756523
   Gollamandala UB, 2022, MICROPROCESS MICROSY, V90, DOI 10.1016/j.micpro.2022.104520
   Guo SL, 2022, BIOMED SIGNAL PROCES, V75, DOI 10.1016/j.bspc.2022.103552
   Komaty A, 2014, IEEE T INSTRUM MEAS, V63, P27, DOI 10.1109/TIM.2013.2275243
   Li HX, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11020126
   Li ZP, 2017, MECH SYST SIGNAL PR, V85, P512, DOI 10.1016/j.ymssp.2016.08.042
   Liu YY, 2016, SIGNAL PROCESS, V125, P349, DOI 10.1016/j.sigpro.2016.02.011
   Lu JY, 2021, MEASUREMENT, V185, DOI 10.1016/j.measurement.2021.110107
   Lu JY, 2020, MEASUREMENT, V151, DOI 10.1016/j.measurement.2019.107283
   Ma LY, 2022, BIOMED SIGNAL PROCES, V78, DOI 10.1016/j.bspc.2022.103889
   [钱林 Qian Lin], 2017, [振动与冲击, Journal of Vibration and Shock], V36, P227
   Routray S, 2020, OPTIK, V216, DOI 10.1016/j.ijleo.2020.164903
   Siddig A, 2018, COMPUT MATH APPL, V76, P1056, DOI 10.1016/j.camwa.2018.05.040
   Tay DB, 2021, SIGNAL PROCESS, V189, DOI 10.1016/j.sigpro.2021.108302
   Voloshynovskiy S, 2005, SIGNAL PROCESS, V85, P1950, DOI 10.1016/j.sigpro.2005.04.007
   Wang GH, 2018, OPTIK, V173, P157, DOI 10.1016/j.ijleo.2018.08.013
   Yu Y, 2023, NEURAL NETWORKS, V166, P162, DOI 10.1016/j.neunet.2023.07.005
   Zhang FL, 2020, SIGNAL PROCESS, V177, DOI 10.1016/j.sigpro.2020.107738
   Zhang L, 2018, OPTIK, V158, P1575, DOI 10.1016/j.ijleo.2017.12.147
   Zhang M, 2017, MECH SYST SIGNAL PR, V93, P460, DOI 10.1016/j.ymssp.2017.02.013
   Zhang X, 2018, MECH SYST SIGNAL PR, V108, P58, DOI 10.1016/j.ymssp.2017.11.029
   Zhu J, 2017, P I MECH ENG C-J MEC, V231, P635, DOI 10.1177/0954406215623311
NR 23
TC 0
Z9 0
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 26
PY 2023
DI 10.1007/s11042-023-16752-5
EA SEP 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA S5NV5
UT WOS:001071641500004
DA 2024-07-18
ER

PT J
AU Echtioui, A
   Ben Ayed, Y
AF Echtioui, Amira
   Ben Ayed, Yassine
TI Automated detection of COVID-19 based on transfer learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; Pneumonia; X-ray image; Transfer learning
AB The world has recently experienced unprecedented disruptions due to the COVID-19 pandemic, which have greatly impacted daily life. Deep Learning (DL) is a branch of Artificial Intelligence (AI) that has seen significant growth in recent years, and its features could be useful in the fight against COVID-19. By leveraging these features, public health efforts could be better supported. In this research, we propose a method for detecting COVID-19 positive patients using chest X-ray images. Our method employs pre-trained deep neural networks, specifically the DenseNet-169 and ResNet-50 architectures. For each architecture, we kept the basic model and replaced the border layers with Dense layers. We used 2Dense in the first iteration and 5Dense in the second iteration. Our results show that Transfer Learning (TL) is a useful technique for detecting COVID-19 cases. The DenseNet-169 + 2Dense, DenseNet-169 + 5Dense, and using the ELU function achieved the highest accuracy value of 90.04%.
C1 [Echtioui, Amira] Sfax Univ, Natl Engn Sch Sfax ENIS, Adv Technol Med & Signals Lab ATMS, Sfax, Tunisia.
   [Ben Ayed, Yassine] Sfax Univ, Natl Engn Sch Sfax ENIS, MIRACL Multimedia InfoRmat Syst & Adv Comp Lab, Sfax, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   Multimedia, InfoRmation Systems & Advancing Computing Laboratory
   (MIRACL)
RP Echtioui, A (corresponding author), Sfax Univ, Natl Engn Sch Sfax ENIS, Adv Technol Med & Signals Lab ATMS, Sfax, Tunisia.
EM echtiouiamira@yahoo.fr; yassine.benayed@isims.usf.tn
OI Echtioui, Amira/0000-0003-2041-1301
CR Ahuja S, 2021, APPL INTELL, V51, P571, DOI 10.1007/s10489-020-01826-w
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Canayaz M, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102257
   Chen NS, 2020, LANCET, V395, P507, DOI 10.1016/S0140-6736(20)30211-7
   Chouat I, 2022, 6 INT C ADV TECHNOLO, P1, DOI [10.1109/ATSIP55956.2022.9805892, DOI 10.1109/ATSIP55956.2022.9805892]
   Chouat I, 2022, BIOGERONTOLOGY, V23, P65, DOI 10.1007/s10522-021-09946-7
   Echtioui A, 2020, SLAS TECHNOL, V25, P566, DOI 10.1177/2472630320962002
   Farooq M., 2020, arXiv, DOI DOI 10.48550/ARXIV.2003.14395
   Ghaderzadeh M, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/6677314
   Gupta A, 2021, APPL SOFT COMPUT, V99, DOI 10.1016/j.asoc.2020.106859
   Jangam E, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104608
   Jangam E, 2022, APPL INTELL, V52, P2243, DOI 10.1007/s10489-021-02393-4
   Khan AI, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105581
   Li Q, 2020, NEW ENGL J MED, V382, P1199, DOI 10.1056/NEJMoa2001316
   Loey M, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12040651
   Mahmud T, 2020, COMPUT BIOL MED, V122, DOI 10.1016/j.compbiomed.2020.103869
   Ng MY, 2020, RADIOL-CARDIOTHORAC, V2, DOI 10.1148/ryct.2020200034
   Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792
   Rothan HA, 2020, J AUTOIMMUN, V109, DOI 10.1016/j.jaut.2020.102433
   Rubin GD, 2020, RADIOLOGY, V296, P172, DOI [10.1016/j.chest.2020.04.003, 10.1148/radiol.2020201365]
   Shan F, 2020, Arxiv, DOI arXiv:2003.04655
   Wang Linda, 2020, Sci Rep, V10, P19549, DOI 10.1038/s41598-020-76550-z
   Zhao S, 2020, INT J INFECT DIS, V92, P214, DOI 10.1016/j.ijid.2020.01.050
   Zouch W, 2022, ANN BIOMED ENG, V50, P825, DOI 10.1007/s10439-022-02958-5
NR 24
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33731
EP 33751
DI 10.1007/s11042-023-17023-z
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001075272400001
DA 2024-07-18
ER

PT J
AU Talaat, FM
AF Talaat, Fatma M.
TI Explainable Enhanced Recurrent Neural Network for lie detection using
   voice stress analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lie detection; Voice stress analysis; Deep recurrent neural network;
   Affective computing
AB Lie detection is a crucial aspect of human interactions that affects everyone in their daily lives. Individuals often rely on various cues, such as verbal and nonverbal communication, particularly facial expressions, to determine if someone is truthful. While automated lie detection systems can assist in identifying these cues, current approaches are limited due to a lack of suitable datasets for testing their performance in real-world scenarios. Despite ongoing research efforts to develop effective and reliable lie detection methods, this remains a work in progress. The polygraph, voice stress analysis, and pupil dilation analysis are some of the methods currently used for this task. In this study, we propose a new detection algorithm based on an Enhanced Recurrent Neural Network (ERNN) with Explainable AI capabilities. The ERNN, based on long short-term memory (LSTM) architecture, was optimized using fuzzy logic to determine the hyperparameters. The LSTM model was then created and trained using a dataset of audio recordings from interviews with a randomly selected group. The proposed ERNN achieved an accuracy of 97.3%, which is statistically significant for the problem of voice stress analysis. These results suggest that it is possible to detect patterns in the voices of individuals experiencing stress in an explainable manner.
C1 [Talaat, Fatma M.] Kafrelsheikh Univ, Fac Artificial Intelligence, Kafrelsheikh 33516, Egypt.
   [Talaat, Fatma M.] New Mansoura Univ, Fac Comp Sci & Engn, Gamasa 35712, Egypt.
C3 Egyptian Knowledge Bank (EKB); Kafrelsheikh University; New Mansoura
   University
RP Talaat, FM (corresponding author), Kafrelsheikh Univ, Fac Artificial Intelligence, Kafrelsheikh 33516, Egypt.; Talaat, FM (corresponding author), New Mansoura Univ, Fac Comp Sci & Engn, Gamasa 35712, Egypt.
EM fatma.nada@ai.kfs.edu.eg
RI M. Talaat, Fatma/IYS-7614-2023
OI M. Talaat, Fatma/0000-0001-6116-2191
FU Kafr El Shiekh University
FX No Statement Available
CR Almatarneh NA., 2022, Pattern Recogn Lett, V153, P19, DOI [10.1016/j.patrec.2021.07.030, DOI 10.1016/J.PATREC.2021.07.030]
   Alshathri S, 2022, CMC-COMPUT MATER CON, V73, P5863, DOI 10.32604/cmc.2022.026547
   [Anonymous], 1966, Methods of research in psychotherapy, DOI [DOI 10.1007/978-1-4684-6045-2_14, 10.1007/978-1-4684-6045-2_14]
   [Anonymous], 2009, The philosophy of deception, DOI DOI 10.1093/ACPROF:OSO/9780195327939.003.0008
   Baierle IC., 2020, Journal of Open Innovation: Technology, Market, and Complexity, V6, P179, DOI DOI 10.3390/JOITMC6040179
   Ben-Shakhar G, 2003, J APPL PSYCHOL, V88, P131, DOI 10.1037/0021-9010.88.1.131
   Lipton ZC, 2017, Arxiv, DOI [arXiv:1606.03490, 10.48550/arXiv.1606.03490]
   Council NR., 2003, The Polygraph and Lie Detection
   Damphousse K, 2009, NIJ J, V259
   Dcosta Malcolm, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163080
   Dede G, 2010, DIGIT SIGNAL PROCESS, V20, P763, DOI 10.1016/j.dsp.2009.10.004
   Ding MY, 2019, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2019.00799
   El-Rashidy N, 2023, NEURAL COMPUT APPL, V35, P7423, DOI 10.1007/s00521-022-08007-5
   El-Rashidy N, 2022, SOFT COMPUT, V26, P11435, DOI 10.1007/s00500-022-07420-1
   Frank M., 2008, HDB SCI TECHNOLOGY F, V5, P1, DOI DOI 10.1016/J.CHB.2014.02.027
   Gamel SA, 2024, MULTIMED TOOLS APPL, V83, P7295, DOI 10.1007/s11042-023-15803-1
   Goyal A., 2023, Int J Speech Technol, V26, P67, DOI [10.1007/s10772-022-09802-5, DOI 10.1007/S10772-022-09802-5]
   Han J., 2022, Expert Syst Appl, V187, P115141, DOI [10.1016/j.eswa.2021.115141, DOI 10.1016/J.ESWA.2021.115141]
   Hanaa S., 2022, Bioengineering, V10, P18, DOI [10.3390/bioengineering10010018, DOI 10.3390/BIOENGINEERING10010018]
   Hassan E, 2022, Review: Mask R-CNN Models, DOI [10.21608/njccs.2022.280047, DOI 10.21608/NJCCS.2022.280047]
   Winata GI, 2018, Arxiv, DOI arXiv:1805.12307
   kaggle, Truth Detection/Deception Detection/Lie Detection
   Kang D., 2023, J Ambient Intell Humaniz Comput, V14, P3315, DOI [10.1007/s12652-022-04342-8, DOI 10.1007/S12652-022-04342-8]
   Krishnamurthy Gangeshwar., 2018, A deep learning approach for multimodal deception detection
   Kulasinghe Y, 2019, preprint)
   Liu XF, 2004, Voice stress analysis: Detecion of deception
   Mohamed FB, 2006, RADIOLOGY, V238, P679, DOI 10.1148/radiol.2382050237
   Nurçin FV, 2017, PROCEDIA COMPUT SCI, V120, P417, DOI 10.1016/j.procs.2017.11.258
   Office of Technology Assessment's, 1983, Technical report
   Palena N, 2019, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02775
   Pérez-Rosas V, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3118
   Porter S, 2010, LEGAL CRIMINOL PSYCH, V15, P57, DOI 10.1348/135532509X433151
   Rothkrantz LJ, 2004, INT C TEXT SPEECH DI
   Sharma R., 2023, J Ambient Intell Humaniz Comput, V14, P197, DOI [10.1007/s12652-022-04358-0, DOI 10.1007/S12652-022-04358-0]
   Siam AI, 2023, NEURAL COMPUT APPL, V35, P12891, DOI 10.1007/s00521-023-08428-w
   Sun C., 2023, Information Fusion, V85, P117, DOI [10.1016/j.inffus.2022.04.011, DOI 10.1016/J.INFFUS.2022.04.011]
   Talaat FM, 2023, NEURAL COMPUT APPL, V35, P18059, DOI 10.1007/s00521-023-08678-8
   Talaat FM, 2023, NEURAL COMPUT APPL, V35, P17281, DOI 10.1007/s00521-023-08619-5
   Talaat FM, 2022, MULTIMED TOOLS APPL, V81, P39945, DOI 10.1007/s11042-022-13000-0
   Talaat FM, 2022, MULTIMED TOOLS APPL, V81, P8235, DOI 10.1007/s11042-022-12223-5
   Talaat FM, 2023, NEURAL COMPUT APPL, V35, P12717, DOI 10.1007/s00521-023-08372-9
   Taye MM, 2023, COMPUTERS, V12, DOI 10.3390/computers12050091
   Tsiamyrtzis P, 2007, INT J COMPUT VISION, V71, P197, DOI 10.1007/s11263-006-6106-y
   Ribeiro MT, 2016, Arxiv, DOI [arXiv:1602.04938, 10.48550/ARXIV.1602.04938, DOI 10.48550/ARXIV.1602.04938]
   Vrij A., 2008, Detecting lies and deceit: Pitfalls and opportunities, V2nd ed.
   Wu Z, 2018, AAAI CONF ARTIF INTE, P1695
   Yang L., 2023, Pattern Anal Appl, V26, P247, DOI [10.1007/s10044-021-00977-9, DOI 10.1007/S10044-021-00977-9]
NR 47
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32277
EP 32299
DI 10.1007/s11042-023-16769-w
EA SEP 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001070386400004
OA hybrid
DA 2024-07-18
ER

PT J
AU Miguel, GFD
   de Sá, AAR
   Tannús, J
   Naves, ELM
AF de Souza Miguel, Guilherme Fernandes
   de Sa, Angela Abreu Rosa
   Tannus, Julia
   Naves, Eduardo Lazaro Martins
TI Proposal of a game streaming based framework for a telerehabilitation
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Exergames; Game Streaming; Serious Games; Remote Rehabilitation;
   Real-time Streaming
ID UPPER-LIMB; REHABILITATION; EXTREMITY
AB Electronic games are being applied in diverse contexts beyond their conventional entertainment purposes. In academic discourse, they are known exergames when utilized to augment physical fitness or medical rehabilitation therapies. Exergames facilitate the advancement of rehabilitation treatments within clinical or hospital environments, as well as within the confines of a patient's domicile. Nonetheless, notwithstanding the advantages of leveraging exergames, they entail certain expenses for patients, encompassing the procurement of gaming devices and the accompanying controllers. An additional drawback lies in the limited oversight afforded to therapists, necessitating either patient visits to clinics or hospitals or therapist home visits to conduct sessions. To address these concerns, this research proposes the implementation of several innovative technologies as viable solutions to the complex issues identified in the existing literature. These cutting-edge technologies encompass the development of an input device utilizing video object tracking, which serves to regulate the execution of the exergames. The exergames themselves are executed on a remote game server, and their rendered frames are streamed to patients over the Internet through the implementation of a game streaming application. Moreover, to facilitate seamless interaction between patients and therapists during telerehabilitation sessions, a real-time audio and video communication channel is seamlessly integrated into this framework, enabling them to engage with each other regardless of their physical proximity.
C1 [de Souza Miguel, Guilherme Fernandes; de Sa, Angela Abreu Rosa; Tannus, Julia; Naves, Eduardo Lazaro Martins] Univ Fed Uberlandia, Fac Elect Engn, Postgrad Program Biomed Engn, Assist Technol Grp, Av Joao Naves de Avila 2160, Bloco 1A, Uberlandia, Brazil.
C3 Universidade Federal de Uberlandia
RP de Sá, AAR (corresponding author), Univ Fed Uberlandia, Fac Elect Engn, Postgrad Program Biomed Engn, Assist Technol Grp, Av Joao Naves de Avila 2160, Bloco 1A, Uberlandia, Brazil.
RI Naves, Eduardo Lazaro Martins/B-5695-2013
OI Naves, Eduardo Lazaro Martins/0000-0003-4175-723X; Abreu Rosa de Sa,
   Angela/0000-0002-1818-8270; Miguel, Guilherme Fernandes de
   Souza/0000-0002-7425-1975
FU Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior - Brasil
   (CAPES) [001]
FX This study was financed in part by the Coordenacao de Aperfeicoamento de
   Pessoal de Nivel Superior - Brasil (CAPES). Finance Code 001.
CR Afyouni I, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20247037
   Nguyen AV, 2019, DISABIL REHABIL-ASSI, V14, P317, DOI 10.1080/17483107.2018.1447608
   Amorim P, 2020, INT J TELEREHABILITA, V12, P65, DOI 10.5195/ijt.2020.6326
   Bamidis PD, 2015, IGI GLOBAL, DOI [10.4018/978-1-4666-8234-4.ch017, DOI 10.4018/978-1-4666-8234-4.CH017]
   Burgos PI, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10110773
   Dodakian L, 2017, NEUROREHAB NEURAL RE, V31, P923, DOI 10.1177/1545968317733818
   Furber S, 2016, J NEURAL ENG, V13, DOI 10.1088/1741-2560/13/5/051001
   Gauthier LV, 2017, BMC NEUROL, V17, DOI 10.1186/s12883-017-0888-0
   Guilherme Fernandes, 2013, BIOS BIOR C BRC 2013, DOI [10.1109/BRC.2013.6487455, DOI 10.1109/BRC.2013.6487455]
   Hoda M, 2020, HAPTICS REHABILITATI, DOI [10.1007/978-3-030-34230-2_5, DOI 10.1007/978-3-030-34230-2_5]
   Hosseiniravandi M, 2020, INT J TECHNOL ASSESS, V36, P113, DOI 10.1017/S0266462320000021
   James CD, 2017, BIOL INSPIR COGN ARC, V19, P49, DOI 10.1016/j.bica.2016.11.002
   Karime A, 2012, IEEE T INSTRUM MEAS, V61, P1816, DOI 10.1109/TIM.2012.2192338
   Li HJ, 2017, J COMPUT SCI TECH-CH, V32, P258, DOI 10.1007/s11390-017-1720-4
   Ibáñez ML, 2022, INT J INTERACT MULTI, V7, P53, DOI 10.9781/ijimai.2021.04.008
   Lu Tan, 2010, 2010 3rd International Conference on Advanced Computer Theory and Engineering (ICACTE 2010), P376, DOI 10.1109/ICACTE.2010.5579543
   Mantovani E, 2020, FRONT NEUROL, V11, DOI 10.3389/fneur.2020.00926
   Matamala-Gomez M, 2020, FRONT NEUROL, V11, DOI 10.3389/fneur.2020.00354
   Oliver M, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113671
   Paraskevopoulos IT, 2016, INT CONF GAMES VIRTU
   Pareto L, 2011, STUD HEALTH TECHNOL, V169, P676, DOI 10.3233/978-1-60750-806-9-676
   Parsec, 2023, ABOUT US
   Parvez I, 2018, IEEE COMMUN SURV TUT, V20, P3098, DOI 10.1109/COMST.2018.2841349
   Peer JS, 2023, ABOUT US
   Pérez-Medina JL, 2019, IEEE ACCESS, V7, P97159, DOI 10.1109/ACCESS.2019.2927461
   Piron L, 2002, STUD HEALTH TECHNOL, V85, P355
   Popescu VG, 2000, IEEE T INF TECHNOL B, V4, P45, DOI 10.1109/4233.826858
   Postolache O, 2021, IEEE J SEL AREA COMM, V39, P562, DOI 10.1109/JSAC.2020.3020600
   Reinkensmeyer DJ, 2002, IEEE T NEUR SYS REH, V10, P102, DOI 10.1109/TNSRE.2002.1031978
   Schuman C.D., 2017, ARXIV170506963, VarXiv, DOI [10.48550/arXiv.1705.06963, DOI 10.48550/ARXIV.1705.06963]
   da Silva TD, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.622678
   Tlili A, 2021, INT J INTERACT MULTI, V7, P250, DOI 10.9781/ijimai.2021.03.003
   Triandafilou KM, 2018, J NEUROENG REHABIL, V15, DOI 10.1186/s12984-018-0429-0
   Varela-Aldás J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20226552
   Vourvopoulos Athanasios, 2013, 2013 IEEE 15th International Conference on e-Health Networking, Applications and Services (Healthcom 2013), P454, DOI 10.1109/HealthCom.2013.6720719
   WebRTC, 2022, ABOUT US
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850932
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850945
   Yang SM, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040455
   Yang SM, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.601109
   Zedda A, 2020, IEEE ENG MED BIO, P5773, DOI 10.1109/EMBC44109.2020.9175742
   Zhang LR, 2002, COMPUT COMMUN, V25, P863, DOI 10.1016/S0140-3664(01)00418-2
NR 42
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33333
EP 33350
DI 10.1007/s11042-023-16741-8
EA SEP 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001066958500010
DA 2024-07-18
ER

PT J
AU Sharma, S
   Varma, T
AF Sharma, Shobha
   Varma, Tarun
TI Discrete combined fractional Fourier transform and its application to
   image enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fourier transform; Fractional Fourier transform; Linear canonical
   transform; Root filtering; Image enhancement
ID ROBUST WATERMARKING; ALGORITHMS; SCHEME
AB Many generalizations of the Fourier transform (FT) have been introduced in the literature, including fractional Fourier transform (FrFT) and linear canonical transform (LCT). This paper aims to extend the discrete combined Fourier transform (DCFT) to the FrFT domains and investigate its applications in image enhancement. The DCFT of a signal is a linear combination of the forward and inverse DFTs of the signal. The discrete combined fractional Fourier transform (DCFrFT) introduced in this work can be seen as a generalization of the of DCFT to the FrFT domains. Simulation results of the proposed DCFrFT and the original signal recovery are given to validate the proposed approach. To present an example of application of the proposed combined transform, we propose a methodology for image enhancement in which the root filtering (RF) technique is extended to the DCFrFT domains. Here the proper selection of the angle parameter of the proposed DCFrFT and the RF parameter are crucial in the enhancement process. For this purpose, simulation results for different values of the RF parameter are carried out and its appropriate value is chosen based on the subjective evaluation. It is seen here that the enhancement approach in the proposed transform domain can improve degraded images when an appropriate RF parameter is used.
C1 [Sharma, Shobha] Ajay Kumar Garg Engn Coll AKGEC, Ghaziabad, Uttar Pradesh, India.
   [Varma, Tarun] MNIT, Jaipur, India.
C3 National Institute of Technology (NIT System); Malaviya National
   Institute of Technology Jaipur
RP Sharma, S (corresponding author), Ajay Kumar Garg Engn Coll AKGEC, Ghaziabad, Uttar Pradesh, India.
EM sharma.shobha90@gmail.com; tvarma.ece@mnit.ac.in
CR Abdelhakim AM, 2018, MULTIMED TOOLS APPL, V77, P27895, DOI 10.1007/s11042-018-6014-5
   Agaian SS, 2007, IEEE T IMAGE PROCESS, V16, P741, DOI 10.1109/TIP.2006.888338
   Ali M, 2018, MULTIMED TOOLS APPL, V77, P11751, DOI 10.1007/s11042-017-4815-6
   ANSARI R, 1985, IEEE T CIRCUITS SYST, V32, P618, DOI 10.1109/TCS.1985.1085750
   Chandrasekharan R, 2018, IEEE SIGNAL PROC LET, V25, P813, DOI 10.1109/LSP.2018.2812861
   Chen BJ, 2018, IET IMAGE PROCESS, V12, P2238, DOI 10.1049/iet-ipr.2018.5440
   Florea L, 2016, IEEE COMPUT SOC CONF, P936, DOI 10.1109/CVPRW.2016.121
   Gong LH, 2018, OPT LASER TECHNOL, V103, P48, DOI 10.1016/j.optlastec.2018.01.007
   Hussain K, 2018, IPSJ T COMPUT VIS AP
   Kumar R., 2019, SN Appl. Sci, V1, P1, DOI [DOI 10.1007/S42452-019-0913-6, 10.1007/s42452-019-0379-6, DOI 10.1007/S42452-019-0379-6]
   Kumar S, 2017, CIRC SYST SIGNAL PR, V36, P1493, DOI 10.1007/s00034-016-0364-x
   Lang J, 2009, 26 INT POP C PAR IUS, P1
   Lim J, 2017, J VIS COMMUN IMAGE R, V45, P107, DOI 10.1016/j.jvcir.2017.02.016
   Ling ZG, 2015, IET IMAGE PROCESS, V9, P1012, DOI 10.1049/iet-ipr.2014.0580
   Loh YP, 2019, COMPUT VIS IMAGE UND, V178, P30, DOI 10.1016/j.cviu.2018.10.010
   NAMIAS V, 1980, J I MATH APPL, V25, P241
   Ozaktas H.M., 2001, FRACTIONAL FOURIER T
   Parihar AS, 2017, IEEE T IMAGE PROCESS, V26, P1810, DOI 10.1109/TIP.2017.2665975
   Pei SC, 1998, SIGNAL PROCESS, V67, P99, DOI 10.1016/S0165-1684(98)00024-3
   Petrol AB, 2014, IMAGE PROCESS ON LIN, V4, P71, DOI 10.5201/ipol.2014.107
   Saxena N, 2018, IET IMAGE PROCESS, V12, P1013, DOI 10.1049/iet-ipr.2017.0961
   Sharma S, 2022, ENG SCI TECHNOL, V32, DOI 10.1016/j.jestch.2021.09.005
   Stimper V, 2019, IEEE ACCESS, V7, P165437, DOI 10.1109/ACCESS.2019.2952899
   Tao R, 2008, OPT LETT, V33, P581, DOI 10.1364/OL.33.000581
   Wang WC, 2020, IEEE ACCESS, V8, P87884, DOI 10.1109/ACCESS.2020.2992749
   Zhang D, 2018, MULTIMED TOOLS APPL, V77, P2191, DOI 10.1007/s11042-017-4370-1
   Zhao L, 2014, J OPT SOC AM A, V31, P2631, DOI 10.1364/JOSAA.31.002631
   Zhao TY, 2020, DIGIT SIGNAL PROCESS, V104, DOI 10.1016/j.dsp.2020.102807
NR 28
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29881
EP 29896
DI 10.1007/s11042-023-16742-7
EA SEP 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066065600011
DA 2024-07-18
ER

PT J
AU Kaur, P
   Malhi, AK
   Pannu, HS
AF Kaur, Parminder
   Malhi, Avleen Kaur
   Pannu, Husanbir Singh
TI Sentiment analysis of linguistic cues to assist medical image
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-modal system; Medical image classification; Sentiment analysis;
   Collateral text; Machine learning
AB Image classification is a challenging problem and often suffers from the bottleneck of visual features. With the ever-growing availability of multimedia data with the help of the Internet and social platforms, many images are available along with their collateral text. These linguistic keywords can be used as additional "sensors" to enhance efficiency while acting as another mode of information. This article has proposed a framework to perform the sentiment analysis on the rich textual information available from the linguistic cues of related images and incorporate them to enhance image classification. The case study has been performed on the binary classification of in-vivo gastral images and related text obtained from a known gastroenterologist. After the image classification is performed, there is a certain complex family of images that often cannot be further classified. Thus, the classification accuracy is further assisted by performing the sentiment analysis using Long Short Term Memory (LSTM) deep learning network and Bag of Words. Experimental results of the proof-of-concept have been compared with the state-of-the-art techniques to demonstrate the performance improvement of the multi-modal system.
C1 [Kaur, Parminder; Pannu, Husanbir Singh] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, India.
   [Malhi, Avleen Kaur] Bournemouth Univ, Dept Comp & Informat, Bournemouth, England.
C3 Thapar Institute of Engineering & Technology; Bournemouth University
RP Kaur, P (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, India.
EM pkaur60_phd18@thapar.edu; amalhi@bournemouth.ac.uk; hspannu@thapar.edu
RI Kaur, Parminder/IZD-9508-2023
OI Kaur, Parminder/0000-0002-1306-3137
FU Authors are thankful to (a) Dr. Sunil Arya, Gastroenterologist at Leela
   Bhawan Patiala, and Dr. G.S. Sidhu at Max Hospital Mohali, India, for
   the dataset and technical feedback; and (b) Professor Khurshid Ahmad,
   Trinity College Dublin Ireland, for research
FX Authors are thankful to (a) Dr. Sunil Arya, Gastroenterologist at Leela
   Bhawan Patiala, and Dr. G.S. Sidhu at Max Hospital Mohali, India, for
   the dataset and technical feedback; and (b) Professor Khurshid Ahmad,
   Trinity College Dublin Ireland, for research direction.
CR Bilal M, 2016, J KING SAUD UNIV-COM, V28, P330, DOI 10.1016/j.jksuci.2015.11.003
   BOAL CARVALHO Pedro, 2017, Arq. Gastroenterol., V54, P16, DOI [10.1590/s0004-2803.2017v54n1-03, 10.1590/S0004-2803.2017v54n1-03]
   Calhoun Vince D, 2016, Biol Psychiatry Cogn Neurosci Neuroimaging, V1, P230
   Chen DP, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P3291, DOI 10.1145/3503161.3548195
   Chen MK, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22051899
   Chen Qufei, 2021, SN Comput Sci, V2, P414, DOI 10.1007/s42979-021-00807-1
   Chen Y., 2015, Convolutional neural network for sentence classificationD
   Devi MD, 2023, MULTIMED TOOLS APPL, V82, P9047, DOI 10.1007/s11042-022-13042-4
   Frermann Lea, 2018, Transactions of the Association for Computational Linguistics, V6, P1, DOI DOI 10.1162/TACLA00001
   Gorr H, 2020, THE MATHWORKS
   Goyal P, 2020, ARXIV
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Guo L, 2017, NEUROCOMPUTING, V240, P98, DOI 10.1016/j.neucom.2017.02.045
   Jain PK, 2021, COMPUT SCI REV, V41, DOI 10.1016/j.cosrev.2021.100413
   JING M, 2016, 2016 27 IR SIGN SYST, P1
   JiweiWei Yang Yang, 2021, IEEE Transactions on Pattern Analysis and Machine Intelligence
   Johnson R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P562, DOI 10.18653/v1/P17-1052
   Kaliyar RK, 2021, MULTIMED TOOLS APPL, V80, P11765, DOI 10.1007/s11042-020-10183-2
   Khare Y, 2021, I S BIOMED IMAGING, P1033, DOI 10.1109/ISBI48211.2021.9434063
   Kong WC, 2019, IEEE T SMART GRID, V10, P841, DOI 10.1109/TSG.2017.2753802
   Kumari A, 2018, COMPUT ELECTR ENG, V72, P1, DOI 10.1016/j.compeleceng.2018.08.015
   Lai SW, 2015, AAAI CONF ARTIF INTE, P2267
   Manaka T, 2022, COMM COM INF SC, V1734, P46, DOI 10.1007/978-3-031-22321-1_4
   Manaswi NK, 2018, TENSORFLOW KERAS, P115
   Marin J, 2021, IEEE T PATTERN ANAL, V43, P187, DOI 10.1109/TPAMI.2019.2927476
   Moon JH, 2022, IEEE J BIOMED HEALTH, V26, P6070, DOI 10.1109/JBHI.2022.3207502
   Neogi AS, 2021, INT J INF MANAG DATA, V1
   Ölçer D, 2022, ONLINE INFORM REV, V46, P715, DOI 10.1108/OIR-02-2021-0089
   Pandey B, 2022, J KING SAUD UNIV-COM, V34, P5083, DOI 10.1016/j.jksuci.2021.01.007
   Patel R, 2020, IOT-BASEL, V1, DOI 10.3390/iot1020014
   Perone C.S., 2019, J MED ARTIF INTELL, V2, DOI [DOI 10.21037/JMAI.2019.01.01, 10.21037/jmai.2019.01.01]
   Pitcher BJ, 2017, ROY SOC OPEN SCI, V4, DOI 10.1098/rsos.160346
   Shen L, 2020, FRONT COMPUT SCI-CHI, V14, DOI 10.1007/s11704-019-8229-7
   Shih HC, 2018, IEEE T CIRC SYST VID, V28, P1212, DOI 10.1109/TCSVT.2017.2655624
   Singh V, 2021, NUTR NEUROSCI, V24, P35, DOI 10.1080/1028415X.2019.1587247
   Staudemeyer R.C., 2019, arXiv
   Tripathi Pravin, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P1818, DOI 10.1109/ICECA.2018.8474611
   Vaswani A, 2017, ADV NEUR IN, V30
   Yang XC, 2021, IEEE T MULTIMEDIA, V23, P4014, DOI 10.1109/TMM.2020.3035277
   Zha WS, 2022, ENERGY, V260, DOI 10.1016/j.energy.2022.124889
   Zhang SY, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4373, DOI 10.1145/3394171.3413518
   Zhao Z, 2017, IET INTELL TRANSP SY, V11, P68, DOI 10.1049/iet-its.2016.0208
   Zhu L, 2022, NEURAL PROCESS LETT, V54, P2549, DOI 10.1007/s11063-021-10447-4
NR 43
TC 0
Z9 0
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30847
EP 30866
DI 10.1007/s11042-023-16538-9
EA SEP 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001081631900007
DA 2024-07-18
ER

PT J
AU Sriram, DS
   Ranjan, A
   Ghuge, V
   Rathore, N
   Agarwal, R
   Diwan, T
   Tembhurne, JV
AF Sriram, Dharwada Sesha
   Ranjan, Aseem
   Ghuge, Vedant
   Rathore, Naveen
   Agarwal, Raghav
   Diwan, Tausif
   Tembhurne, Jitendra V.
TI Personalized federated learning for the detection of COVID-19
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; Chest X-ray; Federated learning; Personalized federated
   learning; Meta learning
AB Federated learning (FL) plays a crucial role in COVID-19 detection by enabling collaborative analysis of medical data while preserving privacy. In this context, medical data is typically dispersed across various medical institutions. FL allows these institutions to collectively train a deep learning model without the need to centralize or transfer the data. But Federated Averaging (FedAvg), the default setting of FL, does not consider personalizing the deep learning model to each institution and cannot ensure model performance when data heterogeneity heavily exists among institutions. In this paper, we investigate Personalized Federated Averaging (PerFedAvg), a personalized variant of the FL framework that aims to train a model that can be tailored to each institution after a few iterations of local gradient descent on the data of that institution while safeguarding the privacy of that institution's patients. We used data from a publicly available Kaggle dataset that contained chest X-ray images of COVID-19, pneumonia, and normal patients, and created two federated settings that would reflect the heterogeneity of data in terms of distribution, and quantity across medical institutions in the real world. We experimentally demonstrate that PerFedAvg outperforms the standard FedAvg technique in such settings with an increase in accuracy by 3.11%-9.30%. With the help of this research, nations and institutions might quickly construct effective artificial intelligence during pandemics, easing the load of centralized aggregation of copious volumes of sensitive data.
C1 [Sriram, Dharwada Sesha; Ranjan, Aseem; Ghuge, Vedant; Rathore, Naveen; Agarwal, Raghav; Diwan, Tausif; Tembhurne, Jitendra V.] Indian Inst Informat Technol, Dept Comp Sci & Engn, Nagpur, India.
RP Diwan, T (corresponding author), Indian Inst Informat Technol, Dept Comp Sci & Engn, Nagpur, India.
EM bt19cse058@iiitn.ac.in; bt19cse085@iiitn.ac.in; bt19cse004@iiitn.ac.in;
   bt19cse117@iiitn.ac.in; bt19cse044@iiitn.ac.in; tdiwan@iiitn.ac.in;
   jtembhurne@iiitn.ac.in
RI Diwan, Tausif/AFN-9746-2022; Tembhurne, Jitendra/AGI-1097-2022
OI Tembhurne, Jitendra/0000-0002-1389-3456
CR [Anonymous], 2022, The true death toll of COVID-19: Estimating global excess mortality
   Charney AW, 2020, NAT MED, V26, P1157, DOI 10.1038/s41591-020-1004-3
   Chen F, 2018, ARXIV
   Chung M, 2020, RADIOLOGY, V295, P202, DOI 10.1148/radiol.2020200230
   Clerkin KJ, 2020, CIRCULATION, V141, P1648, DOI 10.1161/CIRCULATIONAHA.120.046941
   Nguyen DC, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3501296
   Dinh C. T, 2020, Advances in Neural Information Processing Systems, V33, p21 394
   Fallah A., 2020, Advances in Neural Information Processing Systems, V33, P3557
   Feki I, 2021, APPL SOFT COMPUT, V106, DOI 10.1016/j.asoc.2021.107330
   Finn C, 2017, PR MACH LEARN RES, V70
   github, Agchung-overview
   ieee, ieee8023
   Li T., 2020, PROC MACH LEARN SYST, V2, P429, DOI DOI 10.48550/ARXIV.1812.06127
   Li T., 2020, 8 INT C LEARNING REP
   McMahan HB, 2017, PR MACH LEARN RES, V54, P1273
   McMahan HB, 2017, IntConf Learn Rep
   Mei XY, 2020, NAT MED, V26, P1224, DOI [10.1038/s41591-020-0931-3, 10.1101/2020.04.12.20062661]
   Mooney P., 2018, Kaggle
   Patel P., 2020, Chest X-ray (covid-19 & pneumonia)
   Roccetti M, 2023, MATH BIOSCI ENG, V20, P7042, DOI 10.3934/mbe.2023304
   Sigel K, 2020, CLIN INFECT DIS, V71, P2933, DOI 10.1093/cid/ciaa880
   Watson OJ, 2022, LANCET INFECT DIS, V22, P1293, DOI 10.1016/S1473-3099(22)00320-6
   worldometer, Coronavirus death toll
   Wu ZY, 2020, JAMA-J AM MED ASSOC, V323, P1239, DOI 10.1001/jama.2020.2648
   Xu Z, 2020, LANCET RESP MED, V8, P420, DOI 10.1016/S2213-2600(20)30076-X
   Yan B., 2020, arXiv
   Yuki K, 2020, CLIN IMMUNOL, V215, DOI 10.1016/j.clim.2020.108427
   Zhang LL, 2021, INFORM SYST FRONT, V23, P1403, DOI 10.1007/s10796-021-10144-6
   Zhang W, 2021, IEEE Intern Things J
NR 29
TC 0
Z9 0
U1 7
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29067
EP 29084
DI 10.1007/s11042-023-16810-y
EA SEP 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001063374600006
DA 2024-07-18
ER

PT J
AU Niu, AX
   Wang, P
   Zhu, Y
   Sun, JQ
   Yan, QS
   Zhang, YN
AF Niu, Axi
   Wang, Pei
   Zhu, Yu
   Sun, Jinqiu
   Yan, Qingsen
   Zhang, Yanning
TI GRAN: ghost residual attention network for single image super resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single image super-resolution; Ghost residual attention block; Channel
   and spatial attention module; Ghost technology
AB Recently, many works have designed wider and deeper networks to achieve higher image super-resolution performance. Despite their outstanding performance, they still suffer from high computational resources, preventing them from directly applying to embedded devices. To reduce the computation resources and maintain performance, we propose a novel Ghost Residual Attention Network (GRAN) for efficient super-resolution. This paper introduces Ghost Residual Attention Block (GRAB) groups to overcome the drawbacks of the standard convolutional operation, i.e., redundancy of the intermediate feature. GRAB consists of the Ghost Module and Channel and Spatial Attention Module (CSAM) to alleviate the generation of redundant features. Specifically, Ghost Module can reveal information underlying intrinsic features by employing linear operations to replace the standard convolutions. Reducing redundant features by the Ghost Module, our model decreases memory and computing resource requirements in the network. The CSAM pays more comprehensive attention to where and what the feature extraction is, which is critical to recovering the image details. Experiments conducted on the benchmark datasets demonstrate the superior performance of our method in both qualitative and quantitative. Compared to the baseline models, we achieve higher performance with lower computational resources, whose parameters and FLOPs have decreased by more than ten times.
C1 [Niu, Axi; Wang, Pei; Zhu, Yu; Yan, Qingsen; Zhang, Yanning] Northwestern Polytech Univ, Sch Comp Sci, Xian 710129, Peoples R China.
   [Sun, Jinqiu] Northwestern Polytech Univ, Sch Astronaut, Xian 710072, Peoples R China.
C3 Northwestern Polytechnical University; Northwestern Polytechnical
   University
RP Sun, JQ (corresponding author), Northwestern Polytech Univ, Sch Astronaut, Xian 710072, Peoples R China.
EM nax@mail.nwpu.edu.cn; wangpei23@mail.nwpu.edu.cn; yuzhu@nwpu.edu.cn;
   sunjinqiu@nwpu.edu.cn; yqs@mail.nwpu.edu.cn; ynzhang@nwpu.edu.cn
RI wang, haoyu/KHY-6295-2024; Zhang, Yansong/KHW-4097-2024; Wang,
   Xinyi/KHV-4909-2024; wang, nan/KHW-4897-2024; Guo, Li/KCK-9540-2024;
   WANG, YUHAO/KBB-0213-2024; wang, wang/KGW-2828-2024; zhang,
   yingying/KGM-8162-2024; li, fangyu/KCY-0521-2024; Wang,
   Yibin/KEZ-9645-2024; Wang, Fei/KEH-6292-2024; Sun, Yang/KHY-5117-2024;
   Wang, Ling/AGR-4917-2022; li, qing/KHU-6871-2024; wang,
   shuo/KCL-3379-2024; Wang, Ling/KBA-9814-2024; WANG, YANAN/KCL-4840-2024;
   wang, jin/KHD-7243-2024; chen, xiao/KFQ-6812-2024; Lin,
   Wei/KFQ-5381-2024
OI wang, haoyu/0009-0001-2467-5331; zhang, yingying/0000-0001-7479-3398;
   li, fangyu/0009-0009-8303-9157; Wang, Ling/0000-0003-0272-2974; Wang,
   Ling/0000-0003-0272-2974; 
FU Project of the National Natural Science Foundation of Chinaunder
   [61901384, 61871328]; Natural Science Basic Research Program of Shaanxi
   [2021JCW-03]; National Natural Science Foundation of China [U19B2037]
FX This work was funded in part by the Project of the National Natural
   Science Foundation of Chinaunder Grant 61901384 and 61871328, the
   Natural Science Basic Research Program of Shaanxi under Grant
   2021JCW-03, as well as the Joint Funds of the National Natural Science
   Foundation of China under Grant U19B2037
CR Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Ai, 2020, ARXIV
   Barzegar S, 2020, MULTIMED TOOLS APPL, V79, P1119, DOI 10.1007/s11042-019-08218-4
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Cai J, 2019, CVPR
   Cai JR, 2019, IEEE I CONF COMP VIS, P3086, DOI 10.1109/ICCV.2019.00318
   Cao KR, 2020, SCI PROGRAMMING-NETH, V2020, DOI 10.1155/2020/8877851
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Chen Y, 2021, MULTIMED TOOLS APPL
   Chu X., 2020, EUROPEAN C COMPUTER, P465
   Dai Y, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.10.007
   Dean J., 2015, NIPS DEEP LEARNING R
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Fan Y, 2020, ARXIV
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Fukuda T, 2017, INTERSPEECH, P3697, DOI 10.21437/Interspeech.2017-614
   Graf, 2017, ARXIV160808710, P1, DOI DOI 10.48550/ARXIV.1608.08710
   Guo YW, 2018, ADV NEUR IN, V31
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   Han  S., 2015, ARXIV151000149
   Haris M, 2019, ARXIV
   Heo B, 2019, AAAI CONF ARTIF INTE, P3771, DOI 10.1609/aaai.v33i01.33013771
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu S, 2020, MULTIMED TOOLS APPL
   Hu YT, 2020, IEEE T CIRC SYST VID, V30, P3911, DOI 10.1109/TCSVT.2019.2915238
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Jaderberg M, 2015, ARXIV
   Jin MW, 2014, 2014 IEEE NUCLEAR SCIENCE SYMPOSIUM AND MEDICAL IMAGING CONFERENCE (NSS/MIC)
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Li JC, 2018, LECT NOTES COMPUT SC, V11212, P527, DOI 10.1007/978-3-030-01237-3_32
   Li R, 2019, NEUROCOMPUTING
   Li R, 2020, P 28 ACM INT C MULT
   Li X, 2021, MULTIMED TOOLS APPL
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu M, 2020, ARXIV
   Lu X, 2014, IEEE T CYBERN
   Lyn J, 2020, ARXIV
   Ma H., 2019, ARXIV
   Mao Q, 2023, PATTERN RECOGN, V134, DOI 10.1016/j.patcog.2022.109097
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Matsui Y, 2017, MULTIMED TOOLS APPL, V76, P21811, DOI 10.1007/s11042-016-4020-z
   Muqeet A, 2019, ARXIV
   Niu A., 2023, ARXIV
   Niu A, 2022, IEEE T CIRC SYST VID
   Peng HY, 2019, PR MACH LEARN RES, V97
   Peng Y, 2020, MULTIMED TOOLS APPL
   Rajput SS, 2020, MULTIMED TOOLS APPL, V79, P23909, DOI 10.1007/s11042-020-09072-5
   Salvador J, 2015, IEEE I CONF COMP VIS, P325, DOI 10.1109/ICCV.2015.45
   Schulter S, 2015, PROC CVPR IEEE, P3791, DOI 10.1109/CVPR.2015.7299003
   Shamsolmoali P, 2019, MULTIMED TOOL APPL
   Singh A, 2020, MULTIMED TOOLS APPL
   Song Z, 2021, MULTIMED TOOLS APPL
   Tai YW, 2010, PROC CVPR IEEE, P2400, DOI 10.1109/CVPR.2010.5539933
   Timofte R, 2017, IEEE COMPUT SOC CONF, P1110, DOI 10.1109/CVPRW.2017.149
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yang H, 2021, MULTIMED TOOLS APPL
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhao H., 2020, P IEEE CVF C COMP VI, V2020, P10076, DOI 10.1109/CVPR42600.2020.01009
   Zhao W., 2019, arXiv
   Zhu X, 2020, ICCV
NR 64
TC 2
Z9 2
U1 4
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28505
EP 28522
DI 10.1007/s11042-023-15088-4
EA SEP 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001059652000005
DA 2024-07-18
ER

PT J
AU Karanwal, S
AF Karanwal, Shekhar
TI Local tri directional pattern (LTDP): a novel descriptor for face
   recognition in unconstrained conditions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local Binary Pattern (LBP); Local Tri Directional Pattern (LTDP);
   Feature Extraction; Feature compression; Classification
ID BINARY PATTERN; CLASSIFICATION
AB Plentiful of local descriptors has been reported based on Local Binary Pattern (LBP). LBP and most of them establishes a uniform coordination among neighbors and center pixel to develop its code. To be precise the meaning full information located in different directions are missed in the earlier research. In addition the magnitude features are minimal used in earlier research. The invented work develop a novel local descriptor for Face Recognition (FR) called Local Tri Directional Pattern (LTDP) in various unconstrained conditions, by eliminating these problems. LTDP captures direction features from 3 x 3 patch based on first order derivatives generated in clockwise, center and anticlockwise directions, for each neighborhood position of the 3 x 3 patch. The generated first order derivatives are then conceived by novel thresholding function to form the tri directional pattern. The tri directional pattern is further split into three binary patterns, which is further transformed into three LTDP codes by weights assignment and summing values. To increase more discriminativity two magnitude features are also proposed and integrated with the previously extracted features. Eventually all five LTDP codes are merged to develop the size of LTDP for single position. Further all the generated histograms are merged to develop LTDP feature size. Principal Component Analysis (PCA) and Fishers Linear Discriminant Analysis (FLDA) are used for feature compaction and matching is done by Support Vector Machines (SVMs). Results on ORL, GT, EYB and YB illustrates the efficacy of LTDP against the compared methods.
C1 [Karanwal, Shekhar] Graph Era Deemed Univ, Dept CSE, Dehra Dun 248002, Uttarakhand, India.
C3 Graphic Era University
RP Karanwal, S (corresponding author), Graph Era Deemed Univ, Dept CSE, Dehra Dun 248002, Uttarakhand, India.
EM shekhar.karanwal@gmail.com
RI Karanwal, Dr. Shekhar/AGF-1442-2022
OI Karanwal, Dr. Shekhar/0000-0003-2932-4132
CR Ahuja Bhawna, 2021, Proceedings of International Conference on Artificial Intelligence and Applications. ICAIA 2020. Advances in Intelligent Systems and Computing (AISC 1164), P363, DOI 10.1007/978-981-15-4992-2_34
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Chen ZH, 2018, IEEE T IND INFORM, V14, P4334, DOI 10.1109/TII.2018.2789925
   Dornaika F, 2022, INFORM SCIENCES, V584, P467, DOI 10.1016/j.ins.2021.10.041
   El Kissi Ghalleb Asma, 2013, 2013 10th International Multi-Conference on Systems, Signals and Devices (SSD 2013), P1
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Gou JP, 2019, KNOWL-BASED SYST, V167, P38, DOI 10.1016/j.knosys.2019.01.016
   Goyani M.M., 2017, Electronic Letters on Computer Vision and Image Analysis, V16, P54
   Guo D, 2021, INT C COMP VIS IM DE
   Hafiane A, 2007, LECT NOTES COMPUT SC, V4633, P387
   Hassaballah M, 2020, MULTIMED TOOLS APPL, V79, P31183, DOI 10.1007/s11042-020-09456-7
   Hassaballah M, 2019, EXPERT SYST APPL, V118, P182, DOI 10.1016/j.eswa.2018.10.007
   Hazarika BB, 2021, NEURAL COMPUT APPL, V33, P4243, DOI 10.1007/s00521-020-05240-8
   Huu-Tuan Nguyen, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P85, DOI 10.1007/978-3-642-37410-4_8
   Jiang T, 2016, PROC SPIE, V10033, DOI 10.1117/12.2244606
   Karanwal Shekhar, 2022, Machine Learning, Advances in Computing, Renewable Energy and Communication: Proceedings of MARC 2020. Lecture Notes in Electrical Engineering (768), P613, DOI 10.1007/978-981-16-2354-7_54
   Karanwal S, 2022, INT C RECENT ADV ELE
   Karanwal S, 2022, 2022 INT C SMART TEC
   Karanwal S, 2021, INT ARAB C INFORM TE
   Karanwal S, 2021, 2021 IEEE 12TH ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS & MOBILE COMMUNICATION CONFERENCE (UEMCON), P534, DOI 10.1109/UEMCON53757.2021.9666506
   Karanwal S, 2021, MULTIMED TOOLS APPL, V80, P12195, DOI 10.1007/s11042-020-09833-2
   Karanwal S, 2021, PATTERN ANAL APPL, V24, P741, DOI 10.1007/s10044-020-00948-8
   Karanwal S, 2021, OPTIK, V226, DOI 10.1016/j.ijleo.2020.166007
   Kaya Y, 2015, APPL SOFT COMPUT, V34, P728, DOI 10.1016/j.asoc.2015.06.009
   Khanna K, 2022, MULTIMED TOOLS APPL, V81, P20705, DOI 10.1007/s11042-022-12671-z
   Kola DGR, 2021, MULTIMED TOOLS APPL, V80, P2243, DOI 10.1007/s11042-020-09663-2
   Kral P, 2017, ARXIV
   Kravchik M, 2021, IEEE T DEPENDABLE SE
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu J, 2019, MULTIMED TOOLS APPL, V78, P18735, DOI 10.1007/s11042-018-7095-x
   Liu L, 2012, IMAGE VISION COMPUT, V30, P86, DOI 10.1016/j.imavis.2012.01.001
   Lu C, 2011, J SIGNAL PROCESS SYS
   Lu JL, 2021, PATTERN RECOGN, V113, DOI 10.1016/j.patcog.2020.107758
   Lu YJ, 2022, J INTELL SYST, V31, P501, DOI 10.1515/jisys-2022-0011
   Makhmudkhujaev F, 2019, SIGNAL PROCESS-IMAGE, V74, P1, DOI 10.1016/j.image.2019.01.002
   Marcolin F, 2021, NEUROCOMPUTING, V443, P302, DOI 10.1016/j.neucom.2021.02.074
   Marcolin F, 2016, MULTIMED TOOLS APPL
   Ogla R., 2022, INT J ELECTR COMPUT, V12, P2571
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Poonia P, 2022, INT J COMPUT SCI ENG, V25, P116, DOI 10.1504/IJCSE.2022.122204
   Qin YB, 2020, INT J MACH LEARN CYB, V11, P2289, DOI 10.1007/s13042-020-01116-4
   Qu H, 2022, MULTIMED TOOLS APPL
   Regouid M, 2022, MULTIMED TOOLS APPL, V81, P29477, DOI 10.1007/s11042-022-12700-x
   Sghaier S, 2018, INT J AMBIENT COMPUT, V9, P60, DOI 10.4018/IJACI.2018010104
   Shakoor MH, 2018, MULTIMED TOOLS APPL, V77, P21481, DOI 10.1007/s11042-017-5440-0
   Shao CB, 2016, SOFT COMPUT, V20, P3177, DOI 10.1007/s00500-015-1692-7
   Sharma RP, 2021, MULTIMED TOOLS APPL, V80, P9993, DOI 10.1007/s11042-020-10136-9
   Song TC, 2021, IEEE T CIRC SYST VID, V31, P189, DOI 10.1109/TCSVT.2020.2972155
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168
   Tiwari D, 2016, MULTIDIM SYST SIGN P, V27, P563, DOI 10.1007/s11045-015-0319-6
   Vu HN, 2022, APPL INTELL, V52, P5497, DOI 10.1007/s10489-021-02728-1
   W, 2021, PATTERN RECOGNIT, V110
   Wan M, 2017, FUZZY SET SYST
   Wan MH, 2022, IEEE T CIRC SYST VID, V32, P1917, DOI 10.1109/TCSVT.2021.3090420
   Wan MH, 2021, INFORM SCIENCES, V563, P1, DOI 10.1016/j.ins.2021.02.006
   Wang X, 2022, IEEE Trans. Neural Netw. Learn.Syst., P1
   Zeng SN, 2017, EXPERT SYST APPL, V82, P1, DOI 10.1016/j.eswa.2017.04.001
   Zhang Y., 2022, Multimed Tools Appl, P1
   Zhang YJ, 2022, APPL INTELL, V52, P3766, DOI 10.1007/s10489-021-02557-2
   Zhang ZX, 2022, SIGNAL IMAGE VIDEO P, V16, P1091, DOI 10.1007/s11760-021-02058-2
   Zhao SP, 2022, INFORM FUSION, V83-84, P96, DOI 10.1016/j.inffus.2022.03.005
NR 62
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28419
EP 28441
DI 10.1007/s11042-023-16635-9
EA SEP 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001059026300008
DA 2024-07-18
ER

PT J
AU Shi, H
   Yan, KX
   Geng, JN
   Ren, YG
AF Shi, Hui
   Yan, Kexun
   Geng, Jianing
   Ren, Yonggong
TI A cross-embedding based medical image tamper detection and self-recovery
   watermarking scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tamper detection; Self-recovery; Medical image; Reference matrix;
   Cross-embedding
AB With the rapid growth in communication and computing technologies, the transmission of medical images over the Internet is on the rise. In such a scenario, there is a special need to meet the security and privacy issues and challenges of individual and Intellectual Property (IP) owners. It is highly important for an individual to keep his/her personal medical images against invalid manipulation by impostors. Hence developments of authentication and tamper detection techniques are the need of the hour. For this, a tamper detection and self-recovery watermarking scheme for medical images based on texture degree and cross-embedding is proposed in this paper. Firstly, divide medical images into ROI (Region of Interest) and RONI (Region of Non-Interest); generate a double authentication watermark in ROI to improve the accuracy of tamper detection and reduce the probability of false alarm; calculate texture complexity based on 4-dimensional features in ROI, and divide ROI into texture blocks and smooth blocks; generate different recovery watermarks according to the characteristics of different blocks using compression-aware technology. Then, hide the recovery watermark in RONI based on the reference matrix and cross-embedding technology. Finally, locate the tampered blocks in the ROI based on three level tamper detection strategy including pixel-level, block-level, and multi-direction subband-level; restore the tampered region by the extracted recovery watermark. The experimental results indicate that the tamper detection accuracy of the ROI region is close to 100%. Additionally, at an embedding rate of 1.4074bpp, the PSNR reaches 45.0217 dB and the NC is 0.99. In addition, the scheme provides promising results against copy-paste attacks, collage attacks and steganalysis. Also, the scheme achieves privacy protection. This clearly demonstrates that the proposed scheme has several advantages, including strong tamper detection capability, effective self-recovery, high security, excellent concealment, and robustness.
C1 [Shi, Hui; Yan, Kexun; Geng, Jianing; Ren, Yonggong] Liaoning Normal Univ, Sch Comp Sci & Aritificial Intelligence, Dalian 116029, Peoples R China.
C3 Liaoning Normal University
RP Shi, H; Ren, YG (corresponding author), Liaoning Normal Univ, Sch Comp Sci & Aritificial Intelligence, Dalian 116029, Peoples R China.
EM shihui_jiayou@126.com; ryg@lnnu.edu.cn
RI Kexun, Yan/AIF-4542-2022
OI Shi, Hui/0000-0001-5029-7461
FU National Science Foundation of China
FX Supported by National Science Foundation of China (No.61976109,
   62006108, 61601214, 61877007); Liaoning Revitalization Talents Program
   (No.XLYC2006005); Liaoning Provincial Education Department (No.
   WQ2020014); Scientific Research Project of Liaoning
   Province(No.LJKZ0963); Key R&D projects of Liaoning Provincial
   Department of Science and Technology; Liaoning Provincial Key Laboratory
   Special Fund.
CR AlShaikh M, 2023, MULTIMED TOOLS APPL, V82, P10039, DOI 10.1007/s11042-021-11840-w
   Alshanbari HS, 2021, MULTIMED TOOLS APPL, V80, P16549, DOI 10.1007/s11042-020-08814-9
   Ansari IA, 2016, INT J MACH LEARN CYB, V7, P1225, DOI 10.1007/s13042-015-0455-1
   Benrhouma O, 2023, MULTIMED TOOLS APPL, V82, P22149, DOI 10.1007/s11042-022-13350-9
   Bhardwaj R, 2021, EXPERT SYST APPL, V186, DOI 10.1016/j.eswa.2021.115721
   Bhardwaj R, 2021, MULTIMED TOOLS APPL, V80, P31687, DOI 10.1007/s11042-021-10892-2
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Chang CC, 2020, MULTIMED TOOLS APPL, V79, P24795, DOI 10.1007/s11042-020-09132-w
   Chen KM, 2019, J VIS COMMUN IMAGE R, V58, P334, DOI 10.1016/j.jvcir.2018.12.023
   Chen XF, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2020.102702
   Chen YL, 2013, ENTROPY-SWITZ, V15, P3170, DOI 10.3390/e15083260
   Chidambaram N, 2021, MULTIMED TOOLS APPL, V80, P23359, DOI 10.1007/s11042-020-10210-2
   Chin-Chen Chang, 2008, 2008 3rd International Conference on Innovative Computing Information and Control (ICICIC), DOI 10.1109/ICICIC.2008.149
   Chowdhuri P, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102420
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   De S, 2023, MULTIMED TOOLS APPL, V82, P11753, DOI 10.1007/s11042-022-13585-6
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Gao GY, 2021, SIGNAL PROCESS, V178, DOI 10.1016/j.sigpro.2020.107817
   Geetha R, 2020, MULTIMED TOOLS APPL, V79, P12869, DOI 10.1007/s11042-019-08484-2
   Geetha R, 2018, INT C NEXT GENERATIO, V9, P601
   Gull S, 2021, MULTIMED TOOLS APPL, V80, P29939, DOI 10.1007/s11042-021-11170-x
   Iseed SY, 2023, MULTIMED TOOLS APPL, V82, P31181, DOI 10.1007/s11042-023-14824-0
   Jaiswal AK, 2023, MULTIMED TOOLS APPL, V82, P38901, DOI 10.1007/s11042-023-15032-6
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Lin CC, 2015, MULTIMED TOOLS APPL, V74, P3823, DOI 10.1007/s11042-013-1801-5
   Lu W, 2023, IEEE T CIRC SYST VID, V33, P952, DOI 10.1109/TCSVT.2022.3204740
   Mansour RF, 2021, ARAB J SCI ENG, V46, P9129, DOI 10.1007/s13369-021-05716-2
   Otair M, 2022, MULTIMED TOOLS APPL, V81, P28509, DOI 10.1007/s11042-022-12846-8
   Reddy G.T., 2020, Int Conf Emerg Trends Inform Technol Eng Ic-ETITE, P1, DOI 10.1109/ic-etite47903.2020.235
   Sanivarapu PV, 2022, MULTIMED TOOLS APPL, V81, P11605, DOI 10.1007/s11042-022-12273-9
   Sanivarapu PV, 2020, PHYS ENG SCI MED, V43, P213, DOI 10.1007/s13246-019-00838-2
   Shi H, 2017, MULTIMED TOOLS APPL, V76, P6941, DOI 10.1007/s11042-016-3328-z
   Showkat S, 2021, MULTIMED TOOLS APPL, V80, P2009, DOI 10.1007/s11042-020-09732-6
   Singh D, 2023, MULTIMED TOOLS APPL, V82, P1045, DOI 10.1007/s11042-022-13270-8
   Su GD, 2021, MULTIMED TOOLS APPL, V80, P12881, DOI 10.1007/s11042-020-10451-1
   Swaraja K, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101665
   Tan JX, 2022, IEEE T NETW SCI ENG, V9, P888, DOI 10.1109/TNSE.2021.3139671
   Thanki R, 2019, MULTIMED TOOLS APPL, V78, P13905, DOI 10.1007/s11042-018-6746-2
   Wang X, 2021, INFORM SCIENCES, V567, P375, DOI 10.1016/j.ins.2021.02.079
   Yang Y, 2018, MULTIMED TOOLS APPL, V77, P18043, DOI 10.1007/s11042-017-4444-0
   Yu J, 2018, IEEE T INF FOREN SEC, V13, P1317, DOI 10.1109/TIFS.2017.2787986
   Yu M, 2015, AEU-INT J ELECTRON C, V69, P361, DOI 10.1016/j.aeue.2014.10.006
NR 44
TC 0
Z9 0
U1 5
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30319
EP 30360
DI 10.1007/s11042-023-16679-x
EA SEP 2023
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001059026300009
DA 2024-07-18
ER

PT J
AU Tsubokawa, T
   Tajima, H
   Maeda, Y
   Fukushima, N
AF Tsubokawa, Teppei
   Tajima, Hiroshi
   Maeda, Yoshihiro
   Fukushima, Norishige
TI Local look-up table upsampling for accelerating image processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Joint upsample; Local LUT; Acceleration
ID ALGORITHM
AB The resolution of cameras is increasing, and speedup of various image processing is required to accompany this increase. A simple way of acceleration is processing the image at low resolution and then upsampling the result. Moreover, when we can use an additional high-resolution image as guidance formation for upsampling, we can upsample the image processing results more accurately. We propose an approach to accelerate various image processing by downsampling and joint upsampling. This paper utilizes per-pixel look-up tables (LUTs), named local LUT, which are given a low-resolution input image and output pair. Subsequently, we upsample the local LUT. We can then generate a high-resolution image only by referring to its local LUT. In our experimental results, we evaluated the proposed method on several image processing filters and applications: iterative bilateral filtering, l(0) smoothing, local Laplacian filtering, inpainting, and haze removing. The proposed method accelerates image processing with sufficient approximation accuracy, and the proposed outperforms the conventional approaches in the trade-off between accuracy and efficiency. Our code is available at https://fukushimalab.github.io/LLF/.
C1 [Tsubokawa, Teppei] DENSO Corp, Showa-cho 1-1, Kariya, Aichi 4488661, Japan.
   [Tajima, Hiroshi] Canon Inc, Simomaruko 3-30-2, Ohota-ku, Tokyo 1468501, Japan.
   [Maeda, Yoshihiro] Tokyo Univ Sci, Dept Elect Engn, 6-3-1, Niijuku, Katsuhika-ku, Tokyo 1258585, Japan.
   [Tsubokawa, Teppei; Tajima, Hiroshi; Fukushima, Norishige] Nagoya Inst Technol, Dept Engn, Showa-ku, Gokiso-cho, Nagoya, Aichi 4668555, Japan.
C3 DENSO; Canon Incorporated; Tokyo University of Science; Nagoya Institute
   of Technology
RP Fukushima, N (corresponding author), Nagoya Inst Technol, Dept Engn, Showa-ku, Gokiso-cho, Nagoya, Aichi 4668555, Japan.
EM fukushima@nitech.ac.jp
RI Fukushima, Norishige/J-8944-2013; Maeda, Yoshihiro/HOC-5352-2023
OI Fukushima, Norishige/0000-0001-8320-6407; Maeda,
   Yoshihiro/0000-0001-6919-637X
FU JSPS KAKENHI Grant [18K19813, 21K17768, 21H03465]; Environment Research
   and Technology Development Fund of the Environmental Restoration and
   Conservation Agency of Japan [JPMEERF20222M01]
FX This work was supported by JSPS KAKENHI Grant Number (18K19813,
   21K17768, 21H03465) and Environment Research and Technology Development
   Fund (JPMEERF20222M01) of the Environmental Restoration and Conservation
   Agency of Japan. We would like to thank Editage for English language
   editing.
CR Adams A, 2010, COMPUT GRAPH FORUM, V29, P753, DOI 10.1111/j.1467-8659.2009.01645.x
   Aubry M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629645
   Bae SM, 2006, ACM T GRAPHIC, V25, P637, DOI 10.1145/1141911.1141935
   Barron JT, 2015, P COMP VIS PATT REC
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chaudhury KN, 2013, IEEE T IMAGE PROCESS, V22, P1291, DOI 10.1109/TIP.2012.2222903
   Chaudhury KN, 2011, IEEE T IMAGE PROCESS, V20, P3376, DOI 10.1109/TIP.2011.2159234
   Chaudhury KN, 2011, IEEE SIGNAL PROC LET, V18, P651, DOI 10.1109/LSP.2011.2167967
   Chen JW, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982423
   Chen QF, 2017, IEEE I CONF COMP VIS, P2516, DOI 10.1109/ICCV.2017.273
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Fujita S, 2015, P ACM SIGGRAPH AS TE
   Fukushima N, 2016, 3DTV CONF
   Fukushima N, 2019, IEEE IMAGE PROC, P4175, DOI [10.1109/ICIP.2019.8803511, 10.1109/icip.2019.8803511]
   Fukushima N, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1523, DOI 10.1109/ICASSP.2018.8462016
   Fukushima N, 2015, INT CONF ACOUST SPEE, P1588, DOI 10.1109/ICASSP.2015.7178238
   Gastal ESL, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185529
   Gastal ESL, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964964
   Gharbi M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818127
   Ghosh S, 2018, IEEE SIGNAL PROC LET, V25, P1555, DOI 10.1109/LSP.2018.2866949
   He K, 2015, ABS150500996 CORR
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]
   Hennessy J., 2017, Computer Architecture, Sixth Edition: A Quantitative Approach, V6th
   Honda S, 2023, P INT C QUAL MULT EX
   Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156
   Ishikawa K, 2023, PROC SPIE, V12592, DOI 10.1117/12.2666984
   Kodera N, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON VISUAL COMMUNICATIONS AND IMAGE PROCESSING (IEEE VCIP 2013)
   Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276497, 10.1145/1239451.1239547]
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Lin YX, 2022, J FRANKLIN I, V359, P3808, DOI 10.1016/j.jfranklin.2022.03.036
   Lin YX, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13030405
   Liu MY, 2013, PROC CVPR IEEE, P169, DOI 10.1109/CVPR.2013.29
   Maeda Y, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101985
   Maeda Y, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8081235
   Matsuo Takuya, 2013, Proceedings of the 8th International Conference on Computer Vision Theory and Applications. VISAPP 2013, P300
   Matsuo T, 2015, PROC SPIE, V9393, DOI 10.1117/12.2083087
   Min DB, 2014, IEEE T IMAGE PROCESS, V23, P5638, DOI 10.1109/TIP.2014.2366600
   Min DB, 2012, IEEE T IMAGE PROCESS, V21, P1176, DOI 10.1109/TIP.2011.2163164
   Murooka Y, 2018, PROC INT WORKSHOP FR
   Paris S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964963
   Sugimoto K, 2019, IEEE IMAGE PROC, P190, DOI [10.1109/ICIP.2019.8802927, 10.1109/icip.2019.8802927]
   Sugimoto K, 2016, ASIAPAC SIGN INFO PR
   Sugimoto K, 2015, IEEE T IMAGE PROCESS, V24, P3357, DOI 10.1109/TIP.2015.2442916
   Sumiya Y, 2021, IEEE SIGNAL PROC LET
   Tajima H, 2020, P INT C COMP VIS THE
   Tajima H, 2019, P INT C COMP VIS THE
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Timofte R, 2017, IEEE COMPUT SOC CONF, P1110, DOI 10.1109/CVPRW.2017.149
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Tsubokawa T, 2019, P INT WORKSH FRONT C
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Xu Y, 2006, P ROY SOC A-MATH PHY, V462, P3081, DOI 10.1098/rspa.2006.1700
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yang Q., 2007, PROC IEEE C COMPUTER, P1
   Yang QX, 2009, PROC CVPR IEEE, P557, DOI 10.1109/CVPRW.2009.5206542
   Yu GS, 2011, IMAGE PROCESS ON LIN, V1, P292, DOI 10.5201/ipol.2011.ys-dct
   Zabalza J, 2015, IEEE T GEOSCI REMOTE, V53, P4418, DOI 10.1109/TGRS.2015.2398468
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
NR 65
TC 4
Z9 4
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26131
EP 26158
AR s11042-023-16405-7
DI 10.1007/s11042-023-16405-7
EA AUG 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001063782500002
OA hybrid
DA 2024-07-18
ER

PT J
AU Kashyap, S
   Bhandari, AK
   Giri, P
AF Kashyap, Sidharth
   Bhandari, Ashish Kumar
   Giri, Pushpa
TI Low resource FPGA implementation based efficient image edge detector
   architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Edge detector; Low resource consumption; Sobel edge detector; Roberts
   edge detector; Laplacian edge detector and FPGA
ID LAPLACIAN; OPERATOR; DESIGN
AB This paper proposes a resource-efficient architecture of Sobel edge detector, Prewitt edge detector, Roberts edge detector and Laplacian edge detector on the field programmable gate arrays (FPGAs). The proposed architecture is less complex as well as uses lower resources compared to conventional architecture. The rank properties of the convolution kernel followed by pipelining and concurrent output methods have been implemented to reduce the arithmetic operation without compromising the output conformance. In addition, buffering scheme has also been used to reduce Block RAM (BRAM) consumption and bandwidth between external memory and FPGA. All four edge detection techniques have been depicted and compared at various threshold values. The power and resource consumption followed by execution time (software and hardware) have been estimated and compared of various method at clock frequency 100 MHz for 512x512 image resolution. The Sobel edge detector with the proposed architecture shows overall better performance compared to other edge detection techniques. Furthermore, a number of arithmetic operations, and resources using 8-bit architecture as well as 10-bit architecture of proposed Sobel algorithm have been investigated and compared with existing Sobel algorithm. The proposed architecture is implemented on the Xilinx Zynq (TM)-7000 FPGA board. The proposed architecture method paves the way to process 325 frames per second and power consumption is 0.107 W.
C1 [Kashyap, Sidharth; Bhandari, Ashish Kumar; Giri, Pushpa] Natl Inst Technol Patna, Dept Elect & Commun Engn, Patna 800005, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Bhandari, AK (corresponding author), Natl Inst Technol Patna, Dept Elect & Commun Engn, Patna 800005, India.
EM sidharthk.phd19.ec@nitp.ac.in; bhandari.iiitj@gmail.com;
   pushpa.ec@nitp.ac.in
RI Bhandari, Ashish Kumar/AAA-9991-2019
OI Bhandari, Ashish Kumar/0000-0001-9842-8125
CR Abbasi TA, 2007, INT J ELECTRON, V94, P889, DOI 10.1080/00207210701685253
   ABDOU IE, 1979, P IEEE, V67, P753, DOI 10.1109/PROC.1979.11325
   Bakkouri I, 2023, SIGNAL IMAGE VIDEO P, V17, P1181, DOI 10.1007/s11760-022-02325-w
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Bonny T, 2018, J CIRCUIT SYST COMP, V27, DOI 10.1142/S0218126618502092
   Bosi B, 1999, IEEE T VLSI SYST, V7, P299, DOI 10.1109/92.784091
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Ghosal SK, 2018, MULTIMED TOOLS APPL, V77, P30403, DOI 10.1007/s11042-018-6126-y
   Halder Santanu, 2012, Progress in VLSI Design and Test. Proceedings 16th International Symposium, VDAT 2012, P300, DOI 10.1007/978-3-642-31494-0_34
   Huang FC, 2012, IEEE T CIRC SYST VID, V22, P340, DOI 10.1109/TCSVT.2011.2162760
   Ioannidou A, 2012, EXPERT SYST APPL, V39, P11517, DOI 10.1016/j.eswa.2012.02.106
   KANOPOULOS N, 1988, IEEE J SOLID-ST CIRC, V23, P358, DOI 10.1109/4.996
   Khan TM, 2017, IEEE T IMAGE PROCESS, V26, P2116, DOI 10.1109/TIP.2017.2671781
   KIRSCH RA, 1971, COMPUT BIOMED RES, V4, P315, DOI 10.1016/0010-4809(71)90034-6
   Lorencin I, 2020, ARTIF INTELL MED, V102, DOI 10.1016/j.artmed.2019.101746
   Ma ZB, 2016, IEEE T CIRCUITS-II, V63, P979, DOI 10.1109/TCSII.2016.2536202
   Menaka R, 2020, MICROPROCESS MICROSY, V75, DOI 10.1016/j.micpro.2020.103053
   Nausheen N, 2018, MICROPROCESS MICROSY, V56, P84, DOI 10.1016/j.micpro.2017.10.011
   Nixon Mark S, 2012, FEATURE EXTRACTION I, DOI DOI 10.1016/B978-0-12-396549-3.00007-0
   Orujov F, 2020, APPL SOFT COMPUT, V94, DOI 10.1016/j.asoc.2020.106452
   Prewitt J. M., 1970, Picture processing and psychopictorics, V10, P15
   Ravivarma G, 2021, MATER TODAY-PROC, V45, P2401, DOI 10.1016/j.matpr.2020.10.825
   Roberts L. G., 1963, Machine perception of three-dimensional solids
   ROSENFELD A, 1981, IEEE T PATTERN ANAL, V3, P101, DOI 10.1109/TPAMI.1981.4767056
   Segundo MP, 2010, IEEE T SYST MAN CY B, V40, P1319, DOI 10.1109/TSMCB.2009.2038233
   Tolba MF, 2020, INTEGRATION, V72, P163, DOI 10.1016/j.vlsi.2020.02.003
   Wang X, 2007, IEEE T PATTERN ANAL, V29, P886, DOI 10.1109/TPAMI.2007.1027
   Xu Q, 2014, IEEE T IMAGE PROCESS, V23, P2944, DOI 10.1109/TIP.2014.2311656
   Yildirim M, 2019, ANALOG INTEGR CIRC S, V100, P537, DOI 10.1007/s10470-019-01481-3
   Zhang H, 2007, IEEE T CIRCUITS-II, V54, P200, DOI 10.1109/TCSII.2006.886898
   Zhong Y, 2000, IEEE T PATTERN ANAL, V22, P544, DOI 10.1109/34.857008
NR 31
TC 0
Z9 0
U1 10
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25595
EP 25615
DI 10.1007/s11042-023-16472-w
EA AUG 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001052828600006
DA 2024-07-18
ER

PT J
AU Lin, JS
   Liu, KH
   Lin, CL
AF Lin, Jason
   Liu, Kuan-Hung
   Lin, Cih-Lian
TI A novel data hiding scheme based on multidimensional reference tensors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganography; Reference tensor; Embedding capacity; Visual
   imperceptibility
ID WATERMARKING; PVD
AB The protection of transmitted messages from being eavesdropped on the internet by a third party has always been an important research topic. The image steganography, which utilizes natural images to hide secret messages, is a widely used approach. The security of image steganography depends primarily on the undetectability of the transmitted stego-images. However, very few methods can handle customized adjustments to both the security level and embedding capacity simultaneously. Therefore, this study proposes a novel data hiding scheme utilizing a multidimensional reference tensor (MRT) with N dimensions and a side length of M to achieve these adjustments. The proposed method can freely adjust the embedding capacity from 1 bit per pixel (bpp) to 8 bpp, reduce the overall memory usage by up to nearly 99% based on a scalable index encoding (SIE) technique, and customize the level of security by simply altering the number of dimensions or the side length while maintaining a balance between the embedding capacity and visual imperceptibility. Based on experimental results, we demonstrated that the method could achieve a peak signal-to-noise ratio (PSNR) of 46.38 dB with an embedding capacity of 2 bpp, which is equivalent to the performance of state-of-the-art methods. Furthermore, compared with existing steganographic methods, the embedded message through the MRT is less susceptible to hacking owing to the factorial number of solutions for the MRT, which in this case is M to the power of N.
C1 [Lin, Jason; Liu, Kuan-Hung; Lin, Cih-Lian] Natl Chung Hsing Univ, Dept Comp Sci & Engn, 145 Xingda Rd, Taichung 40227, Taiwan.
C3 National Chung Hsing University
RP Lin, JS (corresponding author), Natl Chung Hsing Univ, Dept Comp Sci & Engn, 145 Xingda Rd, Taichung 40227, Taiwan.
EM jasonlin@nchu.edu.tw; g107056191@mail.nchu.edu.tw;
   s108056016@mail.nchu.edu.tw
OI Lin, Jason/0000-0001-8013-9923
FU National Science and Technology Council, Taiwan, R.O.C [NSTC
   112-2221-E-005-048, NSTC 111-2221-E-005-048, NSTC
   112-2634-F-005-001-MBK, NSTC 111-2634-F-005-001]
FX This research was partially supported by the National Science and
   Technology Council, Taiwan, R.O.C. (Grant Nos. NSTC 112-2221-E-005-048,
   NSTC 111-2221-E-005-048, NSTC 112-2634-F-005-001-MBK, and NSTC
   111-2634-F-005-001).
CR [Anonymous], 1977, USC SIPI IMAGE DATAB
   Anushiadevi R, 2023, J INF SECUR APPL, V72, DOI 10.1016/j.jisa.2022.103407
   Anushiadevi R., 2023, MULTIMED TOOLS APPL, V2023, P1
   Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang C.-C., 2008, 2008 3 INT C INN COM, P17, DOI 10.1109/ICICIC.2008.149
   Chang CC, 2017, LECT NOTES COMPUT SC, V10082, P578, DOI 10.1007/978-3-319-53465-7_43
   Chen J, 2014, SIGNAL PROCESS-IMAGE, V29, P375, DOI 10.1016/j.image.2014.01.003
   Chen YY, 2023, COMPLEX INTELL SYST, V9, P2699, DOI 10.1007/s40747-021-00391-0
   Chen Z., 2022, Journal of Computational and Cognitive Engineering, V1, P103, DOI [10.47852/bonviewJCCE149145205514, DOI 10.47852/BON, DOI 10.47852/BONVIEWJCCE149145205514]
   Chi-Nan Lin, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P369, DOI 10.1109/IIH-MSP.2009.143
   Chu WC, 2003, IEEE T MULTIMEDIA, V5, P34, DOI 10.1109/TMM.2003.808816
   Das S, 2023, IEEE T IND INFORM, V19, P821, DOI 10.1109/TII.2022.3167842
   Fakhredanesh M, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.043007
   Felgenhauer Bertram., 2005, Enumerating possible Sudoku grids
   Gutub A, 2023, CAAI T INTELL TECHNO, V8, P440, DOI 10.1049/cit2.12093
   He MZ, 2019, IEEE ACCESS, V7, P141414, DOI 10.1109/ACCESS.2019.2943616
   Horng JH, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092739
   Hsiao TC, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13030387
   Kumar R, 2019, J INF SECUR APPL, V47, P94, DOI 10.1016/j.jisa.2019.04.007
   Kumar R, 2019, MULTIMED TOOLS APPL, V78, P22977, DOI 10.1007/s11042-019-7640-2
   Kumar R, 2018, MULTIMED TOOLS APPL, V77, P13445, DOI 10.1007/s11042-017-4960-y
   Lin J, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14040828
   Lin SD, 2000, IEEE T CONSUM ELECTR, V46, P415, DOI 10.1109/30.883387
   Malik Aruna, 2018, 2018 International Conference on Advances in Computing, Communication Control and Networking (ICACCCN). Proceedings, P828, DOI 10.1109/ICACCCN.2018.8748668
   Malik A, 2018, MULTIMED TOOLS APPL, V77, P15803, DOI 10.1007/s11042-017-5156-1
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Namasudra S, 2022, COMPUT ELECTR ENG, V100, DOI 10.1016/j.compeleceng.2022.108048
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Pavithran P, 2022, COMPUT COMMUN, V188, P1, DOI 10.1016/j.comcom.2022.02.008
   Singh S, 2020, MULTIMED TOOLS APPL, V79, P18815, DOI 10.1007/s11042-020-08745-5
   Su GD, 2020, IET IMAGE PROCESS, V14, P4633, DOI 10.1049/iet-ipr.2019.1694
   Su GD, 2020, IEEE ACCESS, V8, P26984, DOI 10.1109/ACCESS.2020.2966234
   Verma R., 2022, Journal of Computational and Cognitive Engineering, P1
   Wani A, 2021, CAAI T INTELL TECHNO, V6, P281, DOI 10.1049/cit2.12003
   Wong KS, 2007, SIGNAL PROCESS, V87, P1251, DOI 10.1016/j.sigpro.2006.10.014
   Wu Q, 2016, J INF SECUR APPL, V26, P1, DOI 10.1016/j.jisa.2015.08.003
   Yu LF, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/876946
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 39
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25695
EP 25712
DI 10.1007/s11042-023-16526-z
EA AUG 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001052828600009
DA 2024-07-18
ER

PT J
AU Hatakeyama, T
   Wang, XT
   Yamasaki, T
AF Hatakeyama, Tomoyuki
   Wang, Xueting
   Yamasaki, Toshihiko
TI Transferability prediction among classification and regression tasks
   using optimal transport
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
AB Transfer learning is a method for improving generalization performance by training a model for a different task first and then additionally training the pre-learned weights for the target task. However, transferability-the ease with which source task can be effectively transferred to which target task-is often unknown. Existing works proposed methods of measuring the transferability between classification tasks using images and discrete labels, but it cannot be applied to regression tasks. In this work, we investigate transferability among classification and regression tasks, and propose a method for predicting transferability by extending the optimal transport theory. Our transferability prediction model also can be applied to subjective tasks (e.g., aesthetics and memorability), which are usually regression tasks. We show that the appropriate source (pre-training) tasks can be predicted for the chosen target task without conducting actual pre-training and transferring trials. Experimental results demonstrated high prediction accuracy (correlation coefficient of ? = 0.791) and a speed improvement of approximately 300 times compared with the above-mentioned greedy approach.
C1 [Hatakeyama, Tomoyuki; Yamasaki, Toshihiko] Univ Tokyo, Tokyo, Japan.
   [Wang, Xueting] CyberAgent Inc, Tokyo, Japan.
C3 University of Tokyo
RP Hatakeyama, T; Yamasaki, T (corresponding author), Univ Tokyo, Tokyo, Japan.
EM tsumlikt@gmail.com; wang_xueting@cyberagent.co.jp;
   yamasaki@cvm.t.u-tokyo.ac.jp
RI zhang, jiahao/KEE-9357-2024; Liu, Shaobo/JUU-5767-2023; Zhang,
   Xiaoyu/JXR-6386-2024; Liu, Jingyi/JWP-6326-2024; li, lan/KCJ-5061-2024;
   zhang, xiaoyu/KEJ-0657-2024; zheng, Li/JVN-7465-2024; zhang,
   ling/JXW-6931-2024; Li, Yuan/JXW-8930-2024; Yu, Yan/KCL-1047-2024;
   zhang, xinyi/JWA-0980-2024; zhang, xu/JXX-7692-2024; chen,
   yue/JXW-9556-2024; Zhang, Xiaoxi/KBP-8753-2024; zhou, you/KBC-3567-2024;
   wang, xueting/JPY-2782-2023; Li, Xinyue/JVN-4601-2024
OI Li, Yuan/0009-0004-1325-0954; Yu, Yan/0000-0003-2233-344X; Hatakeyama,
   Tomoyuki/0009-0002-7248-0288
FU University of Tokyo
FX Open access funding provided by The University of Tokyo.
CR Achille A, 2019, IEEE I CONF COMP VIS, P6439, DOI 10.1109/ICCV.2019.00653
   Alvarez-Melis D., 2020, ADV NEURAL INFORM PR, V33, P21428
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Asadulaev A., 2022, ARXIV
   BERTSEKAS DP, 1988, MATH PROGRAM, V42, P203, DOI 10.1007/BF01589405
   BERTSEKAS DP, 1981, MATH PROGRAM, V21, P152, DOI 10.1007/BF01584237
   Cuturi M., 2013, ADV NEURAL INFORM PR, P2292, DOI DOI 10.48550/ARXIV.1306.0895
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dukler Y, 2019, PR MACH LEARN RES, V97
   Gu K, 2021, IEEE T IND INFORM, V17, P2261, DOI 10.1109/TII.2020.2991208
   He C, 2022, PATTERN RECOGN LETT, V161, P67, DOI 10.1016/j.patrec.2022.07.014
   He KM, 2019, IEEE I CONF COMP VIS, P4917, DOI 10.1109/ICCV.2019.00502
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kamila NK, 2016, CLUSTER COMPUT, V19, P1723, DOI 10.1007/s10586-016-0643-0
   Kantorovitch L, 1942, CR ACAD SCI URSS, V37, P199
   Khosla A, 2015, IEEE I CONF COMP VIS, P2390, DOI 10.1109/ICCV.2015.275
   Kingma D. P., 2014, arXiv
   Kolouri S, 2018, PROC CVPR IEEE, P3427, DOI 10.1109/CVPR.2018.00361
   Kong S, 2016, LECT NOTES COMPUT SC, V9905, P662, DOI 10.1007/978-3-319-46448-0_40
   Kornblith S, 2019, PROC CVPR IEEE, P2656, DOI 10.1109/CVPR.2019.00277
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Liu F, 2022, LECT NOTES COMPUT SC, V13672, P701, DOI 10.1007/978-3-031-19775-8_41
   Liu X, 2022, ARXIV
   Monge G, 1781, MEMOIRE THEORIE DEBL
   Murray N, 2012, PROC CVPR IEEE, P2408, DOI 10.1109/CVPR.2012.6247954
   Pándy M, 2022, PROC CVPR IEEE, P9162, DOI 10.1109/CVPR52688.2022.00896
   Peyré G, 2019, FOUND TRENDS MACH LE, V11, P355, DOI 10.1561/2200000073
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Raghu M, 2019, ADV NEUR IN, V32
   Rumelhart D.E., 2013, Learning internal representations by error propagation, P399, DOI [10.1016/b978-1-4832-1446-7.50035-2, 10.1016/B978-1-4832-1446-7.50035-2]
   SAATY TL, 1977, J MATH PSYCHOL, V15, P234, DOI 10.1016/0022-2496(77)90033-5
   Saaty TL., 1988, What is the Analytic Hierarchy Process?, P109, DOI DOI 10.1007/978-3-642-83555-1_5
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Tan Y, 2021, PROC CVPR IEEE, P15774, DOI 10.1109/CVPR46437.2021.01552
   Tran AT, 2019, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2019.00148
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Q, 2018, IEEE T CIRC SYST VID, V28, P2633, DOI 10.1109/TCSVT.2017.2703920
   Xiao H., 2017, ARXIV170807747
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   You QZ, 2016, AAAI CONF ARTIF INTE, P308
   Yurochkin M., 2019, ADV NEURAL INFORM PR, V32, P1601
   Zamir AR, 2018, PROC CVPR IEEE, P3712, DOI 10.1109/CVPR.2018.00391
   Zhao Sicheng, 2016, P 24 ACM INT C MULT, P1385, DOI DOI 10.1145/2964284.2964289
NR 44
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25105
EP 25119
DI 10.1007/s11042-023-15852-6
EA AUG 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001051861800002
OA hybrid
DA 2024-07-18
ER

PT J
AU Shahamiri, SR
AF Shahamiri, Seyed Reza
TI An optimized enhanced-multi learner approach towards speaker
   identification based on single-sound segments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Automatic Speaker Identification; MFCC; Deep neural networks;
   Optimization
ID CLASSIFICATION
AB Speaker Identification (SI) is the task of identifying an unknown speaker of an utterance by comparing the voice biometrics of the unknown speaker with previously stored and known speaker models. Although deep learning algorithms have been successful in different speech and speaker recognition systems, they are computationally expensive and require considerable run-time resources. This paper approaches this issue by proposing an optimized text-independent SI system based on convolutional neural networks (CNNs) that not only delivers accuracies on par with state-of-the-art benchmarks but also demands significantly fewer trainable parameters. The proposed system integrates an Enhanced Multi-Active Learner framework, which distributes the complexity of the learning task among an array of learners, with a novel SI approach in which speakers are identified based on a single sound segment of voice biometrics. Here, experiments were conducted with all 1881 VoxCeleb 1 and TIMIT speakers, and results were compared with the SI systems reported in the literature that were assessed on the same speakers' data. Results indicate that first, the proposed system outperformed the benchmark systems' performances by delivering up to 2.43% better top-1 accuracy, and second, it reduced the number of deep learning trainable parameters by up to 95%. The proposed SI could bring offline, large-scale speaker identification to low-end computing machines without specific deep learning hardware and make the technology more affordable.
C1 [Shahamiri, Seyed Reza] Univ Auckland, Fac Engn, Dept Elect Comp & Software Engn, Auckland, New Zealand.
C3 University of Auckland
RP Shahamiri, SR (corresponding author), Univ Auckland, Fac Engn, Dept Elect Comp & Software Engn, Auckland, New Zealand.
EM admin@rezanet.com
RI Shahamiri, Seyed Reza/G-4389-2011
OI Shahamiri, Seyed Reza/0000-0003-1543-5931
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions
CR Ahmed AI, 2022, COMPUT SPEECH LANG, V75, DOI 10.1016/j.csl.2022.101367
   Ali H, 2018, NEURAL COMPUT APPL, V29, P13, DOI 10.1007/s00521-016-2501-7
   Almaadeed N, 2015, IET BIOMETRICS, V4, P18, DOI 10.1049/iet-bmt.2014.0011
   Biagetti G, 2016, SMART INNOV SYST TEC, V57, P465, DOI 10.1007/978-3-319-39627-9_41
   Champiri Z.D., 2015, Int. J. Soc. Sci. Human., V5, DOI [DOI 10.7763/IJSSH.2015.V5.585, 10.7763/IJSSH.2015.V5.585]
   Chatfield K, 2014, Arxiv, DOI arXiv:1405.3531
   Chen C, 2019, DIGIT SIGNAL PROCESS, V89, P104, DOI 10.1016/j.dsp.2019.03.008
   Chung JY, 2014, Arxiv, DOI arXiv:1412.3555
   Dash TK, 2021, PATTERN RECOGN, V117, DOI 10.1016/j.patcog.2021.107999
   Dong Q, 2019, IEEE T PATTERN ANAL, V41, P1367, DOI 10.1109/TPAMI.2018.2832629
   Galar M, 2012, IEEE T SYST MAN CY C, V42, P463, DOI 10.1109/TSMCC.2011.2161285
   Garain A, 2022, NEURAL COMPUT APPL, V34, P14463, DOI 10.1007/s00521-022-07261-x
   Garofolo John, 1993, TIMIT ACOUSTIC PHONE
   Hansen JHL, 2015, IEEE SIGNAL PROC MAG, V32, P74, DOI 10.1109/MSP.2015.2462851
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Islam MA, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0158520
   Karthikeyan V, 2024, J EXP THEOR ARTIF IN, V36, P273, DOI 10.1080/0952813X.2022.2092560
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee HT, 2009, ACM T WEB, V3, DOI 10.1145/1541822.1541823
   Lu H, 2011, LECT NOTES COMPUT SC, V6696, P188, DOI 10.1007/978-3-642-21726-5_12
   Lukic Y., 2016, 2016 IEEE 26 INT WOR, P1, DOI DOI 10.1109/MLSP.2016.7738816
   Lyons J, PYTHON SPEECH FEATUR
   Nagrani A, 2017, INTERSPEECH, P2616, DOI 10.21437/Interspeech.2017-950
   An NN, 2019, IEEE ACCESS, V7, P85327, DOI 10.1109/ACCESS.2019.2917470
   Porwik P, 2019, EXPERT SYST APPL, V115, P673, DOI 10.1016/j.eswa.2018.08.037
   Reddy MK, 2021, COMPUT SPEECH LANG, V69, DOI 10.1016/j.csl.2021.101205
   REYNOLDS DA, 1995, IEEE T SPEECH AUDI P, V3, P72, DOI 10.1109/89.365379
   Richardson F, 2015, IEEE SIGNAL PROC LET, V22, P1671, DOI 10.1109/LSP.2015.2420092
   Roger V, 2022, EURASIP J AUDIO SPEE, V2022, DOI 10.1186/s13636-022-00251-w
   Saeed K, 2007, IEEE T IND ELECTRON, V54, P887, DOI 10.1109/TIE.2007.891647
   Shahamiri S. R., 2010, 2010 2nd International Conference on Software Technology and Engineering (ICSTE 2010), P272, DOI 10.1109/ICSTE.2010.5608808
   Shahamiri SR, 2022, TECHNOL HEALTH CARE, V30, P605, DOI 10.3233/THC-213032
   Shahamiri SR, 2022, J EXP THEOR ARTIF IN, V34, P989, DOI 10.1080/0952813X.2021.1948921
   Shahamiri SR, 2020, MULTIMED TOOLS APPL, V79, P31265, DOI 10.1007/s11042-020-09580-4
   Shahamiri SR, 2023, ENHANCED MULTILEARNE
   Shahin I, 2020, NEURAL COMPUT APPL, V32, P2575, DOI 10.1007/s00521-018-3760-2
   Shi YP, 2020, INT CONF ACOUST SPEE, P7579, DOI [10.1109/icassp40776.2020.9054448, 10.1109/ICASSP40776.2020.9054448]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun LH, 2019, INT J SPEECH TECHNOL, V22, P449, DOI 10.1007/s10772-019-09618-5
   Sun SL, 2011, NEURAL PROCESS LETT, V34, P229, DOI 10.1007/s11063-011-9195-8
   Tirumala S.S., 2017, the 9th International Conference on Signal Processing Systems, P175, DOI [10.1145/3163080.3163097, DOI 10.1145/3163080.3163097]
   Xiaojia Zhao, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3997, DOI 10.1109/ICASSP.2014.6854352
   Xu LT, 2018, IEEE-ACM T AUDIO SPE, V26, P749, DOI 10.1109/TASLP.2018.2793670
   Yadav S, 2018, INTERSPEECH, P2237, DOI 10.21437/Interspeech.2018-1015
   Yang Z., 2016, P 2016 C N AM CHAPT, P1480, DOI [DOI 10.18653/V1/N16-1174, 10.18653/v1/n16-1174]
   Zhang ZF, 2015, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-015-0056-7
NR 46
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 17
PY 2023
DI 10.1007/s11042-023-16507-2
EA AUG 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P3YY0
UT WOS:001050048600008
OA hybrid
DA 2024-07-18
ER

PT J
AU Guemues, S
   Kamisli, F
AF Guemues, Sinem
   Kamisli, Fatih
TI A learned pixel-by-pixel lossless image compression method with 59K
   parameters and parallel decoding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image compression; Artificial neural networks; Entropy coding; Gaussian
   mixture model
AB This paper considers lossless image compression and presents a learned compression system that can achieve state-of-the-art lossless compression performance but uses only 59K parameters, which is one or two order of magnitudes less than other learned systems proposed recently in the literature. The explored system is based on a learned pixel-by-pixel lossless image compression method, where each pixel's probability distribution parameters are obtained by processing the pixel's causal neighborhood (i.e. previously encoded/decoded pixels) with a simple neural network comprising 59K parameters. This causality causes the decoder to operate sequentially, i.e. the neural network has to be evaluated for each pixel sequentially, which increases decoding time significantly with common GPU software and hardware. To reduce the decoding time, parallel decoding algorithms are proposed and implemented. The obtained lossless image compression system is compared to traditional and learned systems in the literature in terms of compression performance, encoding-decoding times and computational complexity.
C1 [Guemues, Sinem; Kamisli, Fatih] Middle East Tech Univ, Elect & Elect Engn, TR-06800 Ankara, Turkiye.
C3 Middle East Technical University
RP Guemues, S; Kamisli, F (corresponding author), Middle East Tech Univ, Elect & Elect Engn, TR-06800 Ankara, Turkiye.
EM sinem.gumus@metu.edu.tr; kamisli@metu.edu.tr
OI Kamisli, Fatih/0000-0001-7112-1633
CR Boutell T., 1997, NETWORK WORKING GROU
   Chi CC, 2012, IEEE T CIRC SYST VID, V22, P1827, DOI 10.1109/TCSVT.2012.2223056
   Chrabaszcz P, 2017, Arxiv, DOI arXiv:1707.08819
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Fu C., 2022, NUMPYAC FAST AUTOREG
   Google, 2022, IM FORM WEB
   Gumus S., 2022, LEARNED PIXEL BY PIX
   Hoogeboom E., 2019, INTEGER DISCRETE FLO
   Kingma D. P., 2014, arXiv
   Krahenbuhl P., 2020, arXiv
   Krasin I., 2017, Openimages: A public dataset for large-scale multi-label and multi-class image classification
   Lee YL, 2006, IEEE T IMAGE PROCESS, V15, P2610, DOI 10.1109/TIP.2006.877396
   Liu XX, 2022, MULTIMED TOOLS APPL, V81, P4781, DOI 10.1007/s11042-021-11017-5
   Malvar H. S., 2003, ISOIEC JTC1SC29WG11
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   Masmoudi A, 2015, MULTIMED TOOLS APPL, V74, P10605, DOI 10.1007/s11042-014-2195-8
   Mentzer F., PRACTICAL FULL RESOL
   Mentzer F, 2019, PROC CVPR IEEE, P10621, DOI 10.1109/CVPR.2019.01088
   Paszke A, 2019, ADV NEUR IN, V32
   Pennebaker W. B., 1992, JPEG STILL IMAGE DAT
   Reed S. etal., 2017, Parallel multiscale autoregressive density estimation
   Ryder T., 2022, SPLIT HIERARCHICAL V
   Salimans Tim, 2017, ICLR
   Sneyers J, 2016, IEEE IMAGE PROC, P66, DOI 10.1109/ICIP.2016.7532320
   Sovrasov V., 2022, Flops Counter for Convolutional Networks in Pytorch Framework
   van den Oord A, 2016, ADV NEUR IN, V29
   van den Oord A, 2016, PR MACH LEARN RES, V48
   vanden Berg R., 2021, IDF ANAL IMPROVING I
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Zhang H. etal., 2020, LOSSLESS IMAGE COMPR
   Zhang MT, 2022, Arxiv, DOI arXiv:2201.05213
   Zhang Shifeng, 2021, ADV NEURAL INFORM PR, V34, P3
   Zhou MH, 2012, IEEE T CIRC SYST VID, V22, P1839, DOI 10.1109/TCSVT.2012.2221524
NR 33
TC 0
Z9 0
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 10
PY 2023
DI 10.1007/s11042-023-16270-4
EA AUG 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O8QT2
UT WOS:001046412000007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhao, ZQ
   Zhu, ZL
   Yan, M
   Wu, B
   Zhao, ZJ
AF Zhao, Zhiqiang
   Zhu, Zhiliang
   Yan, Meng
   Wu, Bin
   Zhao, Zhijian
TI Robust object tracking based on power-law probability map and ridge
   regression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Object tracking; Ridge regression; Correlation filtering; Power-law
   probability map
ID CORRELATION FILTERS
AB Traditional tracking algorithms based on correlation filtering usually use a filter based on Gaussian-like distribution to highlight the information of the target and weaken the interfer-ence of the background on the target. The characteristic of such method is that it highlights the importance of the target center, but it weakens the marginal information of the target. To overcome this problem, this paper proposes a new filter based on power-law probability map and proposes a new tracking algorithm based on the power-law probability map filter and the technology of ridge regression. The filter can screens the overall information of the target effectively, including the marginal information of the target. Firstly, a target block is extracted from the actual image at time t according to the position of the target at time t - 1, and then a probability map is generated from the target block. Next, the power-law probability map filter is generated by several image processing technologies. On this basis, two parts of HOG features are extracted from the target block, and then these two parts HOG features are filtered and are combined with the ridge regression model to locate and track the target. Finally, a large number of experiments show that our proposed tracking algorithm achieves competitive performance compared with the state-of-the-art tracking algorithms.
C1 [Zhao, Zhiqiang] Ningxia Normal Univ, Sch Math & Comp Sci, Guyuan 756000, Ningxia, Peoples R China.
   [Zhu, Zhiliang] Chinese Acad Sci, Inst Software, Beijing 100190, Peoples R China.
   [Yan, Meng] Hubei Univ Technol, Sch Comp, Wuhan 430068, Hubei, Peoples R China.
   [Wu, Bin] Univ Jiujiang, Sch Comp & Big Data Sci, Jiujiang 332005, Jiangxi, Peoples R China.
   [Zhao, Zhijian] Hunan Univ, Business Sch, Changsha 410006, Hunan, Peoples R China.
C3 Ningxia Normal University; Chinese Academy of Sciences; Institute of
   Software, CAS; Hubei University of Technology; Jiujiang University;
   Hunan University
RP Zhao, ZQ (corresponding author), Ningxia Normal Univ, Sch Math & Comp Sci, Guyuan 756000, Ningxia, Peoples R China.
EM zqzhao2000@foxmail.com; zhiliang2019@iscas.ac.cn; ym620@126.com;
   wubincs@gmail.com; zzj0827@foxmail.com
FU National Natural Science Foundation of China [62202165, 62262033];
   Natural Science Foundation of Jiangxi Province [20224BAB202016]
FX AcknowledgementsThank the editor and the anonymous referees for their
   valuable comments. This work has been jointly supported by the National
   Natural Science Foundation of China under Grant 62202165 and 62262033,
   the Natural Science Foundation of Jiangxi Province under Grant
   20224BAB202016.
CR Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bhat G, 2019, IEEE I CONF COMP VIS, P6181, DOI 10.1109/ICCV.2019.00628
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M., 2014, Accurate Scale Estimation for Robust Visual Tracking
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Du F, 2020, IEEE T CIRC SYST VID, V30, P1625, DOI 10.1109/TCSVT.2019.2909654
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Galoogahi HK, 2013, IEEE I CONF COMP VIS, P3072, DOI 10.1109/ICCV.2013.381
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Han YQ, 2019, IEEE T IMAGE PROCESS, V28, P4075, DOI 10.1109/TIP.2019.2905984
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   He WP, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10093021
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Huang W, 2021, MULTIMED TOOLS APPL, V80, P13911, DOI 10.1007/s11042-020-10427-1
   Jiang M, 2021, IEEE T CIRC SYST VID, V31, P3154, DOI 10.1109/TCSVT.2020.3037947
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kuai YL, 2018, J VIS COMMUN IMAGE R, V51, P104, DOI 10.1016/j.jvcir.2018.01.008
   Li D, 2020, IEEE T CIRC SYST VID, V30, P509, DOI 10.1109/TCSVT.2019.2892759
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Liu C, 2018, IEEE T MULTIMEDIA, V20, P889, DOI 10.1109/TMM.2017.2760633
   Ma C., 2022, MULTIMED TOOLS APPL, V81, P20917, DOI [10.1007/s11042-022-12669-7, DOI 10.1007/S11042-022-12669-7]
   Paul M, 2022, LECT NOTES COMPUT SC, V13682, P571, DOI 10.1007/978-3-031-20047-2_33
   Possegger H, 2015, PROC CVPR IEEE, P2113, DOI 10.1109/CVPR.2015.7298823
   Rinosha SMJ, 2023, MULTIMED TOOLS APPL, V82, P7825, DOI 10.1007/s11042-022-13681-7
   Wang C, 2018, P AAAI C ARTIFICIAL, V32
   Wang FS, 2022, MULTIMED TOOLS APPL, V81, P27879, DOI 10.1007/s11042-022-12760-z
   Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Yang K, 2020, KNOWL-BASED SYST, V203, DOI 10.1016/j.knosys.2020.106079
   Yu YC, 2020, PROC CVPR IEEE, P6727, DOI 10.1109/CVPR42600.2020.00676
   Yuan D, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105554
   Yuan D, 2020, KNOWL-BASED SYST, V195, DOI 10.1016/j.knosys.2020.105697
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhao ZQ, 2018, NEUROCOMPUTING, V297, P40, DOI 10.1016/j.neucom.2018.02.043
   Zhu XF, 2021, IEEE T CIRC SYST VID, V31, P557, DOI 10.1109/TCSVT.2020.2979480
   Zuo WM, 2019, IEEE T PATTERN ANAL, V41, P1158, DOI 10.1109/TPAMI.2018.2829180
NR 46
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 10
PY 2023
DI 10.1007/s11042-023-16339-0
EA AUG 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O8QT2
UT WOS:001046412000004
DA 2024-07-18
ER

PT J
AU Rayachoti, E
   Duvvuru, R
AF Rayachoti, Eswaraiah
   Duvvuru, Rajesh
TI Telemedicine and E-healthcare: A novel watermarking method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Telemedicine; E-healthcare; ROI; RONI; NSCT
AB Telemedicine is becoming more and more popular since it enables patients to consult doctors in distant areas and receive sickness treatment online. Safely transmitting medical images is one of the most difficult parts of telemedicine. Regions of interest (ROIs) are normally found in medical images. During transmission, an intruder may manipulate the ROI of the image. In this paper, the Nonsubsampled Contourlet Transform (NSCT) is used to propose a novel watermarking technique. An image to be communicated is segmented into a region of interest (ROI) and a region of non-interest (RONI). Further, segments the RONI into parts. Embeds the hash code, authentication data, recovery data etc. into the parts of RONI. In the event that the ROI is tampered during transmission of the image, the proposed method excerpts the ROI recovery data from the RONI of the image, verifies it, and recovers the ROI with that data if it is authentic. Based on experimental results, the proposed method is capable of embedding higher data volumes by using NSCT, in addition to recognizing tampered areas in the ROI and recovering it.
C1 [Rayachoti, Eswaraiah; Duvvuru, Rajesh] VIT AP Univ, Vijayawada, Andhra Pradesh, India.
C3 VIT-AP University
RP Rayachoti, E (corresponding author), VIT AP Univ, Vijayawada, Andhra Pradesh, India.
EM eswar_507@yahoo.co.in
RI DUVVURU, RAJESH/JAA-9396-2023
CR Alshanbari HS, 2021, MULTIMED TOOLS APPL, V80, P16549, DOI 10.1007/s11042-020-08814-9
   CHEN KS, 1994, IEEE T MED IMAGING, V13, P538, DOI 10.1109/42.310885
   Coatrieux G, 2009, IEEE T INF TECHNOL B, V13, P158, DOI 10.1109/TITB.2008.2007199
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Gao H, 2022, CLUSTER COMPUT, V25, P707, DOI 10.1007/s10586-021-03446-6
   Li QD, 2022, MULTIMED TOOLS APPL, V81, P11415, DOI 10.1007/s11042-022-12266-8
   Mohammed Ahmed A., 2021, IOP Conference Series: Materials Science and Engineering, V1152, DOI 10.1088/1757-899X/1152/1/012025
   Mohammed A, 2014, I C APPL INF COMM TE, P16
   Ooi Jessie, 2020, IOP Conference Series: Materials Science and Engineering, V769, DOI 10.1088/1757-899X/769/1/012068
   Ravichandran D, 2021, MED BIOL ENG COMPUT, V59, P1355, DOI 10.1007/s11517-021-02374-2
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Sinhal R, 2022, MULTIMED TOOLS APPL, V81, P14045, DOI 10.1007/s11042-022-12082-0
   Swaraja K, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101665
   Xiao SZ, 2020, SCI PROGRAMMING-NETH, V2020, DOI 10.1155/2020/8848885
   Zhaoning Y., 2021, J INF SECUR APPL, V58
NR 15
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 9
PY 2023
DI 10.1007/s11042-023-16437-z
EA AUG 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O6VD2
UT WOS:001045151400005
DA 2024-07-18
ER

PT J
AU Leong, SM
   Phan, RCW
   Baskaran, VM
AF Leong, Shu-Min
   Phan, Raphael C. -W.
   Baskaran, Vishnu Monn
TI Emotion-specific AUs for micro-expression recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Action units; FACS; LBP-TOP; Micro-expression recognition
ID ACTION CODING SYSTEM
AB The Facial Action Coding System (FACS) comprehensively describes facial expressions with facial action units (AUs). It is a well-used technique by researchers in emotions research to understand human emotions better. Most micro-expression datasets provide FACS-coded AU ground truths corresponding to micro-expressions classes. It is commonly accepted in computer vision-based emotions research that certain emotions are reliably revealed when specific combinations of AUs occur. However, the reliability of the ground truth AUs in the micro-expression datasets is lower than that of normal expressions, as they have lower AU intensities. Moreover, these micro-expression datasets only report the overall reliability of all AUs. It could not be identified which AUs had been accurately coded. This work aims to revisit the ground truth AUs of popular micro-expression datasets, namely CASME II, SAMM and CAS(ME)(2), and inspect whether any AUs crucial for micro-expression recognition may need to be reconsidered. This paper also provides a detailed AU analysis which yields new AU-based RoIs for each dataset. These new RoIs improve the micro-expression recognition performances compared to the baselines considered in this work. The proposed RoIs for CASME II, SAMM and CAS(ME)(2) improve the recognition rates by 2%, 1% and 4%, respectively, when compared with the existing RoIs.
C1 [Leong, Shu-Min; Phan, Raphael C. -W.; Baskaran, Vishnu Monn] Monash Univ, Sch Informat Technol, Subang Jaya, Malaysia.
C3 Monash University; Monash University Malaysia
RP Leong, SM (corresponding author), Monash Univ, Sch Informat Technol, Subang Jaya, Malaysia.
EM leong.shumin@monash.edu; raphael.phan@monash.edu; vishnu.monn@monash.edu
OI Leong, Shu Min/0000-0003-1041-4170
FU MOHE FRGS AdverSurreal project; Partenariats Hubert Curien
   (PHC)-Hibiscus MyPAIR project GAN Games; Monash Malaysia's Advanced
   Computing Platform
FX This research is supported in part by the MOHE FRGS AdverSurreal
   project, the Partenariats Hubert Curien (PHC)-Hibiscus MyPAIR project
   GAN Games, and Monash Malaysia's Advanced Computing Platform.
CR Ngo ACL, 2017, IEEE T AFFECT COMPUT, V8, P396, DOI 10.1109/TAFFC.2016.2523996
   [Anonymous], 2009, The philosophy of deception, DOI DOI 10.1093/ACPROF:OSO/9780195327939.003.0008
   Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442
   Barra P, 2022, MULTIMEDIA TOOLS APP, P1
   Barrett LF, 2019, PSYCHOL SCI PUBL INT, V20, P1, DOI 10.1177/1529100619832930
   Bisogni C, 2022, IEEE T IND INFORM, V18, P5619, DOI 10.1109/TII.2022.3141400
   Chen LF, 2023, IEEE T IND ELECTRON, V70, P1016, DOI 10.1109/TIE.2022.3150097
   Cohn Jeffrey, 2007, The handbook of emotion elicitation and assessment, P203, DOI DOI 10.1093/OSO/9780195169157.003.0014
   Davison Adrian K., 2018, IEEE Transactions on Affective Computing, V9, P116, DOI 10.1109/TAFFC.2016.2573832
   Davison AK, 2018, J IMAGING, V4, DOI 10.3390/jimaging4100119
   Deeb H, 2022, MULTIMED TOOLS APPL, V81, P24529, DOI 10.1007/s11042-022-12498-8
   Eisenbarth H, 2011, EMOTION, V11, P860, DOI 10.1037/a0022758
   Ekman P., 2002, FACIAL ACTION CODING
   Ekman P, 1978, FACIAL ACTION CODING
   Ekman Paul, 1997, What the Face Reveals: Basic and Applied Studies of Spontaneous Expression using the Facial Action Coding System (FACS)
   Fangbing Qu, 2018, IEEE Transactions on Affective Computing, V9, P424, DOI 10.1109/TAFFC.2017.2654440
   Goh KM, 2019, MULTIMED TOOLS APPL, V78, P21485, DOI 10.1007/s11042-019-7385-y
   Gorbova J, 2019, MULTIMED TOOLS APPL, V78, P23161, DOI 10.1007/s11042-019-7658-5
   Gupta P, 2021, IEEE T AFFECT COMPUT
   Hamm J, 2011, J NEUROSCI METH, V200, P237, DOI 10.1016/j.jneumeth.2011.06.023
   Happy SL, 2019, IEEE T AFFECT COMPUT, V10, P394, DOI 10.1109/TAFFC.2017.2723386
   He YH, 2022, PATTERN RECOGN LETT, V163, P57, DOI 10.1016/j.patrec.2022.09.009
   Huang XH, 2019, IEEE T AFFECT COMPUT, V10, P32, DOI 10.1109/TAFFC.2017.2713359
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kumar AJR, 2021, IEEE COMPUT SOC CONF, P1511, DOI 10.1109/CVPRW53098.2021.00167
   Lei L, 2021, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW53098.2021.00173
   Li XB, 2018, IEEE T AFFECT COMPUT, V9, P563, DOI 10.1109/TAFFC.2017.2667642
   Liong ST, 2018, SIGNAL PROCESS-IMAGE, V62, P82, DOI 10.1016/j.image.2017.11.006
   Liu YJ, 2016, IEEE T AFFECT COMPUT, V7, P299, DOI 10.1109/TAFFC.2015.2485205
   Martinez B, 2019, IEEE T AFFECT COMPUT, V10, P325, DOI 10.1109/TAFFC.2017.2731763
   Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4
   Merghani W, 2020, IEEE INT CONF AUTOMA, P765, DOI 10.1109/FG47880.2020.00067
   Merghani W, 2019, MULTIMED TOOLS APPL, V78, P21613, DOI 10.1007/s11042-019-7434-6
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Sayette MA, 2001, J NONVERBAL BEHAV, V25, P167, DOI 10.1023/A:1010671109788
   Takalkar M, 2018, MULTIMED TOOLS APPL, V77, P19301, DOI 10.1007/s11042-017-5317-2
   Tian YL, 2005, HANDBOOK OF FACE RECOGNITION, P247, DOI 10.1007/0-387-27257-7_12
   Wang SJ, 2015, IEEE T IMAGE PROCESS, V24, P6034, DOI 10.1109/TIP.2015.2496314
   Wang SJ, 2014, INT C PATT RECOG, P4678, DOI 10.1109/ICPR.2014.800
   Wang YD, 2017, MULTIMED TOOLS APPL, V76, P21665, DOI 10.1007/s11042-016-4079-6
   Xie HX, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2871, DOI 10.1145/3394171.3414012
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Yan WJ, 2013, J NONVERBAL BEHAV, V37, P217, DOI 10.1007/s10919-013-0159-8
   Yang B, 2021, MULTIMED TOOLS APPL, V80, P16125, DOI 10.1007/s11042-019-07896-4
   Zhang X, 2014, IMAGE VISION COMPUT, V32, P692, DOI 10.1016/j.imavis.2014.06.002
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao SR, 2022, NEURAL NETWORKS, V153, P427, DOI 10.1016/j.neunet.2022.06.024
   Zhou ZH, 2011, PROC CVPR IEEE, P137, DOI 10.1109/CVPR.2011.5995345
   Zong Y, 2018, IEEE T MULTIMEDIA, V20, P3160, DOI 10.1109/TMM.2018.2820321
NR 50
TC 0
Z9 0
U1 8
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 8
PY 2023
DI 10.1007/s11042-023-16326-5
EA AUG 2023
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O6EV9
UT WOS:001044727600005
OA hybrid
DA 2024-07-18
ER

PT J
AU El Azzaby, F
   El Akkad, N
   Sabour, K
   Kabbaj, S
AF El Azzaby, Fouzia
   El Akkad, Nabil
   Sabour, Khalid
   Kabbaj, Samir
TI A new encryption scheme for RGB color images by coupling 4D chaotic
   laser systems and the Heisenberg group
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Heisenberg group; 4D chaotic system; Encryption; Decryption; RGB images
ID CHAOTIFICATION SYSTEM
AB This research focuses on introducing a novel algorithm for RGB image encryption. The proposed approach is a hybrid fusion of mathematical principles, namely group theory and chaos theory. It leverages the favorable characteristics of the Heisenberg subgroup of GL2n+ 1(Z) and a 4D chaotic laser system derived from the Lorenz-Haken equations. The algorithm aims to provide robust encryption by truncating four sequences from the 4D chaotic map. The initial Heisenberg matrix is generated using two input parameters, while the second matrix is constructed using two additional parameters. To enhance encryption efficiency, four square boxes of dimensions 16 x 16 are designed specifically for the 4D laser system. Each box contains cells that represent the rank of values relative to similar values in the same stream. Furthermore, the source image is divided into threemonochromatic components. The foreground of the Heisenberg matrix is multiplied by each channel extracted from the source image. The encryption process proceeds with digram substitution, wherein two-pixel couples are replaced using the values stored in the four box squares. The first value is selected from box 1, followed by the second value from box 4. The remaining values needed to complete the rectangle are retrieved from boxes 2 and 3. For the subsequent digram, a circular rotation of the boxes is performed. The first value is obtained from box 2, the second value from box 3, and so forth, ensuring a continuous circular pattern. Finally, a second multiplication is applied, involving the second plane of the Heisenberg matrix and the result obtained in the previous stage. Experimental results demonstrate the algorithm's effectiveness, exhibiting resistance to differential attacks, statistical attacks, and superior performance compared to existing encryption techniques.
C1 [El Azzaby, Fouzia; Sabour, Khalid; Kabbaj, Samir] Ibn Tofail Univ, Fac Sci, Dept Math, Kenitra 14000, Morocco.
   [El Akkad, Nabil] Sidi Mohamed Ben Abdellah Univ Fez, Lab Engn Syst & Applicat, ENSA Fez, Fes 30200, Morocco.
C3 Ibn Tofail University of Kenitra; Sidi Mohamed Ben Abdellah University
   of Fez
RP El Azzaby, F (corresponding author), Ibn Tofail Univ, Fac Sci, Dept Math, Kenitra 14000, Morocco.
EM fouzia_099@hotmail.com; nabil.elakkad@usmba.ac.ma;
   khsabour2016@gmail.com; samkabbaj@yahoo.fr
RI Khalid, Sabour/JAC-4894-2023; AKKAD, Nabil EL/AAL-4049-2020
OI AKKAD, Nabil EL/0000-0003-0277-8003; sabour, khalid/0000-0003-2792-955X;
   Elazzaby, Fouzia/0000-0003-3262-446X
CR Boriga R., 2014, MULTIMED ADV, P6
   Chen JY, 2022, INT J INNOV COMPUT I, V18, P73, DOI 10.24507/ijicic.18.01.73
   COOPERSMITH D, 1994, IBM J RES DEV, V38, P243, DOI 10.1147/rd.383.0243
   Elazzaby Fouzia, 2020, Embedded Systems and Artificial Intelligence. Proceedings of ESAI 2019. Advances in Intelligent Systems and Computing (AISC 1076), P589, DOI 10.1007/978-981-15-0947-6_56
   Es-Sabry M, 2020, SOFT COMPUT, V24, P3829, DOI 10.1007/s00500-019-04151-8
   Es-Sabry M, 2018, COMM COM INF SC, V872, P78, DOI 10.1007/978-3-319-96292-4_7
   Es-sabry M, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV2018)
   Faragallah OS, 2019, IEEE ACCESS, V7, P4184, DOI 10.1109/ACCESS.2018.2879857
   Hua ZY, 2020, IEEE T IND INFORM, V16, P887, DOI 10.1109/TII.2019.2923553
   Hua ZY, 2020, IEEE T SIGNAL PROCES, V68, P1937, DOI 10.1109/TSP.2020.2979596
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Jain R, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P1835, DOI 10.1109/RTEICT.2016.7808152
   Kang XJ, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115670
   Kang XJ, 2019, IEEE T CIRC SYST VID, V29, P1919, DOI 10.1109/TCSVT.2018.2859253
   Kaur G, 2020, ENG SCI TECHNOL INT
   Kaur G, 2019, 2019 6TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P399, DOI 10.1109/SPIN.2019.8711777
   Kumar M., 2015, J INFORM SECURITY AP, V21, P2030
   Mishra DC, 2017, J INF SECUR APPL, V37, P65, DOI 10.1016/j.jisa.2017.09.006
   Mollaeefar M, 2017, MULTIMED TOOLS APPL, V76, P607, DOI 10.1007/s11042-015-3064-9
   Natiq H, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21010034
   Rehman AU, 2018, OPTIK, V159, P348, DOI 10.1016/j.ijleo.2018.01.064
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Talhaoui MZ, 2021, VISUAL COMPUT, V37, P541, DOI 10.1007/s00371-020-01822-8
   Talhaoui MZ, 2021, VISUAL COMPUT, V37, P1757, DOI 10.1007/s00371-020-01936-z
   Teng L, 2021, NONLINEAR DYNAM, V105, P1859, DOI 10.1007/s11071-021-06663-1
   Wang X, 2019, NEUROSCI LETT, V699, P1, DOI 10.1016/j.neulet.2019.01.028
   Wang XY, 2019, MOD PHYS LETT B, V33, DOI 10.1142/S0217984919502634
   Wu XJ, 2018, MULTIMED TOOLS APPL, V77, P12349, DOI 10.1007/s11042-017-4885-5
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Wu XL, 2017, IEEE ACCESS, V5, P6429, DOI 10.1109/ACCESS.2017.2692043
   Zhang ZZ, 2022, IEEE ACCESS, V10, P67669, DOI 10.1109/ACCESS.2022.3185229
NR 31
TC 2
Z9 2
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 5
PY 2023
DI 10.1007/s11042-023-16139-6
EA AUG 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O4EJ2
UT WOS:001043360000009
DA 2024-07-18
ER

PT J
AU Singh, C
   Raja, PCK
AF Singh, Charanjeet
   Raja, P. C. Kishore
TI Hybrid optimization assisted transmit antenna selection for massive MIMO
   technology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-input; Multi-output; Secrecy Rate; Energy Efficiency; Elephant
   Herding Optimization Algorithm; Fitness-based Elephant Herding Algorithm
ID SYSTEMS; ALGORITHM
AB MIMO (Multi-input, Multi-output) systems are a key technology for achieving 5G wireless communications' performance goals. They achieve significant levels of various acquisition, consistency, and efficiency. Nonetheless, for more transmit antennas; more radio frequency (RF) chains are necessary, which may result in increased computational complexity and expenses. As a result, selecting the optimal transmit antennas is critical for improving system performance. This paper offers a new Fitness-based Elephant Herding Algorithm (F-EHA) for selecting the optimal broadcast antenna by specifying many criteria such as secrecy rate and efficiency. In addition, the system provides a recommendation for which antenna to use. Finally, the suggested model's advantage over existing techniques in terms of EE (Energy Efficiency) and secrecy rate is demonstrated.
C1 [Singh, Charanjeet] Deenbandhu Chhotu Ram Univ Sci & Technol, Elect & Commun Dept, Sonipat, Haryana, India.
   [Raja, P. C. Kishore] Vellore Inst Technol VIT, Vellore 632014, India.
C3 Deenbandhu Chhotu Ram University of Science & Technology; Vellore
   Institute of Technology (VIT); VIT Vellore
RP Singh, C (corresponding author), Deenbandhu Chhotu Ram Univ Sci & Technol, Elect & Commun Dept, Sonipat, Haryana, India.
EM charanjeet.research@gmail.com
RI SINGH, CHARANJEET/HKN-4250-2023
OI SINGH, CHARANJEET/0000-0001-6598-8150
CR Amadori PV, 2016, IEEE T VEH TECHNOL, V65, P5944, DOI 10.1109/TVT.2015.2477457
   Asaad S, 2018, IEEE J SEL AREA COMM, V36, P817, DOI 10.1109/JSAC.2018.2825159
   Nguyen BC, 2020, AEU-INT J ELECTRON C, V123, DOI 10.1016/j.aeue.2020.153312
   Charanjeet S., 2023, INT J COMMUN SYST, V36
   Dharmarajan A, 2022, MULTIMED TOOLS APPL, V81, P34849, DOI 10.1007/s11042-021-11827-7
   Elhosseini MA, 2019, KNOWL-BASED SYST, V166, P58, DOI 10.1016/j.knosys.2018.12.012
   Eskandari M, 2018, J COMMUN NETW-S KOR, V20, P546, DOI 10.1109/JCN.2018.000087
   Gao Y, 2018, IEEE T SIGNAL PROCES, V66, P1346, DOI 10.1109/TSP.2017.2786220
   Hanif M, 2018, J COMMUN NETW-S KOR, V20, P144, DOI 10.1109/JCN.2018.000022
   Hu Bibo, 2014, [The Journal of China Universities of Posts and Telecommunications, 中国邮电高校学报], V21, P1
   Khalid S, 2020, PHYS COMMUN-AMST, V42, DOI 10.1016/j.phycom.2020.101137
   Khan R, 2019, AEU-INT J ELECTRON C, V111, DOI 10.1016/j.aeue.2019.152880
   Liu ZJ, 2017, IEEE T VEH TECHNOL, V66, P4453, DOI 10.1109/TVT.2016.2598842
   Mchbal A, 2019, PROCEDIA MANUF, V32, P647, DOI 10.1016/j.promfg.2019.02.266
   Mendonça MOK, 2020, IEEE T WIREL COMMUN, V19, P1868, DOI 10.1109/TWC.2019.2959317
   Moualeu JM, 2019, IEEE T COMMUN, V67, P6483, DOI 10.1109/TCOMM.2019.2921966
   Nipanikar SI., 2019, Multimedia Research, V2, P23
   Olyaee M, 2018, IET COMMUN, V12, P255, DOI 10.1049/iet-com.2017.0905
   Rao IV, 2021, EVOL INTELL, V14, P1831, DOI 10.1007/s12065-020-00457-x
   Rao IV, 2019, WIRELESS PERS COMMUN, V109, P1217, DOI 10.1007/s11277-019-06611-8
   Rao IV., 2019, Journal of Networking and Communication Systems, V2, P12, DOI DOI 10.46253/JNACS.V2I4.A2
   Rezaei F, 2019, SIGNAL PROCESS, V164, P58, DOI 10.1016/j.sigpro.2019.05.006
   Sadashiv Halbhavi B., 2019, J COMPUT MECH POWER, V2, P19, DOI [10.46253/jcmps.v2i3.a3, DOI 10.46253/JCMPS.V2I3.A3]
   Tang H, 2018, ELECTRON LETT, V54, P190, DOI 10.1049/el.2017.4346
   Tang H, 2018, IEEE SIGNAL PROC LET, V25, P239, DOI 10.1109/LSP.2017.2783350
   Tiwari K., 2016, PERSPECTIVESCI, V8, P475, DOI [10.1016/j.pisc.2016.06.004, DOI 10.1016/J.PISC.2016.06.004]
   Torabi M, 2018, SIGNAL PROCESS, V142, P457, DOI 10.1016/j.sigpro.2017.07.021
   Vijayarani R, 2016, PROCEDIA COMPUT SCI, V93, P624, DOI 10.1016/j.procs.2016.07.249
   Xu GZ, 2014, CHINA COMMUN, V11, P17, DOI 10.1109/CC.2014.6880457
   Xu LW, 2022, IEEE T IND INFORM, V18, P2063, DOI 10.1109/TII.2021.3082907
   Zhang JH, 2017, J SOUND VIB, V389, P153, DOI 10.1016/j.jsv.2016.11.006
   Zhu FQ, 2017, PHYS COMMUN-AMST, V25, P432, DOI 10.1016/j.phycom.2017.08.009
NR 32
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20909
EP 20929
DI 10.1007/s11042-023-16053-x
EA AUG 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001043063500002
DA 2024-07-18
ER

PT J
AU Sun, ZF
   Feng, R
   Fu, YW
AF Sun, Zhenfeng
   Feng, Rui
   Fu, Yanwei
TI Class-Incremental Generalized Zero-Shot Learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Zero-shot learning; Class-incremental learning
AB Zero-Shot Learning (ZSL) focuses on transferring knowledge learned from the source domain to the target domain. In the classic setting, test data only come from the target domain. Recently, a more reasonable setting GeneralizedZSL (G-ZSL) evaluates the model by recognizing instances from both the source and the target domain. However, G-ZSL still have some unrealistic assumptions. One of such hypotheses is the class-fixed setting: during the training time, G-ZSL algorithms only learn to recognize a fixed class set, and we cannot modify the target model unless retraining. The capacity of learning continuously and efficiently is crucial for learning algorithms in a real scenario. In this paper, we extend G-ZSL to a more realistic setting: instead of supposing the class-fixed training strategy, the incoming data come in the way of class-incremental order. In different learning episodes, disjoint groups of categories are utilized to train the G-ZSL models. As the training process goes on, the source domain is expanding. In such a Class-Incremental Generalized Zero-Shot Learning (CIG-ZSL) setting, learning algorithms are expected to not only transfer the learned knowledge to the target domain but also to remember the previously learned knowledge. We propose a Dual Path Learner (DPL) algorithm to validate the possibility of solving the CIG-ZSL task. Experiments on several benchmarks show that DPL has the capacity of remembering the knowledge learned from previous source instances and be able to migrate all the knowledge to the target domain as the expanding of the source domain.
C1 [Sun, Zhenfeng] Shanghai YOFO ROBOT Intelligent Technol Co Ltd, Shanghai 200433, Peoples R China.
   [Feng, Rui; Fu, Yanwei] Fudan Univ, Org, Shanghai 200433, Peoples R China.
C3 Fudan University
RP Sun, ZF (corresponding author), Shanghai YOFO ROBOT Intelligent Technol Co Ltd, Shanghai 200433, Peoples R China.
EM zf_sun@foxmail.com; fengrui@fudan.edu.cn; yanweifu@fudan.edu.cn
RI Fu, Yanwei/JTT-7059-2023
OI Fu, Yanwei/0000-0002-6595-6893
CR Akata Z, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2487986
   [Anonymous], 2018, LEARNING COMP RELATI
   Bendale A, 2015, PROC CVPR IEEE, P1893, DOI 10.1109/CVPR.2015.7298799
   BenDavid S, 1997, MACH LEARN, V29, P45, DOI 10.1023/A:1007465907571
   Candy P.C., 1991, Self-direction for Lifelong Learning
   Chao WL, 2016, LECT NOTES COMPUT SC, V9906, P52, DOI 10.1007/978-3-319-46475-6_4
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Felix R, 2018, LECT NOTES COMPUT SC, V11210, P21, DOI 10.1007/978-3-030-01231-1_2
   Field J., 2000, Lifelong learning, and the new educational order
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Fu YW, 2018, IEEE SIGNAL PROC MAG, V35, P112, DOI 10.1109/MSP.2017.2763441
   Fu YW, 2016, PROC CVPR IEEE, P5337, DOI 10.1109/CVPR.2016.576
   Fu YW, 2015, IEEE T PATTERN ANAL, V37, P2332, DOI 10.1109/TPAMI.2015.2408354
   Kankuekul P, 2012, PROC CVPR IEEE, P3657, DOI 10.1109/CVPR.2012.6248112
   Kingma D. P., 2015, P INT C LEARN REPR, P1, DOI DOI 10.1002/9781118900772.ETRDS0277
   Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Larochelle H., 2008, AAAI
   Liu SC, 2018, ADV NEUR IN, V31
   McCloskey M., 1989, PSYCHOL LEARN MOTIV, V24, P109, DOI [10.1016/S0079-7421(08)60536-8, DOI 10.1016/S0079-7421(08)60536-8]
   Mensink T, 2013, IEEE T PATTERN ANAL, V35, P2624, DOI 10.1109/TPAMI.2013.83
   Mensink T, 2012, LECT NOTES COMPUT SC, V7573, P488, DOI 10.1007/978-3-642-33709-3_35
   Norouzi M, 2014, Arxiv, DOI arXiv:1312.5650
   Parikh D, 2011, IEEE I CONF COMP VIS, P503, DOI 10.1109/ICCV.2011.6126281
   Patterson G, 2012, PROC CVPR IEEE, P2751, DOI 10.1109/CVPR.2012.6247998
   Pentina A, 2014, PR MACH LEARN RES, V32, P991
   Rebuffi SA, 2017, PROC CVPR IEEE, P5533, DOI 10.1109/CVPR.2017.587
   Rohrbach M, 2011, PROC CVPR IEEE, P1641, DOI 10.1109/CVPR.2011.5995627
   Ruvolo P., 2013, INT C MACH LEARN, P507
   Schlimmer J. C., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence, P496
   Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631, DOI DOI 10.1371/JOURNAL.PONE.0073791
   THRUN S, 1995, ROBOT AUTON SYST, V15, P25, DOI 10.1016/0921-8890(95)00004-Y
   Verma VK, 2018, PROC CVPR IEEE, P4281, DOI 10.1109/CVPR.2018.00450
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Xian YQ, 2018, PROC CVPR IEEE, P5542, DOI 10.1109/CVPR.2018.00581
   Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768
   Yu XD, 2010, LECT NOTES COMPUT SC, V6315, P127
NR 38
TC 0
Z9 0
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 3
PY 2023
DI 10.1007/s11042-023-16316-7
EA AUG 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O3BI7
UT WOS:001042601200009
DA 2024-07-18
ER

PT J
AU Durmus, D
   Güdükbay, U
   Ulusoy, O
AF Durmus, Duygu
   Gudukbay, Ugur
   Ulusoy, Ozgur
TI Learning visual similarity for image retrieval with global descriptors
   and capsule networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Neural networks; Capsule networks; Global descriptors;
   Image retrieval; Triplet loss; Cost-sensitive regularized cross-entropy
   loss
AB Finding matching images across large and unstructured datasets is vital in many computer vision applications. With the emergence of deep learning-based solutions, various visual tasks, such as image retrieval, have been successfully addressed. Learning visual similarity is crucial for image matching and retrieval tasks. Capsule Networks enable learning richer information that describes the object without losing the essential spatial relationship between the object and its parts. Besides, global descriptors are widely used for representing images. We propose a framework that combines the power of global descriptors and Capsule Networks by benefiting from the information of multiple views of images to enhance the image retrieval performance. The Spatial Grouping Enhance strategy, which enhances sub-features parallelly, and self-attention layers, which explore global dependencies within internal representations of images, are utilized to empower the image representations. The approach captures resemblances between similar images and differences between non-similar images using triplet loss and cost-sensitive regularized cross-entropy loss. The results are superior to the state-of-the-art approaches for the Stanford Online Products Database with Recall@K of 85.0, 94.4, 97.8, and 99.3, where K is 1, 10, 100, and 1000, respectively.
C1 [Durmus, Duygu; Gudukbay, Ugur; Ulusoy, Ozgur] Bilkent Univ, Dept Comp Engn, TR-06800 Ankara, Turkiye.
C3 Ihsan Dogramaci Bilkent University
RP Güdükbay, U (corresponding author), Bilkent Univ, Dept Comp Engn, TR-06800 Ankara, Turkiye.
RI Gudukbay, Ugur/F-1012-2011; Ulusoy, Ozgur/KVY-4530-2024
OI Gudukbay, Ugur/0000-0003-2462-6959; Ulusoy, Ozgur/0000-0002-6887-3778
CR Azizpour Hossein, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P36, DOI 10.1109/CVPRW.2015.7301270
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Bell S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766959
   Berman M, 2019, ABS190205509 CORR
   Bucher M, 2016, ABS160807441 CORR
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Dai ZZ, 2019, IEEE I CONF COMP VIS, P3690, DOI 10.1109/ICCV.2019.00379
   Galdran Adrian, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12265), P665, DOI 10.1007/978-3-030-59722-1_64
   Ge WF, 2018, LECT NOTES COMPUT SC, V11210, P272, DOI 10.1007/978-3-030-01231-1_17
   Gu Y, 2018, ABS181100202 CORR
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G.E., 2018, INT C LEARN REPR
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jun H. J., 2020, ARXIV
   Kalantidis Yannis, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P685, DOI 10.1007/978-3-319-46604-0_48
   Kapoor R, 2021, MULTIMED TOOLS APPL, V80, P29561, DOI 10.1007/s11042-021-11045-1
   Kayhan N, 2021, MULTIMED TOOLS APPL, V80, P32763, DOI 10.1007/s11042-021-11217-z
   Kim W, 2018, LECT NOTES COMPUT SC, V11205, P760, DOI 10.1007/978-3-030-01246-5_45
   Kingma D. P., 2014, arXiv
   Kinli F, 2019, IEEE INT CONF COMP V, P3109, DOI 10.1109/ICCVW.2019.00376
   Kosiorek Kosiorek A. A., 2019, P 33 C NEUR INF PROC, P15512
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Li X., 2019, ARXIV
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Melekhov I, 2016, INT C PATT RECOG, P378, DOI 10.1109/ICPR.2016.7899663
   Opitz M, 2017, IEEE I CONF COMP VIS, P5199, DOI 10.1109/ICCV.2017.555
   Ozcan B, 2020, ABS200704389 CORR
   Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ribeiro FD, 2020, AAAI CONF ARTIF INTE, V34, P3749
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sabour S, 2017, ADV NEUR IN, V30
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Sohn K, 2016, ADV NEUR IN, V29
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Sun W, 2021, ADV NEURAL INFORM PR, V34
   Sun YF, 2020, PROC CVPR IEEE, P6397, DOI 10.1109/CVPR42600.2020.00643
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tolias G., 2015, ARXIV151105879
   Wu CY, 2017, IEEE I CONF COMP VIS, P2859, DOI 10.1109/ICCV.2017.309
   Yandex Artem Babenko, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1269, DOI 10.1109/ICCV.2015.150
   Yuan YH, 2017, IEEE I CONF COMP VIS, P814, DOI 10.1109/ICCV.2017.94
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
NR 51
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20243
EP 20263
DI 10.1007/s11042-023-16164-5
EA JUL 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040925900008
DA 2024-07-18
ER

PT J
AU Zhong, YZ
   Tang, ZH
   Zhang, H
   Xie, YF
   Gao, XL
AF Zhong, Yuze
   Tang, Zhaohui
   Zhang, Hu
   Xie, Yongfang
   Gao, Xiaoliang
TI A froth image segmentation method via generative adversarial networks
   with multi-scale self-attention mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bubble size measurement; Froth flotation; Generative adversarial
   network; Self-attention mechanism; Semi-supervised learning
ID BUBBLE-SIZE; FLOTATION; ALGORITHM; DISTANCE
AB Froth image segmentation is the most popular method for bubble size measurement. However, in the froth flotation, froth images are with high-complexity and labeling the froth images with true bubble edges requires high human-labors and professional experiences. This causes that current convolutional neural network-based segmentation methods cannot segment well the bubbles accurately. Therefore, a generative adversarial network with multi-scale self-attention mechanism is proposed for froth image segmentation. First, to reduce the high requirements of true labeled samples, generative adversarial network was used in the framework to make the proposed segmentation model run in a self-supervised learning manner. Next, to strengthen the learning ability of the generator to detect bubble boundaries with different sizes, the receptive field is enlarged through the convolutional down-sampling operation and self-attention gating units are added to different layers. Finally, according to the output image of the generator, true labeled image and original input image, the discriminator outputs a confidence map to improve the parameters of generator and determines final edges. Many experiments were implemented to validate the effectiveness of the proposed method. Compared with other current convolutional neural network-based segmentation methods, the accuracy of the proposed model has been increased at least by 5%.
C1 [Zhong, Yuze; Tang, Zhaohui; Zhang, Hu; Xie, Yongfang; Gao, Xiaoliang] Cent South Univ, Sch Automat, Changsha 410083, Hunan, Peoples R China.
   [Zhang, Hu] Changsha Univ, Coll Comp Sci & Engn, Changsha 410022, Hunan, Peoples R China.
C3 Central South University; Changsha University
RP Zhang, H (corresponding author), Cent South Univ, Sch Automat, Changsha 410083, Hunan, Peoples R China.; Zhang, H (corresponding author), Changsha Univ, Coll Comp Sci & Engn, Changsha 410022, Hunan, Peoples R China.
EM zhanghu@csu.edu.cn
OI Zhong, Yuze/0009-0004-6902-6898; Zhang, Hu/0000-0002-6894-0926
FU National Natural Science Foundation of China (NSFC) [62171476,
   61771492]; China National Fund for Distinguished Young Scientists
   [61725306]; NSFC-Guangdong Joint Fund of Key Projects [U1701261]
FX AcknowledgementsThis work was supported in part by the National Natural
   Science Foundation of China (NSFC) under Grant 62171476 and Grant
   61771492, in part by the China National Fund for Distinguished Young
   Scientists under Grant 61725306, and in part by the NSFC-Guangdong Joint
   Fund of Key Projects under Grant U1701261.
CR Ai MX, 2020, NEURAL COMPUT APPL, V32, P14019, DOI 10.1007/s00521-020-04801-1
   Aldrich C, 2010, INT J MINER PROCESS, V96, P1, DOI 10.1016/j.minpro.2010.04.005
   An FP, 2021, MULTIMED TOOLS APPL, V80, P15017, DOI 10.1007/s11042-021-10515-w
   Ciresan D., 2012, NIPS, P2843
   Dharmalingham V, 2020, MULTIMED TOOLS APPL, V79, P10003, DOI 10.1007/s11042-019-07854-0
   Goodfellow JI, 2014, C NEURAL INFORM PROC, P19
   Hosseini MR, 2015, CHEM ENG COMMUN, V202, P911, DOI 10.1080/00986445.2014.886201
   Hung WC, 2018, ARXIV PREPRINT ARXIV
   Gulrajani I, 2017, ADV NEUR IN, V30
   Jahedsaravani A, 2014, MINER METALL PROC, V31, P66, DOI 10.1007/BF03402350
   Jovanovic I, 2015, MINER ENG, V84, P34, DOI 10.1016/j.mineng.2015.09.020
   Jovanovic I, 2015, MINER ENG, V70, P228, DOI 10.1016/j.mineng.2014.09.022
   Kalaivani S, 2020, MULTIMED TOOLS APPL, V79, P9145, DOI 10.1007/s11042-018-7126-7
   Liu JP, 2021, IEEE T CYBERNETICS, V51, P839, DOI 10.1109/TCYB.2020.2977537
   Liu JP, 2020, IEEE T INSTRUM MEAS, V69, P9618, DOI 10.1109/TIM.2020.3006629
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Meyer F, 2004, J MATH IMAGING VIS, V20, P59, DOI 10.1023/B:JMIV.0000011319.21884.39
   MEYER F, 1994, SIGNAL PROCESS, V38, P113, DOI 10.1016/0165-1684(94)90060-4
   Mnih V., 2014, ARXIV, p1406.6247
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Pu YY, 2020, NEURAL COMPUT APPL, V32, P13639, DOI 10.1007/s00521-020-04773-2
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shean BJ, 2011, INT J MINER PROCESS, V100, P57, DOI 10.1016/j.minpro.2011.05.002
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Xu B., 2015, arXiv
   Yang H, 2021, IEEE SENS J, V21, P11469, DOI 10.1109/JSEN.2020.3016458
   Yang J, 2017, REMOTE SENS ENVIRON, V190, P137, DOI 10.1016/j.rse.2016.12.011
   Zhang H, 2023, IEEE T IND ELECTRON, V70, P11819, DOI 10.1109/TIE.2022.3227274
   Zhang H, 2022, IEEE T IND INFORM, V18, P2539, DOI 10.1109/TII.2021.3092361
   Zhang H, 2021, MINER ENG, V160, DOI 10.1016/j.mineng.2020.106677
   Zhang H, 2020, IEEE T IND INFORM, V16, P4077, DOI 10.1109/TII.2019.2960051
   Zhang H, 2019, MEASUREMENT, V138, P182, DOI 10.1016/j.measurement.2019.02.005
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
NR 33
TC 0
Z9 0
U1 5
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19663
EP 19682
DI 10.1007/s11042-023-16397-4
EA JUL 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040586800003
DA 2024-07-18
ER

PT J
AU Sagar, D
   Reddy, MS
AF Sagar, D.
   Reddy, M. Saidi
TI A brief review on security issues and counter measure techniques for
   future generation communication system (LTE/LTE-A)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Review; Security issues; Counter measure techniques; Future generation;
   Communication system; (LTE; LTE-a)
ID KEY AGREEMENT PROTOCOL; HANDOVER AKA PROTOCOL; GROUP BASED EFFICIENT;
   DATA-COLLECTION; LTE; AUTHENTICATION; NETWORKS; MANAGEMENT; M2M;
   ARCHITECTURE
AB The article addresses the issue of current and critical protections for applications for 4G and 5G mobile phones. The objective of the article is to provide an overview of the threats to 4G and 5G mobile communication networks and to analyze the variables used in conjunction with core and security methods. The research work uses a review of the literature to provide an overview of the threats to 4G and 5G mobile communication networks. The research also analyzed the variables used in conjunction with core and security methods. The research presents an overview of the threats to 4G and 5G mobile communication networks, including privacy attacks, behavioral attacks, space attacks, and authentication attacks. The authors also provide an overview of three types of cases, including road signs, officers, and road signs. The analysis of variables used in conjunction with core and security methods is unclear, often summarizing security. The authors conclude that there is a need for improved protections for applications for 4G and 5G mobile phones. They also suggest that further research is needed to better understand the variables used in conjunction with core and security methods.
C1 [Sagar, D.] SRRS Govt Polytech, Sircilla, Telangana, India.
   [Reddy, M. Saidi] KL Univ, Dept Comp Sci & Engn, Hyderabad, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Sagar, D (corresponding author), SRRS Govt Polytech, Sircilla, Telangana, India.
EM dasarisagar2021@gmail.com
OI malgireddy, saidireddy/0000-0003-0760-6227
CR 3GPP, DEL PUBL SAF COMM IT
   Agiwal M, 2016, IEEE COMMUN SURV TUT, V18, P1617, DOI 10.1109/COMST.2016.2532458
   Ahmad A, 2023, MOBILE NETW APPL, V28, P1, DOI [10.1099/mic.0.000823, 10.1007/s11036-019-01355-y]
   Al-Hourani A, 2013, 2013 7TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION SYSTEMS (ICSPCS)
   Alavikia Z, 2018, WIREL NETW, V24, P1, DOI 10.1007/s11276-016-1310-3
   Althumali H, 2018, IEEE ACCESS, V6, P74961, DOI 10.1109/ACCESS.2018.2883440
   [Anonymous], 2015, NGMN 5G White Paper
   Araniti G, 2013, IEEE COMMUN MAG, V51, P148, DOI 10.1109/MCOM.2013.6515060
   Ashraf E., 2017, INT J COMPUT APPL, V163, P5
   Aziz F. M., 2019, ARXIV
   Aziz FM, 2017, IEEE T VEH TECHNOL, V66, P7422, DOI 10.1109/TVT.2017.2672682
   Aziz FM, 2015, 2015 IEEE 26TH ANNUAL INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE RADIO COMMUNICATIONS (PIMRC), P1344, DOI 10.1109/PIMRC.2015.7343507
   Barros S, 2016, IEEE LATAMER CONF
   Baskaran SBM, 2017, IEEE ACCESS, V5, P21977, DOI 10.1109/ACCESS.2017.2758646
   Bayhan S, 2019, PERVASIVE MOB COMPUT, V56, P71, DOI 10.1016/j.pmcj.2019.04.002
   Bista A, 2015, THESIS U AGDER
   Butun I, 2020, IEEE COMMUN SURV TUT, V22, P616, DOI 10.1109/COMST.2019.2953364
   Cao J, 2014, IEEE COMMUN SURV TUT, V16, P283, DOI 10.1109/SURV.2013.041513.00174
   Cao Jin, 2013, Journal of China Universities of Posts and Telecommunications, V20, P106, DOI 10.1016/S1005-8885(13)60036-9
   Carreras A, 2018, WIRELESS PERSONAL
   Chang C.-Y., 2016, Proc. 2016 ACM the Workshop on Mobility in the Evolving Internet Architecture, P13
   Chung J, 2020, IEEE IC COMP COM NET, DOI 10.1109/icccn49398.2020.9209669
   de Andrade TPC, 2016, IEEE INTERNET THINGS, V3, P366, DOI 10.1109/JIOT.2016.2557240
   Doumi T, 2013, IEEE COMMUN MAG, V51, P106, DOI 10.1109/MCOM.2013.6461193
   El-Mashed MG, 2015, WIRELESS PERS COMMUN, V80, P751, DOI 10.1007/s11277-014-2039-x
   Elsaadany M, 2017, IEEE COMMUN SURV TUT, V19, P2544, DOI 10.1109/COMST.2017.2728013
   Favraud R, 2015, IEEE MILIT COMMUN C, P695, DOI 10.1109/MILCOM.2015.7357525
   Feki S, 2017, P INT C WIR NETW MOB, P27
   Ferrag MA, 2018, J NETW COMPUT APPL, V101, P55, DOI 10.1016/j.jnca.2017.10.017
   Ferrús R, 2014, IEEE VEH TECHNOL MAG, V9, P47, DOI 10.1109/MVT.2014.2333695
   Fortes S, 2015, IEEE COMMUN MAG, V53, P294, DOI 10.1109/MCOM.2015.7010548
   Fu AM, 2017, WIREL NETW, V23, P2165, DOI 10.1007/s11276-016-1277-0
   Fu AM, 2016, SECUR COMMUN NETW, V9, P2002, DOI 10.1002/sec.1455
   Fu YL, 2020, J NETW COMPUT APPL, V155, DOI 10.1016/j.jnca.2020.102549
   Gao Y, 2016, IEEE INTERNET THINGS, V3, P1135, DOI 10.1109/JIOT.2016.2562140
   Ghavimi F, 2015, IEEE COMMUN SURV TUT, V17, P525, DOI 10.1109/COMST.2014.2361626
   Ghubaish A, M2M COMMUNICATION SC
   Giluka MK, 2018, WIRELESS PERS COMMUN, V103, P1791, DOI 10.1007/s11277-018-5881-4
   Gódor G, 2015, COMPUT NETW, V76, P17, DOI 10.1016/j.comnet.2014.10.016
   Gomez K, 2014, COMMUNICATIONS MAGAZ
   Gonzalez DG, 2014, METAHEURISTIC BASED
   Gupta S, 2019, PEER PEER NETW APPL, V12, P989, DOI 10.1007/s12083-018-0703-8
   Gupta S, 2018, WIRELESS PERS COMMUN, V103, P2317, DOI 10.1007/s11277-018-5912-1
   Gupta S, 2018, WIRELESS PERS COMMUN, V98, P2867, DOI 10.1007/s11277-017-5005-6
   Hamandi K, 2017, COMPUT COMMUN, V98, P20, DOI 10.1016/j.comcom.2016.09.009
   Hashim HA, 2019, COMPUT NETW, V157, P78, DOI 10.1016/j.comnet.2019.04.009
   He LM, 2018, IEEE ACCESS, V6, P4220, DOI 10.1109/ACCESS.2018.2792534
   Henrydoss J, 2014, 2014 IEEE ASIA PACIFIC CONFERENCE ON WIRELESS AND MOBILE, P194, DOI 10.1109/APWiMob.2014.6920286
   Hoymann C, 2012, COMMUNICATIONS MAGAZ
   Järvinen K, 2010, COMPUT COMMUN, V33, P1916, DOI 10.1016/j.comcom.2010.04.019
   Jiang B, 2021, IEEE INTERNET THINGS, V8, P10430, DOI 10.1109/JIOT.2021.3057419
   Jover RP, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-7
   Jyothi K. Krishna, 2020, International Journal of Cloud Computing, V9, P258
   Kasmi O., 2017, ADV SCI TECHNOLOGY E, V2, P658, DOI DOI 10.25046/aj020384
   Kim D., 2020, ARXIV
   Kralevska K, 2019, EPIC SERIES COMPUTIN, P44
   Labib M, 2015, 2015 IEEE CONFERENCE ON STANDARDS FOR COMMUNICATIONS AND NETWORKING (CSCN), P315, DOI 10.1109/CSCN.2015.7390464
   Lee YL, 2017, WIRELESS PERS COMMUN, V92, P565, DOI 10.1007/s11277-016-3557-5
   Li QH, 2010, IEEE COMMUN MAG, V48, P86, DOI 10.1109/MCOM.2010.5458368
   Lichtman M, 2016, IEEE COMMUN MAG, V54, P54, DOI 10.1109/MCOM.2016.7452266
   Lin HQ, 2019, J NETW COMPUT APPL, V126, P88, DOI 10.1016/j.jnca.2018.11.002
   Liu YX, 2022, IEEE INTERNET THINGS, V9, P298, DOI 10.1109/JIOT.2021.3099028
   Liyanage M, 2012, IEEE VTS VEH TECHNOL
   Ma R, 2019, PPSHA PRIVACY PRESER
   Ma RH, 2019, AD HOC NETW, V87, P49, DOI 10.1016/j.adhoc.2018.11.012
   Mar Benediktsson B, 2019, CHANNEL BASED INTRUS
   Misic J, 2017, IEEE NETWORK, V31, P63, DOI 10.1109/MNET.2017.1600134
   Muhammad M, 2018, VEH COMMUN
   Mumtaz G, SECURITY THREATS COG
   Pandey P, 2022, J KING SAUD UNIV-COM, V34, P1730, DOI 10.1016/j.jksuci.2019.11.003
   Parne BL, 2019, PEER PEER NETW APPL, V12, P1156, DOI 10.1007/s12083-019-00785-5
   Parne BL, 2018, IEEE ACCESS, V6, P3668, DOI 10.1109/ACCESS.2017.2788919
   Qureshi KN, 2021, NEURAL COMPUT APPL, V33, P10637, DOI 10.1007/s00521-020-04900-z
   Rupprecht D, 2019, P IEEE S SECUR PRIV, P1121, DOI 10.1109/SP.2019.00006
   Salami R, 2006, IEEE COMMUN MAG, V44, P90, DOI 10.1109/MCOM.2006.1637952
   Salman EH, 2017, TELECOMMUN SYST, V65, P215, DOI 10.1007/s11235-016-0221-z
   Sanchez PA, 2020, COMPUT NETW
   Saqib, SEGHAS SECURE EFFICI
   Sesia S., 2009, UMTS LONG TERM EVOLU
   Shaik A, 2018, WISEC'18: PROCEEDINGS OF THE 11TH ACM CONFERENCE ON SECURITY & PRIVACY IN WIRELESS AND MOBILE NETWORKS, P75, DOI 10.1145/3212480.3212497
   Singh G, 2019, SECURE EFFICIENT INT
   Singh G, 2018, WIRELESS PERS COMMUN, V101, P829, DOI 10.1007/s11277-018-5719-0
   Singh G, 2018, SADHANA-ACAD P ENG S, V43, DOI 10.1007/s12046-018-0891-1
   Song H, 2017, INTELL DAT CENT SYST, P1
   Sridevi B., 2015, INT J EL COMP ENG SY, V1, P1
   Sui Y, 2013, COMMUNICATIONS MAGAZ
   Tandiya N, 2018, IEEE INT CONF COMM
   Vallati C, 2015, 2015 IEEE 2ND WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P585, DOI 10.1109/WF-IoT.2015.7389119
   Wang C, 2018, SECURITY COMMUNICATI, V2018
   Wang J, 2021, IEEE AERO EL SYS MAG, V36, P4, DOI 10.1109/MAES.2020.3015537
   Wang J, 2014, INT J SECUR APPL, V8, P17, DOI 10.14257/ijsia.2014.8.4.02
   Xu C, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/6251219
   Yuan Yifei., 2013, LTE-Advanced Relay Technology and Standardization
   Zhou JH, 2019, IEEE ACCESS, V7, P28319, DOI 10.1109/ACCESS.2019.2901548
NR 94
TC 0
Z9 0
U1 5
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19327
EP 19368
DI 10.1007/s11042-023-16187-y
EA JUL 2023
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001037130000003
DA 2024-07-18
ER

PT J
AU Sümbül, H
   Yüzer, AH
AF Sumbul, Harun
   Yuzer, Ahmet Hayrettin
TI Design of a fuzzy input expert system visual information interface for
   classification of apnea and hypopnea
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Apnea; Hypopnea; Fuzzy; Expert systems; Rule base; Medical interface
ID SLEEP-APNEA; LOGIC; EVENTS; DIAGNOSIS
AB In this study, a Fuzzy input Expert System (FES) is developed to detect the patients' PSG results to linguistic statements (apnea-hypopnea). All of the randomly selected 1318 PSG data taken from 15 patients (12 males (80%) and three females (20%)) from St. Vincent University Hospital / University College Dublin Sleep Apnea Database were studied and applied to the FES model. It is understood from the literature that three signals (airflow, SpO(2), and Rib movements) are the primary indicators of apnea and hypopnea. Thus, this study's three important parameters were chosen as input variables to classify the apnea-hypopnea in this study. The output variable DIS (disease) was defined as A (Apnea) and H (Hypopnea). A rule base (consisting of 75 rules) was created using membership functions in the light of AASM's 2012 scoring criteria and an expert's opinion. Since it is the most preferred method, this study uses the center-of-gravity/area (centroid) method for defuzzification. The limit values for each fuzzy expression were created. These parameters were symbolically classified. Membership functions and the degree of the membership function were defined. 231 apnea and 1029 hypopnea events have been successfully detected at 97.5% and 95.2%, respectively. A confusion matrix has been formed for calculating the performances of FES, and accuracy was found to be 97.5%. An interface program was developed using Matlab Graphical User Interface programming language, where some sample results were checked. Thus, results have been converted into understandable linguistic expressions. It can be said that the detection performance of the system developed is good by looking at the results of the correct detection. It is shown that detecting apnea and hypopnea using FES are reliable, consistent, and successful results and helps doctors make quick and reliable diagnoses without any risks.
C1 [Sumbul, Harun] Ondokuz Mayis Univ, Yesilyurt DC Vocat Sch, Samsun, Turkiye.
   [Yuzer, Ahmet Hayrettin] Karabuk Univ, Dept Elect & Elect Engn, Karabuk, Turkiye.
C3 Ondokuz Mayis University; Karabuk University
RP Sümbül, H (corresponding author), Ondokuz Mayis Univ, Yesilyurt DC Vocat Sch, Samsun, Turkiye.
EM harun.sumbul@omu.edu.tr; hayrettinyuzer@karabuk.edu.tr
RI SUMBUL, Harun/AAB-8440-2021
OI SUMBUL, Harun/0000-0001-5135-3410
CR Abdel-Mageed F. Z., 2012, Proceedings of the 2012 29th National Radio Science Conference (NRSC), P691, DOI 10.1109/NRSC.2012.6208584
   Al-Ashmouny KM, 2005, P ANN INT IEEE EMBS, P6132, DOI 10.1109/IEMBS.2005.1615893
   Allam E, 2010, FUZZY INF ENG, V2, P361, DOI 10.1007/s12543-010-0056-3
   Alvarez-Estevez Diego, 2015, Sleep Disord, V2015, P237878, DOI 10.1155/2015/237878
   Alvarez-Estévez D, 2009, EXPERT SYST APPL, V36, P7778, DOI 10.1016/j.eswa.2008.11.043
   archive.physionet.org, 2021, ST VINC U HOSP U COL
   Avci C, 2015, BIO-MED MATER ENG, V26, pS1703, DOI 10.3233/BME-151470
   Baboli M, 2015, IEEE MICROW MAG, V16, P34, DOI 10.1109/MMM.2015.2419771
   Basciftci F., 2010, E J NEW WORLD SCI AC, V5, P463
   Basciftci F., 2011, BOOK SER LECT NOTES, V55, P27
   Basçiftçi F, 2013, MED BIOL ENG COMPUT, V51, P1287, DOI 10.1007/s11517-013-1096-8
   Basçiftçi F, 2012, J MED SYST, V36, P2187, DOI 10.1007/s10916-011-9684-3
   Bi WH, 2022, MULTIMED TOOLS APPL, V81, P11127, DOI 10.1007/s11042-022-12232-4
   Biswas A, 2014, BIOL RHYTHM RES, V45, P955, DOI 10.1080/09291016.2014.939442
   Cabrero-Canosa M, 2003, EXPERT SYST APPL, V24, P335, DOI 10.1016/S0957-4174(02)00184-7
   Cade BE, 2020, AM J RESP CRIT CARE, V202, P1462, DOI 10.1164/rccm.202006-2252LE
   Chatterjee S, 2019, J EXP THEOR ARTIF IN, V31, P369, DOI 10.1080/0952813X.2018.1552315
   Choi B, 2017, MULTIMED TOOLS APPL, V76, P24819, DOI 10.1007/s11042-016-4329-7
   Ciolek M, 2015, IEEE J BIOMED HEALTH, V19, P418, DOI 10.1109/JBHI.2014.2325997
   Dheeba J, 2017, J EXP THEOR ARTIF IN, V29, P1011, DOI 10.1080/0952813X.2017.1280088
   Ding H, 2010, BIOL RHYTHM RES, V41, P235, DOI 10.1080/09291011003687999
   Dursunoglu N., 2014, G NCEL G S HASTAL KL, V2, P159, DOI [10.5152/gghs.2014.0004, DOI 10.5152/GGHS.2014.0004]
   Erdenebayar U, 2019, COMPUT METH PROG BIO, V180, DOI 10.1016/j.cmpb.2019.105001
   Glos M, 2018, J CLIN SLEEP MED, V14, P359, DOI 10.5664/jcsm.6978
   Gögüs FZ, 2020, TRAIT SIGNAL, V37, P145, DOI 10.18280/ts.370201
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Gutiérrez-Tobal GC, 2016, IEEE T BIO-MED ENG, V63, P636, DOI 10.1109/TBME.2015.2467188
   Hayano J, 2011, IEEE ENG MED BIO, P7731, DOI 10.1109/IEMBS.2011.6091905
   Hou LM, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING (ICALIP), P89, DOI 10.1109/ICALIP.2016.7846595
   Jané R, 2011, IEEE ENG MED BIO, P8331, DOI 10.1109/IEMBS.2011.6092054
   Javaid AQ, 2015, 2015 IEEE 14TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P837, DOI 10.1109/ICMLA.2015.79
   Jin JY, 2015, IEEE T BIOMED CIRC S, V9, P96, DOI 10.1109/TBCAS.2014.2314301
   Kagawa M, 2014, 2014 IEEE Healthcare Innovation Conference (HIC), P99, DOI 10.1109/HIC.2014.7038884
   Kaimakamis E, 2009, IEEE ENG MED BIO, P3465, DOI 10.1109/IEMBS.2009.5334605
   Kim J, 2016, IEEE ENG MED BIO, P3199, DOI 10.1109/EMBC.2016.7591409
   Koley BL, 2013, IEEE T BIO-MED ENG, V60, P3354, DOI 10.1109/TBME.2013.2282337
   Kunhimangalam R, 2013, BIOMED RES INT, V2013, DOI 10.1155/2013/846780
   Limbu N, 2022, MULTIMED TOOLS APPL, V81, P38569, DOI 10.1007/s11042-022-13142-1
   Lin YY, 2017, IEEE J BIOMED HEALTH, V21, P1533, DOI 10.1109/JBHI.2016.2636778
   Morgenthaler TI, 2006, SLEEP, V29, P1203, DOI 10.1093/sleep/29.9.1203
   Mostafa SS, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19224934
   Oh TK, 2021, BMC PULM MED, V21, DOI 10.1186/s12890-020-01387-1
   Przystup P, 2013, C HUM SYST INTERACT, P513, DOI 10.1109/HSI.2013.6577874
   Qian K, 2019, ANN BIOMED ENG, V47, P1000, DOI 10.1007/s10439-019-02217-0
   Rosenwein T, 2015, IEEE ENG MED BIO, P7688, DOI 10.1109/EMBC.2015.7320173
   Dell'Aquila CR, 2020, J MED BIOL ENG, V40, P555, DOI 10.1007/s40846-020-00549-0
   Sabil A, 2019, J CLIN SLEEP MED, V15, P285, DOI 10.5664/jcsm.7634
   Sabil A, 2019, SLEEP BREATH, V23, P1169, DOI 10.1007/s11325-019-01793-8
   Sakai M, 2013, 2013 INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P971, DOI 10.1109/SITIS.2013.157
   Sargano AB, 2020, MULTIMED TOOLS APPL, V79, P30653, DOI 10.1007/s11042-020-09381-9
   Saritas I, 2010, EXPERT SYST APPL, V37, P6646, DOI 10.1016/j.eswa.2010.03.056
   Sumbul H., 2011, 2011 International Symposium on Innovations in Intelligent Systems and Applications (INISTA 2011), P432, DOI 10.1109/INISTA.2011.5946111
   Tian JY, 2005, P ANN INT IEEE EMBS, P2571, DOI 10.1109/IEMBS.2005.1616994
   Van Steenkiste T, 2019, IEEE J BIOMED HEALTH, V23, P2354, DOI 10.1109/JBHI.2018.2886064
   Vaquerizo-Villar F, 2018, PHYSIOL MEAS, V39, DOI 10.1088/1361-6579/aae66a
   Várady P, 2002, IEEE T BIO-MED ENG, V49, P936, DOI 10.1109/TBME.2002.802009
   Waltisberg D, 2017, IEEE J BIOMED HEALTH, V21, P930, DOI 10.1109/JBHI.2016.2549938
   Wu YX, 2015, BIOL RHYTHM RES, V46, P161, DOI 10.1080/09291016.2014.963948
   Xie BL, 2012, IEEE T INF TECHNOL B, V16, P469, DOI 10.1109/TITB.2012.2188299
   Yüzer AH, 2020, IRBM, V41, P39, DOI 10.1016/j.irbm.2019.10.007
   Yüzer AH, 2020, APPL ACOUST, V163, DOI 10.1016/j.apacoust.2020.107225
   ZADEH LA, 1983, FUZZY SET SYST, V11, P199, DOI 10.1016/S0165-0114(83)80081-5
   Zoroglu C, 2017, J COGN SYST, V2, P37
NR 63
TC 0
Z9 0
U1 5
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 21133
EP 21152
DI 10.1007/s11042-023-16152-9
EA JUL 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001037378900007
DA 2024-07-18
ER

PT J
AU Lee, W
   Son, G
AF Lee, Wonyoung
   Son, Guiyoung
TI Investigation of human state classification via EEG signals elicited by
   emotional audio-visual stimulation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Emotion recognition; Electroencephalogram (EEG); Support vector machine
   (SVM); Long short term memory (LSTM); Deep learning
ID MODEL
AB EEG-based classification from human states is still challenging in human-computer interaction (HCI). Since it reflects brain activity directly, electroencephalography (EEG) has significant advantages in emotion classification research. This study recorded EEG signals from 12 participants while they perceived emotional audio-visual stimulation movie clips for four minutes. The six emotions studied were anger, excitement, fear, happiness, sadness, and a neutral state. We also perform raw data preprocessing to obtain clean data, extracting the power spectrum using Fast Fourier Transform (FFT) to generate feature vectors. In addition, we conduct extensive experiments to validate the classification of human states using subject-independent machine-learning techniques. As a result, the LSTM network achieved the highest classification accuracy of 81.46% for six emotional states, while the SVM network achieved only 68.64%. In addition, we achieved 82.89% accuracy in the Bi-LSTM network with two layers when applying the deep learning methods to different layers. In conclusion, extensive experiments were conducted on our collected dataset. Experimental results indicate that the LSTM network, a time-sequence-related model, has superior classification results of 82.89% than other methods. It also shows that the long duration of EEG signals is crucial for detecting the emotional state changes of various subject types, including individual subjects and cross-subjects. In future research, we will investigate multiple evaluation experiments utilizing deep learning models or propose novel EEG-based emotion classification features to improve the accuracy of emotion classification.
C1 [Lee, Wonyoung] LG CNS, AI Engn Team, 71 Magokjungang 8 Ro, Seoul 07795, South Korea.
   [Son, Guiyoung] Sejong Univ, Dept Software, 209 Neungdong Ro, Seoul 05009, South Korea.
C3 Sejong University
RP Son, G (corresponding author), Sejong Univ, Dept Software, 209 Neungdong Ro, Seoul 05009, South Korea.
EM sgy1017@sejong.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2022R1I1A1A01053144]
FX AcknowledgementsThis research was supported by Basic Science Research
   Program through the National Research Foundation of Korea (NRF), funded
   by the Ministry of Education (grant number) (NRF-2022R1I1A1A01053144).
CR Acharya D, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207280
   Anubhav, 2020, 2020 16TH IEEE INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2020), P88, DOI [10.1109/CSPA48992.2020.9068691, 10.1109/cspa48992.2020.9068691]
   Bartlett M, 1996, ADV NEURAL INFORM PR, V9
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Chen T, 2020, MEASUREMENT, V164, DOI 10.1016/j.measurement.2020.108047
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Craik A, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/ab0ab5
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Du XB, 2022, IEEE T AFFECT COMPUT, V13, P1528, DOI 10.1109/TAFFC.2020.3013711
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Hefron RG, 2017, PATTERN RECOGN LETT, V94, P96, DOI 10.1016/j.patrec.2017.05.020
   Hongpei Xu, 2019, 2019 IEEE International Conference on Robotics and Biomimetics (ROBIO), P2528, DOI 10.1109/ROBIO49542.2019.8961740
   Hosseini MP, 2021, IEEE REV BIOMED ENG, V14, P204, DOI 10.1109/RBME.2020.2969915
   Islam MR, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104757
   Javaid MM., 2015, INT C NEUR INF PROC
   Maria E, 2019, ELECTRON NOTES THEOR, V343, P35, DOI 10.1016/j.entcs.2019.04.009
   Mehmood RM, 2015, IEEE INT CONF MULTI
   Moon SE, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2556, DOI 10.1109/ICASSP.2018.8461315
   Paszke A, 2019, ADV NEUR IN, V32
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Salzman CD, 2010, ANNU REV NEUROSCI, V33, P173, DOI 10.1146/annurev.neuro.051508.135256
   Wang ZM, 2019, IEEE ACCESS, V7, P143303, DOI 10.1109/ACCESS.2019.2944273
   Yang H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19214736
   Zhao GZ, 2018, FRONT BEHAV NEUROSCI, V12, DOI 10.3389/fnbeh.2018.00225
   Zheng WL, 2015, IEEE T AUTON MENT DE, V7, P162, DOI 10.1109/TAMD.2015.2431497
NR 27
TC 1
Z9 1
U1 6
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUL 22
PY 2023
DI 10.1007/s11042-023-16294-w
EA JUL 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA N1JS0
UT WOS:001034665300004
DA 2024-07-18
ER

PT J
AU Yao, HB
   Luo, YK
   Zhang, Z
   Yang, JH
   Cai, CT
AF Yao, Haibo
   Luo, Yongkang
   Zhang, Zhi
   Yang, Jianhang
   Cai, Chengtao
TI Hierarchical Attention Networks for Fact-based Visual Question Answering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fact-based Visual Question Answering; Hierarchical attention networks;
   Self-attention; Multiple attention interaction; Positional encoding
ID RECOMMENDATION SYSTEM; GRAPH
AB Fact-based Visual Question Answering (FVQA) aims to answer questions with images and facts. It requires a fine-grained and simultaneous understanding visual content, textual questions, and factual knowledge. We propose a novel Hierarchical Attention Network (HANet) for FVQA to address the limitations of existing methods. Most existing FVQA methods only consider external facts as a library of answers, which weakens the role of the external facts, and ignore information from images, questions, and external knowledge. Additionally, they only utilize appearance features of images and disregard position information, which results in a model failing to answer many complex questions, due to the absence of important information in images. Our proposed model considers FVQA as a triple modal interaction task and exploits self-attention and multiple attention interaction to make full use of information from all three modalities. In specific, we introduce three attention modules: Self-Attention Layer, Triple-modal Attention Layer, and Bi-Attention Layer to sufficiently extract useful information from images, questions, facts. Furthermore, we also introduce positional encoding into image embedding acquisition to further improve performance of the model. Our proposed method achieves state-of-the-art performance on the FVQA dataset, with top-3 accuracy of 85.98% and top-1 accuracy of 71.68%.
C1 [Yao, Haibo; Zhang, Zhi; Yang, Jianhang; Cai, Chengtao] Harbin Engn Univ, Coll Intelligent Syst Sci & Engn, Harbin 150001, Peoples R China.
   [Luo, Yongkang] Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.
C3 Harbin Engineering University; Chinese Academy of Sciences; Institute of
   Automation, CAS
RP Zhang, Z (corresponding author), Harbin Engn Univ, Coll Intelligent Syst Sci & Engn, Harbin 150001, Peoples R China.
EM yhb1667662807@hrbeu.edu.cn; yongkang.luo@ia.ac.cn;
   zhangzhi1981@hrbeu.edu.cn; 2015041328@hrbeu.edu.cn;
   caichengtao@hrbeu.edu.cn
FU National Key R amp;D Program of China [2019YFE0105400]
FX AcknowledgementsThis work was supported by National Key R &D Program of
   China (2019YFE0105400).
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bao H. B., 2022, ARXIV
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhatti UA, 2018, HUM VACC IMMUNOTHER, V14, P165, DOI 10.1080/21645515.2017.1379639
   Bordes A., 2013, P 26 INT C NEURAL IN, P2787
   Gardères F, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P489
   Goel R, 2020, AAAI CONF ARTIF INTE, V34, P3988
   Guo YY, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P2061, DOI 10.1145/3503161.3547870
   Gupta S, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P378
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jenatton R, 2012, ADV NEURAL INFORM PR, P3167
   Krishnamurthy Jayant., 2013, Transactions of the Association for Computational Linguistics, V1, P193, DOI DOI 10.1162/TACLA00220
   Li H, 2019, PROC CVPR IEEE, P6312, DOI 10.1109/CVPR.2019.00648
   Li J., 2022, INT C MACHINE LEARNI
   Li JX, 2022, IEEE T CYBERNETICS, V52, P873, DOI 10.1109/TCYB.2020.2988093
   Lin YK, 2015, AAAI CONF ARTIF INTE, P2181
   Liu LP, 2022, KNOWL-BASED SYST, V237, DOI 10.1016/j.knosys.2021.107650
   Liu S, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3069056
   Malaviya C, 2020, AAAI CONF ARTIF INTE, V34, P2925
   Marino K, 2021, PROC CVPR IEEE, P14106, DOI 10.1109/CVPR46437.2021.01389
   Narasimhan K., 2016, ARXIV160307954, P2355, DOI [10.18653/v1/D16-1261, DOI 10.18653/V1/D16-1261]
   Narasimhan M, 2018, ADV NEUR IN, V31
   Narasimhan M, 2018, LECT NOTES COMPUT SC, V11212, P460, DOI 10.1007/978-3-030-01237-3_28
   Nickel M., 2011, P 28 INT C MACH LEAR, V11, P3104482, DOI 10.5555/3104482.3104584
   Nickel M, 2016, AAAI CONF ARTIF INTE, P1955
   Peng L, 2022, IEEE T PATTERN ANAL, V44, P318, DOI 10.1109/TPAMI.2020.3004830
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Rammnath K, 2020, ARXIV
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Salemi A, 2023, ARXIV
   Speer R, 2017, AAAI CONF ARTIF INTE, P4444
   Tandon N, 2014, WSDM'14: PROCEEDINGS OF THE 7TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P523, DOI 10.1145/2556195.2556245
   Vaswani Ashish, 2017, Advances in Neural Information Processing Systems (NeurIPS), V17, P6000, DOI DOI 10.48550/ARXIV.1706.03762
   Wang P, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1290
   Wang P, 2018, IEEE T PATTERN ANAL, V40, P2413, DOI 10.1109/TPAMI.2017.2754246
   Wang W., 2022, ARXIV
   Wang Z, 2014, AAAI CONF ARTIF INTE, P1112
   Wu JL, 2022, AAAI CONF ARTIF INTE, P2712
   Wu Q, 2016, PROC CVPR IEEE, P4622, DOI 10.1109/CVPR.2016.500
   Wu XX, 2023, INT J COMPUT VISION, V131, P1073, DOI 10.1007/s11263-023-01752-7
   Yang B, 2014, P INT C LEARNING REP
   Yu J, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107563
   Yu Z, 2019, PROC CVPR IEEE, P6274, DOI 10.1109/CVPR.2019.00644
   Zhang SL, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P3019
   Zhu Y, 2015, ARXIV
   Zhu ZH, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1097
NR 52
TC 0
Z9 0
U1 6
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17281
EP 17298
DI 10.1007/s11042-023-16151-w
EA JUL 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001034665300003
DA 2024-07-18
ER

PT J
AU Liu, Y
   Li, ZX
   Huan, Z
   Zhou, BW
   Shen, SY
   Gao, S
AF Liu, Yan
   Li, Zhixin
   Huan, Zhan
   Zhou, Bangwen
   Shen, Shiyi
   Gao, Shan
TI Daily unbalanced action recognition based on active learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action recognition; Wearable sensor; Imbalanced data; Active
   learning
AB The identification of daily activities is mainly limited by the imbalanced number of actions and the diversity of categories, which can lead to unsatisfactory classification results and difficult annotation. In this paper, a novel model is proposed to efficiently solve the mentioned problems. The model fully considers the characteristics of sample imbalance and uses the combination of Synthetic Minority Oversampling Technique and K-means clustering undersampling to achieve data balancing. After that, Active Learning is applied to query the most representative samples for labeling to reduce data annotation. Experiments show that the proposed method can balance the number of samples without increasing the computational cost of the system. Compared with the original data, the proposed model can learn the features of each class more fully after the samples are balanced, increasing the F1-score by 23%, and it can reduce the sample annotations by nearly 30% without reducing the recognition results.
C1 [Liu, Yan; Zhou, Bangwen] Changzhou Univ, Sch Comp & Artificial Intelligence, Sch Big Data, Changzhou 213164, Peoples R China.
   [Li, Zhixin; Huan, Zhan; Shen, Shiyi; Gao, Shan] Changzhou Univ, Sch Microelect & Control Engn, Changzhou 213164, Peoples R China.
C3 Changzhou University; Changzhou University
RP Huan, Z (corresponding author), Changzhou Univ, Sch Microelect & Control Engn, Changzhou 213164, Peoples R China.
EM hzh@cczu.edu.cn
RI Wang, Ling/KBA-9814-2024
OI Wang, Ling/0000-0003-0272-2974; Huan, Zhan/0000-0002-8093-5513
FU National Natural Science Foundation of China [61772248]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61772248. The project name is Sensing Theory and Key
   Technologies of Big Behavioral Data for Wearable Computing.
   (Corresponding author: Zhan Huan).
CR Adaimi Rebecca, 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3351228
   Akbari A, 2020, IEEE J BIOMED HEALTH, V24, P2639, DOI 10.1109/JBHI.2020.2966151
   Arafat MY, 2017, I C SOFTWARE KNOWL I
   Arafeh M, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON SMART AND SUSTAINABLE TECHNOLOGIES (SPLITECH), P208, DOI [10.23919/splitech.2019.8783092, 10.1109/skima47702.2019.8982391]
   Bengar JZ, 2021, IEEE INT CONF COMP V, P1631, DOI 10.1109/ICCVW54120.2021.00188
   Bengar Javad Zolfaghari, 2022, P IEEE CVF WINT APPL, P1536
   Bi HX, 2021, IEEE J BIOMED HEALTH, V25, P922, DOI 10.1109/JBHI.2020.3013403
   Buda M, 2018, NEURAL NETWORKS, V106, P249, DOI 10.1016/j.neunet.2018.07.011
   Bulling A, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2499621
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen KX, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3447744
   Chen ZH, 2020, IEEE T INSTRUM MEAS, V69, P3992, DOI 10.1109/TIM.2019.2945467
   Choi J, 2021, PROC CVPR IEEE, P6745, DOI 10.1109/CVPR46437.2021.00668
   Cipolla E, 2017, LECT NOTES COMPUT SC, V10484, P435, DOI 10.1007/978-3-319-68560-1_39
   Cosma G., 2020, 2020 INT C COMPUTING, P1, DOI [10.1109/IJCNN48605.2020.9207697, DOI 10.1109/ICCIT-144147971.2020.9213708]
   Elsts A, 2020, J NETW COMPUT APPL, V168, DOI 10.1016/j.jnca.2020.102770
   Gao G, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21237791
   Guo SK, 2019, NEURAL PROCESS LETT, V50, P1503, DOI 10.1007/s11063-018-9940-3
   Hamad RA., 2020, SN Comput. Sci., V1, P1, DOI DOI 10.1007/S42979-020-00211-1
   Ho SS, 2008, IEEE T PATTERN ANAL, V30, P1557, DOI 10.1109/TPAMI.2007.70811
   Huan Z, 2021, IEEE SENS J, V21, P6440, DOI 10.1109/JSEN.2020.3039865
   Huan Z, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/6471532
   Huan Z, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124328
   Ijaz MF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102809
   Ijaz MF, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8081325
   Janicka M, 2019, INT J AP MAT COM-POL, V29, P769, DOI 10.2478/amcs-2019-0057
   Koziarski M, 2020, KNOWL-BASED SYST, V204, DOI 10.1016/j.knosys.2020.106223
   Koziarski M, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107262
   Kumar Y, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03612-z
   Kwon H, 2019, IEEE INT SYM WRBL CO, P109, DOI 10.1145/3341163.3347744
   Lewis D. D., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P3
   Liu M, 2021, INFORM SCIENCES, V556, P160, DOI 10.1016/j.ins.2020.12.058
   Malki Z., 2020, COMPUT INF SCI, V13, P40, DOI [10.5539/cis.v13n3p40, DOI 10.5539/CIS.V13N3P40]
   Narasimman, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2101.04859
   Nekooeimehr I, 2016, EXPERT SYST APPL, V46, P405, DOI 10.1016/j.eswa.2015.10.031
   Oh S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082760
   Pruengkarn R, 2017, LECT NOTES COMPUT SC, V10638, P67, DOI 10.1007/978-3-319-70139-4_7
   Ramanujam E, 2021, IEEE SENS J, V21, P13029, DOI 10.1109/JSEN.2021.3069927
   Song J, 2016, 2016 IEEE/ACIS 15TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS), P1155
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Taherkhani A, 2019, ADV INTELL SYST COMP, V857, P203, DOI 10.1007/978-3-030-01177-2_15
   Twomey N, 2016, ARXIV, DOI DOI 10.48550/ARXIV.1603.00797
   Woznowski P., 2017, DESIGNING DEV FACILI, P315, DOI [DOI 10.1007/978-3-319-44924-1_14, 10.1007/978-3-319-44924-1_14]
   Wu DG, 2016, NEUROCOMPUTING, V190, P35, DOI 10.1016/j.neucom.2015.11.095
   Xie WH, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/3526539
   Zhao JK, 2020, KNOWL-BASED SYST, V203, DOI 10.1016/j.knosys.2020.106087
NR 46
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16255
EP 16274
DI 10.1007/s11042-023-16181-4
EA JUL 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001030536100006
DA 2024-07-18
ER

PT J
AU Rafati, M
   Kalantari, N
   Azadbakht, J
   Nickfarjam, AM
   Hosseini, F
AF Rafati, Mehravar
   Kalantari, Nadia
   Azadbakht, Javid
   Nickfarjam, Ali Mohammad
   Hosseini, Farahnaz
TI Performance evaluation of fuzzy genetic, fuzzy particle swarm and
   similar insects' optimization algorithms on denoising problem based on
   novel combined filter for digital X-ray and CT images in Pelvic Region
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pelvic Region; Poisson Noise; Anscombe Transformation; Bio-Inspired
   Optimization Algorithms; Insects'-Inspired Optimization Algorithms
ID ANT COLONY OPTIMIZATION; NOISE REMOVAL; ANSCOMBE TRANSFORMATION; QUALITY
   ASSESSMENT; OPTIMAL INVERSION; MEDICAL IMAGES; DOSE REDUCTION;
   CLASSIFICATION
AB This study proposes a novel combined filter accompanied with different optimization algorithms for Poisson noise reduction and increases image quality in digital X-ray and CT images. This filter uses 4th-order PDE, TV, Bayes shrink threshold with optimization algorithms and an exact unbiased inverse of generalized Anscombe transformation (EUIGAT). Experiments were conducted on the basis of displaying the influence of denoising filter on 105 simulated, 102 radiographic and 102 CT images of individuals aged 20-70 years old; 53 men and 49 women. Experimental results demonstrated the lowest value for MSE and the highest values for PSNR, IQI, SSIM, FOM and CNR in different kinds of kernels and images compared with the other fuzzy Bio-inspired algorithms. The results showed proposed method helps physicians and orthopedists in order to enhance their performances in treating injuries of the pelvic region such as acetabulum fossa and head and neck femur bone.
C1 [Rafati, Mehravar; Kalantari, Nadia] Kashan Univ Med Sci, Sch Allied Med Sci, Dept Med Phys & Radiol, Kashan, Iran.
   [Azadbakht, Javid] Kashan Univ Med Sci, Radiol Dept, Kashan, Iran.
   [Nickfarjam, Ali Mohammad] Kashan Univ Med Sci, Sch Allied Med Sci, Dept Hlth Informat Management & Technol, Kashan, Iran.
   [Nickfarjam, Ali Mohammad] Kashan Univ Med Sci, Hlth Informat Management Res Ctr, Kashan, Iran.
   [Hosseini, Farahnaz] Univ Kashan, Fac Elect & Comp Engn, Dept Comp Engn, Kashan, Iran.
C3 University Kashan
RP Nickfarjam, AM (corresponding author), Kashan Univ Med Sci, Sch Allied Med Sci, Dept Hlth Informat Management & Technol, Kashan, Iran.; Nickfarjam, AM (corresponding author), Kashan Univ Med Sci, Hlth Informat Management Res Ctr, Kashan, Iran.
EM afshin_rft@yahoo.com; nadiakalantari71@gmail.com;
   javidazadbkht2@gmail.com; nickfarjam-a@kaums.ac.ir;
   farahnazhosseini@grad.kashanu.ac.ir
CR Abdulameer AT., 2018, I ALHAITHAM J PURE A, V31, P268, DOI [10.30526/31.1.1834, DOI 10.30526/31.1.1834]
   Abualigah L, 2021, PROCESSES, V9, DOI 10.3390/pr9071155
   Ahirwal MK, 2014, DIGIT SIGNAL PROCESS, V25, P164, DOI 10.1016/j.dsp.2013.10.019
   Al Shalabi L., 2006, Journal of Computer Sciences, V2, P735, DOI 10.3844/jcssp.2006.735.739
   Alzyoud K, 2018, J MED IMAGING RADIAT, V49, P316, DOI 10.1016/j.jmir.2018.04.025
   Anoop V, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1370-x
   Anutam R., 2014, Int. J. Multimed. Its Appl, V6, P35, DOI [10.5121/ijma.2014.6303, DOI 10.5121/IJMA.2014.6303]
   Aravindan TE, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1069-4
   Arora S., 2018, Sage Handbook of Nature, P1
   Borges LR, 2016, MED PHYS, V43, P2704, DOI 10.1118/1.4948502
   Cao X, 2017, WORLD J ENG TECHNOL, P90, DOI DOI 10.4236/WJET.2017.51008
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P231, DOI 10.1109/83.902288
   Chauhan N, 2018, INT J FUZZY LOG INTE, V18, P175, DOI 10.5391/IJFIS.2018.18.3.175
   Chetan S., 2017, J BIOMED ENG MED IMA, V4, P1
   Chikhalekar AT., 2016, INT RES ENG TECHNOL, V3, P1364
   commoncrawl, About us
   Dabov K, 2006, PROC SPIE, V6064, DOI 10.1117/12.643267
   Thanh DNH, 2019, INFORM-INT J COMPUT, V43, P151, DOI 10.31449/inf.v43i2.2179
   Das S., 2009, INT J COMPUT SCI SEC, V3, P105
   Djellali C, 2017, PROCEDIA COMPUT SCI, V109, P448, DOI 10.1016/j.procs.2017.05.305
   Djenouri Y, 2019, INFORM SCIENCES, V496, P363, DOI 10.1016/j.ins.2018.07.020
   Fan LW, 2019, VIS COMPUT IND BIOME, V2, DOI 10.1186/s42492-019-0016-7
   Fan ZY, 2013, INT J FUTUR GENER CO, V6, P147, DOI 10.14257/ijfgcn.2013.6.5.14
   Fujii M, 2016, RADIOLOGY, V281, P933, DOI 10.1148/radiol.2016151657
   Ganji MF, 2011, EXPERT SYST APPL, V38, P14650, DOI 10.1016/j.eswa.2011.05.018
   Ghosh P, 2016, NEUROCOMPUTING, V195, P181, DOI 10.1016/j.neucom.2015.09.123
   Godil SS., 2011, SURG NEUROL INT, V9, P1
   GOPALAKRISHNAN RC, 2014, COMPUT MATH METHODS, P1
   Gudmundsson M, 1998, IEEE T MED IMAGING, V17, P469, DOI 10.1109/42.712136
   Hadayzadeh R, 2010, 18 IRANIAN C ELECT E, P1
   Hajiaboli MR, 2011, INT J COMPUT VISION, V92, P177, DOI 10.1007/s11263-010-0330-1
   Hariya Y., 2015, INT S NONLINEAR THEO, V1, P724, DOI DOI 10.34385/PROC.47.B4L-E-3
   Hosseinian S, 2016, INT ARCH PHOTOGRAMM, V41, P835, DOI 10.5194/isprsarchives-XLI-B5-835-2016
   Houssein EH, 2021, NEURAL COMPUT APPL, V33, P16899, DOI 10.1007/s00521-021-06273-3
   Iravani Rad MA, 2017, C MECH ENG, P1
   Izonin I, 2019, LECT NOTES COMPUT SC, V11506, P467, DOI 10.1007/978-3-030-20521-8_39
   Jang JS, 2018, PHYS MEDICA, V50, P46, DOI 10.1016/j.ejmp.2018.05.007
   Janny Shabu SL., 2018, BIOMED RES-TOKYO, V29, P2932, DOI DOI 10.4066/BIOMEDICALRESEARCH.29-18-799
   Kalyani C., 2018, INT J APPL ENG RES, V13, P4989
   Karaboga D, 2008, APPL SOFT COMPUT, V8, P687, DOI 10.1016/j.asoc.2007.05.007
   Karthikeyan K., 2011, INT J COMPUT APPL, V2, P8, DOI DOI 10.5120/2614-3646
   Kaur S., 2016, INT J COMPUT APPL, V145, P15, DOI DOI 10.5120/IJCA2016910867
   Kaushik P., 2018, INT J ELECT COMMUN E, V11, P31
   Khan KB, 2016, IEEE INT CONF INTELL, P301, DOI 10.1109/INTELSE.2016.7475138
   Khanian Maryam, 2014, J Med Signals Sens, V4, P72
   Khmag A., 2013, INT J ADV TRENDS COM, V2, P1
   KHURSHEED S, 2014, ADV STUD BIOL, V6, P181
   Kirti T, 2017, SADHANA-ACAD P ENG S, V42, P855, DOI 10.1007/s12046-017-0654-4
   Kiruthigha K, 2017, RES J PHARM BIOL CHE, V8, P757
   Kockanat S., 2013, Proc. of the International Symposium on Innovation in Intelligent Systems and Applications (INISTA), P1
   Kumar M, 2021, IEEE T SUSTAIN COMPU
   Kumar M, 2020, NEURAL COMPUT APPL, V32, P12103, DOI 10.1007/s00521-019-04266-x
   Kumar M, 2019, J NETW COMPUT APPL, V143, P1, DOI 10.1016/j.jnca.2019.06.006
   Kumar N., 2010, INT J ADV RES COMPUT, V3, P636
   Lambora A., 2019, 2019 INT C MACH LEAR, P380, DOI [DOI 10.1109/COMITCON.2019.8862255, 10.1109/COMITCON.2019.8862255, 10.1109/COMITCon.2019.8862255]
   Lee SC, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072068
   Lee WA, 2016, AM J SPORT MED, V44, P67, DOI 10.1177/0363546515612083
   Li M., 2014, MATH PROBL ENG, V2014, P1, DOI [DOI 10.1155/2014/434972, 10.1155/2014/434972]
   Li Y., 2007, ELECT COMM JPN, V90, P508
   Li YJ, 2019, J INF TECHNOL RES, V12, P89, DOI 10.4018/JITR.2019010107
   Lim Seung-Jae, 2015, Hip Pelvis, V27, P125, DOI 10.5371/hp.2015.27.3.125
   LOVE LA, 1987, MED PHYS, V14, P178, DOI 10.1118/1.596126
   Luisier F, 2011, IEEE T IMAGE PROCESS, V20, P696, DOI 10.1109/TIP.2010.2073477
   Maini R., 2009, Int J Image Process, V3, P1
   Mäkitalo M, 2013, IEEE T IMAGE PROCESS, V22, P91, DOI 10.1109/TIP.2012.2202675
   Mäkitalo M, 2011, IEEE T IMAGE PROCESS, V20, P99, DOI 10.1109/TIP.2010.2056693
   Mirjalili S, 2016, NEURAL COMPUT APPL, V27, P495, DOI 10.1007/s00521-015-1870-7
   Muniyappan S, 2019, MULTIMED TOOLS APPL, V78, P6487, DOI 10.1007/s11042-018-6355-0
   Nader E., 2008, Applied Mathematical Sciences, V2, P981
   Nair R., 2018, INT J COMPUT APPL, V179, P27
   Nie Q, 2021, MOBILE NETW APPL, V26, P404, DOI 10.1007/s11036-020-01675-4
   Nikpour M, 2010, IET IMAGE PROCESS, V4, P452, DOI 10.1049/iet-ipr.2009.0180
   Ostojic VS., 2018, TELFOR J, V10, P26, DOI [10.5937/telfor1801026O, DOI 10.5937/TELFOR1801026O]
   Oulhaj H, 2012, INT CONF MULTIMED, P344, DOI 10.1109/ICMCS.2012.6320218
   Pan QK, 2014, KNOWL-BASED SYST, V62, P69, DOI 10.1016/j.knosys.2014.02.021
   Pan XQ, 2019, NEURAL COMPUT APPL, V31, P1445, DOI 10.1007/s00521-018-3449-6
   Parpinelli RS, 2002, IEEE T EVOLUT COMPUT, V6, P321, DOI 10.1109/TEVC.2002.802452
   Pereira DC, 2014, COMPUT METH PROG BIO, V114, DOI 10.1016/j.cmpb.2014.01.014
   Rafati M, 2018, BIOCYBERN BIOMED ENG, V38, P941, DOI 10.1016/j.bbe.2018.08.005
   Rafati M, 2016, IET COMPUT VIS, V10, P1, DOI 10.1049/iet-cvi.2014.0151
   Rafati M, 2015, IRAN RED CRESCENT ME, V17, DOI 10.5812/ircmj.25013
   Rafati M, 2014, IRAN RED CRESCENT ME, V16, DOI 10.5812/ircmj.14658
   Ragesh NK, 2011, INT J ARTIF INTELL E, V12, P67
   Rahman CM, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/9293617
   ROSENFEL.A, 1966, J ACM, V13, P471
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Saremi S, 2017, ADV ENG SOFTW, V105, P30, DOI 10.1016/j.advengsoft.2017.01.004
   Semchedine M, 2017, ROM J INF SCI TECH, V20, P271
   Sharma S., 2016, INT RES ADV, V3, P56
   Shen WH, 2021, INVERSE PROBL IMAG, V15, P1333, DOI 10.3934/ipi.2020057
   Simone G, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.1.013006
   Sivakumar R., 2010, MULTISCALE FILTER DI, V2, P514, DOI 10.7763/IJET.2010.V2.174
   Stem ES, 2006, SKELETAL RADIOL, V35, P385, DOI 10.1007/s00256-006-0086-4
   Stolojescu-Crisan C, 2013, ADV ELECTR COMPUT EN, V13, P85, DOI 10.4316/AECE.2013.03014
   Sun L, 2015, COMPLEXITY, P1
   Thakur KV, 2016, INT C COMM COMP VIS, P9
   varnan C.Sasi., 2011, IJCST, V2
   Veeramuthu A, 2017, BIOMEDICAL RES 2017, VI, P152
   Wang L, 2008, ELECTR ENG JPN, V163, P37, DOI 10.1002/eej.20486
   Wang X, 2004, 2004 IEEE CONFERENCE ON ROBOTICS, AUTOMATION AND MECHATRONICS, VOLS 1 AND 2, P991
   Wang Z, 2002, IEEE IMAGE PROC, P477
   Xue W, 2021, UNET BASED FULLY AUT
   Yang XS, 2018, STUD COMPUT INTELL, V744, P245, DOI 10.1007/978-3-319-67669-2_11
   Yousif Aballah YM., 2011, CAN J MED, V2, P38
   Yousif Aballah YM., 2014, INT J SCI RES, V3, P1771
   Zhang Y, 2015, METALL MINING IND, P745
   Zhao R, 2019, INT J INNOV COMPUT I, V15, P1967, DOI 10.24507/ijicic.15.05.1967
NR 107
TC 2
Z9 2
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 15483
EP 15531
DI 10.1007/s11042-023-15341-w
EA JUL 2023
PG 49
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001026771300001
DA 2024-07-18
ER

PT J
AU Yu, X
   Ren, ZY
   Guttery, DS
   Zhang, YD
AF Yu, Xiang
   Ren, Zeyu
   Guttery, David S.
   Zhang, Yu-Dong
TI DF-dRVFL: A novel deep feature based classifier for breast mass
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast mass classification; Deep learning; Transfer learning; ELM;
   RVFLN; SNN
ID NEURAL-NETWORKS
AB Amongst all types of cancer, breast cancer has become one of the most common cancers in the UK threatening millions of people's health. Early detection of breast cancer plays a key role in timely treatment for morbidity reduction. Compared to biopsy, which takes tissues from the lesion for further analysis, image-based methods are less time-consuming and pain-free though they are hampered by lower accuracy due to high false positivity rates. Nevertheless, mammography has become a standard screening method due to its high efficiency and low cost with promising performance. Breast mass, as the most palpable symptom of breast cancer, has received wide attention from the community. As a result, the past decades have witnessed the speeding development of computer-aided systems that are aimed at providing radiologists with useful tools for breast mass analysis based on mammograms. However, the main issues of these systems include low accuracy and require enough computational power on a large scale of datasets. To solve these issues, we developed a novel breast mass classification system called DF-dRVFL. On the public dataset DDSM with more than 3500 images, our best model based on deep random vector functional link network showed promising results through five-cross validation with an averaged AUC of 0.93 and an average accuracy of 81.71%. Compared to sole deep learning based methods, average accuracy has increased by 0.38. Compared with the state-of-the-art methods, our method showed better performance considering the number of images for evaluation and the overall accuracy.
C1 [Yu, Xiang; Ren, Zeyu; Zhang, Yu-Dong] Univ Leicester, Sch Comp & Math Sci, Univ Rd, Leicester LE1 7RH, England.
   [Guttery, David S.] Univ Leicester, Leicester Canc Res Ctr, Univ Rd, Leicester LE2 7LX, England.
C3 University of Leicester; University of Leicester
RP Zhang, YD (corresponding author), Univ Leicester, Sch Comp & Math Sci, Univ Rd, Leicester LE1 7RH, England.
EM yudongzhang@ieee.org
RI Ren, Zeyu/GYU-3257-2022; Zhang, Yudong/I-7633-2013
OI Ren, Zeyu/0000-0003-2303-5663; 
FU Medical Research Council Confidence in Concept Award, UK [MC_PC_17171];
   Royal Society International Exchanges Cost Share Award, UK [RP202G0230];
   British Heart Foundation Accelerator Award, UK [AA/18/3/34220]; Hope
   Foundation for Cancer Research, UK [RM60G0680]; Global Challenges
   Research Fund (GCRF), UK [P202PF11]; Sino-UK Industrial Fund, UK
   [RP202G0289]; LIAS, UK [P202ED10, P202RE969]; Data Science Enhancement
   Fund, UK [P202RE237]; Fight for Sight, UK [24NN201]; Sino-UK Education
   Fund, UK [OP202006]; Biotechnology and Biological Sciences Research
   Council (BBSRC), UK [RM32G0178B8]
FX This paper is partially supported by Medical Research Council Confidence
   in Concept Award, UK (MC_PC_17171); Royal Society International
   Exchanges Cost Share Award, UK (RP202G0230); British Heart Foundation
   Accelerator Award, UK (AA/18/3/34220); Hope Foundation for Cancer
   Research, UK (RM60G0680); Global Challenges Research Fund (GCRF), UK
   (P202PF11); Sino-UK Industrial Fund, UK (RP202G0289); LIAS, UK (P202ED10
   and P202RE969); Data Science Enhancement Fund, UK (P202RE237); Fight for
   Sight, UK (24NN201); Sino-UK Education Fund, UK (OP202006);
   Biotechnology and Biological Sciences Research Council (BBSRC), UK
   (RM32G0178B8)
CR [Anonymous], 2017, Proceedings of the 5th international conference on bioinformatics and computational biology
   BassettLW MI, 2000, HOLLAND FREI CANC ME
   Chen X, 2021, AUTOPHAGY, V17, P2054, DOI 10.1080/15548627.2020.1810918
   Chen XL, 2021, PROC CVPR IEEE, P15745, DOI 10.1109/CVPR46437.2021.01549
   Cheng G, 2023, SCI CHINA INFORM SCI, V66, DOI 10.1007/s11432-021-3493-7
   Dhahri H, 2020, BIOMED RES INT, V2020, DOI 10.1155/2020/7638969
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Gerstner W., 2002, SPIKING NEURON MODEL, DOI DOI 10.1017/CBO9780511815706
   Grill J.-B., 2020, arXiv, V33, P21271
   Hakim L, 2017, BAGGING BASED ENSEMB, P670
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heath M, 1998, COMP IMAG VIS, V13, P457
   HODGKIN AL, 1952, J PHYSIOL-LONDON, V117, P500, DOI 10.1113/jphysiol.1952.sp004764
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   IGELNIK B, 1995, IEEE T NEURAL NETWOR, V6, P1320, DOI 10.1109/72.471375
   Izhikevich EM, 2006, NEURAL COMPUT, V18, P245, DOI 10.1162/089976606775093882
   Kasabov N, 2013, NEURAL NETWORKS, V41, P188, DOI 10.1016/j.neunet.2012.11.014
   Keyvanpour MR, 2022, SIGNAL IMAGE VIDEO P, V16, P481, DOI 10.1007/s11760-021-01989-0
   Khan HN, 2019, IEEE ACCESS, V7, P165724, DOI 10.1109/ACCESS.2019.2953318
   Kheradpisheh SR, 2018, NEURAL NETWORKS, V99, P56, DOI 10.1016/j.neunet.2017.12.005
   Kim S, 2020, AAAI CONF ARTIF INTE, V34, P11270
   Kulkarni Sujata, 2022, Proceedings of the 2nd International Conference on Recent Trends in Machine Learning, IoT, Smart Cities and Applications: ICMISC 2021. Lecture Notes in Networks and Systems (237), P773, DOI 10.1007/978-981-16-6407-6_66
   Lee RS, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.177
   Levy D, 2016, ARXIV
   Li H, 2019, BIOMED SIGNAL PROCES, V51, P347, DOI 10.1016/j.bspc.2019.02.017
   Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167
   LOU M, 2021, MULTIMED TOOLS APPL, P1
   Maass W, 1997, NEURAL NETWORKS, V10, P1659, DOI 10.1016/S0893-6080(97)00011-7
   Masquelier T, 2007, PLOS COMPUT BIOL, V3, P247, DOI 10.1371/journal.pcbi.0030031
   Mridha MF, 2021, CANCERS, V13, DOI 10.3390/cancers13236116
   Muramatsu C, 2020, COMPUT BIOL MED, V119, DOI 10.1016/j.compbiomed.2020.103698
   Navega D, 2015, INT J LEGAL MED, V129, P1145, DOI 10.1007/s00414-014-1050-9
   NHS, 2023, BREAST CANC WOM
   Niu J, 2021, MED PHYS, V48, P3878, DOI 10.1002/mp.14942
   O'Connor P, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00178
   Oakden-Rayner L, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180089
   Panda P, 2016, IEEE IJCNN, P299, DOI 10.1109/IJCNN.2016.7727212
   PAO YH, 1992, INT J CONTROL, V56, P263, DOI 10.1080/00207179208934315
   Patil R, 2023, MECH ADV MATER STRUC, V30, P3588, DOI 10.1080/15376494.2022.2079030
   Ragab DA, 2019, PEERJ, V7, DOI 10.7717/peerj.6201
   Rampun A., 2018, 2018 IEEE 20 INT C E, P1
   Ren ZY, 2022, TECHNOL CANCER RES T, V21, DOI 10.1177/15330338221124372
   Ruta D., 2005, Information Fusion, V6, P63, DOI 10.1016/j.inffus.2004.04.008
   Sengupta A, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00095
   Shi QS, 2021, PATTERN RECOGN, V117, DOI 10.1016/j.patcog.2021.107978
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song K, 2022, IEEE T PATTERN ANAL, V44, P4591, DOI 10.1109/TPAMI.2021.3073587
   Suckling J., 2015, MAMMOGRAPHIC IMAGE A, DOI 10.250394
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Taherkhani A, 2020, NEURAL NETWORKS, V122, P253, DOI 10.1016/j.neunet.2019.09.036
   Vaswani A, 2017, ADV NEUR IN, V30
   Weedon-Fekjær H, 2014, BMJ-BRIT MED J, V348, DOI 10.1136/bmj.g3701
   Zhang Q, 2020, J ADV TRANSPORT, V2020, DOI 10.1155/2020/9496259
NR 55
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14393
EP 14422
DI 10.1007/s11042-023-15864-2
EA JUL 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001027813700005
PM 38283725
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Lv, XW
   Wang, R
   Zheng, CY
   Yang, QC
   Wang, ZX
   Nie, J
AF Lv, Xiaowei
   Wang, Rui
   Zheng, Chengyu
   Yang, Qicheng
   Wang, Zhaoxin
   Nie, Jie
TI Multi-representation decoupled joint network for semantic segmentation
   of remote sensing images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Graph convolution; Multi-representation; Decoupling module; Three-way
   information interaction; Remote sensing image; Semantic segmentation
ID LAND-COVER
AB In recent years, semantic segmentation has become an important means of processing remote sensing images, and it is widely used in various fields such as natural disaster detection, environmental protection, and land resource management. In response to this, the mainstream method of the deep convolutional network is constantly innovating and iterating. However, previous methods usually do not fully exploit the information associations between different representations, and the information of low-level representations is usually not well applied. In response to this, we propose a multi-representation decoupled joint network (MDJN) based on a three-branch architecture to improve the performance of semantic segmentation on remote sensing images, which utilizes multi-representation decoupling (MRD) to decouple the original single-branch network into the main branch, body branch and edge branch to enhance information fusion for different representations. Specifically, based on representation learning, we first propose a cross-representation graph convolution (CGC) module to fully mine and learn the context information between different representations with the help of graph convolutional networks (GCN). Secondly, we propose a new three-branch information interaction (TII) module to perform three-way interaction for the information of the three branches, so that the intra-class consistency and inter-class expressivity between different representations can fully play a role. The mean intersection over union (mIoU) of MDJN reaches 78.19% and 81.26% respectively on on both International Society for Photogrammetry and Remote Sensing (ISPRS) Vaihingen and Potsdam datasets.
C1 [Lv, Xiaowei; Wang, Rui; Zheng, Chengyu; Yang, Qicheng; Wang, Zhaoxin; Nie, Jie] Ocean Univ China, Fac Informat Sci & Engn, 238 Songling Rd, Qingdao 266100, Peoples R China.
C3 Ocean University of China
RP Nie, J (corresponding author), Ocean Univ China, Fac Informat Sci & Engn, 238 Songling Rd, Qingdao 266100, Peoples R China.
EM lvxiaowei@stu.ouc.edu.cn; wangrui1585@stu.ouc.edu.cn;
   zhengchengyu@stu.ouc.edu.cn; yqc@stu.ouc.edu.cn;
   wangzhaoxin@stu.ouc.edu.cn; niejie@ouc.edu.cn
RI Nie, Jie/ABG-9228-2021; Wang, Huiyan/JXW-9178-2024
OI Nie, Jie/0000-0003-4952-7666; 
FU National Natural Science Foundation of China [62072418, 62172376]; Major
   Scientific and Technological Innovation Project of Shandong
   [2019JZZY020705]; Fundamental Research Funds for the Central
   Universities [202042008]
FX AcknowledgementsThis work was supported in part by the National Natural
   Science Foundation of China(62072418, 62172376); the Major Scientific
   and Technological Innovation Project of Shandong (2019JZZY020705); the
   Fundamental Research Funds for the Central Universities (202042008).
CR Ao Chen, 2020, Pattern Recognition and Computer Vision. Third Chinese Conference, PRCV 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12305), P734, DOI 10.1007/978-3-030-60633-6_61
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2021, IEEE PHOTONICS J, V13, DOI 10.1109/JPHOT.2021.3059703
   Bhatti UA, 2020, IEEE ACCESS, V8, P155783, DOI 10.1109/ACCESS.2020.3018544
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bruna J., 2014, ABS13126203 CORR, P1, DOI [10.48550/arXiv.1312.6203, DOI 10.48550/ARXIV.1312.6203]
   Chaurasia A, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen YP, 2019, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2019.00052
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Chong Y, 2020, IEEE GEOSCI REMOTE S
   Defferrard M, 2016, ADV NEUR IN, V29
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gilmer J, 2017, PR MACH LEARN RES, V70
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu XX, 2019, IEEE IMAGE PROC, P1440, DOI [10.1109/ICIP.2019.8803025, 10.1109/icip.2019.8803025]
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Kipf TN, 2016, ARXIV
   Li R, 2021, ISPRS J PHOTOGRAMM, V181, P84, DOI 10.1016/j.isprsjprs.2021.09.005
   Liang X., 2018, Advances in Neural Information Processing Systems, V31
   Lin D, 2020, IEEE T CYBERNETICS, V50, P1120, DOI 10.1109/TCYB.2018.2885062
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Minghao Yin, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P191, DOI 10.1007/978-3-030-58555-6_12
   Niu RG, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3065112
   Nogueira K, 2019, IEEE T GEOSCI REMOTE, V57, P7503, DOI 10.1109/TGRS.2019.2913861
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rottensteiner F., 2014, ISPRS, V1, P4
   Sulla-Menashe D, 2019, REMOTE SENS ENVIRON, V222, P183, DOI 10.1016/j.rse.2018.12.013
   Takikawa T, 2019, IEEE I CONF COMP VIS, P5228, DOI 10.1109/ICCV.2019.00533
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Xiangtai Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P435, DOI 10.1007/978-3-030-58520-4_26
   Xie EZ, 2021, ADV NEUR IN, V34
   Yuan YH, 2021, INT J COMPUT VISION, V129, P2375, DOI 10.1007/s11263-021-01465-9
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang C, 2020, REMOTE SENS ENVIRON, V237, DOI 10.1016/j.rse.2019.111593
   Zhang C, 2019, REMOTE SENS ENVIRON, V221, P173, DOI 10.1016/j.rse.2018.11.014
   Zhang F, 2019, IEEE I CONF COMP VIS, P6797, DOI 10.1109/ICCV.2019.00690
   Zhang JH, 2014, ISPRS J PHOTOGRAMM, V94, P102, DOI 10.1016/j.isprsjprs.2014.04.023
   Zhang JM, 2021, IEEE INT CONF COMP V, P1760, DOI 10.1109/ICCVW54120.2021.00202
   Zhang XL, 2020, IEEE T CYBERNETICS, V50, P3855, DOI 10.1109/TCYB.2020.2992433
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11207, P418, DOI 10.1007/978-3-030-01219-9_25
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhen M., 2020, IEEE C COMPUT VIS PA, P13666, DOI DOI 10.48550/ARXIV.2004.07684
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zhong Z., 2020, P IEEE CVF C COMP VI, P13065, DOI DOI 10.1109/CVPR42600.2020.01308
   Zhu Z, 2019, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2019.00068
NR 51
TC 0
Z9 0
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13291
EP 13313
DI 10.1007/s11042-023-15660-y
EA JUL 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001023897700006
DA 2024-07-18
ER

PT J
AU Sun, HQ
   Han, JG
   Pang, YW
   Li, XL
AF Sun, Hanqing
   Han, Jungong
   Pang, Yanwei
   Li, Xuelong
TI Supervised biadjacency networks for stereo matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stereo matching; Convolutional neural networks; Bipartite graph;
   Supervision; Disparity
ID NET
AB Convolutional neural network (CNN) based stereo matching methods using cost volume techniques have gained prominence in stereo matching. State-of-the-art cost volume based methods use two weight-sharing feature extractors to respectively extract left and right unary features and then use them to construct cost volume(s). The quality of those unary features is crucial for the subsequent stereo matching. We propose a Supervised Biadjacency-based (SuperB) module to improve their quality by employing supervised biadjacency matrices to embed stereo information into both unary features. Specifically, disparity supervision is imposed on the biadjacency matrices by transforming them into disparity estimations. The SuperB Module can therefore adaptively enhance matched features and suppress unmatched features. Being aware of the stereo correspondence, the resultant stereo-aware features are more discriminative for subsequent cost aggregation and disparity estimation. Experiments show the SuperB Module can be plugged into cost volume based stereo matching models and lower the disparity estimation error. In addition, a scale-adaptive Voxel-wise Selective Fusion (VSF) module is proposed to adaptively aggregate the multi-scale matching costs. The competitive and efficient experimental results on both synthetic and real-world datasets demonstrate the effectiveness of the resultant Supervised Biadjacency Stereo matching networks (SuperBStereo).
C1 [Sun, Hanqing; Pang, Yanwei] Tianjin Univ, Sch Elect & Informat Engn, Tianjin Key Lab Brain Inspired Intelligence Techno, Tianjin 300072, Peoples R China.
   [Han, Jungong] Aberystwyth Univ, Comp Sci Dept, Aberystwyth SY23 3FL, Ceredigion, Wales.
   [Li, Xuelong] Northwestern Polytech Univ, Sch Artificial Intelligence Opt & Elect iOPEN, Xian 710072, Peoples R China.
C3 Tianjin University; Aberystwyth University; Northwestern Polytechnical
   University
RP Pang, YW (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin Key Lab Brain Inspired Intelligence Techno, Tianjin 300072, Peoples R China.
EM pyw@tju.edu.cn
RI Li, Xue-long/AFU-6301-2022; Sun, Hanqing/E-3397-2018
OI Li, Xue-long/0000-0003-2037-2525; Sun, Hanqing/0000-0002-8022-4172
FU National Key Ramp;D Program of China [2018AAA0102800]; Tianjin Science
   and Technology Program [19ZXZNGX00050]
FX AcknowledgmentsThis work was partially supported by the National Key R&D
   Program of China [2022ZD0160400], the National Key R&D Program of China
   [2018AAA0102800], and Tianjin Science and Technology Program
   [19ZXZNGX00050].
CR Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Chabra R, 2019, PROC CVPR IEEE, P11778, DOI 10.1109/CVPR.2019.01206
   Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Cheng Xuelian, 2020, Advances in Neural Information Processing Systems, V33
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Duggal S, 2019, IEEE I CONF COMP VIS, P4383, DOI 10.1109/ICCV.2019.00448
   Feihu Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P420, DOI 10.1007/978-3-030-58536-5_25
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Guo XY, 2019, PROC CVPR IEEE, P3268, DOI 10.1109/CVPR.2019.00339
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Hongwei Yi, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P766, DOI 10.1007/978-3-030-58545-7_44
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Ji CF, 2022, MULTIMED TOOLS APPL, V81, P5973, DOI 10.1007/s11042-021-11801-3
   Kendall Alex, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P66, DOI 10.1109/ICCV.2017.17
   Khamis S, 2018, LECT NOTES COMPUT SC, V11219, P596, DOI 10.1007/978-3-030-01267-0_35
   Kim T, 2020, IEEE ROBOT AUTOM LET, V5, P5597, DOI 10.1109/LRA.2020.3009065
   Kingma D. P., 2014, arXiv
   Liang W, 2021, MULTIMED TOOLS APPL, V80, P29617, DOI 10.1007/s11042-021-11137-y
   Liang ZF, 2018, PROC CVPR IEEE, P2811, DOI 10.1109/CVPR.2018.00297
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu YC, 2020, PROC CVPR IEEE, P2026, DOI 10.1109/CVPR42600.2020.00210
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438
   Menze M, 2015, ISPRS ANN PHOTO REM, VII-3, P427, DOI 10.5194/isprsannals-II-3-W5-427-2015
   Menze M, 2018, ISPRS J PHOTOGRAMM, V140, P60, DOI 10.1016/j.isprsjprs.2017.09.013
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Nie GY, 2019, PROC CVPR IEEE, P3278, DOI 10.1109/CVPR.2019.00340
   Pang YW, 2021, IEEE T IMAGE PROCESS, V30, P207, DOI 10.1109/TIP.2020.3034487
   Pang YW, 2020, PROC CVPR IEEE, P5930, DOI 10.1109/CVPR42600.2020.00597
   Paszke A, 2019, ADV NEUR IN, V32
   Rahman MM, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-1682-y
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rhemann C, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995372
   Srinivasu PN, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.654
   Su K, 2021, STEREO VOVNET CNN 3D, DOI [10.1007/s11042-021-11506-7, DOI 10.1007/S11042-021-11506-7]
   Sun HQ, 2023, PATTERN RECOGN LETT, V167, P164, DOI 10.1016/j.patrec.2023.02.006
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tankovich V, 2021, PROC CVPR IEEE, P14357, DOI 10.1109/CVPR46437.2021.01413
   Tonioni A, 2019, PROC CVPR IEEE, P195, DOI 10.1109/CVPR.2019.00028
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang LG, 2019, PROC CVPR IEEE, P12242, DOI 10.1109/CVPR.2019.01253
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wu J, 2023, SCI CHINA INFORM SCI, V66, DOI 10.1007/s11432-021-3575-1
   Wu ZY, 2019, IEEE I CONF COMP VIS, P7483, DOI 10.1109/ICCV.2019.00758
   Xinjiang Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13356, DOI 10.1109/CVPR42600.2020.01337
   Xu HF, 2020, PROC CVPR IEEE, P1956, DOI 10.1109/CVPR42600.2020.00203
   Yang M., 2020, P IEEECVF C COMPUTER, P12885, DOI DOI 10.1109/CVPR42600.2020.01290
   Yihui He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7776, DOI 10.1109/CVPR42600.2020.00780
   Yin ZC, 2019, PROC CVPR IEEE, P6037, DOI 10.1109/CVPR.2019.00620
   Zbontar J, 2016, J MACH LEARN RES, V17
   Zhang FH, 2019, PROC CVPR IEEE, P185, DOI 10.1109/CVPR.2019.00027
NR 53
TC 1
Z9 1
U1 5
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10247
EP 10272
DI 10.1007/s11042-023-15362-5
EA JUN 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001015589400005
DA 2024-07-18
ER

PT J
AU Wang, XZ
   Wei, GY
   Chen, SW
   Liu, JH
AF Wang, Xingzheng
   Wei, Guoyao
   Chen, Songwei
   Liu, Jiehao
TI An efficient weakly semi-supervised method for object automated
   annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image annotation; Object localization; Automatic bounding box
   annotation; Point supervision; Weakly semi-supervised learning;
   Teacher-student technique
ID LOCALIZATION
AB Object annotation is essential for computer vision tasks, and more high-quality annotated data can effectively improve the performance of vision models. However, manual annotation is time-consuming (annotating a box takes 35s). Recent studies have explored faster automated annotation, among which weakly supervised methods stand out. Weakly supervised methods learn to automatically localize objects in images from weakly labeled annotations, e.g., class tags or points, replacing manual bounding box annotations. Although using a single weakly labeled annotation can reduce a large amount of time, it leads to poor annotation quality, particularly for the complex scenes containing multiple objects. To balance annotation time and quality, we propose a weakly semi-supervised automated annotation method. Its main idea is to incorporate point-labeled and fully labeled annotations into a teacher-student framework for training, to jointly localize the object bounding boxes on all point-labeled images. We also propose two effective techniques within this framework to better use of these mixed annotations. The first is a point-guided sample assignment technique which optimizes the loss calculation. The second is a pseudo-label filtering technique which generate accurate pseudo labels for model training by utilizing the points and boxes localization confidences. Extensive experiments on MSCOCO demonstrate that our method outperforms existing automated annotation methods. In particular, when using 95% point-labeled and 5% fully labeled data, our approach reduces the annotation time by approximately 52% and achieves an annotation quality of 87.4% mIoU.
C1 [Wang, Xingzheng; Wei, Guoyao; Chen, Songwei; Liu, Jiehao] Shenzhen Univ, Coll Mechatron & Control Engn, Shenzhen 518000, Peoples R China.
C3 Shenzhen University
RP Wang, XZ (corresponding author), Shenzhen Univ, Coll Mechatron & Control Engn, Shenzhen 518000, Peoples R China.
EM xingzheng.wang@szu.edu.cn; wguoyao@163.com; emchensw@163.com;
   jayhaolau@outlook.com
FU NSFC fund [62171288]; Shenzhen Fundamental Research fund
   [20200810150441003, JCYJ20190808143415801]; Guangdong Basic and Applied
   Basic Research Foundation [2020A1515011559, 2021A1515012287]
FX AcknowledgmentsThis work was supported by the NSFC fund (62171288),
   Shenzhen Fundamental Research fund under Grant 20200810150441003 and
   JCYJ20190808143415801, and the Guangdong Basic and Applied Basic
   Research Foundation under Grant 2020A1515011559 and 2021A1515012287.
CR Adhikari B, 2021, EUR W VIS INF PROCES, DOI 10.1109/EUVIP50544.2021.9484022
   Adhikari B, 2021, INT C PATT RECOG, P4040, DOI 10.1109/ICPR48806.2021.9412956
   Adhikari B, 2018, EUR W VIS INF PROCES
   Akhilesh K, 2016, 2016 IEEE 7TH POWER INDIA INTERNATIONAL CONFERENCE (PIICON)
   Anjum Samreen, 2021, Human Computation, V8, P76
   Bacanin N, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0275727
   Bacanin N, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9212705
   Bakkouri I, 2023, SIGNAL IMAGE VIDEO P, V17, P1181, DOI 10.1007/s11760-022-02325-w
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Bearman Amy, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9911, P549, DOI 10.1007/978-3-319-46478-7_34
   Bernal J, 2019, INT J COMPUT ASS RAD, V14, P191, DOI 10.1007/s11548-018-1864-x
   Chandra AL, 2020, PLANT METHODS, V16, DOI 10.1186/s13007-020-00575-8
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   Chen LY, 2021, PROC CVPR IEEE, P8819, DOI 10.1109/CVPR46437.2021.00871
   Cinbis RG, 2017, IEEE T PATTERN ANAL, V39, P189, DOI 10.1109/TPAMI.2016.2535231
   De Boer MHT, 2019, MMEDIA 2019 INT C AD, P36
   Fei-Fei L., 2012, WORKSH 26 AAAI C ART, P40
   Gao W, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108233
   Groenen I, 2022, ARXIV
   Gygli M, 2020, INT J COMPUT VISION, V128, P1061, DOI 10.1007/s11263-019-01255-4
   Han JW, 2014, MULTIMED TOOLS APPL, V72, P2275, DOI 10.1007/s11042-013-1509-6
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Huang Z., 2020, P 34 INT C NEUR INF, V33, P16797
   Ince KG, 2021, IEEE INT CONF COMP V, P1233, DOI 10.1109/ICCVW54120.2021.00143
   Jeong J., 2019, ADV NEUR INFORM PROC, V32, P3
   Jiang BR, 2018, LECT NOTES COMPUT SC, V11218, P816, DOI 10.1007/978-3-030-01264-9_48
   Kiyokawa T, 2019, ADV ROBOTICS, V33, P1264, DOI 10.1080/01691864.2019.1697750
   Kiyokawa T, 2019, IEEE ROBOT AUTOM LET, V4, P1972, DOI 10.1109/LRA.2019.2899153
   Konyushkova K, 2018, PROC CVPR IEEE, P9175, DOI 10.1109/CVPR.2018.00956
   Li C.-L., 2020, Advances in neural information processing systems, V33, P596
   Li XW, 2022, IMAGE VISION COMPUT, V122, DOI 10.1016/j.imavis.2022.104444
   Lin D, 2016, PROC CVPR IEEE, P3159, DOI 10.1109/CVPR.2016.344
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Malakar S, 2020, NEURAL COMPUT APPL, V32, P2533, DOI 10.1007/s00521-018-3937-8
   Papadopoulos DP, 2017, IEEE I CONF COMP VIS, pCP38, DOI 10.1109/ICCV.2017.528
   Papadopoulos DP, 2017, PROC CVPR IEEE, P180, DOI 10.1109/CVPR.2017.27
   Papadopoulos DP, 2016, PROC CVPR IEEE, P854, DOI 10.1109/CVPR.2016.99
   Papadopoulos DP, 2014, LECT NOTES COMPUT SC, V8693, P361, DOI 10.1007/978-3-319-10602-1_24
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ries CX, 2016, MULTIMED TOOLS APPL, V75, P6091, DOI 10.1007/s11042-014-2434-z
   Rochan M, 2016, IMAGE VISION COMPUT, V56, P1, DOI 10.1016/j.imavis.2016.08.015
   Russakovsky O, 2015, PROC CVPR IEEE, P2121, DOI 10.1109/CVPR.2015.7298824
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Sohn Kihyuk, 2020, Advances in Neural Information Processing Systems, P596, DOI DOI 10.48550/ARXIV.2001.07685
   Tang P, 2020, IEEE T PATTERN ANAL, V42, P176, DOI 10.1109/TPAMI.2018.2876304
   Tarvainen Antti, 2017, ADV NEURAL INFORM PR, P2, DOI DOI 10.1137/0330046
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Uijlings JRR, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3302, DOI 10.1145/3394171.3413812
   Wang C, 2015, IEEE T IMAGE PROCESS, V24, P1371, DOI 10.1109/TIP.2015.2396361
   Wang X, 2022, NEURAL PROCESS LETT, V54, P5169, DOI 10.1007/s11063-022-10855-0
   Wu SK, 2020, IMAGE VISION COMPUT, V97, DOI 10.1016/j.imavis.2020.103911
   Xu J, 2015, PROC CVPR IEEE, P3781, DOI 10.1109/CVPR.2015.7299002
   Xu MD, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3040, DOI 10.1109/ICCV48922.2021.00305
   Zhang HY, 2021, PROC CVPR IEEE, P8510, DOI 10.1109/CVPR46437.2021.00841
   Zhang YF, 2022, NEUROCOMPUTING, V506, P146, DOI 10.1016/j.neucom.2022.07.042
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhongzheng Ren, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12364), P288, DOI 10.1007/978-3-030-58529-7_18
   Zhou LM, 2022, IEEE T IMAGE PROCESS, V31, P3684, DOI 10.1109/TIP.2022.3174391
   Zhou Q, 2021, PROC CVPR IEEE, P4079, DOI 10.1109/CVPR46437.2021.00407
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
   Zoph B., 2020, ARXIV200606882, V33, P3833
NR 64
TC 0
Z9 0
U1 11
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 9417
EP 9440
DI 10.1007/s11042-023-15305-0
EA JUN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001012579700009
DA 2024-07-18
ER

PT J
AU Saha, S
   Chowdhury, C
   Neogy, S
AF Saha, Sayantani
   Chowdhury, Chandreyee
   Neogy, Sarmistha
TI A novel two phase data sensitivity based access control framework for
   healthcare data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Access control; Data privacy; Data sensitivity; Data retrieval; User
   attribute; User authorization; User privilege; Linear optimization
AB This paper proposes a secure data access control framework that utilizes the attribute values and the user specific usage details to provide secure and fine-grained data access. It aims to minimize the data leakage during data retrieval which is a critical challenge for handling health data. No standard data retrieval policies are in place for preserving the privacy of medical data though any data breach may have a disastrous effect on society. In our proposed framework data is divided into different segments based on data sensitivity and data utility and users are authorized based on attribute details. An Integer Linear Programming (ILP) based solution is designed here to optimize the amount of information a user can retrieve from the application while minimizing the data leakage. The data storage technique and the user authorization technique complement each other to decide upon access to the portion of the information available to that particular user. An experimental result shows the sensitivity score calculation of the data items, ILP based privilege value assignment of the users and data retrieval strategy to minimize data leakage. The technique is validated on the benchmark datasets. The results show the utility of the sensitivity score of the data items and user privilege values while ensuring faster data retrieval time as compared to state-of-the-art works.
C1 [Saha, Sayantani] Maulana Abul Kalam Azad Univ Technol, Dept Informat Technol, Kolkata 741249, West Bengal, India.
   [Chowdhury, Chandreyee; Neogy, Sarmistha] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, West Bengal, India.
C3 Maulana Abul Kalam Azad University of Technology; Jadavpur University
RP Saha, S (corresponding author), Maulana Abul Kalam Azad Univ Technol, Dept Informat Technol, Kolkata 741249, West Bengal, India.
EM sayantanircc@gmail.com; chandreyee.chowdhury@gmail.com;
   sarmisthaneogy@gmail.com
CR Abdulghani HA, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11060774
   [Anonymous], 2002, SARB OXL ACT
   [Anonymous], 2016, GDPR ACT
   [Anonymous], 2000, HIPAA ACT
   Azeez NA, 2019, EGYPT INFORM J, V20, P97, DOI 10.1016/j.eij.2018.12.001
   Barua Mrinmoy, 2011, International Journal of Security and Networks, V6, P67, DOI 10.1504/IJSN.2011.043666
   Bethencourt J, 2007, P IEEE S SECUR PRIV, P321, DOI 10.1109/sp.2007.11
   Bhatt CA, 2011, MULTIMED TOOLS APPL, V51, P35, DOI 10.1007/s11042-010-0645-5
   Celikel E., 2009, RISK DECISION ANAL, V1, P21, DOI DOI 10.3233/RDA-2008-0002
   Chadwick DW, 2012, J COMPUT SYST SCI, V78, P1359, DOI 10.1016/j.jcss.2011.12.019
   Chase M, 2009, CCS'09: PROCEEDINGS OF THE 16TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P121
   Di Vimercati S.D.C., 2014, SECURE CLOUD COMPUTI, P123
   Eom J, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0621-3
   Garain A, 2022, MULTIMED TOOLS APPL, V81, P40827, DOI 10.1007/s11042-022-13185-4
   Goyal V., 2006, P 13 ACM C COMP COMM, P89, DOI DOI 10.1145/1180405.1180418
   Harel A, 2012, IEEE T DEPEND SECURE, V9, P414, DOI 10.1109/TDSC.2012.17
   Hur J, 2011, IEEE T PARALL DISTR, V22, P1214, DOI 10.1109/TPDS.2010.203
   Jayapradha J, 2022, IEEE ACCESS, V10, P28773, DOI 10.1109/ACCESS.2022.3158312
   Kement CE, 2017, IEEE T IND INFORM, V13, P3226, DOI 10.1109/TII.2017.2718666
   Khan LS, 2023, MULTIMED TOOLS APPL, V82, P6917, DOI 10.1007/s11042-022-13623-3
   Krishnan R, 2015, NSF WORKSH BIG DAT S
   Kudryavtsev LD, 2011, ENCY MATH
   Kumar TKA, 2017, DIGIT COMMUN NETW, V3, P213, DOI 10.1016/j.dcan.2017.07.007
   Kumar TKA, 2015, IEEE I C EMBED SOFTW, P1308, DOI 10.1109/HPCC-CSS-ICESS.2015.293
   Lewko A, 2010, LECT NOTES COMPUT SC, V6110, P62, DOI 10.1007/978-3-642-13190-5_4
   Li M, 2013, IEEE T PARALL DISTR, V24, P131, DOI 10.1109/TPDS.2012.97
   Li SX, 2019, ENG APPL ARTIF INTEL, V81, P300, DOI 10.1016/j.engappai.2018.12.006
   Li W., 2017, IEEECIC INT C COMMUN, P1, DOI DOI 10.1093/applin/amx039
   Liu Y, 2018, FUTURE GENER COMP SY, V78, P1020, DOI 10.1016/j.future.2016.12.027
   Majeed A, 2020, APPL INTELL, V50, P2555, DOI 10.1007/s10489-020-01656-w
   Musthafa S., 2013, INT J ENG SCI INVENT, V2.5, P17
   Qiu MK, 2018, FUTURE GENER COMP SY, V80, P421, DOI 10.1016/j.future.2016.01.006
   Roy Moumita, 2022, Journal of Ambient Intelligence and Humanized Computing, P4135, DOI 10.1007/s12652-022-04010-9
   Saha S., 2022, SN COMPUT SCI, V3.6, P482, DOI [10.1007/s42979-022-01372-x, DOI 10.1007/S42979-022-01372-X]
   Saha S, 2018, ADV INTELL SYST, V562, P175, DOI 10.1007/978-981-10-4603-2_17
   Satyanarayanan M, 2001, IEEE PERS COMMUN, V8, P10, DOI 10.1109/98.943998
   Tang PC, 2006, J AM MED INFORM ASSN, V13, P121, DOI 10.1197/jamia.M2025
   Ullah I, 2023, MULTIMED TOOLS APPL, V82, P6431, DOI 10.1007/s11042-022-13417-7
   Varriale A, 2016, P INT C SEC MAN SAM, P138
   Wang Y, 2019, J INF SECUR APPL, V49, DOI 10.1016/j.jisa.2019.102399
   Wazid M, 2017, IEEE T IND INFORM, V13, P3144, DOI 10.1109/TII.2017.2732999
   Weisstein EW, 2004, LAGRANGE INTERPOLATI
   Wu R, 2012, COLLABORATECOM, P711, DOI 10.4108/icst.collaboratecom.2012.250497
   Wu YD, 2013, IEEE T MULTIMEDIA, V15, P778, DOI 10.1109/TMM.2013.2238910
   Yang H, 2015, IEEE C COMM NETW SEC, DOI [10.1109/CNS.2015.7346888, DOI 10.1109/CNS.2015.7346888]
   Yang P, 2020, IEEE ACCESS, V8, P131723, DOI 10.1109/ACCESS.2020.3009876
   Yang ZQ, 2018, CYBERSECURITY, V1, DOI 10.1186/s42400-018-0011-x
   Yao L, 2021, IEEE T DEPEND SECURE, V18, P904, DOI 10.1109/TDSC.2019.2919833
   Yu SC, 2010, IEEE INFOCOM SER, DOI 10.1109/INFCOM.2010.5462174
   Zeng WR, 2014, IEEE INT CONF BIG DA, P701, DOI 10.1109/BigData.2014.7004294
   Zhang XG, 2018, WIRELESS PERS COMMUN, V103, P117, DOI 10.1007/s11277-018-5429-7
   Zhou J, 2015, IEEE T PARALL DISTR, V26, P1693, DOI 10.1109/TPDS.2014.2314119
NR 52
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8867
EP 8892
DI 10.1007/s11042-023-15427-5
EA JUN 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001009907400009
DA 2024-07-18
ER

PT J
AU Zhang, HG
   Lv, XS
   Liu, YA
   Zou, XY
AF Zhang, HongGuang
   Lv, XiuSha
   Liu, YuanAn
   Zou, XinYing
TI Hedge transfer learning routing for dynamic searching and reconnoitering
   applications in 3D multimedia FANETs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hedge transfer learning framework; UAV swarm; Multi-hop link state;
   Quality of service
ID QOS; PROTOCOLS; INTERNET; OPTIMIZATION; FRAMEWORK; NETWORKS; MANETS
AB With the fast development of unmanned aerial vehicles (UAVs) and the user increasing demand of UAV video transmission, UAV video service is widely used in dynamic searching and reconnoitering applications. Video transmissions not only consider the complexity and instability of 3D UAV network topology but also ensure reliable quality of service (QoS) in flying ad hoc networks (FANETs). We propose hedge transfer learning routing (HTLR) for dynamic searching and reconnoitering applications to address this problem. Compared with the previous transfer learning framework, HTRL has the following innovations. First, hedge principle is introduced into transfer learning. Online model is continuously trained on the basis of offline model, and their weight factors are adjusted in real-time by transfer learning, so as to adapt to the complex 3D FANETs. Secondly, distributed multi-hop link state scheme is used to estimate multi-hop link states in the whole network, thus enhancing the stability of transmission links. Among them, we propose the multiplication rule of multi-hop link states, which is a new idea to evaluate link states. Finally, we use packet delivery rate (PDR) and energy efficiency rate (EER) as two main evaluation metrics. In the same NS3 experimental scenario, the PDR of HTLR is at least 5.11% higher and the EER is at least 1.17 lower than compared protocols. Besides, we use Wilcoxon test to compare HTLR with the simplified version of HTLR without hedge transfer learning (N-HTLR). The results show that HTRL is superior to N-HTRL, effectively ensuring QoS.
C1 [Zhang, HongGuang; Lv, XiuSha; Liu, YuanAn; Zou, XinYing] Beijing Univ Posts & Telecommun, Sch Elect Engn, Beijing Key Lab Work Safety Intelligent Monitoring, Beijing, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Zhang, HG (corresponding author), Beijing Univ Posts & Telecommun, Sch Elect Engn, Beijing Key Lab Work Safety Intelligent Monitoring, Beijing, Peoples R China.
EM hongguang-zhang@bupt.edu.cn
RI Chen, YiJun/KFS-9282-2024; Liu, min/JXW-8493-2024; wang,
   David/KFR-2555-2024; Chen, Fang/JZE-4446-2024; lu, yuan/JZD-0832-2024;
   YANG, DAN/KCL-5217-2024; yu, xiao/KFT-1725-2024
OI Zhang, Hongguang/0000-0002-0724-0440
FU National Natural Science Foundation of China [61876199]; National Key
   Research and Development Program of China [2022YFF0604900]; Research
   Initiative of Ideological and Political Theory Teachers [20SZK10013001]
FX AcknowledgementsThis work was supported by National Natural Science
   Foundation of China (Grant No. 61876199), National Key Research and
   Development Program of China (Grant No. 2022YFF0604900) and Research
   Initiative of Ideological and Political Theory Teachers (No.
   20SZK10013001).
CR Adam SM, 2013, J APPL RES TECHNOL, V11, P844, DOI 10.1016/S1665-6423(13)71590-6
   Alanazi A, 2015, SENSORS-BASEL, V15, P22209, DOI 10.3390/s150922209
   Almeida EN, 2021, AD HOC NETW, V118, DOI 10.1016/j.adhoc.2021.102525
   Arnaldo J, 2018, ANN TELECOMMUN, V73, P601, DOI 10.1007/s12243-018-0658-z
   Avin C, 2022, IEEE ACM T NETWORK, V30, P1838, DOI 10.1109/TNET.2022.3153586
   Balachandra M, 2014, WIREL NETW, V20, P2395, DOI 10.1007/s11276-014-0754-6
   Bayat B, 2017, CURR OPIN BIOTECH, V45, P76, DOI 10.1016/j.copbio.2017.01.009
   Bhardwaj V, 2021, WIRELESS PERS COMMUN, V120, P1251, DOI 10.1007/s11277-021-08513-0
   Dong TJ, 2021, IEEE T NETW SERV MAN, V18, P1673, DOI 10.1109/TNSM.2021.3077249
   Elsayed M, 2021, IEEE T WIREL COMMUN, V20, P2838, DOI 10.1109/TWC.2020.3044597
   Entezami F, 2015, EURASIP J WIREL COMM, DOI 10.1186/s13638-015-0419-x
   Fleury M, 2019, MULTIMED TOOLS APPL, V78, P23749, DOI 10.1007/s11042-019-7679-0
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Fu JS, 2019, IEEE T IND INFORM, V15, P5664, DOI 10.1109/TII.2019.2908439
   Grondman I, 2012, IEEE T SYST MAN CY C, V42, P1291, DOI 10.1109/TSMCC.2012.2218595
   Gupta L, 2016, IEEE COMMUN SURV TUT, V18, P1123, DOI 10.1109/COMST.2015.2495297
   Hamid Z, 2014, WIRELESS PERS COMMUN, V75, P729, DOI 10.1007/s11277-013-1389-0
   He C, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19153394
   Heinzelman WB, 2002, IEEE T WIREL COMMUN, V1, P660, DOI 10.1109/TWC.2002.804190
   Hua J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041278
   Hussen HR, 2019, INT J DISTRIB SENS N, V15, DOI 10.1177/1550147719843879
   Iskanderani AI, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/3277988
   Jiang B, 2019, IEEE INTERNET THINGS, V6, P3525, DOI 10.1109/JIOT.2018.2886964
   Jiang JF, 2018, IEEE COMMUN MAG, V56, P58, DOI 10.1109/MCOM.2017.1700326
   Jiang JF, 2016, J NETW COMPUT APPL, V59, P4, DOI 10.1016/j.jnca.2015.01.005
   Khan A, 2018, IEEE T CYBERNETICS, V48, P187, DOI 10.1109/TCYB.2016.2628161
   Konda VR, 2003, SIAM J CONTROL OPTIM, V42, P1143, DOI 10.1137/S0363012901385691
   Kumar AR, 2020, MULTIMED TOOLS APPL, V79, P14031, DOI 10.1007/s11042-020-08631-0
   Kumari P, 2022, WIRELESS PERS COMMUN, V123, P1145, DOI 10.1007/s11277-021-09174-9
   Li B, 2021, DEF TECHNOL, V17, P457, DOI 10.1016/j.dt.2020.11.014
   Li RP, 2014, IEEE T WIREL COMMUN, V13, P2000, DOI 10.1109/TWC.2014.022014.130840
   Lu CH, 2021, IEEE INTERNET THINGS, V8, P4931, DOI 10.1109/JIOT.2020.3034153
   Masoudifar M, 2009, AD HOC NETW, V7, P1150, DOI 10.1016/j.adhoc.2008.10.004
   Nagalingayya M, 2022, MULTIMED TOOLS APPL, V81, P39785, DOI 10.1007/s11042-022-12938-5
   Nawaz H, 2021, ARCH COMPUT METHOD E, V28, P1349, DOI 10.1007/s11831-020-09418-0
   Niu HB, 2021, IEEE ACCESS, V9, P41566, DOI 10.1109/ACCESS.2021.3065055
   Ostovari P, 2016, IEEE ACM T NETWORK, V24, P1574, DOI 10.1109/TNET.2015.2427161
   Jara EP, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030901
   Pimentel L, 2015, LECT NOTES COMPUT SC, V9071, P122, DOI 10.1007/978-3-319-22572-2_9
   RIEDMILLER M, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P586, DOI 10.1109/ICNN.1993.298623
   Rosário D, 2014, COMPUT COMMUN, V45, P21, DOI 10.1016/j.comcom.2014.04.002
   Souza J, 2019, WIREL COMMUN MOB COM, V2019, DOI 10.1155/2019/8709249
   Srinivasulu M, 2023, MULTIMED TOOLS APPL, V82, P26829, DOI 10.1007/s11042-022-14285-x
   Wan ZT, 2021, NEUROCOMPUTING, V421, P1
   Wang MY, 2021, IEEE T RELIAB, V70, P790, DOI 10.1109/TR.2021.3062045
   Wang YT, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/5552743
   Wu DP, 2019, FUTURE GENER COMP SY, V99, P609, DOI 10.1016/j.future.2018.12.032
   Xu ZY, 2021, IEEE ACM T NETWORK, V29, P360, DOI 10.1109/TNET.2020.3037231
   Zhang M, 2022, CHINA COMMUN, V19, P302, DOI 10.23919/JCC.2022.05.005
   Zhang SW, 2018, IEEE T VEH TECHNOL, V67, P12049, DOI 10.1109/TVT.2018.2871614
   Zhang SS, 2019, IEEE GLOBE WORK, DOI 10.1109/gcwkshps45667.2019.9024517
   Zhang TG, 2020, IEEE ACCESS, V8, P32652, DOI 10.1109/ACCESS.2020.2974191
NR 52
TC 1
Z9 1
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7505
EP 7539
DI 10.1007/s11042-023-15932-7
EA JUN 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001003483000001
PM 37362678
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Agarwal, R
   Jindal, S
   Narain, S
   Kaushal, R
   Yadav, K
AF Agarwal, Riya
   Jindal, Shaifali
   Narain, Shradha
   Kaushal, Rishabh
   Yadav, Kalpana
TI A novel framework for fine-grained spatio-temporal change detection in
   satellite images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Change Detection(CD); Convolutional neural network; Satellite images
ID DIFFERENCE IMAGE; NETWORK; FUSION
AB Change Detection(CD), in the context of remote sensing, determines the differences in different portions of land images when studied over a while. Human change detection and analysis are limited and prone to errors and are incompetent for the scale and speed required for processing satellite data. Automating CD of earth surface features helps humans develop a deeper understanding of the changes in natural phenomena. In this work, we propose a novel framework for detecting the changes in the satellite images using the Siamese based neural network pipeline. Based on Spatio-Temporal analysis, our approach leverages the divide and conquer paradigm to divide the original image into sub-images and then uses the convolution layers to extract the feature maps at a sub-image level to detect fine-grained changes. To evaluate our proposed approach, we used a recently released dataset in 2020, LEVIR-CD, which consists of 637 pairs of high resolution images. In our work, we experimentally establish that decreasing the sub-image size of the original input image increases the accuracy of change detection, with the best performance achieved at 2 x 2 sub-image level with the best recall and F1-score with values 92% and 91.5%, respectively, outperforming the previous best results. Further, we find that our novel framework performs well on different terrains, with varying amounts and types of changes in the satellite image.
C1 [Agarwal, Riya; Jindal, Shaifali; Narain, Shradha; Kaushal, Rishabh; Yadav, Kalpana] Indira Gandhi Delhi Tech Univ Women, Dept Informat Technol, Delhi, India.
C3 Indira Gandhi Delhi Technical University for Women (IGDTUW)
RP Kaushal, R (corresponding author), Indira Gandhi Delhi Tech Univ Women, Dept Informat Technol, Delhi, India.
EM rishabh.kaushal@gmail.com
CR Abbas HK, 2020, AIP CONF PROC, V2290, DOI 10.1063/5.0027390
   Asokan A, 2019, EARTH SCI INFORM, V12, P143, DOI 10.1007/s12145-019-00380-5
   Benhur S, 2020, FRIENDLY INTRO SIAME
   Bontempi G, 2013, LECT NOTES BUS INF P, V138, P62
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Campbell JB, 2011, INTRO REMOTE SENSING
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Chen H, 2020, LEVIR CD DATASET
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Columbia University Mailman School of Public Health, 2020, SPAT AN
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Daudt RC, 2018, INT GEOSCI REMOTE SE, P2115, DOI 10.1109/IGARSS.2018.8518015
   Ghouaiel N, 2016, GEO-SPAT INF SCI, V19, P222, DOI 10.1080/10095020.2016.1244998
   Goel S, 2020, CHANGE DETECTION USI
   Gupta R.K., 2011, Inst. Town Planners India J., V8, P88
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Im J, 2008, INT J REMOTE SENS, V29, P399, DOI 10.1080/01431160601075582
   Jaderberg M, 2015, ADV NEUR IN, V28
   Kasetkasem T, 2002, IEEE T GEOSCI REMOTE, V40, P1815, DOI 10.1109/TGRS.2002.802498
   Ke QT, 2021, IEEE J-STARS, V14, P9987, DOI 10.1109/JSTARS.2021.3113831
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Ma WP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060626
   Mahmoud AS, 2021, IEEE ACCESS, V9, P90366, DOI 10.1109/ACCESS.2021.3089766
   Mozgovoy D., 2018, ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences, VIV -3, P167, DOI DOI 10.5194/ISPRS-ANNALS-IV-3-167-2018
   Nielsen A., 2019, Practical Time Series Analysis: Prediction with Statistics and Machine Learning
   Oh KY, 2012, KOREAN J REMOTE SENS, V28, P39, DOI 10.7780/kjrs.2012.28.1.039
   Olofsson P, 2016, ENVIRON RES LETT, V11, DOI 10.1088/1748-9326/11/6/064002
   Polykretis C, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020319
   Qin D, 2018, EXPERT SYST APPL, V97, P372, DOI 10.1016/j.eswa.2017.12.038
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Rokni K, 2015, INT J APPL EARTH OBS, V34, P226, DOI 10.1016/j.jag.2014.08.014
   Shafique A, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14040871
   Shi WZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101688
   Song KQ, 2021, IEEE J-STARS, V14, P4816, DOI 10.1109/JSTARS.2021.3077545
   Suribabu CR, 2012, J INDIAN SOC REMOTE, V40, P699, DOI 10.1007/s12524-011-0196-x
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   Tomowski D., 2011, 2011 Proceedings of Joint Urban Remote Sensing Event (JURSE 2011), P329, DOI 10.1109/JURSE.2011.5764786
   TURNER MG, 1990, LANDSCAPE ECOL, V4, P21, DOI 10.1007/BF02573948
   Venugopal N, 2020, NEURAL PROCESS LETT, V51, P2355, DOI 10.1007/s11063-019-10174-x
   Wang MY, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020205
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Willhauck G., 2000, Proceedings of XIX ISPRS Congress, V33, P35
   Yin CT, 2015, SCI CHINA INFORM SCI, V58, DOI 10.1007/s11432-015-5397-4
   Zhang Y, 2021, IEEE J-STARS, V14, P8125, DOI 10.1109/JSTARS.2021.3103429
   Zheng YG, 2014, IEEE GEOSCI REMOTE S, V11, P691, DOI 10.1109/LGRS.2013.2275738
   Zhou XL, 2011, LANDSCAPE URBAN PLAN, V100, P268, DOI 10.1016/j.landurbplan.2010.12.013
NR 46
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 6
PY 2023
DI 10.1007/s11042-023-14705-6
EA JUN 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I5ZM2
UT WOS:001003562600002
DA 2024-07-18
ER

PT J
AU Liu, HL
   Zhang, CY
   Wang, ZJ
   Guo, CF
   Gou, PD
   Shan, LY
   Lu, ZW
AF Liu, Hailun
   Zhang, Chunyu
   Wang, Zhaojie
   Guo, Chenfei
   Gou, Peidong
   Shan, Liying
   Lu, Zewei
TI To deliver more information in coverless information hiding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Coverless information hiding; Bag-of-words model; Visual words
AB Coverless information hiding realizes the hiding of secret messages without modifying the carrier, so being able to resist steganalysis algorithms. Many existing hiding methods, however, still face the dilemma of low hiding capacity (i.e., the volume of hidden messages by a single carrier is bounded), which places some restrictions on the application of the methods. To alleviate this problem, in this paper, we explore an effective coverless information hiding method that can deliver more messages through a cover image. A key step of our method is to construct a visual dictionary based on the bag-of-words model. Utilizing the visual dictionary, one participant can generate a binary coding matrix corresponding to the cover image, and then convert the secret messages, based on the matrix, into a coordinate sequence. To enhance the security, the coordinate sequence is encrypted and the ciphertext is transmitted to another participant together with the cover image. Some experiments are implemented to verify the effectiveness of our method, the results and analysis show that our method performs well in terms of undetectability, hiding capacity, and robustness. Compared with other coverless information hiding methods, our method does not need to construct and maintain a large-scale image library and can deliver more messages by only one single image. These characteristics demonstrate that our method has certain application value, and it also broadens the research ideas of coverless information hiding methods.
C1 [Liu, Hailun; Zhang, Chunyu; Guo, Chenfei; Gou, Peidong; Shan, Liying; Lu, Zewei] Xizang Minzu Univ, Sch Informat Engn, Xianyang 712000, Shaanxi, Peoples R China.
   [Wang, Zhaojie] Qufu Normal Univ, Sch Comp Sci, Rizhao 276826, Shandong, Peoples R China.
C3 Xizang Minzu University; Qufu Normal University
RP Zhang, CY (corresponding author), Xizang Minzu Univ, Sch Informat Engn, Xianyang 712000, Shaanxi, Peoples R China.
EM liuhailun2022@163.com; zcy@xzmu.edu.cn; wangzhaojie82@gmail.com;
   1178093159@qq.com; 496061151@qq.com; 2858208584@qq.com; 573570907@qq.com
RI Li, Chun/KBC-9591-2024; Liu, Song/KCX-6842-2024; Wang,
   Ling/KBA-9814-2024; Wang, Ling/AGR-4917-2022; Zhang,
   Tianxi/KEH-5921-2024; LI, HAO/KBD-0866-2024; WANG, YUHAO/KBB-0213-2024;
   li, yuan/KBQ-4200-2024; Chen, GuanYu/KGK-6328-2024; xiang,
   wei/JXL-3308-2024; Liu, Fuyi/KDO-6120-2024
OI Wang, Ling/0000-0003-0272-2974; Wang, Ling/0000-0003-0272-2974; 
FU National Natural Science Foundation of China [62262062]
FX This article is funded by the National Natural Science Foundation of
   China (62262062).
CR Abdulsattar FS, 2021, MULTIMED TOOLS APPL, V80, P18821, DOI 10.1007/s11042-021-10608-6
   [Anonymous], 2007, MIR
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Cao Y, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00524-4
   [董腾林 Dong Tenglin], 2021, [应用科学学报, Journal of Applied Sciences], V39, P893
   Duan X, 2018, ARXIV
   Duan XT, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00506-6
   Fei-Fei L., 2004, CVPR WORKSH GEN MOD, V106, P178, DOI DOI 10.1109/CVPR.2004.383
   Goodfellow I. J., 2014, ARXIV
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Kadhim IJ, 2019, NEUROCOMPUTING, V335, P299, DOI 10.1016/j.neucom.2018.06.075
   Li Q, 2021, NEURAL PROCESS LETT, V53, P4037, DOI 10.1007/s11063-021-10582-y
   Liu Q, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00521-7
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Muhuri PK, 2020, APPL SOFT COMPUT, V92, DOI 10.1016/j.asoc.2020.106257
   Sahu AK, 2019, SENS IMAGING, V21, DOI 10.1007/s11220-019-0262-y
   Sahu AK, 2019, 3D RES, V10, DOI 10.1007/s13319-018-0211-x
   Xianyi Chen, 2015, Cloud Computing and Security. First International Conference, ICCCS 2015. Revised Selected Papers: LNCS 9483, P133, DOI 10.1007/978-3-319-27051-7_12
   Yang LN, 2020, IEEE ACCESS, V8, P108579, DOI 10.1109/ACCESS.2020.3000993
   Yuan CS, 2017, J INTERNET TECHNOL, V18, P435, DOI 10.6138/JIT.2017.18.2.20160624c
   Zhang X, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420500625
   Zheng WB, 2021, IEEE T CYBERNETICS, V51, P393, DOI 10.1109/TCYB.2019.2963138
   Zhili Zhou, 2015, Cloud Computing and Security. First International Conference, ICCCS 2015. Revised Selected Papers: LNCS 9483, P123, DOI 10.1007/978-3-319-27051-7_11
   Zou LM, 2019, MULTIMED TOOLS APPL, V78, P7965, DOI 10.1007/s11042-018-6444-0
NR 26
TC 0
Z9 0
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7215
EP 7229
DI 10.1007/s11042-023-15263-7
EA JUN 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001003562600005
DA 2024-07-18
ER

PT J
AU Gugulothu, VK
   Balaji, S
AF Gugulothu, Vijay Kumar
   Balaji, S.
TI An early prediction and classification of lung nodule diagnosis on CT
   images based on hybrid deep learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Computed tomography; Lung nodules; Feature extraction; Deep learning;
   Lung tumor prediction
AB Detection of malignant lung nodules at an early stage may allow for clinical interventions that increase the survival rate of lung cancer patients. Using hybrid deep learning techniques to detect nodules will improve the sensitivity of lung cancer screening and the interpretation speed of lung scans. Accurate detection of lung nodes is an important step in computed tomography (CT) imaging to detect lung cancer. However, it is very difficult to identify strong nodes due to the diversity of lung nodes and the complexity of the surrounding environment. Here, we proposed lung nodule detection and classification with CT images based on hybrid deep learning (LNDC-HDL) techniques. First, we introduce a chaotic bird swarm optimization (CBSO) algorithm for lung nodule segmentation using statistical information. Second, we illustrate an improved Fish Bee (IFB) algorithm for feature extraction and selection. Third, we develop a hybrid classifier i.e. hybrid differential evolution-based neural network (HDE-NN) for tumor prediction and classification. Experimental results have shown that the use of computed tomography, which demonstrates the efficiency and importance of the HDE-NN specific structure for detecting lung nodes on CT scans, increases sensitivity and reduces the number of false positives. The proposed method shows that the benefits of HDE-NN node detection can be reaped by combining clinical practice.
C1 [Gugulothu, Vijay Kumar] Deemed Univ, Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Hyderabad 500075, Telangana, India.
   [Gugulothu, Vijay Kumar] Govt Polytech, Dept Comp Sci & Engn, Comp Engn, Hyderabad 500075, Telangana, India.
   [Gugulothu, Vijay Kumar; Balaji, S.] Deemed Univ, Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Hyderabad, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University);
   Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Gugulothu, VK (corresponding author), Deemed Univ, Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Hyderabad 500075, Telangana, India.; Gugulothu, VK (corresponding author), Govt Polytech, Dept Comp Sci & Engn, Comp Engn, Hyderabad 500075, Telangana, India.; Gugulothu, VK (corresponding author), Deemed Univ, Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Hyderabad, India.
EM vijaykumargugulothu@gmail.com
OI GUGULOTHU, VIJAY KUMAR/0000-0002-5669-7375
CR Balci MA, 2023, CANCERS, V15, DOI 10.3390/cancers15030843
   Bhattacharjee A, 2023, IEEE T RADIAT PLASMA, V7, P394, DOI 10.1109/TRPMS.2023.3236719
   Chen QQ, 2022, ENVIRON SCI EUR, V34, DOI 10.1186/s12302-022-00605-3
   Eid Alazemi Fayez, 2023, J Healthc Eng, V2023, P8262741, DOI 10.1155/2023/8262741
   Ghashghaei Sara, 2023, SN Comput Sci, V4, P201, DOI 10.1007/s42979-022-01642-8
   Huang SG, 2023, SEMIN CANCER BIOL, V89, P30, DOI 10.1016/j.semcancer.2023.01.006
   Kasinathan G, 2022, BIOMED RES INT, V2022, DOI 10.1155/2022/4185835
   Liu WH, 2023, PATTERN RECOGN, V136, DOI 10.1016/j.patcog.2022.109261
   Mothkur Rashmi, 2023, Procedia Computer Science, P1869, DOI 10.1016/j.procs.2023.01.164
   Pradhan M, 2023, MACHINE LEARNING ART, V311, P329, DOI DOI 10.1201/9781003265436
   Sharma R, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103101
   Shen ZQ, 2023, COMPUT BIOL MED, V154, DOI 10.1016/j.compbiomed.2023.106587
   Siddiqui EA, 2023, CHEMOMETR INTELL LAB, V235, DOI 10.1016/j.chemolab.2023.104763
   Song YC, 2022, COMPUT METH PROG BIO, V220, DOI 10.1016/j.cmpb.2022.106821
   Musthafa AS, 2023, CONCURR COMP-PRACT E, V35, DOI 10.1002/cpe.7488
   Zhang GR, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13030357
NR 16
TC 5
Z9 5
U1 9
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 31
PY 2023
DI 10.1007/s11042-023-15802-2
EA MAY 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H9TW0
UT WOS:000999312400009
PM 37362653
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Singh, SR
   Dubey, SR
   Shruthi, MS
   Ventrapragada, S
   Dasharatha, SS
AF Singh, Satya Rajendra
   Dubey, Shiv Ram
   Shruthi, M. S.
   Ventrapragada, Sairathan
   Dasharatha, Saivamshi Salla
TI Joint Triplet Autoencoder for histopathological colon cancer nuclei
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Retrieval; Siamese; Autoencoder; Deep learning; Colon cancer
ID LOCAL BINARY PATTERNS; FEATURE DESCRIPTOR; IMAGE; CLASSIFICATION
AB Deep learning has shown a great improvement in the performance of visual tasks. Image retrieval is the task of extracting the visually similar images from a database for a query image. The feature matching is performed to rank the images. Various hand-designed features have been derived in past to represent the images. Nowadays, the power of deep learning is being utilized for automatic feature learning from data in the field of biomedical image analysis. Autoencoder and Siamese networks are two deep learning models to learn the latent space (i.e., features or embedding). Autoencoder works based on the reconstruction of the image from latent space. Siamese network utilizes the triplets to learn the intra-class similarity and inter-class dissimilarity. Moreover, Autoencoder is unsupervised, whereas Siamese network is supervised. We propose a Joint Triplet Autoencoder Network (JTANet) by facilitating the triplet learning in autoencoder framework. A joint supervised learning for Siamese network and unsupervised learning for Autoencoder is performed. Moreover, the Encoder network of Autoencoder is shared with Siamese network and referred as the Siamcoder network. The features are extracted by using the trained Siamcoder network for retrieval purpose. The experiments are performed over Histopathological Routine Colon Cancer dataset. We have observed the promising performance using the proposed JTANet model against the Autoencoder and Siamese models for colon cancer nuclei retrieval in histopathological images.
C1 [Singh, Satya Rajendra; Dubey, Shiv Ram; Shruthi, M. S.; Ventrapragada, Sairathan; Dasharatha, Saivamshi Salla] Indian Inst Informat Technol, Comp Vis Grp, Sri City, Andhra Prades, India.
   [Dubey, Shiv Ram] Indian Inst Informat Technol, Comp Vis & Biometr Lab, Allahabad, Uttar Pradesh, India.
C3 Indian Institute of Information Technology Allahabad
RP Dubey, SR (corresponding author), Indian Inst Informat Technol, Comp Vis Grp, Sri City, Andhra Prades, India.; Dubey, SR (corresponding author), Indian Inst Informat Technol, Comp Vis & Biometr Lab, Allahabad, Uttar Pradesh, India.
EM satyarajendra.rs@iiits.in; srdubey@iiita.ac.in; shruthi.ms16@iiits.in;
   sairathan.v16@iiits.in; saivamshi.s16@iiits.in
RI Dubey, Shiv Ram/T-7541-2019
OI Dubey, Shiv Ram/0000-0002-4532-8996
FU Science and Engineering Research Board (SERB) [ECR/2017/000082]; NVIDIA
   Corporation
FX AcknowledgmentsThis research is funded by Science and Engineering
   Research Board (SERB), Govt. of India through Project Sanction Number
   ECR/2017/000082. The authors would like to thank NVIDIA Corporation for
   the support of 2 GeForce Titan X Pascal GPUs.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2016, IJCAI
   Basha SHS, 2018, I C CONT AUTOMAT ROB, P1222, DOI 10.1109/ICARCV.2018.8581147
   Cao Y, 2016, P 30 AAAI C ART INT
   Cao ZJ, 2017, IEEE I CONF COMP VIS, P5609, DOI 10.1109/ICCV.2017.598
   Ding ZY, 2019, MULTIMED TOOLS APPL, V78, P5751, DOI 10.1007/s11042-018-5967-8
   Dubey S R, 2022, 2022 IEEE INT C MULT, P1
   Dubey SR, 2022, IEEE T CIRC SYST VID, V32, P2687, DOI 10.1109/TCSVT.2021.3080920
   Dubey SR, 2020, NEURAL COMPUT APPL, V32, P7539, DOI 10.1007/s00521-019-04279-6
   Dubey SR, 2014, IEEE T IMAGE PROCESS, V23, P5323, DOI 10.1109/TIP.2014.2358879
   Gnouma M, 2019, MULTIMED TOOLS APPL, V78, P2157, DOI 10.1007/s11042-018-6273-1
   Gu Y, 2019, The Mesozoic Tectonic-Magmatic Constraints on the Gold Mineralization in Wulong Gold Mining Area, Eastern Liaoning, P1
   Gu Y, 2019, IEEE J BIOMED HEALTH, V23, P1683, DOI 10.1109/JBHI.2018.2882647
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jiang QY, 2018, AAAI CONF ARTIF INTE, P3342
   Kar MK, 2023, CIRC SYST SIGNAL PR, V42, P1206, DOI 10.1007/s00034-022-02190-5
   Kayhan N, 2021, MULTIMED TOOLS APPL, V80, P32763, DOI 10.1007/s11042-021-11217-z
   Krizhevsky A., 2011, P ESANN, VVolume 1, P2
   Kumar RB, 2020, MULTIMED TOOLS APPL, V79, P22277, DOI 10.1007/s11042-020-08953-z
   Le Q.V., 2015, TUTORIAL DEEP LEARNI
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Leng B, 2015, SIGNAL PROCESS, V112, P119, DOI 10.1016/j.sigpro.2014.09.005
   Li HL, 2018, IEEE T INF FOREN SEC, V13, P2639, DOI 10.1109/TIFS.2018.2825949
   Li J, 2020, IEEE J. Biomed. Health Inform.
   Li LQ, 2020, MULTIMED TOOLS APPL, V79, P14509, DOI 10.1007/s11042-018-6970-9
   Li Q, 2017, ADV NEUR IN, V30
   Li Y, 2020, MULTIMED TOOLS APPL, P1
   Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Majhi M, 2021, MULTIMED TOOLS APPL, V80, P7271, DOI 10.1007/s11042-020-10005-5
   Martinez-Murcia F J, 2019, IEEE Journal of Biomedical and Health Informatics
   Murala S, 2014, IEEE J BIOMED HEALTH, V18, P929, DOI 10.1109/JBHI.2013.2288522
   Murala S, 2013, NEUROCOMPUTING, V119, P399, DOI 10.1016/j.neucom.2013.03.018
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Patel D, 2016, INT C PATT RECOG, P2258, DOI 10.1109/ICPR.2016.7899972
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1
   Rajpurkar P, 2017, Arxiv, DOI arXiv:1711.05225
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Singhal A, 2021, MULTIMED TOOLS APPL, V80, P15901, DOI 10.1007/s11042-020-10319-4
   Sirinukunwattana K, 2016, IEEE T MED IMAGING, V35, P1196, DOI 10.1109/TMI.2016.2525803
   Sun L, 2020, IEEE J BIOMED HEALTH, V24, P2798, DOI 10.1109/JBHI.2020.3019505
   Tripathi S, 2020, MULTIMED TOOLS APPL, V79, P34931, DOI 10.1007/s11042-020-08891-w
   Venugopal V, 2022, COMPUT BIOL MED, V148, DOI 10.1016/j.compbiomed.2022.105852
   Venugopal V, 2022, COMPUT METH PROG BIO, V222, DOI 10.1016/j.cmpb.2022.106935
   Wang XF, 2017, LECT NOTES COMPUT SC, V10111, P70, DOI 10.1007/978-3-319-54181-5_5
   Wang XS, 2018, PROC CVPR IEEE, P9049, DOI 10.1109/CVPR.2018.00943
   Wang Y, 2022, Multimed Tools Appl, P1
   Wu DY, 2019, PROC CVPR IEEE, P9061, DOI 10.1109/CVPR.2019.00928
   Yang HF, 2018, IEEE T PATTERN ANAL, V40, P437, DOI 10.1109/TPAMI.2017.2666812
   Yu LH, 2021, MULTIMED TOOLS APPL, V80, P19157, DOI 10.1007/s11042-020-10355-0
   Zhang J, 2019, IEEE T CIRC SYST VID, V29, P212, DOI 10.1109/TCSVT.2017.2771332
   Zhang XF, 2016, IEEE J BIOMED HEALTH, V20, DOI 10.1109/JBHI.2015.2461671
   Zhou CY, 2019, IEEE J BIOMED HEALTH, V23, P103, DOI 10.1109/JBHI.2018.2856820
   Zhu ZT, 2016, NEUROCOMPUTING, V204, P41, DOI 10.1016/j.neucom.2015.08.127
NR 57
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 31
PY 2023
DI 10.1007/s11042-023-15400-2
EA MAY 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H9TW0
UT WOS:000999312400005
DA 2024-07-18
ER

PT J
AU Wang, ZB
   Liu, XC
   Wang, E
   Zhang, YA
AF Wang, Zhaobin
   Liu, Xinchao
   Wang, E.
   Zhang, Yaonan
TI Unsupervised image segmentation evaluation based on feature extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image segmentation; Segmentation evaluation; Edge detection; Feature
   extraction; Unsupervised evaluation
ID INVARIANT TEXTURE CLASSIFICATION; MEANS CLUSTERING-ALGORITHM; OBJECTIVE
   EVALUATION; FACE RECOGNITION; GRAY-SCALE; FRAMEWORK; QUALITY; FUSION;
   REGION; MODEL
AB Image segmentation is widely used in life. Generally speaking, the segmentation results are divided into good and bad quality, so it is very important to propose an effective method to evaluate the quality of image segmentation. This paper proposed a framework based on edge detection and feature extraction for evaluating the quality of image segmentation. The framework belongs to unsupervised evaluation, the operation is simple and easy to implement, and readers can add or subtract methods in the framework according to specific circumstances. To prove the effectiveness of the proposed framework, we tested on four different datasets. In addition, we compare the proposed framework with some classic and newer evaluation methods. Experimental results show that the proposed framework is suitable for many types of images, and its performance is better than some existing metrics.
C1 [Wang, Zhaobin; Liu, Xinchao; Wang, E.] Lanzhou Univ, Sch Infomat Sci & Engn, Lanzhou 730000, Peoples R China.
   [Zhang, Yaonan] Chinese Acad Sci, Northwest Inst Ecoenvironm & Resources, Natl Cryosphere Desert Data Ctr, Lanzhou, Peoples R China.
C3 Lanzhou University; Chinese Academy of Sciences
RP Wang, ZB (corresponding author), Lanzhou Univ, Sch Infomat Sci & Engn, Lanzhou 730000, Peoples R China.
EM zhaobin_wang@hotmail.com
RI Liu, Xinchao/AAY-8853-2021
FU National Key R&D Program of China [:2022YFF0711700]; Open Fund Project
   of National Cryosphere Desert Data Center
FX We would like to thank the associate editors and the reviewers for their
   valuable comments and suggestions. The authors also thank Shuai Wang for
   his generous help. This work was supported by National Key R&D Program
   of China (No:2022YFF0711700) and Open Fund Project of National
   Cryosphere Desert Data Center (2022).
CR Abusham EEA, 2011, LECT NOTES COMPUT SC, V6762, P169
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alonso-Fernandez F, 2005, ISPA 2005: Proceedings of the 4th International Symposium on Image and Signal Processing and Analysis, P239, DOI 10.1109/ISPA.2005.195416
   Alpert S, 2007, PROC CVPR IEEE, P359
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Audelan B, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101895
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Benini S, 2019, SIGNAL PROCESS-IMAGE, V74, P21, DOI 10.1016/j.image.2019.01.005
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Böck S, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9080769
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chabrier S, 2004, INT C PATT RECOG, P576, DOI 10.1109/ICPR.2004.1334206
   Chen BK., 2019, IEEE T INTELL TRANSP, V20, P137, DOI [10.1109/Tits.2018.2801309, DOI 10.1109/TITS.2018.2801309]
   Chen Q, 2012, IET IMAGE PROCESS, V6, P426, DOI 10.1049/iet-ipr.2010.0078
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Demidova LA, 2019, IOP CONF SER-MAT SCI, V476, DOI 10.1088/1757-899X/476/1/012008
   Dietenbeck T, 2010, IEEE IMAGE PROC, P665, DOI 10.1109/ICIP.2010.5652991
   Faggian N, 2006, INT C PATT RECOG, P287
   Freixenet J, 2002, LECT NOTES COMPUT SC, V2352, P408, DOI 10.1007/3-540-47977-5_27
   Ge F, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2762250
   Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562
   He NJ, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-019-2791-7
   Hesamian MH, 2019, J DIGIT IMAGING, V32, P582, DOI 10.1007/s10278-019-00227-x
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Jiasheng Hao, 2009, 2009 IEEE Instrumentation and Measurement Technology Conference (I2MTC), P373, DOI 10.1109/IMTC.2009.5168478
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Khan AI, 2019, APPL ARTIF INTELL, V33, P87, DOI 10.1080/08839514.2018.1526704
   Khan JF, 2014, OPT LASER TECHNOL, V57, P236, DOI 10.1016/j.optlastec.2013.07.012
   Lei T, 2018, IEEE T FUZZY SYST, V26, P3027, DOI 10.1109/TFUZZ.2018.2796074
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu Y, 2003, CAN J ELECT COMPUT E, V28, P63, DOI 10.1109/CJECE.2003.1532510
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Miao Y, 2012, APPL MECH MATER, V157-158, P1012, DOI 10.4028/www.scientific.net/AMM.157-158.1012
   Nasution TY, 2017, J PHYS CONF SER, V930, DOI 10.1088/1742-6596/930/1/012034
   NAZIF AM, 1984, IEEE T PATTERN ANAL, V6, P555, DOI 10.1109/TPAMI.1984.4767570
   Nie X, 2020, IEEE ACCESS, V8, P9325, DOI 10.1109/ACCESS.2020.2964540
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojala T, 2000, LECT NOTES COMPUT SC, V1842, P404
   Papadomanolaki M, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060684
   Peng B, 2017, IEEE T PATTERN ANAL, V39, P1929, DOI 10.1109/TPAMI.2016.2622703
   Peng B, 2016, IEEE SIGNAL PROC LET, V23, P459, DOI 10.1109/LSP.2016.2517101
   Peng B, 2013, IEEE SIGNAL PROC LET, V20, P689, DOI 10.1109/LSP.2013.2262938
   Peng B, 2012, LECT NOTES COMPUT SC, V7574, P287, DOI 10.1007/978-3-642-33712-3_21
   Pfister T, 2015, LECT NOTES COMPUT SC, V9003, P538, DOI 10.1007/978-3-319-16865-4_35
   Randrianasoa JF, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107667
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Simfukwe M, 2017, IEEE INT C INF COMM, V1, P10
   Simfukwe M, 2017, 2017 12 INT C INT SY
   Simfukwe M, 2019, INT J COMPUT INT SYS, V12, P379, DOI 10.2991/ijcis.2018.125905654
   Simfukwe M, 2016, LECT NOTES COMPUT SC, V9772, P534, DOI 10.1007/978-3-319-42294-7_48
   Taha AA, 2015, BMC MED IMAGING, V15, DOI 10.1186/s12880-015-0068-x
   Tetteh GO, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12183096
   Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Wang S, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020207
   Wang X, 2007, IEEE T PATTERN ANAL, V29, P886, DOI 10.1109/TPAMI.2007.1027
   Wang ZB, 2020, ARTIF INTELL REV, V53, P5637, DOI 10.1007/s10462-020-09830-9
   Williams C.K.I., PASCAL VISUAL OBJECT
   Yu HP, 2019, MULTIMED TOOLS APPL, V78, P11779, DOI 10.1007/s11042-018-6735-5
   Zhang H, 2004, P SOC PHOTO-OPT INS, V5307, P38
   Zhang H, 2008, COMPUT VIS IMAGE UND, V110, P260, DOI 10.1016/j.cviu.2007.08.003
   Zhang YJ, 1996, PATTERN RECOGN, V29, P1335, DOI 10.1016/0031-3203(95)00169-7
   Zhao MF, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12183005
   Ziólko B, 2018, IEEE T FUZZY SYST, V26, P1789, DOI 10.1109/TFUZZ.2017.2752130
NR 69
TC 0
Z9 0
U1 9
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 29
PY 2023
DI 10.1007/s11042-023-15384-z
EA MAY 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H8LP5
UT WOS:000998414300004
DA 2024-07-18
ER

PT J
AU Varde, AS
   Karthikeyan, D
   Wang, WT
AF Varde, Aparna S.
   Karthikeyan, Divydharshini
   Wang, Weitian
TI Facilitating COVID recognition from X-rays with computer vision models
   and transfer learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE AI in medicine; Electronic health records; Big data mining; Computer
   vision; Image recognition; Transfer learning
AB Multimedia data plays an important role in medicine and healthcare since EHR (Electronic Health Records) entail complex images and videos for analyzing patient data. In this article, we hypothesize that transfer learning with computer vision can be adequately harnessed on such data, more specifically chest X-rays, to learn from a few images for assisting accurate, efficient recognition of COVID. While researchers have analyzed medical data (including COVID data) using computer vision models, the main contributions of our study entail the following. Firstly, we conduct transfer learning using a few images from publicly available big data on chest X-rays, suitably adapting computer vision models with data augmentation. Secondly, we aim to find the best fit models to solve this problem, adjusting the number of samples for training and validation to obtain the minimum number of samples with maximum accuracy. Thirdly, our results indicate that combining chest radiography with transfer learning has the potential to improve the accuracy and timeliness of radiological interpretations of COVID in a cost-effective manner. Finally, we outline applications of this work during COVID and its recovery phases with future issues for research and development. This research exemplifies the use of multimedia technology and machine learning in healthcare.
C1 [Varde, Aparna S.; Karthikeyan, Divydharshini; Wang, Weitian] Montclair State Univ, Sch Comp, Montclair, NJ 07043 USA.
   [Varde, Aparna S.] Max Planck Inst Informat, Saarbrucken, Germany.
C3 Montclair State University; Max Planck Society
RP Varde, AS (corresponding author), Montclair State Univ, Sch Comp, Montclair, NJ 07043 USA.; Varde, AS (corresponding author), Max Planck Inst Informat, Saarbrucken, Germany.
EM vardea@montclair.edu; divyakarthi@gmail.com; wangw@montclair.edu
FU Montclair State University; NSF [2018575]
FX This work has been partly supported by internal funding from Montclair
   State University as mentioned in the acknowledgments. External funding
   includes the NSF Award # 2018575 for the grant MRI: Acquisition of a
   High-Performance GPU Cluster for Research and Education for Aparna Varde
   and Weitian Wang. This grant is from Oct 2020 to Sep 2023.
CR Almezhghwi K, 2021, MULTIMED TOOLS APPL, V80, P29051, DOI 10.1007/s11042-021-10907-y
   [Anonymous], 2020, WORLD SHUTS
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Baig MM, 2013, J MED SYST, V37, DOI 10.1007/s10916-012-9898-z
   Bhatt D, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10202470
   Chen YH, 2016, ENERGIES, V9, DOI 10.3390/en9020070
   Conti CJ, 2022, IEEE T AUTOM SCI ENG, V19, P1784, DOI 10.1109/TASE.2022.3159595
   Conti CJ, 2020, 2020 IEEE INTERNATIONAL IOT, ELECTRONICS AND MECHATRONICS CONFERENCE (IEMTRONICS 2020), P170
   Conti CJ, 2020, IEEE INT CONF BIG DA, P5652, DOI 10.1109/BigData50022.2020.9378498
   Fan GF, 2013, ENERGIES, V6, P1887, DOI 10.3390/en6041887
   Ghoshal B, 2020, Arxiv, DOI [arXiv:2003.10769, 10.48550/arXiv.2003.10769]
   Hawkins DM, 2004, J CHEM INF COMP SCI, V44, P1, DOI 10.1021/ci0342472
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hemdan E. E. D., 2020, arXiv, DOI [DOI 10.48550/ARXIV.2003.11055, 10.48550/arXiv.2003.11055]
   Huh JH, 2019, IEEE ACCESS, V7, P164229, DOI 10.1109/ACCESS.2019.2945338
   Jhunjhunwala Ashok, 2020, Trans Indian Natl Acad Eng, V5, P157, DOI 10.1007/s41403-020-00109-7
   kaggle, CNN ARCHITECTURES VG
   Keras Optimizers, ABOUT US
   Khan NUZ, 2015, BMC MED INFORM DECIS, V15, DOI 10.1186/s12911-015-0188-9
   Kingma D. P., 2014, arXiv
   Kuchana M, 2021, MULTIMED TOOLS APPL, V80, P9161, DOI 10.1007/s11042-020-10010-8
   Sinha RK, 2018, Arxiv, DOI arXiv:1804.03928
   Li MW, 2021, NONLINEAR DYNAM, V103, P1167, DOI 10.1007/s11071-020-06111-6
   Lourenco J, HLTH ESSENTIALS APP, DOI [10.13140/RG.2.2.29642.49604, DOI 10.13140/RG.2.2.29642.49604]
   mathworks, VGG19
   mdlive, MD LIVE MOBILE APP 4
   NY Department of Health, 2020, COV AL NY
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Park SW, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10101216
   Park SW, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040688
   Paulino Laura, 2022, Intelligent Systems and Applications: Proceedings of the 2021 Intelligent Systems Conference (IntelliSys). Lecture Notes in Networks and Systems (296), P802, DOI 10.1007/978-3-030-82199-9_54
   Persaud Priya, 2021, Journal of Robotics, DOI 10.1155/2021/5461703
   Pham T, 2020, HEALTH INF SCI SYST, P1
   Pham TD, 2021, HEALTH INF SCI SYST, V9, DOI 10.1007/s13755-020-00135-3
   Puri M, 2021, ACM SIGWEB, P1, DOI [10.1145/3494825.3494830, DOI 10.1145/3494825.3494830]
   Razniewski S, 2021, WSDM '21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P1143, DOI 10.1145/3437963.3441664
   Saha Ishika, 2021, Proceedings of the 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS), P834, DOI 10.1109/ICAIS50930.2021.9395961
   Sethy P, 2020, ARXIV
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun JM, 2020, TRENDS MOL MED, V26, P483, DOI 10.1016/j.molmed.2020.02.008
   Tancer J., 2011, 2011 IEEE International Conference on Data Mining Workshops, P188, DOI 10.1109/ICDMW.2011.166
   Tandon N, 2017, SIGMOD REC, V46, P49, DOI 10.1145/3186549.3186562
   The Triple-I Blog, US
   Tian S., 2019, Global HealthJournal3, V3, P62, DOI [DOI 10.1016/J.GLOHJ.2019.07.001, 10.1016/j.glohj.2019.07.001]
   Torres J, 2021, 2021 IEEE INTERNATIONAL IOT, ELECTRONICS AND MECHATRONICS CONFERENCE (IEMTRONICS), P670, DOI 10.1109/IEMTRONICS52119.2021.9422594
   towardsdatascience, VGG16 VGG19
   Varde Aparna S, 2022, SN Comput Sci, V3, P184, DOI 10.1007/s42979-022-01068-2
   Varghese C, 2021, 2021 IEEE 11TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P408, DOI 10.1109/CCWC51732.2021.9375945
   Wang PQ, 2018, Arxiv, DOI arXiv:1702.08502
   WebMD, COVID 19 SYMPT CHECK
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Xu Du, 2016, 2016 IEEE 32nd International Conference on Data Engineering: Workshops (ICDEW), P54, DOI 10.1109/ICDEW.2016.7495616
   Yang GZ, 2020, SCI ROBOT, V5, DOI 10.1126/scirobotics.abb5589
   Zhang JP, 2020, Arxiv, DOI arXiv:2003.12338
NR 55
TC 4
Z9 4
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 26
PY 2023
DI 10.1007/s11042-023-15744-9
EA MAY 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3VP4
UT WOS:000995280400009
PM 37362714
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Dougherty, ST
   Sahinkaya, S
   Ustun, D
AF Dougherty, Steven T.
   Sahinkaya, Serap
   Ustun, Deniz
TI A novel method for image encryption using time signature-dependent
   s-boxes based on latin squares and the playfair system of cryptography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image encryption; Latin squares; Chaotic map; S-Box
ID CONSTRUCTION; DESIGN
AB This paper presents an image encryption algorithm by using time signature-dependent S-Boxes, which are based on Latin squares, the Playfair system of cryptography, and functions that are inspired by the behavior of a Japanese ladder. The encryption algorithm includes four stages: the construction of the S-Box, the generation of keys, image diffusion, and image permutation. The public key is generated from the grey-scale values of the plaintext image and the time signature, and secret key consists of the time signature and two functions from F82 to F82. Permutation and diffusion stages of the encryption algorithm are based on a given S-Box. Moreover, a chaotic map is used in the permutation phase for an effective shuf-fling of pixel positions. The simulation results and security analyses show that the proposed encryption scheme is quite secure and it can resist various cyber attacks effectively.
C1 [Dougherty, Steven T.] Univ Scranton, Dept Math, Scranton, PA 18518 USA.
   [Sahinkaya, Serap] Tarsus Univ, Fac Engn, Dept Nat & Math Sci, Mersin, Turkiye.
   [Ustun, Deniz] Tarsus Univ, Fac Engn, Dept Comp Engn, Mersin, Turkiye.
C3 University of Scranton; Tarsus University; Tarsus University
RP Sahinkaya, S (corresponding author), Tarsus Univ, Fac Engn, Dept Nat & Math Sci, Mersin, Turkiye.
EM srpsahinkaya@gmail.com
RI USTUN, Deniz/GQB-3301-2022; Sahinkaya, Serap/ABB-4228-2020
OI Sahinkaya, Serap/0000-0002-2084-6260
FU  [1059B192000947]
FX AcknowledgementsSerap Sahinkaya would like to thank T.U.B.I.T.A.K
   (Scientific and Technological Research Council of Turkey) for their
   support while writing this paper (Grant Number is 1059B192000947).
CR Aboytes-González JA, 2018, NONLINEAR DYNAM, V94, P2003, DOI 10.1007/s11071-018-4471-z
   Ahmed HA, 2019, NEURAL COMPUT APPL, V31, P7201, DOI 10.1007/s00521-018-3557-3
   Alawida M, 2019, SIGNAL PROCESS, V160, P45, DOI 10.1016/j.sigpro.2019.02.016
   Alhadawi HS, 2021, MULTIMED TOOLS APPL, V80, P7333, DOI 10.1007/s11042-020-10048-8
   Belazi A, 2017, NONLINEAR DYNAM, V87, P337, DOI 10.1007/s11071-016-3046-0
   Cassal-Quiroga BB, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/2702653
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Dougherty ST., 2020, COMBINATORICS FINITE, P369, DOI [10.1007/978-3-030-56395-0, DOI 10.1007/978-3-030-56395-0]
   Hua ZY, 2021, NONLINEAR DYNAM, V104, P807, DOI 10.1007/s11071-021-06308-3
   Idrees B, 2020, MULTIMED TOOLS APPL, V79, P6135, DOI 10.1007/s11042-019-08282-w
   Jamal SS, 2016, WIRELESS PERS COMMUN, V90, P2033, DOI 10.1007/s11277-016-3436-0
   Khan M, 2018, NEURAL COMPUT APPL, V29, P993, DOI 10.1007/s00521-016-2511-5
   Khan M, 2016, NEURAL COMPUT APPL, V27, P677, DOI 10.1007/s00521-015-1887-y
   Kumar CM, 2022, APPL INTELL, V52, P2556, DOI 10.1007/s10489-021-02508-x
   Liu H., 2020, APPL MATH COMPUT, V376, P125
   Liu HJ, 2022, INT J BIFURCAT CHAOS, V32, DOI 10.1142/S0218127422501632
   Liu HJ, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420501734
   Liu L., J PHYS C SER, V1303, P2019
   Manjula G, 2016, PROCEEDINGS OF THE 2016 2ND INTERNATIONAL CONFERENCE ON APPLIED AND THEORETICAL COMPUTING AND COMMUNICATION TECHNOLOGY (ICATCCT), P613, DOI 10.1109/ICATCCT.2016.7912073
   Naseer A, 2020, INT J COMPUT SCI INF, V18
   Si YY, 2021, INT J BIFURCAT CHAOS, V31, DOI 10.1142/S0218127421501467
   Sosa PM, 2016, Calculating nonlinearity of Boolean functions with Walsh-Hadamard Transform, P1
   Toktas A, 2022, NEURAL COMPUT APPL, V34, P4295, DOI 10.1007/s00521-021-06552-z
   Trappe W., 2006, Introduction to Cryptography with Coding Theory
   Ullah A, 2018, NONLINEAR DYNAM, V91, P359, DOI 10.1007/s11071-017-3874-6
   Ullah A, 2017, NONLINEAR DYNAM, V88, P2757, DOI 10.1007/s11071-017-3409-1
   Vidhya R, 2020, APPL INTELL, V50, P3101, DOI 10.1007/s10489-020-01697-1
   WEBSTER AF, 1986, LECT NOTES COMPUT SC, V218, P523
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Zheng JM, 2022, APPL INTELL, V52, P15703, DOI 10.1007/s10489-022-03174-3
NR 30
TC 3
Z9 3
U1 3
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 23
PY 2023
DI 10.1007/s11042-023-15240-0
EA MAY 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H1DL6
UT WOS:000993432500006
DA 2024-07-18
ER

PT J
AU Agarwal, C
   Mishra, A
   Dubey, G
AF Agarwal, Charu
   Mishra, Anurag
   Dubey, Gaurav
TI A novel gray-scale image watermarking framework using harmony search
   algorithm optimization of multiple scaling factors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Optimization; Visual Quality; Gray-Scale Image Watermarking; Meta
   -heuristic algorithm; Harmony Search Algorithm (HSA); Robustness
ID HEURISTIC ALGORITHM; SCHEME; SVD
AB A Digital image watermarking is a cutting-edge problem that deals with copyright protection, content authentication and ownership identification. Precisely due to this reason, it is quite clear to the media industry. Particularly for images and videos, falling under un-compressed and compressed domain, it deals with minimizing the trade-off between two essential performance evaluation metrics - Visual Quality of the signal and the Robustness criteria. Although several metaheuristic technqiues have been applied to this problem, we are yet to apply new nature inspired techniques to develop watermarking applications for images and video. In this paper, we propose a novel watermark embedding scheme for gray-scale images using Harmony Search Algorithm (HSA). The HSA optimizes the Objective Function which in turn produces the best Multiple Scaling Factors (MSFs) to be used for embedding the watermark coefficients in the most suitable image coefficients in hybrid transform domain. On signed and attacked images, the PSNR show that their visual quality is very good. This scheme is also found to be very robust against common image processing operations except cropping attack of different variants. It is concluded that the proposed scheme is well optimized in terms of aforesaid performance evaluation metrics and proves improvement over other similar state of the art methods.
C1 [Agarwal, Charu] Ajay Kumar Garg Engn Coll, Dept Comp Sci & Engn, Ghaziabad 201009, Uttar Pradesh, India.
   [Mishra, Anurag] Univ Delhi, Deendayal Upadhyay Coll, Dept Elect, Delhi 110078, India.
   [Dubey, Gaurav] ABES Engn Coll, Dept Comp Sci & Engn, Ghaziabad 201009, Uttar Pradesh, India.
C3 University of Delhi
RP Mishra, A (corresponding author), Univ Delhi, Deendayal Upadhyay Coll, Dept Elect, Delhi 110078, India.
EM agarwalcharu2@gmail.com; anuragm1967@gmail.com; gdubey1977@gmail.com
RI Agarwal, Charu/HTM-4123-2023; Dubey, Gaurav/ABD-9682-2020
OI Dubey, Gaurav/0000-0003-2268-3810
CR Agarwal C, 2014, INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND SOFTWARE ENGINEERING (AISE 2014), P430
   Ariatmanto D, 2022, J KING SAUD UNIV-COM, V34, P605, DOI 10.1016/j.jksuci.2020.02.005
   Ayvaz MT, 2007, ADV WATER RESOUR, V30, P2326, DOI 10.1016/j.advwatres.2007.05.009
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Cuevas E, 2012, J INTELL ROBOT SYST, V66, P359, DOI 10.1007/s10846-011-9611-3
   Fattahi M, 2015, J INTELL FUZZY SYST, V28, P2357, DOI 10.3233/IFS-151585
   Findik O, 2010, OPT COMMUN, V283, P4916, DOI 10.1016/j.optcom.2010.07.020
   Geem Z.W., 2005, AM J APPL SCI, V2, P1552, DOI DOI 10.3844/AJASSP.2005.1552
   Geem ZW, 2006, ENG OPTIMIZ, V38, P259, DOI 10.1080/03052150500467430
   Geem ZW, 2001, SIMULATION, V76, P60, DOI 10.1177/003754970107600201
   Hu J, 2022, IEEE T CIRC SYST VID, V32, P1089, DOI 10.1109/TCSVT.2021.3074259
   Huang HC., 2010, J INF HIDING MULTIME, V1, P51
   Ishtiaq M., 2010, ICIC EXPRESS LETT, V4, P1881
   Kim JH, 2001, J AM WATER RESOUR AS, V37, P1131, DOI 10.1111/j.1752-1688.2001.tb03627.x
   Kumsawat P, 2005, IEEE T SIGNAL PROCES, V53, P4707, DOI 10.1109/TSP.2005.859323
   Lai CC, 2011, DIGIT SIGNAL PROCESS, V21, P522, DOI 10.1016/j.dsp.2011.01.017
   Lee KS, 2005, ENG OPTIMIZ, V37, P663, DOI 10.1080/03052150500211895
   Lee KS, 2005, COMPUT METHOD APPL M, V194, P3902, DOI 10.1016/j.cma.2004.09.007
   Lee KS, 2004, COMPUT STRUCT, V82, P781, DOI 10.1016/j.compstruc.2004.01.002
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Loukhaoukha K., 2011, J Inf Hiding Multim Signal Process, V2, P303
   Mahdavi M, 2007, APPL MATH COMPUT, V188, P1567, DOI 10.1016/j.amc.2006.11.033
   Mehta R., 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P123, DOI 10.1109/IIHMSP.2010.38
   Mishra A, 2016, BIO-INSPIRED COMPUTATION AND APPLICATIONS IN IMAGE PROCESSING, P131, DOI 10.1016/B978-0-12-804536-7.00007-7
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Omran MGH, 2008, APPL MATH COMPUT, V198, P643, DOI 10.1016/j.amc.2007.09.004
   Pan JS, 2021, ENG APPL ARTIF INTEL, V97, DOI 10.1016/j.engappai.2020.104049
   Rajpal A., 2016, 2016 IEEE Int Conf Signal Process, Commun and Comput (ICSPCC), P1
   Rajpal A, 2019, APPL SOFT COMPUT, V74, P603, DOI 10.1016/j.asoc.2018.10.043
   Run RS, 2012, EXPERT SYST APPL, V39, P673, DOI 10.1016/j.eswa.2011.07.059
   Takore Tamirat Tagesse, 2018, International Journal of Intelligent Systems and Applications, V10, P50, DOI 10.5815/ijisa.2018.11.06
   Tang XH, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P635, DOI 10.1109/ISIMP.2004.1434144
   Tsai HH, 2012, APPL SOFT COMPUT, V12, P2442, DOI 10.1016/j.asoc.2012.02.021
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang X. S., 2008, Nature-Inspired Metaheuristic Algorithms, DOI DOI 10.1001/JAMA.1994.03520100096046
NR 37
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 18
PY 2023
DI 10.1007/s11042-023-15533-4
EA MAY 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G9GJ2
UT WOS:000992151600004
DA 2024-07-18
ER

PT J
AU Zhou, MD
   Wu, L
   Liu, S
   Li, JJ
AF Zhou, Mengdong
   Wu, Lei
   Liu, Shuai
   Li, Jianjun
TI UAV forest fire detection based on lightweight YOLOv5 model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE UAV; Fire detection; Lightweight network; Distillation of knowledge
ID FRAMEWORK; SELECTION; IOT
AB In recent years, the frequent occurrence of forest fires has caused serious impact on the environment and economy. Fire detection has become a hot research direction. Despite the remarkable achievements, the unmanned aerial vehicle (UAV) still has some problems such as insufficient precision and excessive parameters. In order to improve the application ability of UAV in forest fire prevention and control, a lightweight target detection model based on YOLOv5 is proposed. The model is based on the overall structure of YOLOv5, MobileNetV3 is used as the backbone network, and semi-supervised knowledge distillation (SSLD) is used for training to improve the convergence speed and accuracy of the model. The final model size was reduced by 94.1% from 107.6 MB to 6.3 MB. mAP0.5 increased by 0.8% and mAP0.95 increased by 2.6%. The improved lightweight YOLOv5 model has fewer parameters and less computation, which confirms that MobileNetV3 has an excellent effect on the compression of model memory, and the semi-supervised knowledge distillation method is beneficial to improve the accuracy of the model. In the future, the accuracy of the model and the detection rate of the covered flame should be further improved.
C1 [Zhou, Mengdong; Wu, Lei; Liu, Shuai; Li, Jianjun] Cent South Univ Forestry & Technol, Changsha 410004, Peoples R China.
C3 Central South University of Forestry & Technology
RP Liu, S (corresponding author), Cent South Univ Forestry & Technol, Changsha 410004, Peoples R China.
EM xifang99@126.com
CR Abbassi MAE., 2016, INT REV MODEL SIMUL, V9, P173
   Andrew AM, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010031
   Bhattarai M, 2020, IEEE ACCESS, V8, P88308, DOI 10.1109/ACCESS.2020.2993767
   Borges P., 2008, Sismo 1998-Acores. Uma Decada Depois, P1
   Bushnaq OM, 2021, IEEE INTERNET THINGS, V8, P16984, DOI 10.1109/JIOT.2021.3077593
   Conrad T, 2007, IEEE SENSOR, P1221, DOI 10.1109/ICSENS.2007.4388629
   Foggia P, 2015, IEEE T CIRC SYST VID, V25, P1545, DOI 10.1109/TCSVT.2015.2392531
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Gagliardi A, 2021, J REAL-TIME IMAGE PR, V18, P2085, DOI 10.1007/s11554-021-01094-y
   Gao Y, 2019, FIRE TECHNOL, V55, P1801, DOI 10.1007/s10694-019-00831-x
   Hackner A, 2016, SENSOR ACTUAT B-CHEM, V231, P497, DOI 10.1016/j.snb.2016.02.081
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Jiao ZT, 2020, CHIN CONT DECIS CONF, P4963, DOI 10.1109/CCDC49329.2020.9163816
   Khuzani AZ, 2019, 2019 IEEE GLOB HUM T, P1
   Kuanar S, 2019, IEEE IMAGE PROC, P1351, DOI [10.1109/ICIP.2019.8803037, 10.1109/icip.2019.8803037]
   Kuanar S, 2019, CIRC SYST SIGNAL PR, V38, P5081, DOI 10.1007/s00034-019-01110-4
   Pan J, 2021, FORESTS, V12, DOI 10.3390/f12060768
   Qin YY, 2021, INT J AUTOM COMPUT, V18, P300, DOI 10.1007/s11633-020-1269-5
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Robinne F.-N., 2021, UNFFS Background Paper
   Saeed F, 2020, MULTIMED TOOLS APPL, V79, P9083, DOI 10.1007/s11042-019-07785-w
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shamsoshoara A, 2021, COMPUT NETW, V193, DOI 10.1016/j.comnet.2021.108001
   Sharma A, 2021, COMPUT ELECTR ENG, V93, DOI 10.1016/j.compeleceng.2021.107216
   Sudhakar S, 2020, COMPUT COMMUN, V149, P1, DOI 10.1016/j.comcom.2019.10.007
   Xu MD, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3040, DOI 10.1109/ICCV48922.2021.00305
   Ye X, 2014, SENSORS TRANSDUCERS, P57
   Zhu L., 2018, FIRE SCI TECHNOL, V37, P225
   Zhu MC, 2017, Arxiv, DOI arXiv:1710.01878
   Zhu YL, 2013, ADV MATER RES-SWITZ, V694-697, P961, DOI 10.4028/www.scientific.net/AMR.694-697.961
NR 31
TC 3
Z9 3
U1 6
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 11
PY 2023
DI 10.1007/s11042-023-15770-7
EA MAY 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G1LI4
UT WOS:000986851800004
DA 2024-07-18
ER

PT J
AU Tanwar, S
   Gupta, N
   Kumar, P
   Hu, YC
AF Tanwar, Sarvesh
   Gupta, Neelam
   Kumar, Prashant
   Hu, Yu-Chen
TI Implementation of blockchain-based e-voting system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE De-centralized Application; Ethereum; Smart Contract; Electronic voting
   system
ID CHALLENGES; INTEGRATION; TECHNOLOGY; IOT
AB An electronic voting portal should provide security, integrity, vote transparency, and voter privacy. Electronic voting, or e-voting, has been used in many ways since the 1970s, with essential advantages over paper-based systems, such as higher efficiency and fewer errors. However, attaining widespread acceptance of such systems remains a problem, particularly in enhancing their resistance to potential mistakes. Blockchain is a cutting-edge technology that has the potential to improve the overall security of electronic voting systems. This paper uses smart contracts to develop an e-voting Decentralized Application (DApp) on the Ethereum blockchain and develops a frontend to access the DApp easily on the blockchain. This paper began with an overview of blockchain and explored the blockchain application challenges. One of the things that can be improved is the election voting system that leaves so many gaps for incompetence and tampering with the votes collected, as witnessed by so many real-life cases in our country. Finally, the added visibility of the voting procedure and more effective security can help in providing a fair result. This article also discussed using blockchain, essentially the smart contract function of the Ethereum blockchain, to make a decentralized app for the voting procedure of an election. It provides full transparency over the votes, with real-time tracking by using an election DApp. The blockchain makes it possible to have a fully transparent election while keeping all the voters anonymous.
C1 [Tanwar, Sarvesh; Gupta, Neelam; Kumar, Prashant] Amity Univ Uttar Pradesh, Amity Inst Informat Technol, Noida, India.
   [Hu, Yu-Chen] Providence Univ, Dept Comp Sci & Informat Management, 200,Sec 7,Taiwan Blvd, Taichung 43301, Taiwan.
   [Hu, Yu-Chen] TungHai Univ, Dept Comp Sci, Taichung, Taiwan.
C3 Amity University Noida; Providence University - Taiwan; Tunghai
   University
RP Hu, YC (corresponding author), Providence Univ, Dept Comp Sci & Informat Management, 200,Sec 7,Taiwan Blvd, Taichung 43301, Taiwan.; Hu, YC (corresponding author), TungHai Univ, Dept Comp Sci, Taichung, Taiwan.
EM s.tanwar1521@gmail.com; neelam.gupta@s.amity.edu;
   prashantk4.pk@gmail.com; ychu@pu.edu.tw
RI Kumar, Prashant/AAF-5376-2020
OI Tanwar, Sarvesh/0000-0003-0136-0182; Hu, Yu-Chen/0000-0002-5055-3645
CR Ahsan U., 2017, 2017 26th Wireless and Optical Communication Conference WOCC, P1
   Al Sadawi A, 2021, IEEE ACCESS, V9, P54478, DOI 10.1109/ACCESS.2021.3070555
   Al-Maaitah Sarah, 2021, 2021 International Conference on Information Technology (ICIT), P200, DOI 10.1109/ICIT52682.2021.9491734
   Al-Zubaidie M, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16091490
   Alam T., 2019, INT J SCI RES COMPUT, P151, DOI [10.32628/cseit195137, DOI 10.32628/CSEIT195137]
   Alharby M, 2017, Arxiv, DOI [arXiv:1710.06372, 10.5121/csit.2017.71011, DOI 10.5121/CSIT.2017.71011]
   Latif RAM, 2022, MULTIMED TOOLS APPL, V81, P26609, DOI 10.1007/s11042-020-10087-1
   Andoni M, 2019, RENEW SUST ENERG REV, V100, P143, DOI 10.1016/j.rser.2018.10.014
   Androulaki E, 2018, EUROSYS '18: PROCEEDINGS OF THE THIRTEENTH EUROSYS CONFERENCE, DOI 10.1145/3190508.3190538
   Angrish A, 2018, PROCEDIA MANUF, V26, P1180, DOI 10.1016/j.promfg.2018.07.154
   Bhosale J., 2018, ANN RES J SCMS PUNE, V6, P132
   Braghin C, 2019, LECT NOTES BUS INF P, V373, P274, DOI 10.1007/978-3-030-36691-9_24
   Cheng JR, 2021, MULTIMED TOOLS APPL, V80, P30623, DOI 10.1007/s11042-020-09368-6
   Datta Priyanka, 2020, 2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO), P1115, DOI 10.1109/ICRITO48877.2020.9198032
   Díaz M, 2016, J NETW COMPUT APPL, V67, P99, DOI 10.1016/j.jnca.2016.01.010
   Engelhardt MA, 2017, TECHNOL INNOV MANAG, V7, P22, DOI 10.22215/timreview/1111
   Eyal I, 2016, 13TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI '16), P45
   Gupta M, 2022, TRANSFORMATIONS BLOC, P181, DOI [10.1007/978-3-030-93344-9_8, DOI 10.1007/978-3-030-93344-9_8]
   Hamilton M, 2020, J CORP ACCOUNT FINAN, V31, P7, DOI 10.1002/jcaf.22421
   Han Xiaoting, 2010, 2010 2nd International Conference on Industrial Mechatronics and Automation (ICIMA 2010), P170, DOI 10.1109/ICINDMA.2010.5538341
   Hjálmarsson FT, 2018, PROCEEDINGS 2018 IEEE 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING (CLOUD), P983, DOI 10.1109/CLOUD.2018.00151
   Justinia Taghreed, 2019, Acta Inform Med, V27, P284, DOI 10.5455/aim.2019.27.284-291
   Kakkar Latika, 2021, Proceedings of the Second International Conference on Information Management and Machine Intelligence (ICIMMI 2020). Lecture Notes in Networks and Systems (LNNS 166), P87, DOI 10.1007/978-981-15-9689-6_10
   Kamil M., 2021, INT J ARTIF INTELL R, V5, P25, DOI [10.29099/ijair.v5i1.173, DOI 10.29099/IJAIR.V5I1.173]
   Karamitsos I., 2018, Journal of Information Security, V9, P177, DOI [10.4236/jis.2018.93013, DOI 10.4236/JIS.2018.93013, 10.4236/jis.2018.93]
   Khan SN, 2021, PEER PEER NETW APPL, V14, P2901, DOI 10.1007/s12083-021-01127-0
   Kirillov D, 2019, LECT NOTES COMPUT SC, V11620, P509, DOI 10.1007/978-3-030-24296-1_40
   Kumar Nallapaneni Manoj, 2018, Procedia Computer Science, V132, P1815, DOI 10.1016/j.procs.2018.05.140
   McPhee C., 2017, MANAG REV, V7, P3
   Mik Eliza, 2017, Law Innovation and Technology, V9, P269, DOI 10.1080/17579961.2017.1378468
   Mohammed AH, 2021, P 3 INT C HUM COMP I, P1, DOI DOI 10.1109/HORA52670.2021.9461294
   Nakamoto S., 2008, DECENT BUS REV, V21260, DOI https://bitcoin.org/bitcoin.pdf
   Park J, 2021, IEEE ACCESS, V9, P151004, DOI 10.1109/ACCESS.2021.3126201
   Pawlak M, 2019, LECT NOTE DATA ENG, V23, P233, DOI 10.1007/978-3-319-98557-2_21
   Radziwill, 2018, QUALITY MANAGEMENT J, DOI [10.1080/10686967.2018.1404373, DOI 10.1080/10686967.2018.1404373, 10.1080/10686967.2018.1404372, DOI 10.1080/10686967.2018.1404372]
   Raj A, 2021, MULTIMED TOOLS APPL, V80, P18901, DOI 10.1007/s11042-021-10715-4
   Rathee G, 2021, IEEE ACCESS, V9, P34165, DOI 10.1109/ACCESS.2021.3061411
   Sathish C, 2022, MULTIMED TOOLS APPL, V81, P33419, DOI 10.1007/s11042-022-12784-5
   Scriber BA, 2018, IEEE SOFTWARE, V35, P70, DOI 10.1109/MS.2018.2801552
   Sharma Riya, 2020, Proceedings of the 2020 9th International Conference System Modeling and Advancement in Research Trends (SMART), P149, DOI 10.1109/SMART50582.2020.9337064
   Shukla S, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P873, DOI 10.1109/ICACCI.2018.8554652
   Tas R, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12081328
   Ul Hassan M, 2019, FUTURE GENER COMP SY, V97, P512, DOI 10.1016/j.future.2019.02.060
   Vivek S. K., 2020, Proceedings of Second International Conference on Inventive Research in Computing Applications (ICIRCA 2020), P890, DOI 10.1109/ICIRCA48905.2020.9183185
   Wang ZL, 2021, FRONT COMPUT SCI-CHI, V15, DOI 10.1007/s11704-020-9284-9
   Yi HB, 2019, EURASIP J WIREL COMM, DOI 10.1186/s13638-019-1473-6
   Zheng ZB, 2018, INT J WEB GRID SERV, V14, P352, DOI 10.1504/IJWGS.2018.095647
   Zile K, 2018, APPL COMPUT SYST, V23, P12, DOI 10.2478/acss-2018-0002
NR 48
TC 4
Z9 4
U1 6
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 6
PY 2023
DI 10.1007/s11042-023-15401-1
EA MAY 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F5KI3
UT WOS:000982729800001
DA 2024-07-18
ER

PT J
AU Zhou, TC
   Tao, AM
   Sun, LF
   Qu, BY
   Wang, YZ
   Huang, H
AF Zhou, Tongchi
   Tao, Aimin
   Sun, Liangfeng
   Qu, Boyang
   Wang, Yanzhao
   Huang, Hu
TI Behavior recognition based on the improved density clustering and
   context-guided Bi-LSTM model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Density clustering; Context-guided BiLSTM; ConvLSTM; Fusion module;
   Action recognition
ID ATTENTION; FRAMEWORK; NETWORKS
AB Context information is vital to research video human behavior recognition. Under the LSTM together with CNN of the framework, a novel action recognition method, which extracts keyframes by the improved density clustering, and learns Spatio-temporal context information by Context-Guided BiLSTM, is proposed. Specifically, keyframes are firstly extracted by the Gini-based density clustering, then used as the inputs of CNN. Secondly, a deep Spatio-temporal Bi-directional long short-term memory neural network named by Context-Guided BiLSTM, which is built by each Bi-directional LSTM block, is utilized to model temporal dependencies of spatial features. After learning by ConvLSTM and Context-Guided BiLSTM, the results generated by the fusion module are treated as the inputs of the Softmax layer for action recognition. On the three benchmark datasets, UCF sport, UCF11, and jHMDB, experimental results show that our approach achieves good recognition results. The recognition rate is better than that of most existing action recognition methods.
C1 [Zhou, Tongchi; Tao, Aimin; Sun, Liangfeng; Qu, Boyang; Wang, Yanzhao; Huang, Hu] Zhongyuan Univ Technol, Coll Elect Informat, Zhengzhou 451191, Peoples R China.
C3 Zhongyuan University of Technology
RP Tao, AM (corresponding author), Zhongyuan Univ Technol, Coll Elect Informat, Zhengzhou 451191, Peoples R China.
EM tony2016edu@zut.edu.cn
RI Huang, Hu/A-3650-2012
OI Tao, Aimin/0000-0002-2478-4458
FU National Natural Science Foundation of China [61976237]; China Textile
   Industry Federation [2018107]; Key scientific research project of
   colleges and universities in Henan Province [20B120004]
FX Fund Project of National Natural Science Foundation of China (No.
   61976237), China Textile Industry Federation under Grant (No. 2018107),
   Key scientific research project of colleges and universities in Henan
   Province (No. 20B120004).
CR Ballas N., 2015, arXiv
   Bhattacharya S, 2011, PROC CVPR IEEE
   Chen K, 2021, ARXIV
   Dai C, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105820
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Fan YB, 2020, IEEE ACCESS, V8, P15280, DOI 10.1109/ACCESS.2020.2968054
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Gammulle H, 2017, IEEE WINT CONF APPL, P177, DOI 10.1109/WACV.2017.27
   Graves A, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P273, DOI 10.1109/ASRU.2013.6707742
   Guo YJ, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18030073
   Hua M, 2021, COMPUT AIDED GEOM D, V85, DOI 10.1016/j.cagd.2021.101965
   Ijjina EP, 2016, APPL SOFT COMPUT, V46, P936, DOI 10.1016/j.asoc.2015.08.025
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Ji YL, 2020, IEEE T IMAGE PROCESS, V29, P2742, DOI 10.1109/TIP.2019.2952088
   Jiang YG, 2018, IEEE T MULTIMEDIA, V20, P3137, DOI 10.1109/TMM.2018.2823900
   Kingma D. P., 2014, arXiv
   Li ZY, 2018, COMPUT VIS IMAGE UND, V166, P41, DOI 10.1016/j.cviu.2017.10.011
   Liu HZ, 2021, IEEE T BIG DATA, V7, P341, DOI 10.1109/TBDATA.2018.2867485
   Liu J, 2018, IEEE T IMAGE PROCESS, V27, P1586, DOI 10.1109/TIP.2017.2785279
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Lu JS, 2015, PROC CVPR IEEE, P3762, DOI 10.1109/CVPR.2015.7299000
   Ma CY, 2019, SIGNAL PROCESS-IMAGE, V71, P76, DOI 10.1016/j.image.2018.09.003
   Majd M, 2020, NEUROCOMPUTING, V396, P224, DOI 10.1016/j.neucom.2018.10.095
   Meng B, 2018, MULTIMED TOOLS APPL, V77, P26901, DOI 10.1007/s11042-018-5893-9
   Muhammad K, 2021, FUTURE GENER COMP SY, V125, P820, DOI 10.1016/j.future.2021.06.045
   Nazir S, 2018, PATTERN RECOGN LETT, V103, P39, DOI 10.1016/j.patrec.2017.12.024
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Pan ZG, 2020, SIGNAL PROCESS-IMAGE, V83, DOI 10.1016/j.image.2020.115784
   Pareek P, 2021, ARTIF INTELL REV, V54, P2259, DOI 10.1007/s10462-020-09904-8
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Ramasinghe S, 2019, IEEE T CIRC SYST VID, V29, P2693, DOI 10.1109/TCSVT.2017.2760858
   Ren L., 2010, FUTURE COMPUTER COMM, V3, pV3
   Shi ZY, 2017, PROC CVPR IEEE, P4684, DOI 10.1109/CVPR.2017.498
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2015, PR MACH LEARN RES, V37, P843
   Tang H, 2019, NEUROCOMPUTING, V331, P424, DOI 10.1016/j.neucom.2018.11.038
   Tu ZG, 2019, IEEE T IMAGE PROCESS, V28, P2799, DOI 10.1109/TIP.2018.2890749
   Tu ZG, 2018, PATTERN RECOGN, V79, P32, DOI 10.1016/j.patcog.2018.01.020
   van den Oord A, 2016, PR MACH LEARN RES, V48
   Wang CW, 2017, 2017 IEEE CONFERENCE ON DEPENDABLE AND SECURE COMPUTING, P115, DOI 10.1109/DESEC.2017.8073802
   Wang HR, 2012, PATTERN RECOGN, V45, P3902, DOI 10.1016/j.patcog.2012.04.024
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wu B, 2020, COMPUT APPL, P331
   Xu WR, 2019, NEUROCOMPUTING, V333, P351, DOI 10.1016/j.neucom.2019.01.008
   Yan A, 2019, PROC CVPR IEEE, P7914, DOI 10.1109/CVPR.2019.00811
   Ye JM, 2018, PROC CVPR IEEE, P9378, DOI 10.1109/CVPR.2018.00977
   Yu TZ, 2018, PATTERN RECOGN LETT, V112, P226, DOI 10.1016/j.patrec.2018.07.034
   Zhang HB, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051005
   Zhang PF, 2019, IEEE T PATTERN ANAL, V41, P1963, DOI 10.1109/TPAMI.2019.2896631
   Zhang X., 2020, P IEEE CVF C COMP VI, P14333, DOI DOI 10.1109/CVPR42600202001434
   Zhou TC, 2016, THESIS SE U
   Zhu YQ, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P802, DOI 10.1145/3343031.3350932
NR 53
TC 1
Z9 1
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 45471
EP 45488
DI 10.1007/s11042-023-15501-y
EA MAY 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:001033146000009
DA 2024-07-18
ER

PT J
AU Gnanalakshmi, V
   Indumathi, G
AF Gnanalakshmi, V
   Indumathi, G.
TI A review on image steganographic techniques based on optimization
   algorithms for secret communication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Steganography; Optimization techniques; PSNR; Payload capacity
ID SPATIAL DOMAIN
AB This review paper explores the use of optimization techniques in steganography, the art of hiding secret information within other data. Steganography is a field that has gained significant attention in recent years due to the increasing need for secure communication and data protection. Optimization techniques have been shown to be effective in improving the performance of steganography systems, particularly in terms of maximizing the amount of secret data that can be hidden while minimizing the impact on the cover data. This paper provides a comprehensive overview of the state-of-the-art optimization techniques in steganography, including genetic algorithms, particle swarm optimization, ant colony optimization and fruit fly optimization algorithm. This paper also discusses the advantages and limitations of these techniques and their potential for further development in the future. Also the state-of-the-art methods were compared in terms of PSNR (Peak Signal to Noise Ratio), payload capacity, SSIM (Structured Similarity Index) etc. The review concludes by highlighting the importance of optimization techniques in steganography and their potential impact on the development of more efficient and secure steganography systems.
C1 [Gnanalakshmi, V; Indumathi, G.] Mepco Schelnk Engn Coll, Dept ECE, Sivakasi, India.
C3 Mepco Schlenk Engineering College
RP Gnanalakshmi, V (corresponding author), Mepco Schelnk Engn Coll, Dept ECE, Sivakasi, India.
EM v.gnanalakshmi@mepcoeng.ac.in; gindu@mepcoeng.ac.in
RI G, Indumathi/L-8507-2019
OI G, Indumathi/0000-0002-7760-1387
CR Al-Shatanawi OM, 2015, INT J NETW SECUR APP, V7
   Ambika, 2020, HEALTH TECHNOL-GER, V10, P231, DOI 10.1007/s12553-018-00289-x
   Arivazhagan S, 2019, INT J ENG ADV TECHNO, V8
   Banharnsakun A, 2018, MULTIMED TOOLS APPL, V77, P27491, DOI 10.1007/s11042-018-5933-5
   Bedi P, 2013, COMPUT ELECTR ENG, V39, P640, DOI 10.1016/j.compeleceng.2012.12.021
   Bhandari M., 2022, P 2022 2 INT C INN P, VVolume 2, P429, DOI 10.1109/ICIPTM54933.2022.9753917
   Hemanth DJ, 2016, OPEN PHYS, V14, P452, DOI 10.1515/phys-2016-0052
   Jaradat A, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6679284
   Kamdar NP., 2013, J INFORM KNOWLEDGE R, V2, P505
   Kaur A, 2015, 2015 1ST INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), P990, DOI 10.1109/NGCT.2015.7375269
   Kaur G, 2023, ARTIF INTELL REV, V56, P1577, DOI 10.1007/s10462-022-10211-7
   Li XX, 2007, INFORM SCIENCES, V177, P3099, DOI 10.1016/j.ins.2007.02.008
   Lima R., 2017, INT J COMPUT APPL, V164, P1, DOI 10.5120/ijca2017913686
   Miri A, 2017, OPTIK, V145, P158, DOI 10.1016/j.ijleo.2017.07.043
   Mohsin AH, 2019, IEEE ACCESS, V7, P168994, DOI 10.1109/ACCESS.2019.2949622
   Muhuri PK, 2020, APPL SOFT COMPUT, V92, DOI 10.1016/j.asoc.2020.106257
   Rabevohitra FH, 2011, LECT NOTES COMPUT SC, V6728, P212, DOI 10.1007/978-3-642-21515-5_25
   Rani M., 2022, and AI for Cybersecurity and Critical Infrastructure in SmartCities, P73
   Kiruba RR, 2021, MULTIDIM SYST SIGN P, V32, P405, DOI 10.1007/s11045-019-00697-w
   Sabeti V, 2022, COMPUT ELECTR ENG, V99, DOI 10.1016/j.compeleceng.2022.107809
   Sajedi H, 2010, INT J INF SECUR, V9, P337, DOI 10.1007/s10207-010-0112-3
   Sajedi H, 2009, INT J INF SECUR, V8, P433, DOI 10.1007/s10207-009-0089-y
   Selvaraj A, 2021, IET IMAGE PROCESS, V15, P504, DOI 10.1049/ipr2.12043
   Soleimanpour M, 2013, IRAN J ELECT ELECT E, V9
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wazirali R, 2019, IEEE ACCESS, V7, P133496, DOI 10.1109/ACCESS.2019.2941440
NR 26
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 44245
EP 44258
DI 10.1007/s11042-023-15568-7
EA MAY 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000982739000015
DA 2024-07-18
ER

PT J
AU Mendhe, N
   Vidyarthi, A
AF Mendhe, Nilesh
   Vidyarthi, Abhay
TI An effective hybrid approach based control for the MPPT of PV system
   under partial shading condition for indoor energy harvesting in smart
   homes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE PV system; Partial shading; MPPT; P&o; Aquila optimization; Bird swarm
   algorithm; Hybrid algorithm; Bird swarm fostered Aquila optimization
ID POWER POINT TRACKING; PHOTOVOLTAIC SYSTEMS; BAT ALGORITHM; OPTIMIZATION
AB Renewable radiation is a natural, natural resource that is simultaneously permanent and unrenewable. The two key elements that influence the performance of a PV system are irradiation and temperature. Partial shade, on the other hand, causes a nonlinear maximum power point tracking (MPPT) issue in PV systems. The PV array's P-V characteristics have more than one MPP when exposed to non-uniform solar irradiation. This situation makes tracking MPP more difficult and reduces the PV system's efficiency. This article proposes a hybrid optimization of Aquila optimization (AO) and Bird Swarm Algorithm (BSA) assisted MPPT controller to monitor peak energy in various weather conditions for the MPPT of PV System under partial shading condition for Indoor energy harvesting in smart homes. Finally, the proposed Bird Swarm Fostered Aquila Optimization (BSFAO) assisted MPPT control is compared to that of the standard methods like perturb and observe (P&O), Harris Hawks Optimization (HHO), Bird Swarm Algorithm (BSA), Aquila Optimization (AO). The proposed BSFAO method displays higher MPPT performance and a rapid convergence at the global maxima. Thus, the suggested hybrid (BSFAO) formed MPPT approach provides faster MPPT. The results proved that the suggested BSFAO model has achieved enhanced power tracking efficiency of 99.61% for every shading design when compared to the existing methodology and attained a reduced computational burden (3717.63) approximately, for all shading conditions respectively.
C1 [Mendhe, Nilesh; Vidyarthi, Abhay] VIT Univ, Dept Elect & Elect Engn, Bhopal, Madhya Pradesh, India.
C3 VIT Bhopal University
RP Mendhe, N (corresponding author), VIT Univ, Dept Elect & Elect Engn, Bhopal, Madhya Pradesh, India.
EM nileshmendhe170@gmail.com
CR Abualigah L, 2021, COMPUT IND ENG, V157, DOI 10.1016/j.cie.2021.107250
   Ahmed J, 2015, RENEW SUST ENERG REV, V47, P933, DOI 10.1016/j.rser.2015.03.080
   Avila L, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106711
   Chowdhury SR, 2010, SOL ENERG MAT SOL C, V94, P1441, DOI 10.1016/j.solmat.2010.04.011
   da Rocha MV, 2020, SUSTAIN ENERGY TECHN, V40, DOI 10.1016/j.seta.2020.100761
   Eltamaly Ali M., 2020, Sustainability, V12, DOI 10.3390/su12031185
   Eltamaly AM, 2018, SOL ENERGY, V174, P940, DOI 10.1016/j.solener.2018.09.060
   Femia N, 2005, IEEE T POWER ELECTR, V20, P963, DOI 10.1109/TPEL.2005.850975
   Heidari AA, 2019, FUTURE GENER COMP SY, V97, P849, DOI 10.1016/j.future.2019.02.028
   Houam Y, 2021, J ELECTR ENG TECHNOL, V16, P381, DOI 10.1007/s42835-020-00590-8
   Ibrahim Al-wesabi, 2020, Chinese Journal of Electrical Engineering, V6, P106, DOI 10.23919/CJEE.2020.000035
   Ishaque K, 2013, IEEE T IND ELECTRON, V60, P3195, DOI 10.1109/TIE.2012.2200223
   Jiang LL, 2014, 2014 IEEE 40TH PHOTOVOLTAIC SPECIALIST CONFERENCE (PVSC), P782, DOI 10.1109/PVSC.2014.6925034
   Joisher M, 2020, IEEE ACCESS, V8, P38481, DOI 10.1109/ACCESS.2020.2975742
   Kaced K, 2017, SOL ENERGY, V158, P490, DOI 10.1016/j.solener.2017.09.063
   Koizumi H, 2005, IEEE POWER ELECTRON, P2081, DOI 10.1109/PESC.2005.1581919
   Kumar N, 2017, IEEE T ENERGY CONVER, V32, P983, DOI 10.1109/TEC.2017.2669518
   Meng XB, 2016, J EXP THEOR ARTIF IN, V28, P673, DOI 10.1080/0952813X.2015.1042530
   Mirza AF, 2019, SOL ENERGY, V184, P628, DOI 10.1016/j.solener.2019.04.034
   Mohammad ANM, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12145786
   Mohanty SR, 2015, IEEE T SUSTAIN ENERG, V6, P122, DOI 10.1109/TSTE.2014.2362797
   Nugraha DA, 2019, CAN J ELECT COMPUT E, V42, P173, DOI 10.1109/CJECE.2019.2914723
   Obukhov S, 2020, IEEE ACCESS, V8, P20770, DOI 10.1109/ACCESS.2020.2966430
   Ram JP, 2017, APPL ENERG, V201, P45, DOI 10.1016/j.apenergy.2017.05.102
   Rezk H, 2019, RENEW SUST ENERG REV, V115, DOI 10.1016/j.rser.2019.109372
   Rezk H, 2017, RENEW SUST ENERG REV, V74, P377, DOI 10.1016/j.rser.2017.02.051
   Seyedmahmoudian M, 2015, IEEE T SUSTAIN ENERG, V6, P850, DOI 10.1109/TSTE.2015.2413359
   Subha R, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON ELECTRICAL ENERGY SYSTEMS (ICEES), P232, DOI 10.1109/ICEES.2016.7510646
   Surawdhaniwar S., 2012, International Journal of Advanced Research in Computer Engineering and Technology, V1, P106
   Wu ZQ, 2018, APPL SOFT COMPUT, V62, P101, DOI 10.1016/j.asoc.2017.10.039
   Yang CC, 2020, MICROSYST TECHNOL, V26, P195, DOI 10.1007/s00542-019-04544-7
   Zhang W, 2019, IEEE ACCESS, V7, P160091, DOI 10.1109/ACCESS.2019.2950375
NR 32
TC 2
Z9 2
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 46717
EP 46740
DI 10.1007/s11042-023-15069-7
EA MAY 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000979972200001
DA 2024-07-18
ER

PT J
AU Wang, X
AF Wang, Xiao
TI Detection of natural wood defects with large color differences based on
   branched network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Wood knot; Deep learning; Defect identification; Double
   detection; Image segmentation
ID IDENTIFICATION; CLASSIFICATION
AB Computer vision is regarded as a promising technology which can achieve automatic surface defects detection in wood industry to reduce the manual works and improve reliability. In this study, an efficient algorithm used for natural wood defects detection is proposed based on computer vision. To cope with large color differences of natural defects, branched network architecture is proposed where two networks are trained separately to deal with two extremes of the wood defects: light and dark color. To avoid repeated identification caused by the double detection of the two branches, "Inter-Class suppression" is proposed to remain the real class. Area dividing process is also introduced to implement before the detection work in order to reduce the computing cost. The whole network is constructed under the framework of Region proposal network(RPN) in order to locate the defects. Results show that the proposed model can successfully detect live and dark defects which have totally different colors. More specifically, the use of branched network will enhance the feature expression of live knot which is thought to lack of specific feature. Such a strategy improves the performance on live knot identification which cannot be easily achieved by regular deep learning method. Meanwhile, area dividing can remarkably reduce the running time because it decreases the searching area for the objects detection.
C1 [Wang, Xiao] Chinese Acad Forestry, Res Inst Wood Ind, 1 Dongxiaofu, Xiangshan Rd, Beijing 100091, Peoples R China.
C3 Chinese Academy of Forestry; Research Institute of Wood Industry, CAF
RP Wang, X (corresponding author), Chinese Acad Forestry, Res Inst Wood Ind, 1 Dongxiaofu, Xiangshan Rd, Beijing 100091, Peoples R China.
EM wx_dykm@126.com
FU special fund of basic research funding of Chinese central nonprofit
   research institutions [CAFYBB2022ZC004-2]
FX AcknowledgementsThis work is supported by the special fund of basic
   research funding of Chinese central nonprofit research
   institutions(CAFYBB2022ZC004-2).
CR Bhargava A, 2020, MULTIMED TOOLS APPL, V79, P7857, DOI 10.1007/s11042-019-08564-3
   Chacon MI, 2006, LECT NOTES COMPUT SC, V3973, P1105
   Ding FL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185315
   Du XC, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101778
   Fan Jian-an, 2020, World Forestry Research, V33, P32, DOI 10.13348/j.cnki.sjlyyj.2020.0020.y
   Gao XW, 2019, ADV STRUCT ENG, V22, P2907, DOI 10.1177/1369433219849829
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He T, 2020, MEASUREMENT, V152, DOI 10.1016/j.measurement.2019.107357
   Hittawe MM, 2015, IEEE IMAGE PROC, P427, DOI 10.1109/ICIP.2015.7350834
   Hu K, 2020, BIORESOURCES, V15, P3041, DOI 10.15376/biores.15.2.3041-3052
   Kamal K, 2017, ADV ENG INFORM, V34, P125, DOI 10.1016/j.aei.2017.09.007
   Kurdthongmee W, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e03480
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Luo Wei Luo Wei, 2019, Journal of Northeast Forestry University, V47, P70
   Mahram A, 2012, 2012 35TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P749, DOI 10.1109/TSP.2012.6256397
   Negi A., 2021, Agricultural Informatics: Automation using the IoT and Machine Learning, P117, DOI [10.1002/9781119769231.ch6, DOI 10.1002/9781119769231.CH6]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shi JH, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20164398
   Urbonas A, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9224898
   Nguyen VT, 2020, COMPUT ELECTRON AGR, V171, DOI 10.1016/j.compag.2020.105332
   Wan SH, 2020, COMPUT NETW, V168, DOI 10.1016/j.comnet.2019.107036
   Wang LH, 2009, COMPUT ELECTRON AGR, V69, P142, DOI 10.1016/j.compag.2009.07.019
   Wang QP, 2019, EUR J WOOD WOOD PROD, V77, P1053, DOI 10.1007/s00107-019-01459-y
   Wang X, 2020, MEASUREMENT, V151, DOI 10.1016/j.measurement.2019.107262
   Wei RB, 2020, ISIJ INT, V60, P539, DOI 10.2355/isijinternational.ISIJINT-2019-335
   Xiang ZY, 2016, CHIN CONTR CONF, P4202, DOI 10.1109/ChiCC.2016.7554010
   Xie YH, 2015, OPTIK, V126, P2231, DOI 10.1016/j.ijleo.2015.05.101
   Zhang YZ, 2015, OPT ENG, V54, DOI 10.1117/1.OE.54.10.103102
NR 30
TC 1
Z9 1
U1 9
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 44719
EP 44739
DI 10.1007/s11042-023-15487-7
EA MAY 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000982739000010
DA 2024-07-18
ER

PT J
AU Mohebbian, MR
   Chafjiri, FS
   Vedaei, SS
   Wahid, KA
AF Mohebbian, Mohammad Reza
   Chafjiri, Fatemeh Sedighipour
   Vedaei, Seyed Shahim
   Wahid, Khan A.
TI CFA image compression using an efficient cascaded overlapping color
   transformation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CFA image; Lossless compression; Haar wavelet
ID FILTER-ARRAY IMAGES; LOSSLESS COMPRESSION; DESIGN; SYSTEM
AB Bayer Color-Filter-Array (CFA) is commonly used in single-chip digital image sensors as it efficiently approximates the physiology of the human eye. These sensors capture only one color component per pixel, not an entire RGB image. Conventionally, a Bayer CFA image is converted to an RGB image, and then compressed for processing and storage. However, storing a Bayer CFA image before converting to RGB can preserve more details, which is preferable for post-processing tasks. Due to the arrangement of color channels in a CFA image, compression algorithms cannot efficiently reduce the size of the raw CFA image. In this paper, a Cascade Overlapping Color Transformation (COCT) method is proposed and implemented. In the first step, the Haar Wavelet Transform (HWT) is performed on the image to reduce the spectral redundancy. The second step of the color transformation reduces the redundancy of color components even higher, resulting in a color map that can be compressed better using an image coding system. Experiments performed on several datasets showed that the COCT improves the compression ratio compared to the state-of-the-art techniques. The proposed method improved the compression ratio by 17.6% and 15.6% for 16 bpp and 8 bpp CFA images, respectively. Computational load has also been improved by the proposed method. In addition, the hardware implementation is discussed using a CMOS 65 nm technology that costs 3.18 K gates and 2.05 mW of power.
C1 [Mohebbian, Mohammad Reza; Chafjiri, Fatemeh Sedighipour; Vedaei, Seyed Shahim; Wahid, Khan A.] Univ Saskatchewan, Dept Elect & Comp Engn, Saskatoon, SK S7N 5A9, Canada.
C3 University of Saskatchewan
RP Chafjiri, FS (corresponding author), Univ Saskatchewan, Dept Elect & Comp Engn, Saskatoon, SK S7N 5A9, Canada.
EM fas303@usask.ca
CR Adams MD, 2002, IEEE T SIGNAL PROCES, V50, P2831, DOI [10.1109/TSP.2002.804085, 10.1109/FSP.2002.804085]
   Andriani S, 2013, IEEE IMAGE PROC, P2289, DOI 10.1109/ICIP.2013.6738472
   [Anonymous], KOD DAT
   [Anonymous], NIK DAT
   Bjontegaard G, 2001, VCEGM33
   Bohme R., 2012, DIGITAL IMAGE FORENS, P327, DOI [DOI 10.1007/978-1-4614-0757-7_12, 10.1007/978-1-4614-0757-7_12]
   BRUEKERS FAML, 1992, IEEE J SEL AREA COMM, V10, P130
   Chen CA, 2019, IEEE ACCESS, V7, P107046, DOI 10.1109/ACCESS.2019.2930818
   Chen H, 2009, IEEE T CIRC SYST VID, V19, P1891, DOI 10.1109/TCSVT.2009.2031370
   Chen SC, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240847
   Chen SL, 2016, IEEE ACCESS, V4, P10235, DOI 10.1109/ACCESS.2016.2638475
   Chen SL, 2015, J MED IMAG HEALTH IN, V5, P378, DOI 10.1166/jmihi.2015.1403
   Chen XK, 2009, IEEE T BIOMED CIRC S, V3, P11, DOI 10.1109/TBCAS.2008.2006493
   Chen XK, 2007, IEEE ASIAN SOLID STA, P184, DOI 10.1109/ASSCC.2007.4425761
   Chervyakov N, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10041223
   Dang-Nguyen D.T., 2015, P ACM MULT SYST C, P219
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   Dorobantiu A, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9132681
   Ferroukhi M, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8010088
   Khan TH, 2011, VLSI DES, DOI 10.1155/2011/343787
   Kim S, 2014, IEEE T CIRC SYST VID, V24, P1040, DOI 10.1109/TCSVT.2014.2302546
   Li CC, 2022, IEEE ACCESS, V10, P88632, DOI 10.1109/ACCESS.2022.3199737
   Li J, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11070759
   Liu F, 2017, INFORMATION, V8, DOI 10.3390/info8040131
   Lukac R, 2005, IEEE T CONSUM ELECTR, V51, P1260, DOI 10.1109/TCE.2005.1561853
   Rahman KMM, 2021, SIGNAL IMAGE VIDEO P, V15, P1767, DOI 10.1007/s11760-021-01921-6
   Malvar HS, 2012, IEEE DATA COMPR CONF, P3, DOI 10.1109/DCC.2012.8
   Merlino P, 2009, IEEE T VLSI SYST, V17, P967, DOI 10.1109/TVLSI.2008.2009188
   Mohammed SK, 2018, IET IMAGE PROCESS, V12, P1485, DOI 10.1049/iet-ipr.2017.1401
   Mohammed SK, 2017, IEEE ACCESS, V5, P13823, DOI 10.1109/ACCESS.2017.2726997
   Palum R, 2001, PICS 2001: IMAGE PROCESSING, IMAGE QUALITY, IMAGE CAPTURE, SYSTEMS CONFERENCE, PROCEEDINGS, P239
   Parmar M., 2004, 2004 IEEE International Conference on Acoustics, Speech, and Signal Processing, piii
   Rojas-Hernández R, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24070951
   Starosolski R, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22121385
   Starosolski R, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22070751
   Suzuki T, 2020, IEEE T IMAGE PROCESS, V29, P433, DOI 10.1109/TIP.2019.2928124
   Tashan T, 2018, IET IMAGE PROCESS, V12, P2186, DOI 10.1049/iet-ipr.2018.5611
   Turcza P, 2022, SIGNAL PROCESS-IMAGE, V106, DOI 10.1016/j.image.2022.116716
   Xiang Xie, 2004, Proceedings. Third International Conference on Image and Graphics, P357
   Zhang F, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8121559
NR 40
TC 1
Z9 1
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43233
EP 43250
DI 10.1007/s11042-023-15352-7
EA APR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000976628900001
DA 2024-07-18
ER

PT J
AU Lee, JY
   Choi, Y
   Van Le, T
   Choi, K
AF Lee, Jin Young
   Choi, Yongho
   Van Le, The
   Choi, Kiho
TI Efficient feature coding based on performance analysis of Versatile
   Video Coding (VVC) in Video Coding for Machines (VCM)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Versatile video coding (VVC); Video coding for machines (VCM); Video
   captioning
AB Conventional video coding standards offer efficient compression of traditional 2D images. In particular, versatile video coding (VVC), which is the latest video coding standard, achieves very high compression efficiency, while maintaining high visual quality for humans. On the other hand, video coding for machines (VCM), which is developed as a new style of a video coding standard, mainly targets efficient compression of features extracted from deep neural networks. It generally employs VVC for feature coding. However, since VVC was developed for traditional images, an influence of the VVC based feature coding on VCM is not clear. Therefore, this paper proposes efficient tool combination by analyzing performance of VVC coding tools for the VCM feature coding, and then applies it into video captioning, which automatically generates natural language descriptions from videos. Experimental results show that the proposed tool combination is very efficient, in terms of coding performance and encoding complexity.
C1 [Lee, Jin Young; Choi, Yongho; Van Le, The] Sejong Univ, Dept Intelligent Mechatron Engn, Seoul, South Korea.
   [Choi, Kiho] Kyung Hee Univ, Dept Elect Engn, Yongin, South Korea.
   [Choi, Kiho] Kyung Hee Univ, Dept Elect & Informat Convergence Engn, Yongin, South Korea.
C3 Sejong University; Kyung Hee University; Kyung Hee University
RP Choi, K (corresponding author), Kyung Hee Univ, Dept Elect Engn, Yongin, South Korea.; Choi, K (corresponding author), Kyung Hee Univ, Dept Elect & Informat Convergence Engn, Yongin, South Korea.
EM aikiho@khu.ac.kr
RI Choi, Kiho/HPE-3499-2023
OI Choi, Kiho/0000-0002-2869-0440; Choi, Yongho/0000-0002-5953-5312; Le,
   The/0000-0001-8568-4023
FU Institute of Information & communications Technology Planning &
   Evaluation(IITP) - Korea government(MSIT) [IITP-2021-0-02067,
   IITP-2022-RS-2022-00156345]; National Research Foundation of Korea(NRF)
   - Korean government(MSIT) [NRF-2021R1F1A1060816]
FX This work was supported by the Institute of Information & communications
   Technology Planning & Evaluation(IITP) grant funded by the Korea
   government(MSIT) (IITP-2021-0-02067, IITP-2022-RS-2022-00156345) and the
   National Research Foundation of Korea(NRF) grant funded by the Korean
   government(MSIT) (NRF-2021R1F1A1060816).
CR Aafaq N, 2019, PROC CVPR IEEE, P12479, DOI 10.1109/CVPR.2019.01277
   Alexander A, 2016, IEEE DATA COMPR CONF, P83, DOI 10.1109/DCC.2016.125
   [Anonymous], 2022, JTC1SC29WG2 ISOIEC
   Baroncini V., 2020, doc. JVET-T2020
   Bjontegaard G., 2008, VCEGAI11
   Bossen F, 2019, JVETN1010 ITUTISOIEC
   Bross B, 2018, JVETL0283 ITUTISOIEC
   Chen D., 2011, P 49 ANN M ASS COMP, P190
   Chen H, 2018, JVETJ0063 ITUTISOIEC
   Chen H, 2018, JVETL0369 ITUTISOIEC
   Chen J, 2016, JVETD0123 ITUTISOIEC
   Chen W, 2020, JVETT0013 ITUTISOIEC
   Chiang M-S, 2018, JVETL0100 ITUTISOIEC
   Choi K, 2018, JVETK0171 ITUTISOIEC
   Choi K, 2020, IEEE SIGNAL PROC MAG, V37, P160, DOI 10.1109/MSP.2020.2971765
   De-Luxán-Hernández S, 2019, IEEE IMAGE PROC, P1203, DOI [10.1109/ICIP.2019.8803777, 10.1109/icip.2019.8803777]
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, DOI [10.3115/v1/W14-3348, DOI 10.3115/V1/W14-3348]
   Gao H, 2021, IEEE T CIRC SYST VID, V31, P3603, DOI 10.1109/TCSVT.2020.3040291
   He Y, 2019, JVETO0070 ITUTISOIEC
   Helle P, 2019, IEEE DATA COMPR CONF, P448, DOI 10.1109/DCC.2019.00053
   High Efficient Video Coding (HEVC), 2013, ITU T RECOMMENDATION
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jeong S, 2018, JVETL0054 ITUTISOIEC
   Karczewicz M, 2021, IEEE T CIRC SYST VID, V31, P3907, DOI 10.1109/TCSVT.2021.3072297
   Koo M, 2019, PICT COD SYMP, DOI 10.1109/pcs48520.2019.8954507
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee JY, 2019, MULTIMED TOOLS APPL, V78, P31793, DOI 10.1007/s11042-019-08011-3
   Lei Z, 2021, FUTURE INTERNET, V13, DOI 10.3390/fi13020055
   Li JR, 2020, IEEE DATA COMPR CONF, P203, DOI 10.1109/DCC47342.2020.00028
   Li L, 2018, IEEE T CIRC SYST VID, V28, P1934, DOI 10.1109/TCSVT.2017.2699919
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Nabati M, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102302
   Pan YW, 2017, PROC CVPR IEEE, P984, DOI 10.1109/CVPR.2017.111
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Schwarz H, 2018, JVETK0071 ITUTISOIEC
   Sethuraman S, 2019, JVETM0147 ITUTISOIEC
   Su Y-C, 2018, JVETL0646 ITUTISOIEC
   Szegedy C., 2016, ARXIV
   Van der Auwera G, 2018, JVETJ0023 ITUTISOIEC
   vcgit hhi, VVC REFERENCE SOFTWA
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Venugopalan S, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301326
   Versatile Video Coding (VVC), 2020, ITU T RECOMMENDATION
   Xu XZ, 2019, PICT COD SYMP, DOI 10.1109/pcs48520.2019.8954512
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yu-Wen Huang, 2021, IEEE Transactions on Circuits and Systems for Video Technology, V31, P3818, DOI 10.1109/TCSVT.2021.3088134
   Zhang L, 2018, JVETL0266 ITUTISOIEC
   Zhang Y, 2016, IEEE T CIRC SYST VID, V26, P950, DOI 10.1109/TCSVT.2015.2426552
   Zhang Y, 2013, INT CONF DIGIT SIG
   Zhang Y, 2013, PICT COD SYMP, P353, DOI 10.1109/PCS.2013.6737756
   Zhao Y, 2018, JVETK0139 ITUTISOIEC
NR 51
TC 0
Z9 0
U1 8
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42803
EP 42816
DI 10.1007/s11042-023-15409-7
EA APR 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000977223400001
DA 2024-07-18
ER

PT J
AU Shetty, S
   Ananthanarayana, VS
   Mahale, A
AF Shetty, Shashank
   Ananthanarayana, V. S. V.
   Mahale, Ajit
TI Multimodal medical tensor fusion network-based DL framework for
   abnormality prediction from the radiology CXRs and clinical text reports
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Clinical recommendation systems; Multimodality; Deep learning; Disease
   prediction; Tensor fusion networks; Radiology
ID DECISION-SUPPORT; DEEP; INFORMATION; QUALITY
AB Pulmonary disease is a commonly occurring abnormality throughout this world. The pulmonary diseases include Tuberculosis, Pneumothorax, Cardiomegaly, Pulmonary atelectasis, Pneumonia, etc. A timely prognosis of pulmonary disease is essential. Increasing progress in Deep Learning (DL) techniques has significantly impacted and contributed to the medical domain, specifically in leveraging medical imaging for analysis, prognosis, and therapeutic decisions for clinicians. Many contemporary DL strategies for radiology focus on a single modality of data utilizing imaging features without considering the clinical context that provides more valuable complementary information for clinically consistent prognostic decisions. Also, the selection of the best data fusion strategy is crucial when performing Machine Learning (ML) or DL operation on multimodal heterogeneous data. We investigated multimodal medical fusion strategies leveraging DL techniques to predict pulmonary abnormality from the heterogeneous radiology Chest X-Rays (CXRs) and clinical text reports. In this research, we have proposed two effective unimodal and multimodal subnetworks to predict pulmonary abnormality from the CXR and clinical reports. We have conducted a comprehensive analysis and compared the performance of unimodal and multimodal models. The proposed models were applied to standard augmented data and the synthetic data generated to check the model's ability to predict from the new and unseen data. The proposed models were thoroughly assessed and examined against the publicly available Indiana university dataset and the data collected from the private medical hospital. The proposed multimodal models have given superior results compared to the unimodal models.
C1 [Shetty, Shashank; Ananthanarayana, V. S. V.] Natl Inst Technol Karnataka, Dept Informat Technol, Mangalore 575025, Karnataka, India.
   [Shetty, Shashank] Nitte Deemed ddvb Univ, NMAM Inst Technol NMAMIT, Dept Comp Sci & Engn, Udupi 574110, Karnataka, India.
   [Mahale, Ajit] Manipal Acad Higher Educ, Kasturba Med Coll, Dept Radiol, Mangalore 575001, Karnataka, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka; Manipal Academy of Higher Education (MAHE);
   Kasturba Medical College, Mangalore
RP Shetty, S (corresponding author), Natl Inst Technol Karnataka, Dept Informat Technol, Mangalore 575025, Karnataka, India.; Shetty, S (corresponding author), Nitte Deemed ddvb Univ, NMAM Inst Technol NMAMIT, Dept Comp Sci & Engn, Udupi 574110, Karnataka, India.
EM shashankshetty.177it002@nitk.edu.in; ajit.mahale@manipal.edu
RI SHETTY, SHASHANK/AAU-4004-2020; S, A/AAE-2005-2020
OI SHETTY, SHASHANK/0000-0003-0182-4231; MAHALE, AJIT/0000-0001-6617-7333;
   , Ananthanarayana VS/0000-0001-6593-8938
CR Abadi M., 2015, TENSORFLOW LARGE SAC
   Agarap AF, 2018, ARXIV180308375, P1803
   Al-Damluji MS, 2015, CIRC-CARDIOVASC QUAL, V8, P109, DOI 10.1161/CIRCOUTCOMES.114.001476
   Alfarghaly Omar, 2021, Informatics in Medicine Unlocked, V24, DOI 10.1016/j.imu.2021.100557
   Araujo A., 2019, DISTILL, V4, P21, DOI 10.23915/distill.00021
   Aydin F, 2019, arXiv, DOI DOI 10.48550/ARXIV.1902.08888
   Banerjee I, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.8719
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Boonn WW, 2009, J DIGIT IMAGING, V22, P357, DOI 10.1007/s10278-008-9115-2
   Botsis Taxiarchis, 2010, Summit Transl Bioinform, V2010, P1
   Carvalho R, 2021, LECT NOTES COMPUT SC, V13017, P27, DOI 10.1007/978-3-030-90439-5_3
   Chen XW, 2014, IEEE ACCESS, V2, P514, DOI 10.1109/ACCESS.2014.2325029
   Cohen Mervyn D, 2007, J Am Coll Radiol, V4, P617, DOI 10.1016/j.jacr.2007.02.003
   Collobert R, 2011, Arxiv, DOI arXiv:1103.0398
   Comfere NI, 2014, INT J DERMATOL, V53, P549, DOI 10.1111/ijd.12330
   Bloice MD, 2017, Arxiv, DOI arXiv:1708.04680
   Dean NC, 2015, ANN EMERG MED, V66, P511, DOI 10.1016/j.annemergmed.2015.02.003
   Demner-Fushman D, 2016, J AM MED INFORM ASSN, V23, P304, DOI 10.1093/jamia/ocv080
   Devarakonda M, 2015, AAAI CONF ARTIF INTE, P3942
   Dunnmon J.A., 2018, Radiology, page, P181422
   Dvornik N, 2021, IEEE T PATTERN ANAL, V43, P2014, DOI 10.1109/TPAMI.2019.2961896
   Fukui A., 2016, arXiv
   Gajbhiye G, 2020, AUTOMATIC REPORT GEN, P174, DOI [10.1007/978-981-15-4015-8_15, DOI 10.1007/978-981-15-4015-8_15]
   Gehrmann S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0192360
   Goodfellow I., 2014, arXiv, DOI 10.48550/arXiv.1406.2661
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Hamidinekoo A, 2020, Arxiv, DOI [arXiv:2011.05410, 10.48550/ARXIV.2011.05410, DOI 10.48550/ARXIV.2011.05410]
   Hilmizen Naufal, 2020, 2020 3rd International Seminar on Research of Information Technology and Intelligent Systems (ISRITI), P26, DOI 10.1109/ISRITI51436.2020.9315478
   Hinton G. E., 2012, arXiv
   Hinton G, 2018, JAMA-J AM MED ASSOC, V320, P1101, DOI 10.1001/jama.2018.11100
   Huang SC, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-78888-w
   Ioffe S, 2015, Arxiv, DOI [arXiv:1502.03167, DOI 10.48550/ARXIV.1502.03167]
   Jindal R, 2015, PROCEDIA COMPUT SCI, V46, P314, DOI 10.1016/j.procs.2015.02.026
   Johnson AEW, 2019, SCI DATA, V6, DOI 10.1038/s41597-019-0322-0
   Jonas JB, 2017, LANCET, V390, P2183, DOI 10.1016/S0140-6736(17)31469-1
   Kharazmi P, 2018, SKIN RES TECHNOL, V24, P256, DOI 10.1111/srt.12422
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar E, 2020, Deep Learn. Techniq. Biomed. Health Inform, P79
   Kuperman GJ, 2007, J AM MED INFORM ASSN, V14, P29, DOI 10.1197/jamia.M2170
   Leslie A, 2000, BRIT J RADIOL, V73, P1052, DOI 10.1259/bjr.73.874.11271897
   Li HM, 2019, I S BIOMED IMAGING, P368, DOI 10.1109/ISBI.2019.8759397
   Liu G., 2019, MACHINE LEARNING HEA
   Liu GX, 2019, Arxiv, DOI arXiv:1904.02633
   Lopez K, 2020, FRONT BIG DATA, V3, DOI 10.3389/fdata.2020.00019
   Majkowska A, 2020, RADIOLOGY, V294, P421, DOI 10.1148/radiol.2019191293
   McDonald RJ, 2015, ACAD RADIOL, V22, P1191, DOI 10.1016/j.acra.2015.05.007
   Meystre S M, 2008, Yearb Med Inform, P128
   Nunes N, 2019, Deep Learning for Automatic Classification of Multi-Modal Information Corresponding to
   Ordóñez FJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010115
   Ouahab A, 2021, OPT MEMORY NEURAL, V30, P276, DOI 10.3103/S1060992X21040044
   Pandeya YR, 2021, MULTIMED TOOLS APPL, V80, P2887, DOI 10.1007/s11042-020-08836-3
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Person M, 2019, J DYN SYST-T ASME, V141, DOI 10.1115/1.4043222
   Purwar S, 2020, MULTIMED TOOLS APPL, V79, P4573, DOI 10.1007/s11042-019-07927-0
   Qiu Shangran, 2018, Alzheimers Dement (Amst), V10, P737, DOI 10.1016/j.dadm.2018.08.013
   Radford A, 2016, Arxiv, DOI [arXiv:1511.06434, DOI 10.48550/ARXIV.1511.06434]
   Rajpurkar P, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002686
   Ramachandram D, 2017, IEEE SIGNAL PROC MAG, V34, P96, DOI 10.1109/MSP.2017.2738401
   Reda I, 2018, TECHNOL CANCER RES T, V17, DOI 10.1177/1533034618775530
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Schmidhuber J, 2014, Arxiv, DOI [arXiv:1404.7828, DOI 10.1016/J.NEUNET.2014.09.003]
   Shetty S., 2020, P 21 EANN ENG APPL N, P352, DOI DOI 10.1007/978-3-030-48791-1_27
   Spasov SE, 2018, IEEE ENG MED BIO, P1271, DOI 10.1109/EMBC.2018.8512468
   Trzcinski T, 2018, PROC SPIE, V10808, DOI 10.1117/12.2501679
   Wang XS, 2018, PROC CVPR IEEE, P9049, DOI 10.1109/CVPR.2018.00943
   Wong C, 2015, AM J CLIN PATHOL, V143, P593, DOI 10.1309/AJCPHPG6DQFBKKUR
   Xing E., 2017, ACL
   Xu B, 2016, Arxiv, DOI arXiv:1602.05980
   Xu B, 2015, Arxiv, DOI [arXiv:1505.00853, DOI 10.48550/ARXIV.1505.00853]
   Xue Y, 2018, LECT NOTES COMPUT SC, V11070, P457, DOI 10.1007/978-3-030-00928-1_52
   Yala A, 2019, RADIOLOGY, V292, P60, DOI 10.1148/radiol.2019182716
   Yao Y, 2007, CONSTR APPROX, V26, P289, DOI 10.1007/s00365-006-0663-2
   Yoo Y, 2019, COMP M BIO BIO E-IV, V7, P250, DOI 10.1080/21681163.2017.1356750
   Yu F., 2015, ARXIV
   Yuan J, 2019, arXiv, DOI 10.48550/ARXIV.1907.09085
   Zhang YH, 2018, Arxiv, DOI [arXiv:1809.04698, 10.48550/arXiv.1809.04698]
   Zhao D, 2011, J BIOMED INFORM, V44, P859, DOI 10.1016/j.jbi.2011.05.004
NR 80
TC 3
Z9 3
U1 9
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 44431
EP 44478
DI 10.1007/s11042-023-14940-x
EA APR 2023
PG 48
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000972822600002
PM 37362656
OA Bronze
DA 2024-07-18
ER

PT J
AU Kumar, S
   Singh, J
   Fore, V
   Kumar, A
AF Kumar, Sunil
   Singh, Jasbir
   Fore, Vivudh
   Kumar, Amrish
TI Performance evaluation of ANFIS, ANN and RSM in biodiesel synthesis from
   Karanja oil with Domestic Microwave set up
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Microwave; Karanja oil; ANFIS; ANN; Box-Behnken design
ID RESPONSE-SURFACE METHODOLOGY; AVERAGING FUSION STRATEGY; FUZZY INFERENCE
   SYSTEM; L. SEED; OPTIMIZATION; TRANSESTERIFICATION; ALGORITHM;
   TECHNOLOGIES; PREDICTION; PARAMETERS
AB The research work presents the microwave-assisted transesterification process to transform the Karanja oil into biodiesel. The different optimization and modelling techniques were compared and parameters were optimized to obtain the highest yield. Adaptive neuro-fuzzy inference System (ANFIS), Artificial Neural Network (ANN) and Response Surface Methodology (RSM) are assessed in the transesterification of Karanja oil esterified with methanol in the appearance of NaOH as a catalyst with microwave power. The investigation was carried out by considering the time, methanol/oil mole ratio, volume and catalyst concentration parameters and using Box Behnken design for experimentation. Statistical performance gauge showed Root mean square error (RMSE), coefficient of determination (R-2) adjusted R-2, Sum of square error (SSE) and mean square error (MSE). A modified Domestic Microwave used for experimentation, which is functioning at 2450 MHz, the topmost power output of 700W attached with DC motor having 100 rpm for stirring action. The highest yield of 87.34% was extracted with optimized parameters of rection.
C1 [Kumar, Sunil; Singh, Jasbir; Fore, Vivudh; Kumar, Amrish] DU, FET Gurukula Kangri, Haridwar, India.
RP Kumar, S (corresponding author), DU, FET Gurukula Kangri, Haridwar, India.
EM Sunil508@rediffmail.com
RI Kumar, Sunil/GYV-0347-2022
OI Kumar, Sunil/0000-0002-1953-6273
CR Betiku E, 2016, ENERG CONVERS MANAGE, V124, P219, DOI 10.1016/j.enconman.2016.07.030
   Betiku E, 2015, RENEW ENERG, V76, P408, DOI 10.1016/j.renene.2014.11.049
   Chemat-Djenni Z, 2007, MOLECULES, V12, P1399, DOI 10.3390/12071399
   Chuah LF, 2017, J CLEAN PROD, V146, P181, DOI 10.1016/j.jclepro.2016.05.017
   Dharma S, 2017, J CLEAN PROD, V164, P618, DOI 10.1016/j.jclepro.2017.06.065
   Faried M, 2017, RENEW SUST ENERG REV, V79, P893, DOI 10.1016/j.rser.2017.05.199
   Flórez N, 2015, J CHEM TECHNOL BIOT, V90, P590, DOI 10.1002/jctb.4519
   Giwa S, 2010, ENERGIES, V3, P607, DOI 10.3390/en3040607
   Hariram V, 2019, DATA BRIEF, V25, DOI 10.1016/j.dib.2019.104298
   Jaliliannosrati H, 2013, BIORESOURCE TECHNOL, V136, P565, DOI 10.1016/j.biortech.2013.02.078
   JOGLEKAR AM, 1987, CEREAL FOOD WORLD, V32, P857
   Kanmani M, 2020, MULTIMED TOOLS APPL, V79, P17859, DOI 10.1007/s11042-020-08628-9
   Kanmani M, 2019, INT J BIOMED ENG TEC, V31, P278
   Kanmani M, 2019, MULTIDIM SYST SIGN P, V30, P1911, DOI 10.1007/s11045-019-00636-9
   Kanmani M, 2018, MULTIMED TOOLS APPL, V77, P12701, DOI 10.1007/s11042-017-4911-7
   Kumar S, 2022, ENERG SOURCE PART A, V44, P2284, DOI 10.1080/15567036.2019.1649331
   Kumar S, 2020, ENERG SOURCE PART A, V42, P1425, DOI 10.1080/15567036.2019.1604858
   Kumar S, 2018, ENERG SOURCE PART A, V40, P3000, DOI 10.1080/15567036.2018.1515277
   Kusumo F, 2017, ENERGY, V134, P24, DOI 10.1016/j.energy.2017.05.196
   Madheswari K, 2017, QUANT INFR THERM J, V14, P24, DOI 10.1080/17686733.2016.1229328
   Martinez-Guerra E, 2014, FUEL, V137, P100, DOI 10.1016/j.fuel.2014.07.087
   Meher LC, 2006, BIORESOURCE TECHNOL, V97, P1392, DOI 10.1016/j.biortech.2005.07.003
   Najafi B, 2018, ENG APPL COMP FLUID, V12, P611, DOI 10.1080/19942060.2018.1502688
   PETERSON ER, 1994, RES CHEM INTERMEDIAT, V20, P93, DOI 10.1163/156856794X00108
   Quan X, 2007, J MOL CATAL A-CHEM, V263, P216, DOI 10.1016/j.molcata.2006.08.079
   Sarve A, 2015, ULTRASON SONOCHEM, V26, P218, DOI 10.1016/j.ultsonch.2015.01.013
   Tangy A, 2017, BIORESOURCE TECHNOL, V224, P333, DOI 10.1016/j.biortech.2016.10.068
   Yaghoobi A, 2016, INT J ADV MANUF TECH, V86, P2667, DOI 10.1007/s00170-016-8349-2
   Zobel CW, 2011, ENG APPL ARTIF INTEL, V24, P803, DOI 10.1016/j.engappai.2011.03.001
NR 29
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42509
EP 42525
DI 10.1007/s11042-023-15253-9
EA APR 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000970495100005
DA 2024-07-18
ER

PT J
AU Talasila, S
   Rawal, K
   Sethi, G
AF Talasila, Srinivas
   Rawal, Kirti
   Sethi, Gaurav
TI Black gram disease classification using a novel deep convolutional
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Convolutional neural networks; Plant diseases; Black
   gram; Agriculture
ID RECOGNITION
AB Black gram, the king of pulses, also known as Urad in India, where it is cultivated from ancient times. India is the largest cultivator of black gram crop globally, and its production is declined year by year because of the diseases that occurred to the black gram plant leaves. The plant disease recognition and classification systems that rely on Convolutional Neural Networks (CNNs) have demonstrated encouraging results under limited and controlled circumstances. Such models are often constrained by a laeconomic losses to theck of consistency, making them less reliable. When detecting diseases with complicated background images taken from the cultivation field conditions, the models' accuracy would degrade drastically. To overcome this issue, firstly leaf region is segmented from all the images in the dataset using DeepLabv3 + layers with MobileNetV2 as a feature extractor. And then, the dataset was enhanced and expanded to 15000 images with the help of rotation, mirror symmetry, illumination correction, random shifting, and noise injection augmentation techniques. As a final step, proposed a Deep Convolutional Neural Network (DCNN) model for the identification and classification of black gram plant leaf diseases, taking into consideration of a large number of parameters, size, and depth of the available state-of-the-art CNNs. The proposed DCNN model was trained and tested on the segmented leaf regions from the images in Black gram Plant Leaf Disease (BPLD) Dataset, which was created from real cultivated fields. The 5-fold cross-validation technique was employed to check the proposed model's efficiency for detecting the diseases in all the scenarios. The performance evaluation and the investigation outcomes evident that the proposed DCNN model surpasses the state-of-the-art CNN algorithms with 99.54% accuracy, 98.80% F1 score, 98.78% precision and 98.82% recall for black gram plant leaf diseases classification and can provide a pragmatic solution for real-world applications.
C1 [Talasila, Srinivas; Rawal, Kirti; Sethi, Gaurav] Lovely Profess Univ, SEEE, Phagwara 144001, Punjab, India.
   [Talasila, Srinivas] VNR Vignana Jyothi Inst Engn & Technol, Dept ECE, Hyderabad 500090, India.
C3 Lovely Professional University; Vallurupalli Nageswara Rao Vignana
   Jyothi Institute of Engineering &Technology (VNR VJIET)
RP Talasila, S (corresponding author), Lovely Profess Univ, SEEE, Phagwara 144001, Punjab, India.; Talasila, S (corresponding author), VNR Vignana Jyothi Inst Engn & Technol, Dept ECE, Hyderabad 500090, India.
EM srinivas.41900454@lpu.in; kirti.20248@lpu.co.in; gaurav.11106@lpu.co.in
RI Talasila, Dr Srinivas/ABH-2802-2020
OI Talasila, Dr Srinivas/0000-0003-0658-2307
CR Abed SH, 2021, INT J INTELL ROBOT, V5, P235, DOI 10.1007/s41315-021-00174-3
   Anagnostis A, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020469
   Barbedo JGA, 2018, COMPUT ELECTRON AGR, V153, P46, DOI 10.1016/j.compag.2018.08.013
   Bin Samin O, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.752
   Brahimi M, 2017, APPL ARTIF INTELL, V31, P299, DOI 10.1080/08839514.2017.1315516
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chowdhury MEH, 2021, AGRIENGINEERING, V3, P294, DOI 10.3390/agriengineering3020020
   Elaraby A, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/9153207
   Elfatimi E, 2022, IEEE ACCESS, V10, P9471, DOI 10.1109/ACCESS.2022.3142817
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Geetharamani G, 2019, COMPUT ELECTR ENG, V76, P323, DOI 10.1016/j.compeleceng.2019.04.011
   Gonzalez-Huitron V, 2021, COMPUT ELECTRON AGR, V181, DOI 10.1016/j.compag.2020.105951
   Goyal L., 2021, Informatics in Medicine Unlocked, V25, P100642, DOI DOI 10.1016/J.IMU.2021.100642
   Hang J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19194161
   Hassan SM, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10121388
   Hridoy Rashidul Hasan, 2022, Computer Networks and Inventive Communication Technologies: Proceedings of Fourth ICCNCT 2021. Lecture Notes on Data Engineering and Communications Technologies (75), P189, DOI 10.1007/978-981-16-3728-5_14
   Kamal KC, 2021, AGRICULTURE-BASEL, V11, DOI 10.3390/agriculture11090827
   Karlekar A, 2020, COMPUT ELECTRON AGR, V172, DOI 10.1016/j.compag.2020.105342
   Kong JL, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/4391491
   Kong JL, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12040500
   Liu B, 2020, P INT COMP SOFTW APP, P1267, DOI 10.1109/COMPSAC48688.2020.00-82
   Lu JZ, 2021, AGRICULTURE-BASEL, V11, DOI 10.3390/agriculture11080707
   Ma JC, 2018, COMPUT ELECTRON AGR, V154, P18, DOI 10.1016/j.compag.2018.08.048
   Maeda-Gutiérrez V, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10041245
   Manso G.L., 2019, ARXIV
   Mohanty S. P., 2016, Frontiers in Plant Science, V7, P1419
   Nagaraju M, 2021, 2021 9 INT C REL INF, P1, DOI [10.1109/ICRITO51393.2021.9596200, DOI 10.1109/ICRITO51393.2021.9596200]
   Orchi H, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12010009
   Oyewola DO, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.352
   Pandian JA, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11081266
   Rahman CR, 2020, BIOSYST ENG, V194, P112, DOI 10.1016/j.biosystemseng.2020.03.020
   Rashid J, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10172064
   SAHU P, 2020, IMPLEMENTATION CNNS, V206, DOI DOI 10.22937/IJCSNS.2020.20.10.26
   Sibiya M, 2019, AGRIENGINEERING, V1, P119, DOI 10.3390/agriengineering1010009
   Singh S, 2022, CMC-COMPUT MATER CON, V71, P1849, DOI 10.32604/cmc.2022.021875
   Sunil CK, 2022, IEEE ACCESS, V10, P789, DOI 10.1109/ACCESS.2021.3138920
   Talasila Srinivas, 2022, Intelligent Systems and Sustainable Computing: Proceedings of ICISSC 2021. Smart Innovation, Systems and Technologies (289), P279, DOI 10.1007/978-981-19-0011-2_26
   Talasila S, 2022, DATA BRIEF, V45, DOI 10.1016/j.dib.2022.108725
   Talasila S, 2023, INT J INTELL UNMANNE, V11, P132, DOI 10.1108/IJIUS-08-2021-0100
   Thangaraj R, 2021, J PLANT DIS PROTECT, V128, P73, DOI 10.1007/s41348-020-00403-0
   Too EC, 2019, COMPUT ELECTRON AGR, V161, P272, DOI 10.1016/j.compag.2018.03.032
   Trivedi NK, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21237987
   Wang CS, 2022, FRONT PLANT SCI, V12, DOI 10.3389/fpls.2021.731688
   Wani JA, 2022, ARCH COMPUT METHOD E, V29, P641, DOI 10.1007/s11831-021-09588-5
   Xiong YH, 2020, COMPUT ELECTRON AGR, V177, DOI 10.1016/j.compag.2020.105712
   Yadav S, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2021.101247
   Zheng YY, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051058
NR 47
TC 1
Z9 1
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 44309
EP 44333
DI 10.1007/s11042-023-15220-4
EA APR 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000970495100004
DA 2024-07-18
ER

PT J
AU Liu, N
   Zhang, D
   Wang, XC
   Wu, ZK
AF Liu, Na
   Zhang, Dan
   Wang, Xingce
   Wu, Zhongke
TI Gender and ethnicity classification of the 3D nose region based on
   scaling invariant harmonic wave kernel signature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scaling invariant harmonic wave kernel signature; 3D nose region; Gender
   classification; Ethnicity classification
ID FACE RECOGNITION; FEATURES
AB In 3D face analysis research, automated classification to recognize gender and ethnicity has received an increasing amount of attention in recent years. Feature extraction and feature calculation have a fundamental role in the process of classification construction. In particular, the challenge of 3D low-quality face data, including inconsistent mesh numbers or holes, makes it difficult to extract and calculate facial features. To overcome this challenge, we propose a shape descriptor Scaling invariant harmonic wave kernel signature (SIHWKS) that is robust to scaling, topology and sampling and can effectively describe the global and local properties of 3D shapes simultaneously by involving two energy parameters. We extract a local nose region in the center of the face using isogeodesic stripes replacing full facial information, which has a lower probability of occlusion and lower calculation complexity. Actually, the local nose region is constrained by the skull so that it has high distinction gender and ethnicity property and stability property that are robust to 3D facial expression for gender and ethnicity classification. Compared with gender and ethnicity classification based on 2D deep-learning methods influenced by texture information, the proposed method does not require complex processes for model training and only considers the geometric information of the 3D nose region. In addition, to estimate the effectiveness of our point descriptor SIHWKS for gender and ethnicity classification, we compare our SIHWKS with four existing descriptors - global point signature (GPS), heat kernel signature (HKS), wave kernel signature (WKS) and harmonic wave kernel signature (HWKS) - on four databases, namely, FRGC2.0, Bosphorus3D, Facewarehouse and Asian Mongolian craniofacial. Finally, we perform experiments comparing our method with other recent existing classification methods. The experimental results show that our proposed method can achieve a higher accuracy rate for gender and ethnicity classification.
C1 [Liu, Na; Wang, Xingce; Wu, Zhongke] Beijing Normal Univ BNU, Sch Artificial Intelligence, 19 Xinjiekou Wai St, Beijing, Peoples R China.
   [Zhang, Dan] Qinghai Normal Univ, Comp Coll, 38 Wusi West Rd, Xining, Peoples R China.
C3 Qinghai Normal University
RP Wu, ZK (corresponding author), Beijing Normal Univ BNU, Sch Artificial Intelligence, 19 Xinjiekou Wai St, Beijing, Peoples R China.
EM zwu@bnu.edu.cn
RI chen, bin/KBQ-8114-2024; JIANG, Peng/KGL-3427-2024; li,
   jixiang/JXN-7599-2024; Han, Yang/JVN-5921-2024
OI chen, bin/0000-0002-3398-1314; 
FU National Natural Science Foundation of China [62072045, 62102213];
   National Key Cooperation between the BRICS of China [2017YFB1002604];
   National Key R&D Program of China [2017YFB1402105, KJQN2021004]; Young
   Middle-aged Scientific Research Foundation of Qinghai Normal University
   [61972041];  [2017YFE0100500]
FX This work is partially supported by the National Natural Science
   Foundation of China (No.61972041, No. 62072045), National Key
   Cooperation between the BRICS of China (No. 2017YFE0100500),National Key
   R&D Program of China (No. 2017YFB1002604 and No. 2017YFB1402105),
   National Natural Science Foundation of China (No. 62102213), and Young
   Middle-aged Scientific Research Foundationof Qinghai Normal University
   (No. KJQN2021004).
CR Aflalo Y, 2013, SIAM J IMAGING SCI
   Altameemi A., 2019, INT J ELECTR COMPUT, V9, P1
   Aubry M, 2011, IEEE I CONF COMP VIS, P1411, DOI 10.1109/ICCV.2011.6126396
   Ballihi L, 2012, INT S COMM CONTR SIG, P1, DOI DOI 10.1109/ISCCSP.2012.6217828
   Ballihi L, 2012, IEEE T INF FOREN SEC, V7, P1766, DOI 10.1109/TIFS.2012.2209876
   Bekios-Calfa J, 2011, IEEE T PATTERN ANAL, V33, P858, DOI 10.1109/TPAMI.2010.208
   Berretti S, 2010, IEEE T PATTERN ANAL, V32, P2162, DOI 10.1109/TPAMI.2010.43
   Bronstein AM, 2010, SHREC2010 ROBUST LAR
   Bronstein MM, 2010, PROC CVPR IEEE, P1704, DOI 10.1109/CVPR.2010.5539838
   Drira H, 2009, IEEE I CONF COMP VIS, P2050, DOI 10.1109/ICCV.2009.5459451
   Emambakhsh M, 2017, IEEE T PATTERN ANAL, V39, P995, DOI 10.1109/TPAMI.2016.2565473
   Gilani SZ, 2013, 2013 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES & APPLICATIONS (DICTA), P96
   Guo G., 2010, CVPR Workshop, P79
   Han H, 2015, IEEE T PATTERN ANAL, V37, P1148, DOI 10.1109/TPAMI.2014.2362759
   Han X, 2009, 2009 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P114, DOI 10.1109/CW.2009.41
   Hawraa A., 2018, COMPUTATIONAL VISUAL, V4, P1
   Hosoi S, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P195, DOI 10.1109/AFGR.2004.1301530
   Hu JX, 2009, VISUAL COMPUT, V25, P667, DOI 10.1007/s00371-009-0340-6
   Huang D, 2014, IMAGE VISION COMPUT, V32, P1181, DOI 10.1016/j.imavis.2014.06.009
   Li HS, 2018, INT CONF BIG DATA, P448, DOI 10.1109/BigComp.2018.00072
   Lian HC, 2005, LECT NOTES COMPUT SC
   Lu H, 2007, IEEE NAT COMP C
   Lu XG, 2004, P SOC PHOTO-OPT INS, V5404, P114, DOI 10.1117/12.542847
   Lv C, 2018, PATTERN RECOGN LETT
   Lv CL, 2019, MULTIMED TOOLS APPL, V78, P14753, DOI 10.1007/s11042-018-6839-y
   Moeini A, 2015, ELECTRON LETT, V51, P760, DOI 10.1049/el.2015.0520
   Mostafa E, 2013, 2013 IEEE SIXTH INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS (BTAS)
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ovsjanikov M, 2008, COMPUT GRAPH FORUM, V27, P1341, DOI 10.1111/j.1467-8659.2008.01273.x
   Ra PA, 1991, EIG REC
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Ren J, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275040
   Savelonas MA, 2015, MULTIMED TOOLS APPL, V74, P11783, DOI 10.1007/s11042-014-2267-9
   Shakhnarovich G, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P16, DOI 10.1109/AFGR.2002.1004124
   Sol J, 2017, FACE RECOGNITION BAS
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   ter Haar FB, 2009, GRAPH MODELS, V71, P77, DOI 10.1016/j.gmod.2008.12.003
   Tian Q, 2016, IMAGE VISION COMPUT, V69
   Tokola R, 2015, INT CONF BIOMETR, P201, DOI 10.1109/ICB.2015.7139052
   Wagner A, 2009, PROC CVPR IEEE, P597, DOI 10.1109/CVPRW.2009.5206654
   Wang C, 2020, PATTERN RECOGN LETT, V136, P190, DOI 10.1016/j.patrec.2020.05.035
   Xia BG, 2015, PATTERN RECOGN, V48, P746, DOI 10.1016/j.patcog.2014.09.021
   Xia BQ, 2013, IEEE INT CONF AUTOMA
   Xia BQ, 2017, IMAGE VISION COMPUT, V64, P90, DOI 10.1016/j.imavis.2017.06.004
   Zhang D., 2020, VISUAL COMPUT, V7, P142
   Zhang J, 2020, GRAPH MODELS
   [赵海英 Zhao Haiying], 2012, [自动化学报, Acta Automatica Sinica], V38, P1544
NR 47
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 41791
EP 41811
DI 10.1007/s11042-023-14750-1
EA APR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000968990200001
DA 2024-07-18
ER

PT J
AU Rawat, M
   Bafila, AS
   Kumar, S
   Kumar, M
   Pundir, A
   Singh, S
AF Rawat, Mukesh
   Bafila, Anil Singh
   Kumar, Sunil
   Kumar, Manish
   Pundir, Amit
   Singh, Sanjeev
TI A new encryption model for multimedia content using two dimensional
   Brownian motion and coupled map lattice
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encryption; Decryption; Confusion; Diffusion; Shuffling
ID CRYPTOGRAPHIC MODEL; IMAGE; SYSTEM
AB An image encryption model is presented in this paper. The model uses two-dimensional Brownian Motion as a source of confusion and diffusion in image pixels. Shuffling of image pixels is done using Intertwining Logistic Map due to its desirable chaotic properties. The properties of Brownian motion helps to ensure key sensitivity. Finally, a diffusion mechanism based upon a Coupled Map Lattice helps to bind image pixels together and provide a chaining effect as diffusion. Key streams used in confusion and diffusion are made input image dependent that follows the symmetric encryption model requirements. The model introduces randomness in the cipher image resulting in negligible correlation coefficients between the cipher image pixels. It leads to uniform distribution of pixels in image histogram representing a high degree of confusion complexity assuring resistance against differential attacks. The NPCR (99.83%) and UACI (33.42%) values meet the minimum standard requirements for image security. Details of other test results related to entropy (7.9995%), Peak Signal to Noise Ratio (8.8751dB), noise and NIST randomness tests are also mentioned which support the model's resistivity against various known and chosen plaintext attacks.
C1 [Rawat, Mukesh; Bafila, Anil Singh; Singh, Sanjeev] Univ Delhi, Inst Informat & Commun, South Campus, Delhi, India.
   [Kumar, Sunil] Univ Delhi, Shaheed Rajguru Coll Appl Sci Women, Dept Instrumentat, Delhi, India.
   [Kumar, Manish] Univ Delhi, Cluster Innovat Ctr, North Campus, Delhi, India.
   [Pundir, Amit] Univ Delhi, Maharaja Agrasen Coll, Dept Elect, Delhi, India.
C3 University of Delhi; University of Delhi; University of Delhi;
   University of Delhi
RP Singh, S (corresponding author), Univ Delhi, Inst Informat & Commun, South Campus, Delhi, India.
EM mukesh.rawat13@gmail.com; bafila.anil@gmail.com;
   sunilkumar104@gmail.com; manishshailani@gmail.com;
   amitpundir.du@gmail.com; sanjeev@south.du.ac.in
RI Pundir, Amit/GWQ-4311-2022
OI Singh, Sanjeev/0000-0002-2416-7011; BAFILA, ANIL
   SINGH/0000-0002-3392-2410
CR Abas FS, 2022, INT J INT NETW, V3, P102
   Abbasi AA, 2021, OPT LASER TECHNOL, V140, DOI 10.1016/j.optlastec.2021.106974
   Alarood AA, 2022, AIN SHAMS ENG J, V13, DOI 10.1016/j.asej.2021.09.010
   Ali TS, 2020, MULTIMED TOOLS APPL, V79, P19853, DOI 10.1007/s11042-020-08850-5
   Anwar S, 2019, MULTIMED TOOLS APPL, V78, P27569, DOI 10.1007/s11042-019-07852-2
   Arab AA, 2022, OPTIK, V261, DOI 10.1016/j.ijleo.2022.169122
   Benssalah M, 2021, MULTIMED TOOLS APPL, V80, P2081, DOI 10.1007/s11042-020-09775-9
   Bhat J, 2022, EXPERT SYST APPL, V206, DOI 10.1016/j.eswa.2022.117861
   Biswas P, 2020, MULTIMED TOOLS APPL, V79, P31715, DOI 10.1007/s11042-020-09497-y
   Chai XL, 2017, CHINESE PHYS B, V26, DOI 10.1088/1674-1056/26/2/020504
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P1159, DOI 10.1007/s11042-015-3088-1
   Demirtas M, 2022, OPTIK, V266, DOI 10.1016/j.ijleo.2022.169624
   Dong WL, 2021, CHAOS SOLITON FRACT, V153, DOI 10.1016/j.chaos.2021.111539
   Dong YH, 2022, INFORM SCIENCES, V593, P121, DOI 10.1016/j.ins.2022.01.031
   Duan CF, 2022, OPT LASER ENG, V150, DOI 10.1016/j.optlaseng.2021.106881
   Es-Sabry M, 2022, SCI AFR, V16, DOI 10.1016/j.sciaf.2022.e01217
   Gao XH, 2021, OPT LASER TECHNOL, V142, DOI 10.1016/j.optlastec.2021.107252
   Gao XY, 2022, J KING SAUD UNIV-COM, V34, P1535, DOI 10.1016/j.jksuci.2022.01.017
   Gao XY, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-94748-7
   Ghorbani A, 2022, OPTIK, V259, DOI 10.1016/j.ijleo.2022.168961
   Gupta M, 2021, MULTIMED TOOLS APPL, V80, P10391, DOI 10.1007/s11042-020-10116-z
   Han X, 2020, MULTIMED TOOLS APPL, V79, P9655, DOI 10.1007/s11042-017-5598-5
   Huang XL, 2022, ALEX ENG J, V61, P7637, DOI 10.1016/j.aej.2022.01.015
   Ikbal F, 2021, J KING SAUD UNIV-COM
   Iqbal N., 2021, J INF SECUR APPL, V58, P2214
   Jain K, 2021, PATTERN RECOGN LETT, V152, P356, DOI 10.1016/j.patrec.2021.10.033
   Kanso A, 2012, COMMUN NONLINEAR SCI, V17, P2943, DOI 10.1016/j.cnsns.2011.11.030
   Khaitan S., 2021, Materials Today: Proceedings, DOI [10.1016/j.matpr.2021.05.251, DOI 10.1016/J.MATPR.2021.05.251]
   Kumar K, 2022, CHAOS SOLITON FRACT, V158, DOI 10.1016/j.chaos.2022.111994
   Kumar M, 2018, J INF SECUR APPL, V40, P134, DOI 10.1016/j.jisa.2018.03.007
   Kumar S, 2018, PROCEDIA COMPUT SCI, V143, P804, DOI 10.1016/j.procs.2018.10.386
   Kumar S, 2018, J INF SECUR APPL, V43, P123, DOI 10.1016/j.jisa.2018.10.011
   Kumari M, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0148-5
   Li CH, 2018, MULTIMED TOOLS APPL, V77, P19193, DOI 10.1007/s11042-017-5391-5
   Li CM, 2022, OPTIK, V260, DOI 10.1016/j.ijleo.2022.169042
   Liu LF, 2023, MATH COMPUT SIMULAT, V204, P89, DOI 10.1016/j.matcom.2022.07.030
   Liu Y, 2020, MULTIMED TOOLS APPL, V79, P17669, DOI 10.1007/s11042-020-08645-8
   Luo Y., 2019, Proceedings of the International Conference on Neuromorphic Systems (ICONS), P1, DOI DOI 10.1145/3354265.3354266
   Maazouz M, 2022, J KING SAUD UNIV-COM, V34, P9926, DOI 10.1016/j.jksuci.2021.12.022
   Munson DC, 1996, IEEE T IMAGE PROCESS, V5, P3, DOI 10.1109/TIP.1996.8100841
   Niu Ying N, 2020, MULTIMED TOOLS APPL, P1
   NORROS I, 1995, IEEE J SEL AREA COMM, V13, P953, DOI 10.1109/49.400651
   Özkaynak F, 2018, NONLINEAR DYNAM, V92, P305, DOI 10.1007/s11071-018-4056-x
   Pareek NK, 2013, DIGIT SIGNAL PROCESS, V23, P894, DOI 10.1016/j.dsp.2013.01.005
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   Patro KAK, 2020, MULTIMED TOOLS APPL, V79, P12959, DOI 10.1007/s11042-019-08470-8
   Raghuvanshi KK, 2020, J INF SECUR APPL, V55, DOI 10.1016/j.jisa.2020.102622
   Sang YP, 2022, PATTERN RECOGN LETT, V153, P59, DOI 10.1016/j.patrec.2021.11.025
   Selvi CT, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102465
   Song W, 2023, MATH COMPUT SIMULAT, V204, P71, DOI 10.1016/j.matcom.2022.07.029
   Tang Y, 2010, COMMUN NONLINEAR SCI, V15, P2456, DOI 10.1016/j.cnsns.2009.09.023
   Tao Y, 2020, J INF SECUR APPL, V55, DOI 10.1016/j.jisa.2020.102650
   Tian JF, 2021, MULTIMED TOOLS APPL, V80, P32841, DOI 10.1007/s11042-021-11218-y
   Wang C, 2022, SIGNAL PROCESS, V196, DOI 10.1016/j.sigpro.2022.108536
   Wang J, 2022, J KING SAUD UNIV-COM, V34, P8245, DOI 10.1016/j.jksuci.2022.08.007
   Wang MM, 2022, EXPERT SYST APPL, V207, DOI 10.1016/j.eswa.2022.118067
   Wang MX, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110028
   Wang SY, 2022, OPTIK, V268, DOI 10.1016/j.ijleo.2022.169758
   Wang XF, 2021, MULTIMED TOOLS APPL, V80, P943, DOI 10.1007/s11042-020-09533-x
   Wang XY, 2022, OPTIK, V258, DOI 10.1016/j.ijleo.2022.168955
   Wang XY, 2022, CHAOS SOLITON FRACT, V155, DOI 10.1016/j.chaos.2021.111629
   Wang XY, 2021, OPTIK, V245, DOI 10.1016/j.ijleo.2021.167658
   Wang XY, 2021, OPT LASER TECHNOL, V143, DOI 10.1016/j.optlastec.2021.107316
   Wang XY, 2021, INFORM SCIENCES, V569, P217, DOI 10.1016/j.ins.2021.04.013
   Wang XY, 2021, CHAOS SOLITON FRACT, V143, DOI 10.1016/j.chaos.2020.110582
   Wang XY, 2020, CHAOS SOLITON FRACT, V141, DOI 10.1016/j.chaos.2020.110309
   Wang XY, 2018, IEEE ACCESS, V6, P39705, DOI 10.1109/ACCESS.2018.2855726
   Wang XY, 2014, NONLINEAR DYNAM, V75, P345, DOI 10.1007/s11071-013-1070-x
   Wang XY, 2022, OPT COMMUN, V506, DOI 10.1016/j.optcom.2021.127544
   Wang Y, 2008, INFORM SCIENCES, V178, P1391, DOI 10.1016/j.ins.2007.10.008
   Wei KK, 2021, SIGNAL PROCESS, V185, DOI 10.1016/j.sigpro.2021.108080
   Xiang T, 2007, CHAOS, V17, DOI 10.1063/1.2728112
   Xiong Z, 2019, MULTIMED TOOLS APPL, P1
   Xu D, 2022, AIN SHAMS ENG J
   Xu LH, 2022, INTEGRATION, V87, P313, DOI 10.1016/j.vlsi.2022.07.012
   Xu L, 2017, OPT LASER ENG, V91, P41, DOI 10.1016/j.optlaseng.2016.10.012
   Yahi A, 2022, OPTIK, V249, DOI 10.1016/j.ijleo.2021.168290
   Ye GD, 2022, EXPERT SYST APPL, V205, DOI 10.1016/j.eswa.2022.117709
   Ye GD, 2017, NEUROCOMPUTING, V251, P45, DOI 10.1016/j.neucom.2017.04.016
   Yu JW, 2022, CHAOS SOLITON FRACT, V162, DOI 10.1016/j.chaos.2022.112456
   Zareai D, 2021, MULTIMED TOOLS APPL, V80, P18317, DOI 10.1007/s11042-021-10576-x
   Zhang H, 2017, OPT LASER ENG, V88, P65, DOI 10.1016/j.optlaseng.2016.07.004
   Zhang J., 2016, MATH PROBL ENG, V2016, P1, DOI [10.1155/2016/6408741, DOI 10.1155/2016/6408741]
   Zhang LH, 2022, OPT COMMUN, V504, DOI 10.1016/j.optcom.2021.127494
   Zhang Y, 2012, APPL CRYPTOGRAPH NET, DOI [10.5772/34510, DOI 10.5772/34510]
   Zhang YQ, 2016, OPT LASER ENG, V82, P95, DOI 10.1016/j.optlaseng.2016.02.002
   Zhang YM, 2022, J KING SAUD UNIV-COM, V34, P2993, DOI 10.1016/j.jksuci.2022.04.001
   Zhao RY, 2022, INFORM SCIENCES, V613, P628, DOI 10.1016/j.ins.2022.08.027
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
NR 89
TC 0
Z9 0
U1 4
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43421
EP 43453
DI 10.1007/s11042-023-14841-z
EA APR 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000984450300005
DA 2024-07-18
ER

PT J
AU Yang, G
   Liao, YT
AF Yang, Ge
   Liao, Yuting
TI An improved binocular stereo matching algorithm based on AANet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Three-dimensional displays; Stereo matching; Feature extraction; Neural
   networks; Adaptation models; Training
ID NETWORK; NET
AB Stereo matching is an important part of establishing stereo vision. Parallax information obtained by stereo matching directly affects the three-dimensional information of an object. End-to-end stereo matching algorithms can directly derive parallax maps from the designed network. However, at the same time, the structure of the network is complex, and a large number of parameters take up much memory. The network increases the device burden, which increases the time required to obtain the parallax map, lowering the efficiency of the network movement. Thus, an improved stereo matching algorithm based on AANet (adaptive aggregation network for efficient stereo matching) is proposed in this paper: AEDNet (adaptive end-to-end depth network for stereo matching). In the feature extraction module, the network simplifies the network structure by limiting the convolution kernel size to obtain the features with low abstraction. In cost aggregation, the intra-scale aggregation module is used to achieve adaptive cost aggregation through deformable convolution, and the inter-scale aggregation module uses the traditional cross-scale aggregation method to compensate for the missing global information to a certain extent. The network is verified the performance on the KITTI dataset. The results show that the algorithm can still complete stereo matching efficiently and accurately and obtain a better disparity map when the network is simplified. These provide preconditions for accurate three-dimensional reconstruction.
C1 [Yang, Ge] Beijing Normal Univ, Adv Inst Nat Sci, Key Lab Intelligent Multimedia Technol, Zhuhai 519087, Peoples R China.
   [Liao, Yuting] Peking Univ, Shenzhen Grad Sch, Engn Lab Intelligent Percept Internet Things ELIP, Shenzhen 518055, Peoples R China.
C3 Beijing Normal University; Peking University
RP Yang, G (corresponding author), Beijing Normal Univ, Adv Inst Nat Sci, Key Lab Intelligent Multimedia Technol, Zhuhai 519087, Peoples R China.
EM yangge@pkusz.edu.cn
FU Major Scientific Research Project for Universities of Guangdong Province
   [2020ZDZX3058]; Science and technology projects of Zhuhai in the field
   of social development [2220004000066]; Key Laboratory of Intelligent
   Multimedia Technology [201762005]
FX This research was financially supported by the Major Scientific Research
   Project for Universities of Guangdong Province (2020ZDZX3058); Science
   and technology projects of Zhuhai in the field of social development
   (2220004000066); the Key Laboratory of Intelligent Multimedia Technology
   (201762005)
CR Aleotti F, 2020, AAAI CONF ARTIF INTE, V34, P10435
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567
   Changhee Won, 2021, IEEE Transactions on Pattern Analysis and Machine Intelligence, V43, P3850, DOI 10.1109/TPAMI.2020.2992497
   Chen S., 2020, P AS C COMP VIS ACCV
   Chen W, 2022, IEEE ROBOT AUTOM LET, V7, P581, DOI 10.1109/LRA.2021.3130984
   Cheng MY, 2020, OPTIC J, V40, P144
   Du HZ, 2021, IEEE ROBOT AUTOM LET, V6, P8005, DOI 10.1109/LRA.2021.3101523
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Kim S, 2021, IEEE T INTELL TRANSP, V22, P6875, DOI 10.1109/TITS.2020.2995996
   Kuzmin A, 2017, P IEEE 27 INT WORKSH, P1, DOI [10.1109/MLSP.2017.8168183, DOI 10.1109/MLSP.2017.8168183]
   Laga H, 2022, IEEE T PATTERN ANAL, V44, P1738, DOI 10.1109/TPAMI.2020.3032602
   Li J., 2022, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, P16263
   [李曈 Li Tong], 2020, [计算机研究与发展, Journal of Computer Research and Development], V57, P1531
   Liang ZF, 2021, IEEE T PATTERN ANAL, V43, P300, DOI 10.1109/TPAMI.2019.2928550
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Lipson L, 2021, INT CONF 3D VISION, P218, DOI 10.1109/3DV53792.2021.00032
   Liu J, 2020, S CHINA U TECHNOL NA, V48, P60
   Liu PP, 2020, PROC CVPR IEEE, P6647, DOI 10.1109/CVPR42600.2020.00668
   Mao YM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6291, DOI 10.1109/ICCV48922.2021.00625
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438
   Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925
   Park J, 2022, IEEE ROBOT AUTOM LET, V7, P5095, DOI 10.1109/LRA.2022.3150868
   Shankar K, 2022, IEEE ROBOT AUTOM LET, V7, P2305, DOI 10.1109/LRA.2022.3143895
   Shen ZL, 2021, PROC CVPR IEEE, P13901, DOI 10.1109/CVPR46437.2021.01369
   Song X, 2020, INT J COMPUT VISION, V128, P910, DOI 10.1007/s11263-019-01287-w
   Tankovich V, 2021, PROC CVPR IEEE, P14357, DOI 10.1109/CVPR46437.2021.01413
   Tonioni A, 2019, PROC CVPR IEEE, P195, DOI 10.1109/CVPR.2019.00028
   Wang HL, 2021, IEEE ROBOT AUTOM LET, V6, P4353, DOI 10.1109/LRA.2021.3068108
   Xu B, 2021, PROC CVPR IEEE, P12492, DOI 10.1109/CVPR46437.2021.01231
   Xu CL, 2021, IEEE T CIRC SYST VID, V31, P4007, DOI 10.1109/TCSVT.2020.3044891
   Xu HF, 2020, PROC CVPR IEEE, P1956, DOI 10.1109/CVPR42600.2020.00203
   Yang GR, 2018, LECT NOTES COMPUT SC, V11211, P660, DOI 10.1007/978-3-030-01234-2_39
   Yang JC, 2020, IEEE SENS J, V20, P11959, DOI 10.1109/JSEN.2020.2965086
   Yao CT, 2021, PROC CVPR IEEE, P6087, DOI 10.1109/CVPR46437.2021.00603
   Ye XQ, 2022, IEEE T COMPUT IMAG, V8, P54, DOI 10.1109/TCI.2021.3139328
   Yeongmin Lee, 2022, IEEE Transactions on Circuits and Systems for Video Technology, V32, P411, DOI 10.1109/TCSVT.2021.3061200
   Yufeng W., 2020, J HEMATOL ONCOL, V40, P99
   Yufeng Wang., 2019, ACTA OPT SINICA, V39, P227
   Zeng K, 2022, IEEE T IMAGE PROCESS, V31, P812, DOI 10.1109/TIP.2021.3135485
   Zhang FH, 2019, PROC CVPR IEEE, P185, DOI 10.1109/CVPR.2019.00027
   Zhang JM, 2019, IEEE ROBOT AUTOM LET, V4, P1162, DOI 10.1109/LRA.2019.2894913
   Zhang YM, 2020, AAAI CONF ARTIF INTE, V34, P12926
NR 44
TC 1
Z9 1
U1 14
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40987
EP 41003
DI 10.1007/s11042-023-15183-6
EA APR 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000964979100004
DA 2024-07-18
ER

PT J
AU Kumar, P
   Gupta, V
AF Kumar, Praveen
   Gupta, Varun
TI Restoration of damaged artworks based on a generative adversarial
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artwork restoration; Generative adversarial networks; Deep learning;
   Deep neural networks; Residual networks; U-Net; Image inpainting
AB Ancient and contemporary artworks represent culture, heritage, and history. The artworks act as a bridge between the past and future of humankind. Preserving artwork is necessary for saving cultural heritage for future generations. However, artworks tend to deteriorate with time due to humidity, temperature, improper handling, and storage. Damages to artworks require unique restoration treatments, and, in many cases, they cannot be returned to their original state. Moreover, traditional artwork restoration methods are very costly and time-consuming. Further, the artwork restoration field is very complex as we not only require sharper and visually realistic restoration but also to preserve the artistic style and features of the artwork. The virtual restoration after digitizing the artworks can be very helpful in the actual restoration of the artworks. This paper works in this direction and proposes a novel generative adversarial network-based artwork restoration method that can digitally restore the damaged artwork, which can help in the physical restoration of the artworks. The proposed generative adversarial network uses a modified U-Net architecture for the generator part and pre-trained residual networks to build the generator's encoder part. Since the residual networks are pre-trained on millions of ImageNet images, they generate better feature embeddings out of the input artwork images, which in turn help in the generation of better-restored artwork images. The proposed artwork restoration method works in a single step and does not require the generation of masks. The proposed network has been evaluated on two different datasets using performance metrics such as peak signal-to-noise ratio, mean squared error, structural similarity index, and Frechet inception distance. Results indicate that the proposed network outperforms the existing artwork restoration methods.
C1 [Kumar, Praveen; Gupta, Varun] Chandigarh Coll Engn & Technol, Dept Comp Sci & Engn, Sect 26, Chandigarh 160019, India.
RP Gupta, V (corresponding author), Chandigarh Coll Engn & Technol, Dept Comp Sci & Engn, Sect 26, Chandigarh 160019, India.
EM varungupta@ccet.ac.in
RI Gupta, Varun/AAW-9860-2020; Gupta, Varun/KFA-9728-2024
OI Gupta, Varun/0000-0002-2633-5920; , Praveen Kumar/0009-0004-6441-5309
CR Adhikary A, 2021, 2021 13TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P199, DOI 10.1109/ICACI52617.2021.9435888
   Bakkouri I, 2023, SIGNAL IMAGE VIDEO P, V17, P1181, DOI 10.1007/s11760-022-02325-w
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Ballester C, 2003, MULTISCALE MODEL SIM, V2, P80, DOI 10.1137/S1540345903422458
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Cao JF, 2020, HERIT SCI, V8, DOI 10.1186/s40494-020-0355-x
   Cornelis B, 2013, SIGNAL PROCESS, V93, P605, DOI 10.1016/j.sigpro.2012.07.022
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Fei-Fei L, 2009, J. Vis., V9, P1037, DOI [DOI 10.1167/9.8.1037, 10.1167/9.8.1037]
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gupta V, 2021, EVOL SYST-GER, V12, P439, DOI 10.1007/s12530-019-09303-7
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Jay F., 2010, PROC IEEE INT C COMP, DOI [10.1007/978-1-60327-005-2_13, DOI 10.1007/978-1-60327-005-2_13]
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Knut Nicolaus E, 1999, RESTORATION PAINTING, P465, DOI [10.1109/ICIEV.2018.8641016, DOI 10.1109/ICIEV.2018.8641016]
   Levin A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P305
   Li C, 2016, LECT NOTES COMPUT SC, V9907, P702, DOI 10.1007/978-3-319-46487-9_43
   Li J, 2021, HERIT SCI, V9, DOI 10.1186/s40494-020-00478-w
   LIU G, 2018, IMAGE INPAINTING IRR, V1206
   Nazeri K., 2019, ARXIV
   Park Taesung, 2019, ACM SIGGRAPH 769 201, DOI [DOI 10.1145/3306305.3332370, 10.1145/3306305.3332370]
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Sagong MC, 2019, PROC CVPR IEEE, P11352, DOI 10.1109/CVPR.2019.01162
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Wan ZY, 2023, IEEE T PATTERN ANAL, V45, P2071, DOI 10.1109/TPAMI.2022.3163183
   Wang HL, 2018, SA'18: SIGGRAPH ASIA 2018 TECHNICAL BRIEFS, DOI 10.1145/3283254.3283263
   Xie Junyuan, 2012, ADV NEURAL INFORM PR, P341, DOI [DOI 10.5555/2999134.2999173, DOI 10.1109/AGRO-GEOINFORMATICS.2012.6311605]
   Xu Li, 2014, P ANN C NEUR INF PRO, P1790
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zamir SW, 2021, PROC CVPR IEEE, P14816, DOI 10.1109/CVPR46437.2021.01458
   Zeng Y, 2019, MACH VISION APPL, V30, P1229, DOI 10.1007/s00138-019-01047-3
   Zou Z, 2021, ADV ENG INFORM, V50, DOI 10.1016/j.aei.2021.101421
   Zou ZX, 2021, SOC CHOICE WELFARE, V57, P35, DOI 10.1007/s00355-020-01299-3
NR 37
TC 2
Z9 2
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40967
EP 40985
DI 10.1007/s11042-023-15222-2
EA APR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000963639900006
DA 2024-07-18
ER

PT J
AU Pushpalata, M
   Sasikala, M
AF Pushpalata, M.
   Sasikala, M.
TI A traffic load analysis model using optical flow and boosting classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Traffic load analysis; Boosting classifier; Intelligent traffic
   management system (ITMS); Vehicle tracking; Traffic flow
ID VISION
AB High traffic load is an unfortunate and avoidable companion, especially in urban cities where an enormous number of vehicles move every day from one area to other. However, this situation can be controlled and many problems that occur due to heavy traffic congestion can be avoided if available traffic data is intelligently analyzed, planned, maintained and classified. Therefore, Traffic Load Analyser (TLA) model is presented under the Intelligent Traffic Management System (ITMS) scheme to control high traffic congestion and analyse traffic flow through vehicle tracking. Here, local and global optical flow methods are used to evaluate traffic flow as light traffic and heavy traffic respectively. Here, multi-variant features are determined using optical flow analysis methods to handle traffic congestion problems efficiently. Further, obtained object boundaries help to track vehicles in traffic congestion. Here, Performance results are achieved using the UCSD dataset. Here, performance results are carried out under various weather conditions like rainy weather and overcast weather for all three classes such as light, moderate and heavy traffic. High classification accuracy is achieved using the proposed TLA method as 99.98% and compared against several state-of-art-techniques.
C1 [Pushpalata, M.; Sasikala, M.] Sharnbasva Univ, Fac Engn & Technol Exclusively Women, Kalaburagi, Karnataka, India.
RP Pushpalata, M (corresponding author), Sharnbasva Univ, Fac Engn & Technol Exclusively Women, Kalaburagi, Karnataka, India.
EM pushpalata123456789@rediffmail.com; sasi_mun@rediffmail.com
RI MUNGAMURI, SASIKALA/KHT-6658-2024
CR Asmaa O, 2013, IMAGE VISION COMPUT, V31, P887, DOI 10.1016/j.imavis.2013.09.006
   Beland LP, 2018, J PUBLIC ECON, V160, P96, DOI 10.1016/j.jpubeco.2018.03.002
   Bernas M, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103243
   Buch N, 2011, IEEE T INTELL TRANSP, V12, P920, DOI 10.1109/TITS.2011.2119372
   Cao ZW, 2021, IEEE T INTELL TRANSP, V22, P7460, DOI 10.1109/TITS.2020.3003129
   Chakraborty P, 2018, TRANSPORT RES REC, V2672, P222, DOI 10.1177/0361198118777631
   Chandrasekhar M, 2013, IJAEEE INDIA, V2, P96
   Chen CJ, 2020, IEEE TETCI, V4, P206, DOI 10.1109/TETCI.2019.2926505
   Datondji SRE, 2016, IEEE T INTELL TRANSP, V17, P2681, DOI 10.1109/TITS.2016.2530146
   FHWA, 2016 TRAFF DET HDB
   INIGO RM, 1985, IEEE T IND ELECTRON, V32, P177, DOI 10.1109/TIE.1985.350155
   Jain Neeraj Kumar, 2019, Soft Computing: Theories and Applications. Proceedings of SoCTA 2017. Advances in Intelligent Systems and Computing (AISC 742), P569, DOI 10.1007/978-981-13-0589-4_53
   Ribeiro MVL, 2022, IEEE T INTELL TRANSP, V23, P3797, DOI 10.1109/TITS.2020.3040594
   Loce R.P., 2017, Computer Vision and Imaging in Intelligent Transportation Systems
   Luo ZM, 2018, IEEE T CIRC SYST VID, V28, P878, DOI 10.1109/TCSVT.2016.2632439
   Luo ZM, 2015, IEEE IMAGE PROC, P3290, DOI 10.1109/ICIP.2015.7351412
   Pamula T, 2018, IEEE INTEL TRANSP SY, V10, P11, DOI 10.1109/MITS.2018.2842040
   Puri A, 2005, SURVEY UNMANNED AERI, ppp1
   Riaz Khan SA, 2013, P 6 INT C MACH VIS I, V9067, P3290
   Sobral A., Proc., Computer Graphics and Imaging / 798: Signal Processing, DOI [DOI 10.2316/P.2013.798-105, 10.2316/p.2013.798-105]
   Tian B, 2011, IEEE INT C INTELL TR, P1103, DOI 10.1109/ITSC.2011.6083125
   TYBURSKI RM, 1989, ITE J, V59, P27
   Wald K., 2014, INT J INNOV RES COMP, V2, P289
   Won M, 2018, ARXIV, P3290
   Won M, 2020, IEEE ACCESS, V8, P73340, DOI 10.1109/ACCESS.2020.2987634
   Zhang C, 2020, IEEE T VEH TECHNOL, V69, P10336, DOI 10.1109/TVT.2020.3005363
NR 26
TC 0
Z9 0
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40783
EP 40798
DI 10.1007/s11042-023-14878-0
EA APR 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000961747500008
DA 2024-07-18
ER

PT J
AU Sharma, V
   Bhuyan, MK
   Das, PK
   Bora, K
AF Sharma, Vanshali
   Bhuyan, M. K.
   Das, Pradip K.
   Bora, Kangkana
TI A DWT-based encoder-decoder network for Specularity segmentation in
   colonoscopy images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Colonoscopy; Deep learning; Discrete wavelet transform; Overexposed
   regions; Specular highlights; Specularity segmentation
AB Specularity segmentation in colonoscopy images is a crucial pre-processing step for efficient computational diagnosis. The presence of these specular highlights could mislead the detectors that are intended towards precise identification of biomarkers. Conventional methods adopted so far do not provide satisfactory results, especially in the overexposed regions. The potential of deep learning methods is still unexplored in the related problem domain. Our work aims at providing a solution for more accurate highlights segmentation to assist surgeons. In this paper, we propose a novel deep learning based approach that performs segmentation following a multi-resolution analysis. This is achieved by introducing discrete wavelet transform (DWT) into the proposed model. We replace the standard pooling layers with DWTs, which helps preserve information and circumvent the effect of overexposed regions. All analytical experiments are performed using a publicly available benchmark dataset, and an F1-score (%) of 83.10 +/- 0.14 is obtained on the test set. The experimental results show that this technique outperforms state-of-the-art methods and performs significantly better in overexposed regions. The proposed model also performed superior to some deep learning models (but applied in different domains) when tested with our problem specifications. Our method provides segmentation outcomes that are closer to the actual segmentation done by experts. This ensures improved pre-processed colonoscopy images that aid in better diagnosis of colorectal cancer.
C1 [Sharma, Vanshali; Das, Pradip K.] Indian Inst Technol Guwahati, Dept Comp Sci & Engn, Gauhati, Assam, India.
   [Bhuyan, M. K.] Indian Inst Technol Guwahati, Dept Elect & Elect Engn, Gauhati, Assam, India.
   [Bora, Kangkana] Cotton Univ, Dept Comp Sci & Informat Technol, Gauhati, Assam, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Guwahati
RP Sharma, V (corresponding author), Indian Inst Technol Guwahati, Dept Comp Sci & Engn, Gauhati, Assam, India.
EM vanshalisharma@iitg.ac.in
RI Bhuyan, Manoj Kumar/D-1562-2012
OI Sharma, Vanshali/0000-0003-0008-1579
FU INSPIRE fellowship scheme of Department of Science and Technology,
   Government of India
FX Vanshali Sharma would like to thank INSPIRE fellowship scheme of
   Department of Science and Technology, Government of India for providing
   research fellowship.
CR Akbari M, 2018, IEEE IMAGE PROC, P3134, DOI 10.1109/ICIP.2018.8451699
   Bernal J, 2015, SCREENING COLORECTAL, P109
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bernal J, 2013, IEEE ENG MED BIO, P7350, DOI 10.1109/EMBC.2013.6611256
   Chahal ES, 2022, MULTIMED TOOLS APPL, V81, P37333, DOI 10.1007/s11042-021-11334-9
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Choudhury AR, 2019, LECT NOTES COMPUT SC, V11384, P154, DOI 10.1007/978-3-030-11726-9_14
   Figueiredo IN, 2019, BIOMED SIGNAL PROCES, V53, DOI 10.1016/j.bspc.2019.101577
   Ganz M, 2012, IEEE T BIO-MED ENG, V59, P2144, DOI 10.1109/TBME.2012.2195314
   Gross S, 2012, PROC SPIE, V8315, DOI 10.1117/12.911177
   Gupta Rajiv, 2015, P 19 INT C EV ASS SO, P1
   Hamaguchi R, 2018, IEEE WINT CONF APPL, P1442, DOI 10.1109/WACV.2018.00162
   Hu PY, 2017, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2017.166
   Sánchez FJ, 2017, MACH VISION APPL, V28, P917, DOI 10.1007/s00138-017-0864-0
   Kang J, 2019, IEEE ACCESS, V7, P26440, DOI 10.1109/ACCESS.2019.2900672
   Li JC, 2019, IEEE T BIO-MED ENG, V66, P3499, DOI 10.1109/TBME.2019.2906667
   Li RY, 2020, IEEE T MED IMAGING, V39, P328, DOI 10.1109/TMI.2019.2926501
   Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918
   Liu PJ, 2018, IEEE COMPUT SOC CONF, P886, DOI 10.1109/CVPRW.2018.00121
   Liu QD, 2020, IEEE T MED IMAGING, V39, P2713, DOI 10.1109/TMI.2020.2974574
   Park SY, 2012, IEEE T BIO-MED ENG, V59, P1408, DOI 10.1109/TBME.2012.2188397
   Kumar MRP, 2021, INT J MULTIMED INF R, V10, P1, DOI 10.1007/s13735-020-00196-w
   Prasath VBS, 2017, J IMAGING, V3, DOI 10.3390/jimaging3010001
   Priyadharsini R, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON APPLIED AND THEORETICAL COMPUTING AND COMMUNICATION TECHNOLOGY (ICATCCT), P563, DOI 10.1109/ICATCCT.2015.7456948
   Pyka K, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9010025
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sasmal P, 2019, LECT NOTES COMPUT SC, V11942, P96, DOI 10.1007/978-3-030-34872-4_11
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Stehle T., 2009, MED IMAGING 2009 COM, V7260
   Sun MY, 2019, IEEE ACCESS, V7, P75530, DOI 10.1109/ACCESS.2019.2918800
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Weng Y, 2019, IEEE ACCESS, V7, P44247, DOI 10.1109/ACCESS.2019.2908991
   Yu BX, 2021, FRONT PHYS-LAUSANNE, V8, DOI 10.3389/fphy.2020.616930
   Yu F., 2016, 4 INT C LEARN REPR I, DOI [10.48550/arXiv.1511.07122, DOI 10.48550/ARXIV.1511.07122]
   Zeng ZT, 2019, IEEE ACCESS, V7, P21420, DOI 10.1109/ACCESS.2019.2896920
NR 36
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40065
EP 40084
DI 10.1007/s11042-023-14564-1
EA MAR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000961632300004
DA 2024-07-18
ER

PT J
AU Lohith, JJ
   Manoj, AK
   Nanma, GP
   Srinivasan, P
AF Lohith, J. J.
   Manoj, Anusree K.
   Nanma, Guru P.
   Srinivasan, Pooja
TI TP-Detect: trigram-pixel based vulnerability detection for Ethereum
   smart contracts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blockchain; Machine learning; Ethereum smart contracts; Vulnerabilities
   in smart contracts; Feature extraction
ID KNN
AB Smart contracts are a set of instructions or programs that are stored on the blockchain network and run when predetermined conditions are met. Ethereum smart contracts are deployed on blockchain networks. Ethereum smart contracts are immutable and are vulnerable to simple coding errors called vulnerabilities. The aim of this paper is to classify Ethereum smart contracts vulnerabilities by feature extraction using machine learning. Pixel values collected from images and trigram feature extraction were used to construct the dataset. This dataset was trained using Multilabel k Nearest Neighbours (MLkNN), Binary Relevance kNN (BRkNN), Random Forest (RF), and Naive Bayes (NB), among other machine learning methods. The Naive Bayes Method outperforms the other models in terms of F1-score among all the algorithms tested. The Naive Bayes model achieves F1-scores of 99.38% and 99.44% using Binary Relevance and Classifier Chain respectively. In terms of F1-score, the Random Forest model attained a substantial degree of performance, with F1-scores of 96.71% and 96.61% using Binary Relevance and Classifier Chain respectively. In comparison, the lazy algorithms MLkNN and BRkNN produced lower F1-scores of 88.19% and 89.71%, respectively. This suggests that using the TriPix dataset outperforms models employed in either opcode characteristics or image-based detection used in other works.
C1 [Lohith, J. J.; Manoj, Anusree K.; Nanma, Guru P.; Srinivasan, Pooja] BMS Coll Engn, Comp Sci & Engn, Bull Temple Rd, Bangalore 560019, Karnataka, India.
C3 BMS College of Engineering
RP Srinivasan, P (corresponding author), BMS Coll Engn, Comp Sci & Engn, Bull Temple Rd, Bangalore 560019, Karnataka, India.
EM lohith.cse@bmsce.ac.in; anusreekmanoj2000@gmail.com;
   nanma.p31@gmail.com; poojasrinivasan18@gmail.com
RI J, Lohith J/AAW-1082-2020
OI J, Lohith J/0000-0002-3110-9696; Purushotam, Guru
   Nanma/0009-0003-0933-0997; J J, Dr. Lohith/0000-0003-2117-2250
CR Ahmad D., 2003, IEEE Security & Privacy, V1, P77, DOI 10.1109/MSECP.2003.1219077
   Albert E, 2018, LECT NOTES COMPUT SC, V11138, P513, DOI 10.1007/978-3-030-01090-4_30
   Alharby M, 2017, ARXIV
   Ashizawa N., 2021, P 3 ACM INT S BLOCKC, P47
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Brent L., 2018, ARXIV
   Buterin V., 2013, GitHub repository, P22
   Cachin C., 2016, P WORKSH DISTR CRYPT, V310, P1, DOI DOI 10.4230/LIPICS.OPODIS.2016.24
   Cavnar W.B., 1994, Proceedings of SDAIR-94, 3rd Annual Symposium on Document Analysis and Information Retrieval, V48113, P161
   Chen JX, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116287
   Chen WL, 2019, IEEE ACCESS, V7, P37575, DOI 10.1109/ACCESS.2019.2905769
   Contro F, 2021, ARXIV
   Dharanikota Samvid, 2021, 2021 Formal Methods in Computer Aided Design (FMCAD), P133, DOI 10.34727/2021/isbn.978-3-85448-046-4_22
   Dick S., 2019, Artificial intelligence
   Eshghie M, 2021, PROCEEDINGS OF EVALUATION AND ASSESSMENT IN SOFTWARE ENGINEERING (EASE 2021), P305, DOI 10.1145/3463274.3463348
   Ethylbenzene, 2023, Ethylbenzene
   Feist J, 2019, 2019 IEEE/ACM 2ND INTERNATIONAL WORKSHOP ON EMERGING TRENDS IN SOFTWARE ENGINEERING FOR BLOCKCHAIN (WETSEB 2019), P8, DOI 10.1109/WETSEB.2019.00008
   Ferreira JF, 2020, IEEE INT CONF AUTOM, P1349, DOI 10.1145/3324884.3415298
   Grieco Gustavo, 2020, ISSTA '20: Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, P557, DOI 10.1145/3395363.3404366
   Guo GD, 2003, LECT NOTES COMPUT SC, V2888, P986
   Hegedus P, 2019, TECHNOLOGIES, V7, DOI 10.3390/technologies7010006
   Huang TH-D, 2018, ARXIV
   Jentzsch C., 2016, Decentralized autonomous organization to automate governance
   Kalra S, 2018, 25TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2018), DOI 10.14722/ndss.2018.23082
   Kaviani P., 2017, J ADV RES COMPUTER S, V4, P607
   Khan SA, 2022, POLYM BULL, V79, P2685, DOI 10.1007/s00289-021-03638-5
   Kumar R, 2014, INT CONF COMM SYST, P383, DOI 10.1109/CSNT.2014.82
   Liao X, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103244
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liljestrand H, 2021, 30 USENIX SEC S USEN
   Lutz O, 2021, ARXIV
   Luu L, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P254, DOI 10.1145/2976749.2978309
   Min SangLyul., 1989, A timestamp-Based Cache Coherence Scheme
   Momeni P, 2019, ANN CONF PRIV SECUR, P272, DOI 10.1109/pst47121.2019.8949045
   Mossberg M, 2019, 34TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING (ASE 2019), P1186, DOI 10.1109/ASE.2019.00133
   Mueller B, 2023, CONSENSYS MYTHRIL
   Nakamoto S., 2008, DECENT BUS REV, V21260, DOI https://bitcoin.org/bitcoin.pdf
   Nikolic I, 2018, 34TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2018), P653, DOI 10.1145/3274694.3274743
   Parthasarathy S, 2021, 2021 11 IFIP INT C N, P1, DOI [10.1109/NTMS49979.2021.9432643, DOI 10.1109/NTMS49979.2021.9432643]
   Ray I, 2006, DISTRIB PARALLEL DAT, V20, P5, DOI 10.1007/s10619-006-8593-9
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sambana B, 2020, INT J SECUR APPL, V14, P1, DOI 10.33832/ijsia.2020.14.1.01
   Samreen NF, 2020, PROCEEDINGS OF THE 2020 IEEE 3RD INTERNATIONAL WORKSHOP ON BLOCKCHAIN ORIENTED SOFTWARE ENGINEERING (IWBOSE '20), P22, DOI [10.1109/iwbose50093.2020.9050260, 10.1109/IWBOSE50093.2020.9050260]
   Sarker I. H., 2021, SN COMPUT SCI, V2, DOI [DOI 10.1007/S42979-021-00592-X, 10.1007/s42979-021-00592-x, 10.1007 /s42979-021-00592-x]
   Sezer S, 2020, POEM WORKSH, P11
   Singh R, 2022, COMPUT INTEL NEUROSC, V2022
   Spyromitros E, 2008, LECT NOTES ARTIF INT, V5138, P401, DOI 10.1007/978-3-540-87881-0_40
   Tikhomirov S, 2018, 2018 IEEE/ACM 1ST INTERNATIONAL WORKSHOP ON EMERGING TRENDS IN SOFTWARE ENGINEERING FOR BLOCKCHAIN (WETSEB), P9, DOI 10.1145/3194113.3194115
   Tsankov P, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P67, DOI 10.1145/3243734.3243780
   Xing CP, 2020, WIREL NETW, DOI 10.1007/s11276-020-02379-z
   Xu Y, 2021, SECUR COMMUN NETW, V2021
   Yuhang Sun, 2021, Journal of Physics: Conference Series, V1820, DOI 10.1088/1742-6596/1820/1/012004
   Zeng F, 2009, 2009 5 INT C WIR COM, P1
   Zhang M, 2020, IEEE WCNC, DOI 10.1109/wcnc45663.2020.9120741
   Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019
   Zhu XJ, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.494
   Zhuang Y, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3283
NR 57
TC 2
Z9 2
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 36379
EP 36393
DI 10.1007/s11042-023-15042-4
EA MAR 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN8D9
UT WOS:000983783100001
DA 2024-07-18
ER

PT J
AU Oguz, EA
   Strle, G
   Kosir, A
AF Oguz, Evin Aslan
   Strle, Gregor
   Kosir, Andrej
TI Multimedia ad exposure scale: measuring short-term impact of online ad
   exposure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Consumer behavior; Engagement; Measurement; Multimedia communication;
   Advertisement exposure; Psychometric instrument
ID BRAND ATTITUDE; ENGAGEMENT; CONSUMER; COMMUNICATION; CONCEPTUALIZATION;
   ADVERTISEMENTS; INTRUSIVENESS; FREQUENCY
AB The shift toward fragmented and ubiquitous use of multimedia poses several challenges to our understanding and assessment of multimedia exposure and its effects. This article focuses on multimedia advertising exposure and its impact on consumer behavior. It presents the development of Multimedia Ad Exposure Scale (MMAES) - an instrument designed to measure short-term effects of online multimedia ad exposure in terms of engagement, psychological reactance, awareness and attitude, and purchase intention. The main research challenge has been to identify core dimensions that can reliably measure such exposure, particularly in the context of ad-supported video streaming. The development of MMAES is presented through its conceptualization, operationalization, and an observational study conducted via crowdsourcing. The target group is young adults (ages 18-24, N = 360), digital natives who engage with ad-supported video streaming more than any other user group. Exploratory factor analysis revealed a well-defined four-factor structure of MMAES. The results of the validity and reliability measures show good content and construct validity as well as good overall reliability and very good internal consistency of MMAES. Overall, the results show that MMAES is a reliable instrument for measuring the short-term effects of multimedia ad exposure and its weak ground truth.
C1 [Oguz, Evin Aslan; Strle, Gregor; Kosir, Andrej] Univ Ljubljana, Fac Elect Engn, User adapted Commun & Ambient Intelligence Lab, Trzaska cesta 25, Ljubljana 1001, Slovenia.
   [Oguz, Evin Aslan] Nielsen Lab doo, Obrtniska ul 15, Koper 6000, Slovenia.
   [Strle, Gregor] Res Ctr Slovenian Acad Sci & Arts, Novi trg 2, Ljubljana 1000, Slovenia.
C3 University of Ljubljana; Slovenian Academy of Sciences & Arts (SASA)
RP Oguz, EA (corresponding author), Univ Ljubljana, Fac Elect Engn, User adapted Commun & Ambient Intelligence Lab, Trzaska cesta 25, Ljubljana 1001, Slovenia.; Oguz, EA (corresponding author), Nielsen Lab doo, Obrtniska ul 15, Koper 6000, Slovenia.
EM evin.aslan-oguz@fe.uni-lj.si; gregor.strle@fe.uni-lj.si;
   andrej.kosir@fe.uni-lj.si
RI Strle, Gregor/C-7255-2015
OI Strle, Gregor/0000-0003-1076-6707; Kosir, Andrej/0000-0001-6938-221X
FU Nielsen Company;  [P2-0246 ICT4QoL]
FX This research was supported by The Nielsen Company and project P2-0246
   ICT4QoL - Information and Communications Technologies for Quality of
   Life. We thank our colleagues at The Nielsen Company, who provided
   expert feedback on parts of the research presented.
CR Amarnath DD., 2020, MANAGEMENT REV Q, V71, P41, DOI [DOI 10.1007/S11301-020-00180-Y, 10.1007/s11301-020-00180-y]
   Anderson A, 2017, 10TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2017), P181, DOI 10.1145/3056540.3064956
   Ang CS, 2017, COMPUT HUM BEHAV, V66, P1, DOI 10.1016/j.chb.2016.09.028
   Araujo T, 2020, J ADVERTISING, V49, P428, DOI 10.1080/00913367.2020.1795756
   Bellman S, 2020, J BUS RES, V120, P103, DOI 10.1016/j.jbusres.2020.07.034
   Brassington F, 2007, BRIT J SPEC EDUC, DOI [10.4324/9781315177014, DOI 10.4324/9781315177014]
   Brehm Jack W., 1966, THEORY PSYCHOL REACT
   Calder BJ, 2016, J ADVERTISING RES, V56, P39, DOI 10.2501/JAR-2015-028
   CAMPBELL DT, 1959, PSYCHOL BULL, V56, P81, DOI 10.1037/h0046016
   Che XH, 2015, IEEE MULTIMEDIA, V22, P56, DOI 10.1109/MMUL.2015.34
   Cheong Y, 2010, J ADVERTISING RES, V50, P403, DOI 10.2501/S0021849910091555
   Cho E, 2016, ORGAN RES METHODS, V19, P651, DOI 10.1177/1094428116656239
   Daems K, 2019, COMPUT HUM BEHAV, V99, P245, DOI 10.1016/j.chb.2019.05.031
   Danaher PJ, 2013, J MARKETING RES, V50, P517, DOI 10.1509/jmr.12.0241
   de Vreese CH, 2016, COMMUN METHODS MEAS, V10, P69, DOI 10.1080/19312458.2016.1150441
   de Vries L, 2017, J MARKETING, V81, P1, DOI 10.1509/jm.15.0178
   Dehghani M, 2016, COMPUT HUM BEHAV, V59, P165, DOI 10.1016/j.chb.2016.01.037
   Dessart L, 2016, J MARKET MANAG-UK, V32, P399, DOI 10.1080/0267257X.2015.1130738
   Edwards SM, 2002, J ADVERTISING, V31, P83, DOI 10.1080/00913367.2002.10673678
   Ehrenbrink P., 2018, Quality and User Experience, V3, P1, DOI [DOI 10.1007/S41233-018-0016-Y, 10.1007/s41233-018-0016y, DOI 10.1007/S41233-018-0016Y]
   Feldman T, 1994, BRBRF REPORT
   FORNELL C, 1981, J MARKETING RES, V18, P39, DOI 10.2307/3151312
   Foster D., 2020, Factors influencing the popularity of YouTube videos and users' decisions to watch them
   Goldman S K., 2020, The Oxford Handbook of Electoral Persuasion, P997, DOI [DOI 10.1093/OXFORDHB/9780190860806.013.28, https://doi.org/10.1093/oxfordhb/9780190860806.013.28]
   Henrie CR, 2015, COMPUT EDUC, V90, P36, DOI 10.1016/j.compedu.2015.09.005
   Higgins ET, 2009, J CONSUM PSYCHOL, V19, P100, DOI 10.1016/j.jcps.2009.02.002
   Hinkin TR, 1998, ORGAN RES METHODS, V1, P104, DOI 10.1177/109442819800100106
   Hollebeek LD, 2014, J INTERACT MARK, V28, P149, DOI 10.1016/j.intmar.2013.12.002
   HORN JL, 1965, PSYCHOMETRIKA, V30, P179, DOI 10.1007/BF02289447
   Hossfeld T, 2014, IEEE T MULTIMEDIA, V16, P541, DOI 10.1109/TMM.2013.2291663
   Jung AR, 2017, COMPUT HUM BEHAV, V70, P303, DOI 10.1016/j.chb.2017.01.008
   Li HR, 2002, J ADVERTISING, V31, P37, DOI 10.1080/00913367.2002.10673665
   Mayrhofer M, 2020, INT J ADVERT, V39, P166, DOI 10.1080/02650487.2019.1596447
   Möller J, 2020, SOC SCI COMPUT REV, V38, P616, DOI 10.1177/0894439319828012
   Munsch A, 2021, J GLOB SCHOLARS MARK, V31, P10
   Nagler R.H., 2017, The International Encyclopedia of Communication Research Methods, DOI DOI 10.1002/9781118901731.IECRM0144
   Niederdeppe J, 2016, COMMUN METHODS MEAS, V10, P170, DOI 10.1080/19312458.2016.1150970
   Nijholt A., 2012, P 8 INT C METHODS TE, V63, P72
   O'Brien H., 2009, ADVANCES, V2009, P1
   O'Brien HL, 2018, INT J HUM-COMPUT ST, V112, P28, DOI 10.1016/j.ijhcs.2018.01.004
   PQ Media, 2019, GLOB CONS MED US EXP
   Riedel AS, 2018, J MARKET MANAG-UK, V34, P750, DOI 10.1080/0267257X.2018.1496130
   Sama R, 2019, J CREAT COMMUN, V14, P54, DOI 10.1177/0973258618822624
   Shen WB, 2020, CREATIVITY RES J, V32, P313, DOI 10.1080/10400419.2020.1821568
   Slater MD, 2004, J MASS COMMUN Q, V81, P168, DOI 10.1177/107769900408100112
   STAYMAN DM, 1991, J MARKETING RES, V28, P232, DOI 10.2307/3172812
   The Nielsen Company, 2019, NIELS TOT AUD REP Q1
   The Nielsen Company, 2020, SVOD NIELS CO
   VandenBos G.R.E., 2015, APA dictionary of psychology, V2nd, DOI DOI 10.1037/14646-000
   Weibel D, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00626
   Winter S, 2021, COMPUT HUM BEHAV, V114, DOI 10.1016/j.chb.2020.106525
   Yang R, 2020, COMPUT HUM BEHAV, V110, DOI 10.1016/j.chb.2020.106376
   Yang Y, 2017, COMPUT HUM BEHAV, V73, P459, DOI 10.1016/j.chb.2017.03.066
NR 53
TC 0
Z9 0
U1 5
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 38421
EP 38445
DI 10.1007/s11042-023-14401-5
EA MAR 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000960423600017
OA hybrid
DA 2024-07-18
ER

PT J
AU Gündogdu, S
AF Gundogdu, Serdar
TI Efficient prediction of early-stage diabetes using XGBoost classifier
   with random forest feature selection technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; Diabetes; Feature selection; MLR; Random forest; XGBoost
ID MACHINE; MELLITUS; MODELS; PLASMA
AB Diabetes is one of the most common and serious diseases affecting human health. Early diagnosis and treatment are vital to prevent or delay complications related to diabetes. An automated diabetes detection system assists physicians in the early diagnosis of the disease and reduces complications by providing fast and precise results. This study aims to introduce a technique based on a combination of multiple linear regression (MLR), random forest (RF), and XGBoost (XG) to diagnose diabetes from questionnaire data. MLR-RF algorithm is used for feature selection, and XG is used for classification in the proposed system. The dataset is the diabetic hospital data in Sylhet, Bangladesh. It contains 520 instances, including 320 diabetics and 200 control instances. The performance of the classifiers is measured concerning accuracy (ACC), precision (PPV), recall (SEN, sensitivity), F1 score (F1), and the area under the receiver-operating-characteristic curve (AUC). The results show that the proposed system achieves an accuracy of 99.2%, an AUC of 99.3%, and a prediction time of 0.04825 seconds. The feature selection method improves the prediction time, although it does not affect the accuracy of the four compared classifiers. The results of this study are quite reasonable and successful when compared with other studies. The proposed method can be used as an auxiliary tool in diagnosing diabetes.
C1 [Gundogdu, Serdar] Dokuz Eylul Univ, Bergama Vocat Sch, Dept Comp Technol, Izmir, Turkiye.
C3 Dokuz Eylul University
RP Gündogdu, S (corresponding author), Dokuz Eylul Univ, Bergama Vocat Sch, Dept Comp Technol, Izmir, Turkiye.
EM serdar.gundogdu@deu.edu.tr
RI gündoğdu, serdar/GQH-2961-2022
OI Gundogdu, Serdar/0000-0003-2549-5284
CR Ayon SI, 2022, IETE J RES, V68, P2488, DOI 10.1080/03772063.2020.1713916
   Bloomgarden ZT, 2020, J DIABETES, V12, P347, DOI 10.1111/1753-0407.13027
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Choubey DK, 2017, INT J BIOMED ENG TEC, V23, P71, DOI 10.1504/IJBET.2017.082229
   Craig CL, 2003, MED SCI SPORT EXER, V35, P1381, DOI 10.1249/01.MSS.0000078924.61453.FB
   Damle R, 2016, SEMIN COLON RECTAL S, V27, P92, DOI 10.1053/j.scrs.2016.01.006
   Dong YX, 2021, APPL SOFT COMPUT, V99, DOI 10.1016/j.asoc.2020.106900
   Frank EA, 2012, J CLIN LAB ANAL, V26, P317, DOI 10.1002/jcla.21524
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Garcia-Carretero R, 2020, MED BIOL ENG COMPUT, V58, P991, DOI 10.1007/s11517-020-02132-w
   Ghasemi J, 2007, J MOL STRUC-THEOCHEM, V805, P27, DOI 10.1016/j.theochem.2006.09.026
   Ghorbani H, 2020, J KOREAN SOC MATH ED, V27, P71, DOI 10.7468/jksmeb.2020.27.2.71
   Giglioni V, 2021, ENG STRUCT, V246, DOI 10.1016/j.engstruct.2021.113029
   Goeijenbier M, 2017, VACCINE, V35, P5095, DOI 10.1016/j.vaccine.2017.07.095
   Gourisaria MK, 2022, IET COMMUN, V16, P532, DOI 10.1049/cmu2.12338
   Gündogdu S, 2021, CROAT MED J, V62, P480, DOI 10.3325/cmj.2021.62.480
   Guo WN, 2020, DIABETES-METAB RES, V36, DOI 10.1002/dmrr.3319
   Gupta D, 2021, MULTIMED TOOLS APPL, V80, P30091, DOI 10.1007/s11042-020-10242-8
   Gupta VK, 2021, BIG DATA MIN ANAL, V4, P116, DOI 10.26599/BDMA.2020.9020016
   Han Wu, 2018, Informatics in Medicine Unlocked, V10, P100, DOI 10.1016/j.imu.2017.12.006
   Haque M E., 2018, Proceedings of 2018 21st International Conference of Computer and Information Technology (ICCIT'18), P21, DOI [DOI 10.1109/ICCITECHN.2018.8631957, 10.1109/IC4ME2.2018.8465658, DOI 10.1109/IC4ME2.2018.8465658]
   Hasan MK, 2016, 2016 5TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS AND VISION (ICIEV), P574, DOI 10.1109/ICIEV.2016.7760068
   He K, 2016, BIOINFORMATICS, V32, P50, DOI 10.1093/bioinformatics/btv517
   Hodgson K, 2015, IMMUNOLOGY, V144, P171, DOI 10.1111/imm.12394
   Islam Ayon S., 2019, Int J Inf Eng Electronic Business, V11, P21, DOI DOI 10.5815/IJIEEB.2019.02.03
   Islam M.J., 2020, arXiv
   Islam M. M. Faniqul, 2020, Computer Vision and Machine Intelligence in Medical Image Analysis. International Symposium, ISCMM 2019. Advances in Intelligent Systems and Computing (AISC 992), P113, DOI 10.1007/978-981-13-8798-2_12
   Islam Md Milon, 2020, SN Comput Sci, V1, P274, DOI 10.1007/s42979-020-00300-1
   Islam MM, 2017, IEEE REG 10 HUMANIT, P226, DOI 10.1109/R10-HTC.2017.8288944
   Islam Md Zabirul, 2020, Inform Med Unlocked, V20, P100412, DOI 10.1016/j.imu.2020.100412
   Islam MM, 2020, MEDRXIV, DOI [10.1101/2020.08.24.20181339v1, DOI 10.1101/2020.08.24.20181339V1]
   Jackins V, 2021, J SUPERCOMPUT, V77, P5198, DOI 10.1007/s11227-020-03481-x
   Javed F., 2017, Journal of Internet Banking and Commerce, V22, P1, DOI [10.1007/978-3-642-38427-1_114, DOI 10.1007/978-3-642-38427-1_114]
   Johnson R, 2014, IEEE T PATTERN ANAL, V36, P942, DOI 10.1109/TPAMI.2013.159
   Kandhasamy JP, 2015, PROCEDIA COMPUT SCI, V47, P45, DOI 10.1016/j.procs.2015.03.182
   Kilicarslan S, 2020, MED HYPOTHESES, V137, DOI 10.1016/j.mehy.2020.109577
   Knapp S, 2013, GERONTOLOGY, V59, P99, DOI 10.1159/000345107
   Kononenko I., 1994, EUR C MACH LEARN, V94, P171, DOI DOI 10.1007/3-540-57868-4_57
   Kumar HSS, 2022, MULTIMED TOOLS APPL, V81, P17669, DOI 10.1007/s11042-022-12474-2
   Le NQK, 2021, GENE, V787, DOI 10.1016/j.gene.2021.145643
   Mohapatra S, 2022, MULTIMED TOOLS APPL, V81, P24799, DOI 10.1007/s11042-022-12824-0
   Morse JM., 2002, INT J QUAL METH, V1, P13, DOI [DOI 10.1177/160940690200100202, 10.1177/160940690200100202]
   Muhammad L J, 2020, SN Comput Sci, V1, P206, DOI 10.1007/s42979-020-00216-w
   Naz H, 2020, J DIABETES METAB DIS, V19, P391, DOI 10.1007/s40200-020-00520-5
   Pan YW, 2020, KNOWL-BASED SYST, V189, DOI 10.1016/j.knosys.2019.105088
   Rahman Mohammad Marufur, 2021, SN Comput Sci, V2, P384, DOI 10.1007/s42979-021-00774-7
   Saha Prottoy, 2021, Inform Med Unlocked, V22, P100505, DOI 10.1016/j.imu.2020.100505
   Shrivastav LK, 2021, APPL INTELL, V51, P2727, DOI 10.1007/s10489-020-01997-6
   Song X, 2020, JMIR MED INF, V8, P95, DOI 10.2196/15510
   Tigga NP, 2020, PROCEDIA COMPUT SCI, V167, P706, DOI 10.1016/j.procs.2020.03.336
   Torlay L, 2017, Brain Inform, V4, P159, DOI 10.1007/s40708-017-0065-7
   UCI Machine learning Repository, 2021, EARL STAG DIAB RISK
   Wang DW, 2020, JAMA-J AM MED ASSOC, V323, P1061, DOI 10.1001/jama.2020.1585
   WHO, 2006, DEF DIAGN DIAB MELL, P1
   who, Diabetes
   Yang JK, 2006, DIABETIC MED, V23, P623, DOI 10.1111/j.1464-5491.2006.01861.x
   Yang S., 2017, Southwest Respir. Crit. Care Chron, V5, P34, DOI DOI 10.12746/SWRCCC.V5I19.391
   Zhang X, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS AND MECHATRONICS (ICARM), P380, DOI 10.1109/ICARM.2017.8273192
   Zou Q, 2018, FRONT GENET, V9, DOI 10.3389/fgene.2018.00515
NR 59
TC 5
Z9 5
U1 7
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34163
EP 34181
DI 10.1007/s11042-023-15165-8
EA MAR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000958668000004
PM 37362660
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Mishra, VK
   Chaudhary, PK
   Pant, T
AF Mishra, Vikash Kumar
   Chaudhary, Prince Kumar
   Pant, Triloki
TI Image fusion based approach of water extraction from spectrally mixed
   water regions belonging to the sources of varying nature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Landsat-8; Principal component analysis; Classification; Satellite image
   fusion; Feature mixing; Meet but don't mix; Panchromatic and
   multispectral image
ID INDEX NDWI; SATELLITE; CLASSIFICATION
AB Remote sensing devices are keeping eyes on the earth surface to acquire information directly and quickly. A remote sensing image carries information about the biophysical materials of the million acres of land and hence identification and extraction of earth features from the remote sensing big data is the major application of remote sensing. In the present work Landsat-8 and Sentinel-2 data are used to extract water bodies in Prayagraj district, Uttar Pradesh, India. There are two problems observed in dealing with panchromatic band of Landsat-8 in the study area i.e., meet but don't mix and feature mixing. The meet but don't mix problem refers to the classification of water regions of two confluencing rivers into two different classes. On the other hand, feature mixing refers to the mixing of water regions with neighboring vegetation regions during classification. It is claimed in past research that the Near InfraRed (NIR) band is suitable for water enhancement as the other Land Use Land Cover (LULC) features are suppressed. So, the Panchromatic (PAN) band is fused with Infra-Red band using Principal Component Analysis (PCA). The fused images are classified and it is observed that the aforesaid two problems are resolved and the overall classification accuracy is improved from 74.23% to 89.1% after fusion.
C1 [Mishra, Vikash Kumar; Chaudhary, Prince Kumar; Pant, Triloki] Indian Inst Informat Technol Allahabad, Prayagraj, Uttar Pradesh, India.
C3 Indian Institute of Information Technology Allahabad
RP Mishra, VK (corresponding author), Indian Inst Informat Technol Allahabad, Prayagraj, Uttar Pradesh, India.
EM rsi2018505@iiita.ac.in
RI Pant, Triloki/AAO-2085-2021
OI Pant, Triloki/0000-0001-8472-3094; Mishra, Vikash
   Kumar/0000-0001-5481-1368
FU The first author is thankful to "Ministry of Education" for providing
   partial financial support to this research work.
FX The first author is thankful to "Ministry of Education" for providing
   partial financial support to this research work.
CR Aanaes H, 2008, IEEE T GEOSCI REMOTE, V46, P1336, DOI 10.1109/TGRS.2008.916475
   Al-Wassai FA, 2011, Arxiv, DOI arXiv:1110.4970
   Ablin R, 2020, EUR J REMOTE SENS, V53, P86, DOI 10.1080/22797254.2019.1673216
   Batur E, 2019, IEEE T GEOSCI REMOTE, V57, P2983, DOI 10.1109/TGRS.2018.2879024
   Chi MM, 2016, P IEEE, V104, P2207, DOI 10.1109/JPROC.2016.2598228
   Choi J, 2011, IEEE T GEOSCI REMOTE, V49, P295, DOI 10.1109/TGRS.2010.2051674
   Feyisa GL, 2014, REMOTE SENS ENVIRON, V140, P23, DOI 10.1016/j.rse.2013.08.029
   Fisher A, 2016, REMOTE SENS ENVIRON, V175, P167, DOI 10.1016/j.rse.2015.12.055
   Gharbia R, 2014, Arxiv, DOI arXiv:1403.5473
   Lacaux JP, 2007, REMOTE SENS ENVIRON, V106, P66, DOI 10.1016/j.rse.2006.07.012
   Liu P, 2015, FRONT ENV SCI-SWITZ, V3, DOI 10.3389/fenvs.2015.00045
   McFeeters SK, 1996, INT J REMOTE SENS, V17, P1425, DOI 10.1080/01431169608948714
   Metwalli MR, 2010, J OPT SOC AM A, V27, P1385, DOI 10.1364/JOSAA.27.001385
   Mondejar JP, 2019, SUSTAIN ENVIRON RES, V29, DOI 10.1186/s42834-019-0016-5
   N2YO.com, 2018, N2YO
   Sarp G, 2017, J TAIBAH UNIV SCI, V11, P381, DOI 10.1016/j.jtusci.2016.04.005
   SHEN L, 2010, P 18 INT C GEOINF BE, P1, DOI 10.1109/GEOINFORMATICS.2010.5567762
   Song HH, 2013, IEEE T GEOSCI REMOTE, V51, P1883, DOI 10.1109/TGRS.2012.2213095
   Wenbo W, 2008, Remote Sensing and Spatial Information Sciences, V37, P1141
   Xu HQ, 2006, INT J REMOTE SENS, V27, P3025, DOI 10.1080/01431160600589179
   Yagmur N., 2019, Int Arch Photogramm Remote Sens Spat Inf, V2, P1269, DOI [10.5194/isprs-archives-XLII-2-W13-1269-2019, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-W13-1269-2019]
   Yang WK, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/708985
NR 22
TC 0
Z9 0
U1 5
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39783
EP 39795
DI 10.1007/s11042-023-15095-5
EA MAR 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000983485500003
DA 2024-07-18
ER

PT J
AU Nishimura, T
   Hashimoto, A
   Ushiku, Y
   Kameko, H
   Mori, S
AF Nishimura, Taichi
   Hashimoto, Atsushi
   Ushiku, Yoshitaka
   Kameko, Hirotaka
   Mori, Shinsuke
TI State-aware video procedural captioning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Instructional video; Procedural text; Simulator
AB Video procedural captioning (VPC), which generates procedural text from instructional videos, is an essential task for scene understanding and real-world applications. The main challenge of VPC is to describe how to manipulate materials accurately. This paper focuses on this challenge by designing a new VPC task, generating a procedural text from the clip sequence of an instructional video and material set. In this task, the state of materials is sequentially changed by manipulations, yielding their state-aware visual representations (e.g., eggs are transformed into cracked, stirred, then fried forms). The essential difficulty is to convert such visual representations into textual representations; that is, a model should track the material states after manipulations to better associate the cross-modal relations. To achieve this, we propose a novel VPC method, which modifies an existing textual simulator for tracking material states as a visual simulator and incorporates it into a video captioning model. Our experimental results show the effectiveness of the proposed method, which outperforms state-of-the-art video captioning models. We further analyze the learned embedding of materials to demonstrate that the simulators capture their state transition.
C1 [Nishimura, Taichi] Kyoto Univ, Grad Sch Informat, Yoshidahonmachi, Kyoto, Kyoto 6068501, Japan.
   [Hashimoto, Atsushi; Ushiku, Yoshitaka] OMRON SIN X Corp, 5-24-5 Bunkyo Ku, Tokyo 1138656, Japan.
   [Kameko, Hirotaka; Mori, Shinsuke] Kyoto Univ, Acad Ctr Comp & Media Studies, Yoshidahonmachi, Kyoto, Kyoto 6068501, Japan.
C3 Kyoto University; Kyoto University
RP Nishimura, T (corresponding author), Kyoto Univ, Grad Sch Informat, Yoshidahonmachi, Kyoto, Kyoto 6068501, Japan.
EM taichitary@gmail.com; atsushi.hashimoto@sinicx.com;
   yoshitaka.ushiku@sinicx.com; kameko@i.kyoto-u.ac.jp;
   forest@i.kyoto-u.ac.jp
RI Ushiku, Yoshitaka/Z-4235-2019
OI Ushiku, Yoshitaka/0000-0002-9014-1389; Nishimura,
   Taichi/0000-0001-8725-7164
FU JSPS KAKENHI Grant [JP21J20250, JP20H04210, JP21H04910, JP17H06100];
   JST-Mirai Program [JPMJMI21G2]; JST ACT-I Grant [JPMJPR17U5]
FX This work was supported by JSPS KAKENHI Grant Number JP21J20250 and
   JP20H04210, and partially supported by JP21H04910, JP17H06100, JST-Mirai
   Program Grant Number JPMJMI21G2, and JST ACT-I Grant Number JPMJPR17U5.
CR Akbik Alan, 2018, P 27 INT C COMP LING, P1638
   Alayrac JB, 2017, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2017.234
   Alayrac JB, 2016, PROC CVPR IEEE, P4575, DOI 10.1109/CVPR.2016.495
   Amac MS, 2019, P 23 C COMPUTATIONAL, P441
   Banerjee S., 2005, P ACL WORKSH INTR EX, P65
   Bosselut A, 2018, P ICLR
   Botian Shi, 2020, MM '20: Proceedings of the 28th ACM International Conference on Multimedia, P4355, DOI 10.1145/3394171.3413498
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen JJ, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P32, DOI 10.1145/2964284.2964315
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978
   Dalvi B.B., 2018, P 2018 C N AM CHAPT, DOI 10.18653
   Damen D, 2018, LECT NOTES COMPUT SC, V11208, P753, DOI 10.1007/978-3-030-01225-0_44
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Escorcia V, 2016, LECT NOTES COMPUT SC, V9907, P768, DOI 10.1007/978-3-319-46487-9_47
   Gupta A, 2019, P NAACL WORKSH SPNLP, P7
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jang E., 2017, P ICLR, P1
   Jermsurawong J., 2015, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, P781
   Kiddon C., 2015, P 2015 C EMP METH NA
   Kingma D, 2014, ICLR P, V2014, P1
   Lei J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2603
   Lin Chin-Yew, 2004, P 42 ANN M AOC COMP, P605, DOI [DOI 10.3115/.1218955.1219032, DOI 10.3115/1218955.1219032]
   Maeta H., 2015, Proceedings of the 14th International Conference on Parsing Technologies, P50
   Miech Antoine, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9876, DOI 10.1109/CVPR42600.2020.00990
   Miech A, 2019, IEEE I CONF COMP VIS, P2630, DOI 10.1109/ICCV.2019.00272
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Mintz M., 2009, P JOINT C 47 ANN M A, V2, P1003
   Nishimura T, 2021, P IEEECVF INT C COMP, P3129
   Nishimura T, 2021, P ACMMM
   Nishimura T, 2021, IEEE ACCESS, V9, P2125, DOI 10.1109/ACCESS.2020.3043452
   Pan L, 2020, P ACMMM, P1132
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Park JS, 2019, PROC CVPR IEEE, P6591, DOI 10.1109/CVPR.2019.00676
   Pennington J., 2014, P C EMP METH NAT LAN, P1532, DOI DOI 10.3115/V1/D14-1162
   Radford A., 2015, ARXIV
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Salvador A, 2017, PROC CVPR IEEE, P3068, DOI 10.1109/CVPR.2017.327
   Santoro A, 2019, P NEURIPS, P7299
   See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099
   Shi BT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6382
   Sun C, 2019, IEEE I CONF COMP VIS, P7463, DOI 10.1109/ICCV.2019.00756
   Tan GC, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P745
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2017, ADV NEUR IN, V30
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270
   Xiong YL, 2018, LECT NOTES COMPUT SC, V11215, P489, DOI 10.1007/978-3-030-01252-6_29
   Yamakata Y, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P5187
   Zamir Nadav, 2020, ASYMMETRIC LOSS MULT
   Zhou LW, 2019, PROC CVPR IEEE, P6571, DOI 10.1109/CVPR.2019.00674
   Zhou LW, 2018, AAAI CONF ARTIF INTE, P7590
   Zhou LW, 2018, PROC CVPR IEEE, P8739, DOI 10.1109/CVPR.2018.00911
NR 54
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 20
PY 2023
DI 10.1007/s11042-023-14774-7
EA MAR 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PJ6
UT WOS:000984224700008
DA 2024-07-18
ER

PT J
AU Xiang, J
   Jiang, RD
   Chen, AB
   Zhou, GX
   Chen, WJ
   Liu, ZH
AF Xiang, Jin
   Jiang, Rundong
   Chen, Aibin
   Zhou, Guoxiong
   Chen, Wenjie
   Liu, Zhihua
TI Classification methods of butterfly images based on U-net and STL-MSDNet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Butterfly; U-net; STN; Multi-scale dense network; Laplacian pyramid
ID AUTOMATIC IDENTIFICATION; NETWORK
AB Aiming at the lack of coarse-grained features in butterfly image classification and recognition research, low recognition accuracy, and limited spatial invariance to input data, this paper proposes a butterfly image classification method based on U-Net and STL-MSDNet. Firstly, in order to reduce the influence of complex backgrounds on butterfly image recognition, the U-Net model is used to segment the butterfly ecological image. Then, an STL-MSDNet model is proposed to classify butterfly images. In STL-MSDNet, Spatial Transformer Network (STN) is added to reverse the spatial transformation of butterfly images to eliminate the deformation of image butterflies and make the recognition of the classification network simpler and more efficient. Then, the Laplace pyramid (LP) was introduced to replace gaussian down-sampling in MSDNet, and the butterfly images were decomposed into different spatial frequency bands to obtain butterfly feature maps of three scales, and then they were fused to improve the feature extraction capability of the network. The experimental results show that the butterfly image semantic segmentation algorithm based on U-Net has a good effect and is suitable for the field of image segmentation in complex backgrounds. Compared with MSDNet, DenseNet and traditional classification algorithms, the butterfly image classification model based on STL-MSDNet proposed in this paper has a better effect, better robustness, and a higher recognition rate. The method proposed in this paper solved the problem of low accuracy of classification of butterfly images in complex backgrounds by existing methods, and obtains a classification accuracy of 93.8%, indicating that it has good results in the fine classification of butterflies and can be applied to butterfly identification and realize the application of butterfly ecological research.
C1 [Xiang, Jin; Jiang, Rundong; Chen, Aibin; Zhou, Guoxiong; Chen, Wenjie; Liu, Zhihua] Cent South Univ Forestry & Technol, Inst Artificial Intelligence Applicat, Coll Comp & Informat Engn, Changsha, Peoples R China.
C3 Central South University of Forestry & Technology
RP Chen, AB (corresponding author), Cent South Univ Forestry & Technol, Inst Artificial Intelligence Applicat, Coll Comp & Informat Engn, Changsha, Peoples R China.
EM hotaibin@163.com
RI 刘, 志华/HOF-8314-2023
OI 刘, 志华/0000-0003-3980-2927
CR Chen Yuan, 2011, Acta Entomologica Sinica, V54, P609
   Zeiler MD, 2013, Arxiv, DOI arXiv:1301.3557
   Dai JF, 2016, ADV NEUR IN, V29
   Dong S, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100379
   Fan L, 2015, THESIS BEIJING FORES
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Glorot X., 2010, 13 INT C ARTIFICIAL, V9, P249
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hernández-Serna A, 2014, PEERJ, V2, DOI 10.7717/peerj.563
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jégou S, 2017, IEEE COMPUT SOC CONF, P1175, DOI 10.1109/CVPRW.2017.156
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Kang SH, 2014, J ASIA-PAC ENTOMOL, V17, P143, DOI 10.1016/j.aspen.2013.12.004
   Kaya Y, 2013, TEM J, V2, P13
   Kaya Y, 2014, VISUAL COMPUT, V30, P71, DOI 10.1007/s00371-013-0782-8
   Keserwani P, 2022, IEEE T CIRC SYST VID, V32, P3152, DOI 10.1109/TCSVT.2021.3103922
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin GS, 2018, IEEE T PATTERN ANAL, V40, P1352, DOI 10.1109/TPAMI.2017.2708714
   Liu F, 2007, DISSERTATION, DOI [10.7666/d.y1107954, DOI 10.7666/D.Y1107954]
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Pan Peng-liang, 2008, Entomotaxonomia, V30, P151
   Pan Peng-ling, 2008, Entomotaxonomia, V30, P72
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   [孙晓 Sun Xiao], 2016, [自动化学报, Acta Automatica Sinica], V42, P883
   Sutskever I., 2013, INT C MACHINE LEARNI, P1139
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   [谢娟英 Xie Juanying], 2018, [计算机研究与发展, Journal of Computer Research and Development], V55, P1609
   Yu FS, 2016, Arxiv, DOI [arXiv:1511.07122, DOI 10.48550/ARXIV.1511.07122]
   Yu LH, 2021, MULTIMED TOOLS APPL, V80, P19157, DOI 10.1007/s11042-020-10355-0
   Zhang JW., 2006, DISSERTATION, DOI [10.7666/d.y940039, DOI 10.7666/D.Y940039]
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou Ai-Ming, 2017, Acta Entomologica Sinica, V60, P1339, DOI 10.16380/j.kcxb.2017.11.012
NR 35
TC 0
Z9 0
U1 11
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 18
PY 2023
DI 10.1007/s11042-023-14965-2
EA MAR 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA A0HO6
UT WOS:000952027100004
DA 2024-07-18
ER

PT J
AU Jia, LY
   Wu, W
   Hou, GJ
   Zhao, JJ
   Qiang, Y
   Zhang, YA
   Cai, ML
AF Jia, Liye
   Wu, Wei
   Hou, Guojie
   Zhao, Juanjuan
   Qiang, Yan
   Zhang, Yanan
   Cai, Meiling
TI Residual neural network with mixed loss based on batch training
   technique for identification of EGFR mutation status in lung cancer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mixed loss; Batch training technique; Residual network; EGFR mutation
ID GROWTH-FACTOR RECEPTOR; IMAGING PHENOTYPES; RADIOGENOMICS; FEATURES;
   ADENOCARCINOMA; CLASSIFICATION; CHEMOTHERAPY; ASSOCIATIONS; PREDICTION;
   BIOMARKERS
AB Epidermal growth factor receptor (EGFR) is the key to targeted therapy with tyrosine kinase inhibitors in lung cancer. Traditional identification of EGFR mutation status requires biopsy and sequence testing, which may not be suitable for certain groups who cannot perform biopsy. In this paper, using easily accessible and non-invasive CT images, the residual neural network (ResNet) with mixed loss based on batch training technique is proposed for identification of EGFR mutation status in lung cancer. In this model, the ResNet is regarded as the baseline for feature extraction to avoid the gradient disappearance. Besides, a new mixed loss based on the batch similarity and the cross entropy is proposed to guide the network to better learn the model parameters. The proposed mixed loss utilizes the similarity among batch samples to evaluate the distribution of training data, which can reduce the similarity of different classes and the difference of the same classes. In the experiments, VGG16Net, DenseNet, ResNet18, ResNet34 and ResNet50 models with the mixed loss are trained on the public CT dataset with 155 patients including EGFR mutation status from TCIA. The trained networks are employed to the collected preoperative CT dataset with 56 patients from the cooperative hospital for validating the efficiency of the proposed models. Experimental results show that the proposed models are more appropriate and effective on the lung cancer dataset for identifying the EGFR mutation status. In these models, the ResNet34 with mixed loss is optimal (accuracy = 81.58%, AUC = 0.8861, sensitivity = 80.02%, specificity = 82.90%).
C1 [Jia, Liye; Hou, Guojie; Zhao, Juanjuan; Qiang, Yan; Zhang, Yanan; Cai, Meiling] Taiyuan Univ Technol, Coll Informat & Comp, Taiyuan 030600, Peoples R China.
   [Wu, Wei] Shanxi Med Univ, Dept Physiol, Taiyuan, Peoples R China.
C3 Taiyuan University of Technology; Shanxi Medical University
RP Zhao, JJ (corresponding author), Taiyuan Univ Technol, Coll Informat & Comp, Taiyuan 030600, Peoples R China.
EM zhaojuanjuan@tyut.edu.cn
FU National Natural Science Foundation of China [61972274]; State Key
   Laboratory of Virtual Reality Technology and Systems, China, Beihang
   University [VRLAB2020B0]; Taiyuan City 2019-nCoV Prevention and Control
   Research Project [XE2020-5-04]
FX This work was supported by National Natural Science Foundation of China
   under Grants no. 61972274, the open funding project of State Key
   Laboratory of Virtual Reality Technology and Systems, China, Beihang
   University (Grant No. VRLAB2020B06), and the Taiyuan City 2019-nCoV
   Prevention and Control Research Project (Grant No. XE2020-5-04).
CR Aerts HJWL, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5006
   Chen K, 2021, ARXIV
   Eberhard DA, 2005, J CLIN ONCOL, V23, P5900, DOI 10.1200/JCO.2005.02.857
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Gevaert O, 2017, SCI REP-UK, V7, DOI 10.1038/srep41674
   Gevaert O, 2012, RADIOLOGY, V264, P387, DOI 10.1148/radiol.12111607
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermans Alexander, 2017, ARXIV170307737
   Horvat N, 2019, EUR J RADIOL, V113, P174, DOI 10.1016/j.ejrad.2019.02.022
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang KK, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107744
   Huang ZW, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030764
   Ijaz MF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102809
   Itakura H, 2015, SCI TRANSL MED, V7, DOI 10.1126/scitranslmed.aaa7582
   Jia TY, 2019, EUR RADIOL, V29, P4742, DOI 10.1007/s00330-019-06024-y
   Karlo CA, 2014, RADIOLOGY, V270, P464, DOI 10.1148/radiol.13130663
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lakhani P, 2017, RADIOLOGY, V284, P574, DOI 10.1148/radiol.2017162326
   Lambin P, 2017, NAT REV CLIN ONCOL, V14, P749, DOI 10.1038/nrclinonc.2017.141
   LeCun Y., 1990, ADV NEURAL INFORM PR, P396
   Linardou H, 2008, LANCET ONCOL, V9, P962, DOI 10.1016/S1470-2045(08)70206-7
   Liu Y, 2016, CLIN LUNG CANCER, V17, P441, DOI 10.1016/j.cllc.2016.02.001
   Liu Y, 2016, RADIOLOGY, V280, P271, DOI 10.1148/radiol.2016151455
   Loughran CF, 2011, BRIT J RADIOL, V84, P869, DOI 10.1259/bjr/77245199
   Mandal M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165571
   Morgado J, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11073273
   Oh JE, 2020, CANCER RES TREAT, V52, P51, DOI 10.4143/crt.2019.050
   Qin RX, 2020, IEEE ACCESS, V8, P38517, DOI 10.1109/ACCESS.2020.2971281
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sequist LV, 2013, J CLIN ONCOL, V31, P3327, DOI 10.1200/JCO.2012.44.2806
   Shen W, 2017, PATTERN RECOGN, V61, P663, DOI 10.1016/j.patcog.2016.05.029
   Shiri I, 2020, MOL IMAGING BIOL, V22, P1132, DOI 10.1007/s11307-020-01487-8
   Siegel RL, 2021, CA-CANCER J CLIN, V71, P7, DOI [10.3322/caac.21387, 10.3322/caac.20073, 10.3322/caac.21332, 10.3322/caac.21601, 10.3322/caac.21254, 10.3322/caac.21654, 10.3322/caac.20006, 10.3322/caac.21551]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Song K, 2022, INT J MACH LEARN CYB, V13, P1283, DOI 10.1007/s13042-021-01447-w
   Srinivasu PN, 2021, CMC-COMPUT MATER CON, V69, P3303, DOI 10.32604/cmc.2021.018472
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Thawani R, 2018, LUNG CANCER, V115, P34, DOI 10.1016/j.lungcan.2017.10.015
   Ting DSW, 2017, JAMA-J AM MED ASSOC, V318, P2211, DOI 10.1001/jama.2017.18152
   Velazquez ER, 2017, CANCER RES, V77, P3922, DOI 10.1158/0008-5472.CAN-17-0122
   Wang K, 2019, GUT, V68, P729, DOI 10.1136/gutjnl-2018-316204
   Wang S, 2018, RADIOTHER ONCOL, pS0167
   Wang S, 2019, EUR RESPIR J, V53, DOI 10.1183/13993003.00986-2018
   Wang S, 2018, IEEE ENG MED BIO, P2583, DOI 10.1109/EMBC.2018.8512833
   Wang S, 2017, MED IMAGE ANAL, V40, P172, DOI 10.1016/j.media.2017.06.014
   Yano M, 2006, J THORAC ONCOL, V1, P413, DOI 10.1097/01243894-200606000-00006
   Yue Q, 2018, J NEUROSURG, V129, P27, DOI 10.3171/2017.4.JNS163113
   Zhang JM, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041188
   Zhang LW, 2018, TRANSL ONCOL, V11, P94, DOI 10.1016/j.tranon.2017.10.012
   Zhao JJ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0123694
   Zhou CC, 2011, LANCET ONCOL, V12, P735, DOI 10.1016/S1470-2045(11)70184-X
   Zhou JY, 2015, EUR RADIOL, V25, P1257, DOI 10.1007/s00330-014-3516-z
   Zhou M, 2018, RADIOLOGY, V286, P307, DOI 10.1148/radiol.2017161845
NR 55
TC 0
Z9 0
U1 4
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 33443
EP 33463
DI 10.1007/s11042-023-14876-2
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000953336200015
PM 37362735
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Huang, YB
   Chen, DH
   Zhang, QY
AF Zhang, Yuan
   Huang, Yi-bo
   Chen, De-huai
   Zhang, Qiu-yu
TI Verifiable speech retrieval algorithm based on diversity security
   template and biohashing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Verifiable retrieval of speech; BioHashing; K-medoids; QCNN; Biosafety
   template; Leakage in biometrics
ID TRANSFORM
AB In order to solve the problem of leakage in biometrics, to improve the performance of speech retrieval and the security of single biometric template, this paper proposes a verifiable speech retrieval algorithm based on diversity security template and BioHashing. Firstly, both of biometrics which are the cross-correlation cosine and improved sub-band energy entropy ratio are fused to construct the time-frequency biometric vectors, finally the vectors are classified by the K-medoids algorithm. Then, the dimension vectors of the orthogonal set matrix which is constructed by Schmidt orthogonalization of the QCNN(Quantum Cellular Neural Network) chaotic matrix are one-to-one corresponding to the biometric vectors of the corresponding class to form the diversity biosafety templates, and the templates are further quantified to generate BioHashing sequences. Finally, the address index of dimension vectors of QCNN chaotic matrix and BioHashing sequences of corresponding class are one to one correspondingly encrypted by QCNN chaotic mapping encryption to construct hash index, and then the hash index is stored in the system hash index table of the cloud server. At the same time, the encrypted speech is uploaded to the cloud sever after 2D-LICM chaotic scrambling-shift encryption which is convenient to match and retrieve data for the users. Experimental results show that the diversity template has better security and complexity by using K-medoids algorithm to classify the biometric. Hash index and encrypted speech can effectively prevent the leakage of privacy data. At the same time, the retrieval system has better discrimination and retrieval performance, and it performs verifiable retrieval of speech for content preservation operations.
C1 [Zhang, Yuan; Huang, Yi-bo; Chen, De-huai] Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Peoples R China.
   [Zhang, Qiu-yu] Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Peoples R China.
C3 Northwest Normal University - China; Lanzhou University of Technology
RP Huang, YB (corresponding author), Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Peoples R China.
EM zy13037100557@163.com; huang_yibo@nwnu.edu.cn; chendehuai827@163.com;
   zhangqylz@163.com
OI /0000-0003-1667-3114
FU National Natural Science Foundation of China [61862041]; science and
   technology program of Gansu Province [21JR7RA120]
FX This work is supported by the National Natural Science Foundation of
   China(No.61862041), science and technology program of Gansu
   Province(No.21JR7RA120).
CR Abdullahi SM, 2018, MULTIMED TOOLS APPL, V77, P20753, DOI 10.1007/s11042-017-5509-9
   Atighehchi K, 2019, FUTURE GENER COMP SY, V101, P819, DOI 10.1016/j.future.2019.07.022
   Bernardini C, 2019, COMPUT NETW, V149, P13, DOI 10.1016/j.comnet.2018.11.012
   Bounhas I, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102124
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Chen HC, 2018, MULTIMED TOOLS APPL, V77, P5303, DOI 10.1007/s11042-017-4434-2
   Davis JD, 2017, COGN AFFECT BEHAV NE, V17, P652, DOI 10.3758/s13415-017-0503-2
   Dong XB, 2020, Arxiv, DOI arXiv:1910.07770
   Gong C., 2020, FORENSIC SCI INT REP, V2
   Guo YC, 2017, IEEE T IMAGE PROCESS, V26, P1344, DOI 10.1109/TIP.2017.2652730
   He SF, 2017, COMPUT SCI INF SYST, V14, P703, DOI 10.2298/CSIS170112024H
   Jararweh Y, 2019, MULTIMED TOOLS APPL, V78, P3961, DOI 10.1007/s11042-017-5092-0
   Kermanshahi SK, 2019, LECT NOTES COMPUT SC, V11736, P322, DOI 10.1007/978-3-030-29962-0_16
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Li J, 2017, 2017 10 INT C IM SIG, P1
   Li XF, 2019, CLUSTER COMPUT, V22, P1469, DOI 10.1007/s10586-018-1922-8
   Li Y, 2021, IEEE T COMPUT
   Mafla A., 2021, PATTERN RECOGN, V107656, P110
   Mohamed E, 2019, AIN SHAMS ENG J, V10, P489, DOI 10.1016/j.asej.2018.11.009
   Nair Suraj, 2020, Information Retrieval Technology. 15th Asia Information Retrieval Societies Conference, AIRS 2019. Proceedings. Lecture Notes in Computer Science (LNCS 12004), P145, DOI 10.1007/978-3-030-42835-8_13
   Nakazawa T, 2018, IEEE T SEMICONDUCT M, V31, P309, DOI 10.1109/TSM.2018.2795466
   Prabhu L. Arokia Jesu, 2020, MICROPROCESSORS
   Qin J, 2015, TSINGHUA SCI TECHNOL, V20, P613, DOI 10.1109/TST.2015.7350013
   Revathi B, 2018, J KING SAUD UNIV-COM
   Singh R, 2018, PLANT SIGNAL BEHAV, V13, DOI 10.1080/15592324.2018.1530024
   Solainayagi P, 2019, COGN SYST RES, V56, P26, DOI 10.1016/j.cogsys.2019.01.002
   Tong Q, 2021, IEEE T SERV COMPUT
   Tzelepi M, 2018, NEUROCOMPUTING, V275, P2467, DOI 10.1016/j.neucom.2017.11.022
   Ushakov AV, 2021, INFORM SCIENCES, V545, P344, DOI 10.1016/j.ins.2020.08.121
   Wei Y, 2018, J AUDIO ENG SOC, V66, P100, DOI 10.17743/jaes.2018.0003
   Yang Y, 2018, MULTIMED TOOLS APPL, V77, P9927, DOI 10.1007/s11042-017-4560-x
   Zarezadeh M, 2020, PEER PEER NETW APPL, V13, P207, DOI 10.1007/s12083-019-00736-0
   Zhang Q, 2020, COMPUT SCI J, V31, P168
   Zhang QY, 2020, MULTIMED TOOLS APPL, V79, P29775, DOI 10.1007/s11042-020-09446-9
   Zhang QY, 2021, MULTIMED TOOLS APPL, V80, P1201, DOI 10.1007/s11042-020-09748-y
   Zhang QY, 2020, MULTIMED TOOLS APPL, V79, P6337, DOI 10.1007/s11042-019-08450-y
   Zhang QY, 2018, MULTIMED TOOLS APPL, V77, P21653, DOI 10.1007/s11042-018-5613-5
   Zhang QY, 2018, MULTIMED TOOLS APPL, V77, P1555, DOI 10.1007/s11042-017-4381-y
   Zhang QY, 2019, TURK J ELECTR ENG CO, V27, P1719, DOI 10.3906/elk-1808-161
   Zhou K, 2018, FUTURE GENER COMP SY, V86, P362, DOI 10.1016/j.future.2018.03.047
NR 40
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 17
PY 2023
DI 10.1007/s11042-023-14873-5
EA MAR 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA A2FH1
UT WOS:000953336200011
DA 2024-07-18
ER

PT J
AU Kumar, LMA
   Murugan, S
AF Kumar, L. Maria Anthony
   Murugan, S.
TI Design of cuckoo search optimization with deep belief network for human
   activity recognition and classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human activity recognition; Deep learning; Cuckoo search optimization;
   Deep belief network; Hyperparameter tuning
ID WEARABLE SENSOR
AB In recent years, human activity recognition (HAR) has received significant interest in industrial and academic research due to the widespread sensor deployments like accelerometers and gyroscopes, in products such as smartphones and smartwatches. HAR is utilized in different applications where valuable information about an individual's functional ability and lifestyle is needed namely human computer interaction (HCI), military, healthcare, surveillance, etc. The recent advances of machine learning (ML) and deep learning (DL) models pave a way for the effective design of HAR under restricted experimental setup and adequate training dataset. Therefore, this study develops a new cuckoo search with deep belief network based HAR and classification, named CSODBN-HAR model. The proposed CSODBN-HAR model mianly classifies six different types of human activities such as standing, sitting, lying, walking, walking upstairs, and walking downstairs. The presented CSODBN-HAR model involves standard scalar approach as a pre-processing step. In addition, the DBN model was utilized for the recognition and classification of human activities. Besides, the CSO algorithm is applied for the hyperparameter tuning of the DBN model so that the recognition rate gets considerably enhanced, shows the novelty of the work. A wide range of experimental result analyses is conducted using benchmark dataset and the outcomes are assessed under different aspects. Extensive comparative results stated the superior outcomes of the CSODBN-HAR model over the current state of art HAR systems.
C1 [Kumar, L. Maria Anthony] Annamalai Univ, Dept Comp & Informat Sci, Chidambaram, Tamil Nadu, India.
   [Murugan, S.] Dr MGR Govt Arts & Sci Coll Women, Villupuram, India.
C3 Annamalai University
RP Kumar, LMA (corresponding author), Annamalai Univ, Dept Comp & Informat Sci, Chidambaram, Tamil Nadu, India.
EM lmakumarphd@gmail.com; smuruganmpt79@gmail.com
CR Almanaseer W, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11115228
   Ankita, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113845
   Bianchi V, 2019, IEEE INTERNET THINGS, V6, P8553, DOI 10.1109/JIOT.2019.2920283
   Chen KX, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3447744
   Goyal S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051583
   Hassan MM, 2021, J SUPERCOMPUT, V77, P2237, DOI 10.1007/s11227-020-03361-4
   Hayat A, 2022, INFORMATION, V13, DOI 10.3390/info13060275
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Khan IU, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22010323
   Mekruksavanich S, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10030308
   Nafea O, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062141
   Nweke HF, 2018, EXPERT SYST APPL, V105, P233, DOI 10.1016/j.eswa.2018.03.056
   Peppas K, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10238482
   Ramanujam E, 2021, IEEE SENS J, V21, P13029, DOI 10.1109/JSEN.2021.3069927
   Tasnim N, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11062675
   Wan SH, 2020, MOBILE NETW APPL, V25, P743, DOI 10.1007/s11036-019-01445-x
   Yang XS, 2009, WOR CONG NAT BIOL, P210, DOI 10.1109/nabic.2009.5393690
   Zhang CL, 2022, KNOWL-BASED SYST, V243, DOI 10.1016/j.knosys.2022.108403
   Zhang CL, 2021, APPL SOFT COMPUT, V113, DOI 10.1016/j.asoc.2021.108008
   Zhang CL, 2021, KNOWL-BASED SYST, V220, DOI 10.1016/j.knosys.2021.106924
   Zhang M, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P1036
   Zhou XK, 2020, IEEE INTERNET THINGS, V7, P6429, DOI 10.1109/JIOT.2020.2985082
NR 22
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29823
EP 29841
DI 10.1007/s11042-023-14977-y
EA MAR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000950429600006
DA 2024-07-18
ER

PT J
AU Bai, YJ
   Li, M
   Ma, XJ
   Gan, XJ
   Chen, C
   Chen, C
   Lv, XY
   Li, HT
AF Bai, Yujie
   Li, Min
   Ma, Xiaojian
   Gan, Xiaojing
   Chen, Cheng
   Chen, Chen
   Lv, Xiaoyi
   Li, Hongtao
TI Recognizing breast tumors based on mammograms combined with pre-trained
   neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast imaging reporting and data system; Computer-aided diagnosis;
   Preprocessing; Pre-trained neural network
ID COMPUTER-AIDED DIAGNOSIS; CLASSIFICATION; CANCER; ACCURACY; LESIONS;
   IMAGES; MODEL
AB Breast cancer is one of the most common cancers in women worldwide, and it seriously threatens people's lives and health. Breast Imaging Reporting and Data System is developed as a standardized system or tool for reporting breast mammograms, where different grades of diagnosis and treatment are critical to the survival rate and survival time of patients. Efficient computer-aided diagnosis of breast tumors based on computer vision models can better assist physicians in selecting effective treatment options, thereby reducing patient mortality. Therefore, early detection and early treatment are of great significance to patients with breast disease. In this study, a new image enhancement framework, called Image Negatives and Contrast Limited Adaptive Histogram Equalization Image Enhancement, was created for the first time based on the comparison of a set of multiple data preprocessing methods for detecting normal, benign, and probably benign breasts. The ResNet-50 pre-trained neural network was used for feature extraction and the classification results were compared on K-nearest neighbor, Random Forest, and Support Vector Machine classifiers. The evaluation indexes adopted in this paper include confusion matrix, precision, sensitivity, F1 Score, etc. These evaluation indexes can be used to evaluate the model in a very comprehensive and accurate way. The experiments show that the KNN classifier has the best classification result, the classification accuracy is 85%, and the AUC is 0.89. It is proved that mammography, as a non-invasive screening tool, has certain practical significance in effectively evaluating tumor grade and its clinical application.
C1 [Bai, Yujie; Chen, Cheng; Lv, Xiaoyi] Xinjiang Univ, Coll Software, Urumqi 830046, Peoples R China.
   [Li, Min; Chen, Chen] Xinjiang Univ, Coll Informat Sci & Engn, Urumqi 830046, Peoples R China.
   [Ma, Xiaojian; Gan, Xiaojing; Li, Hongtao] Xinjiang Med Univ, Affiliated Canc Hosp, Urumqi 830011, Peoples R China.
   [Lv, Xiaoyi] Xinjiang Univ, Key Lab Software Engn Technol, Urumqi 830046, Peoples R China.
   [Chen, Chen; Lv, Xiaoyi] Karamay Cent Hosp, Dept Pathol, Xinjiang Key Lab Clin Genet Testing & Biomed Infor, Karamay, Peoples R China.
   [Lv, Xiaoyi] Xinjiang Univ, Key Lab Signal Detect & Proc, Urumqi 830046, Peoples R China.
C3 Xinjiang University; Xinjiang University; Xinjiang Medical University;
   Xinjiang University; Xinjiang University
RP Lv, XY (corresponding author), Xinjiang Univ, Coll Software, Urumqi 830046, Peoples R China.; Li, HT (corresponding author), Xinjiang Med Univ, Affiliated Canc Hosp, Urumqi 830011, Peoples R China.; Lv, XY (corresponding author), Xinjiang Univ, Key Lab Software Engn Technol, Urumqi 830046, Peoples R China.; Lv, XY (corresponding author), Karamay Cent Hosp, Dept Pathol, Xinjiang Key Lab Clin Genet Testing & Biomed Infor, Karamay, Peoples R China.; Lv, XY (corresponding author), Xinjiang Univ, Key Lab Signal Detect & Proc, Urumqi 830046, Peoples R China.
EM xjuwawj01@163.com; lht4656@163.com
RI Zhang, Tianxi/KEH-5921-2024; Yu, Xiaohan/KCK-5462-2024; li,
   li/JVP-2971-2024; wang, zhe/JNE-3510-2023; li, yuan/KBQ-4200-2024; li,
   yifan/JHU-9272-2023; Wang, Yue/JRY-8962-2023; Zhang,
   Yunyi/JHS-3626-2023; wang, jun/JPY-3635-2023; su, hang/KEH-2976-2024;
   Li, siqi/KDN-4520-2024; wang, xiaoxuan/JMP-6531-2023; Wang,
   yl/JNR-4963-2023; li, xiang/JCN-9316-2023; yang, yunfeng/KHT-9566-2024;
   song, yu/KCZ-2003-2024; yang, xiao/JLL-7721-2023; Li, YU/JQV-2716-2023;
   Zhang, Youyou/KCY-0810-2024; YI, J/JJE-7713-2023; Zhang,
   Yuan/JUF-7293-2023; Li, Yan/JRW-0176-2023; Zhou, Yue/JHS-8791-2023;
   zhang, ying/JQX-1479-2023; zhang, xiao/JCN-8822-2023; yuanyuan,
   Li/JEZ-6497-2023; chang, yu/KFB-2822-2024; zhao, lin/JJF-0406-2023; Li,
   J N/JXL-5833-2024; yang, rui/JHI-3328-2023; Li, Yan/JUU-5189-2023; Wang,
   Jing/JRW-1512-2023; wang, xin/JWA-3772-2024; wang, yi/JYO-8193-2024;
   Wang, Xuechun/JRX-6509-2023; LI, WEI/JUE-9796-2023; zhao,
   yan/JNT-6961-2023; wang, wei/JYP-7819-2024; zheng, yan/JKJ-3632-2023;
   Liu, Yang/JVD-6777-2023; Bai, Yujie/AAF-4099-2021; Wang,
   Xin/JVE-0200-2024; Li, Wen/JQI-4757-2023
OI Wang, Yue/0000-0001-8673-6358; 
FU Xinjiang Uygur Autonomous Region Science Foundation for Distinguished
   Young Scholars [2019Q003]; Tianshan Innovation Team Planning Project
   [2020D14031]; Tianshan Youth Planning Project [2019Q043]
FX This work was supported in part by the Xinjiang Uygur Autonomous Region
   Science Foundation for Distinguished Young Scholars under Grant
   2019Q003, in part by the Tianshan Innovation Team Planning Project under
   Grant 2020D14031, and in part by the Tianshan Youth Planning Project
   under Grant 2019Q043.
CR Abdel-Nasser M, 2016, COMPUT METH PROG BIO, V127, P1, DOI 10.1016/j.cmpb.2016.01.019
   Abdelhafiz D, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2823-4
   Al-Najdawi N, 2015, APPL SOFT COMPUT, V35, P175, DOI 10.1016/j.asoc.2015.06.029
   Alshayeji MH, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103141
   [Anonymous], 2021, SOFT COMPUT
   Arputham C, 2021, INTELL AUTOM SOFT CO, V27, P747, DOI 10.32604/iasc.2021.012077
   Bakkouri I, 2019, MULTIMED TOOLS APPL, V78, P12939, DOI 10.1007/s11042-018-6267-z
   Miranda GHB, 2015, COMPUT BIOL MED, V64, P334, DOI 10.1016/j.compbiomed.2014.10.006
   Beeravolu AR, 2021, IEEE ACCESS, V9, P33438, DOI 10.1109/ACCESS.2021.3058773
   Benhassine NE, 2020, INT J IMAG SYST TECH, V30, P45, DOI 10.1002/ima.22352
   Boumaraf S, 2020, BIOMED RES INT, V2020, DOI 10.1155/2020/7695207
   Bozkurt S, 2016, J BIOMED INFORM, V62, P224, DOI 10.1016/j.jbi.2016.07.001
   Chokri F, 2017, IET COMPUT VIS, V11, P189, DOI 10.1049/iet-cvi.2016.0244
   Corcoran J, 2015, REMOTE SENS-BASEL, V7, P4002, DOI 10.3390/rs70404002
   Fanizzi A., 2016, PHYS MEDICA, V32, P217, DOI [10.1016/j.ejmp.2016.07.730, DOI 10.1016/J.EJMP.2016.07.730]
   Ferlay J, 2010, INT J CANCER, V127, P2893, DOI 10.1002/ijc.25516
   Ghaemian N, 2021, CASP J INTERN MED, V12, P573, DOI 10.22088/cjim.12.4.573
   Goel N, 2022, BIOMED SIGNAL PROCES, V75, DOI 10.1016/j.bspc.2022.103624
   Goel N, 2022, SOFT COMPUT, V26, P1231, DOI 10.1007/s00500-021-06546-y
   Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Kumar A., 2019, INT J COMPUTER SCI E, V7, P234, DOI 10.26438/ijcse/v7i1.234240
   Lbachir IA, 2017, I C COMP SYST APPLIC, P166, DOI 10.1109/AICCSA.2017.40
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee S, 2019, OPTIK, V180, P569, DOI 10.1016/j.ijleo.2018.11.167
   Li H, 2019, BIOMED SIGNAL PROCES, V51, P347, DOI 10.1016/j.bspc.2019.02.017
   Li M, 2020, IEEE ACCESS, V8, P141705, DOI 10.1109/ACCESS.2020.3012967
   Loizidou K, 2021, EUR RADIOL EXP, V5, DOI 10.1186/s41747-021-00238-w
   Lu LQ, 2020, PEERJ, V8, DOI 10.7717/peerj.8668
   Luque-Baena RM, 2014, THEOR BIOL MED MODEL, V11, DOI 10.1186/1742-4682-11-S1-S7
   Maroof N, 2020, PHOTODIAGN PHOTODYN, V31, DOI 10.1016/j.pdpdt.2020.101885
   Mathur M, 2020, MULTIMED TOOLS APPL, V79, P31625, DOI 10.1007/s11042-020-09371-x
   Mehmood M, 2021, CMC-COMPUT MATER CON, V67, P641, DOI 10.32604/cmc.2021.013774
   Nwadike UI, 2017, AFR HEALTH SCI, V17, P1044, DOI 10.4314/ahs.v17i4.12
   Payey TG, 2017, J SCI MED SPORT, V20, P75, DOI 10.1016/j.jsams.2016.06.003
   Rajaraman S, 2018, PEERJ, V6, DOI 10.7717/peerj.4568
   Rajathi GM, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02534-6
   Rehman KU, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144854
   Rigatti Steven J, 2017, J Insur Med, V47, P31, DOI 10.17849/insm-47-01-31-39.1
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Saffari N, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10110988
   Shen L, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48995-4
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640
   Verma B, 2008, ARTIF INTELL MED, V42, P67, DOI 10.1016/j.artmed.2007.09.003
   Williamson S, 2022, MULTIMED TOOLS APPL, V81, P36869, DOI 10.1007/s11042-021-11114-5
   Xue J, 2008, IEEE T AUDIO SPEECH, V16, P519, DOI 10.1109/TASL.2007.913036
   Yan ZW, 2020, OPTIK, V208, DOI 10.1016/j.ijleo.2020.164473
   Yang B, 2021, PHOTODIAGN PHOTODYN, V33, DOI 10.1016/j.pdpdt.2021.102199
   Zeng JM, 2019, MED DECIS MAKING, V39, P208, DOI 10.1177/0272989X19832914
   Zhang N, 2021, CLIN IMAG, V79, P56, DOI 10.1016/j.clinimag.2021.03.024
   Zhang QQ, 2020, NEUROCOMPUTING, V376, P141, DOI 10.1016/j.neucom.2019.09.068
   Zhang SL, 2021, IEEE ACCESS, V9, P48980, DOI 10.1109/ACCESS.2021.3064040
   Zhang XF, 2015, IEEE T MED IMAGING, V34, P496, DOI 10.1109/TMI.2014.2361481
   Zhang XF, 2017, IEEE INT C BIOINFORM, P700, DOI 10.1109/BIBM.2017.8217738
NR 55
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27989
EP 28008
DI 10.1007/s11042-023-14708-3
EA MAR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000947594500003
DA 2024-07-18
ER

PT J
AU Dadsena, PK
   Jain, J
   Rana, S
   Dharminder, D
AF Dadsena, Pradeep Kumar
   Jain, Jainendra
   Rana, Saurabh
   Dharminder, Dharminder
TI A construction of post quantum secure authenticated key agreement design
   for mobile digital rights management system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital rights management system; Privacy; Security; Authentication;
   Ideal lattice; Learning with errors
ID DISCRETE LOGARITHMS; PROTOCOL; ALGORITHMS; LATTICES
AB The quantum computing being a threat motivates us to design a post quantum secure authentication protocol for mobile digital rights management system. In current, a post quantum secure protocol "learning with error based secure mobile digital rights management system" has been proposed. The protocol has been claimed to post quantum secure under the ring learning with errors assumption. We have analyzed that this protocol allows the server to keep a fixed private/public key that causes less communication and computation overheads. But, this leads to signal leakage/modified signal leakage attacks. In this paper, we have discussed signal leakage attacks during the authentication phase of the existing protocol. We have proposed a new post quantum authenticated key agreement protocol for the digital rights management system. In the proposed protocol, the server uses a random value instead of using fixed value chosen by the user, and it establishes a session key with the user. Moreover, this protocol needs to exchange just two messages that confirm the efficiency. The protocol has been proved secure in a random oracle model under ring learning with errors assumption. Moreover, the article contains an informal security discussion and a simulation using NS3 simulator.
C1 [Dadsena, Pradeep Kumar; Jain, Jainendra] Govt Engn Coll, Dept Math, Jagdalpur, India.
   [Rana, Saurabh] Chandigarh Univ, Dept Math, Chandigarh, India.
   [Dharminder, Dharminder] Amrita Vishwa Vidyapeetham, Amrita Sch Comp, Dept Comp Sci Engn, Chennai, India.
C3 Chandigarh University; Amrita Vishwa Vidyapeetham; Amrita Vishwa
   Vidyapeetham Chennai
RP Dharminder, D (corresponding author), Amrita Vishwa Vidyapeetham, Amrita Sch Comp, Dept Comp Sci Engn, Chennai, India.
EM manndharminder999@gmail.com
CR Aguilar-Melchor C, 2016, LECT NOTES COMPUT SC, V9610, P341, DOI 10.1007/978-3-319-29485-8_20
   Chang CC, 2013, SECUR COMMUN NETW, V6, P972, DOI 10.1002/sec.647
   Chang CC, 2010, EXPERT SYST APPL, V37, P6176, DOI 10.1016/j.eswa.2010.02.110
   Chen CL, 2008, EXPERT SYST APPL, V35, P878, DOI 10.1016/j.eswa.2007.07.029
   Dabra V, 2020, IEEE Syst J
   Dabra V, 2021, IEEE INT C SEMANT CO, P1
   Das AK, 2015, SECUR COMMUN NETW, V8, P3383, DOI 10.1002/sec.1266
   Dharminder D, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4199
   Dharminder D, 2020, J AMB INTEL HUM COMP, V11, P4089, DOI 10.1007/s12652-019-01675-7
   Dharminder D, 2020, T EMERG TELECOMMUN T, V31, DOI 10.1002/ett.3810
   Ding JT, 2017, IEEE ICC
   Ding JT, 2018, LECT NOTES COMPUT SC, V10946, P467, DOI 10.1007/978-3-319-93638-3_27
   Fan Q, 2022, J INTERNET TECHNOL, V23, P267, DOI 10.53106/160792642022032302007
   Feng Q, 2019, IEEE SYST J, V13, P2775, DOI 10.1109/JSYST.2018.2851295
   Fluhrer S., 2016, Paper 2016/085, V2016, P85
   He DB, 2016, IEEE T INF FOREN SEC, V11, P2052, DOI 10.1109/TIFS.2016.2573746
   He DB, 2014, IEEE T CONSUM ELECTR, V60, P30, DOI 10.1109/TCE.2014.6780922
   Hussain S., 2022, Wireless Communications and Mobile Computing, P1
   Islam SKH, 2016, INT J COMMUN SYST, V29, P1529, DOI 10.1002/dac.3126
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Kim D, 2021, J INF PROCESS SYST, V17, P151, DOI 10.3745/JIPS.01.0063
   Kirkwood B. C., 2015, P WORKSH CYB POSTQ, P21
   Lee CC, 2018, J INF SECUR APPL, V39, P19, DOI 10.1016/j.jisa.2018.02.001
   Liu Y., 2015, Journal of Information Hiding Multimedia Signal Processing, V6, P140
   Lynbashevsky V, 2010, LECT NOTES COMPUT SC, V6110, P1, DOI 10.1145/2535925
   Micciancio D, 2007, COMPUT COMPLEX, V16, P365, DOI 10.1007/s00037-007-0234-9
   Micciancio D, 2007, SIAM J COMPUT, V37, P267, DOI 10.1137/S0097539705447360
   Mishra D, 2021, 2021 1 INT C POWER E, P1
   Rana S, 2021, SADHANA-ACAD P ENG S, V46, DOI 10.1007/s12046-021-01607-2
   SHOR PW, 1994, AN S FDN CO, P124
   Shor PW, 1997, SIAM J COMPUT, V26, P1484, DOI 10.1137/S0036144598347011
   Wang LJ, 2021, NPJ QUANTUM INFORM, V7, DOI [10.10381/s41534-021-00400-7, 10.1038/s41534-021-00400-7]
   Wang Q., 2021, IEEE T DEPEND SECURE
   Yu S, 2020, PEER PEER NETW APPL, V13, P1340, DOI 10.1007/s12083-019-00836-x
   Zeng W, 2012, 2012 SEVENTH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY (ARES), P445, DOI 10.1109/ARES.2012.55
   Zeng W, 2011, ELECTRON NOTES THEOR, V275, P159, DOI 10.1016/j.entcs.2011.09.011
   Zhang J, 2015, LECT NOTES COMPUT SC, V9057, P719, DOI 10.1007/978-3-662-46803-6_24
NR 37
TC 0
Z9 0
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26643
EP 26660
DI 10.1007/s11042-023-14937-6
EA MAR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000946890000004
DA 2024-07-18
ER

PT J
AU Li, KP
   Qi, JL
   Sun, L
AF Li, Kengpeng
   Qi, Jinli
   Sun, Lei
TI Hyperspectral image denoising based on multi-resolution dense memory
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral image (HSI) denoising; Multi-resolution; Power law memory;
   Densely connected convolutional networks
ID RESTORATION
AB Hyperspectral images (HSIs) denoising is an important pre-processing step since noise will seriously degrade the HSIs quality. In this paper, we propose a multi-resolution dense memory denoising network. Specifically, in order to fully use the spatial-spectral correlation of hyperspectral image (HSI), target noisy band and multiple adjacent bands of HSI are extracted as our network input. After feature extraction by convolution kernels, the feature map is divided into resolution of different sizes through average pooling operation. For each resolution, according to the power law distribution of memory system, we design a dense connection structure in which we use weighted sum of the output feature maps for all previous layers. Then, the deconvolution is used for up sampling. Finally, dilated convolution and skip connection are utilized to obtain the denoised HSI. Our method outperforms state-of-the-art denoising algorithms in both quantitative metrics (e.g. PSNR and SSIM) and visual effects on simulated datasets. The real datasets (Indian Pines) experiment demonstrates that the classification accuracy of the denoised HSI is improved by 20.26% compared with the noisy HSI.
C1 [Li, Kengpeng; Qi, Jinli; Sun, Lei] Sun Yat Sen Univ, Sch Syst Sci & Engn, Guangzhou, Guangdong, Peoples R China.
C3 Sun Yat Sen University
RP Sun, L (corresponding author), Sun Yat Sen Univ, Sch Syst Sci & Engn, Guangzhou, Guangdong, Peoples R China.
EM likp6@mail2.sysu.edu.cn; qijli@mail2.sysu.edu.cn;
   sunlei8@mail.sysu.edu.cn
OI Sun, Lei/0000-0002-1017-355X
FU Open Fund of Science & Technology on Integrated Information System
   Laboratory [HLJGXQ20210701001]
FX AcknowledgementsThanks to the authors of the comparison algorithms for
   providing the codes, and sincerely thanks to Strategic Research Systems
   Engineering Laboratory in Sun Yat-Sen University for offering the GPU
   workstation, which greatly helps us to complete the experiment. This
   research is supported in part by the Open Fund of Science & Technology
   on Integrated Information System Laboratory under Grant
   HLJGXQ20210701001.
CR Bioucas-Dias JM, 2012, IEEE J-STARS, V5, P354, DOI 10.1109/JSTARS.2012.2194696
   Chang Y, 2019, IEEE T GEOSCI REMOTE, V57, P667, DOI 10.1109/TGRS.2018.2859203
   Chen Y, 2018, IEEE T CYBERNETICS, V48, P1054, DOI 10.1109/TCYB.2017.2677944
   Edelman M., 2014, Nonlinear dynamics and complexity, P79
   Edelman M., 2018, Chaotic, fractional, and complex dynamics: new insights and perspectives. Understanding complex systems, P147
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He W, 2022, IEEE T PATTERN ANAL, V44, P2089, DOI 10.1109/TPAMI.2020.3027563
   He W, 2018, IEEE J-STARS, V11, P713, DOI 10.1109/JSTARS.2018.2800701
   He W, 2015, IEEE J-STARS, V8, P3050, DOI 10.1109/JSTARS.2015.2398433
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang Y, 2021, IEEE J-STARS, V14, P7654, DOI 10.1109/JSTARS.2021.3099805
   Jia XX, 2019, PROC CVPR IEEE, P6047, DOI 10.1109/CVPR.2019.00621
   Li Q, 2021, IEEE T GEOSCI REMOTE, V59, P8693, DOI 10.1109/TGRS.2020.3047363
   Liu RN, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3100407
   Maffei A, 2020, IEEE T GEOSCI REMOTE, V58, P2516, DOI 10.1109/TGRS.2019.2952062
   Paul A, 2022, MULTIMED TOOLS APPL, V81, P2529, DOI 10.1007/s11042-021-11689-z
   Peng Y, 2014, PROC CVPR IEEE, P2949, DOI 10.1109/CVPR.2014.377
   Ranchin T, 2000, PHOTOGRAMM ENG REM S, V66, P49
   Renard N, 2008, IEEE GEOSCI REMOTE S, V5, P138, DOI 10.1109/LGRS.2008.915736
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   TANNER MA, 1987, J AM STAT ASSOC, V82, P528, DOI 10.2307/2289457
   Wang JH, 2020, IEEE T CYBERNETICS, V50, P2971, DOI 10.1109/TCYB.2019.2891265
   Wang Y, 2018, IEEE J-STARS, V11, P1227, DOI 10.1109/JSTARS.2017.2779539
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei KX, 2021, IEEE T NEUR NET LEAR, V32, P363, DOI 10.1109/TNNLS.2020.2978756
   Yu F., 2015, ARXIV
   Yuan QQ, 2019, IEEE T GEOSCI REMOTE, V57, P1205, DOI 10.1109/TGRS.2018.2865197
   Yuhas R. H., 1993, JPL SUMMARIES 4 ANN, P205
   Zhang HY, 2014, IEEE T GEOSCI REMOTE, V52, P4729, DOI 10.1109/TGRS.2013.2284280
   Zhang LF, 2014, IEEE T GEOSCI REMOTE, V52, P1030, DOI 10.1109/TGRS.2013.2246837
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhuang L, 2018, IEEE J-STARS, V11, P730, DOI 10.1109/JSTARS.2018.2796570
NR 34
TC 2
Z9 2
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29733
EP 29752
DI 10.1007/s11042-023-14778-3
EA MAR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000943970200022
DA 2024-07-18
ER

PT J
AU El Ogri, O
   Karmouni, H
   Sayyouri, M
   Qjidaa, H
AF El Ogri, Omar
   Karmouni, Hicham
   Sayyouri, Mhamed
   Qjidaa, Hassan
TI A new image/video encryption scheme based on fractional discrete
   Tchebichef transform and singular value decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fractional discrete Tchebichef transform; Singular value decomposition;
   Spectral decomposition; Image encryption; Video encryption
ID SEMI-TENSOR PRODUCT; IMAGE ENCRYPTION; FOURIER-TRANSFORM; COSINE
   TRANSFORM; ALGORITHM; MATRIX; CHAOS; MAP
AB One of the major application areas of the fractional-order discrete transform (FrDTs) is in signal and information security, particularly in signal and image/video encryption. Recently, many researchers proposed techniques that implemented not only the fractional transforms, but also various randomized versions of the FrDTs, which add more security features to signal's encryption. In this paper, we propose a new image/video encryption scheme based on fractional-order discrete Tchebichef transform (FrDTT) using singular value decomposition. The FrDTTs are derived algebraically using the spectral decomposition of discrete Tchebichef polynomials, then the singular value decomposition technique in order to build a basic set of orthonormal eigenvectors which help to develop FrDTTs. Finally, we implement and apply the scheme proposed in this paper for encrypting test images and video sequences. Moreover, we methodically perform the security evaluation in terms of brute force and statistical attacks as well as comparisons with the existing methods in terms of secret key sensitivity and space. The promising experiment results demonstrate the effectiveness and efficiency of our proposed FrDTTs based image encryption techniques.
C1 [El Ogri, Omar; Karmouni, Hicham; Qjidaa, Hassan] Sidi Mohamed Ben Abdellah Fez Univ, Dhar Mahrez Fac Sci, Lab Elect Signals & Syst Informat LESSI, STIC,CED ST, Fes, Morocco.
   [Sayyouri, Mhamed] Sidi Mohamed Ben Abdellah Univ, Natl Sch Appl Sci, Syst & Applicat Lab, Engn Syst & Application Lab, My Abdallah Ave Km 5 Imouzzer Rd,72, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP El Ogri, O (corresponding author), Sidi Mohamed Ben Abdellah Fez Univ, Dhar Mahrez Fac Sci, Lab Elect Signals & Syst Informat LESSI, STIC,CED ST, Fes, Morocco.
EM omar.elogri@usmba.ac.ma; hicham.karmouni@usmba.ac.ma;
   mhamed.sayyouri@usmba.ac.ma; qjidah@yahoo.fr
RI Sayyouri, Mhamed/AAB-5496-2020
OI Sayyouri, Mhamed/0000-0002-1615-419X; El Ogri, Omar/0000-0003-4807-0641
CR Acharya Bibhudendra, 2008, 2008 1st International Conference on Emerging Trends in Engineering and Technology (ICETET), P77, DOI 10.1109/ICETET.2008.110
   [Anonymous], 2021, TEST SEQUENCES
   [Anonymous], 2021, YUV SEQUENCES
   Bahrami S, 2014, ARAB J SCI ENG, V39, P4077, DOI 10.1007/s13369-014-1077-8
   Batham S, 2013, P 4 INT C CONFL 2013, P139, DOI 10.1049/cp.2013.2307
   Bhatnagar G, 2014, IEEE T SYST MAN CY-S, V44, P1234, DOI 10.1109/TSMC.2014.2303789
   Chebyshev Pafnuty Lvovich, 1853, Theorie des mecanismes connus sous le nom de parallelogrammes
   Chen LF, 2013, OPT COMMUN, V291, P98, DOI 10.1016/j.optcom.2012.10.080
   Cheng H, 2000, IEEE T SIGNAL PROCES, V48, P2439, DOI 10.1109/78.852023
   Chihara TS, 2011, Dover Books on Mathematics
   Daoui A., 2020, 2020 INT C INT SYST, P1, DOI DOI 10.1109/ISCV49265.2020.9204132
   El Ogri O, 2021, MULTIDIM SYST SIGN P, V32, P431, DOI 10.1007/s11045-020-00745-w
   El Ogri O, 2020, MULTIMED TOOLS APPL, V79, P23261, DOI 10.1007/s11042-020-09084-1
   El Ogri O, 2021, SIGNAL PROCESS-IMAGE, V98, DOI 10.1016/j.image.2021.116410
   El Ogri O, 2021, NEURAL COMPUT APPL, V33, P13539, DOI 10.1007/s00521-021-05977-w
   El Ogri O, 2021, OPT LASER ENG, V137, DOI 10.1016/j.optlaseng.2020.106346
   Fatnassi A., 2020, INT J SECUR 1 PERVAS, V12, P30
   Fridrich J, 1997, IEEE SYS MAN CYBERN, P1105, DOI 10.1109/ICSMC.1997.638097
   Guizani S, 2012, INT WIREL COMMUN, P1057, DOI 10.1109/IWCMC.2012.6314352
   Hanna MT, 2004, IEEE T CIRCUITS-I, V51, P2245, DOI 10.1109/TCSI.2004.836850
   Jindal N, 2014, SIGNAL IMAGE VIDEO P, V8, P1543, DOI 10.1007/s11760-012-0391-4
   Joshi M, 2010, OPT LASER ENG, V48, P754, DOI 10.1016/j.optlaseng.2010.03.011
   Kang XJ, 2019, IEEE T CIRC SYST VID, V29, P1595, DOI 10.1109/TCSVT.2018.2851983
   Kang XJ, 2019, IEEE T CIRC SYST VID, V29, P1919, DOI 10.1109/TCSVT.2018.2859253
   Karuna Y, 2020, MULTIMED TOOLS APPL, V79, P5281, DOI 10.1007/s11042-018-6416-4
   Kaur G, 2022, J KING SAUD UNIV-COM, V34, P5883, DOI 10.1016/j.jksuci.2021.03.007
   Kaur G, 2022, VISUAL COMPUT, V38, P1027, DOI 10.1007/s00371-021-02066-w
   Kumar S, 2019, MED BIOL ENG COMPUT, V57, P2517, DOI 10.1007/s11517-019-02037-3
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Lang J, 2010, OPT COMMUN, V283, P2092, DOI 10.1016/j.optcom.2010.01.060
   Li SJ, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, PROCEEDINGS, P708
   Lian S., 2008, MULTIMEDIA CONTENT E, DOI [10.1201/9781420065282, DOI 10.1201/9781420065282]
   Lima JB, 2014, SIGNAL PROCESS, V94, P521, DOI 10.1016/j.sigpro.2013.07.020
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu LF, 2017, MULTIMED TOOLS APPL, V76, P16511, DOI 10.1007/s11042-016-3925-x
   Liu X, 2015, OPEN AUTOM CONTROL S, V7, P1560
   Liu XL, 2021, SIGNAL PROCESS, V189, DOI 10.1016/j.sigpro.2021.108275
   Liu XL, 2017, IEEE T SIGNAL PROCES, V65, P1894, DOI 10.1109/TSP.2017.2652383
   MCBRIDE AC, 1987, IMA J APPL MATH, V39, P159, DOI 10.1093/imamat/39.2.159
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Oliveira PAM, 2017, IEEE T CIRC SYST VID, V27, P1066, DOI 10.1109/TCSVT.2016.2515378
   Qiudong Sun, 2012, 2012 9th International Conference on Fuzzy Systems and Knowledge Discovery, P1669, DOI 10.1109/FSKD.2012.6233963
   Rajesh G. R., 2013, IET Chennai Fourth International Conference on Sustainable Energy and Intelligent Systems (SEISCON 2013), P554
   Ramalingam Mritha, 2020, Procedia Computer Science, V171, P1147, DOI 10.1016/j.procs.2020.04.123
   Salunke S, 2021, MATER TODAY-PROC, V47, P6991, DOI 10.1016/j.matpr.2021.05.278
   Stewart G., 1973, INTRO MATRIX COMPUTA
   Sui LS, 2014, OPT ENG, V53, DOI 10.1117/1.OE.53.2.026108
   Suresh M., 2021, DATA INTELLIGENCE CO, P781
   Unnikrishnan G, 2000, OPT LETT, V25, P887, DOI 10.1364/OL.25.000887
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2022, IEEE T CIRCUITS-I, V69, P1291, DOI 10.1109/TCSI.2021.3133318
   Wang XY, 2021, INFORM SCIENCES, V579, P128, DOI 10.1016/j.ins.2021.07.096
   Wang XY, 2021, INFORM SCIENCES, V574, P505, DOI 10.1016/j.ins.2021.06.032
   Wang XY, 2021, INFORM SCIENCES, V569, P217, DOI 10.1016/j.ins.2021.04.013
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Watkins DS, 2007, OTHER TITL APPL MATH, DOI [10.1137/1.9780898717808, DOI 10.1137/1.9780898717808]
   Wu JH, 2017, J MOD OPTIC, V64, P334, DOI 10.1080/09500340.2016.1236990
   Wu JH, 2013, J MOD OPTIC, V60, P1760, DOI 10.1080/09500340.2013.858189
   Xian YJ, 2022, IEEE T CIRC SYST VID, V32, P4028, DOI 10.1109/TCSVT.2021.3108767
   Xian YJ, 2021, INFORM SCIENCES, V547, P1154, DOI 10.1016/j.ins.2020.09.055
   Yamni M, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107509
   Yang TF, 2018, IEEE ACCESS, V6, P47521, DOI 10.1109/ACCESS.2018.2866861
   Zhang L., 2020, MULTIMED TOOLS APPL, V79, P1
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   Zhou NR, 2013, OPT LASER TECHNOL, V47, P341, DOI 10.1016/j.optlastec.2012.08.033
   Zhou NR, 2012, OPT LASER TECHNOL, V44, P2270, DOI 10.1016/j.optlastec.2012.02.027
   Zhou NR, 2011, OPT COMMUN, V284, P5588, DOI 10.1016/j.optcom.2011.08.034
NR 73
TC 1
Z9 1
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 33465
EP 33497
DI 10.1007/s11042-023-14573-0
EA MAR 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000942756000004
DA 2024-07-18
ER

PT J
AU Xue, P
   Wang, C
   Huang, W
   Jiang, G
   Zhou, G
   Raza, M
AF Xue, Pengxiang
   Wang, Changyuan
   Huang, Wenbo
   Jiang, Guangyi
   Zhou, Guanghao
   Raza, Muhammad
TI Pupil centre's localization with transformer without real pupil
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pupil; Transformer; ViT; DETR; FNet
AB Pupil Centre's localization is an essential aspect of ergonomics; it may be used in emotion analysis and attention evaluation. Numerous research studies have demonstrated the transformer to be beneficial in computer vision. When applied to pupil localization, it is envisaged that such detection performance should improve. Furthermore, labeling data is time-consuming; thus, utilizing data features to generate data reduces the intensity of data labeling while conserving the manually obtained image features. To initiate, we propose a fake dataset generation algorithm based on affine image features such as pupil and eyelid occlusion. Second, ViT and DETR models are utilized for training fake and real pupil datasets, respectively, and their recognition rates are analyzed. Finally, the FNet and DETR conclusions design the fDETR, train the fake and real pupil datasets, and analyze their recognition rate. The transformer was used for the pupil center's localization and performed effectively (65% on average). There was the little discrepancy in accuracy between the fake dataset and the true pupil dataset (about 3%). The final findings demonstrate that this approach of recognizing pupils using a fake pupil dataset is successful. The model can still produce decent results even if the pupil is occluded.
C1 [Xue, Pengxiang; Wang, Changyuan; Huang, Wenbo] Xian Technol Univ, Sch Optoelectron Engn, Xian 710000, Shaanxi, Peoples R China.
   [Wang, Changyuan; Zhou, Guanghao; Raza, Muhammad] Xian Technol Univ, Sch Comp Sci, Xian 710000, Shaanxi, Peoples R China.
   [Jiang, Guangyi] Xian Technol Univ, Sch Mech Engn, Xian 710000, Shaanxi, Peoples R China.
C3 Xi'an Technological University; Xi'an Technological University; Xi'an
   Technological University
RP Wang, C (corresponding author), Xian Technol Univ, Sch Optoelectron Engn, Xian 710000, Shaanxi, Peoples R China.; Wang, C (corresponding author), Xian Technol Univ, Sch Comp Sci, Xian 710000, Shaanxi, Peoples R China.
EM xuepx@xatu.edu.cn; cyw901@163.com; hwb0722@outlook.com;
   jsyworkbench@126.com; 1906210492@st.xatu.edu.cn; mrghunio@gmail.com
RI XUE, Pengxiang/ACG-8435-2022
FU National Natural Science Foundation of China [52072293]; Basic
   Strengthening Plan Technology Foundation [2020-JCJQJJ-430]; Key research
   and development program of Shaanxi [2023-ZDLGY-02]
FX We are grateful for support from the National Natural Science Foundation
   of China Research on Pilot training fatigue assessment based on
   multi-dimensional datamonitoring and fusion (#52072293) and the Basic
   Strengthening Plan Technology Foundation(#2020-JCJQJJ-430) and the key
   research and development program of Shaanxi (No.2023-ZDLGY-02).
CR [Anonymous], 2005, CVPR WORKSH IEEE COM, P79
   Carion Nicolas, 2020, EUR C COMP VIS ECCV, DOI DOI 10.1007/978-3-030-58452-8_13
   Chaudhary AK, 2019, IEEE INT CONF COMP V, P3698, DOI 10.1109/ICCVW.2019.00568
   Child Rewon, 2019, Generating long sequences with sparse transformers
   Dosovitskiy A, 2011, ARXIV
   Frecker RC, 1984, ADV PSYCHOL, V22, P13
   Fuhl W, 2019, IEEE INT CONF COMP V, P4406, DOI 10.1109/ICCVW.2019.00541
   Fuhl W, 2016, MACH VISION APPL, V27, P1275, DOI 10.1007/s00138-016-0776-4
   Fuhl W, 2015, LECT NOTES COMPUT SC, V9256, P39, DOI 10.1007/978-3-319-23192-1_4
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Huang G, 2022, IEEE T PATTERN ANAL, V44, P8704, DOI 10.1109/TPAMI.2019.2918284
   Javadi Amir-Homayoun, 2015, Front Neuroeng, V8, P4, DOI 10.3389/fneng.2015.00004
   Katsini C, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376840
   Krafka K, 2016, PROC CVPR IEEE, P2176, DOI 10.1109/CVPR.2016.239
   Lee-Thorp J, 2021, ARXIV
   Li D, 2005, COMPUTER VISION PATT
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Loukas A., 2020, IBER CONF INF SYST, DOI DOI 10.23919/cisti49556.2020.9141108
   Muhammad W, 2017, J INTELL ROBOT SYST, V85, P107, DOI 10.1007/s10846-016-0410-8
   Park S, 2018, LECT NOTES COMPUT SC, V11217, P741, DOI 10.1007/978-3-030-01261-8_44
   Parmar N, 2018, PR MACH LEARN RES, V80
   Rakshit K, 2021, IEEE T VIS COMPUT GR, V03, P1
   Richmond S, 2014, SUPERINTELLIGENCE PA, P328, DOI [10.1017/S0031819115000340, DOI 10.1017/S0031819115000340]
   Santini T, 2018, COMPUT VIS IMAGE UND, V170, P40, DOI 10.1016/j.cviu.2018.02.002
   Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2
   Shi L, 2021, SOFT COMPUT, V25, P10117, DOI 10.1007/s00500-021-05984-y
   Shi L, 2021, INT J PATTERN RECOGN, V35, DOI 10.1142/S0218001421560024
   Sutskever I, 2014, ADV NEUR IN, V27
   Swirski L., 2012, P S EYE TRACK RES AP, P173
   Tao JP, 2021, AM J OPHTHALMOL, V228, P35, DOI 10.1016/j.ajo.2021.03.025
   Tonsen M, 2016, 2016 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2016), P139, DOI 10.1145/2857491.2857520
   Valenti R, 2012, IEEE T PATTERN ANAL, V34, P1785, DOI 10.1109/TPAMI.2011.251
   Vaswani A, 2017, ADV NEUR IN, V30
   Vera-Olmos FJ, 2019, INTEGR COMPUT-AID E, V26, P85, DOI 10.3233/ICA-180584
   Wang L, 2022, APPL INTELL, V52, P1145, DOI 10.1007/s10489-021-02458-4
   Yiu YH, 2019, J NEUROSCI METH, V324, DOI 10.1016/j.jneumeth.2019.05.016
   Zheng ZH, 2022, IEEE T CYBERNETICS, V52, P8574, DOI 10.1109/TCYB.2021.3095305
NR 37
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 25467
EP 25484
DI 10.1007/s11042-023-14403-3
EA FEB 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000939608000001
DA 2024-07-18
ER

PT J
AU Madani, Y
   Erritali, M
   Bouikhalene, B
AF Madani, Youness
   Erritali, Mohammed
   Bouikhalene, Belaid
TI A new sentiment analysis method to detect and Analyse sentiments of
   Covid-19 moroccan tweets using a recommender approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sentiment analysis; Covid-19; Recommendation system; Collaborative
   filtering; Classification
AB Since the beginning of the covid-19 crisis, people from all over the world have used social media platforms to publish their opinions, sentiments, and ideas about the coronavirus epidemic and their news. Due to the nature of social networks, users share an immense amount of data every day in a freeway, which gives them the possibility to express opinions and sentiments about the coronavirus pandemic regardless of the time and the place. Moreover, The rapid number of exponential cases globally has become the apprehension of panic, fear, and anxiety among people. In this paper, we propose a new sentiment analysis approach to detect sentiments in Moroccan tweets related to covid-19 from March to October 2020. The proposed model is a recommender approach using the advantages of recommendation systems for classifying each tweet into three classes: positive, negative, or neutral. Experimental results show that our method gives good accuracy(86%) and outperforms the well-known machine learning algorithms. We find also that the sentiments of users changed from period to period, and that the evolution of the epidemiological situation in morocco affects the sentiments of users.
C1 [Madani, Youness; Erritali, Mohammed; Bouikhalene, Belaid] Sultan Moulay Slimane Univ, Beni Mellal, Morocco.
C3 Sultan Moulay Slimane University of Beni Mellal
RP Madani, Y (corresponding author), Sultan Moulay Slimane Univ, Beni Mellal, Morocco.
EM younesmadani9@gmail.com; m.erritali@usms.ma; B.BOUIKHALENE@usms.ma
RI MADANI, Youness/L-4698-2018
OI MADANI, Youness/0000-0001-9363-7147
CR Aslam F, 2020, HUM SOC SCI COMMUN, V7, DOI 10.1057/s41599-020-0523-3
   Chakraborty K, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106754
   Das S, 2021, J HUM BEHAV SOC ENVI, V31, P154, DOI 10.1080/10911359.2020.1781015
   de las Heras-Pedrosa C, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17155542
   Hung M, 2020, J MED INTERNET RES, V22, DOI 10.2196/22590
   Imran AS, 2020, IEEE ACCESS, V8, P181074, DOI 10.1109/ACCESS.2020.3027350
   Jelodar H, 2020, IEEE J BIOMED HEALTH, V24, P2733, DOI 10.1109/JBHI.2020.3001216
   Kaur S, 2018, 2018 1 INT C SECURE, P4, DOI [10.1109/ICSCCC.2018.8703350, DOI 10.1109/ICSCCC.2018.8703350]
   Kruspe A, 2020, ARXIV
   Kumar S, 2018, 2018 C INFORM COMMUN, P1, DOI [10.1109/INFOCOMTECH.2018.8722387, DOI 10.1109/INFOCOMTECH.2018.8722387]
   Madani Y, 2020, NEURAL COMPUT APPL, V32, P8655, DOI 10.1007/s00521-019-04357-9
   Madani Y, 2020, J AMB INTEL HUM COMP, V11, P3921, DOI 10.1007/s12652-019-01627-1
   Manguri K. H., 2020, Kurdistan Journal of Applied Research, P54, DOI [DOI 10.24017/COVID.8, 10.24017/covid.8]
   Mostafa Lamiaa, 2021, Proceedings of the International Conference on Advanced Intelligent Systems and Informatics 2020. Advances in Intelligent Systems and Computing (AISC 1261), P195, DOI 10.1007/978-3-030-58669-0_18
   Nemes L, 2021, J INFORM TELECOMMUN, V5, P1, DOI 10.1080/24751839.2020.1790793
   Pokharel BP, 2020, TWITTER SENTIMENT AN, DOI [10.2139/ssrn.3624719, DOI 10.2139/SSRN.3624719]
   Ra M., 2020, GEDRAG ORGAN, V33, P534, DOI [10.37896/gor33.02/062, DOI 10.37896/GOR33.02/062]
   Samuel J, 2020, INFORMATION, V11, DOI 10.3390/info11060314
   Sharma S, 2017, LECT NOTES COMPUT SC, V10597
   Wang TY, 2020, IEEE ACCESS, V8, P138162, DOI 10.1109/ACCESS.2020.3012595
   Xiaoting Lyu, 2020, Natural Language Processing and Chinese Computing. 9th CCF International Conference, NLPCC 2020. Proceedings. Lecture Notes in Artificial Intelligence Subseries of Lecture Notes in Computer Science (LNAI 12430), P710, DOI 10.1007/978-3-030-60450-9_56
   Youness M, 2018, INT J GRID DISTRIB, V11, P63, DOI 10.14257/ijgdc.2018.11.7.07
NR 22
TC 2
Z9 2
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27819
EP 27838
DI 10.1007/s11042-023-14514-x
EA FEB 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000936302600008
PM 36846530
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Kumari, MRR
   Kumar, VV
   Naidu, KR
AF Kumari, Ms R. Radha
   Kumar, V. Vijaya
   Naidu, K. Rama
TI Digital image watermarking using DWT-SVD with enhanced tunicate swarm
   optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image security; Image watermarking; Enhanced tunicate swarm algorithm;
   Block variance and Arnold scrambling
ID HARMONIC FOURIER MOMENTS; COPYRIGHT PROTECTION; CHAOTIC SYSTEM; SCHEME;
   BLIND
AB Image watermarking is the vital process in leveraging digital rights management for valuable intellectual properties. Recently, large number of works was found out to build the image watermarking efficiency in order to cater to the security demands of content protection. However, it is essential to take into account the robustness of watermarking methods. Therefore, robust image watermarking techniques are introduced to show robustness against various attacks and other issues in watermarking. In this paper, a digital image watermarking technique based on Discrete Wavelet Transform (DWT) and Singular Value Decomposition (SVD) is proposed. The DWT and SVD methods are hybridized to enhance the embedding capacity. Based on the low variance calculation, optimal image blocks are selected by the Enhanced Tunicate Swarm Algorithm. TSA optimization is enhanced by the optimization of Sine Cosine Algorithm which is used to update the optimal solution of low variance value. Before embedding, the watermark is scrambled by Arnold scrambling and Tent Map chaotic encryption for double layer security to the watermark image. After embedding, the extraction process is carried out. The experiments are conducted on Pepper, Barbara, Lena, Baboon and Airplane image sets. The results are compared with different watermarking approaches and optimization approaches in terms of Peak Signal to Noise ratio (PSNR), Normalization Correlation (NC), and Structural Similarity Index Measure (SSIM). To show the robustness, the proposed method is evaluated under various geometric attacks and found to achieve better accuracy and robustness compared to existing methods.
C1 [Kumari, Ms R. Radha; Naidu, K. Rama] Jawaharlal Nehru Technol Univ Ananthpuramu, Dept Elect & Commun Engn, Ananthpuramu 515002, Andhra Pradesh, India.
   [Kumar, V. Vijaya] Anurag Univ, Dept CSE & Dean Res & Dev, Hyderabad 500088, Telangana, India.
RP Kumari, MRR (corresponding author), Jawaharlal Nehru Technol Univ Ananthpuramu, Dept Elect & Commun Engn, Ananthpuramu 515002, Andhra Pradesh, India.
EM radharavada999@gmail.com
OI Kumari, R Radha/0000-0002-7834-6939
CR Ahvanooey MT, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/5325040
   Alshoura WH, 2021, IEEE ACCESS, V9, P32931, DOI 10.1109/ACCESS.2021.3060861
   Alzahrani A, 2022, APPL BIONICS BIOMECH, VBiomech2018, P1
   Alzahrani A, 2021, IEEE ACCESS, V9, P113714, DOI 10.1109/ACCESS.2021.3104985
   Ambadekar Sarita P., 2019, Recent Trends in Signal and Image Processing. ISSIP 2017. Advances in Intelligent Systems and Computing (AISC 727), P187, DOI 10.1007/978-981-10-8863-6_19
   Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Cheema AM, 2020, IEEE ACCESS, V8, P169525, DOI 10.1109/ACCESS.2020.3024181
   Durafe A, 2020, J KING SAUD U COMPUT
   Garg P, 2020, J DISCRET MATH SCI C, V23, P73, DOI 10.1080/09720529.2020.1721875
   Hai T, 2014, J APPL RES TECHNOL, V12, P122, DOI 10.1016/S1665-6423(14)71612-8
   Kaur S, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103541
   Kumar C, 2020, MULTIMED TOOLS APPL, V79, P11069, DOI 10.1007/s11042-018-6177-0
   Lalitha RVSS, 2017, LECT NOTE NETW SYST, V5, P261, DOI 10.1007/978-981-10-3226-4_26
   Liu XL, 2018, IEEE T CIRC SYST VID, V28, P1047, DOI 10.1109/TCSVT.2016.2633878
   Loan NA, 2018, IEEE ACCESS, V6, P19876, DOI 10.1109/ACCESS.2018.2808172
   Maloo S, 2020, SENS IMAGING, V21, DOI 10.1007/s11220-020-00291-6
   Mehta R, 2018, INT J MACH LEARN CYB, V9, P145, DOI 10.1007/s13042-015-0329-6
   Moeinaddini E, 2019, SOFT COMPUT, V23, P9685, DOI 10.1007/s00500-018-3535-9
   Ray A, 2020, INT J MULTIMED INF R, V9, P249, DOI 10.1007/s13735-020-00197-9
   Sattarpoor S, 2021, ARXIV
   Singh A, 2017, MIS Q EXEC, V16, P1
   Singh R, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2020.102734
   Sisaudia V, 2021, MULTIMED TOOLS APPL, V80, P8667, DOI 10.1007/s11042-020-10028-y
   Srinivasu PN, GAZI U J SCI
   Srinivasu PN, 2015, INT J COMPUT APPL, V120
   Teng L, 2013, AEU-INT J ELECTRON C, V67, P540, DOI 10.1016/j.aeue.2012.12.001
   Veni M, 2019, MULTIMED TOOLS APPL, V78, P27491, DOI 10.1007/s11042-019-7650-0
   Wang CP, 2016, SIGNAL PROCESS-IMAGE, V45, P10, DOI 10.1016/j.image.2016.03.007
   Wang CP, 2020, IEEE T CIRC SYST VID, V30, P4440, DOI 10.1109/TCSVT.2019.2960507
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang CP, 2018, INFORM SCIENCES, V450, P141, DOI 10.1016/j.ins.2018.03.040
   Wang CP, 2017, SIGNAL PROCESS, V134, P197, DOI 10.1016/j.sigpro.2016.12.010
   Wang M, 2021, IEEE ACCESS, V9, P27434, DOI 10.1109/ACCESS.2021.3058128
   Xia ZQ, 2021, DIGIT SIGNAL PROCESS, V116, DOI 10.1016/j.dsp.2021.103130
   Xia ZQ, 2021, SIGNAL PROCESS, V180, DOI 10.1016/j.sigpro.2020.107864
   Xia ZQ, 2019, SIGNAL PROCESS, V164, P368, DOI 10.1016/j.sigpro.2019.06.025
   Xia ZQ, 2019, SIGNAL PROCESS, V157, P108, DOI 10.1016/j.sigpro.2018.11.011
NR 37
TC 0
Z9 0
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 28259
EP 28279
DI 10.1007/s11042-023-14618-4
EA FEB 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000936195100004
DA 2024-07-18
ER

PT J
AU Thirunavukkarasu, V
   Kumar, AS
   Prakasam, P
   Suresh, G
AF Thirunavukkarasu, V.
   Kumar, A. Senthil
   Prakasam, P.
   Suresh, G.
TI Elliptic curve cryptography based key management and flexible
   authentication scheme for 5G wireless networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Elliptic curve cryptography; Internet of things; 5G wireless networks;
   Cloud computing; Mapping function
ID INTERNET; DESIGN; IOT
AB Due to the technology development and need, the integration of WSN and 5G will be a key driver for successful IoT deployment. The Security issues are the major threat and challenge while integrating the WSN and 5G. Therefore here Elliptic Curve Cryptography (ECC) based flexible authentication and key management (EKAFAS) scheme is proposed in this paper to overcome the security vulnerabilities and to improve the system robustness of WSN in 5G integrated IoT. In order to provide the system with more secured, the ECC is employed for user's authentication and authorization. For the secured end to end communication user authentication and key agreement are essential. The sensors collect and process a large amount of personal information and it should be prevented from the adversaries that are able to access the private data. The secured system architecture for the integration of WSN and 5G for Internet of things is described by using the cryptanalysis algorithm. The system efficiency is determined for ECC based key agreement and flexible authentication scheme on basis of data transmission cost, computation cost, false positive rate and trust node rate. The proposed method is compared with the existing methods to measure the effectiveness.
C1 [Thirunavukkarasu, V.] Govt Coll Engn, Dept Elect & Commun Engn, Bodinayakanur, India.
   [Kumar, A. Senthil] Kings Engn Coll, Dept Elect & Commun Engn, Chennai, India.
   [Prakasam, P.] Vellore Inst Technol, Sch Elect Engn, Vellore, India.
   [Suresh, G.] Kings Engn Coll, Dept Comp Sci & Engn, Chennai, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Kumar, AS (corresponding author), Kings Engn Coll, Dept Elect & Commun Engn, Chennai, India.
EM veetee_ece1@yahoo.in; senthil.vit526@gmail.com; prakasamp@gmail.com;
   drsureshkec@gmail.com
RI Arumugam, Senthil Kumar/AAO-1655-2021; GULIVINDALA,
   SURESH/AAN-5146-2020; PERIASAMY, PRAKASAM/B-3075-2016
OI Arumugam, Senthil Kumar/0000-0003-4752-4592; GULIVINDALA,
   SURESH/0000-0002-8411-8190; PERIASAMY, PRAKASAM/0000-0002-2471-6375
CR Agyapong PK, 2014, IEEE COMMUN MAG, V52, P65, DOI 10.1109/MCOM.2014.6957145
   Ahmed AA, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082810
   Alduais N., 2016, Proceedings of the 7th Annual Information Technology, Electronics and Mobile Communication Conference, P1, DOI [10.1109/IEMCON.2016.7746084, DOI 10.1109/IEMCON.2016.7746084]
   [Anonymous], 2017, 5G PPP ARCHITECTURE
   [Anonymous], 2017, 2017 9 IEEE GCC C EX
   Chang IP, 2015, SENSORS-BASEL, V15, P29841, DOI 10.3390/s151229767
   Das AK, 2015, J KING SAUD UNIV-COM, V27, P193, DOI 10.1016/j.jksuci.2014.03.020
   Devi R, 2017, AEU-INT J ELECTRON C, V74, P94, DOI 10.1016/j.aeue.2017.01.025
   Gai KK, 2016, SECUR COMMUN NETW, V9, P3049, DOI 10.1002/sec.1224
   Gope P, 2016, IEEE T IND ELECTRON, V63, P7124, DOI 10.1109/TIE.2016.2585081
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Gulen U, 2016, SECUR COMMUN NETW, V9, P4992, DOI 10.1002/sec.1670
   Jiang Q, 2017, IEEE ACCESS, V5, P3376, DOI 10.1109/ACCESS.2017.2673239
   Jiang Q, 2015, PEER PEER NETW APPL, V8, P1070, DOI 10.1007/s12083-014-0285-z
   Lazarescu MT, 2013, IEEE J EM SEL TOP C, V3, P45, DOI 10.1109/JETCAS.2013.2243032
   Li J., 2017, ARXIV
   Liu Z, 2014, LECT NOTES COMPUT SC, V8479, P361, DOI 10.1007/978-3-319-07536-5_22
   Maurya AK, 2017, INFORMATION, V8, DOI 10.3390/info8040136
   Meshram C, 2021, IEEE ACCESS, V9, P131336, DOI 10.1109/ACCESS.2021.3114287
   김유진, 2016, [The journal of Convergence on Culture Technology, 문화기술의 융합], V2, P77, DOI 10.17703/JCCT.2016.2.4.77
   Moon J, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17050940
   Park Y, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16122123
   Priya TS, 2021, WIRELESS PERS COMMUN, V120, P2061, DOI 10.1007/s11277-021-08455-7
   Shin S, 2020, IEEE ACCESS, V8, P67555, DOI 10.1109/ACCESS.2020.2985719
   Shin S, 2018, IEEE ACCESS, V6, P11229, DOI 10.1109/ACCESS.2018.2796539
   Sicari S, 2020, COMPUT NETW, V179, DOI 10.1016/j.comnet.2020.107345
   Sumathi D, 2022, WIRELESS PERS COMMUN, V125, P2253, DOI 10.1007/s11277-022-09655-5
   Sundmaeker H., 2010, CLUSTER EUROPEAN RES, V3, P34, DOI DOI 10.2759/26127
   Vijayakumar P, 2020, IEEE T IND INFORM, V16, P2603, DOI 10.1109/TII.2019.2925071
   Vijayakumar P, 2016, IEEE T INTELL TRANSP, V17, P1015, DOI 10.1109/TITS.2015.2492981
   Windha V., 2018, P 2018 4 INT C WIR T, P1
   Yang L., 2021, WIREL COMMUN MOB COM, V2021, P1
NR 32
TC 1
Z9 1
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21131
EP 21145
DI 10.1007/s11042-023-14539-2
EA FEB 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000936501100003
DA 2024-07-18
ER

PT J
AU Erdas, CB
   Sümer, E
   Kibaroglu, S
AF Erdas, Cagatay Berke
   Sumer, Emre
   Kibaroglu, Seda
TI Neurodegenerative diseases detection and grading using gait dynamics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neurodegenerative diseases; Gait; Detection of diseases; Diseases
   severity grading; Artificial intelligence
ID PARKINSONS-DISEASE; CLASSIFICATION; DISORDERS; DIAGNOSIS; PATTERNS;
   RHYTHM
AB Detection of neurodegenerative diseases such as Parkinson's disease, Huntington's disease, Amyotrophic Lateral Sclerosis, and grading of these diseases' severity have high clinical significance. These tasks based on walking analysis stand out compared to other methods due to their simplicity and non-invasiveness. This study has emerged to realize an artificial intelligence-based disease detection and severity prediction system for neurodegenerative diseases using gait features obtained from gait signals. For the detection of the disease, the problem is divided into parts which are subgroups of 4 classes consisting of Parkinson's, Huntington's, Amyotrophic Lateral Sclerosis diseases, and the control group. In addition, the disease vs. control subgroup where all diseases are collected under a single label, the subgroups where each disease is separately against the control group. For disease severity grading, each disease was divided into subgroups and a solution was sought for the prediction problem mentioned by various machine and deep learning methods separately for each group. In this context, the resulting detection performance was measured by the metrics of Accuracy, F-1 Score, Precision, and Recall while the resulting prediction performance was measured by the metrics such as R, R-2, MAE, MedAE, MSE, and RMSE.
C1 [Erdas, Cagatay Berke; Sumer, Emre] Baskent Univ, Fac Engn, Dept Comp Engn, Ankara, Turkiye.
   [Kibaroglu, Seda] Baskent Univ, Fac Med, Dept Neurol, Ankara, Turkiye.
C3 Baskent University; Baskent University
RP Erdas, CB (corresponding author), Baskent Univ, Fac Engn, Dept Comp Engn, Ankara, Turkiye.
EM berdas@baskent.edu.tr; esumer@baskent.edu.tr; skibaroglu@baskent.edu.tr
RI Sümer, Emre/AGA-5711-2022; Erdaş, Çağatay Berke/IYJ-1639-2023;
   Kibaroglu, Seda/AAJ-2956-2021
OI Erdaş, Çağatay Berke/0000-0003-3467-9923; Kibaroglu,
   Seda/0000-0002-3964-268X
CR Açici K, 2021, HEALTH TECHNOL-GER, V11, P643, DOI 10.1007/s12553-021-00543-9
   Alaskar H, 2018, LECT NOTES ARTIF INT, V10956, P760, DOI 10.1007/978-3-319-95957-3_80
   Ameer S, 2008, INT CONF SIGN PROCES, P728, DOI 10.1109/ICOSP.2008.4697233
   Asraf Amanullah, 2020, SN Comput Sci, V1, P363, DOI 10.1007/s42979-020-00383-w
   Asuroglu T, 2018, BIOCYBERN BIOMED ENG, V38, P760, DOI 10.1016/j.bbe.2018.06.002
   Ayon SI, 2022, IETE J RES, V68, P2488, DOI 10.1080/03772063.2020.1713916
   Baratin E, 2015, GAIT POSTURE, V41, P634, DOI 10.1016/j.gaitpost.2015.01.012
   Barker S, 2006, MED ENG PHYS, V28, P460, DOI 10.1016/j.medengphy.2005.07.017
   Bennasar M, 2016, PROCEDIA COMPUT SCI, V96, P1193, DOI 10.1016/j.procs.2016.08.163
   Bilgin S, 2018, TURK J ELECTR ENG CO, V26, P1367, DOI 10.3906/elk-1708-221
   Brodovitch A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-80370-6
   Chen M, 2006, IEEE T BIO-MED ENG, V53, P959, DOI 10.1109/TBME.2006.872822
   Chung NJ, 2008, J BIOMOL SCREEN, V13, P149, DOI 10.1177/1087057107312035
   Daliri MR, 2013, BIOMED SIGNAL PROCES, V8, P66, DOI 10.1016/j.bspc.2012.04.007
   Daliri MR, 2012, MEASUREMENT, V45, P1729, DOI 10.1016/j.measurement.2012.04.013
   Dandu JR, 2020, HEALTH TECHNOL-GER, V10, P187, DOI 10.1007/s12553-018-00284-2
   Erdas CB., 2020, INT J INTERACT MULTI, V8, P97
   Erdas CB, 2020, 2020 MEDICAL TECHNOL, P1
   Ertugrul ÖF, 2016, EXPERT SYST APPL, V56, P156, DOI 10.1016/j.eswa.2016.03.018
   Fatmawati, 2018, 2018 3RD INTERNATIONAL SEMINAR ON SENSORS, INSTRUMENTATION, MEASUREMENT AND METROLOGY (ISSIMM), P34, DOI 10.1109/ISSIMM.2018.8727734
   Gupta K, 2019, HEALTH TECHNOL-GER, V9, P547, DOI 10.1007/s12553-018-0274-y
   Haque M E., 2018, Proceedings of 2018 21st International Conference of Computer and Information Technology (ICCIT'18), P21, DOI [DOI 10.1109/ICCITECHN.2018.8631957, 10.1109/IC4ME2.2018.8465658, DOI 10.1109/IC4ME2.2018.8465658]
   Hasan MK, 2016, 2016 5TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS AND VISION (ICIEV), P574, DOI 10.1109/ICIEV.2016.7760068
   HAUSDORFF JM, 1995, J BIOMECH, V28, P347, DOI 10.1016/0021-9290(94)00074-E
   Hausdorff JM, 1997, J APPL PHYSIOL, V82, P262
   Hausdorff JM, 2000, J APPL PHYSIOL, V88, P2045, DOI 10.1152/jappl.2000.88.6.2045
   Hausdorff JM, 1998, MOVEMENT DISORD, V13, P428, DOI 10.1002/mds.870130310
   Iadanza E, 2020, HEALTH TECHNOL-GER, V10, P1343, DOI 10.1007/s12553-020-00486-7
   Islam Ayon S., 2019, Int J Inf Eng Electronic Business, V11, P21, DOI DOI 10.5815/IJIEEB.2019.02.03
   Islam MM, 2021, IEEE ACCESS, V9, P30551, DOI 10.1109/ACCESS.2021.3058537
   Islam Md Milon, 2020, SN Comput Sci, V1, P274, DOI 10.1007/s42979-020-00300-1
   Islam MM, 2017, IEEE REG 10 HUMANIT, P226, DOI 10.1109/R10-HTC.2017.8288944
   Islam Md Zabirul, 2020, Inform Med Unlocked, V20, P100412, DOI 10.1016/j.imu.2020.100412
   John V, 2018, INT C PATT RECOG, P189, DOI 10.1109/ICPR.2018.8546108
   Lee SH, 2012, EXPERT SYST APPL, V39, P7338, DOI 10.1016/j.eswa.2012.01.084
   Mannini A, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010134
   Muhammad L J, 2020, SN Comput Sci, V1, P206, DOI 10.1007/s42979-020-00216-w
   Nukala BT, 2016, BIOSENSORS-BASEL, V6, DOI 10.3390/bios6040058
   Price DL, 1999, NATURE, V399, pA3, DOI 10.1038/399a003
   Rahman Mohammad Marufur, 2021, SN Comput Sci, V2, P384, DOI 10.1007/s42979-021-00774-7
   Ren P, 2017, IEEE T BIO-MED ENG, V64, P52, DOI 10.1109/TBME.2016.2536438
   Reyes C, 2010, INT ITG WORKS SMART, P156, DOI 10.1109/WSA.2010.5456452
   Saha Prottoy, 2021, Inform Med Unlocked, V22, P100505, DOI 10.1016/j.imu.2020.100505
   Shi Y, 2021, APPL ENERG, V282, DOI 10.1016/j.apenergy.2020.116046
   Tjärnberg A, 2021, PLOS COMPUT BIOL, V17, DOI 10.1371/journal.pcbi.1008569
   Tougui I, 2020, HEALTH TECHNOL-GER, V10, P1137, DOI 10.1007/s12553-020-00438-1
   Vila MH, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18020720
   Wang S, 2020, 2020 12TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P408, DOI [10.1109/icaci49185.2020.9177709, 10.1109/ICACI49185.2020.9177709]
   Wu YF, 2010, IEEE ENG MED BIO, P1304, DOI 10.1109/IEMBS.2010.5626398
   Wu YF, 2009, MED BIOL ENG COMPUT, V47, P1165, DOI 10.1007/s11517-009-0527-z
   Zeng W, 2015, INFORM SCIENCES, V317, P246, DOI 10.1016/j.ins.2015.04.047
   Zhang KB, 2021, SIGNAL PROCESS, V178, DOI 10.1016/j.sigpro.2020.107771
   2021, ARCH CLIN NEUROPSYCH, V36, P74
NR 53
TC 3
Z9 3
U1 4
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22925
EP 22942
DI 10.1007/s11042-023-14461-7
EA FEB 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000934850300003
PM 36846529
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Xu, K
AF Xu, Ke
TI Artificial intelligence unlocks ecological environment governance -smart
   statistical monitoring based on meteorology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ecological environment; PM2; 5; Picture data; Deep learning; Smart
   monitoring
ID INTERNET; THINGS
AB In recent years, the issue of governance of the ecological environment has been a subject of high of social concern, and the challenges in the governance of smog is even more remarkable. China has accumulated a vast real-time monitoring system, which mainly obtains pollution data through national monitoring stations, providing a strong foundation for atmospheric governance. However, there are still several challenges in obtaining data from national monitoring stations, such as high cost and difficulty in comprehensive coverage. In the internet world, big data, cloud computing and other technologies are rapidly developing. It is imperative that new countermeasures counterfeit, falsify, and establish a sound long-term supervision mechanism. It is a popular research issue in academia and a policy difficulty faced by government departments. In terms of statistical models, various deep learning methods that have made major breakthroughs in the field of computer vision are used to try to obtain standardized estimates of concentration based on picture data. In general, based on the collection and arrangement of a large amount of image data over the past three years, 7 types of deep learning models have been constructed, which can achieve fast reading and accurate estimation of PM2.5 concentrations. Based on this model, we have put forward practical policy recommendations with a view to helping the early realization of smart monitoring to reduce concentration. For the standardized PM2.5 data, the minimum estimate error can reach 0.42. On this basis, we also put forward policy recommendations with practical value, with a view to helping the early realization of smart monitoring of pollutant concentrations.
C1 [Xu, Ke] Univ Int Business & Econ, Sch Stat, Beijing 100029, Peoples R China.
C3 University of International Business & Economics
RP Xu, K (corresponding author), Univ Int Business & Econ, Sch Stat, Beijing 100029, Peoples R China.
EM xk@uibe.edu.cn
FU National Natural Science Foundation of China [12001102]; Fundamental
   Research Funds for the Central Universities" in University of
   International Business and Economics [19QD22, CXTD13-04]
FX This research is supported by National Natural Science Foundation of
   China (Grant No. 12001102), and "the Fundamental Research Funds for the
   Central Universities" in University of International Business and
   Economics (No. 19QD22, and No. CXTD13-04).
CR AlZu'bi S, 2019, MULTIMED TOOLS APPL, V78, P29581, DOI 10.1007/s11042-019-7367-0
   Beloconi A, 2016, REMOTE SENS ENVIRON, V172, P148, DOI 10.1016/j.rse.2015.10.017
   Brevini B, 2020, BIG DATA SOC, V7, DOI 10.1177/2053951720935141
   Chen YY, 2013, P NATL ACAD SCI USA, V110, P12936, DOI 10.1073/pnas.1300018110
   Chow JC, 1986, J IND POLLUT CONTROL, V4, P18
   Chow JC., 1986, J IND POLLUT CONTROL, V4, P30
   Dauvergne P, 2022, REV INT POLIT ECON, V29, P696, DOI 10.1080/09692290.2020.1814381
   Dey N, 2020, COGN COMPUT, V12, P1011, DOI 10.1007/s12559-020-09751-3
   DOCKERY DW, 1993, NEW ENGL J MED, V329, P1753, DOI 10.1056/NEJM199312093292401
   Tran DT, 2022, J SUPERCOMPUT, V78, P11051, DOI 10.1007/s11227-021-04275-5
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huh JH, 2019, IEEE ACCESS, V7, P164229, DOI 10.1109/ACCESS.2019.2945338
   Huh JH, 2017, HUM-CENTRIC COMPUT I, V7, DOI 10.1186/s13673-017-0101-x
   Kaur P, 2019, MULTIMED TOOLS APPL, V78, P19905, DOI 10.1007/s11042-019-7327-8
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liang X, 2016, J GEOPHYS RES-ATMOS, V121, P10220, DOI 10.1002/2016JD024877
   Lin CQ, 2015, REMOTE SENS ENVIRON, V156, P117, DOI 10.1016/j.rse.2014.09.015
   Mao J., 2014, J COMPUT SCI SYST BI, V7, P1, DOI DOI 10.4172/JCSB.1000161
   Peters A., 2005, Toxicol Appl Pharmacol, V207, P477, DOI [DOI 10.1016/j.taap.2005.04.030, DOI 10.1016/J.TAAP.2005.04.030]
   Ross MaryA., 2009, Integrated science assessment for particulate matter, P61
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh AV, 2020, ADV HEALTHC MATER, V9, DOI 10.1002/adhm.201901862
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Wang HQ, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P326, DOI 10.1109/VCIP.2014.7051572
   Xu K, 2019, STAT INTERFACE, V12, P387, DOI 10.4310/SII.2019.v12.n3.a4
   Zheng Zhang, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015. Proceedings: LNCS 8936, P13, DOI 10.1007/978-3-319-14442-9_2
   Zigiene G, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11164501
NR 30
TC 1
Z9 1
U1 6
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21613
EP 21625
DI 10.1007/s11042-023-14685-7
EA FEB 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000934216300003
DA 2024-07-18
ER

PT J
AU Kumbhakar, D
   Sanyal, K
   Karforma, S
AF Kumbhakar, Dulal
   Sanyal, Kanchan
   Karforma, Sunil
TI An optimal and efficient data security technique through crypto-stegano
   for E-commerce
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE E-commerce; Elgamal cryptosystem; LSB steganography; DCT with
   autoencoder; Performance metrics
ID IMAGE
AB E-Commerce or Electronic commerce is the buying and selling of goods and services in which any commercial transactions through wireless electronic devices such as hand-held computers (tablets), mobile phones or laptops is conducted anytime & anywhere via Internet technology. But, E-Commerce transactions or services are suffered by many attacks such as Man in the Middle attack, eavesdropping attacks, and etc. due to the lack of secured security infrastructure. Here, data security is one of the ways to keep the confidential information secure through E-Commerce transactions. In this connection, we have proposed an optimal and efficient data security with the combination of Elgamal cryptosystem and LSB image steganography technique for E-Commerce. In our proposed work, at the merchant side, Elgamal encryption technique is used to protect sensitive information during E-Commerce transactions from intruders and LSB image steganography process is also applied to hide generated Elgamal encrypted data and produce a stego-image (steganography image). Then, DCT (Discrete Cosine Transform) technique through autoencoder is imposed on stego-image to make an optimal image to increase the throughput of the work. After that, the produced optimal image with cipher text is sent to the customer end. At the customer end, first, stego-image is extracted from the optimal image using LSB retrieval process. Then, Elgamal decryption process is used to retrieve the original data and secure the E-Commerce transactions in efficiently. Based on the experiment, we have plotted the performance metrics such as MSE, PSNR and SSIM on the work and entropy of the optimal image is also calculated with respect to the sample image. Thereby, a high level performance metrics is obtained in our proposed work.
C1 [Kumbhakar, Dulal] Vivekananda Mahavidyalaya, Dept BCA, Hooghly, West Bengal, India.
   [Sanyal, Kanchan] Bhadrapur MNK High Sch, Dept Comp Applicat, Birbhum, West Bengal, India.
   [Karforma, Sunil] Univ Burdwan, Dept Comp Sci, Bardhaman, West Bengal, India.
C3 University of Burdwan
RP Kumbhakar, D (corresponding author), Vivekananda Mahavidyalaya, Dept BCA, Hooghly, West Bengal, India.
EM dulalkumbhakar69@gmail.com
RI Karforma, Sunil/AAQ-7556-2021
OI Karforma, Sunil/0000-0003-4968-4055
CR Bin Hureib ES, 2020, INT J COMPUT SCI NET, V20, P1
   Deepika A., 2018, SHANLAX INT J COMMER, V6, P285, DOI DOI 10.5281/ZENODO.1419466
   Dumas T, 2018, ARXIV
   El Rahman Sahar A., 2015, International Journal of Image, Graphics and Signal Processing, V7, P10, DOI 10.5815/ijigsp.2015.06.02
   ELGAMAL T, 1985, IEEE T INFORM THEORY, V31, P469, DOI 10.1109/TIT.1985.1057074
   Kefa Rabah, 2005, Information Technology Journal, V4, P299
   Kumar R., 2018, INT J LATEST TECHNOL, VVII, P43
   Kumar V., 2012, 2012 International Conference on Devices, Circuits and Systems (ICDCS 2012), P447, DOI 10.1109/ICDCSyst.2012.6188797
   Kumbhakar D, 2021, BIOSCI BIOTECH RES C, V14, P93, DOI 10.21786/bbrc/14.5/19
   Latha K, 2020, WORLD J PEDIATR, V10
   Mathey R., 2014, IEEE T PATTERN ANAL, V16, P01, DOI [10.9790/0661-16210105, DOI 10.9790/0661-16210105]
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P8597, DOI 10.1007/s11042-016-3383-5
   Preedanan W, 2018, PROC INT WORKSH ADV
   Sabanoglu T., 2021, Global retail e-commerce sales 2014-2024
   Saleh ME, 2016, INT J ADV COMPUT SC, V7, P390
   Sara U., 2019, J COMPUT COMMUN, V7, P8, DOI [10.4236/jcc.2019.73002, DOI 10.4236/JCC.2019.73002]
   Thangadurai K, 2014, INT CONF COMP COMMUN
   THUM C, 1984, OPT ACTA, V31, P203, DOI 10.1080/713821475
   Uky, E COMMERCE SECURITIE
   Wang Z., 2019, J PHYS C SERIES, V1213, DOI [10.1088/1742-6596/1213/4/042083, DOI 10.1088/1742-6596/1213/4/042083]
   Zachariah B., 2016, INT J ENG RES TECHNO, V5, P186
NR 21
TC 1
Z9 1
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21005
EP 21018
DI 10.1007/s11042-023-14526-7
EA FEB 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000929402000001
PM 36778718
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Bania, RK
AF Bania, Rubul Kumar
TI Ensemble of deep transfer learning models for real-time automatic
   detection of face mask
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face mask; Transfer learning; Ensemble; Covid-19
AB The COVID-19 pandemic is causing a global health crisis. Public spaces need to be safeguarded from the adverse effects of this pandemic. Wearing a facemask has become an adequate protection solution many governments adopt. Manual real-time monitoring of face mask wearing for many people is becoming a difficult task. This paper applies three heterogeneous deep transfer learning models, viz., ResNet50, Inception-v3, and VGG-16, to prepare an ensemble classification model for detecting whether a person is wearing a mask. The ensemble classification model is underlined by the concept of the weighted average technique. The proposed framework is based on two phases. An off-line phase that aims to prepare a classification model by following training-testing steps to detect and locate facemasks. Then in the second online phase, it is deployed to detect real-time faces from live videos, which are captured by a web-camera. The prepared model is compared with several state-of-the-art models. The proposed model has achieved the highest classification accuracy of 99.97%, precision of 0.997, recall of 0.997, F1-score of 0.997 and kappa coefficient 0.994. The superiority of the model over state-of-the-art compared methods is well evident from the experimental results.
C1 [Bania, Rubul Kumar] North Eastern Hill Univ, Dept Comp Applicat, Tura Campus, Tura 794002, Meghalaya, India.
C3 North Eastern Hill University
RP Bania, RK (corresponding author), North Eastern Hill Univ, Dept Comp Applicat, Tura Campus, Tura 794002, Meghalaya, India.
EM rubul.bania@gmail.com
RI Bania, Dr. Rubul Kumar/ABL-0336-2022
OI Bania, Dr. Rubul Kumar/0000-0001-6294-0231
CR Alzubaidi L, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00444-8
   [Anonymous], 2022, CORONAVIRUS WORLD HE
   Asghar MZ, 2022, FRONT PUBLIC HEALTH, V10, DOI 10.3389/fpubh.2022.855254
   Bania Rubul Kumar, 2021, INFOCOMP Journal of Computer Science, P1
   Belete Daniel Mesafint, 2022, International Journal of Computers and Applications, P875, DOI 10.1080/1206212X.2021.1974663
   Das A, 2020, 2020 IEEE PUNE SECTION INTERNATIONAL CONFERENCE (PUNECON), P1, DOI 10.1109/PuneCon50868.2020.9362416
   Goyal H, 2022, MULTIMED TOOLS APPL, V81, P14999, DOI 10.1007/s11042-022-12166-x
   Gupta P., 2018, Int. J. Eng. Manuf.), V8, P63
   Hussain D, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/1536318
   Kedia P, 2021, APPL SOFT COMPUT, V104, DOI 10.1016/j.asoc.2021.107184
   Kumar TA, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11060904
   Loey M, 2021, SUSTAIN CITIES SOC, V65, DOI 10.1016/j.scs.2020.102600
   Loey M, 2021, MEASUREMENT, V167, DOI 10.1016/j.measurement.2020.108288
   Militante SV, 2020, 2020 11TH IEEE CONTROL AND SYSTEM GRADUATE RESEARCH COLLOQUIUM (ICSGRC), P106, DOI [10.1109/icsgrc49013.2020.9232610, 10.1109/ICSGRC49013.2020.9232610]
   Sethi S, 2021, J BIOMED INFORM, V120, DOI 10.1016/j.jbi.2021.103848
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Sitaula C, 2021, APPL INTELL, V51, P2850, DOI 10.1007/s10489-020-02055-x
   Suresh K, 2021, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT 2021), P1084, DOI 10.1109/ICICT50816.2021.9358653
   Talahua JS, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13126900
   Taneja S., 2021, LECT NOTES NETWORKS, P39, DOI [10.1007/978-981-16-0733-2_3, DOI 10.1007/978-981-16-0733-2_3]
   Teboulbi S, 2021, SCI PROGRAMMING-NETH, V2021, DOI 10.1155/2021/8340779
   Ullah N, 2022, J KING SAUD UNIV-COM, V34, P9905, DOI 10.1016/j.jksuci.2021.12.017
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Weitz JS, 2020, NAT MED, V26, P849, DOI 10.1038/s41591-020-0895-3
   Yang DD, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-99015-3
   Zhu J, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0236621
NR 26
TC 4
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 25131
EP 25153
DI 10.1007/s11042-023-14408-y
EA FEB 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000924075600004
PM 36743998
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Golnoori, F
   Boroujeni, FZ
   Monadjemi, A
AF Golnoori, Farzad
   Boroujeni, Farsad Zamani
   Monadjemi, Amirhassan
TI Metaheuristic algorithm based hyper-parameters optimization for skin
   lesion classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin lesion classification; Genetic algorithm; PSO; DE; Deep learning;
   CNN; ISIC
ID NEURAL-NETWORKS; DEEP FEATURES; DERMOSCOPY; SEGMENTATION; CANCER
AB The most dangerous type of skin cancer in the world is Melanoma. Early diagnosis of this cancer in primary stages can increase the chance of surviving death. In recent years, automatic skin cancer detection systems have played a significant role in increasing the rate of cancer diagnosis. Although deep convolutional neural networks presented advantages over traditional methods and brought tremendous breakthroughs in many image classification tasks, accurate classification of skin lesions remains challenging due to the complexity of choosing appropriate architecture for deep neural networks and hyper-parameter tuning. The aim of this paper is to increase the performance of skin lesion classification system through optimizing hyper-parameters and architecture of deep neural network using metaheuristic optimization algorithms. For this purpose, three optimization algorithms are employed to find an optimal configuration for the convolutional neural network either in pre-trained models or model that are trained from scratch. Then the deep features extracted from the optimized models were fused together in pairs and used to train a KNN classifier. The effect of applying hyper-parameter optimization is evaluated on ISIC 2017 and ISIC 2018 datasets. The accuracy of the deep neural network produced by our method reaches to 81.6% and F1-score of 80.9% on ISIC 2017 dataset and accuracy of 90.1% and F1-score of 89.8% on ISIC 2018. The results of the present study indicate that the proposed method outperforms similar methods in classifying seven and three classes of images, without requiring heavy preprocessing and segmentation steps.
C1 [Golnoori, Farzad; Boroujeni, Farsad Zamani] Islamic Azad Univ, Dept Comp Engn, Isfahan Khorasgan Branch, Esfahan, Iran.
   [Monadjemi, Amirhassan] Natl Univ Singapore, Sch continuing & lifelong Educ, Singapore, Singapore.
C3 Islamic Azad University; National University of Singapore
RP Boroujeni, FZ (corresponding author), Islamic Azad Univ, Dept Comp Engn, Isfahan Khorasgan Branch, Esfahan, Iran.
EM f.zamani@khuisf.ac.ir
RI Zamani Boroujeni, Farsad/I-5842-2019
OI Zamani Boroujeni, Farsad/0000-0002-2279-488X
CR Al-masni MA, 2020, COMPUT METH PROG BIO, V190, DOI 10.1016/j.cmpb.2020.105351
   Al-Masni MA, 2018, COMPUT METH PROG BIO, V162, P221, DOI 10.1016/j.cmpb.2018.05.027
   Amin J, 2020, PATTERN RECOGN LETT, V131, P63, DOI 10.1016/j.patrec.2019.11.042
   Bisla D, 2019, IEEE COMPUT SOC CONF, P2720, DOI 10.1109/CVPRW.2019.00330
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Chaabouni S, 2016, IEEE IMAGE PROC, P1604, DOI 10.1109/ICIP.2016.7532629
   Chaturvedi S.S., 2020, Advanced machine learning technologies and applications: proceedings of AMLTA 2020, P165, DOI [DOI 10.1007/978-981-15-3383-9_15, 10.1007/978-981-15-3383-9_15, DOI 10.1007/978-981-15-3383-915]
   Chen LC, 2018, ADV NEUR IN, V31
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Christofides E, 2009, CYBERPSYCHOL BEHAV, V12, P341, DOI 10.1089/cpb.2008.0226
   Chuan L, 2007, ICNC 2007: THIRD INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 3, PROCEEDINGS, P823
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, P303, DOI 10.1007/BF02551274
   Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Feurer M, 2019, SPRING SER CHALLENGE, P3, DOI 10.1007/978-3-030-05318-5_1
   Ghalejoogh GS, 2020, EXPERT SYST APPL, V145, DOI 10.1016/j.eswa.2019.113127
   Gibbons JD, 2014, Nonparametric Statistical Inference
   Guy AFK, 2018, INFORM SCIENCES, V467, P199, DOI 10.1016/j.ins.2018.07.074
   Hameed N, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112961
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton, 2012, NEURAL NETWORKS MACH
   HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Hutter F, 2019, SPRING SER CHALLENGE, P1, DOI 10.1007/978-3-030-05318-5
   Islami F, 2018, CA-CANCER J CLIN, V68, P31, DOI 10.3322/caac.21440
   Khan MA, 2020, PATTERN RECOGN LETT, V129, P293, DOI 10.1016/j.patrec.2019.11.034
   Khan MA, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCIS), P63, DOI 10.1109/iccisci.2019.8716400
   Kingma D. P., 2014, arXiv
   Kittler H, 2002, LANCET ONCOL, V3, P159, DOI 10.1016/S1470-2045(02)00679-4
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulkarni RV, 2007, PROCEEDINGS OF THE 2007 INTERNATIONAL CONFERENCE ON INTELLIGENT SENSORS, SENSOR NETWORKS AND INFORMATION PROCESSING, P539
   Mahbod A, 2019, COMPUT MED IMAG GRAP, V71, P19, DOI 10.1016/j.compmedimag.2018.10.007
   Marks R, 2000, CLIN EXP DERMATOL, V25, P459, DOI 10.1046/j.1365-2230.2000.00693.x
   Masood A, 2013, INT J BIOMED IMAGING, V2013, DOI 10.1155/2013/323268
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pereira PMM, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101765
   POLI R, 2007, SWARM INTELL-US, V1, P33, DOI [DOI 10.1007/S11721-007-0002-0, DOI 10.1109/ICNN.1995.488968]
   Ratul M.A.R., 2020, bioRxiv, DOI DOI 10.1101/860700
   Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shi Y., 1998, Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), V1447, P591, DOI [10.1007/BFB0040810, DOI 10.1007/BFB0040810]
   Silveira M, 2009, IEEE J-STSP, V3, P35, DOI 10.1109/JSTSP.2008.2011119
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soyer HP, 2004, DERMATOLOGY, V208, P27, DOI 10.1159/000075042
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Storn R., 1995, Technical report, V11, DOI DOI 10.1023/A:1008202821328
   Sun SL, 2020, IEEE T CYBERNETICS, V50, P3668, DOI 10.1109/TCYB.2019.2950779
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tan TY, 2020, KNOWL-BASED SYST, V187, DOI 10.1016/j.knosys.2019.06.015
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   Vanschoren J, 2019, SPRING SER CHALLENGE, P35, DOI 10.1007/978-3-030-05318-5_2
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   WHITLEY D, 1994, STAT COMPUT, V4, P65, DOI 10.1007/BF00175354
   Wistuba M, 2016, PROCEEDINGS OF 3RD IEEE/ACM INTERNATIONAL CONFERENCE ON DATA SCIENCE AND ADVANCED ANALYTICS, (DSAA 2016), P41, DOI 10.1109/DSAA.2016.12
   Wu GX, 2016, NEUROCOMPUTING, V175, P310, DOI 10.1016/j.neucom.2015.10.064
   Xie LX, 2017, IEEE I CONF COMP VIS, P1388, DOI 10.1109/ICCV.2017.154
   Yan XH, 2017, J COMPUT SCI TECH-CH, V32, P340, DOI 10.1007/s11390-017-1714-2
   Yang L, 2020, NEUROCOMPUTING, V415, P295, DOI 10.1016/j.neucom.2020.07.061
   Ying C, 2019, PR MACH LEARN RES, V97
   Yu F., 2015, ARXIV
   Zeiler Matthew D, 2012, ARXIV12125701
   Zhang N, 2020, ARTIF INTELL MED, V102, DOI 10.1016/j.artmed.2019.101756
   Zoph B., 2016, INT C LEARN REPR
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 67
TC 10
Z9 10
U1 6
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 25677
EP 25709
DI 10.1007/s11042-023-14429-7
EA FEB 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000922388600003
DA 2024-07-18
ER

PT J
AU Zhang, S
   Che, SB
   Liu, Z
   Zhang, X
AF Zhang, Shuo
   Che, Shengbing
   Liu, Zhen
   Zhang, Xu
TI A real-time and lightweight traffic sign detection method based on
   ghost-YOLO
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Traffic sign detection; Small object detection;
   Ghost-YOLO
ID CONVOLUTIONAL NEURAL-NETWORK; FEATURE AGGREGATION; SCALE-AWARE; CNN
AB Traffic sign detection is an essential part of traffic security and unmanned driving system. Due to the changes in the traffic environment is complex, how to intelligently and efficiently detect traffic signs in real scenes is of great significance. The traffic sign detection task is characterized by many small targets and complex environmental interference, and the detection scene also requires the detection model to be lightweight and efficient. This paper proposes a lightweight model Ghost-YOLO, and a lightweight module C3Ghost is designed to replace the feature extraction module in YOLOv5. C3Ghost modules extract features in a lightweight way, which effectively speeds up inference. At the same time, a new multi-scale feature extraction is designed to enhance the focus on small targets. Experimental results show that the mAP of the Ghost-YOLO is 92.71%, and the number of parameters and computations are respectively reduced to 91.4% and 50.29% of the original. Compared with multiple lightweight models, the speed and accuracy of this method are competitive.
C1 [Zhang, Shuo; Che, Shengbing; Liu, Zhen; Zhang, Xu] Cent South Univ Forestry & Technol, Coll Comp & Informat Engn, Changsha 410004, Peoples R China.
C3 Central South University of Forestry & Technology
RP Che, SB (corresponding author), Cent South Univ Forestry & Technol, Coll Comp & Informat Engn, Changsha 410004, Peoples R China.
EM T20050514@csuft.edu.cn
FU National Science Foundation of China [31870532]
FX AcknowledgmentsThis work has been supported by the National Science
   Foundation of China, No.31870532.
CR [Anonymous], 2014, P BRIT MACH VIS C, DOI DOI 10.48550/ARXIV.1405.3866
   Arcos-García A, 2018, NEUROCOMPUTING, V316, P332, DOI 10.1016/j.neucom.2018.08.009
   Belghaouti O., 2020, PROCEDIA COMPUTER SC, V177, P468, DOI [10.1016/j.procs.2020.10.064, DOI 10.1016/J.PROCS.2020.10.064]
   Bénallal M, 2003, CCECE 2003: CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING, VOLS 1-3, PROCEEDINGS, P1823
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Dai JF, 2016, ADV NEUR IN, V29
   Ding YF, 2021, IEEE T IMAGE PROCESS, V30, P2826, DOI 10.1109/TIP.2021.3055617
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Kayhan N, 2021, MULTIMED TOOLS APPL, V80, P32763, DOI 10.1007/s11042-021-11217-z
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li JA, 2017, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2017.211
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y., 2020, World Scientific Research Journal, P276, DOI DOI 10.6911/WSRJ.202011_6(11).0038
   Liu YY, 2021, NEUROCOMPUTING, V447, P10, DOI 10.1016/j.neucom.2021.03.049
   Liu ZW, 2020, IEEE ACCESS, V8, P77920, DOI 10.1109/ACCESS.2020.2989758
   Liu ZG, 2019, IEEE ACCESS, V7, P57120, DOI 10.1109/ACCESS.2019.2913882
   Mei Y., 2020, ARXIV200413824
   Ou ZH, 2019, IEEE ACCESS, V7, P178798, DOI 10.1109/ACCESS.2019.2959015
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Romero A, 2014, Fitnets: Hints for thin deep nets. arXiv preprint arXiv:1412.6550, DOI [10.48550/arXiv.1412.6550, DOI 10.48550/ARXIV.1412.6550]
   Sermanet P, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2809, DOI 10.1109/IJCNN.2011.6033589
   Sharma S, 2021, MULTIMED TOOLS APPL, V80, P26319, DOI 10.1007/s11042-021-10768-5
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song SJ, 2019, J SYST ARCHITECT, V97, P269, DOI 10.1016/j.sysarc.2019.01.012
   Tang Q, 2021, IEEE ACCESS, V9, P117784, DOI 10.1109/ACCESS.2021.3106350
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   ultralytics, YOLOV5
   Wan JX, 2021, J SIGNAL PROCESS SYS, V93, P899, DOI 10.1007/s11265-020-01614-2
   Wang CS, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3170493
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang WH, 2019, IEEE I CONF COMP VIS, P8439, DOI 10.1109/ICCV.2019.00853
   Wu BC, 2017, IEEE COMPUT SOC CONF, P446, DOI 10.1109/CVPRW.2017.60
   Xia YJ, 2015, NEUROCOMPUTING, V151, P700, DOI 10.1016/j.neucom.2014.05.091
   XiongFei Liu, 2020, IOP Conference Series: Materials Science and Engineering, V787, DOI 10.1088/1757-899X/787/1/012034
   Yang TT, 2018, COMPUT NETW, V136, P95, DOI 10.1016/j.comnet.2018.02.026
   Yuan X, 2015, IEEE T SYST MAN CY-S, V45, P1509, DOI 10.1109/TSMC.2015.2427771
   Zhang HB, 2020, IEEE ACCESS, V8, P64145, DOI 10.1109/ACCESS.2020.2984554
   Zhang JM, 2020, IEEE ACCESS, V8, P29742, DOI 10.1109/ACCESS.2020.2972338
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang ZX, 2013, NEUROCOMPUTING, V99, P250, DOI 10.1016/j.neucom.2012.07.008
   Zhou K, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030686
   Zhou LP, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P578, DOI 10.1109/ITSC.2014.6957752
   [朱双东 ZHU Shuangdong], 2006, [中国图象图形学报, Journal of image and graphics], V11, P1127
   Zhu YY, 2016, NEUROCOMPUTING, V214, P758, DOI 10.1016/j.neucom.2016.07.009
   Zhu Z., 2016, PROC CVPR IEEE, P2110, DOI DOI 10.1109/CVPR.2016.232
NR 55
TC 6
Z9 7
U1 46
U2 172
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26063
EP 26087
DI 10.1007/s11042-023-14342-z
EA JAN 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000926794100002
DA 2024-07-18
ER

PT J
AU Qiang, N
   Shen, XJ
   Ganaa, ED
   Yang, Y
   Wu, SL
   Zhao, ZM
   Huang, SC
AF Qiang, Na
   Shen, Xiangjun
   Ganaa, Ernest Domanaanmwi
   Yang, Yang
   Wu, Shengli
   Zhao, Zengmin
   Huang, Shucheng
TI A correlation analysis framework via joint sample and feature selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Correlation analysis; Sample selection; Feature selection; Cosine
   similarity metric; Total distance metric
ID CANONICAL CORRELATION-ANALYSIS; KERNEL
AB Correlation Analysis is a popular technique for describing relationships between two datasets. In this paper, we proposed a correlation analysis framework via Joint Sample and Feature Selection (CAF-JSFS). Different from traditional correlation analysis where only feature selection is considered and each data point is treated equally, the significance of each data point is measured by a sample selection strategy in this framework. Considering that the principal projection is a feasible representation of data, the relationship between this principal projection and each data sample is recursively learnt through two sample selection strategies: cosine similarity and total distance metrics. In addition, CAF-JSFS solves the problem of feature redundancy caused by sample feature selection, and eliminates irrelevant features, thereby improving classification accuracy. This enhances the discriminative power of CAF-JSFS in noisy scenarios which makes better correlation projections achievable to improve performance. Extensive experiments on several datasets demonstrated the effectiveness of the proposed method compared to the state-of-the-art methods.
C1 [Qiang, Na] JiangSu Univ, JingJiang Coll, Zhenjiang 212013, Jiangsu, Peoples R China.
   [Shen, Xiangjun; Ganaa, Ernest Domanaanmwi; Yang, Yang; Wu, Shengli] JiangSu Univ, Sch Comp Sci & Commun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
   [Zhao, Zengmin] ChangZhou Uzone Intelligent Technol Co Ltd, Changzhou, Jiangsu, Peoples R China.
   [Huang, Shucheng] Jiangsu Univ Sci & Technol, Sch Comp Sci, Zhenjiang 212003, Jiangsu, Peoples R China.
C3 Jiangsu University; Jiangsu University of Science & Technology
RP Shen, XJ (corresponding author), JiangSu Univ, Sch Comp Sci & Commun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
EM xjshen@ujs.edu.cn
RI Wu, Shengli/AAV-5474-2020; Ganaa, Ernest Domanaanmwi/O-5746-2019
OI Wu, Shengli/0000-0003-1167-007X; Ganaa, Ernest
   Domanaanmwi/0000-0002-2161-7435
CR Akaho, 2006, ARXIV, DOI [10.48550/arXiv.cs/0609071, DOI 10.48550/ARXIV.CS/0609071]
   Apasiba Abeo T, GEN MULTIDICTIONARY, V90
   Arenas-García J, 2013, IEEE SIGNAL PROC MAG, V30, P16, DOI 10.1109/MSP.2013.2250591
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Cai D., 2010, KDD, P333
   Cai D, 2007, IEEE DATA MINING, P73, DOI 10.1109/ICDM.2007.89
   Chen ZW, 2022, IEEE T NEUR NET LEAR, V33, P6158, DOI 10.1109/TNNLS.2021.3072491
   Dy JG, 2004, J MACH LEARN RES, V5, P845
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   He X.F., 2005, P 22 INT C MACH LEAR, P281, DOI DOI 10.1145/1102351.1102387
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   Hu ZF, 2016, IEEE T NEUR NET LEAR, V27, P875, DOI 10.1109/TNNLS.2015.2427451
   Lai PL, 2000, IEEE IJCNN, P614
   Liu JM, 2014, IEEE T IMAGE PROCESS, V23, P4022, DOI 10.1109/TIP.2014.2343458
   Liu WF, 2013, IEEE T IMAGE PROCESS, V22, P2676, DOI 10.1109/TIP.2013.2255302
   Liu YJ, 2019, IEEE T SYST MAN CY-S, V49, P2318, DOI 10.1109/TSMC.2018.2815560
   Lu YC, 2014, ADV NEUR IN, V27
   MOGHADDAM BABACK, 2006, P 23 INT C MACH LEAR, P641, DOI DOI 10.1145/1143844.1143925
   Nie F., 2008, P 23 NATL C ARTIFICI, V2, P671
   Nie FP, 2021, IEEE T IMAGE PROCESS, V30, P5277, DOI 10.1109/TIP.2021.3073282
   Nie FP, 2010, IEEE T IMAGE PROCESS, V19, P1921, DOI 10.1109/TIP.2010.2044958
   Passalis N, 2018, IEEE T NEUR NET LEAR, V29, P3429, DOI 10.1109/TNNLS.2017.2728818
   Ping XR, 2021, PROCEEDINGS OF 2021 2ND INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND INFORMATION SYSTEMS (ICAIIS '21), DOI 10.1145/3469213.3470288
   Roth V, 2004, ADV NEUR IN, V16, P473
   Sakar CO, 2012, EXPERT SYST APPL, V39, P3432, DOI 10.1016/j.eswa.2011.09.031
   Shen XJ, 2021, PATTERN RECOGN, V109, DOI 10.1016/j.patcog.2020.107587
   Sun SL, 2016, IEEE T NEUR NET LEAR, V27, P1827, DOI 10.1109/TNNLS.2015.2461009
   Tao JL, 2019, LECT NOTES COMPUT SC, V11296, P352, DOI 10.1007/978-3-030-05716-9_29
   Wang FS, 2013, NEURAL PROCESS LETT, V37, P135, DOI 10.1007/s11063-012-9238-9
   Wang SH, 2015, NEUROCOMPUTING, V168, P747, DOI 10.1016/j.neucom.2015.05.049
   Wu Y., 2011, 22 INT JOINT C ARTIF
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yuan YH, 2014, PATTERN RECOGN, V47, P1411, DOI 10.1016/j.patcog.2013.09.009
   Zhang R, 2018, IEEE T NEUR NET LEAR, V29, P3913, DOI 10.1109/TNNLS.2017.2740341
   Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430
NR 36
TC 0
Z9 0
U1 4
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19539
EP 19555
DI 10.1007/s11042-022-14237-5
EA DEC 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000903299800002
DA 2024-07-18
ER

PT J
AU Basil, N
   Marhoon, HM
   Gokulakrishnan, S
   Buddhi, D
AF Basil, Noorulden
   Marhoon, Hamzah M. M.
   Gokulakrishnan, S.
   Buddhi, Dharam
TI Jaya optimization algorithm implemented on a new novel design of 6-DOF
   AUV body: a case study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Autonomous underwater vehicle; 6-DOF AUV body; Jaya optimization
   algorithm; Trajectory control; PID controller
ID TRAJECTORY TRACKING; PARALLEL
AB The novel Jaya Optimization Algorithm (JOA) was utilized in this research to evaluate the efficiency of a new novel design of Autonomous Underwater Vehicle (AUV). The Three Proportional Integral Derivative (PID) controllers were used to obtain the optimum output for the AUV Trajectory, which can be considered as a main side of the research for solving the AUV Performance. The optimization technique has been developed to solving the motion model of the AUV in order to reduce the rotations of trajectory for the AUV 6-DOF Body in the axis's in x, y and z for the overall positions, velocity were measured in 50 seconds as the velocity compared with the simulated time, and to execute the optimum output for the dynamic kinematics model based on the Novel Euler-6 DOF AUV Body Equation implemented on MATLAB R2021a Version.
C1 [Basil, Noorulden; Marhoon, Hamzah M. M.] Al esraa Univ Coll, Dept Comp Tech Engn, Baghdad, Iraq.
   [Gokulakrishnan, S.] SKP Engn Coll, Dept Math, Tiruvannamalai 606611, India.
   [Buddhi, Dharam] Uttaranchal Univ, Dharam Buddhi Div Res & Innovat, Dehra Dun 248007, Uttarakhand, India.
C3 Al-Esraa University College; Uttaranchal University
RP Basil, N (corresponding author), Al esraa Univ Coll, Dept Comp Tech Engn, Baghdad, Iraq.
EM nooralden@esraa.edu.iq; hamza@esraa.edu.iq
RI Basil, Noorulden/AEK-9719-2022; Buddhi, Dharam/Q-1593-2015; M. Marhoon,
   Hamzah/AAZ-7366-2020
OI Basil, Noorulden/0000-0003-0847-2611; M. Marhoon,
   Hamzah/0000-0001-5613-6685
CR BEGON P, 1995, IEEE INT CONF ROBOT, P1178, DOI 10.1109/ROBOT.1995.525440
   Beji L, 1998, IEEE INT CONF ROBOT, P2309, DOI 10.1109/ROBOT.1998.680667
   Borlaug ILG, 2018, IFAC PAPERSONLINE, V51, P311, DOI 10.1016/j.ifacol.2018.09.506
   Bounemeur A., 2021, INT J ROBOT CONTROL, V1, P102
   Che G., 2022, J. Ambient Intell. Hum. Comput., V14, P1
   Cherdehoosilpa S, 2002, IEEE ICIT' 02: 2002 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY, VOLS I AND II, PROCEEDINGS, P673
   Cuevas E, 2017, COMP PERSPECTIVE, V686, P75
   El-Fergany AA, 2017, IET GENER TRANSM DIS, V11, P637, DOI 10.1049/iet-gtd.2016.0455
   Elouni M, 2022, INT J ROBOT CONTROL, V2, P523
   Ferreira BrunoM., 2012, Proc. 12th Int. Conf. on Autonomous Robot Systems and Competitions, P57
   Gon??alves M., 2022, INT J ROBOT CONTROL, V2, P581, DOI [10.31763/ijrcs.v2i3.768, DOI 10.31763/IJRCS.V2I3.768]
   Herlambang T, 2018, INT REV MECH ENG I R, V12, P928
   Herlambang T, 2014, APPL MECH MATER, V493, P420, DOI 10.4028/www.scientific.net/AMM.493.420
   I-Fang Chung, 1999, IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028), P325, DOI 10.1109/ICSMC.1999.814111
   Kadjie AN, 2021, INT J ROBOT CONTROL, V1, P269
   Lee SH, 2003, MECHATRONICS, V13, P605, DOI 10.1016/S0957-4158(02)00033-8
   Lee SH, 2001, IROS 2001: PROCEEDINGS OF THE 2001 IEEE/RJS INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2184, DOI 10.1109/IROS.2001.976394
   Li X, 2022, FORMATION TRACKING M
   Liu GF, 2001, IEEE INT CONF ROBOT, P3748, DOI 10.1109/ROBOT.2001.933201
   Luque-Chang A, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/6843923
   Maaruf M., 2022, Int. J. Robot. Control Syst., V2, P652, DOI 10.31763/ijrcs.v2i4.743
   Maurya L, 2017, APPL SOFT COMPUT, V52, P575, DOI 10.1016/j.asoc.2016.10.012
   Mohamadwasel NB, 2021, APPL NANOSCI, DOI 10.1007/s13204-021-02034-9
   Mounim MA, 2020, INT J RES APPL SCI E, V8, P121
   Ouadfel S, 2016, EXPERT SYST APPL, V55, P566, DOI 10.1016/j.eswa.2016.02.024
   Ouyang PR, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P4126, DOI 10.1109/ROBOT.2002.1014393
   Pernechele C, 2000, IEEE IJCNN, P349, DOI 10.1109/IJCNN.2000.860796
   Poppinga J., 2011, 2011 Proceedings of IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR 2011), P345, DOI 10.1109/SSRR.2011.6106771
   Raad M, 2022, Int. J. Mech. Eng, V7, P3170
   Rahayu E.S., 2022, Int J Robot Control Syst, V2, P435, DOI [10.31763/ijrcs.v2i2.476, DOI 10.31763/IJRCS.V2I2.476]
   Rasekh M, 2022, P I MECH ENG M-J ENG, V236, P474, DOI 10.1177/14750902211034361
   Rezazadegan F, 2015, OCEAN ENG, V107, P246, DOI 10.1016/j.oceaneng.2015.07.040
   Salumäe T, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1321, DOI 10.1109/IROS.2016.7759218
   Su Y. X., 2004, Fifth World Congress on Intelligent Control and Automation (IEEE Cat. No.04EX788), P5012
   Su YX, 2006, IEEE T ROBOT, V22, P202, DOI 10.1109/TRO.2005.858852
   Suseno E, 2021, International Journal of Robotics and Control Systems, V1, P41, DOI [10.31763/ijrcs.v1i1.249.02/22, DOI 10.31763/IJRCS.V1I1.249.02/22]
   Yiu YK, 2003, 2003 IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION, VOLS I-III, PROCEEDINGS, P1052
   Zahraoui Y, 2021, INT J ROBOT CONTROL, V2, P1
   Zhang JL, 2017, CHIN CONTR CONF, P4796, DOI 10.23919/ChiCC.2017.8028111
NR 39
TC 4
Z9 4
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 DEC 12
PY 2022
DI 10.1007/s11042-022-14293-x
EA DEC 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6Z4XB
UT WOS:000897780500001
DA 2024-07-18
ER

PT J
AU Patil, GG
   Banyal, RK
AF Patil, Ganesh Gopalrao
   Banyal, Rohitash Kumar
TI A hybrid SUGWO optimization for partial face recognition with new
   similarity index
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Partial face recognition; Fully convolutional network; Sparse
   representation classification; Dynamic feature matching; Optimization
ID MODEL
AB This paper introduces a Partial Face Recognition (PFR) method with the benefits of optimization logic using an optimized feature matching aspect. Besides, for better recognition, the Sparse Representation Classification (SRC) and Fully Convolutional Network (FCN) have been combined. As a novelty, this work aims to tune the sparse coefficient of Dynamic Feature Matching (DFM) optimally, in which the reconstruction error should be minimal. Also, this work presents the structural similarity index measure to calculate the similarity scores between the gallery sub-feature map and probe feature map. For optimization purposes, this work deploys a proposed Sealion Updated Grey Wolf Optimization (SUGWO) algorithm. Finally, the proposed method is executed over the traditional methods concerning certain measures.
C1 [Patil, Ganesh Gopalrao; Banyal, Rohitash Kumar] Rajasthan Tech Univ, Dept Comp Sci & Engn, Kota 324010, Rajasthan, India.
C3 Rajasthan Technical University
RP Patil, GG (corresponding author), Rajasthan Tech Univ, Dept Comp Sci & Engn, Kota 324010, Rajasthan, India.
EM gopalraoganesh09@gmail.com
CR Alexandridis G, 2019, COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2019 ), P335, DOI 10.1145/3308560.3316601
   Aminu M, 2019, IN PRESS
   Beno MM, 2014, INT J IMAG SYST TECH, V24, P129, DOI 10.1002/ima.22087
   Brammya A. Suki, 2019, Multimedia Res., V2, P1
   Daniya T., 2020, J NETWORKING COMMUNI, V3, P30
   Duan YQ, 2018, IEEE T INF FOREN SEC, V13, P1823, DOI 10.1109/TIFS.2018.2804919
   Elmahmudi A, 2019, FUTURE GENER COMP SY, V99, P213, DOI 10.1016/j.future.2019.04.025
   Fang C, 2017, PATTERN RECOGN, V69, P14, DOI 10.1016/j.patcog.2017.03.034
   García E, 2017, IEEE LAT AM T, V15, P1960, DOI 10.1109/TLA.2017.8071241
   Grati N, 2020, EXPERT SYST APPL, V150, DOI 10.1016/j.eswa.2020.113319
   Greening SG, 2018, CORTEX, V101, P31, DOI 10.1016/j.cortex.2017.11.016
   Gruber I, 2017, LECT NOTES ARTIF INT, V10459, P67, DOI 10.1007/978-3-319-66471-2_8
   Gunawan T., 2017, INDONES J ELECT ENG, DOI DOI 10.11591/IJEEI.V5I4.361
   He LX, 2019, IEEE T IMAGE PROCESS, V28, P791, DOI 10.1109/TIP.2018.2870946
   He MJ, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107113
   Iranmanesh SM, 2020, IMAGE VISION COMPUT, V94, DOI 10.1016/j.imavis.2019.103861
   Kim H, 2019, NEUROSCI LETT, V708, DOI 10.1016/j.neulet.2019.134344
   Kryza-Lacombe M, 2020, J AM ACAD CHILD PSY, V59, P1380, DOI 10.1016/j.jaac.2019.09.002
   Kumar A, 2019, ARTIF INTELL REV, V52, P927, DOI 10.1007/s10462-018-9650-2
   Lahasan B, 2018, INFORM SCIENCES, V429, P194, DOI 10.1016/j.ins.2017.11.013
   Lei YJ, 2016, PATTERN RECOGN, V52, P218, DOI 10.1016/j.patcog.2015.09.035
   Li PF, 2019, TUNN UNDERGR SP TECH, V91, DOI 10.1016/j.tust.2019.05.019
   Lokku G, 2021, 2021 INT C COMMUNICA, V1, P1, DOI 10.1109/ICCISc52257.2021.9484935
   Mahbub U, 2019, IMAGE VISION COMPUT, V82, P1, DOI 10.1016/j.imavis.2018.12.003
   Mahendran, 2020, J COMPUT MECH POWER, V3, P42, DOI DOI 10.46253/JCMPS.V3I1.A5
   Maria Dominic Savio M., 2021, Journal of Physics: Conference Series, DOI 10.1088/1742-6596/1964/6/062023
   Masadeh R, 2019, INT J ADV COMPUT SC, V10, P388
   Meinhardt-Injac B, 2020, COGNITIVE DEV, V53, DOI 10.1016/j.cogdev.2020.100851
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2015, KNOWL-BASED SYST, V89, P228, DOI 10.1016/j.knosys.2015.07.006
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mukhedkar, 2019, J NETW COMMUN SYST, V2, P1, DOI DOI 10.46253/JNACS.V2I3.A1
   Pawar S, 2018, 4 INT C COMPUTING CO
   Porpiglia F, 2019, EUR UROL ONCOL, V2, P104, DOI 10.1016/j.euo.2018.12.001
   Prasanalakshmi B., 2011, INT J COMPUT SCI, V8, P604
   Roy R. G., 2019, J COMPUT MECH POWER, P9, DOI DOI 10.46253/JCMPS.V2I1.A2
   Roy RG, 2020, ROBOTICA, V38, P1539, DOI 10.1017/S0263574719001620
   Shan XX, 2021, IEEE T CIRC SYST VID, V31, P4347, DOI 10.1109/TCSVT.2020.3047140
   Srikrishnaswetha Kone, 2019, Innovations in Electronics and Communication Engineering. Proceedings of the 7th ICIECE 2018. Lecture Notes in Networks and Systems (LNNS 65), P87, DOI 10.1007/978-981-13-3765-9_10
   Subramanyam T. C., 2018, J. Comput. Mech. Power Syst. Control, P34
   Thomas M. J. S., 2018, MULTIMEDIA RES, P33, DOI DOI 10.46253/J.MR.V1I1.A5
   Trigueros DS, 2018, IMAGE VISION COMPUT, V79, P99, DOI 10.1016/j.imavis.2018.09.011
   Trofimov A, 2017, INT J SOLIDS STRUCT, V108, P289, DOI 10.1016/j.ijsolstr.2016.12.028
   Vinolin V., 2019, MULTIMEDIA RES, V2, P10, DOI DOI 10.46253/J.MR.V2I2.A2
   Wagh MB., 2019, J NETW COMMUN SYST, V2, P34, DOI DOI 10.46253/JNACS.V2I1.A4
   Weng RL, 2016, IEEE T IMAGE PROCESS, V25, P1163, DOI 10.1109/TIP.2016.2515987
   Werghi N, 2016, IEEE T INF FOREN SEC, V11, P964, DOI 10.1109/TIFS.2016.2515505
   Xu Y, 2020, J COMPUT MECH POWER, V3, DOI [10.46253/jcmps.v3i3.a1, DOI 10.46253/JCMPS.V3I3.A1]
   Young SG, 2019, J EXP SOC PSYCHOL, V85, DOI 10.1016/j.jesp.2019.103883
   Yu NG, 2020, IEEE ACCESS, V8, P4700, DOI 10.1109/ACCESS.2019.2963201
   Zheng WB, 2020, NEUROCOMPUTING, V376, P25, DOI 10.1016/j.neucom.2019.09.045
   Zuhaer M., 2019, CIHAN U ERBIL SCI J, V3, P80
NR 52
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18097
EP 18116
DI 10.1007/s11042-022-14205-z
EA DEC 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000921144700003
DA 2024-07-18
ER

PT J
AU Shen, NY
   Feng, ZY
   Li, J
   You, H
   Xia, CY
AF Shen, Nanyan
   Feng, Zeyuan
   Li, Jing
   You, Hua
   Xia, Chenyu
TI Action fusion recognition model based on GAT-GRU binary classification
   networks for human-robot collaborative assembly
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Human-robot collaborative assembly; Fusion
   identification; Graph attention network; Gated recurrent unit; Skeleton
   data
ID LSTM
AB Action recognition makes the interaction in human-robot collaboration (HRC) more natural and enhances the efficiency of work. The common action recognition models can neither handle the undefined beforehand transitional actions of operators in HRC nor quickly modify the action classes to be recognized according to the change of collaboration process. In this paper, an action recognition model for HRC assembly is proposed by fusing the outputs of multiple binary classification networks. Moreover, in order to meet both the action recognition speed and accuracy requirements in HRC applications, a spatio-temporal feature extraction network based on graph attention-gated recurrent unit network is designed for binary classification. The proposed model can identify the different operational actions from continuous skeletal data of the operator and distinguish between operational actions and transitional actions. Therefore, this model can reduce false action recognition and thus avoid the mistaken controls and the dangerous actions of robot serves HRC application better. Besides, due to the structure of fusion identification, this model is also well scalable and able to quickly adjust the action classes required to be recognized for HRC task with no need of retraining the entire recognition model. The case study of HRC personal computer assembly demonstrates that the proposed action recognition model achieves the accuracy of about 84% and the best effectiveness.
C1 [Shen, Nanyan; Feng, Zeyuan; Li, Jing; You, Hua; Xia, Chenyu] Shanghai Univ, Sch Mechatron Engn & Automat, Shanghai Key Lab Intelligent Mfg & Robot, Room 431,Bldg 9,333,Nanchen Rd, Shanghai 200444, Peoples R China.
C3 Shanghai University
RP Li, J (corresponding author), Shanghai Univ, Sch Mechatron Engn & Automat, Shanghai Key Lab Intelligent Mfg & Robot, Room 431,Bldg 9,333,Nanchen Rd, Shanghai 200444, Peoples R China.
EM shny@shu.edu.cn; zeyuanfeng@shu.edu.cn; ian1982@shu.edu.cn;
   huayou_opting@163.com; cyxia@shu.edu.cn
OI Li, Jing/0000-0002-9863-8955
FU Shanghai Municipal Commission of Economy and Information; 
   [2021-GYHLW-01008]
FX This work was supported by the project from Shanghai Municipal
   Commission of Economy and Information (grant number 2021-GYHLW-01008).
CR Birch B, 2021, P I MECH ENG B-J ENG, V235, P1939, DOI 10.1177/09544054211014492
   Bulling A, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2499621
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Carrara F, 2019, MULTIMED TOOLS APPL, V78, P27309, DOI 10.1007/s11042-019-07827-3
   Chathuramali KGM, 2012, INT CONF ADV ICT, P197, DOI 10.1109/ICTer.2012.6421415
   Cho K., 2014, ARXIV14061078
   Coupeté E, 2015, PROCEDIA MANUF, V3, P518, DOI 10.1016/j.promfg.2015.07.216
   Dawar N, 2018, IEEE SENS J, V18, P9660, DOI 10.1109/JSEN.2018.2872862
   Dehghani A, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19225026
   Dos Santos CW, 2020, IFAC PAPERSONLINE, V53, P10168, DOI 10.1016/j.ifacol.2020.12.2744
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Inkulu AK, 2022, IND ROBOT, V49, P226, DOI 10.1108/IR-04-2021-0077
   Keselman L, 2017, IEEE COMPUT SOC CONF, P1267, DOI 10.1109/CVPRW.2017.167
   Li R, 2018, IET COMPUT VIS, V12, P434, DOI 10.1049/iet-cvi.2016.0385
   Li S., 2019, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, P3595
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Li YH, 2016, LECT NOTES COMPUT SC, V9911, P203, DOI 10.1007/978-3-319-46478-7_13
   Liu HY, 2018, PROC CIRP, V72, P3, DOI 10.1016/j.procir.2018.03.224
   Liu PC, 2019, NONLINEAR DYNAM, V98, P1447, DOI 10.1007/s11071-019-05170-8
   Liu S, 2022, INT J ADV MANUF TECH, V118, P949, DOI 10.1007/s00170-021-07985-5
   Ma CY, 2019, SIGNAL PROCESS-IMAGE, V71, P76, DOI 10.1016/j.image.2018.09.003
   Ogenyi UE, 2021, IEEE T CYBERNETICS, V51, P1888, DOI 10.1109/TCYB.2019.2947532
   Ren B, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2002.05907
   Schlagenhauf F, 2018, IEEE INT CONF CON AU, P674, DOI 10.1109/ICCA.2018.8444349
   Shafer Glenn, 1976, MATH THEORY EVIDENCE, P2
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Velickovic Petar, 2018, INT C LEARN REPR
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang KJ, 2022, INT J ADV MANUF TECH, V119, P865, DOI 10.1007/s00170-021-08319-1
   Wang L, 2019, CIRP ANN-MANUF TECHN, V68, P701, DOI 10.1016/j.cirp.2019.05.002
   Wang P, 2018, CIRP ANN-MANUF TECHN, V67, P17, DOI 10.1016/j.cirp.2018.04.066
   Yan S, 2018, 32 AAAI C ART INT, DOI [10.48550/arXiv.1802.09834, DOI 10.48550/ARXIV.1802.09834]
   Zhang K, 2020, IEEE INT CON AUTO SC, P404, DOI [10.1109/CASE48305.2020.9216971, 10.1109/case48305.2020.9216971]
   Zhao R, 2017, IEEE INT C INT ROBOT, P4260, DOI 10.1109/IROS.2017.8206288
NR 36
TC 2
Z9 2
U1 10
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18867
EP 18885
DI 10.1007/s11042-022-14123-0
EA DEC 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000893885100001
DA 2024-07-18
ER

PT J
AU Ji, SZ
   Yao, CX
   Feng, ZH
AF Ji, Shengzheng
   Yao, Chuanxin
   Feng, Zihan
TI Path recognition of UAV based on improved super-greening algorithm and
   design of adaptive Trichogramma pill dispenser
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-greening algorithm; UAV path planning; Edge detection; Adaptive
   PID control algorithm; Trichogramma pill dispenser
AB Aiming at the problem that the traditional Trichogramma pill dispenser is inaccurate due to the change of wind speed during operation, and the traditional algorithm cannot meet the accuracy and applicability of the Unmanned Aerial Vehicle (UAV) path identification and the delivery process, this paper proposes path recognition of UAV based on an improved super-greening algorithm and design of adaptive Trichogramma pill dispenser. The improved super-greening algorithm and the maximum inter-class variance method are used to automatically obtain the green feature binary image, and the morphological processing is used to improve the image quality; the crop location point extraction algorithm based on edge detection is used to extract the feature points, and the feature points are used to fit the navigation line. The wind pressure sensor is used to obtain the voltage signal, and the measured voltage is output after being processed by the airborne 5G board, and the motor speed is controlled according to the adaptive PID control algorithm. The simulation results show that the improved super-greening algorithm more truly reflects the green content in the image, which makes the image extraction more accurate; the crop positioning point extraction algorithm of edge detection is 3.4 and 3.7 smaller than the vertical projection algorithm in average error and positioning error respectively; compared with the vertical projection method, the edge detection method reduces the time consumption by 150 ms and increases the accuracy by 8%; adaptive PID control algorithm compared with the traditional PID control algorithm, the rise time, adjustment time and overshoot are 1.5%, 4.8% and 11.5% smaller respectively. The research results can provide research ideas for the application of UAV precise delivery of Trichogramma bee pills technology in agriculture.
C1 [Ji, Shengzheng; Yao, Chuanxin] Shandong Univ Technol, Sch Mech Engn, Zhangdian Dist 255049, Zibo, Peoples R China.
   [Feng, Zihan] Shandong Univ Technol, Sch Agr Engn & Food Sci, Zhangdian Dist 255049, Zibo, Peoples R China.
C3 Shandong University of Technology; Shandong University of Technology
RP Ji, SZ (corresponding author), Shandong Univ Technol, Sch Mech Engn, Zhangdian Dist 255049, Zibo, Peoples R China.
EM 1304768940@qq.com; 1445828606@qq.com; 534424606@qq.com
CR [Anonymous], 2018, Teacher and Principal Turnover in Public Schools in the District of Columbia, P1
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2021, IEEE PHOTONICS J, V13, DOI 10.1109/JPHOT.2021.3059703
   Bhatti UA, 2020, IEEE ACCESS, V8, P155783, DOI 10.1109/ACCESS.2020.3018544
   Bzowska-Bakalarz M, 2020, PEST MANAG SCI, V76, P2243, DOI 10.1002/ps.5762
   Diwakar M, 2018, IET IMAGE PROCESS, V12, P708, DOI 10.1049/iet-ipr.2017.0639
   Diwakar M, 2018, BIOMED SIGNAL PROCES, V42, P73, DOI 10.1016/j.bspc.2018.01.010
   Gao Z., 2011, APPL OPTICS, V32, P5
   Hua R., 2017, COMMUN POWER TECHNOL, V34, P3
   Jie H., 2014, J AGR MACH, VS1, P265
   Jiu F., 2007, CHINESE J ELECTRON, V35, P5
   Kairo G, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-08380-5
   Kashyap Y, 2012, BIOM BIOINFORMATICS, V4
   Lian W., 2019, CHIN J APPL ENTOMOL, V2, P1
   Ling Y., 2017, JIANGSU AGR SCI, V45, P1
   Montalvo M, 2012, EXPERT SYST APPL, V39, P11889, DOI 10.1016/j.eswa.2012.02.117
   Subramaniam R, 2021, MAT TODAY PROCEED, V1
   Watros A, 2019, APPL ECOL ENV RES, V17, P107, DOI 10.15666/aeer/1701_107121
   Yang P, 2020, INT J COMPUT SCI ENG, V22, P146, DOI 10.1504/IJCSE.2020.107266
   Yong S, 2010, J AGR MACH, V41, P185
   Yong S, 2010, J AGR MACH, V041, P163
   Zhan YL, 2021, PEST MANAG SCI, V77, P3259, DOI 10.1002/ps.6371
   Zhen C., 2019, J S CHINA AGR U, V40, P100
NR 23
TC 1
Z9 1
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 17301
EP 17320
DI 10.1007/s11042-022-14209-9
EA NOV 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000884646200007
DA 2024-07-18
ER

PT J
AU Ma, YP
   Wu, Y
   Li, QW
   Zhou, YQ
   Yu, DB
AF Ma, Yunpeng
   Wu, Yi
   Li, Qingwu
   Zhou, Yaqin
   Yu, Dabing
TI ROV-based binocular vision system for underwater structure crack
   detection and width measurement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater inspection system; ROV system; Binocular vision; Crack
   detection; Crack width measurement
ID LOCALIZATION
AB It is efficient to replace human eyes with underwater vehicles equipped with visual sensors to carry out underwater inspections. However, the inability of monocular vision to provide accurate depth information highlights the importance of binocular vision in underwater target detection and measurement. In this paper, an ROV (Remotely Operated Vehicles) based binocular vision system incorporating a specially designed underwater robot is developed to carry out underwater structure detection in real-time. The system is designed to adapt to long-distance and long-duration underwater missions in various underwater environments. Taking cracks as inspection targets, a crack detection and measurement approach is proposed after the robot's surface cleaning function is applied. Firstly, an affine transformation model is used to enhance the color-distorted underwater images effectively. Then, the multi-directional gray-level fluctuation analysis is applied to acquire an accurate crack segmented result. Finally, the computed disparity map is combined with the segmentation map to determine the crack width quickly. A group of experiments is performed and the validity and effectiveness of the system and crack measurement algorithm are demonstrated.
C1 [Ma, Yunpeng; Wu, Yi; Li, Qingwu; Zhou, Yaqin; Yu, Dabing] Hohai Univ, Coll Internet Things Engn, Changzhou, Peoples R China.
   [Li, Qingwu] Hohai Univ, Key Lab Sensor Networks & Environm Sensing, Changzhou 213022, Peoples R China.
C3 Hohai University; Hohai University
RP Wu, Y (corresponding author), Hohai Univ, Coll Internet Things Engn, Changzhou, Peoples R China.
EM 18761156960@163.com
RI Yu, Dabing/HTQ-8123-2023
FU National Natural Science Foundation of China [62001156]; Jiangsu
   Provincial Key Research and Development Program [BE2019036]
FX This research was funded by the National Natural Science Foundation of
   China, grant number 62001156, and the Jiangsu Provincial Key Research
   and Development Program, grant number BE2019036.
CR Alipour M, 2019, J COMPUT CIVIL ENG, V33, DOI 10.1061/(ASCE)CP.1943-5487.0000854
   Cha YJ, 2017, COMPUT-AIDED CIV INF, V32, P361, DOI 10.1111/mice.12263
   Cha YJ, 2016, AUTOMAT CONSTR, V71, P181, DOI 10.1016/j.autcon.2016.06.008
   Chen Z, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17081784
   Cho H, 2018, IEEE ACCESS, V6, P60100, DOI 10.1109/ACCESS.2018.2875889
   Choi JK, 2018, IEEE J OCEANIC ENG, V43, P665, DOI 10.1109/JOE.2017.2735598
   Collings S, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12152443
   Feng CC, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20072069
   Gong ZJ, 2020, IEEE T VEH TECHNOL, V69, P15857, DOI 10.1109/TVT.2020.3036350
   Gottsäter E, 2019, ENG STRUCT, V189, P272, DOI 10.1016/j.engstruct.2019.03.089
   Hachicha S, 2019, OCEAN ENG, V181, P303, DOI 10.1016/j.oceaneng.2019.03.044
   Hassan N, 2021, MULTIMED TOOLS APPL, V80, P1839, DOI 10.1007/s11042-020-09752-2
   Hong S, 2020, INT J CONTROL AUTOM, V18, P564, DOI 10.1007/s12555-019-0646-8
   Huang DM, 2018, LECT NOTES COMPUT SC, V10704, P453, DOI 10.1007/978-3-319-73603-7_37
   Islam MJ, 2020, IEEE ROBOT AUTOM LET, V5, P3227, DOI 10.1109/LRA.2020.2974710
   Jin S, 2020, AUTOMAT CONSTR, V110, DOI 10.1016/j.autcon.2019.103019
   Kot P, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11062750
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Li LJ, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON ROBOTICS, INTELLIGENT CONTROL AND ARTIFICIAL INTELLIGENCE (RICAI 2019), P738, DOI 10.1145/3366194.3366327
   Li SM, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9173573
   Lu PP, 2016, LECT NOTES ELECTR EN, V359, P29, DOI 10.1007/978-3-662-48386-2_4
   Marques TP, 2020, IEEE COMPUT SOC CONF, P2286, DOI 10.1109/CVPRW50498.2020.00277
   Muhammad N, 2019, AUTON ROBOT, V43, P1419, DOI 10.1007/s10514-018-9797-3
   Muñoz F, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11062797
   Nasr A, 2020, STRUCT INFRASTRUCT E, V16, P738, DOI 10.1080/15732479.2019.1670215
   Hoang ND, 2018, AUTOMAT CONSTR, V94, P203, DOI 10.1016/j.autcon.2018.07.008
   Nowald N, 2016, OCEANS 2016 MTS/IEEE MONTEREY, DOI 10.1109/OCEANS.2016.7761353
   Palomer A, 2019, J FIELD ROBOT, V36, P1333, DOI 10.1002/rob.21907
   Peng X, 2021, CONSTR BUILD MATER, V299, DOI 10.1016/j.conbuildmat.2021.123896
   Protasiuk R, 2019, IEEE WINT CONF APPL, P1433, DOI 10.1109/WACV.2019.00157
   Qiu S., 2016, Journal of Computing in Civil Engineering, V31, DOI DOI 10.1061/(ASCE)CP.1943-5487
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Rizzini DL, 2015, INT J ADV ROBOT SYST, V12, DOI 10.5772/60526
   Salumäe T, 2019, IEEE J OCEANIC ENG, V44, P54, DOI 10.1109/JOE.2017.2774318
   Shi PF, 2022, MULTIMED TOOLS APPL, V81, P4569, DOI 10.1007/s11042-020-10187-y
   Shortis M, 2015, SENSORS-BASEL, V15, P30810, DOI 10.3390/s151229831
   Song W, 2018, LECT NOTES COMPUT SC, V11164, P678, DOI 10.1007/978-3-030-00776-8_62
   Villa J, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12244106
   Wang C, 2019, OCEANS-IEEE, DOI 10.1109/oceanse.2019.8867236
   Wang YY, 2020, IEEE T VEH TECHNOL, V69, P7895, DOI 10.1109/TVT.2020.2993715
   Xue XB, 2015, PHOTONICS RES, V3, P275, DOI 10.1364/PRJ.3.000275
   Yang C, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11062868
   Yang QQ, 2015, IEEE SIGNAL PROC LET, V22, P1429, DOI 10.1109/LSP.2015.2409203
   Yang XC, 2018, COMPUT-AIDED CIV INF, V33, P1090, DOI 10.1111/mice.12412
   Yeum CM, 2015, COMPUT-AIDED CIV INF, V30, P759, DOI 10.1111/mice.12141
   Zhang DJ, 2017, IMAGE VISION COMPUT, V57, P130, DOI 10.1016/j.imavis.2016.11.018
   Zhaojie Huang, 2019, 2019 3rd International Conference on Robotics and Automation Sciences (ICRAS). Proceedings, P137, DOI 10.1109/ICRAS.2019.8809014
NR 47
TC 10
Z9 10
U1 24
U2 86
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 20899
EP 20923
DI 10.1007/s11042-022-14168-1
EA NOV 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000883287200002
DA 2024-07-18
ER

PT J
AU Xie, HW
   Gao, YJ
   Zhang, H
AF Xie, Hong-wei
   Gao, Ya-jun
   Zhang, Hao
TI An image encryption algorithm based on novel block scrambling scheme and
   Josephus sequence generator
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Josephus; Block scrambling; Bit-level; Vector operation; Image
   encryption
ID QUALITY ASSESSMENT; CHAOS
AB This paper proposes a new image encryption algorithm using novel block-level scrambling scheme and bit-level filer diffusion technology. In order to increase the diversity of pseudo-random number generator (PRNG) and improve the security of encryption system, a new Josephus travel scheme is proposed in this paper. Then, based on the novel Josephus travel method, a novel block-level scrambling scheme and bit-vector diffusion operation are proposed to improve the encryption efficiency of the algorithm. Numerical simulation and comparison experiments shows that the proposed encryption algorithm has high security and faster encryption speed, and can resist various attacks.
C1 [Xie, Hong-wei; Gao, Ya-jun] Taiyuan Univ Technol, Coll Software, Jinzhong 030600, Peoples R China.
   [Zhang, Hao] Taiyuan Univ Technol, Coll Informat & Comp, Jinzhong 030600, Peoples R China.
C3 Taiyuan University of Technology; Taiyuan University of Technology
RP Zhang, H (corresponding author), Taiyuan Univ Technol, Coll Informat & Comp, Jinzhong 030600, Peoples R China.
EM zhangh545@126.com
FU National Natural Science Foundation of China [61702356]; National
   Natural Science Foundation of Shanxi Province [20210302124050]
FX This research is supported by the National Natural Science Foundation of
   China (Nos: 61702356), National Natural Science Foundation of Shanxi
   Province (Nos: 20210302124050).
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Arab A, 2019, J SUPERCOMPUT, V75, P6663, DOI 10.1007/s11227-019-02878-7
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chen C, 2020, SIGNAL PROCESS, V168, DOI 10.1016/j.sigpro.2019.107340
   Chen L, 2020, NONLINEAR DYNAM, V100, P3959, DOI 10.1007/s11071-020-05735-y
   Fan CL, 2021, PHYS SCRIPTA, V96, DOI 10.1088/1402-4896/abcb2c
   Fan CL, 2021, NONLINEAR DYNAM, V103, P1081, DOI 10.1007/s11071-020-06160-x
   Fan CL, 2019, COMPLEXITY, DOI 10.1155/2019/3510985
   Gao XY, 2022, NONLINEAR DYNAM, V108, P613, DOI 10.1007/s11071-021-07192-7
   Gu K, 2017, IEEE T IMAGE PROCESS, V26, P4005, DOI 10.1109/TIP.2017.2711279
   Gu K, 2017, IEEE T IND ELECTRON, V64, P3903, DOI 10.1109/TIE.2017.2652339
   Gu K, 2017, IEEE T CYBERNETICS, V47, P4559, DOI 10.1109/TCYB.2016.2575544
   Gu K, 2016, IEEE T MULTIMEDIA, V18, P1098, DOI 10.1109/TMM.2016.2547343
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Guan ZX, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24030384
   Hu GZ, 2021, SIGNAL PROCESS, V178, DOI 10.1016/j.sigpro.2020.107790
   Hua ZY, 2019, IEEE ACCESS, V7, P8660, DOI 10.1109/ACCESS.2018.2890116
   Hua ZY, 2017, INFORM SCIENCES, V396, P97, DOI 10.1016/j.ins.2017.02.036
   Krishnan KS, 2022, INTELL AUTOM SOFT CO, V33, P1081, DOI 10.32604/iasc.2022.024023
   Li HF, 2021, IEEE T NEUR NET LEAR, V32, P1460, DOI 10.1109/TNNLS.2020.2984770
   Li Q, 2021, INFORM SCIENCES, V553, P19, DOI 10.1016/j.ins.2020.12.002
   Li TY, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23050510
   Li T, 2020, IEEE ACCESS, V8, P13792, DOI 10.1109/ACCESS.2020.2966264
   Lydia EL, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3771
   Naz F, 2020, MULTIMED TOOLS APPL, V79, P22107, DOI 10.1007/s11042-020-08897-4
   Nepomuceno EG, 2019, CHAOS, V29, DOI 10.1063/1.5099261
   Nestor T, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14020424
   Pour NR, 2022, MULTIMED TOOLS APPL, V81, P29653, DOI 10.1007/s11042-022-12779-2
   Song W, 2022, SIGNAL PROCESS-IMAGE, V102, DOI 10.1016/j.image.2021.116628
   Wang C, 2022, SIGNAL PROCESS, V196, DOI 10.1016/j.sigpro.2022.108536
   Wang MX, 2021, INFORM SCIENCES, V544, P1, DOI 10.1016/j.ins.2020.07.051
   Wang SC, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2019.105995
   Wang T, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106355
   Wang XY, 2020, OPT LASER TECHNOL, V122, DOI 10.1016/j.optlastec.2019.105854
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu YF, 2021, SIGNAL PROCESS, V181, DOI 10.1016/j.sigpro.2020.107911
   Xu QY, 2020, PHYS SCRIPTA, V95, DOI 10.1088/1402-4896/ab52bc
   Yang C, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24020273
   Ye Guodong, 2022, Alexandria Engineering Journal, V61, P6785, DOI 10.1016/j.aej.2021.12.023
   Yu F, 2021, INFORM SCIENCES, V554, P145, DOI 10.1016/j.ins.2020.12.037
   Yu ZC, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02818-x
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang Y, 2021, INFORM SCIENCES, V547, P307, DOI 10.1016/j.ins.2020.07.058
   Zhang Y, 2016, IETE TECH REV, V33, P310, DOI 10.1080/02564602.2015.1087350
   Zhou S, 2022, MULTIMEDIA SYST, V28, P95, DOI 10.1007/s00530-021-00803-8
   Zhu EQ, 2022, NANOMATERIALS-BASEL, V12, DOI 10.3390/nano12050877
NR 46
TC 3
Z9 3
U1 6
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16431
EP 16453
DI 10.1007/s11042-022-14139-6
EA NOV 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000882352400004
DA 2024-07-18
ER

PT J
AU Hussain, S
   Shah, T
   Javeed, A
AF Hussain, Sadam
   Shah, Tariq
   Javeed, Adnan
TI Modified advanced encryption standard (MAES) based on non-associative
   inverse property loop
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Advanced encryption standard; Non-associative structure; Image privacy;
   Inverse property loop; Encryption analyses
ID SUBSTITUTION BOX; CONSTRUCTION; SYSTEM
AB In this paper, a cryptographic encryption standard is proposed whose model is same as presented in Rijndael Algorithm by Joan Daemen and Vincent Rijmen. The modification lies in the design of the Cipher, we have used inverse property (IP) loop instead of Extended Binary Galois Field (GF). The proposed mathematical structure is superior to GF in terms of complexity and has the ability to create arbitrary randomness due to a larger key space. Moreover, IP loop are non-isomorphic and have more than one Cayley table representation as compared to GF. This in result confirms the resistance against cryptanalytic attacks specifically on mathematical structures. The complete description of S-box, encryption and decryption of this cryptographic scheme is measured and evaluated critically to substantiate its multimedia applications.
C1 [Hussain, Sadam; Shah, Tariq; Javeed, Adnan] Quaid I Azam Univ, Dept Math, Islamabad, Pakistan.
   [Javeed, Adnan] Govt Associate Coll Daultala, Rawalpindi, Pakistan.
C3 Quaid I Azam University
RP Javeed, A (corresponding author), Quaid I Azam Univ, Dept Math, Islamabad, Pakistan.; Javeed, A (corresponding author), Govt Associate Coll Daultala, Rawalpindi, Pakistan.
EM ajaveed@math.qau.edu.pk
CR Alghafis A, 2020, INT J THEOR PHYS, V59, P1227, DOI 10.1007/s10773-020-04402-7
   Ali A., 2008, QUASIGROUPS RELATED, V16, P13
   Alligood KT., 1996, Chaos: An Introduction to Dynamical Systems, DOI [10.1007/b97589, DOI 10.1007/B97589]
   [Anonymous], 2018, J KING SAUD U COMPUT
   Asif M, 2019, J INTELL FUZZY SYST, V37, P3925, DOI 10.3233/JIFS-190137
   Attaullah, 2019, MULTIMED TOOLS APPL, V78, P31467, DOI 10.1007/s11042-019-07981-8
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Cui L., 2007, INT J INNOV COMPUT I, VI 3, P45
   Daemen J, 2020, The design of rijndael: the advanced encryption standard (AES), V2nd, DOI DOI 10.1007/978-3-662-60769-53
   De Canniere C, 2005, ENCY CRYPTOGRAPHY SE, DOI [10.1007/0-387-23483-7_437, DOI 10.1007/0-387-23483-7_437]
   Hussain I, 2011, WORLD APPL SCI J, V13, P2389
   Hussain I, 2012, Z NATURFORSCH A, V67, P282, DOI 10.5560/ZNA.2012-0022
   Hussain S, 2020, IEEE ACCESS, V8, P123492, DOI 10.1109/ACCESS.2020.3005087
   Jahangir S, 2020, MULTIMED TOOLS APPL, V79, P26885, DOI 10.1007/s11042-020-08995-3
   Jamal SS, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0125-z
   Javeed A, 2020, MULTIMED TOOLS APPL, V79, P32487, DOI 10.1007/s11042-020-09582-2
   Javeed A, 2020, CHINESE J PHYS, V66, P645, DOI 10.1016/j.cjph.2020.04.008
   Javeed A, 2020, WIRELESS PERS COMMUN, V112, P467, DOI 10.1007/s11277-020-07052-4
   Javeed A, 2020, MULTIMED TOOLS APPL, V79, P6649, DOI 10.1007/s11042-019-08393-4
   Kaur M, 2021, IEEE T GREEN COMMUN, V5, P1223, DOI 10.1109/TGCN.2021.3081616
   Khan M, 2018, NEURAL COMPUT APPL, V29, P993, DOI 10.1007/s00521-016-2511-5
   Khan M, 2014, NEURAL COMPUT APPL, V25, P1717, DOI 10.1007/s00521-014-1663-4
   Kocarev L., 2001, IEEE CIRC SYST MAG, V1, P6, DOI DOI 10.1109/7384.963463
   Lambic D, 2020, NONLINEAR DYNAM, V100, P699, DOI 10.1007/s11071-020-05503-y
   Li X, 2016, OPTIK, V127, P2558, DOI 10.1016/j.ijleo.2015.11.221
   Liu H, 2020, CRYPTANALYSIS CONSTR, V376
   Meshram C, 2018, SECUR PRIVACY, V1, DOI 10.1002/spy2.12
   Naseer Y, 2020, MATH COMPUT SIMULAT, V178, P207, DOI 10.1016/j.matcom.2020.06.007
   Naseer Y, 2019, WIRELESS PERS COMMUN, V108, P1379, DOI 10.1007/s11277-019-06474-z
   Naseer Y, 2019, MICROPROCESS MICROSY, V65, P1, DOI 10.1016/j.micpro.2018.12.003
   Pelzl J., 2010, Understanding Cryptography: A Textbook for Students and Practitioners, DOI DOI 10.1007/978-3-642-04101-3
   SCHNEIER B, 1994, DR DOBBS J, V19, P38
   Shah T, 2020, WIRELESS PERS COMMUN, V113, P1201, DOI 10.1007/s11277-020-07274-6
   Shah T, 2013, Z NATURFORSCH A, V68, P567, DOI 10.5560/ZNA.2013-0021
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Si YY, 2021, INT J BIFURCAT CHAOS, V31, DOI 10.1142/S0218127421501467
   Ullah A, 2018, NONLINEAR DYNAM, V91, P359, DOI 10.1007/s11071-017-3874-6
   Ullah A, 2017, NONLINEAR DYNAM, V88, P2757, DOI 10.1007/s11071-017-3409-1
   Ye Tian, 2017, Mathematical Problems in Engineering, V2017, DOI 10.1155/2017/6969312
NR 39
TC 3
Z9 3
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16237
EP 16256
DI 10.1007/s11042-022-14064-8
EA NOV 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000877999600002
DA 2024-07-18
ER

PT J
AU Marik, A
   Chattopadhyay, S
   Singh, PK
AF Marik, Aritra
   Chattopadhyay, Soumitri
   Singh, Pawan Kumar
TI A hybrid deep feature selection framework for emotion recognition from
   human speeches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech emotion recognition; Deep learning; Feature selection; Fuzzy
   entropy & similarity measures; Whale optimization algorithm
ID ALGORITHMS
AB Speech Emotion Recognition (SER) is an active area of signal processing research that aims at identifying emotional states from audio speech signals. Applications of SER range from psychological diagnosis to human-computer interaction and as such, a robust framework is needed for accurate classification. To this end, we propose a two-stage hybrid deep feature selection (HDFS) framework that combines deep learning with automated feature engineering for emotion recognition from human speeches, which shines both in terms of accuracy and computational efficiency. Our pipeline extracts self-learned features using a customized Wide-ResNet-50-2 deep learning model from mel-pectrograms of raw audio signals, whose dimensionality is reduced using a hybrid deep feature selection algorithm that comprises a fuzzy entropy and similarity-based feature ranking method, followed by Whale optimization algorithm, which is a popular meta-heuristic optimization algorithm in literature. A k-nearest neighbor classifier is used to classify the optimized feature subset into the respective emotion classes. The proposed pipeline is evaluated on three publicly available SER datasets using a 5-fold cross-validation scheme, where it is found to outperform several state-of-the-art existing works in literature by significant margins thus, justifying the superiority and reliability of the proposed research. The source codes of the proposed method can be found at: .
C1 [Marik, Aritra; Chattopadhyay, Soumitri; Singh, Pawan Kumar] Jadavpur Univ, Dept Informat Technol, Jadavpur Univ Second Campus,Plot 8,LB Block, Kolkata 700106, W Bengal, India.
C3 Jadavpur University
RP Singh, PK (corresponding author), Jadavpur Univ, Dept Informat Technol, Jadavpur Univ Second Campus,Plot 8,LB Block, Kolkata 700106, W Bengal, India.
EM aritramarik2002@gmail.com; soumitri.chattopadhyay@gmail.com;
   pawansingh.ju@gmail.com
OI Chattopadhyay, Soumitri/0000-0002-2647-6053; Marik,
   Aritra/0000-0002-2100-9261
CR Abbaschian BJ, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041249
   Abualigah L, 2021, COMPUT METHOD APPL M, V376, DOI 10.1016/j.cma.2020.113609
   Agrawal P, 2021, IEEE ACCESS, V9, P26766, DOI 10.1109/ACCESS.2021.3056407
   Ahmed S, 2021, NEURAL COMPUT APPL, V33, P6467, DOI 10.1007/s00521-020-05409-1
   Akçay MB, 2020, SPEECH COMMUN, V116, P56, DOI 10.1016/j.specom.2019.12.001
   Albornoz EM, 2011, COMPUT SPEECH LANG, V25, P556, DOI 10.1016/j.csl.2010.10.001
   Alghowinem S, 2013, INT CONF ACOUST SPEE, P8022, DOI 10.1109/ICASSP.2013.6639227
   ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   Ancilin J, 2021, APPL ACOUST, V179, DOI 10.1016/j.apacoust.2021.108046
   Nguyen BH, 2020, SWARM EVOL COMPUT, V54, DOI 10.1016/j.swevo.2020.100663
   Bhavan A, 2019, KNOWL-BASED SYST, V184, DOI 10.1016/j.knosys.2019.104886
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   Chattopadhyay S, 2022, INT J INTELL SYST, V37, P3777, DOI 10.1002/int.22703
   Daneshfar F, 2020, MULTIMED TOOLS APPL, V79, P1261, DOI 10.1007/s11042-019-08222-8
   Danisman T, 2008, LECT NOTES ARTIF INT, V5078, P205, DOI 10.1007/978-3-540-69369-7_23
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dey A, 2020, IEEE ACCESS, V8, P200953, DOI 10.1109/ACCESS.2020.3035531
   Farooq M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20216008
   Fragopanagos N, 2005, NEURAL NETWORKS, V18, P389, DOI 10.1016/j.neunet.2005.03.006
   Ghosh KK, 2020, IEEE ACCESS, V8, P83548, DOI 10.1109/ACCESS.2020.2991543
   Ghosh S, 2022, SOFT COMPUT, V26, P891, DOI 10.1007/s00500-021-06260-9
   Guha R, 2021, NEURAL COMPUT APPL, V33, P5267, DOI 10.1007/s00521-020-05297-5
   Guha R, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106341
   Hajarolasvadi N, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21050479
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ibrahim H, 2021, IEEE ACCESS, V9, P122855, DOI 10.1109/ACCESS.2021.3107858
   Kanwal S, 2021, IEEE ACCESS, V9, P125830, DOI 10.1109/ACCESS.2021.3111659
   Khalil RA, 2019, IEEE ACCESS, V7, P117327, DOI 10.1109/ACCESS.2019.2936124
   Kononenko I., 1994, EUR C MACH LEARN, V94, P171, DOI DOI 10.1007/3-540-57868-4_57
   Latif S, 2019, INT CONF AFFECT, DOI [10.1109/acii.2019.8925513, 10.1109/ACII.2019.8925513]
   Latif S, 2018, INT CONF FRONT INFO, P88, DOI 10.1109/FIT.2018.00023
   Liu ZT, 2018, NEUROCOMPUTING, V309, P145, DOI 10.1016/j.neucom.2018.05.005
   Liu ZT, 2018, NEUROCOMPUTING, V273, P271, DOI 10.1016/j.neucom.2017.07.050
   Livi S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193508
   Luukka P, 2001, 10TH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3, P195, DOI 10.1109/FUZZ.2001.1007281
   Luukka P, 2011, EXPERT SYST APPL, V38, P4600, DOI 10.1016/j.eswa.2010.09.133
   Machado PPP, 1999, J CLIN PSYCHOL, V55, P39, DOI 10.1002/(SICI)1097-4679(199901)55:1<39::AID-JCLP4>3.3.CO;2-M
   Mafarja M, 2020, COGN COMPUT, V12, P150, DOI 10.1007/s12559-019-09668-6
   Mafarja MM, 2017, NEUROCOMPUTING, V260, P302, DOI 10.1016/j.neucom.2017.04.053
   Maldonado S, 2018, APPL SOFT COMPUT, V67, P94, DOI 10.1016/j.asoc.2018.02.051
   Mansouri-Benssassi E., 2019, IEEE IJCNN, P1, DOI [DOI 10.1109/IJCNN.2019.8852473, DOI 10.1109/ijcnn.2019.8852473]
   Mao QR, 2014, IEEE T MULTIMEDIA, V16, P2203, DOI 10.1109/TMM.2014.2360798
   Meftah IT, 2012, PROCEEDINGS OF 2012 INTERNATIONAL CONFERENCE ON COMPLEX SYSTEMS (ICCS12), P252
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2016, KNOWL-BASED SYST, V96, P120, DOI 10.1016/j.knosys.2015.12.022
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mirsamadi S, 2017, INT CONF ACOUST SPEE, P2227, DOI 10.1109/ICASSP.2017.7952552
   Mustaqeem, 2021, APPL SOFT COMPUT, V102, DOI 10.1016/j.asoc.2021.107101
   Ooi CS, 2014, EXPERT SYST APPL, V41, P5858, DOI 10.1016/j.eswa.2014.03.026
   Paszke A, 2019, ADV NEUR IN, V32
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   POLI R, 2007, SWARM INTELL-US, V1, P33, DOI [DOI 10.1007/S11721-007-0002-0, DOI 10.1109/ICNN.1995.488968]
   Ramakrishnan S, 2013, TELECOMMUN SYST, V52, P1467, DOI 10.1007/s11235-011-9624-z
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Sarkar SS, 2021, INTEGR MATER MANUF I, V10, P1, DOI 10.1007/s40192-020-00197-x
   Schipor OA, 2011, 2011 6TH CONFERENCE ON SPEECH TECHNOLOGY AND HUMAN-COMPUTER DIALOGUE (SPED)
   Sen S, 2021, APPL INTELL, V51, P8985, DOI 10.1007/s10489-021-02292-8
   Sheikh KH, 2020, IEEE ACCESS, V8, P158125, DOI 10.1109/ACCESS.2020.3019809
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song P, 2020, IEEE T AFFECT COMPUT, V11, P373, DOI 10.1109/TAFFC.2018.2800046
   Sutskever I., 2013, INT C MACHINE LEARNI, P1139
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Tuncer T, 2021, KNOWL-BASED SYST, V211, DOI 10.1016/j.knosys.2020.106547
   Yang XS, 2009, WOR CONG NAT BIOL, P210, DOI 10.1109/nabic.2009.5393690
   Yildirim S, 2021, APPL ACOUST, V173, DOI 10.1016/j.apacoust.2020.107721
   Zagoruyko S., 2016, ARXIV
   Zehra W, 2021, COMPLEX INTELL SYST, V7, P1845, DOI 10.1007/s40747-020-00250-4
   Zhang H, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2781, DOI 10.1109/ICASSP.2018.8462413
   Zhang R, 2019, INFORM FUSION, V50, P158, DOI 10.1016/j.inffus.2018.11.019
NR 70
TC 2
Z9 2
U1 4
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11461
EP 11487
DI 10.1007/s11042-022-14052-y
EA OCT 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000874426100002
DA 2024-07-18
ER

PT J
AU Arkin, E
   Yadikar, N
   Xu, XB
   Aysa, A
   Ubul, K
AF Arkin, Ershat
   Yadikar, Nurbiya
   Xu, Xuebin
   Aysa, Alimjan
   Ubul, Kurban
TI A survey: object detection methods from CNN to transformer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Object detection; Real-time system; CNN; Transformer
ID NETWORKS
AB Object detection is the most important problem in computer vision tasks. After AlexNet proposed, based on Convolutional Neural Network (CNN) methods have become mainstream in the computer vision field, many researches on neural networks and different transformations of algorithm structures have appeared. In order to achieve fast and accurate detection effects, it is necessary to jump out of the existing CNN framework and has great challenges. Transformer's relatively mature theoretical support and technological development in the field of Natural Language Processing have brought it into the researcher's sight, and it has been proved that Transformer's method can be used for computer vision tasks, and proved that it exceeds the existing CNN method in some tasks. In order to enable more researchers to better understand the development process of object detection methods, existing methods, different frameworks, challenging problems and development trends, paper introduced historical classic methods of object detection used CNN, discusses the highlights, advantages and disadvantages of these algorithms. By consulting a large amount of paper, the paper compared different CNN detection methods and Transformer detection methods. Vertically under fair conditions, 13 different detection methods that have a broad impact on the field and are the most mainstream and promising are selected for comparison. The comparative data gives us confidence in the development of Transformer and the convergence between different methods. It also presents the recent innovative approaches to using Transformer in computer vision tasks. In the end, the challenges, opportunities and future prospects of this field are summarized.
C1 [Arkin, Ershat; Yadikar, Nurbiya; Xu, Xuebin; Ubul, Kurban] Xinjiang Univ, Coll Informat Sci & Engn, Urumqi 830046, Peoples R China.
   [Aysa, Alimjan; Ubul, Kurban] Xinjiang Univ, Key Lab Multilingual Informat Technol, Urumqi 830046, Peoples R China.
C3 Xinjiang University; Xinjiang University
RP Ubul, K (corresponding author), Xinjiang Univ, Coll Informat Sci & Engn, Urumqi 830046, Peoples R China.; Ubul, K (corresponding author), Xinjiang Univ, Key Lab Multilingual Informat Technol, Urumqi 830046, Peoples R China.
EM kurbanu@xju.edu.cn
OI Ubul, Kurban/0000-0002-7566-6494
FU National Key Research and Development Program of China [2021YFB2802100];
   National Science Foundation of China [61862061, 62061045]
FX This work was supported by National Key Research and Development Program
   of China (No.2021YFB2802100) and National Science Foundation of China
   under Grant (61862061, 62061045).
CR Arkin Ershat, 2021, 2021 IEEE 2nd International Conference on Pattern Recognition and Machine Learning (PRML), P99, DOI 10.1109/PRML52754.2021.9520732
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Brock A, 2018, 7 INT C LEARN REPR I, DOI 10.48550/arXiv.1809.11096
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Carion Nicolas, 2020, EUR C COMP VIS ECCV, DOI DOI 10.1007/978-3-030-58452-8_13
   Chen C, 2020, IEEE COMPUT SOC CONF, P2997, DOI 10.1109/CVPRW50498.2020.00358
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   Chen M, 2020, PR MACH LEARN RES, V119
   Cheng B, 2021, ADV NEUR IN, V34
   Chu X., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2102.10882
   Chu XX, 2021, ADV NEUR IN
   Cordonnier J-B, 2020, ICLR 2020, DOI [10.48550/arXiv.1911.03584, DOI 10.48550/ARXIV.1911.03584]
   Dai J., 2021, ICLR
   Dai JF, 2016, ADV NEUR IN, V29
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong X, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.0065
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fang Y.X., 2021, ADV NEURAL INF PROCE, DOI DOI 10.48550/ARXIV.2106.00666
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Ge Z., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.08430
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Han K, 2021, ADV NEUR IN
   Hassani A., 2022, ARXIV
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hong MB, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3103069
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Jiang Y., 2021, NEURIPS, P14745
   Kang K, 2018, IEEE T CIRC SYST VID, V28, P2896, DOI 10.1109/TCSVT.2017.2736553
   Karlinsky L, 2019, PROC CVPR IEEE, P5192, DOI 10.1109/CVPR.2019.00534
   Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Li Y, 2018, ARXIV, DOI DOI 10.48550/ARXIV.1807.11013
   Li YH, 2019, IEEE I CONF COMP VIS, P6053, DOI 10.1109/ICCV.2019.00615
   Liang T, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.00420
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu SK, 2019, PROC CVPR IEEE, P1871, DOI 10.1109/CVPR.2019.00197
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Liu Zhuang, 2022, P IEEECVF C COMPUTER, P11976, DOI [DOI 10.48550/ARXIV.2201.03545, 10.1109/CVPR52688.2022.01167, DOI 10.1109/CVPR52688.2022.01167]
   Liu ZL, 2020, AAAI CONF ARTIF INTE, V34, P11685
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Ma WC, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107149
   Mehta S., 2022, INT C LEARN REPR, DOI [10.48550/arXiv.2110.02178, DOI 10.48550/ARXIV.2110.02178]
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Peng ZL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P357, DOI 10.1109/ICCV48922.2021.00042
   Qiao SY, 2021, PROC CVPR IEEE, P10208, DOI 10.1109/CVPR46437.2021.01008
   Qin Z, 2019, IEEE I CONF COMP VIS, P6717, DOI 10.1109/ICCV.2019.00682
   Qiu HQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3175, DOI 10.1109/ICCV48922.2021.00318
   Rahman S, 2020, INT J COMPUT VISION, V128, P2979, DOI 10.1007/s11263-020-01355-6
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shen ZQ, 2017, IEEE I CONF COMP VIS, P1937, DOI 10.1109/ICCV.2017.212
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh S, 2021, MULTIMED TOOLS APPL, V80, P19753, DOI 10.1007/s11042-021-10711-8
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vaswani A, 2017, ADV NEUR IN, V30
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Vulli A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22082988
   Wan F, 2019, PROC CVPR IEEE, P2194, DOI 10.1109/CVPR.2019.00230
   Wang RJ, 2018, ADV NEUR IN, V31
   Wang WH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P548, DOI 10.1109/ICCV48922.2021.00061
   Wang Y, ADV NEURAL INF PROCE, V34, DOI [10.48550/arXiv.2105.15075, DOI 10.48550/ARXIV.2105.15075]
   Xie EZ, 2021, ADV NEUR IN, V34
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xiong YY, 2021, PROC CVPR IEEE, P3824, DOI 10.1109/CVPR46437.2021.00382
   Yang J, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.00641
   Yin TW, 2021, PROC CVPR IEEE, P11779, DOI 10.1109/CVPR46437.2021.01161
   Yuhang Cao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11580, DOI 10.1109/CVPR42600.2020.01160
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhou P, 2018, PROC CVPR IEEE, P528, DOI 10.1109/CVPR.2018.00062
   Zhou X., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2103.07461
NR 95
TC 24
Z9 24
U1 20
U2 77
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21353
EP 21383
DI 10.1007/s11042-022-13801-3
EA OCT 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000870957300003
OA hybrid
DA 2024-07-18
ER

PT J
AU Khan, SH
   Khan, A
   Lee, YS
   Hassan, M
   Jeong, WK
AF Khan, Saddam Hussain
   Khan, Asifullah
   Lee, Yeon Soo
   Hassan, Mehdi
   Jeong, Woong Kyo
TI Segmentation of shoulder muscle MRI using a new Region and Edge based
   Deep Auto-Encoder
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MRI; Shoulder muscle; Deep Auto-Encoder; Segmentation; Transfer
   learning; CNN
ID SUPRASPINATUS; SHAPE
AB Automatic segmentation of shoulder muscle MRI is challenging due to the high variation in muscle size, shape, texture, and spatial position of tears. Manual segmentation of tear and muscle portion is hard, time-consuming, and subjective to pathological expertise. This work proposes a new Region and Edge-based Deep Auto-Encoder (RE-DAE) for shoulder muscle MRI segmentation. The proposed RE-DAE harmoniously employs average and max-pooling operations in the Convolutional encoder and decoder blocks. The DAE's region and edge-based segmentation encourage the network to extract homogenous and anatomical information, respectively. These two concepts, systematically combined in a DAE, generate a discriminative and sparse hybrid feature space (exploiting both region homogeneity and boundaries). Moreover, the concept of static attention is exploited in the proposed RE-DAE that helps effectively learn the tear region. The performances of the proposed RE-DAE architectures have been tested using a 3D MRI shoulder muscle dataset using the hold-out cross-validation technique. The MRI data has been collected from the Korea University Anam Hospital, Seoul, South Korea. Experimental comparisons have been conducted by employing innovative custom-made and existing pre-trained CNN architectures using transfer learning and fine-tuning. Objective evaluation on the muscle datasets using the proposed SA-RE-DAE showed a dice similarity of 85.58% and 87.07%, an accuracy of 81.57% and 95.58% for tear and muscle regions, respectively. The high visual quality and the objective result suggest that the proposed SA-RE-DAE can correctly segment tear and muscle regions in shoulder muscle MRI for better clinical decisions.
C1 [Khan, Saddam Hussain; Khan, Asifullah] Pakistan Inst Engn & Appl Sci, Dept Comp & Informat Sci, Pattern Recognit Lab, Islamabad 45650, Pakistan.
   [Khan, Saddam Hussain] Univ Engn & Appl Sci UEAS, Dept Comp Syst Engn, Swat 19060, Pakistan.
   [Khan, Saddam Hussain; Khan, Asifullah] Pakistan Inst Engn & Appl Sci, PIEAS Artificial Intelligence Ctr PAIC, Islamabad 45650, Pakistan.
   [Khan, Asifullah] Pakistan Inst Engn & Appl Sci, Ctr Math Sci, Islamabad 45650, Pakistan.
   [Lee, Yeon Soo] Catholic Univ Daegu, Coll Med Sci, Dept Biomed Engn, Daegu, South Korea.
   [Hassan, Mehdi] Air Univ, Dept Comp Sci, Islamabad, Pakistan.
   [Jeong, Woong Kyo] Korea Univ, Coll Med, Dept Orthopaed Surg, Seoul, South Korea.
C3 Pakistan Institute of Engineering & Applied Science; Pakistan Institute
   of Engineering & Applied Science; Pakistan Institute of Engineering &
   Applied Science; Catholic University of Daegu; Air University Islamabad;
   Korea University; Korea University Medicine (KU Medicine)
RP Khan, A (corresponding author), Pakistan Inst Engn & Appl Sci, Dept Comp & Informat Sci, Pattern Recognit Lab, Islamabad 45650, Pakistan.; Khan, A (corresponding author), Pakistan Inst Engn & Appl Sci, PIEAS Artificial Intelligence Ctr PAIC, Islamabad 45650, Pakistan.; Khan, A (corresponding author), Pakistan Inst Engn & Appl Sci, Ctr Math Sci, Islamabad 45650, Pakistan.
EM hengrshkhan822@gmail.com; asif@pieas.edu.pk; yeonsoolee@cu.ac.kr;
   mehdi.hassan5@gmail.com; drshoulder@korea.ac.kr
RI Khan, ASIFULLAH/H-9617-2015
OI Hassan, Mehdi/0000-0003-4629-2582
FU PIEAS IT endowment fund under the Pakistan Higher Education Commission
   (HEC); National Research Foundation of Korea [2017R1A2B2005065]
FX This work was conducted with the support of the PIEAS IT endowment fund
   under the Pakistan Higher Education Commission (HEC). This study was
   also supported by the research grant of National Research Foundation of
   Korea (2017R1A2B2005065).As well as, we thank Pattern Recognition Lab
   (PR-Lab) and Pakistan Institute of Engineering, and Applied Sciences
   (PIEAS), for providing necessary computational resources and a healthy
   research environment.
CR Ahmad P, 2021, MULTIMED TOOLS APPL, V80, P27069, DOI 10.1007/s11042-021-10915-y
   Ahmed U, 2019, ARXIV
   Alipour N, 2021, MULTIMED TOOLS APPL, V80, P8835, DOI 10.1007/s11042-020-10122-1
   Badrinarayanan V, 2015, UNDERSTANDING SYMMET
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Biltz NK, 2017, SKELET MUSCLE, V7, DOI 10.1186/s13395-016-0118-2
   Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0
   Chahal ES, 2022, MULTIMED TOOLS APPL, V81, P37333, DOI 10.1007/s11042-021-11334-9
   cicek Ozgtin, 2016, INT C MED IM COMP CO, P424, DOI DOI 10.1007/978-3-319-46723-8_49
   Conze PH, 2020, COMPUT MED IMAG GRAP, V83, DOI 10.1016/j.compmedimag.2020.101733
   DEPALMA AF, 1963, SURG CLIN N AM, V43, P1507
   Devi D, 2020, INT J DATA WAREHOUS, V16, P60, DOI 10.4018/IJDWM.2020070104
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Javed SG, 2016, MULTIMED TOOLS APPL, V75, P5887, DOI 10.1007/s11042-015-2554-0
   Jiang JW, 2017, BIOMED ENG ONLINE, V16, DOI 10.1186/s12938-017-0420-1
   Khagi B, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/3640705
   Khan A, SURVEY DEEP LEARNING
   Khan Saddam Hussain, 2020, NED University Journal of Research, V17, P35, DOI 10.35453/NEDJR-ASCN-2019-0016
   Khan SH, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12020267
   Khan SH, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104816
   Khan SH, 2021, PHOTODIAGN PHOTODYN, V35, DOI 10.1016/j.pdpdt.2021.102473
   Khan SH, 2020, CLASSIFICATION REGIO
   Kim JY, 2019, COMPUT METH PROG BIO, V182, DOI 10.1016/j.cmpb.2019.105063
   Kim SH, 2017, COMPUT METH PROG BIO, V140, P165, DOI 10.1016/j.cmpb.2016.12.008
   Kollias D, 2018, COMPLEX INTELL SYST, V4, P119, DOI 10.1007/s40747-017-0064-6
   Kumar GA, 2021, MULTIMED TOOLS APPL, V80, P19715, DOI 10.1007/s11042-020-08760-6
   Kumar P, 2018, ARXIV
   Lee H, 2017, J DIGIT IMAGING, V30, P487, DOI 10.1007/s10278-017-9988-z
   Li MW, 2021, NONLINEAR DYNAM, V103, P1167, DOI 10.1007/s11071-020-06111-6
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mandic M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-59267-x
   Pavel Misha, 2013, IEEE Rev Biomed Eng, V6, P156, DOI 10.1109/RBME.2012.2222636
   Pons C, 2017, CLIN BIOMECH, V48, P80, DOI 10.1016/j.clinbiomech.2017.07.010
   Qureshi AS, 2017, APPL SOFT COMPUT, V58, P742, DOI 10.1016/j.asoc.2017.05.031
   Qureshi AS, 2018, ARXIV
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schlemper J, 2019, MED IMAGE ANAL, V53, P197, DOI 10.1016/j.media.2019.01.012
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh L.K, 2021, Multidisciplinary Functions of Blockchain Technology in AI and IoT Applications, P137
   Slabaugh MA, 2012, AM J SPORT MED, V40, P1728, DOI 10.1177/0363546512452714
   Tian Y, 2013, MACH VISION APPL, V24, P47, DOI 10.1007/s00138-011-0363-7
   Trebeschi S, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-05728-9
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Ward AD, 2007, ACAD RADIOL, V14, P1229, DOI 10.1016/j.acra.2007.06.014
   Zafar MM, 2022, PHOTODIAGN PHOTODYN, V37, DOI 10.1016/j.pdpdt.2021.102676
   Zhang C, 2021, COMPUT BIOL MED, V133, DOI 10.1016/j.compbiomed.2021.104424
   Zhang ZC, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107297
NR 47
TC 8
Z9 8
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 14963
EP 14984
DI 10.1007/s11042-022-14061-x
EA OCT 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000869339100002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chakraborty, A
   Mukherjee, N
AF Chakraborty, Amartya
   Mukherjee, Nandini
TI A deep-CNN based low-cost, multi-modal sensing system for efficient
   walking activity identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal sensors; Human activity recognition; Sensor fusion; Deep CNN;
   Supervised learning; Walking activity
ID ACTIVITY RECOGNITION; FALL DETECTION; RECOMMENDATION SYSTEM;
   PATTERN-RECOGNITION; MOBILE; ALGORITHM; ACCURACY; NETWORK
AB The misclassification of human activity information by IoT-based smart, health monitoring devices raises concerns about their reliability. For instance, the identification of walking activity by wrist-worn, hand-held, or pocketed devices is often error-prone because tracking of actual leg movement is necessary for proper identification of a walk. In contrast, wearable systems on the waist recognize the bodily movement as a whole and not limb-specific movement. In this paper, we consider the novel problem of distinguishing the walking activity defined as a sequence of repeated leg-swing actions from repetitive leg-swing activities in sitting state. For this purpose, a heterogeneous sensor system is implemented that acquires novel multi-modal data from low-cost leg-worn IMU sensors (m-module) and finger-tip based pulse sensors (p-module). This dataset is then processed to extract features for a supervised learning framework. A 1-D Deep Convolutional Neural Network (DCNN) model is used for system performance evaluation, that prevents misclassification of walking activity with an average accuracy of 97% and maximum accuracy of 99%. With the fusion of features, the DCNN model performs with 2% more accuracy than the performance of the system using only IMU data. For performance comparison with the DCNN model, 4 other supervised learning algorithms have been used, namely Support Vector Machine (SVM), k-Nearest Neighbors (kNN), Decision Tree (DT), and Gaussian Naive Bayes (GNB). The proposed DCNN model outperforms these algorithms by using the m-module features individually and in unison with the p-module features. The performance is also comparable to the state-of-the-art works on intelligent walking activity detection.
C1 [Chakraborty, Amartya] Univ Engn & Management, Dept Comp Sci & Engn, Kolkata 700160, W Bengal, India.
   [Mukherjee, Nandini] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, W Bengal, India.
C3 Jadavpur University
RP Chakraborty, A (corresponding author), Univ Engn & Management, Dept Comp Sci & Engn, Kolkata 700160, W Bengal, India.
EM amartya3@gmail.com; nandini.mukhopadhyay@jadavpuruniversity.in
RI Mukherjee, Nandini/AGH-9345-2022; Chakraborty, Amartya/JSK-2277-2023
OI Mukherjee, Nandini/0000-0001-7228-8988; Chakraborty,
   Amartya/0000-0001-6789-5740
CR Ahmed N, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010317
   Albright RK, 2011, IEEE ENG MED BIO, P5625, DOI 10.1109/IEMBS.2011.6091361
   ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   Altun K, 2010, LECT NOTES COMPUT SC, V6219, P38, DOI 10.1007/978-3-642-14715-9_5
   Anguita Davide, 2012, INT WORKSH AMB ASS L, V2012, P216, DOI DOI 10.1007/978-3-642-35395-6_30
   Attal F, 2015, SENSORS-BASEL, V15, P31314, DOI 10.3390/s151229858
   Avci A., 2010, 23 INT C ARCH COMP S, P1
   Barshan B, 2014, COMPUT J, V57, P1649, DOI 10.1093/comjnl/bxt075
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhatti UA, 2018, HUM VACC IMMUNOTHER, V14, P165, DOI 10.1080/21645515.2017.1379639
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Bracewell R., 1965, FOURIER TRANSFORM IT, P40
   Bracewell Ronald Newbold, 1986, The Fourier transform and its applications, V31999
   Chakraborty A, 2022, BIG DATA INTELLIGENC, P117
   Chandra I, 2019, CLUSTER COMPUT, V22, P2517, DOI 10.1007/s10586-018-2329-2
   Chen MD, 2016, MED SCI SPORT EXER, V48, P1942, DOI 10.1249/MSS.0000000000000984
   Chetty G, 2015, PROCEDIA COMPUT SCI, V46, P1181, DOI 10.1016/j.procs.2015.01.031
   Cho Y., 2008, Proceedings of the 2nd International Workshop on Systems and Networking Support for Health Care and Assisted Living Environments - HealthNet '08, P1, DOI DOI 10.1145/1515747.1515757
   Chung WY, 2008, IEEE ENG MED BIO, P1529, DOI 10.1109/IEMBS.2008.4649460
   Cleland I, 2013, SENSORS-BASEL, V13, P9183, DOI 10.3390/s130709183
   COOLEY JW, 1965, MATH COMPUT, V19, P297, DOI 10.2307/2003354
   Department SR, 2020, SMART HOM STAT FACTS
   Dernbach S., 2012, Proceedings of the Eighth International Conference on Intelligent Environments (IE 2012), P214, DOI 10.1109/IE.2012.39
   Tran DN, 2016, P INT CONF INTELL, P64, DOI 10.1109/ISMS.2016.51
   Fan L, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCED CLOUD AND BIG DATA (CBD), P64, DOI 10.1109/CBD.2013.19
   Gunn S.R., 1998, Analyst, V14, P5, DOI DOI 10.1039/B918972F
   Hand DJ, 2001, INT STAT REV, V69, P385, DOI 10.1111/j.1751-5823.2001.tb00465.x
   Hardegger M, 2015, PERS UBIQUIT COMPUT, V19, P123, DOI 10.1007/s00779-014-0815-y
   He J, 2015, CHINA COMMUN, V12, P23, DOI 10.1109/CC.2015.7114066
   Hegde N, 2015, IEEE INT C BIOINFORM, P746, DOI 10.1109/BIBM.2015.7359779
   Hinton G. E., 2016, U.S. Patent, Patent No. [9,406,017, 9406017]
   Jatobá LC, 2008, IEEE ENG MED BIO, P5250, DOI 10.1109/IEMBS.2008.4650398
   Kang I, 2020, INT CONF UBIQ ROBOT, P421, DOI 10.1109/UR49135.2020.9144707
   Kantoch Eliasz., 2017, Computing in Cardiology, P1
   Klepeis NE, 2001, J EXPO ANAL ENV EPID, V11, P231, DOI 10.1038/sj.jea.7500165
   Kose M., 2012, WORKSHOP MOBILE SENS, V16, P11
   Kumar VS, 2019, LECT NOTES ELECTR EN, V493, P217, DOI 10.1007/978-981-10-8663-2_23
   Kumari P, 2017, BIOSENS BIOELECTRON, V90, P298, DOI 10.1016/j.bios.2016.12.001
   Lane ND, 2010, IEEE COMMUN MAG, V48, P140, DOI 10.1109/MCOM.2010.5560598
   Lane Nicholas D, 2011, P 5 INT ICST C PERV, P23, DOI DOI 10.4108/ICST.PERVASIVEHEALTH.2011.246161
   LaPier J, 2017, J ACUTE CARE PHYS TH, V8, P96, DOI 10.1097/JAT.0000000000000056
   Liang XY, 2017, IEEE INT CONF MOB, P338, DOI 10.1109/MASS.2017.81
   Marr B, 2020, 5 BIGGEST SMART HOME
   Mirri S, 2017, INT J HUM-COMPUT INT, V33, P1010, DOI 10.1080/10447318.2017.1321218
   Münzner S, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (ISWC 17), P158, DOI 10.1145/3123021.3123046
   Niswar Muhammad, 2013, 2013 International Conference on Information Technology and Electrical Engineering (ICITEE), P291, DOI 10.1109/ICITEED.2013.6676255
   Nweke HF, 2018, EXPERT SYST APPL, V105, P233, DOI 10.1016/j.eswa.2018.03.056
   Panwar M, 2017, IEEE ENG MED BIO, P2438, DOI 10.1109/EMBC.2017.8037349
   Park SM, 2013, J ELECTR ENG TECHNOL, V8, P376, DOI 10.5370/JEET.2013.8.2.376
   Pires IM, 2017, ARXIV
   Pires IM, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9030509
   Pirttikangas S, 2006, LECT NOTES COMPUT SC, V4239, P516
   Rosner DK, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P397, DOI 10.1145/2702123.2702467
   Sahu SN, 2020, REAL TIME DATA ANALY, V6, P37, DOI [10.1016/B978-0-12-818014-3.00002-4, DOI 10.1016/B978-0-12-818014-3.00002-4]
   Sano Akane, 2015, Int Conf Wearable Implant Body Sens Netw, V2015, DOI 10.1109/BSN.2015.7299420
   Sarin S, 2022, J INTELL FUZZY SYST, V42, P981, DOI 10.3233/JIFS-189765
   Saurav S, 2022, MULTIMED TOOLS APPL, V81, P14173, DOI 10.1007/s11042-022-12366-5
   Shoaib M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATION WORKSHOPS (PERCOM WORKSHOPS), P591, DOI 10.1109/PERCOMW.2015.7134104
   Skraba A, 2016, MEDD C EMBED COMPUT, P428, DOI 10.1109/MECO.2016.7525798
   statista, 2020, FOR WEAR UN SHIPM WO
   Tapia EM, 2007, ELEVENTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P37
   Valarmathy G, 2019, HUMAN FALL DETECTION
   Wibawa AD, 2016, PHYSL PATTERN HUMAN
   Wu YC, 2009, EIGHTH IEEE INTERNATIONAL CONFERENCE ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, PROCEEDINGS, P317, DOI 10.1109/DASC.2009.136
   Xu B, 2009, THESIS CITESEER
   Yacchirema D, 2018, PROCEDIA COMPUT SCI, V130, P603, DOI 10.1016/j.procs.2018.04.110
   Yang J, 2015, IEEE IJCNN
   Zeng M, 2014, 2014 6TH INTERNATIONAL CONFERENCE ON MOBILE COMPUTING, APPLICATIONS AND SERVICES (MOBICASE), P197, DOI 10.4108/icst.mobicase.2014.257786
   Zhang PY, 2017, IEEE SENS J, V17, P3613, DOI 10.1109/JSEN.2017.2692263
NR 69
TC 5
Z9 5
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16741
EP 16766
DI 10.1007/s11042-022-13990-x
EA OCT 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000865154500003
DA 2024-07-18
ER

PT J
AU Zou, H
   Wu, QF
   Zou, XL
AF Zou, Hua
   Wu, Qifeng
   Zou, Xiaolong
TI Research on optimization Design of Suspension Parameters of railway
   vehicle bogies based on surrogate model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Vehicle dynamics; Surrogate model; Multi-objective optimization
ID MULTIOBJECTIVE OPTIMIZATION; PARETO-OPTIMIZATION; SPEED; TRAIN
AB The suspension parameters of railway vehicle bogies have a significant impact on the dynamic performance. Its parameters are numerous, the model is complex, and there are different dynamic performance requirements under different working conditions. Establishing a fast optimization method suitable for suspension parameters under different operating conditions is the research goal of this article. For the optimal design of suspension parameters, a surrogate model is used to replace high-precision dynamic models to establish suspension parameter optimization functions based on weights for fast and accurate solution. First, based on the multi-body dynamics model of the railway vehicle, basic suspension parameters and performance index samples that can be simulated. The dynamics model is approximated using response surface model, Kriging model, and radial basis neural network model. According to the fitting accuracy of each model, the most effective fitting surrogate model is obtained; Then, the weight parameters of vehicle motion stability, running safety and ride stability under different working conditions are obtained by Analytic Hierarchy Process (AHP), and the optimization objective function of bogie suspension parameters is established. Finally, the NSCA-II algorithm is used to solve the optimization objective function, and the optimal suspension parameter combination under different working conditions is obtained. Taking a intercity EMU as an example, the calculation analysis based on the surrogate model shows that: using this method, the dynamic performance index of the original municipal vehicles under various working conditions have been optimized targetedly, which has remarkable effect; compared with the optimization based on the precise dynamic model, the optimization calculation time of this method is 1/30, and the efficiency of the optimization design is greatly improved.
C1 [Zou, Hua; Wu, Qifeng] Beijing Jiaotong Univ, Sch Mech Elect & Control Engn, Beijing 100044, Peoples R China.
   [Zou, Xiaolong] CRRC Qingdao Sifang CO LTD, Qingdao 266111, Shandong, Peoples R China.
C3 Beijing Jiaotong University; CRRC Corporation
RP Zou, H (corresponding author), Beijing Jiaotong Univ, Sch Mech Elect & Control Engn, Beijing 100044, Peoples R China.
EM hzoubjtu@126.com; wu.qf@foxmail.com; 18300277259@163.com
OI Zou, Hua/0000-0002-0886-0035
FU National Natural Science Foundation of China [11790281]
FX This work was supported by the National Natural Science Foundation of
   China (11790281).
CR Al-Subhi Al-Harbi K. M., 2001, International Journal of Project Management, V19, P19, DOI 10.1016/S0263-7863(99)00038-1
   [Anonymous], 2009, 518 UIC
   Ashtiani IH, 2017, INT J RAIL TRANSP, V5, P213, DOI 10.1080/23248378.2017.1336652
   Bideleh SMM, 2016, VEHICLE SYST DYN, V54, P1053, DOI 10.1080/00423114.2016.1180405
   Bideleh SMM, 2016, MULTIBODY SYST DYN, V37, P145, DOI 10.1007/s11044-015-9497-0
   Chen ML, 2020, 2020 3RD INTERNATIONAL CONFERENCE ON CONTROL AND ROBOTS (ICCR 2020), P164, DOI 10.1109/ICCR51572.2020.9344251
   Cheng YC, 2011, INT J ADV MECHATRO S, V3
   Cui DB, 2019, STRUCT MULTIDISCIP O, V59, P279, DOI 10.1007/s00158-018-2065-5
   Han X, 2019, ADV STRUCT ENG, V22, P2712, DOI 10.1177/1369433219849809
   He YP, 2005, MULTIBODY SYST DYN, V14, P111, DOI 10.1007/s11044-005-4310-0
   He YP, 2002, VEHICLE SYST DYN, V37, P397
   Jeong NT, 2017, J MECH SCI TECHNOL, V31, P2105, DOI 10.1007/s12206-017-0407-7
   Jiang P, 2020, SPR TRACTS MECH ENG, P1, DOI 10.1007/978-981-15-0731-1
   Jiang YZ, 2020, VEHICLE SYST DYN, V58, P74, DOI 10.1080/00423114.2019.1566557
   Johnsson A, 2012, VEHICLE SYST DYN, V50, P1379, DOI 10.1080/00423114.2012.659846
   Klimenko I., 2019, P INT C TRANSBALTICA, P531
   Knothe K., 2017, Rail vehicle dynamics, DOI [10.1007/978-3-319-45376-7, DOI 10.1007/978-3-319-45376-7]
   Mastinu GRM, 2001, P I MECH ENG C-J MEC, V215, P683, DOI 10.1243/0954406011524054
   Mazzola L., 2010, INT J RAILWAY, V3, P95
   Mousavi-Bideleh SM, 2016, VEHICLE SYST DYN, V54, P58, DOI 10.1080/00423114.2015.1114655
   Pandey M, 2020, INT J RAIL TRANSP, V8, P45, DOI 10.1080/23248378.2019.1593059
   Savoskin AN, 2018, P I MECH ENG F-J RAI, V232, P1549, DOI 10.1177/0954409717737879
   Taheri M, 2016, VEHICLE SYST DYN, V54, P653, DOI 10.1080/00423114.2016.1150497
   Xie H, 2016, ADV MECH ENG, V8, DOI 10.1177/1687814016669636
   Yang Y, 2016, P I MECH ENG F-J RAI, V230, P1890, DOI 10.1177/0954409715617213
   Yao Y, 2020, INT J RAIL TRANSP, V8, P195, DOI 10.1080/23248378.2019.1625824
   Ye YG, 2021, MULTIBODY SYST DYN, V51, P91, DOI 10.1007/s11044-020-09722-4
   Yu Yuewei, 2018, Journal of Mechanical Engineering, V54, P57, DOI 10.3901/JME.2018.08.057
   Zhang J, 2014, INT J ADV MANUF TECH, V73, P251, DOI 10.1007/s00170-014-5822-7
   Zhou JH, 2020, VEHICLE SYST DYN, V58, P357, DOI 10.1080/00423114.2019.1578384
NR 30
TC 5
Z9 5
U1 5
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 OCT 6
PY 2022
DI 10.1007/s11042-022-14022-4
EA OCT 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5C9RO
UT WOS:000864589600002
DA 2024-07-18
ER

PT J
AU Guedri, N
   Gharbi, R
AF Guedri, Naji
   Gharbi, Rached
TI Bulk material flow measurement based only on a smart camera fixed above
   a moving belt conveyor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-contact measurement; Computer vision; Image processing; Conveyor
   belt; Improve energy efficiency; Measure without negative health effect
AB Non-contact measurement of bulk materials is used to measure flow rates of conveying systems. The non-contacting, can facilitate the instant control of the bulk materials, increasing production efficiency and ameliorating energy consumption on a conveyor belt. In this work, we present the innovative measuring instrument-bringing benefit to manufacturing industries. It is a smart camera provides measuring results on the current flow rate and the total produced mass. It helps make the process more reliable, efficient and profitable because it can be installed directly under belt conveyor, doesn't contain any sensor in contact with the conveyor belt (E.g. speed sensors, integrating scales, etc.), maintenance is not required. In addition, it is without any negative impact on human health, because it is based on image processing to measure the flow and without using harmful radiation (laser triangulation, ultrasonic and Hall Effect). The actual results show this camera is identical by 99.927% to another flow sensor for measurement installed in the cement company.
C1 [Guedri, Naji; Gharbi, Rached] Univ Tunis, Lab Ingn Syst Ind & Energies Renouvelables LISIER, Ecole Natl Super Ingenieurs Tunis ENSIT, 5 Ave Taha Hussein, Tunis 1008, Tunisia.
C3 Universite de Tunis
RP Guedri, N; Gharbi, R (corresponding author), Univ Tunis, Lab Ingn Syst Ind & Energies Renouvelables LISIER, Ecole Natl Super Ingenieurs Tunis ENSIT, 5 Ave Taha Hussein, Tunis 1008, Tunisia.
EM naji.guedri.1@gmail.com; rached.gbarbi@ensit.rnuln
RI Gharbi, Rached/AAI-1822-2020
OI Guedri, naji/0000-0001-6622-0274; GHARBI, Rached/0000-0001-7833-3145
CR cancer, XRAYS GAMMA RAYS CAN
   Gao Y, 2019, IEEE ACCESS, V7, P121646, DOI 10.1109/ACCESS.2019.2937317
   Gao Y, 2019, MEASUREMENT, V139, P127, DOI 10.1016/j.measurement.2019.03.030
   Hiltermann J, 2011, PARTICUL SCI TECHNOL, V29, P14, DOI 10.1080/02726351.2010.491105
   Hu YH, 2016, IEEE T INSTRUM MEAS, V65, P1130, DOI 10.1109/TIM.2015.2490958
   Jones SA, 1957, METHOD APPARATUS CAL
   Kozlowski T, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10186259
   Lodewijks G., 2002, BULK SOLIDS HANDLING, V22, P124
   Matthew H, 1970, DEVICE MEASURING TAR
   Mhlongo IN, 2020, 2020 IEEE PES & IAS POWERAFRICA CONFERENCE, DOI 10.1109/powerafrica49420.2020.9219974
   nasa, REGIONS ELECTROMAGNE
   officiel-prevention, RISKS ULTRASOUND
   Ristic LB, 2012, 2012 15TH INTERNATIONAL POWER ELECTRONICS AND MOTION CONTROL CONFERENCE (EPE/PEMC)
   Sujaritha M, 2017, COMPUT ELECTRON AGR, V134, P160, DOI 10.1016/j.compag.2017.01.008
   Wang BJ, 2023, INT J COAL PREP UTIL, V43, P708, DOI 10.1080/19392699.2022.2072306
   Yang MJ, 2020, NEUROCOMPUTING, V397, P447, DOI 10.1016/j.neucom.2019.09.109
   Yingling JC, 1997, IEEE T IND APPL, V33, P90, DOI 10.1109/28.567083
   zasagencies, CONVEYOR BELT SCALE
   Zeng F., 2013, LOG TECH, V32, P411
   Zeng F, 2015, MEASUREMENT, V75, P230, DOI 10.1016/j.measurement.2015.05.041
   Zhang MC, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/8816388
   Zhang SR, 2011, APPL ENERG, V88, P3061, DOI 10.1016/j.apenergy.2011.03.015
   Zhang Z, 2016, ONLINE ANAL COAL ASH, DOI [10.1080/19392699.2016.1140650, DOI 10.1080/19392699.2016.1140650]
NR 23
TC 2
Z9 2
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 14077
EP 14090
DI 10.1007/s11042-022-13893-x
EA SEP 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000861190800004
DA 2024-07-18
ER

PT J
AU Mostafa, MM
   Feizollah, A
   Anuar, NB
AF Mostafa, Mohamed M.
   Feizollah, Ali
   Anuar, Nor Badrul
TI Fifteen years of YouTube scholarly research: knowledge structure,
   collaborative networks, and trending topics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE YouTube; Bibliometric analysis; Co -citation networks; Keyword co
   -occurrence networks
ID CO-WORD ANALYSIS; BIBLIOMETRIC ANALYSIS; DOCTORAL DISSERTATIONS;
   INFORMATION-SYSTEMS; RESEARCH THEMES; MANAGEMENT; DOMAIN; VISUALIZATION;
   EVOLUTION; ECONOMICS
AB Since its inception, YouTube has been a source of entertainment and education. Everyday millions of videos are uploaded to this platform. Researchers have been using YouTube as a source of information in their research. However, there is a lack of bibliometric reports on research carried out on this platform and the pattern in the published works. This study aims at providing a bibliometric analysis on YouTube as a source of information to fill this gap. Specifically, this paper analyzes 1781 articles collected from the Scopus database spanning fifteen years. The analysis revealed that 2006-2007 were initial stage in YouTube research followed by 2008 -2017 which is the decade of rapid growth in YouTube research. The 2017 -2021 is considered the stage of consolidation and stabilization of this research topic. We also discovered that most relevant papers were published in small number of journals such as New Media and Society, Convergence, Journal of Medical Internet Research, Computers in Human Behaviour and the Physics Teacher, which proves the Bradford's law. USA, Turkey, and UK are the countries with the highest number of publications. We also present network analysis between countries, sources, and authors. Analyzing the keywords resulted in finding the trend in research such as "video sharing" (2010-2018), "web -based learning" (2012-2014), and "COVID -19" (2020 onward). Finally, we used Multiple Correspondence Analysis (MCA) to find the conceptual clusters of research on YouTube. The first cluster is related to user -generated content. The second cluster is about health and medical issues, and the final cluster is on the topic of information quality.
C1 [Mostafa, Mohamed M.] Gulf Univ Sci & Technol, Mubarak Al Abdullah, West Mishref, Kuwait.
   [Feizollah, Ali; Anuar, Nor Badrul] Univ Malaya, Fac Comp Sci & Informat Technol, Dept Comp Syst & Technol, Kuala Lumpur 50603, Malaysia.
C3 Universiti Malaya
RP Mostafa, MM (corresponding author), Gulf Univ Sci & Technol, Mubarak Al Abdullah, West Mishref, Kuwait.
EM mostafa@usa.com
RI Feizollah, Ali/JMB-4153-2023; Anuar, Nor Badrul/B-3101-2010
OI Feizollah, Ali/0000-0003-2439-8482; Anuar, Nor
   Badrul/0000-0003-4380-5303; Mostafa, Mohamed/0000-0002-1145-4919
CR Abdi H., 2007, Encyclopedia of measurement and statistics, DOI DOI 10.4135/9781412952644.N299
   Al-Khalifa HS, 2014, INT J WEB INF SYST, V10, P194, DOI 10.1108/IJWIS-01-2014-0001
   Allgaier J, 2019, FRONT COMMUN, V4, DOI 10.3389/fcomm.2019.00036
   Aryadoust V., COMPUT ASSIST LANG L
   Avila-Robinson A, 2018, J DESTIN MARK MANAGE, V10, P101, DOI 10.1016/j.jdmm.2018.06.005
   Bakshy E., 2011, P 4 ACM INT C WEB SE, P65
   Benckendorff P, 2009, J HOSP TOUR MANAG, V16, P1, DOI 10.1375/jhtm.16.1.1
   Bonilla CA, 2015, SCIENTOMETRICS, V105, P1239, DOI 10.1007/s11192-015-1747-7
   Bradford S. C., 1985, Engineering, V137, P176, DOI [DOI 10.1177/016555158501000407, 10.1177/016555158501000, DOI 10.1177/016555158501000]
   CALLON M, 1991, SCIENTOMETRICS, V22, P155, DOI 10.1007/BF02019280
   Chen CM, 2008, DATA KNOWL ENG, V67, P234, DOI 10.1016/j.datak.2008.05.004
   Chen CM, 2014, EXPERT OPIN ORPHAN D, V2, P709, DOI 10.1517/21678707.2014.920251
   Chen CM, 2012, EXPERT OPIN BIOL TH, V12, P593, DOI 10.1517/14712598.2012.674507
   Chen XY, 2020, TRANSPORT POLICY, V85, P1, DOI 10.1016/j.tranpol.2019.10.004
   Chen XL, 2021, EDUC TECHNOL SOC, V24, P205
   Chen X, 2020, COMPUT EDUC, V151, DOI 10.1016/j.compedu.2020.103855
   Cobo MJ, 2011, J INFORMETR, V5, P146, DOI 10.1016/j.joi.2010.10.002
   Colicchia C, 2019, SUPPLY CHAIN MANAG, V24, P5, DOI 10.1108/SCM-01-2018-0003
   Corbet S, 2019, RESOUR POLICY, V63, DOI 10.1016/j.resourpol.2019.101416
   Della Corte V, 2018, BRIT FOOD J, V120, P2270, DOI 10.1108/BFJ-09-2017-0538
   Ding Y, 2011, J INFORMETR, V5, P187, DOI 10.1016/j.joi.2010.10.008
   Dobusch L, 2012, REV POLIT ECON, V24, P469, DOI 10.1080/09538259.2012.701928
   Elango B., 2012, International Journal of Information Dissemination and Technology, V2, P166
   Findlay K, 2018, INT J MARKET RES, V60, P169, DOI 10.1177/1470785317753025
   Firdaus A, 2019, SCIENTOMETRICS, V120, P1289, DOI 10.1007/s11192-019-03170-4
   Gautam P, 2020, INT J MATH ENG MANAG, V5, P1156, DOI 10.33889/IJMEMS.2020.5.6.088
   Glänzel W, 2004, HANDBOOK OF QUANTITATIVE SCIENCE AND TECHNOLOGY RESEARCH: THE USE OF PUBLICATION AND PATENT STATISTICS IN STUDIES OF S&T SYSTEMS, P257
   Glötzl F, 2018, REV POLIT ECON, V30, P210, DOI 10.1080/09538259.2018.1449619
   Hussein Eslam, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3392854
   Jiang YW, 2019, CURR ISSUES TOUR, V22, P1925, DOI 10.1080/13683500.2017.1408574
   Khan GF, 2016, COMMUN ASSOC INF SYS, V39, P367, DOI 10.17705/1CAIS.03918
   Khasseh AA, 2017, INFORM PROCESS MANAG, V53, P705, DOI 10.1016/j.ipm.2017.02.001
   Khatri P, 2020, TRAVEL MED INFECT DI, V35, DOI 10.1016/j.tmaid.2020.101636
   Knoke D., 2010, Social Network Analysis
   Koseoglu MA, 2016, SCIENTOMETRICS, V109, P203, DOI 10.1007/s11192-016-1894-5
   Kumar HA, 2011, LIBR COLLECT ACQUIS, V35, P32, DOI 10.1016/j.lcats.2011.03.002
   Kumar S., 2008, Proceeding paper, P1
   LAW J, 1988, SCIENTOMETRICS, V14, P251, DOI 10.1007/BF02020078
   Lee MR, 2012, KNOWL-BASED SYST, V28, P47, DOI 10.1016/j.knosys.2011.11.016
   Li HOY, 2020, BMJ GLOB HEALTH, V5, DOI 10.1136/bmjgh-2020-002604
   Liao HC, 2019, OMEGA-INT J MANAGE S, V88, P223, DOI 10.1016/j.omega.2018.11.005
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu JY, 2019, SCIENTOMETRICS, V118, P617, DOI 10.1007/s11192-018-2974-5
   González-Valiente CL, 2019, BIBL-AN INVESTIG, V15, P83
   Luo JL, 2020, J CLEAN PROD, V273, DOI 10.1016/j.jclepro.2020.122945
   McPherson M, 2001, ANNU REV SOCIOL, V27, P415, DOI 10.1146/annurev.soc.27.1.415
   Merediz-Solà I, 2019, RES INT BUS FINANC, V50, P294, DOI 10.1016/j.ribaf.2019.06.008
   Merigó JM, 2017, AUST ACCOUNT REV, V27, P71, DOI 10.1111/auar.12109
   Mostafa M., 2016, INT J MANAGEMENT MAR, V9, P81
   Mostafa MM, 2020, TRENDS FOOD SCI TECH, V99, P660, DOI 10.1016/j.tifs.2020.03.022
   Mostafa Mohamed M., 2015, J BUSINESS EC STUDIE, V21, P24
   Neff MW, 2009, SCIENTOMETRICS, V80, P657, DOI 10.1007/s11192-008-2099-3
   Neuhaus C, 2006, PORTAL-LIBR ACAD, V6, P127, DOI 10.1353/pla.2006.0026
   Noruzi A., 2017, WEBOLOGY, V14, P1
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Qian JW, 2019, SCAND J HOSP TOUR, V19, P192, DOI 10.1080/15022250.2018.1526113
   Teng SS, 2020, JMIR PUBLIC HLTH SUR, V6, P16, DOI 10.2196/19618
   van Eck N, 2019, VOSVIEWER VERS 1613
   van Eck NJ, 2014, J INFORMETR, V8, P802, DOI 10.1016/j.joi.2014.07.006
   Vidgen R, 2007, EUR J INFORM SYST, V16, P5, DOI 10.1057/palgrave.ejis.3000661
   Wetzstein A., J PURCH SUPPLY MANAG
   Wong WE, 2021, J SYST SOFTWARE, V180, DOI 10.1016/j.jss.2021.111029
   Zong QJ, 2013, SCIENTOMETRICS, V94, P781, DOI 10.1007/s11192-012-0799-1
   Zou X, 2018, ACCIDENT ANAL PREV, V118, P131, DOI 10.1016/j.aap.2018.06.010
NR 66
TC 2
Z9 2
U1 3
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12423
EP 12443
DI 10.1007/s11042-022-13908-7
EA SEP 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000858369900002
PM 36157354
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Mewada, A
   Dewang, RK
AF Mewada, Arvind
   Dewang, Rupesh Kumar
TI A comprehensive survey of various methods in opinion spam detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Natural language processing; Review feature; Reviewer feature; Word
   representation; Semantic; Part-of-speech
ID NEURAL-NETWORK; FAKE; REVIEWS; FRAMEWORK; SYSTEM
AB With the development of technology, e-marketing and business competition, reviews significantly affect people's lives. Consumers of e-commerce sites share their experiences, referencing other user reviews when making consumption decisions and evaluating product quality. People's dependence on review information and business competition has triggered the emergence of false reviews. False reviews refer to the promotion or demotion of the quality of the product. False reviews can easily confuse new users' opinions or judgments, due to which both the consumer and the company are affected. Addressing this issue, spam review is a new research problem today, and even humans do not quickly classify spam reviews with high accuracy. Machine learning methods and natural language processing techniques effectively recognise false reviews and help users get benign review information. In this research, we have categorized and classified spam review detection methods in the direction of review features, reviewer features, and the spammer's group features. In this article, we focus on three approaches for detecting false reviews: spam review detection, spammer detection, and spammer-group detection. This article provides a motivational analysis of the three types of research and, in particular, compares them to aspects of feature design, model methods, datasets, and rating indicators.
C1 [Mewada, Arvind; Dewang, Rupesh Kumar] Motilal Nehru Natl Inst Technol Allahabad, Comp Sci & Engn Dept, Prayagraj 211004, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Mewada, A (corresponding author), Motilal Nehru Natl Inst Technol Allahabad, Comp Sci & Engn Dept, Prayagraj 211004, Uttar Pradesh, India.
EM arvindmewada@mnnit.ac.in; rupeshdewang@mnnit.ac.in
RI Mewada, Arvind/AAX-2915-2021
OI Mewada, Arvind/0000-0002-4680-611X
CR Aghakhani H, 2018, 2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018), P89, DOI 10.1109/SPW.2018.00022
   Ahmed H, 2018, SECUR PRIVACY, V1, DOI 10.1002/spy2.9
   Akoglu Leman., 2013, ICWSM, P2
   Al Najada H, 2014, 2014 IEEE 15TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI), P553, DOI 10.1109/IRI.2014.7051938
   Al-Zoubi AM, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12073634
   Algur S. P., 2010, 2010 International Conference on Signal and Image Processing (ICSIP 2010), P416, DOI 10.1109/ICSIP.2010.5697509
   [Anonymous], 2013, P 6 WORKSHOP PHD STU
   [Anonymous], 2021, Bloomberg
   [Anonymous], 2021, Fast Facts
   Archchitha K, 2019, INT CONF ADV ICT, DOI 10.1109/icter48817.2019.9023695
   Aslam U, 2019, INT J SCI TECHNOL RE, V8
   Banerjee S, 2015, ACM IMCOM 2015, PROCEEDINGS, DOI 10.1145/2701126.2701130
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Barbado R, 2019, INFORM PROCESS MANAG, V56, P1234, DOI 10.1016/j.ipm.2019.03.002
   Barushka A., 2019, IFIP INT C ARTIFICIA, P340
   Bhuvaneshwari P, 2021, MULTIMED TOOLS APPL, V80, P18107, DOI 10.1007/s11042-021-10602-y
   Bitarafan A, 2019, 2019 5TH INTERNATIONAL CONFERENCE ON WEB RESEARCH (ICWR), P228, DOI [10.1109/ICWR.2019.8765274, 10.1109/icwr.2019.8765274]
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   BrightLocal, 2016, Local consumer review survey
   Cao N, 2020, EXPERT SYST APPL, V156, DOI 10.1016/j.eswa.2020.113465
   Cardoso EF, 2018, NEUROCOMPUTING, V309, P106, DOI 10.1016/j.neucom.2018.04.074
   Chen H, 2018, INFORM FUSION, V44, P22, DOI 10.1016/j.inffus.2017.11.002
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Crawford M., 2015, J BIG DATA, V2, P23, DOI [10.1186/s40537-015-0029-9, DOI 10.1186/S40537-015-0029-9]
   CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341
   Dewang RK, 2016, P 2 INT C INF COMM T, P1, DOI DOI 10.1145/2905055.2905081
   Dewang RK., 2016, INT J ENG TECHNOL IJ, V8, P2946, DOI [10.21817/ijet/2016/v8i6/160806257, DOI 10.21817/IJET/2016/V8I6/160806257]
   Dewang RK, 2018, J INTELL INF SYST, V50, P231, DOI 10.1007/s10844-017-0454-7
   Eimurrigi E, 2017, 2017 SEVENTH INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING TECHNOLOGY (INTECH 2017), P107, DOI 10.1109/INTECH.2017.8102442
   Eisenstein J, 2011, P 28 INT C MACHINE L, P1041
   Fahfouh A, 2020, EXPERT SYST APPL, V157, DOI 10.1016/j.eswa.2020.113517
   Fakhraei S, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1769, DOI 10.1145/2783258.2788606
   Fazil M, 2018, IEEE T INF FOREN SEC, V13, P2707, DOI 10.1109/TIFS.2018.2825958
   Fazzolari M, 2021, ACM J DATA INF QUAL, V13, DOI 10.1145/3439307
   FE Online, 2019, FIN FIN EXPR STOR
   Fei Geli., 2013, ICWSM
   Fornaciari T., 2014, P 14 C EUROPEAN CHAP, P279, DOI DOI 10.3115/V1/E14-1030
   Fu H, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/3086637
   Gao Y, 2021, IEEE T MULTIMEDIA, V23, P784, DOI 10.1109/TMM.2020.2990085
   Gilbert E, 2010, 2010 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P225
   Guo ZW, 2021, IEEE INTERNET THINGS, V8, P9549, DOI 10.1109/JIOT.2020.3003802
   Guo ZW, 2021, FUTURE GENER COMP SY, V117, P205, DOI 10.1016/j.future.2020.11.028
   Guzella TS, 2009, EXPERT SYST APPL, V36, P10206, DOI 10.1016/j.eswa.2009.02.037
   Hai Z., 2016, P C EMP METH NAT LAN, P1817, DOI [10.18653/v1/D16-1187, DOI 10.18653/V1/D16-1187]
   Hajek P, 2020, NEURAL COMPUT APPL, V32, P17259, DOI 10.1007/s00521-020-04757-2
   Hammad ASA, 2013, APPROACH DETECT SPAM
   Hazim M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0198884
   He DJ, 2020, IEEE NETWORK, V34, P298, DOI 10.1109/MNET.001.1900542
   Hernandez D., 2013, Proc. of the 4th Workshop on Computational Approaches to Subjectivity, P38
   Hussain N, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.472
   Hussain N, 2020, IEEE ACCESS, V8, P53801, DOI 10.1109/ACCESS.2020.2979226
   Jain G, 2019, ANN MATH ARTIF INTEL, V85, P21, DOI 10.1007/s10472-018-9612-z
   Ji S, 2019, CUSTOMER REV SUPERFA
   Jindal N., 2007, P 16 INT WORLD WID W, P1189, DOI DOI 10.1145/1242572.1242759
   Jindal N., 2008, WSDM 08, P219, DOI [DOI 10.1145/1341531.1341560, 10.1145/1341531.1341560]
   Jindal N, 2007, IEEE DATA MINING, P547, DOI 10.1109/ICDM.2007.68
   Jindal Nitin., 2010, Proceedings of the 19th ACM international conference on Information and knowledge management, CIKM '10, P1549
   Joachims Thorsten, 1998, EUROPEAN C MACHINE L, P137, DOI 10.1007/
   KARAMI A., 2015, iConference 2015 Proceedings
   Karthik E, 2022, NEURAL PROCESS LETT, V54, P4123, DOI 10.1007/s11063-022-10797-7
   Kennedy S, 2020, ARXIV
   Khan Hanif, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12664), P269, DOI 10.1007/978-3-030-68799-1_19
   Khan MUS, 2018, IEEE T DEPEND SECURE, V15, P551, DOI 10.1109/TDSC.2016.2616879
   Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140
   Krenker A, 2011, ARTIFICIAL NEURAL NETWORKS - METHODOLOGICAL ADVANCES AND BIOMEDICAL APPLICATIONS, P3, DOI 10.5772/15751
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Li CZ, 2018, IEEE DATA MINING, P247, DOI 10.1109/ICDM.2018.00040
   Li F., 2011, P 22 INT JOINT C ART, P2488, DOI [10.5555/2283696, DOI 10.5591/978-1-57735-516-8/IJCAI11-414, 10.5591/978-1-57735-516-8/IJCAI11-]
   Li HY, 2014, IEEE DATA MINING, P899, DOI 10.1109/ICDM.2014.47
   Li Huayi, 2015, P INT AAAI C WEB SOC, P634
   Li J., 2013, P 51 ANN M ASS COMP, VVolume 2, P217
   Li JD, 2021, EXPERT SYST APPL, V171, DOI 10.1016/j.eswa.2021.114585
   Li JW, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1566
   Li LY, 2017, NEUROCOMPUTING, V254, P33, DOI 10.1016/j.neucom.2016.10.080
   Li LY, 2015, LECT NOTES ARTIF INT, V9427, P393, DOI 10.1007/978-3-319-25816-4_32
   Li X. L., 2009, P 2009 SIAM INT C DA, P259, DOI DOI 10.1137/1.9781611972795.23
   Li X, 2016, LECT NOTES COMPUT SC, V9658, P95, DOI 10.1007/978-3-319-39937-9_8
   Li YJ, 2021, MOBILE NETW APPL, V26, P91, DOI 10.1007/s11036-020-01688-z
   Ligthart A, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.107023
   Lim E.P., 2010, P ACM INT C INFORM K, P939, DOI DOI 10.1145/1871437.1871557
   Liming Deng, 2020, Artificial Intelligence and Mobile Services - AIMS 2020. 9th International Conference Held as Part of the Services Conference Federation, SCF 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12401), P106, DOI 10.1007/978-3-030-59605-7_9
   Liu B, 2015, SENTIMENT ANALYSIS: MINING OPINIONS, SENTIMENTS, AND EMOTIONS, P1
   Liu C, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10051425
   Liu P, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE QUALITY, RELIABILITY AND SECURITY COMPANION (QRS-C), P396, DOI 10.1109/QRS-C.2017.72
   Liu YC, 2019, NEUROCOMPUTING, V366, P276, DOI 10.1016/j.neucom.2019.08.013
   Luca M, 2016, MANAGE SCI, V62, P3412, DOI 10.1287/mnsc.2015.2304
   Luo N, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P475, DOI 10.1109/ICISCE.2017.106
   Marinova Iva, 2022, 25 GROUNDBREAKING YE
   Meng H., 2019, P ACM TURING CELEBRA, P1
   Mewada A, 2010, NETWORK
   Mukherjee A, 2012, P 21 INT C WORLD WID, P191
   Mukherjee A., 2013, UICCS201303
   Mukherjee A, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P632
   Mukherjee Arjun, 2013, P INT AAAI C WEB SOC, DOI DOI 10.1609/ICWSM.V7I1.14389
   Mukherjee Arjun., 2011, P 20 INT C COMPANION, P93
   Narayan R, 2018, ADV INTELL SYST, V719, P273, DOI 10.1007/978-981-10-3376-6_30
   Onan A., 2018, P 2018 26 SIGN PROC, P1, DOI [10.1109/SIU.2018.8404258, DOI 10.1109/SIU.2018.8404258]
   Ott M., 2011, ACL HLT 2011 P 49 AN, V1, P309, DOI DOI 10.1145/2567948.2577293
   Ott M., 2013, P 2013 C N AM CHAPT, P497
   Ott M, 2012, P 21 INT C WORLD WID, P201, DOI DOI 10.1145/2187836.2187864
   Pasricha R, 2018, 12TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS), P63, DOI 10.1145/3240323.3240356
   Peng QX, 2014, LECT NOTES COMPUT SC, V8697, P287, DOI 10.1007/978-3-319-14139-8_30
   Pennebaker J.W., 2001, Linguistic inquiry and word count: LIWC 2001, V71, P1
   Qian Tieyun., 2013, EMNLP, P1124
   Radwa MK, 2019, J KING SAUD U COMPUT
   Rathore P, 2021, IEEE T COMPUT SOC SY, V8, P1369, DOI 10.1109/TCSS.2021.3085406
   Rathore S, 2018, APPL SOFT COMPUT, V67, P920, DOI 10.1016/j.asoc.2017.09.032
   Rayana S, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P985, DOI 10.1145/2783258.2783370
   Ren Y., 2014, P 2014 C EMP METH NA, P488, DOI DOI 10.3115/V1/D14-1055
   Ren YF, 2017, INFORM SCIENCES, V385, P213, DOI 10.1016/j.ins.2017.01.015
   Rout Jitendra Kumar, 2018, 2018 International Conference on Information Technology (ICIT), P7, DOI 10.1109/ICIT.2018.00014
   Rout JK, 2017, IEEE ACCESS, V5, P1319, DOI 10.1109/ACCESS.2017.2655032
   Sandulescu V, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P971, DOI 10.1145/2740908.2742570
   Saumya Sunil, 2018, CSI Transactions on ICT, V6, P137, DOI 10.1007/s40012-018-0193-0
   Saumya S, 2022, ELECTRON COMMER RES, V22, P113, DOI 10.1007/s10660-020-09413-4
   Savage D, 2015, EXPERT SYST APPL, V42, P8650, DOI 10.1016/j.eswa.2015.07.019
   Schutze Hinrich, 2019, LEARNING SEMANTIC RE
   Shaalan Y, 2021, DATA MIN KNOWL DISC, V35, P450, DOI 10.1007/s10618-020-00725-5
   Sharma Anurag, 2022, Advances in Communication, Devices and Networking: Proceedings of ICCDN 2020. Lecture Notes in Electrical Engineering (776), P241, DOI 10.1007/978-981-16-2911-2_26
   Shehnepoor S, 2021, IEEE T INF FOREN SEC
   Shojaee S, 2013, INT CONF INTELL SYST, P53, DOI 10.1109/ISDA.2013.6920707
   Sindhu C., 2018, INT J PURE APPL MATH, V118, P683
   Song Y, 2017, INT C COLLABORATIVE, P143
   Stanton G, 2019, ARXIV
   Sultana N., 2020, Int J Inf Eng Electron Bus, V12, P1, DOI DOI 10.5815/IJIEEB.2020.01.01
   Sun C., 2016, Math. Probl. Eng., V2016
   Tao J, 2021, P 54 HAWAII INT C SY, P274
   Tsujioka Y, 2012, COMPUT-AIDED CHEM EN, V31, P830
   Varadarajan J, 2017, IEEE WINT CONF APPL, P615, DOI 10.1109/WACV.2017.74
   Vemprala N, 2019, PROCEEDINGS OF THE 52ND ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P7186
   Wan M, 2019, ARXIV
   Wang G., 2011, ICDM, P1242, DOI DOI 10.1109/ICDM.2011.124
   Wang G, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2337542.2337546
   Wang J, 2022, APPL SOFT COMPUT
   Wang X., 2016, P C EMP METH NAT LAN, P866
   Wang Z., 2019, arXiv
   Wang Z, 2020, DATA MIN KNOWL DISC, V34, P1621, DOI 10.1007/s10618-020-00693-w
   Wang Z, 2018, APPL INTELL, V48, P3094, DOI 10.1007/s10489-018-1142-1
   Wang Z, 2018, KNOWL INF SYST, V55, P571, DOI 10.1007/s10115-017-1068-7
   Wu FZ, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1791, DOI 10.1145/3269206.3269324
   Wu Guangyu., 2010, Proceedings of the Fourth ACM Conference on Recommender Systems, RecSys '10, P241
   Wu YJ, 2020, AAAI CONF ARTIF INTE, V34, P1054
   Wu Z, 2020, IEEE T CYBERNETICS, V50, P1595, DOI 10.1109/TCYB.2018.2877161
   Xiao QK, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0164610
   Xie SA, 2018, PR MACH LEARN RES, V80
   Xie Sihong, 2012, P 21 INT C WORLD WID, P635, DOI [10.1145/2187980.2188164, DOI 10.1145/2187980.2188164]
   Xie Y, 2018, IEEE ACCESS, V6, P76527, DOI 10.1109/ACCESS.2018.2882917
   Xu C., 2015, Proceedings of the 2015 SIAM International Conference on Data Mining, P172
   Xu C, 2015, IEEE DATA MINING, P1051, DOI 10.1109/ICDM.2015.62
   Xu C, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P979, DOI 10.1145/2505515.2505700
   Xu GX, 2021, INFORM SCIENCES, V576, P681, DOI 10.1016/j.ins.2021.07.072
   Xue H, 2015, 2015 IEEE TRUSTCOM/BIGDATASE/ISPA, VOL 1, P726, DOI 10.1109/Trustcom.2015.440
   Yan X, 2011, ACM T INFORM SYST, V29, DOI 10.1145/1993036.1993039
   Ye JT, 2015, LECT NOTES ARTIF INT, V9284, P267, DOI 10.1007/978-3-319-23528-8_17
   Ye Wang, 2019, Artificial Intelligence and Security. 5th International Conference, ICAIS 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11632), P182, DOI 10.1007/978-3-030-24274-9_16
   Yilmaz CM, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P306, DOI 10.1109/ASONAM.2018.8508314
   Yin J, 2021, NEUROCOMPUTING, V428, P130, DOI 10.1016/j.neucom.2020.10.070
   Yu DG, 2017, KNOWL-BASED SYST, V125, P64, DOI 10.1016/j.knosys.2017.03.025
   Zeng ZY, 2019, INFORMATION, V10, DOI 10.3390/info10070243
   Zhang FZ, 2020, KNOWL-BASED SYST, V193, DOI 10.1016/j.knosys.2020.105520
   Zhang L, 2018, IEEE ACCESS, V6, P2559, DOI 10.1109/ACCESS.2017.2784370
NR 161
TC 5
Z9 5
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13199
EP 13239
DI 10.1007/s11042-022-13702-5
EA SEP 2022
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000850023000002
DA 2024-07-18
ER

PT J
AU Matlani, P
   Shrivastava, M
AF Matlani, Princy
   Shrivastava, Manish
TI Efficient abnormal event detection in video using deep attention based
   bidirectional lstm with a mayfly optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Key frame selection; Dimensionality reduction; Noise filtering; Feature
   extraction; Motion estimation; Detection of abnormal events
AB Abnormal event detection is a challenging issue in video surveillance, and it is quite necessary for detecting suspicious behaviour in the normal video data. Detecting abnormalities in video is very crucial and the application ranges from automatic control of quality to visual surveillance data. This paper presented efficient abnormal event detection in video utilizing deep attention based bidirectional LSTM (Long Short Term Memory) with a Mayfly optimization. Initially, the key frames of input video are selected utilizing threshold based discrete wavelet transform. In the second stage, Kernel Entropy Component Analysis (KECA) is used for decreasing the dimensionality. In the third stage, optimal weighted bilateral filtering is utilized for removing the unnecessary noises. In the next stage, a hybrid dual tree Gabor transform is utilized for the effective feature extraction. Afterwards, the Fame back optical methodology is incorporated to estimate the motion in the video sequence. In the final stage, deep attention based bidirectional LSTM with a mayfly optimized model effectively detects the abnormal events. This presented methodology effectively detects normal and abnormal events and it is implemented in PYTHON platform. The performance of the proposed approach is tested on QMUL and UCF datasets. The experimental outcomes of the presented methodology proved that the presented work is significantly better in terms of various effective performance measures like accuracy, AUC (Area Under Curve), execution time and ROC (Receiver Operating Characteristics) measures. The proposed approach achieved the improved outcomes in terms of accuracy as (94.19%) for QMUL dataset, and (93.60%) for UCF dataset.
C1 [Matlani, Princy; Shrivastava, Manish] Guru Ghasidas Univ, Dept Comp Sci & Engn, Bilaspur, India.
C3 Guru Ghasidas Vishwavidyalaya
RP Matlani, P (corresponding author), Guru Ghasidas Univ, Dept Comp Sci & Engn, Bilaspur, India.
EM princy.matlani@gmail.com; manbsp@gmail.com
RI Shrivastava, Manish/AAS-6633-2020
CR [Anonymous], UCF DATASET
   [Anonymous], QMUL DATASET
   Athanesious JJ, 2019, MULTIMED TOOLS APPL, V78, P19877, DOI 10.1007/s11042-019-7332-y
   Balasundaram A, 2020, J REAL-TIME IMAGE PR, V17, P915, DOI 10.1007/s11554-018-0840-6
   Bhargavi MS., 2020, ABNORMAL EVENT DETEC, P701
   Bouindour Samir, 2017, 8th International Conference on Imaging for Crime Detection and Prevention (ICDP 2017), P1
   Bouindour S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040757
   Chen HH, 2018, J ENG-JOE, P254, DOI 10.1049/joe.2018.0093
   Chu WQ, 2019, IEEE T MULTIMEDIA, V21, P246, DOI 10.1109/TMM.2018.2846411
   Fanello SR, 2013, LECT NOTES COMPUT SC, V7887, P31
   Geng Y, 2019, WORLD WIDE WEB, V22, P689, DOI 10.1007/s11280-018-0603-0
   Jiang F, 2007, IEEE IMAGE PROC, P2397
   Jiang F, 2009, IEEE T IMAGE PROCESS, V18, P907, DOI 10.1109/TIP.2008.2012070
   Li A, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107355
   Lu CW, 2019, INT J COMPUT VISION, V127, P993, DOI 10.1007/s11263-018-1129-8
   Sekh AA, 2020, SOFT COMPUT, V24, P16643, DOI 10.1007/s00500-020-04967-9
   Sun JY, 2019, MULTIMED TOOLS APPL, V78, P3633, DOI 10.1007/s11042-017-5244-2
   Wan SH, 2021, IEEE T INTELL TRANSP, V22, P4487, DOI 10.1109/TITS.2020.3017505
   Wang J, 2019, NEURAL COMPUT APPL, V31, P1607, DOI 10.1007/s00521-018-3417-1
   Wang T, 2020, FRONT COMPUT SCI-CHI, V14, P304, DOI 10.1007/s11704-018-7407-3
   Wang T, 2018, OPTIK, V152, P50, DOI 10.1016/j.ijleo.2017.07.064
   Wang T, 2013, J ELECTR COMPUT ENG, V2013, DOI 10.1155/2013/837275
   Wang Zhongxiu., 2004, Price Lists of Modern Seal-carvers, Calligraphers, and Painters, P1, DOI [10.20944/preprints201809.0192.v1, DOI 10.1109/WCNC.2018.8377171, DOI 10.1109/IWQOS.2018.8624171]
   Xu D., 2015, ARXIV
   Ye O, 2020, IEEE ACCESS, V8, P97564, DOI 10.1109/ACCESS.2020.2997357
   Ye RZ, 2017, J COMPUT SCI TECH-CH, V32, P470, DOI 10.1007/s11390-017-1737-8
   Yu MZ, 2020, INT J DIGIT EARTH, V13, P1339, DOI 10.1080/17538947.2020.1738569
NR 27
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42371
EP 42392
DI 10.1007/s11042-022-13494-8
EA AUG 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000839516900006
DA 2024-07-18
ER

PT J
AU Raja, K
   Abilash, B
   Anbalagan, S
   Dev, K
   Ganapathisubramaniyan, A
AF Raja, Kathiroli
   Abilash, B.
   Anbalagan, Sudha
   Dev, Kapal
   Ganapathisubramaniyan, Aishwarya
TI Popularity based content caching of YouTube data in cellular networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content caching; Content popularity prediction; Content updation;
   Machine learning; Quality of experience
AB The rapid growth of video traffic including web-based monitoring, live streaming, video conferencing and other forms of video constitutes the major part of global internet usage. Due to this enormous growth of internet traffic ensuring Quality of Experience (QoE) to the consumers has become a significant challenge for Internet Service Providers (ISPs). Content caching in the cellular networks provides a promising solution to alleviate the internet traffic. Caching serves as an efficient approach when there are recurrent requests of popular content over a period of time. However, caching inside cellular networks comes up with significant challenges including content popularity identification, optimal content placement and cache management. In this paper, an improved cache hit ratio is achieved in two levels: i) Popularity-based Content Placement Strategy (PCPS) deploys the popular files into the network nodes by considering the factors such as video category, content replication and their regions and ii) Popularity-based Cache Updation Strategy (PCUS) dynamically handles the cache updation based on incoming user requests through local and global popularity of videos. Features extracted from the video and its thumbnail are used to identify the popularity. The proposed caching mechanism is carried out with YouTube data and the simulation results reveal that the proposed PCPS and PCUS approach outperforms the traditional caching mechanisms.
C1 [Raja, Kathiroli; Abilash, B.] Anna Univ, Chennai, Tamil Nadu, India.
   [Anbalagan, Sudha] Vellore Inst Technol, Sch Comp Sci & Engn, Ctr Smart Grid Technol, Chennai, Tamil Nadu, India.
   [Dev, Kapal] Trinity Coll Dublin, Connect Ctr, Dublin, Ireland.
   [Ganapathisubramaniyan, Aishwarya] Citicorp Serv India Private Ltd, Chennai, Tamil Nadu, India.
C3 Anna University; Anna University Chennai; Vellore Institute of
   Technology (VIT); VIT Chennai; Trinity College Dublin
RP Raja, K (corresponding author), Anna Univ, Chennai, Tamil Nadu, India.
EM kathirolig@gmail.com; abilashbalaraman6@gmail.com; sudha.a@vit.ac.in;
   kapal.dev@ieee.org; aishwarya97.mit@gmail.com
RI Anbalagan, Sudha/AAH-9214-2020
OI Anbalagan, Sudha/0000-0002-7886-2327; Raja,
   Kathiroli/0000-0003-0757-6750
CR Ahlehagh H, 2014, IEEE ACM T NETWORK, V22, P1444, DOI 10.1109/TNET.2013.2294111
   Amadeo M, 2020, IEEE CONF COMPUT, P610, DOI 10.1109/INFOCOMWKSHPS50562.2020.9162741
   [Anonymous], 2016, INFLUENCE GREEN SPAC
   [Anonymous], 2017, Cisco Visual Networking Index: Global Mobile Data Traffic Forecast Update, 2016-2021 White Paper
   [Anonymous], 2012, BUSINESS CASE CACHIN
   Bradski G, 2000, DR DOBBS J, V25, P120
   .google, 2012, YOUTUBE API
   Guo KY, 2017, IEEE WCNC
   Hagikura J, 2020, P INT COMP SOFTW APP, P1151, DOI 10.1109/COMPSAC48688.2020.0-101
   Hoiles W, 2017, IEEE T KNOWL DATA EN, V29, P1426, DOI 10.1109/TKDE.2017.2682858
   Koch C, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P89, DOI 10.1145/3204949.3204963
   Liu WX, 2018, IEEE ACCESS, V6, P5075, DOI 10.1109/ACCESS.2017.2781716
   Martin A, 2018, IEEE T BROADCAST, V64, P561, DOI 10.1109/TBC.2018.2828608
   Mastorakis Spyridon, 2017, ACM SIGCOMM Computer Communication Review, V47, P19, DOI 10.1145/3138808.3138812
   Minh-Tri Nguyen, 2019, 2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS). Proceedings, P329, DOI 10.1109/HPCC/SmartCity/DSS.2019.00058
   Müller S, 2017, IEEE T WIREL COMMUN, V16, P1024, DOI 10.1109/TWC.2016.2636139
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Poularakis K, 2016, IEEE T WIREL COMMUN, V15, P2995, DOI 10.1109/TWC.2016.2514418
   Ramanan BA, 2013, WIREL TELECOMM SYMP
   Richier C, 2014, 2014 PROCEEDINGS OF THE IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2014), P297, DOI 10.1109/ASONAM.2014.6921600
   scikit-learn, 2013, ABOUT US
   Song JJ, 2017, IEEE T COMMUN, V65, P4309, DOI 10.1109/TCOMM.2017.2713384
   Suksomboon K, 2013, C LOCAL COMPUT NETW, P236, DOI 10.1109/LCN.2013.6761239
   Tanzil SMS, 2017, IEEE ACCESS, V5, P5870, DOI 10.1109/ACCESS.2017.2678990
   Trzcinski T, 2017, IEEE T MULTIMEDIA, V19, P2561, DOI 10.1109/TMM.2017.2695439
   Wu B, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1336, DOI 10.1145/2964284.2964335
   Yadav P, 2020, NAT C COMM NCC, P1
   Zhang JX, 2016, IEEE ACCESS, V4, P3591, DOI 10.1109/ACCESS.2016.2588883
NR 28
TC 1
Z9 1
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37165
EP 37182
DI 10.1007/s11042-022-13528-1
EA AUG 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000838552300011
DA 2024-07-18
ER

PT J
AU Liu, JX
   Tang, LL
   Tian, Y
   Cao, Y
AF Liu, Jixin
   Tang, Linlin
   Tian, Yu
   Cao, Yue
TI Image segmentation application based on the normal cloud model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Normal cloud model; Cloud kernel extraction; Concept
   promotion; Maximum similarity
AB In image segmentation, one important problem is the indeterminacy of pixel value. Based on fuzzy and probability theory, Cloud Model can better solve this same concept problem in segmentation. Methods based on Normal Cloud Model have been proposed here for improving the segmentation performance. Single-Kernel Extraction (SKE) and Multi-Kernel Extraction (MKE) methods have been introduced which are used for determining expected value of the Cloud Model during Cloud Transformation. In addition, a Maximum-Similarity Concept Promotion (MSCP) strategy based on Minimum-Distance Concept Promotion (MDCP) has been proposed and its theoretical validity has also been introduced. Image segmentation experiment results show that our algorithms get a strong adaptability and better image segmentation effect evaluation coefficient.
C1 [Liu, Jixin; Cao, Yue] Guangdong Univ Petrochem Technol, Coll Automat, Maoming, Guangdong, Peoples R China.
   [Tang, Linlin; Tian, Yu] Harbin Inst Technol, Shenzhen, Peoples R China.
C3 Guangdong University of Petrochemical Technology; Harbin Institute of
   Technology
RP Tang, LL (corresponding author), Harbin Inst Technol, Shenzhen, Peoples R China.
EM ljxgdupt@126.com; hittang@126.com; 529304221@qq.com; cygdupt@126.com
FU Talent Introduction Project for Guangdong University of Petrochemical
   Technology [2020rc32]; Shenzhen Science and Technology Plan Fundamental
   Research Funding [JCYJ20180306171938767]; Shenzhen Foundational Research
   Funding [JCYJ20180507183527919]
FX This work was supported by the Talent Introduction Project for Guangdong
   University of Petrochemical Technology under Grant 2020rc32. And it was
   also supported by the Shenzhen Science and Technology Plan Fundamental
   Research Funding JCYJ20180306171938767 and the Shenzhen Foundational
   Research Funding JCYJ20180507183527919.
CR Bai X, 2007, 2007 11 IEEE INT C C, V82, P1, DOI [10.1109/ICCV.2007.4408931, DOI 10.1109/ICCV.2007.4408931]
   Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Cheng MM, 2011, IEEE T PATTERN ANAL, V33, P200, DOI 10.1109/TPAMI.2010.138
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Delong A., 2008, Proc. IEEE International Conference on Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2008.4587464
   DEYI L, 2005, ARTIF INTELL
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Fwu JK, 1996, IEEE T MED IMAGING, V15, P871, DOI 10.1109/42.544504
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   Haralick R. M., 1985, Proceedings of the SPIE - The International Society for Optical Engineering, V548, P2, DOI [10.1016/S0734-189X(85)90153-7, 10.1117/12.948400]
   Hwang K, 2010, IEEE INTERNET COMPUT, V14, P14, DOI 10.1109/MIC.2010.86
   Karadag OO, 2014, INT C PATT RECOG, P930, DOI 10.1109/ICPR.2014.170
   Kohayakawa Y, 2014, EUR J COMBIN, V40, P26, DOI 10.1016/j.ejc.2014.02.004
   Lankoande O, 2005, P SOC PHOTO-OPT INS, V5808, P210, DOI 10.1117/12.603812
   Layer T, 2015, EJNMMI PHYS, V2, DOI 10.1186/s40658-015-0110-7
   Li DR., 2013, SPATIAL DATA MINING, V2
   Li DY., 2000, Engineeringence, V2, P73, DOI DOI 10.3969/J.ISSN.1009-1742.2000.10.018
   Liu YC, 2011, INT J AUTOM COMPUT, V8, P280, DOI 10.1007/s11633-011-0583-3
   Lu Qing-Wen, 2006, Chinese Journal of Computers, V29, P296
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Osuna-Enciso V, 2013, EXPERT SYST APPL, V40, P1213, DOI 10.1016/j.eswa.2012.08.017
   Othman AA, 2014, IEEE T FUZZY SYST, V22, P72, DOI 10.1109/TFUZZ.2013.2246761
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Rong WB, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (IEEE ICMA 2014), P577, DOI 10.1109/ICMA.2014.6885761
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Silva GP, 2015, KNOWL-BASED SYST, V87, P38, DOI 10.1016/j.knosys.2015.07.030
   Spitzer VM., 1998, ATLAS VISIBLE HUMAN
   Tizhoosh HR, 2005, PATTERN RECOGN, V38, P2363, DOI 10.1016/j.patcog.2005.02.014
   Vicente S, 2008, PROC CVPR IEEE, P767
   Wang J, 2007, FOUND TRENDS COMPUT, V3, P97, DOI 10.1561/0600000019
   Xinting T., 2012, COMPUT ENG APPL, V48, P212, DOI [10.3778/j.issn.1002-8331.2012.01.061, DOI 10.3778/J.ISSN.1002-8331.2012.01.061]
   [张国英 Zhang Guoying], 2005, [北京理工大学学报, Journal of beijing institute of technology], V25, P499
   Zhang XF, 2012, SCI CHINA INFORM SCI, V55, P1052, DOI 10.1007/s11432-012-4556-0
   Zhang Y., 2000, MED IMAGING IMAGE PR, V20, P45, DOI [10.1117/12.387617, DOI 10.1117/12.387617]
   Zhang Yong, 2004, Information and Control, V33, P129
   Zheng S, 2014, PROC CVPR IEEE, P3214, DOI 10.1109/CVPR.2014.411
NR 38
TC 1
Z9 1
U1 4
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 6097
EP 6126
DI 10.1007/s11042-022-13603-7
EA AUG 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000836084200005
DA 2024-07-18
ER

PT J
AU Theerthagiri, P
AF Theerthagiri, Prasannavenkatesan
TI Stress emotion recognition with discrepancy reduction using transfer
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mental stress; Emotion analysis; Deep learning; Transfer learning; CNN
AB Stress management is critical for forecasting stress levels and identifying the impact of stress on a person's socioeconomic life. For effective stress prediction, the Deep Belief Network and Transfer Learning (DBNTL) approach extracts information on the top layers but degrades performance on various levels. As a result, this study offers a unique stress emotion identification technique with discrepancy reduction that enables stress emotion recognition-based classifiers on small-scale emotion and stress data domains. The marginal distribution difference at comparable layers and the combined distribution discrepancy of diverse levels aid stress emotion identification in learning better quality features at the top layers; even distinct emotion and stress domains have feature-level similarities. Because all of the stress emotion detection layers are similarly trained, it evaluates both marginal and joint distribution discrepancies across several layers. Furthermore, a careful balance of these two disparities can improve transferability between emotion and stress domains. Finally, when compared to convolutional neural networks and DBNTL-based stress emotion classification techniques, the experimental results show that the stress emotion identification approach is more efficient.
C1 [Theerthagiri, Prasannavenkatesan] GITAM Univ, GITAM Sch Technol, Dept Comp Sci & Engn, Bengaluru, India.
C3 Gandhi Institute of Technology & Management (GITAM)
RP Theerthagiri, P (corresponding author), GITAM Univ, GITAM Sch Technol, Dept Comp Sci & Engn, Bengaluru, India.
EM vprasann@gitam.edu
RI Theerthagiri, Prasanna venkatesan/G-7019-2019
OI Theerthagiri, Prasanna venkatesan/0000-0003-3420-598X
CR Akçay MB, 2020, SPEECH COMMUN, V116, P56, DOI 10.1016/j.specom.2019.12.001
   Banerjee D, 2019, KNOWL INF SYST, V60, P1693, DOI 10.1007/s10115-019-01337-2
   Castaldo R, 2015, BIOMED SIGNAL PROCES, V18, P370, DOI 10.1016/j.bspc.2015.02.012
   Chen LL, 2019, EXPERT SYST APPL, V137, P266, DOI 10.1016/j.eswa.2019.02.005
   Dzedzickis A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030592
   Feng KX, 2020, FRONT COMP SCI-SWITZ, V2, DOI 10.3389/fcomp.2020.00009
   Garcia-Ceja E, 2020, USER MODEL USER-ADAP, V30, P365, DOI 10.1007/s11257-019-09248-1
   He JY, 2019, IEEE ACCESS, V7, P42710, DOI 10.1109/ACCESS.2019.2907076
   Jaiswal M, 2020, AAAI CONF ARTIF INTE, V34, P7985
   Jawharali B., 2019, INT J ENG RES TECHNO, V12, P66
   Kaur Barjinder, 2018, Procedia Computer Science, V132, P752, DOI 10.1016/j.procs.2018.05.087
   Lan ZR, 2019, IEEE T COGN DEV SYST, V11, P85, DOI 10.1109/TCDS.2018.2826840
   Li W., 2021, IEEE T COGN DEV SYST, DOI [10.1109/TCDS.2021.3098842, DOI 10.1109/TCDS.2021.3098842]
   Liapis A, 2015, LECT NOTES COMPUT SC, V9296, P255, DOI 10.1007/978-3-319-22701-6_18
   Luo J, 2018, APPL MATH MODEL, V64, P654, DOI 10.1016/j.apm.2018.07.044
   Masood K, 2019, IEEE ACCESS, V7, P68446, DOI 10.1109/ACCESS.2019.2917718
   Maxhuni A, 2016, J BIOMED INFORM, V63, P344, DOI 10.1016/j.jbi.2016.08.023
   Pereira T, 2017, COMPUT METH PROG BIO, V148, P71, DOI 10.1016/j.cmpb.2017.06.018
   Prasannavenkatesan T, 2021, EAI ENDORSED T PERVA, DOI [10.4108/eai.3-2-2021.168601, DOI 10.4108/EAI.3-2-2021.168601]
   Ruby U., 2020, Int. J. Adv. Trends Comput. Sci. Eng., V9, DOI DOI 10.30534/IJATCSE/2020/175942020
   Shaw A, 2019, ARXIV
   Song SH, 2017, HEALTHC INFORM RES, V23, P285
   Sriamprakash S, 2017, PROCEDIA COMPUT SCI, V115, P359, DOI 10.1016/j.procs.2017.09.090
   Theerthagiri P., 2021, Int J Cur Res Rev, V13, P156, DOI [10.31782/IJCRR.2021.SP173, DOI 10.31782/IJCRR.2021.SP173]
   Theerthagiri P, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6248
   Theerthagiri P, 2019, INT J COMMUN SYST, V32, DOI 10.1002/dac.3951
   Torres EP, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185083
   Uddin MZ, 2020, ENG APPL ARTIF INTEL, V94, DOI 10.1016/j.engappai.2020.103775
   Wu DP, 2021, IEEE J SEL AREA COMM, V39, P479, DOI 10.1109/JSAC.2020.3020677
   Zhang JH, 2020, INFORM FUSION, V59, P103, DOI 10.1016/j.inffus.2020.01.011
   Zhang Q, 2017, COMPUT IND, V92-93, P84, DOI 10.1016/j.compind.2017.04.005
   Zhao JF, 2019, BIOMED SIGNAL PROCES, V47, P312, DOI 10.1016/j.bspc.2018.08.035
   Ziyu Ma, 2021, MuSe '21: Proceedings of the 2nd on Multimodal Sentiment Analysis Challenge, P29, DOI 10.1145/3475957.3484457
NR 33
TC 6
Z9 6
U1 5
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5949
EP 5963
DI 10.1007/S11042-022-13593-6
EA AUG 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000834736500004
DA 2024-07-18
ER

PT J
AU Yang, XF
   Yu, YX
   Zhang, Z
   Huang, Y
   Liu, ZH
   Niu, ZB
   Chai, HW
   Wu, CL
   Du, ZJ
   Li, S
AF Yang, Xuefeng
   Yu, Yanxun
   Zhang, Zhen
   Huang, Yu
   Liu, Zhihui
   Niu, Zhongbin
   Chai, Hongwei
   Wu, Chenglu
   Du, Zhijiang
   Li, Song
TI Lightweight lane marking detection CNNs by self soft label attention
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lane detection; Deep learning; Soft label; Attention; Autonomous drive;
   Semantic segmentation
AB Lane detection models based deep semantic segmentation often fail in challenging scenarios for lacking enough contextual information. In this paper, we first point out that a soft label extracted from a trained semantic segmentation model is capable of encoding rich contextual information. Then, we find that introducing the soft label extracted from the top layer of a well-trained model to low-level features gains substantial improvement. Based on this observation, we propose a novel framework, i.e., Soft Label Attention(SLA), which allows a model to learn contextual attention from the higher layer through a loss function. Significantly, our SLA does not increase the run time in the inference stage because it is only applied in the training stage. We apply the proposed SLA to modified ERFNet and propose an attention deep neural network (DNN) for lane detection (ERFNet-SLA). Tests on the TuSimple dataset show that the ERFNet-SLA outperforms ResNet-18 and ResNet-34 by 3.4% and 3.3% respectively with at least 2.3x faster in computation speed, and is 12.5x faster than SCNN with 0.6% performance loss. Tests on the CULane dataset show that the ERFNet-SLA outperforms ResNet-50 by 5.6% and is 16x faster than ResNet-101 with 0.5% performance loss.
C1 [Yang, Xuefeng; Yu, Yanxun; Zhang, Zhen; Huang, Yu; Liu, Zhihui; Niu, Zhongbin; Chai, Hongwei; Wu, Chenglu; Du, Zhijiang; Li, Song] Zhejiang Dahua Technol Co Ltd, Binan Rd, Hangzhou, Zhejiang, Peoples R China.
RP Yang, XF (corresponding author), Zhejiang Dahua Technol Co Ltd, Binan Rd, Hangzhou, Zhejiang, Peoples R China.
EM xfyang99@outlook.com
FU Zhejiang Dahua Technology Co., Ltd.
FX This work is supported by Zhejiang Dahua Technology Co., Ltd.
CR Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chiu KY, 2005, 2005 IEEE INTELLIGENT VEHICLES SYMPOSIUM PROCEEDINGS, P706
   Dean J., 2015, NIPS DEEP LEARNING R
   Fan GF, 2021, UTIL POLICY, V73, DOI 10.1016/j.jup.2021.101294
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Ghafoorian M, 2019, LECT NOTES COMPUT SC, V11129, P256, DOI 10.1007/978-3-030-11009-3_15
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hinton G. E., 2012, 12070580 ARXIV
   Hou YN, 2019, IEEE I CONF COMP VIS, P1013, DOI 10.1109/ICCV.2019.00110
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang Gao, 2018, INT C LEARN REPR
   Hur J, 2013, IEEE INT VEH SYM, P1297, DOI 10.1109/IVS.2013.6629645
   Jung H, 2013, IEEE INT VEH SYM, P976, DOI 10.1109/IVS.2013.6629593
   Komodakis N, 2017, P ICLR
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Li ZQ, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEM AND ARTIFICIAL INTELLIGENCE (ISAI 2016), P436, DOI [10.1109/ISAI.2016.0099, 10.1109/ISAI.2016.28]
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Neven D, 2018, IEEE INT VEH SYM, P286
   Pan XG, 2018, AAAI CONF ARTIF INTE, P7276
   Paszke A., 2017, NIPS W
   Paszke A., 2016, ARXIV160602147
   Romera E, 2018, IEEE T INTELL TRANSP, V19, P263, DOI 10.1109/TITS.2017.2750080
   Srinivasu PN, 2021, J REAL-TIME IMAGE PR, V18, P1773, DOI 10.1007/s11554-021-01122-x
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Tian Youjin, 2018, Procedia Computer Science, V131, P354, DOI 10.1016/j.procs.2018.04.174
   Wang Y, 2000, PATTERN RECOGN LETT, V21, P677, DOI 10.1016/S0167-8655(00)00021-0
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiao DG, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105584
   Xue X, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21121227
   Yu F., 2015, ARXIV
   Zhang HY, 2019, PR MACH LEARN RES, V97
   Zhang R, 2019, CHIN AUTOM CONGR, P4706, DOI [10.1109/CAC48633.2019.8996824, 10.1109/cac48633.2019.8996824]
   Zhang ZL, 2018, LECT NOTES COMPUT SC, V11214, P273, DOI 10.1007/978-3-030-01249-6_17
NR 34
TC 0
Z9 0
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5607
EP 5626
DI 10.1007/s11042-022-13442-6
EA JUL 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000832565900003
DA 2024-07-18
ER

PT J
AU Mahto, DK
   Singh, OP
   Singh, AK
AF Mahto, Dhiran Kumar
   Singh, Om Prakash
   Singh, Amit Kumar
TI FuSIW: fusion-based secure RGB image watermarking using hashing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Internet of things; Smart city; Security; Images; Watermarking;
   Encryption; Fusion
AB With the proliferation of the use of the Internet and social media, the digital media industry has grown enormously in recent years. However, this has brought some challenges, including issues of content security and copyright violation. In this paper, we propose a fusion-based secure watermarking algorithm that we have named "FuSIW". This uses a hashing scheme, to guarantee copyright protection and authentication of RGB images. The algorithm uses the non-subsampled contourlet transform (NSCT) to create a fused watermark image. This contourlet transform (CT) and randomised-singular-value-decomposition (RSVD) based approach allows concealment of the encrypted fused watermark image in the blue channel of the cover image. Subsequently, the hash value of the cover image is inserted into the green channels of the host image. Experimental evaluation indicates that the FuSIW algorithm provides security from geometric attacks and several other common forms of attack. Simulations indicate that the proposed system exhibits improved robustness and security compared to existing methods.
C1 [Mahto, Dhiran Kumar; Singh, Om Prakash; Singh, Amit Kumar] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Singh, AK (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
EM dhiranm.phd18.cs@nitp.ac.in; omprakash7667@gmail.com;
   amit.singh@nitp.ac.in
RI SINGH, OM PRAKASH/GLS-8702-2022; SINGH, OM PRAKASH/AFR-7033-2022
OI SINGH, OM PRAKASH/0000-0003-2582-5669; 
FU DLRL, Hyderabad, India [DLRL/21CR0003/SWCCENT/GN/LP]
FX ;This work is supported by research project order no.
   DLRL/21CR0003/SWCC&ENT/GN/LP dt. 29 August, 2020, DLRL, Hyderabad,
   India.
CR Ahmadi SBB, 2021, APPL INTELL, V51, P1701, DOI 10.1007/s10489-020-01903-0
   Amrit P, 2022, COMPUT COMMUN, V188, P52, DOI 10.1016/j.comcom.2022.02.023
   Anand A, 2022, IEEE T COMPUT SOC SY, V9, P1265, DOI 10.1109/TCSS.2021.3125025
   Anand A, 2021, SUSTAIN CITIES SOC, V75, DOI 10.1016/j.scs.2021.103398
   Du M, 2019, IEEE ACCESS, V7, P168655, DOI 10.1109/ACCESS.2019.2953878
   Gong LH, 2021, MULTIMED TOOLS APPL, V80, P439, DOI 10.1007/s11042-020-09677-w
   Haddad S, 2020, IEEE T INF FOREN SEC, V15, P2556, DOI 10.1109/TIFS.2020.2972159
   Haghighi BB, 2020, COGN COMPUT, V12, P863, DOI 10.1007/s12559-019-09700-9
   Kumar C, 2018, MULTIMED TOOLS APPL, V77, P3597, DOI 10.1007/s11042-017-5222-8
   Kumar S, 2019, HDB MULTIMED INF SEC, P37
   Mahto DK, 2021, COMPUT ELECTR ENG, V93, DOI 10.1016/j.compeleceng.2021.107255
   Mohan A, 2021, COMPUT ELECTR ENG, V95, DOI 10.1016/j.compeleceng.2021.107385
   Hernandez RAP, 2011, MIDWEST SYMP CIRCUIT
   Roy S, 2019, IJST-T ELECTR ENG, V43, P201, DOI 10.1007/s40998-018-0109-x
   Sharma S, 2023, NEURAL COMPUT APPL, V35, P4919, DOI 10.1007/s00521-020-05634-8
   Sharma S, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105696
   Singh AK, 2019, MULTIMED TOOLS APPL, V78, P30523, DOI 10.1007/s11042-018-7115-x
   Singh KN, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3498342
   Singh OP, 2021, MULTIMED TOOLS APPL, V80, P30367, DOI 10.1007/s11042-020-09606-x
   Singh SP, 2017, IEEE I C SIGNAL IMAG, P440, DOI 10.1109/ICSIPA.2017.8120651
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P8781, DOI 10.1007/s11042-016-3522-z
   Tian C, 2020, MULTIMED TOOLS APPL, V79, P7515, DOI 10.1007/s11042-019-08530-z
   Vaidya SP, 2017, MULTIMED TOOLS APPL, V76, P25623, DOI 10.1007/s11042-017-4355-0
   Wan WB, 2022, NEUROCOMPUTING, V488, P226, DOI 10.1016/j.neucom.2022.02.083
   Wang KS, 2022, MULTIMED TOOLS APPL, V81, P6159, DOI 10.1007/s11042-021-11725-y
   Xiang SJ, 2022, FRONT COMPUT SCI-CHI, V16, DOI 10.1007/s11704-020-0112-z
   Yang Y, 2022, IEEE T CIRC SYST VID, V32, P1860, DOI 10.1109/TCSVT.2021.3084676
   Zear A, 2022, MULTIMED TOOLS APPL, V81, P26721, DOI 10.1007/s11042-020-10472-w
   Zhang H, 2022, J FRANKLIN I, V359, P1755, DOI 10.1016/j.jfranklin.2021.11.027
NR 29
TC 1
Z9 1
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 JUL 22
PY 2022
DI 10.1007/s11042-022-13454-2
EA JUL 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3C9LD
UT WOS:000828935900001
DA 2024-07-18
ER

PT J
AU Hajihashemi, V
   Gharahbagh, AA
   Bastanfard, A
   Oliveira, HS
   Almeida, G
   Ma, Z
   Tavares, JMRS
AF Hajihashemi, Vahid
   Gharahbagh, Abdoreza Alavi
   Bastanfard, Azam
   Oliveira, Hugo S.
   Almeida, Goncalo
   Ma, Zhen
   Tavares, Joao Manuel R. S.
TI A Hierarchical modified AV1 codec for compression cartesian form of
   holograms in holo and object planes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compression; Digital holography; AV1; Wavelet; Interpolation
ID DIGITAL HOLOGRAM; SCHEME; HEVC
AB Three-dimensional (3D) image reconstruction is emerging as a leading challenge for 3D media on the Internet and virtual reality. In this regard, compression performance in 3D technology is one of the most important issues. Various codecs such as HEVC and AV1 have been suggested to improve compression performance in 3D technology. In this study, a hybrid method based on AV1 codec combined with mathematical methods is proposed for improving the quality of this codec. In the proposed method, two AV1 compression steps are used to estimate the AV1 codec error using a linear relationship and added to the basic codec output to improve the compression performance. The proposed method shows better quality in the Cartesian form (real and imaginary parts) of the hologram in Holo and Object plane when compared to new codecs that have been proposed in the field of 3D compression. In addition, the proposed method can be used as a general compression method for 2D images. Based on simulation results, the proposed method improved the quality of reconstructed hologram by up to 63% and 5 dB in terms of BDRate and BDPSNR, respectively.
C1 [Hajihashemi, Vahid; Gharahbagh, Abdoreza Alavi; Oliveira, Hugo S.; Ma, Zhen] Univ Porto, Fac Engn, Porto, Portugal.
   [Bastanfard, Azam] Islamic Azad Univ, Dept Comp Enng, Karaj Branch, Karaj, Iran.
   [Almeida, Goncalo] Univ Porto, Inst Ciencia & Inovacao Engn Mecan & Engn Ind, Fac Engn, Porto, Portugal.
   [Tavares, Joao Manuel R. S.] Univ Porto, Inst Ciencia & Inovacao Engn Mecan & Engn Ind, Dept Engn Mecan, Fac Engn, Porto, Portugal.
C3 Universidade do Porto; Islamic Azad University; Universidade do Porto;
   Universidade do Porto
RP Hajihashemi, V (corresponding author), Univ Porto, Fac Engn, Porto, Portugal.
EM Hajihashemi.vahid@ieee.org; abalavi.gh@ieee.org; Bastanfard@kiau.ac.ir;
   hmso.lsa@gmail.com; galmeida@inegi.up.pt; zhen.ma@fe.up.pt;
   tavares@fe.up.pt
RI Bastanfard, Azam/AAX-8571-2020; Tavares, João Manuel R.S./M-5305-2013;
   Hajihashemi, Vahid/KEZ-9848-2024
OI Bastanfard, Azam/0000-0002-7935-819X; Tavares, João Manuel
   R.S./0000-0001-7603-6526; Sampaio Almeida, Goncalo/0000-0001-5746-0508;
   Ma, Zhen/0000-0001-6855-4622; Alavi Gharahbagh,
   Abdorreza/0000-0003-0863-1977
CR Amirkhani D, 2021, MULTIMED TOOLS APPL, V80, P26199, DOI 10.1007/s11042-021-10883-3
   [Anonymous], 2016, 2016 PICTURE CODING
   [Anonymous], 2016, DIRECTIONAL DERINGIN
   Bernardo MV, 2021, SIGNAL PROCESS-IMAGE, V96, DOI 10.1016/j.image.2021.116306
   Bernardo MV, 2018, SIGNAL PROCESS-IMAGE, V68, P193, DOI 10.1016/j.image.2018.08.006
   Birnbaum T, 2018, DIGITAL HOLOGRAPHY 3, pDW2F
   Blinder D, 2018, THESIS
   Blinder D, 2019, SIGNAL PROCESS-IMAGE, V70, P114, DOI 10.1016/j.image.2018.09.014
   Blinder D, 2016, OPT EXPRESS, V24, P23094, DOI 10.1364/OE.24.023094
   Blinder D, 2015, INT WORK QUAL MULTIM
   Blinder D, 2014, OPT ENG, V53, DOI 10.1117/1.OE.53.12.123102
   Chen Y, 2018, PICT COD SYMP, P41, DOI 10.1109/PCS.2018.8456249
   Dufaux F, 2015, PROC SPIE, V9599, DOI 10.1117/12.2190997
   Fonseca E, 2019, INT WORK QUAL MULTIM
   Gao C, 2015, OPT EXPRESS, V23, P33194, DOI 10.1364/OE.23.033194
   Hajihashemi V, 2021, MULTIMED TOOLS APPL, V80, P31953, DOI 10.1007/s11042-021-11232-0
   Kim JK, 2020, OPT EXPRESS, V28, P36327, DOI 10.1364/OE.406165
   Ko H, 2021, IEEE ACCESS
   Bang LT, 2011, OPT EXPRESS, V19, P8019, DOI 10.1364/OE.19.008019
   Monroy F, 2011, HOLOGRAPHY DIFFERENT
   Muhamad RK, 2021, APPL OPTICS, V60, P641, DOI 10.1364/AO.404305
   Mukherjee D, 2013, PICT COD SYMP, P390, DOI 10.1109/PCS.2013.6737765
   Nemetallah Georges., 2015, ANALOG DIGITAL HOLOG
   Peixeiro JP, 2018, IEEE T MULTIMEDIA, V20, P282, DOI 10.1109/TMM.2017.2742701
   Picart P., 2020, Optical holography-materials, theory and applications, P83, DOI [10.1016/B978- 0-12- 815467- 0.00005-0, DOI 10.1016/B978-0-12-815467-0.00005-0]
   Poon T.- C., 2014, Introduction to Modern Digital Holography: with MATLAB
   Schelkens P, 2019, ETRI J, V41, P93
   Shimobaba T, 2019, OPT LETT, V44, P3038, DOI 10.1364/OL.44.003038
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Taubman DS, 2002, P IEEE, V90, P1336, DOI 10.1109/JPROC.2002.800725
   Viswanathan K, 2013, PROC SPIE, V8856, DOI 10.1117/12.2027199
   Viswanathan K, 2015, IEEE IMAGE PROC, P3334, DOI 10.1109/ICIP.2015.7351421
   Xing Y., 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P172
   Xing YF, 2015, APPL OPTICS, V54, pA98, DOI 10.1364/AO.54.000A98
   Yaroslavsky L., 2009, INTRO DIGITAL HOLOGR
NR 35
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8303
EP 8321
DI 10.1007/s11042-021-11567-8
EA JUL 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000825912900003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Nasiri, E
   Berahmand, K
   Li, YF
AF Nasiri, Elahe
   Berahmand, Kamal
   Li, Yuefeng
TI Robust graph regularization nonnegative matrix factorization for link
   prediction in attributed networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Complex network; Link prediction; Nonnegative matrix factorization;
   Attributed network
ID CLASSIFICATION
AB Link prediction is one of the most widely studied problems in the area of complex network analysis, in which machine learning techniques can be applied to deal with it. The biggest drawback of the existing methods, however, is that in most cases they only consider the topological structure of the network, and therefore completely miss out on the great potential that stems from the nodal attributes. Both topological structure and nodes' attributes are essential in predicting the evolution of attributed networks and can act as complements to each other. To bring out their full potential in solving the link prediction problem, a novel Robust Graph Regularization Nonnegative Matrix Factorization for Attributed Networks (RGNMF-AN) was proposed, which models not only the topology structure of networks but also their node attributes for direct link prediction. This model, in particular, combines two types of information, namely network topology, and nodal attributes information, and calculates high-order proximities between nodes using the Structure-Attribute Random Walk Similarity (SARWS) method. The SARWS score matrix is an indicator structural and attributed matrix that collects more useful attributed information in high-order proximities, whereas graph regularization technology combines the SARWS score matrix with topological and attribute information to collect more valuable attributed information in high-order proximities. Furthermore, the RGNMF-AN employs the l(2,1)-norm to constrain the loss function and regularization terms, effectively removing random noise and spurious links. According to empirical findings on nine real-world complex network datasets, the use of a combination of attributed and topological information in tandem enhances the prediction performance significantly compared to the baseline and other NMF-based algorithms.
C1 [Nasiri, Elahe] Azarbaijan Shahid Madani Univ, Dept Informat Technol & Commun, Tabriz, Iran.
   [Berahmand, Kamal; Li, Yuefeng] Queensland Univ Technol QUT, Fac Sci, Sch Comp Sci, Brisbane, Qld, Australia.
C3 Azarbaijan Shahid Madani University; Queensland University of Technology
   (QUT)
RP Berahmand, K (corresponding author), Queensland Univ Technol QUT, Fac Sci, Sch Comp Sci, Brisbane, Qld, Australia.
EM el.nasiri@azaruniv.ac.ir; kamal.berahmand@hdr.qut.edu.au;
   y2.li@qut.edu.au
RI Li, Yue/B-7669-2016; LI, Yue/GRS-8071-2022; berahmand,
   kamal/ABH-1804-2020
OI Li, Yue/0000-0001-9562-3136; berahmand, kamal/0000-0003-4459-0703
CR Aggarwal CC, 2011, P 2011 SIAM INT C DA
   Aiello LM, 2012, ACM T WEB, V6, DOI 10.1145/2180861.2180866
   [Anonymous], 2011, P 20 ACM INT C INF K
   Bandyopadhyay S., 2018, ARXIV PREPRINT ARXIV
   Berahmand K, 2021, COMPUT BIOL MED, V138, DOI 10.1016/j.compbiomed.2021.104933
   Berahmand K, 2021, COMPUTING, V103, P2227, DOI 10.1007/s00607-021-00982-2
   Berahmand K, 2022, J KING SAUD UNIV-COM, V34, P1869, DOI 10.1016/j.jksuci.2020.08.013
   Bhagat S, 2011, SOCIAL NETWORK DATA ANALYTICS, P115
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Cai HY, 2018, IEEE T KNOWL DATA EN, V30, P1616, DOI 10.1109/TKDE.2018.2807452
   Cao SS, 2016, AAAI CONF ARTIF INTE, P1145
   Chen BL, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182968
   Chen GF, 2020, EXPERT SYST APPL, V148, DOI 10.1016/j.eswa.2020.113290
   Chen GF, 2020, PHYSICA A, V539, DOI 10.1016/j.physa.2019.122882
   Chen GF, 2019, NEUROCOMPUTING, V369, P50, DOI 10.1016/j.neucom.2019.08.068
   Chunaev P, 2020, COMPUT SCI REV, V37, DOI 10.1016/j.cosrev.2020.100286
   Currarini S, 2016, EUR ECON REV, V90, P18, DOI 10.1016/j.euroecorev.2016.03.011
   Dev P, 2016, J PUBLIC ECON THEORY, V18, P268, DOI 10.1111/jpet.12142
   Divakaran A, 2020, NEW GENERAT COMPUT, V38, P213, DOI 10.1007/s00354-019-00065-z
   Esmaeili M, 2021, IEEE T NETW SCI ENG, V8, P1957, DOI 10.1109/TNSE.2021.3078612
   Forouzandeh S, 2021, ENG APPL ARTIF INTEL, V104, DOI 10.1016/j.engappai.2021.104325
   Forouzandeh S, 2021, MULTIMED TOOLS APPL, V80, P7805, DOI 10.1007/s11042-020-09949-5
   Franceschini A, 2016, BIOINFORMATICS, V32, P1085, DOI 10.1093/bioinformatics/btv696
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Guimerà R, 2009, P NATL ACAD SCI USA, V106, P22073, DOI 10.1073/pnas.0908366106
   Guo Yanzhi, 2010, BMC Res Notes, V3, P145, DOI 10.1186/1756-0500-3-145
   Hamilton WL, 2017, ADV NEUR IN, V30
   Huang Z, 2005, ACM-IEEE J CONF DIG, P141, DOI 10.1145/1065385.1065415
   Keikha MM, 2021, J INF SCI, V47, P642, DOI 10.1177/0165551519891345
   Kim YD, 2009, INT CONF ACOUST SPEE, P1541, DOI 10.1109/ICASSP.2009.4959890
   Kumar A, 2020, PHYSICA A, V553, DOI 10.1016/j.physa.2020.124289
   Kumar A, 2020, PHYSICA A, V545, DOI 10.1016/j.physa.2019.123790
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Li J, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1419, DOI 10.1145/3132847.3132926
   Li YF, 2013, SOURCE CODE BIOL MED, V8, DOI 10.1186/1751-0473-8-10
   Liu WP, 2010, EPL-EUROPHYS LETT, V89, DOI 10.1209/0295-5075/89/58007
   Lü LY, 2011, PHYSICA A, V390, P1150, DOI 10.1016/j.physa.2010.11.027
   Ma XK, 2018, PHYSICA A, V496, P121, DOI 10.1016/j.physa.2017.12.092
   Ma XK, 2017, PATTERN RECOGN, V71, P361, DOI 10.1016/j.patcog.2017.06.025
   Masrour F, 2018, 2018 IEEEACM INT C A
   Mehrpooya A, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbab410
   Menon AK, 2011, LECT NOTES ARTIF INT, V6912, P437, DOI 10.1007/978-3-642-23783-6_28
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Mokhtia M, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106255
   Muniz CP, 2018, KNOWL-BASED SYST, V156, P129, DOI 10.1016/j.knosys.2018.05.027
   Nasiri E, 2021, CHAOS SOLITON FRACT, V151, DOI 10.1016/j.chaos.2021.111230
   Nasiri E, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104772
   Nasiri E, 2019, EUR PHYS J B, V92, DOI 10.1140/epjb/e2019-100225-8
   Newman MEJ, 2001, PHYS REV E, V64, DOI [10.1103/PhysRevE.64.016132, 10.1103/PhysRevE.64.016131]
   Ou MD, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1105, DOI 10.1145/2939672.2939751
   Pan S., 2016, P 25 INT JOINT C ART, V11, P12, DOI DOI 10.1145/2623330.2623732
   Pavlov M., 2007, FEWS, V290, P42
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732
   Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854
   Qian B, 2016, 2016 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P100
   Saberi-Movahed F, 2021, MEDRXIV
   Saberi-Movahed F, 2020, INT J MACH LEARN CYB, V11, P1405, DOI 10.1007/s13042-019-01046-w
   Sen P, 2008, AI MAG, V29, P93, DOI 10.1609/aimag.v29i3.2157
   Tropp JA, 2003, LIT SURVEY NONNEGATI, P26, DOI DOI 10.1016/J.NEUNET.2021.03.020
   Vidal R, 2005, IEEE T PATTERN ANAL, V27, P1945, DOI 10.1109/TPAMI.2005.244
   Wang C, 2007, IEEE DATA MINING, P322, DOI 10.1109/ICDM.2007.108
   Wang DX, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1225, DOI 10.1145/2939672.2939753
   Wang D, 2016, IEEE ACM T COMPUT BI, V13, P1059, DOI 10.1109/TCBB.2015.2505294
   Wang P., 2015, SCI CHINA INFORM SCI, V58, P1
   Wang W, 2021, ACM T WEB, V15, DOI 10.1145/3409736
   Wang X, 2017, AAAI CONF ARTIF INTE, P203
   Xie JW, 2017, J NEUROSCI METH, V282, P81, DOI 10.1016/j.jneumeth.2017.03.008
   Xu B, 2018, BMC BIOINFORMATICS, V19, DOI 10.1186/s12859-018-2555-x
   Yang C, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2111
   Yuan GC, 2014, PROCEEDINGS OF THE 8TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'14), P17, DOI 10.1145/2645710.2645734
NR 70
TC 56
Z9 57
U1 18
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3745
EP 3768
DI 10.1007/s11042-022-12943-8
EA JUL 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000825912900001
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Abel, JDK
   Dhanalakshmi, S
   Kumar, R
AF Abel, Jaba Deva Krupa
   Dhanalakshmi, Samiappan
   Kumar, R.
TI A comprehensive survey on signal processing and machine learning
   techniques for non-invasive fetal ECG extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fetal electrocardiography; Congenital heart defects; Stillbirths;
   Maternal ECG; Abdominal ECG
ID QRS COMPLEX DETECTION; HEART-RATE ESTIMATION; R-PEAK DETECTION;
   ELECTROCARDIOGRAM EXTRACTION; ABDOMINAL ECG; SOURCE SEPARATION;
   ALGORITHM; FRAMEWORK; MODE; COMPONENTS
AB Despite the rapid growth in the area of adult ECG signal processing and monitoring systems, the morphological analysis of fetal ECG signals lags farther behind and demands much attention. Non-invasive fetal Electrocardiography is the safest approach for monitoring the fetus health condition by processing the abdominal ECG (AECG) signals acquired by placing electrodes on the mother's abdomen. The primary challenge associated with this method is the very poor SNR of the signal recorded because of dominant maternal ECG and other interferences contained in the AECG signal. This paper aims to provide an extensive review of the existing state of art techniques for extracting the fetal ECG signal from the AECG signals. We present details on methods available in modeling the fetal ECG, challenges associated with electrode placements, morphological analysis of extracted fetal ECG, and evaluation metrics for measuring the performance of extraction techniques. This paper provides the researchers with a detailed understanding of the problem of interest and helps in addressing future directions for processing the abdominal ECG signals.
C1 [Abel, Jaba Deva Krupa; Dhanalakshmi, Samiappan; Kumar, R.] SRM Inst Sci & Technol, Fac Engn & Technol, Coll Engn & Technol, Dept ECE, Kancheepuram 603203, India.
C3 SRM Institute of Science & Technology Chennai
RP Dhanalakshmi, S (corresponding author), SRM Inst Sci & Technol, Fac Engn & Technol, Coll Engn & Technol, Dept ECE, Kancheepuram 603203, India.
EM dhanalas@srmist.edu.in
RI Dhanalakshmi, S./J-2073-2018
OI Dhanalakshmi, S./0000-0002-6970-2719
CR Abel JDK, 2019, PROCEDIA COMPUT SCI, V165, P182, DOI 10.1016/j.procs.2020.01.093
   Adimoolam M, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12884
   Akhavan-Amjadi M, 2020, MULTIDIM SYST SIGN P, V31, P117, DOI 10.1007/s11045-019-00653-8
   Andreotti F, 2016, PHYSIOL MEAS, V37, P627, DOI 10.1088/0967-3334/37/5/627
   Andreotti F, 2014, PHYSIOL MEAS, V35, P1551, DOI 10.1088/0967-3334/35/8/1551
   Anisha M, 2021, BIOMED SIGNAL PROCES, V65, DOI 10.1016/j.bspc.2020.102308
   Assaleh K, 2007, IEEE T BIO-MED ENG, V54, P59, DOI 10.1109/TBME.2006.883728
   Behar J, 2016, ARXIV PREPRINT ARXIV
   Behar J, 2016, PHYSIOL MEAS, V37, pR1, DOI 10.1088/0967-3334/37/5/R1
   Behar J, 2014, PHYSIOL MEAS, V35, P1537, DOI 10.1088/0967-3334/35/8/1537
   Behar J, 2014, ANN BIOMED ENG, V42, P1340, DOI 10.1007/s10439-014-0993-9
   Behar JA, 2019, PRENATAL DIAG, V39, P178, DOI 10.1002/pd.5412
   Bhutto ZA, 2011, LANCET, V377, P1523, DOI 10.1016/S0140-6736(10)62269-6
   BLAAS HG, 1995, ULTRASOUND OBST GYN, V6, P240, DOI 10.1046/j.1469-0705.1995.06040240.x
   Callaerts D, 1989, THESIS KU LEUVEN
   Camps G, 2001, COMPUT CARDIOL, V28, P249, DOI 10.1109/CIC.2001.977639
   Camps-Valls G, 2004, ARTIF INTELL MED, V31, P197, DOI 10.1016/j.artmed.2004.03.005
   Castillo E, 2013, DIGIT SIGNAL PROCESS, V23, P1897, DOI 10.1016/j.dsp.2013.07.010
   De Moor B., 1997, Journal A, V38, P4
   Dessì A, 2014, PHYSIOL MEAS, V35, P1621, DOI 10.1088/0967-3334/35/8/1621
   Fatemi M, 2017, IJST-T ELECTR ENG, V41, P65, DOI 10.1007/s40998-017-0018-4
   FAVRET AG, 1968, MED BIOL ENG, V6, P467, DOI 10.1007/BF02474285
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Goodyer A V, 1942, Yale J Biol Med, V15, P1
   Gupta P, 2016, COMPUT BIOL MED, V68, P121, DOI 10.1016/j.compbiomed.2015.11.007
   Gupta V, 2021, CHAOS SOLITON FRACT, V144, DOI 10.1016/j.chaos.2021.110708
   Gurve D, 2020, IEEE J BIOMED HEALTH, V24, P669, DOI 10.1109/JBHI.2019.2920356
   Haghpanahi M, 2013, COMPUT CARDIOL CONF, V40, P173
   Hasan M. A., 2009, Journal of Software Engineering and Applications, V2, P330, DOI 10.4236/jsea.2009.25043
   Hasan MA, 2009, BIOL PROCED ONLINE, V11, P263, DOI 10.1007/s12575-009-9006-z
   HON E H, 1960, Conn Med, V24, P289
   Huque ASA, 2019, IRBM, V40, P157, DOI 10.1016/j.irbm.2019.04.004
   Jafari MG, 2005, IEEE T BIO-MED ENG, V52, P390, DOI 10.1109/TBME.2004.842958
   Jamshidian-Tehrani F, 2020, IEEE T BIO-MED ENG, V67, P1377, DOI 10.1109/TBME.2019.2936943
   Jaros R, 2019, IEEE ACCESS, V7, P131758, DOI 10.1109/ACCESS.2019.2933717
   Jezewski J, 2012, BIOMED ENG-BIOMED TE, V57, P383, DOI 10.1515/bmt-2011-0130
   John RG, 2019, COMPUT METH PROG BIO, V175, P193, DOI 10.1016/j.cmpb.2019.04.022
   Karvounis EC, 2009, IEEE T BIO-MED ENG, V56, P1394, DOI 10.1109/TBME.2009.2014691
   Krupa AJD, 2022, BIOMED SIGNAL PROCES, V75, DOI 10.1016/j.bspc.2022.103569
   Krupa AJD, 2021, BIOCYBERN BIOMED ENG, V41, P1533, DOI 10.1016/j.bbe.2021.09.006
   Krupa AJD, 2021, BIOMED ENG-BIOMED TE, V66, P503, DOI 10.1515/bmt-2020-0313
   Kulathilake KASH, 2023, COMPLEX INTELL SYST, V9, P2713, DOI 10.1007/s40747-021-00405-x
   Lathauwer L.D., 1995, PROOCEDINGS IEEEATHO, P134
   Li RL, 2017, FRONT PHYSIOL, V8, DOI 10.3389/fphys.2017.00277
   Li S, 2017, FRONT APPL MATH STAT, V3, P2, DOI DOI 10.3389/FAMS.2017.00002
   Li YX, 2008, NEUROCOMPUTING, V71, P1538, DOI 10.1016/j.neucom.2007.05.001
   Lindsley DB, 1942, AM J PSYCHOL, V55, P412, DOI 10.2307/1417473
   Lipponen JA, 2014, PHYSIOL MEAS, V35, P1637, DOI 10.1088/0967-3334/35/8/1637
   Liu CY, 2014, PHYSIOL MEAS, V35, P1665, DOI 10.1088/0967-3334/35/8/1665
   Ma YP, 2018, IET SIGNAL PROCESS, V12, P219, DOI 10.1049/iet-spr.2016.0605
   Ma YP, 2014, ASIAPAC SIGN INFO PR
   Ma YP, 2016, MEAS SCI TECHNOL, V27, DOI 10.1088/0957-0233/27/1/015703
   Martens SMM, 2007, PHYSIOL MEAS, V28, P373, DOI 10.1088/0967-3334/28/4/004
   Matonia A, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-0538-z
   Najafabadi FS, 2006, COMPUT BIOL MED, V36, P241, DOI 10.1016/j.compbiomed.2004.11.004
   NHS, 2014, CONGENIT HEART DIS
   Niknazar M, 2013, IEEE T BIO-MED ENG, V60, P1345, DOI 10.1109/TBME.2012.2234456
   Nizar MHA, 2019, J MED IMAG HEALTH IN, V9, P9, DOI 10.1166/jmihi.2019.2563
   Panigrahy D, 2017, AUSTRALAS PHYS ENG S, V40, P191, DOI 10.1007/s13246-017-0527-5
   Peters M, 2001, J PERINAT MED, V29, P408, DOI 10.1515/JPM.2001.057
   Praneeth CNVS, 2020, BIOMED ENG-APP BAS C, V32, DOI 10.4015/S101623722050026X
   Rajanna RR, 2022, IEEE REV BIOMED ENG, V15, P273, DOI 10.1109/RBME.2021.3055219
   Reaz MBI, 2004, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON INTELLIGENT SENSING AND INFORMATION PROCESSING, P321
   Redif S, 2016, TURK J ELECTR ENG CO, V24, P2483, DOI 10.3906/elk-1401-19
   Sameni R., 2008, Ph.D. dissertation
   Sameni Reza, 2010, Open Pacing Electrophysiol Ther J, V3, P4
   Samiappan D, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S021800142051009X
   Samiappan D, 2016, INT ARAB J INF TECHN, V13, P756
   Sana F, 2019, BIOMED SIGNAL PROCES, V48, P46, DOI 10.1016/j.bspc.2018.08.023
   Sato M, 2007, IEEE T BIO-MED ENG, V54, P49, DOI 10.1109/TBME.2006.883791
   Sevim Y, 2011, TURK J ELECTR ENG CO, V19, P657, DOI 10.3906/elk-0912-311
   Shadaydeh M., 2008, 2008 16th European Signal Processing Conference, P1, DOI DOI 10.1016/j.jsha.2011.01.008
   Silva I, 2013, COMPUT CARDIOL CONF, V40, P149
   Speedie J, 2014, ABORTION CARE, P153
   Stenberg K, 2014, LANCET, V383, P1333, DOI 10.1016/S0140-6736(13)62231-X
   Suganthy M, 2019, CLUSTER COMPUT, V22, pS3875, DOI 10.1007/s10586-018-2477-4
   Sulas E, 2021, SCI DATA, V8, DOI 10.1038/s41597-021-00811-3
   SUREAU C, 1963, MED ELECTRONICS AND BIOL ENGNG, V1, P181, DOI 10.1007/BF02475886
   Sweha A, 1999, AM FAM PHYSICIAN, V59, P2487
   Symonds E. M., 2001, Fetal electrocardiography
   Taha LY, 2020, CAN J ELECT COMPUT E, V43, P295, DOI 10.1109/CJECE.2020.2984602
   Ungureanu GM, 2009, COMPUT BIOL MED, V39, P562, DOI 10.1016/j.compbiomed.2009.03.013
   VANOOSTEROM A, 1986, J PERINAT MED, V14, P411, DOI 10.1515/jpme.1986.14.6.411
   Varanini M, 2014, PHYSIOL MEAS, V35, P1607, DOI 10.1088/0967-3334/35/8/1607
   Varanini M, 2017, COMPUT BIOL MED, V85, P125, DOI 10.1016/j.compbiomed.2016.04.008
   Verdurmen KMJ, 2016, BMC PREGNANCY CHILDB, V16, DOI 10.1186/s12884-016-1021-x
   VINTZILEOS AM, 1995, OBSTET GYNECOL, V85, P149, DOI 10.1016/0029-7844(94)00320-D
   Vullings R, 2010, PHYSIOL MEAS, V31, P935, DOI 10.1088/0967-3334/31/7/005
   Vullings R, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/109756
   Warmerdam GJJ, 2018, IEEE T SIGNAL PROCES, V66, P4388, DOI 10.1109/TSP.2018.2853144
   WIDROW B, 1975, P IEEE, V63, P1692, DOI 10.1109/PROC.1975.10036
   Zarzoso V, 2001, IEEE T BIO-MED ENG, V48, P12, DOI 10.1109/10.900244
   Zaunseder S., 2012, 7 INT WORKSH BIOS IN
   Zhang Y, 2020, MED BIOL ENG COMPUT, V58, P419, DOI 10.1007/s11517-019-02087-7
   Zheng W, 2018, BIOMED SIGNAL PROCES, V42, P287, DOI 10.1016/j.bspc.2018.01.024
   Zheng W, 2010, MED ENG PHYS, V32, P708, DOI 10.1016/j.medengphy.2010.04.012
   Zhong W, 2020, INT J DATA MIN BIOIN, V23, P160
   Zhong W, 2019, AUSTRALAS PHYS ENG S, V42, P1081, DOI 10.1007/s13246-019-00805-x
   Zhong W, 2018, PHYSIOL MEAS, V39, DOI 10.1088/1361-6579/aab297
NR 99
TC 13
Z9 13
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 1373
EP 1400
DI 10.1007/s11042-022-13391-0
EA JUL 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000825002600001
DA 2024-07-18
ER

PT J
AU Kumar, KS
   Singh, NP
AF Kumar, K. Susheel
   Singh, Nagendra Pratap
TI Analysis of retinal blood vessel segmentation techniques: a systematic
   survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Retinal images; Matched filter; Thresholding; Multi-scaling; Vessel
   tracking; Mathematical morphology; Fuzzy c means; Vessel profile model;
   Machine learning
ID MATCHED-FILTER; FUNDUS IMAGES; AUTOMATED DETECTION; GRAY-LEVEL;
   RED-FREE; EXTRACTION; ALGORITHM; MODEL; ENHANCEMENT; SET
AB Segmentation of Blood Vessel is a challenging mission in medical image processing to diagnose the disease. It evaluates vessels crucial in automatic retinal vessel extraction with different methodologies, techniques and algorithms to predict the diseases such as Laryngology, neurosurgery and ophthalmology. Using a computer-aided technique, segmentation of blood vessels is conducted in the retina closer to the clinical application routine. This research aims to provide an overview of numerous retinal vessel segmentation approaches, analyse different categories of segmentation techniques, provide a brief description, and evaluate the performance measures. It also reviews, examines, and classifies the procedures, techniques, and methodologies and highlights the important points. The main intention is to provide the reader with a framework for the existing research, introduce the range of retinal vessel segmentation procedures, deliberate the current trends and future directions and summarize the open problems. First, retinal image photography is introduced from the fundus camera. Pre-processing operations and methods of identifying retinal vessels on computer-aided techniques are introduced and discussed to validate results based on the evaluation of various segmentation techniques. The performance of various segmentation techniques and algorithms is estimated using a publicly present database such as DRIVE, STARE, HRF, CHASE, Infant and MESSIDOR. The performance and comparison of various algorithms are assessed in average accuracy, sensitivity, specificity and ROC curves. A huge volume of techniques is considered based on retinal vessel segmentation published in current years. A systematic review is constructed by considering the publications from 2001 to 2021, focusing on methods based on automatic vessel segmentation and classification using fundus camera images. The advantages and limitations are discussed, and tables are included for summarising results at-a-glance. Then an attempt is made to measure the quantitative merit of segmentation methods in terms of accuracy development compared to other methods. Finally, it represented the recent trends with the future direction and summarized the open challenge issues.
C1 [Kumar, K. Susheel; Singh, Nagendra Pratap] Natl Inst Technol, Dept Comp Sci & Engn, Hamirpur, HP, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Hamirpur
RP Kumar, KS (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Hamirpur, HP, India.
EM sus.iiita.932@gmail.com; nps@nith.ac.in
RI Kumar, Dr K. Susheel/AHC-2432-2022; Singh, Nagendra Pratap/JRY-4378-2023
OI Kumar, Dr K. Susheel/0000-0002-1565-7932; 
CR Abdallah M.B., 2011, Eighth International Multi-Conference on Systems, Signals Devices, P1, DOI [10.1109/SSD.2011.5767376, DOI 10.1109/SSD.2011.5767376]
   Adapa D, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0229831
   Adel M, 2009, IEEE IMAGE PROC, P649, DOI 10.1109/ICIP.2009.5413396
   Akhavan R., 2014, International Journal of Electrical and Computer Engineering, V4, P561, DOI DOI 10.11591/IJECE.V4I4.6253
   Akram M. Usman, 2009, 2009 3rd International Conference on Information and Communication Technologies (ICICT), P181, DOI 10.1109/ICICT.2009.5267194
   Al-Diri B, 2009, IEEE T MED IMAGING, V28, P1488, DOI 10.1109/TMI.2009.2017941
   Al-Rawi M, 2007, COMPUT BIOL MED, V37, P262, DOI 10.1016/j.compbiomed.2006.03.003
   Ali A., 2019, INDONES J ELECT ENG, V13, P1199, DOI DOI 10.11591/IJEECS.V13.I3.PP1199-1207
   Almotiri J, 2018, IEEE J TRANSL ENG HE, V6, DOI 10.1109/JTEHM.2018.2835315
   Amin MA, 2011, SOFT COMPUT, V15, P1217, DOI 10.1007/s00500-010-0574-2
   An CH, 2020, PROC SPIE, V11511, DOI 10.1117/12.2569858
   Anzalone A, 2008, COMPUT BIOL MED, V38, P913, DOI 10.1016/j.compbiomed.2008.05.006
   Aswini S., 2018, P 4 IEEE INT C ADV E, P1, DOI [DOI 10.1109/AEEICB.2018.8480970, 10.1109/aeeicb.2018.8480970]
   Ayala G, 2005, IEEE T FUZZY SYST, V13, P384, DOI 10.1109/TFUZZ.2004.839667
   Balasubramanian K, 2021, J AMB INTEL HUM COMP, V12, P3559, DOI 10.1007/s12652-019-01559-w
   Bansal M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03488-z
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Albargathe SMBK, 2021, MULTIMED TOOLS APPL, V80, P2565, DOI 10.1007/s11042-020-09646-3
   Boudegga H, 2021, COMPUT MED IMAG GRAP, V90, DOI 10.1016/j.compmedimag.2021.101902
   Budai A., 2010, Bildverarbeitung fur die Medizin, V574, P261
   Bühler K, 2004, MATH VISUAL, P399
   Chakraborty S, 2017, 2017 4TH IEEE UTTAR PRADESH SECTION INTERNATIONAL CONFERENCE ON ELECTRICAL, COMPUTER AND ELECTRONICS (UPCON), P618, DOI 10.1109/UPCON.2017.8251120
   Chakraborty S, 2009, EUR J PHARM BIOPHARM, V73, P1, DOI 10.1016/j.ejpb.2009.06.001
   Chanwimaluang T, 2003, IEEE IMAGE PROC, P1093
   Chatterjee I, 2018, MULTIMED TOOLS APPL, V77, P26991, DOI 10.1007/s11042-018-5901-0
   Cheng YL, 2020, MATH BIOSCI ENG, V17, P3088, DOI 10.3934/mbe.2020175
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Christodoulidis A, 2016, COMPUT MED IMAG GRAP, V52, P28, DOI 10.1016/j.compmedimag.2016.06.001
   Cinsdikici MG, 2009, COMPUT METH PROG BIO, V96, P85, DOI 10.1016/j.cmpb.2009.04.005
   Dada, 2018, COVENANT J INFORM CO, V6, P64
   Dasgupta A, 2017, I S BIOMED IMAGING, P248, DOI 10.1109/ISBI.2017.7950512
   Dash Jyotiprava, 2019, Soft Computing and Signal Processing. Proceedings of ICSCSP 2018. Advances in Intelligent Systems and Computing (AISC 900), P603, DOI 10.1007/978-981-13-3600-3_57
   Dash Jyotiprava, 2017, Future Computing and Informatics Journal, V2, P103, DOI 10.1016/j.fcij.2017.10.001
   Dash S, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11112017
   Dash S, 2021, INT J IMAG SYST TECH, V31, P351, DOI 10.1002/ima.22461
   De J, 2016, IEEE T MED IMAGING, V35, P257, DOI 10.1109/TMI.2015.2465962
   Delibasis KK, 2010, COMPUT METH PROG BIO, V100, P108, DOI 10.1016/j.cmpb.2010.03.004
   Dizdaroglu B, 2012, IEEE INT WORKS MACH
   Dora DP, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P4, DOI 10.1109/SPIN.2016.7566652
   dos Santos JCM, 2020, RES BIOMED ENG, P1, DOI DOI 10.1007/S42600-020-00046-Y
   Elangovan P., 2021, Indian J. Radio Space Phys, V50, P33
   Elangovan P, 2021, INT J IMAG SYST TECH, V31, P955, DOI 10.1002/ima.22494
   Emary E, 2014, IEEE IJCNN, P1792, DOI 10.1109/IJCNN.2014.6889932
   Espona L, 2008, INT C PATT RECOG, P2128
   Espona L., 2007, IBPRIA 2007, P4478
   Farnell DJJ, 2008, J FRANKLIN I, V345, P748, DOI 10.1016/j.jfranklin.2008.04.009
   Faust O, 2012, J MED SYST, V36, P145, DOI 10.1007/s10916-010-9454-7
   Fraz MM, 2012, COMPUT METH PROG BIO, V108, P600, DOI 10.1016/j.cmpb.2011.08.009
   Gang L, 2002, IEEE T BIO-MED ENG, V49, P168, DOI 10.1109/10.979356
   Gao JQ, 2020, BIOMED RES INT, V2020, DOI 10.1155/2020/7352129
   Garg D, 2018, MULTIMED TOOLS APPL, V77, P26545, DOI 10.1007/s11042-018-5878-8
   Ghosh SK, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102785
   Gong HM, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P413, DOI 10.1109/CISP.2015.7407915
   Gu L, 2015, IEEE I CONF COMP VIS, P639, DOI 10.1109/ICCV.2015.80
   Guo S, 2019, INT J MED INFORM, V126, P105, DOI 10.1016/j.ijmedinf.2019.03.015
   Hassan G, 2015, PROCEDIA COMPUT SCI, V65, P612, DOI 10.1016/j.procs.2015.09.005
   Hoover A, 2000, IEEE T MED IMAGING, V19, P203, DOI 10.1109/42.845178
   Hu K, 2018, NEUROCOMPUTING, V309, P179, DOI 10.1016/j.neucom.2018.05.011
   Jiang XY, 2003, IEEE T PATTERN ANAL, V25, P131, DOI 10.1109/TPAMI.2003.1159954
   Jiang Y, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11091112
   Jiang ZX, 2017, BIOCYBERN BIOMED ENG, V37, P412, DOI 10.1016/j.bbe.2017.04.001
   Kande GB, 2010, J MED SYST, V34, P849, DOI 10.1007/s10916-009-9299-0
   Karn PK, 2019, IET IMAGE PROCESS, V13, P440, DOI 10.1049/iet-ipr.2018.5413
   Kaur J, 2012, INT J COMPUT SCI NET, V12, P109
   Khan T.M., 2020, NEURAL INFORM PROCES, P159
   Khawaja A, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19224949
   Khomri B, 2018, IET IMAGE PROCESS, V12, P2163, DOI 10.1049/iet-ipr.2018.5425
   Kumar A., 2011, International Journal on Computer Science and Engineering, V3, P933, DOI [10.18488/journal.76.2018.52.20.24, DOI 10.18488/JOURNAL.76.2018.52.20.24]
   Kundu A, 2012, PROC INT CONF EMERG, P316, DOI 10.1109/EAIT.2012.6407935
   Lahiri A, 2016, IEEE ENG MED BIO, P1340, DOI 10.1109/EMBC.2016.7590955
   Lam BSY, 2010, IEEE T MED IMAGING, V29, P1369, DOI 10.1109/TMI.2010.2043259
   Lam BSY, 2008, IEEE T MED IMAGING, V27, P237, DOI 10.1109/TMI.2007.909827
   Li HQ, 2000, P ANN INT IEEE EMBS, V22, P3071, DOI 10.1109/IEMBS.2000.901530
   Li HQ, 2013, C IND ELECT APPL, P232
   Liskowski P, 2016, IEEE T MED IMAGING, V35, P2369, DOI 10.1109/TMI.2016.2546227
   Lowell J, 2004, IEEE T MED IMAGING, V23, P1196, DOI 10.1109/TMI.2004.830524
   Lupascu CA, 2010, IEEE T INF TECHNOL B, V14, P1267, DOI 10.1109/TITB.2010.2052282
   Ma YL, 2021, BIOMED RES INT, V2021, DOI 10.1155/2021/5561125
   Mahadevan V, 2004, IEEE T INF TECHNOL B, V8, P360, DOI 10.1109/TITB.2004.834410
   Maji D., 2016, ARXIV160304833, DOI DOI 10.48550/ARXIV.1603.04833
   Maji D, 2015, IEEE ENG MED BIO, P3029, DOI 10.1109/EMBC.2015.7319030
   Maninis Kevis-Kokitsi, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P140, DOI 10.1007/978-3-319-46723-8_17
   Mardani K, 2021, BIOMED SIGNAL PROCES, V69, DOI 10.1016/j.bspc.2021.102837
   Marín D, 2011, IEEE T MED IMAGING, V30, P146, DOI 10.1109/TMI.2010.2064333
   Martinez-Perez ME, 2007, P ANN INT IEEE EMBS, P892, DOI 10.1109/IEMBS.2007.4352434
   Martinez-Perez ME, 2007, MED IMAGE ANAL, V11, P47, DOI 10.1016/j.media.2006.11.004
   Memari N, 2019, J MED BIOL ENG, V39, P713, DOI 10.1007/s40846-018-0454-2
   Mendonça AM, 2006, IEEE T MED IMAGING, V25, P1200, DOI 10.1109/TMI.2006.879955
   Mingkang Li, 2018, 2018 IEEE International Conference on Vehicular Electronics and Safety (ICVES). Proceedings, DOI 10.1109/ICVES.2018.8519483
   Miri MS, 2011, IEEE T BIO-MED ENG, V58, P1183, DOI 10.1109/TBME.2010.2097599
   Moghimirad E, 2010, I S BIOMED IMAGING, P29, DOI 10.1109/ISBI.2010.5490423
   Mustafa WA, 2017, J BIOMIM BIOMATER BI, V34, P10, DOI 10.4028/www.scientific.net/JBBBE.34.10
   Narasimha-Iyer H, 2007, IEEE T BIO-MED ENG, V54, P1427, DOI 10.1109/TBME.2007.900804
   Nath MK, 2020, J INTELL FUZZY SYST, V38, P6019, DOI 10.3233/JIFS-179687
   Ng J, 2010, IMAGE VISION COMPUT, V28, P55, DOI 10.1016/j.imavis.2009.04.019
   Odstrcilik J, 2013, IET IMAGE PROCESS, V7, P373, DOI 10.1049/iet-ipr.2012.0455
   Ozkava U., 2018, 2018 2 INT S MULTIDI, P1, DOI [10.1109/ISMSIT.2018.8567239, DOI 10.1109/ISMSIT.2018.8567239]
   Pandey M, 2012, INT J GRID UTIL COMP, V3, P200, DOI 10.1504/IJGUC.2012.047771
   Park KB, 2020, IEEE ACCESS, V8, P146308, DOI 10.1109/ACCESS.2020.3015108
   Poon K, 2007, LECT NOTES COMPUT SC, V4792, P444
   Prajna Y, 2022, J INTELL FUZZY SYST, V42, P3477, DOI 10.3233/JIFS-211479
   Quek FKH, 2001, IEEE T MED IMAGING, V20, P117, DOI 10.1109/42.913178
   Ramos-Soto O, 2021, COMPUT METH PROG BIO, V201, DOI 10.1016/j.cmpb.2021.105949
   Rattathanapad S., 2012, 2012 IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI), P345, DOI 10.1109/BHI.2012.6211584
   Ravichandran G, 2019, INT J ELECTRON TELEC, V65, P519, DOI 10.24425/ijet.2019.129808
   Reddy YMS, 2021, MATER TODAY-PROC, DOI [10.1016/j.matpr.2020.12.610, DOI 10.1016/J.MATPR.2020.12.610]
   Ricci E, 2007, IEEE T MED IMAGING, V26, P1357, DOI 10.1109/TMI.2007.898551
   Roy AG, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P735, DOI 10.1109/ACPR.2015.7486600
   Salem SA, 2007, MED BIOL ENG COMPUT, V45, P261, DOI 10.1007/s11517-006-0141-2
   Samuel PM, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11070946
   Sanjay R., 2012, Int J Future Comput Commun, P366, DOI DOI 10.7763/IJFCC.2012.V1.97
   Sathananthavathi V, 2021, COGN SYST RES, V67, P84, DOI 10.1016/j.cogsys.2021.01.003
   Sengar SS, 2020, NEURAL COMPUT APPL, V32, P11443, DOI 10.1007/s00521-019-04635-6
   Shahid M, 2018, IET IMAGE PROCESS, V12, P494, DOI 10.1049/iet-ipr.2017.0457
   Sharma S., 2015, Journal of Network Communications and Emerging Technologies (JNCET), V4, P1
   Shi C., 2019, ARXIV190608501, DOI [10.48550/arXiv.1906.08501, DOI 10.48550/ARXIV.1906.08501]
   Shukla AK, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101883
   Simó A, 2001, PATTERN RECOGN, V34, P795, DOI 10.1016/S0031-3203(00)00032-7
   Singh NP, 2019, P NATL A SCI INDIA A, V89, P269, DOI 10.1007/s40010-017-0465-3
   Singh NP, 2017, ADV INTELL SYST, V509, P427, DOI 10.1007/978-981-10-2525-9_40
   Singh NP, 2016, INT J BIOMED ENG TEC, V21, P229, DOI 10.1504/IJBET.2016.078286
   Singh NP, 2016, COMPUT METH PROG BIO, V129, P40, DOI 10.1016/j.cmpb.2016.03.001
   Singh NP, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION & AUTOMATION (ICCCA), P1166, DOI 10.1109/CCAA.2015.7148552
   Soares JVB, 2006, IEEE T MED IMAGING, V25, P1214, DOI 10.1109/TMI.2006.879967
   Sofka M, 2006, IEEE T MED IMAGING, V25, P1531, DOI 10.1109/TMI.2006.884190
   Solouma NH, 2001, PROC SPIE, V4322, P1311, DOI 10.1117/12.431010
   Srivastava A, 2018, Handbook of Research on Advanced Concepts in Real-time Image and Video Processing, P281, DOI 10.4018/978-1-5225-2848-7.ch011
   Srivastava P, 2017, J VIS COMMUN IMAGE R, V42, P78, DOI 10.1016/j.jvcir.2016.11.008
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Sukkaew Lassada, 2007, Journal of the Medical Association of Thailand, V90, P1780
   Sum KW, 2008, IEEE T BIO-MED ENG, V55, P358, DOI 10.1109/TBME.2007.896587
   Sun KQ, 2011, J MED SYST, V35, P811, DOI 10.1007/s10916-010-9466-3
   Sundaram R, 2019, MATHEMATICS-BASEL, V7, DOI 10.3390/math7020169
   Tamim N, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12060894
   Thukral R, 2022, P INT C REC TRENDS C, P827, DOI DOI 10.1007/978-981-16-7118-0_70
   Tiwari R., 2010, P INT C WORKSH EM TR, P529, DOI [10.1145/1741906.1742026, DOI 10.1145/1741906.1742026]
   Toptas B, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.103053
   Upadhyay Kamini, 2020, 2020 INT C SIGNAL PR, P1, DOI DOI 10.1109/SPCOM50965.2020.9179575
   Verma V, 2020, SOC NETW ANAL MIN, V10, DOI 10.1007/s13278-020-00660-9
   Vermeer KA, 2004, COMPUT BIOL MED, V34, P209, DOI 10.1016/S0010-4825(03)00055-6
   Villalobos-Castaldi FM, 2010, J VISUAL-JAPAN, V13, P263, DOI 10.1007/s12650-010-0037-y
   Vlachos M, 2010, COMPUT MED IMAG GRAP, V34, P213, DOI 10.1016/j.compmedimag.2009.09.006
   Wang CL, 2020, MED IMAGE ANAL, V60, DOI 10.1016/j.media.2019.101623
   Wang L, 2007, IEEE T MED IMAGING, V26, P137, DOI 10.1109/TMI.2006.889732
   Winder RJ, 2009, COMPUT MED IMAG GRAP, V33, P608, DOI 10.1016/j.compmedimag.2009.06.003
   Wink O, 2004, IEEE T MED IMAGING, V23, P130, DOI 10.1109/TMI.2003.819920
   Wu CH, 2007, 2007 INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION, P517
   Xie SH, 2013, 2013 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEM DESIGN AND ENGINEERING APPLICATIONS (ISDEA), P1225, DOI 10.1109/ISDEA.2012.289
   Xu LL, 2010, BIOMED ENG ONLINE, V9, DOI 10.1186/1475-925X-9-14
   Yang JZ, 2020, COMPUT MED IMAG GRAP, V85, DOI [10.1016.j.compmedimag.2020.101783, 10.1016/j.compmedimag.2020.101783]
   Yang Y, 2008, INT J AP MAT COM-POL, V18, P399, DOI 10.2478/v10006-008-0036-5
   Yao C, 2009, J CENT SOUTH UNIV T, V16, P640, DOI 10.1007/s11771-009-0106-3
   Yedidya Tamir, 2008, 2008 Digital Image Computing: Techniques and Applications, P52, DOI 10.1109/DICTA.2008.72
   Yin Y, 2010, IEEE IMAGE PROC, P4081, DOI 10.1109/ICIP.2010.5650937
   You XG, 2011, PATTERN RECOGN, V44, P2314, DOI 10.1016/j.patcog.2011.01.007
   Zana F, 2001, IEEE T IMAGE PROCESS, V10, P1010, DOI 10.1109/83.931095
   Zhang B, 2010, COMPUT BIOL MED, V40, P438, DOI 10.1016/j.compbiomed.2010.02.008
   Zhang J, 2015, CHIN AUTOM CONGR, P993, DOI 10.1109/CAC.2015.7382643
   Zhang YP, 2009, J SIGNAL PROCESS SYS, V55, P103, DOI 10.1007/s11265-008-0179-5
   Zhao YT, 2015, IEEE T MED IMAGING, V34, P1797, DOI 10.1109/TMI.2015.2409024
   Zhu T, 2011, IEEE ENG MED BIO, P5008, DOI 10.1109/IEMBS.2011.6091241
   Zhu T, 2010, COMPUT MED IMAG GRAP, V34, P203, DOI 10.1016/j.compmedimag.2009.09.004
   Zolfagharnasab Hooshiar, 2014, J Med Signals Sens, V4, P1
NR 163
TC 11
Z9 11
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7679
EP 7733
DI 10.1007/s11042-022-13388-9
EA JUL 2022
PG 55
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000824937500001
DA 2024-07-18
ER

PT J
AU Sharma, P
   Alshehri, M
   Sharma, R
AF Sharma, Purushottam
   Alshehri, Mohammed
   Sharma, Richa
TI Activities tracking by smartphone and smartwatch biometric sensors using
   fuzzy set theory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Data mining; Sensors; Smartphone; Smartwatch; Fuzzy
ID SOFTWARE
AB A Real-time available platform for deployment and implementation of mobile motion-based biometric behavior is provided by smartphones and smartwatches, including sensors. Sensors and physical activity evaluation are quite limited for motion-based commercial devices. In some cases, the accelerometer sensor of the smartwatch is utilized or walking is investigated. The combination of multiple sensors can perform better in terms of sensors, which can be determined by sensors on both the smartwatch and phones, i.e., accelerometer and gyroscope. For biometric efficiency, some of the diverse activities of daily routine have been evaluated with biometric authentication. The study's main objective is to track and monitor the daily lives activities using digital devices like smartphones and smartwatches for healthy human life. The result shows that using the different computing techniques in phones and watching for biometric can provide a suitable output based on the mentioned activities. This indicates that the feasibility results of continuous biometrics analysis in terms of average daily routine activities, can enhance the everyday routine life. The study also shows some of the easy to do activities like clapping, and walking may be a viable alternative for healthy life. Fuzzy based classification system is being utilized to improve the tracking system. In the present research, the Fuzzy Rule-Based Classification System justified the improved classification efficiency over the existing techniques for biometric activities.
C1 [Sharma, Purushottam; Sharma, Richa] Amity Univ Uttar Pradesh, ASET, Noida, Uttar Pradesh, India.
   [Alshehri, Mohammed] Majmaah Univ, Dept Informat Technol, Coll Comp & Informat Sci, Majmaah 11952, Saudi Arabia.
C3 Amity University Noida; Majmaah University
RP Alshehri, M (corresponding author), Majmaah Univ, Dept Informat Technol, Coll Comp & Informat Sci, Majmaah 11952, Saudi Arabia.
EM puru.mit2002@gmail.com; ma.alshehri@mu.edu.sa; s.richa.sharma@gmail.com
RI Sharma, Purushottam/AAI-1815-2021; Alshehri, Dr. Mohammed/AAH-3044-2019;
   Sharma, Richa/AAI-1864-2021; sharma, Richa/IXE-0135-2023
OI Sharma, Purushottam/0000-0002-8037-7152; Alshehri, Dr.
   Mohammed/0000-0003-1035-311X; 
CR Ahanathapillai V, 2015, HEALTHC TECHNOL LETT, V2, P34, DOI 10.1049/htl.2014.0091
   Al-khafajiy M, 2019, MULTIMED TOOLS APPL, V78, P24681, DOI 10.1007/s11042-018-7134-7
   Alcalá-Fdez J, 2011, J MULT-VALUED LOG S, V17, P255
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Alzubaidi A, 2016, IEEE COMMUN SURV TUT, V18, P1998, DOI 10.1109/COMST.2016.2537748
   [Anonymous], 2019, SMARTPHONE SMARTWATC
   Bouchrika I., 2018, SURVEILLANCE ACTION
   Cappelli R, 2006, IEEE T PATTERN ANAL, V28, P3, DOI 10.1109/TPAMI.2006.20
   Cordón O, 1999, INT J APPROX REASON, V20, P21, DOI 10.1016/S0888-613X(00)88942-2
   Ehatisham-ul-Haq M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17092043
   Gafurov D., 2007, Proc. IEEE International Conference on Biometrics: Theory, P1
   Gafurov D, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/415817
   Gary, GAWEISS FORDHAMEDU
   Ishibuchi H, 2005, IEEE T FUZZY SYST, V13, P428, DOI 10.1109/TFUZZ.2004.841738
   Ishibuchi H, 1999, FUZZY SET SYST, V103, P223, DOI 10.1016/S0165-0114(98)00223-1
   Jain AK, 2012, SEC OND GENERATION B, V11, DOI 10.1007/978-94-007-3892-8_3
   Kwapisz JR., 2011, ACM SIGKDD EXPLORATI, V12, P74, DOI [DOI 10.1145/1964897.1964918, 10.1145/1964897.1964918]
   Kwapisz JR, 2010, P 4 IEEE INT C BIOM, P1, DOI [DOI 10.1109/BTAS.2010.5634532, 10.1109/BTAS.2010.5634532]
   Mannini A, 2013, MED SCI SPORT EXER, V45, P2193, DOI 10.1249/MSS.0b013e31829736d6
   Orr R. J., 2000, CHI 00 EXTENDED ABST, P275, DOI [DOI 10.1145/633292.633453, 10.1145/633451.633453]
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Purushottam, 2015, 2015 4th International Conference on Reliability, Infocom Technologies and Optimization (ICRITO) (Trends and Future Directions), P1, DOI 10.1109/ICRITO.2015.7359272
   Sharma P, 2017, INT J SYST ASSUR ENG, V8, P1109, DOI 10.1007/s13198-017-0578-8
   Shoaib M, 2014, SENSORS-BASEL, V14, P10146, DOI 10.3390/s140610146
   Triguero I, 2017, INT J COMPUT INT SYS, V10, P1238
   Wang J, 2019, HUM-CENTRIC COMPUT I, V9, DOI 10.1186/s13673-019-0179-4
   Wang J, 2019, INT J DISTRIB SENS N, V15, DOI 10.1177/1550147719839581
   Wang W, 2020, MOB INF SYST, V2020, DOI 10.1155/2020/7602384
   Weiss GM, 2019, IEEE ACCESS, V7, P133190, DOI 10.1109/ACCESS.2019.2940729
   Weiss GM, 2016, PROCEEDINGS OF 3RD IEEE/ACM INTERNATIONAL CONFERENCE ON DATA SCIENCE AND ADVANCED ANALYTICS, (DSAA 2016), P682, DOI 10.1109/DSAA.2016.89
   Weiss GM, 2016, 2016 3RD IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL AND HEALTH INFORMATICS, P426, DOI 10.1109/BHI.2016.7455925
   Witten IH, 2011, MOR KAUF D, P1
   Yoneda K, 2017, 2017 IEEE 8TH ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (UEMCON), P584, DOI 10.1109/UEMCON.2017.8249001
   Yu F, 2019, NEUROCOMPUTING, V350, P108, DOI 10.1016/j.neucom.2019.03.053
   Zheng Y., 2013, IAAI"
NR 37
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2277
EP 2302
DI 10.1007/s11042-022-13290-4
EA JUN 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000814451100001
DA 2024-07-18
ER

PT J
AU Jin, C
AF Jin, Cong
TI Cross-database facial expression recognition based on hybrid improved
   unsupervised domain adaptation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-database; Facial expression recognition; Database adaptation;
   Learning feature; Images in the wild
ID NEURAL-NETWORKS; CLASSIFICATION
AB Since the labeled wild facial expression database is relatively rare, the existing Facial Expression Recognition (FER) models based on machine learning can only be trained with a relatively limited number of samples and whether the trained FER model can have satisfactory recognition performance is a challenge. In this paper, the facial expression database from the Laboratory Environment (LE) is used as the source domain, and the facial expression database from the wild is used as the target domain. Based on these two different databases, a hybrid improved unsupervised Cross-Domain Adaptation (CDA) approach is proposed, which can not only match the data distribution between different databases, but also maximize the correlation of data between different databases, and also maximize data separability on the source database. In the proposed CDA approach, the objective functions of the two improved techniques and those of traditional CDA are to achieve the simultaneous optimization of the three objective functions. After that, the proposed CDA approach was used for Cross-domain FER (CFER) task. To confirm the effectiveness of the proposed CFER model, some experiments are implemented on four cross-database pairs. The comparison and analysis of experimental results show that, compared with other existing CFER models, the proposed CFER model can realize the reuse of LE facial expression data and achieve better recognition performance for wild facial expression data.
C1 [Jin, Cong] Cent China Normal Univ, Sch Comp, Wuhan 430079, Peoples R China.
C3 Central China Normal University
RP Jin, C (corresponding author), Cent China Normal Univ, Sch Comp, Wuhan 430079, Peoples R China.
EM jincong@mail.ccnu.edu.cn
CR Aghamaleki JA, 2019, MULTIMED TOOLS APPL, V78, P22861, DOI 10.1007/s11042-019-7530-7
   Alphonse AS, 2019, MULTIMED TOOLS APPL, V78, P23369, DOI 10.1007/s11042-019-7646-9
   Bejiga MB, 2018, INT GEOSCI REMOTE SE, P1264, DOI 10.1109/IGARSS.2018.8518649
   Ben XY, 2018, PATTERN RECOGN LETT, V107, P50, DOI 10.1016/j.patrec.2017.07.010
   Beygelzimer A., 2007, Multiclass classification with filter trees
   Chen C, 2019, NEUROCOMPUTING, V349, P314, DOI 10.1016/j.neucom.2019.01.056
   Chen WD, 2020, NEURAL PROCESS LETT, V52, P467, DOI 10.1007/s11063-020-10266-z
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Daumé H, 2006, J ARTIF INTELL RES, V26, P101, DOI 10.1613/jair.1872
   Dhall A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Duan YQ, 2018, IEEE T PATTERN ANAL, V40, P1139, DOI 10.1109/TPAMI.2017.2710183
   Francisco EC., 2019, J INTELLIGENT COMPUT, V10, P34, DOI [10.6025/jic/2019/10/1/34-45, DOI 10.6025/JIC/2019/10/1/34-45]
   Gholenji E, 2020, APPL INTELL, V50, P2050, DOI 10.1007/s10489-019-01610-5
   Hashemi SM, 2020, KNOWL INF SYST, V62, P4625, DOI 10.1007/s10115-020-01499-4
   He ZH, 2020, MULTIMED TOOLS APPL, V79, P33973, DOI 10.1007/s11042-020-08877-8
   Herath S, 2017, PROC CVPR IEEE, P3956, DOI 10.1109/CVPR.2017.421
   Huang FC, 2012, IEEE T CIRC SYST VID, V22, P340, DOI 10.1109/TCSVT.2011.2162760
   Huang XH, 2019, IEEE T AFFECT COMPUT, V10, P32, DOI 10.1109/TAFFC.2017.2713359
   Islam MN, 2014, LECT NOTES COMPUT SC, V8835, P344, DOI 10.1007/978-3-319-12640-1_42
   Ji YL, 2019, NEUROCOMPUTING, V333, P231, DOI 10.1016/j.neucom.2018.12.037
   Jin C, 2021, EXPERT SYST APPL, V171, DOI 10.1016/j.eswa.2021.114637
   Kim BK, 2016, J MULTIMODAL USER IN, V10, P173, DOI 10.1007/s12193-015-0209-0
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   Li JJ, 2019, IEEE T CYBERNETICS, V49, P2144, DOI 10.1109/TCYB.2018.2820174
   Liu N, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1897, DOI 10.1109/ICASSP.2018.8461322
   Lo SK, 2008, CYBERPSYCHOL BEHAV, V11, P595, DOI 10.1089/cpb.2007.0132
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Luo LK, 2020, IEEE T CYBERNETICS, V50, P3914, DOI 10.1109/TCYB.2019.2962000
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Miao YQ, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 2, P326, DOI 10.1109/ICMLA.2012.178
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Ni TG, 2021, IEEE T COMPUT SOC SY, V8, P1213, DOI 10.1109/TCSS.2020.3013938
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Rajan S, 2020, IET IMAGE PROCESS, V14, P1373, DOI 10.1049/iet-ipr.2019.1188
   Richhariya B, 2019, APPL SOFT COMPUT, V76, P53, DOI 10.1016/j.asoc.2018.11.046
   Rostami M, 2022, ARTIF INTELL MED, V123, DOI 10.1016/j.artmed.2021.102228
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Sanodiya RK, 2019, KNOWL-BASED SYST, V176, P1, DOI 10.1016/j.knosys.2019.03.021
   Sanodiya RK, 2019, IEEE ACCESS, V7, P42956, DOI 10.1109/ACCESS.2019.2907571
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Sharma M, 2019, MULTIMED TOOLS APPL, V78, P16195, DOI 10.1007/s11042-018-7030-1
   Shen C, 2018, AS C MACH LEARN BEIJ
   Shinnou H, 2015, COMPUT LINGUIST, V593, DOI [10.1007/978-981-10-0515-2_7, DOI 10.1007/978-981-10-0515-2_7]
   Sun W, 2006, NUMERICAL OPTIMIZATI, V1, DOI [10.1007/0-387-24976-1_8, DOI 10.1007/0-387-24976-1_8]
   Tahmoresnezhad J, 2017, KNOWL INF SYST, V50, P585, DOI 10.1007/s10115-016-0944-x
   Usman M, 2017, INT CONF EMERG TECHN
   Nguyen V, 2020, LECT NOTES ARTIF INT, V12084, P699, DOI 10.1007/978-3-030-47426-3_54
   Wang M, 2018, NEUROCOMPUTING, V312, P135, DOI 10.1016/j.neucom.2018.05.083
   Wang YY, 2020, KNOWL-BASED SYST, V192, DOI 10.1016/j.knosys.2019.105344
   Wenming Zheng, 2018, IEEE Transactions on Affective Computing, V9, P21, DOI 10.1109/TAFFC.2016.2563432
   Xie Y, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1255, DOI 10.1145/3394171.3413822
   Xu XM, 2020, IEEE T CIRC SYST VID, V30, P4688, DOI 10.1109/TCSVT.2019.2963318
   Xu YH, 2017, IEEE T KNOWL DATA EN, V29, P1158, DOI 10.1109/TKDE.2017.2669193
   Yan KY, 2019, IEEE ACCESS, V7, P108906, DOI 10.1109/ACCESS.2019.2930359
   Yang YN, 2020, ICAART: PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE, VOL 2, P610, DOI 10.5220/0008966306100617
   Yang ZH, 2020, MULTIMED TOOLS APPL, V79, P33853, DOI 10.1007/s11042-019-08584-z
   Zellinger W, 2021, ANN MATH ARTIF INTEL, V89, P333, DOI 10.1007/s10472-020-09719-x
   Zellinger W, 2019, INFORM SCIENCES, V483, P174, DOI 10.1016/j.ins.2019.01.025
   Zhang J, 2017, PROC CVPR IEEE, P5150, DOI 10.1109/CVPR.2017.547
   Zhang T, 2016, IEEE T MULTIMEDIA, V18, P2528, DOI 10.1109/TMM.2016.2598092
   Zhao CJ, 2020, KNOWL-BASED SYST, V191, DOI 10.1016/j.knosys.2019.105254
NR 61
TC 4
Z9 4
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 1105
EP 1129
DI 10.1007/s11042-022-13311-2
EA JUN 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000810329100001
DA 2024-07-18
ER

PT J
AU Zhao, F
   Wang, W
   Wu, Y
   Wang, KX
   Kang, XB
AF Zhao, Fan
   Wang, Wen
   Wu, Yu
   Wang, Kaixuan
   Kang, Xiaobing
TI A coarse-to-fine temporal action detection method combining light and
   heavy networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Untrimmed video; Temporal action detection; Convolutional neural network
   (CNN); action proposal; Detector; Classifier
ID ACTION LOCALIZATION; RECOGNITION
AB Temporal action detection aims to judge whether there existing a certain number of action instances in a long untrimmed videos and to locate the start and end time of each action. Even though the existing action detection methods have shown promising results in recent years with the widespread application of Convolutional Neural Network (CNN), it is still a challenging problem to accurately locate each action segment while ensuring real-time performance. In order to achieve a good tradeoff between detection efficiency and accuracy, we present a coarse-to-fine hierarchical temporal action detection method by using multi-scale sliding window mechanism. Since the complexity of the convolution operator is proportional to the number and the size of the input video clips, the idea of our proposed method is to first determine candidate action proposals and then perform the detection task on these candidate action proposals only with a view to reducing the overall complexity of the detection method. By making full use of the spatio-temporal information of video clips, a lightweight 3D-CNN classifier is first used to quickly determine whether the video clip is a candidate action proposal, avoiding the re-detection of a large number of non-action video clips by the heavyweight deep network. A heavyweight detector is designed to further improve the accuracy of action positioning by considering both boundary regression loss and category loss in the target loss function. In addition, the Non-Maximum Suppression (NMS) is performed to eliminate redundant detection results among the overlapping proposals. The mean Average Precision (mAP) is 40.6%, 51.7% and 20.4% on THUMOS14, ActivityNet and MPII Cooking dataset when the Intersection-over-Union (tIoU) threshold is set to 0.5, respectively. Experimental results show the superior performance of the proposed method on three challenging temporal activity detection datasets while achieving real-time speed. At the same time, our method can generate proposals for unseen action classes with high recalls.
C1 [Zhao, Fan; Wang, Wen; Wu, Yu; Wang, Kaixuan; Kang, Xiaobing] Xian Univ Technol, Dept Informat Sci, Xian 710054, Peoples R China.
C3 Xi'an University of Technology
RP Zhao, F (corresponding author), Xian Univ Technol, Dept Informat Sci, Xian 710054, Peoples R China.
EM vau@xaut.edu.cn
RI ZHAO, Fan/AEZ-4761-2022
OI ZHAO, Fan/0000-0001-6672-7948
FU Natural Science Basic Research Project of Shaanxi Province of China
   [2021JLM-59]; National Natural Science Foundation of China [61671376]
FX This work was supported by Natural Science Basic Research Project of
   Shaanxi Province of China (Grant No. 2021JLM-59), National Natural
   Science Foundation of China (Grant No. 61671376).
CR [Anonymous], 2017, P BRIT MACH VIS C
   [Anonymous], 2015, BRIT MACH VIS C
   Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen G, 2021, IEEE T MULTIMEDIA, V23, P2672, DOI 10.1109/TMM.2020.3014555
   Dong PX, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2019), P230, DOI [10.1109/SIPROCESS.2019.8868533, 10.1109/siprocess.2019.8868533]
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Escorcia V, 2016, LECT NOTES COMPUT SC, V9907, P768, DOI 10.1007/978-3-319-46487-9_47
   Fayyaz M, 2020, PROC CVPR IEEE, P498, DOI 10.1109/CVPR42600.2020.00058
   Gaidon A, 2013, IEEE T PATTERN ANAL, V35, P2782, DOI 10.1109/TPAMI.2013.65
   Gao JY, 2018, LECT NOTES COMPUT SC, V11206, P70, DOI 10.1007/978-3-030-01216-8_5
   Gao JY, 2017, IEEE I CONF COMP VIS, P3648, DOI 10.1109/ICCV.2017.392
   Gao Jiyang, 2017, BMVC
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heilbron FC, 2016, PROC CVPR IEEE, P1914, DOI 10.1109/CVPR.2016.211
   Jain M, 2014, PROC CVPR IEEE, P740, DOI 10.1109/CVPR.2014.100
   Jiang Y.-G., 2014, THUMOS challenge: Action recognition with a large number of classes
   Kim JH, 2019, IEEE ACCESS, V7, P41273, DOI 10.1109/ACCESS.2019.2907327
   Kim JH, 2018, DISPLAYS, V55, P38, DOI 10.1016/j.displa.2018.08.001
   Kim JH, 2019, IEEE ACCESS, V7, P149797, DOI 10.1109/ACCESS.2019.2946898
   Li NN, 2018, IEEE ACCESS, V6, P59126, DOI 10.1109/ACCESS.2018.2872759
   Li TY, 2021, MULTIMED TOOLS APPL, V80, P2123, DOI 10.1007/s11042-020-09703-x
   Lin TW, 2018, LECT NOTES COMPUT SC, V11208, P3, DOI 10.1007/978-3-030-01225-0_1
   Lin TW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P988, DOI 10.1145/3123266.3123343
   Liu JC, 2019, IEEE ACCESS, V7, P135204, DOI 10.1109/ACCESS.2019.2940407
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long FC, 2019, PROC CVPR IEEE, P344, DOI 10.1109/CVPR.2019.00043
   Mettes P, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P427, DOI 10.1145/2671188.2749404
   Oneata D, 2013, IEEE I CONF COMP VIS, P1817, DOI 10.1109/ICCV.2013.228
   Pedersoli M, 2015, PATTERN RECOGN, V48, P1844, DOI 10.1016/j.patcog.2014.11.006
   Nguyen P, 2018, PROC CVPR IEEE, P6752, DOI 10.1109/CVPR.2018.00706
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Richard A, 2016, PROC CVPR IEEE, P3131, DOI 10.1109/CVPR.2016.341
   Rohrbach M, 2012, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2012.6247801
   Shen ZY, 2020, IEEE ACCESS, V8, P17287, DOI 10.1109/ACCESS.2020.2967627
   Shou Z, 2017, PROC CVPR IEEE, P1417, DOI 10.1109/CVPR.2017.155
   Shou Z, 2016, PROC CVPR IEEE, P1049, DOI 10.1109/CVPR.2016.119
   Simonyan K, 2014, ADV NEUR IN, V27
   Song HJ, 2020, MULTIMED TOOLS APPL, V79, P34471, DOI 10.1007/s11042-020-08771-3
   Song H, 2019, IEEE T MULTIMEDIA, V21, P717, DOI 10.1109/TMM.2018.2866370
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang Limin., 2014, THUMOS14 Action Recognition Challenge
   Wu YC, 2018, IEEE ACCESS, V6, P31677, DOI 10.1109/ACCESS.2018.2842428
   Xiong Y., 2017, CoRR
   Xu MZ, 2019, IEEE I CONF COMP VIS, P5531, DOI 10.1109/ICCV.2019.00563
   Yang XT, 2019, PROC CVPR IEEE, P264, DOI 10.1109/CVPR.2019.00035
   Yao GL, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101924
   Yeo WH, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10249069
   Yeung S, 2016, PROC CVPR IEEE, P2678, DOI 10.1109/CVPR.2016.293
   Yuan Y, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-0496-6
   Zhao Y, 2017, IEEE I CONF COMP VIS, P2933, DOI 10.1109/ICCV.2017.317
   Zheng JY, 2019, IEEE ACCESS, V7, P183860, DOI 10.1109/ACCESS.2019.2933360
   Zheng Y., 2020, P IEEE CVF C COMP VI, P13766
   Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283
   Zhu Y, 2017, IEEE WINT CONF APPL, P197, DOI 10.1109/WACV.2017.29
NR 58
TC 0
Z9 0
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 879
EP 898
DI 10.1007/s11042-022-12720-7
EA JUN 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000808527500001
OA hybrid
DA 2024-07-18
ER

PT J
AU Pashaei, E
   Pashaei, E
AF Pashaei, Elnaz
   Pashaei, Elham
TI A fusion approach based on black hole algorithm and particle swarm
   optimization for image enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contrast enhancement; Particle swarm optimization; Black hole algorithm;
   Histogram equalization; Evolutionary algorithm
ID CONTRAST ENHANCEMENT; GENETIC ALGORITHM; FEATURE-SELECTION;
   CLASSIFICATION; SEGMENTATION; DISEASES
AB The main objective of this paper is to present a new 2-stage hybrid optimization algorithm based scheme named PSO-BHA for image enhancement. A parameterized mapping function and a novel objective function are utilized in this paper to achieve the best-enhanced images. The suggested scheme combines the merits of particle swarm optimization (PSO) with the black hole algorithm (BHA) in two sequential stages to find the best parameters for the mapping function with the aid of the proposed objective function. The objective function uses contrast, edge, entropy, and universal quality index (UQI) for measuring contrast, and different improved information in the enhanced image. In the proposed scheme, PSO is applied first to adjust the tunable parameters of the mapping function and as a result, new pixel intensities are produced. Then, in the second stage, the obtained pixel intensities are again passed through the mapping function whose parameters are tuned by the use of the BHA. The suggested framework overcomes the limitations of the traditional histogram equalization (HE) based enhancement techniques in which excessive contrast enhancement and image information loss can occur. The suggested method is evaluated on several test images and compared with different state-of-the-art methods. The results indicate that the proposed framework provides superior performance to all existing methods in terms of various metrics. The proposed scheme also contributes to substantial feature enhancement and contrast boosting in the enhanced image, while retaining the natural feel of the original image.
C1 [Pashaei, Elnaz] Istanbul Aydin Univ, Dept Software Engn, Istanbul, Turkey.
   [Pashaei, Elham] Istanbul Gelisim Univ, Dept Comp Engn, Istanbul, Turkey.
C3 Istanbul Aydin University; Istanbul Gelisim University
RP Pashaei, E (corresponding author), Istanbul Aydin Univ, Dept Software Engn, Istanbul, Turkey.
EM elnazpashaei@aydin.edu.tr
RI PASHAEI, ELNAZ/AAI-7928-2021; Pashaei, Elham/AAP-8599-2021
OI PASHAEI, ELNAZ/0000-0001-9391-9785; Pashaei, Elham/0000-0001-7401-4964
CR Abdulwahab HA, 2019, IEEE ACCESS, V7, P142085, DOI 10.1109/ACCESS.2019.2937021
   Akram Tallha, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P1083, DOI 10.1007/s12652-018-1051-5
   Al-Ameen Z., 2018, Stat. Optim. Inf. Comput, V6, P577, DOI [DOI 10.19139/SOIC.V6I4.436, 10.19139/soic.v6i4.436]
   Al-Ameen Z, 2015, SCANNING, V37, P116, DOI 10.1002/sca.21187
   [Anonymous], 2013, Int. J. Comput. Appl, DOI DOI 10.5120/13766-1620
   [Anonymous], 2019, TRUE COLOR KODAK IMA
   Anupriya A., 2012, INT J COMPUT APPL, V46, P39
   Asokan A, 2020, GEOSCIENCES, V10, DOI 10.3390/geosciences10020078
   Bhandari AK, 2020, IEEE T INSTRUM MEAS, V69, P6807, DOI 10.1109/TIM.2020.2976279
   Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218
   Campos GFC, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0445-4
   Chen J, 2018, SWARM EVOL COMPUT, V38, P287, DOI 10.1016/j.swevo.2017.09.002
   Chen YB, 2020, J CONTEMP CHINA, V29, P1, DOI [10.1080/10670564.2019.1621526, 10.1080/01932691.2020.1791172, 10.1007/s12652-020-02066-z]
   Chen YT, 2021, VISUAL COMPUT, V37, P1691, DOI 10.1007/s00371-020-01932-3
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   da Costa Oliveira AL, 2020, LECT NOTES COMPUTER
   Dhal KG, 2019, ARCH COMPUT METHOD E, V26, P1607, DOI 10.1007/s11831-018-9289-9
   Dhal KG, 2019, EVOL SYST-GER, V10, P129, DOI 10.1007/s12530-018-9216-1
   Gonzalez R.C., 2018, Digital Image Processing
   Gorai A, 2009, WOR CONG NAT BIOL, P72, DOI 10.1109/NABIC.2009.5393603
   Gupta K., 2012, IOSR J VLSI SIGNAL P, V1, P38, DOI [10.9790/4200-0133845, DOI 10.9790/4200-0133845]
   Hatamlou A, 2013, INFORM SCIENCES, V222, P175, DOI 10.1016/j.ins.2012.08.023
   Hoseini P, 2013, DIGIT SIGNAL PROCESS, V23, P879, DOI 10.1016/j.dsp.2012.12.011
   Jasmine J, 2019, MEASUREMENT, V145, P833, DOI 10.1016/j.measurement.2018.12.105
   Kamoona AM, 2019, APPL SOFT COMPUT, V85, DOI 10.1016/j.asoc.2019.105749
   Kandhway P, 2020, BIOMED SIGNAL PROCES, V56, DOI 10.1016/j.bspc.2019.101677
   Khan MA, 2020, PATTERN RECOGN LETT, V131, P193, DOI 10.1016/j.patrec.2019.12.024
   Khan MA, 2019, IEEE ACCESS, V7, P46261, DOI 10.1109/ACCESS.2019.2908040
   Khan MA, 2019, MICROSC RES TECHNIQ, V82, P741, DOI 10.1002/jemt.23220
   Khan MA, 2018, COMPUT ELECTRON AGR, V155, P220, DOI 10.1016/j.compag.2018.10.013
   Liang K, 2012, INFRARED PHYS TECHN, V55, P309, DOI 10.1016/j.infrared.2012.03.004
   Limare N, 2011, IMAGE PROCESS ON LIN, V1, P297, DOI 10.5201/ipol.2011.llmps-scb
   Lisani JL, 2012, IMAGE PROCESS ON LIN, V2, P243, DOI 10.5201/ipol.2012.lps-pae
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Mahapatra PK, 2015, SOFT COMPUT, V19, P2101, DOI 10.1007/s00500-014-1394-6
   Malik R, 2019, J AMB INTEL HUM COMP, V10, P3563, DOI 10.1007/s12652-018-1082-y
   Meena, 2018, IEEE J-STARS, DOI [10.1109/JSTARS.2018.2870157, DOI 10.1109/JSTARS.2018.2870157]
   Mondal SK, 2018, LECT NOTES NETWORKS
   Morel JM, 2014, IMAGE PROCESS ON LIN, V4, P16, DOI 10.5201/ipol.2014.84
   Muniyappan S, 2019, MULTIMED TOOLS APPL, V78, P6487, DOI 10.1007/s11042-018-6355-0
   Nasir M, 2018, MICROSC RES TECHNIQ, V81, P528, DOI 10.1002/jemt.23009
   Nickfarjam AM, 2017, APPL INTELL, V47, P1132, DOI 10.1007/s10489-017-0931-2
   Pashaei E, 2017, APPL SOFT COMPUT, V56, P94, DOI 10.1016/j.asoc.2017.03.002
   Rahman S, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0138-1
   Rundo L, 2019, EXPERT SYST APPL, V119, P387, DOI 10.1016/j.eswa.2018.11.013
   Sharif M, 2018, COMPUT ELECTRON AGR, V150, P220, DOI 10.1016/j.compag.2018.04.023
   Sun L, 2020, IEEE T CIRC SYST VID, V30, P3829, DOI 10.1109/TCSVT.2019.2946723
   Sun L, 2020, IEEE J-STARS, V13, P1174, DOI 10.1109/JSTARS.2020.2980576
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Xie W, 2019, IEEE ACCESS, V7, P161459, DOI 10.1109/ACCESS.2019.2951716
   Yaghoobi S, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION AND IMAGE ANALYSIS (IPRIA)
   Yang CC, 2006, OPT LASER TECHNOL, V38, P196, DOI 10.1016/j.optlastec.2004.11.009
   Ye ZW, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/825398
   Yue XF, 2021, ARAB J SCI ENG, V46, P3235, DOI 10.1007/s13369-020-05148-4
   Zhang JM, 2020, IEEE ACCESS, V8, P29742, DOI 10.1109/ACCESS.2020.2972338
   Zhang JM, 2020, ANN TELECOMMUN, V75, P369, DOI 10.1007/s12243-019-00731-9
   Zhang YM, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/628693
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 62
TC 5
Z9 5
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 297
EP 325
DI 10.1007/s11042-022-13275-3
EA JUN 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000806683200001
DA 2024-07-18
ER

PT J
AU Petkovic, B
   Resic, S
   Petkovic, D
AF Petkovic, Biljana
   Resic, Sead
   Petkovic, Dalibor
TI Application of hybrid learning algorithm for optimization of LED lens
   design
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE LED; lens design; Optimization procedure; ANFIS
ID ANGLE SHEAR CONNECTORS; AXIAL COMPRESSIVE BEHAVIOR; CONCRETE COMPOSITE
   BEAMS; FUZZY INFERENCE SYSTEM; TO-COLUMN CONNECTIONS; OF-THE-ART;
   FREEFORM LENS; UNIFORM ILLUMINATION; STRENGTH PREDICTION; PERFORMANCE
AB In this study was performed optimization procedure of LED lens design by adaptive neuro fuzzy inference system (ANFIS). There are two objective functions in the optimization procedure: viewing angle and luminance uniformity. Optical design software was used for experimental procedure in order to extract training data for the ANFIS optimization procedure. In the first step of the optimization procedure the viewing angle was used as the optimization objective function. Afterwards the initial optimization of the lens shape was found. In the next step the luminance uniformity was used as the second optimization objective function. ANFIS model was used to find the optimal parameters for the LED lens design. The optimal parameters were found based on minimization of the ANFIS prediction accuracy of the viewing angle and luminance uniformity. The selected optimal parameters could be used further for improvement of the LED lens design.
C1 [Petkovic, Biljana] Univ Educons, Business Econ, Novi Sad, Serbia.
   [Resic, Sead] Univ Tuzla, Fac Nat Sci & Math, Dept Math, Tuzla, Bosnia & Herceg.
   [Petkovic, Dalibor] Univ Nis, Pedag Fac Vranje, Partizanska 14, Vranje 17500, Serbia.
C3 University of Tuzla; University of Nis
RP Petkovic, D (corresponding author), Univ Nis, Pedag Fac Vranje, Partizanska 14, Vranje 17500, Serbia.
EM dalibortc@gmail.com
CR Afshar A, 2020, CONSTR BUILD MATER, V262, DOI 10.1016/j.conbuildmat.2020.120034
   Arabnejad Khanouki M.M., 2010, P 4 INT C STEEL COMP, P21
   Cao B, 2021, IEEE T NETW SCI ENG, V8, P2756, DOI 10.1109/TNSE.2021.3057915
   Cao B, 2021, IEEE T INTELL TRANSP, V22, P3841, DOI 10.1109/TITS.2021.3059455
   Chahnasir ES, 2018, SMART STRUCT SYST, V22, P413, DOI 10.12989/sss.2018.22.4.413
   Chen C, 2019, BEHAV STEEL STORAGE, DOI [10.12989/scs.2019.30.5.457, DOI 10.12989/SCS.2019.30.5.457]
   Chen WC, 2011, EXPERT SYST APPL, V38, P11976, DOI 10.1016/j.eswa.2011.03.092
   Cheng Y, 2019, OPTIK, V179, P266, DOI 10.1016/j.ijleo.2018.10.184
   Davoodnabi SM, 2021, STEEL COMPOS STRUCT, V40, P853, DOI 10.12989/scs.2021.40.6.853
   Davoodnabi SM, 2019, STEEL COMPOS STRUCT, V30, P141, DOI [10.12989/scs.2019.30.2.141, 10.12989/scs.2019.30.5.141]
   Hamidian M., 2011, Int. J. Phys. Sci, V6, P5261
   He SD, 2020, CURR BIOINFORM, V15, P1213, DOI 10.2174/1574893615999200503030350
   He Y, 2020, IEEE COMMUN LETT, V24, P2221, DOI 10.1109/LCOMM.2020.3005947
   Heydari A, 2018, STRUCT ENG MECH, V66, P737, DOI 10.12989/sem.2018.66.6.737
   Hosseini SA, 2021, ADV CONCR CONSTR, V11, P531, DOI 10.12989/acc.2021.11.6.531
   Hosseinpour E, 2018, STEEL COMPOS STRUCT, V26, P485, DOI 10.12989/scs.2018.26.4.485
   Ismail M, 2018, STEEL COMPOS STRUCT, V28, P681, DOI 10.12989/scs.2018.28.6.681
   Jalali A., 2012, Int. J. Phys. Sci, V7, P4061
   JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541
   Katebi J, 2019, ENG COMPUT-GERMANY, P120
   Khanouki MMA, 2016, J CONSTR STEEL RES, V121, P144, DOI 10.1016/j.jcsr.2016.01.002
   Khanouki MMA, 2011, ADV MATER RES-SWITZ, V168-170, P2329, DOI 10.4028/www.scientific.net/AMR.168-170.2329
   Khorami M, 2017, EARTHQ STRUCT, V13, P531, DOI 10.12989/eas.2017.13.6.531
   Khorami M, 2017, STRUCT ENG MECH, V63, P259, DOI 10.12989/sem.2017.63.2.259
   Khorramian K, 2017, STEEL COMPOS STRUCT, V23, P67, DOI 10.12989/scs.2017.23.1.067
   Khorramian K, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0144288
   Kumar H, 2019, OPTIK, V181, P1039, DOI 10.1016/j.ijleo.2018.12.057
   Le NY, 2019, OPTIK, V183, P565, DOI 10.1016/j.ijleo.2019.02.005
   Li A, 2020, IEEE COMMUN SURV TUT, V22, P796, DOI 10.1109/COMST.2020.2980570
   Li DY, 2019, SMART STRUCT SYST, V23, P207, DOI 10.12989/sss.2019.23.2.207
   Liu F, 2020, IEEE T NEUR NET LEAR, V31, P5588, DOI 10.1109/TNNLS.2020.2973293
   Liu ZC, 2022, IEEE T POWER ELECTR, V37, P8767, DOI 10.1109/TPEL.2022.3153797
   Luo ZY, 2019, STEEL COMPOS STRUCT, V30, P271, DOI 10.12989/scs.2019.30.3.271
   Ma SH, 2019, OPTIK, V191, P89, DOI 10.1016/j.ijleo.2019.05.086
   Mansouri I, 2016, STRUCT ENG MECH, V60, P471, DOI 10.12989/sem.2016.60.3.471
   Mehrabi P, 2021, CONSTR BUILD MATER, V287, DOI 10.1016/j.conbuildmat.2021.122652
   Milovancevic M, 2019, PHYSICA A, V531, DOI 10.1016/j.physa.2019.121169
   Mohammadhassani M, 2014, SMART STRUCT SYST, V14, P785, DOI 10.12989/sss.2014.14.5.785
   Mohammadhassani M, 2014, ENG FAIL ANAL, V41, P73, DOI 10.1016/j.engfailanal.2013.08.014
   Mohammadhassani M, 2013, STRUCT ENG MECH, V48, P833, DOI 10.12989/sem.2013.48.6.833
   Mohammadhassani M, 2013, STRUCT ENG MECH, V46, P853, DOI 10.12989/sem.2013.46.6.853
   Mojtaba D., 2011, INT J PHYS SCI, V6, P8044, DOI 10.5897/IJPS11.1585
   Mou JH, 2022, FUTURE GENER COMP SY, V128, P521, DOI 10.1016/j.future.2021.10.003
   Naghipour M, 2020, STEEL COMPOS STRUCT, V35, P279, DOI 10.12989/scs.2020.35.2.279
   Naghipour M, 2020, STEEL COMPOS STRUCT, V34, P347, DOI 10.12989/scs.2020.34.3.347
   Nasrollahi S, 2018, STEEL COMPOS STRUCT, V27, P537, DOI 10.12989/scs.2018.27.5.537
   Trung NT, 2019, SMART STRUCT SYST, V24, P415, DOI 10.12989/sss.2019.24.3.415
   Trung NT, 2019, STRUCT ENG MECH, V70, P639, DOI 10.12989/sem.2019.70.5.639
   Nosrati A, 2018, SMART STRUCT SYST, V22, P425, DOI 10.12989/sss.2018.22.4.425
   Nouri K, 2021, ADV STEEL CONSTR, V17, P28, DOI 10.18057/IJASC.2021.17.1.4
   Paknahad M, 2018, STEEL COMPOS STRUCT, V28, P483, DOI 10.12989/scs.2018.28.4.483
   Qin CJ, 2022, MECH SYST SIGNAL PR, V175, DOI 10.1016/j.ymssp.2022.109148
   Razavian L, 2020, STRUCT ENG MECH, V74, P145, DOI 10.12989/sem.2020.74.1.145
   Safa M, 2016, STEEL COMPOS STRUCT, V21, P679, DOI 10.12989/scs.2016.21.3.679
   Safa M, 2020, PHYSICA A, V550, DOI 10.1016/j.physa.2019.124046
   Sajedi F, 2019, STEEL COMPOS STRUCT, V30, P417, DOI 10.12989/scs.2019.30.5.417
   Sedghi Y, 2018, SMART STRUCT SYST, V22, P335, DOI 10.12989/sss.2018.22.3.335
   Shah SNR, 2016, ENG FAIL ANAL, V66, P240, DOI 10.1016/j.engfailanal.2016.04.017
   Shah SNR, 2016, THIN WALL STRUCT, V106, P471, DOI 10.1016/j.tws.2016.05.021
   Shah SNR, 2016, MECH SYST SIGNAL PR, V70-71, P725, DOI 10.1016/j.ymssp.2015.08.026
   Shah SNR, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0139422
   Shahabi SEM, 2016, STEEL COMPOS STRUCT, V20, P185, DOI 10.12989/scs.2016.20.1.185
   Shahabi SEM, 2016, STEEL COMPOS STRUCT, V20, P651, DOI 10.12989/scs.2016.20.3.651
   Shariat M, 2018, STEEL COMPOS STRUCT, V29, P243, DOI 10.12989/scs.2018.29.2.243
   Shariati A., 2012, INT J PHYS SCI, V7, P2876
   Shariati A, 2014, CONSTR BUILD MATER, V52, P276, DOI 10.1016/j.conbuildmat.2013.11.036
   Shariati M, 2016, CONSTR BUILD MATER, V120, P382, DOI 10.1016/j.conbuildmat.2016.05.102
   Shariati M., 2019, Geomechanics and Engineering, V19, P473
   Shariati M., 2012, 5 INT C ENG FAIL AN, P1
   Shariati M., 2010, P 4 INT C STEEL COMP, P21
   Shariati M., P 2011 WORLD C ADV S
   Shariati M, 2013, Behaviour of C-shaped Shear Connectors in Stell Concrete Composite Beams
   Shariati M., 2008, Assessment building using none-destructive test techniques (ultra sonic pulse velocity and Schmidt rebound hammer)
   Shariati M., 2011, SCI RES ESSAYS, V6, P977, DOI DOI 10.5897/SRE10.1120
   Shariati M., 2017, 5 INT C ADV CIV STRU
   Shariati M, 2021, COMPOS STRUCT, V278, DOI 10.1016/j.compstruct.2021.114524
   Shariati M, 2020, STEEL COMPOS STRUCT, V36, P587, DOI 10.12989/scs.2020.36.5.587
   Shariati M, 2020, STEEL COMPOS STRUCT, V35, P599, DOI 10.12989/scs.2020.35.4.599
   Shariati M, 2020, SMART STRUCT SYST, V25, P183, DOI 10.12989/sss.2020.25.2.183
   Shariati M, 2020, STEEL COMPOS STRUCT, V34, P377, DOI 10.12989/scs.2020.34.3.377
   Shariati M, 2020, GEOMECH ENG, V20, P87, DOI 10.12989/gae.2020.20.2.087
   Shariati M, 2020, STEEL COMPOS STRUCT, V34, P155, DOI 10.12989/scs.2020.34.1.155
   Shariati M, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9245534
   Shariati M, 2019, STEEL COMPOS STRUCT, V33, P319, DOI 10.12989/scs.2019.33.3.319
   Shariati M, 2019, SMART STRUCT SYST, V24, P553, DOI 10.12989/sss.2019.24.4.553
   Shariati M, 2018, ENG FAIL ANAL, V85, P149, DOI 10.1016/j.engfailanal.2017.08.014
   Shariati M, 2016, MATER STRUCT, V49, P3909, DOI 10.1617/s11527-015-0762-8
   Shariati M, 2014, ENG FAIL ANAL, V41, P124, DOI 10.1016/j.engfailanal.2014.02.017
   Shariati M, 2013, CONSTR BUILD MATER, V38, P582, DOI 10.1016/j.conbuildmat.2012.07.050
   Shariati M, 2012, MATER DESIGN, V41, P67, DOI 10.1016/j.matdes.2012.04.039
   Shariati M, 2012, MATER DESIGN, V34, P325, DOI 10.1016/j.matdes.2011.08.008
   Shariati M, 2011, SCI RES ESSAYS, V6, P213
   Shariati M, 2011, ADV MATER RES-SWITZ, V168-170, P2303, DOI 10.4028/www.scientific.net/AMR.168-170.2303
   Shariati M, 2020, STEEL COMPOS STRUCT, V35, P237, DOI 10.12989/scs.2020.35.2.237
   Shariati M, 2019, STEEL COMPOS STRUCT, V33, P569, DOI 10.12989/scs.2019.33.4.569
   Shariati M, 2019, ADV CONCR CONSTR, V8, P225, DOI 10.12989/acc.2019.8.3.225
   Shariati M, 2019, STEEL COMPOS STRUCT, V31, P427, DOI 10.12989/scs.2019.31.5.427
   Shariatit M, 2020, STEEL COMPOS STRUCT, V34, P393, DOI 10.12989/scs.2020.34.3.393
   Sharma M, 2020, ENVIRON SCI POLLUT R, V27, P13325, DOI 10.1007/s11356-020-07765-w
   Shi Y, 2017, OPTIK, V144, P251, DOI 10.1016/j.ijleo.2017.04.049
   Sinaei H., 2011, Int. J. Phys. Sci, V6, P6572
   Sinaei H., 2012, Sci. Res. Essays, V7, P2002
   Suhatril M, 2019, GEOTECH GEOL ENG, V37, P2007, DOI 10.1007/s10706-018-0740-3
   Tahmasbi F, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0156989
   Toghroli A., 2017, P 5 INT C ADV CIV ST
   Toghroli A, 2020, CONSTR BUILD MATER, V252, DOI 10.1016/j.conbuildmat.2020.118997
   Toghroli A, 2018, J INTELL MANUF, V29, P1793, DOI 10.1007/s10845-016-1217-y
   Toghroli A, 2018, SMART STRUCT SYST, V22, P433, DOI 10.12989/sss.2018.22.4.433
   Toghroli Ali, 2014, Steel and Composite Structures, An International Journal, V17, P623, DOI 10.12989/scs.2014.17.5.623
   Wang H, 2017, OPT LASER TECHNOL, V88, P11, DOI 10.1016/j.optlastec.2016.08.015
   Wang KN, 2022, KNOWL-BASED SYST, V235, DOI 10.1016/j.knosys.2021.107675
   Wei X, 2018, STEEL COMPOS STRUCT, V27, P389, DOI 10.12989/scs.2018.27.3.389
   Wu H, 2015, OPT LASER TECHNOL, V73, P166, DOI 10.1016/j.optlastec.2015.04.029
   Xie Q, 2019, STEEL COMPOS STRUCT, V30, P433, DOI 10.12989/scs.2019.30.5.433
   Xiong ZG, 2022, J SIGNAL PROCESS SYS, V94, P1129, DOI 10.1007/s11265-021-01737-0
   Yang WD, 2021, INFORM SCIENCES, V570, P526, DOI 10.1016/j.ins.2021.05.009
   Yazdani M, 2021, J CLEAN PROD, V280, DOI 10.1016/j.jclepro.2020.124138
   Zandi Y, 2018, STEEL COMPOS STRUCT, V28, P439, DOI 10.12989/scs.2018.28.4.439
   Zhang Y, 2021, ACS PHOTONICS, V8, P202, DOI 10.1021/acsphotonics.0c01269
   Zhao ZL, 2018, OPT COMMUN, V410, P123, DOI 10.1016/j.optcom.2017.09.101
   Zheng W, 2021, IEEE T RELIAB, V70, P1658, DOI 10.1109/TR.2021.3118026
   Zheng WF, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.908
   Zheng WF, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.613
   Zhong L, 2023, IEEE T NEUR NET LEAR, V34, P3859, DOI 10.1109/TNNLS.2021.3119965
   Ziaei-Nia A, 2018, STEEL COMPOS STRUCT, V29, P67, DOI 10.12989/scs.2018.29.1.067
   Zuo C, 2022, LIGHT-SCI APPL, V11, DOI 10.1038/s41377-022-00714-x
NR 126
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40469
EP 40488
DI 10.1007/s11042-022-13116-3
EA MAY 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000793007000003
DA 2024-07-18
ER

PT J
AU Mondal, UK
   Debnath, A
AF Mondal, Uttam Kr
   Debnath, Asish
TI Designing a novel lossless audio compression technique with the help of
   optimized graph traversal (LACOGT)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Graph based encoding; Huffman encoding; Directed graph traversal;
   Lossless audio compression
AB In this paper, a lossless audio encoding technique has been proposed with the help of an optimized graph traversal and its performance is further enhanced by applying basic principles of Huffman encoding. Parsing each of the sampled values of input audio and representing each individual digit by the suitable path matching in the proposed weightage graph followed by a combination of dynamic bit sequence (directed graph traversal) produces the compressed audio format. Experimental results are incorporated with statistical parameters (compression ratio, SNR, PSNR) along with other parameters (Mean Opinion Score (MOS) and Entropy) and compared with existing lossless techniques for justifying its performance.
C1 [Mondal, Uttam Kr] Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, WB, India.
   [Debnath, Asish] Tata Consultancy Serv Ltd, Kolkata, WB, India.
C3 Vidyasagar University; Tata Sons; Tata Consultancy Services Limited
   (TCS)
RP Mondal, UK (corresponding author), Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, WB, India.
EM uttam_ku_82@yahoo.co.in; debnathasish@gmail.com
RI Mondal, Uttam Kumar/AAX-6400-2021
OI Mondal, Uttam/0000-0002-7794-9287
CR Arnold M., 2000, 2000 IEEE INT C MULT, V2
   Concord A., 2010, MUSICOLOGICAL EXPLOR, V11, P136
   Farzaneh M, 2018, 2018 9TH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), P410, DOI 10.1109/ISTEL.2018.8661027
   Ghido F, 2013, IEEE T AUDIO SPEECH, V21, P12, DOI 10.1109/TASL.2012.2211014
   Gunawan TS, 2017, Indones J Electr Eng Comput Sci, V6, P422
   Jiang X., 2019, Deep learning in object detection and recognition
   Kotha HD, 2019, J PHYS CONF SER, V1228, DOI 10.1088/1742-6596/1228/1/012007
   Kutter M., 1999, SECURITY WATERMARKIN, V3657
   Li Z. N., 2014, FUNDAMENTALS MULTIME
   Michalski P, 2018, ADV INTELL SYST COMP, V720, P98, DOI 10.1007/978-3-319-75025-5_10
   Moffat A, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3342555
   Mohdar F. J., 2011, IMAGE PROCESSING COM
   Mondal U. K., 2020, INTELLIGENT COMPUTIN, P91101
   Mondal UK, 2021, MULTIMED TOOLS APPL, V80, P8257, DOI 10.1007/s11042-020-09886-3
   monkeysaudio.com, INDEXHTML
   Nowak N., 2011, METHODS SOUND DATA C
   ocw.mit.edu/courses, ELECT ENG AND COMPUT
   Prasad B., 2008, SPEECH AUDIO IMAGE B, V83
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Streijl RC, 2016, MULTIMEDIA SYST, V22, P213, DOI 10.1007/s00530-014-0446-1
   Ulacha G, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9235218
   www.eecs.umich.edu/, COURSES
   www.itu.int/dms_pubrec, REC BT500 13 201201
   xiph.org, INDEXHTML
NR 24
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40385
EP 40411
DI 10.1007/s11042-022-12556-1
EA MAY 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000791885300001
DA 2024-07-18
ER

PT J
AU Raju, D
   Eleswarapu, L
   Pranav, MS
   Sinha, RK
AF Raju, Deril
   Eleswarapu, Lalitha
   Pranav, Muppidi Sai
   Sinha, Rupesh Kumar
TI Multi-level image security using elliptic curve and magic matrix with
   advanced encryption standard
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-level image security; Image cryptography; Elliptic curve
   cryptography; Magic matrix and advanced encryption standard
ID CRYPTOGRAPHIC PROCESSOR; DESIGN; CHAOS
AB Recently, many image encryptions models have been proposed using elliptic curve cryptography and magic matrix. But with security being the highest priority while transferring sensitive information, models nowadays are required to withstand robust hacking without compromising on the speed of the system. This work proposes an image encryption scheme using a combination of elliptic curves, magic matrix, and AES (Advanced Encryption Standard) to provide greater security to the image encryption operation. The pixel intensity values of the image are first transformed by a substitution method utilizing elliptic curves. These pixels are subjected to another round of value transformation before being scrambled according to the magic matrix algorithm in the second stage of the encryption process. The scrambling process ensures position transformation of the pixels in the image. The last encryption stage uses the AES technique to generate a 128-bit key and encrypt the entire image in a block-by-block manner. This was done to provide an additional layer of security and obtain better results when compared to other encryption models. The proposed technique is simulated using MATLAB. After the process of image encryption and decryption, the model's performance was assessed using parameters like mean square error, correlation coefficient, entropy, NPCR (Number of pixels change rate), and UACI (Unified average changing intensity).
C1 [Raju, Deril; Eleswarapu, Lalitha; Pranav, Muppidi Sai; Sinha, Rupesh Kumar] Birla Inst Technol Mesra, Dept Elect & Commun Engn, Ranchi 835215, Bihar, India.
C3 Birla Institute of Technology Mesra
RP Sinha, RK (corresponding author), Birla Inst Technol Mesra, Dept Elect & Commun Engn, Ranchi 835215, Bihar, India.
EM rk.sinha@bitmesra.ac.in
CR Abd Elminaam DiaaSalama., 2010, IJ NETWORK SECURITY, V10, P216
   Abd-El-Hafiz SK, 2014, IET IMAGE PROCESS, V8, P742, DOI 10.1049/iet-ipr.2013.0570
   Adam B, 2013, ADV ENCRYPTION STAND
   afify E., 2020, INT J RECENT TECHNOL, V9, P2214, DOI [10.35940/ijrte.F9712.059120, DOI 10.35940/IJRTE.F9712.059120]
   AL-Hashemy RH, 2020, J INTELL SYST, V29, P1202, DOI 10.1515/jisys-2018-0404
   Amalarethinam DIG, 2015, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTING AND COMMUNICATIONS TECHNOLOGIES (ICCCT 15), P133, DOI 10.1109/ICCCT2.2015.7292733
   Aydos M, 2001, IEE P-COMMUN, V148, P273, DOI 10.1049/ip-com:20010511
   Chen G, 2007, IEEE T CIRCUITS-II, V54, P412, DOI 10.1109/TCSII.2006.889459
   Chen JX, 2015, NONLINEAR DYNAM, V81, P1151, DOI 10.1007/s11071-015-2057-6
   Cheung RCC, 2005, IEEE T VLSI SYST, V13, P1048, DOI 10.1109/TVLSI.2005.857179
   Cilardo A, 2006, P IEEE, V94, P395, DOI 10.1109/JPROC.2005.862438
   Finnigin K. M., 2007, International Journal of Security and Networks, V2, P260, DOI 10.1504/IJSN.2007.013179
   Ganapathi G, 2009, P WORLD C ENG COMP S, V1
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   He PC, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6679288
   IEEE, 13632000 IEEE
   Khalane V., 2020, International Journal of Safety and Security Engineering, V10, P655
   Khare A, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18050201
   Lee J., 2007, INT J NETWORK SECURI, VA, P99
   Loukhaoukha K, 2012, J ELECTR COMPUT ENG, V2012, DOI 10.1155/2012/173931
   Lu CC, 2002, IEEE INT CONF ASAP, P277, DOI 10.1109/ASAP.2002.1030726
   Manjula, 2020, J INTERDISCIP RES, V1, P67
   McIvor CJ, 2006, IEEE T CIRCUITS-I, V53, P1946, DOI 10.1109/TCSI.2006.880184
   Nadeem A., 2005, Information and Communication Technologies, ICICT, V2005, P84, DOI DOI 10.1109/ICICT.2005.1598556
   Shaktawat R., 2020, RELIAB THEORY APPL, V15, P51
   Sharma P., 2020, Int J Eng Res, VV9, P194, DOI [10.17577/ijertv9is080083, DOI 10.17577/IJERTV9IS080083]
   Stallings W., 2006, Cryptography and Network Security, V4th
   Tong XJ, 2013, COMMUN NONLINEAR SCI, V18, P1725, DOI 10.1016/j.cnsns.2012.11.002
   Wang XY, 2013, COMMUN NONLINEAR SCI, V18, P3075, DOI 10.1016/j.cnsns.2013.04.008
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Ye GD, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/8402578
   Zhang R, 2020, INT J DISTRIB SENS N, V16, DOI 10.1177/1550147720912949
   Zhang YP, 2012, ADV INTEL SOFT COMPU, V149, P103
   Zhu C., 2014, SPEC ISSUE RECENT AD, V2014
NR 34
TC 2
Z9 2
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37783
EP 37803
DI 10.1007/s11042-022-12993-y
EA APR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000784679100001
DA 2024-07-18
ER

PT J
AU Wang, YW
   Yan, WQ
AF Wang, Yuewei
   Yan, Wei Qi
TI Colorizing Grayscale CT images of human lungs using deep learning
   methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Colorization; Deep learning; CNN; Lung CT images
ID SEGMENTATION; MODEL
AB Image colorization refers to computer-aided rendering technology which transfers colors from a reference color image to grayscale images or video frames. Deep learning elevated notably in the field of image colorization in the past years. In this paper, we formulate image colorization methods relying on exemplar colorization and automatic colorization, respectively. For hybrid colorization, we select appropriate reference images to colorize the grayscale CT images. The colours of meat resemble those of human lungs, so the images of fresh pork, lamb, beef, and even rotten meat are collected as our dataset for model training. Three sets of training data consisting of meat images are analysed to extract the pixelar features for colorizing lung CT images by using an automatic approach. Pertaining to the results, we consider numerous methods (i.e., loss functions, visual analysis, PSNR, and SSIM) to evaluate the proposed deep learning models. Moreover, compared with other methods of colorizing lung CT images, the results of rendering the images by using deep learning methods are significantly genuine and promising. The metrics for measuring image similarity such as SSIM and PSNR have satisfactory performance, up to 0.55 and 28.0, respectively. Additionally, the methods may provide novel ideas for rendering grayscale X-ray images in airports, ferries, and railway stations.
C1 [Wang, Yuewei; Yan, Wei Qi] Auckland Univ Technol, Auckland 1010, New Zealand.
C3 Auckland University of Technology
RP Yan, WQ (corresponding author), Auckland Univ Technol, Auckland 1010, New Zealand.
EM dcsyanwq@gmail.com
RI Wang, Jinyang/JXN-8650-2024
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions.
CR Agatonovic-Kustrin S, 2000, J PHARMACEUT BIOMED, V22, P717, DOI 10.1016/S0731-7085(99)00272-1
   Aimar A, 2019, IEEE T NEUR NET LEAR, V30, P644, DOI 10.1109/TNNLS.2018.2852335
   Baldassarre F., 2017, DEEP KOALARIZATION I
   Bugeau A, 2014, IEEE T IMAGE PROCESS, V23, P298, DOI 10.1109/TIP.2013.2288929
   Buzug TM, 2011, SPRINGER HANDBOOK OF MEDICAL TECHNOLOGY, P311
   Charpiat G, 2008, LECT NOTES COMPUT SC, V5304, P126, DOI 10.1007/978-3-540-88690-7_10
   Chen MJ, 2011, J REAL-TIME IMAGE PR, V6, P281, DOI 10.1007/s11554-010-0170-9
   Cheng ZZ, 2015, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2015.55
   Chia AYS, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024190
   Fan DP, 2020, IEEE T MED IMAGING, V39, P2626, DOI 10.1109/TMI.2020.2996645
   Galun M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P716
   Gupta R. K., 2012, P 20 ACM INT C MULT, P369, DOI DOI 10.1145/2393347.2393402
   He MM, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3292482
   Hodnett M., 2018, R Deep Learning Essentials: A Step-by-Step Guide to Building Deep Learning Models Using TensorFlow, Keras, and MXNet
   Ironi R., 2005, RENDERING TECHNIQUES, P201
   Johnson DH., 2006, SCHOLARPEDIA, V1, P2088, DOI [DOI 10.4249/SCHOLARPEDIA.2088, 10.4249/scholarpedia.2088]
   Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Liu XP, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409105
   Luan Q., 2007, P 18 EUR C CREND TEC, P309
   Morimoto Y, 2009, SIGGRAPH 2009 TALKS
   Pan F, 2020, RADIOLOGY, V295, P715, DOI 10.1148/radiol.2020200370
   Pandey ATS., 2019, INT J SCI RES ENG TR, V5, P2258
   Qu YG, 2006, ACM T GRAPHIC, V25, P1214, DOI 10.1145/1141911.1142017
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Skora D., 2004, P 3 INT S NONPH AN R, P121, DOI DOI 10.1145/987657.987677
   Tai YW, 2005, PROC CVPR IEEE, P747
   Verdun FR, 2015, PHYS MEDICA, V31, P823, DOI 10.1016/j.ejmp.2015.08.007
   Wang Y., 2021, THESIS AUCKLAND U TE
   Welsh T, 2002, ACM T GRAPHIC, V21, P277, DOI 10.1145/566570.566576
   Wu ZF, 2019, PATTERN RECOGN, V90, P119, DOI 10.1016/j.patcog.2019.01.006
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yatziv L, 2006, IEEE T IMAGE PROCESS, V15, P1120, DOI 10.1109/TIP.2005.864231
   Zhang LJ, 2013, EUR RADIOL, V23, P2666, DOI 10.1007/s00330-013-2907-x
   Zhang R, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073703
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zujovic J, 2013, IEEE T IMAGE PROCESS, V22, P2545, DOI 10.1109/TIP.2013.2251645
NR 37
TC 2
Z9 4
U1 8
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37805
EP 37819
DI 10.1007/s11042-022-13062-0
EA APR 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000786824500007
PM 35475169
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Gu, RS
   Jiang, ZY
   Wang, GA
   McQuade, K
   Hwang, JN
AF Gu, Renshu
   Jiang, Zhongyu
   Wang, Gaoang
   McQuade, Kevin
   Hwang, Jenq-Neng
TI Unsupervised universal hierarchical multi-person 3D pose estimation for
   natural scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D human pose estimation; Monocular camera; Moving camera; Hierarchical
   human pose estimation; Motion capture
AB Multi-person 3D pose estimation using a monocular freely moving camera in real-world scenarios remains a challenge. There is a lack of data with 3D ground truth, and real-world scenes usually contain self-occlusions and inter-person occlusions. To address these challenges, an unsupervised Universal Hierarchical 3D Human Pose Estimation (UH3DHPE) method that optimizes the torso and limb poses based on a hierarchical framework is proposed. To handle the case of an occluded or inaccurate 2D torso keypoints, which play an important role for 3D pose initialization and subsequent inference, an effective method to directly estimate limb poses without building upon the estimated torso pose is proposed, and the torso pose can then be further refined to form the hierarchy in a bottom-up fashion. An adaptive merging strategy is proposed to determine the best hierarchy. To verify the effectiveness of the proposed scheme, a video dataset for multi-person interactions is collected by a moving camera, under a Motion Capture (MoCap) ground truth data acquisition environment, for our performance evaluations. Experimental results show the proposed method outperforms state-of-the-art methods on the multi-person moving camera scenarios.
C1 [Gu, Renshu] Hangzhou Dianzi Univ, Comp & Software Sch, Hangzhou, Zhejiang, Peoples R China.
   [Jiang, Zhongyu; Hwang, Jenq-Neng] Univ Washington, Elect & Comp Engn, Seattle, WA 98195 USA.
   [Wang, Gaoang] Zhejiang Univ, Univ Illinois, Urbana Champaign Inst, Hailing, Zhejiang, Peoples R China.
   [McQuade, Kevin] Univ Washington, Sch Med, Seattle, WA USA.
C3 Hangzhou Dianzi University; University of Washington; University of
   Washington Seattle; Zhejiang University; University of Washington;
   University of Washington Seattle
RP Wang, GA (corresponding author), Zhejiang Univ, Univ Illinois, Urbana Champaign Inst, Hailing, Zhejiang, Peoples R China.
EM gaoangwang@intl.zju.edu.cn
RI WANG, GAOANG/GNM-8993-2022; Jiang, Zhongyu/HZH-7683-2023
OI Wang, Gaoang/0000-0002-8403-1538
FU Zhejiang Provincial Science and Technology Program in China [2021C01108,
   LQ22F020026]; National Key RD Program of China [2020YFB1709402];
   Fundamental Research Funds for the Provincial Universities of Zhejiang
   [GK219909299001-028]; National Natural Science Foundation of China
   [U20A20386]; Zhejiang Key Research and Development Program [2020C01050];
   National Nature Science Foundation of China [61772163]; Zhejiang
   Provincial Science and Technology Programin China [2021C01108]
FX This research was supported by the Zhejiang Provincial Science and
   Technology Programin China (Grant No. LQ22F020026), the National Key RD
   Program of China under Grant No. 2020YFB1709402, the Fundamental
   Research Funds for the Provincial Universities of Zhejiang (Grant No.
   GK219909299001-028), the National Natural Science Foundation of China
   under Grant No. U20A20386, Zhejiang Provincial Science and Technology
   Programin China under Grant 2021C01108, the Zhejiang Key Research and
   Development Program under Grant No. 2020C01050, and the National Nature
   Science Foundation of China under Grant Nos. 61772163.
CR Arnab A, 2019, PROC CVPR IEEE, P3390, DOI 10.1109/CVPR.2019.00351
   Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Gao XS, 2003, IEEE T PATTERN ANAL, V25, P930, DOI 10.1109/TPAMI.2003.1217599
   Gu RS, 2020, IEEE T CIRC SYST VID, V30, P4245, DOI 10.1109/TCSVT.2019.2953678
   Gu Rongzhi, 2020, ARXIV PREPRINT ARXIV
   Guo SJ, 2015, IEEE GLOB COMM CONF, DOI 10.1109/GLOCOM.2015.7417800
   Hossain MRI, 2018, LECT NOTES COMPUT SC, V11214, P69, DOI 10.1007/978-3-030-01249-6_5
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Kay W., 2017, ARXIV170506950
   Lee G. H., 2019, ARXIV190808289
   Li SJ, 2015, IEEE I CONF COMP VIS, P2848, DOI 10.1109/ICCV.2015.326
   Li SJ, 2015, LECT NOTES COMPUT SC, V9004, P332, DOI 10.1007/978-3-319-16808-1_23
   Martinez J, 2017, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2017.288
   Mitra R, 2020, PROC CVPR IEEE, P6906, DOI 10.1109/CVPR42600.2020.00694
   Moon G, 2019, IEEE I CONF COMP VIS, P10132, DOI 10.1109/ICCV.2019.01023
   Nie BX, 2017, IEEE I CONF COMP VIS, P3467, DOI 10.1109/ICCV.2017.373
   Pavllo D, 2019, PROC CVPR IEEE, P7745, DOI 10.1109/CVPR.2019.00794
   POWELL MJD, 1964, COMPUT J, V7, P155, DOI 10.1093/comjnl/7.2.155
   Ramakrishna V, 2012, LECT NOTES COMPUT SC, V7575, P573, DOI 10.1007/978-3-642-33765-9_41
   Rogez G, 2020, IEEE T PATTERN ANAL, V42, P1146, DOI 10.1109/TPAMI.2019.2892985
   Rogez G, 2017, PROC CVPR IEEE, P1216, DOI 10.1109/CVPR.2017.134
   Shu T., 2016, IJCAI
   Simo-Serra E, 2013, PROC CVPR IEEE, P3634, DOI 10.1109/CVPR.2013.466
   Tekin B, 2017, IEEE I CONF COMP VIS, P3961, DOI 10.1109/ICCV.2017.425
   Tekin B, 2016, PROC CVPR IEEE, pCP8, DOI 10.1109/CVPR.2016.113
   von Marcard T, 2018, LECT NOTES COMPUT SC, V11214, P614, DOI 10.1007/978-3-030-01249-6_37
   Wandt B, 2016, IEEE T PATTERN ANAL, V38, P1505, DOI 10.1109/TPAMI.2016.2553028
   Wang CY, 2019, IEEE T PATTERN ANAL, V41, P1227, DOI 10.1109/TPAMI.2018.2828427
   Wang GA, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P482, DOI 10.1145/3343031.3350853
   Xu JW, 2020, PROC CVPR IEEE, P896, DOI 10.1109/CVPR42600.2020.00098
   Yasin H, 2016, PROC CVPR IEEE, P4948, DOI 10.1109/CVPR.2016.535
   Zhou XY, 2017, IEEE I CONF COMP VIS, P398, DOI 10.1109/ICCV.2017.51
NR 34
TC 0
Z9 0
U1 3
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 32883
EP 32906
DI 10.1007/s11042-022-13079-5
EA APR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000782717900001
DA 2024-07-18
ER

PT J
AU Vaish, PP
   Rani, K
   Kumar, S
AF Vaish, Pranshu Prakash
   Rani, Kumi
   Kumar, Sunil
TI Cyclic learning rate based HybridSN model for hyperspectral image
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral image classification; Deep learning; Convolutional neural
   network; Cyclic learning
AB Classification of remotely sensed hyperspectral images (HSI) is a challenging task due to the presence of a large number of spectral bands and due to the less available data of remotely sensed HSI. The use of 3D-CNN and 2D-CNN layers to extract spectral and spatial features shows good test results. The recently introduced HybridSN model for the classification of remotely sensed hyperspectral images is the best to date compared to the other state-of-the-art models. But the test performance of the HybridSN model decreases significantly with the decrease in training data or number of training epochs. In this paper, we have considered cyclic learning for training of the HybridSN model, which shows a significant increase in the test performance of the HybridSN model with 10%, 20%, and 30% training data and limited number of training epochs. Further, we introduce a new cyclic function (ncf) whose training and test performance is comparable to the existing cyclic learning rate policies. More precisely, the proposed HybridSN(ncf ) model has higher average accuracy compared to HybridSN model by 19.47%, 1.81% and 8.33% for Indian Pines, Salinas Scene and University of Pavia datasets respectively in case of 10% training data and limited number of training epochs.
C1 [Vaish, Pranshu Prakash] Microsoft India Dev Ctr, Intelligent Conversat & Commun Cloud, Hyderabad, India.
   [Vaish, Pranshu Prakash; Rani, Kumi; Kumar, Sunil] Indian Inst Technol BHU Varanasi, Dept Math Sci, Varanasi 221005, Uttar Pradesh, India.
C3 Microsoft; Indian Institute of Technology System (IIT System); Indian
   Institute of Technology BHU Varanasi (IIT BHU Varanasi)
RP Kumar, S (corresponding author), Indian Inst Technol BHU Varanasi, Dept Math Sci, Varanasi 221005, Uttar Pradesh, India.
EM pranshup.vaish.mat16@iitbhu.ac.in; kumichauhan@gmail.com;
   skumar.iitd@gmail.com
RI Kumar, Sunil/ABU-7487-2022; Kumar, Sunil/Q-8557-2016
OI KUMAR, SUNIL/0000-0001-9991-1012; Rani, Kumi/0000-0002-8733-5844
CR Camps-Valls G, 2006, IEEE GEOSCI REMOTE S, V3, P93, DOI 10.1109/LGRS.2005.857031
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Fang LY, 2018, IEEE T GEOSCI REMOTE, V56, P3534, DOI 10.1109/TGRS.2018.2801387
   Feng F, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235276
   Ge ZX, 2020, IEEE J-STARS, V13, P5776, DOI 10.1109/JSTARS.2020.3024841
   He X, 2021, IEEE GEOSCI REMOTE S, V18, P876, DOI 10.1109/LGRS.2020.2988494
   Hinton Geoffrey, 2012, CITED, V14
   Jackson J. E., 2005, USERS GUIDE PRINCIPA
   Jing XY, 2016, PATTERN RECOGN, V59, P14, DOI 10.1016/j.patcog.2016.01.023
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Kingma D. P., 2014, arXiv
   Li J, 2015, IEEE T GEOSCI REMOTE, V53, P1592, DOI 10.1109/TGRS.2014.2345739
   Li YT, 2020, PROC SPIE, V11373, DOI 10.1117/12.2557384
   Makantasis K, 2015, INT GEOSCI REMOTE SE, P4959, DOI 10.1109/IGARSS.2015.7326945
   Mohan A, 2021, J REAL-TIME IMAGE PR, V18, P1681, DOI 10.1007/s11554-020-00966-z
   Mou LC, 2017, IEEE T GEOSCI REMOTE, V55, P3639, DOI 10.1109/TGRS.2016.2636241
   Nyasaka D., 2020, ARXIV200202585
   Paul A, 2021, NEURAL COMPUT APPL, V33, P1575, DOI 10.1007/s00521-020-05069-1
   Roy SK, 2020, IEEE GEOSCI REMOTE S, V17, P277, DOI 10.1109/LGRS.2019.2918719
   Smith LN, 2017, IEEE WINT CONF APPL, P464, DOI 10.1109/WACV.2017.58
   Wu F, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107632
   Wu F, 2020, IEEE T CYBERNETICS, V50, P1009, DOI 10.1109/TCYB.2018.2876591
   Yang JH, 2018, IEEE GEOSCI REMOTE S, V15, P112, DOI 10.1109/LGRS.2017.2776113
   Yang SS, 2022, IEEE T NEUR NET LEAR, V33, P4861, DOI 10.1109/TNNLS.2021.3061630
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P2801, DOI 10.1109/TNNLS.2020.3045492
   Yang SM, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.601109
   Yang SM, 2020, IEEE T NEUR NET LEAR, V31, P148, DOI 10.1109/TNNLS.2019.2899936
   Yang SM, 2019, IEEE T FUZZY SYST, V27, P304, DOI 10.1109/TFUZZ.2018.2856182
   Yang SM, 2018, PHYSICA A, V494, P484, DOI 10.1016/j.physa.2017.11.155
   Zeiler Matthew D, 2012, ARXIV12125701
   Zhong ZL, 2018, IEEE T GEOSCI REMOTE, V56, P847, DOI 10.1109/TGRS.2017.2755542
   Zhu L, 2018, IEEE T GEOSCI REMOTE, V56, P5046, DOI 10.1109/TGRS.2018.2805286
NR 32
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 32723
EP 32738
DI 10.1007/s11042-022-12679-5
EA APR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000783454500001
DA 2024-07-18
ER

PT J
AU Lakra, M
   Kumar, S
AF Lakra, Mahima
   Kumar, Sanjeev
TI Solving a generalized order improved diffusion equation of image
   denoising using a CeNN-based scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anisotropic diffusion; Cellular neural network; Generalized order
   derivative; Speckle noise; Ultrasound images
ID OPTICAL COHERENCE TOMOGRAPHY; ANISOTROPIC DIFFUSION; SPECKLE NOISE;
   ULTRASOUND IMAGES; EDGE-DETECTION; REMOVAL; COEFFICIENT; REDUCTION;
   THRESHOLD; FILTER
AB This paper presents a novel algorithm for image denoising using an improved nonlinear diffusion PDE model and a cellular neural network (CeNN) scheme. In particular, the images corrupted with multiplicative (speckle) noise have been considered. The proposed generalized-order nonlinear diffusion (GOND) model is solved through a suitable cellular neural network (CeNN) approach. The CeNN templates act like edge-preserving filters to reduce the multiplicative noise. The present study also gives a convergence analysis of the proposed CeNN based solution scheme. Further, the proposed scheme is numerically validated on synthetic, medical, and real SAR images. The obtained results demonstrate that the proposed algorithm provides a better way to deal with speckle noise and suppresses the staircase effects. To broaden the simulation results, the proposed method is applied to images corrupted with Gaussian, Rayleigh, and gamma noise. The proposed method for SSIM values interpret 0.2dB to 0.4dB better than state-of-the-art methods and comparative results in terms of PSNR in most test cases.
C1 [Lakra, Mahima; Kumar, Sanjeev] Indian Inst Technol Roorkee, Dept Math, Roorkee 247667, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee
RP Lakra, M (corresponding author), Indian Inst Technol Roorkee, Dept Math, Roorkee 247667, Uttar Pradesh, India.
EM mahima@ma.iitr.ac.in; sanjeev.kumar@ma.iitr.ac.in
RI Kumar, Sanjeev/JTV-5459-2023; Kumar, Sanjeev/HKN-6866-2023
OI Kumar, Sanjeev/0000-0001-7728-3668
FU University Grant Commission (UGC) [412261]
FX One of the authors Mahima is thankful the support of University Grant
   Commission (UGC) during her Ph.D through Ref. No. 412261.
CR Aja-Fernández S, 2006, IEEE T IMAGE PROCESS, V15, P2694, DOI 10.1109/TIP.2006.877360
   [Anonymous], 1982, Digital Picture Processing
   Bai J, 2007, IEEE T IMAGE PROCESS, V16, P2492, DOI 10.1109/TIP.2007.904971
   Bezerra HG, 2009, JACC-CARDIOVASC INTE, V2, P1035, DOI 10.1016/j.jcin.2009.06.019
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Burger H., 2012, CVPR
   CATTE F, 1992, SIAM J NUMER ANAL, V29, P182, DOI 10.1137/0729012
   CHUA LO, 1992, INT J CIRC THEOR APP, V20, P497, DOI 10.1002/cta.4490200506
   Coupé P, 2009, IEEE T IMAGE PROCESS, V18, P2221, DOI 10.1109/TIP.2009.2024064
   Deledalle CA, 2009, IEEE T IMAGE PROCESS, V18, P2661, DOI 10.1109/TIP.2009.2029593
   Duarte-Salazar CA, 2020, IEEE ACCESS, V8, P15983, DOI 10.1109/ACCESS.2020.2967178
   FROST VS, 1982, IEEE T PATTERN ANAL, V4, P157, DOI 10.1109/TPAMI.1982.4767223
   Fu XY, 2017, IEEE T IMAGE PROCESS, V26, P2944, DOI 10.1109/TIP.2017.2691802
   GERIG G, 1992, IEEE T MED IMAGING, V11, P221, DOI 10.1109/42.141646
   GOODMAN JW, 1976, J OPT SOC AM, V66, P1145, DOI 10.1364/JOSA.66.001145
   Hu SX, 2013, ADV MATH PHYS, V2013, DOI 10.1155/2013/516919
   Huang J, 2013, SIGNAL PROCESS, V93, P684, DOI 10.1016/j.sigpro.2012.09.005
   Jain V., 2009, ADV NEURAL INFORM PR, P769, DOI DOI 10.5555/2981780.2981876
   Janev M, 2011, MATH COMPUT MODEL, V54, P729, DOI 10.1016/j.mcm.2011.03.017
   Jaybhay J., 2015, Signal Image Process. An Int. J, V6, DOI DOI 10.5121/SIPIJ.2015.6306
   Jin ZM, 2011, J MATH IMAGING VIS, V39, P62, DOI 10.1007/s10851-010-0225-3
   Joseph J, 2018, OPTIK, V157, P841, DOI 10.1016/j.ijleo.2017.11.177
   Krissian K, 2004, ANISOTROPIC DIFFUSIO
   Lakra M, 2020, MULTIMED TOOLS APPL, V79, P23887, DOI 10.1007/s11042-020-09077-0
   LEE JS, 1980, IEEE T PATTERN ANAL, V2, P165, DOI 10.1109/TPAMI.1980.4766994
   Li F, 2010, SIAM J IMAGING SCI, V3, P1, DOI 10.1137/090748421
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Menon SN, 2020, ADV INTELL SYST, V1024, P115, DOI 10.1007/978-981-32-9291-8_10
   Nandal Savita, 2018, Proceedings of 2nd International Conference on Computer Vision & Image Processing. CVIP 2017. Advances in Intelligent Systems and Computing (AISC 704), P301, DOI 10.1007/978-981-10-7898-9_25
   Paolo-Civalleri P, 1999, J VLSI SIG PROC SYST, V23, P429, DOI 10.1023/A:1008109505419
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Rafsanjani HK, 2017, DIGIT SIGNAL PROCESS, V64, P71, DOI 10.1016/j.dsp.2017.02.004
   Rahimizadeh N, 2021, MULTIMED TOOLS APPL, V80, P9231, DOI 10.1007/s11042-020-10051-z
   Ramos-Llordén G, 2015, IEEE T IMAGE PROCESS, V24, P345, DOI 10.1109/TIP.2014.2371244
   Steidl G, 2010, J MATH IMAGING VIS, V36, P168, DOI 10.1007/s10851-009-0179-5
   Sudha S., 2009, International journal of computer theory and engineering, V1, P7, DOI 10.7763/IJCTE.2009.V1.2
   Wang F, 2016, IEEE T IMAGE PROCESS, V25, P4222, DOI 10.1109/TIP.2016.2583793
   Wang PY, 2017, IEEE SIGNAL PROC LET, V24, P1763, DOI 10.1109/LSP.2017.2758203
   Wang S, 2018, NUMER ALGORITHMS, V78, P513, DOI 10.1007/s11075-017-0386-x
   Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1
   Xu JT, 2016, SIGNAL PROCESS, V119, P80, DOI 10.1016/j.sigpro.2015.07.017
   Xu Y, 2017, PATTERN ANAL APPL, V20, P579, DOI 10.1007/s10044-016-0590-7
   You YL, 2000, IEEE T IMAGE PROCESS, V9, P1723, DOI 10.1109/83.869184
   Yu JH, 2010, PATTERN RECOGN, V43, P3083, DOI 10.1016/j.patcog.2010.04.006
   Yu YJ, 2002, IEEE T IMAGE PROCESS, V11, P1260, DOI 10.1109/TIP.2002.804279
   Zhang J, 2012, J MATH IMAGING VIS, V43, P39, DOI 10.1007/s10851-011-0285-z
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
NR 48
TC 1
Z9 1
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 32393
EP 32420
DI 10.1007/s11042-022-12998-7
EA APR 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000783454600005
DA 2024-07-18
ER

PT J
AU Nalmpantis, C
   Vrysis, L
   Vlachava, D
   Papageorgiou, L
   Vrakas, D
AF Nalmpantis, Christoforos
   Vrysis, Lazaros
   Vlachava, Danai
   Papageorgiou, Lefteris
   Vrakas, Dimitris
TI Noise invariant feature pooling for the internet of audio things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of audio things; IoAuT; Robust deep learning; Noise robustness;
   Entropy pooling; Speech commands; Speaker recognition
ID TEMPORAL FEATURE INTEGRATION
AB This manuscript discusses the robustness to noise of deep learning models for two audio classification tasks. The first task is a speaker recognition application, trying to identify five different speakers. The second one is a speech command identification where the goal is to classify ten voice commands. These two tasks are very important to make the communication between humans and smart devices as smooth and natural as possible. The emergence of smart home devices such as personal assistants and the deployment of audio based applications in noisy environments raise new challenges and reveal the weaknesses of existing speech recognition systems. Despite the advances of deep learning in audio tasks, most of the proposed architectures are computationally inefficient and very sensitive to noise. This research addresses these problems by proposing two neural architectures that incorporate a novel pooling operation, named entropy pooling. Entropy pooling is based on the principle of maximum entropy. A detailed ablation study is conducted to evaluate the performance of entropy pooling against the classic max and average pooling layers. The neural networks that are developed are based on two architectures, convolutional networks and residual ones. The study shows that entropy based feature pooling improves the robustness of these architectures in the presence of noise.
C1 [Nalmpantis, Christoforos; Vrysis, Lazaros; Vrakas, Dimitris] Aristotle Univ Thessaloniki, Thessaloniki, Greece.
   [Vlachava, Danai] Int Hellen Univ, Thessaloniki, Greece.
   [Papageorgiou, Lefteris] Entranet Ltd, Thessaloniki, Greece.
C3 Aristotle University of Thessaloniki; International Hellenic University
RP Nalmpantis, C (corresponding author), Aristotle Univ Thessaloniki, Thessaloniki, Greece.
EM christofn@csd.auth.gr; lvrysis@auth.gr; danai.vlachava@gmail.com;
   papageorgiou@entranet.gr; dvrakas@csd.auth.gr
RI Vrysis, Lazaros/V-2260-2019
OI Vrysis, Lazaros/0000-0003-2900-4657; Nalmpantis,
   Christoforos/0000-0002-7398-5862
FU European Regional Development Fund of the European Union; Greek national
   funds through the Operational Program Competitiveness, Entrepreneurship
   and Innovation, under the call RESEARCH-CREATE-INNOVATE [T1EDK-00343
   (95699)]; NVIDIA Corporation
FX This research has been co-financed by the European Regional Development
   Fund of the European Union and Greek national funds through the
   Operational Program Competitiveness, Entrepreneurship and Innovation,
   under the call RESEARCH-CREATE-INNOVATE (project code: T1EDK-00343
   (95699) Energy Controlling Voice Enabled Intelligent Smart Home
   Ecosystem).; We gratefully acknowledge the support of NVIDIA Corporation
   with the donation of the Titan Xp GPU used for this research.
CR Abdufattokhov S, 2019, DYN SYST MECH MACH, DOI 10.1109/dynamics47113.2019.8944452
   Achille A, 2018, IEEE T PATTERN ANAL, V40, P2897, DOI 10.1109/TPAMI.2017.2784440
   Alemi A. A., 2017, ICLR, DOI DOI 10.48550/ARXIV.1612.00410
   Bacanin N, 2021, J REAL-TIME IMAGE PR, V18, P1085, DOI 10.1007/s11554-021-01106-x
   Bandanau D, 2016, INT CONF ACOUST SPEE, P4945, DOI 10.1109/ICASSP.2016.7472618
   Bharitkar Sunil, 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P105, DOI 10.1109/ICMLA.2019.00025
   Bo Dong, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P301, DOI 10.1145/3372278.3390730
   Bountourakis V, 2019, ACOUSTICS-BASEL, V1, P410, DOI 10.3390/acoustics1020023
   Boureau Y. L., 2010, P 27 INT C MACH LEAR, P111
   Chen S., 2020, ADV NEURAL INFORM PR, V33
   Chorowski J, 2015, ADV NEUR IN, V28
   Coucke A., 2019, INT CONF ACOUST SPEE, DOI [DOI 10.1109/ICASSP.2019.8683474, DOI 10.1109/icassp.2019.8683474, 10.1109/icassp.2019.8683474]
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Esmaeilpour M, 2020, IEEE T INF FOREN SEC, V15, P2147, DOI 10.1109/TIFS.2019.2956591
   Falcini F, 2017, COMM COM INF SC, V770, P279, DOI 10.1007/978-3-319-67383-7_21
   Fayyad J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20154220
   Han W, 2020, INTERSPEECH, P3610, DOI 10.21437/Interspeech.2020-2059
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He X, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106622
   Phan H, 2016, INTERSPEECH, P3653, DOI 10.21437/Interspeech.2016-123
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Kingma DP, 2015, ADV NEUR IN, V28
   KO CW, 1995, OPER RES, V43, P684, DOI 10.1287/opre.43.4.684
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kusupati A., 2018, P 32 INT C NEUR INF, P9031
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 1990, ADV NEURAL INFORM PR, P396
   Lentzas A, 2019, PROC INT C TOOLS ART, P1412, DOI 10.1109/ICTAI.2019.00199
   Li B, 2020, AS C MACH LEARN, P289
   Li S, 2019, INTERSPEECH, P4400, DOI 10.21437/Interspeech.2019-2112
   Makridis Georgios, 2020, Discovery Science. 23rd International Conference, DS 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science (LNAI 12323), P566, DOI 10.1007/978-3-030-61527-7_37
   Martin-Morato I, 2018, INT CONF SIGN PROCES, P562, DOI 10.1109/ICSP.2018.8652438
   McGraw I, 2016, INT CONF ACOUST SPEE, P5955, DOI 10.1109/ICASSP.2016.7472820
   Nadal JP, 1998, NETWORK-COMP NEURAL, V9, P207, DOI 10.1088/0954-898X/9/2/004
   Nakamura S, 1999, 6 EUR C SPEECH COMM
   Nalmpantis C, 2020, NEURAL COMPUT APPL, DOI 10.1007/s00521-020-04916-5
   Nalmpantis C, 2019, PROC INT C TOOLS ART, P1729, DOI 10.1109/ICTAI.2019.00256
   Nalmpantis C, 2019, COMM COM INF SC, V1000, P80, DOI 10.1007/978-3-030-20257-6_7
   Pervaiz A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082326
   Qu YB, 2020, IEEE INT CONF ELECTR, P323, DOI 10.1109/iceiec49280.2020.9152352
   Shewry MC, 1987, Journal of Applied Statistics, V14, P165, DOI DOI 10.1080/02664768700000020
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Solovyev RA, 2020, 2020 IEEE 40TH INTERNATIONAL CONFERENCE ON ELECTRONICS AND NANOTECHNOLOGY (ELNANO), P688, DOI [10.1109/elnano50318.2020.9088863, 10.1109/ELNANO50318.2020.9088863]
   Sun ZQ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2158
   Tippaya S, 2017, IEEE ACCESS, V5, P12563, DOI 10.1109/ACCESS.2017.2717998
   Turchet L, 2020, IEEE INTERNET THINGS
   Virtsionis Gkalinikis Nikolaos, 2020, Discovery Science. 23rd International Conference, DS 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science (LNAI 12323), P551, DOI 10.1007/978-3-030-61527-7_36
   Viswanathan J, 2021, DEEP LEARNING APPL M, P156
   Vrysis L, 2020, AUDIO ENG SOC CONVEN, V148
   Vrysis L, 2020, J AUDIO ENG SOC, V68, P66, DOI 10.17743/jaes.2019.0058
   Wang KC, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22020183
   Warden P, 2018, ArXiv e-prints: 1804.03209
   Zeng MJ, 2019, IEEE ACCESS, V7, P10767, DOI 10.1109/ACCESS.2019.2891838
   Zhang ZX, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3178115
NR 54
TC 0
Z9 0
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 32057
EP 32072
DI 10.1007/s11042-022-12931-y
EA APR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781124000006
DA 2024-07-18
ER

PT J
AU Pal, A
   Singh, KP
AF Pal, Aniket
   Singh, Krishna Pratap
TI R-GRU: Regularized gated recurrent unit for handwritten mathematical
   expression recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Handwritten; Mathematical; Expression; Recognition; Encoder-Decoder;
   Gated recurrent unit; Dropout; Regularization
AB Handwritten mathematical expression recognition(HMER) plays a wide variety of roles in different domains like online teaching, scientific research, etc. Due to its two-dimensional non-linear structure, it is a challenging problem. In this work, we proposed a novel architecture using regularization(dropout), attention & gated recurrent unit(R-GRU). R-GRU is used as the central decoding unit that takes the intermediate representation produced by the encoder as an input and generates corresponding LaTeX sequences. Simulation on CROHME 2014 and 2016 datasets achieve results comparable to the latest state-of-the-art.
C1 [Pal, Aniket; Singh, Krishna Pratap] Indian Inst Informat Technol, Dept Informat Technol, Machine Learning & Optimizat Lab, Allahabad, Prayagraj, India.
C3 Indian Institute of Information Technology Allahabad
RP Pal, A (corresponding author), Indian Inst Informat Technol, Dept Informat Technol, Machine Learning & Optimizat Lab, Allahabad, Prayagraj, India.
EM phc2017002@iiita.ac.in
FU MoE, Government of India
FX We would like to thank anonymous reviewers for their insightful comments
   and suggestions. Also, we would like to thank MoE, Government of India
   and, IIIT Allahabad for providing research funds and support.
CR ALVARO F, 2015, PATTERN RECOGN, V51
   Alvaro F, 2014, PATTERN RECOGN LETT, V35, P58, DOI 10.1016/j.patrec.2012.09.023
   Anderson R. H., 1968, SYNTAX DIRECTED RECO
   AWAL AM, 2012, PATTERN RECOGN LETT
   Chen X, 2021, INT J COMPUT VISION, V129, P638, DOI 10.1007/s11263-020-01396-x
   Deng Y, 2016, ARXIV160904938 CORR
   Duc AL, 2017, TRAINING END TO END, DOI 10.1109/ICDAR.2017.175
   Garain U, 2004, IEEE T SYST MAN CY B, V34, P2366, DOI 10.1109/TSMCB.2004.836817
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Le, 2020, P IEEE CVF C COMP VI
   Moon T, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P65, DOI 10.1109/ASRU.2015.7404775
   Mouchère H, 2016, INT CONF FRONT HAND, P607, DOI [10.1109/ICFHR.2016.0116, 10.1109/ICFHR.2016.108]
   Mouchère H, 2014, INT CONF FRONT HAND, P791, DOI 10.1109/ICFHR.2014.138
   Mouchere H, 2014, P INT C FRO HANDWR R, DOI 10.1109/ICFHR.2014.42
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang H, 2020, COMPUTER VISION PATT
   Wang J., 2020, MULTIMODAL ATTENTION, DOI DOI 10.1109/ICDAR.2019.00191
   Wu, 2019, IMAGE TO MARKUP GENE, P18, DOI [10.1007/978-3-030-10925-72, DOI 10.1007/978-3-030-10925-72]
   Yamamoto, 2006, ON LINE RECOGNITION
   Zanibbi R, 2002, IEEE T PATTERN ANAL, V24, P1455, DOI 10.1109/TPAMI.2002.1046157
   Zaremba W., 2014, CORR
   Zhang JS, 2018, INT C PATT RECOG, P2245, DOI 10.1109/ICPR.2018.8546031
   Zhang JS, 2017, PATTERN RECOGN, V71, P196, DOI 10.1016/j.patcog.2017.06.017
NR 23
TC 5
Z9 5
U1 3
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31405
EP 31419
DI 10.1007/s11042-022-12889-x
EA APR 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000779805700007
DA 2024-07-18
ER

PT J
AU Wang, Y
   Wang, FC
   Liu, F
   Wang, XH
AF Wang, Yong
   Wang, Fan-chuan
   Liu, Fei
   Wang, Xiao-hu
TI Securing content-based image retrieval on the cloud using generative
   models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval; Generative adversarial networks (GANs);
   Lattice-based homomorphic scheme; secure multiparty computation; Deep
   neural networks (DNNs)
ID FULLY HOMOMORPHIC ENCRYPTION; FEATURE-EXTRACTION
AB Content-based image retrieval (CBIR) with deep neural networks (DNNs) on the cloud has tremendous business and technical advantages to handle large-scale image repositories. However, cloud-based CBIR service raises challenges in image data and DNN model security. Typically, users who wish to request CBIR services on the cloud require their input images remaining confidential. On the other hand, image owners may intentionally (or unintentionally) upload adversarial examples to the cloud servers, which potentially leads to the misbehavior of CBIR services. Generative Adversarial Networks (GANs) can be utilized to defense against such malicious behavior. However, the GANs model, if not well protected, can be easily abused by the cloud to reconstruct the users' original image data. In this paper, we focus on the problem of secure generative model evaluation and secure gradient descent (GD) computation in GANs. We propose two secure generative model evaluation algorithms and two secure minimizer protocols. Furthermore, we propose and implement Sec-Defense-Gan, a secure image reconstruction framework which can keep the image data, the generative model details and corresponding outputs confidential from the cloud. Finally, We carried out a set of benchmarks over two public available image datasets to show the performance and correctness of Sec-Defense-Gan.
C1 [Wang, Yong; Wang, Fan-chuan; Liu, Fei; Wang, Xiao-hu] Univ Elect Sci & Technol China, Ctr Cyber Secur, Sch Comp Sci & Engn, Chengdu, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Wang, Y (corresponding author), Univ Elect Sci & Technol China, Ctr Cyber Secur, Sch Comp Sci & Engn, Chengdu, Peoples R China.
EM cla@uestc.edu.cn
OI wang, yong/0000-0002-0422-5691
FU National Key Research and Development Program of China [2018YFB0804702]
FX ' This work is supported by the National Key Research and Development
   Program of China (Grant No. 2018YFB0804702).
CR Agrawal S, 2011, LECT NOTES COMPUT SC, V7073, P21, DOI 10.1007/978-3-642-25385-0_2
   Bansal M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03488-z
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Brakerski Z, 2011, LECT NOTES COMPUT SC, V6841, P505, DOI 10.1007/978-3-642-22792-9_29
   Brakerski Z, 2011, ANN IEEE SYMP FOUND, P97, DOI 10.1109/FOCS.2011.12
   Chillotti I, 2020, J CRYPTOL, V33, P34, DOI 10.1007/s00145-019-09319-x
   Chillotti I, 2016, LECT NOTES COMPUT SC, V10031, P3, DOI 10.1007/978-3-662-53887-6_1
   Dowlin N, 2016, PR MACH LEARN RES, V48
   ELGAMAL T, 1985, IEEE T INFORM THEORY, V31, P469, DOI 10.1109/TIT.1985.1057074
   Ferreira B, 2015, SYM REL DIST SYST, P11, DOI 10.1109/SRDS.2015.27
   Goldreich O., 2004, Foundations of Cryptography, V2, DOI DOI 10.1017/CBO9780511721656
   GOLDWASSER S, 1989, SIAM J COMPUT, V18, P186, DOI 10.1137/0218012
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hastings M, 2019, P IEEE S SECUR PRIV, P1220, DOI 10.1109/SP.2019.00028
   Hsu CY, 2012, IEEE T IMAGE PROCESS, V21, P4593, DOI 10.1109/TIP.2012.2204272
   Hu SS, 2016, IEEE T IMAGE PROCESS, V25, P3411, DOI 10.1109/TIP.2016.2568460
   Gulrajani I, 2017, ADV NEUR IN, V30
   Juvekar C, 2018, PROCEEDINGS OF THE 27TH USENIX SECURITY SYMPOSIUM, P1651
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Li P, 2017, SOFT COMPUT, V21, P4349, DOI 10.1007/s00500-016-2066-5
   Liu F, 2019, IEEE ACCESS, V7, P119209, DOI 10.1109/ACCESS.2019.2935222
   Mao Q, 2017, MACH LEARN, V106, P627, DOI 10.1007/s10994-016-5602-8
   Nasr M, 2019, P IEEE S SECUR PRIV, P739, DOI 10.1109/SP.2019.00065
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Samangouei P., 2018, 6 INT C LEARN REPR I
   Singh S, 2021, MULTIMED TOOLS APPL, V80, P19753, DOI 10.1007/s11042-021-10711-8
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Wang X, 2019, AT GAN ADVERSARIAL G
   Wang ZB, 2019, IEEE INFOCOM SER, P2512, DOI [10.1109/infocom.2019.8737416, 10.1109/INFOCOM.2019.8737416]
   Zahur Samee, 2015, Cryptol. Eprint Arch, V2015, P1153
   Zheng P., 2013, P 21 ACM INT C MULT, P803
NR 33
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31219
EP 31243
DI 10.1007/s11042-022-12880-6
EA APR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781336500004
PM 35431613
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Singh, K
   Malhotra, J
AF Singh, Kuldeep
   Malhotra, Jyoteesh
TI Smart neurocare approach for detection of epileptic seizures using deep
   learning based temporal analysis of EEG patterns
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Epilepsy; EEG; Fog computing; Internet of things;
   Healthcare
ID BIDIRECTIONAL LSTM; NEURAL-NETWORK; CLASSIFICATION; SYSTEM
AB Epilepsy is a psychosocial neurological disorder, which emerges as a major threat to public health. In this age of the internet of things, the smart diagnosis of epilepsy has gained huge research attention with machine learning-based seizure detection in cloud-fog assisted environments. The present paper also proposes a cloud-fog integrated smart neurocare approach, which performs a temporal analysis of raw electroencephalogram (EEG) signals using deep learning to detect the occurrence of epileptic seizures. This patient-independent approach makes use of single-channel EEG signals to achieve real-time and computationally efficient seizure detection at fog layer devices. It employs a maximum variance-based channel selection procedure to select only one channel of raw scalp EEG signals, followed by their filtering and segmentation into various short-duration temporal segments. To analyse EEG patterns, these segments are further fed to the proposed models of convolutional neural network, recurrent neural network and stacked autoencoder deep learning classifiers. The performance analysis through simulation results evidently reveals that the proposed convolutional neural network-based temporal analysis approach performs better than other approaches. It realises an optimum accuracy of 96.43%, sensitivity of 100% and specificity of 93.33% for 30s duration EEG segments of CHB-MIT dataset and achieves 100% accuracy, sensitivity and specificity values for EEG segments of Bonn dataset for 23.6s EEG segments. Thus, the proposed convolutional neural network-based approach emerges as an appropriate method for rapid and accurate detection of epileptic seizures in fog-cloud integrated environment.
C1 [Singh, Kuldeep] Guru Nanak Dev Univ, Dept Elect Technol, Amritsar, Punjab, India.
   [Malhotra, Jyoteesh] Guru Nanak Dev Univ, Dept Engn & Technol, Reg Campus, Jalandhar, Punjab, India.
C3 Guru Nanak Dev University; Guru Nanak Dev University
RP Singh, K (corresponding author), Guru Nanak Dev Univ, Dept Elect Technol, Amritsar, Punjab, India.
EM kuldeep.ece@gndu.ac.in
RI Singh, Kuldeep/AAF-1963-2020; Malhotra, Jyoteesh/AAN-9159-2020
OI Singh, Kuldeep/0000-0003-1465-6740; Malhotra,
   Jyoteesh/0000-0002-7016-9982
CR Aayesha, 2021, MULTIMED TOOLS APPL, V80, P17849, DOI 10.1007/s11042-021-10597-6
   Abdullah H, 2014, 15 INT C BIOM ENG, P695, DOI DOI 10.1007/978-3-319-02913-9_177
   Acharya UR, 2018, COMPUT BIOL MED, V100, P270, DOI 10.1016/j.compbiomed.2017.09.017
   Acharya UR, 2012, BIOMED SIGNAL PROCES, V7, P401, DOI 10.1016/j.bspc.2011.07.007
   Ahmadi Z, 2021, MULTIMED TOOLS APPL, V80, P36361, DOI 10.1007/s11042-021-11227-x
   Ahmedt-Aristizabal D, 2018, IEEE ENG MED BIO, P332, DOI 10.1109/EMBC.2018.8512249
   Aktas F, 2018, J MED BIOL ENG, V38, P966, DOI 10.1007/s40846-017-0349-7
   Akut R, 2019, HEALTH INF SCI SYST, V7, DOI 10.1007/s13755-019-0069-1
   Andrzejak RG, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.061907
   [Anonymous], 2002, DALLAS PROJECT
   [Anonymous], 2010, P 27 INT C MACH LEAR, DOI DOI 10.5555/3104322.3104446
   Artameeyanant P, 2017, EXPERT SYST, V34, DOI 10.1111/exsy.12211
   Baratloo A, 2015, EMERGENCY, V3, P48
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Bhardwaj H, 2019, EXPERT SYST, V36, DOI 10.1111/exsy.12338
   Bhurane AA, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12472
   Binder DK, 2013, EPILEPSY BEHAV, V26, P247, DOI 10.1016/j.yebeh.2012.10.027
   Capra M, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11040100
   Chicco D, 2020, BMC GENOMICS, V21, DOI 10.1186/s12864-019-6413-7
   Craik A, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/ab0ab5
   Daoud H, 2020, IEEE T BIOMED CIRC S, V14, P209, DOI 10.1109/TBCAS.2019.2957087
   Dastjerdi AV, 2016, COMPUTER, V49, P112, DOI 10.1109/MC.2016.245
   Faust O, 2018, COMPUT METH PROG BIO, V161, P1, DOI 10.1016/j.cmpb.2018.04.005
   Ferri R, 2021, CLIN NEUROPHYSIOL, V132, P232, DOI 10.1016/j.clinph.2020.09.015
   Ghasemi F, 2019, INT J COMMUN SYST, V32, DOI 10.1002/dac.4002
   Giri D, 2013, KNOWL-BASED SYST, V37, P274, DOI 10.1016/j.knosys.2012.08.011
   Goldberger AL, 2020, PHYSIOBANK PHYSIOTOO
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Guo JM, 2019, MULTIMED TOOLS APPL, V78, P29059, DOI 10.1007/s11042-018-6378-6
   Guo T, 2016, PROCEEDINGS OF 3RD IEEE/ACM INTERNATIONAL CONFERENCE ON DATA SCIENCE AND ADVANCED ANALYTICS, (DSAA 2016), P816, DOI 10.1109/DSAA.2016.92
   Gupta V, 2019, BIOMED SIGNAL PROCES, V53, DOI 10.1016/j.bspc.2019.101569
   Habte TT, 2019, ANALOG CIRC SIG PROC, P7, DOI 10.1007/978-3-319-97016-5_2
   Hassanpour H, 2007, 2007 INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING, P365
   Homan R. W., 1988, American Journal of EEG Technology, V28, P269
   Ilakiyaselvan N, 2020, J BIOMED RES, V34, P240, DOI 10.7555/JBR.34.20190043
   Kannathal N, 2005, COMPUT METH PROG BIO, V80, P17, DOI 10.1016/j.cmpb.2005.06.005
   Ke HJ, 2020, SOFTWARE PRACT EXPER, V50, P596, DOI 10.1002/spe.2668
   Khamparia A, 2019, EXPERT SYST, V36, DOI 10.1111/exsy.12400
   Kraemer FA, 2017, IEEE ACCESS, V5, P9206, DOI 10.1109/ACCESS.2017.2704100
   Kumar M, 2021, 2021 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2021), P257, DOI 10.1109/Confluence51648.2021.9377050
   Kumar M, 2019, J NETW COMPUT APPL, V143, P1, DOI 10.1016/j.jnca.2019.06.006
   Kumar M, 2018, COMPUT ELECTR ENG, V69, P395, DOI 10.1016/j.compeleceng.2017.11.018
   Lever J, 2016, NAT METHODS, V13, P603, DOI 10.1038/nmeth.3945
   Michielli N, 2019, COMPUT BIOL MED, V106, P71, DOI 10.1016/j.compbiomed.2019.01.013
   Mohammadi M, 2018, IEEE COMMUN SURV TUT, V20, P2923, DOI 10.1109/COMST.2018.2844341
   Mora H, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102302
   NINDS, 2021, EP NAT I NEUR DIS ST
   Raghu S, 2019, EXPERT SYST APPL, V127, P323, DOI 10.1016/j.eswa.2019.03.021
   Robertson DGE, 2003, J ELECTROMYOGR KINES, V13, P569, DOI 10.1016/S1050-6411(03)00080-4
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Salehinejad H., 2017, Recent advances in recurrent neural networks, DOI DOI 10.48550/ARXIV.1801.01078
   Sareen S, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0579-1
   Sareen S, 2016, COMPUT SCI ENG, V18, P56, DOI 10.1109/MCSE.2016.82
   Sharma Goel Shalini, 2021, J RELIABLE INTELLIGE, P1
   Singh K, 2018, 2018 5 INT C COMP SU, P1105
   Singh KJ, 2021, 2021 IEEE LATIN AMERICA ELECTRON DEVICES CONFERENCE (LAEDC), DOI 10.1109/LAEDC51812.2021.9437926
   Singh K, 2021, PHYS ENG SCI MED, V44, P313, DOI 10.1007/s13246-021-00970-y
   Singh K, 2021, P I MECH ENG H, V235, P167, DOI 10.1177/0954411920966937
   Singh K, 2019, J AMB INTEL HUM COMP, DOI 10.1007/s12652-019-01613-7
   Singh K, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P249, DOI 10.1109/ICSCCC.2018.8703357
   Subha DP, 2010, J MED SYST, V34, P195, DOI 10.1007/s10916-008-9231-z
   Thara DK, 2019, PATTERN RECOGN LETT, V128, P529, DOI 10.1016/j.patrec.2019.10.034
   Triesch D., 2019, ARXIV PREPRINT ARXIV
   Ullah I, 2018, EXPERT SYST APPL, V107, P61, DOI 10.1016/j.eswa.2018.04.021
   Upadhyay R, 2016, COMPUT ELECTR ENG, V53, P125, DOI 10.1016/j.compeleceng.2016.05.015
   Upadhyay R, 2016, J BIOL SYST, V24, P1, DOI 10.1142/S0218339016500017
   Upadhyay R, 2015, COMPUT ELECTR ENG, V45, P222, DOI 10.1016/j.compeleceng.2015.03.015
   Vareka L, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00302
   Wang GJ, 2017, NEUROCOMPUTING, V228, P283, DOI 10.1016/j.neucom.2016.09.080
   World Health Organizition, 2019, Epilepsy
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yildirim Ö, 2018, COMPUT BIOL MED, V96, P189, DOI 10.1016/j.compbiomed.2018.03.016
   Zhang, 2019, ARXIV PREPRINT ARXIV
   Zhao W, 2020, COMPUT MATH METHOD M, V2020, DOI 10.1155/2020/9689821
NR 76
TC 21
Z9 21
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 29555
EP 29586
DI 10.1007/s11042-022-12512-z
EA APR 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000778057700002
DA 2024-07-18
ER

PT J
AU Raval, KR
   Goyani, MM
AF Raval, Khushali R.
   Goyani, Mahesh M.
TI A survey on event detection based video summarization for cricket
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sports video analysis; Event detection; Video summarization; Temporal
   segmentation; Shot classification
ID SHOT BOUNDARY DETECTION; TEXT; FEATURES; REPLAY
AB Nowadays, sports video analysis is gaining a lot of traction. Cricket is an exciting team sport to watch. Cricket is becoming more popular, but due to the game's length and intricacy, computerized cricket video analysis is difficult. This motivates us to conduct surveys that will aid in the advancement of cricket research. We reviewed event detection-based cricket video summarizing strategies in this article. We give an overview of the automatic cricket video analysis technique and its applications. Automatic extraction of important events involves low-level analysis for temporal segmentation of video into shots or play-break segments, according to the literature evaluation. To categories cricket video images and extract semantically meaningful events, domain knowledge must be included. Different approaches for shot boundary detection, shot categorization, and event detection are thoroughly examined. Finally, future directions in cricket video analysis are discussed.
C1 [Raval, Khushali R.] Gujarat Technol Univ, Comp Engn Dept, Ahmadabad, Gujarat, India.
   [Goyani, Mahesh M.] Govt Engn Coll, Comp Engn Dept, Modasa, India.
C3 Gujarat Technological University; Government Engineering College Modasa
RP Raval, KR (corresponding author), Gujarat Technol Univ, Comp Engn Dept, Ahmadabad, Gujarat, India.
EM khushiraval@gmail.com; mgoyani@gmail.com
CR Abburu S., 2010, INT J ENG SCI TECHNO, V2, P5377
   Abdulhussain SH, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20040214
   [Anonymous], 2011, 2011 NAT C COMM NCC
   [Anonymous], 2016, IEEE T IND INFORM
   [Anonymous], 2009, ACM INT C MULT
   Asghar Muhammad Nabeel, 2014, International Journal of Computer and Information Technology, V3, P148
   Basappanavar A., 2017, INT RES J ENG TECHNO, V4, P427
   Bhalla A, 2019, 2019 6TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P146, DOI [10.1109/spin.2019.8711625, 10.1109/SPIN.2019.8711625]
   Boukadida H, 2017, IEEE T CIRC SYST VID, V27, P920, DOI 10.1109/TCSVT.2015.2513678
   Butka P, 2015, ADV INTELL SYST, V314, P101, DOI 10.1007/978-3-319-10383-9_10
   Chowdhury A.E., 2016 3 INT C EL ENG, P1
   Cyganek B, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19194088
   D'Orazio T, 2010, PATTERN RECOGN, V43, P2911, DOI 10.1016/j.patcog.2010.03.009
   de Sousa SamuelF., 2011, 2011 IEEE Workshop on Applications of Computer Vision (WACV), P31
   El Mahdaouy A, 2017, ADV INTELL SYST, V533, P32, DOI 10.1007/978-3-319-48308-5_4
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Gao Y, 2009, MULTIMED TOOLS APPL, V42, P233, DOI 10.1007/s11042-008-0236-x
   Goyani M., 2011, INT J MULTIMEDIA APP, V3, P111, DOI DOI 10.5121/IJMA.2011.3110
   Goyani MM, 2011, COMM COM INF SC, V131, P388
   Han B, 2007, IEEE T CONSUM ELECTR, V53, P1168, DOI 10.1109/TCE.2007.4341601
   Hari R, 2014, ANNU IEEE IND CONF
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   Javed A, 2019, APPL INTELL, V49, P2899, DOI 10.1007/s10489-019-01410-x
   Javed A, 2019, IET IMAGE PROCESS, V13, P615, DOI 10.1049/iet-ipr.2018.5589
   Jayanth SB, 2014, ELECT LETT COMPUT VI, V13, P33
   Karmaker D, 2015, 2015 SECOND INTERNATIONAL CONFERENCE ON COMPUTING TECHNOLOGY AND INFORMATION MANAGEMENT (ICCTIM), P125, DOI 10.1109/ICCTIM.2015.7224605
   Khan Muhammad Zeeshan, 2018, 2018 International Conference on Applied and Engineering Mathematics (ICAEM), P67, DOI 10.1109/ICAEM.2018.8536277
   Khatun S, 2018, ARXIV180505974
   Kokaram A, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P251, DOI 10.1109/MMSP.2001.962742
   Kolekar MH, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P382, DOI 10.1109/ICVGIP.2008.102
   Kolekar MH, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1617, DOI 10.1109/ICME.2006.262856
   Kolekar MH, 2010, MULTIMED TOOLS APPL, V47, P545, DOI 10.1007/s11042-009-0337-1
   Kolekar MH, 2008, NAT COMM C NCC, P461
   Kolekar MH., 2004, 2004 GRAPH IM PROC P, P1
   Kowsher M, 2019, 5 INT C COMP COMM CH, P11
   Kumar A, 2016, CRIT REV MICROBIOL, V42, P194, DOI 10.3109/1040841X.2014.917068
   Kumar Y. S., 2011, 2011 IEEE 15th International Symposium on Consumer Electronics, P222, DOI 10.1109/ISCE.2011.5973819
   Lee H, 2011, MULTIMED TOOLS APPL, V51, P1127, DOI 10.1007/s11042-010-0462-x
   Li L., 2009, Proc. ACM Multimedia, P653
   Li ZJ, 2016, PROCEEDINGS 2016 FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA AND IMAGE PROCESSING (ICMIP 2016), P15, DOI 10.1109/ICMIP.2016.24
   Lienhart R, 2002, IEEE T CIRC SYST VID, V12, P256, DOI 10.1109/76.999203
   Liu CL, 2013, IEEE T MULTIMEDIA, V15, P884, DOI 10.1109/TMM.2013.2238522
   Liu S, 2021, IEEE T MULTIMEDIA, V23, P2188, DOI 10.1109/TMM.2021.3065580
   Liu S, 2021, NEUROCOMPUTING, V458, P615, DOI 10.1016/j.neucom.2019.12.143
   Mahmoud KM, 2013, LECT NOTES COMPUT SC, V8156, P733
   Midhu K, 2018, L N COMPUT VIS BIOME, V28, P925, DOI 10.1007/978-3-319-71767-8_79
   Minhas RA, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9030483
   Moodley T, 2020, LECT NOTES ELECTR EN, V621, P171, DOI 10.1007/978-981-15-1465-4_18
   Narasimhan H, 2010, GECCO-2010 COMPANION PUBLICATION: PROCEEDINGS OF THE 12TH ANNUAL GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P2051
   Nasir MH., 2018, J IMAGE GRAPHICS, V6, P27, DOI [10.18178/joig.6.1.27-32, DOI 10.18178/JOIG.6.1.27-32]
   Premaratne SC, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON GRAPHICS AND SIGNAL PROCESSING (ICGSP 2018), P69, DOI 10.1145/3282286.3282293
   Priya GGL, 2011, COMM COM INF SC, V157, P161
   Rafiq M., 2020, SENSORS SWITZERLAND, V20, P1
   Rahmad N. A., 2018, Indonesian J. Elect. Eng. Comput. Sci., V11, P987
   Ramsaran M, 2016, 2016 8TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (CICN), P251, DOI 10.1109/CICN.2016.56
   Ravi A, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P1396, DOI 10.1109/SSCI.2018.8628877
   Ravinder M, 2016, ADV INTELL SYST, V394, P599, DOI 10.1007/978-81-322-2656-7_55
   Rehman A, 2014, ARTIF INTELL REV, V41, P451, DOI 10.1007/s10462-012-9319-1
   Ringis D, 2015, IEEE PAC RIM CONF CO, P58, DOI 10.1109/PACRIM.2015.7334809
   Roopchand R, 2016, 2016 8TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (CICN), P256, DOI 10.1109/CICN.2016.57
   Sankar P, 2006, LECT NOTES COMPUT SC, V4338, P433
   Schoeffmann K., 2010, SPIE Reviews, V1, P018004, DOI DOI 10.1117/6.0000005
   SEMWAL A, 2018, 9 INT C COMP NETW TE, P1
   Shahjalal A, 2017, 3 INT C EL INF COMM, P7
   Sharma RA, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P421, DOI 10.1109/ACPR.2015.7486538
   Shen RK, 2018, IEEE T COMPUT SOC SY, V5, P210, DOI 10.1109/TCSS.2017.2780882
   Shih HC, 2018, IEEE T CIRC SYST VID, V28, P1212, DOI 10.1109/TCSVT.2017.2655624
   Shukla P, 2018, IEEE COMPUT SOC CONF, P1881, DOI 10.1109/CVPRW.2018.00233
   Smeaton AF, 2010, COMPUT VIS IMAGE UND, V114, P411, DOI 10.1016/j.cviu.2009.03.011
   Snoek Cees G. M., 2008, Foundations and Trends in Information Retrieval, V2, P215, DOI 10.1561/1500000014
   Tang H, 2011, IEEE INT CON MULTI
   Taskiran CM, 2005, COMP ENG SER, P215
   Tavassolipour M, 2014, IEEE T CIRC SYST VID, V24, P291, DOI 10.1109/TCSVT.2013.2243640
   Thomas SS, 2017, IEEE T CIRC SYST VID, V27, P1790, DOI 10.1109/TCSVT.2016.2556558
   Tizhoosh HR, 2018, IEEE T BIO-MED ENG, V65, P2267, DOI 10.1109/TBME.2018.2791567
   Wang JX, 2003, PROCEEDINGS OF THE 1ST INTERNATIONAL YELLOW RIVER FORUM ON RIVER BASIN MANAGEMENT, VOL II, P87
   Wang L, 2004, IEEE IMAGE PROC, P1585
   Wang S, 2022, IEEE INTERNET THINGS, V9, P7128, DOI 10.1109/JIOT.2021.3077600
   Xu JW, 2016, 2016 30TH ANNIVERSARY OF VISUAL COMMUNICATION AND IMAGE PROCESSING (VCIP)
   Yuan JH, 2007, IEEE T CIRC SYST VID, V17, P168, DOI 10.1109/TCSVT.2006.888023
   Zhang N, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168760
   Zhao YB, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P131, DOI 10.1109/CISP.2015.7407863
NR 82
TC 5
Z9 5
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 29253
EP 29281
DI 10.1007/s11042-022-12834-y
EA APR 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777241600003
DA 2024-07-18
ER

PT J
AU Sushir, RD
   Wakde, DG
AF Sushir, Rupesh D.
   Wakde, Dinkar Govindrao
TI An improved detection of blind image forgery using hybrid deep belief
   network and adaptive fuzzy clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image pre-processing; Feature extraction; Block matching; Clustering;
   Forgery detection
AB Blind image forgery prediction in the field of image forgery is difficult. Hence, it is the major attention for the investigators recently. This work introduces an innovative methodology for blind image forgery detection. The steps are described as: initially, input images are pre-processed using hybrid homomorphic filtering to enhance the images. After pre-processing images, features such as Hybrid Speeded up Robust features and scale-invariant feature transform (hybrid SURF-SIFT) and hybrid wavelet features are extracted. According to the extracted features hybrid deep belief neural network (HDBN) framework performs the block matching to examine the forgery region in images. Here, modified atom search optimization is utilized for weights optimization in HDBN framework and improving the performance of matching process. The HDBN framework detects non matching regions, and finally, the forgery region is accurately localized with the presented Adaptive fuzzy clustering based improved sun flower optimization (AFCSO) approach. The implementation platform used in work is PYTHON. The presented technique is tested with three datasets: CG-1050, SMIFD, and Coverage. Moreover, the experimental results of the presented approach is examined with the existing techniques in regard to accuracy, precision, recall, F-measure, True positive rate, False positive rate, True negative rate, and False-negative rate. The performance measures of forgery detection with CG-1050 dataset is F-measure (98.98%), Accuracy (99%), recall (98%), precision (99.9%), True positive rate (99.5%), False positive rate (0.4%), True negative rate (99.7%), False negative rate (2%). The performance measures of forgery detection with SMIFD dataset is F-measure (99.15%), True positive rate (99.57%), Accuracy (98.67%), precision (99.57%), false-positive rate (1.56%), True negative rate (98.43%), and false-negative rate (1.25%). The performance measures of forgery detection with COVERAGE dataset is F-measure (98%), True positive rate (98%), False positive rate (2%), Accuracy (98.3%), precision (97.1%), True negative rate (98%), False negative rate (2%). This proved that the presented approach outperforms the compared existing approaches.
C1 [Sushir, Rupesh D.] PR Pote Coll Engn & Management, Elect & Telecommun Dept, Amravati 444602, Maharashtra, India.
   [Wakde, Dinkar Govindrao] PR Patil Coll Engn & Technol, Kathora Rd, Amravati, India.
RP Sushir, RD (corresponding author), PR Pote Coll Engn & Management, Elect & Telecommun Dept, Amravati 444602, Maharashtra, India.
EM rupeshsushir18@gmail.com
CR ABID A, 2019, 2019 IEEE INT C DESI, P1
   Abrahim AR, 2019, CLUSTER COMPUT, V22, P647, DOI 10.1007/s10586-017-1668-8
   Agarwal R, 2020, MULTIMED TOOLS APPL, V79, P7355, DOI 10.1007/s11042-019-08495-z
   Alkawaz MH, 2018, NEURAL COMPUT APPL, V30, P183, DOI 10.1007/s00521-016-2663-3
   alZahir S, 2020, MULTIMED TOOLS APPL, V79, P28643, DOI 10.1007/s11042-020-09502-4
   Bharti CN, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P877, DOI 10.1109/WiSPNET.2016.7566257
   Bilal M, 2020, ARAB J SCI ENG, V45, P2975, DOI 10.1007/s13369-019-04238-2
   Castro M, 2020, DATA BRIEF, V28, DOI 10.1016/j.dib.2019.104864
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Devi MU, 2022, EVOL INTELL, V15, P1097, DOI 10.1007/s12065-019-00304-8
   Dhanya R., 2020, Advances in Communication Systems and Networks. Select Proceedings of ComNet 2019. Lecture Notes in Electrical Engineering (LNEE 656), P723, DOI 10.1007/978-981-15-3992-3_61
   Elaskily MA, 2020, MULTIMED TOOLS APPL, V79, P19167, DOI 10.1007/s11042-020-08751-7
   Elsharkawy ZF, 2019, MULTIMED TOOLS APPL, V78, P21585, DOI 10.1007/s11042-019-7206-3
   Gull S, 2020, J AMB INTEL HUM COMP, V11, P1799, DOI 10.1007/s12652-018-1158-8
   Hayat K, 2017, COMPUT ELECTR ENG, V62, P448, DOI 10.1016/j.compeleceng.2017.03.013
   Hegazi A, 2021, J KING SAUD UNIV-COM, V33, P1055, DOI 10.1016/j.jksuci.2019.07.007
   Hilal A, 2017, 2017 SENS NETW SMART, P1
   Jabeen S, 2021, MULTIMED TOOLS APPL, V80, P17025, DOI 10.1007/s11042-020-09623-w
   Jaiprakash SP, 2020, MULTIMED TOOLS APPL, V79, P29977, DOI 10.1007/s11042-020-09415-2
   Kaur N, 2020, MULTIMED TOOLS APPL, V79, P32037, DOI 10.1007/s11042-020-09275-w
   Lin C, 2019, MULTIMED TOOLS APPL, V78, P30081, DOI 10.1007/s11042-018-6922-4
   Liu B, 2020, INFORM SCIENCES, V526, P133, DOI 10.1016/j.ins.2020.03.099
   Marra F, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P384, DOI 10.1109/MIPR.2018.00084
   Nath S, 2021, SIGNAL IMAGE VIDEO P, V15, P1601, DOI 10.1007/s11760-021-01895-5
   Rahman MM, 2021, INT J GEOTECH ENG, V15, P714, DOI 10.1080/19386362.2019.1576352
   Rao Y, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.108051
   Roy A., 2020, Digital image forensics: Theory and implementation, DOI [10.1007/978-981-10-7644-2, DOI 10.1007/978-981-10-7644-2]
   Roy A, 2020, DIGITAL IMAGE FORENS, P57, DOI DOI 10.1007/978-981-10-7644-2_4
   Roy A., 2020, DIGITAL IMAGE FORENS, P65
   Soni B, 2019, J INF SECUR APPL, V45, P44, DOI 10.1016/j.jisa.2019.01.007
   Thakur R, 2020, FORENSIC SCI INT, V312, DOI 10.1016/j.forsciint.2020.110311
   Yang B, 2018, MULTIMED TOOLS APPL, V77, P837, DOI 10.1007/s11042-016-4289-y
   Yang F, 2017, ENG APPL ARTIF INTEL, V59, P73, DOI 10.1016/j.engappai.2016.12.022
   Zhu Y, 2020, IEEE T IND INFORM, V16, P6714, DOI 10.1109/TII.2020.2982705
NR 34
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 29177
EP 29205
DI 10.1007/s11042-022-12923-y
EA APR 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777384900005
DA 2024-07-18
ER

PT J
AU Lou, M
   Qi, YL
   Li, XR
   Xu, CB
   Zhao, WW
   Deng, XY
   Ma, YD
AF Lou, Meng
   Qi, Yunliang
   Li, Xiaorong
   Xu, Chunbo
   Zhao, Wenwei
   Deng, Xiangyu
   Ma, Yide
TI Aggregated pyramid attention network for mass segmentation in mammograms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mammogram; Mass segmentation; Deep learning; Aggregated pyramid
   attention module
ID SCREENING MAMMOGRAPHY; CLASSIFICATION
AB Intra-class inconsistency and inter-class indistinction are intractable problems that commonly exist in breast mass segmentation from mammograms. In this work, a novel deep learning segmentation model is presented to address these problems. Firstly, we propose a simple yet effective aggregated pyramid attention module (APAM) for capturing intra-class dependencies, aiming at effectively aggregating contextual dependencies from different receptive fields to reinforce feature representations. Then, a novel aggregated pyramid attention network (APANet) is developed for further releasing the limitation of both intra-class inconsistency and inter-class indistinction. The APANet can combine low-level spatial details and high-level contextual information via encoder-decoder structure for further refining semantic representations. Finally, our proposed APANet is greatly demonstrated on two public mammographic databases including the DDSM-BCRP and INbreast, separately achieving the Dice Similarity Coefficient (DSC) of 91.04% and 94.02%.
C1 [Lou, Meng; Qi, Yunliang; Li, Xiaorong; Xu, Chunbo; Zhao, Wenwei; Ma, Yide] Lanzhou Univ, Sch Informat Sci & Engn, Lanzhou, Gansu, Peoples R China.
   [Deng, Xiangyu] Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou, Gansu, Peoples R China.
C3 Lanzhou University; Northwest Normal University - China
RP Ma, YD (corresponding author), Lanzhou Univ, Sch Informat Sci & Engn, Lanzhou, Gansu, Peoples R China.
EM ydma@lzu.edu.cn
RI li, xiao/HJP-5134-2023; wang, xicheng/IXX-0974-2023; LI,
   XIAO/IQV-9318-2023; lu, yang/IWE-3635-2023; li, xiao/HKV-8405-2023; li,
   xuedong/JYP-4367-2024; Lou, Meng/JYX-3663-2024
OI Lou, Meng/0000-0001-5409-0281
FU National Natural Science Foundation of China [61961037]; Natural Science
   Foundation of Gansu Province [18JR3RA288]; Fundamental Research Funds
   for the Central Universities [lzuxxxy-2019-tm23]
FX We would like to thank the Breast Research Group, INESC Porto, Portugal
   for the INbreast database. This work is jointly supported by the
   National Natural Science Foundation of China (Nos.61961037), the Natural
   Science Foundation of Gansu Province (Nos. 18JR3RA288), and the
   Fundamental Research Funds for the Central Universities
   (Nos.lzuxxxy-2019-tm23).
CR Al-Najdawi N, 2015, APPL SOFT COMPUT, V35, P175, DOI 10.1016/j.asoc.2015.06.029
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Beller M, 2005, BILDVERARBEITUNG MED
   Birdwell RL, 2001, RADIOLOGY, V219, P192, DOI 10.1148/radiology.219.1.r01ap16192
   Chan HP, 1998, MED PHYS, V25, P2007, DOI 10.1118/1.598389
   Chen L, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3278067
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cheng HD, 2006, PATTERN RECOGN, V39, P646, DOI 10.1016/j.patcog.2005.07.006
   CO Communities and SOO Communities, 2010, HLTH STAT ATL MORT E
   DeSantis CE, 2019, CA-CANCER J CLIN, V69, P438, DOI 10.3322/caac.21583
   Dhungel N, 2015, IEEE IMAGE PROC, P2950, DOI 10.1109/ICIP.2015.7351343
   Dhungel N, 2015, LECT NOTES COMPUT SC, V9349, P605, DOI 10.1007/978-3-319-24553-9_74
   Dhungel N, 2015, I S BIOMED IMAGING, P760, DOI 10.1109/ISBI.2015.7163983
   Freer TW, 2001, RADIOLOGY, V220, P781, DOI 10.1148/radiol.2203001282
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Giger ML, 2013, ANNU REV BIOMED ENG, V15, P327, DOI 10.1146/annurev-bioeng-071812-152416
   Guliato D, 2008, IEEE T BIO-MED ENG, V55, P14, DOI 10.1109/TBME.2007.899310
   He JJ, 2019, PROC CVPR IEEE, P7511, DOI 10.1109/CVPR.2019.00770
   He JJ, 2019, IEEE I CONF COMP VIS, P3561, DOI 10.1109/ICCV.2019.00366
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Heath M, 1998, COMP IMAG VIS, V13, P457
   Horsch A, 2011, INT J COMPUT ASS RAD, V6, P749, DOI 10.1007/s11548-011-0553-9
   Hou QB, 2020, PROC CVPR IEEE, P4002, DOI 10.1109/CVPR42600.2020.00406
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jaime S., 2015, INT J PATTERN RECOGN, V29
   KILDAY J, 1993, IEEE T MED IMAGING, V12, P664, DOI 10.1109/42.251116
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lehman CD, 2017, RADIOLOGY, V283, P49, DOI 10.1148/radiol.2016161174
   Li H, 2019, INT CONF ACOUST SPEE, P1224, DOI [10.1109/icassp.2019.8682496, 10.1109/ICASSP.2019.8682496]
   Li HY, 2018, LECT NOTES COMPUT SC, V11040, P81, DOI 10.1007/978-3-030-00946-5_9
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Liu W, 2016, INT WORKS EARTH OB
   Loberg M, 2015, BREAST CANCER RES, V17, DOI 10.1186/s13058-015-0525-z
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.48550/ARXIV.1411.4038
   Lu X, 2015, EMERG ING TRENDS IMA, P201
   Misra Subhasis, 2010, Adv Surg, V44, P87
   Moreira IC, 2012, ACAD RADIOL, V19, P236, DOI 10.1016/j.acra.2011.09.014
   Mudigonda NR, 2000, IEEE T MED IMAGING, V19, P1032, DOI 10.1109/42.887618
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Oliver A, 2010, MED IMAGE ANAL, V14, P87, DOI 10.1016/j.media.2009.12.005
   Pang T, 2020, EXPERT SYST APPL
   Paszke A, 2019, ADV NEUR IN, V32
   Rahmati P, 2012, MED IMAGE ANAL, V16, P1167, DOI 10.1016/j.media.2012.05.005
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sahiner B, 2001, IEEE T MED IMAGING, V20, P1275, DOI 10.1109/42.974922
   Sanders D., 1988, BREAST CANC DETECTIO, V2d
   Siegel RL, 2019, CA-CANCER J CLIN, V69, P7, DOI 10.3322/caac.21551
   Simonyan K., 2015, P 3 INT C LEARN REPR
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang ZY, 2020, AAAI CONF ARTIF INTE, V34, P6315
   Warren LJ, 2009, RADIOLOGY, V21, P330
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yu CQ, 2018, PROC CVPR IEEE, P1857, DOI 10.1109/CVPR.2018.00199
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
   Zhu WT, 2018, I S BIOMED IMAGING, P847, DOI 10.1109/ISBI.2018.8363704
NR 63
TC 5
Z9 5
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13335
EP 13353
DI 10.1007/s11042-021-10940-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000788327500011
DA 2024-07-18
ER

PT J
AU Awasthi, D
   Srivastava, VK
AF Awasthi, Divyanshu
   Srivastava, Vinay Kumar
TI LWT-DCT-SVD and DWT-DCT-SVD based watermarking schemes with their
   performance enhancement using Jaya and Particle swarm optimization and
   comparison of results under various attacks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image watermarking; PSO; JAYA optimization; Discrete cosine
   transform; Discrete wavelet transform; Lifting wavelet transform;
   Performance comparison
ID IMAGE WATERMARKING; TRANSFORM; ROBUST
AB Robust and undetectable watermarking scheme is important for copyright protection. This paper proposes a DWT-DCT-SVD and LWT-DCT-SVD based image watermarking technology, as well as a comparison of the DWT and LWT systems. The host picture is first divided into sub-bands throughout the embedding phase using multilevel DWT or LWT. The image is divided into various high and low-frequency sub-bands using DWT. LWT breaks up the original filters into a series of smaller structures and provides a faster algorithm. The ensuing sub-bands area unit is then used as the input for DCT. The SVD is performed after applying DCT. The watermark is then inserted into the input image sub-band by using particle swarm optimization intelligence and JAYA optimization to discover an acceptable scale factor. The proposed methodology is compared with other methods under a variety of first-generation and second-generation attacks, including filtering, noise, JPEG compression, JPEG2000 compression, sharpening, thresholding, dithering, motion blur, and shear attack. Furthermore, the proposed watermarking system has a reasonable level of robustness and imperceptibility in the face of most attacks, therefore it is a suitable technique for Copywrite protection. This paper proposes two watermarking schemes based on discrete wavelet transform (DWT) namely DWT-DCT-SVD and lifting wavelet transform (LWT) based scheme namely LWT-DCT-SVD. The comparison of these two schemes is also carried out.
EM divyanshu.2021rel04@mnnit.ac.in; vinay@mnnit.ac.in
RI Srivastava, Vinay Kumar/AAL-2501-2021; awasthi, divyanshu/ABX-1965-2022
OI Srivastava, Vinay Kumar/0000-0002-7993-0993; awasthi,
   divyanshu/0000-0002-1764-772X
CR Allaf AH, 2018, P 3 INT C SMART CIT, P472
   [Anonymous], 2008, 3 INT C COMM SYST SO
   [Anonymous], 2015, 2015 IEEE INT C COMP
   Arya RK, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2042, DOI 10.1109/ICACCI.2015.7275917
   Ayangar Vijay R., 2010, 2010 International Conference on Multimedia Computing and Information Technology (MCIT 2010), P105, DOI 10.1109/MCIT.2010.5444871
   Chandra DVS, 2002, 2002 45TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, CONFERENCE PROCEEDINGS, P264
   Fowler JE, 2005, IEEE SIGNAL PROC LET, V12, P629, DOI 10.1109/LSP.2005.853048
   Furqan A, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION TECHNOLOGY CICT 2015, P638, DOI 10.1109/CICT.2015.74
   Guo JM, 2014, J VIS COMMUN IMAGE R, V25, P1149, DOI 10.1016/j.jvcir.2014.03.012
   Hafed ZM, 2001, INT J COMPUT VISION, V43, P167, DOI 10.1023/A:1011183429707
   Hema Rajini N., 2019, J PHYS C SER, V1362, DOI 10.1088/1742-6596/1362/1/012090
   Hurrah NN, 2019, FUTURE GENER COMP SY, V94, P654, DOI 10.1016/j.future.2018.12.036
   Jane O, 2014, J APPL RES TECHNOL, V12, P750, DOI 10.1016/S1665-6423(14)70091-4
   Kaur J, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P1855, DOI 10.1109/RTEICT.2016.7808156
   Kumar S, 2020, MULTIMED TOOLS APPL, V79, P20149, DOI 10.1007/s11042-020-08881-y
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu JX, 2019, IEEE ACCESS, V7, P80849, DOI 10.1109/ACCESS.2019.2915596
   Maity A, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND NETWORKS (CINE), P148, DOI 10.1109/CINE.2015.36
   Makbol NM, 2013, LECT NOTES COMPUT SC, V8237, P36, DOI 10.1007/978-3-319-02958-0_4
   Nandi S, 2016, ADV INTELL SYST, V394, P69, DOI 10.1007/978-81-322-2656-7_7
   Rastegar S, 2011, AEU-INT J ELECTRON C, V65, P658, DOI 10.1016/j.aeue.2010.09.008
   Rykaczewski R, 2007, IEEE T MULTIMEDIA, V9, P421, DOI 10.1109/TMM.2006.886297
   Singh AK, 2014, NATL ACAD SCI LETT, V37, P351, DOI 10.1007/s40009-014-0241-8
   Thakkar F, 2017, TURK J ELECTR ENG CO, V25, P3273, DOI 10.3906/elk-1603-17
   Vaish A, 2017, OPTIK, V145, P273, DOI 10.1016/j.ijleo.2017.07.041
   Wang B, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON NETWORK INFRASTRUCTURE AND DIGITAL CONTENT, PROCEEDINGS, P1034, DOI 10.1109/ICNIDC.2009.5360866
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zeki AM, 2011, 9 INT C ADV MOB COMP, P198, DOI 10.1145/2095697.2095734
   Zhang H, 2017, FUTURE INTERNET, V9, DOI 10.3390/fi9030045
   Zhang LN, 2019, MULTIMED TOOLS APPL, V78, P28003, DOI 10.1007/s11042-019-07902-9
   Zhang XP, 2005, IEEE T MULTIMEDIA, V7, P593, DOI 10.1109/TMM.2005.843357
NR 34
TC 19
Z9 19
U1 4
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25075
EP 25099
DI 10.1007/s11042-022-12456-4
EA MAR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000771882300005
DA 2024-07-18
ER

PT J
AU Gaffar, A
   Joshi, AB
   Singh, S
   Srivastava, K
AF Gaffar, Abdul
   Joshi, Anand B.
   Singh, Sonali
   Srivastava, Keerti
TI A high capacity multi-image steganography technique based on golden
   ratio and non-subsampled contourlet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-image steganography; Golden ratio; Mosaic process; NSCT; GRNSCT
   model
AB Hiding sensitive information in a host image (or 2D signal) is a challenging task. Several image steganography techniques have been proposed in recent years, which either have low embedding capacity, or the embedded images are vulnerable. The proposed technique, which is based on Golden Ratio and Non-Subsampled Contourlet Transform (GRNSCT) model provides both high embedding capacity as well as the confidentiality of the embedded images. The high embedding capacity is achieved via a combination of mosaic process and two level NSCT (Non-Subsampled Contourlet Transform), while confidentiality is attained via double layer encryption based on shuffling method of a deck of cards. Several types of security evaluation metrics, such as, key sensitivity, histogram, and information entropy, are utilized to assess the robustness of the embedded images. The experimental results demonstrate that the proposed multi-image steganography technique achieves 24 bpp (bits per pixel) embedding capacity, or 300% payload with PSNR up to 42.38 dB (decibels), which is better than the existing techniques.
C1 [Gaffar, Abdul; Joshi, Anand B.; Singh, Sonali] Univ Lucknow, Dept Math & Astron, Lucknow 226007, Uttar Pradesh, India.
   [Srivastava, Keerti] CIPET, Dept Math, Lucknow 226008, Uttar Pradesh, India.
C3 Lucknow University; CIPET - Institute of Petrochemicals Technology (IPT)
   Lucknow
RP Joshi, AB (corresponding author), Univ Lucknow, Dept Math & Astron, Lucknow 226007, Uttar Pradesh, India.
EM abdulgaffar.lu@gmail.com; anandiitd.joshi@gmail.com;
   singhsonali09192@gmail.com; keerti.cipet@gmail.com
RI GAFFAR, ABDUL/HNC-3266-2023; SRIVASTAVA, DR.KEERTI/IWU-8097-2023
OI GAFFAR, ABDUL/0000-0002-3388-9067; SRIVASTAVA,
   DR.KEERTI/0000-0002-1566-8949; Joshi, Anand Ballabh/0000-0003-0227-4032
FU UGC (University Grants Commission), India [415024]
FX This work was supported by UGC (University Grants Commission), India
   under grant No. [415024]
CR Abdulla A. A., 2015, Ph.D. dissertation
   Ahmed Nasir, 1991, Digit Signal Process, V1, P4, DOI [DOI 10.1016/1051-2004(91)90086-Z, 10.1016/1051-2004(91)90086-Z]
   Akansu AliN., 1992, Multiresolution Signal Decomposition : Transforms, Subbands, Wavelets
   [Anonymous], 2001, GEOMETRIC METHODS AP
   [Anonymous], 2001, F5 STEGANOGRAPHIC AL
   ATTA R, 2020, OPTIK
   Atta R, 2018, J VIS COMMUN IMAGE R, V53, P42, DOI 10.1016/j.jvcir.2018.03.009
   Baptiste J, 1993, CONVEX ANAL MINIMIZA
   Biham E., 1993, Differential Cryptanalysis of the Data Encryption Standard
   Brown Margaret., 2004, ADV DIGITAL PHOTOGRA
   Candes EJ, 1999, P CURV SURF FITT
   Chan CS, 2009, FUND INFORM, V96, P49, DOI 10.3233/FI-2009-166
   Cox IJ, 1997, P SOC PHOTO-OPT INS, V3016, P92, DOI 10.1117/12.274502
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Debnath D, 2020, INT J WEB BASED LEAR
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Dunlap Richard A., 1997, The golden ratio and Fibonacci numbers
   Fisher RA, 1938, STAT TABLES EXAMPLE
   Fridrich J, 2007, LECT NOTES COMPUT SC, V4437, P282
   Ghosal SK, 2018, MULTIMED TOOLS APPL, V77, P30403, DOI 10.1007/s11042-018-6126-y
   Gong LH, 2021, MULTIMED TOOLS APPL, V80, P439, DOI 10.1007/s11042-020-09677-w
   Gutub A, 2020, ARAB J SCI ENG, V45, P2631, DOI 10.1007/s13369-020-04413-w
   JEEVITHA S, 2019, HEALTH TECHNOL-GER
   KADHIM IJ, 2019, COGN SYST RES
   Ker A.D., 2013, P 1 ACM WORKSH INF H, P4558, DOI DOI 10.1145/2482513.2482965
   Kingsbury, 1998, P 8 IEEE DSP WORKSH, V86, P120
   KNUTH D. E., 1981, Addison-Wesley Series in Computer Science and Information Processing, V2
   Kumar V, 2018, MULTIMED TOOLS APPL, V77, P13279, DOI 10.1007/s11042-017-4947-8
   Lang S., 1986, INTRO LINEAR ALGEBRA
   LAWTON W, 1993, IEEE T SIGNAL PROCES, V41, P3566, DOI 10.1109/78.258098
   Mangayarkarasi S., 2018, INT J PURE APPL MATH, V119, P3643
   Maschke T., 2004, DIGITAL CAMERA TECHN
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Muhuri PK, 2020, APPL SOFT COMPUT, V92, DOI 10.1016/j.asoc.2020.106257
   Reshma VK, 2022, EVOL INTELL, V15, P1295, DOI 10.1007/s12065-020-00387-8
   Rivest RL, 1990, CRYPTOGRAPHY-BASEL, P1
   Rockafellar T.R., 1970, CONVEX ANAL PRINCETO, V28
   Schneier B., 1996, Applied Cryptography: Protocols, Algorithms, and Source Code in C
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Subhedar MS, 2020, MULTIMED TOOLS APPL, V79, P1865, DOI 10.1007/s11042-019-08221-9
   Sun S, 2015, J INFORM HIDING MULT
   Zhu HQ, 2005, INT CONF ACOUST SPEE, P469
NR 43
TC 4
Z9 4
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24449
EP 24476
DI 10.1007/s11042-022-12246-y
EA MAR 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770960100002
DA 2024-07-18
ER

PT J
AU Agrawal, C
   Pandey, A
   Goyal, S
AF Agrawal, Chetan
   Pandey, Anjana
   Goyal, Sachin
TI Fake news detection system based on modified bi-directional long short
   term memory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fake news detection; Modified bi-directional long short term memory;
   Structural features; Support; PolitiFact
ID INFORMATION; CONTEXT
AB The use of social media has increased tremendously during the past few decades and is considered one of the major sources of news. Social media don't have the authority to verify the authenticity of the news and because of this, it is considered as a significant reason behind the spread of fake news. Many existing methods have been applied to detect fake news in social media and all those have the drawbacks of lower efficiency and overfitting problem. In this research, structural features with the Modified Bi-directional Long Short Term Memory (MBi-LSTM) method are proposed to improve the efficiency of Fake news detection. The attention layer is introduced in the Bi-LSTM to update the weight value of the input features and Term Frequency - Inverse Document Frequency (TF-IDF), based on the scalar factor. This weight value is updated in the input gate weight value of the Bi-LSTM that helps to find the relevant feature to store in cell. The proper weight in the Bi-LSTM model stores the features related to reliable information in long-term that helps to improves the classification performance. The structural, user, content, and temporal features were extracted from the Twitter data and applied to the MBi-LSTM method. 33 features were extracted for structural, user, content, and temporal features for the classification. The PolitiFact dataset is collected and used for testing the efficiency of the proposed MBi-LSTM method. Additionally, the CREDBANK dataset is also applied to test the effectiveness of the proposed MBi-LSTM method in the case of a large dataset. The experimental result shows that the proposed MBi-LSTM method has an accuracy of 91% and the Bi-LSTM method has an accuracy of 86.69% in PolitiFact's dataset.
C1 [Agrawal, Chetan] Rajiv Gandhi Proudyogiki Vishwavidyalay UIT RGPV, Univ Inst Technol, Dept Comp Sci & Engn, Bhopal, India.
   [Pandey, Anjana; Goyal, Sachin] Rajiv Gandhi Proudyogiki Vishwavidyalay UIT RGPV, Univ Inst Technol, Dept Informat Technol, Bhopal, India.
C3 Rajiv Gandhi Technological University; Rajiv Gandhi Technological
   University
RP Agrawal, C (corresponding author), Rajiv Gandhi Proudyogiki Vishwavidyalay UIT RGPV, Univ Inst Technol, Dept Comp Sci & Engn, Bhopal, India.
EM Chetan.agrawal12@gmail.com; anjanapandey@rgtu.net; sachingoyal@rgtu.net
RI Agrawal, Chetan/KMA-1482-2024
CR Agarwal A., 2020, SN Comput Sci, V1, P1, DOI [10.1007/s42979-020-00165-4, DOI 10.1007/S42979-020-00165-4]
   Alkhodair SA, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.02.016
   Aso M, 2020, SPEECH COMMUN, V125, P53, DOI 10.1016/j.specom.2020.09.003
   Boididou C, 2018, MULTIMED TOOLS APPL, V77, P15545, DOI 10.1007/s11042-017-5132-9
   Boididou C, 2018, INT J MULTIMED INF R, V7, P71, DOI 10.1007/s13735-017-0143-x
   Buntain C, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SMART CLOUD (SMARTCLOUD), P208, DOI 10.1109/SmartCloud.2017.40
   Cao J, 2019, PHYSICA A, V519, P127, DOI 10.1016/j.physa.2018.11.061
   Castillo C, 2013, INTERNET RES, V23, P560, DOI 10.1108/IntR-05-2012-0095
   Choudhary A, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114171
   Gravanis G, 2019, EXPERT SYST APPL, V128, P201, DOI 10.1016/j.eswa.2019.03.036
   Hassan Doaa, 2018, 2018 IEEE 27th International Conference on Enabling Technologies: Infrastructure for Collaborative Enterprises (WETICE), P171, DOI 10.1109/WETICE.2018.00039
   Kaliyar RK, 2021, J SUPERCOMPUT, V77, P1015, DOI 10.1007/s11227-020-03294-y
   Kaliyar RK, 2020, COGN SYST RES, V61, P32, DOI 10.1016/j.cogsys.2019.12.005
   Kapusta J, 2020, INFORMATICS-BASEL, V7, DOI 10.3390/informatics7010004
   Kaur S, 2020, SOFT COMPUT, V24, P9049, DOI 10.1007/s00500-019-04436-y
   Kim D, 2019, INFORM SCIENCES, V477, P15, DOI 10.1016/j.ins.2018.10.006
   Kumar S, 2021, COMPUT MATH ORGAN TH, V27, P109, DOI 10.1007/s10588-019-09305-5
   Landi F, 2021, NEURAL NETWORKS, V144, P334, DOI 10.1016/j.neunet.2021.08.030
   Li Q, 2020, PERS UBIQUIT COMPUT, V24, P259, DOI 10.1007/s00779-019-01289-y
   Liu Y, 2019, APPL SOFT COMPUT, V82, DOI 10.1016/j.asoc.2019.105584
   Luo Y, 2017, J BIOMED INFORM, V72, P85, DOI 10.1016/j.jbi.2017.07.006
   Mitra T, 2015, INT AAAI C WEB SOCIA, V9
   Ozbay FA, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123174
   Reddy H, 2020, INT J AUTOM COMPUT, V17, P210, DOI 10.1007/s11633-019-1216-5
   Sahoo SR, 2021, APPL SOFT COMPUT, V100, DOI 10.1016/j.asoc.2020.106983
   Shahid F, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110212
   Shu K., 2017, ACM SIGKDD EXPLOR NE, V19, P22, DOI [DOI 10.1145/3137597.3137600, 10.1145/3137597.3137600]
   Shu K, 2020, BIG DATA, V8, P171, DOI 10.1089/big.2020.0062
   Shu K, 2019, COMPUT MATH ORGAN TH, V25, P60, DOI 10.1007/s10588-018-09280-3
   Song CG, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102712
   Symeonidis S, 2018, EXPERT SYST APPL, V110, P298, DOI 10.1016/j.eswa.2018.06.022
   Wang LQ, 2019, SOC NETW ANAL MIN, V9, DOI 10.1007/s13278-019-0580-z
   Yavary A, 2019, SOC NETW ANAL MIN, V10, DOI 10.1007/s13278-019-0616-4
   Yildirim O, 2019, COMPUT METH PROG BIO, V176, P121, DOI 10.1016/j.cmpb.2019.05.004
   Zhang CW, 2019, EUR J OPER RES, V279, P1036, DOI 10.1016/j.ejor.2019.06.022
   Zhou XX, 2021, ENERGY REP, V7, P5762, DOI 10.1016/j.egyr.2021.09.001
NR 36
TC 2
Z9 2
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24199
EP 24223
DI 10.1007/s11042-022-12772-9
EA MAR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770754000007
DA 2024-07-18
ER

PT J
AU Arafa, DA
   Moustafa, HED
   Ali-Eldin, AMT
   Ali, HA
AF Arafa, Doaa Ahmed
   Moustafa, Hossam El-Din
   Ali-Eldin, Amr M. T.
   Ali, Hesham A.
TI Early detection of Alzheimer's disease based on the state-of-the-art
   deep learning approach: a comprehensive survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Alzheimer's disease (AD); Convolution neural network (CNN); Deep
   Learning (DL); Imaging pre-processing; Neuroimaging classification
ID FEATURE-EXTRACTION; FEATURE-SELECTION; NEURAL-NETWORKS; BRAIN MRI;
   CLASSIFICATION; IMAGES; CNN; SEGMENTATION; AUTOENCODER; DIAGNOSIS
AB Alzheimer's disease (AD) is a form of brain disorder that causes functions' loss in a person's daily activity. Due to the tremendous progress of Alzheimer's patients and the lack of accurate diagnostic tools, early detection and classification of Alzheimer's disease are open research areas. Accurate detection of Alzheimer's disease in an effective way is one of the many researchers' goals to limit or overcome the disease progression. The main objective of the current survey is to introduce a comprehensive evaluation and analysis of the most recent studies for AD early detection and classification under the state-of-the-art deep learning approach. The article provides a simplified explanation of the system stages such as imaging, preprocessing, learning, and classification. It addresses broad categories of structural, functional, and molecular imaging in AD. The included modalities are magnetic resonance imaging (MRI; both structural and functional) and positron emission tomography (PET; for assessment of both cerebral metabolism and amyloid). It reviews the process of pre-processing techniques to enhance the quality. Additionally, the most common deep learning techniques used in the classification process will be discussed. Although deep learning with preprocessing images has achieved high performance as compared to other techniques, there are some challenges. Moreover, it will also review some challenges in the classification and preprocessing image process over some articles what they introduce, and techniques used, and how they solved these problems.
C1 [Arafa, Doaa Ahmed; Ali-Eldin, Amr M. T.; Ali, Hesham A.] Mansoura Univ, Fac Engn, Comp Engn & Control Syst Dept, Mansoura, Egypt.
   [Moustafa, Hossam El-Din] Mansoura Univ, Fac Engn, Elect & Commun Engn Dept, Mansoura, Egypt.
C3 Egyptian Knowledge Bank (EKB); Mansoura University; Egyptian Knowledge
   Bank (EKB); Mansoura University
RP Arafa, DA (corresponding author), Mansoura Univ, Fac Engn, Comp Engn & Control Syst Dept, Mansoura, Egypt.
EM doaaarafa@mans.edu.eg
RI Ali, Hesham Arfafat/U-6362-2019; Moustafa, Hossam El-Din/AAK-8256-2020;
   Ali-Eldin, Amr/J-6421-2013
OI Ali, Hesham Arfafat/0000-0001-6675-7987; Moustafa, Hossam
   El-Din/0000-0002-8242-942X; Ali-Eldin, Amr/0000-0002-3673-3316; Ahmed
   Arafa, Doaa/0000-0003-3340-6472
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Aamir M, 2020, INT J FUZZY LOG INTE, V20, P8, DOI 10.5391/IJFIS.2020.20.1.8
   Aderghal K, 2018, COMP MED SY, P345, DOI 10.1109/CBMS.2018.00067
   AFZAL S, 2019, IEEE COMMUN SURV TUT, P1
   Akkus Z, 2017, J DIGIT IMAGING, V30, P449, DOI 10.1007/s10278-017-9983-4
   Al-Naami B, 2013, WORLD ACAD SCI ENG T, V7
   Al-Qatf M, 2018, IEEE ACCESS, V6, P52843, DOI 10.1109/ACCESS.2018.2869577
   Albawi S, 2017, I C ENG TECHNOL
   Aldweesh A, 2020, KNOWL-BASED SYST, V189, DOI 10.1016/j.knosys.2019.105124
   Alom MZ, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030292
   Amen DanielG., 2015, Change Your Brain, Change Your Life
   An N., 2020, ARXIV PREPRINT ARXIV
   [Anonymous], 2017, ARXIV PREPRINT ARXIV
   Ayodele T.O., 2010, NEW ADV MACH LEARN
   Bardis MD, 2020, CANCERS, V12, DOI 10.3390/cancers12051204
   Basaia S, 2019, NEUROIMAGE-CLIN, V21, DOI 10.1016/j.nicl.2018.101645
   Bashar A., 2019, J ARTIFICIAL INTELLI, V1, P73, DOI [DOI 10.36548/JAICN.2019.2.003, 10.36548/jaicn.2019.2.003]
   Baskar D, 2019, MULTIMED TOOLS APPL, V78, P12883, DOI 10.1007/s11042-018-6287-8
   Bi X, 2020, COGN COMPUT, V12, P513, DOI 10.1007/s12559-019-09688-2
   Borghesani PR, 2008, NEUROBIOL AGING, V29, P981, DOI 10.1016/j.neurobiolaging.2007.01.012
   Brown EM, 2020, NEUROIMAGE, V210, DOI 10.1016/j.neuroimage.2020.116563
   Brown J, 2015, J NEUROL NEUROSUR PS, V86, P680, DOI 10.1136/jnnp-2014-309086
   Busche MA, 2008, SCIENCE, V321, P1686, DOI 10.1126/science.1162844
   Çayir A, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P494, DOI 10.1109/UBMK.2018.8566383
   Chakraborty S, 2017, 2017 IEEE SMARTWORLD, P1
   Chen JY, 2020, NEURAL COMPUT APPL, V32, P10809, DOI 10.1007/s00521-018-3442-0
   Chen Z, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10010139
   Chitradevi D, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105857
   Choi BK, 2020, CURR MED IMAGING, V16, P27, DOI 10.2174/1573405615666191021123854
   Cui RX, 2019, COMPUT MED IMAG GRAP, V73, P1, DOI 10.1016/j.compmedimag.2019.01.005
   de Marvao A, 2020, FRONT CARDIOVASC MED, V6, DOI 10.3389/fcvm.2019.00195
   Deng L., 2014, 15 ANN C INT SPEECH, V2014, P1915, DOI [10.21437/Interspeech.2014-433, DOI 10.21437/INTERSPEECH.2014-433]
   Ding Y, 2019, RADIOLOGY, V290, P456, DOI 10.1148/radiol.2018180958
   DiPietro R, 2020, Handbook of Medical Image Computing and Computer Assisted Intervention, The Elsevier and MICCAI Society Book Series, P503, DOI [10.1016/B978-0-12-816176-0.00026-0, DOI 10.1016/B978-0-12-816176-0.00026-0]
   Dong B, 2016, I C COMM SOFTW NET, P581, DOI 10.1109/ICCSN.2016.7586590
   Dua M, 2020, J MED BIOL ENG, V40, P688, DOI 10.1007/s40846-020-00556-1
   Dubois Bruno, 2009, Dialogues Clin Neurosci, V11, P135
   Ebrahim D., 2021, P 15 INT C COMP ENG, P1, DOI [10.1109/ICCES51560.2020.9334594, DOI 10.1109/ICCES51560.2020.9334594]
   Ebrahimighahnavieh MA, 2020, COMPUT METH PROG BIO, V187, DOI 10.1016/j.cmpb.2019.105242
   Esmaeilzadeh S, 2018, LECT NOTES COMPUT SC, V11046, P337, DOI 10.1007/978-3-030-00919-9_39
   Feng W, 2020, INT J NEURAL SYST, V30, DOI 10.1142/S012906572050032X
   Folego G, 2020, FRONT BIOENG BIOTECH, V8, DOI 10.3389/fbioe.2020.534592
   Fu'adah YN., 1844, J PHYS C SER, V2021, DOI 10.1088/1742-6596/1844/1/012020
   Guidotti R, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3236009
   Gulhare K.K., 2017, INT J ADV RES COMPUT, V7, P1, DOI DOI 10.23956/IJARCSSE/V7I6/0259
   Guo KH, 2019, INFORM FUSION, V51, P215, DOI 10.1016/j.inffus.2019.02.008
   Gupta Y, 2019, J HEALTHC ENG, V2019, DOI 10.1155/2019/2492719
   Han DM, 2018, EXPERT SYST APPL, V95, P43, DOI 10.1016/j.eswa.2017.11.028
   Hazarika Ruhul Amin, 2020, International Conference on Innovative Computing and Communications. Proceedings of ICICC 2019. Advances in Intelligent Systems and Computing (AISC 1087), P279, DOI 10.1007/978-981-15-1286-5_24
   Hazarika RA, 2021, IEEE ACCESS, V9, P58503, DOI 10.1109/ACCESS.2021.3072559
   Herrera LJ, 2013, 2013 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM), P846, DOI 10.1109/SocialCom.2013.127
   Hori T, 2017, COMPUT SPEECH LANG, V46, P401, DOI 10.1016/j.csl.2017.01.013
   Hossain Muhammad Zakir, 2019, Dement Geriatr Cogn Disord, V48, P330, DOI [10.1159/000506123, 10.1159/000506363]
   HU C, 2016, CLIM DYNAM, P1
   Ibrahim A, 2020, IEEE ACCESS, V8, P122121, DOI 10.1109/ACCESS.2020.3007336
   Irankhah E., 2020, Bioprocess Eng, V4, P17, DOI [10.11648/j.be.20200401.13, DOI 10.11648/J.BE.20200401.13]
   Islam T, 2017, 2017 IEEE 1ST INTERNATIONAL CONFERENCE ON COGNITIVE COMPUTING (ICCC 2017), P24, DOI 10.1109/IEEE.ICCC.2017.11
   JAIN A, 2016, PROC CVPR IEEE, P5308, DOI DOI 10.1109/CVPR.2016.573
   Jain R, 2019, COGN SYST RES, V57, P147, DOI 10.1016/j.cogsys.2018.12.015
   JAYALAKSHMI ANM, 2018, J KING SAUD U COMPUT
   Jemwa GT, 2005, AICHE J, V51, P526, DOI 10.1002/aic.10315
   Jo T, 2019, FRONT AGING NEUROSCI, V11, DOI 10.3389/fnagi.2019.00220
   Johnson JM, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0192-5
   Johnson KA, 2012, CSH PERSPECT MED, V2, DOI 10.1101/cshperspect.a006213
   Kazemi Y, 2018, 2018 IEEE CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY (CIBCB), P154
   Khademi A, 2020, MAGN RESON IMAGING, V66, P116, DOI 10.1016/j.mri.2019.08.022
   Khagi B, 2020, IEEE ACCESS, V8, P217830, DOI 10.1109/ACCESS.2020.3040486
   Khagi B, 2019, INT J IMAG SYST TECH, V29, P297, DOI 10.1002/ima.22316
   Khvostikov A, 2018, ARXIV180105968 CORR
   Kundaram Swathi S., 2021, Proceedings of the Fourth International Conference on Microelectronics, Computing and Communication Systems. MCCS 2019. Lecture Notes in Electrical Engineering (LNEE 673), P587, DOI 10.1007/978-981-15-5546-6_50
   Labeeb YA., 2015, INT J ENG RES TECHNO, V04, P2278
   Lechner M, 2020, ADV NEURAL INFORM PR, V33
   Lee G, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-37769-z
   Li F, 2019, J NEUROSCI METH, V323, P108, DOI 10.1016/j.jneumeth.2019.05.006
   Li H, 2017, AUTOM CONTROL COMPUT, V51, P97, DOI 10.3103/S0146411617020043
   Lipton ZC, 2018, COMMUN ACM, V61, P36, DOI 10.1145/3233231
   Liu F, 2013, LECT NOTES COMPUT SC, V8149, P308, DOI 10.1007/978-3-642-40811-3_39
   Liu SQ, 2014, I S BIOMED IMAGING, P1015, DOI 10.1109/ISBI.2014.6868045
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Mehmood A, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10020084
   Ming Y, 2017, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2017.8585721
   Morabito FC, 2019, ARTIFICIAL INTELLIGENCE IN THE AGE OF NEURAL NETWORKS AND BRAIN COMPUTING, P219, DOI 10.1016/B978-0-12-815480-9.00011-6
   Nawaz H, 2021, MULTIMED TOOLS APPL, V80, P35789, DOI 10.1007/s11042-020-09087-y
   Ng YS, 2019, MADIMA'19: PROCEEDINGS OF THE 5TH INTERNATIONAL WORKSHOP ON MULTIMEDIA ASSISTED DIETARY MANAGEMENT, P33, DOI 10.1145/3347448.3357168
   Nicholson C, 2019, SKYMIND SAATAVISSA
   Noda K, 2015, APPL INTELL, V42, P722, DOI 10.1007/s10489-014-0629-7
   Noor Manan Binth Taj, 2020, Brain Inform, V7, P11, DOI 10.1186/s40708-020-00112-2
   O'Mahony N, 2020, ADV INTELL SYST COMP, V943, P128, DOI 10.1007/978-3-030-17795-9_10
   Otter DW, 2021, IEEE T NEUR NET LEAR, V32, P604, DOI 10.1109/TNNLS.2020.2979670
   Pak M, 2017, INT C SYNTH MODEL AN
   Panza F, 2010, AM J GERIAT PSYCHIAT, V18, P98, DOI 10.1097/JGP.0b013e3181b0fa13
   Pathirage CSN, 2018, ENG STRUCT, V172, P13, DOI 10.1016/j.engstruct.2018.05.109
   Paudel YN, 2020, CELLS-BASEL, V9, DOI 10.3390/cells9020383
   Peng JJ, 2019, FRONT GENET, V10, DOI 10.3389/fgene.2019.00226
   Pereira L, 2020, SHOW TELL NEURAL VIS, DOI 10.2139/ssrn.3565282
   Pichler Bernd J., 2008, V185, P109, DOI 10.1007/978-3-540-72718-7_6
   Pierce AL, 2017, NEUROL CLIN, V35, P283, DOI 10.1016/j.ncl.2017.01.006
   Qiu F., 2004, Giscience & Remote Sensing, V41, P244, DOI DOI 10.2747/1548-1603.41.3.244
   Rajeshwari S., 2013, IEEE C INF COMM TECH
   Ramzan F, 2019, J MED SYST, V44, DOI 10.1007/s10916-019-1475-2
   Sajedi H, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1401-7
   Salehi AW, 2020, 2020 INT C SMART EL, DOI 10.1109/icosec49089.2020.9215402
   Sandoub G., 2021, IET IMAGE PROCESS, V118, P3681
   Sarraf S.Tofighi., 2016, Classification of alzheimer's disease using fmri data and deep learning convolutional neural networks
   Shah M, 2011, MED IMAGE ANAL, V15, P267, DOI 10.1016/j.media.2010.12.003
   Shakarami A, 2020, OPTIK, V212, DOI 10.1016/j.ijleo.2020.164237
   Shankar GM, 2009, MOL NEURODEGENER, V4, DOI 10.1186/1750-1326-4-48
   Sharma S, 2017, Towards Data Sci, V6, P310, DOI [DOI 10.33564/IJEAST.2020.V04I12.054, 10.33564/IJEAST.2020.v04i12.054]
   Shen CQ, 2018, ENG APPL ARTIF INTEL, V76, P170, DOI 10.1016/j.engappai.2018.09.010
   Shi J, 2018, IEEE J BIOMED HEALTH, V22, P173, DOI 10.1109/JBHI.2017.2655720
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Shrestha S, 2014, ARXIV PREPRINT ARXIV
   Singh SP, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185097
   Sobhani A, 2017, IEEE INT C INTELL TR
   Spasov S, 2019, NEUROIMAGE, V189, P276, DOI 10.1016/j.neuroimage.2019.01.031
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Suk HI, 2017, MED IMAGE ANAL, V37, P101, DOI 10.1016/j.media.2017.01.008
   Suk HI, 2016, BRAIN STRUCT FUNCT, V221, P2569, DOI 10.1007/s00429-015-1059-y
   Sun C, 2019, IEEE T IND INFORM, V15, P2416, DOI 10.1109/TII.2018.2881543
   Sun WJ, 2016, MEASUREMENT, V89, P171, DOI 10.1016/j.measurement.2016.04.007
   Sun XF, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/s12938-015-0064-y
   Tanveer M, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3344998
   Tao SQ, 2015, CHIN CONTR CONF, P6331, DOI 10.1109/ChiCC.2015.7260634
   Thambusamy V., 2018, IntJPureApplMath, V118, P3681, DOI DOI 10.3390/CANCERS14092132
   THEODORE WH, 1986, NEUROLOGY, V36, P750, DOI 10.1212/WNL.36.6.750
   Trambaiolli LR, 2011, CLIN EEG NEUROSCI, V42, P160, DOI 10.1177/155005941104200304
   Vemuri P, 2009, NEUROLOGY, V73, P294, DOI 10.1212/WNL.0b013e3181af79fb
   Venugopalan J, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-74399-w
   Vu TD, 2017, INT CONF BIG DATA, P309, DOI 10.1109/BIGCOMP.2017.7881683
   Wang F, 2019, JAMA INTERN MED, V179, P293, DOI 10.1001/jamainternmed.2018.7117
   Wang Y, 2018, IEEE ENG MED BIO, P754, DOI 10.1109/EMBC.2018.8512372
   Wei J, 2019, INFOMAT, V1, P338, DOI 10.1002/inf2.12028
   Wen L, 2019, IEEE T SYST MAN CY-S, V49, P136, DOI 10.1109/TSMC.2017.2754287
   Wu MY, 2015, CHIN AUTOM CONGR, P542, DOI 10.1109/CAC.2015.7382560
   Wu O, 2019, STROKE, V50, P1734, DOI 10.1161/STROKEAHA.119.025373
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yanase J, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.112821
   Yildirim M, J HOMEPAGE, V25, P413, DOI 10.18280/isi.250402
   Yin W., 2017, CoRR
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zhang L, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00779
   Zhang Y, 2020, INT CONF BIG DATA, P1, DOI 10.1109/BigComp48618.2020.0-109
   Zhao X, 2021, METHODS, V192, P131, DOI 10.1016/j.ymeth.2020.09.007
   Zotin A, 2018, INTEL SYST REF LIBR, V136, P223, DOI 10.1007/978-3-319-67994-5_9
NR 143
TC 18
Z9 18
U1 6
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 23735
EP 23776
DI 10.1007/s11042-022-11925-0
EA MAR 2022
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770549800014
OA hybrid
DA 2024-07-18
ER

PT J
AU Wei, JS
   Lu, GM
   Yan, JJ
   Liu, HM
AF Wei, Jinsheng
   Lu, Guanming
   Yan, Jingjie
   Liu, Huaming
TI Micro-expression recognition using local binary pattern from five
   intersecting planes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Micro-expression recognition; Oblique direction; Dynamic texture
   features; Eight vertices local binary pattern
ID EMOTIONS; DYNAMICS
AB Micro-expression recognition has important research value and huge research difficulties. Local Binary Pattern from Three Orthogonal Planes (LBP-TOP) is a common and effective feature in micro-expression recognition. However, LBP-TOP only extracts the dynamic texture features in the horizontal and vertical directions and does not consider muscle movement in the oblique direction. In this paper, the feature in oblique directions is studied, and a new feature called Local Binary Pattern from Five Intersecting Planes (LBP-FIP) is proposed by analyzing the movement direction of facial muscles in the micro-expression video. LBP-FIP concatenates the proposed Eight Vertices LBP (EVLBP) with LBP-TOP extracted from three planes, where EVLBP is extracted from two planes in the oblique direction. In this way, the dynamic texture features in the oblique direction are extracted more directly. On the CASME II and SMIC database, we evaluated the proposed feature and the effectiveness of the features in the oblique direction. Extensive experiments prove that LBP-FIP provides more effective feature information than LBP-TOP, and extracting the features in oblique directions is discriminative for recognizing micro-expressions. Also, LBP-FIP has advantages comparing with other LBP based features and achieves satisfactory performance, especially on CASME II.
C1 [Wei, Jinsheng; Lu, Guanming; Yan, Jingjie; Liu, Huaming] Nanjing Univ Posts & Telecommun, Nanjing 210003, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Lu, GM (corresponding author), Nanjing Univ Posts & Telecommun, Nanjing 210003, Peoples R China.
EM lugm@njupt.edu.cn
RI Wei, Jinsheng/KBB-8618-2024
OI Wei, Jinsheng/0000-0002-6112-6307
FU Postgraduate Research and Practice Innovation Program of Jiangsu
   Province [KYCX19 0899]; National Natural Science Foundation of China
   (NSFC) [61971236]; Key Research and Development Program of Jiangsu
   Province [BE2016775]; China Postdoctoral Science Foundation
   [2018M632348]
FX This work was partly supported by the Postgraduate Research and Practice
   Innovation Program of Jiangsu Province under Grant KYCX19 0899, partly
   by the National Natural Science Foundation of China (NSFC) under Grants
   72074038, partly by the Key Research and Development Program of Jiangsu
   Province under Grant BE2016775, partly by the National Natural Science
   Foundation of China (NSFC) under Grants 61971236, partly by China
   Postdoctoral Science Foundation under Grant 2018M632348.
CR Ngo ACL, 2017, IEEE T AFFECT COMPUT, V8, P396, DOI 10.1109/TAFFC.2016.2523996
   Ngo ACL, 2016, INT CONF ACOUST SPEE, P1243, DOI 10.1109/ICASSP.2016.7471875
   [Anonymous], 2009, The philosophy of deception, DOI DOI 10.1093/ACPROF:OSO/9780195327939.003.0008
   Chakraborty Sudipta, 2015, 2015 IEEE Power & Energy Society General Meeting, P1, DOI 10.1109/PESGM.2015.7285795
   Davison AK, 2018, IEEE T AFFECT COMPUT, V9, P116, DOI 10.1109/TAFFC.2016.2573832
   Ekman P., MICROEXPRESSION TRAI
   Fan KC, 2014, IEEE T IMAGE PROCESS, V23, P2877, DOI 10.1109/TIP.2014.2321495
   Gravitz MA, 2011, AM J CLIN HYPN, V53, P287, DOI 10.1080/00029157.2011.10404358
   Han J, 2002, IEEE T IMAGE PROCESS, V11, P944, DOI 10.1109/TIP.2002.801585
   Happy SL, 2019, IEEE T AFFECT COMPUT, V10, P394, DOI 10.1109/TAFFC.2017.2723386
   Huang XH, 2019, IEEE T AFFECT COMPUT, V10, P32, DOI 10.1109/TAFFC.2017.2713359
   Huang XH, 2017, 2017 INTERNATIONAL CONFERENCE ON THE FRONTIERS AND ADVANCES IN DATA SCIENCE (FADS), P198, DOI 10.1109/FADS.2017.8253219
   Huang XH, 2016, NEUROCOMPUTING, V175, P564, DOI 10.1016/j.neucom.2015.10.096
   Khor HQ, 2019, IEEE IMAGE PROC, P36, DOI [10.1109/icip.2019.8802965, 10.1109/ICIP.2019.8802965]
   Khor HQ, 2018, IEEE INT CONF AUTOMA, P667, DOI 10.1109/FG.2018.00105
   Kim DH, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P382, DOI 10.1145/2964284.2967247
   Le Ngo AC, 2015, LECT NOTES COMPUT SC, V9006, P33, DOI 10.1007/978-3-319-16817-3_3
   Li J, 2019, PATTERN ANAL APPL, V22, P1331, DOI 10.1007/s10044-018-0757-5
   Li XB, 2018, IEEE T AFFECT COMPUT, V9, P563, DOI 10.1109/TAFFC.2017.2667642
   Li XB, 2013, IEEE INT CONF AUTOMA, DOI 10.1109/FG.2013.6553717
   Liong ST, 2014, I S INTELL SIG PROC, P180, DOI 10.1109/ISPACS.2014.7024448
   Liu Y.-J., IEEE T AFFECT COMPUT
   Liu YJ, 2016, IEEE T AFFECT COMPUT, V7, P299, DOI 10.1109/TAFFC.2015.2485205
   Martin O., 2006, 22 INT C DATA ENG WO, P8, DOI [DOI 10.1109/ICDEW.2006.145, 10.1109/ICDEW.2006.145]
   Matsumoto D, 2011, MOTIV EMOTION, V35, P181, DOI 10.1007/s11031-011-9212-2
   Méndez-Vázquez H, 2013, INT CONF BIOMETR
   O'Sullivan M, 2009, LAW HUMAN BEHAV, V33, P530, DOI 10.1007/s10979-008-9166-4
   Oh YH, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01128
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Porter S, 2008, PSYCHOL SCI, V19, P508, DOI 10.1111/j.1467-9280.2008.02116.x
   Song BL, 2019, IEEE ACCESS, V7, P184537, DOI 10.1109/ACCESS.2019.2960629
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Verma M, 2020, IEEE T IMAGE PROCESS, V29, P1618, DOI 10.1109/TIP.2019.2912358
   Wang SJ, 2015, IEEE T IMAGE PROCESS, V24, P6034, DOI 10.1109/TIP.2015.2496314
   Wang YD, 2017, MULTIMED TOOLS APPL, V76, P21665, DOI 10.1007/s11042-016-4079-6
   Wang YD, 2015, LECT NOTES COMPUT SC, V9003, P525, DOI 10.1007/978-3-319-16865-4_34
   Wang YF, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0124812
   Weinberger S, 2010, NATURE, V465, P412, DOI 10.1038/465412a
   Wu HY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185561
   Xiao-Bin Huang, 2015, 2015 Asia-Pacific Microwave Conference (APMC). Proceedings, P1, DOI 10.1109/APMC.2015.7413025
   Xu F, 2017, IEEE T AFFECT COMPUT, V8, P254, DOI 10.1109/TAFFC.2016.2518162
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Yan WJ, 2013, J NONVERBAL BEHAV, V37, P217, DOI 10.1007/s10919-013-0159-8
   YANG B, MULTIMED TOOLS APPL
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zheng H, 2016, LECT NOTES COMPUT SC, V9810, P692, DOI 10.1007/978-3-319-42911-3_58
   Zhou ZH, 2011, PROC CVPR IEEE, P137, DOI 10.1109/CVPR.2011.5995345
   Zong Y, 2018, IEEE T MULTIMEDIA, V20, P3160, DOI 10.1109/TMM.2018.2820321
NR 48
TC 9
Z9 10
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 20643
EP 20668
DI 10.1007/s11042-022-12360-x
EA MAR 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000767748600001
DA 2024-07-18
ER

PT J
AU Yadav, DP
   Jalal, AS
   Prakash, V
AF Yadav, D. P.
   Jalal, Anand Singh
   Prakash, Ved
TI Human burn depth and grafting prognosis using ResNeXt topology based
   deep learning network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Classification; Burn; Diagnosis; Graft; CNN
ID CLASSIFICATION
AB The human burn diagnosis is becoming essential. Early diagnosis of a burn can save human life. Therefore, it is essential to develop a fast, robust, and efficient computer-based system for the diagnosis of burn. In recent days, the deep Convolutional Neural Network (CNN) model is set as a benchmark for medical image diagnosis. We have investigated ResNeXt, VGG16 and AlexNet on our human burn image dataset. We found that these model performance is not optimal. Therefore, in this work, we have designed a new model called BNeXt. The BNeXt CNN model kernel and convolutional layers are designed in such a way that it can discriminate the human burn efficiently. In previous studies, the burn has been classified into two broad categories that are graft and non-graft. The proposed study first determines the degree of a burn and later it classifies a burn into graft and non-graft. The manual burn diagnosis is time-consuming and accuracy varies from 75 to 80% by an expert doctor. The proposed model is efficient with an accuracy of 97.17% for burn degree and 99.67% for the grafting and non-grafting determination based on the depth of a burn. This model can be deployed on the cloud or the local system for the fast screening of burn patients.
C1 [Yadav, D. P.; Jalal, Anand Singh] GLA Univ, Dept Comp Engn & Applicat, Mathura, UP, India.
   [Prakash, Ved] Asian Inst Med Sci, Faridabad, India.
C3 GLA University
RP Jalal, AS (corresponding author), GLA Univ, Dept Comp Engn & Applicat, Mathura, UP, India.
EM dhirendra.yadav@gla.ac.in; asjalal@gla.ac.in; ved.prakash@aimsindia.com
OI Jalal, Anand/0000-0002-7469-6608; Yadav, Dhirendra
   Prasad/0000-0001-9349-3964
CR Abubakar A, 2020, J MED BIOL ENG, V40, P321, DOI 10.1007/s40846-020-00520-z
   Acha B, 2004, PROC SPIE, V5370, P1018, DOI 10.1117/12.535491
   Acha B, 2005, J BIOMED OPT, V10, DOI 10.1117/1.1921227
   Acha B, 2013, IEEE T MED IMAGING, V32, P1111, DOI 10.1109/TMI.2013.2254719
   [Anonymous], 2017, RESNEXT IMPLEMENTATI
   Badea MS, 2016, INT CONF COMM, P65, DOI 10.1109/ICComm.2016.7528325
   Beena B., 2017, International Journal of Engineering Trends and Technology, V48, P48, DOI [DOI 10.14445/22315381/IJETT-V48P209, 10.14445/22315381/ijett-v48p209]
   Biomedical Image Processing (BIP) Group from the Signal Theory and Communications Department (University of Seville SPAIN) and Virgen del Rocio Hospital (Seville Spain), BURNS BIP US DAT
   Buttner A., 2019, 2019 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC), DOI 10.1109/CLEOE-EQEC.2019.8871727
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hai T. S, 2017, EAI Endorsed Transactions on Context-Aware Systems and Applications, V4
   Haller HL., 2012, HDB OF BURNS
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jaskille AD, 2009, J BURN CARE RES, V30, P937, DOI 10.1097/BCR.0b013e3181c07f21
   Khan FA, 2020, MULTIMED TOOLS APPL, V79, P34545, DOI 10.1007/s11042-020-08768-y
   Khatib M, 2014, PLASTIC SURG INT, V2014
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuan P., 2017, Journal of Telecommunication, Electronic and Computer Engineering (JTEC), V9, P15
   Lee KC, 2016, BURNS TRAUMA, V4, DOI 10.1186/s41038-016-0036-x
   Mandrekar JN, 2010, J THORAC ONCOL, V5, P1315, DOI 10.1097/JTO.0b013e3181ec173d
   Mikolajczyk Agnieszka, 2018, 2018 International Interdisciplinary PhD Workshop (IIPhDW), P117, DOI 10.1109/IIPHDW.2018.8388338
   Mukherjee R, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/851582
   Pridgen BC., 2019, J BURN CARE RES, V40, pS25, DOI [10.1093/jbcr/irz013.037, DOI 10.1093/JBCR/IRZ013.037]
   Rostami B, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104536
   Serrano C, 2015, BURNS, V41, P1883, DOI 10.1016/j.burns.2015.05.011
   Sevik U, 2019, IET IMAGE PROCESS, V13, P2018, DOI 10.1049/iet-ipr.2018.5899
   Shin JY, 2016, BURNS, V42, P1369, DOI 10.1016/j.burns.2016.03.012
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Suvarna Malini, 2013, International Journal of Computer Science & Information Technology, V5, P104, DOI 10.5121/ijcsit.2013.5109
   Tran H, 2015, Context-Aware Systems and Applications. ICCASA 2015, P233
   Veit A, 2016, ADV NEUR IN, V29
   Wada D, 2017, 2017 56TH ANNUAL CONFERENCE OF THE SOCIETY OF INSTRUMENT AND CONTROL ENGINEERS OF JAPAN (SICE), P483, DOI 10.23919/SICE.2017.8105626
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yadav DP, 2019, IEEE J TRANSL ENG HE, V7, DOI 10.1109/JTEHM.2019.2923628
NR 34
TC 6
Z9 6
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18897
EP 18914
DI 10.1007/s11042-022-12555-2
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000767089800007
DA 2024-07-18
ER

PT J
AU Ramya, R
   Senthilmurugan, M
AF Ramya, R.
   Senthilmurugan, M.
TI An effective super resolution image reconstruction using spatial entropy
   based normalized deep convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AWLS filtering; ARDT based edge preservation; Spatial entropy based
   normalization (SNDCN); Super resolution reconstruction
ID RESIDUAL NETWORKS; SUPERRESOLUTION
AB The main aim of Super Resolution (SR) is to obtain high quality image with high resolution from Low Resolution (LR) images. In numerous computer vision systems, the SR from a single image plays avital role.A major problem in Image SR reconstruction is to acquire a high-resolution (HR) image from a single LR image or multiple LR images which are having sub-pixel changes. Currently, learning based methodology is developed from the HR images from the LR images with better quality. This work presented a spatial entropy based normalization dependent deep convolutional neural network (SNDCN) for SR reconstruction with minimized artifact. Initially, the input LR images are pre-processed utilizing adaptive weighted linear smoothing (AWLS) filtering. Then the pre-processed smoothened images are undergoes to adaptive real time dual threshold (ARDT) technique for preserving the edges. Here, the edge preservation process utilizing the ARDT to enhance the quality of the image. Finally, SNDCN is utilized to construct SR images. The experimental outcomes of the presented technique proved that the varying performance measures attaining better super resolution image reconstruction than the existing methodologies. Additionally, the proposed method complete the reconstruction procedure within 18 s and obtain 34 dB as PSNR value for scaling factor 4 in which the outcome shows that significant of proposed methodology over existing methodologies.
C1 [Ramya, R.] Sri Balaji Vidyapeeth Deemed Univ, Pondicherry 607402, India.
   [Senthilmurugan, M.] AVC Coll Engn, Mayiladuthurai 609305, Tamil Nadu, India.
RP Ramya, R (corresponding author), Sri Balaji Vidyapeeth Deemed Univ, Pondicherry 607402, India.
EM ramyamagesh25@rediffmail.com
CR Bai K, 2020, PATTERN RECOGN IMAGE, V30, P567
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Du JL, 2018, IEEE INT C BIOINFORM, P349, DOI 10.1109/BIBM.2018.8621073
   Fang FM, 2020, IEEE T IMAGE PROCESS, V29, P4656, DOI 10.1109/TIP.2020.2973769
   Ha VK, 2020, J REAL-TIME IMAGE PR, V17, P1961, DOI 10.1007/s11554-020-00973-0
   Hengel A.V.D., 2016, ARXIV PREPRINT ARXIV
   Jiang JJ, 2017, IEEE T MULTIMEDIA, V19, P15, DOI 10.1109/TMM.2016.2599145
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kim JH, 2018, IEEE COMPUT SOC CONF, P913, DOI 10.1109/CVPRW.2018.00124
   Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304
   Lin GM, 2018, NEUROCOMPUTING, V275, P1219, DOI 10.1016/j.neucom.2017.09.062
   Liu P, 2019, PROCEEDINGS OF 2019 IEEE 8TH JOINT INTERNATIONAL INFORMATION TECHNOLOGY AND ARTIFICIAL INTELLIGENCE CONFERENCE (ITAIC 2019), P726, DOI [10.1109/itaic.2019.8785627, 10.1109/ITAIC.2019.8785627]
   Liu YH, 2019, IEEE T GEOSCI REMOTE, V57, P2043, DOI 10.1109/TGRS.2018.2870871
   Nandi D, 2019, IET IMAGE PROCESS, V13, P663, DOI 10.1049/iet-ipr.2018.5139
   Qin JH, 2020, NEUROCOMPUTING, V379, P334, DOI 10.1016/j.neucom.2019.10.076
   Qiu DF, 2021, FUTURE GENER COMP SY, V116, P200, DOI 10.1016/j.future.2020.11.001
   Sánchez-García E, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11161880
   Solanki P., 2018, Statistics, Optimization Information Computing, V6, P619, DOI [https://doi.org/10.19139/soic.v6i4.433, DOI 10.19139/SOIC.V6I4.433]
   Song TA, 2020, IEEE T COMPUT IMAG, V6, P518, DOI [10.1109/TCI.2020.2964229, 10.1109/tci.2020.2964229]
   Suryanarayana G, 2017, CIRC SYST SIGNAL PR, V36, P3409, DOI 10.1007/s00034-016-0470-9
   Tang YL, 2020, NEUROCOMPUTING, V405, P186, DOI 10.1016/j.neucom.2020.04.030
   Wang XF, 2018, J VIS COMMUN IMAGE R, V53, P65, DOI 10.1016/j.jvcir.2018.03.011
   Yang CS, 2019, J OPTICS-UK, V21, DOI 10.1088/2040-8986/ab00d9
   Yang CY, 2014, LECT NOTES COMPUT SC, V8692, P372, DOI 10.1007/978-3-319-10593-2_25
   Yang Q, 2018, ISA T, V82, P163, DOI 10.1016/j.isatra.2017.03.001
   Yoon Y, 2017, IEEE SIGNAL PROC LET, V24, P848, DOI 10.1109/LSP.2017.2669333
   Zeng K, 2019, APPL INTELL, V49, P292, DOI 10.1007/s10489-018-1270-7
   Zhang YF, 2018, IEEE T IMAGE PROCESS, V27, P3782, DOI 10.1109/TIP.2018.2826139
   Zheng H, 2018, IEEE ACCESS, V6, P57856, DOI 10.1109/ACCESS.2018.2873484
NR 29
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18737
EP 18753
DI 10.1007/s11042-022-12511-0
EA MAR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766430800003
DA 2024-07-18
ER

PT J
AU Bian, XF
   Pan, HW
   Zhang, KJ
   Li, PY
   Li, JB
   Chen, CL
AF Bian, Xiaofei
   Pan, Haiwei
   Zhang, Kejia
   Li, Pengyuan
   Li, Jinbao
   Chen, Chunling
TI Skin lesion image classification method based on extension theory and
   deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin lesions; Classification; Skin-dependent feature; Extension theory;
   Deep learning; YOLOv3
ID NETWORKS
AB A skin lesion is a part of the skin that has abnormal growth on body parts. Early detection of the lesion is necessary, especially malignant melanoma, which is the deadliest form of skin cancer. It can be more readily treated successfully if detected and classified accurately in its early stages. At present, most of the existing skin lesion image classification methods only use deep learning. However, medical domain features are not well integrated into deep learning methods. In this paper, for skin diseases in Asians, a two-phase classification method for skin lesion images is proposed to solve the above problems. First, a classification framework integrated with medical domain knowledge, deep learning, and a refined strategy is proposed. Then, a skin-dependent feature is introduced to efficiently distinguish malignant melanoma. An extension theory-based method is presented to detect the existence of this feature. Finally, a classification method based on deep learning (YoDyCK: YOLOv3 optimized by Dynamic Convolution Kernel) is proposed to classify them into three classes: pigmented nevi, nail matrix nevi and malignant melanomas. We conducted a variety of experiments to evaluate the performance of the proposed method in skin lesion images. Compared with three state-of-the-art methods, our method significantly improves the classification accuracy of skin diseases.
C1 [Bian, Xiaofei; Pan, Haiwei; Zhang, Kejia; Chen, Chunling] Harbin Engn Univ, Comp Sci & Technol, 145 Nantong St, Harbin 150001, Heilongjiang, Peoples R China.
   [Li, Pengyuan] Univ Delaware, Dept Comp & Informat Sci, Newark, DE 19716 USA.
   [Li, Jinbao] Qilu Univ Technol, Shandong Artificial Intelligence Inst, Shandong Acad Sci, Jinan, Peoples R China.
C3 Harbin Engineering University; University of Delaware; Qilu University
   of Technology
RP Pan, HW (corresponding author), Harbin Engn Univ, Comp Sci & Technol, 145 Nantong St, Harbin 150001, Heilongjiang, Peoples R China.
EM panhaiwei@hrbeu.edu.cn
RI Li, Pengyuan/GNW-6822-2022
OI Pan, Haiwei/0000-0001-9297-5662
FU National Natural Science Foundation of China [62072135, 61672181]
FX The paper is supported by the National Natural Science Foundation of
   China under Grant No.62072135 and No.61672181.
CR Alfed N, 2017, EXPERT SYST APPL, V90, P101, DOI 10.1016/j.eswa.2017.08.010
   Argenziano G, 1998, ARCH DERMATOL, V134, P1563, DOI 10.1001/archderm.134.12.1563
   Arjovsky, 2017, ARXIV170104862
   Aswin RB, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTROL, INSTRUMENTATION, COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICCICCT), P1304, DOI 10.1109/ICCICCT.2014.6993162
   Cai Wen, 2006, Journal of the Harbin Institute of Technology, V38, P1079
   Celebi ME, 2008, COMPUT MED IMAG GRAP, V32, P670, DOI 10.1016/j.compmedimag.2008.08.003
   Chandy DA, 2014, MULTIMED TOOLS APPL, V72, P2011, DOI 10.1007/s11042-013-1511-z
   Chen BZ, 2020, IEEE J BIOMED HEALTH, V24, P2292, DOI 10.1109/JBHI.2020.2967084
   CHEN CC, 1989, IEEE T MED IMAGING, V8, P133, DOI 10.1109/42.24861
   Chen HJ, 2020, IEEE J BIOMED HEALTH, V24, P2825, DOI 10.1109/JBHI.2020.2973982
   Chen X, 2018, J HEILONGJIANG U SCI, V28, P124
   Chen X, 2016, J INNER MONGOLIA U N, V31, P185
   Choi YH, 2013, MULTIMED TOOLS APPL, V64, P227, DOI 10.1007/s11042-011-0987-7
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   Di Leo G, 2009, 2009 6TH INTERNATIONAL MULTI-CONFERENCE ON SYSTEMS, SIGNALS AND DEVICES, VOLS 1 AND 2, P1007
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Florentin S., 2012, 6 C SOFTW KNOWL INF, P9
   Frid-Adar M, 2018, NEUROCOMPUTING, V321, P321, DOI 10.1016/j.neucom.2018.09.013
   Ganster H, 2001, IEEE T MED IMAGING, V20, P233, DOI 10.1109/42.918473
   Gao LL, 2015, IEEE INT C BIOINFORM, P1004, DOI 10.1109/BIBM.2015.7359821
   Arroyo JLG, 2011, IEEE INT SYMP SIGNAL, P196
   Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401
   Guan Feng-xu, 2006, Journal of the Harbin Institute of Technology, V38, P1146
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He Bin, 2005, Control Theory & Applications, V22, P165
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Janney B, 2020, MULTIMED TOOLS APPL, V79, P3713, DOI 10.1007/s11042-018-6927-z
   Kittler H, 2002, LANCET ONCOL, V3, P159, DOI 10.1016/S1470-2045(02)00679-4
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Leo G.D., 2010, 43rd International Conference on System Sciences, Hawaii January 5-8 2010, P1
   Melbin K, 2021, MULTIMED TOOLS APPL, V80, P8909, DOI 10.1007/s11042-020-10056-8
   Mhaske HR, 2013, 2013 INTERNATIONAL CONFERENCE ON CIRCUITS, CONTROLS AND COMMUNICATIONS (CCUBE)
   Pan HW, 2014, IEEE J BIOMED HEALTH, V18, P574, DOI 10.1109/JBHI.2013.2274798
   Pang SC, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0217647
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Röhrich E, 2012, BMC MED IMAGING, V12, DOI 10.1186/1471-2342-12-32
   Roth HR, 2016, IEEE T MED IMAGING, V35, P1170, DOI 10.1109/TMI.2015.2482920
   Seidenari S, 2010, BRIT J DERMATOL, V163, P302, DOI 10.1111/j.1365-2133.2010.09821.x
   Setiawan Agung W., 2020, 2020 International Seminar on Application for Technology of Information and Communication (iSemantic), P436, DOI 10.1109/iSemantic50169.2020.9234245
   Setiawan Agung W., 2020, 2020 International Seminar on Intelligent Technology and Its Applications (ISITIA). Proceedings, P148, DOI 10.1109/ISITIA49792.2020.9163734
   Stoecker WV, 2011, COMPUT MED IMAG GRAP, V35, P144, DOI 10.1016/j.compmedimag.2010.09.005
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Ulhaq A., 2020, STAT DATA SCI POLICY, P185
   Ünver HM, 2019, DIAGNOSTICS, V9, DOI 10.3390/diagnostics9030072
   Vitoria P, 2019, VISAPP: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 4, P249, DOI 10.5220/0007367902490260
   Warsi Firoz, 2019, Informatics in Medicine Unlocked, V17, P257, DOI 10.1016/j.imu.2019.100176
   Wen C, 1983, Sci. Explor. China, V1, P83
   Yang C., 2007, Extension engineering
   Yang C, 2005, 27 S P XIANGSH SCI C, V12, P35
   Yang Chun-yan, 2011, Journal of Guangdong University of Technology, V28, P86
   Yun Y., 2013, SWED S IM AN SSBA, P14
   Zarit B. D., 1999, Proceedings International Workshop on Recognition, Analysis, and Tracking of Faces and Gestures in Real-Time Systems. In Conjunction with ICCV'99 (Cat. No.PR00378), P58, DOI 10.1109/RATFG.1999.799224
   Zhang XX, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2019), P372, DOI [10.1109/SIPROCESS.2019.8868430, 10.1109/siprocess.2019.8868430]
   Zhang-China B, 2010, INT J BIOM BIOINFORM, V8, P554
   Zhao Yanwei S, 2010, EXTENSION DESIGN
NR 57
TC 4
Z9 4
U1 3
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16389
EP 16409
DI 10.1007/s11042-022-12376-3
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763256300006
DA 2024-07-18
ER

PT J
AU Yang, X
   Li, ZQ
   Guo, YQ
   Zhou, DK
AF Yang, Xin
   Li, Zhiqiang
   Guo, Yingqing
   Zhou, Dake
TI DCU-net: a deformable convolutional neural network based on cascade
   U-net for retinal vessel segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Retinal vessel segmentation; Deep learning; U-net; Deformable
   convolution; Attention mechanism
ID BLOOD-VESSELS
AB To further improve retinal vessel segmentation accuracy, we propose a deformable convolutional neural network based on cascade U-Net for retinal vessel segmentation: DCU-Net. The overall structure of DCU-Net is composed of two U-Net. We introduce deformable convolution to build a feature extraction module, which enhances the modeling ability of the model for vessel deformation. For improving the efficiency of information transfer between U-Net models, we use a residual channel attention module to connect U-Net. DCUNet achieves excellent results on public datasets. On DRIVE and CHASE_DB1 datasets, the Acc reaches 0.9568, 0.9664, respectively, the AUC reaches 0.9810, and 0.9872, respectively. From the experimental results, the residual channel attention module and residual deformable convolution module greatly improve the retinal vessel segmentation accuracy. The comprehensive performance of our method is better than that of some state-of-the-art methods.
C1 [Yang, Xin; Li, Zhiqiang; Guo, Yingqing; Zhou, Dake] Nanjing Univ Aeronaut & Astronaut, Coll Automat Engn, Nanjing 210016, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics
RP Yang, X (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Automat Engn, Nanjing 210016, Peoples R China.
EM yangxin@nuaa.edu.cn
RI WANG, YONGJIA/KFQ-4823-2024; zhong, jing/KBP-7800-2024
OI Yang, Xin/0000-0003-0445-6497
FU National Natural Science Foundation of China [61573182]; Fundamental
   Research Funds for the Central Universities [NS2020025]
FX This study was funded by the National Natural Science Foundation of
   China (61573182), and by the Fundamental Research Funds for the Central
   Universities (NS2020025).
CR Alom M.Z., 2018, J MED IMAGING, DOI DOI 10.1117/1.JMI.6.1.014006
   Araújo RJ, 2019, LECT NOTES COMPUT SC, V11764, P93, DOI 10.1007/978-3-030-32239-7_11
   Azad R, 2019, IEEE INT CONF COMP V, P406, DOI 10.1109/ICCVW.2019.00052
   Chakraborty C, 2016, J COMMUNICATION NAVI, V2016, P57
   Chakraborty C, 2016, J MED SYST, V40, DOI 10.1007/s10916-015-0424-y
   Chakraborty Chinmay., 2015, International Journal of Rough Sets and Data Analysis, V2, P58, DOI DOI 10.4018/IJRSDA.2015070104
   Feng ST, 2020, NEUROCOMPUTING, V392, P268, DOI 10.1016/j.neucom.2018.10.098
   Ghiasi G, 2018, ADV NEUR IN, V31
   Huazhu Fu, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P132, DOI 10.1007/978-3-319-46723-8_16
   Jégou S, 2017, IEEE COMPUT SOC CONF, P1175, DOI 10.1109/CVPRW.2017.156
   Jie H, 2020, IEEE T PATT ANAL MAC, V42
   Li QL, 2016, IEEE T MED IMAGING, V35, P109, DOI 10.1109/TMI.2015.2457891
   Li RR, 2018, IEEE J-STARS, V11, P3954, DOI 10.1109/JSTARS.2018.2833382
   Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918
   Liskowski P, 2016, IEEE T MED IMAGING, V35, P2369, DOI 10.1109/TMI.2016.2546227
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Melinscak Martina, 2015, 10th International Conference on Computer Vision Theory and Applications (VISAPP 2015). Proceedings, P577
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Ngo L, 2017, ELECTRON LETT, V53, P1096, DOI 10.1049/el.2017.2066
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Owen CG, 2009, INVEST OPHTH VIS SCI, V50, P2004, DOI 10.1167/iovs.08-3018
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Wang B, 2019, LECT NOTES COMPUT SC, V11764, P84, DOI 10.1007/978-3-030-32239-7_10
   Wu YC, 2019, LECT NOTES COMPUT SC, V11764, P264, DOI 10.1007/978-3-030-32239-7_30
   Wu YC, 2018, LECT NOTES COMPUT SC, V11071, P119, DOI 10.1007/978-3-030-00934-2_14
   Yan ZQ, 2019, IEEE J BIOMED HEALTH, V23, P1427, DOI 10.1109/JBHI.2018.2872813
   Yu F, 2019, ANNOTATION FREE CARD
   Zhang YS, 2018, LECT NOTES COMPUT SC, V11071, P83, DOI 10.1007/978-3-030-00934-2_10
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
   Zhu X, 2018, ARXIV PREPRINT ARXIV
   Zhuang J.T., 2018, ARXIV PREPRINT ARXIV
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 34
TC 16
Z9 21
U1 10
U2 51
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15593
EP 15607
DI 10.1007/s11042-022-12418-w
EA FEB 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762173600012
DA 2024-07-18
ER

PT J
AU Song, YP
   He, FZ
   Liu, YA
AF Song, Yupeng
   He, Fazhi
   Liu, Yanan
TI A non-invasive learning branch to capture leaf-image attention for tree
   species classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Image classification; Attention mechanism; Tree species
AB Tree species classification is a necessary and challenging task for both multimedia technique and forestry engineering. Continuous developments in multimedia and vision technology enable this task to be achieved faster and more conveniently without relying on professional equipment. However, encountering many species and high similarity tree species, the existing methods cannot be completed well. In this paper, we propose a non-invasive attention learning branch structure to strengthen the discrimination of CNNs for complex tree species classification. Firstly, we proposed a novel network, namely Attention Learning Convolutional Neural Network (ALNet), in which a non-invasive learning branch for leaf-image attention capture is added in the typical convolutional blocks to strengthen the discrimination capacity of CNN, especially in the challenging task of classification of tree species with high similarity leaves, leaves image features only slightly different. Secondly, we designed a novel Attention Learning Branch (ALB), which can capture and learn leaf image attention, and be non-invasively integrated into existing CNN pipelines to capture the Region of Interest (ROI) of input features for image classification processing. Thirdly, we adopted a reliable residual approach to complete the integration of network branches, which improved overall network performance. In the Leafsnap dataset, the ALNet test was performed with 91.76% accuracy on the classification of 185 species of trees, in which trees of different subspecies contained highly similar leaf images. Moreover, in the conventional Flavia dataset of tree leaf-image, our proposed ALNet also achieved satisfying results. The proposed method showed a remarkable improvement in the work done previously.
C1 [Song, Yupeng; He, Fazhi] Wuhan Univ, Sch Comp Sci, Wuhan, Hubei, Peoples R China.
   [Liu, Yanan] Northwestern Polytech Univ, Sch Automat, Xian, Shanxi, Peoples R China.
C3 Wuhan University; Northwestern Polytechnical University
RP He, FZ (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan, Hubei, Peoples R China.
EM whu_cs_songyp@whu.edu.cn; fzhe@whu.edu.cn; lyn2020@mail.nwpu.edu.cn
RI He, Fazhi/Q-3691-2018
OI Song, Yupeng/0000-0003-0791-6268
FU National Natural Science Foundation of China [62072348]; Science and
   Technology Major Project of Hubei Province (Next-Generation AI
   Technologies) [2019AEA170]
FX This work is supported by the National Natural Science Foundation of
   China under Grant No 62072348, the Science and Technology Major Project
   of Hubei Province (Next-Generation AI Technologies) under Grant No
   2019AEA170.
CR Angelstam P, 2011, FORESTRY, V84, P581, DOI 10.1093/forestry/cpr048
   [Anonymous], 2019, Advances in Neural Information Processing Systems
   Barré P, 2017, ECOL INFORM, V40, P50, DOI 10.1016/j.ecoinf.2017.05.005
   Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Chen YL, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106335
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Friedel R, 2014, MULTIMED TOOLS APPL, V73, P2201, DOI 10.1007/s11042-013-1688-1
   Fu H, 2004, CHINESE B BOT
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He T, 2019, PROC CVPR IEEE, P558, DOI 10.1109/CVPR.2019.00065
   Hou N, 2020, FRONT COMPUT SCI-CHI, V14, DOI 10.1007/s11704-019-8184-3
   Hu J., 2017, ARXIV170901507 CORR
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3_36
   Li HR, 2021, MEMET COMPUT, V13, P1, DOI 10.1007/s12293-021-00328-7
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Liu L, 2019, COMPUT ELECTRON AGR, V163, DOI 10.1016/j.compag.2019.104871
   Liu S, 2020, CONCURR COMP-PRACT E, V32
   Luo JK, 2022, INT J BIO-INSPIR COM, V20, P71, DOI 10.1504/IJBIC.2022.126764
   Luo JK, 2020, INTELL DATA ANAL, V24, P581, DOI 10.3233/IDA-194641
   Mzoughi O, 2013, IEEE IMAGE PROC, P3967, DOI 10.1109/ICIP.2013.6738817
   NELDER JA, 1972, J R STAT SOC SER A-G, V135, P370, DOI 10.2307/2344614
   Netzer Yuval, 2011, ADV NEUR INF PROC SY
   Newton PF, 2003, COMPUT ELECTRON AGR, V39, P61, DOI 10.1016/S0168-1699(03)00004-8
   Pan YT, 2020, FRONT COMPUT SCI-CHI, V14, DOI 10.1007/s11704-019-8123-3
   Pearline SA, 2019, J INTELL FUZZY SYST, V36, P1997, DOI 10.3233/JIFS-169911
   Pu RL, 2020, URBAN FOR URBAN GREE, V53, DOI 10.1016/j.ufug.2020.126675
   Qin HT, 2020, PROC CVPR IEEE, P2247, DOI 10.1109/CVPR42600.2020.00232
   Quan Q, 2021, VISUAL COMPUT, V37, P245, DOI 10.1007/s00371-020-01796-7
   Sainath TN, 2015, NEURAL NETWORKS, V64, P39, DOI 10.1016/j.neunet.2014.08.005
   Sfar AR, 2015, INT J COMPUT VISION, V111, P255, DOI 10.1007/s11263-014-0743-3
   SUN Y, 2017, COMPUT INTEL NEUROSC, V2017, DOI DOI 10.1155/2017/7361042
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tran T., 2017, NEURIPS 2017, P2797
   ULABY FT, 1982, IEEE T GEOSCI REMOTE, V20, P42, DOI 10.1109/TGRS.1982.4307519
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wu SG, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P120
   Yan QA, 2016, COMPUT GRAPH FORUM, V35, P1, DOI 10.1111/cgf.12998
   Yan QA, 2014, COMPUT GRAPH FORUM, V33, P339, DOI 10.1111/cgf.12502
   Yigit E, 2019, COMPUT ELECTRON AGR, V156, P369, DOI 10.1016/j.compag.2018.11.036
   Zhang SD, 2020, VISUAL COMPUT, V36, P1797, DOI 10.1007/s00371-019-01774-8
   Zhang XQ, 2020, IEEE T IND INFORM, V16, P532, DOI 10.1109/TII.2019.2926778
   Zhang XQ, 2013, PATTERN RECOGN, V46, P1750, DOI 10.1016/j.patcog.2012.08.015
   Zhang YD, 2019, MULTIMED TOOLS APPL, V78, P3613, DOI 10.1007/s11042-017-5243-3
   Zhao ZQ, 2020, MULTIMED TOOLS APPL, V79, P785, DOI 10.1007/s11042-019-08139-2
   Zhou H, 2016, INT C INTEL HUM MACH, P103, DOI 10.1109/IHMSC.2016.144
   Zhu Z, 2018, SPIE P, V10575
   Zhu Z, 2019, COMPUT BIOL MED, V109, P85, DOI 10.1016/j.compbiomed.2019.04.018
NR 52
TC 2
Z9 2
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13961
EP 13978
DI 10.1007/s11042-022-12036-6
EA FEB 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761979300015
DA 2024-07-18
ER

PT J
AU Bhargava, A
   Bansal, A
   Goyal, V
AF Bhargava, Anuja
   Bansal, Atul
   Goyal, Vishal
TI Machine learning-based automatic detection of novel coronavirus
   (COVID-19) disease
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Coronavirus; COVID-19; Statistical; Textural; Support
   vector machine
ID CLASSIFICATION
AB The pandemic was announced by the world health organization coronavirus (COVID-19) universal health dilemma. Any scientific appliance which contributes expeditious detection of coronavirus with a huge recognition rate may be excessively fruitful to doctors. In this environment, innovative automation like deep learning, machine learning, image processing and medical image like chest radiography (CXR), computed tomography (CT) has been refined promising solution contrary to COVID-19. Currently, a reverse transcription-polymerase chain reaction (RT-PCR) test has been used to detect the coronavirus. Due to the moratorium period is high on results tested and huge false negative estimates, substitute solutions are desired. Thus, an automated machine learning-based algorithm is proposed for the detection of COVID-19 and the grading of nine different datasets. This research impacts the grant of image processing and machine learning to expeditious and definite coronavirus detection using CXR and CT medical imaging. This results in early detection, diagnosis, and cure for the accomplishment of COVID-19 as early as possible. Firstly, images are preprocessed by normalization to enhance the quality of the image and removing of noise. Secondly, segmentation of images is done by fuzzy c-means clustering. Then various features namely, statistical, textural, histogram of gradients, and discrete wavelet transform are extracted (92) and selected from the feature vector by principle component analysis. Lastly, k-NN, SRC, ANN, and SVM are used to make decisions for normal, pneumonia, COVID-19 positive patients. The performance of the system has been validated by the k (5) fold cross-validation technique. The proposed algorithm achieves 91.70% (k-Nearest Neighbor), 94.40% (Sparse Representation Classifier), 96.16% (Artificial Neural Network), and 99.14% (Support Vector Machine) for COVID detection. The proposed results show feature combination and selection improves the performance in 14.34 s with machine learning and image processing techniques. Among k-NN, SRC, ANN, and SVM classifiers, SVM shows more efficient results that are promising and comparable with the literature. The proposed approach results in an improved recognition rate as compared to the literature review. Therefore, the algorithm proposed shows immense potential to benefit the radiologist for their findings. Also, fruitful in prior virus diagnosis and discriminate pneumonia between COVID-19 and other pandemics.
C1 [Bhargava, Anuja; Bansal, Atul; Goyal, Vishal] GLA Univ, Mathura, India.
C3 GLA University
RP Bhargava, A (corresponding author), GLA Univ, Mathura, India.
EM anuja1012@gmail.com; atul.bansal@gla.ac.in; vishal.goyal@gla.ac.in
RI BHARGAVA, ANUJA/AAP-5094-2021; Bansal, Atul/I-1823-2019; Goyal,
   Vishal/E-6998-2012
OI BHARGAVA, ANUJA/0000-0002-2387-2552; Bansal, Atul/0000-0002-8012-0349;
   Goyal, Vishal/0000-0001-7560-0607
CR Abbas A, 2021, APPL INTELL, V51, P854, DOI 10.1007/s10489-020-01829-7
   Abraham B, 2020, BIOCYBERN BIOMED ENG, V40, P1436, DOI 10.1016/j.bbe.2020.08.005
   Afshara P, 2020, COVID CAPS CAPSULE N
   Alom Z, 2020, COVID MTNET COVID 19, P1
   Altan A, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110071
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Ardakani AA, 2021, EUR RADIOL, V31, P121, DOI 10.1007/s00330-020-07087-y
   Ashok V, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P308, DOI 10.1109/IC3I.2014.7019807
   Aslan MF, 2021, APPL SOFT COMPUT, V98, DOI 10.1016/j.asoc.2020.106912
   Barstugan M, 2020, ARXIV200309424
   Bhargava A, 2021, MULTIMED TOOLS APPL, V80, P19931, DOI 10.1007/s11042-021-10714-5
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chowdhury MEH, 2020, IEEE ACCESS, V8, P132665, DOI 10.1109/ACCESS.2020.3010287
   Cicalese MAPA, 2020, RADIOLOGIST LEVEL CO, P1
   Dorj UO, 2017, COMPUT ELECTRON AGR, V140, P103, DOI 10.1016/j.compag.2017.05.019
   Farooq M., 2020, arXiv preprint arXiv:2003.14395
   Fellous JM, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.01346
   Ghoshal B., 2020, ARXIV200310769
   Gupta A, 2021, APPL SOFT COMPUT, V99, DOI 10.1016/j.asoc.2020.106859
   Hall JG, 2013, COMPUTER, V46, P85, DOI 10.1109/MC.2013.42
   Hemdan E. E.- D., 2020, . arXiv preprint arXiv:2003.11055
   Hu SP, 2020, IEEE ACCESS, V8, P118869, DOI 10.1109/ACCESS.2020.3005510
   Jaiswal A, 2021, J BIOMOL STRUCT DYN, V39, P5682, DOI 10.1080/07391102.2020.1788642
   Jiang XG, 2020, CMC-COMPUT MATER CON, V63, P537, DOI 10.32604/cmc.2020.010691
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Joseph P., 2003, ARXIV200311597
   Karakanis S, 2021, COMPUT BIOL MED, V130, DOI 10.1016/j.compbiomed.2020.104181
   Kassani PH, 2020, ARXIV PREPRINT ARXIV
   Khurana S, 2021, EMERG RADIOL, V28, P477, DOI 10.1007/s10140-020-01885-z
   Kusakunniran W, 2021, J MED IMAGING, V8, DOI 10.1117/1.JMI.8.S1.014001
   Li Q, 2020, NEW ENGL J MED, V382, P1199, DOI 10.1056/NEJMoa2001316
   Li YX, 2020, IEEE J BIOMED HEALTH, V24, P2787, DOI 10.1109/JBHI.2020.3018181
   LINDA W, 2020, J NETW COMPUT APPL
   Loey M, 2020, NEURAL COMPUT APPL, DOI 10.1007/s00521-020-05437-x
   Luz Eduardo JS, EFFECTIVE EFFICIENT, P1
   Maghdid HS, 2021, PROC SPIE, V11734, DOI 10.1117/12.2588672
   Mahmud MB, 2020, RADIOLOGY, V200988
   Minaee S, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101794
   Miotto R, 2018, BRIEF BIOINFORM, V19, P1236, DOI 10.1093/bib/bbx044
   Mooney P, 2020, Chest x-ray images (pneumonia)
   Narin A, 2021, PATTERN ANAL APPL, V24, P1207, DOI 10.1007/s10044-021-00984-y
   National Health Commission of the People's Republic of China, 2020, DIAGN PROT COVID 19
   Nour M, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106580
   Ou X, 2014, INT J PHARMACEUT, V460, P28, DOI 10.1016/j.ijpharm.2013.10.024
   Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792
   Pandemic AE, 2020, CORONAVIRUS DIS COVI
   Panwar H, 2020, CHAOS SOLITON FRACT, V138, DOI 10.1016/j.chaos.2020.109944
   Payne AB, 2013, COMPUT ELECTRON AGR, V91, P57, DOI 10.1016/j.compag.2012.11.009
   Pereira RM, 2020, COMPUT METH PROG BIO, V194, DOI 10.1016/j.cmpb.2020.105532
   Rajinikant V., 2020, APPL SCI
   S. I. S. o. M. a. I. Radiology, 2020, COVID 19 DATABASE
   Singh D, 2020, EUR J CLIN MICROBIOL, V39, P1379, DOI 10.1007/s10096-020-03901-z
   Soares E., 2020, medRxiv, V10, P1
   Sun L, 2020, IEEE J BIOMED HEALTH, V24, P2798, DOI 10.1109/JBHI.2020.3019505
   Tang L, 2020, RADIOL-CARDIOTHORAC, V2, DOI 10.1148/ryct.2020200044
   Tao Z, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/7653946
   Wang Linda, 2020, Sci Rep, V10, P19549, DOI 10.1038/s41598-020-76550-z
   Wang WL, 2020, JAMA-J AM MED ASSOC, V323, P1843, DOI 10.1001/jama.2020.3786
   Wen XH, 2013, ENVIRON MONIT ASSESS, V185, P4361, DOI 10.1007/s10661-012-2874-8
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu YH, 2021, IEEE T IMAGE PROCESS, V30, P3113, DOI 10.1109/TIP.2021.3058783
   Xu XW, 2020, ENGINEERING-PRC, V6, P1122, DOI 10.1016/j.eng.2020.04.010
   Yan Q, 2020, CARBON LETT, P1
   Zhao J., 2020, ARXIV PREPRINT ARXIV
   Zhou T, 2021, APPL SOFT COMPUT, V98, DOI 10.1016/j.asoc.2020.106885
NR 65
TC 11
Z9 11
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13731
EP 13750
DI 10.1007/s11042-022-12508-9
EA FEB 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000760059700004
PM 35221781
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Sharma, H
   Jalal, AS
AF Sharma, Himanshu
   Jalal, Anand Singh
TI Improving visual question answering by combining scene-text information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Natural language processing; Commonsense reasoning;
   World knowledge; Visual question answering (VQA)
ID ATTENTION
AB The text present in natural scenes contains semantic information about its surrounding environment. For example, the majority of questions asked by blind people related to images around them require understanding of text in the image. However, most of the existing Visual Question Answering (VQA) models do not consider the text present in an image. In this paper, the proposed model fuses the multiple inputs such as visual features, questions features and OCR tokens. Also, we have captured the relationship between OCR tokens and the objects in an image, which previous model fail to use. As compared to previous model on TextVQA dataset, the proposed model uses dynamic pointer networks based decoder to predict multi-word (OCR tokens and words from fixed vocabulary) answers instead of single-step classification task. OCR tokens are represented using location, appearance, phoc and fisher vectors features in addition to the FastText features used by previous model on TextVQA. A powerful descriptor is constructed by applying Fisher Vectors (FV) which is computed from PHOCs of the text present in images. This FV based feature representation is better than the feature representation based on word embeddings only, which are used by previous state-of-the-art models. Quantitative and qualitative experiments performed on popular benchmarks including TextVQA, ST-VQA and VQA 2.0 reveal the efficacy of proposed model. Our proposed VQA model attains 41.23% on TextVQA dataset, 40.98% on ST-VQA dataset and 74.98% overall accuracy on VQA 2.0 dataset. Results suggest that there is a significant gap between human accuracy and model accuracy on TextVQA and ST-VQA datasets compared to VQA 2.0, recommending the use of TextVQA and ST-VQA datasets for future research which can complement VQA 2.0.
C1 [Sharma, Himanshu; Jalal, Anand Singh] GLA Univ, Dept Comp Engn & Applicat, Mathura, India.
C3 GLA University
RP Sharma, H (corresponding author), GLA Univ, Dept Comp Engn & Applicat, Mathura, India.
EM himanshu.sharma@gla.ac.in; asjalal@gla.ac.in
OI Jalal, Anand/0000-0002-7469-6608
CR Almazán J, 2014, IEEE T PATTERN ANAL, V36, P2552, DOI 10.1109/TPAMI.2014.2339814
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   [Anonymous], 2009, Advances in neural information processing systems
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Ben Abacha A., 2020, PROC CLEF WORKING NO, P22
   Ben-younes H, 2017, IEEE I CONF COMP VIS, P2631, DOI 10.1109/ICCV.2017.285
   Biten AF, 2019, IEEE I CONF COMP VIS, P4290, DOI 10.1109/ICCV.2019.00439
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dey A.U., 2019, Pattern Recognition Letters, V149, P164, DOI DOI 10.1016/J.PATREC.2021.06.011
   Nguyen DK, 2018, PROC CVPR IEEE, P6087, DOI 10.1109/CVPR.2018.00637
   Farazi M, 2021, PATTERN RECOGN, V120, DOI 10.1016/j.patcog.2021.108106
   Friedman M, 1940, ANN MATH STAT, V11, P86, DOI 10.1214/aoms/1177731944
   Fukui Akira, 2016, P C EMP METH NAT LAN
   Gao H., 2015, INT C NEURAL INF PRO, P2296
   Gómez L, 2021, PATTERN RECOGN LETT, V150, P242, DOI 10.1016/j.patrec.2021.06.026
   Gómez L, 2018, LECT NOTES COMPUT SC, V11218, P728, DOI 10.1007/978-3-030-01264-9_43
   GREGOR J, 1969, BIOMETRICS, V25, P79, DOI 10.2307/2528680
   Guo D, 2021, IEEE T NEURAL NETWOR
   Guo DY, 2021, PROC CVPR IEEE, P9538, DOI 10.1109/CVPR46437.2021.00942
   Gurari D, 2018, PROC CVPR IEEE, P3608, DOI 10.1109/CVPR.2018.00380
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hosseinabad SH, 2021, VISUAL COMPUT, V37, P119, DOI 10.1007/s00371-019-01786-4
   Hu R., 2020, COMPUTER VISION ECCV, P742
   Hu Ronghang, 2020, 2020 IEEE CVF C COMP, P9992, DOI DOI 10.1109/CVPR42600.2020.01001
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Jiang Y., 2018, arXiv
   Kafle K, 2018, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2018.00592
   Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942
   Karatzas D, 2013, PROC INT CONF DOC, P1484, DOI 10.1109/ICDAR.2013.221
   Kazemi V., 2017, ARXIV170403162
   Kembhavi A, 2017, PROC CVPR IEEE, P5376, DOI 10.1109/CVPR.2017.571
   Kim JH., 2018, BILINEAR ATTENTION N, P1564
   King DB, 2015, ACS SYM SER, V1214, P1
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Liu Y, 2020, IEEE T NEURAL NETWOR
   Liu Y, 2020, KNOWL-BASED SYST, V207, DOI 10.1016/j.knosys.2020.106339
   Liu Y, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1013, DOI 10.1145/3269206.3271765
   Lobry S, 2020, IEEE T GEOSCI REMOTE, V58, P8555, DOI 10.1109/TGRS.2020.2988782
   Lu JS, 2016, ADV NEUR IN, V29
   Mafla A, 2020, IEEE WINT CONF APPL, P2939, DOI 10.1109/WACV45572.2020.9093373
   Malinowski M, 2017, INT J COMPUT VISION, V125, P110, DOI 10.1007/s11263-017-1038-2
   Marino K, 2019, PROC CVPR IEEE, P3190, DOI 10.1109/CVPR.2019.00331
   Mishra A., 2019, 2019 INT C DOC AN RE, P947, DOI DOI 10.1109/ICDAR.2019.00156
   Mishra A, 2013, IEEE I CONF COMP VIS, P3040, DOI 10.1109/ICCV.2013.378
   Noh H, 2019, PROC CVPR IEEE, P8377, DOI 10.1109/CVPR.2019.00858
   Paszke A., 2017, AUTOMATIC DIFFERENT
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Perronnin F, 2007, PROC CVPR IEEE, P2272
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sharma HS, 2021, PROG BRAIN RES, V265, P1, DOI 10.1016/bs.pbr.2021.04.008
   Sharma H, 2021, IMAGE VISION COMPUT, V116, DOI 10.1016/j.imavis.2021.104327
   Sharma H, 2022, MULTIMED TOOLS APPL, V81, P34775, DOI 10.1007/s11042-021-11276-2
   Sharma H, 2021, IMAGE VISION COMPUT, V110, DOI 10.1016/j.imavis.2021.104165
   Shrestha R, 2019, PROC CVPR IEEE, P10464, DOI 10.1109/CVPR.2019.01072
   Singh A., 2018, SYSML WORKSH 2018, P2019
   Singh AK, 2019, IEEE I CONF COMP VIS, P4601, DOI 10.1109/ICCV.2019.00470
   Singh A, 2019, PROC CVPR IEEE, P8309, DOI 10.1109/CVPR.2019.00851
   Singh Amanpreet, 2021, CVPR, P8802
   Sun B, 2020, J VIS COMMUN IMAGE R, V73, DOI 10.1016/j.jvcir.2020.102762
   Teney D, 2018, PROC CVPR IEEE, P4223, DOI 10.1109/CVPR.2018.00444
   Toor AS, 2019, PATTERN RECOGN LETT, V126, P111, DOI 10.1016/j.patrec.2018.02.013
   Vaswani A, 2017, ADV NEUR IN, V30
   Veit Andreas, 2016, Coco-text: Dataset and benchmark for text detection and recognition in natural images
   Vinyals O., 2015, Advances in neural information processing systems, P2692
   Wu Q, 2017, COMPUT VIS IMAGE UND, V163, P21, DOI 10.1016/j.cviu.2017.05.001
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yin XC, 2021, IEEE T MULTIMEDIA, V1
   Yu Z, 2018, IEEE T NEUR NET LEAR, V29, P5947, DOI 10.1109/TNNLS.2018.2817340
   Yu Z, 2019, PROC CVPR IEEE, P6274, DOI 10.1109/CVPR.2019.00644
   Zellers R, 2019, PROC CVPR IEEE, P6713, DOI 10.1109/CVPR.2019.00688
   Zhan HY, 2022, NEUROCOMPUTING, V467, P323, DOI 10.1016/j.neucom.2021.10.016
   Zhang S, 2021, INFORM FUSION, V73, P1, DOI 10.1016/j.inffus.2021.02.022
   Zhang WF, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106639
   Zhang WF, 2020, INFORM FUSION, V55, P116, DOI 10.1016/j.inffus.2019.08.009
NR 75
TC 6
Z9 8
U1 4
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12177
EP 12208
DI 10.1007/s11042-022-12317-0
EA FEB 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000758308400011
DA 2024-07-18
ER

PT J
AU Hussein, HI
   Dino, HI
   Mstafa, RJ
   Hassan, MM
AF Hussein, Haval I.
   Dino, Hivi Ismat
   Mstafa, Ramadhan J.
   Hassan, Masoud Muhammed
TI Person-independent facial expression recognition based on the fusion of
   HOG descriptor and cuttlefish algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cuttlefish algorithm; Histogram of oriented gradients; Facial expression
   recognition; Support vector machine
ID FEATURE-SELECTION; ORIENTED GRADIENTS; OPTIMIZATION; FEATURES
AB This paper proposes an efficient approach for person-independent facial expression recognition based on the fusion of Histogram of Oriented Gradients (HOG) descriptor and Cuttlefish Algorithm (CFA). The proposed approach employs HOG descriptor due to its outstanding performance in pattern recognition, which results in features that are robust against small local pose and illumination variations. However, it produces some irrelevant and noisy features that slow down and degrade the classification performance. To address this problem, a wrapper-based feature selector, called CFA, is used. This is because CFA is a recent bio-inspired feature selection algorithm, which has been shown to effectively select an optimal subset of features while achieving a high accuracy rate. Here, support vector machine classifier is used to evaluate the quality of the features selected by the CFA. Experimental results validated the effectiveness of the proposed approach in attaining a high recognition accuracy rate on three widely adopted datasets: CK+ (97.86%), RaFD (95.15%), and JAFFE (90.95%). Moreover, the results also indicated that the proposed approach yields competitive or even superior results compared to state-of-the-art approaches.
C1 [Hussein, Haval I.; Dino, Hivi Ismat; Mstafa, Ramadhan J.; Hassan, Masoud Muhammed] Univ Zakho, Dept Comp Sci, Fac Sci, Duhok 42002, Kurdistan Regio, Iraq.
   [Mstafa, Ramadhan J.] Nawroz Univ, Dept Comp Sci, Coll Sci, Duhok 42001, Kurdistan Regio, Iraq.
C3 University of Zakho; Nawroz University
RP Mstafa, RJ (corresponding author), Univ Zakho, Dept Comp Sci, Fac Sci, Duhok 42002, Kurdistan Regio, Iraq.; Mstafa, RJ (corresponding author), Nawroz Univ, Dept Comp Sci, Coll Sci, Duhok 42001, Kurdistan Regio, Iraq.
EM ramadhan.mstafa@uoz.edu.krd
RI Mstafa, Ramadhan J./G-4533-2015; Hassan, Masoud Muhammed/AAQ-8833-2021;
   Hussein, Haval/AAT-1521-2021
OI Mstafa, Ramadhan J./0000-0002-6122-234X; Hussein,
   Haval/0000-0001-8868-1792; Hassan, Masoud/0000-0003-3461-0942
CR Ahmed F, 2014, INT ARAB J INF TECHN, V11, P195
   An L, 2015, NEUROCOMPUTING, V149, P354, DOI 10.1016/j.neucom.2014.04.072
   [Anonymous], 2011, Handbook of face recognition
   [Anonymous], 2017, P INT C COMPUTER VIS, DOI DOI 10.1007/978-981-10-2107-719
   [Anonymous], 2017, 3 INT C ADV TECHN SI
   Bastanfard A, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P306, DOI 10.1109/CW.2004.65
   Bastanfard A, 2004, COMPUT ANIMAT VIRT W, V15, P347, DOI 10.1002/cav.38
   Bin Iqbal MT, 2022, IEEE T AFFECT COMPUT, V13, P1322, DOI 10.1109/TAFFC.2020.2995432
   Carcagnì P, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1427-3
   Chen Jingying., 2012, IEEE COMP SOC C COMP, P29, DOI [DOI 10.1109/CVPRW.2012.6238905, 10.1111/j.1601-183X.2012.00843.x]
   Dagher I, 2019, VIS COMPUT IND BIOME, V2, DOI 10.1186/s42492-019-0034-5
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Dapogny A, 2019, IEEE T AFFECT COMPUT, V10, P167, DOI 10.1109/TAFFC.2017.2708106
   Eesa AS, 2015, EXPERT SYST APPL, V42, P2670, DOI 10.1016/j.eswa.2014.11.009
   Eesa AdelSabry., 2013, International Journal of Scientific and Engineering Research, V4, P1978
   Ekundayo O, 2019, 2019 CONFERENCE ON INFORMATION COMMUNICATIONS TECHNOLOGY AND SOCIETY (ICTAS), DOI 10.1109/ictas.2019.8703619
   Gupta D, 2018, COGN SYST RES, V52, P36, DOI 10.1016/j.cogsys.2018.06.006
   Gupta N, 2019, MEASUREMENT, V140, P590, DOI 10.1016/j.measurement.2019.02.042
   Hassan MM, 2021, CMC-COMPUT MATER CON, V68, P1637, DOI 10.32604/cmc.2021.016467
   Hu M, 2019, IEEE ACCESS, V7, P118435, DOI 10.1109/ACCESS.2019.2936976
   Jin X, 2020, INT J MACH LEARN CYB, V11, P779, DOI 10.1007/s13042-019-01024-2
   Kas M, 2021, INFORM SCIENCES, V549, P200, DOI 10.1016/j.ins.2020.10.065
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   Li K, 2020, VISUAL COMPUT, V36, P391, DOI 10.1007/s00371-019-01627-4
   Li M, 2021, IEEE T AFFECT COMPUT, V12, P544, DOI 10.1109/TAFFC.2018.2880201
   Liu XF, 2019, PATTERN RECOGN, V88, P1, DOI 10.1016/j.patcog.2018.11.001
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Meena HK, 2021, IETE J RES, V67, P667, DOI 10.1080/03772063.2019.1565952
   Mlakar U, 2017, EXPERT SYST APPL, V89, P129, DOI 10.1016/j.eswa.2017.07.037
   Nigam S, 2018, MULTIMED TOOLS APPL, V77, P28725, DOI 10.1007/s11042-018-6040-3
   Ning X, 2023, CONCURR COMP-PRACT E, V35, DOI 10.1002/cpe.6147
   Ning X, 2020, J PHYS CONF SER, V1518, DOI 10.1088/1742-6596/1518/1/012031
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Rettkowski J, 2017, J PARALLEL DISTR COM, V109, P50, DOI 10.1016/j.jpdc.2017.05.005
   Revina IM, 2019, J VIS COMMUN IMAGE R, V62, P43, DOI 10.1016/j.jvcir.2019.04.013
   Revina IM, 2018, J KING SAUD U COMPUT
   Sahu B, 2012, PROCEDIA ENGINEER, V38, P27, DOI 10.1016/j.proeng.2012.06.005
   Salmam FZ, 2016, I C COMP GRAPH IM VI, P125, DOI 10.1109/CGiV.2016.33
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Vedantham R, 2020, MULTIMED TOOLS APPL, V79, P21487, DOI 10.1007/s11042-020-08901-x
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang FY, 2019, J VIS COMMUN IMAGE R, V59, P84, DOI 10.1016/j.jvcir.2018.11.010
   Wang H, 2020, J SUPERCOMPUT, V76, P3211, DOI 10.1007/s11227-018-2554-8
   Wei W, 2020, J MULTIMODAL USER IN, V14, P17, DOI 10.1007/s12193-019-00308-9
   Yan Y, 2020, SIGNAL PROCESS, V169, DOI 10.1016/j.sigpro.2019.107370
   Yang ZW, 2018, MULTIMED TOOLS APPL, V77, P3431, DOI 10.1007/s11042-017-5165-0
   Yolcu G, 2019, MULTIMED TOOLS APPL, V78, P31581, DOI 10.1007/s11042-019-07959-6
   Zeng NY, 2018, NEUROCOMPUTING, V273, P643, DOI 10.1016/j.neucom.2017.08.043
   Zheng H, 2020, INFORM SCIENCES, V533, P60, DOI 10.1016/j.ins.2020.04.041
NR 51
TC 11
Z9 11
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11563
EP 11586
DI 10.1007/s11042-022-12438-6
EA FEB 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757777400018
DA 2024-07-18
ER

PT J
AU Li, WW
   Lin, L
   Zhang, JX
   Shuai, L
   Qiu, JH
AF Wanwu, Li
   Lin, Liu
   Jixian, Zhang
   Shuai, Liu
   Jiahao, Qiu
TI Multi-core parallel architecture design and experiment for deep learning
   model training
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Model training; Multi-core parallel; Architecture design
ID BANDWIDTH
AB The parallel architecture can improve the training speed of Deep learning models and it is beneficial to model optimization. This research designs Optimal Interleaved Distributed Architecture (OIDA). Its characteristics are (1) the data set that each child node participates in training is fixed and unique; (2) multiple approaches ensure that the model parameters of each child node participating in training each time are always optimal; (3) the computing units of each child node are interleaved for training without stopping. The architecture can be deployed as Single Machine Parallel (SMP) or Multi Machine Distributed (MMD), or a combination of both. The experimental results show that its efficiency is obvious in a multi-machine multi-card environment, and the model speed of training millions of parameters in a 5-machine 10-card lightweight (Graphics Processing Unit (GPU) of 2GB memory) cluster can reach megapixels/s. When training the same amount of training data, GPU can process data faster than Central Processing Unit (CPU) with the same number of clusters. 4-machine 4-core GPU parallel saves 65.61% of time compared with 4-machine 4-core CPU parallel, while 4-machine 8-core GPU saves 83.32% of time compared with 4-machine 4-core CPU parallel. For polarized Synthetic Aperture Radar (SAR) Deep learning data sets, increasing the number of computers in the cluster can effectively save training time. In the experimental environment of this research, there is no situation that when the number of computers in the cluster increases due to network data transmission, the training time does not decrease.
C1 [Wanwu, Li; Lin, Liu; Shuai, Liu; Jiahao, Qiu] Shandong Univ Sci & Technol, Qingdao, Peoples R China.
   [Jixian, Zhang] Natl Qual Inspect & Testing Ctr Surveying & Mappi, Beijing 100830, Peoples R China.
C3 Shandong University of Science & Technology
RP Lin, L (corresponding author), Shandong Univ Sci & Technol, Qingdao, Peoples R China.
EM liulin2009@126.com
RI LIU, lin/GZB-2428-2022
OI liu, lin/0000-0002-6305-1548
FU Natural Science Foundation of Shandong Province [ZR 2019MD034]
FX The study was supported by the Natural Science Foundation of Shandong
   Province (NO. ZR 2019MD034).
CR Ahn S, 2018, INT CON DISTR COMP S, P1118, DOI 10.1109/ICDCS.2018.00111
   Aytekin A., ARXIV PREPRINT ARXIV, P2016
   Braham Y, 2020, J REAL-TIME IMAGE PR, V17, P527, DOI 10.1007/s11554-018-0804-x
   Chen YY, 2020, IEEE T INTELL TRANSP, V21, P1624, DOI 10.1109/TITS.2019.2910295
   Dean J, 2013, ADV NEURAL INF PROCE, P1
   Fang JR, 2019, J PARALLEL DISTR COM, V133, P30, DOI 10.1016/j.jpdc.2019.05.016
   Farkas A, 2020, IEEE INT CONF INTELL, P165, DOI [10.1109/ines49302.2020.9147123, 10.1109/INES49302.2020.9147123]
   Fukuda Keisuke, 2017, ABS171104325 CORR
   Goyal Priya, 2017, CoRR abs/1706.02677
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Jia Zhihao, 2018, abs/1804.06826
   Jin Peter H, 2016, ARXIV PREPRINT ARXIV
   Kang B, 2018, TENCON IEEE REGION, P1426, DOI 10.1109/TENCON.2018.8650104
   Kim Y, 2020, CLUSTER COMPUT, V23, P2287, DOI 10.1007/s10586-020-03144-9
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Patarasuk P, 2009, J PARALLEL DISTR COM, V69, P117, DOI 10.1016/j.jpdc.2008.09.002
   Seide F, 2014, INTERSPEECH, P1058
   Sermanet P., 2013, INT C LEARN REPR, DOI DOI 10.1016/J.VISRES.2006.11.009
   Shi GJ, 2021, SHIPS OFFSHORE STRUC, V16, P280, DOI 10.1080/17445302.2020.1724359
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun PJ, 2019, IEEE ACCESS, V7, P147420, DOI 10.1109/ACCESS.2019.2946185
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tomov S., 2020, IEEE INT PAR DISTR P, P1
   Ye DP, 2019, J REAL-TIME IMAGE PR, V16, P623, DOI 10.1007/s11554-019-00870-1
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang JH, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5923
   Zhang YN, 2020, IEEE T IND INFORM, V16, P7369, DOI 10.1109/TII.2020.2976053
   Zhu W, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2539
NR 28
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11587
EP 11604
DI 10.1007/s11042-022-12292-6
EA FEB 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757777400009
DA 2024-07-18
ER

PT J
AU Zheng, CJ
   Wang, CL
   Jia, N
AF Zheng, Chunjun
   Wang, Chunli
   Jia, Ning
TI A two-channel speech emotion recognition model based on raw stacked
   waveform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech emotion recognition; Stacked raw waveform; Acoustic feature;
   Two-channel joint technology; Convolutional recurrent neural network;
   Bi-directional long short-term memory
AB To improve the accuracy and efficiency of speech emotion recognition (SER), the acoustic feature set and speech emotion recognition model was designed based on the original speech signal, and explored the nonlinear relationship between acoustic features, the speech emotion recognition model, and the recognition task. Moreover, the original features of speech signals were studied rather than the traditional statistical features. A joint two-channel model was proposed based on the raw stacked waveform. To model raw waveform features, the convolutional recurrent neural network (CRNN) and bi-directional long short-term memory (BiLSTM) were introduced. An attention mechanism was integrated into the model to ensure that a single channel could learn the expression of the salient local region and global emotion features. Through these channels, the perception ability of speech acoustic features in multi-scale is improved, and the internal correlation between salient region and convolutional neural network is explored. The time domain and frequency domain features of speech are prominent, and the local expression of emotion is emphasized. Based on the preprocessing strategy of background separation and dimension unification, the convolutional recurrent neural network is used to extract global information. The proposed joint model could effectively integrate the advantages of the two channels. Several comparative experiments were conducted on the Interactive Emotional Dyadic Motion Capture (IEMOCAP) database. The experiments results showed that the proposed two-channel SER model could improve recognition accuracy (UA) by 5.1% and the convergence period was shortened by 58%, compared with the popular models. Furthermore, it performed best in solving data skew and improving efficiency, which proved the importance of having features and models based on the raw waveform.
C1 [Zheng, Chunjun; Wang, Chunli] Dalian Maritime Univ, Coll Informat Sci & Technol, Dalian, Liaoning, Peoples R China.
   [Zheng, Chunjun; Jia, Ning] Dalian Neusoft Univ Informat, Sch Software, Dalian, Liaoning, Peoples R China.
C3 Dalian Maritime University
RP Zheng, CJ (corresponding author), Dalian Maritime Univ, Coll Informat Sci & Technol, Dalian, Liaoning, Peoples R China.; Zheng, CJ (corresponding author), Dalian Neusoft Univ Informat, Sch Software, Dalian, Liaoning, Peoples R China.
EM Zheng1711zz@126.com
FU Liaoning provincial Department of Education [86896244]; National Natural
   Science Foundation of China [61,370,070, 61,976,032, r 61,976,124,
   61370070]; Dalian science and technology project [2019RQ120]
FX This work was supported in part by the intercollegiate cooperation
   projects of Liaoning provincial Department of Education, grant number
   86896244; the National Natural Science Foundation of China, grant number
   (61,370,070, 61,976,032, r 61,976,124). Dalian science and technology
   project, grant number 2019RQ120; the National Natural Science Foundation
   of China, grant number 61370070
CR Aldeneh Z, 2017, IEEE INT C AC
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Bandela SR, 2017, INT CONF COMPUT
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Cho J, 2018, INTERSPEECH, P247, DOI 10.21437/Interspeech.2018-2466
   Chunjun Z, 2019, ADV DATA MINING APPL
   Cummins N., 2018, SHAHIN AMIRIPARIAN
   Dai DY, 2019, INT CONF ACOUST SPEE, P7405, DOI [10.1109/icassp.2019.8683765, 10.1109/ICASSP.2019.8683765]
   Eyben F, 2016, IEEE T AFFECT COMPUT, V7, P190, DOI 10.1109/TAFFC.2015.2457417
   Gideon J, 2021, IEEE T AFFECT COMPUT, V12, P1055, DOI [10.1109/TAFFC.2019.2916092, 10.1109/taffc.2019.2916092]
   Han WJ, 2018, INTERSPEECH, P932, DOI 10.21437/Interspeech.2018-1858
   Hsiao PW, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2526, DOI 10.1109/ICASSP.2018.8461431
   Huang CW, 2017, IEEE INT CON MULTI, P583, DOI 10.1109/ICME.2017.8019296
   Jassim WA, 2017, IET SIGNAL PROCESS, V11, P587, DOI 10.1049/iet-spr.2016.0336
   Jiang L, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5427
   Juvela L, 2019, IEEE-ACM T AUDIO SPE, V27, P1019, DOI 10.1109/TASLP.2019.2906484
   Kim E, 2019, INT CONF ACOUST SPEE, P6720, DOI 10.1109/ICASSP.2019.8683077
   Latif S, 2019, INTERSPEECH, P3920, DOI 10.21437/Interspeech.2019-3252
   Lee J, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1537
   Li YC, 2019, INTERSPEECH, P2803, DOI 10.21437/Interspeech.2019-2594
   Liu S, 2020, MULTITARGET EMOTIONA
   Liu ZT, 2018, NEUROCOMPUTING, V309, P145, DOI 10.1016/j.neucom.2018.05.005
   Ma X, 2018, INTERSPEECH, P3683, DOI 10.21437/Interspeech.2018-2228
   Mao QR, 2014, IEEE T MULTIMEDIA, V16, P2203, DOI 10.1109/TMM.2014.2360798
   Ming-hao YANG., 2014, COMPU SCI, V41, P12
   Oord A., 2016, ARXIV160903499
   Pandey SK, 2019, IEEE TENCON 2019
   Parry J, 2019, INTERSPEECH, P1656, DOI 10.21437/Interspeech.2019-2753
   Rajasekhar B, 2019, EVOL INTEL, V1
   Ramanarayanan V, 2019, AUTOMATIC TURN LEVEL
   Ran Jincheng, 2019, COMPOSITES B
   Sarma M, 2018, INTERSPEECH, P3097, DOI 10.21437/Interspeech.2018-1353
   Schuller B, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P336
   Tzirakis P., 2018, ICASSP
   Wang Wei, 2013, Research and Exploration in Laboratory, V32, P91
   Wang ZQ, 2017, INT CONF ACOUST SPEE, P5150, DOI 10.1109/ICASSP.2017.7953138
   Yenigalla P, 2018, INTERSPEECH, P3688, DOI 10.21437/Interspeech.2018-1811
   Zhao JF, 2019, BIOMED SIGNAL PROCES, V47, P312, DOI 10.1016/j.bspc.2018.08.035
   Zhao ZP, 2018, INTERSPEECH, P272, DOI 10.21437/Interspeech.2018-1477
NR 40
TC 1
Z9 1
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11537
EP 11562
DI 10.1007/s11042-022-12378-1
EA FEB 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757777400017
DA 2024-07-18
ER

PT J
AU Du, HS
   Liu, JF
   Tian, YG
   Luo, XY
AF Du, Hansong
   Liu, Jiufen
   Tian, Yuguo
   Luo, Xiangyang
TI Steganographic key recovery for adaptive steganography under
   "known-message attacks"
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Syndrome-Trellis Codes; Secret message extraction; Basic row vector;
   Known-message attack
ID STEGO KEY
AB Since the performance of STC (Syndrome-Trellis Codes) is approaching the theoretical optimum in minimizing embedded distortion, STC-based adaptive steganography has become the focus of forward improvement and the difficulty of reverse analysis of steganography algorithms. At present, the researches on secret message extraction from STC-based adaptive steganography are mainly focused on the scenario where the secret message is plaintext and part of the plaintext format information is known, while it needs to be studied when these characteristics are unknown. Analogous to the "known-plaintext attack" in cryptanalysis, this manuscript proposes a steganographic key recovery algorithm under the condition of "known-message attack". Firstly, by studying the structure characteristics of STC parity-check matrix, the concept of basic row vector is proposed, and the problem of secret message extraction attack is transformed into the problem of solving the basic row vectors. Then, the existence of bit string with special structure in the differential sequences of stego sequences is proved. Finally, using the distribution characteristics of the special bit strings in the differential sequence, the problem of solving the basic row vectors is transformed into the problem of solving the simple linear equation system through the differential analysis, and good code judgment criteria is used to filter out the correct steganographic key. The research results of this manuscript can realize the secret message extraction attack when the secret message is ciphertext, which is expected to solve the application requirements of actual scenarios. At the same time, the experimental results also show that, based on the algorithm proposed in this manuscript, only a PC can be used to extract secret message from the common STC-based adaptive steganography algorithm.
C1 [Du, Hansong; Liu, Jiufen; Tian, Yuguo; Luo, Xiangyang] State Key Lab Math Engn & Adv Comp, Zhengzhou 450001, Peoples R China.
C3 PLA Information Engineering University
RP Luo, XY (corresponding author), State Key Lab Math Engn & Adv Comp, Zhengzhou 450001, Peoples R China.
EM luoxy_ieu@sina.com
FU National Natural Science Founddation of China [U1736214, U1636219,
   61602508, 61772549]; National Key R&D Program of China [2016-
   YFB0801303,2016QY01W0105]; Plan for Scientific Innovation Talent of
   Henan Province [184200510018]
FX This work was supported by the National Natural Science Founddation of
   China (No.U1804263, U1736214, U1636219, 61602508, and 61772549), the
   National Key R&D Program of China (No.2016- YFB0801303,2016QY01W0105)
   and the Plan for Scientific Innovation Talent of Henan Province (No.
   184200510018).
CR Abdulla, 2013, P 1 ACM WORKSH INF H, V12, P45
   Abdulla AA, 2014, LECT NOTES COMPUT SC, V8893, P151, DOI 10.1007/978-3-319-14054-4_10
   [Anonymous], 2014, Signal and Information Processing Association Annual Summit and Conference (APSIPA), 2014 Asia-Pacific, DOI [10.1109/APSIPA.2014, 10.1109/APSIPA.2014.7041565]
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Chen BL, 2019, IH&MMSEC '19: PROCEEDINGS OF THE ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P63, DOI 10.1145/3335203.3335716
   Chen JY, 2013, INT J COMPUT INT SYS, V6, P639, DOI 10.1080/18756891.2013.802116
   Denemark T, 2017, IEEE T INF FOREN SEC, V12, P2308, DOI 10.1109/TIFS.2017.2705625
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Fridrich J, 2005, PROC SPIE, V5681, P631, DOI 10.1117/12.585987
   Fridrich J, 2005, IEEE T SIGNAL PROCES, V53, P3923, DOI 10.1109/TSP.2005.855393
   Fridrich J, 2004, PROC SPIE, V5306, P70, DOI 10.1117/12.521353
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gan JJ, 2018, MULTIMED TOOLS APPL, V77, P18007, DOI 10.1007/s11042-017-5134-7
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Ker A.D., 2013, P 1 ACM WORKSH INF H, P4558, DOI DOI 10.1145/2482513.2482965
   Kim J, 2020, MULTIMED TOOLS APPL, V79, P1355, DOI 10.1007/s11042-019-08251-3
   Kim Y, 2007, LECT NOTES COMPUT SC, V4437, P314
   Kodovsky J, 2013, P SPIE EL IM MED WAT, V8665
   Kodovsky J, 2012, PROC SPIE, V8303, DOI 10.1117/12.907495
   Kodovsky J, 2011, PROC SPIE, V7880, DOI 10.1117/12.872279
   Li, 2020, P INT C SEC PRIV DIG, P560
   Liu JF, 2019, J REAL-TIME IMAGE PR, V16, P649, DOI 10.1007/s11554-018-0805-9
   Liu J, 2016, SCI CHINA INFORM SCI, V59, DOI 10.1007/s11432-016-5526-8
   Liu QY, 2020, MULTIMED TOOLS APPL, V79, P32935, DOI 10.1007/s11042-020-09613-y
   Luo XY, 2016, MULTIMED TOOLS APPL, V75, P13557, DOI 10.1007/s11042-015-2759-2
   Muselli M, 1996, STAT PROBABIL LETT, V31, P121, DOI 10.1016/S0167-7152(96)00022-3
   Pan HK, 2000, IEEE SYMP COMP COMMU, P750, DOI 10.1109/ISCC.2000.860731
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Song, 2017, ELECTRO INF WARFARE, V32, P70
   Su AT, 2020, IEEE SIGNAL PROC LET, V27, P221, DOI 10.1109/LSP.2020.2964485
   Tan SQ, 2021, IEEE T INF FOREN SEC, V16, P131, DOI 10.1109/TIFS.2020.3005304
   Weiwei Liu, 2014, ICIC Express Letters, V8, P2901
   Xu C, 2018, MULTIMED TOOLS APPL, V77, P17973, DOI 10.1007/s11042-017-4878-4
   You WK, 2021, IEEE T INF FOREN SEC, V16, P291, DOI 10.1109/TIFS.2020.3013204
   Yousfi Y, 2020, IEEE SIGNAL PROC LET, V27, P830, DOI 10.1109/LSP.2020.2993959
   Zeng JS, 2019, IEEE T INF FOREN SEC, V14, P2735, DOI 10.1109/TIFS.2019.2904413
   Zhang, 2007, CHINESE J ELECTRON, V35, P2258
   Zhang R, 2020, IEEE T INF FOREN SEC, V15, P1138, DOI 10.1109/TIFS.2019.2936913
   Zhang Y, 2021, INFORM SCIENCES, V564, P306, DOI 10.1016/j.ins.2021.02.058
   Zhu LY, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.108015
NR 41
TC 1
Z9 1
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 10981
EP 11004
DI 10.1007/s11042-022-12109-6
EA FEB 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757200200011
DA 2024-07-18
ER

PT J
AU Alqudah, AM
   Alqudah, A
AF Alqudah, Ali Mohammad
   Alqudah, Amin
TI Improving machine learning recognition of colorectal cancer using 3D
   GLCM applied to different color spaces
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D co-occurrence Matrix; Classification; Colorectal cancer; Colored
   features
ID CLASSIFICATION
AB Colorectal cancer (CRC) is one of the widely happening cancers among men and women. This cancer, which is also known as bowel cancer, affects the human large intestine, especially the rectum or colon. Therefore, providing new techniques with high accuracy to detect CRC cancer leads to providing an early and successful plan to treat it. In this research, we proposed a method to classify colorectal cancer using different machine learning algorithms. The method uses extracted features from 3D Gray Level Cooccurrence Matrix (GLCM) matrices of three different color spaces namely RGB, HSV, and L*A*B colors spaces. The 3D GLCM matrices of the used images were calculated and evaluated using a training dataset of 3504 images and a testing dataset of 1496 images. The five different widely used machine learning algorithms, which are Support Vector Machine (SVM), Artificial Neural Network (ANN), K-Nearest Neighbor (KNN), Quadratic Discriminant Analysis (QDA), and Classification Decision Tree (CDT). The results show that the proposed methodology can detect CRC with a high-performance rate. This higher rate is due to combining texture features from all color space channels. The best performance rate for the used machine learning models was greater than 97% for the training and testing sets using QDA using RG. The obtained results show that the proposed methodology can be used efficiently to detect CRC with high performance compared to all previous methods since texture features from the three color space channels. This research represents the first of its kind in the current research trend.
C1 [Alqudah, Ali Mohammad] Yarmouk Univ, Dept Biomed Syst & Informat Engn, Irbid, Jordan.
   [Alqudah, Amin] Yarmouk Univ, Dept Comp Engn, Irbid, Jordan.
C3 Yarmouk University; Yarmouk University
RP Alqudah, AM (corresponding author), Yarmouk Univ, Dept Biomed Syst & Informat Engn, Irbid, Jordan.
EM ali_qudah@hotmail.com
RI Alqudah, Prof. Amin/HTM-7970-2023; Alqudah, Ali Mohammad/A-1390-2017
OI Alqudah, Prof. Amin/0000-0002-2538-3402; Alqudah, Ali
   Mohammad/0000-0002-5417-0043
CR Ahmad M. Y., 2012, 2012 Proceedings of International Conference on Computer & Information Science (ICCIS 2012), P275, DOI 10.1109/ICCISci.2012.6297253
   Alkan A, 2012, EXPERT SYST APPL, V39, P44, DOI 10.1016/j.eswa.2011.06.043
   Alqudah A.M., 2020, IJATCSE, DOI [DOI 10.30534/IJATCSE/2019/155862019, 10.30534/ijatcse/2019/155862019]
   Alqudah Ali Mohammad, 2019, Journal of Medical Engineering & Technology, V43, P418, DOI 10.1080/03091902.2019.1688408
   Alqudah AM, 2020, MED BIOL ENG COMPUT, V58, P41, DOI 10.1007/s11517-019-02066-y
   Alqudah AM, 2019, BIOMED ENG-APP BAS C, V31, DOI 10.4015/S1016237219500078
   Alqudah AM, 2018, J BIOMIM BIOMATER BI, V39, P40, DOI 10.4028/www.scientific.net/JBBBE.39.40
   Alqudah AM., 2018, J ENG SCI TECHNOL RE, V11, P7, DOI [10.25103/jestr.116.02, DOI 10.25103/JESTR.116.02]
   Alqudah A, 2022, IETE J RES, V68, P59, DOI 10.1080/03772063.2019.1583610
   Alqudaht AM, 2019, J BIOMIM BIOMATER BI, V42, P67, DOI 10.4028/www.scientific.net/JBBBE.42.67
   Alquran H, 2019, NEURAL NETW WORLD, V29, P207, DOI 10.14311/NNW.2019.29.014
   [Anonymous], 2018, WHO | Cancer
   Ben Othmen Elmoez, 2013, 2013 3rd International Conference on Systems and Control (ICSC), P833, DOI 10.1109/ICoSC.2013.6750953
   Bychkov D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21758-3
   Cascianelli S, 2018, P INT C INT INT MULT, P21, DOI DOI 10.1007/978-3-319-59480-4_3
   Chaddad A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0149893
   Chen WS, 2009, LECT NOTES COMPUT SC, V5558, P1122, DOI 10.1007/978-3-642-01793-3_113
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185162
   Damkliang K, 2021, BIOMED ENG-APP BAS C, V33, DOI 10.4015/S1016237221500228
   Garcia-Lamont F, 2018, NEUROCOMPUTING, V292, P1, DOI 10.1016/j.neucom.2018.01.091
   Gonzalez R.C., 2018, DIGITAL IMAGE PROCES, V4th
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Ijaz MF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102809
   Ijaz MF, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8081325
   Ioanovici A-C., 2017, J INTERDISCIP MED, V2, P245, DOI [10.1515/jim-2017-0057, DOI 10.1515/JIM-2017-0057]
   Johnson RD, 1996, SEMIN ROENTGENOL, V31, P94, DOI 10.1016/S0037-198X(96)80003-4
   Kather JN, 2019, PLOS MED, V16, DOI 10.1371/journal.pmed.1002730
   Kather JN, 2016, SCI REP-UK, V6, DOI 10.1038/srep27988
   Kurani AS, 2004, Proceedings of the Seventh IASTED International Conference on Computer Graphics and Imaging, P447
   Liang M., 2012, 3D co-occurrence matrix based texture analysis applied to cervical cancer screening
   Loh WY, 1997, STAT SINICA, V7, P815
   Maguolo G., 2019, ARXIV PREPRINT ARXIV
   Malik J., 2019, ARXIV PREPRINT ARXIV
   Nanni L, 2015, EXPERT SYST APPL, V42, P8989, DOI 10.1016/j.eswa.2015.07.055
   Nanni L, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0083554
   Ohata EF, 2021, J SUPERCOMPUT, V77, P9494, DOI 10.1007/s11227-020-03575-6
   Paladini E, 2021, J IMAGING, V7, DOI 10.3390/jimaging7030051
   Porebski A, 2008, 2008 FIRST INTERNATIONAL WORKSHOPS ON IMAGE PROCESSING THEORY, TOOLS AND APPLICATIONS (IPTA), P206
   Rathore S, 2014, COMPUT BIOL MED, V47, P76, DOI 10.1016/j.compbiomed.2013.12.010
   Sarwinda D, 2021, PROCEDIA COMPUT SCI, V179, P423, DOI 10.1016/j.procs.2021.01.025
   Sengar N, 2016, 2016 39TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P529, DOI 10.1109/TSP.2016.7760936
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Tsai, 2019, PACIS 2019 P, P66
   Vidhya S, 2021, ANN ROMANIAN SOC CEL, P4002
   WCRF, 2018, COL CANC STAT COL CA
   Yoshida H, 2017, ONCOTARGET, V8, P90719, DOI 10.18632/oncotarget.21819
   Zayed N, 2015, INT J BIOMED IMAGING, V2015, DOI 10.1155/2015/267807
NR 48
TC 23
Z9 24
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 10839
EP 10860
DI 10.1007/s11042-022-11946-9
EA FEB 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000756332700018
DA 2024-07-18
ER

PT J
AU Hasan, MM
   Hossain, MM
   Mia, S
   Ahammad, MS
   Rahman, MM
AF Hasan, Md Mahmodul
   Hossain, Muhammad Minoar
   Mia, Shisir
   Ahammad, Mohd Sultan
   Rahman, Mohammad Motiur
TI A combined approach of non-subsampled contourlet transform and
   convolutional neural network to detect gastrointestinal polyp
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Gastrointestinal polyp detection; Convolutional neural network; NSCT;
   Feature reduction; Polyp detection; Multi-criteria decision making
AB The abnormal growth of tissues that disarray the typical organization of cells is popularly known as polyps. The polyp on the gastrointestinal is a primary sign of gastrointestinal cancer. False diagnosis is extremely high using traditional diagnosis procedures that make the polyp diagnosis is a crucial task in real-time colonoscopy. We have developed a polyp detection methodology using a combination of hand-crafted and automated feature extraction techniques. In this study, we have experimented with different convolutional neural network (CNN) architectures and hand-crafted feature extractors to select the best combination. The combined approach of the fine-tuned Xception model with non-subsampled contourlet transform (NSCT) performed significantly well. Besides, we have applied the multi-criteria frame selection technique for selecting the best images from colonoscopy videos. Afterward, the feature extractors have worked on enhanced patch images of selected frames. This study has also experimented with dimensionality reduction techniques to remove irrelevant features from the combined feature vector. We designed an algorithm to localize the polyp regions using the outcomes of patch images. The method did significantly well on several available public datasets. This work might be helpful for the endoscopist during real-time endoscopy to detect polyps.
C1 [Hasan, Md Mahmodul; Hossain, Muhammad Minoar; Mia, Shisir; Ahammad, Mohd Sultan; Rahman, Mohammad Motiur] Mawlana Bhashani Sci & Technol Univ, Dept Comp Sci & Engn, Tangail 1902, Bangladesh.
C3 Mawlana Bhashani Science & Technology University
RP Rahman, MM (corresponding author), Mawlana Bhashani Sci & Technol Univ, Dept Comp Sci & Engn, Tangail 1902, Bangladesh.
EM mahmodul.mbstu@gmail.com; minoarhossain16005@gmail.com;
   shisircse31@yahoo.com; sultan.ahammad36@gmail.com; motiurcse@mbstu.ac.bd
RI Rahman, Mohammad Motiur/AAR-2994-2020
OI Rahman, Mohammad Motiur/0000-0003-4417-8276; Ahammad,
   Sultan/0000-0003-1376-220X
CR Ali HA, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101897
   Bernal J, 2017, IEEE T MED IMAGING, V36, P1231, DOI 10.1109/TMI.2017.2664042
   Bhatnagar G, 2013, IEEE T MULTIMEDIA, V15, P1014, DOI 10.1109/TMM.2013.2244870
   Billah M, 2020, MULTIMED TOOLS APPL, V79, P23633, DOI 10.1007/s11042-020-09151-7
   Billah M, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9545920
   Brandao P, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254361
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143903
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Das TK, 2020, J BIOMIM BIOMATER BI, V45, P57, DOI 10.4028/www.scientific.net/JBBBE.45.57
   Deeba F, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.04.007
   Gopalakrishnan K, 2017, CONSTR BUILD MATER, V157, P322, DOI 10.1016/j.conbuildmat.2017.09.110
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hasan MM, 2022, J KING SAUD UNIV-COM, V34, P526, DOI 10.1016/j.jksuci.2019.12.013
   Hu YF, 2016, IEEE T MED IMAGING, V35, P1522, DOI 10.1109/TMI.2016.2518958
   Kang J, 2019, IEEE ACCESS, V7, P26440, DOI 10.1109/ACCESS.2019.2900672
   Lee JY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-65387-1
   Ma C, 2019, AM J GASTROENTEROL, V114, P1802, DOI 10.14309/ajg.0000000000000407
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   Mesejo P, 2016, IEEE T MED IMAGING, V35, P2051, DOI 10.1109/TMI.2016.2547947
   Ning X, 2021, IEEE T CIRC SYST VID, V31, P3391, DOI 10.1109/TCSVT.2020.3043026
   Ning X, 2020, IEEE SIGNAL PROC LET, V27, P1944, DOI 10.1109/LSP.2020.3032277
   Patino-Barrientos S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020501
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Shin Y, 2018, IEEE ACCESS, V6, P40950, DOI 10.1109/ACCESS.2018.2856402
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Song MY, 2020, LANCET GASTROENTEROL, V5, P537, DOI 10.1016/S2468-1253(20)30009-1
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Urban G, 2018, GASTROENTEROLOGY, V155, P1069, DOI 10.1053/j.gastro.2018.06.037
   van der Maaten L., 2009, J Mach Learn Res, V10, P7
   Wang P, 2019, GUT, V68, P1813, DOI 10.1136/gutjnl-2018-317500
   Wimmer G, 2016, INT C PATT RECOG, P2150, DOI 10.1109/ICPR.2016.7899954
   Yu LQ, 2017, IEEE J BIOMED HEALTH, V21, P65, DOI 10.1109/JBHI.2016.2637004
NR 35
TC 6
Z9 6
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 FEB 14
PY 2022
DI 10.1007/s11042-022-12250-2
EA FEB 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZA9TO
UT WOS:000756497800010
DA 2024-07-18
ER

PT J
AU Yang, G
   Zou, WX
AF Yang, Ge
   Zou, Wu-xing
TI Deep learning network model based on fusion of spatiotemporal features
   for action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Deep learning; CNN; LSTM
AB In view of the problem that the current deep learning network does not fully extract and fuse spatio-temporal information in the action recognition task, resulting in low recognition accuracy, this paper proposes a deep learning network model based on fusion of spatio-temporal features (FSTFN). Through two networks composed of CNN (Convolutional Neural Networks) and LSTM (Long Short-Term Memory), the time and space information are extracted and fused; multi-segment input is used to process large-scale video frame information to solve the problem of long-term dependence and improve the prediction accuracy; The attention mechanism improves the weight of visual subjects in the network. The experimental verification on the UCF101 (University of Central Florida 101) data set shows that the prediction accuracy of the proposed FSFTN on the UCF101 data set is 92.7%, 4.7% higher than that of Two-stream, which verifies the effectiveness of the network model.
C1 [Yang, Ge; Zou, Wu-xing] Beijing Normal Univ, Key Lab Intelligent Multimedia Technol, Zhuhai 519087, Peoples R China.
   [Yang, Ge; Zou, Wu-xing] Beijing Normal Univ Zhuhai, Adv Inst Nat Sci, Zhuhai 519087, Peoples R China.
   [Yang, Ge] Peking Univ, Shenzhen Grad Sch, Engn Lab Intelligent Percept Internet Things ELIP, Shenzhen 518055, Peoples R China.
C3 Beijing Normal University; Beijing Normal University; Beijing Normal
   University Zhuhai; Peking University
RP Yang, G (corresponding author), Beijing Normal Univ, Key Lab Intelligent Multimedia Technol, Zhuhai 519087, Peoples R China.; Yang, G (corresponding author), Beijing Normal Univ Zhuhai, Adv Inst Nat Sci, Zhuhai 519087, Peoples R China.; Yang, G (corresponding author), Peking Univ, Shenzhen Grad Sch, Engn Lab Intelligent Percept Internet Things ELIP, Shenzhen 518055, Peoples R China.
EM yangge@pkusz.edu.cn
FU Major Scientific Research Project for Universities of Guangdong Province
   [2018KTSCX288, 2019KZDXM015, 2020ZDZX3058]; Guangdong Provincial special
   funds Project for Discipline Construction [2013WYXM0122]; Guangdong
   Provincial College Innovation and Entrepreneurship Project
   [S201913177027, S201913177040, 201813177028, 201813177046]; Scientific
   Research Project of Shenzhen [JCYJ20170303140803747]; Key Laboratory of
   Intelligent Multimedia Technology [201762005]
FX This research was financially supported by Major Scientific Research
   Project for Universities of Guangdong Province (2018KTSCX288,
   2019KZDXM015, 2020ZDZX3058); Guangdong Provincial special funds Project
   for Discipline Construction (No.2013WYXM0122); Guangdong Provincial
   College Innovation and Entrepreneurship Project (S201913177027,
   S201913177040, 201813177028, 201813177046); Scientific Research Project
   of Shenzhen (JCYJ20170303140803747); Key Laboratory of Intelligent
   Multimedia Technology(201762005).
CR Ben Tanfous A, 2020, IEEE T PATTERN ANAL, V42, P2594, DOI 10.1109/TPAMI.2019.2932979
   Chen K, 2017, P 30 INT WORKSH QUAL, P55
   Cooijmans T, 2016, INT C LEARN REPR, P1
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fan M, 2018, PROCEEDINGS OF 2018 IEEE 7TH DATA DRIVEN CONTROL AND LEARNING SYSTEMS CONFERENCE (DDCLS), P1033, DOI 10.1109/DDCLS.2018.8515970
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   da Silva BCG, 2019, MULTIDIM SYST SIGN P, V30, P815, DOI 10.1007/s11045-018-0581-5
   Han PY, 2018, PROCEEDINGS OF 2018 VII INTERNATIONAL CONFERENCE ON NETWORK, COMMUNICATION AND COMPUTING (ICNCC 2018), P261, DOI 10.1145/3301326.3301338
   Hao YL, 2018, IEEE I C NETW INFRAS, P334, DOI 10.1109/ICNIDC.2018.8525732
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Jain A., 2019, IITM J MANAG IT, V10, P34
   Jiang BY, 2019, IEEE I CONF COMP VIS, P2000, DOI 10.1109/ICCV.2019.00209
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuehne H, 2013, HIGH PERFORMANCE COMPUTING IN SCIENCE AND ENGINEERING '12: TRANSACTIONS OF THE HIGH PERFORMANCE COMPUTING CENTER, STUTTGART (HLRS) 2012, P571, DOI 10.1007/978-3-642-33374-3_41
   Li J, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107037
   Meng ZL, 2019, INT SOC DESIGN CONF, P77, DOI [10.1109/isocc47750.2019.9027696, 10.1109/ISOCC47750.2019.9027696]
   Nazir S, 2018, COMPUT ELECTR ENG, V72, P660, DOI 10.1016/j.compeleceng.2018.01.037
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Pavithra S, 2020, SCALABLE COMPUT-PRAC, V21, P93, DOI 10.12694/scpe.v21i1.1625
   Ragupathy P, 2021, J AMB INTEL HUM COMP, V12, P3601, DOI 10.1007/s12652-019-01607-5
   Sharma S, 2015, NEURAL INFORM PROCES, P1212
   Simonyan K, 2014, ADV NEUR IN, V27
   Soomro K., 2012, ARXIV12120402CS
   Sun B, 2019, MULTIMED TOOLS APPL, V78, P6329, DOI 10.1007/s11042-018-6370-1
   Tang YS, 2018, PROC CVPR IEEE, P5323, DOI 10.1109/CVPR.2018.00558
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang XJ, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2051, DOI 10.1145/3097983.3098096
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yao KB, 2018, IEEE ACCESS, V6, P54147, DOI 10.1109/ACCESS.2018.2871733
   Yu Y, 2019, NEURAL COMPUT, V31, P1235, DOI 10.1162/neco_a_01199
   Zhang ZJ, 2018, 2018 IEEE/ACM 26TH INTERNATIONAL SYMPOSIUM ON QUALITY OF SERVICE (IWQOS), DOI 10.1109/IWQoS.2018.8624183
NR 35
TC 8
Z9 8
U1 6
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9875
EP 9896
DI 10.1007/s11042-022-11937-w
EA FEB 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000754491300001
DA 2024-07-18
ER

PT J
AU Salmi, A
   Benierbah, S
   Ghazi, M
AF Salmi, Abderrahmane
   Benierbah, Said
   Ghazi, Mehdi
TI Low complexity image enhancement GAN-based algorithm for improving
   low-resolution image crop disease recognition and diagnosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image analysis; Smart agriculture; Plant diseases; Super-resolution;
   Diseases classification
AB Image analysis plays a crucial role in many real-world applications such as smart agriculture. For plant diseases diagnosis, one of the most recent challenges is the improvement of the plant diseases classification on Low-Resolution (LR) images. The farmer is supposed to obtain High-Resolution (HR) images of plant leaves from the field. Because of the small size of plant leaves and other limitations, the obtained HR images can miss some detailed information that results in blurred LR images of leaves with fewer details. In this paper, we introduce a novel Super-Resolution (SR) algorithm named Wider-activation for Attention-mechanism based on a Generative Adversarial Network (WAGAN) to improve the classification of the tomato diseases LR images. The WAGAN consists of three main parts; the generator network, which has the Wider Activation for Residual Channel Attention Block (WARCAB) as the principal block, the discriminator network and the adversarial loss. To evaluate the potential of the proposed method in plant diseases recognition, we first recovered SR plant diseases images from LR images using the WAGAN. Next, we implemented diseases classification using LR, SR, and HR images. The results proved the efficacy of the proposed method (97.63%) with x3.6 lower complexity than the state-of-the-art method and very close to the reference HR (97.81%) accuracy. Due to the efficient design of WARCAB and the adversarial loss, the WAGAN focuses more on edges, textures, and other valuable information, which are the key information, needed for the classifier to recognize the disease.
C1 [Salmi, Abderrahmane; Ghazi, Mehdi] Freres Mentouri Univ Constantine 1, Lab SISCOM, Constantine, Algeria.
   [Benierbah, Said] Freres Mentouri Univ Constantine 1, SP Lab, Constantine, Algeria.
RP Salmi, A (corresponding author), Freres Mentouri Univ Constantine 1, Lab SISCOM, Constantine, Algeria.
EM abderrahmane.umc@gmail.com; said_benierbah@umc.edu.dz;
   mehdighazi.umc@gmail.com
RI Benierbah, Said/P-3578-2016
CR Agarwal M, 2020, SUSTAIN COMPUT-INFOR, V28, DOI 10.1016/j.suscom.2020.100407
   Agarwal M, 2020, PROCEDIA COMPUT SCI, V167, P293, DOI 10.1016/j.procs.2020.03.225
   Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Barbedo JGA, 2019, BIOSYST ENG, V180, P96, DOI 10.1016/j.biosystemseng.2019.02.002
   Arsenovic M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11070939
   Atila Ü, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2020.101182
   Bisen D, 2021, MULTIMED TOOLS APPL, V80, P6443, DOI 10.1007/s11042-020-10038-w
   Cap QH, 2019, 2019 53 ANN C INF SC, P1
   Chen JD, 2020, MULTIMED TOOLS APPL, V79, P31497, DOI 10.1007/s11042-020-09669-w
   Chen X, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105730
   Dai Q, 2020, IEEE ACCESS, V8, P55724, DOI 10.1109/ACCESS.2020.2982055
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Emmanuel TO, 2018, KAGGLE COM
   Espejo-Garcia B, 2021, BIOSYST ENG, V204, P79, DOI 10.1016/j.biosystemseng.2021.01.014
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Hughes A, 2015, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.17
   Hunter MC, 2017, BIOSCIENCE, V67, P385, DOI 10.1093/biosci/bix010
   Karthik R, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105933
   Khairuzzaman, 2016, TF DATA
   Khan MA, 2020, MULTIMED TOOLS APPL, V79, P18627, DOI 10.1007/s11042-020-08726-8
   Kien Trang, 2019, 2019 IEEE Conference on Sustainable Utilization and Development in Engineering and Technologies (CSUDET), P138, DOI 10.1109/CSUDET47057.2019.9214620
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Längkvist M, 2014, PATTERN RECOGN LETT, V42, P11, DOI 10.1016/j.patrec.2014.01.008
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li YT, 2020, IEEE INTERNET COMPUT, V24, P49, DOI 10.1109/MIC.2020.2971447
   Liang QK, 2019, COMPUT ELECTRON AGR, V157, P518, DOI 10.1016/j.compag.2019.01.034
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Lin M, 2014, ABS13124 CORR
   Lu JZ, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21191-6
   Mahmoud MAB, 2020, MULTIMED TOOLS APPL, V79, P26245, DOI 10.1007/s11042-020-09239-0
   Manjunath M, 2018, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.155
   Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35
   Nazki H, 2020, COMPUT ELECTRON AGR, V168, DOI 10.1016/j.compag.2019.105117
   Ozguven MM, 2019, PHYSICA A, V535, DOI 10.1016/j.physa.2019.122537
   Prajwala TM, 2018, INT CONF CONTEMP, P314
   Qin HF, 2021, IEEE T INF FOREN SEC, V16, P2652, DOI 10.1109/TIFS.2021.3059340
   Salimans T, 2016, ADV NEUR IN, V29
   Sardogan M, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P382, DOI 10.1109/UBMK.2018.8566635
   Savary S, 2012, FOOD SECUR, V4, P519, DOI 10.1007/s12571-012-0200-5
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun RC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020466
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tang H, 2019, PROC CVPR IEEE, P2412, DOI 10.1109/CVPR.2019.00252
   Too EC, 2019, COMPUT ELECTRON AGR, V161, P272, DOI 10.1016/j.compag.2018.03.032
   Torres-Sánchez J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0058210
   Wang X, 2020, J COMPOS MATER, V54, P2389, DOI 10.1177/0021998319896842
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wen J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20164601
   Wu H., 2019, Plant Phenome Journal, Volume, V2, P1, DOI DOI 10.2135/TPPJ2019.03.0006
   Wu PD, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12122035
   Yamamoto K, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112557
   Yilma G, 2020, I COMP CONF WAVELET, P67, DOI 10.1109/ICCWAMTIP51612.2020.9317494
   Yu J, 2018, ABS18080 CORR
   Zhang L, 2019, KSII T INTERNET INF, V13, P2012, DOI 10.3837/tiis.2019.04.015
   Zhang Y, 2020, IEEE ACCESS, V8, P56607, DOI 10.1109/ACCESS.2020.2982456
   Zhang YS, 2015, NONLINEAR DYNAM, V82, P1831, DOI 10.1007/s11071-015-2280-1
   Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865
NR 60
TC 4
Z9 5
U1 4
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8519
EP 8538
DI 10.1007/s11042-022-12256-w
EA FEB 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000749966800018
DA 2024-07-18
ER

PT J
AU Kurmi, Y
   Gangwar, S
   Chaurasia, V
   Goel, A
AF Kurmi, Yashwant
   Gangwar, Suchi
   Chaurasia, Vijayshri
   Goel, Aditya
TI Leaf images classification for the crops diseases detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image localization and classification; Computer-assisted diagnosis;
   Crop's leaf image; Tomato leaf image classification; Adaptive analytic
   wavelet transform
ID WAVELET TRANSFORM; SEGMENTATION; EXTRACTION; IDENTIFICATION; ALGORITHM;
   TEXTURE; LEAVES
AB Crop production affects the economy of a specific region or country. To maintain the economic development of any territory crops disease detection is a leading factor in agriculture. There exists various techniques to detect the crops disease, but they offers lilimted accuracy. The proposed mulistage technique utilizes leaf region separation from background prior to the feature extraction for classification of images as healthy and diseased. Initially color transformation-based foreground separation is performed followed by the features extraction. The novelty of the method is attruibuts that are computed though adaptive analytic wavelet transform (AAWT). The AAWT decomposes the preprocessed images into various sub-band images as features. The attributes utilized for categorization are a combination of bag of visual word, Fisher vectors, and AAWT based-features extracted from leaf images. Performance of the proposal is analyzed through PlantVillage dataset. The simulation outcomes validate the superiority of the proferred classification system as compared with the existing techniques of the field. The proposed leaf classification method provides an average accuracy of 94.07% with the area under the characteristic curve 0.961.
C1 [Kurmi, Yashwant] Madhyanchal Proc Univ Bhopal, ECE Dept, Ratibad, India.
   [Kurmi, Yashwant] Mayo Clin, Radiol, Rochester, MN 55905 USA.
   [Gangwar, Suchi] RKDF Univ, Agr Dept, Bhopal, India.
   [Chaurasia, Vijayshri; Goel, Aditya] Maulana Azad Natl Inst Technol, ECE Dept, Bhopal, India.
C3 Mayo Clinic; National Institute of Technology (NIT System); Maulana Azad
   National Institute of Technology Bhopal
RP Kurmi, Y (corresponding author), Madhyanchal Proc Univ Bhopal, ECE Dept, Ratibad, India.; Kurmi, Y (corresponding author), Mayo Clin, Radiol, Rochester, MN 55905 USA.
EM yashwantkurmi18@gmail.com
RI Chaurasia, Vijayshri/A-5554-2016; Goel, Aditya/J-6509-2013; Kurmi,
   Yashwant/AAK-1374-2021
OI Chaurasia, Vijayshri/0000-0002-3347-5630; Goel,
   Aditya/0000-0002-3469-9273; Kurmi, Yashwant/0000-0003-4986-2106
CR Acharya UR, 2017, COMPUT BIOL MED, V88, P72, DOI 10.1016/j.compbiomed.2017.06.022
   Acharya UR, 2016, COMPUT BIOL MED, V73, P131, DOI 10.1016/j.compbiomed.2016.04.009
   Acharya UR, 2011, IEEE T INF TECHNOL B, V15, P449, DOI 10.1109/TITB.2011.2119322
   [Anonymous], 2017, COMPUT INTEL NEUROSC
   Aparajita, 2017, 2017 40TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P758, DOI 10.1109/TSP.2017.8076090
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Barbedo JGA, 2013, SPRINGERPLUS, V2, DOI 10.1186/2193-1801-2-660
   Bayram I, 2013, IEEE T SIGNAL PROCES, V61, P1131, DOI 10.1109/TSP.2012.2232655
   Beucher S., 2018, Mathematical Morphology in Image Processing, P433
   Biswas MK, 1998, PATTERN RECOGN LETT, V19, P309, DOI 10.1016/S0167-8655(98)00002-6
   Biswas S, 2014, 2014 IEEE CANADA INTERNATIONAL HUMANITARIAN TECHNOLOGY CONFERENCE (IHTC)
   Chaurasia V, 2016, J VIS COMMUN IMAGE R, V41, P87, DOI 10.1016/j.jvcir.2016.09.008
   Chen YL, 2015, IEEE T NEUR NET LEAR, V26, P1682, DOI 10.1109/TNNLS.2014.2351418
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cuingnet R, 2013, IEEE T PATTERN ANAL, V35, P682, DOI 10.1109/TPAMI.2012.142
   Dean R, 2012, MOL PLANT PATHOL, V13, P414, DOI 10.1111/j.1364-3703.2011.00783.x
   Dua S, 2012, IEEE T INF TECHNOL B, V16, P80, DOI 10.1109/TITB.2011.2176540
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Fang Y, 2015, BIOSENSORS-BASEL, V5, P537, DOI 10.3390/bios5030537
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Grand-Brochier M, 2015, IEEE T IMAGE PROCESS, V24, P1549, DOI 10.1109/TIP.2015.2400214
   Gupta V, 2019, IEEE SENS J, V19, P2266, DOI 10.1109/JSEN.2018.2883497
   Haninsky R., 2020, PLANTS BASEL SWITZER, V9, P1
   Hojjatoleslami SA, 1998, IEEE T IMAGE PROCESS, V7, P1079, DOI 10.1109/83.701170
   Iftekharuddin KM, 2003, MACH VISION APPL, V13, P352, DOI 10.1007/s00138-002-0087-9
   Islam M, 2017, CAN CON EL COMP EN
   Kaur S, 2018, IET IMAGE PROCESS, V12, P1038, DOI 10.1049/iet-ipr.2017.0822
   Keras, 2018, Keras Documentation
   Khan MA, 2019, IEEE ACCESS, V7, P46261, DOI 10.1109/ACCESS.2019.2908040
   Kim J, 2016, IEEE T IMAGE PROCESS, V25, P9, DOI 10.1109/TIP.2015.2495122
   Klein A, 2017, PR MACH LEARN RES, V54, P528
   Kurmi Y, 2020, 2 INT C DAT ENG APPL, P1
   Kurmi Y, 2020, IET IMAGE PROCESS, P1
   Kurmi Y, 2021, SIGNAL IMAGE VIDEO P, V15, P589, DOI 10.1007/s11760-020-01780-7
   Kurmi Y, 2020, SIGNAL IMAGE VIDEO P, V14, P665, DOI 10.1007/s11760-019-01584-4
   Kurmi Y, 2019, J MED IMAGING RADIAT, V50, P514, DOI 10.1016/j.jmir.2019.07.004
   Kurmi Y, 2018, IET IMAGE PROCESS, V12, P1491, DOI 10.1049/iet-ipr.2017.1020
   Li M, 2005, PATTERN RECOGN LETT, V26, P527, DOI 10.1016/j.patrec.2004.09.007
   Liu LQ, 2017, IEEE T PATTERN ANAL, V39, P2335, DOI 10.1109/TPAMI.2017.2651061
   Mansfield J, 2012, MOL PLANT PATHOL, V13, P614, DOI 10.1111/j.1364-3703.2012.00804.x
   Martis RJ, 2013, BIOMED SIGNAL PROCES, V8, P437, DOI 10.1016/j.bspc.2013.01.005
   Mercan E, 2014, INT C PATT RECOG, P1179, DOI 10.1109/ICPR.2014.212
   Mu Hong-bo, 2019, Engineering in Agriculture, Environment and Food, V12, P477, DOI 10.1016/j.eaef.2019.09.002
   Neto JC, 2006, COMPUT ELECTRON AGR, V51, P66, DOI 10.1016/j.compag.2005.11.002
   Patil P, 2017, IEEE I C COMP INT CO, P1071
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Qin F, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0168274
   Raji CG, 2017, IEEE T SYST MAN CY-S, V47, P2318, DOI 10.1109/TSMC.2017.2661996
   Rumpf T, 2010, COMPUT ELECTRON AGR, V74, P91, DOI 10.1016/j.compag.2010.06.009
   Sabrol H, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P1242, DOI 10.1109/ICCSP.2016.7754351
   Sankaran S, 2010, COMPUT ELECTRON AGR, V72, P1, DOI 10.1016/j.compag.2010.02.007
   Scharr H, 2016, MACH VISION APPL, V27, P585, DOI 10.1007/s00138-015-0737-3
   Schor N, 2016, IEEE ROBOT AUTOM LET, V1, P354, DOI 10.1109/LRA.2016.2518214
   Sharma M, 2017, PATTERN RECOGN LETT, V94, P172, DOI 10.1016/j.patrec.2017.03.023
   Silva LOLA, 2013, COMPUT ELECTRON AGR, V97, P47, DOI 10.1016/j.compag.2013.07.001
   Singh Vijai, 2017, Information Processing in Agriculture, V4, P41, DOI 10.1016/j.inpa.2016.10.005
   Soares JVB, 2013, MACH VISION APPL, V24, P1623, DOI 10.1007/s00138-013-0530-0
   team: GB, 2018, TensorFlow
   Teng CH, 2011, OPT ENG, V50, DOI 10.1117/1.3549927
   Wang JL, 2013, COMPUT ELECTRON AGR, V96, P23, DOI 10.1016/j.compag.2013.04.014
   Wang SJ, 2015, IEEE T IMAGE PROCESS, V24, P6034, DOI 10.1109/TIP.2015.2496314
   Wu JG, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030612
   Xu DX, 2010, INFORM SCI STAT, P47, DOI 10.1007/978-1-4419-1570-2_2
   Xu GL, 2011, PATTERN RECOGN LETT, V32, P1584, DOI 10.1016/j.patrec.2011.04.020
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yanikoglu B, 2014, MACH VISION APPL, V25, P1369, DOI 10.1007/s00138-014-0612-7
   Zhang CL, 2015, MECH SYST SIGNAL PR, V64-65, P162, DOI 10.1016/j.ymssp.2015.03.030
   Zhang XW, 2015, IEEE T NANOBIOSCI, V14, P237, DOI 10.1109/TNB.2015.2403274
NR 70
TC 10
Z9 10
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8155
EP 8178
DI 10.1007/s11042-022-11910-7
EA JAN 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000750341800002
DA 2024-07-18
ER

PT J
AU Raj, S
   Tripathi, S
   Tripathi, KC
AF Raj, Sundeep
   Tripathi, Sandesh
   Tripathi, K. C.
TI ArDHO-deep RNN: autoregressive deer hunting optimization based deep
   recurrent neural network in investigating atmospheric and oceanic
   parameters
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep recurrent neural network (deep RNN); Deer hunting optimization
   (DHO); Weather prediction; Sea surface temperature (SST); Soil moisture
ID PREDICTION
AB In recent decades, weather prediction results in a challenging and complex task in various disciplines. However, prediction of the atmospheric parameters is significant in various applications, like climate monitoring, agriculture and production, aviation industry, pollution dispersal, and drought detection. Due to the dynamic nature of the atmosphere, accurate prediction of the weather parameters is more complex. Sea Surface Temperature (SST) is the major factor that affects ocean climate. Hence, it is more important to analyze the atmospheric and oceanic parameters, like SST, Sea Surface Height (SSH), wind velocity, and soil moisture, for forecasting the weather. Hence, this research has developed an effective method named Autoregressive Deer Hunting Optimization (ArDHO)-based Deep Recurrent Neural Network (Deep RNN) for investigating the atmospheric and oceanic parameters. The technical indicators associated with the atmospheric data are effectively extracted. The process of data augmentation enabled to achieve higher dimensionality of data, as the deep learning classifier is more effective in generating optimal results with the high dimensional training samples. Finally, the Deep RNN classifier is employed to make the prediction strategy, and the training process of the classifier is done with the proposed optimization algorithm. However, the proposed method achieved higher performance by obtaining minimal MSE, RMSE, and speed value of 0.0524, 0.2288, and 31.25 and the maximal model size of 23.
C1 [Raj, Sundeep] Uttarakhand Tech Univ, Dehra Dun, Uttarakhand, India.
   [Raj, Sundeep] Ajay Kumar Garg Engn Coll, Dept Informat Technol, Ghaziabad, Uttar Pradesh, India.
   [Tripathi, Sandesh] Birla Inst Appl Sci, Dept Comp Sci & Engn, Bhimtal, Uttarakhand, India.
   [Tripathi, K. C.] Maharaja Agrasen Inst Technol, Dept Informat Technol, Delhi, India.
C3 Uttarakhand Technical University; Maharaja Agrasen Institute of
   Technology
RP Raj, S (corresponding author), Uttarakhand Tech Univ, Dehra Dun, Uttarakhand, India.; Raj, S (corresponding author), Ajay Kumar Garg Engn Coll, Dept Informat Technol, Ghaziabad, Uttar Pradesh, India.
EM Sundeepraj1@gmail.com
RI Raj, Sundeep/HTM-3491-2023
OI Raj, Sundeep/0000-0002-8124-0940; Tripathi, Krishna/0000-0003-3156-7758
CR Angot G, 2012, J GEOPHYS RES-ATMOS, V117, DOI 10.1029/2012JD017631
   Brammya G., 2019, Comput J, DOI [10.1093/comjnl/bxy133, DOI 10.1093/COMJNL/BXY133]
   Engle RF, 2004, J BUS ECON STAT, V22, P367, DOI 10.1198/073500104000000370
   He Q, 2020, ENERGIES, V13, DOI 10.3390/en13061369
   Im ES, 2018, CLIM DYNAM, V51, P73, DOI 10.1007/s00382-017-3907-3
   Inoue M, 2018, ARTIF LIFE ROBOT, V23, P173, DOI 10.1007/s10015-017-0422-x
   Le Pichon A, 2015, J GEOPHYS RES-ATMOS, V120, P8318, DOI 10.1002/2015JD023273
   Lee J, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12010108
   Li Y, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9010067
   Maloney ED, 2000, J CLIMATE, V13, P1451, DOI 10.1175/1520-0442(2000)013<1451:MOENPH>2.0.CO;2
   Pal NR, 2003, IEEE T GEOSCI REMOTE, V41, P2783, DOI 10.1109/TGRS.2003.817225
   PALMER TN, 1993, B AM METEOROL SOC, V74, P49, DOI 10.1175/1520-0477(1993)074<0049:ERAPAT>2.0.CO;2
   Radhika Y, 2009, Int. J. Comput. Theory Eng, V1, P55, DOI DOI 10.7763/IJCTE.2009.V1.9
   Riordan D, 2002, ENG INTELL SYST ELEC, V10, P139
   Sarkar PP, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-03239-3
   Shynkevich Y, 2017, NEUROCOMPUTING, V264, P71, DOI 10.1016/j.neucom.2016.11.095
   Wang X, 2020, WATER-SUI, V12, DOI 10.3390/w12102685
   Wolff S, 2020, J MARINE SYST, V208, DOI 10.1016/j.jmarsys.2020.103347
   Xiao CJ, 2019, REMOTE SENS ENVIRON, V233, DOI 10.1016/j.rse.2019.111358
   Ye XC, 2021, ATMOSPHERE-BASEL, V12, DOI 10.3390/atmos12020230
   Zhang Z, 2020, J MAR SCI ENG, V8, DOI 10.3390/jmse8040249
NR 21
TC 3
Z9 3
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 7561
EP 7588
DI 10.1007/s11042-021-11794-z
EA JAN 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000750865600005
DA 2024-07-18
ER

PT J
AU Zhou, QY
   Zhang, JW
   Han, GQ
   Ruan, ZH
   Wei, Y
AF Zhou, Qinyu
   Zhang, Jianwei
   Han, Guoqiang
   Ruan, Zhihui
   Wei, Ying
TI Enhanced self-supervised GANs with blend ratio classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Generative adversarial network; Self-supervised learning; Representation
   learning; Image generation
AB Generative adversarial networks (GANs) have achieved remarkable success in image generation, especially training conditional GANs for deriving reliable representations. However, the main downside of conditional GANs is the requirement of labeled data. Using self-supervision information can meet such needs, but the challenges remain for discovering more reliable self-supervised signals and ways to couple different signals to describe characteristics of the training data more precisely. In this paper, we propose a novel self-supervised learning approach to automatically generating pseudo labels for autoencoder-based GANs. Specifically, we blend the input images and the corresponding reconstructed results to produce transformed samples controlled by the blend ratio. Then, an additional classifier attached to the discriminator needs to distinguish the ratio of real images from the transformed samples to derive meaningful representations. Next, we enhance GANs with multiple self-supervision guidances by two different means to further improve the capacity of the discriminator. One merges multiple supervision signals and requires the classifier to predict the mixed probability, whereas the other one utilizes these signals independently. In experiments, we evaluate the quality of the generated image and the learned representation using three datasets. Empirical results prove the effectiveness of our methods on both image synthesis and representation learning.
C1 [Zhou, Qinyu; Zhang, Jianwei; Han, Guoqiang; Ruan, Zhihui; Wei, Ying] South China Univ Technol, Guangzhou, Peoples R China.
C3 South China University of Technology
RP Zhang, JW (corresponding author), South China Univ Technol, Guangzhou, Peoples R China.
EM imbabox@hotmail.com; jwzhang@scut.edu.cn; csgqhan@scut.edu.cn;
   r.gd@outlook.com; 1305400163@qq.com
RI zhang, jian/HPD-1712-2023; zhan, y/ISA-2807-2023; jin, li/IWU-4648-2023;
   Zhang, Jianjun/KEJ-3941-2024
CR [Anonymous], 2019, ADV NEURAL INFORM PR
   Brock AM, 2018, PROCEEDINGS PERVASIVE DISPLAYS 2018: THE 7TH ACM INTERNATIONAL SYMPOSIUM ON PERVASIVE DISPLAYS, DOI 10.1145/3205873.3205877
   Chen T, 2019, PROC CVPR IEEE, P12146, DOI 10.1109/CVPR.2019.01243
   Doersch C, 2017, IEEE I CONF COMP VIS, P2070, DOI 10.1109/ICCV.2017.226
   Doersch C, 2015, IEEE I CONF COMP VIS, P1422, DOI 10.1109/ICCV.2015.167
   Donahue J., 2016, ARXIV160509782
   Dumoulin V., 2017, INT C LEARN REPR, P1
   Feng ZY, 2019, PROC CVPR IEEE, P10356, DOI 10.1109/CVPR.2019.01061
   Gidaris S., 2018, P 6 INT C LEARNING R
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hensel M, 2017, ADV NEUR IN, V30
   Hoang TT, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207181
   Gulrajani I, 2017, ADV NEUR IN, V30
   Karras T, 2018, P INT C LEARN REPR I
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Kingma D. P., 2014, arXiv
   Larsen ABL, 2016, PR MACH LEARN RES, V48
   Mescheder L, 2018, PR MACH LEARN RES, V80
   Metz Luke, 2017, Unrolled generative adversarial networks
   Miyato T, 2018, INT C LEARN REPR
   Tran NT, 2018, LECT NOTES COMPUT SC, V11218, P387, DOI 10.1007/978-3-030-01264-9_23
   Noroozi M, 2016, LECT NOTES COMPUT SC, V9910, P69, DOI 10.1007/978-3-319-46466-4_5
   Pidhorskyi S., 2020, P IEEE CVF C COMP VI, P14104
   Qiao TT, 2019, PROC CVPR IEEE, P1505, DOI 10.1109/CVPR.2019.00160
   Radford A., 2015, ARXIV
   Roccetti M, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0235-y
   Somasundaram A, 2016, PROC 1 INT C RES ENG, P1
   Sun YM, 2009, INT J PATTERN RECOGN, V23, P687, DOI 10.1142/S0218001409007326
   Thanh-Tung H, 2019, 7 INT C LEARNING REP
   Wang JY, 2020, PROC CVPR IEEE, P469, DOI 10.1109/CVPR42600.2020.00055
   Wang Q, 2021, INT J COMPUT VISION, V129, DOI 10.1007/s11263-020-01365-4
   Wang Q, 2020, I C NETWORK PROTOCOL, DOI 10.1109/icnp49622.2020.9259369
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 38
TC 2
Z9 2
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 7651
EP 7667
DI 10.1007/s11042-022-12056-2
EA JAN 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000749232600001
DA 2024-07-18
ER

PT J
AU Hosgurmath, S
   Mallappa, VV
   Patil, NB
   Petli, V
AF Hosgurmath, Sangamesh
   Mallappa, Viswanatha Vanjre
   Patil, Nagaraj B.
   Petli, Vishwanath
TI Effective face recognition using dual linear collaborative discriminant
   regression classification algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Combined distance metric; Deep loss function; Face recognition; Linear
   discriminant analysis; Linear regression classification; Projection
   matrix
ID FEATURE-EXTRACTION
AB In recent decades, face recognition is an attractive and emerging research area in computer vision and pattern recognition applications. Still, facial recognition is a challenging task due to the following factors; different face expressions, posture, wearing of scarves/glasses, and illumination conditions. To overcome the aforementioned factors, a new Dual Linear Collaborative Discriminant Regression Classification (DLCDRC) algorithm is introduced in this research paper. The proposed DLCDRC algorithm contains dual steps such as deep loss function, and combined distance metric. The deep loss function includes inter-class and intraclass loss functions, which are used to decrease inter and intraclass variations in Within Class Reconstruction Error (WCRE), and Collaborative between Class Reconstruction Error (CBCRE). Additionally, the combined distance metric is used to construct CBCRE and WCRE with minimum reconstruction error values that efficiently improve the face recognition performance. By inspecting the resulting phase, the DLCDRC algorithm achieved 92.47%, 96.39%, and 98.86% of classification accuracy on YALE B, ORL, and extended YALE B face datasets. The proposed DLCDRC method has the improvement of 1.85% in Extended YALE B dataset, 3.05% improvement in ORL dataset, and improvement of 2.4% in YALE B dataset. The obtained simulation results are better compared to the existing linear regression algorithms on three benchmark datasets.
C1 [Hosgurmath, Sangamesh] Visvesvaraya Technol Univ, Dept Elect & Commun Engn, Belagavi, India.
   [Mallappa, Viswanatha Vanjre; Petli, Vishwanath] HEK Soc SLN Coll Engn, Dept Elect & Commun Engn, Raichur, India.
   [Patil, Nagaraj B.] Govt Engn Coll, Dept Comp Sci & Engn, Gangavathi, Karnataka, India.
C3 Visvesvaraya Technological University
RP Hosgurmath, S (corresponding author), Visvesvaraya Technol Univ, Dept Elect & Commun Engn, Belagavi, India.
EM sangamesh.hosgurmath@gmail.com; vinviswanatha@gmail.com;
   nagarajbpatil@gmail.com; vishalpetli73@gmail.com
RI Hosgurmath, Sangamesh/AFH-6855-2022; Hosgurmath, Sangamesh/AAF-2901-2022
OI P, Vishwanath/0000-0001-5956-0377
CR Akheel TS, 2022, EVOL INTELL, V15, P1729, DOI 10.1007/s12065-021-00585-y
   Arora M, 2018, NATL ACAD SCI LETT, V41, P365, DOI 10.1007/s40009-018-0694-2
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Benouareth A, 2021, MULTIMED TOOLS APPL, V80, P1457, DOI 10.1007/s11042-020-09527-9
   Bhattacharya S, 2019, PATTERN RECOGN LETT, V125, P63, DOI 10.1016/j.patrec.2019.03.028
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Dumitrescu CM, 2019, STUD INFORM CONTROL, V28, P221, DOI 10.24846/v28i2y201910
   ElBedwehy MN, 2020, ARAB J SCI ENG, V45, P9925, DOI 10.1007/s13369-020-04538-y
   Feng QX, 2016, PROC CVPR IEEE, P4865, DOI 10.1109/CVPR.2016.526
   Gupta KO, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01070-9
   Gupta S, 2021, VISUAL COMPUT, V37, P447, DOI 10.1007/s00371-020-01814-8
   He MJ, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107113
   Heinsohn D, 2019, IMAGE VISION COMPUT, V85, P46, DOI 10.1016/j.imavis.2019.02.012
   Huang P, 2017, IEEE ACCESS, V5, P4340, DOI 10.1109/ACCESS.2017.2680437
   Huang SM, 2013, IEEE SIGNAL PROC LET, V20, P91, DOI 10.1109/LSP.2012.2230257
   Iqbal M, 2019, PATTERN RECOGN LETT, V128, P414, DOI 10.1016/j.patrec.2019.10.002
   Jin X, 2020, INT J MACH LEARN CYB, V11, P779, DOI 10.1007/s13042-019-01024-2
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Li HF, 2006, IEEE T NEURAL NETWOR, V17, P157, DOI 10.1109/TNN.2005.860852
   Li YF, 2018, WIRELESS PERS COMMUN, V103, P1195, DOI 10.1007/s11277-018-5377-2
   Ling HF, 2020, MULTIMED TOOLS APPL, V79, P5595, DOI 10.1007/s11042-019-08422-2
   Lu T, 2018, MULTIMED TOOLS APPL, V77, P11219, DOI 10.1007/s11042-017-5475-2
   Luaibi M., 2019, J SW JIAOTONG U, V54
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Nikan S, 2018, J VIS COMMUN IMAGE R, V55, P742, DOI 10.1016/j.jvcir.2018.08.007
   OUYANG A, 2019, NEUROCOMPUTING
   Pang M, 2021, IEEE T NEUR NET LEAR, V32, P1560, DOI 10.1109/TNNLS.2020.2985099
   Peng CL, 2019, SIGNAL PROCESS, V156, P46, DOI 10.1016/j.sigpro.2018.10.015
   Peng YL, 2019, INT J MACH LEARN CYB, V10, P2229, DOI 10.1007/s13042-018-0862-1
   Qu XC, 2015, J VIS COMMUN IMAGE R, V31, P312, DOI 10.1016/j.jvcir.2015.07.009
   Rejeesh MR, 2019, MULTIMED TOOLS APPL, V78, P22691, DOI 10.1007/s11042-019-7577-5
   Shoba VBT, 2020, MULTIMED TOOLS APPL, V79, P22595, DOI 10.1007/s11042-020-08997-1
   Sikkandar H, 2021, J AMB INTEL HUM COMP, V12, P3037, DOI 10.1007/s12652-020-02463-4
   Singh S, 2021, MULTIMED TOOLS APPL, V80, P19753, DOI 10.1007/s11042-021-10711-8
   TABASSUM F, 2020, J KING SAUD U COMPUT
   Umer S, 2019, MEASUREMENT, V146, P43, DOI 10.1016/j.measurement.2019.06.008
   Vishnoi V, 2021, MAPAN-J METROL SOC I, V36, P67, DOI 10.1007/s12647-020-00379-0
   Yang WK, 2020, NEUROCOMPUTING, V373, P109, DOI 10.1016/j.neucom.2019.09.102
   Yoo CH, 2017, J VIS COMMUN IMAGE R, V45, P11, DOI 10.1016/j.jvcir.2017.02.009
   ZAQOUT I, 2018, INFORM LEARN SCI
   Zhang Y, 2019, J VIS COMMUN IMAGE R, V59, P501, DOI 10.1016/j.jvcir.2019.02.007
   Zhu YN, 2018, SIGNAL PROCESS, V145, P175, DOI 10.1016/j.sigpro.2017.11.018
NR 42
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6899
EP 6922
DI 10.1007/s11042-022-11934-z
EA JAN 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000744378900001
DA 2024-07-18
ER

PT J
AU Ansingkar, NP
   Patil, RB
   Deshmukh, PD
AF Ansingkar, N. P.
   Patil, Rita B.
   Deshmukh, P. D.
TI An efficient multi class Alzheimer detection using hybrid equilibrium
   optimizer with capsule auto encoder
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pre-processing; Segmentation; Feature extraction; Optimization;
   Classification; Alzheimer detection
ID FEATURE-SELECTION; DISEASE; CLASSIFICATION; DIAGNOSIS; IMAGE
AB Alzheimer is an advanced nervous brain disease. In old aged people, Alzheimer is also causing the death. The earlier prediction of Alzheimer's disease (AD) helps to proper treatment and protects from brain tissue damages. In earlier works, different machine learning techniques are presented and the techniques are lacks in the detection performance. This work presented an innovative methodology for the Alzheimer detection in brain image. Initially, an input image is pre-processed by the skull stripping, and normalized linear smoothing and median joint (NLSMJ) filtering. In the next stage, grey matter (GM), white matter (WM) and cerebrospinal fluid (CSF) brain regions are segmented from the filtered images using adaptive fuzzy based atom search optimizer which is the high convergence rate optimizer for enhancing the segmentation performance. After the image segmentation, GM is registered with the filtered images using the improved affine transformation. Subsequently, features are extracted utilizing improved Zernike features and hybrid wavelet walsh features. Afterwards, features are selected utilizing adaptive rain optimization. Finally, hybrid equilibrium optimizer with capsule auto encoder (HEOCAE) framework is utilized for the detection of Alzheimer, normal and mild cognitive impairment images. The implementation platform used in this work is MATLAB. The presented technique is tested with the ADNI dataset images. The experimental results of the presented technique provide improved performance than the existing techniques in regards of accuracy (98.21%), sensitivity (97.31%), specificity (98.64%), precision (97.45%), NPV (0.098), F1 measure (97.37%) and AUC score (98.29%).
C1 [Ansingkar, N. P.; Patil, Rita B.] Dr Babasaheb Ambedkar Marathwada Univ, Dept Comp Sci & IT, Aurangabad, Maharashtra, India.
   [Deshmukh, P. D.] MGM Univ, Aurangabad, Maharashtra, India.
C3 Dr. Babasaheb Ambedkar Marathwada University (BAMU)
RP Ansingkar, NP (corresponding author), Dr Babasaheb Ambedkar Marathwada Univ, Dept Comp Sci & IT, Aurangabad, Maharashtra, India.
EM nirupatodkar@gmail.com
OI Deshmukh, Prapti/0000-0002-3065-6057; Ansingkar,
   Nirupama/0009-0009-3121-6182; Patil, Rita/0000-0001-6009-0181
CR Acharya UR, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1428-9
   Altaf T., 2017, IEEE FUT TECHN C
   Altaf T, 2018, BIOMED SIGNAL PROCES, V43, P64, DOI 10.1016/j.bspc.2018.02.019
   Amini M, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/9523039
   Baskar D, 2019, MULTIMED TOOLS APPL, V78, P12883, DOI 10.1007/s11042-018-6287-8
   Billones CD, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P3724, DOI 10.1109/TENCON.2016.7848755
   Chen K, 2021, ARXIV PREPRINT ARXIV, P1, DOI DOI 10.1061/(ASCE)EY.1943-7897.0000804
   Chyzhyk D, 2014, NEUROCOMPUTING, V128, P73, DOI 10.1016/j.neucom.2013.01.065
   Derby CA, 2020, CURR EPIDEMIOL REP, V7, P68, DOI 10.1007/s40471-020-00231-8
   Duraisamy B, 2019, BRAIN IMAGING BEHAV, V13, P87, DOI 10.1007/s11682-018-9831-2
   Feng JW, 2021, NEUROCOMPUTING, V421, P260
   Grassi M, 2019, FRONT NEUROL, V10, DOI 10.3389/fneur.2019.00756
   Gupta Y, 2019, FRONT COMPUT NEUROSC, V13, DOI 10.3389/fncom.2019.00072
   Islam J, 2017, LECT NOTES ARTIF INT, V10654, P213, DOI 10.1007/978-3-319-70772-3_20
   Islam Jyoti, 2018, Brain Inform, V5, P2, DOI 10.1186/s40708-018-0080-3
   Janghel RR, 2021, IRBM, V42, P258, DOI 10.1016/j.irbm.2020.06.006
   Khan RU, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12566
   Kruthika K. R., 2019, Informatics in Medicine Unlocked, V14, P59, DOI 10.1016/j.imu.2018.12.001
   Lee G, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-37769-z
   Liu CF, 2019, MAGN RESON IMAGING, V64, P190, DOI 10.1016/j.mri.2019.07.003
   Liu MH, 2020, NEUROIMAGE, V208, DOI 10.1016/j.neuroimage.2019.116459
   Lulu Yue, 2018, 2018 14th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD), P228, DOI 10.1109/FSKD.2018.8687207
   Mehmood A, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10020084
   Nawaz A, 2021, ARXIV PREPRINT ARXIV
   Ota K, 2015, J NEUROSCI METH, V256, P168, DOI 10.1016/j.jneumeth.2015.08.020
   Poloni KM, 2021, NEUROCOMPUTING, V419, P126, DOI 10.1016/j.neucom.2020.07.102
   Ramzan F, 2019, J MED SYST, V44, DOI 10.1007/s10916-019-1475-2
   Raza M, 2019, EXPERT SYST APPL, V136, P353, DOI 10.1016/j.eswa.2019.06.038
   Ruiz E, 2018, J ALZHEIMERS DIS, V65, P819, DOI 10.3233/JAD-170514
   Sarraf S.Tofighi., 2016, Classification of alzheimer's disease using fmri data and deep learning convolutional neural networks
   Vu TD, 2018, SOFT COMPUT, V22, P6825, DOI 10.1007/s00500-018-3421-5
   Wen JH, 2020, MED IMAGE ANAL, V63, DOI 10.1016/j.media.2020.101694
NR 32
TC 7
Z9 7
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6539
EP 6570
DI 10.1007/s11042-021-11786-z
EA JAN 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000742610700003
DA 2024-07-18
ER

PT J
AU Yang, J
   Fan, LY
   Sun, QS
AF Yang, Jing
   Fan, Liya
   Sun, Quansen
TI A novel supervised correlation analysis based on partial differential
   equations for multi-feature extraction and fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Canonical correlation analysis; Partial differential equations;
   Supervised information; Feature extraction; Feature fusion
ID CANONICAL CORRELATION-ANALYSIS; DIMENSIONALITY REDUCTION; FACE
   RECOGNITION; LEVEL FUSION; EIGENFACES; FRAMEWORK; PDES; CCA
AB In high dimensional data analysis, canonical correlation analysis (CCA) mainly studies the linear correlation between two sets of features and it is an effective two-view feature extraction method. However, CCA cannot extract the features that are invariant under some transforms. Moreover, CCA is an unsupervised learning algorithm which does not contain the class label information. These limits the classification performance to some extent. In this paper, a novel learning algorithm is proposed, called supervised CCA based on partial differential equations (SCCA-PDEs), which considers both invariance of the features under some transforms and discriminative. More concretely, SCCA-PDEs firstly extracts the feature matrix of each view by using the evolutionary process of PDEs; and then the between-class and within-class scatter matrices are introduced into the criterion function to enhance the discriminative power of features, which results in not only maximizing the correlation between two feature vectors, but also maximizing between-class separability and simultaneously minimizing within-class cohesiveness; and next fuse the extracted features by two given fusion strategy to form discriminative feature vectors for classification tasks. The experimental results on several benchmark databases show that SCCA-PDEs has better discriminating power and robustness than the existing related algorithms.
C1 [Yang, Jing; Fan, Liya] Liaocheng Univ, Sch Math Sci, Liaocheng 252059, Shandong, Peoples R China.
   [Sun, Quansen] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.
C3 Liaocheng University; Nanjing University of Science & Technology
RP Yang, J (corresponding author), Liaocheng Univ, Sch Math Sci, Liaocheng 252059, Shandong, Peoples R China.
EM jingyang@lcu.edu.cn
FU Natural Science Foundation of Shandong Province [ZR2018BF010]; National
   Natural Science Foundation of China [61673220]
FX This work is supported by the Natural Science Foundation of Shandong
   Province (Grant no. ZR2018BF010) and the National Natural Science
   Foundation of China (Grant no. 61673220).
CR Al-Tayyan A, 2017, IMAGE VISION COMPUT, V61, P54, DOI 10.1016/j.imavis.2017.02.004
   Alilou VK, 2017, J VIS COMMUN IMAGE R, V48, P43, DOI 10.1016/j.jvcir.2017.06.003
   Andrew G., 2013, ICML, P1247
   Awad AI, 2016, STUD COMPUT INTELL, V630, P1, DOI 10.1007/978-3-319-28854-3
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230
   Chen J, 2018, IEEE T SIGNAL PROCES, V66, P4398, DOI 10.1109/TSP.2018.2853130
   Constantinidis AS, 2001, PATTERN RECOGN, V34, P1527, DOI 10.1016/S0031-3203(00)00088-1
   Cui Y, 2012, PATTERN RECOGN, V45, P1471, DOI 10.1016/j.patcog.2011.10.006
   de Cheveigné A, 2019, NEUROIMAGE, V186, P728, DOI 10.1016/j.neuroimage.2018.11.026
   Du L, 2016, BIOINFORMATICS, V32, P1544, DOI 10.1093/bioinformatics/btw033
   Elmadany NE, 2018, IEEE T IMAGE PROCESS, V27, P5275, DOI 10.1109/TIP.2018.2855438
   Fang C, 2017, PATTERN RECOGN, V69, P14, DOI 10.1016/j.patcog.2017.03.034
   Fu Y., 2008, P 2008 INT C CONT BA, P127, DOI DOI 10.1145/1386352.1386373
   Gao XZ, 2018, APPL SOFT COMPUT, V62, P45, DOI 10.1016/j.asoc.2017.10.008
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   [侯书东 Hou Shudong], 2012, [自动化学报, Acta Automatica Sinica], V38, P659
   Jing XY, 2003, PATTERN RECOGN, V36, P1675, DOI 10.1016/S0031-3203(02)00287-X
   Kumari P, 2016, NEURAL COMPUT APPL, V27, P659, DOI 10.1007/s00521-015-1885-0
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Lenc L, 2015, COMPUT ELECTR ENG, V46, P256, DOI 10.1016/j.compeleceng.2015.01.014
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2015, PATTERN RECOGN, V48, P2290, DOI 10.1016/j.patcog.2015.01.021
   Li HX, 2015, PROC CVPR IEEE, P5325, DOI 10.1109/CVPR.2015.7299170
   Li YT, 2020, IEEE INTERNET COMPUT, V24, P49, DOI 10.1109/MIC.2020.2971447
   Liu CJ, 2001, IEEE T IMAGE PROCESS, V10, P598, DOI 10.1109/83.913594
   Liu RS, 2013, IMAGE VISION COMPUT, V31, P43, DOI 10.1016/j.imavis.2012.09.004
   Liu RS, 2010, LECT NOTES COMPUT SC, V6311, P115
   Melzer T, 2003, PATTERN RECOGN, V36, P1961, DOI 10.1016/S0031-3203(03)00058-X
   Peng JL, 2015, MULTIMED TOOLS APPL, V74, P4469, DOI 10.1007/s11042-013-1817-x
   Qin Y, 2019, IEEE T GEOSCI REMOTE, V57, P3952, DOI 10.1109/TGRS.2018.2889195
   Shen XB, 2018, J VIS COMMUN IMAGE R, V53, P161, DOI 10.1016/j.jvcir.2018.03.004
   Shen XB, 2015, NEUROCOMPUTING, V148, P397, DOI 10.1016/j.neucom.2014.06.015
   Sun LA, 2011, IEEE T PATTERN ANAL, V33, P194, DOI 10.1109/TPAMI.2010.160
   Sun QS, 2005, PATTERN RECOGN, V38, P2437, DOI 10.1016/j.patcog.2004.12.013
   Sun QS, 2005, PATTERN RECOGN, V38, P449, DOI 10.1016/j.patcog.2004.08.009
   Sun TK, 2007, IMAGE VISION COMPUT, V25, P531, DOI 10.1016/j.imavis.2006.04.014
   Sun TK, 2008, IEEE DATA MINING, P1043, DOI 10.1109/ICDM.2008.28
   Sun Y, 2013, IEEE I CONF COMP VIS, P1489, DOI 10.1109/ICCV.2013.188
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang LQ, 2015, IET COMPUT VIS, V9, P903, DOI 10.1049/iet-cvi.2014.0324
   Yang J, 2003, PATTERN RECOGN, V36, P1369, DOI 10.1016/S0031-3203(02)00262-5
   Yang J, 2018, NEURAL PROCESS LETT, V48, P1583, DOI 10.1007/s11063-018-9780-1
   Yang J, 2017, NEURAL PROCESS LETT, V46, P521, DOI 10.1007/s11063-017-9600-z
   Yang J, 2014, NEURAL PROCESS LETT, V40, P301, DOI 10.1007/s11063-013-9330-9
   Yi YG, 2015, MULTIMED TOOLS APPL, V74, P85, DOI 10.1007/s11042-013-1429-5
   Zhang D, 2010, IEEE T INSTRUM MEAS, V59, P480, DOI 10.1109/TIM.2009.2028772
   Zhao ZY, 2015, NEUROCOMPUTING, V168, P23, DOI 10.1016/j.neucom.2015.06.019
NR 48
TC 1
Z9 1
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6351
EP 6371
DI 10.1007/s11042-021-11755-6
EA JAN 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000741563800001
DA 2024-07-18
ER

PT J
AU Nainwal, A
   Kumar, Y
   Jha, B
AF Nainwal, Ashish
   Kumar, Yatindra
   Jha, Bhola
TI An ECG classification using DNN classifier with modified pigeon inspired
   optimizer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep neural network; Heartbeat classification; PIO; Wavelet transform
ID DEEP LEARNING APPROACH; HEARTBEAT CLASSIFICATION; ARRHYTHMIA
   RECOGNITION; NEURAL-NETWORK; SIGNAL; FEATURES
AB Arrhythmia is a form of heart disease in which the regularity of the pulse is changed.ECG data may be analyzed to detect heart-related illnesses or arrhythmias. This paper presents a wrapper feature selection strategy that employs a Pigeon-inspired optimizer(PIO). The modified Pigeon Inspired Optimizer (MPIO) is used to optimize ECG features and the Deep Neural Network (DNN) to classify the ECG signals. In MPIO, the new blood pigeons were introduced to improve the accuracy of the algorithm. Morphological features, wavelet transform coefficients, and R-R interval dynamic features are extracted for classification of ECG signals. After feature extraction, MPIO is used for feature optimization because optimizing the feature plays a key role in developing the model of machine learning, and irrelevant data features degrade model accuracy and enhance model training time. Using optimised features, the DNN classifier is utilised to classify ECG data. The proposed method achieves 99.10% accuracy, 98.90% specificity, and 98.50% sensitivity. Additionally, when compared with other state-of-the-art methodologies, our method of feature selection also exhibited better outcomes.
C1 [Nainwal, Ashish] FET Gurukul Kangri Univ, Dept ECE, Haridwar, Uttarakhand, India.
   [Kumar, Yatindra; Jha, Bhola] GBPIET, Dept Elect Engn, Pauri Garhwal, Uttarakhand, India.
C3 Gurukul Kangri Vishwavidyalaya
RP Nainwal, A (corresponding author), FET Gurukul Kangri Univ, Dept ECE, Haridwar, Uttarakhand, India.
EM ashish.nainwal@gkv.ac.in
CR Al Rahhal MM, 2016, INFORM SCIENCES, V345, P340, DOI 10.1016/j.ins.2016.01.082
   Alajlan N, 2014, SIGNAL IMAGE VIDEO P, V8, P931, DOI 10.1007/s11760-012-0339-8
   Alcaraz R, 2011, IEEE T BIO-MED ENG, V58, P1441, DOI 10.1109/TBME.2011.2112658
   Alonso-Atienza F, 2014, IEEE T BIO-MED ENG, V61, P832, DOI 10.1109/TBME.2013.2290800
   [Anonymous], 2017, Bitlis Eren Univ. J. Sci. Technol., DOI [10.17678/beuscitech.344953, DOI 10.17678/BEUSCITECH.344953]
   Baloglu UB, 2019, PATTERN RECOGN LETT, V122, P23, DOI 10.1016/j.patrec.2019.02.016
   Celin S, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1083-6
   Chandrakar Bhumika., 2013, International Journal of Advanced Research in Computer and Communication Engineering, V2, P1354
   Choi M, 2020, ARTIF INTELL MED, V105, DOI 10.1016/j.artmed.2020.101843
   Daamouche A, 2012, BIOMED SIGNAL PROCES, V7, P342, DOI 10.1016/j.bspc.2011.07.001
   Daqrouq K, 2014, COMPUT METH PROG BIO, V113, P919, DOI 10.1016/j.cmpb.2013.12.002
   Das A, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERECE ON CONNECTED HEALTH: APPLICATIONS, SYSTEMS AND ENGINEERING TECHNOLOGIES (CHASE), P69, DOI 10.1145/3278576.3278598
   Deng MQ, 2018, NEURAL NETWORKS, V100, P70, DOI 10.1016/j.neunet.2018.01.009
   Diker A, 2020, MED HYPOTHESES, V136, DOI 10.1016/j.mehy.2019.109515
   Dorigo M, 2006, IEEE COMPUT INTELL M, V1, P28, DOI 10.1109/MCI.2006.329691
   Duan HB, 2014, INT J INTELL COMPUT, V7, P24, DOI 10.1108/IJICC-02-2014-0005
   Elhaj FA, 2016, COMPUT METH PROG BIO, V127, P52, DOI 10.1016/j.cmpb.2015.12.024
   GLASS L, 2006, COMPLEX SYSTEMS SCI, P409
   Homaeinezhad MR, 2012, EXPERT SYST APPL, V39, P2047, DOI 10.1016/j.eswa.2011.08.025
   Ince T, 2009, IEEE T BIO-MED ENG, V56, P1415, DOI 10.1109/TBME.2009.2013934
   Jiang J., 2019, Expert Systems with Applications: X, V1, P100003, DOI DOI 10.1016/J.ESWAX.2019.100003
   Karaboga D, 2009, APPL MATH COMPUT, V214, P108, DOI 10.1016/j.amc.2009.03.090
   Khosravy M., 2020, Applied nature-inspired computing: algorithms and case studies, P1, DOI [10.1007/978-981-13-9263-4_1, DOI 10.1080/13813455.2020.1828481]
   Kora, 2016, International Journal of the Cardiovascular Academy, V2, P44, DOI [10.1016/j.ijcac.2015.12.001, DOI 10.1016/J.IJCAC.2015.12.001]
   Korürek M, 2010, EXPERT SYST APPL, V37, P7563, DOI 10.1016/j.eswa.2010.04.087
   Laguna P, 1996, MED BIOL ENG COMPUT, V34, P58, DOI 10.1007/BF02637023
   Lake R., 1981, P IEEE, V69, P856, DOI [10.1109/PROC.1981.12095, DOI 10.1109/PROC.1981.12095]
   Li H, 2017, SCI REP-UK, V7, DOI 10.1038/srep40858
   Li HQ, 2016, CIRC SYST SIGNAL PR, V35, P339, DOI 10.1007/s00034-015-0068-7
   Li Z, 2020, J ELECTROCARDIOL, V58, P105, DOI 10.1016/j.jelectrocard.2019.11.046
   Mar T, 2011, IEEE T BIO-MED ENG, V58, DOI 10.1109/TBME.2011.2113395
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mondéjar-Guerra V, 2019, BIOMED SIGNAL PROCES, V47, P41, DOI 10.1016/j.bspc.2018.08.007
   Moody GA, 2001, IEEE ENG MED BIOL, V20, P45, DOI 10.1109/51.932724
   Neggaz N, 2020, EXPERT SYST APPL, V152, DOI 10.1016/j.eswa.2020.113364
   Oh SL, 2018, COMPUT BIOL MED, V102, P278, DOI 10.1016/j.compbiomed.2018.06.002
   PAN J, 1985, IEEE T BIO-MED ENG, V32, P230, DOI 10.1109/TBME.1985.325532
   Sannino G, 2018, FUTURE GENER COMP SY, V86, P446, DOI 10.1016/j.future.2018.03.057
   Shadmand S, 2016, BIOMED SIGNAL PROCES, V25, P12, DOI 10.1016/j.bspc.2015.10.008
   Silva Ikaro, 2014, J Open Res Softw, V2
   Singh YN, 2015, NEUROCOMPUTING, V167, P322, DOI 10.1016/j.neucom.2015.04.063
   Übeyli ED, 2009, DIGIT SIGNAL PROCESS, V19, P320, DOI 10.1016/j.dsp.2008.09.002
   Vishwanath B, 2021, J KING SAUD UNIV-COM, V33, P54, DOI 10.1016/j.jksuci.2018.02.005
   Wang GJ, 2019, INFORM SCIENCES, V501, P523, DOI 10.1016/j.ins.2018.06.062
   Yildirim Ö, 2018, COMPUT BIOL MED, V96, P189, DOI 10.1016/j.compbiomed.2018.03.016
NR 45
TC 1
Z9 1
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9131
EP 9150
DI 10.1007/s11042-021-11594-5
EA JAN 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000740429700036
DA 2024-07-18
ER

PT J
AU Palani, B
   Elango, S
   Viswanathan, KV
AF Palani, Balasubramanian
   Elango, Sivasankar
   Viswanathan, Vignesh K.
TI CB-Fake: A multimodal deep learning framework for automatic fake news
   detection using capsule neural network and BERT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fake news detection; Deep learning; BERT; Capsule neural network;
   Routing-by-agreement
ID SOCIAL MEDIA
AB The progressive growth of today's digital world has made news spread exponentially faster on social media platforms like Twitter, Facebook, and Weibo. Unverified news is often disseminated in the form of multimedia content like text, picture, audio, or video. The dissemination of such false news deceives the public and leads to protests and creates troubles for the public and the government. Hence, it is essential to verify the authenticity of the news at an early stage before sharing it with the public. Earlier fake news detection (FND) approaches combined textual and visual features, but the semantic correlations between words were not addressed and many informative visual features were lost. To address this issue, an automated fake news detection system is proposed, which fuses textual and visual features to create a multimodal feature vector with high information content. The proposed work incorporates the bidirectional encoder representations from transformers (BERT) model to extract the textual features, which preserves the semantic relationships between words. Unlike the convolutional neural network (CNN), the proposed capsule neural network (CapsNet) model captures the most informative visual features from an image. These features are combined to obtain a richer data representation that helps to determine whether the news is fake or real. We investigated the performance of our model against different baselines using two publicly accessible datasets, Politifact and Gossipcop. Our proposed model achieves significantly better classification accuracy of 93% and 92% for the Politifact and Gossipcop datasets, respectively, compared to 84.6% and 85.6% for the SpotFake+ model.
C1 [Palani, Balasubramanian; Elango, Sivasankar] Natl Inst Technol, Dept Comp Sci & Engn, Tiruchirappalli, Tamil Nadu, India.
   [Viswanathan, Vignesh K.] Visa Inc, Bengaluru, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Palani, B (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Tiruchirappalli, Tamil Nadu, India.
EM balaiiits@gmail.com; sivasankar@nitt.edu; vigneshkvn2098@gmail.com
CR Ahmed H, 2017, LECT NOTES COMPUT SC, V10618, P127, DOI 10.1007/978-3-319-69155-8_9
   Akyol K, 2019, CMC-COMPUT MATER CON, V61, P69, DOI 10.32604/cmc.2019.08143
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Faustini PHA, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113503
   Asghar MZ, 2021, J AMB INTEL HUM COMP, V12, P4315, DOI 10.1007/s12652-019-01527-4
   Bondielli A, 2019, INFORM SCIENCES, V497, P38, DOI 10.1016/j.ins.2019.05.035
   Chen T, 2018, LECT NOTES ARTIF INT, V11154, P40, DOI 10.1007/978-3-030-04503-6_4
   Devlin J., 2018, BERT PRE TRAINING DE
   Goldani MH, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.106991
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo B, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3393880
   Guo CX, 2019, IEEE I CONF COMP VIS, P3908, DOI 10.1109/ICCV.2019.00401
   Gupta M., 2012, P 2012 SIAM INT C DA, DOI [10.1137/1.9781611972825.14, DOI 10.1137/1.9781611972825.14]
   Hinton G.E., 2018, P INT C LEARN REPR I
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Jin ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P795, DOI 10.1145/3123266.3123454
   Kaliyar RK, 2021, MULTIMED TOOLS APPL, V80, P11765, DOI 10.1007/s11042-020-10183-2
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Khattar D, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2915, DOI 10.1145/3308558.3313552
   Kouzy R, 2020, CUREUS J MED SCIENCE, V12, DOI 10.7759/cureus.7255
   Kumar A, 2019, MULTIMED TOOLS APPL, V78, P24083, DOI 10.1007/s11042-019-7398-6
   Li QZ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1173
   Liu Y, 2018, AAAI CONF ARTIF INTE, P354
   Ma J., 2018, Rumor Detection on Twitter with Tree-Structured Recursive Neural Networks
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Ma J, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P585, DOI 10.1145/3184558.3188729
   Marra F, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P384, DOI 10.1109/MIPR.2018.00084
   Mihalcea, 2017, AUTOMATIC DETECTION
   Nayak P., 2019, UNDERSTANDING SEARCH
   Ozbay FA, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123174
   Ozbay FA, 2019, ELEKTRON ELEKTROTECH, V25, P62, DOI 10.5755/j01.eie.25.4.23972
   Patrick MK, 2022, J KING SAUD UNIV-COM, V34, P1295, DOI 10.1016/j.jksuci.2019.09.014
   Qi P, 2019, IEEE DATA MINING, P518, DOI 10.1109/ICDM.2019.00062
   Rapoza K., 2017, FORBES
   Roger M, 2019, GOOGLES BERT ROLLS O
   Sabour S, 2017, ADV NEUR IN, V30
   Savyan PV, 2020, MULTIMED TOOLS APPL, V79, P19349, DOI 10.1007/s11042-020-08721-z
   Shu K., 2017, ACM SIGKDD EXPLOR NE, V19, P22, DOI [DOI 10.1145/3137597.3137600, 10.1145/3137597.3137600]
   Shu K, 2020, BIG DATA, V8, P171, DOI 10.1089/big.2020.0062
   Shu K, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P395, DOI 10.1145/3292500.3330935
   Singh SK, 2021, COMPUT SCI INF SYST, V18, P597, DOI 10.2298/CSIS200330012S
   Singhal S, 2020, AAAI CONF ARTIF INTE, V34, P13915
   Singhal S, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P39, DOI [10.1109/BigMM.2019.00-44, 10.1109/BigMM.2019.00018]
   Vaswani A, 2017, ADV NEUR IN, V30
   Vesperini F, 2019, IEEE J-STSP, V13, P310, DOI 10.1109/JSTSP.2019.2902305
   Wang WY, 2017, P 55 ANN M ASS COMPU, DOI DOI 10.18653/V1/P17-2067
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Wang YW, 2020, FRONT PHARMACOL, V10, DOI 10.3389/fphar.2019.01631
   Wu K, 2015, PROC INT CONF DATA, P651, DOI 10.1109/ICDE.2015.7113322
   Wu L, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P637, DOI 10.1145/3159652.3159677
   Yang KH, 2020, CMC-COMPUT MATER CON, V64, P557, DOI 10.32604/cmc.2020.09907
   Yang Y., 2018, Ti-cnn: Convolutional neural networks for fake news detection
   Yin LB, 2019, CMC-COMPUT MATER CON, V60, P275, DOI 10.32604/cmc.2019.05556
   Yu F, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3901
   Zeng JF, 2019, NEUROCOMPUTING, V366, P295, DOI 10.1016/j.neucom.2019.07.085
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
   Zhou X, 2020, Digital Threats: Research and Practice, V1, P1, DOI 10.1145/3377478
   Zhou XY, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3395046
   Zhou XY, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P836, DOI 10.1145/3289600.3291382
NR 60
TC 32
Z9 32
U1 3
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5587
EP 5620
DI 10.1007/s11042-021-11782-3
EA DEC 2021
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000735344900004
PM 34975284
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Zeng, Q
   Adu, JH
   Sun, XY
   Hong, SY
AF Zeng Qiang
   Adu Jianhua
   Sun Xiaoya
   Hong Sunyan
TI Extended complete local binary pattern for texture classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texture classification; ECLBP; Local binary pattern
ID RECOGNITION; SCALE
AB In this paper, an extended complete LBP (ELBP) for texture classification is proposed, in which the local feature vectors are composed of the ratio of the central pixel and its neighborhood pixels to a specific threshold. ECLBP_C represents the gray level of the image, which is obtained by comparing the center pixel with the global threshold. ECLBP_S and ECLBP_M represent the symbol component and the magnitude component of the 3-neighbor region of the center pixel respectively, which are obtained by calculating two binary codes using the original LBP algorithm for the 3-neighbor region of the center pixel. In order to make the proposed algorithm scalable, in addition to the 3-neighbor pixels of the central pixel, the proposed algorithm use the center pixel as the center, r as the radius in the circle with a as the filter's radius to generate extended binary coding, such as ECLBP_ES_r,alpha ECLBP_EM_ r,alpha. In order to describe the local region feature vector in detail, specified ECLBP_ES_r,alpha and ECLBP_EM_r,alpha can be obtained by defining the number of extensions according to actual needs, and then established and concatenated all ECLBP gray histograms for statistics. In the experimental part, we analyze the performance of the proposed algorithm in detail, and prove that the algorithm has good scalability and robustness. The experimental results show that the classification accuracy of the proposed algorithm is up to 99% after 3 expansions in Table 2. The source codes of the proposed algorithm can be downloaded from iittps://github.comkenqiang/ECLBP.git.
C1 [Adu Jianhua; Sun Xiaoya; Hong Sunyan] Kunming Univ, Kunming 650214, Yunnan, Peoples R China.
   [Zeng Qiang] Chengdu Univ Informat Technol, Software Dept, Chengdu 610225, Peoples R China.
   [Zeng Qiang] Sichuan Univ, Coll Cybersecur, Chengdu 610065, Peoples R China.
C3 Kunming University; Chengdu University of Information Technology;
   Sichuan University
RP Adu, JH (corresponding author), Kunming Univ, Kunming 650214, Yunnan, Peoples R China.
EM adujh@126.com
OI , ceng qiang/0009-0002-6938-4877
FU Kunming University [XJ20210005]; Joint Special Fund Project of
   Fundamental Research of Local Undergraduate Universities in Yunnan
   Province; Key scientific Research Project of Sichuan Science and
   Technology Department [18ZA0100]; Young Scholar Leadership Fund of CUIT
   [J201709]
FX This work was supported in part by Kunming University Introduced Talent
   Project (XJ20210005), Joint Special Fund Project of Fundamental Research
   of Local Undergraduate Universities in Yunnan Province, the Key
   scientific Research Project of Sichuan Science and Technology Department
   (18ZA0100) and the Young Scholar Leadership Fund of CUIT (J201709).
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   Chen J, RLBP ROBUST LOCAL BI
   Csurka G., VISUAL CATEGORIZATIO
   Fathi A, 2012, PATTERN RECOGN LETT, V33, P1093, DOI 10.1016/j.patrec.2012.01.017
   Guo YM, 2012, PATTERN RECOGN, V45, P3834, DOI 10.1016/j.patcog.2012.04.003
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Hafiane A, 2007, LECT NOTES COMPUT SC, V4633, P387
   Hayman E, 2004, LECT NOTES COMPUT SC, V2034, P253
   Hazgui M, 2022, VISUAL COMPUT, V38, P457, DOI 10.1007/s00371-020-02028-8
   Hegenbart S, 2015, PATTERN RECOGN, V48, P2633, DOI 10.1016/j.patcog.2015.02.024
   Iakovidis DK, 2008, LECT NOTES COMPUT SC, V5112, P750, DOI 10.1007/978-3-540-69812-8_74
   JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0
   Kou QQ, 2019, OPTIK, V193, DOI 10.1016/j.ijleo.2019.162999
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu L, 2016, IEEE T IMAGE PROCESS, V25, P1368, DOI 10.1109/TIP.2016.2522378
   Liu L, 2012, IMAGE VISION COMPUT, V30, P86, DOI 10.1016/j.imavis.2012.01.001
   Miao XK, 2019, APPL OPTICS, V58, P6504, DOI 10.1364/AO.58.006504
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojansivu V, 2008, INT C PATT RECOG, P3596
   Pan ZB, 2020, MULTIMED TOOLS APPL, V79, P5477, DOI 10.1007/s11042-019-08205-9
   Qi XB, 2014, IEEE T PATTERN ANAL, V36, P2199, DOI 10.1109/TPAMI.2014.2316826
   Ren JF, 2013, IEEE T IMAGE PROCESS, V22, P4049, DOI 10.1109/TIP.2013.2268976
   Shakoor MH, 2021, MULTIMED TOOLS APPL, V80, P8639, DOI 10.1007/s11042-020-10084-4
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tekin R, 2020, MULTIMED TOOLS APPL, V79, P32541, DOI 10.1007/s11042-020-09698-5
   Thompson EM, 2018, PATTERN RECOGN, V82, P1, DOI 10.1016/j.patcog.2018.04.028
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   Xiangsheng Huang, 2004, Proceedings. Third International Conference on Image and Graphics, P184
   Zhang JG, 2002, PATTERN RECOGN, V35, P735, DOI 10.1016/S0031-3203(01)00074-7
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhou LF, 2018, PATTERN RECOGN, V78, P43, DOI 10.1016/j.patcog.2018.01.003
NR 40
TC 1
Z9 1
U1 3
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5389
EP 5405
DI 10.1007/s11042-021-11776-1
EA DEC 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000732496800001
DA 2024-07-18
ER

PT J
AU Yang, YF
   Li, Q
   Xu, ZH
   Feng, HJ
   Chen, YT
AF Yang, Yifan
   Li, Qi
   Xu, Zhihai
   Feng, Huajun
   Chen, Yueting
TI Continuous digital zoom with cross attention for dual camera system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; Image match; Neural networks; Reference-based imaging
ID IMAGE SUPERRESOLUTION
AB Reference-based super-resolution (RefSR) aims to recover realistic textures, when a reference (Ref) image and low-resolution (LR) image are given. Because the Ref images are selected randomly, the quality of RefSR will degrade when the Ref image has less similar content with LR input. In this article,we propose a dual camera system to unleash the potential of RefSR. Additionally, we presents a cross attention mechanism to realize a high-quality digital zoom by using two camera modules with different focal lengths. In dual camera system, shorter focal length module produces the wide-view image with the low resolution. On the other hand, the longer focal length module produces the tele-view image via optical zoom. The long-focal image contains more details than short-focal image and can be used to guide short-focal image to reconstruct high-frequency part. Since the two images are taken from the same scene, we can get better image matching correlation in dual camera system. Inspired by the recent work on reference-based image super-resolution (RefSR), we propose a cross attention mechanism to fuse two images with different focal length and generate more feature correlations within them by texture transferring. Besides, we use segmentation information to improve match accuracy. Instead of using a direct matching between different images, the attention module fully utilizes texture of different levels. Additionally, we present a feature restoration module to reconstruct more image details. Extensive experiments show that Our method achieves state-of-the-art results both quantitatively and qualitatively across different datasets.
C1 [Yang, Yifan; Li, Qi; Xu, Zhihai; Feng, Huajun; Chen, Yueting] Zhejiang Univ, State Key Lab Modern Opt Instrumentat, Hangzhou 310000, Peoples R China.
C3 Zhejiang University
RP Li, Q (corresponding author), Zhejiang Univ, State Key Lab Modern Opt Instrumentat, Hangzhou 310000, Peoples R China.
EM liqi@zju.edu.cn
CR Bai YL, 2018, LECT NOTES COMPUT SC, V11216, P21, DOI 10.1007/978-3-030-01258-8_2
   Ben Fredj H, 2021, VISUAL COMPUT, V37, P217, DOI 10.1007/s00371-020-01794-9
   Bi L, 2018, VISUAL COMPUT, V34, P1043, DOI 10.1007/s00371-018-1519-5
   Boominathan V, 2014, IEEE INT CONF COMPUT
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chen LL, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P349, DOI 10.1145/3126686.3126723
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Freedman G, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1944846.1944852
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Han W, 2018, PROC CVPR IEEE, P1654, DOI 10.1109/CVPR.2018.00178
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   HUANG JB, 2015, PROC CVPR IEEE, P5197, DOI DOI 10.1109/CVPR.2015.7299156
   Gulrajani I, 2017, ADV NEUR IN, V30
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kim SY, 2021, PROC CVPR IEEE, P10606, DOI 10.1109/CVPR46437.2021.01047
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   LU J, 1994, IEEE IMAGE PROC, P482, DOI 10.1109/ICIP.1994.413617
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Mikaeli E, 2020, VISUAL COMPUT, V36, P1573, DOI 10.1007/s00371-019-01756-w
   Nasrollahi K, 2014, MACH VISION APPL, V25, P1423, DOI 10.1007/s00138-014-0623-4
   Oktay Ozan, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9902, P246, DOI 10.1007/978-3-319-46726-9_29
   Shi WL, 2021, VISUAL COMPUT, V37, P1569, DOI 10.1007/s00371-020-01903-8
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Sun L, 2012, INT C COMP PHOT, P1, DOI DOI 10.1109/ICCPHOT.2012.6215221
   Timofte R, 2017, IEEE COMPUT SOC CONF, P1110, DOI 10.1109/CVPRW.2017.149
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Wang XT, 2018, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2018.00070
   Wang YW, 2017, IEEE T VIS COMPUT GR, V23, P2357, DOI 10.1109/TVCG.2016.2628743
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Xu K, 2018, VISUAL COMPUT, V34, P1065, DOI 10.1007/s00371-018-1554-2
   Yang CY, 2014, LECT NOTES COMPUT SC, V8692, P372, DOI 10.1007/978-3-319-10593-2_25
   Yang FZ, 2020, PROC CVPR IEEE, P5790, DOI 10.1109/CVPR42600.2020.00583
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yildirim Deniz, 2012, J. Geod. Geoinf., V1, P75, DOI DOI 10.9733/JGG.170512.1T
   Yue HJ, 2013, IEEE T IMAGE PROCESS, V22, P4865, DOI 10.1109/TIP.2013.2279315
   Zhang CN, 2021, IEEE WINT CONF APPL, P3549, DOI 10.1109/WACV48630.2021.00359
   Zhang HY, 2019, PR MACH LEARN RES, V97
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhang ZF, 2019, PROC CVPR IEEE, P7974, DOI 10.1109/CVPR.2019.00817
   Zheng H., 2017, BMVC, DOI [10.5244/C.31.138, DOI 10.5244/C.31.138]
   Zheng H., 2018, P IEEE EUR C COMP VI, P88
NR 49
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2959
EP 2977
DI 10.1007/s11042-021-11688-0
EA NOV 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000716853000001
DA 2024-07-18
ER

PT J
AU Huo, FC
   Wang, YX
   Ren, WJ
AF Huo, Fengcai
   Wang, Yuanxiong
   Ren, Weijian
TI Improved artificial bee colony algorithm and its application in image
   threshold segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tent mapping; Update strategies; Image threshold; Segmentation; Bee
   colony algorithm
ID PARTICLE SWARM; OPTIMIZATION; SELECTION
AB Image segmentation is a key problem in the field of computer vision, especially in these fields, such as image processing, analysis and understanding. The key of the problem to be solved is how to obtain reasonable threshold according to the different types of images. Based on these, an improved artificial bee colony algorithm based on Tent mapping in chaos theory is proposed and applied to image threshold segmentation. Firstly, a complementary encoding scheme for the artificial bee colony algorithm is constructed from on the Tent map in chaos theory. According to the characteristics between the current solution and the optimal solution, a fixed orientation updating method is proposed in the colony algorithm updating strategy. The difference between 1 and [0, 1] is still in the range of [0, 1], the way adjust the local optimal solution by the complementary properties. All these construct an Improved Artificial Bee Colony based on Tent Mapping (IABCTM) algorithm. Secondly, according to the characteristics of the algorithm, the algorithm is convergent with probability 1. Finally, the improved algorithm is applied to image threshold segmentation. Through the comparison of multiple images, multiple performance parameters and multiple algorithms, the improved algorithm is proved to have a strong ability to obtain the optimal solution and a good convergence performance.
C1 [Huo, Fengcai; Wang, Yuanxiong; Ren, Weijian] Northeast Petr Univ, Dept Elect Informat Engn, Daqing 163318, Heilongjiang, Peoples R China.
   [Huo, Fengcai; Ren, Weijian] Heilongjiang Prov Key Lab Networking & Intelligen, Daqing 163318, Heilongjiang, Peoples R China.
   [Huo, Fengcai] Bohai Rim Energy Res Inst NEPU, Qinhuangdao 066004, Hebei, Peoples R China.
C3 Northeast Petroleum University
RP Wang, YX (corresponding author), Northeast Petr Univ, Dept Elect Informat Engn, Daqing 163318, Heilongjiang, Peoples R China.
EM 495499230@qq.com
OI Wang, YuanXiong/0000-0003-3091-8456
FU National Natural Science Foundation of China [61374127, 51404073];
   Outstanding Youth Science Foundation of National Natural Science
   Foundation of China [61422301]; Chinese Postdoctoral Science Foundation
   [2014M550180]; Scientific Research Fund of Heilongjiang Provincial
   Department of Education [12541090]; Excellent Youth Foundation of
   Heilongjiang Scientific Committee [JC2015016]; Basic scientific research
   business expenses of Heilongjiang Provincial undergraduate Colleges and
   Universities, special scientific research project of shale oil
   [YYYZX202105]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61374127 and 51404073, the Outstanding
   Youth Science Foundation of National Natural Science Foundation of China
   under Grant 61422301, the Chinese Postdoctoral Science Foundation under
   Grant 2014M550180, the Scientific Research Fund of Heilongjiang
   Provincial Department of Education under Grant 12541090, the Excellent
   Youth Foundation of Heilongjiang Scientific Committee JC2015016, and the
   Basic scientific research business expenses of Heilongjiang Provincial
   undergraduate Colleges and Universities, special scientific research
   project of shale oil NO.YYYZX202105.
CR Bai Yang, 2007, Chinese Journal of Medical Imaging Technology, V23, P1402
   Chen Q, 2012, IET IMAGE PROCESS, V6, P426, DOI 10.1049/iet-ipr.2010.0078
   Cooling CM, 2016, ANN NUCL ENERGY, V88, P158, DOI 10.1016/j.anucene.2015.11.001
   Cura T, 2014, COMPUT IND ENG, V74, P270, DOI 10.1016/j.cie.2014.06.004
   Deng Ting-quan, 2011, Control and Decision, V26, P1079
   El Assad S, 2016, SIGNAL PROCESS-IMAGE, V41, P144, DOI 10.1016/j.image.2015.10.004
   [顾晓清 Gu Xiaoqing], 2012, [计算机科学, Computer Science], V39, P284
   Horng MH, 2011, EXPERT SYST APPL, V38, P13785, DOI 10.1016/j.eswa.2011.04.180
   Jeng FG, 2015, SIGNAL PROCESS-IMAGE, V34, P45, DOI 10.1016/j.image.2015.03.003
   [李积英 Li Jiying], 2014, [系统仿真学报, Journal of System Simulation], V26, P926
   Li ZY, 2015, EXPERT SYST APPL, V42, P8881, DOI 10.1016/j.eswa.2015.07.043
   Liang YQ, 2020, INTEGR COMPUT-AID E, V27, P417, DOI 10.3233/ICA-200641
   Liu SQ, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.4892
   Liu W, 2016, APPL OPTICS, V55, P6960, DOI 10.1364/AO.55.006960
   Mohan U, 2017, THEOR COMPUT SCI, V657, P111, DOI 10.1016/j.tcs.2016.09.017
   Ning Ai-ping, 2013, Control and Decision, V28, P1554
   Rosni, 2015, INT J MOD PHYS C, V26, P687
   Stojanovic T, 2015, APPL SOFT COMPUT, V31, P339, DOI 10.1016/j.asoc.2015.03.017
   Tatsumi K, 2015, APPL MATH COMPUT, V269, P904, DOI 10.1016/j.amc.2015.07.098
   Wan J, 2013, J MACH LEARN RES, V14, P2549
   Wang LH, 2017, ENERGY, V130, P1, DOI 10.1016/j.energy.2017.04.115
   Wang YG, 2017, OCEAN ENG, V134, P119, DOI 10.1016/j.oceaneng.2017.02.029
   Wei YT, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9030203
   Wu, 2007, J SHANDONG U ENG SCI, V6, P51
   Xu QZ, 2019, PHYSICA A, V531, DOI 10.1016/j.physa.2019.121808
   Xu QZ, 2019, IMAGE VISION COMPUT, V87, P1, DOI 10.1016/j.imavis.2019.04.002
   Xue WL, 2018, IEEE T CIRC SYST VID, V28, P2849, DOI 10.1109/TCSVT.2017.2720749
   Yong JS, 2019, APPL MATH SER B, V34, P480, DOI 10.1007/s11766-019-3714-1
   Zhang BW, 2016, PROC CVPR IEEE, P2718, DOI 10.1109/CVPR.2016.297
   Zhang SP, 2015, IEEE T CIRC SYST VID, V25, P1749, DOI 10.1109/TCSVT.2015.2406194
   Zhou, 2010, CHIN J IMAGE GRAPH, V15, P255
NR 31
TC 3
Z9 3
U1 2
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2189
EP 2212
DI 10.1007/s11042-021-11644-y
EA OCT 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000709762100001
DA 2024-07-18
ER

PT J
AU Jain, M
   Jaswani, A
   Mehra, A
   Mudgal, L
AF Jain, Minni
   Jaswani, Aman
   Mehra, Ankita
   Mudgal, Laqshay
TI EDGly: detection of influential nodes using game theory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Centrality; Game-theory; Shapely Value (SV);
   Susceptible-Infected-Recovered (SIR) model; EdMot; Ensemble Clustering
   for Graph (ECG)
ID RUMOR SPREADING MODEL; COMPLEX NETWORKS; CENTRALITY; CLOSENESS
AB Identifying those nodes that play a critical role within a network is of great importance. Many applications such as gossip spreading, disease spreading, news dispersion, identifying prominent individuals in a social network, etc. may take advantage of this knowledge in a complex network. The basic concept is generally to identify the nodes with the highest criticality in a network. As a result, the centrality principle has been studied extensively and in great detail, focusing on creating a consistent and accurate location of nodes within a network in terms of their importance. Both single centrality measures and group centrality measures, although, have their certain drawbacks. Other solutions to this problem include the game-theoretic Shapley Value (SV) calculations measuring the effect of a collection of nodes in complex networks via dynamic network data propagation process. Our novel proposed algorithm aims to find the most significant communities in a graph with community structure and then employs the SV-based games to find the most influential node from each community. A Susceptible-Infected-Recovered (SIR) model has been employed to distinctly determine each powerful node's capacity to spread. The results of the SIR simulation have also been used to show the contrast between the spreading capacity of nodes found through our proposed algorithm and that of nodes found using SV-algorithm and centrality measures alone.
C1 [Jain, Minni; Jaswani, Aman; Mehra, Ankita; Mudgal, Laqshay] Delhi Technol Univ, Delhi, India.
C3 Delhi Technological University
RP Jain, M (corresponding author), Delhi Technol Univ, Delhi, India.
EM minnijain@dtu.ac.in; ajaswani11@gmail.com; mehra.ankita99@gmail.com;
   laqshay.mudgal@gmail.com
RI Jain, Minni/HCI-6045-2022
CR Aadithya KV, 2010, LECT NOTES COMPUT SC, V6484, P1, DOI 10.1007/978-3-642-17572-5_1
   Al-garadi MA, 2017, PHYSICA A, V468, P278, DOI 10.1016/j.physa.2016.11.002
   Amati G, 2019, MULTIMED TOOLS APPL, V78, P3395, DOI 10.1007/s11042-018-6728-4
   [Anonymous], 2011, PROC 25 AAAI C ARTIF
   Bhuiyan B.A., 2018, Philos Prog, P111, DOI [DOI 10.3329/PP.V59I1-2.36683, 10.3329/pp.v59i1-2.36683]
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Chee Wei Tan, 2016, 2016 Annual Conference on Information Science and Systems (CISS), P145, DOI 10.1109/CISS.2016.7460492
   Chen W, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P967, DOI 10.1145/3038912.3052608
   Domingos P., 2001, P 7 ACM SIGKDD INT C, P57, DOI [DOI 10.1145/502512.502525, 10.1145/502512.502525]
   FREEMAN LC, 1979, SOC NETWORKS, V1, P215, DOI 10.1016/0378-8733(78)90021-7
   Gao S, 2014, PHYSICA A, V403, P130, DOI 10.1016/j.physa.2014.02.032
   Guo CG, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22020242
   Huang L, 2018, IEEE DATA MINING, P1043, DOI 10.1109/ICDM.2018.00132
   Jiang LC, 2019, PHYSICA A, V516, P58, DOI 10.1016/j.physa.2018.10.011
   Li PZ, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P479, DOI 10.1145/3292500.3330882
   Li PZ, 2019, NEURAL PROCESS LETT, V49, P879, DOI 10.1007/s11063-018-9815-7
   Li PZ, 2018, IEEE ACCESS, V6, P47707, DOI 10.1109/ACCESS.2018.2867549
   Liu FM, 2019, INT J MACH LEARN CYB, V10, P1449, DOI 10.1007/s13042-018-0826-5
   Liu HL, 2018, PHYSICA A, V492, P2237, DOI 10.1016/j.physa.2017.11.138
   Ma LL, 2016, PHYSICA A, V451, P205, DOI 10.1016/j.physa.2015.12.162
   Mao CY, 2018, COMPLEXITY, DOI 10.1155/2018/1528341
   Michalak TP, 2013, J ARTIF INTELL RES, V46, P607, DOI 10.1613/jair.3806
   Ni CQ, 2011, PRO INT CONF SCI INF, P605
   Nie TY, 2016, PHYSICA A, V453, P290, DOI 10.1016/j.physa.2016.02.009
   Opsahl T, 2013, SOC NETWORKS, V35, P159, DOI 10.1016/j.socnet.2011.07.001
   Poulin V, 2018, ARXIV180905578
   Radicchi F, 2004, P NATL ACAD SCI USA, V101, P2658, DOI 10.1073/pnas.0400054101
   Shetty J., 2005, P 3 INT WORKSHOP LIN, P74
   STEPHENSON K, 1989, SOC NETWORKS, V11, P1, DOI 10.1016/0378-8733(89)90016-6
   Tarkowski MK, 2017, ARXIV PREPRINT ARXIV
   Wei H, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0200091
   Yadati N., 2011, Proceedings of the 20th international conference companion on World wide web, P291
   Yang Z, 2016, SCI REP-UK, V6, DOI 10.1038/srep30750
   Zhan Justin, 2017, Journal of Big Data, V4, DOI 10.1186/s40537-017-0076-5
   Zhang XH, 2013, KNOWL-BASED SYST, V42, P74, DOI 10.1016/j.knosys.2013.01.017
   Zhao LJ, 2013, PHYSICA A, V392, P995, DOI 10.1016/j.physa.2012.09.030
NR 36
TC 1
Z9 1
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 1625
EP 1647
DI 10.1007/s11042-021-11440-8
EA OCT 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000705789000002
DA 2024-07-18
ER

PT J
AU Bhardwaj, R
AF Bhardwaj, Rupali
TI Hiding patient information in medical images : an encrypted dual image
   reversible and secure patient data hiding algorithm for E-healthcare
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE E-healtcare; Privacy protection; Paillier cryptosystem; Reversible data
   hiding (RDH)
ID COPYRIGHT PROTECTION; HIGH-CAPACITY; SCHEME; BLIND
AB E-healthcare framework requires transfer of patient report to a specialist in a real time framework. Subsequently, any damage to patient information can prompt a wrong diagnosis that can be deadly for the patient. To guarantee a secure communication in E-healthcare framework, a high capacity dual image reversible data hiding algorithm has been presented in this paper. Highlight of proposed method is to embed.log(2)(2 x n + 1) x NZ - 1. binary bits of patient information whereas no overflow problem has occurred during embedding process. For authentication analysis of electronic patient information (EPI) at recipient end, a fragile watermark has also been embedded with EPI respectively. To prove the effectiveness of proposed method, experiments have been performed on different test images. The average embedding rate of 2.36 bpp for all test images which demonstrates that the method is capable for embedding high payload in comparison of others respectively.
C1 [Bhardwaj, Rupali] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Bhardwaj, R (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
EM rupali.bhardwaj@thapar.edu
CR Bhalerao S, 2019, PATTERN RECOGN LETT, V125, P463, DOI 10.1016/j.patrec.2019.06.004
   Bharathan R, 2020, J OBSTET GYNAECOL, V40, P1138, DOI 10.1080/01443615.2019.1699039
   Bhardwaj R, 2020, PATTERN RECOGN LETT, V139, P60, DOI 10.1016/j.patrec.2018.01.014
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Chi LP, 2018, MULTIMED TOOLS APPL, V77, P8785, DOI 10.1007/s11042-017-4774-y
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P3085, DOI 10.1007/s11042-013-1579-5
   Horng SJ, 2013, J VIS COMMUN IMAGE R, V24, P1099, DOI 10.1016/j.jvcir.2013.07.008
   Kim YS., 2015, Applied Mathematics Information Sciences, V9, P2627, DOI [10.12988/ams.2015.52103, DOI 10.12988/AMS.2015.52103]
   Lee CF, 2013, TELECOMMUN SYST, V52, P2237, DOI 10.1007/s11235-011-9529-x
   Lu TC, 2019, MULTIMED TOOLS APPL, V78, P34397, DOI 10.1007/s11042-019-07904-7
   Lu TC, 2017, MULTIMED TOOLS APPL, V76, P23903, DOI 10.1007/s11042-016-4135-2
   Lu TC, 2015, SIGNAL PROCESS, V115, P195, DOI 10.1016/j.sigpro.2015.03.017
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Mansour RF, 2019, MULTIDIM SYST SIGN P, V30, P791, DOI 10.1007/s11045-018-0575-3
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P3943, DOI 10.1007/s11042-016-4196-2
   Parah SA, 2017, J BIOMED INFORM, V66, P214, DOI 10.1016/j.jbi.2017.01.006
   Rosiyadi D, 2020, 2020 INTERNATIONAL CONFERENCE ON RADAR, ANTENNA, MICROWAVE, ELECTRONICS, AND TELECOMMUNICATIONS (ICRAMET), P343, DOI [10.1109/ICRAMET51080.2020.9298671, 10.1109/icramet51080.2020.9298671]
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Shi YQ, 2005, LECT NOTES COMPUT SC, V3304, P1
   Shiu HJ, 2017, COMPUT METH PROG BIO, V151, P159, DOI 10.1016/j.cmpb.2017.08.015
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Yao H, 2017, SIGNAL PROCESS, V135, P26, DOI 10.1016/j.sigpro.2016.12.029
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 26
TC 4
Z9 4
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 1125
EP 1152
DI 10.1007/s11042-021-11445-3
EA SEP 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000698308700001
DA 2024-07-18
ER

PT J
AU Rajitha, B
   Agarwal, S
AF Rajitha, B.
   Agarwal, Suneeta
TI Segmentation of Epiphysis Region-of-Interest (EROI) using texture
   analysis and clustering method for hand bone age assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bone age assessment; Epiphysis bones; Carpal bones; Age atlas; Wavelet
   packet transformation; Hoteling T2 model; Texture analysis; Homogeneity;
   H-image; Clustering; Mean structure similarity index
ID SKELETAL AGE; AUTOMATIC SEGMENTATION; TANNER; SYSTEM; WHITEHOUSE
AB Human hand Bone Age Assessment (BAA) is commonly used by paediatrics for diagnosing the childs health, crime investigation, dead human identification (in case of natural disasters) etc. BAA can be estimated using Epiphysis and Carpal bones of hand X-ray images. These X-ray images may be prone to noise, due to which it might affect the process of background separation and auto-segmentation while performing BAA. Methods existing in the literature of BAA lack in resolving one or more issues (noise reduction, background separation and bone pixel segmentation) individually. This paper proposes a new method to segment Epiphysis bones using the (i) Wavelet packet transformation for noise suppression, (ii) Background suppression using texture features of the image, (iii) Enhancement of bone pixels using histogram equalization and (iv) Finally segmenting the Epiphysis region of interest using clustering method. Performance analysis is performed using two quantitative evaluation methods i.e. supervised and unsupervised evaluation. Unsupervised approach uses Mean Structure Similarity Index (MSSIM) and Homogeneity. Supervised approach uses Precision, Recall, Sensitivity, Accuracy and Error Rate. Proposed method for segmenting the epiphysis bones has shown better accuracy rate of 0.9701.
C1 [Rajitha, B.; Agarwal, Suneeta] Motilal Nehru Natl Inst Technol Allahabad, Allahabad, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Rajitha, B (corresponding author), Motilal Nehru Natl Inst Technol Allahabad, Allahabad, Uttar Pradesh, India.
EM rajitha@mnnit.ac.in; suneetaa@mnnit.ac.in
RI B, Rajitha/HHR-8738-2022
CR Alshamrani K., 2019, BA, V7
   AlTaani AT, 1996, ICECS 96 - PROCEEDINGS OF THE THIRD IEEE INTERNATIONAL CONFERENCE ON ELECTRONICS, CIRCUITS, AND SYSTEMS, VOLS 1 AND 2, P1088, DOI 10.1109/ICECS.1996.584610
   Bleka O, 2019, INT J LEGAL MED, V133, P1177, DOI 10.1007/s00414-018-1959-5
   Chai HY, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-87
   Chai HY., 2011, INT J MATH MODELS ME, V5, P628
   Cronk C, 1987, ASSESSMENT SKELETAL
   da Silva AMM, 2001, XIV BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P246, DOI 10.1109/SIBGRAPI.2001.963062
   Dahlberg PS, 2019, EUR RADIOL, V29, P2936, DOI 10.1007/s00330-018-5718-2
   Dinesh M. S., 1995, Proceedings of the First Regional Conference, IEEE Engineering in Medicine and Biology Society and 14th Conference of the Biomedical Engineering Society of India. An International Meet (Cat. No.95TH8089), pSPC9, DOI 10.1109/RCEMBS.1995.533064
   El Soufi K, 2013, I CON ADV BIOMED ENG, P171, DOI 10.1109/ICABME.2013.6648875
   Frisch H, 1996, PEDIATR RADIOL, V26, P226, DOI 10.1007/BF01405306
   Gertych A, 2007, COMPUT MED IMAG GRAP, V31, P322, DOI 10.1016/j.compmedimag.2007.02.012
   Giordano D, 2016, COMPUT METH PROG BIO, V124, P138, DOI 10.1016/j.cmpb.2015.10.012
   Hackman L, 2013, J FORENSIC SCI, V58, P732, DOI 10.1111/1556-4029.12077
   Hackman L, 2013, J FORENSIC SCI, V58, pS146, DOI 10.1111/1556-4029.12004
   Halabi SS, 2019, RADIOLOGY, V290, P498, DOI 10.1148/radiol.2018180736
   Han SH, 2009, J FORENSIC SCI, V54, P519, DOI 10.1111/j.1556-4029.2009.01003.x
   Hsieh CW, 2011, OPT ENG, V50, DOI 10.1117/1.3613940
   Hue T.T.M., 2011, Proceedings of the 13th IASME/WSEAS international conference on Mathematical Methods and Computational Techniques in Electrical Engineering conference on Applied Computing, P147
   ISCAN MY, 1984, J FORENSIC SCI, V29, P1094
   Jing F, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P456
   Kashif M, 2016, COMPUT BIOL MED, V68, P67, DOI 10.1016/j.compbiomed.2015.11.006
   Kimmerle EH, 2008, J FORENSIC SCI, V53, P558, DOI 10.1111/j.1556-4029.2008.00711.x
   Lee H, 2017, J DIGIT IMAGING, V30, P427, DOI 10.1007/s10278-017-9955-8
   Lehmann T. M., 2006, The impact of lossless image compression to radiographs, P614516, DOI [10.1117/12.651697, DOI 10.1117/12.651697]
   Mahalakshmi BV., 2014, INT J COMPUT SCI INF, V5, P5003
   Mansourvar M, 2012, MALAYS J COMPUT SCI, V25, P107
   Martell M, 1997, J PERINAT MED, V25, P168, DOI 10.1515/jpme.1997.25.2.168
   Materka A, 1998, TEXTURE ANAL METHODS, P9
   MICHAEL DJ, 1989, IEEE T MED IMAGING, V8, P64, DOI 10.1109/42.20363
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   PIETKA E, 1991, IEEE T MED IMAGING, V10, P616, DOI 10.1109/42.108597
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Rajith B., 2016, Emerging Research in Computing, Information, Communication and Applications, P449, DOI 10.1007/978-81-322-2553-9_41
   Rajitha B, 2015, ICARCSET'15: PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON ADVANCED RESEARCH IN COMPUTER SCIENCE ENGINEERING & TECHNOLOGY (ICARCSET - 2015), DOI 10.1145/2743065.2743081
   Rajitha B, 2015, 2015 IEEE 2ND INTERNATIONAL CONFERENCE ON RECENT TRENDS IN INFORMATION SYSTEMS (RETIS), P200, DOI 10.1109/ReTIS.2015.7232878
   Ren XH, 2019, IEEE J BIOMED HEALTH, V23, P2030, DOI 10.1109/JBHI.2018.2876916
   Reynolds E, 1950, AM J PHYS ANTHROP-NE, V8, P518, DOI 10.1002/ajpa.1330080429
   Schmidt S, 2008, INT J LEGAL MED, V122, P309, DOI 10.1007/s00414-008-0237-3
   Schneider MK, 2000, IEEE T IMAGE PROCESS, V9, P456, DOI 10.1109/83.826782
   Seok J, 2016, EXPERT SYST APPL, V50, P75, DOI 10.1016/j.eswa.2015.12.011
   Stolojescu-Crisan C, 2013, ADV ELECTR COMPUT EN, V13, P85, DOI 10.4316/AECE.2013.03014
   Tanner J, 1997, J PEDIATR-US, V131, P34, DOI 10.1016/S0022-3476(97)90000-7
   Thodberg HH, 2009, IEEE T MED IMAGING, V28, P52, DOI 10.1109/TMI.2008.926067
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Westerberg E, 2020, THESIS BLEKINGE I TE
   Wu ER, 2019, I S BIOMED IMAGING, P1158, DOI [10.1109/isbi.2019.8759332, 10.1109/ISBI.2019.8759332]
   Yildiz M, 2011, J MED SYST, V35, P1485, DOI 10.1007/s10916-009-9425-z
NR 48
TC 0
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 1029
EP 1054
DI 10.1007/s11042-021-11531-6
EA SEP 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000698048600001
DA 2024-07-18
ER

PT J
AU Katarya, R
   Saini, R
AF Katarya, Rahul
   Saini, Rajat
TI Enhancing the wine tasting experience using greedy clustering wine
   recommender system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Clustering techniques; Recommender system;
   Personalization; Wine tasting
ID ARTIFICIAL NEURAL-NETWORKS; DISCRIMINATION; OPTIMIZATION
AB Wine is not just about taste; it represents your class & overall personality. But tasting the same wine for a long time gets boring; sometimes, everyone needs something new, and for that, we usually get advice from friends. But it is not for sure that their taste will match yours and hence you might not like the wine they like. To resolve this issue, we propose the Greedy Clustering Wine Recommender System (GCWRS). This adaptive wine recommendation system uses principal component analysis (PCA) and K-Means clustering algorithms and a novel ranking algorithm using a greedy technique to recommend wines. Along with that, it also uses the elbow method, which helps find out the ideal number of clusters. Together with the clustering algorithm, the recommendation system is tailored in such a way to help all types of users (the first time tasters or regular wine drinkers) as well as the needs of the users (try something new or enhance their current preferences). The clustering model is trained on the wine dataset (with 6497 entries and 12 attributes) combined with the personal preferences of the user, results in an effective personalized recommendation system. The performance of the model is compared with other standard algorithms like K-means clustering, Agglomerative clustering, DBSCAN, Birch clustering algorithm, using performance evaluation functions like the Silhouette coefficient, Calinski-Harabasz Index, and Davies-Bouldin index. Results indicate that our Greedy Clustering Wine Recommender System (GCWRS) provides a better result than other standard algorithms with Silhouette coefficient=0.28, Calinski-Harabasz Index=2207.84, and Davies-Bouldin index=1.36.
C1 [Katarya, Rahul; Saini, Rajat] Delhi Technol Univ, Dept Comp Sci & Engn, Big Data Analyt & Web Intelligence Lab, Delhi 110042, India.
C3 Delhi Technological University
RP Katarya, R (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, Big Data Analyt & Web Intelligence Lab, Delhi 110042, India.
EM rahuldtu@gmail.com; sainirajat500@gmail.com
OI Katarya, Prof. Rahul/0000-0001-7763-291X
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   Al-Hassan M, 2015, DECIS SUPPORT SYST, V72, P97, DOI 10.1016/j.dss.2015.02.001
   Al-Naymat G., 2018, INT J COMPUT APPL, DOI 10.1080/1206212X.2018.1493074
   [Anonymous], 2002, P 19 INT C MACHINE L
   [Anonymous], EXPERT SYST APPL
   Asuncion A., 2007, Uci machine learning repository
   Azaria A, 2013, MOVIE RECOMMENDER SY
   Basu S, 2004, KDD 2004 P 10 ACM SI, DOI 10.1145/1014052.1014062
   Bholowalia P., 2014, EBK-Means: A Clustering Technique based on Elbow Method and K-Means in WSN
   Blackledget J.M., 2006, Digital Signal Processing, V2nd
   Boehmke B., 2020, HANDS ON MACH LEARN, DOI 10.1201/9780367816377-20
   Brandes U, 2003, LECT NOTES COMPUT SC, V2832, P568
   Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564
   BUSONIU L, 2010, STUD COMPUT INTELL
   CARON M, 2018, LECT NOTES COMPUT SC
   Cengizler C., 2017, BR J MATH COMPUT SCI, DOI 10.9734/bjmcs/2017/33729
   Chandak M, 2015, PROCEDIA COMPUT SCI, V45, P23, DOI 10.1016/j.procs.2015.03.075
   Choi SM, 2012, EXPERT SYST APPL, V39, P8079, DOI 10.1016/j.eswa.2012.01.132
   Contreras P., 2015, HDB CLUST ANAL, DOI 10.1201/b19706
   Cortez P, 2006, NEURAL PROCESS LETT, V24, P41, DOI 10.1007/s11063-006-9009-6
   Cortez P, 2009, DECIS SUPPORT SYST, V47, P547, DOI 10.1016/j.dss.2009.05.016
   Craw S., 2017, ENCY MACH LEARN DATA, DOI 10.1007/978-1-4899-7687-1_511
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   De Maesschalck R, 2000, CHEMOMETR INTELL LAB, V50, P1, DOI 10.1016/S0169-7439(99)00047-7
   Eigenvalues and Eigenvectors, 1973, MATH SCI ENG, DOI 10.1016/S0076-5392(08)60533-0
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Eyjolfsdottir E, 2010, COMPUT SCI DEP
   Fasanghari M, 2010, EXPERT SYST APPL, V37, P6138, DOI 10.1016/j.eswa.2010.02.114
   FEO TA, 1995, J GLOBAL OPTIM, V6, P109, DOI 10.1007/BF01096763
   Gaffney S., 1999, Trajectory clustering with mixtures of regression models
   Gokcekus Omer, 2019, Wine Economics and Policy, V8, P171, DOI 10.1016/j.wep.2019.09.003
   Guo XT, 2007, INT J INTELL SYST, V22, P401, DOI 10.1002/int.20206
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Hartuv E, 2000, INFORM PROCESS LETT, V76, P175, DOI 10.1016/S0020-0190(00)00142-3
   Haseeb S, 2019, TRENDS CARDIOVAS MED, V29, P97, DOI 10.1016/j.tcm.2018.06.010
   Hwangbo H, 2018, ELECTRON COMMER R A, V28, P94, DOI 10.1016/j.elerap.2018.01.012
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Jain E, 2015, P 5 IEEE INT C COMP, DOI 10.1109/ICCCT.2014.7001465
   Johnson H., 1989, Vintage: The story of wine
   Kabassi K., 2010, TELEMAT INFORM, DOI 10.1016/j.tele.2009.05.003
   Karkkainen I, 2000, P IASTED INT C SIGN
   KATARYA R, 2017, EGYPT INFORM J
   Kraskov A, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.066138
   Kurmashov N, 2016, P 2015 12 INT C EL C, DOI 10.1109/ICECCO.2015.7416895
   Kustos M, 2019, INT J HOSP MANAG, V83, P180, DOI 10.1016/j.ijhm.2019.04.018
   Legin A, 2003, ANAL CHIM ACTA, V484, P33, DOI 10.1016/S0003-2670(03)00301-5
   Lekakos G, 2008, MULTIMED TOOLS APPL, V36, P55, DOI 10.1007/s11042-006-0082-7
   Li HR, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106593
   Li HR, 2020, SWARM EVOL COMPUT, V58, DOI 10.1016/j.swevo.2020.100743
   Li YM, 2013, DECIS SUPPORT SYST, V55, P740, DOI 10.1016/j.dss.2013.02.009
   Liu B, 2005, CLUSTERING VIA DECIS, DOI 10.1007/11362197_5
   Liu B, 2000, CLUSTERING DECISION, DOI 10.1145/354756.354775
   Lu J, 2011, LECT NOTES COMPUT SC, DOI 10.1007/978-3-642-22961-9_16
   Lu J, 2010, INTERNET RES, V20, P342, DOI 10.1108/10662241011050740
   Lucia SalvatorePablo., 1963, HIST WINE THERAPY
   Mathew P, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON DATA MINING AND ADVANCED COMPUTING (SAPIENCE), P47, DOI 10.1109/SAPIENCE.2016.7684166
   Maulik U, 2000, PATTERN RECOGN, V33, P1455, DOI 10.1016/S0031-3203(99)00137-5
   McGovern P.E., 2003, The origins and ancient history of wine: food and nutrition in history and antropology
   Moreno IM, 2007, TALANTA, V72, P263, DOI 10.1016/j.talanta.2006.10.029
   Pan YT, 2020, WORLD WIDE WEB, V23, P2259, DOI 10.1007/s11280-020-00793-z
   Pan YT, 2019, NEUROCOMPUTING, V332, P137, DOI 10.1016/j.neucom.2018.12.025
   Perbet F, 2009, BR MACH VIS C BMVC 2, DOI 10.5244/C.23.100
   Pomarici Eugenio, 2017, Wine Economics and Policy, V6, P98, DOI 10.1016/j.wep.2017.09.001
   PRIYANKA K, 2015, GLOB C COMM TECHN GC
   Redei GP, 2008, ENCY GENET GENOM PRO, DOI 10.1007/978-1-4020-6754-9_5603
   Risius Antje, 2019, Wine Economics and Policy, V8, P141, DOI 10.1016/j.wep.2019.09.001
   Rong C, 2011, P 2011 3 IEEE INT C, DOI 10.1109/CloudCom.2011.86
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Schubert E, 2017, ACM T DATABASE SYST, V42, DOI 10.1145/3068335
   Sebastia L, 2009, INT J ARTIF INTELL T, V18, P717, DOI 10.1142/S0218213009000378
   Smith BC, 2019, CURR OPIN FOOD SCI, V27, P123, DOI 10.1016/j.cofs.2019.10.007
   Sohail SS, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1609, DOI 10.1109/ICACCI.2013.6637421
   Steinley D, 2004, PSYCHOL METHODS, V9, P386, DOI 10.1037/1082-989X.9.3.386
   Sun LX, 1997, FRESEN J ANAL CHEM, V359, P143, DOI 10.1007/s002160050551
   Syms C., 2018, ENCY ECOL
   Tewari AS, 2014, IEEE INT ADV COMPUT, P500, DOI 10.1109/IAdCC.2014.6779375
   Tweedale J, 2007, J NETW COMPUT APPL, V30, P1089, DOI 10.1016/j.jnca.2006.04.005
   Vlassides S, 2001, BIOTECHNOL BIOENG, V73, P55, DOI 10.1002/1097-0290(20010405)73:1<55::AID-BIT1036>3.0.CO;2-5
   WANG W, 2018, MULTIMED TOOLS APPL
   Winters-Hilt S, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-S7-S18
   Xu C, 2013, PATTERN RECOGN LETT, V34, P505, DOI 10.1016/j.patrec.2012.12.001
   YANG MS, 1993, MATH COMPUT MODEL, V18, P1, DOI 10.1016/0895-7177(93)90202-A
   Yang Z., 2013, APPL DATA MIN, DOI 10.1201/b15027-15
   Yu HY, 2008, J AGR FOOD CHEM, V56, P307, DOI 10.1021/jf0725575
   Zhang B, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P451
   Zhang T, 1996, SIGMOD REC ACM SPEC, DOI 10.1145/235968.233324
NR 86
TC 6
Z9 6
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 807
EP 840
DI 10.1007/s11042-021-11300-5
EA SEP 2021
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000696768700004
DA 2024-07-18
ER

PT J
AU Sharma, N
   Sharma, R
   Jindal, N
AF Sharma, Neha
   Sharma, Reecha
   Jindal, Neeru
TI Prediction of face age progression with generative adversarial networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Generative adversarial networks (GANs); Face age progression; Face
   super-resolution; Age estimation
ID FASHION DESIGN; SIMULATION
AB Face age progression, goals to alter the individual's face from a given face image to predict the future appearance of that image. In today's world that demands more security and a touchless unique identification system, face aging attains tremendous attention. The existing face age progression approaches have the key problem of unnatural modifications of facial attributes due to insufficient prior knowledge of input images and nearly visual artifacts in the generated output. Research has been continuing in face aging to handle the challenge to generate aged faces accurately. So, to solve the issue, the proposed work focuses on the realistic face aging method using AttentionGAN and SRGAN. AttentionGAN uses two separate subnets in a generator. One subnet for generating multiple attention masks and the other for generating multiple content masks. Then attention mask is multiplied with the corresponding content mask along with an input image to finally achieve the desired results. Further, the regex filtering process is performed to separates the synthesized face images from the output of AttentionGAN. Then image sharpening with edge enhancement is done to give high-quality input to SRGAN, which further generates the super-resolution face aged images. Thus, presents more detailed information in an image because of its high quality. Moreover, the experimental results are obtained from five publicly available datasets: UTKFace, CACD, FGNET, IMDB-WIKI, and CelebA. The proposed work is evaluated with quantitative and qualitative methods, produces synthesized face aged images with a 0.001% error rate, and is also evaluated with the comparison to prior methods. The paper focuses on the various practical applications of super-resolution face aging using Generative Adversarial Networks (GANs).
C1 [Sharma, Neha; Sharma, Reecha] Punjabi Univ, Dept Elect & Commun Engn, Patiala 147001, Punjab, India.
   [Jindal, Neeru] Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala 147001, Punjab, India.
C3 Punjabi University; Thapar Institute of Engineering & Technology
RP Sharma, N (corresponding author), Punjabi Univ, Dept Elect & Commun Engn, Patiala 147001, Punjab, India.
EM nehaleo_sharma@yahoo.com; reecha@pbi.ac.in; neeru.jindal@thapar.edu
RI Sharma, Dr. Neha/AAE-6287-2022
OI Sharma, Dr. Neha/0000-0003-3041-9761
CR Albert AM, 2007, FORENSIC SCI INT, V172, P1, DOI 10.1016/j.forsciint.2007.03.015
   [Anonymous], 2013, Face++ Research Toolkit
   Antipov G, 2017, IEEE IMAGE PROC, P2089, DOI 10.1109/ICIP.2017.8296650
   Arjovsky, 2017, ARXIV170104862
   Bando Y, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P166, DOI 10.1109/PCCGA.2002.1167852
   Bessinger Z, 2019, IEEE WINT CONF APPL, P1569, DOI 10.1109/WACV.2019.00172
   Boissieux L, 2000, SPRING COMP SCI, P15
   Bokade GU, 2019, INT CONF COMPUT
   Cui YR, 2018, COMPUT GRAPH FORUM, V37, P109, DOI 10.1111/cgf.13552
   Denton E., 2015, ADV NEURAL INFORM PR, P1, DOI DOI 10.5555/2969239.2969405
   Editorial, 2020, BIOMETRIC TECHNOLOGY, V2020, P1, DOI [10.1016/S0969-4765(20)30042-4, DOI 10.1016/S0969-4765(20)30042-4]
   Elmahmudi A, 2021, VISUAL COMPUT, V37, P2023, DOI 10.1007/s00371-020-01960-z
   Gonog L, 2019, C IND ELECT APPL, P505, DOI [10.1109/ICIEA.2019.8833686, 10.1109/iciea.2019.8833686]
   Goodfellow I., 2014, ADV NEURAL INF PROCE, V27, DOI DOI 10.1145/3422622
   Gusain R., 2018, 2018 3 INT C INT THI, P1, DOI [10.1109/IoT-SIU.2018.8519850, DOI 10.1109/IOT-SIU.2018.8519850]
   Huang YD, 2019, TSINGHUA SCI TECHNOL, V24, P18, DOI 10.26599/TST.2018.9010067
   HWANG U, 2019, ARXIV190209913V2
   Iqbal T, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1072-9
   Gulrajani I, 2017, ADV NEUR IN, V30
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jia Y, 2019, 32 C NEUR INF PROC S, P1
   Karras T, 2018, P INT C LEARN REPR I
   Kemelmacher-Shlizerman I, 2020, ARXIV200309764V2, P1
   Kim T, 2017, PR MACH LEARN RES, V70
   Koudelová J, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0212618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2015, PATTERN RECOGN, V48, P2290, DOI 10.1016/j.patcog.2015.01.021
   Leng L, 2014, SECUR COMMUN NETW, V7, P1860, DOI 10.1002/sec.900
   Leng L, 2011, J NETW COMPUT APPL, V34, P1979, DOI 10.1016/j.jnca.2011.07.003
   Liu LL, 2019, NEUROCOMPUTING, V341, P156, DOI 10.1016/j.neucom.2019.03.011
   Liu M.-Y., 2017, NIPS
   Ma M, 2014, AUTOMATED AGE PROGR
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Marra F, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P384, DOI 10.1109/MIPR.2018.00084
   Martin V, 2019, MULTIMED TOOLS APPL, V78, P6309, DOI 10.1007/s11042-018-6311-z
   Osman AM, 2018, 2018 CONFERENCE ON INFORMATION COMMUNICATIONS TECHNOLOGY AND SOCIETY (ICTAS)
   Rahmi Z, 2019, IEEE 9 TH INT C SYST, DOI [10.1109/ICSEngT, DOI 10.1109/ICSENGT]
   Ramanathan N, 2006, IEEE T IMAGE PROCESS, V15, P3349, DOI 10.1109/TIP.2006.881993
   Ring T, 2020, SCIENCEDIRECT BIOMET, V2020, P3, DOI [10.1016/S0969-4765(20)30127-2, DOI 10.1016/S0969-4765(20)30127-2]
   del Rio JS, 2016, COMPUT SECUR, V62, P49, DOI 10.1016/j.cose.2016.07.001
   Seiver S, 2015, WHAT WOULD YOU LOOK
   Sharma R., 2015, IOSR J COMPUTER ENG, V17, P17
   Shu XB, 2015, IEEE I CONF COMP VIS, P3970, DOI 10.1109/ICCV.2015.452
   Sumathi S., 2010, 2010 International Conference on E-Health Networking, Digital Ecosystems and Technologies (EDT), P195, DOI 10.1109/EDT.2010.5496604
   Sun H, 2019, INTERSPEECH, P2115, DOI 10.21437/Interspeech.2019-1208
   Suo JL, 2012, IEEE T PATTERN ANAL, V34, P2083, DOI 10.1109/TPAMI.2012.22
   Suo JL, 2010, IEEE T PATTERN ANAL, V32, P385, DOI 10.1109/TPAMI.2009.39
   Takano N, 2019, ARXIV190309922V1, P1
   Tang H., 2020, ARXIV191111897V4, P1
   Thengane VG, 2018, IEEE 13 INT C IND IN, DOI [10.1109/ICIINFS, DOI 10.1109/ICIINFS]
   Tiddeman B, 2001, IEEE COMPUT GRAPH, V21, P42, DOI 10.1109/38.946630
   Tolosana Ruben, 2020, Information Fusion, V64, P131, DOI 10.1016/j.inffus.2020.06.014
   Uricar M, 2020, ARXIV190203442V2, P1
   Wang R, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3444
   Wang W, 2019, IEEE T PATTERN ANAL, V41, P654, DOI 10.1109/TPAMI.2018.2803166
   Wang X, 2020, NEURAL COMPUT APPL, V32, P15503, DOI 10.1007/s00521-020-04748-3
   Wang Z., 2020, ARXIV PREPRINT ARXIV
   Wang ZW, 2018, PROC CVPR IEEE, P7939, DOI 10.1109/CVPR.2018.00828
   Wilson S, 2017, HOW EXPERTS USE AGE
   Yang HY, 2021, IEEE T PATTERN ANAL, V43, P499, DOI 10.1109/TPAMI.2019.2930985
   Yang HY, 2016, IEEE T IMAGE PROCESS, V25, P2493, DOI 10.1109/TIP.2016.2547587
   Yunjey Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8185, DOI 10.1109/CVPR42600.2020.00821
   Zhan FN, 2019, PROC CVPR IEEE, P3648, DOI 10.1109/CVPR.2019.00377
   Zhang ZF, 2017, PROC CVPR IEEE, P4352, DOI 10.1109/CVPR.2017.463
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 66
TC 7
Z9 7
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 25
BP 33911
EP 33935
DI 10.1007/s11042-021-11252-w
EA AUG 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WK6LS
UT WOS:000690714100003
PM 34483708
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Gómez-Albarrán, M
   Sarasa-Cabezuelo, A
   Sierra-Rodríguez, JL
   Temprado-Battad, B
AF Gomez-Albarran, Mercedes
   Sarasa-Cabezuelo, Antonio
   Sierra-Rodriguez, Jose-Luis
   Temprado-Battad, Bryan
TI Authoring and playing interactive fiction with conventional web
   technologies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive fiction; Domain-specific language; Authoring tool; Web
   technologies; Digital edition; Digital humanities
ID POSTMORTEM; SYSTEMS
AB This paper presents an approach to the production of web-based interactive fiction, which is grounded in the requirements posed by an expert focus group, and which integrates a domain-specific language (DSL) for interactive fiction (HEXIFE) and an authoring tool for this DSL (IFDBMaker). HEXIFE is an extension of HMTL5 that includes markup specifically devoted to different aspects of interactive fiction, such as hyperlinking, choice points, personalization, stretchtext, annotations, conditional content, and gamification. This DSL, which can be easily extended with new interactive fiction behaviors, is supported by a runtime environment based on conventional web technologies (HTML5, CSS3, JavaScript, Web Components, PHP, and MySQL). IFDBMaker, in turn, piggybacks in a widely used web-based HTML editing framework (TinyMCE) to allow the creation of interactive HEXIFE fiction through a user-friendly approach. A postmortem evaluation shows how: (i) the approach makes the feasibility of supporting interactive fiction on conventional web technologies apparent; and (ii) the approach is a feasible one to actively involve writers in the final production of interactive fiction that are distributed and played through the web.
C1 [Gomez-Albarran, Mercedes; Sarasa-Cabezuelo, Antonio; Sierra-Rodriguez, Jose-Luis; Temprado-Battad, Bryan] Univ Complutense Madrid, Madrid, Spain.
C3 Complutense University of Madrid
RP Sierra-Rodríguez, JL (corresponding author), Univ Complutense Madrid, Madrid, Spain.
EM jlsierra@ucm.es
RI Sierra, Jose Luis/J-6935-2014
OI Sierra, Jose Luis/0000-0002-0317-0510
FU CetrO+Spec research grant [TIN2017-88092-R]; eLITE-CM research grant
   [S2015/HUM-3426]
FX We would like to thank the LEETHI (European and Spanish Literatures:
   From Texts to Hypermedia) research group at the School of Philology at
   the UCM for helping us with the development and postmortem evaluation of
   HEXIFE and IFDBMaker. We would also like to thank Covadonga Diez for her
   participation in the development of a preliminary version of the
   authoring tool. This work has been funded by CetrO+Spec
   (TIN2017-88092-R) and eLITE-CM S2015/HUM-3426 research grants.
CR Adams D, 2019, J HUMANIST MATH, V9, DOI 10.5642/jhummath.201902.05
   [Anonymous], INKLEWRITER TUTORIAL
   [Anonymous], CHOICESCRIPT DOCUMEN
   [Anonymous], 2006, Hypertext 3.0: Critical Theory and New Media in an Era of Globalization
   [Anonymous], 2004, P 4 INT C COMP SEM G
   Anstey J., 2000, Proceedings IEEE Virtual Reality 2000 (Cat. No.00CB37048), P71, DOI 10.1109/VR.2000.840366
   Anwar T., 2019, DATA ENG APPL, P3
   Barbara J, 2020, LECT NOTES COMPUT SC, V12497, P120, DOI 10.1007/978-3-030-62516-0_11
   Bernstein M, 2009, 20TH ACM CONFERENCE ON HYPERTEXT AND HYPERMEDIA (HYPERTEXT 2009), P5
   Birk A, 2002, IEEE SOFTWARE, V19, P43, DOI 10.1109/MS.2002.1003452
   Bizzocchi J., 2007, Loading - The Journal of the Canadian Games Studies Association, V1, P5
   Blasi C, 2013, INTEROPERABILITY EBO
   Bold MR, 2017, LIBR INFORM SCI RES, V39, P16, DOI 10.1016/j.lisr.2017.01.004
   Bradley N., 2002, XML COMPANION, VThird
   Cavazza M, 2006, LECT NOTES COMPUT SC, V4326, P72
   Chang KE, 2003, IEEE T EDUC, V46, P69, DOI 10.1109/TE.2002.808276
   COOMBS JH, 1987, COMMUN ACM, V30, P933, DOI 10.1145/32206.32209
   De Bra P, 1999, ACM COMPUT SURV, V31, pU58
   DELOPE P, ENTERTAIN COMPUT, V38, P429
   Dingsoyr T, 2005, INFORM SOFTWARE TECH, V47, P293, DOI 10.1016/j.infsof.2004.08.008
   Felfernig A, 2011, RECOMMENDER SYSTEMS HANDBOOK, P187, DOI 10.1007/978-0-387-85820-3_6
   Ford M., 2016, Writing Interactive Fiction with Twine, V1st
   Fowler M., 2010, Domain-specific languages
   GARNAUT R, 1992, BUREAUCRACY POLITICS, P1
   Green D, 2020, LECT NOTES COMPUT SC, V12497, P102, DOI 10.1007/978-3-030-62516-0_9
   Green D, 2018, LECT NOTES COMPUT SC, V11318, P501, DOI 10.1007/978-3-030-04028-4_59
   Hargood C, 2018, HT'18: PROCEEDINGS OF THE 29TH ACM CONFERENCE ON HYPERTEXT AND SOCIAL MEDIA, P128, DOI 10.1145/3209542.3209559
   Harrell D Fox, 2014, P 9 INT C FDN DIG GA
   Hausknecht Matthew, 2019, ARXIV190204259
   Herron, 2018, NODE JS WEB DEV
   Holmes, 2014, FDN DIGITAL GAMES 20
   Jadhwani, 2019, GETTING STARTED WEB
   Juan C, 2008, 8TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P233, DOI 10.1109/ICALT.2008.122
   Kitromili Sofia, 2020, HT '20: Proceedings of the 31st ACM Conference on Hypertext and Social Media, P9, DOI 10.1145/3372923.3404798
   Klint P, 2005, ACM T SOFTW ENG METH, V14, P331, DOI 10.1145/1072997.1073000
   Koh SH, 2015, ENCY INFORM SCI TECH, P2278, DOI DOI 10.4018/978-1-4666-5888-2.CH221
   Lawson Bruce., 2011, Introducing HTML5, VSecond
   Linehan Conor, 2014, CHI, P45, DOI DOI 10.1145/2559206.2560472
   Martens C, 2019, LECT NOTES COMPUT SC, V11869, P290, DOI 10.1007/978-3-030-33894-7_29
   Martins AC, 2008, EDUC TECHNOL SOC, V11, P194
   McTear M., 2020, SYNTHESIS LECT HUMAN, V13, P1, DOI [DOI 10.2200/S01060ED1V01Y202010HLT048, 10.2200/S01060ED1V01Y202010HLT048]
   Millard D, 2017, Authoring for interactive storytelling
   Mohamed MH, 2019, PROCEEDINGS OF 2019 INTERNATIONAL CONFERENCE ON INNOVATIVE TRENDS IN COMPUTER ENGINEERING (ITCE 2019), P149, DOI [10.1109/ITCE.2019.8646645, 10.1109/itce.2019.8646645]
   Montfort N., 2011, IF THEORY READER, P25
   Nash S. S., 2018, Moodle 3 E-Learning Course Development: Create highly engaging and interactive e-learning courses with Moodle 3
   Nelson G, 2011, IF THEORY READER, P141
   NIESZ AJ, 1984, CRIT INQUIRY, V11, P110, DOI 10.1086/448277
   Pereira, 2013, E TEALS E J TEACHER, V4, P1
   Pereira J., 2018, E TEALS E J TEACHER, V4, P1
   Pope J, 2009, ART DES COMMUN HIGH, V8, P157, DOI 10.1386/adch.8.2.157/1
   Popov Andrew, 2018, 2018 IEEE 9th International Conference on Dependable Systems, Services and Technologies (DESSERT), P117, DOI 10.1109/DESSERT.2018.8409111
   Porteous J, 2010, ACM T INTEL SYST TEC, V1, DOI 10.1145/1869397.1869399
   Reinking D, 2001, LITERACY AND MOTIVATION, P195
   Revi AT, 2020, LECT NOTES COMPUT SC, V12497, P58, DOI 10.1007/978-3-030-62516-0_5
   Riedl MO, 2013, AI MAG, V34, P67
   Ronn, 2015, INTERACTIVE FICTION
   Cabezuelo AS, 2018, IEEE INT CON INF VIS, P356, DOI 10.1109/iV.2018.00067
   Sierra JL, 2006, COMPUT J, V49, P562, DOI 10.1093/comjnl/bxl008
   Temprado-Battad B, 2019, IEEE INT CON INF VIS, P339, DOI 10.1109/IV.2019.00064
   Van de Mosselaer N, 2018, J LIT THEORY, V12, P279, DOI 10.1515/jlt-2018-0016
   Vassiliou M, 2008, LIBR HI TECH, V26, P355, DOI 10.1108/07378830810903292
   Vrettakis E, 2020, LECT NOTES COMPUT SC, V12497, P349, DOI 10.1007/978-3-030-62516-0_33
   Wang PC, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3852
   Widjajanto W., 2008, Proceedings of the 6th International Conference on Advances in Mobile Computing and Multimedia, P464
   Yao LL, 2019, AAAI CONF ARTIF INTE, P7378
NR 65
TC 3
Z9 4
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 14705
EP 14747
DI 10.1007/s11042-021-11316-x
EA AUG 2021
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000686512900003
DA 2024-07-18
ER

PT J
AU Daoui, A
   Karmouni, H
   Sayyouri, M
   Qjidaa, H
AF Daoui, Achraf
   Karmouni, Hicham
   Sayyouri, Mhamed
   Qjidaa, Hassan
TI Fast and stable computation of higher-order Hahn polynomials and Hahn
   moment invariants for signal and image analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image reconstruction; Signal reconstruction; Discrete orthogonal Hahn
   moments; Numerical stability; Hahn moment invariants; Higher-order
   moments
ID CHARLIER MOMENTS; MEIXNER; CLASSIFICATION
AB This article presents, on the one hand, new algorithms for the fast and stable computation of discrete orthogonal Hahn polynomials of high order (HPs) based on the elimination of all gamma and factorial functions that cause the numerical fluctuations of HPs, and based on the use of appropriate stability conditions. On the other hand, a new method for the fast and numerically stable computation of Hahn moment invariants (HMIs) is also proposed. This method is mainly based on the use of new recursive relations of HPs and of matrix multiplications when calculating HMIs. To validate the efficiency of the algorithms proposed for the calculation of HPs, several signals and large images (>= 4000 x 4000) are reconstructed by Hahn moments (HMs) up to the last order with a reconstruction error tending towards zero (MSE similar or equal to 10(-10)). The efficiency of the proposed method for calculating HMIs is demonstrated on large medical images (2048 x 2048) with a very low relative error (RE similar or equal to 10(-10)). Finally, comparisons with some recent work in the literature are provided.
C1 [Daoui, Achraf; Sayyouri, Mhamed] Sidi Mohamed Ben Abdellah Fez Univ, Natl Sch Appl Sci, Lab Engn Syst & Applicat, Fes, Morocco.
   [Karmouni, Hicham; Qjidaa, Hassan] Sidi Mohamed Ben Abdellah Fez Univ, Fac Sci, Lab Elect Signals & Syst Informat, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP Daoui, A (corresponding author), Sidi Mohamed Ben Abdellah Fez Univ, Natl Sch Appl Sci, Lab Engn Syst & Applicat, Fes, Morocco.
EM achraf.daoui@usmba.ac.ma; hicham.karmouni@usmba.ac.ma; qjidah@yahoo.fr
RI Sayyouri, Mhamed/AAB-5496-2020; DAOUI, Achraf/AAE-7012-2022; Karmouni,
   Hicham/ACB-0232-2022
OI Sayyouri, Mhamed/0000-0002-1615-419X; DAOUI, Achraf/0000-0002-2326-9550;
   Karmouni, Hicham/0000-0001-9225-8380
CR Abdulhussan SH, 2017, IEEE ACCESS, V5, P2470, DOI 10.1109/ACCESS.2017.2669218
   Benouini R, 2019, PATTERN RECOGN, V91, P100, DOI 10.1016/j.patcog.2019.02.014
   Bocci C, 2016, J ALGEBRA, V448, P595, DOI 10.1016/j.jalgebra.2015.10.008
   Camacho-Bello C, 2014, J OPT SOC AM A, V31, P124, DOI 10.1364/JOSAA.31.000124
   Camacho-Bello C, 2018, PATTERN RECOGN LETT, V112, P332, DOI 10.1016/j.patrec.2018.08.020
   Chung KL, 2003, IEEE T IMAGE PROCESS, V12, P648, DOI 10.1109/TIP.2003.812756
   Comtet, 2012, ADV COMBINATORICS AR
   Daoui A., 2020, 2020 INT C INT SYST, P1, DOI DOI 10.1109/ISCV49265.2020.9204132
   Daoui A, 2022, CIRC SYST SIGNAL PR, V41, P166, DOI 10.1007/s00034-021-01764-z
   Daoui A, 2021, SIGNAL PROCESS, V180, DOI 10.1016/j.sigpro.2020.107854
   Daoui A, 2021, MULTIMED TOOLS APPL, V80, P1641, DOI 10.1007/s11042-020-09739-z
   Daoui A, 2020, CIRC SYST SIGNAL PR, V39, P4552, DOI 10.1007/s00034-020-01384-z
   Daoui A, 2020, INFORM SCIENCES, V521, P251, DOI 10.1016/j.ins.2020.02.019
   Ernawan F, 2017, OPTIK, V148, P106, DOI 10.1016/j.ijleo.2017.08.007
   Flusser J., 2016, 2D and 3D image analysis by moments, P1, DOI 10.1002/9781119039402
   Hart J. F., 1978, Computer Approximations
   Hmimid A, 2018, MULTIMED TOOLS APPL, V77, P23607, DOI 10.1007/s11042-018-5623-3
   Hmimid A, 2015, PATTERN RECOGN, V48, P509, DOI 10.1016/j.patcog.2014.08.020
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Jahid T, 2019, MULTIMED TOOLS APPL, V78, P12183, DOI 10.1007/s11042-018-6757-z
   Karakasis EG, 2013, PATTERN RECOGN, V46, P1998, DOI 10.1016/j.patcog.2013.01.008
   Karmouni H, 2019, MULTIMED TOOLS APPL, V78, P31245, DOI 10.1007/s11042-019-07961-y
   Koekoek R, 2010, SPRINGER MONOGR MATH, P1, DOI 10.1007/978-3-642-05014-5_1
   Liu XL, 2017, IEEE T SIGNAL PROCES, V65, P1894, DOI 10.1109/TSP.2017.2652383
   Moody GA, 2001, IEEE ENG MED BIOL, V20, P45, DOI 10.1109/51.932724
   Morales-Mendoza LJ, 2013, SIGNAL PROCESS, V93, P1785, DOI 10.1016/j.sigpro.2013.01.023
   Mukundan R, 2004, IEEE T IMAGE PROCESS, V13, P1055, DOI 10.1109/TIP.2004.828430
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Nikiforov Arnold F, 1991, Springer Series in Computational Physics
   Peleshko D., 2011, 2011 11th International Conference The Experience of Designing and Application of CAD Systems in Microelectronics (CADSM 2011), P263
   Photojournal, PHOTOJOURNAL NASAS I
   Radiopaedia.org, WIK BAS COLL RAD RES
   Rahman SMM, 2016, PATTERN RECOGN, V54, P83, DOI 10.1016/j.patcog.2016.01.003
   Raj PA, 2020, LECT NOTE NETW SYST, V79, P123, DOI 10.1007/978-981-32-9453-0_13
   Rivero-Castillo D, 2015, J COMPUT APPL MATH, V284, P244, DOI 10.1016/j.cam.2014.11.017
   Sayyouri M, 2015, CIRC SYST SIGNAL PR, V34, P875, DOI 10.1007/s00034-014-9881-7
   Sayyouri M, 2013, J OPT SOC AM A, V30, P2381, DOI 10.1364/JOSAA.30.002381
   Singh C, 2012, DIGIT SIGNAL PROCESS, V22, P1031, DOI 10.1016/j.dsp.2012.06.009
   Sit A, 2014, IEEE T IMAGE PROCESS, V23, P2369, DOI 10.1109/TIP.2014.2315923
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Tsougenis ED, 2015, MULTIMED TOOLS APPL, V74, P3985, DOI 10.1007/s11042-013-1808-y
   Xiao B, 2020, INFORM SCIENCES, V516, P545, DOI 10.1016/j.ins.2019.12.044
   Xiao B, 2016, NEUROCOMPUTING, V214, P587, DOI 10.1016/j.neucom.2016.06.050
   Yamni M, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107509
   Yap PT, 2007, IEEE T PATTERN ANAL, V29, P2057, DOI 10.1109/TPAMI.2007.70709
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
   Zhang GJ, 2010, PATTERN RECOGN LETT, V31, P548, DOI 10.1016/j.patrec.2009.12.007
   Zhu H, 2010, IET IMAGE PROCESS, V4, P335, DOI 10.1049/iet-ipr.2009.0195
   Zhu HQ, 2007, PATTERN RECOGN LETT, V28, P1688, DOI 10.1016/j.patrec.2007.04.013
   Zhu HQ, 2007, SIGNAL PROCESS, V87, P687, DOI 10.1016/j.sigpro.2006.07.007
NR 50
TC 7
Z9 7
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32947
EP 32973
DI 10.1007/s11042-021-11206-2
EA AUG 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000684067200001
PM 34393613
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Horst, R
   Naraghi-Taghi-Off, R
   Rau, L
   Dörner, R
AF Horst, Robin
   Naraghi-Taghi-Off, Ramtin
   Rau, Linda
   Doerner, Ralf
TI Back to reality: transition techniques from short HMD-based virtual
   experiences to the physical world
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Virtual Reality; Transitions; Presentation slides; Asymmetric virtual
   environments; Games Engineering; Short VR experiences; Offboarding
AB Every Virtual Reality (VR) experience has to end at some point. While there already exist concepts to design transitions for users to enter a virtual world, their return from the physical world should be considered, as well, as it is a part of the overall VR experience. We call the latter outro-transitions. In contrast to offboarding of VR experiences, that takes place after taking off VR hardware (e.g., HMDs), outro-transitions are still part of the immersive experience. Such transitions occur more frequently when VR is experienced periodically and for only short times. One example where transition techniques are necessary is in an auditorium where the audience has individual VR headsets available, for example, in a presentation using PowerPoint slides together with brief VR experiences sprinkled between the slides. The audience must put on and take off HMDs frequently every time they switch from common presentation media to VR and back. In a such a one-to-many VR scenario, it is challenging for presenters to explore the process of multiple people coming back from the virtual to the physical world at once. Direct communication may be constrained while VR users are wearing an HMD. Presenters need a tool to indicate them to stop the VR session and switch back to the slide presentation. Virtual visual cues can help presenters or other external entities (e.g., automated/scripted events) to request VR users to end a VR session. Such transitions become part of the overall experience of the audience and thus must be considered. This paper explores visual cues as outro-transitions from a virtual world back to the physical world and their utility to enable presenters to request VR users to end a VR session. We propose and investigate eight transition techniques. We focus on their usage in short consecutive VR experiences and include both established and novel techniques. The transition techniques are evaluated within a user study to draw conclusions on the effects of outro-transitions on the overall experience and presence of participants. We also take into account how long an outro-transition may take and how comfortable our participants perceived the proposed techniques. The study points out that they preferred non-interactive outro-transitions over interactive ones, except for a transition that allowed VR users to communicate with presenters. Furthermore, we explore the presenter-VR user relation within a presentation scenario that uses short VR experiences. The study indicates involving presenters that can stop a VR session was not only negligible but preferred by our participants.
C1 [Horst, Robin; Naraghi-Taghi-Off, Ramtin; Rau, Linda; Doerner, Ralf] RheinMain Univ Appl Sci, Kurt Schumacher Ring 18, D-65197 Wiesbaden, Germany.
RP Horst, R (corresponding author), RheinMain Univ Appl Sci, Kurt Schumacher Ring 18, D-65197 Wiesbaden, Germany.
EM robin.horst@hs-rm.de
OI Horst, Robin/0000-0003-1881-8743; Rau, Linda/0000-0001-7165-0041
FU Federal Ministry of Education and Research of Germany in the project
   Innovative Hochschule [03IHS071]
FX Open Access funding enabled and organized by Projekt DEAL. The work is
   supported by the Federal Ministry of Education and Research of Germany
   in the project Innovative Hochschule (funding number: 03IHS071)
CR ADDELMAN S, 1969, AM STAT, V23, P35, DOI 10.2307/2681737
   Anagram, 2020, COLL COLL
   [Anonymous], 1999, INTERACTION, DOI DOI 10.1145/301153.301168
   [Anonymous], 2003, P M C 2003 INT BEW, DOI DOI 10.1097/00001756-200303030-00034
   [Anonymous], 2015, Interaction design: Beyond human-computer interaction
   [Anonymous], 2011, CALIBRATION GAMES MA, DOI DOI 10.1145/2047196.2047248
   Benford S., 1994, Virtual Reality Software and Technology. Proceedings of the VRST '94 Conference, P223
   Bronack S., 2008, International Journal Of Teaching Learning In Higher Education, V20, P59
   Brownridge P, 2020, THESIS ROWAN U GLASS
   Conover W. J., 1998, PRACTICAL NONPARAMET, V3rd
   Deterding S., 2011, P 15 INT AC MINDTREK, P9, DOI [10.1145/2181037.2181040, DOI 10.1145/2181037.2181040]
   Deterding S., 2011, CHI 2011
   FacebookTechnologies L, 2020, OC HLTH SAF DOC OC HLTH SAF DOC
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Hassenzahl M., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P201, DOI 10.1145/332040.332432
   Hassenzahl M., 2018, FUNOLOGY, P301, DOI [10.1007/978-3-319-68213-6_19, DOI 10.1007/978-3-319-68213-6_19]
   Horst R., 2019, P 16 WORKSHOP VIRTUA, P137, DOI [10.2370/9783844068870, DOI 10.2370/9783844068870]
   Horst R, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364261
   Horst R, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P381, DOI 10.1109/ISMAR-Adjunct.2018.00110
   Hovhannisyan G, 2019, LECT NOTES ARTIF INT, V11580, P225, DOI 10.1007/978-3-030-22419-6_17
   HTC Corporation, 2020, HTC VIV COSM PROD DE HTC VIV COSM PROD DE
   HTC Corporation, 2020, HTC VIV PROD DESCR HTC VIV PROD DESCR
   Hug T, 2005, 4 MED TRANS C 4 MED TRANS C, V6
   Igroup Project Consortium, 2020, IGR PRES QUEST IGR PRES QUEST
   Klinker G, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P76, DOI 10.1109/ISMAR.2002.1115076
   MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491
   Mekler ED, 2017, COMPUT HUM BEHAV, V71, P525, DOI 10.1016/j.chb.2015.08.048
   Men L, 2017, P IEEE VIRT REAL ANN, P285, DOI 10.1109/VR.2017.7892288
   Moghadam K.R., 2018, IEEE T VIS COMPUT GR
   NevesCoelho D, 2018, P GI WORKSH VIRT AUG P GI WORKSH VIRT AUG
   Peter M., 2018, Vr-guide: A specific user role for asymmetric virtual reality setups in distributed virtual reality applications
   Schmalstieg D, 2002, PRESENCE-VIRTUAL AUG, V11, P33, DOI 10.1162/105474602317343640
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schubert TW., 2003, Z MEDIEN, V15, P69, DOI [10.1026//1617-6383.15.2.69, DOI 10.1026//1617-6383.15.2.69]
   Slater M, 1998, VIRTUAL ANTEROOM ASS
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Steed A, 2002, IMM PROJ TECHN WORKS IMM PROJ TECHN WORKS
   Steinicke F., 2009, Proceedings of the 6th Symposium on Applied Perception in Graphics and Visualization, P19, DOI 10.1145/1620993.1620998
   Steinicke F, 2010, COMPUT GRAPH-UK, V34, P26, DOI 10.1016/j.cag.2009.12.003
   Steinicke F, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P203, DOI 10.1109/VR.2009.4811024
   Technalysis Research; Statista estimates, 2020, AV SESS TIM VIRT REA AV SESS TIM VIRT REA
   Technologies U, 2020, UN GAM ENG DESCR
   User Interface Design GmbH, 2020, ATTR QUEST ATTR QUEST
   Valkov D, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P12, DOI 10.1145/3131277.3132183
   Van Kerrebroeck H, 2017, VIRTUAL REAL-LONDON, V21, P177, DOI 10.1007/s10055-017-0306-3
NR 45
TC 7
Z9 7
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2021 AUG 2
PY 2021
DI 10.1007/s11042-021-11317-w
EA AUG 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TT4IW
UT WOS:000680314900003
OA hybrid
DA 2024-07-18
ER

PT J
AU Maity, A
   Prakasam, P
   Bhargava, S
AF Maity, Arunit
   Prakasam, P.
   Bhargava, Sarthak
TI Machine learning based KNN classifier: towards robust, efficient DTMF
   tone detection for a Noisy environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DTMF; Machine learning; KNN classifier; Confusion matrix; F1 score;
   Goertzel's algorithm
ID IMAGE RETRIEVAL APPROACH; AUDIO CLASSIFICATION; NEURAL-NETWORKS; FEATURE
   FUSION; SEGMENTATION
AB Owing to the continuous and rapid evolution of telecommunication equipment, the demand for a more efficient and noise-robust detection of Dual-tone multi-frequency (DTMF) signals is conspicuous. In this research article, a novel machine learning based approach to detect DTMF tones perturbed by noise, frequency and time variations by employing the K-Nearest Neighbour (KNN) algorithm is proposed. The features required for training the proposed KNN classifier are extracted using Goertzel's Algorithm employed to estimate the absolute Discrete Fourier Transform (DFT) coefficient values for the fundamental DTMF frequencies with or without their secondary harmonic frequencies. The proposed KNN classifier model is configured in four different manners which differ in being trained with or without augmented data, as well as, with or without inclusion of secondary harmonic frequency DFT coefficient values as features. These models are validated with an unseen test data set created to simulate real-time noise as observed in telecommunication channels. We found that the model which is trained using the augmented dataset and additionally includes the absolute DFT values pertaining to the secondary harmonic frequency values of the eight fundamental DTMF frequencies as the features, achieved the best performance with a macro classification F1 score of 0.980835, a 5-fold stratified cross-validation accuracy of 98.47% and test dataset detection accuracy of 98.1053%. Additionally, the proposed KNN classifier has been compared with existing models to ascertain its superiority and proclaim its state-of-the-art performance. It has proven itself utterly reliable and accurate whilst being relatively lightweight.
C1 [Maity, Arunit; Prakasam, P.; Bhargava, Sarthak] Vellore Inst Technol, Sch Elect Engn, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Prakasam, P (corresponding author), Vellore Inst Technol, Sch Elect Engn, Vellore, Tamil Nadu, India.
EM arunit.maity2017@vitstudent.ac.in; prakasamp@gmail.com;
   sarthak.bhargava2017@vitstudent.ac.in
RI P, Prakasam/B-3075-2016; p, p/JED-5004-2023
OI P, Prakasam/0000-0002-2471-6375; 
CR Ali N, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-1356-9
   [Anonymous], 1993, ITU-T Recommendation G.711
   Bhavanam, 2014, AM AM INT J RES SCI, V1, P6
   Boudraa AO, 2020, DIGIT SIGNAL PROCESS, V104, DOI 10.1016/j.dsp.2020.102770
   Daponte P, 2000, IEE P-SCI MEAS TECH, V147, P34, DOI 10.1049/ip-smt:20000073
   Deosthali AA, 2000, IEEE T SIGNAL PROCES, V48, P911, DOI 10.1109/78.824692
   Esmaeilpour M, 2020, IEEE T INF FOREN SEC, V15, P2147, DOI 10.1109/TIFS.2019.2956591
   Gunawan TS, 2017, Indones J Electr Eng Comput Sci, V6, P422
   Hussein ZH, 2017, J AL QADISIYAH COMPU, V9, P153
   Joseph T., 2019, 2019 GLOBAL C ADVANC, P1, DOI [10.1109/GCAT47503.2019.8978284, DOI 10.1109/GCAT47503.2019.8978284]
   Karim D, 2018, INT J ADV COMPUT SC, V9, P143
   Mirri S, 2020, COMPUTATION, V8, DOI 10.3390/computation8030074
   Nagi J., 2008, 2008 IEEE Joint 6th National Conference on Telecommunication Technologies & 2nd Malaysia Conference on Photonics, P350, DOI 10.1109/NCTT.2008.4814301
   Nur A., 2014, 1 NAT C EL COMM ENG, P66
   Pamuk Z, 2015, P UBT INT C, V97, P109
   Pao TL, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P39
   PARK MJ, 2004, P 30 ANN C IEEE IND, V3, P2058
   Popovic, 2013, FACTA UNIV-SER ELECT, V16, DOI [10.2298/FUEE0303389P, DOI 10.2298/FUEE0303389P]
   Rahmani MH, 2018, DIGIT SIGNAL PROCESS, V82, P54, DOI 10.1016/j.dsp.2018.06.004
   Reddy P. R., 2014, 2014 11 INT C WIR OP, P1
   Rehman B. Khaleelu, 2020, Intelligent Communication, Control and Devices. Proceedings of ICICCD 2018. Advances in Intelligent Systems and Computing (AISC 989), P851, DOI 10.1007/978-981-13-8618-3_87
   Salamon J, 2017, IEEE SIGNAL PROC LET, V24, P279, DOI 10.1109/LSP.2017.2657381
   Trittler S, 2009, DIGIT SIGNAL PROCESS, V19, P628, DOI 10.1016/j.dsp.2008.10.003
   Unar S, 2019, KNOWL-BASED SYST, V179, P8, DOI 10.1016/j.knosys.2019.05.001
   Unar S, 2019, IET IMAGE PROCESS, V13, P515, DOI 10.1049/iet-ipr.2018.5277
   Unar S, 2018, INFORM FUSION, V44, P176, DOI 10.1016/j.inffus.2018.03.006
   Wang CP, 2020, IEEE T CIRC SYST VID, V30, P4440, DOI 10.1109/TCSVT.2019.2960507
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang XY, 2014, PATTERN RECOGN, V47, P3293, DOI 10.1016/j.patcog.2014.04.020
   Yang XK, 2018, DIGIT SIGNAL PROCESS, V81, P8, DOI 10.1016/j.dsp.2018.03.004
   Yeh CY, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9030422
NR 31
TC 2
Z9 3
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29765
EP 29784
DI 10.1007/s11042-021-11194-3
EA JUL 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000672298900001
DA 2024-07-18
ER

PT J
AU Sahu, B
   Das, PK
   Kabat, MR
   Kumar, R
AF Sahu, Bandita
   Das, Pradipta Kumar
   Kabat, Manas Ranjan
   Kumar, Raghvendra
TI Multi-robot cooperation and performance analysis with particle swarm
   optimization variants
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE PSO variants; Twin robot; Path planning; Path deviation; Performance
ID ROBOTS
AB Cooperation and synchronization of multi-robots is a major concern in robotics research field. Two autonomous robots are assumed to carry a stick and called as the twin robots. Different types of Particle Swarm Optimization (PSO) are analyzed for stick carrying task and a brief review of extension and enhancement of PSO is done to identify the parameters used. Path planning of twin robot is done with variants of PSO. Performance of each variant-applied twin is evaluated based on several parameters. These parameters are execution time, number of steps, number of turns, path travelled and path deviated. Fitness value of each twin is calculated in each algorithm to obtain the next position along the solution path. All the algorithms are executed and the pixels are plotted to represent the twin's trajectory and the performance of PSO variants compared with Artificial Bee Colony Optimization (ABCO) and differential Evolutionary (DE) algorithm. It is observed that PSO variants outperforms with respect to distance value.
C1 [Sahu, Bandita; Kabat, Manas Ranjan] VSSUT Burla, Dept Comp Sci & Engn, Sambalpur, India.
   [Das, Pradipta Kumar] VSSUT Burla, Dept Informat Technol, Sambalpur, India.
   [Kumar, Raghvendra] GIET Univ, Dept Comp Sci & Engn, Gunupur, India.
C3 Veer Surendra Sai University of Technology; Veer Surendra Sai University
   of Technology; GIET University
RP Kumar, R (corresponding author), GIET Univ, Dept Comp Sci & Engn, Gunupur, India.
EM bandita.sahu@gmail.com; daspradipta78@gmail.com; manas_kabat@yahoo.com;
   raghvendraagrawal7@gmail.com
RI Bandita, Dr/IAN-5425-2023; Das, Pradipta/G-9294-2019
OI Das, Pradipta/0000-0003-4771-197X
CR [Anonymous], 2014, Int. J. Metaheuristics (IJMHeur), DOI [10.1504/IJMHEUR.2014.068914, DOI 10.1504/IJMHEUR.2014.068914]
   Bhattacharjee P., 2011, NABIC, P219
   Cheng S, 2018, COMPLEX INTELL SYST, V4, P227, DOI 10.1007/s40747-018-0071-2
   Das PK, 2016, ENG SCI TECHNOL, V19, P651, DOI 10.1016/j.jestch.2015.09.009
   Das S, 2008, STUD COMPUT INTELL, V116, P1, DOI 10.1007/978-3-540-78297-1_1
   Desale S., 2015, Int. J. Comput. Eng. Res. Trends, V351, P2349
   Dorigo M., 2008, Scholarpedia, V3, P1486
   Gasparetto A, 2010, ADV ENG SOFTW, V41, P548, DOI 10.1016/j.advengsoft.2009.11.001
   Hongbo S, 2008, CHIN CONTR DEC C IEE, P85
   Hu JW, 2013, UNMANNED SYST, V1, P121, DOI 10.1142/S2301385013500064
   Imran M, 2013, PROCEDIA ENGINEER, V53, P491, DOI 10.1016/j.proeng.2013.02.063
   Jiao B, 2008, CHAOS SOLITON FRACT, V37, P698, DOI 10.1016/j.chaos.2006.09.063
   John XL, 2005, ROBOTS MANIPULATORS
   Jonker CM, 2014, INT C IND ENG OTH AP, P78
   Kan Chaohao, 2013, Computer Engineering and Applications, V49, P23, DOI 10.3778/j.issn.1002-8331.1208-0230
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kenya J, 2014, IEEE INT C SYST MAN, P587
   KOREN Y, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P1398, DOI 10.1109/ROBOT.1991.131810
   Krishna, 2018, COMMUNICATION SECURI, V771
   Lahbib, 2016, DEMOCRATIC INSPIRED, P247
   Patle BK, 2019, DEF TECHNOL, V15, P582, DOI 10.1016/j.dt.2019.04.011
   Rodriguez-Angeles A, 2004, IEEE T CONTR SYST T, V12, P542, DOI 10.1109/TCST.2004.825065
   Shindo T, 2010, IEEE C EV COMP, P189
   Tan Y, 2013, DEF TECHNOL, V9, P18, DOI 10.1016/j.dt.2013.03.001
   Venu GG, 2004, P 2004 C EV COMP IEE, V2, P99
   Xu C, 2013, APPL MECH MAT T TECH, P401
   Zafar MN, 2018, PROCEDIA COMPUT SCI, V133, P141, DOI 10.1016/j.procs.2018.07.018
   Zhang YY, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/807527
   Zhang Y, 2013, NEUROCOMPUTING, V103, P172, DOI 10.1016/j.neucom.2012.09.019
   Zhu H, 2016, MATH PROBL ENG, P58
NR 30
TC 4
Z9 4
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 36907
EP 36930
DI 10.1007/s11042-021-10986-x
EA JUL 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000672298900002
DA 2024-07-18
ER

PT J
AU Padmavathy, TV
   Vimalkumar, MN
   Nagarajan, S
   Babu, GC
   Parthasarathy, P
AF Padmavathy, T., V
   Vimalkumar, M. N.
   Nagarajan, Sivakumar
   Babu, Gokul Chandra
   Parthasarathy, P.
TI Performance analysis of pre-cancerous mammographic image enhancement
   feature using non-subsampled shearlet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mammogram; Nonsubsampled shearlet transform; Speckle noise; Poisson
   noise; PSNR; MSE
AB Breast cancer is the second highest death causing disease in female. From the data it's clear that one of the eight women is affected by breast cancer. The most effective way to detect the cancer is by using mammography technique and also it detects masses and abnormal conditions. The cluster shaped white spots on mammograms are used the cancer in the early stages. The importance of breast cancer detection to reduce different noises which are commonly found in mammogram images and provides better image quality. Here the multi-scale and the multi-directional analysis would produce optimal approximation and detail coefficients of Non-subsampled shearlet transform (NSST). Hence in this paper, the noisy image is amended into piecewise smooth function in different subbands of frequency. NSST coefficients are amended into information and noise related coefficients are noise is removed by using the adaptive threshold. To evaluate the performance of this proposed algorithm, Mean Square Error (MSE) and Peak Signal-to-Noise Ratio (PSNR) are used. Testing these experimental results show that the proposed algorithm can preserve the edges and textures very well while weakening the noise can obtain better suppressed noise and enhances the objective of evaluations than other noise removal methods.
C1 [Padmavathy, T., V] RMK Engn Coll, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
   [Vimalkumar, M. N.] RMD Engn Coll, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
   [Nagarajan, Sivakumar; Babu, Gokul Chandra; Parthasarathy, P.] Vellore Inst Technol, Vellore, Tamil Nadu, India.
C3 R.M.K. Engineering College; Vellore Institute of Technology (VIT); VIT
   Vellore
RP Padmavathy, TV (corresponding author), RMK Engn Coll, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
EM tvpsweeti@gmail.com
RI M N, VIMAL KUMAR/IUP-9835-2023; V, Padmavathy T/AAE-6176-2019; C,
   GOKULNATH/K-8855-2017; T V, Padmavathy/HKV-3958-2023; Panchatcharam,
   Parthasarthy`/AAR-2127-2021; M N, VIMAL KUMAR/V-8518-2019
OI M N, VIMAL KUMAR/0000-0002-2248-6537; V, Padmavathy
   T/0000-0002-2826-3377; C, GOKULNATH/0000-0003-1484-8531; T V,
   Padmavathy/0000-0002-2826-3377; Panchatcharam,
   Parthasarthy`/0000-0003-3771-8350; M N, VIMAL KUMAR/0000-0002-2248-6537;
   m n, vimalkumar/0000-0002-5688-2562; Nagarajan,
   Sivakumar/0000-0002-8945-6412
CR AbuBaker Ayman A., 2015, International Journal of Computer Theory and Engineering, V7, P40, DOI 10.7763/IJCTE.2015.V7.927
   [Anonymous], 2015, INDIAN J SCI TECHNOL
   [Anonymous], 2017, FUTUR GENER COMPUT S
   Balan EV, 2015, 2015 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P185, DOI 10.1109/ICCSP.2015.7322846
   Balan EV, 2015, PROCEDIA COMPUT SCI, V50, P109, DOI 10.1016/j.procs.2015.04.071
   Devi GU, 2015, INDIAN J SCI TECHNOL, V8, DOI 10.17485/ijst/2015/v8i20/49253
   Gokulnath C, 2015, 2015 INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES AND MANAGEMENT FOR COMPUTING, COMMUNICATION, CONTROLS, ENERGY AND MATERIALS (ICSTM), P202, DOI 10.1109/ICSTM.2015.7225414
   Kumar P.M., 2017, COMPUT ELECTR ENG
   Kumar PM, 2019, CLUSTER COMPUT, V22, pS7733, DOI 10.1007/s10586-017-1323-4
   Lopez D, 2017, BIOMED RES, V28, P1
   Manogaran C.T. G., 2017, Exploring the Convergence of Big Data and the Internet of Things, P141
   Manogaran G, 2018, MULTIMED TOOLS APPL, V77, P4379, DOI 10.1007/s11042-017-5515-y
   Priyan M. K., 2018, Cluster Computing, V21, P213, DOI 10.1007/s10586-017-0998-x
   Priyan MK, 2015, 2015 INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES AND MANAGEMENT FOR COMPUTING, COMMUNICATION, CONTROLS, ENERGY AND MATERIALS (ICSTM), P198, DOI 10.1109/ICSTM.2015.7225413
   Rawal BS., WIRELESS PERS COMMUN, P1
   Varatharajan R., 2018, Cluster Computing, V21, P681, DOI 10.1007/s10586-017-0977-2
   Varatharajan R, 2018, MULTIMED TOOLS APPL, V77, P17573, DOI [10.1007/s11042-017-4768-9, 10.1007/s11042-017-5318-1]
NR 17
TC 12
Z9 12
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 26997
EP 27012
DI 10.1007/s11042-018-5951-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000678822000001
DA 2024-07-18
ER

PT J
AU Chebbi, S
   Ben Jebara, S
AF Chebbi, Safa
   Ben Jebara, Sofia
TI Deception detection using multimodal fusion approaches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deception detection; Multimodality; Audio; Video; Text; Feature
   selection; Feature-level fusion; Decision-level fusion; Belief theory
ID INDICATORS; FEATURES; BEHAVIOR; DECEIT; WORDS; TRUTH; CLUES; CUES
AB Automatic deception detection is an important task that has gained a huge interest in different fields due to its potential applications. Particularly, it can improve justice and security in society by helping in detecting deceivers in high-stakes situations across jurisprudence, law enforcement, and national security domains, among others. However, the existing deception detection systems until today are not as accurate as it is expected, which makes their use very risky especially in critical fields. This article outlines an approach for automatically distinguishing between deceit and truth based on audio, video and text modalities and explores the possibility of combining them together in order to detect deception more accurately. First, each modality has been evaluated separately and then a feature and decision-level fusion approaches have been proposed to combine the considered modalities. The proposed feature level fusion approach investigates a diversified feature selection techniques to select the most relevant ones among the whole used feature set, while the decision level fusion approach is based on the belief theory considering information about the certainty degree of each modality. To do so, we used a real-life video dataset of people communicating truthfully or deceptively collected from public american court trials. Unimodal models trained on audio, video and text separately achieved an accuracy rate of 60%, 94% and 58% respectively. When using the feature level fusion approach, the best accuracy deception detection result reaches 93% using only 19 combined features, while a 100% deception recognition rate has been obtained with the decision-level fusion proposed approach, outperforming the results obtained in the literature.
C1 [Chebbi, Safa; Ben Jebara, Sofia] Univ Carthage, SUPCOM, Ariana 2083, Tunisia.
C3 Universite de Carthage
RP Chebbi, S (corresponding author), Univ Carthage, SUPCOM, Ariana 2083, Tunisia.
EM safa.chebbi@supcom.tn; sofia.benjebara@supcom.tn
CR Abouelenien M, 2017, IEEE T INF FOREN SEC, V12, P1042, DOI 10.1109/TIFS.2016.2639344
   Abouelenien Mohamed., 2014, P 16 INT C MULTIMODA, P58
   Adelson R., 2004, APA Monitor Psychol., V35, P70
   Ahmad K, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3199668
   [Anonymous], 2000, Detecting lies and deceit: the psychology of lying and implications for professional practice
   Avola D, 2020, PATTERN RECOGN LETT, V138, P455, DOI 10.1016/j.patrec.2020.08.014
   Baltrusaitis T, 2016, IEEE WINT CONF APPL
   Ben-Shakhar G., 2002, HDB POLYGRAPH TESTIN, P103, DOI DOI 10.1037/0021-9010.90.1.147
   Bond CF, 2006, PERS SOC PSYCHOL REV, V10, P214, DOI 10.1207/s15327957pspr1003_2
   BURGOON JK, 1989, HUM COMMUN RES, V16, P217, DOI 10.1111/j.1468-2958.1989.tb00210.x
   Burgoon JK, 2009, IEEE T INTELL TRANSP, V10, P103, DOI 10.1109/TITS.2008.2011700
   Caso L, 2006, J NONVERBAL BEHAV, V30, P1, DOI 10.1007/s10919-005-0001-z
   Chebbi, 2020, P INT JOINT C COMP V, P1
   Chebbi S, 2018, 2018 4 INT C ADV TEC, P1
   Chebbi S, 2018, 9TH INTERNATIONAL SYMPOSIUM ON SIGNAL, IMAGE, VIDEO AND COMMUNICATIONS (ISIVC 2018), P82, DOI 10.1109/ISIVC.2018.8709233
   Cohen D, 2010, SEMIOTICA, V182, P133, DOI 10.1515/semi.2010.055
   Conroy N. J., 2015, P ASS INFORM SCI TEC, V52, P1, DOI 10.1002/pra2.2015.145052010082
   Crockett K, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207684
   De Silva L. C., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P332, DOI 10.1109/AFGR.2000.840655
   DePaulo BM, 2003, PSYCHOL BULL, V129, P74, DOI 10.1037//0033-2909.129.1.74
   Dibazar AA, 2002, P ANN INT IEEE EMBS, P182, DOI 10.1109/IEMBS.2002.1134447
   EKMAN P, 1991, J NONVERBAL BEHAV, V15, P125, DOI 10.1007/BF00998267
   EKMAN P, 1969, PSYCHIATR, V32, P88, DOI 10.1080/00332747.1969.11023575
   EKMAN P, 1972, J COMMUN, V22, P353, DOI 10.1111/j.1460-2466.1972.tb00163.x
   Ekman P., 2001, TELLING LIES CLUES D, V2nd
   Ekman P., 1976, SEMIOTICA, V16, P23
   Eyben F., 2015, ACM SIGMULTIMEDIA RE, V6, P4, DOI [10.1145/2729095.2729097, DOI 10.1145/2729095.2729097]
   Feng S., 2012, P 50 ANN M ASS COMP, V2, P171
   FORKOSCH MD, 1975, OKLA LAW REV, V28, P288
   Francis ME., 1993, LINGUISTIC INQUIRY W
   Gogate M, 2017, 2017 IEEE S SERIES C, P1, DOI [DOI 10.1109/SSCI.2017.8285382, 10.1109/SSCI.2017.8285382]
   Granhag PA., 2004, DETECTION DECEPTION, DOI [10.1017/CBO9780511490071, DOI 10.1017/CBO9780511490071]
   Hartwig M, 2006, LAW HUMAN BEHAV, V30, P603, DOI 10.1007/s10979-006-9053-9
   Hassan SZ, 2019, LECT NOTES COMPUT SC, V11752, P104, DOI 10.1007/978-3-030-30645-8_10
   Hirschberg J., 2005, INTERSPEECH 2005 LIS, P1833, DOI DOI 10.1159/.8634
   Honts, 1987, J PSYCHOPHYSIOL
   Jaiswal M, 2016, INT CONF DAT MIN WOR, P938, DOI [10.1109/ICDMW.2016.0137, 10.1109/ICDMW.2016.156]
   Jensen ML, 2010, GROUP DECIS NEGOT, V19, P367, DOI 10.1007/s10726-009-9171-0
   Jensen ML, 2005, 2005 IEEE Intelligent Transportation Systems Conference (ITSC), P1135
   Jordan S, 2019, J INVEST PSYCHOL OFF, V16, P222, DOI 10.1002/jip.1532
   Karimi H, 2018, IEEE INT CONF BIG DA, P1278, DOI 10.1109/BigData.2018.8621909
   Kirchhübel C, 2013, APPL ERGON, V44, P694, DOI 10.1016/j.apergo.2012.04.016
   Kohnken G, 1996, APPL SOCIAL PSYCHOL, P257, DOI DOI 10.4135/9781446250556.N10
   Lee, 1975, HOUS L REV, V13, P551
   Levitan SI, 2018, INTERSPEECH, P416
   Levitan SI, 2016, INTERSPEECH, P2006, DOI 10.21437/Interspeech.2016-1519
   Lu Shan., 2005, Proceedings of the Hawaii International Conference on System Sciences, p20c
   Lv XQ, 2007, 2007 INTERNATIONAL CONFERENCE ON INFORMATION ACQUISITION, VOLS 1 AND 2, P4, DOI 10.1109/ICIA.2007.4295687
   Maschke, 2005, LIE LIE DETECTOR ANT
   Masip J, 2012, SCAND J PSYCHOL, V53, P103, DOI 10.1111/j.1467-9450.2011.00931.x
   Mbaziira, 2016, P INT C TECHN MAN
   Mendels G, 2017, INTERSPEECH, P1472, DOI 10.21437/Interspeech.2017-1723
   Meservy TO, 2005, IEEE INTELL SYST, V20, P36, DOI 10.1109/MIS.2005.85
   Mihalcea Rada, 2009, P ACL IJCNLP 2009 C, P309, DOI [10.3115/1667583.1667679, DOI 10.3115/1667583.1667679]
   Motley M.T., 1974, Western Speech, V38, P81
   Newman ML, 2003, PERS SOC PSYCHOL B, V29, P665, DOI 10.1177/0146167203029005010
   Nunamaker J. F., 2012, Proceedings of the 2012 IEEE International Conference on Intelligence and Security Informatics. Cyberspace, Border, and Immigration Securities (ISI 2012), P202, DOI 10.1109/ISI.2012.6284309
   Owayjan M, 2012, 2012 2ND INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTATIONAL TOOLS FOR ENGINEERING APPLICATIONS (ACTEA), P33, DOI 10.1109/ICTEA.2012.6462897
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Pérez-Rosas V, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P59, DOI 10.1145/2818346.2820758
   Perez-Rosas Veronica., 2015, Proceedings of the 2015 conference on empirical methods in natural language processing, P2336
   Porter S, 1996, LAW HUMAN BEHAV, V20, P443, DOI 10.1007/BF01498980
   Porter S, 2010, LEGAL CRIMINOL PSYCH, V15, P57, DOI 10.1348/135532509X433151
   Qi J, 2020, INFORM FUSION, V55, P269, DOI 10.1016/j.inffus.2019.09.002
   Qin T, 2004, P 37 ANN HAW INT C S, P23, DOI DOI 10.1109/HICSS.2004.1265083
   Randhavane T, 2019, ARXIV191206874
   Rill-García R, 2019, IEEE COMPUT SOC CONF, P1565, DOI 10.1109/CVPRW.2019.00198
   Schuetze P, 2001, INFANCY, V2, P483, DOI 10.1207/S15327078IN0204_06
   Sen MU, 2022, IEEE T AFFECT COMPUT, V13, P306, DOI 10.1109/TAFFC.2020.3015684
   Shafer G., 1976, MATH THEORY EVIDENCE, DOI DOI 10.1515/9780691214696
   Sharma R, 2002, ADV IMAGE PROCESSING, P349, DOI [DOI 10.1142/9789812776952-_}0014, DOI 10.1142/5042]
   Sondhi Savita., 2016, 2016 11th International Conference on Knowledge, Information and Creativity Support Systems (KICSS), P1, DOI DOI 10.1109/KICSS.2016.7951455
   Sporer SL, 1997, APPL COGNITIVE PSYCH, V11, P373
   Steller M., 1989, PSYCHOL METHODS CRIM, P217
   STREETER LA, 1977, J PERS SOC PSYCHOL, V35, P345, DOI 10.1037/0022-3514.35.5.345
   Su L, 2014, INT C PATT RECOG, P2519, DOI 10.1109/ICPR.2014.435
   Talkin D., 1995, Speech coding and synthesis, V495, P518
   Tausczik YR, 2010, J LANG SOC PSYCHOL, V29, P24, DOI 10.1177/0261927X09351676
   Thannoon HH., 2019, Journal of Engineering and Applied Sciences, V14, P5002, DOI DOI 10.36478/JEASCI.2019.5002.5011
   Tian YL, 2005, HANDBOOK OF FACE RECOGNITION, P247, DOI 10.1007/0-387-27257-7_12
   Tree JEF, 2002, DISCOURSE PROCESS, V34, P37, DOI 10.1207/S15326950DP3401_2
   Tsechpenakis G, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P824, DOI 10.1109/ICME.2005.1521550
   Undeutsch, 1967, HDB PSYCHOL, V11, P26
   UNDEUTSCH U, 1989, NATO ADV SCI I D-BEH, V47, P101
   Ververidis D, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P593
   Vrij A, 2000, J NONVERBAL BEHAV, V24, P239, DOI 10.1023/A:1006610329284
   Vrij A, 1996, J NONVERBAL BEHAV, V20, P65, DOI 10.1007/BF02248715
   Vrij A, 1998, PSYCHOL LAW TRUTHFUL, P32
   Wagner J., 2009, Proceedings of the 3rd International Conference on Affective Computing and Intelligent Interaction (ACII), DOI DOI 10.1109/ACII.2009.5349571
   Wilcox, 2009, INT J POLICE SCI MAN
   Wilson N., 1993, Symbolic and Quantitative Approaches to Reasoning and Uncertainty. European Conference ECSQARU '93 Proceedings, P364, DOI 10.1007/BFb0028222
   Wu Z, 2018, AAAI CONF ARTIF INTE, P1695
   Yuzsever S., 2015, Mutual information based feature selection for acoustic autism diagnosis
   Zhang JX, 2020, INTERSPEECH, P359, DOI 10.21437/Interspeech.2020-2320
   Zhou L., 2003, SYSTEM SCI, P10, DOI DOI 10.1109/HICSS.2003.1173793
   Zloteanu, 2019, EMOTION RECOGNITION
NR 96
TC 7
Z9 7
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13073
EP 13102
DI 10.1007/s11042-021-11148-9
EA JUN 2021
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000668056500001
DA 2024-07-18
ER

PT J
AU Guo, L
   Fan, GL
AF Guo, Lin
   Fan, Guoliang
TI Holistic indoor scene understanding by context-supported instance
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic labeling; Object detection; Instance segmentation; RGB-D; Deep
   learning
AB We propose a new method flow that utilizes pixel-level labeling information for instance-level object detection in indoor scenes from RGB-D data. Semantic labeling and instance segmentation are two different paradigms for indoor scene understanding that are usually accomplished separately and independently. We are interested in integrating the two tasks in a synergistic way in order to take advantage of their complementary nature for comprehensive understanding. Our work can capitalize on any deep learning networks used for semantic labeling by treating the intermediate layer as the category-wise local detection output, from which instance segmentation is optimized by jointly considering both the spatial fitness and the relational context encoded by three graphical models, namely, the vertical placement model (VPM), horizontal placement model (HPM) and non-placement model (NPM). VPM, HPM and NPM represent three common but distinct indoor object placement configurations: vertical, horizontal and hanging relationships, respectively. Experimental results on two standard RGB-D datasets show that our method can significantly improve small object segmentation with promising overall performance that is competitive with the state-of-the-art methods.
C1 [Guo, Lin; Fan, Guoliang] Oklahoma State Univ Stillwater, Stillwater, OK 74078 USA.
C3 Oklahoma State University System; Oklahoma State University - Stillwater
RP Fan, GL (corresponding author), Oklahoma State Univ Stillwater, Stillwater, OK 74078 USA.
EM lin.guo@okstate.edu; guoliang.fan@okstate.edu
RI Fan, Guoliang/G-2893-2011
OI Fan, Guoliang/0000-0002-8584-9040
FU US National Institutes of Health (NIH) [R15 AG061833]; Oklahoma Center
   for the Advancement of Science and Technology (OCAST) Health Research
   Grant [HR18-069]
FX This work is supported in part by the US National Institutes of Health
   (NIH) Grant R15 AG061833 and the Oklahoma Center for the Advancement of
   Science and Technology (OCAST) Health Research Grant HR18-069.
CR Abdulnabi AH, 2018, IEEE T MULTIMEDIA, V20, P1656, DOI 10.1109/TMM.2017.2774007
   [Anonymous], 2019, ARXIV190204478
   Bellver M, 2020, MULTIMED TOOLS APPL, V79, P25551, DOI 10.1007/s11042-020-09235-4
   Cabral R, 2014, PROC CVPR IEEE, P628, DOI 10.1109/CVPR.2014.546
   Chen X, 2017, IEEE PHOTON CONF
   Choi MJ, 2012, IEEE T PATTERN ANAL, V34, P240, DOI 10.1109/TPAMI.2011.119
   Choi MJ, 2010, PROC CVPR IEEE, P129, DOI 10.1109/CVPR.2010.5540221
   CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Deng Z, 2017, PROC CVPR IEEE, P398, DOI 10.1109/CVPR.2017.50
   Ding XM, 2016, IEEE T MULTIMEDIA, V18, P1616, DOI 10.1109/TMM.2016.2572000
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Furukawa Y, 2009, PROC CVPR IEEE, P1422, DOI 10.1109/CVPRW.2009.5206867
   Gao MY, 2019, MULTIMED TOOLS APPL, V78, P27383, DOI 10.1007/s11042-019-07858-w
   Graham B, 2018, PROC CVPR IEEE, P9224, DOI 10.1109/CVPR.2018.00961
   Guo, 2019, P CVPR WORKSH
   Guo, 2019, P ICIP
   Guo Lin, 2017, P VCIP
   Hayat M, 2016, IEEE T IMAGE PROCESS, V25, P4829, DOI 10.1109/TIP.2016.2599292
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Ikehata S, 2015, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2015.156
   Jian M, 2016, IEEE T MULTIMEDIA, V18, P458, DOI 10.1109/TMM.2016.2515367
   Jian M, 2014, IEEE T MULTIMEDIA, V16, P413, DOI 10.1109/TMM.2013.2291657
   Jiang H, 2013, PROC CVPR IEEE, P2171, DOI 10.1109/CVPR.2013.282
   Lahoud J, 2019, IEEE I CONF COMP VIS, P9255, DOI 10.1109/ICCV.2019.00935
   Lempitsky V, 2009, IEEE I CONF COMP VIS, P277, DOI 10.1109/ICCV.2009.5459262
   Lewis RM, 2000, J COMPUT APPL MATH, V124, P191, DOI 10.1016/S0377-0427(00)00423-4
   Li W, 2019, MECH AGEING DEV, V181, P1, DOI 10.1016/j.mad.2019.05.001
   Li Y, 2019, IEEE T MULTIMEDIA, V21, P875, DOI 10.1109/TMM.2018.2867720
   Li Z, 2016, LECT NOTES COMPUT SC, V9906, P541, DOI 10.1007/978-3-319-46475-6_34
   Liu RS, 2018, INT J DIGIT MULTIMED, V2018, DOI [10.1155/2018/7543875, 10.1109/TMM.2018.2812605]
   Liu Y, 2018, IEEE CONF COMPUT
   Liu Y, 2015, MULTIMED TOOLS APPL, V74, P543, DOI 10.1007/s11042-014-1967-5
   Lv X, 2017, MULTIMED TOOLS APPL, V76, P4273, DOI 10.1007/s11042-016-3375-5
   Narita G, 2019, IEEE INT C INT ROBOT, P4205, DOI [10.1109/IROS40897.2019.8967890, 10.1109/iros40897.2019.8967890]
   Pinheiro PO, 2015, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2015.7298780
   Qi CR, 2019, IEEE I CONF COMP VIS, P9276, DOI 10.1109/ICCV.2019.00937
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   REN Z, 2016, PROC CVPR IEEE, P1525, DOI DOI 10.1109/CVPR.2016.169
   Ries CX, 2016, MULTIMED TOOLS APPL, V75, P6091, DOI 10.1007/s11042-014-2434-z
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shaikh R.A., 2018, MULTIMEDIA TOOLS APP, P1
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Song SR, 2016, PROC CVPR IEEE, P808, DOI 10.1109/CVPR.2016.94
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Song Shuran, 2018, CVPR
   Tang S., 2012, P ACCV
   Wu LS, 2018, MULTIMED TOOLS APPL, V77, P21185, DOI 10.1007/s11042-017-5576-y
   Xiao J., 2014, IJCV, V110, p3 243 258, DOI 10.1007/s11263-014-0711
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Xiao Z., 2020, Multimedia Tools Appl., V79, P1
   Xu DF, 2018, PROC CVPR IEEE, P244, DOI 10.1109/CVPR.2018.00033
   Yang B, 2019, ADV NEUR IN, V32
   Zhang YD, 2017, IEEE I CONF COMP VIS, P1201, DOI 10.1109/ICCV.2017.135
   Zhang YS, 2021, MULTIMED TOOLS APPL, V80, P23255, DOI 10.1007/s11042-020-09336-0
   Zheng Y, 2017, MULTIMED TOOLS APPL, V76, P4427, DOI 10.1007/s11042-016-3423-1
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 59
TC 2
Z9 2
U1 9
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 35751
EP 35773
DI 10.1007/s11042-021-11145-y
EA JUN 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000667012400002
DA 2024-07-18
ER

PT J
AU Aivatoglou, G
   Anastasiadis, M
   Spanos, G
   Voulgaridis, A
   Votis, K
   Tzovaras, D
   Angelis, L
AF Aivatoglou, Georgios
   Anastasiadis, Mike
   Spanos, Georgios
   Voulgaridis, Antonis
   Votis, Konstantinos
   Tzovaras, Dimitrios
   Angelis, Lefteris
TI A RAkEL-based methodology to estimate software vulnerability
   characteristics & score-an application to EU project ECHO
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Software vulnerabilities; Multi-target classification; Cybersecurity;
   Machine learning
ID CLASSIFICATION; VRSS
AB Software vulnerabilities constitute a critical threat for cybersecurity analysts in the contemporary society, since the successfully exploited vulnerabilities could harm any system in terms of Confidentiality, Integrity and Availability. Similarly, the characterization of vulnerabilities and the assessment of vulnerability risk is a crucial task for cybersecurity managers regarding the resource management. However, the proliferation of software vulnerabilities causes problems related to the response time of the security experts. For this reason, a methodology based on RAndom k-labELsets (RAkEL) is proposed in this paper in order to estimate software vulnerability characteristics and score from the vulnerability technical description. The proposed methodology aims to a) improve an existing multi-target methodology and b) be integrated in a Cyber Threat Intelligence (CTI) information sharing system. The results, in a dataset containing more than 130000 vulnerabilities, clearly proved that the proposed methodology could improve the existing methodology regarding the estimation of vulnerability characteristics and score.
C1 [Aivatoglou, Georgios; Anastasiadis, Mike; Spanos, Georgios; Voulgaridis, Antonis; Votis, Konstantinos; Tzovaras, Dimitrios] Ctr Res & Technol Hellas, Informat Technol Inst, Thessaloniki, Greece.
   [Angelis, Lefteris] Aristotle Univ Thessaloniki, Sch Informat, Thessaloniki, Greece.
C3 Centre for Research & Technology Hellas; Aristotle University of
   Thessaloniki
RP Aivatoglou, G (corresponding author), Ctr Res & Technol Hellas, Informat Technol Inst, Thessaloniki, Greece.
EM aivatoglou@iti.gr; manastas@iti.gr; gspanos@iti.gr; antonismv@iti.gr;
   kvotis@iti.gr; Dimitrios.Tzovaras@iti.gr; lef@csd.auth.gr
RI Tzovaras, Dimitrios/ABB-9576-2021; Spanos, Georgios/AFV-4694-2022
OI Tzovaras, Dimitrios/0000-0001-6915-6722; Spanos,
   Georgios/0000-0002-2804-385X; Voulgaridis, Antonis/0000-0003-4012-8511
FU European Union's Horizon 2020 Research and Innovation Programme through
   ECHO [830943]
FX This work is partially funded by the European Union's Horizon 2020
   Research and Innovation Programme through ECHO (https://echonetwork.eu/)
   project under Grant Agreement No. 830943. This paper reflects only the
   authors views. The European Union is not liable for any use that may be
   made of the information contained therein.
CR Bodungen C., 2019, IND VULNERABILITY SC
   Bogaert M, 2016, DECIS SUPPORT SYST, V82, P26, DOI 10.1016/j.dss.2015.11.003
   Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655
   Chen JF, 2020, J SYST SOFTWARE, V167, DOI 10.1016/j.jss.2020.110616
   Cisco CIAG, 2005, CISC VIS NETW IND GL
   Dembczynski K, 2012, MACH LEARN, V88, P5, DOI 10.1007/s10994-012-5285-8
   First O., 2015, COMMON VULNERABILITY
   Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14, P771
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   Huang GY, 2019, IEEE ACCESS, V7, P28291, DOI 10.1109/ACCESS.2019.2900462
   Hyndman RJ, 2006, INT J FORECASTING, V22, P679, DOI 10.1016/j.ijforecast.2006.03.001
   Kai Liu, 2019, 2019 5th International Conference on Big Data and Information Analytics (BigDIA). Proceedings, P114, DOI 10.1109/BigDIA.2019.8802851
   Kudjo PK, 2020, SOFTWARE QUAL J, V28, P1413, DOI 10.1007/s11219-019-09490-1
   Kudjo PK, 2019, 2019 IEEE 19TH INTERNATIONAL CONFERENCE ON SOFTWARE QUALITY, RELIABILITY AND SECURITY (QRS 2019), P248, DOI 10.1109/QRS.2019.00041
   Liu CH, 2012, LECT NOTES ARTIF INT, V7197, P274, DOI 10.1007/978-3-642-28490-8_29
   Liu QX, 2012, J SYST SOFTWARE, V85, P1699, DOI 10.1016/j.jss.2012.03.057
   Liu QX, 2011, COMPUT COMMUN, V34, P264, DOI 10.1016/j.comcom.2010.04.006
   Meire M, 2016, DECIS SUPPORT SYST, V89, P98, DOI 10.1016/j.dss.2016.06.013
   Mell P., 2007, 1 FORUM INCIDENT RES, P23
   Miyamoto D, 2015, 2015 4TH INTERNATIONAL WORKSHOP ON BUILDING ANALYSIS DATASETS AND GATHERING EXPERIENCE RETURNS FOR SECURITY (BADGERS), P67, DOI [10.1109/BADGERS.2015.018, 10.1109/BADGERS.2015.12]
   Na S, 2017, LECT NOTE DATA ENG, V2, P657, DOI 10.1007/978-3-319-49106-6_65
   Neuhaus Stephan, 2010, Proceedings of the 2010 IEEE 21st International Symposium on Software Reliability Engineering (ISSRE 2010), P111, DOI 10.1109/ISSRE.2010.53
   PRAAGMAN J, 1985, EUR J OPER RES, V19, P144, DOI 10.1016/0377-2217(85)90321-2
   Quinlan J. R., 1993, PROGRAMS MACHINE LEA
   Ruohonen Jukka, 2019, Applied Computing and Informatics, V15, P129, DOI 10.1016/j.aci.2017.12.002
   Russo ER, 2019, J SYST SOFTWARE, V156, P84, DOI 10.1016/j.jss.2019.06.001
   Sahin SE, 2019, PROCEEDINGS OF EASE 2019 - EVALUATION AND ASSESSMENT IN SOFTWARE ENGINEERING, P244, DOI 10.1145/3319008.3319033
   Spanos G., 2013, P 17 PANH C INF, P83, DOI DOI 10.1145/2491845.2491871
   Spanos G, 2018, J SYST SOFTWARE, V146, P152, DOI 10.1016/j.jss.2018.09.039
   Spanos G, 2015, INF SECUR J, V24, P57, DOI 10.1080/19393555.2015.1051675
   Spanos Georgios, 2017, Pan-Hellenic conference on informatics, P1
   Toloudis D, 2016, LECT NOTES BUS INF P, V249, P231, DOI 10.1007/978-3-319-39564-7_22
   Triet Huynh Minh Le, 2019, 2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR), P371, DOI 10.1109/MSR.2019.00063
   Tsoumakas G, 2011, IEEE T KNOWL DATA EN, V23, P1079, DOI 10.1109/TKDE.2010.164
   Yang Y., 2012, J COMPUTINF SYST, V8, P579
   Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39
NR 39
TC 6
Z9 7
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9459
EP 9479
DI 10.1007/s11042-021-11073-x
EA JUN 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000663990000002
DA 2024-07-18
ER

PT J
AU Garg, G
   Juneja, M
AF Garg, Gaurav
   Juneja, Mamta
TI Particle swarm optimization based segmentation of Cancer in
   multi-parametric prostate MRI
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Prostate; Segmentation; Cancer; Multi-parametric; Optimization; MRI
ID COMPUTER-AIDED DIAGNOSIS; LEVEL SET EVOLUTION; IMAGE SEGMENTATION;
   ACTIVE CONTOURS; SHAPE PRIORS; PSO; FUSION; FEATURES; BIOPSY; MODEL
AB Prostate Cancer (PCa) is one among the prominent causes of mortality in men, which can only be reduced by early diagnosis. Multi-parametric Magnetic Resonance Imaging (mp-MRI) is increasingly utilized by clinicians for performing diagnostics tasks because it possesses functional and morphological competencies. Although, manual segmentation of PCa on MRI is a tedious, operator-dependent and time consuming task. Therefore, Computer Aided Diagnosis (CAD) of PCa using mp-MRI images is highly desirable by employing computer-assisted segmentation approaches. In this paper, a method is proposed for segmentation of PCa based on level set with Particle Swarm Optimization (PSO) technique to address the limitations of existing techniques as PSO does not require any cost or objective function to be differentiable and it is easy to implement. The energy function is optimized with PSO based technique. The proposed approach is tested over three different mp-MRI modalities i.e., T2 weighted (T2w), Dynamic Contrast Enhanced (DCE) images and Apparent Diffusion Coefficient (ADC) Maps derived from Diffusion Weighted Images (DWI). The accuracy achieved by PSO based methodology is 7.6% greater than without PSO integration i.e., using Gradient descent with added computational overhead of 0.03 s. The experimental outcomes reveal that the proposed methodology shows better results in terms of considered evaluation metrics when compared with the existing techniques on the I2CVB dataset. The impact of the proposed methodology is that it has the ability for precise segmentation even with intensity inhomogeneity, which validates its applications in clinical treatments. Additionally, the proposed technique reduces the manual interference, which in turn minimizes the execution time.
C1 [Garg, Gaurav; Juneja, Mamta] Panjab Univ, Univ Inst Engn & Technol, Dept Comp Sci & Engn, Chandigarh, India.
C3 Panjab University
RP Juneja, M (corresponding author), Panjab Univ, Univ Inst Engn & Technol, Dept Comp Sci & Engn, Chandigarh, India.
EM ergaurav.garg@yahoo.com; mamtajuneja@pu.ac.in
RI Garg, Gaurav/O-4916-2018
OI Garg, Gaurav/0000-0002-8257-562X; Juneja, Mamta/0000-0002-2611-9005
CR Algohary A, 2018, J MAGN RESON IMAGING, V48, P818, DOI 10.1002/jmri.25983
   Alkadi R, 2019, J DIGIT IMAGING, V32, P793, DOI 10.1007/s10278-018-0160-1
   Anderson D, 2015, INF SYST E-BUS MANAG, V13, P599, DOI 10.1007/s10257-014-0239-2
   [Anonymous], 2014, COMPUTATIONAL INTELL
   Cameron A, 2016, IEEE T BIO-MED ENG, V63, P1145, DOI 10.1109/TBME.2015.2485779
   Cameron A, 2014, IEEE ENG MED BIO, P3357, DOI 10.1109/EMBC.2014.6944342
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   CASELLES V, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P694, DOI 10.1109/ICCV.1995.466871
   Chakraborty R, 2019, ARAB J SCI ENG, V44, P3005, DOI 10.1007/s13369-018-3400-2
   Chan I, 2003, MED PHYS, V30, P2390, DOI 10.1118/1.1593633
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chan TF, 2006, SIAM J APPL MATH, V66, P1632, DOI 10.1137/040615286
   Chung AG, 2015, IEEE ACCESS, V3, P2531, DOI 10.1109/ACCESS.2015.2502220
   Clark T, 2017, J MED IMAGING, V4, DOI 10.1117/1.JMI.4.4.041307
   Cremers D, 2008, J SCI COMPUT, V35, P132, DOI 10.1007/s10915-008-9220-x
   Cremers D, 2006, INT J COMPUT VISION, V69, P335, DOI 10.1007/s11263-006-7533-5
   de Rooij M, 2014, AM J ROENTGENOL, V202, P343, DOI 10.2214/AJR.13.11046
   Duda D, 2014, ADV INTELL SYST COMP, V283, P139, DOI 10.1007/978-3-319-06593-9_13
   Fehr D, 2015, P NATL ACAD SCI USA, V112, pE6265, DOI 10.1073/pnas.1505935112
   Filson CP, 2016, CANCER-AM CANCER SOC, V122, P884, DOI 10.1002/cncr.29874
   Garg G, 2019, MULTIMED TOOLS APPL, V78, P12689, DOI 10.1007/s11042-018-6487-2
   Garg G, 2018, CURR MED IMAGING, V14, P19, DOI 10.2174/1573405613666170504145842
   Giannini V, 2013, PROC SPIE, V8670, DOI 10.1117/12.2006336
   Ginsburg SB, 2017, J MAGN RESON IMAGING, V46, P184, DOI 10.1002/jmri.25562
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Kate Vandana, 2020, Social Networking and Computational Intelligence. Proceedings of SCI-2018. Lecture Notes in Networks and Systems (LNNS 100), P207, DOI 10.1007/978-981-15-2071-6_17
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Khalvati F, 2016, 2016 15TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2016), P146, DOI [10.1109/ICMLA.2016.55, 10.1109/ICMLA.2016.0032]
   Khalvati F, 2015, BMC MED IMAGING, V15, DOI 10.1186/s12880-015-0069-9
   Lankton S, 2008, IEEE T IMAGE PROCESS, V17, P2029, DOI 10.1109/TIP.2008.2004611
   Le MH, 2017, PHYS MED BIOL, V62, P6497, DOI 10.1088/1361-6560/aa7731
   Lemaitre G, Computer-aided diagnosis for prostate cancer using multi-parametric magnetic resonance imaging
   Lemaitre G, 2015, 25 INT C QUAL CONTR, V9534
   Lemaître G, 2015, COMPUT BIOL MED, V60, P8, DOI 10.1016/j.compbiomed.2015.02.009
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li CM, 2005, PROC CVPR IEEE, P430
   Li L, 2010, IEEE T IMAGE PROCESS, V19, P1, DOI 10.1109/TIP.2009.2032341
   Litjens GJS, 2014, PROC SPIE, V9035, DOI 10.1117/12.2043751
   Litjens GJS, 2012, PROC SPIE, V8315, DOI 10.1117/12.911061
   Litjens GJS, 2011, PROC SPIE, V7963, DOI 10.1117/12.877844
   Liu P, 2013, PROC SPIE, V8670, DOI 10.1117/12.2007927
   Liu SG, 2012, PATTERN RECOGN, V45, P2769, DOI 10.1016/j.patcog.2011.11.019
   Lopes R, 2011, MED PHYS, V38, P83, DOI 10.1118/1.3521470
   Matulewicz L, 2014, J MAGN RESON IMAGING, V40, P1414, DOI 10.1002/jmri.24487
   Mazzetti S, 2011, PROC SPIE, V7963, DOI 10.1117/12.877549
   Mohammed Z., 2020, UHD J SCI TECHNOL, V4, P9, DOI [10.21928/uhdjst.v4n1y2020.pp9-17, DOI 10.21928/UHDJST.V4N1Y2020.PP9-17]
   Niaf E, 2011, PROC SPIE, V7963, DOI 10.1117/12.877231
   Niaf E, 2012, PHYS MED BIOL, V57, P3833, DOI 10.1088/0031-9155/57/12/3833
   Niederreiter H, 2012, SCI CHINA INFORM SCI, V55, P165, DOI 10.1007/s11432-011-4369-6
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068
   Parfait S, 2012, BIOMED SIGNAL PROCES, V7, P499, DOI 10.1016/j.bspc.2011.09.003
   Parra NA, 2017, FRONT ONCOL, V7, DOI 10.3389/fonc.2017.00259
   Peng YH, 2013, PROC SPIE, V8670, DOI 10.1117/12.2007979
   Peng YH, 2013, RADIOLOGY, V267, P787, DOI 10.1148/radiol.13121454
   Ramudu K, 2018, CURR MED IMAGING, V14, P389, DOI 10.2174/1573405613666170123124652
   Rundo L, 2020, SMART INNOV SYST TEC, V151, P269, DOI 10.1007/978-981-13-8950-4_25
   Rundo L, 2017, INFORMATION, V8, DOI 10.3390/info8020049
   Schroeder FH, 2009, NEW ENGL J MED, V360, P1320, DOI 10.1056/NEJMoa0810084
   Sharif M, 2020, PATTERN RECOGN LETT, V129, P150, DOI 10.1016/j.patrec.2019.11.017
   Song X, 2020, INT C APPL TECHN CYB, P731
   Steiger P, 2016, CANCER IMAGING, V16, DOI 10.1186/s40644-016-0068-2
   Sung YS, 2011, AM J ROENTGENOL, V197, P1122, DOI 10.2214/AJR.10.6062
   Tarver T, 2012, J CONS HLTH INTERNET, V16, P366, DOI 10.1080/15398285.2012.701177
   Thamaraichelvi B., 2020, 2020 Proceedings of the International Conference on Communication and Signal Processing (ICCSP), P0731, DOI 10.1109/ICCSP48568.2020.9182093
   Tiwari P, 2013, MED IMAGE ANAL, V17, P219, DOI 10.1016/j.media.2012.10.004
   Turkbey B, 2012, CURR OPIN UROL, V22, P310, DOI 10.1097/MOU.0b013e32835481c2
   Valerio M, 2015, EUR UROL, V68, P8, DOI 10.1016/j.eururo.2014.10.026
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Viswanath S, 2011, PROC SPIE, V7963, DOI 10.1117/12.878312
   Viswanath SE, 2012, J MAGN RESON IMAGING, V36, P213, DOI 10.1002/jmri.23618
   Vos PC, 2012, PHYS MED BIOL, V57, P1527, DOI 10.1088/0031-9155/57/6/1527
   Wang LF, 2015, INT CONF ACOUST SPEE, P927, DOI 10.1109/ICASSP.2015.7178105
   Wang LF, 2013, PATTERN RECOGN LETT, V34, P637, DOI 10.1016/j.patrec.2012.12.022
   Wang LP, 2017, COMM COM INF SC, V723, P309, DOI 10.1007/978-3-319-60964-5_27
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Yang X, 2017, MED IMAGE ANAL, V42, P212, DOI 10.1016/j.media.2017.08.006
   Zhang KH, 2010, PATTERN RECOGN, V43, P1199, DOI 10.1016/j.patcog.2009.10.010
   Zhang L, 2020, APPL SOFT COMPUT, V92, DOI 10.1016/j.asoc.2020.106328
   Zhao F, 2019, IEEE ACCESS, V7, P64028, DOI 10.1109/ACCESS.2019.2916894
   Zhao J, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420550113
   Zhiyu Liu, 2019, Artificial Intelligence in Radiation Therapy. First International Workshop, AIRT 2019. Held in Conjunction with MICCAI 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11850), P43, DOI 10.1007/978-3-030-32486-5_6
NR 82
TC 7
Z9 7
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30557
EP 30580
DI 10.1007/s11042-021-11133-2
EA JUN 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000663271700003
DA 2024-07-18
ER

PT J
AU Almezhghwi, K
   Serte, S
   Al-Turjman, F
AF Almezhghwi, Khaled
   Serte, Sertan
   Al-Turjman, Fadi
TI Convolutional neural networks for the classification of chest X-rays in
   the IoT era
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks; Deep learning
AB Chest X-ray medical imaging technology allows the diagnosis of many lung diseases. It is known that this technology is frequently used in hospitals, and it is the most accurate way of detecting most thorax diseases. Radiologists examine these images to identify lung diseases; however, this process can require some time. In contrast, an automated artificial intelligence system could help radiologists detect lung diseases more accurately and faster. Therefore, we propose two artificial intelligence approaches for processing and identifying chest X-ray images to detect chest diseases from such images. We introduce two novel deep learning methods for fast and automated classification of chest X-ray images. First, we propose the use of support vector machines based on the AlexNet model. Second, we develop support vector machines based on the VGGNet16 method. Combined deep networks with a robust classifier have shown that the proposed methods outperform AlexNet and VGG16 deep learning approaches for the chest X-ray image classification tasks. The proposed AlexNet and VGGNet based SVM provide average area under the curve values of 98% and 97%, respectively, for twelve chest X-ray diseases.
C1 [Almezhghwi, Khaled] Coll Elect Technol, Elect & Elect Engn, Tripoli, Libya.
   [Serte, Sertan] Near East Univ, Elect & Elect Engn, Via Mersin 10, Nicosia, North Cyprus, Turkey.
   [Al-Turjman, Fadi] Near East Univ, Dept Artificial Intelligence, Via Mersin 10, Nicosia, North Cyprus, Turkey.
   [Al-Turjman, Fadi] Near East Univ, Res Ctr AI & IoT, Via Mersin 10, Nicosia, North Cyprus, Turkey.
C3 Near East University; Near East University; Near East University
RP Almezhghwi, K (corresponding author), Coll Elect Technol, Elect & Elect Engn, Tripoli, Libya.
EM khaled.almezhghwi@neu.edu.tr
RI Al-Turjman, Fadi/L-2998-2019
OI Al-Turjman, Fadi/0000-0001-5418-873X; Almezhghwi,
   khaled/0000-0001-5755-7297
CR [Anonymous], 2018, Chestnet: A deep neural network for classification of thoracic diseases on chest radiography
   Ayan E, 2019, 2019 SCIENTIFIC MEETING ON ELECTRICAL-ELECTRONICS & BIOMEDICAL ENGINEERING AND COMPUTER SCIENCE (EBBT), DOI 10.1109/ebbt.2019.8741582
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Garstka J, 2020, SIG P ALGO ARCH ARR, P18, DOI 10.23919/spa50552.2020.9241305
   Gundel Sebastian, 2019, Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications. 23rd Iberoamerican Congress, CIARP 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11401), P757, DOI 10.1007/978-3-030-13469-3_88
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hsu C-W, 1998, MULTICLASS SUPPORT V
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   KAYMAK S, 2018, 14 S NEUR NETW APPL, P1
   Kaymak S, 2018, INT C INTELL COMP CO, P265, DOI 10.1109/ICCP.2018.8516635
   Kermany Daniel, 2018, Mendeley Data, V3
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li BC, 2019, IEEE ENG MED BIO, P4851, DOI [10.1109/EMBC.2019.8857277, 10.1109/embc.2019.8857277]
   Rajpurkar P, 2017, Arxiv, DOI arXiv:1711.05225
   Serener A., 2020, 2020 4 INT S MULT ST, P1, DOI DOI 10.1109/ISMSIT50672.2020.9254970
   Serener A., 2020, 2020 4 INT S MULT ST, P1
   Serener A, 2019, 2019 SCIENTIFIC MEETING ON ELECTRICAL-ELECTRONICS & BIOMEDICAL ENGINEERING AND COMPUTER SCIENCE (EBBT), DOI [10.1109/ebbt.2019.8741768, 10.1109/icecco48375.2019.9043264]
   Serener A, 2020, TURK J ELECTR ENG CO, V28, P664, DOI 10.3906/elk-1902-131
   Serte S, 2020, 2020 MED TECHN C
   SERTE S, 2020, MED TECHN C TIPTEKNO
   Serte S, 2019, IET IMAGE PROCESS
   Serte S, 2021, COMPUT BIOL MED, V132, DOI 10.1016/j.compbiomed.2021.104306
   Serte S, 2021, IET IMAGE PROCESS, V15, P797, DOI 10.1049/ipr2.12063
   Serte S, 2022, T EMERG TELECOMMUN T, V33, DOI 10.1002/ett.4080
   Serte S, 2019, COMPUT BIOL MED, V113, DOI 10.1016/j.compbiomed.2019.103423
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tang Y, 2015, DEEP LEARNING USING
   Varshni D., 2019 IEEE INT C EL C, DOI DOI 10.1109/ICECCT.2019.8869364
   Wang X., 2017, PROC CVPR IEEE, P2097, DOI [DOI 10.1109/CVPR.2017.369, 10.1109/CVPR.2017.369]
   Yao L., 2018, Weakly supervised medical diagnosis and localization from multiple resolutions
NR 34
TC 16
Z9 16
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29051
EP 29065
DI 10.1007/s11042-021-10907-y
EA JUN 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000662846600004
PM 34155434
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Tagarev, T
   Davis, BA
   Cooke, M
AF Tagarev, Todor
   Davis, Brid A.
   Cooke, Michael
TI Business, Organisational and governance modalities of collaborative
   cybersecurity networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cybersecurity; Collaborative networked organisation; CNO; Organisational
   modalities; Business model; Governance requirements; Governance model;
   ECHO project
ID DESIGN
AB Countering advanced cyber threats requires investments in awareness and qualified personnel, as well as advanced technological solutions. Very few companies have the competencies and capacity to attempt to provide comprehensive solutions and sustain the technological drive and skill levels. Novel organisational solutions are needed to deliver advantages vis-a-vis both threat actors and competitors. The European Union sees one potential solution in the establishment of a network of cybersecurity competence centres. Starting in the beginning of the centuy, the creation of collaborative networked organisations in other fields demonstrated significant benefits in sharing knowledge, resources, and risk to exploit quickly emerging market opportunities. The major challenge in creating networked organisations is to provide long-term, effective collaboration through adequate governance and management. To support the elaboration of a solid governance model of a cybersecurity competence network in a Horizon 2020 research project, this article presents the results of a study of 92 existing network organisations working in cybersecurity and closely related fields. It presents the implemented methodological approach, the identification of main types of business models depending on funding streams and the degree of coordination among partners, organisational modalities, and prevailing governance models depending on member representation on senior governance bodies.
C1 [Tagarev, Todor] Bulgarian Acad Sci, Inst Informat & Commun Technol, Acad G Bonchev Str,Bl 2, Sofia 1113, Bulgaria.
   [Davis, Brid A.; Cooke, Michael] Natl Univ Ireland Maynooth, Maynooth, Kildare, Ireland.
C3 Bulgarian Academy of Sciences; Maynooth University
RP Tagarev, T (corresponding author), Bulgarian Acad Sci, Inst Informat & Commun Technol, Acad G Bonchev Str,Bl 2, Sofia 1113, Bulgaria.
EM tagarev@bas.bg; Brid.Davis@mu.ie; Michael.Cooke@mu.ie
RI Tagarev, Todor/AAP-2598-2020
OI Tagarev, Todor/0000-0003-4424-0201; Cooke, Michael/0000-0002-2651-3504
FU ECHO project - European Union's Horizon 2020 research and innovation
   programme [830943]
FX This work was supported by the ECHO project, which has received funding
   from the European Union's Horizon 2020 research and innovation programme
   under grant agreement no. 830943. The authors gratefully acknowledge the
   contribution to the primary analysis of existing networks by fellow
   researchers from the Bulgarian Defence Institute, the Centre for
   Research and Technology Hellas (Thessaloniki), the European Software
   Institute - Centre Eastern Europe (Sofia), the Institute of ICT of the
   Bulgarian Academy of Sciences, Link Campus University (Rome), RHEA
   Group, Semmelweis University (Budapest), Telefonica Moviles Espana SA,
   Tallinn University of Technology, Vitrociset Belgium, and Zanasi &
   Partners (Modena).
CR Afsarmanesh Hamideh, 2009, International Journal of Information Technology and Management, V8, P234, DOI 10.1504/IJITM.2009.024604
   Amanowicz M, 2020, INT J ELECTRON TELEC, V66, P321, DOI 10.24425/ijet.2020.131881
   Baram G, 2015, MILITARY STRATEAIC, V7, P79
   Camarinha-Matos LM, 2009, COMPUT IND ENG, V57, P46, DOI 10.1016/j.cie.2008.11.024
   European Commission, 2018, COM2018630
   European Defence Agency, WHO WE AR
   Hatzivasilis G, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10165702
   Mayrhofer U, 2015, INT MANAG, V6, DOI [10.1002/9781118785317.weom060007, DOI 10.1002/9781118785317.WEOM060007]
   Mees, 2020, MULTIMEDIA COMMUNICA, V1284, P37
   Rufenacht D, 2016, RES REPORT
   Sharkov G, 2016, PROCEEDINGS OF THE 2016 ACM WORKSHOP ON AUTOMATED DECISION MAKING FOR ACTIVE CYBER DEFENSE (SAFECONFIG'16), P3, DOI 10.1145/2994475.2994484
   Taddeo M, 2019, MIND MACH, V29, P349, DOI 10.1007/s11023-019-09507-5
   Tagarev T, 2020, 2020 IEEE 11TH INTERNATIONAL CONFERENCE ON DEPENDABLE SYSTEMS, SERVICES AND TECHNOLOGIES (DESSERT): IOT, BIG DATA AND AI FOR A SAFE & SECURE WORLD AND INDUSTRY 4.0, P431, DOI [10.1109/dessert50317.2020.9125011, 10.1109/DESSERT50317.2020.9125011]
   Tagarev T, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12040062
   Tonar R, 2018, FORBES MAGAZINE 0423
   Weiss M, 2019, GOVERNANCE, V32, P259, DOI 10.1111/gove.12368
NR 16
TC 0
Z9 1
U1 5
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9431
EP 9443
DI 10.1007/s11042-021-11109-2
EA JUN 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000658112700002
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Jain, R
   Nayyar, A
   Arora, S
   Gupta, A
AF Jain, Rachna
   Nayyar, Anand
   Arora, Simrann
   Gupta, Akash
TI A comprehensive analysis and prediction of earthquake magnitude based on
   position and depth parameters using machine and deep learning models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Earthquake prediction; USGS; RF regression; SVR; MLP regressor; RMSE;
   Catastrophic destruction
ID MEAN SQUARED ERROR; CRUSTAL EARTHQUAKES; REGRESSION
AB Earthquake is one of the major natural disasters that not only costs human lives but also leads to financial losses, which affect the country's economy. Earthquake Prediction is one of the challenging research areas because its early prediction can save a lot of human lives, helps in minimizing the financial losses to some extent. The objective of this research is to develop an earthquake prediction model based on the position and depth by using machine learning and deep learning algorithms. The dataset is split into seven different csv files after thorough processing and a requisition of best-performing regression models is done to compute the results. These algorithms include Random forest (RF) Regression, Multi-Layer Perceptron (MLP) regression, and Support Vector Regression (SVR). The method is applied for different radii around the target. The dataset for this research is taken from the USGS website. The efficiency of algorithms is compared by computing the deviation between actual and predicted outcomes by using the error metrics. The results are evaluated using the Root Mean Square Error (RMSE) metric. Considering the boundary values, the RMSE for RF Regression is 1.731, for MLP regression the value is 1.647 and for SVR the RMSE achieved is 1.720, all for a minimum radius value of 100 and similarly 0.436, 0.428 and 0.449 RMSE is achieved for the respective algorithms on a maximum radius of 5000. The results demonstrate that MLP Regressor is performing better than other algorithms as the error is least in the case of this algorithm.
C1 [Jain, Rachna; Arora, Simrann; Gupta, Akash] Bharati Vidyapeeths Coll Engn, Dept Comp Sci & Engn, New Delhi, India.
   [Nayyar, Anand] Duy Tan Univ, Fac Informat Technol, Grad Sch, Da Nang 550000, Vietnam.
C3 Duy Tan University
RP Nayyar, A (corresponding author), Duy Tan Univ, Fac Informat Technol, Grad Sch, Da Nang 550000, Vietnam.
EM anandnayyar@duytan.edu.vn
RI Jain, Rachna/AAH-7179-2020; Nayyar, Anand/F-3732-2015
OI Jain, Rachna/0000-0001-9794-614X; Nayyar, Anand/0000-0002-9821-6146;
   Jain, Rachna/0000-0002-1819-550X
CR [Anonymous], 2020, TODAYS EARTHQUAKES U
   [Anonymous], 2019, J EARTHQ ENG
   Asencio-Cortés G, 2016, KNOWL-BASED SYST, V101, P15, DOI 10.1016/j.knosys.2016.02.014
   Asheghi R, 2019, ARAB J SCI ENG, V44, P8645, DOI 10.1007/s13369-019-04046-8
   Asim KM, 2017, NAT HAZARDS, V85, P471, DOI 10.1007/s11069-016-2579-3
   Asim KM, 2020, SOIL DYN EARTHQ ENG, V130, DOI 10.1016/j.soildyn.2019.105932
   Asim KM, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0199004
   Brizová L, 2019, ATMOSPHERE-BASEL, V10, DOI 10.3390/atmos10070413
   Cardona OD, 2019, NATURE, V566, P182, DOI 10.1038/d41586-019-00552-9
   Cheng JCP, 2020, J CONSTR ENG M, V146, DOI 10.1061/(ASCE)CO.1943-7862.0001749
   Cvetkovic VM, 2019, ACTA GEOGR SLOV, V59, P27, DOI 10.3986/AGS.5445
   Dan K, 2019, B SEISMOL SOC AM, V109, P152, DOI 10.1785/0120180123
   Duman H., 2019, ARXIV PREPRINT ARXIV
   Folger P. F, 2010, EARTHQUAKES RISK DET
   Gitis V.G., 2017, P 7 INT C WEB INTELL, P1
   Gosar A, 2019, ACTA GEOGR SLOV, V59, P51, DOI 10.3986/AGS.4845
   Hagen M, 2019, OPEN J EARTHQ RES, V8, P267, DOI 10.4236/ojer.2019.84016
   Harirchian Ehsan, 2020, IOP Conference Series: Materials Science and Engineering, V897, DOI 10.1088/1757-899X/897/1/012014
   Holliday JR, 2006, TECTONOPHYSICS, V413, P87, DOI 10.1016/j.tecto.2005.10.008
   Idini B, 2017, B EARTHQ ENG, V15, P1853, DOI 10.1007/s10518-016-0050-1
   Ishwaran H, 2019, STAT MED, V38, P558, DOI 10.1002/sim.7803
   Jilani Z, 2017, J ENVIRON RADIOACTIV, V172, P43, DOI 10.1016/j.jenvrad.2017.03.010
   Khodaverdizahraee N, 2020, INT J DISAST RISK RE, V46, DOI 10.1016/j.ijdrr.2020.101505
   Kita A, 2020, ENG STRUCT, V219, DOI 10.1016/j.engstruct.2020.110841
   Kobayashi K, 2000, AGRON J, V92, P345, DOI 10.1007/s100870050043
   Kwag S, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12083269
   Kwag S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10041515
   Lanzano G, 2019, B SEISMOL SOC AM, V109, P525, DOI 10.1785/0120180210
   LEITCH G, 1991, AM ECON REV, V81, P580
   Li W, 2016, ADV SPACE RES, V57, P2141, DOI 10.1016/j.asr.2016.02.014
   Liu H, 2019, IEEE ACCESS, V7, P186437, DOI 10.1109/ACCESS.2019.2961434
   Mantrawadi H, 2019, 2019 IEEE S COMP COM, P1
   MIELNICZUK J, 1993, NEURAL NETWORKS, V6, P1019, DOI 10.1016/S0893-6080(09)80011-7
   MOLCHAN GM, 1990, PHYS EARTH PLANET IN, V61, P128, DOI 10.1016/0031-9201(90)90100-C
   Morales-Esteban A, 2010, EXPERT SYST APPL, V37, P8333, DOI 10.1016/j.eswa.2010.05.050
   Moura MD, 2011, RELIAB ENG SYST SAFE, V96, P1527, DOI 10.1016/j.ress.2011.06.006
   Murtagh F., 1991, NEUROCOMPUTING, V2, P183
   Murwantara I.M., 2020, TELKOMNIKA, V18, P1331, DOI DOI 10.12928/TELKOMNIKA.V18I3.14756
   Nadi B, 2020, IJST-T CIV ENG, V44, P165, DOI 10.1007/s40996-019-00247-1
   Panza GF, 2018, REND LINCEI-SCI FIS, V29, P81, DOI 10.1007/s12210-017-0626-y
   Papantonopoulos C, 2002, EARTHQUAKE ENG STRUC, V31, P1699, DOI 10.1002/eqe.185
   Paulo O, 2020, J PHY ADV APP, V1, P13
   Pavlidou E, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11010061
   Pourghasemi HR, 2019, SCI TOTAL ENVIRON, V692, P556, DOI 10.1016/j.scitotenv.2019.07.203
   Pulinets S, 2011, J ASIAN EARTH SCI, V41, P371, DOI 10.1016/j.jseaes.2010.03.005
   Rilstone P, 1996, J ECONOMETRICS, V75, P369, DOI 10.1016/0304-4076(96)89457-7
   Rosenbaum L, 2013, J CHEMINFORMATICS, V5, DOI 10.1186/1758-2946-5-33
   Sarkar P., 2018, INT J PURE APPL MATH, V119, P125
   Schuba CN, 2019, GEOPHYS J INT, V218, P45, DOI 10.1093/gji/ggz142
   Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g
   Tüchler M, 2002, IEEE T SIGNAL PROCES, V50, P673, DOI 10.1109/78.984761
   Van Gestel T, 2001, IEEE T NEURAL NETWOR, V12, P809, DOI 10.1109/72.935093
   Wang QL, 2020, IEEE T EMERG TOP COM, V8, P148, DOI 10.1109/TETC.2017.2699169
   Wang Y, 2020, NAT HAZARDS REV, V21, DOI 10.1061/(ASCE)NH.1527-6996.0000356
   Weber, 2019, GEOPH RES ABSTR, V21
   Yamany Waleed, 2015, 2015 Fourth International Conference on Information Science and Industrial Applications (ISI), P40, DOI 10.1109/ISI.2015.9
   Yang JX, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11216159
   Yariyan P, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12030405
   Zhang JF, 2021, NEURAL COMPUT APPL, V33, P1533, DOI 10.1007/s00521-020-05084-2
NR 59
TC 10
Z9 10
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 28419
EP 28438
DI 10.1007/s11042-021-11001-z
EA JUN 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000658077800004
DA 2024-07-18
ER

PT J
AU Deepak, G
   Rooban, S
   Santhanavijayan, A
AF Deepak, Gerard
   Rooban, S.
   Santhanavijayan, A.
TI A knowledge centric hybridized approach for crime classification
   incorporating deep bi-LSTM neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bi-LSTM; Crime classification; Crime forensics; Deep learning in crimes;
   Knowledge centric approach; Ontological model
ID FRAMEWORK
AB In recent years, the crime rate has increased considerably and there is a need to properly identify the different types of crimes so that it can be tackled. In this paper, a Bi-LSTM neural network for classification is proposed that classifies the different types of crime on data collected from Google News and Twitter. The data is pre-processed and an initial step of labeling is performed with the help of Fuzzy c-means algorithm and Term Frequency - Inverse Document Frequency vectors. GloVe word embeddings were performed for feature extraction. Dynamically generated ontologies with minimal human supervision using a weighted graph modeled from Google News and Social Web like Twitter has been encompassed in order to enhance the quality of crime classification. The proposed method has proven, after experiments, to achieve evaluation metrics better than the existing methods; evaluated on four different datasets and compared with four different methods with an increase in Accuracy and decrease in FNR for four distinguished datasets.
C1 [Deepak, Gerard; Rooban, S.; Santhanavijayan, A.] Natl Inst Technol, Dept Comp Sci & Engn, Tiruchirappalli, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Deepak, G (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Tiruchirappalli, India.
EM gerard.deepak.cse.nitt@gmail.com
RI S, Rooban/AAW-5608-2021
OI S, Rooban/0000-0003-3723-6343
CR Abbass Z, 2020, IEEE INT C SEMANT CO, P363, DOI 10.1109/ICSC.2020.00073
   Abebe MA, 2020, KNOWL-BASED SYST, V188, DOI 10.1016/j.knosys.2019.06.025
   [Anonymous], 1997, NEURAL COMPUT
   Anuar S, 2015, ADV INTELL SYST COMP, V331, P31, DOI 10.1007/978-3-319-13153-5_4
   Bhalla A, 2019, CRIME INDIA 2018
   Bhati S, 2019, P REC ADV INT TRENDS
   Boppuru Prathap Rudra, 2019, International Journal of Web-Based Learning and Teaching Technologies, V14, P49, DOI 10.4018/IJWLTT.2019100103
   Chen HC, 2004, COMPUTER, V37, P50, DOI 10.1109/MC.2004.1297301
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Das P, 2020, COMPUTATIONAL INTELL, V990
   Das P, 2021, NEUROCOMPUTING, V459, P465, DOI 10.1016/j.neucom.2019.10.109
   Fares M, 2019, KNOWL-BASED SYST, V165, P432, DOI 10.1016/j.knosys.2018.12.017
   Gerber MS, 2014, DECIS SUPPORT SYST, V61, P115, DOI 10.1016/j.dss.2014.02.003
   Ghankutkar S, 2019, INT C ADV COMP COMM
   Haggi S, 2020, J ADV COMPUTER ENG T, V6, P78
   Hardy J, 2020, CRIME PREV COMMUNITY, V22, P68, DOI 10.1057/s41300-019-00082-6
   Jurafsky D., 2008, Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition, V2, DOI 10.5555/555733
   KUMAR A., 2020, 2020 INT C EM TRENDS, P1, DOI [10.1109/ic-ETITE47903.2020.155, DOI 10.1109/IC-ETITE47903.2020.155]
   Kumar KBS, 2020, LECT NOTE DATA ENG, V44, P876, DOI 10.1007/978-3-030-37051-0_98
   Lal S, 2020, PROCEDIA COMPUT SCI, V167, P1911, DOI 10.1016/j.procs.2020.03.211
   Munir Kamran, 2018, Applied Computing and Informatics, V14, P116, DOI 10.1016/j.aci.2017.07.003
   Mustapha A, 2020, COMMUN COMPUT PHYS, P68
   Nair S, 2019, P 2016 C TECHN FUT C
   Noormanshah WMU, 2020, LECT NOTES NETWORKS, V118
   Nunez-del-Prado M, 2020, ADV INFORM COMMUNICA, V69
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Priandini N, 2017, AIP CONF PROC, V1867, DOI 10.1063/1.4994415
   Rahma F, 2019, IOP CONF SER-MAT SCI, V662, DOI 10.1088/1757-899X/662/2/022135
   Ramasubbareddy S, 2020, INNOVATIONS COMPUTER, V103
   Saha R, 2020, ACM INT CONF PR SER, P317, DOI 10.1145/3371158.3371405
   Sreejith AG, 2020, LECT NOTE NETW SYST, V89, P699, DOI 10.1007/978-981-15-0146-3_65
   Srinivasa K, 2019, INFORM PROCESS MANAG, V56, DOI 10.1016/j.ipm.2019.102059
   Wang M, 2020, PROC SPIE, V11430, DOI 10.1117/12.2538132
   Wang PF, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P325, DOI 10.1145/3331184.3331223
   Zhang ZJ, 2020, APPL INTELL, V50, P448, DOI 10.1007/s10489-019-01531-3
   Zhong HX, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3540
NR 36
TC 7
Z9 7
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 28061
EP 28085
DI 10.1007/s11042-021-11050-4
EA MAY 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000655825400002
DA 2024-07-18
ER

PT J
AU Khan, MA
   Mittal, M
   Goyal, LM
   Roy, S
AF Khan, Muhammad Attique
   Mittal, Mamta
   Goyal, Lalit Mohan
   Roy, Sudipta
TI A deep survey on supervised learning based human detection and activity
   classification methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Preprocessing; Human segmentation; Human detection; Features extraction;
   Datasets; Classification
ID PEDESTRIAN DETECTION; OBJECT DETECTION; FEATURES FUSION; ACTION
   RECOGNITION; DETECTION ALGORITHM; ORIENTED GRADIENTS; HUMAN
   SEGMENTATION; HEAD DETECTION; HOG FEATURES; TRACKING
AB Human detection and activity recognition is very important research area in the healthcare, video surveillance, pedestrian detection, intelligent vehicle system and home care center. Among the various human activity detection frameworks, the statistical based approach were most intensively studied and used in practice in which pattern recognition was traditionally formulated. More recently, supervised learning based techniques and methods imported from statistical learning theory have deserved increasing attention. Many new supervised learning methods such as transfer learning, multi-instance learning, and the new trends in deep learning techniques have used for the formulation of solutions to the human activity detection. This paper reviews the automatic human detection and their activity recognition in the video sequences and static images. We explain several problems of human detection and activity recognition in different steps such as processing, segmentation of human features extraction and classification. Moreover, discuss the problems in each step and provide the recent state- of-the-art methods, gaps between recent methods, technical difficulties, applications and their challenges. Several features extraction techniques and corresponding problems for human classification have been discussed in details. Special emphasis have been given on convolution neural network that solves the problem of human segmentation, efficient classification and activity recognition. The objective of this review paper is to summarize and review related of the established and recent methods used in various stages of a human detection and activity classification system and identify research topics and applications that are at the forefront of this exciting and challenging field. Further, the evaluation protocols (i.e. datasets and simulation tools) and possible solution of current limitation have been discussed briefly in this survey.
C1 [Khan, Muhammad Attique] HITEC Univ, Dept Comp Sci & Engn, Museum Rd, Taxila, Pakistan.
   [Mittal, Mamta] GB Pant Govt Engn Coll, New Delhi, India.
   [Goyal, Lalit Mohan] JC Bose Univ Sci & Technol, YMCA, Faridabad, India.
   [Roy, Sudipta] Washington Univ, PRTTL, St Louis, MO 63110 USA.
C3 NITEC University; J.C. Bose University of Science & Technology, YMCA;
   Washington University (WUSTL)
RP Roy, S (corresponding author), Washington Univ, PRTTL, St Louis, MO 63110 USA.
EM attique.khan440@gmail.com; mittalmamta79@gmail.com;
   lalitgoyal78@gmail.com; sudiptaroy01@yahoo.com
RI Roy, Sudipta/T-5231-2019; Khan, Dr. Muhammad Attique/AAX-2644-2021;
   GOYAL, LALIT MOHAN/AAH-4030-2020; khan, sajid/HGE-2406-2022; Mittal,
   Mamta/AAC-2229-2020
OI Roy, Sudipta/0000-0001-5161-9311; Khan, Dr. Muhammad
   Attique/0000-0002-6347-4890; GOYAL, LALIT MOHAN/0000-0003-4618-0281;
   Mittal, Mamta/0000-0003-0490-4413
CR Adeel A, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12569
   Afza F, 2021, IMAGE VISION COMPUT, V106, DOI 10.1016/j.imavis.2020.104090
   Afza F, 2022, METHODS, V202, P88, DOI 10.1016/j.ymeth.2021.02.013
   Aguilar WG, 2017, LECT NOTES COMPUT SC, V10306, P563, DOI 10.1007/978-3-319-59147-6_48
   Aguilar WG, 2017, IEEE INT C SEMANT CO, P509, DOI 10.1109/ICSC.2017.83
   Akram T, 2021, PATTERN ANAL APPL, P1, DOI DOI 10.1007/S10044
   Almadhor A, 2021, ENERGY REP, V7, P7906, DOI 10.1016/j.egyr.2021.01.034
   Ameur H, 2014, 2014 GLOBAL SUMMIT ON COMPUTER & INFORMATION TECHNOLOGY (GSCIT)
   Ammar B., 2011, 2011 International Conference on Innovations in Information Technology (IIT), P128, DOI 10.1109/INNOVATIONS.2011.5893802
   [Anonymous], 2015, ARXIV151008160
   [Anonymous], 1998, Technical Report CSD-TR-98-04
   [Anonymous], 1999, IEEE COMPUTER SOC C
   [Anonymous], 2016, RIEMANNIAN COMPUTING
   [Anonymous], 2016, J ELECT ENG TECHNOL
   [Anonymous], 2013, ARXIV13075800
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2011, 2011 INT C COMM COMP, DOI [10.1109/CCCA.2011.6031422, DOI 10.1109/CCCA.2011.6031422]
   [Anonymous], 2017, arXiv
   Arshad H, 2019, INT J MACH LEARN CYB, V10, P3601, DOI 10.1007/s13042-019-00947-0
   Arun Kumar N, 2013, INT J SOFT COMPUT EN
   Ayesha, 2020, MICROSC RES TECHNIQ
   Balasubramanian P, 2016, P IEEE C COMP VIS PA, P104
   Barbu T, 2014, COMPUT ELECTR ENG, V40, P1072, DOI 10.1016/j.compeleceng.2013.12.004
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Bartoli F, 2015, IEEE COMPUT SOC CONF
   BASTANI V, 2015, ADV VID SIGN BAS SUR, P1, DOI DOI 10.1109/AVSS.2015.7301744
   Beaudry C, 2016, MACH VISION APPL, V27, P529, DOI 10.1007/s00138-016-0760-z
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Bellotto N, 2009, IEEE T SYST MAN CY B, V39, P167, DOI 10.1109/TSMCB.2008.2004050
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bhangale KB, 2014, INT J INNOV RES DEV
   Blaschko MB, 2008, PROC CVPR IEEE, P93, DOI 10.1109/CVPR.2008.4587353
   Borges PVK, 2013, IEEE T CIRC SYST VID, V23, P224, DOI 10.1109/TCSVT.2012.2203217
   Breitenstein MD, 2011, IEEE T PATTERN ANAL, V33, P1820, DOI 10.1109/TPAMI.2010.232
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Cao JL, 2017, IEEE T IMAGE PROCESS, V26, P3210, DOI 10.1109/TIP.2017.2694224
   Cao JL, 2016, IEEE T IMAGE PROCESS, V25, P5538, DOI 10.1109/TIP.2016.2609807
   Changyan Li, 2010, 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P290, DOI 10.1109/CISP.2010.5648239
   Chaquet JM, 2013, COMPUT VIS IMAGE UND, V117, P633, DOI 10.1016/j.cviu.2013.01.013
   Chen HW, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P361, DOI 10.1109/AVSS.2014.6918695
   Chen H, 2016, 2016 9TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2016), P23, DOI 10.1109/CISP-BMEI.2016.7852676
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen N, 2015, SIGNAL PROCESS, V110, P155, DOI 10.1016/j.sigpro.2014.08.044
   Chen SY, 2012, IEEE T IND INFORM, V8, P118, DOI 10.1109/TII.2011.2173202
   Chen XF, 2016, COMPUT-AIDED CIV INF, V31, P229, DOI 10.1111/mice.12163
   Cho MS, 2015, INT CONF UBIQ ROBOT, P292, DOI 10.1109/URAI.2015.7358956
   CHONG P, 2016, 2016 IEEE STUD C RES, P1
   Cippitelli E, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/4351435
   Conde C, 2013, NEUROCOMPUTING, V100, P19, DOI 10.1016/j.neucom.2011.12.037
   Coutts FK, 2014, EUR SIGNAL PR CONF, P2180
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Daras, 2016, ACTION RECOGNITION V, P10
   Das Dawn D, 2016, VISUAL COMPUT, V32, P289, DOI 10.1007/s00371-015-1066-2
   Dayananda Kumar NC., 2014, 2014 INT C COMM SIGN, P90
   de Souza KJ, 2016, SIBGRAPI, P195, DOI [10.1109/SIBGRAPI.2016.035, 10.1109/SIBGRAPI.2016.33]
   Dhar P, 2017, P INT C COMP VIS IM, P343
   Dobhal T, 2015, PROCEDIA COMPUT SCI, V58, P178, DOI 10.1016/j.procs.2015.08.050
   DONG C, 2020, TRANSPORTMETRICA A, P1
   Du XZ, 2017, IEEE WINT CONF APPL, P953, DOI 10.1109/WACV.2017.111
   Nguyen DT, 2016, PATTERN RECOGN, V51, P148, DOI 10.1016/j.patcog.2015.08.027
   Ekinci M., 2005, Turkish Journal Electrical Engineering and Computer Sciences, Elektrik, V13, P199
   Elgammal A, 2000, EUR C COMP VIS, P751, DOI DOI 10.1007/3-540-45053-X_48
   Elzein H, 2003, IEEE IV2003: INTELLIGENT VEHICLES SYMPOSIUM, PROCEEDINGS, P500, DOI 10.1109/IVS.2003.1212962
   Endres D, 2011, LECT NOTES ARTIF INT, V7006, P75, DOI 10.1007/978-3-642-24455-1_7
   Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fakharian Ahmad, 2011, 2011 19th Mediterranean Conference on Control & Automation (MED 2011), P1398
   Fathima AA, 2013, INT CONF RECENT, P157, DOI 10.1109/ICRTIT.2013.6844198
   Fernández-Caballero A, 2011, EXPERT SYST APPL, V38, P2577, DOI 10.1016/j.eswa.2010.08.047
   Fernando WSK, 2014, INT CONF INF AUTOMAT
   GAN Gtio-Long, 2011, 2011 7 INT C COMP IN, P1184, DOI DOI 10.1109/CIS.2011.262
   Gang Zheng, 2012, 2012 IEEE Global High Tech Congress on Electronics (GHTCE), P10, DOI 10.1109/GHTCE.2012.6490115
   Gao W, 2009, PROC CVPR IEEE, P1786, DOI 10.1109/CVPRW.2009.5206762
   García J, 2013, IEEE T SYST MAN CY-S, V43, P606, DOI 10.1109/TSMCA.2012.2220540
   Ge Z, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1, DOI 10.1109/ROBIO.2016.7866266
   Gonzalez R.C., 2002, Digital Image Processing, V2nd
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Guan YP, 2010, IET COMPUT VIS, V4, P50, DOI 10.1049/iet-cvi.2008.0016
   Guana YP, 2015, ENG APPL ARTIF INTEL, V37, P181, DOI 10.1016/j.engappai.2014.08.004
   Guangyuan Zhang, 2010, Proceedings 2010 Sixth International Conference on Natural Computation (ICNC 2010), P3257, DOI 10.1109/ICNC.2010.5582537
   Guo GD, 2014, PATTERN RECOGN, V47, P3343, DOI 10.1016/j.patcog.2014.04.018
   Guoqing Xu, 2011, Proceedings 2011 International Conference on Information and Automation (ICIA 2011), P384, DOI 10.1109/ICINFA.2011.5949022
   Gupta M, 2011, 2011 UKSIM 13 INT C, P2011
   Gupta M, 2015, IEEE SYST J, V9, P1363, DOI 10.1109/JSYST.2014.2317777
   Gutchess D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P733, DOI 10.1109/ICCV.2001.937598
   Hanbury A, 2008, J VISUAL LANG COMPUT, V19, P617, DOI 10.1016/j.jvlc.2008.01.002
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Hariyono J, 2014, SCI WORLD J, DOI 10.1155/2014/196415
   Harounabadi, 2016, J CURRENT RES SCI, V1, P505
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He N, 2008, ISISE 2008: INTERNATIONAL SYMPOSIUM ON INFORMATION SCIENCE AND ENGINEERING, VOL 2, P167, DOI 10.1109/ISISE.2008.308
   Hiromoto M, 2009, LECT NOTES COMPUT SC, V5815, P53, DOI 10.1007/978-3-642-04667-4_6
   Hoang VD, 2012, IEEE IND ELEC, P4220, DOI 10.1109/IECON.2012.6389212
   Hong GS, 2016, MULTIMED TOOLS APPL, V75, P15229, DOI 10.1007/s11042-015-2455-2
   Hoseinnezhad R, 2013, IEEE T SIGNAL PROCES, V61, P392, DOI 10.1109/TSP.2012.2222389
   Hou Beiping, 2011, Journal of Computers, V6, P1597, DOI 10.4304/jcp.6.8.1597-1604
   Hou R, 2017, IEEE I CONF COMP VIS, P5823, DOI 10.1109/ICCV.2017.620
   Hou YL, 2011, IEEE T SYST MAN CY A, V41, P24, DOI 10.1109/TSMCA.2010.2064299
   Hu D, 2016, PEDESTRIAN DETECTION
   Hu L, 2020, IEEE ACCESS, V8, P24471, DOI 10.1109/ACCESS.2020.2970164
   Huang SC, 2011, IEEE T CIRC SYST VID, V21, P1, DOI 10.1109/TCSVT.2010.2087812
   Huang YZ, 2008, PROC CVPR IEEE, P2000
   Hussain N, 2024, MULTIMED TOOLS APPL, V83, P14935, DOI 10.1007/s11042-020-08852-3
   Hussain T, 2021, IEEE INTERNET THINGS, V8, P9634, DOI 10.1109/JIOT.2020.3027483
   Idrees H, 2015, IEEE T PATTERN ANAL, V37, P1986, DOI 10.1109/TPAMI.2015.2396051
   Ikizler-Cinbis N, 2010, LECT NOTES COMPUT SC, V6311, P494, DOI 10.1007/978-3-642-15549-9_36
   Intriago-Pazmiño M, 2017, ADV INTELL SYST, V570, P436, DOI 10.1007/978-3-319-56538-5_44
   Jabri S, 2000, INT C PATT RECOG, P627, DOI 10.1109/ICPR.2000.902997
   Jaidhar, 2020, MULTIMED TOOLS APPL, P1
   Jalal A, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22080817
   Jalal A, 2017, INT J INTERACT MULTI, V4, P54, DOI 10.9781/ijimai.2017.447
   Janbandhu, HUMAN DETECTION NONL
   Jay Kuo, 2017, 2017 IEEE WINT C APP
   Jazouli M, 2015, PROCEEDINGS OF 2015 INTERNATIONAL CONFERENCE ON ELECTRICAL AND INFORMATION TECHNOLOGIES (ICEIT 2015), P229, DOI 10.1109/EITech.2015.7162942
   Jeong M, 2017, IEEE T CIRC SYST VID, V27, P1368, DOI 10.1109/TCSVT.2016.2539684
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jia HX, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P683, DOI 10.1109/ICIG.2007.53
   Jiang YS, 2015, PROC CVPR IEEE, P240, DOI 10.1109/CVPR.2015.7298620
   Jodoin PM, 2012, IEEE T IMAGE PROCESS, V21, P4244, DOI 10.1109/TIP.2012.2199326
   Jose, 2015, ADV INTELLIGENT INFO, P117
   Jun B, 2013, IEEE T PATTERN ANAL, V35, P1423, DOI 10.1109/TPAMI.2012.219
   Jung HJ, 2017, PATTERN RECOGN LETT, V85, P21, DOI 10.1016/j.patrec.2016.11.012
   Kamal S, 2016, ARAB J SCI ENG, V41, P1043, DOI 10.1007/s13369-015-1955-8
   Kammerl J., 2011, OCTREE POINT CLOUD C
   Kaur B, 2018, COMPUT ELECTR ENG, V71, P692, DOI 10.1016/j.compeleceng.2018.08.018
   Kaur R, 2014, 2014 INNOVATIVE APPLICATIONS OF COMPUTATIONAL INTELLIGENCE ON POWER, ENERGY AND CONTROLS WITH THEIR IMPACT ON HUMANITY (CIPECH), P54, DOI 10.1109/CIPECH.2014.7019097
   Khan Mansoor, 2020, 2020 IEEE 8th International Conference on Photonics (ICP), P1, DOI 10.1109/ICP46580.2020.9206421
   Khan Meer Muhammad, 2016, 2016 International Conference on Industrial Informatics and Computer Systems (CIICS), DOI 10.1109/ICCSII.2016.7462414
   KHAN MA, 2021, COMPUT ELECTR ENG, V90, DOI DOI 10.1016/J.COMPELECENG.2020.106956
   Khan MA, 2020, PATTERN RECOGN LETT, V131, P193, DOI 10.1016/j.patrec.2019.12.024
   Khan MA, 2021, PATTERN RECOGN LETT, V143, P58, DOI 10.1016/j.patrec.2020.12.015
   Khan MA, 2021, COMPUT ELECTR ENG, V90, DOI 10.1016/j.compeleceng.2020.106960
   Khan MA, 2021, CMC-COMPUT MATER CON, V66, P2923, DOI 10.32604/cmc.2021.013191
   Khan MA, 2020, IEEE ACCESS, V8, P197969, DOI 10.1109/ACCESS.2020.3034217
   Khan MA, 2024, MULTIMED TOOLS APPL, V83, P14885, DOI 10.1007/s11042-020-08806-9
   Khan MA, 2020, MULTIMED TOOLS APPL, V79, P25763, DOI 10.1007/s11042-020-09244-3
   Khan MA, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10080565
   Khan MA, 2020, IEEE ACCESS, V8, P132850, DOI 10.1109/ACCESS.2020.3010448
   Khan MA, 2020, IET IMAGE PROCESS, V14, P818, DOI 10.1049/iet-ipr.2018.5769
   Khan MZ, 2021, CATHETER CARDIO INTE, V98, P343, DOI 10.1002/ccd.29517
   Khemchandani R, 2017, ADV INTELL SYST, V459, P193, DOI 10.1007/978-981-10-2104-6_18
   Kim K, 2016, IEEE T CONSUM ELECTR, V62, P150, DOI [10.1109/TCE.2016.7514714, 10.1109/ICCE.2016.7430551]
   Kim S, 2016, INT C COMP SCI ITS A, P198
   Kim Y, 2016, IEEE GEOSCI REMOTE S, V13, P8, DOI 10.1109/LGRS.2015.2491329
   Kolekar MH, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P393, DOI 10.1109/TENCON.2016.7848028
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar R, 2017, INT CONF ACOUST SPEE, P1922, DOI 10.1109/ICASSP.2017.7952491
   Kumar S. S., 2016, P 2016 IEEE INT CARN, P1, DOI DOI 10.1109/CCST.2016.7815694
   Kushwaha AKS, 2012, 2012 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV), P326, DOI 10.1109/ICIEV.2012.6317384
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Le QV, 2011, PROC CVPR IEEE
   Lee KD, 2013, MULTIMED TOOLS APPL, V63, P27, DOI 10.1007/s11042-012-1020-5
   Lee K, 2010, INT CONF COMP SCI, P18, DOI 10.1109/ICCSIT.2010.5564984
   Lee MunWai., 2007, WMVC, P23
   Lee SM, 2017, INT CONF BIG DATA, P131, DOI 10.1109/BIGCOMP.2017.7881728
   Lee YI, 2013, CYBER SECURITY CULTURE: COUNTERACTING CYBER THREATS THROUGH ORGANIZATIONAL LEARNING AND TRAINING, P1
   Levi D, 2013, PROC CVPR IEEE, P947, DOI 10.1109/CVPR.2013.127
   Levi K, 2004, PROC CVPR IEEE, P53
   Li DW, 2013, INTEGR COMPUT-AID E, V20, P201, DOI 10.3233/ICA-130428
   Li JQ, 2017, IEEE IJCNN, P4052, DOI 10.1109/IJCNN.2017.7966367
   Li L., 2003, MULTIMEDIA 03 P 11 A, P2, DOI DOI 10.1145/957013.957017
   Li L, 2009, WORKSH APPL COMP VIS, P2009
   Li LY, 2012, IEEE T SYST MAN CY B, V42, P1398, DOI 10.1109/TSMCB.2012.2192107
   Li M, 2009, IEEE IMAGE PROC, P2545, DOI 10.1109/ICIP.2009.5414008
   Liang CW, 2015, APPL SOFT COMPUT, V28, P483, DOI 10.1016/j.asoc.2014.09.051
   Lillywhite Kirt., 2009, Workshop on Applications of Computer Vision, P1
   Lim JJ, 2013, PROC CVPR IEEE, P3158, DOI 10.1109/CVPR.2013.406
   Lin DT, 2011, IEEE T INF FOREN SEC, V6, P1432, DOI 10.1109/TIFS.2011.2159972
   Lin Z, 2008, LECT NOTES COMPUT SC, V5305, P423, DOI 10.1007/978-3-540-88693-8_31
   Lin Z, 2007, IEEE I CONF COMP VIS, P2301
   Lin Z, 2010, IEEE T PATTERN ANAL, V32, P604, DOI 10.1109/TPAMI.2009.204
   Lin ZJ, 2017, INT CONF INFO SCI, P200, DOI 10.1109/ICIST.2017.7926757
   Liu H., 2017, HUMAN MOTION SENSING, P233, DOI DOI 10.1007/978-3-662-53692-6_11
   Liu J., 2016, ARXIV161102644, P1, DOI DOI 10.5244/C.30.73
   Jingen Liu, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1996, DOI [10.1109/ICINIS.2009.13, 10.1109/CVPRW.2009.5206744]
   Liu L, 2016, IEEE T CYBERNETICS, V46, P158, DOI 10.1109/TCYB.2015.2399172
   Liu Q, 2016, NEUROCOMPUTING, V194, P10, DOI 10.1016/j.neucom.2016.02.011
   Liu TR, 2017, 10TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2017), P319, DOI 10.1145/3056540.3076202
   Liu YZ, 2009, PROC CVPR IEEE, P1255, DOI 10.1109/CVPRW.2009.5206724
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu Z, 2016, IEEE INT C PERV COMP, P1
   Luo J, 2007, INT CONF ACOUST SPEE, P593
   Luo P, 2014, PROC CVPR IEEE, P899, DOI 10.1109/CVPR.2014.120
   Ma, 2007, P 15 ACM INT C MULT, P269
   Maglogiannis, 2013, P 6 INT C PERV TECHN, V37
   Maity S, 2017, IETE J RES, V63, P160, DOI 10.1080/03772063.2016.1242383
   Maji S, 2008, PROC CVPR IEEE, P2245
   Maji S, 2013, IEEE T PATTERN ANAL, V35, P66, DOI 10.1109/TPAMI.2012.62
   Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229
   Marín J, 2014, IEEE T CYBERNETICS, V44, P342, DOI 10.1109/TCYB.2013.2255271
   Mehmood A, 2024, MULTIMED TOOLS APPL, V83, P14979, DOI 10.1007/s11042-020-08928-0
   Meneguzzi, 2017, DEEP NEURAL ARCHITEC
   Ming Yang, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P522, DOI 10.1109/ICCVW.2009.5457656
   Minh Hoai, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3265, DOI 10.1109/CVPR.2011.5995470
   Mittal A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041068
   Moctezuma D., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1793, DOI 10.1109/ICCVW.2011.6130466
   Mozafari A. S., 2012, 2012 IEEE International Conference on Intelligent Computer Communication and Processing (ICCP 2012). Proceedings, P237, DOI 10.1109/ICCP.2012.6356191
   Muhammad K, 2020, IEEE NETWORK, V34, P108, DOI 10.1109/MNET.011.1900257
   Muhammad K, 2020, PATTERN RECOGN LETT, V130, P370, DOI 10.1016/j.patrec.2018.08.003
   Munder S, 2006, IEEE T PATTERN ANAL, V28, P1863, DOI 10.1109/TPAMI.2006.217
   Murtaza F, 2015, INT CONF FRONT INFO, P297, DOI 10.1109/FIT.2015.59
   Murtza I, 2017, VISUAL COMPUT, V33, P99, DOI 10.1007/s00371-015-1155-2
   Mustafah YM, 2017, PERTANIKA J SCI TECH, V25, P181
   Naheed N, 2020, CMES-COMP MODEL ENG, V125, P1, DOI 10.32604/cmes.2020.011380
   Narasimhan H, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P167
   Nasir IM, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20236793
   Naz M, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.386
   Nazir, 2021, MICROPROCESS MICROSY, DOI [10.1016/j.micpro.2021.104027, DOI 10.1016/J.MICPRO.2021.104027]
   Nazir, 2020, MICROSC RES TECHNIQ
   Noman M, 2016, 2016 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P8
   Olson T., 1997, P DARPA IM UND WORKS, V20, P205
   Ong LY, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ROBOTICS (ICCAR), P385, DOI 10.1109/ICCAR.2017.7942723
   Opelt A, 2006, IEEE T PATTERN ANAL, V28, P416, DOI 10.1109/TPAMI.2006.54
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Oren M, 1997, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.1997.609319
   Ott P, 2009, IEEE I CONF COMP VIS, P723, DOI 10.1109/ICCV.2009.5459238
   Ouyang WL, 2016, IEEE T CIRC SYST VID, V26, P2123, DOI 10.1109/TCSVT.2015.2501940
   Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257
   Ouyang WL, 2013, PROC CVPR IEEE, P3222, DOI 10.1109/CVPR.2013.414
   Ouyang WL, 2012, PROC CVPR IEEE, P3258, DOI 10.1109/CVPR.2012.6248062
   Paisitkriangkrai S, 2014, LECT NOTES COMPUT SC, V8692, P546, DOI 10.1007/978-3-319-10593-2_36
   Paisitkriangkrai S, 2013, IEEE I CONF COMP VIS, P1057, DOI 10.1109/ICCV.2013.135
   Pang YW, 2017, IEEE T CYBERNETICS, V47, P117, DOI 10.1109/TCYB.2015.2508603
   Pang YW, 2011, SIGNAL PROCESS, V91, P773, DOI 10.1016/j.sigpro.2010.08.010
   Park D, 2013, PROC CVPR IEEE, P2882, DOI 10.1109/CVPR.2013.371
   Parrotta E, 2020, NEUROL-NEUROIMMUNOL, V7, DOI 10.1212/NXI.0000000000000835
   Patil Prithvi., 2019, IEEE, P1, DOI DOI 10.1109/ICASERT.2019.8934463
   Patino L, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P88, DOI 10.1109/AVSS.2016.7738072
   Penne, 2011, THESIS U BLAISE PASC
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Prest A, 2013, IEEE T PATTERN ANAL, V35, P835, DOI 10.1109/TPAMI.2012.175
   Priyadharsini S., 2011, 2011 Proceedings of International Conference on Emerging Trends in Electrical and Computer Technology (ICETECT 2011), P531, DOI 10.1109/ICETECT.2011.5760172
   Qian, 2013, LECT NOTES COMPUT SC, P345, DOI DOI 10.1007/978-3-642-35728-2_33
   Qian HM, 2010, PATTERN RECOGN LETT, V31, P100, DOI 10.1016/j.patrec.2009.09.019
   Rahimi S, 2013, IRAN CONF MACH, P349, DOI 10.1109/IranianMVIP.2013.6780009
   Rahimi S., 2013, 2013 First RSI/ISM International Conference on Robotics and Mechatronics (ICRoM 2013). Proceedings, P32, DOI 10.1109/ICRoM.2013.6510077
   Rajaei A, 2013, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE 2013), P229, DOI 10.1109/ICCKE.2013.6682838
   Rashid M, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12125037
   Rauf Hafiz Tayyab, 2023, Pers Ubiquitous Comput, V27, P733, DOI 10.1007/s00779-020-01494-0
   Ren H, 2017, COMPUT VIS IMAGE UND, P1
   Ren HY, 2010, IEEE IMAGE PROC, P2705, DOI 10.1109/ICIP.2010.5651963
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Sabzmeydani P., 2007, CVPR, P1, DOI DOI 10.1109/CVPR.2007.383134
   Saeed F, 2021, APPL SOFT COMPUT, V103, DOI 10.1016/j.asoc.2021.107164
   Sahoo SP, 2015, 2015 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P789, DOI 10.1109/ICCSP.2015.7322600
   Saito M, 2010, IEEE SYS MAN CYBERN
   Saligrama V, 2010, IEEE SIGNAL PROC MAG, V27, P18, DOI 10.1109/MSP.2010.937393
   Sanoj CS, 2013, 2013 INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND EMBEDDED SYSTEMS (ICICES), P64, DOI 10.1109/ICICES.2013.6508394
   Santos TT, 2011, PATTERN RECOGN LETT, V32, P47, DOI 10.1016/j.patrec.2010.05.016
   Satpathy A, 2014, IEEE T IMAGE PROCESS, V23, P287, DOI 10.1109/TIP.2013.2264677
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Schwartz WR, 2011, LECT NOTES COMPUT SC, V7042, P181, DOI 10.1007/978-3-642-25085-9_21
   Seguin G, 2015, IEEE T PATTERN ANAL, V37, P1643, DOI 10.1109/TPAMI.2014.2369050
   Semwal VB, 2020, WEARABLE SENSOR BASE
   Semwal VB, 2019, ADV INTELL SYST COMP, V748, P135, DOI 10.1007/978-981-13-0923-6_12
   Semwal VB, 2018, IEEE T AUTOM SCI ENG, V15, P104, DOI 10.1109/TASE.2016.2594191
   Semwal VB, 2016, IEEE SENS J, V16, P5805, DOI 10.1109/JSEN.2016.2570281
   Semwal VB, 2015, IEEE SENS J, V15, P2021, DOI 10.1109/JSEN.2015.2389525
   Senior A, 2006, IMAGE VISION COMPUT, V24, P1233, DOI 10.1016/j.imavis.2005.06.007
   Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465
   Shao L, 2016, INT J COMPUT VISION, V118, P115, DOI 10.1007/s11263-015-0861-6
   Shao L, 2012, PATTERN RECOGN LETT, V33, P438, DOI 10.1016/j.patrec.2011.05.015
   Sharif M, 2020, J ORGAN END USER COM, V32, P67, DOI 10.4018/JOEUC.2020040104
   Shehzad MI, 2017, IET COMPUT VIS, V11, P68, DOI 10.1049/iet-cvi.2016.0156
   Shi YM, 2017, IEEE T MULTIMEDIA, V19, P1510, DOI 10.1109/TMM.2017.2666540
   Shoaib M, 2009, INT CONF ACOUST SPEE, P773, DOI 10.1109/ICASSP.2009.4959698
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Sindagi VA, 2018, PATTERN RECOGN LETT, V107, P3, DOI 10.1016/j.patrec.2017.07.007
   Siviroj, 2020, J HEALTH RES
   Soryani, 2014, INT J COMPUT APPL, V96
   Sowmiya D, 2013, INT CONF ADV COMPU, P263, DOI 10.1109/ICoAC.2013.6921961
   Sridharan S, 2016, ARXIV161201611
   Sun J, 2006, LECT NOTES COMPUT SC, V3952, P628
   Sung-Tae An, 2011, Proceedings of the 2011 IEEE International Conference on Mechatronics and Automation (ICMA 2011), P483, DOI 10.1109/ICMA.2011.5985610
   Surinta O, 2015, ENG APPL ARTIF INTEL, V45, P405, DOI 10.1016/j.engappai.2015.07.017
   Tang SY, 2014, INT J COMPUT VISION, V110, P58, DOI 10.1007/s11263-013-0664-6
   Thombre DV, 2009, IAMA: 2009 INTERNATIONAL CONFERENCE ON INTELLIGENT AGENT & MULTI-AGENT SYSTEMS, P249
   Tian L, 2012, INT C AUD LANG IM PR, P2012
   Tong RF, 2013, IEEE T CIRC SYST VID, V23, P1502, DOI 10.1109/TCSVT.2013.2248285
   Torrione, 2017, VIEWPOINT ADAPTATION
   Tran D, 2008, LECT NOTES COMPUT SC, V5302, P548, DOI 10.1007/978-3-540-88682-2_42
   Ullah W, 2021, MULTIMED TOOLS APPL, V80, P16979, DOI 10.1007/s11042-020-09406-3
   Hoang VD, 2014, NEUROCOMPUTING, V135, P357, DOI 10.1016/j.neucom.2013.12.017
   Varol G, 2018, IEEE T PATTERN ANAL, V40, P1510, DOI 10.1109/TPAMI.2017.2712608
   Verbeke N, 2007, SUIVI OBJETS MOUVEME
   Vinay GK, 2016, SIGNAL IMAGE VIDEO P, V10, P585, DOI 10.1007/s11760-015-0781-5
   Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Vo BN, 2010, IEEE T SIGNAL PROCES, V58, P5129, DOI 10.1109/TSP.2010.2050482
   Walha A, 2015, MULTIMED TOOLS APPL, V74, P6745, DOI 10.1007/s11042-014-1928-z
   Wang, 2017, IEEE T CIRC SYS VIDE
   Wang H, 2016, INT J COMPUT VISION, V119, P219, DOI 10.1007/s11263-015-0846-5
   Wang KZ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P97, DOI 10.1145/2647868.2654912
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Wang XH, 2020, INT J NEURAL SYST, V30, DOI 10.1142/S0129065719500278
   Watanabe T, 2009, LECT NOTES COMPUT SC, V5414, P37, DOI 10.1007/978-3-540-92957-4_4
   Wei DM, 2013, PROCEEDINGS OF THE 2013 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT CONTROL AND INFORMATION PROCESSING (ICICIP), P459
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Wojek C, 2009, PROC CVPR IEEE, P794, DOI 10.1109/CVPRW.2009.5206638
   Wong C. Y. Jonathan, 2013, 2013 Abstracts IEEE International Conference on Plasma Science (ICOPS), DOI 10.1109/PLASMA.2013.6633389
   Wu B, 2005, IEEE I CONF COMP VIS, P90
   Wu XX, 2012, LECT NOTES COMPUT SC, V7576, P411, DOI 10.1007/978-3-642-33715-4_30
   Xia D, 2010, 2010 INT C COMP APPL, V12, pV12
   Xiaohui Liu, 2012, 2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet), P832, DOI 10.1109/CECNet.2012.6201519
   Xinyi Cui, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3161, DOI 10.1109/CVPR.2011.5995558
   Xu D, 2017, PROC CVPR IEEE, P4236, DOI 10.1109/CVPR.2017.451
   Xu RY, 2015, MULTIMED TOOLS APPL, V74, P729, DOI 10.1007/s11042-014-2177-x
   Yamada K, 2016, INT C PATT RECOG, P591, DOI 10.1109/ICPR.2016.7899698
   Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161
   Yan JJ, 2013, PROC CVPR IEEE, P3033, DOI 10.1109/CVPR.2013.390
   Yang JB, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3995
   Yao SH, 2015, NEUROCOMPUTING, V151, P1006, DOI 10.1016/j.neucom.2014.08.080
   Ye QX, 2010, IEEE IMAGE PROC, P881, DOI 10.1109/ICIP.2010.5654080
   Yi-Ying Wang, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3125, DOI 10.1109/ICIP.2011.6116328
   Yibo Cui, 2008, 5th International Conference on Visual Information Engineering, VIE 2008, P388, DOI 10.1049/cp:20080344
   Zarka N, 2008, 3 INT C ICTTA, P1
   Zeng JX, 2015, IEEE ICCE, P370, DOI 10.1109/ICCE-TW.2015.7216949
   Zeng M, 2014, 2014 6TH INTERNATIONAL CONFERENCE ON MOBILE COMPUTING, APPLICATIONS AND SERVICES (MOBICASE), P197, DOI 10.4108/icst.mobicase.2014.257786
   Zhang H, 2013, IEEE T CYBERNETICS, V43, P1429, DOI 10.1109/TCYB.2013.2275291
   Zhang HB, 2016, IET COMPUT VIS, V10, P528, DOI 10.1049/iet-cvi.2015.0420
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
   Zhang MH, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162830
   Zhang SS, 2018, IEEE T PATTERN ANAL, V40, P973, DOI 10.1109/TPAMI.2017.2700460
   Zhang SS, 2016, MULTIMED TOOLS APPL, V75, P6263, DOI 10.1007/s11042-015-2571-z
   Zhang SS, 2015, PROC CVPR IEEE, P1751, DOI 10.1109/CVPR.2015.7298784
   Zhang SS, 2015, IEEE T CIRC SYST VID, V25, P1709, DOI 10.1109/TCSVT.2015.2397199
   Zhang SS, 2014, PROC CVPR IEEE, P947, DOI 10.1109/CVPR.2014.126
   Zhang SB, 2013, 2013 NINTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION (ICNC), P1349, DOI 10.1109/ICNC.2013.6818189
   Zhang Z, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416550144
   Zhao X, 2016, IEEE VTS VEH TECHNOL, P1, DOI DOI 10.1109/VTCFALL.2016.7880852
   Zhao Y, 2017, IEEE WINT CONF APPL, P962, DOI 10.1109/WACV.2017.112
   Zhen XT, 2017, IEEE T MULTIMEDIA, V19, P2056, DOI 10.1109/TMM.2017.2700204
   Zheng CH, 2017, NEUROCOMPUTING, V228, P71, DOI 10.1016/j.neucom.2016.09.085
   Zhou C, 2009, P 2009 2 INT C IM S, P1, DOI DOI 10.1109/CISP.2009.5304536
   Zhu Q, 2006, 2006 IEEE COMP SOC C, P1491, DOI [10.1109/CVPR.2006.119, DOI 10.1109/CVPR.2006.119]
NR 337
TC 19
Z9 19
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27867
EP 27923
DI 10.1007/s11042-021-10811-5
EA MAY 2021
PG 57
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000655574500001
DA 2024-07-18
ER

PT J
AU Khan, UA
   Javed, A
   Ashraf, R
AF Khan, Umer Ali
   Javed, Ali
   Ashraf, Rehan
TI An effective hybrid framework for content based image retrieval (CBIR)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CBIR; Discrete wavelet transform; Support vector machine; Genetic
   algorithm; L-2 norm; Color moments; Haar wavelet; Daubechies wavelet;
   Bi-orthogonal wavelet transform
AB In recent years, we have witnessed a massive growth in the generation of images on the cyberspace which demands to develop automated solutions for effective content management. Content-based image retrieval (CBIR) systems have been proposed to reduce the dependency on textual annotations-based image retrieval systems. There exists a variety of features-classifier combinations based CBIR methods to analyze the content of query image for relevant images retrieval. Although, these methods provide better retrieval performance in single-class scenario, however, we experience a significant performance drop in multi-class search environments due to semantics similarity among the images of different classes. CBIR methods based on the hybrid classification model offer better retrieval accuracy, however, we experience a biased classification towards the negative class due to the class imbalance problem when we experience an increase in the number of negative samples due to highly correlated semantic classes. Thus, multiple classifiers based CBIR models become unstable especially in one-against-all classification settings. To address the aforementioned problem, we proposed a CBIR method based on a hybrid features descriptor with the genetic algorithm (GA) and SVM classifier for image retrieval in multi-class scenario. More specifically, we employed the first three color moments, Haar Wavelet, Daubechies Wavelet and Bi-Orthogonal wavelets for features extraction, refine the features using GA and then train the multi-class SVM using one-against-all approach. L-2 Norm is used as a similarity measurement function between the query image and retrieved images against the query image from the image repository. The proposed technique successfully addresses the class imbalance problem in CBIR. Performance of the proposed method is evaluated on four standard datasets i.e. WANG, Oxford Flower, CIFAR-10, and kvasir and compared with 25 different CBIR methods. Experimental results illustrate that our method outperforms the existing state-of-the-art CBIR methods in terms of image retrieval.
C1 [Khan, Umer Ali; Javed, Ali] Univ Engn & Technol, Dept Software Engn, Taxila, Pakistan.
   [Ashraf, Rehan] Natl Text Univ, Dept Comp Sci, Sheikhupura Rd, Faisalabad, Pakistan.
C3 University of Engineering & Technology Taxila; National Textile
   University - Pakistan
RP Ashraf, R (corresponding author), Natl Text Univ, Dept Comp Sci, Sheikhupura Rd, Faisalabad, Pakistan.
EM umerdcs@gmail.com; ali.javed@uettaxila.edu.pk; rehan@ntu.edu.pk
RI JAVED, ALI/X-3334-2019
CR Ahmed A, 2020, IEEE ACCESS, V8, P79969, DOI 10.1109/ACCESS.2020.2990557
   Ali N, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157428
   [Anonymous], 2017, ARXIV170308492
   Ashraf R., 2014, J BASIC APPL SCI RES, V4, P136
   Ashraf R, 2020, IEEE ACCESS, V8, P105659, DOI 10.1109/ACCESS.2020.2998808
   Ashraf R, 2020, MULTIMED TOOLS APPL, V79, P8553, DOI 10.1007/s11042-018-5961-1
   Ashraf R, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0880-7
   Ashraf R, 2016, J INF SCI ENG, V32, P245
   Ashraf R, 2015, ENTROPY-SWITZ, V17, P3552, DOI 10.3390/e17063552
   Ballerini L, 2010, LECT NOTES COMPUT SC, V5853, P31, DOI 10.1007/978-3-642-11769-5_3
   Chaudhuri B, 2016, IEEE GEOSCI REMOTE S, V13, P987, DOI 10.1109/LGRS.2016.2558289
   Chen X, 2006, IEEE DATA MINING, P129
   Chen YX, 2005, IEEE T IMAGE PROCESS, V14, P1187, DOI 10.1109/TIP.2005.849770
   ElAlami ME, 2014, APPL SOFT COMPUT, V14, P407, DOI 10.1016/j.asoc.2013.10.003
   ElAlami ME, 2011, KNOWL-BASED SYST, V24, P23, DOI 10.1016/j.knosys.2010.06.001
   Fadaei S, 2017, IET IMAGE PROCESS, V11, P89, DOI 10.1049/iet-ipr.2016.0542
   Gupta Ekta, 2015, 2015 4th International Conference on Reliability, Infocom Technologies and Optimization (ICRITO) (Trends and Future Directions), P1, DOI 10.1109/ICRITO.2015.7359320
   Hafiane A, 2006, PATTERN RECOGN LETT, V27, P259, DOI 10.1016/j.patrec.2005.08.007
   Huang PW, 2003, PATTERN RECOGN, V36, P665, DOI 10.1016/S0031-3203(02)00083-3
   Iakovidou C, 2019, IEEE T IMAGE PROCESS, V28, P3115, DOI 10.1109/TIP.2019.2894281
   Ionescu M, 2004, IEEE INT CONF FUZZY, P1721
   Irtaza A, 2015, MULTIMED TOOLS APPL, V74, P5055, DOI 10.1007/s11042-013-1679-2
   Irtaza A, 2014, MULTIMED TOOLS APPL, V72, P1911, DOI 10.1007/s11042-013-1489-6
   Jhanwar N, 2004, IMAGE VISION COMPUT, V22, P1211, DOI 10.1016/j.imavis.2004.03.026
   Kaur Savroop, 2015, International Journal of Intelligent Systems and Applications, V7, P37, DOI 10.5815/ijisa.2015.03.05
   Khan R, 2015, COMPUT VIS IMAGE UND, V132, P102, DOI 10.1016/j.cviu.2014.09.005
   Khan R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.89
   Lai CC, 2011, IEEE T INSTRUM MEAS, V60, P3318, DOI 10.1109/TIM.2011.2135010
   Latha D, 2019, IET IMAGE PROCESS, V13, P2031, DOI 10.1049/iet-ipr.2018.5797
   Li LJ, 2014, INT J COMPUT VISION, V107, P20, DOI 10.1007/s11263-013-0660-x
   Lin CH, 2011, EXPERT SYST APPL, V38, P11412, DOI 10.1016/j.eswa.2011.03.014
   Lin CH, 2009, IMAGE VISION COMPUT, V27, P658, DOI 10.1016/j.imavis.2008.07.004
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Madabhushi A, 2009, MED IMAGING 2009 COM, V7260
   Mahmoud MI, 2007, PROC WRLD ACAD SCI E, V20, P68
   Meena M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING (ICIP), P366, DOI 10.1109/INFOP.2015.7489409
   Mehmood Z., 2018, KUWAIT J SCI, V1, P45
   Mehmood Z, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/8217250
   Montazer GA, 2015, NEUROCOMPUTING, V168, P221, DOI 10.1016/j.neucom.2015.05.104
   Poursistani P, 2013, MATH COMPUT MODEL, V57, P1005, DOI 10.1016/j.mcm.2011.11.064
   Prakash O, 2013, 2013 IEEE CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES (ICT 2013), P577
   Rahman MM, 2006, COMP MED SY, P285, DOI 10.1109/CBMS.2006.98
   Rangkuti A. Haris, 2013, 2013 IEEE Symposium on Computers & Informatics (ISCI), P122, DOI 10.1109/ISCI.2013.6612388
   Rao M.B., 2011, INT J COMPUT APPL, V18, P40, DOI [10.5120/2285-2961, DOI 10.5120/2285-2961]
   Saadatmand-Tarzjan M, 2007, IEEE T SYST MAN CY B, V37, P139, DOI 10.1109/TSMCB.2006.880137
   Scott GJ, 2017, IEEE GEOSCI REMOTE S, V14, P1638, DOI 10.1109/LGRS.2017.2722988
   Scott GJ, 2017, IEEE GEOSCI REMOTE S, V14, P549, DOI 10.1109/LGRS.2017.2657778
   Song Y, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0103575
   Stejic Z, 2003, INFORM PROCESS MANAG, V39, P1, DOI 10.1016/S0306-4573(02)00024-9
   Tian XL, 2014, SIGNAL PROCESS-IMAGE, V29, P530, DOI 10.1016/j.image.2014.01.010
   Upadhyaya N., 2016, INT J SIGNAL PROCESS, V9, P433
   Wang C., 2013, INT S INTEGRATED UNC, P91, DOI DOI 10.1007/978-3-642-39515-4_8
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wei WY, 2019, IEEE ACCESS, V7, P126430, DOI 10.1109/ACCESS.2019.2938000
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Ye FM, 2019, IEEE ACCESS, V7, P141498, DOI 10.1109/ACCESS.2019.2944253
   Yildizer E, 2012, EXPERT SYST APPL, V39, P2385, DOI 10.1016/j.eswa.2011.08.086
   Youssef SM, 2012, COMPUT ELECTR ENG, V38, P1358, DOI 10.1016/j.compeleceng.2012.05.010
   Yu H, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P929, DOI 10.1109/ICIP.2002.1039125
   Yu J, 2013, NEUROCOMPUTING, V120, P355, DOI 10.1016/j.neucom.2012.08.061
   Zafar B, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8112242
   Zang MJ, 2018, EXPERT SYST APPL, V94, P250, DOI 10.1016/j.eswa.2017.10.057
   Zeng S, 2016, NEUROCOMPUTING, V171, P673, DOI 10.1016/j.neucom.2015.07.008
   Zhang CX, 2016, 2016 9TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2016), P417, DOI 10.1109/CISP-BMEI.2016.7852747
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
NR 65
TC 24
Z9 24
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26911
EP 26937
DI 10.1007/s11042-021-10530-x
EA MAY 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000649226100001
DA 2024-07-18
ER

PT J
AU Movahedi, Z
   Bastanfard, A
AF Movahedi, Zahra
   Bastanfard, Azam
TI Toward competitive multi-agents in Polo game based on reinforcement
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Competitive multi-agent team; Polo game; Multi-agent system;
   Reinforcement learning
AB The learning of agents in a competitive space such as a game is a challenging task. The aim of the proposed research is to improve the reinforcement learning techniques in a competitive multi-agent for the Polo game. First, the video dataset is prepared. Then, the rules of the Polo game are extracted as a class diagram. An architecture is designed for multi-agent team in the Polo game. Therefore, an algorithm is proposed for the temporal difference in the game belief space for improving reward catching. The reward function is implemented in the agent team. Finally, the research improvement is evaluated by increasing 31 units in comparison with previous work. Therefore, competitive learning in the agent team has been improved.
C1 [Movahedi, Zahra] Islamic Azad Univ, Qazvin Branch, Fac Comp & Informat Technol Engn, Qazvin, Iran.
   [Bastanfard, Azam] Islamic Azad Univ, Karaj Branch, Dept Comp Engn, Karaj, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Bastanfard, A (corresponding author), Islamic Azad Univ, Karaj Branch, Dept Comp Engn, Karaj, Iran.
EM zahramovahedi2014@gmail.com; bastanfard@kiau.ac.ir
RI Bastanfard, Azam/AAX-8571-2020
OI Bastanfard, Azam/0000-0002-7935-819X
CR Ali MZ, 2014, 2014 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC), P2180, DOI 10.1109/CEC.2014.6900616
   Baglivo A., 2013, 2013 DIG HER INT C D, VVolume 2, P711, DOI 10.1109/DigitalHeritage.2013.6744840
   Banerjee B, 2017, IEEE T COMP INTEL AI, V9, P402, DOI 10.1109/TCIAIG.2016.2620060
   Beysolow T., 2019, Applied Reinforcement Learning with Python: With OpenAI Gym, Tensorflow, and Keras
   Carmel D, 1998, J EXP THEOR ARTIF IN, V10, P309, DOI 10.1080/095281398146789
   Castelfranchi C., 2000, INTELLIGENT AGENT 7
   Chen B, 2014, NEUROCOMPUTING, V128, P447, DOI 10.1016/j.neucom.2013.08.021
   Collazo M. Nogueira, 2016, IEEE T COMPUT INTELL, V8, P325
   Covaci A, 2018, MULTIMED TOOLS APPL, V77, P21245, DOI 10.1007/s11042-017-5459-2
   Danny W., 2010, ARCHITECTURE BASED D
   De Asis K, 2018, AAAI CONF ARTIF INTE, P2902
   Ding SF, 2019, APPL INTELL, V49, P4211, DOI 10.1007/s10489-019-01487-4
   Duan Y, 2012, ARTIF INTELL REV, V38, P193, DOI 10.1007/s10462-011-9244-8
   Engelbrecht AP, 2014, IEEE S SWARM INT
   Fernando TG, 2019, MULTIMED TOOLS APPL, V78, P29783
   Guimaraes M, 2017, AAMAS'17: PROCEEDINGS OF THE 16TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS, P1562
   Hagelbäck J, 2016, IEEE T COMP INTEL AI, V8, P319, DOI 10.1109/TCIAIG.2015.2414447
   Hajduk M., 2019, COGNITIVE MULTIAGENT, V138, P1
   Hubner JF., 2010, SPRINGER SCI BUSINES, V59, P351
   Jinsong Leng, 2009, International Journal of Knowledge Engineering and Soft Data Paradigms, V1, P26, DOI 10.1504/IJKESDP.2009.021982
   Kamalapurkar R, 2018, COMMUN CONTROL ENG, P1, DOI 10.1007/978-3-319-78384-0
   Kashan AH, 2010, IEEE C EVOL COMPUTAT
   Kim JH, 2000, INTELL AUTOM SOFT CO, V6, P3, DOI 10.1080/10798587.2000.10768155
   Kobti, 2007, P 2007 IEEE S COMP I
   Koseler K, 2018, MACHINE LEARNING APP, P745
   Laffay HA., 2014, POLO ARGENTINA HIST
   Laffay HA., 2011, POLO US HIST
   Laffaye Horace A, 2009, EVALUATION POLO
   Lee JS, 2020, ACTA HORTIC, V1291, P1, DOI 10.17660/ActaHortic.2020.1291.1
   Leng JS, 2007, LECT NOTES COMPUT SC, V4692, P572
   Leng JS, 2011, APPL SOFT COMPUT, V11, P1353, DOI 10.1016/j.asoc.2010.04.007
   Marinheiro J, 2017, ICAART: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE, VOL 1, P107, DOI 10.5220/0006253101070118
   Masoumi B, 2012, PRZ ELEKTROTECHNICZN, V88, P280
   Masoumi B, 2011, EXPERT SYST APPL, V38, P8105, DOI 10.1016/j.eswa.2010.12.152
   Masoumi B, 2012, ASIAN J CONTROL, V14, P137, DOI 10.1002/asjc.315
   Mattiassi ADA, 2019, MULTIMED TOOLS APPL, V78, P13565, DOI 10.1007/s11042-019-7231-2
   Mourao A., 2013, Proceedings of the 21st ACM international conference on Multimedia, P83
   Nandy Abhishek, 2018, REINFORCEMENT LEARNI
   Nash A, 2013, AI MAG, V34, P85, DOI 10.1609/aimag.v34i4.2512
   Collazo MN, 2014, NAT COMPUT, V13, P131, DOI 10.1007/s11047-014-9411-3
   Pelechano N, 2016, COMPUT GRAPH-UK, V59, P68, DOI 10.1016/j.cag.2016.05.023
   Pendharkar PC, 2012, EXPERT SYST APPL, V39, P273, DOI 10.1016/j.eswa.2011.07.017
   Polk S, 2018, APPL INTELL, V48, P1893, DOI 10.1007/s10489-016-0835-6
   Rabin S, 2002, CHARLES RIVER M 0403
   Scheepers C., 2014, SPRINGER SOFT COMPUT, V20, P607
   Scheepers C, 2014, 2014 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC), P1210, DOI 10.1109/CEC.2014.6900236
   Sewak M., 2019, Deep Reinforcement Learning, P51, DOI [10.1007/978-981-13-8285-74, DOI 10.1007/978-981-13-8285-74]
   Stone P, 1998, APPL ARTIF INTELL, V12, P165, DOI 10.1080/088395198117811
   Sun PH, 2019, FUTURE GENER COMP SY, V99, P401, DOI 10.1016/j.future.2019.04.014
   Tomaz L.B.P, 2017, SPRINGER APPL INTELL, V48, P1
   Weyns D, 2019, ENG MULTIAGENT SYSTE
   Wooldridge M, 1997, INTELLIGENT AGENT 2
   Wooldridge M. J., 2002, INTRO MULTIAGENT SYS
   Yu F.R., 2019, Deep reinforcement learning for wireless networks
   Yuan Y, 2019, SPRINGER APPL INTELL, V49, P2878
NR 55
TC 13
Z9 14
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26773
EP 26793
DI 10.1007/s11042-021-10968-z
EA MAY 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000648376500001
DA 2024-07-18
ER

PT J
AU Zheng, YH
   Qin, LN
   Qiu, TR
   Zhou, AY
   Xu, P
   Xue, ZX
AF Zheng, Yinghao
   Qin, Lina
   Qiu, Taorong
   Zhou, Aiyun
   Xu, Pan
   Xue, Zhixin
TI Automated detection and recognition of thyroid nodules in ultrasound
   images using Improve Cascade Mask R-CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ultrasound image; Thyroid nodule; Improve Cascade Mask R-CNN; Automatic
   detection; Recognition
ID FEATURE-SELECTION; CLASSIFICATION; NETWORKS
AB Accurate diagnosis of thyroid nodules using ultrasonography heavily relies on the superb skills and rich experience of senior radiologists, considering the low contrast, high noise of the ultrasound image, and the diverse appearance of the nodules. Computer-aided diagnosis systems could diagnose thyroid nodules based on ultrasound characteristics to assist radiologists. However, the existing learning-based approaches for detecting and recognizing thyroid nodules have the problems of inaccurate localization and low recognition accuracy. In this study, we propose an Improved Cascade Mask R-CNN for effectively detecting and recognizing thyroid nodules. Firstly, a more effective detector is designed to better classify the ROIs and better correct the bounding boxes. Secondly, a more effective balanced L1 loss function is used to increase the gradient of the easy sample and solve the problem of imbalance between hard samples and easy samples during training. Finally, a more effective soft non-maximum suppression (Soft-NMS) method is used to set an attenuation function for adjacent bounding boxes, which solves the problem of possible missing detection in non-maximum suppression (NMS). The improved model is trained and verified by using real 1408 images collected from the known hospital. Under the localization accuracy of the IoU threshold of 0.5, the mAP reaches 87.1%, and the recognition accuracy reaches 98.67%. The experiment results show that the improved model is effective and highly valuable to help the doctors for the recognition of benign and malignant thyroid nodules.
C1 [Zheng, Yinghao; Qin, Lina; Qiu, Taorong; Xue, Zhixin] Nanchang Univ, Sch Informat Engn, Nanchang, Jiangxi, Peoples R China.
   [Zhou, Aiyun; Xu, Pan] Nanchang Univ, Affiliated Hosp 1, Dept Ultrasond, Nanchang, Jiangxi, Peoples R China.
C3 Nanchang University; Nanchang University
RP Qiu, TR (corresponding author), Nanchang Univ, Sch Informat Engn, Nanchang, Jiangxi, Peoples R China.
EM Qiutaorong@ncu.edu.cn
RI Lu, Wang/JVO-0416-2024
OI Zheng, Yinghao/0000-0002-2891-749X
FU Key R&D Program of JiangXi Province of China [20181BBG70031]
FX This work was supported by the Key R&D Program of JiangXi Province of
   China (Grant No.20181BBG70031).
CR [Anonymous], arXiv preprint arXiv:2002.05202
   Bibicu D, 2013, J DIGIT IMAGING, V26, P119, DOI 10.1007/s10278-012-9475-5
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Cai ZW, 2021, IEEE T PATTERN ANAL, V43, P1483, DOI 10.1109/TPAMI.2019.2956516
   Chang CY, 2010, PATTERN RECOGN, V43, P3494, DOI 10.1016/j.patcog.2010.04.023
   [迟剑宁 Chi Jianning], 2018, [中国图象图形学报, Journal of Image and Graphics], V23, P1582
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding JR, 2011, J ULTRAS MED, V30, P1259, DOI 10.7863/jum.2011.30.9.1259
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ke, 2018, THESIS GUANGDONG U T
   Keramidas EG, 2012, J MED SYST, V36, P1271, DOI 10.1007/s10916-010-9588-7
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu TJ, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101555
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Xintong, 2019, Computer Engineering and Applications, V55, P254, DOI 10.3778/j.issn.1002-8331.1804-0131
   Liu Y, 2018, MULTIMED TOOLS APPL, V77, P29407, DOI 10.1007/s11042-018-5691-4
   Ma JL, 2017, MED PHYS, V44, P1678, DOI 10.1002/mp.12134
   Ma JL, 2017, ULTRASONICS, V73, P221, DOI 10.1016/j.ultras.2016.09.011
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Peng, 2017, THESIS ZHEJIANG U
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sipos JA, 2009, THYROID, V19, P1363, DOI 10.1089/thy.2009.1608
   Tsantis S, 2009, COMPUT MED IMAG GRAP, V33, P91, DOI 10.1016/j.compmedimag.2008.10.010
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wu Y., 2019, ARXIV PREPRINT ARXIV
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhu CR, 2009, THYROID, V19, P1061, DOI 10.1089/thy.2008.0342
NR 32
TC 4
Z9 5
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13253
EP 13273
DI 10.1007/s11042-021-10939-4
EA MAY 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000656308500001
DA 2024-07-18
ER

PT J
AU Hou, ZM
   Shi, YH
   Wang, J
   Cui, YX
   Yin, BC
AF Hou, Zhenning
   Shi, Yunhui
   Wang, Jin
   Cui, Yingxuan
   Yin, Baocai
TI MS-Net: A lightweight separable ConvNet for multi-dimensional image
   processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-dimensional image processing; Separable convolution neural
   network; Feature extraction and representation; Matricization
AB As the core technology of deep learning, convolutional neural networks have been widely applied in a variety of computer vision tasks and have achieved state-of-the-art performance. However, it's difficult and inefficient for them to deal with high dimensional image signals due to the dramatic increase of training parameters. In this paper, we present a lightweight and efficient MS-Net for the multi-dimensional(MD) image processing, which provides a promising way to handle MD images, especially for devices with limited computational capacity. It takes advantage of a series of one dimensional convolution kernels and introduces a separable structure in the ConvNet throughout the learning process to handle MD image signals. Meanwhile, multiple group convolutions with kernel size 1 x 1 are used to extract channel information. Then the information of each dimension and channel is fused by a fusion module to extract the complete image features. Thus the proposed MS-Net significantly reduces the training complexity, parameters and memory cost. The proposed MS-Net is evaluated on both 2D and 3D benchmarks CIFAR-10, CIFAR-100 and KTH. Extensive experimental results show that the MS-Net achieves competitive performance with greatly reduced computational and memory cost compared with the state-of-the-art ConvNet models.
C1 [Hou, Zhenning; Shi, Yunhui; Wang, Jin; Cui, Yingxuan; Yin, Baocai] Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
C3 Beijing University of Technology
RP Wang, J (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
EM zhenninghou@163.com; syhzm@bjut.edu.cn; ijinwang@bjut.edu.cn;
   cuiyingxuan@emails.bjut.edu.cn; ybc@bjut.edu.cn
OI Wang, Jin/0000-0001-5437-3150
FU National Natural Science Foundation of China [61976011, 61906008,
   U1937207]; Common Program of Beijing Municipal Commission of Education
   [KM202010005013]
FX This study was funded by National Natural Science Foundation of China
   (grant number 61976011, 61906008, U1937207), and Common Program of
   Beijing Municipal Commission of Education (grant number KM202010005013).
CR [Anonymous], 2015, CVPR
   [Anonymous], 2020, Deep Learning in Computer Vision: Principles and Applications
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Goodfellow IJ, 2013, ARXIV13024389
   Han S, 2015, ADV NEUR IN, V28
   Hassaballah M., 2019, Recent Advances in Computer Vision: Theories and Applications
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A. G., 2017, PREPRINT
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Li GB, 2017, PROC CVPR IEEE, P247, DOI 10.1109/CVPR.2017.34
   Liang M, 2015, PROC CVPR IEEE, P3367, DOI 10.1109/CVPR.2015.7298958
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Maningo JMZ, 2019, TENCON 2018 2018 IEE
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Qi N, 2016, PROC CVPR IEEE, P5916, DOI 10.1109/CVPR.2016.637
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tran A, 2014, IEEE INT C ICASSP 82, P1625
   Veleminska J, 2013, NEUR NETW IJCNN 2013, P1
   Yan S, 2020, ARXIV13124400
   Yu XY, 2017, PROC CVPR IEEE, P67, DOI 10.1109/CVPR.2017.15
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
NR 35
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 25673
EP 25688
DI 10.1007/s11042-021-10903-2
EA APR 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000642389300005
DA 2024-07-18
ER

PT J
AU Zermi, N
   Khaldi, A
   Kafi, MR
   Kahlessenane, F
   Euschi, S
AF Zermi, Narima
   Khaldi, Amine
   Kafi, Med Redouane
   Kahlessenane, Fares
   Euschi, Salah
TI A lossless DWT-SVD domain watermarking for medical information security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Medical image; Electronic patient record; Discrete
   wavelet transform; Singular value decomposition
AB The goal of this work is to protect as much as possible the images exchanged in telemedicine, to avoid any confusion between the patient's radiographs, these images are watermarked with the patient's information as well as the acquisition data. Thus, during the extraction, the doctor will be able to affirm with certainty that the images belong to the treated patient. The ultimate goal of our completed work is to properly integrate the watermark with as little distortion as possible to typically retain the medical information in the image. In this innovative approach used DWT decomposition is appropriately applied to the image which allows a remarkably satisfactory adjustment during the insertion. An SVD is then applied to the three subbands LL, LH and HL, which ideally allows retaining the maximum energy of the used image in a guaranteed minimum of singular values. A specific combination of the three resulting singular value matrices is then performed for watermark integration. The proposed approach ensures data integrity, patient confidentiality when sharing data, and robustness to several conventional attacks.
C1 [Zermi, Narima] Badji Mokhtar Annaba Univ, Fac Engn Sci, Labs Automat & Signals Annaba LASA, Elect Dept, Annaba 23000, Algeria.
   [Khaldi, Amine; Kafi, Med Redouane; Kahlessenane, Fares; Euschi, Salah] Univ Kasdi Merbah, Fac Sci & Technol, Comp Sci Dept, Artificial Intelligence & Informat Technol Lab LI, Ouargla 30000, Algeria.
C3 Universite Badji Mokhtar - Annaba; Universite Kasdi Merbah Ouargla
RP Khaldi, A (corresponding author), Univ Kasdi Merbah, Fac Sci & Technol, Comp Sci Dept, Artificial Intelligence & Informat Technol Lab LI, Ouargla 30000, Algeria.
EM Zermi.Narima@univ-annaba.dz; Khaldi.Amine@univ-ouargla.dz;
   Kafi.Redouane@univ-ouargla.dz; Kahlessnane.Fares@univ-ouargla.dz;
   Euchi.Salah@univ-ouargla.dz
RI Khaldi, Amine/AAV-1266-2020; Kafi, Mohamed Redouane/AAT-2301-2021
OI Khaldi, Amine/0000-0002-1637-9129; Kafi, Mohamed
   Redouane/0000-0002-5500-0943; ZERMI, NARIMA/0000-0002-2812-2267;
   KAHLESSENANE, Fares/0000-0003-1193-6325; Salah,
   EUSCHI/0000-0002-8724-1530
CR Albertina B., 2016, **DATA OBJECT**, DOI 10.7937/K9/TCIA.2016.JGNIHEP5
   Alshanbari HS, 2021, MULTIMED TOOLS APPL, V80, P16549, DOI 10.1007/s11042-020-08814-9
   Anand A, 2020, COMPUT COMMUN, V152, P72, DOI 10.1016/j.comcom.2020.01.038
   [Anonymous], 2011, ULTRASOUND IMAGE DAT
   Aparna P, 2019, IET IMAGE PROCESS, V13, P421, DOI 10.1049/iet-ipr.2018.5288
   Araghi TK, 2019, FUTURE GENER COMP SY, V101, P1223, DOI 10.1016/j.future.2019.07.064
   Assini I., 2018, Int. J. Intell. Eng. Syst., V11, P169, DOI [10.22266/ijies2018.0630.18, DOI 10.22266/IJIES2018.0630.18]
   Badshah G, 2016, J MED IMAGING, V3, DOI 10.1117/1.JMI.3.1.017001
   Barani MJ, 2020, J INF SECUR APPL, V53, DOI 10.1016/j.jisa.2020.102509
   Cedillo-Hernandez M, 2020, BIOMED SIGNAL PROCES, V56, DOI 10.1016/j.bspc.2019.101695
   Cohen JP, 2020, arXiv
   Degadwala SD, 2020, PROCEDIA COMPUT SCI, V167, P213, DOI 10.1016/j.procs.2020.03.198
   Devi HS, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102424
   Du L, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115713
   Euschi S., 2020, OPTIK, V208
   Fan TY, 2019, SIGNAL PROCESS-IMAGE, V70, P174, DOI 10.1016/j.image.2018.09.015
   Favorskaya M, 2019, PROCEDIA COMPUT SCI, V159, P1267, DOI 10.1016/j.procs.2019.09.296
   Gajula S., 2017, Int J Pure Appl Math, V117, P285
   Gangadhar Y, 2018, BIOMED SIGNAL PROCES, V43, P31, DOI 10.1016/j.bspc.2018.02.007
   Goodfellow IJ, 2015, NEURAL NETWORKS, V64, P59, DOI 10.1016/j.neunet.2014.09.005
   Haddad S, 2017, IRBM, V38, P198, DOI 10.1016/j.irbm.2017.06.007
   Haddad S, 2020, IEEE T INF FOREN SEC, V15, P2556, DOI 10.1109/TIFS.2020.2972159
   Hashim MM., 2018, International Journal of Engineering & Technology, V7, P3505, DOI DOI 10.14419/IJET.V7I4.17294
   Hassan B, 2019, IEEE ACCESS, V7, P69758, DOI 10.1109/ACCESS.2019.2919381
   Hu HT, 2020, INFORM SCIENCES, V519, P161, DOI 10.1016/j.ins.2020.01.019
   Barani MJ, 2020, MULTIMED TOOLS APPL, V79, P2127, DOI 10.1007/s11042-019-08225-5
   Kahlessenane F, 2021, J AMB INTEL HUM COMP, V12, P2931, DOI 10.1007/s12652-020-02450-9
   Khaldi A., 2019, INT ANN SCI, V8, P143, DOI [10.21467/ias.8.1.143-149, DOI 10.21467/IAS.8.1.143-149]
   Khaldi A., 2018, REV DIREITO ESTA MAY, V10, P147
   Khaldi A., 2020, INT J COMPUT VIS ROB, V10, P373, DOI [10.1504/IJCVR.2020.10029218, DOI 10.1504/IJCVR.2020.10029218, 10.1504/IJCVR.2020.109389]
   Khor HL, 2016, INT J BIOMED IMAGING, V2016, DOI 10.1155/2016/9583727
   Kishore PVV, 2014, 2014 FIRST INTERNATIONAL CONFERENCE ON NETWORKS & SOFT COMPUTING (ICNSC), P258, DOI 10.1109/CNSC.2014.6906662
   Liu XL, 2018, IEEE T CIRC SYST VID, V28, P1047, DOI 10.1109/TCSVT.2016.2633878
   Memon Nisar A., 2009, 2009 3rd International Conference on Information and Communication Technologies (ICICT), P175, DOI 10.1109/ICICT.2009.5268167
   Mun SM, 2019, NEUROCOMPUTING, V337, P191, DOI 10.1016/j.neucom.2019.01.067
   Peyman A., 2020, J INF SECUR APPL, V52
   Qasim AF, 2018, COMPUT SCI REV, V27, P45, DOI 10.1016/j.cosrev.2017.11.003
   Salah E, 2021, APPL ACOUST, V172, DOI 10.1016/j.apacoust.2020.107652
   Sankaran KS, 2019, 2019 INT C COMM SIGN, P0568
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Thanki R, 2019, MULTIMED TOOLS APPL, V78, P13905, DOI 10.1007/s11042-018-6746-2
   Thanki R, 2017, ENG SCI TECHNOL, V20, P1366, DOI 10.1016/j.jestch.2017.06.001
   Vasudevan N., 2019, INT C COMM SIGN PROC
   Verma U., 2019, Int J Innov Technol Explor Eng, V9, P351, DOI [DOI 10.35940/IJITEE.A4126.119119, 10.35940/ijitee.A4126.119119]
   Zhang LN, 2020, SIGNAL PROCESS, V169, DOI 10.1016/j.sigpro.2019.107421
NR 45
TC 21
Z9 21
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24823
EP 24841
DI 10.1007/s11042-021-10712-7
EA APR 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000639518700004
PM 33867813
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Zhang, YB
   Zhang, F
   Guo, L
   Han, H
AF Zhang, Yanbang
   Zhang, Fen
   Guo, Lei
   Han, Henry
TI Salient object detection using feature clustering and compactness prior
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Salient object detection; Feature clustering;
   Superpixel preprocessing
ID FRAMEWORK; NETWORK; MODEL
AB Salient object detection has been challenging computer vision though some advances have been made recently. In this study, we propose a novel salient object detection method by using feature clustering and compactness prior, in the situation of the absence of any prior information. The proposed method consists of four rigorous steps. Superpixel preprocessing is first employed to segment image into superpixels for suppressing noise and reducing computational complexity. Then, clustering algorithm is applied to get the classification of color features. Furthermore, two-dimensional entropy is used to measure the compactness of each cluster and build the background model. Finally, the salient feature is defined as the contrast between background region and other regions, and enhanced by designing a Gauss filter. To better evaluate the salient object detection accuracy, detailed experimental analysis is carried out by using 7 evaluation indexes. Our proposed method outperforms some peers in extensive experiments. It will inspire more similar techniques to be developed in this research topic.
C1 [Zhang, Yanbang; Zhang, Fen] Xianyang Normal Univ, Coll Math & Informat Sci, Xianyang 712000, Shaanxi, Peoples R China.
   [Zhang, Yanbang; Guo, Lei] Northwestern Polytech Univ, Sch Automat, Xian 710072, Shaanxi, Peoples R China.
   [Han, Henry] Fordham Univ, Dept Comp & Informat Sci, New York, NY 10023 USA.
C3 Xianyang Normal University; Northwestern Polytechnical University;
   Fordham University
RP Zhang, YB (corresponding author), Xianyang Normal Univ, Coll Math & Informat Sci, Xianyang 712000, Shaanxi, Peoples R China.; Zhang, YB (corresponding author), Northwestern Polytech Univ, Sch Automat, Xian 710072, Shaanxi, Peoples R China.
EM zhyb@mail.nwpu.edu.cn
FU National Natural Science Foundation (NNSF) of China [61501388]; Qinglan
   Talent Program of Xianyang Normal University [XSYQL201605]; Shaanxi
   Provincial Education Department [18JK0830]; Specialized Research Fund of
   Xianyang Normal University [XSYK19044]; University Youth Outstanding
   Talents Program of Shaanxi Province
FX This work is supported by National Natural Science Foundation (NNSF) of
   China (61501388), University Youth Outstanding Talents Program of
   Shaanxi Province, Qinglan Talent Program of Xianyang Normal University
   (XSYQL201605). Scientific Research Program Funded by Shaanxi Provincial
   Education Department (18JK0830). The Specialized Research Fund of
   Xianyang Normal University (XSYK19044).
CR Abualigah LM, 2018, APPL INTELL, V48, P4047, DOI 10.1007/s10489-018-1190-6
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2018, IEEE T CYBERN
   [Anonymous], 2016, INT J SIGNAL PROCESS
   [Anonymous], 2016, 2016 INT C SIGNAL PR
   Bai C, 2018, J VIS COMMUN IMAGE R, V50, P199, DOI 10.1016/j.jvcir.2017.11.021
   Borji, 2018, INT JOINT C ART INT
   Borji Ali, 2019, [Computational Visual Media, 计算可视媒体], V5, P117
   Chen JZ, 2017, IET COMPUT VIS, V11, P479, DOI 10.1049/iet-cvi.2016.0453
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Everingham M, 2012, PASCAL VISUAL OBJECT
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2013, IEEE T CIRC SYST VID, V23, P2009, DOI 10.1109/TCSVT.2013.2242594
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Hu WT, 2017, CHIN CONT DECIS CONF, P5757, DOI 10.1109/CCDC.2017.7978195
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   James M., 1967, PROC BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   Jiang HZ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.110
   Jin QW, 2023, IEEE T NEUR NET LEAR, V34, P4555, DOI 10.1109/TNNLS.2021.3114203
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Li YL, 2015, NEUROCOMPUTING, V149, P736, DOI 10.1016/j.neucom.2014.08.003
   Li ZY, 2016, PATTERN RECOGN, V52, P317, DOI 10.1016/j.patcog.2015.10.009
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu ZY, 2020, NEUROCOMPUTING, V387, P210, DOI 10.1016/j.neucom.2020.01.045
   Lyudvichenko V, 2017, INT C INTELL COMP CO, P403, DOI 10.1109/ICCP.2017.8117038
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Montazer GA, 2015, NEUROCOMPUTING, V168, P221, DOI 10.1016/j.neucom.2015.05.104
   Mu N, 2018, NEURAL COMPUT APPL, V29, P181, DOI 10.1007/s00521-017-2870-6
   Mukherjee P, 2017, IMAGE VISION COMPUT, V61, P82, DOI 10.1016/j.imavis.2017.02.008
   Naqvi SS, 2018, NEUROCOMPUTING, V312, P187, DOI 10.1016/j.neucom.2018.05.091
   Qiu WL, 2017, NEUROCOMPUTING, V244, P19, DOI 10.1016/j.neucom.2017.03.016
   Quan R, 2018, IEEE T MULTIMEDIA, V20, P1101, DOI 10.1109/TMM.2017.2763780
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Singh C, 2016, J VIS COMMUN IMAGE R, V41, P225, DOI 10.1016/j.jvcir.2016.10.002
   Spackman K.A., 1989, P 6 INT WORKSH MACH, P160, DOI DOI 10.1016/B978-1-55860-036-2.50047-3
   Sultani W, 2018, IEEE T INTELL TRANSP, V19, P2076, DOI 10.1109/TITS.2017.2728680
   Tatler BW, 2007, J VISION, V7, DOI 10.1167/7.14.4
   Wang BY, 2018, VISUAL COMPUT, V34, P645, DOI 10.1007/s00371-017-1404-7
   Wang J, 2017, SALIENT OBJECT DETEC, V123
   Wang W., 2019, ARXIV190409146
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005
   WEI Y, 2012, ECCV, P29
   Wu Z, 2019, IEEE I CONF COMP VIS, P7263, DOI 10.1109/ICCV.2019.00736
   Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Ye LW, 2017, IEEE T MULTIMEDIA, V19, P1742, DOI 10.1109/TMM.2017.2693022
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang J, 2017, INFORM SCIENCES, V399, P154, DOI 10.1016/j.ins.2017.03.005
   Zhang YB, 2014, IEEE IMAGE PROC, P1184, DOI 10.1109/ICIP.2014.7025236
   Zhang YB, 2014, OPTIK, V125, P5872, DOI 10.1016/j.ijleo.2014.07.052
   Zhao JX, 2019, PROC CVPR IEEE, P3922, DOI 10.1109/CVPR.2019.00405
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhou L, 2017, IEEE T IMAGE PROCESS, V26, P5882, DOI 10.1109/TIP.2017.2738839
   Zhu DD, 2018, J VIS COMMUN IMAGE R, V54, P1, DOI 10.1016/j.jvcir.2018.03.017
   Zhu SP, 2018, NEUROCOMPUTING, V275, P511, DOI 10.1016/j.neucom.2017.08.054
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 66
TC 2
Z9 2
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24867
EP 24884
DI 10.1007/s11042-021-10744-z
EA APR 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000639518700009
DA 2024-07-18
ER

PT J
AU Kumari, R
   Dev, A
   Kumar, A
AF Kumari, Ruchika
   Dev, Amita
   Kumar, Ashwani
TI An efficient adaptive artificial neural network based text to speech
   synthesizer for Hindi language
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hindi TTS synthesis; Prediction accuracy; ANN; ALO; Fundamental
   frequency; Text to speech and MFCC
ID TEAGER ENERGY OPERATOR; SYSTEM; SEGMENTATION; ALGORITHM; DURATION; CUES
AB Speech recognition is one of the major research regions these days under speech processing. This paper depends on developing a whole process that takes the input as the text file from the user and provides the output in speech form. This paper proposes a text to speech synthesizer for the Hindi language depends on the coefficients of Mel-frequency cepstral (MFCC) features are extracted to the production and linguistic constraints proposed for modeling the parameters such as intonation, duration, and syllable intensities. The features extracted from the MFCC features are phrasing, fundamental frequency, duration, etc. Neural network models are discovered to confine the features as mentioned earlier, employing MFCC. The performance of the proposed ALO-ANN is computed utilizing objective measures such as prediction error (eta), standard deviation (sigma), and linear correlation coefficient (chi). The accuracy predicted of the proposed ALO-ANN models is high when compared with other models such as DNN and ANN. The prediction accuracy is high for ALO-ANN models when compared with other models.
C1 [Kumari, Ruchika; Dev, Amita] Indira Gandhi Delhi Tech Univ Women, Delhi, India.
   [Kumar, Ashwani] Indira Gandhi Delhi Tech Univ Women, Dept ECE, Delhi, India.
C3 Indira Gandhi Delhi Technical University for Women (IGDTUW); Indira
   Gandhi Delhi Technical University for Women (IGDTUW)
RP Kumari, R (corresponding author), Indira Gandhi Delhi Tech Univ Women, Delhi, India.
EM kruchika.phd@gmail.com
RI DEV, AMITA/GOV-5004-2022
CR Absa AHA, 2018, IEEE ACCESS, V6, P43157, DOI 10.1109/ACCESS.2018.2859631
   Alam MMG, 2019, SOFT COMPUT, V23, P1079, DOI 10.1007/s00500-018-3124-y
   Ansal V, 2020, SOFT COMPUT, V24, P1171, DOI 10.1007/s00500-019-03952-1
   Athiyaa, 2019, SPOKEN LANGUAGE IDEN, V06, P4243
   Baby A, 2017, INTERSPEECH, P3817, DOI 10.21437/Interspeech.2017-666
   Balyan A, 2016, IETE J RES, V62, P146, DOI 10.1080/03772063.2015.1075914
   Begum Afruza, 2019, Progress in Advanced Computing and Intelligent Engineering. Proceedings of ICACIE 2017. Advances in Intelligent Systems and Computing (AISC 714), P291, DOI 10.1007/978-981-13-0224-4_27
   Deka A., 2019, 2019 NAT C COMM NCC, P1
   Gilbert AC, 2019, J ACOUST SOC AM, V146, P4255, DOI 10.1121/1.5134781
   Gregory MA, 2010, 2010 4 INT C SIGN PR, P1
   Han T, 2019, MEASUREMENT, V138, P400, DOI 10.1016/j.measurement.2019.02.053
   Jalin A. Femina, 2017, 2017 IEEE International Conference on Circuits and Systems (ICCS). Proceedings, P447, DOI 10.1109/ICCS1.2017.8326040
   Javed MF, 2020, APPL NANOSCI, V10, P3011, DOI 10.1007/s13204-019-01071-9
   Li Y, 2015, SPEECH COMMUN, V72, P59, DOI 10.1016/j.specom.2015.05.003
   Mirjalili S, 2015, ADV ENG SOFTW, V83, P80, DOI 10.1016/j.advengsoft.2015.01.010
   Panda SP, 2016, INT J SPEECH TECHNOL, V19, P9, DOI 10.1007/s10772-015-9320-6
   Patil HA, 2011, INT J SPEECH TECHNOL, V14, P321, DOI 10.1007/s10772-011-9110-8
   Pitale, 2019, INT RES J ENG TECHNO, V06, P630
   Rajendran V, 2019, IETE J RES, V65, P601, DOI 10.1080/03772063.2018.1452642
   Rajisha TM, 2016, PROC TECH, V24, P1097, DOI 10.1016/j.protcy.2016.05.242
   Ramani B, 2016, CIRC SYST SIGNAL PR, V35, P1283, DOI 10.1007/s00034-015-0118-1
   Ramteke G. D., 2017, International Journal of Image, Graphics and Signal Processing, V9, P1, DOI 10.5815/ijigsp.2017.03.01
   Rathod Prajakta S, 2011, 2011 NIRMA U INT C E, P1
   Rebai I, 2015, COMPUT SPEECH LANG, V34, P43, DOI 10.1016/j.csl.2015.04.002
   Reddy VR, 2016, NEUROCOMPUTING, V171, P1323, DOI 10.1016/j.neucom.2015.07.053
   Reddy VR, 2013, COMPUT SPEECH LANG, V27, P1105, DOI 10.1016/j.csl.2013.02.003
   Rejeesh MR, 2020, MULTIMED TOOLS APPL, V79, P28411, DOI 10.1007/s11042-020-09234-5
   Rejeesh MR, 2019, MULTIMED TOOLS APPL, V78, P22691, DOI 10.1007/s11042-019-7577-5
   Ribeiro MS, 2016, INTERSPEECH, P3186, DOI 10.21437/Interspeech.2016-1034
   Sangramsing K, 2015, INT RES J ENG TECHNO, V2, P948
   Shahzada, 2016, LANGUAGE TECHNOLOGY, P101
   Sharma P, 2018, COMPUT SPEECH LANG, V52, P191, DOI 10.1016/j.csl.2018.05.003
   Shen JL, 2006, IEEE T MULTIMEDIA, V8, P1179, DOI 10.1109/TMM.2006.884618
   Shreekanth T, 2015, PROCEDIA COMPUT SCI, V46, P60, DOI 10.1016/j.procs.2015.01.056
   Sreenivasa Rao K, 2016, P 13 INT C NAT LANGU, P46
   Subhashini J, 2019, WIRELESS PERS COMMUN, V107, P2105, DOI 10.1007/s11277-019-06374-2
   Sundararaj, 2016, INT J INTELL ENG SYS, V9, P117, DOI [10.22266/ijies2016.0930.12, DOI 10.22266/IJIES2016.0930.12]
   Sundararaj V, 2020, PROG PHOTOVOLTAICS, V28, P1128, DOI 10.1002/pip.3315
   Sundararaj V, 2019, INT J BIOMED ENG TEC, V31, P325, DOI 10.1504/IJBET.2019.103242
   Sundararaj V, 2019, WIRELESS PERS COMMUN, V104, P173, DOI 10.1007/s11277-018-6014-9
   Sundararaj V, 2018, COMPUT SECUR, V77, P277, DOI 10.1016/j.cose.2018.04.009
   Yadav J, 2016, CIRC SYST SIGNAL PR, V35, P139, DOI 10.1007/s00034-015-0051-3
   Zhao Xufang, 2008, 2008 CAN C EL COMP E
   Zhou SP, 2020, LECT NOTES COMPUT SC, V11962, P52, DOI 10.1007/978-3-030-37734-2_5
NR 44
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24669
EP 24695
DI 10.1007/s11042-021-10771-w
EA APR 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000638484500001
DA 2024-07-18
ER

PT J
AU Maken, P
   Gupta, A
AF Maken, Payal
   Gupta, Abhishek
TI A method for automatic classification of gender based on text-
   independent handwriting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Forensics; Gender prediction; Handwriting recognition (HWR); Image
   processing; Support vector machine (SVM)
ID SEGMENTATION; SEX
AB Handwriting recognition is used for the prediction of various demographic traits such as age, gender, nationality, etc. Out of all the applications gender prediction is mainly admired topic among researchers. The relation between gender and handwriting can be seen from the physical appearance of the handwriting. This research work predicts gender from handwriting using the landmarks of differences between the two genders. We use the shape or visual appearance of the handwriting for extracting features of the handwriting such as slanteness (direction), area (no of pixels occupied by text), perimeter (length of edges), etc. Classification is carried out using the Support Vector Machine (SVM) as a classifier which transforms the nonlinear problem into linear using its kernel trick, logistic regression, KNN and at the end to enhance the classification rates we use Majority Voting. The experimental results obtained on a dataset of 282 writers with 2 samples per writer shows that the proposed method attains appealing performance on writer detection and text-independent environment.
C1 [Maken, Payal; Gupta, Abhishek] Shri Mata Vaishno Devi Univ, Sch Comp Sci & Engn, Katra 182320, Jammu & Kashmir, India.
C3 Shri Mata Vaishno Devi University
RP Gupta, A (corresponding author), Shri Mata Vaishno Devi Univ, Sch Comp Sci & Engn, Katra 182320, Jammu & Kashmir, India.
EM payalmaken33@gmail.com; abhishekgupta10@yahoo.co.in
RI Gupta, Abhishek/O-3016-2019
OI Gupta, Abhishek/0000-0002-8592-9964; Maken, Payal/0000-0002-7483-090X
CR Ahmed M, 2017, EXPERT SYST APPL, V85, P158, DOI 10.1016/j.eswa.2017.05.033
   Al, 2012, INT C FRONT HANDWRIT, P831, DOI [10.1109/ICFHR.2012.218, DOI 10.1109/ICFHR.2012.218]
   Al Maadeed S, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-10
   Al Maadeed S, 2012, INT CONF FRONT HAND, P746, DOI 10.1109/ICFHR.2012.256
   Altman N, 2015, NAT METHODS, V12, P999, DOI 10.1038/nmeth.3627
   Atanasiu V, 2011, PROC INT CONF DOC, P628, DOI 10.1109/ICDAR.2011.132
   Atmaja R.D., 2016, Indonesian J. Electric. Eng. Comput. Sci., V3, P377, DOI DOI 10.11591/IJEECS.V3.I2.PP377-382
   Bahrami, 2008, IRAN REHABIL, V6, P39
   Bangare S. L., 2015, International Journal of Applied Engineering Research, V10, P21777, DOI [10.37622/IJAER/10.9.2015.21777-21783, DOI 10.37622/IJAER/10.9.2015.21777-21783]
   Beech JR, 2005, PERS INDIV DIFFER, V39, P459, DOI 10.1016/j.paid.2005.01.024
   Benchamardimath, 2015, INT J RES ENG TECHNO, V03, P155
   Bouadjenek N, 2017, LECT NOTES ELECTR EN, V411, P317, DOI 10.1007/978-3-319-48929-2_24
   Boyadzhieva D, 2014, CYBERN INF TECHNOL, V14, P92, DOI 10.2478/cait-2014-0022
   Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2
   Burr V, 2002, J SOC PSYCHOL, V142, P691, DOI 10.1080/00224540209603929
   Chanda S., 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P369, DOI 10.1109/DAS.2012.86
   Chanda Sukalpa, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2005, DOI 10.1109/ICPR.2010.494
   Cloppet F., 2014, ADV GRAPHONOMICS P I, V2009, P226
   Cutler A, 2010, REGRESSION CLASSIFIC, P1
   Dinehart LH, 2015, J EARLY CHILD LIT, V15, P97, DOI 10.1177/1468798414522825
   Djeddi C, 2014, INT CONF FRONT HAND, P93, DOI 10.1109/ICFHR.2014.23
   Djeddi C, 2015, PROC INT CONF DOC, P1191, DOI 10.1109/ICDAR.2015.7333949
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Fakhr, 2011, ARABIC OPTICAL CHARA, DOI 10.13140/2.1.3898.3682
   Fornés A, 2008, PROCEEDINGS OF THE 8TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, P347, DOI 10.1109/DAS.2008.29
   Gattal, 2020, LECT NOTES ARTIFICIA, DOI 10.1007/978-3-030-51935-3_25
   Gattal A, 2018, EXPERT SYST APPL, V99, P155, DOI 10.1016/j.eswa.2018.01.038
   Ghosh S, 2020, CAAI T INTELL TECHNO, V5, P55, DOI 10.1049/trit.2019.0051
   Gupta B., 2017, INT J COMPUT APPL, V163, P15, DOI DOI 10.5120/IJCA2017913660
   Hamid S, 1996, J SOC PSYCHOL, V136, P778, DOI 10.1080/00224545.1996.9712254
   Hao HR, 2016, CYBERN INF TECHNOL, V16, P5, DOI 10.1515/cait-2016-0047
   Hartley J., 1991, SEX DIFFER HANDWRITI, V17, P141
   HASSAINE A, 2013, PROC INT CONF DOC
   Hayes WN, 1996, PERCEPT MOTOR SKILL, V83, P791, DOI 10.2466/pms.1996.83.3.791
   Hazra Tapan Kumar, 2016, International Journal of Science and Research (IJSR), V5, P750
   Jaeger S., 2001, International Journal on Document Analysis and Recognition, V3, P169, DOI 10.1007/PL00013559
   Jeyalaksshmi, 2017, INT J ENG TECHNOL, V7, P121
   Jung Y, 2015, J NONPARAMETR STAT, V27, P167, DOI 10.1080/10485252.2015.1010532
   KAIRA A., 2017, Journal of the Practice of Cardiovascular Sciences, V3, P36, DOI [10.4103/jpcs.jpcs_11_17, DOI 10.4103/JPCS.JPCS_11_17]
   Kameya H, 2006, PATTERN RECOGN LETT, V27, P567, DOI 10.1016/j.patrec.2005.09.022
   Karlik B., 2011, INT J ARTIF INTELL E, V1, P111, DOI DOI 10.1088/1742-6596/1237/2/022030
   Koppenhaver KM, 2007, PRINCIPLES PRACTICE, P207
   Kumar G, 2014, INT C ADV COMPUT COM, P5, DOI 10.1109/ACCT.2014.74
   Kumar T., 2010, Int J Comput Appl, V7, P7, DOI DOI 10.5120/1140-1493
   Liwicki M, 2006, LECT NOTES COMPUT SC, V3872, P186
   Liwicki M, 2007, PROC 13 C GRAPHONOMI, P179
   Liwicki M, 2011, PATTERN ANAL APPL, V14, P87, DOI 10.1007/s10044-010-0178-6
   Mahanta, 2013, SKEW SLANT ANGLES HA, P2030
   Mahmoud SA, 2014, PATTERN RECOGN, V47, P1096, DOI 10.1016/j.patcog.2013.08.009
   Majnik M, 2013, INTELL DATA ANAL, V17, P531, DOI 10.3233/IDA-130592
   Maken, 2019, INT J SCI RES, V6, P206
   Maken P, 2019, CYBERN INF TECHNOL, V19, P51, DOI 10.2478/cait-2019-0015
   Marti U.-V., 2002, International Journal on Document Analysis and Recognition, V5, P39, DOI 10.1007/s100320200071
   Marti U.-V., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P705, DOI 10.1109/ICDAR.1999.791885
   McLachlan G. J., 1999, Resonance, V4, P20
   Mente, 2014, MANAG RES, V3, P210
   Mirza A, 2016, INT CONF FRONT HAND, P395, DOI [10.1109/ICFHR.2016.0080, 10.1109/ICFHR.2016.75]
   Pali V, 2014, 2014 6TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS, P142, DOI 10.1109/CICN.2014.43
   Parvez MT, 2013, PATTERN RECOGN, V46, P141, DOI 10.1016/j.patcog.2012.07.012
   Patil A. B., 2016, INT J COMPUT ENG RES, V6, P1
   Purkait P., 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P658, DOI 10.1109/ICFHR.2010.108
   Raid A., 2014, Int. J. Comput. Sci., Eng. Inf. Technol. (IJCSEIT), V4, P9, DOI DOI 10.5121/IJCSEIT.2014.4302
   Rastogi P, J INDIAN ACAD FORENS, V32, P11
   Razak Z, 2008, INT J COMPUT SCI NET, V8, P12
   Sapp M., 2007, SLEEP HYPNOSIS, V9, P67
   Saravanan C, 2010, INT C COMPUT ENG APP, P196, DOI 10.1109/ICCEA.2010.192
   Sathya R., 2013, International Journal of Advanced Research in Artificial Intelligence, V2, P34
   Schomaker L, 2007, PATTERN RECOGN LETT, V28, P719, DOI 10.1016/j.patrec.2006.08.005
   Shabani, HANDWRITTEN OBJECTS
   Sharma, 2014, INT J SCI ENG RES, V5, P614
   Sharma A, 2017, REV HANDWRITTEN CHAR, V8491, P71
   Shukla, 2017, DETERMINATION SEX HA, V9, P11
   Siddiqi I., 2017, IMAVIS IMAGE VISION, V59, P7
   Siddiqi I, 2016, 15 INT C FRONT HANDW, P602
   Siddiqi I, 2015, PATTERN ANAL APPL, V18, P887, DOI 10.1007/s10044-014-0371-0
   Sinwar D., 2014, INT J RES APPL SCI E, V2, P270
   Spear M.G., 1989, BRIT EDUC RES J, V15, P271
   Strecht P., 2015, P 8 INT C ED DAT MIN, P392
   Tett RP, 1997, PERS INDIV DIFFER, V22, P11, DOI 10.1016/S0191-8869(96)00183-3
   Ting K.M., 2017, Encyclopedia of Machine Learning and Data Mining, P260, DOI [DOI 10.1007/978-1-4899-7687-1_50, 10.1007/978-1-4899-7687-150, DOI 10.1007/978-1-4899-7687-150]
   Visa Sofia D., 2011, ConfusionMatrixBased Feature Selection Sofia, V710, P8
   Wang XL, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P509
   Xie Q, 2013, INT C DOCUMENT ANAL, P10
   Yilmaz M. B., 2011, 2011 INT JOINT C BIO
NR 84
TC 15
Z9 15
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24573
EP 24602
DI 10.1007/s11042-021-10837-9
EA APR 2021
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000637685200001
DA 2024-07-18
ER

PT J
AU Konstantoudakis, K
   Breitgand, D
   Doumanoglou, A
   Zioulis, N
   Weit, A
   Christaki, K
   Drakoulis, P
   Christakis, E
   Zarpalas, D
   Daras, P
AF Konstantoudakis, Konstantinos
   Breitgand, David
   Doumanoglou, Alexandros
   Zioulis, Nikolaos
   Weit, Avi
   Christaki, Kyriaki
   Drakoulis, Petros
   Christakis, Emmanouil
   Zarpalas, Dimitrios
   Daras, Petros
TI Serverless streaming for emerging media: towards 5G network-driven cost
   optimization A real-time adaptive streaming FaaS service for
   small-session-oriented immersive media
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Immersive media; Serverless; 5G; Real-time adaptive streaming; Service
   optimization; Cognitive networking; OPEX optimization;
   Function-as-a-Service (FaaS)
ID VIDEO; COMPRESSION; ADAPTATION; EFFICIENCY; PLATFORM; QUALITY
AB Immersive 3D media is an emerging type of media that captures, encodes and reconstructs the 3D appearance of people and objects, with applications in tele-presence, teleconference, entertainment, gaming and other fields. In this paper, we discuss a novel concept of live 3D immersive media streaming in a serverless setting. In particular, we present a novel network-centric adaptive streaming framework which deviates from the traditional client-based adaptive streaming used in 2D video. In our framework the decisions for the production of the transcoding profiles are taken in a centralized manner, by considering consumer metrics vs provisioning costs and inferring the expected consumer quality of experience and behavior based on them. In addition, we demonstrate that a naive application of the serverless paradigm might be sub-optimal under some common immersive 3D media scenarios.
C1 [Konstantoudakis, Konstantinos; Doumanoglou, Alexandros; Zioulis, Nikolaos; Christaki, Kyriaki; Drakoulis, Petros; Christakis, Emmanouil; Zarpalas, Dimitrios; Daras, Petros] Ctr Res & Technol Hellas CERTH, Informat Technol Inst ITI, Visual Comp Lab VCL, Thessaloniki, Greece.
   [Breitgand, David; Weit, Avi] IBM Res, Hybrid Cloud Cloud & Data Technol, Haifa, Israel.
C3 Centre for Research & Technology Hellas; International Business Machines
   (IBM)
RP Konstantoudakis, K (corresponding author), Ctr Res & Technol Hellas CERTH, Informat Technol Inst ITI, Visual Comp Lab VCL, Thessaloniki, Greece.
EM k.konstantoudakis@iti.gr; davidbr@il.ibm.com; aldoum@iti.gr;
   nzioulis@iti.gr; weit@il.ibm.com; kchristaki@iti.gr;
   petros.drakoulis@iti.gr; manchr@iti.gr; zarpalas@iti.gr; daras@iti.gr
RI Daras, Petros/F-5284-2012
OI Daras, Petros/0000-0003-3814-6710; Christaki,
   Kyriaki/0000-0002-1137-5196; Breitgand, David/0000-0002-0473-041X;
   ZIOULIS, NIKOLAOS/0000-0002-7898-9344
FU European Union's Horizon 2020 research and innovation programme
   [761699]; H2020 - Industrial Leadership [761699] Funding Source: H2020 -
   Industrial Leadership
FX This work has been realized in the context of the 5G-MEDIA project
   (www.5gmedia.eu), which has received funding from the European Union's
   Horizon 2020 research and innovation programme under grant agreement No.
   761699.
CR Alexiadis DS, 2017, IEEE T CIRC SYST VID, V27, P798, DOI 10.1109/TCSVT.2016.2576922
   Alvarez F, 2019, IEEE T BROADCAST, V65, P369, DOI 10.1109/TBC.2019.2901400
   [Anonymous], 2020, IEEE COMMUNICATION M
   [Anonymous], 2005, P 3 EUR S GEOM PROC
   [Anonymous], 2019, NEW EUROPEAN MEDIA N
   [Anonymous], 1991, The Art of Computer Systems Performance Analysis: Techniques for Experimental Design, Measurement, Simulation, and Modeling
   Ao LX, 2018, PROCEEDINGS OF THE 2018 ACM SYMPOSIUM ON CLOUD COMPUTING (SOCC '18), P263, DOI 10.1145/3267809.3267815
   Apache OpenWhisk:, OP SOURC SERV CLOUD
   Argo Team, ARG WORKFL
   Athanasoulis P, 2020, MMEDIA 2020 12 INT C
   Ballard T, 2019, PROCEEDINGS OF THE 10TH ACM MULTIMEDIA SYSTEMS CONFERENCE (ACM MMSYS'19), P308, DOI 10.1145/3304109.3323837
   Barman N, 2019, IEEE ACCESS, V7, P30831, DOI 10.1109/ACCESS.2019.2901778
   Bentaleb A, 2019, IEEE COMMUN SURV TUT, V21, P562, DOI 10.1109/COMST.2018.2862938
   Bhargava A, 2019, COMP EVALUATION USER, DOI [10.1145/3345313, DOI 10.1145/3345313]
   Breitgand D, 2019, USING GPUS APACHE OP
   Chakarothai Jerdvisanop, 2018, 2018 IEEE International Workshop on Electromagnetics: Applications and Student Innovation Competition (iWEM), DOI 10.1109/iWEM.2018.8536621
   Chen YJ, 2015, IEEE GLOB COMM CONF, DOI 10.1109/GLOCOM.2015.7416940
   Chou PA, 2020, IEEE T IMAGE PROCESS, V29, P2203, DOI 10.1109/TIP.2019.2908095
   Christaki K, 2019, LECT NOTES COMPUT SC, V11296, P566, DOI 10.1007/978-3-030-05716-9_47
   Collet A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766945
   Crowle S, 2015, WEB3D 2015, P269, DOI 10.1145/2775292.2775296
   Cui L, 2019, IEEE CONSUM ELECTR M, V8, P17, DOI 10.1109/MCE.2019.2905483
   Ding AY, 2018, ARXIV181006057
   Domanski M, 2017, INT CONF SYST SIGNAL, DOI 10.1109/IWSSIP.2017.7965623
   Dou MS, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925969
   Doumanoglou Alexandros, 2018, 2018 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB), P11, DOI 10.1109/BMSB.2018.8436942
   Doumanoglou A, 2019, IEEE J EM SEL TOP C, V9, P190, DOI 10.1109/JETCAS.2019.2898768
   Doumanoglou A, 2018, IEEE T BROADCAST, V64, P379, DOI 10.1109/TBC.2018.2823909
   Doumanoglou A, 2014, IEEE T CIRC SYST VID, V24, P2099, DOI 10.1109/TCSVT.2014.2319631
   El Marai O, 2018, IEEE T BROADCAST, V64, P11, DOI 10.1109/TBC.2017.2781146
   ETSI: Multi-access Edge Computing (MEC), 2019, FRAM REF ARCH GS MEC
   Fan CL, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3329119
   Girinathan J, 2018, SIMPLE SERVERLESS VI
   Graf M, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P261, DOI 10.1145/3083187.3084016
   Hannuksela MM, 2019, IEEE DATA COMPR CONF, P418, DOI 10.1109/DCC.2019.00050
   He J, 2018, MOBISYS'18: PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P482, DOI 10.1145/3210240.3210323
   Hosseini M, 2019, ARXIV191100812191100
   Hosseini M, 2016, IEEE INT SYM MULTIM, P107, DOI [10.1109/ISM.2016.45, 10.1109/ISM.2016.0028]
   Hossfeld T, 2015, COMPUT NETW, V81, P320, DOI 10.1016/j.comnet.2015.02.015
   ISO/IEC:, INF TECHN DYN AD STR
   Karakottas A, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P831, DOI 10.1109/VR.2018.8446561
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Kleinrock L, 1976, Queueing Systems, V2
   Kritikos K, 2018, INT CONF UTIL CLOUD, P161, DOI 10.1109/UCC-Companion.2018.00051
   Krivokuca M, 2020, IEEE T IMAGE PROCESS, V29, P2217, DOI 10.1109/TIP.2019.2957853
   kubernetes, Production-Grade Container Orchestration
   Li Z, 2014, IEEE J SEL AREA COMM, V32, P719, DOI 10.1109/JSAC.2014.140405
   Maglo A, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2693443
   Mao HZ, 2017, SIGCOMM '17: PROCEEDINGS OF THE 2017 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P197, DOI 10.1145/3098822.3098843
   Mehrabi A, 2019, IEEE T MOBILE COMPUT, V18, P787, DOI 10.1109/TMC.2018.2850026
   Mekuria R, 2017, IEEE T CIRC SYST VID, V27, P828, DOI 10.1109/TCSVT.2016.2543039
   Misra K, 2013, IEEE J-STSP, V7, P969, DOI 10.1109/JSTSP.2013.2271451
   NVIDIA, Multi-Process Service
   Orts-Escolano S, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P741, DOI 10.1145/2984511.2984517
   Pantos R., 2017, Http live streaming, DOI DOI 10.17487/RFC8216
   Park Jeman., 2018, 2018 16 ANN C PRIVAC, P1, DOI [10.1109/GLOCOM.2018.8647537, DOI 10.1109/GLOCOM.2018.8647537]
   Paudyal P, 2016, MULTIMED TOOLS APPL, V75, P16461, DOI 10.1007/s11042-015-3214-0
   Robitza Werner., 2017, PROC 9 INT C QUAL MU, P1
   SamiKekki EA, 2018, 28 ETSI
   Schatz R, 2017, INT WORK QUAL MULTIM
   Schmidt S, 2018, 2018 10 INT C QUAL M, P1
   Schoeffelen T, 2020, DESIGNING SERVERLESS
   Schreer O, 2019, IEEE IMAGE PROC, P4310, DOI [10.1109/ICIP.2019.8803576, 10.1109/icip.2019.8803576]
   Seufert M, 2015, IEEE COMMUN SURV TUT, V17, P469, DOI 10.1109/COMST.2014.2360940
   Singla A, 2019, PROCEEDINGS OF THE 10TH ACM MULTIMEDIA SYSTEMS CONFERENCE (ACM MMSYS'19), P232, DOI 10.1145/3304109.3306218
   Skupin R, 2017, IEEE IMAGE PROC, P4592, DOI 10.1109/ICIP.2017.8297155
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Spiteri K, 2016, ARXIV 160106748 CS
   Sterzentsenko V, 2018, 2018 14TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS), P200, DOI 10.1109/SITIS.2018.00038
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sun LY, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P162, DOI 10.1145/3204949.3204978
   Tian Y, 2018, 2018 IEEE 8TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P321, DOI 10.1109/CCWC.2018.8301615
   Timmerer C, 2019, 2019 11 INT C QUAL M, P1, DOI [10.1109/QoMEX.2019.8743230, DOI 10.1109/QOMEX.2019.8743230]
   van der Hooft J, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2405, DOI 10.1145/3343031.3350917
   Wette C, 2018, 2018 15 IEEE ANN CON, P1
   Wien M, 2019, IEEE J EM SEL TOP C, V9, P5, DOI 10.1109/JETCAS.2019.2898948
   Xie L, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P315, DOI 10.1145/3123266.3123291
   Xin ZH, 2019, VISUAL COMPUT, V35, P1245, DOI 10.1007/s00371-018-1590-y
   Yamasaki T, 2010, IEEE IMAGE PROC, P3433, DOI 10.1109/ICIP.2010.5652911
   Yates RD, 2014, Probability and stochastic processes: a friendly introduction for electrical and computer engineers
   Yla-Jaaski A., 2017, 2017 IEEE 13 INT C W, P1
   Zhang GH, 2020, IEEE T MOBILE COMPUT, V19, P1346, DOI 10.1109/TMC.2019.2909202
   Zhang M, 2019, PROCEEDINGS OF THE 29TH ACM WORKSHOP ON NETWORK AND OPERATING SYSTEMS SUPPORT FOR DIGITAL AUDIO AND VIDEO (NOSSDAV'19), P61, DOI 10.1145/3304112.3325608
   Zhang W, 2020, ARXIV200502088
   Zheng YH, 2017, IEEE T CIRC SYST VID, V27, P1777, DOI 10.1109/TCSVT.2016.2556584
   Zioulis N, 2016, IEEE IMAGE PROC, P365, DOI 10.1109/ICIP.2016.7532380
NR 86
TC 2
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12211
EP 12250
DI 10.1007/s11042-020-10219-7
EA MAR 2021
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000632315900004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ko, KR
   Pan, SB
AF Ko, Kyeong-Ri
   Pan, Sung Bum
TI CNN and bi-LSTM based 3D golf swing analysis by frontal swing sequence
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Golf swing analysis; Sequence image regression; Deep learning
ID MOTION; SENSOR
AB In this paper, the method to overcome the limitations of the existing three-dimensional golf swing analysis system by using deep learning technology, and analyze the three-dimensional quantitative information through sequence images acquired with a single camera is studied. In this paper, CNN was used to extract the appropriate features from the image of the golf frontal swing sequence, and a regression model based on Bi-LSTM was used to predict the correct information in each sequence. This classifies the major swing section, and analyzes the quantitative status of the twisting angles of the upper body, head, shoulder and pelvis for body-sway, head-up and X-factor analysis. For the experiment, in this paper, a total of 520 times swing data were obtained using no. 1 wood club and no. 7 iron club from five subjects. In the major swing section classification experiment, each swing section was classified with an average accuracy of about 95.44%. Quantitative analysis results from each analysis model showed that the upper body motion prediction RMSE averaged 4.23 degrees, the head motion prediction RMSE averaged 5.18 degrees, and the shoulder and pelvis twisting angle prediction RMSE averaged 3.86 degrees. As a result, it was confirmed that a three-dimensional quantitative analysis based on sequence images is possible.
C1 [Ko, Kyeong-Ri; Pan, Sung Bum] Chosun Univ, IT Res Inst, Gwangju, South Korea.
   [Pan, Sung Bum] Chosun Univ, Dept Elect Engn, Gwangju, South Korea.
C3 Chosun University; Chosun University
RP Pan, SB (corresponding author), Chosun Univ, IT Res Inst, Gwangju, South Korea.; Pan, SB (corresponding author), Chosun Univ, Dept Elect Engn, Gwangju, South Korea.
EM happymode4621@gmail.com; sbpan@chosun.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea(NRF) - Ministry of Education [2017R1A6A1A03015496]; National
   Research Foundation of Korea(NRF) - Korea government(MSIT)
   [NRF-2018R1A2B6001984]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Education (No. 2017R1A6A1A03015496) and by the National Research
   Foundation of Korea(NRF) grant funded by the Korea government(MSIT) (No.
   NRF-2018R1A2B6001984).
CR An J., 2013, Journal of Motor Learning and Development, P2
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bourgain M, 2018, J BIOMECH, V75, P154, DOI 10.1016/j.jbiomech.2018.04.025
   Chiu J.P., 2016, Named entity recognition with bidirectional lstm-cnns, V4, P357, DOI 10.1162/tacl_a_00104
   Chotimanus P., 2012, 2012 Computing, Communications and Applications Conference (ComComAp 2012), P420, DOI 10.1109/ComComAp.2012.6154885
   Fradkin A, 2017, ROUTLEDGE INT HDB GO, V1st Edition, P490
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Ha Chul-Soo, 2008, [The Korean Society of Sports Science, 한국체육과학회지], V17, P675
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hua YS, 2019, ISPRS J PHOTOGRAMM, V149, P188, DOI 10.1016/j.isprsjprs.2019.01.015
   Hua-Tsung Chen, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457819
   Huang SY, 2015, MULTIMED TOOLS APPL, V74, P10679, DOI 10.1007/s11042-014-2198-5
   Ji SP, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10010075
   Jiao L, 2018, IPSI BGD T INTERNET, V14, P29
   Jin So Yeon, 2017, [Journal of the Institute of Electronics and Information Engineers, 전자공학회논문지], V54, P33
   Jong Kim Hwa, 2017, [Informatization Policy, 정보화정책], V24, P79, DOI 10.22693/NIAIP.2017.24.4.079
   Kelly P., 2010, Proceedings of the 2010 ACM workshop on Surreal media and virtual cloning, P51, DOI DOI 10.1145/1878083.1878098
   Kim Pyeoung-Kee, 2014, [Journal of The Korea Society of Computer and Information, 한국컴퓨터정보학회논문지], V19, P197
   Kim Seon-Jeong, 2002, [Journal of Sport and Leisure Studies, 한국사회체육학회지], V17, P145
   Kim YJ, 2017, IEEE T CONSUM ELECTR, V63, P309, DOI 10.1109/TCE.2017.014937
   Ko KR, 2018, THESIS GRADUATE SCH
   Ko KR, 2018, P KIIT SUMM C, P37
   박준욱, 2013, [JOURNAL OF BROADCAST ENGINEERING, 방송공학회 논문지], V18, P380, DOI 10.5909/JBE.2013.18.3.380
   Kyeong-Ri Ko, 2018, [Journal of Korean Institute of Information Technology, 한국정보기술학회논문지], V16, P125, DOI 10.14801/jkiit.2018.16.1.125
   Kyeong-Ri Ko, 2015, [Journal of the Institute of Electronics and Information Engineers, 전자공학회논문지], V52, P117
   Lee Kyungil, 2006, [Journal of Sport and Leisure Studies, 한국사회체육학회지], V28, P349
   Lindsay David M, 2014, Asian J Sports Med, V5, pe24289, DOI 10.5812/asjsm.24289
   Liu QS, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9121330
   McGill S, 2010, STRENGTH COND J, V32, P33, DOI 10.1519/SSC.0b013e3181df4521
   McNally W, 2019, P IEEE C COMP VIS PA
   Mun F, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/s12938-015-0041-5
   Najafi B, 2015, J SPORT SCI MED, V14, P354
   Nam CNK, 2014, IEEE T INSTRUM MEAS, V63, P943, DOI 10.1109/TIM.2013.2283548
   O'Donoghue P, 2014, INTRO PERFORMANCE AN, P274
   Park S, 2017, IEEE COMPUT SOC CONF, P105, DOI 10.1109/CVPRW.2017.19
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Sim K. F., 2010, 2010 International Conference on Computer Applications and Industrial Electronics (ICCAIE), P169, DOI 10.1109/ICCAIE.2010.5735069
   Smith AC, 2017, EUR J SPORT SCI, V17, P168, DOI 10.1080/17461391.2016.1240238
   Smith AC, 2016, J APPL BIOMECH, V32, P23, DOI 10.1123/jab.2015-0032
   Tucker CJ, 2016, GOLF INJURIES SPORTS
   Ueda M, 2013, IEEE T HUM-MACH SYST, V43, P398, DOI 10.1109/TSMC.2013.2266896
   Ullah A, 2018, IEEE ACCESS, V6, P1155, DOI 10.1109/ACCESS.2017.2778011
   Watanabe K, 2006, IEEE T SYST MAN CY A, V36, P549, DOI 10.1109/TSMCA.2005.855777
   Yu-Liang Hsu, 2016, 2016 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW), P1, DOI 10.1109/ICCE-TW.2016.7521016
   Zhang ZC, 2018, PROCEDIA COMPUT SCI, V129, P135, DOI 10.1016/j.procs.2018.03.061
   Zhang ZC, 2017, ELEKTROTEH VESTN, V84, P247
   Zheng N, 2008, INT J SPORTS MED, V29, P487, DOI 10.1055/s-2007-989229
   Zhong LH, 2019, REMOTE SENS ENVIRON, V221, P430, DOI 10.1016/j.rse.2018.11.032
   이성호, 2009, [Journal of Sport and Leisure Studies, 한국사회체육학회지], V37, P1303
NR 49
TC 7
Z9 8
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8957
EP 8972
DI 10.1007/s11042-020-10096-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QZ7ZL
UT WOS:000630940800001
DA 2024-07-18
ER

PT J
AU Hu, CH
   Wang, XC
   Hu, RM
   Wu, YL
AF Hu, Chenhao
   Wang, Xiaochen
   Hu, Ruimin
   Wu, Yulin
TI Audio object coding based on N-step residual compensating
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object-based audio; SAOC; Aliasing distortion; Residual compensating
AB Object-based audio techniques provide more flexibility and convenience for personalized rendering under various playback configurations. Many methods have been proposed to encode and transmit multiple audio objects at a low bit-rate. However, the recovered audio objects have severe frequency aliasing distortion, which will destroy the immersive sound quality. This paper describes a new structure to reduce every object's aliasing distortion. In this method, we extract residual and gain parameters of all objects after N-step operation and use singular value decomposition to compress the residual matrices. The residual matrices can compensate for aliasing distortion in the decoding part. Moreover, we find a proper ordering strategy experimentally to determine the object coding order because it will affect the final decoded quality. From experiment results, the energy sorting strategy is chosen as the best ordering strategy, and the residual information bit-rate can be reduced from 14.11 kbps/per object to 5.87 kbps/per object. Compared with previous studies, our method gets better performance in objective and subjective experiments. The proposed N-step residual compensating structure can reduce every object's aliasing distortion better than the state-of-the-art methods.
C1 [Hu, Chenhao; Wang, Xiaochen; Hu, Ruimin; Wu, Yulin] Wuhan Univ, Sch Comp Sci, Natl Engn Res Ctr Multimedia Software, Wuhan 430072, Peoples R China.
   [Wang, Xiaochen] Wuhan Univ Shenzhen, Res Inst, Shenzhen 518000, Peoples R China.
   [Hu, Ruimin] Wuhan Univ, Hubei Key Lab Multimedia & Network Commun Engn, Wuhan 430072, Peoples R China.
C3 Wuhan University; Wuhan University; Wuhan University
RP Wang, XC (corresponding author), Wuhan Univ, Sch Comp Sci, Natl Engn Res Ctr Multimedia Software, Wuhan 430072, Peoples R China.; Wang, XC (corresponding author), Wuhan Univ Shenzhen, Res Inst, Shenzhen 518000, Peoples R China.
EM clowang@whu.edu.cn
RI Wu, Yulin/JAX-2276-2023
FU National Key R&D Program of China [2017YFB1002803]; National Nature
   Science Foundation of China [61762005, U1736206]; Basic Research Project
   of Science and Technology Plan of Shenzhen [JCYJ20170818143246278]
FX This research is partially supported by the National Key R&D Program of
   China (No. 2017YFB1002803), National Nature Science Foundation of China
   (No. 61762005, U1736206), Basic Research Project of Science and
   Technology Plan of Shenzhen (JCYJ20170818143246278).
CR Ando A, 2011, IEEE T AUDIO SPEECH, V19, P1467, DOI 10.1109/TASL.2010.2092429
   [Anonymous], 2014, ISO IEC 23008 3 2014
   [Anonymous], 2010, ISO IEC 23003 2 2010
   De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696
   Falch, 2008, AUDIO ENG SOC CONVEN, V124, P1
   Faller C, 2006, AUDIO ENG SOC CONVEN, V120, P1
   Fevotte, 2005, IRISA TECH REP 1706
   Herre J, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1894
   ITU-R, 2015, Tech. Rep., ITU-R Rec, BT.2020-2
   Jia MS, 2015, IEEE-ACM T AUDIO SPE, V23, P1082, DOI 10.1109/TASLP.2015.2419980
   Kasuya T, 2019, 2019 IEEE GAMES, ENTERTAINMENT, MEDIA CONFERENCE (GEM), DOI 10.1109/gem.2019.8811549
   Kim C, 2014, 3D FUTURE INTERNET M, P79
   Kim K, 2011, IEEE T MULTIMEDIA, V13, P1208, DOI 10.1109/TMM.2011.2168197
   Koo K, 2008, 10TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS I-III, P1205
   Lee B, 2016, IEICE T INF SYST, VE99D, P1949, DOI 10.1587/transinf.2015EDL8248
   Michel D, 2012, QUASIDATABASE A MUSI
   Oldfield R, 2015, MULTIMED TOOLS APPL, V74, P2717, DOI 10.1007/s11042-013-1472-2
   Rafii Zafar, 2017, MUSDB18 CORPUS MUSIC
   Rocha L., 2003, A Practical Approach to Microarray Data Analysis, P91, DOI [10.1007/0-306-47815-3, DOI 10.1007/0-306-47815-35, 10.1007/0-306-47815-3_5, DOI 10.1007/0-306-47815-3_5]
   Schein EH., 1998, PROCESS CONSULTATION, P1
   Scheirer ED, 1999, MULTIMEDIA SYST, V7, P11, DOI 10.1007/s005300050107
   Shirley B, 2015, J AUDIO ENG SOC, V63, P245, DOI 10.17743/jaes.2015.0017
   Someya, 2016, AUDIO ENG SOC CONVEN, V140, P1
   Vannieuwenhoven N, 2012, SIAM J SCI COMPUT, V34, pA1027, DOI 10.1137/110836067
   Wu TZ, 2019, MULTIMED TOOLS APPL, V78, P20723, DOI 10.1007/s11042-019-7409-7
   Wu TZ, 2017, CHINA COMMUN, V14, P32, DOI 10.1109/CC.2017.8068762
   Zamani S, 2019, INT CONF ACOUST SPEE, P720, DOI [10.1109/icassp.2019.8682315, 10.1109/ICASSP.2019.8682315]
   Zhang S., 2019, PROC 146 AES AUDIO E, P1
   Zheng XG, 2013, INT CONF ACOUST SPEE, P281, DOI 10.1109/ICASSP.2013.6637653
   Zheng XG, 2013, IEEE T AUDIO SPEECH, V21, P27, DOI 10.1109/TASL.2012.2211015
NR 30
TC 4
Z9 4
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18717
EP 18733
DI 10.1007/s11042-020-10339-0
EA FEB 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000619738400005
DA 2024-07-18
ER

PT J
AU Zenati, A
   Ouarda, W
   Alimi, AM
AF Zenati, Anissa
   Ouarda, Wael
   Alimi, Adel M.
TI A new digital steganography system based on hiding online signature
   within document image data in YUV color space
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Beta elliptic signature; Color document image security;
   YUV color space; Binary robust invariant scalable keypoints
ID WRITER IDENTIFICATION; WATERMARKING; MODEL
AB Due to the progression in computer technology and fast growth of interchange of data, Steganographyis becoming the best solution for providing greater security for sensitive document images which are uncontrolled across the internet. In this paper, we introduce a new signature steganography system for color document images in YUV color space based on the stego key and the Beta elliptic modeling. Firstly, the cover color document image is transformed into YUV from RGB space. Afterward, the embedding positions are identified based on the potential feature by using the Binary Robust Invariant Scalable Keypoints (BRISK) detector. In the next step, we decide the channel in which a Beta elliptic signature bits will be hidden on the basis of bitxor operation of Y channel's LSB and the bits of stego key. Finally, the proposed system hides the Beta elliptic signature bits adaptively in U or V channel. It could be perceived from the results of experimentation that by the use of the proposed system, the embedded data is detectable even in the existence of common image processing distortion, as well the proposed steganography system in spatial domain has demonstrated to be robust and outperform the related works in term of the measurements image quality.
C1 [Zenati, Anissa; Ouarda, Wael; Alimi, Adel M.] Univ Sfax, Natl Engn Sch Sfax ENIS, ReSea Grp Intelligent Machines, REGIM Lab, BP 1173, Sfax 3038, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS)
RP Zenati, A (corresponding author), Univ Sfax, Natl Engn Sch Sfax ENIS, ReSea Grp Intelligent Machines, REGIM Lab, BP 1173, Sfax 3038, Tunisia.
EM anissa.zenati@ieee.org; wael.ouarda@ieee.org; adel.alimi@ieee.org
RI Alimi, Adel M./A-5697-2012; Ouarda, Wael/GQP-6480-2022
OI Alimi, Adel M./0000-0002-0642-3384; Ouarda, Wael/0000-0002-6338-7092
FU Ministry of Higher Education and Scientific Research of Tunisia
   [LR11ES48]
FX The research leading to these results has received funding from the
   Ministry of Higher Education and Scientific Research of Tunisia under
   the grant agreement number LR11ES48.
CR Abdulrahman AK, 2019, MULTIMED TOOLS APPL, V78, P17027, DOI 10.1007/s11042-018-7085-z
   Abraham J, 2019, J KING SAUD UNIV-COM, V31, P125, DOI 10.1016/j.jksuci.2016.12.004
   Al-Haj A, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT (ICIM 2017), P441, DOI 10.1109/INFOMAN.2017.7950424
   Avik C, 2019, INTELLIGENT COPYRIGH
   BOURBAKIS N, 1992, PATTERN RECOGN, V25, P567, DOI 10.1016/0031-3203(92)90074-S
   Cu Vinh Loc, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1214, DOI 10.1109/ICDAR.2019.00196
   Loc CV, 2018, INT C PATT RECOG, P1091, DOI 10.1109/ICPR.2018.8546035
   Loc CV, 2017, PROC INT CONF DOC, P21, DOI 10.1109/ICDAR.2017.391
   Dhieb T., 2018, ARXIV180405661
   Dhieb T, 2016, IEEE IJCNN, P1863, DOI 10.1109/IJCNN.2016.7727426
   Dhieb T, 2016, J INF ASSUR SECUR, V11, P263
   García-Soto R, 2013, 2013 10TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING, COMPUTING SCIENCE AND AUTOMATIC CONTROL (CCE), P227, DOI 10.1109/ICEEE.2013.6676011
   Gonge SS, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON ISSUES AND CHALLENGES IN INTELLIGENT COMPUTING TECHNIQUES (ICICT), P776, DOI 10.1109/ICICICT.2014.6781379
   HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Jarusek R, 2018, APPL SOFT COMPUT, V67, P505, DOI 10.1016/j.asoc.2018.03.023
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li B, 2015, IEEE T INF FOREN SEC, V10, P1905, DOI 10.1109/TIFS.2015.2434600
   Li JZ, 2018, MULTIMED TOOLS APPL, V77, P4545, DOI 10.1007/s11042-017-4452-0
   Lou DC, 2004, IEEE T MULTIMEDIA, V6, P501, DOI 10.1109/TMM.2004.827493
   Mair E, 2010, LECT NOTES COMPUT SC, V6312, P183, DOI 10.1007/978-3-642-15552-9_14
   Malik Z, 2014, INT CONF FRONT INFO, P330, DOI 10.1109/FIT.2014.68
   Muhammad, 2015, ARXIV151000226
   Muhammad K, 2015, 11 INT C MULT INF TE, P165
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P8597, DOI 10.1007/s11042-016-3383-5
   Munib S, 2017, MULTIMED TOOLS APPL, V76, P8695, DOI 10.1007/s11042-016-3485-0
   Najoua, 2015, COMP INT SEC INF SYS
   Patvardhan C, 2018, MULTIMED TOOLS APPL, V77, P12655, DOI 10.1007/s11042-017-4909-1
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Sejpal Shveti, 2016, INT J COMPUT APPL, V147, P34, DOI DOI 10.5120/IJCA2016911189
   Sikander, 2018, MICRO SYST TECHNOL, P1
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Viet Quoc Pham, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P473
   Wang SJ, 2005, APPL MATH COMPUT, V164, P99, DOI 10.1016/j.amc.2004.04.059
   Yu LJ, 2005, IMAGE VISION COMPUT, V23, P807, DOI 10.1016/j.imavis.2005.05.014
NR 36
TC 8
Z9 8
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18653
EP 18676
DI 10.1007/s11042-020-10376-9
EA FEB 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000619738400001
DA 2024-07-18
ER

PT J
AU Sigirci, IO
   Albayrak, A
   Bilgin, G
AF Sigirci, I. Onur
   Albayrak, Abdulkadir
   Bilgin, Gokhan
TI Detection of mitotic cells in breast cancer histopathological images
   using deep versus handcrafted features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital histopathology; Mitosis detection; Deep learning; Convolutional
   neural networks; Image spatial statistics; Imbalanced data
ID TEXTURE CLASSIFICATION; SEGMENTATION
AB One of the most important processes in the diagnosis of breast cancer, which is the leading mortality rate in women, is the detection of the mitosis stage at the cellular level. In literature, many studies have been proposed on the computer-aided diagnosis (CAD) system for detecting mitotic cells in breast cancer histopathological images. In this study, comparative evaluation of conventional and deep learning based feature extraction methods for automatic detection of mitosis in histopathological images are focused. While various handcrafted features are extracted with textural/spatial, statistical and shape-based methods in conventional approach, the convolutional neural network structure proposed on the deep learning approach aims to create an architecture that extracts the features of small cellular structures such as mitotic cells. Mitosis detection/counting is an important process that helps us assess how aggressive or malignant the cancer's spread is. In the proposed study, approximately 180,000 non-mitotic and 748 mitotic cells are extracted for the evaluations. It is obvious that the classification stage cannot be performed properly due to the imbalanced numbers of mitotic and non-mitotic cells extracted from histopathological images. Hence, the random under-sampling boosting (RUSBoost) method is exploited to overcome this problem. The proposed framework is tested on mitosis detection in breast cancer histopathological images dataset provided from the International Conference on Pattern Recognition (ICPR) 2014 contest. In the results obtained with the deep learning approach, 79.42% recall, 96.78% precision and 86.97% F-measure values are achieved more successfully than handcrafted methods. A client/server-based framework has also been developed as a secondary decision support system for use by pathologists in hospitals. Thus, it is aimed that pathologists will be able to detect mitotic cells in various histopathological images more easily through necessary interfaces.
C1 [Sigirci, I. Onur] YTU, Dept Comp Engn, TR-34220 Istanbul, Turkey.
   [Sigirci, I. Onur; Albayrak, Abdulkadir] YTU, SIMPLAB, TR-34220 Istanbul, Turkey.
   [Albayrak, Abdulkadir] Dicle Univ, Dept Comp Engn, TR-21280 Diyarbakir, Turkey.
   [Bilgin, Gokhan] Yildiz Tech Univ YTU, Dept Comp Engn, TR-34220 Istanbul, Turkey.
   [Bilgin, Gokhan] YTU, Signal & Image Proc Lab SIMPLAB, TR-34220 Istanbul, Turkey.
C3 Yildiz Technical University; Dicle University; Yildiz Technical
   University
RP Bilgin, G (corresponding author), Yildiz Tech Univ YTU, Dept Comp Engn, TR-34220 Istanbul, Turkey.; Bilgin, G (corresponding author), YTU, Signal & Image Proc Lab SIMPLAB, TR-34220 Istanbul, Turkey.
EM gbilgin@yildiz.edu.tr
RI SIGIRCI, IBRAHIM ONUR/AAJ-6581-2021; Bilgin, Gokhan/W-2666-2018;
   Albayrak, Abdulkadir/AAJ-5801-2021
OI SIGIRCI, IBRAHIM ONUR/0000-0002-6596-9635; Bilgin,
   Gokhan/0000-0002-5532-477X; Albayrak, Abdulkadir/0000-0002-0738-871X
FU Yildiz Technical University, Scientific Research Projects Coordination
   Department [2014-04-01-KAP01]
FX This work was supported by Yildiz Technical University, Scientific
   Research Projects Coordination Department, Project Number:
   2014-04-01-KAP01.
CR [Anonymous], 2012, MITOS ATYPIA DETECTI
   Beral V, 2002, LANCET, V360, P187, DOI 10.1016/S0140-6736(02)09454-0
   BLOOM HJG, 1957, BRIT J CANCER, V11, P359, DOI 10.1038/bjc.1957.43
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chawla NV, 2003, LECT NOTES ARTIF INT, V2838, P107, DOI 10.1007/978-3-540-39804-2_12
   Chen JC, 2016, SCI REP-UK, V6, DOI [10.1038/srep24454, 10.1038/srep25671]
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Cheng JR, 2010, LECT NOTES COMPUT SC, V6388, P244, DOI 10.1007/978-3-642-17711-8_25
   Ciresan DC, 2013, LECT NOTES COMPUT SC, V8150, P411, DOI 10.1007/978-3-642-40763-5_51
   Costa A. F., 2012, 2012 XXV SIBGRAPI - Conference on Graphics, Patterns and Images (SIBGRAPI 2012), P39, DOI 10.1109/SIBGRAPI.2012.15
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalle JR, 2008, IEEE ENG MED BIO, P3052, DOI 10.1109/IEMBS.2008.4649847
   De Angelis R, 2014, LANCET ONCOL, V15, P23, DOI 10.1016/S1470-2045(13)70546-1
   Dundar MM, 2011, IEEE T BIO-MED ENG, V58, P1977, DOI 10.1109/TBME.2011.2110648
   Elston C W, 2002, Histopathology, V41, P154
   Gençtav A, 2012, PATTERN RECOGN, V45, P4151, DOI 10.1016/j.patcog.2012.05.006
   Guo H., 2004, SIGKDD EXPLORATIONS, V6, P30, DOI DOI 10.1145/1007730.1007736
   Gurcan MN, 2006, 2006 28TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY, VOLS 1-15, P4914
   Hafiane A, 2008, INT C PATT RECOG, P2116, DOI 10.1109/icpr.2008.4761744
   Hagwood C, 2012, IEEE T MED IMAGING, V31, P380, DOI 10.1109/TMI.2011.2169806
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Irshad H, 2013, J PATHOL INFORM S, V4
   Irshad H, 2013, IEEE ENG MED BIO, P6091, DOI 10.1109/EMBC.2013.6610942
   Khan AM, 2012, INT C PATT RECOG, P149
   Krawczyk B, 2014, LECT NOTES ARTIF INT, V8467, P539, DOI 10.1007/978-3-319-07173-2_46
   Krawczyk B, 2012, LECT NOTES COMPUT SC, V7594, P483, DOI 10.1007/978-3-642-33564-8_58
   LeCun Y., 1995, The handbook of brain theory and neural networks, V3361, DOI [10.5555/303568.303704, DOI 10.5555/303568.303704]
   Litjens G, 2016, SCI REP-UK, V6, DOI 10.1038/srep26286
   Liu A-A, 2010, Proceedings 2010 7th IEEE International Symposium on Biomedical Imaging: From Nano to Macro, P580, DOI 10.1109/ISBI.2010.5490279
   Naqi SM, 2017, CURR MED IMAGING, V13, P3, DOI 10.2174/1573405612666160610093453
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257
   Paul A, 2015, LECT NOTES COMPUT SC, V9350, P94, DOI 10.1007/978-3-319-24571-3_12
   Porter P, 2008, NEW ENGL J MED, V358, P213, DOI 10.1056/NEJMp0708307
   Rao KN, 2012, INT J SCI ENG RES, V3, P95
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rybski PE, 2010, IEEE INT VEH SYM, P921, DOI 10.1109/IVS.2010.5547996
   Seiffert C, 2010, IEEE T SYST MAN CY A, V40, P185, DOI 10.1109/TSMCA.2009.2029559
   Sertel O, 2009, IEEE ENG MED BIO, P1433, DOI 10.1109/IEMBS.2009.5332910
   Siegel RL, 2021, CA-CANCER J CLIN, V71, P7, DOI [10.3322/caac.21387, 10.3322/caac.20073, 10.3322/caac.21332, 10.3322/caac.21601, 10.3322/caac.21254, 10.3322/caac.21654, 10.3322/caac.20006, 10.3322/caac.21551]
   Sommer C, 2012, INT C PATT RECOG, P2306
   Suzani A, 2015, PROC SPIE, V9415, DOI 10.1117/12.2081542
   Todoroki Y, 2018, INT C INNOVATION MED, V71, P140, DOI 10.1007/978-3-319-59397-5_15
   Van Hulse Jason, 2007, P 24 INT C MACH LEAR, P935, DOI DOI 10.1145/1273496.1273614
   Wan SH, 2015, I S BIOMED IMAGING, P195, DOI 10.1109/ISBI.2015.7163848
   Wan T, 2014, IEEE IMAGE PROC, P2290, DOI 10.1109/ICIP.2014.7025464
   Zhan TM, 2017, CNS NEUROL DISORD-DR, V16, P129, DOI 10.2174/1871527316666170113101559
NR 51
TC 19
Z9 19
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13179
EP 13202
DI 10.1007/s11042-021-10539-2
EA FEB 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000618948700006
DA 2024-07-18
ER

PT J
AU Devi, DAS
   Satyanarayana, C
AF Devi, Anjani Suputri D.
   Satyanarayana, Ch
TI An efficient facial emotion recognition system using novel deep learning
   neural network-regression activation classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial emotion recognition; Gamma-histogram equalization (gamma-HE);
   Modified monarch butterfly optimization (MMBO); And deep learning neural
   network-regression activation (DR)
ID EXPRESSION RECOGNITION; FEATURE-SELECTION
AB In the computer vision field, FER encompasses a significant place. It is being studied for a long period, and in recent decades, it has attained progress, but all is in vain, since, recognizing facial expression with high accuracy is still hard due to disparate facial expressions. To beat such difficulties, an efficient Facial Emotion Recognitions (FER) is proposed by utilizing a novel Deep Learning Neural Network-regression activation (DR) classifier. The proposed method has six phases, namely, pre-processing, facial point extraction, segmentation, feature extraction, feature selection, and classification. Initially the input image has been pre-processed using Gamma-HE technique and then facial points are extracted using Pyramid Histogram of Oriented Gradients (PHOG) based Supervised Descent (SMD) Method. The facial parts are segmented using Viola-Jones Algorithm (VJA) and then Local Tetra Pattern (LTrP), cluster shade, Inverse Divergent Moment (IDM), Local homogeneity, optimum probability, cluster prominence, dissimilarity, autocorrelation, and contrast features have been extracted. Modified Monarch Butterfly Optimization (MMBO) algorithm has been used to select necessary features from the extracted features. From the extracted facial points, the DR classifier classifies the emotions of the particular input image. A '2' datasets were taken for analyzing the proposed system's performance. Centred on the CK+ database, the proposed work attains 0.9885-accuracy, and centred on the JAFFE database, it has 0.9727-accuracy. Also, the investigational results proved that the proposed work trounces the existing systems centred on statistical metrics.
C1 [Devi, Anjani Suputri D.; Satyanarayana, Ch] JNTUK, Dept Comp Sci & Engn, Kakinada, Andhra Pradesh, India.
C3 Jawaharlal Nehru Technological University - Kakinada
RP Devi, DAS (corresponding author), JNTUK, Dept Comp Sci & Engn, Kakinada, Andhra Pradesh, India.
EM anjanihasini@gmail.com
RI D, Anjani Suputri Devi/ABO-6466-2022
CR Alharbi S, 2017, IEEE IPCCC, DOI 10.1109/TCYB.2017.2662199
   Arora M, 2021, MULTIMED TOOLS APPL, V80, P3039, DOI 10.1007/s11042-020-09726-4
   Arora M, 2018, NATL ACAD SCI LETT, V41, P365, DOI 10.1007/s40009-018-0694-2
   Bastanfard A, 2004, COMPUT ANIMAT VIRT W, V15, P347, DOI 10.1002/cav.38
   Bastanfard A, INT C CYB, DOI [10.1109/cw.2004.65, DOI 10.1109/CW.2004.65]
   Bone JK, 2019, J AFFECT DISORDERS, V257, P461, DOI 10.1016/j.jad.2019.06.025
   Boutorh A, 2016, ENG APPL ARTIF INTEL, V51, P58, DOI 10.1016/j.engappai.2016.01.004
   Chen JY, 2019, J PARALLEL DISTR COM, V131, P97, DOI 10.1016/j.jpdc.2019.04.017
   Fan XJ, 2019, J VIS COMMUN IMAGE R, V65, DOI 10.1016/j.jvcir.2019.102659
   Ghosh M, 2019, MULTIMED TOOLS APPL, V78, P25753, DOI 10.1007/s11042-019-07811-x
   He H, 2020, APPL SOFT COMPUT, V94, DOI 10.1016/j.asoc.2020.106426
   HU HM, 2018, IEEE T CIRCUITS SYST
   Ji YL, 2019, NEUROCOMPUTING, V333, P231, DOI 10.1016/j.neucom.2018.12.037
   Jiao J, 2011, PROCEDIA ENGINEER, V15, DOI 10.1016/j.proeng.2011.08.951
   Kalantarian H, 2019, ARTIF INTELL MED, V98, P77, DOI 10.1016/j.artmed.2019.06.004
   Kalsum T, 2018, IET IMAGE PROCESS, V12, P1004, DOI 10.1049/iet-ipr.2017.0499
   Khan S, 2020, IEEE T AFFECT COMPUT, V11, P348, DOI 10.1109/TAFFC.2017.2780838
   Kim JH, 2019, IEEE ACCESS, V7, P41273, DOI 10.1109/ACCESS.2019.2907327
   Kobayashi M, 2017, NEUROCOMPUTING, V260, P174, DOI 10.1016/j.neucom.2017.04.025
   Li YG, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3378026
   Lin CH, 2016, ISA T, V64, P405, DOI 10.1016/j.isatra.2016.05.013
   Majumder A, 2018, IEEE T CYBERNETICS, V48, P103, DOI 10.1109/TCYB.2016.2625419
   Makhmudkhujaev F, 2019, SIGNAL PROCESS-IMAGE, V74, P1, DOI 10.1016/j.image.2019.01.002
   Maria E, 2019, ELECTRON NOTES THEOR, V343, P35, DOI 10.1016/j.entcs.2019.04.009
   Mlakar U, 2017, EXPERT SYST APPL, V89, P129, DOI 10.1016/j.eswa.2017.07.037
   Pino M, 2019, PHYSIOL BEHAV, V207, P73, DOI 10.1016/j.physbeh.2019.03.015
   Rao KP, 2019, J VIS COMMUN IMAGE R, V60, P339, DOI 10.1016/j.jvcir.2019.03.002
   Sadeghi H, 2019, J VIS COMMUN IMAGE R, V62, P152, DOI 10.1016/j.jvcir.2019.05.004
   Sánchez D, 2017, ENG APPL ARTIF INTEL, V64, P172, DOI 10.1016/j.engappai.2017.06.007
   Shao J, 2019, NEUROCOMPUTING, V355, P82, DOI 10.1016/j.neucom.2019.05.005
   Sreedharan NPN, 2018, IET BIOMETRICS, V7, P490, DOI 10.1049/iet-bmt.2017.0160
   Wang FY, 2019, J VIS COMMUN IMAGE R, V59, P84, DOI 10.1016/j.jvcir.2018.11.010
   Wang X., 2018, ARXIV180405448
   Xie SY, 2019, IEEE T MULTIMEDIA, V21, P211, DOI 10.1109/TMM.2018.2844085
   Yang ML, 2017, NEUROCOMPUTING, V267, P195, DOI 10.1016/j.neucom.2017.06.007
   Ye YS, 2019, J VIS COMMUN IMAGE R, V62, P1, DOI 10.1016/j.jvcir.2019.04.009
   Yin Z, 2020, EXPERT SYST APPL, V162, DOI 10.1016/j.eswa.2020.113768
   Zhuang N, 2019, NEUROCOMPUTING, V358, P109, DOI 10.1016/j.neucom.2019.04.057
NR 38
TC 15
Z9 15
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 17543
EP 17568
DI 10.1007/s11042-021-10547-2
EA FEB 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000616158900001
DA 2024-07-18
ER

PT J
AU Sikha, OK
   Soman, KP
AF K., Sikha O.
   P., Soman K.
TI Dynamic Mode Decomposition based salient edge/region features for
   content based image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Localized content based image retrieval; Salient Edge; DMD based salient
   region
AB Considering the gap between low-level image features and high-level retrieval concept, this paper investigates the effect of incorporating visual saliency based features for content-based image retrieval(CBIR).Visual saliency plays an important role in human perception due to its capability to focus the attention on the point of interest, i.e. an intended target. This selection based processing can be well explored in localized CBIR systems, since in context of CBIR the users will be interested only in certain parts of the image. The proposed methodology uses Dynamic Mode Decomposition framework to extract the saliency map which highlights the part of the image that grabs human attention. Then, based on the saliency map, an efficient salient edge detection model is introduced. Visual saliency based features (salient region, edge) are then combined with texture and color features to formulate the high dimensional feature vector for image retrieval. State-of-the-art learning based CBIR models demands for user feed back to model the retrieval concept. In contrast with these models, proposed CBIR system does not require any user interaction, since it uses perceptual level features for the retrieval task. Performance of the proposed CBIR system is evaluated and confirmed on images from Wang's dataset using benchmark evaluation metrics like precision and recall. Experimental results reveals that incorporation of saliency features can represent human perception well and produces good retrieval performance.
C1 [K., Sikha O.; P., Soman K.] Amrita Vishwa Vidyapeetham, Amrita Sch Engn, Dept Comp Sci & Engn, Ctr Computat Engn & Networking CEN, Coimbatore, Tamil Nadu, India.
C3 Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Coimbatore
RP Sikha, OK (corresponding author), Amrita Vishwa Vidyapeetham, Amrita Sch Engn, Dept Comp Sci & Engn, Ctr Computat Engn & Networking CEN, Coimbatore, Tamil Nadu, India.
EM ok_sikha@cb.amrita.edu
OI O K, SIKHA/0000-0002-3499-8062
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2007, 2007 IEEE INT C IM P
   Bi CK, 2017, IEEE PHOTONICS J, V9, DOI 10.1109/JPHOT.2017.2766881
   Borji A, 2012, PROC CVPR IEEE, P470, DOI 10.1109/CVPR.2012.6247710
   Brunton BW, 2016, J NEUROSCI METH, V258, P1, DOI 10.1016/j.jneumeth.2015.10.010
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Feng SH, 2010, SIGNAL PROCESS, V90, P1, DOI 10.1016/j.sigpro.2009.05.017
   Fu H, 2006, PATTERN RECOGN, V39, P1604, DOI 10.1016/j.patcog.2005.12.015
   Giouvanakis E, 2014, INT CONF DIGIT SIG, P280, DOI 10.1109/ICDSP.2014.6900671
   [贺广南 He Guangnan], 2011, [中国图象图形学报, Journal of Image and Graphics], V16, P503
   Huang XD, 2016, PROCEEDINGS OF THE 2016 12TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P3056, DOI 10.1109/WCICA.2016.7578372
   Irtaza A, 2014, MULTIMED TOOLS APPL, V72, P1911, DOI 10.1007/s11042-013-1489-6
   Jing F, 2004, IEEE T IMAGE PROCESS, V13, P699, DOI 10.1109/TIP.2004.826125
   Kanan C, 2010, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2010.5539947
   Khodra, 2018, JCP, V13, P1366, DOI [10.17706/jcp.13.12.1366-1384, DOI 10.17706/JCP.13.12.1366-1384]
   Kutz JN, ARXIV14047592
   Li B, 2015, IEEE T IMAGE PROCESS, V24, P5193, DOI 10.1109/TIP.2015.2479400
   Lin CH, 2009, IMAGE VISION COMPUT, V27, P658, DOI 10.1016/j.imavis.2008.07.004
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Liu Z, 2012, IEEE T MULTIMEDIA, V14, P1275, DOI 10.1109/TMM.2012.2190385
   Mitro, ARXIV160803811
   Müller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   Navalpakkam Vidhya, 2006, Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit, V2, P2049, DOI DOI 10.1109/CVPR.2006.54
   Ojala T, 2000, LECT NOTES COMPUT SC, V1842, P404
   Papushoy A, 2015, DIGIT SIGNAL PROCESS, V36, P156, DOI 10.1016/j.dsp.2014.09.005
   Park J, 2012, IEEE IMAGE PROC, P2741, DOI 10.1109/ICIP.2012.6467466
   PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Schmid PJ, 2010, J FLUID MECH, V656, P5, DOI 10.1017/S0022112010001217
   Sikha OK, 2018, J COMPUT SCI-NETH, V25, P351, DOI 10.1016/j.jocs.2017.07.007
   Singh A, 2017, J VIS COMMUN IMAGE R, V42, P173, DOI 10.1016/j.jvcir.2016.11.017
   Soares RD, 2012, PROC INT C TOOLS ART, P1070, DOI 10.1109/ICTAI.2012.151
   Walia E, 2014, SENS IMAGING, V15, DOI 10.1007/s11220-014-0093-9
   Walia E, 2014, J VIS COMMUN IMAGE R, V25, P1335, DOI 10.1016/j.jvcir.2014.05.005
   Wan SH, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P172
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wang XY, 2011, COMPUT STAND INTER, V33, P59, DOI 10.1016/j.csi.2010.03.004
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu YZ, 2018, MULTIMED TOOLS APPL, V77, P13983, DOI 10.1007/s11042-017-5001-6
   Yang JM, 2017, IEEE T PATTERN ANAL, V39, P576, DOI 10.1109/TPAMI.2016.2547384
   Zhang, 2014, IMPROVED IMAGE RETRI
   Zhang Jing, 2008, Acta Electronica Sinica, V36, P494
   Zheng L, 2015, IEEE T MULTIMEDIA, V17, P648, DOI 10.1109/TMM.2015.2408563
   Zhu X, 2006, US Patent, Patent No. [7,113,944, 7113944]
NR 46
TC 7
Z9 8
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15937
EP 15958
DI 10.1007/s11042-020-10315-8
EA FEB 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000615771800004
DA 2024-07-18
ER

PT J
AU Cai, B
   Shi, ZY
   Zhao, JH
AF Cai, Bo
   Shi, Zeyuan
   Zhao, Jianhui
TI Novel spatial and temporal interpolation algorithms based on extended
   field intensity model with applications for sparse AQI
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Air quality index; Coulomb&#8217; s law; Extended field intensity model;
   Interpolation algorithm
AB For the sparsely distributed air quality index (AQI), existing techniques have low efficiency to interpolate the value of a non-given point. Thus an extended field intensity model (EFIM) is proposed based on the Coulomb's law. Single parameter based EFIM is designed for spatial and temporal interpolations, and parameter c is used to control the attenuation of field intensity, while binary search method is adopted to calculate the optimal c. Next double parameters based EFIM is designed, and parameter k is added to control the range of influence, while iterative bilinear interpolation method is used to compute the optimal set of c and k. Then spatio-temporal interpolation is provided using spatial and temporal information simultaneously. The monitored AQIs from 4 cities of China are randomly collected as experiment data. Taking RMSE, AME, AEE as evaluation criterions and using 10-fold cross-validation, the new EFIM based algorithms perform better for spatial interpolation of sparse AQI than current methods, while double parameters based EFIM algorithms have higher precision than single parameter. Temporal related EFIM algorithms are also tested for their efficiency, and the normalized absolute error is defined to help indicate when spatio-temporal interpolation should be used. As a new approach for interpolation of sparse samples, our EFIM and algorithms have potential application in related fields.
C1 [Cai, Bo] Wuhan Univ, Sch Cyber Sci & Engn, Wuhan 430072, Hubei, Peoples R China.
   [Shi, Zeyuan; Zhao, Jianhui] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Hubei, Peoples R China.
C3 Wuhan University; Wuhan University
RP Zhao, JH (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan 430072, Hubei, Peoples R China.
EM jianhuizhao@whu.edu.cn
OI Zhao, Jianhui/0000-0001-5803-2564; Cai, Bo/0000-0001-5261-0191
CR Ali A, 2016, IET WIREL SENS SYST, V6, P74, DOI 10.1049/iet-wss.2015.0079
   Aliaga RJ, 2017, IEEE T NUCL SCI, V64, P2414, DOI 10.1109/TNS.2017.2721103
   Antonello N, 2017, IEEE-ACM T AUDIO SPE, V25, P1929, DOI 10.1109/TASLP.2017.2730284
   Athawale T, 2013, IEEE T VIS COMPUT GR, V19, P2723, DOI 10.1109/TVCG.2013.208
   Bae JH, 2015, IEEE GEOSCI REMOTE S, V12, P860, DOI 10.1109/LGRS.2014.2364601
   Bhattacharjee S, 2014, IEEE T GEOSCI REMOTE, V52, P4771, DOI 10.1109/TGRS.2013.2284489
   Cafaro M, 2018, IEEE T CLOUD COMPUT, V6, P453, DOI 10.1109/TCC.2015.2396072
   Chaudhari S, 2018, IEEE T VEH TECHNOL, V67, P1113, DOI 10.1109/TVT.2017.2717379
   Chen JM, 2006, IEEE T GEOSCI REMOTE, V44, P2230, DOI 10.1109/TGRS.2006.872089
   Chen XL, 2017, ELECTRON LETT, V53, P956, DOI 10.1049/el.2017.1016
   Di Piazza A, 2011, INT J APPL EARTH OBS, V13, P396, DOI 10.1016/j.jag.2011.01.005
   Emigh MS, 2016, IEEE T COMP INTEL AI, V8, P56, DOI 10.1109/TCIAIG.2014.2369345
   Gerber F, 2018, IEEE T GEOSCI REMOTE, V56, P2841, DOI 10.1109/TGRS.2017.2785240
   Huang CH, 2016, IEEE T CONSUM ELECTR, V62, P69, DOI 10.1109/TCE.2016.7448565
   Huang YQ, 2011, IEEE T GEOSCI REMOTE, V49, P679, DOI 10.1109/TGRS.2010.2061856
   Khlopenkov KV, 2008, IEEE T GEOSCI REMOTE, V46, P2016, DOI 10.1109/TGRS.2008.916633
   Kim H, 2011, IEEE T IMAGE PROCESS, V20, P1895, DOI 10.1109/TIP.2011.2107523
   Li JC, 2018, IEEE-CAA J AUTOMATIC, V5, P1136, DOI 10.1109/JAS.2017.7510442
   Luo W, 2008, INT J CLIMATOL, V28, P947, DOI 10.1002/joc.1583
   Micheli L, 2019, IEEE J PHOTOVOLT, V9, P272, DOI 10.1109/JPHOTOV.2018.2872548
   Oteros J, 2019, ATMOS ENVIRON, V199, P435, DOI 10.1016/j.atmosenv.2018.11.045
   Pino-Povedano S, 2016, IEEE SENS J, V16, P2028, DOI 10.1109/JSEN.2015.2511807
   Santana TAA, 2017, ELECTRON LETT, V53, P1250, DOI 10.1049/el.2017.2210
   Shen QS, 2019, CATENA, V174, P59, DOI 10.1016/j.catena.2018.10.052
   Taherkhani F, 2018, IET IMAGE PROCESS, V12, P20, DOI 10.1049/iet-ipr.2016.0521
   Tang L, 2011, IEEE J-STARS, V4, P844, DOI 10.1109/JSTARS.2011.2135840
   Tang MF, 2017, IEEE T MULTIMEDIA, V19, P408, DOI 10.1109/TMM.2016.2613639
   Tomar V, 2014, IEEE SENS J, V14, P3599, DOI 10.1109/JSEN.2014.2329185
   Wan XM, 2012, COMPUT SCI ENG, V14, P49, DOI 10.1109/MCSE.2011.96
   Wang D, 2015, IEEE T IMAGE PROCESS, V24, P2646, DOI 10.1109/TIP.2015.2427518
   Wang P, 2016, IEEE GEOSCI REMOTE S, V13, P1851, DOI 10.1109/LGRS.2016.2614810
   Wang QM, 2015, IEEE T GEOSCI REMOTE, V53, P1692, DOI 10.1109/TGRS.2014.2346535
   Whited B, 2011, IEEE T VIS COMPUT GR, V17, P757, DOI 10.1109/TVCG.2010.115
NR 33
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19215
EP 19236
DI 10.1007/s11042-020-10226-8
EA FEB 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000615174300002
DA 2024-07-18
ER

PT J
AU Bruni, V
   Tartaglione, M
   Vitulano, D
AF Bruni, Vittoria
   Tartaglione, Michela
   Vitulano, Domenico
TI Coherence of PRNU weighted estimations for improved source camera
   identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE PRNU source camera identification; Normalized correlation coefficient;
   Image forensics
ID DIGITAL IMAGE FORENSICS
AB This paper presents a method for Photo Response Non Uniformity (PRNU) pattern noise based camera identification. It takes advantage of the coherence between different PRNU estimations restricted to specific image regions. The main idea is based on the following observations: different methods can be used for estimating PRNU contribution in a given image; the estimation has not the same accuracy in the whole image as a more faithful estimation is expected from flat regions. Hence, two different estimations of the reference PRNU have been considered in the classification procedure, and the coherence of the similarity metric between them, when evaluated in three different image regions, is used as classification feature. More coherence is expected in case of matching, i.e. the image has been acquired by the analysed device, than in the opposite case, where similarity metric is almost noisy and then unpredictable. Presented results show that the proposed approach provides comparable and often better classification results of some state of the art methods, showing to be robust to lack of flat field (FF) images availability, devices of the same brand or model, uploading/downloading from social networks.
C1 [Bruni, Vittoria; Tartaglione, Michela; Vitulano, Domenico] Sapienza Rome Univ, Dept Basic & Appl Sci Engn, Via Antonio Scarpa 16, I-00161 Rome, Italy.
   [Vitulano, Domenico] Italian Natl Res Council, Inst Calculus Applict, Via Taurini 19, I-00185 Rome, Italy.
C3 Sapienza University Rome; Consiglio Nazionale delle Ricerche (CNR)
RP Bruni, V (corresponding author), Sapienza Rome Univ, Dept Basic & Appl Sci Engn, Via Antonio Scarpa 16, I-00161 Rome, Italy.
EM vittoria.bruni@uniroma1.it; michela.tartaglione@uniroma1.it;
   domenico.vitulano@uniroma1.it
OI BRUNI, VITTORIA/0000-0003-3909-7463
FU Universita degli Studi di Roma La Sapienza
FX Open Access funding provided by Universita degli Studi di Roma La
   Sapienza
CR Akshatha KR, 2016, DIGIT INVEST, V19, P69, DOI 10.1016/j.diin.2016.10.002
   Al-Ani M, 2017, IEEE T INF FOREN SEC, V12, P1067, DOI 10.1109/TIFS.2016.2640938
   Brunet D, 2009, LECT NOTES COMPUT SC, V5627, P1, DOI 10.1007/978-3-642-02611-9_1
   Bruni V, 2015, EUR SIGNAL PR CONF, P2326, DOI 10.1109/EUSIPCO.2015.7362800
   Bruni V, 2012, J MATH IMAGING VIS, V44, P52, DOI 10.1007/s10851-011-0310-2
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Caldelli R, 2018, EUR SIGNAL PR CONF, P1357, DOI 10.23919/EUSIPCO.2018.8553160
   Chan LH, 2013, DIGIT INVEST, V10, P215, DOI 10.1016/j.diin.2013.04.001
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Chierchia G, 2014, IEEE T INF FOREN SEC, V9, P554, DOI 10.1109/TIFS.2014.2302078
   Chierchia Giovanni., 2010, Proceedings of the 2nd ACM workshop on Multimedia in forensics, security, and intelligence, MiFor '10, P117, DOI DOI 10.1145/1877972.1878002
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Farinella GM, 2015, LECT NOTES COMPUT SC, V9386, P464, DOI 10.1007/978-3-319-25903-1_40
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Fridrich J, 2009, IEEE SIGNAL PROC MAG, V26, P26, DOI 10.1109/MSP.2008.931078
   Georgievska S, 2017, DIGIT INVEST, V23, P22, DOI 10.1016/j.diin.2017.08.005
   Gloe T., 2010, ACM S APPL COMP, P1584, DOI DOI 10.1080/15567281.2010.531500
   Huang YG, 2015, IEEE T INF FOREN SEC, V10, P2692, DOI 10.1109/TIFS.2015.2474836
   Kang XG, 2012, IEEE T INF FOREN SEC, V7, P393, DOI 10.1109/TIFS.2011.2168214
   Korus P, 2017, IEEE T INF FOREN SEC, V12, P809, DOI 10.1109/TIFS.2016.2636089
   KUMAR BVKV, 1990, APPL OPTICS, V29, P2997, DOI 10.1364/AO.29.002997
   Lawgaly A, 2017, IEEE T INF FOREN SEC, V12, P392, DOI 10.1109/TIFS.2016.2620280
   Li RZ, 2018, PATTERN RECOGN, V74, P556, DOI 10.1016/j.patcog.2017.09.027
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Marra F, 2017, IEEE T INF FOREN SEC, V12, P2197, DOI 10.1109/TIFS.2017.2701335
   Mihçak MK, 1999, INT CONF ACOUST SPEE, P3253, DOI 10.1109/ICASSP.1999.757535
   Peng F., 2013, J COMPUT INF SYST, V9, P5585
   Rao Q, 2016, IEEE TRUST, P983, DOI [10.1109/TrustCom.2016.163, 10.1109/TrustCom.2016.0165]
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Shullani D, 2017, EURASIP J INF SECUR, DOI 10.1186/s13635-017-0067-2
   Thaia T.H., 2015, DIGIT SIGNAL PROCESS, V00, P1
   Tiwari Mayank, 2019, Advances in Computer Communication and Computational Sciences. Proceedings of IC4S 2017. Advances in Intelligent Systems and Computing (AISC 760), P281, DOI 10.1007/978-981-13-0344-9_24
   Tiwari M, 2018, PROCEEDINGS OF 2018 IEEE APPLIED SIGNAL PROCESSING CONFERENCE (ASPCON), P14, DOI 10.1109/ASPCON.2018.8748857
   Tiwari M, 2018, FORENSIC SCI INT, V285, P111, DOI 10.1016/j.forsciint.2018.02.005
   Tuama A, 2016, IEEE INT WORKS INFOR
   Uhl A., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P230, DOI 10.1109/ICB.2012.6199813
   Valsesia D, 2017, IEEE T INF FOREN SEC, V12, P1941, DOI 10.1109/TIFS.2017.2697402
   Vitulano, 2019, LECT NOTES COMPUTER, V11679
   Xu BC, 2016, NEUROCOMPUTING, V207, P131, DOI 10.1016/j.neucom.2016.05.012
   Zhao YH, 2019, MULTIMED TOOLS APPL, V78, P8247, DOI 10.1007/s11042-018-6809-4
NR 40
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22653
EP 22676
DI 10.1007/s11042-020-10477-5
EA FEB 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000613993900003
OA hybrid, Green Submitted
DA 2024-07-18
ER

PT J
AU Kaur, R
   Singh, B
AF Kaur, Rajwinder
   Singh, Butta
TI A novel approach for data hiding based on combined application of
   discrete cosine transform and coupled chaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DCT; Steganography; Chaotic map; National institute of standards and
   technology (NIST)
ID IMAGE STEGANOGRAPHY; ALGORITHM; ROBUST
AB In the recent years chaotic map and Discrete Cosine transform (DCT) have surfaced to become an important field in data hiding methods. In this proposed work, a randomly high embedding chaotic value differencing method (RCVD) based on combined application of DCT and Chaotic map is proposed. DCT has energy compaction property which removes the rounding error problems in the embedding and extraction process. Whereas, chaotic maps have significant properties of sensitivity to initial and control parameters, which help to provide security to the proposed algorithm. The embedding of secret data is done by hybrid method namely randomly chaotic value differencing (RCVD). RCVD maintains the human vision system (HVS) by embedding more data in smooth area than in edge area. The experimental results are calculated in terms of Peak Signal to Noise Ratio (PSNR) and embedding capacity. The security of the proposed method is examined by the key space, key sensitivity parameter and histogram analysis. Additionally universal image quality index (Q) and entropy are also calculated for the proposed method. The evaluated results show that the proposed method outperforms the existing steganography techniques in terms of embedding capacity and PSNR.
C1 [Kaur, Rajwinder; Singh, Butta] Guru Nanak Dev Univ Reg Campus, Dept Elect & Commun Engn, Jalandhar, Punjab, India.
C3 Guru Nanak Dev University
RP Kaur, R (corresponding author), Guru Nanak Dev Univ Reg Campus, Dept Elect & Commun Engn, Jalandhar, Punjab, India.
EM rajwinder086@gmail.com
OI Singh, Butta/0000-0002-0170-6270
CR Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Bhowal K, 2013, TELECOMMUN SYST, V52, P2197, DOI 10.1007/s11235-011-9542-0
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chauhan DS, 2019, MULTIMED TOOLS APPL, V78, P3911, DOI 10.1007/s11042-017-4886-4
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen C.M., 2017, Data Science and Pattern Recognition, V1, P1
   Chen J, 2014, SIGNAL PROCESS-IMAGE, V29, P375, DOI 10.1016/j.image.2014.01.003
   Divya Bharathi M., 2016, INT J PHARM TECHNOL, V2016, DOI [10.5120/17105-7746, DOI 10.5120/17105-7746]
   Evsutin O, 2021, SIGNAL PROCESS, V179, DOI 10.1016/j.sigpro.2020.107811
   Ghebleh M, 2014, COMMUN NONLINEAR SCI, V19, P1898, DOI 10.1016/j.cnsns.2013.10.014
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Hussain M, 2017, SIGNAL PROCESS-IMAGE, V50, P44, DOI 10.1016/j.image.2016.10.005
   Jung KH, 2015, MULTIMED TOOLS APPL, V74, P2179, DOI 10.1007/s11042-014-2081-4
   Kang S, 2020, MULTIMED TOOLS APPL, V79, P21155, DOI 10.1007/s11042-020-08925-3
   Kanso A, 2012, COMMUN NONLINEAR SCI, V17, P3287, DOI 10.1016/j.cnsns.2011.12.012
   Kaur M, 2020, FUTURE GENER COMP SY, V107, P333, DOI 10.1016/j.future.2020.02.029
   Khan A, 2019, SOFT COMPUT, V23, P8045, DOI 10.1007/s00500-018-3441-1
   Kim C, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10155336
   Kim C, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040644
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Kumar R, 2019, J INF SECUR APPL, V47, P94, DOI 10.1016/j.jisa.2019.04.007
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Lin YK, 2014, COMPUT STAND INTER, V36, P855, DOI 10.1016/j.csi.2013.12.013
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Malik A, 2018, MULTIDIM SYST SIGN P, V29, P1801, DOI 10.1007/s11045-017-0530-8
   Maurer U. M., 1992, Journal of Cryptology, V5, P89, DOI 10.1007/BF00193563
   Nazari M, 2020, MULTIMED TOOLS APPL, V79, P13693, DOI 10.1007/s11042-019-08415-1
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Rukhin Andrew L., 2001, A statistical test suite for random and pseudorandom number generators for cryptographic applications, V22
   Saidi M, 2017, MULTIMED TOOLS APPL, V76, P13493, DOI 10.1007/s11042-016-3722-6
   Salleh, P INT CRYPT INF SEC, P139
   Saxena A, 2013, IEEE T IMAGE PROCESS, V22, P3974, DOI 10.1109/TIP.2013.2265882
   Sharma Vijay Kumar, 2019, Information and Communication Technology for Intelligent Systems. Proceedings of ICTIS 2018. Smart Innovation, Systems and Technologies (SIST 106), P665, DOI 10.1007/978-981-13-1742-2_66
   Shen SY, 2015, COMPUT SECUR, V48, P131, DOI 10.1016/j.cose.2014.07.008
   Smart N., 2012, ECRYPT II Yearly Report on Algorithms and Keysizes (2011-2012)
   Sun SL, 2016, INFORM PROCESS LETT, V116, P93, DOI 10.1016/j.ipl.2015.09.016
   Sun W, 2013, SIGNAL IMAGE VIDEO P, V7, P297, DOI 10.1007/s11760-011-0238-4
   Tseng HW, 2013, J APPL MATH, DOI 10.1155/2013/189706
   Turner LF., 1989, PATENT IPN, V89, P21
   Valandar MY, 2019, MULTIMED TOOLS APPL, V78, P9971, DOI 10.1007/s11042-018-6584-2
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wang Z., 2019, J INF HIDING MULTIME, V10, P1
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   WU HC, 2009, EURASIP J INF SECUR, V1, P1
   Yao YZ, 2015, MULTIMED TOOLS APPL, V74, P11163, DOI 10.1007/s11042-014-2223-8
   Zhang JH, 2019, J VIS COMMUN IMAGE R, V58, P600, DOI 10.1016/j.jvcir.2018.12.038
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 48
TC 8
Z9 8
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 14665
EP 14691
DI 10.1007/s11042-021-10528-5
EA JAN 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000612593600003
DA 2024-07-18
ER

PT J
AU Kumar, RS
   Devaraj, AFS
   Rajeswari, M
   Julie, EG
   Robinson, YH
   Shanmuganathan, V
AF Kumar, R. Satheesh
   Saviour Devaraj, A. Francis
   Rajeswari, M.
   Julie, E. Golden
   Robinson, Y. Harold
   Shanmuganathan, Vimal
TI Exploration of sentiment analysis and legitimate artistry for opinion
   mining
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Opinion mining; Sentiment analysis; IMDb dataset; Stemming; Stop words;
   Term frequency - Inverse document frequency; AdaBoost; Fuzzy lattice
   reasoning; Naive Bayes
ID MACHINE
AB Sentiment analysis/opinion mining is a technique that analyzes people's opinions, evaluations, sentiments, attitudes, appraisals and emotions to entities like products, organizations, services, issues, individuals, topics, events and their attributes. It is a massive problem space. People tend to express their opinions on anything, such as, a product, service, topic, individual, organization, or an event. Here, the term object represents the entity commented on. Certain private states parts that cannot be judged and observed include the following, beliefs, opinion, emotions and sentiments. The above mentioned aspects are usually expressed in documents using certain subjective words that determine the private states with the help of unique dictionaries like the WordNet or SentiWordNet. The feature selection concept is incorporated in the following tasks such as image classification, data mining, cluster analysis, image retrieval, and pattern recognition. This is observed as a data analysis pre-processing strategy; here a subset from the original data features is thus selected for eliminating the noisy/irrelevant/redundant features. This technique essentially helps in minimizing the incurred computational expenses and helps in enhancing the accuracy level of the data analysis procedures. The Semantic features are meant to concentrate on the relationship between the signifiers such as that of the words, phrases, signs and symbols. A special of semantics called as the linguistic semantics is used for understanding human based expression in opinions and blog. A semantic based feature selection strategy has been introduced for establishing the opinion mining tasks. This introduced semantic based feature selection makes use of the SentiWordNet that is observed to be a lexical resource of the WordNet database extracted terms and is therefore used in the research tasks. Feature set is minimized with the help of the introduced semantic based approaches for the purpose of considering the individual predictive ability words and selection features. Experiments were conducted with the help of the Naive Bayes, the FLR and the AdaBoost classifiers and the obtained results were compared for understanding and judging the feature selection methods.
C1 [Kumar, R. Satheesh; Rajeswari, M.] Sahrdaya Coll Engn & Technol, Dept Comp Sci & Engn, Kodakara, Kerala, India.
   [Saviour Devaraj, A. Francis] Kalasalingam Acad Res & Educ, Dept Comp Sci & Engn, Srivilliputhur, India.
   [Julie, E. Golden] Anna Univ, Dept Comp Sci & Engn, Reg Campus, Tirunelveli, India.
   [Robinson, Y. Harold] Vellore Inst Technol, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
   [Shanmuganathan, Vimal] Natl Engn Coll, Dept IT, Kovilpatti, Tamil Nadu, India.
C3 Kalasalingam Academy of Research & Education; Anna University; Anna
   University of Technology Tirunelveli; Vellore Institute of Technology
   (VIT); VIT Vellore; National Engineering College - India
RP Shanmuganathan, V (corresponding author), Natl Engn Coll, Dept IT, Kovilpatti, Tamil Nadu, India.
EM satheeshkumar@sahrdaya.ac.in; saviodev@gmail.com;
   rajeswarim@sahrdaya.ac.in; goldenjuliephd@gmail.com;
   yhrobinphd@gmail.com; svimalphd@gmail.com
RI Devaraj, Francis Saviour/GWU-5316-2022; S, Vimal/E-9551-2016; ROBINSON,
   HAROLD/A-1545-2016
OI Devaraj, Francis Saviour/0000-0001-7867-2083; S,
   Vimal/0000-0002-1467-1206; , Dr. R. Satheesh Kumar/0000-0002-8282-3216;
   Greco, Francesca/0000-0002-6270-5693; ROBINSON,
   HAROLD/0000-0002-4881-7103; MANICKAM, RAJESWARI/0000-0002-2329-1627;
   JAYASUBHA, SATHEES KUMAAR S/0000-0002-7089-7648
CR Abu-Salih B, 2018, J KNOWL MANAG, V22, P949, DOI 10.1108/JKM-11-2016-0489
   Alsaffar A, 2014, I C INF TECH MULTIM, P270, DOI 10.1109/ICIMU.2014.7066643
   Angulakshmi G., 2014, International Journal of Advanced Research in Computer Communication Engineering, V3, P7483
   Baccianella S, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION
   Basari AH, 2013, PROCEDIA ENGINEER, V53, P453, DOI 10.1016/j.proeng.2013.02.059
   Bilal M, 2016, J KING SAUD UNIV-COM, V28, P330, DOI 10.1016/j.jksuci.2015.11.003
   Chinsha TC, 2015, IEEE INT C SEMANT CO, P24, DOI 10.1109/ICOSC.2015.7050774
   Claypo N, 2015, INT CONF KNOWL SMART, P105, DOI 10.1109/KST.2015.7051469
   Dziczkowski G, 2013, INT CONF COMPU ASPEC, P79, DOI 10.1109/CASoN.2013.6622605
   El Alaoui I, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-018-0120-0
   Fernández-Gavilanes M, 2016, EXPERT SYST APPL, V58, P57, DOI 10.1016/j.eswa.2016.03.031
   Ficamos P, 2017, INT CONF BIG DATA, P336, DOI 10.1109/BIGCOMP.2017.7881689
   Hung-Yu Kao, 2010, Proceedings 2010 IEEE/ACM International Conference on Web Intelligence-Intelligent Agent Technology (WI-IAT), P456, DOI 10.1109/WI-IAT.2010.298
   Jeyapriya A, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION SYSTEMS (ICECS), P548, DOI 10.1109/ECS.2015.7124967
   Jotheeswaran Jeevanandam, 2013, Journal of Theoretical and Applied Information Technology, V58, P72
   Khezeli YJ, 2012, ADV FUZZY SYST, V2012, DOI 10.1155/2012/206121
   Li ZH, 2019, MULTIMED TOOLS APPL, V78, P6939, DOI 10.1007/s11042-018-6445-z
   Li ZH, 2018, MULTIMED TOOLS APPL, V77, P1115, DOI 10.1007/s11042-016-4310-5
   Manek AS, 2017, WORLD WIDE WEB, V20, P135, DOI 10.1007/s11280-015-0381-x
   Mazzonello V, 2013, IEEE INT C SEMANT CO, P426, DOI 10.1109/ICSC.2013.82
   Mountassir A, 2013, J THEORETIC APPL INF, V56
   Mukhtar N, 2018, TELEMAT INFORM, V35, P2173, DOI 10.1016/j.tele.2018.08.003
   Pappas N, 2012, PROC INT C TOOLS ART, P508, DOI 10.1109/ICTAI.2012.75
   Peñalver-Martinez I, 2014, EXPERT SYST APPL, V41, P5995, DOI 10.1016/j.eswa.2014.03.022
   Riaz S, 2019, CLUSTER COMPUT, V22, pS7149, DOI 10.1007/s10586-017-1077-z
   Wagh Rasika, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P208, DOI 10.1109/ICECA.2018.8474783
   Weichselbraun A, 2014, KNOWL-BASED SYST, V69, P78, DOI 10.1016/j.knosys.2014.04.039
   Xu L., 2017, Adv Sci Technol Lett, V143, P199
   Zhang W, 2011, EXPERT SYST APPL, V38, P2758, DOI 10.1016/j.eswa.2010.08.066
NR 29
TC 15
Z9 16
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 11989
EP 12004
DI 10.1007/s11042-020-10480-w
EA JAN 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000611041300007
DA 2024-07-18
ER

PT J
AU Yu, NN
   Huang, L
   Wei, ZQ
   Zhang, WF
   Wang, B
AF Yu, Nannan
   Huang, Lei
   Wei, Zhiqiang
   Zhang, Wenfeng
   Wang, Bin
TI Weakly supervised fine-grained recognition based on spatial-channel
   aware attention filters
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Weakly supervised; Fine-grained image classification; Spatial-channel
   aware attention filters; Multi-channel
AB Fine-grained recognition is a very challenging issue, since it is difficulty to mine discriminative and subtle feature for objects with similar visual appearance. Because massive manual annotations (e.g., bounding box for discriminative regions) are time-consuming and labor-consuming, existing methods designed single form of attention model outputted discriminative regions in a weakly supervised way. In this paper, we proposed a novel method named a Spatial-Channel Aware Attention Filters (SCAF) to address the weakly supervised fine-grained recognition problem. Compared with the previous attention models, SCAF can obtain attentions-aware features from two dimensions, i.e., the spatial location of image and the channel of feature maps. With the proposed SCAF, the model can enhance the discriminative regions on both spatial and channel dimensions simultaneously. In addition, the multi-channel network multi-level structure are designed to extract richer regional features. Moreover, focal loss is introduced to balance the samples' distribution of fine-grained image dataset. Comprehensive and comparable experiments are conducted in publicly available datasets, and the experimental results show that our method can achieve the state-of-the-art performance on fine-grained recognition tasks. For instance, we achieve 99.370%, 80.749% accuracy on two underwater datasets respectively, i.e., Fish4Knowlege and Wild Fish.
C1 [Yu, Nannan; Huang, Lei; Wei, Zhiqiang; Zhang, Wenfeng; Wang, Bin] Ocean Univ China, Qingdao 266000, Peoples R China.
   [Huang, Lei; Wei, Zhiqiang] Pilot Natl Lab Marine Sci & Technol Qingdao, Qingdao 266000, Peoples R China.
C3 Ocean University of China; Laoshan Laboratory
RP Huang, L (corresponding author), Ocean Univ China, Qingdao 266000, Peoples R China.; Huang, L (corresponding author), Pilot Natl Lab Marine Sci & Technol Qingdao, Qingdao 266000, Peoples R China.
EM huangl@ouc.edu.cn
RI wei, zhiqiang/M-8868-2013
FU National Key RAMP;D Program of China [2019YFD0900401]; National Natural
   Science Foundation of China [61872326, 61672475]; Shandong Provincial
   Natural Science Foundation [ZR2019MF044]
FX This work is supported by the National Key R&D Program of China
   (2019YFD0900401); National Natural Science Foundation of China
   (No.61872326, No.61672475); Shandong Provincial Natural Science
   Foundation (ZR2019MF044).
CR [Anonymous], 2014, ATTENTION FINE GRAIN
   Branson S, 2014, P BRIT MACH VIS C, DOI [10.5244/C.28.87, DOI 10.5244/C.28.87]
   Chai YN, 2012, LECT NOTES COMPUT SC, V7572, P794, DOI 10.1007/978-3-642-33718-5_57
   Dai YP, 2019, J ENG-JOE, V2019, P6840, DOI 10.1049/joe.2019.0543
   Donahue J, 2014, PR MACH LEARN RES, V32
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Ge WF, 2019, PROC CVPR IEEE, P3029, DOI 10.1109/CVPR.2019.00315
   He XT, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P627, DOI 10.1145/3123266.3123319
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jaderberg M., 2015, ICLR, DOI DOI 10.48550/ARXIV.1506.02025
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Lam M, 2017, PROC CVPR IEEE, P6497, DOI 10.1109/CVPR.2017.688
   Li SQ, 2016, INT CONF CLOUD COMPU, P480, DOI 10.1109/CCIS.2016.7790306
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Nie J, 2019, IEEE ACCESS, V7, P15007, DOI 10.1109/ACCESS.2019.2894347
   [彭宇新 Peng Yuxin], 2019, [计算机研究与发展, Journal of Computer Research and Development], V56, P183
   Peng YX, 2018, IEEE T IMAGE PROCESS, V27, P1487, DOI 10.1109/TIP.2017.2774041
   Qin HW, 2016, NEUROCOMPUTING, V187, P49, DOI 10.1016/j.neucom.2015.10.122
   Rodríguez P, 2020, IEEE T MULTIMEDIA, V22, P502, DOI 10.1109/TMM.2019.2928494
   Shi ZH, 2019, MULTIMED TOOLS APPL, V78, P1017, DOI 10.1007/s11042-018-6082-6
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun M, 2018, LECT NOTES COMPUT SC, V11220, P834, DOI 10.1007/978-3-030-01270-0_49
   Vedaldi A., 2013, Technical report
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Wang YM, 2018, PROC CVPR IEEE, P4148, DOI 10.1109/CVPR.2018.00436
   Xiao TJ, 2015, PROC CVPR IEEE, P842, DOI 10.1109/CVPR.2015.7298685
   Yang Z, 2018, LECT NOTES COMPUT SC, V11218, P438, DOI 10.1007/978-3-030-01264-9_26
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
   Zhang XP, 2016, PROC CVPR IEEE, P1134, DOI 10.1109/CVPR.2016.128
   Zheng HL, 2019, PROC CVPR IEEE, P5007, DOI 10.1109/CVPR.2019.00515
   Zheng HL, 2017, IEEE I CONF COMP VIS, P5219, DOI 10.1109/ICCV.2017.557
   Zhuang PQ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1301, DOI 10.1145/3240508.3240616
NR 34
TC 0
Z9 0
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 14409
EP 14427
DI 10.1007/s11042-020-10268-y
EA JAN 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000611041300008
DA 2024-07-18
ER

PT J
AU Huo, FC
   Zhang, WH
   Wang, Q
   Ren, WJ
AF Huo, Fengcai
   Zhang, Weihao
   Wang, Qiong
   Ren, Weijian
TI Two-stage image denoising algorithm based on noise localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive threshold; Noise localization; Edge extraction; Image
   denoising; Singular value decomposes; Superpixel-like algorithm
ID WATERMARKING SCHEME; TRANSFORM; SPARSE
AB At present, most denoising algorithms cannot determine whether a pixel is noise, but these use the same rules to process all pixels. Most denoising methods will filter out the original image information when they deal with images with more details or little difference between the subject and the background. In order to improve the above shortcomings, a two-stage image denoising algorithm of noise localization in this paper is proposed.Firstly, the thresholds T-1 ' and T-2 ' are extracted according to the image gray value distribution. Image edge information is removed and saved by edge extraction, this gets an edgeless greyscale image. Secondly, singular value decomposes the edgeless image to obtain the singular value matrix, the percentage threshold eta is used to reduce the singular value matrix.The coarse noise filtering is performed by the inverse matrix decomposition. Again, the adaptive thresholds T-1 and T-2 are calculated with the histogram, the image is divided into "Dark Area", "Gray Area" and "Light Area". Then, a superpixel-like algorithm is introduced to determine and remove the noise accurately in three regions. Finally, the image edges are combined with the denoised image. By analyzing the denoising image and comparing the peak signal-to-noise ratio (PSNR) and time of the result in many images, it is verified that the proposed algorithm has a better denoising effect than many other denoising algorithms.
C1 [Huo, Fengcai; Zhang, Weihao; Wang, Qiong; Ren, Weijian] Northeast Petr Univ, Sch Elect Informat Engn, Daqing 163318, Peoples R China.
   [Huo, Fengcai; Zhang, Weihao; Wang, Qiong; Ren, Weijian] Northeast Petr Univ, Heilongjiang Prov Key Lab Networking & Intelligen, Daqing 163318, Peoples R China.
   [Huo, Fengcai; Zhang, Weihao] Bohai Rim Energy Res Inst NEPU, Qinghuagndao 066004, Peoples R China.
C3 Northeast Petroleum University; Northeast Petroleum University
RP Zhang, WH (corresponding author), Northeast Petr Univ, Sch Elect Informat Engn, Daqing 163318, Peoples R China.; Zhang, WH (corresponding author), Northeast Petr Univ, Heilongjiang Prov Key Lab Networking & Intelligen, Daqing 163318, Peoples R China.; Zhang, WH (corresponding author), Bohai Rim Energy Res Inst NEPU, Qinghuagndao 066004, Peoples R China.
EM 1281547935@qq.com
FU Natural Science Foundation of Heilongjiang province [F2018004]
FX This work was supported in part by Natural Science Foundation of
   Heilongjiang province F2018004.
CR [Anonymous], INT J FOOD SCI NUTR
   Chen GY, 2005, INTEGR COMPUT-AID E, V12, P99
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Ebrahimi M., 2008, IEEE INT C IM PROC
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Fan LW, 2019, VIS COMPUT IND BIOME, V2, DOI 10.1186/s42492-019-0016-7
   Fodor IK, 2003, J ELECTRON IMAGING, V12, P151, DOI 10.1117/1.1525793
   Goyal B, 2020, INFORM FUSION, V55, P220, DOI 10.1016/j.inffus.2019.09.003
   Han Shou-Dong, 2011, Acta Automatica Sinica, V37, P11, DOI 10.3724/SP.J.1004.2011.00011
   Hasan M, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0264-z
   Huang QG, 2016, DIGIT SIGNAL PROCESS, V52, P45, DOI 10.1016/j.dsp.2016.02.004
   Karaboga D., 2010, Scholarpedia, V5, P6915, DOI [DOI 10.4249/SCHOLARPEDIA.6915, 10.4249/scholarpedia.6915]
   Konieczka A., 2013, SIGNAL PROCESSING AL
   Kumar S, 2018, BIOCYBERN BIOMED ENG, V38, P297, DOI 10.1016/j.bbe.2018.01.005
   Lebrun M, 2012, IMAGE PROCESS ON LIN, V2, P175, DOI 10.5201/ipol.2012.l-bm3d
   Li B, 2011, SCI CHINA INFORM SCI, V54, P51, DOI 10.1007/s11432-010-4128-0
   Li HJ, 2016, PATTERN RECOGN, V49, P237, DOI 10.1016/j.patcog.2015.05.028
   Liu G., 2010, COMPUTER ENG APPL
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   [刘松涛 Liu Songtao], 2018, [自动化学报, Acta Automatica Sinica], V44, P2210
   Long M, 2019, MULTIMED TOOLS APPL, V78, P489, DOI 10.1007/s11042-017-5101-3
   Lu CT, 2012, PATTERN RECOGN LETT, V33, P1287, DOI 10.1016/j.patrec.2012.03.025
   Luo L, 2019, MULTIDIM SYST SIGN P, V30, P705, DOI 10.1007/s11045-018-0577-1
   Mafi M, 2019, SIGNAL PROCESS, V157, P236, DOI 10.1016/j.sigpro.2018.12.006
   Mohammad AA, 2008, SIGNAL PROCESS, V88, P2158, DOI 10.1016/j.sigpro.2008.02.015
   Rohit U, 2017, MULTIMED TOOLS APPL, V76, P16809, DOI 10.1007/s11042-016-3953-6
   Roy A, 2019, MULTIMED TOOLS APPL, V78, P1785, DOI 10.1007/s11042-018-6303-z
   Thanh DNH, 2020, MULTIMED TOOLS APPL, V79, P21013, DOI 10.1007/s11042-020-08887-6
   Umam AK, 2018, J PHYS CONF SER, V974, DOI 10.1088/1742-6596/974/1/012006
   Wang XH, 2003, IEEE T NANOBIOSCI, V2, P184, DOI 10.1109/TNB.2003.816225
   Yahya AA., 2020, MULTIMED TOOLS APPL, V79, P1
   Yang HY, 2014, NEURAL NETWORKS, V57, P152, DOI 10.1016/j.neunet.2014.06.007
   Zhang R, 2019, COMPUT MATH APPL, V78, P3692, DOI 10.1016/j.camwa.2019.06.009
   Zhao GP, 2018, MULTIMED TOOLS APPL, V77, P29589, DOI 10.1007/s11042-017-5320-7
NR 35
TC 4
Z9 5
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 14101
EP 14122
DI 10.1007/s11042-020-10428-0
EA JAN 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000609388200001
DA 2024-07-18
ER

PT J
AU Mousavi, M
   Sadeghiyan, B
AF Mousavi, Maryam
   Sadeghiyan, Babak
TI A new image encryption scheme with Feistel like structure using chaotic
   S-box and Rubik cube based P-box
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image cipher; Permutation-substitution; Chaos; Rubik cubes; S-box;
   Cryptography
ID ALGORITHM; CRYPTANALYSIS; PERMUTATION
AB In this paper, a novel chaos-based dynamic encryption scheme with a permutation-substitution structure is presented. The S-boxes and P-boxes of the scheme are constructed with chaotic transformation and Rubik cube-based permutation to enrich the security, sensitivity, and robustness of the scheme. We use chaotic map and Feistel network to generate our block cipher. The purpose of using a Feistel network is to do encryption and decryption with the same structure. Due to using chaotic systems in our design, the required rounds of Feistel structure are only seven rounds which are less than the number of rounds for encryption algorithms, and, it would be helpful to improve the efficiency of our design. We made this block cipher fully dynamic, to achieve enhanced security and efficiency. Our design consists of a 192-bit block cipher and 8 x 8-bit S-box which due to chaotic systems is created simple and secure. We studied and tested our scheme with security analyses such as algorithm evalustion, correlation coefficients, histogram, plain text analysis, NPCR, key sensitivity, UACI, and key space analysis and corresponding results are given in detail. The results of simulation and analysis show that the proposed block-cipher encryption scheme provides a secure and efficient encryption.
C1 [Mousavi, Maryam; Sadeghiyan, Babak] Amirkabir Univ Technol, Dept Comp Engn & Informat Technol, Tehran, Iran.
C3 Amirkabir University of Technology
RP Mousavi, M (corresponding author), Amirkabir Univ Technol, Dept Comp Engn & Informat Technol, Tehran, Iran.
EM maryammousavi@aut.ac.ir; Basadegh@aut.ac.ir
RI Mousavi, Maryam/KCY-5223-2024
CR Al-Bahrani EA, 2019, BAGHDAD SCI J, V16, P270, DOI 10.21123/bsj.2019.16.1(Suppl.).0270
   BOUSLEHI H, 2018, MULTIMEDIA TOOLS APP
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   CHEN S, 2018, IEEE T CIRCUITS SYST
   Deng ZJ, 2019, J ALGORITHMS COMPUT, V13, DOI 10.1177/1748302619853470
   Duforges, 2017, INT J INTERNET TECHN, V7, P1, DOI [10.1504/IJITST.2017.10008009, DOI 10.1504/IJITST.2017.10008009]
   FAN C, 2018, ENTROPY-SWITZ
   Fan HJ, 2018, MULTIMED TOOLS APPL, V77, P20103, DOI 10.1007/s11042-017-5437-8
   Hamza R, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/1625678
   Hamza R, 2020, INFORM SCIENCES, V527, P493, DOI 10.1016/j.ins.2019.01.070
   Helmy M, 2018, MULTIMED TOOLS APPL, V77, P27337, DOI 10.1007/s11042-018-5923-7
   HUA Z, 2018, IEEE T CYBER
   HUA Z, 2018, IEEE T IND ELECT
   HUA Z, 2018, IEEE T CIRCUIT SYSTE
   Hua ZY, 2019, IEEE ACCESS, V7, P8660, DOI 10.1109/ACCESS.2018.2890116
   Huang, 2018, INT J CIRC THEOR APP, V46, P1, DOI [10.1016/j.ins.2018.03.055, DOI 10.1016/J.INS.2018.03.055]
   Kanda M., 2001, Selected Areas in Cryptography. 7th Annual International Workshop, SAC 2000. Proceedings (Lecture Notes in Computer Science Vol.2012), P324
   Kumar S, 2018, J INF SECUR APPL, V43, P123, DOI 10.1016/j.jisa.2018.10.011
   Li C, 2019, J INEQUAL APPL, DOI 10.1186/s13660-019-2042-6
   Li CQ, 2016, SIGNAL PROCESS, V118, P203, DOI 10.1016/j.sigpro.2015.07.008
   Li M, 2018, SIGNAL PROCESS-IMAGE, V62, P164, DOI 10.1016/j.image.2018.01.002
   Liu LF, 2018, IET SIGNAL PROCESS, V12, P22, DOI 10.1049/iet-spr.2016.0584
   Luo YL, 2018, MULTIMED TOOLS APPL, V77, P26191, DOI 10.1007/s11042-018-5844-5
   Lv XP, 2018, MULTIMED TOOLS APPL, V77, P28633, DOI 10.1007/s11042-018-6013-6
   Moafimadani SS, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21060577
   Mondal B, 2018, MULTIMED TOOLS APPL, V77, P31177, DOI 10.1007/s11042-018-6214-z
   Nachef, 2017, INT C CRYPT NETW SEC, DOI 10.1007/978-3-319-61273-7_16
   Ni B, 2019, IACR CRYPTOL, DOI 10.1007/978-3-030-35423-7_22
   Özkaynak F, 2018, NONLINEAR DYNAM, V92, P305, DOI 10.1007/s11071-018-4056-x
   Ping P, 2018, IEEE ACCESS, V6, P67581, DOI 10.1109/ACCESS.2018.2879565
   PREISHUBER M, 2018, INFORM FORENSICS SEC
   Pudi V, 2018, IEEE T CIRCUITS-II, V65, P371, DOI 10.1109/TCSII.2017.2715659
   Tutueva AV, 2020, CHAOS SOLITON FRACT, V133, DOI 10.1016/j.chaos.2020.109615
   Ullah A, 2018, NONLINEAR DYNAM, V91, P359, DOI 10.1007/s11071-017-3874-6
   Xie EY, 2017, SIGNAL PROCESS, V132, P150, DOI 10.1016/j.sigpro.2016.10.002
   Ye GD, 2018, NONLINEAR DYNAM, V94, P745, DOI 10.1007/s11071-018-4391-y
   Zhang X, 2018, IEEE PHOTONICS J, V10, DOI [10.1109/JPHOT.2018.2859257, 10.1109/JPHOT.2018.2818715]
   Zhu CX, 2018, IEEE ACCESS, V6, P18759, DOI 10.1109/ACCESS.2018.2817600
NR 38
TC 11
Z9 13
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13157
EP 13177
DI 10.1007/s11042-020-10440-4
EA JAN 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000607504000009
DA 2024-07-18
ER

PT J
AU Bao, LF
   Li, HM
AF Bao, Li-Feng
   Li, Hui-Mei
TI Measurement of the five morphological indexes of follicles using image
   processing toolbox
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Follicle; Shape measurement; Ovulation day
ID BASAL BODY-TEMPERATURE; SEGMENTATION; OVULATION
AB This study aims to investigate the morphological characteristics of mature follicles with clinical value. The five morphological indexes of follicles in 72 natural ovulation cycles were measured. The shoot time of follicle photos was the day before ovulation. Measurement software was the MATLAB Image Processing Toolbox. The measured average area, perimeter, equivalent circle diameter, and roundness were 301.29 +/- 8.52 mm(2), 62.23 +/- 6.82 mm, 20.21 +/- 3.08 mm, and 0.89 +/- 0.05, respectively; and the maximal diameter was 23.12 +/- 3.06 mm. Image Processing Toolbox is a simple and convenient measurement software. The standardization of the reference indexes of follicular morphology has important clinical application value in reproductive medicine.
C1 [Bao, Li-Feng; Li, Hui-Mei] Jiangsu Vocat Coll Elect & Informat, Huaian 223003, Jiangsu, Peoples R China.
   [Bao, Li-Feng; Li, Hui-Mei] Nanjing Med Univ, Huaian Peoples Hosp 1, Ctr Clin Reprod Med, Huaian 223001, Jiangsu, Peoples R China.
C3 Nanjing Medical University
RP Li, HM (corresponding author), Jiangsu Vocat Coll Elect & Informat, Huaian 223003, Jiangsu, Peoples R China.; Li, HM (corresponding author), Nanjing Med Univ, Huaian Peoples Hosp 1, Ctr Clin Reprod Med, Huaian 223001, Jiangsu, Peoples R China.
EM doctorhuimeili@163.com
CR Baerwald AR, 2003, BIOL REPROD, V69, P1023, DOI 10.1095/biolreprod.103.017772
   Chanda B, 1998, PATTERN RECOGN, V31, P1469, DOI 10.1016/S0031-3203(98)00014-4
   GOODMAN AL, 1982, AM J PHYSIOL, V243, pE325, DOI 10.1152/ajpendo.1982.243.4.E325
   HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7
   LEADER A, 1985, FERTIL STERIL, V43, P385
   Lenz S, 1983, Acta Eur Fertil, V14, P305
   Padhy Nabaneeta, 2009, J Hum Reprod Sci, V2, P68, DOI 10.4103/0974-1208.57225
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9
   Schmid P, 1999, IEEE T MED IMAGING, V18, P164, DOI 10.1109/42.759124
   Stouffer Richard L, 2004, Reprod Biol Endocrinol, V2, P32, DOI 10.1186/1477-7827-2-32
   TEMPLETON AA, 1982, BRIT J OBSTET GYNAEC, V89, P985, DOI 10.1111/j.1471-0528.1982.tb04651.x
   Tian B, 1999, IEEE T NEURAL NETWOR, V10, P138, DOI 10.1109/72.737500
   TULANDI T, 1987, INT J FERTIL, V32, P312
   Zeleznik Anthony J, 2004, Reprod Biol Endocrinol, V2, P31, DOI 10.1186/1477-7827-2-31
NR 15
TC 0
Z9 0
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12731
EP 12735
DI 10.1007/s11042-020-10402-w
EA JAN 2021
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000607369100005
DA 2024-07-18
ER

PT J
AU Zhao, GH
   Bai, J
   Yang, G
   Shi, L
   Tao, YC
   Cheng, JL
   Lin, YS
AF Zhao, Guohua
   Bai, Jie
   Yang, Guan
   Shi, Lei
   Tao, Yongcai
   Cheng, Jingliang
   Lin, Yusong
TI Magnetic resonance imaging standardization for accurate grading of
   cerebral gliomas
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data standardization; Histogram specification; Grid search; MRI;
   Multicenter
ID HISTOGRAM SPECIFICATION; SYSTEM; CLASSIFICATION; EQUALIZATION;
   ENHANCEMENT; ADAPTATION
AB Computer-aided diagnosis has attracted attention for the accurate grading of cerebral glioma. Most algorithms are only effective in relatively large datasets. Although multicenter data sharing is expanding, the results of cerebral glioma grading are not promising for multicenter data. Considering that multicenter images differ in contrast, we propose an effective image standardization method to reduce the disparity in image contrast of different datasets. The method is adopted in multiple sets of comparative experiments on a public dataset (BraTS2017) and a local dataset. The classification accuracy of experimental data relative to that of multicenter data without image normalization is improved by approximately 25% on average. Results demonstrate that the proposed approach is effective in solving the image contrast disparity of multicenter data. It also addresses the challenge of limited effective sample size in accurate cerebral glioma grading. The novel image standardization technology proposed in this work is a promising solution that can be integrated into expert systems.
C1 [Zhao, Guohua; Tao, Yongcai] Zhengzhou Univ, Sch Informat Engn, Zhengzhou 450000, Peoples R China.
   [Zhao, Guohua; Bai, Jie; Cheng, Jingliang] Zhengzhou Univ, Affiliated Hosp 1, Dept Magnet Resonance Imaging, Zhengzhou 450004, Peoples R China.
   [Zhao, Guohua; Lin, Yusong] Zhengzhou Univ, Collaborat Innovat Ctr Internet Healthcare, Zhengzhou 450052, Peoples R China.
   [Yang, Guan] Zhongyuan Univ Technol, Sch Comp Sci, Zhengzhou 450007, Peoples R China.
   [Shi, Lei; Lin, Yusong] Zhengzhou Univ, Sch Software, Zhengzhou 450002, Peoples R China.
   [Lin, Yusong] Zhengzhou Univ, Hanwei IoT Inst, Zhengzhou 450002, Peoples R China.
C3 Zhengzhou University; Zhengzhou University; Zhengzhou University;
   Zhongyuan University of Technology; Zhengzhou University; Zhengzhou
   University
RP Lin, YS (corresponding author), Zhengzhou Univ, Collaborat Innovat Ctr Internet Healthcare, Zhengzhou 450052, Peoples R China.; Lin, YS (corresponding author), Zhengzhou Univ, Sch Software, Zhengzhou 450002, Peoples R China.; Lin, YS (corresponding author), Zhengzhou Univ, Hanwei IoT Inst, Zhengzhou 450002, Peoples R China.
EM ghzhao@ha.edu.cn; 13783501377@126.com; guanyang@zut.edu.cn;
   prefetcher@163.com; ieyctao@zzu.edu.cn; cjr.chjl@vip.163.com;
   yslin@ha.edu.cn
OI Shi, Lei/0000-0002-1170-3911
CR Ackaouy A, 2020, FRONT COMPUT NEUROSC, V14, DOI 10.3389/fncom.2020.00019
   Bakas S, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.117
   Bargshady G, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113305
   Celik T, 2012, PATTERN RECOGN, V45, P3810, DOI 10.1016/j.patcog.2012.03.019
   Chen C, 2020, IEEE T MED IMAGING, V39, P2494, DOI 10.1109/TMI.2020.2972701
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Chen X, 2019, J HEALTHC ENG, V2019, DOI 10.1155/2019/9414937
   Chen X, 2017, EUR J RADIOL, V93, P236, DOI 10.1016/j.ejrad.2017.06.006
   Diplas BH, 2019, NEURO-ONCOLOGY, V21, P440, DOI 10.1093/neuonc/noy167
   Ghassemi N, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101678
   Graham RNJ, 2005, CLIN RADIOL, V60, P1133, DOI 10.1016/j.crad.2005.07.003
   Han S, 2020, BRIT J CANCER, V122, P1580, DOI 10.1038/s41416-020-0814-x
   Hsieh KLC, 2017, COMPUT BIOL MED, V83, P102, DOI 10.1016/j.compbiomed.2017.02.012
   Ismael SAA, 2020, ARTIF INTELL MED, V102, DOI 10.1016/j.artmed.2019.101779
   Jin H, 2019, IEEE ACCESS, V7, P61656, DOI 10.1109/ACCESS.2019.2916503
   Joseph J, 2017, BIOCYBERN BIOMED ENG, V37, P489, DOI 10.1016/j.bbe.2016.11.006
   Kudulaiti N, 2019, KOREAN J RADIOL, V20, P967, DOI 10.3348/kjr.2018.0690
   Li LF, 2019, EUR J RADIOL, V118, P81, DOI 10.1016/j.ejrad.2019.07.006
   Li W, 2019, IEEE J BIOMED HEALTH, V23, P1234, DOI 10.1109/JBHI.2018.2839771
   Liang D, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107536
   Liu CW, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11070849
   Liu J, 2018, IEEE T BIO-MED ENG, V65, P1943, DOI 10.1109/TBME.2018.2845706
   Liu M, 2020, IEEE T FUZZY SYST, V28, P92, DOI 10.1109/TFUZZ.2019.2912576
   Liu QL, 2019, STROKE, V50, P2314, DOI 10.1161/STROKEAHA.119.025777
   Louis DN, 2016, ACTA NEUROPATHOL, V131, P803, DOI 10.1007/s00401-016-1545-1
   Lu ZY, 2020, PATTERN RECOGN LETT, V133, P173, DOI 10.1016/j.patrec.2020.03.007
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Nyúl LG, 2000, IEEE T MED IMAGING, V19, P143, DOI 10.1109/42.836373
   Patel V, 2019, HEALTH INFORM J, V25, P1398, DOI 10.1177/1460458218769699
   Perone CS, 2019, NEUROIMAGE, V194, P1, DOI 10.1016/j.neuroimage.2019.03.026
   Raab P, 2010, RADIOLOGY, V254, P876, DOI 10.1148/radiol.09090819
   Rao BS, 2020, APPL SOFT COMPUT, V89, DOI 10.1016/j.asoc.2020.106114
   Roy R, 2020, COMPUT BIOL MED, V120, DOI 10.1016/j.compbiomed.2020.103746
   Rundo L, 2019, EXPERT SYST APPL, V119, P387, DOI 10.1016/j.eswa.2018.11.013
   Sen D, 2011, IEEE T IMAGE PROCESS, V20, P1211, DOI 10.1109/TIP.2010.2083676
   Seppä M, 2007, MED IMAGE ANAL, V11, P346, DOI 10.1016/j.media.2007.03.002
   van Griethuysen JJM, 2017, CANCER RES, V77, pE104, DOI 10.1158/0008-5472.CAN-17-0339
   Wachinger C, 2016, NEUROIMAGE, V139, P470, DOI 10.1016/j.neuroimage.2016.05.053
   Wang R, 2019, CANCER SCI, V110, P107, DOI 10.1111/cas.13858
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xie T, 2018, J MAGN RESON IMAGING, V47, P1099, DOI 10.1002/jmri.25835
   Xu G, 2019, QUANTUM INFORM PROCE, V18
   Yoo JC, 2012, IET IMAGE PROCESS, V6, P483, DOI 10.1049/iet-ipr.2011.0025
NR 43
TC 0
Z9 0
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 41477
EP 41496
DI 10.1007/s11042-020-10487-3
EA JAN 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000607038100003
DA 2024-07-18
ER

PT J
AU Thakkar, F
   Srivastava, VK
AF Falgun Thakkar
   Srivastava, Vinay Kumar
TI An adaptive, secure and imperceptive image watermarking using swarm
   intelligence, Arnold transform, SVD and DWT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive image watermarking; Particle swarm optimization; Scrambling;
   Security; Normalized similarity ratio
ID BLIND WATERMARKING; SCHEME
AB Digital image watermarking is one of the important method of copyright protection and rightful ownership of the digital image and video. In this paper, the existing algorithm based on DWT-SVD is improved and made adaptive with particle swarm optimization (PSO) which increases the robustness and imperceptibility. Existing as well as proposed algorithm based on PSO creates diagonal line in the extracted watermark image against some of the noise attacks. Further to remove diagonal line from the extracted watermark image an algorithm based on PSO and Arnold transform is proposed. Both proposed algorithms (PSO and AT-PSO) are implemented and tested with different types of cover images. The comparative analysis of these two proposed algorithms is carried out with the existing algorithm. The comparative analysis shows that under most of noise attacks both the proposed algorithms outperform over the existing algorithm in terms of Peak Signal to Noise Ratio (PSNR) and Normalized Similarity Ratio (NSR). Moreover, the imperceptibility offered by Arnold transform based algorithm is better as compared to the other proposed algorithm. Robustness of both the proposed algorithms is close to each other.
C1 [Falgun Thakkar] GH Patel Coll Engn & Technol, Elect & Commun Engn Dept, Vv Nagar 388120, Gujarat, India.
   [Srivastava, Vinay Kumar] Motilal Nehru Natl Inst Technol Allahabad, Elect & Commun Engn Dept, Prayagraj, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Thakkar, F (corresponding author), GH Patel Coll Engn & Technol, Elect & Commun Engn Dept, Vv Nagar 388120, Gujarat, India.
EM falgungcet@gmail.com; vinay@mnnit.ac.in
RI Srivastava, Vinay Kumar/AAL-2501-2021
OI Srivastava, Vinay Kumar/0000-0002-7993-0993; Thakkar,
   Falgun/0000-0003-2012-2446
CR Ali M, 2014, SIGNAL PROCESS, V94, P545, DOI 10.1016/j.sigpro.2013.07.024
   Aslantas V, 2008, AEU-INT J ELECTRON C, V62, P386, DOI 10.1016/j.aeue.2007.02.010
   Ben Farah MA, 2020, NONLINEAR DYNAM, V99, P3041, DOI 10.1007/s11071-019-05413-8
   Bhatnagar G, 2009, COMPUT STAND INTER, V31, P1002, DOI 10.1016/j.csi.2008.09.031
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Ghazy RA, 2015, INT J ELECTRON, V102, P1091, DOI 10.1080/00207217.2014.963892
   Ghazy Rania A., 2008, Progress, V8, P147
   Ghosal SK, 2019, J INF SECUR APPL, V46, P320, DOI 10.1016/j.jisa.2018.04.003
   Ghosal SK, 2014, J INF SECUR APPL, V19, P272, DOI 10.1016/j.jisa.2014.07.004
   Ghosal SK, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3984
   Goyal Sachin, 2009, INT J COMPUTER SCI E, V1, P239
   Guo JM, 2014, J VIS COMMUN IMAGE R, V25, P1149, DOI 10.1016/j.jvcir.2014.03.012
   Hongqin Shi, 2014, Journal of Software, V9, P655, DOI 10.4304/jsw.9.3.655-662
   Jain C, 2008, ARXIV08080309V1CSMM
   Jane O, 2014, J APPL RES TECHNOL, V12, P750, DOI 10.1016/S1665-6423(14)70091-4
   Jordehi AR, 2013, J EXP THEOR ARTIF IN, V25, P527, DOI 10.1080/0952813X.2013.782348
   Lai CC, 2011, OPT COMMUN, V284, P938, DOI 10.1016/j.optcom.2010.10.047
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Li L, 2012, RES DIGITAL IMAGE WA
   Liang R, 2019, IOP C SERIES MAT SCI, V677
   Lin C.C., 2014, J INF HIDING MULTIME, V5, P124
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Makbol NM, 2013, LECT NOTES COMPUT SC, V8237, P36, DOI 10.1007/978-3-319-02958-0_4
   Mishra A, 2018, J INF SECUR APPL, V38, P71, DOI 10.1016/j.jisa.2017.11.008
   Mohammad AA, 2008, SIGNAL PROCESS, V88, P2158, DOI 10.1016/j.sigpro.2008.02.015
   Mohan B. Chandra, 2008, Journal of Multimedia, V3, P7, DOI 10.4304/jmm.3.1.7-15
   Pradhan C, 2012, PROC TECH, V1, P897, DOI 10.1016/j.protcy.2012.10.109
   Rao R., 2016, Int J Ind Eng Comput, V7, P19, DOI [DOI 10.5267/J.IJIEC.2015.8.004, 10.5267/j.ijiec.2015.8.004]
   Rao S, 2012, P STUD C ENG SYST AL, DOI [10.1109/SCES.2012.6199012, DOI 10.1109/SCES.2012.6199012]
   Run RS, 2012, EXPERT SYST APPL, V39, P673, DOI 10.1016/j.eswa.2011.07.059
   Rykaczewski R, 2007, IEEE T MULTIMEDIA, V9, P421, DOI 10.1109/TMM.2006.886297
   Shaamala A., 2011, International Journal of Computer Science Issues, V8, P220
   Song J, 2011, 2011 INT C EL COMM A, DOI [10.1007/978-1-4419-8849-2_76, DOI 10.1007/978-1-4419-8849-2_76]
   Wang Z, 2007, NOVEL WATERMARKING S
   Yu CY, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21050460
   Zhang XP, 2005, IEEE T MULTIMEDIA, V7, P593, DOI 10.1109/TMM.2005.843357
NR 36
TC 17
Z9 17
U1 6
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12275
EP 12292
DI 10.1007/s11042-020-10220-0
EA JAN 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000606296900002
DA 2024-07-18
ER

PT J
AU Cai, WW
   Liu, BT
   Wei, ZG
   Li, ML
   Kan, JM
AF Cai, Weiwei
   Liu, Botao
   Wei, Zhanguo
   Li, Meilin
   Kan, Jiangming
TI TARDB-Net: triple-attention guided residual dense and BiLSTM networks
   for hyperspectral image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Triple-attention mechanism; Hyperspectral image; Residual and dense
   networks; Bi-directional long-short term memory networks
AB Each sample in the hyperspectral remote sensing image has high-dimensional features and contains rich spatial and spectral information, which greatly increases the difficulty of feature selection and mining. In view of these difficulties, we propose a novel Triple-attention Guided Residual Dense and BiLSTM networks(TARDB-Net) to reduce redundant features while increasing feature fusion capabilities, which ultimately improves the ability to classify hyperspectral images. First, a novel Triple-attention mechanism is proposed to assign different weights to each feature. Then, the residual network is used to perform the residual operation on the features, and the initial features of the multiple residual blocks and the generated deep residual features are intensively fused, retaining a host number of prior features. And use the bidirectional long short-term memory network to integrate the contextual semantics of deep fusion features. Finally, the classification task is completed by Softmax classifier. Experiments on three hyperspectral datasets-Indian Pines, University of Pavia, and Salinas-show that under 10% of the training samples, the overall accuracy of our method is 87%, 96% and 96%, which is superior to several well-known methods.
C1 [Cai, Weiwei; Wei, Zhanguo; Li, Meilin] Cent South Univ Forestry & Technol, Sch Logist & Transportat, Changsha 410004, Peoples R China.
   [Cai, Weiwei] Changsha Astra Informat Technol Co Ltd, Changsha 410219, Peoples R China.
   [Liu, Botao] Cent South Univ, Changsha 410083, Peoples R China.
   [Kan, Jiangming] Beijing Forestry Univ, Beijing 100083, Peoples R China.
C3 Central South University of Forestry & Technology; Central South
   University; Beijing Forestry University
RP Wei, ZG (corresponding author), Cent South Univ Forestry & Technol, Sch Logist & Transportat, Changsha 410004, Peoples R China.
EM t20110778@csuft.edu.cn
RI Wei, Zhanguo/AAP-9941-2020; Cai, Weiwei/AAH-5456-2020; Cai,
   Weiwei/AAH-5456-2020
OI Wei, Zhanguo/0000-0001-9736-502X; Cai, Weiwei/0000-0001-8992-9999; Cai,
   Weiwei/0000-0001-6795-6152
FU Hunan Key Laboratory of Intelligent Logistics Technology [2019TP1015]
FX This work was supported by the Hunan Key Laboratory of Intelligent
   Logistics Technology under Grant 2019TP1015.
CR [Anonymous], 2018, P 26 SIGN PROC COMM
   Bahdanau Dzmitry, 2014, NEURAL MACHINE TRANS
   Bioucas-Dias JM, 2013, IEEE GEOSC REM SEN M, V1, P6, DOI 10.1109/MGRS.2013.2244672
   Chen YL, 2019, INT GEOSCI REMOTE SE, P3705, DOI [10.1109/IGARSS.2019.8898131, 10.1109/igarss.2019.8898131]
   El-Shafie AHA, 2019, INT WIREL COMMUN, P1476, DOI [10.1109/iwcmc.2019.8766466, 10.1109/IWCMC.2019.8766466]
   Gao HM, 2019, IEEE ACCESS, V7, P176587, DOI 10.1109/ACCESS.2019.2957163
   Hang RL, 2019, IEEE T GEOSCI REMOTE, V57, P5384, DOI 10.1109/TGRS.2019.2899129
   Hassaballah M., 2020, DEEP LEARNING COMPUT, V1st
   He QQ, 2018, INT SYM IND EMBED, P150
   Hua Su, 2019, IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium. Proceedings, P8139, DOI 10.1109/IGARSS.2019.8898899
   Jia BB, 2020, CHEMOMETR INTELL LAB, V198, DOI 10.1016/j.chemolab.2020.103936
   Jing R, 2020, INT J REMOTE SENS, V41, P6209, DOI 10.1080/01431161.2020.1734253
   Li J, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12091366
   Li Y., 2020, IEEE T GEOSCI REMOTE
   Liu ZW, 2020, LWT-FOOD SCI TECHNOL, V132, DOI 10.1016/j.lwt.2020.109815
   Paoletti ME, 2019, IEEE T GEOSCI REMOTE, V57, P740, DOI 10.1109/TGRS.2018.2860125
   Raju KK, 2020, MICROELECTRONICS ELE, P303
   Shumilo L, 2019, 2019 IEEE 39TH INTERNATIONAL CONFERENCE ON ELECTRONICS AND NANOTECHNOLOGY (ELNANO), P813, DOI [10.1109/ELNANO.2019.8783604, 10.1109/elnano.2019.8783604]
   Sowmya V, 2019, RECENT ADV COMPUTER, P401, DOI DOI 10.1007/978-3-030-03000-1_16
   Tao R, 2019, IEEE J-STARS, V12, P4920, DOI 10.1109/JSTARS.2019.2940278
   Tong XY, 2020, REMOTE SENS ENVIRON, V237, DOI 10.1016/j.rse.2019.111322
   Wang ZS, 2020, IEEE ACCESS, V8, P71353, DOI 10.1109/ACCESS.2020.2986267
   Xie FD, 2019, APPL SOFT COMPUT, V75, P428, DOI 10.1016/j.asoc.2018.11.014
   Xu L, 2019, IEEE J-STARS, V12, P1825, DOI 10.1109/JSTARS.2019.2914715
   Yang GF, 2018, INT GEOSCI REMOTE SE, P2595, DOI 10.1109/IGARSS.2018.8517520
   Yang ZL, 2019, IEEE T INF FOREN SEC, V14, P1280, DOI 10.1109/TIFS.2018.2871746
   Yo HF, 2020, IEEE T GEOSCI REMOTE, V58, P1281, DOI 10.1109/TGRS.2019.2945591
   Zhang JM, 2019, MATH BIOSCI ENG, V16, P3345, DOI 10.3934/mbe.2019167
   Zhang S, 2020, IEEE T GEOSCI REMOTE
   Zhou W, 2020, REMOTE SENS ENVIRON, V236, DOI 10.1016/j.rse.2019.111458
   Zhou YY, 2019, J COASTAL RES, P913, DOI 10.2112/SI94-180.1
NR 31
TC 83
Z9 84
U1 7
U2 77
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 11291
EP 11312
DI 10.1007/s11042-020-10188-x
EA JAN 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000605548700016
DA 2024-07-18
ER

PT J
AU Naz, H
   Ahuja, S
   Kumar, D
   Rishu
AF Naz, Huma
   Ahuja, Sachin
   Kumar, Deepak
   Rishu
TI DT-FNN based effective hybrid classification scheme for twitter
   sentiment analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DT-FNN; Opinion mining; Sentiment classification; Hybrid classification
   approach; Twitter dataset
ID DEEP NEURAL-NETWORK
AB Sentiment analysis refers to the interpretation and computational study of emotions, opinions and appraisals within the text data using text analysis methods. A basic aim of sentiment analysis is to categorize the sentiment polarity of the sentences, document or aspects. Product manufacturers use the knowledge from sentiment analysis for improving their services & products. Hence, there is an atrocious need of an efficient technique that can accurately identify the sentiment polarity of the content. The supervised classification algorithm has been proved favourable for most of the sentiment analysis task and is widely used in opinion mining. This study presents a novel method for sentiment analysis by combining two supervised classification algorithms viz. Decision Tree (DT) and Feed Forward Neural Network (FNN). Pre-processing of data is carried out by using Independent Component Analysis (ICA) and Windowed Multivariate Autoregressive Model (WMAR) is introduced for extraction of potential features. Then highest scores are extracted using Improved Bat Algorithm (IBA) technique and finally, the experimental results are compared with existing algorithms i.e. ID3, J48 and Random forest classifier. The proposed method significantly outperforms the existing sentiment classification methods with accuracy of 97.84%.
C1 [Naz, Huma; Ahuja, Sachin; Kumar, Deepak; Rishu] Chitkara Univ, Inst Engn & Technol, Rajpura, Punjab, India.
C3 Chitkara University, Punjab
RP Naz, H (corresponding author), Chitkara Univ, Inst Engn & Technol, Rajpura, Punjab, India.
EM huma.naz@chitkara.edu.in
RI naz, huma/HGA-4519-2022; University, Chitkara/AAZ-3040-2021
OI University, Chitkara/0000-0003-3776-7136; Kumar,
   Deepak/0000-0002-6282-8925; , Rishu/0009-0000-6324-8730
CR Abdullah M, 2020, INTELL AUTOM SOFT CO, V26, P13, DOI 10.31209/2018.100000047
   Agarwal A., 2011, Sentiment Analysis of Twitter Data
   Ahuja Ravinder, 2019, Procedia Computer Science, V152, P341, DOI 10.1016/j.procs.2019.05.008
   Alharbi ASM, 2019, COGN SYST RES, V54, P50, DOI 10.1016/j.cogsys.2018.10.001
   Alsmadi Issa, 2019, Neural Computing and Applications, V31, P3819, DOI 10.1007/s00521-017-3298-8
   Avinash M., 2019, Emerging Technologies in Data Mining and Information Security. Proceedings of IEMIS 2018. Advances in Intelligent Systems and Computing (AISC 814), P475, DOI 10.1007/978-981-13-1501-5_41
   Bahrainian SA, 2013, IEEE INT C COMPUT, P227, DOI 10.1109/CSE.2013.44
   Beskirli M, 2015, INT CONF ADV COMPUT, P68, DOI 10.1109/ACSAT.2015.41
   Bhadane C, 2015, PROCEDIA COMPUT SCI, V45, P808, DOI 10.1016/j.procs.2015.03.159
   Das Sushree, 2018, Procedia Computer Science, V132, P956, DOI 10.1016/j.procs.2018.05.111
   Dridi A, 2019, INT J MACH LEARN CYB, V10, P2045, DOI 10.1007/s13042-017-0727-z
   El Alaoui I, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-018-0120-0
   Greco F, 2020, INT J INFORM MANAGE, V51, DOI 10.1016/j.ijinfomgt.2019.04.007
   Guo SS, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/6068743
   Gurkhe D, 2014, EFFECTIVE SENTIMENT
   Huang GB, 2011, INT J MACH LEARN CYB, V2, P107, DOI 10.1007/s13042-011-0019-y
   Jaiswal A, 2014, ADV MATER SER, P3
   Karlsson B, 2013, IEEE ENG MED BIO, P7444, DOI 10.1109/EMBC.2013.6611279
   Kumar A, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5107
   Kumar HIK, 2019, INT J INTERACT MULTI, V5, P109, DOI 10.9781/ijimai.2018.12.005
   Liao C, 2016, NEUROCOMPUTING, V210, P237, DOI 10.1016/j.neucom.2016.01.110
   Mäntylä MV, 2018, COMPUT SCI REV, V27, P16, DOI 10.1016/j.cosrev.2017.10.002
   Neethu MS, 2013, 2013 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATIONS AND NETWORKING TECHNOLOGIES (ICCCNT)
   O'Dea Bridianne, 2015, Internet Interventions, V2, P183, DOI 10.1016/j.invent.2015.03.005
   Ortigosa A, 2014, COMPUT HUM BEHAV, V31, P527, DOI 10.1016/j.chb.2013.05.024
   Osaba E, 2019, SWARM EVOL COMPUT, V44, P273, DOI 10.1016/j.swevo.2018.04.001
   Rosenthal S, 2019, ARXIV191202387
   Stojanovski D, 2018, MULTIMED TOOLS APPL, V77, P32213, DOI 10.1007/s11042-018-6168-1
   Suhasini M, 2020, ADV INTELL SYST COMP, V1079, P565, DOI 10.1007/978-981-15-1097-7_47
   Symeonidis S, 2018, EXPERT SYST APPL, V110, P298, DOI 10.1016/j.eswa.2018.06.022
   Troussas C., 2016, 2016 7 INT C INF INT, P1
   TROUSSAS C, 2016, 2016 7 INT C INF INT, P1
   Yilmaz Selim, 2013, Lecture Notes on Software Engineering, V1, P279, DOI 10.7763/LNSE.2013.V1.61
NR 33
TC 7
Z9 7
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 11443
EP 11458
DI 10.1007/s11042-020-10190-3
EA JAN 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000605548700022
DA 2024-07-18
ER

PT J
AU Rajbhandari, E
   Alsadoon, A
   Prasad, PWC
   Seher, I
   Nguyen, TQV
   Pham, DTH
AF Rajbhandari, Ereena
   Alsadoon, Abeer
   Prasad, P. W. C.
   Seher, Indra
   Nguyen, Tran Quoc Vinh
   Pham, Duong Thu Hang
TI A novel solution of enhanced loss function using deep learning in sleep
   stage classification: predict and diagnose patients with sleep disorders
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Sleep stages classification; Convolutional neural network
   (CNN); Loss function; Batch normalization; Adaptive filtering
AB Sleep stage classification is important to accurately predict and diagnose patients with sleep disorders. Though various deep learning approaches have been implemented to classify sleep classes, these consist limitations that impact the accuracy and processing time of the classification model. The aim of this research is to enhance the accuracy and minimize the training time of the deep learning classification model. The proposed system consists of One Dimensional Convolutional Neural Network (CNN) with enhanced loss function to improve the accuracy of scoring of five different sleep classes. Preprocessing, Feature Extraction and Classification are the main components of the proposed system. Initially, EEG signals are fed to an adaptive filter for preprocessing, in order to remove any noise in signal. Thereafter, feature is extracted through multiple convolutional and pooling layers, and finally the classification is done by fully connected layer using softmax activation with enhanced loss function. The proposed solution is tested on data samples from multiple datasets with five classes of Sleep classification. Based on the obtained results, the proposed solution has found to achieve an accuracy of 96.26% which is almost 4.2% higher than the state-of-the-art solution which is 92.76%. Furthermore, the processing time has been reduced by 11 milliseconds against the state-of-the-art solution. The proposed system focused on classifying sleep stages in five classes using EEG signals with deep learning approach. It enhances the loss function in order to minimize errors in the prediction of sleep classes and improves the accuracy of the model. Furthermore, the training speed of the model has also been reduced by applying batch normalization techniques inside the model. In the future, larger datasets of different sleep disorder patients with varying features can be used for training and implementing the proposed solution. The datasets can also be pre-processed using additional techniques to refine the data before feeding to the neural network model.
C1 [Rajbhandari, Ereena; Alsadoon, Abeer; Prasad, P. W. C.; Seher, Indra] Charles Sturt Univ, Sch Comp & Math, Sydney, NSW, Australia.
   [Nguyen, Tran Quoc Vinh; Pham, Duong Thu Hang] Univ Da Nang Univ Sci & Educ, Fac Informat Technol, 459 Ton Duc Thang, Lien Chieu 550000, Da Nang, Vietnam.
C3 Charles Sturt University
RP Alsadoon, A (corresponding author), Charles Sturt Univ, Sch Comp & Math, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; withana,
   chandana/0000-0002-3007-687X
CR Aboalayon KAI, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18090272
   Alickovic E, 2018, IEEE T INSTRUM MEAS, V67, P1258, DOI 10.1109/TIM.2018.2799059
   Biswal S, 2018, J AM MED INFORM ASSN, V25, P1643, DOI 10.1093/jamia/ocy131
   Boostani R, 2017, COMPUT METH PROG BIO, V140, P77, DOI 10.1016/j.cmpb.2016.12.004
   Bresch E, 2018, FRONT COMPUT NEUROSC, V12, DOI 10.3389/fncom.2018.00085
   Chambon S, 2018, IEEE T NEUR SYS REH, V26, P758, DOI 10.1109/TNSRE.2018.2813138
   Dimitriadis SI, 2018, CLIN NEUROPHYSIOL, V129, P815, DOI 10.1016/j.clinph.2017.12.039
   Dong H, 2018, IEEE T NEUR SYS REH, V26, P324, DOI 10.1109/TNSRE.2017.2733220
   Ghasemzadeh P, 2019, APPL SOFT COMPUT, V75, P523, DOI 10.1016/j.asoc.2018.11.007
   Hassan AR, 2017, KNOWL-BASED SYST, V128, P115, DOI 10.1016/j.knosys.2017.05.005
   Phan H, 2019, IEEE T NEUR SYS REH, V27, P400, DOI 10.1109/TNSRE.2019.2896659
   Phan H, 2019, IEEE T BIO-MED ENG, V66, P1285, DOI 10.1109/TBME.2018.2872652
   Jeon Y, 2019, IEEE ACCESS, V7, P96495, DOI 10.1109/ACCESS.2019.2928129
   Kotchoubey B, 2018, CLIN NEUROPHYSIOL, V129, P2682, DOI 10.1016/j.clinph.2018.09.020
   Mousavi S, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0216456
   Mousavi Z, 2019, J NEUROSCI METH, V324, DOI 10.1016/j.jneumeth.2019.108312
   Procházka A, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8050697
   Rahman MM, 2018, COMPUT BIOL MED, V102, P211, DOI 10.1016/j.compbiomed.2018.08.022
   Seifpour S, 2018, EXPERT SYST APPL, V104, P277, DOI 10.1016/j.eswa.2018.03.020
   Shen HM, 2019, IEEE ACCESS, V7, P125268, DOI 10.1109/ACCESS.2019.2939038
   Sokolovsky M, 2020, IEEE ACM T COMPUT BI, V17, P1835, DOI 10.1109/TCBB.2019.2912955
   Sors A, 2018, BIOMED SIGNAL PROCES, V42, P107, DOI 10.1016/j.bspc.2017.12.001
   Sun CL, 2019, IEEE ACCESS, V7, P109386, DOI 10.1109/ACCESS.2019.2933814
   Tsinalis O, 2016, ANN BIOMED ENG, V44, P1587, DOI 10.1007/s10439-015-1444-y
   Yildirim O, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16040599
   Yuan Y, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112429
   Zhang JM, 2018, COMPUT METH PROG BIO, V164, P181, DOI 10.1016/j.cmpb.2018.07.015
   Zhang LD, 2019, SLEEP, V42, DOI 10.1093/sleep/zsz159
   Zhang X, 2018, COMPUT BIOL MED, V103, P71, DOI 10.1016/j.compbiomed.2018.10.010
NR 29
TC 6
Z9 8
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 11607
EP 11630
DI 10.1007/s11042-020-10199-8
EA JAN 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000605548700005
DA 2024-07-18
ER

PT J
AU Granato, M
   Gadia, D
   Maggiorini, D
   Ripamonti, LA
AF Granato, Marco
   Gadia, Davide
   Maggiorini, Dario
   Ripamonti, Laura A.
TI An empirical study of players' emotions in VR racing games based on a
   dataset of physiological data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Affective computing; Video games; Emotions recognition; ECG; EMG; GSR;
   EDA; Respiration; Physiological dataset; Valence; Arousal; Machine
   learning; Virtual reality; Players' emotions
ID DESIGN
AB A video game is an interactive software able to arouse intense emotions in players. Consequentially, different theories have been proposed to understand which game aspects are able to affect the players' emotional state. However, only few works have tried to use empirical evidence to investigate the effects of different game aspects of the players' emotions. In this paper, we present the results of a set of experiments aimed at predicting the players' emotions during video games sessions using their physiological data. We have created a physiological dataset from the data acquired by 33 participants during video game fruition using a standard monitor and a Virtual Reality headset. The dataset contains information about electrocardiogram, 5 facials electromyographies, electrodermal activity, and respiration. Furthermore, we have asked the players to self-assess their emotional state on the Arousal and Valence space. We have then analyzed the contribution of each physiological signal to the overall definition of the players' mental state. Finally, we have applied Machine Learning techniques to predict the emotional state of players during game sessions at a precision of one second. The obtained results can contribute to define game devices and engines able to detect physiological data, as well to improve the game design process.
C1 [Granato, Marco; Gadia, Davide; Maggiorini, Dario; Ripamonti, Laura A.] Univ Milan, Dept Comp Sci, Via Celoria 18, I-20133 Milan, Italy.
C3 University of Milan
RP Granato, M (corresponding author), Univ Milan, Dept Comp Sci, Via Celoria 18, I-20133 Milan, Italy.
EM marco.granato@unimi.it; gadia@di.unimi.it; dario@di.unimi.it;
   ripamonti@di.unimi.it
RI Gadia, Davide/P-6309-2016; Ripamonti, Laura Anna/GQH-8599-2022
OI Gadia, Davide/0000-0003-4491-9150; Maggiorini, Dario/0000-0002-7460-2966
CR Abadi MK, 2015, IEEE T AFFECT COMPUT, V6, P209, DOI 10.1109/TAFFC.2015.2392932
   Angie AD, 2011, COGNITION EMOTION, V25, P1393, DOI 10.1080/02699931.2010.550751
   [Anonymous], 2004, WHY WE PLAY GAMES 4
   [Anonymous], 2016, GAMES MOVE US EMOTIO, DOI DOI 10.7551/MITPRESS/9267.001.0001
   [Anonymous], 2013, 2013 10 IEEE INT C W, DOI [10.1109/FG.2013.6553805, DOI 10.1109/FG.2013.6553805]
   Banzi A, 2014, CAPITAL CULT, P69
   Baron-Cohen S, 1998, NATURE, V392, P459, DOI 10.1038/33076
   Bartle R., 2003, Designing Virtual Worlds
   Benedek M, 2010, J NEUROSCI METH, V190, P80, DOI 10.1016/j.jneumeth.2010.04.028
   Betella A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148037
   Boccignone G., 2017, P 19 ACM INT C MULTI, P438
   Boccignone G, 2018, IEEE T COGN DEV SYST, V10, P865, DOI 10.1109/TCDS.2017.2788820
   Boccignone G, 2017, LECT NOTES COMPUT SC, V10484, P197, DOI 10.1007/978-3-319-68560-1_18
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Braithwaite J. J., 2013, PSYCHOPHYSIOLOGY, V1, P1017, DOI DOI 10.1111/J.1469-8986.2012.01384.X
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Caywood MS, 2017, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00647
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Clynes M, 1978, Sentics: the touch of the emotions
   Conover MaryBoudreau., 2003, Understanding Electrocardiography
   Critchley HD, 2002, NEUROSCIENTIST, V8, P132, DOI 10.1177/107385840200800209
   Csikszentmihayli M., 1979, PLAY LEARNING, P257
   Dalgleish T, 2004, NAT REV NEUROSCI, V5, P583, DOI 10.1038/nrn1432
   De Felice D, 2017, LNICST, V181
   Deterding S., 2011, P 15 INT AC MINDTREK, P9, DOI [10.1145/2181037.2181040, DOI 10.1145/2181037.2181040]
   DONOHO D. L., 2000, P AMS C MATH CHALL 2, V1, P32
   Draper JV, 1998, HUM FACTORS, V40, P354, DOI 10.1518/001872098779591386
   Drucker H, 1997, ADV NEUR IN, V9, P155
   Dubin D., 2000, Rapid Interpretation of EKG's: An Interactive Course, V6th
   Ekman P., 1971, Nebraska symposium on motivation, V19, P207
   Englehart K, 2003, IEEE T BIO-MED ENG, V50, P848, DOI 10.1109/TBME.2003.813539
   Fedotov A. A., 2016, Biomedical Engineering, V50, P114, DOI 10.1007/s10527-016-9600-8
   Fernandes CD, 2015, EDUC REV-CURITIBA, P11, DOI 10.1590/0104-4060.42523
   Fourati N, 2018, IEEE T AFFECT COMPUT, V9, P90, DOI 10.1109/TAFFC.2016.2591039
   Freeman D., 2003, Creating emotion in games: The craft and art of emotioneering
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Fullerton T, 2014, GAME DESIGN WORKSHOP, DOI DOI 10.1201/B16671
   FURNHAM A, 1986, PERS INDIV DIFFER, V7, P385, DOI 10.1016/0191-8869(86)90014-0
   Gadia D, 2018, MOBILE NETW APPL, V23, P136, DOI 10.1007/s11036-017-0834-9
   Gadia D, 2014, DISPLAYS, V35, P206, DOI 10.1016/j.displa.2014.05.010
   Granato M, 2018, P 14 INT C SIGN IM T
   Granato M, 2018, GOODTECHS '18: PROCEEDINGS OF THE 4TH EAI INTERNATIONAL CONFERENCE ON SMART OBJECTS AND TECHNOLOGIES FOR SOCIAL GOOD (GOODTECHS), P19, DOI 10.1145/3284869.3284895
   Granato M, 2017, LECT NOTES COMPUT SC, V10653, P197, DOI 10.1007/978-3-319-71940-5_18
   Granic I, 2014, AM PSYCHOL, V69, P66, DOI 10.1037/a0034857
   Grodal T, 2000, LEA COMMUN SER, P197
   Grossi G, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416560073
   Hamilton P, 2002, COMPUT CARDIOL, V29, P101, DOI 10.1109/CIC.2002.1166717
   Han JS, 2000, P 6 INT C SOFT COMP, P890
   Hazlett R. L., 2006, Conference on Human Factors in Computing Systems. CHI2006, P1023
   HERRMANN O, 1970, ELECTRON LETT, V6, P328, DOI 10.1049/el:19700231
   Huang HP, 1999, ICRA '99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P2392, DOI 10.1109/ROBOT.1999.770463
   Huizinga J, 2014, MARTINO FINE BOOKS
   Knutas A, 2019, MULTIMED TOOLS APPL, V78, P13593, DOI 10.1007/s11042-018-6913-5
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Kohavi R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, P1137
   Koster Raph, 2013, Theory of fun for game design
   Kreyszig E, 2011, ADV ENG MATH
   LYKKEN DT, 1971, PSYCHOPHYSIOLOGY, V8, P656, DOI 10.1111/j.1469-8986.1971.tb00501.x
   Lyons R., 2011, Understanding Digital Signal Processing
   Mauss I, 2009, COGNITION EMOTION, V23, P209, DOI 10.1080/02699930802204677
   Mayumi Oshiro Thais, 2012, Machine Learning and Data Mining in Pattern Recognition. Proceedings 8th International Conference, MLDM 2012, P154, DOI 10.1007/978-3-642-31537-4_13
   Menze BH, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-213
   Nunez Castellar Elena, 2014, 2014 Sixth International Workshop on Quality of Multimedia Experience (QoMEX), P292, DOI 10.1109/QoMEX.2014.6982334
   Oskoei MA, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, VOLS 1-3, P1465, DOI 10.1109/ROBIO.2006.340145
   Parnandi A, 2021, IEEE T AFFECT COMPUT, V12, P141, DOI 10.1109/TAFFC.2018.2842727
   Phinyomark A., 2009, Journal of Computing, V1, P71, DOI [10.3109/03091902.2016.1153739, DOI 10.3109/03091902.2016.1153739]
   Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Ravaja N, 2004, P 3 NORD C HUM COMP, P339
   Rechy-Ramirez EJ, 2011, Stages for Developing Control Systems Using EMG and EEG Signals: A Survey, P1744
   Ripamonti LA, 2018, SIMUL MODEL PRACT TH, V83, P124, DOI 10.1016/j.simpat.2017.12.002
   Rukavina S., 2015, INT J COMPUT ELECT A, V9, P977
   RUSSELL JA, 1977, J RES PERS, V11, P273, DOI 10.1016/0092-6566(77)90037-X
   RUSSELL JA, 1991, PSYCHOL BULL, V110, P426, DOI 10.1037/0033-2909.110.3.426
   Schmidt S, 1999, J PARAPSYCHOL, V63, P221
   Sheffield B, 2013, JOURNEY CREATE JOURN
   Snoek J., 2012, 26 ANN C NEUR INF PR, P2951
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P42, DOI 10.1109/T-AFFC.2011.25
   Stojanovi R, 2015, FOLIA MED FM U SARAE, V50, P29
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   Tognetti Simone, 2010, 2010 IEEE Information Theory Workshop (ITW 2010), P321, DOI 10.1109/ITW.2010.5593337
   Van Boxtel Anton., 2010, P OF MEASURING BEHAV, P104, DOI DOI 10.1145/1931344.1931382
   Venables PH, 1980, TECHNIQUES PSYCHOPHY, V54
   Vishay, 2017, DATASHEET NTCLE203E3
   Vismara C, 2017, L N INST COMP SCI SO, V195, P274, DOI 10.1007/978-3-319-61949-1_29
   Zafar M, 2018, IEEE T AFFECTIVE COM
NR 86
TC 49
Z9 51
U1 4
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33657
EP 33686
DI 10.1007/s11042-019-08585-y
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000594855000018
DA 2024-07-18
ER

PT J
AU Rajput, V
   Ansari, IA
AF Rajput, Vishal
   Ansari, Irshad Ahmad
TI Image tamper detection and self-recovery using multiple median
   watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tamper detection; Self-recovery; Median watermarking; Image
   watermarking; Image security
AB Photographs play a very crucial role in our lives, be it in the field of forensic investigation, military intelligence, scientific research, and publications. Nowadays, most of these photographs are in the digital format; which can be easily edited in any photo editing software without requiring any special knowledge of the field. It has become quite hard to identify whether an image is real or fake. This can be very crucial in the cases of forensic investigation or authorization of images. So, we need a solution, which not only identifies the attacks from different schemes like collage attack, crop attack, etc. but also recovers the edited or tampered portion. In proposed work, 4 reduced-size copy of the original image is hidden in the original image's 4-LSB using four pseudo-random codes. Later on, these copies are used for tamper detection. As image gets tampered, recovery images (which are stored in the 4-LSB's of the original image) also get tampered. So, before recovering the edited portion using the median image (or one out of the four recovery images) various filters like median filters, sharpening filters, and noise removal filters are used to enhance the quality. The proposed scheme recovers the host better than the many recently proposed schemes.
C1 [Rajput, Vishal; Ansari, Irshad Ahmad] PDPM Indian Inst Informat Technol Design & Mfg, Elect & Commun, Jabalpur, MP, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur
RP Ansari, IA (corresponding author), PDPM Indian Inst Informat Technol Design & Mfg, Elect & Commun, Jabalpur, MP, India.
EM vishalrajput@iiitdmj.ac.in; irshad@iiitdmj.ac.in
RI Ansari, Irshad Ahmad/AAT-2761-2020
OI Ansari, Irshad Ahmad/0000-0003-2991-0908; Rajput,
   Vishal/0000-0001-7152-212X
CR Cao F, 2017, DISPLAYS, V46, P52, DOI 10.1016/j.displa.2017.01.001
   Celik MU, 2002, IEEE T IMAGE PROCESS, V11, P585, DOI 10.1109/TIP.2002.1014990
   Chang CC, 2008, PATTERN RECOGN, V41, P654, DOI 10.1016/j.patcog.2007.06.003
   Chang YF, 2013, OPTO-ELECTRON REV, V21, P182, DOI 10.2478/s11772-013-0088-4
   Fridrich J, 2002, PROC SPIE, V4675, P691, DOI 10.1117/12.465330
   He HJ, 2009, SIGNAL PROCESS, V89, P1557, DOI 10.1016/j.sigpro.2009.02.009
   He HJ, 2012, IEEE T INF FOREN SEC, V7, P185, DOI 10.1109/TIFS.2011.2162950
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Islam M, NEURAL COMPUT APPL, P1
   Izquierdo E, 2003, IEEE T CIRC SYST VID, V13, P842, DOI 10.1109/TCSVT.2003.815961
   Korus P, 2014, IEEE T INF FOREN SEC, V9, P169, DOI 10.1109/TIFS.2013.2295154
   Kundur D, 1999, P IEEE, V87, P1167, DOI 10.1109/5.771070
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   Qi XJ, 2015, J VIS COMMUN IMAGE R, V30, P312, DOI 10.1016/j.jvcir.2015.05.006
   Qian ZX, 2011, DIGIT SIGNAL PROCESS, V21, P278, DOI 10.1016/j.dsp.2010.04.006
   Sarreshtedari S, 2015, IEEE T IMAGE PROCESS, V24, P2266, DOI 10.1109/TIP.2015.2414878
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Singh D, 2016, J VIS COMMUN IMAGE R, V38, P775, DOI 10.1016/j.jvcir.2016.04.023
   Verma VS, 2015, J VIS COMMUN IMAGE R, V31, P75, DOI 10.1016/j.jvcir.2015.06.001
   Wong PW, 2001, IEEE T IMAGE PROCESS, V10, P1593, DOI 10.1109/83.951543
   Yang CW, 2010, SIGNAL PROCESS, V90, P331, DOI 10.1016/j.sigpro.2009.07.007
   Yeung MM, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P680, DOI 10.1109/ICIP.1997.638587
   Zhang ZW, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0199143
NR 25
TC 16
Z9 16
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35519
EP 35535
DI 10.1007/s11042-019-07971-w
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000595980900045
DA 2024-07-18
ER

PT J
AU Xiao, LY
   Ouyang, HL
   Fan, CD
   Umer, T
   Poonia, RC
   Wan, SH
AF Xiao, Leyi
   Ouyang, Honglin
   Fan, Chaodong
   Umer, Tariq
   Poonia, Ramesh Chandra
   Wan, Shaohua
TI Gesture image segmentation with Otsu's method based on noise adaptive
   angle threshold
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gesture segmentation; Otsu&#8217; s method; Set mapping; Adaptive
   filtering; Angle threshold
AB By analyzing the essence and deficiency of the improved Otsu's method, this paper proposes a noise adaptive angle threshold based Otsu's method for gesture image segmentation. It first designs a two-dimensional histogram of gray value-neighborhood truncated gray mean to avoid the interference of extreme noise by discarding the extremes of the neighborhood. Then, the probability that the pixel is noise is calculated according to the actual situation, adaptive filtering is implemented to enhance the algorithm's universal applicability. It finally converts the threshold space to an angle space from 0 degrees to 90 degrees, and the threshold search range is compressed to improve its efficiency. As the gesture is close to the background and the boundary is blurred, this paper combines the global and local Otsu's method to segment the gesture images based on the angle space. On the one hand, it uses the global Otsu's method to obtain the global threshold t(1). On the other hand, it uses the local Otsu's method to obtain the local threshold t(2), and segments gesture images based on t(2). Experimental results show that the proposed method is effective and can accurately segment gesture images with different noises.
C1 [Xiao, Leyi; Ouyang, Honglin] Hunan Univ, Coll Elect & Informat Engn, Changsha 410082, Peoples R China.
   [Fan, Chaodong] Xiangtan Univ, Coll Informat Engn, Xiangtan 411105, Peoples R China.
   [Umer, Tariq] COMSATS Univ Islamabad, Dept Comp Sci, Lahore 54000, Pakistan.
   [Poonia, Ramesh Chandra] Amity Univ Rajasthan, Amity Inst Informat Technol, Jaipur 302013, Rajasthan, India.
   [Wan, Shaohua] Zhongnan Univ Econ & Law, Sch Informat & Safety Engn, Wuhan 430073, Peoples R China.
C3 Hunan University; Xiangtan University; COMSATS University Islamabad
   (CUI); Zhongnan University of Economics & Law
RP Wan, SH (corresponding author), Zhongnan Univ Econ & Law, Sch Informat & Safety Engn, Wuhan 430073, Peoples R China.
EM shaohua.wan@ieee.org
RI Poonia, Ramesh Chandra/F-2905-2015; Umer, Dr Tariq/AAZ-1887-2020; Wan,
   Shaohua/L-8492-2019; Wan, Shaohua/B-9243-2014
OI Poonia, Ramesh Chandra/0000-0001-8054-2405; Umer, Dr
   Tariq/0000-0002-3333-8142; Wan, Shaohua/0000-0001-7013-9081
CR [Anonymous], 2019, NEUROCOMPUTING
   [Anonymous], 2018, SEBASTIEN MARCEL DYN
   Ben Ishak A, 2017, PHYSICA A, V466, P521, DOI 10.1016/j.physa.2016.09.053
   [范朝冬 Fan Chaodong], 2014, [自动化学报, Acta Automatica Sinica], V40, P2480
   Fan Jiu-lun, 2007, Acta Electronica Sinica, V35, P751
   Ju ZJ, 2017, IEEE SYST J, V11, P1326, DOI 10.1109/JSYST.2015.2468231
   [李擎 Li Qing], 2017, [自动化学报, Acta Automatica Sinica], V43, P528
   Liu J.Z., 1993, Acta Automatica Sin, V19, P101, DOI DOI 10.16383/J.AAS.1993.01.015
   Liu Ke, 2017, Control and Decision, V32, P100, DOI 10.13195/j.kzyjc.2015.1159
   Lv CS, 2017, J ADV COMPUT INTELL, V21, P247, DOI 10.20965/jaciii.2017.p0247
   Nie FY, 2013, MULTIDIM SYST SIGN P, V24, P485, DOI 10.1007/s11045-012-0174-7
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Sathya PD, 2011, MEASUREMENT, V44, P1828, DOI 10.1016/j.measurement.2011.09.005
   Sha CS, 2016, J VIS COMMUN IMAGE R, V41, P339, DOI 10.1016/j.jvcir.2016.10.013
   Thabet E, 2018, J AMB INTEL HUM COMP, V9, P755, DOI 10.1007/s12652-017-0512-6
   Vafadar M, 2015, MULTIMED TOOLS APPL, V74, P7515, DOI 10.1007/s11042-014-1989-z
   Wang M., 2014, INT J LATEST RES SCI, V3, P65
   Wang RY, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531369
   Wu D, 2016, IEEE T PATTERN ANAL, V38, P1583, DOI 10.1109/TPAMI.2016.2537340
   [吴一全 WU Yiquan], 2008, [通信学报, Journal on Communications], V29, P77
   Xi YL, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115648
   [张新明 ZHANG Xinming], 2011, [电子学报, Acta Electronica Sinica], V39, P1778
   Zhao Y, 2019, IEEE J BIOMED HEALTH
NR 23
TC 12
Z9 12
U1 2
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35619
EP 35640
DI 10.1007/s11042-019-08544-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000595980900049
DA 2024-07-18
ER

EF