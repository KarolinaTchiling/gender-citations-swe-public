FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Lei, Y
   Shi, J
   Wu, JJ
AF Lei, Yu
   Shi, Jiao
   Wu, Jiaji
TI Region-driven distance regularized level set evolution for change
   detection in remote sensing images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Change detection; Remote sensing image; Active contour model; Level set;
   Region information
ID UNSUPERVISED CHANGE DETECTION; CLASSIFICATION; SEGMENTATION; MODEL
AB Change detection is a fundamental task in the interpretation and understanding of remote sensing images. The aim is to partition the difference images acquired from multitemporal satellite images into changed and unchanged regions. Level set method is a promising way for remote sensing images change detection among the existed methods. Unfortunately, re-initialization, a necessary step in classical level set methods is known a complex and time-consuming process, which may limits their practical application in remote sensing images change detection. In this paper, we present an unsupervised change detection approach for remote sensing image based on an improved region-based active contour model without re-initialization. In order to eliminate the process for re-initialization and reduce the numerical errors caused by re-initialization, we describe an improving level set method for remote sensing images change detection. The proposed method introduced a distance regularization term into the energy function which could maintain a desired shape of the level set function and keep a signed distance profile near the zero level set. The experimental results on real multi-temporal remote sensing images demonstrate the advantages of our method in terms of human visual perception and segmentation accuracy.
C1 [Lei, Yu; Shi, Jiao] Northwestern Polytech Univ, Sch Elect & Informat, West Youyi Rd, Xian 710072, Shaanxi, Peoples R China.
   [Wu, Jiaji] Xidian Univ, Sch Elect Engn, Xian 710071, Shaanxi, Peoples R China.
C3 Northwestern Polytechnical University; Xidian University
RP Shi, J (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, West Youyi Rd, Xian 710072, Shaanxi, Peoples R China.
EM leiy@nwpu.edu.cn; jiaoshi@nwpu.edu.cn; wujj@mail.xidian.edu.cn
FU National Natural Science Foundation of China [61603299, 61602385]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 61603299 and 61602385).
CR [Anonymous], 2002, SURFACES
   Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bazi Y, 2010, IEEE T GEOSCI REMOTE, V48, P3178, DOI 10.1109/TGRS.2010.2045506
   Ben Ayed I, 2008, IEEE T IMAGE PROCESS, V17, P2301, DOI 10.1109/TIP.2008.2006425
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Camps-Valls G, 2008, IEEE T GEOSCI REMOTE, V46, P1822, DOI 10.1109/TGRS.2008.916201
   Celik T, 2010, IEEE T GEOSCI REMOTE, V48, P1199, DOI 10.1109/TGRS.2009.2029095
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chaturvedi I, 2015, SIGNAL PROCESS, V110, P250, DOI 10.1016/j.sigpro.2014.09.009
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   Evans L., 1998, PARTIAL DIFFERENTIAL
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2014, IEEE T FUZZY SYST, V22, P98, DOI 10.1109/TFUZZ.2013.2249072
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Karantzalos K, 2009, IEEE T GEOSCI REMOTE, V47, P133, DOI 10.1109/TGRS.2008.2002027
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Li CM, 2010, IEEE T IMAGE PROCESS, V19, P3243, DOI 10.1109/TIP.2010.2069690
   Li CM, 2005, PROC CVPR IEEE, P430
   Li H, 2016, APPL SOFT COMPUT, V46, P767, DOI 10.1016/j.asoc.2015.10.044
   Liu YG, 2012, IEEE T VIS COMPUT GR, V18, P202, DOI 10.1109/TVCG.2011.77
   Liu ZG, 2014, IEEE GEOSCI REMOTE S, V11, P168, DOI 10.1109/LGRS.2013.2250908
   Ma HC, 2009, IEEE GEOSCI REMOTE S, V6, P558, DOI 10.1109/LGRS.2009.2021166
   Moser G, 2011, IEEE GEOSCI REMOTE S, V8, P725, DOI 10.1109/LGRS.2010.2102333
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Prendes J, 2015, IEEE T IMAGE PROCESS, V24, P799, DOI 10.1109/TIP.2014.2387013
   Shi J, 2016, APPL SOFT COMPUT, V46, P827, DOI 10.1016/j.asoc.2015.12.031
   Shi Y, 2008, IEEE T IMAGE PROCESS, V17, P645, DOI 10.1109/TIP.2008.920737
   Nguyen TNA, 2012, IEEE T IMAGE PROCESS, V21, P3734, DOI 10.1109/TIP.2012.2191566
   Yetgin Z, 2012, IEEE T GEOSCI REMOTE, V50, P1919, DOI 10.1109/TGRS.2011.2168230
NR 29
TC 2
Z9 2
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 24707
EP 24722
DI 10.1007/s11042-017-4650-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300008
DA 2024-07-18
ER

PT J
AU Srividhya, K
   Ramya, MM
AF Srividhya, K.
   Ramya, M. M.
TI Accurate object recognition in the underwater images using learning
   algorithms and texture features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater object recognition; Image segmentation; Chain coding; Back
   propagation neural network; Texture parameters; Deep learning;
   Morphological operators
AB Underwater image processing is very challenging due to its environmental conditions and poor sunlight. Images captured from the ocean using autonomous vehicles are often non-uniformly illuminated and contain noise due to the underlying environment. Object recognition is a challenging task under water due to the variation in the environment, target shape and orientation. Traditional algorithms based on spatial information may not lead to accurate segmentation as the intensity variation is often less in underwater images. Texture information representing the characteristics of the object is needed. Statistical features like autocorrelation, sum average, sum variance and sum entropy were extracted. These were fed as input to learning algorithms and training was done to effectively classify the object of interest and background. Chain coding was further applied for object recognition. The proposed methodology achieved a maximum classification accuracy of 96%.
C1 [Srividhya, K.; Ramya, M. M.] Hindustan Inst Technol & Sci, Ctr Automat & Robot, Chennai 603103, Tamil Nadu, India.
C3 Hindustan Institute of Technology & Science
RP Srividhya, K (corresponding author), Hindustan Inst Technol & Sci, Ctr Automat & Robot, Chennai 603103, Tamil Nadu, India.
EM sribhuvan@gmail.com; mmramya@hindustanuniv.ac.in
RI Mathanagopal, Ramya/ABC-6669-2020
OI kannan, srividhya/0000-0003-2930-6145; HITS, Hindustan Institute of
   Technology and Science/0009-0004-3570-2675
FU Naval Research Board, DRDO, New Delhi, India [NRB-295/SSB/12-13]; Earth
   System science Organization NIOT (ESSO-NIOT); Ministry of earth
   sciences; Hindustan Institute of Technology and Science
FX This research work was supported by the Naval Research Board (Grant No.
   NRB-295/SSB/12-13), DRDO, New Delhi, India. The authors thank NIOT,
   Chennai, India for providing the necessary dataset. The authors would
   like to acknowledge Earth System science Organization NIOT (ESSO-NIOT)
   and Ministry of earth sciences for their support. The authors also thank
   Hindustan Institute of Technology and Science for their continual
   support.
CR Agrawal S, 2014, INT J COMPUT SCI INF, V5
   Battiato S, 2015, P 16 INT C ACIVS 201
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Bezdek James C., 1981, PATTERN RECOGN
   Bhosle V. V., 2013, INT J SOFT COMPUTING, V3, P69
   Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046
   ERB RJ, 1993, PHARMACEUT RES, V10, P165, DOI 10.1023/A:1018966222807
   Foresti GL, 2000, INT J PATTERN RECOGN, V14, P167, DOI 10.1142/S021800140000012X
   Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627
   Gordan M, 2006, 2006 IEEE-TTTC INTERNATIONAL CONFERENCE ON AUTOMATION, QUALITY AND TESTING, ROBOTICS, VOL 2, PROCEEDINGS, P327
   Han KM, 2011, INT GEOSCI REMOTE SE, P617, DOI 10.1109/IGARSS.2011.6049204
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Jain R, 1995, MACHINE VISION, P5
   Joutsijoki H, 2014, ECOL INFORM, V20, P1, DOI 10.1016/j.ecoinf.2014.01.004
   Jusoh NA, 2009, INT J COMPUT SCI NET, V9, P222
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Ramadass GA, 2010, CURR SCI INDIA, V99, P809
   Ramakrishnan S, 2007, INT J IMAG SYST TECH, V17, P266, DOI 10.1002/ima.20122
   RUSPINI EH, 1970, INFORM SCIENCES, V2, P319, DOI 10.1016/S0020-0255(70)80056-1
   RUSPINI EH, 1969, INFORM CONTROL, V15, P22, DOI 10.1016/S0019-9958(69)90591-9
   Salem A. M., 2005, INT J GRAPHICS VISIO, V5, P1
   Soh LK, 1999, IEEE T GEOSCI REMOTE, V37, P780, DOI 10.1109/36.752194
   Srividhya K, 2017, INT J FUZZY SYST, V19, P1132, DOI 10.1007/s40815-016-0281-y
   Srividhya K., 2016, RES J INF TECHNOL, V8, P29
   Tzacheva AA, 2003, J MAGN RESON IMAGING, V17, P337, DOI 10.1002/jmri.10259
NR 26
TC 13
Z9 15
U1 0
U2 60
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 25679
EP 25695
DI 10.1007/s11042-017-4459-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500009
DA 2024-07-18
ER

PT J
AU Szczuko, P
AF Szczuko, Piotr
TI Real and imaginary motion classification based on rough set analysis of
   EEG signals for multimedia applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE EEG; Signal processing; Rough set; Classification
ID COMPUTER INTERFACE BCI; MOTOR IMAGERY; SENSORIMOTOR RHYTHMS; BRAIN;
   COMMUNICATION; COMPONENTS; NETWORK; CHANNEL; PURPOSE; P300
AB Rough set-based approach to the classification of EEG signals of real and imaginary motion is presented. The pre-processing and signal parametrization procedures are described, the rough set theory is briefly introduced, and several classification scenarios and parameters selection methods are proposed. Classification results are provided and discussed with their potential utilization for multimedia applications controlled by the motion intent. Accuracy metrics of classification for real and imaginary motion obtained with different parameter sets are compared. Results of experiments employing recorded EEG signals are commented and further research directions are proposed.
C1 [Szczuko, Piotr] Gdansk Univ Technol, Fac Elect Telecommun & Informat, Gdansk, Poland.
C3 Fahrenheit Universities; Gdansk University of Technology
RP Szczuko, P (corresponding author), Gdansk Univ Technol, Fac Elect Telecommun & Informat, Gdansk, Poland.
EM szczuko@sound.eti.pg.gda.pl
RI Szczuko, Piotr/AAB-4822-2020
OI Szczuko, Piotr/0000-0003-3703-8734
FU National Science Centre of Poland [DEC-2014/15/B/ST7/04724]
FX The research is funded by the National Science Centre of Poland on the
   basis of the decision DEC-2014/15/B/ST7/04724 (the project supervised by
   prof. Andrzej Czyzewski)
CR Alhaddad MJ, 2014, BIOMED ENG ONLINE, V13, DOI 10.1186/1475-925X-13-36
   Alotaiby T, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0251-9
   Solana AB, 2016, BRAIN IMAGING BEHAV, V10, P373, DOI 10.1007/s11682-015-9404-6
   Bek J, 2016, EXP BRAIN RES, V234, P1819, DOI 10.1007/s00221-016-4570-3
   Bhattacharyya S, 2014, MED BIOL ENG COMPUT, V52, P1007, DOI 10.1007/s11517-014-1204-4
   Chen SW, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-152
   Choi K, 2013, EXP BRAIN RES, V231, P351, DOI 10.1007/s00221-013-3699-6
   Corralejo R, 2014, MED BIOL ENG COMPUT, V52, P861, DOI 10.1007/s11517-014-1191-5
   Diez PF, 2011, J NEUROENG REHABIL, V8, DOI 10.1186/1743-0003-8-39
   Doud AJ, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0026322
   Faller J, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00320
   Gao JF, 2010, NEURAL COMPUT APPL, V19, P1217, DOI 10.1007/s00521-010-0370-z
   Gardener M., 2012, BEGINNING R STAT PRO
   Ge SN, 2014, BIOMED ENG LETT, V4, P55, DOI 10.1007/s13534-014-0118-2
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   He B., 2013, Neural Engineering, V2nd, P87
   He B, 2015, P IEEE, V103, P907, DOI [10.1109/jproc.2015.2407272, 10.1109/JPROC.2015.2407272]
   Iscan Z., 2011, Pattern Recognition and Image Analysis, V21, P481, DOI 10.1134/S1054661811020428
   Janusz A, 2011, LECT NOTES ARTIF INT, V6954, P45, DOI 10.1007/978-3-642-24425-4_8
   Jung TP, 2000, PSYCHOPHYSIOLOGY, V37, P163, DOI 10.1017/S0048577200980259
   Kasahara T, 2012, BMC NEUROSCI, V13, DOI 10.1186/1471-2202-13-66
   Krepki R, 2007, MULTIMED TOOLS APPL, V33, P73, DOI 10.1007/s11042-006-0094-3
   Kumar SU, 2017, NEURAL COMPUT APPL, V28, P3239, DOI 10.1007/s00521-016-2236-5
   LaFleur K, 2013, J NEURAL ENG, V10, DOI 10.1088/1741-2560/10/4/046003
   Leeb R, 2004, P ANN INT IEEE EMBS, V26, P4503
   Leeb R., 2004, 9th Computer Vision Winter Workshop, CVWW, V4, P99
   Li PY, 2013, BIOMED ENG ONLINE, V12, DOI 10.1186/1475-925X-12-77
   Li YT, 2016, MULTIMED TOOLS APPL, V75, P7999, DOI 10.1007/s11042-015-2717-z
   Marple SL, 1999, IEEE T SIGNAL PROCES, V47, P2600, DOI 10.1109/78.782222
   Nakayashiki K, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-90
   Ortega J, 2016, BIOMED ENG ONLINE, V15, DOI 10.1186/s12938-016-0178-x
   PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956
   Pfurtscheller G, 2006, NEUROIMAGE, V31, P153, DOI 10.1016/j.neuroimage.2005.12.003
   Pfurtscheller G, 2001, P IEEE, V89, P1123, DOI 10.1109/5.939829
   Postelnicu CC, 2013, IEEE T BIO-MED ENG, V60, P534, DOI 10.1109/TBME.2012.2228645
   Riza S L, 2016, ROUGHSETS DATA ANAL
   Schalk G, 2004, IEEE T BIO-MED ENG, V51, P1034, DOI 10.1109/TBME.2004.827072
   Shan HJ, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/s12938-015-0087-4
   Silva J, 2008, J NEUROENG REHABIL, V5, DOI 10.1186/1743-0003-5-24
   Suh D, 2006, ADVANCES IN COMPUTER, INFORMATION, AND SYSTEMS SCIENCES AND ENGINEERING, P143, DOI 10.1007/1-4020-5261-8_24
   Tadel F, 2011, COMPUTATIONAL INTELL, V2011
   TESCHE CD, 1995, ELECTROEN CLIN NEURO, V95, P189, DOI 10.1016/0013-4694(95)00064-6
   Tukey J.W., 1977, EXPLORATORY DATA ANA, V2
   Ungureanu M., 2004, MEAS SCI REV, V4, P1
   Uusitalo MA, 1997, MED BIOL ENG COMPUT, V35, P135, DOI 10.1007/BF02534144
   Velasco-Alvarez F, 2013, LECT NOTES COMPUT SC, V7903, P404
   Vidaurre C, 2010, BRAIN TOPOGR, V23, P194, DOI 10.1007/s10548-009-0121-6
   Wu CC, 2016, EXP BRAIN RES, V234, P2133, DOI 10.1007/s00221-016-4615-7
   Xia B, 2013, COGN COMPUT, V5, P243, DOI 10.1007/s12559-013-9202-7
   Yang JH, 2012, ARTIF INTELL MED, V55, P117, DOI 10.1016/j.artmed.2012.02.001
   Yuan H, 2014, IEEE T BIO-MED ENG, V61, P1425, DOI 10.1109/TBME.2014.2312397
NR 51
TC 13
Z9 14
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 25697
EP 25711
DI 10.1007/s11042-017-4458-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500010
OA hybrid
DA 2024-07-18
ER

PT J
AU Alam, M
   Malik, SUR
   Javed, Q
   Khan, A
   Khan, SB
   Anjum, A
   Javed, N
   Akhunzada, A
   Khan, MK
AF Alam, Masoom
   Malik, Saif-ur-Rehman
   Javed, Qaisar
   Khan, Abid
   Khan, Shamaila Bisma
   Anjum, Adeel
   Javed, Nadeem
   Akhunzada, Adnan
   Khan, Muhammad Khurram
TI Formal modeling and verification of security controls for multimedia
   systems in the cloud
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Formal analysis; Formal verification; HLPN; Modeling; SIEM; SMT; Z3
ID PROTOCOLS
AB Organizations deploy the Security Information and Event Management (SIEM) systems for centralized management of security alerts for securing their multimedia content. The SIEM system not only preserves events data, generated by devices and applications, in the form of logs but also performs real-time analysis of the event data. The SIEM works as the Security Operation Centre (SOC) in an organization, therefore, errors in the SIEM may compromise the security of the organization. In addition to focusing on the architecture, features, and the performance of the SIEM, it is imperative to carry out a formal analysis to verify that the system is impeccable. The ensuing research focuses mainly on the formal verification of the OSTORM a SIEM system. We have used High-Level Petri Nets (HLPN) and Z language to model and analyze the system. Moreover, Satisfiability Modulo Theories Library (SMT-Lib) and Z3 solver are used in this research to prove the correctness of the overall working of the OSTORM system. We demonstrate the correctness of the underlying system based on four security properties, namely: a) event data confidentiality, b) authentication, c) event data integrity, and d) alarm integrity. The results reveal that the OSTORM system functions correctly.
C1 [Alam, Masoom; Malik, Saif-ur-Rehman; Khan, Abid; Khan, Shamaila Bisma; Anjum, Adeel; Javed, Nadeem; Akhunzada, Adnan] COMSATS Inst Informat Technol, Dept Comp Sci, Cyber Secur Lab, Islamabad, Pakistan.
   [Javed, Qaisar] Int Islamic Univ, Dept Comp Sci & Software Engn, Islamabad, Pakistan.
   [Khan, Muhammad Khurram] King Saud Univ, CoEIA, Riyadh, Saudi Arabia.
C3 COMSATS University Islamabad (CUI); International Islamic University,
   Pakistan; King Saud University
RP Alam, M (corresponding author), COMSATS Inst Informat Technol, Dept Comp Sci, Cyber Secur Lab, Islamabad, Pakistan.
EM masoom.alam@comsats.edu.pk; saif_ur_rehman@comsats.edu.pk;
   qaisar@iiu.edu.pk; abidkhan@comsats.edu.pk; bis.sarfraz@gmail.com;
   a.qureshi@comsats.edu.pk; mkhurram@ksuedu.sa
RI Anjum, Adeel/L-4391-2013; Malik, Saif Ur Rehman/F-2290-2019; Akhunzada,
   Adnan/N-7917-2017; Malik, Saif Ur Rehman/M-3948-2019; Khan,
   Muhammad/IXN-8470-2023; Khan, Abid/V-1488-2019; Nusa,
   Nuhammad/JXY-5819-2024; KHAN, MUHAMMAD KHURRAM/E-4836-2014
OI Anjum, Adeel/0000-0001-5083-0019; Malik, Saif Ur
   Rehman/0000-0001-8195-1630; Akhunzada, Adnan/0000-0001-8370-9290; Malik,
   Saif Ur Rehman/0000-0001-8195-1630; KHAN, MUHAMMAD
   KHURRAM/0000-0001-6636-0533; Khan, Abid/0000-0003-2712-1956
FU ICT R&D under the CDACDEA project; Deanship of Scientific Research at
   King Saud University [PRG-1436-16]
FX This work has been possible by the funding provided by ICT R&D under the
   CDACDEA project. The SIEM as a service has been launched through the
   collaboration of Trillium Information Security Systems and the Cyber
   Security Lab at COMSATS Institute of Information Technology, Islamabad,
   Pakistan. The authors extend their sincere appreciations to the Deanship
   of Scientific Research at King Saud University for its funding this
   Prolific Research Group (PRG-1436-16)
CR Alam Q, 2016, FORMAL VERIFICATION
   Allen R., 1997, ACM Transactions on Software Engineering and Methodology, V6, P213, DOI 10.1145/258077.258078
   Alruwaili F.F., 2014, INT J CLOUD COMPUTIN, V3, P87, DOI DOI 10.11591/CLOSER.V3I2.6236
   [Anonymous], 2010, SMT LIB STANDARD VER
   [Anonymous], 2006, YICES SMT SOLVER
   Baier C, 2008, PRINCIPLES OF MODEL CHECKING, P1
   Barrett C, 2009, FRONT ARTIF INTEL AP, V185, P825, DOI 10.3233/978-1-58603-929-5-825
   Barrett Clark, 2010, SMT LIB ORG, V15, P18
   Biere A, 2003, ADV COMPUT, V58, P117
   Blanchet B, 2001, LECT NOTES COMPUT SC, V2126, P433
   Bussa T, 2016, GARTNER MAGIC QUADRA
   Chaput SR, 2010, COMPUT COMMUN NETW S, P241, DOI 10.1007/978-1-84996-241-4_14
   de Moura L, 2008, LECT NOTES COMPUT SC, V4963, P337, DOI 10.1007/978-3-540-78800-3_24
   Dimitrios K., 2014, SECURITY INFORM EVEN
   Forouzan B.A., 2007, Cryptography and Network Security
   Gai K., 2015, Security and Communication Networks, P1, DOI DOI 10.1109/CSCLOUD.2015.73
   GmbH A, 2015, RSYSLOG ROCKET FAST
   GORDON AD, 2002, CRYPTYC CRYPTOGRAPHI
   Hanna Y, 2008, WISEC'08: PROCEEDINGS OF THE FIRST ACM CONFERENCE ON WIRELESS NETWORK SECURITY, P109
   Hernan S, 2006, MSDN MAG, V21, P68
   Ihsan A, 2015, 2015 12TH INTERNATIONAL BHURBAN CONFERENCE ON APPLIED SCIENCES AND TECHNOLOGY (IBCAST), P254, DOI 10.1109/IBCAST.2015.7058513
   ISO/IEC Standard, 2000, 15909 ISOIEC
   Jensen K., 1983, High-Level Petri Nets
   Jung M, 2015, MULTIMED TOOLS APPL, V74, P6151, DOI 10.1007/s11042-014-2095-y
   Kim J.S., 2006, ROSATEA '06, P70
   Kim K, 2011, MULTIMED TOOLS APPL, V53, P213, DOI 10.1007/s11042-010-0508-0
   Malik SUR, 2013, IEEE T CLOUD COMPUT, V1, P50, DOI 10.1109/TCC.2013.3
   Matsuo S., 2010, Financial Cryptography and Data Security, P182
   McIver A, 2009, LECT NOTES COMPUT SC, V5850, P41, DOI 10.1007/978-3-642-05089-3_5
   Meyer R., 2007, SECURE AUTHENTICATIO
   Mohammad M, 2011, J SYST SOFTWARE, V84, P77, DOI 10.1016/j.jss.2010.08.048
   NEEDHAM RM, 1978, COMMUN ACM, V21, P993, DOI 10.1145/359657.359659
   Needham RogerM., 1987, OPER SYST REV, V21, P7
   Potts G, 2006, OSSIM USER GUIDE BOO
   Saghar K., 2010, 2010 NASA/ESA Conference on Adaptive Hardware and Systems (AHS 2010), P281, DOI 10.1109/AHS.2010.5546247
   Saghar Kashif, 2010, 2010 7th International Symposium on Communication Systems, Networks & Digital Signal Processing (CSNDSP 2010), P896
   Saghar K, 2009, PGNET 2009, P179
   Swift D., 2006, PRACTICAL APPL SIM S
   Tariq M, 2015, 2015 12TH INTERNATIONAL BHURBAN CONFERENCE ON APPLIED SCIENCES AND TECHNOLOGY (IBCAST), P268, DOI 10.1109/IBCAST.2015.7058515
   Tobarra L., 2007, P 4 C IBEROAM SEGUR, P1
   Tobarra L, 2007, INT FED INFO PROC, P95
   Webster M, 2016, RELIABLE AUTONOMOUS
   Weldemariam K, 2011, J SYST SOFTWARE, V84, P1618, DOI 10.1016/j.jss.2011.03.032
   William Stallings., 2006, Cryptography and Network Security
   Willrich R, 2002, MULTIMED TOOLS APPL, V16, P7, DOI 10.1023/A:1013233517612
   Zhang JX, 2012, ASIA PAC SOFWR ENG, P644, DOI 10.1109/APSEC.2012.60
   Zhang PC, 2010, J SYST SOFTWARE, V83, P723, DOI 10.1016/j.jss.2009.11.709
   Zhao K, 2015, PARALLEL STIMULUS GE
NR 48
TC 2
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22845
EP 22870
DI 10.1007/s11042-017-4853-0
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200049
DA 2024-07-18
ER

PT J
AU Cao, Z
   Príncipe, JC
   Bing, OY
   Dalgleish, F
   Vuorenkoski, A
   Ramos, B
   Alsenas, G
AF Cao, Zheng
   Principe, Jose C.
   Bing Ouyang
   Dalgleish, Fraser
   Vuorenkoski, Anni
   Ramos, Brian
   Alsenas, Gabriel
TI Marine animal classification using UMSLI in HBOI optical test facility
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE UMSLI; Optical test facility; Shape matching; Similarity measure
ID RECOGNITION; CORRENTROPY
AB Environmental monitoring is a critical aspect of marine renewable energy project success. A new system called Unobtrusive Multistatic Serial LiDAR Imager (UMSLI) has been prepared to capture and classify marine life interaction with electrical generation equipment. We present both hardware and software innovations of the UMSLI system. Underwater marine animal imagery has been captured for the first time using red laser diode serial LiDAR, which has advantages over conventional optical cameras in many areas. Moreover, given the scarcity of existing underwater LiDAR data, a shape matching based classification algorithm is proposed which requires few training data. On top of applying shape descriptors, the algorithm also adopts information theoretical learning based affine shape registration, improving point correspondences found by shape descriptors as well as the final similarity measure. Within Florida Atlantic University's Harbor Branch Oceanographic Institute optical test facility, experimental LiDAR data are collected through the front end of the UMSLI prototype, on which the classification algorithm is validated.
C1 [Cao, Zheng; Principe, Jose C.] Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.
   [Bing Ouyang; Dalgleish, Fraser; Vuorenkoski, Anni; Ramos, Brian; Alsenas, Gabriel] Florida Atlantic Univ, Oceanog Inst, Harbor Branch, Boca Raton, FL 33431 USA.
C3 State University System of Florida; University of Florida; State
   University System of Florida; Florida Atlantic University; Harbor Branch
   Oceanographic Institute Foundation
RP Cao, Z (corresponding author), Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.
EM zcao87@ufl.edu; principe@cnel.ufl.edu; bouyang@fau.edu;
   fdalglei@fau.edu; adalglei@fau.edu; bramos5@fau.edu; galsenas@fau.edu
RI principe, jose/N-8099-2014; Ouyang, Bing/AAD-8162-2019
OI Dalgleish, Fraser/0000-0003-1220-4935
FU US Department of Energy [DE-EE0006787]; FAU/HBOI internal fund
FX This work was supported in part by US Department of Energy contract
   DE-EE0006787 and FAU/HBOI internal fund.
CR [Anonymous], THESIS
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Cao Z, 2016, P ICASSP
   Cao Zheng., 2015, OCEANS'15 MTS/IEEE Washington, P1
   Chen BD, 2015, IEEE SIGNAL PROC LET, V22, P1723, DOI 10.1109/LSP.2015.2428713
   Cormen T. H., 2009, Introduction to Algorithms, VSecond
   Cronkite G, 2008, TECH REP
   Dalgleish F, 2013, J UNDERWATER ACOUST, V61
   Dalgleish F, 2013, SEA TECHNOL, V54, P15
   Dalgleish FR, 2013, MAR TECHNOL SOC J, V47, P128
   Donahue J, 2014, PR MACH LEARN RES, V32
   Donoser Michael, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P281
   Giddings TE, 2005, OCEANS-IEEE, P1380
   Hasanbelliu E, 2014, PAMI, V36
   Joslin J, 2014, DEV ADAPTABLE MONI 2
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Liu WF, 2007, IEEE T SIGNAL PROCES, V55, P5286, DOI 10.1109/TSP.2007.896065
   Ma JY, 2016, IEEE T IMAGE PROCESS, V25, P53, DOI 10.1109/TIP.2015.2467217
   Ma JY, 2015, IEEE T SIGNAL PROCES, V63, P1115, DOI 10.1109/TSP.2014.2388434
   Magowan K, 2012, MAR COAST FISH, V4, P651, DOI 10.1080/19425120.2012.730916
   Mobley C. D., 1994, LIGHT WATER RAD TRAN
   Ouyang B, 2012, INT SOC OPTICS PHOTO
   Ouyang B, 2013, IEEE J OCEANIC ENG, V38, P566, DOI 10.1109/JOE.2012.2229066
   Polagye B., 2014, PNNL23110
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924
   Wang JW, 2012, PATTERN RECOGN LETT, V33, P134, DOI 10.1016/j.patrec.2011.09.042
NR 27
TC 7
Z9 9
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 23117
EP 23138
DI 10.1007/s11042-017-4833-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200063
DA 2024-07-18
ER

PT J
AU Guzman-Zavaleta, ZJ
   Feregrino-Uribe, C
   Morales-Sandoval, M
   Menendez-Ortiz, A
AF Jezabel Guzman-Zavaleta, Zobeida
   Feregrino-Uribe, Claudia
   Morales-Sandoval, Miguel
   Menendez-Ortiz, Alejandra
TI A robust and low-cost video fingerprint extraction method for copy
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based video copy detection; ORB; Spectrogram saliency maps;
   TIRI; Video fingerprinting
AB Video fingerprinting for content-based video identification is a very useful task for the management and monetization of copyrighted content distribution. The main challenges of monitoring and copy detection systems are: a) the effective identification of highly transformed videos (robustness) and b) computational efficiency which may be relevant for some applications. Typically, most video fingerprinting methods focus on robustness leaving aside computational efficiency. However, for real-time applications are necessary low computational cost detection methods, for instance, in illegal content monitoring in video streaming distributions. Therefore, in this paper, we propose a low-cost and effective video fingerprint extraction method based on the combination of content-based features using both acoustic and visual video components. Our method is capable of detecting video copies by using computationally efficient fingerprints while maintaining robustness against the decrease in quality and content preserved distortions, which are frequent but severe attacks.
C1 [Jezabel Guzman-Zavaleta, Zobeida; Feregrino-Uribe, Claudia; Menendez-Ortiz, Alejandra] INAOE, Dept Ciencias Computac, Puebla, Mexico.
   [Morales-Sandoval, Miguel] CINVESTAV IPN, Lab Tecnol Informac, Tamaulipas, Mexico.
C3 Instituto Nacional de Astrofisica, Optica y Electronica; CINVESTAV -
   Centro de Investigacion y de Estudios Avanzados del Instituto
   Politecnico Nacional
RP Guzman-Zavaleta, ZJ (corresponding author), INAOE, Dept Ciencias Computac, Puebla, Mexico.
EM zguzman@inaoep.mx
RI Morales Sandoval, Miguel/E-8851-2019; Feregrino, Claudia/AAW-2607-2021;
   Guzman-Zavaleta, Zobeida Jezabel/X-4945-2019; Guzmán,
   Zobeida/HLP-7684-2023; Morales-Sandoval, Miguel/CAG-1219-2022; Guzman
   Zavaleta, Zobeida Jezabel/D-9855-2019
OI Morales Sandoval, Miguel/0000-0003-1702-8467; Morales-Sandoval,
   Miguel/0000-0003-1702-8467; Menendez-Ortiz,
   Alejandra/0000-0002-1258-9882; Guzman Zavaleta, Zobeida
   Jezabel/0000-0002-3163-8862
FU CONACyT Mexico [204554, PDCPN2013-01-216689]
FX This work was partially supported by CONACyT Mexico through the PhD
   grant No. 204554 and project PDCPN2013-01-216689.
CR [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], 2012, Computer Vision and Pattern Recognition Workshops (CVPRW), 2012 IEEE Computer Society Conference on
   [Anonymous], TRECVID 2011 TREC VI
   [Anonymous], EAT AN APPL LOUDL
   [Anonymous], AL ADV WOND LEW CARR
   Awad G, 2014, ACM T INFORM SYST, V32, DOI 10.1145/2629531
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Cano P, 2005, J VLSI SIG PROC SYST, V41, P271, DOI 10.1007/s11265-005-4151-3
   Dimoulas CA, 2015, IEEE MULTIMEDIA, V22, P26, DOI 10.1109/MMUL.2015.33
   Douglas O, 1987, SPEECH COMMUNICATION
   Douze M, 2009, P ACM INT C IM VID R, P1, DOI DOI 10.1145/1646396.1646421
   Esmaeili MM, 2011, IEEE T INF FOREN SEC, V6, P213, DOI 10.1109/TIFS.2010.2097593
   Gu X, 2013, P ICASSP, DOI [10.1109/ICASSP.2013.6637903, DOI 10.1109/ICASSP.2013.6637903]
   Gupta S, 2012, IEEE MULTIMEDIA, V19, P50, DOI 10.1109/MMUL.2011.74
   Guzman-Zavaleta Z. J., 2014, CCC14001 I NAC ASTR
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Harel J., 2012, A Saliency Implementation in MATLAB
   Guzman-Zavaleta ZJ, 2014, INT CONF INTERNET, P47, DOI 10.1109/ICITST.2014.7038773
   Kapoor A, 2009, DYNAMIC STREAMING DE
   Kim S, 2014, SIGNAL PROCESS-IMAGE, V29, P788, DOI 10.1016/j.image.2014.05.002
   Komogortsev O, 2013, US Patent App, Patent No. [13/ 908,748, 13908748]
   Lerch A, 2012, AUDIO FINGERPRINTING, DOI [10.1002/9781118393550.ch9, DOI 10.1002/9781118393550.CH9]
   Li T, 2012, MULTIMEDIA SYST, V22, DOI [10.1109/TCSVT.2012.2201670, DOI 10.1109/TCSVT.2012.2201670]
   Lian SG, 2010, STUD COMPUT INTELL, V282, P253
   Liu XC, 2013, IEEE SIGNAL PROC LET, V20, P1253, DOI 10.1109/LSP.2013.2287006
   Lu ZM, 2015, AEU-INT J ELECTRON C, V69, P82, DOI 10.1016/j.aeue.2014.07.021
   Lv Q., 2007, P 33 INT C VER LARG, P950
   Barrios JM, 2013, MULTIMED TOOLS APPL, V62, P75, DOI 10.1007/s11042-011-0915-x
   Marszalek M, 2009, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2009.5206557, DOI 10.1109/CVPR.2009.5206557]
   Miksik O., 2012, P ICPR
   Nie XS, 2013, SCI CHINA INFORM SCI, V56, DOI 10.1007/s11432-012-4760-y
   NIST T. D. V. R., 2016, TREC VIDEO RETRIEVAL
   NIST T. D. V. R., 2015, GUIDELINES TRECVID 2
   NIST T. D. V. R., 2009, VIDEO DATA TRECVID 2
   OpenCV Dev Team, 2013, OPENCV 2 4 8 0 DOC F
   Paudyal P., 2014, 2014 5 EUR WORKSH
   Pauleve L, 2010, PATTERN RECOGN LETT, V31, P1348, DOI 10.1016/j.patrec.2010.04.004
   Robertson DJ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0119460
   Rossion B, 2012, BRAIN COGNITION, V79, P138, DOI 10.1016/j.bandc.2012.01.001
   Rosten E, 2005, IEEE I CONF COMP VIS, P1508
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Shinde Sandhya R., 2015, 2015 International Conference on Communication, Information & Computing Technology (ICCICT), P1, DOI 10.1109/ICCICT.2015.7045737
   Smith JO., 2011, Spectral Audio Signal Processing
   Smith JO, 2014, MATH DISCRETE FOURIE
   Speech Hearing and Phonetic Sciences, 2009, UCL DIV PHS LANG SCI
   Suman E, 2013, P ARTCOM 2013
   Uchida Y, 2012, INT CONF ACOUST SPEE, P1029, DOI 10.1109/ICASSP.2012.6288061
   Wu SY, 2012, PROCEEDINGS OF THE 2012 EIGHTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS 2012), P280, DOI 10.1109/CIS.2012.69
   Yamaguchi K, 2012, MEXOPENCV COLLECTION
   Yonghong Tian, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3629, DOI 10.1109/ICIP.2011.6116504
NR 50
TC 8
Z9 8
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 24143
EP 24163
DI 10.1007/s11042-016-4168-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700046
DA 2024-07-18
ER

PT J
AU Liaqat, M
   Khan, S
   Majid, M
AF Liaqat, Madiha
   Khan, Sharifullah
   Majid, Muhammad
TI Image retrieval based on fuzzy ontology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Text based image retrieval; Fuzzy ontology; Objective
   evaluation; Subjective evaluation
ID DOCUMENT-RETRIEVAL; ANNOTATION; FEATURES
AB Rapid increase in digital images demands effective and efficient image retrieval systems. In text based image retrieval, images are annotated with keywords based on human perception. A user query is composed of keywords according to his/her requirements. Query keywords are matched with the keywords associated with images, for retrieval. This process has been extended with ontology to resolve semantic heterogeneities. However, crisp annotation and retrieval processes could not produce the desired results because both processes involve human perception. To overcome this problem, we have proposed a retrieval system that makes use of fuzzy ontology for improving retrieval performance. For modeling the semantic description of an image, it is divided into regions in our dataset and then regions are classified into concepts. The concepts are combined into categories. The concepts, categories and images are linked among themselves with fuzzy values in ontology. The retrieved results are ranked based on the relevancy between the keywords of a query and images. For evaluating the performance of the proposed methodology, we have used both the objective and subjective measures. Experimental results show that the proposed system performs better than the existing systems in terms of retrieval performance.
C1 [Liaqat, Madiha; Khan, Sharifullah] Natl Univ Sci & Technol, Sch Elect Engn & Comp Sci, Islamabad, Pakistan.
   [Majid, Muhammad] Univ Engn & Technol, Dept Comp Engn, Taxila, Pakistan.
C3 National University of Sciences & Technology - Pakistan; University of
   Engineering & Technology Taxila
RP Liaqat, M (corresponding author), Natl Univ Sci & Technol, Sch Elect Engn & Comp Sci, Islamabad, Pakistan.
EM 12phdmliaqat@seecs.edu.pk
RI Majid, Muhammad/Z-5667-2019
OI Majid, Muhammad/0000-0003-3662-2525
CR Allani O, 2016, PROCEDIA COMPUT SCI, V96, P1428, DOI 10.1016/j.procs.2016.08.188
   [Anonymous], IJRCCT
   Bannour H, 2014, MULTIMED TOOLS APPL, V72, P2107, DOI 10.1007/s11042-013-1491-z
   Cai B, 2007, INT C INF ACQ 2007
   Dasiopoulou S, 2010, MULTIMED TOOLS APPL, V49, P167, DOI 10.1007/s11042-009-0393-6
   Galindo J., 2008, INFORM SCI REFERENCE
   Guo JM, 2015, IEEE T IMAGE PROCESS, V24, P1010, DOI 10.1109/TIP.2014.2372619
   Horng Y-J, 2001, 10 IEEE INT C FUZZ S
   Hyvonen E, 2003, ONTOLOGY BASED IMAGE
   Jarvelin Kalervo, 2000, P 23 ANN INT ACM SIG
   Liaqat M, 2013, 2013 3 INT C COMP CO
   Liu S, 2004, OTM CONF INT C MOV M
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Long FH, 2003, SIG COM TEC, P1
   Luo B, 2003, ELECT IMAGING
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Müller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5
   OGAWA Y, 1991, FUZZY SET SYST, V39, P163, DOI 10.1016/0165-0114(91)90210-H
   Park K-W, 2007, INT C DAT SYST ADV A
   Pereira R, 2006, CAPTURING INTELL, P395, DOI DOI 10.1016/S1574-9576(06)80022-5
   Pereira R, 2009, INT J INTELL SYST, V24, P340, DOI 10.1002/int.20339
   RADECKI T, 1979, INFORM PROCESS MANAG, V15, P247, DOI 10.1016/0306-4573(79)90031-1
   Sarwar S, 2013, PROCEDIA COMPUT SCI, V22, P285, DOI 10.1016/j.procs.2013.09.105
   Schober J.-P., 2004, KI 2004 WORKSH APPL, P61
   Schreiber AT, 2001, IEEE INTELL SYST APP, V16, P66, DOI 10.1109/5254.940028
   Simou N, 2008, SIGNAL IMAGE VIDEO P, V2, P321, DOI 10.1007/s11760-008-0084-1
   Smeaton AF, 1996, INFORM RETRIEVAL HYP
   Streijl RC, 2016, MULTIMEDIA SYST, V22, P213, DOI 10.1007/s00530-014-0446-1
   Styrman A., 2005, THESIS
   Timpf S., 2001, P 4 AGILE C GEOGR IN
   Town C, 2006, MACH VISION APPL, V17, P94, DOI 10.1007/s00138-006-0017-3
   Ul-Qayyum Z, 2010, INT C IND ENG OTH AP
   Vogel J, 2007, ACM T APPL PERCEPT, V4, DOI 10.1145/1278387.1278393
   Vogel J, 2007, INT J COMPUT VISION, V72, P133, DOI 10.1007/s11263-006-8614-1
   Wang H, 2006, P 14 ACM INT C MULT
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
   Zadeh L., 1975, Synthese, V30, P407, DOI [DOI 10.1007/BF00485052, 10.1007/BF00485052]
NR 37
TC 6
Z9 6
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22623
EP 22645
DI 10.1007/s11042-017-4812-9
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200037
DA 2024-07-18
ER

PT J
AU Pogorelov, K
   Riegler, M
   Eskeland, SL
   de Lange, T
   Johansen, D
   Griwodz, C
   Schmidt, PT
   Halvorsen, P
AF Pogorelov, Konstantin
   Riegler, Michael
   Eskeland, Sigrun Losada
   de lange, Thomas
   Johansen, Dag
   Griwodz, Carsten
   Schmidt, Peter Thelin
   Halvorsen, Pal
TI Efficient disease detection in gastrointestinal videos - global features
   versus neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical; Automatic disease detection; Algorithmic screening; Global and
   local image features; Deep learning neural networks; Information
   retrieval; Performance evaluation
ID TEXTURAL FEATURES; POLYP DETECTION; DEEP
AB Analysis of medical videos from the human gastrointestinal (GI) tract for detection and localization of abnormalities like lesions and diseases requires both high precision and recall. Additionally, it is important to support efficient, real-time processing for live feedback during (i) standard colonoscopies and (ii) scalability for massive population-based screening, which we conjecture can be done using a wireless video capsule endoscope (camera-pill). Existing related work in this field does neither provide the necessary combination of accuracy and performance for detecting multiple classes of abnormalities simultaneously nor for particular disease localization tasks. In this paper, a complete end-to-end multimedia system is presented where the aim is to tackle automatic analysis of GI tract videos. The system includes an entire pipeline ranging from data collection, processing and analysis, to visualization. The system combines deep learning neural networks, information retrieval, and analysis of global and local image features in order to implement multi-class classification, detection and localization. Furthermore, it is built in a modular way, so that it can be easily extended to deal with other types of abnormalities. Simultaneously, the system is developed for efficient processing in order to provide real-time feedback to the doctors and for scalability reasons when potentially applied for massive population-based algorithmic screenings in the future. Initial experiments show that our system has multi-class detection accuracy and polyp localization precision at least as good as state-of-the-art systems, and provides additional novelty in terms of real-time performance, low resource consumption and ability to extend with support for new classes of diseases.
C1 [Pogorelov, Konstantin; Riegler, Michael; Griwodz, Carsten; Halvorsen, Pal] Simula Res Lab, POB 134, N-1325 Lysaker, Norway.
   [Eskeland, Sigrun Losada; de lange, Thomas] Baerum Hosp, Lysaker, Norway.
   [Johansen, Dag] UiT Arctic Univ Norway, Lysaker, Norway.
   [Schmidt, Peter Thelin] Karolinska Inst, Solna, Sweden.
C3 UiT The Arctic University of Tromso; Karolinska Institutet
RP Pogorelov, K (corresponding author), Simula Res Lab, POB 134, N-1325 Lysaker, Norway.
EM konstantin@simula.no; michael@simula.no; sigesk@vestreviken.no;
   t.d.lange@medisin.uio.no; dag.johansen@uit.no; griff@simula.no;
   peter.thelin-schmidt@karolinska.se; paalh@ifi.uio.no
RI Riegler, Michael A/E-5443-2015; de Lange, Thomas/Q-9063-2016
OI de Lange, Thomas/0000-0003-3989-7487; Halvorsen, Pal/0000-0003-2073-7029
FU FRINATEK project "EONS" [231687]
FX This work is founded by the FRINATEK project "EONS" #231687.
CR Albisser Z., 2015, Proceedings of the 6th ACM Multimedia Systems Conference, P73
   Alexandre LA, 2007, LECT NOTES ARTIF INT, V4702, P358
   ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   Ameling S., 2009, BILDVERARBEITUNG MED, P346
   [Anonymous], 2014, ARXIV14121897
   [Anonymous], OPEN SOURCE NEURAL N
   [Anonymous], 2012, ANN IEEE SYM FIELD P, DOI DOI 10.1109/FCCM.2012.47
   [Anonymous], END TO END PEOPLE DE
   [Anonymous], ARXIV151200567
   [Anonymous], 2014, P 31 INT C INT C MAC
   [Anonymous], 2016, P OSDI
   [Anonymous], P MMSYS
   [Anonymous], LEMENTARY MATH THEOR
   [Anonymous], BUYERS XGUIDE CONIC
   [Anonymous], NEURAL NETWORKS MACH
   [Anonymous], 2016, 2016 14 INT WORKSH C, DOI DOI 10.1109/CBMI.2016.7500257
   Breiman L., 2001, Mach. Learn., V45, P5
   Buades A, 2011, IMAGE PROCESS ON LIN, V1, P208, DOI 10.5201/ipol.2011.bcm_nlm
   Chaabouni S, 2016, IEEE IMAGE PROC, P1604, DOI 10.1109/ICIP.2016.7532629
   Chatzichristofis Savvas A., 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P191, DOI 10.1109/WIAMIS.2008.24
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   Cheng DC, 2008, LECT NOTES ARTIF INT, V5108, P62, DOI 10.1007/978-3-540-70715-8_6
   Chin C, 2000, J RES SCI TEACH, V37, P109, DOI 10.1002/(SICI)1098-2736(200002)37:2<109::AID-TEA3>3.0.CO;2-7
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Holme O, 2013, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD009259.pub2
   Kaminski MF, 2010, NEW ENGL J MED, V362, P1795, DOI 10.1056/NEJMoa0907667
   Kang J, 2003, CCECE 2003: CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING, VOLS 1-3, PROCEEDINGS, P1469
   Khaleghi A, 2015, IEEE ENG MED BIO, P4081, DOI 10.1109/EMBC.2015.7319291
   Le Q. V., 2011, P 28 INT C INT C MAC, P265
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Lux M., 2013, Synthesis Lectures on Information Concepts, Retrieval, and Services, V5, P1
   Mallery S, 2000, MED CLIN N AM, V84, P1059, DOI 10.1016/S0025-7125(05)70276-5
   Mamonov AV, 2014, IEEE T MED IMAGING, V33, P1488, DOI 10.1109/TMI.2014.2314959
   O'Connell JB, 2004, JNCI-J NATL CANCER I, V96, P1420, DOI 10.1093/jnci/djh275
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P170, DOI 10.1145/3083187.3083216
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Pogorelov K, 2016, COMP MED SY, P185, DOI 10.1109/CBMS.2016.63
   Redmon J., 2016, P IEEE C COMP VIS PA, P779, DOI DOI 10.1109/CVPR.2016.91
   Riegler M, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3079765
   Riegler Riegler M. M., P 24 ACM INT C MULT, P968, DOI [10.1145/2964284.2976760, DOI 10.1145/2964284.2976760]
   Sae Hwang, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P465
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   von Karsa L, 2012, ENDOSCOPY, V44, pSE1, DOI 10.1055/s-0032-1309822
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   Wang Y, 2014, IEEE J BIOMED HEALTH, V18, P1379, DOI 10.1109/JBHI.2013.2285230
   Zagoris Konstantinos, 2010, Proceedings of the 14th Panhellenic Conference on Informatics (PCI 2010), P143, DOI 10.1109/PCI.2010.38
   Zhou MD, 2014, 2014 7TH INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND INFORMATICS (BMEI 2014), P237, DOI 10.1109/BMEI.2014.7002777
NR 51
TC 37
Z9 43
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22493
EP 22525
DI 10.1007/s11042-017-4989-y
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200032
OA hybrid
DA 2024-07-18
ER

PT J
AU Yang, ZY
   Guo, SX
   Shao, QL
AF Yang, Zhiyao
   Guo, Shuxu
   Shao, Qinglong
TI A fast inter-frame encoding scheme using the edge information and the
   spatiotemporal encoding parameters for HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High Efficiency Video Coding (HEVC); Fast coding unit depth decision;
   Fast prediction unit mode decision; Edge information
ID VIDEO CODING HEVC; MODE DECISION; CU DECISION; ALGORITHM; ENCODERS;
   STANDARD
AB High Efficiency Video Coding (HEVC), as a novel video coding standard, has shown a better coding efficiency than all existing standards, such as H.264/AVC. It adopts a lot of new efficient coding tools, the most important one is the new hierarchical structures which include the coding unit (CU), prediction unit (PU) and transform unit (TU). However, the rate-distortion (RD) optimization process for all CUs, PUs, and TUs cause large computational costs. In this paper, a fast Inter-frame encoding scheme using the edge information and the spatiotemporal encoding parameters is proposed to reduce the encoder complexity of HEVC, which consists of a fast all 2 N x 2 N modes decision method, a fast CU depth level decision method and a fast PU mode decision method. This scheme uses edge information to express the structure complexity and uses the difference of edge information between current CU and its spatiotemporal CUs to express the edge similarity (ES) in one frame and the edge movement (EM) between two adjacent frames. And then, utilizes ES and EM as assistant parameters cooperate with CU depth levels and PU mode RD costs of spatiotemporal CUs to accomplish the early termination of CU split and the PU mode selection. The experimental results show that the proposed fast inter-frame encoding method can significantly reduce the computational costs with negligible RD loss. There are 53.7 and 54.9% encoding time savings on average, but only with average 1.5 and 1.8% Bjontegaard difference bitrate (BDBR) losses for various test sequences under random access and low delay conditions, respectively.
C1 [Yang, Zhiyao; Guo, Shuxu; Shao, Qinglong] Jilin Univ, Coll Elect Sci & Engn, Changchun, Jilin, Peoples R China.
C3 Jilin University
RP Yang, ZY (corresponding author), Jilin Univ, Coll Elect Sci & Engn, Changchun, Jilin, Peoples R China.
EM naruto_yang@163.com
CR Ahn S, 2015, IEEE T CIRC SYST VID, V25, P422, DOI 10.1109/TCSVT.2014.2360031
   Bossen F., 2013, JCTVCK1100
   Bossen F, 2012, IEEE T CIRC SYST VID, V22, P1685, DOI 10.1109/TCSVT.2012.2221255
   Cen YF, 2015, INFORM PROCESS LETT, V115, P719, DOI 10.1016/j.ipl.2015.04.001
   Correa G, 2015, IEEE T CIRC SYST VID, V25, P660, DOI 10.1109/TCSVT.2014.2363753
   Fan X, 2014, TIGHTENING BOUNDS BA, P2439
   Fan XN, 2014, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P200
   Kang J, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P26, DOI 10.1109/CISP.2013.6743998
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Lee A, 2014, ETRI J, V36, P527, DOI 10.4218/etrij.14.0113.0087
   Lee H, 2015, IEEE T BROADCAST, V61, P388, DOI 10.1109/TBC.2015.2419172
   Lee J, 2015, IEEE T CIRC SYST VID, V25, P411, DOI 10.1109/TCSVT.2014.2339612
   Shen LQ, 2015, SIGNAL PROCESS-IMAGE, V32, P121, DOI 10.1016/j.image.2015.01.008
   Shen LQ, 2014, IEEE T CIRC SYST VID, V24, P1709, DOI 10.1109/TCSVT.2014.2313892
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Shen XL, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P453, DOI 10.1109/PCS.2012.6213252
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Xiong J, 2015, IEEE T MULTIMEDIA, V17, P2147, DOI 10.1109/TMM.2015.2491018
   Xiong J, 2014, IEEE T MULTIMEDIA, V16, P2141, DOI 10.1109/TMM.2014.2356795
   Xiong J, 2014, IEEE T MULTIMEDIA, V16, P559, DOI 10.1109/TMM.2013.2291958
   Zhang H, 2014, IEEE T CIRC SYST VID, V24, P660, DOI 10.1109/TCSVT.2013.2290578
   Zhang QW, 2015, OPTIK, V126, P2793, DOI 10.1016/j.ijleo.2015.07.026
   Zhang YF, 2013, IEEE DATA COMPR CONF, P53, DOI 10.1109/DCC.2013.13
   Zhao W, 2015, IEEE T CIRC SYST VID, V25, P1709
   Zhong GY, 2015, MULTIMED TOOLS APPL, V74, P11023, DOI 10.1007/s11042-014-2216-7
   Zhou CT, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.043001
NR 26
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 24125
EP 24142
DI 10.1007/s11042-016-4165-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700045
DA 2024-07-18
ER

PT J
AU Zhang, C
   Zheng, J
   Zhang, YG
   Han, MX
   Li, B
AF Zhang, Chi
   Zheng, Jin
   Zhang, Yugui
   Han, Mengxiong
   Li, Bo
TI Moving object detection algorithm based on pixel spatial sample
   difference consensus
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Moving object detection; Spatial sample difference consensus (SSDC);
   Background model; Frame difference; Stable relationship
AB Moving object detection is an essential component for security video surveillance system and other computer vision applications. Although the latest object detection methods get promising detection expectations, however, accurate detection is still a tricky problem due to various challenges such as aperture effects, illumination variations, camouflage issues and retention problems in unconstrained video environments. In this paper, we propose a brand-new theoretical framework for foreground object detection based on the stable spatial relationship between current pixel and the randomly selected pixels in current frame. Different from the existing methods which determine the moving object area by comparing each pixel value with its surrounding pixels or by comparing two pixel values occupying the same positions in adjacent frames, the proposed algorithm sets up a spatial sample set for each individual pixel and defines Spatial Sample Difference Consensus (SSDC), which denotes changes of stable spatial relationship rather than direct changes in pixel values. Thus, the proposed algorithm computes the SSDC between two adjacent frames to subtract the moving objects. The experiments on recent data-set in both indoor and outdoor surveillance video sequences show that the proposed method achieved promising performance after compared with several state-of-the art methods.
C1 [Zhang, Chi; Zheng, Jin; Zhang, Yugui; Han, Mengxiong; Li, Bo] Beihang Univ, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.
   [Zheng, Jin; Li, Bo] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
C3 Beihang University; Beihang University
RP Zheng, J (corresponding author), Beihang Univ, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.; Zheng, J (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
EM zhongguochi@hotmail.com; JinZheng@buaa.edu.cn;
   hold_attitude@buaa.edu.cn; mxhan@outlook.com; boli@buaa.edu.cn
RI Li, bo/IWL-9318-2023; Li, Bo/AAA-8968-2020; zhang, chao/HTO-2468-2023;
   zhang, chao/IXD-9965-2023; zhang, chi/GRX-3610-2022; Zhang,
   Cheng/JAD-2236-2023
OI Li, Bo/0000-0002-7294-6888; 
FU National Key Research and Development Plan of China [2016YFC0801002];
   National Science Foundation of China [61370124]; China National 863
   Program [2014AA015104]
FX This work is supported by the National Key Research and Development Plan
   of China (Grant No.2016YFC0801002), the National Science Foundation of
   China (No.61370124), the China National 863 Program (Project No.
   2014AA015104). The authors would like to express their heartfelt
   gratitude to all the volunteers in the experiments and the anonymous
   reviewers, for their help on this paper.
CR [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], IM SIGN PROC 2008 CI
   [Anonymous], COMP SOC C COMP VIS
   [Anonymous], COMP SOC C COMP VIS
   [Anonymous], COMP INT SYST ICISS
   [Anonymous], EEE T PATTERN ANAL M
   [Anonymous], CONTR AUT INF SCI IC
   [Anonymous], IEEE
   [Anonymous], FRONT COMP VIS FCV 2
   Brown L.M., 2005, Proceedings of IEEEPETS Workshop, P1
   Chen BH, 2014, IEEE T MULTIMEDIA, V16, P837, DOI 10.1109/TMM.2014.2298377
   Hu QC, 2016, IEEE T INTELL TRANSP, V17, P1002, DOI 10.1109/TITS.2015.2496795
   Huang F., 2017, IEEE Trans. on Image Processing
   JAIN R, 1979, IEEE T PATTERN ANAL, V1, P206, DOI 10.1109/TPAMI.1979.4766907
   Jalal AS, 2014, MULTIMED TOOLS APPL, V73, P779, DOI 10.1007/s11042-012-1326-3
   Karahan S, 2015, SIG PROCESS COMMUN, P2505, DOI 10.1109/SIU.2015.7130393
   Kulchandani JS, 2015, 2015 INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING (ICPC)
   Lee G, 2015, IEEE SIGNAL PROC LET, V22, P1619, DOI 10.1109/LSP.2015.2417592
   Naqvi SS, 2016, IEEE T IMAGE PROCESS, V25, P4298, DOI 10.1109/TIP.2016.2587359
   Sun L, 2015, MULTIMED TOOLS APPL, V74, P3947, DOI 10.1007/s11042-013-1806-0
   Wang XG, 2014, IEEE T PATTERN ANAL, V36, P361, DOI 10.1109/TPAMI.2013.124
   Yang JM, 2016, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.2016.28
   Zhang XW, 2015, NEUROCOMPUTING, V168, P861, DOI 10.1016/j.neucom.2015.05.038
NR 24
TC 3
Z9 3
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22077
EP 22093
DI 10.1007/s11042-017-4802-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200012
DA 2024-07-18
ER

PT J
AU Cao, Q
   An, Y
   Shi, YD
   Zhu, XR
AF Cao, Qun
   An, Yang
   Shi, Yingdi
   Zhu, Xiaorong
TI Sparse representation-based 3D model retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-modal fusion; Latent Dirichlet allocation; 3D object retrieval;
   Sparse representation
ID SEARCH ENGINE; RECOGNITION
AB In this study, we leveraged the sparse representation for multi-modal information fusion to handle 3D model retrieval problem. First, SIFT feature is extracted to represent the visual appearance of 2D view images for each 3D models. With this low-level feature representation, the Latent Dirichlet Allocation model is learned to generate the high-level & discriminative visual representation for individual 3D model. Then, we utilize the sparse representation framework to handle the key problem, the similarity measure between two different 3D models, for model retrieval. The performance of the proposed method is evaluated on the novel MV-RED 3D object dataset, which contains both RGB and depth 3D model data. The comparison experiments demonstrate the proposed sparse representation-based framework can benefit from multi-modal information fusion and consequently augment the performance.
C1 [Cao, Qun; An, Yang; Shi, Yingdi; Zhu, Xiaorong] Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
C3 Tianjin University
RP An, Y; Zhu, XR (corresponding author), Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
EM caoquntju@sina.com; truman.nie@gmail.com; zxr@163.com
FU National Natural Science Foundation of China [61502337, 61472275,
   61170239, 61303208]; Tianjin Research Program of Application Foundation
   and Advanced Technology [15JCYBJC162000]; Elite Scholar Program of
   Tianjin University [2014XRG-0046]
FX This work was supported in part by the National Natural Science
   Foundation of China (61502337, 61472275, 61170239, 61303208), the
   Tianjin Research Program of Application Foundation and Advanced
   Technology (15JCYBJC162000), and the grant of Elite Scholar Program of
   Tianjin University (2014XRG-0046).
CR [Anonymous], 2003, INT J IMAGE GRAPH
   Ansary TF, 2007, IEEE T MULTIMEDIA, V9, P78, DOI 10.1109/TMM.2006.886359
   Bustos B, 2005, ACM COMPUT SURV, V37, P345, DOI 10.1145/1118890.1118893
   Chen BJ, 2015, J MATH IMAGING VIS, V51, P124, DOI 10.1007/s10851-014-0511-6
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Daras P, 2010, INT J COMPUT VISION, V89, P229, DOI 10.1007/s11263-009-0277-2
   Del Bimbo A, 2006, ACM T MULTIM COMPUT, V2, P20
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Gao Y, 2011, SIGNAL PROCESS-IMAGE, V26, P39, DOI 10.1016/j.image.2010.10.006
   Gao Y, 2010, PATTERN RECOGN, V43, P1142, DOI 10.1016/j.patcog.2009.07.012
   Gao Yue, 2015, P EUR WORKSH 3D OBJ, P129
   Gu B, 2015, NEURAL NETWORKS, V67, P140, DOI 10.1016/j.neunet.2015.03.013
   Guétat G, 2006, IEEE T INF TECHNOL B, V10, P362, DOI 10.1109/TITB.2005.863875
   Leng BA, 2011, MULTIMED TOOLS APPL, V51, P935, DOI 10.1007/s11042-009-0424-3
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Liu AA, 2015, SIGNAL PROCESS, V112, P74, DOI 10.1016/j.sigpro.2014.08.038
   Liu A, 2015, INFORM SCIENCES, V320, P429, DOI 10.1016/j.ins.2015.04.042
   Nie W-Z, 2015, J VIS COMMUN IMAGE R
   Nie WZ, 2015, PROC CVPR IEEE, P4503, DOI 10.1109/CVPR.2015.7299080
   Ohbuchi Ryutarou, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P63, DOI 10.1109/ICCVW.2009.5457716
   Ohbuchi R, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P93, DOI 10.1109/SMI.2008.4547955
   Paquet E, 2000, SIGNAL PROCESS-IMAGE, V16, P103, DOI 10.1016/S0923-5965(00)00020-5
   Regli WC, 2000, COMPUT AIDED DESIGN, V32, P119, DOI 10.1016/S0010-4485(99)00095-0
   Shih JL, 2007, PATTERN RECOGN, V40, P283, DOI 10.1016/j.patcog.2006.04.034
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Sundar H, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P130, DOI 10.1109/smi.2003.1199609
   Wang F, 2008, ELECT IMAGING 2008 I
   Wang XY, 2015, NEUROCOMPUTING, V151, P620, DOI 10.1016/j.neucom.2014.03.091
   Wen XZ, 2015, INFORM SCIENCES, V295, P395, DOI 10.1016/j.ins.2014.10.040
   Wong HS, 2007, IEEE T MULTIMEDIA, V9, P1026, DOI 10.1109/TMM.2007.898915
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
NR 33
TC 1
Z9 1
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 20069
EP 20079
DI 10.1007/s11042-016-4238-9
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500043
DA 2024-07-18
ER

PT J
AU Ferraz, CT
   Gonzaga, A
AF Ferraz, Carolina Toledo
   Gonzaga, Adilson
TI Object classification using a local texture descriptor and a support
   vector machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Object recognition; Texture descriptor; Local mapped
   pattern
ID IMAGE; FEATURES; SCALE
AB Objects classification or object detection is one of the most challenging tasks in computer vision. Digital images taken of real-life scenes capture objects at different positions, rotations and scales. Furthermore, variations in lighting, shape, color and texture within the same class make object classification a huge obstacle for computer vision algorithms. The most robust methodologies related to variations in lighting, rotation, color and scale, are based on "key points" localization, followed by applying a local descriptor to each surrounding region. Researchers have used various methods for detecting key points and have applied various local descriptors. Of these, the Scale-Invariant Feature Transform (SIFT), Speeded Up Robust Features (SURF) and Center-Symmetric Local Binary Pattern (CS-LBP) methods have obtained good performance and are associated with clustering algorithms or histogram representation based on independent features (Bag of Features (BoF)). In the BoF approach, the visual codebook extracted around the "key points" regions can effectively describe objects by their appearance based on local texture analysis. Recently, we proposed two new texture descriptors for object detection based on the Local Mapped Pattern (LMP) approach. The Mean-Local Mapped Pattern (M-LMP) and the Center Symmetric Local Mapped Pattern (CS-LMP) exhibit better performance than SIFT and CS-LBP, but prior results have shown that the size of descriptors could be reduced without loss of sensitivity. In this paper, we investigated reducing the size of the M-LMP descriptor and then evaluating its performance for object classification by a Support Vector Machine (SVM) classifier. In our experiments, we implemented an object recognition system based on the M-LMP reduced descriptor, and compared our results against the SIFT, Local Intensity Order Pattern (LIOP) and CS-LMP descriptors. The object classification results were analyzed using a BoF model and a SVM classifier, with the result that performance using the reduced descriptor is better than the other three well-known methods tested and also requires less processing time.
C1 [Ferraz, Carolina Toledo; Gonzaga, Adilson] Univ Sao Paulo, Dept Elect Engn, Sao Carlos, SP, Brazil.
C3 Universidade de Sao Paulo
RP Gonzaga, A (corresponding author), Univ Sao Paulo, Dept Elect Engn, Sao Carlos, SP, Brazil.
EM caroltoledoferraz@gmail.com; agonzaga@sc.usp.br
RI Gonzaga, Adilson/B-4883-2010; Toledo Ferraz, Carolina/O-6559-2016
OI Gonzaga, Adilson/0000-0003-2193-9394; Toledo Ferraz,
   Carolina/0000-0002-0867-6350
FU Sao Paulo Research Foundation (FAPESP) [2015/20812-5]; National Council
   for Scientific and Technological Development (CNPQ); Fundacao de Amparo
   a Pesquisa do Estado de Sao Paulo (FAPESP) [15/20812-5] Funding Source:
   FAPESP
FX The authors would like to thank the Sao Paulo Research Foundation
   (FAPESP), grant #2015/20812-5, and National Council for Scientific and
   Technological Development (CNPQ) for their financial support of this
   research.
CR [Anonymous], 2006, P IEEE COMPUTER SOC, DOI DOI 10.1109/CVPR.2006.95
   [Anonymous], 2000, P KDD WORKSH TEXT MI, DOI DOI 10.1109/ICCCYB.2008.4721382
   [Anonymous], 2003, INT C INT C MACH LEA, DOI DOI 10.1016/0026-2714(92)90278-S
   Bai G, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P610, DOI 10.1109/CISP.2008.520
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Cai HP, 2011, IEEE T PATTERN ANAL, V33, P338, DOI 10.1109/TPAMI.2010.89
   Ferraz CT, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414550106
   Ferraz CT, 2014, P 29 ANN ACM S APPL, P39, DOI DOI 10.1145/2554850.2554895
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Hoiem D, 2012, LECT NOTES COMPUT SC, V7574, P340, DOI 10.1007/978-3-642-33712-3_25
   Hongliang Jin, 2004, Proceedings. Third International Conference on Image and Graphics, P306
   Hou JA, 2010, LECT NOTES COMPUT SC, V6297, P414, DOI 10.1007/978-3-642-15702-8_38
   Hua G, 2007, IEEE I CONF COMP VIS, P229
   Iscen A, 2015, IEEE T IMAGE PROCESS, V24, P2369, DOI 10.1109/TIP.2015.2423557
   Jgou H., 2011, INT J COMPUT VISION, V87, P316
   Jurie F, 2005, IEEE I CONF COMP VIS, P604
   Ke Y, 2004, PROC CVPR IEEE, P506
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mikolajczyk K, 2002, LECT NOTES COMPUT SC, V2350, P128, DOI 10.1007/3-540-47969-4_9
   Mikolajczyk K, 2007, IEEE I CONF COMP VIS, P337
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689
   Pelleg D., 2000, P 17 INT C MACH LEAR, DOI DOI 10.1007/3-540-44491-2_3
   Perronnin F, 2006, LECT NOTES COMPUT SC, V3954, P464
   Schneiderman H, 2000, PROC CVPR IEEE, P746, DOI 10.1109/CVPR.2000.855895
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Streicher A, 2009, INT S VIS COMP
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Vedaldi A, 2012, IEEE T PATTERN ANAL, V34, P480, DOI 10.1109/TPAMI.2011.153
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang ZH, 2011, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2011.6126294
   Yuan X., 2011, IEEE INT C IMAGE PRO, P1061
   Zhang SC, 2009, ADVANCES IN MANAGEMENT OF TECHNOLOGY, PT 1, P19
   Zhao G., 2010, P INT C MULT, P1175
NR 42
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 20609
EP 20641
DI 10.1007/s11042-016-4003-0
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400011
DA 2024-07-18
ER

PT J
AU Gao, Z
   Li, SH
   Zhang, GT
   Zhu, YJ
   Wang, C
   Zhang, H
AF Gao, Z.
   Li, S. H.
   Zhang, G. T.
   Zhu, Y. J.
   Wang, C.
   Zhang, H.
TI Evaluation of regularized multi-task leaning algorithms for
   single/multi-view human action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Dense trajectory; Regularized multi-task learning;
   MTL; Multi-view
ID MODEL
AB Regularized multi-task learning (MTL) algorithms have been exploited in the field of pattern recognition and computer vision gradually, which can fully excavate the relationships of different related tasks. Therefore, many dramatically favorable approaches based on regularized MTL have been proposed. In the past decades, although the promising results about human action recognition have been achieved, most of existing action recognition algorithms focus on action descriptors, single/multi-view and multi-modality action recognition, and few works are related with MTL, especial of lacking the systematic evaluation of existing MTL algorithms for human action recognition. Thus, in the paper, seven popular regularized MTL algorithms in which different actions are considered as different tasks, are systematically exploited on two public multi-view action datasets. In detail, dense trajectory features are firstly extracted for each view, and then the shared codebook are constructed for all views by k-means, and then each video is coded by the shared codebook. Moreover, according to different regularized MTL algorithms, all actions or part of actions are considered as related, and then these actions are set to different tasks in MTL. Further, the effectiveness of different number of training samples from different action views is also evaluated for MTL. Large scale experimental results show that: 1) Regularized MTL is very useful for action recognition which can dig the latent relationship among different actions; 2) Not of all human actions are related, if irrelative actions are put together in MTL, its performance will fall; 3) With the increase of the training samples from different views, the relationships about different actions can be fully exploited, and it promotes the accuracy improvement of action recognition.
C1 [Gao, Z.; Li, S. H.; Zhang, G. T.; Zhang, H.] Tianjin Univ Technol, Minist Educ, Key Lab Comp Vis & Syst, Tianjin 300384, Peoples R China.
   [Gao, Z.; Li, S. H.; Zhang, G. T.; Zhang, H.] Tianjin Univ Technol, Tianjin Key Lab Intelligence Comp & Novel Softwar, Tianjin 300384, Peoples R China.
   [Zhu, Y. J.] Chinese Acad Sci, Inst Informat Engn, Natl Engn Lab Informat Secur Technol, Beijing 100093, Peoples R China.
   [Wang, C.] The Home Depot, Atlanta, GA 30339 USA.
C3 Tianjin University of Technology; Tianjin University of Technology;
   Chinese Academy of Sciences; Institute of Information Engineering, CAS
RP Gao, Z; Zhang, H (corresponding author), Tianjin Univ Technol, Minist Educ, Key Lab Comp Vis & Syst, Tianjin 300384, Peoples R China.; Gao, Z; Zhang, H (corresponding author), Tianjin Univ Technol, Tianjin Key Lab Intelligence Comp & Novel Softwar, Tianjin 300384, Peoples R China.
EM zangao@tjut.edu.cn; hzhang62@163.com
FU National Natural Science Foundation of China [61572357, 61202168];
   Tianjin Research Program of Application Foundation and Advanced
   Technology [14JCZDJC31700, 13JCQNJC0040]; Tianjin Municipal Natural
   Science Foundation [13JCQNJC0040]; Country China Scholarship Council
   [201608120021]
FX This work was supported in part by the National Natural Science
   Foundation of China (No.61572357, No.61202168). Tianjin Research Program
   of Application Foundation and Advanced Technology (14JCZDJC31700 and
   13JCQNJC0040). Tianjin Municipal Natural Science Foundation (No.
   13JCQNJC0040). Country China Scholarship Council (No.201608120021).
CR [Anonymous], 2011, INT C MACHINE LEARNI
   [Anonymous], 2005, BEHAV RECOGNITION VI
   [Anonymous], CVPR 08
   [Anonymous], 2008, P 18 IEEE INT C PATT
   [Anonymous], CORR
   [Anonymous], 2007, ICCV
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2012, CVPRW
   [Anonymous], 2008, PROC BRIT MACH VIS C
   [Anonymous], 2016, CVPR
   [Anonymous], 2004, KDD
   [Anonymous], P EUR C COMP VIS ECC
   [Anonymous], IJCV
   [Anonymous], 2012, MALSAR: Multi-tAsk Learning via StructurAl Regularization
   [Anonymous], ARXIV151104164
   [Anonymous], ICCV
   [Anonymous], 2013, ICCV
   [Anonymous], J ELECTR ENG TECHNOL
   [Anonymous], P IEEE INT C MULT EX
   [Anonymous], 2014, CVPR
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Everts I, 2014, IEEE T IMAGE PROCESS, V23, P1569, DOI 10.1109/TIP.2014.2302677
   Gao Y, 2014, IEEE T IND ELECTRON, V61, P2088, DOI 10.1109/TIE.2013.2262760
   Gao Z, 2016, NEUROCOMPUTING, V215, P138, DOI 10.1016/j.neucom.2016.01.113
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   Gao Z, 2015, NEUROCOMPUTING, V151, P554, DOI 10.1016/j.neucom.2014.06.085
   Gao Z, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P117, DOI 10.1145/2964284.2967194
   Gao Z, 2016, NEURAL COMPUT APPL, V27, P2047, DOI 10.1007/s00521-015-2002-0
   Gao Z, 2016, NEUROCOMPUTING, V173, P110, DOI 10.1016/j.neucom.2015.07.105
   Gao Z, 2014, KSII T INTERNET INF, V8, P483, DOI 10.3837/tiis.2014.02.009
   Gao Z, 2014, MULTIMED TOOLS APPL, V68, P641, DOI 10.1007/s11042-012-1071-7
   Ge L, 2015, LECT NOTES COMPUT SC, V9314, P114, DOI 10.1007/978-3-319-24075-6_12
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Guo WZ, 2015, INFORM SCIENCES, V320, P418, DOI 10.1016/j.ins.2015.04.034
   Guo Y., 2013, Proceedings of the 27th AAAI Conference on Artificial Intelligence, P387
   Hao T, 2016, INT J MOL SCI, V17, DOI 10.3390/ijms17060907
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Ju R, 2015, SIGNAL PROCESS-IMAGE, V38, P115, DOI 10.1016/j.image.2015.07.002
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Li R, 2007, ICCV 07, P1
   Liu A- A, IEEE T CYBERNETICS, V0, P1
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu AA, 2015, IEEE T CYBERNETICS, V45, P1194, DOI 10.1109/TCYB.2014.2347057
   Liu AA, 2015, SIGNAL PROCESS, V112, P74, DOI 10.1016/j.sigpro.2014.08.038
   Liu A, 2015, INFORM SCIENCES, V320, P429, DOI 10.1016/j.ins.2015.04.042
   Liu J, 2017, NEUROCOMPUTING, V236, P134, DOI 10.1016/j.neucom.2016.09.111
   Mansur A, 2013, IEEE T CYBERNETICS, V43, P1226, DOI 10.1109/TSMCB.2012.2226879
   Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557
   Nie LQ, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P695
   Nie WZ, 2015, PROC CVPR IEEE, P4503, DOI 10.1109/CVPR.2015.7299080
   Rodriguez MD, 2008, CVPR 08, P1
   Suk HI, 2011, IEEE T CIRC SYST VID, V21, P932, DOI 10.1109/TCSVT.2011.2133570
   Sun SL, 2013, NEURAL COMPUT APPL, V23, P2031, DOI 10.1007/s00521-013-1362-6
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Xu C., 2013, arXiv:1304.5634, P1, DOI [DOI 10.1145/1553374.1553391, 10.1145/1553374.1553391]
   Yao HT, 2016, IEEE T IMAGE PROCESS, V25, P4858, DOI 10.1109/TIP.2016.2599102
   Zhang XS, 2016, IEEE T IMAGE PROCESS, V25, P1033, DOI 10.1109/TIP.2015.2511585
NR 58
TC 12
Z9 12
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 20125
EP 20148
DI 10.1007/s11042-017-4384-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500047
DA 2024-07-18
ER

PT J
AU Sui, D
   Hou, DH
   Duan, XY
AF Sui, Dan
   Hou, Deheng
   Duan, Xinyu
TI An interpolation algorithm fitted for dynamic 3D face reconstruction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D face dynamic recognition; Iterative interpolation algorithm; Point
   cloud structure
AB In order to solve the problem of low recognition accuracy in later period which is caused by the too few extracted parameters in the 3D face recognition, and the incapable formation of completed point cloud structure. An automatic iterative interpolation algorithm is proposed. The new and more accurate 3D face data points are obtained by automatic iteration. This algorithm can be used to restore the data point cloud information of 3D facial feature in 2D images by means of facial three-legged structure formed by 3D face and automatic interpolation. Thus, it can realize to shape the 3D facial dynamic model which can be recognized and has high saturability. Experimental results show that the interpolation algorithm can achieve the complete the construction of facial feature based on the facial feature after 3D dynamic reconstruction, and the validity is higher.
C1 [Sui, Dan] Wuhan Univ Technol, Sch Informat Sci & Technol, Wuhan 430070, Hubei, Peoples R China.
   [Sui, Dan; Hou, Deheng; Duan, Xinyu] Anyang Normal Univ, Sch Software Engn, Anyang 455000, Henan, Peoples R China.
   [Duan, Xinyu] Calif State Polytech Univ Pomona, Coll Sci, Dept Comp, Pomona, CA 91768 USA.
C3 Wuhan University of Technology; Anyang Normal University; California
   State University System; California State Polytechnic University Pomona
RP Sui, D (corresponding author), Wuhan Univ Technol, Sch Informat Sci & Technol, Wuhan 430070, Hubei, Peoples R China.; Sui, D (corresponding author), Anyang Normal Univ, Sch Software Engn, Anyang 455000, Henan, Peoples R China.
EM suidan_123@163.com
OI Sui, Dan/0000-0002-2788-9677
CR Almazrooie M, 2015, JIPS, V2, P310
   Antonakos E, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2431445
   Chi JN, 2015, IEEE T IMAGE PROCESS, V24, P2671, DOI 10.1109/TIP.2015.2427514
   Delong A, 2009, IEEE I CONF COMP VIS, P285, DOI 10.1109/ICCV.2009.5459263
   Hassen R, 2015, IEEE T IMAGE PROCESS, V24, P2712, DOI 10.1109/TIP.2015.2428051
   Hong DAI, 2014, ELECT DES ENG, V22, P86
   Kim JH, 2015, IEEE T IMAGE PROCESS, V24, P2658, DOI 10.1109/TIP.2015.2428933
   Kong SG, 2015, IEEE T IMAGE PROCESS, V24, P1801, DOI 10.1109/TIP.2015.2405483
   Li CR, 2015, IEEE T IMAGE PROCESS, V24, P2344, DOI 10.1109/TIP.2015.2422575
   Li JQ, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440760
   Li S, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440755
   Li ZG, 2015, IEEE T IMAGE PROCESS, V24, P120, DOI 10.1109/TIP.2014.2371234
   Li ZF, 2015, IEEE T IMAGE PROCESS, V24, P2736, DOI 10.1109/TIP.2015.2426413
   Liu S, 2016, MULTIMED TOOLS APPL, V75, P15525, DOI 10.1007/s11042-014-2446-8
   Liu SA, 2017, MULTIMED TOOLS APPL, V76, P5787, DOI 10.1007/s11042-014-2408-1
   Liu T, 2015, TIP, V3, P424
   Luo Y, 2015, IEEE T IMAGE PROCESS, V24, P2355, DOI 10.1109/TIP.2015.2421309
   Ma Z, 2013, B SCI TECHNOL, V4, P149
   Meng-yi LIAO, 2015, COMPUT SIMUL, V7, P32
   Pei SC, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440172
   Sun YP, 2015, IEEE T IMAGE PROCESS, V24, P2515, DOI 10.1109/TIP.2015.2419075
   Zhang Q, 2014, J INF PROCESS SYST, V10, P523, DOI 10.3745/JIPS.01.0005
   Zhang SC, 2015, IEEE T IMAGE PROCESS, V24, P2466, DOI 10.1109/TIP.2015.2422578
   Zhou C, 2013, JIPS, V9, P511
NR 24
TC 2
Z9 2
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19575
EP 19589
DI 10.1007/s11042-015-3233-x
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500015
DA 2024-07-18
ER

PT J
AU Wang, XD
   Yang, Y
   Liu, H
   Qian, YL
AF Wang, Xiangdong
   Yang, Ying
   Liu, Hong
   Qian, Yueliang
TI Improving speech transcription by exploiting user feedback and word
   repetition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech transcription; Error correction; User feedback; Repeated word
ID ERROR-CORRECTION INTERFACE; RECOGNITION
AB Speech Transcription is important for video/audio retrieval and many other applications. In automatic speech transcription, recognition errors are inevitable, which makes user feedback such as manual error correction necessary. In this paper, an approach is proposed to improve the accuracy of speech transcription by exploiting user feedback and word repetition. The method aims at learning from user feedback and recognition results of preceding utterances and then correcting errors when repeated words are falsely recognized in following utterances. An interaction scheme for user feedback is proposed, which facilitate error correction by candidate lists and provide a new kind of feedback referred to as word indication to extend error correction from repeated words to repeated phrases. For template extraction and matching, the representation of word template and recognition results based on syllable confusion network (SCN) is proposed. During the transcription, templates of multi-syllable words/phrases based on SCN are extracted from user feedback and the N-best lattice, and then matched in SCN corresponding to recognition results of subsequent utterances to yield a new candidate list when repeated words are detected. Experimental results show that considerate error reduction is achieved in the newly-generated candidate lists.
C1 [Wang, Xiangdong; Liu, Hong; Qian, Yueliang] Chinese Acad Sci, Inst Comp Technol, Res Ctr Ubiquitous Comp Syst, Beijing 100190, Peoples R China.
   [Wang, Xiangdong; Liu, Hong; Qian, Yueliang] Chinese Acad Sci, Beijing Key Lab Mobile Comp & Pervas Device, Inst Comp Technol, Beijing 100190, Peoples R China.
   [Yang, Ying] China Agr Univ, Beijing 100083, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   China Agricultural University
RP Wang, XD (corresponding author), Chinese Acad Sci, Inst Comp Technol, Res Ctr Ubiquitous Comp Syst, Beijing 100190, Peoples R China.; Wang, XD (corresponding author), Chinese Acad Sci, Beijing Key Lab Mobile Comp & Pervas Device, Inst Comp Technol, Beijing 100190, Peoples R China.
EM xdwang@ict.ac.cn; hbxtyy@126.com; hliu@ict.ac.cn; ylqian@ict.ac.cn
RI wang, xiao/HGB-7081-2022; Wang, Xiangdong/AAF-9148-2020; wang,
   xiao/HZI-9156-2023
OI wang, xiao/0000-0002-4088-3341; 
CR Chen HZ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1081, DOI 10.1145/2647868.2654964
   Favre Benoit, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P146, DOI 10.1109/ICASSP.2014.6853575
   Harwath D, 2014, INTERSPEECH, P949
   Hong Zhang, 2011, 2011 International Conference on Intelligent Human-Machine Systems and Cybernetics, P97, DOI 10.1109/IHMSC.2011.29
   Jia D, 2016, 2016 INT C PROGR INF
   Karat Clare-Marie, 1999, P SIGCHI C HUM FACT, P568, DOI DOI 10.1145/302979.303160
   Laurent A, 2011, INT CONF ACOUST SPEE, P4884
   Lecouteux  B., 2006, INTERSPEECH 2006
   Li XH, 2009, JCPC: 2009 JOINT CONFERENCE ON PERVASIVE COMPUTING, P583
   Liang Y, 2014, INTERSPEECH, P1194
   Liang Y, 2014, IEEE W SP LANG TECH, P454, DOI 10.1109/SLT.2014.7078617
   Mangu L, 2000, COMPUT SPEECH LANG, V14, P373, DOI 10.1006/csla.2000.0152
   Miró JDV, 2015, SPEECH COMMUN, V74, P65, DOI 10.1016/j.specom.2015.09.006
   Nie LQ, 2013, IEEE T MULTIMEDIA, V15, P426, DOI 10.1109/TMM.2012.2229971
   Ogata J., 2005, P INTERSPEECH, P133
   Parada C, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1269
   Rodriguez L., 2010, INT C MULT INT WORKS
   Rodríguez L, 2007, LECT NOTES COMPUT SC, V4477, P241
   Sperber M, 2016, P LANG RES EV LREC
   Suhm B, 1997, 1997 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING, PROCEEDINGS, P583, DOI 10.1109/ASRU.1997.659139
   Suhm B, 1996, P ACM CHI WORKSH DES
   Miró JDV, 2014, OPEN LEARN, V29, P72, DOI 10.1080/02680513.2014.909722
   Valor Miro JD, 2015, LECT NOTES COMPUTER, V9307
   WANG LJ, 2008, P INTERSPEECH, P2659
   Xiangdong Wang, 2016, Journal of Automation and Control Engineering, V4, P153, DOI 10.12720/joace.4.2.153-158
   Xue J, 2005, INT CONF ACOUST SPEE, P853
NR 26
TC 2
Z9 2
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 20359
EP 20376
DI 10.1007/s11042-017-4714-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500058
DA 2024-07-18
ER

PT J
AU Gupta, PK
   Maharaj, BT
   Malekian, R
AF Gupta, P. K.
   Maharaj, B. T.
   Malekian, Reza
TI A novel and secure IoT based cloud centric architecture to perform
   predictive analysis of users activities in sustainable health centres
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud centric architecture; Cloud health care architectures; Cloud
   security; EHealth; Health care applications; Health care framework; IoT
   architecture; Sustainable health center
ID INTERNET; THINGS; CARE; CHALLENGES; VISION; DEVICE
AB Diabetes, blood pressure, heart, and kidney, some of the diseases common across the world, are termed 'silent killers'. More than 50 % of the world's population are affected by these diseases. If suitable steps are not taken during the early stages then severe complications occur from these diseases. In the work proposed, we have discussed the manner in which the Internet-of-Things based Cloud centric architecture is used for predictive analysis of physical activities of the users in sustainable health centers. The architecture proposed is based on the embedded sensors of the equipment rather than using wearable sensors or Smartphone sensors to store the value of the basic health-related parameters. Cloud centric architecture is composed of a Cloud data center, Public cloud, Private cloud, and uses the XML Web services for secure and fast communication of information. The architecture proposed here is evaluated for its adoption, prediction analysis of physical activities, efficiency, and security. From the results obtained it can be seen that the overall response between the local database server and Cloud data center remains almost constant with the rise in the number of users. For prediction analysis, If the results collected in real time for the analysis of physical activities exceed any of the parameter limits of the defined threshold value then an alert is sent to the health care personnel. Security analysis also shows the effective encryption and decryption of information. The architecture presented is effective and reduces the proliferation of information. It is also suggested, that a person suffering from any of the diseases mentioned above can defer the onset of complications by doing regular physical activities.
C1 [Gupta, P. K.; Maharaj, B. T.; Malekian, Reza] Univ Pretoria, Dept Elect Elect & Comp Engn, ZA-0002 Pretoria, South Africa.
C3 University of Pretoria
RP Gupta, PK (corresponding author), Univ Pretoria, Dept Elect Elect & Comp Engn, ZA-0002 Pretoria, South Africa.
EM pkgupta@ieee.org; sunil.maharaj@up.ac.za; reza.malekian@ieee.org
RI Gupta, Pradeep/AAE-7276-2020
OI Gupta, Pradeep/0000-0003-0416-7097; Maharaj, Bodhaswar
   TJ/0000-0002-3703-3637
CR Amendola S, 2014, IEEE INTERNET THINGS, V1, P144, DOI 10.1109/JIOT.2014.2313981
   [Anonymous], JITA J INFORM TECHNO
   [Anonymous], J MED INTERNET RES
   [Anonymous], BLUENETWORK CONCEPT
   [Anonymous], J ICT STANDARDIZATIO
   Bandyopadhyay D, 2011, WIRELESS PERS COMMUN, V58, P49, DOI 10.1007/s11277-011-0288-5
   Domingo MC, 2012, J NETW COMPUT APPL, V35, P584, DOI 10.1016/j.jnca.2011.10.015
   Castellani Angelo P., 2010, 2010 8th IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOM Workshops), P678, DOI 10.1109/PERCOMW.2010.5470520
   Chen SZ, 2014, IEEE INTERNET THINGS, V1, P349, DOI 10.1109/JIOT.2014.2337336
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Hassanalieragh M, 2015, 2015 IEEE 12TH INTERNATIONAL CONFERENCE ON SERVICES COMPUTING (SCC 2015), P285, DOI 10.1109/SCC.2015.47
   Hossain MS, 2016, COMPUT NETW, V101, P192, DOI 10.1016/j.comnet.2016.01.009
   Islam SMR, 2015, IEEE ACCESS, V3, P678, DOI 10.1109/ACCESS.2015.2437951
   Kang JM, 2006, IEEE T INSTRUM MEAS, V55, P1655, DOI 10.1109/TIM.2006.881035
   Kumar N, 2015, ARTECH HSE MICROW LI, P1
   Kwapisz JR., 2011, ACM SIGKDD EXPLORATI, V12, P74, DOI [DOI 10.1145/1964897.1964918, 10.1145/1964897.1964918]
   Mitra U, 2012, IEEE COMMUN MAG, V50, P116, DOI 10.1109/MCOM.2012.6194391
   Nandyala C., 2016, Internation Journal of Smart Homes, V10, P187, DOI [DOI 10.14257/IJSH.2016.10.2.18, 10.14257/ijsh.2016.10.2.18]
   Oresko JJ, 2010, IEEE T INF TECHNOL B, V14, P734, DOI 10.1109/TITB.2010.2047865
   Ortiz AM, 2014, IEEE INTERNET THINGS, V1, P206, DOI 10.1109/JIOT.2014.2318835
   Pollonini L, 2012, J MED SYST, V36, P653, DOI 10.1007/s10916-010-9531-y
   Santos A, 2014, PROC TECH, V16, P1351, DOI 10.1016/j.protcy.2014.10.152
   Santos J, 2016, J NETW COMPUT APPL, P1
   Seales C, 2015, IEEE INT CONF MO, P368, DOI [10.1109/MobServ.2015.57, 10.1109/MS.2015.57]
   Sheng ZG, 2013, IEEE WIREL COMMUN, V20, P91, DOI 10.1109/MWC.2013.6704479
   Tyagi S, 2016, 2016 6TH INTERNATIONAL CONFERENCE - CLOUD SYSTEM AND BIG DATA ENGINEERING (CONFLUENCE), P503, DOI 10.1109/CONFLUENCE.2016.7508172
   Wan JF, 2014, ELECTRON COMMER RES, V14, P389, DOI 10.1007/s10660-014-9147-2
   Xu BY, 2014, IEEE T IND INFORM, V10, P1578, DOI 10.1109/TII.2014.2306382
   Yang Kang, 2012, Proceedings of the 2012 IEEE Symposium on Robotics and Applications (ISRA), P653, DOI 10.1109/ISRA.2012.6219274
   Yang L, 2014, INT C COMP SUPP COOP, P609, DOI 10.1109/CSCWD.2014.6846914
   Zhang Y, 2014, IEEE INTERNET THINGS, V1, P311, DOI 10.1109/JIOT.2014.2329462
NR 31
TC 50
Z9 51
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18489
EP 18512
DI 10.1007/s11042-016-4050-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800016
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Lu, Y
   Liu, Y
   Dey, S
AF Lu, Yao
   Liu, Yao
   Dey, Sujit
TI Asymmetric and selective object rendering for optimized Cloud Mobile 3D
   Display Gaming user experience
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud Mobile Gaming; 3D; User experience; Subjective testing
ID VIDEO
AB Cloud Mobile 3D Display Gaming has been recently proposed where 3D video rendering and encoding are performed on cloud servers, with the resulting 3D video streamed wirelessly to mobile devices with 3D displays. This approach has the advantage of relieving high computation, power and storage requirements of 3D display gaming from mobile devices, while enabling game developers to focus on a single rich version of the game which can be experienced from any mobile device and platform. However, it is challenging to stream 3D video over dynamically fluctuating and often constrained mobile networks. In this paper, we propose a novel technique called Asymmetric and Selective Object Rendering (ASOR) which proves to be more powerful than previous solutions for Cloud based Mobile 3D display gaming. Specifically, this technique will enable rendering engine to intelligently decide whether or not to render an individual object and how good the corresponding texture detail will be if rendered, and the settings can be asymmetric for two views. Thus, unimportant objects can trade quality for reduced bitrate while important objects can remain high quality so that the overall user experience is optimized given certain bandwidth constraints. To quantitatively measure the user experience and bitrate by applying different rendering settings, we develop a user experience model and a bitrate model. We further propose an optimization algorithm which uses the above two models to automatically decide the optimal rendering settings for left view and right view to ensure the best user experience given the network conditions. Experiments conducted using real 4G-LTE network profiles on commercial cloud service with different genres of games demonstrate significant improvement in user experience when the proposed optimization algorithm is applied.
C1 [Lu, Yao; Liu, Yao; Dey, Sujit] Univ Calif San Diego, Dept Elect & Comp Engn, Mobile Syst Design Lab, San Diego, CA 92103 USA.
C3 University of California System; University of California San Diego
RP Lu, Y (corresponding author), Univ Calif San Diego, Dept Elect & Comp Engn, Mobile Syst Design Lab, San Diego, CA 92103 USA.
EM luyao@ucsd.edu; yliu182@gmail.com; sdey@ucsd.edu
RI Lu, Yao/R-2982-2017; Liu, Yao/AAI-1298-2019
FU National Science Foundation (US) [CCF-1160832]
FX This material is based upon work supported by the National Science
   Foundation (US) under Grant No. CCF-1160832.
CR Agrafiotis D, 2006, P IEEE INT C IM PROC
   Aksay A, 2007, SIGNAL PROCESS-IMAGE, V22, P157, DOI 10.1016/j.image.2006.12.001
   Cai W, 2013, 2013 IEEE SEVENTH INTERNATIONAL SYMPOSIUM ON SERVICE-ORIENTED SYSTEM ENGINEERING (SOSE 2013), P551, DOI 10.1109/SOSE.2013.30
   Chiang TH, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL I, P295, DOI 10.1109/ISCAS.2000.857088
   Chu PC, 1998, J HEURISTICS, V4, P63, DOI 10.1023/A:1009642405419
   Gürler CG, 2010, IEEE IMAGE PROC, P2409, DOI 10.1109/ICIP.2010.5651035
   Hemmati M., 2013, Proceeding of the 23rd ACM Workshop on Network and Operating Systems Support for Digital Audio and Video, P7
   Huang CY, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2537855
   Liu Y, 2008, IEEE T CIRC SYST VID, V18, P134, DOI 10.1109/TCSVT.2007.913754
   Liu Y, 2014, IEEE J EM SEL TOP C, V4, P43, DOI 10.1109/JETCAS.2014.2298921
   Lu Y., 2015, IEEE J SEL TOP QUANT, V9, P1
   Lu Y, 2015, P IEEE INT C COMM IC
   Lu YJ, 2014, ACS SYM SER, V1185, P3
   Ma Z, 2012, IEEE T CIRC SYST VID, V22, P671, DOI 10.1109/TCSVT.2011.2177143
   Ou YF, 2011, IEEE T CIRC SYST VID, V21, P286, DOI 10.1109/TCSVT.2010.2087833
   Ribas-Corbera J, 1999, IEEE T CIRC SYST VID, V9, P172, DOI 10.1109/76.744284
   Saygili G, 2011, IEEE T BROADCAST, V57, P593, DOI 10.1109/TBC.2011.2131450
   Shea R, 2013, IEEE NETWORK, V27, P16, DOI 10.1109/MNET.2013.6574660
   SINHA P, 1979, OPER RES, V27, P503, DOI 10.1287/opre.27.3.503
   Vankeirsbilck B, 2013, 2013 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2013), P1282
   Wang SX, 2013, IEEE T MULTIMEDIA, V15, P870, DOI 10.1109/TMM.2013.2240674
NR 21
TC 2
Z9 3
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18291
EP 18320
DI 10.1007/s11042-016-3798-z
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800006
DA 2024-07-18
ER

PT J
AU Wu, Q
   Qin, GH
   Huang, BB
AF Wu, Qiong
   Qin, Guihe
   Huang, Biaobing
TI The research of multimedia cloud computing platform data dynamic task
   scheduling optimization method in multi core environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-core environment; Multimedia data; Cloud computing platform
ID MODEL
AB In cloud computing platform, current data scheduling algorithm cannot make full use of bandwidth resources of nodes in multi-core environment, resulting in heavy server load and play discontinuity of multimedia files, thus, a multimedia cloud computing platform data dynamic task scheduling method is proposed, on the basis of the related theory of multi-core processor, the system model and multimedia cloud computing platform data dynamic task model are established, multimedia cloud computing platform data dynamic task scheduling strategy is introduced based on the models, and gives assumed conditions of task scheduling strategy design, the priority calculation stage, improved particle swarm task scheduling stage and mapping stage from the task to processor are passed through to complete the analysis of this strategy, the tasks are distributed to the processor in accordance with certain rules, and dynamic task scheduling results are given and optimized. The simulation experimental results show that the proposed method has very high scheduling performance.
C1 [Wu, Qiong; Qin, Guihe; Huang, Biaobing] Jilin Univ, Coll Comp Sci & Technol, Changchun 130122, Peoples R China.
   [Wu, Qiong] Changchun Univ Technol, Coll Humanities & Informat, Changchun 130122, Peoples R China.
C3 Jilin University; Changchun University of Technology
RP Wu, Q (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130122, Peoples R China.
EM wuqiong_wq6780@163.com
RI wu, qiong/GRY-4672-2022
OI Qin, Guihe/0000-0002-2472-4324
FU Foundation of Jilin Province Education Department [2014645]
FX This work is supported by the Foundation of Jilin Province Education
   Department (2014645).
CR Amato F, 2016, J VISUAL LANG COMPUT, V32, P35, DOI 10.1016/j.jvlc.2015.10.012
   [Anonymous], 2016, J SUPERCOMPUT
   [Anonymous], J COMPUT CIV ENG
   [Anonymous], J BIOMECH
   Baranwal G, 2016, J SUPERCOMPUT, V72, P317, DOI 10.1007/s11227-015-1565-y
   Chen G, 2015, INT CONF CONNECT VEH, P263, DOI 10.1109/ICCVE.2015.17
   Crespi A, 2016, SCI TOTAL ENVIRON, V541, P502, DOI 10.1016/j.scitotenv.2015.08.159
   Foltz IN, 2016, IMMUNOL REV, V270, P51, DOI 10.1111/imr.12409
   Gao L., 2015, Multimedia Systems, P1
   Gu L, 2016, IEEE T COMPUT, V65, P19, DOI 10.1109/TC.2015.2417566
   Han QS, 2016, IEEE T COMPUT AID D, V35, P2082, DOI 10.1109/TCAD.2016.2543020
   Huang ML, 2015, COMPUTING, V97, P425, DOI 10.1007/s00607-014-0383-z
   Lu YP, 2016, IEEE T PARALL DISTR, V27, P3323, DOI 10.1109/TPDS.2016.2533606
   Mei J, 2015, IEEE T COMPUT, V64, P3064, DOI 10.1109/TC.2015.2401021
   Nelson C, 2016, OPT COMMUN, V364, P145, DOI 10.1016/j.optcom.2015.11.049
   Önal H, 2016, J ENVIRON MANAGE, V171, P144, DOI 10.1016/j.jenvman.2016.02.005
   Sobeslav V, 2016, J BIOMOL STRUCT DYN, V34, P2688, DOI 10.1080/07391102.2015.1127182
   Tanweer MR, 2016, INFORM SCIENCES, V326, P1, DOI 10.1016/j.ins.2015.07.035
   Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802
   Vallerio M, 2016, CHEM ENG SCI, V140, P201, DOI 10.1016/j.ces.2015.09.012
   VERDOLIVA L, 2016, IEEE SIGNAL PROCESS, V33, P164, DOI DOI 10.1109/MSP.2015.2488018
   Wang ZJ, 2015, J SUPERCOMPUT, V71, P2748, DOI 10.1007/s11227-015-1416-x
   Xie L, 2015, MULTIMEDIA SYST, V21, P525, DOI 10.1007/s00530-014-0397-6
   Yu CP, 2016, PHYS FLUIDS, V28, DOI 10.1063/1.4940044
   Zhang DM, 2016, IEEE T COMPUT AID D, V35, P724, DOI 10.1109/TCAD.2016.2527710
   Zhen Y, 2016, IEEE T CYBERNETICS, V46, P27, DOI 10.1109/TCYB.2015.2392052
NR 26
TC 2
Z9 3
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17163
EP 17178
DI 10.1007/s11042-016-3667-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500016
DA 2024-07-18
ER

PT J
AU Hornansky, M
   Zao, JK
AF Hornansky, Martin
   Zao, John K.
TI Customizing short-length LT codes with evolution strategies for video
   streaming protection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless multimedia streaming; Unequalerasure protection; LT codes;
   Raptorcodes; Scalable video codes; Evolution strategies; Goal
   programming
AB Designing short-length Luby Transform (SLLT) codes to best protect video streaming and multicasting over lossy communication remains largely an empirical exercise. In this paper, we present a systematic approach to customize the decoding performance of these codes so that the protected video bitstreams may have the best playback quality over a wide range of channel loss rates. Our approach begins with the proposal of a new SLLT decoding performance model based on three parameters: decoding overhead, symbol decoding failure rate and tail probability of symbol decoding failure rate. We then formulate the design of SLLT codes as a multi-objective optimization problem, specify the design objectives in terms of goal program, and search for the most suitable codes using an augmented weighted Tchebycheff method implemented with the Covariance Matrix Adaptation Evolution Strategy (CMA-ES). Two design examples are provided to illustrate the effectiveness of our approach: (1) an SLLT postcode of a short-length raptor code that provides erasure protection to H.264 AVC bitstreams, and (2) an SLLT post-code of a rateless UEP code that supports graceful degradation of H.264 SVC playback quality. Empirical results demonstrate that the proposed method is capable of producing SLLT codes with customized decoding performance, whereas, the customized codes enable the playback pictures to attain significantly higher PSNR values at different stages of the decoding process than the pictures recovered under the protection of conventionally optimized codes.
C1 [Hornansky, Martin; Zao, John K.] Natl Chiao Tung Univ, Dept Comp Sci, 1001 Univ Rd, Hsinchu 300, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Hornansky, M (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, 1001 Univ Rd, Hsinchu 300, Taiwan.
EM hornansky.cs95g@nctu.edu.tw; jkzao@cs.nctu.edu.tw
FU Aiming for the Top University Plan of National Chiao Tung University;
   Ministry of Education, Taiwan [105W963]; Ministry of Science and
   Technology, Taiwan [MOST 105-2923-E-009 -001 -MY2]
FX The authors would like to thank Prof. Chung-Hsuan Wang of the NCTU
   Electrical Engineering Department for his valuable advices and fruitful
   discussion on SLLT codes. We are also grateful to Pei-lun Diao for a
   major contribution to the design of statistical decoding performance
   model. This work was supported in part by the Aiming for the Top
   University Plan of National Chiao Tung University, sponsored by the
   Ministry of Education, Taiwan, under Grant Number 105W963, in part by
   the Ministry of Science and Technology, Taiwan, under Grant no. MOST
   105-2923-E-009 -001 -MY2.
CR Ahmad S, 2011, IEEE T MULTIMEDIA, V13, P92, DOI 10.1109/TMM.2010.2093511
   [Anonymous], 3GPP TS26 346
   [Anonymous], 2010, 2010 INT C AUTONOMOU
   [Anonymous], MULTIPLE CRITERIA DE
   [Anonymous], CCSDS FALL M
   [Anonymous], 2012, P 2012 IEEE C EVOLUT
   [Anonymous], DESIGN ANAL LT CODES
   [Anonymous], 1996, P IEEE INT C EV COMP
   [Anonymous], CUSTOMIZATION SHORT
   [Anonymous], RAPTORQ TM TECHNICAL
   [Anonymous], 2012 E C EVOL COMPUT
   [Anonymous], CUSTOMIZATION SLLT C
   Bodine EA, 2008, IEEE ICC, P1195, DOI 10.1109/ICC.2008.233
   Chung-Hsuan Wang, 2011, Proceedings of the 2011 IEEE International Symposium on Multimedia (ISM 2011), P279, DOI 10.1109/ISM.2011.51
   Emmerich Michael., 2006, Multicriteria optimization and decision making
   Hansen M, 1996, IEEE C EVOL COMPUTAT, P312, DOI 10.1109/ICEC.1996.542381
   Hansen N, 2004, LECT NOTES COMPUT SC, V3242, P282
   Hansen N, 2001, EVOL COMPUT, V9, P159, DOI 10.1162/106365601750190398
   Hyytia E, 2006, 6 INT WORKSH RAR EV, P64
   Ignizio J., 2003, ENCY INFORM SYSTEMS, V2, P489, DOI DOI 10.1016/B0-12-227240-4/00082-4
   Joines J. A., 1994, Proceedings of the First IEEE Conference on Evolutionary Computation. IEEE World Congress on Computational Intelligence (Cat. No.94TH0650-2), P579, DOI 10.1109/ICEC.1994.349995
   Lin JG, 2005, MATH PROGRAM, V103, P1, DOI 10.1007/s10107-003-0462-y
   Luby M, 2002, ANN IEEE SYMP FOUND, P271, DOI 10.1109/SFCS.2002.1181950
   Luby M, 2007, IEEE T BROADCAST, V53, P235, DOI 10.1109/TBC.2007.891703
   Maatouk G, 2012, IEEE T INFORM THEORY, V58, P2558, DOI 10.1109/TIT.2012.2184690
   Marler RT, 2004, STRUCT MULTIDISCIP O, V26, P369, DOI 10.1007/s00158-003-0368-6
   Oka A, 2009, IEEE T COMMUN, V57, P2607, DOI 10.1109/TCOMM.2009.080143
   Shokrollahi A, 2004, PROG COM SC, V23, P85
   Shokrollahi A, 2000, 2000 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY, PROCEEDINGS, P5, DOI 10.1109/ISIT.2000.866295
   Shokrollahi A, 2006, IEEE T INFORM THEORY, V52, P2551, DOI 10.1109/TIT.2006.874390
   Shokrollahi A, 2009, FOUND TRENDS COMMUN, V6, P213, DOI 10.1561/0100000060
   Steuer R, 1986, Multiple Criteria Optimization: Theory, Computation and Application
   Talari A, 2012, IEEE T COMMUN, V60, P1237, DOI 10.1109/TCOMM.2012.030712.110032
   Vukobratovic D, 2009, IEEE T MULTIMEDIA, V11, P1094, DOI 10.1109/TMM.2009.2026087
   Wang CH, 2010, IEEE T INFORM THEORY, V56, P296, DOI 10.1109/TIT.2009.2034821
   Yen KK, 2013, INT CONF WIRE COMMUN
   Yen KK, 2013, IEEE T MULTIMEDIA, V15, P2162, DOI 10.1109/TMM.2013.2269898
   Yen KK, 2012, 2012 INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY AND ITS APPLICATIONS (ISITA 2012), P11
   Yen KK, 2013, IEEE COMMUN LETT, V17, P976, DOI 10.1109/LCOMM.2013.040913.130136
   Zhu HJ, 2007, PROCEEDINGS OF 2007 INTERNATIONAL WORKSHOP ON SIGNAL DESIGN AND ITS APPLICATIONS IN COMMUNICATIONS, P65
   Zhu HP, 2008, 2008 11TH IEEE SINGAPORE INTERNATIONAL CONFERENCE ON COMMUNICATION SYSTEMS (ICCS), VOLS 1-3, P1431, DOI 10.1109/ICCS.2008.4737419
   Zielinski Karin., 2008, Advances in Differential Evolution, P111, DOI [10.1007/ 978-3-540-68830-3{\\\\_}4, DOI 10.1007/978-3-540-68830-3]
NR 42
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15221
EP 15250
DI 10.1007/s11042-016-3756-9
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900002
OA hybrid
DA 2024-07-18
ER

PT J
AU Koleini, M
   Ahmadzadeh, MR
   Sadri, S
AF Koleini, Mina
   Ahmadzadeh, Mohammad Reza
   Sadri, Saeed
TI A new efficient feature-combination-based method for dynamic texture
   modeling and classification using semi-random starting parameter dynamic
   Bayesian networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic texture modeling; Dynamic texture classification; Dual tree
   complex wavelet transform; Feature combination; Semi-random starting
   parameter dynamic Bayesian network
ID RECOGNITION
AB Dynamic texture (DT) is an extension of texture to the temporal domain. Recently, modeling and classification of DTs have attracted much attention. In many pattern recognition and computer vision problems, such as our case, applying only one descriptor to extract one type of feature vector is not sufficient to obtain all of the relevant information from the input data. Hence, it is necessary to apply two or more descriptors to extract two or more different feature vector types with different dimensions and domains. In this paper, for the purpose of DT classification, we propose a novel approach to efficiently combine all different types of feature vectors describing the DT in their original form, dimensionality, and domain. On the other hand, each DT has two types of information: texture and dynamism. In addition to classification, the two above-mentioned aspects of a DT are efficiently simulated in order to model DTs, using the novel proposed approach. Therefore, a new method for simultaneous modeling and classification of DTs is proposed. Our approach is based on a Bayesian Network (BN) scheme, especially Dynamic Bayesian Network (DBN). To increase the efficiency of DBNs, we propose Semi-Random Starting Parameter Dynamic Bayesian Networks (SRSP-DBNs). The proposed approach is sufficiently fast and outperforms the state-of-the-art DT classification methods in terms of accuracy. Furthermore, it is invariant to all types of changes that may occur in the DT, including shift, illumination, rotation, and scale variations.
C1 [Koleini, Mina; Ahmadzadeh, Mohammad Reza; Sadri, Saeed] Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan 8415683111, Iran.
C3 Isfahan University of Technology
RP Koleini, M (corresponding author), Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan 8415683111, Iran.
EM m.koleini@ec.iut.ac.ir; Ahmadzadeh@cc.iut.ac.ir; Sadri@cc.iut.ac.ir
OI Ahmadzadeh, Mohammad Reza/0000-0001-9558-5854
CR Ahonen T, 2009, LECT NOTES COMPUT SC, V5575, P61, DOI 10.1007/978-3-642-02230-2_7
   Aji SM, 2000, IEEE T INFORM THEORY, V46, P325, DOI 10.1109/18.825794
   [Anonymous], P C INF SCI SYST
   [Anonymous], IEEE PAC AS C CIRC C
   [Anonymous], ECCV WORKSH DYN VIS
   [Anonymous], 2005, P INT WORKSH TEXT AN
   [Anonymous], 2000, EUR C COMP VIS
   [Anonymous], DYNTEX
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], WORKSH MOT
   [Anonymous], IMPLEMENTATION CLIQU
   [Anonymous], R92 UC IRV ICS
   [Anonymous], P 10 INT C UNC ART I
   [Anonymous], 2005, WACV MOTION
   Arashloo SR, 2014, IEEE T MULTIMEDIA, V16, P2099, DOI 10.1109/TMM.2014.2362855
   Bar-Joseph Z, 2001, IEEE T VIS COMPUT GR, V7, P120, DOI 10.1109/2945.928165
   Bouthemy P, 1998, INT C PATT RECOG, P905, DOI 10.1109/ICPR.1998.711298
   Chan A. B., 2007, IEEE C COMPUTER VISI, P1
   Chan AB, 2005, PROC CVPR IEEE, P846
   Chetverikov D, 2005, ADV SOFT COMP, P17
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Cover T. M., 1991, ELEMENTS INFORM THEO
   Cowell R. G., 1999, Probabilistic Networks and Expert Systems, V543
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Derpanis KG, 2012, IEEE T PATTERN ANAL, V34, P1193, DOI 10.1109/TPAMI.2011.221
   Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132
   Fitzgibbon AW, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P662, DOI 10.1109/ICCV.2001.937584
   Ghanem B., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P987, DOI 10.1109/ICPR.2010.247
   Ghanem B., 2010, LECT NOTES COMPUT SC, P223
   Kingsbury N, 2001, APPL COMPUT HARMON A, V10, P234, DOI 10.1006/acha.2000.0343
   Kingsbury N, 1999, PHILOS T R SOC A, V357, P2543, DOI 10.1098/rsta.1999.0447
   Kingsbury N., 1998, P 9 EUR SIGN PROC C, P1
   Koleini M, 2014, PATTERN RECOGN LETT, V45, P217, DOI 10.1016/j.patrec.2014.04.009
   Kung T., 1988, NATURAL COMPUTATION, P224
   LAURITZEN SL, 1992, J AM STAT ASSOC, V87, P1098, DOI 10.2307/2290647
   LAWTON W, 1993, IEEE T SIGNAL PROCES, V41, P3566, DOI 10.1109/78.258098
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mallat S.A., 1999, WAVELET TOUR SIGNAL
   Mumtaz A, 2013, IEEE T PATTERN ANAL, V35, P1606, DOI 10.1109/TPAMI.2012.236
   Murphy Kevin Patrick, 2002, Dynamic bayesian networks: representation, inference and learning
   NELSON RC, 1992, CVGIP-IMAG UNDERSTAN, V56, P78, DOI 10.1016/1049-9660(92)90087-J
   Ravichandran A, 2009, PROC CVPR IEEE, P1651, DOI 10.1109/CVPRW.2009.5206847
   Saisan P, 2001, PROC CVPR IEEE, P58
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Szummer M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P823, DOI 10.1109/ICIP.1996.560871
   Wang YZ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P213, DOI 10.1109/ICCV.2003.1238343
   Woolfe F, 2006, LECT NOTES COMPUT SC, V3952, P549
   Xu Y, 2011, IEEE I CONF COMP VIS, P1219, DOI 10.1109/ICCV.2011.6126372
   Yu-long Qiao, 2011, Proceedings of the 2011 First International Conference on Instrumentation, Measurement, Computer, Communication and Control (IMCCC 2011), P823, DOI 10.1109/IMCCC.2011.209
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao GY, 2012, IEEE T IMAGE PROCESS, V21, P1465, DOI 10.1109/TIP.2011.2175739
NR 51
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15251
EP 15278
DI 10.1007/s11042-016-3793-4
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900003
DA 2024-07-18
ER

PT J
AU Medjram, S
   Babahenini, MC
   Taleb-Ahmed, A
   Ben Ali, YM
AF Medjram, Sofiane
   Babahenini, Mohamed Chaouki
   Taleb-Ahmed, Abdelmalik
   Ben Ali, Yamina Mohamed
TI Real-time wrist localization in color images based on corner analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin detection; Wrist localization; Hand detection; Corner detection;
   Local minimum; Human-computer interaction
ID HAND DETECTION
AB Hand detection and gestures recognition have become very popular in recent human-computer interaction systems. Although several methods of hand detection have been proposed in the literature, they exist few methods that use the wrist as a factor of detection, others impose constraints on the length of the sleeves and on the orientation of the hand. In this work, we present a new two-stage algorithm of wrist localization designed for hand detection and gestures recognition systems. The first stage of the algorithm consists in separating the skin region containing the hand from the background, and in the second stage, the wrist is localized from the resulted skin mask. The main contribution of the proposed method is based on the analysis of corners along the contour of the skin masks to localize the wrist emplacement. Based on an evaluation on 437 color images with their ground-truth and three sets of skin masks, we compared our method with other efficient methods of literature and the results obtained were very satisfactory.
C1 [Medjram, Sofiane; Ben Ali, Yamina Mohamed] Univ Badji Mokhtar, LRI, Dept Comp Sci, BP 12, Annaba 23000, Algeria.
   [Babahenini, Mohamed Chaouki] Univ Mohamed Khider, Dept Comp Sci, LESIA, BP 145, Biskra 07000, Algeria.
   [Taleb-Ahmed, Abdelmalik] Univ Valenciennes & Hainaut Cambresis, LAMIH UMR CNRS 8201, Valenciennes, France.
C3 Universite Badji Mokhtar - Annaba; Universite Mohamed Khider Biskra;
   Centre National de la Recherche Scientifique (CNRS); Universite
   Polytechnique Hauts-de-France
RP Medjram, S (corresponding author), Univ Badji Mokhtar, LRI, Dept Comp Sci, BP 12, Annaba 23000, Algeria.
EM medjram.sofiane@gmail.com; babahenini@yahoo.com;
   Abdelmalik.Taleb-Ahmed@univ-valenciennes.fr; benaliyam2@yahoo.fr
RI BABAHENINI, Mohamed Chaouki/F-1427-2017; Ali, Yamina Mohamed
   Ben/O-3612-2016
OI BABAHENINI, Mohamed Chaouki/0000-0001-7972-8026; Ali, Yamina Mohamed
   Ben/0000-0002-5001-4799
CR [Anonymous], INT J TECHNOL
   [Anonymous], HANDAWI PUBL CORP SC
   [Anonymous], MAN MACH INTERACT
   [Anonymous], 2013, INT J RECENT TECHNOL
   [Anonymous], SIGN PROC C IEEE 13
   [Anonymous], P 7 INT C UB INF MAN
   [Anonymous], 2016, INT J SCI TECHNOL RE
   Cerlinca TL, 2011, STUD COMPUT INTELL, V382, P259
   Chen J, 2011, COMM COM INF SC, V134, P668
   Choi J., 2009, Proceedings of the 8th International Conference on Virtual Reality Continuum and Its Applications in Industry. VRCAI'09, P319
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Gang-Zeng Mao, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P905, DOI 10.1109/IIH-MSP.2009.133
   Grzejszczak T, 2016, MULTIMED TOOLS APPL, V75, P16363, DOI 10.1007/s11042-015-2934-5
   Grzejszczak T, 2013, ADV INTELL SYST, V226, P439, DOI 10.1007/978-3-319-00969-8_43
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Kakumanu P, 2007, PATTERN RECOGN, V40, P1106, DOI 10.1016/j.patcog.2006.06.010
   Kawulok M, 2013, IEEE INT CONF AUTOMA, DOI 10.1109/FG.2013.6553733
   Kawulok M, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-170
   Kerdvibulvech C, 2014, EURASIP J EMBED SYST, DOI 10.1186/s13639-014-0018-7
   Licsár A, 2004, LECT NOTES COMPUT SC, V3058, P83
   Medjram S, 2016, LECT NOTE NETW SYST, P153, DOI 10.1007/978-3-319-33410-3_11
   Mittal A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.75
   Nguyen T., 2008, IEEE International Conference on Automatic Face and Gesture Recognition, P1, DOI DOI 10.1109/AFGR.2008.4813315
   Patel TP, 2014, INT J ENG DEV RES, V2, P3680
   Paulson B, 2011, INT J HUM-COMPUT ST, V69, P19, DOI 10.1016/j.ijhcs.2010.09.003
   Qiu-yu Z., 2015, International Journal of Signal Processing, Image Processing and Pattern Recognition, V8, P105, DOI DOI 10.14257/IJSIP.2015.8.5.11
   Shipeng Xie, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P553, DOI 10.1109/ICIG.2011.166
   Song Z, 2010, LECT NOTES COMPUT SC, V6454, P628, DOI 10.1007/978-3-642-17274-8_61
   Stergiopoulou E, 2009, ENG APPL ARTIF INTEL, V22, P1141, DOI 10.1016/j.engappai.2009.03.008
   Toni B., 2012, 2012 35th International Convention on Information and Communication Technology, Electronics and Microelectronics, P1768
   Trigueiros P, 2014, ADV INTELL SYST, V275, P605, DOI 10.1007/978-3-319-05951-8_57
   Vidya K, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P705, DOI 10.1109/IndiaCom.2014.6828052
   Wang RY, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531369
   Xiao B, 2010, LECT NOTES ARTIF INT, V6441, P282, DOI 10.1007/978-3-642-17313-4_28
   Yeo HS, 2015, MULTIMED TOOLS APPL, V74, P2687, DOI 10.1007/s11042-013-1501-1
   Yogarajah P, 2010, IEEE IMAGE PROC, P2225, DOI 10.1109/ICIP.2010.5652798
   Zhao XY, 2015, J NANOMATER, V2015, DOI 10.1155/2015/104193
NR 37
TC 4
Z9 4
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15297
EP 15324
DI 10.1007/s11042-016-3820-5
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900005
DA 2024-07-18
ER

PT J
AU Du, SL
   Yan, YP
   Ma, YD
AF Du, Songlin
   Yan, Yaping
   Ma, Yide
TI LAP: a bio-inspired local image structure descriptor and its
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual anisotropy; Local anisotropic pattern; Rotation invariance;
   Texture classification; No-reference image quality assessment
ID QUALITY ASSESSMENT; ORIENTATION ANISOTROPIES; TEXTURE CLASSIFICATION;
   PATTERN; REPRESENTATION; SELECTIVITY; BRAIN
AB Local structural information is crucially important for human visual system to perceive natural scenes. Recent years, a variety of local image structure description methods have been proposed for the artificial modeling of visual perception. Although existing local image structure descriptors have shown successful performances, one general limitation is their numerical instability caused by ignoring the information of the spatial correlation of local orientation. In this paper, we propose a local image structure descriptor by modeling the anisotropic mechanism in the primary visual cortex. In particular, the pixel-wise anisotropy values of a given image are calculated by pseudo-Wigner-Ville distribution (PWVD) and R,nyi entropy. Then the excitatory/inhibitory interactions among visual neurons in the local receptive field are modeled by measuring the similarities between their anisotropies. By mapping visual neurons to image pixels, the correlation between a central pixel and its local neighbors can be represented by a binary pattern which is named as local anisotropic pattern (LAP). Experimental results on texture classification verified that the proposed LAP has satisfactory texture classification accuracy, rotation invariance, and noise robustness; experimental results on no-reference image quality assessment demonstrated that the proposed LAP achieves state-of-the-art performance in objective evaluation of the perceptual quality of natural image, and this reflects that LAP can accurately represent the degradation of local image structure.
C1 [Du, Songlin; Yan, Yaping; Ma, Yide] Lanzhou Univ, Sch Informat Sci & Engn, Lanzhou 730000, Peoples R China.
C3 Lanzhou University
RP Du, SL (corresponding author), Lanzhou Univ, Sch Informat Sci & Engn, Lanzhou 730000, Peoples R China.
EM dusonny@gmail.com; ypylzu@gmail.com; ydma@lzu.edu.cn
FU National Natural Science Foundation of China (NSFC) [61175012];
   Fundamental Research Funds for the Central Universities of China
   [lzujbky-2015-196]
FX The authors would like to thank the editor and the anonymous reviewers
   for their valuable comments and suggestions to improve the quality of
   the paper. They would also like to thank the members at the Institute of
   Circuits and Systems, School of Information Science and Engineering,
   Lanzhou University, for valuable discussions. This work was supported by
   the National Natural Science Foundation of China (NSFC) under Grant
   61175012 and the Fundamental Research Funds for the Central Universities
   of China under Grant lzujbky-2015-196.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2006, MODERN IMAGE QUALITY
   [Anonymous], KERNEL METHODS REMOT
   BERRY JR, 1991, IEEE T SYST MAN CYB, V21, P252, DOI 10.1109/21.101156
   CAMPBELL FW, 1966, J PHYSIOL-LONDON, V187, P437, DOI 10.1113/jphysiol.1966.sp008101
   Chang C.C., LIBSVM: a library for support vector machines
   Crist'obal G., 2011, OPTICAL DIGITAL IMAG
   Fan KC, 2014, IEEE T IMAGE PROCESS, V23, P2877, DOI 10.1109/TIP.2014.2321495
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787
   Furmanski CS, 2000, NAT NEUROSCI, V3, P535, DOI 10.1038/75702
   Gabarda S, 2007, J OPT SOC AM A, V24, pB42, DOI 10.1364/JOSAA.24.000B42
   Gerrow K, 2010, CURR OPIN NEUROBIOL, V20, P631, DOI 10.1016/j.conb.2010.06.010
   Ghosh K, 2009, BIOL CYBERN, V100, P351, DOI 10.1007/s00422-009-0306-9
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Hafiane A, 2015, PATTERN RECOGN, V48, P2609, DOI 10.1016/j.patcog.2015.02.007
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Kirsanova EN, 2002, OPEN SYST INF DYN, V9, P239, DOI 10.1023/A:1019704411382
   Knill DC, 2004, TRENDS NEUROSCI, V27, P712, DOI 10.1016/j.tins.2004.10.007
   Kodituwakku S, 2010, IEEE T SIGNAL PROCES, V58, P3395, DOI 10.1109/TSP.2010.2044252
   Kong H, 2013, IEEE T INTELL TRANSP, V14, P408, DOI 10.1109/TITS.2012.2216878
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Lebrun M, 2015, IEEE T IMAGE PROCESS, V24, P3149, DOI 10.1109/TIP.2015.2439041
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P494, DOI 10.1016/j.image.2014.02.004
   Lorenzi L, 2013, IEEE GEOSCI REMOTE S, V10, P367, DOI 10.1109/LGRS.2012.2206070
   Ma L, 2015, IEEE T GEOSCI REMOTE, V53, P2832, DOI 10.1109/TGRS.2014.2365676
   Ma L, 2010, IEEE T GEOSCI REMOTE, V48, P4099, DOI 10.1109/TGRS.2010.2055876
   Maloney RT, 2015, NEUROIMAGE, V119, P129, DOI 10.1016/j.neuroimage.2015.06.034
   Mangasarian OL, 2000, IEEE T PATTERN ANAL, V22, P950, DOI 10.1109/34.877518
   Mannion DJ, 2010, J NEUROPHYSIOL, V103, P3465, DOI 10.1152/jn.00190.2010
   Michmizos D, 2011, INT J NEUROSCI, V121, P289, DOI 10.3109/00207454.2011.556283
   Mishra A, 2011, IEEE IMAGE PROC
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Mouats T, 2015, IEEE T IMAGE PROCESS, V24, P2685, DOI 10.1109/TIP.2015.2426014
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pan ZB, 2015, IEEE T IMAGE PROCESS, V24, P5379, DOI 10.1109/TIP.2015.2476955
   Park SH, 2013, J NEUROSCI, V33, P1143, DOI 10.1523/JNEUROSCI.2404-12.2013
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Rahtu E, 2012, IMAGE VISION COMPUT, V30, P501, DOI 10.1016/j.imavis.2012.04.001
   Renyi A., 1961, P 4 BERK S MATH STAT, V1, P547
   Ryu J, 2015, IEEE T IMAGE PROCESS, V24, P2254, DOI 10.1109/TIP.2015.2419081
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Sheikh H.R., Live Image Quality Assessment Database
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Swisher JD, 2010, J NEUROSCI, V30, P325, DOI 10.1523/JNEUROSCI.4811-09.2010
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Vipparthi SK, 2015, NEUROCOMPUTING, V167, P336, DOI 10.1016/j.neucom.2015.04.062
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wu JJ, 2015, IEEE T IMAGE PROCESS, V24, P4602, DOI 10.1109/TIP.2015.2460467
   Wu JJ, 2014, IEEE SIGNAL PROC LET, V21, P437, DOI 10.1109/LSP.2014.2304714
   Xu YN, 2010, OPT LETT, V35, P475, DOI 10.1364/OL.35.000475
   Yamada K, 2015, NEUROIMAGE, V113, P289, DOI 10.1016/j.neuroimage.2015.03.059
   Yang B, 2013, NEUROCOMPUTING, V120, P365, DOI 10.1016/j.neucom.2012.10.032
   Yeffet L, 2009, IEEE I CONF COMP VIS, P492, DOI 10.1109/ICCV.2009.5459201
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang M, 2015, IEEE SIGNAL PROC LET, V22, P207, DOI 10.1109/LSP.2014.2326399
   Zhang Y, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.043025
   Zhang ZC, 2015, SIGNAL PROCESS, V114, P45, DOI 10.1016/j.sigpro.2015.02.016
NR 64
TC 4
Z9 4
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 13973
EP 13993
DI 10.1007/s11042-016-3779-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800014
DA 2024-07-18
ER

PT J
AU Huang, TQ
   Yi, BS
   Yao, WQ
   Li, WZ
AF Huang, Tai-qi
   Yi, Ben-shun
   Yao, Wei-qing
   Li, Wei-zhong
TI Unequal error protection scheme for image transmission based on
   regularized variable-node and expanding window fountain codes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image transmission; LT codes; AWGN; Unequal error protection;
   Regularized variable-node
ID DESIGN
AB A transmission scheme based on rateless codes is proposed for image delivery over additive white Gaussian noise (AWGN) channels. Unequal Error Protection (UEP) characteristics are also introduced to provide prioritized delivery for different layers in content-based image. Firstly, layer segmentation processing based on an improved guided filtering is introduced to decompose the source image into the base layer and detail layer. Then, a windowing technique is applied to produce a bias towards certain classes of layers according to their various protection requirements. Variable-node degree distribution is also exploited to provide enhanced UEP and improve the high error floor suffered by some conventional UEP schemes. Compared with the conventional image transmission schemes based on rateless codes with UEP, the additional parameters introduced by the proposed scheme make it more general and flexible for individual applications. Furthermore, the proposed approach can provide better UEP performance and improve the network image transmission quality, which are confirmed both theoretically and experimentally.
C1 [Huang, Tai-qi; Yi, Ben-shun; Yao, Wei-qing; Li, Wei-zhong] Wuhan Univ, Sch Elect Informat, Wuhan 430072, Hubei, Peoples R China.
   [Huang, Tai-qi; Yi, Ben-shun; Yao, Wei-qing; Li, Wei-zhong] Collaborat Innovat Ctr Geospatial Technol, Wuhan 430072, Hubei, Peoples R China.
C3 Wuhan University
RP Huang, TQ; Yi, BS (corresponding author), Wuhan Univ, Sch Elect Informat, Wuhan 430072, Hubei, Peoples R China.; Huang, TQ; Yi, BS (corresponding author), Collaborat Innovat Ctr Geospatial Technol, Wuhan 430072, Hubei, Peoples R China.
EM htq@whu.edu.cn; yibs@whu.edu.cn
FU National Natural Science Foundation of China [61371125]; NSFC
FX This paper was supported by National Natural Science Foundation of China
   under Grant 61371125. The authors would like to thank NSFC for funding
   this research.
CR Anglano C, 2015, IEEE T PARALL DISTR, V26, P1313, DOI 10.1109/TPDS.2014.2321745
   [Anonymous], AN S FDN CO
   Blatsas M, 2013, THE 18TH INTERNATION, V1, P1
   Bursalioglu OY, 2013, IEEE T COMMUN, V61, P3448, DOI 10.1109/TCOMM.2013.061913.120747
   Guo L, 2013, J ELECT INF TECHNOL, V35, P2554
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hussain I, 2013, PLANT BIOSYST, P1
   Hussain I, 2012, P IEEE COMM TECHN WO, P24
   Hussain I, 2011, GLOB TELECOMM CONF
   Hussain I, 2011, 2011 IEEE WIRELESS COMMUNICATIONS AND NETWORKING CONFERENCE (WCNC), P1811, DOI 10.1109/WCNC.2011.5779408
   Mahyar S, 2014, P IEEE INT C COMM IC, P2033
   Rahnavard N, 2007, IEEE T INFORM THEORY, V53, P1521, DOI 10.1109/TIT.2007.892814
   Sajid N, 2015, MULTIMED TOOLS APPL, V74, P5787
   Sejdinovic D, 2009, IEEE T COMMUN, V57, P2510, DOI 10.1109/TCOMM.2009.09.070616
   Shokrollahi A, 2006, IEEE T INFORM THEORY, V52, P2551, DOI 10.1109/TIT.2006.874390
   Sorensen JH, 2014, IEEE T COMMUN, V62, P434, DOI 10.1109/TCOMM.2013.122013.130116
   Sorensen JH, 2013, IEEE COMMUN LETT, V17, P1636, DOI 10.1109/LCOMM.2013.070913.130657
   Suh Y, 2015, IEEE T COMMUN, V63, P3057, DOI 10.1109/TCOMM.2015.2428244
   Tai-qi H, 2015, J ELECT INF TECHNOL, V37, P1931
   Tu K, 2013, 2013 IEEE 24TH INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE RADIO COMMUNICATIONS (PIMRC), P342, DOI 10.1109/PIMRC.2013.6666158
NR 20
TC 0
Z9 0
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13383
EP 13400
DI 10.1007/s11042-016-3745-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900021
DA 2024-07-18
ER

PT J
AU Jung, KH
AF Jung, Ki-Hyun
TI A high-capacity reversible data hiding scheme based on sorting and
   prediction in digital images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information hiding; Reversible data hiding; Steganography; Sorting;
   Prediction
ID HISTOGRAM-MODIFICATION; DIFFERENCE EXPANSION
AB In this paper, a new reversible data hiding method based on sorting and prediction in digital images is proposed. The proposed method can embed two bits in the 3 x 1 sub-block at maximum by dividing into two groups - min and max groups. The pixel pairs of the min group and max group are firstly predicted and then are modified to embed the secret bits. The reversibility is guaranteed since the order of pixel pairs of the sub-block is not changed after embedding a secret bit into two groups. The experimental results show that the proposed method provides high embedding capacity than the previous works.
C1 [Jung, Ki-Hyun] Kyungil Univ, Dept Cyber Secur, 50 Gamasil Gil, Gyongsan 712701, Gyeongbuk, South Korea.
C3 Kyungil University
RP Jung, KH (corresponding author), Kyungil Univ, Dept Cyber Secur, 50 Gamasil Gil, Gyongsan 712701, Gyeongbuk, South Korea.
EM khanny.jung@gmail.com
FU Basic Science Research Program through the National Research Foundation
   of Korea(NRF) - Ministry of Education [2015R1D1A1A01058019]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Education(No.2015R1D1A1A01058019).
CR Al-Qershi OM, 2013, SIGNAL PROCESS, V93, P154, DOI 10.1016/j.sigpro.2012.07.012
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], J INF HIDING MULTIME
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Gui XL, 2014, SIGNAL PROCESS, V98, P370, DOI 10.1016/j.sigpro.2013.12.005
   Hsiao JY, 2009, SIGNAL PROCESS, V89, P556, DOI 10.1016/j.sigpro.2008.10.018
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Huang HC, 2013, EXPERT SYST APPL, V40, P34, DOI 10.1016/j.eswa.2012.07.010
   Huang HC, 2011, SENSORS-BASEL, V11, P9717, DOI 10.3390/s111009717
   Huang LC, 2013, J SYST SOFTWARE, V86, P716, DOI 10.1016/j.jss.2012.11.024
   Lee CF, 2012, DIGIT SIGNAL PROCESS, V22, P941, DOI 10.1016/j.dsp.2012.05.015
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Lou DC, 2009, COMPUT STAND INTER, V31, P329, DOI 10.1016/j.csi.2008.05.009
   Luo H, 2011, INFORM SCIENCES, V181, P308, DOI 10.1016/j.ins.2010.09.022
   Marin J., 2014, J INFORM HIDING MULT, V5, P451
   Ni ZC, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P912
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai YY, 2013, DIGIT SIGNAL PROCESS, V23, P919, DOI 10.1016/j.dsp.2012.12.014
   Zhao ZF, 2011, AEU-INT J ELECTRON C, V65, P814, DOI 10.1016/j.aeue.2011.01.014
NR 25
TC 26
Z9 26
U1 1
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13127
EP 13137
DI 10.1007/s11042-016-3739-x
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900008
DA 2024-07-18
ER

PT J
AU Zhang, XB
AF Zhang, Xiaobo
TI A denoising approach via wavelet domain diffusion and image domain
   diffusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Wiener filter; Non-subsampled shearlet transform
   (NSST); Anisotropic diffusion
ID ANISOTROPIC DIFFUSION; WIENER FILTER; SHRINKAGE
AB This paper presents a new image denoising algorithm based on wavelet transform and nonlinear diffusion. Although the wavelet domain diffusion methods are very effective in image denoising, the salient artifacts are still produced. On the other hand, the image domain diffusion methods output the denoised image with fewer artifacts. So, unlike the previous denoising methods employing wavelet transform and diffusion scheme, the proposed method implements the diffusion not only in the wavelet domain but also in the image domain. The new method is called image denoising method combining the wavelet domain diffusion and the image domain diffusion (WDD-IDD). In the process of denoising, the initial denoised image is obtained by carrying out the wavelet domain isotropic diffusion. And then, the final denoised image is produced by applying the image domain anisotropic diffusion on the initial denoised image. It is noted that the image domain anisotropic diffusion scheme is constructed based on the feature of initial denoised image. In addition, to exemplify the power of the proposed method, the processing is restricted to the non-subsampled shearlet transform (NSST) domain which can better capture the geometry features of image than other wavelet transform. The tests show that the proposed WDD-IDD produces a better result in term of peak signal-to-noise ratio (PSNR), structural similarity (SSIM), and visual effect compared to the related methods.
C1 [Zhang, Xiaobo] Xianyang Normal Univ, Inst Graph & Image Proc, Xianyang 712000, Peoples R China.
C3 Xianyang Normal University
RP Zhang, XB (corresponding author), Xianyang Normal Univ, Inst Graph & Image Proc, Xianyang 712000, Peoples R China.
EM zhangxiaobo419@126.com
OI Zhang, Xiaobo/0000-0001-6018-4655
FU National Natural Science Foundation of China [61401383]; Natural Science
   Foundation of Xianyang Normal University [14XSYK006]; Qinglan Talent
   Program of Xianyang Normal University [XSYQL201503]
FX This work is partially supported by National Natural Science Foundation
   of China (Grant No. 61401383) and Natural Science Foundation of Xianyang
   Normal University (Grant No. 14XSYK006) and Qinglan Talent Program of
   Xianyang Normal University (Grant No. XSYQL201503).
CR Blu T, 2007, IEEE T IMAGE PROCESS, V16, P2778, DOI 10.1109/TIP.2007.906002
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633
   Chen GY, 2005, PATTERN RECOGN, V38, P115, DOI 10.1016/j.patcog.2004.05.009
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Donoho DL, 1995, J AM STAT ASSOC, V90, P1200, DOI 10.1080/01621459.1995.10476626
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Geng P, 2016, J INF HIDING MULTIME, V7, P175
   Guo F., 2015, J INF HIDING MULTIME, V6, P987
   Huang H. C., 2015, J INF HIDING MULTIME, V6, P847
   Liu QH, 2015, OPTIK, V126, P967, DOI 10.1016/j.ijleo.2015.01.023
   Mandava AK, 2011, J ELECTRON IMAGING, V20
   Mihçak MK, 1999, IEEE SIGNAL PROC LET, V6, P300, DOI 10.1109/97.803428
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Pizurica A, 2006, IEEE T IMAGE PROCESS, V15, P654, DOI 10.1109/TIP.2005.863698
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Scharr Hanno., 2000, Pattern Recognition, Proceedings of the 22nd DAGM-Symposium, P460
   Sendur L, 2002, IEEE SIGNAL PROC LET, V9, P438, DOI 10.1109/LSP.2002.806054
   Tao DP, 2016, IEEE T CYBERNETICS, V46, P756, DOI 10.1109/TCYB.2015.2414920
   Tao DP, 2013, IEEE T CIRC SYST VID, V23, P1675, DOI 10.1109/TCSVT.2013.2255413
   Wang XY, 2015, MULTIMED TOOLS APPL, V74, P11703, DOI 10.1007/s11042-014-2258-x
   Wang Y, 2016, IEEE T CIRC IN PRESS
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2016, J INF HIDING MULTIME, V7, P72
   Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1
   Zhang XB, 2014, J VIS COMMUN IMAGE R, V25, P254, DOI 10.1016/j.jvcir.2013.11.006
   Zhang XB, 2013, COMPUT ELECTR ENG, V39, P934, DOI 10.1016/j.compeleceng.2012.07.013
   Zhong JM, 2008, IEEE T CIRCUITS-I, V55, P2716, DOI 10.1109/TCSI.2008.920061
NR 27
TC 1
Z9 1
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13545
EP 13561
DI 10.1007/s11042-016-3778-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900028
DA 2024-07-18
ER

PT J
AU Liu, L
   Chang, CC
   Wang, AH
AF Liu, Li
   Chang, Chin-Chen
   Wang, Anhong
TI Data hiding based on extended turtle shell matrix construction method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Turtle shell matrix; Pixel pair; N-ary notational system
ID STEGANOGRAPHIC METHOD; IMAGES
AB Data hiding research has focused mainly on determining how to embed secret data into various public host media, and to also ensure the host medium is not changed to a degree such that it can be perceived by the human eye. In 2014, Chang et al. proposed a novel concept, named the turtle shell matrix, to embed secret data. This scheme has obvious advantages with respect to its hiding capacity and image quality. However, its disadvantage is lack of flexibility due to the fixed turtle shell matrix structure. In this paper, we extend this turtle shell matrix structure into a different matrix model to meet different hiding capacity and image quality needs. Meanwhile, a general extraction function is derived to generate a matrix having a different turtle shell model. The values of the pixel pairs in the cover image are modified according to guidance provided by the turtle shell to hide a secret digit in an N-ary notational system. The experimental results show that the proposed scheme not only has better flexibility in balancing the trade-off between hiding capacity and stego-image quality, but also provides higher hiding capacity and stego-images with better visual quality than previous schemes.
C1 [Liu, Li] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.
   [Liu, Li; Wang, Anhong] Taiyuan Univ Sci & Technol, Coll Elect Informat & Engn, Taiyuan 030024, Peoples R China.
   [Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
C3 Northwestern Polytechnical University; Taiyuan University of Science &
   Technology; Feng Chia University
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
EM alan3c@gmail.com
RI Chang, Ching-Chun/JAN-6210-2023
FU National Natural Science Foundation of China [61540009, 61272262]
FX This work was supported in part by The National Natural Science
   Foundation of China (No. 61540009, No. 61272262).
CR Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang C.-C., 2008, 2008 3 INT C INN COM, P17, DOI 10.1109/ICICIC.2008.149
   Chang CC, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P89, DOI 10.1109/IIH-MSP.2014.29
   Fridrich J., 2001, P ACM WORKSH MULT SE, P27
   Hajizadeh H, 2013, IEEE AFRICON 2013, P1, DOI DOI 10.1109/AFRCON.2013.6757647
   Joo J.-C., 2010, EURASIP J ADV SIG PR, V2010, P26
   Kaur Blossom., 2011, International Journal of Advances in Engineering Technology, V1, P72
   Kim HJ, 2010, COMPUT MATH APPL, V60, P319, DOI 10.1016/j.camwa.2010.01.006
   Lee CF, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P497
   Lee CF, 2010, J SYST SOFTWARE, V83, P832, DOI 10.1016/j.jss.2009.12.018
   Lin C.-C., 2010, J. Inf. Hiding Multimed. Signal Process, V1, P220
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Makbol NM, 2013, AEU-INT J ELECTRON C, V67, P102, DOI 10.1016/j.aeue.2012.06.008
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Panigrahi BK, 2014, INT J INNOV RES DEV, V3
   Sharma Vijay Kumar, 2012, Journal of Theoretical and Applied Information Technology, V36, P1
   Shen SY, 2015, COMPUT SECUR, V48, P131, DOI 10.1016/j.cose.2014.07.008
   Kieu TD, 2011, EXPERT SYST APPL, V38, P10648, DOI 10.1016/j.eswa.2011.02.122
   Thien CC, 2003, PATTERN RECOGN, V36, P2875, DOI 10.1016/S0031-3203(03)00221-8
   Wang CM, 2008, J SYST SOFTWARE, V81, P150, DOI 10.1016/j.jss.2007.01.049
   Wang JJ, 2010, SIGNAL PROCESS, V90, P2954, DOI 10.1016/j.sigpro.2010.04.022
   Wang SJ, 2005, APPL MATH COMPUT, V164, P99, DOI 10.1016/j.amc.2004.04.059
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Yang CH, 2008, IEEE T INF FOREN SEC, V3, P488, DOI 10.1109/TIFS.2008.926097
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   Zhang XP, 2004, PATTERN RECOGN LETT, V25, P331, DOI 10.1016/j.patrec.2003.10.014
NR 26
TC 31
Z9 31
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12233
EP 12250
DI 10.1007/s11042-016-3624-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200004
DA 2024-07-18
ER

PT J
AU Xiao, J
   Liu, Z
   Yang, H
   Hu, XG
AF Xiao, Jin
   Liu, Zhou
   Yang, Heng
   Hu, Xiaoguang
TI The invariant features-based target tracking across multiple cameras
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video surveillance; Multiple cameras; Invariant feature; Across lenses
   Tracking; Feature pool
ID OBJECTS; TIME
AB Target tracking across lenses is a popular research topic for video surveillance recently. This paper presents a method of target tracking across lenses with overlap regions. First, the target detection and tracking are completed with a single camera. Second, in order to obtain the location-invariant feature of the same target in the images with various cameras, the camera calibration is completed based on a three-dimension (3D) model. After that, for all images via multiple cameras, the coordinates of the 3D model are unified. Finally, referring to the assumption of spatial and temporal consistency of the target location across multiple cameras, the association among detected objects for the same target with different cameras is established. And a feature pool is built which contains perspective and scale features. Thus the same target is continuously tracked across multiple lenses. At last, the performance of the proposed approach is compared with KSP and PABC and demonstrated with indoor and outdoor experiments.
C1 [Xiao, Jin; Hu, Xiaoguang] Beihang Univ, Sch Automat Sci & Elect Engn, State Key Lab Virtual Real Technol & Syst, 37 Xueyuan Rd, Beijing, Peoples R China.
   [Liu, Zhou; Yang, Heng] BeiJing Innovisgroup Co, Beijing, Peoples R China.
C3 Beihang University
RP Xiao, J (corresponding author), Beihang Univ, Sch Automat Sci & Elect Engn, State Key Lab Virtual Real Technol & Syst, 37 Xueyuan Rd, Beijing, Peoples R China.
EM xiaojin_ck@126.com
OI xiao, jin/0000-0003-2462-4996
FU Beijing Nova Program [Z131101000413083]; Beijing Talents Fund
   [2014000021223ZK41]; Aeronautic Science Foundation of China
   [2015ZC51032]
FX This work has been sponsored, in part, by Beijing Nova Program
   (Z131101000413083), Beijing Talents Fund (2014000021223ZK41) and
   Aeronautic Science Foundation of China (2015ZC51032). All supports are
   gratefully acknowledged.
CR Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21
   Black J, 2001, P PERF EV TRACK SURV
   Bouchrika I, 2016, MULTIMED TOOLS APPL, V75, P1201, DOI 10.1007/s11042-014-2364-9
   Calderara S, 2005, 13 INT C IM AN PROC
   Calderara S, 2008, IEEE T PATTERN ANAL, V30, P354, DOI 10.1109/TPAMI.2007.70814
   Chen CH, 2010, IMAGE VISION COMPUT, V28, P851, DOI 10.1016/j.imavis.2009.10.013
   Chen XT, 2014, PATTERN RECOGN, V47, P1126, DOI 10.1016/j.patcog.2013.06.011
   Cheng K.-W., 2008, Radar Conference, P1
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Finlayson GD, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P37
   Fleuret F, 2008, IEEE T PATTERN ANAL, V30, P267, DOI 10.1109/TPAMI.2007.1174
   FORSYTH DA, 1990, INT J COMPUT VISION, V5, P5, DOI 10.1007/BF00056770
   Gijsenij A, 2010, INT J COMPUT VISION, V86, P127, DOI 10.1007/s11263-008-0171-3
   Gilbert A, 2006, LECT NOTES COMPUT SC, V3952, P125
   Hu WM, 2006, IEEE T PATTERN ANAL, V28, P663, DOI 10.1109/TPAMI.2006.80
   Javed O, 2005, PROC CVPR IEEE, P26
   Javed O, 2008, COMPUT VIS IMAGE UND, V109, P146, DOI 10.1016/j.cviu.2007.01.003
   Jeong K, 2008, MACH VISION APPL, V19, P443, DOI 10.1007/s00138-007-0079-x
   Kang J, 2003, IEEE INT C COMP VIS
   Kelly P, 1995, P ACM MULT 95 MAY, P95
   Khan S, 2003, IEEE T PATTERN ANAL, V25, P1355, DOI 10.1109/TPAMI.2003.1233912
   Lee L, 2000, IEEE T PATTERN ANAL, V22, P758, DOI 10.1109/34.868678
   Lian GY, 2011, PATTERN RECOGN, V44, P1121, DOI 10.1016/j.patcog.2010.11.011
   Nam Y, 2013, MULTIMED TOOLS APPL, V67, P289, DOI 10.1007/s11042-012-0997-0
   Prosser Bryan., 2008, BMVC
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
NR 26
TC 1
Z9 2
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12165
EP 12179
DI 10.1007/s11042-015-3067-6
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200001
DA 2024-07-18
ER

PT J
AU Guo, JM
   Liu, YF
   Lee, JD
   Tzeng, YQ
AF Guo, Jing-Ming
   Liu, Yun-Fu
   Lee, Jiann-Der
   Tzeng, Yu-Quan
TI Blind prediction-based wavelet watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Discrete wavelet transform; Human visual system;
   Just noticeable distortion; Least mean square
ID ROBUST IMAGE WATERMARKING
AB In recent years, wavelet transform has been widely applied in multimedia signal processing and digital watermarking is involved for ensuring security. This study presents a blind wavelet-based watermarking incorporated with the Human Visual System (HVS), which embeds watermarks into detail-subband coefficients. Since imperceptibility is the most significant issue in watermarking, the approximation band is maintained constant, while the detail subbands are modified to carry information. The perceptual embedded weights for all subbands are determined according to the Just Noticeable Distortion (JND) criterion. The strength of the modification is investigated to provide a balanced result between robustness and image quality. In the decoder, the Least-Mean-Square (LMS) is employed to predict the original detail-subband coefficients and then extract the embedded watermarks. As documented in the experimental results, the proposed method provides good robustness and excellent image quality.
C1 [Guo, Jing-Ming; Liu, Yun-Fu] Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan.
   [Lee, Jiann-Der; Tzeng, Yu-Quan] Chang Gung Univ, Dept Elect Engn, Taoyuan, Taiwan.
C3 National Taiwan University of Science & Technology; Chang Gung
   University
RP Lee, JD (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan.
EM jdlee@mail.cgu.edu.tw
RI Lee, Jiann-Der/AAE-2442-2022; Liu, Yun-Fu/K-2506-2012
CR Al-Khassaweneh M, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1597, DOI 10.1109/ICME.2006.262851
   Bradley AP, 1999, IEEE T IMAGE PROCESS, V8, P717, DOI 10.1109/83.760338
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   De Vleeschouwer C, 2002, P IEEE, V90, P64, DOI 10.1109/5.982406
   Dugad R, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P419, DOI 10.1109/ICIP.1998.723406
   Guo JM, 2007, IEEE T MULTIMEDIA, V9, P687, DOI 10.1109/TMM.2007.895678
   Guo JM, 2012, IEEE T IMAGE PROCESS, V21, P4808, DOI 10.1109/TIP.2012.2210236
   Guo JM, 2009, SIGNAL PROCESS, V89, P1864, DOI 10.1016/j.sigpro.2009.03.013
   Hsu CT, 1999, IEEE T IMAGE PROCESS, V8, P58, DOI 10.1109/83.736686
   Huang HC, 2007, CIRC SYST SIGNAL PR, V26, P671, DOI 10.1007/s00034-006-0104-z
   Huang JW, 2000, IEEE T CIRC SYST VID, V10, P974, DOI 10.1109/76.867936
   Huo FF, 2006, IEEE IMAGE PROC, P2573, DOI 10.1109/ICIP.2006.312985
   Inoue H, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P391, DOI 10.1109/ICIP.1998.723388
   Khelifi F, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P588
   Li J, 2007, 6TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE, PROCEEDINGS, P207, DOI 10.1109/ICIS.2007.50
   Lu CS, 2000, IEEE T MULTIMEDIA, V2, P209, DOI 10.1109/6046.890056
   Lu CS, 2001, IEEE T IMAGE PROCESS, V10, P1579, DOI 10.1109/83.951542
   Nafornita C, 2005, EUROCON 2005: THE INTERNATIONAL CONFERENCE ON COMPUTER AS A TOOL, VOL 1 AND 2 , PROCEEDINGS, P943
   Nikolaidis N, 1998, SIGNAL PROCESS, V66, P385, DOI 10.1016/S0165-1684(98)00017-6
   Pan JS, 2004, ELECTRON LETT, V40, P1409, DOI 10.1049/el:20046454
   Podilchuk CI, 1998, IEEE J SEL AREA COMM, V16, P525, DOI 10.1109/49.668975
   Ratnakar V., 1999, Conference Record of the Thirty-Third Asilomar Conference on Signals, Systems, and Computers (Cat. No.CH37020), P1513, DOI 10.1109/ACSSC.1999.832002
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Solachidis V, 2001, IEEE T IMAGE PROCESS, V10, P1741, DOI 10.1109/83.967401
   Swanson MD, 1998, P IEEE, V86, P1064, DOI 10.1109/5.687830
   VANSCHYNDELL RG, 1994, IEEE IMAGE PROC, P86, DOI 10.1109/ICIP.1994.413536
   WANG S, 2015, J INFORM HIDING MULT, V6, P1264
   Wang ZF, 2006, WCICA 2006: SIXTH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-12, CONFERENCE PROCEEDINGS, P3024
   Watson AB, 1997, IEEE T IMAGE PROCESS, V6, P1164, DOI 10.1109/83.605413
   WIDROW B, 1976, P IEEE, V64, P1151, DOI 10.1109/PROC.1976.10286
   Widrow B., 1960, IRE WESCON Conv. Rec
   Yan B., 2015, J INFORM HIDING MULT, V6, P882
   Yen JC, 2006, SEVENTH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED COMPUTING, APPLICATIONS AND TECHNOLOGIES, PROCEEDINGS, P474
   Yeung MM, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P680, DOI 10.1109/ICIP.1997.638587
   Zhu WW, 1999, IEEE T CIRC SYST VID, V9, P545, DOI 10.1109/76.767121
NR 35
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9803
EP 9828
DI 10.1007/s11042-016-3580-2
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300031
DA 2024-07-18
ER

PT J
AU Muhammad, G
   Alhamid, MF
AF Muhammad, Ghulam
   Alhamid, Mohammed F.
TI User emotion recognition from a larger pool of social network data using
   active learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social networks; Cloud computing; Emotion recognition; Active learning;
   Extreme learning machine
ID CLASSIFICATION; FEATURES
AB The use of social networks has grown exponentially in recent years. The large amount of data available in these networks can be effectively utilized in many machine learning applications. This paper proposes a framework of an emotion recognition system that fetches huge amount of face images from the social networks into a cloud. In the cloud, the problem of the unlabeled facial images is handled by applying an active learning approach. For the feature extraction, an interlaced derivative pattern is used, while for a base classifier, an extreme learning machine is utilized. Once the emotion is recognized in the cloud, it can be shared with the end users to meet their interests. Several experiments were performed using some publicly available databases and heterogeneous images from the social networks. Experimental results showed that the proposed framework may effectively be used in the emotion recognition.
C1 [Muhammad, Ghulam] King Saud Univ, Dept Comp Engn, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
   [Alhamid, Mohammed F.] King Saud Univ, Dept Software Engn, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
C3 King Saud University; King Saud University
RP Muhammad, G (corresponding author), King Saud Univ, Dept Comp Engn, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
EM ghulam@ksu.edu.sa
RI Guizani, Mohsen/AAX-4534-2021; Muhammad, Ghulam/H-5884-2011
OI Guizani, Mohsen/0000-0002-8972-8094; Muhammad,
   Ghulam/0000-0002-9781-3969
FU Deanship of Scientific Research at King Saud University, Riyadh, Saudi
   Arabia [RGP-1436-023]
FX The authors extend their appreciation to the Deanship of Scientific
   Research at King Saud University, Riyadh, Saudi Arabia for funding this
   work through the research group project no. RGP-1436-023
CR [Anonymous], IEEE T MULTIMED
   Averbeck BB, 2012, PSYCHOL MED, V42, P259, DOI 10.1017/S0033291711001413
   Bettadapura V., 2012, FACE EXPRESSION RECO
   Domes G, 2014, NEUROPSYCHOPHARMACOL, V39, P698, DOI 10.1038/npp.2013.254
   Fang Q, 2015, IEEE T MULTIMEDIA, V17, P2281, DOI 10.1109/TMM.2015.2491019
   Freytag A, 2013, LECT NOTES COMPUT SC, V8142, P282, DOI 10.1007/978-3-642-40602-7_31
   Fu YF, 2014, IEEE T KNOWL DATA EN, V26, P808, DOI 10.1109/TKDE.2013.165
   Haque MM, 2013, IEEE ACM T COMPUT BI, V10, P632, DOI 10.1109/TCBB.2013.38
   Hossain M. S., 2015, J MULTIMODAL USER IN, P1
   Hossain MS, 2016, MOBILE NETW APPL, V21, P753, DOI 10.1007/s11036-016-0685-9
   Hossain MS, 2015, IEEE T CIRC SYST VID, V25, P2105, DOI 10.1109/TCSVT.2015.2444731
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Jiang D, 2010, LNCS, V6974, P609
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Lawrence K, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00761
   Liu KH, 2009, BIOINFORMATICS, V25, P331, DOI 10.1093/bioinformatics/btn644
   Majumder A, 2014, PATTERN RECOGN, V47, P1282, DOI 10.1016/j.patcog.2013.10.010
   Mansoorizadeh M, 2010, MULTIMED TOOLS APPL, V49, P277, DOI 10.1007/s11042-009-0344-2
   Martin O., 2006, 22 INT C DATA ENG WO, P8, DOI [DOI 10.1109/ICDEW.2006.145, 10.1109/ICDEW.2006.145]
   Muhammad G, 2015, CLUSTER COMPUT, V18, P795, DOI 10.1007/s10586-015-0439-7
   Muhammad G, 2014, BIOMED SIGNAL PROCES, V11, P1, DOI 10.1016/j.bspc.2014.02.001
   Qian S., 2015, ACM T MULTIM COMPUT, V11, P1
   Sachse M, 2014, SCHIZOPHR RES, V159, P509, DOI 10.1016/j.schres.2014.08.030
   Senechal T, 2012, IEEE T SYST MAN CY B, V42, P993, DOI 10.1109/TSMCB.2012.2193567
   Shobeirinejad A., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1509, DOI 10.1109/ICPR.2010.1118
   Sourati J, 2014, IEEE T IMAGE PROCESS, V23, P3057, DOI 10.1109/TIP.2014.2325783
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
NR 27
TC 24
Z9 24
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10881
EP 10892
DI 10.1007/s11042-016-3912-2
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400032
DA 2024-07-18
ER

PT J
AU Nandy, A
   Pathak, A
   Chakraborty, P
AF Nandy, Anup
   Pathak, Akanksha
   Chakraborty, Pavan
TI A study on gait entropy image analysis for clothing invariant human
   identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human gait; Clothing invariant; GEnI; Statistical test; Performance
   metrics
ID RECOGNITION; SHAPE
AB A simple and common human gait may be viewed as a strong biometric cue to solve human identification problem through understanding the intrinsic patterns of gait biometrics. An individual's gait pattern appears to be different in gallery and probe gait sequences due to wearing dissimilar clothing types. The gait dataset captures the possible changes found in silhouette shape image which provides the difficulty in distinguishing among individuals. In this paper, a robust feature selection technique has been addressed through Gait Entropy Image (GEnI) analysis. The GEnI has the capacity to accumulate most significant motion information. The width of GEnI, along the horizontal axis is taken as discriminative feature which produces a small intra-class variance. This information is studied as an evidence of feature invariance. The standard statistical tests such as pair-wise clothing correlation and intra-clothing variance are performed on gait dataset to evaluate the reliability of feature. Experimental results demonstrate the efficiency of proposed feature selection method using k-nearest neighbor (k-NN), minimum distance classifier (MDC), and support vector machine (SVM) algorithms. The performance analysis of recognition system has been evaluated on OU-ISIR Treadmill B gait database with different error metrics after performing N-fold cross validation method.
C1 [Nandy, Anup; Pathak, Akanksha; Chakraborty, Pavan] Indian Inst Informat Technol Allahabad, Robot & Artificial Intelligence Lab, Allahabad 211012, Uttar Pradesh, India.
C3 Indian Institute of Information Technology Allahabad
RP Nandy, A (corresponding author), Indian Inst Informat Technol Allahabad, Robot & Artificial Intelligence Lab, Allahabad 211012, Uttar Pradesh, India.
EM nandy.anup@gmail.com; akku.pathak@gmail.com; pavan@iiita.ac.in
RI Pathak, Akanksha/ABG-5427-2021; Chakraborty, Pavan/Y-5495-2019
OI Chakraborty, Pavan/0000-0002-9260-1131
CR [Anonymous], 2006, P IEEE INT C VID SIG
   [Anonymous], 2009, IEEE INT C IM SIGN P
   [Anonymous], 2014, INT J COMPUT VIS ROB, DOI DOI 10.1504/IJCVR.2014.059356
   Bashir K., 2010, the British Machine Vision Conference, P1, DOI DOI 10.1049/IC.2009.0230
   Bashir K, 2008, INT CONF ACOUST SPEE, P985
   Bashir K, 2010, PATTERN RECOGN LETT, V31, P2052, DOI 10.1016/j.patrec.2010.05.027
   BenAbdelkader C, 2004, EURASIP J APPL SIG P, V2004, P572, DOI 10.1155/S1110865704309236
   BENABDELKADER C, 2002, 5 IEEE INT C AUT FAC, P357
   Bobick AF, 2001, PROC CVPR IEEE, P423
   Boyd JE, 2004, COMPUT VIS IMAGE UND, V96, P35, DOI 10.1016/j.cviu.2004.04.004
   CMU, MOBP GAIT DAT
   Cunado D, 2003, COMPUT VIS IMAGE UND, V90, P1, DOI [10.1016/S1077-3142(03)00008-0, 10.1010/SI077-3142(03)00008-0]
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hofmann M, 2012, IEEE IMAGE PROC, P1389, DOI 10.1109/ICIP.2012.6467128
   Hossain MA, 2010, PATTERN RECOGN, V43, P2281, DOI 10.1016/j.patcog.2009.12.020
   Huang XX, 2012, IEEE T IMAGE PROCESS, V21, P2256, DOI 10.1109/TIP.2011.2180914
   Islam MS, 2013, 2013 2ND INTERNATIONAL CONFERENCE ON ADVANCES IN ELECTRICAL ENGINEERING (ICAEE 2013), P411, DOI 10.1109/ICAEE.2013.6750373
   Jeevan M, 2013, IEEE IMAGE PROC, P4195, DOI 10.1109/ICIP.2013.6738864
   Johansson Gunnar, 1973, PERCEPTION PSYCHOPHY, V14
   Johnson AY, 2001, LECT NOTES COMPUT SC, V2091, P301
   Juang L- H, 2012, COMP CONS CONTR IS3C, P837
   Kale A, 2004, IEEE T IMAGE PROCESS, V13, P1163, DOI 10.1109/TIP.2004.832865
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Kusakunniran W, 2012, PATTERN RECOGN LETT, V33, P882, DOI 10.1016/j.patrec.2011.04.014
   Lee L, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P155, DOI 10.1109/AFGR.2002.1004148
   Lee S., 2007, Celebrity Fandom and its Relationship to Tourism and Leisure Behaviors: The Case of Korean Wave, Texas AM Repository, P1
   LIBSVM, LIB SUPP VECT MACH
   Lin Chunli, 2010, 2010 2nd International Conference on Networking and Digital Society (ICNDS 2010), P589, DOI 10.1109/ICNDS.2010.5479416
   Liu ZY, 2004, INT C PATT RECOG, P211, DOI 10.1109/ICPR.2004.1333741
   Makihara Yasushi, 2012, IPSJ Transactions on Computer Vision and Applications, V4, P42, DOI 10.2197/ipsjtcva.4.53
   Nixon MS, 2006, P IEEE, V94, P2013, DOI 10.1109/JPROC.2006.886018
   NIXON MS, 1999, BIOMETRICS PERSONAL
   PUN T, 1981, COMPUT VISION GRAPH, V16, P210, DOI 10.1016/0146-664X(81)90038-1
   Rokanujjaman M, 2013, INT C INF EL VIS IEE, P1
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Singh S, 2009, IEEE DATA MINING, P998, DOI 10.1109/ICDM.2009.93
   Sivapalan Sabesan, 2011, 2011 INT JOINT C BIO, P1, DOI [10.1109/IJCB.2011.6117504, 10.1155/2011/375897]
   Veeraraghavan A, 2005, IEEE T PATTERN ANAL, V27, P1896, DOI 10.1109/TPAMI.2005.246
   Veeraraghavan A, 2004, PROC CVPR IEEE, P730
   Veres GV, 2004, PROC CVPR IEEE, P776
   Wagg DK, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P11, DOI 10.1109/AFGR.2004.1301502
   Yam CY, 2004, PATTERN RECOGN, V37, P1057, DOI 10.1016/j.patcog.2003.09.012
   Yu Guan, 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P321, DOI 10.1109/IIH-MSP.2012.84
   Yu SQ, 2006, INT C PATT RECOG, P441
NR 44
TC 8
Z9 8
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9133
EP 9167
DI 10.1007/s11042-016-3505-0
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300002
DA 2024-07-18
ER

PT J
AU Xiao, DF
   Yang, QW
   Yang, B
   Wei, W
AF Xiao, Degui
   Yang, Qiuwei
   Yang, Bing
   Wei, Wei
TI Monocular scene flow estimation via variational method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene flow; Monocular camera; Time-space consistency; Energy functional;
   Nonlinear iteration; Intelligent healthy drivings
AB Scene flow provides the 3D motion field of point clouds, which correspond to image pixels. Current algorithms usually need complex stereo calibration before estimating flow, which has strong restrictions on the position of the camera. This paper proposes a monocular camera scene flow estimation algorithm. Firstly, an energy functional is constructed, where three important assumptions are turned into data terms derivation: a brightness constancy assumption, a gradient constancy assumption, and a short time object velocity constancy assumption. Two smooth operators are used as regularization terms. Then, an occluded map computation algorithm is used to ensure estimating scene flow only on un-occluded points. After that, the energy functional is solved with a coarse-to-fine variational equation on Gaussian pyramid, which can prevent the iteration from converging to a local minimum value. The experiment results show that the algorithm can use three sequential frames at least to get scene flow in world coordinate, without optical flow or disparity inputting.
C1 [Xiao, Degui; Yang, Qiuwei] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha, Hunan, Peoples R China.
   [Yang, Bing] Hubei Univ, Sch Educ, Wuhan, Peoples R China.
   [Wei, Wei] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Peoples R China.
C3 Hunan University; Hubei University; Huazhong University of Science &
   Technology
RP Yang, B (corresponding author), Hubei Univ, Sch Educ, Wuhan, Peoples R China.
EM dgxiao@hnu.edu.cn; yangqiuwei@hnu.edu.cn; yangbing@126.com;
   Weiwei8329@gmail.com
OI Wei, Wei/0000-0003-4488-0102
FU National Natural Science Foundation of China [61272062, 61300036];
   Projects in the National Science & Technology Pillar Program
   [2013BAH38F01]
FX The authors would like to thank the anonymous reviewers for their
   insightful comments and suggestions. This work is supported in part by
   National Natural Science Foundation of China (Grant No. 61272062,
   61300036), the Projects in the National Science & Technology Pillar
   Program (Grant No. 2013BAH38F01).
CR ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678
   Alcantarilla PF, 2012, IEEE INT CONF ROBOT, P1290, DOI 10.1109/ICRA.2012.6224690
   [Anonymous], 2014, P INT ACM SIGIR WORK
   Baker S, 2011, INT J COMPUT VISION, V92, P1, DOI 10.1007/s11263-010-0390-2
   Basha T, 2013, INT J COMPUT VISION, V101, P6, DOI 10.1007/s11263-012-0542-7
   Birkbeck N, 2011, IEEE I CONF COMP VIS, P1967, DOI 10.1109/ICCV.2011.6126467
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Cech J., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3129, DOI 10.1109/CVPR.2011.5995442
   Civera J, 2008, IEEE T ROBOT, V24, P932, DOI 10.1109/TRO.2008.2003276
   Cruz L., 2012, 2012 XXV SIBGRAPI Conference on Graphics, Patterns and Images Tutorials (SIBGRAPI-T), P36, DOI 10.1109/SIBGRAPI-T.2012.13
   Dame A, 2013, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2013.170
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Geiger A, 2011, IEEE INT VEH SYM, P963, DOI 10.1109/IVS.2011.5940405
   Henry P, 2012, INT J ROBOT RES, V31, P647, DOI 10.1177/0278364911434148
   Herbst E, 2013, IEEE INT CONF ROBOT, P2276, DOI 10.1109/ICRA.2013.6630885
   Hornácek M, 2013, PROC CVPR IEEE, P1123, DOI 10.1109/CVPR.2013.149
   Huang SD, 2007, IEEE T ROBOT, V23, P1036, DOI 10.1109/TRO.2007.903811
   Izadi S, 2011, P UIST, P559, DOI DOI 10.1145/2047196.2047270
   Khoshelham K, 2012, SENSORS-BASEL, V12, P1437, DOI 10.3390/s120201437
   Letouzey A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.46
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Nie LQ, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1245, DOI 10.1145/2600428.2611176
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P396, DOI 10.1109/TKDE.2014.2330813
   Stoyanov D, 2012, LECT NOTES COMPUT SC, V7510, P479, DOI 10.1007/978-3-642-33415-3_59
   Vedula S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P722, DOI 10.1109/ICCV.1999.790293
   Vogel C, 2011, IEEE I CONF COMP VIS, P1291, DOI 10.1109/ICCV.2011.6126381
   Wedel A, 2011, INT J COMPUT VISION, V95, P29, DOI 10.1007/s11263-010-0404-0
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P1867, DOI 10.1109/TIP.2015.2413294
   Yan Y, 2014, IEEE T IMAGE PROCESS, V23, P5599, DOI 10.1109/TIP.2014.2365699
   Yan Y, 2013, IEEE I CONF COMP VIS, P1177, DOI 10.1109/ICCV.2013.150
   Yang Z, 2013, PROC CVPR IEEE, P25, DOI 10.1109/CVPR.2013.11
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
NR 35
TC 13
Z9 14
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10575
EP 10597
DI 10.1007/s11042-015-3091-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400017
DA 2024-07-18
ER

PT J
AU Zhou, P
   Hao, YX
   Yang, J
   Li, W
   Wang, L
   Miao, YM
   Song, J
AF Zhou, Ping
   Hao, Yixue
   Yang, Jun
   Li, Wei
   Wang, Lu
   Miao, Yiming
   Song, Jeungeun
TI Cloud-assisted hugtive robot for affective interaction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion detection; ECG; Smartphone; Robot
ID DATA FUSION; MOBILE; CHALLENGES; FRAMEWORK
AB Owing to the quickening pace and increasing pressure of daily life, people pay more and more attention to life in spiritual level. However, the time for meeting relatives or friends in person is quite short, therefore, it is more and more important for remote emotional communication (i.e., emotional perception and interaction) between users. The existing remote interaction systems mainly pay attention to voice and video communication, and it is difficult to meet the emotional needs of people. How to realize remote emotional communication between different people still faces challenge. In order to cope with this challenge, cloud-assisted hugtive robot (CH-Robot) system is designed in this paper. More specifically, firstly a new-type hugtive robot is designed. Secondly data collected by smart phone and smart clothing are adopted to judge emotional status of user, then emotional communication between users is realized through CH-Robot. Finally, a specific application scene is presented where a mother who is on business in other places comforts her child at home, thus to verify feasibility and effectiveness of the system.
C1 [Zhou, Ping; Hao, Yixue; Yang, Jun; Li, Wei; Wang, Lu; Miao, Yiming; Song, Jeungeun] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Song, J (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM pingzhou@hust.edu.cn; yixuehao@hust.edu.cn; xiaoboshi@hust.edu.cn;
   weili_epic@hust.edu.cn; luwang_epic@hust.edu.cn; yiming.epic@qq.com;
   jsong@hust.edu.cn
RI Hao, Yixue/H-8549-2017
OI Hao, Yixue/0000-0001-7296-2522
FU National Nature Science Foundation of China [61572220]
FX This work is supported by the National Nature Science Foundation of
   China (No. 61572220).
CR [Anonymous], NOVEL MULTIFUNCTIONA
   [Anonymous], IEEE T AFFECT COMPUT
   [Anonymous], 2014, P 2 INT C HUM AG INT, DOI DOI 10.1145/2658861.2658878
   [Anonymous], 2013, 10 IEEE INT C WORKSH
   Chen M., 2015, P 16 ACM INT S MOB A, P399, DOI [10.1145/2746285.2764928, DOI 10.1145/2746285.2764928]
   Chen M, 2016, MOBILE NETW APPL, V21, P825, DOI 10.1007/s11036-016-0745-1
   Chen M, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16070974
   Chen M, 2015, MOBILE NETW APPL, V20, P704, DOI 10.1007/s11036-015-0590-7
   Chen M, 2015, IEEE NETWORK, V29, P32, DOI 10.1109/MNET.2015.7064900
   Chen M, 2015, IEEE WIREL COMMUN, V22, P20, DOI 10.1109/MWC.2015.7054715
   Clavel C, 2015, IEEE T AFFECTIVE COM
   Fang Q, 2015, IEEE T MULTIMED, V17, P7
   Fortino G, 2015, INFORM FUSION, V22, P50, DOI 10.1016/j.inffus.2014.03.005
   Fortino G, 2014, WIREL NETW, V20, P1925, DOI 10.1007/s11276-014-0714-1
   Gravina R, 2016, IEEE T AFFECT COMPUT
   Han MJ, 2013, IEEE T CYBERNETICS, V43, P1290, DOI 10.1109/TSMCB.2012.2228851
   He J, 2014, IEEE T CIRC SYST VID, V24, P669, DOI 10.1109/TCSVT.2013.2283430
   Hossain M. S., 2015, J MULTIMODAL USER IN, P1
   Hossain MS, 2015, IEEE T CIRC SYST VID, V25, P2105, DOI 10.1109/TCSVT.2015.2444731
   Hou X, 2016, IEEE T VEH TECHNOL
   Koelstra S, 2013, IMAGE VISION COMPUT, V31, P164, DOI 10.1016/j.imavis.2012.10.002
   Lahat D, 2015, P IEEE, V103, P1449, DOI 10.1109/JPROC.2015.2460697
   Li Y, 2015, IEEE WIREL COMMUN, V22, P15, DOI 10.1109/MWC.2015.7368820
   Li Y, 2016, IEEE J SEL AREA COMM, V34, P27, DOI 10.1109/JSAC.2015.2452415
   Li Y, 2015, IEEE ACCESS, V3, P2542, DOI 10.1109/ACCESS.2015.2499271
   Li Y, 2014, IEEE T MOBILE COMPUT, V13, P1579, DOI 10.1109/TMC.2013.61
   Li Y, 2014, IEEE COMMUN MAG, V52, P150, DOI 10.1109/MCOM.2014.6829957
   Nardelli M, 2015, IEEE T AFFECT COMPUT
   Shamim Hossain M, 2016, SPRINGER MOBILE NETW
   Taleb T, 2016, IEEE T WIREL COMMUN, V15, P2859, DOI 10.1109/TWC.2015.2512274
   Taleb T, 2016, IEEE J SEL AREA COMM, V34, P483, DOI 10.1109/JSAC.2016.2525342
   Taleb T, 2014, IEEE WIREL COMMUN, V21, P80, DOI 10.1109/MWC.2014.6845052
   Wang HD, 2015, IMC'15: PROCEEDINGS OF THE 2015 ACM CONFERENCE ON INTERNET MEASUREMENT CONFERENCE, P225, DOI 10.1145/2815675.2815680
   Wu D, 2015, IEEE T BROADCAST, V61, P639, DOI 10.1109/TBC.2015.2465173
   Wu D, 2014, IEEE T CIRC SYST VID, V24, P1405, DOI 10.1109/TCSVT.2014.2302543
   Zhang J, 2014, IEEE ICC, P4669, DOI 10.1109/ICC.2014.6884058
   Zhang J, 2013, IEEE T VEH TECHNOL, V62, P4615, DOI 10.1109/TVT.2013.2265780
   Zhang Y, 2014, IEEE NETWORK, V28, P52, DOI 10.1109/MNET.2014.6863132
NR 38
TC 3
Z9 3
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10839
EP 10854
DI 10.1007/s11042-016-3849-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400030
DA 2024-07-18
ER

PT J
AU Shi, H
   Wang, XH
   Li, MC
   Bai, J
   Feng, B
AF Shi, Hui
   Wang, Xianghai
   Li, Mingchu
   Bai, Jun
   Feng, Bin
TI Secure variable-capacity self-recovery watermarking scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Self-recovery watermark; Security; Tamper detection; Variable-capacit;
   Compound watermark; Three level secret-key embedding scheme (TLSES)
ID IMAGE TAMPER DETECTION; FRAGILE WATERMARKING; AUTHENTICATION;
   MODULATION; DIFFERENCE; ATTACK
AB Since existing watermarking schemes usually cannot recover the tampered position, a secure variable-capacity self-recovery watermarking scheme is proposed. Both watermark embedding capacity and security are taken into account. The original image is divided into texture blocks and smooth blocks, and the texture blocks not only save traditional information, and save the "details" information. The so-called "details" information refers to the texture information, which not only can effectively resist mean attack, but also help to improve the quality of the recovered image to meet the needs of practical work. And then according to the characteristics of different blocks, the different length compound watermarks are produced. The so-called "compound watermarks" include the authentication watermarks and information watermarks. Authentication watermarks are used to detect the tampered region, and the information watermarks which include basic watermark and additional watermark are used to recover image. Then the compound watermarks are inserted into the other blocks based on the new proposed scheme called three level secret-key embedding scheme (TLSES). And then detect the tamper blocks and recover them by the three level tamper detection scheme (TLTDS). The experimental results show that the paper can not only accurately detect the tamper region and recover image, but also can effectively resist mean attack and collage attack.
C1 [Shi, Hui] Liaoning Normal Univ, Network Informat Management Ctr, Dalian 116021, Liaoning, Peoples R China.
   [Wang, Xianghai] Liaoning Normal Univ, Grad Sch, Dalian 116021, Liaoning, Peoples R China.
   [Li, Mingchu; Feng, Bin] Dalian Univ Technol, Sch Software, Dalian 116621, Liaoning, Peoples R China.
   [Bai, Jun] Dalian Inst Drug Control, Dalian 116021, Liaoning, Peoples R China.
C3 Liaoning Normal University; Liaoning Normal University; Dalian
   University of Technology
RP Shi, H (corresponding author), Liaoning Normal Univ, Network Informat Management Ctr, Dalian 116021, Liaoning, Peoples R China.
EM shihui_jiayou@126.com
RI Wang, Xianghai/GRR-4512-2022
OI Wang, Xianghai/0000-0002-7600-9939
FU National Youth Fund [61401060]
FX This paper has been supported by the National Youth Fund (Grant No.
   61401060).
CR Abbas Nidaa A., 2015, Applied Computing and Informatics, V11, P102, DOI 10.1016/j.aci.2014.07.003
   Abbasi A, 2015, MEASUREMENT, V74, P116, DOI 10.1016/j.measurement.2015.06.006
   Botta M, 2015, AEU-INT J ELECTRON C, V69, P242, DOI 10.1016/j.aeue.2014.09.004
   Bravo-Solorio S, 2011, SIGNAL PROCESS, V91, P728, DOI 10.1016/j.sigpro.2010.07.019
   Cai NA, 2015, SIGNAL PROCESS-IMAGE, V34, P52, DOI 10.1016/j.image.2015.03.010
   Chang CC, 2008, PATTERN RECOGN, V41, P654, DOI 10.1016/j.patcog.2007.06.003
   [陈帆 Chen Fan], 2012, [计算机学报, Chinese Journal of Computers], V35, P154
   Chen YC, 2014, RES IMAGE AUTHENTICA
   Dadkhah S, 2014, SIGNAL PROCESS-IMAGE, V29, P1197, DOI 10.1016/j.image.2014.09.001
   Deguillaume F, 2003, SIGNAL PROCESS, V83, P2133, DOI 10.1016/S0165-1684(03)00172-5
   Fridrich J, 2002, J ELECTRON IMAGING, V11, P262, DOI 10.1117/1.1459449
   Fridrich J., 1999, P IEEE INT C IM PROC, V3, P792, DOI DOI 10.1109/ICIP.1999.817228
   Ghosal SK, 2014, J INF SECUR APPL, V19, P272, DOI 10.1016/j.jisa.2014.07.004
   He HJ, 2009, LECT NOTES COMPUT SC, V5806, P132
   He HJ, 2009, SIGNAL PROCESS, V89, P1557, DOI 10.1016/j.sigpro.2009.02.009
   He HJ, 2008, LECT NOTES COMPUT SC, V5284, P147
   He HJ, 2008, SCI CHINA SER F, V51, P1487, DOI 10.1007/s11432-008-0094-1
   Holliman M, 2000, IEEE T IMAGE PROCESS, V9, P432, DOI 10.1109/83.826780
   Hsu LY, 2015, J VIS COMMUN IMAGE R, V32, P130, DOI 10.1016/j.jvcir.2015.07.017
   Hu WC, 2015, DIGIT SIGNAL PROCESS, V39, P50, DOI 10.1016/j.dsp.2015.01.006
   Jun-Dong Chang, 2013, 2013 2nd International Symposium on Next-Generation Electronics (ISNE 2013), P173, DOI 10.1109/ISNE.2013.6512330
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Li CL, 2015, NEUROCOMPUTING, V166, P404, DOI 10.1016/j.neucom.2015.03.039
   Li CL, 2012, COMPUT STAND INTER, V34, P367, DOI 10.1016/j.csi.2012.01.003
   Li CL, 2011, COMPUT ELECTR ENG, V37, P927, DOI 10.1016/j.compeleceng.2011.09.007
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   Lou OJ, 2010, J COMPUT RES DEV, V35, P154
   Qi XJ, 2015, J VIS COMMUN IMAGE R, V30, P312, DOI 10.1016/j.jvcir.2015.05.006
   Qian ZX, 2011, DIGIT SIGNAL PROCESS, V21, P278, DOI 10.1016/j.dsp.2010.04.006
   Qin C, 2013, SIGNAL PROCESS, V93, P933, DOI 10.1016/j.sigpro.2012.11.013
   Qin C, 2012, SIGNAL PROCESS, V92, P1137, DOI 10.1016/j.sigpro.2011.11.013
   Qureshi MA, 2015, SIGNAL PROCESS-IMAGE, V39, P46, DOI 10.1016/j.image.2015.08.008
   Rigoni R, 2016, INFORM SCIENCES, V328, P127, DOI 10.1016/j.ins.2015.08.040
   Son CH, 2014, DIGIT SIGNAL PROCESS, V28, P93, DOI 10.1016/j.dsp.2014.02.004
   Verma VS, 2015, EXPERT SYST APPL, V42, P8184, DOI 10.1016/j.eswa.2015.06.041
   Wang H, 2014, SIGNAL PROCESS-IMAGE, V29, P773, DOI 10.1016/j.image.2014.05.001
   Wang XY, 2015, COMPUT ELECTR ENG, V46, P403, DOI 10.1016/j.compeleceng.2015.04.001
   Wang XY, 2014, COMPUT ELECTR ENG, V40, P942, DOI 10.1016/j.compeleceng.2013.12.017
   [王向阳 Wang Xiangyang], 2008, [计算机研究与发展, Journal of Computer Research and Development], V45, P772
   Wu YD, 2005, IEEE T CIRC SYST VID, V15, P161, DOI 10.1109/TCSVT.2004.839978
   Yang CW, 2010, SIGNAL PROCESS, V90, P331, DOI 10.1016/j.sigpro.2009.07.007
   Yang HY, 2015, AEU-INT J ELECTRON C, V69, P389, DOI 10.1016/j.aeue.2014.10.012
   Yu M, 2015, AEU-INT J ELECTRON C, V69, P361, DOI 10.1016/j.aeue.2014.10.006
   Zhang X, 2007, IEEE SIGNAL PROC LET, V14, P727, DOI 10.1109/LSP.2007.896436
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
   Zhang XP, 2009, SIGNAL PROCESS, V89, P675, DOI 10.1016/j.sigpro.2008.10.001
   Zhu SM, 2010, CHIN OPT LETT, V8, P661, DOI 10.3788/COL20100807.0661
NR 47
TC 8
Z9 8
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6941
EP 6972
DI 10.1007/s11042-016-3328-z
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400038
DA 2024-07-18
ER

PT J
AU Shivani, S
   Agarwal, S
AF Shivani, Shivendra
   Agarwal, Suneeta
TI Novel basis matrix creation and preprocessing algorithms for friendly
   progressive visual secret sharing with space-efficient shares
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Progressive visual secret sharing; Secret sharing; Visual cryptography;
   Meaningful shares; Unexpanded shares; basis matrix; Friendly shares;
   Space-efficient shares
AB The traditional k out of n Visual Secret Sharing (VSS) scheme encodes a secret binary image into n shares of random pattern. If the shares are printed onto transparencies, the secret image can be visually revealed only when a subset of k or more transparencies are stacked together otherwise nothing will be revealed. Progressive Visual Secret Sharing (PVSS) also allows the decryption of secret image by stacking of physical transparencies but clarity and contrast of the decoded secret image will be increased progressively with the number of stacked shares. Most of the existing researches on PVSS suffer with the common problems like space-inefficiency(pixel expansion) and noise-like shares. This paper proposes a novel PVSS scheme with four or more number of space-efficient as well as meaningful shares. To achieve this, an efficient preprocessing approach and a basis matrix creation algorithm have also been proposed. This paper also addresses many avoidable encryption limitations like explicit requirement of codebook, restriction on number of shares etc. Experiments show that the contrast of reconstructed secret image is 50% and can be easily decrypted by only human visual system without any cryptographic computation.
C1 [Shivani, Shivendra] Natl Inst Technol Allahabad, Allahabad, Uttar Pradesh, India.
   [Agarwal, Suneeta] Natl Inst Technol Allahabad, Comp Sci & Engn Dept, Allahabad, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology; National Institute of Technology (NIT System);
   Motilal Nehru National Institute of Technology
RP Shivani, S (corresponding author), Natl Inst Technol Allahabad, Allahabad, Uttar Pradesh, India.
EM shivendrashivani@gmail.com; suneeta@mnnit.ac.in
RI Shivani, Shivendra/AFN-2368-2022
OI Shivani, Shivendra/0000-0002-5931-6603
CR Askari N, 2013, 26 ANN IEEE CAN C EL
   Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Ateniese G, 2001, THEOR COMPUT SCI, V250, P143, DOI 10.1016/S0304-3975(99)00127-9
   Chen SK, 2005, PATTERN RECOGN, V38, P2466, DOI 10.1016/j.patcog.2005.04.002
   Chen TH, 2009, PATTERN RECOGN, V42, P2203, DOI 10.1016/j.patcog.2008.11.015
   Chou CS, 2002, THESIS
   Fang WP, 2007, ELE COM ENG, P108
   Fang Wen-Pinn, 2006, [Pattern Recognition and Image Analysis (Advances in Mathematical Theory and Applications), Pattern Recognition and Image Analysis. (Advances in Mathematical Theory and Applications)], V16, P632
   Fang WP, 2008, PATTERN RECOGN, V41, P1410, DOI 10.1016/j.patcog.2007.09.004
   Fu MS, 2004, P IEEE INT C MULT EX
   Haiping L, 2004, IEEE SIGNAL PROCESSI, V11
   Hou Y-C, 2014, IEEE T CIRCUITS SYST, V24
   Hou YC, 2013, INFORM SCIENCES, V233, P290, DOI 10.1016/j.ins.2013.01.006
   Hou Young-Chang, 2011, IEEE T CIRCUITS SYST, V21
   MACPHERSON LA, 2002, THESIS
   Myodo E, 2006, P IEEE ICIP
   Nakajima M, 2002, WSCG'2002, VOLS I AND II, CONFERENCE PROCEEDINGS, P303
   Naor M, 1997, LECT NOTES COMPUT SC, V1294, P322
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Shyu SH, 2007, PATTERN RECOGN, V40, P1014, DOI 10.1016/j.patcog.2006.02.025
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   ULICHNEY R, 1993, P SOC PHOTO-OPT INS, V1913, P332, DOI 10.1117/12.152707
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZM, 2009, IEEE T INF FOREN SEC, V4, P383, DOI 10.1109/TIFS.2009.2024721
   Young DP, 2005, P 2 JOINT IEEE INT W
   Zhou Z, 2006, IEEE T IMAGE PROCESS, V15, P2441, DOI 10.1109/TIP.2006.875249
NR 26
TC 7
Z9 7
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8711
EP 8744
DI 10.1007/s11042-016-3484-1
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800048
DA 2024-07-18
ER

PT J
AU Singh, AK
AF Singh, Amit Kumar
TI Improved hybrid algorithm for robust and imperceptible multiple
   watermarking using digital images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image and text watermarking; Steganography; Discrete wavelet transforms;
   Discrete cosine transforms; Singular value decomposition; Encryption;
   Robustness; Capacity; BER
ID COPYRIGHT PROTECTION; SCHEME; DCT
AB This paper presents a new robust hybrid multiple watermarking technique using fusion of discrete wavelet transforms (DWT), discrete cosine transforms (DCT), and singular value decomposition (SVD) instead of applying DWT, DCT and SVD individually or combination of DWT-SVD / DCT-SVD. For identity authentication purposes, multiple watermarks are embedded into the same medical image / multimedia objects simultaneously, which provides extra level of security with acceptable performance in terms of robustness and imperceptibility. In the embedding process, the cover image is decomposed into first level discrete wavelet transforms where the A (approximation/lower frequency sub-band) is transformed by DCT and SVD. The watermark image is also transformed by DWT, DCT and SVD. The S vector of watermark information is embedded in the S component of the cover image. The watermarked image is generated by inverse SVD on modified S vector and original U, V vectors followed by inverse DCT and inverse DWT. The watermark is extracted using an extraction algorithm. Furthermore, the text watermark is embedding at the second level of the D (diagonal sub-band) of the cover image. The security of the text watermark considered as EPR (Electronic Patient Record) data is enhanced by using encryption method before embedding into the cover. The results are obtained by varying the gain factor, size of the text watermark, and cover medical images. The method has been extensively tested and analyzed against known attacks and is found to be giving superior performance for robustness, capacity and reduced storage and bandwidth requirements compared to reported techniques suggested by other authors.
C1 [Singh, Amit Kumar] Jaypee Univ Informat Technol Waknaghat, Dept Comp Sci & Engn, Solan, Himachal Prades, India.
C3 Jaypee University of Information Technology
RP Singh, AK (corresponding author), Jaypee Univ Informat Technol Waknaghat, Dept Comp Sci & Engn, Solan, Himachal Prades, India.
EM amit_245singh@yahoo.com
RI ; Singh, Amit Kumar/D-1300-2015
OI Singleton, Ann/0000-0003-0010-0418; Singh, Amit
   Kumar/0000-0001-7359-2068
CR [Anonymous], VIS IMAGING IMAGE PR
   [Anonymous], INT J COMPUT APPL
   [Anonymous], INT J COMPUT SCI MOB
   [Anonymous], 2012, AM J BIOMEDICAL ENG, DOI DOI 10.5923/J.AJBE.20120202.06
   [Anonymous], CSI COMMUN
   [Anonymous], ADV ELECT ELECT ENG
   [Anonymous], 2013, IOSR J COMPUTER ENG
   [Anonymous], PRESENCE ACTIVE WARD
   [Anonymous], ACAD PRESS LIB SIGNA
   [Anonymous], INT J ADV RES COMPUT
   [Anonymous], THESIS
   [Anonymous], INF HLTH INF STRAT M
   [Anonymous], 2000, Digital Watermarking
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Golshan F, 2013, IMAGING SCI J, V61, P35, DOI 10.1179/1743131X11Y.0000000049
   Harish N., 2013, INT J ADV ELECT ELEC, V2, P137
   Hartung F, 2000, IEEE COMMUN MAG, V38, P78, DOI 10.1109/35.883493
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P3085, DOI 10.1007/s11042-013-1579-5
   Horng SJ, 2013, J VIS COMMUN IMAGE R, V24, P1099, DOI 10.1016/j.jvcir.2013.07.008
   Khan Mohammad Ibrahim, 2013, INT J COMPUTER SCI I, V10, P223
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P11509, DOI 10.1016/j.eswa.2009.03.060
   Lin WH, 2009, EXPERT SYST APPL, V36, P9869, DOI 10.1016/j.eswa.2009.02.036
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Navas KA, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON COMMUNICATION SYSTEM SOFTWARE AND MIDDLEWARE AND WORKSHOPS, VOLS 1 AND 2, P271, DOI 10.1109/COMSWA.2008.4554423
   Rosiyadi D., 2012, Int J Comput Theory and Eng (IJCTE), V4, P329
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Simmons G. J., 1984, Advances in Cryptology. Proceedings of Crypto 83, P51
   Singh A, 2012, INT J COMPUT APPL, V48, P9
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh AK, 2015, WIRELESS PERS COMMUN, V83, P2133, DOI 10.1007/s11277-015-2505-0
   Singh AK, 2014, P NATL A SCI INDIA A, V84, P345, DOI 10.1007/s40010-014-0140-x
   Singh AK, 2014, NATL ACAD SCI LETT, V37, P351, DOI 10.1007/s40009-014-0241-8
   Singh AK, 2013, LECT NOTES COMPUT SC, V8271, P235, DOI 10.1007/978-3-642-44949-9_22
   Wang B, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON NETWORK INFRASTRUCTURE AND DIGITAL CONTENT, PROCEEDINGS, P1034, DOI 10.1109/ICNIDC.2009.5360866
NR 36
TC 122
Z9 123
U1 2
U2 110
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8881
EP 8900
DI 10.1007/s11042-016-3514-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800055
DA 2024-07-18
ER

PT J
AU Zhang, DL
   Zhou, DJ
   Jin, X
AF Zhang, Dalu
   Zhou, Dejiang
   Jin, Xiang
TI A content-adaptive video quality assessment method for online media
   service
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quality of experiment; Quality of service; QoE online measurement.;
   Content-adaptive
AB Video quality assessment is an important issue for Internet Content Providers (ICPs) to improve their service. Some research has been done on objective video quality assessment, but real-time evaluation is still a difficult task. This paper discusses a real-time content-adaptive evaluation method to evaluate the Quality of Experiment (QoE) for online media services. The method is named as Motion Degree of Video Content (MDVC) which is defined to make the video content measureable and computable. It analyzes the relationship between the information entropy gain and the frame size of I, P and B frames, and then evaluates the motion degree of a video clip. Then with the help of a multimedia service simulation platform, a QoE evaluation model is established to map network QoS to QoE. The model is adjusted by MDVC so as to fit different video content dynamically. In particular, to ensure that the evaluation model fits the real-world conditions, PlanetLab is adopted to monitor the real QoS on Internet. Finally we compare the content-adaptive QoE evaluation model with the actual MOS values to verify the feasibility and fitness of the model. Results show that the correlation coefficient reaches 0.91.
C1 [Zhang, Dalu; Zhou, Dejiang; Jin, Xiang] Tongji Univ, Coll Elect & Informat Engn, Shanghai, Peoples R China.
C3 Tongji University
RP Zhang, DL (corresponding author), Tongji Univ, Coll Elect & Informat Engn, Shanghai, Peoples R China.
EM daluz@acm.org; dejiang_zhou@163.com; jinxiang8910@gmail.com
FU National Natural Science Foundation of China [61073154]
FX This paper is supported by the National Natural Science Foundation of
   China (No. 61073154).
CR [Anonymous], OBJ PERC VID QUAL ME
   [Anonymous], 2006, MEAN OP SCOR MOS TER
   Chun Brent, 2003, ACM SIGCOMM COMPUTER
   Dobrian F, 2011, ACM SIGCOMM COMP COM, V41, P362, DOI 10.1145/2043164.2018478
   Garcia MN, 2011, EURASIP J IMAGE VIDE, DOI 10.1155/2011/629284
   ITU, 2008, FULL REF FR RED REF, V244
   Jain R, 2004, IEEE MULTIMEDIA, V11, P96, DOI 10.1109/MMUL.2004.1261114
   Klaue J, 2003, LECT NOTES COMPUT SC, V2794, P255, DOI 10.1007/978-3-540-45232-4_16
   Li W, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P517, DOI 10.1109/ISM.2009.54
   Liu Yu-Xin, 2006, Journal of Zhejiang University (Science), V7, P919, DOI 10.1631/jzus.2006.A0919
   Pinson M, 2010, 5 INT WORKSH VID PRO
   Rahrer T, 2006, TR126 DSL FOR
   Richardson IE, 2001, MPEG 4 VISUAL H 264, P99
   Sommers J, 2005, ACM SIGCOMM COMP COM, V35, P157, DOI 10.1145/1090191.1080111
   Sullivan G, 2004, 1SC29WG11N6540 ISOIE
   WANG C, 2011, RUBBER PLASTICS RESO, V1, P1, DOI DOI 10.1155/2011/837209
   Welch J., 2006, 4445 RFC
   Wolf MS, 2011, TM11482 NTIA
   Wolf Stephen, 2009, TM10463 NTIA
   Yang FZ, 2012, IEEE J-STSP, V6, P672, DOI 10.1109/JSTSP.2012.2207705
NR 20
TC 6
Z9 7
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 7175
EP 7195
DI 10.1007/s11042-016-3359-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400047
DA 2024-07-18
ER

PT J
AU Fathimal, PM
   Rani, PAJ
AF Fathimal, Mohamed P.
   Rani, Arockia Jansi P.
TI Hierarchical threshold secret sharing scheme for color images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hierarchical Threshold Secret Sharing Scheme; Multilevel Secret Sharing
   Scheme; K Out Of N Secret Sharing Scheme; Access Control; Secure
   Information Sharing; Disjunctive Hierarchical Secret Image Sharing
   Scheme
ID AUTHENTICATION; STEGANOGRAPHY
AB The applications that use pattern recognition via secret sharing are seldom linear, straightforward and uncomplicated. The layers of complexity grows as the process turns more secretive. In applications, such as banking transactions, hierarchical secret sharing comes in as a handy tool. This paper analyses the use of disjunctive hierarchy of secret sharing without compromising security while saving time. This scheme simplifies the process when more hands are involved by using simple Boolean and arithmetic operations and thus reduces the computational complexity from O (nlog(2)n) to O (n). The other features are authentication of the participants using Lagrange Interpolation; non-requirement of half toning of color images; no pixel expansion without degradation in visual quality of the recovered secret image. This paper also provides solution for meaningful share images with the ability to detect the manipulation of share images. The main advantage of this scheme is that it gives the benefit in scenarios in which participants of different levels are involved.
C1 [Fathimal, Mohamed P.] SRM Univ, Dept Comp Sci & Engn, Vadapalani Campus, Madras, Tamil Nadu, India.
   [Rani, Arockia Jansi P.] Manonmaniam Sundaranar Univ, Dept Comp Sci & Engn, Tirunelveli, Tamil Nadu, India.
C3 SRM Institute of Science & Technology Chennai; Manonmaniam Sundaranar
   University
RP Fathimal, PM (corresponding author), SRM Univ, Dept Comp Sci & Engn, Vadapalani Campus, Madras, Tamil Nadu, India.
EM fatnazir@gmail.com; jansi_cse@msuniv.ac.in
RI P, Arockia Jansi Rani/P-8377-2017; P, mohamed fathimal/D-1409-2018
OI P, Arockia Jansi Rani/0000-0003-2412-0106; P, mohamed
   fathimal/0000-0002-2986-8642
CR [Anonymous], 1989, J COMB MATH COMB COM
   BLAKLEY GR, 1979, NAT COMP C, V48, P313
   Brickell E. F., 1991, Journal of Cryptology, V4, P123, DOI 10.1007/BF00196772
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Eslami Z, 2010, PATTERN RECOGN, V43, P397, DOI 10.1016/j.patcog.2009.06.007
   Fathimal P. M., 2015, INT J COMPUTER NETWO, V7, P46
   Fathimal P. M., 2015, INT J APPL ENG RES, V10, P26087
   Fathimal P. M., 2014, INT J SCI ENG TECHNO, V3, P2255
   Fathimal PM, 2016, INT J IMAGE GRAPH, V16, DOI 10.1142/S0219467816500108
   Fathimal P Mohamed, 2015, INT J COMPUT ELECT A, V9, P2015
   Fathimal P Mohamed, 2014, IEEE INT C EL COMP C, P1, DOI [10.1109/ICECCT.2015.7226019, DOI 10.1109/ICECCT.2015.7226019]
   Guo C, 2012, PATTERN RECOGN LETT, V33, P83, DOI 10.1016/j.patrec.2011.09.030
   Mohamed Fathimal P, 2015, ADV INTELLIGENT SYST, P413
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   SIMMONS GJ, 1990, LECT NOTES COMPUT SC, V403, P390
   Tassa T, 2007, J CRYPTOL, V20, P237, DOI 10.1007/s00145-006-0334-8
   Tassa T, 2009, J CRYPTOL, V22, P227, DOI 10.1007/s00145-008-9027-9
   Yang CN, 2012, OPT COMMUN, V285, P1725, DOI 10.1016/j.optcom.2011.12.003
NR 19
TC 7
Z9 7
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5489
EP 5503
DI 10.1007/s11042-016-4074-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500036
DA 2024-07-18
ER

PT J
AU Zhang, JG
   Xiang, QM
   Yin, YG
   Chen, C
   Luo, X
AF Zhang, Junguo
   Xiang, Qiumin
   Yin, Yaguang
   Chen, Chen
   Luo, Xin
TI Adaptive compressed sensing for wireless image sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless sensor networks; Block compressed sensing; Adaptive sampling;
   Rate allocation
ID RECONSTRUCTION; PREDICTION; MODEL
AB Compressed sensing (CS) based image compression can achieve a very low sampling rate, which is ideal for wireless sensor networks with respect to their energy consumption and data transmission. In this paper, an adaptive compressed sensing rate assignment algorithm that is based on the standard deviations of image blocks is proposed. Specifically, each image block is first assigned a fixed sampling rate. In addition to the fixed sampling rate, an adaptive sampling rate is then given to each block based on the standard deviation of the block. With this adaptive sampling strategy, higher sampling rates are assigned to blocks that are less compressible (e.g., blocks with complex textures are less compressible than blocks with a smooth background). The sensing matrix is constructed based on the assigned sampling rate. The fixed measurements and the adaptive measurements are concatenated to form the final measurements. Finally, the measurements are used to reconstruct the image on the decoding side. The experimental results demonstrate that the proposed algorithm can achieve image progressive transmission and improve the reconstruction quality of the images.
C1 [Zhang, Junguo; Xiang, Qiumin; Luo, Xin] Beijing Forestry Univ, Sch Technol, Beijing 100083, Peoples R China.
   [Yin, Yaguang] SAPPRFT, Acad Broadcasting Sci, Beijing, Peoples R China.
   [Chen, Chen] Univ Texas Dallas, Dept Elect Engn, Richardson, TX 75080 USA.
C3 Beijing Forestry University; University of Texas System; University of
   Texas Dallas
RP Zhang, JG (corresponding author), Beijing Forestry Univ, Sch Technol, Beijing 100083, Peoples R China.
EM zhangjunguo@bjfu.edu.cn; xiangqiumin16@126.com; yinyaguang@abs.ac.cn;
   chenchen870713@gmail.com; luoxinstudy@126.com
FU National Natural Science Foundation of China [31300470]; Import Project
   under China State Forestry Administration [2014-4-05]; Beijing Higher
   Education Young Elite Teacher Project [YETP0760]
FX This work was funded by The National Natural Science Foundation of China
   (Grant No. 31300470), Import Project under China State Forestry
   Administration (Grant No.2014-4-05), Beijing Higher Education Young
   Elite Teacher Project (Grant No.YETP0760).
CR Akyildiz IF, 2002, COMPUT NETW, V38, P393, DOI 10.1016/S1389-1286(01)00302-4
   Candes E. J., 2006, PROC INT C MATH, V17, P1433, DOI DOI 10.4171/022-3/69
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Chen C, 2012, SIGN SYST COMP ASILO
   Chen C, 2014, IEEE J-STARS, V7, P1047, DOI 10.1109/JSTARS.2013.2295610
   Chen C, 2011, CONF REC ASILOMAR C, P1193, DOI 10.1109/ACSSC.2011.6190204
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Ferrigno L, 2005, PROCEEDINGS OF THE 2005 IEEE INTERNATIONAL CONFERENCE ON VIRTUAL ENVIRONMENTS, HUMAN-COMPUTER INTERFACES AND MEASUREMENT SYSTEMS, P61
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Junguo Zhang, 2009, 2009 WRI World Congress on Computer Science and Information Engineering, CSIE, P66, DOI 10.1109/CSIE.2009.434
   Liu Q, 2012, IEEE SIGNAL PROC LET, V19, P295, DOI 10.1109/LSP.2012.2190060
   [罗孟儒 Luo Mengru], 2013, [电子与信息学报, Journal of Electronics & Information Technology], V35, P2371
   Mun S, 2009, IEEE IMAGE PROC, P3021, DOI 10.1109/ICIP.2009.5414429
   Tavli B, 2012, MULTIMED TOOLS APPL, V60, P689, DOI 10.1007/s11042-011-0840-z
   [王蓉芳 Wang Rongfang], 2013, [电子学报, Acta Electronica Sinica], V41, P1506
   Yang Y, 2015, INFORM SCIENCES, V320, P306, DOI 10.1016/j.ins.2014.11.014
   Yang Y, 2015, SIGNAL PROCESS, V112, P199, DOI 10.1016/j.sigpro.2014.07.020
   Yang Y, 2015, NEUROCOMPUTING, V151, P663, DOI 10.1016/j.neucom.2014.04.088
   Yang Y, 2014, INFORM SCIENCES, V281, P601, DOI 10.1016/j.ins.2014.03.016
   Zhang J., 2014, Sensors Transducers, V180, P104
   Zhang J, 2014, SIGNAL PROCESS, V103, P114, DOI 10.1016/j.sigpro.2013.09.025
   Zhang Shu-fang, 2012, Journal of Tianjin University, V45, P319
NR 22
TC 47
Z9 47
U1 2
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 4227
EP 4242
DI 10.1007/s11042-016-3496-x
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200051
DA 2024-07-18
ER

PT J
AU Zhu, HY
   Huang, XY
   Zhang, SP
   Yuen, PC
AF Zhu, Heyan
   Huang, Xinyuan
   Zhang, Shengping
   Yuen, Pong C.
TI Plant identification via multipath sparse coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Plant identification; Multipath sparse coding; SIFT descriptor;
   Multi-organ; Linear SVM
AB In this paper, we propose a novel plant identification method based on multipath sparse coding using SIFT features, which avoids the need of feature engineering and the reliance on botanical taxonomy. In particular, the proposed method uses five paths to model the shape and texture features of plant images, and at each path it learns the dictionaries with different sizes using hierarchical sparse coding. Finally, we apply the learned representation for plant identification using linear SVM for classification. We evaluate the proposed method on several plant datasets and find that multi-organ is more informative than single organ for botanist. Experimental results also validate that the proposed method outperforms the state-of-the-art methods.
C1 [Zhu, Heyan] Beijing Forestry Univ, Sch Informat, Beijing, Peoples R China.
   [Zhu, Heyan] Yantai Univ, Sch Optoelect Informat, Yantai, Peoples R China.
   [Huang, Xinyuan] Commun Univ China, Inst Animat & Digital Art, Beijing, Peoples R China.
   [Zhang, Shengping] Harbin Inst Technol, Sch Comp Sci & Technol, Weihai, Peoples R China.
   [Yuen, Pong C.] Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
C3 Beijing Forestry University; Yantai University; Communication University
   of China; Harbin Institute of Technology; Hong Kong Baptist University
RP Huang, XY (corresponding author), Commun Univ China, Inst Animat & Digital Art, Beijing, Peoples R China.
EM zhy1980_office@163.com; hxy@263.net; s.zhang@hit.edu.cn;
   pcyuen@comp.hkbu.edu.hk
FU national key R&D program of China [2015BAH52F03]; Natural Science
   Foundation of China [61300111]; Hubei Provincial Natural Science
   Foundation [2014CFB659]; selfdetermined research funds of CCNU from the
   colleges' basic research and operation of MOE [CCNU15A05023]
FX This work is supported in part by the national key R&D program of China
   (2015BAH52F03), the Natural Science Foundation of China (No. 61300111),
   Hubei Provincial Natural Science Foundation (NO.2014CFB659) and
   selfdetermined research funds of CCNU from the colleges' basic research
   and operation of MOE (No.CCNU15A05023).
CR [Anonymous], 2010, CVPR
   [Anonymous], 2012, P 1 ACM INT WORKSH M
   [Anonymous], 2010, Proceedings of the Conference on Image and Video Retrieval
   [Anonymous], 2014, P WORK NOT CLEF 2014
   [Anonymous], IND C COMP VIS GRAPH
   [Anonymous], 2006, IEEECOMPUT SOC C COM
   [Anonymous], 2010, CVPR
   [Anonymous], 2011, CVPR
   [Anonymous], 2014, Int. J. Innov. Res. Comput. Commun. Eng
   [Anonymous], 2013, Int. 1.Bar Sci. Bio Technol., DOI [10.3724/sp.j.1087.2009.01707, DOI 10.1007/978-94-007-5857-5_12]
   [Anonymous], INT J COMPUT SCI BUS
   Belhumeur PN, 2008, LECT NOTES COMPUT SC, V5305, P116, DOI 10.1007/978-3-540-88693-8_9
   Ben Mabrouk A, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P201
   Bo L., 2013, CVPR
   Du JX, 2007, APPL MATH COMPUT, V185, P883, DOI 10.1016/j.amc.2006.07.072
   Fiel S., 2011, 16 COMP VIS WINT WOR
   Guru D.S., 2010, IJCA Special Issue on "Recent Trends in Image Processing and Pattern Recognition"
   Han JW, 2014, MACH VISION APPL, V25, P1671, DOI 10.1007/s00138-013-0558-1
   Han JW, 2014, NEUROCOMPUTING, V145, P140, DOI 10.1016/j.neucom.2014.05.049
   Hsiao JK, 2014, ICCE
   Hsiao JK, 2014, 2014 SCIENCE AND INFORMATION CONFERENCE (SAI), P389, DOI 10.1109/SAI.2014.6918216
   Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3_36
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Metre V., 2013, INT J COMPUTER SCI N, V2, DOI [10.48550/arXiv.1306.4345, DOI 10.48550/ARXIV.1306.4345]
   Mouine S., 2013, P ACM INT C MULT RET
   Mouine S, 2013, P 2 ACM INT C MULT R, P49
   Patel HN, 2011, INT J COMPUT APPL, V13
   Peng P, 2015, NEUROCOMPUTING, V166, P337, DOI 10.1016/j.neucom.2015.03.067
   Seon-Jong Kim, 2011, SICE 2011 - 50th Annual Conference of the Society of Instrument and Control Engineers of Japan, P1147
   Song Y, 2014, BIOSYST ENG, V118, P203, DOI 10.1016/j.biosystemseng.2013.12.008
   Tang J, 2014, COMPUT VIS IMAGE UND, V124, P91, DOI 10.1016/j.cviu.2014.02.007
   Wang XF, 2008, APPL MATH COMPUT, V205, P916, DOI 10.1016/j.amc.2008.05.108
   Wang Z, 2003, IEE P-VIS IMAGE SIGN, V150, P34, DOI 10.1049/ip-vis:20030160
   Wilf P, 2016, P NATL ACAD SCI USA, V113, P3305, DOI 10.1073/pnas.1524473113
   Xiao XY, 2010, LECT NOTES ARTIF INT, V6216, P149, DOI 10.1007/978-3-642-14932-0_19
   Zhang BC, 2016, NEUROCOMPUTING, V171, P387, DOI 10.1016/j.neucom.2015.06.052
   Zhang BC, 2015, PROC CVPR IEEE, P4557, DOI 10.1109/CVPR.2015.7299086
   Zhang SP, 2015, IEEE T CIRC SYST VID, V25, P1749, DOI 10.1109/TCSVT.2015.2406194
   Zhang SP, 2013, PATTERN RECOGN, V46, P1772, DOI 10.1016/j.patcog.2012.10.006
   Zhiyong Wang, 2011, Proceedings of the 2011 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2011), P650, DOI 10.1109/DICTA.2011.115
NR 40
TC 8
Z9 8
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 4599
EP 4615
DI 10.1007/s11042-016-3538-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200068
DA 2024-07-18
ER

PT J
AU Chen, YR
   Chen, LH
AF Chen, Ying-Ru
   Chen, Ling-Hwei
TI Region image sharing with various secrecy levels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret image sharing; Shadow size; Pixel-security-level map; Predictive
   differential quantizing
AB In most secret image sharing schemes, the secrecy level of each pixel is the same. However, in real applications, different pixels may require different secrecy levels. For example, in a patient's medical image, the region with the patient's name must be highly protected. To solve this problem, Wang and Lin proposed a scheme that allows a dealer to divide an image into multiple regions, each of which is associated with a certain level of secrecy. In their scheme, an extra pixel-security-level map (PSLM) is required to record the secrecy level of each pixel, and the shadow size of the PSLM is approximately 20 % of that of the secret image. It is unreasonable to have such a large overhead. To reduce the shadow size of the PSLM, they restricted each region to be a rectangle. Furthermore, any two participants can reconstruct the PSLM, enabling the content of regions with high secrecy levels to be compromised easily. To resolve these disadvantages, this paper proposes a new encoding scheme for PSLMs. The location of each region is protected according to its secrecy level, thus improving the security of the image. Moreover, the shape of each region is unrestricted, and the shadow size of the PSLM is reduced significantly.
C1 [Chen, Ying-Ru; Chen, Ling-Hwei] Natl Chiao Tung Univ, Dept Comp Sci, Coll Comp Sci, 1001 Ta Hsueh Rd, Hsinchu 300, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Chen, LH (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, Coll Comp Sci, 1001 Ta Hsueh Rd, Hsinchu 300, Taiwan.
EM lhchen@cc.nctu.edu.tw
FU National Science Council [NSC 103-2221-E-009-121-MY2]
FX This work was supported in part by the National Science Council project
   under Grant NSC 103-2221-E-009-121-MY2.
CR Chen LC., 2010, J. Nanomat, V2010, P1
   Chen SK, 2005, PATTERN RECOGN, V38, P2466, DOI 10.1016/j.patcog.2005.04.002
   HUANG TS, 1977, IEEE T COMMUN, V25, P1406, DOI 10.1109/TCOM.1977.1093775
   Lin YY, 2010, IEEE SIGNAL PROC LET, V17, P316, DOI 10.1109/LSP.2009.2038113
   Liu WJ, 2015, MULTIMED TOOLS APPL, V74, P7095, DOI 10.1007/s11042-014-1953-y
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Stalling W, 2002, CRYPTOGRAPHY NETWORK, P104
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Wang RZ, 2007, SIGNAL PROCESS-IMAGE, V22, P363, DOI 10.1016/j.image.2006.12.012
   Wang RZ, 2011, OPT ENG, V50, DOI 10.1117/1.3558811
   Yang CN, 2011, J SYST SOFTWARE, V84, P1726, DOI 10.1016/j.jss.2011.05.008
   Yang CN, 2010, OPT COMMUN, V283, P1750, DOI 10.1016/j.optcom.2009.12.077
NR 12
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 1721
EP 1734
DI 10.1007/s11042-015-3143-y
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000006
DA 2024-07-18
ER

PT J
AU Hiary, S
   Jafar, I
   Hiary, H
AF Hiary, Sawsan
   Jafar, Iyad
   Hiary, Hazem
TI An efficient multi-predictor reversible data hiding algorithm based on
   performance evaluation of different prediction schemes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Predictor; Difference expansion; Histogram
   shifting
ID HISTOGRAM-MODIFICATION; EXPANSION
AB With the broad development and evolution of digital data exchange, security has become an important issue in data storage and transmission since digital data can be easily manipulated and modified. Reversible data hiding algorithms are special class of steganography that are capable of recovering the original cover image upon the extraction of the secret data. This issue is of interest in medical and military imaging applications. Many algorithms in this class exploit the idea of prediction in order to increase the embedding capacity as well as the quality of the stego image. However, the performance of these algorithms depends on the type of predictor that is being used. The main goal in this paper is to survey different predictors and evaluate their performance when employed in two classical reversible data hiding algorithms. The evaluation considered plugging 22 predictors in the two algorithms to process 1438 test images. Experimental results validated the varying capabilities of different predictors and showed that the non-causal median predictor had the best performance in the two algorithms. Further more, the paper proposes a new multi-predictor reversible data hiding algorithm. Basically, the algorithm employs multiple predictors in an extended version of the modification of prediction errors (MPE) algorithm. The algorithm takes advantage of the results obtained from the performance evaluation of different predictors to select the best set of predictors. Performance evaluation proved the ability of the proposed algorithm in increasing the embedding capacity while maintaining high stego image quality.
C1 [Hiary, Sawsan; Jafar, Iyad; Hiary, Hazem] Univ Jordan, Amman 11942, Jordan.
C3 University of Jordan
RP Hiary, H (corresponding author), Univ Jordan, Amman 11942, Jordan.
EM iyad.jafar@ju.edu.jo; hazemh@ju.edu.jo
RI Hiary, Hazem/C-8358-2015
OI Hiary, Hazem/0000-0002-0306-5294
CR Alattar AM, 2003, IEEE IMAGE PROC, P501
   Armstrong RA, 2000, OPHTHAL PHYSL OPT, V20, P235, DOI 10.1016/S0275-5408(99)00064-2
   Avramovic A., 2011, Serbian Journal of Electrical Engineering, V8, P27, DOI DOI 10.2298/SJEE1101027A
   Bansal C, 2014, IEEE INT ADV COMPUT, P1008, DOI 10.1109/IAdCC.2014.6779462
   Cheng-Hsing Yang, 2010, Proceedings of the 2010 Fourth International Conference on Genetic and Evolutionary Computing (ICGEC 2010), P667, DOI 10.1109/ICGEC.2010.170
   Conotter V, 2010, IEEE IMAGE PROC, P2585, DOI 10.1109/ICIP.2010.5651763
   Deng G., 1999, P IEEE INT C IM PROC, V4, P63
   Dragoi IC, 2012, EUR SIGNAL PR CONF, P1688
   Feng GR, 2012, J SYST SOFTWARE, V85, P392, DOI 10.1016/j.jss.2011.08.033
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Gonzalez RC, 2009, DIGITAL IMAGE PROCES, DOI 10.1117/1.3115362
   Hartung F, 1999, P IEEE, V87, P1079, DOI 10.1109/5.771066
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Honsinger C. W., 2001, US Patent, Patent No. [6,278,791, 6278791]
   Hyndman RJ, 1996, AM STAT, V50, P361, DOI 10.2307/2684934
   Jafar IF, 2014, PROC SPIE, V9159, DOI 10.1117/12.2064524
   Jiang J, 2000, IEE P-VIS IMAGE SIGN, V147, P575, DOI 10.1049/ip-vis:20000767
   Jung SW, 2011, IEEE SIGNAL PROC LET, V18, P95, DOI 10.1109/LSP.2010.2095498
   Kau LJ, 2005, IEEE T CIRCUITS-II, V52, P751, DOI 10.1109/TCSII.2005.852194
   Kuo WC, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P365, DOI 10.1109/CISP.2008.730
   Lee CF, 2010, J SYST SOFTWARE, V83, P1864, DOI 10.1016/j.jss.2010.05.078
   Luo H, 2011, INFORM SCIENCES, V181, P308, DOI 10.1016/j.ins.2010.09.022
   Luo Y., 2011, Mistreatment and Psychological Well-being Among Older Adults : Exploring the Role of Psychosocial Resources and Deficits, P1, DOI DOI 10.1109/ICME.2011.6011833
   Ma XX, 2015, J VIS COMMUN IMAGE R, V28, P71, DOI 10.1016/j.jvcir.2015.01.012
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Pan H, 2007, IET IMAGE PROCESS, V1, P353, DOI 10.1049/iet-ipr:20060195
   Rad RM, 2014, IWIHC'14: PROCEEDINGS OF THE FIRST ACM INTERNATIONAL WORKSHOP ON INFORMATION HIDING AND ITS CRITERIA FOR EVALUATION, P42, DOI 10.1145/2598908.2598916
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Starosolski R, 2007, SOFTWARE PRACT EXPER, V37, P65, DOI 10.1002/spe.746
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang SS, 2012, 2012 INTERNATIONAL CONFERENCE ON FUZZY THEORY AND ITS APPLICATIONS (IFUZZY2012), P258, DOI 10.1109/iFUZZY.2012.6409712
   Xuan GR, 2010, IEEE INT SYMP CIRC S, P1129, DOI 10.1109/ISCAS.2010.5537323
   Yip SK, 2006, IEEE INT SYMP CIRC S, P1426
   Yip SK, 2005, IEEE IMAGE PROC, P409
   Yung-Chen Chou, 2013, Journal of Electronic Science and Technology, V11, P9, DOI 10.3969/j.issn.1674-862X.2013.01.003
NR 37
TC 18
Z9 19
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2131
EP 2157
DI 10.1007/s11042-015-3161-9
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000025
DA 2024-07-18
ER

PT J
AU Lin, TL
   Ding, TL
   Fan, CY
   Chen, WC
AF Lin, Ting-Lan
   Ding, Tsai-Ling
   Fan, Chang-Yi
   Chen, Wen-Chih
TI Error concealment algorithm based on sparse optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video communication; Packet loss; Error concealment; Sparse
   optimization; Primal-dual interior point method
ID ROBUST UNCERTAINTY PRINCIPLES; SIGNAL RECONSTRUCTION; RECOVERY;
   TRANSMISSION
AB In this paper, an application of sparse optimization in the error concealment area is proposed. The spatial and temporal formulations of the pixels in the current frame and reference frame are proposed to solve the problem. Based on the sparse characteristics of nature images, we form sparse optimization problems for both formulations. The optimization problem is solved by the primal-dual interior point method. The solutions are combined for better results. By solving for a limited numbers of significant predictors using the sparse optimization, our algorithm performs subjectively and objectively better for the concealed result; compared to two state-of-the-art spatial-temporal hybrid error concealment methods, the proposed methods can improve by up to 0.19 dB and 1.12 dB in PSNR (Peak Signal-to-Noise Ratio).
C1 [Lin, Ting-Lan; Ding, Tsai-Ling; Fan, Chang-Yi; Chen, Wen-Chih] Chung Yuan Christian Univ, Dept Elect Engn, Chungli, Taiwan.
C3 Chung Yuan Christian University
RP Lin, TL (corresponding author), Chung Yuan Christian Univ, Dept Elect Engn, Chungli, Taiwan.
EM tinglan@cycu.edu.tw; dingtasiling@gmail.com; doublechang015@gmail.com;
   hydexiii@gmail.com
FU National Science Council, Taiwan [NSC 100-2218-E-033-004, NSC
   101-2221-E-033-036, NSC 102-2221-E-033-018]; Ministry of Science and
   Technology, Taiwan [MOST 103-2221-E-033-020, MOST 104-2221-E-033-041,
   MOST 104-2218-E-033-010]
FX This research is supported by the National Science Council, Taiwan under
   Grant NSC 100-2218-E-033-004, NSC 101-2221-E-033-036, NSC
   102-2221-E-033-018, and by the Ministry of Science and Technology,
   Taiwan under Grant MOST 103-2221-E-033-020, MOST 104-2221-E-033-041 and
   MOST 104-2218-E-033-010.
CR Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candès EJ, 2006, FOUND COMPUT MATH, V6, P227, DOI 10.1007/s10208-004-0162-x
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Chen Y, 2005, P IEEE INT C IM PROC, V2, P1050
   David L., 2006, IEEE Trans. Inf. Theory, V52, P1289
   Haupt J, 2006, IEEE T INFORM THEORY, V52, P4036, DOI 10.1109/TIT.2006.880031
   Lam W. M., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P417, DOI 10.1109/ICASSP.1993.319836
   Lee YC, 2002, IEEE T IMAGE PROCESS, V11, P1314, DOI 10.1109/TIR2002.804275
   Lie WN, 2014, IEEE T MULTIMEDIA, V16, P216, DOI 10.1109/TMM.2013.2281587
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Rane SD, 2003, IEEE T IMAGE PROCESS, V12, P296, DOI 10.1109/TIP.2002.804264
   Salama P, 2000, IEEE J SEL AREA COMM, V18, P1129, DOI 10.1109/49.848263
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   WANG Y, 1993, IEEE T COMMUN, V41, P1544, DOI 10.1109/26.237889
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yan B, 2012, IEEE T MULTIMEDIA, V14, P936, DOI 10.1109/TMM.2012.2184743
   Zhang Yongbing, 2012, IEEE T CIRCUIT SYSTE, V22
   Zhou J, 2011, IEEE T BROADCAST, V57, P75, DOI 10.1109/TBC.2010.2086771
   Zhou Y, 2015, IEEE SENS J, V15, P1892, DOI 10.1109/JSEN.2014.2366511
   Zhu WW, 1998, IEEE T CIRC SYST VID, V8, P713, DOI 10.1109/76.728413
NR 21
TC 8
Z9 9
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 397
EP 413
DI 10.1007/s11042-015-3056-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000018
DA 2024-07-18
ER

PT J
AU Lu, TC
AF Lu, Tzu-Chuen
TI Adaptive (<i>k</i>, <i>F</i> <sub>1</sub>) interpolation-based hiding
   scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image interpolation; Semi-reversible information hiding; Center folding;
   Adaptive thresholds
ID EXPANSION
AB In 2012, Lee et al. proposed an interpolation technique with neighboring pixels (INP) as the base to conceal secret information in predicted pixels. Their method can effectively predict the pixel between two neighboring pixels. However, the different lengths of secret messages caused great distortion when a large secret message was concealed in the predicted value. Therefore, the proposed scheme applies the center folding strategy to fold the secret message for reducing image distortion. Furthermore, the proposed scheme references the variance of the neighboring pixel to determine the length of the secret message for controlling image quality. The parameter pair (k, F (1)) is used to categorize the variance and determine the size of the secret message hidden in each category. k is the total number of thresholds which computed based on the characteristics of each image for balancing hiding payload and image quality. F (1) is the length of the secret message for the smoothest area. The experimental results show that the embedding capacity of the proposed method is 1.5 bpp higher than that of existing methods. For the same hiding payload, the image quality of the proposed method is 1.6 dB higher than that of existing methods.
C1 [Lu, Tzu-Chuen] Chaoyang Univ Technol, Dept Informat Management, 168 Jifeng East Rd, Taichung 41349, Taiwan.
C3 Chaoyang University of Technology
RP Lu, TC (corresponding author), Chaoyang Univ Technol, Dept Informat Management, 168 Jifeng East Rd, Taichung 41349, Taiwan.
EM tclu@cyut.edu.tw
FU MOST from Taiwan's Ministry of Science and Technology [MOST
   103-2221-E-324 -014 -]
FX This study was financially supported by a Research Grant, MOST, from
   Taiwan's Ministry of Science and Technology (MOST 103-2221-E-324 -014
   -).
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Boehm B., 2014, STEGEXPOSE STEGANALY
   Fridrich J., 2001, P ACM WORKSH MULT SE, P27
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Li J, 2013, SIGNAL PROCESS, V93, P2748, DOI 10.1016/j.sigpro.2013.01.020
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Tang MW, 2014, OPTIK, V125, P3972, DOI 10.1016/j.ijleo.2014.01.149
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wittman T, 2015, MATH TECHNIQUES IMAG
NR 10
TC 5
Z9 5
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 1827
EP 1855
DI 10.1007/s11042-015-3168-2
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000011
DA 2024-07-18
ER

PT J
AU Nguyen, QH
   Vu, H
   Tran, TH
   Nguyen, QH
AF Quoc-Hung Nguyen
   Hai Vu
   Thanh-Hai Tran
   Quang-Hoan Nguyen
TI Developing a way-finding system on mobile robot assisting visually
   impaired people in an indoor environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual odometry; Environmental map; Vision-based localization; Assistive
   technology for visually impaired; Indoor navigation
ID LOCALIZATION; SLAM
AB A way-finding system in an indoor environment consists of several components: localization, representation, path planning, and interaction. For each component, numerous relevant techniques have been proposed. However, deploying feasible techniques, particularly in real scenarios, remains challenging. In this paper, we describe a functional way-finding system deployed on a mobile robot to assist visual impairments (VI). The proposed system deploys state-of-the-art techniques that are adapted to the practical issues at hand. First, we adapt an outdoor visual odometry technique to indoor use by covering manual markers or stickers on ground-planes. The main purpose is to build reliable travel routes in the environment. Second, we propose a procedure to define and optimize the landmark/representative scenes of the environment. This technique handles the repetitive and ambiguous structures of the environment. In order to interact with VI people, we deploy a convenient interface on a smart phone. Three different indoor scenarios and thirteen subjects are conducted in our evaluations. Our experimental results show that VI people, particularly VI pupils, can find the right way to requested targets.
C1 [Quoc-Hung Nguyen; Hai Vu; Thanh-Hai Tran] Hanoi Univ Sci & Technol, CNRS, Int Res Inst MICA, UMI 2954,INP Grenoble, Hanoi, Vietnam.
   [Quoc-Hung Nguyen] Thai Nguyen Med Coll, Thai Nguyen, Vietnam.
   [Quang-Hoan Nguyen] Hung Yen Univ Technol & Educ, Hung Yen, Vietnam.
C3 Hanoi University of Science & Technology (HUST)
RP Nguyen, QH (corresponding author), Hanoi Univ Sci & Technol, CNRS, Int Res Inst MICA, UMI 2954,INP Grenoble, Hanoi, Vietnam.; Nguyen, QH (corresponding author), Thai Nguyen Med Coll, Thai Nguyen, Vietnam.
EM quoc-hung.nguyen@mica.edu.vn
RI Vu, Hai/AAI-9419-2020
OI Vu, Hai/0000-0003-2880-4417; - Khoa Cong nghe thong tin kinh doanh,
   Nguyen Quoc Hung/0000-0002-6363-0160
FU Vietnam National Foundation for Science and Technology Development
   (NAFOSTED) [FWO.102.2013.08]
FX This research is funded by Vietnam National Foundation for Science and
   Technology Development (NAFOSTED) under grant number FWO.102.2013.08.
CR Alcantarilla FP, 2011, THESIS
   [Anonymous], 2008, ASSISTIVE TECHNOLOGY
   [Anonymous], 2010, 2010 IEEE COMP SOC C
   Bailey T, 2006, IEEE ROBOT AUTOM MAG, V13, P108, DOI 10.1109/MRA.2006.1678144
   Bigham JeffreyP., 2010 IEEE COMPUTER S, DOI DOI 10.1109/CVPRW.2010.5543821
   CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961
   Dakopoulos D, 2010, IEEE T SYST MAN CY C, V40, P25, DOI 10.1109/TSMCC.2009.2021255
   Endres H, 1998, P INT C ROB AUT
   Fallah N, 2013, INTERACT COMPUT, V25, P21, DOI 10.1093/iwc/iws010
   Fraundorfer F, 2012, IEEE ROBOT AUTOM MAG, V19, P78, DOI 10.1109/MRA.2012.2182810
   HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136
   Helal A, 2001, FIFTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P149, DOI 10.1109/ISWC.2001.962119
   King S, 1990, P SPIE C MOB ROB BOS, P190
   Korf R.E., 1985, P 9 INT JOINT C ART, V2, P1034
   Kulyukin V, 2006, AUTON ROBOT, V21, P29, DOI 10.1007/s10514-006-7223-8
   Lacey G, 1998, ROBOT AUTON SYST, V23, P245, DOI 10.1016/S0921-8890(98)00011-6
   LaMarca A, 2002, P INT C PERV COMP
   Lehel P, 1999, IEEE COMP SOC C COMP, V2
   Liu J.J., IEEE C COMPUTER VISI, DOI [DOI 10.1109/CVPRW.2010.5543581, 10.1109/CVPRW.2010.5543581.]
   Loomis JM, 2001, KLATZKY GPS BASED NA, P429
   Murali Vidya N, 2013, IEEE Int Conf Multimed Expo Workshops, V2013, P1
   Newman P, 2005, IEEE INT CONF ROBOT, P635
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Pradeep V, 2010, PROC CVPR IEEE, P1514, DOI 10.1109/CVPR.2010.5539792
   Schindler G., 2007, P IEEE C COMP VIS PA, V2007, P1
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Sünderhauf N, 2011, IEEE INT C INT ROBOT, P1234, DOI 10.1109/IROS.2011.6048590
   Van Hamme D, 2011, LECT NOTES COMPUT SC, V6915, P1, DOI 10.1007/978-3-642-23687-7_1
   VladimirKulyukin ChaitanyaGharpure, 2004, P IEEE RSJ INT C INT, V2, P1979
NR 31
TC 21
Z9 24
U1 0
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2645
EP 2669
DI 10.1007/s11042-015-3204-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000047
DA 2024-07-18
ER

PT J
AU Lee, JH
   Kim, D
   Shin, BS
AF Lee, Jin-Hee
   Kim, Dongho
   Shin, Byeong-Seok
TI A wearable guidance system with interactive user interface for persons
   with visual impairment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Guidance system; Wearable computer; User interface; Multi-sensor
   interface
AB We propose a wearable system that helps visually impaired persons to walk to their destination. After a destination is selected, our system computes an optimal path and guides the user with a marker position and its identifier detected by a camera (indoors) or positioning data from a GPS receiver (outdoors). Simultaneously, it utilizes multiple ultrasonic sensors to avoid obstacles lying in the path. In addition, we propose a fast correction algorithm to reduce the positioning error of GPS data and we deploy a map-matching algorithm when the user breaks away from the correct path. We evaluate spatial layout in front of the user on the basis of predefined patterns, and we determine the appropriate avoidance direction by analysing these patterns. The system safely guides a visually impaired person to the destination with interactive user interface.
C1 [Lee, Jin-Hee; Shin, Byeong-Seok] Inha Univ, Dept Comp Sci & Informat Engn, 100 Inha Ro, Inchon 402751, South Korea.
   [Kim, Dongho] Soongsil Univ, Global Sch Media, 369 Sangdo Ro, Seoul 156743, South Korea.
C3 Inha University; Soongsil University
RP Shin, BS (corresponding author), Inha Univ, Dept Comp Sci & Informat Engn, 100 Inha Ro, Inchon 402751, South Korea.
EM jhlee07@outlook.com; cg@su.ac.kr; bsshin@inha.ac.kr
FU Next-Generation Information Computing Development Program through the
   National Research Foundation of Korea(NRF) - Ministry of Science, ICT &
   Future Planning [2012M3C4A7032781]; INHA UNIVERSITY Research Grant
FX This research was supported by Next-Generation Information Computing
   Development Program through the National Research Foundation of
   Korea(NRF) funded by the Ministry of Science, ICT & Future Planning (No.
   2012M3C4A7032781). This work was supported by INHA UNIVERSITY Research
   Grant.
CR Andò B, 2009, IEEE T INSTRUM MEAS, V58, P2488, DOI 10.1109/TIM.2009.2014616
   [Anonymous], 1999, P 2 IEEE ACM INT WOR
   Blasch B., 1997, FDN ORIENTATION MOBI, V2nd
   Borenstein J, 1997, IEEE INT CONF ROBOT, P1283, DOI 10.1109/ROBOT.1997.614314
   Cardin S, 2007, VISUAL COMPUT, V23, P109, DOI 10.1007/s00371-006-0032-4
   Chagnaadorj O, 2014, J INF PROCESS SYST, V10, P92, DOI 10.3745/JIPS.2014.10.1.092
   Chang SM, 2013, HUM-CENTRIC COMPUT I, V3, DOI 10.1186/2192-1962-3-14
   Cho H., 2014, J CONVERGENCE, V5, P32
   Choi BS, 2008, ARTIF LIFE ROBOT, V12, P280, DOI 10.1007/s10015-007-0482-4
   Christou G, 2013, HUM-CENT COMPUT INFO, V3, DOI 10.1186/2192-1962-3-15
   Chung CS, 2001, KOREA J SPORT BIOMEC, V10, P205
   Collins CC, 1977, 4 C SYST DEV DIS
   Dakopoulos D, 2008, P 1 INT C PERV TECHN, P607
   Dakopoulos D, 2010, IEEE T SYST MAN CY C, V40, P25, DOI 10.1109/TSMCC.2009.2021255
   Daniel W, 2007, P 12 COMP VIS WINT W
   Fiala Mark., 2004, National Research Council Publication, V47419, P1
   Hameed O, 2007, P 7 WSEAS INT C ROB
   HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136
   Hyon Lim, 2009, 2009 ICROS-SICE International Joint Conference. ICCAS-SICE 2009, P177
   Imai A, 2010, LECT NOTES COMPUT SC, V6180, P367, DOI 10.1007/978-3-642-14100-3_54
   Ito K., 2005, Procedings of CHI05, Portland, OR, P1483, DOI [DOI 10.1145/1056808.1056947, 10.1145]
   Jin-Hee Lee, 2009, Journal of KISS: Software and Applications, V36, P462
   Kang JH, 2006, 21 INT TECHN C CIRC
   Kay L., 1974, Radio and Electronic Engineer, V44, P605, DOI 10.1049/ree.1974.0148
   Kim HN, 2013, INT J HUM-COMPUT INT, V29, P488, DOI 10.1080/10447318.2012.722465
   Kim JH, 2008, MOL VIS, V14, P556
   Kim J, 2008, IEEE T CONSUM ELECTR, V54, P954, DOI 10.1109/TCE.2008.4637573
   Krisna S, 2008, WORKSH COMP VIS APPL
   Lee Hung Liew LHL, 2013, J CONVERGENCE, V4, P15
   Lim H, 2007, J KOREAN I NEXT GENE, V3, P39
   Liu JJ, 2010, COMP VIS PATT REC WO, P13
   Liu X, 2008, IEEE ENG MED BIO, P2377, DOI 10.1109/IEMBS.2008.4649677
   Meers S, 2005, 1 INT C SENS TECHN, P21
   Mori H., 1998, P 2 EUR C DIS VIRT R, P193
   Nakashima Y, 2011, IEICE T INF SYST, VE94D, P2201, DOI 10.1587/transinf.E94.D.2201
   Nakazato Y, 2005, NINTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P198, DOI 10.1109/ISWC.2005.55
   Nakazato Y., 2005, P IAPR C MACH VIS AP, P140
   Nakazato Y, 2008, IEEE T CONSUM ELECTR, V54, P954
   National Geographic Information Institute, 2006, TECHN GUID PUBL SURV, P24
   Pradeep V, 2010, PROC CVPR IEEE, P1514, DOI 10.1109/CVPR.2010.5539792
   Rajamaki Jyri., 2007, P 6 WSEAS INT C ELEC, P96
   Shahabi C, 2014, J INF PROCESS SYST, V10, P1, DOI 10.3745/JIPS.2014.10.1.001
   Shim HM, 2002, 2002 INT C CIRC SYST, P389
   Shoval S, 2003, IEEE ROBOT AUTOM MAG, V10, P9, DOI 10.1109/MRA.2003.1191706
   Soeda K, 2004, P ANN INT IEEE EMBS, V26, P4870
   Tachi S., 1982, IEEE 1982 Frontiers of Engineering in Health Care. Proceedings - Fourth Annual Conference, P356
   Tae-Jung Kim T-JK, 2014, J CONVERGENCE, V5, P14
   Takatori Norihiko, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P5181
   Treuillet S., 2007, P C ASS TECHN PEOPL
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   Verma OP, 2013, J INF PROCESS SYST, V9, P575, DOI 10.3745/JIPS.2013.9.4.575
   Vipparthi SK, 2014, HUM-CENTRIC COMPUT I, V4, DOI 10.1186/s13673-014-0006-x
   White CE, 2000, SOME MAP MATCHING AL, P91
   Yasumuro Y, 2003, LECT NOTES COMPUT SC, V2615, P409
   Yatani K, 2009, P UIST
   Zhang Z., 1998, A Flexible New Technique for Camera Calibration
NR 56
TC 9
Z9 9
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15275
EP 15296
DI 10.1007/s11042-014-2385-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700010
DA 2024-07-18
ER

PT J
AU Mishra, D
AF Mishra, Dheerendra
TI Design of a password-based authenticated key exchange protocol for SIP
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Session initiation protocol (SIP); Elliptic curve cryptography (ECC);
   Authentication; Key agreement; Anonymity
ID SECURE AUTHENTICATION; PROVABLY SECURE; EFFICIENT AUTHENTICATION;
   AGREEMENT SCHEME
AB The Session Initiation Protocol (SIP) is a signaling communications protocol, which has been chosen for controlling multimedia communication in 3G mobile networks. In recent years, password-based authenticated key exchange protocols are designed to provide strong authentication for SIP. In this paper, we address this problem in two-party setting where the user and server try to authenticate each other, and establish a session key using a shared password. We aim to propose a secure and anonymous authenticated key exchange protocol, which can achieve security and privacy goal without increasing computation and communication overhead. Through the analysis, we show that the proposed protocol is secure, and has computational and computational overheads comparable to related authentication protocols for SIP using elliptic curve cryptography. The proposed protocol is also provably secure in the random oracle model.
C1 [Mishra, Dheerendra] LNM Inst Informat Technol, Dept Math, Jaipur 302031, Rajasthan, India.
C3 LNM Institute of Information Technology
RP Mishra, D (corresponding author), LNM Inst Informat Technol, Dept Math, Jaipur 302031, Rajasthan, India.
EM dheerendra.mishra@lnmiit.ac.in
RI Mishra, Dheerendra/C-4208-2017
OI Mishra, Dheerendra/0000-0001-8115-6397
CR Abdalla M, 2005, LECT NOTES COMPUT SC, V3570, P341
   [Anonymous], 1995, 1801 FIPS PUB NIST U
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2003, SECURITY MECH AGREEM
   [Anonymous], MATH PHYS SCI
   [Anonymous], 2006, Computing, V1, P1
   [Anonymous], P ICCSN
   [Anonymous], IACR CRYPTOL EPRINT
   [Anonymous], IETF INTEM IN PRESS
   Arshad R, 2013, MULTIMED TOOLS APPL, V66, P165, DOI 10.1007/s11042-011-0787-0
   Bellare M., 1996, Advances in Cryptology - CRYPTO'96. 16th Annual International Cryptology Conference. Proceedings, P1
   Boyd C., 1994, Advances in Cryptology - EUROCRYPT '93. Workshop on the Theory and Application of Cryptographic Techniques Proceedings, P240
   DOLEV D, 1983, IEEE T INFORM THEORY, V29, P198, DOI 10.1109/TIT.1983.1056650
   Durlanik A, 2005, PROC WRLD ACAD SCI E, V8, P350
   Farash MS, 2016, PEER PEER NETW APPL, V9, P82, DOI 10.1007/s12083-014-0315-x
   Farash MS, 2016, MULTIMED TOOLS APPL, V75, P405, DOI 10.1007/s11042-014-2296-4
   Farash MS, 2013, INF TECHNOL CONTROL, V42, P333, DOI 10.5755/j01.itc.42.4.2496
   He DB, 2015, MULTIMEDIA SYST, V21, P49, DOI 10.1007/s00530-013-0346-9
   He DB, 2012, SECUR COMMUN NETW, V5, P1423, DOI 10.1002/sec.506
   He DB, 2012, INFORM FUSION, V13, P223, DOI 10.1016/j.inffus.2011.01.001
   Heasuk Jo, 2009, Proceedings of the 2009 Fifth International Joint Conference on INC, IMS and IDC, P618, DOI 10.1109/NCM.2009.251
   Irshad A, 2015, MULTIMED TOOLS APPL, V74, P3967, DOI 10.1007/s11042-013-1807-z
   Islam SKH, 2014, NONLINEAR DYNAM, V78, P2261, DOI 10.1007/s11071-014-1584-x
   Jiang Q, 2015, INT J COMMUN SYST, V28, P1340, DOI 10.1002/dac.2767
   Kolbitz N., 1987, MATH COMPUT, V48, P203
   MILLER VS, 1986, LECT NOTES COMPUT SC, V218, P417, DOI 10.1007/3-540-39799-x_31
   Mishra Dheerendra, 2013, Information Systems Security. 9th International Conference, ICISS 2013. Proceedings: LNCS 8303, P247, DOI 10.1007/978-3-642-45204-8_19
   Riaz S, 2014, MULTIMED TOOLS APPL, V73, P1291, DOI 10.1007/s11042-013-1592-8
   Rosenberg J., 2002, TECHNICAL REPORT
   Salsano S, 2002, IEEE NETWORK, V16, P38, DOI 10.1109/MNET.2002.1081764
   Syverson P., 2001, Foundations of Security Analysis and Design (FOSAD 2000), V2171, P63, DOI [DOI 10.1007/3-540-45608-2_2, 10.1007/3-540-45608-2_2.pdf, DOI 10.1007/3-540-45608-2_2.PDF]
   Tsai J.L., 2009, Int J Netw Secur, V9, P12
   Tu H, 2015, PEER PEER NETW APPL, V8, P903, DOI 10.1007/s12083-014-0248-4
   Wu LF, 2009, COMPUT STAND INTER, V31, P286, DOI 10.1016/j.csi.2008.01.002
   Wu SH, 2013, PEER PEER NETW APPL, V6, P61, DOI 10.1007/s12083-012-0129-7
   Xie Q, 2012, INT J COMMUN SYST, V25, P47, DOI 10.1002/dac.1286
   Xu J, 2009, COMPUT STAND INTER, V31, P723, DOI 10.1016/j.csi.2008.09.006
   Yang CC, 2005, COMPUT SECUR, V24, P381, DOI 10.1016/j.cose.2004.10.007
   Yeh HL, 2014, COMPUT STAND INTER, V36, P397, DOI 10.1016/j.csi.2013.08.010
   Yi XW, 2014, MULTIMED TOOLS APPL, V71, P1913, DOI 10.1007/s11042-012-1324-5
   Yoon EJ, 2010, COMPUT COMMUN, V33, P1674, DOI 10.1016/j.comcom.2010.03.026
   Yoon EJ, 2010, IETE TECH REV, V27, P203, DOI 10.4103/0256-4602.62780
   Zhang LP, 2014, INT J COMMUN SYST, V27, P2691, DOI 10.1002/dac.2499
   Zhang ZZ, 2015, MULTIMED TOOLS APPL, V74, P3477, DOI 10.1007/s11042-014-1885-6
NR 44
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16017
EP 16038
DI 10.1007/s11042-015-2911-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700051
DA 2024-07-18
ER

PT J
AU Fang, ZJ
   Fei, FC
   Fang, YM
   Lee, C
   Xiong, NX
   Shu, L
   Chen, S
AF Fang, Zhijun
   Fei, Fengchang
   Fang, Yuming
   Lee, Changhoon
   Xiong, Naixue
   Shu, Lei
   Chen, Sheng
TI Abnormal event detection in crowded scenes based on deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Abnormal event detection; Crowd analysis; Saliency information; Optical
   flow; Deep learning
ID SALIENT REGION DETECTION; QUALITY ASSESSMENT; DETECTION MODEL;
   RECOGNITION; IMAGE
C1 [Fang, Zhijun; Fei, Fengchang; Fang, Yuming; Xiong, Naixue; Shu, Lei; Chen, Sheng] Jiangxi Univ Finance & Econ, Sch Informat Technol, Nanchang 330032, Peoples R China.
   [Fang, Zhijun] Shanghai Univ Engn Sci, Sch Elect & Elect Engn, Shanghai 201620, Peoples R China.
   [Fei, Fengchang] Jiangxi Univ Finance & Econ, Modern Econ & Management Coll, Nanchang 330013, Peoples R China.
   [Lee, Changhoon] Seoul Natl Univ Sci & Technol, Dept Computat Sci & Engn, Seoul, South Korea.
C3 Jiangxi University of Finance & Economics; Shanghai University of
   Engineering Science; Jiangxi University of Finance & Economics; Seoul
   National University of Science & Technology
RP Fang, YM (corresponding author), Jiangxi Univ Finance & Econ, Sch Informat Technol, Nanchang 330032, Peoples R China.
EM fa0001ng@e.ntu.edu.sg; nxiong@coloradotech.edu
RI xiong, naixue/M-4277-2019; Shu, Lei/JQW-2386-2023
OI xiong, naixue/0000-0002-0394-4635; Lee, Changhoon/0000-0003-4292-5792;
   Shu, Lei/0000-0002-6700-9347
FU National Natural Science Foundation of China [61461021, 61571212]; Key
   Academic Leader Plan in Jiangxi Province [20133BCB22005]; Key Project in
   Science and Technology from the Education Department of Jiangxi Province
   [GJJ14318]; Foreign Cooperation Foundation from the Science and
   Technology Department of Jiangxi Province [20151BDH80003, 20141BDH80003]
FX This research was supported partially by the National Natural Science
   Foundation of China (No. 61461021, 61571212), the Key Academic Leader
   Plan in Jiangxi Province (No. 20133BCB22005), the Key Project in Science
   and Technology from the Education Department of Jiangxi Province (No.
   GJJ14318) and the Foreign Cooperation Foundation from the Science and
   Technology Department of Jiangxi Province (No. 20151BDH80003,
   20141BDH80003).
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   Andrade EL, 2006, INT C PATT RECOG, P175
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Baumgartner T, 2013, PROC CVPR IEEE, P3658, DOI 10.1109/CVPR.2013.469
   Benezeth Y., 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2458, DOI 10.1109/CVPRW.2009.5206686
   Chan TH, PCANET SIMP IN PRESS
   Cheng G., 2008, TRANSPORTATION RES B, P1
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Cong Y, 2013, IEEE T INF FOREN SEC, V8, P1590, DOI 10.1109/TIFS.2013.2272243
   Fang YM, 2012, IEEE T MULTIMEDIA, V14, P187, DOI 10.1109/TMM.2011.2169775
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Gopalakrishnan V, 2009, IEEE T MULTIMEDIA, V11, P892, DOI 10.1109/TMM.2009.2021726
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Han J, 2012, MOR KAUF D, P1
   Hassner T., 2012, 2012 IEEE COMP SOC C, P1, DOI [DOI 10.1109/CVPRW.2012.6239348, 10.1109/CVPRW.2012.6239348]
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Keyvanrad MA, 2014, INT C LEARN IN PRESS
   Kwon J, 2013, PROC CVPR IEEE, P2355, DOI 10.1109/CVPR.2013.305
   Lee YS, 2012, SENSORS-BASEL, V12, P573, DOI 10.3390/s120100573
   Liu Y, 2014, INT J SIGN PROC IMAG, V7, P115
   Ma RH, 2004, 2004 IEEE CONFERENCE ON CYBERNETICS AND INTELLIGENT SYSTEMS, VOLS 1 AND 2, P170
   Mehran R, 2009, C VIS PATT REC
   Mehran R, 2010, LECT NOTES COMPUT SC, V6313, P439
   Popoola OP, 2012, IEEE T SYST MAN CY C, V42, P865, DOI 10.1109/TSMCC.2011.2178594
   Rasheed N, 2014, 2014 28TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS (WAINA), P61, DOI 10.1109/WAINA.2014.18
   Ren XF, 2013, PROC CVPR IEEE, P3246, DOI 10.1109/CVPR.2013.417
   Sang-Hyun Cho, 2012, Proceedings of the 2012 IEEE Southwest Symposium on Image Analysis & Interpretation (SSIAI 2012), P113, DOI 10.1109/SSIAI.2012.6202466
   Shao F, IEEE T BROA IN PRESS
   Shao F, 2014, DIGIT SIGNAL PROCESS, V29, P45, DOI 10.1016/j.dsp.2014.03.003
   Shao F, 2013, IEEE T IMAGE PROCESS, V22, P1940, DOI 10.1109/TIP.2013.2240003
   Shu G, 2013, PROC CVPR IEEE, P3721, DOI 10.1109/CVPR.2013.477
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Supancic JS, 2013, PROC CVPR IEEE, P2379, DOI 10.1109/CVPR.2013.308
   Suriani NS, 2013, SENSORS-BASEL, V13, P9966, DOI 10.3390/s130809966
   Thida M, 2013, IEEE T CYBERNETICS, V43, P2147, DOI 10.1109/TCYB.2013.2242059
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Valenti R, 2009, IEEE I CONF COMP VIS, P2185, DOI 10.1109/ICCV.2009.5459240
   Vapnik V., 1999, NATURE STAT LEARNING
   Varadarajan Jagannadan, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1338, DOI 10.1109/ICCVW.2009.5457456
   Wang LJ, 2012, IEEE IMAGE PROC, P2701, DOI 10.1109/ICIP.2012.6467456
   Wang T, 2014, IEEE T INF FOREN SEC, V9, P988, DOI 10.1109/TIFS.2014.2315971
   Wang T, 2013, SENSORS-BASEL, V13, P17130, DOI 10.3390/s131217130
   Xinyi Cui, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3161, DOI 10.1109/CVPR.2011.5995558
   Yang JM, 2012, PROC CVPR IEEE, P2296, DOI 10.1109/CVPR.2012.6247940
   Yuan JS, 2011, IEEE T PATTERN ANAL, V33, P1728, DOI 10.1109/TPAMI.2011.38
   Zhang L, 2013, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2013.240
   Zhang YH, 2012, IEEE IMAGE PROC, P2689, DOI 10.1109/ICIP.2012.6467453
   Zhang YH, IEEE T CIRC IN PRESS
NR 52
TC 71
Z9 76
U1 0
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14617
EP 14639
DI 10.1007/s11042-016-3316-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500037
DA 2024-07-18
ER

PT J
AU Feng, WN
   Zhang, ZY
   Wang, J
   Han, LQ
AF Feng, Weining
   Zhang, Zhiyong
   Wang, Jian
   Han, Linqian
TI A novel authorization delegation scheme for multimedia social networks
   by using proxy re-encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia social networks; Multimedia security; Authorization;
   Delegation; Proxy re-encryption; Digital rights management
ID ACCESS-CONTROL; SECURE; PRIVACY; MODEL
AB To solve the existing problem of the multimedia social networks platforms, for instance, the copyrighted or private multimedia content can not be safely shared among users, we proposed a novel authorization delegation scheme based on the proxy re-encryption mechanism. This scheme enables one user to delegate digital rights/privileges to another or the group of users, and achieves fine-grained authorization delegation. The ciphertext of content encryption key (CEK) was re-encrypted by the proxy with re-encryption key, which is generated by delegator, and then the ciphertext was sent to the delegatee only who could decrypt the ciphertext. The CCA security of proxy re-encryption was formally proved that this scheme realized the authorization delegation while ensuring the confidentiality of both the sharing content and the delegator's private key. Besides, the privileges can be revoked when the usage control policies have not yet been satisfied. Finally, we demonstrated in detail that the proposed scheme was applied to a multimedia social network prototype called by CyVOD MSN, and it achieved the security share of multimedia content and the functionality of digital rights management, together with better resolving the issue of limited access control list.
C1 [Feng, Weining; Zhang, Zhiyong; Wang, Jian; Han, Linqian] Henan Univ Sci & Technol, Informat Engn Coll, Luoyang 471023, Peoples R China.
   [Zhang, Zhiyong] Iowa State Univ, Dept Comp Sci, Ames, IA 50010 USA.
C3 Henan University of Science & Technology; Iowa State University
RP Zhang, ZY (corresponding author), Henan Univ Sci & Technol, Informat Engn Coll, Luoyang 471023, Peoples R China.; Zhang, ZY (corresponding author), Iowa State Univ, Dept Comp Sci, Ames, IA 50010 USA.
EM xidianzzy@126.com
RI ZHANG, Zhiyong/AAG-3281-2021
OI ZHANG, Zhiyong/0000-0003-3061-7768
FU National Natural Science Foundation of China [61370220]; Program for
   Innovative Research Team (in Science and Technology) in University of
   Henan Province [15IRTSTHN010]; Plan For Scientific Innovation Talent of
   Henan Province [134100510006]; Program for Henan Province Science and
   Technology [142102210425]; Key Program for Basic Research of The
   Education Department of Henan Province [13A520240, 14A520048]; Training
   Foundation for Scientific Innovation Ability of Henan University of
   Science and Technology Grand [2013ZCX022]; Plan For Innovation Fund for
   Postgraduates of Henan University of Science Technology [CXJJ-ZR12]
FX The work was sponsored by National Natural Science Foundation of China
   Grant No. 61370220, Program for Innovative Research Team (in Science and
   Technology) in University of Henan Province Grant No. 15IRTSTHN010, Plan
   For Scientific Innovation Talent of Henan Province Grant No.
   134100510006, Program for Henan Province Science and Technology Grant
   No. 142102210425, Key Program for Basic Research of The Education
   Department of Henan Province Grant No. 13A520240 and No. 14A520048,
   Training Foundation for Scientific Innovation Ability of Henan
   University of Science and Technology Grand No. 2013ZCX022, Plan For
   Innovation Fund for Postgraduates of Henan University of Science &
   Technology Grant No. CXJJ-ZR12. We give thanks to Dr. Changwei Zhao,
   Ranran Sun for their technical assistance on CyVOD MSN prototype, and
   also would like to thank the reviewers and editor for their valuable
   comments, questions, and suggestions.
CR Ateniese G, 2009, LECT NOTES COMPUT SC, V5473, P279, DOI 10.1007/978-3-642-00862-7_19
   Blaze M, 1998, LECT NOTES COMPUT SC, V1403, P127, DOI 10.1007/BFb0054122
   Devigne J, 2014, LECT NOTES COMPUT SC, V8469, P13
   Fabian B, 2015, INFORM SYST, V48, P132, DOI 10.1016/j.is.2014.05.004
   Fotiou N, 2014, IEEE CONF COMPUT, P13, DOI 10.1109/INFCOMW.2014.6849161
   Fu ZJ, 2015, IEICE T COMMUN, VE98B, P190, DOI 10.1587/transcom.E98.B.190
   González-Manzano L, 2014, COMPUT SECUR, V43, P159, DOI 10.1016/j.cose.2014.03.009
   Green M, 2007, LECT NOTES COMPUT SC, V4521, P288
   Hu HX, 2013, IEEE T KNOWL DATA EN, V25, P1614, DOI 10.1109/TKDE.2012.97
   Huang QL, 2014, CHINA COMMUN, V11, P104, DOI 10.1109/CC.2014.6825263
   Jahid Sonia., 2011, Proceedings of the 6th ACM Symposium on Information, Computer and Communications Security, P411
   Jinhong Cui, 2009, Proceedings of the 2009 International Conference on Computational Intelligence and Security (CIS 2009), P493, DOI 10.1109/CIS.2009.212
   Juhrisch M, 2012, INF RESOUR MANAG J, V25, P98, DOI 10.4018/irmj.2012070105
   Kaiiali M, 2013, FUTURE GENER COMP SY, V29, P1909, DOI 10.1016/j.future.2013.04.010
   Külcü Ö, 2014, INT J INFORM MANAGE, V34, P761, DOI 10.1016/j.ijinfomgt.2014.07.006
   Li M, 2012, J INTELL INF SYST, V39, P611, DOI 10.1007/s10844-012-0205-8
   Liang K, 2014, FUTURE GENER COMP SY, V52, P1
   Liang KT, 2014, THEOR COMPUT SCI, V539, P87, DOI 10.1016/j.tcs.2014.04.027
   Liang Xiaohui., 2009, ASIACCS 09, P276, DOI DOI 10.1145/1533057.1533094
   Liu J, 2014, FUTURE GENER COMP SY, V52, P1
   Liu Q, 2014, INFORM SCIENCES, V258, P355, DOI 10.1016/j.ins.2012.09.034
   Park J., 2004, ACM Transactions on Information and Systems Security, V7, P128, DOI 10.1145/984334.984339
   Raji F, 2013, COMPUT ELECTR ENG, V39, P2282, DOI 10.1016/j.compeleceng.2012.09.002
   Ranjbar A, 2014, COMPUT COMMUN, V41, P11, DOI 10.1016/j.comcom.2014.01.002
   Ruan C, 2014, DISTRIB PARALLEL DAT, V32, P245, DOI 10.1007/s10619-012-7120-4
   Seo JW, 2013, IEEE T INFORM THEORY, V59, P3256, DOI 10.1109/TIT.2012.2236606
   Shao J, 2012, INFORM SCIENCES, V206, P83, DOI 10.1016/j.ins.2012.04.013
   Sohr K, 2012, INFORM SOFTWARE TECH, V54, P1396, DOI 10.1016/j.infsof.2012.06.008
   Son J, 2014, IEEE CONF COMPUT, P541, DOI 10.1109/INFCOMW.2014.6849289
   Wu TS, 2014, INFORM SCIENCES, V278, P577, DOI 10.1016/j.ins.2014.03.075
   Xia ZH, 2016, IEEE T PARALL DISTR, V27, P340, DOI 10.1109/TPDS.2015.2401003
   Zhang Z., 2014, MULTIMED TOOLS APPL, P1
   Zhang ZY, 2007, IFIP INT C NETW PARA, P238, DOI 10.1109/NPC.2007.103
NR 33
TC 18
Z9 18
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13995
EP 14014
DI 10.1007/s11042-015-2929-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800052
DA 2024-07-18
ER

PT J
AU Fan, C
   Wang, LZ
   Liu, P
   Lu, K
   Liu, DS
AF Fan, Cong
   Wang, Lizhe
   Liu, Peng
   Lu, Ke
   Liu, Dingsheng
TI Compressed sensing based remote sensing image reconstruction via
   employing similarities of reference images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed sensing; Image reconstruction; Prior information
ID TEXTURE CLASSIFICATION; SIGNAL RECOVERY; WAVELET
AB In the traditional reconstruction algorithm for compressed sensing, we use the measurement matrix and the corresponding observed image to recover the target image. In the application of remote sensing, there are many multi-source and multi-temporal reference images that have similar information to that of the target image. In this paper, we propose an algorithm to reconstruct the target image with information from multi-source and multi-temporal reference images to improve the image reconstruction accuracy, in other words, to improve the degree of similarity between the reconstructed image and the target image. The basic principle of our method is to construct a penalty term with the similarity of the target sparse coefficient and the reference sparse coefficient to constrain the reconstruction process. The experimental results demonstrate the effectiveness of our method.
C1 [Fan, Cong; Wang, Lizhe; Liu, Peng; Liu, Dingsheng] Chinese Acad Sci, Inst Remote Sensing & Digital Earth, Beijing 100094, Peoples R China.
   [Wang, Lizhe] China Univ Geosci, Sch Comp Sci, Wuhan 430074, Peoples R China.
   [Lu, Ke] Univ Chinese Acad Sci, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; The Institute of Remote Sensing & Digital
   Earth, CAS; China University of Geosciences; Chinese Academy of
   Sciences; University of Chinese Academy of Sciences, CAS
RP Wang, LZ (corresponding author), Chinese Acad Sci, Inst Remote Sensing & Digital Earth, Beijing 100094, Peoples R China.; Wang, LZ (corresponding author), China Univ Geosci, Sch Comp Sci, Wuhan 430074, Peoples R China.
EM wanglz@radi.ac.cn
RI Liu, Peng/KMX-5167-2024; Wang, Lizhe/L-7453-2014
OI Wang, Lizhe/0000-0003-2766-0845
FU National Natural Science Foundation of China [41471368, 41571413]
FX This work is supported by the National Natural Science Foundation of
   China (No. 41471368 and No. 41571413).
CR Abramovich F, 1998, J ROY STAT SOC B, V60, P725, DOI 10.1111/1467-9868.00151
   BASSEVILLE M, 1992, IEEE T INFORM THEORY, V38, P766, DOI 10.1109/18.119735
   Blumensath T, 2009, APPL COMPUT HARMON A, V27, P265, DOI 10.1016/j.acha.2009.04.002
   Busch A, 2005, IEEE T PATTERN ANAL, V27, P1720, DOI 10.1109/TPAMI.2005.227
   Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010
   Chipman HA, 1997, J AM STAT ASSOC, V92, P1413, DOI 10.2307/2965411
   Chou K. C., 1994, Proceedings of the IEEE-SP International Symposium on Time-Frequency and Time-Scale Analysis (Cat. No.94TH8007), P25, DOI 10.1109/TFSA.1994.467371
   DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6
   David L., 2006, IEEE Trans. Inf. Theory, V52, P1289
   Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Kim SC, 2007, PATTERN RECOGN, V40, P1207, DOI 10.1016/j.patcog.2006.09.012
   Kokare M, 2003, TENCON IEEE REGION, P571, DOI 10.1109/TENCON.2003.1273228
   Kokare M, 2002, IETE J RES, V48, P261, DOI 10.1080/03772063.2002.11416285
   Kokare M, 2002, ICVGIP
   Kokare M, 2007, PATTERN RECOGN LETT, V28, P1240, DOI 10.1016/j.patrec.2007.02.006
   Lee N, 1996, PROCEEDINGS OF THE IEEE-SP INTERNATIONAL SYMPOSIUM ON TIME-FREQUENCY AND TIME-SCALE ANALYSIS, P13, DOI 10.1109/TFSA.1996.546674
   LUETTGEN MR, 1993, IEEE T SIGNAL PROCES, V41, P3377, DOI 10.1109/78.258081
   Majumdar A, 2010, SIGNAL PROCESS, V90, P3122, DOI 10.1016/j.sigpro.2010.05.016
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Mojsilovic A, 2000, IEEE T IMAGE PROCESS, V9, P2043, DOI 10.1109/83.887972
   Muneeswaran K, 2005, PATTERN RECOGN, V38, P1495, DOI 10.1016/j.patcog.2005.03.021
   Nagesh P, 2009, INT CONF ACOUST SPEE, P1261, DOI 10.1109/ICASSP.2009.4959820
   Needell D, 2009, APPL COMPUT HARMON A, V26, P301, DOI 10.1016/j.acha.2008.07.002
   Pesquet JC, 1996, INT CONF ACOUST SPEE, P2634, DOI 10.1109/ICASSP.1996.548005
   Ravindran A., 2006, Engineering optimization: methods and applications
   Rubinstein R, 2010, P IEEE, V98, P1045, DOI 10.1109/JPROC.2010.2040551
   SHANNON CE, 1949, P IRE, V37, P10, DOI 10.1109/JRPROC.1949.232969
   Simoncelli EP, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL I, P379
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Zhang ZL, 2013, IEEE T SIGNAL PROCES, V61, P2009, DOI 10.1109/TSP.2013.2241055
NR 32
TC 13
Z9 13
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 12201
EP 12225
DI 10.1007/s11042-015-3004-8
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200034
DA 2024-07-18
ER

PT J
AU Fan, D
   Wei, L
   Cao, MY
AF Fan, Di
   Wei, Lu
   Cao, Maoyong
TI Extraction of target region in lung immunohistochemical image based on
   artificial neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial neural network (ANN); Immunohistochemistry; Morphological
   operations; Region segmentation
ID ALGORITHM; DIAGNOSIS
AB Immunohistochemistry is widely used in clinical pathology analysis and diagnosis, the target regions segmentation is the key procedure and always provides support for many qualitative and quantitative analyses on digitized immunohistochemical image. In lung tissue immunohistochemistry applications, the target region needs to be extracted out of the whole image firstly. Most existing methods based on color cannot fulfill the extraction of antibody region. Thus, there is a need of effective extraction method. Methods: According to the features of target region in images to be processed, this paper presents a solution framework based on artificial neural network (ANN). Results: Six effective features of the candidate regions are analyzed and extracted as the inputs of the ANN; three-layers back propagation neural network with six inputs and one output is constructed, and ANN's parameters are trained by the learning image set. By the trained ANN, target region core are obtained and then expanded to the whole target region through conditional expansion. Conclusion: Through testing the framework by testing image set and comparing with the main existing methods, it can be concluded that the proposed framework can remove non-target regions and extract the target regions well, while the contrast methods cannot remove all the non-target regions. Significance: The method presented in this paper has practical and potential significance to realize automated and quantitative tissue immunohistochemical image analysis.
C1 [Fan, Di; Wei, Lu; Cao, Maoyong] Shandong Univ Sci & Technol, Econ & Tech Dev Zone, 579 Qianwangang Rd, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology
RP Cao, MY (corresponding author), Shandong Univ Sci & Technol, Econ & Tech Dev Zone, 579 Qianwangang Rd, Qingdao 266590, Peoples R China.
EM fandi_93@126.com; my-cao@263.net
FU Project of Shandong Province Higher Educational Science and Technology
   Program [J13LN17]; Graduate Student Science and Technology Innovation
   Fund of SDUST [YC140212]; Project of South Africa/China Research
   Collaboration in Science and Technology [2012DFG71060]
FX This paper partially aided by the Shandong Province Young Scientist
   Foundation (BS2012DX034, BS2013NJ023), China Postdoctoral Science
   Foundation (2012 M521361), Shandong Province Natural Science Foundation
   (ZR2012EEM021), Project of Shandong Province Higher Educational Science
   and Technology Program (J13LN17), Graduate Student Science and
   Technology Innovation Fund of SDUST(YC140212), and Project of South
   Africa/China Research Collaboration in Science and Technology
   (2012DFG71060).
CR Amaral T, 2013, IEEE T BIO-MED ENG, V60, P2806, DOI 10.1109/TBME.2013.2264871
   [Anonymous], CHIN J STEREOL IMAGE
   [Anonymous], SPIE C POL MEAS AN R
   [Anonymous], ADV INTELL SYST COMP
   [Anonymous], SPIE C MULT MICR BIO
   [Anonymous], P WORLD C INT CONTR, DOI DOI 10.1109/WCICA.2006.1713888
   [Anonymous], CHIN J STEREOL IMAGE
   [Anonymous], SKIN RES TECHNOL
   [Anonymous], SPIE C BIOPH IMM RES
   [Anonymous], PROGR BIOMEDICAL OPT
   [Anonymous], PROGR BIOMEDICAL OPT
   Awad M, 2007, IEEE GEOSCI REMOTE S, V4, P571, DOI 10.1109/LGRS.2007.903064
   Boughrara H, 2016, MULTIMED TOOLS APPL, V75, P709, DOI 10.1007/s11042-014-2322-6
   Choong MY, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM, COMPUTING AND ENGINEERING (ICCSCE 2012), P430, DOI 10.1109/ICCSCE.2012.6487184
   Ficarra E, 2011, IEEE T BIO-MED ENG, V58, P1421, DOI 10.1109/TBME.2011.2106499
   Forsberg F, 2014, MOL IMAGING, V13, DOI 10.2310/7290.2013.00073
   Haltas A, 2014, SIG PROCESS COMMUN, P1106, DOI 10.1109/SIU.2014.6830427
   Hatanaka Y, 2001, PATHOL INT, V51, P33, DOI 10.1046/j.1440-1827.2001.01162.x
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hu CP, 2015, FRONT COMPUT SCI-CHI, V9, P980, DOI 10.1007/s11704-015-3482-x
   Hu CP, 2014, IEEE T EMERG TOP COM, V2, P376, DOI 10.1109/TETC.2014.2316525
   Irshad Humayun, 2014, IEEE Rev Biomed Eng, V7, P97, DOI 10.1109/RBME.2013.2295804
   Jun Tang, 2010, 2010 2nd International Conference on Computer Engineering and Technology (ICCET), P634, DOI 10.1109/ICCET.2010.5486012
   Lejeune M, 2008, J ANAT, V212, P868, DOI 10.1111/j.1469-7580.2008.00910.x
   Masmoudi H, 2009, IEEE T MED IMAGING, V28, P916, DOI 10.1109/TMI.2009.2012901
   Mostaço-Guidolin LB, 2014, ANAL CHEM, V86, P6346, DOI 10.1021/ac5005635
   Mouelhi A, 2014, 2014 1ST INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP 2014), P177, DOI 10.1109/ATSIP.2014.6834601
   Petersen Kersten, 2014, Breast Imaging. 12th International Workshop, IWDM 2014. Proceedings: LNCS 8539, P88, DOI 10.1007/978-3-319-07887-8_13
   Pham NA, 2007, DIAGN PATHOL, V2, DOI 10.1186/1746-1596-2-8
   Ruifrok AC, 2003, APPL IMMUNOHISTO M M, V11, P85, DOI 10.1097/00022744-200303000-00014
   Ruifrok AC, 2001, ANAL QUANT CYTOL, V23, P291
   Rusek K, 2016, MULTIMED TOOLS APPL, V75, P10617, DOI 10.1007/s11042-014-2114-z
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Shu SJ, 2013, CLIN IMAG, V37, P256, DOI 10.1016/j.clinimag.2012.05.004
   Trabelsi RB, 2016, MULTIMED TOOLS APPL, V75, P687, DOI 10.1007/s11042-014-2315-5
   Ngo TA, 2015, IEEE IMAGE PROC, P2140, DOI 10.1109/ICIP.2015.7351179
   Vincent P., 2008, INT C MACH LEARN ICM, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   [王慧 Wang Hui], 2011, [计算机应用与软件, Computer Applications and Software], V28, P54
   Wang Hui, 2011, Proceedings of the 2011 Seventh International Conference on Computational Intelligence and Security (CIS 2011), P1086, DOI 10.1109/CIS.2011.241
   [王萌萌 Wang Mengmeng], 2013, [计算机应用与软件, Computer Applications and Software], V30, P165
   Wemmert C, 2013, IEEE IMAGE PROC, P1125, DOI 10.1109/ICIP.2013.6738232
   Xu Z, 2016, COMPUTING, V98, P35, DOI 10.1007/s00607-014-0408-7
   Xu Z, 2015, J SYST SOFTWARE, V102, P217, DOI 10.1016/j.jss.2014.07.024
   Zafirellis K, 2008, APMIS, V116, P912, DOI 10.1111/j.1600-0463.2008.01104.x
   Zidan A, 2012, 2012 12TH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS (HIS), P96, DOI 10.1109/HIS.2012.6421316
NR 45
TC 7
Z9 8
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 12227
EP 12244
DI 10.1007/s11042-016-3459-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200035
DA 2024-07-18
ER

PT J
AU Yang, Y
   Wang, X
   Liu, Q
   Xu, ML
   Wu, W
AF Yang, You
   Wang, Xu
   Liu, Qiong
   Xu, Mingliang
   Wu, Wei
TI User models of subjective image quality assessment on virtual viewpoint
   in free-viewpoint video system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image quality assessment; User model; Virtual viewpoint image;
   Free-viewpoint video
ID 3-D OBJECT RETRIEVAL; CLASSIFICATION; RECOGNITION; CUES
AB In this paper, we present a user model of subjective quality assessment on virtual viewpoint image (VVI) for free-viewpoint video system. VVIs are rendered through neighbor viewpoint color and depth images, and it is a new type of image that generated for human-computer interaction (HCI) in free-viewpoint video system. In this system, a natural scene is captured by multi-viewpoint cameras, and users can view the scene from any desired viewpoint, regardless the real or virtual one. The subjective quality of VVIs is crucial for the quality of experiences for HCI, because the magnitude of VVI is much greater than the real. In order to find the user model of VVI quality assessment, we organize three sets of stimuli, including Symmetric Stimuli, Asymmetric Stimuli Part I and Part II, to reveal the psychological responses of participants. A psychometric function is consequently obtained to determine the relationship between stimulus and psychological responses. Further discussions on the factors of distortion level, gender, age and academic background are examined to find the influence on the user model. We find that the distortion level of neighbor viewpoint color images has the dominant impact on the user model, while other factors contribute little.
C1 [Yang, You; Liu, Qiong] Huazhong Univ Sci & Technol, Sch Elect Informat & Commun, Wuhan 430074, Peoples R China.
   [Yang, You] Tsinghua Univ, Dept Automat, Beijing 100086, Peoples R China.
   [Wang, Xu] City Univ Hong Kong, Dept Comp Sci, Kowloon Tong, Hong Kong, Peoples R China.
   [Xu, Mingliang] Zhengzhou Univ, Sch Informat Engn, Zhengzhou, Peoples R China.
   [Wu, Wei] China Acad Civil Aviat Sci & Technol, Beijing, Peoples R China.
C3 Huazhong University of Science & Technology; Tsinghua University; City
   University of Hong Kong; Zhengzhou University
RP Liu, Q (corresponding author), Huazhong Univ Sci & Technol, Sch Elect Informat & Commun, Wuhan 430074, Peoples R China.
EM yangyou@hust.edu.cn; wangxu.cise@gmail.com; q.liu@hust.edu.cn;
   iexumingliang@zzu.edu.cn; wuw@mail.castc.org.cn
RI Yang, You/O-5723-2019; Yang, You/A-9497-2019
FU Natural Science Foundation of China (NSFC) [61170194, 61202301]
FX This work was supported by Natural Science Foundation of China (NSFC)
   (Grant Nos. 61170194 and 61202301).
CR [Anonymous], 2020, INT TELECOMMUNICATIO
   [Anonymous], 2011, JTC1SC29WG11 ISOIEC
   Bex P., 2008, Journal of Vision, V8, P688
   Bex P., 2009, J VIS, V9, P1
   Bosc E, 2011, IEEE J-STSP, V5, P1332, DOI 10.1109/JSTSP.2011.2166245
   Buehren T, 2006, VISION RES, V46, P1633, DOI 10.1016/j.visres.2005.06.009
   Chan SC, 2007, IEEE SIGNAL PROC MAG, V24, P22, DOI 10.1109/MSP.2007.905702
   Chen L, 2005, OPTOMETRY VISION SCI, V82, P358, DOI 10.1097/01.OPX.0000162647.80768.7F
   Gao Y, 2014, IEEE T IND ELECTRON, V61, P2088, DOI 10.1109/TIE.2013.2262760
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Ji RR, 2014, IEEE T GEOSCI REMOTE, V52, P1811, DOI 10.1109/TGRS.2013.2255297
   Ji RR, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2037676.2037688
   Karsten M, 2009, EURASIP J IMAGE VIDE, V2008
   Klimaszewski K, 2009, 3DTV CONF, P193
   Lee CC, 2008, ROUT MED CULT SOC, P11
   Liu Q, 2013, NEUROCOMPUTING, V111, P154, DOI 10.1016/j.neucom.2012.12.022
   Liu Q, 2013, NEUROCOMPUTING, V104, P1, DOI 10.1016/j.neucom.2012.09.009
   Liu YW, 2009, SIGNAL PROCESS-IMAGE, V24, P666, DOI 10.1016/j.image.2009.06.002
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   McIlhagga WH, 2012, J VIS, V12
   Mittal A., 2013, J. Vis, V13, P1056, DOI [10.1167/13.9.1056, DOI 10.1167/13.9.1056]
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   WOLFE JM, 1994, VISION RES, V34, P1187, DOI 10.1016/0042-6989(94)90300-X
   Yang Y, 2010, ELECTRON LETT, V46, P492, DOI 10.1049/el.2010.3522
   Yang Y, 2012, PLOS ONE, V7
   Yang Y, 2015, SIGNAL PROCESS, V112, P199, DOI 10.1016/j.sigpro.2014.07.020
   Zhang L, 2005, IEEE T BROADCAST, V51, P191, DOI 10.1109/TBC.2005.846190
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang LM, 2013, SIGNAL PROCESS, V93, P1597, DOI 10.1016/j.sigpro.2012.05.012
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P802, DOI 10.1109/TIP.2012.2223226
NR 34
TC 5
Z9 6
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12499
EP 12519
DI 10.1007/s11042-014-2321-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700012
DA 2024-07-18
ER

PT J
AU Zhang, XG
   Ouyang, ML
   Zhang, XF
AF Zhang, Xuguang
   Ouyang, Meiling
   Zhang, Xufeng
TI Small scale crowd behavior classification by Euclidean distance
   variation-weighted network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Crowd behavior analysis; Object tracking; Crowd network
ID SURVEILLANCE
AB Crowd behavior analysis is a key research topic in the field of computer vision. The traditional method of crowd behavior analysis can be divided into two categories. One is the microscopic-based method, which is mainly through extracting the gestures and trajectories of every individual to recognize the behavior of a crowd. The other is the macroscopic-based method, in which the statistical characteristics of a crowd are used to represent the crowd behavior. By exploring the connection between the microscopic and macroscopic properties of a crowd, a method which use Euclidean distance variation-weighted network to recognize the crowd behavior is proposed in this paper. Firstly, the trajectories and location information of the individuals in crowd are captured by tracking every pedestrian. Furthermore, by calculating the Euclidean distance variation between two individuals the interaction between individuals is gained. Then, the Euclidean distance variation-weighted networks of five typical crowd behavior including gather, meet, together, separation and dispersion are constructed. The nodes represent individuals in the crowd and the weight of each edge represents the extent of interaction between individuals. Finally, the characteristic parameters of crowd networks including the path length and network weights are extracted and the crowd behavior is classified by using k-nearest neighbor method. Experimental results show the proposed method can effectively express and recognize small-scale crowd behavior. The lowest classification accuracy of the proposed method can reach 86.8 % in the five kinds of crowd behavior.
C1 [Zhang, Xuguang; Ouyang, Meiling; Zhang, Xufeng] Yanshan Univ, Sch Elect Engn, Qinhuangdao, Peoples R China.
C3 Yanshan University
RP Zhang, XG (corresponding author), Yanshan Univ, Sch Elect Engn, Qinhuangdao, Peoples R China.
EM zhangxg@ysu.edu.cn
RI zhang, xiaofei/HJA-9117-2022; zhang, jin/GXV-9154-2022; zhang,
   xu/GYE-3558-2022; zhang, xian/GYA-0290-2022; ZHANG,
   XUCHEN/KBB-7989-2024; Zhang, xiaoyu/HTM-3222-2023; zhang,
   xiaoyu/HJI-4374-2023; zhang, xiaofei/JCD-9045-2023; zhang,
   xu/GRX-9733-2022; Zhang, xiaoyu/GXA-3206-2022; zhang, xian/JAC-5480-2023
FU National Natural Science Foundation of China [61271409]; China
   Postdoctoral Science Foundation [2012M510768, 2013T60264]; Natural
   Science Foundation of Hebei Province, China [F2013203364]; China
   Scholarship Council [2011813018]
FX This research was supported by National Natural Science Foundation of
   China (No. 61271409), China Postdoctoral Science Foundation (No.
   2012M510768, No. 2013T60264), Natural Science Foundation of Hebei
   Province, China (No. F2013203364), and China Scholarship Council (No.
   2011813018).
CR Alqaysi H. H., 2013, DETECTION SIMULATION, P1, DOI [10.1109/AIPR.2013.6749309, DOI 10.1109/AIPR.2013.6749309]
   Amine D, 2014, PROCEDIA COMPUT SCI, V34, P63, DOI 10.1016/j.procs.2014.07.040
   An XL, 2014, PHYSICA A, V412, P149, DOI 10.1016/j.physa.2014.06.033
   Biswas S, 2015, MULTIMED TOOLS APPL, V74, P11099, DOI 10.1007/s11042-014-2219-4
   Brostow G.J., 2006, CVPR, P594, DOI DOI 10.1109/CVPR.2006.320
   Estrada E, 2012, APPL MATH COMPUT, V218, P10393, DOI 10.1016/j.amc.2012.03.091
   Ge Weina, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2913, DOI 10.1109/CVPRW.2009.5206621
   Golas A, 2014, IEEE T VIS COMPUT GR, V20, P1022, DOI 10.1109/TVCG.2013.235
   Gu XX, 2014, OPTIK, V125, P3428, DOI 10.1016/j.ijleo.2014.01.041
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Hsieh JW, 2008, IEEE T MULTIMEDIA, V10, P372, DOI 10.1109/TMM.2008.917403
   Kountouriotis V, 2014, PATTERN RECOGN LETT, V44, P30, DOI 10.1016/j.patrec.2013.10.024
   Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771
   Krishnan R, 2015, PATTERN RECOGN, V48, P1302, DOI 10.1016/j.patcog.2014.10.026
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Lin J, 2013, OPTIK, V124, P6795, DOI 10.1016/j.ijleo.2013.05.097
   Morris BT, 2008, IEEE T CIRC SYST VID, V18, P1114, DOI 10.1109/TCSVT.2008.927109
   Nam Y, 2014, MULTIMED TOOLS APPL, V72, P3001, DOI 10.1007/s11042-013-1593-7
   Nix T, 2014, PROCEDIA COMPUT SCI, V32, P1127, DOI 10.1016/j.procs.2014.05.543
   Raheja JL, 2014, OPTIK, V125, P993, DOI 10.1016/j.ijleo.2013.07.167
   Rao YB, 2011, MULTIMED TOOLS APPL, V54, P397, DOI 10.1007/s11042-010-0542-y
   Saini M, 2014, MULTIMED TOOLS APPL, V68, P135, DOI 10.1007/s11042-012-1207-9
   Vezzani R, 2010, MULTIMED TOOLS APPL, V50, P359, DOI 10.1007/s11042-009-0402-9
   Wang B, 2012, MACH VISION APPL, V23, P501, DOI 10.1007/s00138-011-0341-0
   Wang SX, 2012, PROCEDIA ENGINEER, V29, P1186, DOI 10.1016/j.proeng.2012.01.110
   Zawidzki M, 2014, PATTERN RECOGN LETT, V44, P88, DOI 10.1016/j.patrec.2013.10.025
   Zhang XG, 2011, INT J UNCERTAIN FUZZ, V19, P547, DOI 10.1142/S021848851100712X
   Zhang YY, 2013, MULTIMED TOOLS APPL, V67, P97, DOI 10.1007/s11042-012-1054-8
   Zhou Y, 2008, PROC CVPR IEEE, P3682
   Zhou Y, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1087
NR 30
TC 4
Z9 4
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 11945
EP 11960
DI 10.1007/s11042-015-2670-x
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200020
DA 2024-07-18
ER

PT J
AU Arroyo, I
   Giné, F
   Roig, C
   Granollers, T
AF Arroyo, Ismael
   Gine, Francesc
   Roig, Concepcio
   Granollers, Toni
TI Analyzing Google Earth application in a heterogeneous commodity cluster
   display wall
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cluster display wall; Liquid galaxy; Master-slave; Client-server; Google
   Earth; Benchmarking
ID VISUALIZATION; FRAMEWORK
AB Nowadays, clusters of interconnected workstations have become a common solution for powering large composite displays, or "cluster display walls", to visualize high resolution images. Our paper is focused on analyzing a specific cluster display wall developed by Google, named Liquid Galaxy, made up of heterogeneous commodity hardware with different degrees of heterogeneity, running master-slave (Google Earth) and client-server (Quake III Arena) multimedia applications. With this in mind, we define and test different scenarios, representing the behavior of many kinds of users. Our results show that the CPU, memory and network are good enough to execute the client-server application, while, depending on the user behavior, the external network constitutes the bottleneck of the system in Google Earth. So, the master-slave application has focused our attention. Likewise, in order to analyze the users' point of view when interacting with Google Earth in the Liquid Galaxy, we define a new metric, named Visualization Rate (VR), which enables a relationship to be established between the user experience and the platform performance. In order to set the minimum acceptable value of the VR parameter according to users perception, we carried out different tests with real users. Then, this minimum threshold was compared with the VR value obtained from the automated benchmarking performed afterwards on clusters with different heterogeneity degrees. Finally, we analyzed the VR trend when the Liquid Galaxy is scaled from 3 up to 8 nodes in both the homogeneous and heterogeneous architectures to study the scalability of the system.
C1 [Arroyo, Ismael; Gine, Francesc; Roig, Concepcio; Granollers, Toni] Univ Lleida, Lleida, Spain.
C3 Universitat de Lleida
RP Arroyo, I (corresponding author), Univ Lleida, Lleida, Spain.
EM ismael.arroyo@udl.cat; sisco@diei.udl.cat; roig@diei.udl.cat;
   tonig@diei.udl.cat
RI Gine, Francesc/I-5446-2012; Granollers, Toni/D-2496-2011; Roig,
   Concepcio/J-8425-2014; Arroyo Campos, Ismael/L-2021-2017
OI Granollers, Toni/0000-0001-9189-7308; Roig,
   Concepcio/0000-0003-3029-3820; Arroyo Campos, Ismael/0000-0001-5393-6329
FU MEyC-Spain [TIN2011-28689-C02-02, TIN2014-53234-C2-2-R]
FX This work was supported by MEyC-Spain under contract
   TIN2011-28689-C02-02 and TIN2014-53234-C2-2-R.
CR [Anonymous], 2012, PANORAMIC VIDEO STRE
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], 2009, 9241 210 2010 ERGONO, DOI DOI 10.3403/30388991
   Ball R, 2005, LECT NOTES COMPUT SC, V3585, P350, DOI 10.1007/11555261_30
   Barri I, 2011, J SUPERCOMPUT, V58, P341, DOI 10.1007/s11227-011-0590-8
   Chen YQ, 2001, FIRST IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER COMPUTING AND THE GRID, PROCEEDINGS, P202, DOI 10.1109/CCGRID.2001.923194
   Chung H, 2014, IEEE T VIS COMPUT GR, V20, P1158, DOI 10.1109/TVCG.2013.272
   DeFanti TA, 2011, OPEN ENG, V1, P16, DOI 10.2478/s13531-010-0002-5
   Doerr KU, 2011, IEEE T VIS COMPUT GR, V17, P320, DOI 10.1109/TVCG.2010.59
   Eilemann S, 2009, IEEE T VIS COMPUT GR, V15, P436, DOI 10.1109/TVCG.2008.104
   Hassenzahl M, 2006, BEHAV INFORM TECHNOL, V25, P91, DOI 10.1080/01449290500330331
   Humphreys G, 2002, ACM T GRAPHIC, V21, P693, DOI 10.1145/566570.566639
   Ishiguro Y, 2011, P 2ND AUGM HUM INT C
   Izadi Izadi Shahram Shahram, Proceedings o f UIST (User Interface Software and Technology), P159, DOI [10.1145/964696.964714, DOI 10.1145/964696.964714, 10.1145/964696.964714 10.1145/964696.964714]
   Johnson A, 2006, IEEE COMPUT GRAPH, V26, P10, DOI 10.1109/MCG.2006.127
   Krug S., 2009, Rocket surgery made easy: The do-it-yourself guide to finding and fixing usability problems
   Lau CD, 2010, BIOINFORMATICS, V26, P1915, DOI 10.1093/bioinformatics/btq296
   Leigh J, 2013, P IEEE, V101, P115, DOI 10.1109/JPROC.2012.2191609
   Liu C, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P4147, DOI 10.1145/2556288.2557020
   Nirnimesh, 2007, IEEE T VIS COMPUT GR, V13, P864, DOI 10.1109/TVCG.2007.1049
   OpenArena Team, 2005, OPENARENA QUAK 3 AR
   OSG, 2014, OP GRAPH
   Reda K, 2013, IEEE COMPUT GRAPH, V33, P38, DOI 10.1109/MCG.2013.37
   Renambot L., 2004, P WACE, V9, P2004
   Schikore DR, 2000, IEEE COMPUT GRAPH, V20, P38, DOI 10.1109/38.851748
   Smarr L, 2009, FUTURE GENER COMP SY, V25, P109, DOI 10.1016/j.future.2008.07.014
   *SQUID TEAM, 2002, SQUID WEB PROX CACH
   Staadt O. G., 2003, IPT/EGVE 2003. Seventh Immersive Projection Technology Workshop. Ninth Eurographics Workshop on Virtual Environments, P261, DOI 10.1145/769953.769984
   United Nations Educational Scientific and Cultural Organization (UNESCO), 2018, INT TECHN GUID SEX E
NR 29
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 11391
EP 11416
DI 10.1007/s11042-015-2859-z
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900026
OA hybrid
DA 2024-07-18
ER

PT J
AU Jiang, XB
   Zhong, F
   Peng, QS
   Qin, XY
AF Jiang, Xinbo
   Zhong, Fan
   Peng, Qunsheng
   Qin, Xueying
TI Action recognition based on global optimal similarity measuring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sequence matching; Weighted graph; Dynamic programming
AB Human action recognition based on the 3D skeleton is an important yet challenging task, because of the instability of skeleton joints and great variations in action length. In this paper we propose a novel method that can effectively deal with unstable joints and significant temporal misalignment. Action recognition is elegantly formulated as a sequence-matching problem on a pre-constructed weighted graph, which can encodes any spatio-temporal features and the transition probabilities between action elements. To classify any input sequence of actions, a global optimal matching algorithm based on dynamic programming is introduced, which can deal with temporal misalignment without pre-segmentation, The weighted graph is constructed in training stage. The proposed approach is evaluated on two benchmark datasets captured by a single depth sensor. Experimental results show that our approach can achieve superior performance to most state-of-the-art algorithms.
C1 [Jiang, Xinbo; Zhong, Fan; Qin, Xueying] Shandong Univ, Jinan, Shandong, Peoples R China.
   [Peng, Qunsheng] Zhejiang Univ, Hangzhou, Zhejiang, Peoples R China.
C3 Shandong University; Zhejiang University
RP Qin, XY (corresponding author), Shandong Univ, Jinan, Shandong, Peoples R China.
EM xinboj@gmail.com; zhongfan@sdu.edu.cn; qxy@sdu.edu.cn
RI jiang, xinbo/AAL-7727-2021; Qin, Xueying/AAM-8775-2021
OI Qin, Xueying/0000-0003-0057-295X
CR [Anonymous], ICIAR
   [Anonymous], 2008, BRIT MACH VIS C
   [Anonymous], COMP VIS PATT REC WO
   [Anonymous], 2013, 23 INT JOINT C ARTIF
   Beh J, 2014, PATTERN RECOGNITION
   Deng L, 2010, WAIM AUTOMATED RECOG
   Ellis C, 2013, INT J COMPUT VISION
   Fathi A., 2008, ACTION RECOGNITION L
   Feng Y, 2014, INFORM SCI
   Feng Y, 2014, IEEE T CYBERN
   Fothergill S., 2012, INSTRUCTING PEOPLE T
   Hyunsook C, 2013, PATTERN RECOGNITION
   Laptev I., 2005, International Journal of Computer Vision
   Liang XR, 2013, 2013 12TH INTERNATIONAL CONFERENCE ON OPTICAL COMMUNICATIONS AND NETWORKS (ICOCN)
   Luo J, IEEE INT C COMP VIS
   Matikainen P, WORKSH VID OR OBJ EV
   Ramlrez-Corona M, 2013, P 2011 IEEE C COMP V
   Shotton J, P 2011 IEEE C COMP V
   Wang J, CVPR 12
   Willems G, P 10 EUR C COMP VI 2
   Xiao J, 2014, SIGNAL PROCESSING
   Zhao X, P 21 ACM INT C MULT
   Zou W, 2013, PCM HUMAN ACTION REC
NR 23
TC 7
Z9 9
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 11019
EP 11036
DI 10.1007/s11042-015-2829-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900010
DA 2024-07-18
ER

PT J
AU Lin, KC
   Wang, X
   Tan, YQ
AF Lin, Kuicheng
   Wang, Xue
   Tan, Yuqi
TI Self-adaptive morphable model based collaborative multi-view 3d face
   reconstruction in visual sensor network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual sensor network; Optimal face acquisition; 3D face reconstruction;
   Self-adaptive morphable model; Particle swarm optimization
ID MOTION ESTIMATION; TRACKING
AB 3D face reconstruction is an efficient method for pedestrian recognition in noncooperative environment because of its outstanding performance in robust face recognition for uncontrolled pose and illumination changes. Visual sensor network is widely used in target surveillance as powerful unattended distributed measurement systems. This paper proposes a collaborative multi-view non-cooperative 3D face reconstruction method in visual sensor network. A peer-to-peer paradigm-based visual sensor network is employed for distributed pedestrian tracking and optimal face image acquisition. Gaussian probability distribution-based multi-view data fusion is used for target localization, and kalman filter is applied for target tracking. A lightweight face image quality evaluation method is presented to search optimal face images. A self-adaptive morphable model is designed for multiview 3D face reconstruction. To adjust the self-adaptive morphable model, the optimal face images and their poses estimation are used. Cooperative chaotic particle swarm optimization is employed for parameters optimization of the self-adaptive morphable model. Experimental results on real data show that the proposed method can acquire optimal face images and achieve non-cooperative 3D reconstruction efficiently.
C1 [Lin, Kuicheng; Wang, Xue; Tan, Yuqi] Tsinghua Univ, Dept Precis Instrument, State Key Lab Precis Measurement Technol & Instru, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Wang, X (corresponding author), Tsinghua Univ, Dept Precis Instrument, State Key Lab Precis Measurement Technol & Instru, Beijing 100084, Peoples R China.
EM linkc10@mails.tsinghua.edu.cn; wangxue@mail.tsinghua.edu.cn;
   tan-yq10@mails.tsinghua.edu.cn
OI Wang, Xue/0000-0003-4842-3160
CR [Anonymous], 2005, TECHNICAL REPORT
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Cho Y, 2010, IEEE T CONSUM ELECTR, V56, P1997, DOI 10.1109/TCE.2010.5606357
   Chouvatut V, 2013, MULTIMED TOOLS APPL, V63, P569, DOI 10.1007/s11042-011-0925-8
   Cootes TF, 2002, IMAGE VISION COMPUT, V20, P657, DOI 10.1016/S0262-8856(02)00055-0
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Costa DG, 2013, MULTIMED TOOLS APPL, V64, P549, DOI 10.1007/s11042-011-0961-4
   Ding C, 2012, IEEE T IMAGE PROCESS, V21, P3282, DOI 10.1109/TIP.2012.2188806
   Heath K, 2007, 2007 FIRST ACM/IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS, P112
   Heo J, 2012, IEEE T PATTERN ANAL, V34, P2341, DOI 10.1109/TPAMI.2011.275
   Huang C, 2012, COMPUT VIS IMAGE UND, V116, P777, DOI 10.1016/j.cviu.2012.02.007
   Jongmoo Choi, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3959, DOI 10.1109/ICPR.2010.963
   Kemelmacher-Shlizerman I, 2011, IEEE T PATTERN ANAL, V33, P394, DOI 10.1109/TPAMI.2010.63
   Lee YJ, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-176
   Lian FL, 2013, IEEE T IND INFORM, V9, P172, DOI 10.1109/TII.2012.2209664
   Medeiros H, 2008, IEEE J-STSP, V2, P448, DOI 10.1109/JSTSP.2008.2001310
   Medioni G, 2009, IEEE T SYST MAN CY A, V39, P12, DOI 10.1109/TSMCA.2008.2007979
   Ming Y, 2010, P IEEE INT C ED INF, pV3
   Nam Y, 2012, MULTIMED TOOLS APPL, V73, P129
   Park U, 2013, IEEE T INF FOREN SEC, V8, P1665, DOI 10.1109/TIFS.2013.2261061
   Parker Susan, 2008, Canaveral National Seashore: Historic Resource Study, P1
   Parupati S., 2011, 2011 5 ACM INT C, P1
   Peng Liu, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P794, DOI 10.1109/ICME.2012.61
   Song B, 2010, IEEE T IMAGE PROCESS, V19, P2564, DOI 10.1109/TIP.2010.2052823
   Wang X, 2007, J PARALLEL DISTR COM, V67, P501, DOI 10.1016/j.jpdc.2007.02.001
   Wang X, 2009, IEEE T SYST MAN CY B, V39, P1134, DOI 10.1109/TSMCB.2009.2013196
   Wang Y, 2012, MULTIMED TOOLS APPL, V73, P7
   Wu JW, 2014, MEASUREMENT, V49, P216, DOI 10.1016/j.measurement.2013.11.041
   Xiaowen Wang, 2010, 2010 2nd International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC 2010), P250, DOI 10.1109/IHMSC.2010.163
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 30
TC 3
Z9 3
U1 3
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 11469
EP 11491
DI 10.1007/s11042-015-2864-2
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900030
DA 2024-07-18
ER

PT J
AU Lojka, M
   Pleva, M
   Kiktová, E
   Juhár, J
   Cizmár, A
AF Lojka, Martin
   Pleva, Matus
   Kiktova, Eva
   Juhar, Jozef
   Cizmar, Anton
TI Efficient acoustic detector of gunshots and glass breaking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Acoustic Event Detection; Weighted Finite-State Transducers; Continuous
   Monitoring of Large Urban Areas
ID FEATURE-SELECTION; RECOGNITION; AUDIO; MFCC
AB An efficient acoustic events detection system EAR-TUKE is presented in this paper. The system is capable of processing continuous input audio stream in order to detect potentially dangerous acoustic events, specifically gunshots or breaking glass. The system is programmed entirely in C++ language (core math. functions in C) and was designed to be self sufficient without requiring additional dependencies. In the design and development process the main focus was put on easy support of new acoustic events detection, low memory profile, low computational requirements to operate on devices with low resources, and on long-term operation and continuous input stream monitoring without any maintenance. In order to satisfy these requirements on the system, EAR-TUKE is based on a custom approach to detection and classification of acoustic events. The system is using acoustic models of events based on Hidden Markov Models (HMMs) and a modified Viterbi decoding process with an additional module to allow continuous monitoring. These features in combination with Weighted Finite-State Transducers (WFSTs) for the search network representation fulfill the easy extensibility requirement. Extraction algorithms for Mel-Frequency Cepstral Coefficients (MFCC), Frequency Bank Coefficients (FBANK) and Mel-Spectral Coefficients (MELSPEC) are also included in the preprocessing part. The system contains Cepstral Mean Normalization (CMN) and our proposed removal of basic coefficients from feature vectors to increase robustness. This paper also presents the development process and results evaluating the final design of the system.
C1 [Lojka, Martin; Pleva, Matus; Kiktova, Eva; Juhar, Jozef; Cizmar, Anton] Tech Univ Kosice, Dept Elect & Multimedia Commun, FEI TU Kosice, Pk Komenskeho 13, Kosice 04120, Slovakia.
C3 Technical University Kosice
RP Pleva, M (corresponding author), Tech Univ Kosice, Dept Elect & Multimedia Commun, FEI TU Kosice, Pk Komenskeho 13, Kosice 04120, Slovakia.
EM martin.lojka@tuke.sk; matus.pleva@tuke.sk; eva.kiktova@tuke.sk;
   jozef.juhar@tuke.sk; anton.cizmar@tuke.sk
RI Pleva, Matúš/H-7209-2012; Juhár, Jozef/B-2803-2014; Kiktova-Vozarikova,
   Eva/AAN-3730-2020; Čižmár, Anton/I-4612-2014
OI Pleva, Matúš/0000-0003-4380-0801; Juhár, Jozef/0000-0002-1596-9258;
   Kiktova-Vozarikova, Eva/0000-0001-9325-7339; 
FU Project implementation: University Science Park TECHNICOM for Innovation
   Applications Supported by Knowledge Technology [ITMS: 26220220182];
   Research & Development Operational Programme - ERDF; EU ICT project
   INDECT [FP7 - 218086]; MINEDU [VEGA 1/0075/15]
FX This publication is supported partially (50 %) by the Project
   implementation: University Science Park TECHNICOM for Innovation
   Applications Supported by Knowledge Technology, ITMS: 26220220182,
   supported by the Research & Development Operational Programme funded by
   the ERDF & partially (40 %) by EU ICT project INDECT (FP7 - 218086) and
   MINEDU (10 %) project VEGA 1/0075/15.
CR Alam MJ, 2011, LECT NOTES ARTIF INT, V7015, P246, DOI 10.1007/978-3-642-25020-0_32
   [Anonymous], 2004, P HEINZ BILL PRIC
   [Anonymous], 2011, TECH REP
   Brown G, 2012, J MACH LEARN RES, V13, P27
   Collobert R, 2001, J MACH LEARN RES, V1, P143, DOI 10.1162/15324430152733142
   Dixon PR, 2012, INT CONF ACOUST SPEE, P4209, DOI 10.1109/ICASSP.2012.6288847
   Eyben F., 2013, P 21 ACM INT C MULT, P835, DOI DOI 10.1145/2502081.2502224
   Foote JT, 1997, P SOC PHOTO-OPT INS, V3229, P138, DOI 10.1117/12.290336
   Freire I.L., 2010, PROCEEDING 7 INT TEL, P1
   Gerosa L, 2007, P EUSIPCO POZN POL, P1
   Hládek D, 2014, 2014 5TH IEEE CONFERENCE ON COGNITIVE INFOCOMMUNICATIONS (COGINFOCOM), P315, DOI 10.1109/CogInfoCom.2014.7020469
   Kiktova E, 2014, ELMAR PROC, P47, DOI 10.1109/ELMAR.2014.6923312
   Kiktova E, 2013, COMM COM INF SC, V368, P288
   Kiktova-Vozarikova E, 2015, MULTIMED TOOLS APPL, V74, P4213, DOI 10.1007/s11042-013-1529-2
   Lamere P., 2003, P IEEE INT C ACOUSTI, V1, P2
   Lee A., 2009, ASIA PACIFIC SIGNAL, P131
   Lojka Martin, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P199
   Lojka M., 2010, J ELECT ELECT ENG, V3, P111
   Lopatka K, 2014, INFORM SCIENCES, V285, P223, DOI 10.1016/j.ins.2013.11.030
   Lopatka K, 2011, ARCH ACOUST, V36, P851, DOI 10.2478/v10168-011-0056-2
   McKinney M.F., 2003, Proc. ISMIR, V3, P151
   Mohri M., 2008, SPRINGER HDB SPEECH, P1
   Pleva M., 2012, J ELECT ELECT ENG, V5, P195
   Pleva M., 2011, J ELECT ELECT ENG, V4, P185
   Pleva M, 2012, ELMAR PROC, P179
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rusko M, 2014, LECT NOTES ARTIF INT, V8387, P16, DOI 10.1007/978-3-319-08958-4_2
   Sattar F, 2013, IEEE PAC RIM CONF CO, P383, DOI 10.1109/PACRIM.2013.6625507
   Suman P, 2014, LECT NOTES ELECTR EN, V299, P155, DOI 10.1007/978-81-322-1823-4_15
   Uzkent B, 2012, INT J INNOV COMPUT I, V8, P3511
   Valenzise G, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P21, DOI 10.1109/AVSS.2007.4425280
   Vozáriková E, 2011, COMM COM INF SC, V149, P191
   Wijitha Senadeera Wijitha Senadeera, 2006, International Journal of Food Engineering, V2, P7
NR 33
TC 17
Z9 19
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10441
EP 10469
DI 10.1007/s11042-015-2903-z
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800017
OA hybrid
DA 2024-07-18
ER

PT J
AU Thanh, TM
   Tanaka, K
AF Ta Minh Thanh
   Tanaka, Keisuke
TI The novel and robust watermarking method based on <i>q</i>-logarithm
   frequency domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE q-logarithm frequency domain (q-LFD); q-logarithm function;
   q-exponential function; Quantization index modulation (QIM) technique;
   Image watermarking
ID IMAGE WATERMARKING; DIGITAL WATERMARKING; COLOR IMAGES; DWT
AB In general, watermarking techniques on transform domain are always mainly researched in literature since it is robust against several attacks. In this paper, we continue to focus on the transform domain and extend it to the novel frequency domain, called q-logarithm frequency domain (q-LFD), for robust watermarking. In order to achieve the robustness of embedding method, we embed the scrambled watermark information into the low-band frequency of q-LFD by using the quantization index modulation (QIM) technique. According to the simulation results, our method can improve the quality of embedded image and also the robustness of watermark based on the optimized parameters: q of q-LFD and Q of QIM. Experimental results show that our proposed method is also robust against geometric attacks, processing attacks, filtering attacks, and so on.
C1 [Ta Minh Thanh; Tanaka, Keisuke] Tokyo Inst Technol, Meguro Ku, W8-55,2-12-2, Tokyo 1528552, Japan.
   [Ta Minh Thanh; Tanaka, Keisuke] JST CREST, Meguro Ku, W8-55,2-12-2, Tokyo 1528552, Japan.
   [Ta Minh Thanh] Le Quy Don Tech Univ, 236 Hoang Quoc Viet St, Ha Noi City, Vietnam.
C3 Tokyo Institute of Technology; Japan Science & Technology Agency (JST);
   Le Quy Don Technical University
RP Thanh, TM (corresponding author), Tokyo Inst Technol, Meguro Ku, W8-55,2-12-2, Tokyo 1528552, Japan.; Thanh, TM (corresponding author), JST CREST, Meguro Ku, W8-55,2-12-2, Tokyo 1528552, Japan.; Thanh, TM (corresponding author), Le Quy Don Tech Univ, 236 Hoang Quoc Viet St, Ha Noi City, Vietnam.
EM taminhjp@gmail.com; keisuke@is.titech.ac.jp
RI Thanh, Ta Minh/ABH-2076-2021
OI Thanh, Ta Minh/0000-0002-4776-4265
FU Ministry of Education, Science, Sports and Culture [24240001]; I-System
   Co. Ltd.; NTT Secure Platform Laboratories; CREST, JST; Grants-in-Aid
   for Scientific Research [16H01705] Funding Source: KAKEN
FX This work is supported by the Ministry of Education, Science, Sports and
   Culture, Grant-in-Aid for Scientific Research (A) No.24240001, a grant
   of I-System Co. Ltd., NTT Secure Platform Laboratories and CREST, JST.
CR ABE S, 2001, SERIES LECT NOTES PH
   Byun K, 2005, PDCAT 2005: Sixth International Conference on Parallel and Distributed Computing, Applications and Technologies, Proceedings, P689
   Chen B, 2001, J VLSI SIG PROCESS S, V27, P7, DOI 10.1023/A:1008107127819
   Deb K., 2012, 2012 7th International Conference on Electrical & Computer Engineering (ICECE), P458, DOI 10.1109/ICECE.2012.6471586
   Feng LP, 2010, INT CONF COMP SCI, P455, DOI 10.1109/ICCSIT.2010.5565101
   Fu YG, 2013, OPTIK, V124, P517, DOI 10.1016/j.ijleo.2011.12.042
   Hajizadeh M, 2010, ADV ELECTR COMPUT EN, V10, P96, DOI 10.4316/AECE.2010.03016
   Huang PS, 2005, IEE P-VIS IMAGE SIGN, V152, P561, DOI 10.1049/ip-vis:20041081
   Huang XS, 2012, PHYSCS PROC, V25, P568, DOI 10.1016/j.phpro.2012.03.127
   Hwang RJ, 2002, FIRST INTERNATIONAL SYMPOSIUM ON CYBER WORLDS, PROCEEDINGS, P225, DOI 10.1109/CW.2002.1180883
   Iwakiri M, 2012, INT CON ADV INFO NET, P755, DOI 10.1109/AINA.2012.111
   Jia SL, 2014, OPTIK, V125, P2868, DOI 10.1016/j.ijleo.2014.01.002
   Jun Xiao, 2008, 2008 Pacific-Asia Workshop on Computational Intelligence and Industrial Application. PACIIA 2008, P206, DOI 10.1109/PACIIA.2008.167
   Keyvanpour MR, 2011, PROCEDIA COMPUT SCI, V3, DOI 10.1016/j.procs.2010.12.040
   Kimpan S, 2004, IEEE INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES 2004 (ISCIT 2004), PROCEEDINGS, VOLS 1 AND 2, P374
   Lai CC, 2011, DIGIT SIGNAL PROCESS, V21, P522, DOI 10.1016/j.dsp.2011.01.017
   Lee HK, 2004, LECT NOTES COMPUT SC, V3043, P159
   Lee YK, 2000, IEE P-VIS IMAGE SIGN, V147, P288, DOI 10.1049/ip-vis:20000341
   Lin WH, 2009, EXPERT SYST APPL, V36, P11509, DOI 10.1016/j.eswa.2009.03.060
   Liu F, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P380, DOI 10.1109/CISP.2008.412
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Loukhaoukha K, 2013, DIGIT SIGNAL PROCESS, V23, P1334, DOI 10.1016/j.dsp.2013.02.006
   Lu ZM, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P241
   Pradhan C, 2012, PROC TECH, V1, P897, DOI 10.1016/j.protcy.2012.10.109
   Shih F.Y., 2008, Digital Watermarking and Steganography: Fundamentals and Techniques
   Stanescu D, 2008, 2008 IEEE INTERNATIONAL WORKSHOP ON HAPTIC AUDIO VISUAL ENVIRONMENTS AND THEIR APPLICATIONS, P166, DOI 10.1109/HAVE.2008.4685318
   Sun XY, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P731, DOI 10.1109/IIH-MSP.2008.190
   Thanh TM, 2014, AEU-INT J ELECTRON C
   Tsai MJ, 2000, IEEE T CONSUM ELECTR, V46, P241
   TSALLIS C, 1988, J STAT PHYS, V52, P479, DOI 10.1007/BF01016429
   Voyatzis G, 1996, EUR C MULT APPL SERV, V2, P687
   Wei Cao, 2009, 2009 IEEE International Workshop on Imaging Systems and Techniques (IST 2009), P381, DOI 10.1109/IST.2009.5071670
   Won CS, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3427158
   Yavuz E, 2006, LECT NOTES COMPUT SC, V4105, P66
   Yavuz E, 2007, APPLIED COMPUTING 2007, VOL 1 AND 2, P1051, DOI 10.1145/1244002.1244232
   Yeung MM, 1998, COMMUN ACM, V41, P30
   Yi-lin Bei, 2011, 2011 IEEE International Conference on Computer Science and Automation Engineering (CSAE), P305, DOI 10.1109/CSAE.2011.5952856
   Zhang LJ, 2009, 2009 ASIA-PACIFIC CONFERENCE ON INFORMATION PROCESSING (APCIP 2009), VOL 2, PROCEEDINGS, P19, DOI 10.1109/APCIP.2009.141
   Zhao RM, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL III, PROCEEDINGS, P821, DOI 10.1109/IITA.2008.482
   Zhu XZ, 2006, INT C PATT RECOG, P651
NR 40
TC 4
Z9 4
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 11097
EP 11125
DI 10.1007/s11042-015-2836-6
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900013
DA 2024-07-18
ER

PT J
AU Yu, XG
   Cheng, J
   Wu, SQ
   Song, W
AF Yu, Xinguo
   Cheng, Jun
   Wu, Shiqian
   Song, Wu
TI A framework of timestamp replantation for panorama video surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video panorama surveillance; Timestamp localization; Timestamp removal;
   Timestamp plantation; PTZ motion; Color correction
ID IMAGE; REGISTRATION; LOCALIZATION
AB This paper presents a framework to automatically replant timestamps for panorama video surveillance. The system mainly comprises six modules: 1) timestamp localization; 2) image registration; 3) timestamp pixel recovery; 4) color correction; 5) timestamp recognition; and 6) panorama video generation. The proposed framework first develops a method to localize the timestamp by employing the method of locating digital video clocks. Then, a fast and novel method is developed to recover the pixels covered by timestamps. The proposed method has fast speed because a fast image translation estimation procedure is introduced based on the PTZ camera motion estimation and global histogram-based image matching. Moreover, a hybrid color correction method by combining region matching with the gamma correction and the linear correction is presented. To plant timestamps accurately, a timestamp recognition procedure is developed by adopting the time recognition method for digit video clocks. Experimental results show that the proposed approach can accurately remove timestamps in real time, the recovered frames are visually consistent with the real scene, and the performance of color correction for panorama video is visually acceptable.
C1 [Yu, Xinguo; Cheng, Jun; Song, Wu] Cent China Normal Univ, Natl Engn Res Ctr E Learning, Wuhan, Peoples R China.
   [Cheng, Jun] Hubei Polytech Univ, Comp Sch, Huangshi, Peoples R China.
   [Wu, Shiqian] Wuhan Univ Sci & Technol, Coll Machinery & Automat, Wuhan, Peoples R China.
   [Song, Wu] Hunan Univ Arts & Sci, Changde, Peoples R China.
C3 Central China Normal University; Hubei Polytechnic University; Wuhan
   University of Science & Technology; Hunan University of Arts & Science
RP Cheng, J (corresponding author), Cent China Normal Univ, Natl Engn Res Ctr E Learning, Wuhan, Peoples R China.; Cheng, J (corresponding author), Hubei Polytech Univ, Comp Sch, Huangshi, Peoples R China.
EM juncheng@mails.ccnu.edu.cn
RI Cheng, Jun/AAE-6928-2019; Wu, Shiqian/W-4067-2019
OI Cheng, Jun/0000-0002-3483-747X; Wu, Shiqian/0000-0002-6383-7663
FU National Natural Science Foundation of China [61272206]
FX This work is partially supported by National Natural Science Foundation
   of China (No. 61272206).
CR [Anonymous], 1979, P INT WORKSHOP IMAGE
   [Anonymous], 2009, Proceedings of the 17th ACM International Conference on Multimedia
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bu F, 2008, LECT NOTES COMPUT SC, V5353, P306
   Chugh S., 2011, INT J SCI ENG RES, V2, P1
   Covavisaruch N, 2004, CISST '04: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON IMAGING SCIENCE, SYSTEMS, AND TECHNOLOGY, P173
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Farbman Z, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531373
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gevrekci M, 2007, INT CONF ACOUST SPEE, P1261
   Ha SJ, 2007, IEEE T CONSUM ELECTR, V53, P1217, DOI 10.1109/TCE.2007.4429204
   Li Y., 2006, ICASSP 2006, VII, P653
   Li YQ, 2006, INT C PATT RECOG, P128
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lyu MR, 2005, IEEE T CIRC SYST VID, V15, P243, DOI 10.1109/TCSVT.2004.841653
   Mishra A, 2012, PROC CVPR IEEE, P2687, DOI 10.1109/CVPR.2012.6247990
   Neumann L, 2012, PROC CVPR IEEE, P3538, DOI 10.1109/CVPR.2012.6248097
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Shahab A, 2011, PROC INT CONF DOC, P1491, DOI 10.1109/ICDAR.2011.296
   Smith R, 2007, PROC INT CONF DOC, P629, DOI 10.1109/icdar.2007.4376991
   Tian GY, 2002, SIXTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P483, DOI 10.1109/IV.2002.1028817
   Tico M, 2010, CONF REC ASILOMAR C, P860, DOI 10.1109/ACSSC.2010.5757689
   Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402
   Wang T, 2012, INT C PATT RECOG, P3304
   Weinman JJ, 2009, IEEE T PATTERN ANAL, V31, P1733, DOI 10.1109/TPAMI.2009.38
   Wexler Y, 2007, IEEE T PATTERN ANAL, V29, P463, DOI 10.1109/TPAMI.2007.60
   Wu SQ, 2014, IEEE SIGNAL PROC LET, V21, P885, DOI 10.1109/LSP.2014.2318302
   Xiong Y, 2009, INT C INT MULT COMP, P219
   Xiong YG, 2010, IEEE T CONSUM ELECTR, V56, P2592, DOI 10.1109/TCE.2010.5681145
   Xu W, 2010, PROC CVPR IEEE, P263, DOI 10.1109/CVPR.2010.5540202
   Yin P, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, PROCEEDINGS, P73
   Yu X., 2008, P 2008 IEEE INT EL D, P1
   Yu XG, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S021800141555006X
   Yu XG, 2012, INT C PATT RECOG, P1217
   Zhang MJ, 2001, VSMM 2001: SEVENTH INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS AND MULTIMEDIA, PROCEEDINGS, P328, DOI 10.1109/VSMM.2001.969687
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 37
TC 4
Z9 4
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10357
EP 10381
DI 10.1007/s11042-015-3051-1
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800013
DA 2024-07-18
ER

PT J
AU Pedronette, DCG
   Torres, RD
AF Guimaraes Pedronette, Daniel Carlos
   Torres, Ricardo da S.
TI Combining re-ranking and rank aggregation methods for image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval; Re-ranking; Rank aggregation; Fusion
ID EXPLOITING CONTEXTUAL INFORMATION; CLASSIFICATION; RECOGNITION;
   SIMILARITY; DESCRIPTOR
AB This paper presents novel approaches for combining re-ranking and rank aggregation methods aiming at improving the effectiveness of Content-Based Image Retrieval (CBIR) systems. Given a query image as input, CBIR systems retrieve the most similar images in a collection by taking into account image visual properties. In this scenario, accurately ranking collection images is of great relevance. Aiming at improving the effectiveness of CBIR systems, re-ranking and rank aggregation algorithms have been proposed. However, different re-ranking and rank aggregation approaches, applied to different image descriptors, may produce different and complementary image rankings. In this paper, we present four novel approaches for combining these rankings aiming at obtaining more effective results. Several experiments were conducted involving shape, color, and texture descriptors. The proposed approaches are also evaluated on multimodal retrieval tasks, considering visual and textual descriptors. Experimental results demonstrate that our approaches can improve significantly the effectiveness of image retrieval systems.
C1 [Guimaraes Pedronette, Daniel Carlos] Sao Paulo State Univ UNESP, Dept Stat Appl Math & Comp, Rio Claro, Brazil.
   [Torres, Ricardo da S.] Univ Campinas UNICAMP, Recod Lab, Inst Comp, Campinas, SP, Brazil.
C3 Universidade Estadual Paulista; Universidade Estadual de Campinas
RP Pedronette, DCG (corresponding author), Sao Paulo State Univ UNESP, Dept Stat Appl Math & Comp, Rio Claro, Brazil.
EM daniel@rc.unesp.br; rtorres@ic.unicamp.br
RI Pedronette, Daniel/X-9057-2019
OI Pedronette, Daniel/0000-0002-2867-4838
FU Sao Paulo Research Foundation - FAPESP [2013/08645-0]; CNPq
   [306580/2012-8, 484254/2012-0]; CAPES; AMD; Microsoft Research
FX The authors are grateful to Sao Paulo Research Foundation - FAPESP
   (grant 2013/08645-0), CNPq (grants 306580/2012-8 and 484254/2012-0),
   CAPES, AMD, and Microsoft Research for the financial support. Authors
   are also grateful to Rodrigo T. Calumby for his support in the
   experiments involving multimodal searches.
CR [Anonymous], 2003, ACM S APPL COMP, DOI DOI 10.1145/952532.952698
   [Anonymous], 2012, IEEE C COMP VIS PATT
   [Anonymous], 1994, P TREC
   [Anonymous], 2007, P 16 INT C WORLD WID, DOI DOI 10.1145/1242572.1242638
   Arica N, 2003, PATTERN RECOGN LETT, V24, P1627, DOI 10.1016/S0167-8655(03)00002-3
   Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   Bai XA, 2010, LECT NOTES COMPUT SC, V6313, P328
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Carrillo M, 2009, LECT NOTES ARTIF INT, V5822, P239, DOI 10.1007/978-3-642-04957-6_21
   Clinchant S., 2011, ACM ICMR, P44
   Coppersmith D, 2010, ACM T ALGORITHMS, V6, DOI 10.1145/1798596.1798608
   Cormack GV, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P758, DOI 10.1145/1571941.1572114
   Croft W. B., 2002, ADV INFORM RETRIEVAL, V7, P1
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Deselaers T, 2008, INFORM RETRIEVAL, V11, P77, DOI 10.1007/s10791-007-9039-3
   Fagin R, 2003, SIAM PROC S, P28
   Fagin R., 2004, P 23 ACM SIGMOD SIGA, P47, DOI DOI 10.1145/1055558.1055568
   Faria F.F., 2010, Proceedings of the International Conference on Multimedia information retrieval, P285, DOI DOI 10.1145/1743384.1743434
   Fox E. A., 1994, Second Text REtrieval Conference (TREC-2) (NIST-SP 500-215), P243
   Gopalan R, 2010, LECT NOTES COMPUT SC, V6313, P286
   Guimaraes Pedronette Daniel Carlos, 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P170, DOI 10.1007/978-3-642-33275-3_21
   Pedronette DCG, 2013, INT SYM COMP ARCHIT, P176, DOI 10.1109/SBAC-PAD.2013.19
   Pedronette DCG, 2014, INFORM SCIENCES, V265, P91, DOI 10.1016/j.ins.2013.12.030
   Pedronette DCG, 2012, INT J MULTIMED INF R, V1, P115, DOI 10.1007/s13735-012-0002-8
   Pedronette DCG, 2013, PATTERN RECOGN, V46, P2350, DOI 10.1016/j.patcog.2013.01.004
   Pedronette DCG, 2011, IEEE IMAGE PROC, P97, DOI 10.1109/ICIP.2011.6116726
   Pedronette DCG, 2011, J VISUAL LANG COMPUT, V22, P453, DOI 10.1016/j.jvlc.2011.08.001
   Pedronette DCG, 2010, LECT NOTES COMPUT SC, V6419, P541
   Hoi SCH, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823752
   Huang CB, 2007, INT C COMMUN CIRCUIT, P772
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Jegou H, 2010, IEEE T PATTERN ANAL, V32, P2, DOI 10.1109/TPAMI.2008.285
   Kontschieder Peter, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P655
   Kovalev V, 1998, 1998 MULTIMEDIA MODELING, PROCEEDINGS, P32, DOI 10.1109/MULMM.1998.722972
   Krapac J, 2010, PROC CVPR IEEE, P1094, DOI 10.1109/CVPR.2010.5540092
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   Lewis J, 2006, BIOINFORMATICS, V22, P2298, DOI 10.1093/bioinformatics/btl388
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Ling HB, 2010, LECT NOTES COMPUT SC, V6313, P411
   Nister David, 2006, CVPR
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Park G, 2005, INFORM PROCESS MANAG, V41, P177, DOI 10.1016/j.ipm.2003.08.002
   Pedronette D.C.G., 2010, INT JOINT C COMP VIS, V1, P197
   Pedronette DCG, 2011, ACM INT C MULT RETR
   Perronnin F, 2009, PROC CVPR IEEE, P2350
   Qin DF, 2011, PROC CVPR IEEE, P777, DOI 10.1109/CVPR.2011.5995373
   Schwander O, 2010, INT JOINT C COMP VIS, V1, P118
   Stehling R. O., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P102, DOI 10.1145/584792.584812
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tao B, 2000, J VIS COMMUN IMAGE R, V11, P327, DOI 10.1006/jvci.1999.0448
   Thollard Franck, 2013, Advances in Information Retrieval. 35th European Conference on IR Research, ECIR 2013. Proceedings, P618, DOI 10.1007/978-3-642-36973-5_52
   Torres RD, 2007, IMAGE VISION COMPUT, V25, P3, DOI 10.1016/j.imavis.2005.12.010
   Torres R. S. D., 2006, RITA, V13, P161
   Tu ZW, 2004, LECT NOTES COMPUT SC, V3023, P195
   van de Weijer J, 2006, LECT NOTES COMPUT SC, V3952, P334
   Voravuthikunchai Winn., 2014, ICMR, P129
   Wang XY, 2011, IEEE I CONF COMP VIS, P209, DOI 10.1109/ICCV.2011.6126244
   Williams A, 2007, MULTIMED TOOLS APPL, V34, P239, DOI 10.1007/s11042-006-0087-2
   Wu P, 1999, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES (CBAIVL'99) - PROCEEDINGS, P3, DOI 10.1109/IVL.1999.781114
   Xingwei Yang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2369, DOI 10.1109/CVPR.2011.5995325
   Yang XW, 2008, LECT NOTES COMPUT SC, V5305, P788, DOI 10.1007/978-3-540-88693-8_58
   Yang XW, 2009, PROC CVPR IEEE, P357, DOI 10.1109/CVPRW.2009.5206844
   YOUNG HP, 1974, J ECON THEORY, V9, P43, DOI 10.1016/0022-0531(74)90073-8
   Zhang ST, 2012, LECT NOTES COMPUT SC, V7573, P660, DOI 10.1007/978-3-642-33709-3_47
NR 65
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 9121
EP 9144
DI 10.1007/s11042-015-3044-0
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500016
DA 2024-07-18
ER

PT J
AU Li, M
   Leung, H
AF Li, Meng
   Leung, Howard
TI Graph-based representation learning for automatic human motion
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Motion representation; Graph kernel matching; Motion
   segmentation
ID CAPTURE DATA; RECOGNITION; RETRIEVAL
AB 3D human motion segmentation is a primary processing step for recognition and analysis of motion data recorded by motion capture system. We propose a novel graph based method to segment long motion sequences into segments of different actions. We first introduce a novel Active Joint Relationship Graph (AJRG) construction method which connects the joints that are deemed important for motion segments. In particular, the top-N Relative Ranges of Joint Relative Distances (RRJRD) are proposed to determine which joints should be connected in the resulting graph because these measures indicate the normalized activity levels among the joint pairs. Different motion segments may thus result in different graph structures so the construction of the graphs is made adaptively to the characteristics of these segments and is able to represent a meaningful spatial structure. Second, combining with proposed joint covariance descriptor with temporal pyramid, we give the Active Joint Relationship Graph Kernel (AJRGK) to measure the spatio-temporal consistency between two consecutive motion segments. Furthermore, we propose the Graph Kernel-Based Temporal Cut (GKBTC) to segment the given motion sequences. The experimental results show that our method demonstrates superior performance in comparison to state-of-the-art methods for 3D human motion segmentation.
C1 [Li, Meng] City Univ Hong Kong, Dept Comp Sci, Hall 8 306-C,83 Tat Chee Ave, Kowloon Tong, Hong Kong, Peoples R China.
   [Leung, Howard] City Univ Hong Kong, Dept Comp Sci, AC1-Y6410,83 Tat Chee Ave, Kowloon Tong, Hong Kong, Peoples R China.
C3 City University of Hong Kong; City University of Hong Kong
RP Li, M (corresponding author), City Univ Hong Kong, Dept Comp Sci, Hall 8 306-C,83 Tat Chee Ave, Kowloon Tong, Hong Kong, Peoples R China.
EM mli269-c@my.cityu.edu.hk
CR [Anonymous], THE ANNALS OF STATIS, DOI DOI 10.1214/009053607000000677
   [Anonymous], 2008, ARXIV08052368
   Arikan O, 2003, ACM T GRAPHIC, V22, P402, DOI 10.1145/882262.882284
   Arthur Gretton, 2009, ADV NEURAL INFORM PR, V22, P673
   Barbic J, 2004, PROC GRAPH INTERF, P185
   Borgwardt KM, 2005, BIOINFORMATICS, V21, pI47, DOI 10.1093/bioinformatics/bti1007
   Gärtner T, 2003, LECT NOTES ARTIF INT, V2777, P129, DOI 10.1007/978-3-540-45167-9_11
   Gaüzère B, 2012, INT C PATT RECOG, P1775
   Gong D, 2014, IEEE T PATTERN ANAL, V36, P1414, DOI 10.1109/TPAMI.2013.244
   Hussein, 2013, INT JOINT C ART INT
   Jenkins OC, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P2551, DOI 10.1109/IRDS.2002.1041654
   Lan RY, 2015, VISUAL COMPUT, V31, P35, DOI 10.1007/s00371-013-0902-5
   Li C, 2007, MULTIMED TOOLS APPL, V35, P55, DOI 10.1007/s11042-007-0119-6
   Lin CD, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS, VOLS 1 AND 2, P1
   Lv F, 2006, LECT NOTES COMPUT SC, V3954, P359
   Lv N, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1117, DOI 10.1109/CISP.2013.6745223
   Lv N, 2014, COMPUT ANIMAT VIRT W, V25, P283, DOI 10.1002/cav.1597
   Müller M, 2005, ACM T GRAPHIC, V24, P677, DOI 10.1145/1073204.1073247
   Seward AE, 2005, P 43 ANN SE REG C NE, V2, P388
   Souvenir R, 2005, IEEE I CONF COMP VIS, P648
   Tang JKT, 2008, COMPUT ANIMAT VIRT W, V19, P211, DOI 10.1002/cav.260
   Tang JKT, 2012, PATTERN RECOGN LETT, V33, P420, DOI 10.1016/j.patrec.2011.06.005
   Taniguchi T, 2011, ADV ROBOTICS, V25, P2143, DOI 10.1163/016918611X594775
   Vishwanathan SVN, 2010, J MACH LEARN RES, V11, P1201
   Vogele A, 2014, EFFICIENT UNSUPERVIS
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wei Yi., 2006, VRST 06, P338
   Wen Gaojin., 2006, VRST 06, P165
   Wu S., 2009, P 16 ACM S VIRTUAL R, P207
   Yan Y, 2015, IEEE T PATTERN ANAL, V2016
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P1867, DOI 10.1109/TIP.2015.2413294
   Yan Y, 2013, IEEE I CONF COMP VIS, P1177, DOI 10.1109/ICCV.2013.150
   Yao BP, 2012, LECT NOTES COMPUT SC, V7575, P173, DOI 10.1007/978-3-642-33765-9_13
   Zhao L., 2009, P 17 ACM INT C MULT, P765
   Zhou F, 2013, IEEE T PATTERN ANAL, V35, P582, DOI 10.1109/TPAMI.2012.137
NR 36
TC 5
Z9 5
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 9205
EP 9224
DI 10.1007/s11042-016-3480-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500021
DA 2024-07-18
ER

PT J
AU Piao, JC
   Jung, HS
   Hong, CP
   Kim, SD
AF Piao, Jin-Chun
   Jung, Hyeon-Sub
   Hong, Chung-Pyo
   Kim, Shin-Dug
TI Improving performance on object recognition for real-time on mobile
   devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object recognition; Marker-less; Mobile device; OpenCV; Real-time
AB Augmented reality has been on the rise due to the proliferation of mobile devices. At the same time, object recognition has also come to the fore. In particular, many studies have focused on object recognition based on markerless matching. However, most of these studies have focused on desktop systems, which can have high performance in terms of CPU and memory, rather than investigating the use of mobile systems, which have been previously unable to provide high-performance object recognition based on markerless matching. In this paper, we propose a method that uses the OpenCV mobile library to improve real-time object recognition performance on mobile systems. First, we investigate the original object recognition algorithm to identify performance bottlenecks. Second, we optimize the algorithm by analyzing each module and applying appropriate code enhancements. Last, we change the operational structure of the algorithm to improve its performance, changing the execution frequency of the object recognition task from every frame to every four frames for real-time operation. During the three frames in which the original method is not executed, the object is instead recognized using the mobile devices accelerometer. We carry out experiments to reveal how much each aspect of our method improves the overall object recognition performance; overall, experimental performance improves by approximately 800 %, with a corresponding reduction of approximately 1 % in object recognition accuracy. Therefore, the proposed technique can be used to significantly improve the performance of object recognition based on markerless matching on mobile systems for real-time operation.
C1 [Piao, Jin-Chun; Kim, Shin-Dug] Yonsei Univ, Dept Comp Sci, 50 Yonsei Ro, Seoul 120749, South Korea.
   [Jung, Hyeon-Sub] LG Elect, Home Entertainment, Pyongtaek, South Korea.
   [Hong, Chung-Pyo] LG Elect, Mobile Commun, Seoul, South Korea.
C3 Yonsei University; LG Electronics; LG Electronics
RP Kim, SD (corresponding author), Yonsei Univ, Dept Comp Sci, 50 Yonsei Ro, Seoul 120749, South Korea.
EM kumcun@yonsei.ac.kr; jung2413@naver.com; hulkboy@yonsei.ac.kr;
   sdkim@yonsei.ac.kr
OI Piao, Jin-Chun/0000-0003-1151-6814
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Science, ICT and Future Planning
   [2012R1A1A2043400]; MSIP(Ministry of Science, ICT and Future Planning),
   Korea, under the Global IT Talent support program
   [NIPA-2014-H0905-14-1003]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Science, ICT and Future Planning (2012R1A1A2043400), and the
   MSIP(Ministry of Science, ICT and Future Planning), Korea, under the
   Global IT Talent support program (NIPA-2014-H0905-14-1003) supervised by
   the NIPA(National IT Industry Promotion Agency).
CR ARM, 2008, ARM NEON TECHN ARM N
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gomes RB, 2013, COMPUT GRAPH-UK, V37, P496, DOI 10.1016/j.cag.2013.03.005
   Kaehler A., 2015, LEARNING OPENCV COMP
   Kim J.-H., 2013, LECT NOTES ELECT ENG, P367
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   OpenCV, 2013, OEPNCV 2 4 6 0 API R
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   SMPTE, 1987, SMPTE J, P1150
   Sugano H, 2007, LECT NOTES COMPUT SC, V4872, P932
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
NR 13
TC 3
Z9 3
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 16
BP 9623
EP 9640
DI 10.1007/s11042-015-2999-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LO
UT WOS:000382112500007
DA 2024-07-18
ER

PT J
AU Benrhouma, O
   Hermassi, H
   Abd El-Latif, AA
   Belghith, S
AF Benrhouma, Oussama
   Hermassi, Houcemeddine
   Abd El-Latif, Ahmed A.
   Belghith, Safya
TI Chaotic watermark for blind forgery detection in images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermark; Chaotic maps; Blind detection; Tamper detection
ID COPYRIGHT PROTECTION; TAMPER DETECTION; SCHEME; AUTHENTICATION
AB In this paper, a new chaos based watermarking scheme for effective tamper detection in images is proposed. The proposed scheme is able to detect any possible forgery and spot the areas which have been tampered. To improve the efficiency of the proposed scheme, a binary watermark is constructed from the image itself, which makes the watermark unique for every image and guarantee the blindness in the detection process. To guarantee the security of the proposed scheme, chaotic maps are used to complicate the embedding and the detection process to reduce the vulnerability to different attacks. Experimental results and security analysis show that the proposed scheme achieves superior tamper detection under common attacks.
C1 [Benrhouma, Oussama; Hermassi, Houcemeddine; Belghith, Safya] ENIT, SysComLab, Tunis, Tunisia.
   [Abd El-Latif, Ahmed A.] Menoufia Univ, Fac Sci, Dept Math, Shibin Al Kawm 32511, Egypt.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT); Egyptian Knowledge Bank (EKB); Menofia University
RP Benrhouma, O (corresponding author), ENIT, SysComLab, Tunis, Tunisia.
EM oussama.benrhoumaa@gmail.com
RI Abd El-Latif, Ahmed A. A./GRO-1613-2022; Hermassi,
   Houcemeddine/J-2352-2012; hermassi, houcemeddine/ADK-4317-2022;
   Benrhouma, Oussama/ABE-2730-2020; Benrhouma, Oussama/JCD-7434-2023
OI Abd El-Latif, Ahmed A. A./0000-0002-5068-2033; Benrhouma,
   Oussama/0000-0002-4540-3650; Hermassi, houcemeddine/0000-0002-4681-4312;
   Belghith, Safya/0000-0001-7408-7848
FU ministry of scientific research in Egypt [4-13-A1]; ministry of
   scientific research in Tunisia [4-13-A1]
FX We sincerely thank the two ministries of scientific research in Egypt
   and Tunisia (Egypt-Tunisia Cooperation Programme:4-13-A1) for their
   valuable support. The authors are also thankful to the editor and the
   anonymous reviewers for their advices, valuable comments and suggestions
   that improved the technical and editorial quality of this paper.
CR [Anonymous], P IEEE INT C IM PROC
   [Anonymous], P SPI EINTERNATIONAL
   [Anonymous], CORRELATION PROPERNE
   [Anonymous], 2001, ACM MULTIMEDIA
   [Anonymous], INT J ELECT COMMUN
   [Anonymous], P SPIE SEC WATERMARK
   Aslantas V, 2009, OPT COMMUN, V282, P2806, DOI 10.1016/j.optcom.2009.04.034
   Bao JH, 2012, NONLINEAR DYNAM, V70, P1365, DOI 10.1007/s11071-012-0539-3
   Benrhouma O, 2015, NONLINEAR DYNAM, V79, P1817, DOI 10.1007/s11071-014-1777-3
   Bhatnagar G, 2011, MULTIMED TOOLS APPL, V52, P621, DOI 10.1007/s11042-009-0433-2
   Celik MU, 2002, IEEE T IMAGE PROCESS, V11, P585, DOI 10.1109/TIP.2002.1014990
   Chang CC, 2006, PATTERN RECOGN LETT, V27, P439, DOI 10.1016/j.patrec.2005.09.006
   Chang EC, 2003, MULTIMEDIA SYST, V9, P121, DOI 10.1007/s0530-003-0083-6
   Di Martino F, 2012, INFORM SCIENCES, V195, P62, DOI 10.1016/j.ins.2012.01.014
   Dittmann J, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P209, DOI 10.1109/MMCS.1999.778274
   Fridrich J, 2002, PROC SPIE, V4675, P691, DOI 10.1117/12.465330
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P3085, DOI 10.1007/s11042-013-1579-5
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P2469, DOI 10.1007/s11042-013-1561-2
   Horng SJ, 2013, J VIS COMMUN IMAGE R, V24, P1099, DOI 10.1016/j.jvcir.2013.07.008
   Hsu CS, 2010, OPT COMMUN, V283, P1737, DOI 10.1016/j.optcom.2009.12.073
   Huo YR, 2014, MULTIMED TOOLS APPL, V72, P123, DOI 10.1007/s11042-012-1317-4
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Lin CY, 2001, IEEE T CIRC SYST VID, V11, P153, DOI 10.1109/76.905982
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P11888, DOI 10.1016/j.eswa.2009.04.026
   Lin WH, 2009, EXPERT SYST APPL, V36, P11509, DOI 10.1016/j.eswa.2009.03.060
   Lin WH, 2009, EXPERT SYST APPL, V36, P9869, DOI 10.1016/j.eswa.2009.02.036
   Lu CS, 2003, IEEE T MULTIMEDIA, V5, P161, DOI 10.1109/TMM.2003.811621
   Lu W, 2006, APPL MATH COMPUT, V181, P886, DOI 10.1016/j.amc.2006.02.012
   Luo T, 2014, MULTIMED TOOLS APPL, V73, P1077, DOI 10.1007/s11042-013-1435-7
   Niu PP, 2011, EXPERT SYST APPL, V38, P2081, DOI 10.1016/j.eswa.2010.07.147
   Paquet AH, 2003, SIGNAL PROCESS, V83, P2117, DOI 10.1016/S0165-1684(03)00171-3
   Poonkuntran S, 2014, MULTIMED TOOLS APPL, V68, P79, DOI 10.1007/s11042-012-1227-5
   Rawat S, 2011, AEU-INT J ELECTRON C, V65, P840, DOI 10.1016/j.aeue.2011.01.016
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Simitopoulos D, 2003, IEEE T CIRC SYST VID, V13, P732, DOI 10.1109/TCSVT.2003.815947
   Tang CW, 2003, IEEE T SIGNAL PROCES, V51, P950, DOI 10.1109/TSP.2003.809367
   Wu XY, 2007, PHYS LETT A, V365, P403, DOI 10.1016/j.physleta.2007.01.034
   Yeung MM, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P680, DOI 10.1109/ICIP.1997.638587
NR 40
TC 59
Z9 59
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 14
BP 8695
EP 8718
DI 10.1007/s11042-015-2786-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LW
UT WOS:000382113300026
DA 2024-07-18
ER

PT J
AU Huan, RH
   Wang, C
   Pan, Y
   Guo, F
   Tao, YF
AF Huan, Ruohong
   Wang, Chu
   Pan, Yun
   Guo, Feng
   Tao, Yifan
TI New structure for multi-aspect SAR image target recognition with
   multi-level joint consideration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Synthetic Aperture Radar; Target Recognition; Multi-aspect; Multi-level
ID LOOK SAR; ATR; CLASSIFICATION; PERFORMANCE; FUSION; RESTORATION;
   ALGORITHMS; RESOLUTION; MODEL
AB A new structure for SAR target recognition using multi-aspect SAR images is proposed. The new structure applies new approaches in the two levels of SAR image target recognition, which are data level and decision level, and combines the benefits of the two. Projections onto convex sets (POCS) super-resolution reconstruction algorithm is used in the data level of the new structure, which is to advance the resolution of the SAR image by using a series of multi-aspect SAR images. Weighted Bayes decision fusion algorithm is proposed in the decision level to jointly consider the benefit from the data level. All outcomes from the classifiers are fused in the decision level to generate the final result, which combines the multi-level benefits. Verification and analysis is performed to the proposed structure with multi-target image data in MSTAR database. Experimental results indicate that using the proposed structure for multi-aspect SAR images with multi-level joint consideration, the recognition rate is significantly advanced than that using single SAR target image. Meanwhile, the recognition rate by this structure is also higher than that using individual level approach.
C1 [Huan, Ruohong; Wang, Chu; Guo, Feng; Tao, Yifan] Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou 310023, Zhejiang, Peoples R China.
   [Pan, Yun] Zhejiang Univ, Dept Informat Sci & Elect Engn, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University of Technology; Zhejiang University
RP Huan, RH (corresponding author), Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou 310023, Zhejiang, Peoples R China.
EM huanrh@zjut.edu.cn
RI GUO, FENG/JRX-3555-2023
FU National Natural Science Foundation of China [61302129, 61204030];
   Zhejiang Provincial Natural Science Foundation of China [LY13F020030];
   Zhejiang Provincial Nonprofit Technology Research Projects [2014C31045];
   China Scholarship Council
FX The work is supported by the National Natural Science Foundation of
   China (No. 61302129, No. 61204030), Zhejiang Provincial Natural Science
   Foundation of China (No. LY13F020030), Zhejiang Provincial Nonprofit
   Technology Research Projects (2014C31045) and China Scholarship Council.
CR Bhanu B, 2002, P SOC PHOTO-OPT INS, V4727, P290, DOI 10.1117/12.478686
   Brendel GF, 2000, P SOC PHOTO-OPT INS, V4053, P567, DOI 10.1117/12.396367
   Brown MZ, 2003, PROC SPIE, V5095, P265, DOI 10.1117/12.487171
   Ettinger G, 2002, P SOC PHOTO-OPT INS, V4727, P277, DOI 10.1117/12.478685
   Fung YH, 2006, IEEE T IMAGE PROCESS, V15, P1985, DOI 10.1109/TIP.2006.873432
   He C, 2011, INT GEOSCI REMOTE SE, P366, DOI 10.1109/IGARSS.2011.6048975
   Hong Y, 2008, P 5 INT C VIS INF EN, P494, DOI [10.1049/cp:20080364, DOI 10.1049/CP:20080364]
   Hsu J. T., 2004, Proceedings. Third International Conference on Image and Graphics, P572
   Huan R, 2010, P 2010 WASE INT C IN, V2, P19, DOI [10.1109/ICIE.2010.101, DOI 10.1109/ICIE.2010.101]
   Huan RH, 2013, PROG ELECTROMAGN RES, V134, P267, DOI 10.2528/PIER12100304
   Ito Y, 2009, INT GEOSCI REMOTE SE, P2826, DOI 10.1109/IGARSS.2009.5417409
   Novak LM, 2000, IEEE T AERO ELEC SYS, V36, P1279, DOI 10.1109/7.892675
   Novak LM, 1998, CONF REC ASILOMAR C, P3, DOI 10.1109/ACSSC.1998.750815
   O'Sullivan JA, 2001, IEEE T AERO ELEC SYS, V37, P91, DOI 10.1109/7.913670
   Ross T, 1998, P SOC PHOTO-OPT INS, V3370, P566, DOI 10.1117/12.321859
   Sandirasegaram N, 2005, PROC SPIE, V5808, P314, DOI 10.1117/12.596305
   Sezan M I, 1982, IEEE Trans Med Imaging, V1, P95, DOI 10.1109/TMI.1982.4307556
   Snyder W, 2003, P SOC PHOTO-OPT INS, V5095, P396, DOI 10.1117/12.487036
   STARK H, 1990, 1990 IEEE INTERNATIONAL SYMP ON CIRCUITS AND SYSTEMS, VOLS 1-4, P2034, DOI 10.1109/ISCAS.1990.112153
   STARK H, 1989, J OPT SOC AM A, V6, P1715, DOI 10.1364/JOSAA.6.001715
   Su H, 2010, P 2010 2 INT C SIGN, DOI [10.1109/ICSPS.2010.5555838, DOI 10.1109/ICSPS.2010.5555838]
   Sundareshan MK, 2004, OPT ENG, V43, P199, DOI 10.1117/1.1626665
   Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640
   Vespe M, 2006, IEEE RAD CONF, P256, DOI 10.1109/RADAR.2006.1631809
   Xiao Z, 2006, P 1 INT S SYST CONTR, P680
   Youla D C, 1982, IEEE Trans Med Imaging, V1, P81, DOI 10.1109/TMI.1982.4307555
   Zhang HC, 2012, IEEE T AERO ELEC SYS, V48, P2481, DOI 10.1109/TAES.2012.6237604
   Zhao Q, 2001, IEEE T AERO ELEC SYS, V37, P643, DOI 10.1109/7.937475
NR 28
TC 2
Z9 2
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 13
BP 7519
EP 7540
DI 10.1007/s11042-015-2674-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DR5EA
UT WOS:000379924600003
DA 2024-07-18
ER

PT J
AU Krulis, M
   Lokoc, J
   Skopal, T
AF Krulis, Martin
   Lokoc, Jakub
   Skopal, Tomas
TI Efficient extraction of clustering-based feature signatures using GPU
   architectures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE GPU; Parallel; Extraction; Feature signature; Image indexing
AB Similarity search and content-based retrieval have become widely used in multimedia database systems that often manage huge data collections. Unfortunately, many effective content-based similarity models cannot be fully utilized for larger datasets, as they are computationally demanding and require massive parallel processing for both feature extraction and query evaluation tasks. In this work, we address the performance issues of effective similarity models based on feature signatures, where we focus on fast feature extraction from image thumbnails using affordable hardware. More specifically, we propose a multi-GPU implementation that increases the extraction speed by two orders of magnitude with respect to a single-threaded CPU implementation. Since the extraction algorithm is not directly parallelizable, we propose a modification of the algorithm embracing the SIMT execution model. We have experimentally verified that our GPU extractor can be successfully used to index large image datasets comprising millions of images. In order to obtain optimal extraction parameters, we employed the GPU extractor in an extensive empirical investigation of the parameter space. The experimental results are discussed from the perspectives of both performance and similarity precision.
C1 [Krulis, Martin; Lokoc, Jakub; Skopal, Tomas] Charles Univ Prague, Fac Math & Phys, SIRET Res Grp, Malostranske Nam 25, Prague 11800, Czech Republic.
C3 Charles University Prague
RP Krulis, M (corresponding author), Charles Univ Prague, Fac Math & Phys, SIRET Res Grp, Malostranske Nam 25, Prague 11800, Czech Republic.
EM krulis@ksi.mff.cuni.cz; lokoc@ksi.mff.cuni.cz; skopal@ksi.mff.cuni.cz
RI Skopal, Tomas/G-2679-2017; Krulis, Martin/D-6454-2017; Lokoc,
   Jakub/P-1216-2017
OI Skopal, Tomas/0000-0002-6591-0879; Krulis, Martin/0000-0002-0985-8949;
   Lokoc, Jakub/0000-0002-3558-4144
FU Czech Science Foundation (GACR) [P103/14/14292P, P202/12/P297,
   P202/11/0968]
FX This research has been supported by Czech Science Foundation (GACR)
   projects P103/14/14292P, P202/12/P297, and P202/11/0968.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], MMM
   [Anonymous], EUR 2003
   [Anonymous], 2013, P 3 ACM C INT C MULT
   [Anonymous], 2006, ADV DATABASE SYSTEMS
   Bai Hong-tao, 2009, 2009 WRI World Congress on Computer Science and Information Engineering (CSIE 2009), P651, DOI 10.1109/CSIE.2009.491
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Beecks Christian., 2010, ACM International Conference on Image and Video Retrieval, P438, DOI [10.1145/1816041.1816105, DOI 10.1145/1816041.1816105]
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chávez E, 2001, ACM COMPUT SURV, V33, P273, DOI 10.1145/502807.502808
   Colantoni P, 2003, VISION, MODELING, AND VISUALIZATION 2003, P383
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   DEHNE F, 1987, INFORM SYST, V12, P171, DOI 10.1016/0306-4379(87)90041-X
   Farivar Reza, 2008, Proceedings of the 2008 International Conference on Parallel and Distributed Processing Techniques and Applications. (PDPTA 2008), P340
   Fung J., 2005, GPU GEMS, V2, P649
   GOTLIEB CC, 1990, COMPUT VISION GRAPH, V51, P70, DOI 10.1016/S0734-189X(05)80063-5
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Kozak S, 2013, PROC VLDB ENDOW, V6, P1450, DOI 10.14778/2536274.2536334
   Krulis M, 2012, ITAT, P17
   Krulis M, 2012, DISTRIB PARALLEL DAT, V30, P179, DOI 10.1007/s10619-012-7092-4
   Li P, 2013, IEEE T MULTIMEDIA, V15, P141, DOI 10.1109/TMM.2012.2199970
   LI X, 1989, PARALLEL COMPUT, V11, P275, DOI 10.1016/0167-8191(89)90036-7
   Lokoc Jakub, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8326, P415, DOI 10.1007/978-3-319-04117-9_49
   Lokoc Jakub, 2012, Similarity Search and Applications. Proceedings of the 5th International Conference, SISAP 2012, P177, DOI 10.1007/978-3-642-32153-5_13
   Lokoc J, 2012, P 2 ACM INT C MULT R, V66
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo Y., 2008, IEEE COMPUTER SOC C, P1, DOI [DOI 10.1109/CVPRW.2008.4563088, 10.1109/CVPRW.2008.4563088]
   MCLAREN K, 1976, J SOC DYERS COLOUR, V92, P338
   *MPEG 7, 2002, 1593832002 ISOIEC
   Ogawa Kohei, 2010, Proceedings 2010 First International Conference on Networking and Computing (ICNC 2010), P279, DOI 10.1109/IC-NC.2010.13
   Park BG, 2006, LECT NOTES COMPUT SC, V4179, P990
   Parker J. R., 2010, Algorithms for Image Processing and Computer Vision
   Pelleg D., 1999, P 5 ACM SIGKDD IN TE, P277, DOI DOI 10.1145/312129.312248
   Roodt Y., 2007, IMAGE PROCESSING GPU
   Rubner Y., 2001, Perceptual metrics for image database navigation
   Shalom SAA, 2008, LECT NOTES COMPUT SC, V5182, P166, DOI 10.1007/978-3-540-85836-2_16
   Smolic A., 2007, Proceedings of the International Conference in Central Europe on Computer Graphics, Visualization and Computer Vision, P144
   van de Sande KEA, 2011, IEEE T MULTIMEDIA, V13, P60, DOI 10.1109/TMM.2010.2091400
   Wang M, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2333112.2333120
   Zechner M, 2009, INTENSIVE: 2009 FIRST INTERNATIONAL CONFERENCE ON INTENSIVE APPLICATIONS AND SERVICES, P7, DOI 10.1109/INTENSIVE.2009.19
NR 41
TC 7
Z9 7
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 13
BP 8071
EP 8103
DI 10.1007/s11042-015-2726-y
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DR5EA
UT WOS:000379924600029
DA 2024-07-18
ER

PT J
AU Lima, JB
   Neto, EFD
AF Lima, Juliano B.
   da Silva Neto, Eronides F.
TI Audio encryption based on the cosine number transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia security; Audio encryption; Number-theoretic transform;
   Cosine number transform
ID ALGORITHM
AB In this paper, we introduce an audio encryption scheme based on the cosine number transform (CNT). The transform, which is defined over a finite field, is recursively applied to blocks of samples of a noncompressed digital audio signal. The blocks are selected using a simple overlapping rule, which provides diffusion of the ciphered data to all processed blocks. A secret-key is used to specify the number of times the transform is applied to each one of such blocks. Computer experiments are carried out and security aspects of the proposed scheme are discussed. Our analysis indicates that the method meets the main security requirements of secret-key cryptography. More specifically, after the encryption of 16-bit audio signals, correlation coefficients significantly close to 0 and entropy values close to 16 were obtained. Furthermore, the flexibility of the method easily allows key space sizes greater than 2256 and provides robustness against differential, known-plaintext and chosen-plaintext attacks.
C1 [Lima, Juliano B.; da Silva Neto, Eronides F.] Univ Fed Pernambuco, Dept Elect & Syst, Ave Arquitetura S-N, BR-50740550 Recife, PE, Brazil.
C3 Universidade Federal de Pernambuco
RP Lima, JB (corresponding author), Univ Fed Pernambuco, Dept Elect & Syst, Ave Arquitetura S-N, BR-50740550 Recife, PE, Brazil.
EM juliano_bandeira@ieee.org
RI da Silva Neto, Eronides/AAU-8109-2020; da Silva Neto,
   Eronides/HTP-8062-2023; Lima, Juliano/D-8770-2014
OI Lima, Juliano/0000-0002-1474-1147
FU Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPq)
   [307686/2014-0, 456744/2014-2]
FX This research was supported by Conselho Nacional de Desenvolvimento
   Cientifico e Tecnologico (CNPq) under Grants 307686/2014-0 and
   456744/2014-2.
CR Abuturab MR, 2013, OPT LASER ENG, V51, P317, DOI 10.1016/j.optlaseng.2012.09.008
   [Anonymous], 2007, MORGAN KAUFMANN SERI
   [Anonymous], 2013, INT J ENG RES TECHNO
   [Anonymous], IEICE T FUNDAMENT A
   [Anonymous], APPL SOFT COMPUT
   BIRTWISTLE DT, 1982, SIGNAL PROCESS, V4, P287, DOI 10.1016/0165-1684(82)90004-4
   Blahut Richard E., 2010, FAST ALGORITHMS SIGN
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Cintra RJ, 2009, SIGNAL PROCESS-IMAGE, V24, P587, DOI 10.1016/j.image.2009.04.003
   Eldin SMS, 2015, INT J SPEECH TECHNOL, V18, P131, DOI 10.1007/s10772-014-9253-5
   Fallahpour M, 2009, IEICE ELECTRON EXPR, V6, P1057, DOI 10.1587/elex.6.1057
   Gnanajeyaraman R., 2009, International Journal of Recent Trends in Engineering, V1, P103
   Gong LH, 2013, J MOD OPTIC, V60, P1074, DOI 10.1080/09500340.2013.831139
   I. E, 2011, ECRYPT 2 YEARLY REPO
   Kok CW, 1997, IEEE T SIGNAL PROCES, V45, P757, DOI 10.1109/78.558495
   Kwon GR, 2012, MULTIMED TOOLS APPL, V59, P885, DOI 10.1007/s11042-011-0771-8
   Lian S., 2008, Multimedia Content Encryption: Techniques And Applications
   Lima JB, 2013, SIGNAL PROCESS-IMAGE, V28, P1537, DOI 10.1016/j.image.2013.05.008
   Lima JB, 2011, APPL ALGEBR ENG COMM, V22, P393, DOI 10.1007/s00200-011-0158-0
   Madain A, 2014, MULTIMED TOOLS APPL, V71, P1803, DOI 10.1007/s11042-012-1306-7
   Nibouche O, 2009, IEEE T CIRCUITS-I, V56, P1668, DOI 10.1109/TCSI.2008.2008266
   Peng X, 2003, OPTIK, V114, P69, DOI 10.1078/0030-4026-00224
   Rubanov NS, 1998, IEEE T SIGNAL PROCES, V46, P813, DOI 10.1109/78.661355
   Sadek MM, 2015, MULTIMED TOOLS APPL, V74, P7063, DOI 10.1007/s11042-014-1952-z
   Shih FY, 2013, MULTIMEDIA SECURITY: WATERMARKING, STEGANOGRAPHY, AND FORENSICS, P1
   Sui LS, 2014, OPT LASER ENG, V62, P139, DOI 10.1016/j.optlaseng.2014.06.003
   Wang HG, 2010, IEEE T MULTIMEDIA, V12, P215, DOI 10.1109/TMM.2010.2041102
   Yan DQ, 2012, COMPUT SECUR, V31, P704, DOI 10.1016/j.cose.2012.04.006
   Ye GD, 2010, PATTERN RECOGN LETT, V31, P347, DOI 10.1016/j.patrec.2009.11.008
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
NR 30
TC 59
Z9 60
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 14
BP 8403
EP 8418
DI 10.1007/s11042-015-2755-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LW
UT WOS:000382113300012
DA 2024-07-18
ER

PT J
AU Nguyen, TS
   Chang, CC
   Hsueh, HS
AF Nguyen, Thai-Son
   Chang, Chin-Chen
   Hsueh, Huan-Sheng
TI High capacity data hiding for binary image based on block classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; High embedding capacity; Block classification; Small image
   distortion
ID AUTHENTICATION; SCHEME
AB Data hiding is a technique by which secret data can be delivered securely by embedding it into a cover multimedia document. In this paper, a high capacity data hiding scheme based on block classification is proposed for binary images. In the proposed scheme, the block classification process determines complex regions in the image used for embedding secret data. For each block in the complex region of the image, some secret bits are embedded by lightly modifying few pixels to minimize an embedding distortion. On the receiver side, the secret bits can be then extracted without requiring the original image. Experimental results demonstrated that the proposed scheme obtained a high embedding capacity while maintaining a low distortion. In addition, when compared with previous schemes for binary images, the proposed scheme improved the embedding capacity significantly with the same level of embedding distortion.
C1 [Nguyen, Thai-Son; Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Nguyen, Thai-Son] Tra Vinh Univ, Dept Informat Technol, Tra Vinh, Tra Vinh Provin, Vietnam.
   [Chang, Chin-Chen] Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
   [Hsueh, Huan-Sheng] Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi, Taiwan.
C3 Feng Chia University; Tra Vinh University; Asia University Taiwan;
   National Chung Cheng University
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.; Chang, CC (corresponding author), Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
EM thaison@tvu.edu.vn; alan3c@gmail.com; a0919059585@gmail.com
RI Chang, Ching-Chun/JAN-6210-2023; Nguyen, Thai-Son/AGD-3594-2022
OI Nguyen, Thai-Son/0000-0001-7008-0462
CR Chamlawi R, 2010, INFORM SCIENCES, V180, P4909, DOI 10.1016/j.ins.2010.08.039
   Chang CC, 2014, MULTITOOLS IN PRESS
   Cheng J, 2005, IEEE INT SYMP CIRC S, P4405
   Guo JM, 2011, SIGNAL PROCESS, V91, P126, DOI 10.1016/j.sigpro.2010.06.017
   Jung KH, 2014, INFORM SCIENCES, V277, P188, DOI 10.1016/j.ins.2014.02.016
   Lee Y, 2009, INFORM SCIENCES, V179, P3866, DOI 10.1016/j.ins.2009.07.014
   Lin KT, 2011, OPT COMMUN, V284, P1778, DOI 10.1016/j.optcom.2010.12.010
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Nguyen T.S., 2014, SMART COMPUT REV, V4, P230, DOI [10.6029/smartcr.2014.03.008, DOI 10.6029/SMARTCR.2014.03.008]
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tseng HW, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P307
   Tseng YC, 2002, IEEE T COMPUT, V51, P873, DOI 10.1109/TC.2002.1017706
   Tseng YC, 2001, IEEE INFOCOM SER, P887, DOI 10.1109/INFCOM.2001.916280
   Tzeng CH, 2003, IEEE COMMUN LETT, V7, P443, DOI 10.1109/LCOMM.2003.815656
   Venkatesan M, 2007, P 3 INT S INF ASS SE, P468
   Wang CC, 2014, J SYST SOFTWARE, V93, P152, DOI 10.1016/j.jss.2014.02.023
   Wu M, 2004, IEEE T MULTIMEDIA, V6, P528, DOI 10.1109/tmm.2004.830814
   Yang HJ, 2007, IEEE T MULTIMEDIA, V9, P475, DOI 10.1109/TMM.2006.887990
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 20
TC 6
Z9 6
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 14
BP 8513
EP 8526
DI 10.1007/s11042-015-2768-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LW
UT WOS:000382113300017
DA 2024-07-18
ER

PT J
AU Wang, SF
   Gao, Z
   He, S
   He, MH
   Ji, Q
AF Wang, Shangfei
   Gao, Zhen
   He, Shan
   He, Menghua
   Ji, Qiang
TI Gender recognition from visible and thermal infrared facial images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gender recognition; Thermal infrared images; Visible images; Fusion;
   Learning using privileged information
ID EXPRESSION RECOGNITION; FACE RECOGNITION; CLASSIFICATION; FUSION; 2D
AB Most present research of gender recognition focuses on visible facial images, which are sensitive to illumination changes. In this paper, we proposed hybrid methods for gender recognition by fusing visible and thermal infrared images. First, the active appearance model is used to extract features from visible images, as well as local binary pattern features and several statistical temperature features are extracted from thermal infrared images. Then, feature selection is performed by using the F-test statistic. Third, we propose using Bayesian Networks to perform explicit and implicit fusion of visible and thermal infrared image features. For explicit fusion, we propose two Bayesian Networks to perform decision-level and feature-level fusion. For implicit fusion, we propose using features from one modality as privileged information to improve gender recognition by another modality. Finally, we evaluate the proposed methods on the Natural Visible and Infrared facial Expression spontaneous database and the Equinox face database. Experimental results show that both feature-level and decision-level fusion improve the gender recognition performance, compared to that achieved from one modality. The proposed implicit fusion methods successfully capture the role of privileged information of one modality, thus enhance the gender recognition from another modality.
C1 [Wang, Shangfei; Gao, Zhen; He, Shan; He, Menghua] Univ Sci & Technol China, Sch Comp Sci & Technol, Key Lab Comp & Commun Software Anhui Prov, Hefei 230027, Anhui, Peoples R China.
   [Ji, Qiang] Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Rensselaer Polytechnic Institute
RP Wang, SF (corresponding author), Univ Sci & Technol China, Sch Comp Sci & Technol, Key Lab Comp & Commun Software Anhui Prov, Hefei 230027, Anhui, Peoples R China.
EM sfwang@ustc.edu.cn; gzgqllxh@mail.ustc.edu.cn; shanhe@mail.ustc.edu.cn;
   hemh@mail.ustc.edu.cn; qji@ecse.rpi.edu
RI he, shan/JUV-4092-2023
FU National Natural Science Foundation of China [61175037, 61228304,
   61473270]; US-NSF [CNS-1205664]; Anhui Science and Technology Agency
   [1508085SMF223]
FX This work has been supported by the National Natural Science Foundation
   of China (61175037, 61228304, 61473270), the US-NSF (CNS-1205664), and
   Project from Anhui Science and Technology Agency(1508085SMF223).
CR Abate AF, 2007, PATTERN RECOGN LETT, V28, P1885, DOI 10.1016/j.patrec.2006.12.018
   Aghajanian J, 2009, IEEE I CONF COMP VIS, P1125, DOI 10.1109/ICCV.2009.5459352
   Alexandre LA, 2010, PATTERN RECOGN LETT, V31, P1422, DOI 10.1016/j.patrec.2010.02.010
   [Anonymous], 1990, P ADV NEUR INF PROC
   Arandjelovic O, 2010, PATTERN RECOGN, V43, P1801, DOI 10.1016/j.patcog.2009.11.023
   Balci K, 2002, INT C PATT RECOG, P363, DOI 10.1109/ICPR.2002.1047869
   Baluja S, 2007, INT J COMPUT VISION, V71, P111, DOI 10.1007/s11263-006-8910-9
   Bebis G, 2006, IMAGE VISION COMPUT, V24, P727, DOI 10.1016/j.imavis.2006.01.017
   Bekios-Calfa J, 2011, IEEE T PATTERN ANAL, V33, P858, DOI 10.1109/TPAMI.2010.208
   Buchala S, 2005, INT J SYST SCI, V36, P931, DOI 10.1080/00207720500381573
   Chen X, 2011, IEEE INT C BIOINFORM, P3, DOI 10.1109/BIBM.2011.12
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   De Marsico M, 2010, IEEE T SYST MAN CY A, V40, P121, DOI 10.1109/TSMCA.2009.2033031
   Ding C.H. Q., 2002, RECOMB, P127
   Gaiwak A, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON PERSONAL WIRELESS COMMUNICATIONS, P441, DOI 10.1109/ICPWC.2005.1431384
   Gao W, 2009, LECT NOTES COMPUT SC, V5558, P169, DOI 10.1007/978-3-642-01793-3_18
   Ghiass Reza Shoja., 2013, INT JOINT C NEUR NET, P1
   Golomb BA., 1991, Advances in Neural Information Processing Systems, V3, P572, DOI DOI 10.1007/978-1-4757-2379-3_3
   Gyaourova A, 2004, LECT NOTES COMPUT SC, V2034, P456
   Hernández B, 2007, COMPUT VIS IMAGE UND, V106, P258, DOI 10.1016/j.cviu.2006.08.012
   Jain AK, 2004, PROC SPIE, V5404, P561, DOI 10.1117/12.542890
   Khan MM, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1462055.1462061
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   Maekinen E, 2008, PATTERN RECOGN LETT, V29, P1544, DOI 10.1016/j.patrec.2008.03.016
   Mäkinen E, 2008, IEEE T PATTERN ANAL, V30, P541, DOI 10.1109/TPAMI.2007.70800
   Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P707, DOI 10.1109/34.1000244
   Murphy K.P., 1998, INFERENCE LEARNING H
   Ng C., 2012, PRICAI 2012: Trends in Arti cial Intelligence, V7458, P335
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Raghavendra R, 2011, PATTERN RECOGN, V44, P401, DOI 10.1016/j.patcog.2010.08.006
   Rojas-Bello RN, 2011, IEEE IMAGE PROC, P561, DOI 10.1109/ICIP.2011.6116610
   Saatci Y, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P393
   Scalzo F, 2008, 19 INT C PATT REC IC, P1
   Selinger A., 2001, TECHNICAL REPORT
   Shih HC, 2013, PATTERN RECOGN, V46, P519, DOI 10.1016/j.patcog.2012.08.003
   Singh R, 2008, PATTERN RECOGN, V41, P880, DOI 10.1016/j.patcog.2007.06.022
   Sun ZH, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P165, DOI 10.1109/ACV.2002.1182176
   Vapnik V, 2009, NEURAL NETWORKS, V22, P544, DOI 10.1016/j.neunet.2009.06.042
   Vezzetti E, 2012, IMAGE VISION COMPUT, V30, P698, DOI 10.1016/j.imavis.2012.02.007
   Wang C, 2012, INT C PATT RECOG, P2432
   Wang J, 2010, APPL MECH MATER, V36, P96, DOI [10.4028/www.scientific.net/AMM.36.96, 10.1109/ICICTA.2010.35]
   Wang SF, 2013, IEEE T AFFECT COMPUT, V4, P34, DOI 10.1109/T-AFFC.2012.32
   Wang SF, 2010, IEEE T MULTIMEDIA, V12, P682, DOI 10.1109/TMM.2010.2060716
   Wang SB, 2013, IEEE T NANOTECHNOL, V12, P263, DOI 10.1109/TNANO.2013.2243916
   Wang Y, 2011, INT CONF ACOUST SPEE, P1, DOI 10.1109/PLASMA.2011.5993071
   Xiaofeng Fu, 2010, Proceedings 2010 Sixth International Conference on Natural Computation (ICNC 2010), P2070, DOI 10.1109/ICNC.2010.5584287
   YAMAGUCHI MK, 1995, PERCEPTION, V24, P563, DOI 10.1068/p240563
   Yang ZG, 2007, LECT NOTES COMPUT SC, V4642, P464
NR 48
TC 9
Z9 10
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 14
BP 8419
EP 8442
DI 10.1007/s11042-015-2756-5
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LW
UT WOS:000382113300013
DA 2024-07-18
ER

PT J
AU Shrivastava, N
   Tyagi, V
AF Shrivastava, Nishant
   Tyagi, Vipin
TI An integrated approach for image retrieval using local binary pattern
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Region codes; Local binary pattern; Quantization; Relative location;
   Region of interest
ID LOCATION
AB In this paper an integrated approach for image retrieval has been proposed that uses the concept of local binary pattern. The image is divided into a fixed number of blocks and from each block, LBP based color, texture and shape features are computed. LBP histogram is used for the extraction of color and texture features. Region code based scheme is used to support region based retrieval. Center pixel and its neighbors are used to improve the discrimination power of Local Binary Patterns. Shape feature computed using the binary edge map obtained using Sobel edge detector is combined with color and texture features to make a single completed binary region descriptor. To support region based retrieval, a more effective region code based scheme is employed. The approach is tested on different benchmark databases like COREL, CIFAR-10 andMPEG-7 CCD database. The experimental results have verified that the proposed scheme has impressive retrieval performance in comparison to state-of-the-art techniques.
C1 [Shrivastava, Nishant; Tyagi, Vipin] Jaypee Univ Engn & Technol, Dept Comp Sci & Engn, Guna 473226, MP, India.
RP Tyagi, V (corresponding author), Jaypee Univ Engn & Technol, Dept Comp Sci & Engn, Guna 473226, MP, India.
EM dr.vipin.tyagi@gmail.com
RI Shrivastava, Nishant/A-2784-2019; Tyagi, Vipin/I-2451-2013
OI Shrivastava, Nishant/0000-0001-9626-2301; Tyagi,
   Vipin/0000-0003-4994-3686
CR Abdelali A., 2006, PORTABLE EMERGENCY E, P1
   [Anonymous], 2010, Computer Graphics with Open GL
   Chan YK, 2008, IMAGE VISION COMPUT, V26, P1540, DOI 10.1016/j.imavis.2008.04.019
   Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, P231, DOI 10.1007/BF00962238
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Gupta A, 1997, COMMUN ACM, V40, P70, DOI 10.1145/253769.253798
   Huang CB, 2011, J SUPERCOMPUT, V58, P20, DOI 10.1007/s11227-010-0532-x
   Lee J, 2011, ADV ELECTR COMPUT EN, V11, P85, DOI 10.4316/AECE.2011.03014
   Liu GH, 2008, PATTERN RECOGN, V41, P3521, DOI 10.1016/j.patcog.2008.06.010
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Ma WY, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P568, DOI 10.1109/ICIP.1997.647976
   Martínez JM, 2002, IEEE MULTIMEDIA, V9, P78, DOI 10.1109/93.998074
   Moghaddam B, 2001, MULTIMED TOOLS APPL, V14, P201, DOI 10.1023/A:1011355417880
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143
   Prasad BG, 2004, COMPUT VIS IMAGE UND, V94, P193, DOI 10.1016/j.cviu.2003.10.016
   Shrivastava N, 2015, ADV INTELL SYST COMP, V328, P509, DOI 10.1007/978-3-319-12012-6_56
   Shrivastava N, 2014, VISUAL COMPUT, V30, P1223, DOI 10.1007/s00371-013-0887-0
   Shrivastava N, 2014, INFORM SCIENCES, V259, P212, DOI 10.1016/j.ins.2013.08.043
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Tian Q, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P746, DOI 10.1109/ICIP.2000.899562
   van den Broek EL, 2004, PROC SPIE, V5292, P351, DOI 10.1117/12.526927
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Wong KM, 2005, IEEE INT SYMP CIRC S, P1541
   Zhang J, 2007, ROI BASED NATURAL IM
   Zhao Y, 2013, NEUROCOMPUTING, V106, P68, DOI 10.1016/j.neucom.2012.10.017
NR 26
TC 8
Z9 8
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 11
BP 6569
EP 6583
DI 10.1007/s11042-015-2589-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP5QZ
UT WOS:000378553700025
DA 2024-07-18
ER

PT J
AU Yang, MH
   Jiang, JL
   Tao, JH
   Mu, KH
   Li, H
AF Yang, Minghao
   Jiang, Jinlin
   Tao, Jianhua
   Mu, Kaihui
   Li, Hao
TI Emotional head motion predicting from prosodic and linguistic features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual prosody; Head gesture; Prosody clustering
ID RECOGNITION; ANIMATION; DRIVEN; FACE
AB Emotional head motion plays an important role in human-computer interaction (HCI), which is one of the important factors to improve users' experience in HCI. However, it is still not clear how head motions are influenced by speech features in different emotion states. In this study, we aim to construct a bimodal mapping model from speech to head motions, and try to discover what kinds of prosodic and linguistic features have the most significant influence on emotional head motions. A two-layer clustering schema is introduced to obtain reliable clusters from head motion parameters. With these clusters, an emotion related speech to head gesture mapping model is constructed by a Classification and Regression Tree (CART). Based on the statistic results of CART, a systematical statistic map of the relationship between speech features (including prosodic and linguistic features) and head gestures is presented. The map reveals the features which have the most significant influence on head motions in long or short utterances. We also make an analysis on how linguistic features contribute to different emotional expressions. The discussions in this work provide important references for realistic animation of speech driven talking-head or avatar.
C1 [Yang, Minghao; Tao, Jianhua; Mu, Kaihui; Li, Hao] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China.
   [Jiang, Jinlin] Univ Int Business & Econ, Sch Int Studies, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; University of
   International Business & Economics
RP Yang, MH (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China.
EM mhyang@nlpr.ia.ac.cn; jiangjinlin2014@163.com; jhtao@nlpr.ia.ac.cn;
   khmu@nlpr.ia.ac.cn; hli@nlpr.ia.ac.cn
FU National High-Tech Research and Development Program of China (863
   Program) [2015AA016305]; National Natural Science Foundation of China
   (NSFC) [61332017, 61375027, 61203258, 61273288, 61233009, 61425017]
FX This work is supported by the National High-Tech Research and
   Development Program of China (863 Program) (No. 2015AA016305), the
   National Natural Science Foundation of China (NSFC) (No.61332017,
   No.61375027, No.61203258, No.61273288,No.61233009, No.61425017).
CR Alberto B, 2014, 15 ANN C INT SPEECH
   Aleksandra C, 2009, REALACTOR CHARACTER, VIVA, P486
   Ananthakrishnan S, 2008, IEEE T AUDIO SPEECH, V16, P216, DOI 10.1109/TASL.2007.907570
   [Anonymous], 2011, International Journal of Wavelets Multiresolution and Information Processing, DOI DOI 10.1142/S021969130400041X
   [Anonymous], P 23 INT C COMP AN S
   Badler N, 1994, P SIGGRAPH, P73
   Ben-Youssef A, 2014, INT CONF ACOUST SPEE
   Bo X, 2014, 2014 IE INT C AC SPE
   Bodenheimer B., 1997, COMPUTER ANIMATION S
   Boulic R., 1997, VRST'97. ACM Symposium on Virtual Reality Software and Technology 1997, P111, DOI 10.1145/261135.261156
   Busso C, 2005, COMPUT ANIMAT VIRT W, V16, P283, DOI 10.1002/cav.80
   Cassell J, 2001, COMP GRAPH, P477, DOI 10.1145/383259.383315
   Chuang D, 2014, 15 ANN C INT SPEECH
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   Dang JW, 2004, J ACOUST SOC AM, V115, P853, DOI 10.1121/1.1639325
   de Rosis F, 2003, INT J HUM-COMPUT ST, V59, P81, DOI 10.1016/S1071-5819(03)00020-X
   Ezzat T, 2000, INT J COMPUT VISION, V38, P45, DOI 10.1023/A:1008166717597
   Faloutsos P, 2001, COMP GRAPH, P251, DOI 10.1145/383259.383287
   Fangzhou L, 2008, P 6 INT S CHIN SPOK
   Graf H, 2002, 5 IEEE INT C AUT FAC
   Hong PY, 2002, IEEE T NEURAL NETWOR, V13, P916, DOI 10.1109/TNN.2002.1021892
   Huibin J, 2008, SPEECH PROSODY
   Jia J, 2011, IEEE T AUDIO SPEECH, V19, P570, DOI 10.1109/TASL.2010.2052246
   King SA, 2005, IEEE T VIS COMPUT GR, V11, P341, DOI 10.1109/TVCG.2005.43
   Kipp M., 2010, P 10 INT C INT VIRT
   Kopp S, 2004, COMPUT ANIMAT VIRT W, V15, P39, DOI 10.1002/cav.6
   Kopp S, 2003, KI KUNSTLICHE INTELL, V4/03, P117
   Lijuan W, 2010, INTERSPEECH 2010
   Ling ZH, 2010, SPEECH COMMUN, V52, P834, DOI 10.1016/j.specom.2010.06.006
   Martin JC, 2006, INT J HUM ROBOT, V3, P269, DOI 10.1142/S0219843606000825
   Meng Z, 2008, J SYST SIMUL, V20, P420
   Parke F, 1972, P ACM NAT C
   Pelachaud C, 2009, PHILOS T R SOC B, V364, P3539, DOI 10.1098/rstb.2009.0186
   Shao Y., 2007, CHINESE J ACOUSTIC, V26, P49
   Shiwen Y, 2002, BASIC PROCESSING CON, V16
   Song ML, 2004, PROC CVPR IEEE, P1020
   Stone M, 2004, ACM T GRAPHIC, V23, P506, DOI 10.1145/1015706.1015753
   van Welbergen H, 2010, J MULTIMODAL USER IN, V3, P271, DOI 10.1007/s12193-010-0051-3
   Wachsmuth I, 2008, LECT NOTES ARTIF INT, V4930, P279
   WANG QR, 1984, IEEE T PATTERN ANAL, V6, P406, DOI 10.1109/TPAMI.1984.4767546
   Waters K, 1987, COMPUTER GRAPHICS SI, V22, P7
   Xie L, 2007, PATTERN RECOGN, V40, P2325, DOI 10.1016/j.patcog.2006.12.001
   Xie L, 2007, IEEE T MULTIMEDIA, V9, P500, DOI 10.1109/TMM.2006.888009
   Yamamoto E, 1998, SPEECH COMMUN, V26, P105, DOI 10.1016/S0167-6393(98)00054-5
   Yamamoto SNE, 1997, P AVSP 97 RHOD GREEC
   Young S, 1990, HTK BOOK
   Young S., 2002, HTK BOOK HTK VERSION
   Yu S, 2000, J. Chinese Inf. Proces., V6, P58, DOI [DOI 10.1177/0920203X0001400104, 10.3969/j.issn.1003-0077.2000.06.010, DOI 10.3969/J.ISSN.1003-0077.2000.06.010]
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zeng ZH, 2007, IEEE T MULTIMEDIA, V9, P424, DOI 10.1109/TMM.2006.886310
   Zhang S, 2007, IEEE C INT C AC SPEE
   [周维 ZHOU Wei], 2009, [中国图象图形学报, Journal of Image and Graphics], V14, P1399
NR 52
TC 5
Z9 5
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 9
BP 5125
EP 5146
DI 10.1007/s11042-016-3405-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DM8HE
UT WOS:000376601700018
DA 2024-07-18
ER

PT J
AU Zhou, QJ
   Yan, YC
   Fang, TH
   Luo, X
   Chen, QH
AF Zhou, Qianjin
   Yan, Yuchen
   Fang, Tianhong
   Luo, Xiao
   Chen, Qinghu
TI Text-independent printer identification based on texture synthesis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Document security; Printer identification; Texture features; Text
   independent
AB There are many methods available for printer identification of questioned documents, however most of them need identical contents of the training and testing documents. There is no effective method yet when the contents of the training and testing documents are different. To overcome this obstacle a method based on synthetic texture analysis is proposed in this paper. The inner texture of printed characters is reconstructed in order to generate an artificial textural image similar to the real texture while independent of document content. Fast Fourier Transform (FFT) and Gray Level Co-occurrence Matrix (GLCM) methods are then used for feature extraction. Experimental results demonstrate that the proposed method can achieve a high recognition rate and provide a new platform for printer identification independent on the content of documents.
C1 [Zhou, Qianjin; Yan, Yuchen; Fang, Tianhong; Luo, Xiao; Chen, Qinghu] Wuhan Univ, Sch Elect Informat, Wuhan 430072, Hubei Province, Peoples R China.
C3 Wuhan University
RP Yan, YC (corresponding author), Wuhan Univ, Sch Elect Informat, Wuhan 430072, Hubei Province, Peoples R China.
EM zhouqj@whu.edu.cn; yyc@whu.edu.cn; qhchen@whu.edu.cn
CR Bo Hua, 2006, Acta Electronica Sinica, V34, P155
   Chambers J, 2014, MULTIMEDIA TOOLS APP
   Chen Q, 2010, patent number, Patent No. [ZL 200920084691.2, 2009200846912]
   Chiang PJ, 2010, STUD COMPUT INTELL, V282, P145
   Deng W., 2014, ELECTR MEASUR TECHNO, V37, P70
   Forum of PC Home, 2012, DO YOU KNOW LAS PRIN
   Gebhardt J., 2012, DOCUMENT AUTHENTICAT
   Hae-Yeoun L, 2010, P 5 INT C UB INF TEC
   Jiang W, 2010, ADV MULTIMEDIA INFOR
   Khanna N, 2009, IEEE T INF FOREN SEC, V4, P123, DOI 10.1109/TIFS.2008.2009604
   Losavio M, 2013, INT WORK SYS APPR D
   Mikkilineni A. K., 2010, P SPIE INT C MED FOR
   Mikkilineni AK, 2012, INFORM HIDING PRINTE, P183
   Mikkilineni AK, 2011, P SPIE INT C MED WAT
   Mikkilineni AK, 2005, P SOC PHOT INSTR ENG
   Picard RW, 1993, P CVPR 93 1993 IE CO
   Roy A, 2010, P 7 IND C COMP VIS G
   Sombattheera C, 2011, PRINTED TEXT CHARACT, P201
   [涂岩恺 Tu Yankai], 2011, [电子与信息学报, Journal of Electronics & Information Technology], V33, P499, DOI 10.3724/SP.J.1146.2010.00230
   van Beusekom J, 2013, INT J DOC ANAL RECOG, V16, P189, DOI 10.1007/s10032-011-0181-5
   Wei Li yi, 2000, P 27 ANN C COMP GRAP
   Yubao W, 2009, IM PROC ICIP 16 IEEE
NR 22
TC 11
Z9 12
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 5557
EP 5580
DI 10.1007/s11042-015-2525-5
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600010
DA 2024-07-18
ER

PT J
AU Elhoseiny, M
   Elgammal, A
AF Elhoseiny, Mohamed
   Elgammal, Ahmed
TI Text to multi-level MindMaps A novel method for hierarchical visual
   abstraction of natural language text
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text visualization; Multi-level MindMap Automation; Text summarization;
   Text Abstraction; MindMapping
AB MindMapping (Tony Buzan and Harrison, 2010) is a well-known technique for note-taking, which encourages learning and studying. MindMapping has been manually adopted to help present knowledge and concepts in a visual form. Unfortunately, there is no reliable automated approach to generate MindMaps from Natural Language text. This work firstly introduces the MindMap Multi-level Visualization concept that jointly visualize and summarize textual information. The visualization is achieved pictorially across multiple levels using semantic information (i.e. ontology), while the summarization is achieved by the information in the highest levels as they represent abstract information in the text. This work also presents the first automated approach that takes a text input and generates a MindMap visualization out of it. The approach could visualize text documents in multi-level MindMaps, in which a high-level MindMap node could be expanded into child MindMaps. The proposed method involves understanding of the input text and converting it into intermediate Detailed Meaning Representation (DMR). The DMR is then visualized with two modes; Single level or Multiple levels, which is convenient for larger text. The generated MindMaps from both approaches were evaluated based on human subject experiments performed on Amazon Mechanical Turk with various parameter settings.
C1 [Elhoseiny, Mohamed; Elgammal, Ahmed] Rutgers State Univ, Dept Comp Sci, 110 Frelinghuysen Rd, Piscataway, NJ 08854 USA.
C3 Rutgers University System; Rutgers University New Brunswick
RP Elhoseiny, M (corresponding author), Rutgers State Univ, Dept Comp Sci, 110 Frelinghuysen Rd, Piscataway, NJ 08854 USA.
EM m.elhoseiny@cs.rutgers.edu; elgammal@cs.rutgers.edu
RI Elhoseiny, Mohamed/X-6406-2019
OI Elgammal, Ahmed/0000-0003-2761-4822
CR Afzal S, 2012, TVCG, V18
   Altintas E, 2005, EFFECT WINDOWING WOR, DOI [10.1007/11569596_65, DOI 10.1007/11569596_65]
   [Anonymous], P ACM SIAM S DISCR A
   [Anonymous], 2006, LREC
   [Anonymous], 2006, THEORY UNDERLYING CO
   [Anonymous], ACL
   [Anonymous], 2007, LIT SURVEY LANGUAGE
   [Anonymous], CHARTING TOPIC MAPS
   [Anonymous], 2002, CICLING
   [Anonymous], 2006, THESIS U ULSTER
   Bataineh BM, 2009, WORLD C ENG WCE
   BBC, 2012, BBC HIST FIG
   Berinsky AJ, 2012, POLIT ANAL, V20, P351, DOI 10.1093/pan/mpr057
   Berinsky AJ, 2013, PLOS ONE, V8
   Buhrmester M, 2011, PERSPECT PSYCHOL SCI, V6, P3, DOI 10.1177/1745691610393980
   Collins M, 2003, PLOUGHSHARES, V29, P29
   Conroy JM, 2001, ACM SIGIR
   Coyne B, 2010, KES
   Dhindsa HS, 2011, J SCI ED TECHNOL, V20
   Dou W, 2013, TVCG, V19
   Elhoseiny M, 2012, IEEE INT S MULT ISM
   Farrand P, 2002, J MED ED, V36
   Floyd R. W., 1962, COMMUN ACM
   Hamdy A, 2009, INT C SEM WEB WEB SE
   Kaikhah K, 2004, INT IEEE C INT SYST
   Kamps T, 1996, P S GRAPH DRAW
   Kudelic R, 2011, INT C INF TECHN INT
   Lappin S, 1990, ACL
   Leass HJ, 1994, COMPUT LINGUIST, V20
   Lenat D, 1995, COMMUN ACM, V38
   Litkowski KC, 2001, SYNTACTIC CLUES LEXI
   Marcu D., 1998, THESIS
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Miller GA, 1995, COMMUNICATION, V38
   Navigli R, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1459352.1459355
   Niles I., 2001, FOIS
   Osborne M., 2002, ACL WORKSH AUT SUMM
   Park J., 2003, XML Topic Maps: Creating and Using Topic Maps for the Web
   Qiu L, 2004, LREC
   Ray S., 1999, ICAPRDT
   Tony Buzan BB, 2010, MIND MAP BOOK UNLOCK
   van Ham F, 2009, TVCG, V15
   Viegas F, 2009, TVCG, P15
   Vigas F, 2014, PHRASENET EXAMPLE
   Youzhi Z, 2009, AS PAC C COMP INT IN
NR 45
TC 8
Z9 8
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4217
EP 4244
DI 10.1007/s11042-015-2467-y
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700003
DA 2024-07-18
ER

PT J
AU Jin, C
   Wang, RD
   Yan, DQ
   Ma, PF
   Zhou, JL
AF Jin, Chao
   Wang, Rangding
   Yan, Diqun
   Ma, Pengfei
   Zhou, Jinglei
TI An efficient algorithm for double compressed AAC audio detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AAC; Huffman codebook index; Double compression detection; Probability
   values; Markov model
AB As a new generation of compression encoding standard, MPEG-2/4 Advanced Audio Coding (AAC) would be a widely-used audio format in the near future. However, these AAC audios often be forged by audio forgers for their own benefits in some significant events, which will cause double AAC compression. In this paper, the probability values and Markov features based on the Huffman codebook indexes of AAC audio were constructed and an efficient algorithm is proposed to detect double compression. Experimental results demonstrate that our method has high detection accuracy and low computational complexity. To the best of our knowledge, it is the first time to apply double compression detection to AAC audio forensics.
C1 [Jin, Chao; Wang, Rangding; Yan, Diqun; Ma, Pengfei; Zhou, Jinglei] Ningbo Univ, Coll Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
C3 Ningbo University
RP Wang, RD (corresponding author), Ningbo Univ, Coll Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
EM auking@126.com; wangrangding@nbu.edu.cn; yandiqun@nbu.edu.cn;
   mpfabc@126.com; zhoujinglei1209@qq.com
RI Yan, Diqun/AAY-6775-2021
OI Yan, Diqun/0000-0002-5241-7276
FU National Natural Science Foundation of China [61170137, 61300055,
   61301247]; Zhejiang Natural Science Foundation [LY13F020013]; Ningbo
   Natural Science Foundation [2013A610057, 2013A610059]; Ningbo University
   Fund [XKXL1313, XKXL1310]; K.C. Wong Magna Fund in Ningbo University
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 61170137, 61300055, 61301247), Zhejiang Natural Science
   Foundation (Grant No. LY13F020013), Ningbo Natural Science Foundation
   (Grant No. 2013A610057, 2013A610059), Ningbo University Fund (Grant No.
   XKXL1313, XKXL1310) and K.C. Wong Magna Fund in Ningbo University.
CR [Anonymous], INFORM TECHNOLOGY J
   [Anonymous], 6 INT C WIR COMM NET
   [Anonymous], SIGNAL PROC MAGAZINE
   [Anonymous], INFORM HIDING
   [Anonymous], INT JOINT C NEUR NET
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], MEDIA FORENSICS SECU
   [Anonymous], 1997, 138187 ISOIEC
   [Anonymous], IEEE MULTIMED
   [Anonymous], INT C AUD LANG IM PR
   Chen C., 2008, 19 INT C PATTERN REC, P1
   Chen CH, 2008, IEEE INT SYMP CIRC S, P3029, DOI 10.1109/ISCAS.2008.4542096
   D'Alessandro B, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P57
   Liu QZ, 2010, COGN COMPUT, V2, P291, DOI 10.1007/s12559-010-9045-4
   Tan JQ, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P136, DOI 10.1109/CW.2008.26
   Yang R, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P117
   Zhu J, 2011, 2011 INTERNATIONAL CONFERENCE ON ELECTRONICS, COMMUNICATIONS AND CONTROL (ICECC), P1110, DOI 10.1109/ICECC.2011.6066707
NR 17
TC 10
Z9 10
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4815
EP 4832
DI 10.1007/s11042-015-2552-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700031
DA 2024-07-18
ER

PT J
AU Limna, T
   Tandayya, P
AF Limna, Thanathip
   Tandayya, Pichaya
TI A flexible and scalable component-based system architecture for video
   surveillance as a service, running on infrastructure as a service
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video surveillance as a service; Infrastructure as a service; Cloud
   computing; System design architecture; Flexibility; Scalability; Fault
   toleration
AB There are many proposals for moving traditional video surveillance systems into the cloud, commonly known as Video Surveillance as a Service (VSaaS). Most systems use Hadoop technology for storing video records and distributing video analysis tasks. However, Hadoop is more appropriate for video retrieval services than real time video analysis. Also, existing systems offer neither flexible deployment plans, nor are they capable of automatically minimizing the number of required servers (whether they are physical or virtual machines). Our proposal involves the design and implementation of a component-based VSaaS running on Infrastructure as a Service (IaaS). This paper focuses on the design concepts and component functions that provide solutions for the availability and scalability of VSaaS. Our system can easily scale from one server up to a more complex cluster to support the varying requirements of users. It accesses cloud services via Amazon EC2 for computing services and Amazon S3 API for object storage services, since they are supported by many cloud computing IaaS providers. We also present a components deployment that is suitable for any size and type of system, which combines both physical and virtual machines. Experiments show that the system performs well, and can tolerate difficult scenarios.
C1 Prince Songkla Univ, Dept Comp Engn, Fac Engn, Hat Yai, Hat Yai, Thailand.
   [Limna, Thanathip; Tandayya, Pichaya] Prince Songkla Univ, Fac Engn, Dept Comp Engn, Hat Yai, Songkhla, Thailand.
C3 Prince of Songkla University; Prince of Songkla University
RP Tandayya, P (corresponding author), Prince Songkla Univ, Fac Engn, Dept Comp Engn, Hat Yai, Songkhla, Thailand.
EM thanathip.limna@gmail.com; pichaya@coe.psu.ac.th
RI Tandayya, Pichaya/AAH-6051-2021
FU Thailand Research Fund; Prince of Songkla University through the Royal
   Golden Jubilee Ph.D. Program [PHD/0047/2552]
FX The authors are grateful for financial supports from the Thailand
   Research Fund and Prince of Songkla University through the Royal Golden
   Jubilee Ph.D. Program (Grant No. PHD/0047/2552).
CR [Anonymous], 2012, OpenStack cloud computing cookbook
   [Anonymous], 2009, Hadoop: The definitive guide
   [Anonymous], 2012, Mastering OpenCV With Practical Computer VisionProjects
   Chodorow Kristina., 2010, MONGODB DEFINITIVE G, V1st
   Crockford D., 2006, P XML, V2006
   Fielding R. T, 2002, ACM Transactions on Internet Technology (TOIT), V2, P115, DOI [DOI 10.1145/514183.514185, 10.1145/514183.514185]
   Georis B, 2003, P IEE S INT DISTR SU, p18/1
   Gualdi G, 2008, IEEE T MULTIMEDIA, V10, P1142, DOI 10.1109/TMM.2008.2001378
   Han J, 2014, MULTIMED TOOLS APPL, V73, P241, DOI 10.1007/s11042-012-1285-8
   Hossain MS, 2012, IEEE INT CONF MULTI, P408, DOI 10.1109/ICMEW.2012.77
   Huang Y., 2010, 2010 3 INT C IEEE AD, V2, pV2
   Jaynes C., 2002, PROC IEEE WORKSHOP P, P32
   JongHyuk Lee, 2012, 2012 IEEE 5th International Conference on Cloud Computing (CLOUD), P147, DOI 10.1109/CLOUD.2012.141
   Karimaa A, 2011, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON DEPENDABILITY (DEPEND 2011), P92
   Kivity A., 2007, P LIN S DTTAW DNTOR, V1, P225
   Limna T, 2012, 2012 5TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P197
   Lin CF, 2012, 2012 9TH INTERNATIONAL CONFERENCE ON UBIQUITOUS INTELLIGENCE & COMPUTING AND 9TH INTERNATIONAL CONFERENCE ON AUTONOMIC & TRUSTED COMPUTING (UIC/ATC), P655, DOI 10.1109/UIC-ATC.2012.72
   Mahmoud Q., 2005, MIDDLEWARE COMMUNICA
   Masinter L, 2013, UNIFORM RESOURCE IDE
   McDonough C, 2011, PYRAMID WEB APPL DEV
   Milojicic D, 2011, IEEE INTERNET COMPUT, V15, P11, DOI 10.1109/MIC.2011.44
   Neo IT Solutions Inc, 2013, OVS ONL VID SURV SER
   Nurmi D, 2009, CCGRID: 2009 9TH IEEE INTERNATIONAL SYMPOSIUM ON CLUSTER COMPUTING AND THE GRID, P124, DOI 10.1109/CCGRID.2009.93
   NW Systems Group Limited, 2013, SECURITYSTATION VSAA
   Pivotal Software Inc, 2014, RABBITMQ MESS JUST W
   Python Software Foundation, 2014, SUBPR MAN PYTH DOC
   Rescorla E, 2013, HTTP OVER TLS
   Rodriguez-Silva D. A., 2012, 2012 IEEE 5th International Conference on Cloud Computing (CLOUD), P991, DOI 10.1109/CLOUD.2012.44
   San Miguel Juan Carlos, 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P207, DOI 10.1109/WIAMIS.2008.29
   Secure- i, 2013, VCR DVR NVR NOW HVR
   Suvonvorn Nikom, 2008, 2008 IEEE 10th Workshop on Multimedia Signal Processing (MMSP), P867, DOI 10.1109/MMSP.2008.4665195
   Triornis Ltd, 2013, ZONEMINDER MAIN DOC
   Valera M, 2005, IEE P-VIS IMAGE SIGN, V152, P192, DOI 10.1049/ip-vis:20041147
   Vezzani R, 2010, MULTIMED TOOLS APPL, V50, P359, DOI 10.1007/s11042-009-0402-9
   Videla A., 2012, RABBITMQ ACTION DIST
   Vinoski S, 2006, IEEE INTERNET COMPUT, V10, P87, DOI 10.1109/MIC.2006.116
   Wan EA, 2000, IEEE 2000 ADAPTIVE SYSTEMS FOR SIGNAL PROCESSING, COMMUNICATIONS, AND CONTROL SYMPOSIUM - PROCEEDINGS, P153, DOI 10.1109/ASSPCC.2000.882463
   Wijnhoven R. G. J., 2006, P SOC PHOTO-OPT INS, V6073
   Wu YS, 2012, 2012 9TH INTERNATIONAL CONFERENCE ON UBIQUITOUS INTELLIGENCE & COMPUTING AND 9TH INTERNATIONAL CONFERENCE ON AUTONOMIC & TRUSTED COMPUTING (UIC/ATC), P661, DOI 10.1109/UIC-ATC.2012.43
   Yuan XJ, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P199, DOI 10.1109/AVSS.2003.1217922
NR 40
TC 14
Z9 15
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 4
BP 1765
EP 1791
DI 10.1007/s11042-014-2373-8
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HQ
UT WOS:000371309000002
DA 2024-07-18
ER

PT J
AU Rahman, MA
AF Rahman, Md. Abdur
TI i-Therapy: a non-invasive multimedia authoring framework for
   context-aware therapy design
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User context; Disabled patient's behavior; e-Therapy; Mashup of 3D
   gesture sensing platforms; Multimedia therapy authoring; Therapy
   modeling; Therapeutic context
ID KINECT; REHABILITATION; RESOLUTION; VISION; SENSOR
AB In this paper, we present an e-Therapy framework, named i-Therapy, which collects live therapeutic context by analyzing multi-sensory body joint data in a non-invasive way. Using our proposed framework, a therapist can model complex gestures by mapping them to a set of primitive gesture sequences and generate high-level therapies. As a proof of concept, we have developed scenarios to express a Hemiplegic patient's behavior into a set of track-able primitive gestures. The initial feedback from the therapists who have tested our developed framework is encouraging. Finally, we share the implementation details and analysis of test results.
C1 [Rahman, Md. Abdur] Umm Al Qura Univ, Coll Comp & Informat Syst, Adv Media Lab, Mecca, Saudi Arabia.
C3 Umm Al Qura University
RP Rahman, MA (corresponding author), Umm Al Qura Univ, Coll Comp & Informat Syst, Adv Media Lab, Mecca, Saudi Arabia.
EM marahman@uqu.edu.sa
RI Guizani, Mohsen/AAX-4534-2021; Rahman, Abdur/AAG-9302-2019
OI Guizani, Mohsen/0000-0002-8972-8094; Rahman, Abdur/0000-0002-4105-0368
FU NSTIP strategic technologies program in the Kingdom of Saudi Arabia
   [11-INF1703-10]
FX This project was supported by the NSTIP strategic technologies program
   (11-INF1703-10) in the Kingdom of Saudi Arabia. The authors would like
   to thank the therapists who have given us feedback and domain specific
   knowledge. The authors would also like to thank Dr. Farooque Alwari,
   Ahmad Qamar and Delwar Hossain of Advanced Media Laboratory of Umm
   Al-Qura University for helping in demo and usability testing.
CR Alamri A, 2012, INT J COMP SCI SPORT, V9, P2
   Albrecht I., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P98
   An J, 2009, 11TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS I-III, PROCEEDINGS,, P554
   Anderson S. A., 1993, ANATOMY OF MOVEMENT
   [Anonymous], 2005, ACM SIGGRAPH EUR S C, DOI DOI 10.1145/1073368.1073413
   [Anonymous], THESIS NOTRE DAME
   [Anonymous], 2005, P 2005 ACM SIGGRAPHE, DOI DOI 10.1145/1073368.1073414
   Aziz O, 2007, SURG INNOV, V14, P83, DOI 10.1177/1553350607302326
   Baran M, 2011, IEEE ENG MED BIO, P7602, DOI 10.1109/IEMBS.2011.6091874
   Bardram JE, 2005, PERS UBIQUIT COMPUT, V9, P312, DOI 10.1007/s00779-004-0335-2
   Bhardwaj S., 2008, Sensors Transducers Journal, V90, P87
   Bottazzi D, 2006, IEEE COMMUN MAG, V44, P82, DOI 10.1109/MCOM.2006.1632653
   Chang YJ, 2011, RES DEV DISABIL, V32, P2566, DOI 10.1016/j.ridd.2011.07.002
   Chien-Yen Chang, 2012, 2012 6th International Conference on Pervasive Computing Technologies for Healthcare, P159, DOI 10.4108/icst.pervasivehealth.2012.248714
   Clark RA, 2012, GAIT POSTURE, V36, P372, DOI 10.1016/j.gaitpost.2012.03.033
   Da Gama A., 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P145, DOI 10.1109/3DUI.2012.6184203
   Dey AK, 2001, PERS UBIQUIT COMPUT, V5, P4, DOI 10.1007/s007790170019
   e-Therapy, 2009, CONS PROV E THER
   Erdemir A, 2007, CLIN BIOMECH, V22, P131, DOI 10.1016/j.clinbiomech.2006.09.005
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Gabel Moshe, 2012, Annu Int Conf IEEE Eng Med Biol Soc, V2012, P1964, DOI 10.1109/EMBC.2012.6346340
   Gips J., 2007, DISABILITY REHABILIT, V2, P189
   Gorini A, 2008, J MED INTERNET RES, V10, DOI 10.2196/jmir.1029
   Green CS, 2007, PSYCHOL SCI, V18, P88, DOI 10.1111/j.1467-9280.2007.01853.x
   Harley L, 2011, LECT NOTES COMPUT SC, V6764, P167, DOI 10.1007/978-3-642-21619-0_22
   Holden MK, 2005, CYBERPSYCHOL BEHAV, V8, P187, DOI 10.1089/cpb.2005.8.187
   Hoyet L., 2012, P ACM SIGGRAPH S INT, P79, DOI DOI 10.1145/2159616.2159630.6,17
   Huang JD, 2011, ASSETS 11: PROCEEDINGS OF THE 13TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P319
   Huber Meghan, 2008, 2008 Virtual Rehabilitation, P105, DOI 10.1109/ICVR.2008.4625145
   Hudes Karen, 2011, J Can Chiropr Assoc, V55, P26
   Khoshelham K, 2012, SENSORS-BASEL, V12, P1437, DOI 10.3390/s120201437
   Kim D, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P167
   Koolwaaij J, 2009, PROCEEDINGS OF THE IEEE VIRTUAL WORLDS FOR SERIOUS APPLICATIONS, P61, DOI 10.1109/VS-GAMES.2009.21
   Krco S, 2004, AD HOW SENSOR WIREL, V1, P1
   Lange B, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P170
   Liu CK, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531365
   Livingston MA, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P119, DOI 10.1109/VR.2012.6180911
   Ma M, 2008, MAN CYB IEEE INT C S, P1872
   Ma MH, 2007, LECT NOTES COMPUT SC, V4555, P681
   Memh F., 2011, P 19 ACM INT C MULT, P807, DOI DOI 10.1145/2072298.2072469
   Norris J, 2009, 3D VIRTUAL WORLDS HL, V2, P2
   Phung D., 2009, P IEEE INT C PERV CO, P1
   Rahman M. A., 2010, 2010 IEEE International Instrumentation & Measurement Technology Conference - I2MTC 2010, P1228, DOI 10.1109/IMTC.2010.5488279
   Rahman M.Abdur., 2013, Proceedings of the 3rd ACM conference on International conference on multimedia retrieval, P313, DOI [10.1145/2461466.2461522, DOI 10.1145/2461466.2461522]
   Rahman M. M., 2013, Proceedings of the Second International Symposium on Minor Fruits and Medicinal Plants for Better Lives (2nd ISMF & MP), University of Ruhuna, Sri Lanka, 20 December 2013, P9
   Rahman MA, 2011, IEEE T INSTRUM MEAS, V60, P345, DOI 10.1109/TIM.2010.2084190
   Rahman MdA, 2013, HDB INNOVATIVE MED T
   Roslyn B, 2012, 4 INT IEEE EMBS C NE, P271
   Ryu H, 2007, LECT NOTES COMPUT SC, V4761, P20
   Saini S., 2012, 2012 Proceedings of International Conference on Computer & Information Science (ICCIS 2012), P55, DOI 10.1109/ICCISci.2012.6297212
   Sakzewski L, 2009, PEDIATRICS, V123, pE1111, DOI 10.1542/peds.2008-3335
   Sarikaya S., 2006, ACM IWCMC, Vancouver, British Columbia, Canada, P1369
   Schonauer C, 2011, P INT C VIRT REH ZUR
   Stone EE, 2011, IEEE ENG MED BIO, P6491, DOI 10.1109/IEMBS.2011.6091602
   Sueda S, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360682
   Suma EA, 2011, P IEEE VIRT REAL ANN, P247, DOI 10.1109/VR.2011.5759491
   Taylor R.M., 2001, Proceedings of the ACM Symposium on Virtual Reality Software and Technology - VRST '01, P55, DOI [10.1145/505008.505019, DOI 10.1145/505008.505019, 10.1145/505008.505019., DOI 10.1145/505008.5050192]
   Tong XL, 2012, INT SYM COMPUT INTEL, P347, DOI 10.1109/ISCID.2012.238
   Wu WH, 2008, ARTIF INTELL MED, V42, P137, DOI 10.1016/j.artmed.2007.11.006
   Yang BH, 2000, ROBOT AUTON SYST, V30, P273, DOI 10.1016/S0921-8890(99)00092-5
   Zhao Wenping, 2012, Proceedings of the ACM SIGGRAPH/eurographics symposium on computer animation. Eurographics Association, P33, DOI [10.2312/SCA/SCA12/033-042, DOI 10.2312/SCA/SCA12/033-042]
   Zhou HY, 2008, BIOMED SIGNAL PROCES, V3, P1, DOI 10.1016/j.bspc.2007.09.001
NR 62
TC 5
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 4
BP 1843
EP 1867
DI 10.1007/s11042-014-2376-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HQ
UT WOS:000371309000005
DA 2024-07-18
ER

PT J
AU Huang, F
   Kim, HJ
AF Huang, Fangjun
   Kim, Hyoung Joong
TI Framework for improving the security performance of ordinary distortion
   functions of JPEG steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Security; Steganography; Distortion function; JPEG
ID STEGANALYSIS; FEATURES; SCHEME
AB Digital steganography is a new approach for secure communication. Via using it, the sender and the receiver can easily exchange secret message on the Internet without arousing any suspicion. Previously, a lot of ordinary distortion functions for joint photographic experts group (JPEG) steganography have been presented, which can guide the message embedding in the non-zero alternating current (AC) discrete cosine transform (DCT) coefficients of JPEG image. In this paper, we present a framework for improving the security performance of these distortion functions. In our new framework, these ordinary distortion functions are not restricted to evaluating the distortion values of non-zero AC DCT coefficients any more, and their coverage areas will be extended to all DCT coefficients, including the direct current (DC) coefficients and all the zero and non-zero AC coefficients. All the coefficients in JPEG image are divided into two groups: changeable group (CG) and reserve group (RG), respectively. The coefficients that may result in less detectable distortion are grouped into CG and the rest into RG. Via associating the distortion values to coefficients in CG and RG with different strategies, a series of new advanced distortion functions can be generated. The experimental results demonstrate that while applying these advanced distortion functions to JPEG steganography, the statistical characteristics of the carrier image will be preserved better than the prior art, and consequently secure JPEG steganographic schemes can easily be obtained.
C1 [Huang, Fangjun] Sun Yat Sen Univ, Guangzhou Higher Educ Mega Ctr, Sch Informat Sci & Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Kim, Hyoung Joong] Korea Univ, Grad Sch Informat Secur, Seoul 136701, South Korea.
C3 Sun Yat Sen University; Korea University
RP Kim, HJ (corresponding author), Korea Univ, Grad Sch Informat Secur, Seoul 136701, South Korea.
EM huangfj@mail.sysu.edu.cn; khj-@korea.ac.kr
FU National Natural Science Foundation of China [61173147]; Korea
   Foundation for Advanced Studies' International Scholar Exchange
   Fellowship; Fundamental Research Funds for Central Universities
   [12lgpy31]; Scientific Research Foundation for the Returned Overseas
   Chinese Scholars, State Education Ministry [[2012]1707]
FX This work was partially supported by the National Natural Science
   Foundation of China (61173147), the Korea Foundation for Advanced
   Studies' International Scholar Exchange Fellowship for the academic year
   of 2013-2014, the Fundamental Research Funds for Central Universities
   (12lgpy31), and the Project Sponsored by the Scientific Research
   Foundation for the Returned Overseas Chinese Scholars, State Education
   Ministry ([2012]1707).
CR [Anonymous], 2012, IEEE T INF FORENSICS, DOI DOI 10.1109/TIFS.2011.2175919
   [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   [Anonymous], P 1 ACM WORKSH INF H
   Dumitrescu S, 2003, IEEE T SIGNAL PROCES, V51, P1995, DOI 10.1109/TSP.2003.812753
   Filler T., 2010, BOSS BREAK OUR STEGA
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Fridrich J., 2004, MMSEC 04, P4
   Fridrich J, 2007, LECT NOTES COMPUT SC, V4437, P282
   Fridrich J, 2006, IEEE T INF FOREN SEC, V1, P390, DOI 10.1109/TIFS.2006.879281
   Fridrich J, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P3
   Fridrich Jessica., 2007, STATISTICALLY UNDETE, P3
   Holub V., 2013, P 1 ACM WORKSH INF H
   Holub V, 2012, P 4 IEEE INT WORKSH
   Horng S., 2013, MULTIMED TOOLS APPL, P1
   Huang F, 2013, P 3 INT C MULT TECHN
   Huang F, 2013, P 1 ACM WORKSH INF H
   Huang FJ, 2012, IEEE T INF FOREN SEC, V7, P1181, DOI 10.1109/TIFS.2012.2198213
   Huang FJ, 2011, LECT NOTES COMPUT SC, V6526, P189, DOI 10.1007/978-3-642-18405-5_16
   Huang HC, 2007, CIRC SYST SIGNAL PR, V26, P671, DOI 10.1007/s00034-006-0104-z
   Ker AD, 2007, LECT NOTES COMPUT SC, V4567, P204
   Ker AD, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P27, DOI 10.1145/1411328.1411335
   Kim Y, 2007, LECT NOTES COMPUT SC, V4437, P314
   Kodovsky J, 2010, PROC SPIE, V7541, DOI 10.1117/12.838768
   Kodovsky J, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P63
   Kodovsky Jan, 2012, P SPIE MEDIA WATERMA, V8303, P1
   Li FY, 2013, IEEE SIGNAL PROC LET, V20, P233, DOI 10.1109/LSP.2013.2240385
   Liu QZ, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1899412.1899420
   Moon TK, 2005, ERROR CORRECTION CODING: MATHEMATICAL METHODS AND ALGORITHMS
   Patsakis Constantinos., 2014, Journal of Information Hiding and Multimedia Signal Processing, V5, P20
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Sachnev V, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P131
   Sachnev V, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-89
   Sallee P, 2005, INT J IMAGE GRAPH, V5, P167, DOI 10.1142/S0219467805001719
   Shi YQ, 2007, LECT NOTES COMPUT SC, V4437, P249
   Solanki K, 2007, LECT NOTES COMPUT SC, V4567, P16
   Wang C., 1785, ACOUSTICS SPEECH SIG
   Xuan GR, 2005, LECT NOTES COMPUT SC, V3727, P262
   Zhang RY, 2009, LECT NOTES COMPUT SC, V5806, P48, DOI 10.1007/978-3-642-04431-1_4
NR 39
TC 2
Z9 2
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 1
BP 281
EP 296
DI 10.1007/s11042-014-2291-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5QB
UT WOS:000367856500015
DA 2024-07-18
ER

PT J
AU Iranpour, M
   Rahmati, M
AF Iranpour, Mehran
   Rahmati, Mohammad
TI An efficient steganographic framework based on dynamic blocking and
   genetic algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Image distortion; Dynamic blocking; Genetic algorithm;
   Steganalysis
ID IMAGE; OPTIMIZATION; QUALITY
AB An important property of any robust steganographic method is that it must introduce minimal distortion in the created stego-images. This objective is achieved if one can maximize the similarity between the pixels value of the cover image and the secret data. In the proposed framework, the maximal similarity is obtained by arranging some routes along the pixel positions. Our novel method is based on dynamic blocking and the genetic algorithm which decreases the distortion produced by a base data embedding method. In the proposed parametric framework, the cover image is first divided into several horizontal static-size strips. Then each strip is partitioned into some dynamic-size blocks. The size of each block is determined using the genetic algorithm such that minimal distortion is produced. Traversing the blocks of a strip in a raster scan manner, the route for embedding the data into the strip is obtained. The best route is considered to be the one which partition a strip into different blocks with different sizes. The embedding route is raster scan of the partitioned blocks. In our framework, only the sizes of the blocks need to be recorded as the overhead instead of the routes. The experimental results evaluated on 2000 natural images using several steganalytic algorithms demonstrate that our proposed method decreases the image distortion and thus enhances the security.
C1 [Iranpour, Mehran] Islamic Azad Univ, Garmsar Branch, Dept Comp Engn, Garmsar, Iran.
   [Rahmati, Mohammad] Amirkabir Univ Technol, Dept Comp Engn & Informat Technol, Tehran Polytech, Tehran, Iran.
C3 Islamic Azad University; Amirkabir University of Technology
RP Iranpour, M (corresponding author), Islamic Azad Univ, Garmsar Branch, Dept Comp Engn, Garmsar, Iran.
EM miranpoor@yahoo.com; rahmati@aut.ac.ir
OI Rahmati, Mohammad/0000-0002-0591-6910
CR Abolghasemi M, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3295709
   Amirkhani H, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3554413
   Amirtharajan R, 2012, INFORM SCIENCES, V193, P115, DOI 10.1016/j.ins.2012.01.010
   [Anonymous], 2008, P SPIE ELECT IMAGING
   Back Thomas., 2000, Evolutionary computation 2: advanced algorithms and operators, V2
   Chan CS, 2009, FUND INFORM, V96, P49, DOI 10.3233/FI-2009-166
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chao RM, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/658047
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Fakhredanesh M, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.043007
   Filler T, 2009, LECT NOTES COMPUT SC, V5806, P31, DOI 10.1007/978-3-642-04431-1_3
   Fridrich J., 2001, P ACM WORKSH MULT SE, P27
   Fridrich Jessica, 2010, Steganography in digital media: Principles, algorithms and applications
   Hong W, 2012, IEEE T INF FOREN SEC, V7, P176, DOI 10.1109/TIFS.2011.2155062
   Hsu Chin-Wei, 2010, Technical Report
   Iranpour Mehran, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P27
   Iranpour M, 2013, P 9 IEEE INT C INT I
   Iranpour M, 2013, 18 INT C DIG SIGN PR, P1
   Iranpour M, 2015, MULTIMED TOOLS APPL, V74, P6657, DOI 10.1007/s11042-014-1921-6
   Iranpour M, 2013, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE 2013), P167, DOI 10.1109/ICCKE.2013.6682811
   Joseph L, 2013, J APPL SEC RES, V8, P467, DOI 10.1080/19361610.2013.825753
   Jung KH, 2012, MULTIMED TOOLS APPL, P1
   Kharrazi M, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2400672
   Kim CT, 2012, ENVIRON POL SER, V8, P1, DOI 10.3920/978-90-8686-773-8
   Lin GS, 2010, IEEE T MULTIMEDIA, V12, P345, DOI 10.1109/TMM.2010.2051243
   Luo WQ, 2011, MULTIMED TOOLS APPL, V52, P407, DOI 10.1007/s11042-009-0440-3
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Omoomi M, 2011, MULTIMED TOOLS APPL, V54, P201, DOI 10.1007/s11042-010-0517-z
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Sabeti V, 2013, MULTIMED TOOLS APPL, V64, P777, DOI 10.1007/s11042-011-0975-y
   Sagan H., 1994, SPACE FILLING CURVES
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Sharp Toby, 2001, Information Hiding, V2137, P13, DOI 10.1007/3-540-45496-9_2
   Wang ZH, 2012, INFORM SCIENCES, V192, P98, DOI 10.1016/j.ins.2010.07.011
   Westfeld A, 2013, BOWS2 IMAGE DATABASE
   Wu NI, 2012, APPL SOFT COMPUT, V12, P942, DOI 10.1016/j.asoc.2011.09.002
   Xu H, 2010, INFORM SCIENCES, V180, P1201, DOI 10.1016/j.ins.2009.12.027
   Yang CH, 2008, PATTERN RECOGN, V41, P2674, DOI 10.1016/j.patcog.2008.01.019
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 41
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11429
EP 11450
DI 10.1007/s11042-014-2237-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600020
DA 2024-07-18
ER

PT J
AU Masmoudi, A
   Puech, W
   Masmoudi, A
AF Masmoudi, Atef
   Puech, William
   Masmoudi, Afif
TI An improved lossless image compression based arithmetic coding using
   mixture of non-parametric distributions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Arithmetic coding; Lossless compression; Image compression; Finite
   mixture model; Expectation-maximization algorithm; Kullback-Leibler
   distance
AB In this paper, we propose a new approach for a block-based lossless image compression using finite mixture models and adaptive arithmetic coding. Conventional arithmetic encoders encode and decode images sample-by-sample in raster scan order. In addition, conventional arithmetic coding models provide the probability distribution for whole source symbols to be compressed or transmitted, including static and adaptive models. However, in the proposed scheme, an image is divided into non-overlapping blocks and then each block is encoded separately by using arithmetic coding. The proposed model provides a probability distribution for each block which is modeled by a mixture of non-parametric distributions by exploiting the high correlation between neighboring blocks. The Expectation-Maximization algorithm is used to find the maximum likelihood mixture parameters in order to maximize the arithmetic coding compression efficiency. The results of comparative experiments show that we provide significant improvements over the state-of-the-art lossless image compression standards and algorithms. In addition, experimental results show that the proposed compression algorithm beats JPEG-LS by 9.7 % when switching between pixel and prediction error domains.
C1 [Masmoudi, Atef] Univ Sfax, Sfax Preparatory Engn Inst, Sfax, Tunisia.
   [Masmoudi, Atef; Puech, William] Univ Montpellier 2, LIRMM, UMR CNRS 5506, F-34392 Montpellier 05, France.
   [Masmoudi, Afif] Univ Sfax, Fac Sci Sfax, Lab Stat & Probabil, Sfax, Tunisia.
C3 Universite de Sfax; Centre National de la Recherche Scientifique (CNRS);
   Universite Paul-Valery; Universite Perpignan Via Domitia; Universite de
   Montpellier; Universite de Sfax; Faculty of Sciences Sfax
RP Puech, W (corresponding author), Univ Montpellier 2, LIRMM, UMR CNRS 5506, F-34392 Montpellier 05, France.
EM atef.masmoudi@lirmm.fr; william.puech@lirmm.fr; afif.masmoudi@fss.rnu.tn
RI ; MASMOUDI, Atef/A-3258-2012
OI Puech, William/0000-0001-9383-2401; MASMOUDI, Atef/0000-0001-7540-3646
CR Alcaraz-Corona S, 2010, IEEE J-STSP, V4, P605, DOI 10.1109/JSTSP.2010.2048232
   [Anonymous], 2000, WILEY SERIES PROBABI
   [Anonymous], 2007, J CHEM INF MODEL, DOI DOI 10.1017/CBO9781107415324.004
   [Anonymous], 2002, JPEG2000: Image Compression Fundamentals, Standards, and Practice
   [Anonymous], 1963, Information Theory and Coding
   Aulí-Llinàs F, 2011, IEEE T IMAGE PROCESS, V20, P2153, DOI 10.1109/TIP.2011.2114892
   Burrows M., 1994, Algorithm, Data Compression, DOI 10.1.1.37.6774
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   HOWARD P, 1993, P DAT COMPR C, P351
   HOWARD PG, 1994, P IEEE, V82, P857, DOI 10.1109/5.286189
   Masmoudi A, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3435341
   Matsuda I, 2003, LECT NOTES COMPUT SC, V2849, P199
   Moffat A, 1998, ACM T INFORM SYST, V16, P256, DOI 10.1145/290159.290162
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Teuhola J, 2011, IEEE T INFORM THEORY, V57, P6170, DOI 10.1109/TIT.2011.2161910
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   WITTEN IH, 1987, COMMUN ACM, V30, P520, DOI 10.1145/214762.214771
   WU CFJ, 1983, ANN STAT, V11, P95, DOI 10.1214/aos/1176346060
   Wu JJ, 2013, SIGNAL PROCESS-IMAGE, V28, P727, DOI 10.1016/j.image.2013.04.004
   Ye H., 2002, EUSIPCO, P514
   Zhang L, 2012, IEEE T BROADCAST, V58, P228, DOI 10.1109/TBC.2012.2186728
   Zhao DY, 2008, IEEE T COMMUN, V56, P2094, DOI 10.1109/TCOMM.2008.070357
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 30
TC 16
Z9 16
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10605
EP 10619
DI 10.1007/s11042-014-2195-8
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700021
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, XB
   Feng, XC
AF Zhang, Xiaobo
   Feng, Xiangchu
TI Image denoising using local adaptive layered Wiener filter in the
   gradient domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wiener filter; Local window; Gradient domain; Layered denoising;
   Anisotropic diffusion
ID ANISOTROPIC DIFFUSION; EDGE-DETECTION
AB This paper presents a new image denoising algorithm. Our method is inspired by locally adaptive window-based denoising using maximum likelihood (LAWML). In the research, we find, as with wavelet coefficients, the gradient image coefficients can also be modeled as zero-mean Gaussian random variables with high local correlation. So, we implement the local adaptive Wiener filter in the gradient domain. But unlike LAWML, the layered denoising is adopted in our method. At the same time, the relation between wavelet-based and diffusion-based denoising method is disclosed further. The tests demonstrate the proposed method gets the desired results both subjectively and objectively compared to the related gradient domain algorithms and wavelet-based image denoising methods. At the same time, the tests also show the proposed method outperforms some other diffusion filters and wavelet-based methods and Non-Local means (NL-means) filter in most cases.
C1 [Zhang, Xiaobo] Xianyang Normal Univ, Inst Graph & Image Proc, Xianyang 712000, Peoples R China.
   [Feng, Xiangchu] Xidian Univ, Dept Math, Xian 710071, Peoples R China.
C3 Xianyang Normal University; Xidian University
RP Zhang, XB (corresponding author), Xianyang Normal Univ, Inst Graph & Image Proc, Xianyang 712000, Peoples R China.
EM zhangxiaobo419@126.com
OI Zhang, Xiaobo/0000-0001-6018-4655
FU National Nature Science Foundation of China [61102018, 61271294];
   Natural Science Foundation of Shaanxi Province [2014JM8312]; Natural
   Science Foundation of Xianyang Normal University [11XSYK304]
FX This work is partially supported by the National Nature Science
   Foundation of China (Grant Nos. 61102018 and 61271294) and Natural
   Science Foundation of Shaanxi Province (No. 2014JM8312) and Natural
   Science Foundation of Xianyang Normal University (No. 11XSYK304).
CR Blu T, 2007, IEEE T IMAGE PROCESS, V16, P2778, DOI 10.1109/TIP.2007.906002
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   CATTE F, 1992, SIAM J NUMER ANAL, V29, P182, DOI 10.1137/0729012
   Chao SM, 2010, PATTERN RECOGN LETT, V31, P2012, DOI 10.1016/j.patrec.2010.06.004
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Easley GR, 2009, IEEE T IMAGE PROCESS, V18, P260, DOI 10.1109/TIP.2008.2008070
   Ghael SP, 1997, P SOC PHOTO-OPT INS, V3169, P389, DOI 10.1117/12.292799
   Hajiaboli MR, 2012, IEEE T IMAGE PROCESS, V21, P1561, DOI 10.1109/TIP.2011.2172803
   Li HC, 2012, ELECTRON LETT, V48, P827, DOI 10.1049/el.2011.3994
   Lu JB, 2012, PROC CVPR IEEE, P430, DOI 10.1109/CVPR.2012.6247705
   Luisier F, 2007, IEEE T IMAGE PROCESS, V16, P593, DOI 10.1109/TIP.2007.891064
   Mihçak MK, 1999, INT CONF ACOUST SPEE, P3253, DOI 10.1109/ICASSP.1999.757535
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Steidl G, 2004, SIAM J NUMER ANAL, V42, P686, DOI 10.1137/S0036142903422429
   Sun J, 2010, PATTERN RECOGN, V43, P2630, DOI 10.1016/j.patcog.2010.02.019
   Welk M, 2008, APPL COMPUT HARMON A, V24, P195, DOI 10.1016/j.acha.2007.05.004
   Zhang L, 2010, PATTERN RECOGN, V43, P1531, DOI 10.1016/j.patcog.2009.09.023
   Zhang XB, 2014, J VIS COMMUN IMAGE R, V25, P254, DOI 10.1016/j.jvcir.2013.11.006
   Zhang XB, 2014, AEU-INT J ELECTRON C, V68, P179, DOI 10.1016/j.aeue.2013.08.009
   Zhang XB, 2013, COMPUT ELECTR ENG, V39, P934, DOI 10.1016/j.compeleceng.2012.07.013
   Zhong JM, 2008, IEEE T CIRCUITS-I, V55, P2716, DOI 10.1109/TCSI.2008.920061
NR 22
TC 9
Z9 9
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10495
EP 10514
DI 10.1007/s11042-014-2182-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700016
DA 2024-07-18
ER

PT J
AU Hou, QZ
   Dai, JP
   Li, L
   Lu, JF
   Chang, CC
AF Hou, Qingzheng
   Dai Junping
   Li, Li
   Lu, Jianfeng
   Chang, Chin-Chen
TI Scanned binary image watermarking based on additive model and sampling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Binary image; Digital watermarking; Printing scanning; Data hiding; Hard
   copy; Invariant; Image expansion; Image sampling; Thumbnails
AB Binary image watermarking technology has been the foundation of other anti-counterfeiting techniques such as anti-counterfeit of digital documents and commercial bills and so on. However, researches had been done to hide important data in color image and grayscale image but not enough on binary image. This paper proposes a novel watermarking technique for binary images. First, a binary image is split into multiple thumbnails using a perimeter expansion and sampling operation. Then, the watermarking information is embedded by flipping pixels in the thumbnails to change the number of black pixels. Finally, the watermarked binary image is produced by inverse sampling the thumbnails. The binary image expansion and sampling operation can also be used on a printed and scanned binary image, where the watermarking information is extracted by comparing the difference between the number of black pixels in the thumbnail and the mean value. The experimental results showed that the proposed method is robust to the printing and scanning process.
C1 [Hou, Qingzheng; Li, Li; Lu, Jianfeng] Hangzhou Dianzi Univ, Inst Graph & Image, Hangzhou, Zhejiang, Peoples R China.
   [Dai Junping] Hangzhou Dianzi Univ, Inst Digital Media, Hangzhou, Zhejiang, Peoples R China.
   [Chang, Chin-Chen] Feng Chia Univ, Dept Comp Sci & Informat Engn, Taichung 40724, Taiwan.
   [Chang, Chin-Chen] Asia Univ, Dept Comp Sci & Informat Engn, Taichung 41354, Taiwan.
C3 Hangzhou Dianzi University; Hangzhou Dianzi University; Feng Chia
   University; Asia University Taiwan
RP Li, L (corresponding author), Hangzhou Dianzi Univ, Inst Graph & Image, Hangzhou, Zhejiang, Peoples R China.
EM djp@hdu.edu.cn; lili2008@hdu.edu.cn; alan3c@gmail.com
RI Chang, Ching-Chun/JAN-6210-2023; zhu, yujie/KBC-4009-2024
OI Li, Ling/0000-0001-9722-9503
FU National Key Technology Research and Development Program of Ministry of
   Science and Technology of China [2012BAH91F03]; National Natural Science
   Foundation of China [61370218]
FX This work was partially supported by the National Key Technology
   Research and Development Program of the Ministry of Science and
   Technology of China (No. 2012BAH91F03) and National Natural Science
   Foundation of China (No. 61370218).
CR [Anonymous], P INT S MULT
   Cao H., 2012, SIGN INF PROC ASS AN, P1
   Chen J, 2003, IEEE FIFTH INTERNATIOANL SYMPOSIUM ON MULTIMEDIA SOFTWARE ENGINEERING, PROCEEDINGS, P88
   Daraee F, 2011, INF SEC CRYPT ISCISC, P67
   He B, 2009, COMP SCI INF ENG WRI, P290
   [亓文法 QI Wenfa], 2008, [通信学报, Journal on Communications], V29, P183
   Ren-Jie Li, 2006, 2006 International Symposium on Intelligent Signal Processing and Communications (IEEE Cat. No.06EX1444), P764
   Tan LN, 2012, RADIOENGINEERING, V21, P170
   Wu HC, 2008, ISDA 2008: EIGHTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 3, PROCEEDINGS, P513, DOI 10.1109/ISDA.2008.144
   Wu M, 2004, IEEE T MULTIMEDIA, V6, P528, DOI 10.1109/tmm.2004.830814
   Wu M, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P393, DOI 10.1109/ICME.2000.869623
   Zhao J., 1995, Intellectual Property Rights and New Technologies. Proceedings of the KnowRight'95 Conference, P242
NR 12
TC 6
Z9 8
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9407
EP 9426
DI 10.1007/s11042-014-2124-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200016
DA 2024-07-18
ER

PT J
AU Valuch, C
   Ansorge, U
AF Valuch, Christian
   Ansorge, Ulrich
TI The influence of color during continuity cuts in edited movies: an
   eye-tracking study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Edited videos; Continuity; Color; Attention; Eye movements; Memory
ID VISUAL WORKING-MEMORY; RECOGNITION; SEARCH; MOVEMENTS; CAPACITY; FILM
AB Professionally edited videos entail frequent editorial cuts - that is, abrupt image changes from one frame to another. The impact of these cuts on human eye movements is currently not well understood. In the present eye-tracking study, we experimentally gauged the degree to which color and visual continuity contributed to viewers' eye movements following cinematic cuts. In our experiment, viewers were presented with two edited action sports movies on the same screen but they were instructed to watch and keep their gaze on only one of these movies. Crucially, the movies were frequently interrupted and continued after a short break either at the same or at switched locations. Hence, viewers needed to rapidly recognize the continuation of the relevant movie and re-orient their gaze toward it. Properties of saccadic eye movements following each interruption probed the recognition of the relevant movie after a cut. Two key findings were that (i) memory co-determines attention after cuts in edited videos, resulting in faster re-orientation toward scene continuations when visual continuity across the interruption is high than when it is low, and (ii) color contributes to the guidance of attention after cuts, but its benefit largely rests upon enhanced discrimination of relevant from irrelevant visual information rather than memory. Results are discussed with regard to previous research on eye movements in movies and recognition processes. Possible future directions of research are outlined.
C1 [Valuch, Christian] Univ Vienna, Cognit Sci Res Platform, Vienna, Austria.
   [Valuch, Christian; Ansorge, Ulrich] Univ Vienna, Fac Psychol, A-1010 Vienna, Austria.
C3 University of Vienna; University of Vienna
RP Valuch, C (corresponding author), Univ Vienna, Cognit Sci Res Platform, Vienna, Austria.
EM christian.valuch@univie.ac.at
RI Valuch, Christian/O-5228-2019; Ansorge, Ulrich/H-4413-2013
OI Valuch, Christian/0000-0002-3974-1063; Ansorge,
   Ulrich/0000-0002-2421-9942
FU Wiener Wissenschafts-, Forschungs- und Technologiefonds (WWTF, Vienna
   Science and Technology Fund) [CS 11-009]
FX The authors thank two anonymous reviewers for their excellent and
   helpful feedback on a previous version of this manuscript, as well as
   Blerim Zeqiri and Stefan Kandioller for assistance with data collection.
   This research was funded by a grant from the Wiener Wissenschafts-,
   Forschungs- und Technologiefonds (WWTF, Vienna Science and Technology
   Fund), no. CS 11-009 to Ulrich Ansorge, Shelley Buchinger, and Otmar
   Scherzer.
CR [Anonymous], 1996, Cognitive Ecology, DOI DOI 10.1016/B978-012161966-4/50008-6
   Ansorge U, 2014, 2014 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND MULTIMEDIA APPLICATIONS (SIGMAP), P198
   Böhme M, 2006, NEUROCOMPUTING, V69, P1996, DOI 10.1016/j.neucom.2005.11.019
   Bordwell David., 2001, Film Art: An Introduction, V6th
   Brady TF, 2008, P NATL ACAD SCI USA, V105, P14325, DOI 10.1073/pnas.0803390105
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Carmi R, 2006, J VISION, V6, P898, DOI 10.1167/6.9.4
   Carmi R, 2006, VISION RES, V46, P4333, DOI 10.1016/j.visres.2006.08.019
   Cornelissen FW, 2002, BEHAV RES METH INS C, V34, P613, DOI 10.3758/BF03195489
   Cutting JE, 2012, J EXP PSYCHOL HUMAN, V38, P1476, DOI 10.1037/a0027737
   Dorr M, 2010, J VISION, V10, DOI 10.1167/10.10.28
   DUNCAN J, 1989, PSYCHOL REV, V96, P433, DOI 10.1037/0033-295X.96.3.433
   DZMURA M, 1991, VISION RES, V31, P951, DOI 10.1016/0042-6989(91)90203-H
   Foulsham T, 2013, J EXP PSYCHOL GEN, V142, P41, DOI 10.1037/a0028227
   Gegenfurtner KR, 2000, CURR BIOL, V10, P805, DOI 10.1016/S0960-9822(00)00563-7
   Hansen T, 2009, VISUAL NEUROSCI, V26, P35, DOI 10.1017/S0952523808080796
   Huang LQ, 2004, MEM COGNITION, V32, P12, DOI 10.3758/BF03195816
   Kirchner H, 2006, VISION RES, V46, P1762, DOI 10.1016/j.visres.2005.10.002
   Kristjánsson A, 2010, ATTEN PERCEPT PSYCHO, V72, P5, DOI 10.3758/APP.72.1.5
   Lamy DF, 2013, J VISION, V13, DOI 10.1167/13.3.14
   Levin DT, 2000, MEDIA PSYCHOL, V2, P357, DOI 10.1207/S1532785XMEP0204_03
   Luck SJ, 1997, NATURE, V390, P279, DOI 10.1038/36846
   Magliano JP, 2011, COGNITIVE SCI, V35, P1489, DOI 10.1111/j.1551-6709.2011.01202.x
   MALJKOVIC V, 1994, MEM COGNITION, V22, P657, DOI 10.3758/BF03209251
   May J, 2003, HUM-COMPUT INTERACT, V18, P325, DOI 10.1207/S15327051HCI1804_1
   MOLLON JD, 1989, J EXP BIOL, V146, P21
   Murch Walter., 1995, In the Blink of an Eye: A Perspective on Film Editing, V2nd
   Olivers CNL, 2006, J EXP PSYCHOL HUMAN, V32, P1243, DOI 10.1037/0096-1523.32.5.1243
   Pelli DG, 1997, SPATIAL VISION, V10, P437, DOI 10.1163/156856897X00366
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Reisz Karel., 1953, The Technique of Film Editing
   Rousselet GA, 2002, NAT NEUROSCI, V5, P629, DOI 10.1038/nn866
   Smith T.J., 2008, J EYE MOVEMENT RES, V2, P1, DOI DOI 10.16910/JEMR.2.2.6
   Smith TJ, 2012, PROJECTIONS, V6, P1, DOI 10.3167/proj.2012.060102
   Smith TJ, 2013, J VISION, V13, DOI 10.1167/13.8.16
   Smith TJ, 2012, CURR DIR PSYCHOL SCI, V21, P107, DOI 10.1177/0963721412437407
   STANDING L, 1973, Q J EXP PSYCHOL, V25, P207, DOI 10.1080/14640747308400340
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Valuch C, 2014, P 2014 ACM INT C INT, P119, DOI [10.1145/2602299.2602307, DOI 10.1145/2602299.2602307]
   Valuch C, 2013, J VISION, V13, DOI 10.1167/13.3.3
   Wichmann FA, 2002, J EXP PSYCHOL LEARN, V28, P509, DOI 10.1037//0278-7393.28.3.509
   Wolfe JM, 2004, NAT REV NEUROSCI, V5, P495, DOI 10.1038/nrn1411
NR 42
TC 8
Z9 9
U1 1
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 22
BP 10161
EP 10176
DI 10.1007/s11042-015-2806-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA CV1LQ
UT WOS:000364019400018
DA 2024-07-18
ER

PT J
AU Kim, Y
   Lee, Y
   Chung, KY
   Lee, KD
AF Kim, Younjung
   Lee, Youngho
   Chung, Kyung-Yong
   Lee, Kang-Dae
TI An investigation on the information systems research in supply chain
   management: an analysis of research topic and methodology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information system; Supply chain management; Keyword; Methodology; Trend
   and future direction
ID COORDINATION; PERFORMANCE; INTEGRATION
AB This study is designed to investigate the present status of information system (IS) research in relation to supply chain management (SCM) in order to provide how IS in SCM research is likely to develop in the near future. We attempted to investigate the existing literature about information systems in the fields of SCM that were selected from 91 journal articles published between 2006 and 2010, including the database of ScienceDirect. As a result, we found the current trend and future direction of research with the most popular research topics and methodologies were in the articles. The most frequent research keywords appeared in the sample articles are the characteristics and goals of supply chain, inventory, and the methods of data collection and analysis. And the major research methods in empirical research strategy are a lab experiment and survey. In addition, we found that the topics of research associated with IS in SCM are diversified, while the research methods are limited because of the lack of theoretical stance and qualitative study. Therefore, future research needs to focus on how or why question research which employs qualitative method to find the underlying theoretical mechanism. We conducted this research to determine the direction of future research in this field and such a direction would be helpful to suggest how it be further conducted. Our understanding of the ongoing issues discussed on current IS papers in the field of SCM will be beneficial for both academic and practical purposes.
C1 [Kim, Younjung; Lee, Kang-Dae] Yonsei Univ, Dept Packaging, Wonju, Gangwon Do, South Korea.
   [Lee, Youngho] Gachon Univ Med & Sci, Dept Comp Sci, Inchon, South Korea.
   [Chung, Kyung-Yong] Sangji Univ, Dept Comp Informat Engn, Wonju, Gangwon Do, South Korea.
C3 Yonsei University; Gachon University; Sangji University
RP Lee, KD (corresponding author), Yonsei Univ, Dept Packaging, 1 Yonseidae Gil, Wonju, Gangwon Do, South Korea.
EM pimeson@yonsei.ac.kr
RI Chung, Kyungyong/JAC-2276-2023
CR Alavi M., 1992, Journal of Management Information Systems, V8, P45
   Chatfield DC, 2009, EUR J OPER RES, V196, P651, DOI 10.1016/j.ejor.2008.03.027
   Choi H, 2014, MULTIMED TOOLS APPL, V68, P321, DOI 10.1007/s11042-012-1118-9
   Dehning B, 2007, J OPER MANAG, V25, P806, DOI 10.1016/j.jom.2006.09.001
   Ghafoor A, 2007, MULTIMED TOOLS APPL, V33, P31, DOI 10.1007/s11042-006-0099-y
   Gunasekaran A, 2004, EUR J OPER RES, V159, P269, DOI 10.1016/j.ejor.2003.08.016
   Holweg M, 2008, J OPER MANAG, V26, P389, DOI 10.1016/j.jom.2007.08.003
   Hosoda T, 2006, OMEGA-INT J MANAGE S, V34, P344, DOI 10.1016/j.omega.2004.11.005
   Kelle P, 2005, INT J PROD ECON, V93-4, P41, DOI 10.1016/j.ijpe.2004.06.004
   Ketikidis PH, 2008, OMEGA-INT J MANAGE S, V36, P592, DOI 10.1016/j.omega.2006.11.010
   Kim JY, 2014, MULTIMED TOOLS APPL, V68, P465, DOI 10.1007/s11042-013-1357-4
   Klein R, 2007, J OPER MANAG, V25, P1366, DOI 10.1016/j.jom.2007.03.001
   Kurata H, 2007, EUR J OPER RES, V177, P1026, DOI 10.1016/j.ejor.2006.01.009
   Li XH, 2007, EUR J OPER RES, V179, P1, DOI 10.1016/j.ejor.2006.06.023
   Lin FR, 2008, DECIS SUPPORT SYST, V45, P795, DOI 10.1016/j.dss.2008.02.001
   Mentzer J.T., 2001, J BUSINESS LOGISTICS, V22, P1, DOI [DOI 10.1002/J.2158-1592.2001.TB00001.X, 10.1002/j.2158-1592.2001.tb00001.x]
   Oz E., 2008, MANAGEMENT INFORM SY, V6th
   Palvia P, 2007, INFORM MANAGE-AMSTER, V44, P1, DOI 10.1016/j.im.2006.10.002
   Sachan A., 2005, International Journal of Physical Distribution & Logistics Management, V35, P664, DOI 10.1108/09600030510632032
   Seggie SH, 2006, J BUS RES, V59, P887, DOI 10.1016/j.jbusres.2006.03.005
   Stair R., 1998, Principles of information systems, V3rd
   Su YF, 2010, EXPERT SYST APPL, V37, P456, DOI 10.1016/j.eswa.2009.05.061
   Thuraisingham B, 2007, MULTIMED TOOLS APPL, V33, P13, DOI 10.1007/s11042-006-0096-1
   Trkman P, 2010, DECIS SUPPORT SYST, V49, P318, DOI 10.1016/j.dss.2010.03.007
   Williamson EA, 2004, INT J INFORM MANAGE, V24, P375, DOI 10.1016/j.ijinfomgt.2004.06.002
   Zhang C, 2006, OMEGA-INT J MANAGE S, V34, P427, DOI 10.1016/j.omega.2004.12.005
   Zhou W, 2009, EUR J OPER RES, V198, P252, DOI 10.1016/j.ejor.2008.09.017
NR 27
TC 7
Z9 8
U1 0
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 20
BP 8849
EP 8860
DI 10.1007/s11042-013-1632-4
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CR6XU
UT WOS:000361492600010
DA 2024-07-18
ER

PT J
AU Lee, JE
   Chung, KY
   Lee, KD
   Gen, M
AF Lee, Jeong-Eun
   Chung, Kyung-Yong
   Lee, Kang-Dae
   Gen, Mitsuo
TI A multi-objective hybrid genetic algorithm to minimize the total cost
   and delivery tardiness in a reverse logistics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-objective reverse logistics network (mo-RLN); Pri-awGA
   (priority-based GA with adaptive weight approach); Multi-objective
   hybrid genetic algorithm (mo-hGA); Fuzzy logic controller (FLC)
ID INVENTORY CONTROL; NETWORK DESIGN; MODEL; TIME; OPTIMIZATION;
   MULTIPERIOD; PERSPECTIVE; IMPACT
AB In the recent environmental protection the reverse logistics of the used product is one of the most important research topics. The reverse logistics is the process flow of used-products that are collected to be reproduced so that they can be sold again to customers after some processing. We propose a multi-objective hybrid genetic algorithm (mo-hGA) combined with Fuzzy Logic Controller (FLC) for efficiently dealing with multi-objective reverse logistics network (mo-RLN) problem. The aim of this paper is firstly to formulate mo-RLN model, and secondly to optimize it by mo-hGA method proposed with reusable system configuration. In particular two objective functions to be minimized total costs of mo-RLN, (i.e. fixed opening cost, transportation cost and inventory cost) and also minimized delivery tardiness in all periods are considered in the model. We will clear each objective function (i.e. total costs and total delivery tardiness), computational time and number of Pareto solutions with LINGO, pri-awGA (priority-based GA with adaptive weight approach) and mo-hGA proposed with numerical examples. For demonstrating the effectiveness of the proposed model, we evaluate with the numerical examples and simulate it with a bottles distilling/sale company as a case study in Busan, Korea.
C1 [Lee, Jeong-Eun] Dong Eui Univ, Dept Accounting, Busan, South Korea.
   [Chung, Kyung-Yong] Sangji Univ, Sch Comp Informat Engn, Wonju 220702, Gangwon Do, South Korea.
   [Lee, Kang-Dae] Yonsei Univ, Dept Packaging, Wonju, Kangwon Do, South Korea.
   [Gen, Mitsuo] Fuzzy Log Syst Inst, Iizuka, Fukuoka, Japan.
C3 Dong-Eui University; Sangji University; Yonsei University
RP Lee, KD (corresponding author), Yonsei Univ, Dept Packaging, 234 Maeji Heungup, Wonju, Kangwon Do, South Korea.
EM leeje@deu.ac.kr; dragonhci@hanmail.net; pimeson@yonsei.ac.kr;
   gen@flsi.or.jp
RI Gen, M/GYA-2235-2022; Chung, Kyungyong/JAC-2276-2023
FU Yonsei University; Japan Society of Promotion of Science (JSPS)
   [245102190001]; Taiwan National Science Council (NSC)
   [101-2811-E-007-004]; Grants-in-Aid for Scientific Research [24510219]
   Funding Source: KAKEN
FX This work was partly supported by the Yonsei University Research Fund of
   2012, by the Grant-in-Aid for Scientific Research (C) (No.245102190001)
   of the Japan Society of Promotion of Science (JSPS) and Taiwan National
   Science Council (NSC 101-2811-E-007-004).
CR Altiparmak F, 2006, COMPUT IND ENG, V51, P196, DOI 10.1016/j.cie.2006.07.011
   Alumur SA, 2012, EUR J OPER RES, V220, P67, DOI 10.1016/j.ejor.2011.12.045
   [Anonymous], 1997, GENETIC ALGORITHMS C
   Barnes-Schuster D, 2006, EUR J OPER RES, V174, P1664, DOI 10.1016/j.ejor.2002.08.002
   de Brito MP, 2009, EUR J OPER RES, V194, P85, DOI 10.1016/j.ejor.2007.11.063
   Du F, 2008, COMPUT OPER RES, V35, P2617, DOI 10.1016/j.cor.2006.12.020
   Farahani RZ, 2008, INT J PROD ECON, V111, P229, DOI 10.1016/j.ijpe.2006.11.028
   Galand L, 2010, EUR J OPER RES, V204, P303, DOI 10.1016/j.ejor.2009.10.015
   Salcedo CAG, 2013, EUR J OPER RES, V224, P261, DOI 10.1016/j.ejor.2012.07.029
   Gen M., 2005, COMPLEX INT, V11, P73
   Gen M., 2000, Genetic Algorithms and Engineering Optimization
   Gen MitsuoRunwei Cheng Lin Lin., 2008, NETWORK MODELS OPTIM, DOI DOI 10.1007/978-1-84800-181-7
   Glock CH, 2012, INT J PROD ECON, V136, P37, DOI 10.1016/j.ijpe.2011.09.007
   Grubbstrom RW, 2011, INT J PROD ECON, V143, P395
   Keren B, 2009, OMEGA-INT J MANAGE S, V37, P801, DOI 10.1016/j.omega.2008.07.006
   Kim YK, 2005, J KOREAN I IND ENG, V31, P180
   Ko HJ, 2007, COMPUT OPER RES, V34, P346, DOI 10.1016/j.cor.2005.03.004
   Ko M, 2010, APPL SOFT COMPUT, V10, P661, DOI 10.1016/j.asoc.2009.09.004
   Lee DH, 2009, TRANSPORT RES E-LOG, V45, P61, DOI 10.1016/j.tre.2008.08.002
   Lee JE, 2009, COMPUT IND ENG, V56, P951, DOI 10.1016/j.cie.2008.09.021
   Lin L, 2009, SOFT COMPUT, V13, P157, DOI 10.1007/s00500-008-0303-2
   LINDO Systems Inc, 2003, LINGO MOD LANG OPT
   Min H, 2008, INT J PROD ECON, V113, P176, DOI 10.1016/j.ijpe.2007.01.017
   MOED MC, 1991, P IEEE INT C TOOLS A, P500
   PARK KYUNG SAM, 2009, [korean management review, 경영학연구], V38, P1251
   Pati RK, 2008, OMEGA-INT J MANAGE S, V36, P405, DOI 10.1016/j.omega.2006.04.014
   Pishvaee MS, 2010, FUZZY SET SYST, V161, P2668, DOI 10.1016/j.fss.2010.04.010
   Pishvaee MS, 2010, COMPUT OPER RES, V37, P1100, DOI 10.1016/j.cor.2009.09.018
   Ray S, 2004, EUR J OPER RES, V153, P769, DOI 10.1016/S0377-2217(02)00655-0
   Sha DY, 2006, J OPER RES SOC, V57, P52, DOI 10.1057/palgrave.jors.2601949
   Tempelmeier H, 2006, EUR J OPER RES, V174, P600, DOI 10.1016/j.ejor.2005.01.044
   Ülkü MA, 2012, EUR J OPER RES, V221, P110, DOI 10.1016/j.ejor.2012.03.021
   Xu JP, 2008, INFORM SCIENCES, V178, P2022, DOI 10.1016/j.ins.2007.11.025
   Xu NX, 2011, INT J PROD ECON, V133, P719, DOI 10.1016/j.ijpe.2011.05.026
NR 34
TC 27
Z9 32
U1 2
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 20
BP 9067
EP 9085
DI 10.1007/s11042-013-1594-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CR6XU
UT WOS:000361492600027
OA hybrid
DA 2024-07-18
ER

PT J
AU Chang, TM
   Hsieh, CB
   Chang, PC
AF Chang, Tai-Ming
   Hsieh, Chia-Bin
   Chang, Pao-Chi
TI An enhanced direct chord transformation for music retrieval in the AAC
   transform domain with window switching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AAC; Transform domain; Chroma feature; Audio coding; Music information
   retrieval
ID AUDIO; FEATURES
AB With the explosive growth in the number of music albums produced, retrieving music information has become a critical aspect of managing music data. Extracting frequency parameters directly from the compressed files to represent music greatly benefits processing speed when working on a large database. In this study, we focused on advanced audio coding (AAC) files and analyzed the disparity in frequency expression between discrete Fourier transform and discrete cosine transform, considered the frequency resolution to select the appropriate frequency range, and developed a direct chroma feature-transformation method in the AAC transform domain. An added challenge to using AAC files directly is long/short window switching, ignoring which may result in inaccurate frequency mapping and inefficient information retrieval. For a short window in particular, we propose a peak-competition method to enhance the pitch information that does not include ambiguous frequency components when combining eight subframes. Moreover, for chroma feature segmentation, we propose a simple dynamic-segmentation method to replace the complex computation of beat tracking. Our experimental results show that the proposed method increased the accuracy rate by approximately 7 % in Top-1 search results over transform-domain methods described previously and performed nearly as effectively as state-of-the-art waveform-domain approaches did.
C1 [Chang, Tai-Ming; Hsieh, Chia-Bin; Chang, Pao-Chi] Natl Cent Univ, Dept Commun Engn, Jhongli, Taiwan.
C3 National Central University
RP Chang, PC (corresponding author), Natl Cent Univ, Dept Commun Engn, Jhongli, Taiwan.
EM tmchang@vaplab.ce.ncu.edu.tw; cbhsieh@vaplab.ce.ncu.edu.tw;
   pcchang@ce.ncu.edu.tw
CR [Anonymous], 1999, 111723F ISOIEC
   [Anonymous], 1979, PROGRAMS DIGITAL SIG
   [Anonymous], 2008, P 14 ACM SIGKDD INT, DOI DOI 10.1145/1401890.1401906
   [Anonymous], 1997, 138187 ISOIEC
   Bello J. P., 2005, P 6 INT C MUSIC INFO, P304, DOI 10.5281/zenodo.1417431
   Bertin-Mahieux T, 2011, 2011 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS (WASPAA), P117, DOI 10.1109/ASPAA.2011.6082307
   Bertin-Mahieux Thierry, 2011, P 12 INT C MUSIC INF
   Chang TM, 2013, IEEE 2 GLOB IN PRESS
   Chen SX, 2010, MULTIMED TOOLS APPL, V48, P225, DOI 10.1007/s11042-009-0326-4
   COOLEY JW, 1965, MATH COMPUT, V19, P297, DOI 10.2307/2003354
   Ellis DPW, 2007, INT CONF ACOUST SPEE, P1429
   Fan J., 2005, NONLINEAR TIME SERIE
   Fujishima T., 1999, P INT COMP MUS C, P464
   Hinsen G., 1993, Applicable Analysis, V49, P49, DOI 10.1080/00036819308840164
   Lee MH, 2014, MULTIMED TOOLS APPL, V73, P901, DOI 10.1007/s11042-013-1383-2
   Malvar H., 1992, SIGNAL PROCESSING LA
   Müller M, 2010, IEEE T AUDIO SPEECH, V18, P649, DOI 10.1109/TASL.2010.2041394
   Nakajima Y, 1999, INT CONF ACOUST SPEE, P3005, DOI 10.1109/ICASSP.1999.757473
   OETKEN G, 1975, IEEE T ACOUST SPEECH, VAS23, P301, DOI 10.1109/TASSP.1975.1162686
   Patel NV, 1996, P SOC PHOTO-OPT INS, V2670, P373, DOI 10.1117/12.234776
   Ravelli E, 2010, IEEE T AUDIO SPEECH, V18, P434, DOI 10.1109/TASL.2009.2025099
   Ravuri S, 2009, MIREX AUD COV SONG I
   Serra J., 2010, ADV MUSIC INFORM RET
   Serrà J, 2008, IEEE T AUDIO SPEECH, V16, P1138, DOI 10.1109/TASL.2008.924595
   Shao X, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL IV, PROCEEDINGS, P261
   SMITH TF, 1981, J MOL BIOL, V147, P195, DOI 10.1016/0022-2836(81)90087-5
   Tsai TH, 2007, IEICE T FUND ELECTR, VE90A, P1913, DOI 10.1093/ietfec/e90-a.9.1913
   Yu CH, 2002, LECT NOTES COMPUT SC, V2532, P663
NR 28
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 7921
EP 7942
DI 10.1007/s11042-014-2031-1
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200023
DA 2024-07-18
ER

PT J
AU De Cock, J
   Hofbauer, H
   Stütz, T
   Uhl, A
   Unterweger, A
AF De Cock, Jan
   Hofbauer, Heinz
   Stuetz, Thomas
   Uhl, Andreas
   Unterweger, Andreas
TI An industry-level blu-ray watermarking framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Framework; Watermarking; H.264; Length-preserving; Parallelization
AB In this paper, we present our H.264 Blu-ray watermarking framework which operates at bit stream level and preserves the length of the underlying bit stream. Apart from a description of our watermark embedding and detection (and synchronisation) approaches, we discuss the embedding capacity for different exemplary Blu-ray disks based on their bit stream characteristics as well as the robustness of our watermark to H.264 transcoding and resizing. Furthermore, we assess the parallelizability of our embedding approach and the impact of different hard drive configurations on the overall embedding speed, showing that low access times are as relevant as high transfer rates when maximum speedup through parallelization is desired. Lastly, this paper provides a discussion on a variety of design choices and practical issues which arise when designing an industry-level watermarking framework.
C1 [De Cock, Jan] Ghent Univ iMinds, B-9050 Ledeberg Ghent, Belgium.
   [Hofbauer, Heinz; Uhl, Andreas; Unterweger, Andreas] Salzburg Univ, A-5020 Salzburg, Austria.
   [Stuetz, Thomas] FH Salzburg, Urstein Sud 1, A-5412 Puch Bei Hallein, Austria.
C3 IMEC; Ghent University; Salzburg University
RP Hofbauer, H (corresponding author), Salzburg Univ, Jakob Haringer Str 2, A-5020 Salzburg, Austria.
EM jan.decock@ugent.be; hhofbaue@cosy.sbg.ac.at;
   thomas.stuetz@fh-salzburg.ac.at; uhl@cosy.sbg.ac.at;
   aunterweg@cosy.sbg.ac.at
OI Unterweger, Andreas/0000-0002-3374-1636
FU FFG bridge project [834165]
FX Special thanks to SONY DADC Austria AG, in particular Reinhard
   Blaukovitsch, for the cooperation in the project and the insights into
   industry requirements. This work has been supported by the FFG bridge
   project 834165.
CR [Anonymous], 2007, H264 ITUT
   [Anonymous], 2012, JTC1SC29WG11 ISOIEC
   [Anonymous], 2004, 144962 ISOIEC
   Chen TH, 2006, LECT NOTES ARTIF INT, V3930, P1033
   Cox IJ., 2007, DIGITAL WATERMARKING
   De Cock J, 2010, SIGNAL PROCESS-IMAGE, V25, P235, DOI 10.1016/j.image.2010.01.006
   Hartung F, 1999, P IEEE, V87, P1079, DOI 10.1109/5.771066
   Lin ET, 2004, IEEE T SIGNAL PROCES, V52, P3007, DOI 10.1109/TSP.2004.833866
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   Sinha RK, 2010, J MARKETING, V74, P40, DOI 10.1509/jmkg.74.2.40
   Stutz T., 2014, IEEE T MULT IN PRESS
   Stutz T., 2013, 201302 U SALZB DEP C
   Zou DK, 2010, IEEE INT CON MULTI, P117, DOI 10.1109/ICME.2010.5583550
NR 13
TC 1
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 8079
EP 8101
DI 10.1007/s11042-014-2042-y
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200030
DA 2024-07-18
ER

PT J
AU Zeng, JB
   Leng, B
   Xiong, Z
AF Zeng, Jiabei
   Leng, Biao
   Xiong, Zhang
TI 3-D object retrieval using topic model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3-D retrieval; Topic model
ID 3D MODEL; SEARCH ENGINE; RECOGNITION; SYSTEM
AB In the last few years, extensive effort has been spent to develop better performed 3-D object retrieval methods. View-based methods have attracted a significant amount of attention, not only because their state-of-art performance, but also they merely require some of a 3-D object's 2-D view images. However, most recent approaches only deal with the images' primordial-extracted features and ignore their hidden relationships. Considering these latent characters, a visual-topic-model 3-D object retrieval approach is introduced in this paper. In this framework, dense scale invariant feature transform(dense-SIFT) descriptors are extracted from a set of views of each 3-D object, and all the dense-SIFT descriptors are grouped into bag-of-word features using k-means clustering. Then, the topic distribution of a 3-D object is generated via latent dirichlet allocation (LDA) given its bag-of-word features. Gibbs sampling is applied in the learning and inference processing of LDA. We conduct experiments on the Princeton Shape Benchmark (PSB) and National Taiwan University 3D model database (NTU), and the experimental results demonstrate that the proposed method can achieve better retrieval effectiveness than the state-of-the-art methods under several standard evaluation measures.
C1 [Zeng, Jiabei; Leng, Biao; Xiong, Zhang] Beihang Univ, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
C3 Beihang University
RP Leng, B (corresponding author), Beihang Univ, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
EM lengbiao@buaa.edu.cn
RI Zeng, Jiabei/J-3865-2016
OI Zeng, Jiabei/0000-0003-3256-4524
FU National Natural Science Foundation of China [61103093]; New Teachers'
   Fund for Doctor Stations, Ministry of Education [20111102120017];
   National High-Tech Research and Development Plan of China (863)
   [2013AA01A601]
FX The 3-D model databases PSB and NTU are from the Shape Retrieval and
   Analysis Group at the University of Princeton and the National Taiwan
   University. This work is supported by the National Natural Science
   Foundation of China (No. 61103093), the New Teachers' Fund for Doctor
   Stations, Ministry of Education (No. 20111102120017), and the National
   High-Tech Research and Development Plan of China (863) (No.
   2013AA01A601).
CR Akgül CB, 2010, INT J COMPUT VISION, V89, P392, DOI 10.1007/s11263-009-0294-1
   Akgül CB, 2009, IEEE T PATTERN ANAL, V31, P1117, DOI 10.1109/TPAMI.2009.25
   [Anonymous], 2003, INT J IMAGE GRAPH
   [Anonymous], 2012, P 3DOR
   [Anonymous], 2007, Latent Semantic Analysis: A Road to Meaning. Ed. by
   [Anonymous], 2002, Proceedings of the Eighteenth Conference on Uncertainty in Artificial Intelligence. UAI'02
   Ansary TF, 2007, IEEE T MULTIMEDIA, V9, P78, DOI 10.1109/TMM.2006.886359
   Biao Leng, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8326, P128, DOI 10.1007/978-3-319-04117-9_12
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   Boyer E., 2011, Proceedings of the 4th Eurographics Conference on 3D Object Retrieval, P71
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Daras P, 2010, INT J COMPUT VISION, V89, P229, DOI 10.1007/s11263-009-0277-2
   Del Bimbo A, 2006, ACM T MULTIM COMPUT, V2, P20
   Detry R, 2009, IEEE T PATTERN ANAL, V31, P1790, DOI 10.1109/TPAMI.2009.64
   Ding K, 2013, MULTIMEDIA IN PRESS
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Ferreira A, 2010, INT J COMPUT VISION, V89, P327, DOI 10.1007/s11263-009-0257-6
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Gao Y, 2010, P ACM INT C MULT FIR, P955
   Gao Y, 2014, IEEE MULTIM IN PRESS
   Gao Y, 2014, IEEE T IND ELECTRON, V61, P2088, DOI 10.1109/TIE.2013.2262760
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Gao Y, 2011, IEEE T MULTIMEDIA, V13, P1007, DOI 10.1109/TMM.2011.2160619
   Gao Y, 2011, SIGNAL PROCESS-IMAGE, V26, P39, DOI 10.1016/j.image.2010.10.006
   Gao Y, 2010, NEUROCOMPUTING, V73, P1900, DOI 10.1016/j.neucom.2009.11.050
   Gao Y, 2010, PATTERN RECOGN, V43, P1142, DOI 10.1016/j.patcog.2009.07.012
   Griffiths T., 2002, Standford University, V518, P1
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Guétat G, 2006, IEEE T INF TECHNOL B, V10, P362, DOI 10.1109/TITB.2005.863875
   Hamerly G, 2004, ADV NEUR IN, V16, P281
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Kang L, 2013, FRONT COMPUT SCI-CHI, V7, P69, DOI 10.1007/s11704-013-1266-8
   Kim WY, 2000, SIGNAL PROCESS-IMAGE, V16, P95, DOI 10.1016/S0923-5965(00)00019-9
   Lavoue G., 2011, Eurographics Conference on 3D Object Retrieval, P41, DOI DOI 10.2312/3DOR/3DOR11/041-048
   Leng B, 2008, MULTIMED TOOLS APPL, V40, P135, DOI 10.1007/s11042-007-0188-6
   Leng B, 2007, J ZHEJIANG UNIV-SC A, V8, P1953, DOI 10.1631/jzus.2007.A1953
   Leng B, 2007, LECT NOTES COMPUT SC, V4418, P93
   Leng BA, 2010, FRONT COMPUT SCI CHI, V4, P394, DOI 10.1007/s11704-010-0366-y
   Leng BA, 2011, MULTIMED TOOLS APPL, V51, P935, DOI 10.1007/s11042-009-0424-3
   Leng BA, 2009, CHINESE J ELECTRON, V18, P291
   Liu Y, 2010, INT J COMPUT VISION, V89, P408, DOI 10.1007/s11263-009-0298-x
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mademlis A, 2008, IEEE T MULTIMEDIA, V10, P819, DOI 10.1109/TMM.2008.922790
   Mademlis A, 2009, PATTERN RECOGN, V42, P2447, DOI 10.1016/j.patcog.2009.04.024
   Makadia A, 2010, INT J COMPUT VISION, V89, P193, DOI 10.1007/s11263-009-0280-7
   Meng H, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS I-V, CONFERENCE PROCEEDINGS, P88, DOI 10.1109/ICMA.2007.4303521
   Mian A, 2010, INT J COMPUT VISION, V89, P348, DOI 10.1007/s11263-009-0296-z
   NTU, 2007, 3D MOD RETR
   Ohbuchi R, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P93, DOI 10.1109/SMI.2008.4547955
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Papadakis P, 2010, INT J COMPUT VISION, V89, P177, DOI 10.1007/s11263-009-0281-6
   Paquet E, 2000, SIGNAL PROCESS-IMAGE, V16, P103, DOI 10.1016/S0923-5965(00)00020-5
   Paquet E, 1999, IMAGE VISION COMPUT, V17, P157, DOI 10.1016/S0262-8856(98)00119-X
   Princeton, 2005, PRINC SHAP BENCHM
   Qian Q, 2013, FRONT COMPUT SCI-CHI, V7, P359, DOI 10.1007/s11704-013-2110-x
   Regli WC, 2000, COMPUT AIDED DESIGN, V32, P119, DOI 10.1016/S0010-4485(99)00095-0
   Ruggeri MR, 2010, INT J COMPUT VISION, V89, P248, DOI 10.1007/s11263-009-0250-0
   Shih JL, 2007, PATTERN RECOGN, V40, P283, DOI 10.1016/j.patcog.2006.04.034
   Sivic J., 2005, Discovering object categories in image collections
   Steyvers M., 2004, P 2004 ACM SIGKDD IN, DOI [DOI 10.1145/1014052.1014087, 10.1145/1014052, DOI 10.1145/1014052]
   Teh YeeWhye., 2006, Proceedings of the Neural Information Processing Systems, V6, P1378
   TurboSquid, 2013, 3D MOD TEXT PLUG TUR
   Wang M, 2013, IEEE T IMAGE PROCESS, V22, P1395, DOI 10.1109/TIP.2012.2231088
   Wong HS, 2007, IEEE T MULTIMEDIA, V9, P1026, DOI 10.1109/TMM.2007.898915
   Yeh JS, 2005, BIOINFORMATICS, V21, P3056, DOI 10.1093/bioinformatics/bti458
   Zhang DS, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P425, DOI 10.1109/ICME.2002.1035809
NR 68
TC 4
Z9 4
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 7859
EP 7881
DI 10.1007/s11042-014-2029-8
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200021
DA 2024-07-18
ER

PT J
AU Yin, X
   Kim, DH
   Hong, CP
   Kim, CG
   Kim, KJ
   Kim, SD
AF Yin, Xiyuan
   Kim, Dae-Hwan
   Hong, Chung-Pyo
   Kim, Cheong-Ghil
   Kim, Kuinam J.
   Kim, Shin-Dug
TI Advanced feature point transformation of corner points for mobile object
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart phone; Rotated object recognition; Corner detection; OpenCV;
   Mobile systems
ID PERFORMANCE EVALUATION
AB In this paper, a new method is proposed for recognizing rotated objects based on extracted feature points from the Harris corner detector using object corner points at real time in a mobile environment. With this proposed method, corner points can be rapidly extracted from the input image and object recognition can be conducted by comparing existing feature points. Color values for corner pixels in the feature points of rotated objects are generally varied in accordance with the degree of object rotation. The color values of the feature points are affected by the degree of rotated objects; therefore, there is a possibility that these values can be mixed with nearby pixel values. By analyzing the color values of the rotated pixels, we can extract feature points of rotated objects and use them for object detection to be effectively applied for rotated object detection. Although overall recognition rate is somewhat degraded, using the proposed object recognition with corner information of feature points makes it possible to execute in real time in mobile environments by reducing the amount of computation. Accordingly, this method can be applied to recognizing rotated objects, even in a mobile environment with limited computing capabilities. Experimental results show that the proposed method can provide approximately 96 % accuracy and high performance compared to other methods. Therefore, the proposed method can be adapted to recognize any rotated object with performance and accuracy.
C1 [Yin, Xiyuan; Kim, Shin-Dug] Yonsei Univ, Comp Sci, Seoul 120749, South Korea.
   [Kim, Dae-Hwan] LG Elect Seoul, Seoul, South Korea.
   [Hong, Chung-Pyo] LG Elect, Mobile Commun, Seoul, South Korea.
   [Kim, Cheong-Ghil] Namseoul Univ, Comp Sci, Cheonan Si, South Korea.
   [Kim, Kuinam J.] Kyonggi Univ, Dept Convergence Secur, Suwon, South Korea.
C3 Yonsei University; LG Electronics; Namseoul University; Kyonggi
   University
RP Kim, SD (corresponding author), Yonsei Univ, Comp Sci, Seoul 120749, South Korea.
EM yunhiwen@hotmail.com; manito45@naver.com; hulkboy@yonsei.ac.kr;
   cgkim@nsu.ac.kr; harap123@hanmail.net; sdkim@yonsei.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Science, ICT and future Planning
   [NRF-2012R1A1A2043400]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Science, ICT and future Planning (NRF-2012R1A1A2043400).
CR Agrawal M, 2008, LECT NOTES COMPUT SC, V5305, P102, DOI 10.1007/978-3-540-88693-8_8
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Burghouts GJ, 2009, COMPUT VIS IMAGE UND, V113, P48, DOI 10.1016/j.cviu.2008.07.003
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chung-Pyo H, 2013, P INT MULTICONFERENC, V1, P229
   Gomes RB, 2013, COMPUT GRAPH-UK, V37, P496, DOI 10.1016/j.cag.2013.03.005
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Kim D. H., 2013, 2013 Abstracts IEEE International Conference on Plasma Science (ICOPS), DOI 10.1109/PLASMA.2013.6633365
   Kim J.-H., 2013, LECT NOTES ELECT ENG, P367
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Sinha SN, 2011, MACH VISION APPL, V22, P207, DOI 10.1007/s00138-007-0105-z
   van de Sande K.E. A., 2008, CIVR, P141, DOI DOI 10.1145/1386352.1386376
   Wagner D, 2009, INT SYM MIX AUGMENT, P57, DOI 10.1109/ISMAR.2009.5336497
NR 16
TC 2
Z9 2
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2015
VL 74
IS 16
BP 6541
EP 6556
DI 10.1007/s11042-014-2241-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP4PN
UT WOS:000359864700030
DA 2024-07-18
ER

PT J
AU Fatima, I
   Halder, S
   Saleem, MA
   Batool, R
   Fahim, M
   Lee, YK
   Lee, S
AF Fatima, Iram
   Halder, Sajal
   Saleem, Muhammad Aamir
   Batool, Rabia
   Fahim, Muhammad
   Lee, Young-Koo
   Lee, Sungyoung
TI Smart CDSS: integration of Social Media and Interaction Engine (SMIE) in
   healthcare for chronic disease patients
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social media; CDSS; Personalization; Tweet; Trajectory; Email;
   Healthcare
AB Chronic disease may lead to life threatening health complications like heart disease, stroke, and diabetes that diminish the quality of life. CDSS (Clinical Decision Support System) helps physician in effective utilization of patient's clinical information at the time of diagnosis and medication. This paper points out the importance of social media and interaction integration in existing Smart CDSS for chronic diseases. The proposed system monitors health conditions, emotions and interests of patients from patients' tweets, trajectory and email analysis. We extract keywords, concepts and sentiments from patient's tweets data. Trajectory analysis identifies the focused activities after considering imperative location and semantic tags. Email analysis finds interesting patterns and communication trends from daily routine of patient. All these outputs are supplied to Smart CDSS into vMR (virtual Medical Record) format through social media adapter. This helps the health practitioners to understand the behavior and lifestyle of patients for better decision making about treatment. Consequently, patients can get continuous relevant recommendations from Smart CDSS based on their personalized profile. To verify and validate the working of proposed methodology, we have implemented a proof of concept prototype that reflects its complete working with potential outcomes.
C1 [Fatima, Iram; Halder, Sajal; Saleem, Muhammad Aamir; Batool, Rabia; Fahim, Muhammad; Lee, Young-Koo; Lee, Sungyoung] Kyung Hee Univ, Dept Comp Engn, Yongin, Gyeonggi Do, South Korea.
C3 Kyung Hee University
RP Lee, YK (corresponding author), Kyung Hee Univ, Dept Comp Engn, Yongin, Gyeonggi Do, South Korea.
EM iram.fatima@oslab.khu.ac.kr; sajal@khu.ac.kr; aamir@oslab.khu.ac.kr;
   rabia@oslab.khu.ac.kr; fahim@oslab.khu.ac.kr; yklee@khu.ac.kr;
   sylee@oslab.khu.ac.kr
RI Lee, Sungyoung/HDN-1116-2022; Fahim, Muhammad/T-2029-2017; Lee,
   Sungyoung/AAK-7257-2020; Fatima, Iram/P-1474-2016; Lee,
   Young-Koo/AAK-7941-2020
OI Fahim, Muhammad/0000-0001-6259-5458; Halder, Sajal/0000-0002-0965-6255
FU MSIP (Ministry of Science, ICT&Future Planning), Korea, under the
   ITRC(Information Technology Research Center) [NIPA-2013-(H0301-13-2001)]
FX This research was supported by the MSIP (Ministry of Science, ICT&Future
   Planning), Korea, under the ITRC(Information Technology Research Center)
   support program supervised by the NIPA(National IT Industry Promotion
   Agency) (NIPA-2013-(H0301-13-2001))
CR Abel F., 2011, P 3 INT WEB SCI C WE, DOI [10.1145/2527031.2527040, DOI 10.1145/2527031.2527040]
   Almadhoun N. M., 2011, Proceedings of the 2011 IEEE International Conference on Control System, Computing and Engineering (ICCSCE), P426, DOI 10.1109/ICCSCE.2011.6190564
   Alwan A, 2011, GLOBAL STATUS REPORT ON NONCOMMUNICABLE DISEASES 2010, pVII
   [Anonymous], 2006, P 15 ACM INT C INF K
   [Anonymous], J CONVERG
   Blanke U, 2009, LECT NOTES COMPUT SC, V5561, P192, DOI 10.1007/978-3-642-01721-6_12
   Braga RB, 2011, P 17 INT C DISTR MUL, P130
   Brahami M, 2013, J INF PROCESS SYST, V9, P1, DOI 10.3745/JIPS.2013.9.1.001
   Campbell C., 2003, Proceedings of the 12th In- ternational Conference on Information and Knowledge Management, P528, DOI DOI 10.1145/956863.956965
   Celik I, 2011, LECT NOTES COMPUT SC, V6757, P167, DOI 10.1007/978-3-642-22233-7_12
   Chen JL, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1185
   Fatima I, 2010, P 5 INT C UB INF MAN
   Fox S., HLTH TOPICS
   Han JW, 2007, DATA MIN KNOWL DISC, V15, P55, DOI 10.1007/s10618-006-0059-1
   Huang C, 2006, P AMIA S
   Hung H, 2011, IEEE T AUDIO SPEECH, V19, P847, DOI 10.1109/TASL.2010.2066267
   Hussain Maqbool, 2012, Impact Analysis of Solutions for Chronic Disease Prevention and Management. Proceedings 10th International Conference on Smart Homes and Health Telematics (ICOST 2012), P266, DOI 10.1007/978-3-642-30779-9_41
   Ibrahim N, 2013, HUM-CENTRIC COMPUT I, V3, DOI 10.1186/2192-1962-3-1
   Institute H. R., 2012, SOC MED HEALTHC MARK
   Kang J, 2010, J INF PROCESS SYST, V6, P521, DOI 10.3745/JIPS.2010.6.4.521
   Lahiri M, 2008, IEEE DATA MINING, P373, DOI 10.1109/ICDM.2008.104
   Lahiri M, 2010, KNOWL INF SYST, V24, P467, DOI 10.1007/s10115-009-0253-8
   Le XH, 2010, CONSUM COMM NETWORK, P702
   Lubarski P, 2012, 2012 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P86, DOI 10.1109/ASONAM.2012.24
   Oommen BJ, 2012, J INF PROCESS SYST, V8, P191, DOI 10.3745/JIPS.2012.8.2.191
   Pankaj K, 2012, J CONVERG, V3, P31
   Saif Hassan, 2012, The Semantic Web. 11th International Semantic Web Conference (ISWC 2012). Proceedings, P508, DOI 10.1007/978-3-642-35176-1_32
   Shtykh RY, 2011, HUM-CENTRIC COMPUT I, V1, DOI 10.1186/2192-1962-1-2
   Soumeya A., 2012, J AM MED INFORM ASSN, V8, P351
   Yen N. Y., 2012, J CONVERGENCE, V3, P37
   Yu Chen Zhou, 2010, Proceedings of the 2010 IEEE Congress on Services (SERVICES-1), P1, DOI 10.1109/SERVICES.2010.43
   Yuanyuan YZhang., 2009, Power and Energy Engineering Conference, APPEEC Asia-Pacific, P1, DOI DOI 10.1109/GEOINFORMATICS.2009.5293469
   Zhu Feixiang, 2011, 2011 2nd IEEE International Conference on Emergency Management and Management Sciences (ICEMMS), P772, DOI 10.1109/ICEMMS.2011.6015796
   Zhu YH, 2012, HUM-CENTRIC COMPUT I, V2, DOI 10.1186/2192-1962-2-15
NR 34
TC 13
Z9 13
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 14
BP 5109
EP 5129
DI 10.1007/s11042-013-1668-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XU
UT WOS:000358214900008
DA 2024-07-18
ER

PT J
AU Fu, ZY
   Lu, ZW
   Ip, HHS
   Lu, HT
   Wang, YY
AF Fu, Zhenyong
   Lu, Zhiwu
   Ip, Horace H. S.
   Lu, Hongtao
   Wang, Yunyun
TI Local similarity learning for pairwise constraint propagation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Constrained clustering; Pairwise constraint propagation; Similarity
   learning; Semi-supervised learning
AB Pairwise constraint propagation studies the problem of propagating the scarce pairwise constraints across the entire dataset. Effective propagation algorithms have previously been designed based on the graph-based semi-supervised learning framework. Therefore, these previous constraint propagation methods rely critically on a good similarity measure over the data points. Improper or noisy similarity measurements may dramatically degrade the performance of the constraint propagation algorithms. In this paper, we make attempt to exploit the available pairwise constraints to learn a new set of similarities, which are consistent with the supervisory information in the pairwise constraints, before propagating these initial constraints. Our method is a local learning algorithm. More specifically, we compute the similarities at each data point through simultaneously minimizing the local reconstruction error and local constraint error. The proposed method has been tested in the constrained clustering tasks on eight real-life datasets and then shown to achieve significant improvements with respect to the state of the arts.
C1 [Fu, Zhenyong; Wang, Yunyun] Nanjing Univ Posts & Telecommun, Coll Comp, Nanjing 210003, Jiangsu, Peoples R China.
   [Lu, Zhiwu] Renmin Univ China, Sch Informat, Dept Comp Sci, Beijing, Peoples R China.
   [Ip, Horace H. S.] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
   [Lu, Hongtao] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200030, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Renmin University of
   China; City University of Hong Kong; Shanghai Jiao Tong University
RP Fu, ZY (corresponding author), Nanjing Univ Posts & Telecommun, Coll Comp, Nanjing 210003, Jiangsu, Peoples R China.
EM fuzy@njupt.edu.cn; luzhiwu@ruc.edu.cn; cship@cityu.edu.hk;
   htlu@sjtu.edu.cn; wangyunyun@njupt.edu.cn
OI Lu, Zhiwu/0000-0001-6429-7956; IP, Ho Shing Horace/0000-0002-1509-9002;
   Lu, Zhiwu/0000-0003-0280-7724
FU National Science Foundation of China [61272247, 61202231, 61300164,
   61300165]; Shanghai Science and Technology Committee [13511500200];
   Beijing Natural Science Foundation of China [4132037]; Ph.D. Programs
   Foundation of Ministry of Education of China [20120001120130]
FX We would like to thank the anonymous reviewers for their insightful
   suggestions. The work described in this paper is supported by National
   Science Foundation of China (No. 61272247, 61202231, 61300164,
   61300165), Shanghai Science and Technology Committee (No. 13511500200),
   Beijing Natural Science Foundation of China (No. 4132037) and Ph.D.
   Programs Foundation of Ministry of Education of China (No.
   20120001120130).
CR [Anonymous], 2004, NIPS
   [Anonymous], CVPR
   [Anonymous], 2010, ICDM
   [Anonymous], 2003, NIPS
   Basu S, 2004, SIGKDD
   Basu S, 2009, CH CRC DATA MIN KNOW, P1
   Boyd S., 2004, CONVEX OPTIMIZATION
   Chung F. R. K., 1997, Spectral graph theory
   Fu Zhenyong, 2011, AAAI
   HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075
   Kamvar S.D., 2003, IJCAI
   Kulis B., 2005, ICML
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li Z., 2008, ICML
   Li Z., 2009, ICCV
   Lu Z., 2010, ECCV
   Lu Z., 2008, CVPR
   Lu ZW, 2011, IEEE T SYST MAN CY B, V41, P976, DOI 10.1109/TSMCB.2010.2102749
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   WAGSTAFF K, 2000, ICML
   Wang F, 2008, IEEE T KNOWL DATA EN, V20, P55, DOI 10.1109/TKDE.2007.190672
   Wang X., 2010, SIGKDD
   Zhu X, 2009, Synthesis Lectures on Artificial Intelligence and Machine Learning, V3, P1, DOI 10.1007/978-3-031-01548-9
NR 25
TC 6
Z9 8
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 11
BP 3739
EP 3758
DI 10.1007/s11042-013-1796-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI6UQ
UT WOS:000354898800007
OA hybrid
DA 2024-07-18
ER

PT J
AU Zarraonandia, T
   Diaz, P
   Aedo, I
   Ruiz, MR
AF Zarraonandia, Telmo
   Diaz, Paloma
   Aedo, Ignacio
   Ruiz, Mario Rafael
TI Designing educational games through a conceptual model based on rules
   and scenarios
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Educational game; Game based learning; Game design; Modelling; Game
   design entities
AB The design of a successful educational game (EG) is a challenging task that requires a lot of knowledge and a variety of skills. EG designers not only have to deal with the inherent technical complexity of game design, but also have to be able to interweave learning activities in a way that is enjoyable and educationally effective at the same time. In order to make available the benefits of game based learning to a wider audience, it is necessary to provide means to alleviate the cost of envisioning new EG by providing tools that might contribute to make the design process easier and quicker. As a first step towards this goal, in this paper we introduce a conceptual model that organizes in a modular way and in different design perspectives the game features. In order to help EG designers, the features that are most often regarded in the literature as significant in producing engaging, fun and educational game experiences, have been included in the model through a set of design entities. Furthermore, the organization of the elements of the model facilitates reusing pieces of the EG designs to quickly produce variants of the same game which can be used to match different learning purposes. The opinions gathered from the educators and game designers that participated of an EG design workshop confirmed that the model can help multidisciplinary EG design teams. Moreover, the model successfully contributed to the process of designing a collection of EGs aimed at raising children Is awareness of emergencies and domestic risks, whose educational and ludic value was assessed in an experience conducted with students and educators at a primary school in Madrid.
C1 [Zarraonandia, Telmo; Diaz, Paloma; Aedo, Ignacio; Ruiz, Mario Rafael] Univ Carlos III Madrid, Dept Comp Sci, Madrid, Spain.
C3 Universidad Carlos III de Madrid
RP Zarraonandia, T (corresponding author), Univ Carlos III Madrid, Dept Comp Sci, Madrid, Spain.
EM tzarraon@inf.uc3m.es; pdp@inf.uc3m.es; aedo@inf.uc3m.es;
   mrrvarga@inf.uc3m.es
RI Diaz, Paloma/E-8606-2016; Ruiz Vargas, Mario Rafael/P-3024-2015; Aedo,
   Ignacio/F-3222-2014; Zarraonandia, Telmo/K-7177-2012
OI DIAZ PEREZ, MARIA PALOMA/0000-0002-9493-7739; Ruiz Vargas, Mario
   Rafael/0000-0003-3156-782X; Aedo, Ignacio/0000-0001-5819-0511;
   Zarraonandia, Telmo/0000-0003-3574-0984
FU Spanish Ministry of Science and Innovation [TIN2009-09687]
FX This work is supported by the project urThey funded by the Spanish
   Ministry of Science and Innovation (TIN2009-09687).
CR Amory A., 2003, South African Journal of Higher Education, V17, P206
   Ampatzoglou A, 2007, INFORM SOFTWARE TECH, V49, P445, DOI 10.1016/j.infsof.2006.07.003
   [Anonymous], 1981, 6 EUR C GAM BAS LEAR
   [Anonymous], 2000, BOREDOM ANXIETY
   [Anonymous], 2001, DIGITAL GAME BASED L
   [Anonymous], 2002, Heuristics and usability guidelines for the creation and evaluation of fun in video games
   Brown J., 1989, Educational Researcher, V18, P32, DOI [DOI 10.3102/0013189X018001032, 10.3102/0013189X018001032, DOI 10.2307/1176008]
   Campbell DT., 1963, EXPT QUASIEXPERIMENT
   Crookall D, 1995, GUIDE LIT SIMULATION, P151
   Desurvire H., 2004, EXTENDED ABSTRACTS 2, P1509, DOI [DOI 10.1145/985921.986102, 10.1145/985921.986102]
   Druckman D, 1995, ED EFFECTIVENESS INT, P178
   Fabricatore C, 2000, INT C ASS ED COMM TE
   Garris R., 2002, Simulation & Gaming, V33, P441, DOI 10.1177/1046878102238607
   Hevner AR, 2004, MIS QUART, V28, P75, DOI 10.2307/25148625
   Hunicke R., 2004, P AAAI WORKSH CHALL, P4
   Irwin LG, 2005, QUAL HEALTH RES, V15, P821, DOI 10.1177/1049732304273862
   Katsionis G, 2008, MULTIMED TOOLS APPL, V39, P47, DOI 10.1007/s11042-007-0155-2
   Kiili K., 2005, Internet and Higher Education, V8, P13, DOI 10.1016/j.iheduc.2004.12.001
   LEDERMAN LC, 1992, SIMULAT GAMING, V23, P145, DOI 10.1177/1046878192232003
   Leemkuil H., 2006, Is it all in the game? Learner support in an educational knowledge management simulation game
   Mehm F, 6 EUR C GAM BAS LEAR, V323
   Peters V. A. M., 2004, Simulation & Gaming, V35, P70, DOI 10.1177/1046878103253719
   Prensky M., 2005, Handbook of Computer Game Studies
   Read J. C., 2002, Interaction design and children, V2, P1
   Rollings A., 2004, Game Architecture and Design
   Shen C., 2009, SERIOUS GAMES, P48
   Sweetser P., 2005, ACM COMPUTERS ENTERT, V3
   Torrente J, 2008, P 2008 INT C ADV COM, P191
   Virvou M, 2005, EDUC TECHNOL SOC, V8, P54
   Yin R.K., 2009, CASE STUDIES DESIGN, V4th
NR 30
TC 26
Z9 28
U1 2
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 13
BP 4535
EP 4559
DI 10.1007/s11042-013-1821-1
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA CL7DG
UT WOS:000357130400004
DA 2024-07-18
ER

PT J
AU Arafsha, F
   Alam, KM
   El Saddik, A
AF Arafsha, Faisal
   Alam, Kazi Masudul
   El Saddik, Abdulmotaleb
TI Design and development of a user centric affective haptic jacket
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wearable haptic jacket; Basic emotion; Vibrotactile actuators; Heat
   actuators; Multimedia feedback
ID EMOTIONS
AB Affective haptic research is a rapidly growing field. This article intends to improve the existing literature and contribute by involving consumers directly in the design of a smart haptic jacket by adding heat, vibration actuators, and by enhancing portability. The proposed system is designed for six basic emotions: love, joy, surprise, anger, sadness, and fear. Also, it can support several interacts such as a hug, poke, tickle or touch. An online survey was designed, based on literature, and conducted on 92 respondents, who gave their opinion about the physiological impact of emotions and interactions on the human body. The results of this survey assisted in the general design and implementation of the system. 86 % of the volunteers who participated in the final experiment expressed their interest in the system and said that the quality of their multimedia experience was improved through use of the jacket. Detailed design architecture is provided, along with the details of the hardware and software used for the implementation.
C1 [Arafsha, Faisal; Alam, Kazi Masudul; El Saddik, Abdulmotaleb] Univ Ottawa, Sch Elect Engn & Comp Sci, Multimedia Communicat Res Lab MCRLab, Ottawa, ON, Canada.
C3 University of Ottawa
RP El Saddik, A (corresponding author), Univ Ottawa, Sch Elect Engn & Comp Sci, Multimedia Communicat Res Lab MCRLab, Ottawa, ON, Canada.
EM faraf069@uottawa.ca; mkazi078@uottawa.ca; elsaddik@site.uottawa.ca
RI ; /D-4159-2009
OI ALAM, KAZI MASUDUL/0000-0003-4731-9847; /0000-0002-7690-8547
CR Abdur Rahman M, 2010, MM 10 P INT C MULT A
   Alam K. M., 2011, P VIRT REAL INT C VI
   [Anonymous], 2001, EMOTIONS SOCIAL PSYC
   Berkow R., 1997, The Merck Manual of Medical Information, Home Edition, P79
   Carlson M, 1998, HARVARD MAHONEY NEUR, V7, P12
   Cha J., 2009, MM '09: Proceedings of the seventeen ACM international conference on Multimedia, P1135, DOI [10.1145/1631272.1631535, DOI 10.1145/1631272.1631535]
   El Saddik A., 2011, Haptics Technologies:Bringing Touch to Multimedia
   El Saddik A, 2007, IEEE INSTRU MEAS MAG, V10, P10, DOI 10.1109/MIM.2007.339540
   Field T, 2002, HUM DEV, V45, P100, DOI 10.1159/000048156
   Hossain S. K. A., 2010, IEEE INT S HAPT AUD
   Izard C.E., 1977, Human emotions, P120
   Jones W., 2011, IEEE SPECTRUM
   Lemmens P, 2009, WORLD HAPTICS 2009: THIRD JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P7, DOI 10.1109/WHC.2009.4810832
   ORTONY A, 1990, PSYCHOL REV, V97, P315, DOI 10.1037/0033-295X.97.3.315
   Plutchik R., 1980, EMOTION THEORY RES E, V1, P3, DOI DOI 10.1016/B978-0-12-558701-3.50007-7
   Rajae-Joordens RJE, 2008, PHILIPS RES BOOK SER, V8, P77, DOI 10.1007/978-1-4020-6593-4_7
   Teh J.K. S., 2009, Proceedings of the 8th International Conference on Interaction Design and Children - IDC'09. the 8th International Conference, P290, DOI DOI 10.1145/1551788.1551861
   Teh J. K. S., 2008, P 7 INT C INT DES CH, P250, DOI DOI 10.1145/1463689.1463763
   Tomkins S.S., 1984, APPROACHES EMOTION, P163
   Tsetserukou D, 2009, 3 INT C AFF COMP INT, P1
   Tsetserukou D, 2010, IEEE COMPUT GRAPH, V30, P72, DOI 10.1109/MCG.2010.88
   Viswanathan LN, 2010, 2010 IE INT S HAPT A, P1
   Wu W, 2009, P 17 ACM INT C MULT
   Yun T, 2009, IEEE INT WORKSH MULT
NR 24
TC 15
Z9 17
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 9
BP 3035
EP 3052
DI 10.1007/s11042-013-1767-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CF7NI
UT WOS:000352742800009
DA 2024-07-18
ER

PT J
AU Kim, JW
AF Kim, Jun Woo
TI Developing a job shop scheduling system through integration of graphic
   user interface and genetic algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Job shop scheduling problem; Precedence constrained sequencing problem;
   Candidate order based genetic algorithm; Graphic user interface;
   Scheduling system
ID COMPLEXITY
AB Job shop scheduling problem is one of the well known hardest combinatorial optimization problems that has a wide range of industrial application domains. Due to the NP-hardness of job shop scheduling problem, meta heuristic search methods such as genetic algorithm have been widely applied to find the good schedules, however, solving the precedence constrained sequencing problems such as JSP is still challenging for genetic algorithms. Moreover, the genetic algorithms for the precedence constrained sequencing problems have been often problem dependent or constraint specific, and the user experiences are not considered in developing them. To address these issues, this paper aims to develop a graphic user interface based job shop scheduling system that searches the good schedules by using the candidate order based genetic algorithm. The candidate order based genetic algorithm enable our scheduling system to handle a wide range of precedence constrained sequencing problems conveniently, and the users can construct various sequencing problems via simple graphic user interfaces. For illustration, our system is applied to classical JSP and its variant, and the experiment results reveal the promising applicability of the system.
C1 Dong A Univ, Dept Ind & Management Syst Engn, Busan 604714, South Korea.
C3 Dong A University
RP Kim, JW (corresponding author), Dong A Univ, Dept Ind & Management Syst Engn, 840,Hadan 2 Dong, Busan 604714, South Korea.
EM kjunwoo@dau.ac.kr
RI Kim, Junwoo/AAF-7561-2020
FU Dong-A University
FX This work was supported by the Dong-A University research fund.
CR Abdelmaguid T.F., 2010, Journal of Software Engineering and Applications, V3, P1155, DOI DOI 10.4236/jsea.2010.312135
   Ahmed Z.H., 2010, Int. J. Biometrics Bioinform., V3, P96
   Altiparmak F, 2009, COMPUT IND ENG, V56, P521, DOI 10.1016/j.cie.2007.05.012
   [Anonymous], 1963, Industrial scheduling
   [Anonymous], 1992, The Design and Analysis of Algorithms
   BIERWIRTH C, 1995, OR SPEKTRUM, V17, P87, DOI 10.1007/BF01719250
   BRUCKER P, 1990, COMPUTING, V45, P369, DOI 10.1007/BF02238804
   Cheng RW, 1996, COMPUT IND ENG, V30, P983, DOI 10.1016/0360-8352(96)00047-2
   FANG HL, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P375
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   Kammer M, 2011, COMPUT OPER RES, V38, P1556, DOI 10.1016/j.cor.2011.01.014
   Kim J.K.P., 2013, INT C INT FUS, P12
   Kim JW, 2012, J FUTUR GAME TECHNOL, V2, P165
   Kowalczyk R, 1997, PROCEEDINGS OF 1997 IEEE INTERNATIONAL CONFERENCE ON EVOLUTIONARY COMPUTATION (ICEC '97), P343, DOI 10.1109/ICEC.1997.592333
   LENSTRA JK, 1978, OPER RES, V26, P22, DOI 10.1287/opre.26.1.22
   Peng LH, 2006, MATEMATIKA, V22, P91
   Pezzella F, 2008, COMPUT OPER RES, V35, P3202, DOI 10.1016/j.cor.2007.02.014
   POON PW, 1995, COMPUT OPER RES, V22, P135, DOI 10.1016/0305-0548(93)E0024-N
   Ruiz-Vanoye JA, 2011, INT J COMB OPTIM PRO, V2, P25
   Starkweather T., 1991, P C GENETIC ALGORITH, P69
   Werner F, 2011, GENETIC ALGORITHMS S
   YAMADA T, 1992, PARALLEL PROBLEM SOLVING FROM NATURE, 2, P281
   Zhang GH, 2011, EXPERT SYST APPL, V38, P3563, DOI 10.1016/j.eswa.2010.08.145
NR 23
TC 6
Z9 6
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 10
BP 3329
EP 3343
DI 10.1007/s11042-014-1965-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI1GY
UT WOS:000354493000006
DA 2024-07-18
ER

PT J
AU Park, JH
   Park, HH
   Kwon, YB
AF Park, Jae-Hwa
   Park, Ho-Hyun
   Kwon, Young-Bin
TI Error correction of reference indexing system including multimedia
   journals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Error correction; Science Citation Index; Impact Factor; Faulty
   Referencing; Reference indexing
ID CITATION; RETRIEVAL
AB The Impact Factor evaluated of ISI is exploited as a standard to evaluate the level of academic journals including multimedia journals. However, the service for the impact factors is mainly designed for English-based journals only. A reference index system and database, 'Science Citation Index Processing System: SCIPS' has been developed for reference indexing and to evaluate the impact factors and immediacy indices. And the developed system is applied for Korean domestic journals. It can be easily ported to other domestic journals in other languages. The proposed system has two major steps of indexing and computation. For the indexing process, an error correction system for references of papers is implemented. The typos of reference listing are analysed and the major types are categorized. Then the correction lookup table and indices have been built to calculate more accurate impact factors. In the computation step, the actual impact factors and immediacy indices for the journals listed in the database are calculated. For the overall process, journal databases and indexing system for the journal contents have been built. In the experiments, the data obtained from the actually published papers from 2009 to 2011 of Journals are used and impact factor and immediacy index of 2011 are calculated. The experimental results show the validity of presented system. From the tables of 2011 of high cited rankings, the well known society or famous conferences are cited highly. Also, some international standard documents are highly cited in communication area. Writing errors of approximately 10 % in references degrades the evaluation accuracy of citation index and immediacy index. The error cases such as author error, abbreviation only, and unknown types are classified and analyzes to enhance the accuracy of the metrics.
C1 [Park, Jae-Hwa; Kwon, Young-Bin] Chung Ang Univ, Dept Comp Sci & Engn, Seoul 156756, South Korea.
   [Park, Ho-Hyun] Chung Ang Univ, Dept Elect & Elect Engn, Seoul 156756, South Korea.
C3 Chung Ang University; Chung Ang University
RP Kwon, YB (corresponding author), Chung Ang Univ, Dept Comp Sci & Engn, Seoul 156756, South Korea.
EM jaehwa@cau.ac.kr; hohyun@cau.ac.kr; ybkwon@cau.ac.kr
FU NRF, Electronic and Information Research Information Center program
FX This work is supported by NRF, Electronic and Information Research
   Information Center program, 2013.
CR Aigrain P, 1996, MULTIMED TOOLS APPL, V3, P179, DOI 10.1007/BF00393937
   An Y, 2004, KNOWL INF SYST, V6, P664, DOI 10.1007/s10115-003-0128-3
   Ardizzone E, 1997, MULTIMED TOOLS APPL, V4, P29, DOI 10.1023/A:1009630331620
   Beel J, 2009, INT C INF TECHN NEW, P60
   Beel J, 2009, INT CONF RES CHAL, P439, DOI 10.1109/RCIS.2009.5089308
   Bernstein PA, 2005, SIGMOD REC, V34, P61, DOI 10.1145/1107499.1107507
   Cha GH, 1998, MULTIMED TOOLS APPL, V6, P263, DOI 10.1023/A:1009608331551
   고성순, 2005, [Journal of Korean Library and Information Science Society, 한국도서관Â·정보학회지], V36, P441
   Gloor PA, 1998, MULTIMED TOOLS APPL, V6, P171, DOI 10.1023/A:1009617001852
   Gong YH, 1996, MULTIMED TOOLS APPL, V2, P133, DOI 10.1007/BF00672252
   Jacso P, 2005, CURR SCI, V89
   Korea Research Foundation, 2010, EV AC J INTR KCI SYS
   Ley M., 2002, String Processing and Information Retrieval. 9th International Symposium, SPIRE 2002. Proceedings (Lecture Notes in Computer Science Vol.2476), P1
   LEYDESDORFF L, 1994, SCIENTOMETRICS, V31, P59, DOI 10.1007/BF02018102
   Park HW, 2008, SCIENTOMETRICS, V75, P439, DOI 10.1007/s11192-007-1862-1
   Petricek V, 2005, LECT NOTES COMPUT SC, V3652, P438, DOI 10.1007/11551362_39
   Phanendra Babu G., 1995, Multimedia Tools and Applications, V1, P327, DOI 10.1007/BF01215882
   Rahm E, 2005, ACM SIGMOD REC, V34
   ROSENFELD A, 1989, COMPUT VISION GRAPH, V46, P196, DOI 10.1016/0734-189X(89)90169-2
   Sidiropoulos A, 2005, INT J INF PROCESS MA, V41
   Sidiropoulos A, 2005, ACM SIGMOD REC, V34
   Snoek CGM, 2005, MULTIMED TOOLS APPL, V25, P5, DOI 10.1023/B:MTAP.0000046380.27575.a5
NR 22
TC 2
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 7
BP 2359
EP 2370
DI 10.1007/s11042-014-1971-9
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE0TU
UT WOS:000351520200011
DA 2024-07-18
ER

PT J
AU Yoo, J
AF Yoo, Joon
TI Receiver-centric physical carrier sensing for vehicular Ad Hoc networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vehicular ad hoc networks; Physical carrier sense; Receiver centric;
   Medium access control
AB The sender-centric medium access has been widely deployed to avoid interference in vehicular ad hoc networks, even though sender-centric physical carrier sensing suffers from exposed terminal problems and sender-centric virtual carrier sensing is relatively vulnerable to interference. In this paper, we propose a new receiver-centric MAC protocol, called RIMAC, to increase spatial reuse and network capacity. In RIMAC, the receivers accurately assess their channel status opposed to the sender initiated approach where senders can only heuristically infer that of their receivers. Therefore, the receiver-centric approach achieves a better level of spatial reuse with the same degree of interference prevention. Through both extensive numerical analysis and simulation studies, we find that the proposed receiver-centric MAC achieves up to 68 % higher network capacity than traditional sender-initiated approaches.
C1 Gachon Univ, Dept Software Design & Management, Songnam 461701, South Korea.
C3 Gachon University
RP Yoo, J (corresponding author), Gachon Univ, Dept Software Design & Management, 1342 Seongnamdaero, Songnam 461701, South Korea.
EM joon.yoo@gachon.ac.kr
FU Gachon University [GCU-2013-R285]
FX This work was supported by the Gachon University research fund of 2013
   (GCU-2013-R285).
CR [Anonymous], IEEE
   [Anonymous], 2002, WIRELESS COMMUNICATI
   BHARGHAVAN V, 1994, ACM SIGCOMM 94 LOND
   Daeinabi A, 2013, MULTIMED TOOLS APPL, V66, P325, DOI 10.1007/s11042-011-0789-y
   HEKMAT R, 2002, MED HOC NET SARD IT
   Jamieson K, 2005, ACM E WIND WORKSH 05
   Kim D, 2012, SPRINGER MULTIMEDIA, DOI [10.1007/s11042-012-1113-1, DOI 10.1007/S11042-012-1113-1]
   *MATHWORKS INC, 2000, MATLAB US GUID VERS
   Mittag J, 2013, HIGH PERFORMANCE COMPUTING IN SCIENCE AND ENGINEERING '12: TRANSACTIONS OF THE HIGH PERFORMANCE COMPUTING CENTER, STUTTGART (HLRS) 2012, P561, DOI 10.1007/978-3-642-33374-3_40
   Palazzi CE, 2009, MULTIMED TOOLS APPL, V44, P229, DOI 10.1007/s11042-009-0292-x
   Stanica R, 2011, IEEE MOB ADH SENS SY
   Stanica R, 2012, IEEE SENS MESH AD HO
   TOBAGI FA, 1975, IEEE T COMMUN, V23, P1417, DOI 10.1109/TCOM.1975.1092767
   Wu HT, 2013, MULTIMED TOOLS APPL, V66, P215, DOI 10.1007/s11042-011-0792-3
   Xu K, 2002, IEEE GLOB 02 TAIP TA
   Yang X, 2005, IEEE INF 05 MIAM
   Zhai H, 2006, IEEE INF 06 BARC SPA
   Zhu J, 2004, IEEE ICC 04 PAR FRAN
   Zorzi M, 2003, IEEE T MOBILE COMPUT, V2, P349, DOI 10.1109/TMC.2003.1255650
NR 19
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 7
BP 2405
EP 2415
DI 10.1007/s11042-014-1851-3
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE0TU
UT WOS:000351520200014
DA 2024-07-18
ER

PT J
AU Xie, CH
   Liu, YJ
   Chang, JY
AF Xie, Cong-Hua
   Liu, Yong-Jun
   Chang, Jin-Yi
TI Medical image segmentation using rough set and local polynomial
   regression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image segmentation; Rough set; Local polynomial regression;
   Thresholding segmentation
ID FUZZY; REGION; ENTROPY
AB Rough-set based multimodal histogram thresholding technique is effective for medical image segmentation. However, it is difficult to obtain the significant peaks and valleys of the roughness measure. Moreover, it is sensitive to the noise for medical image. In this paper, we proposed a new medical image segmentation method using rough set theory and local polynomial regression model to address those disadvantages. Firstly, compute histogram of image intensity information and histon of image intensity and spatial information. Secondly, use the local polynomial regression model to smooth the histogram and histon. The smoothed histogram correlates with lower approximation and the smoothed histon correlates with upper approximation. Lastly, rough measure is calculated with the lower and upper approximations. And then, multimodal thresholding method is applied to medical image segmentation. The local polynomial regression model can obtain a smooth rough measure and has two advantages: first, it is easy to find the real peaks and valleys of the smoothed roughness measure to segment medical image; second, the local polynomial regression reduces the effect of noise and can find the thresholds correctly. The proposed approach is compared with the histogram based approach, histon based approach, and rough set with the histogram and histon based approach. Experimental results demonstrate that our approach can find the real peaks and valleys more easily and yields better segmentation results than those of other three methods.
C1 [Xie, Cong-Hua; Liu, Yong-Jun; Chang, Jin-Yi] Changshu Inst Technol, Sch Comp Sci & Engn, Suzhou 215500, Jiangsu, Peoples R China.
C3 Changshu Institute of Technology
RP Xie, CH (corresponding author), Changshu Inst Technol, Sch Comp Sci & Engn, Room 405,99 HusanLu, Suzhou 215500, Jiangsu, Peoples R China.
EM xiech@aliyun.com
FU Natural Science Foundation of Jiangsu Province in China [BK2012209,
   BK20130529]
FX The authors would like to express their sincere thanks to the editor and
   all reviewers who made great contributions to the improvement of the
   final paper. This work is supported by the Natural Science Foundation of
   Jiangsu Province in China (No. BK2012209 and No. BK20130529).
CR Aubert-Broche B, 2006, IEEE T MED IMAGING, V25, P1410, DOI 10.1109/TMI.2006.883453
   Beaubouef T., 2001, Engineering of Intelligent Systems. 14th International Conference on Industrial and Engineering Applications of Artificial Intelligence and Expert Systems, IEA/AIE 2001. Proceedings (Lecture Notes in Artificial Intelligence Vol.2070), P367
   Bonnet N, 2002, PATTERN RECOGN, V35, P2319, DOI 10.1016/S0031-3203(02)00057-2
   Bowman W, 1997, OXFORD STAT SCI SERI
   Bricq S, 2008, MED IMAGE ANAL, V12, P639, DOI 10.1016/j.media.2008.03.001
   BRINK AD, 1995, IEE P-VIS IMAGE SIGN, V142, P128, DOI 10.1049/ip-vis:19951850
   Cai WL, 2007, PATTERN RECOGN, V40, P825, DOI 10.1016/j.patcog.2006.07.011
   Cheng HD, 2002, PATTERN RECOGN, V35, P373, DOI 10.1016/S0031-3203(01)00054-1
   Clive L, 1999, LOCAL REGRESSION LIK
   da Silva ARF, 2007, MED IMAGE ANAL, V11, P169, DOI 10.1016/j.media.2006.12.002
   Ghanizadeh A, 2011, APPL OPTICS, V50, P3191, DOI 10.1364/AO.50.003191
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hassanien A, 2007, IMAGE VISION COMPUT, V25, P172, DOI 10.1016/j.imavis.2006.01.026
   Hirano S, 2005, INT J APPROX REASON, V40, P23, DOI 10.1016/j.ijar.2004.11.008
   Jiafu Jiang, 2008, 5th International Conference on Visual Information Engineering, VIE 2008, P361, DOI 10.1049/cp:20080339
   Karoui I, 2010, IEEE T IMAGE PROCESS, V19, P3146, DOI 10.1109/TIP.2010.2071290
   MAJI P, 2006, IET INT C VIS INF EN, P327
   Maji P, 2007, IEEE T SYST MAN CY B, V37, P1529, DOI 10.1109/TSMCB.2007.906578
   Mohabey A, 2000, IEEE SYS MAN CYBERN, P1529, DOI 10.1109/ICSMC.2000.886073
   Mohabey A, 2000, PEACHFUZZ 2000 : 19TH INTERNATIONAL CONFERENCE OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY - NAFIPS, P338, DOI 10.1109/NAFIPS.2000.877448
   Mushrif MM, 2008, PATTERN RECOGN LETT, V29, P483, DOI 10.1016/j.patrec.2007.10.026
   PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956
   RIDLER TW, 1978, IEEE T SYST MAN CYB, V8, P630, DOI 10.1109/tsmc.1978.4310039
   Sen D, 2006, ANNU IEEE IND CONF, P334
   Sen D, 2009, IEEE T IMAGE PROCESS, V18, P879, DOI 10.1109/TIP.2009.2012890
   Sen D, 2009, IEEE T SYST MAN CY B, V39, P117, DOI 10.1109/TSMCB.2008.2005527
   Shan ZY, 2002, NEUROIMAGE, V17, P1587, DOI 10.1006/nimg.2002.1287
   Sinha D, 2004, ENG APPL ARTIF INTEL, V17, P97, DOI 10.1016/j.engappai.2003.11.002
   Souplet J.C., 2008, PROCMICCAI GRAND CHA, P1
   Tan KS, 2011, PATTERN RECOGN, V44, P1, DOI 10.1016/j.patcog.2010.07.013
   Tobias OJ, 2002, IEEE T IMAGE PROCESS, V11, P1457, DOI 10.1109/TIP.2002.806231
   Wendy L.Martinez Angel R. Martinez., 2002, COMPUTATIONAL STAT H
   Wojcik ZM, 1996, FUZZ-IEEE '96 - PROCEEDINGS OF THE FIFTH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3, P761, DOI 10.1109/FUZZY.1996.552276
   WOJCIK ZM, 1994, IEEE IMAGE PROC, P525, DOI 10.1109/ICIP.1994.413626
   Zhaocong Wu, 2001, 2001 International Conferences on Info-Tech and Info-Net. Proceedings (Cat. No.01EX479), P279, DOI 10.1109/ICII.2001.982759
   ZIJDENBOS AP, 1994, IEEE T MED IMAGING, V13, P716, DOI 10.1109/42.363096
NR 36
TC 16
Z9 16
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 6
BP 1885
EP 1914
DI 10.1007/s11042-013-1723-2
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CD9CN
UT WOS:000351394500009
DA 2024-07-18
ER

PT J
AU Yang, X
   Xu, DQ
   Zhao, L
   Yang, B
AF Yang, Xin
   Xu, Duan-qing
   Zhao, Lei
   Yang, Bing
TI Complex shading efficiently for ray tracing on GPU
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shading; GPU; Ray tracing
AB Complex shading often associates with long shaders and huge data access. To obtain good performance on current generation GPU hardware, it is necessary to design some algorithms to manage data, schedule more efficient threads, and memory access under the hierarchy of GPU memory. In this paper, we propose an approach to accelerate the rendering process for complex shaders by analyzing and sorting shading jobs according to their complexity and potential memory access. We show that by sorting these shading jobs in three levels of memory hierarchies and reorganizing threads block according to the complexity, all shading jobs are scheduled in order, and we can significantly improve cache utilization and GPU hardware utilization, especially for poor performance caused by large branching. All sorting work are processed on CPU with plentiful logic function, and can be processed in a very efficient manner, compared with the expensive compaction operation on GPU. Our experiments with this hierarchy demonstrate improvements against a SIMD packet tracing with compaction on GPU.
C1 [Yang, Xin] Dalian Univ Technol, Coll Comp Sci, Dalian, Peoples R China.
   [Xu, Duan-qing; Zhao, Lei] Zhejiang Univ, Coll Comp Sci, Hangzhou 310003, Zhejiang, Peoples R China.
   [Yang, Bing] Hangzhou Dianzi Univ, Sch Comp Sci, Hangzhou, Zhejiang, Peoples R China.
C3 Dalian University of Technology; Zhejiang University; Hangzhou Dianzi
   University
RP Yang, X (corresponding author), Dalian Univ Technol, Coll Comp Sci, Dalian, Peoples R China.
EM xinyang@zju.edu.cn; xdq@zju.edu.cn; zjuzhaolei@gmail.com; yb@hdu.edu.cn
FU National Natural Science Foundation of China [61300084]; China
   Postdoctoral Science Foundation [2012M520625]; Scientific Research
   Foundation of Dalian University of Technology [DUT12RC(3)63]; Nvidia
   corporation; Microsoft corporation
FX The authors would like to thank the anonymous reviewers for the careful
   reading of the original manuscript. Their comments and suggestions have
   led to a much better presentation of the paper. This research is
   supported in part by the National Natural Science Foundation of China
   under Grant Nos. 61300084, in part by Grant of China Postdoctoral
   Science Foundation under Grant No. 2012M520625, and Scientific Research
   Foundation of Dalian University of Technology under Grant DUT12RC(3)63.
   The authors also appreciate the support of the Nvidia and Microsoft
   corporations.
CR AMD, 2008, ATI STREAM COMP
   [Anonymous], 2009, P C HIGH PERF GRAPH
   Bennett K, 2009, NVIDIAS FERMI ARCHIT
   Bocchino Robert L., 2010, P HIGH PERF GRAPH, P77
   Dammertz H, 2008, COMPUT GRAPH FORUM, V27, P1225, DOI 10.1111/j.1467-8659.2008.01261.x
   Deering M., 1988, Computer Graphics, V22, P21, DOI 10.1145/378456.378468
   Lindholm E, 2008, IEEE MICRO, V28, P39, DOI 10.1109/MM.2008.31
   Månsson E, 2007, RT07: IEEE/EG SYMPOSIUM ON INTERACTIVE RAY TRACING 2007, P79, DOI 10.1109/RT.2007.4342594
   Morley RK, 2006, PROC GRAPH INTERF, P179
   Overbeck R, 2008, RT08: IEEE/EG SYMPOSIUM ON INTERACTIVE RAY TRACING 2008, PROCEEDINGS, P41, DOI 10.1109/RT.2008.4634619
   Pharr M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P101, DOI 10.1145/258734.258791
   Reshetov A, 2007, ACM SIGGRAPH 2007 PO, P171
   Reshetov A, 2006, RT 06: IEEE Symposium on Interactive Ray Tracing 2006, Proceedings, P57
   Sengupta S, 2007, GRAPHICS HARDWARE 2007: ACM SIGGRAPH / EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P97
   Shih M, 2009, LECT NOTES COMPUT SC, V5574, P327, DOI 10.1007/978-3-642-03095-6_32
   Wald I, 2001, COMPUT GRAPH FORUM, V20, pC153, DOI 10.1111/1467-8659.00508
   Wald I, 2007, UUSCI2007012
   Wald I, 2008, RT08: IEEE/EG SYMPOSIUM ON INTERACTIVE RAY TRACING 2008, PROCEEDINGS, P49, DOI 10.1109/RT.2008.4634620
   Wald I, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1186644.1186650
   Wong H, 2010, INT SYM PERFORM ANAL, P235
   Zlatuska M, 2010, WSCG 2010: COMMUNICATION PAPERS PROCEEDINGS, P69
NR 21
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 3
BP 1091
EP 1106
DI 10.1007/s11042-013-1712-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZO
UT WOS:000349356400020
DA 2024-07-18
ER

PT J
AU Lee, SH
   Hwang, WJ
   Kwon, KR
AF Lee, Suk-Hwan
   Hwang, Won-Joo
   Kwon, Ki-Ryong
TI Polyline curvatures based robust vector data hashing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vector data model; Content hashing; Authentication; Copy detection;
   Design drawing; Digital map
AB The growth in applications for vector data such as CAD design drawings and GIS digital maps has increased the requirements for authentication, copy detection, and retrieval of vector data. Vector data hashing is one of the main techniques for meeting these requirements. Its design must be robust, secure, and unique, which is similar to image or video hashing. This paper presents a vector data hashing method based on the polyline curvature for design drawings and digital maps. Our hashing method extracts the feature values by projecting the polyline curvatures, which are obtained from groups of vector data using GMM clustering, onto random values, before generating the final binary hash by binarization. A robustness evaluation showed that our hashingmethod had a very low false detection probability during geometrical modifications, rearrangements, and similar transformations of objects and layers. A security evaluation based on differential entropy showed that the level of uncertainty was very high with our hashing method. Furthermore, a uniqueness evaluation showed that the Hamming distances between hashes were very low.
C1 [Lee, Suk-Hwan] Tongmyong Univ, Dept Informat Secur, Pusan, South Korea.
   [Hwang, Won-Joo] Inje Univ, Dept Informat Commun Engn, Kimhae, Kyungnam, South Korea.
   [Kwon, Ki-Ryong] Pukyong Natl Univ, Dept IT Convergence & Applicat Engn, Pusan, South Korea.
C3 Tongmyong University; Inje University; Pukyong National University
RP Lee, SH (corresponding author), Tongmyong Univ, Dept Informat Secur, 428 Shinseon Ro, Pusan, South Korea.
EM skylee@tu.ac.kr; ichwang@inje.ac.kr; krkwon@pknu.ac.kr
OI Lee, Suk-Hwan/0000-0003-4779-2888
FU Korea Research Foundation Grant - Korean Government (MEST)
   [KRF-2009-0071269, KRF-2011-0023118]
FX This work was supported by the Korea Research Foundation Grant funded by
   the Korean Government (MEST) (KRF-2009-0071269 and KRF-2011-0023118).
CR [Anonymous], 2007, INTELLIGENT MULTIMED
   [Anonymous], 1998, TR97021 INT COMP SCI
   [Anonymous], 2011, DIFFERENTIAL GEOMETR
   Aybet J, 2009, COMM COM INF SC, V45, P18
   Chang K., 2007, Introduction to Geographic Information System, V4th
   Chen Yihua., 2010, ELECTR ENG
   Coskun B, 2006, IEEE T MULTIMEDIA, V8, P1190, DOI 10.1109/TMM.2006.884614
   De Roover C, 2005, IEEE T SIGNAL PROCES, V53, P4020, DOI 10.1109/TSP.2005.855414
   Farin G., 2002, HDB COMPUTER AIDED G
   Kreyszig E., 1991, Differential Geometry. Differential Geometry
   Lee SH, 2013, MULTIMED TOOLS APPL, V63, P757, DOI 10.1007/s11042-011-0894-y
   Lee SH, 2012, DIGIT SIGNAL PROCESS, V22, P744, DOI 10.1016/j.dsp.2012.04.015
   Lee SH, 2010, IEEE INT CON MULTI, P1040, DOI 10.1109/ICME.2010.5583069
   Lee SH, 2010, DIGIT SIGNAL PROCESS, V20, P1379, DOI 10.1016/j.dsp.2010.01.003
   Mao Y, 2007, IEEE T INF FOREN SEC, V2, P462, DOI 10.1109/TIFS.2007.902260
   Monga V, 2007, IEEE T INF FOREN SEC, V2, P376, DOI 10.1109/TIFS.2007.902670
   Monga V, 2006, IEEE T INF FOREN SEC, V1, P68, DOI 10.1109/TIFS.2005.863502
   Ohbuchi R, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P577, DOI 10.1109/ICME.2002.1035847
   Peng F, 2010, COMPUT AIDED DESIGN, V42, P1207, DOI 10.1016/j.cad.2010.08.004
   Shao CY, 2006, IEICE T INF SYST, VE89D, P1290, DOI 10.1093/ietisy/e89-d.3.1290
   Swaminathan A, 2006, IEEE T INF FOREN SEC, V1, P215, DOI 10.1109/TIFS.2006.873601
   Tarmissi K, 2009, EXPERT SYST APPL, V36, P9409, DOI 10.1016/j.eswa.2008.12.062
   Voigt M, 2002, P SOC PHOTO-OPT INS, V4675, P621, DOI 10.1117/12.465322
   Wang CJ, 2012, MULTIMED TOOLS APPL, V57, P67, DOI 10.1007/s11042-010-0536-9
   Wu BY, 2010, GEO-SPAT INF SCI, V13, P40, DOI 10.1007/s11806-010-0196-y
NR 25
TC 7
Z9 9
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1913
EP 1942
DI 10.1007/s11042-013-1661-z
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200037
DA 2024-07-18
ER

PT J
AU Saavedra, JM
   Bustos, B
AF Saavedra, Jose M.
   Bustos, Benjamin
TI Sketch-based image retrieval using keyshapes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sketch-based image retrieval; Content-based image retrieval; Local
   descriptors; Local matching
ID HISTOGRAM; MPEG-7
AB Although sketch based image retrieval (SBIR) is still a young research area, there are many applications capable of exploiting this retrieval paradigm, such as web searching and pattern detection. Moreover, nowadays drawing a simple sketch query turns very simple since touch screen based technology is being expanded. In this work, we propose a novel local approach for SBIR based on detecting simple shapes which are named keyshapes. Our method works as a local strategy, but instead of detecting keypoints, it detects keyshapes over which local descriptors are computed. Our proposal based on keyshapes allow us to represent the structure of the objects in an image which could be used to increase the effectiveness in the retrieval task. Indeed, our results show an improvement in the retrieval effectiveness with respect to the state of the art. Furthermore, we demonstrate that combining our keyshape approach with a Bag of Feature approach allows us to achieve significant improvement with respect to the effectiveness of the retrieval task.
C1 [Saavedra, Jose M.; Bustos, Benjamin] Univ Chile, Dept Comp Sci, PRISMA Res Grp, Santiago, Chile.
   [Saavedra, Jose M.] ORAND SA, Santiago, Chile.
C3 Universidad de Chile
RP Saavedra, JM (corresponding author), Univ Chile, Dept Comp Sci, PRISMA Res Grp, Av Blanco Encalada 2120, Santiago, Chile.
EM jsaavedr@dcc.uchile.cl; bebustos@dcc.uchile.cl
RI ; Bustos, Benjamin/G-1170-2010
OI Saavedra Rondo, Jose Manuel/0000-0002-9644-5164; Bustos,
   Benjamin/0000-0002-3955-361X
FU CONICYT-CHILE [63080026]
FX We thank CONICYT-CHILE for supporting this work through the doctoral
   scholarship number 63080026.
CR [Anonymous], 2011, IEEE T VIS COMPUT GR, DOI DOI 10.1109/TVCG.2010.266
   [Anonymous], SIGGRAPH 2009 TALKS
   [Anonymous], 2009, ACM T GRAPHIC, DOI DOI 10.1145/1618452.1618470
   [Anonymous], P 1 ACM INT C MULT R
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cao Y, 2011, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2011.5995460
   Chalechale A, 2005, IEEE T SYST MAN CY A, V35, P28, DOI 10.1109/TSMCA.2004.838464
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DelBimbo A, 1997, IEEE T PATTERN ANAL, V19, P121, DOI 10.1109/34.574790
   Eitz Mathias., 2009, P 6 EUR S SKETCH BAS, P29
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   GUO ZC, 1989, COMMUN ACM, V32, P359, DOI 10.1145/62065.62074
   Hu R, 2010, IEEE IMAGE PROC, P1025, DOI 10.1109/ICIP.2010.5649331
   Kovesi P.D., 2000, MATLAB and Octave Functions for Computer Vision and Image Processing
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Martínez JM, 2002, IEEE MULTIMEDIA, V9, P83, DOI 10.1109/MMUL.2002.1022862
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Rui Hu, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3661, DOI 10.1109/ICIP.2011.6116513
   Saavedra JM, 2010, LECT NOTES COMPUT SC, V6376, P432
   Stenger B, 2006, IEEE T PATTERN ANAL, V28, P1372, DOI 10.1109/TPAMI.2006.189
   Tuytelaars T., 2008, LOCAL INVARIANT FEAT
   Won CS, 2002, ETRI J, V24, P23, DOI 10.4218/etrij.02.0102.0103
   Wong J. K., 1979, BIT (Nordisk Tidskrift for Informationsbehandling), V19, P418, DOI 10.1007/BF01930994
   XU L, 1990, PATTERN RECOGN LETT, V11, P331, DOI 10.1016/0167-8655(90)90042-Z
   Yao J, 2005, PATTERN ANAL APPL, V8, P149, DOI 10.1007/s10044-005-0252-7
NR 30
TC 28
Z9 31
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 2033
EP 2062
DI 10.1007/s11042-013-1689-0
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200042
DA 2024-07-18
ER

PT J
AU Ejaz, N
   Anwar, J
   Ishtiaq, M
   Baik, SW
AF Ejaz, Naveed
   Anwar, Jamil
   Ishtiaq, M.
   Baik, Sung Wook
TI Adaptive image data hiding using transformation and error replacement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Minimum error LSB replacement; Block based LSB
   watermarking; DCT based watermarking; Invisible watermarking; Genetic
   algorithm
AB Watermarking is popular method for effective copyright protection of digital data. The invisible image watermarking is a type of watermarking which is used to conceal secret information in a cover image. In any watermarking system, there is a trade-off between imperceptibility and payload of the data to be hidden in the cover medium. Therefore, only a limited amount of data can be concealed in the cover image while watermark remain imperceptible. This paper proposes a new method of adaptive blind digital image data hiding in Discrete Cosine Transform (DCT) domain using Minimum Error Lease Significant Bit Replacement (MELSBR) method and Genetic Algorithm (GA). In the proposed method, the secret image is embedded into the DCT transformed cover image. Initially, the host and the secret image both are partitioned into equal sized blocks. Then for each secret image block, host image block is intelligently selected through GA and is embedded using MELSBR method. GA helps in identifying the target cover image blocks such that with the LSB embedding, both visual quality of the cover image and imperceptibility of the secret image remain least affected. In watermark extraction process, the watermarked image is decomposed into equal sized blocks and then using the Jigsaw Puzzle Solver (JPS) the secret image is reconstructed. In spite of doubling the payload of the data to hide, the experimental results have shown better imperceptibility and robustness results of the proposed method as compared to the current approaches in this domain.
C1 [Ejaz, Naveed; Baik, Sung Wook] Sejong Univ, Coll Elect & Informat Engn, Seoul, South Korea.
   [Anwar, Jamil; Ishtiaq, M.] Natl Univ Comp & Emerging Sci, Islamabad, Pakistan.
C3 Sejong University
RP Baik, SW (corresponding author), Sejong Univ, Coll Elect & Informat Engn, Seoul, South Korea.
EM naveed@sju.ac.kr; jamil.anwar@nu.edu.pk; m.ishtiaq@nu.edu.pk;
   sbaik@sejong.ac.kr
RI Ejaz, Naveed/I-2891-2012; Baik, Sung Wook/AAR-8236-2020; Ejaz,
   Naveed/HZJ-6101-2023; Ishtiaq, Muhammad/GSN-4278-2022; anwar,
   Jamil/F-5843-2015; Ejaz, Naveed/HZL-7415-2023
OI Ejaz, Naveed/0000-0003-1295-4787; Ejaz, Naveed/0000-0003-1295-4787;
   Baik, Sung Wook/0000-0002-6678-7788
FU Industrial Strategic Technology Development Program (Development of an
   Adaptive Mixed-Reality Space based on Interactive Architecture) -
   Ministry of Knowledge Economy (MKE, Korea). [10041772]
FX This work was supported by the Industrial Strategic Technology
   Development Program (10041772, the Development of an Adaptive
   Mixed-Reality Space based on Interactive Architecture) funded by the
   Ministry of Knowledge Economy (MKE, Korea).
CR [Anonymous], 1994, Genetic Algorithms + Data Structures = Evolution Programs
   Anwar Muhammad Jamil, 2010, 2010 6th International Conference on Emerging Technologies (ICET), P204, DOI 10.1109/ICET.2010.5638488
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Boland F. M., 1995, Fifth International Conference on Image Processing and its Applications (Conf. Publ. No.410), P326, DOI 10.1049/cp:19950674
   Chan CK, 2004, I C CONT AUTOMAT ROB, P968
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Cox IJ, 1996, WORKSH INF HID
   Ejaz N, 2013, SIGNAL PROCESS-IMAGE, V28, P34, DOI 10.1016/j.image.2012.10.002
   Ejaz N, 2012, MULTIMEDIA SYST, V18, P483, DOI 10.1007/s00530-012-0263-3
   Ejaz N, 2012, J VIS COMMUN IMAGE R, V23, P1031, DOI 10.1016/j.jvcir.2012.06.013
   Findik O., 2009, P 2 INT C INT SCI IN, P945
   Gen M., 1997, GENETIC ALGORITHM EN
   Ishtiaq M., 2010, ICIC EXPRESS LETT, V4, P1881
   Khan A, 2007, INFORM FUSION, V8, P354, DOI 10.1016/j.inffus.2005.09.007
   Lee YK, 2000, IEE P-VIS IMAGE SIGN, V147, P288, DOI 10.1049/ip-vis:20000341
   LEE YK, 1999, P 9 NAT C INF SEC TA, P8
   Lee ZJ, 2008, APPL SOFT COMPUT, V8, P798, DOI 10.1016/j.asoc.2007.03.011
   Li SL, 2006, PATTERN RECOGN, V39, P1168, DOI 10.1016/j.patcog.2005.11.017
   Piva A, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P520, DOI 10.1109/ICIP.1997.647964
   RADACK GM, 1982, COMPUT VISION GRAPH, V19, P1, DOI 10.1016/0146-664X(82)90111-3
   Sikander B., 2010, INT C INF SCI APPL I, P512
   Suganthan PN, 1999, P INT C NEUR NETW JU, P10
   Usman I, 2010, APPL SOFT COMPUT, V10, P332, DOI 10.1016/j.asoc.2009.08.004
   VANSCHYNDELL RG, 1994, IEEE IMAGE PROC, P86, DOI 10.1109/ICIP.1994.413536
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wang RZ, 2000, ELECTRON LETT, V36, P2069, DOI 10.1049/el:20001429
   Yao FH, 2003, PATTERN RECOGN LETT, V24, P1819, DOI 10.1016/S0167-8655(03)00006-0
NR 27
TC 6
Z9 6
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 2
BP 825
EP 840
DI 10.1007/s11042-013-1377-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AQ8MX
UT WOS:000343080700012
DA 2024-07-18
ER

PT J
AU Meng, FB
   Wu, ZY
   Jia, J
   Meng, HL
   Cai, LH
AF Meng, Fanbo
   Wu, Zhiyong
   Jia, Jia
   Meng, Helen
   Cai, Lianhong
TI Synthesizing English emphatic speech for multimodal corrective feedback
   in computer-aided pronunciation training
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emphasis; Feature analysis; Emphatic speech perturbation; Emphatic
   speech synthesis; HMM
ID STRESSED SPEECH; FOCUS
AB Emphasis plays an important role in expressive speech synthesis in highlighting the focus of an utterance to draw the attention of the listener. We present a hidden Markov model (HMM)-based emphatic speech synthesis model. The ultimate objective is to synthesize corrective feedback in a computer-aided pronunciation training (CAPT) system. We first analyze contrastive (neutral versus emphatic) speech recording. The changes of the acoustic features of emphasis at different prosody locations and the local prominences of emphasis are analyzed. Based on the analysis, we develop a perturbation model that predicts the changes of the acoustic features from neutral to emphatic speech with high accuracy. Further based on the perturbation model we develop an HMM-based emphatic speech synthesis model. Different from the previous work, the HMM model is trained with neutral corpus, but the context features and additional acoustic-feature-related features are used during the growing of the decision tree. Then the output of the perturbation model can be used to supervise the HMM model to synthesize emphatic speeches instead of applying the perturbation model at the backend of a neutral speech synthesis model directly. In this way, the demand of emphasis corpus is reduced and the speech quality decreased by speech modification algorithm is avoided. The experiments indicate that the proposed emphatic speech synthesis model improves the emphasis quality of synthesized speech while keeping a high degree of the naturalness.
C1 [Meng, Fanbo; Jia, Jia; Cai, Lianhong] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
   [Meng, Fanbo; Jia, Jia; Cai, Lianhong] Tsinghua Natl Lab Informat Sci & Technol TNList, Beijing, Peoples R China.
   [Wu, Zhiyong; Meng, Helen] Chinese Univ Hong Kong, Dept Syst Engn & Engn Management, Hong Kong, Hong Kong, Peoples R China.
   [Wu, Zhiyong; Jia, Jia; Meng, Helen; Cai, Lianhong] Tsinghua Univ, Grad Sch Shenzhen, Tsinghua CUHK Joint Res Ctr Media Sci Technol & S, Shenzhen 518055, Peoples R China.
C3 Tsinghua University; Tsinghua University; Chinese University of Hong
   Kong; Tsinghua Shenzhen International Graduate School; Tsinghua
   University
RP Jia, J (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
EM skywing32@gmail.com; zywu@se.cuhk.edu.hk; jjia@tsinghua.edu.cn;
   hmmeng@se.cuhk.edu.hk; clh-dcs@tsinghua.edu.cn
RI jia, jia/JKJ-5720-2023; Meng, Helen M/F-6043-2011
OI Meng, Helen M/0000-0002-4427-3532
FU National Basic Research Program of China [2012CB316401, 2013CB329304];
   Hong Kong SAR Government's Research Grants Council [N-CUHK414/09];
   National Natural Science Foundation of China [60805008, 61003094]
FX This work is supported by the National Basic Research Program of China
   (2012CB316401 and 2013CB329304). This work is also partially supported
   by the Hong Kong SAR Government's Research Grants Council
   (N-CUHK414/09), the National Natural Science Foundation of China
   (60805008 and 61003094). The authors would like to thank the students of
   the research group of Human Computer Speech Interaction in Tsinghua
   University, the Graduate School at Shenzhen of Tsinghua University and
   the Chinese University of Hong Kong, for their cooperation with the
   dataset setup and experiments.
CR Bou-Ghazale SE, 1998, IEEE T SPEECH AUDI P, V6, P201, DOI 10.1109/89.668815
   BouGhazale SE, 1996, SPEECH COMMUN, V20, P93, DOI 10.1016/S0167-6393(96)00047-7
   Chen SW, 2009, P INT
   Jia J, 2011, IEEE T AUDIO SPEECH, V19, P570, DOI 10.1109/TASL.2010.2052246
   Kominek J., 2003, CMULTI03177 CARN MEL
   LEGGETTER CJ, 1995, COMPUT SPEECH LANG, V9, P171, DOI 10.1006/csla.1995.0010
   Li AJ, 1994, DURATION CHARACTERIS
   Li Ya, 2011, Journal of Tsinghua University (Science and Technology), V51, P1239
   Li Ya, 2011, Journal of Tsinghua University (Science and Technology), V51, P1171
   Liu F, 2010, P SPEECH PROS
   Maeno Y., 2011, P INTERSPEECH, P1849
   Meng FB, 2012, P INT
   Meng H, 2011, P APSIPA MARCH
   Morizane K, 2009, INT CONF SPEECH DATA, P76, DOI 10.1109/ICSDA.2009.5278371
   Neri A, 2006, P INT PITTSB US
   Plag I, 2006, ENGL LANG LINGUIST, V10, P143, DOI 10.1017/S1360674306001821
   Raux A, 2003, P ASRU
   Rump HH, 1996, LANG SPEECH, V39, P1, DOI 10.1177/002383099603900101
   SELKIRK EO, 1980, LINGUIST INQ, V11, P563
   Strangert E., 2003, 15 INT C PHONETIC SC, P2477
   Tamburini F, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 1, PROCEEDINGS, P385, DOI 10.1109/ISSPA.2003.1224721
   Tamburini Fabio., 2003, 8 EUROPEAN C SPEECH, P129
   Tokuda K, 2003, P IEEE INT C AC SPEE, V3, P1315
   Tokuda K., 2008, HMM BASED SPEECH SYN
   Xie L, 2007, IEEE T MULTIMEDIA, V9, P500, DOI 10.1109/TMM.2006.888009
   Xu JP, 2004, CHIN J ACOUST, V4, P335
   Xu Y, 2005, J PHONETICS, V33, P159, DOI 10.1016/j.wocn.2004.11.001
   Yu K, 2010, INT CONF ACOUST SPEE, P4238, DOI 10.1109/ICASSP.2010.5495690
   Zhou QF, 1996, MICROCOMPUTER, V16, P16
   [朱维彬 ZHU Weibin], 2007, [中文信息学报, Journal of Chinese Information Processing], V21, P122
NR 30
TC 10
Z9 11
U1 0
U2 86
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 1
BP 463
EP 489
DI 10.1007/s11042-013-1601-y
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AP9RX
UT WOS:000342418700023
DA 2024-07-18
ER

PT J
AU Tsai, HC
   Chen, BW
   Wang, JF
   Paul, A
AF Tsai, Hsin-Chun
   Chen, Bo-Wei
   Wang, Jhing-Fa
   Paul, Anand
TI Enhanced long-range personal identification based on multimodal
   information of human features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Height measurement; Face recognition; Multiview face detection; Personal
   identification
ID RECOGNITION; EIGENFACES; IRIS
AB This work presents an enhanced long-range personal identification scheme using multimodal information of human features. Multimodal information includes multiview face detection, height measurement and face recognition. Multiview faces are estimated by collecting five face databases that correspond to left, half-left, right, half-right, and frontal faces, respectively. The sequences of parameters based on four detectors are also designed to determine the face direction. The detectors use the head-shoulder region, frontal face, profile face, and eyes detector respectively. In addition to determining when individuals enter the monitoring area, the multiview face detection module also describes the detected face direction. This result allows the identification system to select the face database of a specific direction to identify subsequent faces. Additionally, the height measurement module estimates individual height by calculating the vanishing points and lines. The module concept is based on single-view metrology. The measured information further refines the face database selected by multiview face detection and minimizes the candidates for face identification. Importantly, the proposed method integrates the multimodal information based on face direction, height and face features to refine the database and analyzes the information to determine the identity of a person. In this work, images from a monitoring area 5.6 m away from a camera are captured using an inexpensive digital web camera. The experimental results show that the proposed method can improve the accuracy rate by more than 21 % in contrast with the baselines and correspondingly demonstrates the effectiveness of the proposed idea.
C1 [Tsai, Hsin-Chun; Chen, Bo-Wei; Wang, Jhing-Fa] Natl Cheng Kung Univ, Dept Elect Engn, Tainan 70101, Taiwan.
   [Paul, Anand] Kyungpook Natl Univ, Sch Comp Sci & Engn, Taegu, South Korea.
C3 National Cheng Kung University; Kyungpook National University
RP Tsai, HC (corresponding author), Natl Cheng Kung Univ, Dept Elect Engn, 1 Univ Rd, Tainan 70101, Taiwan.
EM tsaihcmail@gmail.com; wangjf@mail.ncku.edu.tw
RI Paul, Anand/V-6724-2017; Chen, Bowei/AAB-7002-2021
OI Paul, Anand/0000-0002-0737-2021; Chen, Bowei/0000-0002-4045-3253; Paul,
   Anand/0000-0003-3115-2325
CR Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   BenAbdelkader C, 2002, INT C PATT RECOG, P377, DOI 10.1109/ICPR.2002.1047474
   Berger M., 1987, Geometry I
   Choi YH, 2013, MULTIMED TOOLS APPL, V64, P227, DOI 10.1007/s11042-011-0987-7
   Choras RS, 2010, ADV INTEL SOFT COMPU, V84, P121
   Criminisi A, 2000, INT J COMPUT VISION, V40, P123, DOI 10.1023/A:1026598000963
   Criminisi A, 2002, DAGM S PATT REC SEPT
   Criminisi A., 2001, DISTINGUISHED DISSER
   Dantcheva A, 2011, MULTIMED TOOLS APPL, V51, P739, DOI 10.1007/s11042-010-0635-7
   Feng W, 2009, J VISUAL LANG COMPUT, V20, P188, DOI 10.1016/j.jvlc.2009.01.009
   HRECHAK AK, 1990, PATTERN RECOGN, V23, P893, DOI 10.1016/0031-3203(90)90134-7
   Jain AK, 2004, PROC SPIE, V5404, P561, DOI 10.1117/12.542890
   Kawulok M, 2010, MULTIMED TOOLS APPL, V49, P463, DOI 10.1007/s11042-009-0444-z
   Kuan TW, 2012, EXPERT SYST APPL, V39, P9288, DOI 10.1016/j.eswa.2012.02.075
   Liao YH, 2002, COMPUT SECUR, V21, P439, DOI 10.1016/S0167-4048(02)00514-X
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   MOAYER B, 1986, IEEE T PATTERN ANAL, V8, P376, DOI 10.1109/TPAMI.1986.4767798
   Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802
   Tsai H-C, 2009, 2009 I E REG 10 C TE, P1
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Varetskyy Y, 2010, ADV INTEL SOFT COMPU, V84, P99
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
   Xiao QH, 2007, IEEE COMPUT INTELL M, V2, P5, DOI 10.1109/MCI.2007.353415
   Zewail R, 2004, 2004 47TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL I, CONFERENCE PROCEEDINGS, P225
NR 27
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 1
BP 291
EP 307
DI 10.1007/s11042-013-1606-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AP9RX
UT WOS:000342418700015
DA 2024-07-18
ER

PT J
AU Horng, SJ
   Farfoura, ME
   Fan, PZ
   Wang, X
   Li, TR
   Guo, JM
AF Horng, Shi-Jinn
   Farfoura, Mahmoud E.
   Fan, Pingzhi
   Wang, Xian
   Li, Tianrui
   Guo, Jing-Ming
TI A low cost fragile watermarking scheme in H.264/AVC compressed domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE H.264/AVC; Video watermarking; Intra/inter prediction mode; Discrete
   cosine transform; Content-authentication
ID INTRA-PREDICTION MODES; VIDEO WATERMARKING; DIGITAL VIDEO
AB H.264/AVC-based products have grown tremendously in social networks; issues of content-based authentication become increasingly important. This paper presents a blind fragile watermarking scheme for content-based H.264/AVC authentication, which enjoys high sensitivity to typical video attacks. A spatiotemporal analysis is exploited to guarantee a minimum impact on perceptual quality and bit-rate increment. The watermark features are extracted from intra/inter prediction modes of intra/inter macroblocks, constituting the content-based Message Authentication Code (MAC) which is embedded/extracted in a Group-of-Pictures GOP-based fashion utilizing the syntactic elements of the Network Application Layer (NAL) units from the compressed bitstream. It's unnecessary to fully decode a compressed bitstream before the embedding or detection processes. A content-based key is generated to control fragile watermark generation, embedding, extraction, and verification algorithms. Additionally, fragility is ensured by selecting the last nonzero quantized ac residuals for watermark embedding. The embedded watermark can be detected and verified by means of partially decoding intra/inter prediction modes from syntactic elements of the bitstream without the prior knowledge of the original video or complete decoding. Experiment results demonstrate that the performance of the proposed scheme is excellent in terms of bit-rate and perceptual quality. Furthermore, various types of content-preserving and/or content-changing attacks can be detected efficiently.
C1 [Horng, Shi-Jinn; Fan, Pingzhi; Wang, Xian; Li, Tianrui] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Peoples R China.
   [Horng, Shi-Jinn; Farfoura, Mahmoud E.] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan.
   [Guo, Jing-Ming] Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei 106, Taiwan.
C3 Southwest Jiaotong University; National Taiwan University of Science &
   Technology; National Taiwan University of Science & Technology
RP Horng, SJ (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan.
EM horngsj@yahoo.com.tw; mfarfora@yahoo.com; pingzhifan@gmail.com;
   drwangxian@gmail.com; trli@home.swjtu.edu.cn; jmguo@seed.net.tw
RI Li, Tianrui/F-4974-2019; Horng, Shi-Jinn/GVU-0488-2022; Li,
   Tianrui/A-4889-2012
OI Li, Tianrui/0000-0001-7780-104X; Farfoura, Mahmoud/0000-0002-9010-6989
FU National Science Council [NSC101-2221-E-011-063-MY3]; 111 Project
   [111-2-14]; One Hundred Talents Program, Sichuan Province; National
   Science Foundation of China [60902023, 61171096]; Fundamental Research
   Funds for the Central Universities [SWJTU12CX093]
FX This work was supported in part by the National Science Council under
   contract number NSC101-2221-E-011-063-MY3 and it was also partially
   supported by the 111 Project under the grant No. 111-2-14, One Hundred
   Talents Program 2012, Sichuan Province. M. E. Farfoura is currently a
   system analyst with the Information Technology Center-Royal Scientific
   Society, Jordan-Amman. The work of X. Wang was supported by the National
   Science Foundation of China under Grants 60902023 and 61171096, as well
   as by the Fundamental Research Funds for the Central Universities under
   the Grant SWJTU12CX093.
CR Ahmad I, 2005, IEEE T MULTIMEDIA, V7, P793, DOI 10.1109/TMM.2005.854472
   Aho A.V., 1986, Compilers: Principles. Techniques, P434
   [Anonymous], DIGITAL IMAGE PROCES
   ANSI, 2003, T180103003 ANSI
   Cappellini V, 2001, 12TH INTERNATIONAL WORKSHOP ON DATABASE AND EXPERT SYSTEMS APPLICATIONS, PROCEEDINGS, P825, DOI 10.1109/DEXA.2001.953158
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Fan XP, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P557
   Furht B., 2003, Handbook of video databases: design and applications
   Golikeri A, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2816054
   Horowitz M, 2003, IEEE T CIRC SYST VID, V13, P704, DOI 10.1109/TCSVT.2003.814967
   Hu Y, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1231
   Huang SC, 2008, IEEE T BROADCAST, V54, P499, DOI 10.1109/TBC.2008.2001150
   Kapotas SK, 2009, J REAL-TIME IMAGE PR, V4, P33, DOI 10.1007/s11554-008-0100-2
   Kim SM, 2007, LECT NOTES COMPUT SC, V4633, P698
   Kim T, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.4.047402
   Koz A, 2008, IEEE T CIRC SYST VID, V18, P326, DOI 10.1109/TCSVT.2008.918446
   Lin E., 2005, VIDEO IMAGE WATERMAR
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P11888, DOI 10.1016/j.eswa.2009.04.026
   Lin WH, 2009, EXPERT SYST APPL, V36, P11509, DOI 10.1016/j.eswa.2009.03.060
   Liu CH, 2008, IEEE INT SYMP CIRC S, P3025, DOI 10.1109/ISCAS.2008.4542095
   Mansouri A, 2010, IEEE T INF FOREN SEC, V5, P649, DOI 10.1109/TIFS.2010.2076280
   Noorkami M, 2008, IEEE T INF FOREN SEC, V3, P441, DOI 10.1109/TIFS.2008.923825
   Noorkami M, 2007, IEEE T INF FOREN SEC, V2, P14, DOI 10.1109/TIFS.2006.890306
   Pröfrock D, 2005, PROC SPIE, V5960, P1480, DOI 10.1117/12.632709
   QIU G, 2006, P 17 INT C PATT REC, V4, P2353
   Richardson Iain E, 2004, H. 264 and MPEG-4 Video Compression: Video Coding for Next-Generation Multimedia
   Saadi K, 2009, EUSIPCO 2009 SCOTL G
   Wang CC, 2010, OPT ENG, V49, DOI 10.1117/1.3309472
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wolfgang RB, 1999, PROC SPIE, V3657, P40, DOI 10.1117/12.344700
   Xu D, 2011, SIGNAL PROCESS IMAGE, V26
   Xu DW, 2011, OPT ENG, V50, DOI 10.1117/1.3622759
   Yang GB, 2011, AEU-INT J ELECTRON C, V65, P331, DOI 10.1016/j.aeue.2010.03.011
   Zhu BB, 2004, IEEE SIGNAL PROC MAG, V21, P40, DOI 10.1109/MSP.2004.1276112
NR 36
TC 16
Z9 17
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2469
EP 2495
DI 10.1007/s11042-013-1561-2
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300019
DA 2024-07-18
ER

PT J
AU Long, XZ
   Lu, HT
   Peng, Y
   Li, WB
AF Long, Xianzhong
   Lu, Hongtao
   Peng, Yong
   Li, Wenbin
TI Graph regularized discriminative non-negative matrix factorization for
   face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-negative matrix factorization; Graph Laplacian; Discriminative
   information; Face recognition
ID DIMENSIONALITY REDUCTION; PARTS; ALGORITHMS; OBJECTS
AB Non-negative matrix factorization (NMF) has been widely employed in computer vision and pattern recognition fields since the learned bases can be interpreted as a natural parts-based representation of the input space, which is consistent with the psychological intuition of combining parts to form a whole. In this paper, we propose a novel constrained nonnegative matrix factorization algorithm, called the graph regularized discriminative non-negative matrix factorization (GDNMF), to incorporate into the NMF model both intrinsic geometrical structure and discriminative information which have been essentially ignored in prior works. Specifically, both the graph Laplacian and supervised label information are jointly utilized to learn the projection matrix in the new model. Further we provide the corresponding multiplicative update solutions for the optimization framework, together with the convergence proof. A series of experiments are conducted over several benchmark face datasets to demonstrate the efficacy of our proposed GDNMF.
C1 [Long, Xianzhong; Lu, Hongtao; Peng, Yong] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200030, Peoples R China.
   [Li, Wenbin] Shanghai Jiao Tong Univ, Affiliated Peoples Hosp 6, Dept Diagnost & Intervent Radiol, Shanghai 200030, Peoples R China.
C3 Shanghai Jiao Tong University; Shanghai Jiao Tong University
RP Long, XZ (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200030, Peoples R China.
EM lxz85@sjtu.edu.cn; lu-ht@sjtu.edu.cn; pengyong851012@sjtu.edu.cn;
   liwenbin@sh163.net
RI Peng, Yong/JCO-0601-2023
OI Peng, Yong/0000-0003-1208-972X
FU National Basic Research Program of China (973 program) [2009CB320901];
   National Natural Science Foundation of China [61272247]; National High
   Technology Research and Development Program of China (863 program)
   [2008AA02Z310]; European Union Seventh Framework Programme [247619];
   Shanghai Committee of Science and Technology [08411951200]; Innovation
   Ability Special Fund of Shanghai Jiao Tong University [Z030026]
FX This work is supported in part by the National Basic Research Program of
   China (973 program) under Grant 2009CB320901, the National Natural
   Science Foundation of China under Grant 61272247, the National High
   Technology Research and Development Program of China (863 program) under
   Grant 2008AA02Z310, the European Union Seventh Framework Programme under
   Grant 247619, the Shanghai Committee of Science and Technology under
   Grant 08411951200, and the Innovation Ability Special Fund of Shanghai
   Jiao Tong University under Grant Z030026.
CR [Anonymous], 1997, REGIONAL C SERIES MA
   [Anonymous], 2006, PROC IEEE COMPUT SOC
   [Anonymous], ADV NEURAL INFORM PR
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Berry MW, 2007, COMPUT STAT DATA AN, V52, P155, DOI 10.1016/j.csda.2006.11.006
   Brunet JP, 2004, P NATL ACAD SCI USA, V101, P4164, DOI 10.1073/pnas.0308531101
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Graham Daniel B, 1998, CHARACTERISING VIRTU, P446
   Guan NY, 2011, IEEE T IMAGE PROCESS, V20, P2030, DOI 10.1109/TIP.2011.2105496
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Li SZ, 2001, PROC CVPR IEEE, P207
   Logothetis NK, 1996, ANNU REV NEUROSCI, V19, P577, DOI 10.1146/annurev.ne.19.030196.003045
   PALMER SE, 1977, COGNITIVE PSYCHOL, V9, P441, DOI 10.1016/0010-0285(77)90016-0
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   WACHSMUTH E, 1994, CEREB CORTEX, V4, P509, DOI 10.1093/cercor/4.5.509
   Xu W., 2003, P 26 ANN INT ACM SIG, P267
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
NR 24
TC 51
Z9 58
U1 0
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2679
EP 2699
DI 10.1007/s11042-013-1572-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300027
DA 2024-07-18
ER

PT J
AU Wang, KR
   Han, JS
   Wang, HX
AF Wang, Keren
   Han, Jiesi
   Wang, Hongxia
TI Digital video steganalysis by subtractive prediction error adjacency
   matrix
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video steganalysis; Communication security; Steganography; SPAM; SPEAM
AB Video has become an important cover for steganography for its large volume. There are two main categories among existing methods for detecting steganography which embeds in the spatial domain of videos. One category focuses on the spatial redundancy and the other one mainly focuses on the temporal redundancy. This paper presents a novel method which considers both the spatial and the temporal redundancy for video steganalysis. Firstly, model of spread spectrum steganography is provided. PEF (Prediction Error Frame) is then chosen to suppress the temporal redundancy of the video content. Differential filtering between adjacent samples in PEFs is employed to further suppress the spatial redundancy. Finally, Dependencies between adjacent samples in a PEF are modeled by a first-order Markov chain, and subsets of the empirical matrices are then employed as features for a steganalyzer with classifier of SVM (Support Vector Machine). Experimental results demonstrate that for uncompressed videos, the novel features perform better than previous video steganalytic works, and similar to the well-known SPAM (Subtractive Pixel Adjacency Model) features which are originally designed for image steganalysis. For videos compressed with distortion, the novel features perform better than other features tested.
C1 [Wang, Keren] Natl Digital Switching Syst Engn & Technol Res Ct, Zhengzhou, Peoples R China.
   [Wang, Keren; Han, Jiesi] Sci & Technol Blind Signal Proc Lab, Chengdu, Peoples R China.
   [Wang, Hongxia] Southwest Jiaotong Univ, Chengdu, Peoples R China.
C3 PLA Information Engineering University; Southwest Jiaotong University
RP Wang, KR (corresponding author), Sci & Technol Blind Signal Proc Lab, Chengdu, Peoples R China.
EM cfan662003@gmail.com
RI Wang, Hongxia/AAE-2135-2022
OI Wang, Keren/0000-0002-7140-8164
FU National Natural Science Foundation of China (NSFC) [61170226];
   Fundamental Research Funds for the Central Universities [SWJTU11CX047];
   Chengdu Science and Technology program [12DXYB214JH-002]
FX This research was supported by the National Natural Science Foundation
   of China (NSFC) under the grant No. 61170226, the Fundamental Research
   Funds for the Central Universities under the grant Nos. SWJTU11CX047,
   and Chengdu Science and Technology program under the grant No.
   12DXYB214JH-002.
CR Aly HA, 2011, IEEE T INF FOREN SEC, V6, P14, DOI 10.1109/TIFS.2010.2090520
   [Anonymous], 2007, ELECT IMAGING SECURI
   BUDHIA U, 2006, IEEE T INF FOREN SEC, V1, P43
   BUDHIA U, 2004, P SPIE, V5403
   Cao Y, 2012, IEEE SIGNAL PROC LET, V19, P35, DOI 10.1109/LSP.2011.2176116
   Chang C.C., LIBSVM: a library for support vector machines
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Hartung F, 1998, SIGNAL PROCESS, V66, P283, DOI 10.1016/S0165-1684(98)00011-5
   Jainsky JS, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P161
   Kancherla K., 2009, 2009 International Conference on High Performance Computing & Simulation (HPCS), P200, DOI 10.1109/HPCSIM.2009.5194136
   Kancherla K., 2009, Proceedings 2009 International Joint Conference on Neural Networks (IJCNN 2009 - Atlanta), P1510, DOI 10.1109/IJCNN.2009.5179032
   Kashyap S, 2010, SPATIAL AVERAGING BA, P1
   Li Q, 2007, IEEE T INF FOREN SEC, V2, P127, DOI 10.1109/TIFS.2007.897266
   Liu B, 2008, SECUR COMMUN NETW, V1, P487, DOI 10.1002/sec.84
   Liu QZ, 2008, SEVENTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS, P671, DOI 10.1109/ICMLA.2008.92
   Marvel LM, 1999, IEEE T IMAGE PROCESS, V8, P1075, DOI 10.1109/83.777088
   Pankajakshan V, 2009, IEEE T INF FOREN SEC, V4, P49, DOI 10.1109/TIFS.2008.2012199
   Pérez-González F, 2004, 2004 IEEE 6TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P139
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Rana V., 2008, TENCON 2008 2008 IEE
   Sharp Toby, 2001, Information Hiding, V2137, P13, DOI 10.1007/3-540-45496-9_2
   Su YT, 2011, SIGNAL PROCESS, V91, P1901, DOI 10.1016/j.sigpro.2011.02.012
   Zhang C, 2008, ELECTRON LETT, V44, P801, DOI 10.1049/el:20080582
   Zhang T, 2010, INFORM SCIENCES, V180, P4685, DOI 10.1016/j.ins.2010.07.037
NR 25
TC 18
Z9 18
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 313
EP 330
DI 10.1007/s11042-013-1373-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800015
DA 2024-07-18
ER

PT J
AU Cirakman, O
   Gunsel, B
   Sengor, NS
   Kutluk, S
AF Cirakman, Ozgun
   Gunsel, Bilge
   Sengor, Neslihan Serap
   Kutluk, Sezer
TI Content-based copy detection by a subspace learning based video
   fingerprinting scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video fingerprinting; Non-negative matrix factorization; Content based
   copy detection
ID ROBUST
AB We propose a video copy detection scheme that employs a transform domain global video fingerprinting method. Video fingerprinting has been performed by the subspace learning based on nonnegative matrix factorization (NMF). It is shown that the binary video fingerprints extracted from the basis and gain matrices of the NMF representation enable us to efficiently represent the spatial and temporal content of a video segment respectively. An extensive performance evaluation has been carried out on the query and reference dataset of CBCD task of TRECVID 2011. Our results are compared with the average and the best performance reported for the task. Also NDCR and F1 rates are reported in comparison to the performance achieved via the global methods designed by the TRECVID 2011 participants. Results demonstrate that the proposed method achieves higher correct detection rates with good localization capability for the transformation of text/logo insertion, strong re-encoding, frame dropping, noise addition, gamma change or their mixtures; however there is still potential for improvement to detect copies with picture-in-picture transformations. It is also concluded that the introduced binary fingerprinting scheme is superior to the existing transform based methods in terms of the compactness.
C1 [Cirakman, Ozgun; Gunsel, Bilge; Sengor, Neslihan Serap; Kutluk, Sezer] Istanbul Tech Univ, Dept Elect & Commun Engn, Multimedia Signal Proc & Pattern Recognit Lab, TR-34469 Istanbul, Turkey.
C3 Istanbul Technical University
RP Cirakman, O (corresponding author), Istanbul Tech Univ, Dept Elect & Commun Engn, Multimedia Signal Proc & Pattern Recognit Lab, TR-34469 Istanbul, Turkey.
EM cirakmano@itu.edu.tr; gunselb@itu.edu.tr; sengorn@itu.edu.tr;
   kutluks@itu.edu.tr
RI Günsel, Bilge/ABA-7531-2020; Kutluk, Sezer/AAB-3214-2020; Sengor,
   Neslihan Serap/H-6409-2013
OI Günsel, Bilge/0000-0003-3628-3316; Kutluk, Sezer/0000-0002-3048-5526;
   Cirakman, Ozgun/0000-0001-6649-3280
FU Scientific and Technological Research Council of Turkey (TUBITAK) under
   the project name TUBITAK EEEAG [109E63]
FX This work is supported by The Scientific and Technological Research
   Council of Turkey (TUBITAK) under the project name TUBITAK EEEAG PNo
   109E63.
CR Anguera X, 2011, TRECVID WORKSH NIST
   [Anonymous], 2006, P 8 ACM INT WORKSHOP
   Barrios JM, 2011, TRECVID WORKSH NIST
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bucak Serhat S., 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P113
   Cirakman O, 2010, IEEE IMAGE PROC, P2373, DOI 10.1109/ICIP.2010.5652649
   Gupta V, 2011, TRECVID WORKSH NIST
   Gursoy O, 2009, LECT NOTES COMPUT SC, V5702, P452, DOI 10.1007/978-3-642-03767-2_55
   Hill M, 2010, TRECVID WORKSH NIST, V1, P146
   Hradis M, 2011, TRECVID WORKSH NIST
   Jegou H, 2010, TRECVID WORKSH NIST, V1, P160
   Jiang M, 2011, TRECVID WORKSH NIST
   Küçüktunç O, 2010, J VIS COMMUN IMAGE R, V21, P838, DOI 10.1016/j.jvcir.2010.07.001
   Law-To Julien., 2007, P 6 ACM INT C IMAGE, P371
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Lee S, 2006, P ITN C AC SPEECH, V2, P401, DOI DOI 10.1109/ICASSP.2006.1660364
   Lee S, 2008, IEEE IMAGE PROC, P2156, DOI 10.1109/ICIP.2008.4712215
   Lin Y, 2010, TRECVID WEORKSH NIST, V1, P322
   Liu Z, 2011, TRECVID WORKSH NIST
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Massoudi A, 2006, IEEE IMAGE PROC, P2297, DOI 10.1109/ICIP.2006.312834
   Monga V, 2007, IEEE T INF FOREN SEC, V2, P376, DOI 10.1109/TIFS.2007.902670
   Mukai R, 2011, TRECVID WORKSH NIST
   Naturel X, 2005, P 2 INT WORKSH COMP, P21, DOI DOI 10.1145/1160939.1160947
   Oostveen J., 2002, Recent Advances in Visual Information Systems. 5th International Conference VISUAL 2002. Proceedings (Lecture Notes in Computer Science Vol.2314), P117
   Over P., 2011, Proc. of TRECVID, P1
   Radhakrishnan Regunathan, 2009, Proceedings of the SPIE - The International Society for Optical Engineering, V7254, DOI 10.1117/12.805627
   Rouhi AH, 2011, TRECVID WORKSH NIST
   Sarkar A, 2010, IEEE T CIRC SYST VID, V20, P870, DOI 10.1109/TCSVT.2010.2046056
   Sun C, 2010, TRECVID WORKSH NIST, V1, P404
   Uchida Y, 2011, TRECVID WORKSH NIST
   Zhao W, 2011, TRECVID WORKSH NIST
NR 32
TC 6
Z9 6
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1381
EP 1409
DI 10.1007/s11042-012-1269-8
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000019
DA 2024-07-18
ER

PT J
AU Seo, S
   Ostromoukhov, V
AF Seo, SangHyun
   Ostromoukhov, Victor
TI Pointillist video stylization based on particle tracing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-photorealistic rendering and animation; Video stylization;
   Pointillist animation; Temporal coherence
AB We present an algorithm that stylizes an input video into a painterly animation without user intervention. In particular, we focus on pointillist animation with stable temporal coherence. Temporal coherence is an important problem in non-photorealistic rendering for videos. To realize pointillist animation, the various characters of pointillism should be considered in painting process to maintain temporal coherence. For this, weused the particle video algorithm which is a new approach to long-range motion estimation in video. Based on this method, we introduce a method to control the density of particles considering the features of frames and importance maps. Finally, the propagation methods of stroke to minimize flickering effects of brush strokes are introduced.
C1 [Seo, SangHyun; Ostromoukhov, Victor] Univ Lyon 1, LIRIS, F-69365 Lyon, France.
C3 Institut National des Sciences Appliquees de Lyon - INSA Lyon;
   Universite Claude Bernard Lyon 1
RP Seo, S (corresponding author), Univ Lyon 1, LIRIS, F-69365 Lyon, France.
EM shseo75@gmail.com; victor.ostromoukhov@liris.cnrs.fr
RI Sanghyun, Seo/ADZ-4404-2022
OI Sanghyun, Seo/0000-0002-4824-3517
FU Korea Research Foundation Grant - Korean Government
   [KRF-2011-357-D00202]; French institutional grant AMCQMCSGA
   [ANR-10-CEXC-002]
FX This work was supported by the Korea Research Foundation Grant funded by
   the Korean Government (KRF-2011-357-D00202) and was partly supported by
   French institutional grant AMCQMCSGA ANR-10-CEXC-002.
CR Gossett N, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P113, DOI 10.1109/INFVIS.2004.52
   Haeberli P., 1990, Computer Graphics, V24, P207, DOI 10.1145/97880.97902
   Hays J., 2004, PROC NPAR 01, P113
   Hertzmann A., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P453, DOI 10.1145/280814.280951
   Hertzmann A, 2001, COMPUTER GRAPHICS INTERNATIONAL 2001, PROCEEDINGS, P47, DOI 10.1109/CGI.2001.934657
   Hertzmann A., 2000, NPAR, P7
   Huang H, 2010, COMPUT GRAPH FORUM, V29, P2055, DOI 10.1111/j.1467-8659.2010.01792.x
   Kagaya M, 2011, IEEE T VIS COMPUT GR, V17, P74, DOI 10.1109/TVCG.2010.25
   Kang H, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P43
   Lee H, 2013, MULTIMED TOOLS APPL, V64, P277, DOI 10.1007/s11042-012-1036-x
   Lin L., 2010, Proc. NPAR '10, P73, DOI DOI 10.1145/1809939.1809948
   Litwinowicz P., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P407, DOI 10.1145/258734.258893
   Meier B. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P477, DOI 10.1145/237170.237288
   O'Donovan P, 2012, IEEE T VIS COMPUT GR, V18, P475, DOI 10.1109/TVCG.2011.51
   Park Y, 2008, GRAPH MODELS, V70, P1, DOI 10.1016/j.gmod.2007.06.001
   Sand Peter, 2008, International Journal of Computer Vision, V80, P72, DOI 10.1007/s11263-008-0136-6
   Schwarz M., 2009, Proc. of the apgv, Chania, Crete, DOI DOI 10.1145/1620993.1621012
   Seo S, 2013, MULTIMED TOOLS APPL, V65, P221, DOI 10.1007/s11042-011-0796-z
   Seo S, 2010, VISUAL COMPUT, V26, P421, DOI 10.1007/s00371-010-0505-3
   YANTIS S, 1984, J EXP PSYCHOL HUMAN, V10, P601, DOI 10.1037/0096-1523.10.5.601
   Zhao M., 2011, Proc. NPAR '11, P137, DOI DOI 10.1145/2024676.2024698
NR 21
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 1
BP 279
EP 292
DI 10.1007/s11042-013-1441-9
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK0QX
UT WOS:000338120700016
DA 2024-07-18
ER

PT J
AU Van Deursen, D
   Van Lancker, W
   Mannens, E
   Van de Walle, R
AF Van Deursen, Davy
   Van Lancker, Wim
   Mannens, Erik
   Van de Walle, Rik
TI Experiencing standardized media fragment annotations within HTML5
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HTML5; Media Annotations; Media Fragments; Text Track API; WebVTT
ID SEMANTIC WEB TECHNOLOGIES; ADAPTATION
AB W3C's Video in the Web activity aims at a better integration of media within the Web. In this paper, we show how two specifications currently under development within this activity, i.e., Media Fragment URIs and Media Annotations, can be combined within media-enabled HTML5 Web applications. In particular, we introduce a number of extensions for the Media Annotations ontology in order to close the gap with Media Fragment URIs. Additionally, we show how rich media fragment annotations can be converted into a WebVTT file. The latter can be used by HTML5-enabled players to show the annotations in a synchronized way. Further, a fully integrated Web application has been developed that shows how both specifications can work together within an HTML5 environment. This application relies on Nin-Suna, our media delivery platform targeted at multichannel publication that provides server-side support for both Media Fragment URIs and Media Annotations.
C1 [Van Deursen, Davy; Van Lancker, Wim; Mannens, Erik; Van de Walle, Rik] Ghent Univ IBBT, Dept Elect & Informat Syst, Multimedia Lab, B-9050 Ledeberg Ghent, Belgium.
C3 Ghent University
RP Van Deursen, D (corresponding author), Ghent Univ IBBT, Dept Elect & Informat Syst, Multimedia Lab, Gaston Crommenlaan 8-201, B-9050 Ledeberg Ghent, Belgium.
EM davy.vandeursen@ugent.be
OI Mannens, Erik/0000-0001-7946-4884
FU Ghent University; Interdisciplinary Institute for Broadband Technology
   (IBBT); Institute for the Promotion of Innovation by Science and
   Technology in Flanders (IWT); Fund for Scientific Research-Flanders
   (FWO-Flanders); European Union
FX The research activities as described in this paper were funded by Ghent
   University, the Interdisciplinary Institute for Broadband Technology
   (IBBT), the Institute for the Promotion of Innovation by Science and
   Technology in Flanders (IWT), the Fund for Scientific Research-Flanders
   (FWO-Flanders), and the European Union.
CR [Anonymous], W3C VID WEB WORKSH
   [Anonymous], 2012, MOZ
   FIALHO A, 2010, P WORKSH REC TRACK E, P40
   Google, 2012, YOUTUBE VID ANN
   Haslhofer B., 2010, P 6 INT C SEM SYST I
   Haslhofer B, 2011, P WORKSH MULT WEB
   Haslhofer B, 2009, INT J DIGIT LIBRARIE, V10, P15, DOI 10.1007/s00799-009-0050-8
   Hausenblas M, 2009, P 2 WORKSH LINK DAT
   Hickson I, 2012, HTML5 VOCABULARY ASS
   Kurz T, 2011, P WORKSH MULT WEB
   Lee W., 2012, Ontology for Media Resouces 1.0
   Li Y, 2012, P 5 WORKSH LINK DAT
   Pantos R., 2012, Http live streaming
   Shaw R, 2009, LECT NOTES COMPUT SC, V5926, P153, DOI 10.1007/978-3-642-10871-6_11
   Stegmaier F, 2011, API MEDIA RESOURCES
   Steiner T, 2010, P 9 INT SEM WEB C IS
   Troncy R., 2012, MEDIA FRAGMENTS URI
   Troncy R, 2009, USE CASES REQUIREMEN
   Van Deursen D, 2010, MULTIMEDIA SYST, V16, P85, DOI 10.1007/s00530-009-0178-9
   Van Deursen D, 2010, MULTIMED TOOLS APPL, V46, P371, DOI 10.1007/s11042-009-0354-0
   Van Lancker W, 2012, MULTIMED TOOLS APPL, V57, P243, DOI 10.1007/s11042-011-0785-2
   Verstockt S, 2009, P 13 IASTED INT C IN, P149
   Waitelonis J, 2009, P INT C SEM SYST I S
   [No title captured]
NR 24
TC 2
Z9 2
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 2
BP 827
EP 846
DI 10.1007/s11042-012-1129-6
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI6OW
UT WOS:000336995900013
OA Green Published
DA 2024-07-18
ER

PT J
AU Khan, R
   Hanbury, A
   Sablatnig, R
   Stöttinger, J
   Khan, FA
   Khan, FA
AF Khan, Rehanullah
   Hanbury, Allan
   Sablatnig, Robert
   Stoettinger, Julian
   Khan, Farman Ali
   Khan, Fakhri Alam
TI Systematic skin segmentation: merging spatial and non-spatial data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin detection; Skin segmentation; Classification; Graph cuts for skin
   detection; Neighborhood relationship; Systematic skin detection
   approach; Classifiers integration
ID IMAGE SEGMENTATION; FACE DETECTION; COLOR MODELS; UNIVERSAL
AB Skin detection is used in applications ranging from face detection, tracking of body parts, hand gesture analysis, to retrieval and blocking objectionable content. We present a systematic approach for robust skin segmentation using graph cuts. The skin segmentation process starts by exploiting the local skin information of detected faces. The detected faces are used as foreground seeds for calculating the foreground weights of the graph. If local skin information is not available, we opt for the universal seed. To increase the robustness, the decision tree based classifier is used to augment the universal seed weights when no local information is available in the image. With this setup, we achieve robust skin segmentation, outperforming off-line trained classifiers. The setup also provides a generic skin detection system, using positive training data only. With face detection, we take advantage of the contextual information present in the scene. With the weight augmentation, we provide a setup for merging spatial and non-spatial data. Experiments on two datasets with annotated pixel-level ground truth show that the systematic skin segmentation approach outperforms other approaches and provides robust skin detection.
C1 [Khan, Rehanullah] Sarhad Univ Sci & Informat Technol, Peshawar, Pakistan.
   [Hanbury, Allan; Khan, Farman Ali] TU Wien, Inst Software Technol & Interact Syst, Vienna, Austria.
   [Sablatnig, Robert] TU Wien, Inst Comp Aided Automat, Vienna, Austria.
   [Stoettinger, Julian] Univ Trento, Dept Informat Engn & Comp Sci, Trento, Italy.
   Inst Management Sci, Peshawar, Pakistan.
   [Khan, Fakhri Alam] COMSATS Inst Informat Technol, Islamabad, Pakistan.
C3 Technische Universitat Wien; Technische Universitat Wien; University of
   Trento; COMSATS University Islamabad (CUI)
RP Khan, R (corresponding author), Sarhad Univ Sci & Informat Technol, Peshawar, Pakistan.
EM rehanmarwat1@gmail.com
RI Sablatnig, Robert/AAV-1518-2020; Khan, Fakhri Alam/S-5340-2017;
   Sablatnig, Robert/K-7739-2013; Khan, Fakhri Alam/GPP-4180-2022
OI Sablatnig, Robert/0000-0003-4195-1593; Sablatnig,
   Robert/0000-0003-4195-1593; Khan, Fakhri Alam/0000-0002-9130-1874
CR Albiol A, 2001, IEEE IMAGE PROC, P122, DOI 10.1109/ICIP.2001.958968
   [Anonymous], 2002, PROC 2002 INT C IMAG
   [Anonymous], 2003, PROC GRAPHICON
   Argyros AA, 2004, LECT NOTES COMPUT SC, V3023, P368
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Brown D.A., 2001, Proceedings of the 2001 British Machine Vision Conference, V1, P491
   Cai J, 1999, IMAGE VISION COMPUT, V18, P63, DOI 10.1016/S0262-8856(99)00006-2
   Cao LL, 2002, 2002 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-4, PROCEEDINGS, P1133, DOI 10.1109/ICMLC.2002.1174561
   Chai D, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P124, DOI 10.1109/AFGR.1998.670936
   Fleck M. M., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P593
   Fowlkes C, 2003, PROC CVPR IEEE, P54
   Fu ZY, 2004, INT C PATT RECOG, P549, DOI 10.1109/ICPR.2004.1333831
   Garcia C, 1999, IEEE T MULTIMEDIA, V1, P264, DOI 10.1109/6046.784465
   Hanbury A, 2008, PATTERN RECOGN LETT, V29, P494, DOI 10.1016/j.patrec.2007.11.002
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Hu Zhilan, 2009, Tsinghua Science and Technology, V14, P478, DOI 10.1016/S1007-0214(09)70106-3
   Jie Yang, 1997, Computer Vision - ACCV '98. Third Asian Conference on Computer Vision. Proceedings, P687
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Kakumanu P, 2007, PATTERN RECOGN, V40, P1106, DOI 10.1016/j.patcog.2006.06.010
   Khan R., 2008, P 1 ACM WORKSH AN RE, P89, DOI 10.1145/1463542.1463557
   Khan R, 2012, PATTERN RECOGN LETT, V33, P157, DOI 10.1016/j.patrec.2011.09.032
   Khan R, 2010, LECT NOTES COMPUT SC, V6454, P75, DOI 10.1007/978-3-642-17274-8_8
   Khan R, 2010, IEEE IMAGE PROC, P4613, DOI 10.1109/ICIP.2010.5651638
   Kovac J, 2003, IEEE REGION 8 EUROCON 2003, VOL B, PROCEEDINGS, P144
   Kuo YM, 2007, 2006 ICS INT COMP C, P990
   Lee JS, 2007, PATTERN RECOGN, V40, P2261, DOI 10.1016/j.patcog.2006.11.016
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   LIENSBERGER C, 2009, IEEE INT WORKSH MULT, P1, DOI DOI 10.1109/MMSP.2009.5293337
   Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Micusik B, 2005, LECT NOTES COMPUT SC, V3691, P441
   Micusík B, 2005, LECT NOTES COMPUT SC, V3540, P35
   Micusík B, 2006, LECT NOTES COMPUT SC, V3952, P468
   Pavlovic V, 2001, CVPR, P1
   Phung SL, 2005, IEEE T PATTERN ANAL, V27, P148, DOI 10.1109/TPAMI.2005.17
   Phung SL, 2001, IEEE IJCNN, P2844, DOI 10.1109/IJCNN.2001.938827
   Quinlan J.R., 1993, C4.5 : programs for machine learning
   Schettini R, 2003, PROC SPIE, V5150, P2105, DOI 10.1117/12.503338
   Schmugge SJ, 2007, COMPUT VIS IMAGE UND, V108, P41, DOI 10.1016/j.cviu.2006.10.009
   Sebe N, 2004, INT C PATT RECOG, P903, DOI 10.1109/ICPR.2004.1334405
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Sigal L, 2004, IEEE T PATTERN ANAL, V26, P862, DOI 10.1109/TPAMI.2004.35
   Stöttinger J, 2009, LECT NOTES COMPUT SC, V5876, P303, DOI 10.1007/978-3-642-10520-3_28
   Stokman H, 2005, PROC CVPR IEEE, P560
   Storring M., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P64, DOI 10.1109/AFGR.2000.840613
   Stottinger J, 2012, CVPR
   Terrillon Jean-Christophe., 2000, P THE12TH C VISION I, P180
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang SL, 2005, LECT NOTES ARTIF INT, V3614, P324
   Wong KW, 2003, SIGNAL PROCESS-IMAGE, V18, P103, DOI 10.1016/S0923-5965(02)00088-7
   Yang MH, 1998, PROC SPIE, V3656, P458, DOI 10.1117/12.333865
   Zabih R, 2004, PROC CVPR IEEE, P437
   Zarit B. D., 1999, Proceedings International Workshop on Recognition, Analysis, and Tracking of Faces and Gestures in Real-Time Systems. In Conjunction with ICCV'99 (Cat. No.PR00378), P58, DOI 10.1109/RATFG.1999.799224
   Zheng Q.-F., 2004, IEEE P 3 INT C IM GR, P150
NR 56
TC 7
Z9 7
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2014
VL 69
IS 3
BP 717
EP 741
DI 10.1007/s11042-012-1124-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4HM
UT WOS:000333209300008
DA 2024-07-18
ER

PT J
AU Korus, P
   Bialas, J
   Dziech, A
AF Korus, Pawel
   Bialas, Jaroslaw
   Dziech, Andrzej
TI A new approach to high-capacity annotation watermarking based on digital
   fountain codes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Annotation watermarking; Watermark coding;
   Multiple watermarking; Digital fountain codes
ID SCHEME
AB Annotation watermarking is a technique that allows to associate content descriptions with digital images in a persistent and format independent manner. It is commonly used in medical applications and, hence, existing schemes have been designed to meet rigorous watermark transparency requirements. As a result, the effective capacity of such schemes is severely limited. In this paper, we present a new approach to annotation watermarking. We adopt the fountain coding paradigm and design a convenient watermark communication architecture which resembles a traditional packet network. Our approach allows for straightforward incorporation of content adaptivity, robustness against cropping and support for multiple data streams. In our study, we focus on high-capacity annotations and we assume different requirements with respect to the fidelity of the watermarked images. Our scheme is robust against lossy JPEG compression and cropping. This paper describes the principles of the proposed approach and presents the results of it's experimental evaluation.
C1 [Korus, Pawel; Bialas, Jaroslaw; Dziech, Andrzej] AGH Univ Sci & Technol, Dept Telecommun, PL-30059 Krakow, Poland.
C3 AGH University of Krakow
RP Korus, P (corresponding author), AGH Univ Sci & Technol, Al Mickiewicza 30, PL-30059 Krakow, Poland.
EM korus@kt.agh.edu.pl
RI Dziech, Andrzej/M-4483-2016; Korus, Pawel/J-7454-2012
OI Korus, Pawel/0000-0002-4230-9853
FU INDECT project; European Community's Seventh Framework Programme
   [218086]; European Regional Development Fund under INSIGMA project
   [POIG.01.01.02-00-062/09]
FX The research leading to these results has received funding from the
   INDECT project funded by European Community's Seventh Framework
   Programme under grant agreement no. 218086 and from the European
   Regional Development Fund under INSIGMA project no.
   POIG.01.01.02-00-062/09. The latter has provided an implementation of
   the digital fountain coding toolkit and the SPOMF-based watermark
   detector.
CR Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chen Z, 2010, ICCAD-IEEE ACM INT, P149, DOI 10.1109/ICCAD.2010.5654124
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Eggers JJ, 2003, IEEE T SIGNAL PROCES, V51, P1003, DOI 10.1109/TSP.2003.809366
   Fridrich Jessica, 2010, Steganography in digital media: Principles, algorithms and applications
   Giakoumaki A, 2003, P ANN INT IEEE EMBS, V25, P856, DOI 10.1109/IEMBS.2003.1279900
   He S, 2009, IEEE T IMAGE PROCESS, V18, P429, DOI 10.1109/TIP.2008.2008733
   Hyytia E, 2006, 6 INT WORKSH RAR EV
   Kalker T, 1999, PROC SPIE, V3657, P103, DOI 10.1117/12.344661
   Korus P, 2011, COMM COM INF SC, V149, P1
   Luby M, 2002, P 43 ANN IEEE S FDN, P16
   MacKay DJC, 2005, IEE P-COMMUN, V152, P1062, DOI 10.1049/ip-com:20050237
   Schott M, 2009, 2009 PROCEEDINGS OF 6TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS (ISPA 2009), P483
   Shokrollahi A, 2006, IEEE T INFORM THEORY, V52, P2551, DOI 10.1109/TIT.2006.874390
   Sun G, 2007, 2 INT C INN COMP INF, P607, DOI [10.1109/ICICIC.2007.216, DOI 10.1109/ICICIC.2007.216]
   Zain JM, 2005, P ANN INT IEEE EMBS, P3759, DOI 10.1109/IEMBS.2005.1617302
NR 16
TC 7
Z9 11
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2014
VL 68
IS 1
BP 59
EP 77
DI 10.1007/s11042-011-0986-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 283JZ
UT WOS:000329243600005
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhang, D
   Wang, YH
   Zhang, ZX
   Hu, MD
AF Zhang, De
   Wang, Yunhong
   Zhang, Zhaoxiang
   Hu, Maodi
TI Estimation of view angles for gait using a robust regression method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gait; Robust regression; View estimation; Gender classification
ID RECOGNITION; FACE
AB The performance of most gait recognition methods would drop down if the viewpoint of test data is different from the viewpoint of training data. In this paper, we present an idea of estimating the view angle of a test sample in advance so as to compare it with the corresponding training samples with the same or approximate viewpoint. In order to obtain reliable estimation results, the view-sensitive features should be extracted. We propose a novel and effective feature extraction method to characterize the silhouettes from different views. The discrimination power of this representation is also verified through experiments. Afterwards, the robust regression method is employed to estimate the viewpoint of gait. The view angles of test samples from BUAA-IRIP Gait Database are estimated with the regression models learned from CASIA Gait Database. Compared with the ground truth angles, such estimation is satisfactory with a small error level. Therefore, it can provide necessary help for gait application systems when the view angles of test data are uncertain. This point is verified experimentally through integrating the view angle estimation into a gait based gender classification system.
C1 [Zhang, De; Wang, Yunhong; Zhang, Zhaoxiang; Hu, Maodi] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
   [Zhang, De; Wang, Yunhong; Zhang, Zhaoxiang; Hu, Maodi] Beihang Univ, Sch Comp Sci & Engn, Lab Intelligent Recognit & Image Proc, Beijing 100191, Peoples R China.
C3 Beihang University; Beihang University
RP Wang, YH (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
EM zhangde2000@163.com; yhwang@buaa.edu.cn; zxzhang@buaa.edu.cn;
   londeehu@gmail.com
FU National Basic Research Program of China [2010CB327902]; National
   Natural Science Foundation of China [61005016, 61061130560]; Fundamental
   Research Funds for the Central Universities
FX This work was funded by the National Basic Research Program of China
   under Grant 2010CB327902, by the National Natural Science Foundation of
   China under Grants 61005016, and 61061130560, and by the Fundamental
   Research Funds for the Central Universities.
CR [Anonymous], 2006, 2006 C COMP VIS PATT, DOI DOI 10.1109/CVPRW.2006.216
   BenAbdelkader C, 2001, LECT NOTES COMPUT SC, V2091, P284
   Bouchrika I, 2009, LECT NOTES COMPUT SC, V5558, P990, DOI 10.1007/978-3-642-01793-3_100
   Cunado D., 1999, P 2 INT C AUDIOAND V, P43
   DEMPSTER WT, 1967, AM J ANAT, V120, P33, DOI 10.1002/aja.1001200104
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   Han J., 2005, IEEE INT C IM PROC 2, V3, P297
   Huber P., 2009, Wiley Series in Probability and Statistics, V2nd, DOI DOI 10.1002/9780470434697.CH7
   HUBER PJ, 1964, ANN MATH STAT, V35, P73, DOI 10.1214/aoms/1177703732
   Jean F, 2008, INT C PATT RECOG, P3897
   Kale A, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P143, DOI 10.1109/AVSS.2003.1217914
   Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553
   Makihara Y, 2006, INT C PATT RECOG, P96
   Makihara Y, 2006, LECT NOTES COMPUT SC, V3953, P151, DOI 10.1007/11744078_12
   Michela G., 2008, IEEE International Conference on Biometrics: Theory, Applications And Systems, BTAS, P1, DOI DOI 10.1109/AFGR.2008.4813366.
   Nixon MS, 2006, P IEEE, V94, P2013, DOI 10.1109/JPROC.2006.886018
   NIYOGI SA, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P469, DOI 10.1109/CVPR.1994.323868
   Rogez G, 2004, P BRIT MACH VIS C, V2, P659
   Rousseeuw P. J., 1984, LECTURE NOTES STATIS, V26, P256, DOI [DOI 10.1007/978-1-4615-7821-5_15, 10.1007/978-1-4615-7821-5_15]
   Shakhnarovich G, 2001, PROC CVPR IEEE, P439
   Tanawongsuwan R, 2001, PROC CVPR IEEE, P726
   Weisberg S., 2004, APPL LINEAR REGRESSI, V3rd
   YOHAI VJ, 1987, ANN STAT, V15, P642, DOI 10.1214/aos/1176350366
   Yu SQ, 2006, INT C PATT RECOG, P441
   Zhang D., 2010, 2010 IEEE COMPUTER S, P108
NR 25
TC 5
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2013
VL 65
IS 3
BP 419
EP 439
DI 10.1007/s11042-012-1045-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 144EO
UT WOS:000318922600005
DA 2024-07-18
ER

PT J
AU Khan, A
   Jaffar, MA
   Choi, TS
AF Khan, Ahmad
   Jaffar, M. Arfan
   Choi, Tae-Sun
TI SOM and fuzzy based color image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Self Organizing Map (SOM); Segmentation; FCM; Cluster center
AB Spatial information enhances the quality of clustering which is not utilized in the conventional FCM. Normally fuzzy c-mean (FCM) algorithm is not used for color image segmentation and also it is not robust against noise. In this paper, we presented a modified version of fuzzy c-means (FCM) algorithm that incorporates spatial information into the membership function for clustering of color images A progressive technique based on SOM is used to automatically find the number of optimal clusters. The results show that our technique outperforms state-of-the art methods.
C1 [Khan, Ahmad; Jaffar, M. Arfan] Natl Univ Comp & Emerging Sci, NU FAST, Islamabad, Pakistan.
   [Jaffar, M. Arfan; Choi, Tae-Sun] Gwangju Inst Sci & Technol, Dept Mechatron, Kwangju, South Korea.
C3 Gwangju Institute of Science & Technology (GIST)
RP Jaffar, MA (corresponding author), Gwangju Inst Sci & Technol, Dept Mechatron, Kwangju, South Korea.
EM ahmadkhan.nu@gmail.com; arfanjaffar@gist.ac.kr; tschoi@gist.ac.kr
RI Jaffar, Arfan/GQB-2768-2022; Khan, Ahmad/AAG-1269-2020
OI Khan, Ahmad/0000-0002-6955-8876; Choi, Tae-Sun/0000-0001-7496-2438
FU NRF [2011-0015740]; MEST
FX This work (2011-0015740) was supported by Mid-career Researcher Program
   through NRF grant funded by the MEST.
CR [Anonymous], UCBEECS2006195
   Beucher S., 2018, Mathematical Morphology in Image Processing, P433
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   CHONG RM, 2010, J CONVERGENCE, V1, P49
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Comaniciu D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1197, DOI 10.1109/ICCV.1999.790416
   Duda R. O., 2001, PATTERN CLASSIFICATI, P517
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Ilea DE, 2008, IEEE T IMAGE PROCESS, V17, P1926, DOI 10.1109/TIP.2008.2001047
   Kohonen T., 2001, SPRINGER SERIES INFO, V30, P1
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Loo PK, 2004, LECT NOTES COMPUT SC, V3163, P264
   Lucchese L., 2001, PINSA-A (Proceedings of the Indian National Science Academy) Part A (Physical Sciences), V67, P207
   Martin D., 2001, P ICCV, P416, DOI [DOI 10.1109/ICCV.2001.937655, 10.1109/ICCV.2001.937655]
   Mortensen EN, 1998, GRAPH MODEL IM PROC, V60, P349, DOI 10.1006/gmip.1998.0480
   Mukhopadhyay A, 2009, IEEE T EVOL COMPUT, V13
   Ponomarchuk Y., 2010, Journal of Convergence, V1, P35
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Sathappan OL, 2010, IJITCC, V1, P146
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Tan KS, 2011, PATTERN RECOGN, V44, P1, DOI 10.1016/j.patcog.2010.07.013
   Tsekouras GE., 2004, INT J COMPUT INTELL, V1, P87
   Tu ZW, 2005, IEEE I CONF COMP VIS, P670
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   Ye Y, 2010, INT J INF TECHNOL CO, V1, P206
NR 27
TC 15
Z9 15
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2013
VL 64
IS 2
BP 331
EP 344
DI 10.1007/s11042-012-1003-6
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 116IM
UT WOS:000316876200007
DA 2024-07-18
ER

PT J
AU Yao, XW
   Wang, WL
   Yang, SH
   Chen, SY
AF Yao, Xin-wei
   Wang, Wan-liang
   Yang, Shuang-hua
   Chen, Sheng-yong
TI PABM-EDCF: parameter adaptive bi-directional mapping mechanism for video
   transmission over WSNs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bidirectional mapping; Parameter adaptive; Congestion awareness;
   Cross-layer; Wireless video transmission
ID WIRELESS; STREAMS
AB To support and keep high quality of video transmission over wireless sensor networks, this paper proposes a parameter adaptive bi-directional cross-layer mapping algorithm on the basis of the operation mechanism of IEEE 802.11e Enhanced Distributed Coordination Function (EDCF) supporting video service differentiation, named PABM-EDCF. Instead of classifying video data to a specific access category in 802.11e network, our proposed adaptive cross-layer scheme makes use of the hierarchy characteristic of video stream, dynamically maps video data to the appropriate access categories according to both the significance of the different video frames and the network traffic load. The significance passes from the application layer to the media access layer through a cross-layer architecture. In order to prevent the network congestion and keep the high transmission quality, the proposed algorithm adopts bi-directional floating mapping algorithm and congestion awareness mechanism based on the queue length and frame types. The mapping parameters are updated according to the network condition in time. Our simulation results indicate: the proposed method (a) improves the video transmission quality; (b) optimizes the management and utilization of queue resources; and (c) yields superior performance (under different loads) over 802.11e, static mapping and adaptive mapping schemes.
C1 [Yao, Xin-wei; Wang, Wan-liang; Chen, Sheng-yong] Zhejiang Univ Technol, Dept Comp Sci & Technol, Hangzhou 310023, Zhejiang, Peoples R China.
   [Yang, Shuang-hua] Univ Loughborough, Dept Comp Sci, Loughborough LE11 3TU, Leics, England.
C3 Zhejiang University of Technology; Loughborough University
RP Yao, XW (corresponding author), Zhejiang Univ Technol, Dept Comp Sci & Technol, Hangzhou 310023, Zhejiang, Peoples R China.
EM yxw_zjut@hotmail.com; wwl@zjut.edu.cn; S.H.Yang@Lboro.ac.uk; sy@ieee.org
RI Wang, Wanliang/G-5024-2011; Yao, Xin-Wei/J-6688-2019; Yang,
   Shuang-Hua/GZA-7839-2022; Chen, S./H-3083-2011
OI Yao, Xin-Wei/0000-0001-6352-3165; Chen, S.Y./0000-0002-6705-3831
FU National Natural Science Foundation of China [61070043, 60573123]
FX This work was supported by the National Natural Science Foundation of
   China (Grant Nos. 61070043,60573123).
CR Antoniou P, 2010, COMPUT COMMUN, V33, P2039, DOI 10.1016/j.comcom.2010.07.020
   Chilamkurti N, 2010, MULTIMED TOOLS APPL, V47, P189, DOI 10.1007/s11042-009-0413-6
   Dua A, 2010, IEEE T WIREL COMMUN, V9, P1001, DOI 10.1109/TWC.2010.03.070120
   Foh CH, 2007, IEEE T CIRC SYST VID, V17, P1665, DOI 10.1109/TCSVT.2007.903808
   Huang JW, 2010, IEEE T SIGNAL PROCES, V58, P3635, DOI 10.1109/TSP.2010.2046894
   IEEE, 2005, 80211E2005 IEEE
   Khoukhi L, 2010, COMPUT NETW, V54, P1692, DOI 10.1016/j.comnet.2010.01.014
   Ksentini A, 2006, IEEE COMMUN MAG, V44, P107, DOI 10.1109/MCOM.2006.1580940
   Lin CH, 2009, TELECOMMUN SYST, V42, P223, DOI 10.1007/s11235-009-9182-9
   Pudlewski S, 2010, COMPUT COMMUN, V33, P1380, DOI 10.1016/j.comcom.2010.02.016
   Zhu XQ, 2011, IEEE T CIRC SYST VID, V21, P1181, DOI 10.1109/TCSVT.2011.2129690
   Zhu XQ, 2009, IEEE T MULTIMEDIA, V11, P752, DOI 10.1109/TMM.2009.2017641
   Ziviani A, 2005, MULTIMED TOOLS APPL, V26, P59, DOI 10.1007/s11042-005-6849-4
NR 13
TC 2
Z9 4
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2013
VL 63
IS 3
BP 809
EP 831
DI 10.1007/s11042-011-0934-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 110YF
UT WOS:000316483000010
DA 2024-07-18
ER

PT J
AU Tian, YS
   Yap, KH
   He, Y
AF Tian, Yushuang
   Yap, Kim-Hui
   He, Yu
TI Vehicle license plate super-resolution using soft learning prior
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE License plate super-resolution; Soft learning prior; Optical character
   recognition
ID IMAGE REGISTRATION; LIMITS
AB This paper proposes a new algorithm to perform single-frame image super-resolution (SR) of vehicle license plate (VLP) using soft learning prior. Conventional single-frame SR/interpolation methods such as bi-cubic interpolation often experience over-smoothing near the edges and textured regions. Therefore, learning-based methods have been proposed to handle these shortcomings by incorporating a learning term so that the reconstructed high-resolution images can be guided towards these models. However, existing learning-based methods employ a binary hard-decision approach to determine whether the prior models are fully relevant or totally irrelevant. This approach, however, is inconsistent with many practical applications as the degree of relevance for the prior models may vary. In view of this, this paper proposes a new framework that adopts a soft learning approach in license plate super-resolution. The method integrates image SR with optical character recognition (OCR) to perform VLP SR. The importance of the prior models is estimated through relevance scores obtained from the OCR. These are then incorporated as a soft learning term into a new regularized cost function. Experimental results show that the proposed method is effective in handling license plate SR in both simulated and real experiments.
C1 [Tian, Yushuang; Yap, Kim-Hui; He, Yu] Nanyang Technol Univ, Sch Elect & Elect Engn, Media Technol Lab, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Yap, KH (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Media Technol Lab, Block S2-2,Nanyang Ave, Singapore 639798, Singapore.
EM tian0042@e.ntu.edu.sg; ekhyap@ntu.edu.sg; heyu@ntu.edu.sg
OI Yap, Kim-Hui/0000-0003-1933-4986
CR [Anonymous], 1982, Digital Picture Processing
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Blu T, 2004, IEEE T IMAGE PROCESS, V13, P710, DOI 10.1109/TIP.2004.826093
   Chang SL, 2004, IEEE T INTELL TRANSP, V5, P42, DOI 10.1109/TITS.2004.825086
   Chen L, 2005, ICIP, P1014
   Datsenko D, 2007, MULTIDIM SYST SIGN P, V18, P103, DOI 10.1007/s11045-007-0018-z
   EI-Khamy SE, 2005, DIGIT SIGNAL PROCESS, V15, P137, DOI 10.1016/j.dsp.2004.10.003
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Han P, 2003, 2003 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-5, PROCEEDINGS, P128, DOI 10.1109/ICMLC.2003.1264456
   He Y, 2007, IEEE T IMAGE PROCESS, V16, P2830, DOI 10.1109/TIP.2007.908074
   Hong KP, 1996, IEEE T CONSUM ELECTR, V42, P279, DOI 10.1109/30.536121
   Hwang JW, 2004, IEEE SIGNAL PROC LET, V11, P359, DOI 10.1109/LSP.2003.821718
   KANG MG, 1992, IEEE T SIGNAL PROCES, V40, P2329, DOI 10.1109/78.157234
   Kazemi FM, 2007, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, PROCEEDINGS, P516
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Lin ZC, 2004, IEEE T PATTERN ANAL, V26, P83, DOI 10.1109/TPAMI.2004.1261081
   Nijhuis JAG, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P2232, DOI 10.1109/ICNN.1995.487708
   Ramponi G, 1999, IEEE T IMAGE PROCESS, V8, P629, DOI 10.1109/83.760311
   Suresh KV, 2006, GRAPHICS IMAGE PROCE, V4338, P24
   Yap KH, 2009, IEEE SIGNAL PROC LET, V16, P981, DOI 10.1109/LSP.2009.2028106
   Zhang YG, 2003, IEEE IV2003: INTELLIGENT VEHICLES SYMPOSIUM, PROCEEDINGS, P106, DOI 10.1109/IVS.2003.1212892
NR 22
TC 16
Z9 16
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2012
VL 60
IS 3
BP 519
EP 535
DI 10.1007/s11042-011-0821-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 965ZC
UT WOS:000305805300003
DA 2024-07-18
ER

PT J
AU Karime, A
   Hossain, MA
   Rahman, ASMM
   Gueaieb, W
   Alja'am, JM
   El Saddik, A
AF Karime, Ali
   Hossain, M. Anwar
   Rahman, A. S. M. Mahfujur
   Gueaieb, Wail
   Alja'am, Jihad Mohamed
   El Saddik, Abdulmotaleb
TI RFID-based interactive multimedia system for the children
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RFID; Interactive multimedia system; Edutainment
AB In this paper, we present an interactive edutainment system for the children that leverages multimedia and RFID technologies in a seamless manner. The proposed system allows children to learn about new objects/entities by tapping on physical objects through a specially designed RFID-Bluetooth based Tangible User Interface (TUI) tool. The output of the system is delivered as a set of appropriate multimedia representations related to the objects being tapped. The TUI uses RFID technology for object identification and Bluetooth communication to transmit data to the computer where the system's software is running. We incorporated our system in three games that allow children of different ages to benefit from the system's functionalities and encourage them to interact with it.
C1 [Karime, Ali; Gueaieb, Wail; El Saddik, Abdulmotaleb] Univ Ottawa, Multimedia Commun Res Lab, Sch Informat Technol & Engn, Ottawa, ON, Canada.
   [Hossain, M. Anwar] King Saud Univ, Coll Comp & Informat Sci, Software Engn Dept, Riyadh, Saudi Arabia.
   [Alja'am, Jihad Mohamed] Qatar Univ, Dept Comp Sci & Engn, Doha, Qatar.
   [Alja'am, Jihad Mohamed] Qatar Univ, Dept Comp Sci, Doha, Qatar.
C3 University of Ottawa; King Saud University; Qatar University; Qatar
   University
RP Karime, A (corresponding author), Univ Ottawa, Multimedia Commun Res Lab, Sch Informat Technol & Engn, Ottawa, ON, Canada.
EM ali@mcrlab.uottawa.ca; mahossain@ksu.edu.sa; Kafi@mcrlab.uottawa.ca;
   wgueaieb@site.uottawa.ca; jaam@qu.edu.qa; abed@mcrlab.uottawa.ca
RI ; Hossain, M. Anwar/J-9601-2013; /D-4159-2009
OI Karime, Ali/0000-0001-7826-1540; Hossain, M. Anwar/0000-0002-7673-8410;
   /0000-0002-7690-8547; Rahman, A S M Mahfujur/0000-0002-8243-1191
CR C# Custom Shape Region, 2010, C CUSTOM SHAPE REGIO
   Carbonaro M, 2008, COMPUT EDUC, V51, P687, DOI 10.1016/j.compedu.2007.07.007
   Chipman G., 2006, P 2006 C INT DES CHI, P1, DOI [10.1145/1139073.1139081, DOI 10.1145/1139073.1139081]
   Colace F., 2008, 3rd International Conference on Information and Communication Technologies, P1
   Druin A., 1996, DESIGNING MULTIMEDIA
   El Saddik A, 2008, IEEE T INSTRUM MEAS, V57, P1830, DOI 10.1109/TIM.2008.919867
   Fisher-Price, 2010, SMART CYCL
   Forsyth DA, 1999, INT J COMPUT VISION, V32, P63, DOI 10.1023/A:1008145029462
   Garzotto F., 2006, P 2006 C INTERACTION, P113, DOI DOI 10.1145/1139073.1139102
   Gerald F., 2007, Proceedings of the international workshop on Educational multimedia and multimedia education, P1
   Google Ajax Language API, 2009, GOOGL AJ LANG API
   Greetz C., 2005, DAEDALUS, V134
   Grover F. W., 1946, Inductance Calculations: Working Formulas and Tables
   Hammami M, 2003, IEEE/WIC INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, PROCEEDINGS, P574
   Ip HHS, 2006, LECT NOTES COMPUT SC, V3942, P484, DOI 10.1007/11736639_60
   Johnson A, 1998, P IEEE VIRT REAL ANN, P176, DOI 10.1109/VRAIS.1998.658487
   Karime A, 2009, IEEE INT CON MULTI, P1338, DOI 10.1109/ICME.2009.5202750
   LeapFrog, 2008, LEAPSTER2
   Mahfujur Rahman ASM, 2008, INT J ADV M IN PRESS
   Microsoft Agent, 2009, MICR AG
   Muda Z, 2006, INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MODELLING, CONTROL & AUTOMATION JOINTLY WITH INTERNATIONAL CONFERENCE ON INTELLIGENT AGENTS, WEB TECHNOLOGIES & INTERNET COMMERCE, VOL 2, PROCEEDINGS, P497
   Okan Z., 2007, British Journal of Education Technology, V34, P255
   Raffle H., 2007, P INT C COMPUTER GRA, P137, DOI DOI 10.1145/1297277.1297306
   Rahman AM, 2006, 3 ANN E LEARN C INT
   Read J. C., 2008, P 3 INT C DIG INT ME, P85, DOI [10.1145/1413634.1413654, DOI 10.1145/1413634.1413654]
   Rehm M, 2006, LECT NOTES ARTIF INT, V4021, P197
   Ryokai K., 2004, CHI 04, P303, DOI DOI 10.1145/985692.985731
   Ryokai Kimiko., 1999, CHI '99 Extended Abstracts on Human Factors in Computing Systems. CHI EA '99, P272
   Said N.S., 2004, P 2004 C INTERACTION, P169
   Sung YT, 2008, COMPUT EDUC, V50, P1037, DOI 10.1016/j.compedu.2006.07.011
   Titzer RC, 2009, YOUR BABY CAN READ
   VTech, 2008, BAB LEARN LAPT
   Windows Speech Recognition, 2009, WINDOWS SPEECH RECOG
   Wordnet, 2008, LEX DAT ENGL LANG
   Wu O, 2005, PROCEEDINGS OF THE 2005 IEEE INTERNATIONAL CONFERENCE ON NATURAL LANGUAGE PROCESSING AND KNOWLEDGE ENGINEERING (IEEE NLP-KE'05), P663
   Yeh T, 2008, P 16 ACM INT C MULT
   Zhou Z., 2004, P 2004 ACM SIGCHI IN, P364, DOI [DOI 10.1145/1067343.1067404, 10.1145/1067343.1067404]
NR 37
TC 12
Z9 13
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2012
VL 59
IS 3
BP 749
EP 774
DI 10.1007/s11042-011-0768-3
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 950AF
UT WOS:000304619900002
DA 2024-07-18
ER

PT J
AU Zeng, LF
   Veeravalli, B
   Wei, QS
   Feng, D
AF Zeng, Lingfang
   Veeravalli, Bharadwaj
   Wei, Qingsong
   Feng, Dan
TI SeWDReSS: on the design of an application independent, secure, wide-area
   disaster recovery storage system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Disaster recovery; Storage; Multimedia data; Erasure-coding; Replication
AB Distributed wide-area storage systems must tolerate both physical failure and logic errors. In particular, these functions are needed to enable the storage system to support remote disaster recovery. There are several solutions for distributed wide-area backup/ archive systems implemented at application level, file system level or at storage subsystem level. However, they suffer from high deployment cost and security issues. Moreover, previous researches in literature only focus on any diskrelated failures and ignore the fact that storage server linked predominantly to a Wide-Area-Network (WAN) which may be unavailable or owing to network failures. In this paper, we first model the efficiency and reliability of distributed wide area storage systems for all media, taking both network failures and disk failures into consideration. To provide higher performance, efficiency, reliability, and security to the wide-area disaster recovery storage systems, we present a configurable RAID-like data erasure-coding scheme referred to as Replication-based Snapshot Redundant Array of Independent Imagef iles (RSRAII). We argue that this scheme has benefits resulting from the consolidation of both erasure-coding and replication strategies. To this end, we propose a novel algorithm to improve the snapshot performance referred to as SMPDP (Snapshot based on Multi-Parallel Degree Pipeline). We also extend this study towards implementing a prototype system, called as SeWDReSS, which is shown to strike a tradeoff between reliability, storage space, security, and performance for distributed wide-area disaster recovery.
C1 [Zeng, Lingfang; Veeravalli, Bharadwaj] Natl Univ Singapore, Dept Elect & Comp Engn, Comp Networks & Distributed Syst Lab, Singapore 117576, Singapore.
   [Wei, Qingsong] ASTAR, Data Storage Inst, Data Ctr Technol Div, Singapore 117608, Singapore.
   [Feng, Dan] Huazhong Univ Sci & Technol, Key Lab Informat Storage, Minist Educ, Wuhan 430074, Hubei, Peoples R China.
C3 National University of Singapore; Agency for Science Technology &
   Research (A*STAR); A*STAR - Data Storage Institute; Huazhong University
   of Science & Technology
RP Veeravalli, B (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, Comp Networks & Distributed Syst Lab, Singapore 117576, Singapore.
EM elezengl@nus.edu.sg; elebv@nus.edu.sg; wei_qingsong@dsi.a-star.edu.sg;
   dfeng@hust.edu.cn
RI lin, lin/KCZ-0185-2024; WEI, Qingsong/P-4159-2019
OI Zeng, Lingfang/0000-0003-3130-3015
FU A*STAR, Singapore [R - 263 - 000 - 345 - 305]; National Basic Research
   Program of China (973 Program) [2011CB302301]
FX The authors would like to thank the referees for their comments. This
   work is supported partly by A*STAR, Singapore, under grant R - 263 - 000
   - 345 - 305, and the National Basic Research Program of China (973
   Program) No. 2011CB302301.
CR Amazon. com Inc., 2009, AM SIMPL STOR SERV
   Anastasiadis SV, 2002, USENIX ASSOCIATION PROCEEDINGS OF THE GENERAL TRACK, P191
   [Anonymous], P ICDCS 06
   [Anonymous], 3022 NETW APPL
   [Anonymous], 1995, XOR BASED ERASURE RE
   Apple Computer Inc., 2009, APPL MAC SERV
   Bell WH, 2003, CCGRID 2003: 3RD IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER COMPUTING AND THE GRID, PROCEEDINGS, P661, DOI 10.1109/CCGRID.2003.1199430
   Bhagwat Deepavali., 2006, MASCOTS, P413
   Blake Charles., 2003, Proceedings of the 9th conference on Hot Topics in Operating Systems - Volume 9, HOTOS'03, V9, P1
   CHANDY KM, 1985, ACM T COMPUT SYST, V3, P63, DOI 10.1145/214451.214456
   Chen Y, 1996, P IEEE ICDE FEB, P485
   Cheng-Fu Chou, 2000, Proceedings 20th IEEE International Conference on Distributed Computing Systems, P64, DOI 10.1109/ICDCS.2000.840908
   Chun B, 2006, P NSDI 06
   Douglis F, 2003, USENIX ASSOCIATION PROCEEDINGS OF THE GENERAL TRACK, P113
   *EMC CORP, 2002, EMC CENT CONT ADDR S
   Gerasimov I, 2003, P MSST 03
   Haeberlen A, 2005, P NSDI 05
   Hartman J. H., 1993, Operating Systems Review, V27, P29, DOI 10.1145/173668.168622
   Hennessy J.L., 2006, Computer Architecture: A Quantitative Approach'', V4th
   Iometer benchmark, 2006, IOMETER BENCHMARK
   Kubiatowicz J, 2000, P ASPLOS 00
   Laure E, 2003, ARCHITECTURE EUROPEA
   Li JY, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P121
   Maniatis P, 2005, ACM T COMPUT SYST, V23, P2, DOI 10.1145/1047915.1047917
   Mauelshagen H, 2004, P 11 LIN K ERL GERM
   Moore RW, 2002, DATA GRID IMPLEMENTA
   Muthitacharoen A, 2001, P SOSP 01
   National Security Agency, 2006, GLOB INF GRID GIG
   Patterson D, 1988, P ACM SIGMOD C, P106
   Plank J.S., 2003, Tech. Rep. UT-CS-03-504
   Ranganathan K, 2001, P INT GRID COMP WORK
   RATNASAMY S, 2001, P ACM SIGCOMM 01 SAN
   Rhea S, 2003, P FAST 03
   Rowstron A, 2003, IFIPACM INT C DISTRI
   Schnor B, 1996, PARALLEL AND DISTRIBUTED COMPUTING SYSTEMS - PROCEEDINGS OF THE ISCA 9TH INTERNATIONAL CONFERENCE, VOLS I AND II, P330
   Shenoy PJ, 1999, PERFORM EVALUATION, V38, P175, DOI 10.1016/S0166-5316(99)00044-9
   Storer MW, 2007, P 2007 USENIX TECHN
   Storer MW, 2006, P STORAGESS 06
   Trivedi KishorS., 2002, PROBABILITY STAT REL, V2nd
   UNH iSCSI reference implementation, UNH ISCSI REF IMPL
   Varma A, 1998, IEEE T COMPUT, V47, P228, DOI 10.1109/12.663770
   Wang R. Y., 1998, Performance Evaluation Review, V26, P22, DOI 10.1145/277858.277867
   Weatherspoon H, 2007, P EUROSYS 07
   Weatherspoon H, 2002, P IPTPS 02
   Weatherspoon H, 2006, UCBEECS2006130
   Xiao W, 2006, P MSST 06
   Xin Q, 2007, UCSCSSRC0706
   You LL, 2005, P ICDE 05
   Zhao B, 2001, UCBCSD011141
NR 49
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2012
VL 58
IS 3
BP 543
EP 568
DI 10.1007/s11042-011-0734-0
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 935GU
UT WOS:000303507900005
DA 2024-07-18
ER

PT J
AU Baik, S
AF Baik, Seongbok
TI Rethinking QR code: analog portal to digital world
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE QR code; Ambient media gate; Analog portal
AB In this paper, we are introducing a new view for the applications and the activities using QR codes to access the information for the objects existing in everyday human environment. This view emphasizes the possibility of the QR codes as an Analog Portal-an ambient media gate to the Digital World, because it shows the new way of access to the Internet and may be able to change the culture of retrieving information when the QR code infrastructure becomes mature.
C1 KT Network Lab, Taejon 305811, South Korea.
RP Baik, S (corresponding author), KT Network Lab, 463-1 Jeonmin, Taejon 305811, South Korea.
EM sbbaik@kt.com
CR [Anonymous], 2 INT S UB COMP SYST
   BARRETT R, 1998, UIST 98, P81
   Biggs John, 2008, SCANLIFE BARCODE SCA
   Browne J., 2007, JAPANESE COMPANIES G
   C Chih-Kai, 2010, 2010 2 INT C ED TECH
   Rekimoto Jun, CYBERCODE DESIGNING
   Robert A, 2007, 2007 INT C NEXT GEN
NR 7
TC 11
Z9 15
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2012
VL 58
IS 2
BP 427
EP 434
DI 10.1007/s11042-010-0686-9
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 921NO
UT WOS:000302484500008
DA 2024-07-18
ER

PT J
AU Wan, XM
   Jin, XG
AF Wan, Xianmei
   Jin, Xiaogang
TI Data-driven facial expression synthesis via Laplacian deformation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial animation; Motion capture; Laplacian deformation; Expression
   transfer; Multimedia application
ID CAPTURE; ANIMATION
AB Realistic talking heads have important use in interactive multimedia applications. This paper presents a novel framework to synthesize realistic facial animations driven by motion capture data using Laplacian deformation. We first capture the facial expression from a performer, then decompose the motion data into two components: the rigid movement of the head and the change of the facial expression. By making use of the local-detail preserving property of the Laplacian coordinate, we clone the captured facial expression onto a neutral 3D facial model using Laplacian deformation. We choose some expression "independent points" in the facial model as the fixed points when solving the Laplacian deformation equations. Experimental results show that our approach can synthesize realistic facial expressions in real time while preserving the facial details. We compare our method with the state-of-the-art facial expression synthesis methods to verify the advantages of our method. Our approach can be applied in real-time multimedia systems.
C1 [Wan, Xianmei; Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Zhejiang, Peoples R China.
   [Wan, Xianmei] Zhejiang Univ Finance & Econ, Hangzhou 310018, Zhejiang, Peoples R China.
C3 Zhejiang University; Zhejiang University of Finance & Economics
RP Jin, XG (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Zhejiang, Peoples R China.
EM wanxianmei@cad.zju.edu.cn; jin@cad.zju.edu.cn
FU National Key Basic Research Foundation of China [2009CB320801];
   NSFC-MSRA [60970159]; National Natural Science Foundation of China
   [60933007]; Key Technology RD Program [2007BAH11B03]; Zhejiang
   Provincial Education Department [Y201017097]
FX The authors are grateful to our anonymous reviewers for their insightful
   and constructive comments. We thank Dr. Yuwei Meng for the performance
   of the facial expressions. Special thanks go to Professor Chiew-Lan Tai
   from the Hong Kong University of Science and Technology for the
   discussion of the project. Xiaogang Jin was supported by the National
   Key Basic Research Foundation of China (Grant No. 2009CB320801), the
   NSFC-MSRA Joint Funding (Grant no. 60970159), the National Natural
   Science Foundation of China (Grant No. 60933007), and the Key Technology
   R&D Program (Grant No. 2007BAH11B03). Xianmei Wan was Supported by
   Scientific Research Fund of Zhejiang Provincial Education Department
   (Grant No. Y201017097).
CR Alexa M, 2003, VISUAL COMPUT, V19, P105, DOI 10.1007/s00371-002-0180-0
   [Anonymous], 2004, P 2004 EUR ACM SIGGR
   Bickel B., 2008, Proceedings of the 2008 ACM SIGGRAPH/Eurographics Symposium on Computer Animation (SCA '08), P57
   Bickel B, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239484
   Botsch M, 2005, COMPUT GRAPH FORUM, V24, P611, DOI 10.1111/j.1467-8659.2005.00886.x
   Cao Y., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P225
   Chou YF, 2010, MULTIMED TOOLS APPL, V47, P163, DOI 10.1007/s11042-009-0412-7
   Chuang E, 2005, ACM T GRAPHIC, V24, P331, DOI 10.1145/1061347.1061355
   Deng Z, 2008, COMPUT GRAPH FORUM, V27, P2096, DOI 10.1111/j.1467-8659.2008.01192.x
   Deng Z., 2006, P 2006 S INT 3D GRAP, P43, DOI DOI 10.1145/1111411.1111419]
   Deng Zhigang., 2007, DATA DRIVEN 3D FACIA
   Fratarcangeli M, 2007, GRAPH MODELS, V69, P106, DOI 10.1016/j.gmod.2006.09.006
   Hyewon Pyun, 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P167
   Ju E, 2008, COMPUT GRAPH FORUM, V27, P381, DOI 10.1111/j.1467-8659.2008.01135.x
   Kim SK, 2010, MULTIMED TOOLS APPL, V47, P147, DOI 10.1007/s11042-009-0411-8
   Kshirsagar S, 2001, INT FED INFO PROC, V68, P24
   Lewis J.P., 2006, ACM SIGGRAPH 2006 Courses
   Lipman Y, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P181, DOI 10.1109/SMI.2004.1314505
   Liu XC, 2008, COMPUT ANIMAT VIRT W, V19, P235, DOI 10.1002/cav.248
   Ma WC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409074
   Ma Xiaohan., 2009, Proceedings of SCA 2009, P123
   Müller M, 2005, ACM T GRAPHIC, V24, P471, DOI 10.1145/1073204.1073216
   Noh JY, 2001, COMP GRAPH, P277, DOI 10.1145/383259.383290
   Parke F.I., 1974, THESIS U UTAH
   Parke FrederickI., 1972, Proceedings of the ACM annual conference, V1, P451
   Pighin F., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P75, DOI 10.1145/280814.280825
   Pighin F., 2005, ACM SIGGRAPH 2005 CO
   Schaefer S, 2006, ACM T GRAPHIC, V25, P533, DOI 10.1145/1141911.1141920
   Sorkine O., 2003, Symposium on Geometry Processing, P42
   Sorkine O, 2006, COMPUT GRAPH FORUM, V25, P789, DOI 10.1111/j.1467-8659.2006.00999.x
   Vlasic D, 2005, ACM T GRAPHIC, V24, P426, DOI 10.1145/1073204.1073209
   Vosinakis S, 2005, MULTIMED TOOLS APPL, V25, P253, DOI 10.1007/s11042-005-5607-y
   Williams L., 1990, Computer Graphics, V24, P235, DOI 10.1145/97880.97906
   Yang CK, 2008, MULTIMED TOOLS APPL, V40, P41, DOI 10.1007/s11042-007-0184-x
   Zhao H, 2007, P COMP AN SOC AG HAS
NR 35
TC 11
Z9 20
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2012
VL 58
IS 1
BP 109
EP 123
DI 10.1007/s11042-010-0688-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 917BS
UT WOS:000302147600005
DA 2024-07-18
ER

PT J
AU Novak, D
   Mihelj, M
   Munih, M
AF Novak, Domen
   Mihelj, Matjaz
   Munih, Marko
TI Dual-task performance in multimodal human-computer interaction: a
   psychophysiological perspective
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Psychophysiology; Affective computing; Multitasking; Human-computer
   interaction; Mental workload
ID AUTONOMIC NERVOUS-SYSTEM; WORK STRESS; RESPONSES
AB This paper examines the psychophysiological effects of mental workload in single-task and dual-task human-computer interaction. A mental arithmetic task and a manual error correction task were performed both separately and concurrently on a computer using verbal and haptic input devices. Heart rate, skin conductance, respiration and peripheral skin temperature were recorded in addition to objective performance measures and self-report questionnaires. Analysis of psychophysiological responses found significant changes from baseline for both single-task and dual-task conditions. There were also significant psychophysiological differences between the mental arithmetic task and the manual error correction task, but no differences in questionnaire results. Additionally, there was no significant psychophysiological difference between performing only the mental arithmetic task and performing both tasks at once. These findings suggest that psychophysiological measures respond differently to different types of tasks and that they do not always agree with performance or with participants' subjective feelings.
C1 [Novak, Domen; Mihelj, Matjaz; Munih, Marko] Univ Ljubljana, Fac Elect Engn, Ljubljana 1000, Slovenia.
C3 University of Ljubljana
RP Novak, D (corresponding author), Univ Ljubljana, Fac Elect Engn, Trzaska 25, Ljubljana 1000, Slovenia.
EM domen.novak@robo.fe.uni-lj.si
OI Munih, Marko/0000-0001-5289-4059; Mihelj, Matjaz/0000-0003-2563-7094
FU EU [215756]; Slovenian Research Agency
FX The authors would like to thank the volunteers who participated in this
   study. The work was funded by the EU Information and Communication
   Technologies Collaborative Project MIMICS grant 215756 and additionally
   supported by the Slovenian Research Agency.
CR Backs RW, 2003, HUM FACTORS, V45, P525, DOI 10.1518/hfes.45.4.525.27089
   Backs RW, 1997, ACTA PSYCHOL, V96, P167, DOI 10.1016/S0001-6918(97)00010-3
   BOITEN F, 1993, INT J PSYCHOPHYSIOL, V15, P91, DOI 10.1016/0167-8760(93)90067-Y
   Camm AJ, 1996, EUR HEART J, V17, P354
   Chen JYC, 2009, PRESENCE-TELEOP VIRT, V18, P1, DOI 10.1162/pres.18.1.1
   Collet C, 2009, APPL ERGON, V40, P23, DOI 10.1016/j.apergo.2008.01.019
   Cosic K, 2007, ANN REV CYBERTHERAPY, V5, P213
   DERRICK WL, 1988, HUM FACTORS, V30, P95, DOI 10.1177/001872088803000109
   Detenber BH, 1998, J BROADCAST ELECTRON, V42, P113
   Feldman PJ, 1999, ANN BEHAV MED, V21, P216, DOI 10.1007/BF02884836
   Gwizdka J, 2010, J AM SOC INF SCI TEC, V61, P2167, DOI 10.1002/asi.21385
   Horrey WJ, 2009, J SAFETY RES, V40, P7, DOI 10.1016/j.jsr.2008.10.011
   Kahneman D., 1973, Attention and effort
   Kahol K, 2008, MULTIMED TOOLS APPL, V37, P15, DOI 10.1007/s11042-007-0167-y
   Liu CC, 2009, INT J HUM-COMPUT INT, V25, P506, DOI 10.1080/10447310902963944
   Liu J, 2010, LECT NOTES COMPUT SC, V6461, P1, DOI [10.1109/PCSPA.2010.9, 10.1007/978-3-642-17164-2_1]
   Martinez JM, 2001, DEPRESS ANXIETY, V14, P232, DOI 10.1002/da.1072
   Mulder G., 2000, Engineering psychophysiology: Issues and applications, P139
   NIKULA R, 1991, PSYCHOPHYSIOLOGY, V28, P86, DOI 10.1111/j.1469-8986.1991.tb03392.x
   Novak D, 2010, ROBOTICA IN PRESS
   Ohsuga M, 2001, INT J PSYCHOPHYSIOL, V40, P211, DOI 10.1016/S0167-8760(00)00189-6
   Parasuraman R, 2009, MIL PSYCHOL, V21, P270, DOI 10.1080/08995600902768800
   PARKES AM, 1990, CONTEMPORARY ERGONOMICS 1990, P480
   Pashler H., 1998, Attention, DOI DOI 10.1016/J.TICS.2005.01.008
   Phillips AC, 2006, PSYCHOPHYSIOLOGY, V43, P633, DOI 10.1111/j.1469-8986.2006.00462.x
   Posner M I, 1989, J Cogn Neurosci, V1, P50, DOI 10.1162/jocn.1989.1.1.50
   Raymaekers C, 2010, MULTIMED TO IN PRESS
   Ritvanen T, 2006, APPL ERGON, V37, P311, DOI 10.1016/j.apergo.2005.06.013
   Schwerdtfeger A, 2004, INT J PSYCHOPHYSIOL, V52, P217, DOI 10.1016/j.ijpsycho.2003.10.008
   Veltman JA, 1998, ERGONOMICS, V41, P656, DOI 10.1080/001401398186829
   Wester AE, 2008, ACCIDENT ANAL PREV, V40, P1, DOI 10.1016/j.aap.2007.02.014
   Wickens C. D., 2002, Theor Issues Ergon Sci, V3, P159, DOI [10.1080/14639220210123806, DOI 10.1080/14639220210123806]
   Wilson GF, 2003, HUM FACTORS, V45, P381, DOI 10.1518/hfes.45.3.381.27252
   Xie B, 2000, WORK STRESS, V14, P74, DOI 10.1080/026783700417249
   Zhang T, 2010, THEOR ISS ERGON SCI, V11, P99, DOI 10.1080/14639220903010027
NR 35
TC 11
Z9 12
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2012
VL 56
IS 3
BP 553
EP 567
DI 10.1007/s11042-010-0619-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 891AX
UT WOS:000300189700008
DA 2024-07-18
ER

PT J
AU Arnaud, J
   Négru, D
   Sidibé, M
   Pauty, J
   Koumaras, H
AF Arnaud, Julien
   Negru, Daniel
   Sidibe, Mamadou
   Pauty, Julien
   Koumaras, Harilaos
TI Adaptive IPTV services based on a novel IP Multimedia Subsystem
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IMS; IPTV; User-profile; Adaptation; PQoS
AB Heterogeneous communication devices are emerging and changing the way of communication. Innovative multimedia applications are now accessible through these embedded systems. The 3GPP IP Multimedia Subsystem (IMS) provides a basic architecture framework for the Next Generation Network (NGN) supporting the convergence platform for service provisioning in heterogeneous networks. ETSI TISPAN standardization effort focuses on delivering IPTV services on such platform. Nevertheless, IPTV on IMS standardization suffers from a lack of efficient user-centric network management mechanisms as the end-user may consume IPTV service from different access networks, on different mobile devices, at anytime. User's Perceived Quality of Service (PQoS) or Quality of Experience (QoE) of IPTV service may also suffer from wireless access network impairments. This paper introduces new functionalities in IPTV over IMS architecture which optimize satisfaction of the end-user and resource utilization of the operator's networks. A context-sensitive User Profile (UP) model is used to deliver IPTV streams adapted to the user's environment. In order to optimize the operator network usage, the impact of spatiotemporal dynamics of the video content on the deduced perceptual quality is considered. A Multimedia Content Management System (MCMS) is proposed to perform dynamic cross-layer adaptation of the IPTV stream based on PQoS measurements at the end-user side.
C1 [Arnaud, Julien; Negru, Daniel] Univ Bordeaux, CNRS LaBRI Lab, Talence, France.
   [Sidibe, Mamadou; Pauty, Julien] Viotech Commun, Res & Dev, Versailles, France.
   [Koumaras, Harilaos] NCSR Demokritos, Inst Informat & Telecommun, Athens, Greece.
   [Negru, Daniel] Univ Bordeaux, ENSEIRB Sch Engineers, Talence, France.
   [Koumaras, Harilaos] NCSR Demokritos, Digital Commun Lab, Athens, Greece.
C3 Universite de Bordeaux; National Centre of Scientific Research
   "Demokritos"; Universite de Bordeaux; National Centre of Scientific
   Research "Demokritos"
RP Arnaud, J (corresponding author), Univ Bordeaux, CNRS LaBRI Lab, Talence, France.
EM arnaud@labri.fr; negru@labri.fr; msidibe@viotech.net;
   julien.pauty@viotech.net; koumaras@iit.demokritos.g
RI SIDIBE, Mamadou/KOC-2276-2024
OI Koumaras, Harilaos/0000-0003-0486-2700
FU European Commission [ICT-2007.1.5-214751]
FX This work is supported by the European Commission in the context of the
   ADAMANTIUM project (ICT-2007.1.5-214751). Further information is
   available at http://www.ict-adamantium.eu/.
CR *3GPP TS, 2009, 23228 3GPP TS
   AITCHELLOUCHE S, 2010, 1 IEEE INT WORKSH EM
   [Anonymous], TR126 DSL FOR
   [Anonymous], 2004, The 3G IP multimedia subsystem (IMS)
   [Anonymous], 2002, RFC3261
   *ETSI TS, 2008, 182027 ETSI TS
   FRIEDRICH O, 2008, NETW OP MAN S WORKSH, P21, DOI DOI 10.1109/NOMSW.2007.6
   KHAN A, 2010, IET COMMUNICATIONS V
   KOUMARAS H, 2008, PREENCODING PQOS ASS
   KOUMARAS H, 2009, 3 EUR S MOB MED DEL
   MASONTA MT, 2008, EL COMP ENG 2008 CCE, P453, DOI DOI 10.1109/CCECE.2008.4564575
   Poikselka M., 2006, IMS IP MULTIMEDIA CO
   ROSENBERG J, 2002, 3311 RFC
   Rosenberg J., 2002, 3264 RFC
   Schulzrinne H., 2003, RTP TRANSPORT PROTOC
   Schulzrinne H., 1998, 2326 RFC
   Song SB, 2009, LECT NOTES COMPUT SC, V5842, P189, DOI 10.1007/978-3-642-04994-1_17
   2007, XQUERY 1 0 XML QUERY
NR 18
TC 5
Z9 5
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2011
VL 55
IS 2
SI SI
BP 333
EP 352
DI 10.1007/s11042-010-0576-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 808HU
UT WOS:000293969500008
DA 2024-07-18
ER

PT J
AU Tu, WQ
   Grout, V
   Excell, P
AF Tu, Wanqing
   Grout, Vic
   Excell, Peter
TI Performance evaluation of split transmission in multihop wireless
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless multimedia; Split transmission; Performance evaluation;
   Multiple channels; Multiple radios
AB Multimedia applications in multihop wireless networks have great market potential. Multiple channels and multiple radios are commonly used for exploring multimedia transmissions in multihop wireless networks. Split transmission allows multiple channels attached to different radios simultaneously to be used, and so to achieve a fundamentally improved transmission capacity. The goal of this paper is to present a theoretical background to justify the improved performance of the split transmission. We theoretically study and prove that, by using the split transmission, the worst-case delay is decreased to sigma rho(k-1)/LCm-1 Ck-1 of that without using the split transmission, and the average delay jitter is decreased to 1/1-Pi(K-1)(J=0) alpha(J) of that without using the split transmission, and the average delay jitter is decreased to C-k 1C(p)/C-m 1[C rho + L(rho+C)] of that without using the split transmission. We believe that this is the first attempt to consider split transmission in theory. We also evaluate the performance of the split transmission in ns-2 simulations. The observed results show that the split transmission achieves shorter worst packet delays, higher average throughput, and smaller average delay jitter as compared to the performance achieved without the split transmission.
C1 Glyndwr Univ, Sch Comp, Wrexham, Wales.
   [Excell, Peter] Glyndwr Univ, Inst Arts Sci & Technol, Wrexham, Wales.
   [Excell, Peter] Univ Bradford, Sch Informat, Bradford BD7 1DP, W Yorkshire, England.
C3 Glyndwr University; Glyndwr University; University of Bradford
RP Tu, WQ (corresponding author), Glyndwr Univ, Ctr Appl Internet Res CAIR, Sch Comp & Commun Technol, Plas Coch Campus,Mold Rd, Wrexham, Wales.
EM w.tu@glyndwr.ac.uk
OI Grout, Vic/0000-0003-4330-0137; Tu, Wanqing/0000-0002-0849-6392
CR ADYA A, 2004, P BROADN 2004 25 29
   BAHL P, 2004, IEEE 802 11 AD HOC W
   *BERK UC USC ISI L, 1999, NS NOT DOC
   CAI Wandong, 2000, MULTIMEDIA COMMUNICA
   CRUZ RL, 1991, IEEE T INFORM THEORY, V37, P132, DOI 10.1109/18.61110
   CRUZ RL, 1991, IEEE T INFORM THEORY, V37, P114, DOI 10.1109/18.61109
   Ding Y., 2009, P 17 IEEE INT WORKSH
   ECHBERG AE, 1990, INT J DIGITAL ANALOG, V3, P199
   KYASANUR P, 2005, P WCNC 2005 13 17 MA
   MARINA MK, 2005, P BROADN 2005 3 7 OC
   *NETW WORK GROUP, 2002, 3393 RFC NETW WORK G
   RANIWALA A, 2004, P ACM SIGMOBILE 2004
   RANIWALA R, 2005, P INFOCOM 2005 13 17
   SHIN M, 2006, P IEEE MASS 9 12 OCT
   SIDI M, 1989, DALLAS GLOBECOM 89, VOLS 1-3, P1764, DOI 10.1109/GLOCOM.1989.64245
   SO J, 2004, P MOBIHOC 2004 24 26
   TU W, 2008, P 2008 IEEE WIR COMM
   WU S, 2000, P ISPAN 2000 WASH DC
   ZENG G, 2007, P 2007 IEEE INT C NE
   Zhang Q, 2010, J HOPKINS APL TECH D, V28, P282
   ZHENG Q, 1999, J CHINA I COMMUNICAT, V2
   ZHOU Y, 2000, P APPL TEL S 16 20 A
NR 22
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2011
VL 54
IS 3
SI SI
BP 589
EP 607
DI 10.1007/s11042-010-0559-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 790CH
UT WOS:000292565600004
OA Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU Octavia, JR
   Raymaekers, C
   Coninx, K
AF Octavia, Johanna Renny
   Raymaekers, Chris
   Coninx, Karin
TI Adaptation in virtual environments: conceptual framework and user models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual environments; Adaptation; Framework; User model
AB When interacting in a virtual environment, users are confronted with a number of interaction techniques. These interaction techniques may complement each other, but in some circumstances can be used interchangeably. Because of this situation, it is difficult for the user to determine which interaction technique to use. Furthermore, the use of multimodal feedback, such as haptics and sound, has proven beneficial for some, but not all, users. This complicates the development of such a virtual environment, as designers are not sure about the implications of the addition of interaction techniques and multimodal feedback. A promising approach for solving this problem lies in the use of adaptation and personalization. By incorporating knowledge of a user's preferences and habits, the user interface should adapt to the current context of use. This could mean that only a subset of all possible interaction techniques is presented to the user. Alternatively, the interaction techniques themselves could be adapted, e.g. by changing the sensitivity or the nature of the feedback. In this paper, we propose a conceptual framework for realizing adaptive personalized interaction in virtual environments. We also discuss how to establish, verify and apply a user model, which forms the first and important step in implementing the proposed conceptual framework. This study results in general and individual user models, which are then verified to benefit users interacting in virtual environments. Furthermore, we conduct an investigation to examine how users react to a specific type of adaptation in virtual environments (i.e. switching between interaction techniques). When an adaptation is integrated in a virtual environment, users positively respond to this adaptation as their performance significantly improve and their level of frustration decrease.
C1 [Octavia, Johanna Renny; Raymaekers, Chris; Coninx, Karin] Hasselt Univ TUL IBBT, Expertise Ctr Digital Media, B-3590 Diepenbeek, Belgium.
C3 Hasselt University
RP Octavia, JR (corresponding author), Hasselt Univ TUL IBBT, Expertise Ctr Digital Media, Wetenschapspk 2, B-3590 Diepenbeek, Belgium.
EM johanna.octavia@uhasselt.be; chris.raymaekers@uhasselt.be;
   karin.coninx@uhasselt.be
RI Octavia, Johanna Renny/ABE-2566-2020
OI Octavia, Johanna Renny/0000-0002-5581-2634
CR Bowman D. A., 2006, INT J VIRTUAL REAL, V5, P3, DOI [10.20870/IJVR.2006.5.2.2683, DOI 10.20870/IJVR.2006.5.2.2683]
   Bowman D.A., 2005, 3D User Interfaces: Theory and Practice
   Celentano Augusto., 2004, Proceedings of the Ninth International Conference on 3D Web Technology, Web3D '04, P41
   Chin DN, 2001, USER MODEL USER-ADAP, V11, P181, DOI 10.1023/A:1011127315884
   Debevc M, 1996, USER MODEL USER-ADAP, V6, P1, DOI 10.1007/BF00126652
   GAJOS KZ, 2008, THESIS U WASHINGTON
   GREENBERG S, 1985, BEHAV INFORM TECHNOL, V4, P31, DOI 10.1080/01449298508901785
   Hazlett R., 2003, CHI'03 extended abstracts on Human factors in computing systems, P734
   JAMESON A, 2001, P 17 IJCAI
   KOBSA A, 1993, HUM FAC INF, V10, P111
   Lavie T, 2010, INT J HUM-COMPUT ST, V68, P508, DOI 10.1016/j.ijhcs.2010.01.004
   Mandryk RL, 2006, BEHAV INFORM TECHNOL, V25, P141, DOI 10.1080/01449290500331156
   NOVAK D, 2009, INTERACT, V1, P490
   Octavia JR, 2009, LECT NOTES COMPUT SC, V5535, P361, DOI 10.1007/978-3-642-02247-0_37
   Poupyrev I, 1998, COMPUT GRAPH FORUM, V17, pC41
   Poupyrev I., 1996, P 9 ANN ACM S USER I, P79, DOI [DOI 10.1145/237091.237102, 10.1145/237091.237102]
   Rocchi C., 2007, PEACH - Intelligent interfaces for museum visits, P3
   VANACKEN L, 2008, ICMI 2008 CHAN CRET, P129
   Vanacken L, 2007, LECT NOTES COMPUT SC, V4849, P28, DOI 10.1007/978-3-540-77222-4_4
   Vanacken L, 2009, INT J HUM-COMPUT ST, V67, P237, DOI 10.1016/j.ijhcs.2008.09.001
   WINGRAVE CA, 2002, P 8 EGVE, P63
NR 21
TC 4
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2011
VL 54
IS 1
SI SI
BP 121
EP 142
DI 10.1007/s11042-010-0525-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 770BD
UT WOS:000291061100007
DA 2024-07-18
ER

PT J
AU Luo, B
   Wang, YT
   Liu, Y
AF Luo, Bin
   Wang, Yongtian
   Liu, Yue
TI Sensor fusion based head pose tracking for lightweight flight cockpit
   systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 2nd International Congress on Image and Signal Processing
CY OCT 17-19, 2009
CL Tianjin, PEOPLES R CHINA
SP Tianjin Univ Technol, IEEE Engn Med & Biol Soc (EMBS)
DE Sensor fusion; Head pose tracking; Lightweight flight cockpit system;
   Augmented reality
ID AUGMENTED REALITY; VISION
AB Flight cockpit head tracking systems (HTS) are one of the most important impetuses for head pose tracking in the field of augmented reality. For the purpose of implementing the natural interaction between pilot and the complete internal environment in our lightweight flight cockpit system, a head tracking system consisting of inside-out tracking (IOT) and outside-in tracking (OIT) is designed and a novel approach using sensor fusion is proposed to dynamically track pilot's head pose. The proposed approach utilizes a sensor fusion framework, composed of extended Kalman filters and fusion filter, to fuse the poses from complementary IOT and OIT. An experimental setup is established to simulate the cockpit HTS and verify the proposed approach. Experimental results show that the proposed tracking scheme based on sensor fusion is capable of achieving more accurate and stable pose outputs, extending tracking range as well as better robustness compared with single IOT or OIT.
C1 [Luo, Bin; Wang, Yongtian; Liu, Yue] Beijing Inst Technol, Sch Opt & Elect, Beijing 100081, Peoples R China.
   [Luo, Bin] China Acad Engn Phys, Inst Comp Applicat, Mianyang, Peoples R China.
C3 Beijing Institute of Technology; Chinese Academy of Engineering Physics
RP Luo, B (corresponding author), Beijing Inst Technol, Sch Opt & Elect, Beijing 100081, Peoples R China.
EM luobin1827@bit.edu.cn; wyt@bit.edu.cn; liuyue@bit.edu.cn
CR [Anonymous], COMPUTER VISION
   [Anonymous], THESIS
   [Anonymous], P ACM SIGGRAPH 97 AU
   Auer T., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P13, DOI 10.1109/IWAR.1999.803802
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Baillot Y, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P142, DOI 10.1109/ISMAR.2003.1240697
   BARSHALOM Y, 1986, IEEE T AERO ELEC SYS, V22, P803, DOI 10.1109/TAES.1986.310815
   Broll W, 2008, IEEE COMPUT GRAPH, V28, P40, DOI 10.1109/MCG.2008.85
   Chandaria J, 2007, J REAL-TIME IMAGE PR, V2, P69, DOI 10.1007/s11554-007-0043-z
   Chang KC, 1997, IEEE T AERO ELEC SYS, V33, P1271, DOI 10.1109/7.625124
   Feiner S, 1997, FIRST INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P74, DOI 10.1109/ISWC.1997.629922
   FERRIN FJ, 1991, P SOC PHOTO-OPT INS, V1456, P86, DOI 10.1117/12.45422
   Foxlin E, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P212, DOI 10.1109/ISMAR.2004.32
   Foxlin E, 2003, P IEEE VIRT REAL ANN, P199, DOI 10.1109/VR.2003.1191139
   Foxlin E, 2000, FOURTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, DIGEST OF PAPERS, P155, DOI 10.1109/ISWC.2000.888482
   Girija G, 2000, SADHANA-ACAD P ENG S, V25, P159, DOI 10.1007/BF02703756
   Hamza-Lup FG, 2007, IEEE T INF TECHNOL B, V11, P40, DOI 10.1109/TITB.2006.880552
   HARITOS T, 2005, 24 DIG AV SYST C DAS
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   HOFF W, 1998, P IWAR 98 SAN FRANC
   Hol JD, 2007, J REAL-TIME IMAGE PR, V2, P149, DOI 10.1007/s11554-007-0040-2
   HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629
   JANIN AL, 1995, P SOC PHOTO-OPT INS, V2351, P308
   Jiang BL, 2004, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2004.1310049
   JULIER S, 2000, NATO S INF PROC TECH
   Klein G, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P38, DOI 10.1109/ISMAR.2004.54
   Latham R, 1997, COMPCON IEEE, P302, DOI 10.1109/CMPCON.1997.584738
   Lin L, 2006, IEE P-VIS IMAGE SIGN, V153, P57, DOI 10.1049/ip-vis:20045181
   Marchand É, 2005, IEEE ROBOT AUTOM MAG, V12, P40, DOI 10.1109/MRA.2005.1577023
   PARK FC, 1994, IEEE T ROBOTIC AUTOM, V10, P717, DOI 10.1109/70.326576
   ROECKER JA, 1988, IEEE T AERO ELEC SYS, V24, P447, DOI 10.1109/7.7186
   Saha RK, 1996, J GUID CONTROL DYNAM, V19, P829, DOI 10.2514/3.21706
   Satoh K, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P46, DOI 10.1109/ISMAR.2003.1240687
   SCHOEN T, 2005, INT FED AUT CONTR WO
   Ward Mark., 1992, Proceedings of the 1992 symposium on Interactive 3D graphics, P43, DOI [DOI 10.1145/147156.147162, 10.1145/147156.147162]
   Welch G, 2001, PRESENCE-VIRTUAL AUG, V10, P1, DOI 10.1162/105474601750182289
   Welch G., 2002, 95041 TR U N CAR
   Yamazoe H, 2007, ELECTRON COMM JPN 2, V90, P40, DOI 10.1002/ecjb.20331
   You S, 1999, P IEEE VIRT REAL ANN, P260, DOI 10.1109/VR.1999.756960
   You SY, 2001, P IEEE VIRT REAL ANN, P71, DOI 10.1109/VR.2001.913772
   Zhang Z., 1998, A Flexible New Technique for Camera Calibration
NR 42
TC 1
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2011
VL 52
IS 1
BP 235
EP 255
DI 10.1007/s11042-010-0468-4
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 716RF
UT WOS:000286990500018
DA 2024-07-18
ER

PT J
AU Kalantidis, Y
   Tolias, G
   Avrithis, Y
   Phinikettos, M
   Spyrou, E
   Mylonas, P
   Kollias, S
AF Kalantidis, Yannis
   Tolias, Giorgos
   Avrithis, Yannis
   Phinikettos, Marios
   Spyrou, Evaggelos
   Mylonas, Phivos
   Kollias, Stefanos
TI VIRaL: Visual Image Retrieval and Localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Image clustering; Sub-linear indexing; Geotagging;
   Location recognition; Landmark recognition; Image localization
AB New applications are emerging every day exploiting the huge data volume in community photo collections. Most focus on popular subsets, e.g., images containing landmarks or associated to Wikipedia articles. In this work we are concerned with the problem of accurately finding the location where a photo is taken without needing any metadata, that is, solely by its visual content. We also recognize landmarks where applicable, automatically linking them to Wikipedia. We show that the time is right for automating the geo-tagging process, and we show how this can work at large scale. In doing so, we do exploit redundancy of content in popular locations-but unlike most existing solutions, we do not restrict to landmarks. In other words, we can compactly represent the visual content of all thousands of images depicting e.g., the Parthenon and still retrieve any single, isolated, non-landmark image like a house or a graffiti on a wall. Starting from an existing, geo-tagged dataset, we cluster images into sets of different views of the same scene. This is a very efficient, scalable, and fully automated mining process. We then align all views in a set to one reference image and construct a 2D scene map. Our indexing scheme operates directly on scene maps. We evaluate our solution on a challenging one million urban image dataset and provide public access to our service through our online application, VIRaL.
C1 [Kalantidis, Yannis] Natl Tech Univ Athens, Image & Video Anal IVA Grp Image, Athens, Greece.
C3 National Technical University of Athens
RP Kalantidis, Y (corresponding author), Natl Tech Univ Athens, Image & Video Anal IVA Grp Image, 9 Iroon Polytexneiou Str, Athens, Greece.
EM ykalant@image.ntua.gr; gtolias@image.ntua.gr; iavr@image.ntua.gr;
   finik@image.ntua.gr; espyrou@image.ntua.gr; fmylonas@image.ntua.gr;
   stefanos@image.ntua.gr
RI Mylonas, Phivos/AAF-2497-2019; Kollias, Stefanos/ACY-7285-2022; Tolias,
   Giorgos/O-9939-2017
OI Mylonas, Phivos/0000-0002-6916-3129; Phinikettos,
   Marios/0000-0002-2243-3160; Tolias, Giorgos/0000-0002-9570-3870;
   Kollias, Stefanos/0000-0003-2899-0598
FU European Commission [FP7-215453]
FX This work was partially supported by the European Commission under
   contract FP7-215453 WeKnowIt.
CR [Anonymous], 2006, P 9 EUR C COMP VIS 1
   [Anonymous], 2010, ACMMM
   [Anonymous], COMPUTER VISION PATT
   [Anonymous], COMPUTER VISION PATT
   [Anonymous], EUR C COMP VIS
   [Anonymous], 2009, WWW
   [Anonymous], [No title captured]
   [Anonymous], 2009, INT C COMP VIS
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Chum O., 2007, INT C COMP VIS
   CHUM O, 2009, COMPUTER VISION PATT
   Chum O, 2010, IEEE T PATTERN ANAL, V32, P371, DOI 10.1109/TPAMI.2009.166
   GAMMETER S, 2009, INT C COMP VIS
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Hays J., 2008, Computer Vision and Pattern Recognition (CVPR)
   HEATH K, 2010, COMPUTER VISION PATT
   JEGOU H, 2010, INT J COMPUT VISION, P1
   JOHANSSON B, 2002, IASTED INT C SIGN PR
   KALOGERAKIS E, 2009, INT C COMP VIS
   Kennedy Lyndon., 2007, Proceedings of the 15th International Conference on Multimedia, P631, DOI DOI 10.1145/1291233.1291384
   LAMPERT CH, 2009, INT C COMP VIS
   Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3
   Levenshtein V., 1965, Problems Inf. Transm., V1, P8
   Li XW, 2008, LECT NOTES COMPUT SC, V5302, P427
   Li Y., 2009, INT C COMP VIS
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   LOWE DG, 2001, COMPUTER VISION PATT
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   MCCALLUM A, 2000, 6 ACM INT C KNOWL DI, P178
   MUJA M, 2009, INT C COMP VIS
   Nister D., 2006, Computer Vision and Pattern Rrecognition (CVPR)
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   PERDOCH M, 2009, COMPUTER VISION PATT
   Quack T., 2008, CIVR, P47
   ROBERTSON D, 2004, BRIT MACH VIS C
   Schindler G., 2007, Computer Vision and Pattern Recognition
   Silpa-Anan C., 2008, COMPUTER VISION PATT, P1
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   SNAVELY N, 2006, COMPUTER GRAPHICS IN, P835
   SNAVELY N, 2008, COMPUTER VISION PATT
   STEINHOFF U, 2007, EUR C AMB INT
   Tipping M., 2001, Artificial intelligence and statistics, P129
   ZHANG W, 2006, INT S DAT PROC VIS T
   Zheng Y., 2009, Computer Vision and Pattern Recognition (CVPR)
NR 44
TC 35
Z9 38
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2011
VL 51
IS 2
SI SI
BP 555
EP 592
DI 10.1007/s11042-010-0651-7
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 709WO
UT WOS:000286472300007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Liu, D
   Hua, XS
   Zhang, HJ
AF Liu, Dong
   Hua, Xian-Sheng
   Zhang, Hong-Jiang
TI Content-based tag processing for Internet social images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social images; Tag processing; Tag ranking; Tag refinement;
   Tag-to-region assignment
AB Online social media services such as Flickr and Zooomr allow users to share their images with the others for social interaction. An important feature of these services is that the users manually annotate their images with the freely-chosen tags, which can be used as indexing keywords for image search and other applications. However, since the tags are generally provided by grassroots Internet users, there is still a gap between these tags and the actual content of the images. This deficiency has significantly limited tag-based applications while, on the other hand, poses a new challenge to the multimedia research community. It calls for a series of research efforts for processing these unqualified tags, especially in making use of content analysis techniques to improve the descriptive power of the tags with respect to the image contents. This paper provides a comprehensive survey of the technical achievements in the research area of content-based tag processing for social images, covering the research aspects on tag ranking, tag refinement and tag-to-region assignment. We review the research advances for each topic and present a brief suggestion for future promising directions.
C1 [Liu, Dong] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150006, Peoples R China.
   [Hua, Xian-Sheng] Microsoft Res Asia, Internet Media Grp, Beijing, Peoples R China.
   [Zhang, Hong-Jiang] Microsoft Adv Technol Ctr, Beijing, Peoples R China.
C3 Harbin Institute of Technology; Microsoft; Microsoft Research Asia;
   Microsoft
RP Liu, D (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150006, Peoples R China.
EM dongliu.hit@gmail.com; xshua@microsoft.com; hjzhang@microsoft.com
RI Liu, Dong/AAL-8559-2021
CR Anderson P., 2007, WHAT IS WEB 20 IDEAS
   [Anonymous], 2008, P 17 INT C WORLD WID
   [Anonymous], ACM MIR
   [Anonymous], 2006, ECCV
   [Anonymous], ACM MM
   [Anonymous], 2009, ACM CIVR
   [Anonymous], ACM MM
   CAO L, 2007, IEEE ICCV
   CHEN L, 2010, IEEE CVPR
   Chen Y., 2009, TPAMI
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   FENG S, 2010, ACM CIVR
   JEON J, ACM SIGIR
   JING S, 2008, TPAMI, V30, P1877
   KENNEDY L, 2009, ACM WSMC
   LEE S, 2010, IEEE ICME
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   LI X, 2010, ACM CIVR
   Li X, 2008, ACM MIR
   Li XR, 2009, IEEE T MULTIMEDIA, V11, P1310, DOI 10.1109/TMM.2009.2030598
   LIU D, 2009, ACM WWW
   Liu X., 2009, ACM MM
   LU Y, 2008, IEEE CVPR
   RATTENBURY T, 2007, ACM WWW
   Wang Z., 2010, ACM CIVR
   Weinberger K.Q., 2008, Proceedings of Conference on Multimedia, P111
   Yanai K., 2005, ACM MM
   ZHA J, 2009, ACM MM
NR 28
TC 26
Z9 32
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2011
VL 51
IS 2
SI SI
BP 723
EP 738
DI 10.1007/s11042-010-0647-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 709WO
UT WOS:000286472300013
DA 2024-07-18
ER

PT J
AU Bouyakoub, FM
   Belkhir, A
AF Bouyakoub, Faycal M'hamed
   Belkhir, Abdelkader
TI A similarity measure for the negotiation in web services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Negotiation; Similarity; Adaptation; User profile; Web services; SIP/SDP
AB This paper presents a new negotiation approach integrating a similarity-based metric to measure the client's satisfaction level by quantifying the correspondence between the features required by the client and the ones proposed by the service. This negotiation process is integrated within an adaptation platform for multimedia presentations supporting different types of terminals. The negotiation and adaptation processes are based on the management of user's and service's profiles. We also propose an extension of the SIP protocol to ensure the communication between the client and the server by defining new functionalities.
C1 [Bouyakoub, Faycal M'hamed; Belkhir, Abdelkader] USTHB Univ, Dept Comp Sci, Fac Elect & Comp Sci, Algiers 16111, Algeria.
C3 University Science & Technology Houari Boumediene
RP Bouyakoub, FM (corresponding author), USTHB Univ, Dept Comp Sci, Fac Elect & Comp Sci, BP 32 El Alia, Algiers 16111, Algeria.
EM bouyakoub.f.m@gmail.com; belkhir@lsi-usthb.dz
RI abdelkader, belkhir/P-6367-2016; Bouyakoub, fayçal/AAD-4852-2019
OI Bouyakoub, Faycal M'hamed/0000-0001-5941-5575; abdelkader,
   belkhir/0000-0002-1813-3384
CR [Anonymous], 1994, Rules of Encounter: Designing Conventions for Automated Negotiation among Computers
   BALDZER J, 2004, 2 S INF MOB ANW IMA, P318
   BINMORE K, 1999, APPL GAME THEORY AUT, P2
   BOUYAKOUB FM, 2006, INT C WEB INF SYST T, P487
   BOUYAKOUB FM, 2008, 2 IFIP INT C NEW TEC, P42
   BUI T, 2006, WEB SERVICES NEGOTIA, P469
   BULTERMAN D, 2001, SYNCHRONIZED MULTIME
   Chao KM, 2006, INT J WIREL INF NETW, V13, P141, DOI 10.1007/s10776-006-0031-4
   DIVAKARAN A, 2003, VIDEO MINING, P1
   FARATIN P, 2000, 4 INT C MULT SYST IC
   Fielding R., 1999, Tech. Rep
   Gulliver SR, 2004, INT J HUM-COMPUT ST, V60, P640, DOI 10.1016/j.ijhcs.2003.11.002
   Gulliver SR, 2006, ACM T MULTIM COMPUT, V2, P241, DOI 10.1145/1201730.1201731
   HANDLEY M, 1998, 2327 RFC
   Handley M., 1999, SIP: Session Initiation Protocol
   HANDLEY M, 1999, ONLINE, P2543
   HERRERA E, 2006, SOFT COMPUTING WEB I
   JACOMI M, 1997, BCS HCI, P155
   Jannach D, 2006, APPL INTELL, V24, P109, DOI 10.1007/s10489-006-6933-0
   Joachims T., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P154, DOI 10.1145/1076034.1076063
   KAZIAOUL Z, 2006, 2 IEEE INT C DISTR F, P1, DOI DOI 10.1109/DFMA.2006.296906
   LAYADA N, 2005, IEEE INT C MOB DAT M, P351
   LEMLOUMA T, 2001, P 8 INT C MULT MOD M, P187
   LIENHART R, 2003, HDB VIDEO DATABASES, P961
   Margaritidis M., 2001, Wireless Communications and Mobile Computing, V1, P141, DOI 10.1002/wcm.10
   Plesca C, 2008, INT J DIGIT MULTIMED, V2008, DOI 10.1155/2008/171385
   Pruitt D.G., 1981, Negotiation behavior
   RAGGETT D, 2008, COMPOSITE CAPABILITY
   Romero C, 2004, USER MODEL USER-ADAP, V14, P425, DOI 10.1007/s11257-004-7961-2
   Sierra C., 1999, Collaboration between Human and Artificial Societies. Coordination and Agent-Based Distributed Computing. (Lecture Notes in Artificial Intelligence Vol1624), P201
   Thang TC, 2004, LECT NOTES COMPUT SC, V3332, P347
   TUREL O, 2007, YOU CANT SHAKE HANDS, P141
   YUAN H, 2005, NEGOTIATION BASED SE
NR 33
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2010
VL 50
IS 2
BP 279
EP 312
DI 10.1007/s11042-009-0383-8
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 622XE
UT WOS:000279698700001
DA 2024-07-18
ER

PT J
AU Shirazi, J
   Ghaemmaghami, S
AF Shirazi, Jalil
   Ghaemmaghami, Shahrokh
TI Improvement to speech-music discrimination using sinusoidal model based
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio classification; Sinusoidal model
ID AUDIO CLASSIFICATION; RETRIEVAL
AB This paper addresses a model-based audio content analysis for classification of speech-music mixed audio signals into speech and music. A set of new features is presented and evaluated based on sinusoidal modeling of audio signals. The new feature set, including variance of the birth frequencies and duration of the longest frequency track in sinusoidal model, as a measure of the harmony and signal continuity, is introduced and discussed in detail. These features are used and compared to typical features as inputs to an audio classifier. Performance of these sinusoidal model features is evaluated through classification of audio into speech and music using both the GMM (Gaussian Mixture Model) and the SVM (Support Vector Machine) classifiers. Experimental results show that the proposed features are quite successful in speech/music discrimination. By using only a set of two sinusoidal model features, extracted from 1-s segments of the signal, we achieved 96.84% accuracy in the audio classification. Experimental comparisons also confirm superiority of the sinusoidal model features to the popular time domain and frequency domain features in audio classification.
C1 [Shirazi, Jalil] Islamic Azad Univ, Sci & Res Branch, Tehran, Iran.
   [Ghaemmaghami, Shahrokh] Sharif Univ Technol, Dept Elect Engn, Tehran, Iran.
   [Ghaemmaghami, Shahrokh] Sharif Univ Technol, Elect Res Ctr, Tehran, Iran.
C3 Islamic Azad University; Sharif University of Technology; Sharif
   University of Technology
RP Shirazi, J (corresponding author), Islamic Azad Univ, Sci & Res Branch, Tehran, Iran.
EM J_shirazi@iau-gonabad.ac.ir; ghaemmag@sharif.edu
OI SHIRAZI, JALIL/0000-0001-7334-5067
CR ABUQURAN AR, 2006, IEEE INT WORKSH MULT, P212
   AJMERA J, 2003, ELSEVIER T SPEECH CO, P351
   BABU J, 2007, IEEE ICSCN 2007, P16
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   CORTIZO E, 2005, EUROCON, P1666
   Duda R., 1973, Pattern Classification and Scene Analysis
   EIMALEH K, 2000, ICASSP 2000, P2445
   Guo GD, 2003, IEEE T NEURAL NETWOR, V14, P209, DOI 10.1109/TNN.2002.806626
   Jensen J, 2001, IEEE T SPEECH AUDI P, V9, P731, DOI 10.1109/89.952491
   Lagrange M, 2007, J AUDIO ENG SOC, V55, P385
   LI D, 2001, ELSEVIER PATTERN REC, P533
   Li SZ, 2000, IEEE T SPEECH AUDI P, V8, P619, DOI 10.1109/89.861383
   Lin CC, 2005, IEEE T SPEECH AUDI P, V13, P644, DOI 10.1109/TSA.2005.851880
   Lu L, 2002, IEEE T SPEECH AUDI P, V10, P504, DOI 10.1109/TSA.2002.804546
   Lu L, 2003, MULTIMEDIA SYST, V8, P482, DOI 10.1007/s00530-002-0065-0
   Mahacek P., 2008, OCEANS 2008, P1
   MCAULAY RJ, 1986, IEEE T ACOUST SPEECH, V34, P744, DOI 10.1109/TASSP.1986.1164910
   Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975
   Nunes LO, 2008, SIGMAP 2008: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND MULTIMEDIA APPLICATIONS, P84
   Rabiner L. R., 1975, DIGITAL PROCESSING S
   Ramamohan S, 2006, IEEE T AUDIO SPEECH, V14, P737, DOI 10.1109/TSA.2005.858071
   Regnier L, 2009, INT CONF ACOUST SPEE, P1685, DOI 10.1109/ICASSP.2009.4959926
   SADJADI OS, 2007, 6 IEEE ICICS, P1
   Saunders J, 1996, INT CONF ACOUST SPEE, P993, DOI 10.1109/ICASSP.1996.543290
   SCHEIRER E, 1997, P ICASSP 97 APR, P21
   Smith J, 1987, PARSHL ANAL SYNTHESI
   Somervuo P, 2006, IEEE T AUDIO SPEECH, V14, P2252, DOI 10.1109/TASL.2006.872624
   TANCEREL L, 2000, IEEE WORKSH SPEECH C, P17
   THOSHKAHNA B, 2006, IEEE INT C AC SPEECH, P425
NR 29
TC 11
Z9 12
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2010
VL 50
IS 2
BP 415
EP 435
DI 10.1007/s11042-009-0416-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 622XE
UT WOS:000279698700006
DA 2024-07-18
ER

PT J
AU Dao, MS
   Babaguchi, N
AF Dao, Minh-Son
   Babaguchi, Noboru
TI A new spatio-temporal method for event detection and personalized
   retrieval of sports video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Event detection; Data-mining; Temporal sequential patterns; Web-casting
   text; Personalized retrieval
ID PATTERNS
AB In this paper, a new spatio-temporal method for adaptively detecting events based on Allen temporal algebra and external information support is presented. The temporal information is captured by presenting events as the temporal sequences using a lexicon of non-ambiguous temporal patterns. These sequences are then exploited to mine undiscovered sequences with external text information supports by using class associate rules mining technique. By modeling each pattern with linguistic part and perceptual part those work independently and connect together via transformer, it is easy to deploy this method to any new domain (e.g baseball, basketball, tennis, etc.) with a few changes in perceptual part and transformer. Thus the proposed method not only can work well in unwell structured environments but also can be able to adapt itself to new domains without the need (or with a few modification) for external re-programming, re-configuring and re-adjusting. Results of automatic event detection progress are tailored to personalized retrieval via click-and-see style using either conceptual or conceptual-visual query scheme. Experimental results carried on more than 30 hours of soccer video corpus captured at different broadcasters and conditions as well as compared with well-known related methods, demonstrated the efficiency, effectiveness, and robustness of the proposed method in both offline and online processes.
C1 [Dao, Minh-Son; Babaguchi, Noboru] Osaka Univ, Grad Sch Engn, Div Elect Elect & Informat Engn, Dept Informat & Commun Technol,MICL, Suita, Osaka 5650871, Japan.
C3 Osaka University
RP Dao, MS (corresponding author), Osaka Univ, Grad Sch Engn, Div Elect Elect & Informat Engn, Dept Informat & Commun Technol,MICL, 2-1 Yamadaoka, Suita, Osaka 5650871, Japan.
EM dao@nanase.comm.eng.osaka-u.ac.jp; babaguchi@comm.eng.osaka-u.ac.jp
RI Dao, Minh-Son/S-5984-2019
FU Japan Society for the Promotion of Science (JSPS)
FX This work is partly supported by a Grant-in-Aid for scientific research
   from the Japan Society for the Promotion of Science (JSPS).
CR ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   CALIC J, 2005, EUR WORKSH INT KNOWL, P39
   Chen M, 2006, IEEE SIGNAL PROC MAG, V23, P38, DOI 10.1109/MSP.2006.1621447
   CHEN M, 2007, MDDM 06 C P IEEE APR, P137
   Duan LY, 2005, IEEE T MULTIMEDIA, V7, P1066, DOI 10.1109/TMM.2005.858395
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Fleischman M., 2006, MIR '06: Proceedings of the 8th ACM International Workshop on Multimedia Information Retrieval, P183
   FLEISCHMAN M, 2007, MIR 07 C P ACM SEPT, P87
   Jiang SQ, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1095
   Liu Y, 2005, INT CONF ACOUST SPEE, P421
   MISSAOUI R, 2005, MDM 05 C P ACM AUG, P43
   Pei J, 2004, IEEE T KNOWL DATA EN, V16, P1424, DOI 10.1109/TKDE.2004.77
   Sadlier DA, 2005, IEEE T CIRC SYST VID, V15, P1225, DOI 10.1109/TCSVT.2005.854237
   SEBE N, 2007, ACM MIR 07 C P, P229
   SNOEK C, 2005, J MULTIMEDIA TOOLS A, V35, P5
   Snoek CGM, 2005, IEEE T MULTIMEDIA, V7, P638, DOI 10.1109/TMM.2005.850966
   TONG X, 2004, MIR 05 C P ACM, P337
   Wang F, 2006, IEEE SYS MAN CYBERN, P4932, DOI 10.1109/ICSMC.2006.385087
   Wu SY, 2007, IEEE T KNOWL DATA EN, V19, P742, DOI [10.1109/TKDE.2007.190613, 10.1109/TKDE.2007.1032.]
   Xiong ZY, 2006, IEEE SIGNAL PROC MAG, V23, P18
   Xu C., 2006, PROC 14 ANN ACM INT, P221, DOI DOI 10.1145/1180639.1180699
   Zhao Qiankun., 2003, Sequential pattern mining: A survey, P1
   Zhu XQ, 2005, IEEE T KNOWL DATA EN, V17, P665, DOI 10.1109/TKDE.2005.83
NR 23
TC 6
Z9 7
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2010
VL 50
IS 1
SI SI
BP 227
EP 248
DI 10.1007/s11042-009-0379-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 616HE
UT WOS:000279198900011
DA 2024-07-18
ER

PT J
AU Byrne, D
   Doherty, AR
   Snoek, CGM
   Jones, GJF
   Smeaton, AF
AF Byrne, Daragh
   Doherty, Aiden R.
   Snoek, Cees G. M.
   Jones, Gareth J. F.
   Smeaton, Alan F.
TI Everyday concept detection in visual lifelogs: validation, relationships
   and trends
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Microsoft SenseCam; Lifelog; Passive photos; Concept detection;
   Supervised learning
AB The Microsoft SenseCam is a small lightweight wearable camera used to passively capture photos and other sensor readings from a user's day-to-day activities. It captures on average 3,000 images in a typical day, equating to almost 1 million images per year. It can be used to aid memory by creating a personal multimedia lifelog, or visual recording of the wearer's life. However the sheer volume of image data captured within a visual lifelog creates a number of challenges, particularly for locating relevant content. Within this work, we explore the applicability of semantic concept detection, a method often used within video retrieval, on the domain of visual lifelogs. Our concept detector models the correspondence between low-level visual features and high-level semantic concepts (such as indoors, outdoors, people, buildings, etc.) using supervised machine learning. By doing so it determines the probability of a concept's presence. We apply detection of 27 everyday semantic concepts on a lifelog collection composed of 257,518 SenseCam images from 5 users. The results were evaluated on a subset of 95,907 images, to determine the accuracy for detection of each semantic concept. We conducted further analysis on the temporal consistency, co-occurance and relationships within the detected concepts to more extensively investigate the robustness of the detectors within this domain.
C1 [Byrne, Daragh; Doherty, Aiden R.; Smeaton, Alan F.] Dublin City Univ, CLARITY Ctr Sensor Web Technol, Dublin 9, Ireland.
   [Snoek, Cees G. M.] Univ Amsterdam, Intelligent Syst Lab Amsterdam, NL-1098 XG Amsterdam, Netherlands.
   [Jones, Gareth J. F.] Dublin City Univ, Ctr Digital Video Proc, Dublin 9, Ireland.
C3 Dublin City University; University of Amsterdam; Dublin City University
RP Byrne, D (corresponding author), Dublin City Univ, CLARITY Ctr Sensor Web Technol, Dublin 9, Ireland.
EM daragh.byrne@computing.dcu.ie
OI Byrne, Daragh/0000-0001-7193-006X; Smeaton, Alan F./0000-0003-1028-8389;
   Jones, Gareth/0000-0003-2923-8365; Doherty, Aiden/0000-0003-1840-0451;
   Snoek, Cees/0000-0001-9092-1556
FU AceMedia project; Microsoft Research; Irish Research Council for Science
   Engineering and Technology; Science Foundation Ireland [07/CE/I1147]; EU
FX We are grateful to the AceMedia project and Microsoft Research for
   support. This work is supported by the Irish Research Council for
   Science Engineering and Technology, by Science Foundation Ireland under
   grant 07/CE/I1147 and by the EU IST-CHORUS project. We would also like
   to extend our thanks to the participants who made their personal lifelog
   collection available for these experiments, and who partook in the
   annotation effort.
CR [Anonymous], 2006, ACM INT C MULTIMEDIA, DOI [10.1145/1180639.1180727, DOI 10.1145/1180639.1180727]
   [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], CIVR 07
   [Anonymous], 2007, COLUMBIA U BASELINE
   [Anonymous], BIOMETRICS
   BELL G, 2007, SCI AM NEW YORK
   BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384
   Byrne D., 2007, IMAI'07-5th International Conference on Intelligent Multimedia and Ambient Intelligence, P1454
   Byrne D, 2008, LECT NOTES COMPUT SC, V5392, P15, DOI 10.1007/978-3-540-92235-3_4
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   CHANG SF, 2008, P TRECVID WORKSH GAI
   DeVaul R., 2001, REAL TIME MOTION CLA
   DOHERTY A, 2008, CIT 2008
   Doherty AidenR., 2008, INT C CONTENT BASED, P259
   DOHERTY AR, 2008, WIAMIS, P20
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   FULLER M, 2008, PIM 2008
   Geusebroek Jan -Mark, 2006, BMVC, P1029
   Geusebroek JM, 2005, INT J COMPUT VISION, V62, P7, DOI 10.1007/s11263-005-4632-7
   Gurrin C., 2008, AIRS 2008
   Hauptmann Alexander., 2007, CIVR 07, P627
   Hoang MA, 2005, SIGNAL PROCESS, V85, P265, DOI 10.1016/j.sigpro.2004.10.009
   Hodges S., 2006, UBICOMP
   JURIE F, 2005, COMP VIS 2005 ICCV 2, V1
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   LEE H, 2006, AIR WORKSH 1 INT WOR, P22
   Lin HT, 2007, MACH LEARN, V68, P267, DOI 10.1007/s10994-007-5018-6
   Naphade M.R., 2005, A light scale concept ontology for multimedia understanding for trecvid 2005
   Naphade MR, 2001, IEEE T MULTIMEDIA, V3, P141, DOI 10.1109/6046.909601
   NATSEV A, 2008, P TRECVID WORKSH 200
   OHARE N, 2006, CIVR, P529
   Snoek C.G.M., 2006, P TRECVID WORKSH GAI
   SNOEK CGM, 2007, P TRECVID WORKSH GAI
   van Gemert JC, 2010, COMPUT VIS IMAGE UND, V114, P450, DOI 10.1016/j.cviu.2009.08.004
   Vapnik V.N., 2000, The Nature of Statistical Learning Theory, DOI DOI 10.1007/978-1-4757-3264-1_1
   Wang JX, 2007, WATER POLICY, V9, P61, DOI 10.2166/wp.2007.045
   YANG J, 2006, MIR 06, P33
NR 37
TC 26
Z9 33
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2010
VL 49
IS 1
SI SI
BP 119
EP 144
DI 10.1007/s11042-009-0403-8
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 595WF
UT WOS:000277643600007
OA Green Submitted, Green Accepted
DA 2024-07-18
ER

PT J
AU Troncy, R
   Bailer, W
   Höffernig, M
   Hausenblas, M
AF Troncy, Raphael
   Bailer, Werner
   Hoeffernig, Martin
   Hausenblas, Michael
TI VAMP: a service for validating MPEG-7 descriptions w.r.t. to formal
   profile definitions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VAMP; MPEG-7 semantic validation; Semantic web application; MPEG-7
   profile ontology
ID MULTIMEDIA METADATA; OBSCURE OBJECT; DESIRE; WEB
AB MPEG-7 can be used to create complex and comprehensive metadata descriptions of multimedia content. Since MPEG-7 is defined in terms of an XML schema, the semantics of its elements has no formal grounding. In addition, certain features can be described in multiple ways. MPEG-7 profiles are subsets of the standard that apply to specific application areas and that aim to reduce this syntactic variability, but they still lack formal semantics. We propose an approach for expressing the semantics explicitly by formalizing the constraints of various profiles using ontologies, logical rules and ad-hoc programming, thus enabling interoperability and automatic use for MPEG-7 based applications. We have implemented VAMP, a full semantic validation service that detects any inconsistencies of the semantic constraints formalized. Another contribution of this paper is an analysis of how MPEG-7 is practically used. We report on experiments about the semantic validity of MPEG-7 descriptions produced by numerous tools and projects and we categorize the most common errors found.
C1 [Troncy, Raphael] EURECOM, F-06560 Sophia Antipolis, France.
   [Troncy, Raphael] CWI, NL-1098 SJ Amsterdam, Netherlands.
   [Bailer, Werner; Hoeffernig, Martin] Joanneum Res Forsch Gesell mbH, Inst Informat Syst, A-8010 Graz, Austria.
   [Hausenblas, Michael] Natl Univ Ireland, Digital Enterprise Res Inst, Galway, Ireland.
C3 IMT - Institut Mines-Telecom; EURECOM; Ollscoil na Gaillimhe-University
   of Galway
RP Troncy, R (corresponding author), EURECOM, 2229 Route Cretes, F-06560 Sophia Antipolis, France.
EM raphael.troncy@eurecom.fr; werner.bailer@joanneum.at;
   martin.hoeffernig@joanneum.at; michael.hausenblas@deri.org
RI Troncy, Raphaël/ABE-7222-2021
OI Troncy, Raphaël/0000-0003-0457-1436; Bailer, Werner/0000-0003-2442-4900;
   Hausenblas, Michael/0000-0003-0967-5998
CR [Anonymous], 2005, P 5 INT WORKSH KNOWL
   ARNDT R, 2007, 6 INT SEM WEB C ISWC, P30
   ATHANASIADIS T, 2005, 5 INT WORKSH KNOWL M
   Bailer W, 2006, 12TH INTERNATIONAL MULTI-MEDIA MODELLING CONFERENCE PROCEEDINGS, P217
   BARAL C, 1994, J LOGIC PROGRAM, V20, P73, DOI 10.1016/0743-1066(94)90025-6
   Dean M., 2004, OWL WEB ONTOLOGY LAN
   Hobbs J.R., 2006, TIME ONTOLO IN PRESS
   HOFFERNIG M, 2007, MULT MET APPL WORKSH, P155
   HUNTER J, 2001, 10 INT WORLD WID WEB, P457
   HUNTER J, 2001, 1 INT SEM WEB WORK S
   *INT ORG STAND, 2000, 8601 ISO
   MANOLA F, 2004, RDF RESSOURCE DESCRI
   Motik B, 2005, J WEB SEMANT, V3, P41, DOI 10.1016/j.websem.2005.05.001
   *MPEG 7, 2005, 1593892005 ISOIEC MP
   *MPEG 7, 2001, 15938 ISOIEC MEPG7
   *MPF, 2008, MET PROD FRAM SPEC V
   Nack F, 2005, IEEE MULTIMEDIA, V12, P54, DOI 10.1109/MMUL.2005.12
   Patel-Schneider P.F., 2004, OWL Web Ontology Lan-guage semantics and abstract syntax
   PEREIRA F, 2001, JTC1SC29WG11N4510 IS
   PFEIFFER S, 2000, WORKSH STAND INT PRA
   TRONCY R, 2006, 1 INT C SEM DIG MED, P41
   TRONCY R, 2003, 2 INT SEM WEB C ISWC
   TRONCY R, 2004, INT WORKSH MULT IM V
   TSINARAKI C, 2004, 3 INT C IM VID RETR
   van Ossenbruggen J, 2004, IEEE MULTIMEDIA, V11, P38, DOI 10.1109/MMUL.2004.36
   W3C, 2001, XML SCHEM
NR 26
TC 6
Z9 6
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2010
VL 46
IS 2-3
SI SI
BP 307
EP 329
DI 10.1007/s11042-009-0397-2
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 542GF
UT WOS:000273480300008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Lugmayr, A
   Risse, T
   Stockleben, B
   Laurila, K
   Kaario, J
AF Lugmayr, Artur
   Risse, Thomas
   Stockleben, Bjoern
   Laurila, Kari
   Kaario, Juha
TI Semantic ambient media-an introduction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 1st ACM International Workshop on Semantic Ambient Media Experience
CY OCT 31, 2008
CL Vancouver, CANADA
SP ACM
DE Ambient media; Pervasive computing; Ubiquitous computation; Smart media;
   Semantic; Web 2.0; Collaborative environments
AB The medium is the message! And the message was literacy, media democracy and music charts. Mostly one single distinguishable medium such as TV, the Web, the radio, or books transmitted the message. Now in the age of ubiquitous and pervasive computing, where information flows through a plethora of distributed interlinked media-what is the message ambient media will tell us? What does semantic mean in this context? Which experiences will it open to us? What is content in the age of ambient media? Ambient media are embedded throughout the natural environment of the consumer-in his home, in his car, in restaurants, and on his mobile device. Predominant sample services are smart wallpapers in homes, location based services, RFID based entertainment services for children, or intelligent homes. The goal of this article is to define semantic ambient media and discuss the contributions to the Semantic Ambient Media Experience (SAME) workshop, which was held in conjunction with the ACM Multimedia conference in Vancouver in 2008. The results of the workshop can be found on: http://www.ambientmediaassociation.org.
C1 [Risse, Thomas] L3S Res Ctr, Hannover, Germany.
   [Lugmayr, Artur] Tampere Univ Technol, LugYmedia Inc, FIN-33101 Tampere, Finland.
   [Stockleben, Bjoern] Rundfunk Berlin Brandenburg, Berlin, Germany.
   [Laurila, Kari; Kaario, Juha] Nokia, Tampere, Finland.
C3 Leibniz University Hannover; Tampere University
RP Risse, T (corresponding author), L3S Res Ctr, Hannover, Germany.
EM lartur@acm.org; risse@L3S.de; Bjoern.Stockleben@rbb-online.de;
   Kari.Laurila@nokia.com; Juha.Kaario@nokia.com
RI Lugmayr, Artur/AAY-7738-2020; Lugmayr, Artur/G-4357-2014
OI Lugmayr, Artur/0000-0001-6994-4470; Risse, Thomas/0000-0001-6248-1709
CR Anderson C., 2004, Wired Magazine, V12, P170
   [Anonymous], SEMANTIC WEB, DOI DOI 10.1038/SCIENTIFICAMERICAN0501-34
   [Anonymous], 1999, RESOURCE DESCRIPTION
   Berger J, 1999, Z SOZIOL, V28, P1
   BISCHOFF K, 2008, P 17 ACM C INF KNOWL
   Bowman S., 2003, We Media: How audiences are shaping the future of news and information
   CHUNG SM, 2008, P 1 ACM INT WORKSH S
   CODOGNET P, 2008, P 1 ACM INT WORKSH S
   Cunningham H., 2002, P 40 ANN M ASS COMP, P168
   DOWMAN M, 2005, 14 INT WORLD WID WEB
   Falk J, 1999, LECT NOTES COMPUT SC, V1707, P274
   FRANK J, 2008, P 1 ACM INT WORKSH S
   Fuchsberger V., 2008, P 1 ACM INT WORKSH S
   Gruber TR, 1995, INT J HUM-COMPUT ST, V43, P907, DOI 10.1006/ijhc.1995.1081
   HOSSAIN MA, 2008, P 1 ACM INT WORKSH S
   *ISTAG, 2001, SCEN AMB INT 2010 FI
   *ISTAG, 2003, AMB INT VIS IN PRESS
   Jenkins Henry, 2006, CONVERGENCE CULTURE
   Levi-Strauss Claude., 1995, MYTH MEANING CRACKIN
   LUGMAYR A, 2006, P 4 EUR ITV C ELTRUN
   LUGMAYR A, 2008, P 1 ACM INT WORKSH S
   LUGMAYR A, 2007, INTERACTIVE TV SHARE
   LUGMAYR A, 2006, TICSP 33
   LUGMAYR A, 2006, P SPIE, V6074
   Lugmayr A, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL SYMPOSIUM ON PARALLEL AND DISTRIBUTED PROCESSING WITH APPLICATIONS, P516, DOI 10.1109/ISPA.2008.141
   MANDILIAN LE, 2008, P 1 ACM INT WORKSH S
   OZEKI M, 2008, P 1 ACM INT WORKSH S
   RAFTERY T, CREATIVE WAYS REDUCI
   Rahm E, 2001, VLDB J, V10, P334, DOI 10.1007/s007780100057
   RAKKOLAINEN I, 2007, ACM C ADV COMP ENT T
   RAKKOLAINEN I, 2008, P 1 ACM INT WORKSH S
   RAKKOLAINEN I, 2002, IS T SPIE EL IM 2002, V8
   RAKKOLAINEN I, 2004, P 3 NORD C HUM COMP
   REYMANN S, 2007, INTERACTIVE TV SHARE
   RIVA G., 2005, Ambient Intelligence: the evolution of technology, communication and cognition towards the future of human-computer interaction
   SCHLOSS WA, 2008, P 1 ACM INT WORKSH S
   Schutze H, 1998, COMPUT LINGUIST, V24, P97
   SHARDA N, 2008, P 1 ACM INT WORKSH S
   SIMON R, 2008, P 12 INT C ENT MED U
   SINGH VK, 2008, P 1 ACM INT WORKSH S
   Smith M., 2004, OWL web ontology language: guide
   Srivastava J., 2000, SIGKDD EXPLORATIONS, V1, P12, DOI DOI 10.1145/846183.846188
   STREITZ N, 2005, IEEE COMPUTER    MAR, P41
   STREITZ N, 2002, CHI 02 HUM FACT COMP
   SZUMING C, 2008, P 1 ACM INT WORKSH S
   Weiser M, 1994, WORLD IS NOT DESKTOP, P7
NR 46
TC 22
Z9 23
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2009
VL 44
IS 3
BP 337
EP 359
DI 10.1007/s11042-009-0282-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 474WB
UT WOS:000268313900002
DA 2024-07-18
ER

PT J
AU Kim, JK
   Sohn, WS
   Lim, SB
   Choy, YC
AF Kim, Jae-Kyung
   Sohn, Won-Sung
   Lim, Soon-Bum
   Choy, Yoon-Chul
TI Definition of a layered avatar behavior script language for creating and
   reusing scenario scripts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE avatar; script language; behavior; motion
AB An avatar script language consists of a set of commands which are used to control avatar behaviors in cyberspace. These script languages should be abstracted from complex low-level concepts such as DOF, so that users can create scenario scripts easily without having to be concerned about the physical properties of motion. Also, the scripts should be defined in a standard format and structure so that they can be reused in various applications. In the proposed system, we defined a layered script language for avatar behavior representation and control, which consists of task-level behavior, high-level motion and primitive motion script. The high-level behavior script provides abstract and domain-dependent avatar-object behavior interfaces to the user so that the user can easily create avatar scenario scripts, the high-level motion script represents the avatar motion sequence, and the primitive motion script represents the geometric information of the underlying tools for physical animation control. A presentation domain is chosen to apply the proposed script language, and empirical evaluation shows that a novice user can easily and quickly design a scenario script using the proposed interface
C1 [Kim, Jae-Kyung; Choy, Yoon-Chul] Yonsei Univ, Dept Comp Sci, Seoul 120749, South Korea.
   [Sohn, Won-Sung] Gyeongin Natl Univ Educ, Dept Comp Educ, Seoul, South Korea.
   [Lim, Soon-Bum] Sookmyung Womens Univ, Dept Multimedia Sci, Seoul, South Korea.
C3 Yonsei University; Sookmyung Women's University
RP Kim, JK (corresponding author), Yonsei Univ, Dept Comp Sci, Seoul 120749, South Korea.
EM ki187cm@gmail.com; sohnws@gin.ac.kr; sblim@sookmyung.ac.kr;
   ycchoy@rainbow.yonsei.ac.kr
CR André E, 1998, KNOWL-BASED SYST, V11, P25, DOI 10.1016/S0950-7051(98)00057-4
   [Anonymous], P 8 INT C INT US INT
   AYLETT R, 2001, STAR REPORT INTELLIG
   Badler NI, 2000, EMBODIED CONVERSATIONAL AGENTS, P256
   Bowman DA, 1999, J VISUAL LANG COMPUT, V10, P37, DOI 10.1006/jvlc.1998.0111
   Buttussi F., 2006, P 11 INT C 3D WEB TE, V6, P109
   CAVAZZA FCM, 2002, INT AUT AG, P318
   CLAUDIO S, 2003, PERS UBIQUIT COMPUT, V7, P1
   CONWAY M., 2000, P CHI 2000, P486
   Dann WandaP., 2006, Learning to Program with Alice, Brief Edition
   DOYLE P, 2002, INT C AUTO AGENTS, V2, P342
   GILLIES M, 2004, INT C AUT AG, P336
   HAYASHI M, 2003, ACM SIGGRAPH C APPL, P292
   Huang Z., 2003, PROCEEDING 8 INT C 3, P91
   Ieronutti Lucio, 2005, WEB3D S P, P75, DOI [10.1145/1050491.1050502, DOI 10.1145/1050491.1050502]
   Kallmann M, 2002, J VISUAL LANG COMPUT, V13, P177, DOI 10.1006/jvlc.2001.0229
   KSHIRSAGAR S, 2002, P WORKSH VIRT ENV, P169
   LEBLANC JBA, 2005, P 10 INT C 3D WEB TE, P93
   LESTER C, 1999, EXPLANATORY LIFELIKE
   Lester J. C., 1997, P ACM SIGCHI C HUM F, P359, DOI [10.1145/258549.258797, DOI 10.1145/258549.258797]
   LI TY, 2004, P 2004 IEEE INT C MU
   MARRIOTT A, 2002, P EMB CONV AG AAMAS2
   PERLIN AG, 1996, P SIGGRAPH 96, P205
   Prendinger H, 2004, J VISUAL LANG COMPUT, V15, P183, DOI 10.1016/j.jvlc.2004.01.001
   Prendinger H, 2004, COG TECH, P3
   Rickel J., 2000, Task-oriented collaboration with embodied agents in virtual worlds Embodied conversational agents, P95
   SHINDO Y, 2001, INT C COMP ED, P297
   SU W, 2005, P 2 AUSTR C INT ENT, V123, P179
   THALMANN D, 1995, AUTONOMY TASK LEVEL
   Yang XL, 2003, VECIMS'03: 2003 IEEE INTERNATIONAL SYMPOSIUM ON VIRTUAL ENVIRONMENTS, HUMAN-COMPUTER INTERFACES AND MEASUREMENT SYSTEMS, P101
NR 30
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2008
VL 37
IS 2
BP 233
EP 259
DI 10.1007/s11042-007-0142-7
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 267PV
UT WOS:000253522600007
DA 2024-07-18
ER

PT J
AU Xin, J
   Li, JJ
   Vetro, A
   Sekiguchi, SI
AF Xin, Jun
   Li, Jianjun
   Vetro, Anthony
   Sekiguchi, Shun-Ichi
TI Motion mapping and mode decision for MPEG-2 to H.264/AVC transcoding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video transcoding; H.264/AVC; MPEG-2; mode decision; motion mapping
AB This paper describes novel transcoding techniques aimed for low-complexity MPEG-2 to H.264/AVC transcoding. An important application for this type of conversion is efficient storage of broadcast video in consumer devices. The architecture for such a system is presented, which includes novel motion mapping and mode decision algorithms. For the motion mapping, two algorithms are presented. Both efficiently map incoming MPEG-2 motion vectors to outgoing H.264/AVC motion vectors regardless of the block sizes that the motion vectors correspond to. In addition, the algorithm maps motion vectors to different reference pictures, which is useful for picture type conversion and prediction from multiple reference pictures. We also propose an efficient rate-distortion optimised macroblock coding mode decision algorithm, which first evaluates candidate modes based on a simple cost function so that a reduced set of candidate modes is formed, then based on this reduced set, we evaluate the more complex Lagrangian cost calculation to determine the coding mode. Extensive simulation results show that our proposed transcoder incorporating the proposed algorithms achieves very good rate-distortion performance with low complexity. Compared with the cascaded decoder-encoder solution, the coding efficiency is maintained while the complexity is significantly reduced.
C1 Mitsubishi Elect Res Labs, Cambridge, MA USA.
   Mitsubishi Electr Corp, Kamakura, Kanagawa, Japan.
C3 Mitsubishi Electric Corporation
RP Vetro, A (corresponding author), Mitsubishi Elect Res Labs, Cambridge, MA USA.
EM j_xin@yahoo.com; jli@merl.com; avetro@merl.com;
   Sekiguchi.Shunichi@eb.MitsubishiElectric.co.jp
CR [Anonymous], 2006, H 264 AVC REFERENCE
   *ISO IEC, 2000, 138182 ISO IEC
   LIM KP, 2003, JVT1020
   LU X, 2005, IEEE INT S CIRC SYST
   *MPEG SOFYW SIM GR, 1996, MPEG2 ENC DEC V1 2
   PAN F, 2003, JVTG013
   SU Y, 2005, IEEE INT S CIRC SYST
   Vetro A, 2003, IEEE SIGNAL PROC MAG, V20, P18, DOI 10.1109/MSP.2003.1184336
   Xin J, 2005, P IEEE, V93, P84, DOI 10.1109/JPROC.2004.839620
   XIN J, 2004, PICT COD S
   Zhou Z, 2005, IEEE INT SYMP CIRC S, P1230
   2003, 144960 ITUT REC H264
NR 12
TC 2
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2007
VL 35
IS 2
BP 203
EP 223
DI 10.1007/s11042-007-0125-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 212XA
UT WOS:000249629100006
DA 2024-07-18
ER

PT J
AU Li, C
   Kulkarni, PR
   Prabhakaran, B
AF Li, Chuanjun
   Kulkarni, Punit R.
   Prabhakaran, B.
TI Segmentation and recognition of motion capture data stream by
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia; classification; support vector machine; motion segmentation;
   gesture recognition; pattern analysis; singular value decomposition
ID SUPPORT VECTOR MACHINES
AB Three dimensional human motions recorded by motion capture and hand gestures recorded by using data gloves generate variable-length data streams. These data streams usually have dozens of attributes, and have different variations for similar motions. To segment and recognize motion streams, a classification-based approach is proposed in this paper. Classification feature vectors are extracted by utilizing singular value decompositions (SVD) of motion data. The extracted feature vectors capture the dominating geometric structures of motion data as revealed by SVD. Multi-class support vector machine (SVM) classifiers with class probability estimates are explored for classifying the feature vectors in order to segment and recognize motion streams. Experiments show that the proposed approach can find patterns in motion data streams with high accuracy.
C1 Univ Texas, Dept Comp Sci, Richardson, TX 75080 USA.
C3 University of Texas System; University of Texas Dallas
RP Li, C (corresponding author), Univ Texas, Dept Comp Sci, Richardson, TX 75080 USA.
EM chuanjun@utdallas.edu; prk032000@utdallas.edu; praba@utdallas.edu
CR [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], 2000, ADV LARGE MARGIN CLA
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Dyaberi Vidyarani M., 2004, P 12 ANN ACM INT C M, P332, DOI [10.1145/1027527.1027604, DOI 10.1145/1027527.1027604]
   Ganapathiraju A, 2004, IEEE T SIGNAL PROCES, V52, P2348, DOI 10.1109/TSP.2004.831018
   Golub G.H., 1989, MATRIX COMPUTATIONS
   GORDAN M, 2002, P INT C IM PROC, P24
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Kahol K, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P105
   KRZANOWSKI WJ, 1979, J AM STAT ASSOC, V74, P703, DOI 10.2307/2286995
   LI C, 2005, P 6 INT WORKSH MULT
   LI C, 2005, P 2005 IEEE INT C AC
   Li C., 2004, P ACM MULTIMEDIA C 2, P836
   Li CJ, 2006, KNOWL INF SYST, V10, P163, DOI 10.1007/s10115-005-0223-8
   Natsev A.P., 2004, PROC 10 ACM SIGKDD I, P641
   QIAN G, 2004, P IEEE INT C MULT EX
   SHAHABI C, 2001, P 9 INT C HUM COMP I, P441
   Shahabi C., 2003, P 9 INT C MULT MOD, P93
   Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811
   STEWART GW, 1973, SIAM REV, V15, P727, DOI 10.1137/1015095
   Vlachos M., 2004, KDD 04, P707, DOI DOI 10.1145/1014052.1014144
   Wu TF, 2004, J MACH LEARN RES, V5, P975
   Yang K., 2004, ACM INT WORKSHOP MUL, P65, DOI DOI 10.1145/1032604.1032616
NR 23
TC 15
Z9 17
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2007
VL 35
IS 1
BP 55
EP 70
DI 10.1007/s11042-007-0119-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 209RY
UT WOS:000249406900003
DA 2024-07-18
ER

PT J
AU Toledo, R
   Baldrich, R
   Orriols, X
   Sanchez, J
   Binefa, X
AF Toledo, Ricardo
   Baldrich, Ramon
   Orriols, Xavier
   Sanchez, Juan
   Binefa, Xavier
TI Automatic cataloguing of advertisement in magazines
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia system; computer-aided visual inspection; document image
   analysis; content-based image retrieval
AB Advertising activities are one of the main aspects of companies. Its global evaluation is an important index, not only within economic sectors, but also for public economic policies. The evaluation of the adverts is carried out by specialised companies, which deliver advertisement expenditure information. Their work consist in an exhaustive collection of adverts (e.g., all adverts from any media), and deliver information (integrated from every media) relevant for their clients. The delivered information can range from statistical data to bear witness of an advertisement campaign. Important quality indicators for the delivered information are the exhaustiveness, the delay of delivering and a correct identification of different versions of an advert. In this article, we present an advanced computer-aided system for collecting and delivering advertising information from magazines and daily press. The system provides computer-aided data validation and exploitation resources. Using computerised document image analysis and image database indexing and retrieval, the system is able to locate an advert in a page, extract relevant quality indicators and search the advert (or similar ones) in a database. This tool is configured as an intranet and offers resources for image data acquisition, storage/retrieval and advert quality indicators extraction, however, the key of the system is the underlying idea of incorporating computer-aided visual information management.
C1 Univ Autonoma Barcelona, Comp Vis Ctr, E-08193 Barcelona, Spain.
   Univ Autonoma Barcelona, Dept Comp Sci, E-08193 Barcelona, Spain.
C3 Centre de Visio per Computador (CVC); Autonomous University of
   Barcelona; Autonomous University of Barcelona
RP Toledo, R (corresponding author), Univ Autonoma Barcelona, Comp Vis Ctr, Edifici O,Campus UAB, E-08193 Barcelona, Spain.
EM ricardo.toledo@uab.es
RI Binefa, Xavier/D-7993-2014
OI Binefa, Xavier/0000-0002-4324-9952
CR Aksoy S, 1998, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES - PROCEEDINGS, P45, DOI 10.1109/IVL.1998.694493
   [Anonymous], IEEE COMPUT
   Ballard D.H., 1982, Computer Vision
   Cattoni R., 1998, GEOMETRIC LAYOUT ANA
   Chang SF, 2002, IEEE MULTIMEDIA, V9, P6, DOI 10.1109/93.998041
   CHUA TS, 1997, P INT C MULT COMP SY
   Chuang GCH, 1996, IEEE T IMAGE PROCESS, V5, P56, DOI 10.1109/83.481671
   Gatos B., 2000, International Journal on Digital Libraries, V3, P77
   GRAPS A, 1995, IEEE COMPUT SCI ENG, V2, P50, DOI 10.1109/99.388960
   HARALICK RM, 1994, IEEE COMP SOC C COMP, P385
   Jain AK, 1998, IEEE T PATTERN ANAL, V20, P294, DOI 10.1109/34.667886
   LARISH J, 1999, ADV IMAGING      NOV, P34
   Liang J., 1996, Proceeding. Third IEEE Workshop on Applications of Computer Vision. WACV'96 (Cat. No.96TB100084), P278, DOI 10.1109/ACV.1996.572074
   Mallat S.G. A., 1989, IEEE T PATTERN ANAL, V11, P7
   MEHROTRA S, 1997, P IEEE INT C MULT CO
   Parodi P., 1999, International Journal on Document Analysis and Recognition, V2, P67, DOI 10.1007/s100320050038
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   TANG YY, 1999, HDB PATTERN RECOGNIT, pCH8
   WIEDERHOLD G, 1995, COMMUN ACM, V38, P85, DOI 10.1145/205323.205347
   Wiederhold Gio, 1997, INT J DIGITAL LIB, P311
   XIANG SZ, 2002, IEEE MULTIMEDIA, V9, P22
NR 22
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2006
VL 31
IS 2
BP 119
EP 144
DI 10.1007/s11042-006-0038-y
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 103MP
UT WOS:000241890500001
DA 2024-07-18
ER

PT J
AU Yoo, HW
   Ryoo, HJ
   Jang, DS
AF Yoo, Hun-Woo
   Ryoo, Han-Jin
   Jang, Dong-Sik
TI Gradual shot boundary detection using localized edge blocks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE gradual shot detection; AGI (Average Gradient Image); variance;
   parabolic curve; local blocks; opening
AB A new algorithm for gradual shot boundary detection is proposed in this paper. The proposed algorithm is based on the fact that most of gradual curves can be characterized by variance distribution of edge information in the frame sequences. Average edge frame sequence is obtained by performing Sobel edge detection. Features are extracted by comparing variance with those of local blocks in the average edge frames. Those features are further processed by the opening operation to obtain smoothing variance curves. The lowest variance in the local frame sequence is chosen as a gradual detection point. Experimental results show that the proposed method provides 87.0% precision and 86.3% recall rates for six selected videos.
C1 Yonsei Univ, Ctr Cognit Sci, Seoul 120749, South Korea.
   Korea Univ, Dept Elect & Comp Engn, Seoul 136701, South Korea.
   Korea Univ, Dept Ind Engn & Informat Syst, Seoul 136701, South Korea.
C3 Yonsei University; Korea University; Korea University
RP Yoo, HW (corresponding author), Yonsei Univ, Ctr Cognit Sci, 134 Shinchon Dong, Seoul 120749, South Korea.
EM paulyhw@yonsei.ac.kr; hanjin@mpeg.korea.ac.kr; jang@korea.ac.kr
RI Ryoo, HongJe/C-6764-2017
CR Ahanger G, 1996, J VIS COMMUN IMAGE R, V7, P28, DOI 10.1006/jvci.1996.0004
   Ba Tu Truong, 2000, Proceedings ACM Multimedia 2000, P219, DOI 10.1145/354384.354481
   Brunelli R, 1999, J VIS COMMUN IMAGE R, V10, P78, DOI 10.1006/jvci.1997.0404
   COVELL M, 2002, P ICIP, V1, P23
   Fernando W. A. C., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P299, DOI 10.1109/ICIP.1999.817121
   Ford RM, 2000, MULTIMEDIA SYST, V8, P37, DOI 10.1007/s005300050003
   Gargi U, 2000, IEEE T CIRC SYST VID, V10, P1, DOI 10.1109/76.825852
   Hanjalic A, 2002, IEEE T CIRC SYST VID, V12, P90, DOI 10.1109/76.988656
   Jain AK, 1999, MULTIMEDIA SYST, V7, P369, DOI 10.1007/s005300050139
   JUN SB, 2000, ACM INT C MULT, P391
   Lee SW, 2000, IEEE T MULTIMEDIA, V2, P240, DOI 10.1109/6046.890059
   Lienhart R, 1998, PROC SPIE, V3656, P290, DOI 10.1117/12.333848
   Lienhart R, 2001, PROC SPIE, V4315, P219, DOI 10.1117/12.410931
   Lu H. B., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P304, DOI 10.1109/ICIP.1999.817122
   MENG J, 1994, P SOC PHOTO-OPT INS, V2419, P14
   NAGAURA T, 1991, JEC BATTERY NEWSLETT, V2, P2
   OTSUJI K, 1991, SPIE P VISUAL COMMUN, V1606, P980
   SONG SM, 1998, SPIE, V3312, P404
   Stockman George, 2001, Computer Vision
   TRUONG BT, 1999, THESIS CURTIN U TECH
   Xiong W, 1998, COMPUT VIS IMAGE UND, V71, P166, DOI 10.1006/cviu.1998.0711
   Yeo BL, 1995, IEEE T CIRC SYST VID, V5, P533, DOI 10.1109/76.475896
   Zabih R, 1999, MULTIMEDIA SYST, V7, P119, DOI 10.1007/s005300050115
   Zhang HJ, 1997, PATTERN RECOGN, V30, P643, DOI 10.1016/S0031-3203(96)00109-4
   ZHANG HJ, 1993, ACM MULTIMEDIA SYSTE, V1, P10
NR 25
TC 42
Z9 45
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2006
VL 28
IS 3
BP 283
EP 300
DI 10.1007/s11042-006-7715-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 044FO
UT WOS:000237658000002
DA 2024-07-18
ER

PT J
AU Jin, XY
   French, JC
AF Jin, XY
   French, JC
TI Improving image retrieval effectiveness via multiple queries
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 1st ACM International Workshop on Multimedia Databases
CY NOV 07, 2003
CL New Orleans, LA
SP ACM
DE content-based image retrieval; multi-channel CBIR; result merging;
   relevance feedback
ID RELEVANCE FEEDBACK
AB Conventional approaches to image retrieval are based on the assumption that relevant images are physically near the query image in some feature space. This is the basis of the cluster hypothesis. However, semantically related images are often scattered across several visual clusters. Although traditional Content-based Image Retrieval (CBIR) technologies may utilize the information contained in multiple queries (gotten in one step or through a feedback process), this is often only a reformulation of the original query. As a result most of these strategies only get the images in some neighborhood of the original query as the retrieval result. This severely restricts the system performance. Relevance feedback techniques are generally used to mitigate this problem. In this paper, we present a novel approach to relevance feedback which can return semantically related images in different visual clusters by merging the result sets of multiple queries. We also provide experimental results to demonstrate the effectiveness of our approach.
C1 Univ Virginia, Dept Comp Sci, Charlottesville, VA 22904 USA.
C3 University of Virginia
RP Univ Virginia, Dept Comp Sci, Charlottesville, VA 22904 USA.
EM xj3a@cs.virginia.edu; french@cs.virginia.edu
CR BELKIN N, 1994, P TREC 2, P35
   Belkin N., 1993, P 20 ANN INT ACM SIG, P339
   CHEN Y, 2003, 7 INT S SIGN PROC IT
   Dwork C., 2001, P 10 INT C WORLD WID, P613, DOI [10.1145/371920.372165, DOI 10.1145/371920.372165]
   FAGIN R, 2003, P ACM SIAM S DISCR A
   FRENCH JC, 2002, 45 IEEE INT MIDW S C
   FRENCH JC, 2003, INT WORKSH MULT INF
   FRENCH JC, 2002, WORKSH DOC SEARCH IN
   FRENCH JC, 2004, INT C IM VID RETR CI
   FRRENCH JC, 2003, CS200310 U VIRG DEP
   HIRATA K, 1992, LECT NOTES COMPUT SC, V580, P56
   HUANG TS, 1997, P INT S MULT INF PRO
   ISHIKAWA Y, 1998, 24 INT C VER LARG DA
   JIN X, 2003, 1 ACM INT WORKSH MUL, P86
   KIM D, 2003, P SIGMOD 03 SAN DIEG
   Liu WY, 2001, HUMAN-COMPUTER INTERACTION - INTERACT'01, P326
   NIBLACK W, 1993, P SPIE EL IM SCI TEC
   Porkaew K, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P235, DOI 10.1145/319463.319613
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   SALTON G, 1983, COMMUN ACM, V26, P1022, DOI 10.1145/182.358466
   SALTON G, 1989, INTRO MODERN INFORMA
   Sheikholeslami G, 2002, IEEE T KNOWL DATA EN, V14, P988, DOI 10.1109/TKDE.2002.1033769
   Tahaghoghi SMM, 2001, AUST COMP S, V23, P138, DOI 10.1109/ADC.2001.904476
   VANRIJSBERGERN CJ, 1979, INFORMATION RETRIEVA
   WANG JZ, 2001, P ACM IEEE JOINT C D
   Wu L., 2000, P INT C VERY LARGE D, P297
   YOSHIOKA M, 1993, TEC BEHAV N 2, V11, P1
   Zhang HJ, 2003, WORLD WIDE WEB, V6, P131, DOI 10.1023/A:1023618504691
NR 28
TC 12
Z9 12
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2005
VL 26
IS 2
BP 221
EP 245
DI 10.1007/s11042-005-0453-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 931TJ
UT WOS:000229508100006
DA 2024-07-18
ER

PT J
AU Man, H
   Docef, A
   Kossentini, F
AF Man, H
   Docef, A
   Kossentini, F
TI Performance analysis of the JPEG 2000 image coding standard
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE image compression; JPEG-2000
ID COMPRESSION
AB Some of the major objectives of the JPEG 2000 still image coding standard were compression and memory efficiency, lossy to lossless coding, support for continuous-tone to bi-level images, error resilience, and random access to regions of interest. This paper will provide readers with some insight on various features and functionalities supported by a baseline JPEG 2000-compliant codec. Three JPEG 2000 software implementations (Kakadu, JasPer, JJ2000) are compared with several other codecs, including JPEG, JBIG, JPEG-LS, MPEG-4 VTC and H.264 intra coding. This study can serve as a guideline for users to estimate the effectiveness of JPEG 2000 for various applications, and to select optimal parameters according to specific application requirements.
C1 Stevens Inst Technol, Dept Elect & Comp Engn, Hoboken, NJ 07030 USA.
   Virginia Commonwealth Univ, Dept Elect Engn, Richmond, VA 23284 USA.
   UB Video Inc, Vancouver, BC V6B 2R9, Canada.
C3 Stevens Institute of Technology; Virginia Commonwealth University
RP Man, H (corresponding author), Stevens Inst Technol, Dept Elect & Comp Engn, Hoboken, NJ 07030 USA.
EM hman@stevens-tech.edu; adocef@vcu.edu
CR ADAMS MD, 1SC29WGUN2412 ISOIEC
   [Anonymous], 2001, JTC1SC29WG1 ISOIEC
   [Anonymous], 2002, JTC1SC29WG11 ISOIEC, pN4668
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   *IND JPEG GROUP, JPEG IM COMPR LIB VE
   *ISO IEC, 1993, JTC1SC29WG1 ISOIEC
   *ISO IEC, 1997, JTC1SC29WG1 ISOIEC
   *ISO IEC, 2001, JTC1SC29WG11 ISOIEC
   *ISO IEC, 2000, JTC1SC29WG1 ISOIEC
   *ISO IEC, 1994, JTC1SC29WG1 ISOIEC
   *ISO IEC MPEG ITU, 2002, H 26L REF SOFTW VERS
   KUHN M, 2000, JBIG KIT VERSION 1 2
   Marcellin M. W., 2000, Proceedings DCC 2000. Data Compression Conference, P523, DOI 10.1109/DCC.2000.838192
   *MICR CORP, 2000, MICR MPEG 4 VIS REF
   Rabbani M, 2002, SIGNAL PROCESS-IMAGE, V17, P3, DOI 10.1016/S0923-5965(01)00024-8
   Santa-Cruz D, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P49, DOI 10.1109/ICIP.2000.899222
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   Taubman D., 2012, JPEG2000: image compression fundamentals, standards and practice, V642
   *UBC SIGN PROC MUL, 2000, JBIG2 SOFTW VERS 1 0
   *UBC SIGN PROC MUL, 1999, JPEG LS PUBL DOM COD
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   WIEGAND T, 2002, IN PRESS IEEE T CIRC
   WIEGAND T, 2002, WORKING DRAFT NUMBER
   2000, JASPER PROJECT VERSI
   2000, JJ2000 IMPLEMENTATIO
NR 27
TC 7
Z9 9
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2005
VL 26
IS 1
BP 27
EP 57
DI 10.1007/s11042-005-6848-5
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 915EU
UT WOS:000228281600002
DA 2024-07-18
ER

PT J
AU Chen, IR
   Li, ST
   Yen, IL
AF Chen, IR
   Li, ST
   Yen, IL
TI Adaptive QoS control based on benefit optimization for video servers
   providing differentiated services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video servers; quality of service (QoS); QoS negotiation; streaming
   video; admission control; disk scheduling; data placement
AB We propose and analyze quality of service (QoS) control algorithms for video servers designed to provide differentiated video streaming services. The design concepts are based on resource reservation and benefit optimization so that resources are reserved dynamically and adaptively for different QoS levels in response to the changing workload of the system, with the objective of maximizing the benefit throughput obtainable by the system. We analyze the benefit throughput obtainable by the system for a baseline algorithm for which the QoS levels of admitted users are not changed during the service lifetime and a greedy algorithm that may raise QoS levels of admitted users due to resources being free from departure events. We validate the design of these two QoS control algorithms via a detailed simulation study.
C1 No Virginia Grad Ctr, Virginia Tech, Dept Comp Sci, Falls Church, VA 22043 USA.
   Natl Cheng Kung Univ, Inst Informat Management, Tainan 70101, Taiwan.
   Univ Texas, Dept Comp Sci, Arlington, TX 76019 USA.
C3 Virginia Polytechnic Institute & State University; National Cheng Kung
   University; University of Texas System; University of Texas Arlington
RP Chen, IR (corresponding author), No Virginia Grad Ctr, Virginia Tech, Dept Comp Sci, 7054 Haycock Rd, Falls Church, VA 22043 USA.
EM irchen@cs.vt.edu; stli@mail.ncku.edu.tw; ilyen@utdallas.edu
CR Aurrecoechea C, 1998, MULTIMEDIA SYST, V6, P138, DOI 10.1007/s005300050083
   BRANDT S, 1998, 6 INT WORKSH QUAL SE
   Chang KL, 1996, APPL IMMUNOHISTOCHEM, V4, P1
   CHENG S, 2000, ACM SPRINGER MULTIME, V8, P83
   Cheng ST, 1998, 1998 WINTER SIMULATION CONFERENCE PROCEEDINGS, VOLS 1 AND 2, P1623, DOI 10.1109/WSC.1998.746038
   Henderson T, 2001, IEEE INTERNET COMPUT, V5, P85, DOI 10.1109/4236.957899
   Kleinrock L., 1975, Queueing Systems-Volume 1: Theory, V1
   LAWTON G, 2000, IEEE COMPUTER    JUL, P12
   Lee W, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P147, DOI 10.1109/MMCS.1999.779138
   Li BC, 1999, IEEE J SEL AREA COMM, V17, P1632, DOI 10.1109/49.790486
   Nutt GJ, 2000, IEEE T KNOWL DATA EN, V12, P78, DOI 10.1109/69.842252
   SHENOY PJ, 1998, 7 ACM INT C MEAS MOD, P44
   To TPJ, 2000, IEEE T MULTIMEDIA, V2, P49, DOI 10.1109/6046.825795
   Wijayaratne R, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P487, DOI 10.1109/MMCS.1999.779250
NR 14
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2005
VL 25
IS 2
BP 167
EP 185
DI 10.1007/s11042-005-5604-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 897BM
UT WOS:000226979000001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Amsaleg, L
   Gros, P
   Berrani, SA
AF Amsaleg, L
   Gros, P
   Berrani, SA
TI Robust object recognition in images and the related database problems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 7th Workshop on Multimedia Information Systems
CY NOV 07-09, 2001
CL Capri, ITALY
DE image retrieval systems; fine-grain image recognition; high dimensional
   indexing; databases
AB Traditional content-based image retrieval systems typically compute a single descriptor per image based for example on color histograms. The result of a query is in general the images from the database whose descriptors are the closest to the descriptor of the query image. Systems built this way are able to return images that are globally similar to the query image, but can not return images that contain some of the objects that are in the query. As opposed to this traditional coarse-grain recognition scheme, recent advances in image processing make fine-grain image recognition possible, notably by computing local descriptors that can detect similar objects in different images. Obviously powerful, fine-grain recognition in images also changes the retrieval process: instead of submitting a single query to retrieve similar images, multiple queries must be submitted and their partial results must be post-processed before delivering the answer. This paper first presents a family of local descriptors supporting fine-grain image recognition. These descriptors enforce robust recognition, despite image rotations and translations, illumination variations, and partial occlusions. Many multi-dimensional indexes have been proposed to speed-up the retrieval process. These indexes, however, have been mostly designed for and evaluated against databases where each image is described by a single descriptor. While this paper does not present any new indexing scheme, it shows that the three most efficient indexing techniques known today are still too slow to be used in practice with local descriptors because of the changes in the retrieval process.
C1 CNRS, Irisa, F-35042 Rennes, France.
   Thomson Multimedia R&D France, F-35511 Cesson Sevigne, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite de
   Rennes; Technicolor SA
RP Amsaleg, L (corresponding author), CNRS, Irisa, Campus Beaulieu, F-35042 Rennes, France.
EM Laurent.Amsaleg@irisa.fr; Patrick.Gros@irisa.fr; berranis@thmulti.com
CR Amsaleg L, 2001, PATTERN ANAL APPL, V4, P108, DOI 10.1007/s100440170011
   AMSALEG L, 2001, P 7 WORKSH MULT INF
   [Anonymous], 1995, P 1995 ACM SIGMOD IN, DOI DOI 10.1145/223784.223794
   [Anonymous], P ACM SIGMOD INT C M
   [Anonymous], 1988, ALVEY VISION C
   [Anonymous], P INT C EXT DAT TECH
   BENNETT KP, 1999, P 5 ACM SIGKDD INT C, P233
   BERRANI SA, 2002, 1495 PI IRISA
   Bohm C., 2001, ACM COMPUTING SURVEY, V33
   Ciaccia P., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), P244, DOI 10.1109/ICDE.2000.839417
   DUFOURNAUD Y, 2000, P C COMP VIS PATT RE, V1
   Faloutsos C., 1994, J INTELLIGENT INFORM, V3
   FLORACK LMJ, 1994, J MATH IMAGING VISIO, V4
   Guttman A., 1984, ACM SIGMOD INT C MAN, P47, DOI DOI 10.1145/602259.602266
   Henrich A, 1998, PROC INT CONF DATA, P362, DOI 10.1109/ICDE.1998.655799
   Hinneburg A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P506
   HJALTASON G, 1995, 4 INT S SPAT DAT SSD, P83
   Li C, 2002, IEEE T KNOWL DATA EN, V14, P792, DOI 10.1109/TKDE.2002.1019214
   SCHMID C, 1998, P 6 INT C COMP VIS
   SCHMID C, 1997, IEEE T PATTERN ANAL, V19
   Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P194
NR 21
TC 9
Z9 9
U1 0
U2 1
PU KLUWER ACADEMIC PUBL
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2004
VL 23
IS 3
BP 221
EP 235
DI 10.1023/B:MTAP.0000031758.46389.00
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 829BJ
UT WOS:000222017700004
DA 2024-07-18
ER

PT J
AU Mahalingam, LP
   Candan, KS
AF Mahalingam, LP
   Candan, KS
TI Multi-criteria query optimization in the presence of result size and
   quality tradeoffs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 7th Workshop on Multimedia Information Systems
CY NOV 07-09, 2001
CL Capri, ITALY
DE query optimization; multi-criteria optimization; quality-based
   optimization; similarity-based optimization; top-k retrieval; multimedia
   databases
AB In this paper, we present novel multi-criteria query optimization techniques for performing query optimization in databases, such as multimedia and web databases, which rely on imperfect access mechanisms and top-k predicates. We present an optimization model that ( 1) takes into account different binding patterns associated with query predicates, ( 2) considers the variations in the expected query result sizes as a function of query execution plans, and ( 3) considers the expected result qualities of the execution orders. We address the complexity and the well-known NP-complete nature of the query optimization problem by adaptively reducing the granularity of the search space. For this purpose, unlike the data histograms which capture the data distribution, we propose opt-histograms that capture the distribution of sub-query-plan values over many optimization tasks.
C1 Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85283 USA.
C3 Arizona State University; Arizona State University-Tempe
EM priyam@asu.edu; candan@asu.edu
CR [Anonymous], VLDB
   Candan K. S., 2001, Knowledge and Information Systems, V3, P30, DOI 10.1007/PL00011658
   Candan KS, 2000, DATA KNOWL ENG, V35, P259, DOI 10.1016/S0169-023X(00)00025-2
   CHAUDHURI S, 1996, SIGMOD 1996 CAN JUN, P91
   CHAUDHURI S, 1996, VLDB 96, P87
   CHAUDHURI S, 1998, PRINCIPLES DATABASE
   CHIMENTI D, 1989, VERY LARGE DATA BASES - PROCEEDINGS, P195
   Donjerkovic D, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P411
   FAGIN R, 1996, 15 ACM S PRINC DAT S, P216
   FAGIN R, 1998, FUZZY QUERIES MULTIM
   FLORESCU D, 1999, ACM SIGMOD INT C MAN, P311
   Hellerstein JM, 1998, ACM T DATABASE SYST, V23, P113, DOI 10.1145/292481.277627
   MAHALINGAM LP, 2001, MULT INF SYST WORKSH
   NIE Z, 2001, ACM CIKM ATL GEORG N
   Ortega M, 1998, IEEE T KNOWL DATA EN, V10, P905, DOI 10.1109/69.738357
   Yerneni R., 1999, ICDT, P348
   ZADOROZHNY V, IN PRESS SIGMOD 2002
   [No title captured]
NR 18
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2004
VL 23
IS 3
BP 167
EP 183
DI 10.1023/B:MTAP.0000031755.50716.2a
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 829BJ
UT WOS:000222017700001
DA 2024-07-18
ER

PT J
AU Kosch, H
   Mostefaoui, A
   Böszörményi, L
   Brunie, L
AF Kosch, H
   Mostefaoui, A
   Böszörményi, L
   Brunie, L
TI Heuristics for optimizing multi-clip queries in video databases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video databases; video server; multi-clip queries; piggypacking
ID MANAGEMENT; ALGORITHMS; STREAMS
AB In this paper we address the multi-clip query optimization problem where a multi-clip query requests multiple video clips. We propose a new heuristics called Restricted Search Interval that maximizes clip sharing between queries and consequently reduces the network bandwidth of a video server for a multicast system. An adaptation of our heuristics for optimizing the response time of the query is also presented. The experimental results show that the suggested heuristics reduces the server workload by about 28% on the average in comparison to a classical heuristic approach.
C1 Univ Klagenfurt, Inst Informat Technol, Klagenfurt, Austria.
   Inst Natl Sci Appl, Informat Syst Engn Lab, Lyon, France.
C3 University of Klagenfurt; Institut National des Sciences Appliquees de
   Lyon - INSA Lyon
RP Kosch, H (corresponding author), Univ Klagenfurt, Inst Informat Technol, Klagenfurt, Austria.
EM harald@itec.uni-klu.ac.at; amostefa@pu-pm.univ-fcomte.fr;
   laszlo@itec.uni-klu.ac.at; Lionel.Brunie@insa-lyon.fr
OI Kosch, Harald/0000-0002-7090-1133
CR ADALI S, 1999, P 1999 ACM SIGMOD IN, P121
   Andersson HS, 1997, RRD PURE APPL CHEM, V1, P133
   [Anonymous], 2000, MULTICAST COMMUNICAT
   Balkir NH, 1998, VLDB J, V7, P294, DOI 10.1007/s007780050070
   Balkir NH, 1998, INTERNATIONAL WORKSHOP ON MULTI-MEDIA DATABASE MANAGEMENT SYSTEMS- PROCEEDINGS, P154, DOI 10.1109/MMDBMS.1998.709778
   BOURAS C, 1999, NETWORKING INFORMATI, V2, P741
   Campbell ST, 2002, MULTIMED TOOLS APPL, V18, P5, DOI 10.1023/A:1015816232330
   Chen FCF, 1998, IEEE T KNOWL DATA EN, V10, P493, DOI 10.1109/69.687980
   Dan A., 1994, Proceedings ACM Multimedia '94, P15, DOI 10.1145/192593.192614
   Diot C, 2000, IEEE NETWORK, V14, P78, DOI 10.1109/65.819174
   El-Rewini H., 1994, TASK SCHEDULING PARA
   GAROFALAKIS M, 1998, INT C VER LARG DAT N, P74
   Huang J, 1998, REAL-TIME SYST, V15, P249, DOI 10.1023/A:1008044430932
   Jiang HT, 1999, MULTIMED TOOLS APPL, V9, P227, DOI 10.1023/A:1009638926989
   Jiang XY, 1999, MULTIMEDIA SYST, V7, P294, DOI 10.1007/s005300050131
   Johnson TV, 1999, MULTIMEDIA SYST, V7, P312, DOI 10.1007/s005300050133
   Kosch H., 2001, Proceedings of the 27th International Conference on Very Large Data Bases, P713
   KOSCH H, 2002, SIGMOD RECORDS, V31
   KOSCH H, 2002, MULTIMEDIA TOOLS APP, V18
   Lau SW, 1998, MULTIMEDIA SYST, V6, P29, DOI 10.1007/s005300050074
   Lee T, 2000, MULTIMED TOOLS APPL, V11, P63, DOI 10.1023/A:1009625416681
   Megzari O, 2002, MULTIMED TOOLS APPL, V16, P137, DOI 10.1023/A:1013297803500
   Meng HJ, 1999, MULTIMEDIA SYST, V7, P282, DOI 10.1007/s005300050130
   Oria V, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P536, DOI 10.1109/MMCS.1999.779258
   Prabhakaran B, 2000, MULTIMED TOOLS APPL, V12, P281, DOI 10.1023/A:1009627926302
   RAYMOND TN, 1998, VLDB J, V7, P239
   SELLIS TK, 1988, ACM T DATABASE SYST, V13, P23, DOI 10.1145/42201.42203
   SHAHABI A, 1998, 3 INT C INT DES PROC, P360
   SHAHABI C, 1998, WORLD AUT C WAC
   Sheng L, 1999, PROC INT CONF DATA, P572, DOI 10.1109/ICDE.1999.754973
   SONG Y, 1999, IEEE INT C MULT COMP, V2, P585
   VANBEEK P, 2001, 1593852001 ISOIEC FD
   WU WSM, 2001, MULTIMED TOOLS APPL, V14, P79
   Zhang A, 2000, MULTIMED TOOLS APPL, V10, P133, DOI 10.1023/A:1009658617338
   2001, RECSMIL2020010807
NR 35
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2004
VL 22
IS 3
BP 235
EP 262
DI 10.1023/B:MTAP.0000017030.45487.43
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 776VC
UT WOS:000189139200002
DA 2024-07-18
ER

PT J
AU Cucchiara, R
   Prati, A
   Piccardi, M
AF Cucchiara, R
   Prati, A
   Piccardi, M
TI Improving data prefetching efficacy in multimedia applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE cache performance; hardware prefetching techniques; multimedia
   benchmark; MPEG decode; image processing
AB The workload of multimedia applications has a strong impact on cache memory performance, since the locality of memory references embedded in multimedia programs differs from that of traditional programs. In many cases, standard cache memory organization achieves poorer performance when used for multimedia. A widely-explored approach to improve cache performance is hardware prefetching, which allows the pre-loading of data in the cache before they are referenced. However, existing hardware prefetching approaches are unable to exploit the potential improvement in performance, since they are not tailored to multimedia locality. In this paper we propose novel effective approaches to hardware prefetching to be used in image processing programs for multimedia. Experimental results are reported for a suite of multimedia image processing programs including MPEG-2 decoding and encoding, convolution, thresholding, and edge chain coding.
C1 Univ Modena & Reggio Emilia, Dipartimento Sci Ingn, Modena, Italy.
   Univ Technol Sydney, Dept Comp Sci, Broadway, NSW 2007, Australia.
C3 Universita di Modena e Reggio Emilia; University of Technology Sydney
RP Univ Modena & Reggio Emilia, Dipartimento Sci Ingn, Via Vignolese 905, Modena, Italy.
EM cucchiara.rita@unimore.it; prati.andrea@unimore.it;
   massimo@it.uts.edu.au
RI Piccardi, Massimo/AAY-1323-2020; Prati, Andrea/B-7440-2014; Cucchiara,
   Rita/L-3006-2015
OI Piccardi, Massimo/0000-0001-9250-6604; Prati,
   Andrea/0000-0002-1211-529X; Cucchiara, Rita/0000-0002-2239-283X
CR [Anonymous], P INT C SUP
   Baglietto P, 1996, P IEEE, V84, P917, DOI 10.1109/5.503295
   CHEN TF, 1995, IEEE T COMPUT, V44, P609, DOI 10.1109/12.381947
   CHEN TF, 1996, P 21 INT S COMP ARCH, P223
   Chiariglione L, 1998, P IEEE, V86, P1222, DOI 10.1109/5.687836
   Cucchiara R, 1998, P INT C HIGH PERFORM, P466, DOI 10.1109/HIPC.1998.738023
   Cucchiara R, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P345, DOI 10.1109/MMCS.1999.779228
   CUCCHIARA R, 2000, TEMPORAL ANAL CACHE
   Diefendorff K, 1997, COMPUTER, V30, P43, DOI 10.1109/2.612247
   EICKEMEYER RJ, 1993, IBM J RES DEV, V37, P547, DOI 10.1147/rd.374.0547
   Hennessy John L, 2011, Computer Architecture: A Quantitative Approach
   IRLAM G, 1992, COMMUNICATION
   *ISO IEC, 144962 ISOIEC DIS
   Joseph D, 1999, IEEE T COMPUT, V48, P121, DOI 10.1109/12.752653
   JOUPPI NP, 1990, 17TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P364, DOI 10.1109/ISCA.1990.134547
   KANEKO T, 1985, IEEE T COMMUN, V33, P697, DOI 10.1109/TCOM.1985.1096361
   Katsaggelos AK, 1998, P IEEE, V86, P1126, DOI 10.1109/5.687833
   Kuroda I, 1998, P IEEE, V86, P1203, DOI 10.1109/5.687835
   Lee SH, 1997, MACROMOLECULES, V30, P337, DOI 10.1021/ma960653t
   LEGALL D, 1991, COMMUN ACM, V34, P46, DOI 10.1145/103085.103090
   MILUTINOVIC V, 1996, P SCIZZI, V5, P72
   SMITH AJ, 1982, COMPUT SURV, V14, P473, DOI 10.1145/356887.356892
   SODERQUIST P, 1997, ICCD 97
   Tse J, 1998, IEEE T COMPUT, V47, P509, DOI 10.1109/12.677225
   Wu Z, 1998, 1998 IEEE WORKSHOP ON SIGNAL PROCESSING SYSTEMS-SIPS 98, P23, DOI 10.1109/SIPS.1998.715765
   Zucker DF, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P236, DOI 10.1109/MMCS.1996.534981
NR 26
TC 6
Z9 7
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2003
VL 20
IS 2
BP 159
EP 178
DI 10.1023/A:1023687722225
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 675WP
UT WOS:000182720800003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Tan, KL
   Ooi, BC
   Thiang, LF
AF Tan, KL
   Ooi, BC
   Thiang, LF
TI Retrieving similar shapes effectively and efficiently
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE shape retrieval; retrieval effectiveness; retrieval efficiency;
   centroid-radii model; NR-trees
AB In this paper, we address the following problem: given a large collection of shapes and a query shape, retrieve all shapes (from the shape database) that are similar to the query shape. A generalized centroid-radii model is used to model all forms of shapes -convex shapes, concave shapes and shapes with "holes". Under the model, a shape is represented by a set of vectors, each obtained from the radii emanating from the centroid of a virtual concentric ring.
   The model can also facilitate multi-resolution and similarity retrievals. Furthermore, using the model, the shape of an object can be transformed into a point in a high dimensional data space. To speed up the retrieval of similar shapes, we also propose a multi-level R-tree index, called the Nested R-trees (NR-trees). Unlike traditional high-dimensional index structures that index a high-dimensional point as it is (with its full dimension), the NR-trees splits the dimensionality of the point into a set of lower dimensions that are indexed by levels of the NR-trees. We also proposed a quick filtering mechanism to further prune the search space.
   We implemented a shape retrieval system that employs the generalized centroid-radii model and the NR-trees with the filtering mechanism. Our experimental study shows the effectiveness of the proposed shape model, and the efficiency of the NR-trees. The results also show that the filtering mechanism can significantly reduce the retrieval time.
C1 Natl Univ Singapore, Dept Comp Sci, Singapore 117543, Singapore.
C3 National University of Singapore
RP Natl Univ Singapore, Dept Comp Sci, 3 Sci Dr 2, Singapore 117543, Singapore.
EM tankl@comp.nus.edu.sg; ooibc@comp.nus.edu.sg
OI Tan, Kian-Lee/0000-0001-9315-4057
CR [Anonymous], 1994, The VLDB Journal, DOI DOI 10.1007/BF01231606
   Bach JR, 1996, P SOC PHOTO-OPT INS, V2670, P76, DOI 10.1117/12.234785
   BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93605.98741
   Belongie S., 1997, RECOGNITION IMAGES L
   Berchtold S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P28
   Bertino E., 1997, Indexing Techniques for Advanced Database Systems
   CHAHIR Y, 1997, P SPIE MULT STOR ARC, V2, P172
   CHANG SK, 1992, IEEE T KNOWL DATA EN, V4, P431, DOI 10.1109/69.166986
   Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, P231, DOI 10.1007/BF00962238
   Flickner M., 1995, IEEE COMPUT, V28, P23, DOI DOI 10.1109/2.410146
   GOH ST, 2000, DATA KNOWLEDGE ENG
   Guttman A., 1984, SIGMOD Record, V14, P47, DOI 10.1145/971697.602266
   Huang J, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P325, DOI 10.1145/266180.266383
   Jacobs C.E., 1995, P SIGGRAPH 95, P277
   JAGADISH HV, 1991, P ACM SIGMOD INT C M, P208
   JEA KF, 1990, INFORMATION SYSTEMS, V16, P653
   Katayama N., 1997, P ACM SIGMOD, P369
   KELLY P., 1995, STORAGE RETRIEVAL IM, V2420, P238
   KNUTH DE, 1992, VISUAL DATABASE SYST, V2
   Korn F, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P215
   MALLAT S, 1989, IEEE T PATTERN ANAL, V11, P2091
   MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465
   MARAGOS PA, 1986, IEEE T ACOUST SPEECH, V34, P1228, DOI 10.1109/TASSP.1986.1164959
   Mehrotra R., 1993, Proceedings. Ninth International Conference on Data Engineering (Cat. No.92CH3258-1), P108, DOI 10.1109/ICDE.1993.344072
   NIBLACK W, 1993, SPIE V, V1908
   NIEVERGELT J, 1984, ACM T DATABASE SYST, V9, P38, DOI 10.1145/348.318586
   OGLE VE, 1995, COMPUTER, V28, P40, DOI 10.1109/2.410150
   Ooi BC, 1998, VLDB J, V7, P115, DOI 10.1007/s007780050057
   Robinson J. J., 1981, Paper, 32nd Annual Meeting of the European Association for Animal Production
   Sellis T., 1987, Proceedings of the Thirteenth International Conference on Very Large Data Bases: 1987 13th VLDB, P507
   Serra J., 1988, IMAGE ANAL MATH MORP
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   SWAIN MJ, 1993, SPIE V, V1908
   TAN KL, 2001, MULTIMEDIA TOOLS APP
   WAN X, 1997, P SPIE MULTIMEDIA ST, V2, P182
   Yee CY, 1998, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS, P218, DOI 10.1109/MMCS.1998.693644
   Yuen PC, 1998, INT J PATTERN RECOGN, V12, P209, DOI 10.1142/S0218001498000142
   ZHOU Z, 1988, P IEEE 2 INT C ASSP, P48
   [No title captured]
NR 40
TC 18
Z9 20
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2003
VL 19
IS 2
BP 111
EP 134
DI 10.1023/A:1022142527536
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 640KE
UT WOS:000180687400001
DA 2024-07-18
ER

PT J
AU Tellai, M
   Gao, LJ
   Mao, QR
   Abdelaziz, M
AF Tellai, Mohammed
   Gao, Lijian
   Mao, Qirong
   Abdelaziz, Mounir
TI A novel conversational hierarchical attention network for speech emotion
   recognition in dyadic conversation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Dyadic conversation; Speech emotion recognition; Mel-spectrogram;
   Attention mechanism; Dual-level model
ID FEATURES
AB Speech is one of the most fundamental mediums for human-to-human interaction, thereby playing a pivotal role in shaping the landscape of next-generation human-computer interaction (HCI). The development of an accurate speech emotion recognition (SER) system for human conversation is a critical yet challenging task. Most state-of-the-art research work in SER predominantly centers around the individual modeling of vocal attributes within each discrete speech utterance, often overlooking the integration of transactional cues intrinsic to the broader interactive context. In this paper, we introduce an innovative dual-level framework designed for the recognition of speech emotions, which leverages the complementary attributes of MFCC features and Mel-spectrograms. Furthermore, we propose a hierarchical attention mechanism designed to effectively include contextual information, hence improving the accuracy of emotion recognition. Our experimentation, conducted on the widely recognized IEMOCAP emotional benchmark dataset, yields promising results. Compared to state-of-the-art methods in four-class emotion recognition, our model demonstrates a substantial advancement, achieving a weighted accuracy of 75.0% and an unweighted accuracy of 75.9%. This marks a notable enhancement of 5.8% in terms of unweighted accuracy, underscoring the efficacy of our approach. This work contributes to the advancement of SER by effectively utilizing multiple audio representations and contextual information. The significant improvements underscore the efficacy of our approach, promising more accurate emotion recognition in human-computer interaction and affective computing.
C1 [Tellai, Mohammed; Gao, Lijian; Mao, Qirong] Jiangsu Univ, Dept Comp Sci & Commun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
   [Mao, Qirong] Jiangsu Engn Res Ctr Big Data Ubiquitous Percept &, Zhenjiang 212013, Jiangsu, Peoples R China.
   [Abdelaziz, Mounir] Cent South Univ, Dept Comp Sci & Technol, Changsha 410083, Hunan, Peoples R China.
C3 Jiangsu University; Central South University
RP Mao, QR (corresponding author), Jiangsu Univ, Dept Comp Sci & Commun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.; Mao, QR (corresponding author), Jiangsu Engn Res Ctr Big Data Ubiquitous Percept &, Zhenjiang 212013, Jiangsu, Peoples R China.
EM 5103180322@stmail.ujs.edu.cn; 2112008002@stmail.ujs.edu.cn;
   mao_qr@ujs.edu.cn; Mouniraziz@csu.edu.cn
FU National Natural Science Foundation of China [U1836220]; National Nature
   Science Foundation of China [62176106]; Jiangsu Province key research
   and development plan [BE2020036]
FX This work is supported in part by the Key Projects of the National
   Natural Science Foundation of China under Grant U1836220, the National
   Nature Science Foundation of China of 62176106 and Jiangsu Province key
   research and development plan (BE2020036).
CR Afrillia Y, 2017, J PHYS CONF SER, V930, DOI 10.1088/1742-6596/930/1/012036
   Anagnostopoulos CN, 2015, ARTIF INTELL REV, V43, P155, DOI 10.1007/s10462-012-9368-5
   [Anonymous], 2016, DCASE
   Barsade SG, 2002, ADMIN SCI QUART, V47, P644, DOI 10.2307/3094912
   Bingol MC, 2020, ENG APPL ARTIF INTEL, V95, DOI 10.1016/j.engappai.2020.103903
   Bone Daniel, 2017, IEEE Signal Processing Magazine, V34, p196, 189, 190, DOI 10.1109/MSP.2017.2718581
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Chattopadhyay S, 2022, Multimed Tools Appl, P1
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Eyben Florian, 2010, P 18 ACM INT C MULT, P1459
   Han K, 2014, INTERSPEECH, P223
   Hareli S, 2016, COGNITION EMOTION, V30, P1260, DOI 10.1080/02699931.2015.1056107
   Hazarika D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2594
   Hazarika Devamanyu, 2018, Proc Conf, V2018, P2122, DOI 10.18653/v1/n18-1193
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang ZW, 2017, MULTIMED TOOLS APPL, V76, P6785, DOI 10.1007/s11042-016-3354-x
   Huang ZW, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P801, DOI 10.1145/2647868.2654984
   Ismail A, 2014, MALAYS J COMPUT SCI, V27, P275
   Jokinen K., 2010, Synthesis Lectures on Human Language Technologies
   Kim E, 2019, INT CONF ACOUST SPEE, P6720, DOI 10.1109/ICASSP.2019.8683077
   Kingma D. P., 2014, arXiv
   Kumar P, 2021, INTERSPEECH, P1748, DOI 10.21437/Interspeech.2021-1718
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee CM, 2005, IEEE T SPEECH AUDI P, V13, P293, DOI 10.1109/TSA.2004.838534
   Lee J, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1537
   Li RN, 2019, INT CONF ACOUST SPEE, P6675, DOI 10.1109/icassp.2019.8682154
   Lin YL, 2005, PROCEEDINGS OF 2005 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-9, P4898
   Majumder N, 2019, AAAI CONF ARTIF INTE, P6818
   Mao QR, 2017, SPEECH COMMUN, V93, P1, DOI 10.1016/j.specom.2017.06.006
   Mao QR, 2014, IEEE T MULTIMEDIA, V16, P2203, DOI 10.1109/TMM.2014.2360798
   McFee B., 2015, P 14 PYTH SCI C, P18, DOI [DOI 10.25080/MAJORA-7B98E3ED-003, 10.25080/Majora-7b98e3ed-003]
   Mirsamadi S, 2017, INT CONF ACOUST SPEE, P2227, DOI 10.1109/ICASSP.2017.7952552
   Morrison D, 2007, SPEECH COMMUN, V49, P98, DOI 10.1016/j.specom.2006.11.004
   Narayanan S, 2013, P IEEE, V101, P1203, DOI 10.1109/JPROC.2012.2236291
   Ocquaye ENN, 2021, INT J INTELL SYST, V36, P53, DOI 10.1002/int.22291
   Paszke A, 2019, ADV NEUR IN, V32
   Rajamani ST, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6294, DOI 10.1109/ICASSP39728.2021.9414489
   Rozgic V, 2012, ASIAPAC SIGN INFO PR
   Sarma M, 2018, INTERSPEECH, P3097, DOI 10.21437/Interspeech.2018-1353
   Satt A, 2017, INTERSPEECH, P1089, DOI 10.21437/Interspeech.2017-200
   Schuller B, 2003, INT CONF ACOUST SPEE, P1
   Schuller B, 2010, IEEE T AFFECT COMPUT, V1, P119, DOI 10.1109/T-AFFC.2010.8
   Tellai M, 2023, Int J Speech Technol, P1
   Thornton MA, 2017, P NATL ACAD SCI USA, V114, P5982, DOI 10.1073/pnas.1616056114
   Trigeorgis G, 2016, INT CONF ACOUST SPEE, P5200, DOI 10.1109/ICASSP.2016.7472669
   Wang C, 2021, Multimed Tools Appl, P1
   Wang JY, 2020, INT CONF ACOUST SPEE, P6474, DOI [10.1109/icassp40776.2020.9054629, 10.1109/ICASSP40776.2020.9054629]
   Xu XZ, 2017, IEEE-ACM T AUDIO SPE, V25, P1436, DOI 10.1109/TASLP.2017.2694704
   Yeh SL, 2020, INT CONF ACOUST SPEE, P6479, DOI 10.1109/icassp40776.2020.9053561
   Yeh SL, 2019, INT CONF ACOUST SPEE, P6685, DOI 10.1109/ICASSP.2019.8683293
   Yoon S, 2018, IEEE W SP LANG TECH, P112, DOI 10.1109/SLT.2018.8639583
   Zhao JF, 2019, BIOMED SIGNAL PROCES, V47, P312, DOI 10.1016/j.bspc.2018.08.035
   Zheng C, 2022, Multimed Tools Appl, P1
   Zhou SP, 2018, AAAI CONF ARTIF INTE, P579
NR 54
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 29
PY 2023
DI 10.1007/s11042-023-17803-7
EA DEC 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DL1O1
UT WOS:001132108500001
DA 2024-07-18
ER

PT J
AU Zhang, WY
   Feng, YN
   Lü, F
   Song, CM
   Wang, XH
AF Zhang, Wenya
   Feng, Yining
   Lu, Fang
   Song, Chuanming
   Wang, Xianghai
TI Medical image segmentation model based on caputo fractional differential
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fractional calculus; Medical image segmentation; CV model; Caputo
   fractional differential; Mask operator
ID ACTIVE CONTOURS
AB Medical image segmentation technology, as a key work of modern medical such as intelligent medical diagnosis, has attracted a lot of attention. However, the gray heterogeneity of medical images makes accurate target segmentation of " focus " greatly difficult. In recent years, fractional calculus has attracted much attention in the field of image processing because of its good nonlinear processing characteristics. In this paper, a medical image segmentation model based on Caputo fractional differentia, Caputo CV model, is proposed. The Caputo fractional differential with weak singularity is introduced into the model, and the feasibility of the model is proved theoretically. At the same time, according to the characteristics of high-order Caputo fractional differential and low-order Caputo fractional differential, in the numerical calculation of the model, the fitting term of the model is processed by the high-order Caputo fractional differential mask operator of order in interval (2,3), and the gradient in the approximation term of the model is discretized by the low-order Caputo fractional differential operator of order in interval (0,1). By doing this, the model can effectively maintain the nonlinear characteristics of image low-frequency information while enhancing the high-frequency information in the iteration process, so that make the evolution process of the model more stable and effective. A large number of experiments show that the proposed model can effectively improve the accuracy of gray inhomogeneous target segmentation and greatly reduce the running time.
C1 [Zhang, Wenya; Feng, Yining; Wang, Xianghai] Liaoning Normal Univ, Sch Geog, Dalian City 116029, Peoples R China.
   [Zhang, Wenya] Changchun Univ Sci & Technol, Sch Comp Sci & Technol, Changchun 130022, Jilin, Peoples R China.
   [Zhang, Wenya; Lu, Fang] Liaoning Normal Univ, Sch Math, Dalian 116029, Liaoning, Peoples R China.
   [Song, Chuanming; Wang, Xianghai] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian City 116029, Peoples R China.
C3 Liaoning Normal University; Changchun University of Science &
   Technology; Liaoning Normal University; Liaoning Normal University
RP Wang, XH (corresponding author), Liaoning Normal Univ, Sch Geog, Dalian City 116029, Peoples R China.; Wang, XH (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian City 116029, Peoples R China.
EM chmsong@lnnu.edu.cn; xhwang@lnnu.edu.cn
FU Innovation Team Support Program of Liaoning Higher Education Department
FX No Statement Available
CR Antonelli L, 2021, Annali dell'Universita di Ferrara, V68, P277
   Barbu T, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/1701052
   Butzer P. L., 2015, APIDOLOGIE, V33, P233
   CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen B, 2019, APPL MATH MODEL, V65, P120, DOI 10.1016/j.apm.2018.08.009
   Chen Qingli, 2013, Journal of Computer Aided Design & Computer Graphics, V25, P519
   Feng KD, 2020, INT J DISTRIB SENS N, V16, DOI 10.1177/1550147720903607
   Heena Ayesha, 2019, 2019 1st International Conference on Advances in Information Technology (ICAIT). Proceedings, P180, DOI 10.1109/ICAIT47043.2019.8987396
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kaur C., 2021, TURCOMAT, V12, P2667
   Khin Thuzar, 2020, Proceedings of the Third International Conference on Computational Intelligence and Informatics. ICCII 2018. Advances in Intelligent Systems and Computing (AISC 1090), P213, DOI 10.1007/978-981-15-1480-7_17
   Li CM, 2007, PROC CVPR IEEE, P339
   Li YM, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5763
   Liu XB, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13031224
   Mainardi F, 2018, MATHEMATICS-BASEL, V6, DOI 10.3390/math6090145
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   Mishra S, 2022, IEEE T MED IMAGING, V41, P1560, DOI 10.1109/TMI.2022.3143371
   Mondal A, 2020, SOFT COMPUT, V24, P14411, DOI 10.1007/s00500-020-04794-y
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Podlubny I., 1999, FRACTIONAL DIFFERENT
   Ramesh K.K.D., 2018, EAI ENDORSED T PERVA, DOI DOI 10.4108/EAI.12-4-2021.169184
   Sadoughi F, 2018, BREAST CANCER-TARGET, V10, P219, DOI 10.2147/BCTT.S175311
   Song Y, 2016, DIGIT SIGNAL PROCESS, V48, P322, DOI 10.1016/j.dsp.2015.10.005
   Tian D, 2013, CHIN CONT DECIS CONF, P37
   Wang XH, 2022, J Comput Res, VDev60, P448
   Wang XH, 2020, IET IMAGE PROCESS, V14, P1614, DOI 10.1049/iet-ipr.2018.5027
   Wu Q., 2016, FRACTIONAL CALCULUS
   Xue D.Y, 2018, FRACTIONAL CALCULUS
   Zhang KH, 2016, IEEE T CYBERNETICS, V46, P546, DOI 10.1109/TCYB.2015.2409119
   Zhang Y., 2021, J Beijing Inst Technol, V30, P254, DOI [DOI 10.15918/J.JBIT1004-0579.2021.028, 10.15918/j.jbit1004-0579.2021.028]
   Zhao WX, 2022, SIGNAL PROCESS, V190, DOI 10.1016/j.sigpro.2021.108292
   Zou L, 2021, NEUROCOMPUTING, V452, P606, DOI 10.1016/j.neucom.2020.07.141
NR 34
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 29
PY 2023
DI 10.1007/s11042-023-17872-8
EA DEC 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DL1O1
UT WOS:001132108500004
DA 2024-07-18
ER

PT J
AU Dzhanashia, K
   Evsutin, O
AF Dzhanashia, Kristina
   Evsutin, Oleg
TI FPGA implementation of robust and low complexity template-based
   watermarking for digital images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Watermarking; Digital images; Image processing; Template-based
   watermarking; FPGA
ID HEAT-RELATED MORTALITY; HEALTH; STEGANOGRAPHY; ARCHITECTURES;
   ADAPTATION; STRATEGIES; WEATHER; EUROPE; GREEN; COLD
AB Watermarking is a widespread technique for information protection and an invisible alternative to quick response codes. The literature mainly considers software implementations of watermarking methods, even though there are applications for which hardware watermarking solutions become preferable or the only possible option due to increased speed, power, or information safety requirements. A convenient, flexible, and universal solution for hardware development is intellectual property (IP) cores. IP cores are building blocks for creating processors on FPGA or ASIC. The main objective of this work is to present the implementation of the robust watermarking method in the form of an IP core suitable for image processing systems on processors. The main contribution of this work is that it is the first hardware implementation of template-based watermarking for modern neural network-based extraction methods. The paper briefly discusses the existing hardware solutions for embedding data, describes the implemented watermarking method and the implementation itself, and provides the key indicators of the resulting solution and a link to the public repository with the solution. The proposed watermarking scheme has good imperceptibility (PSNR of 39.66), bpp of 0.00097, and BER of less than 3% for attacks. The implementation supports a frequency of 120 MHz.
C1 [Dzhanashia, Kristina; Evsutin, Oleg] HSE Univ, 20 Myasnitskaya Ulitsa, Moscow 101000, Russia.
C3 HSE University (National Research University Higher School of Economics)
RP Evsutin, O (corresponding author), HSE Univ, 20 Myasnitskaya Ulitsa, Moscow 101000, Russia.
EM kdzhanashia@hse.ru; evsutin.oo@gmail.com
RI Evsutin, Oleg/E-6719-2017
OI Evsutin, Oleg/0000-0002-8257-2082
FU HSE University; Basic Research Program at the National Research
   University Higher School of Economics (HSE University)
FX This work is an output of a research project implemented as part of the
   Basic Research Program at the National Research University Higher School
   of Economics (HSE University). We are very grateful to the anonymous
   referees for their constructive comments and helpful suggestions to
   improve the quality of this paper.
CR Azzaz MS, 2023, 2023 INT C ADV ELECT, P1
   Ball J, 2007, Processor design, DOI [10.1007/978-1-4020-5530-0_11, DOI 10.1007/978-1-4020-5530-0_11]
   Bhattacharjee T, 2022, MULTIMED TOOLS APPL, V81, P18755, DOI 10.1007/s11042-022-12451-9
   Coltuc D, 2007, IEEE SIGNAL PROC LET, V14, P255, DOI 10.1109/LSP.2006.884895
   Das S, 2021, MICROPROCESS MICROSY, V83, DOI 10.1016/j.micpro.2020.103732
   Dzhanashia K, 2022, COMPUT ELECTR ENG, V102, DOI 10.1016/j.compeleceng.2022.108194
   Fang H, 2021, IEEE T CIRC SYST VID, V31, P1436, DOI 10.1109/TCSVT.2020.3009349
   Hartung F, 1999, P IEEE, V87, P1079, DOI 10.1109/5.771066
   Hussain S, 2022, Digest of Technical Papers
   Ismail SM, 2020, AEU-INT J ELECTRON C, V125, DOI 10.1016/j.aeue.2020.153367
   Janakiraman S, 2019, MULTIMED TOOLS APPL, V78, P31485, DOI 10.1007/s11042-019-07960-z
   KarthigaiKumar P, 2011, J SYST ARCHITECT, V57, P404, DOI 10.1016/j.sysarc.2010.03.008
   Madhushree B, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-16706-x
   Mahesh AA, 2019, INT J ADV COMPUT SC, V10, P226
   Maity HK, 2014, J SYST SOFTWARE, V96, P93, DOI 10.1016/j.jss.2014.05.079
   Maity SP, 2013, AEU-INT J ELECTRON C, V67, P438, DOI 10.1016/j.aeue.2012.10.014
   Mohanty SP, 2009, J SYST ARCHITECT, V55, P468, DOI 10.1016/j.sysarc.2009.09.005
   Phadikar A, 2020, MULTIMED TOOLS APPL, V79, P12507, DOI 10.1007/s11042-019-08392-5
   Phadikar A, 2020, MULTIDIM SYST SIGN P, V31, P73, DOI 10.1007/s11045-019-00650-x
   Roy A, 2023, J SUPERCOMPUT, V79, P20790, DOI 10.1007/s11227-023-05450-6
   Sabeeh LN, 2024, Communications in computer and information science, V1911, DOI [10.1007/978-981-99-7240-1_1, DOI 10.1007/978-981-99-7240-1_1]
   Shet KS, 2019, MULTIMED TOOLS APPL, V78, P18309, DOI 10.1007/s11042-019-7187-2
   Sivaraman R, 2023, MULTIMED TOOLS APPL, V82, P21193, DOI 10.1007/s11042-023-14725-2
   Sun JY, 2023, DIGIT SIGNAL PROCESS, V134, DOI 10.1016/j.dsp.2022.103889
   Swetha V, 2023, 2023 INT C BIOSIGNAL, P1
   Tahiri MA, 2023, J KING SAUD UNIV-COM, V35, DOI 10.1016/j.jksuci.2023.101604
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Yuan F, 2021, SIGNAL PROCESS-IMAGE, V91, DOI 10.1016/j.image.2020.116082
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 29
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 27
PY 2023
DI 10.1007/s11042-023-17876-4
EA DEC 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ3E1
UT WOS:001131620700003
DA 2024-07-18
ER

PT J
AU Kumar, M
AF Kumar, Manish
TI A new RGB image encryption algorithm based on
   hyper-chaotic-discrete-wavelet-packet-transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Hyper-chaotic system; Discrete wavelet packet transform; 2D and 3D
   chaotic diffusion; Encryption; Decryption
ID SCHEME
AB The paper proposes a new hyper-chaotic-discrete-wavelet-packet-transform encryption algorithm for RGB images. The highlight is that the 512-bit hash of timestamp is used to get the initial values of the 4D hyper-chaotic system. The sequences generated by the 4D Lorenz system are used to construct 12 keys for encryption. The proposed encryption algorithm uses a newly designed 3D chaotic diffusion and inter-shuffling of pixels followed by 2D diffusion to improve security levels. The obtained images will go through another deep level of diffusion and shuffling in approximation coefficients (where most of the information is stored) after applying discrete wavelet packet transform at the desired level with a wavelet "name" selected by users. This step resists commonly well-known attacks such as differential, noise, and crop attacks. After that, modified approximation coefficients and other remaining coefficients, namely horizontal, vertical, and diagonal coefficients, are reverted back using the inverse wavelet packet transform. In the end, another layer of chaotic diffusion and row-column matrix shuffling is performed to avoid high redundancy and correlation in the encrypted image. The main advantage of using the hyper-chaotic system in the encryption process is that it gives a vast key space to make brute-force attacks infeasible and provides excellent speed to the proposed algorithm. The randomness of the encrypted image has been verified using the NIST SP800-22 statistical test suite. Several well-known attacks have been used to validate the algorithm's robustness. The proposed technique has been compared with other existing algorithms, and the data (presented in tables) confirm that the proposed algorithm is competitive and can be used for practical purposes. Finally, a conclusion, including a future scope, has been provided.
C1 [Kumar, Manish] Birla Inst Technol & Sci Pilani, Dept Math, Hyderabad Campus, Hyderabad 500078, Telangana, India.
C3 Birla Institute of Technology & Science Pilani (BITS Pilani)
RP Kumar, M (corresponding author), Birla Inst Technol & Sci Pilani, Dept Math, Hyderabad Campus, Hyderabad 500078, Telangana, India.
EM manish.math.bhu@gmail.com
RI Kumar, Prof. Manish/C-9163-2012
OI Kumar, Prof. Manish/0000-0003-2925-4218
FU Science & Engineering Research Board, Government of India
   [YSS/2015/000930]
FX The author is thankful to the Science & Engineering Research Board,
   Government of India, for providing financial support through project
   file no. YSS/2015/000930. We sincerely thank the editor for their
   invaluable guidance and the anonymous reviewers for their thorough
   evaluations. Their collective efforts have played a pivotal role in
   enhancing the quality and impact of this research paper.
CR [Anonymous], 1992, Wavelets and their Applications
   Belazi A, 2017, OPT LASER ENG, V88, P37, DOI 10.1016/j.optlaseng.2016.07.010
   Bhatnagar G, 2013, INFORM SCIENCES, V223, P297, DOI 10.1016/j.ins.2012.09.053
   Coifman R.R., 1992, WAVELETS ANDTHEIRAPP, P453
   Dou YQ, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10062187
   Huang CK, 2009, OPT COMMUN, V282, P2123, DOI 10.1016/j.optcom.2009.02.044
   Kanso A, 2017, OPT LASER ENG, V90, P196, DOI 10.1016/j.optlaseng.2016.10.009
   Kaur M, 2023, IEEE ACCESS, V11, P90739, DOI 10.1109/ACCESS.2023.3305271
   Kong DZ, 2014, OPT LASER TECHNOL, V57, P343, DOI 10.1016/j.optlastec.2013.08.013
   Kumar M., 2020, Multimedia Security Using Chaotic Maps: Principles and Methodologies, P1
   Kumar M, 2016, INT J WAVELETS MULTI, V14, DOI 10.1142/S0219691316500089
   Kumar M, 2017, OPT LASER ENG, V88, P51, DOI 10.1016/j.optlaseng.2016.07.009
   Li CQ, 2018, IEEE ACCESS, V6, P75834, DOI 10.1109/ACCESS.2018.2883690
   Lian SG, 2005, CHAOS SOLITON FRACT, V26, P117, DOI 10.1016/j.chaos.2004.11.096
   Lin R., 2021, SECUR COMMUN NETW, V2021, P1
   Liu HJ, 2023, MULTIMED TOOLS APPL, V82, P23899, DOI 10.1007/s11042-022-12069-x
   Liu HJ, 2019, APPL MATH COMPUT, V360, P83, DOI 10.1016/j.amc.2019.04.078
   Liu HJ, 2017, IET IMAGE PROCESS, V11, P324, DOI 10.1049/iet-ipr.2016.0040
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu S, 2013, OPT COMMUN, V287, P73, DOI 10.1016/j.optcom.2012.09.033
   Luo YL, 2015, COMMUN NONLINEAR SCI, V20, P447, DOI 10.1016/j.cnsns.2014.05.022
   Mallat S., 1998, WAVELET TOUR SIGNAL
   Noshadian S, 2020, MULTIMED TOOLS APPL, V79, P25635, DOI 10.1007/s11042-020-09233-6
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   Qin Y, 2016, OPT LASER ENG, V77, P191, DOI 10.1016/j.optlaseng.2015.09.002
   Ruch DK., 2009, Wavelet theory: an elementary approach with applications, DOI [10.1002/9781118165652, DOI 10.1002/9781118165652]
   Sui LS, 2013, OPT LASER ENG, V51, P1297, DOI 10.1016/j.optlaseng.2013.06.005
   Taneja N, 2011, AEU-INT J ELECTRON C, V65, P338, DOI 10.1016/j.aeue.2010.04.011
   Tang M, 2022, OPTIK, V261, DOI 10.1016/j.ijleo.2022.169133
   Vilardy JM, 2017, OPT LASER ENG, V89, P88, DOI 10.1016/j.optlaseng.2016.02.013
   Wu X, 2016, Inform Sci, P349
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Ye GD, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500104
   Zhang XQ, 2012, OPT COMMUN, V285, P1736, DOI 10.1016/j.optcom.2011.12.023
NR 34
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 21
PY 2023
DI 10.1007/s11042-023-17812-6
EA DEC 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5U7
UT WOS:001129334000002
DA 2024-07-18
ER

PT J
AU Hepsag, PU
AF Uskaner Hepsag, Pinar
TI Efficient plant disease identification using few-shot learning: a
   transfer learning approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Plant disease identification; Few-shot learning; Deep learning; Machine
   learning; Crop protection; PlantVillage; PDD271
ID RECOGNITION; IMAGES
AB Traditional disease identification methods are time-consuming and necessitate specialized knowledge, making them unsuitable for large-scale crop production. In such circumstances, conventional methods of deep learning are impractical. Machine learning techniques, particularly few-shot learning, can help to overcome these challenges by allowing the development of accurate and efficient plant disease identification models with a small amount of training data. The study proposes a few-shot learning strategy for identifying plant diseases, which involves using a pre-trained model on the ImageNet dataset and refining it with a relatively similar type of dataset PlantCLEF2022 for plant-based features extraction. This fine-tuned model is used to extract embedding from plant leaf images to train and classify few shot scenario of plant disease identification. The classification head of the Convolutional Neural Networks (CNN) model is replaced with a Support Vector Machines (SVM) classifier to train with fewer example images in each class. Experiments are performed on popular PlantVillage dataset having 38 classes and PDD271 dataset having 271 classes. The proposed few-shot learning framework outperformed previous methods for few-shot plant disease classification, achieving an average accuracy of 88.4% at 10-shots and 75.5% at 5-shots on PlantVillage dataset. PDD271 dataset is relatively new in few-shot learning but have larger number of classes and the proposed framework provided an accuracy of 56.3% at single-shot, 67.5% for 3-shots and 74.20% for 5-shots scenario.
C1 [Uskaner Hepsag, Pinar] Adana Alparslan Turkes Sci & Technol Univ, Comp Engn Dept, TR-01250 Saricam, Adana, Turkiye.
C3 Adana Alparslan Turkes Science & Technology University
RP Hepsag, PU (corresponding author), Adana Alparslan Turkes Sci & Technol Univ, Comp Engn Dept, TR-01250 Saricam, Adana, Turkiye.
EM puskaner@atu.edu.tr
CR Rusu AA, 2019, Arxiv, DOI arXiv:1807.05960
   Ahmad N, 2021, WIRELESS PERS COMMUN, V121, P1139, DOI 10.1007/s11277-021-09054-2
   Ahmed N, 2016, Science International, V28, DOI DOI 10.9790/0661-17134853
   Ahmed N, 2019 13 INT C MATH A, P1
   Ahmed N, 2022, Arxiv, DOI arXiv:2209.12443
   Ahmed N, 2022, SOFT COMPUT, V26, P7601, DOI 10.1007/s00500-021-06662-9
   Ahmed N, 2021, MULTIMED TOOLS APPL, V80, P15677, DOI 10.1007/s11042-020-10286-w
   Ahmed N, 2020, COMPUT INFORM, V39, P385, DOI 10.31577/cai_2020_3_385
   Argüeso D, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105542
   Aslam MA, Vrl-iqa: visual representation learning for image quality assessment
   Bertinetto L, 2019, Arxiv, DOI arXiv:1805.08136
   Chaudhary A, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105747
   Chen JD, 2020, COMPUT ELECTRON AGR, V173, DOI 10.1016/j.compag.2020.105393
   Chen LZ, 2021, FOODS, V10, DOI 10.3390/foods10102441
   Darwish A, 2020, SWARM EVOL COMPUT, V52, DOI 10.1016/j.swevo.2019.100616
   Farjon G, 2020, PRECIS AGRIC, V21, P503, DOI 10.1007/s11119-019-09679-1
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Finn C, 2018, ADV NEUR IN, V31
   Goeau H., 2022, CLEF 2022, V3180, P1916
   Hariharan B, 2017, IEEE I CONF COMP VIS, P3037, DOI 10.1109/ICCV.2017.328
   Hassan SM, 2022, IEEE ACCESS, V10, P5390, DOI 10.1109/ACCESS.2022.3141371
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu GS, 2019, COMPUT ELECTRON AGR, V163, DOI 10.1016/j.compag.2019.104852
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Karthik R, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105933
   Kim Sungyeon., Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, P3238
   KOCH G., ICML DEEP LEARN WORK, V2
   Kolesnikov Alexander, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P491, DOI 10.1007/978-3-030-58558-7_29
   Lee S, 2017, 24TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2017), DOI [10.14722/ndss.2017.23457, 10.1016/j.patcog.2017.05.015]
   Li Y, 2021, COMPUT ELECTRON AGR, V182, DOI 10.1016/j.compag.2021.106055
   Li Y, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105803
   Li Y, 2020, AGRICULTURE-BASEL, V10, DOI 10.3390/agriculture10050178
   Li Y, 2020, COMPUT ELECTRON AGR, V169, DOI 10.1016/j.compag.2020.105240
   Lin H, 2022, PLANTS-BASEL, V11, DOI 10.3390/plants11212814
   Liu B, 2020, FRONT PLANT SCI, V11, DOI 10.3389/fpls.2020.01082
   Liu J, 2021, PLANT METHODS, V17, DOI 10.1186/s13007-021-00722-9
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Nichol A, 2018, Arxiv, DOI [arXiv:1803.02999, DOI 10.48550/ARXIV.1803.02999]
   Nie J, IOP conference series: earth and environmental science, V697
   Nie J, 2019, J MAGN, V24, P328, DOI 10.4283/JMAG.2019.24.2.328
   Pan JC, 2022, J PLANT DIS PROTECT, V129, P651, DOI 10.1007/s41348-022-00585-9
   Ren FJ, 2019, IEEE ACCESS, V7, P122758, DOI 10.1109/ACCESS.2019.2938194
   Saleem G, 2019, COMPUT ELECTRON AGR, V157, P270, DOI 10.1016/j.compag.2018.12.038
   Schönfeld E, 2019, PROC CVPR IEEE, P8239, DOI 10.1109/CVPR.2019.00844
   Sethy PK, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105527
   Sheng XJ, 2016, MATER EVAL, V74, P1675
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh Vijai, 2017, Information Processing in Agriculture, V4, P41, DOI 10.1016/j.inpa.2016.10.005
   Snell J, 2017, ADV NEUR IN, V30
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tang Z, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105735
   Too EC, 2019, J INTELL FUZZY SYST, V37, P4003, DOI 10.3233/JIFS-190184
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Trong VH, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105506
   Wang L, 2020, IEEE ACCESS, V8, P63514, DOI 10.1109/ACCESS.2020.2982224
   Wang YY, 2020, AGR WATER MANAGE, V239, DOI 10.1016/j.agwat.2020.106163
   Wen BQ, 2021, J BIOMECH, V118, DOI 10.1016/j.jbiomech.2020.110198
   Wu XP, 2019, PROC CVPR IEEE, P8779, DOI 10.1109/CVPR.2019.00899
   Xu M, 2022, FRONT PLANT SCI, V13, DOI 10.3389/fpls.2022.1010981
   Zaman MI, 2024, MULTIMED TOOLS APPL, V83, P17163, DOI 10.1007/s11042-023-16243-7
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhong FM, 2020, COMPUT ELECTRON AGR, V179, DOI 10.1016/j.compag.2020.105828
NR 63
TC 0
Z9 0
U1 9
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 21
PY 2023
DI 10.1007/s11042-023-17824-2
EA DEC 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5U7
UT WOS:001129334000004
DA 2024-07-18
ER

PT J
AU Li, Y
   Wu, JS
   Li, WG
   Dong, W
   Fang, AQ
AF Li, Ying
   Wu, Junsheng
   Li, Weigang
   Dong, Wei
   Fang, Aiqing
TI Hierarchical aggregation perceptual pipeline for tactical intention
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Neural network; Intention recognition; Hierarchy
   aggregation
AB Tactical intention recognition involves the analysis of target information to interpret and accurately determine hostile intentions, which is crucial for auxiliary decision-making. The recognition challenges are posed by hierarchical and long-term dependencies in tactical intention. To this end, we propose a pipeline that enhances intention recognition performance by perceiving and aggregating the hierarchy information within the tactical context, termed Hierarchical Aggregation Perceptual Pipeline (HAGP). Specifically, the HAGP comprises two pipelines: maneuver features perceive (MFP), and intention features aggregate (IFA). The MFP captures the maneuver features, which are sub-intentioned with hierarchical information, and the IFA aggregates long-term dependencies in each intention. Then, combining these representations to facilitate precise tactical intention recognition. Extensive experimental results on the tactical dataset demonstrate the superiority of our pipeline compared with the state-of-the-art methods.
C1 [Li, Ying; Wu, Junsheng; Dong, Wei; Fang, Aiqing] Northwestern Polytech Univ, Sch Comp Sci & Engn, 1 Dongxiang Rd, Xian 710129, Shaanxi, Peoples R China.
   [Li, Weigang] Northwestern Polytech Univ, Sch Software, 1 Dongxiang Rd, Xian 710129, Shaanxi, Peoples R China.
C3 Northwestern Polytechnical University; Northwestern Polytechnical
   University
RP Li, WG (corresponding author), Northwestern Polytech Univ, Sch Software, 1 Dongxiang Rd, Xian 710129, Shaanxi, Peoples R China.
EM liying_npu@mail.nwpu.edu.cn; wujunsheng@nwpu.edu.cn;
   liweigang@nwpu.edu.cn; dw156@mail.nwpu.edu.cn; aiqingf@mail.nwpu.edu.cn
OI Li, Ying/0000-0002-9925-4558
FU National Science and technology projects of China; Key R & D projects of
   Shaanxi Province [D5140190006];  [D5120190078]
FX This work has been supported by these following projects: (1) Grant No.
   D5120190078, National Science and technology projects of China. (2)
   Grant No. D5140190006, Key R & D projects of Shaanxi Province.
CR Ahmed AA, 2018, J COMPUT SCI-NETH, V25, P467, DOI 10.1016/j.jocs.2017.09.007
   Basir O, 2007, INFORM FUSION, V8, P379, DOI 10.1016/j.inffus.2005.07.003
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dahlbom Anders, 2013, Modeling Decisions for Artificial Intelligence. 10th International Conference, MDAI 2013. Proceedings: LNCS 8234, P70, DOI 10.1007/978-3-642-41550-0_7
   Das S, 2002, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON INFORMATION FUSION, VOL I, P664, DOI 10.1109/ICIF.2002.1021218
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Fredrik J, 2006, 2006 9 INT C INF FUS, P1
   Ge Shun, 2014, Systems Engineering and Electronics, V36, P76, DOI 10.3969/j.issn.1001-506X.2014.01.12
   Jiang W, 2012, Green Communications and Networks, P975
   Kim Y., 2014, P 2014 C EMP METH NA, P1746, DOI [DOI 10.3115/V1/D14-1181, 10.3115/v1/D14-1181]
   Kingma D. P., 2014, arXiv
   Li YC, 2022, INT C CONTR AUTOMAT, P32, DOI 10.23919/ICCAS55662.2022.10003924
   Liu P, 2016, ARXIV160505101
   NOBLE DF, 1989, IEEE T SYST MAN CYB, V19, P473, DOI 10.1109/21.31054
   Ou S., 2016, COMMAND CONTROL SIMU, V38, P36, DOI DOI 10.3969/J.ISSN.1673-3819.2016.06.008
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Qu CX, 2022, Evol Intell
   [史浩宇 Shi Haoyu], 2019, [火力与指挥控制, Fire Control & Command Control], V44, P51
   Teng F, 2021, IEEE ACCESS, V9, P169122, DOI 10.1109/ACCESS.2021.3135495
   Teng F, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/6082242
   Tong C, 2018, APPL SOFT COMPUT, V73, P344, DOI 10.1016/j.asoc.2018.07.061
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang C, 2019, PR MACH LEARN RES, V97
   Wang Xingyu, 2022, 2022 IEEE International Conference on Unmanned Systems (ICUS), P63, DOI 10.1109/ICUS55513.2022.9986667
   Wang ZG., 2021, Acta Aeronaut. Astronaut. Sin, V42, P47
   Xie H., 2017, Electro-Optic Technol Appl, V32, P41
   Zhao F. J., 2017, Electron Optics Control, V24, P50
   [赵佳欢 Zhao Jiahuan], 2020, [航天控制, Aerospace Control], V38, P47
   [周旺旺 Zhou Wangwang], 2018, [航空学报, Acta Aeronautica et Astronautica Sinica], V39, P322468
NR 29
TC 0
Z9 0
U1 8
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 20
PY 2023
DI 10.1007/s11042-023-17806-4
EA DEC 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4E4
UT WOS:001126688600002
DA 2024-07-18
ER

PT J
AU Akram, SW
   Kumar, APS
AF Akram, Sk. Wasim
   Kumar, A. P. Siva
TI Parkinson's disease diagnosis from T1 and T2 weighted magnetic resonance
   images using FBLstmNet architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Parkinson's disease detection; Gabor filtering; Image
   decomposition-based feature extraction; Tunicate swarm optimization;
   Fired Bilateral Long-short term memory
AB Parkinson's is a dreadful neurodegenerative disorder disease which affects people over the age of 40 around the world. To reduce the risk factors of Parkinson's, early diagnosis is highly required; therefore, the existing studies have developed different methods for an effective detection process. However, the existing methods failed to produce improved classification accuracy because of several limitations, such as higher computational complexity, excess irrelevant features, noisy samples, etc. Therefore, the proposed study introduces a new deep-learning mechanism to mitigate such issues. The most important steps involved in the proposed work are pre-processing, feature extraction, optimal feature selection and classification. Initially, the given raw input images are pre-processed to eliminate unwanted noises through the Gabor filtering process. The significant features are extracted from the pre-processed images using image decomposition methods like Empirical Wavelet Transform (EWT) and Dual-Tree Complex Wavelet Transform (DT-CWT). In order to reduce the higher feature dimensionality issue, optimal features are selected by the Tunicate Swarm Optimization (TSO) algorithm. Finally, the multiple classes of Parkinson's are classified by proposing a new Fired Bilateral Long-short-term Memory Network (FBLstmNet) model. For simulation, Python is employed, and the performance of the proposed model is analyzed by comparing the results with other existing methods. The experimental results exhibit that the proposed method gains superior classification performance in terms of accuracy (99.5%), precision (99.54%), recall (99.52%), specificity (99.57%) and F-measure (99.56%).
C1 [Akram, Sk. Wasim] Jawaharlal Nehru Technol Univ Anantapur, Dept Comp Sci & Engn, Ananthapuramu 515002, Andhra Pradesh, India.
   [Kumar, A. P. Siva] Jawaharlal Nehru Technol Univ Anantapur, Dept Comp Sci & Engn, Ananthapuramu 515002, Andhra Pradesh, India.
C3 Jawaharlal Nehru Technological University - Anantapur; Jawaharlal Nehru
   Technological University - Anantapur
RP Akram, SW (corresponding author), Jawaharlal Nehru Technol Univ Anantapur, Dept Comp Sci & Engn, Ananthapuramu 515002, Andhra Pradesh, India.
EM shaikwasimakram585@gmail.com
CR Almeida JS, 2019, PATTERN RECOGN LETT, V125, P55, DOI 10.1016/j.patrec.2019.04.005
   Aouraghe I, 2023, MULTIMED TOOLS APPL, V82, P11923, DOI 10.1007/s11042-022-13759-2
   Armstrong MJ, 2020, JAMA-J AM MED ASSOC, V323, P548, DOI 10.1001/jama.2019.22360
   Arribarat G, 2020, FRONT NEUROL, V11, DOI 10.3389/fneur.2020.00791
   Asuroglu T, 2022, HEALTH TECHNOL-GER, V12, P943, DOI 10.1007/s12553-022-00698-z
   Bae YJ, 2021, RADIOLOGY, V300, P260, DOI 10.1148/radiol.2021203341
   Basnin N, 2021, LECT NOTES ARTIF INT, V12960, P536, DOI 10.1007/978-3-030-86993-9_48
   Blauwendraat C, 2020, LANCET NEUROL, V19, P170, DOI 10.1016/S1474-4422(19)30287-X
   Camacho M, 2023, NEUROIMAGE-CLIN, V38, DOI 10.1016/j.nicl.2023.103405
   Chakraborty S, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10060402
   Chougar L, 2020, FRONT NEUROL, V11, DOI 10.3389/fneur.2020.00665
   Dhinagar NJ, 2023, Arxiv, DOI arXiv:2302.13631
   Diaz M, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114405
   Heim B, 2017, J NEURAL TRANSM, V124, P915, DOI 10.1007/s00702-017-1717-8
   Kaplan E, 2022, COMPUT METH PROG BIO, V224, DOI 10.1016/j.cmpb.2022.107030
   Kaur S, 2021, MULTIMED TOOLS APPL, V80, P10113, DOI 10.1007/s11042-020-10114-1
   Kollia I, 2019, IEEE IJCNN, DOI 10.1109/IJCNN.2019.8851995
   Kurmi A, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12051173
   Laganas C, 2022, IEEE T BIO-MED ENG, V69, P1573, DOI 10.1109/TBME.2021.3116935
   Liu PS, 2020, FRONT NEUROL, V11, DOI 10.3389/fneur.2020.00248
   Loh HW, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10141740
   Marek K, 2018, ANN CLIN TRANSL NEUR, V5, P1460, DOI 10.1002/acn3.644
   Mostafa TA, 2020, IEEE INT C BIOINF BI, P987, DOI 10.1109/BIBE50027.2020.00167
   Nagasubramanian G, 2021, NEURAL COMPUT APPL, V33, P4849, DOI 10.1007/s00521-020-05233-7
   Pahuja G, 2021, IETE J RES, V67, P4, DOI 10.1080/03772063.2018.1531730
   Qureshi SA, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-30309-4
   Qureshi SA, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12083715
   Ryman SG, 2020, PARKINSONISM RELAT D, V73, P85, DOI 10.1016/j.parkreldis.2019.10.002
   Sadek R.M., 2019, International Journal of Academic Health and Medical Research, V3, P1
   Sarasso E, 2021, J NEUROL, V268, P3144, DOI 10.1007/s00415-020-09863-8
   Shinde S, 2019, NEUROIMAGE-CLIN, V22, DOI 10.1016/j.nicl.2019.101748
   Soumaya Z, 2021, APPL ACOUST, V171, DOI 10.1016/j.apacoust.2020.107528
   Taleb C, 2023, EVOL INTELL, V16, P1813, DOI 10.1007/s12065-020-00470-0
   Talitckii A, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3176898
   Tolosa E, 2021, LANCET NEUROL, V20, P385, DOI 10.1016/S1474-4422(21)00030-2
   Yousif Nada R, 2022, J Ambient Intell Humaniz Comput, P1, DOI 10.1007/s12652-022-04342-6
NR 36
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 13
PY 2023
DI 10.1007/s11042-023-17762-z
EA DEC 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB1N3
UT WOS:001122700100005
DA 2024-07-18
ER

PT J
AU Fernandez-Lanvin, D
   Gonzalez-Rodríguez, M
   De-Andres, J
   Camero, R
AF Fernandez-Lanvin, Daniel
   Gonzalez-Rodriguez, Martin
   De-Andres, Javier
   Camero, Raquel
TI Towards an automatic early screening system for autism spectrum disorder
   in toddlers based on eye-tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE ASD; Autism; Early screening; Behavioural markers; Machine learning; Eye
   gaze tracking
ID FACIAL EMOTION RECOGNITION; 6-MONTH-OLD INFANTS; SOCIAL ATTENTION;
   ABNORMALITIES; PATTERNS; SCENES
AB According to official estimations, autism spectrum disorder (ASD) affects around 1% of European newborns. The high level of dependency of ASD-affected subjects entails an extremely high social and economic cost. However, early intervention can drastically improve children's development and thus reduce their dependency. One of the main common characteristics of subjects with ASD is difficulties with social interaction, which determines how they react to certain stimuli. This behavior can be automatically detected by analyzing their gaze. This study explores and evaluates the feasibility of automatic screening for ASD in toddlers under 24 months of age based on this specific behavior. We applied a matched pairs experimental design and a set of test videos, using a set of variables extracted from gaze analysis from toddlers using eye-tracking devices. The different videos try to capture social engagement, social information gathering gaze exchanges, and gaze following. We used the data to make a thorough comparison of machine learning algorithms (nine learning schemes), including some that were used in related prior research, and others that are popular in classification problems. The results show that several of the tested algorithms provided notable performance.
C1 [Fernandez-Lanvin, Daniel; Gonzalez-Rodriguez, Martin] Univ Oviedo, Dept Comp Sci, c-Leopoldo Calvo Sotelo 18, Oviedo 33007, Spain.
   [De-Andres, Javier] Univ Oviedo, Fac Econ & Empresa, Dept Accounting, Ave Cristo s-n, Oviedo 33006, Spain.
   [Camero, Raquel] ADANSI, Gijon 33213, Spain.
C3 University of Oviedo; University of Oviedo
RP Fernandez-Lanvin, D (corresponding author), Univ Oviedo, Dept Comp Sci, c-Leopoldo Calvo Sotelo 18, Oviedo 33007, Spain.
EM dflanvin@uniovi.es; martin@uniovi.es; jdandres@uniovi.es;
   raquelcamero.adansi@gmail.com
RI Fernandez-Lanvin, Daniel/L-5470-2014; Gonzalez-Rodriguez,
   Martin/H-1768-2014
OI Fernandez-Lanvin, Daniel/0000-0002-5666-9809; Gonzalez-Rodriguez,
   Martin/0000-0002-9695-3919
FU Department of Science, Innovation and Universities (Spain) under the
   National Program for Research, Development, and Innovation
   [RTI2018-099235-B-I00]; Fundacion Trapote (Ayuntamiento de Gijon)
FX This work was partially funded by the Department of Science, Innovation
   and Universities (Spain) under the National Program for Research,
   Development, and Innovation (Project RTI2018-099235-B-I00) and by the
   Fundacion Trapote (Ayuntamiento de Gijon)
   (https://www.gijon.es/es/fundaciones/7).
CR AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470
   Akter Tania, 2021, 2021 2nd International Conference on Robotics, Electrical and Signal Processing Techniques (ICREST), P383, DOI 10.1109/ICREST51555.2021.9331152
   Alie D., 2011, P IEEE WORKSH APPL C, P282
   Altay O, 2018, 2018 6TH INTERNATIONAL SYMPOSIUM ON DIGITAL FORENSIC AND SECURITY (ISDFS), P218
   American Psychiatric Association, 2013, Diagnostic and statistical manual of mental disorders (DSM-5), V5th ed., DOI DOI 10.1176/APPI.BOOKS.9780890425596
   [Anonymous], 2014, International Journal of Computer Networks Communications, DOI DOI 10.5121/IJCNC.2014.6315
   Baum L. E., 1972, Inequalities, V3, P1
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Bovery M, 2021, IEEE T AFFECT COMPUT, V12, P722, DOI [10.1109/TAFFC.2018.2890610, 10.1109/taffc.2018.2890610]
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655
   Buescher AVS, 2014, JAMA PEDIATR, V168, P721, DOI 10.1001/jamapediatrics.2014.210
   Canavan S, 2017, IEEE IMAGE PROC, P3750, DOI 10.1109/ICIP.2017.8296983
   Carette Romuald, 2018, 2018 Thirteenth International Conference on Digital Information Management (ICDIM), P248, DOI 10.1109/ICDIM.2018.8846967
   Chawarska K, 2013, BIOL PSYCHIAT, V74, P195, DOI 10.1016/j.biopsych.2012.11.022
   Chawarska K, 2012, J CHILD PSYCHOL PSYC, V53, P903, DOI 10.1111/j.1469-7610.2012.02538.x
   De Giacomo A, 1998, EUR CHILD ADOLES PSY, V7, P131, DOI 10.1007/s007870050058
   Del Coco M, 2018, IEEE T COGN DEV SYST, V10, P993, DOI 10.1109/TCDS.2017.2783684
   Del Coco M, 2017, IEEE INT CONF COMP V, P1401, DOI 10.1109/ICCVW.2017.166
   Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941
   Drimalla H, 2019, LECT NOTES ARTIF INT, V11051, P193, DOI 10.1007/978-3-030-10925-7_12
   Dris AB, 2019, 2019 2 INT C COMP AP, P1
   Durand K, 2007, J EXP CHILD PSYCHOL, V97, P14, DOI 10.1016/j.jecp.2006.12.001
   Elsabbagh M, 2012, AUTISM RES, V5, P160, DOI 10.1002/aur.239
   Frank E., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P144
   Frazier TW, 2016, J AM ACAD CHILD PSY, V55, P301, DOI 10.1016/j.jaac.2016.01.011
   Freund Y., 1996, INT C MACHINE LEARNI, P148
   Guillon Q, 2014, NEUROSCI BIOBEHAV R, V42, P279, DOI 10.1016/j.neubiorev.2014.03.013
   Guthrie W, 2019, PEDIATRICS, V144, DOI 10.1542/peds.2018-3963
   Hall M., 1999, PhD thesis, DOI 10.1.1.149.3848
   Hastie T., 2009, The Elements of Statistical Learning
   Hyde KK, 2019, REV J AUTISM DEV DIS, V6, P128, DOI 10.1007/s40489-019-00158-x
   Jiang M, 2019, IEEE ENG MED BIO, P6063, DOI [10.1109/embc.2019.8857005, 10.1109/EMBC.2019.8857005]
   Jiang M, 2017, IEEE I CONF COMP VIS, P3287, DOI 10.1109/ICCV.2017.354
   John G. H., 1995, Uncertainty in Artificial Intelligence. Proceedings of the Eleventh Conference (1995), P338
   Jones W, 2008, ARCH GEN PSYCHIAT, V65, P946, DOI 10.1001/archpsyc.65.8.946
   Jones W, 2013, NATURE, V504, P427, DOI 10.1038/nature12715
   Joudar SS, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105553
   Kleinman JM, 2008, J AUTISM DEV DISORD, V38, P827, DOI 10.1007/s10803-007-0450-9
   Kollias KF, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10232982
   Kotthoff L, 2017, J MACH LEARN RES, V18
   Krishnappababu PR, 2021, IEEE T AFFECT COMPUT
   Lawi Armin, 2018, 2018 2nd East Indonesia Conference on Computer and Information Technology (EIConCIT). Proceedings, P218, DOI 10.1109/EIConCIT.2018.8878593
   Lezine I, 1992, Editions et Applications Psychologiques
   Lipkin PH, 2017, Infectiuous Diseases in Children
   Lord C, 2006, ARCH GEN PSYCHIAT, V63, P694, DOI 10.1001/archpsyc.63.6.694
   LORD C, 1989, J AUTISM DEV DISORD, V19, P185, DOI 10.1007/BF02211841
   Murias M, 2018, AUTISM RES, V11, P166, DOI 10.1002/aur.1894
   Oien RA, 2021, J AUTISM DEV DISORD, V51, P763, DOI 10.1007/s10803-020-04860-2
   Oien RA, 2018, PEDIATRICS, V141, DOI 10.1542/peds.2017-3596
   Oliveira JS, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-89023-8
   OSTERLING J, 1994, J AUTISM DEV DISORD, V24, P247, DOI 10.1007/BF02172225
   Payakachat N, 2016, PHARMACOECONOMICS, V34, P127, DOI 10.1007/s40273-015-0331-6
   Pierce K, 2016, BIOL PSYCHIAT, V79, P657, DOI 10.1016/j.biopsych.2015.03.032
   Pierce K, 2011, ARCH GEN PSYCHIAT, V68, P101, DOI 10.1001/archgenpsychiatry.2010.113
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN
   Russell S., 2016, Artificial intelligence a modern approach
   Saemundsen E, 2013, BMJ OPEN, V3, DOI 10.1136/bmjopen-2013-002748
   Sarabadani S, 2020, IEEE T AFFECT COMPUT, V11, P588, DOI 10.1109/TAFFC.2018.2820049
   Shic F, 2014, BIOL PSYCHIAT, V75, P231, DOI 10.1016/j.biopsych.2013.07.009
   Takarae Y, 2008, J INT NEUROPSYCH SOC, V14, P980, DOI 10.1017/S1355617708081277
   Thorup E, 2016, MOL AUTISM, V7, DOI 10.1186/s13229-016-0069-9
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   Tsang V, 2018, AUTISM, V22, P161, DOI 10.1177/1362361316667830
   Tyagi B, 2018, 2018 IEEE PUN IEEE, P1
   Vapnik V, 2000, The Nature of Statistical Learning Theory, DOI [DOI 10.1007/978-1-4757-3264-1, DOI 10.1007/978-1-4757-2440-0]
   Vargas-Cuentas NI, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0188826
   Vargas-Cuentas NI, 2016, IEEE GLOB HUMANIT C, P624, DOI 10.1109/GHTC.2016.7857343
   Wan GB, 2019, J AUTISM DEV DISORD, V49, P209, DOI 10.1007/s10803-018-3690-y
   Wang S, 2015, NEURON, V88, P604, DOI 10.1016/j.neuron.2015.09.042
   Washington P, 2020, BIOL PSYCHIAT-COGN N, V5, P759, DOI 10.1016/j.bpsc.2019.11.015
   Wingfield B, 2020, HEALTH INFORM J, V26, P2538, DOI 10.1177/1460458219887823
   Witten I. H., 2005, DATA MINING PRACTICA
   Zhang H, 2006, PATTERN RECOGN LETT, V27, P892, DOI 10.1016/j.patrec.2005.10.013
NR 75
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 11
PY 2023
DI 10.1007/s11042-023-17694-8
EA DEC 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ2A4
UT WOS:001122190800002
OA hybrid
DA 2024-07-18
ER

PT J
AU Yan, CM
   Liu, XM
AF Yan, Chunman
   Liu, Xiaomin
TI Improved electrical capacitance tomography algorithm based on homotopy
   perturbation regularization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Electrical Capacitance Tomography; Homotopy Perturbation Regularization;
   Landweber Algorithm
ID IMAGE-RECONSTRUCTION ALGORITHMS; SYSTEM; DESIGN
AB Electrical Capacitance Tomography (ECT) is one of typical tomography technologies based on capacitance-sensitive fields, which can reconstruct the distribution images of permittivity distribution of different fluid in the measured field and is often used for realizing industrial detection in specific occasions. Landweber and homotopy perturbation regularization algorithms are used for image reconstruction in ECT system, but these algorithms are with many iteration steps, slow convergence speed, and relatively low quality of the reconstructed images. Aiming at these problems, this paper proposes an improved image reconstruction algorithm. Firstly, a regularization term is added to the target function by using the different dielectric constant distribution between the current moment and the previous moment. Then, using the homotopy perturbation to derive the second-order iterative formula to get the homotopy perturbation regularization algorithm, and finally the improved algorithm is obtained by combining the landweber algorithm based on weight factor. Furthermore, the improved homotopy perturbation regularization algorithm is applied for ECT image reconstruction. The numerical simulation experiment results show that the improved algorithm is with the highest comprehensive scores for the four flow patterns of laminar flow, annular flow, core flow and bubble flow, which is higher than the landweber algorithm and the improved homotopy perturbation regularization algorithm by 3% similar to 20%, and 18% similar to 31%, respectively. The relative error, correlation coefficient and subjective effect of the reconstructed image are significantly improved, and it has certain anti-noise performance. These reflect the improved algorithm is with practical value.
C1 [Yan, Chunman; Liu, Xiaomin] Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou, Peoples R China.
C3 Northwest Normal University - China
RP Yan, CM (corresponding author), Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou, Peoples R China.
EM Yanch139a02@163.com; 2363038202@qq.com
OI Liu, Xiaomin/0000-0003-1393-4147
FU National Natural Science Foundation of China [61961037]; National
   Natural Science Foundation of China [2021CYZC-30]; Industrial Support
   Plan of Education Department of Gansu Province
FX This study is supported by the National Natural Science Foundation of
   China (No. 61961037) and the Industrial Support Plan of Education
   Department of Gansu Province (No. 2021CYZC-30).
CR Abbasian S, 2020, MEAS SCI TECHNOL, V31, DOI 10.1088/1361-6501/ab3dc4
   Alme KJ, 2006, IEEE SENS J, V6, P1256, DOI 10.1109/JSEN.2006.881409
   Chen Yu, 2018, Computer Engineering, V44, P268, DOI 10.3969/j.issn.1000-3428.2018.01.045
   Chen Yu, 2014, Electric Machines and Control, V18, P107
   Cui ZQ, 2020, IEEE SENS J, V20, P3207, DOI 10.1109/JSEN.2019.2954736
   Cui ZQ, 2016, SENSOR REV, V36, P429, DOI 10.1108/SR-01-2016-0027
   Darma PN, 2019, MEAS SCI TECHNOL, V30, DOI 10.1088/1361-6501/ab1022
   Guo G, 2018, FLOW MEAS INSTRUM, V64, P204, DOI 10.1016/j.flowmeasinst.2018.10.010
   Hanke M, 1998, J OPTIMIZ THEORY APP, V98, P37, DOI 10.1023/A:1022680629327
   Hu D, 2020, IEEE T INSTRUM MEAS, V69, P6271, DOI 10.1109/TIM.2020.2967957
   Lei J, 2017, MEAS SCI TECHNOL, V28, DOI 10.1088/1361-6501/aa58a3
   Lei J, 2018, IEEE T INSTRUM MEAS, V67, P2107, DOI 10.1109/TIM.2018.2811228
   Liu T, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23111480
   [刘向龙 Liu Xianglong], 2019, [中国电机工程学报, Proceedings of the Chinese Society of Electrical Engineering], V39, P3971
   [马敏 Ma Min], 2021, [推进技术, Journal of Propulsion Technology], V42, P2590
   Peng LH, 2005, FLOW MEAS INSTRUM, V16, P169, DOI 10.1016/j.flowmeasinst.2005.02.015
   Qin XB, 2022, CMES-COMP MODEL ENG, V130, P1699, DOI 10.32604/cmes.2022.018234
   Rashid WNA, 2016, SENSOR REV, V36, P64, DOI 10.1108/SR-06-2015-0089
   Seonga CK., 2015, Teknologi, V73, P13
   Shi YY, 2021, FLOW MEAS INSTRUM, V79, DOI 10.1016/j.flowmeasinst.2021.101917
   [孙启国 Sun Qiguo], 2020, [润滑与密封, Lubrication Engineering], V45, P121
   Vauhkonen M, 1998, IEEE T MED IMAGING, V17, P285, DOI 10.1109/42.700740
   Wang HG, 2020, APPL THERM ENG, V176, DOI 10.1016/j.applthermaleng.2020.115311
   [王化祥 Wang Huaxiang], 2005, [天津大学学报. 自然科学与工程技术版, Journal of Tianjin University], V38, P1
   XIE CG, 1992, IEE PROC-G, V139, P89, DOI 10.1049/ip-g-2.1992.0015
   Xin Hu., 2019, Harbin Inst Technol, DOI [10.27061/d.cnki.ghgdu.2019.003394, DOI 10.27061/D.CNKI.GHGDU.2019.003394]
   Yan Chunman, 2019, Chinese Journal of Sensors and Actuators, V32, P1522, DOI 10.3969/j.issn.1004-1699.2019.10.015
   Yan H., 2011, Geneva: Trans Tech Publ, V204, P1310
   Yan H, 2021, MEAS SCI TECHNOL, V32, DOI 10.1088/1361-6501/abae3d
   Yang WQ, 1999, MEAS SCI TECHNOL, V10, P1065, DOI 10.1088/0957-0233/10/11/315
   Yang WQ, 2003, MEAS SCI TECHNOL, V14, pR1, DOI 10.1088/0957-0233/14/1/201
   Yang WQ, 2010, MEAS SCI TECHNOL, V21, DOI 10.1088/0957-0233/21/4/042001
   Ye JM, 2016, IEEE SENS J, V16, P2466, DOI 10.1109/JSEN.2015.2513747
   Ye JM, 2014, MEAS SCI TECHNOL, V25, DOI 10.1088/0957-0233/25/11/115402
   [赵玉磊 Zhao Yulei], 2016, [农业机械学报, Transactions of the Chinese Society for Agricultural Machinery], V47, P368
   Zheng J, 2020, IEEE SENS J, V20, P4879, DOI 10.1109/JSEN.2020.2965731
   Zheng J, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113701
   [朱晓丽 Zhu Xiaoli], 2019, [工程热物理学报, Journal of Engineering Thermophysics], V40, P2582
NR 38
TC 0
Z9 0
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 1
PY 2023
DI 10.1007/s11042-023-17285-7
EA DEC 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z5LL9
UT WOS:001112488100006
DA 2024-07-18
ER

PT J
AU Lahmar, I
   Zaier, A
   Yahia, M
   Boaullegue, R
AF Lahmar, Ines
   Zaier, Aida
   Yahia, Mohamed
   Boaullegue, Ridha
TI Binary weighted mean of vectors optimization based type-2 fuzzy-rough
   for feature selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE High dimensional datasets; Neighborhood rough set; Feature selection;
   Binary weighted mean of vectors optimization
ID SET
AB One of the crucial problems in in the fields of machine learning and data mining is data reduction by feature selection (FS). In this context, this paper proposes an FS method based on a hybrid of type 2 fuzzy rough k-nearest neighbors (T2FRKNN) and a weighted mean vector optimization method called FKNINFO. Thus, the significance of the features can be determined by the creation of the lower and upper fuzzy similarity partition matrices. The introduction of INFO is intended to enhance the T2FRKNN with the best parameters and feature subsets. The proposed method is a dynamic framework originally aimed at solving problems through continuous optimization. In this regard, we propose a binary version of FKNINFO (BFKNINFO), which uses the X-shaped function to improve the efficiency of FS. The BFKNINFO is tested using medical datasets and compared to the other optimization methods in terms of fitness, accuracy, precision, recall, ROC curves,Wilcoxon statistical test (P-value), running time, and number of features. BFKNINFO is used to detect the coronavirus disease (COVID-19) datasets. The results of the experiments demonstrate the effectiveness of BFKNINFO in navigating the problem space and identifying the most effective parameter and features by reducing the number of features.
C1 [Lahmar, Ines] Univ Gabes, MACS Lab, Gabes, Tunisia.
   [Zaier, Aida; Boaullegue, Ridha] Univ Carthage Tunis, InnovCom Lab, Tunis, Tunisia.
   [Yahia, Mohamed] Univ Tunis El Manar, Syscom Lab ENIT, Tunis, Tunisia.
C3 Universite de Gabes; Universite de Carthage; Universite de
   Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis (ENIT)
RP Lahmar, I (corresponding author), Univ Gabes, MACS Lab, Gabes, Tunisia.
EM ines12lahmar@gmail.com; zaieraida@yahoo.fr; mohamed_yahia1@yahoo.fr;
   ridha.bouallegue@ieee.org
OI Lahmar, Ines/0000-0002-5363-8724
FU The authors would like to acknowledge the financial support of this work
   by grants from General Direction of Scientific Research (DGRST),
   Tunisia, under the ARUB program.; General Direction of Scientific
   Research (DGRST), Tunisia, under the ARUB program
FX The authors would like to acknowledge the financial support of this work
   by grants from General Direction of Scientific Research (DGRST),
   Tunisia, under the ARUB program.
CR Ahmadianfar I, 2022, EXPERT SYST APPL, V195, DOI 10.1016/j.eswa.2022.116516
   Ahmed S, 2022, EXPERT SYST APPL, V200, DOI 10.1016/j.eswa.2022.116834
   Albahli S, 2022, MULTIMED TOOLS APPL, V81, P37569, DOI 10.1007/s11042-022-13499-3
   Alweshah M, 2022, KNOWL-BASED SYST, V235, DOI 10.1016/j.knosys.2021.107629
   An S, 2023, FUZZY SET SYST, V461, DOI 10.1016/j.fss.2023.01.011
   AsghariVarzaneh Z, 2023, Multimed Tools App, P1
   Awotunde JB., 2022, An enhanced diabetes mellitus prediction using feature selection-based type-2 fuzzy model, P625
   Azar AT, 2020, INT J COMPUT APPL T, V63, P4, DOI 10.1504/IJCAT.2020.107901
   Bandyopadhyay R, 2021, APPL SOFT COMPUT, V111, DOI 10.1016/j.asoc.2021.107698
   Bania RK, 2021, ARTIF INTELL MED, V114, DOI 10.1016/j.artmed.2021.102049
   Cao B, 2020, SWARM EVOL COMPUT, V57, DOI 10.1016/j.swevo.2020.100697
   Chalabi NE, 2021, MULTIMED TOOLS APPL, V80, P33257, DOI 10.1007/s11042-021-11367-0
   Dua D., 2017, UCI MACHINE LEARNING
   Feng JD, 2022, IEEE ACCESS, V10, P33301, DOI 10.1109/ACCESS.2022.3162074
   Ghosh KK, 2020, IEEE ACCESS, V8, P97890, DOI 10.1109/ACCESS.2020.2996611
   Heidari AA, 2019, FUTURE GENER COMP SY, V97, P849, DOI 10.1016/j.future.2019.02.028
   Hema M, 2023, Multimed Tools App, P1
   Huang H, 2019, IEEE ACCESS, V7, P12386, DOI 10.1109/ACCESS.2019.2893063
   Huda RK, 2022, SOFT COMPUT, V26, P2501, DOI 10.1007/s00500-021-06393-x
   Kaur T, 2019, MULTIMED TOOLS APPL, V78, P21853, DOI 10.1007/s11042-019-7498-3
   KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580, DOI 10.1109/TSMC.1985.6313426
   Li J, 2019, PATTERN ANAL APPL, V22, P1331, DOI 10.1007/s10044-018-0757-5
   Melin P, 2018, A new variant of fuzzy k-nearest neighbor using interval type-2 fuzzy logic, P1
   Mendel JM, 2017, Intro New Dir, V684
   Pathak Y, 2019, MULTIMED TOOLS APPL, V78, P1473, DOI 10.1007/s11042-018-6155-6
   Polkowski L., 2002, ROUGH SETS MATH FDN
   Sun L, 2022, IEEE T FUZZY SYST, V30, P1197, DOI 10.1109/TFUZZ.2021.3053844
   Sureshkumar V, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12811
   Thaher T, 2020, ALGO INTELL SY, P251, DOI 10.1007/978-981-32-9990-0_12
   Too J, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106553
   Wang AG, 2015, KNOWL-BASED SYST, V83, P81, DOI 10.1016/j.knosys.2015.03.009
   Wang CZ, 2019, KNOWL-BASED SYST, V164, P205, DOI 10.1016/j.knosys.2018.10.038
   Yadav D.C., 2020, INDIAN J PUBLIC HLTH, V11, P61, DOI 10.37506/v11/i1/2020/ijphrd/193785
   Zhao D, 2017, COMPUT ECON, V49, P325, DOI 10.1007/s10614-016-9562-7
NR 34
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 8
PY 2023
DI 10.1007/s11042-023-17580-3
EA NOV 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X8TR3
UT WOS:001101114600006
DA 2024-07-18
ER

PT J
AU Senthilkumar, S
   Brindha, K
   Chatterjee, JM
   Popat, A
   Gupta, L
   Verma, A
AF Senthilkumar, Sudha
   Brindha, K.
   Chatterjee, Jyotir Moy
   Popat, Anannya
   Gupta, Lakshya
   Verma, Abhimanyu
TI An optimized handwritten polynomial equations solver using an enhanced
   inception V4 model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Polynomial equations; Inception V4; MNIST dataset; EMNIST dataset; CNN
AB In algebra, polynomials are expressions in which a sum is multiplied by its coefficients involving one or more variables such as a0xn + a1xn-1 + a2xn-2 + horizontal ellipsis + an. This paper proposes a convolutional neural network model that takes a picture of an equation as an input and outputs the value of the unknown variable "x" for that equation. The proposed model can solve cubic, quadratic, and quintic equations using an enhanced Inception V4 Convolutional Neural Network(CNN) model. The proposed model is implemented as a web application that allows the user to enter a picture of the handwritten equation and returns the recognized equation. Three datasets were used to collect handwritten arithmetic equations. MathNet was used to contain handwritten arithmetic symbols, the MNIST dataset was used to collect handwritten digits, and EMNIST was used to collect alphabets used as variables in polynomial equations. The proposed model dataset contains 16 classes, including 10 numerals, 3 mathematical operators, and 3 variables of image size 64 x 64 pixels.
C1 [Senthilkumar, Sudha; Brindha, K.; Popat, Anannya; Gupta, Lakshya; Verma, Abhimanyu] Vellore Inst Technol, Sch Comp Sci Engn & Informat Syst, Vellore, India.
   [Chatterjee, Jyotir Moy] Graphic Era Deemed Univ, Dept CSE, Dehra Dun, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Graphic Era
   University
RP Chatterjee, JM (corresponding author), Graphic Era Deemed Univ, Dept CSE, Dehra Dun, India.
EM sudha.s@vit.ac.in; brindha.k@vit.ac.in;
   jyotirmoy.chatterjee.cse@gmail.com;
   anannyarajesh.popat2019@vitstudent.ac.in;
   lakshya.gupta2019@vitstudent.ac.in; abhimanyu.verma2019@vitstudent.ac.in
RI Chatterjee, Jyotir Moy/H-1131-2017
OI Chatterjee, Jyotir Moy/0000-0003-2527-916X
CR Abdulhasan MQ, 2015, WIRELESS PERS COMMUN, V82, P2323, DOI 10.1007/s11277-015-2350-1
   Abdulhussain SH, 2019, INTERNATIONAL CONFERENCE OF INFORMATION AND COMMUNICATION TECHNOLOGY (ICICT 2019), P215, DOI 10.1145/3321289.3321310
   Abdulhussain SH, 2019, J MATH IMAGING VIS, V61, P555, DOI 10.1007/s10851-018-0863-4
   Abdulhussan SH, 2017, IEEE ACCESS, V5, P2470, DOI 10.1109/ACCESS.2017.2669218
   Agrawal AK, 2021, 2021 2 INT C EM TECH, DOI [10.1109/incet51464.2021.9456118, DOI 10.1109/INCET51464.2021.9456118]
   Ahamed P, 2020, J AMB INTEL HUM COMP, V11, P5445, DOI 10.1007/s12652-020-01901-7
   Ahlawat S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123344
   Alani AA, 2017, INFORMATION, V8, DOI 10.3390/info8040142
   Aly S, 2019, IEEE ACCESS, V7, P52024, DOI 10.1109/ACCESS.2019.2911851
   [Anonymous], 2017, Handbook of Research on Machine Learning Innovations and Trends, DOI DOI 10.4018/978-1-5225-2229-4.CH039
   Anwar S, 2021, MULTIMED TOOLS APPL, V80, P9657, DOI 10.1007/s11042-020-09545-7
   Aqab S, 2020, INT J ADV COMPUT SC, V11, P137
   Ashiquzzaman A, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON IMAGING, VISION & PATTERN RECOGNITION (ICIVPR)
   Balaha HM, 2021, MULTIMED TOOLS APPL, V80, P32473, DOI 10.1007/s11042-021-11185-4
   Cohen G, 2017, IEEE IJCNN, P2921, DOI 10.1109/IJCNN.2017.7966217
   Deng Y, 2017, IEEE T NEUR NET LEAR, V28, P653, DOI 10.1109/TNNLS.2016.2522401
   Dey R, 2022, MULTIMED TOOLS APPL, V81, P10469, DOI 10.1007/s11042-022-12148-z
   Dhrif H, 2020, ICAART: PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE, VOL 2, P437, DOI 10.5220/0008919004370444
   Fukeng He, 2020, Pattern Recognition and Artificial Intelligence. International Conference, ICPRAI 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12068), P55, DOI 10.1007/978-3-030-59830-3_5
   G ER, 2022, 2022 2 INT C ADV COM, DOI [10.1109/icacite53722.2022.9823806, DOI 10.1109/ICACITE53722.2022.9823806]
   Garris M, 1997, NIST Interagency/Internal Report (NISTIR), DOI [10.6028/NIST.IR.5959, DOI 10.6028/NIST.IR.5959]
   Ghosh T, 2022, COMPUT SCI REV, V46, DOI 10.1016/j.cosrev.2022.100515
   Golzari S, 2022, MULTIMED TOOLS APPL, V81, P33785, DOI 10.1007/s11042-022-13101-w
   Guo ZY, 2022, SCI PROGRAMMING-NETH, V2022, DOI 10.1155/2022/7490363
   Hasan Fuad, 2020, Innovations in Computer Science and Engineering. Proceedings of 7th ICICSE. Lecture Notes in Networks and Systems (LNNS 103), P555, DOI 10.1007/978-981-15-2043-3_60
   Huda H, 2022, INT CONF UBIQUIT INF, DOI 10.1109/IMCOM53663.2022.9721634
   Jeong CY, 2023, J REAL-TIME IMAGE PR, V20, DOI 10.1007/s11554-023-01270-2
   Ju RY, 2023, J REAL-TIME IMAGE PR, V20, DOI 10.1007/s11554-023-01271-1
   Kawamura A, 2017, INT CONF AWARE SCI, P564, DOI 10.1109/ICAwST.2017.8256521
   Kukreja V, 2022, MULTIMED TOOLS APPL, V81, P28651, DOI 10.1007/s11042-022-12644-2
   Mahmmod BM, 2018, IET SIGNAL PROCESS, V12, P129, DOI 10.1049/iet-spr.2016.0449
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Mondal R, 2022, MULTIMED TOOLS APPL, V81, P975, DOI 10.1007/s11042-021-11425-7
   Naser MA, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9122155
   Nian ZX, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6913, DOI 10.1109/ICASSP39728.2021.9413395
   Ning GY, 2021, DISCRETE DYN NAT SOC, V2021, DOI 10.1155/2021/8832251
   Pal A., 2022, SSRN Electron J, DOI [10.2139/ssrn.4204575, DOI 10.2139/SSRN.4204575]
   Pal A, 2022, MULTIMED TOOLS APPL, V81, P31405, DOI 10.1007/s11042-022-12889-x
   Papa JP, 2016, APPL SOFT COMPUT, V46, P875, DOI 10.1016/j.asoc.2015.08.043
   Pereira Andreia Penso., 2018, 2018 13th Iberian Conference on Information Systems and Technologies (CISTI), P1, DOI 10.1109/ijcnn.2018.8489525
   Prateek K, 2023, TELECOMMUN SYST, V82, P315, DOI 10.1007/s11235-022-00979-y
   Qiao JF, 2018, NEURAL NETWORKS, V107, P61, DOI 10.1016/j.neunet.2018.02.010
   Rajab M.E., 2019, 2019 2 IEEE MIDDLE E, P1, DOI [10.1109/incos45849.2019.8951342, DOI 10.1109/INCOS45849.2019.8951342]
   Sen Maitra D, 2015, PROC INT CONF DOC, P1021, DOI 10.1109/ICDAR.2015.7333916
   Shah P, 2022, 2022 6 INT C TRENDS, DOI [10.1109/icoei53556.2022.9776654, DOI 10.1109/ICOEI53556.2022.9776654]
   Shuvo Shifat Nayme, 2021, Soft Computing Techniques and Applications. Proceedings of the International Conference on Computing and Communication (IC3 2020). Advances in Intelligent Systems and Computing (AISC 1248), P515, DOI 10.1007/978-981-15-7394-1_47
   Shuvo SN, 2020, 2020 11 INT C COMP C, DOI [10.1109/icccnt49239.2020.9225587, DOI 10.1109/ICCCNT49239.2020.9225587]
   Singh P, 2016, STUD FUZZ SOFT COMP, V330, P1, DOI 10.1155/2016/2796863
   Singh S, 2023, MULTIMED TOOLS APPL, V82, P747, DOI 10.1007/s11042-022-13318-9
   Stuner B, 2020, MULTIMED TOOLS APPL, V79, P34407, DOI 10.1007/s11042-020-09198-6
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tong GX, 2023, J REAL-TIME IMAGE PR, V20, DOI 10.1007/s11554-023-01267-x
   Tuba E, 2016, IEEE C EVOL COMPUTAT, P2225, DOI 10.1109/CEC.2016.7744063
   Wang M, 2022, IEEE T IMAGE PROCESS, V31, P3137, DOI 10.1109/TIP.2022.3165989
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu J., 2017, Nat. Key Lab Novel Softw. Technol. Nanjing Univ. China, V5, P495, DOI DOI 10.1007/978-3-642-28661-2-5
   Zeng K, 2018, COMPLEXITY, DOI 10.1155/2018/1342562
   Zhang JS, 2017, PATTERN RECOGN, V71, P196, DOI 10.1016/j.patcog.2017.06.017
   Zhao DB, 2018, IEEE T NEUR NET LEAR, V29, P2038, DOI 10.1109/TNNLS.2018.2818878
   Zhao Z, 2019, Machine learning and real roots of polynomials
NR 60
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 8
PY 2023
DI 10.1007/s11042-023-17574-1
EA NOV 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X8TR3
UT WOS:001101114600002
DA 2024-07-18
ER

PT J
AU Hur, C
   Park, H
AF Hur, Chan
   Park, Hyeyoung
TI EENet: embedding enhancement network for compositional image-text
   retrieval using generated text
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Compositional Image-Text Retrieval; Image-Captioning; Joint embedding;
   Visual Feature Enhancement; Textual Feature Generation
AB In this paper, we consider the compositional image-text retrieval task, which searches for appropriate target images given a reference image with feedback text as a query. For instance, when a user finds a dress on an E-commerce site that meets all their needs except for the length and decoration, the user can give sentence-form feedback, e.g., "I like this dress, but I wish it was a little shorter and had no ribbon," to the system. This is a practical scenario for advanced retrieval systems and is applicable to user interactive search systems or E-commerce systems. To tackle this task, we propose a model, the Embedding Enhancement Network (EENet), which includes a text generation module and an image feature enhancement module using the generated text. While the conventional works mainly focus on developing an efficient composition module of a given image and text query, EENet actively generates an additional textual description to enhance the image feature vector in the embedding space, which is inspired by the human ability to recognize an object using a visual sensor and prior textual information. Also, a new training loss is introduced to ensure that images and additional generated texts are well combined. The experimental results show that the EENet achieves considerable improvement on retrieval performance evaluations; for the Recall@1 metric, it improved by 3.4% in Fashion200k and 1.4% in MIT-States over the baseline model.
C1 [Hur, Chan; Park, Hyeyoung] Kyungpook Natl Univ, Sch Comp Sci & Engn, Daegu, South Korea.
C3 Kyungpook National University
RP Park, H (corresponding author), Kyungpook Natl Univ, Sch Comp Sci & Engn, Daegu, South Korea.
EM chanhur@knu.ac.kr; hypark@knu.ac.kr
FU This work was supported by the Human Resources Program in Energy
   Technology of the Korea Institute of Energy Technology Evaluation and
   Planning (KETEP) granted financial resource from the Ministry of Trade,
   Industry amp; Energy, Republic of Korea (No. 202; Human Resources
   Program in Energy Technology of the Korea Institute of Energy Technology
   Evaluation and Planning (KETEP) [20204010600060]; Ministry of Trade,
   Industry amp; Energy, Republic of Korea [2021-0-02068]; Institute of
   Information amp; communications Technology Planning amp; Evaluation
   (IITP) - Korea government (MSIT)
FX This work was supported by the Human Resources Program in Energy
   Technology of the Korea Institute of Energy Technology Evaluation and
   Planning (KETEP) granted financial resource from the Ministry of Trade,
   Industry & Energy, Republic of Korea (No. 20204010600060). This work was
   supported by Institute of Information & communications Technology
   Planning & Evaluation (IITP) grant funded by the Korea government (MSIT)
   (No. 2021-0-02068, Artificial Intelligence Innovation Hub).
CR Ak KE, 2018, PROC CVPR IEEE, P7708, DOI 10.1109/CVPR.2018.00804
   Anwaar MU, 2021, IEEE WINT CONF APPL, P1139, DOI 10.1109/WACV48630.2021.00118
   Chen Y.-C., 2020, ECCV
   Chen YB, 2020, PROC CVPR IEEE, P2998, DOI 10.1109/CVPR42600.2020.00307
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Faghri F, 2018, BMCV
   Guo XX, 2018, ADV NEUR IN, V31
   Guo XY, 2019, PROC CVPR IEEE, P3268, DOI 10.1109/CVPR.2019.00339
   Han XT, 2017, IEEE I CONF COMP VIS, P1472, DOI 10.1109/ICCV.2017.163
   Hu X., 2022, CVPR
   Huang Y, 2018, PROC CVPR IEEE, P6163, DOI 10.1109/CVPR.2018.00645
   Isola P, 2015, PROC CVPR IEEE, P1383, DOI 10.1109/CVPR.2015.7298744
   Jandial S, 2022, IEEE WINT CONF APPL, P597, DOI 10.1109/WACV51458.2022.00067
   Kim Jongseok, 2021, AAAI
   Kovashka A, 2012, PROC CVPR IEEE, P2973, DOI 10.1109/CVPR.2012.6248026
   Li X., 2020, P EUR C COMP VIS, DOI DOI 10.1007/978-3-030-58577-8_8
   Liu CX, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P3, DOI 10.1145/3343031.3350869
   Noh H, 2016, PROC CVPR IEEE, P30, DOI 10.1109/CVPR.2016.11
   Perez E, 2018, AAAI CONF ARTIF INTE, P3942
   Radford A, 2021, PR MACH LEARN RES, V139
   Reed S, 2016, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2016.13
   Sadeh G, 2019, Arxiv, DOI arXiv:1906.06620
   Santoro A, 2017, ADV NEUR IN, V30
   Sarafianos N, 2019, IEEE I CONF COMP VIS, P5813, DOI 10.1109/ICCV.2019.00591
   Tan F, 2019, NIPS
   Tan MX, 2019, PR MACH LEARN RES, V97
   Wang LW, 2019, IEEE T PATTERN ANAL, V41, P394, DOI 10.1109/TPAMI.2018.2797921
   Wang YX, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3792
   Wei K, 2020, IEEE ACCESS
   Wen HK, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1369, DOI 10.1145/3404835.3462967
   Wu H, 2020, Arxiv, DOI [arXiv:1905.12794, DOI 10.48550/ARXIV.1905.12794]
   Wu Y, 2019, MM
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang Y, 2021, MM
   Yu Q, 2016, PROC CVPR IEEE, P799, DOI 10.1109/CVPR.2016.93
   Yuan Y, 2021, SIGIR
   Zhang L, 2017, PROC CVPR IEEE, P3010, DOI 10.1109/CVPR.2017.321
   Zhang Q, 2020, PROC CVPR IEEE, P3533, DOI 10.1109/CVPR42600.2020.00359
   Zhang Y, 2021, IEEE TIP
   Zhang Y, 2018, LECT NOTES COMPUT SC, V11205, P707, DOI 10.1007/978-3-030-01246-5_42
   Zhao B, 2017, PROC CVPR IEEE, P6156, DOI 10.1109/CVPR.2017.652
NR 41
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 2
PY 2023
DI 10.1007/s11042-023-17531-y
EA NOV 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X1LQ6
UT WOS:001096134900008
DA 2024-07-18
ER

PT J
AU Kalananda, VKRA
   Komanapalli, VLN
AF Kalananda, Vamsi Krishna Reddy Aala
   Komanapalli, Venkata Lakshmi Narayana
TI A competitive learning-based Grey wolf Optimizer for engineering
   problems and its application to multi-layer perceptron training
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Competitive learning-based Grey wolf Optimizer (Clb-GWO); Grey wolf
   Optimizer (GWO); CEC2020 and CEC2019; Multi-layer perceptron training
ID DIFFERENTIAL EVOLUTION; SWARM INTELLIGENCE; ALGORITHM; ENSEMBLE; DESIGN;
   HEURISTICS; NETWORKS
AB This article presents a competitive learning-based Grey Wolf Optimizer (Clb-GWO) formulated through the introduction of competitive learning strategies to achieve a better trade-off between exploration and exploitation while promoting population diversity through the design of difference vectors. The proposed method integrates population sub-division into majority groups and minority groups with a dual search system arranged in a selective complementary manner. The proposed Clb-GWO is tested and validated through the recent CEC2020 and CEC2019 benchmarking suites followed by the optimal training of multi-layer perceptron's (MLPs) with five classification datasets and three function approximation datasets. Clb-GWO is compared against the standard version of GWO, five of its latest variants and two modern meta-heuristics. The benchmarking results and the MLP training results demonstrate the robustness of Clb-GWO. The proposed method performed competitively compared to all its competitors with statistically significant performance for the benchmarking tests. The performance of Clb-GWO the classification datasets and the function approximation datasets was excellent with lower error rates and least standard deviation rates.
C1 [Kalananda, Vamsi Krishna Reddy Aala; Komanapalli, Venkata Lakshmi Narayana] Vellore Inst Technol, Sch Elect Engn, Vellore 632014, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Komanapalli, VLN (corresponding author), Vellore Inst Technol, Sch Elect Engn, Vellore 632014, Tamil Nadu, India.
EM vamsikrishna.ak2022@gmail.com; vlnarayana.k@vit.ac.in
RI Komanapalli, Venkata Lakshmi Narayana/E-4948-2015; KALANANDA, VAMSI
   KRISHNA REDDY AALA/AAZ-1936-2020
OI Komanapalli, Venkata Lakshmi Narayana/0000-0001-8270-0737; 
CR Abdel-Basset M., 2018, Metaheuristic algorithms: A comprehensive review
   Alba E, 2013, INT T OPER RES, V20, P1, DOI 10.1111/j.1475-3995.2012.00862.x
   Amirsadri S, 2018, NEURAL COMPUT APPL, V30, P3707, DOI 10.1007/s00521-017-2952-5
   Benabderrahmane S, 2017, INT J INTELL ROBOT, V1, P410, DOI 10.1007/s41315-017-0037-3
   Bhaskar A, 2022, CMC-COMPUT MATER CON, V71, P3069, DOI 10.32604/cmc.2022.019866
   Blum C, 2011, APPL SOFT COMPUT, V11, P4135, DOI 10.1016/j.asoc.2011.02.032
   CHAKHLEVITCH K., 2008, Adaptive and Multilevel Metaheuristics, V136, P3, DOI [10.1007/978-3-540-79438-7_1, DOI 10.1007/978-3-540-79438-7_1]
   Darwish Ashraf, 2018, Future Computing and Informatics Journal, V3, P231, DOI 10.1016/j.fcij.2018.06.001
   Del Ser J, 2019, SWARM EVOL COMPUT, V48, P220, DOI 10.1016/j.swevo.2019.04.008
   Dhargupta S, 2020, EXPERT SYST APPL, V151, DOI 10.1016/j.eswa.2020.113389
   Dokeroglu T, 2019, COMPUT IND ENG, V137, DOI 10.1016/j.cie.2019.106040
   Faris H, 2018, NEURAL COMPUT APPL, V30, P413, DOI 10.1007/s00521-017-3272-5
   Gharehchopogh FS, 2019, SWARM EVOL COMPUT, V48, P1, DOI 10.1016/j.swevo.2019.03.004
   Gupta S, 2019, SWARM EVOL COMPUT, V44, P101, DOI 10.1016/j.swevo.2018.01.001
   Hasan M, 2019, INTERNET THINGS-NETH, V7, DOI 10.1016/j.iot.2019.100059
   He M, 2018, MICROCHEM J, V142, P394, DOI 10.1016/j.microc.2018.07.016
   Heidari AA, 2019, FUTURE GENER COMP SY, V97, P849, DOI 10.1016/j.future.2019.02.028
   Heidari AA, 2017, APPL SOFT COMPUT, V60, P115, DOI 10.1016/j.asoc.2017.06.044
   Ibrahim RA, 2018, EXPERT SYST APPL, V108, P1, DOI 10.1016/j.eswa.2018.04.028
   Igiri CP., 2020, Recent Adv Comput Sci Commun, V13, P5, DOI [10.2174/2213275912666190101120202, DOI 10.2174/2213275912666190101120202]
   Johnvictor AC, 2022, WIRES COMPUT STAT, V14, DOI 10.1002/wics.1528
   Kar AK, 2016, EXPERT SYST APPL, V59, P20, DOI 10.1016/j.eswa.2016.04.018
   Kaur J, 2018, ADV INTELL SYST, V624, P305, DOI 10.1007/978-981-10-5903-2_32
   Kaveh A, 2018, ENG COMPUT-GERMANY, V34, P685, DOI 10.1007/s00366-017-0567-1
   Khishe M, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113338
   Kishor A, 2016, Empirical Study of Grey Wolf Optimizer, P1037, DOI [10.1007/978-981-10-0448-3, DOI 10.1007/978-981-10-0448-3]
   Kohli M, 2018, J COMPUT DES ENG, V5, P458, DOI 10.1016/j.jcde.2017.02.005
   Kusetogullari H, 2014, APPL SOFT COMPUT, V14, P536, DOI 10.1016/j.asoc.2013.09.001
   Li J, 2020, J AMB INTEL HUM COMP, V11, P6319, DOI 10.1007/s12652-020-02224-3
   Li SM, 2020, FUTURE GENER COMP SY, V111, P300, DOI 10.1016/j.future.2020.03.055
   Liang JJ, 2006, IEEE T EVOLUT COMPUT, V10, P281, DOI 10.1109/TEVC.2005.857610
   Liu SQ, 2019, PHYSICA A, V521, P667, DOI 10.1016/j.physa.2019.01.036
   Long W, 2018, ENG APPL ARTIF INTEL, V68, P63, DOI 10.1016/j.engappai.2017.10.024
   Lu C, 2020, MEMET COMPUT, V12, P371, DOI 10.1007/s12293-020-00313-6
   Luo KP, 2019, APPL SOFT COMPUT, V77, P225, DOI 10.1016/j.asoc.2019.01.025
   Lynn N, 2017, APPL SOFT COMPUT, V55, P533, DOI 10.1016/j.asoc.2017.02.007
   Maier HR, 2019, ENVIRON MODELL SOFTW, V114, P195, DOI 10.1016/j.envsoft.2018.11.018
   Mallipeddi R, 2011, APPL SOFT COMPUT, V11, P1679, DOI 10.1016/j.asoc.2010.04.024
   Man KF, 1996, IEEE T IND ELECTRON, V43, P519, DOI 10.1109/41.538609
   Mirjalili S, Grey wolf optimizer (GWO)
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2015, APPL INTELL, V43, P150, DOI 10.1007/s10489-014-0645-7
   Mirjalili S, 2015, ADV ENG SOFTW, V83, P80, DOI 10.1016/j.advengsoft.2015.01.010
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Molina D, 2018, COGN COMPUT, V10, P517, DOI 10.1007/s12559-018-9554-0
   Movassagh AA, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02623-6
   Nadimi-Shahraki MH, 2021, EXPERT SYST APPL, V166, DOI 10.1016/j.eswa.2020.113917
   Nasrabadi MS, 2016, 2016 1ST CONFERENCE ON SWARM INTELLIGENCE AND EVOLUTIONARY COMPUTATION (CSIEC 2016), P18, DOI 10.1109/CSIEC.2016.7482116
   Negi G, 2021, INT J SYST ASSUR ENG, V12, P1, DOI 10.1007/s13198-020-00995-8
   Binh NTM, 2020, APPL INTELL, V50, P1889, DOI 10.1007/s10489-019-01628-9
   Niu PF, 2019, KNOWL-BASED SYST, V171, P37, DOI 10.1016/j.knosys.2019.01.018
   Pan J, 2017, Advances-in-intelligent-information-hiding-and-multimedia-Signal-2018.Pdf
   Poli Riccardo, 2007, Swarm Intelligence, V1, P33, DOI 10.1007/s11721-007-0002-0
   Price KV, 2018, PROBLEM DEFINITIONS, V22
   Rojas-Delgado J, 2019, PATTERN RECOGN LETT, V125, P373, DOI 10.1016/j.patrec.2019.05.017
   Sabahno M, 2022, MULTIMED TOOLS APPL, V81, P34677, DOI 10.1007/s11042-021-10678-6
   Saxena A, 2019, APPL SOFT COMPUT, V75, P84, DOI 10.1016/j.asoc.2018.10.044
   Sharma V, 2022, ARRAY-NY, V14, DOI 10.1016/j.array.2022.100164
   Simons CL, 2013, SOFT COMPUT, V17, P2147, DOI 10.1007/s00500-013-1039-1
   Singh N, 2017, ENG SCI TECHNOL, V20, P1586, DOI 10.1016/j.jestch.2017.11.001
   Stephenson M, 2003, ACM SIGPLAN NOTICES, V38, P77, DOI 10.1145/780822.781141
   Tu Q, 2019, APPL SOFT COMPUT, V76, P16, DOI 10.1016/j.asoc.2018.11.047
   Wang JS, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-43546-3
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Wu GH, 2016, INFORM SCIENCES, V329, P329, DOI 10.1016/j.ins.2015.09.009
   Xu Q, 2014, MATH PROBL ENG, V2014
   Xu QZ, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123205
   Xu QZ, 2019, PHYSICA A, V531, DOI 10.1016/j.physa.2019.121808
   Xu QZ, 2019, IMAGE VISION COMPUT, V87, P1, DOI 10.1016/j.imavis.2019.04.002
   Xu QZ, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/659809
   Yang X-S., 2015, Recent advances in swarm intelligence and evolutionary computation, DOI [10.1007/978-3-319-13826-8, DOI 10.1007/978-3-319-13826-8]
   Yue CT, 2019, PROBLEM DEFINITIONS
   Zhang XM, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.107061
   Zhang XM, 2020, NEURAL COMPUT APPL, V32, P1305, DOI 10.1007/s00521-019-04483-4
   Zhang XM, 2018, APPL SOFT COMPUT, V67, P197, DOI 10.1016/j.asoc.2018.02.049
   Zhang YD, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/931256
   Zhu GP, 2010, APPL MATH COMPUT, V217, P3166, DOI 10.1016/j.amc.2010.08.049
NR 78
TC 2
Z9 2
U1 10
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40209
EP 40267
DI 10.1007/s11042-023-15146-x
PG 59
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT5Z1
UT WOS:001120732800001
PM 37362670
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Ouyang, KY
   Pan, ZL
AF Ouyang, Kangyue
   Pan, Zhongliang
TI Multi-model weighted voting method based on convolutional neural network
   for human activity recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Human activity recognition; Convolutional neural networks; Feature
   extraction; Two-dimensional graphs; Sensor data; Weighted voting
ID ENSEMBLE
AB In recent years, human activity recognition (HAR) has been widely used in medical rehabilitation, smart home and other fields. Currently, the recognition performance highly depends on feature extraction and effective algorithm. On the one hand, traditional manual feature extraction and classification algorithms hinder the improvement of HAR. On the other hand, the latest deep learning technology can automatically process data and extract features, but it faces the problems of poor feature quality and information loss. In order to solve this problem, this paper proposes a new recognition method using only wearable sensor data. In the feature extraction stage, the axis information of each sensor is extracted separately into one-dimensional data, and information of all axes is integrated into a two-dimensional graph. Then, two deep convolutional neural network models are designed to train the features based on one-dimensional data and two-dimensional graph respectively. Finally, weighted voting method is used to get the classification results. Experiments have shown that the average recognition accuracy of the method in this paper is about 3% higher than that of other HAR deep neural network methods, which shown the advantage of the method in this paper in obtaining better recognition result with limited data.
C1 [Ouyang, Kangyue; Pan, Zhongliang] South China Normal Univ, Sch Elect & Informat Engn, Guangzhou 510006, Peoples R China.
C3 South China Normal University
RP Pan, ZL (corresponding author), South China Normal Univ, Sch Elect & Informat Engn, Guangzhou 510006, Peoples R China.
EM panzhongliang@m.scnu.edu.cn
FU This work was supported by Guangzhou Science and Technology Project
   (Grant No. 201904010107), Guangdong Provincial Natural Science
   Foundation of China (Grant No. 2019A1515010793). [201904010107];
   Guangzhou Science and Technology Project [2019A1515010793]; Guangdong
   Provincial Natural Science Foundation of China
FX This work was supported by Guangzhou Science and Technology Project
   (Grant No. 201904010107), Guangdong Provincial Natural Science
   Foundation of China (Grant No. 2019A1515010793).
CR Anguita D, 2013, ESANN, P437, DOI DOI 10.3390/S20082200
   Arshad M., 2022, EAI Endorsed Transactions on Internet of Things, V7, P170006, DOI [10.4108/eai.26-5-2021.170006, DOI 10.4108/EAI.26-5-2021.170006]
   Azar SM, 2019, PROC CVPR IEEE, P7884, DOI 10.1109/CVPR.2019.00808
   Bulling A, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2499621
   Casale P, 2011, LECT NOTES COMPUT SC, V6669, P289
   Catal C, 2015, APPL SOFT COMPUT, V37, P1018, DOI 10.1016/j.asoc.2015.01.025
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Chen YQ, 2015, IEEE SYS MAN CYBERN, P1488, DOI 10.1109/SMC.2015.263
   Chen ZH, 2019, IEEE T IND INFORM, V15, P2691, DOI 10.1109/TII.2018.2869843
   Chen ZH, 2018, IEEE T IND INFORM, V14, P4334, DOI 10.1109/TII.2018.2789925
   Feng ZT, 2015, IEEE ENG MED BIO, P5074, DOI 10.1109/EMBC.2015.7319532
   Gupta S., 2021, Int. J. Inf. Manage. Data Insights, V1, DOI [DOI 10.1016/J.JJIMEI.2021.100046, 10.1016/j.jjimei.2021.100046]
   Hammerla N.Y., 2016, P 25 INT JOINT C ART
   Host K, 2022, HELIYON, V8, DOI 10.1016/j.heliyon.2022.e09633
   Javed AR, 2021, SUSTAIN CITIES SOC, V71, DOI 10.1016/j.scs.2021.102970
   Jiang WC, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1307, DOI 10.1145/2733373.2806333
   Jordao A, 2018, CoRR, abs/1806.05226
   Kim HJ, 2012, ASIAPAC SIGN INFO PR
   Kwapisz JR., 2011, ACM SIGKDD EXPLORATI, V12, P74, DOI [DOI 10.1145/1964897.1964918, 10.1145/1964897.1964918]
   Lara OD, 2012, PERVASIVE MOB COMPUT, V8, P717, DOI 10.1016/j.pmcj.2011.06.004
   Lyu LJ, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1219, DOI 10.1145/3132847.3132990
   Maurer U, 2006, BSN 2006: INTERNATIONAL WORKSHOP ON WEARABLE AND IMPLANTABLE BODY SENSOR NETWORKS, PROCEEDINGS, P113
   Ordóñez FJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010115
   Prossegger M, 2014, LECT NOTES ARTIF INT, V8779, P182, DOI 10.1007/978-3-319-11298-5_19
   Raeis H, 2021, IEEE INSTRU MEAS MAG, V24, P46, DOI 10.1109/MIM.2021.9513637
   Raziani S., 2022, NEUROSCI INFORM, V2, P100078, DOI [10.1016/j.neuri.2022.100078, DOI 10.1016/J.NEURI.2022.100078]
   Reiss A., 2013, PROC EUROPEAN S ARTI, P455
   Ronao CA, 2014, P INT CONF NAT COMPU, P681, DOI 10.1109/ICNC.2014.6975918
   Silva DF, 2013, IEEE DATA MINING, P687, DOI 10.1109/ICDM.2013.128
   Tao DP, 2016, IEEE INTERNET THINGS, V3, P1124, DOI 10.1109/JIOT.2016.2561962
   Wang AG, 2016, IEEE SENS J, V16, P4566, DOI 10.1109/JSEN.2016.2545708
   Wang JD, 2019, PATTERN RECOGN LETT, V119, P3, DOI 10.1016/j.patrec.2018.02.010
   Xia K, 2020, IEEE ACCESS, V8, P56855, DOI 10.1109/ACCESS.2020.2982225
   Xu C, 2019, IEEE ACCESS, V7, P9893, DOI 10.1109/ACCESS.2018.2890675
   Yang P, 2022, IEEE T IND INFORM, V18, P6619, DOI 10.1109/TII.2022.3142315
   Yu-Liang Hsu, 2017, 2017 International Conference on Applied System Innovation (ICASI). Proceedings, P1718, DOI 10.1109/ICASI.2017.7988270
   Zappi P, 2008, LECT NOTES COMPUT SC, V4913, P17
   Zhang M, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P1036
   Zhang XJ, 2021, INT J SYST ASSUR ENG, V12, P835, DOI 10.1007/s13198-021-01118-7
NR 39
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 1
PY 2023
DI 10.1007/s11042-023-17500-5
EA NOV 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W1XQ3
UT WOS:001089636200002
DA 2024-07-18
ER

PT J
AU Shi, H
   Hu, BY
   Zhou, ZY
   Li, MC
   Li, SY
AF Shi, Hui
   Hu, Baoyue
   Zhou, Ziyi
   Li, Mingchu
   Li, Shiying
TI A secure color image dual watermarking combining block feature
   modulation and voting mechanism for authentication and copyright
   protection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Dual watermarking; Block Feature Modulation Scrambling (BFMS); Voting
   Mechanism with Majority Rule (VMMR); Fibonacci Arnold Scrambling (FAS);
   Two-layer visual cryptography
ID ALGORITHM; ATTACKS; DOMAIN; DCT
AB In this paper, a color dual image watermarking is proposed by embedding a robust watermark to protect copyright, as well as a zero watermark for tampering detection. Block Feature Modulation Scrambling (BFMS) is proposed for security, which satisfies additive homomorphic encryption and reduces the numbers of key transmission. Moreover, Voting Mechanism with Majority Rule (VMMR) is proposed for tampering detection, and multiple watermarks are used to improve accuracy. In addition, Fibonacci Arnold Scrambling (FAS) and two-layer visual cryptography are also presented. In terms of red channel of RGB color space, a zero-watermark is constructed for the purpose of tampering detection, taking advantage of LT code, SVD (Singular value decomposition), Haar DWT and two-layer visual cryptography. In blue channel, a robust watermark is embedded by BFMS, FAS, SVD and QR decomposition, and it uses a specialized FOA (Fruit Fly Optimization Algorithm) and evolutionary optimization methods to balance the trade-off between robustness and imperceptibility. In green channel, no watermark is embedded due to its sensitivity, but BFMS is adopted to improve security. The authenticity of a suspected image can be verified in the absence of the original watermark and host images. According to the experimental and comparative results, the proposed scheme provides superior outcomes with high security, robustness, imperceptibility, and capacity along with a good accuracy rate in locating tampering.
C1 [Shi, Hui; Hu, Baoyue; Zhou, Ziyi] Liaoning Normal Univ, Sch Comp & Artificial Intelligence, Dalian 116029, Peoples R China.
   [Hu, Baoyue] Chongqing Univ Posts & Telecommun, Sch Comp Sci & Technol, Chongqing 400065, Peoples R China.
   [Li, Mingchu] Dalian Univ Technol, Sch Software Technol, Dalian 116029, Peoples R China.
   [Li, Shiying] Dalian Yongjia Elect Technol Co LTD, Dalian 116029, Peoples R China.
C3 Liaoning Normal University; Chongqing University of Posts &
   Telecommunications; Dalian University of Technology
RP Shi, H (corresponding author), Liaoning Normal Univ, Sch Comp & Artificial Intelligence, Dalian 116029, Peoples R China.
EM shihui_jiayou@126.com
RI 周, 梓怡/JGM-2983-2023
OI 周, 梓怡/0009-0009-0367-7256; Shi, Hui/0000-0001-5029-7461
FU National Science Foundation of China [61976109, 62006108, 61601214,
   61877007]; Liaoning Revitalization Talents Program [XLYC2006005];
   Liaoning Provincial Education Department [WQ2020014]; Scientific
   Research Project of Liaoning Province [LJKZ0963]; Key R&D projects of
   Liaoning Provincial Department of Science and Technology; Liaoning
   Provincial Key Laboratory Special Fund
FX This work was supported by National Science Foundation of China
   (No.61976109, 62006108, 61601214, 61877007); Liaoning Revitalization
   Talents Program (No.XLYC2006005); Liaoning Provincial Education
   Department (Grant No. WQ2020014); Scientific Research Project of
   Liaoning Province (No.LJKZ0963); Key R&D projects of Liaoning Provincial
   Department of Science and Technology; Liaoning Provincial Key Laboratory
   Special Fund.
CR Ahmadi SBB, 2021, APPL INTELL, V51, P1701, DOI 10.1007/s10489-020-01903-0
   Alam S., 2021, Pers Ubiquit Comput, V3, P1
   Altay SY, 2021, MULTIMED TOOLS APPL, V80, P23457, DOI 10.1007/s11042-020-10251-7
   Amiri A, 2010, EURASIP J Adv Sig Process, V5, P1
   [Anonymous], 2016, Kodak lossless true color image suite
   [Anonymous], 2016, USC-SIPI image database
   [Anonymous], 2016, UCID-uncompressed colour image database
   Ahmadi SBB, 2021, VISUAL COMPUT, V37, P385, DOI 10.1007/s00371-020-01808-6
   Bhardwaj J, 2020, MED BIOL ENG COMPUT, V58, P2397, DOI 10.1007/s11517-020-02209-6
   Chauhan S, 2023, SOFT COMPUT, V27, P9565, DOI 10.1007/s00500-023-08090-3
   Chen SY, 2023, SOFT COMPUT, V27, P12517, DOI 10.1007/s00500-023-07898-3
   Chen SY, 2022, VISUAL COMPUT, V38, P2189, DOI 10.1007/s00371-021-02277-1
   Darwish SM, 2020, MULTIMED TOOLS APPL, V79, P6503, DOI 10.1007/s11042-019-08290-w
   Deeba Farah, 2020, International Journal of Machine Learning and Computing, P277, DOI 10.18178/ijmlc.2020.10.2.932
   Duan XT, 2020, IEEE ACCESS, V8, P25777, DOI 10.1109/ACCESS.2020.2971528
   Fengming Qin, 2020, Artificial Intelligence and Security. 6th International Conference (ICAIS 2020). Proceedings. Lecture Notes in Computer Science (LNCS 12240), P179, DOI 10.1007/978-3-030-57881-7_16
   Garg M, 2023, MULTIMED TOOLS APPL, V82, P6271, DOI 10.1007/s11042-022-13596-3
   Gong XH, 2020, MULTIMED TOOLS APPL, V79, P18071, DOI 10.1007/s11042-019-08594-x
   Holliman M, 2000, IEEE T IMAGE PROCESS, V9, P432, DOI 10.1109/83.826780
   Hosny KM, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.103007
   Hosny KM, 2021, IEEE ACCESS, V9, P91209, DOI 10.1109/ACCESS.2021.3091614
   Hou YC., 2001, IEEE C IM AC SPEECH, V2, P32054
   Hu K, 2021, VISUAL COMPUT, V37, P2841, DOI 10.1007/s00371-021-02168-5
   Hurrah NN, 2020, MULTIMED TOOLS APPL, V79, P21441, DOI 10.1007/s11042-020-08988-2
   Jin D, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.1993625
   Jin LP, 2016, EURASIP J WIREL COMM, DOI 10.1186/s13638-016-0748-4
   Kang XB, 2020, J VIS COMMUN IMAGE R, V70, DOI 10.1016/j.jvcir.2020.102804
   Kaur A, 2021, EXPERT SYST APPL, V186, DOI 10.1016/j.eswa.2021.115686
   Khelifi F, 2018, SIGNAL PROCESS, V143, P336, DOI 10.1016/j.sigpro.2017.09.020
   Kumar GD, 2017, PROCEDIA COMPUT SCI, V115, P423, DOI 10.1016/j.procs.2017.09.101
   Li M, 2019, MULTIMED TOOLS APPL, V78, P22727, DOI 10.1007/s11042-019-7560-1
   Liu D., 2020, Multimed Tools Appl, V79, P1
   Liu DC, 2021, EXPERT SYST APPL, V170, DOI 10.1016/j.eswa.2020.114540
   Liu J, 2019, CMC-COMPUT MATER CON, V61, P889, DOI 10.32604/cmc.2019.06034
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Luby M, 2002, ANN IEEE SYMP FOUND, P271, DOI 10.1109/SFCS.2002.1181950
   Mata-Mendoza D, 2022, VISUAL COMPUT, V38, P2073, DOI 10.1007/s00371-021-02267-3
   Moosazadeh M, 2019, J INF SECUR APPL, V47, P28, DOI 10.1016/j.jisa.2019.04.001
   Mun SM, 2019, NEUROCOMPUTING, V337, P191, DOI 10.1016/j.neucom.2019.01.067
   Naor M., 1995, Advances in Cryptology - EUROCRYPT '94. Workshop on the Theory and Application of Cryptographic Techniques. Proceedings, P1, DOI 10.1007/BFb0053419
   Prasad S, 2020, IJST-T ELECTR ENG, V44, P703, DOI 10.1007/s40998-019-00275-7
   Qin C, 2016, INFORM SCIENCES, V373, P233, DOI 10.1016/j.ins.2016.09.001
   [屈凌峰 Qu Lingfeng], 2021, [计算机研究与发展, Journal of Computer Research and Development], V58, P849
   Roy S, 2017, ROY SOC OPEN SCI, V4, DOI 10.1098/rsos.170326
   Sharma K., 2019, J. Artif. Intell. Syst, V1, P143
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Sumika C, 2023, Eng Appl Artif Intell, V119
   Sun YA, 2022, MULTIMED TOOLS APPL, V81, P6091, DOI 10.1007/s11042-021-11815-x
   Ubhi JS, 2022, J VIS COMMUN IMAGE R, V85, DOI 10.1016/j.jvcir.2022.103483
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang G, 2017, MULTIMED TOOLS APPL, V76, P9427, DOI 10.1007/s11042-016-3549-1
   Wei XY, 2021, J DIGIT IMAGING, V34, P1447, DOI 10.1007/s10278-021-00524-4
   Weir J, 2010, springer transactions on data hiding and multimedia security, V6010, P70
   Weir J, 2009, IEEE INT SYMP CIRC S, P509, DOI 10.1109/ISCAS.2009.5117797
   Xia ZQ, 2021, DIGIT SIGNAL PROCESS, V116, DOI 10.1016/j.dsp.2021.103130
   Xia ZQ, 2021, SIGNAL PROCESS, V180, DOI 10.1016/j.sigpro.2020.107864
   Yang XY., 2021, J Commun, V42, P96
   Yeung MM, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P680, DOI 10.1109/ICIP.1997.638587
   Yuan ZH, 2020, OPTIK, V204, DOI 10.1016/j.ijleo.2019.164152
   Zear A, 2022, MULTIMED TOOLS APPL, V81, P26721, DOI 10.1007/s11042-020-10472-w
   Zhang XT, 2020, OPTIK, V219, DOI 10.1016/j.ijleo.2020.165272
NR 61
TC 0
Z9 0
U1 4
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 24
PY 2023
DI 10.1007/s11042-023-17122-x
EA OCT 2023
PG 53
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0VW7
UT WOS:001088903700001
DA 2024-07-18
ER

PT J
AU Vaz, RA
   Alves, LGP
   Lobeiro, M
   Ferraz, ED
   de Oliveira, GHMG
   Jerji, F
   Akamine, C
AF Vaz, Rodrigo Admir
   Alves, Luiz Gustavo Pacola
   Lobeiro, Marcelo
   da Silva Ferraz, Eric
   de Oliveira, George Henrique Maranhao Garcia
   Jerji, Fadi
   Akamine, Cristiano
TI Integrated broadband broadcast video scalability usage proposal to
   next-generation of brazilian DTTB system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Digital TV; DTTB; Hybrid Reception; ROUTE-DASH; TV 3.0; UHDTV; Video
   Scalability; Video Latency
ID COMPLEXITY
AB This paper introduces the current Brazilian DTV (Digital Television) scenario toward the next DTTB (Digital Terrestrial Television Broadcasting) system (named TV 3.0), the fixed Internet broadband scenario, as well the video scalability advantages of the new DTTB generation. Targeting to contribute with solutions for the new system, it is proposed to use video scalability and hybrid transmission to deliver UHD (Ultra High Definition) 4K video to the final user to enhance video quality and user experience. 2K video BL (Base Layer) is OTA (Over the Air) broadcasted using ROUTE (Real-Time Object Delivery Over Unidirectional Transport) protocol as a transport layer. In contrast, the UHD 4K EL (Enhancement Layer) is OTT (Over-The-Top) transmitted to the receiver via DASH (Dynamic Adaptive Streaming over HTTP - Hypertext Transfer Protocol) for synchronizing both layers. A hybrid receiver's architecture is proposed to receive and combine the BL and EL video contents. Video delivery latency is a challenge that video distributors should always be aware not to impact the user's experience. Therefore, different tests have been executed to measure latency between video layers and test the receiver's behavior in different conditions.
C1 [Vaz, Rodrigo Admir; Alves, Luiz Gustavo Pacola; Lobeiro, Marcelo; da Silva Ferraz, Eric] SIDIA Inst Sci & Technol, DTV Lab, Samsung, Sao Paulo, Brazil.
   [de Oliveira, George Henrique Maranhao Garcia; Jerji, Fadi; Akamine, Cristiano] Univ Prebiteriana Mackenzie, Digital TV Res Lab, Sao Paulo, Brazil.
C3 Universidade Presbiteriana Mackenzie
RP Vaz, RA (corresponding author), SIDIA Inst Sci & Technol, DTV Lab, Samsung, Sao Paulo, Brazil.
EM rodrigo.vaz@samsung.com; luiz.alves@samsung.com;
   marcelo.lobeiro@samsung.com; eric.ferraz@samsung.com;
   george.oliveira@mackenzie.br; fadi.jerji@gmail.com;
   cristiano.akamine@mackenzie.br
RI JERJI, FADI/AGF-7341-2022
OI JERJI, FADI/0000-0002-2076-5831
FU This work was partially supported by Samsung <italic>Eletrnica da
   Amaznia Ltda</italic>, under the auspice of the Informatics Law Ndegrees
   8.387/91. [Ndegrees 8.387/91]; Samsung <italic>Eletrnica da Amaznia Ltda
FX The authors would like to thank SIDIA/Samsung and Mackenzie Presbyterian
   University for the support, infrastructure, and opportunity to develop
   this research.This work was partially supported by Samsung Eletronica da
   Amazonia Ltda, under the auspice of the Informatics Law N degrees
   8.387/91.r This work was partially supported by Samsung
   <ITALIC>Eletronica da Amazonia Ltda</ITALIC>, under the auspice of the
   Informatics Law N degrees 8.387/91.
CR Adeyemi-Ejeye AO, 2019, MULTIMED TOOLS APPL, V78, P31733, DOI 10.1007/s11042-019-07996-1
   Ahmad I, 2022, MULTIMED TOOLS APPL, V81, P34919, DOI 10.1007/s11042-021-11249-5
   Almadani B, 2016, MULTIMED TOOLS APPL, V75, P5841, DOI 10.1007/s11042-015-2551-3
   Amazon, 2021, AWS Cloud Computing Services
   ANATEL, 2022, Number of Accesses to Telecommunications Services
   [Anonymous], 2003, H.264 and MPEG-4 video compression: video coding for next generation multimedia
   [Anonymous], 2022, H266 ITUT
   Ateme, 2021, TITAN Live Encoder
   ATSC, 2022, ATSC Standard: ATSC 3.0 System, document A/300, ATSC 3.0
   ATSC, 2022, ATSC 3.0
   ATSC, 2022, ATSC Standard: Video-HEVC, document A/341, ATSC 3.0
   AWS, 2022, Video Latency in Live Streaming
   Boyce JM, 2016, IEEE T CIRC SYST VID, V26, P20, DOI 10.1109/TCSVT.2015.2461951
   Bross B, 2021, IEEE T CIRC SYST VID, V31, P3736, DOI 10.1109/TCSVT.2021.3101953
   Celandroni N, 2000, MULTIMED TOOLS APPL, V10, P73, DOI 10.1023/A:1009616005969
   Computer Graphics Technology Group, 2021, Lua Programming Language
   Digicap, 2021, UHD Broadcasting Solutions
   DVB, 2015, ETSI 302 755 V.1.4.1
   Gazdar A, 2018, MULTIMED TOOLS APPL, V77, P15829, DOI 10.1007/s11042-017-5157-0
   Gómez-Barquero D, 2016, IEEE T BROADCAST, V62, P298, DOI 10.1109/TBC.2015.2505399
   GPAC, 2021, Video Player
   IBGE, 2021, Continuous PNAD-Internet and TV access and possession of a cell phone for personal use 2021
   IETF, 2009, RFC 5651
   ISO/IEC, 2019, Technical Report
   ITU-T, 2021, Recommendation ITU-T H.265
   Jung KH, 2017, MULTIMED TOOLS APPL, V76, P11273, DOI 10.1007/s11042-016-3324-3
   Kantarci A, 2008, MULTIMED TOOLS APPL, V36, P303, DOI 10.1007/s11042-007-0147-2
   Le Feuvre J., 2007, P 15 ACM INT C MULT, P1009, DOI [10.1145/1291233.1291452, DOI 10.1145/1291233.1291452]
   Le Feuvre J, 2020, MMSYS'20: PROCEEDINGS OF THE 2020 MULTIMEDIA SYSTEMS CONFERENCE, P249, DOI 10.1145/3339825.3394929
   Lee JY, 2020, IEEE T BROADCAST, V66, P440, DOI 10.1109/TBC.2020.2983301
   Luaces D, 2018, MULTIMED TOOLS APPL, V77, P28023, DOI 10.1007/s11042-018-6021-6
   Park SI, 2016, IEEE T BROADCAST, V62, P233, DOI 10.1109/TBC.2015.2492459
   Pereira DMG, 2021, MULTIMED TOOLS APPL, V80, P1813, DOI 10.1007/s11042-020-09645-4
   Protelevision, 2021, ATSC 3.0 Exciter
   Regueiro C, 2015, IEEE INT S BROADB MU, P1, DOI [10.1109/BMSB.2015.7177224, DOI 10.1109/BMSB.2015.7177224]
   SBTVD Forum, 2020, SBTVD Forum Phase 1-Call for Proposals
   SBTVD Forum, 2021, Adopted Technologies. SBTVD Forum Phase 2-Results
   SBTVD Forum, 2021, SBTVD Forum Phase 2-Test Procedures
   Solyman AAA, 2020, IEEE ACCESS, V8, P67591, DOI 10.1109/ACCESS.2020.2982001
   Stadelmeier L, 2016, IEEE T BROADCAST, V62, P289, DOI 10.1109/TBC.2016.2529289
   Trojahn TH, 2012, MULTIMED TOOLS APPL, V57, P373, DOI 10.1007/s11042-011-0753-x
   Vaz RA, 2020, SET Int J Broadcast Eng
   Vaz RA, 2022, Lua Dissector for ROUTE Protocol ATSC 3.0
   Walker GK, 2016, IEEE T BROADCAST, V62, P328, DOI 10.1109/TBC.2016.2515539
   Wireshark, 2021, Wireshark Packet Analyzer
   Yim HJ, 2021, IEEE INT SYM BROADB, DOI 10.1109/BMSB53066.2021.9547184
   You D, 2021, IEEE ACCESS, V9, P164503, DOI 10.1109/ACCESS.2021.3133626
NR 47
TC 0
Z9 0
U1 8
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 24
PY 2023
DI 10.1007/s11042-023-17480-6
EA OCT 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0VW7
UT WOS:001088903700008
DA 2024-07-18
ER

PT J
AU Bolourchi, P
AF Bolourchi, Pouya
TI Improved gene expression diagnosis via cascade entropy-fisher score and
   ensemble classifiers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cascade feature selection; Classification; Entropy score; Fisher score;
   Ensemble of classifiers; Gene data
ID FEATURE-SELECTION; MEMETIC ALGORITHM; RANKING ANALYSIS; CLASSIFICATION;
   TOOL
AB Feature selection is an important technique used in bioinformatics modeling to reduce the dimensionality of high-dimensional data. However, filter-based approaches that have shown better performance often depend on specific measurement methods, which can limit their effectiveness. To address this problem, this paper proposes a novel cascade feature selection approach, named the cascade entropy-fisher score (CEFS), that combines entropy score (ES)-based and Fisher score (FS)-based feature selection. CEFS involves a two-step process where in the first step, the entropy of each gene in the dataset is calculated to measure the uncertainty associated with its expression levels across different samples. In the second step, the Fisher score is computed to measure the extent to which the gene's expression levels differ between classes of samples. CEFS has been shown to outperform other methods in identifying disease-specific genes in gene expression datasets, making it a promising tool for disease diagnosis and prognosis. The proposed method was evaluated on biomedical datasets, and its effectiveness was measured in terms of accuracy, sensitivity, specificity, and area under the curve (AUC). The results showed that CEFS has comparable performance to state-of-the-art feature selection methods in the literature. Additionally, the selected features were fed to an ensemble of three classifiers, including support vector machine (SVM), k-nearest neighbor (k-NN), and decision tree (DT), to evaluate performance in the classification stage. The ensemble approach is based on majority voting, which aggregates the outputs of the individual classifiers to determine the final label. The results demonstrate the potential of CEFS in machine learning applications, particularly in the context of disease diagnosis and prognosis.
C1 [Bolourchi, Pouya] Final Int Univ, Elect & Elect Engn, Via Mersin 10, TR-99320 Girne, Turkiye.
C3 Uluslararasi Final Universitesi
RP Bolourchi, P (corresponding author), Final Int Univ, Elect & Elect Engn, Via Mersin 10, TR-99320 Girne, Turkiye.
EM pouya.bolourchi@final.edu.tr
RI Bolourchi, Pouya/M-3311-2019
OI Bolourchi, Pouya/0000-0003-3492-0617
CR Ang JC, 2016, IEEE ACM T COMPUT BI, V13, P971, DOI 10.1109/TCBB.2015.2478454
   Bennet J, 2014, SCI WORLD J, DOI 10.1155/2014/195470
   Cai RC, 2009, NEUROCOMPUTING, V72, P991, DOI 10.1016/j.neucom.2008.04.005
   Chaudhuri A, 2022, KNOWL-BASED SYST, V236, DOI 10.1016/j.knosys.2021.107804
   Chuang LY, 2011, COMPUT BIOL MED, V41, P228, DOI 10.1016/j.compbiomed.2011.02.004
   El Akadi A, 2011, KNOWL INF SYST, V26, P487, DOI 10.1007/s10115-010-0288-x
   Garro BA, 2016, APPL SOFT COMPUT, V38, P548, DOI 10.1016/j.asoc.2015.10.002
   Ghosh M, 2019, EXPERT SYST APPL, V116, P172, DOI 10.1016/j.eswa.2018.06.057
   Ghosh M, 2019, MED BIOL ENG COMPUT, V57, P159, DOI 10.1007/s11517-018-1874-4
   Gunavathi C., 2017, Res J Pharm Technol, V10, P1395, DOI [10.5958/0974-360X.2017.00249.9, DOI 10.5958/0974-360X.2017.00249.9]
   Hancer E, 2015, APPL SOFT COMPUT, V36, P334, DOI 10.1016/j.asoc.2015.07.023
   Hasri N. N. M., 2017, Int J Adv Sci Eng Inf Technol, V7, P1589, DOI [DOI 10.18517/IJASEIT.7.4-2.3394, 10.18517/ijaseit.7.4-2.3394, DOI 10.18517/ijaseit.7.4-2.3394]
   Hira Zena M., 2015, Advances in Bioinformatics, V2015, P198363, DOI 10.1155/2015/198363
   Huerta Edmundo Bonilla, 2008, Genomics Proteomics & Bioinformatics, V6, P61, DOI 10.1016/S1672-0229(08)60021-2
   Källberg D, 2021, FRONT GENET, V12, DOI 10.3389/fgene.2021.632620
   Kar S, 2015, EXPERT SYST APPL, V42, P612, DOI 10.1016/j.eswa.2014.08.014
   Khodarev NN, 2003, GENOMICS, V81, P202, DOI 10.1016/S0888-7543(02)00042-3
   Koul N, 2022, GLOB TRANSITIONS P
   Lazar C, 2012, IEEE ACM T COMPUT BI, V9, P1106, DOI 10.1109/TCBB.2012.33
   Lee CP, 2011, APPL SOFT COMPUT, V11, P208, DOI 10.1016/j.asoc.2009.11.010
   Marczyk M, 2013, BMC BIOINFORMATICS, V14, DOI 10.1186/1471-2105-14-101
   Mazumder DH, 2019, ETRI J, V41, P358, DOI 10.4218/etrij.2018-0522
   Mohammadi M, 2016, GENOMICS, V107, P83, DOI 10.1016/j.ygeno.2015.12.006
   Qi YS, 2011, GENOMICS, V97, P326, DOI 10.1016/j.ygeno.2011.03.002
   Rahman MM, 2018, Gene editing: a molecular miracle
   Sheikhi G, 2021, COMPUT INTELL-US, V37, P1865, DOI 10.1111/coin.12470
   Shukla AK, 2019, MATH BIOSCI, V315, DOI 10.1016/j.mbs.2019.108230
   Sun L, 2019, SCI REP-UK, V9, DOI [10.1038/s41598-019-46684-w, 10.1038/s41598-019-45223-x]
   Sun YQ, 2018, GENES-BASEL, V9, DOI 10.3390/genes9050258
   Talloen W, 2007, BIOINFORMATICS, V23, P2897, DOI 10.1093/bioinformatics/btm478
   Tan YD, 2006, GENOMICS, V88, P846, DOI 10.1016/j.ygeno.2006.08.003
   Vukusic I, 2007, GENOMICS, V89, P471, DOI 10.1016/j.ygeno.2007.01.001
   Wahid A, 2020, CHEMOMETR INTELL LAB, V199, DOI 10.1016/j.chemolab.2020.103958
   Wang AG, 2017, COMPUT BIOL MED, V81, P11, DOI 10.1016/j.compbiomed.2016.12.002
   Wang H, 2017, KNOWL-BASED SYST, V126, P8, DOI 10.1016/j.knosys.2017.04.004
   Wang YQ, 2011, GENOMICS, V98, P73, DOI 10.1016/j.ygeno.2011.04.011
   Xiong Wei, 2008, Genomics Proteomics & Bioinformatics, V6, P83, DOI 10.1016/S1672-0229(08)60023-6
   Xu J, 2013, J Softw, V8
   Yu Hualong, 2009, Genomics Proteomics & Bioinformatics, V7, P200, DOI 10.1016/S1672-0229(08)60050-9
   Zhang H, 2021, Front Genet, V12
   Zheng Chun-Hou, 2008, Genomics Proteomics & Bioinformatics, V6, P74, DOI 10.1016/S1672-0229(08)60022-4
   Zhou Nina, 2007, Genomics Proteomics & Bioinformatics, V5, P242, DOI 10.1016/S1672-0229(08)60011-X
   Zhu ZX, 2007, PATTERN RECOGN, V40, P3236, DOI 10.1016/j.patcog.2007.02.007
   Zibakhsh A, 2013, ENG APPL ARTIF INTEL, V26, P1274, DOI 10.1016/j.engappai.2012.12.009
NR 44
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 23
PY 2023
DI 10.1007/s11042-023-17447-7
EA OCT 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U9NV8
UT WOS:001088011000010
DA 2024-07-18
ER

PT J
AU Lan, L
   Wang, SS
AF Lan, Lin
   Wang, Shengsheng
TI Improved African vultures optimization algorithm for medical image
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Medical image segmentation; Multi-level thresholding; Swarm
   intelligence; African vultures optimization algorithm,; OAVOA
ID INTELLIGENCE; SELECTION; ENTROPY; TESTS
AB Multi-level threshold image segmentation is widely used in medical image segmentation. Traditional methods for selecting optimal thresholds suffer from exponentially increasing time complexity as the number of threshold levels increases. In order to solve these problems, we choose African vultures optimization algorithm (AVOA) and introduce a novel modified African vultures optimization algorithm method called OLAVOA that combines predatory memory and logarithmic spiral based on opposition learning. In addition, we also apply 2D Kapur's entropy as a fitness value function of OLAVOA for multi-threshold image segmentation to solve the problem of traditional method. In the 30 benchmark function experiments at IEEE CEC2014, the average value of the experimental results of OLAVOA mostly outperforms the other algorithms. In the experimental convergence graph, OLAVOA's performance showed its convergence's velocity and capacity to depart from the local best. In addition, to demonstrate the effectiveness of OLAVOA on medical image segmentation, the image segmentation experiment included chest X-ray image of patients with COVID-19 and brain MRI image. Additionally, it was demonstrated that OLAVOA outperformed other approaches in segmentation trials by having greater adaptability in different threshold levels. Therefore, OLAVOA is effectively utilized to segment medical images.
C1 [Lan, Lin; Wang, Shengsheng] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Lan, Lin; Wang, Shengsheng] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.
C3 Jilin University; Jilin University
RP Wang, SS (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.; Wang, SS (corresponding author), Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.
EM 2365568182@qq.com; wss@jlu.edu.cn
FU This work is supported by the National Natural Science Foundation of
   China (62376106), the Innovation Capacity Construction Project of Jilin
   Province Development and Reform Commission (2021FGWCXNLJSSZ10,
   2019C053-3), the National Key Research and Developme [62376106];
   National Natural Science Foundation of China [2021FGWCXNLJSSZ10,
   2019C053-3]; Innovation Capacity Construction Project of Jilin Province
   Development and Reform Commission [2020YFA0714103]; National Key
   Research and Development Program of China; Fundamental Research Funds
   for the Central Universities
FX This work is supported by the National Natural Science Foundation of
   China (62376106), the Innovation Capacity Construction Project of Jilin
   Province Development and Reform Commission (2021FGWCXNLJSSZ10,
   2019C053-3), the National Key Research and Development Program of China
   (No. 2020YFA0714103) and the Fundamental Research Funds for the Central
   Universities, JLU.
CR Abd Elaziz M, 2020, IEEE ACCESS, V8, P125306, DOI 10.1109/ACCESS.2020.3007928
   Abdel-Basset M, 2022, EXPERT SYST APPL, V190, DOI 10.1016/j.eswa.2021.116145
   Abdollahzadeh B, 2021, COMPUT IND ENG, V158, DOI 10.1016/j.cie.2021.107408
   Ahmadianfar I, 2021, EXPERT SYST APPL, V181, DOI 10.1016/j.eswa.2021.115079
   Alihodzic A, 2014, SCI WORLD J, DOI 10.1155/2014/176718
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Cohen JP, 2020, COVID 19 IMAGE DATA, DOI 10.59275/j.melba.2020-48g7
   Derrac J, 2011, SWARM EVOL COMPUT, V1, P3, DOI 10.1016/j.swevo.2011.02.002
   Dong RY, 2021, KNOWL-BASED SYST, V233, DOI 10.1016/j.knosys.2021.107529
   Dutta T, 2021, EXPERT SYST APPL, V181, DOI 10.1016/j.eswa.2021.115107
   Esmaeili L, 2021, EXPERT SYST APPL, V182, DOI 10.1016/j.eswa.2021.115106
   Faramarzi A, 2020, EXPERT SYST APPL, V152, DOI 10.1016/j.eswa.2020.113377
   García S, 2010, INFORM SCIENCES, V180, P2044, DOI 10.1016/j.ins.2009.12.010
   Gupta S, 2019, EXPERT SYST APPL, V119, P210, DOI 10.1016/j.eswa.2018.10.050
   Heidari AA, 2019, FUTURE GENER COMP SY, V97, P849, DOI 10.1016/j.future.2019.02.028
   Hemdan E. E. D., 2020, arXiv, DOI [DOI 10.48550/ARXIV.2003.11055, 10.48550/arXiv.2003.11055]
   Ismael AM, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.114054
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Kaur S, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103541
   Khorram B, 2019, J DIGIT IMAGING, V32, P162, DOI 10.1007/s10278-018-0111-x
   Kotte S, 2018, MEASUREMENT, V130, P340, DOI 10.1016/j.measurement.2018.08.007
   Li CY, 2021, EXPERT SYST APPL, V185, DOI 10.1016/j.eswa.2021.115499
   Liang Y, 2019, ENERGY, V166, P653, DOI 10.1016/j.energy.2018.10.119
   Liu QX, 2023, ARTIF INTELL REV, V56, P159, DOI 10.1007/s10462-023-10498-0
   Loizou CP, 2015, J NEURORADIOLOGY, V42, P99, DOI 10.1016/j.neurad.2014.05.006
   Loizou CP, 2009, 2009 9TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND APPLICATIONS IN BIOMEDICINE, P131
   Loizou CP, 2011, IFIP ADV INF COMM TE, V364, P400
   Maguolo G, 2021, INFORM FUSION, V76, P1, DOI 10.1016/j.inffus.2021.04.008
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2016, KNOWL-BASED SYST, V96, P120, DOI 10.1016/j.knosys.2015.12.022
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mittal H, 2018, ENG APPL ARTIF INTEL, V71, P226, DOI 10.1016/j.engappai.2018.03.001
   Narmatha C, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02470-5
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PUN T, 1981, COMPUT VISION GRAPH, V16, P210, DOI 10.1016/0146-664X(81)90038-1
   Qi AL, 2022, COMPUT BIOL MED, V148, DOI 10.1016/j.compbiomed.2022.105810
   Renugambal A, 2023, MULTIMED TOOLS APPL, V82, P32711, DOI 10.1007/s11042-023-14637-1
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Si TP, 2022, EXPERT SYST APPL, V204, DOI 10.1016/j.eswa.2022.117481
   Tarkhaneh O, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.07.037
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xue JK, 2020, SYST SCI CONTROL ENG, V8, P22, DOI 10.1080/21642583.2019.1708830
   Yue XF, 2019, J INTELL FUZZY SYST, V37, P1399, DOI 10.3233/JIFS-182806
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang ZC, 2020, IEEE ACCESS, V8, P16269, DOI 10.1109/ACCESS.2020.2966665
   Zhao SW, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104427
NR 46
TC 0
Z9 0
U1 9
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 21
PY 2023
DI 10.1007/s11042-023-17189-6
EA OCT 2023
PG 50
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W1VN4
UT WOS:001089581100001
DA 2024-07-18
ER

PT J
AU Gupta, R
   Alam, T
AF Gupta, Ruchi
   Alam, Tanweer
TI An efficient federated learning based intrusion detection system using
   LS<SUP>2</SUP>DNN with PBKA based lightweight privacy preservation in
   cloud server
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Intrusion Detection System (IDS); Privacy preservation; Jaya
   Optimization Algorithm (JOA); Deep Neural Network (DNN); Federated
   Learning (FL); K-Anonymity (KA); Cloud computing
AB To execute seamless computing along with information sharing, Cloud Computing (CC) plays an important role in measurable resource sharing. But, owing to its open and distributed framework, privacy is a major risk as it is open to attackers. To accomplish their malicious goals, cloud services are abused by intruders. In this paper, using Linear Sigmoid Singleton Deep Neural Network ((LSDNN)-D-2)with Pearson correlation and Brownian motion induced K-Anonymity (PBKA)centered lightweight privacy preservation technique in the cloud server, an efficient federated learning-based Intrusion Detection System (IDS) is proposed. From the publically available sources, NSL-KDD datasets are downloaded; also, Feature Extraction (FE), null feature removal, and feature mapping are executed. Subsequently, for feature selection, Chebyshev Chaotic Mapping adapted Jaya Optimization Algorithm (C(2)MJOA) is wielded. Then, for classifying attacked and normal data, the LS(2)DNNclassifier is utilized.The incoming data from the data owners are privacy preserved via federated learning-centered Pearson correlation and Brownian motion-induced K-Anonymity (PBKA) while testing; moreover, the data is verified for intrusion. Finally, when compared with the prevailing models, the proposed model attained better results.
C1 [Gupta, Ruchi] Abdul Kalam Tech Univ, Fac Ajay Kumar Garg Engn Coll, Lucknow, India.
   [Alam, Tanweer] Islamic Univ Madinah, Fac Comp & Informat Syst, Madinah, Saudi Arabia.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); Islamic University
   of Al Madinah
RP Gupta, R (corresponding author), Abdul Kalam Tech Univ, Fac Ajay Kumar Garg Engn Coll, Lucknow, India.
EM guptaruchi@akgec.ac.in; tanweer03@iu.edu.sa
RI Alam, Tanweer/M-7780-2017
OI Alam, Tanweer/0000-0003-2731-4627
CR Alabdulatif A, 2019, J PARALLEL DISTR COM, V127, P209, DOI 10.1016/j.jpdc.2017.12.011
   Aldallal A, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13122306
   Aljurayban NS, 2015, 2015 2ND WORLD SYMPOSIUM ON WEB APPLICATIONS AND NETWORKING (WSWAN)
   Amarudin RF, 2020, 4 INT C INF COMP SCI
   Balamurugan V, 2019, CLUSTER COMPUT, V22, P13027, DOI 10.1007/s10586-017-1187-7
   Dwivedi S, 2021, CLUSTER COMPUT, V24, P1881, DOI 10.1007/s10586-020-03229-5
   Ghosh P, 2016, INT J CLOUD APPL COM, V6, P18, DOI 10.4018/IJCAC.2016100102
   Ghosh P, 2015, ADV INTELL SYST, V339, P91, DOI 10.1007/978-81-322-2250-7_10
   Ghribi S, 2017, 14 INT C WIR NETW MO
   Jaber AN, 2020, CLUSTER COMPUT, V23, P3221, DOI 10.1007/s10586-020-03082-6
   Kene SG, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION SYSTEMS (ICECS), P227, DOI 10.1109/ECS.2015.7124898
   Kumar N., 2020, Mater Today Proc, DOI [10.1016/j.matpr.2020.10.082, DOI 10.1016/J.MATPR.2020.10.082]
   Kumar U., 2015, INT J COMPUT APPL, V109, P6, DOI DOI 10.5120/19150-0573
   Mehmood Y, 2015, 2015 CONFERENCE ON INFORMATION ASSURANCE AND CYBER SECURITY (CIACS), P1, DOI 10.1109/CIACS.2015.7395559
   Mishra V, 2016, Intrusion detection system with snort in cloud computing advanced IDS
   Mondal A, 2021, MICROPROCESS MICROSY, V81, DOI 10.1016/j.micpro.2020.103719
   Patil R, 2018, INT CONF COMPUT
   Pham V., 2020, J. Commun, V15, P808, DOI [10.12720/jcm.15.11.808-817, DOI 10.12720/JCM.15.11.808-817]
   Salek Z, 2016, 2016 6TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P94, DOI 10.1109/ICCKE.2016.7802122
   Samrin R, 2017, 2017 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, COMMUNICATION, COMPUTER, AND OPTIMIZATION TECHNIQUES (ICEECCOT), P141
   Samriya JK, 2020, MATER TODAY-PROC, V2, P23, DOI DOI 10.1016/J.MATPR.2020.09.614
   Saranya T., 2020, Procedia Computer Science, V171, P1251, DOI 10.1016/j.procs.2020.04.133
   Singh D. Asir Antony Gnana, 2018, International Journal of Computer Network and Information Security, V10, P42, DOI 10.5815/ijcnis.2018.11.05
   Singh Parul, 2021, International Journal of Information Technology, V13, P565, DOI 10.1007/s41870-020-00583-w
   Zhi Li, 2017, International Journal of Distributed Sensor Networks, V13, P315, DOI 10.1177/1550147716687995
   Zhou YY, 2020, COMPUT NETW, V174, DOI 10.1016/j.comnet.2020.107247
NR 26
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 19
PY 2023
DI 10.1007/s11042-023-17401-7
EA OCT 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6OE7
UT WOS:001085969000020
DA 2024-07-18
ER

PT J
AU Kumar, SR
   Goyal, M
AF Kumar, Shipra Ravi
   Goyal, Mukta
TI Design of an incremental learning model for shard management in
   performance-aware blockchains: GA-TLEHO approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Blockchain; Delay; Energy consumption; GA-TLEHO; Incremental learning;
   Performance-Aware Blockchain (PAB); Sharding; Security attacks
ID SECURITY; ANALYZE
AB Performance-Aware Blockchains (PABs) are the highly optimized version of regular blockchains, capable of mining blocks with low delay and low energy. To incorporate performance awareness, researchers have proposed various lightweight consensus models that depend on single-chained blockchains, which limits their scalability performance after several blocks. To overcome this limitation, sharded blockchains were introduced, but very few of these sharded chains use lightweight consensus models. Hence, in this work, we propose a novel incremental learning model with light-weighted consensus for shard management in performance-aware blockchains. By using incremental learning, the model could continuously learn from the changing characteristics of the blockchain and make informed decisions about shard size adjustments to optimize performance. Further, to optimize shard size and ensure mining operates with lower delay and lower energy consumption, we use a hybrid combination of Genetic Algorithm and the Learner-based Elephant Herd Optimizer (GA-TLEHO) method. The reason for this hybrid combination of optimization methods is to enhance convergence by leveraging both exploration and exploitation. It is evident from the simulation analysis that the proposed method potentially mitigates Masquerading, Distributed Denial-of-Service (DDoS), and Finney attacks with higher efficiency and lower delay when compared with other state-of-the-art blockchain methods.
C1 [Kumar, Shipra Ravi; Goyal, Mukta] Jaypee Inst Informat Technol, Dept Comp Sci & Engn & Informat Technol, Noida, UP, India.
C3 Jaypee Institute of Information Technology (JIIT)
RP Kumar, SR (corresponding author), Jaypee Inst Informat Technol, Dept Comp Sci & Engn & Informat Technol, Noida, UP, India.
EM shipra.chaudhary85@gmail.com; mukta.goyal20@gmail.com
RI Goyal, Mukta/GNP-8767-2022
OI Goyal, Mukta/0000-0001-6726-3073
CR Aggarwal S, 2021, ADV COMPUT, V121, P399, DOI 10.1016/bs.adcom.2020.08.020
   Ameri R, 2024, CLUSTER COMPUT, V27, P2715, DOI 10.1007/s10586-023-04108-5
   Asheralieva A, 2020, IEEE INTERNET THINGS, V7, P11830, DOI 10.1109/JIOT.2020.3002969
   Besancon L, 2022, IEEE ACCESS, V10, P49905, DOI 10.1109/ACCESS.2022.3173313
   Bidgoly AJ, 2023, COMPUT OPER RES, V156, DOI 10.1016/j.cor.2023.106250
   Chadd Anthony, 2018, Network Security, V2018, P13, DOI 10.1016/S1353-4858(18)30069-2
   Ding SF, 2014, NEURAL COMPUT APPL, V25, P549, DOI 10.1007/s00521-013-1522-8
   Du MX, 2020, IEEE ACCESS, V8, P87665, DOI 10.1109/ACCESS.2020.2993759
   Gao L, 2022, J PARALLEL DISTR COM, V163, P283, DOI 10.1016/j.jpdc.2022.01.019
   Hafid A, 2019, IEEE ACCESS, V7, P185447, DOI 10.1109/ACCESS.2019.2961065
   Hafid A, 2020, IEEE ACCESS, V8, P179389, DOI 10.1109/ACCESS.2020.3027952
   Jia DY, 2021, IEEE ACCESS, V9, P67890, DOI 10.1109/ACCESS.2021.3077650
   Jo HJ, 2020, IEEE T VEH TECHNOL, V69, P2204, DOI 10.1109/TVT.2019.2961765
   Li GS, 2021, J PARALLEL DISTR COM, V157, P157, DOI 10.1016/j.jpdc.2021.06.007
   Li J, 2021, IEEE T NETW SERV MAN, V18, P3092, DOI 10.1109/TNSM.2021.3078142
   Li J, 2021, IEEE INTERNET THINGS, V8, P10052, DOI 10.1109/JIOT.2021.3049227
   Li J, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8091415
   Li SZ, 2021, IEEE T INF FOREN SEC, V16, P249, DOI 10.1109/TIFS.2020.3009610
   Li XQ, 2020, FUTURE GENER COMP SY, V107, P841, DOI 10.1016/j.future.2017.08.020
   Ma SC, 2022, IEEE WIREL COMMUN LE, V11, P1825, DOI 10.1109/LWC.2022.3183197
   Mirjalili S, 2019, STUD COMPUT INTELL, V780, P43, DOI 10.1007/978-3-319-93025-1_4
   Rao RV, 2012, INFORM SCIENCES, V183, P1, DOI 10.1016/j.ins.2011.08.006
   Ravi Kumar Shipra, 2023, International Journal of Information Technology, P1845, DOI 10.1007/s41870-023-01214-w
   Ren JY, 2022, TSINGHUA SCI TECHNOL, V27, P760, DOI 10.26599/TST.2021.9010046
   Saleh F, 2021, REV FINANC STUD, V34, P1156, DOI 10.1093/rfs/hhaa075
   Schinckus C, 2021, RENEW SUST ENERG REV, V152, DOI 10.1016/j.rser.2021.111682
   Singh PK, 2021, IEEE T INTELL TRANSP, V22, P3616, DOI 10.1109/TITS.2020.3004041
   Xie JF, 2019, IEEE NETWORK, V33, P166, DOI 10.1109/MNET.001.1800290
   Xu GQ, 2022, J PARALLEL DISTR COM, V164, P1, DOI 10.1016/j.jpdc.2022.01.029
   Xue LD, 2022, IEEE T COGN COMMUN, V8, P13, DOI 10.1109/TCCN.2021.3086490
   Yu GS, 2020, IEEE ACCESS, V8, P14155, DOI 10.1109/ACCESS.2020.2965147
   Yun J, 2021, IEEE INTERNET THINGS, V8, P708, DOI 10.1109/JIOT.2020.3006896
NR 32
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 19
PY 2023
DI 10.1007/s11042-023-17227-3
EA OCT 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6OE7
UT WOS:001085969000021
DA 2024-07-18
ER

PT J
AU Kavand, A
   Bekrani, M
AF Kavand, Ali
   Bekrani, Mehdi
TI Speckle noise removal in medical ultrasonic image using spatial filters
   and DnCNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Ultrasound image; Speckle noise; SRAD; DnCNN; Spatial filters
ID REDUCTION; SUPPRESSION; MODEL
AB Medical ultrasonic imaging is affected by an inherent phenomenon called speckle noise, which prevents the identification of details in images. While several state-of-the-art methods have been already proposed for speckle noise reduction, they often suffer from blurring, artifacts, and losing the useful details and features of image which limits the accuracy of medical diagnosis. To address such challenges, in this paper, taking the advantage of convolutional neural network (CNN), a hybrid algorithm composed of anisotropic spatial filter and denoising CNN (DnCNN) is proposed for speckle noise reduction. To further eliminate the blurring effect and increase the contrast of image edges, we incorporate Wiener filter and fast local Laplacian filter as post-processing. The experimental results on medical images show that the proposed method, in addition to an effective noise suppression, can preserve the edges and structural details of the image. The proposed algorithm outperforms state-of-the-art noise removal filters, including Frost, Lee, Median, the speckle reducing anisotropic diffusion (SRAD) filter, Wiener filter, DnCNN, and fusion filters including SRAD + DnCNN, and SRAD + DnCNN + Wiener, in terms of PSNR, SSI, and SSIM metrics.
C1 [Kavand, Ali; Bekrani, Mehdi] Qom Univ Technol, Fac Elect & Comp Engn, Qom, Iran.
RP Bekrani, M (corresponding author), Qom Univ Technol, Fac Elect & Comp Engn, Qom, Iran.
EM bekrani@qut.ac.ir
OI Bekrani, Mehdi/0000-0002-7825-2131
CR Al-Asad JF, 2018, 2018 INTERNATIONAL SYMPOSIUM ON ADVANCED ELECTRICAL AND COMMUNICATION TECHNOLOGIES (ISAECT)
   Al-Asadi JF, 2019, CURR MED IMAGING, V15, P679, DOI 10.2174/1573405614666180813113914
   Al-Dhabyani W, 2020, DATA BRIEF, V28, DOI 10.1016/j.dib.2019.104863
   Attlas N., 2014, Int. J. Res., V1, P112
   Aubry M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629645
   Baboshina VA, 2022, 2022 INT C QUAL MAN, P66, DOI 10.1109/ITQMIS56172.2022.9976753
   Bafaraj AS., 2019, Int J Appl Eng Res, V14, P1340
   Bao ZY, 2020, MULTIMED TOOLS APPL, V79, P7401, DOI 10.1007/s11042-019-08569-y
   Chambolle A, 2010, Theor Found Numer Methods Sparse Recovery, V9, DOI DOI 10.1515/9783110226157
   Chang Y, 2020, IEEE T INSTRUM MEAS, V69, P2707, DOI 10.1109/TIM.2019.2925881
   Chen HH, 2019, OPT COMMUN, V452, P510, DOI 10.1016/j.optcom.2019.07.027
   Choi H, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12060938
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dass Rajeshwar, 2018, Procedia Computer Science, V132, P1543, DOI 10.1016/j.procs.2018.05.118
   Devnani Ashish, 2016, 2016 International Conference on Global Trends in Signal Processing, Information Computing and Communication (ICGTSPICC). Proceedings, P353, DOI 10.1109/ICGTSPICC.2016.7955327
   Duarte-Salazar CA, 2020, IEEE ACCESS, V8, P15983, DOI 10.1109/ACCESS.2020.2967178
   El-Said SA, 2012, J MED IMAGING RADIAT, V43, P200, DOI 10.1016/j.jmir.2012.06.001
   Feng DL, 2020, LECT NOTES COMPUT SC, V11977, P85, DOI 10.1007/978-3-030-37969-8_11
   FROST VS, 1982, IEEE T PATTERN ANAL, V4, P157, DOI 10.1109/TPAMI.1982.4767223
   Gai S, 2018, DIGIT SIGNAL PROCESS, V72, P192, DOI 10.1016/j.dsp.2017.10.006
   Grubinger M., 2006, Language Resources and Evaluation, P13
   Hasan M., 2014, BM3D Image Denoising using SSIM Optimized Wiener Filter
   images, About us
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Joel T, 2018, APPL ACOUST, V138, P18, DOI 10.1016/j.apacoust.2018.03.023
   Kapoor A., 2016, Int J Eng Trends Technol, V37, P283, DOI [10.14445/22315381/IJETT-V37P249, DOI 10.14445/22315381/IJETT-V37P249]
   Karthikeyan K., 2011, INT J COMPUT APPL, V2, P8, DOI DOI 10.5120/2614-3646
   Karthikeyan S., 2019, 2019 3rd International Conference on Electronics, Communication and Aerospace Technology (ICECA). Proceedings, P605, DOI 10.1109/ICECA.2019.8822052
   Kumar Pal Shivam, 2021, 2021 International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE), P973, DOI 10.1109/ICACITE51222.2021.9404638
   Latif G, 2020, IEEE RIVF INT CONF, P210, DOI 10.1109/rivf48685.2020.9140767
   Latif Ghazanfar, 2018, Int J Eng Technol, V7, P37, DOI DOI 10.1109/ASAR.2018.8480289
   Lee H, 2022, IEEE T ULTRASON FERR, V69, P2638, DOI 10.1109/TUFFC.2022.3193640
   LEE JS, 1980, IEEE T PATTERN ANAL, V2, P165, DOI 10.1109/TPAMI.1980.4766994
   Li D, 2013, APPL OPTICS, V52, P8617, DOI 10.1364/AO.52.008617
   Lim J.S., 1990, Two-dimensional Signal and Image Processing
   Liu SF, 2019, ENGINEERING-PRC, V5, P261, DOI 10.1016/j.eng.2018.11.020
   Majee S, 2022, IEEE T IMAGE PROCESS, V31, P1963, DOI 10.1109/TIP.2022.3149230
   Mia S, 2023, Biomed Eng Adv, DOI [10.1016/j.bea.2023.100085, DOI 10.1016/J.BEA.2023.100085]
   Mohammadi M, 2021, 2021 26TH INTERNATIONAL COMPUTER CONFERENCE, COMPUTER SOCIETY OF IRAN (CSICC), DOI 10.1109/CSICC52343.2021.9420572
   Navabian, 2019, J SIGNAL PROCESS REN, V3, P9
   Nikesh P, 2019, INT C DAT SCI COMM I, P1, DOI [10.1109/IconDSC.2019.8816989, DOI 10.1109/ICONDSC.2019.8816989]
   Paris S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964963
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Qiang ZP, 2019, MULTIMED TOOLS APPL, V78, P619, DOI 10.1007/s11042-017-5347-9
   Sari S., 2012, J Signal Process, V16, P79, DOI [10.2299/jsp.16.79, DOI 10.2299/JSP.16.79]
   Sawant S, 2022, 8 INT C ADV COMP COM, P1197, DOI [10.1109/ICACCS54159.2022.9785110, DOI 10.1109/ICACCS54159.2022.9785110]
   Shamla Beevi A., 2021, 2021 7th International Conference on Advanced Computing and Communication Systems (ICACCS), P291, DOI 10.1109/ICACCS51430.2021.9441837
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh I., 2014, INT J COMPUTER APPL, V96, P21, DOI 10.5120/16903-6969
   Singh P, 2022, BIOCYBERN BIOMED ENG, V42, P512, DOI 10.1016/j.bbe.2022.03.003
   Tasnim T, 2017, INT CONF ADV ELECTR, P229, DOI 10.1109/ICAEE.2017.8255358
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z., 2006, Modern Image Quality Assessment, DOI 10.2200/S00010ED1V01Y200508IVM003
   Yahia M, 2020, 2020 5 INT C ADV TEC, P1, DOI [10.1109/ATSIP49331.2020.9231848, DOI 10.1109/ATSIP49331.2020.9231848]
   Yu HQ, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0205390
   Yu YJ, 2002, IEEE T IMAGE PROCESS, V11, P1260, DOI 10.1109/TIP.2002.804279
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang L, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.873
   Zhang PF, 2019, BIOMED OPT EXPRESS, V10, P552, DOI 10.1364/BOE.10.000552
   Zhao Y, 2018, BIOMED OPT EXPRESS, V9, P616, DOI 10.1364/BOE.9.000616
NR 60
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 18
PY 2023
DI 10.1007/s11042-023-17374-7
EA OCT 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6VJ6
UT WOS:001086159600012
DA 2024-07-18
ER

PT J
AU Li, JX
   Han, LX
   Wang, X
   Wang, Y
   Xia, JH
   Yang, Y
   Hu, B
   Li, S
   Yan, H
AF Li, Jingxian
   Han, Lixin
   Wang, Xin
   Wang, Yang
   Xia, Jianhua
   Yang, Yi
   Hu, Bing
   Li, Shu
   Yan, Hong
TI A hybrid neural network model based on optimized margin softmax loss
   function for music classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Music classification; CNN-LSTM model; AACM-Softmax; Combined margin
   penalties; Temporal dependencies
ID FEATURES
AB Music classification has achieved great progress due to the development of Convolutional Neural Networks (CNNs), which is important for music retrieval and recommendation. However, CNN cannot capture temporal information from music audio, which restricts the prediction performance of the model. To address the issue, we propose a Convolutional Neural Network-Long Short Term Memory (CNN-LSTM) model to learn local spatial features by CNN and learn temporal dependencies by LSTM. In addition, the traditional softmax loss function commonly lacks sufficient discrimination in music classification. Therefore, we propose an additive angular margin and cosine margin softmax (AACM-Softmax) loss function to improve classification results, which minimizes intra-class variances and maximizes inter-class variances simultaneously by enforcing combined margin penalties. Furthermore, we combine the CNN-LSTM model with AACM-Softmax loss function to comprehensively improve the classification performance by learning temporal-dependencies-included discriminative essential features. Extensive experiments on music genre datasets and music emotion datasets show that the proposed model consistently outperforms other models.
C1 [Li, Jingxian; Han, Lixin; Wang, Xin; Hu, Bing; Li, Shu] Hohai Univ, Sch Comp & Informat, Nanjing, Peoples R China.
   [Li, Jingxian] Jinling Inst Technol, Sch Software Engn, Nanjing, Peoples R China.
   [Wang, Yang] Anqing Normal Univ, Sch Comp & Informat, Anqing, Peoples R China.
   [Xia, Jianhua] Huaihua Univ, Sch Comp & Artificial Intelligence, Huaihua 418000, Peoples R China.
   [Yang, Yi] Huaibei Normal Univ, Coll Comp Sci & Technol, Huaibei, Peoples R China.
   [Yan, Hong] City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
C3 Hohai University; Jinling Institute of Technology; Anqing Normal
   University; Huaihua University; Huaibei Normal University; City
   University of Hong Kong
RP Li, JX; Han, LX (corresponding author), Hohai Univ, Sch Comp & Informat, Nanjing, Peoples R China.; Li, JX (corresponding author), Jinling Inst Technol, Sch Software Engn, Nanjing, Peoples R China.
EM lijingxian@jit.edu.cn; lixinhan2002@aliyun.com
FU This work is supported by the Natural Science Foundation of the Colleges
   and Universities in Anhui Province of China under Grant No. KJ2020A0035
   and No. KJ2021A0640, and the Hong Kong Innovation and Technology
   Commission (InnoHK Project CIMDA). [KJ2020A0035, KJ2021A0640]; Natural
   Science Foundation of the Colleges and Universities in Anhui Province of
   China; Hong Kong Innovation and Technology Commission (InnoHK Project
   CIMDA)
FX This work is supported by the Natural Science Foundation of the Colleges
   and Universities in Anhui Province of China under Grant No. KJ2020A0035
   and No. KJ2021A0640, and the Hong Kong Innovation and Technology
   Commission (InnoHK Project CIMDA).
CR Abdulwahab HM, 2022, APPL INTELL, V52, P13568, DOI 10.1007/s10489-021-03118-3
   Alhagry S, 2017, INT J ADV COMPUT SC, V8, P355, DOI 10.14569/IJACSA.2017.081046
   Almalawi A, 2022, CHEMOSPHERE, V303, DOI 10.1016/j.chemosphere.2022.134960
   Bhattacharjee M, 2020, IEEE-ACM T AUDIO SPE, V28, P1549, DOI 10.1109/TASLP.2020.2993152
   Chen CL, 2020, MOB INF SYST, V2020, DOI 10.1155/2020/8454327
   Chen GG, 2015, INT CONF ACOUST SPEE, P5236, DOI 10.1109/ICASSP.2015.7178970
   Choi K, 2017, INT CONF ACOUST SPEE, P2392, DOI 10.1109/ICASSP.2017.7952585
   Choi Keunwoo, 2016, ARXIV160600298, DOI 10.5281/zenodo.1416254
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Costa YMG, 2017, APPL SOFT COMPUT, V52, P28, DOI 10.1016/j.asoc.2016.12.024
   Dai J, 2016, 2016 10TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP)
   Defferrard M, 2016, P 18 INT SOC MUS INF, P316
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Dhal P, 2022, APPL INTELL, V52, P4543, DOI 10.1007/s10489-021-02550-9
   Dong YZ, 2019, IEEE T MULTIMEDIA, V21, P3150, DOI 10.1109/TMM.2019.2918739
   Douglas Eck, 2002, Istituto Dalle Molle Di Studi Sull'Intelligenza Artificiale, V103, P48
   Ferraro A, 2021, EUR SIGNAL PR CONF, P131
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   Han DH, 2022, FRONT COMPUT SCI-CHI, V16, DOI 10.1007/s11704-021-0569-4
   Hizlisoy S, 2021, ENG SCI TECHNOL, V24, P760, DOI 10.1016/j.jestch.2020.10.009
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Islam N, 2022, CHEMOSPHERE, V309, DOI 10.1016/j.chemosphere.2022.136615
   Jakubik J, 2018, ADV INTELL SYST COMP, V655, P27, DOI 10.1007/978-3-319-67220-5_3
   Khan AI, 2022, ENG APPL ARTIF INTEL, V114, DOI 10.1016/j.engappai.2022.104996
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee J, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8010150
   Li C, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102185
   Li JX, 2022, NEURAL COMPUT APPL, V34, P10337, DOI 10.1007/s00521-022-06896-0
   Li JX, 2022, MULTIMED TOOLS APPL, V81, P4621, DOI 10.1007/s11042-020-10465-9
   Lidy T., 2016, MIREX, V2016, P3
   Liu H, 2019, P 2018 INT C MATH MO, P15
   Liu H, 2019, PROC CVPR IEEE, P11939, DOI 10.1109/CVPR.2019.01222
   Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212
   Liu WY, 2016, PR MACH LEARN RES, V48
   Lyu Q, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P991, DOI 10.1145/2733373.2806383
   Mao QR, 2014, IEEE T MULTIMEDIA, V16, P2203, DOI 10.1109/TMM.2014.2360798
   da Silva ACM, 2020, EXPERT SYST APPL, V144, DOI 10.1016/j.eswa.2019.113071
   Nam J, 2019, IEEE SIGNAL PROC MAG, V36, P41, DOI 10.1109/MSP.2018.2874383
   Pons J, 2019, INT CONF ACOUST SPEE, P336, DOI 10.1109/ICASSP.2019.8682912
   Rajesh S, 2020, PROCEDIA COMPUT SCI, V167, P16, DOI 10.1016/j.procs.2020.03.178
   Ranjan R, 2017, Arxiv, DOI arXiv:1703.09507
   Russo M, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102270
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Singh S, 2018, MULTIMED TOOLS APPL, V77, P27061, DOI 10.1007/s11042-018-5904-x
   Song GX, 2018, NEUROCOMPUTING, V292, P104, DOI 10.1016/j.neucom.2018.02.076
   Tang CP, 2018, PROC SPIE, V10828, DOI 10.1117/12.2501763
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Wang F, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1041, DOI 10.1145/3123266.3123359
   Wang F, 2018, IEEE SIGNAL PROC LET, V25, P926, DOI 10.1109/LSP.2018.2822810
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Wang J, 2020, IEEE-ACM T AUDIO SPE, V28, P581, DOI 10.1109/TASLP.2019.2959251
   Wang Z., 2019, 2019 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC), DOI 10.1109/CLEOE-EQEC.2019.8873324
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Weng W, 2023, APPL INTELL, V53, P3017, DOI 10.1007/s10489-022-03386-7
   Wu HH, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P556, DOI 10.1109/ICASSP39728.2021.9414405
   Yin Yu, 2021, 2021 5th Asian Conference on Artificial Intelligence Technology (ACAIT), P473, DOI 10.1109/ACAIT53529.2021.9731277
   Zhang WB, 2016, INTERSPEECH, P3304, DOI 10.21437/Interspeech.2016-1236
   Zhao JF, 2019, BIOMED SIGNAL PROCES, V47, P312, DOI 10.1016/j.bspc.2018.08.035
   Zhao K, 2019, PROCEEDINGS OF 2019 IEEE 3RD INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2019), P2039, DOI [10.1109/itnec.2019.8729266, 10.1109/ITNEC.2019.8729266]
   Zhou ZH, 2019, NATL SCI REV, V6, P74, DOI 10.1093/nsr/nwy108
NR 63
TC 0
Z9 0
U1 20
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-17056-4
EA OCT 2023
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY6P9
UT WOS:001142539400019
DA 2024-07-18
ER

PT J
AU Zebhi, S
AF Zebhi, Saeedeh
TI An efficient 3D convolutional neural network with informative 3D volumes
   for human activity recognition using wearable sensors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Continuous wavelet transform; 3D-CNNs; Action recognition; Short-time
   fourier transform
AB Short-Time Fourier Transform (STFT) and Continuous Wavelet Transform (CWT) are two popular transforms which can be used to find time-frequency representations. By using them, one-dimensional signals acquired from different axes or sensors are mapped to time-frequency representations. These representations can construct 3D volumes which include time-frequency information of signals. Recently, the advantage of 3D convolutional neural networks (3D-CNNs) for video classification causes to incorporate them with the 3D volumes. Based on this opinion, a novel method composed of two basic methods is proposed in this paper. The magnitude of the STFT and the CWT are used for constructing 3D volumes in basic methods. Also, a developed 3D-CNN is applied for classifying. Two streams of these 3D volumes are fused in the proposed method. It attains the accuracies of 96.61%, 97.77%, 99.65% and 98.32% for UCI HAR, MOTIONSENSE, MHEALTH and WISDM datasets, respectively. Achieved results demonstrate the superiority of the proposed method compared with state-of-the-art approaches.
C1 [Zebhi, Saeedeh] Yazd Univ, Elect Engn Dept, Yazd, Iran.
C3 University of Yazd
RP Zebhi, S (corresponding author), Yazd Univ, Elect Engn Dept, Yazd, Iran.
EM saeedehzebhi@gmail.com
CR Aljarrah Amir A., 2019, 2019 2nd International Conference on Engineering Technology and its Applications (IICETA), P156, DOI 10.1109/IICETA47481.2019.9012979
   Anguita D, 2013, ESANN, P437, DOI DOI 10.3390/S20082200
   [Anonymous], 1999, SIGNALS SYSTEMS
   Banos O, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/1475-925X-14-S2-S6
   Batool Mouazma, 2019, 2019 International Conference on Applied and Engineering Mathematics (ICAEM), P145, DOI 10.1109/ICAEM.2019.8853770
   Chen KX, 2020, IEEE T NEUR NET LEAR, V31, P1747, DOI 10.1109/TNNLS.2019.2927224
   Chen LM, 2012, IEEE T SYST MAN CY C, V42, P790, DOI 10.1109/TSMCC.2012.2198883
   Daubechies I., 1992, Ten lectures on wavelets, DOI [DOI 10.1137/1.9781611970104, 10.1137/1.9781611970104]
   Deep Samundra, 2019, 2019 20th International Conference on Parallel and Distributed Computing, Applications and Technologies (PDCAT), P259, DOI 10.1109/PDCAT46702.2019.00055
   Dua N, 2021, COMPUTING, V103, P1461, DOI 10.1007/s00607-021-00928-8
   Hajihassani O, 2021, Learning representations for anonymizing sensor data in IoT applications
   Ignatov A, 2018, APPL SOFT COMPUT, V62, P915, DOI 10.1016/j.asoc.2017.09.027
   Jalal A, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10207122
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Khatun S, 2018, INT CONF ELECTRO INF, P934, DOI 10.1109/EIT.2018.8500135
   Lavanya B, 2017, IEEE I C COMP INT CO, P194
   Lin S-Y, 2018, BMVC, P239
   Malekzadeh M, 2015, PROCEEDINGS OF THE WORKSHOP ON PRIVACY BY DESIGN IN DISTRIBUTED SYSTEMS (P2DS'18), DOI 10.1145/3195258.3195260
   Mutegeki Ronald, 2020, 2020 International Conference on Artificial Intelligence in Information and Communication (ICAIIC), P362, DOI 10.1109/ICAIIC48513.2020.9065078
   Nanda Sarmistha, 2021, Progress in Advanced Computing and Intelligent Engineering. Proceedings of ICACIE 2019. Advances in Intelligent Systems and Computing (AISC 1199), P185, DOI 10.1007/978-981-15-6353-9_17
   Nematallah H, 2019, IEEE SENSOR, DOI 10.1109/sensors43011.2019.8956951
   Ngueveu CR, 2020, arXiv
   Oluwalade B, 2021, Arxiv, DOI arXiv:2103.03836
   Papamitsiou Z, 2020, IEEE T LEARN TECHNOL, V13, P689, DOI 10.1109/TLT.2020.3020499
   Ponce H, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16071033
   Saeed Aaqib, 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3328932
   Shaw R, 2023, COGN COMPUT, V15, P1243, DOI 10.1007/s12559-022-10023-5
   Shaw R, 2022, FUTURE GENER COMP SY, V126, P305, DOI 10.1016/j.future.2021.08.018
   Shojaedini SV, 2020, BIOMED ENG LETT, V10, P419, DOI 10.1007/s13534-020-00160-x
   Tahir SBUD, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22050579
   Tang CI, 2021, PROC ACM INTERACT MO, V5, DOI 10.1145/3448112
   Uddin M.T., 2015, 2015 INT C ELECT ENG, DOI 10.1109/ICEEICT.2015.7307384
   Wang K, 2019, IEEE SENS J, V19, P7598, DOI 10.1109/JSEN.2019.2917225
   Wang ZL, 2012, IEEE T INF TECHNOL B, V16, P691, DOI 10.1109/TITB.2012.2196440
   Weiss GM, 2019, IEEE ACCESS, V7, P133190, DOI 10.1109/ACCESS.2019.2940729
   Xia K, 2020, IEEE ACCESS, V8, P56855, DOI 10.1109/ACCESS.2020.2982225
   Ye J, 2020, IEEE T PATTERN ANAL, V42, P126, DOI 10.1109/TPAMI.2018.2874455
NR 37
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-17400-8
EA OCT 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU6A2
UT WOS:001155212900003
DA 2024-07-18
ER

PT J
AU Liu, XY
   Li, XJ
   Niu, XH
   Shi, CH
   Xiong, L
   Qing, Q
   Liu, YS
   Yang, TY
AF Liu, Xiangyi
   Li, Xiaojie
   Niu, Xianhua
   Shi, Canghong
   Xiong, Ling
   Qing, Qian
   Liu, Yushi
   Yang, Tianyu
TI Robust audio watermarking algorithm resisting cropping based on SIFT
   transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cropping attack; Discrete wavelet transform; Scale-invariant feature
   transform; Audio watermarking; Robustness
ID SPREAD-SPECTRUM; NORM-SPACE; SCHEME
AB Robust watermarking plays a key role in copyright protection and information leakage tracking, network conference recording, etc. However, cropping attack is a strong geometric attack, which can destroy the watermarked information of audio signal. For this problem, this paper proposes a robust audio watermarking algorithm by combining chaotic system, scale invariant feature transform (SIFT) feature and discrete wavelet transform (DWT) to resist cropping attack. After applying DWT to the original signal, we use the obtained DWT low-frequency coefficients to construct a square matrix and extract the SIFT features with scale invariance from this matrix. The watermark is encrypted by Tent map, and then it is embedded into the low-frequency components according to the sift features location information. Watermark extraction is the inverse process of embedding. Compared with the state of the art audio watermarking algorithms, the proposed algorithm has better performance in terms of robustness and payload capacity while ensuring good imperceptibility.
C1 [Liu, Xiangyi; Niu, Xianhua; Shi, Canghong; Xiong, Ling; Liu, Yushi; Yang, Tianyu] Xihua Univ, Sch Comp & Software Engn, Chengdu 610039, Peoples R China.
   [Li, Xiaojie] Chengdu Univ Informat Technol, Coll Comp Sci, Chengdu 610225, Peoples R China.
   [Qing, Qian] Guizhou Univ Finance & Econ, Sch Informat, Guiyang 550000, Peoples R China.
C3 Xihua University; Chengdu University of Information Technology; Guizhou
   University of Finance & Economics
RP Shi, CH (corresponding author), Xihua Univ, Sch Comp & Software Engn, Chengdu 610039, Peoples R China.
EM xiangyiliu18@163.com; lixiaojie000000@163.com; niuxh@mail.xhu.edu.cn;
   canghongshi@163.com; lingdonghua99@163.com; qqian2018_p@163.com;
   lyusi2000@163.com; yty_2022_10_17@163.com
RI xiangyi, liu/HKP-0004-2023; yang, tianyu/ABB-5181-2020
OI xiangyi, liu/0000-0002-0541-5390; yang, tianyu/0000-0001-9658-4933
FU This work was supported by the Sichuan Science and Technology program
   (Grant nos.23NSFSC0470, 2021YFQ0053, 2022YFG0152), and the National
   Natural Science Foundation of China (NSFC) program (No.62171387,
   No.62202390, No.61902085). [23NSFSC0470, 2021YFQ0053, 2022YFG0152];
   Sichuan Science and Technology program [62171387, 62202390, 61902085];
   National Natural Science Foundation of China (NSFC) program
FX This work was supported by the Sichuan Science and Technology program
   (Grant nos.23NSFSC0470, 2021YFQ0053, 2022YFG0152), and the National
   Natural Science Foundation of China (NSFC) program (No.62171387,
   No.62202390, No.61902085).
CR Al-Haj A, 2011, INT ARAB J INF TECHN, V8, P326
   Al-Qerem A, 2020, SOFT COMPUT, V24, P5695, DOI 10.1007/s00500-019-04220-y
   Alsmirat MA, 2018, Multimed Tools Appl
   Bernardi G, 2018, IEEE-ACM T AUDIO SPE, V26, P1010, DOI 10.1109/TASLP.2018.2808042
   Bhat KV, 2010, DIGIT SIGNAL PROCESS, V20, P1547, DOI 10.1016/j.dsp.2010.02.006
   Dhar PK, 2014, 2014 INTERNATIONAL CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (ICECE), P136, DOI 10.1109/ICECE.2014.7027012
   Dhar PK, 2015, J INF SECUR APPL, V20, P74, DOI 10.1016/j.jisa.2014.10.007
   Fallahpour M, 2015, IEEE-ACM T AUDIO SPE, V23, P1273, DOI 10.1109/TASLP.2015.2430818
   Fan MQ, 2011, DIGIT SIGNAL PROCESS, V21, P110, DOI 10.1016/j.dsp.2010.09.003
   Kabal P., 2002, TSP Lab Technical Report.
   Kang XG, 2011, IEEE T MULTIMEDIA, V13, P181, DOI 10.1109/TMM.2010.2098850
   Khaldi K, 2013, IEEE T AUDIO SPEECH, V21, P675, DOI 10.1109/TASL.2012.2227733
   Lei BY, 2013, IEEE T AUDIO SPEECH, V21, P2368, DOI 10.1109/TASL.2013.2277929
   Lei BY, 2012, SIGNAL PROCESS, V92, P1985, DOI 10.1016/j.sigpro.2011.12.021
   Li D, 2018, Inf Sci
   Li JF, 2018, MULTIMED TOOLS APPL, V77, P14481, DOI 10.1007/s11042-017-5024-z
   Liu ZH, 2019, IEEE T INF FOREN SEC, V14, P1171, DOI 10.1109/TIFS.2018.2871748
   Liu ZH, 2017, MULTIMED TOOLS APPL, V76, P9297, DOI 10.1007/s11042-016-3533-9
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Malvar HS, 2003, IEEE T SIGNAL PROCES, V51, P898, DOI 10.1109/TSP.2003.809385
   Nam SH, 2018, MULTIMED TOOLS APPL, V77, P7811, DOI 10.1007/s11042-017-4678-x
   Natgunanathan I, 2017, IEEE-ACM T AUDIO SPE, V25, P2176, DOI 10.1109/TASLP.2017.2749001
   Piper J, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.305802
   Pun CM, 2013, IEEE T AUDIO SPEECH, V21, P2412, DOI 10.1109/TASL.2013.2279312
   Raj MG, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.300824
   Rastogi S, 2016, PROCEDIA COMPUT SCI, V78, P26, DOI 10.1016/j.procs.2016.02.006
   Saadi S, 2019, SIGNAL PROCESS, V154, P74, DOI 10.1016/j.sigpro.2018.08.011
   Shi CH, 2021, MULTIMED TOOLS APPL, V80, P25773, DOI 10.1007/s11042-021-10896-y
   tech.ebu.ch, ABOUT US
   Torcoli M, 2021, arXiv
   Valizadeh A., 2011, IEEE Transactions on Information Forensics and Security, V6, P267, DOI 10.1109/TIFS.2010.2103061
   Wang S, 2014, MEASUREMENT, V48, P54, DOI 10.1016/j.measurement.2013.10.028
   Wang XK, 2013, SIGNAL PROCESS, V93, P913, DOI 10.1016/j.sigpro.2012.11.003
   Xiang Y, 2015, IEEE-ACM T AUDIO SPE, V23, P2228, DOI 10.1109/TASLP.2015.2476755
   Yamni M, 2022, DIGIT SIGNAL PROCESS, V120, DOI 10.1016/j.dsp.2021.103251
   Zhang P, 2012, INT J FUZZY SYST, V14, P289
   Zhang XQ, 2013, IEEE INT WORKS INFOR, P186, DOI 10.1109/WIFS.2013.6707816
   Zhao J, 2023, IEEE-ACM T AUDIO SPE, V31, P448, DOI 10.1109/TASLP.2022.3225668
   Zou XG, 2014, 2014 5TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING AND SERVICE SCIENCE (ICSESS), P996, DOI 10.1109/ICSESS.2014.6933733
NR 39
TC 0
Z9 0
U1 9
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 10
PY 2023
DI 10.1007/s11042-023-16827-3
EA OCT 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U2RB1
UT WOS:001083315100009
DA 2024-07-18
ER

PT J
AU Sophia, SSJ
   Diwakaran, S
AF Sophia, S. Sheeba Jeya
   Diwakaran, S.
TI Effective recognition of glaucoma using SIFT and RFSO classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Glaucoma; Retinal images; SIFT clustering & feature extractions; RFSO
   classification
ID AUTOMATED DIAGNOSIS; ALGORITHM
AB One of the most serious eye illnesses, glaucoma affects the astrocytes and optic nerve fibres, causing irreversible damage to the eyes. As a result, glaucoma early identification is crucial in the medical industry. Retinal image-based detection falls within the category of non-invasive ways of detection among the many techniques. Automatic periodical screening can aid in the prompt detection of retinal glaucoma, while also easing the workload of skilled ophthalmologists. Effective glaucoma treatment can also lessen the severity of vision impairments brought on by the disease's advanced stages. The retinal fundus dataset is used in this paper to undertake a novel glaucoma detection procedure. Additionally, the Scale-invariant feature transform (SIFT) is a widely used method for feature extraction and clustering in picture classification tasks. The characteristic is robust to variations in illumination, noise, partial occlusion, and minor changes in viewpoint in the photos. It is independent of the scale and orientation of the images. The real-time glaucoma screening system is suggested for use with this clustering approach. Convolutional neural network (CNN) classifier optimization is performed using a mix of the SIFT and Rooster Food Search optimization (RFSO) based algorithms for exploration and exploitation procedures. To assess whether a retina is glaucomatous or healthy, the resulting optic disc area is used. As a result, the study was presented based on efficient clustering, precise classification, and the use of various data sets, including the LAG and Rim-One database. The suggested technique was created in MATLAB and tested on this database. The suggested strategy produced accuracy levels above 95% and performed better on comparisons for additional metrics like clustering and classifier-related factors. In order to help researchers conduct additional study on glaucoma detection, we provide research difficulties and their respective solutions.
C1 [Sophia, S. Sheeba Jeya; Diwakaran, S.] Kalasalingam Acad Res & Educ, Dept Elect & Commun Engn, Krishnankoil, India.
C3 Kalasalingam Academy of Research & Education
RP Sophia, SSJ (corresponding author), Kalasalingam Acad Res & Educ, Dept Elect & Commun Engn, Krishnankoil, India.
EM s.sheebajeyasophia@klu.ac.in
FU The authors would like to thank Technical head and team members at
   Vaigai College of Engineering for their helpful discussions and
   technical assistance. Also authors would like to thank research scholars
   of Computer science, Electrical and Electronics, Ele
FX The authors would like to thank Technical head and team members at
   Vaigai College of Engineering for their helpful discussions and
   technical assistance. Also authors would like to thank research scholars
   of Computer science, Electrical and Electronics, Electronics and
   Communication Engineering Vaigai College of Engineering for frequency
   pattern development, which is used in software level checking process.
CR Acharya UR, 2011, IEEE T INF TECHNOL B, V15, P449, DOI 10.1109/TITB.2011.2119322
   Agarwal A, 2015, 2015 4TH INTERNATIONAL WORK CONFERENCE ON BIOINSPIRED INTELLIGENCE (IWOBI), P139, DOI 10.1109/IWOBI.2015.7160157
   Allison K, 2020, CUREUS J MED SCIENCE, V12, DOI 10.7759/cureus.11686
   Almazroa A, 2015, J OPHTHALMOL, V2015, DOI 10.1155/2015/180972
   Bock R, 2010, MED IMAGE ANAL, V14, P471, DOI 10.1016/j.media.2009.12.006
   Burlina PM, 2018, JAMA OPHTHALMOL, V136, P1359, DOI 10.1001/jamaophthalmol.2018.4118
   Deb S, 2020, ARTIF INTELL REV, V53, P1737, DOI 10.1007/s10462-019-09718-3
   Dong YY, 2017, IEEE CONF IMAGING SY, P127, DOI 10.1109/ist.2017.8261463
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Harmon SA, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17971-2
   Hemelings R, 2020, ACTA OPHTHALMOL, V98, pE94, DOI 10.1111/aos.14193
   Hussain SA., 2015, Int J Comput Sci Inf Technol, V6, P1217
   Kumar BN, 2018, SEMIN OPHTHALMOL, V33, P275, DOI 10.1080/08820538.2016.1229801
   Marino L, 2017, ANIM COGN, V20, P127, DOI 10.1007/s10071-016-1064-4
   Meng XB, 2014, LECT NOTES COMPUT SC, V8794, P86, DOI 10.1007/978-3-319-11857-4_10
   Mookiah MRK, 2012, KNOWL-BASED SYST, V33, P73, DOI 10.1016/j.knosys.2012.02.010
   Nayak J, 2009, J MED SYST, V33, P337, DOI 10.1007/s10916-008-9195-z
   Poshtyar J, 2010, Med Biometrics, P64
   Schacknow PN, 2010, GLAUCOMA BOOK: A PRACTICAL, EVIDENCE-BASED APPROACH TO PATIENT CARE, P1, DOI 10.1007/978-0-387-76700-0
   Sophia SSSJ, 2023, J Intell Fuzzy Syst, P1
   Tan NYQ, 2020, CURR OPIN OPHTHALMOL, V31, P91, DOI 10.1097/ICU.0000000000000649
   Tham YC, 2014, OPHTHALMOLOGY, V121, P2081, DOI 10.1016/j.ophtha.2014.05.013
   Thompson AC, 2019, AM J OPHTHALMOL, V201, P9, DOI 10.1016/j.ajo.2019.01.011
   Vlachokosta AA, 2007, P ANN INT IEEE EMBS, P888, DOI 10.1109/IEMBS.2007.4352433
   Wang YC, 2020, IEEE ACCESS, V8, P88133, DOI 10.1109/ACCESS.2020.2989157
   Weinreb RN, 2014, JAMA-J AM MED ASSOC, V311, P1901, DOI 10.1001/jama.2014.3192
   Zhang K, 2019, IEEE ACCESS, V7, P115637, DOI 10.1109/ACCESS.2019.2935879
   Zhuo Zhang, 2010, 2010 5th IEEE Conference on Industrial Electronics and Applications (ICIEA 2010), P1686, DOI 10.1109/ICIEA.2010.5515221
NR 29
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 7
PY 2023
DI 10.1007/s11042-023-17109-8
EA OCT 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2OY9
UT WOS:001096913600028
DA 2024-07-18
ER

PT J
AU Farooq, U
   Khurana, SS
   Singh, P
   Kumar, M
AF Farooq, Umar
   Khurana, Surinder Singh
   Singh, Parvinder
   Kumar, Munish
TI An Empirical Study on Detection of Android Adware Using Machine Learning
   Techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Android Adware Detection; Malware; Ensemble Learning; Light Gradient
   Boosting Machine; Extended Gradient Boosting Machine
ID FRAMEWORK
AB The Android operating system, without showing signs of diminishing, has experienced unprecedented popularity and continues to thrive with a significant user base. Its notable aspect for supporting third-party applications has revolutionized the digital landscape, allowing developers to generate revenue through advertising. Adware has emerged as a prominent monetization method for developers of both Adware and the applications that integrate it. However, as the utilization of Adware proliferates, it simultaneously escalates the risk of fraudulent activities associated with advertising approaches. The increasing prevalence of Adware introduces a pressing need for robust detection and mitigation strategies to address the potentially detrimental effects of fraudulent practices. In response, the proposed system focuses on analyzing and identifying alterations in network traffic acquired from Android devices. This research delves into an extensive exploration of machine and deep learning models, aiming to enhance the detection and mitigation of Adware. The exceptional capabilities of the LGBM model highlight the system's noteworthy performance in binary classification. However, in multiclass classification, the XGBM model emerges as the frontrunner, outperforming other models and showcasing superior effectiveness in distinguishing and classifying Adware and general Malware. These outcomes highlight the remarkable efficacy of the system in accurately classifying adware instances, regardless of the classification scenario. The findings not only validate the viability of the proposed system but also underscore the superior performance of specific machine learning models employed in the research. With further refinement and optimization, the system holds great promise in enhancing the security and integrity of the Android ecosystem.
C1 [Farooq, Umar; Khurana, Surinder Singh; Singh, Parvinder] Cent Univ Punjab, Dept Comp Sci & Technol, Bathinda, India.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, India.
C3 Central University of Punjab
RP Singh, P (corresponding author), Cent Univ Punjab, Dept Comp Sci & Technol, Bathinda, India.
EM psdcuraj.cs@gmail.com
RI Singh, Parvinder/AAM-5012-2021; Kumar, Munish/P-7756-2018
OI Singh, Parvinder/0000-0001-7258-7769; Kumar, Munish/0000-0003-0115-1620;
   Farooq, Umar/0000-0002-3786-2574
CR Abbas G., 2023, SN Comput Sci, V4, P1
   Aboosh Omar Sh Ahmed, 2021, 2021 International Conference on Computing and Communications Applications and Technologies (I3CAT), P98, DOI 10.1109/I3CAT53310.2021.9629400
   Aboosh Omar Sh. Ahmed, 2021, IEEE, P1, DOI [10.13140/RG.2.2.27362.61126, DOI 10.13140/RG.2.2.27362.61126]
   Agrawal R., 2020, 2020 INT C EM TRENDS, P1
   Ahmadi M, 2016, PROCEEDINGS OF THE 6TH WORKSHOP ON SECURITY AND PRIVACY IN SMARTPHONES AND MOBILE DEVICES (SPSM'16), P103, DOI 10.1145/2994459.2994469
   Alani MM, 2022, COMPUT SECUR, V117, DOI 10.1016/j.cose.2022.102718
   Alzaylaee MK, 2020, COMPUT SECUR, V89, DOI 10.1016/j.cose.2019.101663
   [Anonymous], 1993, C45 PROGRAMS MACHINE, DOI [DOI 10.1007/BF00993309, 10.1007/bf00993309]
   Arivudainambi D, 2019, COMPUT COMMUN, V147, P50, DOI 10.1016/j.comcom.2019.08.003
   Arp D, 2014, 21ST ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2014), DOI 10.14722/ndss.2014.23247
   Bagui S, 2021, Int J Cyber Res Educ (IJCRE), V3, P1
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chen ZX, 2018, INFORM SCIENCES, V433, P346, DOI 10.1016/j.ins.2017.04.044
   Crussell J, 2014, MOBISYS'14: PROCEEDINGS OF THE 12TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P123, DOI 10.1145/2594368.2594391
   Demertzis Konstantinos, 2017, Vietnam Journal of Computer Science, V4, P245, DOI 10.1007/s40595-017-0095-3
   Dina AS, 2021, INTERNET THINGS-NETH, V16, DOI 10.1016/j.iot.2021.100462
   Erturk E, 2014, A case study in open source software security and privacy: Android Adware
   Farooq U, 2021, TEH GLAS, V15, P112, DOI 10.31803/tg-20210205101347
   Farooq Umar, 2020, international Journal of Engineering Research & Technology (IJERT), V9
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Grace M., 2012, P 19 ANN NETW DISTR
   Hancock JT, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00369-8
   Ideses I, 2014, IEEE CONV EL ELECT I
   Jiang HB, 2021, IEEE ACM T NETWORK, V29, P2228, DOI 10.1109/TNET.2021.3084251
   Ke GL, 2017, ADV NEUR IN, V30
   Lashkari AH, 2017, P 52 IEEE INT CARN C
   Lashkari AH, 2017, ANN CONF PRIV SECUR, P233, DOI 10.1109/PST.2017.00035
   Lee K., 2019, Proc IMIS, P609
   Li B, 2022, INFORM SCIENCES, V612, P384, DOI 10.1016/j.ins.2022.08.093
   Liu Bin, 2014, 11 USENIX S NETW SYS, P57
   Liu X, 2023, HUM SOC SCI COMMUN, V10, DOI 10.1057/s41599-023-01816-6
   Lu N, 2021, COMPUT NETW, V189, DOI 10.1016/j.comnet.2021.107932
   Mitchell R, 2017, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.127
   Moonsamy V, 2014, FUTURE GENER COMP SY, V36, P122, DOI 10.1016/j.future.2013.09.014
   Nancy D., 2016, Int J Comp Sci Inf Technol, V7, P1970
   Narayanan A, 2014, 2014 IEEE NINTH INTERNATIONAL CONFERENCE ON INTELLIGENT SENSORS, SENSOR NETWORKS AND INFORMATION PROCESSING (IEEE ISSNIP 2014)
   Sanal Y, 2017, Mediterr J Humanit, P367
   Schultz EE, 2003, COMPUT SECUR, V22, P366, DOI 10.1016/S0167-4048(03)00501-7
   Shahzad R. K., 2011, 2011 Sixth International Conference on Availability, Reliability and Security, P189, DOI 10.1109/ARES.2011.35
   Shaw G, 2003, Network Security, P12, DOI [DOI 10.1016/S1353-4858(03)00908-5, 10.1016/s1353-4858(03)00908-5]
   Singhai P, 2023, CIRC SYST SIGNAL PR, V42, P3509, DOI 10.1007/s00034-022-02280-4
   Statista, 2023, US
   Suresh S, 2019, J COMPUT VIROL HACKI, V15, P147, DOI 10.1007/s11416-018-0328-8
   UNB, 2017, ABOUT US
   Wang W, 2018, IEEE ACCESS, V6, P31798, DOI 10.1109/ACCESS.2018.2835654
   Wu Z, 2020, IEEE T CYBERNETICS, V50, P1595, DOI 10.1109/TCYB.2018.2877161
NR 48
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 6
PY 2023
DI 10.1007/s11042-023-16920-7
EA OCT 2023
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U0GP6
UT WOS:001081680200015
DA 2024-07-18
ER

PT J
AU Kumar, C
   Kumar, M
AF Kumar, Chhotelal
   Kumar, Mukesh
TI Next-item recommendation within a short session using the combined
   features of horizontal and vertical convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Recommendation systems; Convolutional neural networks; Next-item
   recommendation; Sequential recommendation; Session-based recommendation
   system
AB Session-based recommendation systems are designed to offer recommendations to users based on their current browsing session rather than relying on their entire historical behavior. In many real-world scenarios, user profiles and historical behaviors are not readily available, which makes it challenging to provide accurate recommendations. However, most recommender systems only consider the user's long-term profile and static preferences while ignoring their dynamic preferences, resulting in unreliable recommendations. The existing traditional and deep learning-based methods generate recommendations based on session data, such as clicks are not able to capture sequential patterns, contextual information, and dynamic preferences altogether. To address these issues, a deep learning-based model, i.e., horizontal vertical convolutional neural network (HV-CNN) has been proposed, which uses the combination of horizontal and vertical convolutional features to recommend the next item for a given sequence of items in the current ongoing session. The session clicks present in the dataset have been embedded using Word2Vec embedding technique before providing it to the proposed HV-CNN model. Although predicting the next item within a session is challenging due to the limited contextual information available, the proposed model outperforms state-of-the-art methods on the publicly available 30Music dataset.
C1 [Kumar, Chhotelal; Kumar, Mukesh] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna 800005, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Kumar, C (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna 800005, Bihar, India.
EM chhotelalk.phd18.cs@nitp.ac.in; mukesh.kumar@nitp.ac.in
RI Kumar, Mukesh/GNW-5893-2022
OI Kumar, Mukesh/0000-0001-5668-3419; Kumar, Dr.
   Chhotelal/0000-0003-4218-2351
CR Bullinaria JA., 2013, Recurrent neural networks. Neural Comput: Lect, V12, P1
   Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564
   Da'u A, 2020, ARTIF INTELL REV, V53, P2709, DOI 10.1007/s10462-019-09744-1
   Ekstrand Michael D., 2010, Foundations and Trends in Human-Computer Interaction, V4, P81, DOI 10.1561/1100000009
   Hidasi B, 2016, Arxiv, DOI arXiv:1511.06939
   Hidasi B, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P843, DOI 10.1145/3269206.3271761
   Jordan MI, 2015, SCIENCE, V349, P255, DOI 10.1126/science.aaa8415
   Kamehkhosh I, 2017, RECTEMP RECSYS, P50
   Kim P., 2017, MATLAB DEEP LEARNING, P121, DOI DOI 10.1007/978-1-4842-2845-6
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Kumar C, 2023, APPL INTELL, V53, P23147, DOI 10.1007/s10489-023-04679-1
   Kumar C, 2023, MULTIMED TOOLS APPL, V82, P21279, DOI 10.1007/s11042-022-13993-8
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li ZW, 2022, IEEE T NEUR NET LEAR, V33, P6999, DOI 10.1109/TNNLS.2021.3084827
   Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344
   Liu C, 2023, J INTELL INF SYST, V60, P137, DOI 10.1007/s10844-022-00733-5
   Ludewig M, 2021, USER MODEL USER-ADAP, V31, P149, DOI 10.1007/s11257-020-09277-1
   Ludewig M, 2018, USER MODEL USER-ADAP, V28, P331, DOI 10.1007/s11257-018-9209-6
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Pazzani M. J., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P325
   Schafer J. B., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P291
   Shih SY, 2018, Arxiv, DOI arXiv:1809.04214
   Soni S, 2023, APPL INTELL, V53, P14249, DOI 10.1007/s10489-022-04221-9
   Tan Y. K., 2016, Proceedings of the 1st workshop on deep learning for recommender systems, P17
   Tang JX, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P565, DOI 10.1145/3159652.3159656
   Turrin R., 2015, RecSys posters, P75
   Wang N, 2022, WORLD WIDE WEB, V25, P425, DOI 10.1007/s11280-021-00930-2
   Wang SP, 2022, ACTA BIOCH BIOPH SIN, V54, P952, DOI [10.3724/abbs.2022077, 10.1145/3465401]
   Wu S, 2019, AAAI CONF ARTIF INTE, P346
   Yuan FJ, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P582, DOI 10.1145/3289600.3290975
   Zhao W, 2020, IEEE T CYBERNETICS, V50, P4680, DOI 10.1109/TCYB.2019.2896766
   Zhou J, 2020, AI OPEN, V1, P57, DOI 10.1016/j.aiopen.2021.01.001
NR 32
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 5
PY 2023
DI 10.1007/s11042-023-17201-z
EA OCT 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ4I6
UT WOS:001156484900003
DA 2024-07-18
ER

PT J
AU Hussan, M
   Parah, SA
   Qureshi, GJ
AF Hussan, Muzamil
   Parah, Shabir A.
   Qureshi, G. J.
TI Reversible data hiding framework with content authentication capability
   for e-health
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Authentication; Reversibility; Security; e-Healthcare; Tamper Detection
ID IMAGE WATERMARKING; SCHEME
AB Security of data exchanged and authentication of the content received are of paramount importance in the fields like healthcare, defense, the court of law, etc. In this paper, we propose a reversible embedding framework for effectively securing data besides authenticating the content at the receiver. It makes use of a Block-Based Histogram Bin Shifting (BBHBS) mechanism, capable of reversibly embedding the secret data and ensuring its security. To facilitate content authentication and detect any tampering in the received images, we compute Message Authentication Bit Vector (MABV) or Message Authentication Code (MAC) from the Region of Interest (ROI) of the cover image and embed it in the Region of Non-Interest (RONI) of the cover image. The receiver looks out for MABV and based on its value decides the authenticity of the received content. We have tested our scheme for medical as well as general images. The results show that the proposed scheme provides better subjective as well as objective results compared to state-of-art. The average Peak Signal-to-Noise Ratio (PSNR) of the suggested approach for medical images is 51.57 dB for a payload of 0.518 bpp and for general images, it is 51.92 dB for a payload of 0.405 bpp.
C1 [Hussan, Muzamil; Parah, Shabir A.] Univ Kashmir, Dept Elect & Instrumentat Technol, Srinagar, India.
   [Qureshi, G. J.] Higher Educ Dept, Srinagar, J&K, India.
C3 University of Kashmir
RP Parah, SA (corresponding author), Univ Kashmir, Dept Elect & Instrumentat Technol, Srinagar, India.
EM shabireltr@gmail.com
OI Parah, Shabir/0000-0001-5983-0912
FU The authors acknowledge the role of JK Science Technology amp;
   Innovation Council, Department of Science and Technology, Government of
   Jammu and Kashmir, for funding this work under grant number
   JKSTamp;IC/SRE/874-77 [JKSTIC/SRE/874-77]; Department of Science and
   Technology, Government of Jammu and Kashmir
FX The authors acknowledge the role of JK Science Technology & Innovation
   Council, Department of Science and Technology, Government of Jammu and
   Kashmir, for funding this work under grant number JKST&IC/SRE/874-77
CR Abbasi Rashid, 2018, Vietnam Journal of Computer Science, V5, P185, DOI 10.1007/s40595-018-0114-z
   Bhardwaj R, 2019, OPTIK, V181, P1099, DOI 10.1016/j.ijleo.2018.12.130
   Bhatti UA, 2021, MULTIMED TOOLS APPL, V80, P13367, DOI 10.1007/s11042-020-10257-1
   Cao F, 2019, MULTIMED TOOLS APPL, V78, P7911, DOI 10.1007/s11042-018-6031-4
   Fang Y., 2021, INN MED HEALTHC P 9
   Gao XB, 2011, IEEE T CIRC SYST VID, V21, P1061, DOI 10.1109/TCSVT.2011.2130410
   Geetha R., 2020, Journal of Medical Engineering & Technology, V44, P55, DOI 10.1080/03091902.2020.1718223
   Gull S, 2018, Journal of Ambient Intelligence and Humanized Computing, P1
   Gull S, 2020, COMPUT COMMUN, V163, P134, DOI 10.1016/j.comcom.2020.08.023
   Hussan M, 2022, HEALTH TECHNOL-GER, V12, P385, DOI 10.1007/s12553-021-00632-9
   Hussan M, 2019, 2019 FIFTH INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP 2019), P221, DOI 10.1109/ICIIP47207.2019.8985824
   Kelkar V, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/3538979
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Li Y, 2022, LECT NOTES COMPUT SC, V13340, P386, DOI 10.1007/978-3-031-06791-4_31
   Lin CC, 2022, IEEE ACCESS, V10, P18470, DOI 10.1109/ACCESS.2022.3144322
   Liu Wenyi, 2022, Advances in Artificial Intelligence and Security: 8th International Conference on Artificial Intelligence and Security, ICAIS 2022, Proceedings. Communications in Computer and Information Science (1588), P350, DOI 10.1007/978-3-031-06764-8_28
   Lu TC, 2017, MULTIMED TOOLS APPL, V76, P23903, DOI 10.1007/s11042-016-4135-2
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2019, IEEE T CIRC SYST VID, V29, P2176, DOI 10.1109/TCSVT.2018.2859792
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Peng YY, 2018, J INF SECUR APPL, V40, P236, DOI 10.1016/j.jisa.2018.04.007
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Qin JQ, 2019, IEEE SIGNAL PROC LET, V26, P843, DOI 10.1109/LSP.2019.2909080
   Rajkumar R, 2019, CLUSTER COMPUT, V22, P12313, DOI 10.1007/s10586-017-1614-9
   Sajedi H., 2019, Smart Health
   Shaik A, 2021, J KING SAUD UNIV-COM, V33, P878, DOI 10.1016/j.jksuci.2018.06.001
   Vo PH, 2018, MULTIMED TOOLS APPL, V77, P28777, DOI 10.1007/s11042-018-5991-8
   Wang WQ, 2018, SIGNAL PROCESS, V150, P102, DOI 10.1016/j.sigpro.2018.04.008
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Xiang SJ, 2022, IEEE T CIRC SYST VID, V32, P2868, DOI 10.1109/TCSVT.2021.3103215
   Xiliang Xiao, 2021, Innovation in Medicine and Healthcare. Proceedings of 9th KES-InMed 2021. Smart Innovation, Systems and Technologies (SIST 242), P75, DOI 10.1007/978-981-16-3013-2_7
   Xuan GR, 2018, J INF SECUR APPL, V39, P58, DOI 10.1016/j.jisa.2018.01.006
   Yaqoob T, 2020, IEEE J BIOMED HEALTH, V24, P1752, DOI 10.1109/JBHI.2019.2952906
   Zeng C, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03539-5
   Zhang DY, 2018, MULTIMED TOOLS APPL, V77, P11823, DOI 10.1007/s11042-017-4829-0
   Zhang T, 2020, IEEE T INF FOREN SEC, V15, P2306, DOI 10.1109/TIFS.2019.2963766
   Zhang YH, 2018, IEEE INTERNET THINGS, V5, P2130, DOI 10.1109/JIOT.2018.2825289
   Zong TR, 2015, IEEE T CIRC SYST VID, V25, P717, DOI 10.1109/TCSVT.2014.2363743
NR 38
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 29
PY 2023
DI 10.1007/s11042-023-17019-9
EA SEP 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T3XY3
UT WOS:001077361600012
DA 2024-07-18
ER

PT J
AU Shams, MY
   Elshewey, AM
   El-kenawy, EM
   Ibrahim, A
   Talaat, FM
   Tarek, Z
AF Shams, Mahmoud Y.
   Elshewey, Ahmed M.
   El-kenawy, El-Sayed M.
   Ibrahim, Abdelhameed
   Talaat, Fatma M.
   Tarek, Zahraa
TI Water quality prediction using machine learning models based on grid
   search method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Water quality; Machine learning models; Grid search; Water quality
   index; Water quality classification
ID RIVER; IDENTIFICATION; NETWORKS; SYSTEM; INDEX
AB Water quality is very dominant for humans, animals, plants, industries, and the environment. In the last decades, the quality of water has been impacted by contamination and pollution. In this paper, the challenge is to anticipate Water Quality Index (WQI) and Water Quality Classification (WQC), such that WQI is a vital indicator for water validity. In this study, parameters optimization and tuning are utilized to improve the accuracy of several machine learning models, where the machine learning techniques are utilized for the process of predicting WQI and WQC. Grid search is a vital method used for optimizing and tuning the parameters for four classification models and also, for optimizing and tuning the parameters for four regression models. Random forest (RF) model, Extreme Gradient Boosting (Xgboost) model, Gradient Boosting (GB) model, and Adaptive Boosting (AdaBoost) model are used as classification models for predicting WQC. K-nearest neighbor (KNN) regressor model, decision tree (DT) regressor model, support vector regressor (SVR) model, and multi-layer perceptron (MLP) regressor model are used as regression models for predicting WQI. In addition, preprocessing step including, data imputation (mean imputation) and data normalization were performed to fit the data and make it convenient for any further processing. The dataset used in this study includes 7 features and 1991 instances. To examine the efficacy of the classification approaches, five assessment metrics were computed: accuracy, recall, precision, Matthews's Correlation Coefficient (MCC), and F1 score. To assess the effectiveness of the regression models, four assessment metrics were computed: Mean Absolute Error (MAE), Median Absolute Error (MedAE), Mean Square Error (MSE), and coefficient of determination (R2). In terms of classification, the testing findings showed that the GB model produced the best results, with an accuracy of 99.50% when predicting WQC values. According to the experimental results, the MLP regressor model outperformed other models in regression and achieved an R2 value of 99.8% while predicting WQI values.
C1 [Shams, Mahmoud Y.; Talaat, Fatma M.] Kafrelsheikh Univ, Fac Artificial Intelligence, Kafrelsheikh 33516, Egypt.
   [Elshewey, Ahmed M.] Suez Univ, Fac Comp & Informat, Comp Sci Dept, Suez, Egypt.
   [El-kenawy, El-Sayed M.] Delta Higher Inst Engn & Technol, Dept Commun & Elect, Mansoura 35111, Egypt.
   [Ibrahim, Abdelhameed] Mansoura Univ, Fac Engn, Comp Engn & Control Syst Dept, Mansoura 35516, Egypt.
   [Talaat, Fatma M.] New Mansoura Univ, Fac Comp Sci & Engn, Mansoura 35712, Egypt.
   [Tarek, Zahraa] Mansoura Univ, Fac Comp & Informat, Comp Sci Dept, Mansoura 35561, Egypt.
C3 Egyptian Knowledge Bank (EKB); Kafrelsheikh University; Egyptian
   Knowledge Bank (EKB); Suez University; Delta Higher Institute for
   Engineering & Technology; Egyptian Knowledge Bank (EKB); Mansoura
   University; New Mansoura University; Egyptian Knowledge Bank (EKB);
   Mansoura University
RP Shams, MY (corresponding author), Kafrelsheikh Univ, Fac Artificial Intelligence, Kafrelsheikh 33516, Egypt.
EM mahmoud.yasin@ai.kfs.edu.eg; ahmed.elshewey@fci.suezuni.edu.eg;
   skenawy@ieee.org; afai79@mans.edu.eg; fatma.nada@ai.kfs.edu.eg;
   zahraatarek@mans.edu.eg
RI Shams, Mahmoud Y./AAM-9251-2020; El-Kenawy, El-Sayed M./AAQ-3425-2020;
   Elshewey, Ahmed M./KBB-2707-2024; Tarek, Zahraa/ABC-4464-2021; M.
   Talaat, Fatma/IYS-7614-2023; Ibrahim, Abdelhameed/B-3981-2015
OI Shams, Mahmoud Y./0000-0003-3021-5902; El-Kenawy, El-Sayed
   M./0000-0002-9221-7658; Elshewey, Ahmed M./0000-0002-3048-1920; Tarek,
   Zahraa/0000-0001-9389-2850; Ibrahim, Abdelhameed/0000-0002-8352-6731
FU Science, Technology & Innovation Funding Authority (STDF) in
   cooperation; Egyptian Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Abba SI, 2020, ENVIRON SCI POLLUT R, V27, P41524, DOI 10.1007/s11356-020-09689-x
   Al-Adhaileh MH, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13084259
   Aldhyani THH, 2020, APPL BIONICS BIOMECH, V2020, DOI 10.1155/2020/6659314
   Asadollah SBHS, 2021, J ENVIRON CHEM ENG, V9, DOI 10.1016/j.jece.2020.104599
   Beyer K, 1999, LECT NOTES COMPUT SC, V1540, P217
   Bhardwaj D., 2017, INT J ADV RES COMPUT, V8,, P2496
   Biau G, 2012, J MACH LEARN RES, V13, P1063
   Chen H, 2020, AGR WATER MANAGE, V228, DOI 10.1016/j.agwat.2019.105923
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Cheng YJ, 2020, COMPUT IND ENG, V139, DOI 10.1016/j.cie.2019.04.047
   Clark RM., 2011, Protecting Critical Infrastructure, P1, DOI DOI 10.1007/978-1-4614-0189-6
   Deng TN, 2021, J ENVIRON MANAGE, V284, DOI 10.1016/j.jenvman.2021.112051
   Elbeltagi A, 2022, ENVIRON SCI POLLUT R, V29, P17591, DOI 10.1007/s11356-021-17064-7
   Elshewey A., 2023, Computer Systems Science and Engineering, V46, P765, DOI [10.32604/csse.2023.034324, DOI 10.32604/CSSE.2023.034324]
   Elshewey AM, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15010757
   Forests R, 1999, Statistics Department University of California Berkeley, P1
   Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2
   Garabaghi FH, 2021, Res Square, V1, P1, DOI [10.21203/rs.3.rs-876980/v2, DOI 10.21203/RS.3.RS-876980/V2]
   Halim Z, 2020, KNOWL-BASED SYST, V208, DOI 10.1016/j.knosys.2020.106443
   Halim Z, 2020, INFORM FUSION, V53, P66, DOI 10.1016/j.inffus.2019.06.006
   Hassan MM., 2021, Human-Centric Intell Syst, V1, P86, DOI [10.2991/hcis.k.211203.001, DOI 10.2991/HCIS.K.211203.001]
   Hu ZH, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19061420
   Jain Danish, 2021, Proceedings of International Conference on Intelligent Computing, Information and Control Systems. (ICICCS 2020). Advances in Intelligent Systems and Computing (AISC 1272), P619, DOI 10.1007/978-981-15-8443-5_53
   Khan MSI, 2022, J KING SAUD UNIV-COM, V34, P4773, DOI 10.1016/j.jksuci.2021.06.003
   Khoi DN, 2022, WATER-SUI, V14, DOI 10.3390/w14101552
   Khullar S, 2022, ENVIRON SCI POLLUT R, V29, P12875, DOI 10.1007/s11356-021-13875-w
   Lee S, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15071322
   Liao ZM, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12145814
   Liu P, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11072058
   Lu HF, 2020, CHEMOSPHERE, V249, DOI 10.1016/j.chemosphere.2020.126169
   Malek NHA, 2022, WATER-SUI, V14, DOI 10.3390/w14071067
   Nosair AM, 2022, ENVIRON SCI POLLUT R, V29, P9318, DOI 10.1007/s11356-021-16289-w
   Prakash R, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P1501, DOI 10.1109/ICICCT.2018.8473168
   Radhakrishnan N., 2020, P 2020 5 INT C COMM, P1183, DOI DOI 10.1109/ICCES48766.2020.09137903
   Shams MY, 2023, Studies in Big Data, P61, DOI [10.1007/978-3-031, DOI 10.1007/978-3-031]
   Slatnia A, 2022, ONL INT S APPL MATH, V1, P16
   Tarek Z, 2023, CMC-COMPUT MATER CON, V74, P715, DOI 10.32604/cmc.2023.032533
   Tyagi S., 2013, AM J WATER RESOURCES, V1, P34, DOI [DOI 10.12691/AJWR-1-3-3, 10.12691/ajwr-1-3-3]
   Wang S, 2022, J HYDROL, V605, DOI 10.1016/j.jhydrol.2021.127320
   Waqas M, 2022, ARTIF INTELL REV, V55, P5215, DOI 10.1007/s10462-022-10143-2
   Wu JH, 2022, WATER-SUI, V14, DOI 10.3390/w14040610
   Zhou J, 2018, WATER-SUI, V10, DOI 10.3390/w10091148
   Zhou Y, 2020, EXPERT SYST APPL, V162, DOI 10.1016/j.eswa.2020.113864
NR 43
TC 11
Z9 11
U1 12
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 29
PY 2023
DI 10.1007/s11042-023-16737-4
EA SEP 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T3XY3
UT WOS:001077361600026
OA hybrid
DA 2024-07-18
ER

PT J
AU Thakur, N
   Kumar, P
   Kumar, A
AF Thakur, Neha
   Kumar, Pardeep
   Kumar, Amit
TI A systematic review of machine and deep learning techniques for the
   identification and classification of breast cancer through medical image
   modalities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Breast cancer; Machine learning (ML); Deep learning (DL); Medical image
   modalities; Convolutional neural network (CNN)
ID CONVOLUTIONAL NEURAL-NETWORK; AIDED DIAGNOSIS SYSTEM; MASSES; FEATURES;
   MAMMOGRAMS; SEGMENTATION
AB This paper examines and assesses state-of-the-art proposed machine and deep learning techniques for breast cancer identification and classification based on breast screening image modalities. Ten research questions related to the medical image modalities, image dataset, image pre-processing, segmentation and classification techniques are framed to identify the scope of the review. From the perspective of research questions, an extensive review is carried out with various research papers, book chapters published in SCI/Scopus-indexed journals and international conferences from 2010 to 2021. Many issues such as image modalities, segmentation techniques, features, and evaluation metrics are identified with the machine and deep learning methodologies. This review shows that about 57% of the selected studies have used digital mammograms for breast cancer identification and classification. Most of the selected studies have used public datasets and employed noise removal, data augmentation, scaling, and image normalization techniques to alleviate the inconsistencies in breast cancer images. It is observed that mainly thresholding-based, region-based, edge-based, clustering-based, and deep learning (DL) based segmentation techniques are used in many studies. It has also been observed that the support vector machine (SVM) and variants of convolutional neural network (CNN) are the most used classifiers for breast cancer identification and classification. It is found that CNN-based classification models have achieved an accuracy of 100% in the classification of breast cancer for 250 ultrasound images. This review may help researchers to figure out whether a machine or deep learning technique works better on a particular dataset and which features are significant for breast cancer detection. Traditional machine-learning approaches are mostly used in classification, whereas deep-learning techniques have conquered the field of image analysis. This review presents the strengths and weaknesses of the existing machine and deep learning-based models. This review is summarized by providing appropriate answers to the formed research questions with future recommendations in the identification and classification of breast cancer.
   Illustrate the applications of the machine and deep learning techniques in breast cancer detection. Illustrate the medical image modalities used to identify and classify breast cancer. Present the breast image datasets used in the classification models for medical images. Illustrate the image pre-processing, image segmentation, feature extraction techniques and classification algorithms. Provide machine learning techniques for breast cancer identification and classification using various medical image modalities. Provide deep learning techniques for breast cancer identification and classification using various medical image modalities. Identify research gaps and recommendations for the future are proposed.
C1 [Thakur, Neha; Kumar, Pardeep; Kumar, Amit] Jaypee Univ Informat Technol, Dept Comp Sci & Engn, Solan, HP, India.
C3 Jaypee University of Information Technology
RP Kumar, P (corresponding author), Jaypee Univ Informat Technol, Dept Comp Sci & Engn, Solan, HP, India.
EM pardeepkumarkhokhar@gmail.com
OI Kumar, Pardeep/0000-0001-5303-7219
CR Abdel-Nasser M, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8010100
   Abdel-Nasser M, 2017, ENG APPL ARTIF INTEL, V59, P84, DOI 10.1016/j.engappai.2016.12.019
   Acharya UR, 2012, J MED SYST, V36, P1503, DOI 10.1007/s10916-010-9611-z
   Al-antari MA, 2018, INT J MED INFORM, V117, P44, DOI 10.1016/j.ijmedinf.2018.06.003
   Alzu'bi A, 2021, MULTIMED TOOLS APPL, V80, P13787, DOI 10.1007/s11042-020-10448-w
   Aminikhanghahi S, 2017, MULTIMED TOOLS APPL, V76, P10191, DOI 10.1007/s11042-016-3605-x
   [Anonymous], 2002, AJCC cancer staging manual, P223, DOI [10.1007/978-1-4757-3656-4, DOI 10.1007/978-1-4757-3656-4]
   Arefan D, 2020, MED PHYS, V47, P110, DOI 10.1002/mp.13886
   Arevalo J, 2016, COMPUT METH PROG BIO, V127, P248, DOI 10.1016/j.cmpb.2015.12.014
   Azizi N, 2014, INT CONF MULTIMED, P415, DOI 10.1109/ICMCS.2014.6911285
   Basile TMA, 2019, PHYS MEDICA, V64, P1, DOI 10.1016/j.ejmp.2019.05.022
   Beheshti SMA, 2014, J DIGIT IMAGING, V27, P661, DOI 10.1007/s10278-013-9654-z
   Bhogal Rosepreet Kaur, 2021, Proceedings of the 5th International Conference on Trends in Electronics and Informatics (ICOEI 2021), P847, DOI 10.1109/ICOEI51242.2021.9452835
   Braithwaite J., 1895, Lancet, V145, P1636, DOI [10.1016/S0140-6736(00)79809-6, DOI 10.1016/S0140-6736(00)79809-6]
   Burt JR, 2018, BRIT J RADIOL, V91, DOI 10.1259/bjr.20170545
   Caballo M, 2020, COMPUT BIOL MED, V118, DOI 10.1016/j.compbiomed.2020.103629
   Cai HM, 2019, COMPUT MATH METHOD M, V2019, DOI 10.1155/2019/2717454
   Chan HP, 2020, BRIT J RADIOL, V93, DOI 10.1259/bjr.20190580
   CHANG CHJ, 1980, CANCER, V46, P939, DOI 10.1002/1097-0142(19800815)46:4+<939::AID-CNCR2820461315>3.0.CO;2-L
   Charan Saira, 2018, 2018 International Conference on Computing, Mathematics and Engineering Technologies (iCoMET). Proceedings, DOI 10.1109/ICOMET.2018.8346384
   Chouhan N, 2021, COMPUT BIOL MED, V132, DOI 10.1016/j.compbiomed.2021.104318
   Chugh G, 2021, COGN COMPUT, V13, P1451, DOI 10.1007/s12559-020-09813-6
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Conte L, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10176109
   Dhahbi S, 2015, COMPUT BIOL MED, V64, P79, DOI 10.1016/j.compbiomed.2015.06.012
   Dheeba J., 2011, 2011 Proceedings of International Conference on Emerging Trends in Electrical and Computer Technology (ICETECT 2011), P686, DOI 10.1109/ICETECT.2011.5760205
   Diaz RAN, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON CYBERNETICS AND INTELLIGENT SYSTEM (ICORIS), P233, DOI [10.1109/ICORIS.2019.8874873, 10.1109/icoris.2019.8874873]
   do Nascimento MZ, 2013, EXPERT SYST APPL, V40, P6213, DOI 10.1016/j.eswa.2013.04.036
   Duggento A, 2019, CONTRAST MEDIA MOL I, DOI 10.1155/2019/5982834
   Ertosun MG, 2015, IEEE INT C BIOINFORM, P1310, DOI 10.1109/BIBM.2015.7359868
   Fraioli F, 2010, RADIOL MED, V115, P385, DOI 10.1007/s11547-010-0507-2
   Francis SV, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0023-3
   Frazer HML, 2021, J MED IMAG RADIAT ON, V65, P529, DOI 10.1111/1754-9485.13278
   Ganggayah MD, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0801-4
   Gayathri BK, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING TECHNOLOGIES AND INTELLIGENT DATA ENGINEERING (ICCTIDE'16)
   Gedik N, 2013, TURK J ELECTR ENG CO, V21, P1002, DOI 10.3906/elk-1201-8
   Gennaro G, 2010, EUR RADIOL, V20, P1545, DOI 10.1007/s00330-009-1699-5
   Gilbert FJ, 2019, IDKD SPR SER, P155, DOI 10.1007/978-3-030-11149-6_13
   Guan S, 2017, 2017 IEEE APPL IM PA, P1, DOI [DOI 10.1109/AIPR.2017.8457948, 10.1109/AIPR.2017.8457948]
   HALL EL, 1971, IEEE T COMPUT, VC 20, P1032, DOI 10.1109/T-C.1971.223399
   Haskins G, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01060-x
   He SM, 2018, INT SYM COMPUT INTEL, P3, DOI 10.1109/ISCID.2018.00007
   Heath M, 1998, COMP IMAG VIS, V13, P457
   Heenaye-Mamode Khan M, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0256500
   Heidari M, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aaa1ca
   Houssein EH, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114161
   Huang QH, 2015, INFORM SCIENCES, V314, P293, DOI 10.1016/j.ins.2014.08.021
   Ibraheem A.M., 2019, 2019 NOV INT LEAD EM, V1, P88, DOI 10.1109/NILES.2019.8909345
   Iranmakani S, 2020, EGYPT J RADIOL NUC M, V51, DOI 10.1186/s43055-020-00175-5
   Jiao ZC, 2016, NEUROCOMPUTING, V197, P221, DOI 10.1016/j.neucom.2016.02.060
   Jongwon Chang, 2017, 2017 IEEE 19th International Conference on e-Health Networking, Applications and Services (Healthcom), P1, DOI 10.1109/HealthCom.2017.8210843
   Král P, 2016, IEEE IMAGE PROC, P2643, DOI 10.1109/ICIP.2016.7532838
   Lee RS, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.177
   Li B, 2018, PROCEEDINGS OF 2018 10TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING (ICMLC 2018), P247, DOI 10.1145/3195106.3195163
   Li CI, 2003, JAMA-J AM MED ASSOC, V289, P1421, DOI 10.1001/jama.289.11.1421
   Li P, 2014, BIO-MED MATER ENG, V24, P3397, DOI 10.3233/BME-141163
   Liu XM, 2015, NEUROCOMPUTING, V152, P388, DOI 10.1016/j.neucom.2014.10.040
   Lopez Pinaya W. H., 2020, MACH LEARN, P173, DOI [DOI 10.1016/B978-0-12-815739-8.00010-9, 10.1016/B978-0-12-815739-8.00010-9]
   Lu W, 2017, COMPUT BIOL MED, V83, P157, DOI 10.1016/j.compbiomed.2017.03.002
   Luo ST, 2012, J MED SYST, V36, P569, DOI 10.1007/s10916-010-9518-8
   Mahmood T, 2020, IEEE ACCESS, V8, P165779, DOI 10.1109/ACCESS.2020.3021343
   Masud M, 2021, ACM T INTERNET TECHN, V21, DOI 10.1145/3418355
   McKinney SM, 2020, NATURE, V577, P89, DOI 10.1038/s41586-019-1799-6
   Meyer Charles R, 2015, TCIA, V1, DOI 10.7937/K9/TCIA.2015.H1SXNUXL
   Moon WK, 2017, ULTRASONICS, V76, P70, DOI 10.1016/j.ultras.2016.12.017
   Moreira IC, 2012, ACAD RADIOL, V19, P236, DOI 10.1016/j.acra.2011.09.014
   Murtaza G, 2020, ARTIF INTELL REV, V53, P1655, DOI 10.1007/s10462-019-09716-5
   Niwas SI, 2012, J MED SYST, V36, P3091, DOI 10.1007/s10916-011-9788-9
   Oliveira JEE, 2008, PROC SPIE, V6915, DOI 10.1117/12.770325
   Pak F, 2015, COMPUT METH PROG BIO, V122, P89, DOI 10.1016/j.cmpb.2015.06.009
   Park YH, 2011, ANN ONCOL, V22, P1554, DOI 10.1093/annonc/mdq617
   Peng W, 2016, COMPUT METH PROG BIO, V125, P134, DOI 10.1016/j.cmpb.2015.09.019
   Platania R, 2017, ACM-BCB' 2017: PROCEEDINGS OF THE 8TH ACM INTERNATIONAL CONFERENCE ON BIOINFORMATICS, COMPUTATIONAL BIOLOGY,AND HEALTH INFORMATICS, P536, DOI 10.1145/3107411.3107484
   Prabusankarlal KM, 2015, HUM-CENT COMPUT INFO, V5, DOI 10.1186/s13673-015-0029-y
   Ragab DA, 2019, PEERJ, V7, DOI 10.7717/peerj.6201
   Ramos-Pollán R, 2012, J MED SYST, V36, P2259, DOI 10.1007/s10916-011-9693-2
   Raza S, 2010, RADIOGRAPHICS, V30, P1199, DOI 10.1148/rg.305095144
   Rouhi R, 2016, EXPERT SYST APPL, V46, P45, DOI 10.1016/j.eswa.2015.10.011
   Sanae B., 2014, 2014 9 INT C INT SYS, P1, DOI DOI 10.1109/SITA.2014.6847307
   Sánchez-Cauce R, 2021, COMPUT METH PROG BIO, V204, DOI 10.1016/j.cmpb.2021.106045
   Schnitt SJ, 2010, MODERN PATHOL, V23, pS60, DOI 10.1038/modpathol.2010.33
   Senan EM, 2021, J APPL SCI ENG, V24, P323, DOI 10.6180/jase.202106_24(3).0007
   Shan J., 2008, 2008 19 INT C PATT R, P1, DOI DOI 10.1109/ICPR.2008.4761336
   Sharma GN, 2010, J ADV PHARM TECHNOL, V1, P109
   Sharma Jaya, 2014, 2014 International Conference on Medical Imaging, m-Health and Emerging Communication Systems (MedCom), P115, DOI 10.1109/MedCom.2014.7005987
   Sharma S, 2020, J DIGIT IMAGING, V33, P632, DOI 10.1007/s10278-019-00307-y
   Shibusawa M, 2016, J MED ULTRASON, V43, P387, DOI 10.1007/s10396-016-0718-9
   Silva JD, 2015, J DIGIT IMAGING, V28, P323, DOI 10.1007/s10278-014-9739-3
   Singh Shiksha, 2020, 2020 7th International Conference on Signal Processing and Integrated Networks (SPIN), P498, DOI 10.1109/SPIN48934.2020.9071218
   Soliman OO, 2018, CAIRO INT BIOM ENG, P110, DOI 10.1109/CIBEC.2018.8641807
   SUCKLING J, 1994, INT CONGR SER, V1069, P375
   Sun WQ, 2016, COMPUT METH PROG BIO, V135, P77, DOI 10.1016/j.cmpb.2016.07.017
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660
   Suzuki S, 2016, 2016 55TH ANNUAL CONFERENCE OF THE SOCIETY OF INSTRUMENT AND CONTROL ENGINEERS OF JAPAN (SICE), P1382, DOI 10.1109/SICE.2016.7749265
   Tan MX, 2014, INT J COMPUT ASS RAD, V9, P1005, DOI 10.1007/s11548-014-0992-1
   Tan T, 2013, IEEE T MED IMAGING, V32, P1698, DOI 10.1109/TMI.2013.2263389
   Tariq M, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114095
   Taylor L, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P1542, DOI 10.1109/SSCI.2018.8628742
   Tembhurne JV, 2021, MULTIMED TOOLS APPL, V80, P31647, DOI 10.1007/s11042-021-11199-y
   Vijayarajeswari R, 2019, MEASUREMENT, V146, P800, DOI 10.1016/j.measurement.2019.05.083
   Wu N, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6682, DOI 10.1109/ICASSP.2018.8462671
   Wu WJ, 2015, J DIGIT IMAGING, V28, P576, DOI 10.1007/s10278-014-9757-1
   Yadav A, 2021, 2021 6TH INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT), DOI 10.1109/I2CT51068.2021.9417996
   Yassin NIR, 2018, COMPUT METH PROG BIO, V156, P25, DOI 10.1016/j.cmpb.2017.12.012
   Yemini M, 2019, IEEE GLOB COMM CONF, DOI 10.1109/globecom38437.2019.9014051
   Yuan YD, 2010, ACAD RADIOL, V17, P1158, DOI 10.1016/j.acra.2010.04.015
   Zakeri FS, 2012, J MED SYST, V36, P1621, DOI 10.1007/s10916-010-9624-7
   Zheng YF, 2010, ALGORITHMS, V3, P44, DOI 10.3390/a3010044
NR 108
TC 0
Z9 0
U1 5
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 28
PY 2023
DI 10.1007/s11042-023-16634-w
EA SEP 2023
PG 94
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM7
UT WOS:001076639200017
DA 2024-07-18
ER

PT J
AU Goud, PS
   Sastry, PN
   Sekhar, PC
AF Goud, P. Satyanarayana
   Sastry, Panyam Narahari
   Sekhar, P. Chandra
TI A novel intelligent deep optimized framework for heart disease
   prediction and classification using ECG signals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Heart disease classification; Grey wolf algorithm; Generative
   adversarial network; Arrhythmia; Heart failure
AB The advancement in medical diagnosis approaches increases the demand for effective disease prediction and classification system. Although, various machine learning (ML) based disease classification techniques were developed, they face severe issues. Hence, a novel optimized framework named as Wolf based Generative Adversarial System (WbGAS) system was designed to predict and specify the heart disease using Electrocardiogram (ECG) database. The collected dataset contains three classes namely Normal Sinus Rhythm (NSR), Arrhythmia (ARR), and Congestive Heart Failure (CHF). The dataset is initialized and trained using the proposed (WbGAS) approach to predict the normal and abnormal signals present in dataset. In addition, the integration of wolf fitness function in the presented approach provides finest prediction rate. Moreover, the type of heart disease is specified based on the trained features. Also, a case study was presented with three different cases to explain the functioning of designed (WbGAS) approach. The designed model is implemented in MATLAB software and then, the performance of the system is determined as specificity, recall, accuracy, and precision value. At the end, to verify the results of the developed technique a comparative assessment was performed by comparing the outcomes of presented approach with existing ML based approaches.
C1 [Goud, P. Satyanarayana] G Narayanamma Inst Technol & Sci for Women, Fac Elect & Commun Engn, Hyderabad 500104, Telangana, India.
   [Sastry, Panyam Narahari] Chaitanya Bharathi Inst Technol CBIT, Dept Elect & Commun Engn, Hyderabad 500075, Telangana, India.
   [Sekhar, P. Chandra] Osmania Univ, Dept Elect & Commun Engn, Hyderabad 500007, Andhra Pradesh, India.
C3 Chaitanya Bharathi Institute of Technology; Osmania University
RP Goud, PS (corresponding author), G Narayanamma Inst Technol & Sci for Women, Fac Elect & Commun Engn, Hyderabad 500104, Telangana, India.
EM satyanarayanagoudp@gmail.com; naraharisastry_ece@cbit.ac.in;
   sekharpaidimarry@gmail.com
CR Al-Zuhairi DT, 2022, SIGNAL IMAGE VIDEO P, V16, P1489, DOI 10.1007/s11760-021-02102-1
   Chen JM, 2019, IEEE ACCESS, V7, P120831, DOI 10.1109/ACCESS.2019.2937875
   Cheng JY, 2021, BMC MED INFORM DECIS, V21, DOI 10.1186/s12911-021-01736-y
   Dai H, 2021, COMPUT METH PROG BIO, V203, DOI 10.1016/j.cmpb.2021.106035
   Dami S, 2021, NEURAL COMPUT APPL, V33, P7979, DOI 10.1007/s00521-020-05542-x
   Dixit S, 2021, MULTIMED TOOLS APPL, V80, P32615, DOI 10.1007/s11042-021-11083-9
   Fradi M, 2022, MULTIMED TOOLS APPL, V81, P41711, DOI 10.1007/s11042-021-11268-2
   Gupta VK, 2021, BIG DATA MIN ANAL, V4, P116, DOI 10.26599/BDMA.2020.9020016
   Hammad M, 2021, INFORM SCIENCES, V571, P580, DOI 10.1016/j.ins.2021.05.035
   Hullender DA, 2021, COMPUT METH PROG BIO, V198, DOI 10.1016/j.cmpb.2020.105768
   Ibtehaz N, 2019, BIOMED SIGNAL PROCES, V49, P349, DOI 10.1016/j.bspc.2018.12.016
   Jahmunah V, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104457
   Jha CK, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101875
   Kania M, 2019, ANN BIOMED ENG, V47, P1300, DOI 10.1007/s10439-019-02231-2
   Kariya T, 2020, ANN BIOMED ENG, V48, P1740, DOI 10.1007/s10439-020-02488-y
   Kaur S, 2020, IEEE ACCESS, V8, P228049, DOI 10.1109/ACCESS.2020.3042273
   Khan MA, 2020, IEEE ACCESS, V8, P34717, DOI 10.1109/ACCESS.2020.2974687
   Li GX, 2022, BIOMED SIGNAL PROCES, V75, DOI 10.1016/j.bspc.2022.103607
   Li WQ, 2022, INFORM SCIENCES, V589, P738, DOI 10.1016/j.ins.2021.12.083
   Li YR, 2022, BIOMED SIGNAL PROCES, V72, DOI 10.1016/j.bspc.2021.103344
   Linlin Tu, 2020, Smart Health, DOI 10.1016/j.smhl.2019.100090
   Lopes RR, 2021, COMPUT BIOL MED, V131, DOI 10.1016/j.compbiomed.2021.104262
   Panda R, 2020, COMPUT BIOL MED, V124, DOI 10.1016/j.compbiomed.2020.103939
   Park J, 2022, ANN BIOMED ENG, V50, P111, DOI 10.1007/s10439-022-02902-7
   Peimankar A, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113911
   Poongodi T., 2020, Principles of Internet of Things (IoT) Ecosystem: Insight Paradigm, P127, DOI DOI 10.1007/978-3-030-33596-0_5
   Saini SK, 2022, ARTIF INTELL REV, V55, P1519, DOI 10.1007/s10462-021-09999-7
   Sárközy M, 2021, CLIN RES CARDIOL, V110, P507, DOI 10.1007/s00392-021-01809-y
   Sathiyabhama B, 2021, NEURAL COMPUT APPL, V33, P14583, DOI 10.1007/s00521-021-06099-z
   Sharma P, 2021, NEURAL COMPUT APPL, V33, P13123, DOI 10.1007/s00521-021-06005-7
   Sun ZQ, 2022, MULTIMED TOOLS APPL, V81, P13467, DOI 10.1007/s11042-021-11523-6
   Tyagi A, 2021, SN APPL SCI, V3, DOI 10.1007/s42452-021-04185-4
   Venkataramanaiah B, 2020, SOFT COMPUT, V24, P17457, DOI 10.1007/s00500-020-05191-1
   Wasimuddin M, 2020, IEEE ACCESS, V8, P177782, DOI 10.1109/ACCESS.2020.3026968
   Zunic E, 2019, PROCEEDINGS OF 18TH INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES (IEEE EUROCON 2019), DOI 10.1109/eurocon.2019.8861619
NR 35
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 27
PY 2023
DI 10.1007/s11042-023-16850-4
EA SEP 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T1YW6
UT WOS:001076019000002
DA 2024-07-18
ER

PT J
AU Sarathkumar, M
   Dhanalakshmi, KS
AF Sarathkumar, M.
   Dhanalakshmi, K. S.
TI CBGAT: an efficient breast cancer prediction model using deep learning
   methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Convolution neural network; VGG-16; Breast cancer prediction; Gated
   recurrent unit; Bidirectional long-short term memory; Attention
   mechanism; MIAS; CBIS-DDSM
AB In recent years, breast cancer is observed to be more prevalent among women. Timely and accurate prediction of the disease enables health care professionals to adopt a strong decision-making system in treatment optimization. Thus, this study employed a deep learning-based strategy for efficient breast cancer diagnosis. In this study, the feature extraction is efficiently performed with the Deep CNN and VGG-16 and the classification process has been processed that intends to classify appropriate features by using the newly introduced CBGAT (CNN-Bi-LSTM-GRU-AM) technique that helps to enhance the accuracy of image recognition and to predict the breast cancer without any human intervention. The complete approach uses MIAS and the CBIS-DDSM dataset for the process of training and for the evaluations. The proposed study aims in minimising the cases of human intervention of breast cancer diagnosis. The approach DL architectures comprising both the Deep CNN and VCG-16, for the process of feature extraction from the breast cancer diagnosis. Further, the proposed approach is embedded with the PCA in enhancing the procedures of feature extraction. This PCA is used in the proposed study as a fusion technique. PCA is used as one of a dimensionality reduction technique, used in capturing the more of exact information from the features. The combination of CNN-Bi-LSTM-GRU-AM classification approach used in the study is considered in analysing the sequential information and in capturing the long-term dependencies also used in focusing the salient features. The Deep-CNN and VCG-16 are incorporated for leveraging the strengths of each of the network, and are used in capturing the range of features. This integration aids in enhancing the representation and the discriminative power of the extracted features. Influencing the use of AM in the classification process is one more an added advantage of the proposed approach. This AM allows the model to be focused on the vita regions of features within the images provided as input.The experimental implementation and performance analysis of the proposed system is undertaken. The accuracy of each proposed classification technique is discussed with respect to their dataset. The analytical outcomes explore that the proposed model is more effective than the traditional methods as the proposed model highlights a higher accuracy rate, F1 score, sensitivity, specificity, and Area under the curve (AUC). The proposed also determined the importance of breast cancer prediction.
C1 [Sarathkumar, M.] Madurai Kamaraj Univ, Univ Sci Instrumentat Ctr USIC, Madurai, Tamil Nadu, India.
   [Dhanalakshmi, K. S.] Kalasalingam Acad Res & Educ, Dept Elect & Commun Engn, Krishnankoil, Virudhunagar, India.
C3 Madurai Kamaraj University; Kalasalingam Academy of Research & Education
RP Sarathkumar, M (corresponding author), Madurai Kamaraj Univ, Univ Sci Instrumentat Ctr USIC, Madurai, Tamil Nadu, India.
EM msksarathkumar01@gmail.com
OI , Sarathkumar/0009-0007-1666-1929
CR Akram M, 2017, BIOL RES, V50, DOI 10.1186/s40659-017-0140-9
   Bardou D, 2018, IEEE ACCESS, V6, P24680, DOI 10.1109/ACCESS.2018.2831280
   Barman UD, 2020, NETW MODEL ANAL HLTH, V9, DOI 10.1007/s13721-020-00234-x
   Budak Ü, 2019, APPL SOFT COMPUT, V85, DOI 10.1016/j.asoc.2019.105765
   Burçak KC, 2021, J SUPERCOMPUT, V77, P973, DOI 10.1007/s11227-020-03321-y
   Chakravarthy SRS, 2023, IETE J RES, V69, P7326, DOI 10.1080/03772063.2022.2028584
   Dabeer S., 2019, Inform Med Unlocked, V16, P100231, DOI DOI 10.1016/J.IMU.2019.100231
   Ed-daoudy A, 2020, NETW MODEL ANAL HLTH, V9, DOI 10.1007/s13721-020-00237-8
   Falconi L.G., 2020, Adv. Sci. Technol. Eng. Syst. J, V5, P154, DOI DOI 10.25046/AJ050220
   Fatima N, 2020, IEEE ACCESS, V8, P150360, DOI 10.1109/ACCESS.2020.3016715
   Gao S, 2020, BIOMED ENG ONLINE, V19, DOI 10.1186/s12938-020-0747-x
   Gour M, 2020, INT J IMAG SYST TECH, V30, P621, DOI 10.1002/ima.22403
   Gupta K, 2020, PROCEDIA COMPUT SCI, V167, P878, DOI 10.1016/j.procs.2020.03.427
   Hosseinzadeh M, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02579-7
   Idowu IR, 2021, Prediction of breast Cancer images classification using bidirectional long short term memory and two-dimensional convolutional neural network
   Jahangeer GSB, 2021, MULTIMED TOOLS APPL, V80, P7853, DOI 10.1007/s11042-020-09914-2
   Khan S, 2019, PATTERN RECOGN LETT, V125, P1, DOI 10.1016/j.patrec.2019.03.022
   Krishnan S., 2021, Int J Electr Comput Eng, V11, P2088
   Malebary SJ, 2021, IEEE ACCESS, V9, P55312, DOI 10.1109/ACCESS.2021.3071297
   Navamani TM, 2019, DEEP LEARNING AND PARALLEL COMPUTING ENVIRONMENT FOR BIOENGINEERING SYSTEMS, P123, DOI 10.1016/B978-0-12-816718-2.00014-2
   Le NQK, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2972-5
   Qin Y, 2021, IEEE T IND INFORM, V17, P6438, DOI 10.1109/TII.2020.2999442
   Ragab DA, 2021, COMPUT BIOL MED, V131, DOI 10.1016/j.compbiomed.2021.104245
   Rahmani AM, 2021, CLUSTER COMPUT, V24, P1347, DOI 10.1007/s10586-020-03189-w
   Roslidar Roslidar, 2019, 2019 IEEE International Conference on Cybernetics and Computational Intelligence (CyberneticsCom). Proceedings, P77, DOI 10.1109/CYBERNETICSCOM.2019.8875661
   Shahrior A, 2022, J King Saud Univ-Comput Inf Sci
   Sharma S, 2022, ICT EXPRESS, V8, P101, DOI 10.1016/j.icte.2021.11.010
   Sinha A, 2021, IEEE J BIOMED HEALTH, V25, P121, DOI 10.1109/JBHI.2020.2986926
   Sun DD, 2019, IEEE ACM T COMPUT BI, V16, P841, DOI 10.1109/TCBB.2018.2806438
   Tembhurne JV, 2021, MULTIMED TOOLS APPL, V80, P31647, DOI 10.1007/s11042-021-11199-y
   Tiwari Monika., 2020, Breast cancer prediction using deep learning and machine learning techniques
   Wollmann T, 2019, MED IMAGE ANAL, V56, P68, DOI 10.1016/j.media.2019.04.011
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850932
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850945
   Yang SM, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040455
   Yang Yang, 2019, 2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). Proceedings, P1141, DOI 10.1109/BIBM47256.2019.8983378
   Yao HD, 2019, CANCERS, V11, DOI 10.3390/cancers11121901
   Zainudin Zanariah, 2020, International Conference on Advanced Machine Learning Technologies and Applications (AMLTA2019). Advances in Intelligent Systems and Computing (AISC 921), P43, DOI 10.1007/978-3-030-14118-9_5
   Zhang DJ, 2018, IEEE ACCESS, V6, P28936, DOI 10.1109/ACCESS.2018.2837654
   Zhang HB, 2020, INFORM SCIENCES, V539, P461, DOI 10.1016/j.ins.2020.05.080
   Zhang Q, 2020, J Healthcare Eng, V2020
   Zuluaga-Gomez J, 2021, COMP M BIO BIO E-IV, V9, P131, DOI 10.1080/21681163.2020.1824685
NR 42
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 26
PY 2023
DI 10.1007/s11042-023-16640-y
EA SEP 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA S8YJ1
UT WOS:001073965700003
DA 2024-07-18
ER

PT J
AU Hu, JY
   Xue, R
   Teng, GF
   Niu, SM
   Jin, DY
AF Hu, Jingyun
   Xue, Ru
   Teng, Guofeng
   Niu, Shiming
   Jin, Danyang
TI Image splicing manipulation location by multi-scale dual-channel
   supervision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image manipulation detection; Image splicing; Attention mechanism;
   Pyramid module
ID FORGERIES; NETWORK
AB The swift growth of diverse editing software has resulted in image splicing manipulation becoming more complex, the discovery of a meticulously crafted splice forgery in digital images poses a significant challenge for both humans and machines. Existing image splicing manipulation detection algorithms have low localization accuracy and poor detection of small manipulation areas. In this paper, we proposed an end-to-end effective image manipulation location method based on a multi-scale and dual-channel model, MD_Unet. First, a dual-channel encoding network model is constructed. Adding a high-pass filtering branch containing SRM filters and Gabor filters at the input of the model and helps it to learn the manipulation traces of the image. Secondly, the dual-channel features are fused using an improved multi-scale pyramid pooling module. Then, Squeeze-Excitation is introduced to recalibrate the fused features so that the network pays more attention to splicing manipulation-related features. Finally, the fused feature map is input to the decoder, and the predicted image is decoded layer by layer to segment the manipulation region. We have performed extensive experimental validation and powerfully demonstrate the efficacy of the proposed approach.
C1 [Hu, Jingyun; Xue, Ru; Teng, Guofeng; Niu, Shiming; Jin, Danyang] Xizang Minzu Univ, Sch Informat Engn, Xianyang 712082, Shaanxi, Peoples R China.
C3 Xizang Minzu University
RP Xue, R (corresponding author), Xizang Minzu Univ, Sch Informat Engn, Xianyang 712082, Shaanxi, Peoples R China.
EM rxue@xzmu.edu.cn
FU major programs incubation plan
FX This work was supported by major programs incubation plan of Xizang
   Minzu University: 22MDZ03 and key project of the Natural Science
   Foundation of the Tibet Autonomous Region: image forgery detection and
   location based on multi semantics and attention: XZ202301ZR0042G.
CR Bahrami K, 2015, IEEE T INF FOREN SEC, V10, P999, DOI 10.1109/TIFS.2015.2394231
   Bappy JH, 2017, IEEE I CONF COMP VIS, P4980, DOI 10.1109/ICCV.2017.532
   Bayar B, 2018, IEEE T INF FOREN SEC, V13, P2691, DOI 10.1109/TIFS.2018.2825953
   Bi X, 2019, 2019 IEEE CVF C COMP
   Bi XL, 2019, IEEE COMPUT SOC CONF, P30, DOI 10.1109/CVPRW.2019.00010
   Bi Y, 2019, IEEE GLOB COMM CONF
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Bin Li, 2018, IEEE Signal Processing Letters, V25, P650, DOI 10.1109/LSP.2018.2816569
   Cao G, 2019, MATH BIOSCI ENG, V16, P5022, DOI 10.3934/mbe.2019253
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen Xinru, 2021, ICCV, P14185
   Cozzolino D, 2015, IEEE INT WORKS INFOR
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   Ding HW, 2023, NEURAL COMPUT APPL, V35, P5015, DOI 10.1007/s00521-021-06329-4
   Dirik AE, 2009, IEEE IMAGE PROC, P1497, DOI 10.1109/ICIP.2009.5414611
   Farid H, 2008, TR2008638 DARTM COLL, P1
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gabor D., 1946, Journal of the Institution of Electrical Engineers-part III: radio and communication engineering, V93, P429, DOI [DOI 10.1049/JI-3-2.1946.0074, 10.1049/ji-3-2.1946.0074]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hsu YF, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P549, DOI 10.1109/ICME.2006.262447
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu WC, 2015, DIGIT SIGNAL PROCESS, V39, P50, DOI 10.1016/j.dsp.2015.01.006
   Huh M, 2018, LECT NOTES COMPUT SC, V11215, P106, DOI 10.1007/978-3-030-01252-6_7
   Iakovidou C, 2018, J VIS COMMUN IMAGE R, V54, P155, DOI 10.1016/j.jvcir.2018.05.011
   Jie H, 2017, IEEE Trans Pattern Anal Mach Intell PP, VPP, P1
   Jing Dong, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P422, DOI 10.1109/ChinaSIP.2013.6625374
   Kakar P, 2011, IEEE T MULTIMEDIA, V13, P443, DOI 10.1109/TMM.2011.2121056
   Kong C, 2019, IEEE INT C ELECTR TA, DOI 10.1109/icce-tw46550.2019.8991905
   Lee JC, 2015, INFORM SCIENCES, V321, P250, DOI 10.1016/j.ins.2015.03.009
   Liu GJ, 2013, MATH COMPUT MODEL, V57, P2647, DOI 10.1016/j.mcm.2011.06.026
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P3948, DOI 10.1109/TSP.2005.855406
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rosa LD., 2022, ARTIF INTELL MED IMA, V3, P13
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Salloum R, 2018, J VIS COMMUN IMAGE R, V51, P201, DOI 10.1016/j.jvcir.2018.01.010
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang B, 2021, J PHYS C SER, V2010
   Wu Y, 2019, PROC CVPR IEEE, P9535, DOI 10.1109/CVPR.2019.00977
   Xiao B, 2020, INFORM SCIENCES, V511, P172, DOI 10.1016/j.ins.2019.09.038
   Yang Y, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2109.06094
   Yedroudj M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2092, DOI 10.1109/ICASSP.2018.8461438
   Zampoglou M, 2017, MULTIMED TOOLS APPL, V76, P4801, DOI 10.1007/s11042-016-3795-2
   Zeng H, 2017, MULTIMED TOOLS APPL, V76, P4783, DOI 10.1007/s11042-016-3712-8
   Zhang RY, 2020, INT CONF ACOUST SPEE, P2982, DOI [10.1109/icassp40776.2020.9054068, 10.1109/ICASSP40776.2020.9054068]
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
NR 50
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 31759
EP 31782
DI 10.1007/s11042-023-16705-y
EA SEP 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069156900004
DA 2024-07-18
ER

PT J
AU Kumar, KV
   Sathish, A
AF Kumar, Kanike Vijay
   Sathish, Anchula
TI Medical image fusion based on type-2 fuzzy sets with teaching learning
   based optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; Diagnosis; Fuzzy sets; Type-2 fuzzy sets; Spatial
   frequency
ID WAVELET TRANSFORM; RECOGNITION; SCHEMES; DESIGN; IHS
AB The main objective of image fusion for multimodal medical images is to retrieve valuable information by combining multiple images obtained from various sources into a single image suitable for better diagnosis. In general, the visibility of structural details in medical images is difficult to interpret. The vast majority of the best in class image fusing systems are based on non-fuzzy sets, and the fused image so obtained lags with complementary information. Soft computing techniques like fuzzy sets have been applied to enhance the medical images and to extract the visibility features from the images. Fuzzy sets are strong-minded to be more appropriate for medical image processing as more hesitations are considered compared with non-fuzzy sets. Type-2 fuzzy sets are used in this work. Type-2 fuzzy sets are the fuzzy sets for which the membership function is not a single value for every element but an interval. In this paper, a procedure for efficiently fusing multimodal medical images is presented. In the proposed method, images are initially converted into Type-2 fuzzy images. Next, the enhanced images are decomposed into blocks and the blocks are compared using fitness function, contrast visibility (CV). Then, a decision map (DM) is built by taking the decision for each coefficient using the contrast visibility of the respective block. Then, teaching learning based optimization (TLBO) is introduced to optimize combination factors that change under teaching phase, and learner phase of TLBO. Finally, the fused image is achieved using optimal coefficients. Simulations on several pairs of multimodal medical images are performed and matched with the current fusion approaches. The dominance of the proposed technique is presented and is justified. Fused image quality is also verified with various quality metrics, such as peak signal to noise ratio (PSNR), universal quality index (UQI), structural similarity (SSIM), correlation coefficient (CC), entropy (E), spatial frequency (SF), edge information preservation (QAB/F) and standard deviation (SD).
C1 [Kumar, Kanike Vijay] Jawaharlal Nehru Technol Univ Anantapur, Ananthapuramu, Andhra Pradesh, India.
   [Sathish, Anchula] Jawaharlal Nehru Technol Univ Anantapur, Rajeev Gandhi Mem Coll Engn & Technol, Ananthapuramu, Andhra Pradesh, India.
C3 Jawaharlal Nehru Technological University - Anantapur; Jawaharlal Nehru
   Technological University - Anantapur
RP Kumar, KV (corresponding author), Jawaharlal Nehru Technol Univ Anantapur, Ananthapuramu, Andhra Pradesh, India.
EM vijay.kanike2012@gmail.com; sathishanchula@gmail.com
CR Aggarwal AK, 2020, UNMANNED AERIAL VEHICLE: APPLICATIONS IN AGRICULTURE AND ENVIRONMENT, P159, DOI 10.1007/978-3-030-27157-2_12
   Ali F. E., 2008, Progress In Electromagnetics Research C, V3, P215, DOI 10.2528/PIERC08041305
   Assareh A, 2009, CIBCB: 2009 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY, P193
   Atanassov K. T., 1986, Fuzzy Sets and Systems, V20, P87, DOI 10.1016/S0165-0114(86)80034-3
   Azam MA, 2022, COMPUT BIOL MED, V144, DOI 10.1016/j.compbiomed.2022.105253
   Balasubramaniam P, 2014, INFORM FUSION, V20, P21, DOI 10.1016/j.inffus.2013.10.011
   Barra V, 2001, NEUROIMAGE, V13, P410, DOI 10.1006/nimg.2000.0707
   Baum KG, 2007, IEEE NUCL SCI CONF R, P3774, DOI 10.1109/NSSMIC.2007.4436944
   Bhatnagar G, 2015, NEUROCOMPUTING, V157, P143, DOI 10.1016/j.neucom.2015.01.025
   Bloch I, 2005, PATTERN RECOGN LETT, V26, P449, DOI 10.1016/j.patrec.2004.08.009
   Broussard RP, 1999, IEEE T NEURAL NETWOR, V10, P554, DOI 10.1109/72.761712
   Cai HJ, 2023, IEEE T MED IMAGING, V42, P456, DOI 10.1109/TMI.2022.3222093
   Chaira T, 2012, APPL SOFT COMPUT, V12, P1259, DOI 10.1016/j.asoc.2011.12.011
   Chavan S, 2016, ADV INTELLIGENT SYST, V137, P627
   Cheng S., 2008, 2008 2 INT C BIOINFO, P2523, DOI DOI 10.1109/ICBBE.2008.964
   Daneshvar S, 2010, INFORM FUSION, V11, P114, DOI 10.1016/j.inffus.2009.05.003
   Das S., 2011, Progress In Electromagnetics Research B, V30, P355
   Das S, 2013, INT J MATH COMPUT, P1
   Dou W, 2007, IMAGE VIS COMPUT, V25
   Du J, 2016, NEUROCOMPUTING, V194, P326, DOI 10.1016/j.neucom.2016.02.047
   Duan JW, 2021, IEEE ACCESS, V9, P96353, DOI 10.1109/ACCESS.2021.3094972
   El-Hoseny HM, 2019, MULTIMED TOOLS APPL, V78, P26373, DOI 10.1007/s11042-019-7552-1
   Ensafi P, 2005, LECT NOTES COMPUT SC, V3656, P159, DOI 10.1007/11559573_20
   Fowler JE, 2005, IEEE SIGNAL PROC LET, V12, P629, DOI 10.1109/LSP.2005.853048
   Gopi Krishna E., 2015, INT J TECH RES ENG, V2, P3184
   Haddadpour M, 2017, BIOMED J, V40, P219, DOI 10.1016/j.bj.2017.05.002
   Haghighat MBA, 2011, COMPUT ELECTR ENG, V37, P789, DOI 10.1016/j.compeleceng.2011.04.016
   He CT, 2010, PROCEDIA ENGINEER, V7, P280, DOI 10.1016/j.proeng.2010.11.045
   Holupka EJ, 1996, INT J RADIAT ONCOL, V35, P975, DOI 10.1016/0360-3016(96)00231-3
   Hosseini HG, 2007, INT J BIOMED IMAGING, V2007, DOI 10.1155/2007/40980
   Jagalingam P, 2015, AQUAT PR, V4, P133, DOI 10.1016/j.aqpro.2015.02.019
   James AP, 2014, INFORM FUSION, V19, P4, DOI 10.1016/j.inffus.2013.12.002
   Jana M, 2023, IEEE T INSTRUM MEAS, V72, DOI 10.1109/TIM.2023.3240222
   Jin HY, 2014, INFRARED PHYS TECHN, V64, P134, DOI 10.1016/j.infrared.2014.02.013
   Jionghua Teng, 2010, 2010 Proceedings of 3rd International Congress on Image and Signal Processing (CISP 2010), P1552, DOI 10.1109/CISP.2010.5646958
   Kaplan I., 1998, Int J Rad Oncol Biol Phys, V42, P294, DOI DOI 10.1016/S0360-3016(98)80441-0
   Karnik NN, 1999, IEEE T FUZZY SYST, V7, P643, DOI 10.1109/91.811231
   Kavitha C. T., 2010, 2010 International Conference on Signal and Image Processing (ICSIP 2010), P296, DOI 10.1109/ICSIP.2010.5697486
   Kor S, 2004, P ANN INT IEEE EMBS, V26, P1479
   Li B, 2021, SIGNAL PROCESS, V178, DOI 10.1016/j.sigpro.2020.107793
   LI HY, 1995, IEEE T MED IMAGING, V14, P212, DOI 10.1109/42.387703
   Li SX, 2022, IEEE J BIOMED HEALTH, V26, P4123, DOI 10.1109/JBHI.2022.3161466
   Li W, 2018, OPTIK, V172, P1, DOI 10.1016/j.ijleo.2018.06.123
   Li X, 2010, IET IMAGE PROCESS, V4, P283, DOI 10.1049/iet-ipr.2008.0259
   Lin KP., 1995, IEEE 17 ANN C ENG ME, V1, P377
   Liu XB, 2017, NEUROCOMPUTING, V235, P131, DOI 10.1016/j.neucom.2017.01.006
   Liu Y, 2019, IEEE SIGNAL PROC LET, V26
   Liu Y, 2019, IEEE SIGNAL PROC LET, V26, P485, DOI 10.1109/LSP.2019.2895749
   Manchanda M, 2016, J VIS COMMUN IMAGE R, V40, P197, DOI 10.1016/j.jvcir.2016.06.021
   Marshall S., 1995, IMAGE SIGNAL PROCESS, V141, P1
   Megalooikonomou V, 2007, IEEE ENG MED BIOL, V26, P36, DOI 10.1109/EMB.2007.901790
   Meher B, 2019, INFORM FUSION, V48, P119, DOI 10.1016/j.inffus.2018.07.010
   Mendel J. M., 2017, Uncertain Rule-Based Fuzzy Systems: Introduction and NewDirections, V2nd
   Mitianoudis N, 2007, INFORM FUSION, V8, P131, DOI 10.1016/j.inffus.2005.09.001
   Mukhopadhyay S, 2001, PATTERN RECOGN, V34, P1939, DOI 10.1016/S0031-3203(00)00123-0
   Na Y, 2008, FIFTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 3, PROCEEDINGS, P37, DOI 10.1109/FSKD.2008.608
   Naidu VPS, 2008, DEFENCE SCI J, V58, P338
   Naidu VPS., 2017, CONTROL DATA FUSION, V1, P13
   Prakash O, 2019, OPTIK, V182, P995, DOI 10.1016/j.ijleo.2018.12.028
   Qiu CH, 2017, COMPUT MATH METHOD M, V2017, DOI 10.1155/2017/9308745
   Qu GH, 2001, OPT EXPRESS, V9, P184, DOI 10.1364/OE.9.000184
   Rao RV, 2011, COMPUT AIDED DESIGN, V43, P303, DOI 10.1016/j.cad.2010.12.015
   Raza M, 2005, LECT NOTES ARTIF INT, V3684, P866
   Rogova G. L., 2002, Information Fusion, V3, P91, DOI 10.1016/S1566-2535(02)00054-4
   SHAHDOOSTI HR, 2018, DIGIT SIGNAL PROCESS, V79, P9, DOI DOI 10.1016/J.DSP.2018.04.002
   Shanker Mishra HO., 2014, INT J INFORM COMPUTA, V4, P47
   Shreyamshakumar BK, 2012, SIGNAL IMAGE PROCESS
   Siddiqui AB, 2011, INT J INNOV COMPUT I, V7, P3583
   Singh P, 2020, IEEE SYS MAN CYBERN, P2446, DOI [10.1109/smc42975.2020.9283171, 10.1109/SMC42975.2020.9283171]
   Singh R, 2014, INFORM FUSION, V19, P49, DOI 10.1016/j.inffus.2012.09.005
   Singh R, 2009, ICAPR 2009: SEVENTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, PROCEEDINGS, P232, DOI 10.1109/ICAPR.2009.97
   Srilatha K, 2015, RES J PHARM BIOL CHE, V6, P775
   Srivastava A, 2018, Handbook of Research on Advanced Concepts in Real-time Image and Video Processing, P281, DOI 10.4018/978-1-5225-2848-7.ch011
   Srivastava R, 2016, IET COMPUT VIS, V10, P513, DOI 10.1049/iet-cvi.2015.0251
   Szu H, 2003, P ANN INT IEEE EMBS, V25, P1133, DOI 10.1109/IEMBS.2003.1279448
   Tirupal T, 2019, IRAN J FUZZY SYST, V16, P33
   Tirupal T, 2017, ETRI J, V39, P173, DOI 10.4218/etrij.17.0116.0568
   TOET A, 1989, PATTERN RECOGN LETT, V9, P255, DOI 10.1016/0167-8655(89)90004-4
   TOET A, 1989, PATTERN RECOGN LETT, V9, P245, DOI 10.1016/0167-8655(89)90003-2
   Togan V, 2012, ENG STRUCT, V34, P225, DOI 10.1016/j.engstruct.2011.08.035
   Vakaimalar E, 2019, MULTIMED TOOLS APPL, V78, P17573, DOI 10.1007/s11042-018-7124-9
   Wang GF, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3170983
   Xiao J, 2023, REMOTE SENS APPL, V32, DOI 10.1016/j.rsase.2023.101005
   Xu XJ, 2016, BIOMED SIGNAL PROCES, V27, P103, DOI 10.1016/j.bspc.2016.02.008
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yang B, 2008, CONF CYBERN INTELL S, P55
   Yang L, 2008, NEUROCOMPUTING, V72, P203, DOI 10.1016/j.neucom.2008.02.025
   Yang Y, 2014, COMPUT MATH METHOD M, V2014, DOI 10.1155/2014/835481
   Yang Y, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/579341
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zuo Q, 2021, IEEE J BIOMED HEALTH, V25, P3438, DOI 10.1109/JBHI.2021.3083752
NR 91
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33235
EP 33262
DI 10.1007/s11042-023-16859-9
EA SEP 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001066958500005
DA 2024-07-18
ER

PT J
AU Gupta, A
   Kumar, R
   Kumar, Y
AF Gupta, Astha
   Kumar, Rakesh
   Kumar, Yogesh
TI Hybrid deep learning based automatic speech recognition model for
   recognizing non-Indian languages
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic Speech Recognition; Spectrogram; Short Term Fourier transform;
   MFCC; ResNet10; Inception V3; VGG16; DenseNet201; EfficientNetB0
AB Speech is a natural phenomenon and a significant mode of communication used by humans that is divided into two categories, human-to-human and human-to-machine. Human-to-human communication depends on the language the speaker uses. In contrast, human-to-machine communication is a technique in which machines recognize human speech and act accordingly, often termed Automatic Speech Recognition (ASR). Recognition of Non-Indian language is challenging due to pitch variations and other factors such as accent, pronunciation, etc. This paper proposes a novel approach based on Dense Net201 and EfficientNetB0, i.e., a hybrid model for the recognition of Speech. Initially, 76,263 speech samples are taken from 11 non-Indian languages, including Chinese, Dutch, Finnish, French, German, Greek, Hungarian, Japanese, Russian, Spanish and Persian. When collected, these speech samples are pre-processed by removing noise. Then, Spectrogram, Short-Term Fourier Transform (STFT), Spectral Rolloff-Bandwidth, Mel-frequency Cepstral Coefficient (MFCC), and Chroma feature are used to extract features from the speech sample. Further, a comparative analysis of the proposed approach is shown with other Deep Learning (DL) models like ResNet10, Inception V3, VGG16, DenseNet201, and EfficientNetB0. Standard parameters like Precision, Recall, F1-Score, Confusion Matrix, Accuracy, and Loss curves are used to evaluate the performance of each model by considering speech samples from all the languages mentioned above. Thus, the experimental results show that the hybrid model stands out from all the other models by giving the highest recognition accuracy of 99.84% with a loss of 0.004%.
C1 [Gupta, Astha; Kumar, Rakesh] Chandigarh Univ, Dept Comp Sci & Engn, Mohali, Punjab, India.
   [Kumar, Yogesh] Indus Univ, Indus Inst Technol & Engn, Ahmadabad, Gujarat, India.
C3 Chandigarh University
RP Kumar, R (corresponding author), Chandigarh Univ, Dept Comp Sci & Engn, Mohali, Punjab, India.
EM astha.gupta26d@gmail.com; rakesh77kumar@gmail.com;
   yogesh.arora10744@gmail.com
RI Kumar, Yogesh/AAW-1656-2021; kumar, rakesh/AFF-8807-2022
OI Kumar, Yogesh/0000-0002-8169-7481; kumar, rakesh/0000-0002-2659-5941;
   Gupta, Astha/0000-0002-5813-3717
CR Abdallah A, 2020, J IMAGING, V6, DOI 10.3390/jimaging6120141
   Abushariah AAM, 2023, IEEE ACCESS, V11, P5944, DOI 10.1109/ACCESS.2022.3218684
   Al-karawi KA, 2021, MULTIMED TOOLS APPL, V80, P22231, DOI 10.1007/s11042-021-10767-6
   Antoniadis P, 2022, MULTIMED TOOLS APPL, V81, P40635, DOI 10.1007/s11042-022-12953-6
   Berjon P., 2021, SOFT COMPUTING LETT, DOI 10.1016/j.socl.2021.100018
   Chen J.D., 2020, Sci. Total Environ., V9, P1
   Deguo Mu, 2019, 2019 IEEE International Conference on Smart Internet of Things (SmartIoT). Proceedings, P402, DOI 10.1109/SmartIoT.2019.00071
   Delic V, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/4368036
   Dokuz Y, 2022, MULTIMED TOOLS APPL, V81, P9969, DOI 10.1007/s11042-022-12304-5
   French Park K., FRENCH SINGLE SPEAKE
   Gazeau Valentin, 2018, International Journal of Information Technology and Computer Science, V10, P11, DOI 10.5815/ijitcs.2018.08.02
   Gong CX, 2014, 2014 9TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP), P459, DOI 10.1109/ISCSLP.2014.6936636
   Guntur R, 2021, IEEE 2 GLOB C ADV TE, DOI [10.1109/GCAT52182.2021.9587650, DOI 10.1109/GCAT52182.2021.9587650]
   Jain N, 2022, NEURAL COMPUT APPL, V34, P21481, DOI 10.1007/s00521-021-06003-9
   kaggle, DUTCH SINGLE SPEAKER
   kaggle, CHINESE SINGLE SPEAK
   Kalhor E, 2021, MULTIMED TOOLS APPL, V80, P8127, DOI 10.1007/s11042-020-10119-w
   Kaur AP, 2023, MULTIMED TOOLS APPL, V82, P13307, DOI 10.1007/s11042-022-13645-x
   Kaur G, 2023, J BIG DATA-GER, V10, DOI 10.1186/s40537-022-00680-6
   Kayte, 2020, IEEE INT C ADVENT TR, DOI [10.1109/ICATMRI51801.2020.9398431, DOI 10.1109/ICATMRI51801.2020.9398431]
   Malik M, 2021, MULTIMED TOOLS APPL, V80, P9411, DOI 10.1007/s11042-020-10073-7
   Milde B, 2018, P 36 AAAI C ART INT, DOI [10.48550/arXiv.1807.10311, DOI 10.48550/ARXIV.1807.10311]
   Pantazoglou F., 2019, WSEAS TRANSACT SYST, V13, P550
   Park, GERMAN SINGLE SPEAKE
   Park K., HUNGARIAN SINGLE SPE
   Park K., SPANISH SINGLE SPEAK
   Park K., RUSSIAN SINGLE SPEAK
   Park K., JAPANESE SINGLE SPEA
   Park K., GREEK SINGLE SPEAKER
   Park K, FINNISH SINGLE SPEAK
   Pengyuan Shao, 2020, Journal of Physics: Conference Series, V1549, DOI 10.1088/1742-6596/1549/2/022012
   Persian dataset, PERS SPEECH
   Ropke W, 2019, P REF AI ML C BELG N, P2491
   Savaghebi Mehdi, 2015, 2015 IEEE Power & Energy Society General Meeting, P1, DOI 10.1109/PESGM.2015.7286092
   Singh G, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/5123671
   Smit P, 2021, COMPUT SPEECH LANG, V66, DOI 10.1016/j.csl.2020.101158
   Szarvas M., 2000, International Journal of Speech Technology, V3, P237, DOI 10.1023/A:1026515132762
   Thukroo IA, 2022, MULTIMED TOOLS APPL, V81, P32593, DOI 10.1007/s11042-022-13054-0
   Veisi H, 2020, INT J SPEECH TECHNOL, V23, P893, DOI 10.1007/s10772-020-09768-x
   Xiaohui Chu X, 2021, IEEE INT C SOC COMP, DOI [10.1109/ICSCDE54196.2021.00075, DOI 10.1109/ICSCDE54196.2021.00075]
   Xu JH, 2020, 2020 4TH INTERNATIONAL CONFERENCE ON NATURAL LANGUAGE PROCESSING AND INFORMATION RETRIEVAL, NLPIR 2020, P102, DOI 10.1145/3443279.3443313
   Xu X, 2014, 2014 9TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP), P345, DOI 10.1109/ISCSLP.2014.6936641
   Xue YF, 2017, I C VIRTUAL REALITY, P180, DOI 10.1109/ICVRV.2017.00044
   Yang H, 2011, COMP INF SCI ICIS 20, DOI [10.1109/ICIS.2011.38, DOI 10.1109/ICIS.2011.38]
NR 44
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30145
EP 30166
DI 10.1007/s11042-023-16748-1
EA SEP 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066762000012
DA 2024-07-18
ER

PT J
AU Al-Betar, MA
   Abu Doush, I
   Makhadmeh, SN
   Al-Naymat, G
   Alomari, OA
   Awadallah, MA
AF Al-Betar, Mohammed Azmi
   Abu Doush, Iyad
   Makhadmeh, Sharif Naser
   Al-Naymat, Ghazi
   Alomari, Osama Ahmad
   Awadallah, Mohammed A.
TI Equilibrium optimizer: a comprehensive survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Swarm algorithm; Equilibrium optimizer; Metaheuristics; Optimization
ID DIFFERENTIAL EVOLUTION; ALGORITHM; DESIGN; METAHEURISTICS; PARAMETERS;
   EMOTION
AB Equilibrium optimizer (EO) is a recent optimization method inspired by the physical equation of the mass balance that provides the conservation of mass entering, leaving, and generating in a control volume and the system always reaches an equilibrium point. It is a fast-growing algorithm that has been adopted by several researchers due to its successful features, such as simplicity, parameter-less, derivative-free, and sound-and-complete. In this survey paper, a comprehensive analysis of EO and its evolution, since its introduction in 2020 until now, is provided. Its performance and convergence behavior are initially studied and compared against eight well-established methods using 23 mathematical optimization functions which reveals its superiority. Since EO is established to deal with a single objective and free optimization problems of the continuous domain, a comprehensive analysis of the different EO versions which are either modified versions or hybridized versions are introduced to deal with different search spaces of optimization problems. Furthermore, this research aims to provide a deep analysis of the applications of the EO algorithm, including the population type, the optimizer version used, and the main contribution. This is realized by its successful applications in different domains such as scheduling and planning, power and electrical engineering, civil and environmental engineering, communication and networking, image processing, etc. A discussion about the different EO versions and applications is provided to highlight the pros and cons of such algorithms. This discussion leads this survey to end up providing several possible research directions that can be followed in the future. Overall, this survey provides a comprehensive analysis of Equilibrium Optimizer performance and applications and contributes to the broader field of optimization algorithms.
C1 [Al-Betar, Mohammed Azmi; Al-Naymat, Ghazi] Ajman Univ, Coll Engn & Informat Technol, Dept Informat Technol, POB 346, Ajman, U Arab Emirates.
   [Al-Betar, Mohammed Azmi; Makhadmeh, Sharif Naser; Al-Naymat, Ghazi; Awadallah, Mohammed A.] Ajman Univ, Artificial Intelligence Res Ctr AIRC, POB 346, Ajman, U Arab Emirates.
   [Al-Betar, Mohammed Azmi] Al Balqa Appl Univ, Al Huson Univ Coll, Dept Informat Technol, POB 50, Irbid, Jordan.
   [Abu Doush, Iyad] Yarmouk Univ, Comp Sci Dept, Irbid, Jordan.
   [Abu Doush, Iyad] Amer Univ Kuwait, Coll Engn & Appl Sci, Comp Dept, Salmiya, Kuwait.
   [Makhadmeh, Sharif Naser] Univ Petra, Dept Data Sci & Artificial Intelligence, POB 11196, Amman, Jordan.
   [Alomari, Osama Ahmad] Abu Dhabi Univ, Coll Engn, Dept Comp Sci & Informat Technol, Abu Dhabi, U Arab Emirates.
   [Awadallah, Mohammed A.] Al Aqsa Univ, Dept Comp Sci, POB 4051, Gaza, Palestine.
C3 Ajman University; Ajman University; Al-Balqa Applied University; Yarmouk
   University; American University of Kuwait; Petra University; Abu Dhabi
   University; Al-Aqsa University
RP Al-Betar, MA (corresponding author), Ajman Univ, Coll Engn & Informat Technol, Dept Informat Technol, POB 346, Ajman, U Arab Emirates.; Al-Betar, MA (corresponding author), Ajman Univ, Artificial Intelligence Res Ctr AIRC, POB 346, Ajman, U Arab Emirates.; Al-Betar, MA (corresponding author), Al Balqa Appl Univ, Al Huson Univ Coll, Dept Informat Technol, POB 50, Irbid, Jordan.
EM m.albetar@ajman.ac.ae
RI Awadallah, Mohammed A./F-3103-2017; Al-Betar, Al-betar Azmi/E-9758-2017;
   Makhadmeh, Sharif N/A-3428-2019
OI Awadallah, Mohammed A./0000-0002-7815-8946; Al-Betar, Al-betar
   Azmi/0000-0003-1980-1791; Makhadmeh, Sharif N/0000-0002-2894-7998;
   ALOMARI, OSAMA/0000-0002-1135-5750
CR Abd El Moiz Dahi Zakaria, 2017, International Journal of Reasoning-based Intelligent Systems, V9, P22
   Abdechiri M, 2013, APPL SOFT COMPUT, V13, P2932, DOI 10.1016/j.asoc.2012.03.068
   Abdel-Basset M, 2021, COMPUT IND ENG, V151, DOI 10.1016/j.cie.2020.106946
   Abdel-Basset M, 2020, SOL ENERGY, V209, P694, DOI 10.1016/j.solener.2020.09.032
   Abdel-Basset M, 2021, NEURAL COMPUT APPL, V33, P10685, DOI 10.1007/s00521-020-04820-y
   Abderazek H, 2021, MATER TEST, V63, P552, DOI 10.1515/mt-2020-0092
   Abdul-hamied DT, 2020, ALEX ENG J, V59, P4787, DOI 10.1016/j.aej.2020.08.043
   Abu Doush I, 2023, NEURAL COMPUT APPL, V35, P15923, DOI 10.1007/s00521-023-08577-y
   Abu Doush I, 2023, NEURAL COMPUT APPL, V35, P1125, DOI 10.1007/s00521-021-05805-1
   Abualigah L, 2021, COMPUT METHOD APPL M, V376, DOI 10.1016/j.cma.2020.113609
   Agnihotri S., 2020, PIICON 2020 - 9th IEEE Power India International Conference, P1, DOI 10.1109/PIICON49524.2020.9113048
   Agushaka JO, 2022, COMPUT METHOD APPL M, V391, DOI 10.1016/j.cma.2022.114570
   Ahanch M, 2021, INTEGRATED VOLT VAR
   Ahmed M., 2020, 2020 INT YOUTH C RAD, P1, DOI DOI 10.1109/REEPE49198.2020.9059219
   Ahmed S, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107283
   Al Bataineh A, 2021, IEEE ACCESS, V9, P78993, DOI 10.1109/ACCESS.2021.3084131
   Al-akayshee AS, 2021, IEEE NW RUSS YOUNG, P1354, DOI 10.1109/ElConRus51938.2021.9396604
   Al-Betar MA, 2021, NEURAL COMPUT APPL, V33, P5011, DOI 10.1007/s00521-020-05296-6
   Al-Betar MA, 2017, NEURAL COMPUT APPL, V28, pS153, DOI 10.1007/s00521-016-2328-2
   Al-Betar MA, 2019, J SUPERCOMPUT, V75, P5280, DOI 10.1007/s11227-019-02776-y
   Al-Betar MA, 2018, EXPERT SYST APPL, V107, P126, DOI 10.1016/j.eswa.2018.04.024
   Alatas B, 2011, EXPERT SYST APPL, V38, P13170, DOI 10.1016/j.eswa.2011.04.126
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Ansingkar NP, 2022, MULTIMED TOOLS APPL, V81, P6539, DOI 10.1007/s11042-021-11786-z
   Arnold DV, 2002, IEEE T EVOLUT COMPUT, V6, P30, DOI 10.1023/A:1015059928466
   Askari Q, 2020, KNOWL-BASED SYST, V195, DOI 10.1016/j.knosys.2020.105709
   Askarzadeh A, 2016, COMPUT STRUCT, V169, P1, DOI 10.1016/j.compstruc.2016.03.001
   Atashpaz-Gargari E, 2007, IEEE C EVOL COMPUTAT, P4661, DOI 10.1109/CEC.2007.4425083
   Ates A, 2021, FRACTIONAL ORDER CHA, V7
   Aval SBB, 2022, INT J STRUCT STAB DY, V22, DOI 10.1142/S0219455422500560
   Awadallah MA, 2023, ARCH COMPUT METHOD E, V30, P2831, DOI 10.1007/s11831-023-09887-z
   Awadallah MA, 2022, EXPERT SYST APPL, V194, DOI 10.1016/j.eswa.2021.116431
   Awadallah MA, 2020, SOFT COMPUT, V24, P13461, DOI 10.1007/s00500-020-04760-8
   Baluja S, 1994, Technical Report CMU-CS- 94-163
   Bardhan A, 2022, TRANSP GEOTECH, V32, DOI 10.1016/j.trgeo.2021.100678
   Bardhan A, 2021, CMES-COMP MODEL ENG, V128, P1033, DOI 10.32604/cmes.2021.015885
   Bastopcu M, 2020, 2020 54TH ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS (CISS), P98, DOI 10.1109/CISS48834.2020.1570617397
   Behera Sasmita, 2021, 2021 International Symposium of Asian Control Association on Intelligent Robotics and Industrial Automation (IRIA), P209, DOI 10.1109/IRIA53009.2021.9588710
   Blum C, 2003, ACM COMPUT SURV, V35, P268, DOI 10.1145/937503.937505
   Braik M, 2022, KNOWL-BASED SYST, V243, DOI 10.1016/j.knosys.2022.108457
   Braik M, 2022, NEURAL COMPUT APPL, V34, P409, DOI 10.1007/s00521-021-06392-x
   Calasan M, 2021, MACHINES, V9, DOI 10.3390/machines9110265
   Chattopadhyay S, 2023, MULTIMED TOOLS APPL, V82, P9693, DOI 10.1007/s11042-021-11839-3
   Chen H, 2020, COMPUT INTEL NEUROSC, V2020
   Chen MR, 2021, EXPERT SYST APPL, V175, DOI 10.1016/j.eswa.2021.114812
   Chen P, 2022, ENG APPL ARTIF INTEL, V111, DOI 10.1016/j.engappai.2022.104805
   Cikan M, 2022, ALEX ENG J, V61, P991, DOI 10.1016/j.aej.2021.06.079
   Dey A, 2020, IEEE ACCESS, V8, P200953, DOI 10.1109/ACCESS.2020.3035531
   Dhiman G, 2021, J AMB INTEL HUM COMP, V12, P8457, DOI 10.1007/s12652-020-02580-0
   Dinh PH, 2021, APPL INTELL, V51, P8416, DOI 10.1007/s10489-021-02282-w
   Dinkar SK, 2021, EXPERT SYST APPL, V174, DOI 10.1016/j.eswa.2021.114766
   Dogan B, 2015, INFORM SCIENCES, V293, P125, DOI 10.1016/j.ins.2014.08.053
   Dorigo M., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), P1470, DOI 10.1109/CEC.1999.782657
   Durmus A, 2021, INT J MICROW WIREL T, V13, P986, DOI 10.1017/S1759078720001774
   Eiben AE, 1999, IEEE T EVOLUT COMPUT, V3, P124, DOI 10.1109/4235.771166
   El-Shorbagy MA, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/6672131
   Elgamal ZM, 2021, COMPUTATION, V9, DOI 10.3390/computation9060068
   Elmanakhly DA, 2021, IEEE ACCESS, V9, P120309, DOI 10.1109/ACCESS.2021.3108097
   ElSayed SK, 2021, ENERGIES, V14, DOI 10.3390/en14051373
   Elsheikh AH, 2021, J INTELL MANUF, V32, P1377, DOI 10.1007/s10845-020-01617-7
   Fadakar E, 2016, 2016 1ST CONFERENCE ON SWARM INTELLIGENCE AND EVOLUTIONARY COMPUTATION (CSIEC 2016), P6, DOI 10.1109/CSIEC.2016.7482120
   Fan QS, 2021, EXPERT SYST APPL, V170, DOI 10.1016/j.eswa.2021.114575
   Faramarzi A, 2020, KNOWL-BASED SYST, V191, DOI 10.1016/j.knosys.2019.105190
   Fathollahi-Fard AM, 2020, SOFT COMPUT, V24, P14637, DOI 10.1007/s00500-020-04812-z
   Fu ZL, 2021, INTELL AUTOM SOFT CO, V27, P233, DOI 10.32604/iasc.2021.014192
   Gabis AB, 2021, ARTIF INTELL REV, V54, P5469, DOI 10.1007/s10462-021-10026-y
   Gabr AR, 2022, INT J PAVEMENT ENG, V23, P3346, DOI 10.1080/10298436.2021.1892109
   Gandomi AH, 2012, COMMUN NONLINEAR SCI, V17, P4831, DOI 10.1016/j.cnsns.2012.05.010
   Gao YY, 2020, IEEE ACCESS, V8, P140936, DOI 10.1109/ACCESS.2020.3013617
   Gao Z, 2020, IMPROVED EQUILIBRIUM, V1575
   Gao Z-M, 2020, BINARY EQUILIBRIUM O, P193
   Gao Z-M, 2020, IMPROVED EQUILIBRIUM, P26
   Geem ZW, 2001, SIMULATION, V76, P60, DOI 10.1177/003754970107600201
   Glover F., 1990, ORSA Journal on Computing, V2, P4, DOI [10.1287/ijoc.1.3.190, 10.1287/ijoc.2.1.4]
   Guha D, 2021, INT T ELECTR ENERGY, V31, DOI 10.1002/2050-7038.12702
   Gui P, 2021, KNOWL-BASED SYST, V233, DOI 10.1016/j.knosys.2021.107552
   Guo ZH, 2002, ENVIRON POLLUT, V120, P533, DOI 10.1016/S0269-7491(02)00187-2
   Gupta S, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106542
   Hamdy A, 2021, INT J RENEW ENERGY R, V11, P1095
   Hatamlou A, 2013, INFORM SCIENCES, V222, P175, DOI 10.1016/j.ins.2012.08.023
   Heidari E, 2022, INT J COMMUN SYST, V35, DOI 10.1002/dac.5148
   Hemalatha R, 2021, WIRELESS PERS COMMUN, V120, P1837, DOI 10.1007/s11277-021-08537-6
   Holland J. H., 1992, Scientific American (International Edition), V267, P44, DOI 10.1038/scientificamerican0792-66
   Hou CZ, 2021, PROCEEDINGS OF THE 2021 IEEE INTERNATIONAL CONFERENCE ON PROGRESS IN INFORMATICS AND COMPUTING (PIC), P14, DOI 10.1109/PIC53636.2021.9687084
   Houssein EH, 2022, EXPERT SYST APPL, V195, DOI 10.1016/j.eswa.2022.116552
   Houssein EH, 2022, NEURAL COMPUT APPL, V34, P3165, DOI 10.1007/s00521-021-06580-9
   Hu P., 2022, Journal of Network Intelligence, V7, P45
   Hussain K, 2019, ARTIF INTELL REV, V52, P2191, DOI 10.1007/s10462-017-9605-z
   Irizarry R, 2004, EVOL COMPUT, V12, P435, DOI 10.1162/1063656043138897
   Ismael O., 2021, J EUROPEEN SYSTEMES, V54, P131, DOI DOI 10.18280/JESA.540115
   Jia HM, 2021, J INTELL FUZZY SYST, V40, P5583, DOI 10.3233/JIFS-200101
   Joshi PM, 2021, EMERGING TRENDS IND, P1, DOI [10.1109/ETI4.051663.2021.9619191, DOI 10.1109/ETI4.051663.2021.9619191]
   Kann V, 1992, THESIS CITESEER
   Karami H, 2014, NEURAL COMPUT APPL, V25, P1455, DOI 10.1007/s00521-014-1636-7
   Karami H, 2021, COMPUT IND ENG, V156, DOI 10.1016/j.cie.2021.107224
   Kardani N, 2022, ACTA GEOTECH, V17, P1239, DOI 10.1007/s11440-021-01257-y
   Kaveh A, 2016, COMPUT STRUCT, V167, P69, DOI 10.1016/j.compstruc.2016.01.008
   Kaveh A, 2012, COMPUT STRUCT, V112, P283, DOI 10.1016/j.compstruc.2012.09.003
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Khadanga RK, 2021, ARAB J SCI ENG, V46, P9831, DOI 10.1007/s13369-021-05580-0
   Kharrich M, 2021, IEEE ACCESS, V9, P13655, DOI 10.1109/ACCESS.2021.3051573
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   KOZA JR, 1994, STAT COMPUT, V4, P87, DOI 10.1007/BF00175355
   Lam AYS, 2010, IEEE T EVOLUT COMPUT, V14, P381, DOI 10.1109/TEVC.2009.2033580
   Lan P, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13091706
   Lim TY, 2016, EXPERT SYST APPL, V54, P241, DOI 10.1016/j.eswa.2016.01.055
   Lim TY, 2014, ARTIF INTELL REV, V41, P385, DOI 10.1007/s10462-012-9314-6
   Liu JS, 2022, EXPERT SYST APPL, V198, DOI 10.1016/j.eswa.2022.116828
   Lourenco H. R., 2003, Handbook of metaheuristics, P320, DOI DOI 10.1007/0-306-48056-5_11
   Mahmoodjanloo M, 2022, INT J PROD RES, V60, P4973, DOI 10.1080/00207543.2021.1946193
   Malik MM, 2022, J KING SAUD UNIV-COM, V34, P7559, DOI 10.1016/j.jksuci.2021.08.032
   Mansoor M, 2021, ENERG CONVERS MANAGE, V246, DOI 10.1016/j.enconman.2021.114694
   Meng XB, 2014, LECT NOTES COMPUT SC, V8794, P86, DOI 10.1007/978-3-319-11857-4_10
   Micev Mihailo, 2021, Computers & Electrical Engineering, V89, P243, DOI 10.1016/j.compeleceng.2020.106930
   Minocha S, 2022, COMPUT ELECTR ENG, V98, DOI 10.1016/j.compeleceng.2022.107689
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2016, KNOWL-BASED SYST, V96, P120, DOI 10.1016/j.knosys.2015.12.022
   Mirjalili S, 2015, KNOWL-BASED SYST, V89, P228, DOI 10.1016/j.knosys.2015.07.006
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mladenovic N, 1997, COMPUT OPER RES, V24, P1097, DOI 10.1016/S0305-0548(97)00031-2
   Moosavi SHS, 2019, ENG APPL ARTIF INTEL, V86, P165, DOI 10.1016/j.engappai.2019.08.025
   Mostafa A, 2021, IEEE ACCESS, V9, P69985, DOI 10.1109/ACCESS.2021.3078115
   Mousa AA, 2021, PROCESSES, V9, DOI 10.3390/pr9020200
   Naik MK, 2021, SWARM EVOL COMPUT, V65, DOI 10.1016/j.swevo.2021.100907
   Nasiri E, 2023, MULTIMED TOOLS APPL, V82, P3745, DOI 10.1007/s11042-022-12943-8
   Ndi FE, 2021, ENERGY REP, V7, P4761, DOI 10.1016/j.egyr.2021.07.025
   Nguyen Q, 2021, INT J INTELL ENG SYS, V14, P46
   Nusair K, 2020, ENERGIES, V13, DOI 10.3390/en13226066
   Ouadfel S, 2022, EXPERT SYST APPL, V187, DOI 10.1016/j.eswa.2021.115882
   Özkaya H, 2020, MATER TEST, V62, P492, DOI 10.3139/120.111509
   Paliwal N, 2021, INT T ELECTR ENERGY, V31, DOI 10.1002/2050-7038.12930
   Pan JS., 2021, J NETW INTELL, V6, P216
   Pandya SB, 2021, SMART SCI, V9, P257, DOI 10.1080/23080477.2021.1932164
   Parouha RP, 2016, APPL SOFT COMPUT, V38, P501, DOI 10.1016/j.asoc.2015.10.022
   Dinh PH, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102696
   Premkumar M, 2022, J COMPUT DES ENG, V9, P24, DOI 10.1093/jcde/qwab065
   Qi H, 2021, MATH BIOSCI ENG, V18, P4648, DOI 10.3934/mbe.2021236
   Rabehi A, 2020, SUPERLATTICE MICROST, V146, DOI 10.1016/j.spmi.2020.106665
   Rao R., 2016, Int J Ind Eng Comput, V7, P19, DOI [DOI 10.5267/J.IJIEC.2015.8.004, 10.5267/j.ijiec.2015.8.004]
   Rao RV, 2011, COMPUT AIDED DESIGN, V43, P303, DOI 10.1016/j.cad.2010.12.015
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Rezk H, 2021, ENERGY, V234, DOI 10.1016/j.energy.2021.121267
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Roy B, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11136238
   Saberi-Movahed F, 2022, KNOWL-BASED SYST, V256, DOI 10.1016/j.knosys.2022.109884
   Salimi H, 2015, KNOWL-BASED SYST, V75, P1, DOI 10.1016/j.knosys.2014.07.025
   Sayed EA, 2021, 16 INT C COMP ENG SY, P1, DOI [10.1109/ICCES54031.2021.9686130, DOI 10.1109/ICCES54031.2021.9686130]
   SAYED GI, 2021, J AMB INTEL HUM COMP, P1
   Seleem SI, 2021, RENEW ENERG, V169, P117, DOI 10.1016/j.renene.2020.12.131
   Shaheen AM, 2021, APPL SOFT COMPUT, V98, DOI 10.1016/j.asoc.2020.106867
   Shaik MA, 2022, ALEX ENG J, V61, P4081, DOI 10.1016/j.aej.2021.09.063
   Shankar N, 2021, J COMPUT ELECTRON, V20, P1560, DOI 10.1007/s10825-021-01722-7
   SHAO ZY, 2021, ENTERP INF SYST-UK, P1, DOI DOI 10.1018/15567036.2020.1859014
   Simon D., 2013, EVOLUTIONARY OPTIMIZ
   Simon D, 2008, IEEE T EVOLUT COMPUT, V12, P702, DOI 10.1109/TEVC.2008.919004
   Sörensen K, 2015, INT T OPER RES, V22, P3, DOI 10.1111/itor.12001
   Soliman MA, 2021, IEEE ACCESS, V9, P41891, DOI 10.1109/ACCESS.2021.3065386
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Sun FK, 2021, ENERGY REP, V7, P5997, DOI 10.1016/j.egyr.2021.09.012
   Sun Y, 2023, J INTELL MANUF, V34, P1639, DOI 10.1007/s10845-021-01899-5
   Tabak A, 2021, COMPEL, V40, P722, DOI 10.1108/COMPEL-02-2021-0044
   Tang AD, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051814
   Nguyen TT, 2022, NEURAL COMPUT APPL, V34, P6119, DOI 10.1007/s00521-021-06779-w
   Tiachacht S., 2021, Structural Health Monitoring and Engineering Structures. Select Proceedings of SHM&ES 2020. Lecture Notes in Civil Engineering (LNCE 148), P19, DOI 10.1007/978-981-16-0945-9_2
   Too J, 2021, APPL ARTIF INTELL, V35, P247, DOI 10.1080/08839514.2020.1861407
   Tuan Ngoc Anh Nguyen, 2021, WSEAS Transactions on Systems and Control, V16, P216, DOI 10.37394/23203.2021.16.18
   Wang JB, 2021, ENERG CONVERS MANAGE, V236, DOI 10.1016/j.enconman.2021.114051
   Wang W, 2022, SUSTAINABILITY SWITZ, V14
   Wansasueb K, 2022, KNOWL-BASED SYST, V239, DOI 10.1016/j.knosys.2021.107955
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Wu XD, 2021, J ADV COMPUT INTELL, V25, P110
   Wunnava A, 2020, ENG APPL ARTIF INTEL, V94, DOI 10.1016/j.engappai.2020.103836
   Xia YK, 2022, ENERG CONVERS MANAGE, V251, DOI 10.1016/j.enconman.2021.115017
   Xin-She Yang, 2012, Unconventional Computation and Natural Computation. Proceedings of the 11th International Conference, UCNC 2012, P240, DOI 10.1007/978-3-642-32894-7_27
   Xu X-W., 2021, Journal of Network Intelligence, V6, P117
   Xue JK, 2020, SYST SCI CONTROL ENG, V8, P22, DOI 10.1080/21642583.2019.1708830
   Yang XS, 2012, ENG COMPUTATION, V29, P464, DOI 10.1108/02644401211235834
   Yao X, 1999, IEEE T EVOLUT COMPUT, V3, P82, DOI 10.1109/4235.771163
   Yazdani M, 2016, J COMPUT DES ENG, V3, P24, DOI 10.1016/j.jcde.2015.06.003
   Yin SH, 2022, ARAB J SCI ENG, V47, P10115, DOI 10.1007/s13369-021-06513-7
   Zayed ME, 2021, ENERGY, V235, DOI 10.1016/j.energy.2021.121289
   Zhang XM, 2022, ARTIF INTELL REV, V55, P4241, DOI 10.1007/s10462-021-10105-0
   Zhao J, 2020, SIMULATION RES BINAR, P140
   Zhao J, 2020, NEURAL COMPUT APPL, V32, P9777, DOI 10.1007/s00521-019-04510-4
   Zhao J, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS 2020), P352, DOI 10.1109/ICCCS49078.2020.9118502
   Zhao XQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030619
   Zhou ZY, 2022, J OPT SOC AM A, V39, P482, DOI 10.1364/JOSAA.446692
   Zitar RA, 2021, ARCH COMPUT METHOD E, P1
NR 192
TC 1
Z9 1
U1 9
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29617
EP 29666
DI 10.1007/s11042-023-16764-1
EA SEP 2023
PG 50
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001064737700003
DA 2024-07-18
ER

PT J
AU Kumar, K
   Roy, S
   Rawat, U
   Shandilya, A
AF Kumar, Krishna
   Roy, Satyabrata
   Rawat, Umashankar
   Shandilya, Astitv
TI SOCIET: Second-order cellular automata and chaotic map-based hybrid
   image encryption technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cellular automata Chaotic map; Image encryption; Lightweight; Pixel
   shuffling
AB Image encryption plays a vital role in securing sensitive visual information during transmission and storage. This paper proposes SOCIET, a novel lightweight image encryption technique that combines Second-Order Cellular Automata (SOCA) and a chaotic map. The SOCA model is utilized to generate pseudo-random sequences, which are used for pixel shuffling and bitwise XOR operations with the image pixels. The chaotic map is employed to randomly generate the key image from an arbitrary initial vector, enhancing the security of the encryption process. The proposed scheme achieves a high encryption speed due to the lightweight nature of the SOCA model, making it suitable for real-time applications. Extensive experimental results demonstrate the effectiveness and robustness of the proposed scheme against various attacks, including various statistical analyses and differential attacks.Furthermore, the scheme achieved improvements of 9.47% and 16.5% in terms of MSE and PSNR values compared to the other existing schemes. Moreover, the encryption scheme maintains a low computational complexity, making it suitable for resource-constrained devices.
C1 [Kumar, Krishna; Roy, Satyabrata; Rawat, Umashankar; Shandilya, Astitv] Manipal Univ Jaipur, Dept Comp Sci & Engn, Jaipur, India.
C3 Manipal University Jaipur
RP Roy, S (corresponding author), Manipal Univ Jaipur, Dept Comp Sci & Engn, Jaipur, India.
EM krishna.kumar@jaipur.manipal.edu; satya2k6ster@gmail.com;
   umashankar.rawat@jaipur.manipal.edu; astitv.199301523@muj.manipal.edu
RI Rawat, Umashankar/ADH-9469-2022
OI Rawat, Umashankar/0000-0002-1293-1836; Roy,
   Satyabrata/0000-0002-1856-5144
CR Alghafis A, 2020, MATH COMPUT SIMULAT, V177, P441, DOI 10.1016/j.matcom.2020.05.016
   AMINE K, 2023, MULTIMED TOOLS APPL, P1
   Amine K, 2023, MULTIMED TOOLS APPL, V82, P7901, DOI 10.1007/s11042-022-13649-7
   Arab AA, 2022, OPTIK, V261, DOI 10.1016/j.ijleo.2022.169122
   Ayubi P, 2021, ARTIF INTELL REV, V54, P1237, DOI 10.1007/s10462-020-09877-8
   Babaei A, 2020, OPTIK, V203, DOI 10.1016/j.ijleo.2019.164000
   Bakhshandeh A, 2013, OPT LASER ENG, V51, P665, DOI 10.1016/j.optlaseng.2013.01.001
   Baptista MS, 1998, PHYS LETT A, V240, P50, DOI 10.1016/S0375-9601(98)00086-3
   Benaissi S, 2023, OPTIK, V272, DOI 10.1016/j.ijleo.2022.170316
   Broumandnia A, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102553
   Chai XL, 2020, NEURAL COMPUT APPL, V32, P4961, DOI 10.1007/s00521-018-3913-3
   Choi US, 2020, MULTIMED TOOLS APPL, V79, P22825, DOI 10.1007/s11042-020-09033-y
   CHOWDHURY DR, 1994, J ELECTRON TEST, V5, P67, DOI 10.1007/BF00971964
   Demirtas M, 2022, OPTIK, V265, DOI 10.1016/j.ijleo.2022.169430
   Dong YH, 2022, INFORM SCIENCES, V593, P121, DOI 10.1016/j.ins.2022.01.031
   Enayatifar R, 2015, OPT LASER ENG, P7133
   Farrell E, 2022, J LARYNGOL OTOL, V136, P632, DOI 10.1017/S0022215121004424
   Gangadari BR, 2016, HEALTHC TECHNOL LETT, V3, P177, DOI 10.1049/htl.2016.0033
   Ghadirli HM, 2019, SIGNAL PROCESS, V164, P163, DOI 10.1016/j.sigpro.2019.06.010
   Jasra B, 2022, EXPERT SYST APPL
   JIANG D, 2023, MULTIMED TOOLS APPL, P1
   Kanso A, 2009, CHAOS SOLITON FRACT, V40, P2557, DOI 10.1016/j.chaos.2007.10.049
   Kaur M, 2020, ARCH COMPUT METHOD E, V27, P15, DOI 10.1007/s11831-018-9298-8
   Kaur M, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418501328
   Khaldi A, 2023, MULTIMED TOOLS APPL, V82, P12211, DOI 10.1007/s11042-022-13724-z
   Khalil AA, 2022, JPN PSYCHOL RES, V64, P426, DOI 10.1111/jpr.12339
   Khedmati Y, 2020, INFORM SCIENCES, V512, P855, DOI 10.1016/j.ins.2019.10.028
   Kocarev L, 2001, PHYS LETT A, V289, P199, DOI 10.1016/S0375-9601(01)00609-0
   Lai Q, 2022, CHAOS SOLITON FRACT, V158, DOI 10.1016/j.chaos.2022.112017
   Li CQ, 2019, IEEE T CIRCUITS-I, V66, P2322, DOI 10.1109/TCSI.2018.2888688
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Liu S, 2021, IEEE MULTIMEDIA
   Liu S., 2001, PROGR CRYPTOLOGY IND, V2247, P316, DOI [DOI 10.1007/3-540-45311-3_30, 10.1007/3-540-45311-3_30.]
   Lozi Rene, 2013, Topology and Dynamics of Chaos: In Celebration of Robert Gilmore's 70th Birthday, P63
   Malik MGA, 2020, IEEE ACCESS, V8, P88093, DOI 10.1109/ACCESS.2020.2990170
   Mandal MK, 2012, IETE TECH REV, V29, P395, DOI 10.4103/0256-4602.103173
   Mathivanan P, 2023, IMAGING SCI J, V71, P343, DOI 10.1080/13682199.2023.2182547
   Mathivanan P, 2023, MULTIMED TOOLS APPL, V82, P14945, DOI 10.1007/s11042-022-14072-8
   Moad MS, 2023, CYBERNET SYST, DOI 10.1080/01969722.2023.2166253
   Mondal B, 2019, J INF SECUR APPL, V45, P117, DOI 10.1016/j.jisa.2019.01.010
   N.R. Neena Raj, 2022, Journal of Visual Communication and Image Representation, DOI 10.1016/j.jvcir.2022.103500
   NANDI S, 1994, IEEE T COMPUT, V43, P1346, DOI 10.1109/12.338094
   Naskar PK, 2020, NONLINEAR DYNAM, V100, P2877, DOI 10.1007/s11071-020-05625-3
   Nayak P, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P412, DOI 10.1109/ICACCI.2018.8554728
   Noshadian S, 2020, MULTIMED TOOLS APPL, V79, P25635, DOI 10.1007/s11042-020-09233-6
   Patro KAK, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102470
   Ping P, 2014, SIGNAL PROCESS, V105, P419, DOI 10.1016/j.sigpro.2014.06.020
   Roy S, 2021, J INF SECUR APPL, V61, DOI 10.1016/j.jisa.2021.102919
   Roy S, 2021, MULTIMED TOOLS APPL, V80, P31529, DOI 10.1007/s11042-020-09880-9
   Sayah Moad Med, 2023, Research on Biomedical Engineering, P167, DOI 10.1007/s42600-023-00261-3
   Shahna K, 2020, APPL SOFT COMPUT, V90, DOI 10.1016/j.asoc.2020.106162
   Shao, 2022, SIGNAL PROCESS-IMAGE
   Shrivastava M, 2021, NONLINEAR DYNAM, V106, P2679, DOI 10.1007/s11071-021-06923-0
   Soppari K, 2023, INT J INTELL ROBOT, V7, P164, DOI 10.1007/s41315-022-00241-3
   SSB Aldin, 2023, MULTIMED TOOLS APPL, P1
   Sun S, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2017.2766087
   Valandar MY, 2022, J INF SECUR APPL, V66, DOI 10.1016/j.jisa.2022.103160
   Von Neumann J., 1966, IEEE Transactions on Neural Networks, V5.1, P3, DOI DOI 10.1126/SCIENCE.157.3785.180
   Wang J, 2022, J KING SAUD UNIV-COM
   Wang SM, 2022, OPT LASER TECHNOL, V148, DOI 10.1016/j.optlastec.2021.107753
   Wang T, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106355
   Wang XY, 2022, EXPERT SYST APPL, V209, DOI 10.1016/j.eswa.2022.118426
   Wang XY, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106501
   Wang XY, 2020, OPT LASER TECHNOL, V131, DOI 10.1016/j.optlastec.2020.106366
   Wang XY, 2013, COMMUN NONLINEAR SCI, V18, P3075, DOI 10.1016/j.cnsns.2013.04.008
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Yildirim M, 2022, CHAOS SOLITON FRACT, V155, DOI 10.1016/j.chaos.2021.111631
   Zhang H, 2020, SIGNAL PROCESS-IMAGE, V84, DOI 10.1016/j.image.2020.115829
   Zhang QY, 2019, IET IMAGE PROCESS, V13, P2905, DOI 10.1049/iet-ipr.2019.0667
   Zhang X, 2018, IEEE PHOTONICS J, V10, DOI [10.1109/JPHOT.2018.2859257, 10.1109/JPHOT.2018.2818715]
   Zhang YM, 2022, J KING SAUD UNIV-COM, V34, P2993, DOI 10.1016/j.jksuci.2022.04.001
   Zhou S, 2022, CHAOS SOLITON FRACT, V161, DOI 10.1016/j.chaos.2022.112380
   Zhu ZL, 2020, MULTIMED TOOLS APPL, V79, P25497, DOI 10.1007/s11042-020-09193-x
NR 75
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29455
EP 29484
DI 10.1007/s11042-023-16735-6
EA SEP 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066976400006
DA 2024-07-18
ER

PT J
AU Chakrabarti, B
   Jain, A
   Nagpal, P
   Rout, JK
AF Chakrabarti, Binayak
   Jain, Amol
   Nagpal, Pavit
   Rout, Jitendra Kumar
TI A spatiotemporal context aware hierarchical model for corporate
   bankruptcy prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bankruptcy prediction; Deep learning; Machine learning; Financial
   analysis
ID LEARNING-MODELS
AB Corporations getting bankrupt has been a severe issue for investors, businesses as well as ordinary individuals. Several research works have been conducted over the years to accurately predict bankruptcy, with the earliest works depending on the financial metrics of the company taken under consideration and the latest ones trying to predict bankruptcy from various kinds of data of organizations. However, the present works do not capture the dynamic nature of the business world and the possibility of a turnaround scenario. Hence, predictive models that are spatiotemporally aware when they predict a firm's financial distress are needed. Considering this imminent problem, our work focuses on building a unique spatiotemporal context-aware bankruptcy prediction model that can predict bankruptcy with the help of daily news articles of a company or its related companies and key financial metrics to predict bankruptcy. Knowledge graphs were used to represent the vast amount of textual data. Their embeddings, along with the financial metrics, were used in the classification process. In the first stage, various machine learning algorithms were used for the financial metrics, while for the textual data or the embeddings, attention-based LSTM was used. Next, both were assembled together in the second stage to form the final predictive model, which has given an accuracy of 0.97 on the test set and an F1 score of 0.95. We hope our novel approach to this problem helps those who are uncertain about the future of any organization in predicting its bankruptcy beforehand and thereby timely decision making.
C1 [Chakrabarti, Binayak; Jain, Amol; Nagpal, Pavit] KIIT Deemed Univ, Sch Comp Engn, Campus 15, Bhubaneswar 751024, Orissa, India.
   [Rout, Jitendra Kumar] Natl Inst Technol, Dept Comp Sci & Engn, GE Rd, Raipur 492010, Chhattisgarh, India.
C3 Kalinga Institute of Industrial Technology (KIIT); National Institute of
   Technology (NIT System); National Institute of Technology Raipur
RP Rout, JK (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, GE Rd, Raipur 492010, Chhattisgarh, India.
EM binayak042000@gmail.com; amoljain2000@gmail.com; pavit2000@gmail.com;
   jitu2rout@gmail.com
CR Acharjya DP, 2022, MULTIMED TOOLS APPL, V81, P35117, DOI 10.1007/s11042-021-10518-7
   Alam TM, 2021, COMPUT J, V64, P1731, DOI 10.1093/comjnl/bxaa056
   Alexandropoulos SAN, 2019, COMM COM INF SC, V1000, P435, DOI 10.1007/978-3-030-20257-6_37
   ALTMAN EI, 1968, J FINANC, V23, P589, DOI 10.2307/2978933
   Ansari A, 2020, HYBRID METAHEURISTIC, V8, DOI [10.1109/ACCESS.2020.3026529, DOI 10.1109/ACCESS.2020.3026529]
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Barboza F, 2017, EXPERT SYST APPL, V83, P405, DOI 10.1016/j.eswa.2017.04.006
   Ben Jabeur S, 2023, COMPUT ECON, V61, P715, DOI 10.1007/s10614-021-10227-1
   Ben Jabeur S, 2021, TECHNOL FORECAST SOC, V166, DOI 10.1016/j.techfore.2021.120658
   Cao Y, 2022, INT J FINANC ECON, V27, P455, DOI 10.1002/ijfe.2162
   Chang H., 2019, P 2019 3 INT C SOFTW, P199, DOI [10.1145/3374549.3374550, DOI 10.1145/3374549.3374550]
   Chaudhuri A., 2018, BANKRUPTCY PREDICTIO, DOI [10.1007/978-981-10-6683-2, DOI 10.1007/978-981-10-6683-2]
   Chen ZS, 2020, EXPERT SYST APPL, V146, DOI 10.1016/j.eswa.2019.113155
   Devi S. Sarojini, 2018, International Journal of Machine Learning and Computing, V8, P133, DOI 10.18178/ijmlc.2018.8.2.676
   du Jardin P, 2021, DECIS SUPPORT SYST, V147, DOI 10.1016/j.dss.2021.113576
   Faris H, 2020, PROG ARTIF INTELL, V9, P31, DOI 10.1007/s13748-019-00197-9
   Ghatasheh N, 2020, PROG ARTIF INTELL, V9, P361, DOI 10.1007/s13748-020-00219-x
   Hinton G, 2012, Cited on, V14, P2
   Horak J, 2020, J RISK FINANC MANAG, V13, DOI 10.3390/jrfm13030060
   Jones S, 2017, REV ACCOUNT STUD, V22, P1366, DOI 10.1007/s11142-017-9407-1
   Keya MS, 2021, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT 2021), P705, DOI 10.1109/ICICT50816.2021.9358587
   Kim H, 2022, COMPUT ECON, V59, P1231, DOI 10.1007/s10614-021-10126-5
   Kim H, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12166325
   Kingma D. P., 2014, arXiv
   Kou G, 2021, DECIS SUPPORT SYST, V140, DOI 10.1016/j.dss.2020.113429
   Kristóf T, 2020, J RISK FINANC MANAG, V13, DOI 10.3390/jrfm13020035
   Lahmiri S, 2019, QUANT FINANC, V19, P1569, DOI 10.1080/14697688.2019.1588468
   Li Y., 2018, OPEN J BUSINESS MANA, V06, P1, DOI [10.4236/ojbm.2018.61001, DOI 10.4236/OJBM.2018.61001]
   Lin YK, 2015, AAAI CONF ARTIF INTE, P2181
   Long JW, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106205
   Mai F, 2019, EUR J OPER RES, V274, P743, DOI 10.1016/j.ejor.2018.10.024
   Naidu GP, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INVENTIVE SYSTEMS AND CONTROL (ICISC 2018), P248, DOI 10.1109/ICISC.2018.8399072
   Nguyen BH, 2022, J OPER RES SOC, V73, P102, DOI 10.1080/01605682.2020.1784049
   Ogachi D, 2020, J RISK FINANC MANAG, V13, DOI 10.3390/jrfm13030047
   Perboli G, 2021, EXPERT SYST APPL, V174, DOI 10.1016/j.eswa.2021.114758
   Ptak-Chmielewska A., 2021, Statistics in Transition New Series, V22, P179, DOI [10.21307/stattrans-2021-010, DOI 10.21307/STATTRANS-2021-010]
   Sehgal S, 2021, MANAG FINANC, V47, P1428, DOI 10.1108/MF-06-2020-0332
   Shrivastav SK, 2020, RISKS, V8, DOI 10.3390/risks8020052
   Smiti S, 2020, INFORM SYST FRONT, V22, P1067, DOI 10.1007/s10796-020-10031-6
   Son H, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.07.033
   Soui M, 2020, APPL ARTIF INTELL, V34, P80, DOI 10.1080/08839514.2019.1691849
   Tabbakh A., 2021, TURK J COMPUT MATH E, V12, P3060
   Veganzones D, 2018, DECIS SUPPORT SYST, V112, P111, DOI 10.1016/j.dss.2018.06.011
   Wagle M, 2017, 8 INT C INF COMM TEC, P1, DOI [10.1109/ICTEmSys.2017.7958771, DOI 10.1109/ICTEMSYS.2017.7958771]
   Zoricák M, 2020, ECON MODEL, V84, P165, DOI 10.1016/j.econmod.2019.04.003
NR 45
TC 0
Z9 0
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28281
EP 28303
DI 10.1007/s11042-023-15353-6
EA SEP 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001059652000004
DA 2024-07-18
ER

PT J
AU Chu, KK
AF Chu, Keke
TI Application of animation products via multimodal information and
   semantic analogy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-modal information; Image segmentation; Bidirectional optical flow
   fusion; Animation derivatives
ID NETWORKS
AB With the rapid development of AI, image semantic segmentation techniques are now widely used in many fields. Image semantic segmentation is an important branch within the field of computer vision, and its main purpose is to divide images according to different semantic categories. Due to the rich semantic information in real scenes, multi-modal information has loaded application value in real scenes. In this paper, optical flow information characterizes the motion relationship of pixels between frames, which is introduced into the video semantic segmentation task and focuses on the motion changes of key parts of video sequences to reduce the redundancy in the network based on the independent image segmentation. To address the redundancy problem in optical flow mapping, this paper proposes a bidirectional optical flow fusion module by exploiting the symmetry of optical flow, and the test results in the DAVIS single-target video segmentation dataset demonstrate that the segmentation method of bidirectional optical flow fusion outperforms classical algorithms such as Siam Mask, FAVOS, FEELVOS, and RGMP in terms of accuracy, and is significantly faster than OSVOS in the case of similar accuracy.
C1 [Chu, Keke] Anqing Vocat & Tech Coll, Sch Informat Technol, Anqing 246003, Anhui, Peoples R China.
RP Chu, KK (corresponding author), Anqing Vocat & Tech Coll, Sch Informat Technol, Anqing 246003, Anhui, Peoples R China.
EM 15155696786@163.com
FU Anhui Provincial Education and Teaching Research Key Project; Anhui
   Provincial Education Department, Art Based on Maker Space Construction
   Design Club System Teaching Reform Research [2018jyxm0642]
FX This study is supported by Anhui Provincial Education and Teaching
   Research Key Project, Anhui Provincial Education Department, Art Based
   on Maker Space Construction Design Club System Teaching Reform Research,
   Project No.:2018jyxm0642
CR AlQuraishi M, 2021, NAT METHODS, V18, P1169, DOI 10.1038/s41592-021-01283-4
   Bhandari A, 2021, NEUROCOMPUTING, V433, P162, DOI 10.1016/j.neucom.2020.12.092
   Christino L, 2022, INFORMATION, V13, DOI 10.3390/info13080368
   Dosenko A., 2022, STATE REGIONS SERIES, V4, P97, DOI [10.32840/cpu2219-8741/2021.4(48).13, DOI 10.32840/CPU2219-8741/2021.4(48).13]
   Doulamis ND, 2000, IEEE T CIRC SYST VID, V10, P501, DOI 10.1109/76.844996
   Fei NY, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30761-2
   Fourati E, 2020, MULTIMED TOOLS APPL, V79, P865, DOI 10.1007/s11042-019-08115-w
   Fu SC, 2020, INFORM SCIENCES, V514, P484, DOI 10.1016/j.ins.2019.11.019
   Little K, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21020498
   Liu C, 2019, EXPERT SYST APPL, V123, P246, DOI 10.1016/j.eswa.2019.01.003
   Liu J, 2018, NANO ENERGY, V52, P183, DOI 10.1016/j.nanoen.2018.07.056
   Liu QL, 2020, NEUROCOMPUTING, V398, P469, DOI 10.1016/j.neucom.2019.03.100
   Meinhardt T, 2020, Advances in Neural InformationProcessing Systems, V33, P10607
   Minhas RA, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9030483
   Ningtao S., 2018, DRAMA HOUSE, V20, P90
   Pedrood K, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-90104-x
   Peng SM, 2021, IEEE ACCESS, V9, P18235, DOI 10.1109/ACCESS.2021.3054176
   Samanta A, 2021, IEEE SENS J, V21, P5035, DOI 10.1109/JSEN.2020.3033431
   Sengar SS, 2017, J VIS COMMUN IMAGE R, V49, P89, DOI 10.1016/j.jvcir.2017.08.007
   Shenke G., 2021, J GRAPHOLOG, V42, P406
   Thiruthuvanathan MM, 2022, MULTIMED TOOLS APPL, V81, P35535, DOI 10.1007/s11042-021-11010-y
   Voulodimos A, 2020, MULTIMED TOOLS APPL, V79, P3243, DOI 10.1007/s11042-018-6935-z
   Wang ZK, 2023, IEEE T CYBERNETICS, V53, P483, DOI 10.1109/TCYB.2021.3126341
   Xiong X., 2022, COMPUT ENG APPL, V58, P185
   Yang B, 2022, SYST BIOL, V71, P690, DOI 10.1093/sysbio/syab076
   Yang L, 2021, IEEE T AFFECT COMPUT, V12, P239, DOI 10.1109/TAFFC.2018.2870398
   Yuan HL, 2020, INFORM SCIENCES, V522, P214, DOI 10.1016/j.ins.2020.02.070
   Zhang han, 2022, Computer Engineering and Applications, P151, DOI 10.3778/j.issn.1002-8331.2011-0476
   Zhou JC, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2022.3170702
NR 29
TC 0
Z9 0
U1 6
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26031
EP 26054
DI 10.1007/s11042-023-16556-7
EA AUG 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001060295500005
DA 2024-07-18
ER

PT J
AU Ko, H
   Praca, I
   Choi, SG
AF Ko, Hoon
   Praca, Isabel
   Choi, Seong Gon
TI Anomaly detection analysis based on correlation of features in graph
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anomaly detection; Multiconnection; DDoS attack; Graph neural networks
   (GNN)
ID DDOS ATTACKS; DEFENSE
AB Various studies have been conducted to detect network anomalies. However, because anomaly signals are determined by the pattern characteristics using the dataset, the real-time detection problem continues. Even if there is a signal with an attack sign among the constantly transmitted and received signals, the attack cannot be blocked in advance. Moreover, it appears in many places in a distributed denial-of-service (DDoS) attack, so the real-time defense must be the best option. Therefore, it is necessary first to discover the characteristics and elements regarded as abnormal signals to discover anomalies in real time. Finally, by analyzing the correlation between network data and features, extracting the elements of the anomaly, and analyzing the behavior of the extracted elements in detail, we aim to increase the accuracy of the anomaly. In this study, we used Coburg intrusion detection and KDDCup datasets and analyzed the correlation of elements in the dataset using a graph neural network. The calculated accuracy values of the anomaly detection were 94.5% and 98.85%.
C1 [Ko, Hoon] CMT Info & Comm Co Ltd, Secur R&D Lab, Seongsu Ro 22 Gil, Seoul 04798, South Korea.
   [Praca, Isabel] Polytech Inst Porto IPP, Inst Super Engn Porto ISEP, R Dr Antonio Bernardino de Almeida 431, P-4249015 Porto, Portugal.
   [Choi, Seong Gon] Chungbuk Natl Univ, Sch Informat & Commun Engn, 8-7,Chungdae Ro 1, Cheongju 28644, Chungcheongbuk, South Korea.
C3 Instituto Politecnico do Porto; Chungbuk National University
RP Ko, H (corresponding author), CMT Info & Comm Co Ltd, Secur R&D Lab, Seongsu Ro 22 Gil, Seoul 04798, South Korea.
EM skoh21@cmtinfo.co.kr; icp@isep.ipp.pt; choisg@chungbuk.ac.kr
RI Praca, Isabel/K-8430-2014
OI Praca, Isabel/0000-0002-2519-9859
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2021R1I1A3040361]; 
   [2020R1A6A1A12047945]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (No. 2020R1A6A1A12047945). This research was supported by
   Basic Science Research Program through the National Research Foundation
   of Korea (NRF) funded by the Ministry of Education (No.
   2021R1I1A3040361).
CR Cano A, 2020, MACH LEARN, V109, P175, DOI 10.1007/s10994-019-05840-z
   De Raadt A, 2019, EDUC PSYCHOL MEAS, V79, P558, DOI 10.1177/0013164418823249
   Douligeris C, 2003, PROCEEDINGS OF THE 3RD IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, P190
   Garg R, 2020, TAXONOMY CLASSIFICAT
   Geng T, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P922, DOI 10.1109/MICRO50266.2020.00079
   Gottwalt F, 2019, COMPUT SECUR, V83, P234, DOI 10.1016/j.cose.2019.02.008
   Lathif MRA, 2018, MIDDLEWARE'18: PROCEEDINGS OF THE 2018 ACM/IFIP/USENIX MIDDLEWARE CONFERENCE (POSTERS), P7, DOI 10.1145/3284014.3284018
   Nooribakhsh M, 2020, INF SECUR J, V29, P118, DOI 10.1080/19393555.2020.1717019
   Panigrahi R, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9060690
   Panigrahi R, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9070751
   Parashar Manish., 2008, P 1 ACM WORKSHOP WOR, P43
   Ring M., 2017, P 16 EUR C CYB WARF, P361
   Ring M., 2017, Journal of Information Warfare, V16, P41
   Siddiqui M.K., 2013, International Journal of Database Theory and Application, V6, P23, DOI [10.14257/ijdta.2013.6.5.03, DOI 10.14257/IJDTA.2013.6.5.03]
   Spyridopoulos T, 2013, COMPUT SECUR, V38, P39, DOI 10.1016/j.cose.2013.03.014
   Velickovic P, 2017, ARXIV
   Xu X, 2007, LECT NOTES COMPUT SC, V4430, P196
   Zhou W, 2014, FUTURE GENER COMP SY, V38, P36, DOI 10.1016/j.future.2013.08.002
NR 18
TC 2
Z9 2
U1 7
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25487
EP 25501
DI 10.1007/s11042-023-15635-z
EA AUG 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001051861800004
OA hybrid
DA 2024-07-18
ER

PT J
AU Devi, KG
   Balasubramanian, K
   Senthilkumar, C
AF Devi, K. Gayathri
   Balasubramanian, Kishore
   Senthilkumar, C.
TI Feature analysis and classification of maize crop diseases employing
   AlexNet-inception network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ADAM optimizer; AlexNet model; AlexNet-inception network; Corn leaf
   diseases; Grad-CAM; LIME; RMSprop; Stochastic gradient descent
ID LEAF DISEASES
AB Classification of plant diseases is an important aspect of agriculture and this proposed methodology aims at identification, prediction and classification of corn leaf disease using AlexNet architecture with transfer learning methodology and AlexNet-Inception model. Different optimizers such as Stochastic Gradient Descent with Momentum, RMSprop and ADAM were employed in training the network. A 25-layer AlexNet model with transfer learning approach was modelled to sort the dataset into 4 classes, healthy, blight, common rust, and grey leaf spot. Both the networks were trained with multiple hyper parameter configurations with various learning rates, mini batch sizes, and training-to-test ratios. The modified AlexNet-Inception network performs multiple parallel convolution operations with different sizes of filters 1 x 1, 3 x 3 and 5 x 5 and average pooling on the output of 2D max pooling layer of AlexNet layer and these outputs are concatenated to produce one output. Thus the network gets progressively wider, not deeper and the computational cost is reduced and thereby avoiding the vanishing gradient problem. The detailed analysis of the features that were prioritized by AlexNet and AlexNet-Inception network for the classification of test images were validated with LIME and Grad-CAM technique and it was proved that AlexNet-Inception network outperforms the AlexNet transfer learning approach and the accuracy achieved were 98.91% for the ideal learning rate setting of 0.0001. The trials' findings indicate that the algorithm is more precise and quicker than conventional AlexNet model, providing a novel method for detecting abnormalities in maize plants. In a number of agricultural industries, this suggested effort can be utilized to implement in real time applications.
C1 [Devi, K. Gayathri] Dr NGP Inst Technol, Coimbatore, Tamilnadu, India.
   [Balasubramanian, Kishore] Dr Mahalingam Coll Engn & Technol, Pollachi, India.
   [Senthilkumar, C.] Sri Krishna Coll Technol, Coimbatore, Tamilnadu, India.
RP Balasubramanian, K (corresponding author), Dr Mahalingam Coll Engn & Technol, Pollachi, India.
EM bkishore1979@gmail.com
RI K, Gayathri Devi/AAR-6054-2020; Asso.Prof, Dr Senthil kumar
   C/IQV-4380-2023
OI K, Gayathri Devi/0000-0001-6308-7615; Asso.Prof, Dr Senthil kumar
   C/0000-0002-6363-0099
CR Arroyo JA, 2017, 2017 IEEE MEXICAN HUMANITARIAN TECHNOLOGY CONFERENCE (MHTC), P137, DOI 10.1109/MHTC.2017.8006410
   Amara J., 2017, DAT BUS TECHN WEB BT
   Arora J., 2020, Journal of Artificial Intelligence and Systems, V2, P14, DOI [10.33969/AIS.2020, DOI 10.33969/AIS.2020.21002]
   Balasubramanian Kishore, 2021, International Journal of Computational Intelligence Studies, V10, P217, DOI 10.1504/IJCISTUDIES.2021.120499
   Chen Y, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12122047
   da Rocha EL, 2020, AN 16 WORKSH VIS COM, P104
   Daneshwari AN, 2022, INT J ELECT COMPUT E, V12
   Goluguri NVRR, 2021, ARTIF INTELL REV, V54, P359, DOI 10.1007/s10462-020-09849-y
   Ha JG, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.042621
   Hanson AMGJ, 2017, INT J ENG SCI
   Hidayat A., 2019, JURNAL ILMU KOMPUTER, V12, P51, DOI [10.21609/jiki.v12i1.695, DOI 10.21609/JIKI.V12I1.695]
   Kussul N, 2017, IEEE GEOSCI REMOTE S, V14, P778, DOI 10.1109/LGRS.2017.2681128
   Liu B, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010011
   Lu Y, 2017, NEUROCOMPUTING, V267, P378, DOI 10.1016/j.neucom.2017.06.023
   Mohanty S. P., 2016, Frontiers in Plant Science, V7, P1419
   Ren C, 2020, J INF PROCESS SYST, V16, P1015
   Ristorto G, 2015, INT CONF UNMAN AIRCR, P502, DOI 10.1109/ICUAS.2015.7152329
   Rothe PR, 2015, 2015 INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING (ICPC)
   Sheikh M. Z. H., 2019, P IEEE 89 VEH TECHN, P1
   Sibiya M, 2019, AGRIENGINEERING, V1, P119, DOI 10.3390/agriengineering1010009
   Subramanian M, 2022, BIG DATA, V10, P215, DOI 10.1089/big.2021.0218
   Yallappa D, 2017, IEEE GLOB HUMANIT C
   Yu HL, 2021, IEEE ACCESS, V9, P143824, DOI 10.1109/ACCESS.2021.3120379
   Zeng WH, 2022, COMPUT ELECTRON AGR, V197, DOI 10.1016/j.compag.2022.106943
   Zhang XH, 2018, IEEE ACCESS, V6, P30370, DOI 10.1109/ACCESS.2018.2844405
NR 25
TC 2
Z9 2
U1 32
U2 49
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26971
EP 26999
DI 10.1007/s11042-023-16467-7
EA AUG 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001050733600004
DA 2024-07-18
ER

PT J
AU Lakshmi, TRV
   Reddy, CVK
   Kora, P
   Swaraja, K
   Meenakshi, K
   Kumari, CU
   Reddy, LP
AF Lakshmi, T. R. Vijaya
   Reddy, Ch. Venkata Krishna
   Kora, Padmavathi
   Swaraja, K.
   Meenakshi, K.
   Kumari, Ch. Usha
   Reddy, L. Pratap
TI Classification of multi-spectral data with fine-tuning variants of
   representative models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multi-spectral data; Tuning variants; Land use and land cover
   classification; Global average pooling layer; Batch normalization;
   Feature maps
ID DEEP LEARNING BENCHMARK; FEATURE-SELECTION; LAND-USE; IMAGE
   CLASSIFICATION; SCENE; FEATURES; SALIENCY; EUROSAT; PCA
AB Due to rapid urbanization, agriculture drought, and environmental pollution, significant efforts have been focused on land use and land cover (LULC) multi-spectral scene classification. Identifying the changes in land use and land cover can facilitate updating the geographical maps. Besides, the technical challenges in multi-spectral images with implicit deep learning models due to the nature of multi-modal, it tackles real-life issues such as the collection of large-scale high-resolution data. The limited training samples are considered a crucial challenge in LULC deep learning classification as requiring a huge number of training samples to ensure the optimal learning procedure. The present work has focused on considering the fraction of multi-spectral data (EuroSAT data) and evaluated the exemplary CNN architectures such as shallow network (VGG16) and deep network (ResNet152V2) with different tuning variants along with the additional layers prior to classification layer to improve the optimal training of the networks to classify the multi-spectral data. The performance of the thirteen spectral bands of EuroSAT dataset that contain ten scene classes of land use and land cover were analyzed band-wise and combination of spectral bands. For the scene class 'Sea & lake' the best accuracy obtained was 96.17% with individual band B08A and 95.7% with Color Infra Red (CIR) band combination. The analysis provided in this work enables the remote sensing research community to boost performance even if the multi-spectral dataset size is small.
C1 [Lakshmi, T. R. Vijaya] Mahatma Gandhi Inst Technol, Dept ECE, Hyderabad, India.
   [Reddy, Ch. Venkata Krishna] Chaitanya Bharathi Inst Technol, Dept EEE, Hyderabad, India.
   [Kora, Padmavathi; Swaraja, K.; Meenakshi, K.; Kumari, Ch. Usha] GRIET, Dept ECE, Hyderabad, India.
   [Reddy, L. Pratap] JNTUH CESTH, Dept ECE, Hyderabad, India.
C3 Chaitanya Bharathi Institute of Technology; Gokaraju Rangaraju Institute
   of Engineering & Technology
RP Lakshmi, TRV (corresponding author), Mahatma Gandhi Inst Technol, Dept ECE, Hyderabad, India.
EM trvijayalakshmi_ece@mgit.ac.in
RI T R, Vijaya Lakshmi/AAP-1431-2020; kuraparthi, swaraja/AAY-9068-2020;
   Kumari, Usha/JPA-4885-2023
OI T R, Vijaya Lakshmi/0000-0002-1197-2935; , ch venkata krishna
   reddy/0000-0002-3319-5639
CR Alem Abebaw, 2020, DEEP LEARNING METHOD
   Alzubaidi L, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00444-8
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Cerreta M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10186205
   Chaib S, 2016, IEEE GEOSCI REMOTE S, V13, P147, DOI 10.1109/LGRS.2015.2501383
   Chen C, 2016, SIGNAL IMAGE VIDEO P, V10, P745, DOI 10.1007/s11760-015-0804-2
   Chen GZ, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10050719
   Chen YC, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8122178
   Cheng DH, 2018, PROCEEDINGS OF 2018 IEEE 4TH INFORMATION TECHNOLOGY AND MECHATRONICS ENGINEERING CONFERENCE (ITOEC 2018), P1734, DOI 10.1109/ITOEC.2018.8740759
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Cheriyadat AM, 2014, IEEE T GEOSCI REMOTE, V52, P439, DOI 10.1109/TGRS.2013.2241444
   Dai DX, 2011, IEEE GEOSCI REMOTE S, V8, P173, DOI 10.1109/LGRS.2010.2055033
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dong JY, 2019, IEEE GEOSCI REMOTE S, V16, P173, DOI 10.1109/LGRS.2018.2870880
   dos Santos JA, 2010, VISAPP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P203
   Douze M, 2009, P ACM INT C IM VID R, P1, DOI DOI 10.1145/1646396.1646421
   Du B, 2017, IEEE T CYBERNETICS, V47, P1017, DOI 10.1109/TCYB.2016.2536638
   Faqeerzada MA, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10186569
   Ghiasi G, 2018, ADV NEUR IN, V31
   Gong Cheng, 2016, 2016 4th International Workshop on Earth Observation and Remote Sensing Applications (EORSA), P433, DOI 10.1109/EORSA.2016.7552845
   Gorban AN, 2020, COGN COMPUT, V12, P388, DOI 10.1007/s12559-019-09667-7
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Helber P, 2019, IEEE J-STARS, V12, P2217, DOI 10.1109/JSTARS.2019.2918242
   Helber P, 2018, INT GEOSCI REMOTE SE, P204, DOI 10.1109/IGARSS.2018.8519248
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hu F, 2015, IEEE J-STARS, V8, P2015, DOI 10.1109/JSTARS.2015.2444405
   Huang LH, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060483
   Ince IF, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10238474
   Kandel I, 2020, J IMAGING, V6, DOI 10.3390/jimaging6090092
   Ke Y, 2004, PROC CVPR IEEE, P506
   Kim M, 2009, PHOTOGRAMM ENG REM S, V75, P819, DOI 10.14358/PERS.75.7.819
   Lakshmi TRV, 2022, MULTIMED TOOLS APPL, V81, P20229, DOI 10.1007/s11042-022-12485-z
   Lakshmi TRV, 2018, ALEX ENG J, V57, P2393, DOI 10.1016/j.aej.2017.09.009
   Lakshmi TRV, 2018, SIGNAL IMAGE VIDEO P, V12, P223, DOI 10.1007/s11760-017-1149-9
   Lakshmi TRV, 2017, ADV INTELL SYST, V516, P397, DOI 10.1007/978-981-10-3156-4_41
   Lakshmi TRV, 2017, ENG SCI TECHNOL, V20, P143, DOI 10.1016/j.jestch.2016.06.006
   Lakshmi TV, 2023, IN PRESS, pEng1
   Li ZC, 2011, IEEE T IMAGE PROCESS, V20, P2017, DOI 10.1109/TIP.2010.2099128
   Li ZL, 2020, IEEE T GEOSCI REMOTE, V58, P3685, DOI 10.1109/TGRS.2019.2960889
   Lu Z, 2021, IEEE T PATT ANAL MAC
   Mishra NB, 2014, INT J REMOTE SENS, V35, P1175, DOI 10.1080/01431161.2013.876120
   Narmatha P, 2023, BIOMED SIGNAL PROCES, V86, DOI 10.1016/j.bspc.2023.105264
   Othmana E, 2016, INT J REMOTE SENS, V37, P2149, DOI 10.1080/01431161.2016.1171928
   Park S, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030354
   Passah A, 2021, IET IMAGE PROCESS, V15, P1285, DOI 10.1049/ipr2.12104
   Penatti Otavio A. B., 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P44, DOI 10.1109/CVPRW.2015.7301382
   Qi KL, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.042005
   [钱晓亮 Qian Xiaoliang], 2018, [遥感学报, Journal of Remote Sensing], V22, P758
   Sheng GF, 2012, INT J REMOTE SENS, V33, P2395, DOI 10.1080/01431161.2011.608740
   Shyu CR, 2007, IEEE T GEOSCI REMOTE, V45, P839, DOI 10.1109/TGRS.2006.890579
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stumpf A, 2011, REMOTE SENS ENVIRON, V115, P2564, DOI 10.1016/j.rse.2011.05.013
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Thirumala VL, 2021, TURK J ELECTR ENG CO, V29, P994, DOI 10.3906/elk-2004-7
   Vijaya Lakshmi TR, 2017, COGNITIVE INFORMATIC, P403
   Walker JS, 2007, PHOTOGRAMM ENG REM S, V73, P577, DOI 10.14358/PERS.73.5.577
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Yang Y., 2010, P 18 SIGSPATIAL INT, P270, DOI DOI 10.1145/1869790.1869829
   Yuksel ME, 2018, J INTELL FUZZY SYST, V34, P2273, DOI 10.3233/JIFS-171307
   Zhang F, 2015, IEEE T GEOSCI REMOTE, V53, P2175, DOI 10.1109/TGRS.2014.2357078
   Zhang WC, 2014, IEEE GEOSCI REMOTE S, V11, P74, DOI 10.1109/LGRS.2013.2246538
   Zhao B, 2016, IEEE T GEOSCI REMOTE, V54, P2108, DOI 10.1109/TGRS.2015.2496185
   Zhao LJ, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.035004
   Zheng XW, 2013, IEEE GEOSCI REMOTE S, V10, P652, DOI 10.1109/LGRS.2012.2216499
   Zhou WX, 2018, ISPRS J PHOTOGRAMM, V145, P197, DOI 10.1016/j.isprsjprs.2018.01.004
   Zou JY, 2016, INFORM SCIENCES, V348, P209, DOI 10.1016/j.ins.2016.02.021
   Zou Q, 2015, IEEE GEOSCI REMOTE S, V12, P2321, DOI 10.1109/LGRS.2015.2475299
NR 68
TC 3
Z9 3
U1 5
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 16
PY 2023
DI 10.1007/s11042-023-16291-z
EA AUG 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P2QW4
UT WOS:001049147100002
DA 2024-07-18
ER

PT J
AU Sharma, A
   Singh, S
   Ratna, S
AF Sharma, Anuj
   Singh, Sukhdeep
   Ratna, S.
TI Graph Neural Network Operators: a Review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Graph neural networks; GNN convolutional operators; Deep learning; Graph
   structural representation
AB Graph Neural Networks (GNN) is one of the promising machine learning areas in solving real world problems such as social networks, recommender systems, computer vision and pattern recognition. One of the important component of GNN is GNN operators which are responsible to train GNN graph structured data and forward learning nodes information to other layers. This review focus on recent advancements of GNN operators in detail. The rich Mathematical nature of GNN operators has been discussed for selected GNN operators. The review also highlights different benchmark graph structured datasets and presents results using different GNN operators. We have included thorough discussion for state-of-the-art in this field including limitations and future directions. Overall, the review covers important areas of GNN as GNN operators from future research directions point of view and real world applications perspective.
C1 [Sharma, Anuj; Ratna, S.] Panjab Univ, Dept Comp Sci & Applicat, Chandigarh, India.
   [Singh, Sukhdeep] DM Coll, Comp Sci Dept, Moga, India.
C3 Panjab University
RP Sharma, A (corresponding author), Panjab Univ, Dept Comp Sci & Applicat, Chandigarh, India.
EM anujs@pu.ac.in
RI Sharma, Anuj/AAX-5778-2020
CR Bai S, 2020, Arxiv, DOI arXiv:1901.08150
   Baumgartner J, 2020, Arxiv, DOI [arXiv:2001.08435, DOI 10.1609/ICWSM.V14I1.7347]
   bitcoin otc, US
   Brockschmidt M, 2019, 25TH AMERICAS CONFERENCE ON INFORMATION SYSTEMS (AMCIS 2019)
   Brody S, 2022, Arxiv, DOI arXiv:2105.14491
   btc-alpha, BITC ALPH
   Buterez David, 2022, Adv. Neural Inf. Process. Syst., V35, P19746
   Carlson A, 2010, AAAI CONF ARTIF INTE, P1306
   Chen M, 2020, Arxiv, DOI arXiv:2007.02133
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Deng C, 2022, LEARNING GRAPHS C, P3
   Ding Kaize, 2022, ACM SIGKDD Explorations Newsletter, P61, DOI 10.1145/3575637.3575646
   Du J, 2018, Arxiv, DOI [arXiv:1710.10370, 10.48550/arXiv.1710.10370]
   Dudzik A. J., 2022, Advances in neural information processing systems, P20635
   Fey M, 2018, PROC CVPR IEEE, P869, DOI 10.1109/CVPR.2018.00097
   Fu GJ, 2022, 39 INT C MACHINE LEA
   Gasteiger J, 2022, P MACHINE LEARNING R, V198, P9
   Gilmer J, 2017, PR MACH LEARN RES, V70
   Gravina A, 2023, INT C LEARN REPR
   Guan C., 2022, INT C MACH LEARN, P7968
   Hamilton W.L., 2020, Graph Representation Learning, DOI 10.2200/s01045ed1v01y202009aim046
   Hamilton WL, 2017, ADV NEUR IN, V30
   Hamilton WL., 2020, SYNTHESIS LECT ARTIF, V14, P1, DOI [10.1007/978-3-031-01588-5, DOI 10.2200/S01045ED1V01Y202009AIM046, 10.2200/s01045ed1v01y202009aim046]
   He Yixuan, 2022, P 39 INT C MACH LEAR, P8581
   He Yixuan, 2022, PMLR, P40
   Hu ZN, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2704, DOI 10.1145/3366423.3380027
   Huang T., 2022, LEARNING GRAPHS C, V198, P8
   Itoh TD, 2022, NEURAL NETWORKS, V145, P356, DOI 10.1016/j.neunet.2021.11.001
   Jin Y, 2022, INT CONF DAT MIN WOR, P682, DOI 10.1109/ICDMW58026.2022.00094
   Lai KH, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P461, DOI 10.1145/3394486.3403088
   Lan SY, 2022, 38 INT C MACHINE LEA
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Li GH, 2021, PR MACH LEARN RES, V139
   Li Y., 2016, P 4 INT C LEARNING R
   Liu J., 2022, Advances in Neural Information Processing Systems, V35, P21358
   Liu Y., 2022, Adv. Neural Inf. Proces. Syst., V35, P19414
   Lu ZK, 2023, DATA SCI ENG, V8, P36, DOI 10.1007/s41019-023-00206-x
   Bianchi FM, 2021, Arxiv, DOI arXiv:1901.01343
   Nikolentzos G, 2021, J ARTIF INTELL RES, V72, P943
   Ong E., 2022, P 1 LEARNING GRAPHS, V198, P43
   Parvathaneni Naga S, 2023, J HEALTHC ENG
   Qin Y, 2022, Advances in neural information processing systems, V35, P54
   Ranjan E, 2020, AAAI CONF ARTIF INTE, V34, P5470
   Ranjan Rishabh, 2022, P ADV NEURAL INFORM, P22518
   Rossi RA, 2015, AAAI CONF ARTIF INTE, P4292
   Sanchez-Gonzalez A, 2020, P 37 INT C MACHINE L
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P81, DOI 10.1109/TNN.2008.2005141
   Sen P, 2008, AI MAG, V29, P93, DOI 10.1609/aimag.v29i3.2157
   Shi WJ, 2020, PROC CVPR IEEE, P1708, DOI 10.1109/CVPR42600.2020.00178
   Shi Y., 2021, P 30 INT JOINT C ART, P1548, DOI [10.24963/ijcai.2021/214, DOI 10.24963/IJCAI.2021/214, 10.24963]
   Tang Jianheng, 2022, INT C MACHINE LEARNI, P21076
   Wang XY, 2022, PR MACH LEARN RES
   Wang Z, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P1949, DOI 10.1145/3534678.3539387
   Weisfeiler B., 1968, Nauchno-Technicheskaya Informatsiya, V2, P12
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xie T, 2018, PHYS REV LETT, V120, DOI 10.1103/PhysRevLett.120.145301
   Ying Z, 2019, P 33 AAAI C ART INT, P10848
   You JX, 2019, PR MACH LEARN RES, V97
   Yuen B, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-96723-8
   Zhang H, 2022, P 5 MLSYS, P1
   Zhang Z., 2022, Advances in neural information processing systems, V35, P6074
   Zhang ZW, 2022, IEEE T KNOWL DATA EN, V34, P249, DOI 10.1109/TKDE.2020.2981333
   Zhao H., 2020, arXiv
   Zhou J, 2020, AI OPEN, V1, P57, DOI 10.1016/j.aiopen.2021.01.001
   Zhu ZC, 2022, PR MACH LEARN RES
   Zitnik M, 2017, BIOINFORMATICS, V33, pI190, DOI 10.1093/bioinformatics/btx252
   Zuo S, 2022, DiP-GNN: Discriminative pre-training of graph neural networks
NR 69
TC 1
Z9 1
U1 80
U2 169
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 15
PY 2023
DI 10.1007/s11042-023-16440-4
EA AUG 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P6LA0
UT WOS:001051759100008
DA 2024-07-18
ER

PT J
AU Xie, MY
   Liu, ZW
   Xiang, SC
   Liu, T
   Fu, YZ
AF Xie, Mingye
   Liu, Zongwei
   Xiang, Suncheng
   Liu, Ting
   Fu, Yuzhuo
TI Editing outdoor scenes with a large annotated synthetic dataset
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Scene editing; Synthetic data generation; Generative adversarial network
   (GAN); Attribute editing
AB With the continuous popularization of smartphones and their ever-evolving photographic capabilities, individuals can easily take a large number of photos in their daily lives, creating a natural impetus for image editing. With the ability of style-based GAN, images can be reasonably edited on specific semantics by manipulating in latent space of the generator, particularly for human facial photographs. However, such methods are heavily rely on the datasets with diverse data and rich semantic annotations at the same time. Unfortunately, there is no such dataset for outdoor scenes with diverse and complex structural content, which makes current editing methods almost ineffective. To overcome these challenges, we first construct an extensive synthetic outdoor scene dataset with fine-grained semantic annotations based on an automated process. Based on it, we propose an editing network dedicated to multi-class annotations that can efficiently edit specific attributes while preserving others as much as possible. Extensive experiments evince that our method achieves better performance in outdoor scene editing, especially in regards to distance and viewpoint across several outdoor scene datasets.
C1 [Xie, Mingye; Liu, Zongwei; Liu, Ting; Fu, Yuzhuo] Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
   [Xiang, Suncheng] Shanghai Jiao Tong Univ, Sch Biomed Engn, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University; Shanghai Jiao Tong University
RP Xie, MY (corresponding author), Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
EM xiemingye@sjtu.edu.cn; 18090938508@sjtu.edu.cn;
   xiangsuncheng17@sjtu.edu.cn; louisa_liu@sjtu.edu.cn; yzfu@sjtu.edu.cn
OI Xie, Mingye/0000-0001-9826-9806
FU National Natural Science Foundation of China [61977045]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No.61977045).
CR Abdal R, 2019, IEEE I CONF COMP VIS, P4431, DOI 10.1109/ICCV.2019.00453
   Chen XL, 2020, Arxiv, DOI arXiv:2003.04297
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Harkonen E., 2020, Adv. Neural Inf. Process. Syst., V33
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jahanian Ali, 2020, ICLR
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Laffont PY, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601101
   Northcutt CG, 2021, Arxiv, DOI arXiv:2103.14749
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Patashnik O, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2065, DOI 10.1109/ICCV48922.2021.00209
   Patterson G, 2012, PROC CVPR IEEE, P2751, DOI 10.1109/CVPR.2012.6247998
   Radford A, 2021, PR MACH LEARN RES, V139
   Richter SR, 2017, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2017.243
   Ros G, 2016, PROC CVPR IEEE, P3234, DOI 10.1109/CVPR.2016.352
   Shen YJ, 2021, PROC CVPR IEEE, P1532, DOI 10.1109/CVPR46437.2021.00158
   Shen Yujun, 2020, P IEEE CVF C COMP VI, P9243, DOI DOI 10.1109/CVPR42600.2020.00926
   Sun P, 2020, PROC CVPR IEEE, P2443, DOI 10.1109/CVPR42600.2020.00252
   Thompson W. B., 2002, Journal of Graphics Tools, V7, P1, DOI 10.1080/10867651.2002.10487550
   Tov O, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459838
   Xiang SC, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102822
   Xie Meng, 2022, 2022 Global Reliability and Prognostics and Health Management (PHM-Yantai), P1, DOI 10.1109/PHM-Yantai55411.2022.9942195
   Xie MY, 2022, INT CONF ACOUST SPEE, P3244, DOI 10.1109/ICASSP43922.2022.9746768
   Yang CY, 2021, INT J COMPUT VISION, V129, P1451, DOI 10.1007/s11263-020-01429-5
   Yao Shunyu., 2018, ADV NEURAL INFORM PR
   Yu FS, 2016, Arxiv, DOI arXiv:1506.03365
   Zamir AR, 2014, IEEE T PATTERN ANAL, V36, P1546, DOI 10.1109/TPAMI.2014.2299799
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
NR 32
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 9
PY 2023
DI 10.1007/s11042-023-16385-8
EA AUG 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O6VD2
UT WOS:001045151400001
DA 2024-07-18
ER

PT J
AU Saeed, N
   Malik, H
   Naeem, A
   Bashir, U
AF Saeed, Nimra
   Malik, Hassaan
   Naeem, Ahmad
   Bashir, Umair
TI Incorporating big data and IoT in intelligent ecosystems:
   state-of-the-arts, challenges and opportunities, and future directions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Big data; IoT; Intelligent ecosystem; Smart environment; Health
ID DATA ANALYTICS; DATA-STORAGE; THINGS IOT; INTERNET; MANAGEMENT; SYSTEM;
   CLOUD; IDENTIFICATION; ENVIRONMENTS; OPTIMIZATION
AB The present study discusses big data (BD) and Internet of Things (IoT)-based applications in intelligent ecosystems. The purpose of these areas is to identify important application domains, recent development, and data architectures, and to handle any challenges that arise. To our knowledge, this is the first systematic literature review (SLR) of this kind, reviewing research works published in peer-reviewed venues between 2011 and 2022 utilizing a 4-step selection technique of recognition, monitoring, eligibility, and selection. To study these records, an SLR was conducted, and six key research questions (RQs) were answered. The findings suggest that merging BD and IoT technology opens up new opportunities for intelligent ecosystem applications that monitor, protect, and improve natural resources in the real world. Among the topics covered in this survey are intelligent environment analysis, intelligent farming, ultraprecision agriculture, industrial IoTs, and intelligent disaster warning. Finally, we review the most frequently used BD and IoT approaches, which we believe will serve as a platform for future transdisciplinary research in intelligent environments and smart cities.
C1 [Saeed, Nimra; Malik, Hassaan; Bashir, Umair] Natl Coll Business Adm & Econ Lahore, Dept Comp Sci, Sub Campus Multan, Multan 6000, Pakistan.
   [Malik, Hassaan; Naeem, Ahmad] Univ Management & Technol, Sch Syst & Technol, Dept Comp Sci, Lahore 54000, Pakistan.
C3 University of Management & Technology (UMT)
RP Malik, H (corresponding author), Natl Coll Business Adm & Econ Lahore, Dept Comp Sci, Sub Campus Multan, Multan 6000, Pakistan.; Malik, H (corresponding author), Univ Management & Technol, Sch Syst & Technol, Dept Comp Sci, Lahore 54000, Pakistan.
EM f2019288004@umt.edu.pk
OI Malik, Hassaan/0000-0002-4402-5088
CR Akoka J, 2017, COMPUT STAND INTER, V54, P105, DOI 10.1016/j.csi.2017.01.004
   Al Mamun MA, 2019, IEEE SENS J, V19, P7771, DOI 10.1109/JSEN.2019.2919352
   Al-Sarem M, 2019, IEEE ACCESS, V7, P152788, DOI 10.1109/ACCESS.2019.2947855
   Alam F, 2017, IEEE ACCESS, V5, P9533, DOI 10.1109/ACCESS.2017.2697839
   Alshamsi A., 2017, 2017 International Conference on Electrical and Computing Technologies and Applications (ICECTA), P1, DOI 10.1109/ICECTA.2017.8251998
   Ardagna D, 2018, FUTURE GENER COMP SY, V89, P548, DOI 10.1016/j.future.2018.07.014
   Arridha R, 2017, INT J SPACE-BASED SI, V7, P82, DOI 10.1504/IJSSC.2017.10008038
   Asaithambi SPR, 2021, BIG DATA COGN COMPUT, V5, DOI 10.3390/bdcc5010006
   Asghari P, 2019, COMPUT NETW, V148, P241, DOI 10.1016/j.comnet.2018.12.008
   Ashton K., RFID journal, V22 22, P97, DOI DOI 10.1145/2967977
   Avci Cigdem, 2020, Big Data Analytics, V5, P1, DOI 10.1186/s41044-020-00045-1
   Babar M, 2019, FUTURE GENER COMP SY, V96, P398, DOI 10.1016/j.future.2019.02.035
   Babar M, 2019, J AMB INTEL HUM COMP, V10, P4167, DOI 10.1007/s12652-018-0820-5
   Babar M, 2017, FUTURE GENER COMP SY, V77, P65, DOI 10.1016/j.future.2017.07.029
   Banafa A, 2017, NEWSLETTER
   Baranwal T, 2016, 2016 6th International Conference - Cloud System and Big Data Engineering (Confluence), P597, DOI 10.1109/CONFLUENCE.2016.7508189
   Bellini P, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12031607
   Ben Atitallah S, 2020, COMPUT SCI REV, V38, DOI 10.1016/j.cosrev.2020.100303
   Berlian MH, 2016, 2016 INTERNATIONAL ELECTRONICS SYMPOSIUM (IES), P403, DOI 10.1109/ELECSYM.2016.7861040
   Berouine A., 2017, 2017 3rd International conference of cloud computing technologies and applications (CloudTech), P1, DOI DOI 10.1109/CLOUDTECH.2017.8284729
   Bibri SE, 2018, SUSTAIN CITIES SOC, V38, P230, DOI 10.1016/j.scs.2017.12.034
   Birong Xu, 2017, 2017 IEEE 2nd International Conference on Big Data Analysis (ICBDA), P178, DOI 10.1109/ICBDA.2017.8078802
   Boulila W., 2014, J MULTIMEDIA PROCESS, V5, P12
   Boulila W., 2009, World Academy of Science, Engineering and Technology, V9, P222
   Boulila W, 2019, EARTH SCI INFORM, V12, P295, DOI 10.1007/s12145-018-00376-7
   Boulila W, 2018, EARTH SCI INFORM, V11, P31, DOI 10.1007/s12145-017-0313-7
   Boulila W, 2017, J COMPUT SCI-NETH, V23, P58, DOI 10.1016/j.jocs.2017.10.006
   Carvalho DF, 2018, 2018 IEEE SENSORS APPLICATIONS SYMPOSIUM (SAS), P297
   Chaczko Z, 2018, IEEE INT CONF INTELL, P57, DOI 10.1109/INES.2018.8523957
   Chang HY, 2018, INT SYMP COMP CONS, P302, DOI 10.1109/IS3C.2018.00083
   Chebbi I, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP)
   Chebbi I, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP), P31, DOI 10.1109/ATSIP.2016.7523046
   Chebbi I, 2015, LECT NOTES ARTIF INT, V9330, P638, DOI 10.1007/978-3-319-24306-1_62
   Chen M, 2018, IEEE COMMUN MAG, V56, P14, DOI 10.1109/MCOM.2018.1700571
   Chin J, 2017, PROC IEEE INT SYMP, P2050, DOI 10.1109/ISIE.2017.8001570
   Cicirelli F, 2019, 2019 IEEE 5TH WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P35, DOI [10.1109/wf-iot.2019.8767246, 10.1109/WF-IoT.2019.8767246]
   Cook D., 2004, SMART ENV TECHNOLOGY, DOI [10.1002/047168659X, DOI 10.1002/047168659X]
   Corbellini A, 2017, INFORM SYST, V63, P1, DOI 10.1016/j.is.2016.07.009
   Dai HN, 2020, ENTERP INF SYST-UK, V14, P1279, DOI 10.1080/17517575.2019.1633689
   De Mauro A, 2016, LIBR REV, V65, P122, DOI 10.1108/LR-06-2015-0061
   De Mauro A, 2015, AIP CONF PROC, V1644, P97, DOI 10.1063/1.4907823
   Dinl S, 2015, I CONF SENS TECHNOL, P677, DOI 10.1109/ICSensT.2015.7438483
   Dupont C, 2017, 2017 GLOBAL INTERNET OF THINGS SUMMIT (GIOTS 2017), P49
   El-Din DM, 2021, RECENT ADV INTELLIGE, P511
   Elarabi T, 2015, IEEE INT SYMP SIGNAL, P297, DOI 10.1109/ISSPIT.2015.7394347
   Evans D., 2011, Whitepaper, DOI DOI 10.1109/IEEESTD.2007.373646
   Fang SF, 2014, IEEE T IND INFORM, V10, P1596, DOI 10.1109/TII.2014.2302638
   Fazio M, 2015, PROCEDIA COMPUT SCI, V52, P500, DOI 10.1016/j.procs.2015.05.023
   Ferchichi A, 2018, KNOWL INF SYST, V55, P719, DOI 10.1007/s10115-017-1102-9
   Ferchichi A, 2017, ECOL INFORM, V37, P24, DOI 10.1016/j.ecoinf.2016.11.006
   Flume apache, US
   Gao F, 2019, COGN COMPUT, V11, P809, DOI 10.1007/s12559-018-9563-z
   Gomez C, 2019, J AMB INTEL SMART EN, V11, P23, DOI 10.3233/AIS-180509
   Romero CDG, 2016, LECT NOTES COMPUT SC, V9714, P457, DOI 10.1007/978-3-319-40973-3_46
   Goswami P, 2021, P INT C DISTR COMP N, P31, DOI DOI 10.1145/3427477.3429988
   Gu F, 2017, WASTE MANAGE, V68, P434, DOI 10.1016/j.wasman.2017.07.037
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Hajjaji Y, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP)
   Hammad M, 2020, COMPUT SCI REV, V37, DOI 10.1016/j.cosrev.2020.100266
   Hanga KM, 2019, COMPUT SCI REV, V34, DOI 10.1016/j.cosrev.2019.08.002
   He ZW, 2018, IEEE ACCESS, V6, P75598, DOI 10.1109/ACCESS.2018.2883421
   Horita F, 2023, INFORM SYST FRONT, V25, P275, DOI 10.1007/s10796-020-10075-8
   Huang C, 2021, MOB INF SYST, V2021, DOI 10.1155/2021/6674479
   Huang Y, 2018, IEEE ACCESS, V6, P78678, DOI 10.1109/ACCESS.2018.2885142
   Hutton B, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0092508
   Islam SMR, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10020148
   Ito Tomoki, 2020, 2020 IEEE International Conference on Informatics, IoT, and Enabling Technologies (ICIoT), P463, DOI 10.1109/ICIoT48696.2020.9089597
   Jabbar J., 2020, International Journal of Engineering Technology, V9, P454, DOI DOI 10.14419/IJET.V9I2.30396
   Jabbar J, 2020, INT J COMPUT SCI NET, V20, P158
   Jiang H, 2020, COGN COMPUT, V12, P176, DOI 10.1007/s12559-019-09661-z
   Jiang RF, 2013, 2013 12TH INTERNATIONAL SYMPOSIUM ON DISTRIBUTED COMPUTING AND APPLICATIONS TO BUSINESS, ENGINEERING & SCIENCE (DCABES), P176, DOI 10.1109/DCABES.2013.39
   Kadir EA, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING, COMPUTER SCIENCE AND INFORMATICS (EECSI 2018), P281
   Kafka apache, US
   Kang YS, 2016, IEEE SENS J, V16, P485, DOI 10.1109/JSEN.2015.2483499
   Katal A, 2013, INT CONF CONTEMP, P404, DOI 10.1109/IC3.2013.6612229
   Khan M, 2020, INT J PARALLEL PROG, V48, P178, DOI 10.1007/s10766-018-0573-y
   Khorshed MT, 2015, 2 AS PAC WORLD C COM, P1
   Koo D, 2015, PROCEDIA ENGINEER, V118, P489, DOI 10.1016/j.proeng.2015.08.465
   Lavric A, 2018, 2018 14TH INTERNATIONAL CONFERENCE ON DEVELOPMENT AND APPLICATION SYSTEMS (DAS), P74, DOI 10.1109/DAAS.2018.8396074
   Lazarescu MT, 2013, IEEE J EM SEL TOP C, V3, P45, DOI 10.1109/JETCAS.2013.2243032
   Leal B, 2010, INTERNET OF THINGS-BOOK, P3, DOI 10.1007/978-1-4419-1674-7_1
   Lee JG, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.4135
   Li XM, 2022, FUTURE GENER COMP SY, V128, P167, DOI 10.1016/j.future.2021.10.006
   Lieberman J, 2017, IEEE INT CONF BIG DA, P4592, DOI 10.1109/BigData.2017.8258503
   Liu L, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8040568
   Lu SQ, 2015, 2015 IEEE FIRST INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING SERVICE AND APPLICATIONS (BIGDATASERVICE 2015), P218, DOI 10.1109/BigDataService.2015.68
   Mahmud M, 2018, IEEE T NEUR NET LEAR, V29, P2063, DOI 10.1109/TNNLS.2018.2790388
   Manman L, 2020, PROC IEEE 8 INT C CO, P1
   Talavera JM, 2017, COMPUT ELECTRON AGR, V142, P283, DOI 10.1016/j.compag.2017.09.015
   Masood F, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12111893
   Meng XR, 2016, J MACH LEARN RES, V17
   Middel A, 2019, LANDSCAPE URBAN PLAN, V183, P122, DOI 10.1016/j.landurbplan.2018.12.001
   Mukherjee S, 2020, INFORM SYST FRONT, V22, P23, DOI 10.1007/s10796-019-09965-3
   Narayanan K, 2017, MICROWAVE J, V60, P110
   Onal AC, 2017, IEEE INT CONF BIG DA, P2037, DOI 10.1109/BigData.2017.8258150
   Ouafiq El Mehdi, 2021, Human Centred Intelligent Systems. Proceedings of KES-HCIS 2020 Conference. Smart Innovation, Systems and Technologies (SIST 189), P269, DOI 10.1007/978-981-15-5784-2_22
   Pallavi S, 2017, 2017 INTERNATIONAL CONFERENCE ON BIG DATA, IOT AND DATA SCIENCE (BID), P44, DOI 10.1109/BID.2017.8336571
   Pan GH, 2018, 2018 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND BIG DATA (ICAIBD), P224, DOI 10.1109/ICAIBD.2018.8396199
   Pang ZB, 2015, INFORM SYST FRONT, V17, P289, DOI 10.1007/s10796-012-9374-9
   Peffers K, 2007, J MANAGE INFORM SYST, V24, P45, DOI 10.2753/MIS0742-1222240302
   Peng M, 2020, IEEE ACCESS, V8, P128490, DOI 10.1109/ACCESS.2020.3008289
   Raimundo RJ, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12031598
   Rajeswari S, 2017, PROCEEDINGS OF 2017 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL (I2C2)
   Rehman MHU, 2019, FUTURE GENER COMP SY, V99, P247, DOI 10.1016/j.future.2019.04.020
   Rodriguez-Mier P, 2019, COGN COMPUT, V11, P418, DOI 10.1007/s12559-019-09630-6
   Roy S, 2017, 2017 8TH ANNUAL INDUSTRIAL AUTOMATION AND ELECTROMECHANICAL ENGINEERING CONFERENCE (IEMECON), P303, DOI 10.1109/IEMECON.2017.8079610
   Saeed H, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0266462
   Safaei M, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12030328
   Safaei M, 2020, SOFTWARE PRACT EXPER, V50, P428, DOI 10.1002/spe.2785
   Sebestyén V, 2021, FRONT ENV SCI-SWITZ, V9, DOI 10.3389/fenvs.2021.619092
   Shadroo S, 2018, COMPUT NETW, V139, P19, DOI 10.1016/j.comnet.2018.04.001
   Shafique K, 2020, IEEE ACCESS, V8, P23022, DOI 10.1109/ACCESS.2020.2970118
   Shah SA, 2019, IEEE ACCESS, V7, P54595, DOI 10.1109/ACCESS.2019.2913340
   Shah SA, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8040508
   Shanzhi Chen, 2017, IEEE Communications Standards Magazine, V1, P70, DOI 10.1109/MCOMSTD.2017.1700015
   Shi Q, 2015, TRANSPORT RES C-EMER, V58, P380, DOI 10.1016/j.trc.2015.02.022
   Sood SK, 2018, SUSTAIN COMPUT-INFOR, V20, P102, DOI 10.1016/j.suscom.2017.12.001
   Srinivasulu P, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON ELECTRICAL, INSTRUMENTATION AND COMMUNICATION ENGINEERING (ICEICE)
   Suciu G., 2017, Black sea conference on communications and networking (blackseacom), 2017 ieee international, P1, DOI DOI 10.1109/ECAI.2017.8166451
   Tanoli SAK, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10061983
   Thorat A, 2017, 2017 INTERNATIONAL CONFERENCE ON BIG DATA, IOT AND DATA SCIENCE (BID), P193, DOI 10.1109/BID.2017.8336597
   Tickle R, 2019, COGN COMPUT, V11, P434, DOI 10.1007/s12559-019-09638-y
   Tsai CF, 2018, PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL CONFERENCE ON ADVANCED MANUFACTURING (IEEE ICAM), P170, DOI 10.1109/AMCON.2018.8614989
   Tu L, 2020, J SUPERCOMPUT, V76, P5175, DOI 10.1007/s11227-019-02773-1
   Tyagi SKS, 2021, IEEE T IND INFORM, V17, P7734, DOI 10.1109/TII.2021.3055818
   Ullo SL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20113113
   Villari M, 2014, 2014 INTERNATIONAL CONFERENCE ON SMART COMPUTING WORKSHOPS (SMARTCOMP WORKSHOPS), P9, DOI 10.1109/SMARTCOMP-W.2014.7046676
   Vuran MC, 2018, AD HOC NETW, V81, P160, DOI 10.1016/j.adhoc.2018.07.017
   Wang H, 2015, TENCON IEEE REGION, DOI 10.1109/TENCON.2015.7372918
   Wang MZ, 2020, COMPUT COMMUN, V157, P124, DOI 10.1016/j.comcom.2020.04.023
   Wang YY, 2020, SHOCK VIB, V2020, DOI 10.1155/2020/1850286
   Ward J.S., 2013, UNDEFINED DATA SURVE
   Warnakulasooriya K, 2018, P INT C SYST SCI ENG, P1, DOI DOI 10.1109/ICSSE.2018.8520238
   Wixted AJ, 2016, IEEE SENSOR
   Xu J, 2015, 2015 INTERNATIONAL CONFERENCE ON CYBER-ENABLED DISTRIBUTED COMPUTING AND KNOWLEDGE DISCOVERY, P372, DOI 10.1109/CyberC.2015.17
   Yang CT, 2019, FUTURE GENER COMP SY, V96, P731, DOI 10.1016/j.future.2018.02.041
   Yang CJ, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON BIG DATA ANALYSIS (ICBDA), P504, DOI 10.1109/ICBDA.2017.8078684
   Yang L, 2013, TECHNOL FORECAST SOC, V80, P1854, DOI 10.1016/j.techfore.2012.07.011
   Yuxi Liu, 2012, Proceedings of the 2012 Fifth International Conference on Intelligent Computation Technology and Automation (ICICTA 2012), P197, DOI 10.1109/ICICTA.2012.56
   Zahid A, 2019, PLANT METHODS, V15, DOI 10.1186/s13007-019-0522-9
   Zeinab K.A. M., 2017, World Scientific News, V2, P126
   Zhang AZ, 2019, COGN COMPUT, V11, P789, DOI 10.1007/s12559-018-9582-9
   Zhang F, 2018, SUSTAIN COMPUT-INFOR, V20, P210, DOI 10.1016/j.suscom.2017.08.003
   Zhang L, 2019, INFORM FUSION, V50, P20, DOI 10.1016/j.inffus.2018.09.015
   Zhang Y, 2019, CONCURR COMP-PRACT E, V31, DOI 10.1002/cpe.4751
NR 145
TC 1
Z9 1
U1 5
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20699
EP 20741
DI 10.1007/s11042-023-16328-3
EA AUG 2023
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001042601200010
DA 2024-07-18
ER

PT J
AU Sucharita, S
   Sahu, B
   Swarnkar, T
   Meher, SK
AF Sucharita, Swati
   Sahu, Barnali
   Swarnkar, Tripti
   Meher, Saroj K.
TI Classification of cancer microarray data using a two-step feature
   selection framework with moth-flame optimization and extreme learning
   machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cancer microarray data classification; Moth-flame optimization; Extreme
   learning machine; Feature selection; Ensemble of filters
ID ALGORITHM
AB Analysis of microarray gene expression data for the detection/classification of cancer is one of the common approaches adopted worldwide. However, many genes (features) with correlated and irrelevant information in these data sets become the bottleneck for a classification model and significantly deteriorate its performance. A large number of features with fewer samples further make the classification task more cumbersome. Several feature selection methods (both filter and wrapper) have been proposed individually to address this issue, but choosing the best one among them is an open challenge. Our objective in the present study is to simplify the search for the best feature selection method without relying completely on individual methods and propose a two-step hybrid approach. In the first step, we use an ensemble of filter-based heterogeneous feature selection methods. These selected features then undergo the second step of wrapper-based selection. We propose to use the bio-inspired method called Moth-flame optimization (MFO) with an extreme learning machine (ELM) as its fitness function in this step. The motivation for using ELM is to leverage its learning strategy with one-pass processing of samples. Using this hybrid feature selection method, we proposed a classification model for Cancer Micraoarray data, where ELM is also considered as a classifier. The work demonstrates the superiority of the proposed model over other state-of-the-art methods in classifying cancer data from four different microarray gene expression datasets. Several measurement indexes are used for the performance evaluation of models.
C1 [Sucharita, Swati; Sahu, Barnali] Siksha O Anusandhan Deemed Univ, Dept Comp Sci & Engn, Bhubaneswar, India.
   [Swarnkar, Tripti] Siksha O Anusandhan Deemed Univ, Dept Comp Applicat, Bhubaneswar, India.
   [Meher, Saroj K.] Indian Stat Inst, Syst Sci & Informat Unit, Bangalore, India.
C3 Siksha 'O' Anusandhan University; Siksha 'O' Anusandhan University;
   Indian Statistical Institute; Indian Statistical Institute Bangalore
RP Sucharita, S (corresponding author), Siksha O Anusandhan Deemed Univ, Dept Comp Sci & Engn, Bhubaneswar, India.
EM swatisucharita08@gmail.com
RI Swarnkar, Tripti/ABT-9034-2022
OI Swarnkar, Tripti/0000-0002-1853-4874; SUCHARITA,
   SWATI/0000-0003-3409-3295
CR Ab Hamid TMT, 2021, MACH LEARN APPL, V5, DOI 10.1016/j.mlwa.2021.100054
   Abdulla M, 2020, ARTIF INTELL MED, V108, DOI 10.1016/j.artmed.2020.101941
   Alomari OA, 2021, KNOWL-BASED SYST, V223, DOI 10.1016/j.knosys.2021.107034
   Alzaqebah M., 2020, INT J EL COMP ENG SY, V10, P3684, DOI [10.11591/ijece.v10i4.pp3672-3684, DOI 10.11591/IJECE.V10I4.PP3672-3684]
   Arowolo MO., 2016, AJPAS J, V3, P1
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Bolón-Canedo V, 2019, INFORM FUSION, V52, P1, DOI 10.1016/j.inffus.2018.11.008
   Cao JH, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/287816
   Chuang LY, 2011, COMPUT BIOL MED, V41, P228, DOI 10.1016/j.compbiomed.2011.02.004
   Dabba A, 2021, EXPERT SYST APPL, V166, DOI 10.1016/j.eswa.2020.114012
   Dabba A, 2021, J AMB INTEL HUM COMP, V12, P2731, DOI 10.1007/s12652-020-02434-9
   Ding YY, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-S2-S12
   Haznedar B, 2017, MENDELEY DATA, V2
   Jackson LA., 2012, DIAGNOSIS SEXUALLY T, P3343
   Khurma RA., 2005, J THEORET APPL INF T, V98, P3794
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Lazar C, 2012, IEEE ACM T COMPUT BI, V9, P1106, DOI 10.1109/TCBB.2012.33
   Li CW, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-41225-x
   Li GZ, 2007, PROCEEDINGS OF THE 7TH IEEE INTERNATIONAL SYMPOSIUM ON BIOINFORMATICS AND BIOENGINEERING, VOLS I AND II, P1439
   Li Y, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12081234
   Liang S, 2018, COMPUT STRUCT BIOTEC, V16, P88, DOI 10.1016/j.csbj.2018.02.005
   Lin GQ, 2020, J CLEAN PROD, V253, DOI 10.1016/j.jclepro.2020.119966
   Mirjalili S, 2015, KNOWL-BASED SYST, V89, P228, DOI 10.1016/j.knosys.2015.07.006
   Mollaee M, 2016, BIOCYBERN BIOMED ENG, V36, P521, DOI 10.1016/j.bbe.2016.05.001
   Muduli D, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101912
   Nadimi-Shahraki MH, 2021, COMPUTERS, V10, DOI 10.3390/computers10110136
   Pashaei E, 2016, 2016 3RD IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL AND HEALTH INFORMATICS, P308, DOI 10.1109/BHI.2016.7455896
   Prakash J, 2020, MEASUREMENT, V151, DOI 10.1016/j.measurement.2019.107225
   Radovic M, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-016-1423-9
   Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344
   Santos V, 2014, PROC TECH, V17, P223, DOI 10.1016/j.protcy.2014.10.232
   Singh N, 2021, CHEMOMETR INTELL LAB, V217, DOI 10.1016/j.chemolab.2021.104396
   Uzma, 2021, KNOWL-BASED SYST, V234, DOI 10.1016/j.knosys.2021.107560
   Wang AG, 2022, COMPUT BIOL MED, V142, DOI 10.1016/j.compbiomed.2021.105208
   Wang MJ, 2017, NEUROCOMPUTING, V267, P69, DOI 10.1016/j.neucom.2017.04.060
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Zhang G, 2020, INTERDISCIP SCI, V12, P288, DOI 10.1007/s12539-020-00372-w
   Zhu ZX, 2007, PATTERN RECOGN, V40, P3236, DOI 10.1016/j.patcog.2007.02.007
NR 38
TC 2
Z9 2
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 21319
EP 21346
DI 10.1007/s11042-023-16353-2
EA AUG 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040962400003
DA 2024-07-18
ER

PT J
AU Ayoub, A
   Naeem, EA
   El-Shafai, W
   El-Samie, FEA
   Hamad, EKI
   EL-Rabaie, EM
AF Ayoub, Abeer
   Naeem, Ensherah A.
   El-Shafai, Walid
   El-Samie, Fathi E. Abd
   Hamad, Ehab K. I.
   EL-Rabaie, El-Sayed M.
TI Video quality enhancement using dual-transmission-map dehazing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hazy visible frame; NIR frame; Video sequence; Dual-transmission-map
   dehazing; Gradient-domain guided filtering; Dynamic range; Homomorphic
   processing
ID IMAGE
AB Video imaging in open environments faces several problems such as the haze problem. Haze has a degradation effect on images. To enhance the video quality, we use a dual-transmission-map dehazing algorithm. We work on two video sequences: a Near Infrared (NIR) sequence and a visible sequence. We modify this dual-transmission-map dehazing algorithm by applying pre-processing on frames before the dehazing process to enhance the frame quality. All frames may have some noise or limited dynamic range due to sensor measurement errors that can be amplified in the haze removal process if ignored. We use different types of image enhancement techniques to either remove noise or control the dynamic range before the dehazing process. The dehazing algorithm can be implemented using a dual-transmission map depending on the Dark Channel Prior (DCP) method. Gradient-domain guided filtering is used to refine the two obtained transmission maps to obtain the best results for the dehazed frames. We investigate the effect of a regularization parameter & omega; on the visible and NIR dehazed frames without and with enhancement techniques. Results for visible video are more obvious than those for NIR video, because hazy visible frames have a large amount of haze compared to hazy NIR frames. We use the Peak Signal-to-Noise Ratio (PSNR) and correlation between hazy and dehazed frames after the dehazing process as evaluation metrics for the proposed algorithm. The proposed algorithm provides good results in the enhancement of two types of video as proved by the spectral entropy of dehazed frames.
C1 [Ayoub, Abeer; El-Shafai, Walid; El-Samie, Fathi E. Abd; EL-Rabaie, El-Sayed M.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
   [Naeem, Ensherah A.] Suez Univ, Fac Technol & Educ, Elect Dept, Suez 43527, Egypt.
   [El-Shafai, Walid] Prince Sultan Univ, Comp Sci Dept, Secur Engn Lab, Riyadh 11586, Saudi Arabia.
   [El-Samie, Fathi E. Abd] Princess Nourah Bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Informat Technol, POB 84428, Riyadh 11671, Saudi Arabia.
   [Hamad, Ehab K. I.] Aswan Univ, Fac Engn, Elect Engn Dept, Aswan 81542, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University; Egyptian Knowledge
   Bank (EKB); Suez University; Prince Sultan University; Princess Nourah
   bint Abdulrahman University; Egyptian Knowledge Bank (EKB); Aswan
   University
RP Ayoub, A (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
EM abeerayoub777@gmail.com; ensherah_naeem@yahoo.com;
   eng.waled.elshafai@gmail.com; fathi_sayed@yahoo.com;
   e.hamad@aswu.edu.eg; srabie1@yahoo.com
RI El-Shafai, Walid/AAG-4796-2021
OI El-Shafai, Walid/0000-0001-7509-2120
FU Prince Sultan University
FX & nbsp;The authors are very grateful to all institutions in the
   affiliation list for successfully performing this research work. The
   authors would like to thank Prince Sultan University for support.
CR Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Biagetti G, 2017, IEEE J BIOMED HEALTH, V21, P328, DOI 10.1109/JBHI.2016.2530943
   Bonneel N, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818107
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Cai Z, 2021, EUROGRAPHICS, DOI [10.2312/EGS.20211018, DOI 10.2312/EGS.20211018]
   Du YX, 2018, IEEE COMPUT SOC CONF, P843, DOI 10.1109/CVPRW.2018.00116
   Ehsan SM, 2021, IEEE ACCESS, V9, P89055, DOI 10.1109/ACCESS.2021.3090078
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Feris RS, 2012, IEEE T MULTIMEDIA, V14, P28, DOI 10.1109/TMM.2011.2170666
   He JX, 2016, IEEE IMAGE PROC, P2246, DOI 10.1109/ICIP.2016.7532758
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Kim I, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 4, P77, DOI 10.5220/0006132400770088
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   Koschmieder H., 1924, Beitraege Phys. Atmosp., P33
   Thanh LT, 2019, ASIA-PAC CONF COMMUN, P36, DOI [10.1109/APCC47188.2019.9026457, 10.1109/apcc47188.2019.9026457]
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Liu Y, 2017, IEEE ACCESS, V5, P8890, DOI 10.1109/ACCESS.2017.2710305
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Narasimhan S., 2015, PROC IEEE WORKSHOP, P598
   Orcioni S, 2018, NEUROCOMPUTING, V292, P165, DOI 10.1016/j.neucom.2018.03.007
   Orcioni S, 2017, NEUROCOMPUTING, V267, P605, DOI 10.1016/j.neucom.2017.06.029
   Pal NS, 2018, TEM J, V7, P859, DOI 10.18421/TEM74-26
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Saini M, 2012, IEEE T MULTIMEDIA, V14, P555, DOI 10.1109/TMM.2012.2186957
   Solbo S, 2004, IEEE T GEOSCI REMOTE, V42, P711, DOI 10.1109/TGRS.2003.821885
   Swamy S., 2020, INT RES J ENG TECHNO, V7, P50
   Zhang H, 2014, IEEE IMAGE PROC, P4542, DOI 10.1109/ICIP.2014.7025921
   Zhang JW, 2011, VISUAL COMPUT, V27, P749, DOI 10.1007/s00371-011-0569-8
   Zhang Y, 2021, COMPUT GRAPH FORUM, V40, P179, DOI 10.1111/cgf.142624
NR 31
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20289
EP 20306
DI 10.1007/s11042-023-15937-2
EA JUL 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040925900011
DA 2024-07-18
ER

PT J
AU Yadava, GT
   Nagaraja, BG
   Jayanna, HS
AF Yadava, G. Thimmaraja
   Nagaraja, B. G.
   Jayanna, H. S.
TI Amalgamation of noise elimination and TDNN acoustic modelling techniques
   for the advancements in continuous Kannada ASR system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Continuous Kannada speech data; ASR; IVRS; TDNN; WER
ID SPECTRAL SUBTRACTION; SPEECH RECOGNITION
AB The enhancements made to an earlier continuous Kannada automatic speech recognition (ASR) spoken query system (SQS) under real-time environment are demonstrated in this work. The earlier SQS was corrupted by various types of degradation, leading to significantly less accurate speech recognition. In the advanced SQS, the proposed background noise suppression block is introduced before the speech feature extraction part. The experimental results show that the proposed noise reduction algorithm has given better performance in terms of audibility and intelligibility of speech sound compared to conventional spectral subtraction and magnitude squared spectrum estimators. Therefore, the proposed noise elimination algorithm is applied to the corrupted continuous Kannada speech data for its background noise removal. Using a combination of noise reduction and time delay neural network (TDNN) acoustic modeling techniques, there is a 1.87% improvement in terms of word error rate (WER) compared to the earlier SQS. The online testing statistics of the newly developed continuous Kannada ASR system by 500 speakers under real-time conditions are also demonstrated in this work. The algorithms source code and ASR models are made publicly available at
C1 [Yadava, G. Thimmaraja] Nitte Meenakshi Inst Technol, E &CE, Bengaluru 560064, Karnataka, India.
   [Nagaraja, B. G.] Vidyavardhaka Coll Engn, E &CE, Gokulam 3 Stage, Mysuru 570002, Karnataka, India.
   [Jayanna, H. S.] Siddaganga Inst Technol, IS &E, BH Rd, Tumkur 572103, Karnataka, India.
C3 Nitte Meenakshi Institute of Technology; Vidyavardhaka College of
   Engineering; Siddaganga Institute of Technology
RP Yadava, GT (corresponding author), Nitte Meenakshi Inst Technol, E &CE, Bengaluru 560064, Karnataka, India.
EM thimrajyadav@gmail.com; nagarajbg@gmail.com; jayannahs@gmail.com
RI Yadava G, Thimmaraja/AEO-3181-2022
OI Yadava G, Thimmaraja/0000-0002-3266-9732
CR [Anonymous], 2000, ITU-T Recommendation P.862
   Berouti M., 1979, ICASSP 79. 1979 IEEE International Conference on Acoustics, Speech and Signal Processing, P208
   BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209
   Cappé O, 1994, IEEE T SPEECH AUDI P, V2, P345, DOI 10.1109/89.279283
   Dua M, 2019, J AMB INTEL HUM COMP, V10, P2301, DOI 10.1007/s12652-018-0828-x
   EPHRAIM Y, 1984, IEEE T ACOUST SPEECH, V32, P1109, DOI 10.1109/TASSP.1984.1164453
   Evans NWD, 2006, INT CONF ACOUST SPEE, P145
   Gustafsson H, 2001, IEEE T SPEECH AUDI P, V9, P799, DOI 10.1109/89.966083
   Hirsch H., 2000, AUTOMATIC SPEECH REC
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054
   Hu Y, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1447
   Jainar SJ, 2020, INT J SIGNAL IMAGING, V12, P1, DOI 10.1504/IJSISE.2020.113552
   Kamath S, 2002, INT CONF ACOUST SPEE, P4164
   Kitaoka N, 2002, 7 INT C SPOK LANG PR, P477
   Liu H, 2019, CIRC SYST SIGNAL PR, V38, P4840, DOI 10.1007/s00034-019-01092-3
   LOCKWOOD P, 1992, SPEECH COMMUN, V11, P215, DOI 10.1016/0167-6393(92)90016-Z
   Loizou PC, 2005, IEEE T SPEECH AUDI P, V13, P857, DOI 10.1109/TSA.2005.851929
   Lu Y, 2008, SPEECH COMMUN, V50, P453, DOI 10.1016/j.specom.2008.01.003
   Papoulis A., 1965, PROBABILITY RANDOM V
   Philipos CL., 2007, SPEECH ENHANCEMENT T
   Povey D., 2011, IEEE 2011 WORKSH AUT
   Kumar PSP, 2020, CIRC SYST SIGNAL PR, V39, P391, DOI 10.1007/s00034-019-01189-9
   Thimmaraja YG, 2021, INT J SPEECH TECHNOL, V24, P165, DOI 10.1007/s10772-020-09786-9
   Thimmaraja YG, 2018, SPEECH ENHANCEMENT C, V22, P639
   Upadhyaya P, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P786, DOI 10.1109/WiSPNET.2017.8299868
   Virag N, 1999, IEEE T SPEECH AUDI P, V7, P126, DOI 10.1109/89.748118
   Yadava T, 2017, INT J SPEECH TECHNOL, V20, P635, DOI 10.1007/s10772-017-9428-y
   Yoma NB, 1998, IEEE T SPEECH AUDI P, V6, P579, DOI 10.1109/89.725325
NR 28
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19953
EP 19968
DI 10.1007/s11042-023-16100-7
EA JUL 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040015500003
DA 2024-07-18
ER

PT J
AU Jaber, MM
   Ali, MH
   Abd, SK
   Jassim, MM
   Alkhayyat, A
   Majid, MS
   Alkhuwaylidee, AR
   Alyousif, S
AF Jaber, Mustafa Musa
   Ali, Mohammed Hasan
   Abd, Sura Khalil
   Jassim, Mustafa Mohammed
   Alkhayyat, Ahmed
   Majid, Mohammed Sh.
   Alkhuwaylidee, Ahmed Rashid
   Alyousif, Shahad
TI Resnet-based deep learning multilayer fault detection model-based fault
   diagnosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ResNet; Fault diagnosis; Automation; Multilayer; Deep learning; Fault
   detection model; SVM
ID CLOUD; VIRTUALIZATION; NETWORK
AB Fault detection has taken on critical relevance in today's automated manufacturing processes. Defect tolerance, dependability, and safety are some of the fundamental design attributes of complex engineering systems provided by this method. Fault Diagnosis is made more difficult by a lack of performance; data-driven design and the capacity to transfer learning are also essential considerations. This paper proposes the ResNet-based deep learning multilayer fault detection model (ResNet-DLMFDM) to enrich high performance, design, and transmission-learning skills. Wavelet pyramid packet decomposition and each sub drive coefficient utilize the input of each deep research network channel for multi-kernel domain analysis. Pseudo-label networks have been developed conceptually to investigate different interval lengths of sequential functionality and to gather local database flow sequence functions to improve existing error detection processes. Experiment findings reveal that the proposed approach outperforms current algorithms regarding data correctness, storage space utilization, computational complexity, noiselessness, and transfer performance. The results are obtained by analyzing the multi-kernel and showing the domain ratio of 87.6%, increased storage space ratio of 88.6%, wavelet decomposition performance ratio of 84.5%, and the high accuracy of the data transmission ratio of 83.5%, and the noiseless diagnosis ratio of 93.8%.
C1 [Jaber, Mustafa Musa] Iraqi Commiss Comp & Informat, Informat Inst Postgrad Studies, Baghdad, Iraq.
   [Jaber, Mustafa Musa] Al turath Univ Coll, Dept Comp Sci, Baghdad, Iraq.
   [Ali, Mohammed Hasan] Imam Jaafar Al Sadiq Univ, Fac Informat Technol, Comp Tech Engn Dept, Najaf 10023, Iraq.
   [Abd, Sura Khalil] Minist higher Educ & Sci Res, Directorate Res & Dev, Baghdad, Iraq.
   [Jassim, Mustafa Mohammed] Al Farahidi Univ, Dept Med Instruments Engn Tech, Baghdad 10011, Iraq.
   [Alkhayyat, Ahmed] Islamic Univ, Coll Tech Engn, Najaf, Iraq.
   [Majid, Mohammed Sh.] Al Mustaqbal Univ Coll, Med Instrumentat Tech Engn Dept, Babylon, Iraq.
   [Alkhuwaylidee, Ahmed Rashid] Mazaya Univ Coll, Comp Tech Engn, Thi Qar, Iraq.
   [Alyousif, Shahad] Gulf Univ, Coll Engn, Dept Elect & Elect Engn, Sanad 26489, Bahrain.
   [Alyousif, Shahad] Univ Mashreq, Res Ctr, Baghdad, Iraq.
C3 Imam Jaa'far al-Sadiq University; Islamic University College;
   Al-Mustaqbal University College
RP Jaber, MM (corresponding author), Iraqi Commiss Comp & Informat, Informat Inst Postgrad Studies, Baghdad, Iraq.; Jaber, MM (corresponding author), Al turath Univ Coll, Dept Comp Sci, Baghdad, Iraq.
EM Mustafa.jaber@turath.edu.iq; sura.khalil@duc.edu.iq;
   m.altaee@alfarahidiuc.edu.iq; Dr.shahad.alyousif@gulfuniversity.edu.bh
RI Alkhuwaylidee, Ahmed Rashid/ABL-3928-2022; Sh .majid,
   mohammed/GLR-6850-2022; alkhayyat, ahmed/B-6434-2018; Jassim, Mustafa
   Mohammed/GOK-1635-2022
OI Alkhuwaylidee, Ahmed Rashid/0000-0002-1542-1188; Sh .majid,
   mohammed/0000-0002-4295-7391; alkhayyat, ahmed/0000-0002-1270-4713;
   Jassim, Mustafa Mohammed/0000-0002-3739-0343
CR Basheer S, 2019, INT J SOFTW INNOV, V7, P41, DOI 10.4018/IJSI.2019040104
   Baskar S., 2016, ASIAN J RES SOCIAL S, V6, P519, DOI DOI 10.5958/2249-7315.2016.00980.1
   Baskar S., 2018, J COMPUT THEOR NANOS, V15, P1395, DOI [10.1166/jctn.2018.7249, DOI 10.1166/jctn.2018.7249]
   Chen YW, 2021, APPL SOFT COMPUT, V100, DOI 10.1016/j.asoc.2020.106907
   Deng Z, 2020, CAAI T INTELL TECHNO, V5, P141, DOI 10.1049/trit.2019.0094
   Duan J, 2021, J VIB CONTROL, V27, P1036, DOI 10.1177/1077546320936506
   Edalatpanah SA, 2020, CAAI T INTELL TECHNO, V5, P94, DOI 10.1049/trit.2020.0016
   Ezhilmaran D, 2016, CYBERN INF TECHNOL, V16, P205, DOI 10.1515/cait-2016-0044
   Feng XM, 2020, CAAI T INTELL TECHNO, V5, P128, DOI 10.1049/trit.2019.0065
   Fuyuan Xiao, 2021, IEEE Transactions on Fuzzy Systems, V29, P186, DOI 10.1109/TFUZZ.2020.3002431
   Gao MY, 2021, FORESTS, V12, DOI 10.3390/f12020212
   Guo FY, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/8891424
   Hongtao Hu, 2021, 2021 6th International Conference on Intelligent Computing and Signal Processing (ICSP), P1036, DOI 10.1109/ICSP51882.2021.9408785
   Jagadeesan A, 2016, ADV BIOINFORM BIOMED, P37, DOI 10.4018/978-1-5225-0427-6.ch003
   Jiang FC, 2017, NEUROCOMPUTING, V256, P90, DOI 10.1016/j.neucom.2016.08.134
   Jin YR, 2021, MEASUREMENT, V173, DOI 10.1016/j.measurement.2020.108500
   Khalaf OI., 2014, INT J ENG RES APPL, V4, P172
   Li CAJ, 2021, NEUROCOMPUTING, V439, P197, DOI 10.1016/j.neucom.2021.01.099
   Luo J, 2022, J VIB CONTROL, V28, P1379, DOI 10.1177/1077546321993563
   Peifu Yao, 2021, 2021 IEEE 5th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC), P728, DOI 10.1109/IAEAC50856.2021.9391030
   Pengyu Cheng, 2021, Advances in Simulation and Process Modelling. Proceedings of the Second International Symposium on Simulation and Process Modelling (ISSPM 2020). Advances in Intelligent Systems and Computing (AISC 1305), P459, DOI 10.1007/978-981-33-4575-1_44
   Qian L, 2022, MACHINES, V10, DOI 10.3390/machines10070521
   Molano JIR, 2018, J AMB INTEL HUM COMP, V9, P709, DOI 10.1007/s12652-017-0469-5
   Saravanan V, 2013, RES J AGR FORESTRY S, V1, P5
   Sathishkumar VE, 2020, COMPUT COMMUN, V153, P353, DOI 10.1016/j.comcom.2020.02.007
   Shakeel PM, 2018, HEALTH INF SCI SYST, V6, DOI 10.1007/s13755-018-0054-0
   Shankar A, 2021, J AMB INTEL HUM COMP, V12, P2285, DOI 10.1007/s12652-020-02325-z
   Shaofeng Fu, 2020, Journal of Physics: Conference Series, V1682, DOI 10.1088/1742-6596/1682/1/012004
   Shoucong Xiong, 2020, Journal of Physics: Conference Series, V1707, DOI 10.1088/1742-6596/1707/1/012010
   Wan LJ, 2021, IEEE ACCESS, V9, P28753, DOI 10.1109/ACCESS.2021.3059221
   Wang CY, 2021, J LOW FREQ NOISE V A, V40, P588, DOI 10.1177/1461348419889511
   Wang K, 2021, IEEE T IND INFORM, V17, P678, DOI 10.1109/TII.2020.2971584
   Wang Y, 2021, IEEE SENS J, V21, P10946, DOI 10.1109/JSEN.2021.3061595
   WEI C, 2019, 2019 22 INT C ELECT, P1
   Wen L, 2020, NEURAL COMPUT APPL, V32, P6111, DOI 10.1007/s00521-019-04097-w
   Yang B, 2020, SCANNING, V2020, DOI 10.1155/2020/9176509
   Yang CT, 2014, J SUPERCOMPUT, V69, P1103, DOI 10.1007/s11227-013-1045-1
   Yang DG, 2021, NEURAL NETWORKS, V141, P133, DOI 10.1016/j.neunet.2021.04.003
   Yu JB, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3039614
   Zhang K, 2021, MECH SYST SIGNAL PR, V161, DOI 10.1016/j.ymssp.2021.107963
   Zhao MH, 2021, IEEE T IND ELECTRON, V68, P2587, DOI 10.1109/TIE.2020.2972458
   Zhao MH, 2020, MEASUREMENT, V152, DOI 10.1016/j.measurement.2019.107331
   Zhou A, 2019, CLUSTER COMPUT, V22, P11619, DOI 10.1007/s10586-017-1426-y
   Zhuang ZL, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9091823
NR 44
TC 4
Z9 4
U1 16
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19277
EP 19300
DI 10.1007/s11042-023-16233-9
EA JUL 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001037378900001
DA 2024-07-18
ER

PT J
AU Wu, B
   Xie, D
   Chen, FL
   Zhu, HJ
   Wang, XL
   Zeng, YY
AF Wu, Bin
   Xie, Dong
   Chen, Fulong
   Zhu, Huijun
   Wang, Xueli
   Zeng, Yangyang
TI Compressed sensing based visually secure multi-secret image
   encryption-sharing scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Semi-tensor product; Compressed sensing; Secret image
   sharing
ID NEURAL-NETWORKS; CHAOS
AB The existing encryption schemes of visually secure image have drawbacks, such as excessive concentration of image data and insufficient resistance to various attacks in the transmission channel. Based on the combination of compressed sensing and secret image sharing, this paper presents a visually secure multi-secret image encryption-sharing scheme, which effectively solves the above shortcomings. First, the plain image is perceived as sparse and encrypted by semi-tensor compressed sensing for security. Secondly, the encrypted image is divided into n shadows by secret image sharing. This solves the problem of image data being too centralized and meets the requirements of risk dispersion and intrusion tolerance. Finally, the n shadows are embedded into n carriers by steganography technology to form a visually secure image. On the basis of guaranteeing the quality of image reconstruction, this paper has high compression and security.
C1 [Wu, Bin; Xie, Dong; Chen, Fulong; Wang, Xueli; Zeng, Yangyang] Anhui Normal Univ, Sch Comp & Informat, Wuhu 241002, Peoples R China.
   [Zhu, Huijun] Nanyang Inst Technol, Sch Digital Media, Nanyang 473000, Henan, Peoples R China.
C3 Anhui Normal University; Nanyang Institute of Technology
RP Xie, D (corresponding author), Anhui Normal Univ, Sch Comp & Informat, Wuhu 241002, Peoples R China.
EM xiedong@ahnu.edu.cn
RI Wu, Bin/KHD-4133-2024; chen, xu/JNT-3068-2023
FU National Natural Science Foundation of China [61801004, 61972438];
   Natural Science Foundation of Anhui Province [1808085QF211]; Science and
   Technology Department of Henan Province [212102310297]; Key Research and
   Development Projects in Anhui Province [202004a05020002]
FX AcknowledgementsThis paper is partially supported by the National
   Natural Science Foundation of China (Grant Nos. 61801004 and 61972438),
   the Natural Science Foundation of Anhui Province (Grant No.
   1808085QF211), the Science and Technology Department of Henan Province
   (No. 212102310297), and the Key Research and Development Projects in
   Anhui Province (Grant No. 202004a05020002).
CR Belazi A, 2019, IEEE ACCESS, V7, P36667, DOI 10.1109/ACCESS.2019.2906292
   Chai XL, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107684
   Chai XL, 2017, SIGNAL PROCESS, V134, P35, DOI 10.1016/j.sigpro.2016.11.016
   Chen LP, 2020, NEURAL NETWORKS, V125, P174, DOI 10.1016/j.neunet.2020.02.008
   Cheng DZ, 2007, J SYST SCI COMPLEX, V20, P304, DOI 10.1007/s11424-007-9027-0
   Chih-Ching Thien, 2002, Computers & Graphics, V26, P765, DOI 10.1016/S0097-8493(02)00131-0
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   GAO H, 2022, IEEE T NEURAL NETW L, P1
   Gao HH, 2022, IEEE T COMPUT SOC SY, V9, P1725, DOI 10.1109/TCSS.2022.3178416
   Gao HH, 2023, IEEE T NETW SCI ENG, V10, P2978, DOI 10.1109/TNSE.2022.3163144
   Gao H, 2022, IEEE T INTELL TRANSP, V23, P17301, DOI 10.1109/TITS.2022.3154650
   Gong LH, 2019, OPT LASER ENG, V121, P169, DOI 10.1016/j.optlaseng.2019.03.006
   Gupta M, 2021, INTELLIGENT SESSION
   Hu GZ, 2021, SIGNAL PROCESS, V178, DOI 10.1016/j.sigpro.2020.107790
   Hua ZY, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.107998
   Huo DM, 2021, OPT COMMUN, V492, DOI 10.1016/j.optcom.2021.126976
   Jiang DH, 2021, SIGNAL PROCESS, V188, DOI 10.1016/j.sigpro.2021.108220
   Luo SY, 2023, SIGNAL PROCESS, V206, DOI 10.1016/j.sigpro.2023.108931
   Man ZL, 2021, CHAOS SOLITON FRACT, V152, DOI 10.1016/j.chaos.2021.111318
   Mani P, 2019, INFORM SCIENCES, V491, P74, DOI 10.1016/j.ins.2019.04.007
   Meng KJ, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116221
   Sahasrabuddhe A, 2021, INFORM SCIENCES, V550, P252, DOI 10.1016/j.ins.2020.10.031
   Shi CY, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14040773
   Varga D, 2022, SIGNALS-BASEL, V3, P483, DOI 10.3390/signals3030028
   Wang H, 2019, SIGNAL PROCESS, V155, P218, DOI 10.1016/j.sigpro.2018.10.001
   Wang JM, 2020, INFORM SCIENCES, V512, P693, DOI 10.1016/j.ins.2019.09.071
   Wang XY, 2019, OPT LASER ENG, V115, P107, DOI 10.1016/j.optlaseng.2018.11.010
   Wang XY, 2021, INFORM SCIENCES, V574, P505, DOI 10.1016/j.ins.2021.06.032
   Wen WY, 2020, SIGNAL PROCESS, V173, DOI 10.1016/j.sigpro.2020.107580
   Wu B, 2022, DIGIT SIGNAL PROCESS, V123, DOI 10.1016/j.dsp.2022.103391
   Xie D, 2019, IEEE ACCESS, V99
   Xie D, 2019, DIGIT SIGNAL PROCESS, V95, DOI 10.1016/j.dsp.2019.102587
   Xie D, 2016, DIGIT SIGNAL PROCESS, V58, P85, DOI 10.1016/j.dsp.2016.07.003
   Xiong LZ, 2021, SIGNAL PROCESS, V185, DOI 10.1016/j.sigpro.2021.108064
   Xiong LZ, 2020, SIGNAL PROCESS, V173, DOI 10.1016/j.sigpro.2020.107571
   Xu QY, 2020, OPT LASER ENG, V134, DOI 10.1016/j.optlaseng.2020.106178
   Xu QY, 2019, OPT LASER ENG, V121, P203, DOI 10.1016/j.optlaseng.2019.04.011
   Yadav M, 2022, MULTIMED TOOLS APPL, V81, P22677, DOI 10.1007/s11042-021-10625-5
   Yan XH, 2021, INFORM SCIENCES, V562, P475, DOI 10.1016/j.ins.2021.03.029
   Yang FF, 2020, OPT LASER ENG, V129, DOI 10.1016/j.optlaseng.2020.106031
   Yu Y, 2017, MEMET COMPUT
   Zarebnia M, 2021, CHAOS SOLITON FRACT, V152, DOI 10.1016/j.chaos.2021.111402
   Zhang SJ, 2021, MATH COMPUT SIMULAT, V190, P723, DOI 10.1016/j.matcom.2021.06.012
   Zhang X, 2018, IEEE PHOTONICS J, V10, DOI [10.1109/JPHOT.2018.2859257, 10.1109/JPHOT.2018.2818715]
   Zhou WJ, 2022, OPT LASER ENG, V149, DOI 10.1016/j.optlaseng.2021.106782
NR 45
TC 1
Z9 1
U1 12
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 18919
EP 18941
DI 10.1007/s11042-023-15922-9
EA JUL 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001035725000001
DA 2024-07-18
ER

PT J
AU Jiang, ZG
   Zaheer, W
   Wali, A
   Gilani, SAM
AF Jiang, Zhiguo
   Zaheer, Waneeza
   Wali, Aamir
   Gilani, S. A. M.
TI Visual sentiment analysis using data-augmented deep transfer learning
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual sentiment analysis; Transfer learning; VGG16; Data augmentation
ID PREDICTION
AB There has been a growing trend among users of social media platforms to express their emotions using visual content. Visual sentiment analysis is the process of understanding the emotional polarity of images or videos and is still considered a challenging problem in artificial intelligence. Most of the existing models are based on robust machine learning or deep learning techniques. The idea of using deep transfer learning techniques for visual sentiment analysis is fairly new. In this paper, we propose a new approach using data-augmented-transfer learning architecture consisting of a pre-trained VGG16 model that is fine-tuned using SVM with augmented training data. For fine-tuning and evaluation, we initially use two Twitter image datasets. We further validated the proposed model on a third dataset. The commonly used geometric augmentation methods such as rotation, zoom range, width shift, height shift, shear range and horizontal flip were are used. We compare our proposed VGG16-SVM model with 3 other state-of-the-art deep models commonly used for transfer learning and 4 machine learning models (besides SVM) used for fine-tuning. The results show that VGG16-SVM produces the overall best accuracy (94%) and recall (96%) among all transfer learning and machine learning pairs. We also show that our proposed model outperforms all previous studies that use the same dataset.
C1 [Jiang, Zhiguo] Anhui Vocat Coll Def Technol, Sch Elect Technol, Luan, Peoples R China.
   [Zaheer, Waneeza; Wali, Aamir; Gilani, S. A. M.] Natl Univ Comp & Emerging Sci, Dept Comp Sci, Lahore, Pakistan.
RP Wali, A (corresponding author), Natl Univ Comp & Emerging Sci, Dept Comp Sci, Lahore, Pakistan.
EM zhiguo_jiang77@outlook.com; l105472@lhr.nu.edu.pk; aamir.wali@nu.edu.pk;
   asif.gilani@nu.edu.pk
OI , Aamir/0009-0001-6571-6611; Wali, Aamir/0000-0002-5314-6113
CR Ahsan U, 2017, IEEE IJCNN, P1372, DOI 10.1109/IJCNN.2017.7966013
   Ain QT, 2017, INT J ADV COMPUT SC, V8, P424
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Borth D, 2013, SENTIBANK LARGE SCAL, P459
   Cai GY, 2017, INT SYM COMPUT INTEL, P252, DOI 10.1109/ISCID.2017.172
   Cambria Erik, 2012, Cognitive Behavioural Systems (COST 2012). International Training School. Revised Selected Papers, P144, DOI 10.1007/978-3-642-34584-5_11
   Campos V, 2017, IMAGE VISION COMPUT, V65, P15, DOI 10.1016/j.imavis.2017.01.011
   Chandrasekaran G, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12031030
   Chen SQ, 2017, C IND ELECT APPL, P1033, DOI 10.1109/ICIEA.2017.8282991
   Fan SJ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P217, DOI 10.1145/3123266.3123445
   Giancristofaro GT, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P2113, DOI 10.1109/ITSC.2016.7795898
   Goring S, 2018, INT C QUAL MULT EXP, P1
   Hassan SZ etal, 2020, PREPRINT
   Huang C-C, 2019, HUMAN FACE SENTIMENT, P1
   Islam J, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCES ON BIG DATA AND CLOUD COMPUTING (BDCLOUD 2016) SOCIAL COMPUTING AND NETWORKING (SOCIALCOM 2016) SUSTAINABLE COMPUTING AND COMMUNICATIONS (SUSTAINCOM 2016) (BDCLOUD-SOCIALCOM-SUSTAINCOM 2016), P124, DOI 10.1109/BDCloud-SocialCom-SustainCom.2016.29
   Ji RR, 2016, FRONT COMPUT SCI-CHI, V10, P602, DOI 10.1007/s11704-016-5453-2
   Li ZY, 2021, SURG ENDOSC, V35, P6903, DOI 10.1007/s00464-020-08198-9
   Li ZH, 2019, MULTIMED TOOLS APPL, V78, P6939, DOI 10.1007/s11042-018-6445-z
   Liu W, 2019, PREPRINT
   McDuff D, 2015, IEEE T AFFECT COMPUT, V6, P223, DOI 10.1109/TAFFC.2014.2384198
   Mittal N, 2018, 2018 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2018), P684, DOI 10.1109/WI.2018.00-11
   Poria S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P873, DOI 10.18653/v1/P17-1081
   Poria S, 2017, NEUROCOMPUTING, V261, P217, DOI 10.1016/j.neucom.2016.09.117
   Siersdorfer S., 2010, ACM MM, P715
   Sun M, 2016, DISCOVERING AFFECTIV, P1
   Vadicamo L, 2017, IEEE INT CONF COMP V, P308, DOI 10.1109/ICCVW.2017.45
   Wang C, 2019, PROC CVPR IEEE, P31, DOI 10.1109/CVPR.2019.00012
   Wang FJ, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATICS: CONCEPTS, THEORY AND APPLICATIONS (ICAICTA 2018), P66, DOI 10.1109/ICAICTA.2018.8541312
   Wang YL, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P1584, DOI 10.1109/ICDMW.2015.142
   Wu L., 2021, WEAKLY SUPERVISED IN
   Wu LF, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11041404
   Yadav A, 2020, ARTIF INTELL REV, V53, P4335, DOI 10.1007/s10462-019-09794-5
   Yang JF, 2018, IEEE T MULTIMEDIA, V20, P2513, DOI 10.1109/TMM.2018.2803520
   Yang L, 2019, PROC CVPR IEEE, P364, DOI 10.1109/CVPR.2019.00045
   Yazdavar AH, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0226248
   You QZ, 2017, AAAI CONF ARTIF INTE, P231
   You QZ, 2015, AAAI CONF ARTIF INTE, P381
   Yuan J., 2013, P 2 INT WORKSH ISS S, P1
   Zhang K, 2021, KNOWL-BASED SYST, V216, DOI 10.1016/j.knosys.2021.106803
   Zisad SN, 2021, ALGORITHMS, V14, DOI 10.3390/a14070213
NR 40
TC 2
Z9 2
U1 4
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17233
EP 17249
DI 10.1007/s11042-023-16262-4
EA JUL 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001034665300005
DA 2024-07-18
ER

PT J
AU Manafifard, M
AF Manafifard, Mehrtash
TI A review on camera calibration in soccer videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Calibration; Feature extraction; Lines; Registration; Player
   localization; Camera parameters
ID PARTICLE SWARM OPTIMIZATION; SELF-CALIBRATION; IMAGE SEQUENCE; VIRTUAL
   ADVERTISEMENT; MULTIPLAYER DETECTION; FIELD REGISTRATION; PLAYER
   TRACKING; SPORTS VIDEO; BALL; REPRESENTATIONS
AB Camera calibration has attracted much attention, as a primary step of various soccer game analyses, such as real-world player tracking and offside detection. Moreover, metric evaluation of player detection and tracking can be provided via camera calibration, which is a crucial task for player localization assessment. Camera calibration is also challenging due to the blur and duplicated lines, freely moving camera in broadcast streams and lack of well distributed 3D features on the playfield. The main goal of this paper is to review the state-of-the-art in camera calibration and its different prior steps, including transformation computation, feature extraction, image to model registration, image to image registration, camera parameters estimation and conclude future research directions.
C1 [Manafifard, Mehrtash] Arak Univ Technol, Fac Earth Sci, Arak, Iran.
RP Manafifard, M (corresponding author), Arak Univ Technol, Fac Earth Sci, Arak, Iran.
EM mehrtash64@yahoo.com
OI Manafifard, Mehrtash/0000-0003-0722-8617
CR Alemán-Flores M, 2014, PATTERN RECOGN, V47, P89, DOI 10.1016/j.patcog.2013.05.011
   Alvarez Luis, 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P406, DOI 10.1007/978-3-642-33275-3_50
   Alvarez L, 2016, J REAL-TIME IMAGE PR, V11, P287, DOI 10.1007/s11554-013-0360-3
   Alvarez L, 2011, J MATH IMAGING VIS, V39, P75, DOI 10.1007/s10851-010-0226-2
   [Anonymous], 2008, PROC INT C CONTENT B
   [Anonymous], 2007, P 5 INT C COMP VIS S
   Assfalg E, 2003, COMPUT VIS IMAGE UND, V92, P285, DOI 10.1016/j.cviu.2003.06.004
   Barceló L, 2005, LECT NOTES COMPUT SC, V3568, P237
   Barceló L, 2005, LECT NOTES COMPUT SC, V3522, P77
   Barros RML, 2007, J SPORT SCI MED, V6, P233
   Bastian A, 2019, 2019 2ND INTERNATIONAL CONFERENCE OF COMPUTER AND INFORMATICS ENGINEERING (IC2IE 2019), P1, DOI 10.1109/ic2ie47452.2019.8940861
   Battikh T, 2011, MULTIMED TOOLS APPL, V51, P997, DOI 10.1007/s11042-009-0434-1
   Baysal S, 2016, IEEE T CIRC SYST VID, V26, P1350, DOI 10.1109/TCSVT.2015.2455713
   Bebie T, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P898, DOI 10.1109/ICIP.1998.723665
   Beetz M, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2066
   Beetz Michael., 2006, AAMAS, P42
   Bozorgpour A, 2015, IRAN CONF ELECTR ENG, P787, DOI 10.1109/IranianCEE.2015.7146320
   BU J, 2011, P IEEE INT C MULT EX, P1
   Cai Z.Q., 2005, Fifth International Conference on Information, Communications and Signal Processing, P538
   Carvalho PCP, 1998, SIBGRAPI '98 - INTERNATIONAL SYMPOSIUM ON COMPUTER GRAPHICS, IMAGE PROCESSING, AND VISION, PROCEEDINGS, P388, DOI 10.1109/SIBGRA.1998.722777
   Chen JH, 2018, IEEE WINT CONF APPL, P287, DOI 10.1109/WACV.2018.00038
   Chen JH, 2017, COMPUT VIS IMAGE UND, V159, P59, DOI 10.1016/j.cviu.2016.10.017
   Choi K, 2011, PATTERN RECOGN LETT, V32, P1274, DOI 10.1016/j.patrec.2011.03.009
   Chu YJ, 2022, IEEE COMPUT SOC CONF, P3522, DOI 10.1109/CVPRW56347.2022.00396
   Cioppa A, 2018, IEEE COMPUT SOC CONF, P1846, DOI 10.1109/CVPRW.2018.00229
   Cioppa A, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01469-1
   Cioppa A, 2021, IEEE COMPUT SOC CONF, P4532, DOI 10.1109/CVPRW53098.2021.00511
   Citraro L, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01064-7
   Cuevas C, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107278
   D'Orazio T., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4105, DOI 10.1109/ICPR.2010.998
   D'Orazio T, 2010, PATTERN RECOGN, V43, P2911, DOI 10.1016/j.patcog.2010.03.009
   D'Orazio T, 2009, COMPUT VIS IMAGE UND, V113, P622, DOI 10.1016/j.cviu.2008.01.010
   D'Orazio T, 2009, IEEE T CIRC SYST VID, V19, P1804, DOI 10.1109/TCSVT.2009.2026817
   Desurmont X, 2006, WORKSH COMP VIS BAS, P92
   Duarte MRP, 2015, THESIS, P1
   Dzialowski Karol, 2021, Computational Science - ICCS 2021. 21st International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12746), P193, DOI 10.1007/978-3-030-77977-1_15
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Enomoto A, 2009, LECT NOTES COMPUT SC, V5622, P421, DOI 10.1007/978-3-642-02771-0_47
   Fakour H, 2010, 6 INT C WIR COMM NET, P1
   Farin D, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P482, DOI 10.1109/ICME.2005.1521465
   Farin D, 2004, PROC SPIE, V5307, P80
   Figueroa PJ, 2006, COMPUT VIS IMAGE UND, V101, P122, DOI 10.1016/j.cviu.2005.07.006
   Fotouhi M, 2017, MULTIMED TOOLS APPL, V76, P16189, DOI 10.1007/s11042-016-3904-2
   Fotouhi M, 2015, 2015 INTERNATIONAL SYMPOSIUM ON ARTIFICIAL INTELLIGENCE AND SIGNAL PROCESSING (AISP), P136, DOI 10.1109/AISP.2015.7123505
   Gaddam VR., 2018, MEDIASYNC, P565, DOI DOI 10.1007/978-3-319-65840-7_20
   Gerke S, 2017, COMPUT VIS IMAGE UND, V159, P105, DOI 10.1016/j.cviu.2017.04.010
   Goorts P, 2014, 2014 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND MULTIMEDIA APPLICATIONS (SIGMAP), P107
   Hadian M, 2015, 2015 9TH IRANIAN CONFERENCE ON MACHINE VISION AND IMAGE PROCESSING (MVIP), P185, DOI 10.1109/IranianMVIP.2015.7397533
   Hamid R, 2010, PROC CVPR IEEE, P731, DOI 10.1109/CVPR.2010.5540142
   Hayes JP, 2004, ASIAN TEST SYMPOSIUM, P100, DOI 10.1109/ATS.2004.84
   Hayet JB, 2005, IEEE IMAGE PROC, P3017
   Hayet JB, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P493
   Hayet JB, 2004, BRIT MACH VIS C BMVC, P687
   Hayet JB, 2007, LECT NOTES ARTIF INT, V4827, P736
   Homayounfar N, 2017, PROC CVPR IEEE, P4012, DOI 10.1109/CVPR.2017.427
   Inamoto N, 2007, IEEE T MULTIMEDIA, V9, P1155, DOI 10.1109/TMM.2007.902832
   INTILLE SS, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P672, DOI 10.1109/ICCV.1995.466874
   ipl ce, SOCCER DATASET IPL A
   Iwase S, 2004, INT C PATT RECOG, P751, DOI 10.1109/ICPR.2004.1333881
   Iwase S, 2003, PROC SPIE, V5150, P283, DOI 10.1117/12.502967
   Jing Jia, 2008, 5th International Conference on Visual Information Engineering, VIE 2008, P662, DOI 10.1049/cp:20080396
   KAMBLE PR, 2017, ARTIF INTELL REV, P1
   Kang J, 2004, P AS C COMP VIS
   Kashany VB, 2012, IET COMPUT VIS, V6, P133, DOI 10.1049/iet-cvi.2010.0107
   Kayumbi G., 2008, INT C DISTRIBUTED SM, P1
   Khatoonabadi SH, 2009, IMAGE VISION COMPUT, V27, P469, DOI 10.1016/j.imavis.2008.06.015
   Kim H, 2000, INT C PATT RECOG, P592, DOI 10.1109/ICPR.2000.905407
   Kim H, 2001, PATTERN ANAL APPL, V4, P9, DOI 10.1007/s100440170020
   Kim H, 2003, P IM VIS COMP PALM N, P159
   Kong Y, 2010, LECT NOTES COMPUT SC, V5994, P103
   Kong Y, 2008, INT C PATT RECOG, P249
   Le Troter A, 2005, IEEE WRK SIG PRO SYS, P365, DOI 10.1109/SIPS.2005.1579894
   Li Q, 2005, AUTOMATIC CAMERA CAL, P170
   Li SJ, 2007, C IND ELECT APPL, P288
   Li Y, 2009, PROCEEDINGS OF THE 2009 WRI GLOBAL CONGRESS ON INTELLIGENT SYSTEMS, VOL IV, P404, DOI 10.1109/GCIS.2009.88
   Linnemann A, 2013, IEEE IMAGE PROC, P1316, DOI 10.1109/ICIP.2013.6738271
   Liu Y, 2006, LECT NOTES COMPUT SC, V3852, P852
   Liu Y, 2005, PROC SPIE, V5960, P1524, DOI 10.1117/12.632721
   Long Sha, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13624, DOI 10.1109/CVPR42600.2020.01364
   Mackowiak S., 2012, 2012 International Conference on Systems, Signals and Image Processing (IWSSIP), P409
   Mackowiak S, 2013, INT J ELECTRON TELEC, V59, P75, DOI 10.2478/eletel-2013-0009
   Mackowiak S, 2010, INTERNATIONAL CONFERENCE ON SIGNALS AND ELECTRONIC SYSTEMS (ICSES '10): CONFERENCE PROCEEDINGS, P119
   Manafifard M, 2017, COMPUT VIS IMAGE UND, V159, P19, DOI 10.1016/j.cviu.2017.02.002
   Manafifard M, 2017, SIGNAL PROCESS-IMAGE, V55, P157, DOI 10.1016/j.image.2017.04.001
   Manafifard M, 2017, MULTIMED TOOLS APPL, V76, P12251, DOI 10.1007/s11042-016-3625-6
   Manafifard M, 2015, SCI IRAN, V22, P1031
   Manafifard M., 2017, ENG J GEOSPATIAL INF, V5, P57, DOI [10.29252/jgit.5.2.57, DOI 10.29252/JGIT.5.2.57]
   Martín R, 2014, MULTIMED TOOLS APPL, V73, P1617, DOI 10.1007/s11042-013-1659-6
   Matsui K, 1998, PROC CVPR IEEE, P860, DOI 10.1109/CVPR.1998.698705
   Mei T, 2008, MULTIMED TOOLS APPL, V40, P89, DOI 10.1007/s11042-007-0186-8
   Mochizuki Takahiro, 2009, 2009 Proceedings of 6th International Symposium on Image and Signal Processing and Analysis, P408
   Naidoo W., 2006, PROC 2006 ANN RES C, P51, DOI DOI 10.1145/1216262.1216268
   Nasiri M, 2018, MULTIMED TOOLS APPL, V77, P31363, DOI 10.1007/s11042-018-6225-9
   Niu ZX, 2012, PATTERN RECOGN, V45, P1937, DOI 10.1016/j.patcog.2011.10.023
   Ohno Y., 1999, Proceedings. 1999 IEEE/SICE/RSJ. International Conference on Multisensor Fusion and Integration for Intelligent Systems. MFI'99 (Cat. No.99TH8480), P147, DOI 10.1109/MFI.1999.815980
   Ohta Y, 2007, INT J COMPUT VISION, V75, P173, DOI 10.1007/s11263-006-0030-z
   Pallavi V, 2008, IEEE T MULTIMEDIA, V10, P794, DOI 10.1109/TMM.2008.922869
   Papadakis N., 2010, Proceedings 2010 Conference on Visual Media Production (CVMP 2010). 7th European Conference on Visual Media Production, P97, DOI 10.1109/CVMP.2010.20
   Pourreza R, 2008, INT C INTELL COMP CO, P123, DOI 10.1109/ICCP.2008.4648363
   Rianthong Thanaphon, 2020, 2020 12th International Conference on Knowledge and Smart Technology (KST), P131, DOI 10.1109/KST48564.2020.9059550
   Sadlier DA, 2005, IEEE T CIRC SYST VID, V15, P1225, DOI 10.1109/TCSVT.2005.854237
   Sanyal S, 2021, J VIS COMMUN IMAGE R, V78, DOI 10.1016/j.jvcir.2021.103190
   Schlipsing M, 2017, J REAL-TIME IMAGE PR, V13, P345, DOI 10.1007/s11554-014-0406-1
   Seo Y., 1997, International Conference on Image Analysis and Processing, P196, DOI DOI 10.1007/3-540-63508-4
   Sun L, 2009, INT CONF ACOUST SPEE, P1237, DOI 10.1109/ICASSP.2009.4959814
   Svoboda T, 2005, PRESENCE-VIRTUAL AUG, V14, P407, DOI 10.1162/105474605774785325
   Szenberg F, 2001, INT C ADV PATT REC, P303, DOI DOI 10.1007/3-540-44732-6_31
   Taki T, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P815, DOI 10.1109/ICIP.1996.560865
   Theiner J, 2022, ARXIV
   Thomas G, 2007, J REAL-TIME IMAGE PR, V2, P117, DOI 10.1007/s11554-007-0041-1
   Tong XF, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1899412.1899419
   Vandenbroucke N, 1997, P SOC PHOTO-OPT INS, V3071, P23, DOI 10.1117/12.280606
   Viet AN, 2010, IEEE INT SYMP CIRC S, P3441, DOI 10.1109/ISCAS.2010.5537853
   Wan KW, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P185
   Wang F, 2006, IEEE SYS MAN CYBERN, P4932, DOI 10.1109/ICSMC.2006.385087
   Watanabe T, 2004, IEEE IMAGE PROC, P1633
   Watve A, 2008, PATTERN RECOGN LETT, V29, P994, DOI 10.1016/j.patrec.2008.01.022
   Xu CS, 2004, LECT NOTES COMPUT SC, V3332, P264
   Xu M., 2004, Intelligent Distributed Surveillance Systems (IDSS-04), P51
   Yamada A, 2002, INT C PATT RECOG, P303, DOI 10.1109/ICPR.2002.1044697
   Yao Q, 2017, INT CONF ACOUST SPEE, P1612, DOI 10.1109/ICASSP.2017.7952429
   Yihong Gong, 1995, Proceedings of the International Conference on Multimedia Computing and Systems (Cat. No.95TH8066), P167, DOI 10.1109/MMCS.1995.484921
   Yoon HS, 2002, ETRI J, V24, P443, DOI 10.4218/etrij.02.0102.0005
   Yow D., 1995, ACCV '95. Second Asian Conference on Computer Vision. Proceedings, P499
   Yu X, 2005, P IEEE INT C MULT EX, P1
   Yu XG, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1555
   Yu XG, 2006, IEEE T MULTIMEDIA, V8, P1164, DOI 10.1109/TMM.2006.884621
   Zhang Peng., 2017, Proceedings of the ACM on Human-Computer Interaction, V1, P1
   Zhang S., 2015, INT J U E SERVICE SC, V8, P89, DOI [10.14257/ijunesst.2015.8.3.08, DOI 10.14257/IJUNESST.2015.8.3.08]
   Zhu G., 2007, Proc. ACM Int. Conf. Multimedia, P58, DOI DOI 10.1145/1291233.1291250
NR 130
TC 0
Z9 0
U1 7
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 18427
EP 18458
DI 10.1007/s11042-023-16145-8
EA JUL 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001031485100004
DA 2024-07-18
ER

PT J
AU Estevao, RD
   Gomes, JGRC
   Nunes, LO
AF de Moura Estevao Filho, Roberto
   Rodriguez Carneiro Gomes, Jose Gabriel
   Oliveira Nunes, Leonardo
TI Evaluation of visual relationship classifiers with partially annotated
   datasets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep convolutional neural networks; Visual relationships; Partial
   annotation; Computer vision; Machine learning
AB In this work, we investigate neural networks as visual relationship classifiers for precision-constrained applications in partially annotated datasets. The classifier is a convolutional neural network, which we benchmark on three visual relationship datasets. We discuss the effect of partial annotation on precision and why precision-based metrics are not adequate in partial annotation cases. So far, this topic has not been explored in the context of visual relationship classification. We introduce a threshold tuning method that imposes a soft con-straint on precision while being less sensitive to the degree of annotation than a regular precision-recall trade-off method. Performance can then be measured via recall of predic-tions computed with thresholds tuned by the proposed method. Our previously introduced negative sample mining method is now extended to partially annotated datasets (namely Visual Relationship Detection, VRD, and Visual Genome, VG), by sampling from unlabeled pairs instead of unrelated pairs. When thresholds are tuned using our method, negative sam-ple mining improves recall from 24.1% to 30.6% and from 36.7% to 41.3% for VRD and VG, respectively. The neural networks also maintain the ability to correctly classify between predicates. When considering only ground-truth relationships for threshold tuning, there is only a small decrease in recall (from 45.1% to 43.8% in VRD, or from 60.5% to 58.7% in VG) compared to when the neural networks are trained only on ground-truth samples.
C1 [de Moura Estevao Filho, Roberto; Rodriguez Carneiro Gomes, Jose Gabriel] Univ Fed Rio de Janeiro, Dept Elect Engn, Rio De Janeiro, Brazil.
   [Oliveira Nunes, Leonardo] Microsoft, Rio De Janeiro, Brazil.
C3 Universidade Federal do Rio de Janeiro
RP Estevao, RD (corresponding author), Univ Fed Rio de Janeiro, Dept Elect Engn, Rio De Janeiro, Brazil.
EM robertomestevao@gmail.com
FU Microsoft ATL in Rio de Janeiro; Conselho Nacional de Desenvolvimento
   Cientifico e Tecnologico - CNPq - Brazil
FX Funding this work has been supported in part by Microsoft ATL in Rio de
   Janeiro, and in part by Conselho Nacional de Desenvolvimento Cientifico
   e Tecnologico - CNPq - Brazil.
CR Ahmad S, 2022, CLUSTER COMPUT, V25, P3733, DOI 10.1007/s10586-022-03598-z
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Cole E, 2021, PROC CVPR IEEE, P933, DOI 10.1109/CVPR46437.2021.00099
   Dai B, 2017, PROC CVPR IEEE, P3298, DOI 10.1109/CVPR.2017.352
   DILLON M, 1983, INFORM PROCESS MANAG, V19, P402, DOI 10.1016/0306-4573(83)90062-6
   du Plessis MC, 2014, ADV NEUR IN, V27
   Estevao RD, 2020, IEEE IMAGE PROC, P2251, DOI 10.1109/ICIP40778.2020.9191170
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Inayoshi Sho, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P682, DOI 10.1007/978-3-030-58558-7_40
   Johnson J, 2018, PROC CVPR IEEE, P1219, DOI 10.1109/CVPR.2018.00133
   Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494
   Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z
   Li L, 2022, PROC CVPR IEEE, P18847, DOI 10.1109/CVPR52688.2022.01830
   Li YK, 2017, PROC CVPR IEEE, P7244, DOI 10.1109/CVPR.2017.766
   Li Z., 2017, Meta-sgd: Learning to learn quickly for few-shot learning
   Liang KM, 2018, AAAI CONF ARTIF INTE, P7098
   Liang YZ, 2019, IEEE I CONF COMP VIS, P10402, DOI 10.1109/ICCV.2019.01050
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   Liu R, 2018, ADV NEUR IN, V31
   Lu CW, 2016, LECT NOTES COMPUT SC, V9905, P852, DOI 10.1007/978-3-319-46448-0_51
   Ma CX, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107684
   Newell A., 2017, ADV NEUR IN, P2171
   Nyo MT, 2022, MULTIMED TOOLS APPL, V81, P43837, DOI 10.1007/s11042-022-13215-1
   Paszke A, 2019, ADV NEUR IN, V32
   Peng YX, 2020, IEEE T CIRC SYST VID, V30, P4368, DOI 10.1109/TCSVT.2019.2953692
   Peyre J, 2017, IEEE I CONF COMP VIS, P5189, DOI 10.1109/ICCV.2017.554
   Qi MS, 2020, IEEE T CIRC SYST VID, V30, P2617, DOI 10.1109/TCSVT.2019.2921655
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sadeghi MA, 2011, PROC CVPR IEEE, P1745, DOI 10.1109/CVPR.2011.5995711
   Sutskever I., 2013, INT C MACHINE LEARNI, P1139
   Tang KH, 2020, PROC CVPR IEEE, P3713, DOI 10.1109/CVPR42600.2020.00377
   Wang, 2015, ARXIV
   Xi YL, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115648
   Xu DF, 2017, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2017.330
   Yang JK, 2022, LECT NOTES COMPUT SC, V13687, P178, DOI 10.1007/978-3-031-19812-0_11
   Yu F., 2020, arXiv
   Yu RC, 2017, IEEE I CONF COMP VIS, P1068, DOI 10.1109/ICCV.2017.121
   Zellers R, 2018, PROC CVPR IEEE, P5831, DOI 10.1109/CVPR.2018.00611
   Zhan YB, 2019, PROC CVPR IEEE, P5123, DOI 10.1109/CVPR.2019.00527
   Zhang HW, 2017, PROC CVPR IEEE, P3107, DOI 10.1109/CVPR.2017.331
   Zhang J, 2019, AAAI CONF ARTIF INTE, P9185
   Zhang J, 2017, PROC CVPR IEEE, P5226, DOI 10.1109/CVPR.2017.555
   Zhang ZJ, 2021, IMAGE VISION COMPUT, V109, DOI 10.1016/j.imavis.2021.104146
   Zhou H, 2021, IEEE T CIRC SYST VID, V31, P2751, DOI 10.1109/TCSVT.2020.3032650
   Zhuang BH, 2017, IEEE I CONF COMP VIS, P589, DOI 10.1109/ICCV.2017.71
NR 51
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 18333
EP 18352
DI 10.1007/s11042-023-15967-w
EA JUL 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001030536100009
DA 2024-07-18
ER

PT J
AU Xia, DW
   Shen, BQ
   Zheng, YL
   Zhang, WY
   Bai, DW
   Hu, Y
   Li, HQ
AF Xia, Dawen
   Shen, Bingqi
   Zheng, Yongling
   Zhang, Wenyong
   Bai, Dewei
   Hu, Yang
   Li, Huaqing
TI A bidirectional-a-star-based ant colony optimization algorithm for
   big-data-driven taxi route recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Big data analytics; Image processing; Route recommendation; BiA*; Ant
   colony optimization; Big taxi trajectory data
ID PATH PLANNING ALGORITHM; GENETIC ALGORITHM
AB To address the critical problems of high fuel consumption and severe traffic congestion of brought by blindly cruising in a vast transportation system, we propose a Bidirectional-A-star-based Ant Colony Optimization (BiA*-ACO) algorithm to recommend the fastest route for taxicabs in a complex urban road network with passenger prediction results in this paper. More specifically, the cost estimation function of the Bidirectional A-star (BiA*) algorithm is employed to optimize the heuristic function of the Ant Colony (AC) algorithm for enhancing the global searching ability of ACO. Furthermore, the optimal route obtained from each cycle is introduced to improve the pheromone updating rules of AC for accelerating the convergence speed of ACO. Finally, the BiA*-ACO algorithm is applied to recommend the fastest route successfully. The experimental results of real-world taxi GPS trajectory big data with an urban road network demonstrate that the BiA*-ACO algorithm is at least 47.05% more efficient than the traditional ACO algorithm when the data set is small. As the big GPS trajectory data grows exponentially, the BiA*-ACO algorithm is at least 49.81% more efficient than ACO, Dijkstra, and Bellman-Ford. In particular, compared with the A-star algorithm, the Acyclic algorithm, and the Gurobi algorithm, the fastest route length recommended by the BiA*-ACO algorithm is reduced by 102.73m, 73.27m, and 23.08m.
C1 [Xia, Dawen; Shen, Bingqi; Zheng, Yongling; Zhang, Wenyong; Bai, Dewei] Guizhou Minzu Univ, Coll Data Sci & Informat Engn, Guiyang 550025, Peoples R China.
   [Hu, Yang] Guizhou Traff Technician & Transportat Coll, Dept Automot Engn, Guiyang 550008, Peoples R China.
   [Li, Huaqing] Southwest Univ, Coll Elect & Informat Engn, Chongqing 400715, Peoples R China.
C3 Guizhou Minzu University; Southwest University - China
RP Xia, DW (corresponding author), Guizhou Minzu Univ, Coll Data Sci & Informat Engn, Guiyang 550025, Peoples R China.; Li, HQ (corresponding author), Southwest Univ, Coll Elect & Informat Engn, Chongqing 400715, Peoples R China.
EM dwxia@gzmu.edu.cn; huaqingli@swu.edu.cn
RI CHEN, MINGWEI/KHT-6744-2024; tong, li/KDO-7821-2024; zhao,
   wei/JZD-4475-2024
FU National Natural Science Foundation of China [62162012, 62173278];
   Science and Technology Support Program of Guizhou Province, China
   [QKHZC2021YB531]; Natural Science Research Project of Department of
   Education of Guizhou Province, China [QJJ2022015, QJJ2022047]; Science
   and Technology Foundation of Guizhou Province, China [QKHJCZK2022YB195,
   QKHJCZK2022YB197, QKHJCZK2023YB143]; Scientific Research Platform
   Project of Guizhou Minzu University, China [[2021]04]
FX AcknowledgementsThis work described in this paper was supported in part
   by the National Natural Science Foundation of China (Grant nos. 62162012
   and 62173278), the Science and Technology Support Program of Guizhou
   Province, China (Grant no. QKHZC2021YB531), the Natural Science Research
   Project of Department of Education of Guizhou Province, China (Grant
   nos. QJJ2022015 and QJJ2022047), the Science and Technology Foundation
   of Guizhou Province, China (Grant nos. QKHJCZK2022YB195,
   QKHJCZK2022YB197, and QKHJCZK2023YB143), and the Scientific Research
   Platform Project of Guizhou Minzu University, China (Grant no.
   GZMUSYS[2021]04).
CR Le AV, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082585
   Ashokkumar P, 2018, COMPUT ELECTR ENG, V68, P526, DOI 10.1016/j.compeleceng.2018.05.004
   Bakdi A, 2017, ROBOT AUTON SYST, V89, P95, DOI 10.1016/j.robot.2016.12.008
   Chen C, 2014, IEEE T INTELL TRANSP, V15, P1451, DOI 10.1109/TITS.2014.2298892
   Chen K, 2021, ARXIV
   Chen RM, 2019, 2019 20TH IEEE/ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING (SNPD), P212, DOI [10.1109/SNPD.2019.8935815, 10.1109/snpd.2019.8935815]
   Cui G, 2018, INT J DIGIT EARTH, V11, P284, DOI 10.1080/17538947.2017.1326535
   Dewantoro RW, 2019, 2019 3RD INTERNATIONAL CONFERENCE ON ELECTRICAL, TELECOMMUNICATION AND COMPUTER ENGINEERING (ELTICOM), P160, DOI 10.1109/elticom47379.2019.8943832
   Fu B, 2018, ROBOT AUTON SYST, V106, P26, DOI 10.1016/j.robot.2018.04.007
   Garg N, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1425, DOI 10.1145/3219819.3220055
   Guo SM, 2022, IEEE T MOBILE COMPUT, V21, P1909, DOI 10.1109/TMC.2020.3033274
   Hu XZ, 2020, PROCEEDINGS OF 2020 IEEE 4TH INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2020), P98, DOI [10.1109/itnec48623.2020.9084895, 10.1109/ITNEC48623.2020.9084895]
   Ji SG, 2020, KNOWL-BASED SYST, V205, DOI 10.1016/j.knosys.2020.106302
   Jing Y, 2019, P 2019 INT C ROB SYS, P138
   Khairnar HS, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS 2020), P191, DOI 10.1109/ICCCS49078.2020.9118575
   Lai YX, 2019, IEEE T INTELL TRANSP, V20, P3024, DOI 10.1109/TITS.2018.2870990
   Lamini C, 2018, PROCEDIA COMPUT SCI, V127, P180, DOI 10.1016/j.procs.2018.01.113
   Li, 2021, PHYSICA A, V578, P1
   Li J, 2020, ACM S THEORY COMPUT, P308, DOI 10.1145/3357713.3384268
   Lin BL, 2021, APPL MATH MODEL, V93, P811, DOI 10.1016/j.apm.2020.12.031
   Liu H, 2022, IEEE T KNOWL DATA EN, V34, P723, DOI 10.1109/TKDE.2020.2985954
   Mazur V, 2016, 2016 XII International Conference on Perspective Technologies and Methods in MEMS Design (MEMSTECH), P196, DOI 10.1109/MEMSTECH.2016.7507541
   McKenna Conor, 2019, 2019 IEEE 5th International Conference on Computer and Communications (ICCC), P2203, DOI 10.1109/ICCC47050.2019.9064471
   Nazarahari M, 2019, EXPERT SYST APPL, V115, P106, DOI 10.1016/j.eswa.2018.08.008
   Niu HL, 2018, OCEAN ENG, V161, P308, DOI 10.1016/j.oceaneng.2018.01.025
   Parimala M, 2021, COMPLEX INTELL SYST, V7, P2373, DOI 10.1007/s40747-021-00430-w
   Qiu YH, 2018, 2018 14TH INTERNATIONAL CONFERENCE ON MOBILE AD-HOC AND SENSOR NETWORKS (MSN 2018), P121, DOI 10.1109/MSN.2018.00027
   Sub-R-Pa C, 2018, 2018 INT C COMP INF, P264
   Wu N, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1923, DOI 10.1145/3357384.3357907
   Xia D, 2021, MULTIMED TOOLS APPL, P1
   Xia DW, 2021, NEURAL COMPUT APPL, V33, P2393, DOI 10.1007/s00521-020-05076-2
   Xia DW, 2016, NEUROCOMPUTING, V179, P246, DOI 10.1016/j.neucom.2015.12.013
   Xiong J, 2020, IEEE ACCESS, V8, P150539, DOI 10.1109/ACCESS.2020.3017132
   Xu XL, 2018, SOFT COMPUT, V22, P6567, DOI 10.1007/s00500-017-2705-5
   Xu Y, 2020, COMPUT COMMUN, V154, P12, DOI 10.1016/j.comcom.2020.02.043
   Yang GF, 2021, RES TRANSP BUS MANAG, V38, DOI 10.1016/j.rtbm.2020.100502
   Zhang GH, 2019, J INTELL ROBOT SYST, V94, P219, DOI 10.1007/s10846-018-0894-5
   Zhou H., 2020, DISTRIB PARAL DATABA, V38, P1
   Zimmermann M, 2017, TRANSPORT RES C-EMER, V75, P183, DOI 10.1016/j.trc.2016.12.009
NR 39
TC 0
Z9 0
U1 10
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16313
EP 16335
DI 10.1007/s11042-023-15498-4
EA JUL 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001030536100008
DA 2024-07-18
ER

PT J
AU Angelis, GF
   Chorozoglou, D
   Papadopoulos, S
   Drosou, A
   Giakoumis, D
   Tzovaras, D
AF Angelis, Georgios-Fotios
   Chorozoglou, Dimitrios
   Papadopoulos, Stavros
   Drosou, Anastasios
   Giakoumis, Dimitrios
   Tzovaras, Dimitrios
TI AI-enabled Underground Water Pipe non -destructive Inspection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pipe; Detection; Degradation; YOLOv5; GANs; cGAN
ID DEEP CONVOLUTIONAL NETWORKS; LOCALIZATION; ALGORITHM
AB A study conducted by the World Bank indicated that the global annual economic losses from the water leakage are estimated at US$ 14.6 billion. For this reason, locating and repairing water leaks as well as the maintenance of water pipelines is extremely important for the optimization and rationalization of water resources. The basic technique for inspecting water delivery infrastructure is the water audit but this technique does not provide any information about the location of the water leakage. This paper focuses on this gap, aiming to provide information not only for the location of the water leakage but also for the level of water pipe material degradation due to its corrosion before the leakage presents. Here, the identification of the extent and severity of the evolving defect of water pipes is performed through deep learning models using simulated and real Ground Penetrating Radar (GPR) data. Synthetic GPR images are generated, with underground water pipes that either present leakage or no in various steps of their corrosion, using gprMax software. Especially, this addresses as a solution YOLOv5 algorithm for the automatic detection of water pipes and leaks in the underground space and a conditional Generative Adversarial Network (cGAN) for the investigation of water pipe material degradation. The results reveal that the YOLOv5 algorithm distinguishes the regions of pipes in GPR data and classified correctly the pipes which present leakage or no, and they are better than the corresponding results of other literature baseline methods. In addition, as shown through extensive simulations on generated GPR data the proposed cGAN produces high quality results that contribute to revelation of the extent and severity of the evolving defect of pipeline due to its corrosion.
C1 [Angelis, Georgios-Fotios; Chorozoglou, Dimitrios; Papadopoulos, Stavros; Drosou, Anastasios; Giakoumis, Dimitrios; Tzovaras, Dimitrios] Ctr Res & Technol Hellas, Informat Technol Inst, 6th km Charilaou Thermi Rd, Thessaloniki 57001, Greece.
C3 Centre for Research & Technology Hellas
RP Angelis, GF; Chorozoglou, D (corresponding author), Ctr Res & Technol Hellas, Informat Technol Inst, 6th km Charilaou Thermi Rd, Thessaloniki 57001, Greece.
EM angelisg@iti.gr; dimitrischorozo@pragma-iot.com; spap@iti.gr;
   drosou@iti.gr; dgiakoum@iti.gr; Dimitrios.Tzovaras@iti.gr
OI Angelis, Georgios-Fotios/0000-0001-6887-8758
FU TERRAPIN project from European Union's Horizon 2020 research and
   innovation programme [824990]; PALIMPSISTO project from European
   Regional Development Fund of the European Union; Greek national funds
   through the Operational Program Competitiveness, Entrepreneurship and
   Innovation B' phase, under the call RESEARCH-CREATE-INNOVATE
   [T2EDK-01894]; H2020 Societal Challenges Programme [824990] Funding
   Source: H2020 Societal Challenges Programme
FX This work was supported by the TERRAPIN project that it has received
   funding from the European Union's Horizon 2020 research and innovation
   programme under grant agreement No 824990 and by the PALIMPSISTO project
   co-financed from the European Regional Development Fund of the European
   Union and Greek national funds through the Operational Program
   Competitiveness, Entrepreneurship and Innovation B' phase, under the
   call RESEARCH-CREATE-INNOVATE (project code:T2EDK-01894).
CR Ahmed M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21155116
   Almahasneh M, 2022, MACH VISION APPL, V33, DOI 10.1007/s00138-021-01261-y
   Alshamy HM, 2021, IOP C SERIES MAT SCI, V1090
   Ayala-Cabrera D, 2014, PROCEDIA ENGINEER, V89, P304, DOI 10.1016/j.proeng.2014.11.192
   Beal J., 2020, ARXIV
   Besaw LE, 2015, PROC SPIE, V9454, DOI 10.1117/12.2176250
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   Chen KA, 2019, PROC CVPR IEEE, P5114, DOI 10.1109/CVPR.2019.00526
   Chen Y, 2019, J MACH LEARN RES, V20
   Chi Cheng, 2020, NEURIPS
   Ding J, 2016, IEEE GEOSCI REMOTE S, V13, P364, DOI 10.1109/LGRS.2015.2513754
   Dinh K, 2018, AUTOMAT CONSTR, V89, P292, DOI 10.1016/j.autcon.2018.02.017
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gupta A, 2022, PROC CVPR IEEE, P9225, DOI 10.1109/CVPR52688.2022.00902
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hensel M, 2017, ADV NEUR IN, V30
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kang Kim, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P355, DOI 10.1007/978-3-030-58595-2_22
   Karras T, 2018, P INT C LEARN REPR I
   Kaur P, 2016, IEEE T CYBERNETICS, V46, P2265, DOI 10.1109/TCYB.2015.2474747
   Kim D, 2019, IEEE ICCE, P418
   Kouros G, 2018, IEEE INT C INT ROBOT, P3218, DOI 10.1109/IROS.2018.8593848
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee J, 2020, ENG STRUCT, V203, DOI 10.1016/j.engstruct.2019.109882
   Lei WT, 2013, TURK J ELECTR ENG CO, V21, P1820, DOI 10.3906/elk-1201-6
   Li F, 2022, PROC CVPR IEEE, P13609, DOI 10.1109/CVPR52688.2022.01325
   Li JA, 2017, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2017.211
   Li YH, 2019, IEEE I CONF COMP VIS, P6053, DOI 10.1109/ICCV.2019.00615
   Lin T, 2021, arXiv
   Liu MY, 2017, ADV NEUR IN, V30
   Liu S., 2022, ARXIV
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Mathieu M., 2015, ARXIV
   Pham MT, 2018, INT GEOSCI REMOTE SE, P6804, DOI 10.1109/IGARSS.2018.8517683
   Navarro P, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-14910-7
   Pantraki E, 2021, MACH VISION APPL, V32, DOI 10.1007/s00138-021-01207-4
   Papadopoulos S, 2021, SIGNAL PROCESS-IMAGE, V94, DOI 10.1016/j.image.2021.116200
   Qiu Z, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14081895
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ruchti GF, 2017, WATER PIPELINE CONDI
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salimans T, 2016, ADV NEUR IN, V29
   Shinya Y, 2021, ARXIV
   Singh B, 2018, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2018.00377
   Skartados E, 2019, EUR SIGNAL PR CONF, DOI 10.23919/eusipco.2019.8902528
   Skartados E, 2019, LECT NOTES COMPUT SC, V11754, P224, DOI 10.1007/978-3-030-34995-0_21
   Sun PZ, 2021, PROC CVPR IEEE, P14449, DOI 10.1109/CVPR46437.2021.01422
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tong Z, 2020, COMPUT-AIDED CIV INF, V35, P832, DOI 10.1111/mice.12533
   Truong T, 2019, IEEE IJCNN, DOI 10.1109/ijcnn.2019.8851887
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Veal C, 2018, INT SOC OPTICS PHOTO, V10628, P18
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Warren C, 2016, COMPUT PHYS COMMUN, V209, P163, DOI 10.1016/j.cpc.2016.08.020
   Wu Y., 2019, DETECTRON2
   Xinjiang Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13356, DOI 10.1109/CVPR42600.2020.01337
   Yue YP, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13224590
   Zaidi SSA, 2022, DIGIT SIGNAL PROCESS, V126, DOI 10.1016/j.dsp.2022.103514
   Zhang H., 2022, arXiv
   Zhang S., 2020, P IEEECVF C COMPUTER, P9759
   Zhang X, 2021, IEEE ACCESS, V9, P39009, DOI 10.1109/ACCESS.2021.3064205
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu X., 2020, arXiv
NR 68
TC 1
Z9 1
U1 9
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 18309
EP 18332
DI 10.1007/s11042-023-15797-w
EA JUL 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001027492600005
DA 2024-07-18
ER

PT J
AU Zhang, Z
   Jiang, W
   Zhang, Y
   Wang, XW
   Yang, JJ
AF Zhang, Zhen
   Jiang, Wei
   Zhang, Yuan
   Wang, Xiangwen
   Yang, Junjie
TI Rate-accuracy optimized quantization algorithm based on ROI image coding
   in power line inspection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligent inspection; Image coding; Attention-map; Rate-accuracy
ID RATE-DISTORTION OPTIMIZATION; BIT ALLOCATION; VIDEO; QUALITY
AB In the context of big data, transmission line inspection of the Grid has evolved from the era of human inspection to intelligent inspection. Large quantities of image data will be collected and analyzed by machines. Since the foreground may have greater value compared with the background, Region of Interest (ROI) image coding is applied. However, the traditional image coding aims to maintain good human-perceivable visual quality and is not designed for semantic analysis. The image coding paradigms that comprehensively balance the human visual quality and automatic analysis performance are needed. In this paper, a Rate-Accuracy Optimized quantization algorithm based on Region of Interest image coding is proposed to obtain the optimal analysis performance with the given coded bit rate. First, a machine vision-oriented attention-map is determined. Since the features are leveraged to reflect abstract semantic meaning which is vital for image analysis tasks, it is reasonable to regard the region containing the feature vector information as the key area and others as the non-key area. The key area is compressed with fine-grained quantization while the non-key area is with coarse-grained quantization. Then the relationship between rate, accuracy and quantization parameters are analyzed and modeled. Finally, the optimal quantization parameters are determined based on the Rate-Accuracy criteria. The proposed algorithm is verified by the insulator dataset (Image of insulator defect collected by drone inspection). Experimental results show that the accuracy of defect identification is improved by 12% at the same bit rate.
C1 [Zhang, Zhen; Jiang, Wei; Wang, Xiangwen] Shanghai Univ Elect Power, Sch Elect & Informat Engn, Shanghai, Peoples R China.
   [Zhang, Yuan] Zhejiang Univ, Coll Informat & Elect Engn, Shanghai, Peoples R China.
   [Yang, Junjie] Shanghai DianJi Univ, Shanghai, Peoples R China.
C3 Shanghai University of Electric Power; Zhejiang University; Shanghai
   Dianji University
RP Jiang, W (corresponding author), Shanghai Univ Elect Power, Sch Elect & Informat Engn, Shanghai, Peoples R China.
EM zz2822107241@163.com; shiepjw@shiep.edu.cn; zhangy666@chinatelecom.cn;
   wxw21st@163.com; yangjj@sdju.edu.cn
RI li, song/JVO-5938-2024; feng, feng/KBR-1814-2024; xie,
   jing/KDO-9486-2024
FU National Natural Science Foundation of China [61202369, 61401269];
   Shanghai Technology Innovation Project [17020500900]; Shanghai Education
   Development Foundation; Shanghai Municipal Education Commission [17SG51]
FX This paper was partially financially supported by the National Natural
   Science Foundation of China (61202369, 61401269), Shanghai Technology
   Innovation Project (17020500900), and "Shuguang Program" sponsored by
   Shanghai Education Development Foundation and Shanghai Municipal
   Education Commission (17SG51).
CR Adhuran J, 2020, IEEE T CONSUM ELECTR, V66, P213, DOI 10.1109/TCE.2020.3001231
   Alam MM, 2015, PROC SPIE, V9599, DOI 10.1117/12.2188913
   Alvar SR, 2021, IEEE T IMAGE PROCESS, V30, P3348, DOI 10.1109/TIP.2021.3060875
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Cai CL, 2019, IEEE T CIRC SYST VID, V29, P3687, DOI 10.1109/TCSVT.2018.2880492
   Cai Q, 2021, IEEE T CIRC SYST VID, V31, P4924, DOI 10.1109/TCSVT.2021.3056134
   Chang JH, 2022, IEEE T IMAGE PROCESS, V31, P2809, DOI 10.1109/TIP.2022.3159477
   Chen HG, 2022, IEEE T NEUR NET LEAR, V33, P430, DOI 10.1109/TNNLS.2021.3124370
   Chen T, 2019, ARXIV
   Chen Z, 2020, IEEE T IMAGE PROCESS, V29, P2230, DOI 10.1109/TIP.2019.2941660
   Cheng ZX, 2020, IEEE T MULTIMEDIA, V22, P860, DOI 10.1109/TMM.2019.2938345
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Ding L, 2017, IEEE T IMAGE PROCESS, V26, P5743, DOI 10.1109/TIP.2017.2745203
   Duan LY, 2020, IEEE T IMAGE PROCESS, V29, P8680, DOI 10.1109/TIP.2020.3016485
   Fischer K, 2020, IEEE INT WORKSH MULT, DOI 10.1109/MMSP48831.2020.9287136
   Fu HS, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2019.115774
   Hu YH, 2020, IEEE INT C INTELL TR, DOI [10.1109/ICIDDT52279.2020.00008, 10.1109/itsc45102.2020.9294515]
   Huang B, 2021, IEEE T BROADCAST, V67, P721, DOI 10.1109/TBC.2021.3077771
   Kim S, 2020, IEEE ACCESS, V8, P149999, DOI 10.1109/ACCESS.2020.3016213
   Lee JM, 2019, APPL MICROBIOL BIOT, V103, P1429, DOI 10.1007/s00253-018-9480-9
   Li Y, 2021, IEEE T BROADCAST, V67, P500, DOI 10.1109/TBC.2021.3068871
   Li Y, 2018, IEEE IMAGE PROC, P1797, DOI 10.1109/ICIP.2018.8451396
   Liu FY, 2021, IEEE T IMAGE PROCESS, V30, P4706, DOI 10.1109/TIP.2021.3072225
   Ma SW, 2019, IEEE T CIRC SYST VID, V29, P3095, DOI 10.1109/TCSVT.2018.2873102
   Schafer M, 2021, IEEE OPEN J CIRCUITS, V2, P633, DOI 10.1109/OJCAS.2021.3124995
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Wallace G. K., 1991, Communications of the ACM, V34, P30, DOI 10.1145/103085.103089
   Wang SR, 2022, IEEE T MULTIMEDIA, V24, P3169, DOI 10.1109/TMM.2021.3094300
   Wang SR, 2019, IEEE IMAGE PROC, P2691, DOI [10.1109/ICIP.2019.8803255, 10.1109/icip.2019.8803255]
   Wang XW, 2020, IEEE T IMAGE PROCESS, V29, P9458, DOI 10.1109/TIP.2020.3028280
   Wang YF, 2021, IEEE T CIRC SYST VID, V31, P1193, DOI 10.1109/TCSVT.2020.3000331
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xia SF, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102843
   Yang F, 2020, IEEE SIGNAL PROC LET, V27, P331, DOI 10.1109/LSP.2020.2970539
   Yang L, 2020, IEEE T INSTRUM MEAS, V69, P9350, DOI 10.1109/TIM.2020.3031194
   Yang S, 2021, IEEE T MULTIMEDIA, V23, P2957, DOI 10.1109/TMM.2021.3068580
   Yilmaz MA, 2022, IEEE T IMAGE PROCESS, V31, P974, DOI 10.1109/TIP.2021.3138300
   Zhao LJ, 2019, J VIS COMMUN IMAGE R, V63, DOI 10.1016/j.jvcir.2019.102589
NR 40
TC 0
Z9 0
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16139
EP 16160
DI 10.1007/s11042-023-15271-7
EA JUL 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001027492600001
DA 2024-07-18
ER

PT J
AU Patil, S
   Sasikala, M
AF Patil, Savitha
   Sasikala, M.
TI A weighted KNN model for identification of medicinal plant species
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Folio leaf dataset; Medicinal plant leaf images; Weighted KNN model;
   Classification; Feature extraction
ID LEAF; SHAPE; CLASSIFICATION; FEATURES; ALGORITHM
AB Medicinal plants can provide immense contribution towards the growth of modern medicine and pharmaceutical industries to protect people from current deadly diseases like cancer and cardiovascular diseases. However, presence of thousands of plant species globally and similarity in their features like color, texture and shape makes their identification critical and immensely challenging. Moreover, utilization of traditional methods to classify plant leaf under expert's guidance is costly, challenging and time taking process. Therefore, in this article, a Weighted KNN Classification (WKNNC) Model is adopted for the accurate identification of plant leaf images based on machine learning techniques. High quality morphological and discriminative features are obtained by using Region of Interest (ROI) of the images, which is extracted from segmentation process. The proposed WKNNC model works upon Local Intensity Relation (LIR) and directional group encoding method to obtain high quality features. Further, the obtained feature weights provide high classification accuracy. Folio Leaf dataset is utilized to evaluate performance of proposed WKNNC model. The obtained classification accuracy is compared against several state-of-art-techniques and proposed WKNNC model outperforms all of them.
C1 [Patil, Savitha; Sasikala, M.] Sharanbasava Univ, CSE, Kalaburagi 585105, Karnataka, India.
RP Patil, S (corresponding author), Sharanbasava Univ, CSE, Kalaburagi 585105, Karnataka, India.
EM savitha019@gmail.com; sasi_mum@rediffmail.com
RI MUNGAMURI, SASIKALA/KHT-6658-2024
CR Agrawal P, 2014, LECT NOTES COMPUT SC, V8695, P329, DOI 10.1007/978-3-319-10584-0_22
   Ahmed A, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0237645
   Anami BS., 2010, INT J COMPUT APPL, V6, P45
   [Anonymous], COMPUT VIS PATTERN R
   [Anonymous], 1999, WHO MONOGRAPHS SELEC
   Azlah MAF, 2019, COMPUTERS, V8, DOI 10.3390/computers8040077
   Chaudhury A, 2020, IEEE ACM T COMPUT BI, V17, P1042, DOI 10.1109/TCBB.2018.2873611
   Durairajah V, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON CONTROL, ROBOTICS AND CYBERNETICS (CRC), P6, DOI 10.1109/CRC.2018.00011
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   GUYER DE, 1993, T ASAE, V36, P163
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Im C, 1998, INT C PATT RECOG, P1171, DOI 10.1109/ICPR.1998.711904
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jiang HX, 2020, IEEE ACCESS, V8, P68828, DOI 10.1109/ACCESS.2020.2986946
   Journal of Botany, 2014, J BOT
   Karami N., 2017, CANC PRESS, V3, P22, DOI [10.15562/tcp.41, DOI 10.15562/TCP.41]
   Kumar M, 2019, IEEE ACCESS, V7, P163912, DOI 10.1109/ACCESS.2019.2952176
   Larese MG, 2014, PATTERN RECOGN, V47, P158, DOI 10.1016/j.patcog.2013.06.012
   Lulekal E, 2008, J ETHNOBIOL ETHNOMED, V4, DOI 10.1186/1746-4269-4-10
   Muneer A, 2020, IEEE ACCESS, V8, P196747, DOI 10.1109/ACCESS.2020.3034033
   Ni ZW, 1997, J ANHUI U NATURAL SC, V21
   Oide M, 2000, COMPUT ELECTRON AGR, V29, P59, DOI 10.1016/S0168-1699(00)00136-8
   Patil AA., 2016, INT J ENG TRENDS TEC, V8, P359, DOI [10.14445/22315381/IJETT-V35P273, DOI 10.14445/22315381/IJETT-V35P273]
   Pushpanathan K, 2021, ARTIF INTELL REV, V54, P305, DOI 10.1007/s10462-020-09847-0
   Qingfeng W, 2007, ADV ART INTELL
   Simard PY, 2003, PROC INT CONF DOC, P958
   Soderkvist O, 2001, COMPUTER VISION CLAS
   Tan JW, 2020, IEEE ACM T COMPUT BI, V17, P82, DOI 10.1109/TCBB.2018.2848653
   Thanikkal JG, 2020, IEEE SENS J, V20, P13103, DOI 10.1109/JSEN.2020.3002909
   Wang LiJun Wang LiJun, 2015, Journal of Beijing Forestry University, V37, P55
   Wang X, 2020, IEEE ACCESS, V8, P39175, DOI 10.1109/ACCESS.2020.2976117
   Wang ZB, 2016, NEURAL COMPUT APPL, V27, P899, DOI 10.1007/s00521-015-1904-1
   Yang XB, 2020, IEEE ACCESS, V8, P151555, DOI 10.1109/ACCESS.2020.3017560
   Zhang CY, 2015, CIT/IUCC/DASC/PICOM 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY - UBIQUITOUS COMPUTING AND COMMUNICATIONS - DEPENDABLE, AUTONOMIC AND SECURE COMPUTING - PERVASIVE INTELLIGENCE AND COMPUTING, P2147, DOI 10.1109/CIT/IUCC/DASC/PICOM.2015.318
   Zhang SW, 2020, NEUROCOMPUTING, V408, P246, DOI 10.1016/j.neucom.2019.09.113
   Zheng Y., 2018, TRANSCHIN SOC AGR MA, V49, P354, DOI [10.6041/j.issn.1000-1298.2018.S0.047, DOI 10.6041/J.ISSN.1000-1298.2018.S0.047]
   [郑一力 Zheng Yili], 2017, [农业机械学报, Transactions of the Chinese Society for Agricultural Machinery], V48, P30
NR 39
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13775
EP 13789
DI 10.1007/s11042-023-15931-8
EA JUL 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001026613700008
DA 2024-07-18
ER

PT J
AU Chatterjee, S
   Maity, S
   Ghosh, K
   Das, AK
   Banerjee, S
AF Chatterjee, Sankhadeep
   Maity, Soumyajit
   Ghosh, Kushankur
   Das, Asit Kumar
   Banerjee, Soumen
TI Majority biased facial emotion recognition using residual variational
   autoencoders
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial emotion recognition; Residual variational autoencoder; Class
   imbalance; Oversampling; Undersampling
ID DEEP NEURAL-NETWORK; SPARSE AUTOENCODER; SMOTE
AB Recent studies have established the success of deep learning models in facial emotion recognition. However, such models are often not well suited to tackle one of the most commonly encountered problems of imbalanced classes. In real datasets, various emotion classes are found to be highly underrepresented leading to dramatic reduction in the performance of classification models. In the current study, a residual variational autoencoder-based model has been proposed to address the problem of imbalanced facial emotion recognition. Firstly, in order to capture the most important features in the form of embeddings, a variational autoencoder equipped with residual connections has been trained in an unsupervised fashion to obtain the most effective latent space representation of all input images. After the training phase, only the encoder part of the actual autoencoder is used to transform all labeled facial images into a latent vector form. Next, the imbalanced latent vectors are resampled using well-known algorithms to tackle the imbalanced classes. In this context, three major types of algorithms viz., Undersampling, Oversampling, and Hybrid are used for the same. To establish the quality of the proposed method, various well-known classifiers are trained and tested in terms of test phase confusion matrix-based performance indicators. All hyperparameters are selected by employing the Grid search method. In addition, to understand the effect of oversampling minority class samples, a separate study is conducted by observing classifier performance against varying degrees of oversampling. Experimental results and extensive comparative studies have shown that the residual variational autoencoder model combined with SMOTE-ENN hybrid resampling technique can boost the classifier performance to a greater extent.
C1 [Chatterjee, Sankhadeep; Das, Asit Kumar] Indian Inst Engn Sci & Technol, Dept Comp Sci & Technol, Howrah, Shibpur, India.
   [Maity, Soumyajit] Univ Engn & Management, Dept Comp Sci & Engn, Kolkata, India.
   [Ghosh, Kushankur] Univ Alberta, Dept Comp Sci, Edmonton, AB, Canada.
   [Banerjee, Soumen] Narula Inst Technol, Kolkata, India.
C3 Indian Institute of Engineering Science Technology Shibpur (IIEST);
   University of Alberta
RP Chatterjee, S (corresponding author), Indian Inst Engn Sci & Technol, Dept Comp Sci & Technol, Howrah, Shibpur, India.
EM chatterjeesankhadeep.cu@gmail.com; soumyajitmaity2709@gmail.com;
   kushanku@ualberta.ca; akdas@cs.iiests.ac.in; prof.sbanerjee@gmail.com
RI Chatterjee, Sankhadeep/F-4672-2017
OI Chatterjee, Sankhadeep/0000-0002-3930-4699; Maity,
   Soumyajit/0000-0001-6772-9398
CR Abayasekara RP, 2016, INT CONF INF AUTOMAT
   Abdul-Hadi Meaad Hussein, 2020, 2020 International Conference on Computer Science and Software Engineering (CSASE). Proceedings, P191, DOI 10.1109/CSASE48920.2020.9142065
   Alamgir Alam M, 2022, MULTIMED TOOLS APPL, VApp, P1
   Allognon S.O.C., 2020, 2020 INT JOINT C NEU, P1
   Arora M, 2021, MULTIMED TOOLS APPL, V80, P3039, DOI 10.1007/s11042-020-09726-4
   Arora M, 2018, NATL ACAD SCI LETT, V41, P365, DOI 10.1007/s40009-018-0694-2
   Arora S., 2017, ARXIV
   Arora V, 2019, INT CONF ACOUST SPEE, P3297, DOI 10.1109/ICASSP.2019.8682395
   Banerjee Arghasree, 2021, Advances in Smart Communication Technology and Information Processing. OPTRONIX 2020. Lecture Notes in Networks and Systems (LNNS 165), P181, DOI 10.1007/978-981-15-9433-5_18
   Banerjee A, 2020, MULTIMED TOOLS APPL, V79, P35995, DOI 10.1007/s11042-020-09138-4
   Batista G. E., 2004, ACM SIGKDD EXPL NEWS, V6, P20, DOI DOI 10.1145/1007730.1007735
   Batista GEAPA, 2003, Wob, V3, P10
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Calderon-Ramirez S, 2021, APPL SOFT COMPUT, V111, DOI 10.1016/j.asoc.2021.107692
   Chatterjee S, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10030406
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen L, 2021, EMOTION RECOGNITION, P25
   Chen LF, 2020, IEEE T FUZZY SYST, V28, P1252, DOI 10.1109/TFUZZ.2020.2966167
   Chen LF, 2018, INFORM SCIENCES, V428, P49, DOI 10.1016/j.ins.2017.10.044
   Chen YL, 2019, 2019 INTERNATIONAL CONFERENCE ON MICROWAVE AND MILLIMETER WAVE TECHNOLOGY (ICMMT 2019), DOI 10.1109/icmmt45702.2019.8992327
   Christy A, 2020, INT J SPEECH TECHNOL, V23, P381, DOI 10.1007/s10772-020-09713-y
   Deeb H, 2022, MULTIMED TOOLS APPL, VAppl, P1
   Dino Hivi Ismat, 2019, 2019 International Conference on Advanced Science and Engineering (ICOASE), P70, DOI 10.1109/ICOASE.2019.8723728
   Estabrooks A, 2004, COMPUT INTELL-US, V20, P18, DOI 10.1111/j.0824-7935.2004.t01-1-00228.x
   Fard AP, 2022, IEEE ACCESS, V10, P26756, DOI 10.1109/ACCESS.2022.3156598
   Farzaneh AH, 2021, IEEE WINT CONF APPL, P2401, DOI 10.1109/WACV48630.2021.00245
   Gautam K. S., 2021, International Journal of Computers and Applications, V43, P858, DOI 10.1080/1206212X.2019.1642438
   Ghosh Kushankur, 2021, Advances in Smart Communication Technology and Information Processing. OPTRONIX 2020. Lecture Notes in Networks and Systems (LNNS 165), P207, DOI 10.1007/978-981-15-9433-5_20
   Ghosh K, 2021, 2021 INT C COMP COMM, P1
   Ghosh K, 2021, IEEE INT CONF BIG DA, P4859, DOI 10.1109/BigData52589.2021.9672056
   Ghosh K, 2019, INT CONF AWARE SCI, P384, DOI 10.1109/icawst.2019.8923218
   Green MC, 2021, ARXIV
   Haddad Jad, 2020, Advances in Visual Computing. 15th International Symposium, ISVC 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12510), P298, DOI 10.1007/978-3-030-64559-5_23
   Han H, 2005, LECT NOTES COMPUT SC, V3644, P878, DOI 10.1007/11538059_91
   He HB, 2008, IEEE IJCNN, P1322, DOI 10.1109/IJCNN.2008.4633969
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu M, 2019, J VIS COMMUN IMAGE R, V59, P176, DOI 10.1016/j.jvcir.2018.12.039
   Huang CY, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4717
   Imani M, 2019, J NETW COMPUT APPL, V147, DOI 10.1016/j.jnca.2019.102423
   Jain DK, 2019, PATTERN RECOGN LETT, V120, P69, DOI 10.1016/j.patrec.2019.01.008
   Jang J, 2021, EXPERT SYST APPL, V179, DOI 10.1016/j.eswa.2021.115067
   Japkowicz N., 2002, Intelligent Data Analysis, V6, P429
   Jiang M, 2019, IEEE ENG MED BIO, P6063, DOI [10.1109/embc.2019.8857005, 10.1109/EMBC.2019.8857005]
   Kim D, 2021, AAAI CONF ARTIF INTE, V35, P5948
   Kumov V, 2020, 2020 26 C OPEN INNOV, P1
   Lakshmi D, 2021, MICROPROCESS MICROSY, V82, DOI 10.1016/j.micpro.2021.103834
   Laurikkala J, 2001, LECT NOTES ARTIF INT, V2101, P63, DOI 10.1007/3-540-48229-6_9
   Lee S-C, 2021, J AFFECTIVE DISORDER
   Lee SC, 2020, J AFFECT DISORDERS, V275, P224, DOI 10.1016/j.jad.2020.07.003
   Li Xiaoyan, 2023, Infect Dis Immun, V3, P20, DOI [10.1097/ID9.0000000000000076, 10.1109/TAI.2021.3107807]
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P2439, DOI 10.1109/TIP.2018.2886767
   Lin CJ, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9132593
   Lopes N, 2018, 2018 2 INT C TECHNOL, P1, DOI DOI 10.1109/TISHW.2018.8559494
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Mustaqeem, 2020, IEEE ACCESS, V8, P79861, DOI 10.1109/ACCESS.2020.2990405
   Naruniec J, 2020, COMPUT GRAPH FORUM, V39, P173, DOI 10.1111/cgf.14062
   Ngo QT, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092639
   Nguyen Dung, 2021, IEEE Transactions on Multimedia, P1
   Nguyen Hien M., 2011, International Journal of Knowledge Engineering and Soft Data Paradigms, V3, P4, DOI 10.1504/IJKESDP.2011.039875
   Nnamoko N, 2020, ARTIF INTELL MED, V104, DOI 10.1016/j.artmed.2020.101815
   Ottl Sandra, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P821, DOI 10.1145/3382507.3417964
   Panda MR, 2021, VISUAL COMPUT, P1
   Panda R, 2020, IEEE T AFFECTIVE COM
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pise A, 2022, MULTIMED TOOLS APPL, V81, P26633, DOI 10.1007/s11042-020-10133-y
   Pouyanfar S, 2019, 2019 2ND IEEE CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2019), P199, DOI 10.1109/MIPR.2019.00043
   Rajotte J.F., 2021, ARXIV
   Richardson AM, 2017, BMC MED INFORM DECIS, V17, DOI 10.1186/s12911-017-0522-5
   Ruiz-Garcia A., 2020, 2020 INT JOINT C NEU, P1
   Sengupta S, 2021, PROC SPIE, V11313, DOI 10.1117/12.2549869
   Sivasangari A., 2019, J AMB INTEL HUM COMP, DOI 10.1007/s12652-019-01492-y
   Sujanaa J, 2021, MULTIMED TOOLS APPL, VAppl, P1
   Talpur BA, 2020, INFORMATICS-BASEL, V7, DOI 10.3390/informatics7040052
   Tarnowski P, 2017, PROCEDIA COMPUT SCI, V108, P1175, DOI 10.1016/j.procs.2017.05.025
   Tian Ma, 2020, Mobile Networks and Management. 10th EAI International Conference, MONAMI 2020. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 338), P30, DOI 10.1007/978-3-030-64002-6_3
   Vinay A, 2018, INT C MATH MOD SCI C, P427
   Vinay A, 2018, EMERGING TRENDS ENG, P881
   Wang K, 2020, IEEE T IMAGE PROCESS, V29, P4057, DOI 10.1109/TIP.2019.2956143
   WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137
   Wu JL, 2020, IEEE ACCESS, V8, P66638, DOI 10.1109/ACCESS.2020.2985228
   Xu CT, 2022, EXPERT SYST APPL, V197, DOI 10.1016/j.eswa.2022.116705
   Yang DQ, 2021, ECOL INFORM, V64, DOI 10.1016/j.ecoinf.2021.101350
   Yen SJ, 2009, EXPERT SYST APPL, V36, P5718, DOI 10.1016/j.eswa.2008.06.108
   Yi W, 2018, PR ELECTROMAGN RES S, P710, DOI 10.23919/PIERS.2018.8598226
   Zeng NY, 2018, NEUROCOMPUTING, V273, P643, DOI 10.1016/j.neucom.2017.08.043
   Zepf S, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3388790
   Zhang HL, 2020, IEEE ACCESS, V8, P164130, DOI 10.1109/ACCESS.2020.3021994
   Zhao Juan-juan, 2017, Transactions of Beijing Institute of Technology, V37, P386, DOI 10.15918/j.tbit1001-0645.2017.04.011
   Zheng M, 2021, INFORM SCIENCES, V576, P658, DOI 10.1016/j.ins.2021.07.053
NR 89
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13659
EP 13688
DI 10.1007/s11042-023-15888-8
EA JUL 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001023991000003
DA 2024-07-18
ER

PT J
AU Meng, LJ
   Jiang, XH
   Zhang, ZZ
   Li, ZH
   Sun, TF
AF Meng, Laijin
   Jiang, Xinghao
   Zhang, Zhenzhen
   Li, Zhaohong
   Sun, Tanfeng
TI A robust coverless video steganography based on maximum DC coefficients
   against video attacks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Coverless video steganography; Gaussian distribution model; Maximum DC
   coefficients; Hash generation
AB Coverless steganography has been of great interest in recent years, since it is a technology that can absolutely resist the detection of steganalysis by not modifying the carriers. Most existing coverless steganography algorithms select images as carriers, and few studies are reported on coverless video steganography. Compared with images, the video sequence contains more information. However, there are few methods that can be used in coverless video steganography for resisting video compression and other video attacks. In this paper, a novel coverless video steganography algorithm based on maximum Direct Current (DC) coefficients against video attacks is proposed. Firstly, a Gaussian distribution model of DC coefficients considering the video coding process is built, which indicates that the distribution of changes for maximum DC coefficients in a block is more stable than the adjacent DC coefficients. Then, a novel hash sequence generation method based on the maximum DC coefficients is proposed. After that, the video index structure is established to speed up the efficiency of searching videos. In the process of hiding, the secret information is converted into binary segments, and the video whose hash sequence equals the secret information segment is selected as the carrier according to the video index structure. Experimental results and analysis show that the proposed algorithm can resist most kinds of attacks because of the strong robustness of the maximum DC coefficients. What's more, compared with the state-of-the-art work, the proposed algorithm has achieved apparent advantages in the resistance to the mainstream video coding and frame deletion, and gotten much higher effective capacity.
C1 [Meng, Laijin; Jiang, Xinghao; Sun, Tanfeng] Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
   [Zhang, Zhenzhen] Beijing Inst Grap Commun, Sch Informat Engn, Beijing 102600, Peoples R China.
   [Li, Zhaohong] Beijing Jiaotong Univ, Sch Elect & Informat Engn, Beijing 100044, Peoples R China.
C3 Shanghai Jiao Tong University; Beijing Jiaotong University
RP Jiang, XH (corresponding author), Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
EM menglaijin@sjtu.edu.cn; xhjiang@sjtu.edu.cn; zhangzhenzhen@bigc.edu.cn;
   zhhli2@bjtu.edu.cn; tfsun@sjtu.edu.cn
RI Sun, Xinyu/JXX-2281-2024
FU Scientific Research Common Program of Beijing Municipal Commission of
   Education [KM202110015004]; Nature Natural Science Foundation of China
   [62002220]
FX AcknowledgementsThis work is funded by the Scientific Research Common
   Program of Beijing Municipal Commission of Education (No.
   KM202110015004) and the Nature Natural Science Foundation of China
   (62002220).
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Bojanowski P, 2014, LECT NOTES COMPUT SC, V8693, P628, DOI 10.1007/978-3-319-10602-1_41
   Cetin O, 2009, COMPUT SECUR, V28, P670, DOI 10.1016/j.cose.2009.04.002
   Chen X, 2020, IN PRESS, P1, DOI [10.1109/TNSE.2020.3041529, DOI 10.1109/TNSE.2020.3041529]
   Chhikara S, 2021, MULTIMED TOOLS APPL, V80, P31865, DOI 10.1007/s11042-021-11118-1
   El-Emam NN, 2015, COMPUT SECUR, V55, P21, DOI 10.1016/j.cose.2015.06.012
   Huang FJ, 2012, IEEE T INF FOREN SEC, V7, P1181, DOI 10.1109/TIFS.2012.2198213
   Huang K, 2020, MULTIMED TOOLS APPL, V79, P31147, DOI 10.1007/s11042-020-09435-y
   Jin ZY, 2020, SIGNAL PROCESS, V170, DOI 10.1016/j.sigpro.2020.107455
   Kang ZW, 2007, J SYST ENG ELECTRON, V18, P628, DOI 10.1016/S1004-4132(07)60139-X
   Khare P., 2011, J ENG RES STUDIES, V2, P101
   Lerch-Hostalot D, 2013, COMPUT SECUR, V32, P192, DOI 10.1016/j.cose.2012.11.005
   Li FY, 2022, SIGNAL PROCESS, V190, DOI 10.1016/j.sigpro.2021.108341
   Li ZH, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11081015
   Liu Q, 2020, KNOWL-BASED SYST, V192, DOI 10.1016/j.knosys.2019.105375
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Luo YJ, 2021, IEEE T CIRC SYST VID, V31, P2779, DOI 10.1109/TCSVT.2020.3033945
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Pan N, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00512-8
   Ray B, 2021, MULTIMED TOOLS APPL, V80, P33475, DOI 10.1007/s11042-021-11177-4
   Tan Y, 2021, SECURITY COMMUNICATI
   Wu ST, 2020, IEEE T MULTIMEDIA, V22, P256, DOI 10.1109/TMM.2019.2920605
   Yanbin Zhao, 2016, Digital Forensics and Watermarking. 14th International Workshop, IWDW 2015. Revised Selected Papers: LNCS 9569, P119, DOI 10.1007/978-3-319-31960-5_11
   Yang YY, 2019, MULTIMED TOOLS APPL, V78, P8423, DOI 10.1007/s11042-018-6859-7
   Yuan CS, 2017, J INTERNET TECHNOL, V18, P435, DOI 10.6138/JIT.2017.18.2.20160624c
   Zhai LM, 2020, IEEE T INF FOREN SEC, V15, P1762, DOI 10.1109/TIFS.2019.2949428
   Zhang LY, 2017, LECT NOTES COMPUT SC, V10082, P518, DOI 10.1007/978-3-319-53465-7_39
   Zhang S., 2019, SYMMETRY, V11, P115, DOI [10.3390/sym11010115, DOI 10.3390/SYM11010115]
   Zhang X, 2018, IEEE T MULTIMEDIA, V20, P3223, DOI 10.1109/TMM.2018.2838334
   Zhang Y, 2019, IEEE INT SYM MULTIM, P140, DOI 10.1109/ISM46123.2019.00033
   [张珍珍 Zhang Zhenzhen], 2015, [北京邮电大学学报, Journal of Beijing University of Posts Telecommunications], V38, P84
   Zheng SL, 2017, LECT NOTES ARTIF INT, V10363, P536, DOI 10.1007/978-3-319-63315-2_47
   Zhou ZL, 2019, SOFT COMPUT, V23, P4927, DOI 10.1007/s00500-018-3151-8
   Zou L., 2021, GEOMETRY VIS 1 INT S, P134
NR 34
TC 7
Z9 7
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13427
EP 13461
DI 10.1007/s11042-023-15697-z
EA JUL 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001024891800008
DA 2024-07-18
ER

PT J
AU Verma, V
   Singh, D
   Khanna, N
AF Verma, Vinay
   Singh, Deepak
   Khanna, Nitin
TI Block-level double JPEG compression detection for image forgery
   localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensics; Compression artifacts; Quantization matrix; DenseNet;
   Unseen compression
AB Forged images in JPEG format have a ubiquitous presence in today's world due to the ease of availability of image manipulation tools. This paper presents a deep learning-based system that utilizes the inherent relationship between histograms of quantized DCT coefficients and corresponding quantization step sizes to distinguish between original and forged regions in a JPEG image, based on detecting single and double compressed blocks, without fully decompressing the JPEG image. In this direction, we propose a novel combination of raw histograms of the quantized DCT coefficients and corresponding quantization step sizes and use it as input to the counterpart standard CNN architectures designed to handle the proposed input representation for single vs. double JPEG compression detection. The proposed input is shown to have a minimal effect on performance with various standard CNN architectures that are designed to handle the proposed input for the task at hand. Specifically, we have utilized DenseNet to extract the compression-specific artifacts from the proposed input for additional experiments reported in this work. We considered a publicly available dataset generated with a diverse set of 1,120 quantization matrices. Using the proposed input to learn the compression artifacts outperforms the baseline methods for the blocks of sizes 256 x 256, 128 x 128, and 64 x 64. Furthermore, in the case of test blocks compressed with completely different quantization matrices than matrices used in training, the proposed method outperforms the baseline methods. Consequently, improved forgery localization performances are obtained for forged JPEG images.
C1 [Verma, Vinay] Indian Inst Technol Gandhinagar IITGN, Multimedia Anal & Secur MANAS Lab, Elect Engn, Gandhinagar, India.
   [Singh, Deepak] Indian Inst Technol Gandhinagar IITGN, Multimedia Anal & Secur MANAS Lab, Math, Gandhinagar, India.
   [Khanna, Nitin] Indian Inst Technol Bhilai IITBh, Multimedia Anal & Secur MANAS Lab, Elect Engn & Comp Sci EECS, Gandhinagar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Gandhinagar; Indian Institute of Technology System
   (IIT System); Indian Institute of Technology (IIT) - Gandhinagar; Indian
   Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) Bhilai
RP Khanna, N (corresponding author), Indian Inst Technol Bhilai IITBh, Multimedia Anal & Secur MANAS Lab, Elect Engn & Comp Sci EECS, Gandhinagar, India.
EM vinay.verma@iitgn.ac.in; deepak.singh@msc2016.iitgn.ac.in;
   nitin@iitbhilai.ac.in
RI Khanna, N/AAE-6267-2020
FU Department of Science and Technology (DST), New Delhi, India
   [ECR/2015/000583]
FX This material is based upon work partially supported by a grant from the
   Department of Science and Technology (DST), New Delhi, India, under
   Award Number ECR/2015/000583. Any opinions, findings, and conclusions or
   recommendations expressed in this material are those of the author(s)
   and do not necessarily reflect the views of the funding agencies.
   Address all correspondence to Nitin Khanna at nitin@iitbhilai.ac.in.
CR Amerini I, 2017, IEEE COMPUT SOC CONF, P1865, DOI 10.1109/CVPRW.2017.233
   Amerini I, 2014, IEEE INT WORKS INFOR, P143, DOI 10.1109/WIFS.2014.7084318
   [Anonymous], 2003, P DIG FOR RES WORKSH
   [Anonymous], 2014, APSIPA Trans. Signal Inf. Process, DOI DOI 10.1017/ATSIP.2014.19
   Barni M, 2017, J VIS COMMUN IMAGE R, V49, P153, DOI 10.1016/j.jvcir.2017.09.003
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bianchi T, 2011, INT CONF ACOUST SPEE, P2444
   Chen YL, 2011, IEEE T INF FOREN SEC, V6, P396, DOI 10.1109/TIFS.2011.2106121
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Dang-Nguyen D.T., 2015, P ACM MULT SYST C, P219
   Farid H, 2009, IEEE T INF FOREN SEC, V4, P154, DOI 10.1109/TIFS.2008.2012215
   Fu DD, 2007, PROC SPIE, V6505, DOI 10.1117/12.704723
   Gloe T., 2010, ACM S APPL COMP, P1584, DOI DOI 10.1080/15567281.2010.531500
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hsu YF, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P549, DOI 10.1109/ICME.2006.262447
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kingma D. P., 2014, arXiv
   Korus P, 2017, DIGIT SIGNAL PROCESS, V71, P1, DOI 10.1016/j.dsp.2017.08.009
   Li B., 2017, ARXIV
   Li B, 2019, MULTIMED TOOLS APPL, V78, P8577, DOI 10.1007/s11042-018-7073-3
   Li WH, 2009, SIGNAL PROCESS, V89, P1821, DOI 10.1016/j.sigpro.2009.03.025
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Luo WQ, 2007, INT CONF ACOUST SPEE, P217
   Park J, 2018, LECT NOTES COMPUT SC, V11209, P656, DOI 10.1007/978-3-030-01228-1_39
   Pasquini C, 2014, IEEE INT WORKS INFOR, P113, DOI 10.1109/WIFS.2014.7084313
   Piva A., 2013, Int. Scholarly Res. Notices, V2013
   Popescu AC, 2004, LECT NOTES COMPUT SC, V3200, P128
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Sencar HT, 2009, STAT SCI INTERDISC R, V3, P325
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stamm MC, 2013, IEEE ACCESS, V1, P167, DOI 10.1109/ACCESS.2013.2260814
   Taimori A, 2017, MULTIMED TOOLS APPL, V76, P7749, DOI 10.1007/s11042-016-3409-z
   Verdoliva L, 2020, IEEE J-STSP, V14, P910, DOI 10.1109/JSTSP.2020.3002101
   Verma V, 2018, SIGNAL PROCESS-IMAGE, V67, P22, DOI 10.1016/j.image.2018.04.014
   Wallace G. K., 1991, Communications of the ACM, V34, P30, DOI 10.1145/103085.103089
   Wang JY, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P433
   Wang Q, 2016, EURASIP J INF SECUR, DOI 10.1186/s13635-016-0047-y
   Wang W, 2014, IEEE T INF FOREN SEC, V9, P1653, DOI 10.1109/TIFS.2014.2345479
   Ye SM, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P12
   Zeng XM, 2019, MULTIMED TOOLS APPL, V78, P8183, DOI 10.1007/s11042-018-6737-3
NR 42
TC 1
Z9 1
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 9949
EP 9971
DI 10.1007/s11042-023-15942-5
EA JUN 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001022083300010
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Park, P
   Jang, S
   Cho, Y
   Kim, Y
AF Park, Pilseo
   Jang, Soojin
   Cho, Yunsung
   Kim, Youngbin
TI SAM: cross-modal semantic alignments module for image-text retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image-text retrieval; Cross-modal; Vision-language; Graph neural
   networks
AB Cross-modal image-text retrieval has gained increasing attention due to its ability to combine computer vision with natural language processing. Previously, image and text features were extracted and concatenated to feed the transformer-based retrieval network. However, these approaches implicitly aligned the image and text modalities since the self-attention mechanism computes attention coefficients for all input features. In this paper, we propose cross-modal Semantic Alignments Module (SAM) to establish an explicit alignment through enhancing an inter-modal relationship. Firstly, visual and textual representations were extracted from an image and text pair. Secondly, we constructed a bipartite graph by representing the image regions and words in the sentence as nodes, and the relationship between them as edges. Then our proposed SAM allows the model to compute attention coefficients based on the edges in the graph. This process helps explicitly align the two modalities. Finally, a binary classifier was used to determine whether the given image-text pair is aligned. We reported extensive experiments on MS-COCO and Flickr30K test sets, showing that SAM could capture the joint representation between the two modalities and could be applied to the existing retrieval networks.
C1 [Park, Pilseo] Chung Ang Univ, Dept Artificial Intelligence, Seoul 06974, South Korea.
   [Jang, Soojin; Cho, Yunsung; Kim, Youngbin] Chung Ang Univ, Dept Image Sci & Arts, Seoul 06974, South Korea.
C3 Chung Ang University; Chung Ang University
RP Kim, Y (corresponding author), Chung Ang Univ, Dept Image Sci & Arts, Seoul 06974, South Korea.
EM bpilseo@cau.ac.kr; sujin0110@cau.ac.kr; cho4062002@cau.ac.kr;
   ybkim85@cau.ac.kr
FU Institute for Information amp; communications Technology Planning amp;
   Evaluation (IITP) through the Korea government (MSIT) [2021-0-01341];
   National Research Foundation of Korea (NRF) through the Korea government
   (MSIT) [2022R1C1C1008534]; Korea Creative Content Agency - Ministry of
   Culture, Sports [R2021040044]
FX This research was supported in part by Institute for Information &
   communications Technology Planning & Evaluation (IITP) through the Korea
   government (MSIT) under Grant No. 2021-0-01341 (Artificial Intelligence
   Graduate School Program (Chung-Ang University), Contribution Rate: 33%),
   the National Research Foundation of Korea (NRF) through the Korea
   government (MSIT) under Grant No. NRF- 2022R1C1C1008534 (Contribution
   Rate: 33%), and Culture Technology R &D Program through the Korea
   Creative Content Agency grant funded by Ministry of Culture, Sports and
   Tourism in 2021 (Project Name: A Specialist Training of Content R &D
   based on Virtual Production, Project Number: R2021040044, Contribution
   Rate: 34%).
CR [Anonymous], 2020, ARXIV
   [Anonymous], 2020, ARXIV
   [Anonymous], 2013, P 30 INT C MACHINE L
   [Anonymous], 2020, ARXIV
   Ba J. L., 2016, LAYER NORMALIZATION, DOI DOI 10.48550/ARXIV.1607.06450
   Bi B, 2020, C EMP METH NAT LANG
   Chen TN, 2021, IEEE INT CONF COMP V, P3096, DOI 10.1109/ICCVW54120.2021.00345
   Chen Y., 2019, ARXIV
   Dejie Yang, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P44, DOI 10.1145/3372278.3390673
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Diao H, 2021, ARXIV
   Dong X, 2021, P 29 ACM INT C MULTI
   Faghri F, 2017, BRIT MACHINE VISION
   Frisoni G, 2022, P 2022 C EMP METH NA, P5770, DOI 10.18653/v1/2022
   Gao H, IEEE T NEUR NET LEAR
   Gao HH, 2022, IEEE T COMPUT SOC SY, V9, P336, DOI 10.1109/TCSS.2021.3102591
   Gao H, 2022, IEEE T INTELL TRANSP, V23, P17301, DOI 10.1109/TITS.2022.3154650
   Guo DL, 2023, IEEE T NEUR NET LEAR, V34, P1023, DOI 10.1109/TNNLS.2021.3104937
   Guo JX, 2018, AAAI CONF ARTIF INTE, P5141
   Hamilton W., 2017, PROC NIPS
   Henderson M, 2019, ARXIV
   Ji Z, 2021, ARXIV
   Jiasen Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10434, DOI 10.1109/CVPR42600.2020.01045
   Jimmy Lin, 2021, ACM SIGIR Forum, P1, DOI 10.1145/3527546.3527552
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kayhan N, 2021, MULTIMED TOOLS APPL, V80, P32763, DOI 10.1007/s11042-021-11217-z
   Kim J, 2021, AAAI CONF ARTIF INTE, V35, P1789
   Kim W, 2021, PR MACH LEARN RES, V139
   Kipf T. N., 2017, ARXIV
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Lee K., 2018, ARXIV
   Li LJ, 2019, IEEE I CONF COMP VIS, P10312, DOI 10.1109/ICCV.2019.01041
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Ling Huan, 2021, Advances in Neural Information Processing Systems (NeurIPS)
   Loshchilov I., 2017, P INT C LEARN REPR
   Lu JS, 2019, ADV NEUR IN, V32
   Lu Xiaopeng, 2021, ACL
   Messina N, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3451390
   Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shah R., 2020, INT C EM TRENDS SMAR, V2020, P1
   Shizhe Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9959, DOI 10.1109/CVPR42600.2020.00998
   Song XM, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P992, DOI 10.1145/3477495.3532076
   Takase S, 2021, ARXIV
   Tan HH, 2019, arXiv
   Toker A, 2021, PROC CVPR IEEE, P6484, DOI 10.1109/CVPR46437.2021.00642
   Vaswani A, 2017, ADV NEUR IN, V30
   Velickovic P, 2017, ARXIV
   Wang W, 2020, INT CONF ACOUST SPEE, P8199, DOI [10.1109/ICASSP40776.2020.9052954, 10.1109/icassp40776.2020.9052954]
   Wang Y, 2019, IEEE I CONF COMP VIS, P3522, DOI 10.1109/ICCV.2019.00362
   Wang ZH, 2019, IEEE I CONF COMP VIS, P5763, DOI 10.1109/ICCV.2019.00586
   Yang ZL, 2019, ADV NEUR IN, V32
   Ye Y., 2021, IEEE Transactions on Knowledge and Data Engineering
   Yin X, 2020, EUROPEAN C COMPUTER
   Yu T, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P4655, DOI 10.1145/3511808.3557653
   Zhang SZ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2204
   Zhang YF, 2021, IEEE T IMAGE PROCESS, V30, P617, DOI 10.1109/TIP.2020.3038354
   Zheng ZD, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3383184
NR 58
TC 0
Z9 0
U1 4
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 12363
EP 12377
DI 10.1007/s11042-023-15798-9
EA JUN 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001016469800007
DA 2024-07-18
ER

PT J
AU Nadeem, MS
   Kurugollu, F
   Saravi, S
   Atlam, HF
   Franqueira, VNL
AF Nadeem, Muhammad Shahroz
   Kurugollu, Fatih
   Saravi, Sara
   Atlam, Hany F.
   Franqueira, Virginia N. L.
TI Deep labeller: automatic bounding box generation for synthetic violence
   detection datasets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data labelling; Violence detection; WVD; USI; Synthetic virtual violence
ID MIND
AB Manually labelling datasets for training violence detection systems is time-consuming, expensive, and labor-intensive. Mind wandering, boredom, and short attention span can also cause labelling errors. Moreover, collecting and distributing sensitive images containing violence has ethical implications. Automation is the future for labelling sensitive image datasets. Deep labeller is a two-stage Deep Learning (DL) method that uses pre-trained DL object detection methods on MS-COCO for automatic labelling. The Deep Labeller method labels violent and nonviolent images in WVD and USI. In stage 1, WVD generates weak labels using synthetic images. In stage 2, the Deep labeller method is retrained on weak labels. USI dataset is used to test our method on real-world violence. Deep labeller generated weak and strong labels with an IoU of 0.80036 in stage 1 and 0.95 in stage 2 on the WVD. Automatically generated labels. To test our method's generalisation power, violent and nonviolent image labels on USI dataset had a mean IoU of 0.7450.
C1 [Nadeem, Muhammad Shahroz; Kurugollu, Fatih; Atlam, Hany F.] Univ Derby, Coll Engn & Technol, Markeaton St, Derby DE1 1DW, England.
   [Nadeem, Muhammad Shahroz] Univ Suffolk, Sch Engn Arts Sci & Technol, Ipswich, England.
   [Kurugollu, Fatih] Univ Sharjah, Coll Comp & informat, Sharjah, U Arab Emirates.
   [Saravi, Sara] Loughborough Univ, Epinal Way, Loughborough LE11 3TT, England.
   [Franqueira, Virginia N. L.] Univ Kent, Dept, Giles Ln, Canterbury CT2 7NZ, England.
C3 University of Derby; University of Suffolk; University of Sharjah;
   Loughborough University; University of Kent
RP Nadeem, MS (corresponding author), Univ Derby, Coll Engn & Technol, Markeaton St, Derby DE1 1DW, England.; Nadeem, MS (corresponding author), Univ Suffolk, Sch Engn Arts Sci & Technol, Ipswich, England.
EM M.Nadeem@derby.ac.uk; FKurugollu@sharjah.ac.ae; S.Saravi@lboro.ac.uk;
   H.Atlam@derby.ac.uk; V.Franqueira@kent.ac.uk
RI Kurugollu, Fatih/IWU-3230-2023; Atlam, Hany/S-8160-2018
OI Atlam, Hany/0000-0003-4142-6377; Nadeem, Muhammad
   Shahroz/0000-0001-5835-1602
CR Aktt S, 2019, INT CONF IMAG PROC, DOI 10.1109/ipta.2019.8936070
   Aljundi R, 2017, LECT NOTES COMPUT SC, V10113, P467, DOI 10.1007/978-3-319-54187-7_31
   Bah MD, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111690
   Nievas EB, 2011, LECT NOTES COMPUT SC, V6855, P332, DOI 10.1007/978-3-642-23678-5_39
   Dai JF, 2016, ADV NEUR IN, V29
   Demarty CH, 2014, INT WORK CONTENT MUL
   Dong Y, 2016, NEUROCOMPUTING, V187, P4, DOI 10.1016/j.neucom.2015.09.115
   Eastwood JD, 2012, PERSPECT PSYCHOL SCI, V7, P482, DOI 10.1177/1745691612456044
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fradi H, 2017, IEEE T CIRC SYST VID, V27, P589, DOI 10.1109/TCSVT.2016.2615443
   Huang J, 2017, PROC CVPR IEEE, P3296, DOI 10.1109/CVPR.2017.351
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Killingsworth MA, 2010, SCIENCE, V330, P932, DOI 10.1126/science.1192439
   Le QV, 2013, INT CONF ACOUST SPEE, P8595, DOI 10.1109/ICASSP.2013.6639343
   Li T, 2015, IEEE T CIRC SYST VID, V25, P367, DOI 10.1109/TCSVT.2014.2358029
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu J, 2009, PATTERN RECOGN LETT, V30, P103, DOI 10.1016/j.patrec.2008.02.011
   Liu L, 2009, MEAN AVERAGE PRECISI, P1703, DOI [10.1007/978-0-387-39940-9_3032, DOI 10.1007/978-0-387-39940-9_3032]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557
   Moses Olafenwa, 2018, IMAGEAI OPEN SOURCE
   Nadeem MS, 2019, LECT NOTES ARTIF INT, V11927, P158, DOI 10.1007/978-3-030-34885-4_13
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Niemeyer M, 2018, PR INT CONF DATA SC, P160, DOI 10.1109/DSAA.2018.00026
   Papadopoulos DP, 2016, PROC CVPR IEEE, P854, DOI 10.1109/CVPR.2016.99
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Rota P, 2012, LECT NOTES COMPUT SC, V7585, P111, DOI 10.1007/978-3-642-33885-4_12
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang T, 2019, IEEE T INF FOREN SEC, V14, P1390, DOI 10.1109/TIFS.2018.2878538
   Xiang T, 2005, IEEE I CONF COMP VIS, P1238
   Zhang T, 2017, IEEE T CIRC SYST VID, V27, P696, DOI 10.1109/TCSVT.2016.2589858
   Zhou TF, 2022, IEEE T IMAGE PROCESS, V31, P799, DOI 10.1109/TIP.2021.3132834
NR 33
TC 1
Z9 1
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10717
EP 10734
DI 10.1007/s11042-023-15621-5
EA JUN 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001016153400002
OA Green Submitted, hybrid, Green Accepted
DA 2024-07-18
ER

PT J
AU Usmani, S
   Kumar, S
   Sadhya, D
AF Usmani, Shaheen
   Kumar, Sunil
   Sadhya, Debanjan
TI Efficient deepfake detection using shallow vision transformer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Deepfake; Generative adversarial network;
   Vision transformer
ID NETWORKS; IMAGES
AB Deepfake is a deep learning-based technique that generates fake face images by mimicking the distribution of original images. Deepfake images can be used for malicious intent like creating fake news; hence, it is important to detect them at an early stage. The existing works on deepfake detection mainly focus on appearance-based features and also require substantial computing resources, memory and training data to optimize the model. Since these resources may not be available in many situations, it is important to develop a lightweight model which can work under constrained resources. In this work, we propose a shallow vision transformer for deepfake detection. Our proposed model uses an attention mechanism with a multi-head attention module. The attention mechanism highlights the important sections of deepfake images, whereas the multi-head attention module determines the attention that has to be given to each of the local-level features of an image. Finally, the softmax layer is used to classify an image as real or fake. The proposed model is shallow as it has 16.48 times fewer parameters and approx 2.97 times fewer FLOPS than the baseline vision transformer. Experiments on the Real Fake Face (RFF) and Real and Fake Face Detection (RFFD) datasets show that the model can achieve an accuracy of 92.15% and 88.52% respectively, which are better than many of the existing state-of-the-art models for deepfake detection like GoogleNet, XceptionNet, ResNet50, MesoNet, CNN and baseline vision transformers. Importantly, shallow ViT achieves an accuracy of 90.94% when only half of the RFF dataset is used for training the model, thereby demonstrating its applicability in constrained scenarios.
C1 [Usmani, Shaheen; Kumar, Sunil] ABV Indian Inst Informat Technol & Management, Dept Informat Technol, Gwalior, Madhya Pradesh, India.
   [Sadhya, Debanjan] ABV Indian Inst Informat Technol & Management, Dept Comp Sci & Engn, Gwalior, Madhya Pradesh, India.
C3 ABV-Indian Institute of Information Technology & Management, Gwalior;
   ABV-Indian Institute of Information Technology & Management, Gwalior
RP Sadhya, D (corresponding author), ABV Indian Inst Informat Technol & Management, Dept Comp Sci & Engn, Gwalior, Madhya Pradesh, India.
EM shaheenusmani57@gmail.com; snk@iiitm.ac.in; debanjan.sadhya@gmail.com
RI Kumar, Sunil/GYV-0347-2022
OI Kumar, Sunil/0000-0002-1953-6273
CR Afchar D., 2018, 2018 IEEE INT WORKSH, P1, DOI [DOI 10.1109/WIFS.2018.8630761, 10.1109/WIFS.2018.8630761]
   Bhardwaj D, 2021, FORENSIC SCI INT, V328, DOI 10.1016/j.forsciint.2021.111040
   Dosovitskiy Alexey, 2021, ICLR
   Gong D, 2021, INT J ADV COMPUT SC, V12, DOI [10.14569/IJACSA.2021.0120622, DOI 10.14569/IJACSA.2021.0120622]
   Güera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   Guo YF, 2018, IEEE T INF FOREN SEC, V13, P1932, DOI 10.1109/TIFS.2018.2806926
   Guo ZQ, 2021, COMPUT VIS IMAGE UND, V204, DOI 10.1016/j.cviu.2021.103170
   Hamid Yasir, 2023, International Journal of Information Technology, P5, DOI 10.1007/s41870-022-01130-5
   Han K., 2021, Adv. Neural Inf. Process. Syst., V34, P15908, DOI DOI 10.48550/ARXIV.2103.00112
   Hsu CC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10010370
   Karnouskos Stamatis, 2020, IEEE Transactions on Technology and Society, V1, P138, DOI 10.1109/TTS.2020.3001312
   Korshunov P., 2018, arXiv
   Lee S, 2021, APPL SOFT COMPUT, V105, DOI 10.1016/j.asoc.2021.107256
   McCloskey S, 2019, IEEE IMAGE PROC, P4584, DOI [10.1109/icip.2019.8803661, 10.1109/ICIP.2019.8803661]
   Mirsky Y, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3425780
   Nguyen HH, 2019, INT CONF ACOUST SPEE, P2307, DOI 10.1109/ICASSP.2019.8682602
   Nguyen X., 2021, FORENSIC SCI INT DIG, DOI 10.1016/j.fsidi.2021.301108
   Perov Ivan, 2021, ARXIV
   Rukundo O, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12040985
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Taeb M., 2022, J. Cybersecurity Priv., V2, P89, DOI DOI 10.3390/JCP2010007
   Nguyen TT, 2022, COMPUT VIS IMAGE UND, V223, DOI 10.1016/j.cviu.2022.103525
   Thompson N.C., 2020, arXiv
   Tolosana Ruben, 2020, Information Fusion, V64, P131, DOI 10.1016/j.inffus.2020.06.014
   Vaswani A, 2017, ADV NEUR IN, V30
   Verdoliva L, 2020, IEEE J-STSP, V14, P910, DOI 10.1109/JSTSP.2020.3002101
   Xu ZP, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103119
   Xuan XS, 2019, LECT NOTES COMPUT SC, V11818, P134, DOI 10.1007/978-3-030-31456-9_15
   Yang JC, 2021, FUTURE GENER COMP SY, V125, P127, DOI 10.1016/j.future.2021.06.043
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Zhang Y, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P15, DOI 10.1109/SIPROCESS.2017.8124497
NR 31
TC 1
Z9 1
U1 6
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 12339
EP 12362
DI 10.1007/s11042-023-15910-z
EA JUN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019903000020
DA 2024-07-18
ER

PT J
AU Vaishali, S
   Neetu, S
AF Vaishali, Sharma
   Neetu, Singh
TI Enhanced copy-move forgery detection using deep convolutional neural
   network (DCNN) employing the ResNet-101 transfer learning model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyper-parameters; Cyclical learning rate; Forensics; Deep convolutional
   neural network; Authentication; Vanishing and exploding gradients
ID ROBUST-DETECTION; ALGORITHM; DCT
AB The rapid proliferation of high-quality false images on social media sites calls for research on legitimate image recognition systems. Copy-move forgery (CMF), which involves copying portions of an image, is one of the most commonly used image altering methods. Due to the problem of exploding and vanishing gradients, the present Convolutional Neural Network (CNN) model must be trained for up to 100 epochs to achieve the greatest accuracy. In this work, a deep CNN (DCNN) model using the residual network with 101 deep layers has been used. In order to solve the problem of exploding and disappearing gradients, the concept of skip connections has been included in the residual network. In addition, in order to maximize the performance of the suggested ResNet-101 model, the cyclical learning rate (CLR) hyper-parameter is utilized to further tune the model. The model was trained and evaluated using a variety of datasets, including MICC-F600, MICC-F2000, MICC-F220, and CoMoFoD v2. Accuracy, error rate, true positive rate (TPR), false positive rate (FPR), true negative rate (TNR), and false negative rate (FNR) were analyzed quantitatively. The proposed model achieves highest accuracy of 97.75% only after training the model for 5 epochs only for CoMoFoD v2 dataset. For MICC-F220, MICC-F600 and MICC-F2000 datasets the achieved accuracy was 96.09%, 97.63% and 96.87% respectively only after training the model up to 10 epochs. In order to demonstrate the efficacy of the suggested approach, a comparative study with various state-of-the-art-models available in the literature has been presented.
C1 [Vaishali, Sharma; Neetu, Singh] Jaypee Inst informat & technol, Elect & Commun, Ghaziabad 201309, Uttar Pradesh, India.
RP Vaishali, S (corresponding author), Jaypee Inst informat & technol, Elect & Commun, Ghaziabad 201309, Uttar Pradesh, India.
EM vaishalisharma473@gmail.com; neetu.singh@jiit.ac.in
RI Singh, Neetu/HSH-1859-2023
OI Singh, Neetu/0009-0001-3362-6515
CR Abdalla Y, 2019, INFORMATION, V10, DOI 10.3390/info10090286
   ABID A, 2019, 2019 IEEE INT C DESI, P1
   Agarwal R, 2020, MULTIMED TOOLS APPL, V79, P7355, DOI 10.1007/s11042-019-08495-z
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Ardizzone E, 2010, IEEE IMAGE PROC, P2117, DOI 10.1109/ICIP.2010.5652490
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Bashar M, 2010, IEEE Trans Image Process, DOI 10.1109/TIP.2010.2046599
   Bravo-Solorio S, 2011, SIGNAL PROCESS, V91, P1759, DOI 10.1016/j.sigpro.2011.01.022
   Cao YJ, 2012, FORENSIC SCI INT, V214, P33, DOI 10.1016/j.forsciint.2011.07.015
   Chauhan D, 2016, PROCEDIA COMPUT SCI, V85, P206, DOI 10.1016/j.procs.2016.05.213
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Das T, 2018, IEEE GLOB COMM CONF, DOI 10.1109/GLOCOM.2018.8647566
   Elaskily MA, 2020, MULTIMED TOOLS APPL, V79, P19167, DOI 10.1007/s11042-020-08751-7
   Elaskily MA, 2019, MULTIMED TOOLS APPL, V78, P15353, DOI 10.1007/s11042-018-6891-7
   Gavrilov Andrei Dmitri, 2018, International Journal of Software Science and Computational Intelligence, V10, P19, DOI 10.4018/IJSSCI.2018100102
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1998, INT J UNCERTAIN FUZZ, V6, P107, DOI 10.1142/S0218488598000094
   Howard J, 2020, INFORMATION, V11, DOI 10.3390/info11020108
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Igiri CP, 2015, INT J ENG RES TECHNO, Vvol4
   Kakar P, 2012, IEEE T INF FOREN SEC, V7, P1018, DOI 10.1109/TIFS.2012.2188390
   Kaur H., 2015, INT C J ELECT ELECT, V4, P62
   Lin X, 2018, ENGINEERING-PRC, V4, P29, DOI 10.1016/j.eng.2018.02.008
   Luo WQ, 2006, INT C PATT RECOG, P746
   Lynch G, 2013, INFORM SCIENCES, V239, P253, DOI 10.1016/j.ins.2013.03.028
   Mishra P, 2013, SCI WORLD J, DOI 10.1155/2013/267691
   Ouyang JL, 2017, 2017 10TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI)
   Pachón CG, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11031281
   Popescu AC, 2004, 2016 IEEE INT WORKSH, P1
   Salmon BP, 2015, INT GEOSCI REMOTE SE, P3057, DOI 10.1109/IGARSS.2015.7326461
   Senior A, 2013, INT CONF ACOUST SPEE, P6724, DOI 10.1109/ICASSP.2013.6638963
   Sharma Vaishali, 2021, 2021 7th International Conference on Signal Processing and Communication (ICSC), P146, DOI 10.1109/ICSC53193.2021.9673422
   Smith LN, 2017, IEEE WINT CONF APPL, P464, DOI 10.1109/WACV.2017.58
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Thakur Rahul, 2019, 2019 2nd International Conference on Power Energy, Environment and Intelligent Control (PEEIC), P561, DOI 10.1109/PEEIC47157.2019.8976868
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Ulloa C, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11020476
   Vulli A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22082988
   Wang YL, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102536
   Xu Bo, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P889, DOI 10.1109/MINES.2010.189
   Zhao J, 2013, FORENSIC SCI INT, V233, P158, DOI 10.1016/j.forsciint.2013.09.013
NR 41
TC 2
Z9 2
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10839
EP 10863
DI 10.1007/s11042-023-15724-z
EA JUN 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019903000017
DA 2024-07-18
ER

PT J
AU Iqbal, N
AF Iqbal, Nadeem
TI Image encryption using Queen
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encryption; Decryption; Image processing; Chess; Queen; Chaos
ID DNA-SEQUENCE OPERATION; CHAOTIC SYSTEM; ALGORITHM; MAP; CRYPTANALYSIS;
   SCHEME; IMPROVEMENT; ENHANCEMENTS; CONSTRUCTION; COMBINATION
AB A high performance scrambler (HPS) is presented to encrypt the color square images based on the sophisticated move of Queen on the large hypothetical chessboard. The input plain image is broken into the red, green and blue channels. The pixels of each channel are scrambled by the Queen one by one. Then diffusion effects have been thrown in the scrambled images to get the encrypted images. The final color cipher image has been obtained by merging the cipher images of these three channels. Plaintext sensitivity has been created by the SHA-256 hash function and by making starting address of the Queen dependent upon the randomly chosen pixels from the input plain image. This act also increased the key space. Intertwining logistic map has been employed to get the chaotic vectors. Both the experiments on the computer machine and the security analysis vividly certify efficiency, security and potential for some real world application of the proposed image cipher. The information entropy came out to be 7.9974. Besides, the floating frequency security parameter gave very promising results regarding the uniformly random pixels data in the output encrypted image. Moreover, time complexity of the proposed cipher is very competitive.
C1 [Iqbal, Nadeem] Univ Lahore, Dept Comp Sci & IT, Lahore 54590, Pakistan.
C3 University of Lahore
RP Iqbal, N (corresponding author), Univ Lahore, Dept Comp Sci & IT, Lahore 54590, Pakistan.
EM nadeem.iqbal537@gmail.com
OI Iqbal, Nadeem/0000-0002-0954-5563
CR Alvarez G, 2009, COMMUN NONLINEAR SCI, V14, P3743, DOI 10.1016/j.cnsns.2009.02.033
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Amani HR, 2019, MULTIMED TOOLS APPL, V78, P21537, DOI 10.1007/s11042-018-6989-y
   Murillo-Escobar MA, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21080815
   Aqeel-ur-Rehman, 2018, OPTIK, V153, P117, DOI 10.1016/j.ijleo.2017.09.099
   Aqeel-ur-Rehman, 2016, MULTIMED TOOLS APPL, V75, P11241, DOI 10.1007/s11042-015-2851-7
   Bashir Z, 2021, MULTIMED TOOLS APPL, V80, P1029, DOI 10.1007/s11042-020-09695-8
   Boriga R, 2014, SIGNAL PROCESS-IMAGE, V29, P887, DOI 10.1016/j.image.2014.04.001
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P1159, DOI 10.1007/s11042-015-3088-1
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen JX, 2015, NONLINEAR DYNAM, V81, P1151, DOI 10.1007/s11071-015-2057-6
   Chen L, 2017, NONLINEAR DYNAM, V87, P1797, DOI 10.1007/s11071-016-3153-y
   Choi J, 2016, MULTIMED TOOLS APPL, V75, P14685, DOI 10.1007/s11042-016-3274-9
   Çokal C, 2009, PHYS LETT A, V373, P1357, DOI 10.1016/j.physleta.2009.02.030
   Diaconu AV, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/932875
   ElKamchouchi DH, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22020180
   Floating-Point Working Group, 1985, 7541985 FLOAT POINT
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gao HJ, 2006, CHAOS SOLITON FRACT, V29, P393, DOI 10.1016/j.chaos.2005.08.110
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   Guesmi R, 2016, MULTIMED TOOLS APPL, V75, P4753, DOI 10.1007/s11042-015-2501-0
   Han JW, 1999, OPT ENG, V38
   Hanif M, 2020, IEEE ACCESS, V8, P123536, DOI 10.1109/ACCESS.2020.3004536
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Huang XL, 2012, NONLINEAR DYNAM, V67, P2411, DOI 10.1007/s11071-011-0155-7
   Iqbal N., 2021, JISA, V58
   Iqbal N, 2021, IEEE ACCESS, V9, P118253, DOI 10.1109/ACCESS.2021.3106028
   Iqbal N, 2021, MULTIMED TOOLS APPL, V80, P36305, DOI 10.1007/s11042-021-11386-x
   Iqbal N, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.2.023025
   Iqbal N, 2021, IEEE ACCESS, V9, P8069, DOI 10.1109/ACCESS.2021.3049325
   Ji XY, 2017, MULTIMED TOOLS APPL, V76, P12965, DOI 10.1007/s11042-016-3684-8
   Kulsoom A, 2016, MULTIMED TOOLS APPL, V75, P1, DOI 10.1007/s11042-014-2221-x
   Li CQ, 2012, NONLINEAR DYNAM, V70, P2383, DOI 10.1007/s11071-012-0626-5
   Liu HJ, 2021, SOFT COMPUT, V25, P11077, DOI 10.1007/s00500-021-05849-4
   Liu HJ, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420501734
   Liu HJ, 2020, APPL MATH COMPUT, V376, DOI 10.1016/j.amc.2020.125153
   Liu HJ, 2019, MULTIMED TOOLS APPL, V78, P15997, DOI 10.1007/s11042-018-6996-z
   Liu HJ, 2019, APPL MATH COMPUT, V360, P83, DOI 10.1016/j.amc.2019.04.078
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Mamta, 2021, IEEE-CAA J AUTOMATIC, V8, P1877, DOI 10.1109/JAS.2021.1004003
   Mirzaei O, 2012, NONLINEAR DYNAM, V67, P557, DOI 10.1007/s11071-011-0006-6
   Özkaynak F, 2013, SIG PROCESS COMMUN
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   Ponnain D, 2016, OPTIK, V127, P8111, DOI 10.1016/j.ijleo.2016.05.127
   Ramesh VP., 2017, RAMANUJAN MATH SOC M, V28, P10
   Sam IS, 2012, NONLINEAR DYNAM, V69, P1995, DOI 10.1007/s11071-012-0402-6
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Si YY, 2021, INT J BIFURCAT CHAOS, V31, DOI 10.1142/S0218127421501467
   Solak E, 2010, INT J BIFURCAT CHAOS, V20, P1405, DOI 10.1142/S0218127410026563
   Suri S, 2019, J AMB INTEL HUM COMP, V10, P2277, DOI 10.1007/s12652-018-0825-0
   Wang H, 2018, SIGNAL PROCESS, V144, P444, DOI 10.1016/j.sigpro.2017.11.005
   Wang K, 2005, PHYS LETT A, V343, P432, DOI 10.1016/j.physleta.2005.05.040
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang XY, 2020, OPT LASER ENG, V125, DOI 10.1016/j.optlaseng.2019.105851
   Wang XY, 2014, DIGIT SIGNAL PROCESS, V25, P244, DOI 10.1016/j.dsp.2013.10.020
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wang Y, 2007, PHYS LETT A, V363, P277, DOI 10.1016/j.physleta.2006.11.023
   Wu JH, 2018, SIGNAL PROCESS, V142, P292, DOI 10.1016/j.sigpro.2017.06.014
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Xiang T, 2006, PHYS LETT A, V349, P109, DOI 10.1016/j.physleta.2005.02.083
   Xiao D, 2009, CHAOS SOLITON FRACT, V40, P2191, DOI 10.1016/j.chaos.2007.10.009
   Yavuz E, 2016, COMPUT ELECTR ENG, V54, P471, DOI 10.1016/j.compeleceng.2015.11.008
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Yu ZM, 2018, IEEE ACCESS, V6, P31918, DOI 10.1109/ACCESS.2018.2840119
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhang W, 2015, OPT COMMUN, V338, P199, DOI 10.1016/j.optcom.2014.10.044
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   Zhang YQ, 2014, NONLINEAR DYNAM, V77, P687, DOI 10.1007/s11071-014-1331-3
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhang Y, 2012, NONLINEAR DYNAM, V69, P1091, DOI 10.1007/s11071-012-0329-y
   Zhao MD, 2022, INT J BIFURCAT CHAOS, V32, DOI 10.1142/S021812742250081X
   Zheng QM, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2017.2775038
   Zhou GM, 2015, NEUROCOMPUTING, V169, P150, DOI 10.1016/j.neucom.2014.11.095
   Zhu CX, 2013, NONLINEAR DYNAM, V71, P25, DOI 10.1007/s11071-012-0639-0
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 81
TC 0
Z9 0
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10551
EP 10585
DI 10.1007/s11042-023-15674-6
EA JUN 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001014722500010
DA 2024-07-18
ER

PT J
AU Bellamkonda, S
   Settipalli, L
AF Bellamkonda, Sivaiah
   Settipalli, Lavanya
TI EFL-LCNN: Enhanced face localization augmented light convolutional
   neural network for human emotion recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional Neural Networks; Deep networks; Facial emotion
   recognition; Face localization; Feature extraction; Image enhancement
ID EXPRESSION; FEATURES
AB Facial expression is an inevitable aspect of human communication, and hence facial emotion recognition (FER) has become the basis for many machine vision applications. Many deep learning based FER models have been developed and shown good results on emotion recognition. However, FER using deep learning still suffering from illumination conditions, noise around the face such as hair, background, and other ambience conditions. To mitigate such issues and improve the performance of FER, we propose Enhanced Face Localization augmented Light Convolution Neural Network (EFL-LCNN). EFL-LCNN incorporates three phase pre-processing and Light CNN, a trimmed VGG16 model. Three phase pre-processing includes face detection, enhanced face region cropping for ambience noise removal and image enhancement using CLAHE for addressing illumination problems. Three phase pre-processing is followed by the implementation of Light CNN to improve FER performance with reduced complexity. The EFL-LCNN is rigorously tested on four publicly available benchmark datasets: JAFFE, CK, MUG and KDEF. It is observed from the empirical results that the EFL-LCNN boosted recognition accuracies significantly when compared with the state-of-the-art.
C1 [Bellamkonda, Sivaiah] Indian Inst Informat Technol Kottayam, Dept Comp Sci & Engn, Kottayam 686635, Kerala, India.
   [Settipalli, Lavanya] Indian Inst Informat Technol, Dept Cyber Secur, Kottayam 686635, Kerala, India.
RP Bellamkonda, S (corresponding author), Indian Inst Informat Technol Kottayam, Dept Comp Sci & Engn, Kottayam 686635, Kerala, India.
EM sivaiah.bk@gmail.com; lavanya.sp86@gmail.com
RI Bellamkonda, Sivaiah/A-1645-2016
OI Bellamkonda, Sivaiah/0000-0001-6948-3483
CR Aifanti N., 2010, P 11 INT WORKSH IM A, DOI DOI 10.1371/JOURNAL.PONE.0009715
   Alphonse AS, 2021, J AMB INTEL HUM COMP, V12, P3447, DOI 10.1007/s12652-020-02517-7
   Banerjee A, 2022, MULTIMED TOOLS APPL, P1
   Barua PD, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-21380-4
   Bellamkonda Sivaiah, 2018, 2018 Second International Conference on Intelligent Computing and Control Systems (ICICCS). Proceedings, P1457, DOI 10.1109/ICCONS.2018.8662971
   Bellamkonda S, 2023, COGN NEURODYNAMICS, V17, P985, DOI 10.1007/s11571-022-09879-y
   Bellamkonda S, 2020, INT J AMBIENT COMPUT, V11, P48, DOI 10.4018/IJACI.2020010103
   Chowdary MK, 2023, NEURAL COMPUT APPL, V35, P23311, DOI 10.1007/s00521-021-06012-8
   Ekman P., 1978, Facial action coding system
   Gopalan N., 2018, 2018 International Conference on Inventive Research in Computing Applications (ICIRCA), P1149
   Gopalan N. P., 2018, International Journal of Image, Graphics and Signal Processing, V10, P27, DOI 10.5815/ijigsp.2018.09.04
   Kanade T., 2000, P 4 IEEE INT C AUT F, P46, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]
   Kar NB., 2022, IMAGE VISION COMPUT, V123, P44
   Kim TH, 2018, ELECTRON LETT, V54, P1326, DOI 10.1049/el.2018.6932
   Lundqvist D, 1998, COGNITION EMOTION, DOI [DOI 10.1037/T27732000, 10.1037/t27732-000, DOI 10.1037/T27732-000]
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Pizer S. M., 1990, Proceedings of the First Conference on Visualization in Biomedical Computing (Cat. No.90TH0311-1), P337, DOI 10.1109/VBC.1990.109340
   Reddy AH, 2022, SIGNAL IMAGE VIDEO P, V16, P369, DOI 10.1007/s11760-021-01941-2
   Sivaiah B., 2018, IJ MATH SCI COMPUT, V4, P56
   Sivaiah B, 2023, SIGNAL IMAGE VIDEO P, V17, P1705, DOI 10.1007/s11760-022-02381-2
   Sun X, 2021, NEUROCOMPUTING, V444, P378, DOI 10.1016/j.neucom.2019.11.127
   Sun Z, 2022, ARTIF INTELL REV, V55, P6547, DOI 10.1007/s10462-022-10160-1
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Xie SY, 2019, IEEE T MULTIMEDIA, V21, P211, DOI 10.1109/TMM.2018.2844085
   Yang B, 2018, IEEE ACCESS, V6, P4630, DOI 10.1109/ACCESS.2017.2784096
   Zhang KH, 2017, IEEE T IMAGE PROCESS, V26, P4193, DOI 10.1109/TIP.2017.2689999
NR 27
TC 0
Z9 0
U1 5
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 12089
EP 12110
DI 10.1007/s11042-023-15899-5
EA JUN 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019116600013
DA 2024-07-18
ER

PT J
AU Cohen, J
   Crispim-Junior, C
   Chiappa, JM
   Rodet, LT
AF Cohen, Julia
   Crispim-Junior, Carlos
   Chiappa, Jean-Marc
   Rodet, Laure Tougne
TI Industrial object detection with multi-modal SSD: closing the gap
   between synthetic and real images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Deep learning; Synthetic dataset; Industrial; RGB-D
ID UNSUPERVISED DOMAIN ADAPTATION
AB Object detection for industrial applications faces challenges that are yet to solve by state-of-the-art deep learning models. They usually lack training data, and the common solution of using a synthetic dataset introduces a domain gap when the model is provided real images. Besides, few architectures fit in the small memory of a mobile device and run in real-time with limited computation capabilities. The models fulfilling these requirements generally have low learning capacity, and the domain gap reduces further the performance. In this work, we propose multiple strategies to reduce the domain gap when using RGB-D images, and to increase the overall performance of a Convolutional Neural Network (CNN) for object detection with a reasonable increase of the model size. First, we propose a new architecture based on the Single Shot Detector (SSD) architecture, and we compare different fusion methods to increase the performance with few or no additional parameters. We applied the proposed method to three synthetic datasets with different visual characteristics, and we show that classical image processing reduces significantly the domain gap for depth maps. Our experiments have shown an improvement when fusing RGB and depth images for two benchmark datasets, even when the depth maps contain few discriminative information. Our RGB-D SSD Lite model performs on par or better than a ResNet-FPN RetinaNet model on the LINEMOD and T-LESS datasets, while requiring 20 times less computation. Finally, we provide some insights on training a robust model for improved performance when one of the modalities is missing.
C1 [Cohen, Julia; Crispim-Junior, Carlos; Rodet, Laure Tougne] Univ Lyon, Univ Lyon 2, CNRS, Cent Lyon,INSA Lyon,UCBL,LIRIS,UMR 5205, F-69676 Bron, France.
   [Cohen, Julia; Chiappa, Jean-Marc] DEMS, St Bonnet de Mure, France.
C3 Universite Claude Bernard Lyon 1; Institut National des Sciences
   Appliquees de Lyon - INSA Lyon; Centre National de la Recherche
   Scientifique (CNRS); Universite Lyon 2
RP Crispim-Junior, C (corresponding author), Univ Lyon, Univ Lyon 2, CNRS, Cent Lyon,INSA Lyon,UCBL,LIRIS,UMR 5205, F-69676 Bron, France.
EM carlos.crispim-junior@liris.cnrs.fr
FU ANRT;  [n.2018/0872]
FX This work was supported by grant CIFRE n.2018/0872 from ANRT.
CR Abu Alhaija H, 2018, INT J COMPUT VISION, V126, P961, DOI 10.1007/s11263-018-1070-x
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.470
   Sampaio IGB, 2021, PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON ENTERPRISE INFORMATION SYSTEMS (ICEIS 2021), VOL 1, P75, DOI 10.5220/0010451100750082
   Bi S, 2019, IEEE I CONF COMP VIS, P2730, DOI 10.1109/ICCV.2019.00282
   Bousmalis K, 2017, PROC CVPR IEEE, P95, DOI 10.1109/CVPR.2017.18
   Carlson A, 2019, LECT NOTES COMPUT SC, V11129, P505, DOI 10.1007/978-3-030-11009-3_31
   Carlucci Fabio Maria, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1362, DOI 10.1109/ICRA.2017.7989162
   Carlucci FM, 2019, PROC CVPR IEEE, P2224, DOI 10.1109/CVPR.2019.00233
   Cavallari GB, 2018, SIBGRAPI, P440, DOI 10.1109/SIBGRAPI.2018.00063
   Chang A. X., 2015, ARXIV
   Cohen J, 2021, IEEE IMAGE PROC, P714, DOI 10.1109/ICIP42928.2021.9506574
   Cohen J, 2020, PROCEEDINGS OF THE 15TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 5: VISAPP, P644, DOI 10.5220/0008975506440651
   Denninger M, 2019, ARXIV
   Doersch C, 2015, IEEE I CONF COMP VIS, P1422, DOI 10.1109/ICCV.2015.167
   Donahue J., 2016, arXiv
   Dosovitskiy A, 2016, IEEE T PATTERN ANAL, V38, P1734, DOI 10.1109/TPAMI.2015.2496141
   Dvornik N, 2018, LECT NOTES COMPUT SC, V11216, P375, DOI 10.1007/978-3-030-01258-8_23
   Eitel A, 2015, IEEE INT C INT ROBOT, P681, DOI 10.1109/IROS.2015.7353446
   Everingham M., 2007, The PASCAL Visual Object Classes Chal- lenge (VOC) Results, DOI 10.1007/s11263-009-0275-4
   Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406
   Fang K, 2018, IEEE INT CONF ROBOT, P3516, DOI 10.1109/ICRA.2018.8461041
   Feng ZY, 2019, IEEE I CONF COMP VIS, P3244, DOI 10.1109/ICCV.2019.00334
   Fujii K, 2022, IEEE ACCESS, V10, P59534, DOI 10.1109/ACCESS.2022.3180344
   Ganin Y, 2016, J MACH LEARN RES, V17
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Gao Y, 2019, PROC CVPR IEEE, P3200, DOI 10.1109/CVPR.2019.00332
   Ghifary M, 2016, LECT NOTES COMPUT SC, V9908, P597, DOI 10.1007/978-3-319-46493-0_36
   Ghifary M, 2015, IEEE I CONF COMP VIS, P2551, DOI 10.1109/ICCV.2015.293
   Giannone G, 2019, IEEE COMPUT SOC CONF, P408, DOI 10.1109/CVPRW.2019.00054
   Gidaris S., 2018, P 6 INT C LEARNING R
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Goyal P, 2019, IEEE I CONF COMP VIS, P6400, DOI 10.1109/ICCV.2019.00649
   Gschwandtner Michael, 2011, PROC 7 INT S VISUAL, P199, DOI DOI 10.1007/978-3-642-24031-7_20
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Heindl C, 2020, INT C PATTERN RECOGN, P538, DOI [DOI 10.1007/978-3-030-68799-1_39, 10.1007/978-3-030-68799-1_39]
   Hinterstoisser S, 2019, IEEE INT CONF COMP V, P2787, DOI 10.1109/ICCVW.2019.00340
   Hinterstoisser S, 2019, LECT NOTES COMPUT SC, V11129, P682, DOI 10.1007/978-3-030-11009-3_42
   Hinterstoisser V., 2012, P COMP VIS ACCV 2012, P548
   Hodan T, 2020, ARXIV
   Hodan T, 2018, LECT NOTES COMPUT SC, V11214, P19, DOI 10.1007/978-3-030-01249-6_2
   Hodan T, 2017, IEEE WINT CONF APPL, P880, DOI 10.1109/WACV.2017.103
   Hoffman J, 2018, PR MACH LEARN RES, V80
   Hoffman J, 2016, IEEE INT CONF ROBOT, P5032, DOI 10.1109/ICRA.2016.7487708
   Hou SH, 2016, IEEE COMPUT SOC CONF, P1092, DOI 10.1109/CVPRW.2016.140
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jalal M, 2019, IEEE COMPUT SOC CONF, P475, DOI 10.1109/CVPRW.2019.00063
   Jaritz M., 2020, CVPR, P12605
   Karras Tero, 2020, IEEE C COMP VIS PATT
   Kim D, 2018, IEEE WINT CONF APPL, P793, DOI 10.1109/WACV.2018.00092
   Kim J, 2019, LECT NOTES COMPUT SC, V11364, P90, DOI 10.1007/978-3-030-20870-7_6
   Koch S, 2019, PROC CVPR IEEE, P9593, DOI 10.1109/CVPR.2019.00983
   Ku J, 2018, 2018 15TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P16, DOI 10.1109/CRV.2018.00013
   Langlois J, 2018, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS (ICPRAM 2018), P409, DOI 10.5220/0006597604090416
   Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35
   Lee KH, 2018, ECO-EFFIC IND SCI, V33, P1, DOI 10.1007/978-3-319-70899-7_1
   Li YJ, 2019, PR MACH LEARN RES, V97
   Liu DN, 2023, IEEE T MULTIMEDIA, V25, P1333, DOI 10.1109/TMM.2022.3141614
   Liu M.-Y., 2016, P ADV NEUR INF PROC, P469
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Loghmani MR, 2020, IEEE ROBOT AUTOM LET, V5, P6631, DOI 10.1109/LRA.2020.3007092
   Marcel S., 2010, P 18 ACM INT C MULTI, P1485, DOI DOI 10.1145/1873951.1874254
   Mishra S, 2022, PROC CVPR IEEE, P9184, DOI 10.1109/CVPR52688.2022.00898
   Misra I, 2016, PROC CVPR IEEE, P3994, DOI 10.1109/CVPR.2016.433
   Neverova N, 2016, IEEE T PATTERN ANAL, V38, P1692, DOI 10.1109/TPAMI.2015.2461544
   Nogues FC, 2018, ARXIV
   Noroozi M, 2016, LECT NOTES COMPUT SC, V9910, P69, DOI 10.1007/978-3-319-46466-4_5
   Ophoff T, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19040866
   Padilla R, 2020, INT CONF SYST SIGNAL, P237, DOI [10.1109/IWSSIP48289.2020.9145130, 10.1109/iwssip48289.2020.9145130]
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Pavlakos G., 2017, P IEEE C COMPUTER VI, P2011, DOI DOI 10.1109/CVPR.2017.139
   Peng XC, 2015, IEEE I CONF COMP VIS, P1278, DOI 10.1109/ICCV.2015.151
   Pizzati F, 2020, IEEE WINT CONF APPL, P2979, DOI 10.1109/WACV45572.2020.9093540
   Planche B, 2017, INT CONF 3D VISION, P1, DOI 10.1109/3DV.2017.00011
   Prakash A, 2019, IEEE INT CONF ROBOT, P7249, DOI [10.1109/icra.2019.8794443, 10.1109/ICRA.2019.8794443]
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Ren ZZ, 2018, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.2018.00086
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Roitberg A, 2019, IEEE COMPUT SOC CONF, P198, DOI 10.1109/CVPRW.2019.00029
   Rozantsev A, 2015, COMPUT VIS IMAGE UND, V137, P24, DOI 10.1016/j.cviu.2014.12.006
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sarkar K, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 5, P130, DOI 10.5220/0006272901300137
   Schwarz M, 2018, INT J ROBOT RES, V37, P437, DOI 10.1177/0278364917713117
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Shrivastava A, 2017, PROC CVPR IEEE, P2242, DOI 10.1109/CVPR.2017.241
   Song SR, 2017, PROC CVPR IEEE, P190, DOI 10.1109/CVPR.2017.28
   Sun XY, 2018, PROC CVPR IEEE, P2974, DOI 10.1109/CVPR.2018.00314
   Sun Y., 2019, ARXIV
   Sundermeyer Martin, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13913, DOI 10.1109/CVPR42600.2020.01393
   Sundermeyer M, 2018, LECT NOTES COMPUT SC, V11210, P712, DOI 10.1007/978-3-030-01231-1_43
   Sweeney C, 2019, IEEE INT CONF ROBOT, P796, DOI [10.1109/icra.2019.8793820, 10.1109/ICRA.2019.8793820]
   Thalhammer S, 2019, TUGRAZ OPEN LIB, P14
   To T, 2018, NDDS NVIDIA DEEP LEA
   Tobin Josh, 2017, 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), P23, DOI 10.1109/IROS.2017.8202133
   Tremblay J., 2018, ARXIV180910790, P306
   Tremblay J, 2018, IEEE COMPUT SOC CONF, P1082, DOI 10.1109/CVPRW.2018.00143
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Xiang Y, 2016, LECT NOTES COMPUT SC, V9912, P160, DOI 10.1007/978-3-319-46484-8_10
   Xiang Y, 2014, IEEE WINT CONF APPL, P75, DOI 10.1109/WACV.2014.6836101
   Xiaoqi Zhao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P646, DOI 10.1007/978-3-030-58542-6_39
   Xu XY, 2017, PATTERN RECOGN, V72, P300, DOI 10.1016/j.patcog.2017.07.026
   Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255
   Yu J., 2016, P 24 ACM INT C MULT, P516, DOI DOI 10.1145/2964284.2967274
   Yue XY, 2019, IEEE I CONF COMP VIS, P2100, DOI 10.1109/ICCV.2019.00219
   Zakharov S, 2019, IEEE I CONF COMP VIS, P532, DOI 10.1109/ICCV.2019.00062
   Zhang D, 2022, INFORM FUSION, V78, P138, DOI 10.1016/j.inffus.2021.09.011
   Zhang R, 2017, PROC CVPR IEEE, P645, DOI 10.1109/CVPR.2017.76
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhao X., 2021, arXiv
   Zhou KY, 2023, IEEE T PATTERN ANAL, V45, P4396, DOI 10.1109/TPAMI.2022.3195549
   Zhou Q, 2016, ARXIV
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 117
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 12111
EP 12138
DI 10.1007/s11042-023-15367-0
EA JUN 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019116600009
DA 2024-07-18
ER

PT J
AU Mahalingam, N
   Sharma, P
AF Mahalingam, Nagarajan
   Sharma, Priyanka
TI An intelligent blockchain technology for securing an IoT-based
   agriculture monitoring system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recurrent Neural Approach; Blockchain Technology; Agricultural data;
   Elliptical Curve Crypto analysis; Cryptanalysis
ID INTERNET; THINGS
AB Nowadays, securing the sensed data in the cloud server is one of the significant concerns in blockchain technology. Although different Machine Learning (ML) based security frameworks are developed, they face specific issues in confidentiality, time consumption, if the dataset is large, processing the data in an existing security system isn't easy, etc. Thus, a novel hybrid Recurrent Neural Elliptical Curve Blockchain (RNECB) was designed to securely store the sensed agricultural data in the cloud server. The dataset was gathered from a standard website. This model filters the input dataset in the pre-processing phase and enters it into the field monitoring module. The monitoring mechanism in the presented approach provides continuous monitoring and extracts meaningful features. In addition, crypto analysis was carried out to hide the extracted features from third parties. These encrypted data were then stored in the cloud server. Furthermore, security analysis was performed by launching attacks on the cloud server, and the results are estimated in two cases before and after the attack. The presented model was implemented in python software, and the accuracy attained about 97.7%, the confidential rate about 97.98%, encryption, decryption, and execution time taken were about 2.7 ms, 2.6 ms, and 11 ms, respectively. And also, the proposed model attained a lower error rate of about 0.0227%. The calculated results were compared with the existing security approaches. The comparative assessment verifies that the designed model earned better results than others.
C1 [Mahalingam, Nagarajan; Sharma, Priyanka] Rashtriya Raksha Univ, Sch IT AI & Cyber Secur, Gandhinagar 382305, Gujarat, India.
RP Mahalingam, N (corresponding author), Rashtriya Raksha Univ, Sch IT AI & Cyber Secur, Gandhinagar 382305, Gujarat, India.
EM mnagarajan@gujgov.edu.in
CR Ab Aziz MF, 2021, EXPERT SYST APPL, V183, DOI 10.1016/j.eswa.2021.115441
   Adam I, 2021, INF ECON POLICY, V57, DOI 10.1016/j.infoecopol.2021.100950
   Akhter R, 2022, J KING SAUD UNIV-COM, V34, P5602, DOI 10.1016/j.jksuci.2021.05.013
   Al Sadawi A, 2021, TECHNOL FORECAST SOC, V173, DOI 10.1016/j.techfore.2021.121124
   Alharbi A, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23063020
   Aydinocak EU, 2022, LOGISTICS 4 0 FUTURE, ppp153
   Benyam A, 2021, J CLEAN PROD, V323, DOI 10.1016/j.jclepro.2021.129099
   Bodendorf F, 2022, IND MARKET MANAG, V104, P400, DOI 10.1016/j.indmarman.2022.04.003
   Chatterjee K, 2023, COMPUT ELECTR ENG, V106, DOI 10.1016/j.compeleceng.2023.108594
   Dalla'Ora N, 2022, IEEE T EMERG TOP COM, V10, P46, DOI 10.1109/TETC.2021.3132432
   Deshpande V, 2022, PEER PEER NETW APPL, V15, P267, DOI 10.1007/s12083-021-01248-6
   Devi N, 2023, ECOL INFORM, V75, DOI 10.1016/j.ecoinf.2023.102044
   Dey K, 2021, J CLEAN PROD, V316, DOI 10.1016/j.jclepro.2021.128254
   Ehlers MH, 2021, FOOD POLICY, V100, DOI 10.1016/j.foodpol.2020.102019
   Garcia L., 2018, Network Protocols and Algorithms, V10, P23, DOI DOI 10.5296/NPA.V10I1.12798
   Ghayvat H, 2021, SUSTAIN CITIES SOC, V69, DOI 10.1016/j.scs.2021.102798
   Gkountis C, 2017, JT IFIP WIREL MOB
   Goel A, 2023, PEER PEER NETW APPL, V1, P1
   Grover Preeti, 2021, 2021 2nd International Conference on Big Data Analytics and Practices (IBDAP), P112, DOI 10.1109/IBDAP52511.2021.9552120
   Gyawali BR, 2023, TECHNOL SOC, V72, DOI 10.1016/j.techsoc.2023.102202
   Hemdan EED., 2023, MULTIMED TOOLS APP, V1, P1
   Hu Y, 2022, ADV FUNCT MATER, V32, DOI 10.1002/adfm.202109181
   Jamil S, 2021, TELECOMMUN POLICY, V45, DOI 10.1016/j.telpol.2021.102206
   Kaushik I, 2021, 2021 IEEE 12TH ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS & MOBILE COMMUNICATION CONFERENCE (UEMCON), P854, DOI 10.1109/UEMCON53757.2021.9666554
   Keshk M, 2021, IEEE ACCESS, V9, P55077, DOI 10.1109/ACCESS.2021.3069737
   Li HZ, 2019, IEEE ACCESS, V7, P179273, DOI 10.1109/ACCESS.2019.2956157
   Lin HF, 2023, DIGIT COMMUN NETW, V9, P111, DOI 10.1016/j.dcan.2022.09.021
   Majumder S, 2021, WIRELESS PERS COMMUN, V116, P1867, DOI 10.1007/s11277-020-07769-2
   Manikandan R, 2023, WIRELESS PERS COMMUN, V128, P1715, DOI 10.1007/s11277-022-10016-5
   Mohanta Bhabendu Kumar, 2021, 2021 19th OITS International Conference on Information Technology (OCIT)., P410, DOI 10.1109/OCIT53463.2021.00086
   Nanda SK, 2023, MULTIMED TOOLS APPL, V82, P32917, DOI 10.1007/s11042-023-14846-8
   Ntantogian C, 2021, HDB COMPUTATIONAL NE, P1
   Obi Reddy G. P., 2023, Smart agriculture for developing nations: Status, perspectives and challenges, P15
   Pourvahab M, 2019, IEEE ACCESS, V7, P153349, DOI 10.1109/ACCESS.2019.2946978
   Praveen P., 2021, Blockchain Applications in IoT Ecosystem, P225
   Qazi R, 2021, J AMB INTEL HUM COMP, V12, P547, DOI 10.1007/s12652-020-02020-z
   Rajan Thomas P., 2022, IECON 2022 - 48th Annual Conference of the IEEE Industrial Electronics Society, P1, DOI 10.1109/IECON49645.2022.9968385
   Raju KL., 2023, MULTIMED TOOLS APP, V22, P1
   Ramamoorthi S, 2023, COMPUT COMMUN, V202, P166, DOI 10.1016/j.comcom.2023.02.010
   Rejeb A, 2023, INTERNET THINGS-NETH, V22, DOI 10.1016/j.iot.2023.100721
   Ren W, 2021, FUTURE GENER COMP SY, V117, P453, DOI 10.1016/j.future.2020.12.007
   Rezk NG, 2021, MULTIMED TOOLS APPL, V80, P773, DOI 10.1007/s11042-020-09740-6
   Sharma A, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4333
   Sinha BB, 2022, FUTURE GENER COMP SY, V126, P169, DOI 10.1016/j.future.2021.08.006
   Suresh, 2023, MULTIMED TOOLS APPL, V82, P1935, DOI 10.1007/s11042-022-12893-1
   Taha M, 2017, IEEE INT CONF COMM, P840, DOI 10.1109/ICCW.2017.7962763
   Thakur PS, 2023, MULTIMED TOOLS APPL, V82, P497, DOI 10.1007/s11042-022-13144-z
   Tyagi AK, 2021, IJIN, V2, P175, DOI DOI 10.1016/J.IJIN.2021.09.007
   Vangala A, 2023, IEEE T INF FOREN SEC, V18, P904, DOI 10.1109/TIFS.2022.3231121
   Velmurugadass P, 2021, MATER TODAY-PROC, V37, P2653, DOI 10.1016/j.matpr.2020.08.519
   Venkataraman Ramanathan, 2021, CSI Transactions on ICT, V9, P207, DOI 10.1007/s40012-021-00341-8
   Vidal VF, 2022, FUTURE GENER COMP SY, V135, P146, DOI 10.1016/j.future.2022.04.015
NR 52
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10297
EP 10320
DI 10.1007/s11042-023-15985-8
EA JUN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019116600007
DA 2024-07-18
ER

PT J
AU Thirumoorthy, K
   Britto, JJJ
AF Thirumoorthy, K.
   Britto, J. Jerold John
TI A feature selection model for document classification using Tom and
   Jerry Optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature selection; Tom and Jerry optimization; Parameter-free
   optimization; Text classification
AB Since the last decade, high-dimensional data has been increasing in various document mining fields, such as text summarization, text clustering, and text classification. The curse of dimensionality has an impact on the classification model's performance. The feature selection strategy is extremely effective in dealing with the curse of dimensionality issue. In this work, we present the Tom and Jerry Optimization technique(TJO) for feature subset selection. The proposed work uses the classifier error rate and the feature chosen rate to measure the candidate's fitness. The performance of the proposed scheme is examined using two popular benchmark text corpus and compared with five metaheuristic approaches. The best success rate obtained by the proposed scheme is 95.77%, whereas the best precision is 0.9509, recall is 0.9577 and F1-score is 0.9541. According to the comparison results, the proposed feature subset selection scheme outperforms the standard strategy.
C1 [Thirumoorthy, K.] Mepco Schlenk Engn Coll, Sivakasi 626005, India.
   [Britto, J. Jerold John] Ramco Inst Technol, Rajapalayam 626117, India.
C3 Mepco Schlenk Engineering College
RP Thirumoorthy, K (corresponding author), Mepco Schlenk Engn Coll, Sivakasi 626005, India.
EM kthirumoorthy@mepcoeng.ac.in; jerold@ritrjpm.ac.in
RI J, JEROLD JOHN BRITTO/JUF-6708-2023
OI J, JEROLD JOHN BRITTO/0000-0002-0881-4987; Karpagalingam,
   Thirumoorthy/0000-0001-8107-5183
CR Adam SP, 2019, SPRINGER OPTIM APPL, V145, P57, DOI 10.1007/978-3-030-12767-1_5
   Bahassine S, 2020, J KING SAUD UNIV-COM, V32, P225, DOI 10.1016/j.jksuci.2018.05.010
   Bai XH, 2018, IEEE C EVOL COMPUTAT, P989, DOI 10.1109/CEC.2018.8477773
   Balochian S, 2019, EXPERT SYST APPL, V134, P178, DOI 10.1016/j.eswa.2019.05.035
   Behjat A., 2013, PSO BASED FEATURE SU, V378, P183, DOI [10.1007/978-3-642-40567-9_16, DOI 10.1007/978-3-642-40567-9_16]
   Chantar H, 2020, NEURAL COMPUT APPL, V32, P12201, DOI 10.1007/s00521-019-04368-6
   Dada EG, 2019, HELIYON, V5, DOI 10.1016/j.heliyon.2019.e01802
   Dehghani M., 2020, Int J Intell Eng Syst, V13, P246
   Dey Sarkar Subhajit, 2014, Int Sch Res Notices, V2014, P717092, DOI 10.1155/2014/717092
   Dhar A., 2019, Efficient feature selection based on modified cuckoo search optimization problem for classifying web text documents, P640
   Elakiya E, 2021, J AMB INTEL HUM COMP, V12, P3571, DOI 10.1007/s12652-019-01588-5
   Feng GZ, 2015, PATTERN RECOGN LETT, V65, P109, DOI 10.1016/j.patrec.2015.07.028
   Ghareb AS, 2016, EXPERT SYST APPL, V49, P31, DOI 10.1016/j.eswa.2015.12.004
   Jalal N, 2022, J KING SAUD UNIV-COM, V34, P2733, DOI 10.1016/j.jksuci.2022.03.012
   Kawade D., 2017, International Journal of Engineering and Technology, V09, P2183, DOI [DOI 10.21817/IJET/2017/V9I3/1709030151, 10.21817/ijet/2017/v9i3/170903151, DOI 10.21817/IJET/2017/V9I3/170903151]
   Kim K, 2019, DATA KNOWL ENG, V119, P1, DOI 10.1016/j.datak.2018.10.003
   Kumar A, 2019, INT J INF RETR RES, V9, P1, DOI 10.4018/IJIRR.2019010101
   Kumar A, 2017, ADV INTELL SYST, V556, P693, DOI 10.1007/978-981-10-3874-7_66
   Marie-Sainte SL, 2020, J KING SAUD UNIV-COM, V32, P320, DOI 10.1016/j.jksuci.2018.06.004
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2016, KNOWL-BASED SYST, V96, P120, DOI 10.1016/j.knosys.2015.12.022
   Mirjalili S, 2016, NEURAL COMPUT APPL, V27, P495, DOI 10.1007/s00521-015-1870-7
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Moghdani R, 2018, APPL SOFT COMPUT, V64, P161, DOI 10.1016/j.asoc.2017.11.043
   Moosavi SHS, 2019, ENG APPL ARTIF INTEL, V86, P165, DOI 10.1016/j.engappai.2019.08.025
   Neogi Pinaki Prasad Guha, 2020, Emerging Technology in Modelling and Graphics. Proceedings of IEM Graph 2018. Advances in Intelligent Systems and Computing (AISC 937), P395, DOI 10.1007/978-981-13-7403-6_36
   Parlak B, 2023, J INF SCI, V49, P59, DOI 10.1177/0165551521991037
   Rao R., 2016, Int J Ind Eng Comput, V7, P19, DOI [DOI 10.5267/J.IJIEC.2015.8.004, 10.5267/j.ijiec.2015.8.004]
   Rao RV, 2020, INT J IND ENG COMP, V11, P107, DOI 10.5267/j.ijiec.2019.6.002
   Rehman A, 2018, EXPERT SYST APPL, V114, P78, DOI 10.1016/j.eswa.2018.07.028
   Rehman A, 2017, INFORM PROCESS MANAG, V53, P473, DOI 10.1016/j.ipm.2016.12.004
   Rustam Z., 2021, IAES INT J ARTIF INT, V10, P253, DOI 10.11591/ijai.v10.i1.pp253-256
   S R Sannasi Chakravarthy, 2019, Asian Pac J Cancer Prev, V20, P2333, DOI 10.31557/APJCP.2019.20.8.2333
   Saigal P, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-2266-6
   Saremi S, 2017, ADV ENG SOFTW, V105, P30, DOI 10.1016/j.advengsoft.2017.01.004
   Sel I, 2019, 2019 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND DATA PROCESSING (IDAP 2019), DOI 10.1109/idap.2019.8875927
   Shadravan S, 2019, ENG APPL ARTIF INTEL, V80, P20, DOI 10.1016/j.engappai.2019.01.001
   Shang CX, 2013, KNOWL-BASED SYST, V54, P298, DOI 10.1016/j.knosys.2013.09.019
   Thirumoorthy K, 2021, PATTERN RECOGN LETT, V147, P63, DOI 10.1016/j.patrec.2021.03.034
   Thirumoorthy K, 2022, NATL ACAD SCI LETT, V45, P51, DOI 10.1007/s40009-021-01043-0
   Thirumoorthy K, 2020, SADHANA-ACAD P ENG S, V45, DOI 10.1007/s12046-020-01443-w
   Uysal AK, 2012, KNOWL-BASED SYST, V36, P226, DOI 10.1016/j.knosys.2012.06.005
   Wang L, 2021, DISCRETE DYN NAT SOC, V2021, DOI 10.1155/2021/7796696
   Wei L., 2012, Journal of Software Engineering and Applications, V5, P55, DOI [DOI 10.4236/JSEA.2012.512B012, 10.4236/jsea.2012.512B012]
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Yazdani M, 2016, J COMPUT DES ENG, V3, P24, DOI 10.1016/j.jcde.2015.06.003
   Yigit F, 2014, INT CONF CLOUD COMPU, P523, DOI 10.1109/CCIS.2014.7175792
   Zhou HF, 2018, IEEE ACCESS, V6, P51655, DOI 10.1109/ACCESS.2018.2868844
   ZHU L., 2017, proceedings of the 6th International Conference on Software and Computer Applications, P72
   Zhu WY, 2014, 2014 INTERNATIONAL CONFERENCE ON DATA SCIENCE AND ADVANCED ANALYTICS (DSAA), P76, DOI 10.1109/DSAA.2014.7058055
NR 50
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10273
EP 10295
DI 10.1007/s11042-023-15828-6
EA JUN 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019116600002
DA 2024-07-18
ER

PT J
AU Bajaj, A
   Vishwakarma, DK
AF Bajaj, Ashish
   Vishwakarma, Dinesh Kumar
TI A state-of-the-art review on adversarial machine learning in image
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Attacks; Adversarial machine learning (AML); Deep neural networks
   (DNNs); Convolutional neural networks (CNN); Defences; Data poisoning;
   Backdoor attacks; Robustness; Evasion; Brittle
ID SECURITY; ATTACKS
AB Computer vision applications like traffic monitoring, security checks, self-driving cars, medical imaging, etc., rely heavily on machine learning models. It raises an essential growing concern regarding the dependability of machine learning algorithms, which cannot be entirely trusted due to their fragile nature. This leads us to a dire need for systematic analysis of adversarial settings in neural networks. Hence, this article presents a comprehensive study of vulnerabilities, possible attacks such as data poisoning and data access during training, evasion, and oracle attacks at the test time, and their defensive and preventive measures using novel taxonomies. The survey has covered the complete scenario where an adversary can make malicious manipulations and elaborated more on the most potent threat, i.e., test time evasion attack using an adversarial image (maliciously perturbed image). It expounds an intuition behind generating an adversarial image, covering all relevant adversarial attack algorithms and strategies for increasing robustness against adversarial images. The existence and effect of adversarial images, as well as their transferability, are also examined. The article guides the reader with an approach on building new models to enhance their reliability. Additionally, the survey presents the procedures that still demand further exploration with limitations in existing methods, enhancing future research directions.
C1 [Bajaj, Ashish; Vishwakarma, Dinesh Kumar] Delhi Technol Univ, Dept Informat Technol, Biometr Res Lab, Bawana Rd, Delhi 110042, India.
C3 Delhi Technological University
RP Vishwakarma, DK (corresponding author), Delhi Technol Univ, Dept Informat Technol, Biometr Res Lab, Bawana Rd, Delhi 110042, India.
EM bajaj.ashish25@gmail.com; dvishwakarma@gmail.com
RI VISHWAKARMA, DINESH KUMAR/L-3815-2018
OI VISHWAKARMA, DINESH KUMAR/0000-0002-1026-0047
CR Abbasi M, 2019, 5 INT C COMPUTING CO, P1
   Ahmad S, 2022, CLUSTER COMPUT, V25, P3733, DOI 10.1007/s10586-022-03598-z
   Ahmadi MA, 2021, MULTIMED TOOLS APPL, V80, P10985, DOI 10.1007/s11042-020-10261-5
   Akhtar N, 2021, IEEE ACCESS, V9, P155161, DOI 10.1109/ACCESS.2021.3127960
   Akhtar N, 2018, PROC CVPR IEEE, P3389, DOI 10.1109/CVPR.2018.00357
   Alcorn MA, 2019, PROC CVPR IEEE, P4840, DOI 10.1109/CVPR.2019.00498
   Alsmadi I, 2022, IEEE ACCESS, V10, P17043, DOI 10.1109/ACCESS.2022.3146405
   Alsuwat E, 2020, INT J GEN SYST, V49, P3, DOI 10.1080/03081079.2019.1630401
   Alzantot M, 2019, PROCEEDINGS OF THE 2019 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO'19), P1111, DOI 10.1145/3321707.3321749
   Andriushchenko Maksym, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P484, DOI 10.1007/978-3-030-58592-1_29
   Athalye A., 2018, INT C MACH LEARN, P1
   Athalye A, 2018, PR MACH LEARN RES, V80
   Bakhti Y, 2019, IEEE ACCESS, V7, P160397, DOI 10.1109/ACCESS.2019.2951526
   Baluja S, P AAAI 2018 AAAI, P2687
   Bao ZD, 2022, IEEE INTERNET THINGS, V9, P9012, DOI 10.1109/JIOT.2021.3120197
   Barbu A, 2019, ADV NEUR IN, V32
   Barreno M, 2010, MACH LEARN, V81, P121, DOI 10.1007/s10994-010-5188-5
   Bhagoji AN, 2018, 2018 52ND ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS (CISS)
   Bickel S, 2009, J MACH LEARN RES, V10, P2137
   Biggio B, 2011, LECT NOTES COMPUT SC, V6713, P350, DOI 10.1007/978-3-642-21557-5_37
   Biggio B, 2010, INT J MACH LEARN CYB, V1, P27, DOI 10.1007/s13042-010-0007-7
   Brendel W, 2017, ARXIV171204248
   Brendel Wieland, 2019, INT C LEARN REPR
   Buckman J., 2018, INT C LEARN REPR
   Cao XY, 2017, ANN COMPUT SECURITY, P278, DOI 10.1145/3134600.3134606
   Carlini N, MAGNET EFFICIENT DEF
   Carlini N, 2019, EVALUATING ADVERSARI, P1
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Carlini N, 2018, 2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018), P1, DOI 10.1109/SPW.2018.00009
   Carrara F, 2019, MULTIMED TOOLS APPL, V78, P2815, DOI 10.1007/s11042-018-5853-4
   Changjiang Li, 2019, Cyberspace Safety and Security. 11th International Symposium, CSS 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11982), P307, DOI 10.1007/978-3-030-37337-5_25
   Chen J, 2017, ARXIV
   Chen JB, 2020, P IEEE S SECUR PRIV, P1277, DOI 10.1109/SP40000.2020.00045
   Chen JY, 2019, COMPUT SECUR, V85, P89, DOI 10.1016/j.cose.2019.04.014
   Chen JY, 2021, MACH LEARN, V110, P651, DOI 10.1007/s10994-021-05951-6
   Chen PY, 2018, AAAI CONF ARTIF INTE, P10
   Chen PY, 2017, P 10 ACM WORKSH ART, P15, DOI [10.1145/3128572.3140448, DOI 10.1145/3128572.3140448]
   Cisse M, 2017, ADV NEUR IN, V30
   Cisse M, 2017, PR MACH LEARN RES, V70
   Cohen Gilad, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14441, DOI 10.1109/CVPR42600.2020.01446
   Croce F, 2019, 25TH AMERICAS CONFERENCE ON INFORMATION SYSTEMS (AMCIS 2019)
   Das N, 2017, ARXIV
   Dhillon GS, 2018, ARXIV PREPRINT ARXIV
   Dong YP, 2018, PROC CVPR IEEE, P9185, DOI 10.1109/CVPR.2018.00957
   Du C, 2017, ARXIV
   Dubey A, 2019, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2019.00897
   Eykholt K, 2018, PROC CVPR IEEE, P1625, DOI 10.1109/CVPR.2018.00175
   Fan WQ, 2019, MULTIMED TOOLS APPL, V78, P20409, DOI 10.1007/s11042-019-7353-6
   Feinman R., 2017, arXiv
   Folz J, 2020, IEEE WINT CONF APPL, P3568, DOI [10.1109/wacv45572.2020.9093310, 10.1109/WACV45572.2020.9093310]
   Fredrikson M, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1322, DOI 10.1145/2810103.2813677
   Galloway A, 2018, 6 INT C LEARNING REP
   Gao J, 2019, ARXIV, P1
   Gao R, 2021, ICML, P1
   Geirhos Robert, 2020, Nature Machine Intelligence, V2, P665, DOI 10.1038/s42256-020-00257-z
   Geirhos Robert, 2019, IMAGENET TRAINED CNN
   Gong Zhitao, 2017, ARXIV
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Goodman D, 2020, ARXIV
   Grosse K., 2017, ARXIV
   Gu Shixiang, 2015, 3 INT C LEARNING REP
   Gu Tianyu, 2017, arXiv
   Guo C., 2018, 6 INT C LEARN REPR I
   Ha T., 2020, SN Comput. Sci, V1, P1, DOI [DOI 10.1007/S42979-020-00254-4, 10.1007/s42979-020-00254-4]
   Hayes J, 2018, 2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018), P43, DOI 10.1109/SPW.2018.00015
   He W., 2018, ICLR
   He W, 2017, P 11 USENIX C OFF TE, P15
   Hendrycks D, 2021, PROC CVPR IEEE, P15257, DOI 10.1109/CVPR46437.2021.01501
   Hendrycks Dan, 2017, INT C LEARNING REPRE
   Hendrycks Dan, 2019, ARXIV190312261
   Hinton G., 2015, COMPUT SCI, V2
   Ho JC, 2022, APPL INTELL, V52, P4364, DOI 10.1007/s10489-021-02523-y
   Huang Y, 2020, P 2 MATH SCI MACHINE, V145, P1
   Ilyas A, 2019, ADV NEUR IN, V32
   Ilyas Andrew, 2018, P INT C MACH LEARN, V80
   Jacobsen J, 2019, INT C LEARN REPR, P1
   Jagielski M, 2018, P IEEE S SECUR PRIV, P19, DOI 10.1109/SP.2018.00057
   Jiang HL, 2022, FUTURE GENER COMP SY, V132, P194, DOI 10.1016/j.future.2022.02.019
   Jin GQ, 2019, INT CONF ACOUST SPEE, P3842, DOI [10.1109/ICASSP.2019.8683044, 10.1109/icassp.2019.8683044]
   Kabilan VM, 2021, ARXIV
   Kaidi Xu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P665, DOI 10.1007/978-3-030-58558-7_39
   Kannan H., 2018, ARXIV
   Kantaros Y, 2021, ACM IEEE INT CONF CY, P67, DOI 10.1145/3450267.3450535
   Kantipudi Jayendra, 2020, IEEE Transactions on Artificial Intelligence, V1, P181, DOI 10.1109/TAI.2020.3046167
   Karmon D., 2018, ICML, V80, P2512
   Katabi D, 2019, 36 INT C MACHINE LEA
   Kim J, 2021, INT C CONTR AUT SYST, V2021, DOI [10.23919/ICCAS52745.2021.9650004, DOI 10.23919/ICCAS52745.2021.9650004]
   Koh PW, 2022, MACH LEARN, V111, P1, DOI 10.1007/s10994-021-06119-y
   Ku HC, 2022, COMPUT STAND INTER, V80, DOI 10.1016/j.csi.2021.103583
   Kurakin A., 2016, WORKSHOP TRACK P
   Kurakin Alexey, 2017, INT C LEARN REPR
   Laidlaw C., 2019, ADV NEURAL INFORM PR, P1
   Lamb Alex, 2018, ICLR 2019
   Lee JW, 2022, IEEE ACCESS, V10, P30039, DOI 10.1109/ACCESS.2022.3159694
   Li D, 2017, IEEE I CONF COMP VIS, P5543, DOI 10.1109/ICCV.2017.591
   Li X, 2017, IEEE I CONF COMP VIS, P5775, DOI 10.1109/ICCV.2017.615
   Liang B, 2021, IEEE T DEPEND SECURE, V18, P72, DOI 10.1109/TDSC.2018.2874243
   Liao FZ, 2018, PROC CVPR IEEE, P1778, DOI 10.1109/CVPR.2018.00191
   Lin JW, 2019, INTERACT LEARN ENVIR, DOI 10.1080/10494820.2019.1593198
   Ling X, 2019, P IEEE S SECUR PRIV, P673, DOI 10.1109/SP.2019.00023
   Nguyen L, 2018, LECT NOTES COMPUT SC, V11199, P453, DOI 10.1007/978-3-030-01554-1_26
   Liu NH, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1803, DOI 10.1145/3219819.3220027
   Liu Q, 2017, COMPUT ELECTR ENG, V59, P153, DOI 10.1016/j.compeleceng.2016.10.005
   Liu X, 2017, LECT NOTES COMPUTER, P381
   Liu X, 2019, DYNAMIC ACCESS POLIC
   Liu X, 2019, ICLR 2019, P1
   Liu XM, 2021, IEEE ACCESS, V9, P4566, DOI 10.1109/ACCESS.2020.3045078
   Liu Y, 2017, 5 INT C LEARNING REP
   Liu Z, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2247
   Lu JJ, 2017, IEEE I CONF COMP VIS, P446, DOI 10.1109/ICCV.2017.56
   Lyu CC, 2015, IEEE DATA MINING, P301, DOI 10.1109/ICDM.2015.84
   Ma JQ, 2022, WSDM'22: PROCEEDINGS OF THE FIFTEENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P675, DOI 10.1145/3488560.3498497
   Ma SQ, 2019, 26TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2019), DOI 10.14722/ndss.2019.23415
   Ma X., 2018, 6 INT C LEARNING REP
   Machado GR, 2019, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON ENTERPRISE INFORMATION SYSTEMS (ICEIS), VOL 1, P307, DOI 10.5220/0007714203070318
   Machado GR, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3485133
   Mattsson UT, 2005, ICEIS 2005 P 7 INT C, DOI [10.5220/0002518001460153, DOI 10.5220/0002518001460153]
   Meng DY, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P135, DOI 10.1145/3133956.3134057
   Meng MH, 2022, IEEE T DEPEND SECURE, P1, DOI DOI 10.1109/TDSC.2022.3179131
   Metzen J.H., 2017, 5 INT C LEARN REPR I
   Metzen JH, 2017, IEEE I CONF COMP VIS, P2774, DOI 10.1109/ICCV.2017.300
   Michel A, 2022, PROG ARTIF INTELL, V11, P131, DOI 10.1007/s13748-021-00269-9
   Miller DJ, 2020, P IEEE, V108, P402, DOI 10.1109/JPROC.2020.2970615
   Moosavi-Dezfooli S.-M., 2018, ARXIV
   Moosavi-Dezfooli SM, 2017, PROC CVPR IEEE, P86, DOI 10.1109/CVPR.2017.17
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Moosavi-Dezfooli SM, 2017, ARXIV, DOI [10.48550/arXiv.2012.14352, DOI 10.48550/ARXIV.2012.14352]
   Mustafa A, 2020, IEEE T IMAGE PROCESS, V29, P1711, DOI 10.1109/TIP.2019.2940533
   Na T., 2017, IEEE T KNOWL DATA EN, P1
   Narodytska N, 2017, IEEE COMPUT SOC CONF, P1310, DOI 10.1109/CVPRW.2017.172
   Naseer M, 2020, PROC CVPR IEEE, P259, DOI 10.1109/CVPR42600.2020.00034
   Nelson B, 2009, Machine Learning in Cyber Trust: Security, Privacy, and Reliability, P17, DOI DOI 10.1007/978-0-387-88735-72
   Nicolae M.-I., 2018, ARXIV
   Nyo MT, 2022, MULTIMED TOOLS APPL, V81, P43837, DOI 10.1007/s11042-022-13215-1
   PAPERNOT N., 2017, ARXIV
   Papernot N., 2016, CORR
   Papernot N, 2018, ARXIV
   Papernot N, 2018, AISEC'18: PROCEEDINGS OF THE 11TH ACM WORKSHOP ON ARTIFICIAL INTELLIGENCE AND SECURITY, P1, DOI 10.1145/3270101.3270102
   Papernot N, 2017, PROCEEDINGS OF THE 2017 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIA CCS'17), P506, DOI 10.1145/3052973.3053009
   Papernot N, 2016, P IEEE S SECUR PRIV, P582, DOI 10.1109/SP.2016.41
   Papernot N, 2016, 1ST IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY, P372, DOI 10.1109/EuroSP.2016.36
   Prakash A, 2018, PROC CVPR IEEE, P8571, DOI 10.1109/CVPR.2018.00894
   Ranjan R, 2017, ARXIV
   Rauber J, 2017, ARXIV
   Ren HL, 2021, INT J MACH LEARN CYB, V12, P3325, DOI 10.1007/s13042-020-01242-z
   Rivest Ronald L., 1978, Found. Secure Comput., V4, P169
   Ros AS, 2018, AAAI CONF ARTIF INTE, P1660
   Rozsa A, 2016, IEEE COMPUT SOC CONF, P410, DOI 10.1109/CVPRW.2016.58
   Ruan YB, 2018, FUTURE INTERNET, V10, DOI 10.3390/fi10030026
   Rubinstein BIP, 2009, IMC'09: PROCEEDINGS OF THE 2009 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P1
   Rui Zhao, 2021, 2021 2nd International Conference on Computing and Data Science (CDS), P287, DOI 10.1109/CDS52072.2021.00057
   Ryu G, 2021, J INF SECUR APPL, V60, DOI 10.1016/j.jisa.2021.102874
   Samangouei P., 2018, 6 INT C LEARN REPR I
   Sankaranarayanan S, 2018, AAAI CONF ARTIF INTE, P4008
   Sarkar S., 2017, ARXIV
   Scholkopf B, 2012, P 29 INT C MACHINE L, V2
   Sengupta S, 2019, LECT NOTES COMPUT SC, V11836, P479, DOI 10.1007/978-3-030-32430-8_28
   Shaham U, 2018, NEUROCOMPUTING, V307, P195, DOI 10.1016/j.neucom.2018.04.027
   Shailaja GK, 2022, EVOL INTELL, V15, P1123, DOI 10.1007/s12065-019-00309-3
   Shane J., 2018, Do neural nets dream of electric sheep?
   Sharif M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1528, DOI 10.1145/2976749.2978392
   Sharma A, 2022, ARXIV
   Shokri R, 2017, P IEEE S SECUR PRIV, P3, DOI 10.1109/SP.2017.41
   Singh A, 2022, IEEE INTERNET THINGS, V9, P2602, DOI 10.1109/JIOT.2021.3138541
   Sinha A, 2018, IEEE C EVOL COMPUTAT, P213, DOI 10.1109/CEC.2018.8477763
   Song Y, 2019, P COMBUST INST, V37, P667, DOI 10.1016/j.proci.2018.06.115
   Srinivasan V, 2018, ARXIV
   Steinhardt J, 2017, ADV NEUR IN, P1
   Strateva T, 2018, INFECT DIS-NOR, V50, P718, DOI 10.1080/23744235.2018.1453946
   Su JW, 2019, IEEE T EVOLUT COMPUT, V23, P828, DOI 10.1109/TEVC.2019.2890858
   Sykes ER, 2022, VISUAL COMPUT, V38, P729, DOI 10.1007/s00371-020-02047-5
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tanay, 2016, ARXIV PREPRINT ARXIV
   Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347
   Tramer F, 2020, ADV NEURAL INFORM PR, V2020
   Tramèr F, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P601
   Tramer Florian, 2017, Ensemble adversarial training: Attacks and defenses
   Tramonti F, 2019, PSYCHOL HEALTH MED, V24, P27, DOI 10.1080/13548506.2018.1510131
   Tsipras D., 2019, ROBUSTNESS MAY BE OD
   Tu CC, 2019, AAAI CONF ARTIF INTE, P742
   Turner A, 2019, INT C LEARN REPR
   Uesato J, 2018, PR MACH LEARN RES, V80
   Vivek BS, 2020, PROC CVPR IEEE, P947, DOI 10.1109/CVPR42600.2020.00103
   Vladu Adrian, 2018, PROC 6 INT C LEARN R
   Wang J, 2022, MULTIMED TOOLS APPL, DOI 10.1007/s11042-022-14067-5
   Wang WQ, 2022, INT J INTELL SYST, V37, P3440, DOI 10.1002/int.22696
   Wang XM, 2019, J PARALLEL DISTR COM, V130, P12, DOI 10.1016/j.jpdc.2019.03.003
   Wang YJ, 2021, INFORM SCIENCES, V556, P459, DOI 10.1016/j.ins.2020.08.087
   Wang YT, 2020, PHARM DEV TECHNOL, V25, P865, DOI 10.1080/10837450.2020.1753770
   Wenger E, 2021, PROC CVPR IEEE, P6202, DOI 10.1109/CVPR46437.2021.00614
   Wiyatno RR, 2019, ARXIV
   Wu JQ, 2020, IEEE T INF FOREN SEC, V15, P2282, DOI 10.1109/TIFS.2019.2963764
   Xiao CW, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3905
   Xiao Chaowei, 2018, 6 INT C LEARN REPR I
   Xiao H, 2015, NEUROCOMPUTING, P97
   XIE C, 2018, 6 INT C LEARN REPR I, P1
   Xu RH, 2019, INT CON DISTR COMP S, P1199, DOI 10.1109/ICDCS.2019.00121
   Xu WL, 2018, 25TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2018), DOI 10.14722/ndss.2018.23198
   Yan H., 2019, arXiv
   Yan Z, 2018, ADV NEURAL INFORM PR, V31, P1
   Yang ZQ, 2019, PROCEEDINGS OF THE 2019 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'19), P225, DOI 10.1145/3319535.3354261
   Yu XY, 2019, IEEE T NEUR NET LEAR, V30, P2805, DOI 10.1109/TNNLS.2018.2886017
   Zantedeschi V, 2017, P 10 ACM WORKSH ART, P39
   Zelun Kong, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14242, DOI 10.1109/CVPR42600.2020.01426
   Zhang CY, 2022, IEEE ACM T NETWORK, V30, P1294, DOI 10.1109/TNET.2021.3137084
   Zheng Z., 2018, 32 C NEURAL INFORM P
   Zhou YY, 2019, IEEE INT CONF MOB, P25, DOI 10.1109/MASSW.2019.00012
   Zhu CD, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/3719971
   Ziller A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-93030-0
NR 209
TC 3
Z9 3
U1 13
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 9351
EP 9416
DI 10.1007/s11042-023-15883-z
EA JUN 2023
PG 66
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001012579700008
DA 2024-07-18
ER

PT J
AU Uzun, S
   Kaçar, S
   Aricioglu, B
AF Uzun, Sueleyman
   Kacar, Sezgin
   Aricioglu, Burak
TI Deep learning based classification of time series of chaotic systems
   over graphic images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic systems; Time series; Classification; Deep learning
ID DYNAMICS; MODEL
AB In this study, for the first time in the literature, identification of different chaotic systems by classifying graphic images of their time series with deep learning methods is aimed. For this purpose, a data set is generated that consists of the graphic images of time series of the most known three chaotic systems: Lorenz, Chen, and Rossler systems. The time series are obtained for different parameter values, initial conditions, step size and time lengths. After generating the data set, a high-accuracy classification is performed by using transfer learning method. In the study, the most accepted deep learning models of the transfer learning methods are employed. These models are SqueezeNet, VGG-19, AlexNet, ResNet50, ResNet101, DenseNet201, ShuffleNet and GoogLeNet. As a result of the study, classification accuracy is found between 96% and 97% depending on the problem. Thus, this study makes association of real time random signals with a mathematical system possible.
C1 [Uzun, Sueleyman] Sakarya Univ Appl Sci, Fac Technol, Dept Comp Engn, TR-54050 Sakarya, Turkiye.
   [Kacar, Sezgin; Aricioglu, Burak] Sakarya Univ Appl Sci, Fac Technol, Dept Elect & Elect Engn, TR-54050 Sakarya, Turkiye.
C3 Sakarya University of Applied Science; Sakarya University of Applied
   Science
RP Uzun, S (corresponding author), Sakarya Univ Appl Sci, Fac Technol, Dept Comp Engn, TR-54050 Sakarya, Turkiye.
EM suleymanuzun@subu.edu.tr
RI UZUN, Süleyman/IZQ-1556-2023
OI UZUN, Süleyman/0000-0001-8246-6733
CR Agarwal Aman, 2021, 2021 6th International Conference on Communication and Electronics Systems (ICCES), P1390, DOI 10.1109/ICCES51350.2021.9489033
   Aksoy B, 2020, International Journal of Engineering and Innovative Research, V2, P194, DOI DOI 10.47933/IJEIR.772514
   Altan G, 2019, AVRUPA BILIM TEKNOLO, P319, DOI [10.31590/ejosat.638256, DOI 10.31590/EJOSAT.638256]
   [Anonymous], 2016, NEUROCOMPUTING, DOI [DOI 10.1016/J.NEUC0M.2015.09.116, DOI 10.1016/J.NEUCOM.2015.09.116, 10. 1016/j.neucom.2015.09.116]
   Arena P, 2019, NONLINEAR DYNAM, V95, P1999, DOI 10.1007/s11071-018-4673-4
   Balagourouchetty L, 2020, IEEE J BIOMED HEALTH, V24, P1686, DOI 10.1109/JBHI.2019.2942774
   Ballester P, 2016, AAAI CONF ARTIF INTE, P1124
   Barros P, 2017, NEUROCOMPUTING, V253, P104, DOI 10.1016/j.neucom.2017.01.096
   Boullé N, 2020, PHYSICA D, V403, DOI 10.1016/j.physd.2019.132261
   Chen GR, 1999, INT J BIFURCAT CHAOS, V9, P1465, DOI 10.1142/S0218127499001024
   CUOMO KM, 1993, PHYS REV LETT, V71, P65, DOI 10.1103/PhysRevLett.71.65
   Dang WD, 2020, NONLINEAR DYNAM, V102, P667, DOI 10.1007/s11071-020-05665-9
   Deng L., 2018, DEEP LEARNING NATURA, DOI [DOI 10.1007/978-981-10-5209-5, 10.1007/978-981-10-5209-5]
   Dhungel N, 2017, ADV COMPUT VIS PATT, P225, DOI 10.1007/978-3-319-42999-1_13
   Duque AB, 2019, LECT NOTES COMPUT SC, V11727, P193, DOI 10.1007/978-3-030-30487-4_16
   Gaikwad A. S., 2018, P IEEE INT S SIGN PR, P1
   GORMAN M, 1986, PHYSICA D, V19, P255, DOI 10.1016/0167-2789(86)90022-9
   HAKEN H, 1975, PHYS LETT A, VA 53, P77, DOI 10.1016/0375-9601(75)90353-9
   Han XB, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9080848
   Haskins G, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01060-x
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   HEMATI N, 1994, IEEE T CIRCUITS-I, V41, P40, DOI 10.1109/81.260218
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Karadag B, 2021, J POLYTECH, V24, P1611, DOI 10.2339/politeknik.885838
   Kaya U., 2019, Eur J Sci Technol, P792, DOI DOI 10.31590/EJOSAT.573248
   Keles A., 2018, J TURKISH STUD, V13, P113, DOI DOI 10.7827/TURKISHSTUDIES.14189
   Kk D, 2018, INT J MANAG INF SYST, V2, P76
   KNOBLOCH E, 1981, PHYS LETT A, V82, P439, DOI 10.1016/0375-9601(81)90274-7
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuremoto T, 2014, 2014 7TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP 2014), P1130, DOI 10.1109/CISP.2014.7003950
   Le Cun Y., 1990, Neurocomputing, Algorithms, Architectures and Applications. Proceedings of the NATO Advanced Research Workshop, P303
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LETELLIER C, 1995, CHAOS, V5, P271, DOI 10.1063/1.166076
   Li Y, 2020, PROCEEDINGS OF 2020 IEEE 4TH INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2020), P769, DOI [10.1109/itnec48623.2020.9085091, 10.1109/ITNEC48623.2020.9085091]
   Liang XY, 2017, CHAOS SOLITON FRACT, V98, P173, DOI 10.1016/j.chaos.2017.03.021
   LORENZ EN, 1963, J ATMOS SCI, V20, P130, DOI 10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2
   Lu SY, 2019, J COMPUT SCI-NETH, V30, P41, DOI 10.1016/j.jocs.2018.11.008
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P7885, DOI 10.1109/TPAMI.2021.3115815
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Pchelintsev AN, 2014, NUMER ANAL APPL, V7, P159, DOI 10.1134/S1995423914020098
   Qian YM, 2016, IEEE-ACM T AUDIO SPE, V24, P2263, DOI 10.1109/TASLP.2016.2602884
   Rakhlin A, 2018, LECT NOTES COMPUT SC, V10882, P737, DOI 10.1007/978-3-319-93000-8_83
   Ravì D, 2017, IEEE J BIOMED HEALTH, V21, P4, DOI 10.1109/JBHI.2016.2636665
   ROSSLER OE, 1976, PHYS LETT A, V57, P397, DOI 10.1016/0375-9601(76)90101-8
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sangiorgio M, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110045
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Talo M, 2018, FIRAT U MUHENDISLIK, V31, P391, DOI DOI 10.35234/FUMBD.517939
   Togacar M, 2020, FIRAT UNIVERSITESI M, P37, DOI [10.35234/fumbd.573630, DOI 10.35234/FUMBD.573630]
   Toraman S, 2018, J AVIAT, V2, P64, DOI DOI 10.30518/JAV.450913
   WANG L, 1994, 1994 IEEE GLOBECOM - CONFERENCE RECORD, VOLS 1-3, AND COMMUNICATIONS THEORY MINI-CONFERENCE RECORD, P186, DOI 10.1109/GLOCOM.1994.513404
   Wen L, 2019, INT C COMP SUPP COOP, P205, DOI [10.1109/cscwd.2019.8791884, 10.1109/CSCWD.2019.8791884]
   Xu ZB, 2018, NATL SCI REV, V5, P22, DOI 10.1093/nsr/nwx099
   Yeo K, 2017, ARXIV, DOI DOI 10.48550/ARXIV.1710.01693
   Yilmaz F, 2019, 2019 MEDICAL TECHNOLOGIES CONGRESS (TIPTEKNO), P521, DOI 10.1109/tiptekno47231.2019.8972042
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zhang K, 2019, IEEE ACCESS, V7, P9872, DOI 10.1109/ACCESS.2018.2890127
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang Y, 2016, INTERSPEECH, P410, DOI 10.21437/Interspeech.2016-1446
   Zhang ZR, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS AND COMPUTER ENGINEERING (ICCECE), P565, DOI [10.1109/ICCECE51280.2021.9342418, 10.1109/CCECI51280.2021.9342418]
   Zhi WT, 2020, 2020 3RD WORLD CONFERENCE ON MECHANICAL ENGINEERING AND INTELLIGENT MANUFACTURING (WCMEIM 2020), P122, DOI 10.1109/WCMEIM52463.2020.00032
   Zhu Z., 2017, P INT C DIG IM COMP, P1, DOI [10.1109/DICTA.2017.8227431, DOI 10.1109/DICTA.2017.8227431]
NR 64
TC 2
Z9 2
U1 5
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8413
EP 8437
DI 10.1007/s11042-023-15944-3
EA JUN 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001012324600001
DA 2024-07-18
ER

PT J
AU Saini, P
   Kumar, K
AF Saini, Parul
   Kumar, Krishan
TI S-method: secure multimedia encryption technique in cloud environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud security; Multimedia; Quadratic residue; Quadratic non-residue;
   Virtual machines
AB Security of multimedia content on the Cloud has emerged as the major research area in today's era of the internet. Most exchange of multimedia content across the globe is done over the Cloud. Such communication is done openly in a cloud environment where anyone can quickly access the data. Therefore, it should provide reliable security mechanisms and standards for the shared multimedia data for users. This study highlights better protection of multimedia data over the Cloud than the existing approaches, where the information cannot be unwrapped reasonably. The encryption process is speedup using the multiple VMs over the Cloud for parallel processing of the chunks of the data. The proposed algorithm is well-designed and suited for efficient computation with limited resources,as most wireless devices come with limited bandwidth and computational power. The qualitative and quantitative evaluation is performed to compare the performance of the proposed S-Method model with the state-of-the-art models. A computing time shows that the proposed approach can meet the requirement of real-time applications.
C1 [Saini, Parul; Kumar, Krishan] Natl Inst Technol Uttarakhand, Dept Comp Sci & Engn, Garhwal 246174, Uttarakhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Uttarakhand
RP Saini, P (corresponding author), Natl Inst Technol Uttarakhand, Dept Comp Sci & Engn, Garhwal 246174, Uttarakhand, India.
EM parulsaini.phd2020@nituk.ac.in; k2b@ieee.org
RI Berwal, Krishan/AAC-3473-2020
OI Berwal, Krishan/0000-0002-7068-6541; Saini, Parul/0000-0002-6552-1216
FU DST GoI [DST/ICPS/General/2018]
FX AcknowledgementsThe authors thank the DST GoI for sponsoring the work
   under DST/ICPS/General/2018
CR Abood OG, 2017, PROC INT MID EAST P, P644, DOI 10.1109/MEPCON.2017.8301249
   Amroune A, 2019, THESIS U MOHAMED BOU
   [Anonymous], 2003, LNCS, P255, DOI DOI 10.1007/3-540-39200-916
   Azad S, 2017, COMPUT ELECTR ENG, V59, P99, DOI 10.1016/j.compeleceng.2016.12.007
   de Carvalho CAB, 2017, COMPUT ELECTR ENG, V59, P141, DOI 10.1016/j.compeleceng.2016.12.030
   Belazi A, 2019, IEEE ACCESS, V7, P36667, DOI 10.1109/ACCESS.2019.2906292
   Bhagat V, 2023, CONCURR COMP-PRACT E, V35, DOI 10.1002/cpe.7425
   Chandrasekaran K., 2014, ESSENTIALS CLOUD COM, DOI [10.1201/b17805, DOI 10.1201/B17805]
   Coppolino L, 2017, COMPUT ELECTR ENG, V59, P126, DOI 10.1016/j.compeleceng.2016.03.004
   Cormen Thomas H., 2001, INTRO ALGORITHMS
   Cox I., 2002, J. Electron. Imag., V11, P414, DOI 10.1117/1.1494075
   Dey J, 2021, INTERNET VEHICLES IT, P149, DOI DOI 10.1007/978-3-030-46335-9_10
   Docs.openstack.org, 2017, OPENSTACK DOCS OP IN
   Dumachev VN, 2020, ARXIV
   Elkandoz MT, 2022, MULTIMED TOOLS APPL, V81, P25497, DOI 10.1007/s11042-022-12595-8
   Forouzan B.A., 2011, Cryptography and Network Security (Sie)
   Ghosh Santosh., 2007, TENCON 2007-2007 IEEE Region 10 Conference, P1
   Griotti M, 2017, MOBILE COMPUTING UBI, P1
   Gupta BB, 2018, MULTIMED TOOLS APPL, V77, P9203, DOI 10.1007/s11042-017-5301-x
   Hosny KM, 2017, COMPUT ELECTR ENG, V62, P429, DOI 10.1016/j.compeleceng.2017.05.015
   Jaeger PT, 2008, J INF TECHNOL POLITI, V5, P269, DOI 10.1080/19331680802425479
   Johnson N.F., 2001, Information Hiding: Steganography and Watermarking-Attacks and Countermeasures: Steganography and Watermarking: Attacks and Countermeasures, V1
   Kakkad V, 2019, MULTISCALE MULTI MOD, V2, P233, DOI 10.1007/s41939-019-00049-y
   Kalpana G, 2017, COMPUT ELECTR ENG
   Kasyap H, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3426474
   Kaur M, 2020, ARCH COMPUT METHOD E, V27, P15, DOI 10.1007/s11831-018-9298-8
   Kaur S, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P870, DOI 10.1109/IndiaCom.2014.6828087
   Kelahmetoglu O, 2015, J CRANIOFAC SURG, V26, P1437, DOI 10.1097/SCS.0000000000001627
   Krishnaswamy S, 1999, U.S. Patent, Patent No. [5,867,494, 5867494]
   Kumar K, 2016, IEEE CONF CLOUD COMP, P95, DOI [10.1109/CCEM.2016.025, 10.1109/CCEM.2016.24]
   Kumar KP, 2017, ADV BUS STRATEGY COM, P1, DOI 10.4018/978-1-5225-1008-6.ch001
   Kumar S, 2015, HDB RES SECURING CLO, P1
   Kumar S, 2022, INT J SENS NETW, V39, P227, DOI 10.1504/IJSNET.2022.125113
   Kumar S, 2018, MULTIMED TOOLS APPL, V77, P11017, DOI 10.1007/s11042-017-4966-5
   Kumar Shubham, 2018, LSRC LEXICON STAR RA
   Li HJ, 2021, MULTIMED TOOLS APPL, V80, P8721, DOI 10.1007/s11042-020-10117-y
   Liu Q, 2017, COMPUT ELECTR ENG, V59, P153, DOI 10.1016/j.compeleceng.2016.10.005
   Liu ZC, 2018, J NETW COMPUT APPL, V108, P112, DOI 10.1016/j.jnca.2018.01.016
   Manupriya P, 2017, 2017 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT), DOI 10.1109/INFOCOMTECH.2017.8340639
   Namasudra S, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3392665
   Noshy, 2018, J NETWORK COMPUT APP
   Saini Parul, 2022, 2022 IEEE 9th Uttar Pradesh Section International Conference on Electrical, Electronics and Computer Engineering (UPCON), P1, DOI 10.1109/UPCON56432.2022.9986417
   Shankar K, 2020, J AMB INTEL HUM COMP, V11, P1821, DOI 10.1007/s12652-018-1161-0
   Shikhar S, 2017, COMPUTER VISION IMAG, P1
   Shparlinski IE, 2012, ARCH MATH, V99, P345, DOI 10.1007/s00013-012-0436-5
   Smith J. E., 2005, VIRTUAL MACHINES VER
   Stinson DR., 2005, CRYPTOGRAPHY THEORY, DOI [10.1201/9781420057133, DOI 10.1201/9781420057133]
   Wang B, 2017, COMPUT ELECTR ENG, V62, P414, DOI 10.1016/j.compeleceng.2017.01.015
   Wang D, 2015, INFORM SCIENCES, V321, P162, DOI 10.1016/j.ins.2015.03.070
   William Stallings., 2006, Cryptography and Network Security
   Xie Q, 2017, COMPUT ELECTR ENG, V59, P218, DOI 10.1016/j.compeleceng.2016.11.038
   Yin XC, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT CONTROL, AUTOMATIC DETECTION AND HIGH-END EQUIPMENT (ICADE), P160, DOI 10.1109/ICADE.2012.6330119
   Zhang HL, 2020, IEEE INTERNET THINGS, V7, P2968, DOI 10.1109/JIOT.2020.2964015
NR 53
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8295
EP 8309
DI 10.1007/s11042-023-15600-w
EA JUN 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001012326000006
DA 2024-07-18
ER

PT J
AU Wang, YQ
   Qin, GH
   Zou, M
   Liang, YH
   Wang, GF
   Wang, KP
   Feng, Y
   Zhang, ZZ
AF Wang, Yingqing
   Qin, Guihe
   Zou, Mi
   Liang, Yanhua
   Wang, Guofeng
   Wang, Kunpeng
   Feng, Yao
   Zhang, Zizhan
TI A lightweight intrusion detection system for internet of vehicles based
   on transfer learning and MobileNetV2 with hyper-parameter optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Intrusion Detection System; Transfer Learning; Internet of Vehicles;
   MobileNetV2; Lightweight Networks; Hyper-parameter Optimization
ID NETWORK; ATTACKS; IOV
AB With the rapid development of Internet of Vehicles (IoV) technology, Intelligent Connected Vehicles (ICVs) have richer vehicle information functions and applications. In recent years, as ICVs have become more complex and intelligent, vehicle information security is facing great threats and challenges. Therefore, it is of great significance to develop efficient intrusion detection methods to protect the information security of IoV. In this paper, after analyzing the vulnerability of intra-vehicle networks (IVNs) and external vehicle networks (EVNs), we propose a lightweight intrusion detection method, which uses MobileNetv2 as the backbone, combines transfer learning (TL) techniques and the hyper-parameter optimization (HPO) method. The proposed method can detect various types of attacks, and the Accuracy, Precision, and Recall on the Car-Hacking dataset representing IVNs data are all 100 %. The Accuracy, Precision, and Recall on the CICIDS2017 dataset representing EVNs data are all 99.93 %. The average processing time of each packet tested is about 0.75 ms, and the model space is 23 M. Experimental results demonstrate that the proposed intrusion detection method is effective and lightweight.
C1 [Wang, Yingqing; Qin, Guihe; Zou, Mi; Liang, Yanhua; Wang, Guofeng; Wang, Kunpeng; Feng, Yao; Zhang, Zizhan] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Wang, Yingqing; Qin, Guihe; Zou, Mi; Liang, Yanhua; Wang, Guofeng; Wang, Kunpeng; Feng, Yao; Zhang, Zizhan] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.
   [Zou, Mi] Jilin Univ, Publ Comp Educ & Res Ctr, Changchun 130012, Peoples R China.
C3 Jilin University; Jilin University; Jilin University
RP Zou, M; Liang, YH (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.; Zou, M; Liang, YH (corresponding author), Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.; Zou, M (corresponding author), Jilin Univ, Publ Comp Educ & Res Ctr, Changchun 130012, Peoples R China.
EM yingqing22@mails.jlu.edu.cn; qingh@jlu.edu.cn; zoumijlu@163.com;
   yhliang18@mails.jlu.edu.cn; gfwang21@mails.jlu.edu.cn;
   wangkp21@mails.jlu.edu.cn; fengyao21@mails.jlu.edu.cn;
   zzzhang21@mails.jlu.edu.cn
RI Zhang, Zizhan/F-5705-2016; Wang, Kunpeng/HCH-0099-2022
OI Wang, Kunpeng/0000-0001-5088-2548
FU Jilin Scientific and Technological Development Program [20200401132GX,
   20210101166JC]
FX This work was supported in part by the Jilin Scientific and
   Technological Development Program under Grant (20200401132GX and
   20210101166JC).
CR Al-Jarrah OY, 2019, IEEE ACCESS, V7, P21266, DOI 10.1109/ACCESS.2019.2894183
   Alheeti KMA, 2018, SYST SCI CONTROL ENG, V6, P48, DOI 10.1080/21642583.2018.1440260
   Aloqaily M, 2019, AD HOC NETW, V90, DOI 10.1016/j.adhoc.2019.02.001
   Alshammari A., 2018, Wireless Eng. Technol., V9, P79, DOI 10.4236/wet.2018.94007
   Ang LM, 2019, IEEE ACCESS, V7, P6473, DOI 10.1109/ACCESS.2018.2887076
   Ashoor A.S., 2011, International Journal of Scientific and Engineering Research, V2, P1
   Aswal K, 2020, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT-2020), P312, DOI 10.1109/icict48043.2020.9112422
   Chen Z., 2022, Journal of Computational and Cognitive Engineering, V1, P103, DOI [10.47852/bonviewJCCE149145205514, DOI 10.47852/BON, DOI 10.47852/BONVIEWJCCE149145205514]
   Cozza F, 2020, COMPUT NETW, V167, DOI 10.1016/j.comnet.2019.106993
   Das S, 2023, T EMERG TELECOMMUN T, V34, DOI 10.1002/ett.4716
   Faraoun KM., 2006, Intl J Comp Intelligence, V3, P28
   Fu B, 2022, INT J IMAG SYST TECH, V32, P144, DOI 10.1002/ima.22658
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Gao Y, 2019, IEEE ACCESS, V7, P154560, DOI 10.1109/ACCESS.2019.2948382
   Gutub A, 2023, CAAI T INTELL TECHNO, V8, P440, DOI 10.1049/cit2.12093
   He H, 2022, SECUR COMMUN NETW, DOI [10.11552/2022/2076987, DOI 10.11552/2022/2076987]
   Injadat MN, 2021, IEEE T NETW SERV MAN, V18, P1803, DOI 10.1109/TNSM.2020.3014929
   Kapoor A, 2022, HELIYON, V8, DOI 10.1016/j.heliyon.2022.e09336
   Khamparia A, 2021, MULTIDIM SYST SIGN P, V32, P747, DOI 10.1007/s11045-020-00756-7
   Lee H, 2017, ANN CONF PRIV SECUR, P57, DOI 10.1109/PST.2017.00017
   Leonardo MM, 2018, SIBGRAPI, P41, DOI 10.1109/SIBGRAPI.2018.00012
   Liang HY, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3243488
   Liu JJ, 2017, IEEE NETWORK, V31, P50, DOI 10.1109/MNET.2017.1600257
   Lokman Siti Farhana, 2018, Int. J. Eng. Technol, V7, P375
   Lu SY, 2020, PATTERN RECOGN LETT, V140, P252, DOI 10.1016/j.patrec.2020.10.017
   Luo A, 2022, J PHYS C SERIES, V2414
   Mehedi ST, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144736
   Min EX, 2018, LECT NOTES COMPUT SC, V11065, P322, DOI 10.1007/978-3-030-00012-7_30
   Namasudra S., 2018, Adv. DNA Comput. cryptogr., P138
   Olufowobi H, 2020, IEEE T VEH TECHNOL, V69, P1484, DOI 10.1109/TVT.2019.2961344
   Olufowobi H, 2019, PROCEEDINGS OF THE ACM WORKSHOP ON AUTOMOTIVE CYBERSECURITY (AUTOSEC '19), P25, DOI 10.1145/3309171.3309178
   Petrov D, 2019, Arxiv, DOI arXiv:1907.06291
   Rosay A., 2020, 2020 IEEE 91st Vehicular Technology Conference (VTC2020-Spring), P1, DOI [10.1109/VTC2020Spring48590.2020.9129472, DOI 10.1109/VTC2020SPRING48590.2020.9129472]
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Santa Barletta V, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10155062
   Schmidt DA, 2020, INTERNET TECHNOL LET, V3, DOI 10.1002/itl2.155
   Seo E, 2018, ANN CONF PRIV SECUR, P286
   Sharafaldin I, 2018, ICISSP: PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS SECURITY AND PRIVACY, P108, DOI 10.5220/0006639801080116
   Shen JL, 2021, INFORM SCIENCES, V569, P469, DOI 10.1016/j.ins.2020.11.026
   Siddiqi MA, 2022, IEEE ACCESS, V10, P108530, DOI 10.1109/ACCESS.2022.3213937
   Song HM, 2020, VEH COMMUN, V21, DOI 10.1016/j.vehcom.2019.100198
   Tripathy MR, 2015, LECT NOTES COMPUT SC, V9502, P315, DOI 10.1007/978-3-319-27293-1_28
   Tai TT, 2022, IEEE ACCESS, V10, P7793, DOI 10.1109/ACCESS.2022.3143119
   Verma R., 2022, Journal of Computational and Cognitive Engineering, P1
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Wang Q, 2018, PROCEEDINGS OF THE 2018 ASIAN HARDWARE ORIENTED SECURITY AND TRUST SYMPOSIUM (ASIANHOST), P86, DOI 10.1109/AsianHOST.2018.8607178
   Wani A, 2021, CAAI T INTELL TECHNO, V6, P281, DOI 10.1049/cit2.12003
   Yang L, 2018, THESIS U GUELPH
   Yang L, 2022, IEEE ICC, P2774, DOI 10.1109/ICC45855.2022.9838780
   Yang L, 2022, IEEE T NETW SERV MAN, V19, P686, DOI 10.1109/TNSM.2021.3100308
   Yang L, 2022, IEEE INTERNET THINGS, V9, P616, DOI 10.1109/JIOT.2021.3084796
   Yang L, 2020, NEUROCOMPUTING, V415, P295, DOI 10.1016/j.neucom.2020.07.061
   Yao YP, 2019, IEEE TRUST, P120, DOI 10.1109/TrustCom/BigDataSE.2019.00025
   Yuan HY, 2022, MULTIMED TOOLS APPL, V81, P38513, DOI 10.1007/s11042-022-13157-8
   Zarpelao BB, 2017, J NETW COMPUT APPL, V84, P25, DOI 10.1016/j.jnca.2017.02.009
   Zhou Chao, 2021, 2021 35th Symposium on Microelectronics Technology and Devices (SBMicro), P383, DOI 10.1109/IAECST54258.2021.9695851
NR 56
TC 2
Z9 2
U1 16
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 16
PY 2023
DI 10.1007/s11042-023-15771-6
EA JUN 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA J8UR5
UT WOS:001012326000005
DA 2024-07-18
ER

PT J
AU Ferhat, R
   Chelali, FZ
AF Ferhat, Roumiassa
   Chelali, Fatma Zohra
TI Textural feature descriptors for a static and dynamic hand gesture
   recognition system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand gesture recognition; LBP; LOOP; LDP; Gabor Binary patter; SVM; etc
ID EXTRACTION; MODEL
AB Hand gesture recognition has become one of the most important directions in human-computer interaction (HCI) research. Despite recent advances in this area, the development of methods and techniques to correctly recognize gestures is still ongoing. In this paper, a hand gesture and sign recognition system (HGRS/SGRS) based on textural features is implemented using a local binary pattern (LBP), local directional pattern (LDP), local optimal-oriented pattern (LOOP) and local Gabor binary pattern histogram sequence (LGBPHS). In terms of feature extraction, we introduce Modified(i)-LOOP, a modified local texture descriptor for HGRS and SGRS to improve the efficiency of our system. The experiments are carried out on five datasets, for Arabic, American Alphabet Sign languages and dynamic gestures where the proposed M-i-LOOP as well as LGBPHS achieve satisfactory simulation results.
C1 [Ferhat, Roumiassa; Chelali, Fatma Zohra] Univ Sci & Technol Houari Boumediene USTHB, Speech Commun & Signal Proc Lab, Fac Elect Engn, Bab Ezzouar 16111, Algeria.
C3 University Science & Technology Houari Boumediene
RP Ferhat, R (corresponding author), Univ Sci & Technol Houari Boumediene USTHB, Speech Commun & Signal Proc Lab, Fac Elect Engn, Bab Ezzouar 16111, Algeria.
EM rferhat@usthb.dz; fchelali@usthb.dz
CR Adeyanju I., 2022, NIGER J TECHNOL DEV, V19, P195, DOI [DOI 10.4314/NJTD.V19I3.2, 10.4314/njtd.v19i3.2]
   Agab S, 2019, INT C ADV EL ENG ICA, P1, DOI DOI 10.1109/ICAEE47123.2019.9014683
   Agab S, 2018, 2018 INT C SIGN IM V, P1
   Agab SE, 2021, 2021 INT C ART INT C, P1
   Al-Jarrah O, 2001, ARTIF INTELL, V133, P117, DOI 10.1016/S0004-3702(01)00141-2
   Aljuhani R, 2022, ARAB J SCI ENG, P1
   Alshomrani S., 2021, Advances in Science and Technology. Research Journal, V15
   Angelopoulou A, 2019, PATTERN ANAL APPL, V22, P1667, DOI 10.1007/s10044-019-00819-x
   Assaleh K, 2005, EURASIP J APPL SIG P, V2005, P2136, DOI 10.1155/ASP.2005.2136
   Bastos ILO, 2015, SIBGRAPI, P305, DOI 10.1109/SIBGRAPI.2015.26
   Bose SR, 2022, EXPERT SYST APPL, V193, DOI 10.1016/j.eswa.2021.116427
   Çevik N, 2020, PATTERN ANAL APPL, V23, P371, DOI 10.1007/s10044-019-00803-5
   Chakraborti T, 2018, IEEE SIGNAL PROC LET, V25, P635, DOI 10.1109/LSP.2018.2817176
   Damaneh MM, 2023, EXPERT SYST APPL, V211, DOI 10.1016/j.eswa.2022.118559
   DAVIES ER, 1986, PATTERN RECOGN LETT, V4, P111, DOI 10.1016/0167-8655(86)90032-2
   Dong C, 2015, IEEE COMPUT SOC CONF
   Dong JQ, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11219789
   El Khadiri I, 2022, EXPERT SYST APPL, V205, DOI 10.1016/j.eswa.2022.117646
   Elmezain M, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P1170
   Elmezain M, 2008, INT C PATT RECOG, P424
   Elouariachi I, 2020, PATTERN ANAL APPL, V23, P1337, DOI 10.1007/s10044-020-00866-9
   Fagiani M, 2015, PATTERN ANAL APPL, V18, P385, DOI 10.1007/s10044-014-0400-z
   Faudzi AAM, 2012, PROCEDIA ENGINEER, V41, P798, DOI 10.1016/j.proeng.2012.07.246
   Ferhat R, 2020, P 3 INT C SMART CIT, P844
   Halidou A, 2014, COMPUT ELECTR ENG, V40, P375, DOI 10.1016/j.compeleceng.2014.10.003
   Haria A, 2017, PROCEDIA COMPUT SCI, V115, P367, DOI 10.1016/j.procs.2017.09.092
   Heikkilä M, 2006, LECT NOTES COMPUT SC, V4338, P58
   Huang H., 2019, J. Phys., Conf. Ser., V1213, DOI [10.1088/1742-6596/1213/2/02200, DOI 10.1088/1742-6596/1213/2/022001]
   Ibrahim NB, 2018, J KING SAUD UNIV-COM, V30, P470, DOI 10.1016/j.jksuci.2017.09.007
   Jabid T, 2010, IEEE ICCE
   Jabid T, 2010, ETRI J, V32, P784, DOI 10.4218/etrij.10.1510.0132
   Jasim M, 2014, 2014 INT C INFORMATI, P1, DOI DOI 10.1109/ICIEV.2014.7136001
   Karanwal S, 2021, PATTERN ANAL APPL, V24, P741, DOI 10.1007/s10044-020-00948-8
   Kaur B, 2016, ADV HUM-COMPUT INTER, P2016
   Kim J, 2017, PATTERN RECOGN, V61, P139, DOI 10.1016/j.patcog.2016.07.039
   Kowdiki M, 2021, COMPUT SCI REV, V39, DOI 10.1016/j.cosrev.2020.100320
   Kumar TGS, 2019, PATTERN ANAL APPL, V22, P1233, DOI 10.1007/s10044-018-0724-1
   Lahiani H, 2017, INT C INT SYST DES A, P180
   Lahiani H, 2018, PROCEDIA COMPUT SCI, V126, P254, DOI 10.1016/j.procs.2018.07.259
   Latif G., 2020, International Journal of Computing and Digital Systems, V9, P715
   Li LW, 2021, PATTERN ANAL APPL, V24, P1173, DOI 10.1007/s10044-021-00965-1
   Liu WF, 2009, 2009 WASE INTERNATIONAL CONFERENCE ON INFORMATION ENGINEERING, ICIE 2009, VOL I, P197, DOI 10.1109/ICIE.2009.36
   Maqueda AI, 2015, COMPUT VIS IMAGE UND, V141, P126, DOI 10.1016/j.cviu.2015.07.009
   Meena K., 2011, 2011 International Conference on Recent Trends in Information Technology (ICRTIT 2011), P782, DOI 10.1109/ICRTIT.2011.5972286
   Mohanty A., 2016, P INT C COMP VIS IM, V2, P449
   Nasri S, 2015, INT J COMPUT MATH, V92, P662, DOI 10.1080/00207160.2014.915958
   Palanisamy G, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.7109
   Parvathy P, 2021, J AMB INTEL HUM COMP, V12, P6793, DOI 10.1007/s12652-020-02314-2
   Popov PA, 2022, MULTIMED TOOLS APPL, V81, P40311, DOI 10.1007/s11042-022-12870-8
   Ren Z., 2011, P 19 ACM INT C MULTI, P1093
   Sadeddine K, 2018, 2018 6 INT C MULTIME, P1, DOI DOI 10.1109/ICMCS.2018.8525908
   Sahoo JP, 2018, IET IMAGE PROCESS, V12, P1780, DOI 10.1049/iet-ipr.2017.1312
   Shanableh T, 2007, IEEE T SYST MAN CY B, V37, P641, DOI 10.1109/TSMCB.2006.889630
   Shanmuganathan V, 2020, NEURAL COMPUT APPL, V32, P16723, DOI 10.1007/s00521-020-05349-w
   Shanthakumar VA, 2020, MULTIMED TOOLS APPL, V79, P17707, DOI 10.1007/s11042-019-08520-1
   Sharma S, 2021, EXPERT SYST APPL, V182, DOI 10.1016/j.eswa.2021.115657
   Sheena C. V., 2021, Machine Vision and Augmented Intelligence-Theory and Applications: Select Proceedings of MAI 2021. Lecture Notes in Electrical Engineering (796), P157, DOI 10.1007/978-981-16-5078-9_14
   Singh S, 2012, INT J COMPUTER APPL, V52
   Song T, 2021, FUTURE GENER COMP SY, V115, P298, DOI 10.1016/j.future.2020.09.013
   Sonia, 2021, Proceedings of International Conference on Big Data, Machine Learning and their Applications. ICBMA 2019. Lecture Notes in Networks and Systems (LNNS 150), P365, DOI 10.1007/978-981-15-8377-3_31
   Starner T., 1997, Motion-Based Recognit, P227
   Stergiopoulou E, 2009, ENG APPL ARTIF INTEL, V22, P1141, DOI 10.1016/j.engappai.2009.03.008
   Tang H, 2019, NEUROCOMPUTING, V331, P424, DOI 10.1016/j.neucom.2018.11.038
   Tang JR, 2018, PATTERN RECOGN, V80, P21, DOI 10.1016/j.patcog.2018.02.011
   Tharwat G., 2021, Journal of Electrical and Computer Engineering, P2021
   TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769
   Triesch J, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P170, DOI 10.1109/AFGR.1996.557260
   Tyagi A, 2022, INT ARAB J INF TECHN, V19, P403, DOI 10.34028/iajit/19/3/15
   WANG L, 1990, PATTERN RECOGN, V23, P905, DOI 10.1016/0031-3203(90)90135-8
   Wu XY, 2020, MULTIMED TOOLS APPL, V79, P9193, DOI 10.1007/s11042-019-7193-4
   Yang LC, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20072106
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P1061, DOI 10.1109/TPAMI.2002.1023803
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zheng JQ, 2017, MULTIMED TOOLS APPL, V76, P20525, DOI 10.1007/s11042-016-3988-8
   Zhong FJ, 2013, NEUROCOMPUTING, V119, P375, DOI 10.1016/j.neucom.2013.03.020
NR 75
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8165
EP 8187
DI 10.1007/s11042-023-15410-0
EA JUN 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001010465000004
DA 2024-07-18
ER

PT J
AU Ahmed, SM
   Elkamchouchi, HMA
   Elfahar, A
   El-Shafai, W
   Mohamed, AG
AF Ahmed, Sara M.
   Elkamchouchi, Hassan M. A.
   Elfahar, Adel
   El-Shafai, Walid
   Mohamed, Amira G.
TI A hybrid medical image cryptosystem based on 4D-hyperchaotic S-boxes and
   logistic maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image security; DNA; S-Box; UACI; NPCR; Hyperchaotic map;
   Logistic maps
ID ENCRYPTION ALGORITHM; DNA; DIFFUSION
AB Privacy and confidentiality are essential for any patient-related information, including medical images. In this paper, a novel image encryption technique for medical images is introduced. This method is based on a four-dimensional (4D) hyperchaotic map, used to generate four substitution-boxes (S-boxes), employed for medical image encryption. The main advantage of this new method is its sensitivity toward attacks, making it highly secure. The encryption process starts by shuffling the plain image using a three-dimensional (3D) Chen map. This step is followed by the subdivision of the image into four sub-images. The third step involves replacing the pixel values in each of the sub-images with corresponding values from one of the four S-boxes. The pre-final step is the combination of the four sub-images, followed by the diffusion of this combined image while using a one-dimensional (1D) logistic map. This results in the final encrypted image. To test the efficiency of this new encryption technique, a 256 x 256 lost block within the encrypted image are subject to different types of attacks using numerical simulation. In the simulation analysis, the encrypted images are also subjected to salt and pepper noise, with the following values: 0.005, 0.05, and 0.1. The pixel correlation coefficient for images encrypted with the tested algorithm is found to be between 0.00241 and -0.000052 in the horizontal direction, between -0.00181 and -0.000952 in the vertical direction, and between 0.00263 and -0.000071 in the diagonal direction. As for information entropy, its value is close to 8 (the ideal value), between 7.9991 and 7.9994. The Unified Average Changing Intensity (UACI) ranged between 0.2857 and 0.3938, and the Number of Pixel Change Rate (NPCR) was between 0.9958 and 0.9962. These ranges are in the proximity of the optimum values for these variables. The results of encryption of other conventional encryption techniques, such as fractional discrete cosine transform with chaotic function, image encryption in the dual domain, and hybrid chaotic DNA diffusion, were compared to those of the proposed technique, which proved to be more effective and yields better results when used for medical image encryption.
C1 [Ahmed, Sara M.; Mohamed, Amira G.] Alexandria Higher Inst Engn & Technol AIET, Dept Elect & Elect Commun Engn, Alexandria, Egypt.
   [Ahmed, Sara M.; Elkamchouchi, Hassan M. A.; Elfahar, Adel] Alexandria Univ, Dept Elect & Elect Commun Engn, Alexandria, Egypt.
   [El-Shafai, Walid] Prince Sultan Univ, Comp Sci Dept, Secur Engn Lab, Riyadh 11586, Saudi Arabia.
   [El-Shafai, Walid] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
C3 Egyptian Knowledge Bank (EKB); Alexandria University; Prince Sultan
   University; Egyptian Knowledge Bank (EKB); Menofia University
RP Ahmed, SM (corresponding author), Alexandria Higher Inst Engn & Technol AIET, Dept Elect & Elect Commun Engn, Alexandria, Egypt.; Ahmed, SM (corresponding author), Alexandria Univ, Dept Elect & Elect Commun Engn, Alexandria, Egypt.
EM sara.mohamedaiet@gmail.com; hass.elkam@gmail.com; a.elfhar@gmail.com;
   eng.waled.elshafai@gmail.com; eng_amira90@yahoo.com
RI El-Shafai, Walid/AAG-4796-2021
OI El-Shafai, Walid/0000-0001-7509-2120
FU Prince Sultan University
FX The authors are very grateful to all the institutions in the affiliation
   list for successfully performing this research work. The authors would
   like to thank Prince Sultan University for their support.
CR Açikkapi MS, 2021, IEEE ACCESS, V9, P1482, DOI 10.1109/ACCESS.2020.3046470
   Akbari Tootkaboni Mohammad, 2023, S BOXES DESIGN BASED
   Al-KateebZeena N, 2020, J PHYS C SER, V1591
   Al-Saidi NMG, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12111881
   Alarood AA, 2022, AIN SHAMS ENG J, V13, DOI 10.1016/j.asej.2021.09.010
   Alghamdi Y, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24101344
   Alkhayyat A, 2022, J SIGNAL PROCESS SYS, V94, P315, DOI 10.1007/s11265-022-01744-9
   Banu SA, 2020, MED BIOL ENG COMPUT, V58, P1445, DOI 10.1007/s11517-020-02178-w
   Bashir Z, 2021, MULTIMED TOOLS APPL, V80, P1029, DOI 10.1007/s11042-020-09695-8
   Belazi A, 2019, IEEE ACCESS, V7, P36667, DOI 10.1109/ACCESS.2019.2906292
   Ben Farah MA, 2020, NONLINEAR DYNAM, V99, P3041, DOI 10.1007/s11071-019-05413-8
   Brahim AH, 2023, INF SECUR J, V32, P59, DOI 10.1080/19393555.2021.1943572
   Chai XL, 2019, MULTIMED TOOLS APPL, V78, P35419, DOI 10.1007/s11042-019-08168-x
   Chaudhary N, 2022, J IMAGING, V8, DOI 10.3390/jimaging8060167
   Dagadu JC, 2019, WIRELESS PERS COMMUN, V108, P591, DOI 10.1007/s11277-019-06420-z
   Deb S, 2021, MULTIMED TOOLS APPL, V80, P19803, DOI 10.1007/s11042-020-10308-7
   Diaconu Adrian-Viorel, 2013, MATH PROBL ENG, V2013
   Dutta Wriddhirup, 2017, 2017 INT C INV COMP
   Ebrahim Seham Muawadh Ali, 2020, ARXIV
   El-Khamy SE, 2020, IEEE ACCESS, V8, P148935, DOI 10.1109/ACCESS.2020.3015687
   El-Shafai W, 2021, J AMB INTEL HUM COMP, V12, P9007, DOI 10.1007/s12652-020-02597-5
   Fawad Masood, 2021, PERS COMMUN, P1
   Gao Y, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/701756
   Girdhar A, 2021, APPL PHYS B-LASERS O, V127, DOI 10.1007/s00340-021-07585-x
   Gu GS, 2014, OPTIK, V125, P4700, DOI 10.1016/j.ijleo.2014.05.023
   Guesmi R, 2021, MULTIMED TOOLS APPL, V80, P1925, DOI 10.1007/s11042-020-09672-1
   Gupta A, 2020, J AMB INTEL HUM COMP, V11, P1309, DOI 10.1007/s12652-019-01493-x
   Hanif M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22166243
   Huang XL, 2014, COMMUN NONLINEAR SCI, V19, P4094, DOI 10.1016/j.cnsns.2014.04.012
   Idrees B, 2020, MULTIMED TOOLS APPL, V79, P6135, DOI 10.1007/s11042-019-08282-w
   Iqbal N, 2021, MULTIMED TOOLS APPL, V80, P36305, DOI 10.1007/s11042-021-11386-x
   Javan AAK, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113925
   John Siju, 2023, Procedia Computer Science, P918, DOI 10.1016/j.procs.2023.01.072
   Kaur M, 2020, ARCH COMPUT METHOD E, V27, P15, DOI 10.1007/s11831-018-9298-8
   Khalil N, 2021, OPT LASER TECHNOL, V143, DOI 10.1016/j.optlastec.2021.107326
   Khan JS, 2020, IEEE ACCESS, V8, P159732, DOI 10.1109/ACCESS.2020.3020917
   Khan JS, 2019, MULTIDIM SYST SIGN P, V30, P943, DOI 10.1007/s11045-018-0589-x
   Kumar S, 2019, MED BIOL ENG COMPUT, V57, P2517, DOI 10.1007/s11517-019-02037-3
   Lee WK, 2018, NONLINEAR DYNAM, V92, P575, DOI 10.1007/s11071-018-4076-6
   Li CL, 2021, MULTIMED TOOLS APPL, V80, P18479, DOI 10.1007/s11042-021-10631-7
   Li TY, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21030319
   Liu H, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21040343
   Liu JZ, 2018, MULTIMED TOOLS APPL, V77, P22787, DOI 10.1007/s11042-017-5534-8
   Lu Y, 2023, J KING SAUD UNIV-COM, V35, P37, DOI 10.1016/j.jksuci.2023.02.004
   Mirzaei O, 2012, NONLINEAR DYNAM, V67, P557, DOI 10.1007/s11071-011-0006-6
   Mohamed AG, 2021, IEEE ACCESS, V9, P14284, DOI 10.1109/ACCESS.2021.3052161
   Mohamed Gafsi, 2020, SCI PROGRAMMING 2020
   Mohamed Heba G, 2020, Entropy (Basel), V22, DOI 10.3390/e22020158
   Muhammad Asif, 2021, COMPUT INTEL NEUROSC, V2021
   Nestor T, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14020424
   Niu Y, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/4079793
   Pareek NK, 2013, DIGIT SIGNAL PROCESS, V23, P894, DOI 10.1016/j.dsp.2013.01.005
   Patro KAK, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102470
   Pavithra V, 2018, IEEE I C COMP INT CO, P319
   Qayyum A, 2020, IEEE ACCESS, V8, P140876, DOI 10.1109/ACCESS.2020.3012912
   Ravichandran D, 2021, MED BIOL ENG COMPUT, V59, P589, DOI 10.1007/s11517-021-02328-8
   Raza SF, 2019, NONLINEAR DYNAM, V95, P859, DOI 10.1007/s11071-018-4600-8
   Shabieh Farwa, 2017, INT J ADV COMPUTER S, V6
   Stalin S, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1389-z
   Talhaoui MZ, 2021, J REAL-TIME IMAGE PR, V18, P85, DOI 10.1007/s11554-020-00948-1
   Vaseghi B, 2021, IEEE ACCESS, V9, P25911, DOI 10.1109/ACCESS.2021.3056037
   Vyavahare Puja, 2019, ANAL CHAOTIC HYPERCH
   Wang XY, 2021, CHAOS SOLITON FRACT, V150, DOI 10.1016/j.chaos.2021.111117
   Wang XY, 2020, CHAOS SOLITON FRACT, V141, DOI 10.1016/j.chaos.2020.110309
   Wang XY, 2019, OPT LASER TECHNOL, V119, DOI 10.1016/j.optlastec.2019.105581
   Wang X, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040781
   Xu JJ, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24020186
   Zareai D, 2021, MULTIMED TOOLS APPL, V80, P18317, DOI 10.1007/s11042-021-10576-x
   Zhan K, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.1.013021
   Zhang L, 2020, MULTIMED TOOLS APPL, V79, P20753, DOI 10.1007/s11042-020-08835-4
   Zhang Y, 2016, IETE TECH REV, V33, P310, DOI 10.1080/02564602.2015.1087350
   Zhou Y, 2021, NONLINEAR DYNAM, V103, P2043, DOI 10.1007/s11071-021-06206-8
NR 72
TC 1
Z9 1
U1 6
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8837
EP 8865
DI 10.1007/s11042-023-15925-6
EA JUN 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001009907400002
DA 2024-07-18
ER

PT J
AU Liu, Y
   Ji, SJ
   Fu, Q
   Chiu, DKW
AF Liu, Yun
   Ji, Shujuan
   Fu, Qiang
   Chiu, Dickson K. W.
TI A semantic-consistency asymmetric matrix factorization hashing method
   for cross-modal retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-modal retrieval; Matrix factorization; Hashing; Semantic
   information
AB Hashing methods have recently received widespread attention due to their flexibility and effectiveness for cross-modal retrieval tasks. However, existing cross-modal hashing methods have a common challenging problem, how to effectively exploit semantic information to learn discriminative hash codes while saving storage and computation cost. To address this issue, in this paper, we propose an efficient Semantic-consistency Asymmetric Matrix Factorization Hashing (SAMFH) method. Specifically, this method first leverages matrix factorization to obtain the latent semantic representations for different modalities and the label representation for class label information. To further utilize semantic information and learn discriminative binary codes, we adopt an asymmetric supervised learning strategy to fuse the pairwise semantic matrix into the framework. Finally, we directly update unified hash codes with an efficient discrete optimization strategy. Experimental results on three benchmark datasets demonstrate that our SAMFH method outperforms many state-of-the-art cross-modal hashing methods.
C1 [Liu, Yun; Ji, Shujuan] Shandong Univ Sci & Technol, Key Lab Wisdom Mine Informat Technol Shandong Prov, Qingdao 266590, Shandong, Peoples R China.
   [Fu, Qiang] Chinese Acad Sci, Inst Software, Beijing Key Lab Human Comp Interact, Beijing 100190, Peoples R China.
   [Chiu, Dickson K. W.] Univ Hong Kong, Fac Educ, Hong Kong, Peoples R China.
C3 Shandong University of Science & Technology; Chinese Academy of
   Sciences; Institute of Software, CAS; University of Hong Kong
RP Ji, SJ (corresponding author), Shandong Univ Sci & Technol, Key Lab Wisdom Mine Informat Technol Shandong Prov, Qingdao 266590, Shandong, Peoples R China.
EM jane_ji2003@aliyun.com
RI Chiu, Dickson K. W./B-9630-2017; ji, shujuan/HKP-2990-2023
OI Chiu, Dickson K. W./0000-0002-7926-9568; ji, shujuan/0000-0003-2650-0161
FU Natural Science Foundation of China [71772107, 62072288]; Natural
   Science Foundation of Shandong Province of China [ZR2020MF044,
   ZR202102230289, ZR2019MF003, ZR2021MF104]; Shandong Education Quality
   Improvement Plan for Postgraduate; SDUST Research Fund; Humanity and
   Social Science Fund of the Ministry of Education [20YJAZH078,
   20YJAZH127]
FX This paper is supported by the Natural Science Foundation of China
   (71772107, 62072288), the Natural Science Foundation of Shandong
   Province of China (ZR2020MF044, ZR202102230289, ZR2019MF003,
   ZR2021MF104), Shandong Education Quality Improvement Plan for
   Postgraduate (2021), the SDUST Research Fund, Humanity and Social
   Science Fund of the Ministry of Education under Grant 20YJAZH078 and
   20YJAZH127.
CR Bronstein MM, 2010, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2010.5539928
   Chatfield K., 2014, ARXIV
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Deng C, 2018, IEEE T IMAGE PROCESS, V27, P3893, DOI 10.1109/TIP.2018.2821921
   Ding GG, 2014, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2014.267
   Fang YX, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107062
   Fang YX, 2019, KNOWL-BASED SYST, V171, P69, DOI 10.1016/j.knosys.2019.02.004
   Hu MQ, 2019, IEEE T IMAGE PROCESS, V28, P2770, DOI 10.1109/TIP.2018.2890144
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Jiang QY, 2017, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2017.348
   Kumar Shaishav, 2011, P 22 INT JOINT C ART, P1360, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-230
   Li C, 2018, PROC CVPR IEEE, P4242, DOI 10.1109/CVPR.2018.00446
   Li C, 2018, DES AUT CON, DOI 10.1145/3195970.3196091
   Lin ZJ, 2015, PROC CVPR IEEE, P3864, DOI 10.1109/CVPR.2015.7299011
   Liu H, 2017, PROC CVPR IEEE, P6345, DOI 10.1109/CVPR.2017.672
   Liu W., 2014, P NEURAL INF PROCESS, P3419
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Lu X, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P715, DOI 10.1145/3331184.3331217
   Lu X, 2019, SIGNAL PROCESS, V154, P217, DOI 10.1016/j.sigpro.2018.09.007
   Luo X, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2518
   Mandal D, 2017, IEEE IMAGE PROC, P2901, DOI 10.1109/ICIP.2017.8296813
   Peng YX, 2018, IEEE T CIRC SYST VID, V28, P2372, DOI 10.1109/TCSVT.2017.2705068
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Shao J, 2019, MULTIMED TOOLS APPL, V78, P16615, DOI 10.1007/s11042-018-7068-0
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Song J., 2013, P ACM SIGMOD INT C M, P785, DOI DOI 10.1145/2463676.2465274
   Tang J, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2564638
   Wang T, 2020, NEUROCOMPUTING, V386, P84, DOI 10.1016/j.neucom.2019.12.058
   Wang D, 2018, IEEE T CIRC SYST VID, V28, P2703, DOI 10.1109/TCSVT.2017.2723302
   Wang D, 2019, IEEE T PATTERN ANAL, V41, P2466, DOI 10.1109/TPAMI.2018.2861000
   Wang D, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3890
   Wang K, 2016, ARXIV
   Wang YX, 2022, IEEE T CYBERNETICS, V52, P10064, DOI 10.1109/TCYB.2021.3059886
   Wang YX, 2021, IEEE T KNOWL DATA EN, V33, P3507, DOI 10.1109/TKDE.2020.2974825
   Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345
   Yan JH, 2018, MULTIMED TOOLS APPL, V77, P3009, DOI 10.1007/s11042-017-4918-0
   Yang EK, 2017, AAAI CONF ARTIF INTE, P1618
   Yao T, 2016, NEUROCOMPUTING, V193, P250, DOI 10.1016/j.neucom.2016.02.016
   Zhang DQ, 2014, AAAI CONF ARTIF INTE, P2177
   Zhang J, 2018, AAAI CONF ARTIF INTE, P539
   Zhang MJ, 2019, MULTIMED TOOLS APPL, V78, P28285, DOI 10.1007/s11042-019-07909-2
   Zhong FM, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107523
   Zhou JL, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P415
NR 43
TC 0
Z9 0
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 6621
EP 6649
DI 10.1007/s11042-023-15535-2
EA JUN 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001009907400011
DA 2024-07-18
ER

PT J
AU Tang, YH
   Zhang, LY
   Yuan, Y
AF Tang, Yuhao
   Zhang, Liyan
   Yuan, Ye
TI Fashion item captioning via grid-relation self-attention and
   gated-enhanced decoder
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fashion; E-Commerce; Transformer; Image captioning
AB Fashion Item Captioning aims to describe fine-grained item details according to several image angles, which is an advancement of the conventional image captioning task(generating a simple sentence for a single image). Most recent researches are dedicated to describe one image, and less attention is paid to capturing item details from different angles. As a result, they commonly take advantage of formula structure in the general domain rather than taking into account the characteristics of product images in the fashion domain. In this paper, we re-define the fashion captioning task to be Fashion Item Captioning, which is aimed to describe the item angles based on a multi-branch design. Based on this thinking, fashion item captioning still face two challenges. First, existing image captioning methods simply consider the grid features as a set of visual tokens while ignoring the positional relationships among them. And these rich relationships are difficult to be established by such coarse-grained visual representations. To this end, we propose a Grid-relation Self-Attention(GSA), in which three positional relations among grid-level features are captured to strengthen the visual representations from multi perspectives. Second, the attributes of products are usually scattered in images from different angles, which means different angles contribute differently to the sentence caption. Thus, a Gated-Enhanced Decoder(GED) is introduced to dynamically measure the contribution of different views to the target word. Finally, we apply GSA and GED to the vanilla transformer model for the fashion item captioning task. Extensive experiments demonstrate the proposed GSA-GED is effective. More remarkably, GSA-GED achieves competitive performance on Fashion-Gen and FACAD datasets, with the CIDEr-D score being increased from 106.7% to 112.1%, 47.1% to 49.3%, respectively.
C1 [Tang, Yuhao; Zhang, Liyan; Yuan, Ye] Nanjing Univ Aeronaut & Astronaut, Nanjing 210000, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics
RP Zhang, LY (corresponding author), Nanjing Univ Aeronaut & Astronaut, Nanjing 210000, Peoples R China.
EM bx2016006@nuaa.edu.cn; zhangliyan@nuaa.edu.cn; yuanyeh@nuaa.edu.cn
OI Yuan, Ye/0009-0005-3886-3527
FU National Natural Science Foundation of China [62172212]
FX AcknowledgementThis work was supported in part by the National Natural
   Science Foundation of China under Grant 62172212.
CR Alsaffar MF, 2019, DRUG INVENTION TODAY, V12
   Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Cao DY, 2019, MULTIMED TOOLS APPL, V78, P35329, DOI 10.1007/s11042-019-08116-9
   Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059
   Das R, 2022, MULTIMED TOOLS APPL, V81, P10051, DOI 10.1007/s11042-022-12042-8
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, DOI [10.3115/v1/W14-3348, DOI 10.3115/V1/W14-3348]
   Gao DH, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P2251, DOI 10.1145/3397271.3401430
   Guo Q, 2021, 2021 IEEE INT C MULT, P1
   Herdade S., 2019, ARXIV
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang L, 2019, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2019.00473
   Li G, 2019, IEEE I CONF COMP VIS, P8927, DOI 10.1109/ICCV.2019.00902
   Li ZW, 2020, PROC CVPR IEEE, P3437, DOI 10.1109/CVPR42600.2020.00350
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Longteng Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10324, DOI 10.1109/CVPR42600.2020.01034
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Luo YP, 2021, AAAI CONF ARTIF INTE, V35, P2286
   Ma Z, 2020, AAAI CONF ARTIF INTE, V34, P11741
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Rostamzadeh N., 2018, ARXIV
   Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556
   Singh A, 2021, MULTIMED TOOLS APPL, V80, P35721, DOI 10.1007/s11042-021-11106-5
   Vaswani A, 2017, ADV NEUR IN, V30
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2017, IEEE T PATTERN ANAL, V39, P652, DOI 10.1109/TPAMI.2016.2587640
   Wang J, 2021, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR46437.2021.00136
   Wang WG, 2018, PROC CVPR IEEE, P4271, DOI 10.1109/CVPR.2018.00449
   Wu H, 2021, PROC CVPR IEEE, P11302, DOI 10.1109/CVPR46437.2021.01115
   Wu K., 2021, arXiv
   Xia PF, 2020, MULTIMED TOOLS APPL, V79, P24225, DOI 10.1007/s11042-020-09110-2
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang X., 2020, COMPUTER VISION ECCV, P1
   Yingwei Pan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10968, DOI 10.1109/CVPR42600.2020.01098
   Yuan Y., 2021, ARXIV
   Zakizadeh R, 2018, ARXIV
   Zhang WQ, 2021, MULTIMED TOOLS APPL, V80, P16267, DOI 10.1007/s11042-020-08832-7
   Zhuge MC, 2021, PROC CVPR IEEE, P12642, DOI 10.1109/CVPR46437.2021.01246
NR 39
TC 0
Z9 0
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7631
EP 7655
DI 10.1007/s11042-023-15492-w
EA JUN 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001006598900001
DA 2024-07-18
ER

PT J
AU Yan, F
   Silamu, W
   Chai, YC
   Li, YB
AF Yan, Feng
   Silamu, Wushouer
   Chai, Yachuang
   Li, Yanbing
TI OECA-Net: A co-attention network for visual question answering based on
   OCR scene text feature enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual question answering; Faster R-CNN; Self-attention; Spatial
   position relationship
AB Most VQA(visual question answering) models can not understand the scene text in the image. Poor text reading ability is a significant reason for the current VQA model's poor performance. To solve the problems, we designed a co-attention model that incorporates the scene text features in images. We detect and obtain the OCR token in the image through the OCR model, which is conducive to further understanding the image. We design a model based on a co-attention mechanism, including a question self-attention unit, question-guided image visual attention unit and question-guided image OCR token attention unit. The redundant question information is filtered under the question self-attention module. The question-guided attention module is used to obtain the final visual features and OCR token features in the image. The information of question text features, visual image features and OCR token features in the image is fused. We design a classifier which can get an answer from the fixed answer set or directly copy the text detected from the OCR model as the final answer so that the model can answer the questions about the text in the image. The experimental results show that our model is improved.
C1 [Yan, Feng; Silamu, Wushouer; Chai, Yachuang; Li, Yanbing] Xinjiang Univ, Sch Informat Sci & Engn, Shengli Rd 666, Urumqi 830046, Xinjiang, Peoples R China.
   [Silamu, Wushouer] Xinjiang Key Lab Multilingual Informat Technol, Shengli Rd 666, Urumqi 830046, Xinjiang, Peoples R China.
C3 Xinjiang University
RP Yan, F (corresponding author), Xinjiang Univ, Sch Informat Sci & Engn, Shengli Rd 666, Urumqi 830046, Xinjiang, Peoples R China.
EM yanfeng@stu.xju.edu.cn; wushour@xju.edu.cn; cyc@stu.xju.edu.cn;
   liyb@xju.edu.cn
RI Guo, Lin/KFS-9366-2024; li, sixuan/KGR-3943-2024; zhang,
   yingying/KGM-8162-2024; li, bai/GRJ-4913-2022; Cheng, Lin/KFQ-3111-2024
OI zhang, yingying/0000-0001-7479-3398; Yan, Feng/0000-0002-8615-139X
FU National Natural Science Foundation of China [U1911401]; Ministry of
   Science and Technology of China [ZDI135-96]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant U1911401 and Key Project of Science and
   Technology Innovation 2030 supported by the Ministry of Science and
   Technology of China under Grant ZDI135-96.
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Ba J. L., 2016, LAYER NORMALIZATION, DOI DOI 10.48550/ARXIV.1607.06450
   Ben-younes H, 2017, IEEE I CONF COMP VIS, P2631, DOI 10.1109/ICCV.2017.285
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   Borisyuk F, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P71, DOI 10.1145/3219819.3219861
   Cadene R, 2019, PROC CVPR IEEE, P1989, DOI 10.1109/CVPR.2019.00209
   Chen CQ, 2022, PATTERN RECOGN, V132, DOI 10.1016/j.patcog.2022.108980
   Chen K, 2015, ARXIV
   Fukui Akira, 2016, P C EMP METH NAT LAN
   Gao P, 2019, PROC CVPR IEEE, P6632, DOI 10.1109/CVPR.2019.00680
   Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670
   Guo MH, 2022, COMPUT VIS MEDIA, V8, P331, DOI 10.1007/s41095-022-0271-y
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu Ronghang, 2020, 2020 IEEE CVF C COMP, P9992, DOI DOI 10.1109/CVPR42600.2020.01001
   Jia S, 2018, MULTIMED TOOLS APPL, V77, P14859, DOI 10.1007/s11042-017-5070-6
   Jiang XZ, 2020, AAAI CONF ARTIF INTE, V34, P11125
   Kim J-H, 2016, ARXIV
   Kim J, 2018, TENCON IEEE REGION, P0090, DOI 10.1109/TENCON.2018.8650166
   Li J., 2022, INT C MACHINE LEARNI, P12888, DOI DOI 10.48550/ARXIV.2201.12086
   Lu JS, 2019, ADV NEUR IN, V32
   Manmadhan S, 2020, ARTIF INTELL REV, V53, P5705, DOI 10.1007/s10462-020-09832-7
   Peng Liang, 2020, IEEE T PATTERN ANAL
   Peng Wang, 2022, PMLR, P23318
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Shahi TB, 2022, ARTIF INTELL REV, V55, P3401, DOI 10.1007/s10462-021-10093-1
   Singh A, 2019, PROC CVPR IEEE, P8309, DOI 10.1109/CVPR.2019.00851
   Tan HH, 2019, arXiv
   Teney D, 2018, PROC CVPR IEEE, P4223, DOI 10.1109/CVPR.2018.00444
   Vaswani Ashish, 2017, Advances in Neural Information Processing Systems (NeurIPS), V17, P6000, DOI DOI 10.48550/ARXIV.1706.03762
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Yan F, 2022, VISUAL COMPUT, V38, P3097, DOI 10.1007/s00371-022-02524-z
   Yan F, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22031045
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yen-Chun Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P104, DOI 10.1007/978-3-030-58577-8_7
   Yu DF, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3316767
   Yu Z, 2018, IEEE T NEUR NET LEAR, V29, P5947, DOI 10.1109/TNNLS.2018.2817340
   Yu Z, 2019, PROC CVPR IEEE, P6274, DOI 10.1109/CVPR.2019.00644
   Zhang S, 2021, INFORM FUSION, V73, P1, DOI 10.1016/j.inffus.2021.02.022
   Zhang WF, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106639
   Zhang Y, 2020, IEEE ACCESS, V8, P19033, DOI 10.1109/ACCESS.2020.2966827
NR 41
TC 2
Z9 2
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7085
EP 7096
DI 10.1007/s11042-023-15418-6
EA JUN 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001000907700006
DA 2024-07-18
ER

PT J
AU Mathur, G
   Pandey, A
   Goyal, S
AF Mathur, Garima
   Pandey, Anjana
   Goyal, Sachin
TI A review on blockchain for DNA sequence: security issues, application in
   DNA classification, challenges and future trends
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Healthcare; DNA sequence; Classification; Blockchain; Genomes; Genbank;
   Machine learning
ID COMPRESSION
AB In biological science, the study of DNA sequences is considered an important factor because it carries the genomic details that can be used by researchers and doctors for the early prediction of disease using DNA classification. The NCBI has the world's largest database of genetic sequences, but the security of this massive amount of data is currently the greatest issue. One of the options is to encrypt these genetic sequences using blockchain technology. As a result, this paper presents a survey on healthcare data breaches, the necessity for blockchain in healthcare, and the number of research studies done in this area. In addition, the report suggests DNA sequence classification for earlier disease identification and evaluates previous work in the field.
C1 [Mathur, Garima] RGPV, Dept Comp Sci & Engn, UIT, Bhopal, India.
   [Pandey, Anjana; Goyal, Sachin] RGPV, Dept Informat Technol, UIT, Bhopal, India.
C3 Barkatullah University; Rajiv Gandhi Technological University;
   Barkatullah University; Rajiv Gandhi Technological University
RP Mathur, G (corresponding author), RGPV, Dept Comp Sci & Engn, UIT, Bhopal, India.
EM garima41mathur@gmail.com; anjanapandey@rgtu.net; sachingoyal@rgtu.net
CR Abadi M., 2016, arXiv, DOI DOI 10.48550/ARXIV.1603.04467
   Afshar P, 2018, IEEE IMAGE PROC, P3129, DOI 10.1109/ICIP.2018.8451379
   Angraal S, 2017, CIRC-CARDIOVASC QUAL, V10, DOI 10.1161/CIRCOUTCOMES.117.003800
   Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865
   Ardakani AA, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103795
   Aste T, 2017, COMPUTER, V50, P18, DOI 10.1109/MC.2017.3571064
   Aumasson J-P., 2017, Serious Cryptography: A Practical Introduction to Modern Encryption
   Bai HX, 2020, RADIOLOGY, V296, pE46, DOI 10.1148/radiol.2020200823
   Benson D.A., 2012, NUCLEIC ACIDS RES, P1, DOI DOI 10.1093/nar/gkl986
   European Coordination Committee of the Radiological, 2017, BLOCKCH HEALTHC
   ghr.nlm.nih.gov, WHAT IS DNA GENETICS
   Hach F, 2014, NAT METHODS, V11, P1082, DOI 10.1038/nmeth.3133
   Holbl M, 2018, MDPI J
   Jin S, 2020, medRxiv, DOI [10.1101/2020.03.19.20039354, 10.1101/2020.03.19.20039354, DOI 10.1101/2020.03.19.20039354]
   Khan MA, 2018, FUTURE GENER COMP SY, V82, P395, DOI 10.1016/j.future.2017.11.022
   Kim Hwiyoung, 2019, [Journal of the Korean Society of Radiology (JKSR), 대한영상의학회지], V80, P259, DOI 10.3348/jksr.2019.80.2.259
   Le Cun Y., 1990, Neurocomputing, Algorithms, Architectures and Applications. Proceedings of the NATO Advanced Research Workshop, P303
   Lee H, 2011, LECT NOTES COMPUT SC, V6513, P273, DOI 10.1007/978-3-642-17955-6_20
   Lee SJ, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8091471
   Levy S, 1997, LECT NOTES COMPUT SC, V1261, P339
   Li L, 2020, RADIOLOGY, V296, pE65, DOI 10.1148/radiol.2020200905
   Lo Bosco G, 2017, LECT NOTES ARTIF INT, V10147, P162, DOI 10.1007/978-3-319-52962-2_14
   Ma QC, 2001, IEEE T SYST MAN CY C, V31, P468, DOI 10.1109/5326.983930
   Mathur G, 2020, 2 INT C DAT ENG APPL, P1, DOI [10.1109/IDEA49133.2020.9170715, DOI 10.1109/IDEA49133.2020.9170715]
   Mathur G., 2021, ENG, V7, P7130
   Mathur G, 2022, INT MED THINGS IOMT, P177
   Mathur G., 2021, SECURITY PRIVACY HEA, V19, P93
   Mathur G., 2021, TURK ONLINE J QUAL I, V12, P4498
   Mathur Garima, 2022, J Ambient Intell Humaniz Comput, P1, DOI 10.1007/s12652-022-04099-y
   McConaghy T, 2018, BIGCHAINDB 2 0 BLOCK
   McConaghy T, 2016, BIGCHAIN DB SCALABLE
   Mei XY, 2020, NAT MED, V26, P1224, DOI [10.1038/s41591-020-0931-3, 10.1101/2020.04.12.20062661]
   Miotto R, 2018, BRIEF BIOINFORM, V19, P1236, DOI 10.1093/bib/bbx044
   Mohammed MH, 2012, BIOINFORMATICS, V28, P2527, DOI 10.1093/bioinformatics/bts467
   Müller HM, 2003, J THEOR BIOL, V223, P161, DOI 10.1016/S0022-5193(03)00082-1
   Ohno-Machado L, 2002, J INTELL FUZZY SYST, V12, P19
   Papangelou K, 2019, LECT NOTES ARTIF INT, V11051, P35, DOI 10.1007/978-3-030-10925-7_3
   Phan D., 2016, J Biomed Sci Eng, V9, P280, DOI DOI 10.4236/JBISE.2016.95021
   Qayyum A, 2021, IEEE REV BIOMED ENG, V14, P156, DOI 10.1109/RBME.2020.3013489
   Ranawana R, 2005, NEURAL COMPUT APPL, V14, P122, DOI 10.1007/s00521-004-0447-7
   Roehrs A, 2017, J BIOMED INFORM, V71, P70, DOI 10.1016/j.jbi.2017.05.012
   Sardaraz M, 2016, J BIOINF COMPUT BIOL, V14, DOI 10.1142/S0219720016300021
   Sleiman MD, 2015, 2015 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P332, DOI 10.1109/CW.2015.56
   Szegedy C., 2013, Advances in Neural Information Processing Systems, V26, P2553
   TusharDey Shweta Sunderkrishnan, P INT C INT SUST SYS
   Wang JTL, 1996, PROTEIN ENG, V9, P381, DOI 10.1093/protein/9.5.381
   Wang LC, 2019, J NETW COMPUT APPL, V127, P43, DOI 10.1016/j.jnca.2018.11.003
   Wüst K, 2018, 2018 CRYPTO VALLEY CONFERENCE ON BLOCKCHAIN TECHNOLOGY (CVCBT), P45, DOI 10.1109/CVCBT.2018.00011
   Xu XW, 2020, ENGINEERING-PRC, V6, P1122, DOI 10.1016/j.eng.2020.04.010
   Yang AM, 2020, FRONT BIOENG BIOTECH, V8, DOI 10.3389/fbioe.2020.01032
   Yu XY, 2019, IEEE T NEUR NET LEAR, V30, P2805, DOI 10.1109/TNNLS.2018.2886017
   Zhang K, 2020, CELL, V181, P1423, DOI 10.1016/j.cell.2020.04.045
   Zheng ZB, 2017, IEEE INT CONGR BIG, P557, DOI 10.1109/BigDataCongress.2017.85
   Zhu ZX, 2015, BRIEF BIOINFORM, V16, P1, DOI 10.1093/bib/bbt087
NR 54
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 25
PY 2023
DI 10.1007/s11042-023-15857-1
EA MAY 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3NP9
UT WOS:000995070900006
PM 37362738
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Bularz, M
   Przystalski, K
   Ogorzalek, M
AF Bularz, Michal
   Przystalski, Karol
   Ogorzalek, Maciej
TI Car make and model recognition system using rear-lamp features and
   convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Car make and model recognition; Computer vision; Convolutional neural
   networks; Image binarization
ID VEHICLE
AB Recognizing cars based on their features is a difficult task. We propose a solution that uses a convolutional neural network (CNN) and image binarization method for car make and model classification. Unlike many previous works in this area, we use a feature extraction method combined with a binarization method. In the first stage of the pre-processing part we normalize and change the size of an image. The image is then used to recognize where the rear-lamps are placed on the image. We extract the region and use the image binarization method. The binarized image is used as input to the CNN network that finds the features of a specific car model. We have tested the combinations of three different neural network architectures and eight binarization methods. The convolutional neural network with parameters of the highest quality metrics value is used to find the characteristics of the rear lamps on the binary image. The convolutional network is tested with four different gradient algorithms. We have tested the method on two data sets which differ in the way the images were taken. Each data set consists of three subsets of the same car, but is scaled to different image dimensions. Compared to related works that are based on CNN, we use rear view images in different position and light exposure. The proposed method gives better results compared to most available methods. It is also less complex, and faster to train compared to other methods. The proposed approach achieves an average accuracy of 93,9% on the first data set and 84,5% on the second set.
C1 [Bularz, Michal; Przystalski, Karol; Ogorzalek, Maciej] Jagiellonian Univ Cracow, Dept Informat Technol, Lojasiewicza 11, PL-30348 Krakow, Poland.
C3 Jagiellonian University
RP Bularz, M (corresponding author), Jagiellonian Univ Cracow, Dept Informat Technol, Lojasiewicza 11, PL-30348 Krakow, Poland.
EM mbularz95@interia.pl; karol.przystalski@uj.edu.pl;
   maciej.ogorzalek@uj.edu.pl
OI Przystalski, Karol/0000-0002-8572-1469
CR Abbas A, 2020, B ELECT ENG INFORM, P9
   [Anonymous], 2014, INT J COMPUT APPL, DOI DOI 10.5120/17579-8345
   [Anonymous], 2005, P IRISH C ARTIFICIAL
   Arzani M. M., 2010, 2010 International Conference on Signal and Image Processing (ICSIP 2010), P353, DOI 10.1109/ICSIP.2010.5697497
   Asgarian Dehkordi R., 2020, J AI DATA MIN, V8, P427
   Baran R, 2015, MULTIMED TOOLS APPL, V74
   Boonsim N, 2017, PATTERN ANAL APPL, V20, P1195, DOI 10.1007/s10044-016-0559-6
   Boukerche A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3107614
   Clady X, 2008, LECT NOTES ARTIF INT, V5064, P228, DOI 10.1007/978-3-540-69939-2_22
   Corrales Sanchez H, 2020, CNNS FINE GRAINED CA, P104
   Daya Bassam, 2010, 2010 IEEE Fifth International Conference on Bio-Inspired Computing: Theories and Applications (BIC-TA), P1607, DOI 10.1109/BICTA.2010.5645260
   DIASVELASCO FR, 1980, IEEE T SYST MAN CYB, V10, P771
   Dodge J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2185
   FBI.gov, MOTOR VEHICLE THEFT
   Fomin I., 2020, 2020 INT C IND ENG A, P1
   Fraz M, 2014, INT C PATT RECOG, P393, DOI 10.1109/ICPR.2014.76
   Ghassemi S, 2019, SIGNAL PROCESS-IMAGE, V72, P69, DOI 10.1016/j.image.2018.12.009
   Gormer S, 2009, VEHICLE RECOGNITION, P1
   He HS, 2015, IEEE T INTELL TRANSP, V16, DOI 10.1109/TITS.2015.2437998
   Hsieh JW, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P472, DOI 10.1109/AVSS.2013.6636685
   Jamil AA, 2020, SENSORS-BASEL, P20
   Kamal I., 2012, 2012 International Conference on Multimedia Computing and Systems (ICMCS), P328, DOI 10.1109/ICMCS.2012.6320284
   Kazemi FM, 2007, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, PROCEEDINGS, P516
   Khorramshahi P, 2019, IEEE I CONF COMP VIS, P6131, DOI 10.1109/ICCV.2019.00623
   Kim J, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR 2019), P42, DOI 10.1145/3357254.3357284
   Krause J, 2015, PROC CVPR IEEE, P5546, DOI 10.1109/CVPR.2015.7299194
   Lee HJ, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19050982
   Lee Suhan, 2013, INT J SIGNAL PROCESS, V6, P175
   Li CH, 1998, PATTERN RECOGN LETT, V19, P771, DOI 10.1016/S0167-8655(98)00057-9
   Llorca DF, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P3094, DOI 10.1109/ITSC.2014.6958187
   Lu L, 2020, NEUROCOMPUTING, V372, P92, DOI 10.1016/j.neucom.2019.09.049
   Ma XC, 2021, P I MECH ENG F-J RAI, V235, P155, DOI 10.1177/0954409720909971
   Manzoor MA, 2019, MACH LEARN KNOW EXTR, V1, P611, DOI 10.3390/make1020036
   Negri P, 2006, INT C PATT RECOG, P574
   Ni X, 2021, J SIGNAL PROCESS SYS, V93
   Niblack W., 1986, An Introduction to Digital Image Processing
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Park SH, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22030921
   Pearce G., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P373, DOI 10.1109/AVSS.2011.6027353
   Psyllos A, 2011, COMPUT STAND INTER, V33, P142, DOI 10.1016/j.csi.2010.06.005
   Rahati S, 2008, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS, P894, DOI 10.1109/ITNG.2008.136
   Saravi S., 2013, 2013 18 INT C DIGITA, P1
   Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2
   Sochor J, 2016, PROC CVPR IEEE, P3006, DOI 10.1109/CVPR.2016.328
   Varjas V, 2013, INT SYMP IMAGE SIG, P819
   Wang CC, 2005, 2005 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P3314
   Wang HB, 2020, IEEE T VEH TECHNOL, V69, P10484, DOI 10.1109/TVT.2020.3009162
   Xiang Y, 2019, NEUROCOMPUTING, V367, P287, DOI 10.1016/j.neucom.2019.07.098
   YEN JC, 1995, IEEE T IMAGE PROCESS, V4, P370, DOI 10.1109/83.366472
   Zafar I, 2007, PROC SPIE, V6496, DOI 10.1117/12.704592
   Zhang BL, 2013, IEEE T INTELL TRANSP, V14, P322, DOI 10.1109/TITS.2012.2213814
NR 51
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 23
PY 2023
DI 10.1007/s11042-023-15081-x
EA MAY 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G9PS3
UT WOS:000992395000001
OA hybrid
DA 2024-07-18
ER

PT J
AU Sesli, E
AF Sesli, Erhan
TI Human-Robot Interaction (HRI) through hand gestures for possible future
   war robots: A leap motion controller application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Human-robot interaction; Cumulative distribution function; Deep neural
   network; Leap motion controller; Hand gesture recognition
ID DENSITY
AB In this article, the futuristically possible human (commander)-robot (soldier) interaction (HRI) based on effective hand gesture recognition is discussed. As methodologically, Leap Motion Controller (LMC), which is frequently used in virtual reality applications, was used to obtain hand gesture features. Only the relevant distance of the fingers to each other and to the normal of the hand is considered as a feature and high performance is questioned under these constraints. Then performances of six hand gesture recognition methods, classified as light, medium weight, and complex, were examined with random dynamic movements and in different frame numbers. The performance of the proposed cumulative distribution function (CDF) based deep neural network (DNN) approach has achieved an accuracy of 88.44%. With this result, an improvement of 4.76% has been achieved compared to the second closest method, Kullback Leibler Divergence, by using the proposed method. Although limited features, high performance has been achieved. There is no mechanical or electronic robot design in the study; however, the computer used as the decision mechanism of the robot was modeled and made ready for application. In this sense, we believe wholeheartedly that in the future, this work can be a pioneer study in the military field.
C1 [Sesli, Erhan] Karadeniz Tech Univ, Technol Fac, Dept Elect & Telecommun Engn, TR-61080 Trabzon, Turkiye.
C3 Karadeniz Technical University
RP Sesli, E (corresponding author), Karadeniz Tech Univ, Technol Fac, Dept Elect & Telecommun Engn, TR-61080 Trabzon, Turkiye.
EM erhansesli@ktu.edu.tr
RI Sesli, Erhan/L-6234-2017
OI Sesli, Erhan/0000-0002-0039-2927
CR Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   Ahn HJ, 2008, INFORM SCIENCES, V178, P37, DOI 10.1016/j.ins.2007.07.024
   [Anonymous], 2023, MILITARY HAND SIGNAL
   Antillon DWO, 2023, IEEE T NEUR NET LEAR, V34, P9874, DOI 10.1109/TNNLS.2022.3161682
   Bechtel MG, 2018, 2018 IEEE 24TH INTERNATIONAL CONFERENCE ON EMBEDDED AND REAL-TIME COMPUTING SYSTEMS AND APPLICATIONS (RTCSA), P11, DOI 10.1109/RTCSA.2018.00011
   Bird JJ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185151
   Bistron M, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10070871
   Budiharto Widodo, 2020, ICIC Express Letters, V14, P83, DOI 10.24507/icicel.14.03.289
   Butt AH, 2018, BIOMED ENG ONLINE, V17, DOI 10.1186/s12938-018-0600-7
   Chen C, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION ENGINEERING (ICRAE), P48, DOI 10.1109/ICRAE.2017.8291351
   Chen LF, 2020, IEEE T FUZZY SYST, V28, P1252, DOI 10.1109/TFUZZ.2020.2966167
   Choi B, 2019, J FIELD ROBOT, V36, P656, DOI 10.1002/rob.21843
   Chong TW, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103554
   Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822
   Fang YF, 2023, INT J MACH LEARN CYB, V14, P1119, DOI 10.1007/s13042-022-01687-4
   Galán JJ, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10091397
   Ghouse Z., 2017, INT RES J ENG TECHNO, V4, P1767
   Hu B, 2020, INT J AUTOM COMPUT, V17, P17, DOI 10.1007/s11633-019-1194-7
   Ibe O., 2014, Fundamentals of Applied Probability and Random Processes
   Ismail Rakshana, 2021, Intelligent Manufacturing and Energy Sustainability. Proceedings of ICIMES 2020. Smart Innovation, Systems and Technologies (SIST 213), P637, DOI 10.1007/978-981-33-4443-3_61
   Jain R, 2022, VISUAL COMPUT, V38, P1957, DOI 10.1007/s00371-021-02259-3
   Jiang D, 2019, MULTIMED TOOLS APPL, V78, P29953, DOI 10.1007/s11042-018-6748-0
   Joudaki S., 2022, Int. J. Comput. Vis. Robot, V12, P1, DOI [10.1504/IJCVR.2022.119239, DOI 10.1504/IJCVR.2022.119239]
   Khaleghi Leyla, 2022, IEEE Internet of Things Magazine, V5, P54, DOI 10.1109/IOTM.002.2200022
   Lee AR, 2020, COMPUT METH PROG BIO, V190, DOI 10.1016/j.cmpb.2020.105385
   Mies G., 2010, Atlantic Association for Research in the Mathematical Sciences (AARMS), V9, P125
   Minu MS., 2020, INT J ADV SCI TECHNO, V29, P5485
   Mittal A, 2019, IEEE SENS J, V19, P7056, DOI 10.1109/JSEN.2019.2909837
   Pasquini C, 2020, EURASIP J INF SECUR, V2020, DOI 10.1186/s13635-020-00104-z
   Plawiak P, 2016, IEEE T IND INFORM, V12, P1104, DOI 10.1109/TII.2016.2550528
   Poularakis S, 2016, IEEE T CYBERNETICS, V46, P2094, DOI 10.1109/TCYB.2015.2464195
   Qi W, 2022, T I MEAS CONTROL, V44, P735, DOI 10.1177/0142331220984350
   Rawat R., 2021, Machine Learning for Robotics Applications, P107, DOI [10.1007/978-981-16-0598-7_9, DOI 10.1007/978-981-16-0598-7_9]
   Reinschmidt E, 2022, IEEE SENSOR, DOI 10.1109/SENSORS52175.2022.9967346
   Salman A, 2020, ICES J MAR SCI, V77, P1295, DOI 10.1093/icesjms/fsz025
   Sanaullah M., 2022, NDC E J, V2, P123
   Sankaran PG, 2016, STAT PROBABIL LETT, V111, P72, DOI 10.1016/j.spl.2016.01.007
   Sapaty Peter Simon, 2015, International Journal of Advanced Research in Artificial Intelligence, V4, P9
   Sharma S, 2017, Towards Data Sci, V6, P310, DOI [DOI 10.33564/IJEAST.2020.V04I12.054, 10.33564/IJEAST.2020.v04i12.054]
   Tan PC, 2022, ADV MATER, V34, DOI 10.1002/adma.202200793
   Tao W, 2018, P 2018 I IND SYST EN
   Usha MNS., 2017, INT J ADV ENG RES SC, V4, P49, DOI [10.22161/ijaers.4.2.10, DOI 10.22161/IJAERS.4.2.10]
   Vaitkevicius A, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9030445
   Vedhapriyavadhana R., 2018, INDO IRANIAN J SCI R, V2, P121
   Wang M, 2020, EUR J NUCL MED MOL I, V47, P2753, DOI 10.1007/s00259-020-04814-x
   Wang W, 2016, SIGNAL PROCESS, V126, P12, DOI 10.1016/j.sigpro.2016.01.008
   Wen R, 2014, COMPUT METH PROG BIO, V116, P68, DOI 10.1016/j.cmpb.2013.12.018
   Yasen M., 2019, PEERJ COMPUT SCI, V2019, P1
   Yi-Leh Wu, 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, P488
   Young S, 2016, Arxiv, DOI arXiv:1606.01288
   Zhang WD, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22062349
NR 51
TC 0
Z9 0
U1 7
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 17
PY 2023
DI 10.1007/s11042-023-15278-0
EA MAY 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G7EQ1
UT WOS:000990751100012
DA 2024-07-18
ER

PT J
AU Sabeena, M
   Abraham, L
AF Sabeena, M.
   Abraham, Lizy
TI Convolutional block attention based network for copy-move image forgery
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Copy-move forgery localization; Convolutional Block Attention Module;
   Atrous Spatial Pyramid Pooling; Neural network training; Performance
   evaluation
AB Computer-generated picture forgery is a growing problem due to the development of easily available technology that makes the forging procedure very simple. In response, numerous methods have evolved for detecting computer-generated forgeries. This paper introduces a new AI algorithm using the deep learning concept for advanced copy-move image counterfeit detection and localization. In this work, feature extraction, segmentation of the image, and localizing the area of forgery in an image have been performed using the Convolutional Block Attention Module (CBAM). Specifically, spatial and channel attention features are fused by the convolution block attention mechanism to fully capture context information, and enrich the representation of features. Furthermore, deep matching is used to compute feature map self-correlation, and Atrous Spatial Pyramid Pooling (ASPP) is used to fuse the scaled correlation maps to construct the coarse mask. Finally, bilinear upsampling is done to resize the predicted output to the same size as the original image. The CoMoFoD dataset is used for conducting and checking the effectiveness of the proposed work. Various performance analyses conducted on the proposed work demonstrate that CBAM has superior performance for forgery detection and localization than several state-of- the-art methods and has high strength in post-processing operations, such as noise addition, noise blur, brightness change, colour reduction, and JPEG recompression.
C1 [Sabeena, M.; Abraham, Lizy] LBS Inst Technol Women, Dept Elect & Commun Engn, Thiruvananthapuram 695012, Kerala, India.
   [Sabeena, M.] Coll Engn, Attingal 695101, Kerala, India.
   [Sabeena, M.; Abraham, Lizy] APJ Abdul Kalam Technol Univ, Thiruvananthapuram 695016, Kerala, India.
C3 LBS Institute of Technology for Women
RP Sabeena, M (corresponding author), LBS Inst Technol Women, Dept Elect & Commun Engn, Thiruvananthapuram 695012, Kerala, India.; Sabeena, M (corresponding author), Coll Engn, Attingal 695101, Kerala, India.; Sabeena, M (corresponding author), APJ Abdul Kalam Technol Univ, Thiruvananthapuram 695016, Kerala, India.
EM sabeena.tvm@gmail.com; lizyabraham@lbsitw.ac.in
CR Abdalla Y, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11101280
   Agarwal R, 2020, MULTIMED TOOLS APPL, V79, P7355, DOI 10.1007/s11042-019-08495-z
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Bappy JH, 2019, IEEE T IMAGE PROCESS, V28, P3286, DOI 10.1109/TIP.2019.2895466
   Bi XL, 2019, IEEE COMPUT SOC CONF, P30, DOI 10.1109/CVPRW.2019.00010
   Chen L.Z, 2017, CORR ABS170605587
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Costanzo A, 2014, IEEE T INF FOREN SEC, V9, P1450, DOI 10.1109/TIFS.2014.2337654
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Doegar A., 2019, Int. J. Comput. Intell. IoT
   Elaskily MA, 2020, MULTIMED TOOLS APPL, V79, P19167, DOI 10.1007/s11042-020-08751-7
   Goel N., 2020, DUAL BRANCH CONVOLUT
   He KM, 2016, Arxiv, DOI arXiv:1603.05027
   Huang DY, 2017, MULTIMED TOOLS APPL, V76, P1509, DOI 10.1007/s11042-015-3152-x
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu XH, 2021, Arxiv, DOI arXiv:2103.10596
   Liu YQ, 2020, Arxiv, DOI arXiv:2012.08697
   Liu YQ, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P85, DOI 10.1145/3206004.3206010
   Mahmood T, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/8713202
   Muhammad G, 2012, DIGIT INVEST, V9, P49, DOI 10.1016/j.diin.2012.04.004
   Ouyang JL, 2017, 2017 10TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI)
   Rao Y, 2020, IEEE ACCESS, V8, P25611, DOI 10.1109/ACCESS.2020.2970735
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Shi ZN, 2020, IEEE SIGNAL PROC LET, V27, P1755, DOI 10.1109/LSP.2020.3026954
   Shivakumar B., 2011, Int J Comput Sci Issues (IJCSI), V8, P199
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Su LC, 2018, IEEE T MULTIMEDIA, V20, P825, DOI 10.1109/TMM.2017.2760098
   Thakur A, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P451, DOI 10.1109/ICSCCC.2018.8703287
   Thakur Rahul, 2019, 2019 2nd International Conference on Power Energy, Environment and Intelligent Control (PEEIC), P561, DOI 10.1109/PEEIC47157.2019.8976868
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Wang XY, 2019, MATH BIOSCI ENG, V16, P4581, DOI 10.3934/mbe.2019229
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu Y, 2018, LECT NOTES COMPUT SC, V11210, P170, DOI 10.1007/978-3-030-01231-1_11
   Wu Y, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1480, DOI 10.1145/3123266.3123411
   Yang C, 2020, Arxiv, DOI arXiv:1911.08217
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang Y, 2016, CRYPTOL INF SEC SER, V14, P1, DOI 10.3233/978-1-61499-617-0-1
   Zhong JL, 2016, NONLINEAR DYNAM, V84, P189, DOI 10.1007/s11071-015-2374-9
   Zhu Y, 2020, IEEE T IND INFORM, V16, P6714, DOI 10.1109/TII.2020.2982705
   Zhu Y, 2016, MULTIMED TOOLS APPL, V75, P3221, DOI 10.1007/s11042-014-2431-2
NR 41
TC 2
Z9 2
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 13
PY 2023
DI 10.1007/s11042-023-15649-7
EA MAY 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G3ZM6
UT WOS:000988577200002
DA 2024-07-18
ER

PT J
AU Mohsen, S
AF Mohsen, Saeed
TI Recognition of human activity using GRU deep learning algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Gated recurrent unit (GRU); Human activity recognition
   (HAR); Artificial intelligence (AI)
ID CONVOLUTIONAL NEURAL-NETWORKS; HEALTH; MODEL
AB Human activity recognition (HAR) is a challenging issue in several fields, such as medical diagnosis. Recent advances in the accuracy of deep learning have contributed to solving the HAR issues. Thus, it is necessary to implement deep learning algorithms that have high performance and greater accuracy. In this paper, a gated recurrent unit (GRU) algorithm is proposed to classify human activities. This algorithm is applied to the Wireless Sensor Data Mining (WISDM) dataset gathered from many individuals with six classes of various activities - walking, sitting, downstairs, jogging, standing, and upstairs. The proposed algorithm is tested and trained via a hyper-parameter tuning method with TensorFlow framework to achieve high accuracy. Experiments are conducted to evaluate the performance of the GRU algorithm using receiver operating characteristic (ROC) curves and confusion matrices. The results demonstrate that the GRU algorithm provides high performance in the recognition of human activities. The GRU algorithm achieves a testing accuracy of 97.08%. The rate of testing loss for the GRU is 0.221, while the precision, sensitivity, and F1-score for the GRU are 97.11%, 97.09%, and 97.10%, respectively. Experimentally, the area under the ROC curves (AUC(S)) is 100%.
C1 [Mohsen, Saeed] Al Madinah Higher Inst Engn & Technol, Dept Elect & Commun Engn, Giza 12947, Egypt.
   [Mohsen, Saeed] King Salman Int Univ KSIU, Fac Comp Sci & Engn, Dept Artificial Intelligence Engn, South Sinai 46511, Egypt.
C3 King Salman International University
RP Mohsen, S (corresponding author), Al Madinah Higher Inst Engn & Technol, Dept Elect & Commun Engn, Giza 12947, Egypt.; Mohsen, S (corresponding author), King Salman Int Univ KSIU, Fac Comp Sci & Engn, Dept Artificial Intelligence Engn, South Sinai 46511, Egypt.
EM g17082131@eng.asu.edu.eg
RI Mohsen, Saeed/GQH-2016-2022
OI Mohsen, Saeed/0000-0003-2863-0074
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Abu Alsheikh M, 2016, IEEE NETWORK, V30, P22, DOI 10.1109/MNET.2016.7474340
   Agarwal P, 2020, PROCEDIA COMPUT SCI, V167, P2364, DOI 10.1016/j.procs.2020.03.289
   Alani AA, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207697
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Alzantot Moustafa, 2017, 2017 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops), P188, DOI 10.1109/PERCOMW.2017.7917555
   Anguita D., 2020, PUBLIC DOMAIN DATASE, V20
   Antunes RS, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3177852
   Bulling A, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2499621
   Chavarriaga R, 2013, PATTERN RECOGN LETT, V34, P2033, DOI 10.1016/j.patrec.2012.12.014
   Chen YW, 2016, ADV INTEL SYS RES, V127
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Chu AK, 2019, SECUR COMMUN NETW, V2019, DOI 10.1155/2019/6757685
   Cipolla E, 2017, LECT NOTES COMPUT SC, V10484, P435, DOI 10.1007/978-3-319-68560-1_39
   cis, 2012, WIR SENS DAT MIN DAT
   Cruciani F, 2020, CCF T PERVAS COMPUT, V2, P18, DOI 10.1007/s42486-020-00026-2
   Demrozi F, 2020, IEEE J BIOMED HEALTH, V24, P2444, DOI 10.1109/JBHI.2019.2952618
   Dos Santos C., 2014, Coling, P69
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Hammerla N.Y., 2016, P 25 INT JOINT C ART
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hong JH, 2016, IEEE T HUM-MACH SYST, V46, P101, DOI 10.1109/THMS.2015.2489688
   Hsu YL, 2019, IEEE ACCESS, V7, P170199, DOI 10.1109/ACCESS.2019.2955545
   Huang JH, 2020, IEEE J BIOMED HEALTH, V24, P292, DOI 10.1109/JBHI.2019.2909688
   Ignatov A, 2018, APPL SOFT COMPUT, V62, P915, DOI 10.1016/j.asoc.2017.09.027
   Igual R, 2015, MED ENG PHYS, V37, P870, DOI 10.1016/j.medengphy.2015.06.009
   Jia PF, 2014, INT CONF BIG DATA, P217, DOI 10.1109/BIGCOMP.2014.6741439
   Khorram A, 2021, APPL INTELL, V51, P736, DOI 10.1007/s10489-020-01859-1
   Kingma D. P., 2014, arXiv
   Klosowski P, 2018, SIG P ALGO ARCH ARR, P223, DOI 10.23919/SPA.2018.8563389
   Kwapisz JR., 2011, ACM SIGKDD EXPLORATI, V12, P74, DOI [DOI 10.1145/1964897.1964918, 10.1145/1964897.1964918]
   Lattanzi E, 2020, ENG APPL ARTIF INTEL, V94, DOI 10.1016/j.engappai.2020.103812
   Lawal IA, 2020, IEEE ACCESS, V8, P155060, DOI 10.1109/ACCESS.2020.3017681
   Malaise A., 2018, P 11 INT C ADV COMP, P1
   Malhotra P., 2015, ESANN, V89, P89
   Mekruksavanich S, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12091570
   Mohsen S, 2022, SMART INNOV SYST TEC, V262, P304, DOI 10.1007/978-981-16-6128-0_29
   Mohsen S, 2021, IEEE ACCESS, V9, P150508, DOI 10.1109/ACCESS.2021.3125733
   Ordóñez FJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010115
   Pienaar SW, 2019, 2019 IEEE 2ND WIRELESS AFRICA CONFERENCE (WAC), P80, DOI [10.1109/africa.2019.8843403, 10.1109/africa.2019.8843417]
   Qiu S, 2022, INFORM FUSION, V80, P241, DOI 10.1016/j.inffus.2021.11.006
   Ronao CA, 2016, EXPERT SYST APPL, V59, P235, DOI 10.1016/j.eswa.2016.04.032
   Ronao CA, 2015, LECT NOTES COMPUT SC, V9492, P46, DOI 10.1007/978-3-319-26561-2_6
   Shakeel M, 2021, APPL INTELL, V51, P8305, DOI 10.1007/s10489-021-02285-7
   Shakya Sarbagya Ratna, 2018, International Journal of Machine Learning and Computing, V8, P577, DOI 10.18178/ijmlc.2018.8.6.748
   Shoaib M, 2015, SENSORS-BASEL, V15, P2059, DOI 10.3390/s150102059
   Stiefmeier T, 2008, IEEE PERVAS COMPUT, V7, P42, DOI 10.1109/MPRV.2008.40
   Stisen A, 2015, SENSYS'15: PROCEEDINGS OF THE 13TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P127, DOI 10.1145/2809695.2809718
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tanberk S, 2020, IEEE ACCESS, V8, P19799, DOI 10.1109/ACCESS.2020.2968529
   Tao WJ, 2020, ENG APPL ARTIF INTEL, V95, DOI 10.1016/j.engappai.2020.103868
   Twomey N, 2016, SPHERE CHALLENGE ACT, P1
   Verma S., 2019, UNDERSTANDING INPUT, V10, P2020
   Vinayakumar R, 2019, IEEE ACCESS, V7, P41525, DOI 10.1109/ACCESS.2019.2895334
   Wang JD, 2019, PATTERN RECOGN LETT, V119, P3, DOI 10.1016/j.patrec.2018.02.010
   Wang Y, 2019, EXPERT SYST APPL, V137, P167, DOI 10.1016/j.eswa.2019.04.057
   Xia K, 2020, IEEE ACCESS, V8, P56855, DOI 10.1109/ACCESS.2020.2982225
   Xiong J, 2019, INT WIREL COMMUN, P1737, DOI 10.1109/iwcmc.2019.8766500
   Xu WC, 2018, INT C PATT RECOG, P165, DOI 10.1109/ICPR.2018.8545435
   Yu D, 2015, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-4471-5779-3
   Yuming Cheng, 2019, 2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS). Proceedings, P1249, DOI 10.1109/HPCC/SmartCity/DSS.2019.00175
   Zhang CY, 2021, INT J COMPUT INTEG M, V34, P709, DOI 10.1080/0951192X.2019.1699256
   Zhang Y., 2015, arXiv
   Zhao R, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17020273
NR 66
TC 6
Z9 6
U1 5
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47733
EP 47749
DI 10.1007/s11042-023-15571-y
EA MAY 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000986851800005
OA hybrid
DA 2024-07-18
ER

PT J
AU Xu, T
   Zhao, WS
   Chai, HJ
   Cai, L
AF Xu, Tao
   Zhao, Weishuo
   Chai, Haojie
   Cai, Lei
TI Dual-stream encoded fusion saliency detection based on RGB and grayscale
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency detection; Dual-stream encoding; Multi-level integration; Gray
   image; Hybrid weighted loss
ID OBJECT DETECTION; OPTIMIZATION; FEATURES
AB Existing saliency algorithms based on deep learning are not sufficient to extract features of images. And the features are fused only during decoding. As a result, the edge of saliency detection result is not clear and the internal structure display is not uniform. To solve the above problems, this paper proposes a saliency detection method of dual-stream encoding fusion based on RGB and grayscale image. Firstly, an interactive dual-stream encoder is constructed to extract the feature information of gray stream and RGB stream. Secondly, a multi-level fusion strategy is used to obtain more effective multi-scale features. These features are extended and optimized in the decoding stage by linear transformation with hybrid attention. Finally, We propose a hybrid weighted loss function. So that the prediction results of the model can keep a high level accuracy at pixel level and region level. The experimental results of the model proposed to this paper on 6 public datasets illustrate that: The prediction results of the proposed method are clearer about the edge of salient targets and more uniform within salient targets. And has a more lightweight model size.
C1 [Xu, Tao; Chai, Haojie; Cai, Lei] Henan Inst Sci & Technol, Sch Artificial Intelligence, Xinxiang 453003, Henan, Peoples R China.
   [Zhao, Weishuo] Henan Inst Sci & Technol, Sch Informat Engn, Xinxiang 453003, Henan, Peoples R China.
C3 Henan Institute of Science & Technology; Henan Institute of Science &
   Technology
RP Xu, T (corresponding author), Henan Inst Sci & Technol, Sch Artificial Intelligence, Xinxiang 453003, Henan, Peoples R China.
EM xutao1206@qq.com; zhaoweishuo91@126.com; nefuchj@163.com;
   cailei2014@126.com
RI chai, haojie/KHT-1817-2024
OI Xu, Tao/0000-0002-8821-4550
FU Major Science and Technology Project in Henan Province [221100110500];
   Science and Technology Project of Henan Province [222102320380,
   222102110194, 212102210161]; National Key Research and Development
   Project [2019YFB1311000]
FX AcknowledgmentsThis work was supported by the Major Science and
   Technology Project in Henan Province [221100110500], Science and
   Technology Project of Henan Province [222102320380, 222102110194,
   212102210161], the National Key Research and Development Project
   [2019YFB1311000].
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Chen H, 2018, PROC CVPR IEEE, P3051, DOI 10.1109/CVPR.2018.00322
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Cheng X, 2014, CIRC SYST SIGNAL PR, V33, P1507, DOI 10.1007/s00034-013-9713-1
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   Elder, 2010, P IEEE C COMP VIS PA, P49, DOI [10.1109/CVPRW.2010.5543739, DOI 10.1109/CVPRW.2010.5543739]
   Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406
   Feng G, 2022, PATTERN RECOGN, V128, DOI 10.1016/j.patcog.2022.108666
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   Feng XL, 2022, PATTERN RECOGN LETT, V162, P81, DOI 10.1016/j.patrec.2022.09.004
   Gao Y, 2015, IEEE T MULTIMEDIA, V17, P359, DOI 10.1109/TMM.2015.2389616
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Golner MA, 2002, CIRC SYST SIGNAL PR, V21, P163, DOI 10.1007/s00034-002-2004-x
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Jerripothula KR, 2016, IMAGE CO SEGMENTATIO
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78
   Li GB, 2017, PROC CVPR IEEE, P247, DOI 10.1109/CVPR.2017.34
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu J, 2022, DIGIT SIGNAL PROCESS, V126, DOI 10.1016/j.dsp.2022.103425
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Liu Z, 2012, IEEE T MULTIMEDIA, V14, P1275, DOI 10.1109/TMM.2012.2190385
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo ZM, 2017, PROC CVPR IEEE, P6593, DOI 10.1109/CVPR.2017.698
   Mahadevan V, 2009, PROC CVPR IEEE, P1007, DOI 10.1109/CVPRW.2009.5206573
   Mu X, 2019, CIRC SYST SIGNAL PR, V39
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5
   Qin XB, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107404
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Qu LQ, 2017, IEEE T IMAGE PROCESS, V26, P2274, DOI 10.1109/TIP.2017.2682981
   Ren JY, 2022, COGN COMPUT, V14, P794, DOI 10.1007/s12559-021-09952-4
   Ren ZX, 2014, IEEE T CIRC SYST VID, V24, P769, DOI 10.1109/TCSVT.2013.2280096
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rutishauser U., 2004, P IEEE COMP SOC C CO, DOI DOI 10.1109/CVPR.2004.1315142
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang TT, 2018, PROC CVPR IEEE, P3127, DOI 10.1109/CVPR.2018.00330
   Wang XQ, 2022, IEEE T IMAGE PROCESS, V31, P1107, DOI 10.1109/TIP.2021.3139232
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wu RM, 2019, PROC CVPR IEEE, P8142, DOI 10.1109/CVPR.2019.00834
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Youwei Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9410, DOI 10.1109/CVPR42600.2020.00943
   Zhang H, 2022, IEEE COMPUT SOC CONF, P2735, DOI 10.1109/CVPRW56347.2022.00309
   Zhang J., 2020, P IEEE CVF C COMP VI, P8579, DOI DOI 10.1109/CVPR42600.2020.00861
   Zhang J, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4318, DOI 10.1109/ICCV48922.2021.00430
   Zhang YY, 2016, CIRC SYST SIGNAL PR
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhou H., 2020, P IEEE C COMP VIS PA, P9141, DOI 10.1109/CVPR42600.2020.00916
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 57
TC 0
Z9 0
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47327
EP 47346
DI 10.1007/s11042-023-15217-z
EA MAY 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000985452800015
DA 2024-07-18
ER

PT J
AU Srivastava, A
   Mishra, PK
AF Srivastava, Ankita
   Mishra, Pramod Kumar
TI Energy efficient clustering using modified PROMETHEE-II and AHP approach
   in wireless sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Clustering; Cluster head selection; Efficient energy; WSN; IoT; MADM
   method; Network lifetime
ID LEACH PROTOCOL; ARCHITECTURE; HYBRID; HEED; IOT
AB In wireless sensor networks (WSNs), sensor nodes were considered to be an integral part of IoT (Internet of Things) for sensing and monitoring the environment. The IoT-based applications need to be optimized regarding the changing requirements of users as everything is connected via the internet. In today's era, where every day new technologies were rebuilt where sensor nodes plays an important role on it. In every field, whether it is healthcare, smart agriculture, smart home appliances, smart traffic, or smart city sensors were deployed for sensing their environment, collecting data from them, and forwarding it to the servers. These sensor nodes were made up of non-rechargeable power batteries, as a fact efficient energy consumption of these batteries becomes vital. In WSN, efficient energy consumption is still an issue, and its solutions were given by many researchers among them, clustering is considered to be more effective in this domain. For efficient energy consumption, multi-attributes of cluster head selection need to be considered and proper coordination among the conflicting nature of multi-attributes needs to be done. In this paper, we have proposed PROMETHEE II and modified AHP together for cluster heads selection by considering multi-attributes. Twenty-one attributes were considered including connectivity, distance to the base station, residual energy, member nodes, and many more. Being conflicting in nature, proper coordination among these attributes has been done and optimal cluster heads were selected modified for data transmissions. In this paper, modified AHP has been compared with our proposed modified PROMETHEE II and AHP for understanding the significance of this integration. Results is evaluated in terms of energy consumption, network lifetime, and load balancing and it also validate that our proposed approach outperforms with modified AHP and other existing algorithms. Our proposed algorithm enriches network lifetime by balancing the load among sensor nodes which leads to efficient energy consumption.
C1 [Srivastava, Ankita; Mishra, Pramod Kumar] Banaras Hindu Univ, Inst Sci, Dept Comp Sci, Varanasi, India.
C3 Banaras Hindu University (BHU)
RP Mishra, PK (corresponding author), Banaras Hindu Univ, Inst Sci, Dept Comp Sci, Varanasi, India.
EM ankita1490@gmail.com; mishra@bhu.ac.in
OI Mishra, Prof P K/0000-0003-3957-1161
CR Abbasi AA, 2007, COMPUT COMMUN, V30, P2826, DOI 10.1016/j.comcom.2007.05.024
   Akyildiz IF, 2002, COMPUT NETW, V38, P393, DOI 10.1016/S1389-1286(01)00302-4
   Al Sibahee MA, 2016, 2016 INTERNATIONAL CONFERENCE ON NETWORK AND INFORMATION SYSTEMS FOR COMPUTERS (ICNISC), P36, DOI [10.1109/ICNISC.2016.59, 10.1109/ICNISC.2016.018]
   Ali H, 2021, IEEE SYST J, V15, P2386, DOI 10.1109/JSYST.2020.2986811
   Behera TM, 2018, IET WIREL SENS SYST, V8, P223, DOI 10.1049/iet-wss.2017.0099
   Bharany S, 2021, ENERGIES, V14, DOI 10.3390/en14196016
   Daanoune I, 2021, AD HOC NETW, V114, DOI 10.1016/j.adhoc.2020.102409
   Dhingra S, 2021, INTERNET THINGS-NETH, V14, DOI 10.1016/j.iot.2020.100175
   El Khediri S, 2014, PROCEDIA COMPUT SCI, V32, P1180, DOI 10.1016/j.procs.2014.05.551
   Hassan AAH, 2020, IEEE ACCESS, V8, P200500, DOI 10.1109/ACCESS.2020.3035624
   Heinzelman WB, 2002, IEEE T WIREL COMMUN, V1, P660, DOI 10.1109/TWC.2002.804190
   Kalaimani Deepa, 2021, Australian Journal of Multi-Disciplinary Engineering, V17, P23, DOI 10.1080/14488388.2020.1811454
   Kalburgi SS, 2022, MULTIMED TOOLS APPL, V81, P15815, DOI 10.1007/s11042-022-12302-7
   Kathiroli P, 2022, J KING SAUD UNIV-COM, V34, P8564, DOI 10.1016/j.jksuci.2021.08.031
   Ketu S, 2021, J NETW COMPUT APPL, V192, DOI 10.1016/j.jnca.2021.103179
   Ketu S, 2022, IETE TECH REV, V39, P713, DOI 10.1080/02564602.2021.1898482
   Khera S, 2023, MULTIMED TOOLS APPL, V82, P3879, DOI 10.1007/s11042-022-13446-2
   Kumar A, 2022, SUSTAIN ENERGY TECHN, V52, DOI 10.1016/j.seta.2022.102243
   Li H, 2013, COMPUT COMMUN, V36, P256, DOI 10.1016/j.comcom.2012.10.006
   Liang HB, 2019, EURASIP J WIREL COMM, DOI 10.1186/s13638-019-1509-y
   Madhu S, 2022, WIRELESS PERS COMMUN, V122, P1967, DOI 10.1007/s11277-021-08976-1
   Mehta D, 2022, MULTIMED TOOLS APPL, V81, P35083, DOI 10.1007/s11042-020-09633-8
   PATIL NS, 2022, PHYS REV D, P1
   Pitchaimanickam B, 2020, NEURAL COMPUT APPL, V32, P7709, DOI 10.1007/s00521-019-04441-0
   Prasad RK, 2021, WIREL NETW, V27, P4111, DOI 10.1007/s11276-021-02710-2
   Priyanka BN, 2022, WIRELESS PERS COMMUN, V123, P1467, DOI 10.1007/s11277-021-09192-7
   Raghavendra YM, 2021, WIRELESS PERS COMMUN, V119, P1009, DOI 10.1007/s11277-021-08247-z
   Rajpoot Prince, 2021, IOP Conference Series: Materials Science and Engineering, V1020, DOI 10.1088/1757-899X/1020/1/012003
   Rajpoot P, 2019, WIRELESS PERS COMMUN, V106, P829, DOI 10.1007/s11277-019-06192-6
   Rathore PS, 2021, J SUPERCOMPUT, V77, P7649, DOI 10.1007/s11227-020-03593-4
   Rawat P, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100396
   Russo RDSM, 2015, PROCEDIA COMPUT SCI, V55, P1123, DOI 10.1016/j.procs.2015.07.081
   Sah DK, 2020, INFORM FUSION, V63, P223, DOI 10.1016/j.inffus.2020.07.005
   Saxena M, 2021, WIRELESS PERS COMMUN, V118, P2505, DOI 10.1007/s11277-021-08140-9
   Shahraki Amin, 2021, IEEE Transactions on Network and Service Management, V18, P2242, DOI 10.1109/TNSM.2020.3035315
   Shahraki A, 2020, COMPUT NETW, V180, DOI 10.1016/j.comnet.2020.107376
   Sharma R, 2020, TELECOMMUN SYST, V74, P253, DOI 10.1007/s11235-020-00654-0
   Sheriba ST, 2021, TELECOMMUN SYST, V77, P213, DOI 10.1007/s11235-021-00751-8
   Shi S, 2012, 2012 7TH INTERNATIONAL ICST CONFERENCE ON COMMUNICATIONS AND NETWORKING IN CHINA (CHINACOM), P487, DOI 10.1109/ChinaCom.2012.6417532
   Singh S, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114264
   Srivastava A, 2021, WIRELESS PERS COMMUN, V121, P745, DOI 10.1007/s11277-021-08659-x
   Tyagi S, 2013, J NETW COMPUT APPL, V36, P623, DOI 10.1016/j.jnca.2012.12.001
   Ullah Z, 2020, WIRELESS PERS COMMUN, V112, P2685, DOI 10.1007/s11277-020-07170-z
   VenkTraman S., 2018, EURASIP J WIREL COMM, V2018, P1
   Quy VK, 2022, COMPLEX INTELL SYST, V8, P3805, DOI 10.1007/s40747-021-00582-9
   Yadav RK, 2022, PERVASIVE MOB COMPUT, V79, DOI 10.1016/j.pmcj.2021.101504
   Younis O, 2004, IEEE T MOBILE COMPUT, V3, P366, DOI 10.1109/TMC.2004.41
NR 47
TC 2
Z9 2
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47049
EP 47080
DI 10.1007/s11042-023-15378-x
EA MAY 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000981387900010
DA 2024-07-18
ER

PT J
AU Sundar, K
   Sasikumar, S
   Jayakumar, C
   Nagarajan, D
   Karthick, S
AF Sundar, K.
   Sasikumar, S.
   Jayakumar, C.
   Nagarajan, D.
   Karthick, S.
TI Quantum cryptography based cloud security model (QC-CSM) for ensuring
   cloud data security in storage and accessing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data Encryption; Attribute Based Encryption (ABE); Quantum Key
   Distribution Protocol (QKDP); Data security; Confidentiality; Secure key
ID KEY DISTRIBUTION
AB In recent days, cloud computing is a universal computing and conventional paradigm, in which the resources are provided over the Internet based on requirements. With the huge growth of cloud storage and processing, security in Cloud has become the most captivating research domains. Though there are many methods for enhancing security and data confidentiality over cloud, security is the major threat among data owners and users in data storages and data sharing between two parties in Cloud. In data sharing, for assuring security, the data are secured with key and the key is required to be encrypted to keep that not accessible for attacks. With that concern, this work develops a Quantum Cryptography based Cloud Security Model (QC-CSM) that uses Quantum Key Distribution Protocol (QKDP) for sharing the secret key between parties. For ensuring the data owner about the security of their share data over Cloud, Attribute Based Encryption (ABE) is used. Further, the data can be accessed by an authenticated user, who is having the access for decryption through the key from a secure quantum channel. The results show that the proposed model outperforms the existing works by providing a more secure environment and confidential data sharing between entities in minimal time in the Cloud framework.
C1 [Sundar, K.] Velammal Engn Coll, Dept Comp Sci, Chennai, India.
   [Sasikumar, S.] Hindustan Inst Technol & Sci, Dept Elect & Commun, Chennai, India.
   [Jayakumar, C.] Sri Venkateswara Coll Engn CSE, Dept Comp Sci, Chennai, India.
   [Nagarajan, D.] Rajalakshmi Inst Technol, Dept Math, Chennai, India.
   [Karthick, S.] Motilal Nehru Natl Inst Technol, Dept Chem Engn, Allahabad, India.
C3 Velammal Engineering College; Hindustan Institute of Technology &
   Science; National Institute of Technology (NIT System); Motilal Nehru
   National Institute of Technology
RP Nagarajan, D (corresponding author), Rajalakshmi Inst Technol, Dept Math, Chennai, India.
EM stephensundarks@gmail.com; drssk75@gmail.com; cjayakumar2007@gmail.com;
   dnrmsu2002@yahoo.com; karthickchem93@gmail.com
RI c, Jayakumar/W-2345-2018; s, sasikumar/AAG-1209-2021;
   DEIVANAYAGAMPILLAI, NAGARAJAN/P-4665-2014
OI s, sasikumar/0000-0001-9732-3268; DEIVANAYAGAMPILLAI,
   NAGARAJAN/0000-0003-1411-532X
CR Alan M., 2009, INT J NETW SECUR APP, V1, P1
   Avesani M, 2021, PHYS REV APPL, V15, DOI 10.1103/PhysRevApplied.15.034034
   Barsoum A. F., 2012, Proceedings of the 2012 12th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGrid 2012), P829, DOI 10.1109/CCGrid.2012.55
   BENNETT CH, 1993, PHYS REV LETT, V70, P1895, DOI 10.1103/PhysRevLett.70.1895
   Bennett CH, 2005, IEEE T INFORM THEORY, V51, P56, DOI 10.1109/TIT.2004.839476
   Bensch S, 2015, INT J COMPUT SCI ENG, V10, P336, DOI 10.1504/IJCSE.2015.070990
   Brassard G, 2001, P C THEORY APPL CRYP, P49
   Broadbent A, 2009, ANN IEEE SYMP FOUND, P517, DOI 10.1109/FOCS.2009.36
   Cotler JS, 2014, QUANTUM INF COMPUT, V14, P1081
   Curty M, 2001, PHYS REV A, V64, DOI 10.1103/PhysRevA.64.062309
   Dianati Mehrdad, 2007, 2007 32nd IEEE Conference on Local Computer Networks, P1025, DOI 10.1109/LCN.2007.107
   Dikaiakos MD, 2009, IEEE INTERNET COMPUT, V13, P10, DOI 10.1109/MIC.2009.103
   Esposito C, 2017, IEEE COMMUN MAG, V55, P102, DOI 10.1109/MCOM.2017.1700089
   Gao F, 2011, IEEE J QUANTUM ELECT, V47, P630, DOI 10.1109/JQE.2011.2107889
   Gorantla MC, 2010, LECT NOTES COMPUT SC, V6168, P300, DOI 10.1007/978-3-642-14081-5_19
   Guihua Z, 2001, QUANTUM KEY DISTRIBU, P1
   Indu I, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P1187, DOI 10.1109/WiSPNET.2016.7566324
   Indu I, 2015, PROCEEDINGS OF THE 2015 IEEE RECENT ADVANCES IN INTELLIGENT COMPUTATIONAL SYSTEMS (RAICS), P406, DOI 10.1109/RAICS.2015.7488450
   Jithin Raj K., 2015, INT J APPL ENG RES, V10, P455
   Kihidis Anastasios, 2010, Proceedings of the 14th Panhellenic Conference on Informatics (PCI 2010), P101, DOI 10.1109/PCI.2010.48
   Langford NK, 2004, PHYS REV LETT, V93, DOI 10.1103/PhysRevLett.93.053601
   Lim CCW, 2013, PHYS REV X, V3, DOI 10.1103/PhysRevX.3.031006
   Liu X, 2004, COMPUTATIONAL INFORM, V3314, DOI [10.1007/978-3-540-30497-5_162, DOI 10.1007/978-3-540-30497-5_162]
   Liu XF, 2013, IEEE T PARALL DISTR, V24, P1182, DOI 10.1109/TPDS.2012.331
   Mosca M, 2013, LECT NOTES COMPUT SC, V7932, P136, DOI 10.1007/978-3-642-38616-9_9
   Peres A, 2022, QUANTUM THEORY CONCE, V57
   Pinnell J, 2020, LASER PHOTONICS REV, V14, DOI 10.1002/lpor.202000012
   Premarathne U, 2016, IEEE CLOUD COMPUT, V3, P58, DOI 10.1109/MCC.2016.76
   Shaik S, 2016, INT J EMERG TECHNOL, V23, P61
   Shen J, 2017, IEEE T DEPEND SEC CO, VPP
   Shi BS, 2001, PHYS LETT A, V281, P83, DOI 10.1016/S0375-9601(01)00129-3
   Shih HC, 2009, IEEE J SEL TOP QUANT, V15, P1602, DOI 10.1109/JSTQE.2009.2019617
   Sundar DS, 2019, LASER PHYS, V29, DOI 10.1088/1555-6611/ab1413
   Sundar K, 2022, QUANTUM INF PROCESS, V21, DOI 10.1007/s11128-022-03452-6
   Terhal BM, 2001, PHYS REV LETT, V86, P5807, DOI 10.1103/PhysRevLett.86.5807
   THANGAPANDIYAN M, 2016, 2016 IEEE INT C COMP, P1
   Wang C, 2010, COMMUN THEOR PHYS, V53, P67, DOI 10.1088/0253-6102/53/1/15
   Xu H, 2009, AGENT ORIENTED NOVEL, P426
   Zeng GH, 2002, PHYS REV A, V65, DOI 10.1103/PhysRevA.65.042312
   Zhang DX, 2007, ICNC 2007: THIRD INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 4, PROCEEDINGS, P608
NR 40
TC 2
Z9 2
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42817
EP 42832
DI 10.1007/s11042-023-15463-1
EA APR 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000977223400002
DA 2024-07-18
ER

PT J
AU Al Dujaili, MJ
   Ebrahimi-Moghadam, A
AF Al Dujaili, Mohammed Jawad
   Ebrahimi-Moghadam, Abbas
TI Automatic speech emotion recognition based on hybrid features with ANN,
   LDA and K_NN classifiers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech emotion recognition (SER); MFCC; Jitter; Shimmer; PCA; ANN; LDA;
   K_NN
ID MODELS
AB Despite many efforts in Speech Emotion Recognition, there is still a big gap between natural human feelings and computer perception. In this article, the recognition of the speaker's emotions in Persian and German has been examined. For this purpose, Persian emotional speech utterances have been expressed, including 748 sentences with seven feelings of Neutral, Disgust, Fear, Anger, Sadness, Boredom and Happiness. German emotional speech utterances consist of 536 sentences created by professional actors in a laboratory environment, 16 of which with seven different feelings of Happiness, hatred, naturalness, fear, Sadness, Anger, and fatigue. After extracting widely used properties such as MFCC Mel Frequency Cepstral Coefficients and its derivatives, local frequency perturbation coefficient (Jitter), and local perturbation coefficient (Shimmer), various features of this database are extracted separately because of the vast number of options. Reducing feature space is required before applying the principal component classification (PCA) algorithm. Also, three classifications of Artificial neural network (ANN), Linear Discriminant Analysis (LDA), and K_Nearest Neighbor (K_NN) have been used to classify emotions. For the German database, the top results were obtained by fusing the MFCC + Shimmer properties and LDA classification with a precision detection of 91.26% and a runtime execution of 0.43 s, and the best results for the Persian database were obtained by fusing the Jitter + Shimmer properties and K_NN classification with a precision detection of 91.5% and a runtime execution of 0.65 s. The results show that the ability to distinguish attribute vectors is quite different for each emotional state. Expression of emotions and their effect on speech differ in Persian and German.
C1 [Al Dujaili, Mohammed Jawad] Univ Kufa, Fac Engn, Dept Elect & Commun, Najaf, Iraq.
   [Ebrahimi-Moghadam, Abbas] Ferdowsi Univ Mashhad, Elect Engn Dept, Fac Engn, Mashhad, Iran.
C3 University of Kufa; Ferdowsi University Mashhad
RP Al Dujaili, MJ (corresponding author), Univ Kufa, Fac Engn, Dept Elect & Commun, Najaf, Iraq.
EM Mohammed.challab@uokufa.edu.iq; a.ebrahimi.m@gmail.com
OI AL_Dujaili, Mohammed Jawad/0000-0002-3804-6667
CR AbuZeina D, 2018, COMPUT ELECTR ENG, V66, P474, DOI 10.1016/j.compeleceng.2017.11.002
   Akçay MB, 2020, SPEECH COMMUN, V116, P56, DOI 10.1016/j.specom.2019.12.001
   Al Dujaili M.J., 2021, International Journal of Electrical and Computer Engineering (IJECE), V11, P1259, DOI [10.11591/ijece.v11i2.pp1259-1264, DOI 10.11591/IJECE.V11I2.PP1259-1264]
   ALDUJAILI MJ, 2023, WIRELESS PERS COMMUN, P1
   [Anonymous], 2004, A Computational Model for the Automatic Recognition of Affect in Speech"
   Athanaselis T, 2005, NEURAL NETWORKS, V18, P437, DOI 10.1016/j.neunet.2005.03.008
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhavan A, 2019, KNOWL-BASED SYST, V184, DOI 10.1016/j.knosys.2019.104886
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   Busso C, 2009, IEEE T AUDIO SPEECH, V17, P582, DOI 10.1109/TASL.2008.2009578
   Cambara G., 2020, arXiv
   Chauhan N, 2020, 2020 INT C INT ENG M
   Daneshfar F, 2020, APPL ACOUST, V166, DOI 10.1016/j.apacoust.2020.107360
   Daneshfar F, 2020, MULTIMED TOOLS APPL, V79, P1261, DOI 10.1007/s11042-019-08222-8
   Farrús M, 2007, INTERSPEECH 2007: 8TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION, VOLS 1-4, P1153
   Gaurav M, 2008, 2008 IEEE WORKSHOP ON SPOKEN LANGUAGE TECHNOLOGY: SLT 2008, PROCEEDINGS, P313, DOI 10.1109/SLT.2008.4777903
   Haider F, 2021, COMPUT SPEECH LANG, V65, DOI 10.1016/j.csl.2020.101119
   Harb H, 2005, J INTELL INF SYST, V24, P179, DOI 10.1007/s10844-005-0322-8
   Jain M., 2020, ARXIV
   Kacha A, 2020, COMPUT SPEECH LANG, V59, P114, DOI 10.1016/j.csl.2019.07.001
   Kalia A, 2020, LECT NOTES ELECTR EN, V607, P781, DOI 10.1007/978-981-15-0214-9_82
   Kaur J, 2021, ARCH COMPUT METHOD E, V28, P1039, DOI 10.1007/s11831-020-09414-4
   Landau MJ, 2008, VANDERBILT UNDERGRAD, V4
   Laukka P, 2011, COMPUT SPEECH LANG, V25, P84, DOI 10.1016/j.csl.2010.03.004
   Liscombe JacksonJ., 2007, PROSODY SPEAKER STAT
   Lokesh S, 2019, CLUSTER COMPUT, V22, P11669, DOI 10.1007/s10586-017-1447-6
   Malik M, 2021, MULTIMED TOOLS APPL, V80, P9411, DOI 10.1007/s11042-020-10073-7
   Marvin H., 2013, J AI DATA MIN, V1, P111
   Nancy Maria A, 2019, J COMPUT THEOR NANOS, V15, P2255
   Pan Y., 2012, P ONLINEPRESENT ORG, V2, P64
   Parthasarathy S, 2020, IEEE-ACM T AUDIO SPE, V28, P2697, DOI 10.1109/TASLP.2020.3023632
   Polzehl T, 2011, SPEECH COMMUN, V53, P1198, DOI 10.1016/j.specom.2011.05.002
   Renjith S, 2017, PROCEEDINGS OF 2017 IEEE INTERNATIONAL CONFERENCE ON CIRCUIT ,POWER AND COMPUTING TECHNOLOGIES (ICCPCT)
   Roy T, 2020, LECT N MECH ENG, P427, DOI 10.1007/978-981-15-0287-3_30
   Roy Tanmoy, 2020, Mathematical Methods in Interdisciplinary Sciences, P33
   Sahoo KK, 2021, IEEE ACCESS, V9, P166518, DOI 10.1109/ACCESS.2021.3135658
   Saxena A., 2020, J ARTIF INTELL SYST, V1, P53, DOI DOI 10.33969/AIS.2020.21005
   Sofia B., 2008, J ED SCI, V21, P103, DOI [10.33899/edusj.2008.51255, DOI 10.33899/EDUSJ.2008.51255]
   Wang KX, 2020, NEUROCOMPUTING, V398, P257, DOI 10.1016/j.neucom.2020.02.085
   Wang XS, 2020, SIGNAL PROCESS-IMAGE, V84, DOI 10.1016/j.image.2020.115831
   Wu SQ, 2011, SPEECH COMMUN, V53, P768, DOI 10.1016/j.specom.2010.08.013
   Xianxin Ke, 2018, International Journal of Machine Learning and Computing, V8, P198, DOI 10.18178/ijmlc.2018.8.3.687
   Zimmermann M, 2016, AS C COMP VIS
NR 44
TC 1
Z9 1
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42783
EP 42801
DI 10.1007/s11042-023-15413-x
EA APR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000974364100002
DA 2024-07-18
ER

PT J
AU Liu, SY
   Chen, J
   Wang, C
   Lin, L
AF Liu, Siyu
   Chen, Jian
   Wang, Cheng
   Lin, Lin
TI Ultrasonic positioning and IMU data fusion for pen-based 3D hand gesture
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human-computer interaction; 3D hand gesture recognition; 3D positioning;
   3D pen-like interaction; Inertial sensor; Multichannel interaction
AB In this paper, a pen-based 3D hand gesture dataset and recognition method using ultrasonic positioning and inertial data is proposed. First, considering that 3D hand gestures have six degrees of freedom, a 3D hand gesture dataset based on trajectory shape attributes, motion direction attributes and pen attitude attributes is proposed. Then, each attribute of the gesture is processed according to its priority, and the corresponding data channel and recognition method are selected to determine the 3D hand gesture label. Finally, experimental verification is conducted using a 3D multi-channel pen-like interactive device. For a 10-gesture set, the gesture recognition rates achieved ranged from 86.5-99.5%, depending on whether a single or multiple templates and thresholds are used. The results show that the 3D hand gesture recognition method proposed in this paper can recognize pen-based gestures effectively and solve the problem of traditional gesture recognition methods not being able to recognize 3D hand gestures containing multiple attributes.
C1 [Liu, Siyu; Chen, Jian; Wang, Cheng; Lin, Lin] Jilin Univ, Coll Commun Engn, Changchun 130022, Peoples R China.
C3 Jilin University
RP Chen, J (corresponding author), Jilin Univ, Coll Commun Engn, Changchun 130022, Peoples R China.
EM chenjian@jlu.edu.cn
RI Liu, Siyu/GYV-4856-2022
FU National Key Research and Development Program of China [2016YFB1001301]
FX AcknowledgementsThis work was supported by the National Key Research and
   Development Program of China. (Grand 2016YFB1001301)
CR Abid MR, 2015, IEEE T INSTRUM MEAS, V64, P596, DOI 10.1109/TIM.2014.2351331
   Akan E, 2017, IEEE I C ELECT CIRC, P140, DOI 10.1109/ICECS.2017.8292074
   Akl A, 2011, IEEE T SIGNAL PROCES, V59, P6197, DOI 10.1109/TSP.2011.2165707
   Akl A, 2010, INT CONF ACOUST SPEE, P2270, DOI 10.1109/ICASSP.2010.5495895
   Asano T, 2010, 2010 IEEE RO-MAN, P56, DOI 10.1109/ROMAN.2010.5598705
   BADDELEY A, 1992, Science (Washington D C), V255, P556, DOI 10.1016/j.cub.2009.12.014
   Che YL, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P228, DOI 10.1109/ISMAR-Adjunct.2019.00-41
   Chen J, 2021, IEEE SENS J, V21, P1756, DOI 10.1109/JSEN.2020.3016292
   Chen J, 2020, IEEE ACCESS, V8, P143837, DOI 10.1109/ACCESS.2020.3014169
   Chen MY, 2016, IEEE T HUM-MACH SYST, V46, P403, DOI 10.1109/THMS.2015.2492598
   Cheng H, 2016, IEEE T CIRC SYST VID, V26, P1659, DOI 10.1109/TCSVT.2015.2469551
   Djemal A, 2022, 2022 IEEE 9 INT C CO, P1
   Dudak P, 2016, 2016 17 INT C MECHAT, P1
   Hsieh CC, 2015, J REAL-TIME IMAGE PR, V10, P357, DOI 10.1007/s11554-012-0295-0
   Hsu YL, 2015, IEEE SENS J, V15, P154, DOI 10.1109/JSEN.2014.2339843
   Huang MJ, 2016, C IND ELECT APPL, P1634, DOI 10.1109/ICIEA.2016.7603847
   Ji Z, 2015, 2015 12TH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (FSKD), P1243, DOI 10.1109/FSKD.2015.7382120
   Katsura S, 2007, IEEE T IND ELECTRON, V54, P3353, DOI 10.1109/TIE.2007.896503
   Keskin C, 2003, REAL TIME HAND TRACK
   Long AC, 1997, PDA GESTURE USE PRAC
   Marasovic T, 2015, J MULTIMODAL USER IN, V9, P211, DOI 10.1007/s12193-015-0194-3
   Pan TY, 2019, IEEE TETCI, V3, P261, DOI 10.1109/TETCI.2018.2803777
   Pezzuoli F, 2021, SN Comput Sci, V2, P1, DOI DOI 10.1007/S42979-020-00396-5
   Pomboza-Junez G., 2016, 2016 IEEE 6 INT C CO, P174, DOI DOI 10.1109/ICCE-BERLIN.2016.7684748
   Qi JX, 2019, IEEE ACCESS, V7, P61378, DOI 10.1109/ACCESS.2019.2914728
   Sali Shajideen SM, 2018, 2018 INT C EMERGING, P1
   Takahashi H, 2016, 2016 4TH INTL CONF ON APPLIED COMPUTING AND INFORMATION TECHNOLOGY/3RD INTL CONF ON COMPUTATIONAL SCIENCE/INTELLIGENCE AND APPLIED INFORMATICS/1ST INTL CONF ON BIG DATA, CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (ACIT-CSII-BCD), P81, DOI [10.1109/ACIT-CSII-BCD.2016.27, 10.1109/ACIT-CSII-BCD.2016.027]
   Teachasrisaksakul K, 2018, IEEE ENG MED BIO, P3517, DOI 10.1109/EMBC.2018.8513098
   Wang JS, 2012, IEEE T IND ELECTRON, V59, P2998, DOI 10.1109/TIE.2011.2167895
   Xin YZ, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P849
   Xu RZ, 2012, IEEE SENS J, V12, P1166, DOI 10.1109/JSEN.2011.2166953
   Zhu C, 2021, IEEE-CAA J AUTOMATIC, V8, P1600, DOI 10.1109/JAS.2019.1911534
   Zhu YM, 2014, IEEE IJCNN, P3240, DOI 10.1109/IJCNN.2014.6889481
NR 33
TC 1
Z9 1
U1 9
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 41841
EP 41859
DI 10.1007/s11042-023-15252-w
EA APR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000973330100002
DA 2024-07-18
ER

PT J
AU Sarigül, M
AF Sarigul, Mehmet
TI A survey on digital video stabilization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video stabilization; Digital video processing; Motion estimation; Motion
   correction; Frame synthesis; Image registration
ID CONTENT-PRESERVING WARPS; FILTER; TRACKING; SYSTEM
AB Shakes and jitters are an eventual result of involuntary camera movements during video recording. Digital video stabilization is the elimination of these errors with smart algorithms. This process is usually performed in three steps which are camera motion estimation, motion correction, and stable video synthesis. In the literature, methods differ by the way they perform these steps. The recent success of deep learning has pioneered learning-based video stabilization approaches. This paper provides a detailed explanation of video stabilization methods by analyzing and comparing the applied approaches from past to present.
C1 [Sarigul, Mehmet] Cukurova Univ, Comp Engn Dept, Adana, Turkiye.
   [Sarigul, Mehmet] Iskenderun Tech Univ, Comp Engn Dept, Iskenderun Hatay, Turkiye.
C3 Cukurova University; Iskenderun Technical University
RP Sarigül, M (corresponding author), Cukurova Univ, Comp Engn Dept, Adana, Turkiye.; Sarigül, M (corresponding author), Iskenderun Tech Univ, Comp Engn Dept, Iskenderun Hatay, Turkiye.
EM msarigul@cu.edu.tr
RI Sarıgül, Mehmet/ISA-7474-2023
OI Sarıgül, Mehmet/0000-0001-7323-6864
FU TUBITAK (Scientific and Technological Research Council of Turkey)
   [120E447]
FX AcknowledgementsThis work has been supported by project number 120E447
   from the TUBITAK (Scientific and Technological Research Council of
   Turkey).
CR Ali MK, 2020, ARXIV
   Auberger S, 2005, ISPA 2005: PROCEEDINGS OF THE 4TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P474, DOI 10.1109/ISPA.2005.195458
   Battiato S, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P373, DOI 10.1109/ICME.2008.4607449
   Battiato S, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P825, DOI 10.1109/ICIAP.2007.4362878
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bradley A, 2021, IEEE WINT CONF APPL, P1040, DOI 10.1109/WACV48630.2021.00108
   Broggi A, 2005, IEEE VTS VEH TECHNOL, P2760
   Buehler C, 2001, PROC CVPR IEEE, P609
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Cao MW, 2020, COMPUT COMMUN, V158, P104, DOI 10.1016/j.comcom.2020.05.007
   Chang HC, 2006, J VIS COMMUN IMAGE R, V17, P659, DOI 10.1016/j.jvcir.2005.10.004
   Chen BY, 2008, COMPUT GRAPH FORUM, V27, P1805, DOI 10.1111/j.1467-8659.2008.01326.x
   Chen K., 2018, arXiv
   Chen YT, 2021, IEEE IMAGE PROC, P1929, DOI 10.1109/ICIP42928.2021.9506801
   Choi J, 2021, arXiv
   Choi J, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3363550
   Djuric PM, 2003, IEEE SIGNAL PROC MAG, V20, P19, DOI 10.1109/MSP.2003.1236770
   Farid, 1997, TR2007605 DARTM COLL
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Garbin SJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14326, DOI 10.1109/ICCV48922.2021.01408
   Grundmann M, 2011, PROC CVPR IEEE, P225, DOI 10.1109/CVPR.2011.5995525
   Guilluy W., 2021, SIGNAL PROCESS-IMAGE, V116015, P90
   Hu R, 2007, IEEE INT CONF INF VI, P871
   Huang CH, 2019, ARXIV
   Huang HM, 2020, INT CONF ACOUST SPEE, P1055, DOI [10.1109/ICASSP40776.2020.9053405, 10.1109/icassp40776.2020.9053405]
   Ito MS, 2021, INT C PATT RECOG, P8819, DOI 10.1109/ICPR48806.2021.9413034
   ITO MS, 2020, 2020 IEEE INT C MULT, P1
   Jaderberg Max, 2015, ADV NEURAL INFORM PR, P8
   Kaba K, 2018, ENERGY, V162, P126, DOI 10.1016/j.energy.2018.07.202
   KARAGEORGOS K, 2017, 2017 14 IEEE INT C A, P1
   Kim SK, 2013, IEEE T CONSUM ELECTR, V59, P267, DOI 10.1109/TCE.2013.6490269
   Kosiorek A. R., 2021, P INT C MACHINE LEAR, P5742
   Kwon O, 2005, LECT NOTES COMPUT SC, V3656, P141, DOI 10.1007/11559573_18
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee KY, 2009, IEEE I CONF COMP VIS, P1397
   Lee YC, 2021, PROC CVPR IEEE, P10616, DOI 10.1109/CVPR46437.2021.01048
   Liang YM, 2004, IEEE T VEH TECHNOL, V53, P1636, DOI 10.1109/TVT.2004.836923
   Litvin A, 2003, PROC SPIE, V5022, P663, DOI 10.1117/12.476436
   Liu F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899408
   Liu F, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531350
   Liu SC, 2016, LECT NOTES COMPUT SC, V9910, P800, DOI 10.1007/978-3-319-46466-4_48
   Liu SC, 2014, PROC CVPR IEEE, P4209, DOI 10.1109/CVPR.2014.536
   Liu S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461995
   Liu Y., 2021, ARXIV
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Matsushita Y, 2006, IEEE T PATTERN ANAL, V28, P1150, DOI 10.1109/TPAMI.2006.141
   Meng-Li Shih, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8025, DOI 10.1109/CVPR42600.2020.00805
   Niskanen M, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P405
   PAIK JK, 1992, IEEE T CONSUM ELECTR, V38, P607, DOI 10.1109/30.156744
   Pinto Binoy, 2011, 2011 International Conference on Communications and Signal Processing (ICCSP), P527, DOI 10.1109/ICCSP.2011.5739378
   Raj R, 2020, IMAGE VISION COMPUT, V101, DOI 10.1016/j.imavis.2020.103957
   Ratakonda K., 1998, ISCAS '98. Proceedings of the 1998 IEEE International Symposium on Circuits and Systems (Cat. No.98CH36187), P69, DOI 10.1109/ISCAS.1998.698760
   Roberto ME, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3494525
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sarigül M, 2019, NEURAL NETWORKS, V116, P279, DOI 10.1016/j.neunet.2019.04.025
   Shen XL, 2019, PROC CVPR IEEE, P8124, DOI 10.1109/CVPR.2019.00832
   Shen Y, 2009, IEEE T CONSUM ELECTR, V55, P1714, DOI 10.1109/TCE.2009.5278047
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Shi Zhenmei, 2022, P IEEE CVF WINT C AP, P1250
   Sobel I., 1968, STANF ART PROJ, P271
   Song CH, 2012, IEEE T CONSUM ELECTR, V58, P570, DOI 10.1109/TCE.2012.6227462
   Targ S., 2016, ARXIV
   Tico M, 2005, INT C IMAGE PROCESSI, V3, pIII
   ULLMAN S, 1979, PROC R SOC SER B-BIO, V203, P405, DOI 10.1098/rspb.1979.0006
   Vlahovic N, 2018, 2018 14 S NEUR NETW, P1
   Walha A, 2015, MULTIMED TOOLS APPL, V74, P6745, DOI 10.1007/s11042-014-1928-z
   Wang JM, 2009, IEEE IMAGE PROC, P3477, DOI 10.1109/ICIP.2009.5413831
   Wang M, 2018, ARXIV
   Wang M, 2019, IEEE T IMAGE PROCESS, V28, P2283, DOI 10.1109/TIP.2018.2884280
   Wang YS, 2013, IEEE T VIS COMPUT GR, V19, P1354, DOI 10.1109/TVCG.2013.11
   Welch G., 1995, An introduction to the kalman filter
   Wu HC, 2021, IEEE T IMAGE PROCESS, V30, P4637, DOI 10.1109/TIP.2021.3073865
   Xu J, 2012, IEEE T CONSUM ELECTR, V58, P993, DOI 10.1109/TCE.2012.6311347
   Xu SZ, 2018, COMPUT GRAPH FORUM, V37, P267, DOI 10.1111/cgf.13566
   Xu Y., 2020, ARXIV
   Xu Y., 2021, P IEEE CVF INT C COM, P4842
   Yang JL, 2006, IEEE IMAGE PROC, P1545, DOI 10.1109/ICIP.2006.312645
   Yang JL, 2009, IEEE T CIRC SYST VID, V19, P945, DOI 10.1109/TCSVT.2009.2020252
   Yanhong Zeng, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P528, DOI 10.1007/978-3-030-58517-4_31
   Yu J., 2020, P IEEE CVF C COMP VI, P8159
   Yu JY, 2021, PROC CVPR IEEE, P12031, DOI 10.1109/CVPR46437.2021.01186
   Yu JY, 2019, PROC CVPR IEEE, P3795, DOI 10.1109/CVPR.2019.00392
   Yu JY, 2018, LECT NOTES COMPUT SC, V11209, P569, DOI 10.1007/978-3-030-01228-1_34
   Zhang G, 2007, AEROSP CONF PROC, P3929
   Zhang GF, 2009, VISUAL COMPUT, V25, P997, DOI 10.1007/s00371-009-0310-z
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zhao M, 2020, IEEE T CIRC SYST VID
   Zhao MD, 2020, IEEE T IMAGE PROCESS, V29, P3582, DOI 10.1109/TIP.2019.2963380
   Zhou ZH, 2013, PROC CVPR IEEE, P2299, DOI 10.1109/CVPR.2013.298
   Zhu X, 2021, IEEE T CIRC SYST VID
   Zhu XY, 2019, IEEE T PATTERN ANAL, V41, P78, DOI 10.1109/TPAMI.2017.2778152
   Zhu Xiangyuan, 2021, IEEE Transactions on Multimedia
NR 94
TC 3
Z9 3
U1 6
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40181
EP 40207
DI 10.1007/s11042-023-14726-1
EA APR 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000961747500002
DA 2024-07-18
ER

PT J
AU Long, JL
   Xie, CZ
   Gao, ZS
AF Long, Jialin
   Xie, Chunzhi
   Gao, Zhisheng
TI High discriminant features for writer-independent online signature
   verification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic-driven feature extraction; Writer independence; Online
   signature verification; Global features; Deep learning
ID NETWORKS; INFORMATION; FUSION
AB The application of online signature is promising. However, its huge intra-individual variability and its extremely low inter-class distance brought by forged signatures make it difficult for even state-of-the-art online signature algorithms to be applied in practical scenarios on a large scale. This paper proposes a semantic-driven extraction method of high discriminative features for writer-independent online signature verification, addressing the problem of representation learning with high discriminative features. The semantic-driven model aims at learning the high-level semantic representation of the writer's inherent signature habits, and it has combined the advantages of LSTM and CNN. Furthermore, several global feature descriptors are designed to extract writer habitual features such as speed, and writing pressure at keystroke positions. The most difficult, writer-independent, 1v1 experiments on the three benchmark data sets of MCYT-100, SUSIG, and MOBISIG were performed, and the results show that the performance of the proposed method is better than that of the state-of-the-art methods, and its performance on the MCYT-100 dataset is 16% higher than the second-best method.
C1 [Long, Jialin; Xie, Chunzhi; Gao, Zhisheng] Xihua Univ, Sch Comp & Software Engn, Chengdu 610039, Peoples R China.
C3 Xihua University
RP Gao, ZS (corresponding author), Xihua Univ, Sch Comp & Software Engn, Chengdu 610039, Peoples R China.
EM gzs_xihua@mail.xhu.edu.cn
FU Key scientific research fund of Xihua University [Z17134]; Xihua
   University Key Laboratory Development Program [szjj2017-065]; Xihua
   University Graduate Innovation Fund Research Project [YCJJ2021032];
   Sichuan science and technology program [2021YFG0022,2019YFG0108]
FX AcknowledgementsThis work has been partially supported by the Key
   scientific research fund of Xihua University (Grant No: Z17134), Xihua
   University Key Laboratory Development Program (Grant No: szjj2017-065),
   Xihua University Graduate Innovation Fund Research Project (Grant No:
   YCJJ2021032) and Sichuan science and technology program (Grant No:
   2021YFG0022,2019YFG0108).
CR Ahrabian K, 2019, NEURAL COMPUT APPL, V31, P9321, DOI 10.1007/s00521-018-3844-z
   Alexandre D., 2018, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, P2539
   Antal M, 2018, MOB INF SYST, V2018, DOI 10.1155/2018/3127042
   Caruana Miguel, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12665), P501, DOI 10.1007/978-3-030-68821-9_42
   Chan S, 2021, NEPHROLOGY, V26, P471, DOI 10.1111/nep.13853
   Chuang Li, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P526, DOI 10.1109/ICDAR.2019.00090
   Diaz M, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3274658
   Diaz M, 2019, IEEE T PATTERN ANAL, V41, P2807, DOI 10.1109/TPAMI.2018.2869163
   Diaz M, 2018, IEEE T CYBERNETICS, V48, P228, DOI 10.1109/TCYB.2016.2630419
   Diaz M, 2015, PROC INT CONF DOC, P631, DOI 10.1109/ICDAR.2015.7333838
   Fierrez-Aguilar J, 2005, LECT NOTES COMPUT SC, V3546, P523
   Gal Y, 2016, ADV NEUR IN, V29
   Ghosh R, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114249
   Graves A, 2005, LECT NOTES COMPUT SC, V3697, P799
   Gupta D, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165491
   Guru DS, 2017, EXPERT SYST APPL, V80, P232, DOI 10.1016/j.eswa.2017.03.024
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   Hajihashemi V., 2020, 2020 INT C MACH VIS, P1, DOI DOI 10.1109/MVIP49855.2020.9116913
   Huang Z., 2015, Comput. Sci., DOI [10.48550/arXiv.1508.01991, DOI 10.48550/ARXIV.1508.01991]
   Impedovo D, 2021, IEEE T EMERG TOP COM, V9, P554, DOI 10.1109/TETC.2018.2865345
   Jampour M, 2021, CAPSNET REGULARIZATI
   Jia Y, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19081808
   Kholmatov A, 2009, PATTERN ANAL APPL, V12, P227, DOI 10.1007/s10044-008-0118-x
   Lai SX, 2019, IEEE T INF FOREN SEC, V14, P1624, DOI 10.1109/TIFS.2018.2883152
   Lai SX, 2017, PROC INT CONF DOC, P400, DOI 10.1109/ICDAR.2017.73
   Liu YS, 2015, IEEE T CYBERNETICS, V45, P2498, DOI 10.1109/TCYB.2014.2375959
   Minoofam SAH, 2023, IEEE T NEUR NET LEAR, V34, P2480, DOI 10.1109/TNNLS.2021.3106705
   Modhej N, 2020, IEEE ACCESS, V8, P212803, DOI 10.1109/ACCESS.2020.3040298
   Mohammed RA, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND COMPUTATIONAL INTELLIGENCE (CSCI), P519, DOI 10.1109/CSCI.2015.180
   Okawa M, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107699
   Okawa M, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107227
   Ortega-Garcia J, 2003, IEE P-VIS IMAGE SIGN, V150, P395, DOI 10.1049/ip-vis:20031078
   Pal S, 2015, 2015 INT C COMP COMM, P1, DOI [10.1109/IJCNN.2015.7280518, DOI 10.1109/ICCCI.2015.7218157]
   Pirlo G, 2015, IEEE T HUM-MACH SYST, V45, P805, DOI 10.1109/THMS.2015.2443050
   Rani S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21196474
   Sae-Bae N, 2018, PATTERN RECOGN, V84, P332, DOI 10.1016/j.patcog.2018.07.024
   Sae-Bae N, 2014, IEEE T INF FOREN SEC, V9, P933, DOI 10.1109/TIFS.2014.2316472
   Sharma A, 2018, IEEE T CYBERNETICS, V48, P611, DOI 10.1109/TCYB.2017.2647826
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Tang L, 2018, IEEE T INF FOREN SEC, V13, P861, DOI 10.1109/TIFS.2017.2769023
   Tolosana Ruben, 2021, IEEE Transactions on Biometrics, Behavior, and Identity Science, V3, P229, DOI 10.1109/TBIOM.2021.3054533
   Tolosana R, 2021, AAAI CONF ARTIF INTE, V35, P600
   Tolosana R, 2018, IEEE ACCESS, V6, P5128, DOI 10.1109/ACCESS.2018.2793966
   Vera-Rodriguez Ruben, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1326, DOI 10.1109/ICDAR.2019.00214
   Vorugunti Chandra Sekhar, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1125, DOI 10.1109/ICDAR.2019.00182
   Vorugunti CS, 2020, NEUROCOMPUTING, V409, P157, DOI 10.1016/j.neucom.2020.05.072
   Xia XH, 2018, PATTERN RECOGN, V74, P422, DOI 10.1016/j.patcog.2017.09.033
   Xia XH, 2017, PATTERN RECOGN, V65, P188, DOI 10.1016/j.patcog.2016.12.019
   Yang L, 2018, SOFT COMPUT, V22, P7811, DOI 10.1007/s00500-018-3477-2
NR 49
TC 1
Z9 1
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 38447
EP 38465
DI 10.1007/s11042-023-14638-0
EA MAR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000983783100006
DA 2024-07-18
ER

PT J
AU Rejula, MA
   Amutha, S
   Shilpa, GM
AF Rejula, M. Anline
   Amutha, S.
   Shilpa, G. M.
TI Classification of acute lymphoblastic leukemia using improved ANFIS
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive network-based fuzzy inference systems (ANFIS); Neural network;
   Least Square estimate (LSE); Leukaemia classification
ID ARTIFICIAL NEURAL-NETWORKS; SEGMENTATION; SYSTEM; CELLS
AB Many advanced technologies have been developed in the medical field where leukaemia plays a vital role, which may cause serious issues when it is unidentified. In the convolution method, human error may occur, so to avoid it, many tools have been introduced, like Adaptive Network-Based Fuzzy Inference Systems (ANFIS), which helps to diagnose and classify systems for leukaemia, and it is also shown to be an excellent function approximation tool. ANFIS also uses the ANN theory, which is used to conclude the attributes of neuro-fuzzy systems. But the accuracy is not up to the mark. To overcome this drawback, we have proposed an improved ANFIS (I ANFIS) model to predict leukaemia data using a Euclidean distance to measure between the trained feature data and the test feature data. An Improved Adaptive Neuro-Fuzzy Neural Network (ANFNN) is also introduced, which helps the input space be partitioned into many local regions by the fuzzy clustering, in which the computation complexity is decreased and, based on both the separation and the compactness among the clusters, the fuzzy rule number is determined by the validity function. Then, the premise parameters and consequent parameters are trained by a hybrid learning algorithm which uses forward and backward passes. Following the arrangement of principle parameters, until layer 4, a node outputs move ahead in the forward pass and, using Least Square Estimate (LSE), the consequent parameters are calculated for each node. Then an error measure is calculated for each node. To update principal parameters, the error signals are distributed backward with gradient descent in the backward pass. Improved ANFIS obtains the best accuracy, sensitivity, specificity of 97.14%, 96% and 90%, and classification for all the cell types, especially in the microscopic blood cell dataset.
C1 [Rejula, M. Anline] Scott Christian Coll Autonomous, Nagercoil 629003, Tamil Nadu, India.
   [Amutha, S.] Vellore Inst Technol, Chennai, India.
   [Shilpa, G. M.] Noorul Islam Coll Arts & Sci, Kumaracoil 629180, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai
RP Rejula, MA (corresponding author), Scott Christian Coll Autonomous, Nagercoil 629003, Tamil Nadu, India.
EM rejularajesh77@gmail.com; amuthabenziker@gmail.com; gmshilpa43@gmail.com
RI AMUTHA, S/AAV-3691-2021
OI AMUTHA, S/0000-0002-7397-6683
CR Angelova E, 2019, HAEMATOLOGICA, V104, P749, DOI 10.3324/haematol.2018.205252
   Angulo J, 2006, CELL MOL BIOL, V52, P2, DOI 10.1170/T732
   Angulo J., 2001, Analytical Cellular Pathology, V22, P69
   Angulo J, 2003, SCI TECHNOL ED MICRO, P304
   [Anonymous], 2017, Int J Adv Res Sci Eng Technol
   Cario G, 2014, HAEMATOLOGICA, V99, P103, DOI 10.3324/haematol.2013.090225
   Duffield AS, 2023, VIRCHOWS ARCH, V482, P11, DOI 10.1007/s00428-022-03448-8
   DUHAMEL SS, 1991, PROCEEDINGS OF THE ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY, VOL 13, PTS 1-5, P260
   Foran DJ, 2000, IEEE T INF TECHNOL B, V4, P265, DOI 10.1109/4233.897058
   Ghosh Madhumala, 2010, Proceedings of the 2010 IEEE Students' Technology Symposium (TechSym 2010), P59, DOI 10.1109/TECHSYM.2010.5469197
   Gupta L, 2009, IEEE ENG MED BIO, P6675, DOI 10.1109/IEMBS.2009.5334016
   Halim Nurul Hazwani Abd, 2011, International Journal of Research and Reviews in Computer Science, V2, P971
   Haykin S., 2009, Neural Network and Machine Learning, V3rd
   Hosseini Monireh Sheikh, 2012, J Med Signals Sens, V2, P49
   Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891
   Escalante HJ, 2012, ARTIF INTELL MED, V55, P163, DOI 10.1016/j.artmed.2012.03.005
   JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541
   Jang JSR., 1997, NEUROFUZZY SOFT COMP, V42, P1482
   Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044
   Ko BC, 2011, MICRON, V42, P695, DOI 10.1016/j.micron.2011.03.009
   Kovalev V. A., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P371, DOI 10.1109/ICPR.1996.547448
   Labati RD, 2011, IEEE IMAGE PROC
   Leblebici SY, 2016, NAT ENERGY, V1, DOI [10.1038/nenergy.2016.93, 10.1038/NENERGY.2016.93]
   Loganathan C., 2013, INT J COMPUT SCI TEC, V4, P6
   Markiewicz T, 2005, IEEE IJCNN, P2496
   McCulloch WS, 2016, EMBODIMENTS OF MIND, P19
   Mishra S, 2017, BIOMED SIGNAL PROCES, V33, P272, DOI 10.1016/j.bspc.2016.11.021
   Mohapatra S, 2014, NEURAL COMPUT APPL, V24, P1887, DOI 10.1007/s00521-013-1438-3
   Ongun G, 2001, P ANN INT IEEE EMBS, V23, P2583, DOI 10.1109/IEMBS.2001.1017309
   Piuri V, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MEASUREMENT SYSTEMS AND APPLICATIONS, P103, DOI 10.1109/CIMSA.2004.1397242
   Putzu L, 2013, PROCEEDINGS IWBBIO 2013: INTERNATIONAL WORK-CONFERENCE ON BIOINFORMATICS AND BIOMEDICAL ENGINEERING, P99
   Rawat J, 2017, MULTIMED TOOLS APPL, V76, P19057, DOI 10.1007/s11042-017-4478-3
   Reta C, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0134066
   Saraswat M, 2014, MED BIOL ENG COMPUT, V52, P1041, DOI 10.1007/s11517-014-1200-8
   Savita Dumyan AG., 2017, INT J ADV RES COMPUT, V6, P38
   Scotti F, 2005, PROCEEDINGS OF THE 2005 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MEASUREMENT SYSTEMS AND APPLICATIONS, P96
   Scotti F, 2006, IEEE IMTC P, P43, DOI 10.1109/IMTC.2006.328170
   SESHADRI R, 1985, MED PEDIATR ONCOL, V13, P214, DOI 10.1002/mpo.2950130411
   Shanthi P., 2017, INT RES J ENG TECHNO, V4, P1460
   Swolin B, 2003, CLIN LAB HAEMATOL, V25, P139, DOI 10.1046/j.1365-2257.2003.00516.x
   Tang H., 2007, Neural networks: computational models and applications
   Werbos P.J., 1994, The roots of backpropagation: from ordered derivatives to neural networks and political forecasting, VVolume 1
NR 42
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35475
EP 35491
DI 10.1007/s11042-023-15113-6
EA MAR 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN8D9
UT WOS:000983783100014
DA 2024-07-18
ER

PT J
AU Lingappa, E
   Parvathy, LR
AF Lingappa, Ediga
   Parvathy, L. Rama
TI Deep learning-based active contour technique with bagging and boosting
   algorithms hybrid approach for detecting bone Cancer from Mri scan
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Active contour methods; Artificial neural network; Bone cancer; Deep
   learning; Machine learning techniques
ID CLASSIFICATION; SEGMENTATION; WAVELET
AB Bone Cancer is a fatal disease caused by uncontrolled cell development. Following extensive research, about 100 different types of cancer have been discovered in the human body. Bone cancer is one of the most widely distributed of them, and it is fatal. The diagnosis of bone cancer is critical and has a low prognosis. For the process of medical picture analysis, some of the work is presently undertaken using data mining tools and image processing technology. Despite ongoing advancements in cancer research, it continues to be one of the world's most lethal diseases. It is critical to pool all resources in order to achieve a breakthrough in cancer treatment. Early detection would go a long way toward lengthening the patient's life and lowering the death rate. As a result, it is critical to develop approaches that are both inventive and efficient, as well as having fewer negative consequences. This research examines all aspects of bone cancer and its characteristics in order to determine its type. One of the most prominent methods for dividing up the Bone picture into distinct portions is the Active Contour Method. The study uses a Deep Learning-based Active Contour Method with bagging and boosting algorithms to achieve this goal. It is thought to be extremely difficult to extract critical information about the organ's shapes and volumes from a photograph. However, advances in machine learning, particularly deep learning, have made it possible to segment images and classify sick regions more effectively. It entails a number of stages, including noise removal, segmentation, feature extraction, and selection. Pixels from the object's edges are segmented. They are then processed to achieve the desired result. Finally, active cancer approaches were used to classify the MRI pictures, and the results were extremely accurate. To evaluate the success of the recommended strategy, we used three criteria: accuracy, specificity, and sensitivity. In terms of accuracy, specificity, and sensitivity, experiments show that the proposed system beats existing methods.
C1 [Lingappa, Ediga; Parvathy, L. Rama] Saveetha Univ, Saveetha Inst Med & Tech Sci, Saveetha Sch Engn, Dept Comp Sci & Engn, Chennai 600056, Tamil Nadu, India.
C3 Saveetha Institute of Medical & Technical Science; Saveetha School of
   Engineering
RP Lingappa, E (corresponding author), Saveetha Univ, Saveetha Inst Med & Tech Sci, Saveetha Sch Engn, Dept Comp Sci & Engn, Chennai 600056, Tamil Nadu, India.
EM edigalingappa10@gmail.com
RI L, Rama/AAM-1205-2021; L, Ramaparvathy/IWE-3683-2023
OI L, Rama/0000-0001-8645-254X; Lingappa, Ediga/0000-0002-7445-3227
CR Anand Dama, 2022, Applications of Computational Methods in Manufacturing and Product Design: Select Proceedings of IPDIMS 2020. Lecture Notes in Mechanical Engineering, P523, DOI 10.1007/978-981-19-0296-3_48
   Apiparakoon T, 2020, IEEE ACCESS, V8, P27047, DOI 10.1109/ACCESS.2020.2971391
   Arenas-Herrera JE, 2013, BIOMED MATER, V8, DOI 10.1088/1748-6041/8/1/014106
   Bagaria R, 2021, OPTIK, V236, DOI 10.1016/j.ijleo.2021.166687
   Burns JE, 2017, RADIOLOGY, V284, P788, DOI 10.1148/radiol.2017162100
   Chen K, 2021, ARXIV
   Chung SW, 2018, ACTA ORTHOP, V89, P468, DOI 10.1080/17453674.2018.1453714
   CopernicaWhels R, 2021, PROC SPIE, P17197
   Dadgar H, 2022, WORLD J NUCL MED, V21, P1, DOI 10.1055/s-0042-1748154
   de Leiris N, 2020, CANCER IMAGING, V20, DOI 10.1186/s40644-020-00333-y
   Ghaderzadeh M, 2021, SCI PROGRAMMING-NETH, V2021, DOI 10.1155/2021/9933481
   Gray K, 2012, PSYCHOL INQ, V23, P206, DOI 10.1080/1047840X.2012.686247
   Han S, 2022, EUR J NUCL MED MOL I, V49, P585, DOI 10.1007/s00259-021-05481-2
   Hinzpeter R, 2022, EUR RADIOL, V32, P1823, DOI 10.1007/s00330-021-08245-6
   Kouketsu A, 2021, ORAL ONCOL, V120, DOI 10.1016/j.oraloncology.2021.105453
   Krois J, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-44839-3
   Kumar D, 2020, IEEE ACCESS, V8, P142521, DOI 10.1109/ACCESS.2020.3012292
   Kumaraswamy N., 2013, INT REV SOCIAL SCI H, V5, P135, DOI DOI 10.24941/IJCR.33132.12.2018
   Kumaresan T., 2015, INT J BIO-INSPIR COM, V10, P15643
   Kumaresan T., 2014, INT J COMPUT INF SYS, V8, P1746
   Masoudi S, 2021, IEEE ACCESS, V9, P87531, DOI [10.1109/access.2021.3074051, 10.1109/ACCESS.2021.3074051]
   Raciborska A, 2022, CURR ONCOL, V29, P1001, DOI 10.3390/curroncol29020085
   Rahimi HR, 2016, AVICENNA J PHYTOMEDI, V6, P567
   Rajakumar K, 2013, J ELECTR ENG TECHNOL, V8, P1188, DOI 10.5370/JEET.2013.8.5.1188
   Ramírez F, 2016, NUCLEIC ACIDS RES, V44, pW160, DOI 10.1093/nar/gkw257
   Ranjitha P., 2021, 2021 5th International Conference on Intelligent Computing and Control Systems (ICICCS), P838, DOI 10.1109/ICICCS51141.2021.9432244
   Saba T, 2020, J INFECT PUBLIC HEAL, V13, P1274, DOI 10.1016/j.jiph.2020.06.033
   Saravanakumar S, 2022, J INTELL FUZZY SYST, V43, P4501, DOI 10.3233/JIFS-212797
   Saravanakumar S, 2019, J MED SYST, V43, DOI 10.1007/s10916-018-1147-7
   Saravanakumar S., 2018, INT J PURE APPL MATH, V119, P2391
   Saravanakumar S, 2018, CLUSTER COMPUT, V10
   Saravanakumar S., 2020, INT J ADV MANUF TECH, V63, P225
   Sharif MHU, 2021, INT J COMPUTER SCI I, V19
   Shimizu A, 2020, INT J COMPUT ASS RAD, V15, P389, DOI 10.1007/s11548-019-02105-x
   Shrivastava Deepshikha., 2020, Smart Healthcare for Disease Diagnosis and Prevention, P175, DOI DOI 10.1016/B978-0-12-817913-0.00017-1
   Stalin Alex D, 2019, INT J RECENT TECHNOL, V8, P15
   Thanh DNH, 2020, J DIGIT IMAGING, V33, P574, DOI 10.1007/s10278-019-00316-x
   Yan YJ, 2021, DENT J-BASEL, V9, DOI 10.3390/dj9070074
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850945
   Yang SM, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040455
NR 40
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 36363
EP 36377
DI 10.1007/s11042-023-14811-5
EA MAR 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000960423600020
DA 2024-07-18
ER

PT J
AU Martínez, G
   Saavedra, JM
   Murrugara-Llerena, N
AF Martinez, Guillermo
   Saavedra, Jose M. M.
   Murrugara-Llerena, Nils
TI VETE: improving visual embeddings through text descriptions for
   eCommerce search engines
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval; Self-supervised representation learning;
   Visual and text embeddings
AB A search engine is a critical component in the success of eCommerce. Searching for a particular product can be frustrating when users want specific product features that cannot be easily represented by a simple text search or catalog filter. Due to the advances in artificial intelligence and deep learning, content-based visual search engines are included in eCommerce search bars. A visual search is instantaneous, just take a picture and search; and it is fully expressive of image details. However, visual search in eCommerce still undergoes a large semantic gap. Traditionally, visual search models are trained in a supervised manner with large collections of images that do not represent well the semantic of a target eCommerce catalog. Therefore, we propose VETE (Visual Embedding modulated by TExt) to boost visual embeddings in eCommerce leveraging textual information of products in the target catalog. with real eCommerce data. Our proposal improves the baseline visual space for global and fine-grained categories in real-world eCommerce data. We achieved an average improvement of 3.48% for catalog-like queries, and 3.70% for noisy ones.
C1 [Martinez, Guillermo] Univ Chile, Dept Comp Sci, Beauchef 850, Santiago 8370448, RM, Chile.
   [Saavedra, Jose M. M.] Univ Los Andes, Fac Ingn & Ciencias Aplicadas, Mons Alvaro del Portillo 124555, Santiago 7620001, RM, Chile.
   [Murrugara-Llerena, Nils] Weber State Univ, 3848 Harrison Blvd, Ogden, UT 84408 USA.
C3 Universidad de Chile; Universidad de los Andes - Chile; Utah System of
   Higher Education; Weber State University
RP Saavedra, JM (corresponding author), Univ Los Andes, Fac Ingn & Ciencias Aplicadas, Mons Alvaro del Portillo 124555, Santiago 7620001, RM, Chile.
EM g.martinez.1@ug.uchile.cl; jmsaavedrar@miuandes.cl;
   nmurrugarrallerena@weber.edu
OI Saavedra Rondo, Jose Manuel/0000-0002-9644-5164; Murrugarra-Llerena,
   Nils/0000-0002-0248-6222
CR Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Baevski A, 2022, ARXIV
   Bui T, 2018, COMPUT GRAPH-UK, V71, P77, DOI 10.1016/j.cag.2017.12.006
   Cao ZJ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1653, DOI 10.1145/3240508.3240516
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen XL, 2021, PROC CVPR IEEE, P15745, DOI 10.1109/CVPR46437.2021.01549
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dubey SR, 2022, IEEE T CIRC SYST VID, V32, P2687, DOI 10.1109/TCSVT.2021.3080920
   Ericsson L, 2022, IEEE SIGNAL PROC MAG, V39, P42, DOI 10.1109/MSP.2021.3134634
   Gonzaga VM, 2021, PROCEEDINGS OF THE 27TH BRAZILIAN SYMPOSIUM ON MULTIMEDIA AND THE WEB (WEBMEDIA '21), P216, DOI 10.1145/3470482.3479636
   Gorlich D., 2022, ParadigmPlus, V3, P1, DOI [10.55969/paradigmplus.v3n2a1, DOI 10.55969/PARADIGMPLUS.V3N2A1]
   Grill Jean-Bastien, 2020, ADV NEURAL INFORM PR
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hussain Z, 2017, PROC CVPR IEEE, P1100, DOI 10.1109/CVPR.2017.123
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kruk J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4622
   Li LH, 2022, PROC CVPR IEEE, P10955, DOI 10.1109/CVPR52688.2022.01069
   Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227
   Liu Y., 2019, ROBERTA ROBUSTLY OPT
   Liu Z, 2021, 20 CHINA NATL C 250, P471
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.48550/ARXIV.1802.03426, 10.21105/joss.00861]
   Mery D, 2017, IEEE T SYST MAN CY-S, V47, P682, DOI 10.1109/TSMC.2016.2628381
   Murrugarra-Llerena N, 2021, COMPUT VIS IMAGE UND, V207, DOI 10.1016/j.cviu.2021.103204
   Murrugarra-Llerena N, 2019, PROC CVPR IEEE, P6422, DOI 10.1109/CVPR.2019.00659
   Murrugarra-Llerena Nils, 2018, BRIT MACH VIS C BMVC
   Parkhi OM, 2015, Proceedings of the British Machine Vision Conference, DOI DOI 10.5244/C.29.41
   Radford A, 2021, PR MACH LEARN RES, V139
   Sangkloy P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925954
   Shao Z, 2022, REGION OBJECT RELATI
   Shen YM, 2020, PROC CVPR IEEE, P2815, DOI 10.1109/CVPR42600.2020.00289
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Torres P, 2021, IEEE COMPUT SOC CONF, P2115, DOI 10.1109/CVPRW53098.2021.00240
   Tsagkias Manos, 2020, ACM SIGIR Forum, V54, DOI 10.1145/3451964.3451966
   Tyagi V., 2017, Content-Based Image Retrieval: Ideas, Influences, and Current Trends, DOI DOI 10.1007/978-981-10-6759-4
   Vaswani A, 2017, ADV NEUR IN, V30
   Veit A, 2018, PROC CVPR IEEE, P5919, DOI 10.1109/CVPR.2018.00620
   Velickovic Petar, 2019, ICLR
   Wang RK, 2020, IEEE WINT CONF APPL, P2482, DOI [10.1109/wacv45572.2020.9093468, 10.1109/WACV45572.2020.9093468]
   Wang XF, 2017, LECT NOTES COMPUT SC, V10111, P70, DOI 10.1007/978-3-319-54181-5_5
   Ye KR, 2018, LECT NOTES COMPUT SC, V11219, P868, DOI 10.1007/978-3-030-01267-0_51
   Zheng Q, 2009, INTRODUCTION TO E-COMMERCE, P3, DOI 10.1007/978-3-540-49645-8_1
NR 43
TC 0
Z9 0
U1 5
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 41343
EP 41379
DI 10.1007/s11042-023-14595-8
EA MAR 2023
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000960423600006
DA 2024-07-18
ER

PT J
AU Sharma, MK
   Kumar, V
   Sheet, D
   Biswas, PK
AF Sharma, Manoj Kumar
   Kumar, Vikas
   Sheet, Debdoot
   Biswas, Prabir Kumar
TI Frame-level global context modeling for detection and localization of
   abnormality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Abnormality detection; Localization; Contextual abnormality; Deep
   learning; Image and video processing
ID ANOMALY DETECTION
AB Abnormality detection helps human beings by reducing the amount of data to be processed manually. However, detection and localization of contextual abnormality in image and video sequence have to deal with many challenges. Some object which is normal in one scenario may be considered as abnormal in another. The general solution is to divide the frame into regions or patches, followed by abnormality detection. The performance of the patch-based approach is limited to the size of the context window and suffers from issues of limited field-of-view. It does not consider the information available in the entire frame at a time. Increasing the patch size requires more number-of-nodes to be present in the network, and hence more computation memory is demanded. It also requires significant trainable parameters to train the system. Decreasing the node will reduce the performance and size of the context it can capture. These issues are overcome in the proposed method. The framework combines the convolution neural network and adversarial autoencoder for the localization of contextual abnormality. The spatial arrangement between objects across the different channels in the feature map of CNN is jointly trained from the normal data. The developed framework is further extended to reduce the required trainable parameters, which otherwise becomes a computational challenge. Experimental result outperforms the baseline approach in terms of localizing contextual abnormality.
C1 [Sharma, Manoj Kumar; Sheet, Debdoot; Biswas, Prabir Kumar] Indian Inst Technol Kharagpur, Kharagpur 721302, West Bengal, India.
   [Kumar, Vikas] Homi Bhabha Natl Inst, Indira Gandhi Ctr Atom Res, Chennai, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur; Indira Gandhi Centre for Atomic Research
   (IGCAR); Homi Bhabha National Institute
RP Sharma, MK (corresponding author), Indian Inst Technol Kharagpur, Kharagpur 721302, West Bengal, India.
EM manojsharma.net@gmail.com; vranjan90@gmail.com; debdoot@ee.iitkgp.ac.in;
   pkb@ece.iitkgp.ac.in
RI Kumar, Vikas/E-3272-2018
OI Kumar, Vikas/0000-0002-8062-7123
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   Aggarwal CC, 2014, CH CRC DATA MIN KNOW, P1
   Andrews Jerone, 2016, JMLR
   [Anonymous], 2011, CVPR
   Aytar Y, 2011, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2011.6126504
   Belhadi A, 2022, IEEE T INTELL TRANSP, V23, P9346, DOI 10.1109/TITS.2021.3114064
   Belhadi A, 2021, IEEE T INTELL TRANSP, V22, P4496, DOI 10.1109/TITS.2020.3022612
   Benezeth Y., 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2458, DOI 10.1109/CVPRW.2009.5206686
   Biswas S, 2015, MULTIMED TOOLS APPL, V74, P11099, DOI 10.1007/s11042-014-2219-4
   Boiman O, 2007, INT J COMPUT VISION, V74, P17, DOI 10.1007/s11263-006-0009-9
   Chen BZ, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107209
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Djenouri Y, 2021, ACM T KNOWL DISCOV D, V15, DOI 10.1145/3425867
   Galleguillos C, 2008, PROC CVPR IEEE, P3552
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hajabdollahi M, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101792
   Hayes MA, 2014, IEEE INT CONGR BIG, P64, DOI 10.1109/BigData.Congress.2014.19
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jaechul Kim, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPRW.2009.5206569
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Leach MJV, 2014, PATTERN RECOGN LETT, V44, P71, DOI 10.1016/j.patrec.2013.11.018
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Makhzani A., 2015, ARXIV
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Oh J, 2017, PATTERN RECOGN LETT, V98, P16, DOI 10.1016/j.patrec.2017.08.003
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Popoola OP, 2012, IEEE T SYST MAN CY C, V42, P865, DOI 10.1109/TSMCC.2011.2178594
   Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882
   Reddy V., 2011, Computer Vision and Pattern Recognition Workshops (CVPRW), 2011 IEEE Computer Society Conference on, P55
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sabokrou Mohammad, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P56, DOI 10.1109/CVPRW.2015.7301284
   Sabokrou M, 2018, COMPUT VIS IMAGE UND, V172, P88, DOI 10.1016/j.cviu.2018.02.006
   Sabokrou M, 2017, IEEE T IMAGE PROCESS, V26, P1992, DOI 10.1109/TIP.2017.2670780
   Saligrama V, 2010, IEEE SIGNAL PROC MAG, V27, P18, DOI 10.1109/MSP.2010.937393
   Sharif MU, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577368
   Sharma MK, 2021, MACH VISION APPL, V32, DOI 10.1007/s00138-021-01179-5
   Sharma MK, 2020, ADV INTELL SYST COMP, V1024, P243, DOI 10.1007/978-981-32-9291-8_20
   Sharma MK, 2020, MULTIMED TOOLS APPL, V79, P11237, DOI 10.1007/s11042-020-08786-w
   Sharma M K, 2020, ABNORMALITY DETECTIO
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sodemann AA, 2012, IEEE T SYST MAN CY C, V42, P1257, DOI 10.1109/TSMCC.2012.2215319
   Tommasi T, 2010, PROC CVPR IEEE, P3081, DOI 10.1109/CVPR.2010.5540064
   Xu D., 2015, ARXIV
   Yong SP, 2012, PATTERN RECOGN, V45, P3439, DOI 10.1016/j.patcog.2012.02.036
   Zaharescu A, 2010, LECT NOTES COMPUT SC, V6311, P563, DOI 10.1007/978-3-642-15549-9_41
NR 50
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 38345
EP 38370
DI 10.1007/s11042-023-14575-y
EA MAR 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000958668000008
DA 2024-07-18
ER

PT J
AU Souza, TLD
   Nishijima, M
   Pires, R
AF Souza, Thais Luiza Donega
   Nishijima, Marislei
   Pires, Ricardo
TI Revisiting predictions of movie economic success: random Forest applied
   to profits
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Movie success; Machine learning; Classification; Movie market; Profit;
   Regime change
ID BOX-OFFICE PERFORMANCE; EXPERT REVIEWS; SOCIAL MEDIA; THEATRICAL MOVIES;
   CONSUMER; REVENUES; MODEL; TIME; FILM
AB Previous studies have employed machine learning tools to classify films according to success to guide a reduction in the degree of uncertainty of film production. We revisited the literature to contribute to three relevant issues in classifying films according to economic success. First, we explored the differences between the results of the shortest or longest samples in terms of time to study possible changes in patterns of consumption mainly due to technological changes and between total and wide-released films. Second, we used profits free of price inflation as measures of economic success instead of the usual box office nominal revenues. Third, we employed a smaller set of features, only the ones available at the time of production, to help producers maneuver contingencies since little or nothing can be done by the time a film is in the theaters. We followed the literature to choose the classifiers - Random Forest, Support Vector Machine, and Neural Network - and designed sub-datasets to model and compare the performance of our results. Our dataset includes all films with budgets disclosed at the Box Office Mojo website, resulting in 3167 movies released at theaters worldwide between 1980 and 2019. The Random Forest results outperform previous similar studies with different sampling in time, including results for a less usual larger sample, with the best data sample about 97% both in accuracy and F1-score.
C1 [Souza, Thais Luiza Donega] Univ Sao Paulo, Informat Syst Dept, 1000 Arlindo Bettio Ermelino Matarazzo, Room L1-32, BR-03828000 Sao Paulo, SP, Brazil.
   [Nishijima, Marislei] Univ Sao Paulo, Inst Int Relationships, Ave Prof Lucio Martins Rodrigues, Tv 4&5, Cidade U, BR-05508020 Sao Paulo, SP, Brazil.
   [Pires, Ricardo] Fed Inst Sao Paulo, Dept Elect, R Pedro Vicente 625-Caninde, BR-01109010 Sao Paulo, SP, Brazil.
C3 Universidade de Sao Paulo; Universidade de Sao Paulo; Instituto Federal
   de Sao Paulo (IFSP)
RP Souza, TLD (corresponding author), Univ Sao Paulo, Informat Syst Dept, 1000 Arlindo Bettio Ermelino Matarazzo, Room L1-32, BR-03828000 Sao Paulo, SP, Brazil.
EM thais.donega@usp.br; marislei@usp.br; ricardo_pires@ifsp.edu.br
RI Pires, Ricardo/KAM-3742-2024
OI Pires, Ricardo/0000-0003-4677-8435; Souza, Thais/0000-0002-2879-694X
FU CAPES (Higher Education Improvement Coordination); FAPESP (Sao Paulo
   Research Foundation)
FX This work was supported by CAPES (Higher Education Improvement
   Coordination); and FAPESP (Sao Paulo Research Foundation).
CR Abidi SMR, 2020, MULTIMED TOOLS APPL, V79, P35583, DOI 10.1007/s11042-019-08546-5
   Ahmad J, 2017, INT CONF COMPUT
   Ahmed U, 2020, SOFT COMPUT, V24, P6635, DOI 10.1007/s00500-019-04303-w
   Antipov EA, 2017, J REVENUE PRICING MA, V16, P295, DOI 10.1057/s41272-016-0072-y
   Basu S, 2019, ADV INTELLIGENT SYST
   Bhattacharjee Biplab, 2017, International Journal of Business Information Systems, V24, P344
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Brewer SM, 2009, APPL ECON, V41, P589, DOI 10.1080/00036840601007351
   Casini A., 2019, OXFORD RES ENCY EC F
   Chang BH, 2005, J MEDIA ECON, V18, P247, DOI 10.1207/s15327736me1804_2
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chintagunta PK, 2010, MARKET SCI, V29, P944, DOI 10.1287/mksc.1100.0572
   Derrick FW, 2014, J CULT ECON, V38, P173, DOI 10.1007/s10824-012-9198-y
   Dhir R, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P385, DOI 10.1109/ICSCCC.2018.8703320
   Du JF, 2014, EXPERT SYST APPL, V41, P1680, DOI 10.1016/j.eswa.2013.08.065
   Duan J, 2015, COMM COM INF SC
   Einav L, 2007, RAND J ECON, V38, P127, DOI 10.1111/j.1756-2171.2007.tb00048.x
   Eliashberg J, 1997, J MARKETING, V61, P68, DOI 10.2307/1251831
   Eliashberg J, 2006, MARKET SCI, V25, P638, DOI 10.1287/mksc.1050.0177
   Garikar DD, 2015, IND MANAGE DATA SYST, V115, P1604, DOI 10.1108/IMDS-04-2015-0145
   Ghiassi M, 2015, EXPERT SYST APPL, V42, P3176, DOI 10.1016/j.eswa.2014.11.022
   Ginsburgh V, 2003, J ECON PERSPECT, V17, P99, DOI 10.1257/089533003765888458
   Gislason PO, 2006, PATTERN RECOGN LETT, V27, P294, DOI 10.1016/j.patrec.2005.08.011
   Guo Z, 2015, LECT NOTES COMPUT SC
   Hadida AL, 2010, J CULT ECON, V34, P45, DOI 10.1007/s10824-009-9109-z
   Hastie T., 2009, The Elements of Statistical Learning
   Honthaner EL, 2013, COMPLETE FILM PRODUC
   Hossein N, 2018, INT J INTELL COMPUT, V11, P64, DOI 10.1108/IJICC-04-2017-0033
   Hu YH, 2018, ELECTRON LIBR, V36, P1010, DOI 10.1108/EL-02-2018-0040
   Hur M, 2016, INFORM SCIENCES, V372, P608, DOI 10.1016/j.ins.2016.08.027
   Husak W, 2004, SIGNAL PROCESS-IMAGE, V19, P921, DOI 10.1016/j.image.2004.06.006
   Khalilia M, 2011, BMC MED INFORM DECIS, V11, DOI 10.1186/1472-6947-11-51
   Kim D, 2013, NEW REV HYPERMEDIA M, V19, P259, DOI 10.1080/13614568.2013.835450
   Kim SH, 2013, J MEDIA ECON, V26, P98, DOI 10.1080/08997764.2013.785551
   Kim T, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/4315419
   Kim T, 2015, INT J FORECASTING, V31, P364, DOI 10.1016/j.ijforecast.2014.05.006
   Krauss J., 2008, Predicting movie success and academy awards through sentiment and social network analysis"
   Lash MT, 2016, J MANAGE INFORM SYST, V33, P874, DOI 10.1080/07421222.2016.1243969
   Lee K, 2018, INFORM SYST FRONT, V20, P577, DOI 10.1007/s10796-016-9689-z
   Legoux R, 2016, INT J RES MARK, V33, P357, DOI 10.1016/j.ijresmar.2015.07.003
   Lehrer S, 2017, REV ECON STAT, V99, P749, DOI 10.1162/REST_a_00671
   Leung TC, 2020, REV IND ORGAN, V56, P489, DOI 10.1007/s11151-019-09706-5
   Lipizzi C, 2016, TECHNOL FORECAST SOC, V109, P35, DOI 10.1016/j.techfore.2016.05.013
   LITMAN BR, 1983, J POP CULT, V16, P159, DOI 10.1111/j.0022-3840.1983.1604_159.x
   Liu T, 2016, MULTIMED TOOLS APPL, V75, P1509, DOI 10.1007/s11042-014-2270-1
   LUCAS RE, 1976, CARN ROCH CONF SERIE, V1, P19, DOI 10.1016/S0167-2231(76)80003-6
   Mestyán M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0071226
   Mohanty S, 2018, INT J BUS ANAL, V5, P1, DOI 10.4018/IJBAN.2018010101
   Moon S, 2010, J MARKETING, V74, P108, DOI 10.1509/jmkg.74.1.108
   MPA-Motion Picture Association, 2019, 2019 THEME REP MOT P
   Oh C, 2017, INFORM MANAGE-AMSTER, V54, P25, DOI 10.1016/j.im.2016.03.004
   Pokorny M, 2010, ECON HIST REV, V63, P56, DOI 10.1111/j.1468-0289.2009.00488.x
   Quader N, 2017, 2017 20TH INTERNATIONAL CONFERENCE OF COMPUTER AND INFORMATION TECHNOLOGY (ICCIT)
   Reinstein DA, 2005, J IND ECON, V53, P27, DOI 10.1111/j.0022-1821.2005.00244.x
   Ren Y, 2016, IEEE COMPUT INTELL M, V11, P41, DOI 10.1109/MCI.2015.2471235
   Rhee TG, 2016, 2016 15TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2016), P665, DOI [10.1109/ICMLA.2016.138, 10.1109/ICMLA.2016.0117]
   Riwinoto MT, 2015, J TEKNOL, DOI [10.11113/jt.v77.6693, DOI 10.11113/JT.V77.6693]
   Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7
   Ru YN, 2018, COGN SYST RES, V52, P182, DOI 10.1016/j.cogsys.2018.06.018
   Shapiro C., 1999, Information rules: A strategic guide to the network economy
   Sharda R, 2006, EXPERT SYST APPL, V30, P243, DOI 10.1016/j.eswa.2005.07.018
   Souza TLD, 2019, J CULT ECON, V43, P145, DOI 10.1007/s10824-018-9332-6
   STONE M, 1974, J R STAT SOC B, V36, P111, DOI 10.1111/j.2517-6161.1974.tb00994.x
   Subramaniyaswamy V, 2017, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT SUSTAINABLE SYSTEMS (ICISS 2017), P182, DOI 10.1109/ISS1.2017.8389394
   Tadimari A, 2016, INT CONF ACOUST SPEE, P2777, DOI 10.1109/ICASSP.2016.7472183
   Vany A. de, 1999, Journal of Cultural Economics, V23, P285, DOI 10.1023/A:1007608125988
   Varian HR, 2000, J IND ECON, V48, P473
   Waldfogel J, 2017, J ECON PERSPECT, V31, P195, DOI 10.1257/jep.31.3.195
   Wang Y, 2019, NEURAL COMPUT APPL, V31, P4809, DOI 10.1007/s00521-018-3731-7
   Wang ZY, 2020, INFORM FUSION, V60, P25, DOI 10.1016/j.inffus.2020.02.002
   Wooldridge JM., 2002, BOOKSGOOGLECOM, V58, P752, DOI DOI 10.1515/HUMR.2003.021
   Wu SY, 2019, 2019 IEEE SYMPOSIUM ON PRODUCT COMPLIANCE ENGINEERING - ASIA 2019 (IEEE ISPCE-CN 2019), P17, DOI 10.1109/ispce-cn48734.2019.8958631
   Zhang L, 2009, EXPERT SYST APPL, V36, P6580, DOI 10.1016/j.eswa.2008.07.064
   Zhang Z, 2016, P 2015 8 INT S COMPU
   Zhou Y, 2019, NEURAL COMPUT APPL, V31, P1855, DOI 10.1007/s00521-017-3162-x
NR 77
TC 1
Z9 1
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 38397
EP 38420
DI 10.1007/s11042-023-15169-4
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000958668000009
PM 37362710
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Aliyu, F
   Abdeen, MAR
   Sheltami, T
   Alfraidi, T
   Ahmed, MH
AF Aliyu, Farouq
   Abdeen, Mohammad A. R.
   Sheltami, Tarek
   Alfraidi, Tareq
   Ahmed, Mohamed H.
TI Fog computing-assisted path planning for smart shopping
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; Internet of things; Pervasive computing; Smart cities; Smart
   shopping
ID SYSTEM-DESIGN
AB A Smart City (SC) is a viable solution for green and sustainable living, especially with the current explosion in global population and rural-urban immigration. One of the fields that is not getting much attention in the Smart Economy (SE) is customer satisfaction. The SE is a component of SC that is concerned with using Information and Communication Technology (ICT) to improve stages of the traditional economy. In this paper, we propose a fog computing-based shopping recommendation system. Our simulations used Al-Madinah city as a case study. It aims to improve the customer shopping experience. Customers in shopping malls can connect to the system via Wi-Fi. Then the system recommends products to the shoppers according to their preferences. It optimizes shoppers' schedules using price, the distance between the shops, and the congestion. It also improves customers' savings by up to 30%. It also increases the shopping speed by up to 6.12% compared to the system proposed in the literature.
C1 [Aliyu, Farouq; Sheltami, Tarek] King Fahd Univ Petr & Mineral, Comp Engn Dept, Acad Belt Rd, Dhahran 31261, Saudi Arabia.
   [Abdeen, Mohammad A. R.] Islamic Univ Madinah, Dept Comp Sci, Al Jamiah 42351, Madina, Saudi Arabia.
   [Alfraidi, Tareq] Islamic Univ Madinah, Dept Linguist, Al Jamiah 42351, Madina, Saudi Arabia.
   [Ahmed, Mohamed H.] Univ Ottawa, Sch Elect Engineer & Comp Sci, 75 Laurier Ave East, Ottawa, ON K1N 6N5, Canada.
C3 King Fahd University of Petroleum & Minerals; Islamic University of Al
   Madinah; Islamic University of Al Madinah; University of Ottawa
RP Aliyu, F (corresponding author), King Fahd Univ Petr & Mineral, Comp Engn Dept, Acad Belt Rd, Dhahran 31261, Saudi Arabia.
EM farouq.muhammad@kfupm.edu.sa; mabdeen@iu.edu.sa; tarek@kfupm.edu.sa;
   t.alfraidi@iu.edu.sa; mahme3@uottawa.ca
RI Sheltami, Tarek R/B-6019-2015
OI Sheltami, Tarek R/0000-0002-7879-1469; Aliyu, Farouq/0000-0003-4481-8851
FU Deputyship for Research & Innovation, Ministry of Education in Saudi
   Arabia [15/20]; King Fahd University of Petroleum and Minerals
FX AcknowledgementsThe authors would to acknowledge the support of the
   Deputyship for Research & Innovation, Ministry of Education in Saudi
   Arabia for funding this work through the project number 15/20. The
   authors would like also to acknowledge the support of King Fahd
   University of Petroleum and Minerals.
CR Aliyu F, 2021, FOG COMPUTING ASSIST
   Allam AK, 2020, IKEA FURNITURE KAGGL
   Almalki FA, 2023, MOBILE NETW APPL, V28, P178, DOI 10.1007/s11036-021-01790-w
   Anitta AD, 2021, SMART SHOPPING CART, P301, DOI [10.1109/ICDI3C53598.2021.00067, DOI 10.1109/ICDI3C53598.2021.00067]
   AnyLogic, 2021, ANYLOGIC SIM MOD SOF
   Ayoola AE, 2019, P WORLD C ENG COMP S, P22
   Batra G, 2020, US Patent, Patent No. [10,692,128, 10692128]
   Bellini P, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12031607
   Bita AA, 2021, SUSTAINABLE DEV CITI, P141
   Chen CC, 2014, PERS UBIQUIT COMPUT, V18, P339, DOI 10.1007/s00779-013-0649-z
   Chu THS, 2013, SMART SHOPPING SYSTE, V2202, P239
   Datafiniti.co, 2018, EL PROD PRIC DAT DAT
   Fang YH, 2021, INFORM TECHNOL PEOPL, V34, P731, DOI 10.1108/ITP-05-2019-0208
   Gadgay B, 2021, SMART SHOPPING PROGR, DOI [10.1109/CSITSS54238.2021.9683254, DOI 10.1109/CSITSS54238.2021.9683254]
   Giffinger R., 2007, Cent. Reg. Sci. Vienna UT, P1
   Guan CY, 2019, INT J CLOTH SCI TECH, V31, P376, DOI 10.1108/IJCST-02-2018-0019
   Gunasagar T, 2020, INT J ADV RES ENG TE, V11
   Gundogan K, 2022, SWIFTLY CUSTOMER APP, P1, DOI [10.1145/3524304.3524305, DOI 10.1145/3524304.3524305]
   Gupte Ruchi, 2020, Proceedings of Second International Conference on Inventive Research in Computing Applications (ICIRCA 2020), P400, DOI 10.1109/ICIRCA48905.2020.9183100
   Henning S, 2017, OVERVIEW GLOBAL TREN
   Hussien Naseer Ali, 2020, International Journal of Interactive Mobile Technologies, V14, P17, DOI 10.3991/ijim.v14i04.13511
   Islam MM, 2022, COMPUT BIOL MED, V149, DOI 10.1016/j.compbiomed.2022.106060
   Jain Raj, 1999, ATM Forum Contribut., V99
   Jarir Bookstore, 2021, JARIR
   Javali SKS., 2020, INT J RES ENG SCI MA, V3, P337
   Jayawilal WAH, 2017, 2017 IEEE 13TH MALAYSIA INTERNATIONAL CONFERENCE ON COMMUNICATIONS (MICC), P124, DOI 10.1109/MICC.2017.8311745
   Killamsetty S, 2020, INT J RES APPL SCI E, V8
   Kiran Dendukuri Ravi, 2021, Proceedings of International Conference on Recent Trends in Machine Learning, IoT, Smart Cities and Applications. ICMISC 2020. Advances in Intelligent Systems and Computing (AISC 1245), P543, DOI 10.1007/978-981-15-7234-0_50
   Lakshmi Divya JK., 2022, LECT NOTES DATA ENG, V117, P837, DOI [10.1007/978-981-19-0898-9_63, DOI 10.1007/978-981-19-0898-9_63]
   Lulu Hypermarket, 2021, SHOP GROC ONL LULU H
   Lv ZH, 2021, IEEE COMMUN MAG, V59, P126, DOI 10.1109/MCOM.001.2000945
   Mabilama JM, 2020, PRODUCTS CATALOG FRO
   Maulana F, 2021, SELF CHECKOUT SYSTEM, P273
   Mittal Darshita, 2020, ICT Analysis and Applications. Proceedings of ICT4SD 2019. Lecture Notes in Networks and Systems (LNNS 93), P85, DOI 10.1007/978-981-15-0630-7_9
   Nasir MA., 2022, ANAL VARIANCE INTRO, P148, DOI [10.2174/97898150390231220101, DOI 10.2174/97898150390231220101]
   Nasr M, 2021, IEEE ACCESS, V9, P145248, DOI 10.1109/ACCESS.2021.3118960
   Naveenprabu T, 2020, INT CONF ADVAN COMPU, P426, DOI [10.1109/icaccs48705.2020.9074173, 10.1109/ICACCS48705.2020.9074173]
   Nazim SF., 2022, J SUSTAIN OUTREACH, V3, P19, DOI [10.37357/1068/jso/3.1.02, DOI 10.37357/1068/JSO/3.1.02]
   Pangasa Himani, 2022, Journal of Ambient Intelligence and Humanized Computing, V13, P3883, DOI 10.1007/s12652-022-03904-y
   Panic N, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0083138
   Paul Charles, 2021, 2021 7th International Conference on Advanced Computing and Communication Systems (ICACCS), P522, DOI 10.1109/ICACCS51430.2021.9441762
   Perisa M, 2022, EAI SPRINGER INNOV C, P167, DOI [10.1007/978-3-030-67241-6_14, DOI 10.1007/978-3-030-67241-6_14]
   Sarker IH, 2022, INTERNET THINGS-NETH, V19, DOI 10.1016/j.iot.2022.100528
   Sharma H, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10091012
   Shete V., 2022, REV COMPUT ENG RES, V9, P122, DOI [10.18488/76.v9i2.3083, DOI 10.18488/76.V9I2.3083]
   Shinde S, 2021, ML BASED SMART SHOPP, DOI [10.1109/ICCICT50803.2021.9509938, DOI 10.1109/ICCICT50803.2021.9509938]
   Song H., 2017, Smart Cities: Foundations, Principles, and Applications
   Syed AS, 2021, SMART CITIES-BASEL, V4, P429, DOI 10.3390/smartcities4020024
   Taleb MB, 2021, NOON PERFUME KAGGLE
   Yanfu L., 2020, SMART SHOPPING CART, V16, p420,943
   Yewatkar A, 2016, PROCEDIA COMPUT SCI, V79, P793, DOI 10.1016/j.procs.2016.03.107
NR 51
TC 4
Z9 4
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 38827
EP 38852
DI 10.1007/s11042-023-14926-9
EA MAR 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000956327700007
PM 37362689
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Tao, Y
   Dong, LL
   Xu, LQ
   Chen, GT
   Xu, WH
AF Tao, Ye
   Dong, Lili
   Xu, Luqiang
   Chen, Guangtong
   Xu, Wenhai
TI An effective and robust underwater image enhancement method based on
   color correction and artificial multi-exposure fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Underwater image enhancement; Color-balance; Adaptive reduction
   algorithm; Artificial multi-exposure fusion strategy; Multi-scale fusion
   framework
ID QUALITY ASSESSMENT; MODEL
AB Underwater images/frames are always subjected to color distortion, contrast reduction and detail loss, which degrade the visual quality severely. Current dehazing methods could not improve the visual quality of underwater images/frames robustly and effectively, especially in removing the undesired color cast. To address the issue, this paper introduces an effective and robust underwater image enhancement method without any dedicated hardware or prior knowledge. First, an adaptive reduction operation on the two stronger color-channels of inputs is employed to avoid the red over-compensated deficiency appearing in color-balanced result. Second, three kinds of color-balanced images are generated from the operation, which combines color compensation algorithms and famous Gray-World assumption. Third, a novel algorithm based on two non-reference quantitative evaluation indicators is utilized to choose the optimal color-balancing version. Then, gamma adjustment operation is employed to generate artificial over-/under-exposure visions of color-balancing image. Last, 'exposedness' and 'contrast' are set as two weights, being blended into the famous multi-scale fusion framework to generate the enhanced result. Our experimental results demonstrate the superior performance of the proposed method in both subjective and objective evaluations. Besides, the proposed method is also suitable for dehazing regular fogged images and local feature points matching.
C1 [Tao, Ye; Dong, Lili; Xu, Wenhai] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
   [Tao, Ye; Xu, Luqiang; Chen, Guangtong] Liaoning Port Grp Co Ltd, Ctr Technol, Dalian 116001, Peoples R China.
C3 Dalian Maritime University
RP Tao, Y (corresponding author), Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.; Tao, Y (corresponding author), Liaoning Port Grp Co Ltd, Ctr Technol, Dalian 116001, Peoples R China.
EM taoye@dlmu.edu.cn
OI Tao, Ye/0000-0002-6437-6512
FU National Key Research and Development Program of China [2019YFB1600400];
   Fundamental Research Funds for the Central Universities of China
   [3132019340, 3132019200]; high-tech ship research project from ministry
   of industry and information technology of the people's republic of China
   [MC-201902-C01]
FX AcknowledgementsThe author(s) disclosed receipt of the following
   financial support for the research, authorship, and/or publication of
   this article: This paper is supported by National Key Research and
   Development Program of China under Grant 2019YFB1600400. This paper is
   also supported in part by the Fundamental Research Funds for the Central
   Universities of China under Grant 3132019340 and 3132019200, and
   high-tech ship research project from ministry of industry and
   information technology of the people's republic of China under Grant
   MC-201902-C01.
CR Alex Raj SM, 2016, INT S OCEAN ELECT SY
   Ancuti C, P IEEE COMP SOC C CO, P81
   Ancuti CO, 2020, IEEE COMPUT SOC CONF, P1798, DOI 10.1109/CVPRW50498.2020.00230
   Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Berman D, 2021, IEEE T PATTERN ANAL, V43, P2822, DOI 10.1109/TPAMI.2020.2977624
   BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chen WL, 2020, IEEE T CIRC SYST VID, V30, P334, DOI 10.1109/TCSVT.2019.2890878
   Chen XY, 2021, IEEE T CIRC SYST VID, V31, P594, DOI 10.1109/TCSVT.2020.2980876
   Drews P, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P825, DOI 10.1109/ICCVW.2013.113
   Finlayson GD, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P37
   Fu XY, 2017, I S INTELL SIG PROC, P789, DOI 10.1109/ISPACS.2017.8266583
   Fu XY, 2016, SIGNAL PROCESS, V129, P82, DOI 10.1016/j.sigpro.2016.05.031
   Fu XY, 2014, IEEE IMAGE PROC, P4572, DOI 10.1109/ICIP.2014.7025927
   Galdran A, 2018, SIGNAL PROCESS, V149, P135, DOI 10.1016/j.sigpro.2018.03.008
   Hayat N, 2020, MULTIMED TOOLS APPL, V79, P25067, DOI 10.1007/s11042-020-09190-0
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hung-Yu Yang, 2011, Proceedings of the 2011 2nd International Conference on Innovations in Bio-Inspired Computing and Applications (IBICA 2011), P17, DOI 10.1109/IBICA.2011.9
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Iqbal K, 2010, IEEE INT C SYSTEMS M
   Islam MJ, 2020, ROBOTICS: SCIENCE AND SYSTEMS XVI
   Islam MJ, 2020, IEEE ROBOT AUTOM LET, V5, P3227, DOI 10.1109/LRA.2020.2974710
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li CY, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107038
   Li CY, 2016, INT CONF ACOUST SPEE, P1731, DOI 10.1109/ICASSP.2016.7471973
   Lin WH, 2020, INT CONF ACOUST SPEE, P2588, DOI [10.1109/icassp40776.2020.9053829, 10.1109/ICASSP40776.2020.9053829]
   Liu K, 2021, DEHAZING ENHANCEMENT
   Liu RS, 2020, IEEE T CIRC SYST VID, V30, P4861, DOI 10.1109/TCSVT.2019.2963772
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Marini D, LECT NOTES COMPUTER, V1310, P62
   Marques TP, 2020, IEEE COMPUT SOC CONF, P2286, DOI 10.1109/CVPRW50498.2020.00277
   Mertens T, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P382, DOI 10.1109/PG.2007.17
   Panetta K, 2016, IEEE J OCEANIC ENG, V41, P541, DOI 10.1109/JOE.2015.2469915
   Pizer S. M., 1990, Proceedings of the First Conference on Visualization in Biomedical Computing (Cat. No.90TH0311-1), P337, DOI 10.1109/VBC.1990.109340
   Song W, 2020, IEEE T BROADCAST, V66, P153, DOI 10.1109/TBC.2019.2960942
   Song W, 2018, LECT NOTES COMPUT SC, V11164, P678, DOI 10.1007/978-3-030-00776-8_62
   Van de Weijer J, 2007, IEEE T IMAGE PROCESS, V16, P2207, DOI 10.1109/TIP.2007.901808
   Wang Y, 2019, IEEE ACCESS, V7, P140233, DOI 10.1109/ACCESS.2019.2932130
   Wang Y, 2018, COMPUT ELECTR ENG, V70, P904, DOI 10.1016/j.compeleceng.2017.12.006
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wen HC, 2013, IEEE INT SYMP CIRC S, P753, DOI 10.1109/ISCAS.2013.6571956
   Williams SB, 2012, IEEE ROBOT AUTOM MAG, V19, P73, DOI 10.1109/MRA.2011.2181772
   Yan H, 2020, ADV MATER INTERFACES, V7, DOI 10.1002/admi.202000966
   Yang K, 2019, OPTICS INFOBASE C F
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
   Zhang H, LECT NOTES COMPUTER, V11717, P67
   Zhuang PX, 2021, ENG APPL ARTIF INTEL, V101, DOI 10.1016/j.engappai.2021.104171
NR 48
TC 4
Z9 4
U1 5
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 24
PY 2023
DI 10.1007/s11042-023-15153-y
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA A6PS9
UT WOS:000956328600002
DA 2024-07-18
ER

PT J
AU Gautam, A
   Rana, D
   Aggarwal, S
   Bhosle, S
   Sharma, H
AF Gautam, Anjali
   Rana, Divyesh
   Aggarwal, Saksham
   Bhosle, Swaraj
   Sharma, Hritik
TI Deep learning approach to automatically recognise license number plates
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ANPR; Plate recognition; Rectification; Convolutional Neural Networks
   (CNNs); Prediction; Recognition
ID NEURAL-NETWORK
AB Automatic Number Plate Recognition (ANPR) has become an important aspect in our daily life because of unlimited increase of vehicles and transportation system. This makes it more and more difficult to fully manage and monitor by humans. Due to the diversity of license plates formats, varying scales and sizes, different angles, illuminations, this is quite a challenging problem in the area of computer vision. In this paper, we have proposed methods for automatic detection of a license plate from an image, which is followed by plate correction, or in other words, plate rectification. Thereafter, character recognition methodology has been applied to identify characters from the number plate. Convolutional Neural Networks (CNNs) based approach is used to locate corner points of license plate image, after that plate rectification done using perspective transformation. The CNNs models for locating corner points are neural networks for regression. Here, the loss function is based on an average sum of Euclidean distance between predicted corner points and actual corner points, the loss function is also known as the mean squared error function. The results show that our CNNs models are able to accurately predict corner points from number plate. Furthermore, an optical character recognition (OCR) model is used to identify characters from the plate. The developed methodology shows excellent results on the Chinese City Parking Dataset (CCPD).
C1 [Gautam, Anjali; Rana, Divyesh; Aggarwal, Saksham; Bhosle, Swaraj; Sharma, Hritik] Indian Inst Informat Technol Allahabad, Dept Informat Technol, Prayagraj, India.
C3 Indian Institute of Information Technology Allahabad
RP Gautam, A (corresponding author), Indian Inst Informat Technol Allahabad, Dept Informat Technol, Prayagraj, India.
EM anjaligautam@iiita.ac.in
CR Abolghasemi V, 2009, IMAGE VISION COMPUT, V27, P1134, DOI 10.1016/j.imavis.2008.10.012
   [Anonymous], 2020, CAR LICENSE PLATES D
   Bradski G., 2000, Opencv. Dr. Dobb's journal of software tools
   Dalarmelina ND, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010055
   DAVIES ER, 1989, PATTERN RECOGN LETT, V9, P181, DOI 10.1016/0167-8655(89)90053-6
   Du S, 2013, IEEE T CIRC SYST VID, V23, P322, DOI 10.1109/TCSVT.2012.2203741
   Farhat A, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0298-2
   Gan Vi Vi, 2022, Recent Trends in Mechatronics Towards Industry 4.0: Selected Articles from iM3F 2020, Malaysia. Lecture Notes in Electrical Engineering (730), P617, DOI 10.1007/978-981-33-4597-3_56
   Giannoukos I, 2010, PATTERN RECOGN, V43, P3866, DOI 10.1016/j.patcog.2010.06.008
   Graves A, 2012, STUD COMPUT INTELL, V385, P61
   Hsu GS, 2013, IEEE T VEH TECHNOL, V62, P552, DOI 10.1109/TVT.2012.2226218
   Huang J., 2017, CVPR
   Huang QY, 2021, IEEE T MULTIMEDIA, V23, P3768, DOI 10.1109/TMM.2020.3031074
   ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1
   Jia WJ, 2006, INT C PATT RECOG, P574
   Kabiraj A, 2023, MULTIMED TOOLS APPL, V82, P13837, DOI 10.1007/s11042-022-14018-0
   Khan MA, 2018, IET IMAGE PROCESS, V12, P200, DOI 10.1049/iet-ipr.2017.0368
   Khan MG, 2022, IEEE ACCESS, V10, P64172, DOI 10.1109/ACCESS.2022.3183101
   Kim DS, 2001, ISIE 2001: IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS PROCEEDINGS, VOLS I-III, P2022, DOI 10.1109/ISIE.2001.932025
   Kim KK, 2000, NEURAL NETWORKS FOR SIGNAL PROCESSING X, VOLS 1 AND 2, PROCEEDINGS, P614, DOI 10.1109/NNSP.2000.890140
   Kong XJ, 2021, IEEE T IND INFORM, V17, P8523, DOI 10.1109/TII.2021.3067324
   Lubna, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093028
   Modi Nipa D., 2011, 2011 International Conference on Communication Systems and Network Technologies (CSNT), P339, DOI 10.1109/CSNT.2011.77
   N Kamal N., 2021, PARTICUL SCI TECHNOL, V39, P101, DOI [10.30684/etj.v39i1B.1839, DOI 10.30684/ETJ.V39I1B.1839]
   Nur-A-Alam NA, 2021, TECHNOLOGIES, V9, DOI 10.3390/technologies9010009
   Pan MS, 2009, INT J AUTOM COMPUT, V6, P210, DOI 10.1007/s11633-009-0210-8
   Pustokhina IV, 2020, IEEE ACCESS, V8, P92907, DOI 10.1109/ACCESS.2020.2993008
   Rajput H, 2015, COMPUTER, V48, P56, DOI 10.1109/MC.2015.244
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Silva SM, 2022, IEEE T INTELL TRANSP, V23, P5693, DOI 10.1109/TITS.2021.3055946
   Silva SM, 2018, LECT NOTES COMPUT SC, V11216, P593, DOI 10.1007/978-3-030-01258-8_36
   Tang JJ, 2021, TRANSPORTMETRICA A, V17, P1217, DOI 10.1080/23249935.2020.1845250
   Wang WW, 2019, IEEE ACCESS, V7, P173875, DOI 10.1109/ACCESS.2019.2956357
   Xiaoyu Zhang, 2021, 2021 IEEE 2nd International Conference on Pattern Recognition and Machine Learning (PRML), P342, DOI 10.1109/PRML52754.2021.9520386
   Xu H, 2021, INT C PATT RECOG, P202, DOI 10.1109/ICPR48806.2021.9413152
   Xu ZB, 2018, LECT NOTES COMPUT SC, V11217, P261, DOI 10.1007/978-3-030-01261-8_16
   Yang X., 2019, ARXIV
   Yoo H, 2021, MULTIMEDIA SYST, V27, P779, DOI 10.1007/s00530-020-00655-8
   Zhang LJ, 2021, IEEE T INTELL TRANSP, V22, P6967, DOI 10.1109/TITS.2020.3000072
   Zhang YX, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2019), P137, DOI [10.1109/SIPROCESS.2019.8868545, 10.1109/siprocess.2019.8868545]
NR 41
TC 3
Z9 3
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31487
EP 31504
DI 10.1007/s11042-023-15020-w
EA MAR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000952258900001
DA 2024-07-18
ER

PT J
AU Mistry, YD
   Birajdar, GK
   Khodke, AM
AF Mistry, Yogita D. D.
   Birajdar, Gajanan K. K.
   Khodke, Archana M. M.
TI Time-frequency visual representation and texture features for audio
   applications: a comprehensive review, recent trends, and challenges
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Time-frequency representation; Time-frequency texture image;
   Spectrogram; Cochleagram; Textural features; Audio classification;
   Acoustic scene classifcation; Music genre classification
ID IMAGE FEATURE; EVENT CLASSIFICATION; FEATURE-EXTRACTION; ACOUSTIC
   FEATURES; SPECTROGRAM; SPEECH; RECOGNITION; BIRD
AB The conventional audio feature extraction methods employed in the audio analysis are categorized into time-domain and frequency-domain. Recently, a new audio feature extraction approach using time-frequency texture image is developed and utilized for different applications. In this approach, the input audio signal is first converted into a time-frequency image, and then textural features are extracted from the visual representation. The distinctive two-dimensional time-frequency visualization textural descriptors can produce better features for improved audio detection and classification. In this article, a comprehensive review of state-of-the-art techniques used for audio detection and classification is presented. The generalized architecture of time-frequency texture feature extraction approaches in audio classification algorithms is presented first. Based on a review of over 70 papers, the key contributions in the area of time-frequency representations of various researchers are highlighted in addition to the textural features. This survey also compares and analyzes the existing experimental algorithms proposed for various audio classification tasks. Finally, the critical challenges and limitations with different visual representations are highlighted, along with potential future research directions.
C1 [Mistry, Yogita D. D.; Birajdar, Gajanan K. K.; Khodke, Archana M. M.] DY Patil Deemed Univ, Ramrao Adik Inst Technol, Dept Elect Engn, Navi Mumbai 400706, Maharashtra, India.
RP Birajdar, GK (corresponding author), DY Patil Deemed Univ, Ramrao Adik Inst Technol, Dept Elect Engn, Navi Mumbai 400706, Maharashtra, India.
EM yogita.mistry@rait.ac.in; gajanan.birajdar@rait.ac.in;
   archana.khodke@rait.ac.in
RI Birajdar, Gajanan/Z-1937-2018
OI Birajdar, Gajanan/0000-0003-3531-3958
CR Abidin S., 2018, 2018 IEEE INT C MULT, P1, DOI DOI 10.1109/ICME.2018.8486578
   Abidin S, 2018, IEEE-ACM T AUDIO SPE, V26, P2112, DOI 10.1109/TASLP.2018.2854861
   Abidin S, 2017, INT CONF ACOUST SPEE, P626, DOI 10.1109/ICASSP.2017.7952231
   Agera N, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P822, DOI 10.1109/ICCUBEA.2015.164
   Ahmed F, 2016, SMART INNOV SYST TEC, V57, P455, DOI 10.1007/978-3-319-39627-9_40
   Alam MS, 2018, IET SIGNAL PROCESS, V12, P260, DOI 10.1049/iet-spr.2017.0170
   Battaglino D, 2015, IEEE WORK APPL SIG
   Bhattacharjee M., 2018, TIME FREQUENCY AUDIO
   Bhatti UA, 2021, IEEE PHOTONICS J, V13, DOI 10.1109/JPHOT.2021.3059703
   Bhatti UA, 2020, IEEE ACCESS, V8, P155783, DOI 10.1109/ACCESS.2020.3018544
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Birajdar GK, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-022-03781-5
   Birajdar GK, 2020, J AMB INTEL HUM COMP, V11, P329, DOI 10.1007/s12652-019-01303-4
   Birajdar GK, 2019, MULTIMED TOOLS APPL, V78, P15141, DOI 10.1007/s11042-018-6899-z
   Bisot V, 2015, EUR SIGNAL PR CONF, P719, DOI 10.1109/EUSIPCO.2015.7362477
   Breve B, 2020, 26 INT C DISTRIBUTED, P49, DOI [10.18293/DMSVIVA20-011, DOI 10.18293/DMSVIVA20-011]
   Breve B, 2022, MULTIMED TOOLS APPL, V81, P73, DOI 10.1007/s11042-021-11077-7
   Chen Y, 2019, PRECIS ENG, V56, P235, DOI 10.1016/j.precisioneng.2018.12.004
   Chowdhury AA, 2020, J EXP THEOR ARTIF IN, V32, P111, DOI 10.1080/0952813X.2019.1631392
   CONNOLLY JH, 1986, INT J MAN MACH STUD, V24, P611, DOI 10.1016/S0020-7373(86)80012-8
   Costa Y., 2013, Prog. Pattern Recognit. Image Anal. Comput. Vis. and Appl, P67
   Costa YMG, 2012, SIGNAL PROCESS, V92, P2723, DOI 10.1016/j.sigpro.2012.04.023
   Costa Y.M.G., 2011, 2011 18th International Conference on Systems, Signals and Image Processing, P1
   Costa Y, 2013, INT CONF SYST SIGNAL, P55, DOI 10.1109/IWSSIP.2013.6623448
   Costa YMG, 2012, NEUR NETW IJCNN 2012, P1, DOI [10.1109/IJCNN.2012.6252626, DOI 10.1109/IJCNN.2012.6252626]
   Demir F, 2018, IEEE ENG MED BIO, P413, DOI 10.1109/EMBC.2018.8512459
   Dennis J, 2013, IEEE T AUDIO SPEECH, V21, P367, DOI 10.1109/TASL.2012.2226160
   Dennis J, 2011, IEEE SIGNAL PROC LET, V18, P130, DOI 10.1109/LSP.2010.2100380
   Dutta A, 2022, INTERNET TECHNOL LET, V5, DOI 10.1002/itl2.191
   Felipe G.Z., 2017, 2017 36 INT C CHILEA, P1, DOI DOI 10.1109/SCCC.2017.8405119
   Felipe GZ, 2019, INT CONF SYST SIGNAL, P181, DOI 10.1109/IWSSIP.2019.8787318
   GHOSAL A., 2012, Proceedings of the CUBE International Information Technology Conference, P21, DOI [10.1145/2381716.2381722, DOI 10.1145/2381716.2381722]
   Godbole Shubham, 2020, ITM Web of Conferences, V32, DOI 10.1051/itmconf/20203201010
   Haiqian Wu, 2013, Advanced Materials Research, V756-759, P4407, DOI 10.4028/www.scientific.net/AMR.756-759.4407
   Jassim WA, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5524, DOI 10.1109/ICASSP.2018.8461952
   Jog AH, 2018, 2018 15 IEEE IND COU, P1, DOI [10.1109/INDICON45594.2018.8987167, DOI 10.1109/INDICON45594.2018.8987167]
   KLATT DH, 1973, IEEE T ACOUST SPEECH, VAU21, P210, DOI 10.1109/TAU.1973.1162453
   Kobayashi Takumi, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3052, DOI 10.1109/ICASSP.2014.6854161
   Lacerda EB, 2017, PROCEDIA COMPUT SCI, V112, P2204, DOI 10.1016/j.procs.2017.08.115
   Li Y, 2019, CHINESE J ELECTRON, V28, P667, DOI 10.1049/cje.2019.04.005
   Lim H, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3325
   Matsui T, 2011, EUR SIGNAL PR CONF, P724
   McLoughlin I, 2020, CIRC SYST SIGNAL PR, V39, P1672, DOI 10.1007/s00034-019-01203-0
   Ming-Ju Wu, 2011, Proceedings of the 2011 Tenth International Conference on Machine Learning and Applications (ICMLA 2011), P124, DOI 10.1109/ICMLA.2011.48
   Montalvo A, 2015, LECT NOTES COMPUT SC, V9423, P543, DOI 10.1007/978-3-319-25751-8_65
   Mostafa TA, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21196446
   Mulimani M, 2019, APPL ACOUST, V155, P130, DOI 10.1016/j.apacoust.2019.05.020
   Nanni L, 2017, PATTERN RECOGN LETT, V88, P49, DOI 10.1016/j.patrec.2017.01.013
   Nanni L., 2014, Set of texture descriptors for music genre classification
   Nanni L, 2018, J NEW MUSIC RES, V47, P383, DOI 10.1080/09298215.2018.1438476
   Nanni L, 2018, IET COMPUT VIS, V12, P178, DOI 10.1049/iet-cvi.2017.0075
   Nanni L, 2016, PROC INT C TOOLS ART, P396, DOI [10.1109/ICTAI.2016.64, 10.1109/ICTAI.2016.0067]
   Nanni L, 2016, EXPERT SYST APPL, V45, P108, DOI 10.1016/j.eswa.2015.09.018
   Oo MM, 2020, INT C SOFTW ENG RES, P175, DOI [10.1007/978-3-030-24344-9-11, DOI 10.1007/978-3-030-24344-9_11]
   Özseven T, 2018, APPL ACOUST, V142, P70, DOI 10.1016/j.apacoust.2018.08.003
   Rahmeni R, 2019, I C SCI TECH AUTO CO, P501, DOI [10.1109/sta.2019.8717297, 10.1109/STA.2019.8717297]
   Rakotomamonjy A, 2015, IEEE-ACM T AUDIO SPE, V23, P142, DOI 10.1109/TASLP.2014.2375575
   Ren JF, 2017, IEEE T MULTIMEDIA, V19, P447, DOI 10.1109/TMM.2016.2618218
   Sell Gregory, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2489, DOI 10.1109/ICASSP.2014.6854048
   Sharan RV, 2018, APPL ACOUST, V140, P198, DOI 10.1016/j.apacoust.2018.05.030
   Sharan RV, 2019, IEEE T BIO-MED ENG, V66, P485, DOI 10.1109/TBME.2018.2849502
   Sharan RV, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P432, DOI 10.1109/ICDSP.2015.7251908
   Sharan RV, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P441, DOI 10.1109/ICDSP.2015.7251910
   Sharan RV, 2015, INT CONF ACOUST SPEE, P1956, DOI 10.1109/ICASSP.2015.7178312
   Sharan RV, 2015, NEUROCOMPUTING, V158, P90, DOI 10.1016/j.neucom.2015.02.001
   Sharan RV, 2014, INT CONF DIGIT SIG, P130, DOI 10.1109/ICDSP.2014.6900815
   Sharma G, 2020, APPL ACOUST, V158, DOI 10.1016/j.apacoust.2019.107020
   Shi XR, 2015, IET RADAR SONAR NAV, V9, P1251, DOI 10.1049/iet-rsn.2014.0432
   Spyrou E, 2019, TECHNOLOGIES, V7, DOI 10.3390/technologies7010020
   Valerio VD, 2018, 31 INT FLORIDA ARTIF, P500
   Vyas S., 2021, COMPUTATIONAL INTELL, P81, DOI DOI 10.1002/9781119818717.CH5
   Wakefield GH, 1999, P SOC PHOTO-OPT INS, V3807, P637, DOI 10.1117/12.367679
   Wu HQ, 2012, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION APPLICATIONS (ICCIA 2012), P419
   Wu MJ, 2015, ACM T MULTIM COMPUT, V12, DOI 10.1145/2801127
   Xie J, 2019, EXPERT SYST APPL, V126, P20, DOI 10.1016/j.eswa.2019.01.085
   Yang WJ, 2017, IEEE-ACM T AUDIO SPE, V25, P1315, DOI 10.1109/TASLP.2017.2690558
   Yang XY, 2018, PROCEEDINGS OF 2018 10TH INTERNATIONAL CONFERENCE ON COMPUTER AND AUTOMATION ENGINEERING (ICCAE 2018), P75, DOI 10.1145/3192975.3193006
   Yasmin Ghazaala, 2019, Recent Trends in Signal and Image Processing. ISSIP 2017. Advances in Intelligent Systems and Computing (AISC 727), P197, DOI 10.1007/978-981-10-8863-6_20
   Ye JX, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1291, DOI 10.1145/2733373.2806389
   Yu GS, 2009, INT CONF ACOUST SPEE, P1677, DOI 10.1109/ICASSP.2009.4959924
   Zhang SH, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P271, DOI 10.1109/ICASSP.2018.8462156
   Zhang YH, 2021, APPL ACOUST, V178, DOI 10.1016/j.apacoust.2021.107970
   Zhang YJ, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9010023
   Zottesso RHD, 2018, ECOL INFORM, V48, P187, DOI 10.1016/j.ecoinf.2018.08.007
   Zue V. W., 1979, ICASSP 79. 1979 IEEE International Conference on Acoustics, Speech and Signal Processing, P116
   Zue V. W., 1986, ICASSP 86 Proceedings. IEEE-IECEJ-ASJ International Conference on Acoustics, Speech and Signal Processing (Cat. No.86CH2243-4), P1197
NR 86
TC 1
Z9 1
U1 18
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 36143
EP 36177
DI 10.1007/s11042-023-14734-1
EA MAR 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000950429600008
DA 2024-07-18
ER

PT J
AU Rajpoot, V
   Tiwari, A
   Jalal, AS
AF Rajpoot, Vikram
   Tiwari, Akhilesh
   Jalal, Anand Singh
TI Automatic early detection of rice leaf diseases using hybrid deep
   learning and machine learning methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Plant Disease; Rice leaf disease; Machine learning; Deep Learning;
   Faster R-CNN; VGG-16; Random Forest
ID RECOMMENDATION SYSTEM
AB Plant leaf disease detection is critical for long-term agricultural viability. Numerous Artificial Intelligence (AI) and Machine Learning (ML) technologies have been implemented for detecting rice diseases. However, such methods failed to identify or have slow recognition causing severe output loss. Therefore, an advanced and precise detection method has become necessary to overcome this issue. This study analyzes plant diseases that affect rice, comprising three different forms of diseases. Bacterial leaf blight, Brown spot, and Leaf smut are three of the six diseases that can affect rice plants. In the proposed approach a VGG-16 transfer learning with Faster R-CNN deep architecture is used to extract features. After completing the transfer learning step, the gathered characteristics are categorized using the random forest method. The random forest classifier divided the radish field into three distinct regions. The images of rice plant leaves are taken from UCI Machine Learning Repository. The proposed approach obtains an average predicting accuracy of 97.3% for rice disease imagery class prediction. The extensive experiment outcomes demonstrate the suggested technique's validity, so it effectively detects rice diseases.
C1 [Rajpoot, Vikram; Tiwari, Akhilesh] Madhav Inst Sci & Technol, Dept Informat Technol, Gwalior, Madhya Pradesh, India.
   [Jalal, Anand Singh] GLA Univ, Dept Comp Engn & Applicat, Mathura, Uttar Pradesh, India.
C3 Madhav Institute of Technology & Science; GLA University
RP Jalal, AS (corresponding author), GLA Univ, Dept Comp Engn & Applicat, Mathura, Uttar Pradesh, India.
EM vikramraj@mitsgwalior.in; atiwari@mitsgwalior.in; asjalal@gla.ac.in
RI Tiwari, Akhilesh/AAE-5437-2021
OI Jalal, Anand/0000-0002-7469-6608
CR Abduljabbar R, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11010189
   Ahmed KT, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCIS), P162, DOI 10.1109/iccisci.2019.8716437
   Anari MS, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/6504616
   Anjna, 2020, PROCEDIA COMPUT SCI, V167, P1056, DOI 10.1016/j.procs.2020.03.404
   [Anonymous], 2020, Geeksforgeeks
   Baranwal S, 2019, P INT C SUST COMP SC, DOI [10.2139/ssrn.3351641, DOI 10.2139/SSRN.3351641]
   Barbosa A, 2020, COMPUT ELECTRON AGR, V170, DOI 10.1016/j.compag.2019.105197
   Bari BS, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.432
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2022, ENVIRON SCI POLLUT R, V29, P14780, DOI 10.1007/s11356-021-16627-y
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhatti UA, 2018, HUM VACC IMMUNOTHER, V14, P165, DOI 10.1080/21645515.2017.1379639
   Bhavatarini CMT., 2020, INT J MACH LEARN CYB, V11, P1021
   Bigirimana VD, 2015, FRONT PLANT SCI, V6, DOI 10.3389/fpls.2015.01066
   Bohra J., 2018, INT J CHEM STUD, V6, P1721
   Chaudhari AK, 2019, INT J CURR MICROBIOL, DOI [10.20546/ijcmas.2019.806.337, DOI 10.20546/IJCMAS.2019.806.337]
   Chen JD, 2020, J SCI FOOD AGR, V100, P3246, DOI 10.1002/jsfa.10365
   Chokey T, 2019, PROCEEDINGS 2019 AMITY INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AICAI), P259, DOI [10.1109/aicai.2019.8701294, 10.1109/AICAI.2019.8701294]
   Chopda J, 2018, COTTON CROP DIS DETE, DOI [10.1109/ICSCET.2018.8537336, DOI 10.1109/ICSCET.2018.8537336]
   Cynthia ST, 2019, AUTOMATED DETECTION, DOI [10.1109/STI47673.2019.9068092, DOI 10.1109/STI47673.2019.9068092]
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Ginanni K, 2004, J ACAD LIBR, V30, P249
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Govardhan M, 2019, DIAGNOSIS TOMATO PLA, DOI [10.1109/GCAT47503.2019.8978431, DOI 10.1109/GCAT47503.2019.8978431]
   Hasan MJ, 2019, RICE DIS IDENTIFICAT, DOI [10.1109/ICASERT.2019.8934568, DOI 10.1109/ICASERT.2019.8934568]
   Johannes A, 2017, COMPUT ELECTRON AGR, V138, P200, DOI 10.1016/j.compag.2017.04.013
   Kamal KC, 2019, COMPUT ELECTRON AGR, V165, DOI 10.1016/j.compag.2019.104948
   Kim WS, 2020, COMPUT ELECTRON AGR, V168, DOI 10.1016/j.compag.2019.105099
   Krishnamoorthy N, 2021, ENVIRON RES, V198, DOI 10.1016/j.envres.2021.111275
   Kusumo BS, 2018, 2018 INTERNATIONAL CONFERENCE ON COMPUTER, CONTROL, INFORMATICS AND ITS APPLICATIONS (IC3INA), P93, DOI 10.1109/IC3INA.2018.8629507
   Lee SH, 2020, COMPUT ELECTRON AGR, V170, DOI 10.1016/j.compag.2020.105220
   Lu Y, 2017, NEUROCOMPUTING, V267, P378, DOI 10.1016/j.neucom.2017.06.023
   Maniyath SR, 2018, PLANT DIS DETECTION, DOI [10.1109/ICDI3C.2018.00017, DOI 10.1109/ICDI3C.2018.00017]
   Nanjundan J, 2020, PLANT PATHOLOGY J, V36, P111, DOI 10.5423/PPJ.OA.07.2019.0205
   Naqvi Syed Atif Hasan, 2019, Pakistan Journal of Agricultural Research, V32, P359, DOI 10.17582/journal.pjar/2019/32.2.359.380
   Pandian JA, 2019, INT CONF ADV COMPU, P199, DOI [10.1109/IACC48062.2019.8971580, 10.1109/iacc48062.2019.8971580]
   Prajapati HB, 2017, INTELL DECIS TECHNOL, V11, P357, DOI 10.3233/IDT-170301
   Ram Singh Ram Singh, 2016, Indian Phytopathology, V69, P340
   Ramesh S, 2018, RICE BLAST DIS DETEC, DOI [10.1109/ICMETE.2018.00063, DOI 10.1109/ICMETE.2018.00063]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandika B, 2017, INT C SIGN PROC P IC, DOI [DOI 10.1109/ICSP.2016.7878133, 10.1109/icsp.2016.7878133]
   Shahriar SA, 2020, Annu. Res. Rev. Biol., P50, DOI [10.9734/ARRB/2020/v35i130180, DOI 10.9734/ARRB/2020/V35I130180]
   Sharif M, 2018, COMPUT ELECTRON AGR, V150, P220, DOI 10.1016/j.compag.2018.04.023
   SHARMA P, 2020, CONFLUENCE, DOI [DOI 10.1109/CONFLUENCE47617.2020.9057889, 10.1109/Confluence47617.2020.9057889]
   SHRUTHI U, 2019, 5 INT C ADV COMP COM, DOI [10.1109/ICACCS.2019.8728415, DOI 10.1109/ICACCS.2019.8728415]
   Singh AK, 2022, J FOOD QUALITY, V2022, DOI 10.1155/2022/2845320
   Singh R, 2017, ENERGY ECOL ENVIRON, V2, P296, DOI 10.1007/s40974-017-0074-7
   Sinha Khushbu, 2022, Cognitive Informatics and Soft Computing: Proceeding of CISC 2021. Lecture Notes in Networks and Systems (375), P467, DOI 10.1007/978-981-16-8763-1_38
   Tian K, 2019, COMPUT ELECTRON AGR, V165, DOI 10.1016/j.compag.2019.104962
   Truong T, 2017, IOT ENV DATA COLLECT, DOI [10.1109/CCECE.2017.7946787, DOI 10.1109/CCECE.2017.7946787]
   Verma G, 2019, VISION BASED DETECTI, DOI [10.1109/ICon-CuTE47290.2019.8991476, DOI 10.1109/ICON-CUTE47290.2019.8991476]
NR 53
TC 4
Z9 5
U1 7
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 36091
EP 36117
DI 10.1007/s11042-023-14969-y
EA MAR 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000949737400001
DA 2024-07-18
ER

PT J
AU Su, LY
   Yin, ML
   Zhao, SL
AF Su, Liyun
   Yin, Mingliang
   Zhao, Shengli
TI PSR-LSTM model for weak pulse signal detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Phase space reconstruction; LSTM; Weak pulse signal; Rolling bearing
   fault diagnosis
AB In this paper, a weak impulse signal detection method based on phase space reconstruction of chaotic time series and long-term and short-term memory neural network (LSTM) in the deep learning model is proposed. Reconstructing the phase space of chaotic signals can effectively extract the chaotic information in the sequence, and constructing LSTM neural network can effectively distinguish the signal points from the non-signal points to achieve better detection results. When detecting the weak pulse signal in Lorenz chaotic system and Rossler chaotic system, the model has high detection accuracy and can still maintain the detection performance when the signal-to-noise ratio is low. This paper compares it with other machine learning models and deep learning models, such as Support Vector Machine (SVM), Recurrent Neural Network (RNN), Extreme Learning Machine (ELM), and so on. The results show that the detection accuracy of this model is higher than other comparable models under different signal-to-noise ratios and has strong detection performance. In addition, the weak pulse signal in the sunspot sequence is detected, and the fault signal in the rolling bearing is diagnosed. These results show that this model can accurately detect the weak pulse signal in the chaotic background when the signal-to-noise ratio is low and is suitable for dealing with the weak signal detection problem in the chaotic background in real life and the fault diagnosis problem in the engineering application field. This not only reduces the detection threshold of weak signal detection but also widens the application field of weak signal detection.
C1 [Su, Liyun; Yin, Mingliang; Zhao, Shengli] Chongqing Univ Technol, Sch Sci, Chongqing 400054, Peoples R China.
C3 Chongqing University of Technology
RP Su, LY (corresponding author), Chongqing Univ Technol, Sch Sci, Chongqing 400054, Peoples R China.
EM cloudhopping@163.com; 1351563821@qq.com; zhaoshengli@cqut.edu.cn
RI su, liyun/IXD-5997-2023
FU National Natural Science Foundation of China [11871124]; Chongqing
   Education Commission [KJQN202101125]
FX AcknowledgmentsThis study is supported by the National Natural Science
   Foundation of China (Grant No.11871124) and the Chongqing Education
   Commission (Grant KJQN202101125).Data and program availabilityThe data
   used to support the findings of this study and the program in this study
   are available from the corresponding author upon request.
CR Ahmed R, 2022, DIGIT SIGNAL PROCESS, V120, DOI 10.1016/j.dsp.2021.103290
   Cai KH., 2021, J HEALTHC ENG, V2021, P32
   Cao LY, 1997, PHYSICA D, V110, P43, DOI 10.1016/S0167-2789(97)00118-8
   Charnbon S, 2019, J NEUROSCI METH, V321, P64, DOI 10.1016/j.jneumeth.2019.03.017
   Chen ZY, 2021, ELECTROMAGNETIC INTE, DOI [10.26969/d.cnki.gbydu.2021.001675, DOI 10.26969/D.CNKI.GBYDU.2021.001675]
   Deng L, 2020, STAT DETECTION ESTIM, DOI [10.27753/d.cnki.gcqgx.2020.000079, DOI 10.27753/D.CNKI.GCQGX.2020.000079]
   Fan J., 2003, NONLINEAR TIME SERIE, DOI [DOI 10.1007/978-0-387-69395-8, 10.1007/978-0-387-69395-8]
   Feng H., 2008, J HEBEI N U NAT SCI, V24, P29
   Glenn CM, 1996, IEEE MTT-S, P1883, DOI 10.1109/MWSYM.1996.512314
   Guo, 2017, RES METHODOLOGY WEAK
   HAYKIN S, 1995, P IEEE, V83, P95, DOI 10.1109/5.362751
   He JB., 2011, ACTA PHYS SIN-CH ED, V60, P50
   Rodríguez PH, 2013, ISA T, V52, P278, DOI 10.1016/j.isatra.2012.12.006
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hong T.J., 2021, Sci. Technol. Eng., V21, P9203
   Hu JF., 2015, ACTA PHYS SIN-CH ED, V64, P95
   Huang WJ, 2021, ACTA PHYS SIN-CH ED, V70, DOI 10.7498/aps.70.20200899
   Jiang KY., 2007, J WUHAN U TECHNOL TR, V2007, P850
   [金江涛 Jin Jiangtao], 2022, [控制理论与应用, Control Theory & Applications], V39, P109
   Kurian AP, 2008, IEEE IMTC P, P1219, DOI 10.1109/IMTC.2008.4547227
   Leung H, 1996, IEEE T SIGNAL PROCES, V44, P2456, DOI 10.1109/78.539030
   LEUNG H, 1993, IEEE J OCEANIC ENG, V18, P287, DOI 10.1109/JOE.1993.236367
   LEUNG H, 1990, APPL PHYS LETT, V56, P593, DOI 10.1063/1.102750
   Li M., 2010, COMPUT APPL SOFTW, V27, P29
   Li Y, 2003, CHINESE SCI BULL, V48, P508, DOI 10.1360/03tb9107
   Lin J. Y., 1999, Signal Processing, V15, P220
   Liu, 2021, RES RADAR SIGNAL DET, DOI [10.27005/d.cnki.gdzku.2021.002354, DOI 10.27005/D.CNKI.GDZKU.2021.002354]
   Liu Jin-zhen, 2021, Journal of Zhejiang University (Engineering Science), V55, P2054, DOI 10.3785/j.issn.1008-973X.2021.11.005
   Liyun Su, 2021, Journal of Physics: Conference Series, V1738, DOI 10.1088/1742-6596/1738/1/012011
   Loparok A, BEARINGS VIBRATION D
   Lv Huiying, 2009, 2009 Asia-Pacific Conference on Computational Intelligence and Industrial Applications (PACIIA 2009), P106, DOI 10.1109/PACIIA.2009.5406484
   Niu, 2019, CLASSIFICATION PARAM, DOI [10.26991/d.cnki.gdllu.2019.000532, DOI 10.26991/D.CNKI.GDLLU.2019.000532]
   Short KM, 1998, PHYS REV E, V58, P1159, DOI 10.1103/PhysRevE.58.1159
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Su LY, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/3284587
   [苏理云 Su Liyun], 2017, [电子学报, Acta Electronica Sinica], V45, P837
   Su LY., 2017, ACTA PHYS SIN-CH ED, V66, P29, DOI DOI 10.7498/APS.66.090503
   Takens F, 1981, Lecture Notes in Mathematics, V898, P366, DOI [10.1007/BFb0091924, DOI 10.1007/BFB0091924]
   Tu Y, 2022, CHINESE J AERONAUT, V35, P35, DOI 10.1016/j.cja.2021.08.016
   Wang SY., 2018, ACTA PHYS SIN-CH ED, V67, P283
   Xing HY, 2007, ACTA PHYS SIN-CH ED, V56, P3771, DOI 10.7498/aps.56.3771
   Xing HY, 2014, ACTA PHYS SIN-CH ED, V63, DOI 10.7498/aps.63.100505
   Xing HY., 2012, ACTA PHYS SIN-CH ED, V61, P90
   Xu, 2019, WEAK SIGNAL DETECTIO, DOI [10.27210/d.cnki.glnju.2019.000185, DOI 10.27210/D.CNKI.GLNJU.2019.000185]
   Yang L., 2018, J Comput Applic, V38, P1
   Zhang KL., 2009, AVIONICS TECHNOLOGY, V40, P30
   Zhao SL, 2021, J SENSORS, V2021, DOI 10.1155/2021/5597841
   Zhao ZH., 2021, IEEE T INSTRUM MEAS, V35, P108
NR 48
TC 2
Z9 2
U1 4
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35853
EP 35877
DI 10.1007/s11042-023-14987-w
EA MAR 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000946885800001
DA 2024-07-18
ER

PT J
AU Mojiborrahman, D
   Yang, CK
AF Mojiborrahman, Dehvari
   Yang, Chuan-Kai
TI Video visualization via face and speaker clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face tracking; Scene change detection; Face clustering; Speaker
   clustering
ID DIARIZATION; RECOGNITION
AB When we are watching a video, often we may find it difficult to differentiate a character as we are unfamiliar with his/her face, especially if there are numerous actors/actresses or they are from different countries/cultures. There are also other circumstances like for deaf people or when people cannot hear the voice in noisy places(e.g. streets), a diarization method along with subtitles can be a more effective way to understand scripts. To address this, we proposed a video visualization system via face and speaker clustering. Given an input video, our system first separates the voice from the video and then extracts facial and voice features for face clustering and speaker clustering. Finally, the system finds the correspondence between face and speaker clustering results, and as a result, people could easily know when a character appears and who is the speaker in a video via our proposed video visualization system.
C1 [Mojiborrahman, Dehvari; Yang, Chuan-Kai] Natl Taiwan Univ Sci & Technol, Dept Informat Management, 43, Sec 4,Keelung Rd, Taipei 106, Taiwan.
C3 National Taiwan University of Science & Technology
RP Yang, CK (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Informat Management, 43, Sec 4,Keelung Rd, Taipei 106, Taiwan.
EM mojib.dh@gmail.com; ckyang@cs.ntust.edu.tw
FU Ministry of Science and Technology of Taiwan [MOST
   106-2221-E-011-148-MY3, MOST 109-2221-E-011-133]
FX This work was supported in part by the Ministry of Science and
   Technology of Taiwan under the grants MOST 106-2221-E-011-148-MY3 and
   MOST 109-2221-E-011-133. Conflict of Interest: Both authors have
   received the aforementioned funding support and both authors have no
   conflict of interest
CR Ahmad R, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235163
   [Anonymous], PySceneDetect
   [Anonymous], SPEAKER DIARIZATION
   [Anonymous], MTCNN FACE DETECTOR
   Barzelay Z, 2010, IEEE T MULTIMEDIA, V12, P108, DOI 10.1109/TMM.2009.2037387
   Bredin H, 2016, ACM MULTIMEDIA 2016
   Cabañas-Molero P, 2018, MULTIMED TOOLS APPL, V77, P27685, DOI 10.1007/s11042-018-5944-2
   Chung JS, 2018, INTERSPEECH, P1086
   Dehvari M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11104336
   Dong S, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100379
   Dong S, 2013, IETE J RES, V59, P326, DOI 10.4103/0377-2063.118021
   El Khoury E, 2014, MULTIMED TOOLS APPL, V68, P747, DOI 10.1007/s11042-012-1080-6
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Garau G, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2662
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Komai Y, 2011, LECT NOTES COMPUT SC, V7087, P97
   Leon Villalba AF, 2020, 2020 CONGRESO INT IN, P1
   Potamianos G, 2003, P IEEE, V91, P1306, DOI 10.1109/JPROC.2003.817150
   Ramirez J. M., 2007, ROBUST SPEECH RECOGN, V6, P1, DOI [DOI 10.5772/4740, 10.5772/4740]
   Rivet B, 2007, IEEE T AUDIO SPEECH, V15, P96, DOI 10.1109/TASL.2006.872619
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Sung J, 2008, INT J COMPUT VISION, V80, P260, DOI 10.1007/s11263-007-0125-1
   Tranter SE, 2006, IEEE T AUDIO SPEECH, V14, P1557, DOI 10.1109/TASL.2006.878256
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Xie WD, 2019, INT CONF ACOUST SPEE, P5791, DOI 10.1109/ICASSP.2019.8683120
   Xie YG, 2020, J INTERNET TECHNOL, V21, P1463, DOI 10.3966/160792642020092105020
   Zhang AN, 2019, INT CONF ACOUST SPEE, P6301, DOI 10.1109/ICASSP.2019.8683892
   Zhang K., 2016, IEEE Signal Processing Letters, V23
   Zhong YJ, 2019, LECT NOTES COMPUT SC, V11362, P35, DOI 10.1007/978-3-030-20890-5_3
NR 29
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 25865
EP 25881
DI 10.1007/s11042-023-14552-5
EA MAR 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000946890000008
DA 2024-07-18
ER

PT J
AU Pashaei, E
   Pashaei, E
AF Pashaei, Elnaz
   Pashaei, Elham
TI Gaussian quantum arithmetic optimization-based histogram equalization
   for medical image enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contrast enhancement; Arithmetic optimization algorithm; Medical image;
   Histogram equalization
ID CONTRAST ENHANCEMENT; BRIGHTNESS ERROR; RESONANCE
AB The quality of medical images is critical for accurate diagnosis. This paper introduces a novel Quantum-behaved Arithmetic Optimization Algorithm (QAOA) for medical images. A mutation operator with Gaussian probability distribution is used in the proposed QAOA as a powerful strategy to enhance QAOA performance in preventing premature convergence to local optima. Gaussian QAOA (GQAOA) is tailored for medical image enhancement and hybridized with Contrast Limited Adaptive Histogram Equalization (CLAHE) to boost the information contents and details of medical images. GQAOA computes the optimal clip limit and other parameters of CLAHE using a new multi-objective fitness function. A combination of five image quality measurements including contrast, information entropy, edge information, Structural Similarity Index Measure (SSIM), and sharpness is suggested as an efficient fitness function to help the proposed framework produce good results. A comparative study is conducted with well-known histogram-based process techniques and state-of-art methods to demonstrate the efficiency of the suggested algorithm. The experimental results prove that the suggested approach performs better than the most current well-established enhancement strategies in the terms of visual interpretation, information entropy, SSIM, Peak Signal to Noise Ratio (PSNR), Naturalness Image Quality Evaluator (NIQE), Absolute Mean Brightness Error (AMBE), and Quality Index (QI) metrics.
C1 [Pashaei, Elnaz] Istanbul Aydin Univ, Dept Software Engn, Istanbul, Turkiye.
   [Pashaei, Elnaz] Indiana Univ Sch Med, Dept Med & Mol Genet, Indianapolis, IN 46202 USA.
   [Pashaei, Elham] Istanbul Gelisim Univ, Dept Comp Engn, Istanbul, Turkiye.
C3 Istanbul Aydin University; Indiana University System; Indiana University
   Bloomington; Istanbul Gelisim University
RP Pashaei, E (corresponding author), Istanbul Aydin Univ, Dept Software Engn, Istanbul, Turkiye.; Pashaei, E (corresponding author), Indiana Univ Sch Med, Dept Med & Mol Genet, Indianapolis, IN 46202 USA.
EM elnazpashaei@aydin.edu.tr; epashaei@gelisim.edu.tr
RI Pashaei, Elham/AAP-8599-2021; PASHAEI, ELNAZ/AAI-7928-2021
OI Pashaei, Elham/0000-0001-7401-4964; PASHAEI, ELNAZ/0000-0001-9391-9785
CR Abreu da Rocha Douglas, 2020, Research on Biomedical Engineering, V36, P67, DOI 10.1007/s42600-019-00032-z
   Abualigah L, 2021, PROCESSES, V9, DOI 10.3390/pr9071155
   Abualigah L, 2021, COMPUT METHOD APPL M, V376, DOI 10.1016/j.cma.2020.113609
   Acharya UK, 2021, OPTIK, V230, DOI 10.1016/j.ijleo.2021.166273
   Acharya UK, 2020, OPTIK, V224, DOI 10.1016/j.ijleo.2020.165760
   Agushaka JO, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0255703
   Aydin N, 2020, INT C INTELLIGENT FU, P1431, DOI 10.1007/978-3-030-51156-2_166
   Bhandari AK, 2020, IEEE T INSTRUM MEAS, V69, P6807, DOI 10.1109/TIM.2020.2976279
   Birdal Tolga, 2022, SHARPNESS ESTIMATION
   Carneiro P, 2019, IEEE LAT AM T, V17, P851, DOI 10.1109/TLA.2019.8891954
   Campos GFC, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0445-4
   Chandrashekar Leena, 2020, Procedia Computer Science, V171, P1770, DOI 10.1016/j.procs.2020.04.190
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Dabass J, 2018, COMM COM INF SC, V799, P260, DOI 10.1007/978-981-10-8527-7_22
   Dhal Krishna Gopal, 2018, International Journal of Medical Engineering and Informatics, V10, P164
   Dhal KG, 2018, INT J BIOMED ENG TEC, V28, P160
   Gautam R, 2015, CURR SCI INDIA, V108, P341
   Huang XW, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/5652340
   Ibrahim RA, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23091189
   Joseph J, 2018, BIOMED SIGNAL PROCES, V39, P271, DOI 10.1016/j.bspc.2017.08.003
   Joseph J, 2017, BIOCYBERN BIOMED ENG, V37, P489, DOI 10.1016/j.bbe.2016.11.006
   Kandhway P, 2020, BIOMED SIGNAL PROCES, V56, DOI 10.1016/j.bspc.2019.101677
   Kaveh A, 2022, STRUCTURES, V35, P748, DOI 10.1016/j.istruc.2021.11.012
   Khatir S, 2021, COMPOS STRUCT, V273, DOI 10.1016/j.compstruct.2021.114287
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Kumar N, 2021, EXPERT SYST APPL, V172, DOI 10.1016/j.eswa.2021.114646
   Kuran U., 2021, Intelligent Systems with Applications, V12, P200051, DOI DOI 10.1016/J.ISWA.2021.200051
   Min B. S., 2013, International Journal of Software Engineering and Its Applications, V7, P113, DOI DOI 10.14257/IJSEIA.2013.7.5.11
   Moré LG, 2015, IEEE IMAGE PROC, P4644, DOI 10.1109/ICIP.2015.7351687
   Pashaei E., 2021, 2021 5 INT S MULT ST, P37, DOI 10.1109/ISMSIT52890.2021.9604701
   Pashaei E, 2022, J SUPERCOMPUT, V78, P15598, DOI 10.1007/s11227-022-04507-2
   Pashaei E, 2023, MULTIMED TOOLS APPL, V82, P297, DOI 10.1007/s11042-022-13275-3
   Patel S, 2020, ADV INTELL SYST, V1048, P657, DOI 10.1007/978-981-15-0035-0_54
   Popnoe DO, 2019, J APPL CLIN MED PHYS, V20, P171, DOI 10.1002/acm2.12685
   Singh K, 2016, J MOD OPTIC, V63, P1444, DOI 10.1080/09500340.2016.1154194
   Singh K, 2015, OPTIK, V126, P2619, DOI 10.1016/j.ijleo.2015.06.060
   Singh M, 2017, BIOCYBERN BIOMED ENG, V37, P124, DOI 10.1016/j.bbe.2016.10.006
   Siracusano G, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12208573
   Sonali, 2019, OPT LASER TECHNOL, V110, P87, DOI 10.1016/j.optlastec.2018.06.061
   Waite S, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00213
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Yuan L, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14020331
   Zhou YP, 2019, QUANT IMAG MED SURG, V9, P1528, DOI 10.21037/qims.2019.08.19
NR 43
TC 2
Z9 2
U1 6
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34725
EP 34748
DI 10.1007/s11042-023-15025-5
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000946890000009
DA 2024-07-18
ER

PT J
AU Sapkal, A
   Arti
   Pawar, D
   Singh, P
AF Sapkal, Ashwini
   Arti
   Pawar, Dishant
   Singh, Prashant
TI Lane detection techniques for self-driving vehicle: comprehensive review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Autonomous driving; Lane detection; Deep learning; Advanced driver
   assisting system; Lane keeping assisting system; Lane departure warning
   system
ID TRACKING
AB According to WHO, 1.35 million people, every year are cut short in road accidents, most of them caused due to human misconduct and ignorance. To improve safety over the roads, road perception and lane detection play a crucial part in avoiding accidents. Lane Detection is a constitution for various Advanced Driver Assisting System (ADAS) like Lane Keeping Assisting System (LKAS) and Lane Departure Warning System (LDWS). It also enables fully assistive and autonomous navigation in self-driving vehicles. Therefore, it has been an effective field of research for the past few decades, but various milestones are yet to be achieved. The problem has encountered various challenging scenarios due to the past limitations of resources and technologies. In this paper, we reviewed the different approaches based on image processing and computer vision that have revolutionized the lane detection problem. This paper also summarizes the different benchmark data sets for lane detection, evaluation criteria. We implemented Lane detection system using Unet and Segnet model and applied it on Tusimple dataset. The Unet performance is better as compared to Segnet model. We also compare the detection performance and running time of various methods, and conclude with some current challenges and future trends for deep learning-based lane marking detection algorithm. Finally, we compare various researcher's approaches with their performances. This paper concluded with the challenges to predict accurate lanes under different scenarios.
C1 [Sapkal, Ashwini; Arti; Pawar, Dishant; Singh, Prashant] Army Inst Technol, Dept Informat Technol, Pune 411015, Maharashtra, India.
RP Sapkal, A (corresponding author), Army Inst Technol, Dept Informat Technol, Pune 411015, Maharashtra, India.
EM asapkal@aitpune.edu.in; artisaradhna12@gmail.com;
   dishantpawar17343@aitpune.edu.in; prashantsingh17459@aitpune.edu.in
OI Sapkal, Ashwini/0000-0003-4141-1757
FU Chinchwad College of Engineering
FX AcknowledgementsWe thank Dr Swati Shinde, Professor, Pimpari Chinchwad
   College of Engineering, Pune for her assistance in the revision of this
   paper. Her comments and suggestions has greatly improved the manuscript.
CR Alvarez JM, 2014, IEEE WINT CONF APPL, P501, DOI 10.1109/WACV.2014.6836060
   Aly M, 2008, IEEE INT VEH SYM, P165, DOI 10.1109/ivs.2008.4621152
   [Anonymous], 2017, TUSIMPLE DATASET
   [Anonymous], 2022, CALTECH LANES DATASE
   Assidiq AAM, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION ENGINEERING, VOLS 1-3, P82, DOI 10.1109/ICCCE.2008.4580573
   AUBERT D, 1991, P SOC PHOTO-OPT INS, V1388, P141, DOI 10.1117/12.25463
   Behrendt K, 2019, IEEE INT CONF COMP V, P832, DOI 10.1109/ICCVW.2019.00111
   Borkar A, 2009, IEEE IMAGE PROC, P3261, DOI 10.1109/ICIP.2009.5413980
   Broggi A, 2006, PATTERN RECOGN LETT, V27, P1164, DOI 10.1016/j.patrec.2005.07.014
   Broggi A, 2010, IEEE T INTELL TRANSP, V11, P194, DOI 10.1109/TITS.2010.2041231
   Brostow GJ, 2009, PATTERN RECOGN LETT, V30, P88, DOI 10.1016/j.patrec.2008.04.005
   Buehler M., 2007, 2005 DARPA GRAND CHA, V36
   Burrow MPN, 2003, P I CIVIL ENG-TRANSP, V156, P17
   Chen ZP, 2019, IEEE INT VEH SYM, P2563, DOI [10.1109/IVS.2019.8813778, 10.1109/ivs.2019.8813778]
   Cheng HY, 2006, IEEE T INTELL TRANSP, V7, P571, DOI 10.1109/TITS.2006.883940
   Chunzhao Guo, 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P5543, DOI 10.1109/IROS.2010.5650695
   Fritsch J, 2013, IEEE INT C INTELL TR, P1693, DOI 10.1109/ITSC.2013.6728473
   Ghafoorian M, 2019, LECT NOTES COMPUT SC, V11129, P256, DOI 10.1007/978-3-030-11009-3_15
   Gurghian A, 2016, IEEE COMPUT SOC CONF, P38, DOI 10.1109/CVPRW.2016.12
   Haloi M, 2015, IEEE INT VEH SYM, P126, DOI 10.1109/IVS.2015.7225674
   He B, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P2475, DOI 10.1109/ITSC.2016.7795954
   He B, 2016, IEEE INT VEH SYM, P1041, DOI 10.1109/IVS.2016.7535517
   Hou Y., 2019, arXiv
   Hou YN, 2019, IEEE I CONF COMP VIS, P1013, DOI 10.1109/ICCV.2019.00110
   Huang A, 2009, AUTON ROBOT, V26, P103, DOI 10.1007/s10514-009-9113-3
   Huang YP, 2018, KSII T INTERNET INF, V12, P643, DOI 10.3837/tiis.2018.02.006
   Jung CR, 2004, XVII BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P72, DOI 10.1109/SIBGRA.2004.1352945
   Kim Z, 2008, IEEE T INTELL TRANSP, V9, P16, DOI 10.1109/TITS.2007.908582
   Kuderer M, 2013, IEEE INT C INT ROBOT, P3138, DOI 10.1109/IROS.2013.6696802
   Lee S, 2017, IEEE I CONF COMP VIS, P1965, DOI 10.1109/ICCV.2017.215
   Li J, 2017, IEEE T NEUR NET LEAR, V28, P690, DOI 10.1109/TNNLS.2016.2522428
   Li YM, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P1682
   Liu GL, 2010, IEEE INT VEH SYM, P993, DOI 10.1109/IVS.2010.5548021
   Liu WR, 2014, INT J COMPUT MATH, V91, P2359, DOI 10.1080/00207160.2013.813020
   Mamidala RS, 2019, TENCON IEEE REGION, P2454, DOI [10.1109/tencon.2019.8929655, 10.1109/TENCON.2019.8929655]
   McCall JC, 2004, 2004 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P533
   Neven D, 2018, IEEE INT VEH SYM, P286
   Niu JW, 2016, PATTERN RECOGN, V59, P225, DOI 10.1016/j.patcog.2015.12.010
   Ozgunalp Umar, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P8129, DOI 10.1109/ICASSP.2014.6855185
   Pan XG, 2018, AAAI CONF ARTIF INTE, P7276
   Philion J, 2019, PROC CVPR IEEE, P11574, DOI 10.1109/CVPR.2019.01185
   Pizzati Fabio, 2019, LANE DETECTION CLASS
   Pomerleau Dean., 1995, Intelligent Vehicles' 95 Symposium., P506
   Rose C, 2014, IEEE T INTELL TRANSP, V15, P2615, DOI 10.1109/TITS.2014.2321108
   Sehestedt S, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P123, DOI 10.1109/IROS.2007.4399388
   Sivaraman S, 2013, IEEE T INTELL TRANSP, V14, P906, DOI 10.1109/TITS.2013.2246835
   Tabelini L, 2021, PROC CVPR IEEE, P294, DOI 10.1109/CVPR46437.2021.00036
   Veit T, 2008, PROCEEDINGS OF THE 11TH INTERNATIONAL IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, P174, DOI 10.1109/ITSC.2008.4732564
   von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300
   Wang Y, 2004, IMAGE VISION COMPUT, V22, P269, DOI 10.1016/j.imavis.2003.10.003
   Wu CF, 2012, IEEE T SYST MAN CY C, V42, P577, DOI 10.1109/TSMCC.2011.2166067
   Xu XM, 2021, IEEE T INTELL TRANSP, V22, P4986, DOI 10.1109/TITS.2020.2983077
   Yoo JH, 2017, IEEE T INTELL TRANSP, V18, P3254, DOI 10.1109/TITS.2017.2679222
   Yoo S, 2020, IEEE COMPUT SOC CONF, P4335, DOI 10.1109/CVPRW50498.2020.00511
   Yuan J, 2014, CHIN CONTR CONF, P4887, DOI 10.1109/ChiCC.2014.6895768
   Zhang G, 2009, IEEE INT VEH SYM, P556, DOI 10.1109/IVS.2009.5164338
   Zhang YC, 2021, IEEE T INTELL TRANSP, V22, P1532, DOI 10.1109/TITS.2020.2971728
NR 57
TC 2
Z9 2
U1 23
U2 81
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 33983
EP 34004
DI 10.1007/s11042-023-14446-6
EA MAR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000946890000012
DA 2024-07-18
ER

PT J
AU Yadav, DP
   Jalal, AS
   Goyal, A
   Mishra, A
   Uprety, K
   Guragai, N
AF Yadav, Dhirendra P. P.
   Jalal, Anand Singh
   Goyal, Ayush
   Mishra, Avdesh
   Uprety, Khem
   Guragai, Nirmal
TI COVID-19 radiograph prognosis using a deep CResNeXt network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Coronavirus (COVID-19); Machine learning; Deep learning; Chest
   radiographs; Radiology images
AB COVID-19 has caused an epidemic in the entire world and it is caused by the novel virus SARS-COV-2. In severe conditions, this virus can cause a critical lung infection or viral pneumonia. To administer the correct treatment to patients, COVID-19 testing is important for diagnosing and determining patients who are infected with COVID-19, as opposed to those infected with other bacterial or viral infections. In this paper, a CResNeXt chest radiograph COVID-19 prediction model is proposed using residual network architecture. The advantage of the proposed model is that it requires lesser free hyper-parameters as compared to other residual networks. In addition, the training time per epochs of the model is very less compared to VGG19, ResNet-50, ResNeXt. The proposed CResNeXt model's binary classification (COVID-19 versus No-Finding) accuracy is observed to be 98.63% and 99.99% and multi-class classification (COVID-19, Pneumonia, and No-Finding) accuracy is observed to be 97.42% and 99.27% on the original and augmented datasets, respectively.
C1 [Yadav, Dhirendra P. P.; Jalal, Anand Singh] GLA Univ, Dept Comp Engn & Applicat, Mathura, UP, India.
   [Goyal, Ayush; Mishra, Avdesh] Texas A&M Univ, Dept Elect Engn & Comp Sci, Kingsville, TX USA.
   [Uprety, Khem] Univ Tennessee Hlth Sci Ctr, Memphis, TN USA.
   [Guragai, Nirmal] St Joseph Reg Med Ctr, Dept Cardiol, Paterson, NJ USA.
C3 GLA University; Texas A&M University System; Texas A&M University
   Kingsville; University of Tennessee System; University of Tennessee
   Health Science Center
RP Jalal, AS (corresponding author), GLA Univ, Dept Comp Engn & Applicat, Mathura, UP, India.
EM anandsinghjalal@gmail.com
OI Jalal, Anand/0000-0002-7469-6608; Goyal, Ayush/0000-0002-1585-8806;
   Yadav, Dhirendra Prasad/0000-0001-9349-3964
CR Abbas A., 2020, ARXIV
   Alizadehsani R, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3462635
   Alom MZ, 2020, ARXIV
   Alshukairi AN, 2018, MBIO, V9, DOI [10.1128/mBio.01985-18, 10.1128/mbio.01985-18]
   [Anonymous], 2019, COVID 19
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Ardakani AA, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103795
   Ayyar MP, 2021, IEEE INT CONF COMP V, P519, DOI 10.1109/ICCVW54120.2021.00064
   Basu S, 2020, 2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), P2521, DOI 10.1109/SSCI47803.2020.9308571
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Brunese L, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105608
   Chowdhury M., 2020, ARXIV
   Cohen J.P., 2020, arXiv
   Duda R., 1973, Pattern Classification and Scene Analysis
   Farooq M., 2020, arXiv preprint arXiv:2003.14395
   Ghassemi N., 2021, ARXIV
   Goodfellow I, MAXOUT NETWORKS, P1319
   Haghanifar A, 2020, ARXIV
   Hall LO, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2004.02060
   Hastie T., 2009, The Elements of Statistical Learning
   Hemdan E. E.- D., 2020, . arXiv preprint arXiv:2003.11055
   Hinton G.E., 2012, RESEARCHGATE, V3, P212, DOI DOI 10.48550/ARXIV.1207.0580
   Hirano G, 2020, SKIN RES TECHNOL, V26, P891, DOI 10.1111/srt.12891
   Horry M.J., 2020, X RAY IMAGE BASED CO, DOI [10.31224/osf.io/wx89s, DOI 10.31224/OSF.IO/WX89S]
   Jin Jian-Min, 2020, Front Public Health, V8, P152, DOI 10.3389/fpubh.2020.00152
   Kermany Daniel, 2018, Mendeley Data, V3
   Khan AI, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105581
   Khozeimeh F, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-93543-8
   LAI CC, 2020, INT J ANTIMICROB AG, V55, DOI DOI 10.1016/J.IJANTIMICAG.2020.105924
   Liu Y, 2020, LANCET INFECT DIS, V20, P656, DOI [10.1016/S1473-3099(20)30232-2, 10.1016/S1473-3099(15)00424-7]
   Luz E, 2020, ARXIV
   Medhi K., 2020, AUTOMATIC DETECTION, DOI [10.1101/2020.05.10.20097063, DOI 10.1101/2020.05.10.20097063]
   Mikolajczyk Agnieszka., 2018, Data augmentation for improving deep learning in image classification problem, P117
   Minaee S, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101794
   Nahata Hardik., 2020, Machine Learning with Health Care Perspective: Machine Learning and Healthcare, P159, DOI [DOI 10.1007/978-3-030-40850-3_8, 10.1007/978-3-030-40850-3_8]
   Narin A, 2021, PATTERN ANAL APPL, V24, P1207, DOI 10.1007/s10044-021-00984-y
   Oh Y, 2020, IEEE T MED IMAGING, V39, P2688, DOI 10.1109/TMI.2020.2993291
   Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792
   Pathak Y, 2022, IRBM, V43, P87, DOI 10.1016/j.irbm.2020.05.003
   Pereira RM, 2020, COMPUT METH PROG BIO, V194, DOI 10.1016/j.cmpb.2020.105532
   Rahimzadeh Mohammad, 2020, Inform Med Unlocked, V19, P100360, DOI 10.1016/j.imu.2020.100360
   Sethy PK, 2020, Detection of coronavirus disease (covid-19) based on deep features
   Sharifrazi D, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102622
   Shoeibi A., 2020, ARXIV
   Silva P, 2020, EFFICIENT DEEP LEARN
   Song Y, 2021, IEEE ACM T COMPUT BI, V18, P2775, DOI 10.1109/TCBB.2021.3065361
   Tetro JA, 2020, MICROBES INFECT, V22, P72, DOI 10.1016/j.micinf.2020.02.006
   Ucar F, 2020, MED HYPOTHESES, V140, DOI 10.1016/j.mehy.2020.109761
   W. H. Organization, 2020, 165 WHO, P165
   Wang Lucy Lu, 2020, CORD 19 COVID 19 OPE
   Wang S., 2020, medRxiv
   Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369
   Wong HYF, 2019, RADIOLOGY, DOI DOI 10.1148/RADIOL.2020201160
   worldometers, COVID-19 CORONAVIRUS PANDEMIC
   Wu ZY, 2020, JAMA-J AM MED ASSOC, V323, P1239, DOI 10.1001/jama.2020.2648
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xu JB, 2020, VIRUSES-BASEL, V12, DOI 10.3390/v12020244
   Zeiler M.D., 2013, arXiv
   Zhang J., 2020, ARXIV
NR 59
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 36479
EP 36505
DI 10.1007/s11042-023-14960-7
EA MAR 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000945792800010
PM 37362635
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Dhawan, K
   Perumal, RS
   Nadesh, RK
AF Dhawan, Kshitij
   Perumal, R. Srinivasa
   Nadesh, R. K.
TI Identification of traffic signs for advanced driving assistance systems
   in smart cities using deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ADAS; YOLO v3; YOLO v4-tiny; Traffic signs recognition; Customised CNN;
   Image augmentation
AB The ability of Advanced Driving Assistance Systems (ADAS) is to identify and understand all objects around the vehicle under varying driving conditions and environmental factors is critical. Today's vehicles are equipped with advanced driving assistance systems that make driving safer and more comfortable. A camera mounted on the car helps the system recognise and detect traffic signs and alerts the driver about various road conditions, like if construction work is ahead or if speed limits have changed. The goal is to identify the traffic sign and process the image in a minimal processing time. A custom convolutional neural network model is used to classify the traffic signs with higher accuracy than the existing models. Image augmentation techniques are used to expand the dataset artificially, and that allows one to learn how the image looks from different perspectives, such as when viewed from different angles or when it looks blurry due to poor weather conditions. The algorithms used to detect traffic signs are YOLO v3 and YOLO v4-tiny. The proposed solution for detecting a specific set of traffic signs performed well, with an accuracy rate of 95.85%.
C1 [Dhawan, Kshitij] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore 632014, Tamilnadu, India.
   [Perumal, R. Srinivasa; Nadesh, R. K.] Vellore Inst Technol, Sch Informat Technol & Engn, Vellore 632014, Tamilnadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Vellore Institute of
   Technology (VIT); VIT Vellore
RP Nadesh, RK (corresponding author), Vellore Inst Technol, Sch Informat Technol & Engn, Vellore 632014, Tamilnadu, India.
EM kshitij.dhawan310@gmail.com; r.srinivasaperumal@vit.ac.in;
   rknadesh@gmail.com
OI R, Dr. Srinivasa Perumal/0000-0001-7143-7371
CR Ali NM, 2013, IOP CONF SER-MAT SCI, V53, DOI 10.1088/1757-899X/53/1/012017
   Arcos-García A, 2018, NEUROCOMPUTING, V316, P332, DOI 10.1016/j.neucom.2018.08.009
   Ayachi R, 2020, NEURAL PROCESS LETT, V51, P837, DOI 10.1007/s11063-019-10115-8
   Bi ZQ, 2021, INT J MACH LEARN CYB, V12, P3069, DOI 10.1007/s13042-020-01185-5
   Ciresan D, 2012, NEURAL NETWORKS, V32, P333, DOI 10.1016/j.neunet.2012.02.023
   Corovic A, 2018, 2018 26TH TELECOMMUNICATIONS FORUM (TELFOR), P731
   Gudigar A, 2016, MULTIMED TOOLS APPL, V75, P333, DOI 10.1007/s11042-014-2293-7
   Han C, 2019, MULTIMED TOOLS APPL, V78, P13263, DOI 10.1007/s11042-018-6428-0
   Huang SC, 2017, JOINT INT CONF SOFT
   Isa ISBM., 2022, INT J EL COMP ENG SY, V12, P331, DOI DOI 10.11591/IJECE.V12I1.PP331-338
   Islam MM, 2020, IEEE ACCESS, V8, P166117, DOI 10.1109/ACCESS.2020.3021943
   Islam Md Zabirul, 2020, Inform Med Unlocked, V20, P100412, DOI 10.1016/j.imu.2020.100412
   Liu CJ, 2018, PROCEEDINGS OF 2018 IEEE 4TH INFORMATION TECHNOLOGY AND MECHATRONICS ENGINEERING CONFERENCE (ITOEC 2018), P799, DOI 10.1109/ITOEC.2018.8740604
   Mallela NC, 2021, MULTIMED TOOLS APPL, V80, P8175, DOI 10.1007/s11042-020-10126-x
   Mehta S, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICCS), P1293, DOI [10.1109/ICCS45141.2019.9065537, 10.1109/iccs45141.2019.9065537]
   Panigrahi R, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9060690
   Panigrahi R, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9070751
   Qian RQ, 2015, 2015 11TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION (ICNC), P791, DOI 10.1109/ICNC.2015.7378092
   Rahman MM, 2020, 2020 IEEE INTERNATIONAL IOT, ELECTRONICS AND MECHATRONICS CONFERENCE (IEMTRONICS 2020), P271
   Ramalingam SP., 2018, B ELECT ENG INFORM, V7, P96, DOI [10.11591/eei.v7i1.761, DOI 10.11591/EEI.V7I1.761]
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Tai SK, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10196997
   Wu YQ, 2020, MULTIMED TOOLS APPL, V79, P18201, DOI 10.1007/s11042-020-08722-y
   Yadav Shubham, 2019, INT J APPL SCI SMART, V1, DOI [1-10.10.24071/ijasst.v1i1.1843, DOI 10.24071/IJASST.V1I1.1843]
   Yuan Y, 2019, IEEE T IMAGE PROCESS, V28, P3423, DOI 10.1109/TIP.2019.2896952
   Zhang CW, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420550034
NR 26
TC 1
Z9 1
U1 7
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26465
EP 26480
DI 10.1007/s11042-023-14823-1
EA MAR 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000943638900010
PM 37362733
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Pramanik, S
AF Pramanik, Sabyasachi
TI An adaptive image steganography approach depending on integer wavelet
   transform and genetic algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganalysis; Integer wavelet transform (IWT); Steganography; Genetic
   algorithm; Discrete wavelet transform (DWT)
ID SCHEME; STEGANALYSIS; DOMAIN
AB Steganography is the art and a science of obscuring the presence of communication by hiding content in electronic media and so obscuring the presence of communication from the adversary's perspective. The goal of spatial adaptive approaches is to incorporate additional information in the image's edge regions. The portions of the picture with the most changes are prioritized for embedding in these approaches. In contrast, wavelet-based approaches insert in high-frequency sub-bands to resemble the human visual system. The concept described in this study is a hybrid of these two concepts. On the contrary, the coefficients of the wavelet transform's high-frequency sub-bands are more suited for embedding, since they have bigger coefficients surrounding them and reflect the image's edge regions. Based on a local neighborhood analysis, an edge intensity criterion is employed to identify the suitable embedding coefficients in this technique. The receiver may also recognize these coefficients and fully extract the encoded data. In the suggested technique, the picture is first blocked, and then each block is given a wavelet transform. Several coefficients are discovered for each high-frequency sub-band, depending on the duration of the data, and then, using a genetic algorithm and the coefficients are chosen from the detected coefficients using a genetic approach to ensure that the resulting stego picture has the maximum PSNR value. The results of the implementation reveal that in the suggested strategy, employing the Integer Wavelet Transform is far more effective than using the Discrete Wavelet Transform. The suggested approach is safe against steganalysis assaults such as PDH analysis, RS, and universal steganalysers, and the quality of the stego picture is better than previous methods like SPAM (Steganography by Printed Arrays by Microbes) and SRM (Spatial Rich Model).
C1 [Pramanik, Sabyasachi] Haldia Inst Technol, Haldia, India.
C3 Haldia Institute of Technology
RP Pramanik, S (corresponding author), Haldia Inst Technol, Haldia, India.
EM sabyalnt@gmail.com
RI Pramanik, Sabyasachi/AAR-1342-2020
OI Pramanik, Sabyasachi/0000-0002-9431-8751
CR Abedini A, 2017, J COMPUT ENG INF TEC, V06, DOI [10.4172/2324-9307.1000170, DOI 10.4172/2324-9307.1000170]
   Al-Dmour H, 2016, EXPERT SYST APPL, V46, P293, DOI 10.1016/j.eswa.2015.10.024
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Banharnsakun A, 2018, MULTIMED TOOLS APPL, V77, P27491, DOI 10.1007/s11042-018-5933-5
   Chang CC, 2004, PATTERN RECOGN LETT, V25, P1431, DOI 10.1016/j.patrec.2004.05.006
   Chang CC, 2010, INFORM SCIENCES, V180, P2286, DOI 10.1016/j.ins.2010.01.034
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen P-Y, 2009, INT J APPL SCI ENG, V7
   Chen WJ, 2010, EXPERT SYST APPL, V37, P3292, DOI 10.1016/j.eswa.2009.09.050
   Douglas M, 2018, MULTIMED TOOLS APPL, V77, P17333, DOI 10.1007/s11042-017-5308-3
   El Safy R. O., 2009, 2009 International Conference on Networking and Media Convergence (ICNM'09), P111, DOI 10.1109/ICNM.2009.4907200
   Fakhredanesh M, 2019, MULTIMED TOOLS APPL, V78, P18475, DOI 10.1007/s11042-019-7238-8
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gulve AK, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/684824
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Jayasingh Roopa J., 2022, International Journal of Reliable and Quality E-Healthcare, V11, P1, DOI 10.4018/IJRQEH.295083
   Jeevitha S, 2020, HEALTH TECHNOL-GER, V10, P217, DOI 10.1007/s12553-018-00285-1
   Kadhim IJ, 2018, SECURE IMAGE STEGANO, DOI [10.1109/ICECA.2018.8474616, DOI 10.1109/ICECA.2018.8474616]
   Kadhim IJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107481
   Kalita M, 2019, COMPUT J, V62, P1639, DOI 10.1093/comjnl/bxz014
   Kanan HR, 2014, EXPERT SYST APPL, V41, P6123, DOI 10.1016/j.eswa.2014.04.022
   Khamrui A., 2017, COMMUN COMPUT INFO S, V776, p577 584, DOI [10.1007/978-981-10-6430-2_45, DOI 10.1007/978-981-10-6430-2_45]
   Khan S., 2018, Int J Electric Comput Eng (IJECE), V8, P379, DOI [10.11591/ijece.v8i1.pp379-389, DOI 10.11591/IJECE.V8I1.PP379-389]
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Kumar S, 2010, DATA HIDING TECHNIQU, DOI [10.1109/IPTC.2010.46, DOI 10.1109/IPTC.2010.46]
   Kumar V, 2018, MULTIMED TOOLS APPL, V77, P13279, DOI 10.1007/s11042-017-4947-8
   Laishram D, 2021, MULTIMED TOOLS APPL, V80, P831, DOI 10.1007/s11042-020-09519-9
   Lee CF, 2018, DISPLAYS, V53, P30, DOI 10.1016/j.displa.2018.06.001
   Lu TC, 2007, LOSSLESS INFORM HIDI, DOI [10.1109/SITIS.2007.60, DOI 10.1109/SITIS.2007.60]
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Maheswari SU, 2015, DEFENCE SCI J, V65, P214, DOI 10.14429/dsj.65.7871
   Maheswari SU, 2015, AEU-INT J ELECTRON C, V69, P539, DOI 10.1016/j.aeue.2014.11.004
   Maniccam SS, 2004, PATTERN RECOGN, V37, P475, DOI 10.1016/j.patcog.2003.08.010
   Miri A, 2018, MULTIMED TOOLS APPL, V77, P13133, DOI 10.1007/s11042-017-4935-z
   Miri A, 2017, OPTIK, V145, P158, DOI 10.1016/j.ijleo.2017.07.043
   Muhammad N, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1534-1
   Muhuri PK, 2020, APPL SOFT COMPUT, V92, DOI 10.1016/j.asoc.2020.106257
   Mukherjee N, 2021, INFORM SCIENCES, V552, P278, DOI 10.1016/j.ins.2020.11.044
   Nipanikar SI, 2018, ALEX ENG J, V57, P2343, DOI 10.1016/j.aej.2017.09.005
   Pandey BK, 2022, CYBER SECURITY NETWO
   Patil V, 2018, L N COMPUT VIS BIOME, V28
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Prabha K, 2021, INTELLIGENT SYSTEMS, DOI [10.1007/978-981-16-2248-9_15, DOI 10.1007/978-981-16-2248-9_15]
   Pramanik S., 2020, Advan Math: Sci J, V9, P4533, DOI [10.37418/amsj.9.7.22, DOI 10.37418/AMSJ.9.7.22]
   Pramanik S, 2021, J NEUROVIROL, V15, P4
   Pramanik S, 2014, IEEE T MICROW THEORY, P276
   Pramanik S., 2014, INT J INNOVATIVE RES, V1, P1
   Pramanik S., 2019, ENVIRON DEV SUSTAIN, V22, P106
   Pramanik S., 2020, INDONESIAN J ELECT E, V8, P525
   Pramanik S, 2020, MULTIMED TOOLS APPL, V79, P17463, DOI 10.1007/s11042-020-08676-1
   Sabeti V, 2021, ISECURE-ISC INT J IN
   Sabeti V, 2013, MULTIMED TOOLS APPL, V64, P777, DOI 10.1007/s11042-011-0975-y
   Sabeti V, 2010, PATTERN RECOGN, V43, P405, DOI 10.1016/j.patcog.2009.06.006
   Sajasi S, 2015, APPL SOFT COMPUT, V30, P375, DOI 10.1016/j.asoc.2015.01.032
   Sarkar M., 2020, J AMB INTEL HUM COMP, V11, P906
   Sathisha N, 2013, PROC SPIE, V9067, DOI 10.1117/12.2051889
   Shaukat A., 2016, NOVEL IMAGE STEGANOG, DOI [10.1109/ICRTIT.2016.7569519, DOI 10.1109/ICRTIT.2016.7569519]
   Singh S, 2013, 2013 INTERNATIONAL CONFERENCE ON MULTIMEDIA, SIGNAL PROCESSING AND COMMUNICATION TECHNOLOGIES (IMPACT), P56, DOI 10.1109/MSPCT.2013.6782087
   Subhedar MS, 2018, MULTIMED TOOLS APPL, V77, P8115, DOI 10.1007/s11042-017-4706-x
   Subhedar MS, 2016, COMPUT ELECTR ENG, V54, P406, DOI 10.1016/j.compeleceng.2016.04.017
   Thabit R, 2015, DIGIT SIGNAL PROCESS, V38, P77, DOI 10.1016/j.dsp.2014.12.005
   Kieu TD, 2011, EXPERT SYST APPL, V38, P10648, DOI 10.1016/j.eswa.2011.02.122
   Wazirali R, 2019, IEEE ACCESS, V7, P133496, DOI 10.1109/ACCESS.2019.2941440
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Xiao MY, 2015, PROC SPIE, V9811, DOI 10.1117/12.2205279
   Yadav GS, 2018, APPL SOFT COMPUT, V73, P497, DOI 10.1016/j.asoc.2018.08.034
   Zhang XP, 2004, PATTERN RECOGN LETT, V25, P331, DOI 10.1016/j.patrec.2003.10.014
NR 67
TC 0
Z9 0
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34287
EP 34319
DI 10.1007/s11042-023-14505-y
EA MAR 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000943638900004
DA 2024-07-18
ER

PT J
AU Salih, FAA
   Abdulla, AA
AF Salih, Fawzi Abdul Azeez
   Abdulla, Alan Anwer
TI Two-layer content-based image retrieval technique for improving
   effectiveness
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CBIR; Feature descriptor; Distance metric; BoF; DWT; LBP
ID FEATURE INTEGRATION; FEATURES
AB Content-based image retrieval (CBIR) is an automated process that seeks to retrieve similar/closer images from a large-scale image collection by extracting visual content from the images themselves. In general, CBIR systems consist of two main steps: 1) feature extraction and 2) feature matching. The extraction of features entails decreasing the amount of data required to describe a large set of data. Feature matching, on the other hand, is the process of comparing the extracted features from the query image to the extracted features from images in the database using a certain distance metric. Meanwhile, the extracted features of the query image are compared to those of the images in the database throughout the retrieval process, allowing each indexed image to be ranked according to its distance from the query image. This paper exploits to take the advantage from both global and local feature and hence a hybrid CBIR technique is devised which contains two layers of filtering. The first layer uses the Bag of Features (BoF) technique to compare the query image to all images in the database in order to eliminate/exclude as many dissimilar images as possible. This results in the retrieval of a number of images that are closer to the query image. The second layer aims to compare the query image to the retrieved images earned from the first layer. This is based on the extraction of texture-based and color-based features. The Local Binary Pattern (LBP) and Discrete Wavelet Transform (DWT) were used as texture features. Color features were also used from three distinct color spaces (RGB, HSV, and YCbCr). Entropy and mean of every single channel are measured. The experiments are carried out in details utilizing the widely used and well-known Corel-1 k database. In regards of precision rate, the experimental findings show that the proposed two-layer strategy outperforms existing state-of-the-art approaches, with top-10 and top-20 precision rates of 86.65% and 81%, respectively.
C1 [Salih, Fawzi Abdul Azeez] Univ Sulaimani, Coll Sci, Dept Comp Sci, Sulaimani, Iraq.
   [Abdulla, Alan Anwer] Univ Sulaimani, Coll Commerce, Dept Informat Technol, Sulaimani, Iraq.
C3 University of Sulimanyah; University of Sulimanyah
RP Abdulla, AA (corresponding author), Univ Sulaimani, Coll Commerce, Dept Informat Technol, Sulaimani, Iraq.
EM alan.abdulla@univsul.edu.iq
CR Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Abdulla AA, 2013, IEEE INT SYM MULTIM, P287, DOI 10.1109/ISM.2013.55
   Ahmed KT, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCIS), P162, DOI 10.1109/iccisci.2019.8716437
   Ahmed KT, 2017, APPL INTELL, V47, P526, DOI 10.1007/s10489-017-0916-1
   Ahmed MW., 2020, UHD J SCI TECHNOL, V4, P1, DOI DOI 10.21928/UHDJST.V4N1Y2020.PP1-8
   Aiswarya KS., 2020, J CRIT REV, V7, P63
   Al-Jubouri H., 2018, IRAQI J ELECT ELECT, V14, P90, DOI [10.37917/ijeee.14.2.1, DOI 10.37917/IJEEE.14.2.1]
   Ashraf R, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0880-7
   Hassan G, 2020, BIOMED ENG-APP BAS C, V32, DOI 10.4015/S1016237220500398
   Hassan G, 2020, IEEE ACCESS, V8, P175669, DOI 10.1109/ACCESS.2020.3026452
   KATO T, 1992, P SOC PHOTO-OPT INS, V1662, P112, DOI 10.1117/12.58497
   Kenchappa YD, 2022, INT J SYST ASSUR ENG, V13, P2540, DOI 10.1007/s13198-022-01663-9
   Latif A, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/9658350
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Li ZC, 2020, INT J COMPUT VISION, V128, P2265, DOI 10.1007/s11263-020-01331-0
   Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750
   Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035
   Liu HW, 2018, NEURAL COMPUT APPL, V29, P1, DOI 10.1007/s00521-017-3243-x
   Mohammed ZF, 2021, MULTIMED TOOLS APPL, V80, P6355, DOI 10.1007/s11042-020-10066-6
   Pavithra LK, 2019, PROCEDIA COMPUT SCI, V165, P691, DOI 10.1016/j.procs.2020.01.065
   Pradhan J, 2020, VISUAL COMPUT, V36, P1847, DOI 10.1007/s00371-019-01773-9
   Rana SP, 2019, J VIS COMMUN IMAGE R, V58, P205, DOI 10.1016/j.jvcir.2018.11.015
   Rashno A, 2019, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.1902.02059
   Sadique M.F., 2019, 2019 9 INT C POWER E, P1
   Shrivastava N, 2014, INFORM SCIENCES, V259, P212, DOI 10.1016/j.ins.2013.08.043
   Singh S, 2020, MULTIMED TOOLS APPL, V79, P17731, DOI 10.1007/s11042-019-08401-7
   Wang WQ, 2022, MULTIMED TOOLS APPL, V81, P16621, DOI 10.1007/s11042-022-12348-7
   Wojciechowska A, 2017, INT C IMAGE PROCESSI, P1
   Xie GY, 2020, IEEE ACCESS, V8, P146284, DOI 10.1109/ACCESS.2020.3015285
   Yu J, 2013, NEUROCOMPUTING, V120, P355, DOI 10.1016/j.neucom.2012.08.061
   Zhou JX, 2019, MULTIMED TOOLS APPL, V78, P6163, DOI 10.1007/s11042-018-6192-1
NR 31
TC 3
Z9 3
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31423
EP 31444
DI 10.1007/s11042-023-14678-6
EA MAR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000943638900015
DA 2024-07-18
ER

PT J
AU Mkindu, H
   Wu, LW
   Zhao, YQ
AF Mkindu, Hassan
   Wu, Longwen
   Zhao, Yaqin
TI Lung nodule detection of CT images based on combining 3D-CNN and
   squeeze-and-excitation networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hybrid ECA module; Convolutional neural network; Nodule candidate;
   Computed tomography; Computer-aided design
ID FALSE-POSITIVE REDUCTION
AB Malignant lung nodules are the worse stage for lung cancer patients. Early detection of lung nodules is essential for early treatment of the patients and significantly improves their survival rate. Recently, several computer-aided diagnosis (CAD) schemes based on deep learning approaches have been suggested to assist in lung nodule diagnosis. This study presents a 3D U-shaped encoding and decoding deep convolutional neural network (CNN) integrated with channel attention mechanisms for lung nodule detection in chest CT images. The U-shaped network applies the encoder to extract nodule representation features and the decoder to indicate the prediction results of the nodule candidates. Hybrid efficient channel attention (ECA) modules are integrated to enhance network representation power by retaining rich contextual nodule information and suppressing useless features. Correspondingly, the 3D regional proposal network (RPN) with three anchor boxes is employed for multilevel nodule candidates detection. The Lung Nodule Analysis 2016 (LUNA16) dataset was used to validate the proposed method. Experimental results show that through 10-fold cross-validation, the proposed algorithm gives the highest detection sensitivity of 98.65% and the competition performance metric (CPM) value of 0.911. Therefore, the results of our design show competitiveness compared with the methods in the prior studies for lung nodule detection in chest CT images.
C1 [Mkindu, Hassan; Wu, Longwen; Zhao, Yaqin] Harbin Inst Technol, Sch Elect & Informat Engn, Harbin 150001, Peoples R China.
C3 Harbin Institute of Technology
RP Wu, LW (corresponding author), Harbin Inst Technol, Sch Elect & Informat Engn, Harbin 150001, Peoples R China.
EM hmkindu@hit.edu.cn; wulongwen@hit.edu.cn; yaqinzhao@hit.edu.cn
RI Wu, Longwen/ACU-0254-2022
OI Wu, Longwen/0000-0002-6914-6695
CR Afshar P, 2021, PATTERN RECOGN, V116, DOI 10.1016/j.patcog.2021.107942
   [Anonymous], 2021, LIDC IDRI CANC IMAGI
   [Anonymous], 2021, LUNG NODULE ANAL
   Cao HC, 2019, IEEE ACCESS, V7, P67380, DOI 10.1109/ACCESS.2019.2906116
   Chen LY, 2021, COMPUT MED IMAG GRAP, V89, DOI 10.1016/j.compmedimag.2021.101899
   De Moura J., 2018, IEEE T MED IMAGING, V7, P1, DOI DOI 10.1117/12.2285954
   Dou Q, 2017, IEEE T BIO-MED ENG, V64, P1558, DOI 10.1109/TBME.2016.2613502
   Dutande P, 2021, BIOMED SIGNAL PROCES, V67, DOI 10.1016/j.bspc.2021.102527
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gong L, 2019, INT J COMPUT ASS RAD, V14, P1969, DOI 10.1007/s11548-019-01979-1
   Gu DD, 2021, COMPUT MED IMAG GRAP, V89, DOI 10.1016/j.compmedimag.2021.101886
   Gu Y, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0210551
   Halder A, 2020, J DIGIT IMAGING, V33, P655, DOI 10.1007/s10278-020-00320-6
   Heuvelmans MA, 2021, LUNG CANCER, V154, P1, DOI 10.1016/j.lungcan.2021.01.027
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang XJ, 2017, I S BIOMED IMAGING, P379, DOI 10.1109/ISBI.2017.7950542
   Janocha Katarzyna, 2017, Theor Found Mach Learn, DOI [DOI 10.4467/20838476SI.16.004.6185, 10.4467/20838476SI.16. 004.6185]
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Jenuwine NM, 2018, PROC SPIE, V10575, DOI 10.1117/12.2293918
   Jiang HY, 2018, IEEE J BIOMED HEALTH, V22, P1227, DOI 10.1109/JBHI.2017.2725903
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Li YM, 2020, I S BIOMED IMAGING, P1866, DOI [10.1109/ISBI45749.2020.9098317, 10.1109/isbi45749.2020.9098317]
   Liu JY, 2019, IRAN J RADIOL, V16, DOI 10.5812/iranjradiol.65034
   Lv WH, 2021, LUNG CANCER, V155, P78, DOI 10.1016/j.lungcan.2021.03.008
   Mittapalli PS, 2021, ARTIF INTELL MED, V113, DOI 10.1016/j.artmed.2021.102017
   Qin RX, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/6153657
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Schückes M, 2021, SMALL BUS ECON, V57, P1027, DOI 10.1007/s11187-020-00337-9
   Setio AAA, 2016, IEEE T MED IMAGING, V35, P1160, DOI 10.1109/TMI.2016.2536809
   Valente IRS, 2016, COMPUT METH PROG BIO, V124, P91, DOI 10.1016/j.cmpb.2015.10.006
   Wang J, 2019, IEEE ACCESS, V7, P46033, DOI 10.1109/ACCESS.2019.2908195
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang Q, 2019, J DIGIT IMAGING, V32, P971, DOI 10.1007/s10278-019-00221-3
   Xie HT, 2019, PATTERN RECOGN, V85, P109, DOI 10.1016/j.patcog.2018.07.031
   Xu QQ, 2021, EUR J RADIOL, V139, DOI 10.1016/j.ejrad.2021.109667
   Zhang MY, 2023, CONCURR COMP-PRACT E, V35, DOI 10.1002/cpe.6237
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhu WT, 2018, IEEE WINT CONF APPL, P673, DOI 10.1109/WACV.2018.00079
   Zuo WX, 2019, IEEE ACCESS, V7, P32510, DOI 10.1109/ACCESS.2019.2903587
NR 39
TC 4
Z9 4
U1 9
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 25747
EP 25760
DI 10.1007/s11042-023-14581-0
EA MAR 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000943009100012
DA 2024-07-18
ER

PT J
AU Shao, XT
   Guo, Y
   Shen, Y
   Qian, MY
   Wang, ZL
AF Shao, Xiaotao
   Guo, Yan
   Shen, Yan
   Qian, Manyi
   Wang, Zhongli
TI From local to global: a multi-group feature enhancement network for
   non-uniform and dense haze removal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-uniform haze; Dense haze; Global and local context fusion; Feature
   residual enhancement
AB In the past few years, significant research on single-image dehazing has developed rapidly. Despite this effort, it is still hard to remove the dense haze completely, particularly in complex real-world cases. The real-world haze is non-uniform and varied (light or dense). In the non-uniform case, the structure of the image can be destroyed. Besides, the procedure of dense haze removal usually leads to color distortion, detail loss and structure blurring, which increases the difficulty of image restoration. To solve these problems, we propose a multi-group feature enhancement network (MGFEN) based on a global and local context fusion pattern to remove haze progressively. Unlike previous methods, we develop a global feature fusion (GFF) module which takes a more global perspective to extract features and performs attention fusion with high-frequency features obtained from the Laplace pyramid to effectively preserve structure information of the image and remove artifacts caused by non-uniform haze. We also design a feature residual enhancement (FRE) module to improve image details and boost color fidelity by enhancing effective residuals group by group. The Experimental results of different datasets show that our MGFEN establishes the new state-of-the-art performance for real-world non-uniform and dense haze removal both in objective metrics and visual quality with better structure and color recovery ability.
C1 [Shao, Xiaotao; Guo, Yan; Shen, Yan; Qian, Manyi; Wang, Zhongli] Beijing Jiaotong Univ, Sch Elect & Informat Engn, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University
RP Shen, Y (corresponding author), Beijing Jiaotong Univ, Sch Elect & Informat Engn, Beijing 100044, Peoples R China.
EM sheny@bjtu.edu.cn
FU Ministry of Education [8091B0203]; National Science and Technology
   Innovation 2030 Major Program [2022ZD0205000]
FX This study was supported by the Joint Fund of Ministry of Education for
   Equipment Pre-research (Grant number 8091B0203) and National Science and
   Technology Innovation 2030 Major Program (Grantnumber 2022ZD0205000).
CR Ancuti CO, 2019, IEEE IMAGE PROC, P1014, DOI [10.1109/icip.2019.8803046, 10.1109/ICIP.2019.8803046]
   Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119
   [Anonymous], 1952, VISION ATMOSPHERE
   Berman D, 2020, IEEE T PATTERN ANAL, V42, P720, DOI 10.1109/TPAMI.2018.2882478
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Bu QR, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10175898
   Chen Y, 2018, PROC CVPR IEEE, P3339, DOI 10.1109/CVPR.2018.00352
   Chen ZY, 2021, PROC CVPR IEEE, P7176, DOI 10.1109/CVPR46437.2021.00710
   Dong H, 2020, PROC CVPR IEEE, P2154, DOI 10.1109/CVPR42600.2020.00223
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Guo CL, 2022, PROC CVPR IEEE, P5802, DOI 10.1109/CVPR52688.2022.00572
   Hassan H, 2022, APPL INTELL, V52, P16334, DOI 10.1007/s10489-022-03245-5
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hong M, 2020, PROC CVPR IEEE, P3459, DOI 10.1109/CVPR42600.2020.00352
   Huang YF, 2021, IEEE IMAGE PROC, P3852, DOI 10.1109/ICIP42928.2021.9506603
   Kan SC, 2022, SIGNAL PROCESS-IMAGE, V102, DOI 10.1016/j.image.2021.116599
   Khan S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3505244
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu H., 2022, P IEEECVF C COMPUTER, P5831
   Liu S, 2019, ARXIV
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Sakaridis C, 2018, LECT NOTES COMPUT SC, V11217, P707, DOI 10.1007/978-3-030-01261-8_42
   Sakaridis C, 2018, INT J COMPUT VISION, V126, P973, DOI 10.1007/s11263-018-1072-8
   Shao XT, 2021, IEEE ACCESS, V9, P849, DOI 10.1109/ACCESS.2020.3046498
   Shao YJ, 2020, PROC CVPR IEEE, P2805, DOI 10.1109/CVPR42600.2020.00288
   Sharma T, 2020, MULTIMED TOOLS APPL, V79, P30769, DOI 10.1007/s11042-020-09496-z
   Song Y., 2022, ARXIV
   Wang C, 2020, J VIS COMMUN IMAGE R, V72, DOI 10.1016/j.jvcir.2020.102897
   Wang T, 2021, NEUROCOMPUTING, V439, P75, DOI 10.1016/j.neucom.2021.01.042
   Wu HY, 2021, PROC CVPR IEEE, P10546, DOI 10.1109/CVPR46437.2021.01041
   Yang C., 2022, P IEEE CVF C COMP VI, P2037
   Yang HH, 2020, INT CONF ACOUST SPEE, P2628, DOI [10.1109/ICASSP40776.2020.9053920, 10.1109/icassp40776.2020.9053920]
   Yu YK, 2021, IEEE COMPUT SOC CONF, P193, DOI 10.1109/CVPRW53098.2021.00028
   Zamir SW, 2022, PROC CVPR IEEE, P5718, DOI 10.1109/CVPR52688.2022.00564
   Zhang Hongyi, 2018, MIXUP EMPIRICAL RISK, DOI DOI 10.48550/ARXIV.1710.09412
   Zhang XY, 2021, PROC CVPR IEEE, P9235, DOI 10.1109/CVPR46437.2021.00912
   Zhao WX, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14010001
   Zotti C, 2018, LECT NOTES COMPUT SC, V10663, P73, DOI 10.1007/978-3-319-75541-0_8
NR 45
TC 0
Z9 0
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 27057
EP 27073
DI 10.1007/s11042-023-14950-9
EA MAR 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000943009100018
DA 2024-07-18
ER

PT J
AU Moran, J
   Qing, H
AF Moran, Ju
   Qing, Hu
TI Brain-inspired filtering Network for small infrared target detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Small infrared target detection;
   Brain-inspired; Filtering mechanism
ID LOCALIZATION
AB Small infrared target detection is a challenge in computer vision because small infrared target occupies fewer pixels and the environment around the small infrared targets is complex. Although numerous small infrared target detection methods have been proposed, training an end-to-end deep detection model for small infrared target has not been thoroughly investigated. In this paper, we design a brain-inspired neural network (FilterDet) for small infrared target detection. There are two inter-connected modules in FilterDet, namely the brain-inspired filtering module and the target detection module. Brain-inspired filtering module consists of bottom-up filtering module and top-down filtering module which are modeled by bottom-up filtering mechanism and top-down filtering mechanism of the human brain, aiming to filter out the complex environment and interference. Target detection module takes the filtered infrared images as input and performs small infrared target detection. To train FilterDet in an end-to-end way, the loss function is designed by multi-task loss. Furthermore, we build a synthetic single frame infrared image set by generating synthetic infrared images with small targets. Comparative experiments are conducted on three real infrared image sequences and the single frame infrared image set to demonstrate the detection performance of FilterDet. The results show FilterDet has better performance for small infrared target detection compared with other detectors.
C1 [Moran, Ju; Qing, Hu] Dalian Maritime Univ, Coll Informat Sci & Technol, Dalian 116026, Liaoning, Peoples R China.
C3 Dalian Maritime University
RP Moran, J (corresponding author), Dalian Maritime Univ, Coll Informat Sci & Technol, Dalian 116026, Liaoning, Peoples R China.
EM jumoran@dlmu.edu.cn
FU National Natural Science Foundation of China [62201114]; Fundamental
   Research Funds for the Central Universities [3132022242]
FX The authors acknowledge National Natural Science Foundation of China
   (Grant no. 62201114) and~the Fundamental Research Funds for the Central
   Universities (Grant no. 3132022242).
CR Benicasa A X, 2012, 2012 INT JOINT C NEU, P1
   Cai YF, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3065438
   Chen CLP, 2014, IEEE T GEOSCI REMOTE, V52, P574, DOI 10.1109/TGRS.2013.2242477
   Chen SH, 2020, INFRARED PHYS TECHN, V105, DOI 10.1016/j.infrared.2019.103184
   Chen YW, 2016, IEEE GEOSCI REMOTE S, V13, P962, DOI 10.1109/LGRS.2016.2556218
   Dai YM, 2016, INFRARED PHYS TECHN, V77, P421, DOI 10.1016/j.infrared.2016.06.021
   Deshpande SD, 1999, P SOC PHOTO-OPT INS, V3809, P74, DOI 10.1117/12.364049
   Gao CQ, 2013, IEEE T IMAGE PROCESS, V22, P4996, DOI 10.1109/TIP.2013.2281420
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Han JH, 2014, IEEE GEOSCI REMOTE S, V11, P2168, DOI 10.1109/LGRS.2014.2323236
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hui B., 2019, CHINA SCI DATA, DOI [10.11922/csdata.2019.0074.zh, DOI 10.11922/CSDATA.2019.0074.ZH]
   Jiang BT, 2019, INFRARED PHYS TECHN, V97, P229, DOI 10.1016/j.infrared.2018.12.040
   Katsuki Fumi, 2014, Neuroscientist, V20, P509, DOI 10.1177/1073858413514136
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Li YC, 2021, EXPERT SYST APPL, V184, DOI 10.1016/j.eswa.2021.115543
   Liu M, 2017, CURRENT TRENDS IN COMPUTER SCIENCE AND MECHANICAL AUTOMATION, VOL 1, P211
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Loshchilov I, 2016, ARXIV
   Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Shi M, 2019, MOBILE NETW APPL, P1
   TOM VT, 1993, P SOC PHOTO-OPT INS, V1954, P2, DOI 10.1117/12.157758
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang H, 2020, MULTIMED TOOLS APPL, V79, P35383, DOI 10.1007/s11042-019-7643-z
   Wang H, 2019, IEEE I CONF COMP VIS, P8508, DOI 10.1109/ICCV.2019.00860
   Wei YT, 2016, PATTERN RECOGN, V58, P216, DOI 10.1016/j.patcog.2016.04.002
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Zeng M, 2006, INFRARED PHYS TECHN, V48, P67, DOI 10.1016/j.infrared.2005.04.006
   Zhang DQ, 2021, IEEE T RELIAB, V70, P887, DOI 10.1109/TR.2020.3001232
   Zhang DW, 2022, IEEE T PATTERN ANAL, V44, P5866, DOI 10.1109/TPAMI.2021.3074313
   Zhang DW, 2019, INT J COMPUT VISION, V127, P363, DOI 10.1007/s11263-018-1112-4
   Zhang P., 2021, IEEE T IMAGE PROCESS, V99, P1
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang XY., 2017, INFRARED LASER ENG, V46, P0726002, DOI 10.3788/IRLA201746.0726002
NR 41
TC 2
Z9 2
U1 24
U2 84
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 28405
EP 28426
DI 10.1007/s11042-023-14762-x
EA MAR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000941926100009
DA 2024-07-18
ER

PT J
AU Xu, K
   Yang, GM
   Fang, XJ
   Zhang, J
AF Xu, Kun
   Yang, Gaoming
   Fang, Xianjin
   Zhang, Ji
TI Facial depth forgery detection based on image gradient
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial depth forgery detection; DeepFakes detection; Image gradient;
   Deep learning
ID FACE MANIPULATION
AB With the widespread application of deep learning, many artificially generated fake images and videos appear on the Internet. However, it is difficult for people to distinguish the real from the fake ones, making the research on detecting and recognizing fake images or videos receive significant attention. Since new forgery techniques can reduce the effectiveness of specific detection methods or even make them ineffective, research on detecting facial depth forgery needs to be continuously developed. To defend against the onslaught of new facial depth forgery methods, we proposed an image gradient-based approach to transform the facial depth forgery detection problem into the recognition and analysis of video frames. Specifically, there are two key components in this approach: (1) we capture images from videos and crop the face section, which dramatically reduces the amount of data; (2) we use the image gradient operator to process the face image that extracts image features for detection and recognition. After these, we have conducted extensive experiments on different facial depth forgery datasets. Experimental results demonstrated that using our image gradient approach could effectively detect facial depth forgery and achieve excellent detection and identification performance.
C1 [Xu, Kun; Yang, Gaoming; Fang, Xianjin] Anhui Univ Sci & Technol, Sch Comp Sci & Engn, Huainan, Peoples R China.
   [Zhang, Ji] Univ Southern Queensland, Dept Math & Comp, Toowoomba, Qld, Australia.
C3 Anhui University of Science & Technology; University of Southern
   Queensland
RP Yang, GM (corresponding author), Anhui Univ Sci & Technol, Sch Comp Sci & Engn, Huainan, Peoples R China.
EM gmyang@aust.edu.cn
RI wang, shuo/KCL-3379-2024; Xu, Kun/GXV-6266-2022
OI Xu, Kun/0000-0002-1866-4433; fang, xian jin/0000-0002-3894-2007; Yang,
   Gaoming/0000-0002-7666-1038
FU Natural Science Foundation of Anhui Province of China [2008085MF220];
   School Foundation of Anhui University of Science and Technology
   [2021CX2102]
FX AcknowledgementsThis work was supported by the Natural Science
   Foundation of Anhui Province of China under Grant No.2008085MF220, and
   the School Foundation of Anhui University of Science and Technology
   under Grant No.2021CX2102.
CR Afchar D, 2018, IEEE INT WORKS INFOR
   Agarwal, 2019, 2019 IEEECVF C COMPU
   Bonettini N, 2021, INT C PATT RECOG, P5012, DOI 10.1109/ICPR48806.2021.9412711
   Chesney B, 2019, CALIF LAW REV, V107, P1753, DOI 10.15779/Z38RV0D15J
   Dang H, 2020, PROC CVPR IEEE, P5780, DOI 10.1109/CVPR42600.2020.00582
   Dolhansky B., 2020, arXiv
   Fei JW, 2021, MULTIMED TOOLS APPL, V80, P30789, DOI 10.1007/s11042-020-09147-3
   Gonzalez RC, 2009, DIGITAL IMAGE PROCES, DOI 10.1117/1.3115362
   Güera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   Guo ZQ, 2021, MULTIMED TOOLS APPL, V80, P7687, DOI 10.1007/s11042-020-10098-y
   Ha S, 2020, AAAI CONF ARTIF INTE, V34, P10893
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Nguyen HD, 2019, INT J ADV MANUF TECH, V104, P211, DOI 10.1007/s00170-019-03352-7
   Jeon H. J., 2020, IFIP INT C ICT SYST
   Johnston P, 2020, NEURAL COMPUT APPL, V32, P12243, DOI 10.1007/s00521-019-04272-z
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kingma DP, 2018, ADV NEUR IN, V31
   Korshunova I, 2017, IEEE I CONF COMP VIS, P3697, DOI 10.1109/ICCV.2017.397
   Li LZ, 2020, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR42600.2020.00505
   Li YZ, 2017, ADV NEUR IN, V30
   Li YZ, 2020, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR42600.2020.00327
   Liu HG, 2021, PROC CVPR IEEE, P772, DOI 10.1109/CVPR46437.2021.00083
   Liu S, 2021, IEEE T MULTIMEDIA, V23, P2188, DOI 10.1109/TMM.2021.3065580
   Liu S, 2021, IEEE T FUZZY SYST, V29, P90, DOI 10.1109/TFUZZ.2020.3006520
   Liu S, 2021, COMPLEX INTELL SYST, V7, P1895, DOI 10.1007/s40747-020-00161-4
   Liu X., 2020, P IEEE CVF C COMP VI, P8057
   Masi Iacopo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P667, DOI 10.1007/978-3-030-58571-6_39
   Mirsky Y, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3425780
   Nguyen HH, 2019, INT CONF ACOUST SPEE, P2307, DOI 10.1109/ICASSP.2019.8682602
   Pan D, 2020, 2020 IEEE/ACM INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING, APPLICATIONS AND TECHNOLOGIES (BDCAT 2020), P134, DOI 10.1109/BDCAT50828.2020.00001
   Pumarola A, 2020, INT J COMPUT VISION, V128, P698, DOI 10.1007/s11263-019-01210-3
   Qian Y., 2020, EUROPEAN C COMPUTER, V12357, P86, DOI 10.1007/978-3- 030-58610-2 6
   Rossi A, 2020, IEEE T INTELL TRANSP, V21, P2980, DOI 10.1109/TITS.2019.2922002
   Ruiz N., 2020, EUR C COMP VIS, P236, DOI [10.1007/978-3-030-66823-5_14, DOI 10.1007/978-3-030-66823-5_14]
   Shang ZH, 2021, PATTERN RECOGN, V116, DOI 10.1016/j.patcog.2021.107950
   Singh A., 2020, SN Comput. Sci., V1, P1, DOI [10.1007/s42979-020-00225-9, DOI 10.1007/S42979-020-00225-9]
   Tan M., 2020, INT C MACH LEARN, DOI DOI 10.48550/ARXIV.1905.11946
   Tolosana Ruben, 2020, Information Fusion, V64, P131, DOI 10.1016/j.inffus.2020.06.014
   Wang KD, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON SIMULATION, MODELING, AND PROGRAMMING FOR AUTONOMOUS ROBOTS (SIMPAR), P1, DOI 10.1109/SIMPAR.2018.8376263
   Wang M, 2021, NEUROCOMPUTING, V429, P215, DOI 10.1016/j.neucom.2020.10.081
   Wang W, 2011, LECT NOTES COMPUT SC, V6526, P120, DOI 10.1007/978-3-642-18405-5_10
   Wang ZZ, 2020, PROC CVPR IEEE, P5041, DOI 10.1109/CVPR42600.2020.00509
   Zakharov E, 2019, IEEE I CONF COMP VIS, P9458, DOI 10.1109/ICCV.2019.00955
   Zhang JN, 2020, PROC CVPR IEEE, P5325, DOI 10.1109/CVPR42600.2020.00537
   Zhang WG, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22020249
   Zhao HQ, 2021, PROC CVPR IEEE, P2185, DOI 10.1109/CVPR46437.2021.00222
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
   Zhu BQ, 2020, PROCEEDINGS OF THE 3RD AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY AIES 2020, P414, DOI 10.1145/3375627.3375849
NR 49
TC 4
Z9 4
U1 13
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29501
EP 29525
DI 10.1007/s11042-023-14626-4
EA FEB 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000940065100005
DA 2024-07-18
ER

PT J
AU Huan, RH
   Zhang, J
   Xie, CJ
   Liang, RH
   Chen, P
AF Huan, Ruohong
   Zhang, Ji
   Xie, Chaojie
   Liang, Ronghua
   Chen, Peng
TI MLFFCSP: a new anti-occlusion pedestrian detection network with
   multi-level feature fusion for small targets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pedestrian detection; Multi-level; Feature; Fusion; Anti-occlusion;
   Small targets
AB Pedestrian detection relying on deep convolution neural networks has achieved significant progress. However, the performance of current pedestrian detection algorithms remains unsatisfactory when it comes to small targets or heavily occluded pedestrians. In this paper, a new anti-occlusion video pedestrian detection network with multi-level feature fusion named MLFFCSP is proposed for small targets and heavily occluded pedestrians. In the proposed network, the pyramid convolutional neural network PyConvResNet101 is used as backbone to extract features. Then, the shallow and deep features are fused at multiple levels to fully obtain the shallow location information and deep semantic information. In order to improve the robustness of the model, data augmentation is also implemented via random erasing on the training data. Experiments are carried out on Caltech and Citypersons datasets, and the log-average miss rate is used to evaluate the performance of the model. The results show that the performance of MLFFCSP is better than other pedestrian detection algorithms in the case of small targets and serious occlusion.
C1 [Huan, Ruohong; Zhang, Ji; Xie, Chaojie; Liang, Ronghua; Chen, Peng] Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University of Technology
RP Huan, RH (corresponding author), Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou, Zhejiang, Peoples R China.
EM huanrh@zjut.edu.cn; 1425069443@qq.com; 408261278@qq.com;
   rhliang@zjut.edu.cn; chenpeng@zjut.edu.cn
RI Chen, Peng/T-7500-2019; liang, ronghua/H-4463-2012
OI Chen, Peng/0000-0001-6122-0574; 
FU National Natural Science Foundation of China [U1909203, 62036009]
FX This work was supported by National Natural Science Foundation of China
   [grant number U1909203, 62036009].This study was funded by National
   Natural Science Foundation of China (grant number U1909203, 62036009)
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.141
   Brazil G, 2017, IEEE I CONF COMP VIS, P4960, DOI 10.1109/ICCV.2017.530
   Cai JW, 2020, IEEE ACCESS, V8, P179666, DOI 10.1109/ACCESS.2020.3027590
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Cai ZW, 2015, IEEE I CONF COMP VIS, P3361, DOI 10.1109/ICCV.2015.384
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Dollar Piotr, 2009, BMVC, DOI 10.5244/ C.23.91
   Du XZ, 2017, IEEE WINT CONF APPL, P953, DOI 10.1109/WACV.2017.111
   Duta IC., 2020, P IEEE COMP SOC C CO
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Jiang W., 2019, IEEE ICC, P5, DOI DOI 10.1109/icc.2019.8761422
   Kong T, 2020, IEEE T IMAGE PROCESS, V29, P7389, DOI 10.1109/TIP.2020.3002345
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Li JN, 2018, IEEE T MULTIMEDIA, V20, P985, DOI 10.1109/TMM.2017.2759508
   Lin CZ, 2020, IEEE T IMAGE PROCESS, V29, P3820, DOI 10.1109/TIP.2020.2966371
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu ST, 2019, PROC CVPR IEEE, P6452, DOI 10.1109/CVPR.2019.00662
   Liu W, 2018, LECT NOTES COMPUT SC, V11218, P643, DOI 10.1007/978-3-030-01264-9_38
   Liu W, 2019, PROC CVPR IEEE, P5182, DOI 10.1109/CVPR.2019.00533
   Lu R., 2019, P IEEE COMPUTER SOC
   Ma J, 2021, SIGNAL IMAGE VIDEO P, V15, P231, DOI 10.1007/s11760-020-01742-z
   Mao JY, 2017, PROC CVPR IEEE, P6034, DOI 10.1109/CVPR.2017.639
   Mingxing Tan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10778, DOI 10.1109/CVPR42600.2020.01079
   Ning Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11940, DOI 10.1109/CVPR42600.2020.01196
   Ouyang WL, 2013, PROC CVPR IEEE, P3198, DOI 10.1109/CVPR.2013.411
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ruan BJ, 2021, IET IMAGE PROCESS, V15, P2292, DOI 10.1049/ipr2.12196
   Song T, 2018, LECT NOTES COMPUT SC, V11211, P554, DOI 10.1007/978-3-030-01234-2_33
   Srinivasu PN, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.654
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Tan YZ, 2021, INT C PATT RECOG, P6059, DOI 10.1109/ICPR48806.2021.9412031
   Tang SY, 2014, INT J COMPUT VISION, V110, P58, DOI 10.1007/s11263-013-0664-6
   Tian YL, 2015, IEEE I CONF COMP VIS, P1904, DOI 10.1109/ICCV.2015.221
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Trajkovska, 2017, LEARNING PROBABILIST, P1, DOI [10.11588/heidok.00023778, DOI 10.11588/HEIDOK.00023778]
   Wang S., 2017, P IEEE COMPUTER SOC
   Wang W., 2020, P IEEE COMP SOC C CO
   Wang XL, 2018, PROC CVPR IEEE, P7774, DOI 10.1109/CVPR.2018.00811
   Wenshuo Ma, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P560, DOI 10.1007/978-3-030-58558-7_33
   Wojek C., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1993, DOI 10.1109/CVPR.2011.5995547
   Xie J, 2021, SCI CHINA INFORM SCI, V64, DOI 10.1007/s11432-020-2969-8
   Xu Z., 2020, ADV NEUR IN
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
   Zhang SF, 2018, LECT NOTES COMPUT SC, V11207, P657, DOI 10.1007/978-3-030-01219-9_39
   Zhang XW., 2017, P IEEE COMPUTER SOC
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhou CL, 2017, IEEE I CONF COMP VIS, P3506, DOI 10.1109/ICCV.2017.377
   Zhu CC, 2019, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2019.00093
NR 56
TC 3
Z9 3
U1 11
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29405
EP 29430
DI 10.1007/s11042-023-14721-6
EA FEB 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000937854600009
DA 2024-07-18
ER

PT J
AU Kumar, P
   Suresh, S
AF Kumar, Prabhat
   Suresh, S.
TI Deep-HAR: an ensemble deep learning model for recognizing the simple,
   complex, and heterogeneous human activities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human activity recognition; Class imbalance problem; CNNs; RNNs;
   Wireless sensor technology
ID HUMAN ACTIVITY RECOGNITION; PHYSICAL-ACTIVITY RECOGNITION;
   NEURAL-NETWORK; SUSTAINABILITY
AB The recognition of human activities has become a dominant emerging research problem and widely covered application areas in surveillance, wellness management, healthcare, and many more. In real life, the activity recognition is a challenging issue because human beings are often performing the activities not only simple but also complex and heterogeneous in nature. Most of the existing approaches are addressing the problem of recognizing only simple straightforward activities (e.g. walking, running, standing, sitting, etc.). Recognizing the complex and heterogeneous human activities are a challenging research problem whereas only a limited number of existing works are addressing this issue. In this paper, we proposed a novel Deep-HAR model by ensembling the Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) for recognizing the simple, complex, and heterogeneous type activities. Here, the CNNs are used for extracting the features whereas RNNs are used for finding the useful patterns in time-series sequential data. The activities recognition performance of the proposed model was evaluated using three different publicly available datasets, namely WISDM, PAMAP2, and KU-HAR. Through extensive experiments, we have demonstrated that the proposed model performs well in recognizing all types of activities and has achieved an accuracy of 99.98%, 99.64%, and 99.98% for simple, complex, and heterogeneous activities respectively.
C1 [Kumar, Prabhat; Suresh, S.] Banaras Hindu Univ, Inst Sci, Dept Comp Sci, Varanasi 221005, India.
C3 Banaras Hindu University (BHU)
RP Kumar, P (corresponding author), Banaras Hindu Univ, Inst Sci, Dept Comp Sci, Varanasi 221005, India.
EM prabhat.kumar13@bhu.ac.in
FU UGC, New Delhi
FX The authors would like to express their gratitude to the anonymous
   reviewers for their insightful comments, which greatly improved the
   quality of the paper. The authors are grateful for the support provided
   by the UGC, New Delhi through the JRF and Banaras Hindu University
   through the Institute of Eminence (IoE) Seed Grant.
CR Agarwal P, 2020, PROCEDIA COMPUT SCI, V167, P2364, DOI 10.1016/j.procs.2020.03.289
   [Anonymous], 2009, Pervasive Computing and Communications, DOI DOI 10.1109/PERCOM.2009.4912776
   Cao Y, 2020, NAT MACH INTELL, V2, P500, DOI 10.1038/s42256-020-0217-y
   Chen WH, 2017, 2017 IEEE 19TH INTERNATIONAL CONFERENCE ON E-HEALTH NETWORKING, APPLICATIONS AND SERVICES (HEALTHCOM), DOI 10.1109/HealthCom.2017.8210846
   De Vita A, 2021, MICROPROCESS MICROSY, V87, DOI 10.1016/j.micpro.2021.104371
   Dhillon A, 2020, PROG ARTIF INTELL, V9, P85, DOI 10.1007/s13748-019-00203-0
   Dhiman C, 2019, ENG APPL ARTIF INTEL, V77, P21, DOI 10.1016/j.engappai.2018.08.014
   Luptáková ID, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22051911
   Tran DN, 2016, P INT CONF INTELL, P64, DOI 10.1109/ISMS.2016.51
   Elshafei M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030759
   Fridriksdottir E, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20226424
   Ganaie MA, 2022, ENG APPL ARTIF INTEL, V115, DOI 10.1016/j.engappai.2022.105151
   Gao WB, 2021, APPL SOFT COMPUT, V111, DOI 10.1016/j.asoc.2021.107728
   Garcia-Ceja E, 2018, PROCEDIA COMPUT SCI, V130, P157, DOI 10.1016/j.procs.2018.04.025
   Gardas BB, 2019, J CLEAN PROD, V229, P850, DOI 10.1016/j.jclepro.2019.05.018
   Gil-Martín M, 2020, ENG APPL ARTIF INTEL, V92, DOI 10.1016/j.engappai.2020.103679
   Han CL, 2022, EXPERT SYST APPL, V198, DOI 10.1016/j.eswa.2022.116764
   Hoang ML, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21072313
   Huh JH, 2019, IEEE ACCESS, V7, P164229, DOI 10.1109/ACCESS.2019.2945338
   Inoue M, 2018, ARTIF LIFE ROBOT, V23, P173, DOI 10.1007/s10015-017-0422-x
   Ishii S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21010091
   Janarthanan R, 2020, MEASUREMENT, V164, DOI 10.1016/j.measurement.2020.108050
   Jethanandani M, 2020, INTERNET THINGS-NETH, V12, DOI 10.1016/j.iot.2020.100324
   Kasnesis P, 2021, PATTERN RECOGN LETT, V146, P90, DOI 10.1016/j.patrec.2021.03.003
   Kim E, 2010, IEEE PERVAS COMPUT, V9, P48, DOI 10.1109/MPRV.2010.7
   Kim Y, 2016, IEEE ACCESS, V4, P1548, DOI 10.1109/ACCESS.2016.2547948
   Kiranyaz S, 2021, MECH SYST SIGNAL PR, V151, DOI 10.1016/j.ymssp.2020.107398
   Kolosnjaji B, 2015, LECT NOTES COMPUT SC, V9375, P378, DOI 10.1007/978-3-319-24834-9_44
   Kwapisz JR., 2011, ACM SIGKDD EXPLORATI, V12, P74, DOI [DOI 10.1145/1964897.1964918, 10.1145/1964897.1964918]
   Lee H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030785
   Lipton ZC, 2015, ARXIV, DOI DOI 10.48550/ARXIV.1506.00019
   Liu L, 2016, INFORM SCIENCES, V340, P41, DOI 10.1016/j.ins.2016.01.020
   Morales J, 2017, BIOCYBERN BIOMED ENG, V37, P388, DOI 10.1016/j.bbe.2017.04.004
   Nahid A-A., 2020, PATTERN RECOGN LETT, V3, P46, DOI [10.1016/j.patrec.2021.02.024, DOI 10.1016/J.PATREC.2021.02.024]
   Park SW, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10101216
   Polap D, 2018, FUTURE GENER COMP SY, V87, P16, DOI 10.1016/j.future.2018.04.050
   Raut RD, 2019, J CLEAN PROD, V224, P10, DOI 10.1016/j.jclepro.2019.03.181
   Reiss A, 2012, IEEE INT SYM WRBL CO, P108, DOI 10.1109/ISWC.2012.13
   Shrestha A, 2019, IEEE ACCESS, V7, P53040, DOI 10.1109/ACCESS.2019.2912200
   Sindi H, 2021, MEASUREMENT, V171, DOI 10.1016/j.measurement.2020.108794
   Tao M, 2021, APPL SOFT COMPUT, V99, DOI 10.1016/j.asoc.2020.106788
   Tarafdar P, 2021, DECIS SUPPORT SYST, V140, DOI 10.1016/j.dss.2020.113426
   Thapa K, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20205770
   Ullah A, 2021, APPL SOFT COMPUT, V103, DOI 10.1016/j.asoc.2021.107102
   Wang JD, 2019, PATTERN RECOGN LETT, V119, P3, DOI 10.1016/j.patrec.2018.02.010
   Wang T, 2022, KNOWL-BASED SYST, V243, DOI 10.1016/j.knosys.2022.108459
   Wang Y, 2019, EXPERT SYST APPL, V137, P167, DOI 10.1016/j.eswa.2019.04.057
   Weiss GM, 2019, IEEE ACCESS, V7, P133190, DOI 10.1109/ACCESS.2019.2940729
   Weiss GM, 2016, 2016 3RD IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL AND HEALTH INFORMATICS, P426, DOI 10.1109/BHI.2016.7455925
   Wozniak M, 2018, COMPUT METH PROG BIO, V161, P173, DOI 10.1016/j.cmpb.2018.04.025
   Xiao YW, 2018, COMPUT METH PROG BIO, V153, P1, DOI 10.1016/j.cmpb.2017.09.005
   Ye J, 2015, PERVASIVE MOB COMPUT, V19, P47, DOI 10.1016/j.pmcj.2014.02.003
   Zhang WT, 2019, IEEE ACCESS, V7, P80027, DOI 10.1109/ACCESS.2019.2922974
   Zhou T, 2021, APPL SOFT COMPUT, V98, DOI 10.1016/j.asoc.2020.106885
NR 54
TC 7
Z9 7
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 30435
EP 30462
DI 10.1007/s11042-023-14492-0
EA FEB 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000936292600007
PM 36851913
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Potluri, T
   Venkatramaphanikumar, S
   Kishore, KVK
AF Potluri, Tejaswi
   Venkatramaphanikumar, S.
   Kishore, K. Venkata Krishna
TI An automated online proctoring system using attentive-net to assess
   student mischievous behavior
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Online proctoring; Face spoofing; Face detection; Head pose estimation;
   Attentive -Net
ID HEAD POSE ESTIMATION; CONVOLUTIONAL NETWORKS; EXAMS
AB In recent years, the pandemic situation has forced the education system to shift from traditional teaching to online teaching or blended learning. The ability to monitor remote online examinations efficiently is a limiting factor to the scalability of this stage of online evaluation in the education system. Human Proctoring is the most used common approach by either asking learners to take a test in the examination centers or by monitoring visually asking learners to switch on their camera. However, these methods require huge labor, effort, infrastructure, and hardware. This paper presents an automated AI-based proctoring system- 'Attentive system' for online evaluation by capturing the live video of the examinee. Our Attentive system includes four components to estimate the malpractices such as face detection, multiple person detection, face spoofing, and head pose estimation. Attentive Net detects the faces and draws bounding boxes along with confidences. Attentive Net also checks the alignment of the face using the rotation matrix of Affine Transformation. The face net algorithm is combined with Attentive-Net to extract landmarks and facial features. The process for identifying spoofed faces is initiated only for aligned faces by using a shallow CNN Liveness net. The head pose of the examiner is estimated by using the SolvePnp equation, to check if he/she is seeking help from others. Crime Investigation and Prevention Lab (CIPL) datasets and customized datasets with various types of malpractices are used to evaluate our proposed system. Extensive Experimental results demonstrate that our method is more accurate, reliable and robust for proctoring system that can be practically implemented in real time environment as Automated proctoring System. An improved accuracy of 0.87 is reported by authors with the combination of Attentive Net, Liveness net and head pose estimation.
C1 [Potluri, Tejaswi; Venkatramaphanikumar, S.; Kishore, K. Venkata Krishna] Vignans Fdn Sci Technol & Res, Dept Comp Sci & Engn, Guntur, Andhra Pradesh, India.
C3 Vignan's Foundation for Science, Technology & Research (VFSTR)
RP Venkatramaphanikumar, S (corresponding author), Vignans Fdn Sci Technol & Res, Dept Comp Sci & Engn, Guntur, Andhra Pradesh, India.
EM svrphanikumar@yahoo.com
RI Potluri, Tejaswi/W-5943-2019; Sistla, Dr.
   Venkatramaphanikumar/HKN-2885-2023
OI Potluri, Tejaswi/0000-0003-3384-6507; Sistla, Dr.
   Venkatramaphanikumar/0000-0002-6861-6317
CR Albiero V, 2020, ARXIV
   Atoum Y, 2017, IEEE T MULTIMEDIA, V19, P1609, DOI 10.1109/TMM.2017.2656064
   Borghi G, 2020, IEEE T PATTERN ANAL, V42, P596, DOI 10.1109/TPAMI.2018.2885472
   Bu W, 2017, CASCADE FRAMEWORK MA, DOI 10.1109/ICCIS.2017.8274819
   BULAT A, 2016, LECT NOTES COMPUT SC
   Chang FJ, 2019, INT J COMPUT VISION, V127, P930, DOI 10.1007/s11263-019-01151-x
   CHEN D, 2014, LECT NOTES COMPUT SC
   Chen HN, 2020, IEEE T INF FOREN SEC, V15, P578, DOI 10.1109/TIFS.2019.2922241
   Chen W, 2019, FACE ALIGNMENT DISCR, DOI 10.1109/ICIP.2019.8803112
   Clarke NL, 2013, INTERNATIONAL CONFERENCE ON INFORMATION SOCIETY (I-SOCIETY 2013), P238
   Cluskey G.R., 2011, Journal of Academic and Business Ethics, V4, P1
   Cuimei L, 2017, HUMAN FACE DETECTION, DOI 10.1109/ICEMI.2017.8265863
   de Souza GB, 2017, IEEE T CIRCUITS-II, V64, P1397, DOI 10.1109/TCSII.2017.2764460
   Deshpande N.T., 2017, Advances in Computational Sciences and Technology, V10, P1173, DOI DOI 10.9790/0661-1806020106
   Dong S, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100379
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Gunther M, 2017, UNCONSTRAINED FACE D, DOI 10.1109/BTAS.2017.8272759
   Guo Ping, 2008, 2008 IEEE INT S IT M
   GUPTA A, 2019, INT CONF ACOUST SPEE
   Gupta P, 2018, INT J ENG MANUF, V8, DOI 10.5815/ijem.2018.01.06
   Han BJ, 2015, INT CONF WIRE COMMUN
   Hsu HW, 2019, IEEE T MULTIMEDIA, V21, P1035, DOI 10.1109/TMM.2018.2866770
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Jia JY, 2022, INTERACT TECHNOL SMA, V19, P112, DOI 10.1108/ITSE-12-2020-0246
   Jung IY, 2009, IEEE T EDUC, V52, P340, DOI 10.1109/TE.2008.928909
   Khan M, 2019, FACE DETECTION RECOG, DOI 10.1109/ICCCIS48478.2019.8974493
   Li, 2020, FACE DETECTION BASED, DOI 10.1007/978-981-13-9406-5_34
   Li L, 2018, J VIS COMMUN IMAGE R, V54, P182, DOI 10.1016/j.jvcir.2018.05.009
   Maatta Jukka., 2011, Face Spoofing Detection from Single Images Using Micro-texture Analysis, DOI 10.1109/IJCB.2011.6117510
   Milone AS, 2017, CURR PHARM TEACH LEA, V9, P108, DOI 10.1016/j.cptl.2016.08.037
   Motwani S, 2021, J IMMUNOTHER CANCER, DOI 10.2139/ssrn.3866446
   Patacchiola M, 2017, PATTERN RECOGN, V71, P132, DOI 10.1016/j.patcog.2017.06.009
   Potluri Tejaswi, 2016, Journal of Theoretical and Applied Information Technology, V85, P165
   Potluri T, 2019, CONTENT BASED VIDEO, P1035, DOI [10.1007/978-981-13-9181-1_24, DOI 10.1007/978-981-13-9181-1_24]
   Potluri T, 2017, ADV INTELL SYST, V507, P373, DOI 10.1007/978-981-10-2471-9_36
   Prathish S, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE (ICIS), P138, DOI 10.1109/INFOSCI.2016.7845315
   Priadana A, 2019, FACE DETECTION USING, DOI 10.1109/ICAIIT.2019.8834526
   ProctorU, REAL PEOPLE REAL PRO
   QIN X, 2017, PROC INT CONF DOC
   Rosen WA, 2013, AUTONOMOUS ARTICULAT, DOI 10.1109/FIE.2013.6685172
   RUIZ N, 2018, IEEE COMPUT SOC CONF
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   SHAO Z, 2020, NEUROCOMPUTING, V396
   Song X, 2019, PATTERN RECOGN, V85, P220, DOI 10.1016/j.patcog.2018.08.019
   Sun XD, 2018, NEUROCOMPUTING, V299, P42, DOI 10.1016/j.neucom.2018.03.030
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tsai YH, 2018, IMAGE VISION COMPUT, V78, P26, DOI 10.1016/j.imavis.2018.07.003
   Vaishali, 2019, INT RES J ENG TECHNO, V06, P5727
   Voss C, 2018, SYSTEMS METHODS DETE
   Wahid A, 2015, ACM IMCOM 2015, PROCEEDINGS, DOI 10.1145/2701126.2701203
   Wang YP, 2019, IEEE INT CONF CL NET
   Wang YJ, 2019, PATTERN RECOGN, V94, P196, DOI 10.1016/j.patcog.2019.05.026
   Wu SZ, 2019, INT J COMPUT VISION, V127, P560, DOI 10.1007/s11263-019-01157-5
   Wu WY, 2018, PROC CVPR IEEE, P2129, DOI 10.1109/CVPR.2018.00227
   XU X, 2017, IEEE INT CONF AUTOMA
   Xu YQ, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108210
   Yun Z, 2017, 2017 10TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI)
   Zhang HM, 2019, SIGNAL PROCESS-IMAGE, V78, P1, DOI 10.1016/j.image.2019.05.016
   Zhang Y, 2021, IEEE T EM TOP COMP I, V5, P726, DOI 10.1109/TETCI.2021.3100641
   Zhen XT, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2020.107311
NR 61
TC 1
Z9 1
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 30375
EP 30404
DI 10.1007/s11042-023-14604-w
EA FEB 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000936302600004
PM 36846528
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Dalai, R
   Dalai, N
   Senapati, KK
AF Dalai, Radhamadhab
   Dalai, Nibedita
   Senapati, Kishore Kumar
TI An accurate volume estimation on single view object images by deep
   learning based depth map analysis and 3D reconstruction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Volume estimation; Pre-processing; Feature extraction; Depth map;
   3DU-GNet; Single view; And deep learning
AB The volume estimation of a rigid object from a single view object image is the important need in numerous automated vision based systems. The volume estimation on multiple view images are simple to estimate. But volume estimation on a single view object image is a difficult process and has significant importance in volume estimation. This work presents effective object volume estimation in both regular and irregular single view object images. Initially, the single view input images are pre-processed with Mean-median filtering. Afterwards, edge features are extracted by utilizing the Gaussian edge based laplacian operator and key points are extracted using the Scale invariant feature transform (SIFT) feature. The extracted features are considered for the shape analysis of the objects. Subsequently, VGG-ResNet framework is utilized for depth analysis based on the extracted features. The point clouds generation for the volume estimation is attained through the extracted features. Finally, the volume estimation on single view object is effectively attained through the hybrid 3 dimensional U-Net and graph neural network (Hybrid 3DU-GNet). This framework provides the 3D geometric creation for the accurate volume estimation. This provides the significant improvement on volume estimation. The presented methodology effectively estimates the volume on both regular and irregular single view object images. The presented approach is implemented in the working platform of MATLAB. The experimental results of the presented work is analysed with the different existing approaches and proved the significant improvement in performance metrics. The performance metrics are Accuracy (98.59%), precision (98.21%), recall (97.09%), computational time (3.2 seconds), R-squared (98.2%), (Mean absolute percentage error) MAPE (6.1%), and (Root mean squared error) RMSE (0.93).
C1 [Dalai, Radhamadhab; Senapati, Kishore Kumar] BIT Mesra, Comp Sci & Engn, Ranchi 835215, Jharkhand, India.
   [Dalai, Nibedita] PMEC Coll, Civil Engn, Bhubaneswar 761003, Odisha, India.
C3 Birla Institute of Technology Mesra
RP Dalai, R (corresponding author), BIT Mesra, Comp Sci & Engn, Ranchi 835215, Jharkhand, India.
EM rdalai.teqip@bitmesra.ac.in
RI Senapati, Kishore Kumar/M-1222-2017
OI Senapati, Kishore Kumar/0000-0002-5696-4832
CR Ambrus R, 2019, ARXIV
   Chaudhuri K., 2009, P 26 ANN INT C MACH, P129
   Chen PH, 2020, IEEE T IMAGE PROCESS, V29, P7261, DOI 10.1109/TIP.2020.3000611
   Dehais J, 2017, IEEE T MULTIMEDIA, V19, P1090, DOI 10.1109/TMM.2016.2642792
   Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214
   Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393
   Goldman M, 2019, IEEE COMPUT SOC CONF, P2886, DOI 10.1109/CVPRW.2019.00348
   Guo YW, 2016, IEEE T IMAGE PROCESS, V25, P2610, DOI 10.1109/TIP.2016.2551374
   He L, 2021, NEUROCOMPUTING, V440, P251, DOI 10.1016/j.neucom.2021.01.126
   He T., 2020, Adv. Neural Inf. Process. Syst, V33, P9276
   HOU T, 2020, ARXIV
   Huang PH, 2018, PROC CVPR IEEE, P2821, DOI 10.1109/CVPR.2018.00298
   Jadhav T, 2019, MULTIMED TOOLS APPL, V78, P1613, DOI 10.1007/s11042-018-6271-3
   Khan F, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082272
   Kharazi BA, 2021, COMPUT ENVIRON URBAN, V88, DOI 10.1016/j.compenvurbsys.2021.101628
   Khojastehnazhand M, 2019, SCI HORTIC-AMSTERDAM, V251, P247, DOI 10.1016/j.scienta.2019.03.033
   Kirk Raymond, 2021, Computer Vision Systems: 13th International Conference, ICVS 2021, Proceedings. Lecture Notes in Computer Science, Theoretical Computer Science and General Issues (12899), P223, DOI 10.1007/978-3-030-87156-7_18
   Lam Huynh, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12371), P581, DOI 10.1007/978-3-030-58574-7_35
   Lee JH, 2019, AUTOPHAGY, V15, P726, DOI 10.1080/15548627.2019.1569917
   Liang B, 2017, IEEE T IMAGE PROCESS, V26, P5560, DOI 10.1109/TIP.2017.2740122
   Liao J, 2021, COMPUT GRAPH-UK, V97, P268, DOI 10.1016/j.cag.2021.04.016
   Liu JZ, 2019, COMPUT ELECTRON AGR, V166, DOI 10.1016/j.compag.2019.105012
   Luo KY, 2019, IEEE I CONF COMP VIS, P10451, DOI 10.1109/ICCV.2019.01055
   Maugey T, 2016, IEEE T IMAGE PROCESS, V25, P1808, DOI 10.1109/TIP.2016.2530303
   Mon T, 2020, BIOSYST ENG, V198, P338, DOI 10.1016/j.biosystemseng.2020.08.021
   Okinda C, 2020, J FOOD ENG, V283, DOI 10.1016/j.jfoodeng.2020.110041
   Pandey Surya, 2020, Intelligent Communication, Control and Devices. Proceedings of ICICCD 2018. Advances in Intelligent Systems and Computing (AISC 989), P255, DOI 10.1007/978-981-13-8618-3_27
   Penghui Sun, 2020, 2020 IEEE 22nd International Conference on High Performance Computing and Communications; IEEE 18th International Conference on Smart City; IEEE 6th International Conference on Data Science and Systems (HPCC/SmartCity/DSS), P808, DOI 10.1109/HPCC-SmartCity-DSS50907.2020.00106
   Rematas K, 2017, IEEE T PATTERN ANAL, V39, P1576, DOI 10.1109/TPAMI.2016.2601093
   Rosa ND, 2019, 2019 19TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR), P793, DOI [10.1109/icar46387.2019.8981652, 10.1109/ICAR46387.2019.8981652]
   Su Z., 2020, VIRTUAL REAL INTELL, V2, P43, DOI [10.1016/j.vrih.2019.12.001, DOI 10.1016/J.VRIH.2019.12.001]
   Tiwari, 2019, PROCESSING FRUITS VE, P203
   Tosi F, 2019, PROC CVPR IEEE, P9791, DOI 10.1109/CVPR.2019.01003
   Wu XX, 2013, IEEE I CONF COMP VIS, P609, DOI 10.1109/ICCV.2013.81
   Xie HZ, 2019, IEEE I CONF COMP VIS, P2690, DOI 10.1109/ICCV.2019.00278
   Xie HZ, 2020, INT J COMPUT VISION, V128, P2919, DOI 10.1007/s11263-020-01347-6
   Xu Q., 2019, Proc. Adv. Neural Inf. Process. Syst., V32, P1
   Yang HC, 2020, IEEE T IMAGE PROCESS, V29, P6590, DOI 10.1109/TIP.2020.2991883
   Yang ZG, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10131556
   Yu AZ, 2021, ISPRS J PHOTOGRAMM, V175, P448, DOI 10.1016/j.isprsjprs.2021.03.010
   Zanfir A, 2018, PROC CVPR IEEE, P2148, DOI 10.1109/CVPR.2018.00229
   Zhao SS, 2019, PROC CVPR IEEE, P9780, DOI 10.1109/CVPR.2019.01002
NR 42
TC 1
Z9 1
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 28235
EP 28258
DI 10.1007/s11042-023-14615-7
EA FEB 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000936195100007
DA 2024-07-18
ER

PT J
AU Sukanya, ST
   Jerine, S
AF Sukanya, S. T.
   Jerine, S.
TI Skin lesion analysis towards melanoma detection using optimized deep
   learning network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Melonoma detection; Improved K-means model; SA-SLnO; NVLVP; GLCM
ID CLASSIFICATION; SEGMENTATION; DIAGNOSIS; FEATURES
AB The deadliest form of skin lesion is known as melanoma. Detection of melanoma at earlier stages significantly raises the rate of survival. Nevertheless, the precise detection of melanoma is very challenging for reasons like lower contrast among skin and lesion, visual similarity among non-melanoma and melanoma lesions, etc. This work presents a new melanoma detection approach, which is comprised of 3 foremost stages like: segmentation, feature extraction and detection. Beginning with segmentation, a new algorithm called the Self Adaptive Sea Lion Algorithm (SA-SLnO) is used to improve the K-means clustering model's initial centroids in a way that maximizes performance. Here, the multi-objective considerations of intensity diverse centroid, geographical map, and frequency of occurrence, respectively, are used to carry out the best selection. Further, from the segmented images, the texture features were extracted, and they are subjected to "Deep Belief Network (DBN)" for melanoma detection. Eventually, the supremacy of the presented model is confirmed over existing models in terms of various measures.
C1 [Sukanya, S. T.; Jerine, S.] Noorul Islam Ctr Higher Educ, Thuckalay 629180, Tamil Nadu, India.
RP Sukanya, ST (corresponding author), Noorul Islam Ctr Higher Educ, Thuckalay 629180, Tamil Nadu, India.
EM stsukanya7@gmail.com
RI S, Jerine/HZK-9920-2023
OI S, Jerine/0000-0002-4696-7204
CR Abuzaghleh O, 2015, IEEE J TRANSL ENG HE, V3, DOI 10.1109/JTEHM.2015.2419612
   Aima A., 2019, P INT C SUSTAINABLE
   Alfed N, 2017, EXPERT SYST APPL, V90, P101, DOI 10.1016/j.eswa.2017.08.010
   [Anonymous], 2020, PROPERTIES VARIANCE
   Bliznuks D, 2017, PROCEDIA COMPUT SCI, V104, P468, DOI 10.1016/j.procs.2017.01.161
   Carrera C., 2017, J AM ACAD DERMATOL
   Chen K, 2021, ARXIV
   Codella NCF, 2017, IBM J RES DEV, V61, DOI 10.1147/JRD.2017.2708299
   Dascalu A, 2019, EBIOMEDICINE, V43, P107, DOI 10.1016/j.ebiom.2019.04.055
   Ferris LK, 2015, J AM ACAD DERMATOL, V73, P769, DOI 10.1016/j.jaad.2015.07.028
   Harangi B, 2018, J BIOMED INFORM, V86, P25, DOI 10.1016/j.jbi.2018.08.006
   Hussain AA, 2016, PHOTODIAGN PHOTODYN, V14, P178, DOI 10.1016/j.pdpdt.2016.04.010
   Jadhav Ashwin R., 2019, Computational Intelligence: Theories, Applications and Future Directions - Volume I. ICCI-2017. Advances in Intelligent Systems and Computing (AISC 798), P97, DOI 10.1007/978-981-13-1132-1_8
   Jaimes N, 2015, J AM ACAD DERMATOL, V72, P1027, DOI 10.1016/j.jaad.2015.02.1117
   Kasmi R, 2016, IET IMAGE PROCESS, V10, P448, DOI 10.1049/iet-ipr.2015.0385
   Loescher Lois J, 2013, Semin Oncol Nurs, V29, P170, DOI 10.1016/j.soncn.2013.06.003
   Lokesh Kumar R., 2019, J COMPUT MECH POWER, V2, P1, DOI [10.46253/jcmps.v2i3.a1, DOI 10.46253/JCMPS.V2I3.A1]
   Mahbod A, 2019, COMPUT MED IMAG GRAP, V71, P19, DOI 10.1016/j.compmedimag.2018.10.007
   Marchetti MA, 2018, J AM ACAD DERMATOL, V78, P270, DOI 10.1016/j.jaad.2017.08.016
   Masadeh R, 2019, INT J ADV COMPUT SC, V10, P388
   Mehta P, 2016, PROCEDIA COMPUT SCI, V85, P309, DOI 10.1016/j.procs.2016.05.238
   Meshram A, 2022, AUTOMATICSKIN MELANO, V8350
   Mukherjee Soumen, 2019, Contemporary Advances in Innovative and Applicable Information Technology. Proceedings of ICCAIAIT 2018. Advances in Intelligent Systems and Computing (AISC 812), P101, DOI 10.1007/978-981-13-1540-4_11
   Niukkanen A, 2018, J DIGIT IMAGING, V31, P425, DOI 10.1007/s10278-017-0031-1
   Oliveira RB, 2017, COMPUT METH PROG BIO, V149, P43, DOI 10.1016/j.cmpb.2017.07.009
   Pennisi A, 2016, COMPUT MED IMAG GRAP, V52, P89, DOI 10.1016/j.compmedimag.2016.05.002
   Punal M., 2016, PERSPECT SCI, V8, P203, DOI [10.1016/j.pisc.2016.03.018, DOI 10.1016/J.PISC.2016.03.018]
   Rajakumar BR, 2013, AASRI PROC, V4, P288, DOI 10.1016/j.aasri.2013.10.043
   Rajakumar BR, 2013, INT J COMPUT SCI ENG, V8, P180, DOI 10.1504/IJCSE.2013.053087
   Rajakumar BR, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMPUTING RESEARCH (ICCIC), P606
   Rajakumar B.R., 2013, International Journal of Hybrid Intelligent Systems, V10, P11, DOI [10.3233/HIS-120161, DOI 10.3233/HIS-120161]
   Srinivasan K, 2018, BASIC CLIN PHARMACOL, V124, P3
   Sukanya, COMUNICATION
   Sukanya, 2019, DEEP LEARNING BASED
   Swamy S. M., 2013, IET CHENN 4 INT C SU, DOI [DOI 10.1049/IC.2013.0361, 10.1049/ic.2013.0361]
   Tan TY, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105725
   Tan TY, 2018, KNOWL-BASED SYST, V158, P118, DOI 10.1016/j.knosys.2018.05.042
   Do TT, 2018, IEEE T MULTIMEDIA, V20, P2849, DOI 10.1109/TMM.2018.2814346
   Thomas M. J. S., 2018, MULTIMEDIA RES, P33, DOI DOI 10.46253/J.MR.V1I1.A5
   Wagh MB., 2019, J NETW COMMUN SYST, V2, P34, DOI DOI 10.46253/JNACS.V2I1.A4
   Wang HZ, 2016, APPL ENERG, V182, P80, DOI 10.1016/j.apenergy.2016.08.108
   Xie FY, 2020, COMPUT METH PROG BIO, V186, DOI 10.1016/j.cmpb.2019.105241
   Yang S, 2017, BIOMED SIGNAL PROCES, V32, P90, DOI 10.1016/j.bspc.2016.09.019
   Yuan YD, 2017, IEEE T MED IMAGING, V36, P1876, DOI 10.1109/TMI.2017.2695227
   Zanddizari H, 2021, MED BIOL ENG COMPUT, V59, P1123, DOI 10.1007/s11517-021-02355-5
   Zhang N, 2020, ARTIF INTELL MED, V102, DOI 10.1016/j.artmed.2019.101756
NR 46
TC 2
Z9 2
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27795
EP 27817
DI 10.1007/s11042-023-14454-6
EA FEB 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000936195100011
DA 2024-07-18
ER

PT J
AU Ghorbanali, A
   Sohrabi, MK
AF Ghorbanali, Alireza
   Sohrabi, Mohammad Karim
TI Exploiting bi-directional deep neural networks for multi-domain
   sentiment analysis using capsule network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-domain sentiment analysis; Sentiment analysis; Bidirectional LSTM;
   Capsule network; BERT; GRU
ID DOMAIN ADAPTATION; WORD EMBEDDINGS; CLASSIFICATION; STRATEGY; MACHINE
AB Sentiment analysis (SA) is the computational analysis of the ideas, feelings, and opinions that determines the polarity of the text documents or comments using natural language processing (NLP) and text analyses techniques. The purpose of the multi-domain SA is to train a classifier using an appropriate set of tagged data to reduce the need for large amounts of data on specific domains and to address their data scarcity challenges using existing data in other domains. A combined use of the pre-trained BERT model, convolutional neural network (CNN), bi-directional long short-term memory (LSTM) and gated recurrent unit (GRU) is exploited in the proposed method of this paper for analysing the multi-domain sentiments using capsule network (CapsuleNet). In the proposed model of this paper, the pre-trained BERT (with CNN) and LSTM extracts the proper features for the CapsuleNet. The proposed approach is evaluated using the Dranziera protocol and the experimental results show that the accuracy of the proposed method is improved in comparison with the other basic deep learning-based methods, such as Multi CNN and LSTM. The results of the experiments show the superiority of the proposed method compared to the other similar methods on in-domain and out-of-domain data.
C1 [Ghorbanali, Alireza; Sohrabi, Mohammad Karim] Islamic Azad Univ, Dept Comp Engn, Semnan Branch, Semnan, Iran.
C3 Islamic Azad University
RP Sohrabi, MK (corresponding author), Islamic Azad Univ, Dept Comp Engn, Semnan Branch, Semnan, Iran.
EM A.ghorbanali@stu.semnaniau.ac.ir; Amir_sohraby@aut.ac.ir
RI Ghorbanali, Alireza/JKI-1302-2023
OI GHorbanali, Alireza/0000-0003-3618-9469
CR [Anonymous], 2012, DATA CENTRIC SYST AP, DOI DOI 10.1007/978-3-031-02145-9
   Atzeni M, 2020, FUTURE GENER COMP SY, V110, P984, DOI 10.1016/j.future.2019.10.012
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Basari AH, 2013, PROCEDIA ENGINEER, V53, P453, DOI 10.1016/j.proeng.2013.02.059
   Beigi OM, 2021, KNOWL-BASED SYST, V213, DOI 10.1016/j.knosys.2020.106423
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   CHURCH KW, 1990, 27TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P76
   Demotte P, 2023, MULTIMED TOOLS APPL, V82, P8665, DOI 10.1007/s11042-021-11471-1
   Devlin J., 2018, BERT PRE TRAINING DE
   Dragoni M, 2018, INT J APPROX REASON, V93, P59, DOI 10.1016/j.ijar.2017.10.021
   Dragoni M, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P267
   Dragoni M, 2017, IEEE T AFFECT COMPUT, V8, P457, DOI 10.1109/TAFFC.2017.2717879
   Fernandez-Gavilanes M, 2015, P 9 INT WORKSH SEM E, P533, DOI DOI 10.18653/V1/S15-2089
   Gers FA, 1999, IEE CONF PUBL, P850, DOI [10.1049/cp:19991218, 10.1162/089976600300015015]
   Ghorbanali A, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.102929
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Hemmatian F, 2019, ARTIF INTELL REV, V52, P1495, DOI 10.1007/s10462-017-9599-6
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jha V, 2018, COMPUT ELECTR ENG, V69, P585, DOI 10.1016/j.compeleceng.2017.10.015
   Kim Y, 2014, ARXIV, DOI DOI 10.3115/V1.D14-1181
   Krishnakumari K, 2020, SOFT COMPUT, V24, P3511, DOI 10.1007/s00500-019-04117-w
   LeCun Y, 1999, LECT NOTES COMPUT SC, V1681, P319, DOI 10.1007/3-540-46805-6_19
   Li J., 2015, ARXIV
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Lokegaonkar, 2018, EMPIRICAL STUDY CONV
   Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011
   Nassif AB, 2021, APPL SOFT COMPUT, V98, DOI 10.1016/j.asoc.2020.106836
   Otter DW, 2021, IEEE T NEUR NET LEAR, V32, P604, DOI 10.1109/TNNLS.2020.2979670
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Peng HY, 2021, INFORM FUSION, V70, P88, DOI 10.1016/j.inffus.2021.01.005
   Pröllochs N, 2020, INFORM SCIENCES, V536, P205, DOI 10.1016/j.ins.2020.05.022
   Pucci R, 2020, MULTIMED TOOLS APPL, V79, P32243, DOI 10.1007/s11042-020-09455-8
   Rojas-Barahona LM, 2016, LANG LINGUIST COMPAS, V10, P701, DOI 10.1111/lnc3.12228
   Routray P., 2013, INT J COMPUT APPL, V76, P1, DOI DOI 10.5120/13280-0527
   Sabour S, 2017, ADV NEUR IN, V30
   Sohrabi MK, 2019, MULTIMED TOOLS APPL, V78, P24863, DOI 10.1007/s11042-019-7586-4
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   Tembhurne JV, 2021, MULTIMED TOOLS APPL, V80, P6871, DOI 10.1007/s11042-020-10037-x
   Torabian, 2016, SENTIMENT CLASSIFICA
   Tripathy A, 2023, MULTIMED TOOLS APPL, V82, P7991, DOI 10.1007/s11042-022-13047-z
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P417
   Wu FZ, 2017, IEEE T KNOWL DATA EN, V29, P1370, DOI 10.1109/TKDE.2017.2669975
   Yadav A, 2020, ARTIF INTELL REV, V53, P4335, DOI 10.1007/s10462-019-09794-5
   Yang M, 2019, NEURAL NETWORKS, V117, P240, DOI 10.1016/j.neunet.2019.05.021
   Yang SY, 2018, EXPERT SYST APPL, V114, P388, DOI 10.1016/j.eswa.2018.07.056
   Ye Q, 2009, EXPERT SYST APPL, V36, P6527, DOI 10.1016/j.eswa.2008.07.035
   Yuan ZG, 2018, KNOWL-BASED SYST, V155, P1, DOI 10.1016/j.knosys.2018.05.004
   Yue CY, 2021, APPL INTELL, V51, P3174, DOI 10.1007/s10489-020-02021-7
   Zagibalov Taras., 2008, Proceedings of the 22nd International Conference on Computational Linguistics (COLING-2008), V1, P1073, DOI DOI 10.3115/1599081.1599216
   Zhao CJ, 2020, KNOWL-BASED SYST, V191, DOI 10.1016/j.knosys.2019.105254
NR 50
TC 5
Z9 5
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22943
EP 22960
DI 10.1007/s11042-023-14449-3
EA FEB 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000936501100010
DA 2024-07-18
ER

PT J
AU Verma, G
   He, WQ
   Peng, X
AF Verma, Gaurav
   He, Wenqi
   Peng, Xiang
TI A novel four image encryption approach in sparse domain based on
   biometric keys
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optical encryption and decryption; Fourier transform; And phase
   retrieval algorithm
ID FRACTIONAL FOURIER-TRANSFORM; OPTICAL ENCRYPTION; FRESNEL-TRANSFORM;
   SECURING INFORMATION; PLAINTEXT ATTACK; PHASE; AUTHENTICATION; SCHEME;
   INTERFEROMETRY; REPRESENTATION
AB In this paper, a novel four-image encryption method using biometric keys based on a compressive phase retrieval algorithm is proposed. In the encryption procedure, each input image to be encrypted is initially encoded in sparse data by using a phase retrieval algorithm, which is further combined with a distinct biometric phase mask key. This approach increases the non-linearity of the encryption process and also offers an additional layer of system security against unauthorized attacks. In the system, multiple phase keys from a single biometric hologram by changing the reconstruction parameters during the numerical reconstruction process are generated. The digital nature of the key generation process makes it available at encryption and decryption stages. In addition, the advantage associated with the proposed scheme is related to achieve in reducing space for data storage and transmission over a communication channel. The algorithms to implement the proposed scheme are discussed, and the results of the numerical simulations have presented the effectiveness of the proposed four-image encryption scheme that exhibits better performance in comparison to the reported methods.
C1 [Verma, Gaurav] Gautam Buddha Univ, Sch Informat & Commun Technol, Greater Noida 201312, India.
   [Verma, Gaurav] B K Birla Inst Engn & Technol, Dept Elect & Commun Engn, Pilani 333031, Rajasthan, India.
   [He, Wenqi; Peng, Xiang] Shenzhen Univ, Coll Phys & Optoelect Engn, Key Lab Optoelect Devices & Syst, Minist Educ & Guangdong Prov, Shenzhen, Peoples R China.
C3 Gautam Buddha University; Shenzhen University
RP Verma, G (corresponding author), Gautam Buddha Univ, Sch Informat & Commun Technol, Greater Noida 201312, India.; Verma, G (corresponding author), B K Birla Inst Engn & Technol, Dept Elect & Commun Engn, Pilani 333031, Rajasthan, India.
EM gaurav.sgs85@gmail.com; he.wenqi@qq.com; xpeng@szu.edu.cn
RI Verma, Gaurav/ABB-2567-2021; HE, Wenqi/F-4016-2011
OI HE, Wenqi/0000-0002-8606-4608; VERMA, GAURAV/0000-0002-5141-4938
CR Alfalou A, 2009, ADV OPT PHOTONICS, V1, P589, DOI 10.1364/AOP.1.000589
   Alfalou A, 2009, APPL OPTICS, V48, P5933, DOI 10.1364/AO.48.005933
   Chen JX, 2015, OPT LASER TECHNOL, V70, P50, DOI 10.1016/j.optlastec.2015.01.016
   Chen JX, 2017, OPTIK, V136, P1, DOI 10.1016/j.ijleo.2017.02.001
   Chen W, 2014, J OPTICS-UK, V16, DOI 10.1088/2040-8978/16/2/025402
   Chen W, 2013, IEEE PHOTONICS J, V5, DOI 10.1109/JPHOT.2013.2258144
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Di H, 2016, OPT ENG, V55, DOI 10.1117/1.OE.55.7.073103
   Diab SL, 2011, OPT LASER TECHNOL, V43, P838, DOI 10.1016/j.optlastec.2010.11.001
   Ferdous J., 2021, Affordable and Clean Energy, Encyclopedia of the UN Sustainable Development Goals, P1, DOI DOI 10.1007/978-3-319-95864-4
   Gao Y, 2020, OPT COMMUN, V463, DOI 10.1016/j.optcom.2020.125476
   Garg D, 2018, MULTIMED TOOLS APPL, V77, P26545, DOI 10.1007/s11042-018-5878-8
   Gong Q, 2013, APPL OPTICS, V52, P7486, DOI 10.1364/AO.52.007486
   Gupta S, 2021, VISUAL COMPUT, V37, P447, DOI 10.1007/s00371-020-01814-8
   Gupta S, 2019, MULTIMED TOOLS APPL, V78, P34157, DOI 10.1007/s11042-019-08232-6
   Hazer A, 2021, J OPTICS-UK, V23, DOI 10.1088/2040-8986/ac2463
   Hwang HE, 2009, OPT LETT, V34, P3917, DOI 10.1364/OL.34.003917
   Javidi B, 2000, OPT LETT, V25, P28, DOI 10.1364/OL.25.000028
   Kumar M, 2021, J VIS COMMUN IMAGE R, V75, DOI 10.1016/j.jvcir.2021.103052
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Liu H, 2020, STRUCT INFRASTRUCT E, V16, P1447, DOI 10.1080/15732479.2020.1712610
   Liu ZJ, 2007, OPT COMMUN, V275, P324, DOI 10.1016/j.optcom.2007.03.039
   Nishchal NK, 2004, OPT COMMUN, V235, P253, DOI 10.1016/j.optcom.2004.02.052
   Nomura T, 2000, OPT ENG, V39, P2031, DOI 10.1117/1.1304844
   Peng X, 2006, OPT LETT, V31, P1044, DOI 10.1364/OL.31.001044
   Peng X, 2006, OPT LETT, V31, P3261, DOI 10.1364/OL.31.003261
   Pérez-Cabré E, 2012, J OPTICS-UK, V14, DOI 10.1088/2040-8978/14/9/094001
   Pérez-Cabré E, 2011, OPT LETT, V36, P22, DOI 10.1364/OL.36.000022
   Qin W, 2010, OPT LETT, V35, P118, DOI 10.1364/OL.35.000118
   Rajput SK, 2015, APPL OPTICS, V54, P1657, DOI 10.1364/AO.54.001657
   Rawat N, 2015, APPL OPTICS, V54, P1782, DOI 10.1364/AO.54.001782
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Saini N, 2013, OPT LASER ENG, V51, P1014, DOI 10.1016/j.optlaseng.2013.03.006
   SCHNARS U, 1994, J OPT SOC AM A, V11, P2011, DOI 10.1364/JOSAA.11.002011
   Singh N, 2008, OPT LASER ENG, V46, P117, DOI 10.1016/j.optlaseng.2007.09.001
   Situ G, 2004, OPT COMMUN, V232, P115, DOI 10.1016/j.optcom.2004.01.002
   Situ GH, 2004, OPT LETT, V29, P1584, DOI 10.1364/OL.29.001584
   Situ GH, 2005, OPT LETT, V30, P1306, DOI 10.1364/OL.30.001306
   Suzuki H, 2006, OPT EXPRESS, V14, P1755, DOI 10.1364/OE.14.001755
   Suzuki H., 2004, JPN J OPT, V33, P37
   Unnikrishnan G, 2000, OPT LETT, V25, P887, DOI 10.1364/OL.25.000887
   Verma G, 2021, IEEE PHOTONICS J, V13, DOI 10.1109/JPHOT.2020.3047806
   Verma G, 2019, OPT LASER ENG, V123, P28, DOI 10.1016/j.optlaseng.2019.06.028
   Verma G, 2019, OPT LASER ENG, V116, P32, DOI 10.1016/j.optlaseng.2018.12.010
   Verma G, 2016, J OPTICS-UK, V18, DOI 10.1088/2040-8978/18/11/115701
   Wang Q, 2013, APPL OPTICS, V52, P6849, DOI 10.1364/AO.52.006849
   Wang XG, 2015, IEEE PHOTONICS J, V7, DOI 10.1109/JPHOT.2015.2412936
   Wu JH, 2013, OPT LASER TECHNOL, V45, P571, DOI 10.1016/j.optlastec.2012.05.030
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhang JH, 2021, OPT COMMUN, V485, DOI 10.1016/j.optcom.2021.126762
   Zhang XQ, 2022, MULTIMED TOOLS APPL, V81, P20021, DOI 10.1007/s11042-022-12554-3
   Zhang X, 2018, IEEE ACCESS, V6, P18074, DOI 10.1109/ACCESS.2018.2820724
   Zhang X, 2018, OPT LASER ENG, V100, P118, DOI 10.1016/j.optlaseng.2017.08.002
   Zhang Y, 2008, OPT LETT, V33, P2443, DOI 10.1364/OL.33.002443
   Zhao TY, 2015, OPT LASER ENG, V72, P12, DOI 10.1016/j.optlaseng.2015.03.024
NR 55
TC 1
Z9 1
U1 7
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22889
EP 22904
DI 10.1007/s11042-023-14801-7
EA FEB 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000934222700010
DA 2024-07-18
ER

PT J
AU Yadav, AK
   Ranvijay
   Yadav, RS
   Maurya, AK
AF Yadav, Avaneesh Kumar
   Ranvijay
   Yadav, Rama Shankar
   Maurya, Ashish Kumar
TI State-of-the-art approach to extractive text summarization: a
   comprehensive review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Text summarization; Extractive text summarization; Research issues;
   Graph-based approaches; Machine learning techniques; Clustering-based
   approaches
ID SINGLE-DOCUMENT; EVOLUTIONARY; FRAMEWORK; SYSTEM
AB With the rapid growth of social media platforms, digitization of official records, and digital publication of articles, books, magazines, and newspapers, lots of data are generated every day. This data is a foundation of information and contains a vast amount of text that may be complex, ambiguous, redundant, irrelevant, and unstructured. Therefore, we require tools and methods that can help us understand and automatically summarize the vast amount of generated text. There are mainly two types of approaches to perform text summarization: abstractive and extractive. In Abstractive Text Summarization, a concise summary is generated by including the salient features of the input documents and paraphrasing documents using new sentences and phrases. While in Extractive Text Summarization, a summary is produced by selecting and combining the most significant sentences and phrases from the source documents. The researchers have given numerous techniques for both kinds of text summarization. In this work, we classify Extractive Text Summarization approaches and review them based on their characteristics, techniques, and performance. We have discussed the existing Extractive Text Summarization approaches along with their limitations. We also classify and discuss evaluation measures and provide the research challenges faced in Extractive Text Summarization.
C1 [Yadav, Avaneesh Kumar; Ranvijay; Yadav, Rama Shankar; Maurya, Ashish Kumar] Motilal Nehru Natl Inst Technol Allahabad, Dept Comp Sci & Engn, Prayagraj, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Yadav, AK (corresponding author), Motilal Nehru Natl Inst Technol Allahabad, Dept Comp Sci & Engn, Prayagraj, India.
EM avaneesh17@mnnit.ac.in; ranvijay@mnnit.ac.in; rsy@mnnit.ac.in;
   ashishmaurya@mnnit.ac.in
RI Maurya, Ashish/N-5994-2019
OI Maurya, Ashish/0000-0001-9679-9045
CR Abdi A, 2021, KNOWL-BASED SYST, V213, DOI 10.1016/j.knosys.2020.106658
   Abdi A, 2017, SOFT COMPUT, V21, P1785, DOI 10.1007/s00500-015-1881-4
   Abhiman BD, 2021, TEXT SUMMARIZATION U
   Al-Sabahi K, 2018, IEEE ACCESS, V6, P24205, DOI 10.1109/ACCESS.2018.2829199
   Al-Taani AT, 2014, INT ARAB C INFORM TE
   Alami N, 2021, EXPERT SYST APPL, V172, DOI 10.1016/j.eswa.2021.114652
   Alami N, 2021, MULTIMED TOOLS APPL, V80, P19567, DOI 10.1007/s11042-021-10613-9
   Alami N, 2019, EXPERT SYST APPL, V123, P195, DOI 10.1016/j.eswa.2019.01.037
   Ali ZH., 2021, TELKOMNIKA, V19, P89, DOI [10.12928/TELKOMNIKA.v19i1.15766, DOI 10.12928/TELKOMNIKA.V19I1.15766]
   Amarappa S., 2013, INT J ELECTR COMPUT, V2, P281
   [Anonymous], 2014, P WORKSH CONT VECT S, DOI DOI 10.3115/V1/W14-1504
   Arumae K, 2019, ARXIV, DOI DOI 10.48550/ARXIV.1904.02321
   Asa AS., 2017, AM J ENG RES, V6, P226
   Awan MN, 2021, COMPUT SPEECH LANG, V65, DOI 10.1016/j.csl.2020.101116
   Azadani MN, 2018, J BIOMED INFORM, V84, P42, DOI 10.1016/j.jbi.2018.06.005
   Baralis E, 2013, INFORM SCIENCES, V249, P96, DOI 10.1016/j.ins.2013.06.046
   Barrera A, 2011, P 2011 ACM S APPL CO, P268, DOI [10.1145/1982185.1982247, DOI 10.1145/1982185.1982247]
   Baruah N, 2019, 2019 4 INT C INF SYS, P305, DOI [10.1109/ISCON47742.2019.9036285, DOI 10.1109/ISCON47742.2019.9036285]
   Belkebir R., 2018, INTELLIGENT NATURAL, P435, DOI [10.1007/978-3-319-67056-0_21, DOI 10.1007/978-3-319-67056-0_21]
   Bommasani R, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8075
   Cai HY, 2018, IEEE T KNOWL DATA EN, V30, P1616, DOI 10.1109/TKDE.2018.2807452
   Cao MY, 2020, FUTURE GENER COMP SY, V109, P331, DOI 10.1016/j.future.2020.03.046
   Castillo Jonalyn M., 2013, International Journal of Future Computer and Communication, V2, P530, DOI 10.7763/IJFCC.2013.V2.220
   Chao Shen, 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P626, DOI 10.1109/ICDM.2011.91
   Chen KY, 2015, IEEE-ACM T AUDIO SPE, V23, P1322, DOI 10.1109/TASLP.2015.2432578
   Chouigui A, 2021, ARAB J SCI ENG, V46, P3925, DOI 10.1007/s13369-020-05258-z
   Chowdhury Sohini Roy, 2017, 2017 8th International Conference on Information Technology (ICIT), P11, DOI 10.1109/ICIT.2017.12
   Cizmeciler K, 2022, MULTIMED TOOLS APPL, V81, P17457, DOI 10.1007/s11042-022-12442-w
   Daiya D, 2018, ARXIV, DOI DOI 10.48550/ARXIV.1805.04579
   Dang H. T., 2005, P DOCUMENT UNDERSTAN, V2005, P1
   Dang HT, 2006, P WORKSH TASK FOC SU, P48, DOI DOI 10.3115/1654679.1654689
   Dernoncourt F, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P3221
   Dixit RS., 2012, IOSR J COMPUTER ENG, V5, P5, DOI [10.9790/0661-0560510, DOI 10.9790/0661-0560510]
   DunlaVy DM, 2007, INFORM PROCESS MANAG, V43, P1588, DOI 10.1016/j.ipm.2007.01.003
   Dutta Madhurima, 2019, Emerging Technologies in Data Mining and Information Security. Proceedings of IEMIS 2018. Advances in Intelligent Systems and Computing (AISC 813), P179, DOI 10.1007/978-981-13-1498-8_16
   Dwivedi V., 2022, SN COMPUT SCI, V3, P1, DOI [10.1007/s42979-021-00895-z, DOI 10.1007/S42979-021-00895-Z]
   El-Hadidy M, 2008, HANN BEITR NACHRICHT, V2, P1, DOI 10.1109/ICUWB.2008.4653337
   El-Kassas WS, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113679
   Elayeb B, 2020, COGN COMPUT, V12, P1043, DOI 10.1007/s12559-020-09748-y
   Elbarougy R, 2020, EGYPT INFORM J, V21, P73, DOI 10.1016/j.eij.2019.11.001
   Elrefaiy A., 2018, J THEOR APPL INF TEC, V96, P7739
   Erkan G, 2004, J ARTIF INTELL RES, V22, P457, DOI 10.1613/jair.1523
   Fang CJ, 2017, EXPERT SYST APPL, V72, P189, DOI 10.1016/j.eswa.2016.12.021
   Fei L, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/6145196
   Ferreira R, 2014, EXPERT SYST APPL, V41, P5780, DOI 10.1016/j.eswa.2014.03.023
   Ferreira R, 2013, EXPERT SYST APPL, V40, P5755, DOI 10.1016/j.eswa.2013.04.023
   Fitrianah D, 2022, BULLET ELECT ENG INF, V11, DOI [10.11591/eei.v11i1.3278, DOI 10.11591/EEI.V11I1.3278]
   Gamal M, 2021, INT J INTELL ENG SYS, V14, DOI [10.22266/ijies2021.0630.27, DOI 10.22266/IJIES2021.0630.27]
   Gambhir M, 2022, MULTIMED TOOLS APPL, V81, P20829, DOI 10.1007/s11042-022-12729-y
   Gambhir M, 2017, ARTIF INTELL REV, V47, P1, DOI 10.1007/s10462-016-9475-9
   Gholamrezazadeh S., 2009, Proceedings of CSA, V9, P1
   Goldman J, 2005, INT J DIGIT LIBRARIE, V5, P287, DOI 10.1007/s00799-004-0101-0
   Gong Y., 2001, P 24 ANN INT ACM SIG, P19, DOI DOI 10.1145/383952.383955
   Goularte FB, 2019, EXPERT SYST APPL, V115, P264, DOI 10.1016/j.eswa.2018.07.047
   Gupta P., 2011, Proceedings of the 2011 13th International Conference on Advanced Communication Technology (ICACT). Smart Service Innovation through Mobile Interactivity, P1620
   Gupta Vishal, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P258, DOI 10.4304/jetwi.2.3.258-268
   Thu HNT, 2013, 2013 COMPUTING, COMMUNICATIONS AND IT APPLICATIONS CONFERENCE (COMCOMAP), P69, DOI 10.1109/ComComAp.2013.6533611
   Hai Leong Chieu, 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P425
   Hassel M., 2004, THESIS, P1
   Hernández-Castañeda A, 2022, COMPUT SPEECH LANG, V71, DOI 10.1016/j.csl.2021.101267
   Herskovic JR, 2011, INT J MED INFORM, V80, P431, DOI 10.1016/j.ijmedinf.2011.02.008
   Hin D, 2022, ARXIV, DOI DOI 10.48550/ARXIV.2203.05181
   Irfan M, 2017, 2017 2 INT C INF COM, P1, DOI 10.1109/IAC.2017.8280646
   Isonuma M., 2017, P 2017 C EMP METH NA, P2101, DOI DOI 10.18653/V1/D17-1223
   Jain A., 2021, INT J OPERATIONS RES, V12, P1, DOI [10.4018/IJORIS.20210701.oa1, DOI 10.4018/IJORIS.20210701.OA1]
   Jain D, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, AND INTELLIGENT SYSTEMS (ICCCIS), P394, DOI 10.1109/ICCCIS51004.2021.9397119
   Jain H.J., 2012, International Journal of Soft Computing and Engineering, P301
   Jang M, 2021, IEEE ACCESS, V9, P14358, DOI 10.1109/ACCESS.2021.3051237
   Jones KS, 2007, INFORM PROCESS MANAG, V43, P1449, DOI 10.1016/j.ipm.2007.03.009
   Joshi A, 2022, EXPERT SYST APPL, V200, DOI 10.1016/j.eswa.2022.116846
   Joshi A, 2019, EXPERT SYST APPL, V129, P200, DOI 10.1016/j.eswa.2019.03.045
   Kaikhah K, 2004, 2004 2ND INTERNATIONAL IEEE CONFERENCE INTELLIGENT SYSTEMS, VOLS 1 AND 2, PROCEEDINGS, P40, DOI 10.1109/IS.2004.1344634
   Keyvanpour MR, 2019, 2019 5TH INTERNATIONAL CONFERENCE ON WEB RESEARCH (ICWR), P234, DOI [10.1109/ICWR.2019.8765294, 10.1109/icwr.2019.8765294]
   Khurana A, 2022, EXPERT SYST APPL, V187, DOI 10.1016/j.eswa.2021.115820
   Kiyomarsi F, 2011, 2011 INT C INTELLIGE
   Koto F, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2104.05882
   Kumar Akshi, 2020, ICIIT 2020: Proceedings of the 2020 5th International Conference on Intelligent Information Technology, P7, DOI 10.1145/3385209.3385235
   Kumar YJ, 2014, APPL SOFT COMPUT, V21, P265, DOI 10.1016/j.asoc.2014.03.041
   Kumar Y, 2021, ARTIF INTELL REV, V54, P5897, DOI 10.1007/s10462-021-09964-4
   LeClair A, 2020, INT C PROGRAM COMPRE, P184, DOI 10.1145/3387904.3389268
   Li X, 2013, IEEE T KNOWL DATA EN, V25, P1162, DOI 10.1109/TKDE.2012.42
   Lins R., 2019, Proceedings of the ACM Symposium on Document Engineering, P1
   Lins RD, 2019, DOCENG'19: PROCEEDINGS OF THE ACM SYMPOSIUM ON DOCUMENT ENGINEERING 2019, DOI 10.1145/3342558.3345388
   Lins RD, 2020, P ACM S DOCUMENT ENG, P1, DOI [10.1145/3395027.3419579, DOI 10.1145/3395027.3419578]
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Liu F., 2008, short papers, P201
   Liu SH, 2015, IEEE-ACM T AUDIO SPE, V23, P957, DOI 10.1109/TASLP.2015.2414820
   Liu Y., 2012, P AAAI C ART INT, P1699
   LUHN HP, 1958, IBM J RES DEV, V2, P159, DOI 10.1147/rd.22.0159
   Luo L, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3033
   Lwin SS, 2019, 2019 INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION TECHNOLOGIES (ICAIT), P200, DOI [10.1109/aitc.2019.8921386, 10.1109/AITC.2019.8921386]
   Lwin SS, 2018, 2018 INTERNATIONAL JOINT SYMPOSIUM ON ARTIFICIAL INTELLIGENCE AND NATURAL LANGUAGE PROCESSING (ISAI-NLP 2018), P138
   Mandal S., 2018, J INFORM MATH SCI, V10, P703, DOI [10.26713/jims.v10i4.891, DOI 10.26713/JIMS.V10I4.891]
   Mathkour Hassan I., 2008, Journal of Computer Sciences, V4, P713, DOI 10.3844/jcssp.2008.713.720
   Maurya Ashish Kumar, 2020, 2020 Sixth International Conference on Parallel, Distributed and Grid Computing (PDGC), P566, DOI 10.1109/PDGC50313.2020.9315806
   Maurya R, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P444, DOI 10.1109/IndiaCom.2014.6828177
   Maurya SK, 2023, APPL INTELL, V53, P2189, DOI 10.1007/s10489-022-03427-1
   Meena YK, 2015, PROCEDIA COMPUT SCI, V48, P244, DOI 10.1016/j.procs.2015.04.177
   Mehta P, 2018, INFORM PROCESS MANAG, V54, P145, DOI 10.1016/j.ipm.2017.11.002
   Mei JP, 2012, KNOWL INF SYST, V31, P527, DOI 10.1007/s10115-011-0437-x
   Mendoza M, 2014, EXPERT SYST APPL, V41, P4158, DOI 10.1016/j.eswa.2013.12.042
   Merchant K, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1803, DOI 10.1109/ICACCI.2018.8554831
   Mihalcea R., 2004, P 2004 C EMPIRICAL M, P404, DOI DOI 10.3115/1219044.1219064
   MirShojaee H., 2017, INT J IND ENG PROD R, V28, P75
   Mirshojaei SH., 2015, J COMPUT ROBOT, V8, P19
   Mohamed M, 2019, INFORM PROCESS MANAG, V56, P1356, DOI 10.1016/j.ipm.2019.04.003
   Moiyadi HS., 2016, INT J ADV ENG MANAGE, V2
   Moratanch N, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATION AND SIGNAL PROCESSING (ICCCSP), P265
   Muthu B, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3392048
   Mutlu B, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102359
   Mutlu B, 2019, KNOWL-BASED SYST, V183, DOI 10.1016/j.knosys.2019.07.019
   Nagalla S., 2021, EUR J MOL CLIN MED, V7, P1991
   NagaPrasad S, 2015, PROCEDIA COMPUT SCI, V48, P58, DOI 10.1016/j.procs.2015.04.110
   Naik SS, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P1364, DOI 10.1109/RTEICT.2017.8256821
   Nallapati R, 2016, ARXIV, DOI DOI 10.48550/ARXIV.1611.04244
   Nallapati R, 2017, AAAI CONF ARTIF INTE, P3075
   Narayan S., 2018, P NAACL 2018, DOI [10.48550/arXiv.1802.08636, DOI 10.48550/ARXIV.1802.08636]
   Nawaz A, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102383
   Neto JL, 2002, LECT NOTES ARTIF INT, V2507, P205
   Ozsoy MG, 2011, J INF SCI, V37, P405, DOI 10.1177/0165551511408848
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parveen D, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1298
   Patel D, 2019, EXPERT SYST APPL, V134, P167, DOI 10.1016/j.eswa.2019.05.045
   Patil SR, 2011, P INT C WORKSH EM TR, P583, DOI [10.1145/1980022.1980150, DOI 10.1145/1980022.1980150]
   Potnurwar A, 2020, BIOSCI BIOTECH RES C, V13, P32, DOI 10.21786/bbrc/13.14/8
   Qaroush A, 2021, J KING SAUD UNIV-COM, V33, P677, DOI 10.1016/j.jksuci.2019.03.010
   Rahman N, 2015, 2015 INTERNATIONAL SYMPOSIUM ON ADVANCED COMPUTING AND COMMUNICATION (ISACC), P98, DOI 10.1109/ISACC.2015.7377323
   Rani R, 2021, MULTIMED TOOLS APPL, V80, P3275, DOI 10.1007/s11042-020-09549-3
   Rautray R, 2017, PHYSICA A, V477, P174, DOI 10.1016/j.physa.2017.02.056
   Raval KR, 2022, MULTIMED TOOLS APPL, V81, P29253, DOI 10.1007/s11042-022-12834-y
   Ravinuthala VVMK, 2017, INT J INTELL ENG SYS, DOI [10.22266/ijies2017.1031.17, DOI 10.22266/IJIES2017.1031.17]
   Rothe S, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1392
   Sahba Ramin., 2018, 2018 World Automation Congress (WAC), P1
   Sahoo D, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P873, DOI 10.1109/CCAA.2016.7813838
   Salton G, 1997, INFORM PROCESS MANAG, V33, P193, DOI 10.1016/S0306-4573(96)00062-3
   Sanchez-Gomez JM, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112904
   Sanchez-Gomez JM, 2018, KNOWL-BASED SYST, V159, P1, DOI 10.1016/j.knosys.2017.11.029
   Shirwandkar N.S., 2018, 2018 Fourth International Conference on Computing Communication Control and Automation (ICCUBEA), P1
   Shoaib M, 2014, P ELSEVIER 2 INT C E, V3, P648
   Shoaib M, 2014, 2014 INT C ADV ENG T, P1, DOI [10.1109/ICAETR.2014.7012962, DOI 10.1109/ICAETR.2014.7012962]
   Shyamal AK, 2007, IRAN J FUZZY SYST, V4, P75
   Siddiqui MK, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2106.00619
   Singh RK, 2021, NEURAL COMPUT APPL, V33, P3251, DOI 10.1007/s00521-020-05188-9
   Singh SP, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P1195, DOI 10.1109/ICEEOT.2016.7754874
   Sirohi NK., 2021, J BIG DATA, V3, P35, DOI [10.32604/jbd.2021.015954, DOI 10.32604/JBD.2021.015954]
   Song SL, 2019, MULTIMED TOOLS APPL, V78, P857, DOI 10.1007/s11042-018-5749-3
   Sreelakshmi P. R., 2021, 2021 7th International Conference on Advanced Computing and Communication Systems (ICACCS), P100, DOI 10.1109/ICACCS51430.2021.9441682
   Srivastava AK, 2021, MULTIMED TOOLS APPL, V80, P11273, DOI 10.1007/s11042-020-10176-1
   Srivastava R, 2022, KNOWL-BASED SYST, V246, DOI 10.1016/j.knosys.2022.108636
   Steinberger J., 2004, Proc. ISIM, V4, P93
   Steinberger J, 2009, COMPUT INFORM, V28, P251
   Suleman RM, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.114130
   Suleman RM, 2020, CS IT C P, V10, DOI [10.5121/csit.2020.100401, DOI 10.5121/CSIT.2020.100401]
   Tarnpradab S, 2017, P 30 INT FLORIDA ART, P288
   Thakkar HK, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102474
   Uçkan T, 2020, EGYPT INFORM J, V21, P145, DOI 10.1016/j.eij.2019.12.002
   Vale Rafaella, 2020, P ACM S DOCUMENT ENG, DOI DOI 10.1145/3395027.3419588
   Van Lierde H, 2019, INFORM PROCESS MANAG, V56, P1317, DOI 10.1016/j.ipm.2019.03.003
   Verma P, 2022, APPL SOFT COMPUT, V120, DOI 10.1016/j.asoc.2022.108670
   Wang D, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2004.12393
   Wang DD, 2011, ACM T KNOWL DISCOV D, V5, DOI 10.1145/1993077.1993078
   Wang S, 2017, IEEE INT CONGR BIG, P305, DOI 10.1109/BigDataCongress.2017.46
   Wang XR, 2020, MULTIMED TOOLS APPL, V79, P33875, DOI 10.1007/s11042-020-08690-3
   Wu K, 2015, 2015 12th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD), P1350, DOI 10.1109/FSKD.2015.7382140
   Wu M, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P1457, DOI 10.1145/3366423.3380219
   Wu ZD, 2017, EXPERT SYST APPL, V84, P12, DOI 10.1016/j.eswa.2017.04.054
   Xu J, 2019, ARXIV, DOI DOI 10.48550/ARXIV.1902.00863
   Yadav AK, 2016, INDIAN J SCI TECHNOL, V9, DOI [10.17485/ijst/2016/v9i44/105143, DOI 10.17485/ijst/2016/v9i44/105143]
   Yadav AK., 2021, Ingenierie des Systemes d'Information, DOI [10.18280/isi.260112, DOI 10.18280/ISI.260112]
   Yadav H, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2005.11184
   Yadav J, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2071, DOI 10.1109/ICACCI.2016.7732356
   Ye S, 2007, INFORM PROCESS MANAG, V43, P1643, DOI 10.1016/j.ipm.2007.03.010
   Yogatama Dani, 2015, P 2015 C EMPIRICAL M, P1961
   Yu WR, 2013, PROC INT CONF DATA, P601, DOI 10.1109/ICDE.2013.6544859
   Zajic DM, 2008, INFORM PROCESS MANAG, V44, P1600, DOI 10.1016/j.ipm.2007.09.007
   Zhang K, 2014, P 23 ACM INT C C INF, P2033, DOI [10.1145/2661829.2661840, DOI 10.1145/2661829.2661840]
   Zopf M, 2018, 2018 FIFTH INTERNATIONAL CONFERENCE ON SOCIAL NETWORKS ANALYSIS, MANAGEMENT AND SECURITY (SNAMS), P272, DOI 10.1109/SNAMS.2018.8554853
NR 177
TC 7
Z9 7
U1 12
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29135
EP 29197
DI 10.1007/s11042-023-14613-9
EA FEB 2023
PG 63
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000939670800009
DA 2024-07-18
ER

PT J
AU Cheng, YD
   Ling, BWK
   Lin, YX
   Huang, ZY
   Chan, YL
AF Cheng, Yingdan
   Ling, Bingo Wing-Kuen
   Lin, Yuxin
   Huang, Ziyin
   Chan, Yui-Lam
TI Image super resolution via combination of two dimensional quaternion
   valued singular spectrum analysis based denoising, empirical mode
   decomposition based denoising and discrete cosine transform based
   denoising methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super resolution image; Two dimensional quaternion valued singular
   spectrum analysis; Empirical mode decomposition; Discrete cosine
   transform; Binary linear programming
AB This paper formulates the image super resolution problem as various denoising problems. In particular, the discrete cosine transform zero padding approach is used to generate an initial high resolution image. Then, three different time frequency analysis based denoising methods are applied iteratively to improve the quality of the super resolution image. In particular, the two dimensional quaternion valued singular spectrum analysis (2DQSSA) based denoising method, the empirical mode decomposition (EMD) based denoising method and the discrete cosine transform based denoised method are applied. For the 2DQSSA based denoising method, the luminance plane is used as the real part of the quaternion valued image. Since different color planes in the quaternion valued image are fused together via the quaternion valued operation, some high frequency information missing in one color plane can be generated using those in other color planes. On the other hand, for the EMD based denoising method, the selection of the intrinsic mode functions (IMFs) is formulated as a binary linear programming problem. Here, the high frequency components generated by the aliasing are removed by discarding some IMFs. The computer numerical simulation results show that our proposed method can achieve the super resolution performance better than those without performing any one of the above three time frequency analysis based denoising.
C1 [Cheng, Yingdan; Ling, Bingo Wing-Kuen; Lin, Yuxin; Huang, Ziyin] Guangdong Univ Technol, Fac Informat Engn, Guangzhou 510006, Peoples R China.
   [Chan, Yui-Lam] Hong Kong Polytech Univ, Dept Elect & Informat Engn, Hung Hom, Hong Kong, Peoples R China.
C3 Guangdong University of Technology; Hong Kong Polytechnic University
RP Ling, BWK (corresponding author), Guangdong Univ Technol, Fac Informat Engn, Guangzhou 510006, Peoples R China.
EM 1783675881@qq.com; yongquanling@gdut.edu.cn; a19860075121@163.com;
   shmillehzy@gmail.com; enylchan@polyu.edu.hk
FU National Nature Science Foundation of China [U1701266, 61671163,
   62071128]; Team Project of the Education Ministry of the Guangdong
   Province [2017KCXTD011]; Guangdong Higher Education Engineering
   Technology Research Center for Big Data onManufacturing Knowledge Patent
   [501130144]; Hong Kong Innovation and Technology Commission, Enterprise
   Support Scheme [S/E/070/17]
FX This paper was supported partly by the National Nature Science
   Foundation of China (no. U1701266,no. 61671163 and no. 62071128), the
   Team Project of the Education Ministry of the Guangdong Province
   (no.2017KCXTD011), the Guangdong Higher Education Engineering Technology
   Research Center for Big Data onManufacturing Knowledge Patent (no.
   501130144) and the Hong Kong Innovation and Technology Commission,
   Enterprise Support Scheme (no. S/E/070/17)
CR Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Buccini A, 2019, J COMPUT APPL MATH, VMath373
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Enshaeifar S, 2016, IEEE T NEUR SYS REH, V24, P57, DOI 10.1109/TNSRE.2015.2465177
   Ertürk A, 2012, INT GEOSCI REMOTE SE, P4162, DOI 10.1109/IGARSS.2012.6351695
   Ho CYF, 2008, IEEE T CIRCUITS-II, V55, P168, DOI 10.1109/TCSII.2007.910803
   Hu JK, 2021, IEEE SIGNAL PROC LET, V28, P2152, DOI 10.1109/LSP.2021.3099746
   Li Z, 2019, NEUROCOMPUTING, P377
   Lin YX, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13030405
   Patel V., 2011, 2011 International Conference on Communication Systems and Network Technologies (CSNT), P495, DOI 10.1109/CSNT.2011.106
   Qiu DF, 2020, COMPUT METH PROG BIO, V187, DOI 10.1016/j.cmpb.2019.105059
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Wu HP, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2018.2831791
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
NR 15
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22705
EP 22722
DI 10.1007/s11042-023-14474-2
EA FEB 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000933104800003
DA 2024-07-18
ER

PT J
AU Zhang, XT
   Su, QT
   Sun, YH
   Chen, SY
AF Zhang, Xueting
   Su, Qingtang
   Sun, Yehan
   Chen, Siyu
TI A robust and high-efficiency blind watermarking method for color images
   in the spatial domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spatial domain; Robust watermarking; DC component; Discrete Tchebichef
   transform
ID ALGORITHM; TRANSFORM; SCHEME
AB To respond the digital infringement quickly and effectively in the fifth-generation (5G) new environment, a novel spatial-domain watermarking method combining discrete Tchebichef transform (DTT) is proposed in this paper. Based on the energy concentration property of DTT, its direct current (DC) component is calculated directly by image pixels, then is quantified to embed the color watermark in the spatial domain by using the variable quantization steps, and the embedded watermark can be extracted from the DC component in the spatial domain. The contributions and novelty of this paper are summarized as follows: 1) the mechanism combining DTT and spatial domain is analyzed and derived to quickly implement watermark embedding and blind extraction; 2) different quantization steps are used in different channels to improve the watermark imperceptibility; 3) the overflow detection is set up to ensure the accurate and complete extraction of the watermark. The objective performance of the proposed method is shown as follows: 1) the average of peak signal-to-noise ratio (PSNR) is greater than 41 dB; 2) the average of structural similarity index metric (SSIM) is more than 0.97; 3) all normalized cross-correlation (NC) values without attacks remain 1; 4) the average of NC after various attacks is above 0.96; 5) the total execution time is within 0.5 seconds; 6) the maximum embedding payload keeps 0.0625bpp; 7) the key space reaches to 2206. The obtained simulation results manifest that the proposed method provides strong robustness, high real-time performance, and reliable security around the premise of the better imperceptibility and satisfactory embedding payload, which is suitable for fast and efficient copyright protection occasions in 5G environment.
C1 [Zhang, Xueting; Su, Qingtang; Sun, Yehan; Chen, Siyu] Ludong Univ, Sch Informat & Elect Engn, Yantai 264025, Peoples R China.
C3 Ludong University
RP Su, QT (corresponding author), Ludong Univ, Sch Informat & Elect Engn, Yantai 264025, Peoples R China.
EM sdytsqt@163.com
FU National Natural Science Foundations of China [61771231, 61772253,
   62171209, 61873117, 61872170, 61803253]; Key Project of Shandong Natural
   Science Foundation [ZR2020KF023]; Natural Science Foundation of Shandong
   Province [ZR2019MF062]
FX AcknowledgementsThe work was supported by the National Natural Science
   Foundations of China (No. 61771231, 61772253, 62171209, 61873117,
   61872170 and 61803253), the Key Project of Shandong Natural Science
   Foundation (No. ZR2020KF023), and Natural Science Foundation of Shandong
   Province (No. ZR2019MF062).
CR Abraham J, 2019, J KING SAUD UNIV-COM, V31, P125, DOI 10.1016/j.jksuci.2016.12.004
   Ahmad Asma, 2014, International Journal of Computer Network and Information Security, V6, P58, DOI 10.5815/ijcnis.2014.12.07
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Chen Y, 2021, SIGNAL PROCESS, V185, DOI 10.1016/j.sigpro.2021.108088
   Fares K, 2020, OPTIK, V208, DOI 10.1016/j.ijleo.2020.164562
   Golea N., 2010, IEEE INT C COMPUTER, P1
   Gonzalez R. C., 2002, DIGITAL IMAGE PROCES
   Kahlessenane F, 2021, MULTIMED TOOLS APPL, V80, P19827, DOI 10.1007/s11042-021-10713-6
   Kamili A, 2021, IEEE T IND INFORM, V17, P5108, DOI 10.1109/TII.2020.3028612
   Kashyap N., 2012, Int J Mod Educ Comput Sci, V4, P50, DOI DOI 10.5815/IJMECS.2012.03.07
   Kashyap N., 2012, ADV COMPUTATIONAL RE, V4, P42
   Ko HJ, 2020, INFORM SCIENCES, V517, P128, DOI 10.1016/j.ins.2019.11.005
   Laishram D, 2021, MULTIMED TOOLS APPL, V80, P23815, DOI 10.1007/s11042-020-10389-4
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Liu DC, 2021, EXPERT SYST APPL, V170, DOI 10.1016/j.eswa.2020.114540
   Liu XL, 2018, IEEE T CIRC SYST VID, V28, P1047, DOI 10.1109/TCSVT.2016.2633878
   Liu YW, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3425605
   MAY RM, 1976, NATURE, V261, P459, DOI 10.1038/261459a0
   Noor R, 2019, SOFT COMPUT, V23, P9821, DOI 10.1007/s00500-019-03838-2
   Pandey P, 2014, MULTIMED TOOLS APPL, V72, P2653, DOI 10.1007/s11042-013-1577-7
   Pandey P, 2014, MULTIMED TOOLS APPL, V72, P723, DOI 10.1007/s11042-013-1375-2
   Pourhashemi SM, 2021, NEURAL COMPUT APPL, V33, P6161, DOI 10.1007/s00521-020-05389-2
   Prabha K, 2022, J KING SAUD UNIV-COM, V34, P2982, DOI 10.1016/j.jksuci.2020.04.003
   Reyes-Reyes R, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11073187
   Sangwine S, 1998, COLOUR IMAGE PROCESS, V29
   Setyono A, 2020, EUR RESPIR J, V13, P432, DOI [10.22266/ijies2020.1231.38, DOI 10.22266/IJIES2020.1231.38]
   Singh AK, 2019, MULTIMED TOOLS APPL, V78, P30523, DOI 10.1007/s11042-018-7115-x
   Singh SK, 2009, UKSIM EURO SYMP COMP, P241, DOI 10.1109/EMS.2009.114
   Sinhal R, 2021, PATTERN RECOGN LETT, V145, P171, DOI 10.1016/j.patrec.2021.02.011
   Sivananthamaitrey P, 2022, MULTIMED TOOLS APPL, V81, P1001, DOI 10.1007/s11042-021-11204-4
   Su QT, 2020, SOFT COMPUT, V24, P445, DOI 10.1007/s00500-019-03924-5
   Su QT, 2018, MULTIDIM SYST SIGN P, V29, P1055, DOI 10.1007/s11045-017-0487-7
   Su QT, 2013, OPTIK, V124, P6255, DOI 10.1016/j.ijleo.2013.05.013
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   University of Granada Computer Vision Group, 2002, CVG-UGR Image Database
   University of Southern California Signal and Image Processing Institute, 1997, USC-SIPI Image Database.
   Voloshynovskiy S, 2001, IEEE COMMUN MAG, V39, P118, DOI 10.1109/35.940053
   Wan WB, 2022, NEUROCOMPUTING, V488, P226, DOI 10.1016/j.neucom.2022.02.083
   Wan WB, 2020, MULTIMED TOOLS APPL, V79, P4907, DOI 10.1007/s11042-018-6860-1
   Wan WB, 2020, PATTERN RECOGN LETT, V130, P157, DOI 10.1016/j.patrec.2018.08.009
   Wang J, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112868
   Wang X, 2020, IEEE T CIRC SYST VID, V30, P2406, DOI 10.1109/TCSVT.2019.2915116
   Yuan ZH, 2020, MULTIMED TOOLS APPL, V79, P30557, DOI 10.1007/s11042-020-09499-w
   Zhang FY, 2019, MULTIMED TOOLS APPL, V78, P20133, DOI 10.1007/s11042-019-7326-9
NR 44
TC 4
Z9 4
U1 5
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27217
EP 27243
DI 10.1007/s11042-023-14479-x
EA FEB 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000931751400004
DA 2024-07-18
ER

PT J
AU Jaber, MM
   Ali, MH
   Abd, SK
   Abosinnee, AS
   Malik, RQ
AF Jaber, Mustafa Musa
   Ali, Mohammed Hasan
   Abd, Sura Khalil
   Abosinnee, Ali S.
   Malik, R. Q.
TI Simulation research on the collision between freight cars and expressway
   three-wave beam steel guardrail
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE FE simulation; Collision; Freight cars; Guardrail; Safety
ID SYSTEM; ENERGY; MODEL; OPTIMIZATION; FRAMEWORK
AB Steel guardrails on expressways are a vital piece of traffic safety infrastructure. Unexpected events, such as accidents, might cause a freight vehicle travelling on the road to lose control. Because it may prevent the freight vehicle from speeding off the road, a steel guardrail can help keep the driver safe. As a result, the steel guardrail's guiding ability, anti-collision performance and safety behaviour are crucial indices to measure expressway steel safety in collision accidents between freight vehicles and the steel guardrails. In this study, finite element (FE) simulation is carried out on the collision between freight cars and an expressway three-wave steel guardrail. A two-wave beam steel guardrail has been compared to the simulation results. The dynamic simulation results were predicted using the LS-Dyna FE simulator at a speed of 90 km/h and impact angles of 10 degrees, 15 degrees, 20 degrees, 25 degrees, and 30 degrees. To estimate the steel guardrail's protective function in real-time experimental approaches, freight vehicles clash with steel guardrails on expressways, resulting in the steel guardrail collapsing and the freight car rushing off the road. To accurately anticipate the safety of highway steel guardrails, FE modelling is the best option. The expressway three-wave steel guardrail absorbs more than 60% of the freight car's principal translational momentum in a collision, reducing collision force transmitted to passengers and highway accident severity.
C1 [Jaber, Mustafa Musa] Al Turath Univ Coll, Dept Comp Sci, Baghdad, Iraq.
   [Jaber, Mustafa Musa] Al Farahidi Univ, Med Instrumentat Tech Engn Dept, Baghdad, Iraq.
   [Ali, Mohammed Hasan] Imam Jaafar Al Sadiq Univ, Fac Informat Technol, Comp Tech Engn Dept, Najaf 10023, Iraq.
   [Abd, Sura Khalil] Dijlah Univ Coll, Dept Comp Sci, Baghdad 10021, Iraq.
   [Abosinnee, Ali S.] Altoosi Univ Coll, Najaf, Iraq.
   [Abosinnee, Ali S.] Islamic Univ, Coll Tech Engn, Dept Comp Tech Engn, Najaf, Iraq.
   [Malik, R. Q.] Al Mustaqbal Univ Coll, Med Instrumentat Tech Engn Dept, Babylon, Iraq.
C3 Imam Jaa'far al-Sadiq University; Altoosi University College; Islamic
   University College; Al-Mustaqbal University College
RP Jaber, MM (corresponding author), Al Turath Univ Coll, Dept Comp Sci, Baghdad, Iraq.; Jaber, MM (corresponding author), Al Farahidi Univ, Med Instrumentat Tech Engn Dept, Baghdad, Iraq.
EM Mustafa.jaber@turath.edu.iq; mh180250@gmail.com; sura.khalil@duc.edu.iq;
   ramiqays@gmail.com
RI Malik, Rami Qays/AAA-9177-2020
OI Malik, Rami Qays/0000-0003-2518-9260
CR Amudha G, 2018, WIRELESS PERS COMMUN, V102, P3303, DOI 10.1007/s11277-018-5369-2
   Amudha G., 2012, INT C COMPUT INTELL, V4, P2012
   Bhatti MM, 2019, OPEN PHYS, V17, P177, DOI 10.1515/phys-2019-0018
   Bielenberg RW, 2017, TRANSPORT RES REC, P77, DOI 10.3141/2638-09
   Billah MFRM, 2021, IPSN'21: PROCEEDINGS OF THE 20TH ACM/IEEE CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS, P132, DOI 10.1145/3412382.3458262
   Chipengo U, 2018, IEEE ACCESS, V6, P70053, DOI 10.1109/ACCESS.2018.2881101
   Gheisari M, 2021, FUTURE GENER COMP SY, V123, P1, DOI 10.1016/j.future.2021.01.028
   Gholipour G, 2020, MAR STRUCT, V69, DOI 10.1016/j.marstruc.2019.102662
   Goyat R, 2021, FUTURE GENER COMP SY, V125, P221, DOI 10.1016/j.future.2021.06.039
   Gutowski M, 2017, ADV ENG SOFTW, V114, P85, DOI 10.1016/j.advengsoft.2017.06.004
   Gutowski M, 2017, ADV ENG SOFTW, V112, P88, DOI 10.1016/j.advengsoft.2017.04.004
   Huang Z, 2020, FRONT SOC SCI TECHNO, V13
   Kapoor Archit, 2020, 2020 International Conference on Smart Technologies in Computing, Electrical and Electronics (ICSTCEE), P208, DOI 10.1109/ICSTCEE49637.2020.9277417
   Kurtulus D, 2020, MATER TEST, V62, P251, DOI 10.3139/120.111478
   Kuthadi VM, 2022, WIRELESS PERS COMMUN, V127, P1377, DOI 10.1007/s11277-021-08583-0
   Lai J, 2021, VEHICLE SYST DYN, V59, P1803, DOI 10.1080/00423114.2020.1792941
   Li Z, 2021, ACCIDENT ANAL PREV, V159, DOI 10.1016/j.aap.2021.106286
   Liu Y, 2020, IEEE WIREL COMMUN, V27, P24, DOI 10.1109/MWC.01.1900525
   Manogaran G, 2021, IEEE SENS J, V21, P15564, DOI 10.1109/JSEN.2020.3017384
   Manogaran G, 2021, IEEE T VEH TECHNOL, V70, P2404, DOI 10.1109/TVT.2021.3058689
   Manogaran G, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19133030
   Meng YZ, 2019, SAE INT J COMMER VEH, V12, P271, DOI 10.4271/02-12-04-0021
   Neves RR, 2018, J BRAZ SOC MECH SCI, V40, DOI 10.1007/s40430-018-1201-x
   Nguyen NT, 2018, T EMERG TELECOMMUN T, V29, DOI 10.1002/ett.3433
   Nguyen NT, 2017, 2017 IEEE 16TH INTERNATIONAL SYMPOSIUM ON NETWORK COMPUTING AND APPLICATIONS (NCA), P241
   Nie XT, 2020, COMPUT COMMUN, V154, P188, DOI 10.1016/j.comcom.2020.02.052
   Noh MH, 2017, THIN WALL STRUCT, V120, P138, DOI 10.1016/j.tws.2017.08.028
   Ozcanan S, 2019, STRUCT MULTIDISCIP O, V60, P343, DOI 10.1007/s00158-019-02203-z
   Palassi M, 2019, J TRANSPORT RES
   Agudelo GER, 2021, INTELIGENCIA ARTIFIC, V24, P121, DOI 10.4114/intartf.vol24iss67pp121-128
   Shanmugam L, 2020, IET CONTROL THEORY A, V14, P1321, DOI 10.1049/iet-cta.2019.0246
   Srivastava AK, 2021, J HYDROMETEOROL, V22, P971, DOI 10.1175/JHM-D-20-0180.1
   Sundarasekar R, 2019, IEEE ACCESS, V7, P80093, DOI 10.1109/ACCESS.2019.2921833
   Tajchman K, 2020, APPL ECOL ENV RES, V18, P1981, DOI 10.15666/aeer/1801_19811997
   Unyong B, 2021, AIMS MATH, V6, P1607, DOI 10.3934/math.2021096
   Vijayakumar KP, 2019, SOFT COMPUT, V23, P2655, DOI 10.1007/s00500-018-3636-5
   Wilde K, 2020, INT J NONLIN SCI NUM, V21, P65, DOI 10.1515/ijnsns-2018-0169
   Yang F, 2021, ENVIRON IMPACT ASSES, V88, DOI 10.1016/j.eiar.2021.106565
   Yang J, 2019, ENG STRUCT, V182, P459, DOI 10.1016/j.engstruct.2018.12.090
   Yao JC, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21155152
   Yin HF, 2017, ADV ENG SOFTW, V112, P154, DOI 10.1016/j.advengsoft.2017.05.002
   Younan M, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.500
   Zhang R, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12083115
   Zhang XD, 2021, SUSTAIN ENERGY TECHN, V46, DOI 10.1016/j.seta.2021.101208
NR 44
TC 1
Z9 1
U1 6
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JAN 31
PY 2023
DI 10.1007/s11042-023-14374-5
EA JAN 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8J3HG
UT WOS:000922310300006
DA 2024-07-18
ER

PT J
AU Ragavan, SV
   Tarun, AH
   Yogeeshwar, S
   Kumar, BSV
   Reka, SS
AF Ragavan, S. Venkat
   Tarun, A. H.
   Yogeeshwar, S.
   Kumar, B. S. Vishwath
   Sofana Reka, S.
TI A realtime portable and accessible aiding system for the blind - a cloud
   based approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image captioning; Object spatial analysis; Optical Character Recognition
   (OCR); Text to Speech (TTS); Multilingual voice; Language translation
ID RECOGNITION
AB With the rise of AI and Deep Learning technologies, it is now possible to give the visually impaired a sense of sight. This work intends to propose a system, which helps the blind to perceive their surrounding without any extra hand. The system harnesses the power of revolutionary cloud technology, cutting-edge artificial intelligence systems and state of the art language translation technologies for the inevitable cause of assisting the blind. This work mainly focusses on developing a simple gesture-controlled cloud based mobile application, which would allow them to capture their surroundings and help them to navigate through their surroundings in real-time. In this work a real case system architecture is proposed which would analyse the spatial reference of objects in the image and also the custom trained NLP engine generates a description that is narrated in their own native language which stands the unique aspect of the work. The proposed application proves to be a one-stop solution for the visually impaired with real case analysis. To strengthen the analysis of the work, results pertaining to the system architecture emphasising its real-time performance and accessibility are done.
C1 [Ragavan, S. Venkat; Tarun, A. H.] Vellore Inst Technol, Sch Comp Sci Engn, Chennai, India.
   [Yogeeshwar, S.; Kumar, B. S. Vishwath] Vellore Inst Technol, Sch Elect Engn, Chennai, India.
   [Sofana Reka, S.] Vellore Inst Technol, Ctr Smart Grid Technol, Sch Elect Engn, Chennai, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai; Vellore Institute of
   Technology (VIT); VIT Chennai; Vellore Institute of Technology (VIT);
   VIT Chennai
RP Reka, SS (corresponding author), Vellore Inst Technol, Ctr Smart Grid Technol, Sch Elect Engn, Chennai, India.
EM chocos.sofana@gmail.com
RI Balan, Dr Santhosh Kumar/N-3734-2016
OI Balan, Dr Santhosh Kumar/0000-0003-1929-7337
CR Ahmed F, 2018, 2018 1ST INTERNATIONAL CONFERENCE ON DATA INTELLIGENCE AND SECURITY (ICDIS 2018), P85, DOI 10.1109/ICDIS.2018.00020
   Arora A, 2019, WIRELESS PERS COMMUN, V107, P651, DOI 10.1007/s11277-019-06294-1
   Bagwan SMR, 2015, 2015 INT C COMP COMM, P1, DOI DOI 10.1109/IC4.2015.7375665
   Bai Jinqiang., 2017, Proceedings of the 2017 International Conference on Artificial Intelligence, Automation and Control Technologies, P1, DOI [DOI 10.1145/3080845.3080867, 10.1145/3080845.3080867]
   Bakshi AM, 2019, 2019 IEEE GAMES, ENTERTAINMENT, MEDIA CONFERENCE (GEM), DOI 10.1109/gem.2019.8811556
   Berger A, 2019, 2019 INTERNATIONAL SYMPOSIUM ON EDUCATIONAL TECHNOLOGY (ISET 2019), P265, DOI 10.1109/ISET.2019.00063
   Chaudhuri A, 2017, STUD FUZZ SOFT COMP, V352, P9
   Cutter M, 2017, ACM T ACCESS COMPUT, V10, DOI 10.1145/3075300
   Dong JF, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1082, DOI 10.1145/2964284.2984064
   Evans G, 2017, PROC SPIE, V10197, DOI 10.1117/12.2262626
   Fiannaca A, 2014, P ACM SIGACCESS C CO, P19, DOI DOI 10.1145/2661334.2661453
   Fusco Giovanni, 2014, ASSETS, V2014, P281
   Gaudissart V, 2004, 9 C SPEECH COMP
   Gupta P, 2022, MACHINE LEARNING CRI, P177
   Gurari D, 2020, ARXIV
   Hammami A, 2021, MULTIMED TOOLS APPL, V80, P7479, DOI 10.1007/s11042-020-09982-4
   Hasnine MN, 2019, LECT NOTES COMPUT SC, V11587, P346, DOI 10.1007/978-3-030-21935-2_26
   Hu MH, 2019, INT J ROBOT AUTOM, V34, P580, DOI 10.2316/J.2019.206-0302
   Huang JH, 2020, IEEE J BIOMED HEALTH, V24, P292, DOI 10.1109/JBHI.2019.2909688
   Jain A, 2013, FUNDAMENTAL CHALLENG, V2, P86
   Jasmine GS, 2021, 2021 7 INT C ADV COM, V1, P1122
   Khan MA, 2020, IEEE T HUM-MACH SYST, V50, P507, DOI 10.1109/THMS.2020.3027534
   Kumar Sandeep, 2020, Innovations in Electronics and Communication Engineering. Proceedings of the 8th ICIECE 2019. Lecture Notes in Networks and Systems (LNNS 107), P437, DOI 10.1007/978-981-15-3172-9_42
   Kuriakose Bineeth, 2020, Universal Access in Human-Computer Interaction. Applications and Practice. 14th International Conference, UAHCI 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12189), P568, DOI 10.1007/978-3-030-49108-6_41
   Landa, 2011, VIDEATION ASSISTANT
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lu DH, 2021, IEEE INT CONF COMP V, P1718, DOI 10.1109/ICCVW54120.2021.00197
   Mackowski M, 2018, MULTIMED TOOLS APPL, V77, P6191, DOI 10.1007/s11042-017-4526-z
   Maheshan MS, 2020, INT J INTERACT MULTI, V6, P78, DOI 10.9781/ijimai.2019.03.006
   Martinez Gutierrez MF, 2019, THESIS U GENEVA
   Matusiak K, 2013, C HUM SYST INTERACT, P479, DOI 10.1109/HSI.2013.6577868
   Murali M., 2020, 2020 Proceedings of the International Conference on Communication and Signal Processing (ICCSP), P0795, DOI 10.1109/ICCSP48568.2020.9182201
   Neto R, 2014, PROC TECH, V16, P1200, DOI 10.1016/j.protcy.2014.10.135
   Onyejegbu LN., 2016, INT J COMPUT APPL, V146, P14
   Pamparau C, 2021, MULTIMED TOOLS APPL, V80, P30943, DOI 10.1007/s11042-020-10164-5
   Peters J.-P., 2004, Proceedings. 33rd Applied Imagery Pattern Recognition Workshop, P217
   Price LC, 2021, AUTOMAT CONSTR, V124, DOI 10.1016/j.autcon.2021.103552
   Qureshi T. A., 2021, Int Res J Eng Technol, V8, P2883, DOI DOI 10.1177/02646196221131746
   Rahman W, 2021, INTERNET THINGS-NETH, V13, DOI 10.1016/j.iot.2020.100344
   Raj V. P. Gowtham, 2022, 2022 4th International Conference on Smart Systems and Inventive Technology (ICSSIT), P1419, DOI 10.1109/ICSSIT53264.2022.9716412
   Schauerte B, 2012, LECT NOTES COMPUT SC, V7383, P566, DOI 10.1007/978-3-642-31534-3_83
   Singh Nitin, 2021, 2021 5th International Conference on Electronics, Communication and Aerospace Technology (ICECA), P1179, DOI 10.1109/ICECA52323.2021.9676158
   Smith R, 2007, PROC INT CONF DOC, P629, DOI 10.1109/icdar.2007.4376991
   Tamimi AA, 2019, P INT C IM PROC COMP, P98
   Vaithiyanathan D, 2019, INT CONF ADV COMPU, P90, DOI 10.1109/ICoAC48765.2019.246822
   Vázquez SR, 2018, LECT NOTES COMPUT SC, V10896, P31, DOI 10.1007/978-3-319-94277-3_6
   Verma KK, 2020, INT J INTERACT MULTI, V6, P125, DOI 10.9781/ijimai.2020.04.002
   Wang MS, 2016, IEEE IMAGE PROC, P4448
   Wang Q., 2018, ARXIV
   Yang CS, 2017, PATTERN RECOGN LETT, V100, P14, DOI 10.1016/j.patrec.2017.08.005
   Yin XC, 2016, IEEE T IMAGE PROCESS, V25, P2752, DOI 10.1109/TIP.2016.2554321
NR 51
TC 0
Z9 0
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20641
EP 20654
DI 10.1007/s11042-023-14419-9
EA JAN 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000920970600003
DA 2024-07-18
ER

PT J
AU Yang, S
   Tong, XJ
   Wang, Z
   Zhang, M
AF Yang, Sen
   Tong, Xiaojun
   Wang, Zhu
   Zhang, Miao
TI S-box generation algorithm based on hyperchaotic system and its
   application in image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 4D hyperchaotic system; S-box; Image encryption; Particle swarm
   optimization algorithm; Simulated annealing algorithm
ID SCHEME; CRYPTOSYSTEM; COMBINATION
AB S-box is the only non-linear device in the cryptographic algorithm, and its quality determines the lower limit strength of the cryptographic algorithm. However, because the image data is highly correlated, the traditional encryption methods and their S-boxes, such as AES and DES are not suitable for using in image encryption. Based on this, this paper proposes an S-box generation algorithm based on a 4D hyperchaotic system and improved particle swarm optimization. Firstly, this paper improves on the Lorenz chaotic system and proposes a 4D hyperchaotic system with a higher Lyapunov exponent and more complex dynamics. Secondly, the idea of simulated annealing algorithm is introduced into the particle swarm optimization algorithm, which further improves the efficiency of the particle swarm optimization algorithm and improves the problem that the particle swarm optimization algorithm is easy to fall into the local optimal solution. Then an improved particle swarm optimization algorithm is used to optimize the nonlinearity of the S-box to improve the performance of the S-box. Finally, use the generated S-box to design an image encryption algorithm and prove the security of the S-box. The experimental results show that the S-box designed in this paper has excellent performance in the five indicators of Nonlinearity, SAC, BIC-NL, LP, and DP. At the same time, the encryption result can resist common attacks, so it has strong multimedia security.
C1 [Yang, Sen; Tong, Xiaojun; Wang, Zhu; Zhang, Miao] Harbin Inst Technol, Comp Sci & Technol, Weihai 264200, Peoples R China.
C3 Harbin Institute of Technology
RP Tong, XJ (corresponding author), Harbin Inst Technol, Comp Sci & Technol, Weihai 264200, Peoples R China.
EM tong_xiaojun@163.com
FU Shandong Provincial Natural Science Foundation [ZR2019MF054]; National
   Natural Science Foundation of China [61902091]; Fundamental Research
   Funds for Central Universities [HIT.NSRIF.2020099]; Weihai University
   Co-construction Project
FX This work was supported by the following projects and foundations:
   project ZR2019MF054 supported by Shandong Provincial Natural Science
   Foundation, the National Natural Science Foundation of China
   (No.61902091) and Fundamental Research Funds for Central Universities
   (HIT.NSRIF.2020099), 2017 Weihai University Co-construction Project.Data
   availability statementsThe data that support the findings of this study
   are available from the corre-sponding author upon reasonable request.
CR Abbasi AA, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106465
   Ahmad M, 2015, PROCEDIA COMPUT SCI, V57, P572, DOI 10.1016/j.procs.2015.07.394
   Alhadawi HS, 2021, MULTIMED TOOLS APPL, V80, P7333, DOI 10.1007/s11042-020-10048-8
   Belazi A, 2017, OPTIK, V130, P1438, DOI 10.1016/j.ijleo.2016.11.152
   Belazi A, 2017, NONLINEAR DYNAM, V87, P337, DOI 10.1007/s11071-016-3046-0
   Çavusoglu Ü, 2017, NONLINEAR DYNAM, V87, P1081, DOI 10.1007/s11071-016-3099-0
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen JX, 2018, NONLINEAR DYNAM, V93, P2399, DOI 10.1007/s11071-018-4332-9
   Cun QQ, 2021, OPTIK, V243, DOI 10.1016/j.ijleo.2021.167286
   Ding LN, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9081280
   Fang DJ, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0242110
   Farah T, 2017, NONLINEAR DYNAM, V88, P1059, DOI 10.1007/s11071-016-3295-y
   Gbaden T., 2019, NIGERIAN ANN PURE AP, V2, P223, DOI [10.46912/napas.125, DOI 10.46912/NAPAS.125]
   Hematpour N, 2021, NEURAL COMPUT APPL, V33, P5111, DOI 10.1007/s00521-020-05304-9
   Hosny KM, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10091066
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Khan M, 2015, SIGNAL IMAGE VIDEO P, V9, P1335, DOI 10.1007/s11760-013-0577-4
   Lambic D, 2017, NONLINEAR DYNAM, V87, P2407, DOI 10.1007/s11071-016-3199-x
   Liu GJ, 2015, NONLINEAR DYNAM, V82, P1867, DOI 10.1007/s11071-015-2283-y
   Liu HJ, 2020, APPL MATH COMPUT, V376, DOI 10.1016/j.amc.2020.125153
   Liu LY, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8122650
   Liu S, 2021, IEEE T FUZZY SYST, V29, P90, DOI 10.1109/TFUZZ.2020.3006520
   Liu S, 2018, COMPLEXITY, DOI 10.1155/2018/2016976
   Liu S, 2017, FRACTALS, V25, DOI 10.1142/S0218348X17400047
   Nematzadeh H, 2020, OPTIK, V202, DOI 10.1016/j.ijleo.2019.163505
   Tang GP, 2005, CHAOS SOLITON FRACT, V23, P413, DOI 10.1016/j.chaos.2004.04.023
   Ullah A, 2017, NONLINEAR DYNAM, V88, P2757, DOI 10.1007/s11071-017-3409-1
   Wang XY, 2020, CHAOS SOLITON FRACT, V141, DOI 10.1016/j.chaos.2020.110309
   Wang XY, 2020, OPTIK, V217, DOI 10.1016/j.ijleo.2020.164884
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wang Y, 2020, INFORM SCIENCES, V523, P152, DOI 10.1016/j.ins.2020.03.025
   Wang Y, 2012, PHYS LETT A, V376, P827, DOI 10.1016/j.physleta.2012.01.009
   Wu XJ, 2014, COMMUN NONLINEAR SCI, V19, P1884, DOI 10.1016/j.cnsns.2013.10.025
   Yang Y, 2021, OPT LASER TECHNOL, V133, DOI 10.1016/j.optlastec.2020.106553
   Zhang XQ, 2019, MULTIMED TOOLS APPL, V78, P7841, DOI 10.1007/s11042-018-6496-1
   Zhou MJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107484
NR 36
TC 11
Z9 11
U1 13
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 25559
EP 25583
DI 10.1007/s11042-023-14394-1
EA JAN 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000918001600002
DA 2024-07-18
ER

PT J
AU Padhye, V
   Lakshmanan, K
   Chaturvedi, A
AF Padhye, Vaibhav
   Lakshmanan, Kailasam
   Chaturvedi, Amrita
TI Proximal policy optimization based hybrid recommender systems for large
   scale recommendations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Proximal policy optimization; Hybrid recommender system; Reinforcement
   learning; Policy gradient algorithms
AB Recommender systems have become increasingly popular due to the significant rise in digital information over the internet in recent users. They help provide personalized recommendations to the user by selecting a few items out of a large set of items. However, with the growing size of item space and users, scalability remains a key issue for recommender systems. However, most existing policy gradient approaches in recommendations suffer from high variance leading to an increase in instability during the learning process. Policy Gradient Algorithms such as PPO are proven to be effective in large action spaces (a large number of items) as they learn the optimal policy directly from the samples. We use the PPO algorithm to train our Reinforcement Learning agent modeling the collaborative filtering process as a Markov Decision Process. PPO utilizes the actor-critic framework and thus mitigates the high variance in Policy Gradient Algorithms. Further, we address the cold start issue in Collaborative filtering with autoencoder-based content filtering. Proximal Policy Optimization (PPO) methods are today considered among the most effective reinforcement learning methods, achieving state-of-the-art performance and even outperforming Deep Q learning methods. In this paper, we propose a switching hybrid recommender system using the two different recommender system techniques. A switching hybrid system can switch between recommendation techniques depending on some criterion and can tackle its constituent recommender system's shortfall using the other counterpart in a particular situation. We show that our method outperforms various baseline methods on the popular Movielens datasets for different evaluation metrics. On Movielens 1m, our method outperforms the baseline by 9.19% in terms of R@10 and 3.86% and 6.58% in terms of P@10 and P@20, respectively. For the Movielens 100k dataset, our method improves on the baseline methods by 4.10% in terms of P@10 and 3.90% and 2.40% in terms of R@10 and R@20.
C1 [Padhye, Vaibhav; Lakshmanan, Kailasam; Chaturvedi, Amrita] IIT BHU, Varanasi BHU, Varanasi, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi)
RP Padhye, V (corresponding author), IIT BHU, Varanasi BHU, Varanasi, India.
EM vaibhavpadhye10@gmail.com
RI University, St Joseph/KCJ-4770-2024; Chaturvedi, Amrita/D-7823-2017
OI University, St Joseph/0009-0005-5536-0390; 
CR Akerkar B, 2010, KNOWL-BASED SYST
   Aljunid Mohammed Fadhel, 2020, Procedia Computer Science, V171, P829, DOI 10.1016/j.procs.2020.04.090
   Arulkumaran K, 2017, IEEE SIGNAL PROC MAG, V34, P26, DOI 10.1109/MSP.2017.2743240
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhatti UA, 2018, HUM VACC IMMUNOTHER, V14, P165, DOI 10.1080/21645515.2017.1379639
   Breese J., 1998, P 14 C UNC ART INT, P43
   Brockman Greg, 2016, arXiv
   Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564
   Chen HC, 2021, IEEE INT CONF BIG DA, P5699, DOI 10.1109/BigData52589.2021.9671947
   Chen M, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P456, DOI 10.1145/3289600.3290999
   Chen XL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9620, DOI 10.1109/ICCV48922.2021.00950
   Dulac-Arnold G., 2015, CoRR
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Hu Y, 2018, ABS180300710 CORR
   Koren Y., 2008, P 14 ACM SIGKDD INT, P426
   Li L., 2010, P 19 INT C WORLD WID, DOI [10.1145/1772690.1772758, DOI 10.1145/1772690.1772758]
   Li WM, 2019, IEEE ACCESS, V7, P45451, DOI 10.1109/ACCESS.2018.2885084
   Lin WM, 2021, IEEE T COMPUT SOC SY, V8, P227, DOI 10.1109/TCSS.2020.2965234
   Liu F, 2018, ARXIV
   Liu Y, 2018, BIG DATA MIN ANAL, V1, P211, DOI 10.26599/BDMA.2018.9020019
   Marlin B., 2003, Modeling User Rating Profiles For Collaborative Filtering
   Pan FY, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P1421, DOI 10.1145/3308558.3313616
   Polat Huseyin, 2005, P 2005 ACM S APPL CO, P791
   Raffin A, 2021, J MACH LEARN RES, V22, P1
   Salakhutdinov R., 2007, P 24 INT C MACH LEAR, P791, DOI DOI 10.1145/1273496.1273596
   Salakhutdinov Ruslan, 2008, ADV NEURAL INFORM PR, P1257, DOI DOI 10.5555/2981562.2981720
   Salakhutdinov Ruslan, 2008, P INT C MACH LEARN, P880, DOI [10.1145/1390156.1390267, DOI 10.1145/1390156.1390267]
   Sarwar B, 2017, ARXIV
   Sedhain S, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P111, DOI 10.1145/2740908.2742726
   Shani G, 2005, J MACH LEARN RES, V6, P1265
   Singh M, 2020, KNOWL INF SYST, V62, P1, DOI 10.1007/s10115-018-1254-2
   Srivihok A, 2005, SEVENTH INTERNATIONAL CONFERENCE ON ELECTRONIC COMMERCE, VOLS 1 AND 2, SELECTED PROCEEDINGS, P287
   Sutton R. S., 2000, IEEE Transactions on Systems, Man, and Cybernetics
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Taghipour N, 2008, APPLIED COMPUTING 2008, VOLS 1-3, P1164
   Tao Y, 2023, NEURAL COMPUT APPL, V35, P13077, DOI 10.1007/s00521-021-05723-2
   Van den Oord A., 2013, ADV NEURAL INFORM PR, P2643, DOI [DOI 10.1109/MMUL.2011.34.VAN, 10.5555/2999792.2999907]
   Van Hasselt Hado, 2018, arXiv
   Vincent Pascal, 2008, P 25 INT C MACHINE L, DOI DOI 10.1145/1390156.1390294
   Vozalis M., 2006, Web Intelligence and Agent Systems, V4, P117
   Vozalis M, 2004, COLLABORATIVE FILTER
   Wang H, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1235, DOI 10.1145/2783258.2783273
   Wei KN, 2007, I C SERV SYST SERV M, P734
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Wu C, 2018, ARXIV
   Wu Y, 2016, PROCEEDINGS OF THE NINTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'16), P153, DOI 10.1145/2835776.2835837
   Xue HJ, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3203
   Zhang SA, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3285029
   Zhao X, 2018, ABS180206501 CORR2
   Zhao XY, 2018, 12TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS), P95, DOI 10.1145/3240323.3240374
   Zheng GJ, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P167, DOI 10.1145/3178876.3185994
   Zou LX, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P749, DOI 10.1145/3397271.3401181
   Zou LX, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P816, DOI 10.1145/3336191.3371801
NR 53
TC 0
Z9 0
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20079
EP 20100
DI 10.1007/s11042-022-14231-x
EA DEC 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000899521900001
DA 2024-07-18
ER

PT J
AU Ravi, V
   Chaganti, R
AF Ravi, Vinayakumar
   Chaganti, Rajasekhar
TI EfficientNet deep learning meta-classifier approach for image-based
   android malware detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cybersecurity; Cybercrime; Android; Malware; Deep learning; Transfer
   learning; Feature fusion; Meta-classifier
AB A survey of literature shows that transforming the application files into images and employing deep learning-based models for image classification has been considered as one of the significant directions for malware detection and classification. Mainly, convolutional neural networks (CNN)-based models are successfully employed for Android malware detection and classification. This is mainly due to the reason that this type of malware detection and classification approach is platform independent and has the capability to detect metamorphic and polymorphic malware. The Image-based Android malware detection is resilient to both unpacked and packed malware. Following, this work employs various 26 CNN-based pretrained models and the detailed investigation and analysis of experiments are shown on the Image-based Android malware dataset. Each of these models have the capability to extract its own optimal features and these features are distinct to each other. The penultimate layer features of best performed CNN-based pretrained models are extracted and dimensionality of the features were reduced using kernel principal component analysis (KPCA). The reduced features were fused together and passed into a meta-classifier or stacked classifier for classification. This classifier has two levels; in the first level support vector machine (SVM) and random forest (RForest) machine learning classifier were included for prediction and logistic regression in the second level for classification. The four combinations of fused models are DenseNet, ResNet, InceptionResNet, and EfficientNet. EfficientNet-based fused models showed better performances compared to other fused models and non-fused CNN based pretrained models. Moreover, the EfficientNet-based fused models outperformed the existing approaches for Android malware detection. All the model performances were shown on two different testing datasets and the proposed model has shown the similar performances on both the testing datasets with attaining better performances during training and testing. This indicates that the proposed model is more generalizable, robust, and it can be used as tool that can be deployed in any application play store.
C1 [Ravi, Vinayakumar] Prince Mohammad Bin Fahd Univ, Ctr Artificial Intelligence, Khobar, Saudi Arabia.
   [Chaganti, Rajasekhar] Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX 78249 USA.
C3 Prince Mohammad Bin Fahd University; University of Texas System;
   University of Texas at San Antonio (UTSA)
RP Ravi, V (corresponding author), Prince Mohammad Bin Fahd Univ, Ctr Artificial Intelligence, Khobar, Saudi Arabia.
EM vravi@pmu.edu.sa; Raj.chaganti2@gmail.com
RI Ravi, Vinayakumar/L-4202-2018; Chaganti, Rajasekhar/AAE-3643-2020
OI Chaganti, Rajasekhar/0000-0001-5341-6729
CR Android Malware, 2021, VOL STAT
   Arslan RS, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.7180
   Awotunde JB, 2021, COMM COM INF SC, V1455, P319, DOI 10.1007/978-3-030-89654-6_23
   Bakour K, 2021, NEURAL COMPUT APPL, V33, P11499, DOI 10.1007/s00521-021-05816-y
   Bakour K, 2021, NEURAL COMPUT APPL, V33, P3133, DOI 10.1007/s00521-020-05195-w
   Chen HJ, 2018, PROCEEDINGS OF 2018 IEEE 4TH INFORMATION TECHNOLOGY AND MECHATRONICS ENGINEERING CONFERENCE (ITOEC 2018), P1358, DOI 10.1109/ITOEC.2018.8740537
   Dai YS, 2018, DIGIT INVEST, V27, P30, DOI 10.1016/j.diin.2018.09.006
   Darus FM, 2018, PROCEEDINGS OF THE 2018 CYBER RESILIENCE CONFERENCE (CRC)
   Darus FM, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON INTERNET OF THINGS AND INTELLIGENCE SYSTEM (IOTAIS), P118, DOI [10.1109/IoTaIS47347.2019.8980412, 10.1109/iotais47347.2019.8980412]
   de Oliveira A., 2020, CHIMERA ANDROID MALW, P1, DOI DOI 10.36227/TECHRXIV.13359767.V1
   Ding YX, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02196-4
   Ding YX, 2018, LECT NOTES COMPUT SC, V10971, P164, DOI 10.1007/978-3-319-94307-7_13
   Galov N, 2021, 21 EXCITING ANDROID
   Guerra-Manzanares A, 2022, COMPUT SECUR
   Guerra-Manzanares A, 2022, MACH LEARN APPL, V9, DOI 10.1016/j.mlwa.2022.100357
   Hsien-De Huang T, 2018, IEEE INT CONF BIG DA, P2633, DOI 10.1109/BigData.2018.8622324
   Huang WQ, 2018, AIP CONF PROC, V1967, DOI 10.1063/1.5038987
   Jerbi M, 2022, COMPUT SECUR, V121, DOI 10.1016/j.cose.2022.102825
   Jung J, 2018, PROCEEDINGS OF THE 2018 CONFERENCE ON RESEARCH IN ADAPTIVE AND CONVERGENT SYSTEMS (RACS 2018), P149, DOI 10.1145/3264746.3264780
   Kumar Ajit., 2016, 2016 10th international conference on intelligent systems and control (ISCO), P1, DOI DOI 10.1109/ISCO.2016.7726949
   Kumar TA, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11060904
   Lachtar N, 2020, IEEE EMBEDDED SYST L
   Lakshmanan R., 2021, NEW ANDROID MALWARE
   Lekssays A, 2020, ICSOFT: PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON SOFTWARE TECHNOLOGIES, P606, DOI 10.5220/0009822906060614
   Malware, 2021, STATISTICS
   Mercaldo F, 2020, J COMPUT VIROL HACKI, V16, P157, DOI 10.1007/s11416-019-00346-7
   Muzaffar A, 2022, COMPUT SECUR, V121, DOI 10.1016/j.cose.2022.102833
   Naeem H, 2019, KSII T INTERNET INF, V13, P3756, DOI 10.3837/tiis.2019.07.023
   Peng He, 2020, IOP Conference Series: Earth and Environmental Science, V428, DOI 10.1088/1755-1315/428/1/012061
   Qiu JY, 2021, ACM COMPUT SURV, V53, DOI 10.1145/3417978
   Rafiq H, 2023, IEEE T IND INFORM, V19, P960, DOI 10.1109/TII.2022.3189046
   Rahali Abir, 2020, ICCNS 2020: 10th International Conference on Communication and Network Security, P70, DOI 10.1145/3442520.3442522
   Rehman ZU, 2018, COMPUT ELECTR ENG, V69, P828, DOI 10.1016/j.compeleceng.2017.11.028
   Ren ZR, 2020, AD HOC NETW, V101, DOI 10.1016/j.adhoc.2020.102098
   Selvaganapathy S., 2021, J CYBER SECUR MOBIL, P177, DOI DOI 10.13052/JCSM2245-1439.1017
   Shangyu Gu, 2020, ICCAI '20: Proceedings of the 2020 6th International Conference on Computing and Artificial Intelligence, P261, DOI 10.1145/3404555.3404574
   Singh J, 2021, IEEE ACCESS, V9, P90102, DOI 10.1109/ACCESS.2021.3090998
   Singh J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20247013
   Su X, 2016, IEEE TRUST, P244, DOI [10.1109/TrustCom.2016.69, 10.1109/TrustCom.2016.0070]
   Tan M., 2019, arXiv
   Ünver HM, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-3132-2
   Venkatraman S, 2019, J INF SECUR APPL, V47, P377, DOI 10.1016/j.jisa.2019.06.006
   Vinayakumar R, 2019, IEEE ACCESS, V7, P46717, DOI 10.1109/ACCESS.2019.2906934
   Vinayakumar R, 2018, J INTELL FUZZY SYST, V34, P1277, DOI 10.3233/JIFS-169424
   Vinayakumar R, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1677, DOI 10.1109/ICACCI.2017.8126084
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Yang MZ, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND BIG DATA ANALYSIS (ICCCBDA 2017), P344, DOI 10.1109/ICCCBDA.2017.7951936
   Yang S, 2019, 34TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING (ASE 2019), P1259, DOI 10.1109/ASE.2019.00155
   Yen YS, 2019, MICROELECTRON RELIAB, V93, P109, DOI 10.1016/j.microrel.2019.01.007
   Yumlembam R, 2023, IEEE INTERNET THINGS, V10, P8432, DOI 10.1109/JIOT.2022.3188583
   Zhang H, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8882295
   Zhang WH, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13071107
   Zhao JW, 2021, IEEE COMMUN SURV TUT, V23, P1838, DOI 10.1109/COMST.2021.3086475
NR 53
TC 4
Z9 4
U1 10
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24891
EP 24917
DI 10.1007/s11042-022-14236-6
EA DEC 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000899122900003
DA 2024-07-18
ER

PT J
AU Latif, S
   Sabir, Z
   Raja, MAZ
   Altamirano, GC
   Nunez, RAS
   Gago, DO
   Sadat, R
   Ali, MR
AF Latif, Sohaib
   Sabir, Zulqurnain
   Raja, Muhammad Asif Zahoor
   Altamirano, Gilder Cieza
   Sandoval Nunez, Rafael Artidoro
   Oseda Gago, Dulio
   Sadat, R.
   Ali, Mohamed R.
TI IoT technology enabled stochastic computing paradigm for numerical
   simulation of heterogeneous mosquito model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fractional order; IoT; Mean square error; Artificial neural networks;
   Scaled conjugate gradient; Reference results
ID HIV-INFECTION MODEL; ALGORITHM; DESIGN; SYSTEM
AB In this communication, a fractional order design and numerical form of the solutions are presented for numerical simulations of heterogeneous mosquito model. The use of the fractional order derivatives is exploited to observe more accurate and exhaustive performances of the numerical simulation of the model. The novel design of the fractional order heterogeneous mosquito differential system is analyzed with stochastic solver based on the internet of things (IoT) technologies, represented with four categories i.e., normal individuals, people with reflex behavior, panic behavior and controlled behavior based differential system. The solutions of the novel design of the fractional order system are presented by using the stochastic paradigm of artificial neural network (ANN) procedures along with the Scaled Conjugate Gradient (SCG), i.e., ANN-SCG, for learning of weights. In ANN-SCG implementation, the data statistics are picked as 78% for training, 11% for both authorization and testing samples to approximate the solutions. The accuracy of the ANN-SCG technique is seen by correlation of the determined outcomes and the information base on Adams-Bashforth-Moulton method based standard solutions. To achieve the capacity, legitimacy, consistent quality, fitness, and accuracy of the ANN-SCG strategy, the reproductions-based error histograms (EHs), MSE, regression, and state transitions (STs) are used for extensive experimentations.
C1 [Latif, Sohaib] Anhui Univ Sci & Technol, Sch Math & Big Data, Huainan 232001, Anhui, Peoples R China.
   [Sabir, Zulqurnain] Hazara Univ, Dept Math & Stat, Mansehra, Pakistan.
   [Sabir, Zulqurnain] Lebanese Amer Univ, Dept Comp Sci & Math, Beirut, Lebanon.
   [Raja, Muhammad Asif Zahoor] Natl Yunlin Univ Sci & Technol, Future Technol Res Ctr, 123 Univ Rd,Sect 3, Douliouyunlin 64002, Taiwan.
   [Altamirano, Gilder Cieza; Sandoval Nunez, Rafael Artidoro] Univ Nacl Autonoma Chota, Chota, Peru.
   [Oseda Gago, Dulio] Univ Nacl Mayor San Marcos, Lima, Peru.
   [Sadat, R.] Zagazig Univ, Zagazig Fac Engn, Dept Math, Zagazig, Egypt.
   [Ali, Mohamed R.] Future Univ Egypt, Fac Engn & Technol, New Cairo 11835, Egypt.
   [Ali, Mohamed R.] Benha Fac Engn, Basic Engn Sci Dept, Banha, Egypt.
C3 Anhui University of Science & Technology; Hazara University; Lebanese
   American University; National Yunlin University Science & Technology;
   Universidad Nacional Mayor de San Marcos; Egyptian Knowledge Bank (EKB);
   Zagazig University; Egyptian Knowledge Bank (EKB); Future University in
   Egypt; Egyptian Knowledge Bank (EKB); Benha University
RP Ali, MR (corresponding author), Future Univ Egypt, Fac Engn & Technol, New Cairo 11835, Egypt.; Ali, MR (corresponding author), Benha Fac Engn, Basic Engn Sci Dept, Banha, Egypt.
EM sohaib.latif@aust.edu.cn; zulqurnain_maths@hu.edu.pk;
   rajamaz@yuntech.edu.tw; gciezaa@unach.edu.pe; asandoval@unach.edu.pe;
   dosedag@unmsm.edu.pe; mohamedseda@bhit.bu.edu.eg
RI Latif, Dr Sohaib/AAL-2885-2020; Núñez, Rafaél Artidoro
   Sandoval/AAX-9514-2020; Raja, Muhammad Asif Zahoor/D-7325-2013; Ali,
   Mohamed/B-8932-2019
OI Latif, Dr Sohaib/0000-0002-0690-2326; Núñez, Rafaél Artidoro
   Sandoval/0000-0003-3930-2332; Raja, Muhammad Asif
   Zahoor/0000-0001-9953-822X; sabir, zulqurnain/0000-0001-7466-6233; CIEZA
   ALTAMIRANO, GILDER/0000-0002-7936-1495; Ali, Mohamed/0000-0002-0795-0709
FU Program Management Unit for Human Resources & Institutional Development,
   Research and Innovation
FX The first author was supported by the Program Management Unit for Human
   Resources & Institutional Development, Research and Innovation.
CR Abdelkawy MA, 2020, OPEN PHYS, V18, P770, DOI 10.1515/phys-2020-0185
   Afreen H, 2021, IEEE ACCESS, V9, P38236, DOI 10.1109/ACCESS.2021.3056672
   Akkilic AN, 2022, EUR PHYS J PLUS, V137, DOI 10.1140/epjp/s13360-022-02525-w
   AL Nuwairan M, 2022, AIP ADV, V12, DOI 10.1063/5.0085737
   Bukhari AH, 2020, IEEE ACCESS, V8, P71326, DOI 10.1109/ACCESS.2020.2985763
   Cheng YJ, 2020, MULTIMED TOOLS APPL, V79, P30235, DOI 10.1007/s11042-020-09382-8
   Dubey K, 2022, J GRID COMPUT, V20, DOI 10.1007/s10723-021-09591-x
   Durur H, 2020, APPL MATH NONLIN SCI, V5, P447, DOI 10.2478/AMNS.2020.1.00042
   Goel S.S., 2021, J. Reliab. Intell. Environ, DOI 10.1007/s40860-020-00127-w
   Guerrero-Sánchez Y, 2021, DISCRETE CONT DYN-S, V14, P3611, DOI 10.3934/dcdss.2020431
   Hwang HK, 2021, IEEE ACCESS, V9, P13440, DOI 10.1109/ACCESS.2020.3048048
   Ilhan E, 2020, APPL MATH NONLIN SCI, V5, P171, DOI 10.2478/AMNS.2020.1.00016
   Ilyas H, 2021, CHINESE J PHYS, V72, P386, DOI 10.1016/j.cjph.2021.05.012
   Ilyas H, 2021, INT COMMUN HEAT MASS, V123, DOI 10.1016/j.icheatmasstransfer.2021.105196
   Javeed A, 2020, MULTIMED TOOLS APPL, V79, P6649, DOI 10.1007/s11042-019-08393-4
   Junsawang P, 2022, IEEE ACCESS, V10, P31116, DOI 10.1109/ACCESS.2022.3159813
   Kiani AK, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13179537
   Kumar M, 2020, NEURAL COMPUT APPL, V32, P18285, DOI 10.1007/s00521-020-04955-y
   Li MW, 2022, NONLINEAR DYNAM, V107, P2447, DOI 10.1007/s11071-021-07139-y
   Li MW, 2021, NONLINEAR DYNAM, V103, P1167, DOI 10.1007/s11071-020-06111-6
   Malhotra P, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051809
   Mehmood A, 2020, NEURAL COMPUT APPL, V32, P7121, DOI 10.1007/s00521-019-04197-7
   Musanna F, 2019, MULTIMED TOOLS APPL, V78, P14867, DOI 10.1007/s11042-018-6827-2
   Naz S, 2021, EUR PHYS J PLUS, V136, DOI 10.1140/epjp/s13360-021-01382-3
   Sabir Z, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/3774123
   Sabir Z, 2022, INT J BIOMATH, V15, DOI 10.1142/S1793524522500127
   Sabir Z, 2022, INT J BIOMATH, V15, DOI 10.1142/S179352452250005X
   Sabir Z, 2022, INT J COMPUT INT SYS, V15, DOI 10.1007/s44196-021-00057-2
   Sabir Z, 2022, FRACTAL FRACT, V6, DOI 10.3390/fractalfract6010029
   Sabir Z, 2022, NEURAL COMPUT APPL, V34, P4193, DOI 10.1007/s00521-021-06452-2
   Sabir Z, 2021, CHAOS SOLITON FRACT, V152, DOI 10.1016/j.chaos.2021.111404
   Shoaib M, 2022, ARAB J SCI ENG, V47, P8211, DOI 10.1007/s13369-021-06202-5
   Ullah I, 2020, IEEE ACCESS, V8, P159371, DOI 10.1109/ACCESS.2020.3016277
   Umar M, 2021, RESULTS PHYS, V25, DOI 10.1016/j.rinp.2021.104235
   Umar M, 2021, MATH COMPUT SIMULAT, V188, P241, DOI 10.1016/j.matcom.2021.04.008
   Umar M, 2020, EUR PHYS J PLUS, V135, DOI 10.1140/epjp/s13360-020-00557-8
   Yoon S, 2020, IEEE T NETW SERV MAN, V17, P1653, DOI 10.1109/TNSM.2020.2987085
   Zhang ZC, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107297
NR 38
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18851
EP 18866
DI 10.1007/s11042-022-14270-4
EA DEC 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000894424400001
DA 2024-07-18
ER

PT J
AU Aishwarya, N
   Praveena, NG
   Priyanka, S
   Pramod, J
AF Aishwarya, N.
   Praveena, N. G.
   Priyanka, S.
   Pramod, J.
TI Smart farming for detection and identification of tomato plant diseases
   using light weight deep neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Plant disease; Deep learning; Convolution neural network; Smart farming
AB Tomato occupies a protuberant place in every kitchen in various forms and this is one of the finest crops cultivated worldwide. However, the production of tomato crops is adversely affected due to different type of diseases. On one hand, timely recognition and classification of diseases is very essential for maintaining both the quality and quantity of tomatoes. And on the other hand, the combination of rising worldwide smartphone adoption and recent deep learning advancements has paved the way for smartphone-assisted disease detection. Hence, to accomplish the above-mentioned perspectives, a custom CNN model (CCNN) is designed to classify various tomato plant diseases. In contrast to state-of-the-art architectures such as Alex net and VGG-16, the proposed CCNN model has three convolution layers followed by three fully connected layers which reduces the processing time and the computational power while achieving a greater accuracy in classification of various diseases. Also, the number of hyper parameters of the proposed model is significantly decreased as compared with the existing models. The competency of the proposed model is experimentally verified with 10 classes of tomato leaves both qualitatively and quantitatively. The results exhibit that the Custom CNN model attains competitive accuracy as compared with the conventional models with lesser computational cost. Further, the deployment of the proposed CCNN model in the mobile based system paves way for widespread global smartphone-assisted crop disease diagnosis.
C1 [Aishwarya, N.; Priyanka, S.; Pramod, J.] Amrita Vishwa Vidyapeetham, Dept ECE, Amrita Sch Engn, Chennai, India.
   [Praveena, N. G.] Anna Univ, K Coll Engn & Technol, Dept ECE, Chennai, India.
C3 Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Chennai; Anna
   University; Anna University Chennai
RP Aishwarya, N (corresponding author), Amrita Vishwa Vidyapeetham, Dept ECE, Amrita Sch Engn, Chennai, India.
EM aishwarya8914@gmail.com
RI N G, Praveena/AAH-2279-2020; N, AISHWARYA/HGD-4106-2022
OI N G, Praveena/0000-0003-1410-0048; N, AISHWARYA/0000-0003-4054-6801
CR Agarwal M, 2020, PROCEDIA COMPUT SCI, V167, P293, DOI 10.1016/j.procs.2020.03.225
   Ahmed AA, 2021, AGRIENGINEERING, V3, P478, DOI 10.3390/agriengineering3030032
   Aishwarya N, 2021, FUTURISTIC COMMUNICA, V792, P199
   Barbedo JGA, 2016, BIOSYST ENG, V144, P52, DOI 10.1016/j.biosystemseng.2016.01.017
   Atila Ü, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2020.101182
   Bir Paarth, 2020, 2020 IEEE International Conference on Computing, Power and Communication Technologies (GUCON), P34, DOI 10.1109/GUCON48875.2020.9231174
   Brahimi M, 2017, APPL ARTIF INTELL, V31, P299, DOI 10.1080/08839514.2017.1315516
   Chowdhury MEH, 2021, AGRIENGINEERING, V3, P294, DOI 10.3390/agriengineering3020020
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Elhassouny A., 2019, INT C COMP SCI REN E, P1, DOI [DOI 10.1109/ICCSRE.2019.8807737, 10.1109/ICCSRE.2019.8807737]
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Habiba Sultana Umme, 2021, Proceedings of 2021 International Conference on Information and Communication Technology for Sustainable Development (ICICT4SD), P82, DOI 10.1109/ICICT4SD50815.2021.9396883
   Hernandez-Rabadan Deny Lizbeth, 2014, ScientificWorldJournal, V2014, P214674, DOI 10.1155/2014/214674
   Kaur Manveet, 2019, 2019 URSI Asia-Pacific Radio Science Conference (AP-RASC), DOI 10.23919/URSIAP-RASC.2019.8738576
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Luna-Benoso B., 2020, INT J COMPUT OPTIM, V7, P35
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Mokhtar U, 2015, ADV INTELL SYST, V323, P641, DOI 10.1007/978-3-319-11310-4_55
   Mokhtar U, 2015, ADV INTELL SYST, V339, P771, DOI 10.1007/978-81-322-2250-7_77
   Moussafir M., 2022, PLANT, V475, P1
   Rangarajan AK, 2018, PROCEDIA COMPUT SCI, V133, P1040, DOI 10.1016/j.procs.2018.07.070
   Raza SEA, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0123262
   Reddy JN, 2019, 2019 IEEE INT C ELEC
   Sembiring A, 2020, J PHYS C SERIES, V1845
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wang QM, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/9142753
   Yang X., 2017, Eur. J. BioMed. Res., V3, P6, DOI DOI 10.18088/EJBMR.3.1.2017.PP6-9
   Zhang KK, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/6710865
NR 28
TC 9
Z9 9
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18799
EP 18810
DI 10.1007/s11042-022-14272-2
EA NOV 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000890126700001
DA 2024-07-18
ER

PT J
AU Madain, A
AF Madain, Alia
TI Clustering paper shreds of different sizes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Clustering; Shredded paper reconstruction; Strip-cut shreds; Cross-cut
   shreds; Micro-cut shreds; GLCM; Invariant moment; SFTA algorithm; Color
   moments; K-means
ID RECONSTRUCTION; DOCUMENTS; ALGORITHM
AB Although paper shredding is widely used to prevent confidential papers from being misused, still it cannot be considered a convenient process. The size of paper shreds became smaller and smaller, as new methods of shredded paper reassembly and reconstruction are evolving. This paper focuses on clustering, which is a possible phase in the assembly process. This work considers real strip-cut shreds, in addition to images shredded by a simulator in one direction to make strip-cut shreds of different sizes, from wide to narrow shreds, and images shredded in two directions, possibly reflecting cross-cut and micro-cut shreds. K-means is used to cluster shreds, the features tested are gray-level ranges, and the well-known gray-level co-occurrence matrix, invariant moments, segmentation-based fractal texture analysis algorithm, and color moments. The number of shreds grouped in the same cluster with originally adjacent neighbors is used to indicate clustering effectiveness, in addition to the overall accuracy of strip-cut shreds clustering. When the number of clusters is 5, and the k-means experiments run 100 times for 38 images, the overall accuracy of gray-level ranges in simulated strip-cut shreds is 84.87, 89.27, and 93.5 percent in the three different sizes tested, also in cross-cut and micro-cut shreds, gray-level ranges achieve a relatively high number of shreds with 3 and 4 originally adjacent neighbors found in the same cluster.
C1 [Madain, Alia] Jordan Univ Sci & Technol, Dept Comp Sci, Irbid 22110, Jordan.
C3 Jordan University of Science & Technology
RP Madain, A (corresponding author), Jordan Univ Sci & Technol, Dept Comp Sci, Irbid 22110, Jordan.
EM asmadain@just.edu.jo
CR Alhaidari FA, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCIS), P541, DOI 10.1109/iccisci.2019.8716432
   Atallah AS, 2015, INT CONF COMM SYST, P345, DOI 10.1109/CSNT.2015.69
   Biswas A, 2005, IEEE IMAGE PROC, P3133
   Butler P, 2012, IEEE CONF VIS ANAL, P113, DOI 10.1109/VAST.2012.6400560
   Chen GH, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P1034, DOI 10.1109/ICIVC.2017.7984711
   Chen JH, 2019, EXPERT SYST APPL, V127, P35, DOI 10.1016/j.eswa.2019.02.039
   Chen JH, 2018, MULTIMED TOOLS APPL, V77, P19281, DOI 10.1007/s11042-017-5389-z
   Costa A. F., 2012, 2012 XXV SIBGRAPI - Conference on Graphics, Patterns and Images (SIBGRAPI 2012), P39, DOI 10.1109/SIBGRAPI.2012.15
   Deever A, 2012, IEEE IMAGE PROC, P233, DOI 10.1109/ICIP.2012.6466838
   Gonzalez RC, 2009, DIGITAL IMAGE PROCES, DOI 10.1117/1.3115362
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hong HC, 2018, IEEE ACCESS, V6, P67762, DOI 10.1109/ACCESS.2018.2877697
   Hongrong Yang, 2021, Journal of Physics: Conference Series, V1827, DOI 10.1088/1742-6596/1827/1/012063
   Htet ZW, 2018, PROCEEDINGS OF THE 2018 IEEE CONFERENCE OF RUSSIAN YOUNG RESEARCHERS IN ELECTRICAL AND ELECTRONIC ENGINEERING (EICONRUS), P1844, DOI 10.1109/EIConRus.2018.8317466
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Justino E, 2006, FORENSIC SCI INT, V160, P140, DOI 10.1016/j.forsciint.2005.09.001
   Liang YQ, 2020, IEEE T MULTIMEDIA, V22, P1168, DOI 10.1109/TMM.2019.2941777
   Liao PS, 2001, J INF SCI ENG, V17, P713
   Lin HY, 2012, EXPERT SYST APPL, V39, P3324, DOI 10.1016/j.eswa.2011.09.019
   Lin HY, 2009, IMAGE BASED TECHNIQU, DOI [10.1007/978-3-540-92957-4_14, DOI 10.1007/978-3-540-92957-4_14]
   Liu HR, 2011, IEEE T MULTIMEDIA, V13, P1154, DOI 10.1109/TMM.2011.2160845
   Ou X, 2014, INT J PHARMACEUT, V460, P28, DOI 10.1016/j.ijpharm.2013.10.024
   Paixao TM, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107535
   Paixao TM, 2019, IEEE T INF FOREN SEC, V14, P1744, DOI 10.1109/TIFS.2018.2885253
   Paixao TM, 2018, SIBGRAPI, P87, DOI 10.1109/SIBGRAPI.2018.00018
   Paixao Thiago M., 2020, P IEEE CVF C COMP VI, P14343
   Panggabean Teamsar Muliadi, 2020, ICAIP 2020: Proceedings of 2020 4th International Conference on Advances in Image Processing, P143, DOI 10.1145/3441250.3441251
   Patel B., 2015, INT J SCI RES IJSR, V4, P737, DOI [10.21275/v4i12.NOV152063, DOI 10.21275/V4I12.NOV152063]
   Phienthrakul T, 2015, 2015 11TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P623, DOI 10.1109/SITIS.2015.13
   Saboia P, 2014, ASSESSING CROSS CUT, DOI [10.1007/978-3-319-12568-8_34, DOI 10.1007/978-3-319-12568-8_34]
   Schauer C, 2010, MEMETIC ALGORITHM RE, DOI [10.1007/978-3-642-16054-7_8, DOI 10.1007/978-3-642-16054-7_8]
   Shuxuan Guo, 2015, Image and Graphics. 8th International Conference, ICIG 2015. Proceedings: LNCS 9217, P447, DOI 10.1007/978-3-319-21978-3_39
   Sleit A, 2013, TELECOMMUN SYST, V52, P1491, DOI 10.1007/s11235-011-9626-x
   Ukovich A, 2004, PROCEEDINGS OF THE FOURTH IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, P334, DOI 10.1109/ISSPIT.2004.1433788
   Ukovich A., 2005, Proc. - Int. Conf. Image Process. ICIP, V3, P93, DOI [10.1109/ICIP.2005.1530336, DOI 10.1109/ICIP.2005.1530336]
   Ukovich A, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2898551
   Wang Y, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P12, DOI 10.1109/CIS.2014.92
   Wang YQ, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2019), P727, DOI [10.1109/SIPROCESS.2019.8868511, 10.1109/siprocess.2019.8868511]
   Xing N, 2017, PROCEDIA COMPUT SCI, V116, P151, DOI 10.1016/j.procs.2017.10.060
   Xing N, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7090951
   Xing N, 2017, MULTIMED TOOLS APPL, V76, P12871, DOI 10.1007/s11042-016-3685-7
   Zhao B, 2014, PROC INT C TOOLS ART, P1016, DOI 10.1109/ICTAI.2014.154
NR 42
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19441
EP 19461
DI 10.1007/s11042-022-13835-7
EA NOV 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000889417700006
DA 2024-07-18
ER

PT J
AU Zhang, H
   Sun, SH
   Hu, LT
   Meng, FL
AF Zhang, Hua
   Sun, Shihuan
   Hu, Liting
   Meng, Fanli
TI A novel data hiding scheme based on improved diamond encoding in IWT
   domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Improved diamond encoding; Integer wavelet transform; Human
   visual system; Mixed base sequence
ID STEGANOGRAPHIC METHOD; EMBEDDING CAPACITY; ALGORITHM; LSB; PVD; SECURE;
   SYSTEM; BIT
AB DE is applied into discrete wavelet transform (DWT) data hiding method for lower distortion. However, it does not consider human vision sensitivity and cannot achieve accurate extraction of secret bits. Therefore, a novel data hiding scheme based on improved diamond encoding (IDE) and integer wavelet transform (IWT) is proposed in this paper. Because the human eyes tolerate more changes in edge and texture areas than in smooth areas, the proposed method exploits coefficient value sum/difference to select the base for digits to be embedded for each coefficient pair. With the help of a mixed base sequence, secret messages are re-expressed as secret digits. Moreover, an improved diamond encoding with the novel extraction function is developed to conceal secret digits into the cover image to reduce the distortion. Experimental results demonstrate that the proposed scheme outperforms state-of-the-art schemes in terms of embedding capacity and image quality.
C1 [Zhang, Hua; Sun, Shihuan; Hu, Liting; Meng, Fanli] Northeastern Univ, Coll Informat Sci & Engn, Shenyang, Peoples R China.
C3 Northeastern University - China
RP Zhang, H; Meng, FL (corresponding author), Northeastern Univ, Coll Informat Sci & Engn, Shenyang, Peoples R China.
EM zhanghua@ise.neu.edu.cn; mengfanli@ise.neu.edu.cn
OI Zhang, Hua/0000-0002-2731-2050; Sun, Shihuan/0000-0002-5861-3569
FU National Natural Science Foundation of China [62033002, 62071112];
   National Key R&D Program of China [2019YFB2006001]; Fundamental Research
   Funds for the Central Universities of China [N180408018]
FX This work was supported in part by the National Natural Science
   Foundation of China (62033002, 62071112), the National Key R&D Program
   of China (2019YFB2006001), and the Fundamental Research Funds for the
   Central Universities of China (N180408018).
CR Al-Dmour H, 2016, EXPERT SYST APPL, V46, P293, DOI 10.1016/j.eswa.2015.10.024
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Chan YK, 2009, J SYST SOFTWARE, V82, P411, DOI 10.1016/j.jss.2008.07.008
   Chao RM, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/658047
   Chen XF, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2020.102702
   Darabkh KA, 2017, INF TECHNOL CONTROL, V46, P16, DOI 10.5755/j01.itc.46.1.15253
   El Safy R. O., 2009, 2009 International Conference on Networking and Media Convergence (ICNM'09), P111, DOI 10.1109/ICNM.2009.4907200
   Elshazly E, 2018, J SYST ENG ELECTRON, V29, P639, DOI 10.21629/JSEE.2018.03.21
   Ghebleh M, 2014, COMMUN NONLINEAR SCI, V19, P1898, DOI 10.1016/j.cnsns.2013.10.014
   Hameed MA, 2018, MULTIMED TOOLS APPL, V77, P14705, DOI 10.1007/s11042-017-5056-4
   Hisham SI, 2017, PATTERN ANAL APPL, V20, P1129, DOI 10.1007/s10044-016-0552-0
   Hong W, 2012, IEEE T INF FOREN SEC, V7, P176, DOI 10.1109/TIFS.2011.2155062
   Houssein EH, 2016, ACSIS-ANN COMPUT SCI, V8, P641, DOI 10.15439/2016F521
   Hussain M, 2021, MULTIMED TOOLS APPL, V80, P20381, DOI 10.1007/s11042-021-10652-2
   Jung KH, 2018, J REAL-TIME IMAGE PR, V14, P127, DOI 10.1007/s11554-017-0719-y
   Kuo WC, 2016, INFORM PROCESS LETT, V116, P183, DOI 10.1016/j.ipl.2015.08.003
   Leng HS, 2021, DIGIT SIGNAL PROCESS, V113, DOI 10.1016/j.dsp.2021.103026
   Liao X, 2011, J VIS COMMUN IMAGE R, V22, P1, DOI 10.1016/j.jvcir.2010.08.007
   Liu HH, 2019, MULTIMED TOOLS APPL, V78, P12157, DOI 10.1007/s11042-018-6766-y
   Liu YX, 2019, SIGNAL PROCESS-IMAGE, V78, P216, DOI 10.1016/j.image.2019.07.013
   Mandal Bishwas, 2019, 2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P459, DOI 10.1109/ICOEI.2019.8862579
   Miri A, 2018, MULTIMED TOOLS APPL, V77, P13133, DOI 10.1007/s11042-017-4935-z
   Moon SK, 2019, MULTIMED TOOLS APPL, V78, P22045, DOI 10.1007/s11042-019-7503-x
   Redely H. S. Manjunatha, 2011, International Journal of Advanced Networking and Applications, V3, P1203
   Sahu AK, 2019, INT J ELECTRON SECUR, V11, P458, DOI 10.1504/IJESDF.2019.102567
   Setiadi DIM, 2021, MULTIMED TOOLS APPL, V80, P8423, DOI 10.1007/s11042-020-10035-z
   Seyedi S.R, 2011, P 19 IRANIAN CMIFERE, P1
   Singh S, 2012, ICPCES 2012 2012 2 I, P9, DOI [10.1109/ICPCES.2012.6508088, DOI 10.1109/ICPCES.2012.6508088]
   Swain G, 2016, PROCEDIA COMPUT SCI, V85, P39, DOI 10.1016/j.procs.2016.05.174
   Thanekar SA., 2013, IEEE INT C COMPUT IN, V2013, P2, DOI [10.1109/ICCIC.2013.6724139, DOI 10.1109/ICCIC.2013.6724139]
   Xiong LZ, 2020, SIGNAL PROCESS, V173, DOI 10.1016/j.sigpro.2020.107571
   Yang C., 2016, ASIAN J COMPUT INF S, V04, P69
   Zhang H, 2019, SIGNAL PROCESS-IMAGE, V78, P331, DOI 10.1016/j.image.2019.07.019
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   Zhang XP, 2005, IEEE SIGNAL PROC LET, V12, P67, DOI 10.1109/LSP.2004.838214
NR 35
TC 1
Z9 1
U1 4
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18727
EP 18745
DI 10.1007/s11042-022-14235-7
EA NOV 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000888710500001
DA 2024-07-18
ER

PT J
AU Liu, XK
   Sun, KH
   Wang, HH
AF Liu, Xinkang
   Sun, Kehui
   Wang, Huihai
TI A novel image encryption scheme based on 2D SILM and improved
   permutation-confusion-diffusion operations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos; 2D SILM; Image encryption; SHA-512; DNA coding
ID ALGORITHM; CHAOS; MAP; CIRCUIT
AB Security issues of digital images have rapidly become a frontier research focus in the past decades. When a chaotic system is applied to encrypt image, it usually requires large parameter space, high ergodicity and easy implementation. In this paper, taking Sine and ICMIC map as seed maps, a novel 2D hyperchaotic Logistic map (2D-SILM) is designed based on the 2D parameter modulation model (PMM). Its dynamics are analyzed by means of attractor diagrams, Lyapunov exponent spectrum (LEs) and complexity diagrams. The results along with NIST SP-800 test prove the feasibility of 2D-SILM. Based on 2D-SILM and DNA coding, a reliable image encryption scheme is proposed with two-round improved permutation-confusion-diffusion operations. SHA-512 function is introduced in the generation of the secret key. After applying the effective permutation process called chaotic grouping shuffle (CGS) on pixels position, DNA sequences procedures varied from different rounds are used to confuse the image pixels value. Finally, a novel diffusion method containing row and column operation is designed. Simulation results of some indexes validate the security and efficiency of the proposed algorithm. It also shows better resistance to typical attacks.
C1 [Liu, Xinkang; Sun, Kehui; Wang, Huihai] Cent South Univ, Sch Phys & Elect, YueLu St, Changsha 410083, Hunan, Peoples R China.
C3 Central South University
RP Sun, KH (corresponding author), Cent South Univ, Sch Phys & Elect, YueLu St, Changsha 410083, Hunan, Peoples R China.
EM 1526650801@qq.com; kehui@csu.edu.cn; wanghuihaicsu@csu.edu.cn
OI sun, kehui/0000-0003-2503-9262
FU National Natural Science Foundation of China [62071496, 61901530,
   62061008]
FX This work was supported by the National Natural Science Foundation of
   China (Nos. 62071496, 61901530, 62061008).
CR ADLEMAN LM, 1994, SCIENCE, V266, P1021, DOI 10.1126/science.7973651
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Chai XL, 2021, INFORM SCIENCES, V556, P305, DOI 10.1016/j.ins.2020.10.007
   Chai XL, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105837
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen L, 2022, J VIS COMMUN IMAGE R, V83, DOI 10.1016/j.jvcir.2021.103424
   Dong WL, 2021, CHAOS SOLITON FRACT, V153, DOI 10.1016/j.chaos.2021.111539
   Enayatifar R, 2019, OPT LASER ENG, V115, P131, DOI 10.1016/j.optlaseng.2018.11.017
   Fridrich J, 1997, IEEE SYS MAN CYBERN, P1105, DOI 10.1109/ICSMC.1997.638097
   Garrett D, 2003, IEEE T NEUR SYS REH, V11, P141, DOI 10.1109/TNSRE.2003.814441
   He PC, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6679288
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Huang W, 2021, IEEE ACCESS, V9, P41704, DOI 10.1109/ACCESS.2021.3065453
   Ibrahim S, 2021, INFORM SCIENCES, V558, P246, DOI 10.1016/j.ins.2021.01.014
   Kumar A, 2011, COMMUN NONLINEAR SCI, V16, P372, DOI 10.1016/j.cnsns.2010.04.010
   Li XH, 2022, SOFT COMPUT, V26, P511, DOI 10.1007/s00500-021-06500-y
   Liu S, 2022, IEEE MULTIMEDIA, V29, P74, DOI 10.1109/MMUL.2021.3114589
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Luo YL, 2019, SIGNAL PROCESS, V161, P227, DOI 10.1016/j.sigpro.2019.03.022
   Nardo LG, 2021, CHAOS, V31, DOI 10.1063/5.0061639
   Pareschi F, 2012, IEEE T INF FOREN SEC, V7, P491, DOI 10.1109/TIFS.2012.2185227
   Shevchenko II, 2014, PHYS LETT A, V378, P34, DOI 10.1016/j.physleta.2013.10.035
   Shrivastava M, 2021, NONLINEAR DYNAM, V106, P2679, DOI 10.1007/s11071-021-06923-0
   Tang ZJ, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/8694678
   Tang ZJ, 2016, OPT LASER ENG, V80, P1, DOI 10.1016/j.optlaseng.2015.12.004
   Tsafack N, 2020, INFORM SCIENCES, V515, P191, DOI 10.1016/j.ins.2019.10.070
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang XY, 2021, CHAOS SOLITON FRACT, V143, DOI 10.1016/j.chaos.2020.110582
   Wang XY, 2019, OPT LASER TECHNOL, V119, DOI 10.1016/j.optlastec.2019.105581
   Wang XY, 2019, MULTIMED TOOLS APPL, V78, P6191, DOI 10.1007/s11042-018-6326-5
   Wang XY, 2015, NONLINEAR DYNAM, V79, P1141, DOI 10.1007/s11071-014-1729-y
   Wu XG, 2004, CHAOS SOLITON FRACT, V22, P359, DOI 10.1016/j.chaos.2004.02.008
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Wu Y, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.1.013014
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Xu QY, 2020, OPT LASER ENG, V134, DOI 10.1016/j.optlaseng.2020.106178
   Ye GD, 2021, NONLINEAR DYNAM, V104, P2807, DOI 10.1007/s11071-021-06422-2
   Ye GD, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107563
   Yu WQ, 2019, MULTIMED TOOLS APPL, V78, P20037, DOI 10.1007/s11042-018-7110-2
   Yuan F, 2019, CHAOS, V29, DOI 10.1063/1.5094936
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zhou S, 2020, CHAOS SOLITON FRACT, V141, DOI 10.1016/j.chaos.2020.110225
   Zhou WJ, 2022, OPT LASER ENG, V149, DOI 10.1016/j.optlaseng.2021.106782
   Zhu LY, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107629
   Zhu SQ, 2019, IEEE ACCESS, V7, P147106, DOI 10.1109/ACCESS.2019.2946208
NR 48
TC 4
Z9 4
U1 7
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23179
EP 23205
DI 10.1007/s11042-022-14133-y
EA NOV 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000884893600007
DA 2024-07-18
ER

PT J
AU Mishra, AK
   Choudhry, MS
   Kumar, M
AF Mishra, Amarendra Kumar
   Choudhry, Mahipal Singh
   Kumar, Manjeet
TI Underwater image enhancement using multiscale decomposition and gamma
   correction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater-image enhancement; Real-world underwater images; Retinex;
   Brightness adjustment; Gamma correction; Gradient-domain
ID COLOR; ALGORITHM; LIGHT
AB Underwater image enhancement has been attracting much attention due to its significance in marine engineering and aquatic robotics. Captured underwater images usually suffer from contrast degradation, low illumination, color cast, and noise. Many underwater image enhancement and restoration algorithms have been developed but are not able to solve all these problems. In this paper, a new single image retinex algorithm using gamma correction is proposed. Here the input image is decomposed into illumination and Reflectance. Illumination contains brightness variation, and Reflectance preserves the details information. Then Reflectance decomposed into multiple layers, which carried out gamma correction and contrast enhancement. Whereas illumination carried out brightness adjustment. Finally, these layers are combined to obtain an enhanced image. The proposed method produces high-quality enhanced images compared to the existing state-of-art method such as the Hue-preserving-based approach for underwater color image enhancement, Underwater image processing using a hybrid technique, and Underwater dark channel before using a guided image filter. The proposed method is tested for the underwater image enhancement benchmark data set and compared with the existing state-of-art method. Qualitative and quantitative results demonstrate the effectiveness of the proposed method in terms of seven parameters such as measure of enhancement (EME), discrete entropy (DE), peak signal to noise ratio (PSNR), Structure similarity index measure (SSIM), underwater color image quality evaluation (UCIQE), underwater image quality measure (UIQM), and patch-based contrast quality index (PCQI) for underwater images. Six parameters of the proposed method performed better compared to an existing method. The visual appearance of the output image of the proposed method has a very high quality.
C1 [Mishra, Amarendra Kumar; Choudhry, Mahipal Singh; Kumar, Manjeet] Delhi Technol Univ, Dept Elect & Commun Engn, Delhi, India.
C3 Delhi Technological University
RP Kumar, M (corresponding author), Delhi Technol Univ, Dept Elect & Commun Engn, Delhi, India.
EM Amarendra_2k18dce502@dtu.ac.in; msc_1976@yahoo.com;
   manjeetchhillar@gmail.com
RI KUMAR, MANJEET/K-1325-2015
OI KUMAR, MANJEET/0000-0001-6578-9741
CR Ancuti C., 2012, PROC CVPR IEEE, P81, DOI DOI 10.1109/CVPR.2012.6247661
   Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   AUTHOR, AUT RED CHANN UND IM
   Bailey GN, 2008, QUATERNARY SCI REV, V27, P2153, DOI 10.1016/j.quascirev.2008.08.012
   Bhandari AK, 2020, J AMB INTEL HUM COMP, V11, P1605, DOI 10.1007/s12652-019-01258-6
   Bhandari AK, 2014, EXPERT SYST APPL, V41, P3538, DOI 10.1016/j.eswa.2013.10.059
   Bhunia AK, 2019, IEEE WINT CONF APPL, P609, DOI 10.1109/WACV.2019.00070
   Cao KM, 2018, IEEE SW SYMP IMAG, P1, DOI 10.1109/SSIAI.2018.8470347
   Carlevaris-Bianco N., 2010, OCEANS, P1, DOI DOI 10.1109/OCEANS.2010.5664428
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Codruta AO, 2020, IEEE T IMAGE PROCESS, V29, P2653, DOI 10.1109/TIP.2019.2951304
   Dai CG, 2019, IEEE ACCESS, V7, P178685, DOI 10.1109/ACCESS.2019.2958078
   Deng G, 2011, IEEE T IMAGE PROCESS, V20, P1249, DOI 10.1109/TIP.2010.2092441
   Drews P, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P825, DOI 10.1109/ICCVW.2013.113
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Fu XY, 2017, I S INTELL SIG PROC, P789, DOI 10.1109/ISPACS.2017.8266583
   Fu XY, 2014, IEEE INT WORKSH MULT
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Fu XY, 2015, IEEE T IMAGE PROCESS, V24, P4965, DOI 10.1109/TIP.2015.2474701
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hitam Muhammad Suzuri, 2013, 2013 INT C COMPUTER
   Hooda A, 2022, MOL CRYST LIQ CRYST, V726, P90, DOI 10.1080/15421406.2021.1935162
   Hou G, 2018, HUE PRESERVING BASED
   Hu JK, 2021, IEEE SIGNAL PROC LET, V28, P2152, DOI 10.1109/LSP.2021.3099746
   Image S., 2012, United States Patent, Patent No. 2
   Iqbal K, 2010, IEEE INT C SYSTEMS M
   Krishnapriya TS, 2019, PROCEEDINGS OF 2019 1ST INTERNATIONAL CONFERENCE ON INNOVATIONS IN INFORMATION AND COMMUNICATION TECHNOLOGY (ICIICT 2019), DOI 10.1109/iciict1.2019.8741468
   Kumar Adesh, 2021, International Journal of Organizational and Collective Intelligence, V11, P1, DOI 10.4018/IJOCI.2021070105
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li XJ, 2020, IEEE ACCESS, V8, P197448, DOI 10.1109/ACCESS.2020.3034275
   Liang Z, 2021, NEUROCOMPUTING, V425, P160, DOI 10.1016/j.neucom.2020.03.091
   Mi Z., 2020, MULTIPURPOSE ORIENTE
   Pandey V, 2022, MATH BIOSCI ENG, V19, P7920, DOI 10.3934/mbe.2022370
   Parthasarathy S., 2012, NATL C COMMUNICATION, P1, DOI DOI 10.1109/NCC.2012.6176791
   Song W, 2018, LECT NOTES COMPUT SC, V11164, P678, DOI 10.1007/978-3-030-00776-8_62
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Wang SQ, 2015, IEEE SIGNAL PROC LET, V22, P2387, DOI 10.1109/LSP.2015.2487369
   Wang Y, 2019, IEEE ACCESS, V7, P140233, DOI 10.1109/ACCESS.2019.2932130
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei XY, 2021, MULTIMED TOOLS APPL, V80, P33747, DOI 10.1007/s11042-021-11230-2
   Xu B, 2022, IEEE ACCESS, V10, P36766, DOI 10.1109/ACCESS.2022.3163241
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
   Zhang S, 2017, NEUROCOMPUTING, V245, P1, DOI 10.1016/j.neucom.2017.03.029
   Zhao XW, 2015, OCEAN ENG, V94, P163, DOI 10.1016/j.oceaneng.2014.11.036
NR 49
TC 4
Z9 4
U1 5
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15715
EP 15733
DI 10.1007/s11042-022-14008-2
EA OCT 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000873458400003
DA 2024-07-18
ER

PT J
AU Jain, V
   Kashyap, KL
AF Jain, Vipin
   Kashyap, Kanchan Lata
TI Ensemble hybrid model for Hindi COVID-19 text classification with
   metaheuristic optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; Sentiment; Grey wolf; Optimization; Deep learning; Ensemble
   learning
AB A SARS-CoV-2 virus has spread around the globe since March 2020. Millions of people infected worldwide with coronavirus. People from every country expressed their sentiments about coronavirus on social media. The aim of this work is to determine the general public opinion of Indian Twitter users about coronavirus. The Hindi tweets posted about COVID-19 is used as input data for sentiment analysis. The natural language processing is applied on input data for feature extraction. Further, the optimal features are selected from the pre-processed data using the metaheuristic based Grey wolf optimization technique. Finally, a hybrid of convolution neural network(CNN) and a long short-term memory (LSTM) model pair is employed to categorize the sentiments as positive, negative, and neutral. The outcome of the proposed model is compared with other machine learning techniques, namely, Random Forest, Decision Tree, K-Nearest Neighbor, Naive Bayes, Support vector machine (SVM), CNN, LSTM, LSTM-CNN, and CNN-LSTM. The highest accuracy of 87.75%, 88.41%, 87.89%, 85.54%, 89.11%, 91.46%, 88.72%, 91.54%, and 92.34% is obtained by Random Forest, Decision Tree, K-Nearest Neighbor, Naive Bayes, SVM, CNN, LSTM, LSTM-CNN, and CNN-LSTM, respectively. The proposed ensemble hybrid model gives the highest 95.54%, 91.44%, 89.63%, and 90.87% classification accuracy, precision, recall, and F-score, respectively.
C1 [Jain, Vipin; Kashyap, Kanchan Lata] VIT Univ Bhopal, SCSE, Bhopal 466114, Madhya Pradesh, India.
C3 VIT Bhopal University
RP Jain, V (corresponding author), VIT Univ Bhopal, SCSE, Bhopal 466114, Madhya Pradesh, India.
EM vipin.jain2020@vitbhopal.ac.in; kanchan.k@vitbhopal.ac.in
RI JAIN, VIPIN/GYE-0014-2022
OI JAIN, VIPIN/0000-0002-0099-3933
CR Abualigah LM, 2017, J SUPERCOMPUT, V73, P4773, DOI 10.1007/s11227-017-2046-2
   Ahmad M., 2017, Int. J. Comput. Appl, V177, P25, DOI [DOI 10.5120/IJCA2017915758, 10.5120/ijca2017915758]
   Ambati L S, 2021, DESIGN PRINCIPLES MU
   Ambati LS., 2019, J MIDWEST ASS INF SY, V2021, P49, DOI DOI 10.17705/3JMWA.000065
   [Anonymous], 2013, P 11 WORKSHOP ASIAN
   [Anonymous], 2012, Int. J. Comput. Linguist. Appl
   Barkur G, 2020, ASIAN J PSYCHIATR, V51, DOI 10.1016/j.ajp.2020.102089
   Basile V, 2021, FUTURE INTERNET, V13, DOI 10.3390/fi13020029
   Bhattacharyya P, 2010, P 8 INT C NAT LANG P
   Bohat V K, 2018, 2018 C INFORM COMMUN, P1
   Chandra R, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0255615
   Chen L., 2020, arXiv
   [程玖玲 Cheng Jiuling], 2020, [中华结核和呼吸杂志, Chinese Journal of Tuberculosis and Respiratiory Diseases], V43, P327
   Chintalapudi N, 2021, INFECT DIS REP, V13, P329, DOI 10.3390/idr13020032
   Crawford K, 2009, CONTINUUM-J MEDIA CU, V23, P525, DOI 10.1080/10304310903003270
   El-Gayar OmarF., 2020, BIG DATAS POTENTIAL, P104, DOI DOI 10.4018/978-1-5225-9687-5.CH005
   Faris H, 2018, NEURAL COMPUT APPL, V30, P413, DOI 10.1007/s00521-017-3272-5
   Geron A, 2017, HANDS ON MACHINE LEA
   Gupta E, 2016, COGENT ENG, V3, DOI 10.1080/23311916.2016.1151612
   Gupta S, 2018, J EXP THEOR ARTIF IN, V30, P1051, DOI 10.1080/0952813X.2018.1513080
   Gupta V, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3450447
   Howe WT, 2018, ATL J COMMUN, V26, P180, DOI 10.1080/15456870.2018.1472093
   Jelodar H, 2020, IEEE J BIOMED HEALTH, V24, P2733, DOI 10.1109/JBHI.2020.3001216
   Ji X, 2016, STUD COMPUT INTELL, V639, P425, DOI 10.1007/978-3-319-30319-2_17
   Kaila R.P., 2020, International Journal of Advanced Research in Engineering and Technology (IJARET), V11, P128, DOI [10.34218/IJARET.11.3.2020.011, DOI 10.34218/IJARET.11.3.2020.011]
   Kaur C, 2020, EasyChair2516-2314
   Kim KS, 2014, COLL RES LIBR, V75, P442, DOI 10.5860/crl.75.4.442
   Kunchukuttan Anoop, 2020, The IndicNLP Library
   Li Q, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11120255
   Liu R, 2020, CLIN CHIM ACTA, V505, P172, DOI 10.1016/j.cca.2020.03.009
   Lwin May Oo, 2020, JMIR Public Health Surveill, V6, pe19447, DOI 10.2196/19447
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Nemes L, 2021, J INFORM TELECOMMUN, V5, P1, DOI 10.1080/24751839.2020.1790793
   Pan XC, 2020, MICROBES INFECT, V22, P86, DOI 10.1016/j.micinf.2020.02.004
   Raamkumar AS, 2020, J MED INTERNET RES, V22, DOI 10.2196/19334
   Ruangkanokmas P, 2016, P INT CONF INTELL, P9, DOI 10.1109/ISMS.2016.9
   Sai Ambati L, 2020, INFLUENCE DIGITAL DI
   Samuel J, 2020, INFORMATION, V11, DOI 10.3390/info11060314
   Sangaiah AK, 2019, CLUSTER COMPUT, V22, pS4535, DOI 10.1007/s10586-018-2084-4
   Singh P, 2020, INT J NATURAL LANGUA, V9
   Tan Y, 2017, ADV SWARM INTELLIGEN, V10385
   Tatbul N, 2018, ADV NEUR IN, V31
   World Health Organization, 2020, 145 WHO
   Zhao Y., 2020, PREPRINT
NR 44
TC 3
Z9 5
U1 4
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16839
EP 16859
DI 10.1007/s11042-022-13937-2
EA OCT 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000871318500005
PM 36313485
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Tyagi, A
   Singh, VP
   Gore, MM
AF Tyagi, Ashima
   Singh, Vibhav Prakash
   Gore, Manoj Madhava
TI Towards artificial intelligence in mental health: a comprehensive survey
   on the detection of schizophrenia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Schizophrenia; Neuroimaging; EEG; MRI; Machine learning; Deep learning
ID ADOLESCENT-ONSET SCHIZOPHRENIA; RESONANCE-IMAGING DATA; RANGE FUNCTIONAL
   CONNECTIVITY; COMPUTER-AIDED DIAGNOSIS; RESTING-STATE FMRI; 1ST-EPISODE
   SCHIZOPHRENIA; REGIONAL HOMOGENEITY; NEURAL-NETWORKS; WORKING-MEMORY;
   STRUCTURAL MRI
AB Computer Aided Diagnosis systems assist radiologists and doctors in the early diagnosis of mental disorders such as Alzheimer's, bipolar disorder, depression, autism, dementia, and schizophrenia using neuroimaging. Advancements in Artificial Intelligence (AI) have leveraged neuroimaging research to unfold numerous techniques for analyzing and interpreting thousands of scans in order to detect and classify various mental illnesses. Schizophrenia is a long-standing psychiatric disorder affecting millions of people worldwide. It causes hallucinations, delusions, and defacement in thinking, behavior, and cognition. Machine Learning and Deep Learning are the subsets of AI which are used for the detection and diagnosis of schizophrenia by gathering insights from different types of modalities. This paper work examines several methods of AI used for the automated diagnosis of schizophrenia using three primary modalities- EEG, structural MRI, and functional MRI. This paper explores different datasets available for schizophrenia along with the techniques and software used to pre-process the EEG and MR images. Further this paper focuses on the different feature extraction and selection techniques to retrieve an appropriate set of features along with the brief overview of machine learning & deep learning approaches. We have also reviewed numerous studies on the prognosis of schizophrenia and presented an exhaustive analysis of the machine learning and deep learning techniques used across EEG and MRI.
C1 [Tyagi, Ashima; Singh, Vibhav Prakash; Gore, Manoj Madhava] Motilal Nehru Natl Inst Technol Allahabad, Dept Comp Sci & Engn, Prayagraj, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Tyagi, A (corresponding author), Motilal Nehru Natl Inst Technol Allahabad, Dept Comp Sci & Engn, Prayagraj, India.
EM ashima.202Orcs01@mnnit.ac.in; vibhav@mnnit.ac.in; gore@mnnit.ac.in
OI Singh, Dr. Vibhav Prakash/0000-0002-6823-2524; Tyagi,
   Ashima/0000-0002-0754-9456
CR Acar E, 2017, IEEE INT SYMP CIRC S, P314
   Aine CJ, 2017, NEUROINFORMATICS, V15, P343, DOI 10.1007/s12021-017-9338-9
   Alam MA, 2018, J NEUROSCI METH, V309, P161, DOI 10.1016/j.jneumeth.2018.08.027
   Algunaid RF, 2018, BIOMED SIGNAL PROCES, V43, P289, DOI 10.1016/j.bspc.2018.02.018
   Ambrosen KS, 2020, TRANSL PSYCHIAT, V10, DOI 10.1038/s41398-020-00962-8
   American Psychiatric Association, 2020, What is schizophrenia?
   Andreou C, 2020, MOL PSYCHIATR, V25, P2773, DOI 10.1038/s41380-020-0679-7
   [Anonymous], RES TEAM WE STUDY NE
   [Anonymous], MIND RES NETW NEUR D
   [Anonymous], FREESURFER SOFTWARE
   [Anonymous], EEG HLTH ADOLESCENTS
   [Anonymous], FUNCTIONAL MRI FMRI
   Arbabshirani MR, 2017, NEUROIMAGE, V145, P137, DOI 10.1016/j.neuroimage.2016.02.079
   Ashburner JT, 2006, STAT MAPPING ANAL FU
   Aslan Z, 2022, PHYS ENG SCI MED, V45, P83, DOI 10.1007/s13246-021-01083-2
   Bae Y, 2018, J DIGIT IMAGING, V31, P252, DOI 10.1007/s10278-017-0020-4
   Bagherzadeh S, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105570
   Baker JT, 2014, JAMA PSYCHIAT, V71, P109, DOI 10.1001/jamapsychiatry.2013.3469
   Barros C, 2022, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.813460
   Behroozi M, 2012, BASIC CLIN NEUROSCI, V3, P71
   Behroozi M, 2011, BASIC CLIN NEUROSCI, V2, P67
   Bhandari A., 2020, Analytics Vidhya
   Bilder R., 2020, OpenNeuro
   Buettner R., 2019, 2019 IEEE INT C E HL, P1, DOI [DOI 10.1109/HEALTHCOM46333.2019.9009437, 10.1109/HealthCom46333.2019.9009429, DOI 10.1109/HEALTHCOM46333.2019.9009429]
   Cai XL, 2020, HUM BRAIN MAPP, V41, P172, DOI 10.1002/hbm.24797
   Calhas D, 2020, ARTIF INTELL MED, V105, DOI 10.1016/j.artmed.2020.101852
   Campese S, 2020, RECENT ADV BIG DATA, P48, DOI DOI 10.1007/978-3-030-16841-4_6
   Chang Q, 2021, IEEE T NEUR SYS REH, V29, P1784, DOI 10.1109/TNSRE.2021.3105669
   Chatterjee I, 2020, MULTIMED TOOLS APPL, V79, P24757, DOI 10.1007/s11042-020-09183-z
   Chatterjee I, 2018, MULTIMED TOOLS APPL, V77, P26991, DOI 10.1007/s11042-018-5901-0
   Chen J, 2020, BIOL PSYCHIAT, V87, P282, DOI 10.1016/j.biopsych.2019.08.031
   Chen ZH, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/6405930
   Chilla GS, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-06651-4
   Chin R, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32290-9
   Cortes-Briones JA, 2022, SCHIZOPHR RES, V245, P122, DOI 10.1016/j.schres.2021.05.018
   Cox RW, 1996, COMPUT BIOMED RES, V29, P162, DOI 10.1006/cbmr.1996.0014
   Crosson B, 2010, J REHABIL RES DEV, V47, pVII, DOI 10.1682/JRRD.2010.02.0017
   Dadgostar M, 2018, BIOMED ENG-APP BAS C, V30, DOI 10.4015/S1016237218500084
   de Moura AM, 2018, PSYCHIAT RES-NEUROIM, V275, P14, DOI 10.1016/j.pscychresns.2018.03.003
   de Pierrefeu A., 2018, 2018 INT WORKSHOP PA, P1
   Delude CM, 2009, ALT BRAIN ACT SCHIZ
   Dontaraju K, 2018, CONF REC ASILOMAR C, P1351, DOI 10.1109/ACSSC.2018.8645300
   Dwyer DB, 2018, SCHIZOPHRENIA BULL, V44, P1060, DOI 10.1093/schbul/sby008
   Elakkiya MK, 2022, COGNITIVE SYSTEMS SI, P293, DOI DOI 10.1016/B978-0-12-824410-4.00004-0
   Fernández A, 2011, CLIN NEUROPHYSIOL, V122, P2227, DOI 10.1016/j.clinph.2011.04.011
   Gaser C, 2004, AM J PSYCHIAT, V161, P154, DOI 10.1176/appi.ajp.161.1.154
   Georgiadis P, 2008, COMPUT METH PROG BIO, V89, P24, DOI 10.1016/j.cmpb.2007.10.007
   Gollub RL, 2013, NEUROINFORMATICS, V11, P367, DOI 10.1007/s12021-013-9184-3
   Gong J, 2020, SCHIZOPHR RES, V216, P262, DOI 10.1016/j.schres.2019.11.046
   Guo WB, 2017, PSYCHIAT RES-NEUROIM, V264, P60, DOI 10.1016/j.pscychresns.2017.04.010
   Guo YY, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10080562
   Han SQ, 2019, NEUROCOMPUTING, V365, P44, DOI 10.1016/j.neucom.2019.07.061
   Haryanto Ardy Wibowo, 2018, 2018 3rd International Seminar on Application for Technology of Information and Communication. Proceedings, P229, DOI 10.1109/ISEMANTIC.2018.8549748
   Hashimoto Y, 2020, BIORXIV
   Hu MJ, 2022, SCHIZOPHR RES, V243, P330, DOI 10.1016/j.schres.2021.06.011
   Hu MJ, 2020, IEEE ENG MED BIO, P1742, DOI 10.1109/EMBC44109.2020.9176610
   Hua J, 2019, SCHIZOPHR RES, V206, P370, DOI 10.1016/j.schres.2018.10.016
   Huang JS, 2019, IEEE J BIOMED HEALTH, V23, P342, DOI 10.1109/JBHI.2018.2796588
   Huang W, 2017, APPL INFORM, V4
   Iyer D, 2012, CLIN NEUROPHYSIOL, V123, P1810, DOI 10.1016/j.clinph.2011.12.021
   Jääskeläinen E, 2013, SCHIZOPHRENIA BULL, V39, P1296, DOI 10.1093/schbul/sbs130
   Jaber HA, 2019, IEEE ACCESS, V7, P122864, DOI 10.1109/ACCESS.2019.2937482
   Jain P, 2021, IEEE ENG MED BIO, P6695, DOI 10.1109/EMBC46164.2021.9630822
   Jenkinson M, 2012, NEUROIMAGE, V62, P782, DOI 10.1016/j.neuroimage.2011.09.015
   Jia XZ, 2019, SCI BULL, V64, P953, DOI 10.1016/j.scib.2019.05.008
   Jing RX, 2019, HUM BRAIN MAPP, V40, P3930, DOI 10.1002/hbm.24678
   Jo T, 2019, FRONT AGING NEUROSCI, V11, DOI 10.3389/fnagi.2019.00220
   Johannesen Jason K, 2016, Neuropsychiatr Electrophysiol, V2, P3
   Jun L, 2017, PROCEEDINGS OF 2017 13TH IEEE INTERNATIONAL CONFERENCE ON ELECTRONIC MEASUREMENT & INSTRUMENTS (ICEMI), VOL 1, P1, DOI 10.1109/ICEMI.2017.8265904
   Juneja A, 2018, MULTIMED TOOLS APPL, V77, P3963, DOI 10.1007/s11042-017-4404-8
   Juneja A, 2018, COMPUT METH PROG BIO, V155, P139, DOI 10.1016/j.cmpb.2017.12.001
   Kadry S, 2021, 2021 7 INT C BIOSIGN, P1, DOI DOI 10.1109/ICBSII51839.2021.9445133
   Kaggle, 2014, MLSP 2014 DAT
   Kirino E, 2017, PSYCHIAT CLIN NEUROS, V71, P262, DOI 10.1111/pcn.12495
   Krishnan PT, 2020, BIOCYBERN BIOMED ENG, V40, P1124, DOI 10.1016/j.bbe.2020.05.008
   Kumra S, 2008, SCHIZOPHRENIA BULL, V34, P60, DOI 10.1093/schbul/sbm109
   Latha, 2017, 2017 4 INT C SIGNAL, P1
   Latha M, 2021, IRBM, V42, P353, DOI 10.1016/j.irbm.2020.10.006
   Latha M, 2019, NEURAL COMPUT APPL, V31, P5195, DOI 10.1007/s00521-018-3360-1
   Latha M, 2018, MAGN RESON MATER PHY, V31, P483, DOI 10.1007/s10334-018-0674-z
   Laton J, 2014, J NEUROL SCI, V347, P262, DOI 10.1016/j.jns.2014.10.015
   Lee J, 2018, NEUROIMAGE-CLIN, V18, P467, DOI 10.1016/j.nicl.2018.02.007
   Lei D, 2020, HUM BRAIN MAPP, V41, P1119, DOI 10.1002/hbm.24863
   Lei D, 2020, PSYCHOL MED, V50, P1852, DOI 10.1017/S0033291719001934
   Lemaitre H, 2012, NEUROBIOL AGING, V33, DOI 10.1016/j.neurobiolaging.2010.07.013
   Li G, 2020, IEEE ACCESS, V8, P20093, DOI 10.1109/ACCESS.2020.2968634
   Li JH, 2019, BRAIN IMAGING BEHAV, V13, P1386, DOI 10.1007/s11682-018-9947-4
   Liang SG, 2020, SCHIZOPHR RES, V220, P187, DOI 10.1016/j.schres.2020.03.022
   Liu J, 2018, MULTIMED TOOLS APPL, V77, P29651, DOI 10.1007/s11042-017-5470-7
   Liu J, 2017, IEEE T NANOBIOSCI, V16, P600, DOI 10.1109/TNB.2017.2751074
   Liu L., 2020, BIOMARK NEUROPSYCHIA, V3, DOI DOI 10.1016/J.BIONPS.2020.100022
   Liu P, 2019, CHIN CONTR CONF, P7694, DOI [10.23919/ChiCC.2019.8865960, 10.23919/chicc.2019.8865960]
   Liu Y, 2018, SCHIZOPHR RES, V192, P408, DOI 10.1016/j.schres.2017.04.028
   Man WQ, 2021, IEEE ENG MED BIO, P4060, DOI 10.1109/EMBC46164.2021.9631085
   Manj├a┬│n JV., 2017, MRI PREPROCESSING, P53
   Manohar L, 2018, J MED BIOL ENG, V38, P917, DOI 10.1007/s40846-017-0355-9
   Matsubara T, 2019, IEEE T BIO-MED ENG, V66, P2768, DOI 10.1109/TBME.2019.2895663
   Mayo Clinic, 2020, EEG EL
   MCCARTHY J, 1983, PSYCHOL TODAY, V17, P46
   Miller R.L., 2018, 2018 INT WORKSHOP PA, P1
   Mirjalili M, 2017, PROCEEDINGS OF THE 2017 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P37, DOI 10.1109/ICCKE.2017.8167925
   Moghimi P, 2018, FRONT NEUROINFORM, V12, DOI 10.3389/fninf.2018.00071
   Neuhaus AH, 2014, SCHIZOPHRENIA BULL, V40, P1062, DOI 10.1093/schbul/sbt151
   Neuhaus AH, 2011, NEUROIMAGE, V55, P514, DOI 10.1016/j.neuroimage.2010.12.038
   Nguyen H, 2018, CORRECTING DIFFERENC
   Nimkar A.V., 2018, 2018 4 INT C COMP IN, P1, DOI DOI 10.1109/ICCOINS.2018
   Niu Y., 2021, 2021 IEEE EMBS INT C, P1, DOI DOI 10.1109/BHI50953.2021.9508521
   Niu YW, 2019, 2019 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT CONTROL AND INFORMATION PROCESSING (ICICIP), P297, DOI [10.1109/ICICIP47338.2019.9012169, 10.1109/icicip47338.2019.9012169]
   Oh J, 2020, FRONT PSYCHIATRY, V11, DOI 10.3389/fpsyt.2020.00016
   Oh K, 2019, SCHIZOPHR RES, V212, P186, DOI 10.1016/j.schres.2019.07.034
   Oh SL, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9142870
   Olejarczyk E, 2017, EEG SCHIZOPHRENIA, DOI 10.18150/repod.0107441
   Olejarczyk E, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0188629
   Orban P, 2018, SCHIZOPHR RES, V192, P167, DOI 10.1016/j.schres.2017.05.027
   Pan YZ, 2020, SCHIZOPHRENIA BULL, V46, P623, DOI 10.1093/schbul/sbz112
   Pande S., 2018, J Adv Res Dynam Control Syst, V10, P2765
   Park BY, 2019, FRONT NEUROINFORM, V13, DOI 10.3389/fninf.2019.00005
   Parvinnia E, 2014, J KING SAUD UNIV-COM, V26, P1, DOI 10.1016/j.jksuci.2013.01.001
   Phang CR, 2019, I IEEE EMBS C NEUR E, P401, DOI [10.1109/ner.2019.8717087, 10.1109/NER.2019.8717087]
   Pinaya WHL, 2019, HUM BRAIN MAPP, V40, P944, DOI 10.1002/hbm.24423
   Pinaya WHL, 2016, SCI REP-UK, V6, DOI 10.1038/srep38897
   Pizurica A, 2006, CURR MED IMAGING, V2, P247, DOI 10.2174/157340506776930665
   Plis SM, 2018, NEUROIMAGE, V181, P734, DOI 10.1016/j.neuroimage.2018.07.047
   Potkin SG, 2009, SCHIZOPHRENIA BULL, V35, P19, DOI 10.1093/schbul/sbn162
   Qiu Y, 2019, LECT NOTES COMPUT SC, V11555, P540, DOI 10.1007/978-3-030-22808-8_53
   Qureshi MNI, 2019, ARTIF INTELL MED, V98, P10, DOI 10.1016/j.artmed.2019.06.003
   Qureshi MNI, 2017, FRONT NEUROINFORM, V11, DOI 10.3389/fninf.2017.00059
   Rajeshwari S, 2013, 2013 IEEE CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES (ICT 2013), P391
   Ramkiran S, 2019, PSYCHIAT RES-NEUROIM, V284, P1, DOI 10.1016/j.pscychresns.2018.12.013
   Rodrigues AF, 2017, 2017 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL & HEALTH INFORMATICS (BHI), P381, DOI 10.1109/BHI.2017.7897285
   Rokham H, 2020, BIOL PSYCHIAT-COGN N, V5, P819, DOI 10.1016/j.bpsc.2020.05.008
   Ross, 2014, SCHIZOPHRENIA INNOVA
   Sabeti M, 2011, EXPERT SYST APPL, V38, P2063, DOI 10.1016/j.eswa.2010.07.145
   Sadeghi D, 2021, ARXIV
   Saeed M, 2021, INTRO RECURRENT NEUR
   Salimi-Khorshidi G, 2014, NEUROIMAGE, V90, P449, DOI 10.1016/j.neuroimage.2013.11.046
   Salman MS, 2017, INT CONF ACOUST SPEE, P904, DOI 10.1109/ICASSP.2017.7952287
   Salvador R, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.01203
   Febles ES, 2022, FRONT NEUROINFORM, V16, DOI 10.3389/fninf.2022.893788
   Sargolzaei S, 2015, COMPUT BIOL MED, V56, P158, DOI 10.1016/j.compbiomed.2014.10.018
   Sarker Iqbal H, 2021, SN Comput Sci, V2, P160, DOI 10.1007/s42979-021-00592-x
   Sartipi S, 2020, MULTIMED TOOLS APPL, V79, P23401, DOI 10.1007/s11042-020-09122-y
   SchizConnect, 2022, SCHIZC DAT
   Sendi MSE, 2021, IEEE ENG MED BIO, P1640, DOI 10.1109/EMBC46164.2021.9629825
   Sendi MSE, 2020, IEEE SW SYMP IMAG, P112, DOI 10.1109/SSIAI49293.2020.9094620
   Shim M, 2016, SCHIZOPHR RES, V176, P314, DOI 10.1016/j.schres.2016.05.007
   Shoeibi A, 2021, FRONT NEUROINFORM, V15, DOI 10.3389/fninf.2021.777977
   Shoeibi A, 2021, EXPERT SYST APPL, V163, DOI 10.1016/j.eswa.2020.113788
   Siuly S, 2020, IEEE T NEUR SYS REH, V28, P2390, DOI 10.1109/TNSRE.2020.3022715
   Skåtun KC, 2017, SCHIZOPHRENIA BULL, V43, P914, DOI 10.1093/schbul/sbw145
   Sobahi N, 2022, IEEE SENS J, V22, P7913, DOI 10.1109/JSEN.2022.3151465
   Song XW, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025031
   [Spitzer RobertL. American Psychological Association American Psychological Association], 1980, DIAGN STAT MAN MENT, V3rd
   Srinivasagopalan S, 2019, J EXP THEOR ARTIF IN, V31, P803, DOI 10.1080/0952813X.2018.1563636
   Sujatha C.M., 2021, 2021 7 INT C BIOSIGN, P1, DOI DOI 10.1109/ICBSII51839.2021.9445189
   Swiebocka-Wiek J, 2016, LECT NOTES COMPUT SC, V9842, P172, DOI 10.1007/978-3-319-45378-1_16
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Talpalaru A, 2019, SCHIZOPHR RES, V214, P51, DOI 10.1016/j.schres.2019.05.044
   Tanveer M, 2022, IEEE J BIOMED HEALTH, P1
   Tas C, 2018, NEURAL COMPUT APPL, V29, P377, DOI 10.1007/s00521-016-2451-0
   Taylor JA, 2017, NEUROIMAGE-CLIN, V15, P264, DOI 10.1016/j.nicl.2017.04.027
   Urbanowicz RJ, 2018, J BIOMED INFORM, V85, P189, DOI 10.1016/j.jbi.2018.07.014
   Wang J, 2021, COMPUT MATH METHOD M, P7
   Wang L, 2013, FRONT NEUROINFORM, V7, DOI 10.3389/fninf.2013.00025
   Wang S, 2018, SCHIZOPHR RES, V192, P179, DOI 10.1016/j.schres.2017.05.038
   Wang S, 2018, PROG NEURO-PSYCHOPH, V81, P445, DOI 10.1016/j.pnpbp.2017.08.012
   Wang T, 2022, INT J CONSTR MANAG, V22, P1585, DOI 10.1080/15623599.2020.1735610
   Wang Y, 2018, J INTEGR NEUROSCI, V17, P331, DOI 10.31083/j.jin.2018.04.0410
   Wang ZJ, 2019, IEEE ACCESS, V7, P134388, DOI 10.1109/ACCESS.2019.2941912
   WHO, SCHIZ
   Winterburn JL, 2019, SCHIZOPHR RES, V214, P3, DOI 10.1016/j.schres.2017.11.038
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Wong CG, 2012, BIOL PSYCHIAT, V71, P458, DOI 10.1016/j.biopsych.2011.11.011
   Xiang YZ, 2020, FRONT BIOENG BIOTECH, V7, DOI 10.3389/fbioe.2019.00479
   Xiao Y, 2019, SCHIZOPHR RES, V214, P11, DOI 10.1016/j.schres.2017.11.037
   Xu WX, 2020, 2020 3RD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND BIG DATA (ICAIBD 2020), P195, DOI [10.1109/ICAIBD49809.2020.9137483, 10.1109/icaibd49809.2020.9137483]
   Yamaguchi H, 2020, BIORXIV
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yan CG, 2010, FRONT SYST NEUROSCI, V4, DOI 10.3389/fnsys.2010.00013
   Yan W, 2021, SCHIZOPHR RES
   Yan WZ, 2019, EBIOMEDICINE, V47, P543, DOI 10.1016/j.ebiom.2019.08.023
   Yang B, 2019, IEEE ACCESS, V7, P109956, DOI 10.1109/ACCESS.2019.2933550
   Yang HH, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00192
   Yang J, 2020, SCHIZOPHRENIA BULL, V46, P916, DOI 10.1093/schbul/sbz137
   Yang YP, 2017, AER ADV ENG RES, V141, P1, DOI 10.1109/ULTSYM.2017.8091994
   Yoon JH, 2008, BIOL PSYCHIAT, V64, P1035, DOI 10.1016/j.biopsych.2008.07.025
   [袁非牛 Yuan Feiniu], 2019, [计算机学报, Chinese Journal of Computers], V42, P203
   Yuan L, 2017, I S BIOMED IMAGING, P952, DOI 10.1109/ISBI.2017.7950673
   Yuh EL, 2017, STRUCTURAL IMAGING T, V344
   Zarogianni E, 2017, SCHIZOPHR RES, V181, P6, DOI 10.1016/j.schres.2016.08.027
   Zeng LL, 2018, EBIOMEDICINE, V30, P74, DOI 10.1016/j.ebiom.2018.03.017
   Zhang J, 2022, DETECTING SCHIZOPHRE
   Zhang L, 2020, PROCEEDINGS OF 2020 IEEE 19TH INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI*CC 2020), P68, DOI 10.1109/ICCICC50026.2020.9450257
   Zhang L, 2019, IEEE ENG MED BIO, P4521, DOI [10.1109/embc.2019.8857946, 10.1109/EMBC.2019.8857946]
   Zhao JL, 2020, J NEUROSCI METH, V341, DOI 10.1016/j.jneumeth.2020.108756
   Zhao MR, 2009, LECT NOTES COMPUT SC, V5754, P187, DOI 10.1007/978-3-642-04070-2_21
   Zhou AJ, 2018, INT CONF CLOUD COMPU, P451, DOI 10.1109/CCIS.2018.8691336
   Zhu FR, 2019, EUR NEUROPSYCHOPHARM, V29, P519, DOI 10.1016/j.euroneuro.2019.02.006
   Zhu Q, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00603
   Zhu Q, 2018, BIOMED ENG ONLINE, V17, DOI 10.1186/s12938-018-0464-x
   Zhu YF, 2020, IEEE ACCESS, V8, P62698, DOI 10.1109/ACCESS.2020.2983317
   Zhu YH, 2022, SCHIZOPHRENIA BULL, V48, P563, DOI 10.1093/schbul/sbac030
   Zhuang HX, 2019, NEUROSCI LETT, V705, P87, DOI 10.1016/j.neulet.2019.04.039
   Zou HL, 2020, MED BIOL ENG COMPUT, V58, P1779, DOI 10.1007/s11517-020-02193-x
NR 204
TC 11
Z9 11
U1 8
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20343
EP 20405
DI 10.1007/s11042-022-13809-9
EA OCT 2022
PG 63
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000869194800002
DA 2024-07-18
ER

PT J
AU Han, L
   Lan, PY
   Shi, X
   Wang, XM
   He, JH
   Li, GY
AF Han, Li
   Lan, Pengyan
   Shi, Xue
   Wang, Xiaomin
   He, Jinhai
   Li, Genyu
TI Topological and geometrical joint learning for 3D graph data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D shape analysis; Deep learning; Graph convolution network; Graph-based
   leaarning
AB Traditional convolutional neural networks (CNNs) are limited to be directly applied to 3D graph data due to their inherent grid structure. And most of graph-based learning methods use local-to-global hierarchical structure learning, and often ignore the global context. To overcome these issues, we propose two strategies: one is topological learning with 3D offset convolution, which provides learnable parameters in local graph construction, effectively expands the sampling space and improves the perception ability of diverse local structures. The other is geometrical learning with an adaptive spec-graph convolution network (AsGCN), which establishes a joint learning mechanism of local geometry in spatial domain and global structure in feature domain, and generates informative deep features through spectral filtering and weighting. Extensive experiments demonstrate that our deep features have strong discerning ability and robustness to non-rigid transformed graph data, incomplete mesh data, and better performance can be obtained compared to state-of-the-art methods.
C1 [Han, Li; Lan, Pengyan; Shi, Xue; Wang, Xiaomin; He, Jinhai; Li, Genyu] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian, Peoples R China.
C3 Liaoning Normal University
RP Han, L (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian, Peoples R China.
EM hl_dlls@dl.cn
RI xiaomin, wang/AFX-8377-2022
OI Han, Li/0000-0002-0975-9908
FU NSFC [61702246]; Liaoning province [2019lsktyb-084, 2020JH4/10100045,
   LJ2020015]; fund of Dalian Science and Technology [2019J12GX038]
FX We would like to thank the anonymous reviewers for their helpful
   comments. The research presented in this paper is supported by a grant
   from NSFC (61702246), grants from research projects of Liaoning province
   (2019lsktyb-084, 2020JH4/10100045, LJ2020015) and a fund of Dalian
   Science and Technology (2019J12GX038).
CR Bansal M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03488-z
   Bansal M, 2021, ARCH COMPUT METHOD E, V28, P1147, DOI 10.1007/s11831-020-09409-1
   Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405
   Bruna J., 2014, ABS13126203 CORR, P1, DOI [10.48550/arXiv.1312.6203, DOI 10.48550/ARXIV.1312.6203]
   Chen J, 2018, PROC INT C LEARNING
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Chiang WL, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P257, DOI 10.1145/3292500.3330925
   Defferrard M, 2016, ADV NEUR IN, V29
   Gilmer J, 2017, PR MACH LEARN RES, V70
   Hamilton WL, 2017, ADV NEUR IN, V30
   Hammond DK, 2011, APPL COMPUT HARMON A, V30, P129, DOI 10.1016/j.acha.2010.04.005
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermosilla P, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275110
   Kipf TN, 2017, INT C LEARN REPR
   Klokov R, 2017, IEEE I CONF COMP VIS, P863, DOI 10.1109/ICCV.2017.99
   Lee J., 2018, INT C LEARN REPR ICL
   Lio P., 2018, arXiv
   Liu JX, 2019, IEEE I CONF COMP VIS, P7545, DOI 10.1109/ICCV.2019.00764
   Liu S, 2021, IEEE T FUZZY SYST, V29, P90, DOI 10.1109/TFUZZ.2020.3006520
   Liu SC, 2023, IEEE T CYBERNETICS, V53, P1460, DOI 10.1109/TCYB.2021.3102642
   Liu XH, 2019, AAAI CONF ARTIF INTE, P8778
   Luciano L, 2018, PATTERN RECOGN LETT, V105, P182, DOI 10.1016/j.patrec.2017.05.011
   Masoumi M, 2016, PATTERN RECOGN LETT, V83, P339, DOI 10.1016/j.patrec.2016.04.009
   Niepert M, 2016, PR MACH LEARN RES, V48
   Qi C., 2017, NeurIPS, P5105, DOI [10.1109/ CVPR.2017.16, DOI 10.1109/CVPR.2017.16]
   Qi CR, 2017, ADV NEUR IN, V30
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Simonovsky M, 2017, PROC CVPR IEEE, P29, DOI 10.1109/CVPR.2017.11
   Thomas H, 2019, IEEE I CONF COMP VIS, P6420, DOI 10.1109/ICCV.2019.00651
   Turlach B A., 1993, Technical Report
   Velickovic Petar, 2018, INT C LEARN REPR
   Verma N, 2018, PROC CVPR IEEE, P2598, DOI 10.1109/CVPR.2018.00275
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P56, DOI 10.1007/978-3-030-01225-0_4
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wu WK, 2020, AAAI CONF ARTIF INTE, V34, P6422
   Wu WX, 2019, PROC CVPR IEEE, P9613, DOI 10.1109/CVPR.2019.00985
   Xie J, 2016, COMPUT VIS PATTERN R
   Xu BB, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1928
   Yan X, 2020, PROC CVPR IEEE, P5588, DOI 10.1109/CVPR42600.2020.00563
   Yi L, 2017, PROC CVPR IEEE, P6584, DOI 10.1109/CVPR.2017.697
   Yu F., 2015, ARXIV
   Zhang DJ, 2020, INTEGR COMPUT-AID E, V27, P57, DOI 10.3233/ICA-190608
NR 44
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15457
EP 15474
DI 10.1007/s11042-022-13806-y
EA OCT 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000864310100004
DA 2024-07-18
ER

PT J
AU Ahmed, I
   Khan, A
AF Ahmed, Irfan
   Khan, Aftab
TI Learning based speech compressive subsampling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressive sensing; Sensing matrix; Speech signal recovery; Gaussian
   random matrix; Deterministic sensing matrix; Learning based compressive
   subsampling
ID RECOMMENDATION SYSTEM
AB In this paper, we present a learning-based approach to speech compressive subsampling. Prior work in the field has mainly used random or deterministic matrices, which are unaffected by the structure and nature of the signal to be sampled. As a result, recovery algorithms require more computational and power resources to recover the original signal from a small number of samples. The framework presented in this paper aims to propose an efficient methodology for optimised speech sensing matrix design using standard speech datasets via offline training. The effectiveness of the suggested method is assessed using the signal-to-noise ratio that is obtained after reconstructing the original speech signal from samples supplied by the developed matrix. The baseline sensing matrices chosen for this work are widely used random and deterministic matrices, including the Gaussian random matrix, the Bernoulli random matrix, the Toeplitz matrix, and the Hadamard matrix. Convex relaxation and linear reconstruction algorithms were used to perform the signal reconstruction, and the key performance indicators for the relevant sensing matrix are chosen to be reconstruction accuracy and speed. In this work, we observe almost 4% on average improvement in reconstruction accuracy when the proposed method is compared with one of the efficient sensing matrices.
C1 [Ahmed, Irfan; Khan, Aftab] Univ Engn & Technol, Dept Comp Syst Engn, Peshawar, Pakistan.
C3 University of Engineering & Technology Peshawar
RP Ahmed, I (corresponding author), Univ Engn & Technol, Dept Comp Syst Engn, Peshawar, Pakistan.
EM irfanahmed@uetpeshawar.edu.pk; aftab.khan@uetpeshawar.edu.pk
RI Ahmed, Irfan/HHD-1948-2022
OI Ahmed, Irfan/0000-0002-3489-3519
CR Ahmed I, 2022, MULTIMED TOOLS APPL, V81, P39077, DOI 10.1007/s11042-022-12894-0
   Ahmed I, 2021, MULTIMED TOOLS APPL, V80, P20327, DOI 10.1007/s11042-021-10657-x
   Ahmed I, 2020, ARAB J SCI ENG, V45, P1567, DOI 10.1007/s13369-019-04080-6
   Ahmed I, 2012, INT CONF ROBOT ARTIF, P139, DOI 10.1109/ICRAI.2012.6413380
   Ahmed Irfan., 2012, AUTOMATION COMPUTING, P1
   Bala S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION TECHNOLOGY CICT 2015, P632, DOI 10.1109/CICT.2015.136
   Baldassarre L, 2016, IEEE J-STSP, V10, P809, DOI 10.1109/JSTSP.2016.2548442
   Baraniuk R., 2011, CONNEXIONS TXB, P24
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2022, ENVIRON SCI POLLUT R, V29, P14780, DOI 10.1007/s11356-021-16627-y
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhatti UA, 2018, HUM VACC IMMUNOTHER, V14, P165, DOI 10.1080/21645515.2017.1379639
   Candès EJ, 2008, CR MATH, V346, P589, DOI 10.1016/j.crma.2008.03.014
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Indyk P, 2010, LECT NOTES COMPUT SC, V6034, P157, DOI 10.1007/978-3-642-12200-2_15
   Liu F, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10082811
   Mahabadi RK, 2018, EUR SIGNAL PR CONF, P1925, DOI 10.23919/EUSIPCO.2018.8553402
   Parchami M, 2020, IET SIGNAL PROCESS, V14, P385, DOI 10.1049/iet-spr.2019.0245
   Rani M, 2018, IEEE ACCESS, V6, P4875, DOI 10.1109/ACCESS.2018.2793851
   Srinivas Kankanala., 2018, INT C ADV COMPUTING, P342
   Thapliyal M, 2022, J COMPUT HIGH EDUC, V34, P60, DOI 10.1007/s12528-021-09278-y
NR 23
TC 4
Z9 4
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15327
EP 15343
DI 10.1007/s11042-022-14003-7
EA OCT 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000863553600002
DA 2024-07-18
ER

PT J
AU Hu, AQ
   Sun, ZX
   Li, Q
   Xu, YC
   Zhu, YH
   Zhang, S
AF Hu, Anqi
   Sun, Zhengxing
   Li, Qian
   Xu, Yechao
   Zhu, Yihuan
   Zhang, Sheng
TI Fine-grained traffic video vehicle recognition based orientation
   estimation and temporal information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fine-grained vehicle recognition; Orientation estimation; RNN; Traffic
   video
AB In this paper, we propose a method for fine-grained vehicle recognition in traffic surveillance video. Compared with general theory about single image fine-grained recognition, this method focuses on multi-frame information combination and the viewpoint changes across videos. Firstly, we detect vehicle instances and their local frames in input traffic video by vehicle tracking. For each vehicle instance, pose estimation is used to extract the 3D orientation in corresponding frame. We encode the 3D orientation as an extra supervising clue, and merge it with CNN feature to show the appearance information and changes in moving process. In addition, recurrent neural network (RNN) is proposed to select abundant information over traffic video and fuse CNN feature of each vehicle frames into comprehensive feature which includes not only spatial information but also temporal information for fine-grained recognition. We do our experiments on the personal CarVideo dataset which collected by surveillance cameras and the open dataset BoxCar116k for performance evaluation. The experiments show that our method outperforms the state-of-the-art methods for fine-grained recognition in traffic video application.
C1 [Hu, Anqi; Sun, Zhengxing; Li, Qian; Xu, Yechao; Zhu, Yihuan; Zhang, Sheng] Nanjing Univ, Coll Comp Sci & Technol, Nanjing, Peoples R China.
   [Li, Qian] Natl Univ Def Technol, Coll Meteorol & Oceanog, Changsha, Peoples R China.
C3 Nanjing University; National University of Defense Technology - China
RP Sun, ZX; Li, Q (corresponding author), Nanjing Univ, Coll Comp Sci & Technol, Nanjing, Peoples R China.; Li, Q (corresponding author), Natl Univ Def Technol, Coll Meteorol & Oceanog, Changsha, Peoples R China.
EM szx@nju.edu.cn; public_liqian@163.com
RI Sun, Zhengxing/A-7411-2011
OI Qian, Li/0000-0002-9530-4925
FU National Natural Science Foundation of China [42075139, 42077232,
   61272219]; National High Technology Research and Development Program of
   China [2007AA01Z334]; Science and technology program of Jiangsu Province
   [BE2020082, BE2010072, BE2011058, BY2012190]; Program for New Century
   Excellent Talents in University of China [NCET-04-04605]; China
   Postdoctoral Science Foundation [2017 M621700]; Innovation Fund of State
   Key Laboratory for Novel Software Technology [ZZKT2021A17]
FX Supported by:The National Natural Science Foundation of China No.
   42075139,42077232, 61272219; The National High Technology Research and
   Development Program of China No. 2007AA01Z334; The Science and
   technology program of Jiangsu Province No. BE2020082, BE2010072,
   BE2011058, BY2012190; The Program for New Century Excellent Talents in
   University of China No. NCET-04-04605; The China Postdoctoral Science
   Foundation No. 2017 M621700 and Innovation Fund of State Key Laboratory
   for Novel Software Technology No. ZZKT2021A17.
CR Bae SH, 2014, PROC CVPR IEEE, P1218, DOI 10.1109/CVPR.2014.159
   Biglari M, 2018, IEEE T INTELL TRANSP, V19, P273, DOI 10.1109/TITS.2017.2749961
   Chen QQ, 2020, IEEE ACCESS, V8, P171912, DOI 10.1109/ACCESS.2020.3024658
   Chen Y, 2019, PROC CVPR IEEE, P5152, DOI 10.1109/CVPR.2019.00530
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Duan K, 2012, PROC CVPR IEEE, P3474, DOI 10.1109/CVPR.2012.6248089
   Fang J, 2017, IEEE T INTELL TRANSP, V18, P1782, DOI 10.1109/TITS.2016.2620495
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Ge WF, 2019, PROC CVPR IEEE, P3029, DOI 10.1109/CVPR.2019.00315
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu HN, 2019, IEEE I CONF COMP VIS, P5389, DOI 10.1109/ICCV.2019.00549
   Huang SL, 2016, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2016.132
   HuaZhang, 2019, I C OPT COMMUN NETW, DOI [10.1109/icocn.2019.8934417, 10.1109/avss.2019.8909879, 10.1109/itec.2019.8790595]
   Krause J, 2015, PROC CVPR IEEE, P5546, DOI 10.1109/CVPR.2015.7299194
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumaran SK, 2019, EXPERT SYST APPL, V134, P267, DOI 10.1016/j.eswa.2019.05.049
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li XX, 2019, IEEE T VEH TECHNOL, V68, P4204, DOI 10.1109/TVT.2019.2895651
   Liao L, 2015, IEEE IMAGE PROC, P745, DOI 10.1109/ICIP.2015.7350898
   Lin D, 2015, PROC CVPR IEEE, P1666, DOI 10.1109/CVPR.2015.7298775
   Lin TY, 2018, IEEE T PATTERN ANAL, V40, P1309, DOI 10.1109/TPAMI.2017.2723400
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103
   Rachmadi RF, 2018, 2018 INTERNATIONAL WORKSHOP ON BIG DATA AND INFORMATION SECURITY (IWBIS), P19, DOI 10.1109/IWBIS.2018.8471695
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Simon M, 2015, IEEE I CONF COMP VIS, P1143, DOI 10.1109/ICCV.2015.136
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sochor J, 2019, IEEE T INTELL TRANSP, V20, P97, DOI 10.1109/TITS.2018.2799228
   Tabernik D, 2020, IEEE T INTELL TRANSP, V21, P1427, DOI 10.1109/TITS.2019.2913588
   Tang Siyu., 2015, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, P5033
   Xu Z, 2017, IEEE T IMAGE PROCESS, V26, P135, DOI 10.1109/TIP.2016.2621661
   Yao BP, 2012, PROC CVPR IEEE, P3466, DOI 10.1109/CVPR.2012.6248088
   Yuan Y, 2019, IEEE T IMAGE PROCESS, V28, P3423, DOI 10.1109/TIP.2019.2896952
   Zhang Jian-zhong, 2014, Instrument Technique and Sensor, P14
   Zhang Q, 2018, 2018 IEEE FOURTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM)
   Zhang Q, 2016, PR IEEE I C PROGR IN, P233, DOI 10.1109/PIC.2016.7949501
   Zheng HL, 2017, IEEE I CONF COMP VIS, P5219, DOI 10.1109/ICCV.2017.557
   Zhu YY, 2018, IEEE T INTELL TRANSP, V19, P209, DOI 10.1109/TITS.2017.2768827
NR 39
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13745
EP 13763
DI 10.1007/s11042-022-13811-1
EA SEP 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000862219700003
DA 2024-07-18
ER

PT J
AU Dewangan, NK
   Chandrakar, P
   Kumari, S
   Rodrigues, JJPC
AF Dewangan, Narendra K.
   Chandrakar, Preeti
   Kumari, Saru
   Rodrigues, Joel J. P. C.
TI Enhanced privacy-preserving in student certificate management in
   blockchain and interplanetary file system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blockchain technology; Certificate management; Identity management;
   Interplanetary file system; Privacy; proof-of-authentication
AB Blockchain technology is popular due to properties such as immutability, transparency, distributed storage, and control decentralisation. Student certificates and skill verification are used for job applications and other purposes. Forgery of certificates with centralised authority is a major issue in online education. This challenge can be solved by using blockchain-based certificate management for students and skill evidence management for employees. However, these types of certificate managements have many issues like security and privacy breaches, fear of cyber-attack, hijacking of the session, identity theft of participants, etc. Because blockchain uses cryptographic hash and digital signature for sending and verifying transactions in blockchain peer-to-peer networks, we can overcome many security and privacy difficulties. We proposed a system that generates the identity of students using the tokens and stores them in the interplanetary file system (IPFS). The proposed system makes use of IPFS and EdDSA (Edward-curve Digital Signature Algorithm) for digital signature and verification, as well as SHA-256 for cryptographic hashing. Our proposed system results provide the transaction speed, time required for per transaction, and time required for signing and verifying a transaction. We compare our proposed system with the previously developed systems in terms of privacy, transaction cost, large file storage, blockchain implementation and registration cost.
C1 [Dewangan, Narendra K.; Chandrakar, Preeti] Natl Inst Technol Raipur, Dept Comp Sci & Engn, GE Rd, Raipur 492010, Chhattisgarh, India.
   [Kumari, Saru] Chaudhary Charan Singh Univ Meerut, Dept Math, Meerut 250001, Uttar Pradesh, India.
   [Rodrigues, Joel J. P. C.] China Univ Petr East China, Coll Comp Sci & Technol, Qingdao 266555, Peoples R China.
   [Rodrigues, Joel J. P. C.] Inst Telecomunicacoes, P-6201001 Covilha, Portugal.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur; Chaudhary Charan Singh University; China University
   of Petroleum
RP Dewangan, NK (corresponding author), Natl Inst Technol Raipur, Dept Comp Sci & Engn, GE Rd, Raipur 492010, Chhattisgarh, India.
EM narendra.dewangan89@gmail.com; pchandrakar.cs@nitrr.ac.in;
   saryusiirohi@gmail.com; joeljr@ieee.org
RI Rodrigues, Joel J. P. C./A-8103-2013; DEWANGAN, NARENDRA/AAD-4933-2022;
   Kumari, Saru/K-2038-2019
OI Rodrigues, Joel J. P. C./0000-0001-8657-3800; DEWANGAN,
   NARENDRA/0000-0002-8857-8290; Kumari, Saru/0000-0003-4929-5383
CR Al Mamun M. Abdullah, 2020, Advances in Information and Communication. Proceedings of the 2020 Future of Information and Communication Conference (FICC). Advances in Intelligent Systems and Computing (AISC 1129), P93, DOI 10.1007/978-3-030-39445-5_9
   Alammary A, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122400
   Ali SIM, 2022, EGYPT INFORM J, V23, P187, DOI 10.1016/j.eij.2021.12.002
   Amo Daniel, 2019, New Knowledge in Information Systems and Technologies. Advances in Intelligent Systems and Computing (AISC 932), P371, DOI 10.1007/978-3-030-16187-3_36
   Asamoah KO, 2020, IEEE INTERNET THINGS, V7, P10336, DOI 10.1109/JIOT.2020.2986367
   Bellini E, 2019, IEEE INT CONF CLOUD, P484, DOI 10.1109/CLOUD.2019.00085
   Nguyen BM, 2020, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.266
   Budhiraja Sugandha, 2020, Inventive Computation Technologies. Lecture Notes in Networks and Systems (LNNS 98), P150, DOI 10.1007/978-3-030-33846-6_17
   Chen CL, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/8241801
   Cheng H., 2020, Revised Selected Papers, V2, P456
   Curmi A, 2019, LECT NOTES BUS INF P, V339, P211, DOI 10.1007/978-3-030-04849-5_18
   Deenmahomed HAM, 2021, COMPUT APPL ENG EDUC, V29, P1234, DOI 10.1002/cae.22381
   Dewangan NK, 2021, 2021 4 INT C SECURIT, P1
   Grech A, 2021, FRONT BLOCKCHAIN, V4, DOI 10.3389/fbloc.2021.616779
   Gresch J, 2019, LECT NOTES BUS INF P, V339, P185, DOI 10.1007/978-3-030-04849-5_16
   Huan L., 2020, SCI TECHNOL DEV J EN, V3, P95, DOI [10.32508/stdjet.v3iSI1.516, DOI 10.32508/STDJET.V3ISI1.516]
   Karapapas C, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON BLOCKCHAIN AND CRYPTOCURRENCY (IEEE ICBC), DOI 10.1109/icbc48266.2020.9169451
   Kassem JA, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9152953
   Krejci S, 2020, LECT NOTES COMPUT SC, V12054, P177, DOI 10.1007/978-3-030-44769-4_14
   Kumar P, 2021, J SYST ARCHITECT, V115, DOI 10.1016/j.sysarc.2020.101954
   Lam TY, 2022, INTERACT LEARN ENVIR, V30, P1229, DOI 10.1080/10494820.2020.1716022
   Latif S, 2021, J IND INF INTEGR, V21, DOI 10.1016/j.jii.2020.100190
   Liu B, 2020, IEEE ACCESS, V8, P91751, DOI 10.1109/ACCESS.2020.2993921
   Liu L., 2020, BLOCKCHAIN CYBERSECU, P269, DOI DOI 10.1007/978-3-030-38181-3_14
   Liu LY, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON BLOCKCHAIN (BLOCKCHAIN 2019), P140, DOI 10.1109/Blockchain.2019.00027
   Mishra R, 2020, IMPLEMENTATION ANAL, DOI 10.1109/CCNC46108.2020.9045196
   Mishra RA, 2020, CONSUM COMM NETWORK, DOI 10.1109/ccnc46108.2020.9045196
   Mishra RA, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102512
   Naz M, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11247054
   Patole D, 2020, ALGO INTELL SY, P439, DOI 10.1007/978-981-15-0222-4_41
   Politou E, 2020, FUTURE GENER COMP SY, V112, P956, DOI 10.1016/j.future.2020.06.037
   Qi YH, 2021, FUTURE GENER COMP SY, V117, P328, DOI 10.1016/j.future.2020.12.003
   Turkanovic M, 2018, IEEE ACCESS, V6, P5112, DOI 10.1109/ACCESS.2018.2789929
   Pham VD, 2020, IEEE RIVF INT CONF, P310, DOI 10.1109/rivf48685.2020.9140747
   Vidal FR, 2020, IBER CONF INF SYST
   Xu YQ, 2017, LECT NOTES COMPUT SC, V10580, P288, DOI 10.1007/978-3-319-67729-3_17
NR 36
TC 7
Z9 7
U1 12
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12595
EP 12614
DI 10.1007/s11042-022-13915-8
EA SEP 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000859866500005
DA 2024-07-18
ER

PT J
AU Bodini, A
   Colecchia, F
   Manohar, A
   Harrison, D
   Garaj, V
AF Bodini, Aimone
   Colecchia, Federico
   Manohar, Arthi
   Harrison, David
   Garaj, Vanja
TI Using immersive technologies to facilitate location scouting in
   audiovisual media production: a user requirements study and proposed
   framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audiovisual production; Real-time graphic engines; Virtual reality;
   Augmented reality; Virtual production; Location scouting
AB In common with many industries, the audiovisual sector is likely to be transformed by real-time graphic engines in combination with immersive technologies such as Virtual Reality and Augmented Reality. This technological mix enables what is presently known as Virtual Production, introducing a new process to the audiovisual professional, capable of fostering creativity, collaboration, and decision making, while at the same time increasing efficiency. The potential for Virtual Production to transform workflows and creative processes within large-scale productions in the audiovisual sector is significant and includes the prospective introduction of new capabilities for remote co-creation of content. However, barriers to democratisation need to be overcome, particularly in relation to adoption of the technology by small and medium independent productions that generally have limited access to resources and technical knowledge. Following an extensive study of the current literature and involvement in the research of professionals working in the field through online interviews, this article documents a first step towards filling this gap by investigating Virtual Production adoption scenarios for small and medium independent productions. The primary aim is to design intuitive, engaging, and effective solutions to address the needs of Directors, Cinematographers, and Producers. Thanks to the valuable time and experience of industry professionals, this study has gathered user requirements for a Virtual Production design solution capable of facilitating location scouting and pre-production. A novel framework for remote exploration of target locations within immersive environments, co-created with relevant stakeholders, is presented to lay the foundations of future co-design work.
C1 [Bodini, Aimone; Colecchia, Federico; Manohar, Arthi; Harrison, David; Garaj, Vanja] Brunel Univ London, Brunel Design Sch, Kingston Lane, Uxbridge UB8 3PH, Greater London, England.
C3 Brunel University
RP Bodini, A (corresponding author), Brunel Univ London, Brunel Design Sch, Kingston Lane, Uxbridge UB8 3PH, Greater London, England.
EM aimone.bodini@brunel.ac.uk
RI Bodini, Aimone/ABT-6421-2022
OI Bodini, Aimone/0000-0001-7421-2768
FU Arts and Humanities Research Council (AHRC), UK [AH/S002758/1]; UUI
   [AH/S002758/1] Funding Source: UKRI
FX This work was supported by StoryFutures: Gateway Cluster Partnership for
   Audiovisual Digital Creativity (AH/S002758/1), a research and
   development grant by the Arts and Humanities Research Council (AHRC),
   UK.; All diagrams in the paper were created by the authors.
CR Agentmaps, 2021, US
   Anderson C., 2004, WIRED MAGAZINE, P170, DOI DOI 10.3359/OZ0912041
   [Anonymous], 23 STREET R SUBWAY S
   [Anonymous], 2019, BEFORES AFTERS 2019
   Ardal DA, 2019, CVMP 2019 16 ACM SIG
   Bennett J., 2014, Proceedings of the 7th Annual International Conference on Computer Games, Multimedia and Allied Technology, P81
   Bodker K., 2004, PARTICIPATORY IT DES, DOI [10.7551/mitpress/5249.001.0001, DOI 10.7551/MITPRESS/5249.001.0001]
   Bouville RA, 2016, INT C COMPUTER GRAPH, P1
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Briand GA, 2014, INT BROADC CONV AMST
   Chemical Wedding, 2021, HEL PRO
   de Goussencourt T, 2015, LECT NOTES COMPUT SC, V9386, P883, DOI 10.1007/978-3-319-25903-1_76
   Dunlop R., 2014, Production Pipeline Fundamentals for Films and Games
   Epic Games, 2021, UNR ENG
   Giardina C, 2019, LION KING VFX TEAM O
   Google, 2021, GOOGLE DOCS
   Helzle VA, 2015, DIGITAL REPRESENTATI
   Hennink MM, 2017, QUAL HEALTH RES, V27, P591, DOI 10.1177/1049732316665344
   IEA, 2020, Tracking Industries
   Jutan MA, 2017, ACM SIGGRAPH 2017 TA, P2
   Kadner N., 2019, VIRTUAL PRODUCTION F
   Last Pixel, 2019, I MOTH VR STOR
   Leipzig A, 2014, SUNDANCE INFOGRAPHIC
   Lin IS, 2018, PROCEEDINGS OF THE 16TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2018), DOI 10.1145/3284398.3284424
   Liu MN, 2021, J MANUF SYST, V58, P346, DOI 10.1016/j.jmsy.2020.06.017
   Muender T, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188612
   MULLER MJ, 1993, COMMUN ACM, V36, P26
   QSR International, 2021, NVIVO12
   Roth E, 1993, FORREST GUMP SCRIPT
   Schuler D., 1993, Participatory Design: Principles and Practices
   Seymour M, 2018, VISUAL DISRUPTOR WHA
   Seymour M, 2020, ART LED WALL VIRTU 1
   Simonsen J, 2013, Routledge international handbook of participatory design
   Sitescape, 2021, SIT
   Spielmann S, 2018, ACM SIGGRAPH 2018 EM
   Spinuzzi C, 2005, TECH COMMUN-STC, V52, P163
   Strauss WA, 1991, HARPER PERENNIAL
   Thacker J, 2012, FMX 2012 SEARCH VIRT
   The Third Floor Inc, 2020, VIRT SET SCOUT VIRT
   Unity, 2021, Unity
   Wilkinson G, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173780
   Zimmer CA, 2017, SIGGRAPH ASIA 2017 M, P3
NR 42
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12379
EP 12400
DI 10.1007/s11042-022-13680-8
EA SEP 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000854682700008
PM 36118186
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Kaur, N
   Pandey, S
AF Kaur, Navneet
   Pandey, Shreelekha
TI Predicting clothing attributes with CNN and SURF based classification
   model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image matching; Image enhancement; Local feature; Neural network
ID NEURAL-NETWORKS; IMAGE
AB Fashion industry utilizes learning-based strategy for e-commerce applications such as apparel recognition, apparel search, and apparel attribute detection. However, apparel recognition is challenging due to variability in tags for similarly looking apparels. This work utilizes a combination of Convolutional Neural Network and Speed up Robust Feature to propose a framework for efficient apparel recognition. Research highlights that a good quality cloth image provides more information and hence better feature extraction. This work thus proposes Atmospheric Dark Light Adjustment (ADLA) technique to enhance image in the pre-processing phase of the framework. Effectiveness of the proposed integration (ADLA, SURF, and CNN) is validated by experimental results using six apparel attributes on three datasets, namely LSF, DeepFashion2, and Consumer to shop. Results obtained for various performance parameters ensure the desired accuracy. Experimental results are computed for further performance analysis using precision, recall, f-measure, and accuracy parameters. Results show improvements by nearly 4%, 10%, 6%, and 4%, respectively, for the same as compared to CNN alone. Comparison with prior mechanisms considering LSF dataset also highlights the superiority of the proposed framework. Overall, the proposed framework using ADLA with SURF-CNN enhances the performance by 4% to 10% using three fashion datasets.
C1 [Kaur, Navneet; Pandey, Shreelekha] Thapar Inst Engn & Technol, CSED, Patiala 147004, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Pandey, S (corresponding author), Thapar Inst Engn & Technol, CSED, Patiala 147004, Punjab, India.
EM nkaur_hd16@thapar.edu; shreelekha.pandey@thapar.edu
RI KAUR, NAVNEET/HMP-0723-2023
CR Bedeli M, 2018, FOREN SCI RES, V3, P219, DOI 10.1080/20961790.2018.1526251
   Chenbunyanon C., 2018, INT COMPUTER S, P190
   Damodaran S, 2018, STUDIES COMPUTATIONA, P363
   Foody GM, 2004, IEEE T GEOSCI REMOTE, V42, P1335, DOI 10.1109/TGRS.2004.827257
   Halstead MA, 2019, J VIS COMMUN IMAGE R, V58, P439, DOI 10.1016/j.jvcir.2018.12.001
   Hassaballah M, 2016, STUD COMPUT INTELL, V630, P1, DOI 10.1007/978-3-319-28854-3_1
   Huang ZH, 2018, NEUROCOMPUTING, V314, P154, DOI 10.1016/j.neucom.2018.06.063
   Jain Priyal, 2019, Information Systems Design and Intelligent Applications. Proceedings of Fifth International Conference INDIA 2018. Advances in Intelligent Systems and Computing (AISC 862), P169, DOI 10.1007/978-981-13-3329-3_16
   Jin Huang, 2019, Recent Developments in Intelligent Computing, Communication and Devices. Proceedings of International Conference on Intelligent Computing, Communication and Devices (ICCD 2017). Advances in Intelligent Systems and Computing (AISC 752), P233, DOI 10.1007/978-981-10-8944-2_28
   Lee W, 2018, LECT NOTES ARTIF INT, V11016, P241, DOI 10.1007/978-3-319-97289-3_19
   Li AN, 2015, IEEE T CIRC SYST VID, V25, P869, DOI 10.1109/TCSVT.2014.2352552
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Li Y, 2021, WIREL COMMUN MOB COM
   Li Y, 2021, WORLD WIDE WEB, V24, P1885, DOI 10.1007/s11280-021-00913-3
   Li YC, 2017, IEEE T MULTIMEDIA, V19, P1946, DOI 10.1109/TMM.2017.2690144
   Lin JY, 2021, MULTIMED TOOLS APPL, V80, P17183, DOI 10.1007/s11042-020-09009-y
   Liu S, 2014, IEEE T MULTIMEDIA, V16, P253, DOI 10.1109/TMM.2013.2285526
   Medina A, 2022, ENERGIES, V15, DOI 10.3390/en15051811
   Papegnies E., 1955, INT C COMPUTATIONAL, P8
   Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
   Sales LF, 2021, MULTIMED TOOLS APPL, V80, P25851, DOI 10.1007/s11042-021-10885-1
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Seo Y, 2019, EXPERT SYST APPL, V116, P328, DOI 10.1016/j.eswa.2018.09.022
   Shajini M, 2022, VISUAL COMPUT, V38, P3551, DOI 10.1007/s00371-021-02178-3
   Shi ZH, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0251-4
   Sun TC, 2017, IEEE T IMAGE PROCESS, V26, P4102, DOI 10.1109/TIP.2017.2710631
   Wang WG, 2018, PROC CVPR IEEE, P4271, DOI 10.1109/CVPR.2018.00449
   Xiao B, 2018, NEUROCOMPUTING, V275, P2798, DOI 10.1016/j.neucom.2017.11.057
   Yue XD, 2021, APPL INTELL, V51, P3548, DOI 10.1007/s10489-020-01950-7
   Zhang SY, 2020, IEEE T CIRC SYST VID, V30, P1051, DOI 10.1109/TCSVT.2019.2902268
   Zhou M, 2018, IEEE T BIO-MED ENG, V65, P521, DOI 10.1109/TBME.2017.2700627
NR 31
TC 1
Z9 1
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10681
EP 10701
DI 10.1007/s11042-022-13714-1
EA SEP 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000852929600007
DA 2024-07-18
ER

PT J
AU Wali, A
   Lisan, A
   Ather, H
   Qasim, M
   Abid, MU
AF Wali, Aamir
   Lisan, Aliza
   Ather, Hammad
   Qasim, Muhammad
   Abid, Muhammad Uzair
TI Application in multimedia: from camera to VR
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual scenario; User experience; Virtual reality; Paper to VR; Maze
   design; VR games; 3D modeling
ID 3D BUILDING MODELS; FP
AB This work describes a framework that allows children and domestic users to create architectural structures like mazes, houses etc., and navigate them in virtual reality (VR). The user can draw a 2D map of a maze etc. using a simple paper, pen and ruler. The application works by taking as input such a hand drawn image via gallery or camera, and then building a 3D model in VR using Unity3D. The 3D model completely follows the design of the floor plan including the placement of doors and windows. Detecting and then constructing walls, doors and windows on the fly in VR is a challenge. The user can also customize walls, windows, doors and floors. This is done by looking at the object and using the VR controller to select various options. The purpose of the framework is purely entertainment and is specifically designed for children and domestic users. From hand-drawn images on a paper to ready-to-navigate 3-D model in VR in just one click is the novelty of our work. User is completely isolated from the complexities and intricacies of programming and usage of different tools and platforms. We also extend our work from hand drawn designs to professional home blueprints and floor plans. We used fully convolutional network to extract walls from the professional floor plans with mean pixel accuracy of 97.3%. For hand-drawn designs, we were able to detect doors and windows with MAE of 0. Our wall segmentation method reported an MAE of only 1.2.
C1 [Wali, Aamir; Lisan, Aliza; Ather, Hammad; Qasim, Muhammad; Abid, Muhammad Uzair] Natl Univ Comp & Emerging Sci, Dept Comp Sci, Lahore, Pakistan.
RP Wali, A (corresponding author), Natl Univ Comp & Emerging Sci, Dept Comp Sci, Lahore, Pakistan.
EM aamir.wali@nu.edu.pk; 1145851@lhr.nu.edu.pk; 1144250@lhr.nu.edu.pk;
   1144157@nu.edu.pk; 1144036@nu.edu.pk
OI , Aamir/0009-0001-6571-6611; Ather, Hammad/0000-0002-0023-8145; Wali,
   Aamir/0000-0002-5314-6113
CR Ahmed S, 2011, PROC INT CONF DOC, P864, DOI 10.1109/ICDAR.2011.177
   [Anonymous], 2019, VIS DER IM INS VIA M
   [Anonymous], 2017, Opencv
   [Anonymous], 2018, SketchUp
   Autodesk Inc., 2020, 3DS MAX
   Autodeskcom, 2022, INV SOFTW
   Bukowski R, 1995, WALKTHRU EDITOR REAL
   Chung TM, 2018, STRATEGIES VR PROTOT
   Dalal S, 2020, PROCEDIA COMPUT SCI, V167, P562, DOI 10.1016/j.procs.2020.03.318
   de las Heras LP, 2015, INT J DOC ANAL RECOG, V18, P15, DOI 10.1007/s10032-014-0236-5
   Dodge S, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P358, DOI 10.23919/MVA.2017.7986875
   Dosch P., 2000, International Journal on Document Analysis and Recognition, V3, P102, DOI 10.1007/PL00010901
   Exxar, 2022, EXP CAD REAL
   Gai W, 2016, PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI 2016), P591, DOI 10.1145/2957265.2961824
   Gai W, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5016, DOI 10.1145/3025453.3025494
   Gimenez L, 2016, AUTOMAT CONSTR, V63, P48, DOI 10.1016/j.autcon.2015.12.008
   Halim Zahid, 2010, International Journal of Information Technology, Communications and Convergence, V1, P92, DOI 10.1504/IJITCC.2010.035229
   Horna S, 2007, GRAPP 2007: PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL GM/R, P37
   Kaminska D, 2019, INFORMATION, V10, DOI 10.3390/info10100318
   Kamppari-Miller S, 2018, VR SKETCH SHEETS PAP
   Kamppari-Miller Saara, 2017, VR Paper Prototyping
   Kurbatov V, 2019, TEMPLATES ARVR SKETC
   Kurbatov V, 2017, DRAW SKETCHES VIRTUA
   Lewis R, 1998, COMPUT AIDED DESIGN, V30, P765, DOI 10.1016/S0010-4485(98)00031-1
   Liu C, 2017, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2017.241
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Maya Ronse, 2020, MAYA
   Mcintosh J., 2019, J. Digital Landscape Architec, V1, P185
   Nebeling M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300826
   Noor M.N., 2021, P NAT C ENG COMP TEC, VVolume 8
   OpenCV, 2017, APPR POL
   OpenCV, 2017, CONV HULL
   OpenCV, 2017, BOUND RECT
   Planner5D, 2016, PLANN 5D HOM INT DES
   Racz Anett, 2018, 2018 International Conference on Advances in Computing and Communication Engineering (ICACCE), P11, DOI 10.1109/ICACCE.2018.8441714
   Rieffe C, 2006, PERS INDIV DIFFER, V40, P123, DOI 10.1016/j.paid.2005.05.013
   Roosendaal Ton, 2017, BLENDER
   Ruihong Yan, 2018, 2018 IEEE International Conference on Progress in Informatics and Computing (PIC). Proceedings, P236, DOI 10.1109/PIC.2018.8706144
   RYAN RM, 1983, J PERS SOC PSYCHOL, V45, P736, DOI 10.1037/0022-3514.45.4.736
   SketchUp, 2018, SKETCHUP
   Software SDI, 2022, NX VIRT REAL
   Statista, 2018, FOR AUGM AR VIRT REA
   Swaileh W, 2021, LECT NOTES COMPUT SC, V12821, P34, DOI 10.1007/978-3-030-86549-8_3
   Sweetser P, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364800
   Trimble Inc., 2020, SKETCHUP
   Vidil F, 2003, MOKA
   Wang W, 2020, ROOM CLASSIFICATION, DOI [10.1145/3441250.3441265, DOI 10.1145/3441250.3441265]
   Wang WL, 2020, IEEE NON-VOLATILE ME, P48, DOI [10.1145/3441250.3441265, 10.1109/nvmsa51238.2020.9188083]
   Yamasaki T, 2018, RETECH'18: PROCEEDINGS OF THE 2018 ACM WORKSHOP ON MULTIMEDIA FOR REAL ESTATE TECH, P1, DOI 10.1145/3210499.3210528
   Zhang XY, 2020, PATTERN RECOGN LETT, V130, P73, DOI 10.1016/j.patrec.2019.01.006
   Zhongguo Xu, 2021, AIPR 2021: 2021 4th International Conference on Artificial Intelligence and Pattern Recognition, P346, DOI 10.1145/3488933.3489017
   Zhu J., 2014, Comput. Des. Appl, V11, P704, DOI [10.1080/16864360.2014.914388, DOI 10.1080/16864360.2014.914388]
NR 52
TC 2
Z9 2
U1 4
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11721
EP 11751
DI 10.1007/s11042-022-13687-1
EA SEP 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000847985700001
DA 2024-07-18
ER

PT J
AU Kumar, R
   Gupta, S
   Venkatesh, KS
AF Kumar, Rupesh
   Gupta, Sumana
   Venkatesh, K. S.
TI Quadratic smoothing based video stabilization using spatio-temporal
   regularity flow
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Regularity; Stabilization; Flow curve; Quadratic smoothing; Affine
   motion parameter; Regularization
ID DIGITAL IMAGE STABILIZATION; MOTION COMPENSATION; ALGORITHM
AB Camera motion such as jitter, hand sake, vibration are the common causes of video destabilization. They appear as noise in the form of undesired motion in the video frames. In this paper, we propose a video stabilization method that uses quadratic smoothing to remove undesired camera motion. Spatio-temporal regularity flow (SPREF) model is used to estimate the affine motion parameters of video frames by minimizing the flow energy. To obtain the smoothed affine motion parameters of a frame, the minimization of motion parameters is formulated as an unconstrained optimization problem with suitable penalty term. Selection of optimal penalty term to penalize the undesired camera motion and to preserve the desired camera motion is the key idea of the proposed method. Multiple penalty terms generate multiple stabilized videos. The video with maximum interframe transform fidelity (ITF) value is chosen as the most stabilized video. We also describe a method to detect irregular video frames or segments using flow curves and perform selective stabilization of these frames. This is in addition to the stabilization of all the frames in a destabilized video. Proposed video stabilization method is tested on various videos with different scene contents and conditions, and its performance comparison is made with several recent methods. An improved performance based on subjective and objective measures establish the effectiveness of the proposed method in different environments.
C1 [Kumar, Rupesh; Gupta, Sumana; Venkatesh, K. S.] IIT Kanpur, Dept EE, Kanpur, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kanpur
RP Kumar, R (corresponding author), IIT Kanpur, Dept EE, Kanpur, Uttar Pradesh, India.
EM rupeshxav@gmail.com
CR Alatas O, 2007, IEEE T CIRC SYST VID, V17, P584, DOI 10.1109/TCSVT.2007.893832
   Battiato S, 2008, 19 INT C PATT REC IC, P1
   Battiato S, 2010, IEEE T MULTIMEDIA, V12, P622, DOI 10.1109/TMM.2010.2060474
   Boyd S.P., 2004, Convex optimization, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441]
   Chang HC, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P29, DOI 10.1109/ICME.2004.1394117
   Chen HH, 2007, IEEE T CIRC SYST VID, V17, P801, DOI 10.1109/TCSVT.2007.897113
   Chien SY, 2004, IEEE T MULTIMEDIA, V6, P732, DOI 10.1109/TMM.2004.834868
   Diego F, 2013, IEEE T MULTIMEDIA, V15, P1377, DOI 10.1109/TMM.2013.2247390
   Dong J, 2017, IEEE T CIRC SYST VID, V27, P716, DOI 10.1109/TCSVT.2016.2589860
   Ertürk S, 2003, IEEE T CONSUM ELECTR, V49, P1320, DOI 10.1109/TCE.2003.1261235
   Ertürk S, 2002, REAL-TIME IMAGING, V8, P317, DOI 10.1006/rtim.2001.0278
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Goldstein A, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2231816.2231824
   Grundmann M, 2011, PROC CVPR IEEE, P225, DOI 10.1109/CVPR.2011.5995525
   Hu FY, 2018, SIGNAL PROCESS-IMAGE, V68, P42, DOI 10.1016/j.image.2018.07.001
   Hu WC, 2018, MULTIMED TOOLS APPL, V77, P5107, DOI 10.1007/s11042-017-4369-7
   Hu WC, 2018, MULTIMED TOOLS APPL, V77, P1237, DOI 10.1007/s11042-016-4291-4
   Joshi N, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766954
   Kang S, 2017, MULTIMED TOOLS APPL, V76, P24635, DOI 10.1007/s11042-017-4647-4
   Ko SJ, 1998, IEEE T CONSUM ELECTR, V44, P617, DOI 10.1109/30.713172
   Ko SJ, 1999, IEEE T CONSUM ELECTR, V45, P598, DOI 10.1109/30.793546
   Kumar R, 2017, SIGNAL IMAGE VIDEO P, V11, P1519, DOI 10.1007/s11760-017-1115-6
   Lee KY, 2009, IEEE I CONF COMP VIS, P1397
   Li JN, 2017, IEEE T CIRC SYST VID, V27, P907, DOI 10.1109/TCSVT.2016.2515238
   Li XL, 2016, IEEE T IMAGE PROCESS, V25, P3329, DOI 10.1109/TIP.2016.2568752
   Ling Q, 2018, IEEE T CIRC SYST VID, V28, P561, DOI 10.1109/TCSVT.2016.2618934
   Litvin A, 2003, PROC SPIE, V5022, P663, DOI 10.1117/12.476436
   Liu F, 2013, IEEE I CONF COMP VIS, P73, DOI 10.1109/ICCV.2013.16
   Liu F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899408
   Liu F, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531350
   Liu SC, 2017, IEEE T IMAGE PROCESS, V26, P3291, DOI 10.1109/TIP.2017.2697759
   Liu SC, 2014, PROC CVPR IEEE, P4209, DOI 10.1109/CVPR.2014.536
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu C, 2013, IEEE T MULTIMEDIA, V15, P70, DOI 10.1109/TMM.2012.2225036
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Matsushita Y, 2006, IEEE T PATTERN ANAL, V28, P1150, DOI 10.1109/TPAMI.2006.141
   Morimoto C, 1998, INT CONF ACOUST SPEE, P2789, DOI 10.1109/ICASSP.1998.678102
   Morimoto C., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P284, DOI 10.1109/ICPR.1996.546956
   Okade M, 2016, IEEE T CIRC SYST VID, V26, P453, DOI 10.1109/TCSVT.2015.2412772
   Okade M, 2014, MULTIMED TOOLS APPL, V68, P947, DOI 10.1007/s11042-012-1095-z
   Pae DS, 2019, MULTIMED TOOLS APPL, V78, P16489, DOI 10.1007/s11042-018-6932-2
   Puglisi G, 2011, IEEE T CIRC SYST VID, V21, P1390, DOI 10.1109/TCSVT.2011.2162689
   Qu H, 2013, IEEE IMAGE PROC, P29, DOI 10.1109/ICIP.2013.6738007
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Shen Y, 2009, IEEE T CONSUM ELECTR, V55, P1714, DOI 10.1109/TCE.2009.5278047
   Son W, 2013, IEEE ICCE, P380, DOI 10.1109/ICCE.2013.6486938
   Spampinato G, 2019, MULTIMED TOOLS APPL, V78, P13787, DOI 10.1007/s11042-018-6571-7
   Tico M, 2005, IEEE INT C IM PROCES
   Wang YS, 2013, IEEE T VIS COMPUT GR, V19, P1354, DOI 10.1109/TVCG.2013.11
   Wang ZQ, 2016, MULTIMED TOOLS APPL, V75, P15939, DOI 10.1007/s11042-015-2907-8
   Yang JL, 2006, IEEE IMAGE PROC, P1545, DOI 10.1109/ICIP.2006.312645
   Yang JL, 2009, IEEE T CIRC SYST VID, V19, P945, DOI 10.1109/TCSVT.2009.2020252
   Yuan H, 2012, IEEE T MULTIMEDIA, V14, P1370, DOI 10.1109/TMM.2012.2190393
   Zhai B, 2016, MULTIMED TOOLS APPL, V75, P12173, DOI 10.1007/s11042-015-3183-3
   Zhang L, 2017, IEEE T CIRC SYST VID, V27, P225, DOI 10.1109/TCSVT.2015.2501941
NR 55
TC 0
Z9 0
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10337
EP 10366
DI 10.1007/s11042-022-13570-z
EA AUG 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000844934900004
DA 2024-07-18
ER

PT J
AU Zhu, DK
   Deng, S
   Wang, WM
   Cheng, G
   Wei, MQ
   Wang, FL
   Xie, HR
AF Zhu, Dingkun
   Deng, Sen
   Wang, Weiming
   Cheng, Gary
   Wei, Mingqiang
   Wang, Fu Lee
   Xie, Haoran
TI HDRD-Net: High-resolution detail-recovering image deraining network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HDRD-Net; Image deraining; High-resolution; Detail-recovering; Outdoor
   vision systems
ID RAIN REMOVAL
AB Image deraining aims to restore the clean scenes of rainy images, which facilitates a number of outdoor vision systems, such as autonomous driving, unmanned aerial vehicles and surveillance systems. This paper proposes a high-resolution detail-recovering image deraining network (HDRD-Net) to effectively remove rain streaks and recover lost details, as well as improving the quality of derained images. HDRD-Net consists of three sub-networks. First, we combine the residual network and Squeeze-and-Excitation block for rain streak removal. Second, we integrate the Structure Detail Context Aggregation block into the detail-recovering network to extract detail features form rainy images. Third, a dual super-resolution reconstruction network is utilized to enhance the quality of derained images. In addition, we extend the Rain100 dataset by incorporating low-resolution rainy images to construct a new Rain100++ dataset for high-resolution image deraining. Experimental results on several datasets show that HDRD-Net outperforms state-of-the-art methods in terms of rain removal, detail preservation and visual quality.
C1 [Zhu, Dingkun; Wang, Weiming; Wang, Fu Lee] Hong Kong Metropolitan Univ, Hong Kong, Peoples R China.
   [Deng, Sen; Wei, Mingqiang] Nanjing Univ Aeronaut & Astronaut, Nanjing, Peoples R China.
   [Cheng, Gary] Educ Univ Hong Kong, Hong Kong, Peoples R China.
   [Xie, Haoran] Lingnan Univ, Hong Kong, Peoples R China.
C3 Hong Kong Metropolitan University; Nanjing University of Aeronautics &
   Astronautics; Education University of Hong Kong (EdUHK); Lingnan
   University
RP Cheng, G (corresponding author), Educ Univ Hong Kong, Hong Kong, Peoples R China.
EM zhudingkun51@gmail.com; sendeng@nuaa.edu.cn; wmwang@hkmu.edu.hk;
   chengks@eduhk.hk; mqwei@nuaa.edu.cn; pwang@hkmu.edu.hk; hrxie2@gmail.com
RI Wang, Fu Lee/AAD-9782-2021; Xie, Haoran/AFS-3515-2022
OI Wang, Fu Lee/0000-0002-3976-0053; Xie, Haoran/0000-0003-0965-3617;
   Cheng, Gary/0000-0002-5614-3348
FU Research Grants Council of the Hong Kong Special Administrative Region,
   China [UGC/FDS16/E01/19]; Hong Kong Metropolitan University Research
   Grant [RD/2021/09]; One-off Special Fund from Central and Faculty Fund
   in Support of Research from 2019/20 to 2021/22 [MIT02/19-20]; Research
   Cluster Fund [RG 78/2019-2020R]; Interdisciplinary Research Scheme of
   the Dean's Research Fund 2019-20 of The Education University of Hong
   Kong [FLASS/DRF/IDS-2]; Lam Woo Research Fund of Lingnan University,
   Hong Kong [LWI20011]
FX The work described in this paper was fully supported by a grant from the
   Research Grants Council of the Hong Kong Special Administrative Region,
   China (UGC/FDS16/E01/19), Hong Kong Metropolitan University Research
   Grant (No. RD/2021/09), the One-off Special Fund from Central and
   Faculty Fund in Support of Research from 2019/20 to 2021/22
   (MIT02/19-20), the Research Cluster Fund (RG 78/2019-2020R), the
   Interdisciplinary Research Scheme of the Dean's Research Fund 2019-20
   (FLASS/DRF/IDS-2) of The Education University of Hong Kong, and the Lam
   Woo Research Fund (LWI20011) of Lingnan University, Hong Kong.
CR Anderson P.M., 2003, Power System Control and Stability., Vsecond
   Bossu J, 2011, INT J COMPUT VISION, V93, P348, DOI 10.1007/s11263-011-0421-7
   Brewer N, 2008, LECT NOTES COMPUT SC, V5342, P451, DOI 10.1007/978-3-540-89689-0_49
   Chen YL, 2013, IEEE I CONF COMP VIS, P1968, DOI 10.1109/ICCV.2013.247
   Ding XH, 2016, MULTIMED TOOLS APPL, V75, P2697, DOI 10.1007/s11042-015-2657-7
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Eigen D, 2013, IEEE I CONF COMP VIS, P633, DOI 10.1109/ICCV.2013.84
   Fu XY, 2017, PROC CVPR IEEE, P1715, DOI 10.1109/CVPR.2017.186
   Fu YH, 2011, INT CONF ACOUST SPEE, P1453
   GARG K, 2004, PROC CVPR IEEE, P528, DOI DOI 10.1109/CVPR.2004.1315077
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu XW, 2021, IEEE T IMAGE PROCESS, V30, P1759, DOI 10.1109/TIP.2020.3048625
   Hu XW, 2019, PROC CVPR IEEE, P8014, DOI 10.1109/CVPR.2019.00821
   Jain V., 2009, ADV NEURAL INFORM PR, P769, DOI DOI 10.5555/2981780.2981876
   Kang LW, 2012, IEEE T IMAGE PROCESS, V21, P1742, DOI 10.1109/TIP.2011.2179057
   Li X, 2018, LECT NOTES COMPUT SC, V11211, P262, DOI 10.1007/978-3-030-01234-2_16
   Li Y, 2016, PROC CVPR IEEE, P2736, DOI 10.1109/CVPR.2016.299
   Mu P, 2019, IEEE SIGNAL PROC LET, V26, P307, DOI 10.1109/LSP.2018.2889277
   Pan JS, 2018, PROC CVPR IEEE, P3070, DOI 10.1109/CVPR.2018.00324
   Ren WH, 2017, PROC CVPR IEEE, P2838, DOI 10.1109/CVPR.2017.303
   Santhaseelan V, 2015, INT J COMPUT VISION, V112, P71, DOI 10.1007/s11263-014-0759-8
   Sen Deng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14548, DOI 10.1109/CVPR42600.2020.01457
   Tripathi AK, 2011, IETE J RES, V57, P82, DOI 10.4103/0377-2063.78382
   Xianhui Zheng, 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P258, DOI 10.1007/978-3-642-42051-1_33
   Xu J., 2012, 2012 IEEE INT C COMP, P304
   Yang W., 2017, PROC CVPR IEEE, P1685, DOI DOI 10.1109/CVPR.2017.183
   Yang YZ, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1814, DOI 10.1145/3343031.3351149
   Yu F., 2015, ARXIV
   Yu WJ, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1795, DOI 10.1145/3343031.3350883
   Zhang H, 2020, IEEE T CIRC SYST VID, V30, P3943, DOI 10.1109/TCSVT.2019.2920407
   Zhang XP, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P461, DOI 10.1109/ICME.2006.262572
   Zhao X, 2008, P 11 JOINT C INF SCI, P382, DOI DOI 10.2991/JCIS.2008.65
   Zhu L, 2021, IEEE T CIRC SYST VID, V31, P2147, DOI 10.1109/TCSVT.2020.3022707
   Zhu L, 2017, IEEE I CONF COMP VIS, P2545, DOI 10.1109/ICCV.2017.276
NR 34
TC 1
Z9 1
U1 4
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42889
EP 42906
DI 10.1007/s11042-022-13489-5
EA AUG 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000840291300005
DA 2024-07-18
ER

PT J
AU Kumar, PMA
   Raj, LA
   Sagayam, KM
   Ram, NS
AF Kumar, P. M. Ashok
   Raj, L. Arun
   Sagayam, K. Martin
   Ram, N. Sree
TI Expression invariant face recognition based on multi-level feature
   fusion and transfer learning technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks (CNN); Face recognition; Facial
   expressions; Multilevel feature fusion; Internet of things (IoT);
   Transfer learning; VGG-face
ID NETWORK
AB Face Recognition is always considered to be one of the attractive areas of study among researchers even today, due to many of its Internet of Things (IoT) applications. Recently deep learning methods gained huge popularity due to its excellent performance in visual identification and classification challenges. However Deep networks has still lot of challenges like expression variations, limited training dataset and network training complexity, which is to be addressed in the field of face recognition. To solve the aforementioned problems, we present a new methodology based on Multi-Level Feature Fusion and Transfer Learning Convolutional Neural Network (MLFFTL-CNN). First, we construct Expression based CNN (E-CNN) classifier with fine tuning of pre-trained VGG-face model on emotion database. During the training phase, we used E-CNN features to fuse at the intermediate layers in the proposed MLFFTL-CNN, then fine-tuned the suggested MLFFTL-CNN model with Neutral/Limited datasets to recognise human faces. In the testing phase, the proposed MLFFTL-CNN model is applied on facial images containing different expressions (belonging to limited dataset) to recognize faces. Experiments were performed out on the Cohn-Kanade Dataset, which is a standard data set containing facial expressions. Our greatest classification accuracy rating in the Cohn-Kanade Dataset is 99.7%. Furthermore, Receiver Operating Characteristic (ROC) curves and Precision-Recall Curves are drawn for the proposed MLFFTL-CNN method and achieves better performance than the state of art algorithms like Light CNN [35], Deep id2 [28], Deep face [29].
C1 [Kumar, P. M. Ashok; Ram, N. Sree] KL Deemed Univ, Dept Comp Sci Engn, Vaddeswaram, Andhra Pradesh, India.
   [Raj, L. Arun] BS Abdur Rahman Univ, Sch Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Sagayam, K. Martin] Karunya Inst Technol & Sci, Dept Elect & Commun Engn, Coimbatore, Tamil Nadu, India.
C3 B. S. Abdur Rahman Crescent Institute of Science & Technology; Karunya
   Institute of Technology & Sciences
RP Kumar, PMA (corresponding author), KL Deemed Univ, Dept Comp Sci Engn, Vaddeswaram, Andhra Pradesh, India.
EM profpmashok@gmail.com; arun4u85mit@gmail.com; martinsagayam.k@gmail.com
RI L, Arun Raj/ABD-5645-2020; L, A/HZI-4043-2023; KUMAR, ASHOK/D-5535-2017
OI L, Arun Raj/0000-0001-8181-5022; KUMAR, ASHOK/0000-0002-4134-4163
CR [Anonymous], 2015, CVPR, DOI DOI 10.1109/CVPR.2015.7298642
   [Anonymous], 2015, P 2015 IEEE C COMPUT
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Cai J, 2015, SENSORS-BASEL, V15, P1071, DOI 10.3390/s150101071
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Cheng Y, 2017, IEEE INT CONF COMP V, P1924, DOI 10.1109/ICCVW.2017.227
   Choe J, 2017, IEEE INT CONF COMP V, P1940, DOI 10.1109/ICCVW.2017.229
   Du LS, 2019, IEEE SIGNAL PROC LET, V26, P390, DOI 10.1109/LSP.2019.2892236
   Ghazi MM, 2016, IEEE COMPUT SOC CONF, P102, DOI 10.1109/CVPRW.2016.20
   Guo Y, 2017, ARXIV
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He LX, 2018, PROC CVPR IEEE, P7054, DOI 10.1109/CVPR.2018.00737
   Hu JL, 2013, INT CONF ACOUST SPEE, P2342, DOI 10.1109/ICASSP.2013.6638073
   Huang GL, 2017, IEEE ICC
   Li HJ, 2016, PATTERN RECOGN, V60, P13, DOI 10.1016/j.patcog.2016.05.014
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Nielsen M. A., 2015, NEURAL NETWORKS DEEP, DOI DOI 10.1145/2939672.2945397
   Omkar P., 2015, P BRIT MACHINE VISIO
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Peng X, 2017, IEEE I CONF COMP VIS, P1632, DOI 10.1109/ICCV.2017.180
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Ranjan R, 2017, IEEE INT CONF AUTOMA, P17, DOI 10.1109/FG.2017.137
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Su Y, 2009, IEEE T IMAGE PROCESS, V18, P1885, DOI 10.1109/TIP.2009.2021737
   Sun Y, 2014, ADV NEUR IN, V27
   Sun Y, 2015, PROC CVPR IEEE, P2892, DOI 10.1109/CVPR.2015.7298907
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tiong LCO, 2019, MULTIMED TOOLS APPL, V78, P22743, DOI 10.1007/s11042-019-7618-0
   Torrey L., 2010, Transfer Learning
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Videla Lakshmi Sarvani, 2019, Smart Intelligent Computing and Applications. Proceedings of the Second International Conference on SCI 2018. Smart Innovation, Systems and Technologies (SIST 104), P135, DOI 10.1007/978-981-13-1921-1_13
   Wu X, 2018, IEEE T INF FOREN SEC, V13, P2884, DOI 10.1109/TIFS.2018.2833032
   Wu Y, 2017, IEEE INT CONF COMP V, P1933, DOI 10.1109/ICCVW.2017.228
   Xie SF, 2010, IEEE T IMAGE PROCESS, V19, P1349, DOI 10.1109/TIP.2010.2041397
   Xu Y.J., 2017, DEStech Transactions on Computer Science and Engineering
   Yang JH, 2018, IEEE ACCESS, V6, P187, DOI 10.1109/ACCESS.2017.2761898
   Yasarla R, 2019, PROC CVPR IEEE, P8397, DOI 10.1109/CVPR.2019.00860
   Yin X, 2018, FEATURE TRANSFER LEA
   Yin X, 2018, IEEE T IMAGE PROCESS, V27, P964, DOI 10.1109/TIP.2017.2765830
   Zhang ZH, 2016, ANN TRANSL MED, V4, DOI 10.3978/j.issn.2305-5839.2015.12.38
   Zhong Y, 2016, BMVC 27 BRIT MACHINE
NR 43
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37183
EP 37201
DI 10.1007/s11042-022-13538-z
EA AUG 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000839516900008
DA 2024-07-18
ER

PT J
AU Ali, NA
   El Abbassi, A
   Bouattane, O
AF Ali, Noureddine Ait
   El Abbassi, Ahmed
   Bouattane, Omar
TI Performance evaluation of spatial fuzzy C-means clustering algorithm on
   GPU for image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fuzzy C-mean; SFCM; SIMD architecture; Clustering; GPU; CUDA
AB Image processing by segmentation technique is an important phase in medical imaging such as MRI. Its objective is to analyze the different tissues in human body. In research area, Fuzzy set is one of the most successful techniques that guarantees a robust classification. Spatial FCM (SFCM); one of the fuzzy c-means variants; considers spatial information to deal with the noisy images. To reduce this iterative algorithm's execution time, a hard SIMD architecture has been planted named the Graphical Processing Unit (GPU). In this work, a great contribution has been done to diagnose, confront and implement three different parallel implementations on GPU. A parallel implementations' extensive study of SFCM entitled PSFCM using 3 x 3 window is presented, and the experiments illustrate a significant decrease in terms of running time of this algorithm known by its high complexity. The experimental results indicate that the parallel version's execution time is about 9.46 times faster than the sequential implementation on image segmentation. This gain in terms of speed-up is achieved on the Nvidia GeForce GT 740 m GPU.
C1 [Ali, Noureddine Ait; El Abbassi, Ahmed] Moulay Ismail Univ Meknes, FST Errachidia, Labo ERTTI, Meknes, Morocco.
   [Bouattane, Omar] Mohammedia Hassan II Univ Casablanca, SSDIA Lab, ENSET, Casablanca, Morocco.
C3 Moulay Ismail University of Meknes; Hassan II University of Casablanca
RP Ali, NA (corresponding author), Moulay Ismail Univ Meknes, FST Errachidia, Labo ERTTI, Meknes, Morocco.
EM aitalinoureddine@gmail.com
OI el abbassi, Ahmed/0000-0002-1149-0215
CR Aitali N, 2016, COLLOQ INF SCI TECH, P460, DOI 10.1109/CIST.2016.7805092
   Aitali N, 2015, INT C MICROELECTRON, P118, DOI 10.1109/ICM.2015.7438002
   AITALI N, 2016, IJACSA, V7
   Akgün D, 2015, COMPUT MED IMAG GRAP, V43, P53, DOI 10.1016/j.compmedimag.2015.02.009
   Al-Ayyoub M, 2015, J SUPERCOMPUT, V71, P3149, DOI 10.1007/s11227-015-1431-y
   Ali N. A., 2019, P 4 INT C BIG DATA I, P1, DOI 10.1145/3372938.3373007
   Ali NA., 2022, 2022 2 INT C INNOVAT, P1
   Ali NA, 2022, J SUPERCOMPUT, V78, P1583, DOI 10.1007/s11227-021-03928-9
   Bak S, 2022, PARALLEL COMPUT, V109, DOI 10.1016/j.parco.2021.102856
   Baúto J, 2018, EXPERT SYST APPL, V105, P77, DOI 10.1016/j.eswa.2018.03.026
   BEZDEK JC, 1987, IEEE T SYST MAN CYB, V17, P873, DOI 10.1109/TSMC.1987.6499296
   Bharadwaj B, 2021, SOFT COMPUT, V25, P14413, DOI 10.1007/s00500-021-06225-y
   Bouattane O, 2011, PARALLEL COMPUT, V37, P230, DOI 10.1016/j.parco.2011.03.001
   Bousselham A, 2018, J THERM BIOL, V71, P52, DOI 10.1016/j.jtherbio.2017.10.014
   Cao PY, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/3830285
   Cecilia JM, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20216335
   Che S, 2008, J PARALLEL DISTR COM, V68, P1370, DOI 10.1016/j.jpdc.2008.05.014
   Chuang KS, 2006, COMPUT MED IMAG GRAP, V30, P9, DOI 10.1016/j.compmedimag.2005.10.001
   Cook S, 2013, CUDA PROGRAMMING: A DEVELOPER'S GUIDE TO PARALLEL COMPUTING WITH GPUS, P1, DOI 10.1016/B978-0-12-415933-4.00001-6
   Eklund A, 2013, MED IMAGE ANAL, V17, P1073, DOI 10.1016/j.media.2013.05.008
   Elnakib A, 2011, MULTI MODALITY STATE-OF-THE-ART MEDICAL IMAGE SEGMENTATION AND REGISTRATION METHODOLOGIES, VOL II, P1, DOI 10.1007/978-1-4419-8204-9_1
   Ferraz O, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13061077
   Fritz Florian, 2020, Architecture of Computing Systems - ARCS 2020. 33rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12155), P241, DOI 10.1007/978-3-030-52794-5_18
   Haiyang Li, 2014, Journal of Software, V9, P1985, DOI 10.4304/jsw.9.8.1985-1990
   Hamida S, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/9437538
   Hassanien AE, 2019, HDB RES DEEP LEARNIN, DOI 10.4018/978-1-5225-7862-8
   Ivanovska T., 2013, PATTERN RECOGN, P674, DOI [DOI 10.1007/978-3-642-38628-2_80, 10.1007/978-3-642-38628-2_80]
   James M., 1967, PROC BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   Li Y, 2013, J COMPUT SYST SCI, V79, P216, DOI 10.1016/j.jcss.2012.05.004
   Liu LY, 2021, MED IMAGE ANAL, V74, DOI 10.1016/j.media.2021.102214
   Merjulah R, 2017, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTING AND INFORMATICS (ICICI 2017), P1055, DOI 10.1109/ICICI.2017.8365301
   Moujahid H, 2022, INTELL AUTOM SOFT CO, V32, P723, DOI 10.32604/iasc.2022.022179
   Peng H, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101871
   Petcu D, 2011, PROC SPIE, V8183, DOI 10.1117/12.898281
   Pratx G, 2011, MED PHYS, V38, P2685, DOI 10.1118/1.3578605
   Punithakumar K, 2017, IEEE ACCESS, V5, P20374, DOI 10.1109/ACCESS.2017.2755863
   Qu JH, 2017, DISCRETE DYN NAT SOC, V2017, DOI 10.1155/2017/2013673
   Reska D, 2021, MULTIMED TOOLS APPL, V80, P5087, DOI 10.1007/s11042-020-09911-5
   Rivera C, 2021, J PARALLEL DISTR COM, V151, P70, DOI 10.1016/j.jpdc.2021.02.013
   Rodriguez D, 2021, ALGORITHMS, V14, DOI 10.3390/a14100275
   Sanders J, 2010, CUDA EXAMPLE INTRO G
   Satpute N, 2020, COMPUT METH PROG BIO, V192, DOI 10.1016/j.cmpb.2020.105430
   Saxena S, 2018, 2018 FIFTH INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (IEEE PDGC), P580, DOI 10.1109/PDGC.2018.8745726
   Sharma DK, 2020, PROCEDIA COMPUT SCI, V178, P55, DOI 10.1016/j.procs.2020.11.007
   Shehab M, 2017, J SUPERCOMPUT, V73, P1929, DOI 10.1007/s11227-016-1897-2
   Singh P, 2021, EXPERT SYST APPL, V185, DOI 10.1016/j.eswa.2021.115637
   Smistad E, 2014, INT J COMPUT ASS RAD, V9, P561, DOI 10.1007/s11548-013-0956-x
   Valsalan P, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02132-6
   Wang HF, 2018, QUANT IMAG MED SURG, V8, P196, DOI 10.21037/qims.2018.03.07
   Wang L, 2018, ENG APPL ARTIF INTEL, V68, P53, DOI 10.1016/j.engappai.2017.10.023
   Wasif Mohiuddin K., 2011, 2011 18 INT C HIGH P, P1
   Xu HM, 2021, COMPUT MED IMAG GRAP, V93, DOI 10.1016/j.compmedimag.2021.101974
   Yang KH, 2017, IEEE IND ELEC, P1186, DOI 10.1109/IECON.2017.8216202
   Youssfi Mohamed, 2010, Journal of Software Engineering and Applications, V3, P11, DOI 10.4236/jsea.2010.31002
   Zhang XF, 2021, COMPUT VIS MEDIA, V7, P513, DOI 10.1007/s41095-021-0239-3
NR 55
TC 4
Z9 4
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 6787
EP 6805
DI 10.1007/s11042-022-13635-z
EA AUG 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000838552300006
PM 35968411
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Li, JY
   Hou, GJ
   Wang, GD
AF Li, Jingyi
   Hou, Guojia
   Wang, Guodong
TI Underwater image restoration using oblique gradient operator and light
   attenuation prior
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater image restoration; Oblique gradient operator; Underwater
   light attenuation prior; Scene depth
ID CONTRAST ENHANCEMENT; COLOR; WORLD
AB Underwater captured images are often degraded with low contrast, color distortion, and poor visibility caused by absorption and scattering when light travels through water. To address these issues, we propose a novel underwater image restoration method which aims at recovering the scene radiance with an accurate scene depth. Depending on the accuracy estimation of scene depth obtained by combing the oblique gradient operator and underwater light attenuation prior, the transmission map can be further precisely determined. Moreover, we utilize the quad-tree subdivision to estimate the background light by both considering smoothness and color difference. After acquiring the background light and transmission map, the scene radiance can be finally restored based on the underwater image formation model. Experiential results demonstrate that the proposed method has a good performance on dehazing, color correction and contrast enhancement. Qualitative and quantitative comparisons with several state-of-the-art methods further validate the superiority of the proposed method.
C1 [Li, Jingyi; Hou, Guojia; Wang, Guodong] Qingdao Univ, Coll Comp Sci & Technol, Qingdao 266071, Peoples R China.
C3 Qingdao University
RP Hou, GJ (corresponding author), Qingdao Univ, Coll Comp Sci & Technol, Qingdao 266071, Peoples R China.
EM hgjouc@126.com
RI WANG, YONGJIA/KFQ-4823-2024; zhong, jing/KBP-7800-2024
OI Hou, Guojia/0000-0001-6509-6259
FU National Natural Science Foundation of China [61901240]; Natural Science
   Foundation of Shandong Province, China [ZR2019BF042, ZR2019MF050];
   Marine S&T Fund of Shandong Province for Pilot National Laboratory for
   Marine Science and Technology (Qingdao) [2022QNLM050301]; China
   Scholarship Council [201908370002]; China Postdoctoral Science
   Foundation [2017 M612204]
FX The research work is partially supported by National Natural Science
   Foundation of China (No. 61901240), the Natural Science Foundation of
   Shandong Province, China (No. ZR2019BF042, ZR2019MF050), the Marine S&T
   Fund of Shandong Province for Pilot National Laboratory for Marine
   Science and Technology (Qingdao) (No.2022QNLM050301), and China
   Scholarship Council (No. 201908370002), and the China Postdoctoral
   Science Foundation (No. 2017 M612204).
CR Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Berman D, 2021, IEEE T PATTERN ANAL, V43, P2822, DOI 10.1109/TPAMI.2020.2977624
   Borkar S, 2016, 2016 INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (ICONSIP)
   Cao KM, 2018, IEEE SW SYMP IMAG, P1, DOI 10.1109/SSIAI.2018.8470347
   Carlevaris-Bianco N., 2010, OCEANS, P1, DOI DOI 10.1109/OCEANS.2010.5664428
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Ding X., 2019, ARXIV
   Drews P, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P825, DOI 10.1109/ICCVW.2013.113
   Fang YM, 2015, IEEE SIGNAL PROC LET, V22, P838, DOI 10.1109/LSP.2014.2372333
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Gao YK, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/3141478
   Garg D, 2018, MULTIMED TOOLS APPL, V77, P26545, DOI 10.1007/s11042-018-5878-8
   Gu K, 2018, IEEE T NEUR NET LEAR, V29, P1301, DOI 10.1109/TNNLS.2017.2649101
   Gu K, 2017, IEEE T IND ELECTRON, V64, P3903, DOI 10.1109/TIE.2017.2652339
   Gu K, 2017, IEEE T CYBERNETICS, V47, P4559, DOI 10.1109/TCYB.2016.2575544
   Gu K, 2016, IEEE T CYBERNETICS, V46, P284, DOI 10.1109/TCYB.2015.2401732
   Gu K, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2439035
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]
   Hou GJ, 2020, IEEE ACCESS, V8, P122078, DOI 10.1109/ACCESS.2020.3006359
   Hou GJ, 2020, MULTIMED TOOLS APPL, V79, P20199, DOI 10.1007/s11042-020-08759-z
   Hou GJ, 2019, NEUROCOMPUTING, V369, P106, DOI 10.1016/j.neucom.2019.08.041
   Huang, 2022, IEEEJ SELECTED TOPIC, P1
   Huang BX, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3103251
   Huang BX, 2021, PATTERN RECOGN, V116, DOI 10.1016/j.patcog.2021.107967
   Huang BX, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2019.115745
   JAFFE JS, 1990, IEEE J OCEANIC ENG, V15, P101, DOI 10.1109/48.50695
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li KQ, 2020, INFORM SCIENCES, V521, P422, DOI 10.1016/j.ins.2020.02.055
   Li XJ, 2022, ENG APPL ARTIF INTEL, V111, DOI 10.1016/j.engappai.2022.104759
   Li XJ, 2020, IEEE ACCESS, V8, P197448, DOI 10.1109/ACCESS.2020.3034275
   Li YJ, 2020, IET IMAGE PROCESS, V14, P4401, DOI 10.1049/iet-ipr.2019.1570
   Liu Chao, 2010, 2010 2nd International Conference on Computer Engineering and Technology (ICCET), P35, DOI 10.1109/ICCET.2010.5485339
   Liu H, 2019, MULTIMED TOOLS APPL, V78, P28919, DOI 10.1007/s11042-017-5474-3
   Liu RS, 2020, IEEE T CIRC SYST VID, V30, P4861, DOI 10.1109/TCSVT.2019.2963772
   Liu YB, 2020, IEEE ACCESS, V8, P91116, DOI 10.1109/ACCESS.2020.2994614
   Lu HM, 2020, MOBILE NETW APPL, V25, P1008, DOI 10.1007/s11036-018-1117-9
   Panetta K, 2016, IEEE J OCEANIC ENG, V41, P541, DOI 10.1109/JOE.2015.2469915
   Park E, 2020, IEEE ACCESS, V8, P157918, DOI 10.1109/ACCESS.2020.3019767
   Peng YT, 2018, IEEE T IMAGE PROCESS, V27, P2856, DOI 10.1109/TIP.2018.2813092
   Peng YT, 2017, IEEE T IMAGE PROCESS, V26, P1579, DOI 10.1109/TIP.2017.2663846
   Peng YT, 2015, IEEE IMAGE PROC, P4952, DOI 10.1109/ICIP.2015.7351749
   Qi, 2022, ARXIV
   Qi Q, 2022, IEEE T CIRC SYST VID, V32, P1133, DOI 10.1109/TCSVT.2021.3074197
   Ren WQ, 2020, INT J COMPUT VISION, V128, P240, DOI 10.1007/s11263-019-01235-8
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Sanila KH, 2019, OCEAN ELECTR, P106, DOI [10.1109/sympol48207.2019.9005301, 10.1109/SYMPOL48207.2019.9005301]
   Schechner Y. Y., 2004, PROC CVPR IEEE, P1, DOI DOI 10.1109/CVPR.2004.1315078
   Si JW, 2022, IEEE T IMAGE PROCESS, V31, P3066, DOI 10.1109/TIP.2022.3164537
   Singh D, 2019, SIGNAL PROCESS-IMAGE, V70, P131, DOI 10.1016/j.image.2018.09.011
   Song W, 2018, LECT NOTES COMPUT SC, V11164, P678, DOI 10.1007/978-3-030-00776-8_62
   Wang Y, 2018, IEEE T CIRCUITS-I, V65, P992, DOI 10.1109/TCSI.2017.2751671
   Wong SL, 2018, ADV ELECTR COMPUT EN, V18, P109, DOI 10.4316/AECE.2018.02014
   Xie JY, 2022, IEEE T CYBERNETICS, V52, P11847, DOI 10.1109/TCYB.2021.3072311
   Xue B, 2021, IEEE J-STARS, V14, P12348, DOI 10.1109/JSTARS.2021.3130238
   Yang H, 2022, IET IMAGE PROCESS, V16, P1594, DOI 10.1049/ipr2.12433
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
   Zhang SY, 2020, MULTIMED TOOLS APPL, V79, P14357, DOI 10.1007/s11042-018-6694-x
   Zhou Y, 2019, IEEE T CIRC SYST VID, V29, P907, DOI 10.1109/TCSVT.2018.2884615
NR 63
TC 4
Z9 4
U1 3
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 6625
EP 6645
DI 10.1007/s11042-022-13605-5
EA AUG 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000837148800002
DA 2024-07-18
ER

PT J
AU Meeradevi, T
   Sasikala, S
   Gomathi, S
   Prabakaran, K
AF Meeradevi, T.
   Sasikala, S.
   Gomathi, S.
   Prabakaran, K.
TI An analytical survey of textile fabric defect and shade variation
   detection system using image processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Fabric defect detection; Neural networks; Deep
   learning; Defect survey
ID NEURAL-NETWORK; SEGMENTATION; INSPECTION
AB In modern days the detection of defects in textile industries using digital image processing techniques is an emerging area of research. The faulty fabric is subjected to several image processing techniques such as preprocessing, feature identification, segmentation and classification. The detection in the fabric are identified through manual inspection which is highly difficult because of the significant number of fabric defect groups distinguished by their vagueness and ambiguity. Thus considering the effectiveness of detection and the labor cost, there is a need for automated system for the identification of fabric defects. Several techniques for detecting fabric defects and shade variation have been developed by various researchers. The aim of the paper is to present the detailed review of the techniques and algorithms developed for finding the defects and shade variation in the fabric. Totally, 79 papers have been reviewed and the results are compared to identify the best suited method for fabric defect detection. This paper compares the various techniques used by various researchers, the state-of- the-art, pros and cons of the techniques, the background of the proven findings and their detection ratio over the past three years i.e. 2017-2020. From the survey, it is analyzed that the deep learning approach gives the highest detection accuracy than other methods.
C1 [Meeradevi, T.; Sasikala, S.; Gomathi, S.; Prabakaran, K.] Kongu Engn Coll, Elect & Commun Engn, Perundurai, India.
C3 Kongu Engineering College
RP Meeradevi, T (corresponding author), Kongu Engn Coll, Elect & Commun Engn, Perundurai, India.
EM tmeeradevi@gmail.com
OI Meeradevi, Thiagarajan/0000-0003-4989-4028
FU Ministry of Science and Technology, Department of Science and
   Technology, Government of India [DST/SSTP/2018/232(G), 18521]
FX This research received funding from Ministry of Science and Technology,
   Department of Science and Technology, Government of India, under Grant
   Agreement F.No.: DST/SSTP/2018/232(G), TPN No. 18521 dated 31 March
   2019.
CR Anandan P, 2018, PROCEDIA COMPUT SCI, V133, P1056, DOI 10.1016/j.procs.2018.07.058
   Aziz MA, 2013, INT C COMM SIG PROC
   Bai FY, 2021, PARTICUOLOGY, V56, P163, DOI 10.1016/j.partic.2020.10.002
   Bandara P, 2018, INT CONF ADV ICT, P119, DOI 10.1109/ICTER.2018.8615491
   Biradar M, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, CONTROL AND AUTOMATION (ICCUBEA)
   Chandrasekaran V, 2009, ANN ALLERTON CONF, P962, DOI 10.1109/ALLERTON.2009.5394889
   Chang XZ, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/3709821
   Choi Y., 2013, INT J INFORM THEORY, V2, P1, DOI DOI 10.5121/IJIT.2014.2401
   Cui FY, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION AND LOGISTICS, VOLS 1-6, P2320, DOI 10.1109/ICAL.2008.4636554
   Deotale NT, 2019, 3D RES, V10, DOI 10.1007/s13319-019-0215-1
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Gao GS, 2017, PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P73, DOI 10.1109/ACPR.2017.37
   Guan M, 2019, INT CONF ADV CLOUD B, P297, DOI 10.1109/CBD.2019.00060
   Guan SQ, 2018, J TEXT I, V109, P1560, DOI 10.1080/00405000.2018.1434112
   Guan SQ, 2018, J TEXT I, V109, P1133, DOI 10.1080/00405000.2017.1414669
   Habib M. T., 2014, INT J FOUND COMPUT S, V4, P17, DOI DOI 10.5121/IJFCST.2014.4102
   Hamdi Azhar A., 2017, 2017 Eighth International Conference on Intelligent Computing and Information Systems (ICICIS). Proceedings, P111, DOI 10.1109/INTELCIS.2017.8260041
   Hamdi AA, 2018, PROCEEDINGS OF 2018 INTERNATIONAL CONFERENCE ON INNOVATIVE TRENDS IN COMPUTER ENGINEERING (ITCE' 2018), P130, DOI 10.1109/ITCE.2018.8316611
   Hanbay K, 2017, 2017 INTERNATIONAL ARTIFICIAL INTELLIGENCE AND DATA PROCESSING SYMPOSIUM (IDAP)
   Hanbay K, 2016, OPTIK, V127, P11960, DOI 10.1016/j.ijleo.2016.09.110
   Hanbay K, 2015, SIG PROCESS COMMUN, P735, DOI 10.1109/SIU.2015.7129932
   Hu MC, 2000, J TEXT I, V91, P420, DOI 10.1080/00405000008659518
   Huangpeng QZ, 2018, IEEE ACCESS, V6, P37965, DOI 10.1109/ACCESS.2018.2852663
   Jaafar NH., 2020, INT J ADV TRENDS COM, V9, P166, DOI [10.30534/ijatcse/2020/3091.12020, DOI 10.30534/IJATCSE/2020/3091.12020]
   Javed Ali, 2013, International Journal of Image, Graphics and Signal Processing, V5, P40, DOI 10.5815/ijigsp.2013.01.06
   Jia L, 2020, INFORM SCIENCES, V512, P964, DOI 10.1016/j.ins.2019.10.032
   Jia L, 2018, J FRANKLIN I, V355, P7764, DOI 10.1016/j.jfranklin.2018.07.005
   Jia L, 2017, NEUROCOMPUTING, V238, P84, DOI 10.1016/j.neucom.2017.01.039
   Kaynar O, 2017, 2017 INTERNATIONAL ARTIFICIAL INTELLIGENCE AND DATA PROCESSING SYMPOSIUM (IDAP)
   Khar, 2018, TRENDS TEXT ENG FASH, V3, P271, DOI [10.31031/tteft.2018.03.000555, DOI 10.31031/TTEFT.2018.03.000555]
   Kumar A, 2003, PATTERN RECOGN, V36, P1645, DOI 10.1016/S0031-3203(03)00005-0
   Kumar A, 2008, IEEE T IND ELECTRON, V55, P348, DOI 10.1109/TIE.1930.896476
   Kuo CFJ, 2003, TEXT RES J, V73, P238, DOI 10.1177/004051750307300307
   Kure N., 2017, INT C INF COMM INSTR, P1, DOI DOI 10.1109/ICOMICON.2017.8279095
   Li CL, 2019, IEEE ACCESS, V7, P83962, DOI 10.1109/ACCESS.2019.2925196
   Li CL, 2018, IEEE ACCESS, V6, P27659, DOI 10.1109/ACCESS.2018.2841055
   Li N, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/9497083
   Li YY, 2019, J TEXT I, V110, P487, DOI 10.1080/00405000.2018.1489951
   Li YD, 2017, IEEE T AUTOM SCI ENG, V14, P1256, DOI 10.1109/TASE.2016.2520955
   Li YD, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-2452-6
   Li YY, 2019, NEUROCOMPUTING, V329, P329, DOI 10.1016/j.neucom.2018.10.070
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu ZF, 2017, PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P465, DOI 10.1109/ACPR.2017.34
   Lizarraga-Morales RA, 2019, IEEE ACCESS, V7, P18042, DOI 10.1109/ACCESS.2019.2896078
   Mak KL, 2009, IMAGE VISION COMPUT, V27, P1585, DOI 10.1016/j.imavis.2009.03.007
   Miao Guan, 2019, 2019 International Conference on Communications, Information System and Computer Engineering (CISCE). Proceedings, P465, DOI 10.1109/CISCE.2019.00108
   Ngan HYT, 2011, IMAGE VISION COMPUT, V29, P442, DOI 10.1016/j.imavis.2011.02.002
   Ouyang WB, 2019, IEEE ACCESS, V7, P70130, DOI 10.1109/ACCESS.2019.2913620
   Pan ZL, 2017, 2017 IEEE 2ND ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC), P2104, DOI 10.1109/IAEAC.2017.8054389
   Peng DZ, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P113, DOI 10.1109/ICIVC.2018.8492813
   Priya S., 2011, Proceedings 2011 International Conference on Signal Processing, Communication, Computing and Networking Technologies (ICSCCN 2011), P228, DOI 10.1109/ICSCCN.2011.6024549
   Rebhi A., 2015, Journal of photonics, DOI DOI 10.1155/2015/376163
   Ren ZH, 2022, INT J PR ENG MAN-GT, V9, P661
   Sadaghiyanfam S., 2018, P EL EL COMP SCI BIO, P1
   Seker A, 2018, 2018 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND DATA PROCESSING (IDAP)
   Senthilkumar M, 2010, WOODHEAD PUBL TEXT, P125
   Shah R, 2015, INNOVATION, ENTREPRENEURSHIP, AND THE ECONOMY IN THE US, CHINA, AND INDIA: HISTORICAL PERSPECTIVES AND FUTURE TRENDS, P1
   Shi BS, 2019, IEEE ACCESS, V7, P130423, DOI 10.1109/ACCESS.2019.2939843
   Silvestre-Blanes J, 2019, AUTEX RES J, V19, P363, DOI 10.2478/aut-2019-0035
   Tian H, 2019, PROCEEDINGS OF MVA 2019 16TH INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS (MVA)
   Tilocca A, 2002, TEXT RES J, V72, P545, DOI 10.1177/004051750207200614
   Tong L, 2017, IEEE ACCESS, V5, P5947, DOI 10.1109/ACCESS.2017.2667890
   Üzen H, 2019, 2019 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND DATA PROCESSING (IDAP 2019), DOI [10.1109/idap.2019.8875886, 10.1109/idap.2019.8875890]
   Vladimir G, 2019, IEEE NW RUSS YOUNG, P2218, DOI [10.1109/EIConRus.2019.8657318, 10.1109/eiconrus.2019.8657318]
   Wang JZ, 2017, IEEE IMAGE PROC, P2776, DOI 10.1109/ICIP.2017.8296788
   Wang JP, 2018, INT CONF SIGN PROCES, P323, DOI 10.1109/ICSP.2018.8652495
   Weninger L, 2018, IEEE IMTC P, P1956
   Wijesingha D, 2018, 2018 MORATUWA ENGINEERING RESEARCH CONFERENCE (MERCON) 4TH INTERNATIONAL MULTIDISCIPLINARY ENGINEERING RESEARCH CONFERENCE, P601, DOI 10.1109/MERCon.2018.8421944
   Yapi Daniel, 2018, IEEE Transactions on Automation Science and Engineering, V15, P1014, DOI 10.1109/TASE.2017.2696748
   Yazan E, 2018, INT C ARTIFICIAL INT, P1, DOI [10.1109/IDAP.2018.8620911, DOI 10.1109/IDAP.2018.8620911]
   Zhang CM, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.6.063026
   Zhang H, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (ICCIA), P322, DOI 10.1109/CIAPP.2017.8167231
   Zhang HW, 2018, PROCEEDINGS OF 2018 IEEE 7TH DATA DRIVEN CONTROL AND LEARNING SYSTEMS CONFERENCE (DDCLS), P170, DOI 10.1109/DDCLS.2018.8516094
   Zhang J, 2018, J TEXT I, V109, P577, DOI 10.1080/00405000.2017.1361580
   Zhang KB, 2018, IEEE ACCESS, V6, P49170, DOI 10.1109/ACCESS.2018.2868059
   Zhang YH, 2011, TEXT RES J, V81, P1772, DOI 10.1177/0040517511410102
   Zhou H., 2012, INT J DIGITAL CONTEN, V6, P144, DOI [10.4156/jdcta.vol6.issue1.18, DOI 10.4156/JDCTA.VOL6.ISSUE1.18]
NR 77
TC 4
Z9 4
U1 10
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 6167
EP 6196
DI 10.1007/s11042-022-13575-8
EA AUG 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000836084200002
DA 2024-07-18
ER

PT J
AU Arora, S
   Mittal, R
   Kukreja, H
   Bhatia, MPS
AF Arora, Shefali
   Mittal, Ruchi
   Kukreja, Harshita
   Bhatia, M. P. S.
TI An evaluation of denoising techniques and classification of biometric
   images based on deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information retrieval; Biometric system; Pytorch
ID NOISE
AB A biometric system uses pattern recognition to identify an individual based on various traits such as the face, fingerprints, etc. Adverse or uncontrolled conditions can often lead to the introduction of noise in data. In this paper, we evaluate the impact of noise on the quality of images that are input into a biometric system. Further, we analyze the role of various filters in the denoising of images. The paper proposes a robust deep learning-based framework in Pytorch to classify denoised images, which is validated by evaluating performance metrics on two popular benchmarks. Our study shows that our proposed framework helps achieve state-of-the-art accuracy without any trade-off caused due to the introduction of noise in images.
C1 [Arora, Shefali; Bhatia, M. P. S.] Netaji Subhas Inst Technol, New Delhi, India.
   [Mittal, Ruchi] Ganga Inst Technol & Management, Jhajjar, Haryana, India.
   [Kukreja, Harshita] Indira Gandhi Delhi Tech Univ Women, New Delhi, India.
C3 Netaji Subhas University of Technology; Indira Gandhi Delhi Technical
   University for Women (IGDTUW)
RP Arora, S (corresponding author), Netaji Subhas Inst Technol, New Delhi, India.
EM arorashef@gmail.com; ruchi.mittal138@gmail.com;
   harshitakukreja8@gmail.com; bhatia.mps@gmail.com
OI arora, shefali/0000-0002-8839-749X
CR Abbaas F, 2020, ARXIV PREPRINT ARXIV
   Adiga V., 2019, LECT NOTES COMPUT SC, P51, DOI DOI 10.1007/978-3-030-00889-5_1
   Alonso-Fernandez F, 2012, IEEE SECUR PRIV, V10, P52, DOI 10.1109/MSP.2011.178
   Alqahtani A, 2014, P INT C IMAGE PROCES
   Angle S., 2005, UAE INT C BIOL MED P
   [Anonymous], 2012, TYPES BIOMETRIC IDEN
   [Anonymous], 2011, INT J COMPUT APPL
   Azzeh J., 2018, JOIV: International Journal on Informatics Visualization, V2, P252, DOI DOI 10.30630/JOIV.2.4.151
   Bajaj Komal, 2020, Procedia Computer Science, V171, P1535, DOI 10.1016/j.procs.2020.04.164
   Bharadwaj S, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-34
   Buades A, 2011, IMAGE PROCESS ON LIN, V1, P208, DOI 10.5201/ipol.2011.bcm_nlm
   Delac K, 2004, PROCEEDINGS ELMAR-2004: 46TH INTERNATIONAL SYMPOSIUM ELECTRONICS IN MARINE, P184
   Deshpande RG., 2018, Indonesian J. Electr. Eng. Comp. Sci., V11, P918, DOI DOI 10.11591/IJEECS.V11.I3.PP918-924
   Dorizzi B., 2005, BIOMETRICS FRONTIERS
   Dupé FX, 2009, IEEE T IMAGE PROCESS, V18, P310, DOI 10.1109/TIP.2008.2008223
   Hammod DN., 2020, INT J BIOMETRICS BIO, V13, P1
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Ilesanmi AE, 2021, COMPLEX INTELL SYST, V7, P2179, DOI 10.1007/s40747-021-00428-4
   Jain AK, 2004, INT C PATT RECOG, P935, DOI 10.1109/ICPR.2004.1334413
   Jan F, 2020, BIOCYBERN BIOMED ENG, V40, P1064, DOI 10.1016/j.bbe.2020.06.002
   Jeon W, 2018, OPT LETT, V43, P4240, DOI 10.1364/OL.43.004240
   Mahfouz A, 2017, J INF SECUR APPL, V37, P28, DOI 10.1016/j.jisa.2017.10.002
   Pandey Astitva Narayan, 2020, Innovations in Computer Science and Engineering. Proceedings of 7th ICICSE. Lecture Notes in Networks and Systems (LNNS 103), P93, DOI 10.1007/978-981-15-2043-3_12
   Pflug A, 2014, 2014 37TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1342, DOI 10.1109/MIPRO.2014.6859776
   Prabhu R., 2019, Inpainting and Denoising Challenges, P45
   Ramli DA, 2010, ADV INTEL SOFT COMPU, V85, P73
   Rathgeb C, 2008, IRIS BASED BIOMETRIC
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Russo F, 2003, IEEE T INSTRUM MEAS, V52, P1148, DOI 10.1109/TIM.2003.815989
   Saini R., 2014, International Journal of Advances in Science and Technology, V2, P24
   Santarelli A, 2011, EUR MICROW INTEGRAT, P1
   Sardy S, 2001, IEEE T SIGNAL PROCES, V49, P1146, DOI 10.1109/78.923297
   Singh A, 2014, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR.2014.364
   Soni R, 2019, MULTIMED TOOLS APPL, V78, P31757, DOI 10.1007/s11042-019-07998-z
   Soni R, 2019, APPL INTELL, V49, P1376, DOI 10.1007/s10489-018-1338-4
   Venkatesh S, 2019, INT CONF IMAG PROC
   Wagner J., 2004, 2 LANGUAGE CONVERSAT, P1
   Xu S, 2020, NEURAL NETWORKS, V123, P420, DOI 10.1016/j.neunet.2019.12.023
   Zeng JH, 2021, MATH BIOSCI ENG, V18, P1187, DOI 10.3934/mbe.2021064
   Zhang YX, 2014, NEUROCOMPUTING, V140, P299, DOI 10.1016/j.neucom.2014.03.008
NR 40
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8287
EP 8302
DI 10.1007/s11042-021-11573-w
EA JUL 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000825912900006
DA 2024-07-18
ER

PT J
AU Seyedi, S
   Navimipour, NJ
AF Seyedi, Saeid
   Navimipour, Nima Jafari
TI A fault-tolerant image processor for executing the morphology operations
   based on a nanoscale technology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Nanotechnology; Quantum-dot cellular automata;
   Morphology operations; Nano-Design; Fault-tolerant
ID DESIGN; ADDER
AB The morphology algorithms are an exciting field that provides a powerful and unified method applied to image and video processing applications. Also, they have many advantages to give manageable hardware implementations and are widely employed as parts of image processing techniques. On the other hand, Quantum-dot Cellular Automata (QCA) is a promising and novel nanotechnology that contains notable benefits against common technologies in diverse features like extremely small size, low energy loss, and high operation frequency. Besides, schematizing circuits with no info loss or fault-tolerant might be beneficial in reducing power wastage. In the present paper, we suggest a novel fault-tolerant procedure to execute the morphology operations in digital image processing based on QCA. The mentioned fault-tolerant schematization for executing the morphology operations in digital image processing is easy to build. It contains notably lower elements than Complementary Metal Oxide Semiconductor (CMOS) design. Implementation and testing of all circuits are achieved using the QCADesigner tool. The suggested fault-tolerant circuit for morphological dilation/erosion operation attains high fault-tolerant in all cases of defects.
C1 [Seyedi, Saeid] Islamic Azad Univ, Urmia Branch, Young Researcher & Elite Club, Orumiyeh, Iran.
   [Seyedi, Saeid] Islamic Azad Univ, Dept Comp Engn, Tabriz Branch, Tabriz, Iran.
   [Navimipour, Nima Jafari] Kadir Has Univ, Dept Comp Engn, Istanbul, Turkey.
C3 Islamic Azad University; Islamic Azad University; Kadir Has University
RP Navimipour, NJ (corresponding author), Kadir Has Univ, Dept Comp Engn, Istanbul, Turkey.
EM nima.navimipour@khas.edu.tr
RI Seyedi, Saeid/J-3098-2019; Jafari Navimipour, Nima/AAF-5662-2021
OI Seyedi, Saeid/0000-0001-8579-699X; Jafari Navimipour,
   Nima/0000-0002-5514-5536
CR Ahmadpour SS, 2022, J SUPERCOMPUT, V78, P1672, DOI 10.1007/s11227-021-03913-2
   [Anonymous], 1999, Morphological Image Analysis: Principles and Applications
   Bhoi BK, 2019, ADV APPL MATH SCI, V18, P893
   Chabi Amir Mokhtar, 2014, Int Sch Res Notices, V2014, P463967, DOI 10.1155/2014/463967
   Chen HX, 2021, J WEB ENG, V20, P253, DOI 10.13052/jwe1540-9589.2022
   Cho H, 2007, IEEE T NANOTECHNOL, V6, P374, DOI 10.1109/TNANO.2007.894839
   De DJIQC, 2020, REVERSIBLE PRIORITY, V1, P72
   Gin A, 1999, J APPL PHYS, V85, P8281, DOI 10.1063/1.370670
   Hasani B, 2021, IJST-T ELECTR ENG, V45, P993, DOI 10.1007/s40998-020-00395-5
   Kim CG, 2005, IEEE T IMAGE PROCESS, V14, P1503, DOI 10.1109/TIP.2005.846030
   Kumar D, 2016, MICROELECTRON J, V53, P90, DOI 10.1016/j.mejo.2016.04.004
   Lent CS, 1997, P IEEE, V85, P541, DOI 10.1109/5.573740
   Lent CS., 1993, NANOTECHNOLOGY, V4, P49, DOI [10.1088/0957-4484/4/1/004, DOI 10.1088/0957-4484/4/1/004]
   Li BB, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3124065
   Li XJ, 2020, INT J COMMUN SYST, V33, DOI 10.1002/dac.4254
   Liu H, 2023, NEURAL COMPUT APPL, V35, P12331, DOI 10.1007/s00521-020-05687-9
   Liu RJ, 2021, MOBILE NETW APPL, V26, P3, DOI 10.1007/s11036-020-01717-x
   Liu Y, 2022, FRONT NEUROROBOTICS, V16, DOI 10.3389/fnbot.2022.840594
   Liu Y, 2021, ADV POWDER TECHNOL, V32, P3885, DOI 10.1016/j.apt.2021.08.038
   Liu Y, 2021, MINER ENG, V172, DOI 10.1016/j.mineng.2021.107020
   Liu ZC, 2022, IEEE T POWER ELECTR, V37, P8767, DOI 10.1109/TPEL.2022.3153797
   Lv ZH, 2023, IEEE T IND INFORM, V19, P1176, DOI 10.1109/TII.2021.3139897
   Majeed AH, 2020, CIRCUIT WORLD, V46, P147, DOI 10.1108/CW-06-2019-0062
   Mardiris V., 2014, Cellular automata in image processing and geometry, P65
   Mardiris V A., 2016, Journal of Engineering Science and Technology Review, vol, V9.no, P25, DOI [10.25103/jestr.092.05, DOI 10.25103/JESTR.092.05]
   Meng FQ, 2022, J ELECTR ENG TECHNOL, V17, P2507, DOI 10.1007/s42835-022-01032-3
   Meyer F., 1990, Journal of Visual Communication and Image Representation, V1, P21, DOI 10.1016/1047-3203(90)90014-M
   Nejad MY, 2020, MULTIMED TOOLS APPL, V79, P26489, DOI 10.1007/s11042-020-09326-2
   Panagiotopoulos FK, 2012, LECT NOTES COMPUT SC, V7495, P554, DOI 10.1007/978-3-642-33350-7_57
   Pesaresi M, 2001, IEEE T GEOSCI REMOTE, V39, P309, DOI 10.1109/36.905239
   Ramji DR, 2020, MULTIMED TOOLS APPL, V79, P10047, DOI 10.1007/s11042-019-08091-1
   Sen B, 2014, MICROELECTRON J, V45, P1522, DOI 10.1016/j.mejo.2014.08.012
   Seyedi S, 2022, OPTIK, V251, DOI 10.1016/j.ijleo.2021.168409
   Seyedi S, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10212565
   Seyedi S, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6653
   Seyedi S, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10151806
   Seyedi S, 2021, INT J THEOR PHYS, V60, P2613, DOI 10.1007/s10773-021-04734-y
   Seyedi S, 2018, NANO COMMUN NETW, V16, P1, DOI 10.1016/j.nancom.2018.02.002
   Seyedi S, 2018, OPTIK, V158, P243, DOI 10.1016/j.ijleo.2017.12.062
   Singh R, 2021, CIRCUIT WORLD, V47, P31, DOI 10.1108/CW-10-2019-0138
   TOUGAW PD, 1994, J APPL PHYS, V75, P1818, DOI 10.1063/1.356375
   Tripathi Shiv Bhusan, 2018, Journal of Physics: Conference Series, V1039, DOI 10.1088/1742-6596/1039/1/012028
   Vankamamidi V., 2006, IEEE C NANOTECHNOLGY, P343
   Walus K, 2004, IEEE T NANOTECHNOL, V3, P26, DOI 10.1109/TNANO.2003.820815
   Wang L, 2020, MULTIMED TOOLS APPL, V79, P6661, DOI 10.1007/s11042-019-08514-z
   Xu J, 2021, ARAB J SCI ENG, V46, P11319, DOI 10.1007/s13369-021-05787-1
   Ye YX, 2022, APPL THERM ENG, V202, DOI 10.1016/j.applthermaleng.2021.117849
   Zhang N, 2022, ENERG CONVERS MANAGE, V253, DOI 10.1016/j.enconman.2021.115124
   Zhang ZY, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103261
   Zheng WF, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.613
   Zhou WJ, 2021, IEEE T IMAGE PROCESS, V30, P7790, DOI 10.1109/TIP.2021.3109518
   Zhou WJ, 2018, IEEE T IMAGE PROCESS, V27, P2086, DOI 10.1109/TIP.2018.2794207
   Zuo C, 2022, LIGHT-SCI APPL, V11, DOI 10.1038/s41377-022-00714-x
NR 53
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2489
EP 2502
DI 10.1007/s11042-022-13330-z
EA JUN 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000817041800002
DA 2024-07-18
ER

PT J
AU Sun, XX
   Pan, JS
   Weng, SW
   Hu, CC
   Chu, SC
AF Sun, Xiao-Xue
   Pan, Jeng-Shyang
   Weng, Shaowei
   Hu, Chia-Cheng
   Chu, Shu-Chuan
TI Optimization of MSFs for watermarking using DWT-DCT-SVD and fish
   migration optimization with QUATRE
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Fish migration optimization; PSNR; NC
ID IMAGE WATERMARKING; ROBUST; STEGANOGRAPHY; ALGORITHM; SCHEME
AB Nowadays, the security of information has attracted widespread attention. When multimedia information is transmitted to the receiver over the Internet, it is usually protected. As an effective means for protecting the copyright of multimedia information, digital watermarking has developed rapidly in recent years. The paper proposes a new algorithm for embedding secret data into the color cover image to obtain satisfactory imperceptibility and robustness. Specifically, a new strategy called fish migration optimization with QUasi-Affine TRansformation evolutionary Fish Migration Optimization (QTFMO) that is constructed by combing Fish Migration Optimization (FMO) into QUasi-Affine TRansformation Evolutionary (QUATRE) is proposed to select adaptively multiple scaling factors (MSFs). QTFMO learns in a matrix form based on FMO. The data is embedded into the original color image, which is decomposed by Discrete Wavelet Transform (DWT), Discrete Cosine Transform (DCT), and Single Value Decomposition (SVD). The experimental results demonstrate that our method performs well on Peak Signal to Noise Ratio (PSNR) and Normalized Correlation (NC) compared to similar watermarking algorithms.
C1 [Sun, Xiao-Xue; Pan, Jeng-Shyang; Chu, Shu-Chuan] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao, Peoples R China.
   [Weng, Shaowei] Fujian Univ Technol, Sch Informat Sci & Engn, Fuzhou, Peoples R China.
   [Hu, Chia-Cheng] Yango Univ, Coll Artificial Intelligence, Fuzhou, Peoples R China.
C3 Shandong University of Science & Technology; Fujian University of
   Technology
RP Pan, JS (corresponding author), Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao, Peoples R China.
EM xues1123@163.com; jspan@cc.kuas.edu.tw; wswweiwei@126.com;
   cchu.chiachenghu@gmail.com; scchu0803@gmail.com
RI Chu, Shu-Chuan/AFQ-6798-2022; Pan, Jeng-Shyang/AEO-3450-2022
OI Chu, Shu-Chuan/0000-0003-2117-0618; Pan, Jeng-Shyang/0000-0002-3128-9025
FU National NSF of China [61872095, 61571139, 61872128]
FX This work was supported in part by the National NSF of China under Grant
   61872095, Grant 61571139, Grant 61872128.
CR Abdallah Emad E., 2007, Proceedings Graphics Interface 2007, P327, DOI 10.1145/1268517.1268570
   Abdallah EE, 2009, SIGNAL IMAGE VIDEO P, V3, P375, DOI 10.1007/s11760-008-0079-y
   Abdallah EE, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2764466
   Abraham A., 2006, EVOLUTIONARY COMPUTA
   Ahmadi SBB, 2020, MULTIMED TOOLS APPL, V79, P1075, DOI 10.1007/s11042-019-08197-6
   [Anonymous], 2018, J INFORM HIDING MULT
   Calkins H, 2017, J ARRYTHM, V33, P369, DOI 10.1016/j.joa.2017.08.001
   Chandra DVS, 2002, 2002 45TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, CONFERENCE PROCEEDINGS, P264
   Chu SC, 2006, LECT NOTES ARTIF INT, V4099, P854
   Chu SC, 2020, J INTERNET TECHNOL, V21, P15, DOI 10.3966/160792642020012101002
   Chu SG, 2020, J NEUROSURG, V133, P1970, DOI 10.3171/2020.2.JNS191920a
   Dey N, 2013, INT J BIO-INSPIR COM, V5, P315, DOI 10.1504/IJBIC.2013.057193
   Emary E, 2015, PROCEDIA COMPUT SCI, V65, P623, DOI 10.1016/j.procs.2015.09.006
   Findik O, 2010, OPT COMMUN, V283, P4916, DOI 10.1016/j.optcom.2010.07.020
   Hu P, 2020, KNOWL-BASED SYST, V195, DOI 10.1016/j.knosys.2020.105746
   Hu P, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9214514
   Huang HC, 2009, INFORM HIDING APPL, V227
   Huang HC, 2011, INFORM SCIENCES, V181, P3379, DOI 10.1016/j.ins.2011.04.007
   Huang PC, 2019, MULTIMED TOOLS APPL, V78, P26023, DOI 10.1007/s11042-019-07795-8
   Ishtiaq M., 2010, ICIC Express Lett, V4, P1
   Jeng-Shyang Pan, 2010, Proceedings of the 2010 Fourth International Conference on Genetic and Evolutionary Computing (ICGEC 2010), P783, DOI 10.1109/ICGEC.2010.198
   Jiang B Q, 2019, J. Netw. Intell., V4, P30
   Kenndy J., 1995, P ICNN 95 INT C NEUR, P1942
   Kumsawat P, 2005, IEEE T SIGNAL PROCES, V53, P4707, DOI 10.1109/TSP.2005.859323
   Lai CC, 2011, DIGIT SIGNAL PROCESS, V21, P522, DOI 10.1016/j.dsp.2011.01.017
   Li LD, 2010, INFORM SCIENCES, V180, P2875, DOI 10.1016/j.ins.2010.04.009
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Meng ZY, 2018, KNOWL-BASED SYST, V155, P35, DOI 10.1016/j.knosys.2018.04.034
   Mirjalili S, 2016, NEURAL COMPUT APPL, V27, P495, DOI 10.1007/s00521-015-1870-7
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Nassar SS, 2016, WIRELESS PERS COMMUN, V91, P1023, DOI 10.1007/s11277-016-3387-5
   Pan J.-S., 2004, INTELLIGENT WATERMAR, V7
   Pan JS, 2021, ENG APPL ARTIF INTEL, V97, DOI 10.1016/j.engappai.2020.104049
   Pan JS, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8030333
   Pan JS, 2019, PROCESSES, V7, DOI 10.3390/pr7110845
   Pan JS, 2016, LECT NOTES ARTIF INT, V9799, P657, DOI 10.1007/978-3-319-42007-3_57
   Pan JS, 2015, MULTIMED TOOLS APPL, V74, P9191, DOI 10.1007/s11042-014-2076-1
   Pan JS, 2004, ELECTRON LETT, V40, P1409, DOI 10.1049/el:20046454
   PAN JS, 2007, INTELLIGENT MULTIMED
   Pan JS., 2020, Data Sci. Pattern Recognit, V4, P41
   Sharma S, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105696
   Song PC, 2020, APPL SOFT COMPUT, V94, DOI 10.1016/j.asoc.2020.106443
   Sun XX, 2020, INT J DISTRIB SENS N, V16, DOI 10.1177/1550147720932749
   Sverdlov Alexander, 2005, 2005 13th European Signal Processing Conference, P1
   Tsai PW, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3328, DOI 10.1109/ICMLC.2008.4620980
   Wang FH, 2007, INFORM SCIENCES, V177, P2522, DOI 10.1016/j.ins.2006.12.025
   Wang FH, 2009, STUD COMPUT INTELL, V232, P11
   Weng C.J., 2018, P INT C INTELLIGENT, P124, DOI [10.1007/978-3-030-03745-1_16, DOI 10.1007/978-3-030-03745-1_16]
   Weng SW, 2007, IEEE IMAGE PROC, P1369
   Weng SW, 2008, INT J INNOV COMPUT I, V4, P351
   Weng SW, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010049
   Weng SW, 2016, INFORM SCIENCES, V369, P144, DOI 10.1016/j.ins.2016.05.030
   Xu HC, 2018, INT J ELECTRON SECUR, V10, P79, DOI 10.1504/IJESDF.2018.089215
   Yan XH, 2020, IEEE T INF FOREN SEC, V15, P3848, DOI 10.1109/TIFS.2020.3001735
NR 54
TC 1
Z9 2
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2255
EP 2276
DI 10.1007/s11042-022-13173-8
EA JUN 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000814451100002
DA 2024-07-18
ER

PT J
AU Gu, GS
   Lu, HH
   Deng, JH
   Wang, H
   Wei, HM
   Ling, J
AF Gu, Guosheng
   Lu, Huihong
   Deng, Jiehang
   Wang, Hao
   Wei, Haomin
   Ling, Jie
TI A synergetic image encryption method based on discrete fractional random
   transform and chaotic maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic map; Discrete fractional random transform; Image encryption
ID COLOR-IMAGE; FOURIER-TRANSFORM; BLOCK CIPHER; DECOMPOSITION; 2D
AB The discrete fractional random transform (DFrRT) has excellent mathematical properties and inherent randomness feature from the Fourier Transform which makes it to be a suitable candidate for digital image encryption. However, we have found that this method has an encryption flaw of the linear property and the flaw has been analyzed in this paper. After that, we propose a synergetic encryption algorithm which combines DFrRT and chaotic maps to overcome the presented flaw in the original DFrRT. All the image correlation coefficient values between different test images have decreased from 1 to almost 0, which means the linearity between different images preserved by the original DFrRT has been effectively eliminated. Experimental results show that our proposed encryption algorithm not only maintains the merits of both the original DFrRT and the chaotic maps, but also has better cryptographic performances in terms of the key space, the key sensitivity, the plain image sensitivity, the statistical characteristics and the ability to resist common attacks.
C1 [Gu, Guosheng; Lu, Huihong; Deng, Jiehang; Wei, Haomin; Ling, Jie] Guangdong Univ Technol, Sch Comp, Guangzhou, Peoples R China.
   [Wang, Hao] Norwegian Univ Sci & Technol, Dept Comp Sci, Trondheim, Norway.
C3 Guangdong University of Technology; Norwegian University of Science &
   Technology (NTNU)
RP Deng, JH (corresponding author), Guangdong Univ Technol, Sch Comp, Guangzhou, Peoples R China.
EM dengjiehang@gdut.edu.cn; hawa@ntnu.no
RI Ling, Jie/JJF-9995-2023; Wang, Hao/B-3650-2019
OI Wang, Hao/0000-0001-9301-5989
FU Key Areas Research and Development Program of Guangdong Province
   [2019B010139002]; project of Guangzhou Science and Technology
   [201902020007, 202007010004, 201807010058]
FX This work is supported by the Key Areas Research and Development Program
   of Guangdong Province under Grant 2019B010139002, the project of
   Guangzhou Science and Technology under Grant 201902020007 , 202007010004
   , 201807010058.
CR Abanda Y, 2016, IET IMAGE PROCESS, V10, P742, DOI 10.1049/iet-ipr.2015.0244
   Abbas NA, 2016, EGYPT INFORM J, V17, P139, DOI 10.1016/j.eij.2015.10.001
   Abuturab MR, 2014, OPT LASER ENG, V58, P39, DOI 10.1016/j.optlaseng.2014.01.025
   [Anonymous], 2016, HDB APPL CRYPTOGRAPH
   Artiles JAP, 2019, SIGNAL PROCESS-IMAGE, V79, P24, DOI 10.1016/j.image.2019.08.014
   Chen BJ, 2018, IET IMAGE PROCESS, V12, P2238, DOI 10.1049/iet-ipr.2018.5440
   Chen H, 2019, OPT LASER ENG, V112, P7, DOI 10.1016/j.optlaseng.2018.08.020
   Chen H, 2017, OPT LASER ENG, V93, P1, DOI 10.1016/j.optlaseng.2017.01.005
   Chen H, 2013, OPT LASER ENG, V51, P768, DOI 10.1016/j.optlaseng.2013.01.016
   Chen W, 2013, OPT COMMUN, V286, P123, DOI 10.1016/j.optcom.2012.09.014
   Chen W, 2012, OPT EXPRESS, V20, P3853, DOI 10.1364/OE.20.003853
   Fouda JSAE, 2014, APPL SOFT COMPUT, V25, P435, DOI 10.1016/j.asoc.2014.08.059
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Kang XJ, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115670
   Lan RS, 2018, SIGNAL PROCESS, V147, P133, DOI 10.1016/j.sigpro.2018.01.026
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Liu ZJ, 2007, OPT COMMUN, V279, P285, DOI 10.1016/j.optcom.2007.07.045
   Liu ZJ, 2015, OPT LASER ENG, V68, P87, DOI 10.1016/j.optlaseng.2014.12.022
   Liu ZJ, 2005, OPT COMMUN, V255, P357, DOI 10.1016/j.optcom.2005.06.031
   Muniraj I, 2015, OPT EXPRESS, V23, P15907, DOI 10.1364/OE.23.015907
   Özkaynak F, 2018, NONLINEAR DYNAM, V92, P305, DOI 10.1007/s11071-018-4056-x
   Parvaz R, 2018, OPT LASER TECHNOL, V101, P30, DOI 10.1016/j.optlastec.2017.10.024
   Pei SC, 1997, OPT LETT, V22, P1047, DOI 10.1364/OL.22.001047
   Qu G, 2021, OPT LASER ENG, V137, DOI 10.1016/j.optlaseng.2020.106392
   Ran QW, 2015, OPT COMMUN, V348, P43, DOI 10.1016/j.optcom.2015.03.016
   Sasikaladevi N, 2020, OPT LASER TECHNOL, V127, DOI 10.1016/j.optlastec.2020.106173
   Singh P, 2017, OPT LASER ENG, V91, P187, DOI 10.1016/j.optlaseng.2016.11.022
   Song J, 2021, OPT COMMUN, V485, DOI 10.1016/j.optcom.2020.126707
   Sui LS, 2015, OPT COMMUN, V343, P140, DOI 10.1016/j.optcom.2015.01.021
   Tang YD, 2021, SIGNAL PROCESS-IMAGE, V93, DOI 10.1016/j.image.2021.116168
   Tao R, 2010, IEEE T INF FOREN SEC, V5, P734, DOI 10.1109/TIFS.2010.2068289
   Unnikrishnan G, 2000, OPT LETT, V25, P887, DOI 10.1364/OL.25.000887
   Wu XL, 2017, IEEE ACCESS, V5, P6429, DOI 10.1109/ACCESS.2017.2692043
   Xu L, 2017, OPT LASER ENG, V91, P41, DOI 10.1016/j.optlaseng.2016.10.012
   Zhang M, 2014, J SYST SOFTWARE, V98, P140, DOI 10.1016/j.jss.2014.08.066
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P2066, DOI 10.1016/j.cnsns.2012.12.012
   Zhao TY, 2016, OPT COMMUN, V376, P47, DOI 10.1016/j.optcom.2016.05.016
   Zhong Z, 2012, OPT COMMUN, V285, P18, DOI 10.1016/j.optcom.2011.08.068
   Zhou GM, 2015, NEUROCOMPUTING, V169, P150, DOI 10.1016/j.neucom.2014.11.095
NR 39
TC 0
Z9 0
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 22123
EP 22147
DI 10.1007/s11042-022-13348-3
EA JUN 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000812603300001
DA 2024-07-18
ER

PT J
AU Yang, N
   Zhang, C
   Zhang, YM
   Yang, HW
   Du, L
AF Yang, Ning
   Zhang, Chen
   Zhang, Yumo
   Yang, Haowei
   Du, Ling
TI A benchmark dataset and baseline model for co-salient object detection
   within RGB-D images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RGB-D images; Within-image co-salient object detection; Benchmark
   dataset; Unsupervised baseline method
AB Within-image co-salient object detection (wCoSOD) identifies the common and salient objects within an image, which can benefit for many applications, such as reducing information redundancy, animation synthesis, and so on. Besides, the introduction of depth information that conforms to the stereo perception of human is also more conducive to accurately detecting salient objects. Thus, in this paper, we focus on a new task from the perspective of the benchmark dataset and baseline model, i.e., within-image co-salient object detection in RGB-D images. To bridge the gap the new task and algorithm verification, we first collect a new dataset containing 240 RGB-D images and the corresponding pixel-wise ground truth. Then, we propose an unsupervised method for within-image co-salient object detection in RGB-D images. Under the constraint of depth information, our model decomposes the within-image co-salient object detection task into two parts: determining the salient object proposals; combining the similarity constraint and cluster-based constraint between different proposals to locate the co-salient object and generate the final result. The experimental results on the collected dataset demonstrate that our method achieves competitive performance both qualitatively and quantitatively.
C1 [Yang, Ning; Zhang, Chen; Zhang, Yumo; Yang, Haowei] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
   [Yang, Ning; Zhang, Chen; Zhang, Yumo; Yang, Haowei] Beijing Key Lab Adv Informat Sci & Network Techno, Beijing 100044, Peoples R China.
   [Du, Ling] Tiangong Univ, Sch Comp Sci & Technol, Tianjin 300387, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University; Tiangong
   University
RP Du, L (corresponding author), Tiangong Univ, Sch Comp Sci & Technol, Tianjin 300387, Peoples R China.
EM duling@tiangong.edu.cn
FU Beijing Nova Program [Z201100006820016]
FX This work was supported by the Beijing Nova Program under Grant
   Z201100006820016.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2014, P INT C INT MULT COM
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Cao XC, 2014, IEEE T IMAGE PROCESS, V23, P4175, DOI 10.1109/TIP.2014.2332399
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Cong RM, 2016, IEEE SIGNAL PROC LET, V23, DOI 10.1109/LSP.2016.2557347
   Cong RM, 2019, IEEE T CIRC SYST VID, V29, P2941, DOI 10.1109/TCSVT.2018.2870832
   Cong RM, 2018, IEEE T IMAGE PROCESS, V27, P568, DOI 10.1109/TIP.2017.2763819
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406
   Fang YM, 2014, IEEE J EM SEL TOP C, V4, P95, DOI 10.1109/JETCAS.2014.2298919
   Fu HZ, 2013, IEEE T IMAGE PROCESS, V22, P3766, DOI 10.1109/TIP.2013.2260166
   Gao Y, 2015, IEEE T MULTIMEDIA, V17, P359, DOI 10.1109/TMM.2015.2389616
   Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393
   Guo H, 2019, PROC CVPR IEEE, P729, DOI 10.1109/CVPR.2019.00082
   Han SY, 2006, IEEE IMAGE PROC, P3097, DOI 10.1109/ICIP.2006.313095
   He XM, 2014, PROC CVPR IEEE, P296, DOI 10.1109/CVPR.2014.45
   Jeong DJ, 2018, IEEE T IMAGE PROCESS, V27, P5866, DOI 10.1109/TIP.2018.2859752
   Ju R, 2014, IEEE IMAGE PROC, P1115, DOI 10.1109/ICIP.2014.7025222
   Kim H, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2425544
   Li CH, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376209
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu N., 2020, ARXIV201005537
   Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708
   Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7
   Piao YR, 2019, IEEE I CONF COMP VIS, P7253, DOI 10.1109/ICCV.2019.00735
   Qu LQ, 2017, IEEE T IMAGE PROCESS, V26, P2274, DOI 10.1109/TIP.2017.2682981
   Song HK, 2016, IEEE SIGNAL PROC LET, V23, P1722, DOI 10.1109/LSP.2016.2615293
   Song SY, 2019, NEUROCOMPUTING, V358, P166, DOI 10.1016/j.neucom.2019.05.009
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Xi T, 2017, IEEE T IMAGE PROCESS, V26, P3425, DOI 10.1109/TIP.2016.2631900
   Xu XM, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409070
   Ye LW, 2017, IEEE T MULTIMEDIA, V19, P1742, DOI 10.1109/TMM.2017.2693022
   Yongri Piao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9057, DOI 10.1109/CVPR42600.2020.00908
   Yu HK, 2020, IEEE T MULTIMEDIA, V22, P3051, DOI 10.1109/TMM.2020.2972165
   Zheng K, 2018, 32 AAAI C ART INT
   Zhu CB, 2017, IEEE INT CONF COMP V, P1509, DOI 10.1109/ICCVW.2017.178
   Zhu CB, 2017, IEEE INT CONF COMP V, P3008, DOI 10.1109/ICCVW.2017.355
NR 40
TC 2
Z9 2
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 35831
EP 35842
DI 10.1007/s11042-021-11555-y
EA JUN 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000804560500005
DA 2024-07-18
ER

PT J
AU Yang, YG
   Wang, BP
   Yang, YL
   Zhou, YH
   Shi, WM
   Liao, X
AF Yang, Yu-Guang
   Wang, Bao-Pu
   Yang, Yong-Li
   Zhou, Yi-Hua
   Shi, Wei-Min
   Liao, Xin
TI A visually meaningful image encryption algorithm based on adaptive 2D
   compressive sensing and chaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Compressive sensing; Visually meaningful encrypted
   image; Chaotic system
ID 2(K) CORRECTION
AB A novel visually meaningful image encryption algorithm is proposed based on adaptive 2D compressive sensing and chaotic system. The plain image is first compressed and encrypted simultaneously by adaptive 2D compressive sensing to obtain the pre-encrypted compressed image. In this process, 3D cat map is used to generate the measurement matrix and the scrambling sequence. Then, the pre-encrypted compressed image is embedded into the host image by dynamic LSB method based on 2(K) correction so as to get cipher images with higher visual quality. A four-dimensional discrete chaotic system is used for region scrambling in the embedding process in order to further improve the security of the algorithm. In the simulation tests, the plain image with the maximum size 2048 x 2048 can be compressed and embedded into a host image of size 512 x 512. The embedding ratio is better than the existing algorithms. Most importantly, our algorithm is tens or even hundreds of times more efficient than other algorithms.
C1 [Yang, Yu-Guang; Wang, Bao-Pu; Yang, Yong-Li; Zhou, Yi-Hua; Shi, Wei-Min] Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
   [Yang, Yu-Guang] Beijing Key Lab Trusted Comp, Beijing 100124, Peoples R China.
   [Liao, Xin] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
C3 Beijing University of Technology; Hunan University
RP Yang, YG (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.; Yang, YG (corresponding author), Beijing Key Lab Trusted Comp, Beijing 100124, Peoples R China.
EM yangyang7357@bjut.edu.cn
RI Liao, Xin/ITT-1021-2023; Liao, Xin/X-2736-2018
OI Liao, Xin/0000-0002-9131-0578; Liao, Xin/0000-0002-9131-0578
FU National Natural Science Foundation of China [62071015, 62171264]
FX This work was supported by the National Natural Science Foundation of
   China (Grant Nos. 62071015, 62171264).
CR [Anonymous], 1977, FEDERAL INFORM PROCE
   Armijo-Correa JO, 2020, OPT LASER TECHNOL, V127, DOI 10.1016/j.optlastec.2020.106165
   Bao L, 2015, INFORM SCIENCES, V324, P197, DOI 10.1016/j.ins.2015.06.049
   Calderbank AR, 1998, APPL COMPUT HARMON A, V5, P332, DOI 10.1006/acha.1997.0238
   Chai XL, 2021, INFORM SCIENCES, V556, P305, DOI 10.1016/j.ins.2020.10.007
   Chai XL, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107525
   Chai XL, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105837
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Chai XL, 2017, SIGNAL PROCESS, V134, P35, DOI 10.1016/j.sigpro.2016.11.016
   Chen E, 2017, INT J BIFURCAT CHAOS, V27, DOI 10.1142/S0218127417500468
   Deng J, 2017, MULTIMED TOOLS APPL, V76, P10097, DOI 10.1007/s11042-016-3600-2
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Eftekhari A, 2011, SIGNAL PROCESS, V91, P1589, DOI 10.1016/j.sigpro.2011.01.002
   Gao ZR, 2013, J VIS COMMUN IMAGE R, V24, P885, DOI 10.1016/j.jvcir.2013.06.006
   Hua ZY, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.107998
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Huo DM, 2021, OPT COMMUN, V492, DOI 10.1016/j.optcom.2021.126976
   Kanso A, 2017, OPT LASER ENG, V90, P196, DOI 10.1016/j.optlaseng.2016.10.009
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Mohimani H, 2009, IEEE T SIGNAL PROCES, V57, P289, DOI 10.1109/TSP.2008.2007606
   Musanna F, 2020, MULTIMED TOOLS APPL, V79, P25115, DOI 10.1007/s11042-020-09034-x
   National Institute of Standards and Technology, 2001, ADV ENCRYPTION STAND
   Ping P, 2019, IEEE ACCESS, V7, P170168, DOI 10.1109/ACCESS.2019.2955570
   Sun SL, 2016, INFORM PROCESS LETT, V116, P93, DOI 10.1016/j.ipl.2015.09.016
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Tuncer T, 2019, INT J AP MAT COM-POL, V29, P817, DOI 10.2478/amcs-2019-0060
   Wang H, 2019, SIGNAL PROCESS, V155, P218, DOI 10.1016/j.sigpro.2018.10.001
   Wen WY, 2020, SIGNAL PROCESS, V173, DOI 10.1016/j.sigpro.2020.107580
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xu GB, 2021, QUANTUM INF PROCESS, V20, DOI 10.1007/s11128-021-03062-8
   Yang YG, 2021, INFORM SCIENCES, V562, P304, DOI 10.1016/j.ins.2021.01.041
   Yang YG, 2021, MULTIMED TOOLS APPL, V80, P9055, DOI 10.1007/s11042-020-10149-4
   Yang YG, 2020, OPTIK, V213, DOI 10.1016/j.ijleo.2020.164422
   Yang YG, 2019, OPT LASER TECHNOL, V119, DOI 10.1016/j.optlastec.2019.105661
   Yang YG, 2018, INFORM SCIENCES, V429, P102, DOI 10.1016/j.ins.2017.11.009
   Yang YG, 2016, INFORM SCIENCES, V345, P257, DOI 10.1016/j.ins.2016.01.078
   Ye GD, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4071
   Ye GD, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107563
   Zhang YS, 2016, IEEE ACCESS, V4, P2507, DOI 10.1109/ACCESS.2016.2569421
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
   Zhou NR, 2015, OPT COMMUN, V343, P10, DOI 10.1016/j.optcom.2014.12.084
   Zhou RG, 2013, INT J THEOR PHYS, V52, P1802, DOI 10.1007/s10773-012-1274-8
   Zhu LY, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107629
NR 44
TC 15
Z9 15
U1 9
U2 84
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 22033
EP 22062
DI 10.1007/s11042-021-11656-8
EA JUN 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000805063200004
DA 2024-07-18
ER

PT J
AU Li, XH
   Wang, J
   Tan, JH
   Ji, SY
   Jia, HD
AF Li, Xiaohan
   Wang, Jun
   Tan, Jinghua
   Ji, Shiyu
   Jia, Huading
TI A graph neural network-based stock forecasting method utilizing
   multi-source heterogeneous data fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stock prediction; Graph data; Graph neural network; Multi-source data
ID RETURNS; NEWS
AB The study of the prediction of stock market volatility is of great significance to rationally control financial market risks and increase excessive investment returns and has received extensive attention from academic and commercial circles. However, as a dynamic and complex system, the stock market is affected by multiple factors and has a comprehensive capability to include complex financial data. Given that the explanatory variables of influencing factors are diverse, heterogeneous and complex, the existing intelligent algorithms have great limitations for the analysis and processing of multi-source heterogeneous data in the stock market. Therefore, this study adopts the edge weight and information transmission mechanism suitable for subgraph data to complete node screening, the gate recurrent unit (GRU) and long short-term memory (LSTM) to aggregate subgraph nodes. The compiled data contain the metapaths of three types of index data, and the introduction of the association relationship attention dimension effectively mines the implicit meanings of multi-source heterogeneous data. The metapath attention mechanism is combined with a graph neural network to complete the classification of multi-source heterogeneous graph data, by which the prediction of stock market volatility is realized. The results show that the above method is feasible for the fusion of heterogeneous stock market data and the mining of implicit semantic information of association relations. The accuracy of the proposed method for the prediction of stock market volatility in this study is 16.64% higher than that of the dimensional reduction index and 14.48% higher than that of other methods for the fusion and prediction of heterogeneous data using the same model.
C1 [Li, Xiaohan; Wang, Jun; Tan, Jinghua; Ji, Shiyu; Jia, Huading] Southwestern Univ Finance & Econ, Sch Econ Informat Engn, Chengdu 610000, Peoples R China.
C3 Southwestern University of Finance & Economics - China
RP Li, XH (corresponding author), Southwestern Univ Finance & Econ, Sch Econ Informat Engn, Chengdu 610000, Peoples R China.
EM 365092342@qq.com
RI Li, Xiaohan/GRY-1499-2022
FU National Natural Science Foundation of China (NSFC) [71873108,
   62072379]; Fundamental Research Funds for the Central Universities
   [kjcx20210103]; Financial Intelligence and Financial Engineering Key Lab
   of Sichuan Province, Jiaozi Institute of Financial Technology
   Innovation, Southwest University of Finance and Economics
   [cgzh20210204]; Research Program of Science and Technology at
   Universities of Inner Mongolia Autonomous Region [2021GG0164]; Financial
   Innovation Center of the Southwestern University of Finance and
   Economics
FX The research work is supported by the National Natural Science
   Foundation of China (NSFC) (71873108 and 62072379), Fundamental Research
   Funds for the Central Universities kjcx20210103), Financial Intelligence
   and Financial Engineering Key Lab of Sichuan Province, Jiaozi Institute
   of Financial Technology Innovation, Southwest University of Finance and
   Economics (cgzh20210204), Research Program of Science and Technology at
   Universities of Inner Mongolia Autonomous Region (2021GG0164) and
   Financial Innovation Center of the Southwestern University of Finance
   and Economics.
CR [Anonymous], 2012, ENCY CANLESTICK CHAR
   [Anonymous], 1996, International Library of Critical Writings in Economics
   [Anonymous], 2015, Irrational Exuberance: Revised and Expanded
   Arasu Arvind, 2004, P 30 INT C VER LARG, P336
   Atkins A., 2018, The Journal of Finance and Data Science, V4, P120, DOI [10.1016/j.jfds.2018.02.002, DOI 10.1016/J.JFDS.2018.02.002]
   Belov G, 2006, EUR J OPER RES, V171, P85, DOI 10.1016/j.ejor.2004.08.036
   Bruna J., 2014, ABS13126203 CORR, P1, DOI [10.48550/arXiv.1312.6203, DOI 10.48550/ARXIV.1312.6203]
   Chai L, 2020, NEUROCOMPUTING, V418, P11, DOI 10.1016/j.neucom.2020.07.073
   Chan WS, 2003, J FINANC ECON, V70, P223, DOI 10.1016/S0304-405X(03)00146-6
   Chen YJ, 2017, EXPERT SYST APPL, V80, P340, DOI 10.1016/j.eswa.2017.02.044
   De Gooijer JG, 2006, INT J FORECASTING, V22, P443, DOI 10.1016/j.ijforecast.2006.01.001
   Defferrard M, 2016, ADV NEUR IN, V29
   Ding X., 2014, EMNLP
   Ding X, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2327
   Edwards R.D., 2018, Technical analysis of stock trends
   FAMA EF, 1993, J FINANC ECON, V33, P3, DOI 10.1016/0304-405X(93)90023-5
   Fama EF, 1996, J FINANC, V51, P55, DOI 10.2307/2329302
   FAMA EF, 1992, J FINANC, V47, P427, DOI 10.2307/2329112
   FAMA EF, 1970, J FINANC, V25, P383, DOI 10.2307/2325486
   GEURTS M, 1977, J MARKETING RES, V14, P269, DOI 10.2307/3150485
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Granville J., 1960, STRATEGY DAILY STOCK
   Guo J. -Y., 2020, J SOFTWARE, V31, P156
   Huang TL, 2018, PAC-BASIN FINANC J, V49, P129, DOI 10.1016/j.pacfin.2018.04.005
   JEGADEESH N, 1993, J FINANC, V48, P65, DOI 10.1111/j.1540-6261.1993.tb04702.x
   Jiao G, 2019, J INF SYST, V1
   Kahneman D, 2003, AM ECON REV, V93, P1449, DOI 10.1257/000282803322655392
   Kim R., 2019, ARXIV PREPRINT ARXIV
   Kipf TN, 2017, INT C LEARN REPR
   Kusuma RMI, 2019, ARXIV PREPRINT ARXIV
   [李立辉 Li Lihui], 2005, [计算机工程与应用, Computer Engineering and Application], V41, P221
   Li Q, 2015, P 20 9 AAAI C ARTIFI
   Li Q, 2017, MULTIMED TOOLS APPL, V76, P12315, DOI 10.1007/s11042-016-3643-4
   Li Y., 2016, P 4 INT C LEARNING R
   Liu Jue, 2019, P 52 HAWAII INT C SY
   Liu XW, 2016, AAAI CONF ARTIF INTE, P1888
   Liu Y, 2018, P PACIFIC RIM KNOWLE
   Lo AW, 1988, REV FINANC STUD, V1, P41, DOI 10.1093/rfs/1.1.41
   Matsunaga D., 2019, ARXIV PREPRINT ARXIV
   Menon VK, 2016, P INT C DATA MINING
   Mittal A., 2012, STOCK PREDICTION USI, P15
   Qu Q., 2018, J NETWORK INFORM SEC, V004, P39
   Rojas I, 2008, NEUROCOMPUTING, V71, P519, DOI 10.1016/j.neucom.2007.07.018
   Roondiwala M., 2017, International Journal of Science and Research (IJSR), V6, P1754, DOI [10.21275/ART20172755, DOI 10.21275/ART20172755]
   Shihavuddin A, 2010, P 3 INT C ADV COMPUT, P2226
   Si J., 2013, Short Papers, V2, P24
   Tan J., 2019, P 52 HAW INT C SYST
   Tanaka-Yamawaki M, 2007, PHYSICA A, V383, P125, DOI 10.1016/j.physa.2007.04.126
   Tang H, 2003, PROCEEDINGS OF THE 7TH JOINT CONFERENCE ON INFORMATION SCIENCES, P1112
   Tsai CF, 2014, ACM TRANS MANAG INF, V5, DOI 10.1145/2591672
   Wei YC, 2017, N AM J ECON FINANC, V39, P158, DOI 10.1016/j.najef.2016.10.004
   Zhang X., 2018, KNOWL INF SYST
   Zhang X, 2018, KNOWL-BASED SYST, V143, P236, DOI 10.1016/j.knosys.2017.12.025
NR 53
TC 9
Z9 9
U1 6
U2 75
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43753
EP 43775
DI 10.1007/s11042-022-13231-1
EA MAY 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000805509400003
PM 35668823
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU AlShaikh, M
   Alzaqebah, M
   Jawarneh, S
AF AlShaikh, Muath
   Alzaqebah, Malek
   Jawarneh, Sana
TI Robust watermarking based on modified Pigeon algorithm in DCT domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; DCT; Pigeon algorithm; Robustness
ID SCHEME
AB Watermarking is one of the techniques for improving the authenticity, integrity, and safety of data. A frequency domain approach is more robust against different attacks compared to a spatial domain approach. However, watermarking approaches are characterized by imperceptibility, robustness, and capacity. The problem of finding the optimal location for embedding the watermark can be challenging and affect the performance of the techniques, but it can also be seen as a path planning problem. Our main aim is to determine the optimal region for embedding the watermark in the Discrete Cosine Transform (DCT) based watermarking approach. We employ a modified Pigeon algorithm to determine the optimal embedding path, in which two objectives are considered to determine the optimal embedding place, as well as the behavior of the algorithm is enhanced to handle the nature of the problem. Our analysis indicates that our approach is highly resistant to different attacks, highly imperceptible after embedding the watermark, and consumes less complexity in embedding and extracting.
C1 [AlShaikh, Muath] Saudi Elect Univ, Dept Comp Sci, Coll Comp & Informat, Riyadh 11673, Saudi Arabia.
   [Alzaqebah, Malek] Imam Abdulrahman Bin Faisal Univ, Dept Math, Coll Sci, POB 1982, Dammam, Saudi Arabia.
   [Alzaqebah, Malek] Imam Abdulrahman Bin Faisal Univ, Basic & Appl Sci Res Ctr, POB 1982, Dammam, Saudi Arabia.
   [Jawarneh, Sana] Imam Abdulrahman Bin Faisal Univ, Dept Comp Sci, Appl Coll, POB 1982, City Of Dammam 31441, Saudi Arabia.
C3 Saudi Electronic University; Imam Abdulrahman Bin Faisal University;
   Imam Abdulrahman Bin Faisal University; Imam Abdulrahman Bin Faisal
   University
RP AlShaikh, M (corresponding author), Saudi Elect Univ, Dept Comp Sci, Coll Comp & Informat, Riyadh 11673, Saudi Arabia.
EM m.alshaikh@seu.edu.sa; maafehaid@iau.edu.sa; sijawarneh@iau.edu.sa
RI Alzaqebah, Malek/HOH-7778-2023
OI Alzaqebah, Malek/0000-0002-3846-0673; Alshaikh,
   Muath/0000-0002-1520-9814; AlShaikh, Muath/0000-0001-5550-7659
CR Abdulrahman AK, 2019, MULTIMED TOOLS APPL, V78, P17027, DOI 10.1007/s11042-018-7085-z
   Alazzam H, 2020, EXPERT SYST APPL, V148, DOI 10.1016/j.eswa.2020.113249
   AlShaikh M., 2016, INT J COMPUT SCI INF, V14, P261
   AlShaikh M, 2016, INT J COMPUT SCI NET, V16, P62
   Begum M, 2022, J KING SAUD UNIV-COM, V34, P5856, DOI 10.1016/j.jksuci.2021.07.012
   Dai Q., 2019, INNOVATION MED HEALT, V145, P93, DOI [10.1007/978-981-13-8566-7_9, DOI 10.1007/978-981-13-8566-7_9/COVER]
   Deng YM, 2016, NONLINEAR DYNAM, V85, P97, DOI 10.1007/s11071-016-2670-z
   Duan HB, 2014, INT J INTELL COMPUT, V7, P24, DOI 10.1108/IJICC-02-2014-0005
   Gao QX, 2020, AAAI CONF ARTIF INTE, V34, P3930
   Ge FW, 2020, APPL INTELL, V50, P2800, DOI 10.1007/s10489-020-01650-2
   Goel S, 2014, 2014 INTERNATIONAL CONFERENCE ON DATA MINING AND INTELLIGENT COMPUTING (ICDMIC)
   Hemdan EE, 2021, MULTIMED TOOLS APPL, V80, P1749, DOI 10.1007/s11042-020-09769-7
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Jeruchim M. C., 1984, IEEE Journal on Selected Areas in Communications, VSAC-2, P153, DOI 10.1109/JSAC.1984.1146031
   Ko HJ, 2020, INFORM SCIENCES, V517, P128, DOI 10.1016/j.ins.2019.11.005
   Laouamer L, 2015, P 12 IEEE INT C IM S, P331
   Laouamer L, 2016, INT J ELECTRON SECUR, V8, P262, DOI 10.1504/IJESDF.2016.077451
   Li JY, 2020, MULTIMED TOOLS APPL, V79, P1373, DOI 10.1007/s11042-019-08213-9
   Pandey HM, 2014, APPL SOFT COMPUT, V24, P1047, DOI 10.1016/j.asoc.2014.08.025
   Singh AK, 2019, MULTIMED TOOLS APPL, V78, P30523, DOI 10.1007/s11042-018-7115-x
   Singh R, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2020.102734
   Singh R, 2020, IET IMAGE PROCESS, V14, P2052, DOI 10.1049/iet-ipr.2019.1059
   Sisaudia V, 2021, MULTIMED TOOLS APPL, V80, P8667, DOI 10.1007/s11042-020-10028-y
   Soni GK., 2020, SMART SYSTEMS IOT IN, P483, DOI 10.1007/978-981-13-8406-6_46
   Sun H, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (IEEE ICMA 2014), P1416, DOI 10.1109/ICMA.2014.6885907
   Sun XC, 2021, MULTIMED TOOLS APPL, V80, P13491, DOI 10.1007/s11042-020-10392-9
   Varun A., 2018, Int. J. Eng. Technol, V7, P758
   Yang CS, 2020, MULTIMED TOOLS APPL, V79, P30709, DOI 10.1007/s11042-020-08916-4
   Yoo JC, 2009, CIRC SYST SIGNAL PR, V28, P819, DOI [10.1007/s00034-009-9130-7, 10.1007/S00034-009-9130-7]
   Zear A, 2022, MULTIMED TOOLS APPL, V81, P26721, DOI 10.1007/s11042-020-10472-w
   Zhang B, 2017, IEEE ACM T COMPUT BI, V14, P97, DOI 10.1109/TCBB.2015.2443789
   Zhang XR, 2020, CMC-COMPUT MATER CON, V64, P1435, DOI 10.32604/cmc.2020.011359
NR 32
TC 4
Z9 4
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 3033
EP 3053
DI 10.1007/s11042-022-13233-z
EA MAY 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000800087800001
DA 2024-07-18
ER

PT J
AU Deng, L
AF Deng, Li
TI The influence of curvature and proportion on emotional preference for
   human-machine interface design
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Product design; Aesthetics; Emotional preference; Curvature; Proportion
ID AESTHETIC PREFERENCE; INDIVIDUAL-DIFFERENCES; PRODUCT APPEARANCE;
   DIMENSIONS; NOVELTY; TYPICALITY; RESPONSES; AMYGDALA; SHAPE; FORM
AB Previous studies had found that people preferred curved visual objects. This study aimed to explore the relationship between curvature and proportion of human-machine interface and emotional preference based on Kansei Engineering. First, through the survey, the five groups of target emotional images of human-machine interface were deduced: Safe - Dangerous, Rigorous - Lively, Masculine - Feminine, Cold - Warm, and Soft - Hard. Secondly, different curvature and proportion levels were used as stimuli to explore their influence on emotional preference. Participants in the experiment interacted with the prototype of human-machine interface samples, and provide Likert scale scores about emotional preference for each sample. Then, based on analysis of variance and factor analysis, the subjects' perception to the evaluated interface was revealed. In Study 1, one-way analysis of variance studied the influence of curvature levels of human-machine interface on emotional preference. The results showed that curvature was positively correlated with the emotions of safe, lively, feminine, warm, and soft, while curvature was negatively correlated with the emotions of dangerous, rigorous, masculine, cold, and hard. In Study 2, one-way analysis of variance studied the influence of the proportion of length to width of human-machine interface on emotional preference. The results showed that the proportion affected Safe - Dangerous, Rigorous - Lively, Masculine - Feminine, and Cold - Warm, but not Soft - Hard. In Study 3, a two-way analysis of variance was conducted with Serious - Relaxed as target emotions, and the curvature and proportion were changed at the same time. The results showed no interaction between curvature and proportion, and people's perception of curvature change was stronger than proportion. Therefore, designers should pay more attention to curvature design than the proportion of length to width of human-machine interface, and use curvature design to meet the consumers' emotional needs, to increase aesthetic pleasure.
C1 [Deng, Li] Southwest Petr Univ, Minist Educ, Key Lab Oil & Gas Equipment, Chengdu 610500, Peoples R China.
   [Deng, Li] Southwest Petr Univ, Sch Mechatron Engn, Chengdu 610500, Peoples R China.
C3 Southwest Petroleum University; Southwest Petroleum University
RP Deng, L (corresponding author), Southwest Petr Univ, Minist Educ, Key Lab Oil & Gas Equipment, Chengdu 610500, Peoples R China.; Deng, L (corresponding author), Southwest Petr Univ, Sch Mechatron Engn, Chengdu 610500, Peoples R China.
EM dengli@swpu.edu.cn
FU National Natural Science Foundation of China [51905458]; Open Research
   Subject of Research Center of Industrial Design [GYSJ2019-003];
   Sub-project of National Key Research and Development Program
   [2018YFC0310201-08]
FX This project is supported by National Natural Science Foundation of
   China (Grant No. 51905458); Open Research Subject of Research Center of
   Industrial Design (Grant No. GYSJ2019-003) and Sub-project of National
   Key Research and Development Program (Grant No. 2018YFC0310201-08).
CR Adolphs R, 2008, CURR OPIN NEUROBIOL, V18, P166, DOI 10.1016/j.conb.2008.06.006
   Akhtaruzzaman Md., 2011, INT J ARTS VOL, V1, P1, DOI [10.5923/j.arts.20110101.01, DOI 10.5923/J.ARTS.20110101.01]
   Al-Samarraie H, 2018, COGN TECHNOL WORK, V20, P337, DOI 10.1007/s10111-018-0470-6
   Bar M, 2007, NEUROPSYCHOLOGIA, V45, P2191, DOI 10.1016/j.neuropsychologia.2007.03.008
   Bar M, 2006, PSYCHOL SCI, V17, P645, DOI 10.1111/j.1467-9280.2006.01759.x
   Berlyne DavidE., 1974, STUDIES NEW EXPT AES, P1
   BERLYNE DE, 1970, PERCEPT PSYCHOPHYS, V8, P279, DOI 10.3758/BF03212593
   Blijlevens J, 2017, PSYCHOL AESTHET CREA, V11, P86, DOI 10.1037/aca0000098
   Blijlevens J, 2013, INT J DES, V7, P55
   Blijlevens J, 2012, BRIT J PSYCHOL, V103, P44, DOI 10.1111/j.2044-8295.2011.02038.x
   Blijlevens J, 2009, INT J DES, V3, P27
   Bloch PH, 2003, J CONSUM RES, V29, P551, DOI 10.1086/346250
   Chuang MC, 2001, INT J IND ERGONOM, V27, P233, DOI 10.1016/S0169-8141(00)00053-6
   Creusen MEH, 2005, J PROD INNOVAT MANAG, V22, P63, DOI 10.1111/j.0737-6782.2005.00103.x
   Deng L, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/9815937
   Elam Kimberly., 2001, Geometry of Design / Studies in Proportion and Composition
   Hekkert P, 2003, BRIT J PSYCHOL, V94, P111, DOI 10.1348/000712603762842147
   Hekkert P., 2006, PSYCHOL SCI, V48, P157
   Ho CH, 2016, INT J DES, V10, P17
   Hsiao KA, 2006, INT J IND ERGONOM, V36, P553, DOI 10.1016/j.ergon.2005.11.009
   Hsu SH, 2000, INT J IND ERGONOM, V25, P375, DOI 10.1016/S0169-8141(99)00026-8
   Hu MC, 2020, ERGONOMICS, V63, P563, DOI 10.1080/00140139.2020.1735528
   [黄丹妮 Huang Danni], 2014, [机械设计, Journal of Machine Design], V31, P120
   Hung WK, 2012, INT J DES, V6, P81
   Jung JY., 2017, KOREANS PREF PROPORT, V30, P5
   Kapkin E, 2018, INT J IND ERGONOM, V67, P259, DOI 10.1016/j.ergon.2018.05.009
   Karana E, 2008, 27TH COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, VOL 2, PTS A AND B 2007, P471
   Kim W, 2019, APPL ERGON, V74, P145, DOI 10.1016/j.apergo.2018.08.014
   Krippendorff K., 1984, INNOVATION J IND DES, V3, P4
   Leder H, 2005, APPL COGNITIVE PSYCH, V19, P603, DOI 10.1002/acp.1088
   Leder H, 2011, PERCEPTION, V40, P649, DOI 10.1068/p6845
   Liu C.H., 1997, Metaphor and Symbol, V12, P135, DOI [10.1207/s15327868ms1202_3, DOI 10.1207/S15327868MS1202_3]
   Mohanty, 2013, INT J ADV PSYCHOL, V2, P19
   Mohanty SN, 2014, PSYCHOL REP, V115, P91, DOI 10.2466/20.04.PR0.115c16z2
   Moshagen M, 2010, INT J HUM-COMPUT ST, V68, P689, DOI 10.1016/j.ijhcs.2010.05.006
   Mugge R, 2009, DESIGN STUD, V30, P287, DOI 10.1016/j.destud.2008.10.002
   Murray EA, 2007, TRENDS COGN SCI, V11, P489, DOI 10.1016/j.tics.2007.08.013
   Ngo DCL, 2003, INFORM SCIENCES, V152, P25, DOI 10.1016/S0020-0255(02)00404-8
   Norman D.A., 2004, EMOTIONAL DESIGN WHY
   Qiu YY, 2013, ABSTR APPL ANAL, DOI 10.1155/2013/814912
   [尚淼 SHANG Miao], 2009, [包装工程, Packaging Engineering], V30, P135
   Sieu B, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041133
   Silvera DH, 2002, J BEHAV DECIS MAKING, V15, P189, DOI 10.1002/bdm.410
   Silvia P. J., 2009, EMPIR STUD ARTS, V27, P25, DOI [10.2190/EM.27.1.b, DOI 10.2190/EM.27.1.B, https://doi.org/10.2190/EM.27.1.b]
   Strohmeier P, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3781, DOI 10.1145/2858036.2858537
   Troncoso XG., 2010, J VISION, V6, P717, DOI [10.1167/6.6.717, DOI 10.1167/6.6.717]
   Velasco C, 2016, FOOD QUAL PREFER, V52, P17, DOI 10.1016/j.foodqual.2016.03.005
   Veryzer RW, 1998, J CONSUM RES, V24, P374
   Wang Y., 2017, PACKAGE ENG, V38, P216
   Westerman SJ, 2013, FOOD QUAL PREFER, V27, P8, DOI 10.1016/j.foodqual.2012.05.007
   Westerman SJ, 2012, PSYCHOL MARKET, V29, P595, DOI 10.1002/mar.20546
   You HC, 2007, DESIGN STUD, V28, P23, DOI 10.1016/j.destud.2006.07.002
   [周蕾 Zhou Lei], 2013, [计算机辅助设计与图形学学报, Journal of Compute-Aided Design and Graphics], V25, P758
   [朱丽萍 Zhu Liping], 2010, [包装工程, Packaging Engineering], V31, P51
NR 54
TC 2
Z9 2
U1 16
U2 51
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43581
EP 43611
DI 10.1007/s11042-022-12835-x
EA MAY 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000802317700003
DA 2024-07-18
ER

PT J
AU Majeed, A
   Beg, MO
   Arshad, U
   Mujtaba, H
AF Majeed, Adil
   Beg, Mirza Omer
   Arshad, Umair
   Mujtaba, Hasan
TI Deep-EmoRU: mining emotions from roman urdu text using deep learning
   ensemble
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Roman Urdu; Emotion detection; Roman Urdu corpus; Text classification
ID SENTIMENT ANALYSIS
AB Detecting emotions play a vital role in our lives. In various ways, people convey their feelings, i.e., facial expressions, movements, speech, and text. This study aims to classify the emotions from Roman Urdu's text. Much research has previously been done on different emotion detection languages, but there is minimal work done in Roman Urdu. There is also a need to explore Roman Urdu, as it is the most widely used social media site for communication. The absence of a benchmark corpus for emotion detection from text is a significant problem for Roman Urdu because language assets are essential for various tasks of natural language processing (NLP). The emotional analysis has many practical applications, such as optimizing product quality, dialog systems, investment patterns, and mental health. In this research, we build a corpus of 18k sentences collected from different domains and annotate it with six other classes to concentrate on the emotional polarity of the Roman Urdu text. We also proposed a Deep-EmoRU model for emotion detection from Roman Urdu text. Our proposed model is based on Long short-term memory (LSTM) and Convolutional neural network (CNN) feature learners. We applied different baseline algorithms like LSTM, Adaboost, XGboost, Random Forest, MLP, SVM, Decision tree, and KNN on our corpus. After experimentation and evaluation, the results showed that our model achieves a better F-measure score than LSTM, KNN, SVM, Adaboost, XGboost, MLP, Decision tree, and Random Forest. We achieve an accuracy of 82.2% and an F-measure of 0.82 on Emotion Detection for Roman Urdu.
C1 [Majeed, Adil] Riphah Int Univ, Dept Software Engn & Comp Sci, Islamabad, Pakistan.
   [Beg, Mirza Omer; Arshad, Umair; Mujtaba, Hasan] Natl Univ Comp & Emerging Sci, Dept Comp Sci, Islamabad, Pakistan.
RP Majeed, A (corresponding author), Riphah Int Univ, Dept Software Engn & Comp Sci, Islamabad, Pakistan.
EM adil.majeed@riphah.edu.pk; omer.beg@nu.edu.pk; umair.arshad@nu.edu.pk;
   hasan.mujtaba@nu.edu.pk
RI Arshad, Usman/CAI-6902-2022
OI Arshad, Usman/0000-0001-5312-4523
CR Abdullah M, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P835, DOI 10.1109/ICMLA.2018.00134
   Agrawal A, 2012, 2012 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY (WI-IAT 2012), VOL 1, P346, DOI 10.1109/WI-IAT.2012.170
   Bothe C, 2019, P 13 INT WORKSHOP SE, P261
   Carstensen LL, 2000, J PERS SOC PSYCHOL, V79, P644, DOI 10.1037//0022-3514.79.4.644
   Cassell J., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P413, DOI 10.1145/192161.192272
   Crowston K, 2012, INT J SOC RES METHOD, V15, P523, DOI 10.1080/13645579.2011.625764
   Fathy S, 2017, INT J INF RETR RES, V7, P32, DOI 10.4018/IJIRR.2017010103
   Gaind B, 2019, ARXIV 190108458
   Ghulam H, 2019, PROCEDIA COMPUT SCI, V147, P131, DOI 10.1016/j.procs.2019.01.202
   Gilani DIS, 2009, PREFERRED MEDIUM COM
   Hasan M, 2019, INT J DATA SCI ANAL, V7, P35, DOI 10.1007/s41060-018-0096-z
   Kanwal S, 2020, ACM T ASIAN LOW-RESO, V19, DOI 10.1145/3329710
   Li BH, 2017, FRONT INFORM TECH EL, V18, P86, DOI 10.1631/FITEE.1601885
   LIANG Y, 2012, P 13 CHIN C CHIN LEX, P122
   Lu C-Y, 2010, P IEEE INT C COMP SC
   Mahmood Z, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102233
   Majeed A, 2020, 2020 35TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING WORKSHOPS (ASEW 2020), P125, DOI 10.1145/3417113.3423375
   Mehmood K, 2020, ACM T ASIAN LOW-RESO, V19, DOI 10.1145/3329709
   Mohammad S., 2014, P 5 WORKSH COMP APPR
   Mukhtar N, 2018, EXPERT SYST, V35, DOI 10.1111/exsy.12317
   Mukhtar N, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418510011
   Nargis GZ, 2016, GENERATING EMOTION O
   Rafique A, 2019, MEHRAN UNIV RES J EN, V38, P463, DOI 10.22581/muet1982.1902.20
   Seyeditabari A, 2018, ARXIV 180600674
   Shen Y, 2009, 2009 1ST IEEE SYMPOSIUM ON WEB SOCIETY, PROCEEDINGS, P71, DOI 10.1109/SWS.2009.5271711
   Shivhare SN, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION & AUTOMATION (ICCCA), P52, DOI 10.1109/CCAA.2015.7148343
   Strapparava C, 2008, APPLIED COMPUTING 2008, VOLS 1-3, P1556
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zahid R, 2020, 2020 35TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING WORKSHOPS (ASEW 2020), P138, DOI 10.1145/3417113.3423377
NR 29
TC 9
Z9 9
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43163
EP 43188
DI 10.1007/s11042-022-13147-w
EA MAY 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000800825900002
DA 2024-07-18
ER

PT J
AU Bhattacharya, S
   Borah, S
   Mishra, BK
   Mondal, A
AF Bhattacharya, Sudipta
   Borah, Samarjeet
   Mishra, Brojo Kishore
   Mondal, Atreyee
TI Emotion detection from multilingual audio using deep analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Convolution neural network; Speech; Emotion detection;
   RAVDESS; EmoDb; Emo-vo; MFCC
ID RECOGNITION; SPEECH; FEATURES
AB Human emotion detection from multiple languages is a very challenging job. In this work, we have used language emotional databases of various languages such as - Ryerson-Audio-Visual database (RAVDESS), Berlin Database (EmoDb) and Italian Database (Emo-Vo) which are in English, German and Italian languages respectively. The proposed model extract MFCC, chroma, Tonnetz, Contrast from the raw audio file, which is further taken as input in the CNN model to identify emotions correctly. We are not using any visual representation of sound only direct from natural sound data. An extensive comparison is made with some of the previous approaches on emotion detection from speech. The experimental result shows that; the proposed model has successfully worked with all the selected databases with higher accuracy. The same also has been tested with the augmented database. We secure 70.46% for RAVDESS, 70.37% Emo-Db and 73.47% for Emo-Vo in the initial database and best model work in the augmented database. However, test with Original test dataset, secured 96.53% in RAVDESS 96.22% in Emo-Db and Emo-Vo 96.11% respectively. Multilingual Emotion detection, a state of art model, has been discussed with an accuracy of 97.89%. The proposed model is a speaker-independent as well as language-independent emotion detection system.
C1 [Bhattacharya, Sudipta; Mishra, Brojo Kishore] GIET Univ, Sch Comp Engn SOCE, Gunupur, India.
   [Borah, Samarjeet] Sikkim Manipal Univ, Dept Comp Applicat, SMIT, Rangpo, Sikkim, India.
   [Mondal, Atreyee] Techno India Coll Technol, Dept Informat Technol, Kolkata, India.
C3 GIET University; Sikkim Manipal University; Sikkim Manipal Institute of
   Technology
RP Borah, S (corresponding author), Sikkim Manipal Univ, Dept Comp Applicat, SMIT, Rangpo, Sikkim, India.
EM sudipta.bhattacharya@giet.edu; samarjeetborah@gmail.com;
   bkmishra@giet.edu; atreyee.shakshi@gmail.com
RI Mishra, Brojo Kishore Kishore/M-2190-2015; Borah, Samarjeet/C-9801-2013
OI Mishra, Brojo Kishore Kishore/0000-0002-7836-052X; BHATTACHARYA,
   SUDIPTA/0000-0001-9778-0506; Borah, Samarjeet/0000-0001-9304-3525
CR Ahuja R, 2019, INT J AMBIENT COMPUT, V10, P60, DOI 10.4018/IJACI.2019070104
   Akçay MB, 2020, SPEECH COMMUN, V116, P56, DOI 10.1016/j.specom.2019.12.001
   Ali MNY, 2019, INT J AMBIENT COMPUT, V10, P92, DOI 10.4018/IJACI.2019070106
   Alsharif MH, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12010088
   Atreyee K., 2017, 2017 INT C WIRELESS
   Badshah AM, 2017, 2017 INTERNATIONAL CONFERENCE ON PLATFORM TECHNOLOGY AND SERVICE (PLATCON), P125
   Bellamkonda S, 2020, INT J AMBIENT COMPUT, V11, P48, DOI 10.4018/IJACI.2020010103
   Benzebouchi NE, 2019, J EXP THEOR ARTIF IN, V31, P841, DOI 10.1080/0952813X.2019.1653383
   Bharati Puja, 2020, Computational Intelligence in Pattern Recognition. Proceedings of CIPR 2019. Advances in Intelligent Systems and Computing (AISC 999), P657, DOI 10.1007/978-981-13-9042-5_56
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   Costantini G, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3501
   Dangol R, 2020, MULTIMED TOOLS APPL, V79, P32917, DOI 10.1007/s11042-020-09693-w
   Demircan S, 2018, NEURAL COMPUT APPL, V29, P59, DOI 10.1007/s00521-016-2712-y
   Dey N., 2018, DIRECTION ARRIVAL ES
   Dey N, 2012, ARXIV PREPRINT ARXIV
   Dey N., 2012, 2012 IEEE INT C COMP, pp. 1, DOI [10.1109/ICCIC.2012.6510173, DOI 10.1109/ICCIC.2012.6510173]
   Dey N, 2018, Direction of arrival estimation and localization of multi-speech sources, P49
   Dey N., 2018, DIRECTION ARRIVAL ES, P23
   Haider F, 2021, COMPUT SPEECH LANG, V65, DOI 10.1016/j.csl.2020.101119
   Huang ZW, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P801, DOI 10.1145/2647868.2654984
   Ingryd P., 2018, SEMISUPERVISED MODEL
   Issa D, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101894
   Jiang DN, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P113, DOI 10.1109/ICME.2002.1035731
   Jouni P., 2014, 2014 IEEE INT C ACOU
   Kadiri SR, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1324
   Kalita Dhruba Jyoti, 2020, Social Networking and Computational Intelligence. Proceedings of SCI-2018. Lecture Notes in Networks and Systems (LNNS 100), P243, DOI 10.1007/978-981-15-2071-6_20
   Lampropoulos A. S., 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P98, DOI 10.1109/IIH-MSP.2012.29
   Latif S, 2019, INT CONF AFFECT, DOI [10.1109/acii.2019.8925513, 10.1109/ACII.2019.8925513]
   Leong AS, 2018, SPRBRIEF ELECT, P35, DOI 10.1007/978-3-319-65614-4_3
   Lim W, 2016, ASIAPAC SIGN INFO PR, DOI 10.1109/APSIPA.2016.7820699
   Livi S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193508
   Luengo I, 2010, IEEE T MULTIMEDIA, V12, P490, DOI 10.1109/TMM.2010.2051872
   McFee B., 2015, P 14 PYTH SCI C, P18, DOI [DOI 10.25080/MAJORA-7B98E3ED-003, 10.25080/Majora-7b98e3ed-003]
   Mignot R., 2019, Trans. Int. Soc. Music Inf. Retr, V2, P97, DOI DOI 10.5334/TISMIR.26
   Mirri S, 2020, COMPUTATION, V8, DOI 10.3390/computation8030074
   Popova AS, 2018, STUD COMPUT INTELL, V736, P117, DOI 10.1007/978-3-319-66604-4_18
   Robel A., 2005, 8th International Conference on Digital Audio Effects, DAFx 2005 Proceedings, P30
   Robel A., 2003, PROC INT COMPUTER MU, P247
   Sen S., 2019, Audio Process. Speech Recognit.: Concepts, Tech. Res. Overviews, P13, DOI [10.1007/978-981-13-6098-5_2, DOI 10.1007/978-981-13-6098-5_2]
   Sen S., 2019, Asian J Pregnancy Childbirth, V2, P1
   Shegokar P., 2016, 10 INT C SIGNAL PROC, P1
   Sidorov M, 2016, J SIB FED UNIV-MATH, V9, P518, DOI 10.17516/1997-1397-2016-9-4-518-523
   Sinith MS, 2015, PROCEEDINGS OF THE 2015 IEEE RECENT ADVANCES IN INTELLIGENT COMPUTATIONAL SYSTEMS (RAICS), P139, DOI 10.1109/RAICS.2015.7488403
   Wang KX, 2015, IEEE T AFFECT COMPUT, V6, P69, DOI 10.1109/TAFFC.2015.2392101
   Weisskirchen N, 2017, INT CONF AFFECT, P50, DOI 10.1109/ACIIW.2017.8272585
   Wu SQ, 2011, SPEECH COMMUN, V53, P768, DOI 10.1016/j.specom.2010.08.013
   Yang N, 2017, INT J SPEECH TECHNOL, V20, P27, DOI 10.1007/s10772-016-9364-2
   Yüncü E, 2014, INT C PATT RECOG, P773, DOI 10.1109/ICPR.2014.143
   Zeng YN, 2019, MULTIMED TOOLS APPL, V78, P3705, DOI 10.1007/s11042-017-5539-3
   Zhang BQ, 2016, INT CONF ACOUST SPEE, P5805, DOI 10.1109/ICASSP.2016.7472790
   Zhao JF, 2019, BIOMED SIGNAL PROCES, V47, P312, DOI 10.1016/j.bspc.2018.08.035
NR 51
TC 8
Z9 8
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 41309
EP 41338
DI 10.1007/s11042-022-12411-3
EA MAY 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000800827600002
DA 2024-07-18
ER

PT J
AU Dubey, D
   Tomar, GS
AF Dubey, Deepika
   Tomar, Geetam Singh
TI BPSO based neural network approach for content-based face retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biogeography particle swarm optimization (BPSO); Neural network (NN);
   Particle swarm plus optimization (PSO); Genetic algorithms (GA);
   content-based image retrieval (CBIR); hue-saturation-value (HSV)
ID BIOGEOGRAPHY-BASED OPTIMIZATION; ANT COLONY OPTIMIZATION; PARTICLE SWARM
   OPTIMIZATION; SEARCH ALGORITHM; SEGMENTATION; CONVERGENCE; RECOGNITION;
   DESIGN; MODELS; IMAGES
AB This study presents Biogeography Particle Swarm Optimization with Neural Network, which is based on Content-Based Image Retrieval and is used to solve face-related problems during face matching. A new approach is deployed called Content-Based Face Retrieval. In Content-Based Face Retrieval, face images are retrieved based on low-level features like colour and texture. A new learning method of migration of biogeographic swarm intelligence, based on Particle Swarm Optimization to cut off the local optima has been introduced. Biogeography Particle Swarm Optimization is easy to set the neural network's weights and threshold. Biogeography Particle Swarm Optimization based on Neural Network uses the fitness function as a comparison between query and database pictures. Usually, the similarity measure function depends on colour and texture features. A colour histogram is used to determine an image's colour feature, and filters are reused to obtain texture features. The proposed method estimates the quality check and introduces tests on the FEI dataset.
C1 [Dubey, Deepika] Uttrakhand Tech Univ, Dept Comp Sci & Engn, Dehra Dun 248007, Uttarakhand, India.
   [Tomar, Geetam Singh] Rajkiya Engn Coll, Dept Elect & Commun Engn, Sonbhadra 231206, India.
C3 Uttarakhand Technical University
RP Tomar, GS (corresponding author), Rajkiya Engn Coll, Dept Elect & Commun Engn, Sonbhadra 231206, India.
EM deepika.sa1304@grnail.com; gstomar@ieee.org
RI Tomar, Geetam/O-6745-2015
OI Tomar, Geetam/0000-0002-0246-1527
CR Ababneh J, 2015, INT J INTELL COMPUT, V8, P28, DOI 10.1108/IJICC-01-2014-0003
   Abdull Hamed H. N., 2008, J TEKNOL, V49, P13, DOI 10.11113/jt.v49.194
   Adhikari R, 2011, IND INT C ART INT II, P15
   Alzu'bi A, 2015, J VIS COMMUN IMAGE R, V32, P20, DOI 10.1016/j.jvcir.2015.07.012
   [Anonymous], 2009, INT J COMPUT SCI INF
   Ayvaz MT, 2009, ENG OPTIMIZ, V41, P1119, DOI 10.1080/03052150902926835
   Bisi M., 2020, 2020 IEEE 4 C INF CO, P1, DOI DOI 10.1109/CICT51604.2020.9311921
   Bulbule SS, 2019, TENCON IEEE REGION, P2519, DOI 10.1109/tencon.2019.8929301
   Celik C, 2017, PATTERN RECOGN, V68, P1, DOI 10.1016/j.patcog.2017.03.006
   Chang YP, 2010, EXPERT SYST APPL, V37, P5415, DOI 10.1016/j.eswa.2010.01.015
   Chatterjee A, 2012, ENG APPL ARTIF INTEL, V25, P1698, DOI 10.1016/j.engappai.2012.02.007
   Chen X, 2017, SOFT COMPUT, V21, P7519, DOI 10.1007/s00500-016-2307-7
   Clerc M, 2002, IEEE T EVOLUT COMPUT, V6, P58, DOI 10.1109/4235.985692
   Dengiz B, 2010, IIE TRANS, V42, P273, DOI 10.1080/07408170903039836
   Ergezer M, 2009, IEEE SYS MAN CYBERN, P1009, DOI 10.1109/ICSMC.2009.5346043
   Feng QX, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/353969
   Garg S, 2014, SADHANA-ACAD P ENG S, V39, P533, DOI 10.1007/s12046-014-0244-7
   Gudivada VN, 1997, INFORM PROCESS MANAG, V33, P427, DOI 10.1016/S0306-4573(97)00007-1
   Guo WA, 2017, NEURAL COMPUT APPL, V28, P1909, DOI 10.1007/s00521-016-2179-x
   Guo WA, 2014, ENG OPTIMIZ, V46, P1465, DOI 10.1080/0305215X.2013.854349
   Hanmandlu M, 2013, NEUROCOMPUTING, V120, P235, DOI 10.1016/j.neucom.2012.09.043
   Hill T, 1996, MANAGE SCI, V42, P1082, DOI 10.1287/mnsc.42.7.1082
   Ho CK, 2009, APPL ARTIF INTELL, V23, P570, DOI 10.1080/08839510903161139
   Hordri NF., 2013, INT J ADV SOFT COMPU, V5, P16
   Innocente MS, 2011, P 2011 INT C SWARM I, P12
   Jain R, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P1970, DOI 10.1109/RTEICT.2016.7808181
   Jamil N, 2001, IEEE INMIC 2001: IEEE INTERNATIONAL MULTI TOPIC CONFERENCE 2001, PROCEEDINGS, P277, DOI 10.1109/INMIC.2001.995351
   Jha Girish K., 2009, Proceedings 2009 International Joint Conference on Neural Networks (IJCNN 2009 - Atlanta), P1422, DOI 10.1109/IJCNN.2009.5178707
   Kaipravan M, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON DATA MINING AND ADVANCED COMPUTING (SAPIENCE), P170, DOI 10.1109/SAPIENCE.2016.7684169
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Khehra BS., 2017, J I ENG INDIA B, V98, P189, DOI [10.1007/s40031-016-0226-8, DOI 10.1007/S40031-016-0226-8]
   Kobayashi M, 2021, IEEE T NEUR NET LEAR, V32, P2274, DOI 10.1109/TNNLS.2020.2995413
   Liao TW, 2010, APPL SOFT COMPUT, V10, P1188, DOI 10.1016/j.asoc.2010.05.007
   Marinakis Y, 2010, ENG APPL ARTIF INTEL, V23, P463, DOI 10.1016/j.engappai.2010.02.002
   Marinakis Y, 2010, EXPERT SYST APPL, V37, P1446, DOI 10.1016/j.eswa.2009.06.085
   Mo HW, 2015, NEUROCOMPUTING, V148, P91, DOI 10.1016/j.neucom.2012.07.060
   Mo HW, 2010, LECT NOTES COMPUT SC, V6145, P405
   Niknam T, 2010, APPL ENERG, V87, P327, DOI 10.1016/j.apenergy.2009.05.016
   Niu Q, 2014, ENERG CONVERS MANAGE, V86, P1173, DOI 10.1016/j.enconman.2014.06.026
   PalupiRini D., 2011, INT J COMPUTER APPL, V14, P19, DOI [10.5120/1810-2331, DOI 10.5120/IJAIS-3651]
   Panchal VK, 2011, P 2011 3 INT C EL CO, P2832
   Pandey S, 2010, INT CON ADV INFO NET, P400, DOI 10.1109/AINA.2010.31
   Peng YX, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/9464593
   Rahmati SHA, 2012, INT J ADV MANUF TECH, V58, P1115, DOI 10.1007/s00170-011-3437-9
   Rane V.A., 2013, International Journal of Innovative Research and Development, V2, P8
   Ratyal NI, 2015, COMPUT ELECTR ENG, V46, P241, DOI 10.1016/j.compeleceng.2015.06.007
   Rodan A., 2016, INT J COMMUN NETW SY, V9, P19, DOI DOI 10.4236/IJCNS.2016.91002
   Savsani P, 2014, APPL SOFT COMPUT, V21, P542, DOI 10.1016/j.asoc.2014.03.011
   Siegel B, 2020, IEEE SENSOR LETT, V4, DOI 10.1109/LSENS.2020.3007880
   Simon D, 2011, EVOL COMPUT, V19, P167, DOI 10.1162/EVCO_a_00018
   Simon D, 2011, IEEE T SYST MAN CY B, V41, P299, DOI 10.1109/TSMCB.2010.2051149
   Simon D, 2009, IEEE SYS MAN CYBERN, P991, DOI 10.1109/ICSMC.2009.5346058
   Simon D, 2008, IEEE T EVOLUT COMPUT, V12, P702, DOI 10.1109/TEVC.2008.919004
   Trelea IC, 2003, INFORM PROCESS LETT, V85, P317, DOI 10.1016/S0020-0190(02)00447-7
   Wang XH, 2013, OPTIK, V124, P5447, DOI 10.1016/j.ijleo.2013.03.124
   Wang XG, 2016, NEUROCOMPUTING, V207, P387, DOI 10.1016/j.neucom.2016.04.046
   Yan WZ, 2012, IEEE T NEUR NET LEAR, V23, P1028, DOI 10.1109/TNNLS.2012.2198074
   Yang GP, 2013, APPL INTELL, V39, P132, DOI 10.1007/s10489-012-0398-0
   Yogesh CK, 2017, EXPERT SYST APPL, V69, P149, DOI 10.1016/j.eswa.2016.10.035
   Yu B, 2009, EUR J OPER RES, V196, P171, DOI 10.1016/j.ejor.2008.02.028
   Zhang GQ, 1998, INT J FORECASTING, V14, P35, DOI 10.1016/S0169-2070(97)00044-7
   Zhang NA, 2018, INT CONF INFO SCI, P364, DOI 10.1109/ICIST.2018.8426154
   Zhang P, 2012, IET IMAGE PROCESS, V6, P1014, DOI 10.1049/iet-ipr.2010.0497
NR 63
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 41271
EP 41293
DI 10.1007/s11042-022-13208-0
EA MAY 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000797788600001
DA 2024-07-18
ER

PT J
AU Peng, C
   Liu, YK
   Yuan, XP
   Chen, Q
AF Peng, Cheng
   Liu, Yikun
   Yuan, Xinpan
   Chen, Qing
TI Research of image recognition method based on enhanced
   inception-ResNet-V2
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Feature extraction; Image classification; Convolutional
   neural network
AB In order to improve the accuracy of CNN (convolutional neural network) in image classification, an enhanced Inception-ResNet-v2 model based on CNN is designed through the comparative study and analysis of the structure of classification model. This paper proposes to use multi-scale depthwise separable convolution to replace the convolution structure in Inception-ResNet-v2 model, which can reduce the amount of model parameters and extract features under different receptive fields. At the same time, this paper establishes channel filtering module based on global information comparison to filter and join channels, which realizes the effective extraction of features. Finally, through data enhancement, batch normalization and learning rate adjustment, the effect of the model used in this paper is better than most other models in each dataset, and the accuracy rate can reach 94.8%.
C1 [Peng, Cheng; Liu, Yikun; Yuan, Xinpan; Chen, Qing] Hunan Univ Technol, Sch Comp Sci, Zhuzhou, Hunan, Peoples R China.
   [Peng, Cheng] Cent South Univ, Sch Automat, Changsha, Peoples R China.
C3 Hunan University of Technology; Central South University
RP Yuan, XP (corresponding author), Hunan Univ Technol, Sch Comp Sci, Zhuzhou, Hunan, Peoples R China.
EM chengpeng@csu.edu.cn; Liuyikun1113@163.com; xpyuanfly@163.com;
   qingchen@hut.edu.cn
OI Yuan, XinPan/0000-0001-9509-0755
FU Natural Science Foundation of China [61871432, 61771492]; Natural
   Science Foundation of Hunan Province [2020JJ4275, 2019JJ6008,
   2019JJ60054]; National College Students' research based learning and
   innovation experimental project [201811535012]; Research based learning
   and innovative experiment project for college students in Hunan Province
FX This work is supported by Natural Science Foundation of China (No.
   61871432, No. 61771492), the Natural Science Foundation of Hunan
   Province (No.2020JJ4275, No.2019JJ6008, and No.2019JJ60054), National
   College Students' research based learning and innovation experimental
   project(No.201811535012), and Research based learning and innovative
   experiment project for college students in Hunan
   Province(No.S201911535027).
CR Can S., 2020, INFORM TECHNOL R & D, V44, P33
   [郭瑞琴 Guo Ruiqin], 2019, [同济大学学报. 自然科学版, Journal of Tongji University. Natural Science], V47, P1216
   Hao C., 2021, COMP ENG APPL, V57, P130
   He X., 2020, AUTOM INF ENG, V41, P16
   Jingzhi, WUHAN ZHICHENG TIMES
   Kewen L., 2020, COMPUT SYST APPL, V29, P266
   Lin CC, 2022, IEEE ACM T COMPUT BI, V19, P1285, DOI 10.1109/TCBB.2020.3003445
   Linlin L, 2021, COMP ENG APPL, V19
   McNeely-White D, 2020, COGN SYST RES, V59, P312, DOI 10.1016/j.cogsys.2019.10.004
   Peisen Y, 2021, J AGR MACHINERY, V110
   Qiaohong C, 2020, J ZHEJIANG U ENG SCI, V54
   Rahimzadeh Mohammad, 2020, Inform Med Unlocked, V19, P100360, DOI 10.1016/j.imu.2020.100360
   Shen R., 2020, Journal of Heihe University, V11, P181
   Wenqian D, 2021, COMP ENG APPL, P110
   Xia L, 2020, PLOS ONE, V15
   Xu X, 2021, COMPUT APPL, V19
   Yan Z., 2020, CHIN J REHAB THEORY, V26, P643
   Yang H, 2020, STUDY SMALL SAMPLE M
   Yu H., 2020, LAB RES EXPLOR, V39, P28
   Zou W, 2020, NAVIG CONTROL, V19, P106, DOI [DOI 10.3969/J.ISSN.1674-5558.2020.02.015, 10.3969/j.issn.1674-5558.2020.02.015]
NR 20
TC 11
Z9 11
U1 4
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34345
EP 34365
DI 10.1007/s11042-022-12387-0
EA MAY 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000795177900010
DA 2024-07-18
ER

PT J
AU Zhai, XY
   Wang, J
AF Zhai, Xiao-Ying
   Wang, Jian
TI A multi-server biometric authentication scheme based on extended chaotic
   map for telecare medical information system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE TMIS; Chebyshev chaotic map; Biometric; Authentication; Revocation and
   re-registration; BAN
ID SECURE AUTHENTICATION; KEY AGREEMENT; PROTOCOL
AB Telemedicine Information System (TMIS) is a platform for data communication and exchange between patients and medical servers via the Internet. Recently, Lee et al. proposed a ticket-based multi-server biometric authentication scheme using extended chaotic maps for TMIS, which enables legal participants to directly perform authentication and communication, and can effectively avoid the problem of third-party bandwidth overload. In this paper, we analyze this scheme and point out that it is vulnerable to offline password guessing attack and known session-specific temporary information attack. Besides, its scheme does not provide the user revocation function when the smart card is lost/stolen or the user's identity authentication information is leaked, which also makes it insecure against other attacks such as impersonation attack. Meanwhile, this scheme does not provide the server to re-register with the same identity when the server's private key is leaked. To this end, we pertinently propose a multi-server biometric authentication scheme based on extended chaotic mapping and fuzzy verification factor applied to TMIS, which further provides user revocation and re-registration functions. On the one hand, we employ the Burrows-Abadi-Needham logic to prove that the user and server can securely achieve mutual authentication by this proposed scheme. On the other hand, we employ informal analysis to prove that our scheme can also resist various known attacks. Overall, it has high security along with low computational cost, low communication cost, and a diversified of security features and thus more suitable for TMIS.
C1 [Zhai, Xiao-Ying; Wang, Jian] Nanjing Univ Aeronaut & Astronaut NUAA, Coll Comp Sci & Technol, Nanjing 210016, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics
RP Wang, J (corresponding author), Nanjing Univ Aeronaut & Astronaut NUAA, Coll Comp Sci & Technol, Nanjing 210016, Peoples R China.
EM zxy777@nuaa.edu.cn; wangjian@nuaa.edu.cn
CR Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Abdulla AA, 2014, LECT NOTES COMPUT SC, V8893, P151, DOI 10.1007/978-3-319-14054-4_10
   Amin Ruhul, 2016, International Journal of Network Security, V18, P172
   An Y, 2012, J BIOMED BIOTECHNOL, DOI 10.1155/2012/519723
   Bellare M, 1998, P 30 ANN ACM S THEOR
   BELLOVIN, 1992, P IEEE S SEC PRIV
   Brickell E, 2012, IEEE T DEPEND SECURE, V9, P345, DOI 10.1109/TDSC.2011.63
   Burrows M., 1989, P R SOC A, V426, P1
   Byun JW, 2002, INT C INFORM COMMUNI
   Chattopadhyay S, 2016, IEEE GLOB COMM CONF, DOI 10.1109/GLOCOM.2016.7841822
   Cheng TF, 2017, INT J COMMUN SYST, V30, DOI 10.1002/dac.3267
   Dodis Y, 2004, FUZZY EXTRACTORS GEN
   Dolev D, 1981, S FDN COMPUTER SCI
   Duchêne J, 2018, J COMPUT VIROL HACKI, V14, P53, DOI 10.1007/s11416-016-0289-8
   FIPS, 1995, SECURE HASH STANDARD
   Halevi S., 1999, ACM Trans. Inf. Syst. Secur, V2, P230
   He DB, 2014, IEEE T CONSUM ELECTR, V60, P30, DOI 10.1109/TCE.2014.6780922
   He DB, 2012, J MED SYST, V36, P1989, DOI 10.1007/s10916-011-9658-5
   Huang XY, 2011, IEEE T PARALL DISTR, V22, P1390, DOI 10.1109/TPDS.2010.206
   Huh JH, 2019, J SUPERCOMPUT, V75, P1831, DOI 10.1007/s11227-018-2342-5
   Irshad A, 2018, ARAB J SCI ENG, V43, P811, DOI 10.1007/s13369-017-2764-z
   Irshad A, 2016, J SUPERCOMPUT, V72, P1623, DOI 10.1007/s11227-016-1688-9
   Jang S, 2021, INT J SUSTAIN TRANSP, V15, P351, DOI 10.1080/15568318.2020.1783726
   Katz J, 2010, EFFICIENT SECURE AUT, V57
   Khan MK, 2013, BIOMED RES INT, V2013, DOI 10.1155/2013/491289
   Kocarev L, 2011, STUD COMPUT INTELL, V354, P1, DOI 10.1007/978-3-642-20542-2
   Lee TF, 2019, MULTIMED TOOLS APPL, V78, P31649, DOI 10.1007/s11042-019-07949-8
   Lee TF, 2015, INFORM SCIENCES, V290, P63, DOI 10.1016/j.ins.2014.08.041
   Li X, 2018, FUTURE GENER COMP SY, V84, P149, DOI 10.1016/j.future.2017.08.029
   Li X, 2016, WIRELESS PERS COMMUN, V89, P569, DOI 10.1007/s11277-016-3293-x
   Li X, 2013, J NETW COMPUT APPL, V36, P1365, DOI 10.1016/j.jnca.2013.02.034
   Lin C, 2020, IEEE INTERNET THINGS, V7, P818, DOI 10.1109/JIOT.2019.2944400
   Lwamo NMR, 2019, INFORM SCIENCES, V477, P369, DOI 10.1016/j.ins.2018.10.037
   M. Abdalla, 2005, P PUBLIC KEY CRYPTOG, V153, P27
   Mandal S., 2020, IEEE INT THING J, V99, P1
   Messerges TS, 2002, IEEE T COMPUT, V51, P541, DOI 10.1109/TC.2002.1004593
   Odelu V, 2015, IEEE T INF FOREN SEC, V10, P1953, DOI 10.1109/TIFS.2015.2439964
   Pfitzmann, 2001, ANAL KEY EXCHANGE PR, V2045
   Qiu SM, 2018, IEEE ACCESS, V6, P7452, DOI 10.1109/ACCESS.2017.2780124
   Shin S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092012
   Srinivas, KUMAR N 1 CLOUD CENT
   Sutrala AK, 2020, IEEE T VEH TECHNOL, V69, P5535, DOI 10.1109/TVT.2020.2981934
   Veyrat-Charvillon N, 2011, C ADV CRYPTOLOGY
   Wang D., 2016, IMPLICATIONS ZIPFS L, DOI [10.1007/978-3-319-45744-4_6, DOI 10.1007/978-3-319-45744-4_6]
   Wang D, 2016, ACM CCS 2016
   Wang D, 2015, IEEE T DEPEND SECURE, V12, P428, DOI 10.1109/TDSC.2014.2355850
   Wang FF, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/2838615
   Wang XL, 2019, J INF SECUR APPL, V47, P132, DOI 10.1016/j.jisa.2019.04.010
   Wang XY, 2010, COMMUN NONLINEAR SCI, V15, P4052, DOI 10.1016/j.cnsns.2010.02.014
   Wei JH, 2012, J MED SYST, V36, P3597, DOI 10.1007/s10916-012-9835-1
   Wen FT, 2015, WIRELESS PERS COMMUN, V80, P1747, DOI 10.1007/s11277-014-2111-6
   Wu LF, 2009, COMPUT STAND INTER, V31, P286, DOI 10.1016/j.csi.2008.01.002
   Wu ZY, 2012, J MED SYST, V36, P1529, DOI 10.1007/s10916-010-9614-9
   Xu J, 2009, COMPUT STAND INTER, V31, P723, DOI 10.1016/j.csi.2008.09.006
   Yoon EJ, 2011, COMMUN NONLINEAR SCI, V16, P2383, DOI 10.1016/j.cnsns.2010.09.021
   Zhang LH, 2008, CHAOS SOLITON FRACT, V37, P669, DOI 10.1016/j.chaos.2006.09.047
   Zhu ZA, 2012, J MED SYST, V36, P3833, DOI 10.1007/s10916-012-9856-9
NR 57
TC 2
Z9 3
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40159
EP 40179
DI 10.1007/s11042-022-13177-4
EA MAY 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000791638100006
DA 2024-07-18
ER

PT J
AU Talaat, FM
AF Talaat, Fatma M.
TI Effective deep Q-networks (EDQN) strategy for resource allocation based
   on optimized reinforcement learning algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial Intelligence; Machine Learning; Reinforcement Learning;
   Critical care; Decision support systems; Particle Swarm Optimization
   (PSO); Resource Allocation
AB The healthcare industry has always been an early adopter of new technology and a big benefactor of it. The use of reinforcement learning in the healthcare system has repeatedly resulted in improved outcomes.. Many challenges exist concerning the architecture of the RL method, measurement metrics, and model choice. More significantly, the validation of RL in authentic clinical settings needs further work. This paper presents a new Effective Resource Allocation Strategy (ERAS) for the Fog environment, which is suitable for Healthcare applications. ERAS tries to achieve effective resource management in the Fog environment via real-time resource allocating as well as prediction algorithms. Comparing the ERAS with the state-of-the-art algorithms, ERAS achieved the minimum Makespan as compared to previous resource allocation algorithms, while maximizing the Average Resource Utilization (ARU) and the Load Balancing Level (LBL). For each application, we further compared and contrasted the architecture of the RL models and the assessment metrics. In critical care, RL has tremendous potential to enhance decision-making. This paper presents two main contributions, (i) Optimization of the RL hyperparameters using PSO, and (ii) Using the optimized RL for the resource allocation and load balancing in the fog environment. Because of its exploitation, exploration, and capacity to get rid of local minima, the PSO has a significant significance when compared to other optimization methodologies.
C1 [Talaat, Fatma M.] Kafrelsheikh Univ, Fac Artificial Intelligence, Kafrelsheikh, Egypt.
C3 Egyptian Knowledge Bank (EKB); Kafrelsheikh University
RP Talaat, FM (corresponding author), Kafrelsheikh Univ, Fac Artificial Intelligence, Kafrelsheikh, Egypt.
EM fatma.nada@ai.kfs.edu.eg
RI M. Talaat, Fatma/IYS-7614-2023; Mohamed Talaat, Fatma/HSE-4811-2023
OI M. Talaat, Fatma/0000-0001-6116-2191
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Al-Khafajiy M, 2018, P 2 INT C FUTURE NET
   Almirall D, 2012, STAT MED, V31, P1887, DOI 10.1002/sim.4512
   [Anonymous], 1960, DYNAMIC PROGRAMMING
   Arulkumaran K, 2017, IEEE SIGNAL PROC MAG, V34, P26, DOI 10.1109/MSP.2017.2743240
   Burke AE, 2019, AM J OBSTET GYNECOL, V221, P527, DOI 10.1016/j.ajog.2019.06.015
   Chen YC, 2018, PR MACH LEARN RES, V80
   Chen Z, 2016, THEOR PRACT LOG PROG, V16, P604, DOI 10.1017/S1471068416000429
   Choi E, 2016, JMLR WORKSH C P AUG, V56
   Dagan N, 2020, NAT MED, V26, P77, DOI 10.1038/s41591-019-0720-z
   Doya K, 2002, NEURAL COMPUT, V14, P1347, DOI 10.1162/089976602753712972
   Elfwing S, 2018, GECCO'18: PROCEEDINGS OF THE 2018 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P426, DOI 10.1145/3205455.3205486
   Fan JW, 2019, MED PHYS, V46, P370, DOI 10.1002/mp.13271
   Gia TN, 2015, PROC IEEE INT C COMP
   Hannes K., 2005, BMC Family Practice, V6, P37, DOI DOI 10.1186/1471-2296-6-37]
   Jaderberg M., 2017, Population based training of neural networks
   James JT, 2013, J PATIENT SAF, V9, P122, DOI 10.1097/PTS.0b013e3182948a69
   Javed AR, 2020, HUM-CENT COMPUT INFO, V10, DOI 10.1186/s13673-020-00245-7
   Kiumarsi B, 2018, IEEE T NEUR NET LEAR, V29, P2042, DOI 10.1109/TNNLS.2017.2773458
   Komorowski M, 2018, NAT MED, V24, P1716, DOI 10.1038/s41591-018-0213-5
   Laffey JG, 2018, LANCET RESP MED, V6, P659, DOI 10.1016/S2213-2600(18)30279-0
   Laserson J, 2018, LECT NOTES COMPUT SC, V11071, P553, DOI 10.1007/978-3-030-00934-2_62
   Liessner R, 2019, PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE (ICAART), VOL 2, P134, DOI 10.5220/0007364701340144
   Masip-Bruin X, 2016, P MED AD HOC NETW WO, P15
   Mnih V, 2013, ARXIV PREPRINT 2013
   Mnih V, 2016, ARXIV 2016
   Montague PR, 1999, TRENDS COGN SCI, V3, P360, DOI 10.1016/S1364-6613(99)01331-5
   Nemati S, 2016, IEEE ENG MED BIO, P2978, DOI 10.1109/EMBC.2016.7591355
   Neural RM, 2005, P EUR C MACH LEARN 2, DOI 10.1007/11564096_32
   Ng A., 2006, EXPT ROBOTICS 9 AUTO, V363, P372
   Parker-Holder J, 2020, ADV NEURAL INF PROCE, V33
   Sehgal A, 2019, 2019 THIRD IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING (IRC 2019), P596, DOI 10.1109/IRC.2019.00121
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Tentori M, 2007, LECT NOTES COMPUT SC, V4715, P337, DOI 10.1007/978-3-540-74812-0_27
   Van Hasselt H., 2016, P 30 AAAI C ARTIFICI
   Van Hasselt H., 2010, DOUBLE Q LEARNING
   Watanabe AT, 2019, J DIGIT IMAGING, V32, P625, DOI 10.1007/s10278-019-00192-5
   Wiering M, 2012, ADAPT LEARN OPTIM, V12, P1, DOI 10.1007/978-3-642-27645-3
   Wilson, 1999, BMJ, V319, P1078
   Zhang ZH, 2018, INTENS CARE MED, V44, P1189, DOI 10.1007/s00134-018-5142-8
   Zhou Y, 2019, INT C APPL EV COMP E
NR 40
TC 13
Z9 13
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 39945
EP 39961
DI 10.1007/s11042-022-13000-0
EA MAY 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000790645400001
OA hybrid
DA 2024-07-18
ER

PT J
AU Yang, ZZ
   Yang, YP
   Fan, L
   Bao, BK
AF Yang, Zhenzhen
   Yang, Yongpeng
   Fan, Lu
   Bao, Bing-Kun
TI Truncated γ norm-based low-rank and sparse decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low-rank and sparse decomposition; Truncated gamma norm; Generalized
   alternating direction method of multipliers; Image denoising; Video
   foreground and background separation
ID ALTERNATING DIRECTION METHOD; ROBUST PCA; MATRIX
AB Low-rank and sparse decomposition (LRSD) has been gained considerable attention due to its success in computer vision and many other numerous fields. However, the traditional LRSD methods have the problem of the low approximation accuracy of the rank function. To deal with this problem, the truncated gamma norm is used to approximate the rank function and an improved model of truncated gamma norm-based low-rank and sparse decomposition (TNLRSD) is proposed in this paper. In addition, to further improve the accuracy of the proposed model, a relaxation factor is added to the classic alternating direction method of multipliers and the generalized alternating direction method of multipliers (GADMM) is presented to solve the proposed model. Finally, simulation experiments are carried out to low-rank image denoising and video foreground and background separation to verify the effectiveness and superiority of the proposed TNLRSD method. By comparing and analysing the experimental results, we can get that the proposed TNLRSD method is more effective and robust than other LRSD methods.
C1 [Yang, Zhenzhen; Fan, Lu; Bao, Bing-Kun] Nanjing Univ Posts & Telecommun, Key Lab, Minist Educ Broadband Wireless Commun & Sensor Ne, Nanjing 210023, Peoples R China.
   [Yang, Zhenzhen] Nanjing Univ Posts & Telecommun, Sch Sci, Nanjing 210023, Peoples R China.
   [Yang, Yongpeng] Nanjing Vocat Coll Informat Technol, Sch Network & Commun, Nanjing 210023, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Nanjing University of
   Posts & Telecommunications; Nanjing Vocational College of Information
   Technology
RP Yang, ZZ (corresponding author), Nanjing Univ Posts & Telecommun, Key Lab, Minist Educ Broadband Wireless Commun & Sensor Ne, Nanjing 210023, Peoples R China.; Yang, ZZ (corresponding author), Nanjing Univ Posts & Telecommun, Sch Sci, Nanjing 210023, Peoples R China.; Yang, YP (corresponding author), Nanjing Vocat Coll Informat Technol, Sch Network & Commun, Nanjing 210023, Peoples R China.
EM yangzz@njupt.edu.cn; yangyp@njcit.cn
FU National Natural Science Foundation of China [61501251, 62071242]; China
   Postdoctoral Science Foundation [2018M632326]; Open Research Fund of Key
   Lab of Broadband Wireless Communication and Sensor Network Technology
   [JZNY202113]; Natural Science Foundation of the Jiangsu Higher Education
   Institutions of China [19KJB510044]; NUPTSF [NY220207]
FX This work is sponsored by the National Natural Science Foundation of
   China (Nos.61501251, 62071242), the China Postdoctoral Science
   Foundation (No.2018M632326), the Open Research Fund of Key Lab of
   Broadband Wireless Communication and Sensor Network Technology
   (No.JZNY202113), the Natural Science Foundation of the Jiangsu Higher
   Education Institutions of China (No.19KJB510044), and the NUPTSF
   (No.NY220207).
CR Beinert R, 2021, J MATH IMAGING VIS, V63, P626, DOI 10.1007/s10851-021-01019-1
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Cao LB, 2019, IEEE INT C NETW SENS, P323, DOI [10.1109/icnsc.2019.8743225, 10.1109/ICNSC.2019.8743225]
   Fan JQ, 2001, J AM STAT ASSOC, V96, P1348, DOI 10.1198/016214501753382273
   Fang EX, 2015, MATH PROGRAM COMPUT, V7, P149, DOI 10.1007/s12532-015-0078-2
   Feng PH, 2019, IET SIGNAL PROCESS, V13, P149, DOI 10.1049/iet-spr.2018.5086
   Gao C, 2017, IEEE GLOB CONF SIG, P1240, DOI 10.1109/GlobalSIP.2017.8309159
   Hoi, 2020, P IEEE CVF C COMP VI, P8960, DOI DOI 10.1109/CVPR42600.2020.00898
   Hu Y, 2013, IEEE T PATTERN ANAL, V35, P2117, DOI 10.1109/TPAMI.2012.271
   Jin KH, 2018, IEEE T IMAGE PROCESS, V27, P1448, DOI 10.1109/TIP.2017.2771471
   Kang Z, 2015, IEEE DATA MINING, P211, DOI 10.1109/ICDM.2015.15
   Ke GY, 2018, IEEE T CYBERNETICS, V48, P993, DOI 10.1109/TCYB.2017.2670608
   Keshavarzian R, 2018, IRAN CONF ELECTR ENG, P440, DOI 10.1109/ICEE.2018.8472423
   Lin HJ, 2015, IEEE T INSTRUM MEAS, V64, P2850, DOI 10.1109/TIM.2015.2433651
   Liu J, 2019, IEEE T SIGNAL PROCES, V67, P535, DOI 10.1109/TSP.2018.2883924
   Liu JJ, 2019, IEEE ACCESS, V7, P112939, DOI 10.1109/ACCESS.2019.2935235
   Lu X., 2020, ECCV, V12348, P661, DOI DOI 10.1007/978-3-030-58580-8_39
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Masuyama Y, 2019, IEEE SIGNAL PROC LET, V26, P184, DOI 10.1109/LSP.2018.2884026
   Nguyen MU, 2018, INT CONF KNOWL SYS, P1, DOI [10.1109/KSE.2018.8573361, 10.1109/IEEE-IWS.2018.8400811, 10.1109/PRNI.2018.8423955]
   Moore BE, 2019, IEEE T COMPUT IMAG, V5, P195, DOI 10.1109/TCI.2019.2891389
   Nehorai, 2011, CISS
   Nie YM, 2017, APPL OPTICS, V56, P6094, DOI 10.1364/AO.56.006094
   Oh TH, 2016, IEEE T PATTERN ANAL, V38, P744, DOI 10.1109/TPAMI.2015.2465956
   Recht B, 2010, SIAM REV, V52, P471, DOI 10.1137/070697835
   Wang HY, 2020, IEEE T CIRC SYST VID, V30, P349, DOI 10.1109/TCSVT.2019.2890880
   Wang JJ, 2017, J COMPUT APPL MATH, V309, P342, DOI 10.1016/j.cam.2016.02.001
   Wang SQ, 2018, IEEE ACCESS, V6, P18945, DOI 10.1109/ACCESS.2018.2818322
   Wen F, 2020, IEEE T CIRC SYST VID, V30, P1497, DOI 10.1109/TCSVT.2019.2908833
   Xiao YH, 2018, MATH PROGRAM COMPUT, V10, P533, DOI 10.1007/s12532-018-0134-9
   Xie T, 2020, IEEE T IMAGE PROCESS, V29, P44, DOI 10.1109/TIP.2019.2926736
   Xu XW, 2020, BMJ-BRIT MED J, V368, DOI [10.1136/bmj.m606, 10.1136/bmj.m792]
   Yang ZZ, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107527
   Yang ZZ, 2019, J FRANKLIN I, V356, P10138, DOI 10.1016/j.jfranklin.2019.09.017
   Yang ZZ, 2018, IEEE ACCESS, V6, P56945, DOI 10.1109/ACCESS.2018.2872688
   Yisu Zhou, 2018, 2018 IEEE 4th International Conference on Computer and Communications (ICCC). Proceedings, P1670, DOI 10.1109/CompComm.2018.8780967
   Yu YW, 2017, IEEE INT CONF BIG DA, P508, DOI 10.1109/BigData.2017.8257965
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P12853, DOI 10.1007/s11042-017-4919-z
   Zhao LL, 2019, INT J ENG BUS MANAG, V11, DOI 10.1177/1847979019880061
   Zhou ZH, 2010, IEEE INT SYMP INFO, P1518, DOI 10.1109/ISIT.2010.5513535
   Zhuang L, 2018, IEEE J-STARS, V11, P730, DOI 10.1109/JSTARS.2018.2796570
NR 42
TC 2
Z9 2
U1 5
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 38279
EP 38295
DI 10.1007/s11042-022-12509-8
EA APR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000785933700019
DA 2024-07-18
ER

PT J
AU Cheggoju, N
   Satpute, VR
AF Cheggoju, Naveen
   Satpute, Vishal R.
TI Blind quality scalable video compression algorithm for low bit-rate
   coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Two threshold EZW; Compression; Group of frames; 3D-discrete wavelet
   transform; Rate distortion; Scalability
ID RATE-DISTORTION OPTIMIZATION; 3-D WAVELET TRANSFORM; ARCHITECTURE;
   EFFICIENCY; DWT
AB An efficient way of using Embedded Zero-trees of Wavelet (EZW) architecture for video compression, termed as "Two Threshold EZW", has been introduced in this paper. This architecture is free from motion compensation and post-compression rate-distortion (PCRD) optimization algorithms. To catch up with the compression obtained by H.265, traditional EZW architecture has been modified for exploiting the temporal/inter-frame dependency. To exploit this, the concept of two thresholds for intra and inter-frame coding has been introduced for a single frame. It is also helpful in coding spatial high-pass and low-pass components independently, which adds more degree of freedom for rate optimization. This architecture makes it easier for achieving blind scalability without using PCRD optimization. To evaluate the algorithm, it has been compared with H.265 at different bit rates. Peak Signal to Noise Ratio (PSNR) and Structural Similarity (SSIM) index are calculated to compare the quality of reconstruction at various low bit rates.
C1 [Cheggoju, Naveen] VIT AP Univ, Sch Elect, Vijayawada, Andhra Pradesh, India.
   [Satpute, Vishal R.] Visvesvaraya Natl Inst Technol, Dept Elect & Commun Engn, Nagpur, Maharashtra, India.
C3 VIT-AP University; National Institute of Technology (NIT System);
   Visvesvaraya National Institute of Technology, Nagpur
RP Cheggoju, N (corresponding author), VIT AP Univ, Sch Elect, Vijayawada, Andhra Pradesh, India.
EM naveen.c@vitap.ac.in; vrsatpute@ece.vnit.ac.in
RI SATPUTE, VISHAL RAMESH/AAA-7713-2022; Cheggoju, Naveen/L-3006-2019
OI SATPUTE, VISHAL RAMESH/0000-0001-9944-9489; Cheggoju,
   Naveen/0000-0002-4734-9344
CR [Anonymous], 2021, X265 ENCODER
   [Anonymous], 2020, XIPH ORG VIDEO TEST
   Badawy W, 2002, IEEE ENG MED BIOL, V21, P95, DOI 10.1109/MEMB.2002.1032646
   Bernabé G, 2002, EUROMICRO CONF PROC, P108, DOI 10.1109/EURMIC.2002.1046141
   Chen Z, 2019, IEEE APP IMG PAT, DOI 10.1109/aipr47015.2019.9174584
   Choonsup Lee, 2017, 2017 42nd International Conference on Infrared, Millimeter and Terahertz Waves (IRMMW-THz), DOI 10.1109/IRMMW-THz.2017.8066916
   Das B, 2005, IEE P-CIRC DEV SYST, V152, P17, DOI 10.1049/ip-cds:20040817
   Das B, 2002, P ANN INT IEEE EMBS, P1062, DOI 10.1109/IEMBS.2002.1106277
   Gringoli F, 2019, IEEE T MOBILE COMPUT, V18, P2549, DOI 10.1109/TMC.2018.2876000
   He C, 2003, IEEE T CIRC SYST VID, V13, P961, DOI 10.1109/TCSVT.2003.816514
   He J, 2015, IET IMAGE PROCESS, V9, P652, DOI 10.1049/iet-ipr.2014.0849
   Mehrseresht N, 2006, IEEE T IMAGE PROCESS, V15, P740, DOI 10.1109/TIP.2005.860619
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Ohm JR, 2013, IEEE SIGNAL PROC MAG, V30, P152, DOI 10.1109/MSP.2012.2219672
   Rassool R, 2017, IEEE INT SYM BROADB, P351
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Singh K, 2018, IEEE T CONSUM ELECTR, V64, P267, DOI 10.1109/TCE.2018.2867823
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sun HM, 2017, IEEE T MULTIMEDIA, V19, P2375, DOI 10.1109/TMM.2017.2700629
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weeks M, 2002, IEEE T SIGNAL PROCES, V50, P2050, DOI 10.1109/TSP.2002.800402
   Xu JZ, 2002, IEEE T CIRC SYST VID, V12, P812, DOI 10.1109/TCSVT.2002.803231
   Yang KF, 2019, IEEE T CIRC SYST VID, V29, P1230, DOI 10.1109/TCSVT.2019.2896664
   Zhi L, 2021, VMAF VIDEO MULTIMETH
NR 24
TC 4
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33715
EP 33730
DI 10.1007/s11042-022-12061-5
EA APR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784679300003
DA 2024-07-18
ER

PT J
AU Tuli, P
   Patra, JP
AF Tuli, Preeti
   Patra, Jyoti Prakash
TI Symbol question conversion in structured query language using fuzzy with
   deep attention based rain LSTM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Natural language processing; Structured query language; Feature matrix;
   Fuzzy logic; Rain optimization algorithm; Long short-term memory
ID TEXT-TO-SQL
AB Effective communication between human and machine is achieved using Natural Language Processing (NLP). However, the users are not aware about the Structured Query Language (SQL) of the normal database (DB). Therefore, to make users more aware of SQL, a deep attention based rain LSTM (Long Short-Term Memory) is introduced in proposed process for developing the SQL query model. The input query of user is entered in natural language form which is initially pre-processed. Different steps are included in pre-processing they are Lower case conversion, Tokenization, Escape Word Removal and Parts Of speech (POS) tagger. After pre-processing stage, a novel fuzzy approach is introduced with the help of rain LSTM method. With the help of the feature matrix technique, the words of the pre-processed query are given a certain rank. The LSTM-ROA (Rain Optimization Algorithm) method is used for categorizing the words into relations, attributes and clauses on the basis of tagged elements. After removing ambiguous attributes, a final query is generated based on the extracted elements. The proposed method is implemented in the Python platform and the performances are analysed in terms of Accuracy, Precision, Recall and Error Rate. The proposed DA-RLSTM achieved 95.74% accuracy which illustrates that the proposed work has attained better result than the existing methods.
C1 [Tuli, Preeti; Patra, Jyoti Prakash] Shri Shankaracharya Inst Profess Management & Tec, Comp Sci & Engn Dept, Raipur, Madhya Pradesh, India.
C3 Shri Shankaracharya Group of Institutions
RP Tuli, P (corresponding author), Shri Shankaracharya Inst Profess Management & Tec, Comp Sci & Engn Dept, Raipur, Madhya Pradesh, India.
EM preetituli@gmail.com
OI Tuli, Preeti/0009-0004-6709-8935; Patra, Dr J P/0000-0003-2924-6090
CR Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Alotaibi O, 2019, DATA, V4, DOI 10.3390/data4040148
   [Anonymous], 2019, ACL
   Arcuri A, 2020, ACM T SOFTW ENG METH, V29, DOI 10.1145/3391533
   Bai ZW, 2021, COMPUT SPEECH LANG, V67, DOI 10.1016/j.csl.2020.101185
   Brunel R, 2015, PROC INT CONF DATA, P1280, DOI 10.1109/ICDE.2015.7113376
   Choi D, 2021, COMPUT LINGUIST, V47, P309, DOI [10.1162/coli_a_00403, 10.1162/COLI_a_00403]
   Dehraj P, 2020, APPL SOFT COMPUT, V90, DOI 10.1016/j.asoc.2020.106137
   Dong KW, 2021, LECT NOTES ARTIF INT, V12979, P335, DOI 10.1007/978-3-030-86517-7_21
   Guo AB, 2021, NEUROCOMPUTING, V465, P359, DOI 10.1016/j.neucom.2021.08.134
   He, TEXT TO SQL TRANSLAT
   Kate Abhilasha, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P488, DOI 10.1109/ICECA.2018.8474639
   Krause C, 2016, LECT NOTES COMPUT SC, V9761, P153, DOI 10.1007/978-3-319-40530-8_10
   Li N., 2020, ARXIV PREPRINT ARXIV
   Li Q, 2020, IEEE T IND INFORM, V16, P2542, DOI 10.1109/TII.2019.2952929
   Li Z, 2017, ARXIV PREPRINT ARXIV
   Poole D.L., 2010, ARTIF INTELL, DOI DOI 10.1017/9781108164085
   Pradeep T., NATURAL LANGUAGE NOS
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Rostami M, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-020-00398-3
   Rostami M, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00352-3
   Singh G., 2016, Selforganizology, V3, P100
   Solanki A, 2018, INT J INF TECHNOL, P1
   Sontakke, 2014, INT J SCI ENG RES, V3, P81
   Sun Ningyuan, 2020, TABLEQA LARGE SCALE
   Sutskever I, 2014, ADV NEUR IN, V27
   Taipalus T, 2020, J SYST SOFTWARE, V165, DOI 10.1016/j.jss.2020.110576
   Wu Y., 2016, GOOGLES NEURAL MACHI
   Xu BY, 2019, IEEE ACCESS, V7, P35012, DOI 10.1109/ACCESS.2019.2904720
   Xuan, 2021, ARXIV PREPRINT ARXIV
   Yang XY, 2009, PROC VLDB ENDOW, V2
   Yang XY, 2011, PROC VLDB ENDOW, V4, P899
   Yu W, 2021, NEURAL NETWORKS, V142, P573, DOI 10.1016/j.neunet.2021.07.014
   Zhang GY, 2020, IEEE SENS J, V20, P3113, DOI 10.1109/JSEN.2019.2956998
   Zhong Victor, 2017, ARXIV170900103
NR 37
TC 3
Z9 3
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 32323
EP 32349
DI 10.1007/s11042-022-12841-z
EA APR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781941300003
DA 2024-07-18
ER

PT J
AU Bouaziz, Y
   Royer, E
   Bresson, G
   Dhome, M
AF Bouaziz, Youssef
   Royer, Eric
   Bresson, Guillaume
   Dhome, Michel
TI Map management for robust long-term visual localization of an autonomous
   shuttle in changing conditions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual-based navigation; Computer vision for transportation; SLAM
ID EXPERIENCE
AB Changes in appearance present a tremendous problem for the visual localization of an autonomous vehicle in outdoor environments. Data association between the current image and the landmarks in the map can be challenging in cases where the map was built with different environmental conditions. This paper introduces a solution to build and use multi-session maps incorporating sequences recorded in different conditions (day, night, fog, snow, rain, change of season, etc.). During visual localization, we exploit a ranking function to extract the most relevant keyframes from the map. This ranking function is designed to take into account the pose of the vehicle as well as the current environmental condition. In the mapping phase, covering all conditions by constantly adding data to the map leads to a continuous growth in the map size which in turn deteriorates the localization speed and performance. Our map management strategy is an incremental approach that aims to limit the size of the map while keeping it as diverse as possible. Our experiments were performed on real data collected with our autonomous shuttle as well as on a widely used public dataset. The results demonstrate that our keyframe-based ranking function is suitable for long-term scenarios. Our map management algorithm aims to build a map with as much diversity as possible whereas some state of the art approaches tend to filter out the less observed landmarks. This strategy shows a reduction of localization failures while maintaining real-time performance.
C1 [Bouaziz, Youssef] Inst VEDECOM, Inst Pascal, CNRS, Versailles, France.
   [Royer, Eric; Dhome, Michel] Inst Pascal, SIGMA Clermont, CNRS, Clermont Ferrand, France.
   [Bresson, Guillaume] Inst VEDECOM, Versailles, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite Clermont
   Auvergne (UCA); Centre National de la Recherche Scientifique (CNRS)
RP Bouaziz, Y (corresponding author), Inst VEDECOM, Inst Pascal, CNRS, Versailles, France.
EM youssef.bouaziz@etu.uca.fr; eric.royer@uca.fr;
   guillaume.bresson@vedecom.fr; michel.dhome@uca.fr
OI BOUAZIZ, YOUSSEF/0000-0003-3257-6859
FU French government research program "Investissements d'Avenir" through
   the IMobS3 Laboratory of Excellence [ANR-10-LABX-16-01]; French
   government research program "Investissements d'Avenir" through the
   RobotEx Equipment of Excellence [ANR-10-EQPX-44]; European Union through
   the Regional Competitiveness and Employment program 2014-2020 (ERDF -
   AURA region); AURA region
FX This work has been sponsored by the French government research program
   "Investissements d'Avenir" through the IMobS3 Laboratory of Excellence
   (ANR-10-LABX-16-01) and the RobotEx Equipment of Excellence
   (ANR-10-EQPX-44), by the European Union through the Regional
   Competitiveness and Employment program 2014-2020 (ERDF - AURA region)
   and by the AURA region.
CR Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Berrio JS, 2019, IEEE INT VEH SYM, P1166, DOI 10.1109/IVS.2019.8814289
   Bouaziz Y., 2021, INT C INF CONTR AUT, P383, DOI [10.5220/0010518303830387, DOI 10.5220/0010518303830387]
   Bouaziz Y, 2021, 2021 IEEE 19TH WORLD SYMPOSIUM ON APPLIED MACHINE INTELLIGENCE AND INFORMATICS (SAMI 2021), P93, DOI 10.1109/SAMI50585.2021.9378614
   Bürki M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4137, DOI 10.1109/IROS.2016.7759609
   Bürki M, 2018, IEEE INT VEH SYM, P682, DOI 10.1109/IVS.2018.8500432
   Burki M, 2019, J FIELD ROBOT, V36, P1041, DOI 10.1002/rob.21870
   Carlevaris-Bianco N, 2016, INT J ROBOT RES, V35, P1023, DOI 10.1177/0278364915614638
   Chen C., 2020, ARXIV200612567
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193
   Churchill W, 2012, IEEE INT CONF ROBOT, P4525, DOI 10.1109/ICRA.2012.6224596
   Clark R, 2017, PROC CVPR IEEE, P2652, DOI 10.1109/CVPR.2017.284
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Diaz-Escobar J, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/3758102
   Dusmanu M, 2019, PROC CVPR IEEE, P8084, DOI 10.1109/CVPR.2019.00828
   Dymczyk M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4572, DOI 10.1109/IROS.2016.7759673
   Dymczyk M, 2015, IEEE INT CONF ROBOT, P2767, DOI 10.1109/ICRA.2015.7139575
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Gridseth M, 2020, IEEE INT CONF ROBOT, P1674, DOI [10.1109/icra40945.2020.9197362, 10.1109/ICRA40945.2020.9197362]
   Halodová L, 2019, IEEE INT C INT ROBOT, P7033, DOI [10.1109/iros40897.2019.8967994, 10.1109/IROS40897.2019.8967994]
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Jatzkowski I, 2018, IEEE INT C INTELL TR, P2030, DOI 10.1109/ITSC.2018.8569692
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336
   Krajnik T, 2019, IEEE ROBOT AUTOM LET, V4, P3310, DOI 10.1109/LRA.2019.2926682
   Krajník T, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4558, DOI 10.1109/IROS.2016.7759671
   Laskar Z, 2017, IEEE INT CONF COMP V, P920, DOI 10.1109/ICCVW.2017.113
   Lebraly Pierre, 2011, 2011 IEEE International Conference on Robotics and Automation, P221
   Linegar C, 2015, IEEE INT CONF ROBOT, P90, DOI 10.1109/ICRA.2015.7138985
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MacTavish K, 2018, J FIELD ROBOT, V35, P1265, DOI 10.1002/rob.21838
   Maddern W., 2020, ARXIV200210152
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498
   Magnago V, 2019, IEEE T INSTRUM MEAS, V68, P4443, DOI 10.1109/TIM.2018.2887071
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623
   Mühlfellner P, 2016, J FIELD ROBOT, V33, P561, DOI 10.1002/rob.21595
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Murillo A. C., 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P2196, DOI 10.1109/ICCVW.2009.5457552
   Naseer Tayyab, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P2614, DOI 10.1109/ICRA.2017.7989305
   Pascoe G, 2017, PROC CVPR IEEE, P1446, DOI 10.1109/CVPR.2017.158
   Pepperell E, 2016, INT J ROBOT RES, V35, DOI 10.1177/0278364915618766
   Rosen DM, 2016, IEEE INT CONF ROBOT, P1063, DOI 10.1109/ICRA.2016.7487237
   Royer E, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P2248, DOI 10.1109/ITSC.2016.7795919
   Schneider Thomas, 2018, IEEE Robotics and Automation Letters, V3, P1418, DOI 10.1109/LRA.2018.2800113
   Schönberger JL, 2018, PROC CVPR IEEE, P6896, DOI 10.1109/CVPR.2018.00721
   Stenborg E, 2020, INT CONF 3D VISION, P938, DOI 10.1109/3DV50981.2020.00104
   Tian YR, 2019, PROC CVPR IEEE, P11008, DOI 10.1109/CVPR.2019.01127
   Walch F, 2017, IEEE I CONF COMP VIS, P627, DOI 10.1109/ICCV.2017.75
   Yan Z, 2020, IEEE INT C INT ROBOT, P10697, DOI 10.1109/IROS45743.2020.9341406
   Yi KM, 2016, LECT NOTES COMPUT SC, V9910, P467, DOI 10.1007/978-3-319-46466-4_28
NR 50
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22449
EP 22480
DI 10.1007/s11042-021-11870-4
EA APR 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000781124000002
DA 2024-07-18
ER

PT J
AU Omayio, EO
   Indu, S
   Panda, J
AF Omayio, Enock Osoro
   Indu, Sreedevi
   Panda, Jeebananda
TI Historical manuscript dating: traditional and current trends
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Historical manuscript dating (HMD); Carbon-14 (C-14) dating;
   Spectroscopy; Convolutional neural network (CNN); K nearest neighbor
   (KNN); Support Vector machine (SVM)
ID INDEPENDENT WRITER IDENTIFICATION; DEAD-SEA-SCROLLS; VINLAND MAP; RAMAN
   MICROSCOPY; LANGUAGE MODELS; AGE ESTIMATION; RADIOCARBON; RECOGNITION;
   DEEP; SPECTROSCOPY
AB There is a huge number of undated digitized and undigitized historical manuscripts from antiquity. The dates of production of these historical manuscripts are of interest to historians, curators, paleographers, scholars and other stakeholders. This paper discourses comprehensively the trend of historical manuscript dating (HMD) approaches and techniques from traditional to modern (computer-based) methods. There are many methods for historical manuscript dating (HMD) that have been developed. They are divided into 3 main categories: paleographic, physical and computer-based techniques. Traditional HMD methods require samples of actual manuscripts, are time consuming, costly, and destructive. These drawbacks have informed the preferential shift to modern computer-based HMD methods. Computer-based methods use scanned images of manuscripts thereby preserving them, are relatively less costly, faster, convenient, and applicable in large scale. The future trend for computer-based HMD is discussed with aim of achieving better results in manuscript dating task. It is noted that not much research has been done in historical manuscript dating especially in modern computer-based methods which are applicable in large scale.
C1 [Omayio, Enock Osoro; Indu, Sreedevi; Panda, Jeebananda] Delhi Technol Univ, Elect & Commun Engn Dept, Delhi, India.
C3 Delhi Technological University
RP Omayio, EO (corresponding author), Delhi Technol Univ, Elect & Commun Engn Dept, Delhi, India.
EM omayio2008@gmail.com; s.indu@dce.ac.in; jpanda@dce.ac.in
RI Sreedevi, Indu/HCH-5463-2022; Sreedevi, Indu/AFU-2449-2022
OI Sreedevi, Indu/0000-0002-4975-5047; OMAYIO, ENOCK
   OSORO/0000-0003-0285-570X
CR Adak C, 2019, IEEE ACCESS, V7, P24738, DOI 10.1109/ACCESS.2019.2899908
   Adam K, 2018, INT J DOC ANAL RECOG, V21, P283, DOI 10.1007/s10032-018-0312-3
   Adam K, 2017, 2017 1ST INTERNATIONAL WORKSHOP ON ARABIC SCRIPT ANALYSIS AND RECOGNITION (ASAR), P95, DOI 10.1109/ASAR.2017.8067767
   Alarifi J, 2019, INT CONF COMP INFO, P177, DOI 10.1109/cits.2019.8862107
   [Anonymous], 2015, P 3 INT WORKSH HIST
   [Anonymous], 2006, P 14 ANN ACM INT C M
   [Anonymous], 2015, P 3 INT WORKSH HIST, DOI DOI 10.1145/2809544.2809560
   Aubin V, 2018, PATTERN RECOGN, V79, P414, DOI 10.1016/j.patcog.2018.02.024
   Bagnall RS, 2009, EARLY CHRISTIAN BOOK, P11
   Banerjee Protima, 2009, Journal of Computing Science and Engineering, V3, P143, DOI 10.5626/JCSE.2009.3.3.143
   Barker D, 2011, NEW TESTAMENT STUD, V57, P571, DOI 10.1017/S0028688511000129
   Beare FrankW., 1944, JBL, V63, P379, DOI DOI 10.2307/3262540
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bensefia A, 2020, 2020 IEEE 21ST INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION FOR DATA SCIENCE (IRI 2020), P53, DOI 10.1109/IRI49571.2020.00016
   BONANI G, 1992, RADIOCARBON, V34, P843, DOI 10.1017/S0033822200064158
   Brink AA, 2012, PATTERN RECOGN, V45, P162, DOI 10.1016/j.patcog.2011.07.005
   Broder AZ, 1998, COMPRESSION AND COMPLEXITY OF SEQUENCES 1997 - PROCEEDINGS, P21, DOI 10.1109/SEQUEN.1997.666900
   Broder AZ, 1997, COMPUT NETWORKS ISDN, V29, P1157, DOI 10.1016/S0169-7552(97)00031-7
   Brown KL, 2002, ANAL CHEM, V74, P3658, DOI 10.1021/ac025610r
   Bulacu M, 2007, IEEE T PATTERN ANAL, V29, P701, DOI 10.1109/TPAMI.2007.1009
   Burgio L, 2009, J RAMAN SPECTROSC, V40, P2031, DOI 10.1002/jrs.2364
   CAHILL TA, 1987, ANAL CHEM, V59, P829, DOI 10.1021/ac00133a009
   Casabianca T, 2019, ARCHAEOMETRY, V61, P1223, DOI 10.1111/arcm.12467
   Castro K, 2004, ANAL BIOANAL CHEM, V379, P674, DOI 10.1007/s00216-004-2642-x
   Castro K, 2004, SPECTROCHIM ACTA A, V60, P2919, DOI 10.1016/j.saa.2004.02.004
   Chahi A, 2019, EXPERT SYST APPL, V123, P357, DOI 10.1016/j.eswa.2019.01.045
   Chen SM, 2019, INFORM SCIENCES, V482, P156, DOI 10.1016/j.ins.2019.01.024
   Christlein V, 2017, PROC INT CONF DOC, P991, DOI 10.1109/ICDAR.2017.165
   Clark RJH, 2007, APPL PHYS A-MATER, V89, P833, DOI 10.1007/s00339-007-4212-5
   CLARK RJH, 1995, CHEM SOC REV, V24, P187, DOI 10.1039/cs9952400187
   Clark RJH, 1999, J MOL STRUCT, V481, P15, DOI 10.1016/S0022-2860(98)00649-8
   Cloppet F, 2017, PROC INT CONF DOC, P1371, DOI 10.1109/ICDAR.2017.224
   Cloppet F, 2016, INT CONF FRONT HAND, P590, DOI [10.1109/ICFHR.2016.0113, 10.1109/ICFHR.2016.106]
   Comfort PhilipW., 1999, The Complete Text of the Earliest New Testament Manuscripts
   Comfort PW, 2001, TEXT EARLIEST NEW TE, P204
   DAMON PE, 1989, NATURE, V337, P611, DOI 10.1038/337611a0
   Dargan S, 2019, ARCH COMPUT METHOD E, V26, P1283, DOI 10.1007/s11831-018-9278-z
   de Jong F, 2005, HUMANITIES, COMPUTERS AND CULTURAL HERITAGE, P161
   DelCarmine P, 1996, NUCL INSTRUM METH B, V113, P354, DOI 10.1016/0168-583X(95)01335-0
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dhali MA, 2020, PATTERN RECOGN LETT, V131, P413, DOI 10.1016/j.patrec.2020.01.027
   Djeddi C, 2013, PATTERN RECOGN LETT, V34, P1196, DOI 10.1016/j.patrec.2013.03.020
   Dolfing H, 2019, SCRIBBLELENS DUTCH H
   Dolfing HJGA, 2020, INT CONF FRONT HAND, P67, DOI 10.1109/ICFHR2020.2020.00023
   Donahue DJ, 2002, RADIOCARBON, V44, P45, DOI 10.1017/S0033822200064651
   Duran A, 2009, ANAL BIOANAL CHEM, V395, P1997, DOI 10.1007/s00216-009-2992-5
   Edwards H.G.M., 2000, Encyclopedia of Spectroscopy and Spectrometry, V1, P2
   Evans CA, 2017, BIBLICAL INTERP SER, V150, P201, DOI 10.1163/9789004335936_009
   Fedi M., 2009, ORGANIC MASS SPECTRO, P459, DOI [10.1002/9780470741917.ch16, DOI 10.1002/9780470741917.CH16]
   Fedi ME, 2010, RADIOCARBON, V52, P356, DOI 10.1017/S0033822200045409
   Fernández-Mota D, 2014, INT C PATT RECOG, P256, DOI 10.1109/ICPR.2014.53
   Feuerverger A., 2008, Inst. Math. Stat. Collect., V1, P321, DOI [10.1214/193940307000000248, DOI 10.1214/193940307000000248]
   Fiallos R., 2000, Dating Undated Medieval Charters
   Fiel S., 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P145, DOI 10.1109/DAS.2012.99
   Fiel S, 2013, PROC INT CONF DOC, P545, DOI 10.1109/ICDAR.2013.114
   Garain U., 2007, 9 INT C DOC AN REC I, DOI [10.1109/ICDAR.2007.4377017, DOI 10.1109/ICDAR.2007.4377017]
   Gauglitz G., 2003, HDB SPECTROSCOPY, DOI [10.1002/3527602305, DOI 10.1002/3527602305]
   Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733
   Gervers M, 2000, DATING MEDIEVA UNPUB
   GERVERS Michael, 2000, DATING UNDATED MEDIE, P13
   GIUNTINI L, 1995, NUCL INSTRUM METH B, V95, P389, DOI 10.1016/0168-583X(94)00538-9
   Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280
   Haibin Ling, 2007, 2007 11th IEEE International Conference on Computer Vision, P1
   Hamid Anmol, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P967, DOI 10.1109/ICDAR.2019.00159
   Hamid A, 2018, INT CONF FRONT INFO, P235, DOI 10.1109/FIT.2018.00048
   He KM, 2019, IEEE I CONF COMP VIS, P4917, DOI 10.1109/ICCV.2019.00502
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He S, 2020, IEEE T INF FOREN SEC, V15, P3013, DOI 10.1109/TIFS.2020.2981236
   He S, 2019, PATTERN RECOGN, V88, P64, DOI 10.1016/j.patcog.2018.11.003
   He S, 2016, INT CONF FRONT HAND, P7, DOI [10.1109/ICFHR.2016.0015, 10.1109/ICFHR.2016.12]
   He S, 2016, COMPUT VIS IMAGE UND, V152, P167, DOI 10.1016/j.cviu.2016.08.008
   He S, 2016, IEEE T IMAGE PROCESS, V25, P5252, DOI 10.1109/TIP.2016.2602078
   He S, 2016, PATTERN RECOGN, V58, P159, DOI 10.1016/j.patcog.2016.03.032
   He S, 2015, PROC INT CONF DOC, P6, DOI 10.1109/ICDAR.2015.7333715
   He S, 2014, INT CONF FRONT HAND, P265, DOI 10.1109/ICFHR.2014.52
   He S, 2015, PATTERN RECOGN, V48, P4036, DOI 10.1016/j.patcog.2015.05.022
   He S, 2014, INT C PATT RECOG, P2023, DOI 10.1109/ICPR.2014.353
   Head PeterM., 1995, TynBul, V46, P251
   Hellborg R, 2008, MASS SPECTROM REV, V27, P398, DOI 10.1002/mas.20172
   Hiemstra D., 1998, Research and Advanced Technology for Digital Libraries. Second European Conference, ECDL'98. Proceedings, P569
   Hodgins GWL., 2011, FORENSIC INVESTIGATI
   Hollas J. M., 2004, Modern spectroscopy, V4th
   Hoskier HermanCharles., 1937, Journal of Theological Studies, V38, P148
   Howe NR, 2017, PROC INT CONF DOC, P783, DOI 10.1109/ICDAR.2017.133
   Islam AU, 2019, IEEE, DOI [10.1109/DICTA47822.2019.8945886, DOI 10.1109/DICTA47822.2019.8945886]
   Jing-Ming Guo, 2011, Proceedings of the 2011 International Conference on System Science and Engineering (ICSSE), P55, DOI 10.1109/ICSSE.2011.5961873
   Jull AJT, 2013, J PHYS CONF SER, V436, DOI 10.1088/1742-6596/436/1/012083
   Jull A.J.T., 2014, Archeometr. Muhely, V11, P139
   JULL AJT, 1995, RADIOCARBON, V37, P11, DOI 10.1017/S0033822200014740
   Jurado-López A, 2004, J RAMAN SPECTROSC, V35, P119, DOI 10.1002/jrs.1115
   Jurafsky D., 2000, Speech and language processing: An introduction to natural language processing, computational linguistics, and speech recognition
   KAISER R, 1990, INTERDISCIPL SCI REV, V15, P133
   Kanhabua N, 2008, LECT NOTES COMPUT SC, V5173, P358
   Khan FA, 2019, IEEE T INF FOREN SEC, V14, P289, DOI 10.1109/TIFS.2018.2850011
   KIM YK, 1988, BIBLICA, V69, P248
   Kornblith S, 2019, PROC CVPR IEEE, P2656, DOI 10.1109/CVPR.2019.00277
   Kraaij W., 2004, THESIS U TWENTE
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   KUHL FP, 1982, COMPUT VISION GRAPH, V18, P236, DOI 10.1016/0146-664X(82)90034-X
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Larkin PJ, 2011, INFRARED AND RAMAN SPECTROSCOPY: PRINCIPLES AND SPECTRAL INTERPRETATION, P1
   Latecki LJ, 1999, COMPUT VIS IMAGE UND, V73, P441, DOI 10.1006/cviu.1998.0738
   Lauwers D, 2014, J RAMAN SPECTROSC, V45, P1266, DOI 10.1002/jrs.4500
   Lavrenko V., 2001, SIGIR Forum, P120
   Le Bourgeois F, 2004, FIRST INTERNATIONAL WORKSHOP ON DOCUMENT IMAGE ANALYSIS FOR LIBRARIES, PROCEEDINGS, P2, DOI 10.1109/DIAL.2004.1263233
   Levy T.E., 2005, BIBLE RADIOCARBON DA
   Lim T, 1995, DEAD SEA SCROLLS ELE, V1
   Llido D M, 2001, EXTRACTING TEMPORAL, V2113
   Lucarelli F, 1996, NUCL INSTRUM METH B, V109, P644, DOI 10.1016/0168-583X(95)00985-X
   Mani I, 2000, 38TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P69
   McCown ChesterC., 1941, Harvard Theological Review, P219, DOI DOI 10.1017/S0017816000022471
   MCCRONE WC, 1976, ANAL CHEM, V48, pA676, DOI 10.1021/ac50002a003
   MCCRONE WC, 1988, ANAL CHEM, V60, P1009, DOI 10.1021/ac00161a013
   Melessanaki K, 2001, SPECTROCHIM ACTA B, V56, P2337, DOI 10.1016/S0584-8547(01)00302-0
   Metzger BM, 1981, GREEK BIBLE IN UNPUB, P14
   Moalla L, 2006, LECT NOTES COMPUT SC, V3872, P25
   Murgue T, 2004, LECT NOTES COMPUT SC, V3138, P269
   Nesmerák K, 2012, ANAL LETT, V45, P330, DOI 10.1080/00032719.2011.644741
   Nongbri B, 2005, HARVARD THEOL REV, V98, P23, DOI 10.1017/S0017816005000842
   Oda H, 2010, NUCL INSTRUM METH B, V268, P1041, DOI 10.1016/j.nimb.2009.10.092
   Olin JS, 2003, ANAL CHEM, V75, P6745, DOI 10.1021/ac034533c
   Orsini P, 2012, EPHEMER THEOL LOVAN, V88, P443, DOI 10.2143/ETL.88.4.2957937
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Ponte J. M., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P275, DOI 10.1145/290941.291008
   Popovic Mladen, 2016, STDJ, V116, P155
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rasmussen KL, 2009, RADIOCARBON, V51, P1005
   Rehbein M, 2009, CODICOLOGY PALAEOGRA, P219
   Rehman A, 2019, IEEE ACCESS, V7, P17149, DOI 10.1109/ACCESS.2018.2890810
   RENGER K, 1986, MASTER DRAWINGS, V23-4, P527
   Rugg G, 2004, CRYPTOLOGIA, V28, P31, DOI 10.1080/0161-110491892755
   Sanders HA, 1935, 3 CENTURY PAPYRUS CO, P13
   Sarlin P, 2013, NEUROCOMPUTING, V99, P496, DOI 10.1016/j.neucom.2012.07.011
   Sawant MM, 2019, IEEE ACCESS, V7, P9142, DOI 10.1109/ACCESS.2018.2889873
   Schmeh K, 2013, CRYPTOLOGIA, V37, P193, DOI 10.1080/01611194.2013.797045
   Settle FA, 1997, HDB INSTRUMENTAL TEC
   Shor P, 2014, J EAST MEDITERR ARCH, V2, P71
   Siddiqi I, 2010, PATTERN RECOGN, V43, P3853, DOI 10.1016/j.patcog.2010.05.019
   Song F, 1999, PROCEEDINGS OF THE EIGHTH INTERNATIONAL CONFERENCE ON INFORMATION KNOWLEDGE MANAGEMENT, CIKM'99, P316, DOI 10.1145/319950.320022
   Songxuan Lai, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1137, DOI 10.1109/ICDAR.2019.00184
   Studer L, 2019, P INT C DOC AN REC I, P720
   Stutzmann D, 2016, DIGIT MEDIEVALIST J, V10, DOI [10.16995/dm.61, DOI 10.16995/DM.61]
   Sulaiman A, 2019, IEEE ACCESS, V7, P91772, DOI 10.1109/ACCESS.2019.2927286
   Szegedy C., 2015, PROC IEEE C COMPUT V, P1
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tensmeyer C, 2017, PROC INT CONF DOC, P985, DOI 10.1109/ICDAR.2017.164
   Thiede CarstenPeter., 1995, TynBul, V46, P29
   Tigchelaar Eibert., 2010, The Eerdmans Dictionary of Early Judaism, P163
   TOWE KM, 1990, ACCOUNTS CHEM RES, V23, P84, DOI 10.1021/ar00171a005
   Trafela T, 2007, ANAL CHEM, V79, P6319, DOI 10.1021/ac070392t
   Tuniz C., 1998, Accelerator Mass Spectrometry: Ultrasensitive Analysis for Global Science
   Vincent L, 2007, PROC INT CONF DOC, P819
   Wahlberg F, 2016, INT CONF FRONT HAND, P205, DOI [10.1109/ICFHR.2016.114, 10.1109/ICFHR.2016.0048]
   Wahlberg F, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P48, DOI 10.1109/DAS.2016.71
   Wang XG, 2014, PATTERN RECOGN, V47, P2116, DOI 10.1016/j.patcog.2013.12.008
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   WHO, 2012, GLOBAL TUBERCULOSIS REPORT 2012, P1
   WITTEN IH, 1991, IEEE T INFORM THEORY, V37, P1085, DOI 10.1109/18.87000
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yao HT, 2019, IEEE T IMAGE PROCESS, V28, P2860, DOI 10.1109/TIP.2019.2891888
   Zhai CX, 2004, ACM T INFORM SYST, V22, P179, DOI 10.1145/984321.984322
NR 162
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31573
EP 31602
DI 10.1007/s11042-022-12927-8
EA APR 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000779805700006
DA 2024-07-18
ER

PT J
AU Boldaji, MRN
   Semnani, SH
AF Naderi Boldaji, Mohammad Reza
   Hosseini Semnani, Samaneh
TI Color image segmentation using multi-objective swarm optimizer and
   multi-level histogram thresholding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Multi-level thresholding; Multi-objective swarm
   optimizers; 3D histogram
ID ALGORITHM; ENTROPY
AB Rapid developments in swarm intelligence optimizers and computer processing abilities make opportunities to design more accurate, stable, and comprehensive methods for color image segmentation. This paper presents a new way for unsupervised image segmentation by combining histogram thresholding methods (Kapur's entropy and Otsu's method) and different multi-objective swarm intelligence algorithms (MOPSO, MOGWO, MSSA, and MOALO) to thresholding 3D histogram of a color image. More precisely, this method first combines the objective function of traditional thresholding algorithms to design comprehensive objective functions then uses multi-objective optimizers to find the best thresholds during the optimization of designed objective functions. Also, our method uses a vector objective function in 3D space that could simultaneously handle the segmentation of entire image color channels with the same thresholds. To optimize this vector objective function, we employ multi-objective swarm optimizers that can optimize multiple objective functions at the same time. Therefore, our method considers dependencies between channels to find the thresholds that satisfy objective functions of color channels (which we name as vector objective function) simultaneously. Segmenting entire color channels with the same thresholds also benefits from the fact that our proposed method needs fewer thresholds to segment the image than other thresholding algorithms; thus, it requires less memory space to save thresholds. It helps a lot when we want to segment many images to many regions. The subjective and objective results show the superiority of this method to traditional thresholding methods that separately threshold histograms of a color image.
C1 [Naderi Boldaji, Mohammad Reza] Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan 8415683111, Iran.
   [Hosseini Semnani, Samaneh] Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan 8415683111, Iran.
C3 Isfahan University of Technology; Isfahan University of Technology
RP Semnani, SH (corresponding author), Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan 8415683111, Iran.
EM mr.naderi@ec.iut.ac.ir; samane.hosseini@iut.ac.ir
CR Al-Zu'bi S, 2021, MULTIMED TOOLS APPL, V80, P16887, DOI 10.1007/s11042-020-09160-6
   AlZu'bi S, 2020, PATTERN RECOGN LETT, V130, P312, DOI 10.1016/j.patrec.2018.07.026
   AlZu'bi S, 2019, MULTIMED TOOLS APPL, V78, P24223, DOI 10.1007/s11042-018-7003-4
   [Anonymous], 2018, BERKELEY SEGMENTATIO
   Awad M, 2007, IEEE GEOSCI REMOTE S, V4, P571, DOI 10.1109/LGRS.2007.903064
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bao XL, 2019, IEEE ACCESS, V7, P76529, DOI 10.1109/ACCESS.2019.2921545
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P8707, DOI 10.1016/j.eswa.2015.07.025
   Bhandari AK, 2020, IEEE T INSTRUM MEAS, V69, P1871, DOI 10.1109/TIM.2019.2922516
   Breve F, 2019, EXPERT SYST APPL, V123, P18, DOI 10.1016/j.eswa.2019.01.031
   Fredo ARJ, 2017, MEASUREMENT, V100, P270, DOI 10.1016/j.measurement.2017.01.002
   Fu XH, 2018, COMPUT BIOL MED, V98, P147, DOI 10.1016/j.compbiomed.2018.05.015
   Gao H, 2010, IEEE T INSTRUM MEAS, V59, P934, DOI 10.1109/TIM.2009.2030931
   Heidari AA, 2019, FUTURE GENER COMP SY, V97, P849, DOI 10.1016/j.future.2019.02.028
   Hu XX, 2019, IEEE IMAGE PROC, P1440, DOI [10.1109/ICIP.2019.8803025, 10.1109/icip.2019.8803025]
   Jiang YZ, 2017, APPL SOFT COMPUT, V52, P1181, DOI 10.1016/j.asoc.2016.09.008
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Karimpouli S, 2019, COMPUT GEOSCI-UK, V126, P142, DOI 10.1016/j.cageo.2019.02.003
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Lee SH, 2010, PATTERN RECOGN LETT, V31, P2325, DOI 10.1016/j.patrec.2010.07.004
   Li JF, 2019, OPTIK, V183, P30, DOI 10.1016/j.ijleo.2019.02.004
   Manikandan S, 2014, MEASUREMENT, V47, P558, DOI 10.1016/j.measurement.2013.09.031
   Manzke R, 2010, IEEE T MED IMAGING, V29, P260, DOI 10.1109/TMI.2009.2021946
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Mirjalili S, 2017, APPL INTELL, V46, P79, DOI 10.1007/s10489-016-0825-8
   Mirjalili S, 2016, EXPERT SYST APPL, V47, P106, DOI 10.1016/j.eswa.2015.10.039
   Mousavirad SJ, 2017, EVOL INTELL, V10, P45, DOI 10.1007/s12065-017-0152-y
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pare S, 2018, COMPUT ELECTR ENG, V70, P476, DOI 10.1016/j.compeleceng.2017.08.008
   Parsopoulos K.E., 2002, P 2002 ACM S APPL CO, P603, DOI DOI 10.1145/508791.508907
   Qian PJ, 2017, KNOWL-BASED SYST, V130, P33, DOI 10.1016/j.knosys.2017.05.018
   Rafael C.Gonzalez Richard E. Woods., 2018, DIGITAL IMAGE PROCES
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Tan CQ, 2018, LECT NOTES COMPUT SC, V11141, P270, DOI 10.1007/978-3-030-01424-7_27
   Tang N, 2018, NEUROCOMPUTING, V318, P261, DOI 10.1016/j.neucom.2018.08.064
   Yadav D, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICCS), P852, DOI [10.1109/iccs45141.2019.9065881, 10.1109/ICCS45141.2019.9065881]
   Yang AQ, 2018, BIOSYST ENG, V176, P36, DOI 10.1016/j.biosystemseng.2018.10.005
   Yang YY, 2018, MAGN RESON IMAGING, V54, P15, DOI 10.1016/j.mri.2018.06.015
NR 39
TC 2
Z9 2
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30647
EP 30661
DI 10.1007/s11042-022-12443-9
EA APR 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779233200005
DA 2024-07-18
ER

PT J
AU Singh, K
   Malhotra, J
AF Singh, Kuldeep
   Malhotra, Jyoteesh
TI Prediction of epileptic seizures from spectral features of intracranial
   eeg recordings using deep learning approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Epilepsy; Healthcare; Internet of things; Intracranial
   EEG; Cloud computing
ID HEALTH-CARE; INTERNET; THINGS
AB Epilepsy is a prevalent neurological disorder, which disturbs the lives of millions of people worldwide owing to the onset of abrupt seizures. The forecasting of seizures could help in protecting their lives by alerts or in clinical operations during epilepsy surgeries. The present paper addresses this problem by proposing a deep learning framework for prediction of epileptic seizures using intracranial EEG (iEEG) recordings. This framework performs filtering and segmentation of iEEG signals into 10s, 20s, 30s, 40s, 50s and 60s duration segments. These segments are further resolved into eight distinct spectral bands corresponding to delta, theta, alpha, beta and gamma sub-bands with frequency-domain transformation. Then, mean amplitude and band power features are extracted from each band, which are provided to convolutional neural network (CNN) and long short-term memory network (LSTM) algorithms for classification. The simulation results of the proposed CNN model exhibit higher performance with average accuracy, sensitivity, specificity, AUC and F1 score of 94.74%, 95.8%, 94.46%, 95.13% and 94.75% respectively for iEEG segments of 40s duration. Thus, the performance analysis and comparison with existing literature unveil that the proposed CNN model is an optimal approach for accurate and real-time prediction of epileptic seizures.
C1 [Singh, Kuldeep] Guru Nanak Dev Univ, Dept Elect Technol, Amritsar, Punjab, India.
   [Malhotra, Jyoteesh] Guru Nanak Dev Univ, Dept Engn & Technol, Reg Campus, Jalandhar, Punjab, India.
C3 Guru Nanak Dev University; Guru Nanak Dev University
RP Singh, K (corresponding author), Guru Nanak Dev Univ, Dept Elect Technol, Amritsar, Punjab, India.
EM kuldeep.ece@gndu.ac.in
RI Malhotra, Jyoteesh/AAN-9159-2020; Singh, Kuldeep/AAF-1963-2020
OI Malhotra, Jyoteesh/0000-0002-7016-9982; Singh,
   Kuldeep/0000-0003-1465-6740
CR Acharya UR, 2018, COMPUT BIOL MED, V100, P270, DOI 10.1016/j.compbiomed.2017.09.017
   Akrivopoulos O, 2019, J AMB INTEL SMART EN, V11, P237, DOI 10.3233/AIS-190523
   Aktas F, 2018, J MED BIOL ENG, V38, P966, DOI 10.1007/s40846-017-0349-7
   Albawi S, 2017, I C ENG TECHNOL
   Andrews J. R., 1977, SPECTRUM AMPLITUDE D, V699
   Assi E. Bou, 2015, 2015 IEEE Biomedical Circuits and Systems Conference (BioCAS), P1, DOI 10.1109/BioCAS.2015.7348367
   Aziz ANA, 2020, J MATERN-FETAL NEO M, V33, P2751, DOI 10.1080/14767058.2018.1560408
   Baratloo A, 2015, EMERGENCY, V3, P48
   Berendt M, 1999, ACTA NEUROL SCAND, V99, P276, DOI 10.1111/j.1600-0404.1999.tb00676.x
   Boden Mikael, 2002, the Dallas project
   Brinkmann BH, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0133900
   Cavanna AE, 2011, BEHAV NEUROL, V24, P1, DOI 10.3233/BEN-2011-0323
   Chandler K, 2006, VET J, V172, P207, DOI 10.1016/j.tvjl.2005.07.001
   Cho KO, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-019-56958-y
   Darwish A, 2019, J AMB INTEL HUM COMP, V10, P4151, DOI 10.1007/s12652-017-0659-1
   Dastjerdi AV, 2016, COMPUTER, V49, P112, DOI 10.1109/MC.2016.245
   Daud SS, 2015, P INT CONF INTELL, P123, DOI 10.1109/ISMS.2015.29
   Debener S, 2015, SCI REP-UK, V5, DOI 10.1038/srep16743
   Detti P, 2020, PROCESSES, V8, DOI 10.3390/pr8070846
   Dhillon PK, 2019, J AMB INTEL SMART EN, V11, P149, DOI 10.3233/AIS-190516
   Faust O, 2018, COMPUT METH PROG BIO, V161, P1, DOI 10.1016/j.cmpb.2018.04.005
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Howells FM, 2018, TRANSL PSYCHIAT, V8, DOI 10.1038/s41398-018-0105-y
   Hughes JR, 2008, EPILEPSY BEHAV, V13, P25, DOI 10.1016/j.yebeh.2008.01.011
   Hussein R., 2020, ARXIV200711716
   Hussein Ramy, 2019, NEURAL EVOLUTIONARY
   Islam SMR, 2015, IEEE ACCESS, V3, P678, DOI 10.1109/ACCESS.2015.2437951
   Kaggle, 2014, KAGGL AM EP SOC SEIZ
   Kannathal N, 2005, COMPUT METH PROG BIO, V80, P17, DOI 10.1016/j.cmpb.2005.06.005
   Kovac S, 2017, SEIZURE-EUR J EPILEP, V44, P125, DOI 10.1016/j.seizure.2016.10.016
   Kraemer FA, 2017, IEEE ACCESS, V5, P9206, DOI 10.1109/ACCESS.2017.2704100
   Kuhlmann L, 2018, NAT REV NEUROL, V14, P618, DOI 10.1038/s41582-018-0055-2
   Liu CL, 2019, IEEE ACCESS, V7, P170352, DOI 10.1109/ACCESS.2019.2955285
   Ma XL, 2018, LECT NOTES COMPUT SC, V11257, P157, DOI 10.1007/978-3-030-03335-4_14
   Mora H, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102302
   Moretti DV, 2004, CLIN NEUROPHYSIOL, V115, P299, DOI 10.1016/S1388-2457(03)00345-6
   Myers MH, 2016, ANN NEUROSCI, V23, P100, DOI 10.1159/000443567
   Nejedly P, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/ab172d
   Truong ND, 2018, NEURAL NETWORKS, V105, P104, DOI 10.1016/j.neunet.2018.04.018
   NINDS, 2019, FOC EP REEAR NATL I
   Panichev O, 2015, 2015 Signal Processing Symposium (SPSympo)
   Parvez Mohammad Zavid, 2014, 2013 16th International Conference on Computer and Information Technology (ICCIT), P126, DOI 10.1109/ICCITechn.2014.6997315
   Robertson DGE, 2003, J ELECTROMYOGR KINES, V13, P569, DOI 10.1016/S1050-6411(03)00080-4
   Roy Y, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/ab260c
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Salehinejad H., 2017, Recent advances in recurrent neural networks, DOI DOI 10.48550/ARXIV.1801.01078
   Samie F, 2018, DES AUT TEST EUROPE, P955, DOI 10.23919/DATE.2018.8342147
   Singh K, 2021, PHYS ENG SCI MED, V44, P313, DOI 10.1007/s13246-021-00970-y
   Singh K, 2021, P I MECH ENG H, V235, P167, DOI 10.1177/0954411920966937
   Singh K, 2019, J AMB INTEL HUM COMP, DOI 10.1007/s12652-019-01613-7
   Singh K, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P249, DOI 10.1109/ICSCCC.2018.8703357
   Subha DP, 2010, J MED SYST, V34, P195, DOI 10.1007/s10916-008-9231-z
   Sun MR, 2018, IEEE ACCESS, V6, P77596, DOI 10.1109/ACCESS.2018.2883562
   Suto J, 2019, COGN SYST RES, V54, P37, DOI 10.1016/j.cogsys.2018.11.009
   Tsipouras M, 2019, EURASIP J ADV SIG PR, DOI 10.1186/s13634-019-0606-8
   Wang YH, 2016, FRONT NEUROINFORM, V10, DOI 10.3389/fninf.2016.00015
   World Health Organizition, 2019, Epilepsy
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yao X, 2019, NOVEL INDEPENDENT RN
   Zhang J, 2019, ARXIV190106469
   Zhou MN, 2018, FRONT NEUROINFORM, V12, DOI 10.3389/fninf.2018.00095
NR 64
TC 7
Z9 7
U1 3
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28875
EP 28898
DI 10.1007/s11042-022-12611-x
EA MAR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777375900007
DA 2024-07-18
ER

PT J
AU Oktay, AB
   Akhtar, Z
   Gurses, A
AF Oktay, Ayse Betul
   Akhtar, Zahid
   Gurses, Anil
TI Dental biometric systems: a comparative study of conventional
   descriptors and deep learning-based features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dental biometrics; Human identification; Local descriptors; Deep neural
   networks
ID X-RAY IMAGES; AUTOMATIC HUMAN IDENTIFICATION; PATTERN; TEETH
AB Dental biometrics utilizes the evidence divulged by radiographic dental images for human identification. Dental biometrics is commonly used to recognize dead individuals by comparing their before death (ante-mortem) and after death (post-mortem) dental images with the attributes such as tooth contours, restorations, number and shape of the teeth, and relative positions. In recent years, conventional local image descriptors and deep learning based features have shown excellent performances in different applications due to their excellent flexibility and capacity. Regardless of dental biometrics' potential, the efficacy of human identification using dental radiographic images with advanced machine learning methods has not been adequately analyzed so far. In this paper, we investigate various facets of conventional hand-crafted microtextural (12 different descriptors) and deep learning-based features (8 different architectures) for dental biometrics. The dental features of single tooth images (segmented with Mask RCNN) are extracted and the features are matched with various distance functions and fusion techniques. Also, pretraining and fine-tuning transfer learning methods are employed while evaluating deep learning based methods. The empirical analysis, performed on a dataset of 100 dental images and fully reproducible, demonstrates the potential of local microtextural and deep learning tools for dental biometrics. The experiments showed that deep learning based methods with majority voting outperform other methods where Inception architecture has higher identification accuracy. All of the deep learning based methods have at least than 96% Rank-1 accuracy with majority voting.
C1 [Oktay, Ayse Betul; Gurses, Anil] Yildiz Tech Univ, Dept Comp Engn, Istanbul, Turkey.
   [Akhtar, Zahid] State Univ New York Polytech Inst, New York, NY USA.
C3 Yildiz Technical University
RP Oktay, AB (corresponding author), Yildiz Tech Univ, Dept Comp Engn, Istanbul, Turkey.
EM aoktay@yildiz.edu.tr; anilgurses@ieee.org
RI Gurses, Anil/JND-8639-2023
OI Gurses, Anil/0000-0002-8129-3583; Akhtar, Zahid/0000-0002-5026-5416;
   Oktay, Ayse/0000-0003-0827-173X
CR Abdel-Mottaleb M, 2003, Proceedings of the 46th IEEE International Midwest Symposium on Circuits & Systems, Vols 1-3, P411
   Ahonen T., 2008, 19th Intl. Conf. on Pattern Recognition, P1, DOI DOI 10.1109/ICPR.2008.4761847
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Ajaz A, 2013, 2013 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P717, DOI 10.1109/iccsp.2013.6577149
   [Anonymous], 2016, DENT DESIGNATION SYS
   Atheeswaran A., 2014, INT J APPL ENG RES, V9, P4428
   Banday M, 2019, TENCON IEEE REGION, P2363, DOI [10.1109/TENCON.2019.8929642, 10.1109/tencon.2019.8929642]
   Barboza E, 2012, SEMIAUTOMATIC DENT R, P348
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Chan CH, 2007, LECT NOTES COMPUT SC, V4642, P809
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Cui ZM, 2019, PROC CVPR IEEE, P6361, DOI 10.1109/CVPR.2019.00653
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dubey SR, 2019, MULTIMED TOOLS APPL, V78, P16411, DOI 10.1007/s11042-018-7028-8
   Fahmy G, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.2135310
   Fan F, 2020, FORENSIC SCI INT, V314, DOI 10.1016/j.forsciint.2020.110416
   Fan Y, 2019, DENTOMAXILLOFAC RAD, V48, DOI 10.1259/dmfr.20180261
   Frejlichowski D, 2013, LECT NOTES COMPUT SC, V8104, P67, DOI 10.1007/978-3-642-40925-7_7
   Frejlichowski D, 2011, LECT NOTES COMPUT SC, V6855, P65, DOI 10.1007/978-3-642-23678-5_6
   Guises A, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P232, DOI [10.1109/UBMK50275.2020.9219513, 10.1109/ubmk50275.2020.9219513]
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Heinrich A, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-60817-6
   Hofer M, 2007, SIBGRAPI, P281, DOI 10.1109/SIBGRAPI.2007.9
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hwang JJ, 2019, IMAGNG SCI DENT, V49, P1, DOI 10.5624/isd.2019.49.1.1
   Iandola Forrest N, 2016, SQUEEZENET ALEXNET L
   Jader G, 2018, SIBGRAPI, P400, DOI 10.1109/SIBGRAPI.2018.00058
   Jain AK, 2004, PATTERN RECOGN, V37, P1519, DOI 10.1016/j.patcog.2003.12.016
   Joseph LCCJ, 2016, 2016 INTERNATIONAL CONFERENCE ON ENERGY EFFICIENT TECHNOLOGIES FOR SUSTAINABILITY (ICEETS), P802, DOI 10.1109/ICEETS.2016.7583857
   Kannala J, 2012, INT C PATT RECOG, P1363
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai YH, 2020, IEEE POSITION LOCAT, P1, DOI [10.1109/PLANS46316.2020.9109858, 10.1109/plans46316.2020.9109858, 10.1016/j.ibmed.2020.100002]
   Lan RS, 2016, IEEE T IMAGE PROCESS, V25, P566, DOI 10.1109/TIP.2015.2507404
   Lee C, 2019, FORENSIC SCI INT, V299, P229, DOI 10.1016/j.forsciint.2019.04.012
   Lee JH, 2020, OR SURG OR MED OR PA, V129, P635, DOI 10.1016/j.oooo.2019.11.007
   Lin PL, 2010, PATTERN RECOGN, V43, P1380, DOI 10.1016/j.patcog.2009.10.005
   Lin PL, 2012, PATTERN RECOGN, V45, P934, DOI 10.1016/j.patcog.2011.08.027
   LORTON L, 1988, J FORENSIC SCI, V33, P977
   Matsuda S, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-70474-4
   Miki Y, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254332
   Nomir O, 2007, IEEE T INF FOREN SEC, V2, P188, DOI 10.1109/TIFS.2007.897245
   Oktay AB, 2018, IET BIOMETRICS, V7, P349, DOI 10.1049/iet-bmt.2017.0078
   Olberg JV, 2016, SCAND J FORENSIC SCI, V22, P44, DOI 10.1515/sjfs-2016-0008
   Petju M, 2007, PUBLIC HEALTH, V121, P251, DOI 10.1016/j.puhe.2006.12.003
   Reesu GV, 2020, FORENSIC SCI INT, V309, DOI 10.1016/j.forsciint.2020.110218
   Sathya B, 2020, J FORENSIC LEG MED, V76, DOI 10.1016/j.jflm.2020.102066
   Shah N, 2014, WORLD J RADIOL, V6, P794, DOI 10.4329/wjr.v6.i10.794
   Silva G, 2018, EXPERT SYST APPL, V107, P15, DOI 10.1016/j.eswa.2018.04.001
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168
   Tuzoff DV, 2019, DENTOMAXILLOFAC RAD, V48, DOI 10.1259/dmfr.20180051
   UTSUNO DDS, 2019, IATSS RES, V43
   Vijayakumari B, 2020, IET BIOMETRICS, V9, P38, DOI 10.1049/iet-bmt.2019.0064
   Vu NS, 2010, LECT NOTES COMPUT SC, V6311, P313
   WANG YJ, 2018, PHYS MED BIOL, V64
   Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224
   Wu QS, 2021, SENS IMAGING, V22, DOI 10.1007/s11220-020-00326-y
   Zhang HY, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3277958
   Zhang L, 2012, IEEE IMAGE PROC, P81, DOI 10.1109/ICIP.2012.6466800
   Zhang ZY, 2016, PATTERN RECOGN, V60, P189, DOI 10.1016/j.patcog.2016.05.007
   Zhong X, 2013, COMPUT IND, V64, P1355, DOI 10.1016/j.compind.2013.06.005
   Zoroofi HA, 2009, J APPL SCI, V9, DOI 10.3923/jas.2009.2031.2044
NR 64
TC 0
Z9 0
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28183
EP 28206
DI 10.1007/s11042-022-12019-7
EA MAR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000775769200004
DA 2024-07-18
ER

PT J
AU Babu, MM
   Reddy, PC
   Sam, RP
AF Babu, M. Muni
   Reddy, P. Chenna
   Sam, R. Praveen
TI A novel cross-layer based priority aware scheduling scheme for QoE
   guaranteed video transmission over wireless networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video transmission; M-RTP; Path scheduling; Cross-layer design; Priority
   estimation
ID OPTIMIZATION; QUALITY
AB The rapid proliferation of wireless networks increases the demand for video transmission in surveillance, online gaming, video streaming, and other applications. Still, assurance of Quality of Experience (QoE) in video transmission is restricted by multiple constraints, including wireless medium characteristics, multipath routing limitations, and so on. QoE is measured at the source in many prior works, which is not suitable for QoE assurance. This paper addresses all these issues in video transmission over wireless networks with a novel cross-layer design. The proposed cross-layer approach initially measures video quality at a destination based on video quality score (VQS) which is obtained from past destination by application layer, and the feedback is given to the source to guarantee QoE. For improving the quality of video transmission, Quality-based Adaptive Scalable Video Coding (QA-SVC) based video coding is performed in the source node to increase the transmission efficiency. The encoded video is transmitted over multiple paths which are scheduled using the Enriched Particle Swarm Optimization with Multiple Solutions (EPSO-MS) algorithm by considering numerous metrics to reduce the data loss. Improved Artificial Neural Network (IANN) and Deficit Weighted Round Robin (DWRR) are jointly used to schedule the video in intermediate nodes based on priority level which reduces the waiting delay with efficient video quality for transmitting the video before deadline. Video scheduling and priority classification are supported by the Modified Real-time Transport protocol (M-RTP) for fast priority provisioning. QoE of the video is assured and enhanced by performing video quality estimation based on VQS and it is carried out at the destination node using Type-2 Fuzzy Logic (T2FL). Finally, the proposed cross-layer design is modeled in NS-3.26 and evaluated based on throughput (2mbps (high)), jitter (20 ms (low)), goodput (1 mbps(high)), delay (25 ms (low)), Peak Signal-to-Noise Ratio (PSNR) (30 dB (high)), packet drop (7% (low)), bandwidth utilization (20%(high)), and mean opinion score (MOS) (2 (high)).
C1 [Babu, M. Muni; Reddy, P. Chenna] JNT Univ, Dept CSE, Anantapur, Andhra Pradesh, India.
   [Sam, R. Praveen] G Pulla Reddy Engn Coll Kurnool, Dept CSE, Kurnool, Andhra Pradesh, India.
C3 Jawaharlal Nehru Technological University - Anantapur
RP Babu, MM (corresponding author), JNT Univ, Dept CSE, Anantapur, Andhra Pradesh, India.
EM munibabu.m@gmail.com; chennareddy.cse@jntua.ac.in;
   rpraveensam.cse@gprec.ac.in
RI pakanati, chenna reddy/W-5355-2019
OI pakanati, chenna reddy/0000-0001-5348-8028
CR Ahmad SJ, 2016, LECT NOTES COMPUT SC, V9581, P122, DOI 10.1007/978-3-319-28034-9_15
   Al-Zubaidy H, 2017, IEEE T MULTIMEDIA, V19, P2238, DOI 10.1109/TMM.2017.2742399
   Badia L, 2010, IEEE J SEL AREA COMM, V28, P488, DOI 10.1109/JSAC.2010.100419
   Baguda YS, 2020, IEEE ACCESS, V8, P127034, DOI 10.1109/ACCESS.2020.3008257
   Bijur G, 2021, COMPUTERS, V10, DOI 10.3390/computers10040039
   Chenna RB., 2018, ACM INT C DISTR COMP
   Deng R, 2018, MULTIMED TOOLS APPL, V77, P6445, DOI 10.1007/s11042-017-4551-y
   Elgabli A, 2019, IEEE T VEH TECHNOL, V68, P6975, DOI 10.1109/TVT.2019.2915355
   Elgabli A, 2020, IEEE T MOBILE COMPUT, V19, P159, DOI 10.1109/TMC.2018.2889039
   Fan S, 2018, CHINA COMMUN, V15, P215, DOI 10.1109/CC.2018.8456464
   Gao H., 2021, IEEE T INTELL TRANSP, P1, DOI [10.5194/hess-2021-264, DOI 10.1109/TITS.2021.3129458]
   Gao HH, 2021, IEEE T INTELL TRANSP, V22, P3533, DOI 10.1109/TITS.2020.2983835
   Gao HH, 2019, INTELL AUTOM SOFT CO, V25, P547, DOI 10.31209/2019.100000110
   Goswami K, 2018, IEEE T IND ELECTRON, V65, P8861, DOI 10.1109/TIE.2018.2815941
   Gupta P, 2018, INT C INT THINGS SMA
   Hasan MZ, 2018, IEEE ACCESS, V6, P20371, DOI 10.1109/ACCESS.2018.2822551
   Huang YZ, 2021, IEEE T GREEN COMMUN, V5, P670, DOI 10.1109/TGCN.2021.3067374
   Khan N, 2016, EURASIP J WIREL COMM, DOI 10.1186/s13638-016-0584-6
   Kirubha D., 2018, CLUSTER COMPUT, V22, P1
   Lal C, 2018, WIREL NETW, V24, P235, DOI 10.1007/s11276-016-1325-9
   Li CL, 2018, IEEE T MULTIMEDIA, V20, P361, DOI 10.1109/TMM.2017.2745709
   Li F, 2010, IET COMMUN, V4, P1012, DOI 10.1049/iet-com.2009.0618
   Li GY, 2018, INT J COMMUN SYST, V31, DOI 10.1002/dac.3778
   Li PS, 2022, IEEE T INTELL TRANSP, V23, P2762, DOI 10.1109/TITS.2021.3085026
   Lin CH, 2013, IEEE T MULTIMEDIA, V15, P195, DOI 10.1109/TMM.2012.2225028
   Liu PS, 2017, COMM COM INF SC, V728, P184, DOI 10.1007/978-981-10-6388-6_16
   Lu W, 2018, INT J DIGIT MULTIMED, V2018, DOI 10.1155/2018/1413026
   Lu Z, 2019, IEEE T MULTIMEDIA, V21, P197, DOI 10.1109/TMM.2018.2847240
   Ma XJ, 2021, IEEE T NETW SERV MAN, V18, P4002, DOI 10.1109/TNSM.2021.3125395
   Mahmood A, 2018, IEEE WCNC
   Mercat A, 2020, MMSYS'20: PROCEEDINGS OF THE 2020 MULTIMEDIA SYSTEMS CONFERENCE, P297, DOI 10.1145/3339825.3394937
   MohideenBadhusha S, 2018, INT J COMMUN SYST, V31
   Quang PTA, 2017, IEEE T VEH TECHNOL, V66, P1533, DOI 10.1109/TVT.2016.2552041
   Prakash PB, 2018, WIRELESS PERS COMMUN, P1
   Pudlewski S, 2015, IEEE J-STSP, V9, DOI 10.1109/JSTSP.2014.2342202
   Quinlan JJ, 2018, INFORMATION, V9, DOI 10.3390/info9030059
   Sah DK, 2018, COMPUT SCI REV, V27, P112, DOI 10.1016/j.cosrev.2017.12.002
   Sandeep GS, 2017, ADV INTELL SYST COMP, P628
   Sedrati M, 2018, WIRELESS PERS COMMUN, V99, P999, DOI 10.1007/s11277-017-5163-6
   Song S, 2019, IEEE ACCESS, V7, P146470, DOI 10.1109/ACCESS.2019.2945357
   Pham TAQ, 2018, AD HOC NETW, V80, P1, DOI 10.1016/j.adhoc.2018.07.005
   Wan Z, 2018, WIRELESS PERS COMMUN, V102, P2417, DOI 10.1007/s11277-018-5262-z
   Wu JY, 2018, IEEE T CIRC SYST VID, V28, P2007, DOI 10.1109/TCSVT.2017.2695368
   Wu JY, 2018, IEEE T MULTIMEDIA, V20, P457, DOI 10.1109/TMM.2017.2741425
   Wu JY, 2017, IEEE ACM T NETWORK, V25, P2701, DOI 10.1109/TNET.2017.2701153
   Wu JY, 2017, IEEE T MOBILE COMPUT, V16, P1090, DOI 10.1109/TMC.2016.2584049
   Wu JY, 2017, IEEE J SEL AREA COMM, V35, P30, DOI 10.1109/JSAC.2016.2632599
   Wu JY, 2016, IEEE T MOBILE COMPUT, V15, P2345, DOI 10.1109/TMC.2015.2497238
   Wu JY, 2016, IEEE T COMMUN, V64, P2477, DOI 10.1109/TCOMM.2016.2553138
   HoangVan X, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9060915
   Xu DY, 2004, 2004 IEEE Workshop on IP Operations and Management Proceedings (IPOM 2004), P191, DOI 10.1109/IPOM.2004.1547616
   Xu ZY, 2020, IEEE T MULTIMEDIA, V22, P445, DOI 10.1109/TMM.2019.2929965
   Yan T, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9010166
   Yang H, 2018, MULTIMED TOOLS APPL, V77, P4453, DOI 10.1007/s11042-016-4245-x
   Zhang ZW, 2017, IEEE ACCESS, V5, P26328, DOI 10.1109/ACCESS.2017.2748138
   Zhao P, 2016, J COMMUN NETW-S KOR, V18, P806, DOI 10.1109/JCN.2016.000109
   Zhao TS, 2017, IEEE COMMUN SURV TUT, V19, P285, DOI 10.1109/COMST.2016.2619982
   Zheng X, 2017, IEEE T MOBILE COMPUT, V16, P1787, DOI 10.1109/TMC.2016.2613529
   Zhou JW, 2019, SIGNAL PROCESS-IMAGE, V76, P118, DOI 10.1016/j.image.2019.03.016
NR 59
TC 1
Z9 2
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28129
EP 28164
DI 10.1007/s11042-022-12896-y
EA MAR 2022
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000774644100003
DA 2024-07-18
ER

PT J
AU Coelho, MS
   Melo, CA
   Da Fonseca, NLS
AF Coelho, Maiara Souza
   Melo, Cesar A., V
   da Fonseca, Nelson L. S.
TI An encoding-aware bitrate adaptation mechanism for video streaming over
   HTTP
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bitrate adaptation mechanism; HTTP streaming; Video QoE metric; Video
   encoding awareness
AB The great interest in flix-like services has amplified multimedia traffic over the Internet. Recently released traffic forecasting predicts that video-related traffic will be responsible for the majority of Internet traffic by 2022. Such traffic will come in a wide range of duration and in the two modes of live and on-demand. Additionally, it is expected to scale and deliver a smoothed experience to an already fragmented audience. The adaptive bitrate over Hypertext Transfer Protocol (HTTP) has emerged as the top technology for multimedia content transport and delivery. Despite the large amount of work in this area, running streaming applications on overload channels still demands the development of effective strategies. In this work, a video bitrate adaptation mechanism deployed in an overloaded channel of an access network is proposed and evaluated under live and on-demand service modes. This mechanism makes decisions regarding bitrate switching based on the Quality of Experience (QoE)-related parameters to accommodate conflicting variables of its design space, namely, image quality, session continuity and short play time. To evaluate this mechanism, a multifactor QoE metric is proposed based on session parameters such as stalls, startup delay, image quality and the mechanism bitrate misalignment. Moreover, in the numerical studies for the evaluation of the effectiveness of the proposed mechanism, the average video bitrate, instability and fairness are measured. Overall, the proposed mechanism was able to improve the session QoE for both live and on-demand modes.
C1 [Coelho, Maiara Souza; Melo, Cesar A., V] Univ Fed Amazonas, Inst Comp, Manaus, Amazonas, Brazil.
   [da Fonseca, Nelson L. S.] Univ Estadual Campinas, Inst Comp, Campinas, SP, Brazil.
C3 Universidade Federal de Amazonas; Universidade Estadual de Campinas
RP Coelho, MS (corresponding author), Univ Fed Amazonas, Inst Comp, Manaus, Amazonas, Brazil.
EM maiara@icomp.ufam.edu.br; nfonseca@ic.unicamp.br
OI COELHO, MAIARA/0000-0002-1582-2715; Fonseca, Nelson L. S.
   da/0000-0003-2046-602X; Viana Melo, Cesar Augusto/0000-0002-6868-8548
FU Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior -Brasil
   (CAPES) [001]; Fundacao de Amparo `a Pesquisa do Estado do Amazonas
   [024/2014]
FX This study was financed in part by the Coordenacao de Aperfeicoamento de
   Pessoal de Nivel Superior -Brasil (CAPES) -Finance Code 001 and by the
   Fundacao de Amparo `a Pesquisa do Estado do Amazonas -Finance Code
   024/2014.
CR [Anonymous], 2014, P 5 ACM MULT SYST C, DOI DOI 10.1145/2557642.2563671
   Ayad I, 2018, COMPUT NETW, V133, P90, DOI 10.1016/j.comnet.2018.01.019
   Bampis CG, 2018, SIGNAL PROCESS-IMAGE, V68, P218, DOI 10.1016/j.image.2018.05.017
   Barman N, 2019, IEEE ACCESS, V7, P30831, DOI 10.1109/ACCESS.2019.2901778
   Beben A, 2016, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON MULTIMEDIA SYSTEMS (MMSYS'16), P13, DOI 10.1145/2910017.2910596
   Bentaleb A, 2019, IEEE COMMUN SURV TUT, V21, P562, DOI 10.1109/COMST.2018.2862938
   Bouraqia K, 2020, IEEE ACCESS, V8, P13341, DOI 10.1109/ACCESS.2020.2965099
   Brown M. A., 2006, GUIDE IP LAYER NETWO
   Bulkan U, 2019, MULTIMED TOOLS APPL, V78, P18787, DOI 10.1007/s11042-019-7164-9
   CISCO, 2018, CISCO VISUAL NETWORK, P1
   Coelho MdS, 2017, IEEE INT C COMM ICC, P1, DOI [10.1109/ICC.2017.7996743, DOI 10.1109/ICC.2017.7996743]
   Corporation A, 2020, HTTP LIVE STREAMING
   ISO/IEC, 2019, Technical Report
   Jiang JC, 2017, PROCEEDINGS OF NSDI '17: 14TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P393
   Jiang JC, 2014, IEEE ACM T NETWORK, V22, P326, DOI 10.1109/TNET.2013.2291681
   Juluri P, 2016, IEEE COMMUN SURV TUT, V18, P401, DOI 10.1109/COMST.2015.2401424
   Juluri P, 2015, IEEE INT CONF COMM, P1765, DOI 10.1109/ICCW.2015.7247436
   Mao HZ, 2017, SIGCOMM '17: PROCEEDINGS OF THE 2017 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P197, DOI 10.1145/3098822.3098843
   Murugadoss R., 2020, Int. J. Fut. Gener. Commun. Netw., V13, P1491
   Pantos R., 2017, Http live streaming, DOI DOI 10.17487/RFC8216
   Petrangeli S, 2017, J NETW COMPUT APPL, V94, P78, DOI 10.1016/j.jnca.2017.07.009
   Spiteri K, 2016, IEEE INFOCOM SER, DOI 10.1109/infocom.2016.7524428
   Sun LH, 2020, INT GEOL REV, V62, P1094, DOI 10.1080/00206814.2019.1669079
   Tian GB, 2016, IEEE ACM T NETWORK, V24, P2386, DOI 10.1109/TNET.2015.2464700
   Thang TC, 2014, IEEE J SEL AREA COMM, V32, P693, DOI 10.1109/JSAC.2014.140403
   Wilk S, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2983636
   Wisniewski P, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3092837
NR 27
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27423
EP 27451
DI 10.1007/s11042-022-12520-z
EA MAR 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000780464800012
DA 2024-07-18
ER

PT J
AU Soni, N
   Sharma, EK
   Kapoor, A
AF Soni, Neha
   Sharma, Enakshi Khular
   Kapoor, Amita
TI Deep neural network and 3D model for face recognition with multiple
   disturbing environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Occlusion; Bird swarm algorithm; Convolution neural
   network; Shuffled shepherd optimization
AB This paper presents the proposed bird search-based shuffled shepherd optimization algorithm (BSSSO) for face recognition. Initially, the input image undergoes a noise removal phase to eliminate noise in order to make them suitable for subsequent processing. The noise removal is performed using the type II fuzzy system and cuckoo search optimization algorithm (T2FCS), which detects noisy pixels from the image for improved processing. After the noise removal phase, the feature extraction is carried out using the convolution neural network (CNN) model and landmark enabled 3D morphable model (L3DMM). The obtained features are subjected to deep CNN for face recognition. The training of deep CNN is performed using the bird search-based shuffled shepherd optimization algorithm (BSSSO). Here, the proposed BSSSO is designed by combining the shuffled shepherd optimization algorithm (SSOA) and bird swarm algorithm (BSA) for inheriting the merits of both optimizations towards effective training of deep CNN. The proposed method obtained higher accuracy of 0.8935 and minimum FAR and FRR of 0.2190 and 0.2021 using LFW database with respect to training data.
C1 [Soni, Neha; Sharma, Enakshi Khular] Univ Delhi, Dept Elect Sci, South Campus, Delhi, India.
   [Kapoor, Amita] Univ Delhi, Shaheed Rajguru Coll Appl Sci Women, Delhi, India.
C3 University of Delhi; University of Delhi
RP Soni, N (corresponding author), Univ Delhi, Dept Elect Sci, South Campus, Delhi, India.
EM soni.neha2191@gmail.com
FU Department of Science & Technology (DST), Ministry of Science &
   Technology, New Delhi, India
FX One of the authors, Neha Soni, wants to thank the Department of Science
   & Technology (DST), Ministry of Science & Technology, New Delhi, India,
   for the financial support as DST Inspire Fellow.
CR Abdelmaksoud M, 2020, IEEE ACCESS, V8, P102212, DOI 10.1109/ACCESS.2020.2999030
   Ahsan MM, 2020, J SENS ACTUAR NETW, V9, DOI 10.3390/jsan9040054
   Arsenovic M, 2017, P IEEE 15 INT S INT
   Chen ZW, 2017, MULTIMED TOOLS APPL, V76, P17669, DOI 10.1007/s11042-015-2882-0
   Chen Z, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107118
   Gao GW, 2020, INFORM SCIENCES, V506, P19, DOI 10.1016/j.ins.2019.08.004
   Gulli Antonio, 2019, Deep Learning with TensorFlow 2 and Keras
   He MJ, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107113
   Hu HL, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON NETWORKING, ARCHITECTURE AND STORAGE (NAS)
   Iranmanesh SM, 2020, IMAGE VISION COMPUT, V94, DOI 10.1016/j.imavis.2019.103861
   Kapoor A., 2019, Handson Artificial Intelligence for IOT
   Kaveh A, 2021, ENG COMPUT-GERMANY, V37, P3265, DOI 10.1007/s00366-020-00999-9
   Knyazev B, 2018, IEEE INT CONF AUTOMA, P692, DOI 10.1109/FG.2018.00109
   Kortli Y, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020342
   Kumar SV, 2019, J VIS COMMUN IMAGE R, V58, P619, DOI 10.1016/j.jvcir.2018.12.020
   Li XX, 2020, J AMB INTEL HUM COMP, V11, P2349, DOI 10.1007/s12652-019-01257-7
   Li YT, 2020, ACM T SENSOR NETWORK, V16, DOI 10.1145/3397179
   Marsot M, 2020, COMPUT ELECTRON AGR, V173, DOI 10.1016/j.compag.2020.105386
   Meng XB, 2016, J EXP THEOR ARTIF IN, V28, P673, DOI 10.1080/0952813X.2015.1042530
   Peng B, 2016, IEEE IMAGE PROC, P3932, DOI 10.1109/ICIP.2016.7533097
   Prasad PS, 2020, LECT NOTES ELECTR EN, V570, P419, DOI 10.1007/978-981-13-8715-9_50
   Soni N, 2018, INT C HUM SYST ENG D
   Soni N., 2019, IMPACT ARTIFICIAL IN
   Soni N, 2016, 2016 INT C WIR COMM
   Soni N, 2021, J COMPUT SCI-NETH, V51, DOI 10.1016/j.jocs.2021.101352
   Soni N, 2018, ADV INTELL SYST, V563, P39, DOI 10.1007/978-981-10-6872-0_4
   Vishwakarma VP, 2020, MULTIMED TOOLS APPL, V79, P11503, DOI 10.1007/s11042-019-08537-6
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Yang WK, 2020, NEUROCOMPUTING, V373, P109, DOI 10.1016/j.neucom.2019.09.102
   Zangeneh E, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112854
NR 30
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25319
EP 25343
DI 10.1007/s11042-022-12698-2
EA MAR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000771882200001
DA 2024-07-18
ER

PT J
AU Linssen, L
   Landman, A
   van Baardewijk, JU
   Bottenheft, C
   Binsch, O
AF Linssen, Lotte
   Landman, Annemarie
   van Baardewijk, Jan Ubbo
   Bottenheft, Charelle
   Binsch, Olaf
TI Using accelerometry and heart rate data for real-time monitoring of
   soldiers' stress in a dynamic military virtual reality scenario
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VR-Training; Stress; Monitoring; Heart rate; Accelerometry; Military
ID BODY
AB Real-time physiological stress monitoring would be a relevant addition to virtual reality (VR) training for high-risk professions, such as the military. VR is highly suitable for the implementation of such monitoring due to the controlled environment and the already used wearables. However, physiological stress measurements suffer from distortion due to physical activity. Therefore, we tested whether we can use accelerometry to correct non-invasively measured heart rate (HR) for physical activity in 23 soldiers who performed three room-clearing VR scenarios. These scenarios were dynamic, in that soldiers moved around in the VR environment by walking around in the real environment. In contrast to uncorrected HR, and HR corrected by subtracting baseline HR measured when walking, the accelerometry-corrected HR was able to significantly predict the participants' self-reported stress in the scenarios, p = 0.047, R-2 = 0.11. Whereas uncorrected HR significantly predicted self-reported physical demand, p = 0.028, R-2 = 0.09, the accelerometry-corrected HR did not. All HR measures significantly predicted self-reported mental effort, which was most strongly the case for uncorrected HR, p < 0.001 R-2 = 0.42. These findings, in combination with the methods' low sensitivity to motion artifacts and non-invasiveness, are very promising for its use to monitor stress in real-time during dynamic VR training scenarios.
C1 [Linssen, Lotte; Landman, Annemarie; van Baardewijk, Jan Ubbo; Bottenheft, Charelle; Binsch, Olaf] Netherlands Org Appl Sci Res TNO, Dept Human Performance, Soesterberg, Netherlands.
C3 Netherlands Organization Applied Science Research
RP Linssen, L (corresponding author), Netherlands Org Appl Sci Res TNO, Dept Human Performance, Soesterberg, Netherlands.
EM Lotte.linssen@tno.nl
FU Dutch Department of Defense
FX Funding for this project was provided by the Dutch Department of
   Defense.
CR Altini M, 2015, IEEE J BIOMED HEALTH, V19, P219, DOI 10.1109/JBHI.2014.2313039
   [Anonymous], 1993, THESIS DELFT U TECHN
   Bhagat KK, 2016, VIRTUAL REAL-LONDON, V20, P127, DOI 10.1007/s10055-016-0284-x
   Binsch O, 2021, MIL PSYCHOL, V33, P182, DOI 10.1080/08995605.2021.1897494
   BLIX AS, 1974, AEROSPACE MED, V45, P1219
   Bos JE, 2008, DISPLAYS, V29, P47, DOI 10.1016/j.displa.2007.09.002
   Brouwer AM, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00284
   Cain B., 2007, A Review of the Mental Workload Literature. Technical Report
   de Waard D., 1996, Thesis fully internal (DIV
   Folkman S., 1984, STRESS APPRAISAL COP, P150
   FURNHAM A, 1986, PERS INDIV DIFFER, V7, P385, DOI 10.1016/0191-8869(86)90014-0
   Grossman P, 2004, AM J PHYSIOL-HEART C, V287, pH728, DOI 10.1152/ajpheart.00825.2003
   Hancock P.A., 2008, Performance under stress
   HART S G, 1988, P139
   HOUTMAN ILD, 1989, J PERS ASSESS, V53, P575, DOI 10.1207/s15327752jpa5303_14
   KALTON G, 1982, J ROY STAT SOC A STA, V145, P42, DOI 10.2307/2981421
   Kavanagh J., 2005, STRESS PERFORMANCE R
   Kim HG, 2018, PSYCHIAT INVEST, V15, P235, DOI 10.30773/pi.2017.08.17
   Królak A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20216372
   LIANG KY, 1993, ANNU REV PUBL HEALTH, V14, P43, DOI 10.1146/annurev.pu.14.050193.000355
   MYRTEK M, 1986, PSYCHOPHYSIOLOGY, V23, P663, DOI 10.1111/j.1469-8986.1986.tb00690.x
   Myrtek M, 1996, BIOL PSYCHOL, V42, P147, DOI 10.1016/0301-0511(95)05152-X
   Myrtek M, 2000, J PSYCHOPHYSIOL, V14, P106, DOI 10.1027//0269-8803.14.2.106
   Myrtek M., 2004, HEART EMOTION AMBULA
   Noori FM, 2019, INT WORK CONTENT MUL
   Pallavicini F, 2016, AEROSP MED HUM PERF, V87, P1021, DOI 10.3357/AMHP.4596.2016
   PAN J, 1985, IEEE T BIO-MED ENG, V32, P230, DOI 10.1109/TBME.1985.325532
   Perry CM, 2008, THEOR ISS ERGON SCI, V9, P95, DOI 10.1080/14639220600959237
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Qasem L, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0031187
   Re-liON, 2018, RE LION BLACKSUIT VI
   ROTH DL, 1990, PSYCHOPHYSIOLOGY, V27, P694, DOI 10.1111/j.1469-8986.1990.tb03196.x
   Saunders T, 1996, J Occup Health Psychol, V1, P170, DOI 10.1037/1076-8998.1.2.170
   Sedghamiz H., 2014, MATLAB IMPLEMENTATIO
   Stevens J.A., 2015, OPEN J MODELLING SIM, V2015, P41, DOI [DOI 10.4236/OJMSI.2015.32005, https://doi.org/10.4236/ojmsi.2015.32005]
   Streb J, 2015, TRENDS NEUROSCI EDUC, V4, P102, DOI 10.1016/j.tine.2015.11.001
   TURNER JR, 1988, PSYCHOPHYSIOLOGY, V25, P209, DOI 10.1111/j.1469-8986.1988.tb00990.x
   Whitney SJ, 2014, J DEF MODEL SIMUL-AP, V11, P319, DOI 10.1177/1548512912472773
   Zheng BY, 2000, STAT MED, V19, P1265, DOI 10.1002/(SICI)1097-0258(20000530)19:10<1265::AID-SIM486>3.0.CO;2-U
   Zijlstra F.R.H., 1985, CONSTRUCTION SCALE M
   Zijlstra FRH., 1989, MENTALE BELASTING WE, P42
NR 41
TC 7
Z9 7
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24739
EP 24756
DI 10.1007/s11042-022-12705-6
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000771380200010
DA 2024-07-18
ER

PT J
AU Gao, JX
   Gao, XM
   Wu, N
   Yang, HY
AF Gao, Jinxiong
   Gao, Xiumei
   Wu, Nan
   Yang, Hongye
TI Bi-directional LSTM with multi-scale dense attention mechanism for
   hyperspectral image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral image classification; Long-short term memory; Dense
   attention mechanism
ID RECURRENT NEURAL-NETWORKS; REPRESENTATION
AB Feature representation has always been the top priority of research in the field of hyperspectral image (HSI) classification. Efficient analysis of those features extracted from HSI massively depends on the way how features are represented. In this paper, we propose a bi-directional long short-term memory network (Bi-LSTM)-based multi-scale dense attention framework, namely MBDA-Net. In this framework, we develop a new multi-scale dense attention module (MCDA) that uses different sizes of convolution kernels to obtain multi-scale features. Then, we perform feature selection by using a multi-layer attention mechanism that assigns different weight coefficients to the extracted multi-scale features. Specifically, we use the bi-directional LSTM to obtain contextual semantic information. The extensive experiments conducted on three hyperspectral datasets demonstrate the effectiveness of our method in identifying hyperspectral images.
C1 [Gao, Jinxiong; Gao, Xiumei; Wu, Nan; Yang, Hongye] Inner Mongolia Univ Technol, Hohhot 010050, Peoples R China.
C3 Inner Mongolia University of Technology
RP Gao, JX (corresponding author), Inner Mongolia Univ Technol, Hohhot 010050, Peoples R China.
EM 254716786@qq.com
RI Wu, Nan/ABI-4409-2020
FU Inner Mongolia natural science foundation [RZ1900004206]
FX This work was supported by the Inner Mongolia natural science foundation
   (Grant No.RZ1900004206).
CR Bai L., 2021, IEEE GEOSCI REMOTE S, V2021, P1
   Buters T, 2019, DRONES-BASEL, V3, DOI 10.3390/drones3030053
   Cai WW, 2021, MULTIMED TOOLS APPL, V80, P11291, DOI 10.1007/s11042-020-10188-x
   Cai WW, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2020.3026587
   Chakouri M., 2020, Int. J., V9, P5772
   Chen JZ, 2019, IEEE ACCESS, V7, P81407, DOI 10.1109/ACCESS.2019.2923776
   Gao HM, 2019, IEEE ACCESS, V7, P176587, DOI 10.1109/ACCESS.2019.2957163
   Ghamisi P, 2018, IEEE GEOSC REM SEN M, V6, P10, DOI 10.1109/MGRS.2018.2854840
   Hao SY, 2021, IEEE T GEOSCI REMOTE, V59, P2448, DOI 10.1109/TGRS.2020.3005623
   Haut JM, 2019, IEEE T GEOSCI REMOTE, V57, P8065, DOI 10.1109/TGRS.2019.2918080
   Hsieh TH, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061734
   Hu WS, 2020, IEEE T GEOSCI REMOTE, V58, P4237, DOI 10.1109/TGRS.2019.2961947
   Jia BB, 2020, CHEMOMETR INTELL LAB, V198, DOI 10.1016/j.chemolab.2020.103936
   Li W, 2017, IEEE T GEOSCI REMOTE, V55, P844, DOI 10.1109/TGRS.2016.2616355
   Liu QS, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9121330
   Ma WP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111307
   Mei XG, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11080963
   Mou LC, 2017, IEEE T GEOSCI REMOTE, V55, P3639, DOI 10.1109/TGRS.2016.2636241
   Paoletti ME, 2018, ISPRS J PHOTOGRAMM, V145, P120, DOI 10.1016/j.isprsjprs.2017.11.021
   Paoletti ME, 2020, J SUPERCOMPUT, V76, P8866, DOI 10.1007/s11227-020-03187-0
   Paoletti ME, 2019, IEEE T GEOSCI REMOTE, V57, P740, DOI 10.1109/TGRS.2018.2860125
   Pasolli E, 2018, ADV HYPERSPECTRAL IM
   Peng Z, 2017, ARXIV PREPRINT ARXIV, P2021
   Qin J, 2019, INT GEOSCI REMOTE SE, P2985, DOI [10.1109/igarss.2019.8900335, 10.1109/IGARSS.2019.8900335]
   Qin J, 2018, INT GEOSCI REMOTE SE, P4776, DOI 10.1109/IGARSS.2018.8518946
   Salman M, 2018, SIG PROCESS COMMUN
   Sankey TT, 2018, REMOTE SENS ECOL CON, V4, P20, DOI 10.1002/rse2.44
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Ventura D, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10091331
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P911, DOI 10.1109/TGRS.2018.2862899
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P1155, DOI 10.1109/TGRS.2018.2864987
   Wang ZS, 2020, IEEE ACCESS, V8, P71353, DOI 10.1109/ACCESS.2020.2986267
   Xia XL, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P783, DOI 10.1109/ICIVC.2017.7984661
   Xiaoqiang Y, 2022, EXPERT SYST APPL, V187
   Yang GF, 2018, INT GEOSCI REMOTE SE, P2595, DOI 10.1109/IGARSS.2018.8517520
   Yang JF, 2020, INT J REMOTE SENS, V41, P7163, DOI 10.1080/01431161.2020.1754496
   Yo HF, 2020, IEEE T GEOSCI REMOTE, V58, P1281, DOI 10.1109/TGRS.2019.2945591
   Zhang S, 2020, IEEE T GEOSCI REMOTE, V58, P4764, DOI 10.1109/TGRS.2020.2966805
   Zhou F, 2019, NEUROCOMPUTING, V328, P39, DOI 10.1016/j.neucom.2018.02.105
NR 39
TC 6
Z9 6
U1 5
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24003
EP 24020
DI 10.1007/s11042-022-12809-z
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770754000015
DA 2024-07-18
ER

PT J
AU Puri, A
   Alsadoon, A
   Prasad, PWC
   Al-Neami, I
   Haddad, S
AF Puri, Anjana
   Alsadoon, Abeer
   Prasad, P. W. C.
   Al-Neami, Israa
   Haddad, Sami
TI Augmented reality for visualization the narrow areas in jaw surgery:
   modified Correntropy based enhanced ICP algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Iterative Closest Point (ICP); Image registration;
   Correntropy; Jaw surgery
ID NAVIGATION SYSTEM; REGISTRATION
AB Over time, Augmented Reality (AR) based technology becomes not being properly to implement with oral and maxillofacial surgery to visualise the narrow area spot in jaw surgery as blood vassals and root canals in these types of surgeries. Image registration is considered the major limitation of using the AR in these types of surgeries and reduces the accuracy of visualising the narrow areas. In this research, we propose a Correntropy based scale ICP algorithm as a solution to improve the image registration during jaw surgery. Correntropy is considered here to minimise the error metric of the ICP algorithm instead of the Euclidean distance measurement compared to the state-of-the-art solution. This led to decrease the registration error, increase the video accuracy and reduce the processing time simultaneously. The proposed system consists of Enhanced Tracking Learning Detection (TLD), which is used as an occlusion removal featured algorithm in the intra-operative stage of the AR-based jaw surgery system. In this research, a Modified Correntropy-based enhanced ICP (MCbeICP) algorithm is proposed for the system's pose-refinement phase. Moreover, this proposed algorithm (MCbeICP) has a new function to process the point set registration with great noises and outliers. It eliminates the poor performance of the ICP algorithm of the noisy point set. Furthermore, the ICP algorithm considers the scale factor to register the point with different scales of the real-time video and the sample models. Additionally, this method improves the result of the pose refinement stage in terms of registration accuracy and processing time. By this method, the pose refinement stage gives an improved result in terms of registration accuracy and processing time. The samples, which were taken from the upper (maxillary) and the lower (mandible) jaw bone show that the proposed algorithm provides a significant accuracy improvement in alignment to 0.21- 0.29 mm from 0.23 to 0.35 mm and an increment in processing time from 8 to 12 frames per second (fs/s) to 10-14 fs/s compared to the result provided by state of the art. The proposed augmented reality (AR) system is focused on the overlay accuracy and processing time. Finally, this study addressed the limitation of Image registration with AR using modified Correntropy-based enhanced ICP algorithm to implement oral and maxillofacial surgery successfully.
C1 [Puri, Anjana; Alsadoon, Abeer; Prasad, P. W. C.] Charles Sturt Univ CSU, Sch Comp & Math, Sydney Campus, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Univ Western Sydney UWS, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Southern Cross Univ SCU, Sch Informat Technol, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Asia Pacif Int Coll APIC, Dept Informat Technol, Sydney, NSW, Australia.
   [Al-Neami, Israa] Univ Technol Baghdad, Dept Comp Engn, Baghdad, Iraq.
   [Haddad, Sami] Greater Western Sydney Area Hlth Serv, Dept Oral & Maxillofacial Serv, North Parramatta, Australia.
   [Haddad, Sami] Cent Coast Area Hlth, Dept Oral & Maxillofacial Serv, Gosford, Australia.
C3 Charles Sturt University; Western Sydney University; Southern Cross
   University; University of Technology- Iraq; Florey Institute of
   Neuroscience & Mental Health
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp & Math, Sydney Campus, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Univ Western Sydney UWS, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Southern Cross Univ SCU, Sch Informat Technol, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Asia Pacif Int Coll APIC, Dept Informat Technol, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; withana,
   chandana/0000-0002-3007-687X
CR Basnet BR, 2018, ORAL MAXILLOFAC SURG, V22, P385, DOI 10.1007/s10006-018-0719-5
   Bernhardt S, 2017, MED IMAGE ANAL, V37, P66, DOI 10.1016/j.media.2017.01.007
   Chen XJ, 2015, J BIOMED INFORM, V55, P124, DOI 10.1016/j.jbi.2015.04.003
   Choi H, 2017, MINIM INVASIV THER, V26, P144, DOI 10.1080/13645706.2016.1274766
   Choi H, 2016, INT J MED ROBOT COMP, V12, P62, DOI 10.1002/rcs.1657
   Du S, 2018, PATTERN RECOGNIT LET
   Du SY, 2019, MULTIMEDIA SYST, V25, P119, DOI 10.1007/s00530-017-0573-6
   Gao QH, 2018, MULTIMED TOOLS APPL, P1
   Gao QH, 2017, 2017 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P41, DOI 10.1109/CW.2017.44
   Hettig J, 2018, INT J COMPUT ASS RAD, V13, P1717, DOI 10.1007/s11548-018-1825-4
   Jiang WP, 2018, INT J ORAL MAX IMPL, V33, P1219, DOI 10.11607/jomi.6638
   Li L., 2016, PLoS One, V11, P1, DOI DOI 10.1371/JOURNAL.PONE.0144219
   Ma LF, 2019, MED BIOL ENG COMPUT, V57, P47, DOI 10.1007/s11517-018-1861-9
   Mahmoud N, 2017, INT J COMPUT ASS RAD, V12, P1, DOI 10.1007/s11548-016-1444-x
   Meng FL, 2018, INT J COMPUT ASS RAD, V13, P253, DOI 10.1007/s11548-017-1675-5
   Murugesan YP, 2018, INT J MED ROBOT COMP, V14, DOI 10.1002/rcs.1889
   Pokhrel S, 2019, INT J MED ROBOT COMP, V15, DOI 10.1002/rcs.1958
   Scuderi GR, 2014, ORTHOP CLIN N AM, V45, P167, DOI 10.1016/j.ocl.2013.11.002
   Shin S, 2015, IEEE ENG MED BIO, P5272, DOI 10.1109/EMBC.2015.7319581
   Somogyi-Ganss E, 2015, CLIN ORAL IMPLAN RES, V26, P882, DOI 10.1111/clr.12414
   Suenaga H, 2015, BMC MED IMAGING, V15, DOI 10.1186/s12880-015-0089-5
   Suenaga H, 2013, INT J ORAL SCI, V5, P98, DOI 10.1038/ijos.2013.26
   Ulrich M, 2012, IEEE T PATTERN ANAL, V34, P1902, DOI 10.1109/TPAMI.2011.266
   Wang JH, 2020, IEEE T CYBERNETICS, V50, P2971, DOI 10.1109/TCYB.2019.2891265
   Wang JC, 2017, INT J MED ROBOT COMP, V13, DOI 10.1002/rcs.1754
   Wang JC, 2013, LECT NOTES COMPUT SC, V8090, P9, DOI 10.1007/978-3-642-40843-4_2
   Wang JC, 2014, IEEE T BIO-MED ENG, V61, P1295, DOI 10.1109/TBME.2014.2301191
   Yamaguchi S, 2009, LECT NOTES COMPUT SC, V5622, P633, DOI 10.1007/978-3-642-02771-0_70
   Zhang WB, 2016, COMPUT ASSIST SURG, V21, P137, DOI 10.1080/24699322.2016.1187767
   Zhu M, 2017, SCI REP-UK, V7, DOI 10.1038/srep42365
NR 30
TC 0
Z9 0
U1 11
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24319
EP 24345
DI 10.1007/s11042-022-11963-8
EA MAR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770549500003
OA hybrid
DA 2024-07-18
ER

PT J
AU Chung, JH
   Kim, DW
   Kang, TK
   Lim, MT
AF Chung, Jun Ho
   Kim, Dong Won
   Kang, Tae Koo
   Lim, Myo Taeg
TI ADM-Net: attentional-deconvolution module-based net for noise-coupled
   traffic sign recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Traffic sign recognition; Attention
   mechanism; Deconvolution; Fully convolutional network
ID DEEP NEURAL-NETWORK; SEGMENTATION; SYSTEMS; CNN
AB Convolutional Neural Networks (CNNs) have become primary technologies in computer vision systems across multiple fields. Its central characteristic is to slide filters on input images and repeats the same procedures to obtain the image's robust features. However, conventional CNNs struggle to classify objects when the input images are contaminated by unavoidable external noises such as missing information, blur, or illumination. This paper proposes an attentional-deconvolution module (ADM)-based net(ADM-Net) in which ADMs, convolutional-pooling, and a fully convolutional network (FCN) are applied to improve classification under such harsh conditions. The structure of ADM includes an attention layer, deconvolution layer and max-pooling. The attention layer and convolutional pooling help the proposed network maintain key features through convolution procedures under noise-coupled environments. The deconvolution layers and fully convolutional structure have advantages in providing additional information from upscale feature maps and enabling the network to store local pixel information. The ADM-Net was demonstrated on the German traffic sign recognition benchmark with different noise cases comparing densenet, multi-scale CNN, a committee of CNN, hierarchical CNN, and a multi-column deep neural network. Demonstrations of ADM-Net achieve the highest records in different cases such as 1) blur and missing information case: 86.637%, 2) missing information and illumination case: 92.329%, and 3) blur, missing information, and illumination case: 80.221%. Training datasets for ADM-Net have limited conditions, the proposed network demonstrates its robustness effectively under noise-coupled environments.
C1 [Chung, Jun Ho; Lim, Myo Taeg] Korea Univ, Sch Elect Engn, Seoul, South Korea.
   [Kim, Dong Won] Inha Tech Coll, Dept Digital Elect, Incheon, South Korea.
   [Kang, Tae Koo] Sangmyung Univ, Dept Human Intelligence & Robot Engn, Cheonan, South Korea.
C3 Korea University; Inha Technical College; Inha University; Sangmyung
   University
RP Lim, MT (corresponding author), Korea Univ, Sch Elect Engn, Seoul, South Korea.; Kim, DW (corresponding author), Inha Tech Coll, Dept Digital Elect, Incheon, South Korea.
EM junho9503@korea.ac.kr; dwnkim@inhatc.ac.kr; tkkang@smu.ac.kr;
   mlim@korea.ac.kr
OI Kim, Dong W/0000-0002-8700-4199; Lim, Myo Taeg/0000-0003-2990-8066
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2016R1D1A1B01016071,
   NRF-2017R1D1A1B03031467]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (NRF-2016R1D1A1B01016071 and NRF-2017R1D1A1B03031467).
CR [Anonymous], 2014, Advances in Neural Information Processing Systems
   Arcos-Garcia A., 2012, NEURAL NETWORKS, V99, P165
   Bengio Yoshua, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P437, DOI 10.1007/978-3-642-35289-8_26
   Bi Q, 2020, NEUROCOMPUTING, V377, P345, DOI 10.1016/j.neucom.2019.11.068
   Cheng G, 2021, SCI CHINA INFORM SCI, V64, DOI 10.1007/s11432-020-3156-7
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Chu X, 2017, PROC CVPR IEEE, P5669, DOI 10.1109/CVPR.2017.601
   Chung JH, 2020, NEURAL PROCESS LETT, V51, P2551, DOI 10.1007/s11063-020-10211-0
   Ciresan D, 2012, NEURAL NETWORKS, V32, P333, DOI 10.1016/j.neunet.2012.02.023
   Ciresan D, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P1918, DOI 10.1109/IJCNN.2011.6033458
   Ding XH, 2019, IEEE I CONF COMP VIS, P1911, DOI 10.1109/ICCV.2019.00200
   Du WB, 2018, IEEE T IMAGE PROCESS, V27, P1347, DOI 10.1109/TIP.2017.2778563
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Girshick R., 2014, P IEEE C COMP VIS PA, P580
   Gudigar A, 2019, NEURAL COMPUT APPL, V31, P395, DOI 10.1007/s00521-017-3063-z
   Hamker FH, 2004, NEUROCOMPUTING, V56, P329, DOI 10.1016/j.neucom.2003.09.006
   Haque WA, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114481
   Hechri A, 2020, IET IMAGE PROCESS, V14, P939, DOI 10.1049/iet-ipr.2019.0634
   Hong I, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.06.011
   Huang GL, 2017, IEEE ICC
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Ji YF, 2020, IEEE T GEOSCI REMOTE, V58, P3941, DOI 10.1109/TGRS.2019.2959702
   Jin JQ, 2014, IEEE T INTELL TRANSP, V15, P1991, DOI 10.1109/TITS.2014.2308281
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lateef F, 2019, NEUROCOMPUTING, V338, P321, DOI 10.1016/j.neucom.2019.02.003
   Li X, 2018, PATTERN RECOGN, V79, P183, DOI 10.1016/j.patcog.2018.01.015
   Liu CS, 2016, IEEE T INTELL TRANSP, V17, P79, DOI 10.1109/TITS.2015.2459594
   Liu D, 2020, IEEE T IMAGE PROCESS, V29, P3695, DOI 10.1109/TIP.2020.2964518
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P5655, DOI 10.1109/TNNLS.2017.2787781
   Liu ZG, 2019, IEEE ACCESS, V7, P57120, DOI 10.1109/ACCESS.2019.2913882
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.48550/ARXIV.1411.4038
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P7885, DOI 10.1109/TPAMI.2021.3115815
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XA, 2017, IEEE T INTELL TRANSP, V18, P960, DOI 10.1109/TITS.2016.2598356
   Luo HL, 2018, IEEE T INTELL TRANSP, V19, P1100, DOI 10.1109/TITS.2017.2714691
   Mao T, 2018, COMPUT CHEM ENG, V118, P77, DOI 10.1016/j.compchemeng.2018.07.009
   Mhalla A, 2019, IMAGE VISION COMPUT, V88, P120, DOI 10.1016/j.imavis.2019.03.002
   Mogelmose A, 2012, IEEE T INTELL TRANSP, V13, P1484, DOI 10.1109/TITS.2012.2209421
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Pang YW, 2018, IEEE T NEUR NET LEAR, V29, P1587, DOI 10.1109/TNNLS.2017.2676130
   Saedi SI, 2020, EXPERT SYST APPL, V159, DOI 10.1016/j.eswa.2020.113594
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10
   Sermanet P, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2809, DOI 10.1109/IJCNN.2011.6033589
   Sharma S., 2016, ARXIV151104119
   Shen JL, 2021, INFORM SCIENCES, V569, P469, DOI 10.1016/j.ins.2020.11.026
   Simonyan K., 2014, 14091556 ARXIV
   Springenberg Jost Tobias, 2015, Striving for simplicity: The all convolutional net, DOI DOI 10.48550/ARXIV.1412.6806
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stallkamp J, 2012, NEURAL NETWORKS, V32, P323, DOI 10.1016/j.neunet.2012.02.016
   Sun ML, 2017, NEUROCOMPUTING, V224, P96, DOI 10.1016/j.neucom.2016.10.049
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tabernik D, 2020, IEEE T INTELL TRANSP, V21, P1427, DOI 10.1109/TITS.2019.2913588
   Timofte R., 2021, MACH VIS APPL, V25, P647
   van Noord N, 2017, PATTERN RECOGN, V61, P583, DOI 10.1016/j.patcog.2016.06.005
   Vidnerová P, 2020, NEURAL NETWORKS, V127, P168, DOI 10.1016/j.neunet.2020.04.015
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Wickramasinghe CS, 2019, IEEE T IND INFORM, V15, P5837, DOI 10.1109/TII.2019.2906083
   Wojna Z, 2017, PROC INT CONF DOC, P844, DOI 10.1109/ICDAR.2017.143
   Wong A, 2018, IEEE ACCESS, V6, P59803, DOI 10.1109/ACCESS.2018.2873948
   Xie BQ, 2019, IEEE ACCESS, V7, P53330, DOI 10.1109/ACCESS.2019.2912311
   Yan Z, 2018, IET INTELL TRANSP SY, V12, P186, DOI 10.1049/iet-its.2017.0066
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P7126, DOI 10.1109/TNNLS.2021.3084250
   Yang SM, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.601109
   Yang SM, 2020, IEEE T NEUR NET LEAR, V31, P148, DOI 10.1109/TNNLS.2019.2899936
   Yang SM, 2019, IEEE T FUZZY SYST, V27, P304, DOI 10.1109/TFUZZ.2018.2856182
   Yang SM, 2018, PHYSICA A, V494, P484, DOI 10.1016/j.physa.2017.11.155
   Yuan Y, 2019, IEEE T IMAGE PROCESS, V28, P3423, DOI 10.1109/TIP.2019.2896952
   Zeiler MD, 2013, ARXIV13013557, P2278
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
NR 71
TC 2
Z9 2
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 23373
EP 23397
DI 10.1007/s11042-022-12219-1
EA MAR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000770549800012
DA 2024-07-18
ER

PT J
AU Kenye, L
   Kala, R
AF Kenye, Lhilo
   Kala, Rahul
TI An Ensemble of Spatial Clustering and Temporal Error Profile Based
   Dynamic Point Removal for visual Odometry
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual odometry; Visual localization; SLAM; Pose estimation; Dynamic
   environments
ID SIMULTANEOUS LOCALIZATION
AB Visual odometry in the field of computer vision and robotics is a well-known approach with which the position and orientation of an agent can be obtained using only images from a camera or multiple of them. In most traditional point feature-based visual odometry, one important assumption and also an ideal condition is that the scene remains static. In environments with dynamic objects, this assumption can lead to erroneous pose estimations. Though most modern systems that use visual odometry are equipped with approaches which reduce the effects of dynamic objects, having a module that can help the system to have a pre-understanding on the behaviour of features can better reduce errors. This work proposes complementary approaches suitable for different types of situations that filter out dynamic points as an ensemble: clustering triangulated points intended for reducing the effects of moving objects, analysing the reprojection errors and checking the consistency of points in three-dimensional space. The techniques employ a stereo camera and filtered points are passed through perspective-n-point for pose estimation. The approaches are tested on publicly available TUM dataset, as well as self-collected datasets with sequences containing dynamic objects in the scene. Results confirm that filtering the points before using them for pose estimation reduces errors in the trajectory.
C1 [Kenye, Lhilo; Kala, Rahul] Indian Inst Informat Technol, Ctr Intelligent Robot, Jhalwa, Prayagraj, India.
   [Kenye, Lhilo] NavAjna Technol Private Ltd, Hyderabad, India.
C3 Indian Institute of Information Technology Allahabad
RP Kenye, L (corresponding author), Indian Inst Informat Technol, Ctr Intelligent Robot, Jhalwa, Prayagraj, India.; Kenye, L (corresponding author), NavAjna Technol Private Ltd, Hyderabad, India.
EM lkenye02@gmail.com
FU Mercedes-Benz Research & Development India; Indian Institute of
   Information Technology, Allahabad; NavAjna Technologies Pvt. Ltd.
FX This work is supported by NavAjna Technologies Pvt. Ltd., Mercedes-Benz
   Research & Development India and the Indian Institute of Information
   Technology, Allahabad.
CR An LF, 2017, INT J ADV ROBOT SYST, V14, DOI 10.1177/1729881417735667
   Azartash Haleh, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1280, DOI 10.1109/ICASSP.2014.6853803
   Bak A, 2014, MACH VISION APPL, V25, P681, DOI 10.1007/s00138-011-0389-x
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754
   Gao XS, 2003, IEEE T PATTERN ANAL, V25, P930, DOI 10.1109/TPAMI.2003.1217599
   Kitt B, 2010, IEEE INT C INT ROBOT, P5551, DOI 10.1109/IROS.2010.5650517
   Labbé M, 2019, J FIELD ROBOT, V36, P416, DOI 10.1002/rob.21831
   Lee S, 2019, ABS190708388
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6
   Lucas B., 1981, Proc. DARPA Image Understanding Workshop, P121
   Maimone M, 2007, J FIELD ROBOT, V24, P169, DOI 10.1002/rob.20184
   Moreno-Noguer F., 2007, 2007 IEEE 11 INT C C, P1
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Nistér D, 2004, PROC CVPR IEEE, P652
   Parra Ignacio, 2008, 2008 IEEE Intelligent Vehicles Symposium (IV), P440, DOI 10.1109/IVS.2008.4621277
   Pire T, 2017, ROBOT AUTON SYST, V93, P27, DOI 10.1016/j.robot.2017.03.019
   Scaramuzza D, 2011, IEEE ROBOT AUTOM MAG, V18, P80, DOI 10.1109/MRA.2011.943233
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Zhang Y, 2018, IEEE IND ELEC, P5648, DOI 10.1109/IECON.2018.8591053
   Zou DP, 2013, IEEE T PATTERN ANAL, V35, P354, DOI 10.1109/TPAMI.2012.104
NR 21
TC 1
Z9 1
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 23259
EP 23288
DI 10.1007/s11042-022-12063-3
EA MAR 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000770549800001
DA 2024-07-18
ER

PT J
AU Naderi, H
   Goli, L
   Kasaei, S
AF Naderi, Hanieh
   Goli, Leili
   Kasaei, Shohreh
TI Generating unrestricted adversarial examples via three parameteres
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unrestricted adversarial examples; Transformation; Attack; Adversarial
   training
AB Deep neural networks have been shown to be vulnerable to adversarial examples deliberately constructed to misclassify victim models. As most adversarial examples have restricted their perturbations to the L-p-norm, existing defense methods have focused on these types of perturbations and less attention has been paid to unrestricted adversarial examples; which can create more realistic attacks, able to deceive models without affecting human predictions. To address this problem, the proposed adversarial attack method generates an unrestricted adversarial example with a limited number of parameters. The attack selects three points on the input image and based on their locations transforms the image into an adversarial example. By limiting the range of movement and location of these three points and by using a discriminatory network, the proposed unrestricted adversarial example preserves the image appearance. Experimental results show that the proposed adversarial examples obtain an average success rate of 93.5% in terms of human evaluation on the MNIST and SVHN datasets. It also reduces the model accuracy by an average of 73% on six datasets MNIST, FMNIST, SVHN, CIFAR10, CIFAR100, and ImageNet. The adversarial train of the attack also improves the model robustness against a randomly transformed image.
C1 [Naderi, Hanieh; Goli, Leili; Kasaei, Shohreh] Sharif Univ Technol, Dept Comp Sci & Engn, Tehran, Iran.
C3 Sharif University of Technology
RP Naderi, H (corresponding author), Sharif Univ Technol, Dept Comp Sci & Engn, Tehran, Iran.
EM hnaderi@ce.sharif.edu
FU Iran National Science Foundation (INSF)
FX LL The authors would like to thank Dr. Seyed-Mohsen Moosavi-Dezfooli for
   the helpful discussions. This work was partly supported by a grant from
   Iran National Science Foundation (INSF).
CR Alaifari Rima, 2018, ARXIV180407729
   Alcorn MA, 2019, PROC CVPR IEEE, P4840, DOI 10.1109/CVPR.2019.00498
   [Anonymous], 2019, ARXIV190406347
   Athalye A, 2018, PR MACH LEARN RES, V80
   Brown, 2017, ADVERSARIAL PATCH
   Brown T. B., 2018, ARXIV180908352
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Cohen TS, 2016, PR MACH LEARN RES, V48
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Dong YP, 2018, PROC CVPR IEEE, P9185, DOI 10.1109/CVPR.2018.00957
   Engstrom L., 2017, arXiv preprint arXiv:1712.02779
   Engstrom L, 2019, PR MACH LEARN RES, V97
   Eykholt K, 2018, PROC CVPR IEEE, P1625, DOI 10.1109/CVPR.2018.00175
   Fawzi A., 2015, ARXIV150706535
   Furui S, 2012, IEEE SIGNAL PROC MAG, V29, P16, DOI 10.1109/MSP.2012.2209906
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Gupta S, 2021, ARCH COMPUT METHOD E, V28, P2209, DOI 10.1007/s11831-020-09452-y
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ho CH, 2019, PROC CVPR IEEE, P9221, DOI 10.1109/CVPR.2019.00945
   Hosseini H, 2018, IEEE COMPUT SOC CONF, P1695, DOI 10.1109/CVPRW.2018.00212
   Huq A., 2020, P 2020 INT C DAT SCI, P1, DOI DOI 10.1109/ICODSA50139.2020.9212850
   Jaderberg M, 2015, ADV NEUR IN, V28
   Kanbak C, 2018, PROC CVPR IEEE, P4441, DOI 10.1109/CVPR.2018.00467
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar M, 2020, ARTIF INTELL REV, V53, P2075, DOI 10.1007/s10462-019-09727-2
   Kurakin A., 2016, Adversarial machine learning at scale
   Laptev D, 2016, PROC CVPR IEEE, P289, DOI 10.1109/CVPR.2016.38
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Madry A., 2018, ARXIV
   Marcos D, 2017, IEEE I CONF COMP VIS, P5058, DOI 10.1109/ICCV.2017.540
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Naderi H, 2020, 2020 INT C MACH VIS, P1
   Netzer Yuval, 2011, ADV NEUR INF PROC SY
   Poursaeed O, 2019, ARXIV191109058
   Riba E, 2020, IEEE WINT CONF APPL, P3663, DOI 10.1109/WACV45572.2020.9093363
   Shen X., 2016, Proceedings of the 24th ACM international conference on Multimedia, P1345, DOI 10.1145/2964284.2964316
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sitawarin C., 2018, Darts: Deceiving autonomous cars with toxic signs
   Song Y., 2018, ADV NEURAL INFPROCES, P8312
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tramer F., 2020, ADAPTIVE ATTACKS ADV
   Tramer Florian, 2017, Ensemble adversarial training: Attacks and defenses
   Xiao Chaowei, 2018, 6 INT C LEARN REPR I
   Xiao H., 2017, ARXIV170807747
   Zhao H., 2019, ARXIV191001329
NR 48
TC 5
Z9 5
U1 4
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21919
EP 21938
DI 10.1007/s11042-022-12007-x
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000770205800003
DA 2024-07-18
ER

PT J
AU Kumar, R
   Kumar, N
   Jung, KH
AF Kumar, Rajeev
   Kumar, Neeraj
   Jung, Ki-Hyun
TI Enhanced interpolation-based AMBTC image compression using Weber's law
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AMBTC; Image compression; Interpolation; Weber's law; PSNR
ID BLOCK; ALGORITHM; SCHEME
AB In this paper, we propose a new enhanced absolute moment block truncation coding (AMBTC) image compression method based on interpolation. The proposed compression method takes the human visual system characteristics into the account using Weber's law while compressing the image so that perceived image quality is maintained. Further, the low and high mean values of AMBTC trios are efficiently represented along with bit-plane so that number of bits representing the bit-plane can be reduced. As a result, the proposed method significantly reduces the number of bits to represent the compressed image without any visual image quality degradation.
C1 [Kumar, Rajeev] Delhi Technol Univ, Dept Comp Sci & Engn, Delhi, India.
   [Kumar, Neeraj] Jamia Milia Islamia Univ, Dept Elect & Commun, Delhi, India.
   [Jung, Ki-Hyun] Kyungil Univ, Dept Cyber Secur, Gyongsan, South Korea.
C3 Delhi Technological University; Jamia Millia Islamia; Kyungil University
RP Jung, KH (corresponding author), Kyungil Univ, Dept Cyber Secur, Gyongsan, South Korea.
EM khanny.jung@gmail.com
RI Kumar, Rajeev/IUP-5006-2023; Kumar, Neeraj/L-3500-2016
OI Kumar, Rajeev/0000-0002-5000-7644; Kumar, Neeraj/0000-0002-3020-3947;
   Jung, Ki-Hyun/0000-0002-0662-8355
FU National Research Foundation of Korea (NRF) - Ministry of Education
   [2021R1I1A3049788]; Ministry of Science and ICT through the National
   Research Foundation of Korea [2019H1D3A1A01101687, 2021H1D3A2A01099390]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by theMinistry of
   Education (2021R1I1A3049788) and Brain Pool program funded by the
   Ministry of Science and ICT through the National Research Foundation of
   Korea (2019H1D3A1A01101687, 2021H1D3A2A01099390).
CR Amarunnishad T. M., 2006, ADCOM 2006: Autonomic Computing Fourteenth International Conference on Advanced Computing and Communications, P344
   [Anonymous], 1834, PULSU ABSORTIONE AUD
   CHEN DP, 1990, IEEE T COMMUN, V38, P2137, DOI 10.1109/26.64656
   Chuang JC, 2020, MULTIMED TOOLS APPL, V79, P28189, DOI 10.1007/s11042-020-09325-3
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Dhara BC, 2004, PATTERN RECOGN, V37, P2131, DOI 10.1016/j.patcog.2004.02.008
   HALVERSON DR, 1984, IEEE T ACOUST SPEECH, V32, P664, DOI 10.1109/TASSP.1984.1164341
   Hameed MA., 2012, ALMUSTANSIRIYA J SCI, V23, P87
   Hu YC, 2004, J ELECTRON IMAGING, V13, P871, DOI 10.1117/1.1785158
   Hu YC, 2003, ELECTRON LETT, V39, P1377, DOI 10.1049/el:20030884
   Hu YC, 2003, OPT ENG, V42, P1964, DOI 10.1117/1.1576776
   Hui, 2018 8 INT C IM PROC, DOI [10.1109/IPTA.2018.8608124, DOI 10.1109/IPTA.2018.8608124]
   Kumar R, 2015, MULTIMED TOOLS APPL, P1
   Kumar R, 2019, MULTIMED TOOLS APPL, V78, P32239, DOI 10.1007/s11042-019-07997-0
   Kumar R, 2019, 2019 6TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P854, DOI [10.1109/SPIN.2019.8711774, 10.1109/spin.2019.8711774]
   Kumar R, 2019, 2019 6TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P903, DOI [10.1109/SPIN.2019.8711635, 10.1109/spin.2019.8711635]
   Kumar R, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P1399, DOI 10.1109/CCAA.2016.7813937
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   RAO YVR, 1995, IEEE T COMMUN, V43, P2010, DOI 10.1109/26.387439
   VAISEY J, 1992, IEEE T SIGNAL PROCES, V40, P2040, DOI 10.1109/78.150005
   WU YY, 1992, IEEE J SEL AREA COMM, V10, P952, DOI 10.1109/49.139000
   Xiang ZY, 2019, MULTIMED TOOLS APPL, V78, P7895, DOI 10.1007/s11042-018-6030-5
   Yang CK, 1997, IEEE T COMMUN, V45, P1513, DOI 10.1109/26.650223
   Yin ZX, 2018, MULTIMED TOOLS APPL, V77, P18067, DOI 10.1007/s11042-017-4957-6
   ZENG B, 1991, ELECTRON LETT, V27, P1126, DOI 10.1049/el:19910703
NR 25
TC 4
Z9 4
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 20817
EP 20828
DI 10.1007/s11042-022-12634-4
EA MAR 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000767922000002
DA 2024-07-18
ER

PT J
AU MirMashhouri, A
   Bastanfard, A
   Amirkhani, D
AF MirMashhouri, Abbas
   Bastanfard, Azam
   Amirkhani, Dariush
TI Collecting a database for emotional responses to simple and patterned
   two-color images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Affective response; Color emotion; Emotion classification; Thayer
   psychology model; Self-assessment manikins; Multimedia database
ID COLOR-EMOTION; CIRCUMPLEX MODEL; PREFERENCE
AB One of the most important challenges in the field of affective computing is the collection of databases from human color-based affective responses. This multimedia database has many applications in anthropology, sociology, psychology, computer, and graphics. However, researches have conducted some research on the affective aspect of monochrome images. Unfortunately, a complete and coherent database is not available to researchers right now. In this paper, data collection for multimedia affective response is tailored to images with two adjacent colors. Here, we examined the color parameters luminance, chrominance, and color hue in the images as well as the observers' characteristics such as age, gender, and education level. To this end, the observers obtained a simple and a patterned two-color image by posting images on a website and using the Self-Assessment Manikin (SAM) technique. A total of 171 simple two-color images and 105 patterned two-color images were considered. The total number of observers was 405, and finally, 4757 responses were collected. Finally, by statistically examining the effect of the mentioned parameters on the emotional valence and arousal, we found that lightness, hue, and pattern parameters had the greatest effect on the value of emotions (valence), but arousal was more related to lightness and chrominance parameters. The parameters were lightness and chrominance. This Two-Color Affective Response (TCAR) database is suitable for processing using advanced computer algorithms such as clustering and classification. The entire data collection process, including color selection to make images, getting emotional responses, and evaluation, was fully described.
C1 [MirMashhouri, Abbas; Bastanfard, Azam] Islamic Azad Univ, Dept Comp Engn, Karaj Branch, Karaj, Iran.
   [Amirkhani, Dariush] Univ Quebec Outaouais, Dept Comp Sci & Engn, Gatineau, PQ, Canada.
C3 Islamic Azad University; University of Quebec; University Quebec
   Outaouais
RP Bastanfard, A (corresponding author), Islamic Azad Univ, Dept Comp Engn, Karaj Branch, Karaj, Iran.
EM minnashhouri@gmail.com; Bastanfard@kiau.ac.ir; amid01@uqo.ca
RI Amirkhani, Dariush/IYT-2131-2023; Bastanfard, Azam/AAX-8571-2020
OI Bastanfard, Azam/0000-0002-7935-819X; Amirkhani,
   Dariush/0000-0001-5653-9644
CR Amirkhani D, 2021, MULTIMED TOOLS APPL, V80, P26199, DOI 10.1007/s11042-021-10883-3
   Amirkhani D, 2019, 2019 5TH IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS 2019), DOI 10.1109/icspis48872.2019.9066140
   Bastanfard A, 2004, COMPUT ANIMAT VIRT W, V15, P347, DOI 10.1002/cav.38
   Bastanfard A, IEEE C KNOWL BAS ENG, P592
   Bastos AF, 2020, IEEE POW ENER SOC GE, DOI 10.1109/pesgm41954.2020.9281989
   Bezooijen RV., 1984, CHARACTERISTICS RECO, DOI [10.1515/9783110850390, DOI 10.1515/9783110850390]
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Cacioppo J.T., 2000, Handbook of Emotions, P173
   Clarke T, 2008, COLOR RES APPL, V33, P406, DOI 10.1002/col.20435
   Cusano C, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21031010
   D'Zmura M, 1998, VISION RES, V38, P3455, DOI 10.1016/S0042-6989(97)00407-0
   Darwin C., 1965, EXPRESS EMOT MAN, DOI [10.7208/chicago/9780226220802.001.0001, DOI 10.7208/CHICAGO/9780226220802.001.0001]
   Ekman P., 2000, HDB COGNITION EMOTIO, P51
   Fathi Ahmadsaraei M, 2021, J MACHINE VISION IMA, P13
   Gao XP, 2007, COLOR RES APPL, V32, P223, DOI 10.1002/col.20321
   Gilbert AN, 2016, FOOD QUAL PREFER, V52, P203, DOI 10.1016/j.foodqual.2016.04.007
   Hanada M, 2018, COLOR RES APPL, V43, P224, DOI 10.1002/col.22171
   Hargrave S, 1982, LANGUAGE CULTURE, P201
   He L, 2015, SIGNAL IMAGE VIDEO P, V9, P1965, DOI 10.1007/s11760-014-0691-y
   Hemphill M, 1996, J GENET PSYCHOL, V157, P275, DOI 10.1080/00221325.1996.9914865
   Hofmann M., 2005, CONTENT NETWORKING A, P179, DOI [10.1016/B978-155860834-4/50026-3, DOI 10.1016/B978-155860834-4/50026-3]
   Holden R., 2013, OXFORD DICT
   Kaya N., 2004, COLL STUD J, V38, P396
   Keltner D., 2000, Handbook of emotions, Vsecond, P236
   Kobayashi S., 1992, COLOR IMAGE SCALE
   Lang P. J., 1999, A4 U FLOR CTR RES PS
   Lee MF, 2016, MULTIMED TOOLS APPL, V75, P15185, DOI 10.1007/s11042-014-2231-8
   Liu D, 2018, PATTERN RECOGN LETT, V110, P16, DOI 10.1016/j.patrec.2018.03.015
   Loia V, 2014, FUZZY ORIENTED SENTI
   MATSUMOTO D, 1990, MOTIV EMOTION, V14, P195, DOI 10.1007/BF00995569
   Ou LC, 2004, COLOR RES APPL, V29, P381, DOI 10.1002/col.20047
   Ou LC, 2004, COLOR RES APPL, V29, P292, DOI 10.1002/col.20024
   Ou LC, 2004, COLOR RES APPL, V29, P232, DOI 10.1002/col.20010
   Panigrahy C, 2020, PATTERN ANAL APPL, V23, P819, DOI 10.1007/s10044-019-00839-7
   Pantic M, 2003, P IEEE, V91, P1370, DOI 10.1109/JPROC.2003.817122
   Picard RW., 2000, AFFECTIVE COMPUTING, DOI [10.7551/mitpress/1140.001.0001, DOI 10.7551/MITPRESS/1140.001.0001]
   Pittman RE, TAXONOMY LEARNING
   Posner J, 2005, DEV PSYCHOPATHOL, V17, P715, DOI 10.1017/S0954579405050340
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Savargiv M, 2016, 2016 ARTIFICIAL INTELLIGENCE AND ROBOTICS (IRANOPEN), P72, DOI 10.1109/RIOS.2016.7529493
   Shigeno S., 1998, P ICSLP, P281
   Solli M, 2011, COLOR RES APPL, V36, P210, DOI 10.1002/col.20604
   Suk HJ, 2010, COLOR RES APPL, V35, P64, DOI 10.1002/col.20554
   Tao JH, 2005, LECT NOTES COMPUT SC, V3784, P981
   Thayer R., 1989, BIOPSYCHOLOGY MOOD A
   VALDEZ P, 1994, J EXP PSYCHOL GEN, V123, P394, DOI 10.1037/0096-3445.123.4.394
   Wei-Ning W, 2006, IEEE SYS MAN CYBERN, P3534, DOI 10.1109/ICSMC.2006.384667
   Wierzbicka A., 1993, Pragmatics Cognition, V1, P1
   Wierzbicka A., 1996, SEMANTICS PRIMES UNI
NR 49
TC 6
Z9 6
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18935
EP 18953
DI 10.1007/s11042-022-11966-5
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000767089800004
DA 2024-07-18
ER

PT J
AU Panneerselvam, IR
AF Panneerselvam, Ithaya Rani
TI Transfer learning autoencoder used for compressing multimodal biosignal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biosignal; Health monitoring system; Wearable IoT device; micro-sensors;
   micro-hub; Wireless communication; Multimodal compression; Transfer
   learning
ID ECG; PHYSIONET; RESOURCE
AB Electrocardiogram, electromyogram, electroencephalogram are the foremost required vital signs for diagnosing chronic diseases like sleep disorder, mood disorder, epilepsy etc., which demands long-term monitoring. A sensor based wearable system which is enabled with internet technology, supports the continuous recordings of these vital signs without troubling the patient's daily activities. And the wearable hub is responsible for collecting the readings of biosignals from multiple micro-sensor nodes deployed around the body which creates the short range of communication and forward to the observer. These continuous monitoring increases the signal transmission cost and declines the battery life of wearables. So, the observed multiple biosignals can be compressed jointly than individually before sending, at an edge level. This paper proposes transfer learning based multimodal convolutional denoising auto encoder to perform multimodal compression and to reconstruct the data from its latent representation. Transfer learning helps the system to reuse the learned weights which may reconstruct the data with better quality score than by randomly initialized weights. The proposed work achieves compression ratio of 128 and it is proved that multimodal compression is better than unimodal compression in case of consuming multiple sensors. And the experimental result proves that the computation cost is low in multimodal compression than in unimodal compression.
C1 [Panneerselvam, Ithaya Rani] Koneru Lakshmaiah Educ Fdn KLEF, Dept Comp Sci & Engn, Vijayawada, Andhra Pradesh, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Panneerselvam, IR (corresponding author), Koneru Lakshmaiah Educ Fdn KLEF, Dept Comp Sci & Engn, Vijayawada, Andhra Pradesh, India.
EM muhilrani@gmail.com
CR AHMED B, 2017, IEEE WIREL COMMUN NE
   Ameri A, 2020, IEEE T NEUR SYS REH, V28, P370, DOI 10.1109/TNSRE.2019.2962189
   Andrzejak RG, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.061907
   Cao YS, 2020, IEEE ACCESS, V8, P94757, DOI 10.1109/ACCESS.2020.2995442
   Carotti ESG, 2009, IEEE T BIO-MED ENG, V56, P2604, DOI 10.1109/TBME.2009.2027691
   Chambon S, 2018, IEEE T NEUR SYS REH, V26, P758, DOI 10.1109/TNSRE.2018.2813138
   Chiang HT, 2019, IEEE ACCESS, V7, P60806, DOI 10.1109/ACCESS.2019.2912036
   Craven D, 2015, IEEE J BIOMED HEALTH, V19, P529, DOI 10.1109/JBHI.2014.2327194
   Del Testa D, 2015, IEEE SIGNAL PROC LET, V22, P2304, DOI 10.1109/LSP.2015.2476667
   Dixon AMR, 2012, IEEE T BIOMED CIRC S, V6, P156, DOI 10.1109/TBCAS.2012.2193668
   Dong BW, 2021, MULTIMED TOOLS APPL, V80, P33865, DOI 10.1007/s11042-021-11205-3
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Hooshmand M, 2017, IEEE INTERNET THINGS, V4, P1647, DOI 10.1109/JIOT.2017.2689164
   Hu JL, 2016, IEEE T IMAGE PROCESS, V25, P5576, DOI 10.1109/TIP.2016.2612827
   Huang SH, 2019, IEEE INTERNET THINGS, V6, P10627, DOI 10.1109/JIOT.2019.2940131
   Jin L, 2017, J CLIN NEUROSCI, V43, P130, DOI 10.1016/j.jocn.2017.04.035
   Kerner HR, 2019, IEEE J-STARS, V12, P3900, DOI 10.1109/JSTARS.2019.2936771
   Klösch G, 2001, IEEE ENG MED BIOL, V20, P51, DOI 10.1109/51.932725
   Liu SQ, 2019, PHYSICA A, V521, P667, DOI 10.1016/j.physa.2019.01.036
   Moody GB, 2001, IEEE ENG MED BIOL, V20, P70, DOI 10.1109/51.932728
   Mukhopadhyay SK, 2018, IEEE T BIOMED CIRC S, V12, P137, DOI 10.1109/TBCAS.2017.2760298
   Qingzhen X., 2019, COMPUTING, V87, P1
   QINGZHEN X, 2013, MATH PROBL ENG
   Samanta A, 2018, IEEE SYST J, V12, P74, DOI 10.1109/JSYST.2015.2458586
   Sharma N, 2021, MULTIMED TOOLS APPL, V80, P33911, DOI 10.1007/s11042-021-11252-w
   Singh A, 2017, HEALTHC TECHNOL LETT, V4, P50, DOI 10.1049/htl.2016.0049
   Sun C, 2021, MULTIMED TOOLS APPL, V80, P33593, DOI 10.1007/s11042-021-11413-x
   Sun C, 2019, IEEE T IND INFORM, V15, P2416, DOI 10.1109/TII.2018.2881543
   Thiyagarajan A, 2021, MULTIMED TOOLS APPL, V80, P33641, DOI 10.1007/s11042-021-11416-8
   Tomasini M, 2016, IEEE SENS J, V16, P3887, DOI 10.1109/JSEN.2016.2536363
   Vaiciukynas E, 2018, IEEE T INTELL TRANSP, V19, P3723, DOI 10.1109/TITS.2018.2865103
   Wang F, 2019, COMPUT METH PROG BIO, V175, P139, DOI 10.1016/j.cmpb.2019.03.019
   Xie B, 2019, IEEE ACCESS, V7, P125357, DOI 10.1109/ACCESS.2019.2939284
   Xu QZ, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123205
   Xu QZ, 2019, PHYSICA A, V531, DOI 10.1016/j.physa.2019.121808
   Xu QZ, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/353910
   Xu XM, 2018, IEEE ACCESS, V6, P29700, DOI 10.1109/ACCESS.2018.2843762
   Yang SL, 2021, MULTIMED TOOLS APPL, V80, P33937, DOI 10.1007/s11042-021-11417-7
NR 38
TC 2
Z9 2
U1 5
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 17547
EP 17565
DI 10.1007/s11042-022-12597-6
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000765198400001
DA 2024-07-18
ER

PT J
AU Girirajan, S
   Pandian, A
AF Girirajan, S.
   Pandian, A.
TI Acoustic model with hybrid Deep Bidirectional Single Gated Unit (DBSGU)
   for low resource speech recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic Speech Recognition (ASR); Gated recurrent unit (GRU); Deep
   bidirectional; Deep bidirectional single gated unit (DBSGU); Word Error
   Rate (WER); Long short-term memory (LSTM)
ID RECURRENT; LSTM
AB Nowadays Long Short-Term Memory RNNs (LSTM RNNs) are widely used in Automatic Speech Recognition (ASR) and achieved excellent result in the problem of vanishing gradients. Bidirectional LSTM (BLSTM) will run the inputs in two ways ,both past as well as in future that shows good performance. However implementation of BLSTM is quite difficult because of its high computational requirements and also the problem of vanishing gradients still persist, when we have multiple layer of LSTM. The extensive size of LSTM systems makes them powerless in over fitting issues. The Gated Recurrent Unit (GRU) is the latest generation recurrent neural networks with two gates. The update gate acts similar to forget and input gates of LSTM's and reset gate responsible to decide how much previous data you should remember. GRU avoids over fitting and also training the GRU is faster compared to LSTM, since size of the GRU network is small. The proposed work is in two- fold architecture. First stage, we tend to reduce the gates in GRU by combining the reset and update gate together to form a Single Gated Unit (SGU). SGU takes half of the parameter compared with LSTM and one third of parameter compared with GRU. It increases the training speed of SGU. Second stage, SGU is combined with Deep Bidirectional design (DBSGU) to build a hybrid acoustic model that takes less number of parameters and increases the learning capability. The proposed model is compared with similarities and differences between Deep Bidirectional GRU (DBGRU) and Deep Bidirectional LSTM (DBLSTM) and found that 2 to 4% decrease in Word Error Rate (WER).The Learning rate of the is increased by 30% The entire work has been evaluated on Crowd Sourced high-quality Multi-Speaker speech (CSMS) data set.
C1 [Girirajan, S.; Pandian, A.] SRM Inst Sci & Technol, Sch Comp, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
C3 SRM Institute of Science & Technology Chennai
RP Girirajan, S (corresponding author), SRM Inst Sci & Technol, Sch Comp, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM girirajans.cse@gmail.com; pandiana@srmist.edu.in
RI Pandian, Dr. A./ABE-8626-2021
OI Pandian, Dr. A./0000-0002-1592-9205; S, Girirajan/0000-0003-4978-542X
CR Abandah GA, 2015, INT J DOC ANAL RECOG, V18, P183, DOI 10.1007/s10032-015-0242-2
   Barman PP, 2018, PROCEDIA COMPUT SCI, V143, P117, DOI 10.1016/j.procs.2018.10.359
   Chavan RupaliS., 2013, International Journal of Computer Science and Mobile Computing, V2, P233
   Cheng GF, 2018, INTERSPEECH, P1793, DOI 10.21437/Interspeech.2018-1403
   Chung Junyoung, 2014, ARXIV14123555
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   He F., 2020, P 12 LREC C MARS FRA
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jozefowicz R, 2015, PR MACH LEARN RES, V37, P2342
   KIMJ, 2016, OCEANS 2016 MTSIEEE
   Kingma D. P., 2014, arXiv
   Kumar J, 2018, PROCEDIA COMPUT SCI, V125, P676, DOI 10.1016/j.procs.2017.12.087
   Kumar Sumit, 2018, 2018 Fifth International Conference on Emerging Applications of Information Technology (EAIT). Proceedings, DOI 10.1109/EAIT.2018.8470406
   Li XX, 2016, INT CONF ACOUST SPEE, P544, DOI 10.1109/ICASSP.2016.7471734
   Panayotov V, 2015, INT CONF ACOUST SPEE, P5206, DOI 10.1109/ICASSP.2015.7178964
   Panzner Maximilian, 2016, Machine Learning, Optimization and Big Data. Second International Workshop, MOD 2016. Revised Selected Papers: LNCS 10122, P94, DOI 10.1007/978-3-319-51469-7_8
   Povey D., 2011, IEEE 2011 WORKSH AUT
   Ravanelli M, 2018, IEEE T EM TOP COMP I, V2, P92, DOI 10.1109/TETCI.2017.2762739
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Stolcke A, 2002, INTERSPEECH, V2002, P2002
   Thireou T, 2007, IEEE ACM T COMPUT BI, V4, P441, DOI 10.1109/TCBB.2007.1015
   Zhang Y, 2016, INT CONF ACOUST SPEE, P5755, DOI 10.1109/ICASSP.2016.7472780
   Zhou GB, 2016, INT J AUTOM COMPUT, V13, P226, DOI 10.1007/s11633-016-1006-2
NR 25
TC 2
Z9 2
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 17169
EP 17184
DI 10.1007/s11042-022-12723-4
EA MAR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000764960200004
DA 2024-07-18
ER

PT J
AU Salama, WM
   Shokry, A
AF Salama, Wessam M.
   Shokry, Ahmed
TI A novel framework for brain tumor detection based on convolutional
   variational generative models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumor; Computer aided diagnosis (CAD); Convolutional neural
   network; Transfer learning; Variational Autoencoders
ID NETWORK
AB Brain tumor detection can make the difference between life and death. Recently, deep learning-based brain tumor detection techniques have gained attention due to their higher performance. However, obtaining the expected performance of such deep learning-based systems requires large amounts of classified images to train the deep models. Obtaining such data is usually boring, time-consuming, and can easily be exposed to human mistakes which hinder the utilization of such deep learning approaches. This paper introduces a novel framework for brain tumor detection and classification. The basic idea is to generate a large synthetic MRI images dataset that reflects the typical pattern of the brain MRI images from a small class-unbalanced collected dataset. The resulted dataset is then used for training a deep model for detection and classification. Specifically, we employ two types of deep models. The first model is a generative model to capture the distribution of the important features in a set of small class-unbalanced brain MRI images. Then by using this distribution, the generative model can synthesize any number of brain MRI images for each class. Hence, the system can automatically convert a small unbalanced dataset to a larger balanced one. The second model is the classifier that is trained using the large balanced dataset to detect brain tumors in MRI images. The proposed framework acquires an overall detection accuracy of 96.88% which highlights the promise of the proposed framework as an accurate low-overhead brain tumor detection system.
C1 [Salama, Wessam M.] Pharos Univ, Alexandria, Egypt.
   [Shokry, Ahmed] Amer Univ Cairo, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); Pharos University in Alexandria; Egyptian
   Knowledge Bank (EKB); American University Cairo
RP Shokry, A (corresponding author), Amer Univ Cairo, Cairo, Egypt.
EM wessam.salama@pua.edu.eg; ahmed.shokry@aucegypt.edu
OI Shokry, Ahmed/0000-0003-3753-8886
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Abiwinanda N, 2019, IFMBE PROC, V68, P183, DOI 10.1007/978-981-10-9035-6_33
   Ahmed KB, 2017, PROC SPIE, V10134, DOI 10.1117/12.2253982
   Al-Zu'bi S, 2021, MULTIMED TOOLS APPL, V80, P16887, DOI 10.1007/s11042-020-09160-6
   AlZu'bi S, 2020, PATTERN RECOGN LETT, V130, P312, DOI 10.1016/j.patrec.2018.07.026
   AlZu'bi S, 2019, MULTIMED TOOLS APPL, V78, P24223, DOI 10.1007/s11042-018-7003-4
   AlZu'bi S, 2018, 2018 FIFTH INTERNATIONAL CONFERENCE ON SOCIAL NETWORKS ANALYSIS, MANAGEMENT AND SECURITY (SNAMS), P172, DOI 10.1109/SNAMS.2018.8554487
   Baldi P., 2012, P ICML WORKSH UNS TR, P37, DOI [10.5555/3045796.3045801., DOI 10.1561/2200000006, 10.1561/2200000006]
   Chakrabarty, 2019, DATASET BRAIN TUMOR
   Deepak S, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103345
   Doersch Carl, 2016, ARXIV160605908
   Elbes M, 2019, EVOL INTELL, V12, P113, DOI 10.1007/s12065-019-00210-z
   Gopal Krishna Patro S., 2015, IARJSET, V2, P20, DOI [10.17148/IARJSET.2015.2305, DOI 10.17148/IARJSET.2015.2305]
   Gumaei A, 2019, IEEE ACCESS, V7, P36266, DOI 10.1109/ACCESS.2019.2904145
   Guo XJ, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 4, PROCEEDINGS, P192, DOI 10.1109/ICNC.2008.871
   Isensee F., 2020, Revised Selected Papers, P118
   Jain R, 2019, COGN SYST RES, V57, P147, DOI 10.1016/j.cogsys.2018.12.015
   Japkowicz N., 2002, Intelligent Data Analysis, V6, P429
   Joyce J.M., 2011, Kullback-Leibler Divergence, P720, DOI [DOI 10.1007/978-3-642-04898-2_327, DOI 10.1007/978-3-642-04898-2327, 10.1007/978-3-642-04898-2327]
   Kingma D. P., 2014, AUTOENCODING VARIATI, P3581
   Kumar S, 2017, PROCEDIA COMPUT SCI, V122, P510, DOI 10.1016/j.procs.2017.11.400
   Liu RH, 2016, IEEE IJCNN, P235, DOI 10.1109/IJCNN.2016.7727204
   Lo SCB, 1995, NEURAL NETWORKS, V8, P1201, DOI 10.1016/0893-6080(95)00061-5
   Mohan G, 2018, BIOMED SIGNAL PROCES, V39, P139, DOI 10.1016/j.bspc.2017.07.007
   Myronenko A, 2019, LECT NOTES COMPUT SC, V11384, P311, DOI 10.1007/978-3-030-11726-9_28
   Pan YH, 2015, IEEE ENG MED BIO, P699, DOI 10.1109/EMBC.2015.7318458
   Prasad, 2006, MAGNETIC RESONANCE I, V124
   Rizk Hamada, 2019, ARXIV190608171
   Rosenstein M., 2005, NIPS 2005 Workshop on Transfer Learning, V898, P3
   Sajjad M, 2019, J COMPUT SCI-NETH, V30, P174, DOI 10.1016/j.jocs.2018.12.003
   Shokry A, 2018, 26TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2018), P339, DOI 10.1145/3274895.3274909
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Thotapally S, 2020, BRAIN CANC DETECTION
   Yang Y, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00804
   Zhang DW, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107562
   Zhang DW, 2020, IEEE T IMAGE PROCESS, V29, P9032, DOI 10.1109/TIP.2020.3023609
NR 35
TC 10
Z9 10
U1 4
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16441
EP 16454
DI 10.1007/s11042-022-12362-9
EA MAR 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763872100003
OA hybrid
DA 2024-07-18
ER

PT J
AU Baloni, D
   Verma, SK
AF Baloni, Dev
   Verma, Shashi Kant
TI Detection of hydrocephalus using deep convolutional neural network in
   medical science
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hydrocephalus; Clinical; Central nervous system; Deep learning; Emperor
   penguin optimization
ID NORMAL-PRESSURE HYDROCEPHALUS; BRAIN; CLASSIFICATION; DISEASE
AB Hydrocephalus is a generally known disease found in the central nervous system and requires neurosurgical treatment. However, there is no prevalent solution and effective method for precise detection. This paper introduces Hydrocephalus detection based on the deep learning model which undergoes the stages like pre-processing, segmentation, feature extraction, and classification. Colour based transformation technique is used for better processing of input tested images. Then, these pre-processed images are segmented by mean shift clustering which is used to segment the image and to provide a reliable and accurate estimated value. Then the features are extracted using Complete Local Binary Pattern (CLBP). Finally, the classification uses Deep Convolutional Neural Network with Emperor Penguin Optimization (DCNN-EPO) for improving the system efficiency. The implementation of the developed scheme is implemented in PYTHON 3.7. At last, the performance of the developed scheme and the existing techniques are compared. The developed model achieves an accuracy of about 99.1%, sensitivity of about 98.5% and precision value of about 98.2% respectively. In addition, the average training and validation accuracy of the system is found to be 84.75% and 87.25% and the overall classification time of the developed model is 20.67 s only. Thus the proposed model proves its superiority against other models.
C1 [Baloni, Dev] Veer Madho Singh Bhandari Uttarakhand Tech Univ, Comp Sci & Engn, Sudhowala 248007, Uttarakhand, India.
   [Verma, Shashi Kant] Govind Ballabh Pant Inst Engn & Technol, Pauri Garhwal, Uttarakhand, India.
C3 Uttarakhand Technical University
RP Baloni, D (corresponding author), Veer Madho Singh Bhandari Uttarakhand Tech Univ, Comp Sci & Engn, Sudhowala 248007, Uttarakhand, India.
EM devbaloni1982@gmail.com
CR Ahmed HM, 2019, MULTIMED TOOLS APPL, V78, P27983, DOI 10.1007/s11042-019-07876-8
   Akram R., 2020, J RAWALPINDI MED COL, V24, P3, DOI [10.37939/jrmc/vol24.iss1.2, DOI 10.37939/JRMC/VOL24.ISS1.2]
   Alford EN, 2020, WORLD NEUROSURG, V134, pE747, DOI 10.1016/j.wneu.2019.10.188
   Bayar MA, 2018, TURK NEUROSURG, V28, P62, DOI 10.5137/1019-5149.JTN.18702-16.1
   Bonte S, 2018, COMPUT BIOL MED, V98, P39, DOI 10.1016/j.compbiomed.2018.05.005
   Deb D, 2021, MULTIMED TOOLS APPL, V80, P2621, DOI 10.1007/s11042-020-09810-9
   Demyanchuk A, 2019, ARXIV PREPRINT ARXIV
   Dewan MC, 2019, J NEUROSURG, V130, P1065, DOI 10.3171/2017.10.JNS17439
   Dhiman G, 2018, KNOWL-BASED SYST, V159, P20, DOI 10.1016/j.knosys.2018.06.001
   Duan WK, 2020, MEDICINE, V99, DOI 10.1097/MD.0000000000021229
   Gao H, 2019, COMPUT OPT, V43, P78, DOI 10.18287/2412-6179-2019-43-1-78-82
   Ge CJ, 2020, BMC MED IMAGING, V20, DOI 10.1186/s12880-020-00485-0
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Huang Y, 2021, DEEP LEARNING ACHIEV
   Iqbal S, 2018, BIOMED ENG LETT, V8, P5, DOI 10.1007/s13534-017-0050-3
   Ivkovic M, 2013, AM J NEURORADIOL, V34, P1168, DOI 10.3174/ajnr.A3368
   Karimy JK, 2020, NAT REV NEUROL, V16, P285, DOI 10.1038/s41582-020-0321-y
   Kaur B, 2018, COMPUT ELECTR ENG, V71, P692, DOI 10.1016/j.compeleceng.2018.08.018
   Khan MA, 2020, IEEE ACCESS, V8, P132850, DOI 10.1109/ACCESS.2020.3010448
   Khan MA, 2020, PATTERN RECOGN LETT, V129, P293, DOI 10.1016/j.patrec.2019.11.034
   Klebe D, 2020, J NEUROSCI RES, V98, P105, DOI 10.1002/jnr.24394
   Klimont M, 2019, BIOMED RES INT, V2019, DOI 10.1155/2019/3059170
   Kockum K, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0232275
   Kumar SM, 2021, J PHYS C SERIES, V1964
   Mohan S, 2019, IEEE ACCESS, V7, P81542, DOI 10.1109/ACCESS.2019.2923707
   Mohsen Heba, 2018, Future Computing and Informatics Journal, V3, P68, DOI 10.1016/j.fcij.2017.12.001
   Nakajima M, 2021, NEUROL MED-CHIR, V61, P63, DOI 10.2176/nmc.st.2020-0292
   Nassar FJ, 2020, FRONT MED-LAUSANNE, V7, DOI 10.3389/fmed.2020.00028
   Ono K., 2020, J Image Graph, V8, P42
   Pedano N., 2016, CANC GENOME ATLAS LO, V2
   Quon JL, 2021, J NEUROSURG-PEDIATR, V27, P131, DOI 10.3171/2020.6.PEDS20251
   Rau A, 2021, CLIN NEURORADIOL, P1
   Reeves BC, 2020, TRENDS MOL MED, V26, P285, DOI 10.1016/j.molmed.2019.11.008
   Rudhra B, 2021, J INTELL FUZZY SYST, P1
   Sahli H, 2020, TECHNOL HEALTH CARE, V28, P643, DOI 10.3233/THC-191752
   Scarpace L., 2016, The Cancer Imaging Archive
   Scarpace L, 2015, CANC IMAGING ARCH
   Sultan HH, 2019, IEEE ACCESS, V7, P69215, DOI 10.1109/ACCESS.2019.2919122
   Suresh K, 2020, MULTIMED TOOLS APPL, V79, P4133, DOI 10.1007/s11042-019-07934-1
   Tamilarasi R, 2021, Journal of Physics: Conference Series, V1964
   Thambusamy V., 2018, IntJPureApplMath, V118, P3681, DOI DOI 10.3390/CANCERS14092132
   Tripathi MK, 2021, IET IMAGE PROCESS, V15, P1940, DOI 10.1049/ipr2.12163
   Vallabhaneni RB, 2018, ALEX ENG J, V57, P2387, DOI 10.1016/j.aej.2017.09.011
   Wadhwa A, 2020, MULTIMED TOOLS APPL, V79, P25379, DOI 10.1007/s11042-020-09177-x
   Zhang YD, 2020, INFORM FUSION, V64, P149, DOI 10.1016/j.inffus.2020.07.006
NR 45
TC 3
Z9 3
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16171
EP 16193
DI 10.1007/s11042-022-11953-w
EA MAR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763256600016
DA 2024-07-18
ER

PT J
AU Alonso, R
   Bonini, A
   Recupero, DR
   Spano, LD
AF Alonso, Ruben
   Bonini, Alessandro
   Recupero, Diego Reforgiato
   Spano, Lucio Davide
TI Exploiting virtual reality and the robot operating system to
   remote-control a humanoid robot
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Humanoids robot; ROS framework; Virtual reality; Human-robot
   interaction; NAO robot; Unity engine
AB The availability of frameworks and applications in the robotic domain fostered in the last years a spread in the adoption of robots in daily life activities. Many of these activities include the robot teleoperation, i.e. controlling its movements remotely. Virtual Reality (VR) demonstrated its effectiveness in lowering the skill barrier for such a task. This paper discusses the engineering and implementation of a general-purpose, open-source framework for teleoperating a humanoid robot through a VR headset. It includes a VR interface for articulating different robot actions using the VR controllers, without the need for training. Besides, it exploits the Robot Operating System (ROS) for the control and synchronization of the robot hardware, the distribution of the computation and its scalability. The framework supports the extension for operating other types of robots and using different VR configurations. We carried out a user experience evaluation with twenty users using System Usability Scale questionnaires and with six stakeholders on five different scenarios using the Software Architecture Analysis Method.
C1 [Alonso, Ruben] R2M Solut Srl, Via Fratelli Cuzio 42, I-27100 Pavia, Italy.
   [Bonini, Alessandro; Recupero, Diego Reforgiato; Spano, Lucio Davide] Univ Cagliari, Dept Math & Comp Sci, Via Osped 72, I-09124 Cagliari, Italy.
C3 University of Cagliari
RP Alonso, R (corresponding author), R2M Solut Srl, Via Fratelli Cuzio 42, I-27100 Pavia, Italy.
EM ruben.alonso@r2msolution.com; alessandro.bonini@unica.it;
   diego.reforgiato@unica.it; davide.spano@unica.it
OI Reforgiato Recupero, Diego/0000-0001-8646-6183; Alonso,
   Ruben/0000-0001-6062-9933
FU EU [812882]; Marie Curie Actions (MSCA) [812882] Funding Source: Marie
   Curie Actions (MSCA)
FX This research was partially funded by the EU's Marie Curie training
   network PhilHumans - Personal Health Interfaces Leveraging HUman-MAchine
   Natural interactionS (grant number 812882).
CR Ajili I, 2017, IEEE ROMAN, P1115, DOI 10.1109/ROMAN.2017.8172443
   Alonso R, 2019, WORKSH AD INT SOC RO
   [Anonymous], 2020, Unity Technologies Using Occlusion Culling with Dynamic GameObjects 2018
   Atzeni M, 2020, FUTURE GENER COMP SY, V110, P984, DOI 10.1016/j.future.2019.10.012
   Atzeni M, 2018, LECT NOTES COMPUT SC, V11155, P14, DOI 10.1007/978-3-319-98192-5_3
   Babar MA, 2004, 11TH ASIA-PACIFIC SOFTWARE ENGINEERING CONFERENCE, PROCEEDINGS, P600, DOI 10.1109/APSEC.2004.38
   Babington P, 2020, ROBOT OPERATING SYST, V4
   Bass L., 2013, SOFTWARE ARCHITECTUR
   Berg J., 2020, CURR ROBOT REP, V1, P27, DOI [10.1007/s43154-020-00005-6, DOI 10.1007/S43154-020-00005-6]
   Brooke John., 1996, Usability evaluation in industry, V189, P4, DOI DOI 10.1201/9781498710411
   Clements P, 2000, ACTIVE REV INTERMEDI, P26
   Dahl TS, 2014, ROBOTICS, V3, P1, DOI 10.3390/robotics3010001
   Dehnavi S, 2019, PROCEDIA COMPUT SCI, V155, P59, DOI 10.1016/j.procs.2019.08.012
   Elbasiony R, 2018, INTEL SERV ROBOT, V11, P149, DOI 10.1007/s11370-018-0247-z
   Franzluebbers A, 2019, REMOTE ROBOTIC ARM T
   Franzluebbers A, 2019, S SPAT US INT, P1
   Gerina F, 2020, HUM-CENT COMPUT INFO, V10, DOI 10.1186/s13673-020-00235-9
   Gerina F, 2019, LECT NOTES COMPUT SC, V11912, P318, DOI 10.1007/978-3-030-34255-5_22
   Gharaybeh Zaid., 2019, Telerobotic control in virtual reality
   Hashimoto S, 2013, J ROBOT MECHATRON, V25, P529, DOI 10.20965/jrm.2013.p0529
   Hetrick R, 2020, COMPARING VIRTUAL RE
   Hong S, 2018, INT J HUM ROBOT, V15, DOI 10.1142/S0219843618500081
   Ismail LI, 2012, PROCEDIA ENGINEER, V41, P1441, DOI 10.1016/j.proeng.2012.07.333
   Kasahara Shunichi, 2013, P 7 INT C TANG EMB E, P223, DOI DOI 10.1145/2460625.2460661
   KAZMAN R, 1994, PROC INT CONF SOFTW, P81, DOI 10.1109/ICSE.1994.296768
   Kazman R, 1998, IEEE INT C ENG COMP, P68, DOI 10.1109/ICECCS.1998.706657
   Lewis JR, 2018, J USABILITY STUD, V13, P158
   Li CX, 2016, IEEE ICARM 2016 - 2016 INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS AND MECHATRONICS (ICARM), P133, DOI 10.1109/ICARM.2016.7606908
   Makhataeva Z, 2020, ROBOTICS, V9, DOI 10.3390/robotics9020021
   Mataric MJ, 2016, SPRINGER HANDBOOK OF ROBOTICS, P1973
   Melchiorri C, 2014, ENCY SYSTEMS CONTROL, P1
   Melinte O, 2015, HAPTIC INTELLIGENT I
   Munoz JR, 2017, INT J TOUR RES, V19, P477, DOI 10.1002/jtr.2110
   Naceri A, 2019, 2019 19TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR), P284, DOI 10.1109/ICAR46387.2019.8981649
   Nunez L, 2018, TELEOPERATION HUMANO
   Quigley M, 2009, IEEE INT CONF ROBOT, P3604
   Recupero DR, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102094
   Recupero DR, 2019, LECT NOTES COMPUT SC, V11912, P311, DOI 10.1007/978-3-030-34255-5_21
   Robles-Bykbaev V, 2016, IEEE INT AUT MEET
   Rodriguez I, 2014, IEEE-RAS INT C HUMAN, P179, DOI 10.1109/HUMANOIDS.2014.7041357
   Roldan J.J., 2019, Robot Operating System (ROS) The Complete Reference, P29, DOI [10.1007/, 10.1007/978-3-319-91590-6_, DOI 10.1007/978-3-319-91590-6]
   Sani AYM, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON ROBOTICS, INTELLIGENT CONTROL AND ARTIFICIAL INTELLIGENCE (RICAI 2019), P396, DOI 10.1145/3366194.3366264
   Schmidt L, 2014, IND ROBOT, V41, P6, DOI 10.1108/IR-02-2013-325
   Sun D, 2020, IEEE T HUM-MACH SYST, V50, P55, DOI 10.1109/THMS.2019.2960676
   Vircikova M, 2013, ROBOT INTELLIGENCE T, P347, DOI [10.1007/978-3-642-37374-9_34, DOI 10.1007/978-3-642-37374-9_34]
   Walker ME, 2019, ACMIEEE INT CONF HUM, P202, DOI [10.1109/HRI.2019.8673306, 10.1109/hri.2019.8673306]
   Wang QY, 2019, J MANUF PROCESS, V48, P210, DOI 10.1016/j.jmapro.2019.10.016
   Yuan F, 2019, IEEE WORK ADV ROBOT, P7, DOI [10.1109/arso46408.2019.8948758, 10.1109/ARSO46408.2019.8948758]
NR 48
TC 2
Z9 2
U1 5
U2 55
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15565
EP 15592
DI 10.1007/s11042-022-12021-z
EA FEB 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762173600002
DA 2024-07-18
ER

PT J
AU Chakraborty, N
   Mitra, A
   Choudhury, A
   Mollah, AF
   Basu, S
   Sarkar, R
AF Chakraborty, Neelotpal
   Mitra, Arkoprobho
   Choudhury, Ayush
   Mollah, Ayatullah Faruk
   Basu, Subhadip
   Sarkar, Ram
TI How to handle bi/tri-lingual Indic texts in a single image? A new
   dataset of natural scene and born-digital images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-lingual text; Mixed-lingual; Natural scene image; Born digital
   image; Text detection and localization; Language identification; Deep
   learning
ID SCRIPT IDENTIFICATION; RECOGNITION
AB Detection and language identification of multi-lingual texts in natural scene images (NSI) and born-digital images (BDI) are popular research problems in the domain of information retrieval. Several methods addressing these problems have been evaluated over the years upon mostly NSI based standard datasets. However, datasets highlighting bi/tri-lingual Indic texts in a single image are quite a few. Also, datasets housing BDIs with multi-lingual texts are hardly available. To this end, a new dataset called Mixed-lingual Indic Texts in Digital Images (MITDI) having 500 NSIs and 500 BDIs, is introduced where each image contains texts written in at least two of the either English, Bangla and Hindi languages which are quite commonly used in India. Overall, NSI pool contains 360 images with bi-lingual texts and 140 with tri-lingual texts, whereas BDI pool contains 489 images with bi-lingual texts and 11 with tri-lingual texts. To benchmark the performance on MITDI, a deep learning based Connectionist-DenseNet framework is built and evaluated for each data pool NSI, BDI and combined set. The proposed dataset can serve as an important resource for evaluating state-of-the-art methods in this domain. The dataset is publicly available at: https://github.com/NCJUCSE/MITDI
C1 [Chakraborty, Neelotpal; Choudhury, Ayush; Basu, Subhadip; Sarkar, Ram] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, India.
   [Mitra, Arkoprobho] Jadavpur Univ, Dept Civil Engn, Kolkata 700032, India.
   [Mollah, Ayatullah Faruk] Aliah Univ, Dept Comp Sci & Engn, Kolkata 700160, India.
C3 Jadavpur University; Jadavpur University; Aliah University
RP Chakraborty, N (corresponding author), Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, India.
EM chakraborty.neelotpal@gmail.com
RI CHAKRABORTY, NEELOTPAL/HNB-7710-2023; Sarkar, Ram/AAX-3822-2020
OI CHAKRABORTY, NEELOTPAL/0000-0003-2723-1434; Sarkar,
   Ram/0000-0001-8813-4086
FU DBT [BT/PR16356/BID/7/596/2016]; DST [EMR/2016/007213]; CMATER research
   laboratory of the Computer Science and Engineering Department, Jadavpur
   University, India
FX This work is partially supported by the CMATER research laboratory of
   the Computer Science and Engineering Department, Jadavpur University,
   India, PURSE-II and UPE-II, project. This work is partially funded by
   DBT grant (BT/PR16356/BID/7/596/2016) and DST grant (EMR/2016/007213).
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/3022670.2976746, 10.1145/2951913.2976746]
   Agrawal Aarushi, 2018, Proceedings of 2nd International Conference on Computer Vision & Image Processing. CVIP 2017. Advances in Intelligent Systems and Computing (AISC 703), P359, DOI 10.1007/978-981-10-7895-8_28
   Bhunia AK, 2019, PATTERN RECOGN, V85, P172, DOI 10.1016/j.patcog.2018.07.034
   Busta M, 2019, LECT NOTES COMPUT SC, V11367, P127, DOI 10.1007/978-3-030-21074-8_11
   Chakraborty N, 2021, J AMB INTEL HUM COMP, V12, P7997, DOI 10.1007/s12652-020-02528-4
   Chakraborty N, 2021, MULTIMED TOOLS APPL, V80, P323, DOI 10.1007/s11042-020-09728-2
   Changxu Cheng, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1077, DOI 10.1109/ICDAR.2019.00175
   Chen H., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2609, DOI 10.1109/ICIP.2011.6116200
   Chicco D, 2020, BMC GENOMICS, V21, DOI 10.1186/s12864-019-6413-7
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Christoph B., 2017, P 20 INT C MED IM CO, P311
   Deng D, 2018, AAAI CONF ARTIF INTE, P6773
   Dhar Dibyajyoti, 2020, International Journal of Computer Vision and Image Processing, V10, P1, DOI 10.4018/IJCVIP.2020070103
   Doulamis N, 2014, IEEE IMAGE PROC, P848, DOI 10.1109/ICIP.2014.7025170
   Dutta IN, 2021, MULTIMED TOOLS APPL, V80, P7609, DOI 10.1007/s11042-020-09785-7
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Fan K, 2018, NEUROCOMPUTING, V304, P47, DOI 10.1016/j.neucom.2018.03.041
   Fujii Y, 2017, PROC INT CONF DOC, P161, DOI 10.1109/ICDAR.2017.35
   Gomez L, 2017, PATTERN RECOGN, V67, P85, DOI 10.1016/j.patcog.2017.01.032
   Gómez L, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P192, DOI 10.1109/DAS.2016.64
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Haifeng D., 2020, J PHYS C SERIES, V1634
   Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jiang YY, 2018, INT C PATT RECOG, P3610, DOI 10.1109/ICPR.2018.8545598
   Joan SPF, 2019, P NATL A SCI INDIA A, V89, P77, DOI 10.1007/s40010-017-0478-y
   Jung J, 2011, ETRI J, V33, P78, DOI 10.4218/etrij.11.1510.0029
   Karatzas D, 2011, PROC INT CONF DOC, P1485, DOI 10.1109/ICDAR.2011.295
   Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942
   Karatzas D, 2013, PROC INT CONF DOC, P1484, DOI 10.1109/ICDAR.2013.221
   Khan T, 2021, ARTIF INTELL REV, V54, P3239, DOI 10.1007/s10462-020-09930-6
   Khan T, 2019, MULTIMED TOOLS APPL, V78, P32159, DOI 10.1007/s11042-019-08028-8
   Kingma D. P., 2014, arXiv
   Liao MH, 2018, IEEE T IMAGE PROCESS, V27, P3676, DOI 10.1109/TIP.2018.2825107
   Liao MH, 2017, AAAI CONF ARTIF INTE, P4161
   Lienhart R, 2000, MULTIMEDIA SYST, V8, P69, DOI 10.1007/s005300050006
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu ZD, 2019, MULTIMED TOOLS APPL, V78, P18205, DOI 10.1007/s11042-019-7177-4
   Liu ZC, 2019, PROC CVPR IEEE, P7261, DOI 10.1109/CVPR.2019.00744
   Lu LQ, 2019, IEEE ACCESS, V7, P52669, DOI 10.1109/ACCESS.2019.2911964
   Lucas S. M., 2005, International Journal on Document Analysis and Recognition, V7, P105, DOI 10.1007/s10032-004-0134-3
   Lucas SM, 2005, PROC INT CONF DOC, P80, DOI 10.1109/ICDAR.2005.231
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Mei JR, 2016, INT C PATT RECOG, P4053, DOI 10.1109/ICPR.2016.7900268
   Mukhopadhyay Anirban, 2019, International Journal of Computer Vision and Image Processing, V9, P48, DOI 10.4018/IJCVIP.2019040104
   Nayef Nibal, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1582, DOI 10.1109/ICDAR.2019.00254
   Nayef N, 2017, PROC INT CONF DOC, P1454, DOI 10.1109/ICDAR.2017.237
   Ozgen AC, 2018, 2018 26 SIGN PROC CO, P1
   Paul S, 2019, MULTIMED TOOLS APPL, V78, P18017, DOI 10.1007/s11042-019-7178-3
   Raghunandan KS, 2019, IEEE T CIRC SYST VID, V29, P1145, DOI 10.1109/TCSVT.2018.2817642
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Saha S, 2020, PATTERN RECOGN LETT, V138, P16, DOI 10.1016/j.patrec.2020.06.024
   Tarvainen A, 2017, ADV NEUR IN, V30
   Tian Z, 2016, LECT NOTES COMPUT SC, V9912, P56, DOI 10.1007/978-3-319-46484-8_4
   Veit A, 2016, ADV NEUR IN, V29
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wang SH, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3341095
   Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787
   Zhang HG, 2013, NEUROCOMPUTING, V122, P310, DOI 10.1016/j.neucom.2013.05.037
   Zhang Z, 2016, PROC CVPR IEEE, P4159, DOI 10.1109/CVPR.2016.451
   Zhang ZC, 2018, IEEE T MED IMAGING, V37, P1407, DOI 10.1109/TMI.2018.2823338
   Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283
NR 62
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15367
EP 15394
DI 10.1007/s11042-022-12596-7
EA FEB 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762173600010
DA 2024-07-18
ER

PT J
AU Roy, S
   Howlader, J
   Sanyal, G
AF Roy, Subhajit
   Howlader, Jaydeep
   Sanyal, Goutam
TI A novel approach of data hiding in video using region selection and PCA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video Steganography; Segmentation; Principal component analysis (PCA)
ID IMAGE STEGANOGRAPHY; ALGORITHM
AB With the ubiquitous progress of information technology it is now possible to transfer multimedia information rapidly over the Internet. Significant growth of video data on the Internet insists the users towards video steganography as a popular choice for data hiding. Steganography algorithm must emphasis to improve the embedding efficiency, payload and robustness against the intruders. In this paper, we have addressed those issues and present a new approach of steganography. Our segmentation process is based on video frames. We apply a region selection method followed by the dimensionality reduction process, called principal component analysis (PCA), to compress the regions and embed secret data on those compact regions. This PCA is used as a best-fitted vector that minimizes the average square distance from the pixel values to that vector. Our results show higher embedding capacity along with better visual quality. Moreover, the proposed method improves the robustness in the sense that the secret message can be retrieved by the receiver even after some known attacks on the channel.
C1 [Roy, Subhajit; Howlader, Jaydeep; Sanyal, Goutam] Natl Inst Technol, Dept Comp Sci & Engn, Durgapur, W Bengal, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Durgapur
RP Roy, S (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Durgapur, W Bengal, India.
EM subhajit2111@gmail.com
OI Roy, Subhajit/0000-0002-6920-6328
CR Alavianmehr M. A., 2012, 2012 2nd International eConference on Computer and Knowledge Engineering (ICCKE 2012), P194, DOI 10.1109/ICCKE.2012.6395377
   [Anonymous], 2018, J Inf Secur Cybercrimes Res (JISCR), DOI DOI 10.26735/16587790.2018.006
   Cetin O, 2012, IMAGING SCI J, V60, P75, DOI 10.1179/1743131X11Y.0000000004
   Chang PC, 2014, J VIS COMMUN IMAGE R, V25, P239, DOI 10.1016/j.jvcir.2013.10.007
   Cheddad A, 2008, PROCEEDINGS OF THE FIFTH CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, P326, DOI 10.1109/CRV.2008.54
   Dasgupta K, 2013, PROC TECH, V10, P131, DOI 10.1016/j.protcy.2013.12.345
   Ferris J, 2009, PALG STUD THEAT PERF, P1
   Kar N, 2018, ICT EXPRESS, V4, P6, DOI 10.1016/j.icte.2018.01.003
   Mstafa RJ, 2017, MULTIMED TOOLS APPL, V76, P21749, DOI 10.1007/s11042-016-4055-1
   Mstafa RJ, 2017, IEEE ACCESS, V5, P5354, DOI 10.1109/ACCESS.2017.2691581
   Mstafa RJ, 2016, MULTIMED TOOLS APPL, V75, P10311, DOI 10.1007/s11042-015-3060-0
   Mukherjee Srilekha, 2017, International Journal of Computers and Applications, V39, P59, DOI 10.1080/1206212X.2016.1273624
   Mukherjee S, 2019, MULTIMED TOOLS APPL, V78, P17607, DOI 10.1007/s11042-018-7127-6
   Mukherjee S, 2019, MULTIMED TOOLS APPL, V78, P16363, DOI 10.1007/s11042-018-6975-4
   Mukherjee S, 2018, MULTIMED TOOLS APPL, V77, P27851, DOI 10.1007/s11042-018-5996-3
   Ntalianis K. S., 2002, 2002 IEEE International Conference on Systems, Man and Cybernetics. Conference Proceedings (Cat. No.02CH37349), DOI 10.1109/ICSMC.2002.1176068
   Ntalianis K, 2016, IEEE T EMERG TOP COM, V4, P156, DOI 10.1109/TETC.2015.2400135
   Ranjithkumar R, 2021, MULTIMED TOOLS APPL, V80, P13865, DOI 10.1007/s11042-020-10324-7
   Roy S, 2018, 2018 2ND INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (ICDSP 2018), P142, DOI 10.1145/3193025.3193045
   Roy S, 2016, PROCEEDINGS OF THE 2016 2ND INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P209, DOI 10.1109/IC3I.2016.7917962
   Sadek MM, 2017, MULTIMED TOOLS APPL, V76, P3065, DOI 10.1007/s11042-015-3170-8
   Sadek MM, 2015, MULTIMED TOOLS APPL, V74, P7063, DOI 10.1007/s11042-014-1952-z
   Schöttle P, 2016, IEEE T INF FOREN SEC, V11, P760, DOI 10.1109/TIFS.2015.2509941
   Shahid Z, 2013, SIGNAL IMAGE VIDEO P, V7, P75, DOI 10.1007/s11760-011-0225-9
   Song GH, 2015, MULTIMED TOOLS APPL, V74, P3759, DOI 10.1007/s11042-013-1798-9
   Sur A, 2015, MULTIMED TOOLS APPL, V74, P10479, DOI 10.1007/s11042-014-2181-1
   Weng XY, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P87, DOI 10.1145/3323873.3325011
   Wu KC, 2015, IEEE T IMAGE PROCESS, V24, P130, DOI 10.1109/TIP.2014.2371246
   Yao YZ, 2015, MULTIMED TOOLS APPL, V74, P11163, DOI 10.1007/s11042-014-2223-8
   Zaitoun NM, 2015, PROCEDIA COMPUT SCI, V65, P797, DOI 10.1016/j.procs.2015.09.027
   Zhang YN, 2017, TSINGHUA SCI TECHNOL, V22, P198
NR 31
TC 2
Z9 2
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 14553
EP 14571
DI 10.1007/s11042-022-12029-5
EA FEB 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761979300021
DA 2024-07-18
ER

PT J
AU Zhao, LJ
   Zhang, JJ
   Bai, HH
   Wang, AH
   Zhao, Y
AF Zhao, Lijun
   Zhang, Jinjing
   Bai, Huihui
   Wang, Anhong
   Zhao, Yao
TI LMDC: Learning a multiple description codec for deep learning-based
   image compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple description coding; Scalar quantizer; Auto-encoder; Symmetrical
   sharing
ID DESCRIPTION VECTOR QUANTIZATION; TRANSFORM; DESIGN
AB Although deep learning technique has been widely leveraged to compress image, few attentions are paid to multiple description (MD) coding based on this technique. Meanwhile, packet loss and bit error may occur inevitably during transmission over unreliable networks, which seriously corrupts image quality. Thus, we introduce a deep Multiple Description Coding (MDC) framework for low bit-rate image compression, which is optimized according to deep MD rate-distortion minimization. Our framework includes MD multi-scale encoder network, MD cascaded-Resblock decoder networks, and arithmetic codec as well as a pair of learnable scalar quantizers and conditional probability models. In encoder, a pair of MD tensors are firstly generated by MD multi-scale encoder network, after which these tensors are discretized by a pair of learnable scalar quantizers respectively. Then, these quantized tensors are fed into conditional probability models for soft entropy estimation to regularize the learning of our encoder and decoder network during training, while these quantized tensors are lossly coded by arithmetic coding during testing. In decoder, these quantized tensors are decoded from bit-streams and then they are decompressed by MD cascaded-Resblock decoder networks for image decoding. To greatly reduce the total amount of network parameters, we design an auto-encoder network composed of these encoder and decoder networks with a symmetrical parameter sharing structure. Additionally, considering image spatial variation, each scalar quantizer is accompanied by an importance-indicator map to generate MD tensors, rather than using direct quantization. Experimental results have demonstrated that our MDC framework performs better than several existing MDC approaches in terms of several image quality metrics.
C1 [Zhao, Lijun; Wang, Anhong] Taiyuan Univ Sci & Technol, 66 Waliu Rd, Taiyuan 030051, Shanxi, Peoples R China.
   [Zhang, Jinjing] North Univ China, 3 Xueyuan Rd, Taiyuan 030051, Shanxi, Peoples R China.
   [Bai, Huihui; Zhao, Yao] Beijing Jiaotong Univ, 3 Shangyuancun Haidian Dist, Beijing 100044, Peoples R China.
C3 Taiyuan University of Science & Technology; North University of China;
   Beijing Jiaotong University
RP Zhao, LJ (corresponding author), Taiyuan Univ Sci & Technol, 66 Waliu Rd, Taiyuan 030051, Shanxi, Peoples R China.
EM leejun@tyust.edu.cn
RI Zhao, Lijun/S-7237-2019
OI Zhao, Lijun/0000-0002-2305-1914
FU Doctoral Scientific Research Starting Foundation of Taiyuan University
   of Science and Technology [20192023]; Natural Science Foundation of
   Shanxi (Project: Research on Multi-Granularity Multiple Description
   Coding for Reliable Transmission in Wireless Channel); Funding Awards
   for Outstanding Doctors Volunteering to Work in Shanxi Province
   [20192055]
FX This work was supported by Doctoral Scientific Research Starting
   Foundation of Taiyuan University of Science and Technology
   (No.20192023), Natural Science Foundation of Shanxi (Project: Research
   on Multi-Granularity Multiple Description Coding for Reliable
   Transmission in Wireless Channel), and Funding Awards for Outstanding
   Doctors Volunteering to Work in Shanxi Province (No.20192055).
CR Agustsson E, 2017, ADV NEUR IN, V30
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   [Anonymous], VARIABLE RATE IMAGE
   Awan N, 2021, IEEE ACCESS, V9, P26502, DOI 10.1109/ACCESS.2021.3056926
   Ballé J, 2021, IEEE J-STSP, V15, P339, DOI 10.1109/JSTSP.2020.3034501
   Chang HB, 2014, IEEE T SIGNAL PROCES, V62, P718, DOI 10.1109/TSP.2013.2290508
   Chen J, 2016, MULTIMED TOOLS APPL, V75, P2801, DOI 10.1007/s11042-015-2546-0
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dumitrescu S., 2018, IEEE T COMMUN, P1
   Dumitrescu S, 2015, IEEE T INFORM THEORY, V61, P2748, DOI 10.1109/TIT.2015.2413780
   Foi A, 2007, IEEE T IMAGE PROCESS, V16, P1395, DOI 10.1109/TIP.2007.891788
   Franchi N, 2005, IEEE T CIRC SYST VID, V15, P321, DOI 10.1109/TCSVT.2004.842606
   Gadgil N, 2015, 2015 PICTURE CODING SYMPOSIUM (PCS) WITH 2015 PACKET VIDEO WORKSHOP (PV), P90, DOI 10.1109/PCS.2015.7170053
   Gao ZY, 2014, IEEE T COMMUN, V62, P4281, DOI 10.1109/TCOMM.2014.2367014
   Goyal VK, 2011, IEEE SIGNAL PROC LET, V18, DOI 10.1109/LSP.2011.2161867
   Goyal VK, 2002, IEEE T INFORM THEORY, V48, P781, DOI 10.1109/18.986048
   Goyal VK, 2001, IEEE T INFORM THEORY, V47, P2199, DOI 10.1109/18.945243
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jafarkhani H, 1999, IEEE T COMMUN, V47, P799, DOI 10.1109/26.771331
   Jerbi A, 2005, IEEE T CIRC SYST VID, V15, P1175, DOI 10.1109/TCSVT.2005.852619
   Kazemi M, 2018, IEEE T MULTIMEDIA, V20, P781, DOI 10.1109/TMM.2017.2758578
   Li HF, 2019, IEEE ACCESS, V7, P26013, DOI 10.1109/ACCESS.2019.2900498
   Li MH, 2018, PROC CVPR IEEE, P6644, DOI 10.1109/CVPR.2018.00695
   Li X, 2021, MULTIMED TOOLS APPL, V80, P10323, DOI 10.1007/s11042-020-09283-w
   Majid M, 2018, MULTIMED TOOLS APPL, V77, P20955, DOI 10.1007/s11042-017-5499-7
   Meng LL, 2014, IEEE T IMAGE PROCESS, V23, P582, DOI 10.1109/TIP.2013.2288928
   Mentzer F, 2018, PROC CVPR IEEE, P4394, DOI 10.1109/CVPR.2018.00462
   Rippel O, 2017, PR MACH LEARN RES, V70
   Romano G, 2015, EUR SIGN PROC C VIEN
   Saitoh D, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT)
   Shirani F, 2018, IEEE T INFORM THEORY, V64, P3781, DOI 10.1109/TIT.2018.2804439
   Theis L, 2017, INT C LEARN REPR PAL
   Tillo T, 2004, IEEE SIGNAL PROC LET, V11, P908, DOI 10.1109/LSP.2004.836949
   VAISHAMPAYAN VA, 1993, IEEE T INFORM THEORY, V39, P821, DOI 10.1109/18.256491
   Vaishampayan VA, 2001, IEEE T INFORM THEORY, V47, P1718, DOI 10.1109/18.930913
   Wang Y, 2001, IEEE T IMAGE PROCESS, V10, P351, DOI 10.1109/83.908500
   Wu HH, 2017, IEEE T COMMUN, V65, P3453, DOI 10.1109/TCOMM.2017.2704585
   Xu, 2020, EURASIP J WIREL COMM, V93
   Xu YY, 2013, IEEE T CIRC SYST VID, V23, P1523, DOI 10.1109/TCSVT.2013.2249018
   Yochai B, 2018, IEEE C COMP VIS PATT
   Zeeshan M, 2021, TELECOMMUN SYST, V76, P63, DOI 10.1007/s11235-020-00702-9
   Zhang GJ, 2004, IEEE IMAGE PROC, P829
   Zhang J, 2016, IEEE T IMAGE PROCESS, V25, P1246, DOI 10.1109/TIP.2016.2515985
   Zhang XS, 2018, IEEE IMAGE PROC, P390, DOI 10.1109/ICIP.2018.8451694
   Zhao L, 2019, DATA COMPRESSION C
   Zhao LJ, 2019, J VIS COMMUN IMAGE R, V63, DOI 10.1016/j.jvcir.2019.102589
   Zhao LJ, 2019, IEEE T CIRC SYST VID, V29, P2494, DOI 10.1109/TCSVT.2018.2867067
   Zhao LJ, 2019, PATTERN RECOGN, V88, P356, DOI 10.1016/j.patcog.2018.11.028
   Zhu C, 2009, IEEE T CIRC SYST VID, V19, P511, DOI 10.1109/TCSVT.2009.2013521
NR 50
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13889
EP 13910
DI 10.1007/s11042-022-12216-4
EA FEB 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761979300008
DA 2024-07-18
ER

PT J
AU Ho, CL
   Lin, TG
   Chang, CR
AF Ho, Chin-Ling
   Lin, Tsang-Gang
   Chang, Chan-Ru
TI Interactive multi-sensory and volumetric content integration for music
   education applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Multi-sensory design; Volumetric capture; Learning
   technology; Music education with children
AB Taiwan's heritage in terms of the local music culture has been gradually fading in recent years. Thus, boosting and passing on the local music culture to pre-school and elementary school students are urgent requirements. This study proposes an interactive integration of multi-sensory and volumetric content for music education in Taiwan into applications for children. Further, the study introduces a technological multi-sensory pop-up sketch book created in collaboration with the National Taiwan Symphony Orchestra (NTSO) and Industrial Technology Research Institute (ITRI). Both organizations collaborate to integrate emerging media technologies, including augmented reality (AR) and volumetric capture for content production, and creative music teaching methods, derived from traditional pop-up sketch books. The final product featured 3D animated videos to achieve interactive learning with digital formation additional to the real worlds. This AR multi-sensory pop-up sketch book utilizes advanced volumetric capture technology to capture the motions of main actors in vivid 3D animation. Besides, modularized pop-up cards of musical instruments provide a haptic experience to complement the story. The book targets children aged between 3 and 12 years. An actual reading survey was conducted on 497 students from five kindergartens in Taiwan. Satisfaction with the book was rated using a five-rank scale. The cluster random sampling method was used for data analysis. Results of t-test produced an average score of 4.9980, which indicated that the target audience ranked the book with high levels of satisfaction. The results also confirmed that the story line was familiar among young children within the target age range. Additionally, using digital audio-visual augmented reality technology will be conducive to young children in terms of acceptance and recognition of traditional music culture. 3D animations of famous intellectual property characters aroused the interest of readers in learning about music through interactive contents. Moreover, this study provided evidence that the STEAM education model, which represents a cross-curricular approach that integrates Science, Technology, Engineering, Art, and Mathematics, is applicable to the inheritance and development of the local music culture.
C1 [Ho, Chin-Ling] Natl Taiwan Symphony Orchestra, Taichung, Taiwan.
   [Ho, Chin-Ling] Chaoyang Univ Technol, Taichung, Taiwan.
   [Lin, Tsang-Gang; Chang, Chan-Ru] Ind Technol Res Inst, Serv Syst Technol Ctr, Hsinchu, Taiwan.
   [Lin, Tsang-Gang; Chang, Chan-Ru] Interplan Int Corp, Taipei, Taiwan.
C3 Chaoyang University of Technology; Industrial Technology Research
   Institute - Taiwan
RP Ho, CL (corresponding author), Natl Taiwan Symphony Orchestra, Taichung, Taiwan.; Ho, CL (corresponding author), Chaoyang Univ Technol, Taichung, Taiwan.
EM clho@ntso.gov.tw
OI Ho, Chin-Ling/0000-0001-7429-0280
FU Ministry of Culture, R.O.C. (Taiwan) [1083035025]
FX This work was supported by the Ministry of Culture, R.O.C. (Taiwan)
   [grant number 1083035025].
CR Alakärppä I, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI '17), DOI 10.1145/3098279.3098547
   Barnes J, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312890
   정석호, 2019, [Journal of Korea Game Society, 한국게임학회 논문지], V19, P25
   Guo KW, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356571
   Hilton A, 2000, VISUAL COMPUT, V16, P411, DOI 10.1007/PL00013395
   Horváth I, 2018, INT CONF COGN INFO, P355, DOI 10.1109/CogInfoCom.2018.8639907
   Kening Z, 2016, S ED TALKS SIGGRAPH, P1, DOI [10.1145/2993363.3006041, DOI 10.1145/2993363.3006041]
   Lee LS, 2018, MICROBIOLOGYOPEN, V7, DOI 10.1002/mbo3.615
   Lemos B.H.V., 2017, COMPUTER SCI INFORM, V5, P121, DOI [10.13189/CSIT.2017.050401, DOI 10.13189/CSIT.2017.050401]
   Mahayuddin ZR., 2020, J CRIT REV, V7, P514, DOI [10.31838/jcr.07.19.66, DOI 10.31838/JCR.07.19.66]
   Makhkamova A., 2020, AUGMENTED REALITY VI, P283, DOI DOI 10.1007/978-3-030-37869-1_23
   Maraffi Chris., 2003, Maya character creation: modeling and animation controls
   Regenbrecht H, 2021, IEEE ACCESS, V9, P68185, DOI 10.1109/ACCESS.2021.3076488
   Shatunova Olga., 2019, J SOCIAL SCI ED RES, V10, P131
   Starck J, 2007, IEEE COMPUT GRAPH, V27, P21, DOI 10.1109/MCG.2007.68
   Wei CC, 2015, THESIS NATL CHENG KU
   Yannier N, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1045, DOI 10.1145/2702123.2702397
NR 17
TC 3
Z9 3
U1 7
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 4847
EP 4862
DI 10.1007/s11042-022-12314-3
EA FEB 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000758308400006
DA 2024-07-18
ER

PT J
AU Dong, WL
   Zeng, H
   Peng, Y
   Gao, XM
   Peng, AJ
AF Dong, Wanli
   Zeng, Hui
   Peng, Yong
   Gao, Xiaoming
   Peng, Anjie
TI A deep learning approach with data augmentation for median filtering
   forensics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Median filtering forensics; Data augmention; Convolutional neural
   network
ID IDENTIFICATION; NETWORK; MODELS
AB Median filtering forensics for small-size JPEG compressed images is practicable and useful in the block-based tampering detection. In this paper, we concentrate the detection of median filtering for small-size JPEG compressed images. Such a task is chanllenging because it is difficult to learn effective and reliable feature from insufficient and subtle median filtering traces left in the small-size JPEG compressed images. We propose a median filtering forensics network called MFFNet to solve these problems, which is driven by both deep convolutional neural network (CNN) and data augmention. Since median filtering forensics is essentially a binary classification task, we borrow a powerful image classification model Xception as the base model to construct the proposed MFFNet. In order to enhance the weak traces of median filtering left in the small-size JPEG compressed images, we carefully simplify and re-design the architecture of Xception, among which the pre-processing layers containing up-scaling and extracting residuals, pooling layers and squeeze-and-excitation block are employed. In addition, a large number of training images along with data augmentation are also employed to improve the generalization ablilty of the MFFNet. The extensive experimental results on the composite database demonstrate that the proposed approach outperforms the state-of-the-arts, achieveing at least 4% higher detection accuracy for detecting median filtering on 32 x 32 JPEG 70 compressed images.
C1 [Dong, Wanli; Zeng, Hui; Peng, Yong; Gao, Xiaoming; Peng, Anjie] Southwest Univ Sci & Technol, Sch Comp Sci & Technol, Mianyang 621010, Sichuan, Peoples R China.
C3 Southwest University of Science & Technology - China
RP Peng, AJ (corresponding author), Southwest Univ Sci & Technol, Sch Comp Sci & Technol, Mianyang 621010, Sichuan, Peoples R China.
EM penganjie200012@163.com
RI GAO, XIAO/JED-3257-2023
OI dong, wanli/0000-0003-2680-3736
FU NSFC [61702429]; Sichuan Science and Technology Program [21ZDYF3119]
FX This work was partially supported by NSFC (No. 61702429), Sichuan
   Science and Technology Program (No. 21ZDYF3119).
CR Barni M, 2010, INT CONF ACOUST SPEE, P1690, DOI 10.1109/ICASSP.2010.5495494
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bas P., 2008, BOWS-2 Contest (Break Our Watermarking System)
   Bayar B, 2018, IEEE T INF FOREN SEC, V13, P2691, DOI 10.1109/TIFS.2018.2825953
   BOVIK AC, 1987, IEEE T ACOUST SPEECH, V35, P493, DOI 10.1109/TASSP.1987.1165153
   Cao G, 2010, IEEE INT CON MULTI, P89, DOI 10.1109/ICME.2010.5583869
   Chen C., 2012, INT WORKSHOP INFORM, V1, P15
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Chen YF, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2111, DOI 10.1109/ICASSP.2018.8462057
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Chuang WH, 2009, INT CONF ACOUST SPEE, P1517, DOI 10.1109/ICASSP.2009.4959884
   Dang-Nguyen D.T., 2015, P ACM MULT SYST C, P219
   Dauphin Y. N., 2017, arXiv preprint arXiv: 1703.09452v3
   Dozat T., 2016, INT C LEARN REPR SAN
   Duan G., 2019, INT WORKSH DIG WAT, P126
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gloe T., 2010, ACM S APPL COMP, P1584, DOI DOI 10.1080/15567281.2010.531500
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Heydarpour F, 2020, INT J INTERACT MULTI, V6, P18, DOI 10.9781/ijimai.2020.11.011
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jin X, 2018, IEEE ACCESS, V6, P50459, DOI 10.1109/ACCESS.2018.2867370
   Kang XG, 2013, IEEE T INF FOREN SEC, V8, P1456, DOI 10.1109/TIFS.2013.2273394
   Kim D, 2018, IEEE SIGNAL PROC LET, V25, DOI 10.1109/LSP.2017.2782363
   Kirchner M, 2010, PROC SPIE, V7541, DOI 10.1117/12.839100
   Kodovsky J, 2014, IEEE T INF FOREN SEC, V9, P752, DOI 10.1109/TIFS.2014.2309054
   Li HD, 2018, IEEE T CIRC SYST VID, V28, P31, DOI 10.1109/TCSVT.2016.2599849
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Liu AN, 2019, MULTIMED TOOLS APPL, V78, P26851, DOI 10.1007/s11042-016-4251-z
   Liu AN, 2017, MULTIMED TOOLS APPL, V76, P22119, DOI 10.1007/s11042-017-4845-0
   Luo SH, 2019, IEEE ACCESS, V7, P80614, DOI 10.1109/ACCESS.2019.2923000
   Niu YK, 2017, SIGNAL PROCESS-IMAGE, V53, P65, DOI 10.1016/j.image.2017.01.008
   Patterson G, 2016, LECT NOTES COMPUT SC, V9910, P85, DOI 10.1007/978-3-319-46466-4_6
   Peng AJ, 2019, IEEE ACCESS, V7, P28525, DOI 10.1109/ACCESS.2019.2897761
   [彭安杰 Peng Anjie], 2016, [计算机学报, Chinese Journal of Computers], V39, P503
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Shan WY, 2019, IEEE ACCESS, V7, P17174, DOI 10.1109/ACCESS.2019.2894981
   Shen ZY, 2016, MULTIMED TOOLS APPL, V75, P2327, DOI 10.1007/s11042-014-2407-2
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stamm MC, 2013, IEEE ACCESS, V1, P167, DOI 10.1109/ACCESS.2013.2260814
   Stamm MC, 2011, IEEE T INF FOREN SEC, V6, P1050, DOI 10.1109/TIFS.2011.2119314
   Takahashi R., 2018, ASIAN C MACHINE LEAR, P786
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tang HS, 2018, J VIS COMMUN IMAGE R, V51, P162, DOI 10.1016/j.jvcir.2018.01.011
   Tariang DB, 2019, IEEE SIGNAL PROC LET, V26, P1132, DOI 10.1109/LSP.2019.2922498
   Yang JQ, 2018, MULTIMED TOOLS APPL, V77, P7931, DOI 10.1007/s11042-017-4691-0
   Yu L, 2019, IEEE ACCESS, V7, P120594, DOI 10.1109/ACCESS.2019.2932810
   Yuan HD, 2011, IEEE T INF FOREN SEC, V6, P1335, DOI 10.1109/TIFS.2011.2161761
   Zhan YF, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P165, DOI 10.1145/3082031.3083250
   Zhang J, 2020, IEEE SIGNAL PROC LET, V27, P276, DOI 10.1109/LSP.2020.2966888
   Zhang YJ, 2014, IEEE SIGNAL PROC LET, V21, P275, DOI 10.1109/LSP.2013.2295858
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
NR 54
TC 6
Z9 6
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11087
EP 11105
DI 10.1007/s11042-022-12040-w
EA FEB 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757200200012
DA 2024-07-18
ER

PT J
AU de Oliveira, GAA
   Oliveira, OD
   de Abreu, S
   de Bettio, RW
   Freire, AP
AF de Oliveira, Gabriela A. A.
   Oliveira, Otavio de Faria
   de Abreu, Stenio
   de Bettio, Raphael W.
   Freire, Andre P.
TI Opportunities and accessibility challenges for open-source
   general-purpose home automation mobile applications for visually
   disabled users
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visually disabled users; Accessibility; Mobile applications; Home
   automation; Screen readers; WCAG
ID INTERNET; THINGS; PEOPLE; DESIGN
AB The Internet of Things approaches applied in the context of home automation have been an important promise to improve the lives of users with visual impairments. However, there are few research studies that result in well-established techniques and guidelines for making these applications accessible for use with screen reading software or other adjustments required by visually impaired users. This article presents an analysis of design features to help design more affordable mobile home automation applications for visually impaired users. The analysis was carried out through tests by seven visually impaired users on a prototype developed in previous studies. Despite the limitations in the proof-of-concept prototype used in this study, users found the application promising and highlighted the need for improvements in the field, highlighting the opportunities to provide home automation applications to enhance independent living scenarios. The article also shows the challenges to be faced in these applications, considering the current limitations with support for mobile interaction through screen readers for applications that are very intensive in terms of dynamic elements and the need for immediate and accurate feedback.
C1 [de Oliveira, Gabriela A. A.; Oliveira, Otavio de Faria; de Abreu, Stenio; de Bettio, Raphael W.; Freire, Andre P.] Univ Fed Lavras, Caixa Postal 3037, BR-37200000 Lavras, MG, Brazil.
C3 Universidade Federal de Lavras
RP Freire, AP (corresponding author), Univ Fed Lavras, Caixa Postal 3037, BR-37200000 Lavras, MG, Brazil.
EM gabriela.araujoa@gmail.com; otaviolaoliveira@gmail.com;
   stenioabreu96@gmail.com; raphaelwb@dcc.ufla.br; apfreire@dcc.ufla.br
RI Freire, Andre/C-9233-2013
OI Freire, Andre/0000-0001-7894-9740
FU CNPq; FAPEMIG; CAPES; SAo Paulo Research Foundation (FAPESP)
   [2020/05187-5]
FX We thank all the participants who participated in this study for their
   valuable contribution. We also thank CNPq, FAPEMIG, CAPES and SAo Paulo
   Research Foundation (FAPESP) (proc. 2020/05187-5) for funding this
   study.
CR Abascal J., 2004, ACMS SPECIAL INTERES
   Afif M, 2020, MULTIMED TOOLS APPL, V79, P31645, DOI 10.1007/s11042-020-09662-3
   Alam T, 2020, COMPUTER SCI INFORM, V1
   Albacete P. L., 1998, Assistive technology and artificial intelligence. Applications in robotics, user interfaces and natural language processing, P12, DOI 10.1007/BFb0055967
   American Foundation for the Blind, 2021, LEARN BLINDN
   [Anonymous], 2015, HIVEMQ EMB MQTT 101
   [Anonymous], 2018, P 2018 CHI C HUMAN F
   Berners-Lee Tim, 1999, Weaving the Web: The Original Design and Ultimate Destiny of the World Wide Web
   Domingo MC, 2012, J NETW COMPUT APPL, V35, P584, DOI 10.1016/j.jnca.2011.10.015
   Carvalho L. P., 2016, P 2016 IEEE BIENN C, P1
   Chiti S, 2012, LECT NOTES COMPUT SC, V7383, P607, DOI 10.1007/978-3-642-31534-3_89
   Choras M., 2015, INNOVATIVE SOLUTIONS, P401
   Demiris G, 2008, Yearb Med Inform, P33
   Demirkan H, 2014, ARCHIT SCI REV, V57, P90, DOI 10.1080/00038628.2013.832141
   Dohr A., 2010, Proceedings of the Seventh International Conference on Information Technology: New Generations (ITNG 2010), P804, DOI 10.1109/ITNG.2010.104
   Emiliani PL, 2005, IBM SYST J, V44, P605, DOI 10.1147/sj.443.0605
   Ericsson KA., 1998, Mind, Culture, and Activity, V5, P178, DOI [DOI 10.1207/S15327884MCA0503_3, 10.1207/s15327884mca0503_3]
   Gabriela Amaral Araujo de Oliveira., 2016, Proceedings of the 15th Brazilian Symposium on Human Factors in Computing Systems, P1
   Gallagher B., 2012, OPTOM PRACT, V13, P45
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Gulliksen J., 2004, Universal Access in the Information Society, V3, P6, DOI 10.1007/s10209-003-0079-1
   Hanson V.L., 2009, W4A '09: Proceedings of the 2009 International Cross-Disciplinary Conference on Web Accessibility (W4A), P7, DOI DOI 10.1145/1535654.1535658
   Hudec M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17081926
   Iakovidis DK., 2020, TECHNOLOGICAL TRENDS, P237, DOI DOI 10.1007/978-3-030-16450-8_10
   Islam MM, 2019, IEEE SENS J, V19, P2814, DOI 10.1109/JSEN.2018.2890423
   Kartakis S, 2010, COMPUT IND, V61, P318, DOI 10.1016/j.compind.2009.12.002
   Lanigan PE, 2006, TENTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P147
   Leporini B., 2012, P 24 AUSTR COMPUTER, P339
   Leporini B, 2018, 15TH INTERNATIONAL WEB FOR ALL CONFERENCE (W4A) 2018, DOI 10.1145/3192714.3192823
   Lopes NV, 2014, IEEE CONF WIREL MOB, P152, DOI 10.1109/WiMOB.2014.6962164
   Mahida P, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20216238
   Manjari K., 2020, INTERNET THINGS-NETH, V11, DOI [DOI 10.1016/j.iot.2020.100188, 10.1016/j.iot.2020.100188]
   Mittal VO, 1998, ASSIST TECHNOL, V1458
   Oliveira JD, 2021, INT J HUM-COMPUT INT, P1
   Oliveira Otavio de Faria FAPBRW, 2021, IN PRESS
   Park E, 2018, UNIVERSAL ACCESS INF, V17, P175, DOI 10.1007/s10209-017-0533-0
   Plos O., 2006, Human factors in computing systems (CHI), P1229, DOI DOI 10.1145/1125451.1125681
   Queirós A, 2015, UNIVERSAL ACCESS INF, V14, P57, DOI 10.1007/s10209-013-0328-x
   Rahman M., 2020, SN COMPUT SCI, V1, P1
   Ramlee R., 2012, P 2012 INT C SYSTEM, P1
   Robles R.J., 2010, International Journal of Advanced Science and Technology, V15, P37, DOI DOI 10.2298/FUEE1603451D
   Roentgen U.R., 2008, J. Vis. Impair. Blind, V102, P702, DOI [DOI 10.1177/0145482X0810201105, 10.1177/0145482X0810201105]
   Serra LC, 2015, PROCEDIA COMPUT SCI, V67, P348, DOI 10.1016/j.procs.2015.09.279
   Siddesh G, 2020, SECURING INTERNET TH, P999
   Siebra C, 2016, PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI 2016), P807, DOI 10.1145/2957265.2961848
   Siebra C, 2015, ASSETS'15: PROCEEDINGS OF THE 17TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS & ACCESSIBILITY, P321, DOI 10.1145/2700648.2811358
   Stoyanova M, 2020, IEEE COMMUN SURV TUT, V22, P1191, DOI 10.1109/COMST.2019.2962586
   Talukdar PS, 2020, IEEE REGION 10 SYMP, P291
   Tayyaba S, 2020, INTEL SYST REF LIBR, V172, P343, DOI 10.1007/978-3-030-32644-9_31
   W3C, 2016, ACC
   WHO WHO, 2011, WORLD REP DIS
   Wortmann F, 2015, BUS INFORM SYST ENG+, V57, P221, DOI 10.1007/s12599-015-0383-3
   Xia F, 2012, INT J COMMUN SYST, V25, P1101, DOI 10.1002/dac.2417
   Zanella A, 2014, IEEE INTERNET THINGS, V1, P22, DOI 10.1109/JIOT.2014.2306328
NR 54
TC 2
Z9 3
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 10695
EP 10722
DI 10.1007/s11042-022-12074-0
EA FEB 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000756332700020
DA 2024-07-18
ER

PT J
AU Li, YF
   Chen, X
   Kong, CH
   Dai, LG
   Huang, YF
AF Li, Yufeng
   Chen, Xiang
   Kong, Caihua
   Dai, Longgang
   Huang, Yufeng
TI A deep hourglass-structured fusion model for efficient single image
   dehazing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single image dehazing; Hourglass architecture; Multi-scale features;
   Parallel fusion; Channel attention; Deep learning
ID VISIBILITY
AB Hazy images obstruct the visibility of image content, which can negatively affect vision-based decision-making in multimedia systems and applications. Recently, convolutional neural networks (CNN) are proven with great benefit to remove single image haze, which has aroused research attention. However, in practice, previous works fail to fully exploit multi-scale features and restore the faithful image details from the hazy inputs, resulting in sub-optimal performance. In this paper, we propose a novel and high-efficiency deep hourglass-structured fusion model to address this issue, which also indicates the applicability of the modified hourglass architecture to remove haze. Unlike the conventional multi-scale learning schemes, top-down and bottom-up feature fusions are repeated, so each of the coarse-to-fine scale representations receives data of parallel ones, which allows for more flexible information exchange and aggregation at various scales. To be specific, we develop residual dense module as the backbone unit, while introducing the channel-wise attention mechanism to further enhance the representation ability of the network. As proved by extensive assessments demonstrate, our designed model outclasses existing ones and achieves the advanced performance on benchmark datasets and real hazy images. We have released source codes on GitHub: https://github.com/cxtalk/ Hourglass-DehazeNet.
C1 [Li, Yufeng; Chen, Xiang; Kong, Caihua; Dai, Longgang; Huang, Yufeng] Shenyang Aerosp Univ, Coll Elect Informat Engn, Shenyang 110135, Peoples R China.
C3 Shenyang Aerospace University
RP Chen, X (corresponding author), Shenyang Aerosp Univ, Coll Elect Informat Engn, Shenyang 110135, Peoples R China.
EM liyufeng@sau.edu.cn; ev.xchen@gmail.com; kongcaihua@stu.sau.edu.cn;
   dailonggang@stu.sau.edu.cn; yufengh_sau@sina.com
RI Chen, Xiang/AAX-2272-2020; Huang, Yufeng/IVU-9570-2023
OI Chen, Xiang/0000-0002-8966-8159; Huang, Yufeng/0000-0003-2852-8555; li,
   yufeng/0000-0002-4731-829X; Kong, Caihua/0000-0002-6055-1774
CR Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen DD, 2019, IEEE WINT CONF APPL, P1375, DOI 10.1109/WACV.2019.00151
   Chen X, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3072917
   Chen X, 2021, IEEE COMPUT SOC CONF, P872, DOI 10.1109/CVPRW53098.2021.00097
   Dong H, 2020, PROC CVPR IEEE, P2154, DOI 10.1109/CVPR42600.2020.00223
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Fourure D., 2017, ARXIV170707958, P181
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Huang Gao, 2018, INT C LEARN REPR
   Kui Jiang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8343, DOI 10.1109/CVPR42600.2020.00837
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li RD, 2018, PROC CVPR IEEE, P8202, DOI 10.1109/CVPR.2018.00856
   Li YN, 2018, NEUROCOMPUTING, V283, P73, DOI 10.1016/j.neucom.2017.12.046
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306
   NEWELL A, 2016, LECT NOTES COMPUT SC, DOI DOI 10.1145/2901318.2901343
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Qu YY, 2019, PROC CVPR IEEE, P8152, DOI 10.1109/CVPR.2019.00835
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Shao YJ, 2020, PROC CVPR IEEE, P2805, DOI 10.1109/CVPR42600.2020.00288
   Sharma T, 2020, MULTIMED TOOLS APPL, V79, P30769, DOI 10.1007/s11042-020-09496-z
   Shen JW, 2020, IEEE COMPUT SOC CONF, P877, DOI 10.1109/CVPRW50498.2020.00117
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Wang C, 2020, MULTIMED TOOLS APPL, V79, P19595, DOI 10.1007/s11042-020-08855-0
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yang Y, 2019, IEEE SIGNAL PROC LET, V26, P1877, DOI 10.1109/LSP.2019.2952047
   Yeh CH, 2020, IEEE T IMAGE PROCESS, V29, P3153, DOI 10.1109/TIP.2019.2957929
   Zhang H, 2018, IEEE COMPUT SOC CONF, P1015, DOI 10.1109/CVPRW.2018.00135
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang X, 2019, ARXIV180710806
   Zhang YF, 2017, IEEE IMAGE PROC, P3205, DOI 10.1109/ICIP.2017.8296874
   Zung J, 2017, ARXIV170802599
NR 42
TC 1
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 35247
EP 35260
DI 10.1007/s11042-022-12312-5
EA FEB 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000756208600003
DA 2024-07-18
ER

PT J
AU Xu, XN
   Wei, YZ
AF Xu, Xining
   Wei, Yuzhou
TI An ultra-short-term wind speed prediction model using LSTM and CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Long short-term memory network; Convolutional neural network;
   Ultra-short-term prediction; Wind speed prediction
ID NEURAL-NETWORKS
AB Gale weather can easily cause high-speed train accidents such as derailment and rollover. Therefore, the ultra-short-term prediction of wind speed is of great significance for a safe operation of high-speed rail. A prediction model based on long short-term memory (LSTM) networks and convolutional neural network (CNN) is proposed in this paper. The maximum wind speed data per minute collected by WindLog wind speed sensor is pre-processed. Setting includes reasonable step parameters and convolution kernel to establish a prediction model combined with two-layer LSTM and two-layer CNN. The proposed model was tested using wind speed data of Haidian District, and the wind speeds of 1 min, 5 min and 10 min ahead were predicted. The mean absolute error (MAE) of 1 min ahead prediction was 0.487 m/s. The MAE of 5 min ahead prediction is 0.547 m/s. The MAE of 10 min ahead prediction is 0.593 m/s. The predicting performances of different models are compared by using the same data. The experimental results show that the proposed prediction model has better adaptability and higher prediction accuracy.
C1 [Xu, Xining] Beijing Jiaotong Univ, Sch Mech Elect & Control Engn, Beijing 100044, Peoples R China.
   [Xu, Xining] Beijing Jiaotong Univ, Key Lab Vehicle Adv Mfg Measuring & Control Techn, Minist Educ, Beijing 100044, Peoples R China.
   [Wei, Yuzhou] CRRC Qishuyan Inst Co Ltd, Technol R&D Ctr, Changzhou 213011, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University; CRRC
   Corporation
RP Xu, XN (corresponding author), Beijing Jiaotong Univ, Sch Mech Elect & Control Engn, Beijing 100044, Peoples R China.; Xu, XN (corresponding author), Beijing Jiaotong Univ, Key Lab Vehicle Adv Mfg Measuring & Control Techn, Minist Educ, Beijing 100044, Peoples R China.
EM xuxining@bjtu.edu.cn
OI Xu, Xining/0000-0001-6815-6018
FU Fundamental Research Funds for the Central Universities of China
   [2019JBM045]
FX This research was funded by the Fundamental Research Funds for the
   Central Universities of China (2019JBM045).
CR Asghar AB, 2018, NEUROCOMPUTING, V287, P58, DOI 10.1016/j.neucom.2018.01.077
   Bandarathilake, 2018, ICSBE, P227
   [崔新强 Cui Xinqiang], 2016, [灾害学, Journal of Catastrophology], V31, P26
   [龚小龙 Gong Xiaolong], 2017, [电子测量与仪器学报, Journal of Electronic Measurement and Instrument], V31, P1890
   He K., 2018, Electronic Measurement Technology, V41, P146, DOI [10.19651/j.cnki.emt.1701311, DOI 10.19651/J.CNKI.EMT.1701311]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jing, 2017, FOREIGN ELECT MEAS T, V36, P109
   Khosravi A, 2018, APPL ENERG, V224, P550, DOI 10.1016/j.apenergy.2018.05.043
   [李锋 Li Feng], 2018, [仪器仪表学报, Chinese Journal of Scientific Instrument], V39, P217
   Liu H, 2018, ENERG CONVERS MANAGE, V166, P120, DOI 10.1016/j.enconman.2018.04.021
   [刘兴杰 Liu Xingjie], 2014, [中国电机工程学报, Proceedings of the Chinese Society of Electrical Engineering], V34, P3162
   Madhiarasan M, 2017, ARTIF INTELL REV, V48, P449, DOI 10.1007/s10462-016-9506-6
   Moreno SR, 2018, RENEW ENERG, V126, P736, DOI 10.1016/j.renene.2017.11.089
   Pinson P, 2007, WIND ENERGY, V10, P497, DOI 10.1002/we.230
   [秦剑 Qin Jian], 2012, [电子测量与仪器学报, Journal of Electronic Measurement and Instrument], V26, P236
   Ren C, 2014, KNOWL-BASED SYST, V56, P226, DOI 10.1016/j.knosys.2013.11.015
   [任尊松 REN Zunsong], 2006, [铁道学报, Journal of the China Railway Society], V28, P46
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sugimoto S, 2001, J HYDROL, V242, P137, DOI 10.1016/S0022-1694(00)00390-5
   Tasnim S, 2018, KNOWL-BASED SYST, V145, P15, DOI 10.1016/j.knosys.2017.12.036
   Torres-Barrán A, 2019, NEUROCOMPUTING, V326, P151, DOI 10.1016/j.neucom.2017.05.104
   [徐晓冰 Xu Xiaobing], 2013, [电子测量与仪器学报, Journal of Electronic Measurement and Instrument], V27, P944
   [叶瑞丽 Ye Ruili], 2017, [电工技术学报, Transactions of China Electrotechnical Society], V32, P103
   [郑啸 Zheng Xiao], 2018, [电子测量与仪器学报, Journal of Electronic Measurement and Instrument], V32, P195
NR 24
TC 8
Z9 9
U1 3
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 10819
EP 10837
DI 10.1007/s11042-022-12215-5
EA FEB 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000756332700013
DA 2024-07-18
ER

PT J
AU Wang, YQ
   Jiang, K
   Lu, H
   Xu, ZH
   Li, GJ
   Chen, C
   Geng, X
AF Wang, Yingquan
   Jiang, Ke
   Lu, Hu
   Xu, Ziheng
   Li, Gaojian
   Chen, Chao
   Geng, Xia
TI Encoder-decoder assisted image generation for person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person ReID; GAN; AutoEncoder
ID NEURAL-NETWORKS
AB Due to the low number of pedestrian samples in the categories in person Re-Identification (ReID) benchmarks, many researchers use Generative Adversarial Networks (GANs) to generate samples and expand the datasets. Real and generated samples are then used to train the person ReID model. In traditional GANs, high-dimensional samples are generated from noise. However, due to the complexity of pedestrian samples, the visual effect of generated samples is unsatisfactory. In this work, we propose a new generative model called the Encoder-Decoder Assisted Image Generative Adversarial Network (EDAGAN). EDAGAN improves the visual effects of the generated samples by reducing the dimensions of generated feature, which are obtained by the traditional GANs. In addition, many existing methods cannot optimize the real and generated samples simultaneously. Thus, the person ReID model may not make good use of the generated samples to improve the performance. For this purpose, we propose a new loss function called Soft Label Smoothing Regularization for Outliers (SLSRO), which facilitates the use of real samples and generated samples for model training. We use ResNet-50 as the backbone network to evaluate the effectiveness of EDAGAN and SLSRO. The experiments show that the EDAGAN with the SLSRO achieves a significant improvement compared to other models on the three public benchmarks, Market-1501, DukeMTMC-ReID and CUHK03.
C1 [Wang, Yingquan; Jiang, Ke; Lu, Hu; Xu, Ziheng; Chen, Chao; Geng, Xia] Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang, Jiangsu, Peoples R China.
   [Lu, Hu] Jiangsu Prov Big Data Ubiquitous Percept & Intell, Zhenjiang, Jiangsu, Peoples R China.
   [Li, Gaojian] Shanghai Univ Engn Sci, Sch Elect & Elect Engn, Shanghai, Peoples R China.
C3 Jiangsu University; Shanghai University of Engineering Science
RP Lu, H (corresponding author), Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang, Jiangsu, Peoples R China.; Lu, H (corresponding author), Jiangsu Prov Big Data Ubiquitous Percept & Intell, Zhenjiang, Jiangsu, Peoples R China.
EM luhu@ujs.edu.cn
FU Postgraduate Research & Practice Innovation Program of Jiangsu Province
   [KYCX20_3083]; Program of Shanghai Academic/Technology Research Leader
   [18XD1423200]
FX This work was supported by the Postgraduate Research & Practice
   Innovation Program of Jiangsu Province (Project No. KYCX20_3083) and
   Program of Shanghai Academic/Technology Research Leader (Project
   No.18XD1423200).
CR Amponsah AA, 2021, CONNECT SCI, V33, P803, DOI 10.1080/09540091.2021.1900072
   [Anonymous], 2013, INT C MACH LEARN WOR
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247939
   Arjovsky M., 2017, ARXIV170107875
   Augustus, 2016, ICML WORKSH
   Ba J. L., 2016, LAYER NORMALIZATION, DOI DOI 10.48550/ARXIV.1607.06450
   Bai S, 2017, AAAI CONF ARTIF INTE, P1281
   Bak S, 2018, LECT NOTES COMPUT SC, V11217, P193, DOI 10.1007/978-3-030-01261-8_12
   Bolle RM, 2005, FOURTH IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P15, DOI 10.1109/AUTOID.2005.48
   Bottou L., 2012, Neural networks: Tricks of the trade, P421, DOI DOI 10.1007/978-3-642-35289-8_25
   Chang YS, 2020, PATTERN RECOGN LETT, V130, P306, DOI 10.1016/j.patrec.2018.08.011
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Ge YX, 2018, ADV NEUR IN, V31
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G. E., 2012, 12070580 ARXIV
   Huang Y, 2019, IEEE T IMAGE PROCESS, V28, P1391, DOI 10.1109/TIP.2018.2874715
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Gulrajani I, 2017, ADV NEUR IN, V30
   King DB, 2015, ACS SYM SER, V1214, P1
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Ling QH, 2019, COGN SYST RES, V53, P51, DOI 10.1016/j.cogsys.2018.01.001
   Liu JX, 2018, PROC CVPR IEEE, P4099, DOI 10.1109/CVPR.2018.00431
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lu H, 2021, MULTIMED TOOLS APPL, V80, P24759, DOI 10.1007/s11042-021-10880-6
   Lu H, 2021, NEURAL NETWORKS, V135, P148, DOI 10.1016/j.neunet.2020.12.005
   Lu H, 2020, SOFT COMPUT, V24, P14157, DOI 10.1007/s00500-020-04785-z
   Ma LQ, 2017, ADV NEUR IN, V30
   Maas AL, 2013, RECTIFIER NONLINEARI
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Ning X, 2021, IEEE T CIRC SYST VID, V31, P3391, DOI 10.1109/TCSVT.2020.3043026
   Ning X, 2021, NEUROCOMPUTING, V453, P801, DOI 10.1016/j.neucom.2020.05.106
   Qian XL, 2018, LECT NOTES COMPUT SC, V11213, P661, DOI 10.1007/978-3-030-01240-3_40
   Radford A., 2015, ARXIV
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Salimans T, 2016, ADV NEUR IN, V29
   Shamsolmoali P, 2021, INFORM FUSION, V72, P126, DOI 10.1016/j.inffus.2021.02.014
   Siarohin A, 2018, PROC CVPR IEEE, P3408, DOI 10.1109/CVPR.2018.00359
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhang ZZ, 2020, IEEE T IMAGE PROCESS, V29, P2463, DOI 10.1109/TIP.2019.2949929
   Zheng L., 2016, PERSON REIDENTIFICAT
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zheng ZD, 2019, IEEE T CIRC SYST VID, V29, P3037, DOI 10.1109/TCSVT.2018.2873599
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
NR 56
TC 6
Z9 6
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 10373
EP 10390
DI 10.1007/s11042-022-11907-2
EA FEB 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000755422300007
DA 2024-07-18
ER

PT J
AU Chen, PH
   Huang, CH
   Chiu, WT
   Liao, CM
   Lin, YR
   Hung, SK
   Chen, LC
   Hsieh, HL
   Chiou, WY
   Lee, MS
   Lin, HY
   Liu, WM
AF Chen, Pin-Hsiu
   Huang, Cheng-Hsien
   Chiu, Wen-Tse
   Liao, Chen-Mao
   Lin, Yu-Ruei
   Hung, Shih-Kai
   Chen, Liang-Cheng
   Hsieh, Hui-Ling
   Chiou, Wen-Yen
   Lee, Moon-Sing
   Lin, Hon-Yi
   Liu, Wei-Min
TI A multiple organ segmentation system for CT image series using
   Attention-LSTM fused U-Net
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple organ segmentation system; Attention U-net; LSTM; CT image;
   DICOM-RT; Contour
ID DELINEATION; RADIOTHERAPY
AB The multi-organ contouring (MOC) task is required when a radiotherapy is performed to eradicate the cancerous tissue while minimizing the dosage delivered to the surrounding healthy organs. Currently most of the task is done manually with enormous labor and time cost. To reduce the scheduling waiting time from increasing cancer population, it is beneficial to both the patients and therapeutists to have an automatic contouring tool. In this work an Attention-LSTM fused U-Net model is proposed to perform the multiple organ segmentation from a CT image series. The organs to be delineated include lung, liver, stomach, esophagus, heart, and kidneys. To train and evaluate our model, the CT image series of 146 patients was acquired from a local hospital with IRB approval. The segmentation accuracy of the six organs in terms of Dice Similarity Coefficient (DSC) were 99.27%, 95.48%, 88.53%, 80.81%, 93.8%, and 93.46%, respectively. To make the AI-embedded MOC system readily applicable in clinical environments, a data processing workflow and the corresponding GUI were also implemented and published on Github. The doctors can download the CT image data from the PACS server, use our system to perform MOC tasks, and output the contouring results in DICOM-RT format so they can be uploaded back to the treatment planning system for further fine-tuning and dosage/path calculation. To our best knowledge the work might be the first non-commercial model-integrated system compatible with the commercial treatment planning systems and ready to be used by the doctors.
C1 [Chen, Pin-Hsiu; Huang, Cheng-Hsien; Chiu, Wen-Tse; Liao, Chen-Mao; Lin, Yu-Ruei; Liu, Wei-Min] Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi, Taiwan.
   [Hung, Shih-Kai; Chen, Liang-Cheng; Hsieh, Hui-Ling; Chiou, Wen-Yen; Lee, Moon-Sing; Lin, Hon-Yi] Dalin Tzu Chi Hosp, Buddhist Tzu Chi Med Fdn, Dept Radiat Oncol, Chiayi, Taiwan.
C3 National Chung Cheng University; Buddhist Tzu Chi General Hospital;
   Dalin Tzu Chi Hospital
RP Liu, WM (corresponding author), Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi, Taiwan.
EM chenpin860627@alum.ccu.edu.tw; qe903121@icloud.com;
   b072351017@gmail.com; morris598107@gmail.com; a0928870301@gmail.com;
   oncology158@gmail.com; airinsummer1425@gmail.com;
   df154221@tzuchi.com.tw; armstrong_washington@hotmail.com;
   rtjo5566@gmail.com; doc31221@gmail.com; wmliu@cs.ccu.edu.tw
RI Hsieh, Hui-Ling/GPW-9991-2022; Hsieh, Hui-Ling/ABB-5601-2021
OI Hsieh, Hui-Ling/0000-0003-3024-3639; Hsieh,
   Hui-Ling/0000-0003-3024-3639; Chen, Liang-Cheng/0000-0002-0657-5636;
   Chiou, Wen-Yen/0000-0002-5541-6834
FU Ministry of Science and Technology, Taiwan [MOST 108-2221-E-194 -042]
FX Supported by the grant from Ministry of Science and Technology, Taiwan
   (No.: MOST 108-2221-E-194 -042).
CR [Anonymous], 2019, The liver tumor segmentation benchmark (lits)
   Chen PH, 2020, INT S COMP CONS CONT
   Huang HM, 2020, INT CONF ACOUST SPEE, P1055, DOI [10.1109/ICASSP40776.2020.9053405, 10.1109/icassp40776.2020.9053405]
   La Macchia M, 2012, RADIAT ONCOL, V7, DOI 10.1186/1748-717X-7-160
   Le Maitre A, 2012, PHYS MED BIOL, V57, P5381, DOI 10.1088/0031-9155/57/17/5381
   Liu YZ, 2020, MED PHYS, V47, P4316, DOI 10.1002/mp.14386
   Mattiucci GC, 2013, ACTA ONCOL, V52, P1417, DOI 10.3109/0284186X.2013.813069
   Novikov AA, 2019, IEEE T MED IMAGING, V38, P1207, DOI 10.1109/TMI.2018.2881678
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shen C, 2019, PROC SPIE, V10949, DOI 10.1117/12.2512790
   Shi XJ, 2015, ADV NEUR IN, V28
   Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28
   Taha AA, 2015, BMC MED IMAGING, V15, DOI 10.1186/s12880-015-0068-x
   Tang H, 2021, IEEE WINT CONF APPL, P938, DOI 10.1109/WACV48630.2021.00098
   Tang YC, 2021, MED IMAGE ANAL, V69, DOI 10.1016/j.media.2020.101894
   Thomson D, 2014, RADIAT ONCOL, V9, DOI 10.1186/1748-717X-9-173
   Tian ZQ, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/9595687
   Wang Y, 2019, MED IMAGE ANAL, V55, P88, DOI 10.1016/j.media.2019.04.005
   Yang JZ, 2015, MED PHYS, V42, P5310, DOI 10.1118/1.4928485
   Yu LQ, 2017, AAAI CONF ARTIF INTE, P66
NR 21
TC 2
Z9 2
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 11881
EP 11895
DI 10.1007/s11042-021-11889-7
EA JAN 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000749055500007
DA 2024-07-18
ER

PT J
AU Molina, G
   Gimeno, J
   Portalés, C
   Casas, S
AF Molina, Guillermo
   Gimeno, Jesus
   Portales, Cristina
   Casas, Sergio
TI A comparative analysis of two immersive virtual reality systems in the
   integration and visualization of natural hand interaction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality; CAVE; HMD; HTC vive; Leap motion; Hand tracking;
   Natural interface; Comparative analysis
ID CAVE; HMD
AB It is generally accepted that the use of natural interaction provides a positive impact in Virtual Reality (VR) applications. Therefore, it is important to understand what is the best way to integrate and visualize this feature in VR. For this reason, this paper presents a comparative study of the integration of natural hand interaction in two immersive VR systems: a Cave Audio Visual Experience (CAVE) system -where users' real hands are visible- and a non-see-through Head-Mounted Display (HMD) system -where only a virtual representation of the hands is possible-. In order to test the suitability of using this type of interaction in a CAVE and compare it to an HMD, we raise six research questions related to task performance, usability and perception differences regarding natural hand interaction with these two systems. To answer these questions, we designed an experiment where users have to complete a pick-and-place task with virtual balls and a text-typing task with virtual keyboards. In both systems, the same tracking technology, based on a Leap Motion device, was used. To the best of our knowledge this is the first academic work addressing a comparison of this type. Objective and subjective data were collected during the experiments. The results show that the HMD has a performance, preference and usability advantage over the CAVE with respect to the integration of natural hand interaction. Nevertheless, the results also show that the CAVE system can be, as well, successfully used in combination with an optical hand tracking device.
C1 [Molina, Guillermo; Gimeno, Jesus; Portales, Cristina; Casas, Sergio] Univ Valencia UV, Dept Comp Sci, Valencia, Spain.
C3 University of Valencia
RP Portalés, C (corresponding author), Univ Valencia UV, Dept Comp Sci, Valencia, Spain.
EM Cristina.Portales@uv.es
RI Casas Yrurzum, Sergio/S-3693-2017
OI Casas Yrurzum, Sergio/0000-0002-0396-4628
FU CRUE-CSIC agreement; Springer Nature; Spanish government
   [RYC2018025009-I]
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature. Cristina Portales is supported by the Spanish
   government postdoctoral grant Ramon y Cajal, under grant No.
   RYC2018025009-I.
CR [Anonymous], IBM SPSS software
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Aykent B, 2015, EFFECT VR DEVICE HMD
   Azmandian M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1968, DOI 10.1145/2858036.2858226
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Bazzaz SA, 2020, ECAADE PROC, P375
   Benda B, 2020, INT SYM MIX AUGMENT, P269, DOI 10.1109/ISMAR50242.2020.00050
   Bowman D. A., 2002, Proceedings of the Human Factors and Ergonomics Society 46th Annual Meeting, P2134
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Juan MC, 2009, PRESENCE-VIRTUAL AUG, V18, P232, DOI 10.1162/pres.18.3.232
   Combe T, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P448, DOI 10.1109/VRW52623.2021.00106
   Cordeil M, 2017, IEEE T VIS COMPUT GR, V23, P441, DOI 10.1109/TVCG.2016.2599107
   Cruz-Neira C., 2018, Multimodal Technol. Interact, V2, DOI [DOI 10.3390/MTI2010008, 10.3390/MTI2010008]
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   Elor Aviv, 2020, ACM Transactions on Computing and Healthcare, V1, DOI 10.1145/3396249
   Ghinea M, 2018, LECT NOTES COMPUT SC, V10850, P148, DOI 10.1007/978-3-319-95270-3_10
   Grabowski, 2021, PRACTICAL SKILLS TRA
   Kim K, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P143, DOI 10.1109/VR.2012.6180922
   Leite DQ, 2017, MULTIMED TOOLS APPL, V76, P20423, DOI 10.1007/s11042-016-3959-0
   Likert R., 1932, Arch. Psychol., V22, P44, DOI DOI 10.4135/9781412961288.N454
   Lin Lorraine, 2019, 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P510, DOI 10.1109/VR.2019.8797787
   Lindsey S, 2017, EVALUATION LOW COST
   Dorado JL, 2017, IEEE SYMP 3D USER, P221, DOI 10.1109/3DUI.2017.7893351
   Mallaro S, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139171
   MASSEY FJ, 1951, J AM STAT ASSOC, V46, P68, DOI 10.2307/2280095
   Mestre DR., 2017, Electronic Imaging, V29, P31, DOI DOI 10.2352/ISSN.2470-1173.2017.3.ERVR-094
   Miller J, COMP VIRTUAL GAME DA
   Mishra P, 2019, ANN CARD ANAESTH, V22, P67, DOI 10.4103/aca.ACA_157_18
   Pala P, 2021, ACCIDENT ANAL PREV, V152, DOI 10.1016/j.aap.2021.106004
   Perani D, 2001, NEUROIMAGE, V14, P749, DOI 10.1006/nimg.2001.0872
   Perez-Marcos D, 2012, COGN NEURODYNAMICS, V6, P295, DOI 10.1007/s11571-011-9178-5
   Philpot A, 2017, P 2017 ACM INT C INT, P65, DOI DOI 10.1145/3077548.3077550
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Ronchi E, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1873
   Schneider D, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P805, DOI [10.1109/VRW50115.2020.00253, 10.1109/VRW50115.2020.00-22]
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.1093/biomet/52.3-4.591
   Tcha-Tokey K., 2017, ACM International Conference Proceeding Series, Part, VF1311, P1, DOI [DOI 10.1145/3121283.3121284, 10.1145/3121283.3121284]
   Unity Technologies Unity Real-time Development Platform, UN 3D
   University of Valencia IRTIC, I ROB INF COMM TECHN
   Weichert F, 2013, SENSORS-BASEL, V13, P6380, DOI 10.3390/s130506380
NR 40
TC 4
Z9 6
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 7733
EP 7758
DI 10.1007/s11042-021-11760-9
EA JAN 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000750865600006
OA hybrid
DA 2024-07-18
ER

PT J
AU Jain, M
   Bhalla, G
   Jain, A
   Sharma, S
AF Jain, Minni
   Bhalla, Grusha
   Jain, Amita
   Sharma, Swati
TI Automatic keyword extraction for localized tweets using fuzzy graph
   connectivity measures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fuzzy centrality measures; Graph-based method; Information retrieval;
   Location-based; Extraction; Social media analysis
AB With an upsurge in the use of social media, a tremendous amount of textual data is being generated, which is being used for applications like sentiment analysis, industry trend analysis, information retrieval etc. In this context, automatic keyword extraction is a crucial and useful task. Many graph - based methods have been proposed which consider co-occurrence as edge weight, but these methods neglect the semantic relations between words. This paper proposes an automatic keyword extraction method for tweets from Twitter that represents text as a fuzzy graph and applies fuzzy centrality measures to find relevant keywords (vertices). Proposed work, F-GAKE (fuzzy graph automatic keyword extraction) takes belongingness of two words concerning the theme of the dataset into consideration and provides a fuzzy edge weight. It also considers node weight which incorporates the position of the words, frequency, importance, strength of neighbours and distance from the central node. It then uses fuzzy degree centrality, fuzzy betweenness, fuzzy PageRank and fuzzy Node and Edge (NE) Rank measures which provide relevant keywords. It is further extended to extract keywords for localized trending topics from Twitter. For experimentation, various Twitter datasets are used and results show that F-GAKE performs better than the state-of-the-art approaches for automatic keyword extraction for short messages, such as tweets.
C1 [Jain, Minni; Bhalla, Grusha] Delhi Technol Univ, Dept Comp Engn, Delhi, India.
   [Jain, Amita] Netaji Subhas Univ Technol, Dept Comp Sci & Engn, East Campus, Delhi, India.
   [Sharma, Swati] Indira Gandhi Delhi Tech Univ Women, Dept Comp Sci & Engn, Delhi, India.
C3 Delhi Technological University; Netaji Subhas University of Technology;
   Indira Gandhi Delhi Technical University for Women (IGDTUW)
RP Jain, M (corresponding author), Delhi Technol Univ, Dept Comp Engn, Delhi, India.
EM amitajain@aiactr.ac.in
RI Jain, Minni/HCI-6045-2022
CR Abdelhaq H, 2017, GEOINFORMATICA, V21, P365, DOI 10.1007/s10707-016-0258-x
   Abilhoa WD, 2014, APPL MATH COMPUT, V240, P308, DOI 10.1016/j.amc.2014.04.090
   Aggarwal A, 2018, COMPUT SIST, V22, P1307, DOI [10.13053/cys-22-4-3077, 10.13053/CyS-22-4-3077]
   Anjali, 2019, 2 INT C ADV COMP COM
   Bellaachia A, 2012, 2012 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY (WI-IAT 2012), VOL 1, P372, DOI 10.1109/WI-IAT.2012.82
   Biswas SK, 2018, EXPERT SYST APPL, V97, P51, DOI 10.1016/j.eswa.2017.12.025
   Caragea Cornelia, 2014, P 2014 C EMPIRICAL M, P1435, DOI DOI 10.3115/V1/D14-1150
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Diakopoulos N., 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P115, DOI 10.1109/VAST.2010.5652922
   Hong TP, 1996, FUZZY SET SYST, V84, P33, DOI 10.1016/0165-0114(95)00305-3
   Hu RJ, 2015, FUZZY INF ENG, V7, P115, DOI 10.1016/j.fiae.2015.03.008
   Hulth A, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P216
   Imran M, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P1021
   Jain A, 2022, COMPUT J, V65, P926, DOI 10.1093/comjnl/bxaa133
   Jain A, 2019, COMPUT SIST, V23, P1337, DOI [10.13053/cys-23-4-2984, 10.13053/CyS-23-4-2984]
   Jain A, 2016, ACM T ASIAN LOW-RESO, V15, DOI 10.1145/2790079
   James S, 2004, INT ENCY INFORM LIB
   Kosko B., 1994, FUZZY THINKING NEW S
   Kwon K, 2015, P 2015 INT C BIG DAT
   Lachlan KA, 2014, COMMUN STUD, V65, P500, DOI 10.1080/10510974.2014.956941
   Litvak M, 2011, ADV INTEL SOFT COMPU, V86, P121, DOI 10.1007/978-3-642-18029-3_13
   LIU F, 2008, IEEE WORKSH SPOK LAN, P181
   Liu F., 2009, NAACL HLT 2009-Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, Proceedings of the Conference, P620, DOI DOI 10.3115/1620754.1620845
   Mathew S, 2009, INFORM SCIENCES, V179, P1760, DOI 10.1016/j.ins.2009.01.003
   Medasani S, 1998, INT J APPROX REASON, V19, P391, DOI 10.1016/S0888-613X(98)10017-8
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Noh J, 2016, MULTIMED TOOLS APPL, V75, P12765, DOI 10.1007/s11042-016-3528-6
   Palshikar GK, 2007, LECT NOTES COMPUT SC, V4815, P503
   Rahutomo F., 2012, in The 7th international student conference on advanced science and technology ICAST
   Rose D., 2010, TEXT MINING APPL THE, V1, P1, DOI [DOI 10.1002/9780470689646.CH1, 10.1002/9780470689646.CH1]
   Rosenfeld A., 1975, Fuzzy Sets and their Applications to Cognitive and Decision Processes, P77, DOI [10.1016/B978-0-12-775260-0.50008-6, DOI 10.1016/B978-0-12-775260-0.50008-6]
   Sayyadi H, 2009, ICWSM
   Turney P.D., 1999, ERB1057 NRC, P1
   Vetriselvi T, 2021, J AMB INTEL HUM COMP, V12, P4609, DOI 10.1007/s12652-020-01856-9
   Vij S., 2019, 4 INT C INT THINGS S
   Vij S, 2018, INT J FUZZY SYST, V20, P444, DOI 10.1007/s40815-017-0433-8
   Wang Z., 2016, INT J SIMUL SYST SCI, V17
   Webster J.J., 1992, COLING 1992, V4, P1106, DOI [DOI 10.3115/992424.992434, 10.3115/992424.992434]
   WILBUR WJ, 1992, J INF SCI, V18, P45, DOI 10.1177/016555159201800106
   Yang M, 2018, MULTIMED TOOLS APPL, V77, P3171, DOI 10.1007/s11042-017-5041-y
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhang C, 2008, J Comput Inf Syst, V4, P1169
   Zhang K, 2006, LECT NOTES COMPUT SC, V4016, P85, DOI 10.1007/11775300_8
   Zhang Q, 1998, J PRAGMATICS, V29, P13, DOI 10.1016/S0378-2166(97)00014-3
NR 44
TC 3
Z9 3
U1 4
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 42931
EP 42956
DI 10.1007/s11042-021-11893-x
EA JAN 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000748678300008
DA 2024-07-18
ER

PT J
AU Romero-González, C
   García-Varea, I
   Martínez-Gómez, J
AF Romero-Gonzalez, Cristina
   Garcia-Varea, Ismael
   Martinez-Gomez, Jesus
TI Shape binary patterns: an efficient local descriptor and keypoint
   detector for point clouds
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shape binary patterns; Point clouds; Local descriptor; Keypoint detector
ID OBJECT RECOGNITION; 3D; MANIPULATION; HISTOGRAMS; IMAGES; SCALE
AB Many of the research problems in robot vision involve the detection of keypoints, areas with salient information in the input images and the generation of local descriptors, that encode relevant information for such keypoints. Computer vision solutions have recently relied on Deep Learning techniques, which make extensive use of the computational capabilities available. In autonomous robots, these capabilities are usually limited and, consequently, images cannot be processed adequately. For this reason, some robot vision tasks still benefit from a more classic approach based on keypoint detectors and local descriptors. In 2D images, the use of binary representations for visual tasks has shown that, with lower computational requirements, they can obtain a performance comparable to classic real-value techniques. However, these achievements have not been fully translated to 3D images, where research is mainly focused on real-value approaches. Thus, in this paper, we propose a keypoint detector and local descriptor based on 3D binary patterns. The experimentation demonstrates that our proposal is competitive against state-of-the-art techniques, while its processing can be performed more efficiently.
C1 [Romero-Gonzalez, Cristina; Garcia-Varea, Ismael; Martinez-Gomez, Jesus] Univ Castilla La Mancha, Comp Syst Dept, Campus Univ S-N, Albacete 02071, Spain.
C3 Universidad de Castilla-La Mancha
RP García-Varea, I (corresponding author), Univ Castilla La Mancha, Comp Syst Dept, Campus Univ S-N, Albacete 02071, Spain.
EM Cristina.RGonzalez@uclm.es; Ismael.Garcia@uclm.es;
   Jesus.Martinez@uclm.es
RI Martinez-Gomez, Jesus/K-4259-2013; Garcia-Varea, Ismael/P-6816-2017
OI Martinez-Gomez, Jesus/0000-0002-4000-1951; Garcia-Varea,
   Ismael/0000-0003-3451-7852
FU Government of Castilla-La Mancha and "ERDF A way of making Europe"
   [SBPLY/17/180501/000493];  [PID2019-106758GB-C33]; 
   [MCIN/AEI/10.13039/501100011033]
FX This work has been funded by the Government of Castilla-La Mancha and
   "ERDF A way of making Europe" through the project
   SBPLY/17/180501/000493. It is also part of the project
   PID2019-106758GB-C33 funded by MCIN/AEI/10.13039/501100011033.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   Alexandre L.A., 2012, WORKSH COL DEPTH CAM, V1, P7, DOI DOI 10.1109/TPAMI.2011.263
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bo LF, 2011, IEEE INT C INT ROBOT, P821, DOI 10.1109/IROS.2011.6048717
   Bro R, 2008, J CHEMOMETR, V22, P135, DOI 10.1002/cem.1122
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Canclini A, 2013, INT CONF DIGIT SIG
   Castellani U, 2008, COMPUT GRAPH FORUM, V27, P643, DOI 10.1111/j.1467-8659.2008.01162.x
   Chen H, 2007, PATTERN RECOGN LETT, V28, P1252, DOI 10.1016/j.patrec.2007.02.009
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Deng HW, 2018, PROC CVPR IEEE, P195, DOI 10.1109/CVPR.2018.00028
   Fehr, 2007, FINN SIGN PROC S FIN
   Fehr J, 2008, INT C PATT RECOG, P616
   Guo YL, 2021, IEEE T PATTERN ANAL, V43, P4338, DOI 10.1109/TPAMI.2020.3005434
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F
   Krainin M, 2011, IEEE INT CONF ROBOT
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mair E, 2010, LECT NOTES COMPUT SC, V6312, P183, DOI 10.1007/978-3-642-15552-9_14
   Martinez-Carranza J, 2013, WORKSH MULT GEOM ROB
   Martínez-Gómez J, 2014, INT J ADV ROBOT SYST, V11, DOI 10.5772/58900
   Mian A, 2010, INT J COMPUT VISION, V89, P348, DOI 10.1007/s11263-009-0296-z
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Miksik O, 2012, INT C PATT RECOG, P2681
   Morgado PM, 2013, I S BIOMED IMAGING, P117
   Muja M., 2012, 2012 Canadian Conference on Computer and Robot Vision, P404, DOI 10.1109/CRV.2012.60
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Paulhac L, 2008, LECT NOTES COMPUT SC, V5112, P670, DOI 10.1007/978-3-540-69812-8_66
   Poiesi F, 2021, INT C PATT RECOG, P5720, DOI 10.1109/ICPR48806.2021.9411978
   Prakhya SM, 2017, AUTON ROBOT, V41, P1501, DOI 10.1007/s10514-016-9612-y
   Romero-Gonzalez C, 2016, IEEE WINTER C APPL C, P1, DOI [10.1109/WACV.2016.7477727, DOI 10.1109/WACV.2016.7477727]
   Romero-González C, 2016, ADV INTELL SYST, V418, P685, DOI 10.1007/978-3-319-27149-1_53
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Rusu RB, 2010, KUNSTL INTELL, V24, P345, DOI 10.1007/s13218-010-0059-6
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848
   Rusu RB, 2008, 2008 10TH INTERNATIONAL CONFERENCE ON CONTROL AUTOMATION ROBOTICS & VISION: ICARV 2008, VOLS 1-4, P643, DOI 10.1109/ICARCV.2008.4795593
   Salti S., 2011, 2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission (3DIMPVT), P236, DOI 10.1109/3DIMPVT.2011.37
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Somanath G, 2011, LECT NOTES COMPUT SC, V6494, P483, DOI 10.1007/978-3-642-19318-7_38
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Stückler J, 2013, ROBOT AUTON SYST, V61, P1106, DOI 10.1016/j.robot.2012.08.003
   Tombari F, 2011, IEEE IMAGE PROC, P809, DOI 10.1109/ICIP.2011.6116679
   Tombari F, 2010, LECT NOTES COMPUT SC, V6313, P356, DOI 10.1007/978-3-642-15558-1_26
   Unnikrishnan Ranjith, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563030
   Wang M, 2013, IEEE T IMAGE PROCESS, V22, P1395, DOI 10.1109/TIP.2012.2231088
   Werghi N, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P562, DOI 10.1109/ICCVW.2013.78
   Xiangsheng Huang, 2004, Proceedings. Third International Conference on Image and Graphics, P184
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Yu Zhong, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P689, DOI 10.1109/ICCVW.2009.5457637
   Zaharescu A, 2009, PROC CVPR IEEE, P373, DOI 10.1109/CVPRW.2009.5206748
   Zeng A, 2017, PROC CVPR IEEE, P199, DOI 10.1109/CVPR.2017.29
   Zhang Z., 2020, Virtual Real Intell Hardw, V2, P222, DOI DOI 10.1016/J.VRIH.2020.05.002
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 59
TC 2
Z9 2
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3577
EP 3601
DI 10.1007/s11042-021-11586-5
EA JAN 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000742319000012
OA hybrid
DA 2024-07-18
ER

PT J
AU Suman, RR
   Mondal, B
   Mandal, T
AF Suman, Rajiv Ranjan
   Mondal, Bhaskar
   Mandal, Tarni
TI A secure encryption scheme using a Composite Logistic Sine Map (CLSM)
   and SHA-256
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encryption; Chaotic map; Random number generation; PRNG; PRNS; SHA256
ID IMAGE ENCRYPTION; ALGORITHM
AB We present an algorithm for image encryption for secure transmission and storage of images over insecure public networks. Our algorithm uses Composite Logistic Sine Map (CLSM) and Secure Hash Algorithm-256 (SHA-256). The algorithm first scrambles the pixels of the plain image based on pseudo random number sequence (PRNS) generated by the CLSM. This is followed by diffusing the pixel values by using values generated by SHA-256. The initial conditions and parameters of the CLSM together with a nonce chosen by the user act as key for the algorithm. The nonce is used to initialize the SHA-256 that generates hash values for the diffusion phase. The algorithm has a very wide key space to defeat any brute force or guessing attack. The proposed algorithm was tested with several images of different characteristics against nine security measures. The tests results show that the scheme is robust, scalable and capable of providing strong security to data. The lightweight arithmetic and logical operations involved in the used chaotic map and in permutation-substitution steps enable it to have fast speed due to low computational overhead. This makes it suitable for low power battery operated devices equipped with inexpensive processors having limited computing speed.
C1 [Suman, Rajiv Ranjan] Natl Inst Technol Jamshedpur, Dept Comp Sci & Engn, Jamshedpur 831014, Bihar, India.
   [Mondal, Bhaskar] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
   [Mandal, Tarni] Natl Inst Technol Jamshedpur, Dept Math, Jamshedpur 831014, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Jamshedpur; National Institute of Technology (NIT System);
   National Institute of Technology Patna; National Institute of Technology
   (NIT System); National Institute of Technology Jamshedpur
RP Suman, RR (corresponding author), Natl Inst Technol Jamshedpur, Dept Comp Sci & Engn, Jamshedpur 831014, Bihar, India.
EM rrsuman.cse@nitjsr.ac.in; bhaskar.cs@nitp.ac.in
RI Mondal, Dr. Bhaskar/Q-6376-2018
OI Mondal, Dr. Bhaskar/0000-0001-6863-9183
CR Broumandnia A, 2019, FUTURE GENER COMP SY, V99, P489, DOI 10.1016/j.future.2019.04.005
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Elashry IF, 2020, MULTIMED TOOLS APPL, V79, P20665, DOI 10.1007/s11042-019-08322-5
   Essaid M, 2019, J INF SECUR APPL, V47, P173, DOI 10.1016/j.jisa.2019.05.006
   Gueron S., 2011, Proceedings of the 2011 Eighth International Conference on Information Technology: New Generations (ITNG), P354, DOI 10.1109/ITNG.2011.69
   Hasheminejad A, 2019, OPTIK, V184, P205, DOI 10.1016/j.ijleo.2019.03.065
   Kamrani A, 2020, MULTIMED TOOLS APPL, V79, P20263, DOI 10.1007/s11042-020-08879-6
   Lee WK, 2018, NONLINEAR DYNAM, V92, P575, DOI 10.1007/s11071-018-4076-6
   Li HJ, 2021, MULTIMED TOOLS APPL, V80, P8721, DOI 10.1007/s11042-020-10117-y
   Liu Y, 2020, MULTIMED TOOLS APPL, V79, P21579, DOI 10.1007/s11042-020-08880-z
   Luo YL, 2019, SIGNAL PROCESS, V161, P227, DOI 10.1016/j.sigpro.2019.03.022
   Luo YQ, 2019, MULTIMED TOOLS APPL, V78, P22023, DOI 10.1007/s11042-019-7453-3
   Mondal B., 2017, ICICCS, P261, DOI [10.15439/2017R47, DOI 10.15439/2017R47]
   Mondal B, 2012, UACEE INT J COMP SCI, V2, P61
   Mondal B, 2020, MULTIMED TOOLS APPL, V79, P17497, DOI 10.1007/s11042-019-08352-z
   Montero-Canela R, 2020, AD HOC NETW, V97, DOI 10.1016/j.adhoc.2019.102005
   Mozaffari S, 2018, MULTIMED TOOLS APPL, V77, P25799, DOI 10.1007/s11042-018-5817-8
   Naskar PK, 2020, NONLINEAR DYNAM, V100, P2877, DOI 10.1007/s11071-020-05625-3
   Nesa N, 2019, J INF SECUR APPL, V47, P320, DOI 10.1016/j.jisa.2019.05.017
   Ping P, 2018, NEUROCOMPUTING, V283, P53, DOI 10.1016/j.neucom.2017.12.048
   Rayappan D, 2021, WIREL NETW, V27, P981, DOI 10.1007/s11276-020-02486-x
   Shoukat IA, 2020, ARAB J SCI ENG, V45, P11019, DOI 10.1007/s13369-020-04919-3
   Sui LS, 2019, OPT LASER ENG, V122, P113, DOI 10.1016/j.optlaseng.2019.06.005
   Talhaoui MZ, 2021, VISUAL COMPUT, V37, P541, DOI 10.1007/s00371-020-01822-8
   Valandar MY, 2019, OPTIK, V193, DOI 10.1016/j.ijleo.2019.06.021
   Xiang HY, 2020, MULTIMED TOOLS APPL, V79, P30329, DOI 10.1007/s11042-020-09595-x
   Zhang J, 2019, MULTIMED TOOLS APPL, V78, P15605, DOI 10.1007/s11042-018-6973-6
   Zhang L, 2020, MULTIMED TOOLS APPL, V79, P20753, DOI 10.1007/s11042-020-08835-4
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 29
TC 17
Z9 17
U1 2
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27089
EP 27110
DI 10.1007/s11042-021-11460-4
EA JAN 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000740429700013
DA 2024-07-18
ER

PT J
AU Chatterjee, R
   Chatterjee, A
   Islam, SKH
AF Chatterjee, Rajdeep
   Chatterjee, Ankita
   Islam, S. K. Hafizul
TI Deep learning techniques for observing the impact of the global warming
   from satellite images of water-bodies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Detectron2; Global warming; Instance segmentation;
   Water-body
ID LAKES
AB Global warming is a threat to modern human civilization. There are different reasons for speed up the global average temperature. The consequences are catastrophic for human existence. Seafloor rise, drought, flood, wildfire, dry riverbed are some of the consequences. This paper analyzes the changes in boundaries of different water bodies such as fresh-water lakes and glacial lakes. Over time, the area covered by a water body has been varied due to human interventions or natural causes. Here, variants of Detectron2 instance segmentation architectures have been employed to detect a water-body and compute the changes in its area from the time-lapsed images captured over 32 years, that is, 1984 to 2016. The models are validated using water-bodies images taken by the Sentinel-2 Satellite and compared based on the average precision (AP), 99.95 and 94.51 at AP(50) and AP(75) metrics, respectively. In addition, an ensemble approach has also been introduced for the efficient identification of shrinkage or expansion of water bodies.
C1 [Chatterjee, Rajdeep] KIIT Deemed Univ, Sch Comp Engn, Bhubaneswar 751024, Odisha, India.
   [Chatterjee, Ankita] Indian Inst Technol Bhubaneswar, Sch Elect Sci, Khordha 752050, Odisha, India.
   [Islam, S. K. Hafizul] Indian Inst Informat Technol, Dept Comp Sci & Engn, Kalyani 741235, W Bengal, India.
C3 Kalinga Institute of Industrial Technology (KIIT); Indian Institute of
   Technology System (IIT System); Indian Institute of Technology (IIT) -
   Bhubaneswar
RP Islam, SKH (corresponding author), Indian Inst Informat Technol, Dept Comp Sci & Engn, Kalyani 741235, W Bengal, India.
CR [Anonymous], 2018, SHRINKING ARAL SEA
   [Anonymous], 2016, BOLIVIAS LAKE POOPO
   [Anonymous], 2020, ADABELIEF OPTIMIZER
   [Anonymous], 2020, DETECTRON2 MODEL ZOO
   [Anonymous], 2020, DETECTRON2
   [Anonymous], 2020, KAGGLE SENTINEL 2 SA
   [Anonymous], 2014, LAKE MEAD STILL SHRI
   [Anonymous], 2016, LANDSAT TOP 10 A SHR
   [Anonymous], 2016, DEAD SEA DRYING NEW
   [Anonymous], 2017, DRYING LAKES CLIMATE
   Barthakur M, 2020, LECT NOTE DATA ENG, V32, P79, DOI 10.1007/978-3-030-25797-2_4
   Bates B., 2008, Technical Paper of the Intergovernmental Panel on Climate Change, DOI DOI 10.1029/90EO00112
   Bolya D, 2022, IEEE T PATTERN ANAL, V44, P1108, DOI 10.1109/TPAMI.2020.3014297
   Bolya D, 2019, IEEE I CONF COMP VIS, P9156, DOI 10.1109/ICCV.2019.00925
   Chen YW, 2013, QUATERNARY RES, V80, P189, DOI 10.1016/j.yqres.2013.06.008
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dhyakesh S, 2020, 2 EAI INT C BIG DAT, P301
   Ghosh S, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3329784
   Gross Michael, 2017, WORLDS VANISHING LAK
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hosang J, 2017, PROC CVPR IEEE, P6469, DOI 10.1109/CVPR.2017.685
   Khryashchev V., 2020, 2020 MOSC WORKSH EL, P1, DOI [10.1109/MWENT47943.2020.9067475, DOI 10.1109/MWENT47943.2020.9067475]
   Kirillov A, 2019, PROC CVPR IEEE, P6392, DOI 10.1109/CVPR.2019.00656
   Kirillov A, 2019, PROC CVPR IEEE, P9396, DOI 10.1109/CVPR.2019.00963
   Lu X., 2020, ECCV, V12348, P661, DOI DOI 10.1007/978-3-030-58580-8_39
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Minaee S., 2020, ARXIV200105566
   Mooij WM, 2005, AQUAT ECOL, V39, P381, DOI 10.1007/s10452-005-9008-0
   NASA Global Climate Change, 2019, VIT SIGNS PLAN
   Padilla R, 2020, INT CONF SYST SIGNAL, P237, DOI [10.1109/IWSSIP48289.2020.9145130, 10.1109/iwssip48289.2020.9145130]
   Revaud J, 2019, IEEE I CONF COMP VIS, P5106, DOI 10.1109/ICCV.2019.00521
   Shugar DH, 2020, NAT CLIM CHANGE, V10, P939, DOI 10.1038/s41558-020-0855-4
   Tatikonda Sekhar, 2020, C NEUR INF PROC SYST
   Wu M, 2019, IEEE ACCESS, V7, P55609, DOI 10.1109/ACCESS.2019.2913442
   Wu Y, 2019, GIRSHICK R DETECTRON
NR 35
TC 3
Z9 3
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6115
EP 6130
DI 10.1007/s11042-021-11811-1
EA JAN 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000739790800008
PM 35018130
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Guo, F
   Ren, QQ
   Tang, J
   Li, ZY
AF Guo, Fan
   Ren, Qingquan
   Tang, Jin
   Li, Zhiyong
TI Dilated Multi-scale Fusion for Point Cloud Classification and
   Segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Point cloud feature; Classification; Segmentation; Dilated KNN;
   Multi-scale fusion
AB We propose a novel network called Dilated Multi-Scale Fusion network (DMSF) for point cloud analysis in this paper. The network aims to integrate different scales to enhance the feature of point cloud, and each scale feature is obtained by Dilated K - Nearest Neighbor (DKNN) operation, which significantly enhances the size of the receptive field of point cloud. Experimental results show that compared with other state-of-art methods, the proposed network can obtain comparable or even better results in the representative public dataset for point cloud classification and segmentation tasks. Specifically, the oAcc reached 93.6 on the ModelNet40 classification dataset, and the mIoU reached 67.2 on the S3DIS segmentation dataset.
C1 [Guo, Fan; Ren, Qingquan; Tang, Jin; Li, Zhiyong] Cent South Univ, Sch Automat, Changsha 410083, Peoples R China.
C3 Central South University
RP Li, ZY (corresponding author), Cent South Univ, Sch Automat, Changsha 410083, Peoples R China.
EM lizy@csu.edu.cn
RI li, zy/HZM-1892-2023
FU Science & Technology innovation system for Military Commission of the
   Communist Party Central Committee of China [193-A11-10311-07,
   193-A11-103-11-04]
FX This work was supported by the Science & Technology innovation system
   for Military Commission of the Communist Party Central Committee of
   China under grant agreement no. 193-A11-10311-07 and 193-A11-103-11-04.
CR [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   [Anonymous], 2017, Understanding the effective receptive field in deep convolutional neural networks
   [Anonymous], 2016, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, DOI [DOI 10.1109/CVPR.2016.170, 10.1109/CVPR.2016.170]
   Bello SA, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12111729
   Chen Chun-Fu, 2019, P INT C LEARN REPR
   Chen L, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3278067
   Chen Lin-Zhuo, 2019, ARXIV PREPRINT ARXIV
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Jacobsen JH, 2016, PROC CVPR IEEE, P2610, DOI 10.1109/CVPR.2016.286
   Jiang M., 2018, ARXIV180700652
   Landrieu L, 2018, PROC CVPR IEEE, P4558, DOI 10.1109/CVPR.2018.00479
   Li JX, 2018, PROC CVPR IEEE, P9397, DOI 10.1109/CVPR.2018.00979
   Li YY, 2018, ADV NEUR IN, V31
   Lin YQ, 2020, PROC CVPR IEEE, P4292, DOI 10.1109/CVPR42600.2020.00435
   Liu XH, 2019, AAAI CONF ARTIF INTE, P8778
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Minar MR., 2018, Recent Advances in Deep Learning: An Overview, DOI DOI 10.13140/RG.2.2.24831.10403
   Pang S, METHODS
   Qi C., 2017, NeurIPS, P5105, DOI [10.1109/ CVPR.2017.16, DOI 10.1109/CVPR.2017.16]
   Riegler G, 2017, PROC CVPR IEEE, P6620, DOI 10.1109/CVPR.2017.701
   Shi ZJ, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.102977
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Won CS, 2020, IEEE ACCESS, V8, P116663, DOI 10.1109/ACCESS.2020.3005150
   Wu WX, 2019, PROC CVPR IEEE, P9613, DOI 10.1109/CVPR.2019.00985
   Yu F., 2017, PROC CVPR IEEE, P472, DOI [DOI 10.1109/CVPR.2017.75, 10.1109/CVPR.2017.75]
   Zhang ZY, 2019, IEEE I CONF COMP VIS, P1607, DOI 10.1109/ICCV.2019.00169
   Zhu H, 2021, IEEE INT CONF ROBOT, P1488, DOI 10.1109/ICRA48506.2021.9561963
NR 29
TC 6
Z9 6
U1 4
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6069
EP 6090
DI 10.1007/s11042-021-11825-9
EA JAN 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000739790800003
DA 2024-07-18
ER

PT J
AU Jayavarthini, C
   Malathy, C
AF Jayavarthini, C.
   Malathy, C.
TI Deep convolution neural network with context based expanded
   neighbourhoods distance re-ranking model for person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Deep learning; Similarity measurement;
   Expanded neighbourhood re-ranking process; DenseNet
AB Presently, Person Re-Identification (PRe-ID) acts as a vital part of real time video surveillance to ensure the rising need for public safety. Resolving the PRe-ID problem includes the process of matching observations of persons among distinct camera views. Earlier models consider PRe-ID as a unique object retrieval issue and determine the retrieval results mainly based on the unidirectional matching among the probe and gallery images. But the accurate matching might not present in the top-k ranking results owing to the appearance modifications caused by the difference in illumination, pose, viewpoinst, and occlusion. For addressing these issues, this paper presents new deep learning (DL) with expanded neighbourhood distance reranking (DL-ENDR) model for PRe-ID. The proposed DL-ENDR involves different processes for PRe-ID, such as feature extraction, similarity measurement, and feature re-ranking. The DL-ENDR model uses a Densely Connected Convolutional Networks (DenseNet169) model as a feature extractor. Additionally, Euclidean distance-based similarity measurement is employed to determine the resemblance between the probe and gallery images. Finally, the DL-ENDR model incorporated ENDR model to re-rank the outcome of the person-reidentification along with Mahala Nobis distance. An extensive experimental analysis takes place on benchmark dataset and the obtained results verified the effective performance of the DL-ENDR model interms of different aspects.
C1 [Jayavarthini, C.; Malathy, C.] SRM Inst Sci & Technol, Sch Comp, Dept Comp Sci & Engn, Chennai 603203, Tamil Nadu, India.
C3 SRM Institute of Science & Technology Chennai
RP Jayavarthini, C (corresponding author), SRM Inst Sci & Technol, Sch Comp, Dept Comp Sci & Engn, Chennai 603203, Tamil Nadu, India.
EM jayavarthini8800@gmail.com
CR [Anonymous], 2009, Applications of Computer Vision (WACV), 2009 Workshop on
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Chen K, 2021, ARXIV PREPRINT ARXIV, P1, DOI DOI 10.1061/(ASCE)EY.1943-7897.0000804
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Hu Y, 2015, LECT NOTES COMPUT SC, V9010, P650, DOI 10.1007/978-3-319-16634-6_47
   Karanam S, 2019, IEEE T PATTERN ANAL, V41, P523, DOI 10.1109/TPAMI.2018.2807450
   Kowsari K, 2020, INFORMATION, V11, DOI 10.3390/info11060318
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li W., 1936, P IEEE C COMPUTER VI, P152
   Lv JY, 2020, IMAGE VISION COMPUT, V95, DOI 10.1016/j.imavis.2020.103875
   Varior RR, 2016, LECT NOTES COMPUT SC, V9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Wang JY, 2018, PROC CVPR IEEE, P2275, DOI 10.1109/CVPR.2018.00242
   Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010
   Wei L, 2015, AAAI CONF ARTIF INTE, P1882
   Wu WY, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107424
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
NR 19
TC 1
Z9 1
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5957
EP 5971
DI 10.1007/s11042-021-11795-y
EA JAN 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000737741900012
DA 2024-07-18
ER

PT J
AU Marín-Vega, H
   Alor-Hernández, G
   Colombo-Mendoza, LO
   Bustos-López, M
   Zataraín-Cabada, R
AF Marin-Vega, Humberto
   Alor-Hernandez, Giner
   Omar Colombo-Mendoza, Luis
   Bustos-Lopez, Maritza
   Zatarain-Cabada, Ramon
TI ZeusAR: a process and an architecture to automate the development of
   augmented reality serious games
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality serious game; Software process
ID EDUCATION; TOOL; CHALLENGES; FRAMEWORK; DESIGN
AB A software development process comprises all the steps necessary to produce a software product. This research proposes a new process for developing augmented reality serious games (ARSGs), which comprises three phases: analysis, configuration, and generation. The analysis phase involves examining the standard project structure of a typical serious game to identify the applicable actions to which AR content can be added. The configuration phase involves configuring the AR features and the AR library to be integrated into the game structure. Finally, the generation phase entails inserting the AR code in the game structure, as well as all the files necessary to in-corporate AR features in the game. Our process allows generating ARSGs step by step, both easily and rapidly. To implement this process, we propose an ARSG development software architecture. The underlying assumption of this architecture is that software development tools are essential validation elements of the software generation process. By implementing our ARSG development process through a software architecture, we provide users with a formal, automated method for creating ARSGs. The ARSG development process and the architecture, collectively called ZeusAR, are not dependent on specific software development technologies and/or programming languages. To perform a proof-of-concept of our process, we developed an ARSG generator tool based on the proposed architecture and conducted a case study in which geometry ARSGs are developed to help high school students learn about geometric shapes and their properties. We conducted a qualitative evaluation of the ZeusAR tool through a System-Usability-Scale (SUS) based survey, which was administered to a group of geometry teachers to evaluate the tool's characteristics, such as ease of use and ease of configuration. Additionally, a group of software developers and professors assessed the performance of the ZeusAR tool in terms of game development time.
C1 [Marin-Vega, Humberto] Tecnol Nacl Mexico, ITS Zongolica, Zongolica, Mexico.
   [Alor-Hernandez, Giner] Tecnol Nacl Mexico, IT Orizaba, Orizaba, Mexico.
   [Omar Colombo-Mendoza, Luis] Tecnol Nacl Mexico, ITS Teziutlan, Teziutlan, Mexico.
   [Bustos-Lopez, Maritza] Univ Veracruzana, Ctr Invest Inteligencia Artificial, Xalapa, Veracruz, Mexico.
   [Zatarain-Cabada, Ramon] Tecnol Nacl Mexico, IT Culiacan, Culiacan Rosales, Mexico.
C3 Universidad Veracruzana
RP Alor-Hernández, G (corresponding author), Tecnol Nacl Mexico, IT Orizaba, Orizaba, Mexico.
EM humberto_marin_pd177@zongolica.tecnm.mx; galorh@orizaba.tecnm.mx;
   luis.cm@teziutlan.tecnm.mx; maritbustos@gmail.com;
   rzatarain@itculiacan.edu.mx
RI Cabada, Ramón Zatarain/L-5729-2019; Alor-Hernandez, Giner/U-9203-2017
OI Cabada, Ramón Zatarain/0000-0002-4524-3511; Alor-Hernandez,
   Giner/0000-0003-3296-0981
CR Akçayir M, 2017, EDUC RES REV-NETH, V20, P1, DOI 10.1016/j.edurev.2016.11.002
   Arango-López J, 2019, TELEMAT INFORM, V38, P62, DOI 10.1016/j.tele.2018.08.005
   Avila-Pesantez D, 2018, IEEE GLOB ENG EDUC C, P843, DOI 10.1109/EDUCON.2018.8363318
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Barroso J., 2016, INT J TECHNOLOGY ED, V2, P77, DOI [10.20548/innoeduca.2016.v2i2.1955, DOI 10.20548/INNOEDUCA.2016.V2I2.2028]
   Bass Len, 2012, SEI S SOFTW
   Bekebrede G, 2011, COMPUT EDUC, V57, P1521, DOI 10.1016/j.compedu.2011.02.010
   Bower M, 2014, EDUC MEDIA INT, V51, P1, DOI 10.1080/09523987.2014.889400
   Charsky D, 2010, GAMES CULT, V5, P177, DOI 10.1177/1555412009354727
   Checa D, 2020, MULTIMED TOOLS APPL, V79, P5501, DOI 10.1007/s11042-019-08348-9
   DASH AK, 2018, DISPLAYS
   El Sayed NAM, 2011, COMPUT EDUC, V56, P1045, DOI 10.1016/j.compedu.2010.10.019
   ELEFTHERIA CA, 2013, IISA 2013, P70
   Emmerich F, 2017, LECT NOTES COMPUT SC, V10653, P161, DOI 10.1007/978-3-319-71940-5_15
   Fazel A, 2018, AUTOMAT CONSTR, V85, P135, DOI 10.1016/j.autcon.2017.10.015
   Gu J, 2011, HANDBOOK OF AUGMENTED REALITY, P99, DOI 10.1007/978-1-4614-0064-6_4
   Herbert B, 2018, COMPUT GRAPH-UK, V77, P166, DOI 10.1016/j.cag.2018.09.017
   Jordan P.W., 1996, Usability Evaluation in Industry, DOI DOI 10.1201/9781498710411
   Juul J., 2005, HALF REAL VIDEO GAME
   Kitchenham B, 1997, INFORM SOFTWARE TECH, V39, P731, DOI 10.1016/S0950-5849(97)00024-4
   Kitchenham B., 2004, PROCEDURES PERFORMIN, V33, P1
   Klimova A, 2018, PROCEDIA COMPUT SCI, V136, P5, DOI 10.1016/j.procs.2018.08.232
   Klopfer E., 2008, AUGMENTED LEARNING R, DOI 10.7551/mitpress/9780262113151.001.0001
   Laine TH, 2016, ETR&D-EDUC TECH RES, V64, P507, DOI 10.1007/s11423-015-9419-0
   Lameras P, 2017, BRIT J EDUC TECHNOL, V48, P972, DOI 10.1111/bjet.12467
   Liarokapis F, 2009, LOOKING FUTURE TECHN, P178
   Liarokapis F, 2009, PROCEEDINGS OF THE IEEE VIRTUAL WORLDS FOR SERIOUS APPLICATIONS, P148, DOI 10.1109/VS-GAMES.2009.40
   López-Faican L, 2020, COMPUT EDUC, V149, DOI 10.1016/j.compedu.2020.103814
   Maia LF, 2017, ENTERTAIN COMPUT, V22, P3, DOI 10.1016/j.entcom.2017.05.001
   MARINVEGA H, 2019, IET SOFTW
   McCallum Simon, 2013, Stud Health Technol Inform, V189, P139
   Noor N.M., 2018, COMMUN COMPUT PHYS, P163, DOI [10.1007/978-981-13-1628-9_15, DOI 10.1007/978-981-13-1628-9_15]
   Colombo-Mendoza LO, 2014, AUTOMAT SOFTW ENG, V21, P391, DOI 10.1007/s10515-014-0143-5
   Perez Diaz, 2016, EDUTEC REV ELECT TEC, DOI 10.21556/edutec.2016.57.768
   Perez-Colado VM, 2017, P 5 INT C TECHN EC E
   Perry B, 2015, PROCD SOC BEHV, V174, P2308, DOI 10.1016/j.sbspro.2015.01.892
   Rauschnabel PA, 2017, COMPUT HUM BEHAV, V76, P276, DOI 10.1016/j.chb.2017.07.030
   Rosenbaum E., 2007, Journal of Science Education and Technology, V16, P31, DOI DOI 10.1007/S10956-006-9036-0
   Rugelj J, 2016, L N INST COMP SCI SO, V161, P94, DOI 10.1007/978-3-319-29060-7_15
   Ruminski D, 2020, GRAPH MODELS, V107, DOI 10.1016/j.gmod.2019.101027
   Sannikov S, 2015, PROCEDIA COMPUT SCI, V66, P720, DOI 10.1016/j.procs.2015.11.082
   Sauro J., 2011, MeasuringU
   Sood SK, 2018, COMPUT APPL ENG EDUC, V26, P1565, DOI 10.1002/cae.21965
   Sotiriou S, 2008, ADV SCI LETT, V1, P114, DOI 10.1166/asl.2008.012
   Tabuenca B, 2016, UNIVERSAL ACCESS INF, V15, P329, DOI 10.1007/s10209-014-0391-y
   Tsai CH, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/498560
   Vidal ECE, 2019, INTERACT LEARN ENVIR, V27, P895, DOI 10.1080/10494820.2018.1504305
   Wu HK, 2013, COMPUT EDUC, V62, P41, DOI 10.1016/j.compedu.2012.10.024
   Young J. C., 2018, User Science and Engineering. i-USEr 2018, V886, DOI [10.1007/978-981-13-1628-9_20, DOI 10.1007/978-981-13-1628-9_20]
   Zsila A, 2018, PERS INDIV DIFFER, V133, P56, DOI 10.1016/j.paid.2017.06.024
NR 50
TC 4
Z9 4
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2901
EP 2935
DI 10.1007/s11042-021-11695-1
EA NOV 2021
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000716240000002
DA 2024-07-18
ER

PT J
AU Singh, A
   Dutta, MK
AF Singh, Abhilasha
   Dutta, Malay Kishore
TI An integrity control system for retinal images based on watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image watermarking; Integrity control; Retinal images; Retinal
   images; Tele-ophthalmology
ID REVERSIBLE WATERMARKING; MEDICAL IMAGES; SCHEME; AUTHENTICATION
AB In telemedicine, images may possibly be tailored deliberately or unintentionally as this transmission may occur all the way through vulnerable networks. Prior to making any investigative judgment, the integrity of watermarked medical image has to be validated by the medical practitioner so as to avoid erroneous verdict. An approach that can be used to verify the integrity of medical images is digital watermarking. This paper proposes a watermarking algorithm which conforms to all unique requirements of medical image watermarking viz. complete restoration of original cover image after watermark extraction, vital parts being not tampered at all and lossless watermarking. Unique blood vessel pattern in vicinity of optic disk is strategically combined with patient ID to create secret share. Reversible watermarking has been used to embed secret share in Region of Non-Interest (RONI). High values of PSNR (greater than 69 dB) and SSIM have been achieved which imply that the algorithm is highly imperceptible in nature. Proposed system protects the image without modifying its most vital components, and permits the total restoration of the original image with verification of its authenticity and integrity. Unique Feature Extraction makes the proposed algorithm suitable for the purpose of distinctive identification of medical images during transmission and storage in large distributed databases along with enhanced security and confidentiality in tele-ophthalmological applications.
C1 [Singh, Abhilasha] Amity Univ, Amity Sch Engn & Technol, Noida, Uttar Pradesh, India.
   [Dutta, Malay Kishore] Dr APJ Abdul Kalam Tech Univ, Ctr Adv Studies, Lucknow, Uttar Pradesh, India.
C3 Amity University Noida; Dr. A.P.J. Abdul Kalam Technical University
   (AKTU); Centre for Advanced Studies (CAS, AKTU)
RP Singh, A (corresponding author), Amity Univ, Amity Sch Engn & Technol, Noida, Uttar Pradesh, India.
EM abhilashasingh28@gmail.com
RI Singh, Abhilasha/AAE-6866-2019
OI Singh, Abhilasha/0000-0002-9482-3141
CR Al-qdah M., 2018, SIGNAL IMAGE PROCESS, DOI 10.5121/sipij.2018.9101
   Al-Qershi O. M., 2010, 2010 IEEE International Conference on Information Theory and Information Security, P151, DOI 10.1109/ICITIS.2010.5688743
   Al-Qershi OM, 2011, J DIGIT IMAGING, V24, P114, DOI 10.1007/s10278-009-9253-1
   Alshanbari HS, 2021, MULTIMED TOOLS APPL, V80, P16549, DOI 10.1007/s11042-020-08814-9
   An LL, 2012, IEEE T IMAGE PROCESS, V21, P3598, DOI 10.1109/TIP.2012.2191564
   Anand A, 2020, COMPUT COMMUN, V152, P72, DOI 10.1016/j.comcom.2020.01.038
   [Anonymous], 2012, INT J MOD ENG RES
   Assini I., 2018, Int. J. Intell. Eng. Syst., V11, P169, DOI [10.22266/ijies2018.0630.18, DOI 10.22266/IJIES2018.0630.18]
   Coatrieux G, 2013, IEEE J BIOMED HEALTH, V17, P1057, DOI 10.1109/JBHI.2013.2263533
   Coatrieux G, 2009, IEEE T INF TECHNOL B, V13, P158, DOI 10.1109/TITB.2008.2007199
   Devi HS, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102424
   Dutta MK, 2015, 2015 38TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P781, DOI 10.1109/TSP.2015.7296372
   DUTTA MK, 2015, COMP M BIO BIO E-IV
   Eswaraiah R, 2015, IET IMAGE PROCESS, V9, P615, DOI 10.1049/iet-ipr.2014.0986
   Fallahpour M, 2011, IET IMAGE PROCESS, V5, P190, DOI 10.1049/iet-ipr.2009.0226
   Furon T, 2007, IEEE T INF FOREN SEC, V2, P149, DOI 10.1109/TIFS.2007.897272
   Gangadhar Y, 2018, BIOMED SIGNAL PROCES, V43, P31, DOI 10.1016/j.bspc.2018.02.007
   Ganguly S, 2015, 2014 INTERNATIONAL CONFERENCE ON MEDICAL IMAGING, M-HEALTH & EMERGING COMMUNICATION SYSTEMS (MEDCOM), P91
   Giakoumaki A, 2006, IEEE T INF TECHNOL B, V10, P722, DOI 10.1109/TITB.2006.875655
   Golestani HB, 2013, IET IMAGE PROCESS, V7, P733, DOI 10.1049/iet-ipr.2013.0086
   Guo XT, 2009, J DIGIT IMAGING, V22, P620, DOI 10.1007/s10278-008-9120-5
   Han B., 2013, International Journal of Signal Processing, Image Processing and Pattern Recognition, V6, P245
   Hill RB, 1978, Patent, Patent No. [US4109237, 4109237]
   Kalantari NK, 2010, IEEE T CIRC SYST VID, V20, P396, DOI 10.1109/TCSVT.2009.2035842
   Kundu M. K., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1457, DOI 10.1109/ICPR.2010.360
   Kurniawan MT, 2012, 2012 2ND INTERNATIONAL CONFERENCE ON UNCERTAINTY REASONING AND KNOWLEDGE ENGINEERING (URKE), P145, DOI 10.1109/URKE.2012.6319530
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Lin Gao, 2012, Proceedings of the 2012 International Conference on Wavelet Analysis and Pattern Recognition (ICWAPR), P33, DOI 10.1109/ICWAPR.2012.6294751
   Luo AW, 2020, MULTIMED TOOLS APPL, V79, P243, DOI 10.1007/s11042-019-08074-2
   Moosazadeh M, 2019, J INF SECUR APPL, V47, P28, DOI 10.1016/j.jisa.2019.04.001
   Pei SC, 2003, IEEE T CIRC SYST VID, V13, P867, DOI 10.1109/TCSVT.2003.815943
   Poonkuntran S, 2014, MULTIMED TOOLS APPL, V68, P79, DOI 10.1007/s11042-012-1227-5
   Rahimi F, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-53
   Rai A, 2017, MULTIMED TOOLS APPL, V76, P18605, DOI 10.1007/s11042-016-4215-3
   Rocek A, 2016, BIOMED SIGNAL PROCES, V29, P44, DOI 10.1016/j.bspc.2016.05.005
   Singh Abhilasha, 2014, 2014 International Conference on Medical Imaging, m-Health and Emerging Communication Systems (MedCom), P230, DOI 10.1109/MedCom.2014.7006009
   Singh AK, 2019, MULTIMED TOOLS APPL, V78, P30523, DOI 10.1007/s11042-018-7115-x
   Singh A, 2020, J KING SAUD UNIV-COM, V32, P895, DOI 10.1016/j.jksuci.2017.12.008
   Singh A, 2017, INT J E-HEALTH MED C, V8, P38, DOI 10.4018/IJEHMC.2017070103
   Singh A, 2016, INT C ULTRA MOD TELE, P408, DOI 10.1109/ICUMT.2016.7765394
   Singh A, 2016, INT J ELECTRON SECUR, V8, P392, DOI 10.1504/IJESDF.2016.079452
   Singh A, 2016, COMPUT METH PROG BIO, V135, P61, DOI 10.1016/j.cmpb.2016.07.011
   Viswanathan P, 2014, IEEE J BIOMED HEALTH, V18, P753, DOI 10.1109/JBHI.2013.2281322
   Zhang B, 2010, COMPUT BIOL MED, V40, P438, DOI 10.1016/j.compbiomed.2010.02.008
   Zhou NR, 2019, MULTIMED TOOLS APPL, V78, P2507, DOI 10.1007/s11042-018-6322-9
   Zhou NR, 2018, MULTIMED TOOLS APPL, V77, P30251, DOI 10.1007/s11042-018-6128-9
NR 47
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2429
EP 2452
DI 10.1007/s11042-021-11600-w
EA OCT 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000712196600001
DA 2024-07-18
ER

PT J
AU Singh, S
   Tripathi, BK
AF Singh, Sukhendra
   Tripathi, B. K.
TI Pneumonia classification using quaternion deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Convolution neural network; Computer aided detection and
   diagnosis; Quaternion convolution neural network; Residual network; High
   dimensional neural network
ID CONVOLUTIONAL NEURAL-NETWORKS
AB Pneumonia is an infection in one or both the lungs because of virus or bacteria through breathing air. It inflames air sacs in lungs which fill with fluid which further leads to problems in respiration. Pneumonia is interpreted by radiologists by observing abnormality in lungs in case of fluid in Chest X-Rays. Computer Aided Detection Diagnosis (CAD) tools can assist radiologists by improving their diagnostic accuracy. Such CAD tools use neural networks which are trained on Chest X-Ray dataset to classify a Chest X-Ray into normal or infected with Pneumonia. Convolution neural networks have shown remarkable performance in object detection in an image. Quaternion Convolution neural network (QCNN) is a generalization of conventional convolution neural networks. QCNN treats all three channels (R, G, B) of color image as a single unit and it extracts better representative features and which further improves classification. In this paper, we have trained Quaternion residual network on a publicly available large Chest X-Ray dataset on Kaggle repository and obtained classification accuracy of 93.75% and F-score of .94. We have also compared our performance with other CNN architectures. We found that classification accuracy was higher with Quaternion Residual network when we compared it with a real valued Residual network.
C1 [Singh, Sukhendra] JSS Acad Tech Educ, Noida, India.
   [Tripathi, B. K.] Harcourt Butler Technol Univ Kanpur, Kanpur, Uttar Pradesh, India.
C3 Harcourt Butler Technical University (HBTU)
RP Singh, S (corresponding author), JSS Acad Tech Educ, Noida, India.
EM sukhendrasingh@gmail.com; abkt.iitk@gmail.com
RI Singh, Sukhendra/W-7248-2018
OI Singh, Sukhendra/0000-0001-7980-9889
CR ABUBAKAR A, 2020, APPL SYST INNOV
   Agarwal R, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.3.031409
   Aizenberg I, 2011, STUD COMPUT INTELL, V353, P1, DOI 10.1007/978-3-642-20353-4
   ALBAHLI S, 2020, J XRAY SCI TECHNOL
   [Anonymous], 2017, INT J INTELL ENG SYS, DOI DOI 10.22266/IJIES2017.0831.22
   Babu RV, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2803, DOI 10.1109/IJCNN.2011.6033588
   Clevert D., 2016, ARXIV151107289
   Comminiello D, 2019, INT CONF ACOUST SPEE, P8533, DOI [10.1109/icassp.2019.8682711, 10.1109/ICASSP.2019.8682711]
   Ezzat D., 2020, ARXIV PREPRINT ARXIV
   Farag A. T., 2020, MULTICHEXNET MULTITA
   Gabruseva T, 2020, IEEE COMPUT SOC CONF, P1436, DOI 10.1109/CVPRW50498.2020.00183
   Gaudet CJ, 2018, IEEE IJCNN
   Ge ZY, 2020, MULTIMED TOOLS APPL, V79, P14889, DOI 10.1007/s11042-019-08260-2
   Hardt M, 2016, PR MACH LEARN RES, V48
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hirose Akira, 2009, Proceedings 2009 International Joint Conference on Neural Networks (IJCNN 2009 - Atlanta), P1237, DOI 10.1109/IJCNN.2009.5178754
   HUANG G, 2020, CONCURR COMPUT
   Isokawa T., 2009, Quaternionic Neural Networks: Fundamental Properties and Applications, DOI [10.4018/978-1-60566-214-5.ch016, DOI 10.4018/978-1-60566-214-5.CH016]
   Kensert A, 2019, SLAS DISCOV, V24, P466, DOI 10.1177/2472555218818756
   Kermany Daniel, 2018, Mendeley Data, V3
   LAN R, 2016, IEEE T IMAGE PROCESS
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Parcollet T., 2019, INT C LEARN REPR ICL, P1
   Parcollet T., 2018, Quaternion convolutional neural networks for end-to-end automatic speech recognition
   Parcollet T, 2019, INT CONF ACOUST SPEE, P8514, DOI [10.1109/icassp.2019.8682495, 10.1109/ICASSP.2019.8682495]
   Rajpurkar P, 2017, Arxiv, DOI arXiv:1711.05225
   Shaha Manali, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P656, DOI 10.1109/ICECA.2018.8474802
   SHALLU M, 2018, ICT EXPRESS
   Simonyan K, 2015, VGGNET 3 INT C LEARN
   Szegedy C., 2013, Advances in Neural Information Processing Systems, V26, P2553
   Tripathi, 2015, COMPUT INTELL-US, V571, P79
   Tripathi BK, 2010, STUD COMPUT INTELL, V275, P215
   Turkoglu M, 2019, J AMB INTEL HUM COMP, DOI 10.1007/s12652-019-01591-w
   ul Hassan M, 2018, Neurohive
   Van Hieu N, 2020, INT J EMERG TECHNOL
   Vince J, 2009, GEOMETRIC ALGEBRA: AN ALGEBRAIC SYSTEM FOR COMPUTER GAMES AND ANIMATION, P1
   Wu Y, 2019, J COMPUT BIOL, V26, P1203, DOI 10.1089/cmb.2018.0139
   Zhang J, 2020, INT J BEHAV MED, V27, P400, DOI [10.1007/s40684-020-00268-6, 10.1007/s12529-020-09863-y]
   Zhu XY, 2018, LECT NOTES COMPUT SC, V11212, P645, DOI 10.1007/978-3-030-01237-3_39
NR 39
TC 24
Z9 24
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 1743
EP 1764
DI 10.1007/s11042-021-11409-7
EA OCT 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000706547800001
PM 34658656
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Guha, R
   Alam, I
   Bera, SK
   Kumar, N
   Sarkar, R
AF Guha, Ritam
   Alam, Imran
   Bera, Suman Kumar
   Kumar, Neeraj
   Sarkar, Ram
TI Enhancement of image contrast using Selfish Herd Optimizer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image contrast enhancement; Selfish Herd Optimizer; Meta-heuristic;
   Transformation function; Evolutionary algorithm; Kodak dataset; H-DIBCO
   2018
ID ARTIFICIAL BEE COLONY; ALGORITHM
AB Contrast enhancement is an important pre-processing task in any Image Analysis (IA) system. In this paper, we formulate the image contrast enhancement problem as an optimization problem where the goal is to optimize the pixel intensity values of an input image to obtain a contrast enhanced version of the same. This optimization task is executed by suitably customizing a nature-inspired optimization algorithm called Selfish Herd Optimizer (SHO). The optimization problem is solved using two different solution representations: pixel wise optimization (SHO(direct)) and transformation function based optimization (SHO(transformation)). Moreover, an ablation study is performed to select the most appropriate parameters which can be used in fitness measure for this optimization problem. On experimenting over the popular Kodak image dataset, it has been observed that the proposed methods outperform many existing methods published recently. Further comparisons indicate that the direct approach performs better than its transformation counterpart. This paper further investigates the robustness of SHO(direct) approach by applying it to enhance the degraded document images of H-DIBCO 2018.
C1 [Guha, Ritam; Alam, Imran; Bera, Suman Kumar; Sarkar, Ram] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
   [Kumar, Neeraj] Univ Petr & Energy Studies, Sch Comp Sci, Dehra Dun, Uttarakhand, India.
   [Kumar, Neeraj] Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
   [Kumar, Neeraj] Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Patiala, Punjab, India.
C3 Jadavpur University; University of Petroleum & Energy Studies (UPES);
   Asia University Taiwan; Thapar Institute of Engineering & Technology
RP Guha, R (corresponding author), Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
EM ritamguha16@gmail.com; imranalam5555@gmail.com; berasuman007@gmail.com;
   neeraj.kumar@thapar.edu; ramjucse@gmail.com
RI Sarkar, Ram/AAX-3822-2020; Guha, Ritam/JGC-9425-2023; Kumar,
   Neeraj/L-3500-2016
OI Sarkar, Ram/0000-0001-8813-4086; Kumar, Neeraj/0000-0002-3020-3947;
   Guha, Ritam/0000-0002-1375-777X
CR Agrawal S, 2012, LECT NOTES COMPUT SC, V7677, P82, DOI 10.1007/978-3-642-35380-2_11
   Akay B, 2015, SIGNAL IMAGE VIDEO P, V9, P967, DOI 10.1007/s11760-015-0758-4
   [Anonymous], 2015, INT J APPL ENG RES
   Bao P, 2005, IEEE T PATTERN ANAL, V27, P1485, DOI 10.1109/TPAMI.2005.173
   Bhardwaj S, 2012, PROC TECH, V4, P220, DOI 10.1016/j.protcy.2012.05.033
   Chen J, 2018, SWARM EVOL COMPUT, V38, P287, DOI 10.1016/j.swevo.2017.09.002
   Daniel E, 2016, COMPUT BIOL MED, V71, P149, DOI 10.1016/j.compbiomed.2016.02.011
   Deborah H., 2010, 2010 Proceedings of Second International Conference on Advances in Computing, Control and Telecommunication Technologies (ACT 2010), P108, DOI 10.1109/ACT.2010.24
   Draa A, 2014, SWARM EVOL COMPUT, V16, P69, DOI 10.1016/j.swevo.2014.01.003
   Franzen R, 1999, Kodak lossless true color image suite
   Gao QQ, 2011, C IND ELECT APPL, P234, DOI 10.1109/ICIEA.2011.5975586
   Ghosh M, 2019, CONTRAST ENHANCEMENT
   Ghosh M, 2020, J INTELL SYST, V29, P1598, DOI 10.1515/jisys-2019-0062
   Ghosh M, 2020, NEURAL COMPUT APPL, V32, P7839, DOI 10.1007/s00521-019-04171-3
   Gong T, 2017, ENG APPL ARTIF INTEL, V62, P405, DOI 10.1016/j.engappai.2016.10.004
   Gu K, 2016, IEEE T CYBERNETICS, V46, P284, DOI 10.1109/TCYB.2015.2401732
   Guha R, 2021, EVOL INTELL, V14, P357, DOI 10.1007/s12065-019-00218-5
   Hashemi S, 2010, PATTERN RECOGN LETT, V31, P1816, DOI 10.1016/j.patrec.2009.12.006
   Joshi P, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON IDENTITY, SECURITY AND BEHAVIOR ANALYSIS (ISBA)
   Kanmani M, 2018, MULTIMED TOOLS APPL, V77, P23371, DOI 10.1007/s11042-018-5650-0
   Kim HJ, 2006, LECT NOTES COMPUT SC, V4319, P1150
   Kittler J., 1983, Image and Vision Computing, V1, P37, DOI [DOI 10.1016/0262-8856(83)90006-9, 10.1016/0262-8856(83)90006-9]
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Ling ZG, 2015, IET IMAGE PROCESS, V9, P1012, DOI 10.1049/iet-ipr.2014.0580
   Lu HP, 2004, IEEE SIGNAL PROC LET, V11, P228, DOI 10.1109/LSP.2003.821748
   Poddar S, 2013, IET IMAGE PROCESS, V7, P641, DOI 10.1049/iet-ipr.2012.0507
   Pratikakis Ioannis, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1547, DOI 10.1109/ICDAR.2019.00249
   Pratikakis I, 2018, INT CONF FRONT HAND, P489, DOI 10.1109/ICFHR-2018.2018.00091
   Russo F, 2004, EURASIP J APPL SIG P, V2004, P1861, DOI 10.1155/S1110865704404041
   Santhi K, 2015, OPTIK, V126, P1809, DOI 10.1016/j.ijleo.2015.05.023
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Singh M, 2017, BIOCYBERN BIOMED ENG, V37, P124, DOI 10.1016/j.bbe.2016.10.006
   Srihari SN, 2006, SECOND INTERNATIONAL CONFERENCE ON DOCUMENT IMAGE ANALYSIS FOR LIBRARIES, PROCEEDINGS, P198, DOI 10.1109/DIAL.2006.17
   Tao L, 2017, IEEE IMAGE PROC, P3215, DOI 10.1109/ICIP.2017.8296876
   Tian J, 2012, IEEE SIGNAL PROC LET, V19, P395, DOI 10.1109/LSP.2012.2197200
   Tian J, 2011, OPT COMMUN, V284, P80, DOI 10.1016/j.optcom.2010.08.085
   TUBBS JD, 1987, PATTERN RECOGN, V20, P617, DOI 10.1016/0031-3203(87)90031-8
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Westphal F, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), P263, DOI 10.1109/DAS.2018.71
   Winkler S, 2008, IEEE T BROADCAST, V54, P660, DOI 10.1109/TBC.2008.2000733
   Wong WJ, 2020, PATTERN RECOGN, V101, DOI 10.1016/j.patcog.2020.107203
   Xue Y, 2018, SOFT COMPUT, V22, P2935, DOI 10.1007/s00500-017-2547-1
   Ye ZW, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/825398
NR 44
TC 7
Z9 7
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 637
EP 657
DI 10.1007/s11042-021-11404-y
EA SEP 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000695787100004
DA 2024-07-18
ER

PT J
AU Silva, TW
   Reis, H
   Melcher, EUK
   Lima, AMN
   Brito, AV
AF Silva, Thiago W.
   Reis, Halamo
   Melcher, Elmar U. K.
   Lima, Antonio M. N.
   Brito, Alisson, V
TI An image generator based on neural networks in GPU
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image generation; GPU; Neural network; Generation by deformation;
   Functional verification
AB Existing image databases contain a few diversity of images. Likewise, there is no specific image base available in other situations, leading to the need to undertake additional efforts in capturing images and creating datasets. Many of these datasets contain only a single object in each image, but often the scenario in which projects must operate in production requires several objects per image. Thus, it is necessary to expand original datasets into more complex ones with specific combinations to achieve the goal of the application. This work proposes a technique for image generation to extend an initial dataset. It has been designed generically to work with various images and create a data set from some initial images. The generated set of images is used in a distributed environment. It is possible to perform image generation in this environment, producing datasets with specific images to work in certain applications. The generation of images consists of two methods: generation by deformation and generation by a neural network. With the proposed methods, this work sought to bring as main contributions the specification and implementation of an image generating component so that it is possible to easily integrate it with possible heterogeneous devices capable of parallel computing, such as General Purpose Graphics Processing Unit (GPGPU). In comparison with the existing methods to the proposed one, this one proposes to use the image generator enlarging an initial image bank with the combination of two methods. Some experiments are presented doing generation with handwritten digits to validate the proposed approach. The generator was designed with CUDA and GPU-optimized libraries as TensorFlow-specific modules. The results obtained can optimize the integration process with the simulation of possible stimuli choices, avoiding problems in the generation of image phase tests.
C1 [Silva, Thiago W.; Melcher, Elmar U. K.; Lima, Antonio M. N.] Fed Univ Campina Grande UFCG, Campina Grande, Paraiba, Brazil.
   [Silva, Thiago W.] Fed Univ Ceara UFC, Quixada, Brazil.
   [Reis, Halamo; Brito, Alisson, V] Fed Univ Paraiba UFPB, Joao Pessoa, Paraiba, Brazil.
C3 Universidade Federal de Campina Grande; Universidade Federal do Ceara;
   Universidade Federal da Paraiba
RP Brito, AV (corresponding author), Fed Univ Paraiba UFPB, Joao Pessoa, Paraiba, Brazil.
EM alisson@ci.ufpb.br
RI Lima, Antonio M. N./F-9201-2014; Brito, Alisson/J-3714-2017
OI Lima, Antonio M. N./0000-0002-4568-9126; Brito,
   Alisson/0000-0001-5215-443X
CR [Anonymous], 2016, LAB SV IMAGENET
   [Anonymous], 2017, IEEE STD 16092A 2017, P1, DOI [DOI 10.1109/IEEESTD.2017.8055462, 10.1109/IEEESTD.2017.8055462]
   [Anonymous], 2018, KHRON GI OPENCL OV
   Balaban, 2018, TITAN RTX DEEP LEARN
   Bhatia N, 2010, Survey of nearest neighbor techniques
   Cohen G, 2017, IEEE IJCNN, P2921, DOI 10.1109/IJCNN.2017.7966217
   Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202
   Delorme Nicolas, 2014, 2014 10th Conference on Ph.D. Research in Microelectronics and Electronics (PRIME), DOI 10.1109/PRIME.2014.6872709
   Dostal, 2018, ANIMALS ATTRIBUTES 2
   Garg ML, DEEP LEARNING PREDIC
   Garris M. D., 1992, Social Science Computer Review, V10, P196
   Hawkins DM, 2004, J CHEM INF COMP SCI, V44, P1, DOI 10.1021/ci0342472
   Horsley Lewis, 2017, 2017 IEEE Conference on Computational Intelligence and Games (CIG), P134, DOI 10.1109/CIG.2017.8080426
   Jaiswal A, HIGH PERFORMANCE PAR
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Lawrence J., 2017, Student-Faculty Res
   Ma Y.Q., 2014, Support vector machines applications, DOI [10.1007/978-3-319-02300-7, DOI 10.1007/978-3-319-02300-7]
   Osadchy M, 2017, IEEE T INF FOREN SEC, V12, P2640, DOI 10.1109/TIFS.2017.2718479
NR 19
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36353
EP 36374
DI 10.1007/s11042-021-11489-5
EA SEP 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000695787100003
DA 2024-07-18
ER

PT J
AU Das, S
   Swain, MK
   Nayak, GK
   Saxena, S
   Satpathy, SC
AF Das, Suchsimita
   Swain, Mahesh ku.
   Nayak, G. K.
   Saxena, Sanjay
   Satpathy, S. C.
TI Effect of learning parameters on the performance of U-Net Model in
   segmentation of Brain tumor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE U-Net; Image Segmentation; Deep Learning; Brain Tumor Segmentation;
   Magnetic Resonance Imaging; Glioma
ID NEURAL-NETWORKS; IMAGE
AB Automatic brain tumor segmentation using several image processing techniques supports early diagnosis and provides useful information for treatment planning. However, due to the heterogeneous nature of brain tumor makes the segmentation process very challenging and exhaustive. Glioma is one type of the fast-growing brain tumors. Its shape, size, and location vary across the patients. Manual extraction of exact glioma from brain MRI (Magnetic Resonance Imaging) is very tricky and time-consuming task for the radiologists. U-Net model is one of the most popular deep learning models for biomedical image segmentation utilized by the researchers and scientists around the world. The up-sampling and down-sampling architecture of U-Net model deliver a remarkable result with small amount of data in various medical image analysis applications. This paper presents the effect of different learning parameters on the performance of the deep U-Net model for brain tumor segmentation. Here, we have compared the performance by tuning the different learning parameters such as the activation function, pooling strategies, kernel or filter size, dropout and batch normalization and measured the accuracy in terms of AUC (area under the curve) and F1score. The experiment was performed on two well-known freely data sets available, BraTs 2017 and BraTs 2018. The whole tumor along with its core and enhancing parts were segmented from FLAIR (Fluid Attenuated Inversion Recovery) MR scans and it is observed that the AUC is improved by 2% in whole tumor segmentation from base model with fine-tuned parameters.
C1 [Das, Suchsimita; Nayak, G. K.; Saxena, Sanjay] IIIT Bhubaneswar, Khurja, Odisha, India.
   [Swain, Mahesh ku.; Satpathy, S. C.] KIIT Univ, Bhubaneswar, Odisha, India.
C3 International Institute of Information Technology, Bhubaneswar; Kalinga
   Institute of Industrial Technology (KIIT)
RP Das, S (corresponding author), IIIT Bhubaneswar, Khurja, Odisha, India.
EM Suchismita.dasfcs@kiit.ac.in; 1850002@kiit.ac.in; gopal@iiit-bh.ac.in;
   sanjay@iiit-bh.ac.in; suresh.satapathyfcs@kiit.ac.in
RI Saxena, Sanjay/T-3216-2019
OI Saxena, Sanjay/0000-0002-8288-1010
CR Agrawal A, 2020, VISUAL COMPUT, V36, P405, DOI 10.1007/s00371-019-01630-9
   Ahn H, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10061959
   Bakas S, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.117
   Bakas Spyridon, 2018, ARXIV181102629, DOI DOI 10.17863/CAM.38755
   Ben Naceur M, 2018, COMPUT METH PROG BIO, V166, P39, DOI 10.1016/j.cmpb.2018.09.007
   BERA S, 2019, IET IMAGE PROCESS 14
   Cai Jin-Yi., 2017, CoRR
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   cicek Ozgtin, 2016, INT C MED IM COMP CO, P424, DOI DOI 10.1007/978-3-319-46723-8_49
   Cong W, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/9871529
   de Bruijne M, 2016, MED IMAGE ANAL, V33, P94, DOI 10.1016/j.media.2016.06.032
   Dong H, 2017, COMM COM INF SC, V723, P506, DOI 10.1007/978-3-319-60964-5_44
   Haralick R. M., 1985, Proceedings of the SPIE - The International Society for Optical Engineering, V548, P2, DOI [10.1016/S0734-189X(85)90153-7, 10.1117/12.948400]
   HARE HF, 1949, RADIOLOGY, V52, P193, DOI 10.1148/52.2.193
   Herholz K, 2012, SEMIN NUCL MED, V42, P356, DOI 10.1053/j.semnuclmed.2012.06.001
   Hesamian MH, 2019, J DIGIT IMAGING, V32, P582, DOI 10.1007/s10278-019-00227-x
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Isensee F., 2018, nnU-Net: Self-adapting Framework for U-Net-Based Medical Image Segmentation, DOI DOI 10.1007/978-3-658-25326-4_7
   Israt Jahan, 2017, INT J NEUROSCIENCE B, P60
   Li X, 2019, SIGNAL PROCESS, V161, P136, DOI 10.1016/j.sigpro.2019.03.019
   Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo Q, 2018, MEDICINE, V97
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Mesfin FB., 2020, GLIOMAS
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Nwankpa C., 2018, ARXIV181103378
   Pare S, 2020, IJST-T ELECTR ENG, V44, P1, DOI 10.1007/s40998-019-00251-1
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9
   Salman N, 2015, ADV IMAGE VIDEO PROC, V3, DOI 10.14738/aivp.32.1006
   Samat NA, 2020, COMP POOLING FUNCTIO, DOI 10.1007/978-3-030-36056-6_20
   Sastry R, 2017, J NEUROIMAGING, V27, P5, DOI 10.1111/jon.12382
   Shailaja K., 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P910, DOI 10.1109/ICECA.2018.8474918
   Shen TA, 2011, IEEE T MED IMAGING, V30, P774, DOI 10.1109/TMI.2010.2094623
   Song S., 2017, BIOMED ENG REV, V1, P2375, DOI 10.18103/bme.v3i1.1550
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tak R, 2017, SEGMENTATION MEDICAL, P1247, DOI [10.1109/ICCONS.2017.8250668, DOI 10.1109/ICCONS.2017.8250668]
   Varuna Shree N, 2018, BRAIN INFORM, V5, P23, DOI DOI 10.1007/S40708-017-0075-5
   Wiens J, 2018, CLIN INFECT DIS, V66, P149, DOI 10.1093/cid/cix731
NR 44
TC 8
Z9 8
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34717
EP 34735
DI 10.1007/s11042-021-11273-5
EA AUG 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000689522000003
DA 2024-07-18
ER

PT J
AU Yang, HR
   Tong, JH
   Dou, QY
   Xiao, L
   Jeon, G
   Yang, XM
AF Yang, Haoran
   Tong, Jiahui
   Dou, Qingyu
   Xiao, Long
   Jeon, Gwanggil
   Yang, Xiaomin
TI Wide receptive field networks for single image super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single image super-resolution (SISR); Deep learning; Receptive field;
   Contextual information
AB Recently, using deep learning(DL) in super-resolution(SR) has ac- hieved great success. These methods combine the convolutional neural network(CNN) to learn a general matrix function for an end-to-end mapping. However, as the width and depth of the network increase, there are two essential problems in the SR tasks. On the one hand, a wider and deeper network will bring better performance but increase the calculating complexity and memory consumption. On the other hand, the expanded architecture will miss the intermediate feature details in the information transmitting process. Hence, a SISR(Single Image Super-Resolution) network with wider feature information blocks(WFIB) is proposed to address these issues by making a balance between the network complexity and performance. Cascade residual block(CRB) helps the network make full use of contextual feature information. Extensive experiments verify that our network achieves better performance and with fewer parameters than the state-of-the-art methods.
C1 [Yang, Haoran; Tong, Jiahui; Yang, Xiaomin] Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610064, Sichuan, Peoples R China.
   [Dou, Qingyu] Sichuan Univ, West China Hosp, Ctr Gerontol & Geriatr, Chengdu, Peoples R China.
   [Xiao, Long] Sci & Technol Elect Informat Control Lab, Chengdu 610036, Peoples R China.
   [Jeon, Gwanggil] Dept Embedded Syst Engn, Incheon 22012, South Korea.
C3 Sichuan University; Sichuan University
RP Dou, QY (corresponding author), Sichuan Univ, West China Hosp, Ctr Gerontol & Geriatr, Chengdu, Peoples R China.; Jeon, G (corresponding author), Dept Embedded Syst Engn, Incheon 22012, South Korea.
EM ddqqking@126.com; ggjeon@gmail.com
RI Xiao, Long/R-1343-2017; yang, xiao/HJI-7815-2023
OI Dou, Qingyu/0000-0001-8849-3716
FU National Natural Science Foundation of China [61701327]
FX The research in our paper is sponsored by National Natural Science
   Foundation of China (No.61701327)
CR Ahn N., 2018, P EUR C COMP VIS ECC, P252, DOI DOI 10.1007/978-3-030-01249-6_16
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Chen YP, 2019, IEEE I CONF COMP VIS, P3434, DOI 10.1109/ICCV.2019.00353
   Cheng Ma, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7766, DOI 10.1109/CVPR42600.2020.00779
   Cong Liu PL, 2021, KNOWL-BASED SYST
   Ding L, 2018, NONLOCAL RECURRENT N
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Fang F., 2020, IEEE Transactions on Neural Networks and Learning Systems, P1
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Han D, 2015, PROC CVPR IEEE, P5016, DOI 10.1109/CVPR.2015.7299136
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Hui Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2024, DOI 10.1145/3343031.3351084
   Jiang HZ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.110
   Jie Liu, 2020, Proceedings of the 16th European Conference on Computer Vision - ECCV 2020 Workshops. Lecture Notes in Computer Science (LNCS 12537), P41, DOI 10.1007/978-3-030-67070-2_2
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kingma D. P., 2014, arXiv
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Li JC, 2018, LECT NOTES COMPUT SC, V11212, P527, DOI 10.1007/978-3-030-01237-3_32
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Li Z, 2019, PROC CVPR IEEE, P3862, DOI 10.1109/CVPR.2019.00399
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Muqeet Abdul, 2020, Proceedings of the 16th European Conference on Computer Vision - ECCV 2020 Workshops. Lecture Notes in Computer Science (LNCS 12537), P103, DOI 10.1007/978-3-030-67070-2_6
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772
   Piella G, 2002, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON INFORMATION FUSION, VOL II, P1557, DOI 10.1109/ICIF.2002.1021002
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Tian CW, 2020, KNOWL-BASED SYST, V205, DOI 10.1016/j.knosys.2020.106235
   Timofte R, 2017, 2017 IEEE C COMP VIS
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang X., 2020, P AS C COMP VIS
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Xiaotong Luo, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P272, DOI 10.1007/978-3-030-58542-6_17
   Xu B., 2015, Empirical evaluation of rectified activations in convolutional network, DOI DOI 10.48550/ARXIV.1505.00853
   Yang WH, 2020, IEEE T PATTERN ANAL, V42, P1377, DOI 10.1109/TPAMI.2019.2895793
   Yu J., 2018, P IEEE C COMPUTER VI
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
NR 47
TC 1
Z9 1
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 4859
EP 4876
DI 10.1007/s11042-021-11258-4
EA AUG 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000680824700002
DA 2024-07-18
ER

PT J
AU Luo, J
   Wu, HN
   Lei, L
   Wang, HY
   Yang, T
AF Luo, Jun
   Wu, Haonan
   Lei, Lei
   Wang, Huiyan
   Yang, Tao
TI GCA-Net: Gait contour automatic segmentation model for video gait
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gait recognition; Instance segmentation
AB Gait recognition from videos is a very important task for surveillance video analysis. Although a number of studies have explored gait recognition models, they lack clarity in the gait contour segmentation, which is an important but difficult step for automatic gait recognition. Most of the gait recognition algorithms use manually segmented gait contours, which is not available in real situations and not suited for real-time video processing applications. To date, there are very little research directly investigating automatic pedestrian gait contour segmentation. Current state-of-the-art instance segmentation methods fail to accurately describe the contour of whole pedestrian body and often deviate from the accurate boundaries, especially for the contour between two legs, which is the essential information for gait recognition. This paper presents a novel gait contour automatic segmentation model (GCA-Net) for gait recognition in videos. To improve the segmentation and edge fitting accuracy, we firstly use the dilated convolutions in the residual block to enhance the feature representative ability of the ResNet backbone, and then an edge detection module is added to the model which can make the predicted gait contour closer to the actual boundaries and therefore improve the edge fitting result. The experiment results show the effectiveness of the proposed method. The edge detection module can increase the performance by 5.4% and the residual block with dilated convolution can further increase the performance by 0.4%. More important, the proposed model can be directly integrated into existing gait recognition methods and automate video gait recognition.
C1 [Luo, Jun] Minist Publ Secur, Res Inst 3, Shanghai 200031, Peoples R China.
   [Wu, Haonan; Lei, Lei; Wang, Huiyan; Yang, Tao] Zhejiang Gongshang Univ, Sch Comp & Informat Engn, Hangzhou 310018, Peoples R China.
C3 Ministry of Public Security (China); Zhejiang Gongshang University
RP Yang, T (corresponding author), Zhejiang Gongshang Univ, Sch Comp & Informat Engn, Hangzhou 310018, Peoples R China.
EM yangt@zjgsu.edu.cn
RI Wang, Huiyan/JXW-9178-2024; Xi, Yang/KEH-5204-2024; Wang,
   Yifan/KDO-8319-2024
OI Yang, Tao/0000-0002-3822-198X
FU National Key Research and Development Program of China [2018YFC0824406]
FX This work is supported by the National Key Research and Development
   Program of China (No. 2018YFC0824406).
CR [Anonymous], CoRR abs/1511.07122
   [Anonymous], COMPUT VIS PATTERN R
   [Anonymous], 2017, ARXIV170506820
   Brejl M, 1998, IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, P814, DOI 10.1109/IJCNN.1998.685872
   Chao HQ, 2019, AAAI CONF ARTIF INTE, P8126
   Chen LL, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P349, DOI 10.1145/3126686.3126723
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Dai Jifeng, 2016, Advances in Neural Information Processing Systems, DOI DOI 10.1016/J.JPOWSOUR.2007.02.075
   Farag A.A., 1992, REMOTE SENSING REV, V6, P95, DOI DOI 10.1080/02757259209532148
   Giusti A, 2013, IEEE IMAGE PROC, P4034, DOI 10.1109/ICIP.2013.6738831
   Hamaguchi R, 2018, IEEE WINT CONF APPL, P1442, DOI 10.1109/WACV.2018.00162
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   HOU Y, 2008, J JILIN U ENG TECHNO, P4
   Huang J, 2017, IEEE INT C INT ROBOT, P3296, DOI 10.1109/IROS.2017.8206166
   Huang ZJ, 2019, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2019.00657
   Karthick S., 2014, INT J ENG TRENDS TEC, V7, P143, DOI [10.14445/22315381/IJETT-V7P262, DOI 10.14445/22315381/IJETT-V7P262]
   KRAHENBUHL P, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472
   Li H., 2014, Highly efficient forward and backward propagation of convolutional neural networks for pixelwise classification
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma YA, 2014, COMPUT ELECTRON AGR, V106, P102, DOI 10.1016/j.compag.2014.05.014
   Papandreou G, 2015, PROC CVPR IEEE, P390, DOI 10.1109/CVPR.2015.7298636
   Paszke A., 2017, ADV NEURAL INF PROCE, V9, P1, DOI DOI 10.1017/CB09781107707221.009
   Prasad M, 2006, LECT NOTES COMPUT SC, V4338, P94
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Saranathan AM, 2013, 2013 5 WORKSH HYP IM, P1
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Yu F., 2017, PROC CVPR IEEE, P472, DOI [DOI 10.1109/CVPR.2017.75, 10.1109/CVPR.2017.75]
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
   Zimmermann RS, 2019, COMPUT VIS IMAGE UND, V188, DOI 10.1016/j.cviu.2019.102795
NR 34
TC 4
Z9 4
U1 3
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34295
EP 34307
DI 10.1007/s11042-021-11248-6
EA JUL 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000678013400002
DA 2024-07-18
ER

PT J
AU Abel, MH
AF Abel, Marie-Helene
TI MEMORAe project: an approach and a platform for learning innovation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Learning innovation; Learning ecosystem; Organisational learning;
   Multimedia document system; Collaborative platform
AB Technologies developed in recent years have transformed the way we communicate, collaborate and work. It is therefore necessary to consider them from this point of view in the context of training. Learners evolve in a learning ecosystem that includes the learner himself but also his/her physical and social environment. Learning innovation is no longer about creating new teaching methods, but rather about creating learning conditions for exploiting the ecosystem in which learners evolve. In this paper, we identify the needs related to the evolution of a learner within his/her own learning ecosystem. We present why and how the MEMORAe project has enabled us to model and develop a collaborative platform as support of an ecosystem for the put into practice of learning innovation.
C1 [Abel, Marie-Helene] Univ Technol Compiegne, Heudiasyc Heurist & Diag Complex Syst, CNRS, CS 60 319, F-60203 Compiegne, France.
C3 Universite de Technologie de Compiegne; Centre National de la Recherche
   Scientifique (CNRS)
RP Abel, MH (corresponding author), Univ Technol Compiegne, Heudiasyc Heurist & Diag Complex Syst, CNRS, CS 60 319, F-60203 Compiegne, France.
EM marie-helene.abel@utc.fr
OI Abel, Marie-Helene/0000-0003-1812-6763
CR Abel, 2008, INT J COMPUTER SCI A, V5, P108
   Abel MH, 2015, COMPUT HUM BEHAV, V51, P960, DOI 10.1016/j.chb.2014.10.012
   Arduin PE, 2013, THESIS U PARIS DAUPH
   Atrash A, 2015, THESIS U TECHNOLOGY
   Baizid K, 2017, AUTON ROBOT, V41, P1203, DOI 10.1007/s10514-016-9590-0
   Ben SarraAbbes., 2012, Proceedings of the 7th International Conference on Formal Ontologies in Information Systems (FOIS), P13
   Benayache A, 2005, THESIS U TECHNOLOGY
   Breschi S., 2001, IND CORP CHANGE, V10, P975, DOI DOI 10.1093/ICC/10.4.975
   Carlsson B., 1991, J. Evol. Econ., V1, P93, DOI [DOI 10.1007/BF01224915, 10.1007/BF01224915]
   Daud A, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P415, DOI 10.1145/3041021.3054164
   Dennery M, 2014, CONCEPT PRINCIPES PE
   Deparis É, 2013, INT C COMP SUPP COOP, P581, DOI 10.1109/CSCWD.2013.6581026
   Dong H, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS, PROCEEDINGS, VOLS 1-8, P2944, DOI 10.1109/ISIE.2007.4375082
   Doran P., 2007, P CIKM 07, P61, DOI DOI 10.1145/1321440.1321451
   Leblanc A, 2009, THESIS U TECHNOLOGY
   Lhuillier JN, 2005, MANAGEMENT INFORM DO
   Li S, 2021, THESIS U TECHNOLOGIE
   Li SY, 2019, INT C COMP SUPP COOP, P93, DOI [10.1109/cscwd.2019.8791845, 10.1109/CSCWD.2019.8791845]
   Lozano R, 2008, IEEE DECIS CONTR P, P3713, DOI 10.1109/CDC.2008.4739071
   Mediani C, 2016, 2016 INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS AND COMPUTER SYSTEMS (CIICS)
   Muntjewerff A, 1999, WORKSH ONT INT ED SY
   Negre E, 2017, 9 INT C MAN DIG EC
   Oh KK, 2015, AUTOMATICA, V53, P424, DOI 10.1016/j.automatica.2014.10.022
   Pathak J, 2009, INTEGR COMPUT-AID E, V16, P225, DOI 10.3233/ICA-2009-0315
   Perkins D.N., 1995, Revue francaise de Pedagogie, V111, P57, DOI DOI 10.3406/RFP.1995.1232
   Popper StevenW., 2004, System of systems symposium: Report on a summer conversation, P320
   Prax J.-Y., 2000, GUIDE KNOWLEDGE MANA
   Saleh M, 2018, THESIS U TECHNOLOGIE
   Torre, 2001, HAL INRAE, V54, P147
   Tsuchiya S., 1993, ISMICK 1993 P INT S, P87
   Wang NN, 2016, IEEE GLOB COMM CONF, DOI 10.1109/GLOCOM.2016.7842309
NR 31
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 35555
EP 35569
DI 10.1007/s11042-021-11157-8
EA JUL 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000673731800002
DA 2024-07-18
ER

PT J
AU Ahrar, AM
   Roodaki, H
AF Ahrar, Amir Mahmoud
   Roodaki, Hoda
TI A new tile boundary artifact removal method for tile-based
   viewport-adaptive streaming in 360° videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 360 degrees video; Tile-based viewport-adaptive streaming; Boundary
   artifact removal; Mixed-resolution packing
AB In recent years, 360 degrees video is becoming popular with the development of the virtual reality technology. However, the 360 degrees video streaming faces many challenging issues since such video contains a large volume of data and requires streaming omnidirectional view. The Tile-based viewport-adaptive streaming method is used to deliver 360 degrees videos more efficiently. In this method, a set of high and low-resolution tiles, corresponding to the viewport and non-viewport parts of the scene, is generated. These tiles are encoded and decoded independently using the Motion Constrained Tile Set (MCTS) technique. However, coding and decoding each tile independently, may create artifacts around the tile boundaries. In this paper, a novel method, called Resizing, is proposed to reduce the tile boundary artifact in tile-based viewport-adaptive streaming. In this method, the adjacent tiles are overlapped before encoding. Then, the overlapping tiles are downsampled to keep the resolution of video constant. This way, the mixed-resolution packing of 6K equirectangular (ERP) content, defined in MPEG Omnidirectional Media Format (OMAF) standard Annex D, can be used so that the output bitstream complies with the 4K-decoding constraint and the High Efficiency Video Coding (HEVC) standard. Finally, the video is upsampled after decoding and the overlapping parts are removed. Then, a novel method to remove the overlapping areas at the decoder side is proposed that could increase the perceived quality considerably. Simulation results indicate that our proposed approach achieves a 14.14% reduction in bandwidth in the Bjontegaard-Bitrate scale, compared to the state-of-the-art methods that use variants of filtering for tile boundary artifact removal.
C1 [Ahrar, Amir Mahmoud; Roodaki, Hoda] KN Toosi Univ Technol, Tehran, Iran.
C3 K. N. Toosi University of Technology
RP Roodaki, H (corresponding author), KN Toosi Univ Technol, Tehran, Iran.
EM am.ahrar@email.kntu.ac.ir; hroodaki@kntu.ac.ir
CR Aksu E, 2019, IBC 2019
   [Anonymous], 2020, HIGH EFFICIENCY VIDE
   Bjotegaard G., 2001, VCEGM33
   Blumenberg C, 2013, PICT COD SYMP, P185, DOI 10.1109/PCS.2013.6737714
   Boyce J., 2017, JVETH1030
   Cho S, 2015, IEEE T MULTIMEDIA, V17, P778, DOI 10.1109/TMM.2015.2418995
   de la Fuente YS, 2019, IEEE J EM SEL TOP C, V9, P18, DOI 10.1109/JETCAS.2019.2899516
   Gankhuyag G, 2019, I C INF COMM TECH CO, P682, DOI 10.1109/ictc46691.2019.8939730
   Hannuksela MM, 2019, IEEE DATA COMPR CONF, P418, DOI 10.1109/DCC.2019.00050
   Sauer Johannes, 2018, 2018 PICT COD S PCS
   Shafi R, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12091491
   Son J, 2018, PROCEEDINGS OF THE 28TH ACM WORKSHOP ON NETWORK AND OPERATING SYSTEMS SUPPORT FOR DIGITAL AUDIO AND VIDEO (NOSSDAV'18), P61, DOI 10.1145/3210445.3210455
   Sun YL, 2019, PICT COD SYMP, DOI 10.1109/pcs48520.2019.8954549
   Sze V., 2014, HIGH EFFICIENCY VIDE, DOI [10.1007/978-3-319-06895-4, DOI 10.1007/978-3-319-06895-4]
   Wang, 2019, JTC1SC29WG11 ISOIEC
   Zare A., 2016, P 24 ACM INT C MULT, P601, DOI DOI 10.1145/2964284.2967292
   Zare A, 2018, PROCEEDINGS OF THE 23TH ACM WORKSHOP ON PACKET VIDEO (PV'18), P72, DOI 10.1145/3210424.3210425
   Zou WJ, 2021, IEEE T CIRC SYST VID, V31, P4241, DOI 10.1109/TCSVT.2021.3050157
NR 18
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29785
EP 29803
DI 10.1007/s11042-021-11173-8
EA JUL 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000673031500002
DA 2024-07-18
ER

PT J
AU Krishna, S
   George, B
AF Krishna, Sruthi
   George, Betsy
TI An affordable solution for the recognition of abnormality in breast
   thermogram
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Breast thermograms; Remote monitoring; Computer aided
   diagnosis
ID SEGMENTATION; FEATURES
AB Lack of sufficient expertise in the rural regions of the country contributes to a higher mortality rate of breast cancer. Remote breast health monitoring systems, including image acquisition devices and advanced communication technologies, have been laid out of a new lease of life by the conveyance of quality healthcare services in developing parts of the world. Despite the high mortality rate of breast cancer, very limited existing works have been explored in integrating screening techniques with machine learning approaches and real-time communication to remote areas, secondary or tertiary hospitals. This approach is necessary to develop scalable and affordable breast screening technologies for clinical prediction of breast abnormality in the remote regions of the country. In this research work, we propose an affordable and portable infrared imaging solution for remote breast health monitoring. The proposed system integrates an Infrared Image Acquisition Module (IIAM), Screening Module (SM), and Transmission Module (TM). The IIAM includes a thermal camera and associated software to acquire thermal images of the breast. SM is the combination of four submodules such as Pre-processing Module (PM), Automatic Segmentation Module (ASM), Feature Extraction Module (FEM), and Classification Module (CM). The key challenge in implementing SM is that the penetration of thermography based diagnostic approaches are impeded by the frequent misclassifications in the diagnosis of breast cancer. The main reasons for this misclassification is the poor Signal to Noise Ratio (SNR) and inefficient segmentation of breast regions in thermograms. To address these challenges, co-occurrence filter-based edge-preserved technique is adopted to design the PM. Using morphological operations and Distance Regularized Level Set Evolution (DRLSE), ASM delineates the Region of Interest (ROI). FEM extracts both statistical features, and wavelet transform based features from the segmented breast ROI's. CM depends on the SVM classifier to predict normal and abnormal images in the compiled dataset. The TM accesses and transmits the breast thermograms, predicted results, and patient's history to the healthcare professionals in the tertiary hospitals for further diagnosis. Detailed in-person screening and experimentation was performed on 71 patients which consisted of 34 healthy and 37 abnormal images. The performance of the proposed solution is evaluated, which demonstrated a classification accuracy of 96.46% competitive compared to state-of-the-art schemes.
C1 [Krishna, Sruthi; George, Betsy] Amnia Vishwa Vidyapeetham, Ctr Wireless Networks & Applicat WNA, Amritapuri, India.
RP Krishna, S (corresponding author), Amnia Vishwa Vidyapeetham, Ctr Wireless Networks & Applicat WNA, Amritapuri, India.
EM sruthik@am.amrita.edu
FU Department of Science & Technology (DST), Government of India
   [SR/WOS-B/250/2016]
FX The project was funded by a grant from the Women Scientists program
   SR/WOS-B/250/2016, under the aegis of the Department of Science &
   Technology (DST), Government of India.
CR Ali MAS, 2015, ACSIS-ANN COMPUT SCI, V5, P255, DOI 10.15439/2015F318
   [Anonymous], 2014, UNIQUE J ENG ADV SCI
   Garduño-Ramón MA, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030497
   Bhowmik MK, 2018, IEEE J BIOMED HEALTH, V22, P1238, DOI 10.1109/JBHI.2017.2740500
   Bhowmik MK, 2016, PROC SPIE, V9861, DOI 10.1117/12.2223421
   Boquete L, 2012, J MED SYST, V36, P103, DOI 10.1007/s10916-010-9450-y
   Conci, 2013, WORKSH VIS COMP RIO, V350
   Faust O, 2014, INFRARED PHYS TECHN, V66, P160, DOI 10.1016/j.infrared.2014.06.001
   Golestani N, 2014, EXCLI J, V13, P241
   Gopakumar S, 2018, 2018 3RD INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT)
   Heidari Z, 2018, BIOMED ENG-APP BAS C, V30, DOI 10.4015/S1016237218500242
   Hossam A., 2018, J Eng Sci, V46, P12
   Ibrahim A, 2020, IEEE ACCESS, V8, P122121, DOI 10.1109/ACCESS.2020.3007336
   Jevnisek RJ, 2017, PROC CVPR IEEE, P3816, DOI 10.1109/CVPR.2017.406
   Kapoor P, 2010, INT CONF COMPUT AUTO, P564, DOI 10.1109/ICCAE.2010.5451827
   Koay J, 2004, P ANN INT IEEE EMBS, V26, P1159
   Li L, 2010, IEEE T IMAGE PROCESS, V19, P1, DOI 10.1109/TIP.2009.2032341
   Ma J, 2019, VIBROENGINEERING PRO, DOI [10.21595/vp.2019.20978, DOI 10.21595/VP.2019.20978]
   Majeed B, 2018, BIOMED CIRC SYST C, P89
   Milosevic M, 2014, EXCLI J, V13, P1204
   Qi HR, 2001, P ANN INT IEEE EMBS, V23, P2866, DOI 10.1109/IEMBS.2001.1017386
   Ramesh, 2019, INT C WIR COMM SIGN
   Sánchez-Ruiz D, 2020, PATTERN RECOGN LETT, V135, P72, DOI 10.1016/j.patrec.2020.03.025
   Sathish D, 2019, VISUAL COMPUT, V35, P57, DOI 10.1007/s00371-017-1447-9
   Scales N, 2004, P ANN INT IEEE EMBS, V26, P1737
   Schaefer G, 2009, PATTERN RECOGN, V42, P1133, DOI 10.1016/j.patcog.2008.08.007
   Singh D, 2020, COMPUT METH PROG BIO, V183, DOI 10.1016/j.cmpb.2019.105074
   Singh J, 2020, MULTIMED TOOLS APPL, V79, P15273, DOI 10.1007/s11042-018-7113-z
   Srinivasan, 2014, IFMBE P, P231, DOI DOI 10.1007/978-3-319-02913-9_59
   Suganthi SS, 2014, BIOMED SIGNAL PROCES, V10, P128, DOI 10.1016/j.bspc.2014.01.008
   Yadav SS, 2022, MULTIMED TOOLS APPL, V81, P13139, DOI 10.1007/s11042-020-09600-3
   Zhang J, 2008, 2008 INTERNATIONAL MULTISYMPOSIUMS ON COMPUTER AND COMPUTATIONAL SCIENCES (IMSCCS), P102, DOI 10.1109/IMSCCS.2008.14
NR 32
TC 1
Z9 1
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 28303
EP 28328
DI 10.1007/s11042-021-11082-w
EA JUN 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000657212500002
DA 2024-07-18
ER

PT J
AU Sahin, N
   Alpaslan, N
   Hanbay, D
AF Sahin, Nurullah
   Alpaslan, Nuh
   Hanbay, Davut
TI Robust optimization of SegNet hyperparameters for skin lesion
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Melanoma; Segmentation; Skin lesion; SegNet; Bayesian optimization
ID DERMOSCOPY IMAGES; CLASSIFICATION; DIAGNOSIS; CHECKLIST; NETWORKS;
   COLOR; DEPTH
AB Melanoma is considered the deadliest form of skin cancer, and the number of cases is increasing day by day. The early diagnosis of melanoma is critical, as it significantly increases the patient's chance of survival. However, distinguishing melanoma from other skin lesion types by the physician can be a complicated process due to the diversity of its structural and textural features. Numerous computer-aided diagnosis (CAD) systems have been developed to assist the physician in detecting melanoma during recent years. The segmentation is a critical step for CAD systems, as it directly contributes to the performance of both feature extraction and classification steps. The optimization of the hyperparameters of deep learning methods is a challenging research topic. In this paper, the Bayesian optimized SegNet approach is proposed for precise skin lesion segmentation. The proposed method is obtained competitive results with the latest skin lesion segmentation methods. The hyperparameters optimized SegNet has achieved the best results with the average Jaccard Index of 84.9 on ISBI2016 and 74.5 on ISBI2017 dataset. Experimental results indicate the validity of Bayesian optimized SegNet. In this study, it has been observed that the bayesian hyperparameter optimization in the SegNet, which is the latest deep learning architecture, increased the segmentation performance of the SegNet by 16% in the ISBI2016 dataset and by 7% in the ISBI2017 dataset.
C1 [Sahin, Nurullah; Hanbay, Davut] Inonu Univ, Fac Engn, Malatya, Turkey.
   [Alpaslan, Nuh] Bingol Univ, Fac Engn & Architecture, Bingol, Turkey.
C3 Inonu University; Bingol University
RP Sahin, N (corresponding author), Inonu Univ, Fac Engn, Malatya, Turkey.
EM nursahin.net@gmail.com
RI Hanbay, Davut/AAG-8511-2019; ALPASLAN, Nuh/AAA-4227-2022
OI Hanbay, Davut/0000-0003-2271-7865; ALPASLAN, Nuh/0000-0002-6828-755X;
   SAHIN, Nurullah/0000-0002-3578-9959
CR Abbas Q, 2011, COMPUT METH PROG BIO, V104, pE1, DOI 10.1016/j.cmpb.2010.06.016
   Agarwal A, 2017, 2017 40TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P743, DOI 10.1109/TSP.2017.8076087
   Ahmed, 2019, OPTIMIZATION FACIAL, DOI 10.1007/978-3-030-27272-2_21
   Ahn E, 2017, IEEE J BIOMED HEALTH, V21, P1685, DOI 10.1109/JBHI.2017.2653179
   Ahn E, 2015, IEEE ENG MED BIO, P3009, DOI 10.1109/EMBC.2015.7319025
   Al-Masni MA, 2018, COMPUT METH PROG BIO, V162, P221, DOI 10.1016/j.cmpb.2018.05.027
   Argenziano G, 1998, ARCH DERMATOL, V134, P1563, DOI 10.1001/archderm.134.12.1563
   Argenziano G, 2001, LANCET ONCOL, V2, P443, DOI 10.1016/S1470-2045(00)00422-8
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Barata C, 2015, IEEE J BIOMED HEALTH, V19, P1146, DOI 10.1109/JBHI.2014.2336473
   Bi L, 2017, IEEE T BIO-MED ENG, V64, P2065, DOI 10.1109/TBME.2017.2712771
   Bi L, 2016, I S BIOMED IMAGING, P1059, DOI 10.1109/ISBI.2016.7493448
   Brahmbhatt P, 2019, INT C ARTIFICIAL INT
   Brochu E, 2010, TUTORIAL BAYESIAN OP
   Celebi ME, 2008, SKIN RES TECHNOL, V14, P347, DOI 10.1111/j.1600-0846.2008.00301.x
   Celebi ME, 2013, SKIN RES TECHNOL, V19, pE252, DOI 10.1111/j.1600-0846.2012.00636.x
   Dalila F, 2017, OPTIK, V140, P749, DOI 10.1016/j.ijleo.2017.04.084
   Eiben, 2020, ARXIV
   Fan HD, 2017, COMPUT BIOL MED, V85, P75, DOI 10.1016/j.compbiomed.2017.03.025
   Finlayson GD, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P37
   Garnavi R, 2011, COMPUT MED IMAG GRAP, V35, P105, DOI 10.1016/j.compmedimag.2010.08.001
   Gülcü A, 2020, IEEE ACCESS, V8, P52528, DOI 10.1109/ACCESS.2020.2981141
   Henning JS, 2007, J AM ACAD DERMATOL, V56, P45, DOI 10.1016/j.jaad.2006.09.003
   Huang L, 2019, SIGNAL IMAGE VIDEO P, V13, P431, DOI 10.1007/s11760-018-01410-3
   Kasmi R, 2016, SKIN RES TECHNOL, V22, P208, DOI 10.1111/srt.12252
   Lee T, 1997, COMPUT BIOL MED, V27, P533, DOI 10.1016/S0010-4825(97)00020-6
   Li X, 2009, LECT NOTES COMPUT SC, V5762, P1100
   Li YX, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020556
   Menzies SW, 1996, ARCH DERMATOL, V132, P1178, DOI 10.1001/archderm.132.10.1178
   Peng YJ, 2019, MULTIMED TOOLS APPL, V78, P10965, DOI 10.1007/s11042-018-6523-2
   Ninh QC, 2019, PROCEEDINGS OF 2019 6TH NATIONAL FOUNDATION FOR SCIENCE AND TECHNOLOGY DEVELOPMENT (NAFOSTED) CONFERENCE ON INFORMATION AND COMPUTER SCIENCE (NICS), P575, DOI [10.1109/nics48868.2019.9023862, 10.1109/NICS48868.2019.9023862]
   Shan PF, 2020, COMPUT BIOL MED, V123, DOI 10.1016/j.compbiomed.2020.103762
   Snoek J., 2012, Advances in Neural Information Processing Systems, V25, DOI DOI 10.48550/ARXIV.1206.2944
   Sreena S., 2019, 2019 2nd International Conference on Intelligent Computing, Instrumentation and Control Technologies (ICICICT), P32, DOI 10.1109/ICICICT46008.2019.8993219
   STOLZ W, 1994, EUR J DERMATOL, V4, P521
   Tang P, 2019, COMPUT METH PROG BIO, V178, P289, DOI 10.1016/j.cmpb.2019.07.005
   Terai S., 2020, BAYESIAN OPTIMIZATIO
   Tripp MK, 2016, CA-CANCER J CLIN, V66, P461, DOI 10.3322/caac.21352
   Valle E, 2020, NEUROCOMPUTING, V383, P303, DOI 10.1016/j.neucom.2019.12.003
   Xie FY, 2020, COMPUT METH PROG BIO, V186, DOI 10.1016/j.cmpb.2019.105241
   Ye F, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0188746
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
   Yuan YD, 2017, IEEE T MED IMAGING, V36, P1876, DOI 10.1109/TMI.2017.2695227
   Zalaudek I, 2006, BRIT J DERMATOL, V154, P431, DOI 10.1111/j.1365-2133.2005.06983.x
NR 44
TC 10
Z9 10
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36031
EP 36051
DI 10.1007/s11042-021-11032-6
EA MAY 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000655960200001
DA 2024-07-18
ER

PT J
AU Wu, YF
   Liu, XL
   Gao, PT
   Chen, ZH
AF Wu, Yongfei
   Liu, Xilin
   Gao, Peiting
   Chen, Zehua
TI A variational level set model with closed-form solution for bimodal
   image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Variational level set model; Closed&#8211; form
   solution; Global optimum
ID ACTIVE CONTOUR; ENERGY; MINIMIZATION; FORMULATION; ALGORITHMS
AB In this work, we present a variational level set model with closed-form solution via combining with the fuzzy clustering method for robust and efficient image segmentation. For the designed energy functional, the two region parameters are first quickly pre-computed by means of the fuzzy c-means method and then embedded into a variational binary level set framework. Unlike the traditional variational level set models and optimization algorithms, our proposed model could directly obtain an exact closed-form solution of the level set function without using any iterative calculations and it is thus the globally optimal solution. Furthermore, we investigate the closed-form formula and achieve a significant property of the solution. As a byproduct, the manual initialization of the level set function and the sophisticated setting of time step in the process of numerical implementation are completely eliminated and thus leads to more robust segmentation results. Numerical experiments on both synthetic and real images verify the theoretical analysis of the proposed model and confirm the segmentation performance of the proposed method in terms of efficiency, accuracy and insensitiveness to parameters tuning.
C1 [Wu, Yongfei; Liu, Xilin; Gao, Peiting; Chen, Zehua] Taiyuan Univ Technol, Coll Data Sci, Taiyuan, Shanxi, Peoples R China.
   [Wu, Yongfei] Univ Macau, Fac Sci & Technol, Taipa, Macau, Peoples R China.
C3 Taiyuan University of Technology; University of Macau
RP Wu, YF (corresponding author), Taiyuan Univ Technol, Coll Data Sci, Taiyuan, Shanxi, Peoples R China.; Wu, YF (corresponding author), Univ Macau, Fac Sci & Technol, Taipa, Macau, Peoples R China.
EM yongfeiwu522@sina.com; liuxilin@tyut.edu.cn; gaopeiting@tyut.edu.cn;
   chenzehua@tyut.edu.cn
RI Liu, Xilin/AFQ-1082-2022
OI Liu, Xilin/0000-0002-1136-6783; Yongfei, Wu/0000-0002-6344-1992
FU National Natural Science Foundation of China [61901292]; Natural Science
   Foundation of Shanxi Province, China [201801D221186, 201901D211080]
FX The authors gratefully thank the editors and the anonymous reviewers for
   their valuable comments and helpful suggestions. This work was supported
   in part by the National Natural Science Foundation of China under Grant
   No. 61901292, the Natural Science Foundation of Shanxi Province, China
   under Grant No. 201801D221186 and Grant No. 201901D211080.
CR BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0
   Brown ES, 2012, INT J COMPUT VISION, V98, P103, DOI 10.1007/s11263-011-0499-y
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chan TF, 2006, SIAM J APPL MATH, V66, P1632, DOI 10.1137/040615286
   Dong XP, 2016, IEEE T IMAGE PROCESS, V25, P516, DOI 10.1109/TIP.2015.2505184
   Dong XP, 2015, IEEE T IMAGE PROCESS, V24, P3966, DOI 10.1109/TIP.2015.2456636
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Gong MG, 2015, INFORM SCIENCES, V293, P351, DOI 10.1016/j.ins.2014.09.023
   Hoi, 2020, P IEEE CVF C COMP VI, P8960, DOI DOI 10.1109/CVPR42600.2020.00898
   Jin R, 2019, COMPUT MATH APPL, V78, P3678, DOI 10.1016/j.camwa.2019.06.010
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee SH, 2006, IEEE T IMAGE PROCESS, V15, P2843, DOI 10.1109/TIP.2006.877308
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Li Y, 2012, APPL MATH COMPUT, V219, P3083, DOI 10.1016/j.amc.2012.09.038
   Liang YL, 2016, IEEE T CIRC SYST VID, V26, P928, DOI 10.1109/TCSVT.2015.2406232
   Liang ZY, 2020, IEEE T IMAGE PROCESS, V29, P3351, DOI 10.1109/TIP.2019.2959256
   Lie J, 2006, IEEE T IMAGE PROCESS, V15, P1171, DOI 10.1109/TIP.2005.863956
   Liu, 2020, APPL SOFT COMPUT
   Liu J, 2019, MULTIMED TOOLS APPL, V78, P33659, DOI 10.1007/s11042-019-08174-z
   Liu Y, 2019, SIGNAL PROCESS, V155, P193, DOI 10.1016/j.sigpro.2018.08.017
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   MacQueen J, 1965, P 5 BER S MATH STAT, P281
   Mondal A, 2016, APPL SOFT COMPUT, V47, P191, DOI 10.1016/j.asoc.2016.05.026
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Peng JT, 2016, IEEE T CYBERNETICS, V46, P1616, DOI 10.1109/TCYB.2015.2453091
   Shen JB, 2019, IEEE T NEUR NET LEAR, V30, P2637, DOI 10.1109/TNNLS.2018.2885591
   Shen JB, 2018, IEEE T IMAGE PROCESS, V27, P2688, DOI 10.1109/TIP.2018.2795740
   Shen JB, 2017, IEEE T IMAGE PROCESS, V26, P4911, DOI 10.1109/TIP.2017.2722691
   Shen JB, 2016, IEEE T IMAGE PROCESS, V25, P5933, DOI 10.1109/TIP.2016.2616302
   Shen JB, 2014, IEEE T CIRC SYST VID, V24, P1088, DOI 10.1109/TCSVT.2014.2302545
   Shen JB, 2014, IEEE T IMAGE PROCESS, V23, P1451, DOI 10.1109/TIP.2014.2302892
   Venkatesh YV, 2000, PATTERN RECOGN, V33, P1239, DOI 10.1016/S0031-3203(99)00046-1
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Wang Y, 2013, APPL MATH COMPUT, V219, P11420, DOI 10.1016/j.amc.2013.05.049
   Wen WY, 2017, MULTIDIM SYST SIGN P, V28, P657, DOI 10.1007/s11045-015-0365-0
   Wu YF, 2019, MULTIMED TOOLS APPL, V78, P33633, DOI 10.1007/s11042-019-08098-8
   Wu YF, 2018, APPL MATH MODEL, V54, P697, DOI 10.1016/j.apm.2017.10.018
   Wu YF, 2015, SIGNAL PROCESS, V106, P123, DOI 10.1016/j.sigpro.2014.07.013
   Zhang HL, 2019, INFORM SCIENCES, V493, P152, DOI 10.1016/j.ins.2019.04.048
   Zhang KH, 2010, IMAGE VISION COMPUT, V28, P668, DOI 10.1016/j.imavis.2009.10.009
   Zhu J, 2020, SIGNAL PROCESS
NR 47
TC 1
Z9 1
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 25943
EP 25963
DI 10.1007/s11042-021-10926-9
EA APR 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000643591800002
DA 2024-07-18
ER

PT J
AU Ashiba, HI
AF Ashiba, H., I
TI Dark infrared night vision imaging proposed work for pedestrian
   detection and tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE OD; DIRNV images; Pedestrian detection and tracking; SURF; LAF; GE;
   ECLAHE; NT and CH
ID ENHANCEMENT
AB This framework presents three efficient proposed algorithms for pedestrian detection and tracking in Dark Infrared Night Vision (DIRNV) images. The first approach is relied on Gradient Estimation (GE) after mixing structure Equalization Exponential Contrast Limited Adaptive Histogram Equalization (ECLAHE) with Gamma Correction, and finally Cumulative Histogram (GECUGC) for discrimination. The GECUGC relies on enhancement using mixing ECLAHE Using Gamma Correction (ECUG) in addition to pre-processing followed by the GE using Laplacian Filter (LAF), and finally Cumulative Histograms (CH) for the detection or classification task. The second approach is based GE after a hybrid structure Histogram Equalization (HE) with Nonlinear Technique and finally CH (GHNTC) for discrimination. The GHNTC depends on enhancement by merging HE with Nonlinear Technique (NT) (HENT) followed by the GE using LAF and finally CH for pedestrian detection and tracking using DIRNV imaging. After the CH estimation, the difference between cumulative histograms with and without objects is estimated and used for pedestrian detection and tracking using DIRNV imaging. The third algorithm is based scale space analysis with the number of the Speeded Up Robust Features (SURF) points as the key parameters for classification. This technique is presented to detect the features of DIRNV pedestrian images and tracking. The performance metrics are the difference area between the cumulative histograms of DIRNV images with and without pedestrian, computation time, points of features and speed up factor. Simulation results prove that the success of three suggested techniques in pedestrian detection and tracking using DIRNV imaging. By comparing the three presented algorithms, it is clear that the second suggested technique gives superior for pedestrian detection and tracking from point view difference area between the cumulative histograms.On the other hand the first suggested technique is the best algorithms for pedestrian detection and tracking from point view the computation time. The obtained results clear that the third approach has sucesseded in gait pedestrian detection and tracking using DIRNV imaging.
C1 [Ashiba, H., I] Bilbis Higher Inst Engn Bilbis, Dept Elect & Elect Commun, Bilbis, Sharqia, Egypt.
RP Ashiba, HI (corresponding author), Bilbis Higher Inst Engn Bilbis, Dept Elect & Elect Commun, Bilbis, Sharqia, Egypt.
EM eng_h_2006@yahoo.com
CR Abd El-Samie FE, 2020, MULTIMED TOOLS APPL, V79, P5671, DOI 10.1007/s11042-019-7634-0
   Ahmed HM, 2016, GLOB J SCI FRONT RES, V16
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   Ashiba HI, 2020, MULTIMED TOOLS APPL, V79, P21539, DOI 10.1007/s11042-020-08899-2
   Ashiba HI, 2020, MULTIMED TOOLS APPL, V79, P2543, DOI 10.1007/s11042-019-08154-3
   Ashiba HI, 2019, MULTIMED TOOLS APPL, V78, P11277, DOI 10.1007/s11042-018-6545-9
   Ashiba HI, 2018, WIRELESS PERS COMMUN, V99, P619, DOI 10.1007/s11277-017-4958-9
   Ashiba HI, 2011, CIRC SYST SIGNAL PR, V30, P543, DOI 10.1007/s00034-010-9243-z
   Ashiba H. I., 2008, Progress In Electromagnetics Research C, V1, P123, DOI 10.2528/PIERC08012301
   Ashiba MI, 2020, MULTIMED TOOLS APPL, V79, P23111, DOI 10.1007/s11042-020-09039-6
   Bai XZ, 2017, INFRARED PHYS TECHN, V80, P44, DOI 10.1016/j.infrared.2016.11.011
   BAOHUA Z, 2017, INFRARED PHYS TECHN
   Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222
   Dai SS, 2015, INFRARED PHYS TECHN, V68, P10, DOI 10.1016/j.infrared.2014.09.042
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Hussein NJ, 2017, PATTERN RECOGN LETT, V94, P219, DOI 10.1016/j.patrec.2016.12.011
   Kim BG, 2003, PATTERN RECOGN LETT, V24, P2995, DOI 10.1016/S0167-8655(03)00160-0
   Kim BG, 2017, MULTIMED TOOLS APPL, V76, P22741, DOI 10.1007/s11042-017-4344-3
   Lu SY, 2019, COMPUT ELECTR ENG, V77, P398, DOI 10.1016/j.compeleceng.2019.05.009
   Cañada PM, 2013, J SYST ARCHITECT, V59, P30, DOI 10.1016/j.sysarc.2012.10.005
   Park, 2002, ELECT LETTERS4TH JUL, V38
   Park, 2002, P 16 INT C PATT REC, V3
   Pinoli, SIG PROCESS, V58, P11
   Qi W, 2016, INFRARED PHYS TECHN, V76, P684, DOI 10.1016/j.infrared.2016.04.038
   Sarma, 2013, IEEE T CYBERN, V43
   Schlenke J, 2012, ANAL CHIM ACTA, V754, P8, DOI 10.1016/j.aca.2012.10.012
   Singh B.B., 2017, INT J COMPUT APPL, V167, P0975
   Yin JL, 2016, INFRARED PHYS TECHN, V77, P302, DOI 10.1016/j.infrared.2016.06.004
   Zhang XL, 2015, EXPERT SYST APPL, V42, P2382, DOI 10.1016/j.eswa.2014.10.050
   Zhao JF, 2017, INFRARED PHYS TECHN, V81, P201, DOI 10.1016/j.infrared.2017.01.012
   Zhu P, 2017, INFRARED PHYS TECHN, V81, P282, DOI 10.1016/j.infrared.2017.01.013
NR 32
TC 2
Z9 3
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 25823
EP 25849
DI 10.1007/s11042-021-10864-6
EA APR 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000643186000004
DA 2024-07-18
ER

PT J
AU Kumar, PR
   Vimala, M
   Govindamoorthi, P
AF Kumar, Paulraj Ranjith
   Vimala, M.
   Govindamoorthi, P.
TI An optimal weighted HEVC coding for video compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video compression; Encoding; HEVC; PSNR; WWO
AB In recent years, the applications of multimedia are rising in greedy mode and hence the amount of video transactions are also increasing exponentially. It has been shouted a great demands for researchers to develop an effective models for video encoding & decoding, compression, bandwidth allocation, transmission channel and congestion control. This research work mainly focusses on to develop an efficient video compression standard algorithm named as High Efficiency Video Coding (HEVC). It proposes a new improved Iterative based propagation update in water wave Optimization Algorithm (IPU-WWO) that optimize the weights in adopted HEVC encoding. The proposed HEVC produces double the ratio of data compression at the similar level of quality of the video and considerably enhanced video quality with same bit rate compared with Advanced Video Coding (AVC). The performance of proposed IPU-WWO is compared with other conventional methods like Artificial Bee Colony (ABC), Firefly (FF), Particle Swarm Optimization (PSO) and Genetic Algorithm (GA) with respect to Peak Signal to Noise Ratio (PSNR). The experimental results show that proposed method produces better compression rate of 3.03%, 4.98%, 6.82%, and 8.38% compared with PSO, GA, FF, and ABC, respectively with high PSNR for the block size of 4. Moreover, the proposed method outperforms the state-of-the-art fast encoding algorithms for in terms of compression and performance.
C1 [Kumar, Paulraj Ranjith; Vimala, M.; Govindamoorthi, P.] PSR Engn Coll, Dept ECE, Sivakasi, Tamil Nadu, India.
RP Kumar, PR (corresponding author), PSR Engn Coll, Dept ECE, Sivakasi, Tamil Nadu, India.
EM p_ranjith_kumar@rediffmail.com; vimala@psr.edu.in; govindaccet@gmail.com
RI Kumar, Ranjith/Y-6739-2019; Vimala, M/AAB-9152-2022
OI Kumar, Ranjith/0000-0002-2362-3695; Vimala, M/0000-0002-9310-126X
CR [Anonymous], 2016, SMPTE MOTION IMAG J, DOI DOI 10.5594/J18659
   Antony A, 2015, AEU-INT J ELECTRON C, V69, P1650, DOI 10.1016/j.aeue.2015.07.019
   Christopher, 2017, J KING SAUD U COMPUT
   Gandomi AH, 2013, COMMUN NONLINEAR SCI, V18, P89, DOI 10.1016/j.cnsns.2012.06.009
   Gao Y, 2016, IEEE T MULTIMED, V18, P12
   Heindel A, 2017, IEEE T CIRC SYST VID, V27, P1749, DOI 10.1109/TCSVT.2016.2556338
   Ichigaya A, 2016, IEEE T BROADCAST, V62, P417, DOI 10.1109/TBC.2016.2550778
   Jridi M, 2017, IEEE T CIRC SYST VID, V27, P1815, DOI 10.1109/TCSVT.2016.2556578
   Karaboga D, 2008, APPL SOFT COMPUT, V8, P687, DOI 10.1016/j.asoc.2007.05.007
   Kumar BSS, 2018, ALEX ENG J, V57, P1, DOI 10.1016/j.aej.2016.09.003
   Lee H, 2015, IEEE T BROADCAST, V61, P388, DOI 10.1109/TBC.2015.2419172
   Lian XC, 2018, IEEE T CIRC SYST VID, V28, P958, DOI 10.1109/TCSVT.2016.2638857
   Lin CH, 2016, IEEE T CIRC SYST VID, V26, P1722, DOI 10.1109/TCSVT.2015.2472118
   McCall J, 2005, J COMPUT APPL MATH, V184, P205, DOI 10.1016/j.cam.2004.07.034
   Memos V, 2017, EFFICIENT ALGORITHM
   Memos VA, 2016, J REAL-TIME IMAGE PR, V12, P473, DOI 10.1007/s11554-015-0509-3
   Pan ZQ, 2016, IEEE T BROADCAST, V62, P675, DOI 10.1109/TBC.2016.2580920
   Pastuszak G, 2016, IEEE T CIRC SYST VID, V26, P210, DOI 10.1109/TCSVT.2015.2428571
   Pedersen MEH, 2010, APPL SOFT COMPUT, V10, P618, DOI 10.1016/j.asoc.2009.08.029
   Pourazad MT, 2012, IEEE CONSUM ELECTR M, V1, P36, DOI 10.1109/MCE.2012.2192754
   Psannis KE, 2019, IEEE T SUST COMPUT, V4, P77, DOI 10.1109/TSUSC.2018.2817043
   Stergiou C., 2018, J MULTIMED INF SYST, V5, P1
   Sullivan GJ, 2013, IEEE J-STSP, V7, P1001, DOI 10.1109/JSTSP.2013.2283657
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tew YQ, 2016, J VIS COMMUN IMAGE R, V40, P502, DOI 10.1016/j.jvcir.2016.07.017
   Tohidypour HR, 2017, IEEE T CIRC SYST VID, V27, P2204, DOI 10.1109/TCSVT.2016.2576738
   Tohidypour HR, 2016, IEEE T BROADCAST, V62, P664, DOI 10.1109/TBC.2016.2576600
   Xu XZ, 2016, IEEE J EM SEL TOP C, V6, P409, DOI 10.1109/JETCAS.2016.2597645
   Yu ST, 2018, SIGNAL PROCESS-IMAGE, V64, P68, DOI 10.1016/j.image.2018.02.008
   Yuan H, 2017, IEEE T MULTIMEDIA, V19, P1416, DOI 10.1109/TMM.2017.2669858
   Zhang HB, 2018, IEEE T CIRC SYST VID, V28, P513, DOI 10.1109/TCSVT.2016.2612693
   Zheng YJ, 2015, COMPUT OPER RES, V55, P1, DOI 10.1016/j.cor.2014.10.008
   Zhou DJ, 2017, IEEE J SOLID-ST CIRC, V52, P113, DOI 10.1109/JSSC.2016.2616362
   Zhu LW, 2017, IEEE T BROADCAST, V63, P547, DOI 10.1109/TBC.2017.2711142
NR 34
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 25389
EP 25409
DI 10.1007/s11042-021-10828-w
EA APR 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000640862600001
DA 2024-07-18
ER

PT J
AU Taghizadeh, M
   Chalechale, A
AF Taghizadeh, Maryam
   Chalechale, Abdolah
TI A class-independent flexible algorithm to generate region proposals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Region proposal; Superpixel; Segmentation; Recall
ID OBJECT PROPOSALS; GRADIENTS
AB Generating a sufficient number of regions with high accuracy is an important objective in the region proposal generation techniques. This paper presents a new, robust, and effective approach, which is based on the bottom-up segmentation, to produce a pool of well-quality regions. After image segmentation, the segmented candidates are expanded into the surrounding regions. The suggested algorithm produces some enlarged regions, which better cover objects and stuff. The proposed process can be applied in three different modes, namely fixed_mode, all_mode, and efficient_mode. The fixed_mode extends each region into parts of all the adjacent regions using an extension controller, which considers adjacent sequential pixels for each point on the region boundary. In all_mode, the current region is merged with all the adjacent regions to generate a larger region. The efficient_mode is then implemented using the accumulation of the results from both the fixed_mode and all_mode. Besides, the algorithm can be repeated in the fixed_mode and all_mode by considering a variety of values for the extension controller factor. No features are required to be extracted in the proposed algorithm, except for the image segmentation stage. In this study, four challenging datasets known as MSRC, VOC2007, VOC2012, and COCO 2017 are used to compare the proposed algorithm with other segmentation and region proposal algorithms. As a significant advantage compared to well-known region proposal algorithms, our approach achieves a greater Recall with the desirable number of regions. Furthermore, the algorithm shows a good improvementin extraction of small, medium, and large objects.
C1 [Taghizadeh, Maryam; Chalechale, Abdolah] Razi Univ, Kermanshah, Iran.
C3 Razi University
RP Chalechale, A (corresponding author), Razi Univ, Kermanshah, Iran.
EM taghizadeh.maryam@razi.ac.ir; chalechale@razi.ac.ir
RI Chalechale, Abdolah/AIC-3770-2022
OI Chalechale, Abdolah/0000-0002-7217-905X
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   Buluç A, 2016, LECT NOTES COMPUT SC, V9220, P117, DOI 10.1007/978-3-319-49487-6_4
   Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231
   Chen J, 2020, P IEEECVF WINTER C A, P767
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Endres I, 2014, IEEE T PATTERN ANAL, V36, P222, DOI 10.1109/TPAMI.2013.122
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Ghodrati A, 2015, IEEE I CONF COMP VIS, P2578, DOI 10.1109/ICCV.2015.296
   Gidaris S., 2016, arXiv preprint arXiv:1606.04446
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gu CH, 2009, PROC CVPR IEEE, P1030, DOI 10.1109/CVPRW.2009.5206727
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hosang J, 2016, IEEE T PATTERN ANAL, V38, P814, DOI 10.1109/TPAMI.2015.2465908
   Humayun A, 2014, PROC CVPR IEEE, P336, DOI 10.1109/CVPR.2014.50
   Jian MW, 2018, J VIS COMMUN IMAGE R, V57, P202, DOI 10.1016/j.jvcir.2018.11.007
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Kaya EC, 2018, IEEE IMAGE PROC, P1308, DOI 10.1109/ICIP.2018.8451686
   Ke W., 2016, P IEEE C COMPUTER VI, P10
   Kim J, 2012, LECT NOTES COMPUT SC, V7578, P444, DOI 10.1007/978-3-642-33786-4_33
   Krähenbühl P, 2014, LECT NOTES COMPUT SC, V8693, P725, DOI 10.1007/978-3-319-10602-1_47
   Kuo WC, 2015, IEEE I CONF COMP VIS, P2479, DOI 10.1109/ICCV.2015.285
   Lampert CH, 2009, IEEE T PATTERN ANAL, V31, P2129, DOI 10.1109/TPAMI.2009.144
   Li HY, 2019, INT J COMPUT VISION, V127, P225, DOI 10.1007/s11263-018-1101-7
   Li JN, 2018, IEEE T MULTIMEDIA, V20, P985, DOI 10.1109/TMM.2017.2759508
   Li SY, 2017, IEEE WINT CONF APPL, P979, DOI 10.1109/WACV.2017.114
   Liao M, 2017, 31 AAAI C ARTIFICIAL, P4167
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Manen S, 2013, IEEE I CONF COMP VIS, P2536, DOI 10.1109/ICCV.2013.315
   Mordan T, 2019, INT J COMPUT VISION, V127, P1659, DOI 10.1007/s11263-018-1109-z
   Najibi M, 2019, PROC CVPR IEEE, P7715, DOI 10.1109/CVPR.2019.00791
   Pinheiro P.O., 2015, NEURIPS, P1990
   Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5
   Pont-Tuset J, 2017, IEEE T PATTERN ANAL, V39, P128, DOI 10.1109/TPAMI.2016.2537320
   Rahtu E, 2011, IEEE I CONF COMP VIS, P1052, DOI 10.1109/ICCV.2011.6126351
   Rantalankila P, 2014, P IEEE C COMPUTER VI
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1
   Sorkhi AG, 2020, MULTIMED TOOLS APPL, V79, P18033, DOI 10.1007/s11042-019-08264-y
   Taghizadeh M, 2020, 2020 INT C MACH VIS, P1
   Tang YX, 2017, IEEE T MULTIMEDIA, V19, P393, DOI 10.1109/TMM.2016.2614862
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vedaldi A., 2008, LECT NOTES COMPUT SC
   Vu T., 2019, NEURIPS, P1430
   Wang JQ, 2019, PROC CVPR IEEE, P2960, DOI 10.1109/CVPR.2019.00308
   Zhang ZM, 2018, IEEE T PATTERN ANAL, V40, P1209, DOI 10.1109/TPAMI.2017.2707492
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 51
TC 3
Z9 3
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24697
EP 24717
DI 10.1007/s11042-021-10826-y
EA APR 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000638484500002
DA 2024-07-18
ER

PT J
AU Rathore, V
   Pal, AK
AF Rathore, Vandana
   Pal, Arup Kumar
TI An image encryption scheme in bit plane content using Henon map based
   generated edge map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic sequence; 2-D Henon map; Lyapunov exponent; Edge map
AB At present times the topic of Chaos gain a lot of attention for the encryption/decryption methodology, yet we didn't settled to get a good difference between conventional counterparts. Several chaotic maps can be considered sensitivity dependence to seed values. Taking into consideration for this property, In this paper, the author have presented an image encryption technique employing a 2-dimensional chaotic Henon map, initially it implemented the confusion scheme using chaotic sequence obtained by several iterations using chaotic map approach. In the subsequent stage Edge Maps, generated by edge detection filters and binary bit plane decomposition is applied to perform further confusion using a bit-xor operation to get a cipher image. It is more secure and robust, experimental analysis and simulation is performed to get required results which better revealed that the encrypted images are secured and tolerant to different attacks.
C1 [Rathore, Vandana; Pal, Arup Kumar] Indian Inst Technol ISM, Dept Comp Sci & Engn, Dhanbad, Bihar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Rathore, V (corresponding author), Indian Inst Technol ISM, Dept Comp Sci & Engn, Dhanbad, Bihar, India.
EM vandanarathore.in@gmail.com; arupkrpal@gmail.com
CR Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Cao WJ, 2017, SIGNAL PROCESS, V132, P96, DOI 10.1016/j.sigpro.2016.10.003
   Cao WJ, 2012, IEEE SYS MAN CYBERN, P1185, DOI 10.1109/ICSMC.2012.6377892
   Data Encryption Standard, 1999, DAT ENCR STAND FED I
   El Assad S, 2016, SIGNAL PROCESS-IMAGE, V41, P144, DOI 10.1016/j.image.2015.10.004
   FREI W, 1977, IEEE T COMPUT, V26, P988, DOI 10.1109/TC.1977.1674733
   Gao WS, 2010, INT CONF COMP SCI, P67, DOI 10.1109/ICCSIT.2010.5563693
   Han JW, 1999, OPT ENG, V38, P47, DOI 10.1117/1.602060
   Hua ZY, 2018, SIGNAL PROCESS, V144, P134, DOI 10.1016/j.sigpro.2017.10.004
   Hua ZY, 2014, IEEE SYS MAN CYBERN, P3229, DOI 10.1109/SMC.2014.6974425
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Maini R., 2009, Int J Image Process, V3, P1
   Nadernejad E., 2008, Appl. Math. Sci, V2, P1507
   PELI T, 1982, COMPUT VISION GRAPH, V20, P1, DOI 10.1016/0146-664X(82)90070-3
   Richter H, 2002, INT J BIFURCAT CHAOS, V12, P1371, DOI 10.1142/S0218127402005121
   Roushdy Mohamed., 2006, GVIP J, V6, P17
   Tang ZJ, 2016, OPT LASER ENG, V80, P1, DOI 10.1016/j.optlaseng.2015.12.004
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Ye GD, 2017, NEUROCOMPUTING, V251, P45, DOI 10.1016/j.neucom.2017.04.016
   Ye GD, 2010, PATTERN RECOGN LETT, V31, P347, DOI 10.1016/j.patrec.2009.11.008
   Zhang CC, 2016, INFORM SCIENCES, V363, P140, DOI 10.1016/j.ins.2016.05.008
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang LH, 2005, CHAOS SOLITON FRACT, V24, P759, DOI 10.1016/j.chaos.2004.09.035
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhang YS, 2014, OPTIK, V125, P1562, DOI 10.1016/j.ijleo.2013.09.018
   Zhang YS, 2014, COMMUN NONLINEAR SCI, V19, P74, DOI 10.1016/j.cnsns.2013.06.031
   Zheng Fan, 2008, Journal of China Universities of Posts and Telecommunications, V15, P64, DOI 10.1016/S1005-8885(08)60109-0
   Zhou NR, 2011, OPT COMMUN, V284, P3234, DOI 10.1016/j.optcom.2011.02.065
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zhou YC, 2012, OPT COMMUN, V285, P594, DOI 10.1016/j.optcom.2011.11.044
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 33
TC 16
Z9 16
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 22275
EP 22300
DI 10.1007/s11042-021-10719-0
EA MAR 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000633324300001
DA 2024-07-18
ER

PT J
AU Maswadi, K
   Ghani, NA
   Hamid, S
   Rasheed, MB
AF Maswadi, Kholoud
   Ghani, Norjihan Abdul
   Hamid, Suraya
   Rasheed, Muhammads Babar
TI Human activity classification using Decision Tree and Naive Bayes
   classifiers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Accelerometer; Activity classification; Data preprocessing; Feature
   classification; Machine learning
ID ACTIVITY RECOGNITION; PHYSICAL-ACTIVITY; FALL DETECTION; SMART HOMES;
   HEALTH-CARE; FUSION; ACCELEROMETER; TECHNOLOGIES; INFORMATION; INTERNET
AB With rapid development in wireless sensor networks and continuous improvements in developing artificial intelligence-based scientific solutions, the concept of ambient assisted living has been encouraged and adopted. This is due to its widespread applications in smart homes and healthcare. In this regard, the concept of human activity recognition (HAR) & classification has drawn numerous researchers' attention as it improves the quality of life. However, before using this concept in real-time scenarios, it is required to analyse its performance following activities of daily living using benchmarked data set. In this continuation, this work has adopted the activity classification algorithms to improve their accuracy further. These algorithms can be used as a benchmark to analyse others' performance. Initially, the raw 3-axis accelerometer data is first preprocessed to remove noise and make it feasible for training and classification. For this purpose, the sliding window algorithm, linear and Gaussian filters have been applied to raw data. Then Naive Bayes (NB) and Decision Tree (DT) classification algorithms are used to classify human activities such as: sitting, standing, walking, sitting down and standing up. From results, it can be seen that maximum 89.5% and 99.9% accuracies are achieved using NB and DT classifiers with Gaussian filter. Furthermore, we have also compared the obtained results with its counterpart algorithms in order to prove its effectiveness.
C1 [Maswadi, Kholoud; Ghani, Norjihan Abdul; Hamid, Suraya] Univ Malaya, Dept Informat Syst, Kuala Lumpur, Malaysia.
   [Maswadi, Kholoud] Jazan Univ, Dept Management Informat Syst, Jazan, Saudi Arabia.
   [Rasheed, Muhammads Babar] Univ Alcala, Intelligent Syst Grp IGS, Alcala De Henares 28871, Spain.
   [Rasheed, Muhammads Babar] Univ Lahore, Lahore, Pakistan.
C3 Universiti Malaya; Jazan University; Universidad de Alcala; University
   of Lahore
RP Maswadi, K; Ghani, NA (corresponding author), Univ Malaya, Dept Informat Syst, Kuala Lumpur, Malaysia.; Maswadi, K (corresponding author), Jazan Univ, Dept Management Informat Syst, Jazan, Saudi Arabia.
EM kmaswadi@jcba.edu.sa; norjihan@um.edu.my; babarmeher@gmail.com
RI Hamid, Suraya/JCE-1921-2023; Rasheed, Muhammad B./L-4948-2016; ABDUL
   GHANI, NORJIHAN/B-9381-2010
OI Rasheed, Muhammad B./0000-0002-9911-0693; Maswadi,
   Kholoud/0000-0002-2083-3902
CR Alpaydin E., 2010, Introduction to Machine Learning
   Amer AYA, 2021, IEEE INTELL SYST, V36, P58, DOI 10.1109/MIS.2020.2964738
   Babiker M, 2017, 2017 IEEE 4TH INTERNATIONAL CONFERENCE ON SMART INSTRUMENTATION, MEASUREMENT AND APPLICATION (ICSIMA 2017)
   Bakhshayeshian Z, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED ENGINEERING AND INNOVATION (KBEI), P1170, DOI 10.1109/KBEI.2015.7436213
   Barros, SPRINGER BRIEFS COMP, DOI 10.1007/978-3-319-14231-9_2
   Bhargava Neeraj, 2017, 2017 2nd International Conference on Communication and Electronics Systems (ICCES). Proceedings, P606, DOI 10.1109/CESYS.2017.8321150
   Bhargava N, 2017, PROCEEDINGS OF 2017 11TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND CONTROL (ISCO 2017), P212, DOI 10.1109/ISCO.2017.7855983
   Bi Y, 2016, IEEE SENS J, V16, P806, DOI 10.1109/JSEN.2015.2469095
   Bisio I, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511596
   Cao JJ, 2018, INFORM FUSION, V41, P68, DOI 10.1016/j.inffus.2017.08.002
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Chen ZH, 2017, IEEE T IND INFORM, V13, P3070, DOI 10.1109/TII.2017.2712746
   Cheng J, 2013, IEEE J BIOMED HEALTH, V17, P38, DOI 10.1109/TITB.2012.2226905
   Chernbumroong S, 2015, IEEE J BIOMED HEALTH, V19, P282, DOI 10.1109/JBHI.2014.2313473
   Chowdhury AK, 2018, IEEE J BIOMED HEALTH, V22, P678, DOI 10.1109/JBHI.2017.2705036
   De-La-Hoz-Franco E, 2018, IEEE ACCESS, V6, P59192, DOI 10.1109/ACCESS.2018.2873502
   Deen MJ, 2015, PERS UBIQUIT COMPUT, V19, P573, DOI 10.1007/s00779-015-0856-x
   Ehrenhard M, 2014, TECHNOL FORECAST SOC, V89, P306, DOI 10.1016/j.techfore.2014.08.002
   Figo D, 2010, PERS UBIQUIT COMPUT, V14, P645, DOI 10.1007/s00779-010-0293-9
   Fullerton E, 2017, IEEE SENS J, V17, P5290, DOI 10.1109/JSEN.2017.2722105
   Han CM, 2014, IEEE INFOCOM SER, P271, DOI 10.1109/INFOCOM.2014.6847948
   HE XL, 2018, IEEE INT SYMP POWER, pNI220
   Huang DC, 2018, INT CONF HIGH VOLTA
   Khan A. M. A., 2010, P 5 INT C FUT INF TE, P1, DOI DOI 10.1109/FUTURETECH.2010.5482729
   KSE N, 2017, IEEE INT C IM PROC I, P396
   Kubo T, 2006, AM J EPIDEMIOL, V164, P549, DOI 10.1093/aje/kwj232
   Kushwaha AKS, 2017, MULTIMEDIA SYST, V23, P451, DOI 10.1007/s00530-016-0505-x
   Lauriks S, 2007, AGEING RES REV, V6, P223, DOI 10.1016/j.arr.2007.07.002
   Lee S.W., IEEE Transactions on Industrial Electronics
   Li F, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020679
   LIN W, 2018, IEEE SENS J
   Liu Y, 2012, INT C PATT RECOG, P898
   Mannini A, 2010, SENSORS-BASEL, V10, P1154, DOI 10.3390/s100201154
   Maswadi K, 2020, IEEE ACCESS, V8, P92244, DOI 10.1109/ACCESS.2020.2992727
   Maziewski P, 2009, SPA 2009: SIGNAL PROCESSING ALGORITHMS, ARCHITECTURES, ARRANGEMENTS, AND APPLICATIONS CONFERENCE PROCEEDINGS, P95
   Mitchell E, 2013, SENSORS-BASEL, V13, P5317, DOI 10.3390/s130405317
   Mohd Azmi MuhammadSufyian., 2017, Int. J. Adv. Sci., Eng. Inf. Technol., DOI 10.18517/ijaseit.7.1.1790
   Moschetti A, 2017, IEEE SENS J, V17, P8395, DOI 10.1109/JSEN.2017.2764323
   Nam Y, 2013, IEEE J BIOMED HEALTH, V17, P420, DOI 10.1109/JBHI.2012.2235075
   Pal D, 2018, IEEE ACCESS, V6, P10483, DOI 10.1109/ACCESS.2018.2808472
   Plotnik M, 2011, EXP BRAIN RES, V210, P529, DOI 10.1007/s00221-011-2551-0
   Qian X, IEEE SENS J, V20, P9408
   Rogers SJ, 2003, J AUTISM DEV DISORD, V33, P631, DOI 10.1023/B:JADD.0000006000.38991.a7
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458
   Sazonov ES, 2011, IEEE T BIO-MED ENG, V58, P983, DOI 10.1109/TBME.2010.2046738
   Shi DX, 2017, PERS UBIQUIT COMPUT, V21, P427, DOI 10.1007/s00779-017-1007-3
   Singh A, 2020, IEEE SENS J, V20, P6889, DOI 10.1109/JSEN.2020.2976554
   Stojkoska BLR, 2017, J CLEAN PROD, V140, P1454, DOI 10.1016/j.jclepro.2016.10.006
   Tang WL, 2014, IEEE J BIOMED HEALTH, V18, P309, DOI 10.1109/JBHI.2013.2287400
   Twomey N, 2018, INFORMATICS-BASEL, V5, DOI 10.3390/informatics5020027
   Ugulino Wallace, 2012, Advances in Artificial Intelligence - SBIA 2012. Proceedings 21th Brazilian Symposium on Artificial Intelligence, P52, DOI 10.1007/978-3-642-34459-6_6
   Vanrell SR, 2018, IEEE J BIOMED HEALTH, V22, P1001, DOI 10.1109/JBHI.2017.2722870
   Venkatesh V, 2012, MIS QUART, V36, P157
   Wang H, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P25, DOI 10.1145/2971648.2971744
   Wang H, 2017, IEEE T MOBILE COMPUT, V16, P511, DOI 10.1109/TMC.2016.2557795
   Wang W, 2017, IEEE J SEL AREA COMM, V35, P1118, DOI 10.1109/JSAC.2017.2679658
   Wu, IEEE INTERNET THINGS
   Wu D, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P351, DOI 10.1145/2971648.2971658
   Yang Xue, 2010, 2010 IEEE International Conference on Systems, Man and Cybernetics (SMC 2010), P4081, DOI 10.1109/ICSMC.2010.5641790
   Zdravevski E, 2017, IEEE ACCESS, V5, P5262, DOI 10.1109/ACCESS.2017.2684913
   ZHOU X, IEEE INTERNET THINGS
   Zhuo YW, 2017, IEEE INFOCOM SER
   2010, DECISION TREES DATA, P1
NR 63
TC 22
Z9 22
U1 1
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21709
EP 21726
DI 10.1007/s11042-020-10447-x
EA MAR 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000630647100005
DA 2024-07-18
ER

PT J
AU Rafiq, M
   Bajwa, UI
   Gilanie, G
   Anwar, W
AF Rafiq, Maimoona
   Bajwa, Usama Ijaz
   Gilanie, Ghulam
   Anwar, Waqas
TI Reconstruction of scene using corneal reflection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cornea reflection; Scene reconstruction; Super resolution; Generative
   adversarial network
AB Corneal reflection extracted from an eye image identifies the relationship between the subject of the image and the scene in front of the subject. The reconstructed scene from corneal reflection provides detailed information about the environment opposite to the subject. It also provides scrutiny about any critical scenario, a subject is encountered with. This research area has significant applications in computer vision, human-computer interaction, psychology, and image forgery detection. Digital image processing and computer vision techniques have been used to reconstruct the scene from cornea image. The proposed model involved the following steps, i.e., identification of the corneal area in an eye, unnecessary reflection removal from cornea surface, developing eye geometric model to correct the spherical effect of the eye, and implementation of super-resolution (SR) algorithm to reconstruct the lost visual information present in the environment. The proposed study is able to reconstruct the SR scene image from cornea image. The effectiveness of the study is evaluated by using subjective as well as objective evaluation measures. Some useful insights related to cornea reflection construction have been described to make this study more effective.
C1 [Rafiq, Maimoona; Bajwa, Usama Ijaz; Gilanie, Ghulam; Anwar, Waqas] COMSATS Univ Islamabad, Dept Comp Sci, Lahore Campus, Lahore, Pakistan.
C3 COMSATS University Islamabad (CUI)
RP Bajwa, UI (corresponding author), COMSATS Univ Islamabad, Dept Comp Sci, Lahore Campus, Lahore, Pakistan.
EM fa17-rcs-017@cuilahore.edu.pk; usamabajwa@cuilahore.edu.pk
RI Gilanie, Ghulam/HDN-2595-2022
OI Gilanie, Ghulam/0000-0001-6880-8506; Bajwa, Usama/0000-0001-5755-1194
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Ali M, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATIONS AND COMPUTING (ICSPCC), P184, DOI 10.1109/ICSPCC.2014.6986179
   [Anonymous], 2018, ECCV
   Helland T, 2013, SIMPLE ALGORITHM COR
   Jenkins R, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0083325
   Kumar R, 2019, EYE PROTECTION DEP A
   Ledig C., 2017, P IEEE C COMP VIS PA, P4681
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   MacKenzie I, 2018, FITTS LAW
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Nagamatsu T, 2019, INT C HUM COMP INT, P385
   Nakazawa A, 2016, J OPT SOC AM A, V33, P2264, DOI 10.1364/JOSAA.33.002264
   Nakazawa A, 2012, LECT NOTES COMPUT SC, V7573, P159, DOI 10.1007/978-3-642-33709-3_12
   Nishino K, 2006, INT J COMPUT VISION, V70, P23, DOI 10.1007/s11263-006-6274-9
   Nitschke Christian., 2012, BMVC, P1
   Nitschke Christian., 2013, IPSJ Transactions on Computer Vision and Applications, V5, P1, DOI [10.2197/ipsjtcva.5.1, DOI 10.2197/ipsjtcva.5.1]
   Numakura K, 2019, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI'19), DOI 10.1145/3338286.3344388
   Ogawa T, 2018, IEICE T INF SYST, VE101D, P1278, DOI 10.1587/transinf.2017MVP0020
   Pedersen S., 2007, Circular hough transform
   Raza MF, 2009, VISIONS COME NOT POL
   Rong J., 2016, Asian Conference on Computer Vision
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Wang C, 2019, IEEE INT CON MULTI, P1276, DOI 10.1109/ICME.2019.00222
   Wei KX, 2019, PROC CVPR IEEE, P8170, DOI 10.1109/CVPR.2019.00837
   Xue ZC, 2019, PROC CVPR IEEE, P1643, DOI 10.1109/CVPR.2019.00174
   Yang JC, 2018, AEBMR ADV ECON, V66, P654
   Zhang X, 2018, PROC CVPR IEEE, P4786, DOI 10.1109/CVPR.2018.00503
NR 27
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21363
EP 21379
DI 10.1007/s11042-020-10409-3
EA MAR 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000629494100007
DA 2024-07-18
ER

PT J
AU Acharjya, DP
   Rathi, R
AF Acharjya, D. P.
   Rathi, R.
TI An integrated fuzzy rough set and real coded genetic algorithm approach
   for crop identification in smart agriculture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fuzzy rough set; Quick reduct; Fuzzy approximation; Fuzzy equivalence;
   Data reduction; Fuzzy positive region; Linear regression; Smart
   agriculture
ID PREDICTION; FRAMEWORK; OPERATOR
AB Digitalization accumulates data in a short period. Smart agriculture for crop identification for cultivation is a common problem in agriculture for agronomists. The generated data due to digitalization does not provide any useful information unless some meaningful information is retrieved from it. Therefore from the existing information system, prediction of decision for unseen associations of attribute values is of challenging. This paper presents a model that hybridizes a fuzzy rough set, real-coded genetic algorithm, and linear regression. The model works in two phases. In the initial phase, the fuzzy rough set is used to remove superfluous attributes whereas, in the second phase, a real-coded genetic algorithm is used to predict the decision values of unseen instances by making use of linear regression. The proposed model is analyzed for its viability using agricultural information system obtained from Krishi Vigyan Kendra of Thiruvannamalai district of Tamilnadu, India. Further, the accuracy of the proposed model is compared with existing techniques.
C1 [Acharjya, D. P.] VIT Vellore, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
   [Rathi, R.] VIT Vellore, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Vellore Institute of
   Technology (VIT); VIT Vellore
RP Acharjya, DP (corresponding author), VIT Vellore, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
EM dpacharjya@gmail.com; raathiraj@gmail.com
RI Acharjya, Debi/T-1205-2018
OI Acharjya, Debi/0000-0003-3828-2050
CR Abed-Erndoust A, 2012, OCEAN ENG, V54, P244, DOI 10.1016/j.oceaneng.2012.07.020
   Acharjya DP, 2020, ENG APPL ARTIF INTEL, V96, DOI 10.1016/j.engappai.2020.103924
   Acharjya DP., 2012, INT J INTELL SYST AP, V4, P1
   Anitha A, 2018, NEURAL COMPUT APPL, V30, P3633, DOI 10.1007/s00521-017-2948-1
   [Anonymous], 2014, International Journal of Innovative Research in Electrical, Electronics, Instrumentation and Control Engineering
   [Anonymous], 2013, An Introductory Study on Time Series Modeling and Forecasting
   Bharati S.K., 2014, INT J COMPUT APPL, V89, P17
   Bhatt RB, 2005, PATTERN RECOGN LETT, V26, P965, DOI 10.1016/j.patrec.2004.09.044
   Chifurira R., 2014, MEDITERRANEAN J SOCI, V5, P34, DOI DOI 10.5901/MJSS.2014.V5N7P34
   Cornelis C, 2003, EXPERT SYST, V20, P260, DOI 10.1111/1468-0394.00250
   Deb K, 2012, Optimization for engineering design: Algorithms and examples
   Deep K, 2007, APPL MATH COMPUT, V193, P211, DOI 10.1016/j.amc.2007.03.046
   Deep K, 2007, APPL MATH COMPUT, V188, P895, DOI 10.1016/j.amc.2006.10.047
   Demartini E, 2015, ENVIRON SCI POLICY, V54, P226, DOI 10.1016/j.envsci.2015.07.006
   DUBOIS D, 1990, INT J GEN SYST, V17, P191, DOI 10.1080/03081079008935107
   Dubois D., 1992, Intelligent Decision Support: Handbook of Applications and Advances of the Rough Sets Theory, P203, DOI [10.1007/978-94-015-7975-9_14, DOI 10.1007/978-94-015-7975-9_14]
   Enke D, 2011, PROCEDIA COMPUT SCI, V6, DOI 10.1016/j.procs.2011.08.038
   Herrera F, 1998, ARTIF INTELL REV, V12, P265, DOI 10.1023/A:1006504901164
   Jensen R, 2004, FUZZY SET SYST, V141, P469, DOI 10.1016/S0165-0114(03)00021-6
   Jensen R, 2007, IEEE T FUZZY SYST, V15, P73, DOI 10.1109/TFUZZ.2006.889761
   Jensen R, 2011, THEOR COMPUT SCI, V412, P5871, DOI 10.1016/j.tcs.2011.05.040
   Jensen R, 2009, IEEE T FUZZY SYST, V17, P824, DOI 10.1109/TFUZZ.2008.924209
   KUNCHEVA LI, 1992, FUZZY SET SYST, V51, P147, DOI 10.1016/0165-0114(92)90187-9
   Liu GL, 2010, KNOWL-BASED SYST, V23, P110, DOI 10.1016/j.knosys.2009.06.011
   Liu J, 2001, T ASAE, V44, P705
   McKee T. E., 2000, International Journal of Intelligent Systems in Accounting, Finance and Management, V9, P159, DOI 10.1002/1099-1174(200009)9:3<159::AID-ISAF184>3.0.CO;2-C
   Papageorgiou EI, 2011, APPL SOFT COMPUT, V11, P3643, DOI 10.1016/j.asoc.2011.01.036
   Pawlak Z., 1991, ROUGH SETS THEORETIC
   Rao DJ, 2005, P 2 IND INT C ART IN, P2420
   Rathi R, 2018, ARAB J SCI ENG, V43, P4215, DOI 10.1007/s13369-017-2838-y
   Rathi R., 2018, International Journal of Fuzzy Systems Applications, V7, P74, DOI 10.4018/IJFSA.2018010106
   Singh Amarjeet, 2015, International Journal of Intelligent Systems and Applications, V7, P1, DOI 10.5815/ijisa.2015.12.01
   Sun B, 2013, J OPER RES SOC, V64, P1079, DOI 10.1057/jors.2012.75
   Tsoumakas G., 2007, INT J DATA WAREHOUS, V3, P1, DOI DOI 10.4018/JDWM.2007070101
   Wang XY, 2005, LECT NOTES ARTIF INT, V3613, P370
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
NR 36
TC 4
Z9 4
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 35117
EP 35142
DI 10.1007/s11042-021-10518-7
EA MAR 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000628488100003
DA 2024-07-18
ER

PT J
AU Hao, XL
   Sun, ZY
   Pei, LL
   Li, W
   Geng, FY
   Shao, NN
AF Hao, Xueli
   Sun, Zhaoyun
   Pei, Lili
   Li, Wei
   Geng, Fangyuan
   Shao, Nana
TI A denoising method for pavement 3d data based on breakpoint
   interpolation and reference plane filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Laser-based 3D data; Uneven pavement surface; Breakpoint interpolation;
   Reference plane filtering
AB In order to meet the current pavement intelligent detection and feature parameter extraction requirements, a 3D pavement surface data denoising method based on breakpoint interpolation and reference plane filtering (BI-RPF) is proposed and demonstrated using 3D pavement data acquired by a laser-based 3D imaging system. First, the principal structure and major characteristics of 3D pavement data were analyzed. Next, the breakpoint interpolation method considering the relationship between ordinate and slope was proposed to complete the missing values from the original pavement data. Then, reference plane filtering based on the horizontal and longitudinal reference plane was realized so as to overcome the unevenness of the pavement. Finally, the filtering effectiveness of the proposed method was compared with that of the standard deviation filtering and median filtering methods. The results show that the proposed filtering method takes breakpoints and uneven road surface into account, which can provide more accurate 3D road surface data under more complex conditions. The algorithm provided a good denoising effect while retaining valid data describing the road surface morphology, which establishes a foundation of BI-RPF to 3D pavement reconstruction.
C1 [Hao, Xueli; Sun, Zhaoyun; Pei, Lili; Li, Wei; Geng, Fangyuan; Shao, Nana] Changan Univ, Sch Informat Engn, Xian, Shaanxi, Peoples R China.
C3 Chang'an University
RP Li, W (corresponding author), Changan Univ, Sch Informat Engn, Xian, Shaanxi, Peoples R China.
EM xueli.hao@foxmail.com; zhaoyunsun@126.com; peilili@chd.edu.cn;
   grandy@chd.edu.cn; 2019124028@chd.edu.cn; 913648563@qq.com
FU National key research and development program [2018YFB1600202]; National
   Natural Science Foundation of China Youth Program [51908059, 51978071];
   Fundamental Research Funds for the Central Universities, CHD
   [300102240206, 300102249301]
FX This research is funded by National key research and development
   program(Grant number: 2018YFB1600202); National Natural Science
   Foundation of China Youth Program (Grant number: 51908059, 51978071);
   The Fundamental Research Funds for the Central Universities, CHD (Grant
   No.: 300102240206, 300102249301).
CR Cheng W, 2018, IEEE T IMAGE PROCESS, V27, P3446, DOI 10.1109/TIP.2018.2820812
   Fan GF, 2016, NEUROCOMPUTING, V173, P958, DOI 10.1016/j.neucom.2015.08.051
   [冯兴乐 Feng Xingle], 2013, [激光杂志, Laser Journal], V34, P28
   Laurent J., 2012, 7th RILEM International Conference on Cracking in Pavements, Delft, Netherlands, P157, DOI DOI 10.1007/978-94-007-4566-7_16
   Li H, 2018, PATTERN RECOGN, V79
   Li Ming-Wei, 2019, NONLINEAR DYNAMICS
   Li W, 2017, J TRANSP ENG B-PAVE, V143, DOI 10.1061/JPEODX.0000006
   Liu Rufei, 2015, Geomatics and Information Science of Wuhan University, V40, P751, DOI 10.13203/j.whugis20130450
   Ouyang W, 2013, MEAS SCI TECHNOL, V24, DOI 10.1088/0957-0233/24/10/105204
   Rastiveis H, 2020, ISPRS J PHOTOGRAMM, V160, P149, DOI 10.1016/j.isprsjprs.2019.12.009
   Siregar S, 2018, JPN J APPL PHYS, V57, DOI 10.7567/JJAP.57.07LB06
   Sun XM, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-191
   [孙朝云 Sun Zhaoyun], 2015, [长安大学学报. 自然科学版, Journal of Chang'An University. Natural Science Edition], V35, P20
   Wang KCP, 2011, J TRANSP ENG, V137, P571, DOI 10.1061/(ASCE)TE.1943-5436.0000240
   Wang Xing-jian, 2010, Journal of Computer Applications, V30, P1606, DOI 10.3724/SP.J.1087.2010.01606
   Wanqiu L, 2020, J MAT CIV ENG, V32
   Wei L, 2017, J TRANSP ENG, V143, P1
   Wei L, 2015, J CHINA HIGHWAY, V28, P21
   Xiling L, 2018, J GEOPHYS ENG, V15, P4116
   Xu B, 2012, REAL TIME 3D SCANNIN
   Zalama E, 2014, COMPUT-AIDED CIV INF, V29, P342, DOI 10.1111/mice.12042
   Zhang A, 2013, TRANSPORT RES REC, P30, DOI 10.3141/2367-04
   Zhang Z, 2019, NONLINEAR DYNAMICS, V98
   Zhang ZC, 2019, ENG APPL ARTIF INTEL, V85, P254, DOI 10.1016/j.engappai.2019.06.017
   Zhaoyun S, 2020, J S CHINA U TECHNOL, V48, p[2, 84]
   Zhou YQ, 2015, J MATER CHEM C, V3, P10099, DOI 10.1039/c5tc02002f
NR 26
TC 1
Z9 2
U1 4
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 20803
EP 20819
DI 10.1007/s11042-021-10508-9
EA MAR 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000627245300002
DA 2024-07-18
ER

PT J
AU Ibrahim, E
   Shouman, MA
   Torkey, H
   El-Sayed, A
AF Ibrahim, Elhossiny
   Shouman, Marwa A.
   Torkey, Hanaa
   El-Sayed, Ayman
TI Handling missing and outliers values by enhanced algorithms for an
   accurate diabetic classification system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Prediction; Healthcare; Data imputation; Machine learning; Diabetes;
   Outliers; Missing data
ID IMPUTATION
AB Recently, healthcare data analysis has become an attractive research topic. Data gathering is the first step in data analysis and processing. During the collection of the data, some errors may occur due to human mistakes, devices' errors, or the transmission process noise. The correct treatment of the missed data and outliers conserve the data size and improve the model's performance. This paper provides two enhanced algorithms to handle missing values and outliers in big datasets. The main idea is dividing the dataset into its different classes, or clustering it by using k-means++, then calculate the average value of each part, finally replace the missed data and outliers with its corresponding part mean value. The projected imputation and outliers' data handling algorithms are tested on a dataset called Pima Indian diabetic, which contains 2768 patients dividing into 952 diabetic and 1816 controls. Four classifiers (Random Forest, Decision Tree, Support Vector Machine, and Naive Bayes) are used to evaluate the effect of the proposed algorithms. The results show that the proposed algorithms improve classification accuracy by 8% and decrease the RMSE by 17% over Deep Learning (DL). DL is the most powerful algorithms used in repairing the missed data.
C1 [Ibrahim, Elhossiny; Shouman, Marwa A.; Torkey, Hanaa; El-Sayed, Ayman] Fac Elect Engn, Dept Comp Sci & Engn, Menoufia, Egypt.
RP Ibrahim, E (corresponding author), Fac Elect Engn, Dept Comp Sci & Engn, Menoufia, Egypt.
EM elhossiny@el-eng.menofia.edu.eg
RI EL-SAYED, Ayman E./AFM-8547-2022; Torkey, Hanaa/GLR-0493-2022
OI EL-SAYED, Ayman E./0000-0002-4437-259X; Torkey,
   Hanaa/0000-0003-4495-225X; ibrahim, Elhossiny/0000-0001-5421-2170
CR [Anonymous], 2015, ACS SUSTAIN CHEM ENG
   Ayilara OF, 2019, HEALTH QUAL LIFE OUT, V17, DOI 10.1186/s12955-019-1181-2
   Azimi I, 2019, FUTURE GENER COMP SY, V96, P297, DOI 10.1016/j.future.2019.02.015
   Azur MJ, 2011, INT J METH PSYCH RES, V20, P40, DOI 10.1002/mpr.329
   Bartlett JW, 2015, STAT METHODS MED RES, V24, P462, DOI 10.1177/0962280214521348
   Biessmann F, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2017, DOI 10.1145/3269206.3272005
   Choi J, 2019, EUR J EPIDEMIOL, V34, P23, DOI 10.1007/s10654-018-0447-z
   Donders ART, 2006, J CLIN EPIDEMIOL, V59, P1087, DOI 10.1016/j.jclinepi.2006.01.014
   Dzulkalnine MF, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-0383-x
   Farhangfar A, 2008, PATTERN RECOGN, V41, P3692, DOI 10.1016/j.patcog.2008.05.019
   Leurent B, 2020, HEALTH ECON, V29, P171, DOI 10.1002/hec.3963
   LI X, HLTH EC UK, P1
   Maniruzzaman M, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0940-7
   Moore, 2017, MISSING DATA IMPUTAT, P208
   Noor MN, 2014, KEY ENG MATER, V594-595, P902, DOI 10.4028/www.scientific.net/KEM.594-595.902
   Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882
   Qiu Y.L., 2018, A deep learning framework for imputing missing values in genomic data, P406066
   Sedik A, 2019, INT J SPEECH TECHNOL, V22, P739, DOI 10.1007/s10772-019-09610-z
   Sherif AS., 2011, IJCSI, V8, P133
   Stekhoven DJ, 2012, BIOINFORMATICS, V28, P112, DOI 10.1093/bioinformatics/btr597
   Sunith L., 2014, International Journal of Advanced Research in Computer and Communication Engineering, V3, P7255
   Tang F, 2017, STAT ANAL DATA MIN, V10, P363, DOI 10.1002/sam.11348
   Yilmaz N, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0048-7
   Zhang ZH, 2016, ANN TRANSL MED, V4, DOI 10.3978/j.issn.2305-5839.2015.12.38
NR 24
TC 2
Z9 2
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 20125
EP 20147
DI 10.1007/s11042-021-10727-0
EA MAR 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000625612900001
DA 2024-07-18
ER

PT J
AU Agarwal, G
   Om, H
AF Agarwal, Gaurav
   Om, Hari
TI Performance of deer hunting optimization based deep learning algorithm
   for speech emotion recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech emotion recognition; Adaptive wavelet transform; Modified
   galactic swarm optimization; Adaptive sunflower optimization algorithm;
   Optimized deep neural network; Deer hunting optimization algorithm
ID IDENTIFICATION; SYSTEM; VOICE
AB This paper proposes a speech emotion recognition technique based on Optimized Deep Neural Network. The speech signals are denoised by presenting a novel adaptive wavelet transform with a modified galactic swarm optimization algorithm (AWT_MGSO). From the noise removed speech signals, the spectral features like LPC (Linear Prediction Coefficients), MFCC (Mel frequency cepstral coefficients), PSD (power spectral density) and prosodic features like energy, entropy, formant frequencies and pitch are extracted and certain features are selected by ASFO (Adaptive Sunflower Optimization Algorithm). The optimized DNN-DHO (Deep Neural Network with Deer Hunting Optimization Algorithm) is proposed for emotion classification. An enhanced squirrel search algorithm is proposed to update the weight in the optimized DNN_DHO classifier. In this study, all the eight emotions of the speech from RAVDESS (Ryerson Audio-Visual Database of Emotional Speech and Song) and TESS (Toronto Emotional Speech Set) databases for English and IITKGP-SEHSC (Indian Institute of Technology Kharagpur Simulated Emotion Hindi Speech Corpus) database for Hindi are classified. The experimental results are obtained and compared with the classifiers such as DNN_DHO, DNN (Deep Neural Network) and DAE (Deep Auto Encoder). The experimental results show that the proposed algorithm obtains maximum accuracy as 97.85% by the TESS dataset, 97.14% by the RAVDESS dataset and 93.75% by the IITKGP-SEHSC dataset by the DNN-HHO classifier.
C1 [Agarwal, Gaurav; Om, Hari] IIT ISM, Dept Comp Sci & Engn, Dhanbad 826004, Jharkhand, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Agarwal, G (corresponding author), IIT ISM, Dept Comp Sci & Engn, Dhanbad 826004, Jharkhand, India.
EM gaurav13shaurya@gmail.com
RI OM, HARI/AAY-6011-2021; Agarwal, Gaurav/HSG-8834-2023
OI OM, HARI/0000-0002-9750-2706; 
CR Al-Anzi F., 2018, PROC INT C COMPUT SC, P1, DOI 10.1109/ICCSE1.2018.8374215
   [Anonymous], 2018, P SPEECH LANG PROC H
   Arafa Moner N. M., 2018, International Journal of Image, Graphics and Signal Processing, V10, P31, DOI 10.5815/ijigsp.2018.04.04
   Arora V, 2018, J ACOUST SOC AM, V143, P98, DOI 10.1121/1.5017834
   Awan S. K., 2018, 2018 Systems and Information Engineering Design Symposium (SIEDS), P159, DOI 10.1109/SIEDS.2018.8374728
   Badshah AM, 2019, MULTIMED TOOLS APPL, V78, P5571, DOI 10.1007/s11042-017-5292-7
   Barker J, 2018, INTERSPEECH, P1561, DOI 10.21437/Interspeech.2018-1768
   Bernal E, 2018, STUD COMPUT INTELL, V749, P131, DOI 10.1007/978-3-319-71008-2_11
   Bhavan A, 2019, KNOWL-BASED SYST, V184, DOI 10.1016/j.knosys.2019.104886
   Brammya G, 2019, COMPUT J
   Choudhary, 2018, SPEECH LANGUAGE PROC, P195, DOI DOI 10.1007/978-981-10-6626-9_22
   Daqrouq K, 2015, APPL SOFT COMPUT, V27, P231, DOI 10.1016/j.asoc.2014.11.016
   Darabkh KA, 2018, COMPUT APPL ENG EDUC, V26, P285, DOI 10.1002/cae.21884
   Gardini S., 2018, DATA PREPARATION IMP
   Gomes GF, 2019, ENG COMPUT-GERMANY, V35, P619, DOI 10.1007/s00366-018-0620-8
   Gong N, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04485-1
   Hamsa S, 2020, IEEE ACCESS, V8, P96994, DOI 10.1109/ACCESS.2020.2991811
   Haridas AV, 2018, INT J KNOWL-BASED IN, V22, P39, DOI 10.3233/KES-180374
   Huang CZ., 2018, IEEE T AFFECT COMPUT, V1, P1
   Karle KN, 2018, SOC COGN AFFECT NEUR, V13, P233, DOI 10.1093/scan/nsy001
   Koolagudi SG, 2011, 2011 international conference on devices and communications (ICDeCom), P1
   Latif S, 2020, IEEE T AFFECT COMPUT
   Liu JC, 2018, CONCURR COMP-PRACT E, V30, DOI 10.1002/cpe.4255
   Livingstone SR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196391
   Mirzaei MS, 2018, COMPUT SPEECH LANG, V49, P17, DOI 10.1016/j.csl.2017.11.001
   Moro-Velázquez L, 2018, APPL SOFT COMPUT, V62, P649, DOI 10.1016/j.asoc.2017.11.001
   Mustaqeem, 2020, IEEE ACCESS, V8, P79861, DOI 10.1109/ACCESS.2020.2990405
   Mustaqeem, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010183
   Özseven T, 2019, APPL ACOUST, V146, P320, DOI 10.1016/j.apacoust.2018.11.028
   Patel P., 2017, International Journal of Research In Science & Engineering, V3
   Price M, 2018, IEEE J SOLID-ST CIRC, V53, P66, DOI 10.1109/JSSC.2017.2752838
   Song P, 2020, IEEE T AFFECT COMPUT, V11, P373, DOI 10.1109/TAFFC.2018.2800046
   Vryzas N, 2020, J AUDIO ENG SOC, V68, P14, DOI 10.17743/jaes.2019.0043
   Wei PC, 2019, PERS UBIQUIT COMPUT, V23, P521, DOI 10.1007/s00779-019-01246-9
   Zhang Y, 2016, ENG APPL ARTIF INTEL, V50, P245, DOI 10.1016/j.engappai.2016.01.032
   Zhao JF, 2019, BIOMED SIGNAL PROCES, V47, P312, DOI 10.1016/j.bspc.2018.08.035
NR 36
TC 27
Z9 27
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 9961
EP 9992
DI 10.1007/s11042-020-10118-x
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO7LK
UT WOS:000641223300002
DA 2024-07-18
ER

PT J
AU Asan, MA
   Ozsoy, A
AF Asan, M. Ali
   Ozsoy, Adnan
TI cuRCD: Region covariance descriptor CUDA implementation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Parallel region covariance; CUDA; Real time object detection; GPGPU
ID TRACKING; GPU
AB Region covariance is a robust feature descriptor that allows the use of even the simplest image features like intensity and gradient combined to form a well-performing descriptor for regions on the image. Beyond its robustness, it requires many identical heavy computations on different parts of input data which makes it a good candidate for parallel execution. In this manuscript, we present a real-time parallel implementation of the region covariance which, to our best knowledge, is the first in the literature. We experimented against existing implementations and achieved 6 times faster execution time over vectorized CPU parallel implementation that provides necessary speed up for real-time processing. Additionally, we improved the existing integral image calculation method on CUDA, reducing memory usage by 50%, achieving the fastest computation speed compared to exist- ing solutions, and improved the covariance matrix comparison metric by using a distance metric that is lightweight to compute and easy to implement.
C1 [Asan, M. Ali; Ozsoy, Adnan] Hacettepe Univ, Comp Engn Dept, Ankara, Turkey.
C3 Hacettepe University
RP Ozsoy, A (corresponding author), Hacettepe Univ, Comp Engn Dept, Ankara, Turkey.
EM adnan.ozsoy@hacettepe.edu.tr
RI OZSOY, ADNAN/M-5714-2018
OI OZSOY, ADNAN/0000-0002-0302-3721
CR Acharya KA, 2018, J REAL-TIME IMAGE PR, V14, P267, DOI 10.1007/s11554-014-0446-6
   Artner NM, 2011, PATTERN RECOGN, V44, P800, DOI 10.1016/j.patcog.2010.10.025
   Awad AI, 2013, INFORM-J COMPUT INFO, V37, P279
   Bailey T, 2006, IEEE ROBOT AUTOM MAG, V13, P108, DOI 10.1109/MRA.2006.1678144
   Bilgic B, 2010, IEEE INT VEH SYM, P528, DOI 10.1109/IVS.2010.5548142
   Cakir S, 2013, OPT ENG, V52, DOI 10.1117/1.OE.52.2.027207
   Chang CH, 2016, J REAL-TIME IMAGE PR, V12, P567, DOI 10.1007/s11554-015-0539-x
   CHENG J., 2014, Professional CUDA c Programming
   Cherian A, 2011, IEEE I CONF COMP VIS, P2399, DOI 10.1109/ICCV.2011.6126523
   Coifman B, 1998, TRANSPORT RES C-EMER, V6, P271, DOI 10.1016/S0968-090X(98)00019-9
   Fassold H, 2015, PROC SPIE, V9400, DOI 10.1117/12.2083201
   Faulkner H, 2015, GEODESY THE CHALLENG
   Forsyth DA, 2002, COMPUTER VISION MODE, P88
   Genc, 2011, MACH VISION APPL, V22, P202
   Harris M., 2007, Parallel prefix sum (scan) with cuda
   KANOPOULOS N, 1988, IEEE J SOLID-ST CIRC, V23, P358, DOI 10.1109/4.996
   Karacan L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508403
   Liu ST, 2018, J SYST ENG ELECTRON, V29, P483, DOI 10.21629/JSEE.2018.03.05
   Lu XK, 2021, IEEE T CIRC SYST VID, V31, P1268, DOI 10.1109/TCSVT.2019.2944654
   Lu XK, 2019, NEUROCOMPUTING, V349, P133, DOI 10.1016/j.neucom.2019.02.021
   Mader K, 2012, ARXIV PREPRINT ARXIV
   Mehrez, 2018, J REAL-TIME IMAGE PR, P1
   Myung Hwan Tak, 2016, Transactions of the Korean Institute of Electrical Engineers, V65, P1738, DOI 10.5370/KIEE.2016.65.10.1738
   Nguyen H, 2007, GPU GEMS
   Paramkusham S, 2013, 2013 15 INT C ADV CO, P1
   Polap Dawid., 2019, 2019 International Joint Conference on Neural Networks (IJCNN), P1, DOI DOI 10.1109/IJCNN.2019.8851958
   Rister B, 2013, INT CONF ACOUST SPEE, P2674, DOI 10.1109/ICASSP.2013.6638141
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Yang XM, 2019, J REAL-TIME IMAGE PR, V16, P115, DOI 10.1007/s11554-018-0803-y
NR 32
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19737
EP 19751
DI 10.1007/s11042-021-10644-2
EA MAR 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000623093800001
DA 2024-07-18
ER

PT J
AU Kumar, GA
   Sridevi, PV
AF Kumar, G. Anand
   Sridevi, P. V.
TI E-fuzzy feature fusion and thresholding for morphology segmentation of
   brain MRI modalities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Segmentation; Magnetic resonance imaging; Feature extraction; Brain
   tumor; Fuzzy-feature fusion; Thresholding; Morphology operators
ID TUMOR SEGMENTATION; FEATURE-SELECTION
AB Brain tumor segmentation is a significant procedure in medical image processing. Effective and efficient segmentation is always a key concern for the radiologists due to the presence of low illumination in imaging modalities of Magnetic Resonance (MR) imaging. Some of the challenging issues addressed in this paper are the sensitivity of noise, variations, and non-standardization in inter-slice intensity, and intensity inhomogeneity. A reliable segmentation method for the brain tumor segmentation is necessary for efficient measurement of the tumor. The foremost objective of the research is to fuse the different modalities of MRI images by considering the most useful features to obtain the best segmentation. Sufficient diagnostic information in clinical applications is not provided by single modality images. Therefore, combining the features of different modalities of images is vital. Recently, many researchers applied many techniques for fusing medical images, still many issues are to be addressed. Hence, to combine different modality of images, a novel fusion method is proposed. Our proposed work contains four stages (i) pre-processing, (ii) feature extraction (iii) feature fusion, and (iv) segmentation. In the pre-processing step, the image quality is increased and the unwanted noise is removed using average filtering. In the feature extraction stage, the Extended Grey Level Co-occurrence Matric (E-GLCM) is introduced to extract the suitable intensity and texture features of brain tumor MRI images. To fuse the correct features for efficient segmentation, the Enhanced Fuzzy Radial Basis function Neural Network (E-FRBNN) incorporates five layer inputs, fuzzy partition, front combination, inference, and output. Finally, the segmentation is carried by thresholding based segmentation approach with morphology operators. The simulation results of the proposed segmentation procedure acquire competitive performance when compared with the existing techniques for the BRATS 2015 dataset.
C1 [Kumar, G. Anand; Sridevi, P. V.] Andhra Univ, Coll Engn Autonomous, Dept Elect & Commun Engn, Visakhapatnam, Andhra Pradesh, India.
C3 Andhra University
RP Kumar, GA (corresponding author), Andhra Univ, Coll Engn Autonomous, Dept Elect & Commun Engn, Visakhapatnam, Andhra Pradesh, India.
EM anandkumar.g.408@gmail.com; sridevi.pv.111@gmail.com
RI SRIDEVI, PADAVALA/ABG-1461-2021
OI SRIDEVI, PADAVALA/0000-0001-5998-0232
CR Alansary A, 2016, IEEE J BIOMED HEALTH, V20, P925, DOI 10.1109/JBHI.2015.2415477
   [Anonymous], 2017, NEUROIMAGE
   Binaghi Elisabetta, 2014, Proceedings of the International Conference on Neural Computation Theory and Applications NCTA 2014, P152
   Dasarathy B., 2015, ARXIV PREPRINT ARXIV
   Deepa AR, 2019, MULTIMED TOOLS APPL, V78, P11799, DOI 10.1007/s11042-018-6731-9
   Deng Y, 2017, IEEE T FUZZY SYST, V25, P1006, DOI 10.1109/TFUZZ.2016.2574915
   Despotovic I, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/450341
   Dimitriadis SI, 2018, J NEUROSCI METH, V302, P14, DOI 10.1016/j.jneumeth.2017.12.010
   El-Dahshan ESA, 2014, EXPERT SYST APPL, V41, P5526, DOI 10.1016/j.eswa.2014.01.021
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Isin A, 2016, PROCEDIA COMPUT SCI, V102, P317, DOI 10.1016/j.procs.2016.09.407
   Islam A, 2013, IEEE T BIO-MED ENG, V60, P3204, DOI 10.1109/TBME.2013.2271383
   Kwon D, 2014, LECT NOTES COMPUT SC, V8673, P763, DOI 10.1007/978-3-319-10404-1_95
   Lahmiri S, 2017, BIOMED SIGNAL PROCES, V31, P148, DOI 10.1016/j.bspc.2016.07.008
   Lakshmi A., 2017, ARAB J SCI ENG, P1
   Lesage D, 2009, MED IMAGE ANAL, V13, P819, DOI 10.1016/j.media.2009.07.011
   Ma C, 2018, IEEE T MED IMAGING, V37, P1943, DOI 10.1109/TMI.2018.2805821
   Mangai UG, 2010, IETE TECH REV, V27, P293, DOI 10.4103/0256-4602.64604
   Meng X, 2017, NEUROIMAGE, V145, P218, DOI 10.1016/j.neuroimage.2016.05.026
   Nabizadeh N., 2015, Automated Brain Lesion Detection and Segmentation Using Magnetic Resonance Images
   Nongmeikapam K, 2018, IET IMAGE PROCESS, V12, P513, DOI 10.1049/iet-ipr.2017.1102
   Parekh P, 2014, INT J COMPUTER APPL, V90
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Rajinikanth V., 2018, Microelectronics, Electromagnetics and Telecommunications. Proceedings of ICMEET 2017. LNEE 471, P453, DOI 10.1007/978-981-10-7329-8_46
   REED TR, 1993, CVGIP-IMAG UNDERSTAN, V57, P359, DOI 10.1006/ciun.1993.1024
   Selvapandian A, 2018, COMPUT METH PROG BIO, V166, P33, DOI 10.1016/j.cmpb.2018.09.006
   Shattuck DW, 2001, NEUROIMAGE, V13, P856, DOI 10.1006/nimg.2000.0730
   Sun QS, 2005, PATTERN RECOGN, V38, P2437, DOI 10.1016/j.patcog.2004.12.013
   Varuna Shree N, 2018, Brain Inform, V5, P23, DOI 10.1007/s40708-017-0075-5
   Zhang N, 2011, COMPUT VIS IMAGE UND, V115, P256, DOI 10.1016/j.cviu.2010.09.007
   Zhao XM, 2018, MED IMAGE ANAL, V43, P98, DOI 10.1016/j.media.2017.10.002
   Zulpe N., 2012, Int. J. Comput. Sci. Issues (IJCSI), V9, P354
NR 32
TC 7
Z9 7
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19715
EP 19735
DI 10.1007/s11042-020-08760-6
EA MAR 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000623716500006
DA 2024-07-18
ER

PT J
AU Nahta, R
   Meena, YK
   Gopalani, D
   Chauhan, GS
AF Nahta, Ravi
   Meena, Yogesh Kumar
   Gopalani, Dinesh
   Chauhan, Ganpat Singh
TI Embedding metadata using deep collaborative filtering to address the
   cold start problem for the rating prediction task
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender systems; Collaborative filtering; Cold start problem; Neural
   networks; Matrix factorization; Metadata
AB In recent years, deep learning has yielded success in many research fields including machine translation, natural language processing, computer vision, and social network filtering. The area of deep learning in the recommender system is flourishing. Previous research has relied on incorporating metadata information in various application domains using deep learning techniques to achieve better recommendation accuracy. The use of metadata is desirable to address the cold start problem and better learning the user-item interaction, which is not captured by the user-item rating matrix. Existing methods rely on fixed user-item latent representation and ignore the metadata information. It restricts the model performance to correctly identify actual latent vectors, which results in high rating prediction error. To tackle these problems, we propose a generalized recommendation model named Meta Embedding Deep Collaborative Filtering (MEDCF), which inputs user demographics and item genre as metadata features together with the rating matrix. The proposed framework primarily comprises of Generalized Matrix Factorization (GMF), Multilayer Perceptron (MLP), and Neural Matrix Factorization (NeuMF) methods. GMF is applied to the rating matrix, whereas MLP is applied to metadata. Using NeuMF, the outputs for GMF and MLP are then concatenated and input to a neural network for rating prediction. To prove the effectiveness of proposed model, two metrics are used, Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE). The MEDCF model is experimented on MovieLens and Amazon Movies datasets showing a significant improvement over the baseline methods.
C1 [Nahta, Ravi; Meena, Yogesh Kumar; Gopalani, Dinesh; Chauhan, Ganpat Singh] Malaviya Natl Inst Technol, Dept Comp Sci & Engn, Jaipur, Rajasthan, India.
C3 National Institute of Technology (NIT System); Malaviya National
   Institute of Technology Jaipur
RP Nahta, R (corresponding author), Malaviya Natl Inst Technol, Dept Comp Sci & Engn, Jaipur, Rajasthan, India.
EM 2018rcp9077@mnit.ac.in; ymeena.cse@mnit.ac.in; dgopalani.cse@mnit.ac.in;
   2018rcp9063@mnit.ac.in
RI Meena, Yogesh/GZH-0796-2022; Chauhan, Ganpat/GLT-3511-2022; Nahta,
   Ravi/P-4622-2018
OI Chauhan, Ganpat/0000-0003-0193-4297; MEENA, YOGESH/0000-0001-5380-3892;
   Nahta, Ravi/0000-0001-7085-9230
CR Al-Shamri MYH, 2016, KNOWL-BASED SYST, V100, P175, DOI 10.1016/j.knosys.2016.03.006
   Bai T, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1979, DOI 10.1145/3132847.3133083
   Bennett J, 2007, P KDD CUP WORKSH, P3
   Callvik J, 2017, USING DEMOGRAPHIC IN
   Cheng ZY, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3291060
   Cheng ZY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3748
   D'Addio RM, 2019, INFORM SYST, V83, P1, DOI 10.1016/j.is.2019.01.008
   Dong X, 2017, AAAI CONF ARTIF INTE, P1309
   Ekstrand Michael D., 2018, C FAIRNESS ACCOUNTAB, P172
   Elkahky A, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P278, DOI 10.1145/2736277.2741667
   Fernández-Tobías I, 2019, USER MODEL USER-ADAP, V29, P443, DOI 10.1007/s11257-018-9217-6
   Gleichman S, 2011, IEEE T INFORM THEORY, V57, P6958, DOI 10.1109/TIT.2011.2165821
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Guan XY, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3309546
   Gunawardana A, 2009, J MACH LEARN RES, V10, P2935
   Hamilton WL, 2017, ADV NEUR IN, V30
   Hastie T, 2015, J MACH LEARN RES, V16, P3367
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He X., 2016, Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval, P549
   He XN, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P639, DOI 10.1145/3397271.3401063
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Hsieh CK, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P193, DOI 10.1145/3038912.3052639
   Hu YF, 2008, IEEE DATA MINING, P263, DOI 10.1109/ICDM.2008.22
   Kaden Z, 2018, ARXIV180606192
   Kim D, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P233, DOI 10.1145/2959100.2959165
   Kim KS, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11040561
   Kingma D. P., 2014, arXiv
   Koren Y., 2008, P 14 ACM SIGKDD INT, P426
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Kula M, 2015, Proceedings of the 2nd Workshop on New Trends on Content-Based Recommender Systems co-located with 9th ACM Conference on Recommender Systems (RecSys 2015), Vienna, Austria, September 16-20, 2015, P14
   Lehmann, 2019, RECNLP WORKSH AAAI W
   Li D., 2017, P ANN C NEUR INF PRO, P477
   Liu DH, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P344, DOI 10.1145/3292500.3330906
   Liu F, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1526, DOI 10.1145/3343031.3350953
   Liu TQ, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3027, DOI 10.1145/3308558.3313580
   Luo X, 2020, IEEE T CYBERNETICS, V50, P1844, DOI 10.1109/TCYB.2019.2894283
   Ma H., 2008, P 17 ACM C INF KNOWL, P931, DOI [DOI 10.1145/1458082.1458205, 10.1145/1458082.1458205]
   Majumdar A, 2015, ARXIV150501621
   McAuley Julian, 2013, RECSYS
   Mittal P, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2659, DOI 10.1109/ICACCI.2014.6968531
   Rendle Steffen, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P995, DOI 10.1109/ICDM.2010.127
   Rendle S., 2009, P 25 C UNC ART INT, P452, DOI DOI 10.5555/1795114.1795167
   Salakhutdinov Ruslan, 2008, ADV NEURAL INFORM PR, P1257, DOI DOI 10.5555/2981562.2981720
   Sarwar B, 2002, 5 INT C COMPUTER INF, P27
   SEDHAIN S, 2015, P 24 INT C WORLD WID, P111, DOI DOI 10.1145/2740908.2742726
   Shang J, 2018, IEEE DATA MINING, P1218, DOI 10.1109/ICDM.2018.00162
   Shang MS, 2019, IEEE-CAA J AUTOMATIC, V6, P131, DOI 10.1109/JAS.2018.7511189
   Singh A, 2008, INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, P650
   Soares M, 2015, MULTIMED TOOLS APPL, V74, P7015, DOI 10.1007/s11042-014-1950-1
   Socher R., 2013, ADV NEURAL INFORM PR, V26, P1
   Srebro N., 2005, ADV NEURAL INFORM PR, P1329
   Sridevi M., 2017, Advances in Computational Sciences and Technology, V10, P1969
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Strub F., 2016, P 1 WORKSH DEEP LEAR, P11
   Tang DY, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1340
   Do TDT, 2018, AAAI CONF ARTIF INTE, P2918
   Vasile F, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P225, DOI 10.1145/2959100.2959160
   Vozalis M, 2004, AIAI S PROF PRACT AI
   Wang Chong, 2011, P 17 ACM SIGKDD INT, P448, DOI [DOI 10.1145/2020408.2020480, 10.1145/2020408.2020480]
   Wang H, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1235, DOI 10.1145/2783258.2783273
   Wang M, 2016, IEEE T KNOWL DATA EN, V28, P1864, DOI 10.1109/TKDE.2016.2535367
   Wang SH, 2018, IEEE T KNOWL DATA EN, V30, P1022, DOI 10.1109/TKDE.2018.2789443
   Wang X, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P165, DOI 10.1145/3331184.3331267
   Wu D, 2021, IEEE T SYST MAN CY-S, V51, P4285, DOI 10.1109/TSMC.2019.2931393
   Wu Y, 2016, PROCEEDINGS OF THE NINTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'16), P153, DOI 10.1145/2835776.2835837
   Xiao T., 2019, P 33 AAAI C ART INT
   Xin L, 2021, IEEE T SYST MAN CY-S, V51, P4612, DOI 10.1109/TSMC.2019.2931468
   Yoon YC, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P91
   Zhang HW, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P325, DOI 10.1145/2911451.2911502
   Zhang HW, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P187, DOI 10.1145/2647868.2654915
NR 71
TC 8
Z9 11
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18553
EP 18581
DI 10.1007/s11042-021-10529-4
EA FEB 2021
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000619425300001
DA 2024-07-18
ER

PT J
AU Deng, ZJ
   Liu, YW
   Liu, JX
   Argyriou, A
AF Deng, Zhenjie
   Liu, Yanwei
   Liu, Jinxia
   Argyriou, Antonios
TI Cross-layer DASH-based multipath video streaming over LTE and 802.11ac
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DASH; Multipath; LTE; 802; 11ac; Video streaming; MCS
ID ADAPTATION; FAIRNESS
AB Dynamic Adaptive Streaming over Http (DASH) -based video streaming applications are becoming increasingly prevalent over the mobile Internet. Many efforts have been made to optimize their performances. Multipath video streaming that simultaneously utilizes multiple wireless networks for video content delivery is a common method. Another effective approach is the cross-layer video streaming optimization that jointly takes the parameters at different protocol layers into account. However, multipath streaming schemes mainly focus on how to efficiently utilize multiple wireless networks and the collaboration of parameters at different layers in each network is neglected. Likewise, the cross-layer schemes normally optimize the parameters at different layers in purely one network without fully utilizing the aggregated bandwidths of multiple available wireless networks. Therefore, both of them are sub-optimal and might suffer from degrading performance. In this paper, we propose a joint Cross-layer DASH-based multipath video streaming scheme that takes advantage of bandwidth aggregation of multiple wireless networks and further improves the performance by optimizing the different layers' parameters in each network with a cross-layer manner. In the proposed scheme, the LTE and 802.11ac networks are adopted. The bitrate of DASH-based video chunk at application layer, the rate allocation among networks and the Modulation and Coding Scheme (MCS) at physical layers in LTE and 802.11ac downlink are jointly optimized. We also compare our proposed scheme to state-of-the-art schemes using trace-driven experiments. Experimental results show that our proposed scheme outperforms state-of-the-art schemes in terms of PSNR, normalized QoE, and balance between video bitrate and rebuffering penalty.
C1 [Deng, Zhenjie] Guangdong Univ Finance, Guangzhou, Guangdong, Peoples R China.
   [Liu, Yanwei] Chinese Acad Sci, Inst Informat Engn, Beijing, Peoples R China.
   [Liu, Jinxia] Zhejiang Wanli Univ, Ningbo, Peoples R China.
   [Argyriou, Antonios] Univ Thessaly, Volos, Greece.
C3 Guangdong University of Finance; Chinese Academy of Sciences; Institute
   of Information Engineering, CAS; Zhejiang Wanli University; University
   of Thessaly
RP Deng, ZJ (corresponding author), Guangdong Univ Finance, Guangzhou, Guangdong, Peoples R China.
EM 47-047@gduf.edu.cn; liuyanwei@iie.ac.cn
RI Argyriou, Antonios/AAF-9586-2021; Liu, Jinxia/H-1794-2011
OI Argyriou, Antonios/0000-0002-2510-3124; deng,
   zhenjie/0000-0002-3432-2169
FU National Natural Science Foundation of China [61771469]; Ningbo Natural
   Science Foundation [2019A610109]
FX This work was supported in part by National Natural Science Foundation
   of China under Grant 61771469 and Ningbo Natural Science Foundation
   under Grant 2019A610109.
CR Andrews JG, 2014, IEEE J SEL AREA COMM, V32, P1065, DOI 10.1109/JSAC.2014.2328098
   [Anonymous], 2016, VISUAL NETWORKING IN
   [Anonymous], 2017, 2017 IEEE INT C COMM
   Argyriou A, 2015, IEEE T MULTIMEDIA, V17, P736, DOI 10.1109/TMM.2015.2408254
   Bruneau-Queyreix J, 2018, IEEE MULTIMEDIA, V25, P65, DOI 10.1109/MMUL.2018.112142627
   Caire G, 2007, IEEE T INFORM THEORY, V53, P1366, DOI 10.1109/TIT.2007.892790
   Campanile, 2020, NETWORK SIMULATOR NS
   Chang CY, 2017, IEEE SYST J, V11, P2546, DOI 10.1109/JSYST.2015.2431291
   Chen YC, 2016, IEEE J SEL AREA COMM, V34, P2198, DOI 10.1109/JSAC.2016.2577322
   Deng ZJ, 2016, 2016 IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATION (ISCC), P868, DOI 10.1109/ISCC.2016.7543845
   Elgabli A, 2019, IEEE T VEH TECHNOL, V68, P6975, DOI 10.1109/TVT.2019.2915355
   Evensen K, 2010, NOSSDAV 2010: PROCEEDINGS OF THE 20TH INTERNATIONAL WORKSHOP ON NETWORK AND OPERATING SYSTEMS SUPPORT FOR DIGITAL AUDIO AND VIDEO, P21
   Han B, 2016, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON EMERGING NETWORKING EXPERIMENTS AND TECHNOLOGIES (CONEXT'16), P129, DOI 10.1145/2999572.2999606
   Ho D, 2018, IEEE T MOBILE COMPUT, V17, P1090, DOI 10.1109/TMC.2017.2748592
   Huang TY, 2014, SIGCOMM'14: PROCEEDINGS OF THE 2014 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P187, DOI 10.1145/2619239.2626296
   James C, 2016, I S MOD ANAL SIM COM, P331, DOI 10.1109/MASCOTS.2016.75
   Jensen TL, 2010, IEEE T VEH TECHNOL, V59, P3766, DOI 10.1109/TVT.2010.2053727
   Jiang JC, 2014, IEEE ACM T NETWORK, V22, P326, DOI 10.1109/TNET.2013.2291681
   Koo J, 2019, IEEE T MOBILE COMPUT, V18, P1647, DOI 10.1109/TMC.2018.2863234
   Mao HZ, 2017, SIGCOMM '17: PROCEEDINGS OF THE 2017 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P197, DOI 10.1145/3098822.3098843
   Ong EH, 2011, 2011 IEEE 22ND INTERNATIONAL SYMPOSIUM ON PERSONAL INDOOR AND MOBILE RADIO COMMUNICATIONS (PIMRC), P849, DOI 10.1109/PIMRC.2011.6140087
   Sesia S., 2011, LTE UMTS LONG TERM E
   Spiteri K., 2020, IEEE ACM T NETWORKIN
   Stockhammer T., 2011, P 2 ANN ACM C MULTIM, P133
   Sun Y, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '16), P272, DOI 10.1145/2934872.2934898
   Taranetz M, 2015, IEEE ACCESS, V3, P725, DOI 10.1109/ACCESS.2015.2437903
   Tourapis, 2020, H 264 MPEG 4AVC REFE
   Viernickel T, 2018, IEEE ICC
   Xing M, 2014, IEEE J SEL AREA COMM, V32, P795, DOI 10.1109/JSAC.2014.140411
   Yazid M, 2018, IEEE T VEH TECHNOL, V67, P10243, DOI 10.1109/TVT.2018.2870127
   Yin XQ, 2015, ACM SIGCOMM COMP COM, V45, P325, DOI 10.1145/2785956.2787486
   Yoon D, 2000, IEEE VTS VEH TECHNOL, P2422, DOI 10.1109/VETECF.2000.883298
   Zhao PH, 2016, SIGNAL PROCESS-IMAGE, V40, P36, DOI 10.1016/j.image.2015.11.005
NR 33
TC 4
Z9 4
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 16007
EP 16026
DI 10.1007/s11042-020-10393-8
EA FEB 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000615771800002
DA 2024-07-18
ER

PT J
AU Sun, XN
   Shao, ZH
   Shang, YY
   Liang, MX
   Yang, FJ
AF Sun, Xiaoni
   Shao, Zhuhong
   Shang, Yuanyuan
   Liang, Mingxian
   Yang, Fengjian
TI Multiple-image encryption based on cascaded gyrator transforms and
   high-dimensional chaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple-image encryption; Fractional order Chua&#8217; s system;
   Cascaded gyrator transforms; Sharing; Kronecker product
ID SEMI-TENSOR PRODUCT; PHASE RETRIEVAL; WAVELET TRANSFORM; COLOR IMAGES;
   SECRET KEY; ALGORITHM; MAP
AB In order to increase encryption capacity and improve transmission efficiency, this paper investigates an encryption scheme for multiple-image based on cascaded gyrator transforms and high-dimensional chaos. Firstly, each plainimage is converted into a real matrix through modulation, quaternion gyrator transform and sharing. The real matrices are connected in turn by plural coding and gyrator transforms. During the process of cascade, phase truncation and preservation operations are performed. The phase of the preceding transformation is modulated by that of the latter complex matrix to enhance security. Followed by splicing and scrambling, a real-valued ciphertext can be obtained. At the receiver end, all the plaintext images can be restituted by the reverse operation of the encryption process using the authorized keys. The adoption of high-dimensioanl chaos and Kronecker product further guarantees the security of the cryptosystem. The numerical results performed on 300 color images have demonstrated that the average PSNR of correctly decrypted images is up to 303.9939 dB, the NMSE is as low as 2.8024 x 10(-28) and SSIM is equal to 1.0000. The analysis of sensitivity, statistical characteristic and robustness proves the feasibility and relibility of the proposed encryption scheme.
C1 [Sun, Xiaoni; Shao, Zhuhong; Shang, Yuanyuan] Capital Normal Univ, Coll Informat Engn, Beijing 100048, Peoples R China.
   [Shang, Yuanyuan] Beijing Adv Innovat Ctr Imaging Technol, Beijing 100048, Peoples R China.
   [Liang, Mingxian] Hosp Tradit Chinese Med Wuzhou City, Wuzhou 543002, Peoples R China.
   [Yang, Fengjian] Jilin Med Univ, Jilin 132013, Jilin, Peoples R China.
C3 Capital Normal University; Jilin Medical University
RP Shao, ZH (corresponding author), Capital Normal Univ, Coll Informat Engn, Beijing 100048, Peoples R China.
EM zhshao@cnu.edu.cn
RI Shang, Yuanyuan/ACH-0016-2022; Shao, Zhuhong/AAD-4129-2022
OI Shang, Yuanyuan/0000-0003-4219-2541; 
FU National Natural Science Foundation of China [61876112, 61601311];
   Project of Beijing Excellent Talents [2016000020124G088]; Beijing
   Municipal Education Research Plan Project [SQKM201810028018]
FX This work was supported by the National Natural Science Foundation of
   China (61876112, 61601311), Project of Beijing Excellent Talents
   (2016000020124G088) and Beijing Municipal Education Research Plan
   Project (SQKM201810028018).
CR Abdelfattah M, 2020, OPT LASER ENG, V129, DOI 10.1016/j.optlaseng.2020.106063
   Abuturab MR, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105810
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bhatnagar G, 2013, INFORM SCIENCES, V223, P297, DOI 10.1016/j.ins.2012.09.053
   Chen BJ, 2018, IET IMAGE PROCESS, V12, P2238, DOI 10.1049/iet-ipr.2018.5440
   Chen H, 2018, OPT LASER ENG, V107, P62, DOI 10.1016/j.optlaseng.2018.03.011
   Chidambaram N, 2020, IET IMAGE PROCESS, V14, P3143, DOI 10.1049/iet-ipr.2018.5654
   Czaplewski B, 2014, PATTERN RECOGN LETT, V46, P11, DOI 10.1016/j.patrec.2014.05.001
   Dorgham O, 2018, INT J CLOUD APPL COM, V8, P154, DOI 10.4018/IJCAC.2018010108
   Faragallah OS, 2020, IEEE ACCESS, V8, P103200, DOI 10.1109/ACCESS.2020.2994583
   Firdous A, 2019, MULTIMED TOOLS APPL, V78, P24809, DOI 10.1007/s11042-019-7623-3
   Ghadirli HM, 2019, SIGNAL PROCESS, V164, P163, DOI 10.1016/j.sigpro.2019.06.010
   Golea Nour El-Houda, 2019, International Journal of High Performance Computing and Networking, V13, P199
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Kang XJ, 2019, IEEE T CIRC SYST VID, V29, P1595, DOI 10.1109/TCSVT.2018.2851983
   Kaur M, 2020, ARCH COMPUT METHOD E, V27, P15, DOI 10.1007/s11831-018-9298-8
   Kumar A, 2019, INT J CLOUD APPL COM, V9, P22, DOI 10.4018/IJCAC.2019070102
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li XY, 2018, OPT LASER ENG, V102, P106, DOI 10.1016/j.optlaseng.2017.10.023
   Li Z, 2019, INT J HIGH PERFORM C, V14, P60, DOI [10.1504/IJHPCN.2019.099744, DOI 10.1504/IJHPCN.2019.099744]
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Luan GY, 2019, IEEE PHOTONICS J, V11, DOI 10.1109/JPHOT.2018.2886295
   Mamta Gupta B B, 2019, CONCURR COMP-PRACT E
   Mu Y., 2019, INT J HIGH PERFORM C, V14, P333, DOI [10.1504/IJHPCN.2019.102133, DOI 10.1504/IJHPCN.2019.102133]
   Paral P, 2014, 2 INT C ADV COMP NET
   Premkamal PK, 2020, INT J CLOUD APPL COM, V10, P28, DOI 10.4018/IJCAC.2020010103
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Shao ZH, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115662
   Shao ZH, 2018, MULTIMED TOOLS APPL, V77, P25821, DOI 10.1007/s11042-018-5818-7
   Shao ZH, 2018, MULTIMED TOOLS APPL, V77, P1285, DOI 10.1007/s11042-016-4279-0
   Shao ZH, 2014, OPT EXPRESS, V22, P4932, DOI 10.1364/OE.22.004932
   Sivaraman R, 2020, IET IMAGE PROCESS, V14, P2987, DOI 10.1049/iet-ipr.2019.0168
   Sui LS, 2018, OSA CONTINUUM, V1, P1370, DOI 10.1364/OSAC.1.001370
   Sui LS, 2019, OPT LASER ENG, V113, P29, DOI 10.1016/j.optlaseng.2018.10.002
   Wang Q, 2014, OPT COMMUN, V320, P12, DOI 10.1016/j.optcom.2014.01.041
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Yao QJ, 2020, MULTIMED TOOLS APPL, V79, P27555, DOI 10.1007/s11042-020-09296-5
   Ye HS, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107652
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Yu ZM, 2018, IEEE ACCESS, V6, P31918, DOI 10.1109/ACCESS.2018.2840119
   Zhang LZ, 2018, OPT LASER TECHNOL, V105, P162, DOI 10.1016/j.optlastec.2018.03.004
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zheng QM, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2017.2775038
NR 53
TC 23
Z9 23
U1 5
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15825
EP 15848
DI 10.1007/s11042-021-10550-7
EA FEB 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000615564900009
DA 2024-07-18
ER

PT J
AU Lu, PX
   Li, X
   Hu, LT
   Lu, L
AF Lu, Peixin
   Li, Xin
   Hu, Lianting
   Lu, Long
TI Integrating genomic and resting State fMRI for efficient autism spectrum
   disorder classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ASD; MKL; rs-fMRI; Genetic
ID DEFAULT MODE NETWORK; DE-NOVO VARIANTS; ALZHEIMERS-DISEASE; INTELLECTUAL
   DISABILITY; FUNCTIONAL CONNECTIVITY; GENES; MICRODELETION; MUTATIONS;
   12Q24.31; IDENTIFICATION
AB Autism spectrum disorder (ASD) is a neurodevelopmental disorder with a complex clinical syndrome and difficult diagnosis. The fusion of multimodal data improves the accuracy of ASD diagnosis, benefiting from the complementary information contained in the multimodal data. The aim of this study was to diagnose ASD using predictors based on integrated resting state MRI (rs-fMRI) and genetic data. Our study used fMRI and gene expression data from 71 participants in the National Database for Autism Research (NDAR). T-test and SVM-RFE were used for feature reduction and optimal feature selection. To make the best use of the features extracted from each data source, we used the EasyMKL to establish a classification model for the prediction of ASD rather than simply concatenating feature matrices. The experimental results validate the effectiveness of our method. In addition, the imaging and genetic features we extracted have been shown to be significantly associated with ASD supported by previous studies.
C1 [Lu, Peixin; Li, Xin; Hu, Lianting; Lu, Long] Wuhan Univ, Sch Informat Management, Wuhan, Peoples R China.
C3 Wuhan University
RP Lu, L (corresponding author), Wuhan Univ, Sch Informat Management, Wuhan, Peoples R China.
EM lupx@whu.edu.cn; XinLi2020@whu.edu.cn; liantinghu@whu.edu.cn;
   lulong@whu.edu.cn
RI Hu, Lianting/KOC-2697-2024
OI Hu, Lianting/0000-0003-4573-3809
CR AIOLLI F, 2015, NEUROCOMPUTING
   Aiolli F., 2014, EUROPEAN S ARTIFICIA, P289
   Anney RJL, 2017, MOL AUTISM, V8, DOI 10.1186/s13229-017-0137-9
   APA, 2013, DIAGNOSTIC STAT MANU, V5th ed.
   Baple E, 2010, MOL SYNDROMOL, V1, P42, DOI 10.1159/000275671
   Bishop-Fitzpatrick L, 2018, AUTISM RES, V11, P1120, DOI 10.1002/aur.1960
   Dai ZJ, 2012, NEUROIMAGE, V59, P2187, DOI 10.1016/j.neuroimage.2011.10.003
   De Rubeis S, 2014, NATURE, V515, P209, DOI 10.1038/nature13772
   Den K, 2019, J HUM GENET, V64, P821, DOI 10.1038/s10038-019-0617-1
   Donini M, 2019, NEUROIMAGE, V195, P215, DOI 10.1016/j.neuroimage.2019.01.053
   Dukart J, 2016, J ALZHEIMERS DIS, V49, P1143, DOI 10.3233/JAD-150570
   Feliciano P, 2019, NPJ GENOM MED, V4, DOI 10.1038/s41525-019-0093-8
   Filipovych Roman, 2012, Int Workshop Pattern Recognit Neuroimaging, P105, DOI 10.1109/PRNI.2012.9
   Fox MD, 2005, P NATL ACAD SCI USA, V102, P9673, DOI 10.1073/pnas.0504136102
   Guo WT, 2015, J MED IMAGING, V2, DOI 10.1117/1.JMI.2.4.041007
   Guyon I., 2002, MACH LEARN
   Heinsfeld AS, 2018, NEUROIMAGE-CLIN, V17, P16, DOI 10.1016/j.nicl.2017.08.017
   Hiraide T, 2019, EPILEPSIA OPEN, V4, P476, DOI 10.1002/epi4.12339
   Hiraide T, 2018, HUM GENET, V137, P95, DOI 10.1007/s00439-017-1863-y
   Hong L, 2002, J HUM GENET, V47, P262, DOI 10.1007/s100380200036
   Iossifov I, 2015, P NATL ACAD SCI USA, V112, pE5600, DOI 10.1073/pnas.1516376112
   Iossifov I, 2014, NATURE, V515, P216, DOI 10.1038/nature13908
   Iossifov I, 2012, NEURON, V74, P285, DOI 10.1016/j.neuron.2012.04.009
   Irie F, 2012, P NATL ACAD SCI USA, V109, P5052, DOI 10.1073/pnas.1117881109
   Jiang TZ, 2004, HUM BRAIN MAPP, V22, P63, DOI 10.1002/hbm.20012
   Jiao Y, 2012, J AUTISM DEV DISORD, V42, P971, DOI 10.1007/s10803-011-1327-5
   Jin SC, 2017, NAT GENET, V49, P1593, DOI 10.1038/ng.3970
   Jordan MI, 2015, SCIENCE, V349, P255, DOI 10.1126/science.aaa8415
   Kim Y.S., 2011, American Journal of Psychiatry, P1
   Krishnan A, 2016, NAT NEUROSCI, V19, P1454, DOI 10.1038/nn.4353
   Krupp DR, 2017, AM J HUM GENET, V101, P369, DOI 10.1016/j.ajhg.2017.07.016
   Labonne JDJ, 2016, HUM GENET, V135, P757, DOI 10.1007/s00439-016-1668-4
   Lai MC, 2014, LANCET, V383, P896, DOI 10.1016/S0140-6736(13)61539-1
   Lelieveld SH, 2016, NAT NEUROSCI, V19, P1194, DOI 10.1038/nn.4352
   LI B, 2017, PLOS ONE, V12
   Lind T, 1998, J BIOL CHEM, V273, P26265, DOI 10.1074/jbc.273.41.26265
   LOWE MJ, 1998, NEUROIMAGE
   Lynch CJ, 2013, BIOL PSYCHIAT, V74, P212, DOI 10.1016/j.biopsych.2012.12.013
   Marier Allison., 2016, Journal of the American Medical Informatics Association, V23, P8, DOI DOI 10.1093/JAMIA
   MATSON JL, 2008, RES AUTISM SPECT DIS
   Mazurowski MA, 2014, RADIOLOGY, V273, P365, DOI 10.1148/radiol.14132641
   Mizuno A, 2006, BRAIN RES, V1104, P160, DOI 10.1016/j.brainres.2006.05.064
   Nho K, 2016, BMC MED GENOMICS, V9, DOI 10.1186/s12920-016-0190-9
   Pagel KA, 2019, PLOS COMPUT BIOL, V15, DOI 10.1371/journal.pcbi.1007112
   Palumbo O, 2015, AM J MED GENET A, V167, P438, DOI 10.1002/ajmg.a.36872
   Peng JL, 2019, PATTERN RECOGN, V88, P370, DOI 10.1016/j.patcog.2018.11.027
   Qiao Y, 2013, CLIN GENET, V83, P145, DOI 10.1111/j.1399-0004.2012.01860.x
   Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491
   Reuter MS, 2017, JAMA PSYCHIAT, V74, P293, DOI 10.1001/jamapsychiatry.2016.3798
   Rolls ET, 2015, NEUROIMAGE, V122, P1, DOI 10.1016/j.neuroimage.2015.07.075
   Ruzzo EK, 2019, CELL, V178, P850, DOI 10.1016/j.cell.2019.07.015
   Smedley NF, 2018, I S BIOMED IMAGING, P1529, DOI 10.1109/ISBI.2018.8363864
   Stolerman ES, 2019, AM J MED GENET A, V179, P1276, DOI 10.1002/ajmg.a.61173
   Wang Y, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0062789
   Yan JW, 2017, BIOCOMPUT-PAC SYM, P94, DOI 10.1142/9789813207813_0010
   Yerys BE, 2015, NEUROIMAGE-CLIN, V9, P223, DOI 10.1016/j.nicl.2015.07.018
   Yuen RKC, 2017, NAT NEUROSCI, V20, P602, DOI 10.1038/nn.4524
   Zhang F, 2018, NEUROIMAGE, V172, P826, DOI 10.1016/j.neuroimage.2017.10.029
   Zhang ZM, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00260
   Zhou T, 2019, IEEE T MED IMAGING, V38, P2411, DOI 10.1109/TMI.2019.2913158
   Zhou T, 2019, HUM BRAIN MAPP, V40, P1001, DOI 10.1002/hbm.24428
   Zhu YJ, 2015, SCI REP-UK, V5, DOI 10.1038/srep11087
NR 62
TC 6
Z9 6
U1 3
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19183
EP 19194
DI 10.1007/s11042-020-10473-9
EA FEB 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000614681600003
DA 2024-07-18
ER

PT J
AU Ashiba, HI
AF Ashiba, H., I
TI Proposed framework for cancelable face recognition system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cancelable biometrics; Biometric templates; The HFM; AT; Template
   protection
AB This paper suggests two novel presented cancellable biometric realization approaches recognition and template protection. In the suggested scheme, the A Trous Transform (AT) algorithm is applied on the face images. Then the AT divides the image into seven subbands. The resultant map is encrypted with the Homomorphic Filtering Masking (HFM) encoding algorithm is utilized for cancelable face recognition system. Then the second HFM utilized is produced from the image. This technique can be used to advance a frequency domain procedure for making this system for biometric template protection. The second algorithm presents a new technique to detect the features for Facial Expression Recognition (FER). This technique is established on segmentation process by Canny Edge Detection (CD) and Hough Transform (HT) with the number of feature points as the key parameters for classification. This algorithm is set up analysis the FER with the number of HT feature points as the key parameters for classification. Simulation results using evaluation metrics False Positive Rate (FPR), False Negative Rate (FNR), Equal Error Rate (EER), Receiver Operating Characteristic (ROC) and Area under ROC (AROC) prove that the first proposed cancelable biometric technique with the second key are best with comparing the other keys.The obtained results clear that the second suggested technique has sucesseded in detection the features of FER for sad, happy, neutral, angry, disgust, fear, surprise cases and the face positions.
C1 [Ashiba, H., I] Bilbis Higher Inst Engn, Dept Elect & Elect Commun, Bilbis, Shaniia, Egypt.
RP Ashiba, HI (corresponding author), Bilbis Higher Inst Engn, Dept Elect & Elect Commun, Bilbis, Shaniia, Egypt.
EM eng_h_2006@yahoo.com
RI ashiba, huda/GQI-4310-2022
OI ashiba, huda/0000-0002-4926-8919
CR Akdogan D, 2018, COMPUT NETW, V142, P33, DOI 10.1016/j.comnet.2018.06.001
   Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   Ashiba HI, 2020, MULTIMED TOOLS APPL, V79, P2543, DOI 10.1007/s11042-019-08154-3
   Ashiba HI, 2019, MULTIMED TOOLS APPL, V78, P11277, DOI 10.1007/s11042-018-6545-9
   Ashiba H. I., 2008, Progress In Electromagnetics Research C, V1, P123, DOI 10.2528/PIERC08012301
   Barra S, 2019, FUTURE GENER COMP SY, V101, P534, DOI 10.1016/j.future.2019.06.019
   Das S, 2019, PATTERN RECOGN LETT, V126, P102, DOI 10.1016/j.patrec.2018.06.026
   Davis L.S., 1975, Comput. Graph. Image Process, V4, P248, DOI DOI 10.1016/0146-664X(75)90012-X
   Dwivedi R, 2019, PATTERN RECOGN LETT, V126, P58, DOI 10.1016/j.patrec.2018.04.022
   Evelyn Brindha V., 2012, J. Biom. Biostat, V3, P100
   Feng YC, 2010, IEEE T INF FOREN SEC, V5, P103, DOI 10.1109/TIFS.2009.2038760
   Hassanein AS., 2015, IJCSI INT J COMPUT S, V12, P2
   Hengjian Li, 2012, Journal of Software, V7, P1827, DOI 10.4304/jsw.7.8.1827-1834
   Jing W., 2019, International Journal of High Performance Computing and Networking, V13, P222, DOI [10.1504/IJHPCN.2019.097502, DOI 10.1504/IJHPCN.2019.097502]
   Kaur H, 2020, FUTURE GENER COMP SY, V102, P30, DOI 10.1016/j.future.2019.07.023
   Kaur H, 2019, PATTERN RECOGN LETT, V126, P31, DOI 10.1016/j.patrec.2018.02.016
   Kaur H, 2015, PROCEDIA COMPUT SCI, V54, P661, DOI 10.1016/j.procs.2015.06.077
   Kho JB, 2019, PATTERN RECOGN, V91, P245, DOI 10.1016/j.patcog.2019.01.039
   Li HJ, 2020, MULTIMED TOOLS APPL, V79, P11947, DOI 10.1007/s11042-019-08446-8
   Li HJ, 2012, PROCEDIA ENGINEER, V29, P1239, DOI 10.1016/j.proeng.2012.01.120
   Li YK, 2019, INT J SOFTW SCI COMP, V11, P1, DOI 10.4018/IJSSCI.2019100101
   Ling, 2007, INT J COMPUT ELECT A, V1
   Liu Y., 2019, INT J HIGH PERFORM C, V14, P376, DOI DOI 10.1504/IJHPCN.2019.101249
   Maiorana E, 2010, EXPERT SYST APPL, V37, P3454, DOI 10.1016/j.eswa.2009.10.043
   Oh BS, 2012, PATTERN RECOGN, V45, P3288, DOI 10.1016/j.patcog.2012.02.027
   Oran, 2002, FAST FOURIER TRANSFO
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Rathgeb C, 2014, COMPUT SECUR, V42, P1, DOI 10.1016/j.cose.2013.12.005
   Saini N, 2010, OPT COMMUN, V283, P894, DOI 10.1016/j.optcom.2009.11.003
   Savvides M, 2004, INT C PATT RECOG, P922, DOI 10.1109/ICPR.2004.1334679
   Senthilkumaran N., 2009, International Journal of Recent Trends in Engineering, V1, P250
   Sikender M., 2020, SSRN Electronic Journal, DOI DOI 10.2139/SSRN.3622882
   Sunaryono D, 2021, J KING SAUD UNIV-COM, V33, P304, DOI 10.1016/j.jksuci.2019.01.006
   Taheri M, 2015, J OPT SOC AM A, V32, P1772, DOI 10.1364/JOSAA.32.001772
   Teoh ABJ, 2005, PATTERN RECOGN LETT, V26, P1454, DOI 10.1016/j.patrec.2004.11.021
   Trivedi AK, 2020, COMPUT SECUR, V90, DOI 10.1016/j.cose.2019.101690
   Umer S, 2017, INFORM SCIENCES, V406, P102, DOI 10.1016/j.ins.2017.04.026
   Verma G, 2019, OPT LASER ENG, V123, P28, DOI 10.1016/j.optlaseng.2019.06.028
   Verma G, 2016, J OPTICS-UK, V18, DOI 10.1088/2040-8978/18/5/055705
   Wang S, 2016, PATTERN RECOGN, V54, P14, DOI 10.1016/j.patcog.2016.01.001
   Xu Y, 2020, SOFT COMPUT, V24, P5971, DOI 10.1007/s00500-019-04530-1
   Yang WC, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11020141
   Yang WC, 2018, PATTERN RECOGN, V78, P242, DOI 10.1016/j.patcog.2018.01.026
   Zhou K, 2018, IEEE T INF FOREN SEC, V13, P3050, DOI 10.1109/TIFS.2018.2838540
NR 44
TC 4
Z9 4
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13677
EP 13705
DI 10.1007/s11042-020-10291-z
EA JAN 2021
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000608106900002
DA 2024-07-18
ER

PT J
AU Hameed, AS
AF Hameed, Abbas Salman
TI Speech compression and encryption based on discrete wavelet transform
   and chaotic signals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech compression; Speech encryption; Wavelet transform; Chaotic map
AB To increase transfer and storage efficiencies of the information, data compression has emerged as a significant issue in the communication environments. This paper introduces compression and encryption of speech signals based on Discrete Wavelet Transform (DWT) and Chaotic signals. DWT sparsens and codes the speech signal to the wavelet coefficients. The less impactful coefficients are eliminated to reduce the amount of data. After that, a new coding process which utilizes the chaotic signals is proposed to encode, in encrypted form, the residual coefficients. A High strength to the encryption process is realized by using four linked Henon Chaotic Maps (HCM) in the proposed scheme. Multi HCM guarantees larger than 10(240) of key space to the encryption process. The proposed system obtains up to -41.449 dB of spectral segmental signal-to-noise ratio, which measures and proves the strength of encryption. Also, at 10% compression ratio, signal-to-noise ratio of 11.549 dB and perceptual evaluation speech quality of 3.02945 demonstrate that the proposed system has high quality and intelligibility of the reconstructed speech.
C1 [Hameed, Abbas Salman] Univ Diyala, Coll Engn, Diyala, Iraq.
C3 University of Diyala
RP Hameed, AS (corresponding author), Univ Diyala, Coll Engn, Diyala, Iraq.
EM abbasfuture@yahoo.com
RI hameed, abbas salman/F-1044-2019
CR Al-Azawi MKM, 2018, IET SIGNAL PROCESS, V12, P214, DOI 10.1049/iet-spr.2016.0708
   Ambikairajah E, 2011, 2011 4 INT C MECH IN, P17, DOI [10.1109/ICOM.2011.5937130, DOI 10.1109/ICOM.2011.5937130]
   Cernak M, 2018, IEEE SIGNAL PROC MAG, V35, P97, DOI 10.1109/MSP.2017.2761895
   Chelali F.z., 2018, 6 INT C MULT COMP SY, P1
   Dusan S, 2007, IEEE T AUDIO SPEECH, V15, P387, DOI 10.1109/TASL.2006.881705
   GRAPS A, 1995, IEEE COMPUT SCI ENG, V2, P50, DOI 10.1109/99.388960
   Hameed AS., 2017, DIYALA J ENG SCI, V10, P81
   ITU-T, 2001, PERCEPTUAL EVALUATIO, P749
   Jawad AK, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCE IN SUSTAINABLE ENGINEERING AND ITS APPLICATION (ICASEA), P7, DOI 10.1109/ICASEA.2018.8370947
   Joseph S. M., 2011, 2011 International Conference on Recent Trends in Information Technology (ICRTIT 2011), P754, DOI 10.1109/ICRTIT.2011.5972258
   Joseph SM, 2016, INT J SPEECH TECHNOL, V19, P537, DOI 10.1007/s10772-014-9240-x
   Karajeh H, 2019, MULTIMED TOOLS APPL, V78, P18395, DOI 10.1007/s11042-019-7214-3
   Katzberg F, 2018, IEEE-ACM T AUDIO SPE, V26, P1962, DOI 10.1109/TASLP.2018.2851144
   Kornsing S., 2012, 2012 International Symposium on Computer, Consumer and Control (IS3C 2012), P393, DOI 10.1109/IS3C.2012.106
   Lee YS, 2019, SIGNAL PROCESS-IMAGE, V70, P104, DOI 10.1016/j.image.2018.09.004
   Makbol NM, 2016, IET IMAGE PROCESS, V10, P34, DOI 10.1049/iet-ipr.2014.0965
   Mehra M., 2018, WAVELETS THEORY ITS
   Meranza-Castillón MO, 2019, AEU-INT J ELECTRON C, V107, P239, DOI 10.1016/j.aeue.2019.05.028
   Narkhedkar SG, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P1135, DOI 10.1109/IC3I.2014.7019767
   Ramdas V., 2015, 2015 IEEE INT C SIGN, P1, DOI DOI 10.1109/SPICES.2015.7091436
   Rani M, 2018, IEEE ACCESS, V6, P4875, DOI 10.1109/ACCESS.2018.2793851
   Sankar MSA, 2019, HELIYON, V5, DOI 10.1016/j.heliyon.2019.e01820
   Sheela SJ, 2017, J COMPUT NETW COMMUN, V2017, DOI 10.1155/2017/2721910
   Stankovic L, 2018, IEEE-ACM T AUDIO SPE, V26, P1216, DOI 10.1109/TASLP.2018.2819819
   Strohmer T, 2012, IEEE SIGNAL PROC LET, V19, P887, DOI 10.1109/LSP.2012.2224518
   Su YG, 2017, OPT LASER ENG, V88, P20, DOI 10.1016/j.optlaseng.2016.07.012
   Vig Rekha, 2018, Procedia Computer Science, V132, P1404, DOI 10.1016/j.procs.2018.05.070
   Waldekar S, 2020, MULTIMED TOOLS APPL, V79, P7911, DOI 10.1007/s11042-019-08279-5
   Wang SS, 2018, IEEE-ACM T AUDIO SPE, V26, P564, DOI 10.1109/TASLP.2017.2779787
   Zhang QY, 2018, MULTIMED TOOLS APPL, V77, P21653, DOI 10.1007/s11042-018-5613-5
   Zhao Dan, 2010, Proceedings 2010 Second International Conference on Computer Modeling and Simulation (ICCMS), P360, DOI 10.1109/ICCMS.2010.68
NR 31
TC 5
Z9 6
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13663
EP 13676
DI 10.1007/s11042-020-10334-5
EA JAN 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000608388900001
DA 2024-07-18
ER

PT J
AU Alterkavi, S
   Erbay, H
AF Alterkavi, Suleyman
   Erbay, Hasan
TI Novel authorship verification model for social media accounts
   compromised by a human
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Authorship verification; Natural language processing; Machine learning
ID NETWORKS; ATTRIBUTION
AB Social media networks usage is spreading but accompanied by a new shape of the social engineering attacks in which users' accounts are compromised by attackers to spread malicious messages for different purposes. To overcome these attacks, authorship verification, a classification problem for classifying a text, whether it belongs to a user or not, is needed. Moreover, the verification must be accurate and fast. Herein, an authorship verification model proposed. The model uses XGBoost, as a preprocessor, to discover functional features of the text message, which ranked using MCDM methods to build a classification model. Twitter messages are used to test the model; however, any social media's data might be used. The suggested model was evaluated against a crawled dataset from Twitter composed of 16124 tweets with 280 characters. The proposed method achieved F-score over 0.94.
C1 [Alterkavi, Suleyman] Kirikkale Univ, Kirikkale, Turkey.
   [Erbay, Hasan] Univ Turkish Aeronaut Assoc, Engn Fac, Comp Engn Dept, TR-06790 Ankara, Turkey.
C3 Kirikkale University; Turkish Aeronautical Association; Turk Hava Kurumu
   University
RP Alterkavi, S (corresponding author), Kirikkale Univ, Kirikkale, Turkey.
EM sleman-terkawi@hotmail.com; herbay@thk.edu.tr
OI Alterkavi, Suleyman/0000-0002-9598-4975
CR Adelaiye, RANDOMIZED CYBER ATT
   Al-Khaldi MM, 2021, IEEE T GEOSCI REMOTE, V59, P4454, DOI 10.1109/TGRS.2020.3009784
   Alazab Mamoun, 2014, Journal of Networks, V9, P2878, DOI 10.4304/jnw.9.11.2878-2891
   [Anonymous], 2020, STATISTA NUMBER SOCI
   [Anonymous], 2017, PHYS ORG TWITTER DOU
   [Anonymous], 2013, NDSS
   [Anonymous], 2013, BLOOMBERG TECHNOLOGY
   [Anonymous], 2020, WORLDOMETERS WORLD P
   Barbon S, 2017, MULTIMED TOOLS APPL, V76, P3213, DOI 10.1007/s11042-016-3899-8
   Benevenuto Fabricio., 2010, CEAS
   Bhattacharya S, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9020219
   Boenninghoff B, 2020, ARXIV200810105
   borison R, 2014, PRESENTING 100 MOST
   Calabresi Massimo., 2017, TIME
   Castro A., 2012, AUTHOR IDENTIFICATIO
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Fulop J., 2005, Introduction to Decision Making Methods, P1
   Gong NZ, 2014, IEEE T INF FOREN SEC, V9, P976, DOI 10.1109/TIFS.2014.2316975
   Grgurinam, 2013, APPLYING MULTICRITER
   Gunther Specht EvaZangerle., 2014, P 29 ANN ACM S APPL, P587
   Hall M. A., 1999, Proceedings of the Twelfth International Florida AI Research Society Conference, P235
   HOLMES DI, 1994, COMPUT HUMANITIES, V28, P87, DOI 10.1007/BF01830689
   Jahan A, 2013, MULTI-CRITERIA DECISION ANALYSIS FOR SUPPORTING THE SELECTION OF ENGINEERING MATERIALS IN PRODUCT DESIGN, P1
   Kaur R, 2018, EXPERT SYST APPL, V113, P397, DOI 10.1016/j.eswa.2018.07.011
   Kotsiantis SB, 2006, J COMPUT, V1, P30, DOI 10.4304/jcp.1.4.30-37
   Kumar G.D., 2018, MACHINE LEARNING TEC
   Lagerholm F, 2017, USING ARTIFICIAL INT
   Li JS, 2014, INT CONF E BUS ENG, P314, DOI 10.1109/ICEBE.2014.61
   live stats I, 2020, TWITTER USAGE STAT
   Maria KA, 2016, THESIS TECHNOGLOSSIA
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Nauta Meike, 2016, P 25 TWENT STUD C IT
   Parmigiani, 2001, DECISION THEORY
   Press CU, 2009, TOKENIZATION
   Ramos J, 2003, P 1 INSTRUCTIONAL C, V242, P29
   Rocha A, 2017, IEEE T INF FOREN SEC, V12, P5, DOI 10.1109/TIFS.2016.2603960
   Roszkowska E., 2013, Optimum. Studia Ekonomiczne, V5, P14, DOI DOI 10.15290/OSE.2013.05.65.02
   Saaty T. L., 2008, INT J SERV SCI, V1, P83, DOI [10.1504/IJSSCI.2008.017590, DOI 10.1504/IJSSCI.2008.017590]
   Saaty T. L., 2005, THEORY APPL ANALYTIC
   Saaty TL., 2001, ISAHP 2001 P, P2
   Savyan PV, 2020, MULTIMED TOOLS APPL, V79, P19349, DOI 10.1007/s11042-020-08721-z
   Schoenfeld B., 2018, ARXIV181009942
   Seyler D, 2018, ARXIV180407247
   Sivic J, 2009, IEEE T PATTERN ANAL, V31, P591, DOI 10.1109/TPAMI.2008.111
   Stamatatos E, 2009, J AM SOC INF SCI TEC, V60, P538, DOI 10.1002/asi.21001
   Steinert-Threlkeld ZacharyC., 2018, Twitter as Data
   Suman C, 2021, COGN COMPUT, V13, P261, DOI 10.1007/s12559-020-09715-7
   Trång D, 2015, SECOND EUROPEAN NETWORK INTELLIGENCE CONFERENCE (ENIC 2015), P75, DOI 10.1109/ENIC.2015.19
   Usha Athira, 2017, Security, Privacy, and Anonymity in Computation, Communication, and Storage. 10th International Conference, SpaCCS 2017. Proceedings: LNCS 10656, P212, DOI 10.1007/978-3-319-72389-1_18
NR 49
TC 12
Z9 12
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13575
EP 13591
DI 10.1007/s11042-020-10361-2
EA JAN 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000608106800001
DA 2024-07-18
ER

PT J
AU Budhi, GS
   Chiong, R
   Wang, ZL
AF Budhi, Gregorius Satia
   Chiong, Raymond
   Wang, Zuli
TI Resampling imbalanced data to detect fake reviews using machine learning
   classifiers and textual-based features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fake review detection; Textual-based features; Machine learning;
   Imbalanced data
AB Fraudulent online sellers often collude with reviewers to garner fake reviews for their products. This act undermines the trust of buyers in product reviews, and potentially reduces the effectiveness of online markets. Being able to accurately detect fake reviews is, therefore, critical. In this study, we investigate several preprocessing and textual-based featuring methods along with machine learning classifiers, including single and ensemble models, to build a fake review detection system. Given the nature of product review data, where the number of fake reviews is far less than that of genuine reviews, we look into the results of each class in detail in addition to the overall results. We recognise from our preliminary analysis that, owing to imbalanced data, there is a high imbalance between the accuracies for different classes (e.g., 1.3% for the fake review class and 99.7% for the genuine review class), despite the overall accuracy looking promising (around 89.7%). We propose two dynamic random sampling techniques that are possible for textual-based featuring methods to solve this class imbalance problem. Our results indicate that both sampling techniques can improve the accuracy of the fake review class-for balanced datasets, the accuracies can be improved to a maximum of 84.5% and 75.6% for random under and over-sampling, respectively. However, the accuracies for genuine reviews decrease to 75% and 58.8% for random under and over-sampling, respectively. We also discover that, for smaller datasets, the Adaptive Boosting ensemble model outperforms other single classifiers; whereas, for larger datasets, the performance improvement from ensemble models is insignificant compared to the best results obtained by single classifiers.
C1 [Budhi, Gregorius Satia; Chiong, Raymond] Univ Newcastle, Sch Elect Engn & Comp, Callaghan, NSW 2308, Australia.
   [Budhi, Gregorius Satia] Petra Christian Univ, Informat Dept, Surabaya 60236, Indonesia.
   [Wang, Zuli] Chengdu Univ Informat Technol, Sch Cybersecur, Chengdu 610225, Peoples R China.
C3 University of Newcastle; Universitas Kristen Petra; Chengdu University
   of Information Technology
RP Chiong, R (corresponding author), Univ Newcastle, Sch Elect Engn & Comp, Callaghan, NSW 2308, Australia.; Wang, ZL (corresponding author), Chengdu Univ Informat Technol, Sch Cybersecur, Chengdu 610225, Peoples R China.
EM Raymond.Chiong@newcastle.edu.au; wangzuli@cuit.edu.cn
OI Chiong, Raymond/0000-0002-8285-1903; Satia Budhi,
   Gregorius/0000-0002-1929-7399
FU Indonesian Endowment Fund for Education (LPDP), Ministry of Finance;
   Directorate General of Higher Education (DIKTI), Ministry of Education
   and Culture, Republic of Indonesia
FX The first author would like to acknowledge financial support from the
   Indonesian Endowment Fund for Education (LPDP), Ministry of Finance, and
   the Directorate General of Higher Education (DIKTI), Ministry of
   Education and Culture, Republic of Indonesia.
CR Akram AU, 2018, KSII T INTERNET INF, V12, P5120, DOI 10.3837/tiis.2018.10.026
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Bajaj S, 2017, PROCEDIA COMPUT SCI, V122, P1009, DOI 10.1016/j.procs.2017.11.467
   Barbado R, 2019, INFORM PROCESS MANAG, V56, P1234, DOI 10.1016/j.ipm.2019.03.002
   Birchall G., 2018, TRIPADVISOR DENIES C
   Breiman L., 2001, Mach. Learn., V45, P5
   Budhi G. S., 2014, INT J APPL ENG RES, V9, P18025
   Budhi GS, 2021, ARCH COMPUT METHOD E, V28, P2543, DOI 10.1007/s11831-020-09464-8
   Budhi GS, 2018, 2018 IEEE CONFERENCE ON BIG DATA AND ANALYTICS (ICBDA), P68, DOI 10.1109/ICBDAA.2018.8629593
   Budhi GS, 2017, 2017 IEEE CONFERENCE ON BIG DATA AND ANALYTICS (ICBDA), P19, DOI 10.1109/ICBDAA.2017.8284101
   Campbell C., 2011, Learning with Support Vector Machines
   Cardoso EF, 2018, NEUROCOMPUTING, V309, P106, DOI 10.1016/j.neucom.2018.04.074
   D'onfro Jillian., 2013, A Whopping 20% Of Yelp Reviews Are Fake
   Darzi MRK, 2019, EXPERT SYST APPL, V128, P169, DOI 10.1016/j.eswa.2019.03.024
   Deng XL, 2019, MULTIMED TOOLS APPL, V78, P3797, DOI 10.1007/s11042-018-6083-5
   Dobson A.J., 2008, INTRO GEN LINEAR MOD, DOI [10.1201/9780367807849., DOI 10.1201/9780367807849, 10.1201/9780367807849]
   Dunteman GH, 2011, INTRO GEN LINEAR MOD, P2
   Ellson A, 2018, The Times
   Etaiwi W, 2017, PROCEDIA COMPUT SCI, V113, P273, DOI 10.1016/j.procs.2017.08.368
   Felbermayr A, 2016, J INTERACT MARK, V36, P60, DOI 10.1016/j.intmar.2016.05.004
   Fernández A, 2018, J ARTIF INTELL RES, V61, P863, DOI 10.1613/jair.1.11192
   Freeman, 2016, MONEY, V45, P30
   Glorot X., 2010, P INT C ART INT STAT, P249
   Hastie T., 1990, Generalized additive model
   Hazim M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0198884
   Fusilier DH, 2015, INFORM PROCESS MANAG, V51, P433, DOI 10.1016/j.ipm.2014.11.001
   Heydari A, 2015, EXPERT SYST APPL, V42, P3634, DOI 10.1016/j.eswa.2014.12.029
   Hu ZY, 2019, IND MANAGE DATA SYST, V119, P676, DOI 10.1108/IMDS-02-2018-0072
   Hu ZY, 2016, IEEE C EVOL COMPUTAT, P5186, DOI 10.1109/CEC.2016.7748347
   Imran M, 2019, INT J EMERG TECHNOL, V14, P92, DOI 10.3991/ijet.v14i14.10310
   Ivanova O, 2017, DECIS SUPPORT SYST, V104, P64, DOI 10.1016/j.dss.2017.10.003
   Kingma D. P., 2014, arXiv
   Kumar N, 2018, J MANAGE INFORM SYST, V35, P350, DOI 10.1080/07421222.2018.1440758
   Li LY, 2017, NEUROCOMPUTING, V254, P33, DOI 10.1016/j.neucom.2016.10.080
   Luca M, 2016, MANAGE SCI, V62, P3412, DOI 10.1287/mnsc.2015.2304
   Malbon J, 2013, J CONSUM POLICY, V36, P139, DOI 10.1007/s10603-012-9216-7
   Menard S., 2010, Logistic regression analysis
   Munzel A, 2016, J RETAIL CONSUM SERV, V32, P96, DOI 10.1016/j.jretconser.2016.06.002
   Rahman M, 2015, STAT ANAL DATA MIN, V8, P147, DOI 10.1002/sam.11264
   Rathore S, 2018, APPL SOFT COMPUT, V67, P920, DOI 10.1016/j.asoc.2017.09.032
   Rout JK, 2017, MULTIMED TOOLS APPL, V76, P3187, DOI 10.1007/s11042-016-3819-y
   Rumelhart D.E., 2013, Learning internal representations by error propagation, P399, DOI [10.1016/b978-1-4832-1446-7.50035-2, 10.1016/B978-1-4832-1446-7.50035-2]
   Savage D, 2015, EXPERT SYST APPL, V42, P8650, DOI 10.1016/j.eswa.2015.07.019
   Sun CG, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/4935792
   Wahyuni ED, 2016, MATEC WEB CONF, V58, DOI 10.1051/matecconf/20165803003
   Zhang DS, 2016, J MANAGE INFORM SYST, V33, P456, DOI 10.1080/07421222.2016.1205907
NR 46
TC 23
Z9 23
U1 1
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13079
EP 13097
DI 10.1007/s11042-020-10299-5
EA JAN 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000607504000006
DA 2024-07-18
ER

PT J
AU Tuncer, T
   Ertam, F
   Dogan, S
AF Tuncer, Turker
   Ertam, Fatih
   Dogan, Sengul
TI Automated malware identification method using image descriptors and
   singular value decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Malware identification; Local ternary pattern network; Local binary
   pattern; Singular value decomposition
ID NEURAL-NETWORKS; CLASSIFICATION; STEPS
AB Cyber-attacks have become a significant problem worldwide. Therefore, many methods, networks, and applications have been suggested for providing information security in the literature. Automated malware classification has become one of the hot-topic research areas in information security and digital forensics. Image processing methods have been used to solve malware detection and recognition problem. Three effective feature extractors are used to propose an automated malware classification method in this work. The proposed method uses local binary pattern (LBP), singular value decomposition (SVD), and a novel local ternary pattern network (LTPNet) to extract features. The extracted features using the hybrid feature extractor are reduced using principal component analysis (PCA). The final features are forwarded to linear discriminant analysis (LDA) classifier. A commonly used heterogonous and big malware dataset (Maligm) is used to obtain the success of the proposed LBP, LTPNet, and SVD based malware classification method. There are 9339 malwares with 25 classes in the Maligm dataset. The proposed LBP-SVD-LTPNet based method achieved an 88.08% success rate using this dataset. The obtained accuracy rate of the proposed LBP-SVD-LTPNet based method is higher than the selected deep learning methods. These methods are convolutional neural network (CNN), multi-layer perceptron (MLP), gated recurrent units (GRU), GoogleNet, VGG16, and ResNet. These results openly demonstrated that the proposed LBP-SVD-LTPNet based malware classification method is successful.
C1 [Tuncer, Turker; Ertam, Fatih; Dogan, Sengul] Firat Univ, Dept Digital Forens Engn, Coll Technol, Elazig, Turkey.
C3 Firat University
RP Tuncer, T (corresponding author), Firat Univ, Dept Digital Forens Engn, Coll Technol, Elazig, Turkey.
EM turkertuncer@firat.edu.tr; fatih.ertam@firat.edu.tr; sdogan@firat.edu.tr
RI DOGAN, Sengul/W-4854-2018; TUNCER, Turker/W-4846-2018; Ertam,
   Fatih/V-5288-2018
OI DOGAN, Sengul/0000-0001-9677-5684; Ertam, Fatih/0000-0002-9736-8068
CR Agarap AF, 2017, ARXIV180100318
   Akarsh S, 2019, INT CONF ADVAN COMPU, P1059, DOI [10.1109/ICACCS.2019.8728471, 10.1109/icaccs.2019.8728471]
   ALTMAN EI, 1994, J BANK FINANC, V18, P505, DOI 10.1016/0378-4266(94)90007-8
   AQUILINA James M., 2008, Malware Forensics: Investigating and Analyzing Malicious Code
   Banin S, 2018, DIGIT INVEST, V26, pS107, DOI 10.1016/j.diin.2018.04.019
   Basu I, 2016, AM J ADV COMPUT, V3, P18
   Boero L, 2017, 2017 29TH INTERNATIONAL TELETRAFFIC CONGRESS (ITC 29), VOL 3, P25, DOI [10.23919/ITC.2017.8065806, 10.1109/JTC29.147]
   Chakkaravarthy SS, 2019, COMPUT SCI REV, V32, P1, DOI 10.1016/j.cosrev.2019.01.002
   Chen SC, 2004, PATTERN RECOGN, V37, P1081, DOI 10.1016/j.patcog.2003.09.004
   Dai YS, 2018, DIGIT INVEST, V27, P30, DOI 10.1016/j.diin.2018.09.006
   De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696
   Egele M, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2089125.2089126
   Elhadi AAE, 2013, INT J SECUR APPL, V7, P29, DOI 10.14257/ijsia.2013.7.5.03
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Flach PA, 2015, ADV NEUR IN, V28
   GOLUB GH, 1970, NUMER MATH, V14, P403, DOI 10.1007/BF02163027
   Guanghui Liang, 2016, International Journal of Information and Education Technology, V6, P291, DOI 10.7763/IJIET.2016.V6.702
   Günther J, 2014, PROC TECH, V15, P474, DOI 10.1016/j.protcy.2014.09.007
   Islam R, 2013, J NETW COMPUT APPL, V36, P646, DOI 10.1016/j.jnca.2012.10.004
   Kim K., 2009, P ASME TURBO EXPO 20, P1, DOI DOI 10.1145/1657120.1657121
   Kruczkowski M, 2014, 2014 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 2, P415, DOI 10.1109/WI-IAT.2014.127
   Kumar P., 2018, RECENT PATENTS ENG, V12, P23, DOI DOI 10.2174/1872212111666170808104744
   Li Q., 2005, ADV NEURAL INFORM PR, P1569, DOI DOI 10.5555/2976040.2976237
   Lin CT, 2015, J INF SCI ENG, V31, P965
   LONGSTAFF ID, 1987, PATTERN RECOGN LETT, V5, P315, DOI 10.1016/0167-8655(87)90072-9
   Machado JAT, 2017, COMPUTATIONAL COMPLE
   Mohaisen A, 2015, COMPUT SECUR, V52, P251, DOI 10.1016/j.cose.2015.04.001
   Nataraj Lakshmanan, 2011, P 8 INT S VIS CYB SE, P1
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojala T., 2001, Advances in Pattern Recognition - ICAPR 2001. Second International Conference. Proceedings (Lecture Notes in Computer Science Vol.2013), P397
   Pai S, 2017, J COMPUT VIROL HACKI, V13, P95, DOI 10.1007/s11416-016-0265-3
   Provataki A, 2013, DIGIT INVEST, V10, P311, DOI 10.1016/j.diin.2013.08.006
   Raff E, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1007, DOI 10.1145/3097983.3098111
   Ren L, 2019, FUTURE GENER COMP SY, V94, P601, DOI 10.1016/j.future.2018.12.009
   Rieck K, 2008, LECT NOTES COMPUT SC, V5137, P108, DOI 10.1007/978-3-540-70542-0_6
   Rieck K, 2011, J COMPUT SECUR, V19, P639, DOI 10.3233/JCS-2010-0410
   Rudd EM, 2017, IEEE COMMUN SURV TUT, V19, P1145, DOI 10.1109/COMST.2016.2636078
   Sahu MK., 2014, International Journal of Computer Science and Information Technologies (IJCSIT), V5, P944
   Santos I, 2013, INFORM SCIENCES, V231, P64, DOI 10.1016/j.ins.2011.08.020
   Saxe J, 2015, 2015 10TH INTERNATIONAL CONFERENCE ON MALICIOUS AND UNWANTED SOFTWARE (MALWARE), P11, DOI 10.1109/MALWARE.2015.7413680
   Shabtai Asaf, 2009, Information Security Technical Report, V14, P16, DOI 10.1016/j.istr.2009.03.003
   Sharma K, 2017, SCALABLE COMPUT-PRAC, V18, pIII, DOI 10.12694/scpe.v18i3.1299
   Shrivastava G, 2012, CCSEA SEA CLOUD DKMP, P207
   Sinha A, 2022, SOFTWARE PRACT EXPER, V52, P729, DOI 10.1002/spe.2832
   Souri A, 2018, HUM-CENT COMPUT INFO, V8, DOI 10.1186/s13673-018-0125-x
   Srivastava PK., 2018, International Journal of Sensors Wireless Communications and Control, V8, P26, DOI [10.2174/2210327908666180413154130, DOI 10.2174/2210327908666180413154130]
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Ucci D, 2019, COMPUT SECUR, V81, P123, DOI 10.1016/j.cose.2018.11.001
   Vinayakumar R, 2019, IEEE ACCESS, V7, P46717, DOI 10.1109/ACCESS.2019.2906934
   Wuchner T., 2015, INT C DET INTR MALW, P98, DOI [10.1007/978-3-319-20550, DOI 10.1007/978-3-319-20550-2_6, 10.1007/978-3-319-20550-2_6]
   Ye YF, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3073559
   Yoo S.G., 2017, International Journal of Applied Engineering Research, V12, P7207
NR 52
TC 6
Z9 6
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10881
EP 10900
DI 10.1007/s11042-020-10317-6
EA JAN 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000604479100009
DA 2024-07-18
ER

PT J
AU Ramchandran, A
   Sangaiah, AK
AF Ramchandran, Anitha
   Sangaiah, Arun Kumar
TI Unsupervised deep learning system for local anomaly event detection in
   crowded scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video surveillance; Abnormal event detection; Crowd analysis;
   Convolutional auto encoder; Convolut LSTM
AB Anomaly detection in video surveillance is a significant research subject because of its immense use in real-time applications. These days, open spots like hospitals, traffic areas, airports are monitored by video surveillance cameras. Strange occasions in these recordings have alluded to the anomaly. Unsupervised anomaly detection in the video be endowed with many challenges as there is no exact definition of abnormal events. It varies as for various situations. This paper aims to propose an effective unsupervised deep learning framework for video anomaly detection. Raw image sequences are combined with edge image sequences and given as input to the convolutional auto encoder-ConvLSTM model. Experimental evaluation of the proposed work is performed in three different benchmark datasets such as Avenue, UCSD ped1 and UCSD ped2. The proposed method Hybrid Deep Learning framework for Video Anomaly Detection (HDLVAD) reaches better accuracy compared to existing methods. Investigating video streaming in big data is our further research work.
C1 [Ramchandran, Anitha; Sangaiah, Arun Kumar] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Sangaiah, AK (corresponding author), Vellore Inst Technol, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.
EM anitha66r@gmail.com; arunkumarsangaiah@gmail.com
RI Ramchandran, Anitha/KEH-4993-2024; Sangaiah, Arun Kumar/U-6785-2019
OI Sangaiah, Arun Kumar/0000-0002-0229-2460; Ramachandran,
   Anitha/0000-0003-3348-6126
CR Amraee S, 2018, SIGNAL IMAGE VIDEO P, V12, P1115, DOI 10.1007/s11760-018-1267-z
   Amraee S, 2018, MULTIMED TOOLS APPL, V77, P14767, DOI 10.1007/s11042-017-5061-7
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chaker R, 2017, PATTERN RECOGN, V61, P266, DOI 10.1016/j.patcog.2016.06.016
   Cheng KW, 2015, PROC CVPR IEEE, P2909, DOI 10.1109/CVPR.2015.7298909
   Chong YS, 2017, LECT NOTES COMPUT SC, V10262, P189, DOI 10.1007/978-3-319-59081-3_23
   Cong Y, 2013, PATTERN RECOGN, V46, P1851, DOI 10.1016/j.patcog.2012.11.021
   Fang ZJ, 2016, MULTIMED TOOLS APPL, V75, P14617, DOI 10.1007/s11042-016-3316-3
   Feng YC, 2017, NEUROCOMPUTING, V219, P548, DOI 10.1016/j.neucom.2016.09.063
   Feng YC, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2964284.2967290
   Haering N, 2008, MACH VISION APPL, V19, P279, DOI 10.1007/s00138-008-0152-0
   Hu X, 2018, EURASIP J ADV SIG PR, DOI 10.1186/s13634-018-0574-4
   Colque RVHM, 2017, IEEE T CIRC SYST VID, V27, P673, DOI 10.1109/TCSVT.2016.2637778
   Ionescu RT, 2017, IEEE I CONF COMP VIS, P2914, DOI 10.1109/ICCV.2017.315
   Kamath S., 2017, DYNAMIC VIDEO ANOMAL
   Leyva R, 2017, IEEE T IMAGE PROCESS, V26, P3463, DOI 10.1109/TIP.2017.2695105
   Li SF, 2018, PATTERN RECOGN LETT, V107, P91, DOI 10.1016/j.patrec.2017.09.001
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Liu C., 2018, ANOMALY DETECTION BA, V60
   Liu P, 2017, NEUROCOMPUTING, V269, P3, DOI 10.1016/j.neucom.2016.09.138
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7
   Piciarelli C, 2008, IEEE T CIRC SYST VID, V18, P1544, DOI 10.1109/TCSVT.2008.2005599
   Ravanbakhsh M, 2019, IEEE WINT CONF APPL, P1896, DOI 10.1109/WACV.2019.00206
   Ribeiro M, 2018, PATTERN RECOGN LETT, V105, P13, DOI 10.1016/j.patrec.2017.07.016
   Sabokrou M, 2016, ELECTRON LETT, V52, P1122, DOI 10.1049/el.2016.0440
   Sabokrou M, 2018, COMPUT VIS IMAGE UND, V172, P88, DOI 10.1016/j.cviu.2018.02.006
   Sabokrou M, 2017, IEEE T IMAGE PROCESS, V26, P1992, DOI 10.1109/TIP.2017.2670780
   Shahi A, 2016, ONLINE WEIGHTED CLUS, P536
   Sodemann AA, 2012, IEEE T SYST MAN CY C, V42, P1257, DOI 10.1109/TSMCC.2012.2215319
   Tran H. T. M., 2017, Anomaly detection using a convolutional autoencoder, winner-takeall
   Vu H., 2017, Energy-based models for video anomaly detection
   Wang J, 2015, CROWD ANOMALY DETECT
   Wang SQ, 2018, NEUROCOMPUTING, V277, P161, DOI 10.1016/j.neucom.2016.08.156
   Wang T, 2019, IEEE T INF FOREN SEC, V14, P1390, DOI 10.1109/TIFS.2018.2878538
   Wang T, 2018, OPTIK, V152, P50, DOI 10.1016/j.ijleo.2017.07.064
   Wang X, 2018, INT SYMP ELECTR APP, DOI 10.1109/SIELA.2018.8447105
   Xingjian S., 2015, CONVOLUTIONAL LSTM N
   Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010
   Yi Y, 2016, CONSTRAINED SPARSE R
   Yuan Y., 2014, ANOMALY DETECTION CR, P158
   Yuan Y, 2018, PATTERN RECOGN, V73, P99, DOI 10.1016/j.patcog.2017.08.001
   Zhang Y, 2016, PATTERN RECOGN, V59, P302, DOI 10.1016/j.patcog.2015.11.018
   Zhang Y, 2016, PATTERN RECOGN, V51, P443, DOI 10.1016/j.patcog.2015.09.005
   Zhang Z., 2016, SPATIALTEMPORAL CONV, V47
   Zhao YR, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1933, DOI 10.1145/3123266.3123451
NR 46
TC 24
Z9 26
U1 5
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35275
EP 35295
DI 10.1007/s11042-019-7702-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000595980900031
DA 2024-07-18
ER

PT J
AU Li, PA
   Tang, HD
   Yu, J
   Song, W
AF Li, Peian
   Tang, Huadong
   Yu, Jing
   Song, Wei
TI LSTM and multiple CNNs based event image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Event classification; Convolutional neural networks; Long short-term
   memory; Feature combination; Context information
ID CONVOLUTIONAL NEURAL-NETWORKS; DEEP; RECOGNITION
AB Previous studies have demonstrated that complexity and variation of event images are the major challenges in event classification. We approach the problem through an integrated methodology by utilizing Long Short-Term Memory network (LSTM) to fuse multiple Convolutional Neural Networks (CNNs). To address the issue of complexity, we use three specific CNNs to extract the scene, object and human visual cues respectively. To reduce the semantic gap and utilize the complementarity of the features in different levels, we choose AlexNet and VGG-16 network as the basic structures, and concatenate their outputs of the first fully-connected layer and the second fully-connected layer. Considering the contextual correlations between visual cues, we arrange the concatenations of three CNNs in the sequence of scene, object and human as a whole and put into the LSTM network. Particularly for context, we crop the images into five blocks as input and an individual image is supplemented with contextual features due to the temporal characteristics of the LSTM. We evaluate our method on the Web Image Dataset for Event Recognition (WIDER), and the obtained results demonstrate the effectiveness of all the above points. Compared with the state-of-the-art methods, the proposed method gives a considerable way for improving the performance on event classification.
C1 [Li, Peian; Song, Wei] Minzu Univ China, Sch Informat Engn, Beijing, Peoples R China.
   [Li, Peian; Tang, Huadong; Yu, Jing] Beijing Jiaotong Univ, Sch Elect Informat & Engn, Beijing, Peoples R China.
   [Song, Wei] Minzu Univ China, Natl Language Resource Monitoring & Res Ctr Minor, Beijing, Peoples R China.
C3 Minzu University of China; Beijing Jiaotong University; Minzu University
   of China
RP Song, W (corresponding author), Minzu Univ China, Sch Informat Engn, Beijing, Peoples R China.; Song, W (corresponding author), Minzu Univ China, Natl Language Resource Monitoring & Res Ctr Minor, Beijing, Peoples R China.
EM songwei@muc.edu.cn
RI Tang, Huadong/AAE-5387-2021; Tang, Huadong/IUQ-8603-2023
OI Tang, Huadong/0000-0003-3604-4390
FU National Science Foundation Project of P. R. China [52071349, 61701554];
   cross-discipline research project of Minzu University of China
   [2020MDJC08]; State Language Commission Key Project [ZDl135-39];
   Promotion plan for young teachers' scientific research ability of Minzu
   University of China , MUC 111 Project, First class courses (Digital
   Image Processing) [KC2066]
FX This work was supported in part by National Science Foundation Project
   of P. R. China under Grant No.52071349, No.61701554 and the
   cross-discipline research project of Minzu University of China
   (2020MDJC08), State Language Commission Key Project (ZDl135-39),
   Promotion plan for young teachers' scientific research ability of Minzu
   University of China, MUC 111 Project, First class courses (Digital Image
   Processing KC2066). We gratefully acknowledge the assistance of Dr.
   Lizhi Zhao providing part of the revised manuscript and valuable
   discussion.
CR Agrawal P, 2014, LECT NOTES COMPUT SC, V8695, P329, DOI 10.1007/978-3-319-10584-0_22
   [Anonymous], 2015, ARXIV150906033
   [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], 2016, P KOREA JAPAN JOINT
   [Anonymous], 2015, ARXIV150801667
   [Anonymous], 2015, CORR
   Bai S, 2018, NEUROCOMPUTING, V311, P291, DOI 10.1016/j.neucom.2018.05.080
   Bai S, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S0218001417550138
   Bai S, 2017, EXPERT SYST APPL, V71, P279, DOI 10.1016/j.eswa.2016.10.038
   Bossard L, 2013, IEEE I CONF COMP VIS, P1193, DOI 10.1109/ICCV.2013.151
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Hayat M, 2016, IEEE T IMAGE PROCESS, V25, P4829, DOI 10.1109/TIP.2016.2599292
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Izadinia H, 2014, PROC CVPR IEEE, P232, DOI 10.1109/CVPR.2014.37
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kolen JF, 2009, A Field Guide to Dynamical Recurrent Networks, DOI [DOI 10.1109/9780470544037.CH14, 10.1109/9780470544037]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li LJ, 2007, IEEE I CONF COMP VIS, P345
   Li LJ, 2010, ADV NEURAL INF PROCE, P23
   Limin Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P30, DOI 10.1109/CVPRW.2015.7301333
   Lin D, 2014, PROC CVPR IEEE, P3726, DOI 10.1109/CVPR.2014.476
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Liu JE, 2013, IEEE WORK APP COMP, P339, DOI 10.1109/WACV.2013.6475038
   Liu MY, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P274, DOI 10.1109/ICCVW.2015.44
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mattivi R., 2011, Proceedings of the 2011 joint ACM workshop on Modeling and representing events, P7, DOI DOI 10.1145/2072508.2072511
   Oh SJ, 2015, IEEE I CONF COMP VIS, P3862, DOI 10.1109/ICCV.2015.440
   Pandey M, 2011, IEEE I CONF COMP VIS, P1307, DOI 10.1109/ICCV.2011.6126383
   Parizi SN, 2012, PROC CVPR IEEE, P2775, DOI 10.1109/CVPR.2012.6248001
   Park S, 2015, IEEE C COMP VIS PATT, P45
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Quelhas P, 2007, IEEE T PATTERN ANAL, V29, P1575, DOI 10.1109/TPAMI.2007.1155
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salvador A, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301334
   Simonyan K., 2015, P 3 INT C LEARN REPR
   Sun X, 2019, IEEE T CYBERNETICS, V49, P2156, DOI 10.1109/TCYB.2018.2820731
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tian Z, 2016, LECT NOTES COMPUT SC, V9912, P56, DOI 10.1007/978-3-319-46484-8_4
   Wang J, 2018, ADV SOC SCI EDUC HUM, V196, P214
   Wang LZ, 2015, TUNN UNDERGR SP TECH, V45, P52, DOI 10.1016/j.tust.2014.09.005
   Wang LM, 2018, INT J COMPUT VISION, V126, P390, DOI 10.1007/s11263-017-1043-5
   Wang MS, 2019, CMC-COMPUT MATER CON, V60, P781, DOI 10.32604/cmc.2019.05595
   Wang YF, 2016, PROC CVPR IEEE, P4810, DOI 10.1109/CVPR.2016.520
   Wu XY, 2019, CMC-COMPUT MATER CON, V61, P289, DOI 10.32604/cmc.2019.05990
   Xiong YJ, 2015, PROC CVPR IEEE, P1600, DOI 10.1109/CVPR.2015.7298768
   Xu F, 2019, CMC-COMPUT MATER CON, V58, P697, DOI 10.32604/cmc.2019.05375
   Yang Y, 2012, LECT NOTES COMPUT SC, V7574, P722, DOI 10.1007/978-3-642-33712-3_52
   Yogatama Dani, 2017, CoRR abs/1703.01898
   Yosinski J, 2014, ADV NEUR IN, V27
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang CJ, 2017, NEUROCOMPUTING, V257, P88, DOI 10.1016/j.neucom.2016.11.065
   Zhang N, 2015, PROC CVPR IEEE, P4804, DOI 10.1109/CVPR.2015.7299113
   Zhang TL, 2018, AAAI CONF ARTIF INTE, P620
   Zhou B., 2014, CORR, V1412, P6856
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhou P., 2016, ARXIV161106639
NR 61
TC 8
Z9 9
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30743
EP 30760
DI 10.1007/s11042-020-10165-4
EA NOV 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000591969300002
DA 2024-07-18
ER

PT J
AU Chen, JJ
   Tian, YL
   Ma, W
   Mao, ZD
   Hu, Y
AF Chen, Jianjun
   Tian, Youliang
   Ma, Wei
   Mao, Zhengdong
   Hu, Yue
TI Scale channel attention network for image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Convolutional neural network; Attention mechanism;
   Spatial pyramid pooling; Multi-source and heterogeneous data
AB The object scale variation results in a negative effect on image segmentation performance. Spatial pyramid pooling module or the attention mechanism are two widely used components in deep neural networks to handle this problem. Applying the single component commonly achieves limited benefit. To push the limit, in this paper, we propose a scale channel attention network (SCA-Net), which enhances the fusion feature of multi-scale by using channel attention components. After the multiple-scale pooling step, the multi-scale spatial information distributes in different feature channels. Meanwhile, the channel attention block is employed to guide SCA-Net focus on the object-relevant scale channels. We further explore the channel attention block and find a simple yet effective structure to combine global average pooling and global maximum pooling, resulting in a robust global information encoder. The SCA-Net does not contain any time-consuming post-processing, which is an extra step after the neural network for the segmentation result optimization. The assessment results on PASCAL VOC 2012 and Cityscapes benchmarks achieve the test set performance of 75.5% and 77.0%.
C1 [Chen, Jianjun; Ma, Wei; Mao, Zhengdong; Hu, Yue] Chinese Acad Sci, Inst Informat Engn, Natl Engn Lab Informat Secur Technol, Beijing 100093, Peoples R China.
   [Chen, Jianjun] Univ Chinese Acad Sci, Sch Cyber Secur, Beijing, Peoples R China.
   [Tian, Youliang] Guizhou Univ, Coll Comp Sci & Technol, Guizhou Prov Key Lab Publ Big Data, Guiyang 550025, Guizhou, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Information Engineering, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Guizhou University
RP Tian, YL (corresponding author), Guizhou Univ, Coll Comp Sci & Technol, Guizhou Prov Key Lab Publ Big Data, Guiyang 550025, Guizhou, Peoples R China.
EM yltian@gzu.edu.cn
RI Hu, Yue/HGE-1673-2022
FU National Key Research and Development Program of China [2017YFB0803301];
   Major Scientific and Technological Special Project of Guizhou Province
   [20183001]
FX This paper is partly supported by the National Key Research and
   Development Program of China (2017YFB0803301) and the Major Scientific
   and Technological Special Project of Guizhou Province (20183001).
CR Adelson E. H., 1984, RCA engineer, V29, P33, DOI 10.1.1.59.9419.
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], 2019, IEEE T MED IMAGING, DOI DOI 10.1109/TMI.2018.2867261
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bluche T, 2016, ADV NEUR IN, P838
   Bulò SR, 2017, PROC CVPR IEEE, P7082, DOI 10.1109/CVPR.2017.749
   Burt P. J., 1988, 9th International Conference on Pattern Recognition (IEEE Cat. No.88CH2614-6), P977, DOI 10.1109/ICPR.1988.28419
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Du H, 2019, MULTIMED TOOLS APPL, V78, P12125, DOI 10.1007/s11042-018-6736-4
   Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang Z., 2018, COMPUTER VISION PATT
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin GS, 2016, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2016.348
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Mnih V, 2014, ADV NEUR IN, V27
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tian YL, 2019, IEEE ACCESS, V7, P44037, DOI 10.1109/ACCESS.2019.2908858
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang CC, 2017, MULTIMED TOOLS APPL, V76, P10481, DOI 10.1007/s11042-016-3616-7
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Woo S., 2018, P EUR C COMP VIS ECC, DOI DOI 10.1007/978-3-030-01234-2_1
   Xie HT, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3231737
   Xie HT, 2019, PATTERN RECOGN, V85, P109, DOI 10.1016/j.patcog.2018.07.031
   Zhang W, 2018, IEEE CONF COMPUT
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
NR 41
TC 4
Z9 4
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16473
EP 16489
DI 10.1007/s11042-020-08921-7
EA NOV 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000590503300004
DA 2024-07-18
ER

PT J
AU Khalid, S
   Ullah, S
   Ali, N
   Alam, A
   Rasheed, N
   Fayaz, M
   Ahmad, M
AF Khalid, Shah
   Ullah, Sehat
   Ali, Numan
   Alam, Aftab
   Rasheed, Nasir
   Fayaz, Muhammad
   Ahmad, Masood
TI The effect of combined aids on users performance in collaborative
   virtual environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality (VR); 3D virtual environments (VEs); Collaborative
   virtual environments (CVEs); Navigational aids; Visual and audio aids;
   Three dimensional map with liner (3DML); Combined navigational aids
ID MAP; GUIDANCE; REALITY
AB For Collaborative Virtual Environments (CVEs), many interaction techniques have been developed. Depending on the purpose of the collaborative work, techniques of interaction and manipulation change from one application to another. There is no general, good and efficient solution for all the collaborative systems. In addition, people in CVEs also use communication channels to share task goals, task decomposition and task progress. Therefore, awareness and communications are usually considered as important instruments to complete collaborative task. In this paper, we have combined different virtual navigation aids i.e. 3DML + audio, 3DML + textual, 3DML + arrows-casting, arrows-casting + audio, arrows-casting + textual and audio + textual; and presented a comparative study of user performance to perform an assembly task in CVEs. We reported the results of a precise experiment containing, 30 virtual teams of 60 individual students. Overall, results showed that students performed task faster using 3DML + arrows-casting while they were slow with audio + textual support in navigation.
C1 [Khalid, Shah; Ullah, Sehat; Ali, Numan; Alam, Aftab; Rasheed, Nasir] Univ Malakand, Dept Comp Sci & IT, Chakdara 18800, Pakistan.
   [Ali, Numan] Univ Agr Peshawar, Inst Comp Sci & IT ICS IT, Peshawar 25000, Pakistan.
   [Fayaz, Muhammad] Univ Cent Asia, Dept Comp Sci, Naryn, Kyrgyzstan.
   [Ahmad, Masood] Abdul Wali Khan Univ Timergara, Dept Comp Sci, Timergara 18300, Pakistan.
C3 University of Malakand; University of Central Asia
RP Ali, N (corresponding author), Univ Malakand, Dept Comp Sci & IT, Chakdara 18800, Pakistan.; Ali, N (corresponding author), Univ Agr Peshawar, Inst Comp Sci & IT ICS IT, Peshawar 25000, Pakistan.
EM shahkhalid@uom.edu.pk; sehatullah@uom.edu.pk; numan@uom.edu.pk;
   alam@uom.edu.pk; nasir@uom.edu.pk; muhammad.fayaz@ucentralasia.org;
   masood@awkm.edu.pk
RI Fayaz, Muhammad/CAF-2058-2022; Ali, Dr. Numan/AAQ-6257-2020; ALAM,
   AFTAB/KBB-9870-2024; ullah, sehat/HTT-4581-2023
OI Fayaz, Muhammad/0000-0001-6383-2988; ullah, sehat/0000-0002-1193-9350;
   Ali, Dr. Numan/0000-0002-9087-4814
CR [Anonymous], 1999, Wayfinding behavior: Cognitive mapping and other spatial processes
   Bowers J., 1996, Human Factors in Computing Systems. Common Ground. CHI 96 Conference Proceedings, P58, DOI 10.1145/238386.238404
   Chen CH, 2007, EDUC TECHNOL SOC, V10, P289
   Chen J, 2003, P YOUNG INV FOR VIRT
   Churchill Elizabeth F, 2012, Collaborative virtual environments: digital places and spaces for interaction
   Chwen Jen Chen, 2008, Journal of Interactive Learning Research, V19, P579
   Dominic J, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P607, DOI [10.1109/VR46266.2020.00-21, 10.1109/VR46266.2020.1581637338566]
   Hanna N, 2014, PACIS, P284
   Harrison Steve R, 1996, P 1996 ACM C COMP SU, V96, P67, DOI [DOI 10.1145/240080.240193, 10.1145/240080.240193]
   Hölscher C, 2007, LECT NOTES ARTIF INT, V4387, P365
   Inamura T, 2019, ACMIEEE INT CONF HUM, P552, DOI [10.1109/hri.2019.8673218, 10.1109/HRI.2019.8673218]
   Khan N, 2018, INT J HUM-COMPUT INT, V34, P1135, DOI 10.1080/10447318.2017.1418804
   Kiraly AP, 2004, IEEE T MED IMAGING, V23, P1365, DOI 10.1109/TMI.2004.829332
   Klippel A, 2010, SPAT COGN COMPUT, V10, P83, DOI 10.1080/13875861003770625
   Latombe JC, 2006, PROCEEDINGS OF THE FIFTH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS, VOLS 1 AND 2, P1
   Lobben AK, 2007, ANN ASSOC AM GEOGR, V97, P64, DOI 10.1111/j.1467-8306.2007.00524.x
   Meade ME, 2019, BRAIN SCI, V9, DOI 10.3390/brainsci9030047
   Monahan T, 2008, COMPUT EDUC, V50, P1339, DOI 10.1016/j.compedu.2006.12.008
   Montuwy A, 2019, BEHAV INFORM TECHNOL, V38, P150, DOI 10.1080/0144929X.2018.1519035
   Nguyen T. T. H., 2013, GUIDING TECHNIQUES C
   Noborio H, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P4255, DOI 10.1109/ROBOT.2002.1014424
   Raees M, 2019, INT J INTERACT DES M, V13, P35, DOI 10.1007/s12008-018-0481-9
   Raper J, 2007, J LOCAT BASED SERV, V1, P5, DOI 10.1080/17489720701584069
   Rehman IU, 2014, 2014 INTERNATIONAL CONFERENCE ON OPEN SOURCE SYSTEMS AND TECHNOLOGIES (ICOSST), P87, DOI 10.1109/ICOSST.2014.7029326
   Rothe S, 2019, MULTIMODAL TECHNOLOG, V3, DOI 10.3390/mti3010019
   Sampaio A., 2006, P M ICTE, V4
   Sayers H. M., 2004, Virtual Reality, V7, P131, DOI 10.1007/s10055-004-0124-2
   Schlender D., 2000, Spatial Cognition and Computation, V2, P421, DOI 10.1023/A:1015544021492
   Shendarkar A, 2006, PROCEEDINGS OF THE 2006 WINTER SIMULATION CONFERENCE, VOLS 1-5, P545, DOI 10.1109/WSC.2006.323128
   Tao Y, 2020, IEEE ACCESS, V8, P20028, DOI 10.1109/ACCESS.2020.2968435
   Tsovaltzi D, 2010, INT J TECHNOL ENHANC, V2, P91, DOI 10.1504/IJTEL.2010.031262
   Ullah S, 2016, J CHEM EDUC, V93, P2018, DOI 10.1021/acs.jchemed.5b00969
   Wang HM, 2009, J NANJING U SCI TECH, V5
   Wu F, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P79, DOI [10.1109/VRW50115.2020.0-255, 10.1109/VRW50115.2020.00021]
   Yong S, 2008, INT J COMPUT SCI NET, V8, P14
NR 35
TC 7
Z9 7
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9371
EP 9391
DI 10.1007/s11042-020-09953-9
EA NOV 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000587972300002
DA 2024-07-18
ER

PT J
AU Zhang, X
   Ye, RS
AF Zhang, Xing
   Ye, Ruisong
TI A novel RGB image encryption algorithm based on DNA sequences and chaos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos; Image encryption; DNA sequence; Hamming distance; Circle distance
ID SCHEME; MAP; CRYPTANALYSIS; OPERATION; SYSTEM
AB Based on the deoxyribonucleic acid (DNA) sequence operations and chaotic systems, a novel improved color image encryption algorithm is presented with one-time-pad. Three DNA matrices are obtained by DNA encoding the plain-image firstly. To enhance the proposed algorithm's robustness of resisting known-plaintext and chosen-plaintext attacks, the key streams, which are used to scramble the positions of the three DNA matrices, are generated from 3D skew tent map (3D-STM) by using the secret keys and the hamming distances between the DNA matrices. Then, we perform the DNA XOR, addition and subtraction operations on the DNA matrices and the key streams to get the cipher-image. At this stage, we also update the initial values of the coupled map lattice (CML) by the circle distance of DNA matrices obtained from the previous step to further enhance the proposed algorithm's ability of resisting plaintext attack. Finally, we get the encrypted color image by decoding DNA matrices. The simulation and security analysis show that the proposed algorithm has an extraordinary ability to resist plaintext attack, differential attack and statistical attack, etc.
C1 [Zhang, Xing; Ye, Ruisong] Shantou Univ, Dept Math, Shantou 515063, Guangdong, Peoples R China.
C3 Shantou University
RP Ye, RS (corresponding author), Shantou Univ, Dept Math, Shantou 515063, Guangdong, Peoples R China.
EM rsye@stu.edu.cn
OI Ye, Ruisong/0000-0003-2341-5076
FU National Natural Science Foundation of China [11771265]; key research
   projects of general universities in Guangdong Province [2019KZDXM034];
   Basic research and applied basic research projects in Guangdong Province
   (Projects of Guangdong, Hong Kong and Macao Center for Applied
   Mathematics) [20202002110000018]
FX The authors would like to thank for the support of National Natural
   Science Foundation of China under grant no. 11771265, key research
   projects of general universities in Guangdong Province under grant no.
   2019KZDXM034 and Basic research and applied basic research projects in
   Guangdong Province (Projects of Guangdong, Hong Kong and Macao Center
   for Applied Mathematics) under grant no. 20202002110000018. The authors
   also would like to thank the anonymous referees for their valuable,
   constructive comments and suggestions.
CR Al-Maytami BA, 2020, AD HOC NETW, V98, DOI 10.1016/j.adhoc.2019.102028
   Alloghani M, 2019, J INF SECUR APPL, V48, DOI 10.1016/j.jisa.2019.102362
   [Anonymous], 2004, An Introduction to Dynamical Systems: Continuous and Discrete
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chen JX, 2015, OPT LASER ENG, V67, P191, DOI 10.1016/j.optlaseng.2014.11.017
   Clelland CT, 1999, NATURE, V399, P533, DOI 10.1038/21092
   Gaborit P, 2005, THEOR COMPUT SCI, V334, P99, DOI 10.1016/j.tcs.2004.11.004
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   Hou YC, 2013, INFORM SCIENCES, V233, P290, DOI 10.1016/j.ins.2013.01.006
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Kalpana J, 2015, OPTIK, V126, P5703, DOI 10.1016/j.ijleo.2015.09.091
   Konishi K, 1999, PHYS LETT A, V263, P307, DOI 10.1016/S0375-9601(99)00710-0
   Kumar M, 2015, J INF SECUR APPL, V21, P20, DOI 10.1016/j.jisa.2014.11.003
   Li S, 2005, CHAOS BASED ENCRYPTI
   Li TH, 2011, 2011 INTERNATIONAL CONFERENCE ON MECHANICAL ENGINEERING AND TECHNOLOGY (ICMET 2011), P317
   Li X, 2016, OPTIK, V127, P2558, DOI 10.1016/j.ijleo.2015.11.221
   Liao XF, 2010, SIGNAL PROCESS, V90, P2714, DOI 10.1016/j.sigpro.2010.03.022
   Liu HJ, 2015, OPT COMMUN, V338, P340, DOI 10.1016/j.optcom.2014.10.021
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Liu SB, 2009, J COMPUT, V4, P1091
   Liu YS, 2014, OPT LASER TECHNOL, V60, P111, DOI 10.1016/j.optlastec.2014.01.015
   Murillo-Escobar MA, 2015, SIGNAL PROCESS, V109, P119, DOI 10.1016/j.sigpro.2014.10.033
   Shen CW, 2014, IEEE T CIRCUITS-I, V61, P2380, DOI 10.1109/TCSI.2014.2304655
   Shevchenko II, 2014, PHYS LETT A, V378, P34, DOI 10.1016/j.physleta.2013.10.035
   Tong XJ, 2015, J VIS COMMUN IMAGE R, V33, P219, DOI 10.1016/j.jvcir.2015.09.014
   Volos CK, 2013, SIGNAL PROCESS, V93, P1328, DOI 10.1016/j.sigpro.2012.11.008
   Wang K, 2005, PHYS LETT A, V343, P432, DOI 10.1016/j.physleta.2005.05.040
   Wang LY, 2016, OPT LASER ENG, V77, P118, DOI 10.1016/j.optlaseng.2015.07.015
   Wang XY, 2015, NONLINEAR DYNAM, V82, P1269, DOI 10.1007/s11071-015-2234-7
   Wang XY, 2010, COMMUN NONLINEAR SCI, V15, P2479, DOI 10.1016/j.cnsns.2009.10.001
   Wang Y, 2007, PHYS LETT A, V363, P277, DOI 10.1016/j.physleta.2006.11.023
   Wang Y, 2009, CHAOS SOLITON FRACT, V41, P1773, DOI 10.1016/j.chaos.2008.07.031
   Wasiewicz P, 2000, IEEE SYS MAN CYBERN, P265, DOI 10.1109/ICSMC.2000.885000
   Wei J, 2007, COMMUN NONLINEAR SCI, V12, P814, DOI 10.1016/j.cnsns.2005.06.001
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Ye RS, 2011, OPT COMMUN, V284, P5290, DOI 10.1016/j.optcom.2011.07.070
   Ye Ruisong, 2012, INT J COMPUTER NETWO, V4, P38
   YU W, 2006, PHYS J, V396, P9
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang Q, 2010, ADV SCI LETT, V3, P447, DOI 10.1166/asl.2010.1170
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang YS, 2014, OPTIK, V125, P1562, DOI 10.1016/j.ijleo.2013.09.018
   Zhou YC, 2014, SIGNAL PROCESS, V100, P197, DOI 10.1016/j.sigpro.2014.01.020
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 45
TC 14
Z9 15
U1 2
U2 50
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8809
EP 8833
DI 10.1007/s11042-020-09465-6
EA NOV 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000586377600004
DA 2024-07-18
ER

PT J
AU Kaspal, R
   Alsadoon, A
   Prasad, PWC
   Al-Saiyd, NA
   Nguyen, TQV
   Pham, DTH
AF Kaspal, Rabin
   Alsadoon, Abeer
   Prasad, P. W. C.
   Al-Saiyd, Nedhal A.
   Nguyen, Tran Quoc Vinh
   Pham, Duong Thu Hang
TI A novel approach for early prediction of sudden cardiac death (SCD)
   using hybrid deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sudden cardiac death; Convolution neural network; Recurrence complex
   network deep learning; Dropout regularization; Electrocardiogram (ECG)
   signals
ID FEATURE-SELECTION; NEURAL-NETWORK; CLASSIFICATION; STRATEGY
AB Importance of early prediction of Sudden Cardiac Deaths (SCD) has been rising as a large percentage of mortality of patients with cardiovascular diseases. Various deep learning methodologies has been developed to predict the onset of SCDs, Their key limitation is either classification accuracy or the processing time. This research tries to improve the classification accuracy and decrease the processing time. A Convolutional Neural Network (CNN) is combined with a Recurrence Complex Network (RCN) along with Dropout Regularization to enhance the accuracy of SCD classification. Initially, the synchronization feature of individual heartbeat of the electrocardiogram (ECG) signal is constructed by RCN. The recurrence matrix from the (RCN) will generate Eigen values. Then, CNN will be employed to extract features and detect SCD by analysing the Eigen values. Finally, the performance of the classification is improved by the developing a voting algorithm for the SCD detection. MIT-BIH SCD database is used to evaluate the proposed system. The average accuracy and processing time for MIT-BIH Arrhythmia dataset is 93.24% and 21 epochs, MIT-BIH SCD Holter dataset is 90.60% and 11.5 epochs, and Apnoea-ECG dataset is 92.13% and 13.5 epochs. The average processing time has also been reduced to 20.77 milliseconds against the current processing time of 32.96 milliseconds. The proposed system enhances the classification accuracy and the processing time of the prediction system. The study eradicates the issue of gradient saturation during the training of the CNN by proposing a new activation function as well as eliminates the risk of overfitting by implementing dropout regularization in CNN.
C1 [Kaspal, Rabin; Alsadoon, Abeer; Prasad, P. W. C.] Charles Sturt Univ, Sch Comp & Math, Sydney, NSW, Australia.
   [Al-Saiyd, Nedhal A.] Appl Sci Private Univ, Fac Informat Technol, Amman, Jordan.
   [Nguyen, Tran Quoc Vinh; Pham, Duong Thu Hang] Univ Da Nang Univ Sci & Educ, Fac Informat Technol, Da Nang, Vietnam.
C3 Charles Sturt University
RP Alsadoon, A (corresponding author), Charles Sturt Univ, Sch Comp & Math, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021; Al-Saiyd, Nedhal/JMB-0807-2023
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; Al-Saiyd,
   Nedhal/0000-0002-9282-890X; withana, chandana/0000-0002-3007-687X
CR Acharya UR, 2017, INFORM SCIENCES, V415, P190, DOI 10.1016/j.ins.2017.06.027
   Alfarhan KA, 2018, J MED IMAG HEALTH IN, V8, P1769, DOI 10.1166/jmihi.2018.25311769
   Amezquita-Sanchez JP, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1031-5
   [Anonymous], 2015, ABS151107289 CORR
   Chugh SS, 2000, CIRCULATION, V102, P649, DOI 10.1161/01.CIR.102.6.649
   Dang H, 2019, IEEE ACCESS, V7, P75577, DOI 10.1109/ACCESS.2019.2918792
   Delakis M, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P290
   Devi R, 2019, BIOCYBERN BIOMED ENG, V39, P586, DOI 10.1016/j.bbe.2019.05.011
   Ebrahimzadeh E, 2019, COMPUT METH PROG BIO, V169, P19, DOI 10.1016/j.cmpb.2018.12.001
   Ebrahimzadeh E, 2018, MED BIOL ENG COMPUT, V56, P1253, DOI 10.1007/s11517-017-1764-1
   Fujita H, 2016, APPL SOFT COMPUT, V43, P510, DOI 10.1016/j.asoc.2016.02.049
   Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401
   Jang DH, 2020, AM J EMERG MED, V38, P43, DOI 10.1016/j.ajem.2019.04.006
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Korpusik M, 2017, INT CONF ACOUST SPEE, P5685, DOI 10.1109/ICASSP.2017.7953245
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   KWON JM, 2019, PLOS ONE, V14, DOI DOI 10.1371/JOURNAL.PONE.0219302
   Kwon JM, 2019, RESUSCITATION, V139, P84, DOI 10.1016/j.resuscitation.2019.04.007
   Kwon JM, 2019, ECHOCARDIOGR-J CARD, V36, P213, DOI 10.1111/echo.14220
   Kwon JM, 2018, J AM HEART ASSOC, V7, DOI 10.1161/JAHA.118.008678
   Lai DK, 2019, IEEE ACCESS, V7, P94701, DOI 10.1109/ACCESS.2019.2925847
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li J, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/7354081
   Li ZJ, 2019, IEEE ACCESS, V7, P77849, DOI 10.1109/ACCESS.2019.2920900
   Parsi A, 2020, IEEE REV BIOMED ENG, V13, P5, DOI 10.1109/RBME.2019.2912313
   Sannino G, 2018, FUTURE GENER COMP SY, V86, P446, DOI 10.1016/j.future.2018.03.057
   Wei XL, 2019, J PROBAB STAT, V2019, DOI 10.1155/2019/8057820
   Zhai XL, 2018, IEEE ACCESS, V6, P27465, DOI 10.1109/ACCESS.2018.2833841
   Zhang M, 2017, IEEE ACCESS, V5, P11074, DOI 10.1109/ACCESS.2017.2716191
NR 29
TC 9
Z9 9
U1 3
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 8063
EP 8090
DI 10.1007/s11042-020-10150-x
EA OCT 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000583128600010
DA 2024-07-18
ER

PT J
AU Jan, F
   Min-Allah, N
   Agha, S
   Usman, I
   Khan, I
AF Jan, Farmanullah
   Min-Allah, Nasro
   Agha, Shahrukh
   Usman, Imran
   Khan, Irfanullah
TI A robust iris localization scheme for the iris recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pupil localization; Iris localization; Iris biometrics; Iris
   segmentation; Digital image processing; Security and surveillance
ID VISIBLE WAVELENGTH; SEGMENTATION
AB Due to current security situations around the globe, iris biometric technology is highly preferred for both overt and covert applications. A typical iris biometric system includes image acquisition, iris segmentation, features extraction, and matching and recognition modules. Amongst these modules, iris segmentation plays a decisive role because it segments the valid iris part in an input eyeimage. It includes two tasks: iris localization and noise (e.g., eyelids) removal. Notably, the overall performance of an iris biometric system strongly relies on the iris localization task, because it demarcates the actual iris contours. Some contemporary iris localization schemes search over a three-dimensional (3D) space while marking iris boundaries, which is a time-consuming process if not optimized properly. Besides, some schemes also resort to the fixed and/or crude thresholding-based techniques for pupil localization. Notably, such schemes may perform poorly if image data do not maintain quality. To address these issues, this study proposes a robust iris localization scheme maintaining both speed and accuracy. It includes preprocessing the input eyeimage using an order statistic-filter and the bilinear interpolation scheme, extracting an adaptive threshold using the image's histogram, processing binary image via the morphological operators, extracting pupil's center and radius based on the centroid and geometry concepts, marking iris outer boundary using the Circular Hough transform (CHT) and refining coarse iris boundaries through the Fourier series. The proposed scheme exhibits relatively better experimental results compared with some contemporary iris localization schemes on the public iris databases: IITD V1.0, CASIA-Iris-Interval and MMU V1.0.
C1 [Jan, Farmanullah; Min-Allah, Nasro; Khan, Irfanullah] Imam Abdulrahman Bin Faisal Univ, Coll Comp Sci & Informat Technol, Dept Comp Sci, POB 1982, Dammam, Saudi Arabia.
   [Agha, Shahrukh] COMSATS Univ Islamabad, Dept Elect & Comp Engn, Pk Rd, Islamabad 44000, Pakistan.
   [Usman, Imran] Saudi Elect Univ, Coll Comp & Informat, Dept Comp Sci, Riyadh, Saudi Arabia.
C3 Imam Abdulrahman Bin Faisal University; COMSATS University Islamabad
   (CUI); Saudi Electronic University
RP Jan, F (corresponding author), Imam Abdulrahman Bin Faisal Univ, Coll Comp Sci & Informat Technol, Dept Comp Sci, POB 1982, Dammam, Saudi Arabia.
EM fzmjan@iau.edu.sa
RI Min-Allah, Nasro/O-3147-2019
OI Jan, Farmanullah/0000-0002-9118-3652; min-allah,
   nasro/0000-0002-3435-8823
CR [Anonymous], 2003, Matlab source code for a biometric identification system based on iris patterns
   Basil A, 2007, INTERNATIONAL CONFERENCE ON MACHINE VISION 2007, PROCEEDINGS, P23, DOI 10.1109/ICMV.2007.4469267
   Bowyer K, 2012, HDB IRIS RECOGNITION
   Bowyer KW, 2008, COMPUT VIS IMAGE UND, V110, P281, DOI 10.1016/j.cviu.2007.08.005
   COCOBOD, 2007, COCOBOD NEWS, V3, P3
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Daugman J, 2007, IEEE T SYST MAN CY B, V37, P1167, DOI 10.1109/TSMCB.2007.903540
   Gonzalez RC, 1992, PRENTICE HALL PROFES, V2nd
   Jan F., 2014, THESIS
   Jan F, 2018, MULTIMED TOOLS APPL, V77, P1041, DOI 10.1007/s11042-016-4334-x
   Jan F, 2017, SIGNAL PROCESS, V133, P192, DOI 10.1016/j.sigpro.2016.11.007
   Jan F, 2014, OPTIK, V125, P4274, DOI 10.1016/j.ijleo.2014.04.009
   Jan F, 2012, DIGIT SIGNAL PROCESS, V22, P971, DOI 10.1016/j.dsp.2012.06.001
   Kapoor R, 2019, MULTIMED TOOLS APPL, V78, P19279, DOI 10.1007/s11042-019-7314-0
   Khan TM, 2011, OPT LASER ENG, V49, P177, DOI 10.1016/j.optlaseng.2010.08.020
   Labati RD, 2010, IMAGE VISION COMPUT, V28, P270, DOI 10.1016/j.imavis.2009.05.004
   Ma L, 2020, DIGIT SIGNAL PROCESS, V100, DOI 10.1016/j.dsp.2020.102682
   Masek L., 2003, THESIS CITESEER
   Mehrotra H, 2013, MATH COMPUT MODEL, V58, P132, DOI 10.1016/j.mcm.2012.06.034
   Nguyen K, 2017, PATTERN RECOGN, V72, P123, DOI 10.1016/j.patcog.2017.05.021
   Ross AA., 2006, International series on biometrics, P1, DOI DOI 10.1109/BCC.2006.4341625
   Santos Gil, 2009, Proceedings of the 2009 International Conference on Computational Intelligence and Security (CIS 2009), P315, DOI 10.1109/CIS.2009.113
   Sardar M, 2018, APPL SOFT COMPUT, V67, P61, DOI 10.1016/j.asoc.2018.02.047
   Shah S, 2009, IEEE T INF FOREN SEC, V4, P824, DOI 10.1109/TIFS.2009.2033225
   Soliman NF, 2017, OPTIK, V140, P469, DOI 10.1016/j.ijleo.2016.11.150
   Tan Chun-Wei., 2011, CVPR_2011_WORKSHOPS, P9
   Wan HL, 2013, IET IMAGE PROCESS, V7, P111, DOI 10.1049/iet-ipr.2012.0084
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
NR 28
TC 7
Z9 9
U1 5
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4579
EP 4605
DI 10.1007/s11042-020-09814-5
EA SEP 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000574101100007
DA 2024-07-18
ER

PT J
AU Tang, R
   Chen, LH
   Zhang, RZ
   Ahmad, A
   Albertini, MK
   Yang, XM
AF Tang, Rui
   Chen, Lihui
   Zhang, Rongzhu
   Ahmad, Awais
   Albertini, Marcelo Keese
   Yang, Xiaomin
TI Medical image super-resolution with laplacian dense network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image; Super-resolution; Laplacian pyramid structure; Dense
   convolutional neural network
AB High resolution medical images are expected for accurate analysis results in medical diagnosis. However, the resolution of these medical images is always restricted by the factors such as medical devices, time constraints. Despite these restrictions, the resolution of these medical images can be enhanced with a well-designed super-resolution(SR) algorithm. As a post-processing manner after medical imaging, the adoption of the SR algorithms has the advantages of low cost and high efficiency compared with upgrading medical devices. In this paper, we propose a network named LDSRN that combines the Laplacian pyramid structure and the dense network to reconstruct clear and convincing medical HR images. Our LDSRN can make full use of the information from different pyramid levels to recover faithful HR images by the dense connection. Specifically, the Laplacian structure decomposes the difficult SR task into several easy SR tasks to obtain the HR images step by step for better reconstruction. Experimental results demonstrate that our LDSRN can obtain better HR medical images than several state-of-the-art SR methods in terms of objective indices and subjective evaluations.
C1 [Tang, Rui; Chen, Lihui; Zhang, Rongzhu; Yang, Xiaomin] Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610064, Sichuan, Peoples R China.
   [Ahmad, Awais] Univ Milan, Dipartimento Informat DI, Via Celoria 18, I-20133 Milan Mi, Italy.
   [Albertini, Marcelo Keese] Univ Fed Uberlandia, Fac Comp, Uberlandia, MG, Brazil.
C3 Sichuan University; University of Milan; Universidade Federal de
   Uberlandia
RP Yang, XM (corresponding author), Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610064, Sichuan, Peoples R China.
EM arielyang@scu.edu.cn
RI Chen, Lihui/ABP-5066-2022; Albertini, Marcelo K/J-7495-2012; yang,
   xiao/HJI-7815-2023
OI Chen, Lihui/0000-0002-0948-1600; 
FU National Natural Science Foundation of China [61711540303, 61701327]
FX This work is sponsored by the National Natural Science Foundation of
   China (grant no. 61711540303 and 61701327).
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Ali M, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATIONS AND COMPUTING (ICSPCC), P184, DOI 10.1109/ICSPCC.2014.6986179
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Bevilacqua M, 2012, INT CONF ACOUST SPEE, P1289, DOI 10.1109/ICASSP.2012.6288125
   Bishop Christopher M, 2003, AISTATS
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chen XX, 2014, IEEE SIGNAL PROC LET, V21, P79, DOI 10.1109/LSP.2013.2286417
   DEBOOR C, 1962, J MATH PHYS, V41, P212
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Hui Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2024, DOI 10.1145/3343031.3351084
   Hui Z, 2018, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2018.00082
   Humblot F, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/36971
   Katsuki T, 2012, IEEE T IMAGE PROCESS, V21, P3182, DOI 10.1109/TIP.2012.2189578
   Kingma D. P., 2014, arXiv
   Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Lehmann TM, 1999, IEEE T MED IMAGING, V18, P1049, DOI 10.1109/42.816070
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P36, DOI 10.1109/TIP.2008.2008067
   Rousseau F, 2010, MED IMAGE ANAL, V14, P594, DOI 10.1016/j.media.2010.04.005
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Wang YF, 2018, IEEE COMPUT SOC CONF, P977, DOI 10.1109/CVPRW.2018.00131
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Wei SF, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5084
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zhang KB, 2011, IEEE J-STSP, V5, P230, DOI 10.1109/JSTSP.2010.2048606
   Zhang W, 2018, IEEE CONF COMPUT
NR 41
TC 2
Z9 3
U1 5
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3131
EP 3144
DI 10.1007/s11042-020-09845-y
EA SEP 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000572865900002
DA 2024-07-18
ER

PT J
AU Li, N
   Wan, S
AF Li, Ning
   Wan, Shuai
TI Intra prediction based on geometry padding for omnidirectional video
   coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Omnidirectional video; Video coding; ERP; Intra prediction
ID EFFICIENCY
AB Omnidirectional videos or 360 degree videos play an important role in virtual reality (VR) applications. In order to employ the existing video coding standards, omnidirectional videos are firstly projected onto the 2-Dimension (2D) plane, which generates the discontinuity at boundaries and may result in unexpected artifacts when lossy coding is applied. In this paper, we propose a new intra prediction method to deal with the above coding artefacts in omnidirectional videos. Different from the conventional intra prediction using the left and top reference samples, the right reference samples are derived from the reconstructed samples on the left boundary and padded for intra prediction. The proposed method applies to the planar, DC and partial angular prediction modes in intra prediction. The experimental results demonstrate a Bjontegaard-Delta-rate reduction of up to 2.97% using weighted spherical peak-signal to noise ratio (WSPSNR) quality metric for the coding tree units (CTUs) at the right boundary.
C1 [Li, Ning; Wan, Shuai] Northwestern Polytech Univ, Sch Elect & Informat, Xian, Peoples R China.
C3 Northwestern Polytechnical University
RP Wan, S (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian, Peoples R China.
EM ning_li@mail.nwpu.edu.cn; swan@nwpu.edu.cn
RI 王, 宇佳/AGU-6378-2022
OI 王, 宇佳/0000-0001-8434-4801
CR Albrecht M., 2018, JVETJ0014
   Alshina E, 2016, JVETD1030
   Birkbeck N, 2019, IEEE T CIRCUITS SYST, P1
   Bordes P, 2018, JVETJ0018
   Chen H., 2018, JVETJ0025
   Chen Y.-W., 2018, JVETJ0021
   der Auwera GV, 2018, JVETJ0069
   Fu CW, 2009, IEEE T MULTIMEDIA, V11, P634, DOI 10.1109/TMM.2009.2017626
   Gisle B, 2001, VCEGM33 ITUT
   Hanhart P, 2016, JVETD0092
   Hsu C.-W., 2018, JVETJ0018
   Kamisli F, 2015, IEEE T IMAGE PROCESS, V24, P1247, DOI 10.1109/TIP.2015.2400818
   Kamisli F, 2013, IEEE T IMAGE PROCESS, V22, P3916, DOI 10.1109/TIP.2013.2264679
   Kang J, 2018, JVETJ0013
   Lee SH, 2017, ELECTRON LETT, V53, P655, DOI 10.1049/el.2017.0035
   Li JS, 2016, IEEE IMAGE PROC, P370, DOI 10.1109/ICIP.2016.7532381
   Li N, 2018, ASIAPAC SIGN INFO PR, P1987, DOI 10.23919/APSIPA.2018.8659696
   Li XX, 2018, NUCL SCI TECH, V29, DOI 10.1007/s41365-018-0458-1
   Lin JL, 2019, IEEE J EM SEL TOP C, V9, P84, DOI 10.1109/JETCAS.2019.2899660
   Lin P-H, 2018, JVETJ0070
   Matsuda I, 2013, IEEE IMAGE PROC, P1646, DOI 10.1109/ICIP.2013.6738339
   Misra K, 2018, JVETJ0026
   Ng KT, 2005, IEEE T CIRC SYST VID, V15, P82, DOI 10.1109/TCSVT.2004.839989
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Shiodera T., 2007, P IEEE INT C IM PROC, pVI
   Snyder J. P., 1997, FLATTENING EARTH 200
   Sullivan G.J., 2014, High Efficiency Video Coding (HEVC)"
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sun Y, 2017, PAIN RES MANAG, V2017, DOI 10.1155/2017/7346103
   Suzuki T, 2018, JVETJ0028
   Tan TK, 2016, IEEE T CIRC SYST VID, V26, P76, DOI 10.1109/TCSVT.2015.2477916
   Tang MH, 2017, IEEE INT CON MULTI, P799, DOI 10.1109/ICME.2017.8019460
   Toma T, 2018, JVETJ0020
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xu M, 2020, IEEE J-STSP, V14, P5, DOI 10.1109/JSTSP.2020.2966864
   Ye Y, 2017, JVETE0084
   Youvalari RG, 2016, PICT COD SYMP
   Youvalari RG, 2016, IEEE INT SYM MULTIM, P525, DOI [10.1109/ISM.2016.74, 10.1109/ISM.2016.0115]
   Yu Matt., 2015, P 3 INT WORKSHOP IMM, P1
   Zhang XY, 2012, PROCEEDINGS OF THE ASME 10TH FUEL CELL SCIENCE, ENGINEERING, AND TECHNOLOGY CONFERENCE, 2012, P1, DOI 10.1109/ACC.2007.4282196
   Zheng AM, 2016, IEEE T CIRC SYST VID, V26, P2152, DOI 10.1109/TCSVT.2015.2501738
   Zheng A, 2014, IEEE IMAGE PROC, P3724, DOI 10.1109/ICIP.2014.7025756
NR 42
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3409
EP 3424
DI 10.1007/s11042-020-09544-8
EA SEP 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000571689900003
DA 2024-07-18
ER

PT J
AU Agenis-Nevers, M
   Bokde, ND
   Yaseen, ZM
   Shende, MK
AF Agenis-Nevers, Marc
   Bokde, Neeraj Dhanraj
   Yaseen, Zaher Mundher
   Shende, Mayur Kishor
TI An empirical estimation for time and memory algorithm complexities:
   newly developed R package
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Time complexity; Memory complexity; Empirical approach; R package;
   Algorithm complexity
AB When an algorithm or a program runs on a computer, it requires some resources. The complexity of an algorithm is the measure of the resources, for some input. These complexities are usually space and time. The subject of the empirical computational complexity has been studied in the research. This article introduces GuessCompx which is an R package that performs an empirical estimation on the time and memory complexities of an algorithm or a function, and provides a reliable, convenient and simple procedure for estimation process. It tests multiple increasing-sizes samples of the user's data and attempts to fit one of seven complexity functions:O(N), O(N<SIC>2), O(log(N)), etc. In addition, based on the best fit procedure using leave one out-mean squared error (LOO-MSE), it predicts the full computation time and memory usage on the whole dataset. Together with this results, a plot and a significance test are returned. Complexity is assessed with regard to the user's actual dataset through its size (and no other parameter). This article provides several examples demonstrating several cases (e.g., distance function, time series and custom function) and optimal parameters tuning.
C1 [Agenis-Nevers, Marc] Epictr Factory, Clermont Ferrand, France.
   [Bokde, Neeraj Dhanraj] Aarhus Univ, Dept Engn Renewable Energy & Thermodynam, Aarhus, Denmark.
   [Yaseen, Zaher Mundher] Ton Duc Thang Univ, Sustainable Dev Civil Engn Res Grp, Fac Civil Engn, Ho Chi Minh City, Vietnam.
   [Shende, Mayur Kishor] Govt Coll Engn, Nagpur, Maharashtra, India.
C3 Aarhus University; Ton Duc Thang University
RP Yaseen, ZM (corresponding author), Ton Duc Thang Univ, Sustainable Dev Civil Engn Res Grp, Fac Civil Engn, Ho Chi Minh City, Vietnam.
EM yaseen@tdtu.edu.vn
RI Shende, Mayur/ABD-9981-2021; Bokde, Neeraj Dhanraj/I-2621-2016; Yaseen,
   Zaher Mundher/G-7029-2018
OI Shende, Mayur/0000-0002-1738-2573; Bokde, Neeraj
   Dhanraj/0000-0002-3493-9302; Yaseen, Zaher Mundher/0000-0003-3647-7137
CR Abualigah L. M. Q., 2019, FEATURE SELECTION EN, V816
   Abualigah L, 2020, NEURAL COMPUT APPL, V32, P12381, DOI 10.1007/s00521-020-04839-1
   Abualigah LM, 2018, J COMPUT SCI-NETH, V25, P456, DOI 10.1016/j.jocs.2017.07.018
   Abualigah LM, 2017, J SUPERCOMPUT, V73, P4773, DOI 10.1007/s11227-017-2046-2
   Agenis M, 2019, GUESSCOMPX
   Agenis M, 2019, GUESSCOMPXPERFORMANC
   ANDERSON JB, 1984, IEEE T COMMUN, V32, P169, DOI 10.1109/TCOM.1984.1096023
   Bournez O., 2018, ARXIV180505729
   Chivers I., 2015, An introduction to algorithms and the big O notation, P359, DOI [10.1007/978-3-319-17701-4, DOI 10.1007/978-3-319-17701-4, DOI 10.1007/978-3-319-17701-4_23]
   Contributors W, 2019, TIM COMPL WID FREE E
   Dong YQ, 2018, ENERGIES, V11, DOI 10.3390/en11041009
   Goldsmith Simon F., 2007, P 6 JOINT M EUR SOFT, P395, DOI 10.1145/1287624.1287681
   He J, 2001, ARTIF INTELL, V127, P57, DOI 10.1016/S0004-3702(01)00058-3
   Hong WC, 2019, APPL MATH MODEL, V72, P425, DOI 10.1016/j.apm.2019.03.031
   Hong WC, 2011, ENERGIES, V4, P960, DOI 10.3390/en4060960
   Jensen MT, 2003, IEEE T EVOLUT COMPUT, V7, P503, DOI 10.1109/TEVC.2003.817234
   Kundra H., 2015, RES J INF TECHNOL, V7, P58, DOI DOI 10.3923/RJIT.2015.58.69
   Min W., 2010, INF TECHN APPL IFITA, V1, P208
   Paliwal V, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12010084
   Pegny M, 2013, 39 ANN CONV SOC STUD, P1
   Pégny M, 2016, MIND MACH, V26, P359, DOI 10.1007/s11023-016-9407-0
   Qiu JF, 2016, EURASIP J ADV SIG PR, DOI 10.1186/s13634-016-0355-x
   Salih SQ, 2020, NEURAL COMPUT APPL, V32, P10359, DOI 10.1007/s00521-019-04575-1
   Shapiro JF, 1979, TECH REP
   Sharma DK, 2018, INT CONF CONTEMP, P6, DOI 10.1109/IC3.2018.8530473
   Valiant L. G., 1979, Theoretical Computer Science, V8, P189, DOI 10.1016/0304-3975(79)90044-6
   Wang Min, 2010, Proceedings 2010 International Forum on Information Technology and Applications (IFITA 2010), P208, DOI 10.1109/IFITA.2010.9
   Woeginger GJ, 2004, LECT NOTES COMPUT SC, V3162, P281
   Wong IC, 2004, 2004 IEEE WORKSHOP ON SIGNAL PROCESSING SYSTEMS DESIGN AND IMPLEMENTATION, PROCEEDINGS, P1
   You Yang, 2011, 2011 Second International Conference on Mechanic Automation and Control Engineering, P1314
   Zhang ZC, 2020, IEEE ACCESS, V8, P14642, DOI 10.1109/ACCESS.2020.2966712
   Zhang ZC, 2019, NONLINEAR DYNAM, V98, P1107, DOI 10.1007/s11071-019-05252-7
   **DATA OBJECT**
NR 33
TC 11
Z9 11
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2997
EP 3015
DI 10.1007/s11042-020-09471-8
EA SEP 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000570841100003
DA 2024-07-18
ER

PT J
AU Wen, J
   Zeng, H
   Wang, YZ
   Liu, SR
   Xue, YM
AF Wen, Juan
   Zeng, Hao
   Wang, Yuzhu
   Liu, Shurong
   Xue, Yiming
TI An SVD-based adaptive robust speech steganography using MDCT coefficient
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech steganography; Voice activity detector; Modified discrete cosine
   transform; Singular value decomposition; Robustness
ID SINGULAR-VALUE DECOMPOSITION; WATERMARKING SCHEME; BLIND
AB Speech is one of the essential ways of communication. The study of speech steganography provides great value in information security. To improve imperceptibility and robustness of speech steganography, the characteristics of speech signals should be fully taken into account. In this paper, a robust speech steganographic scheme based on Singular Value Decomposition (SVD) and Modified Discrete Cosine Transform (MDCT) is proposed. Firstly, Voice Activity Detector (VAD) is used to detect voiced frames from speech signals, along with MDCT with Kaiser Bessel Derived (KBD) window being performed on each frame. Then the MDCT coefficients are selected from a certain frequency range and divided into a pair of segments. The two largest singular values of the paired segments are modified respectively according to their value difference to embed secret message. The thresholds are adaptively adjusted according to the largest singular values. Extensive experiments are carried out to compare the proposed method with three other methods from imperceptibility, robustness, capacity, and security. The experimental results show that under the simulation parameters beta = 320,N-k= 58,f(l)= 100 Hz,f(h)= 3 kHz, and alpha= 0.61, the proposed method has striking advantages to resist common robust attacks and the state-of-the-art steganalysis attacks while maintaining good imperceptibility.
C1 [Wen, Juan; Zeng, Hao; Wang, Yuzhu; Liu, Shurong; Xue, Yiming] China Agr Univ, Coll Informat & Elect Engn, Beijing, Peoples R China.
C3 China Agricultural University
RP Xue, YM (corresponding author), China Agr Univ, Coll Informat & Elect Engn, Beijing, Peoples R China.
EM wenjuan@cau.edu.cn; cauzenghao@cau.edu.cn; sy20183081438@cau.edu.cn;
   2401488893@qq.com; xueym@cau.edu.cn
RI Liu, Shurong/AAE-7066-2019; Wen, Juan/ADU-0902-2022; Zeng,
   Hao/AAD-8060-2021
OI Liu, Shurong/0000-0002-5456-8828; Xue, Yiming/0000-0001-6500-3868
FU National Natural Science Foundation of China [61872368, 61802410]
FX We would like to sincerely thank the editors and reviewers for their
   valuable comments and suggestions. This work is supported by the
   National Natural Science Foundation of China (Grant No. 61872368 and
   No.61802410)
CR Ahangama S., 2015, Icis-Rp, P1
   Al-Nuaimy W, 2011, DIGIT SIGNAL PROCESS, V21, P764, DOI 10.1016/j.dsp.2011.01.013
   [Anonymous], 2009, IEEE INT C COMM 2009
   Banik BG, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/1781384
   Bhat KV, 2010, DIGIT SIGNAL PROCESS, V20, P1547, DOI 10.1016/j.dsp.2010.02.006
   BIGLIERI E, 1989, SIGNAL PROCESS, V18, P277, DOI 10.1016/0165-1684(89)90039-X
   Bo XA, 2008, GLOB TELECOMM CONF, DOI 10.1109/GLOCOM.2008.ECP.375
   Dhar PK, 2015, J INF SECUR APPL, V20, P74, DOI 10.1016/j.jisa.2014.10.007
   Dhas MDK, 2017, 2017 IEEE INT C ADV, P1
   Ghasemzadeh H, 2017, IET SIGNAL PROCESS, V11, P916, DOI 10.1049/iet-spr.2016.0690
   Hu HT, 2019, DIGIT SIGNAL PROCESS, V87, P75, DOI 10.1016/j.dsp.2019.01.006
   Hu HT, 2017, CLUSTER COMPUT, V20, P805, DOI 10.1007/s10586-017-0770-2
   Hua G, 2016, SIGNAL PROCESS, V128, P222, DOI 10.1016/j.sigpro.2016.04.005
   Huang YF, 2012, IEEE T INF FOREN SEC, V7, P1865, DOI 10.1109/TIFS.2012.2218599
   Hwang MJ, 2018, IEEE T MULTIMEDIA, V20, P45, DOI 10.1109/TMM.2017.2721642
   Ito A, 2009, INT CONF ACOUST SPEE, P1409, DOI 10.1109/ICASSP.2009.4959857
   Kanhe A, 2018, CIRC SYST SIGNAL PR, V37, P5049, DOI 10.1007/s00034-018-0805-9
   Kazemi R, 2016, IET INFORM SECUR, V10, P156, DOI 10.1049/iet-ifs.2014.0555
   Kumar A, 2019, ENVIRONMENTAL INFORMATION SYSTEMS: CONCEPTS, METHODOLOGIES, TOOLS, AND APPLICATIONS, P369, DOI 10.4018/978-1-5225-7033-2.ch017
   Lei BY, 2011, SIGNAL PROCESS, V91, P1973, DOI 10.1016/j.sigpro.2011.03.001
   Lei BY, 2013, J SYST SOFTWARE, V86, P1638, DOI 10.1016/j.jss.2013.02.022
   Lei BY, 2012, SIGNAL PROCESS, V92, P1985, DOI 10.1016/j.sigpro.2011.12.021
   Li JF, 2015, 2015 INTERNATIONAL CONFERENCE ON INFORMATIVE AND CYBERNETICS FOR COMPUTATIONAL SOCIAL SYSTEMS (ICCSS), P1, DOI 10.1109/ICCSS.2015.7281138
   Liu J, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P1133
   Liu P, 2017, MULTIMED TOOLS APPL, V76, P2837, DOI 10.1007/s11042-016-3257-x
   Liu QZ, 2009, IEEE T INF FOREN SEC, V4, P359, DOI 10.1109/TIFS.2009.2024718
   Nematollahi MA, 2017, P NATL A SCI INDIA A, V87, P433, DOI 10.1007/s40010-017-0371-8
   Nematollahi MA, 2015, J KING SAUD UNIV-COM, V27, P58, DOI 10.1016/j.jksuci.2014.03.012
   Piotrowski Z, 2012, ACTA PHYS POL A, V121, pA82
   TABARA B, 2017, 2017 SIGN PROC S, pNI305
   Tsai SE, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/6420314
   Wu ZJ, 2020, IEEE ACCESS, V8, P23308, DOI 10.1109/ACCESS.2020.2970194
   Xiang SJ, 2017, ADV MULTIMED, V2017, DOI 10.1155/2017/8492672
   Xiang Y, 2012, IEEE T INF FOREN SEC, V7, P383, DOI 10.1109/TIFS.2011.2173678
   Xin GJ, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/7096271
   Xue YM, 2019, IEEE ACCESS, V7, P153724, DOI 10.1109/ACCESS.2019.2948946
   Yan SF, 2015, MULTIMED TOOLS APPL, V74, P11763, DOI 10.1007/s11042-014-2265-y
NR 37
TC 4
Z9 4
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2517
EP 2536
DI 10.1007/s11042-020-09725-5
EA SEP 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000569701000004
DA 2024-07-18
ER

PT J
AU Jabeen, S
   Khan, UG
   Iqbal, R
   Mukherjee, M
   Lloret, J
AF Jabeen, Saira
   Khan, Usman Ghani
   Iqbal, Razi
   Mukherjee, Mithun
   Lloret, Jaime
TI A deep multimodal system for provenance filtering with universal forgery
   detection and localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Provenance filtering; Convolutional neural networks; Forgery detection
   and localization; Manipulation detection
ID COPY-MOVE FORGERY; IMAGE; FEATURES; NETWORK; MODEL
AB Traditional multimedia forensics techniques inspect images to identify, localize forged regions and estimate forgery methods that have been applied. Provenance filtering is the research area that has been evolved recently to retrieve all the images that are involved in constructing a morphed image in order to analyze an image, completely forensically. This task can be performed in two stages: one is to detect and localize forgery in the query image, and the second integral part is to search potentially similar images from a large pool of images. We propose a multimodal system which covers both steps, forgery detection through deep neural networks(CNN) followed by part based image retrieval. Classification and localization of manipulated region are performed using a deep neural network. InceptionV3 is employed to extract key features of the entire image as well as for the manipulated region. Potential donors and nearly duplicates are retrieved by using the Nearest Neighbour Algorithm. We take the CASIA-v2, CoMoFoD and NIST 2018 datasets to evaluate the proposed system. Experimental results show that deep features outperform low-level features previously used to perform provenance filtering with achieved Recall@50 of 92.8%.
C1 [Jabeen, Saira; Khan, Usman Ghani] Univ Engn & Technol, Dept Comp Sci & Engn, Lahore, Pakistan.
   [Iqbal, Razi] Univ Engn & Technol, Al Khawarizi Inst Comp Sci, Lahore, Pakistan.
   [Mukherjee, Mithun] Guangdong Univ Petrochem Technol, Guangdong Prov Key Lab Petrochem Equipment Fault, Maoming 525000, Peoples R China.
   [Lloret, Jaime] Univ Politecn Valencia, Valencia 46022, Spain.
   [Lloret, Jaime] Staffordshire Univ, Sch Comp & Digital Technol, Stoke, England.
C3 University of Engineering & Technology Lahore; University of Engineering
   & Technology Lahore; Guangdong University of Petrochemical Technology;
   Universitat Politecnica de Valencia; Staffordshire University
RP Jabeen, S (corresponding author), Univ Engn & Technol, Dept Comp Sci & Engn, Lahore, Pakistan.
EM saira.jabeen@kics.edu.pk; usman.ghani@kics.edu.pk; razi.iqbal@ieee.org;
   m.mukherjee@ieee.org; jlloret@dcom.upv.es
RI Lloret, Jaime/H-3994-2013
OI Lloret, Jaime/0000-0002-0862-0533
CR Agarwal R, 2020, MULTIMED TOOLS APPL, V79, P7355, DOI 10.1007/s11042-019-08495-z
   Ahmed B, 2020, SIGNAL IMAGE VIDEO P, V14, P1035, DOI 10.1007/s11760-020-01636-0
   AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], 2018, NIST MEDIA FORENSICS
   [Anonymous], 2016, NIST MEDIA FORENSICS
   [Anonymous], 2000, P KDD WORKSH TEXT MI, DOI DOI 10.1109/ICCCYB.2008.4721382
   Asghar K, 2017, AUST J FORENSIC SCI, V49, P281, DOI 10.1080/00450618.2016.1153711
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bayar Y, 2016, TRANSYLV REV ADM SCI, P5
   Bhatti MH, 2019, IEEE T IND INFORM, V15, P5747, DOI 10.1109/TII.2019.2925624
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Bunk J, 2017, IEEE COMPUT SOC CONF, P1881, DOI 10.1109/CVPRW.2017.235
   Cao G, 2010, IEEE INT CON MULTI, P89, DOI 10.1109/ICME.2010.5583869
   Cao YJ, 2012, FORENSIC SCI INT, V214, P33, DOI 10.1016/j.forsciint.2011.07.015
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Chum O., 2008, BMVC, P812, DOI DOI 10.5244/C.22.50
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Dias Z, 2013, FORENSIC SCI INT, V231, P178, DOI 10.1016/j.forsciint.2013.05.002
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Garcia M, 2008, 3 INT C MOB UB COMP
   Helgason S., 1999, The Radon Transform, V2
   Jaiswal AK, 2019, IMAGE SPLICING DETEC
   Kang XG, 2013, IEEE T INF FOREN SEC, V8, P1456, DOI 10.1109/TIFS.2013.2273394
   Khan MZ, 2019, IEEE ACCESS, V7, P72622, DOI 10.1109/ACCESS.2019.2918275
   Li M, 2010, Google Patents. US Patent, Patent No. [7,647,331, 7647331]
   Lin S. D., 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P1086, DOI 10.1109/CISP.2011.6100366
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Lloret J, 2011, SENSORS-BASEL, V11, P6165, DOI 10.3390/s110606165
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahmood T, 2018, J VIS COMMUN IMAGE R, V53, P202, DOI 10.1016/j.jvcir.2018.03.015
   Moreira D, 2018, IEEE T IMAGE PROCESS, V27, P6109, DOI 10.1109/TIP.2018.2865674
   Muhammad G, 2014, MACH VISION APPL, V25, P985, DOI 10.1007/s00138-013-0547-4
   Murabayashi A, 2018, PROBLEM FAKE PHOTOS
   Pinto A, 2017, IEEE IMAGE PROC, P1502, DOI 10.1109/ICIP.2017.8296532
   Qu ZH, 2009, LECT NOTES COMPUT SC, V5806, P247
   Rao Y, 2016, IEEE INT WORKS INFOR
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shen HC, 2012, FEBS OPEN BIO, V2, P1, DOI 10.1016/j.fob.2011.12.001
   Shivakumar B., 2011, Int J Comput Sci Issues (IJCSI), V8, P199
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Wang PF, 2016, MULTIMED TOOLS APPL, V75, P2897, DOI 10.1007/s11042-015-2521-9
   Wojna Z, 2017, P BRIT MACH VIS C BM, P1, DOI [DOI 10.5244/C.31.10, 10.5244/C.31.10]
   Wu Y, 2018, LECT NOTES COMPUT SC, V11210, P170, DOI 10.1007/978-3-030-01231-1_11
   Wu Y, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1480, DOI 10.1145/3123266.3123411
   Xu Bo, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P889, DOI 10.1109/MINES.2010.189
   Xu XK, 2013, IEEE IMAGE PROC, P4422, DOI 10.1109/ICIP.2013.6738911
   Yosinski J, 2014, ADV NEUR IN, V27
   Yuan HD, 2011, IEEE T INF FOREN SEC, V6, P1335, DOI 10.1109/TIFS.2011.2161761
NR 53
TC 6
Z9 6
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 17025
EP 17044
DI 10.1007/s11042-020-09623-w
EA SEP 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000569366600001
OA Green Published
DA 2024-07-18
ER

PT J
AU Benssalah, M
   Rhaskali, Y
   Drouiche, K
AF Benssalah, Mustapha
   Rhaskali, Yesser
   Drouiche, Karim
TI An efficient image encryption scheme for TMIS based on elliptic curve
   integrated encryption and linear cryptography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Elliptic curves; DICOM; ECIES; Chaos; Hill cipher
ID CHAOTIC SYSTEM; PERMUTATION
AB Nowadays, diagnosing patient diseases remotely is a routine and digital medical images analysis as a part of Telecare Medical Information Systems (TMIS) play a fundamental role in early diagnosing and treating most common and serious diseases such as breast cancer. In this context, altering or distorting even a single pixel of a medical image during its transmission over an unsure channel could lead to a wrong diagnosis and harm patient health, induce damaging delays. Therefore the security and privacy of the transmitted medical images must be addressed most seriously. Several techniques are proposed in the literature to address these issues using different techniques such as chaos theory, more recently, elliptic curves cryptography (ECC) or improved classical methods such as linear cryptography. In this paper, we address the security level concern of an image encryption technique combining ECC with Hill cipher (ECCHC) which has been recently proposed by Dawahdeh et al [13]. Our study rises concerns about some weaknesses and flaws of the analyzed encryption scheme against some plain-text and known plain-text attacks. In addition, and not least issue, it is found that the key length used in Dawahdeh et al. scheme is not sufficiently large to be robust against brute force attack. To fix the found flaws and to improve the encryption scheme, a generalized cryptosystem is suggested. In the enhanced version, the key matrix negotiation is redefined to a cipher that combines a modified EC Integrated Encryption Scheme (ECIES) and the linear multiplication matrix is generalized to key matrix of (2nx 2n),n> 2 to counter efficiently the exhaustive search attack. The effectiveness of the proposed version is evaluated and verified through extensive experimentation and most recent available security tools. Compared with the state-of-the art techniques, the proposed version exhibits excellent security features and can resist to various knowing attacks.
C1 [Benssalah, Mustapha; Rhaskali, Yesser] Ecole Mil Polytech, Signal Proc Lab, BP 17 Bordj El Bahri, Algiers 16111, Algeria.
   [Drouiche, Karim] Cergy Pontoise Univ, LIK Neuville Sur Oise, Cergy Pontoise, France.
C3 Ecole Military Polytechnic; CY Cergy Paris Universite
RP Benssalah, M (corresponding author), Ecole Mil Polytech, Signal Proc Lab, BP 17 Bordj El Bahri, Algiers 16111, Algeria.
EM bensmusta@gmail.com
CR Abdulla AA, 2014, LECT NOTES COMPUT SC, V8893, P151, DOI 10.1007/978-3-319-14054-4_10
   Acharya B., 2007, INT J SECURITY, V1, P14
   Ali TS, 2020, MULTIMED TOOLS APPL, P1
   Allaf AH, 2018, P 3 INT C SMART CIT, P472
   Alshanbari HS, 2021, MULTIMED TOOLS APPL, V80, P16549, DOI 10.1007/s11042-020-08814-9
   [Anonymous], 2003, Elliptic Curves: Number Theory and Cryptology
   Belazi A, 2019, IEEE ACCESS, V7, P36667, DOI 10.1109/ACCESS.2019.2906292
   Cao WJ, 2017, SIGNAL PROCESS, V132, P96, DOI 10.1016/j.sigpro.2016.10.003
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P15561, DOI 10.1007/s11042-016-3858-4
   Chen JX, 2018, SIGNAL PROCESS, V142, P340, DOI 10.1016/j.sigpro.2017.07.034
   Chen YM, 2014, NONLINEAR DYNAM, V77, P569, DOI 10.1007/s11071-014-1318-0
   Dawahdeh ZE, 2018, J KING SAUD UNIV-COM, V30, P349, DOI 10.1016/j.jksuci.2017.06.004
   Ding JN, 2019, IEEE T CIRCUITS-I, V66, P1003, DOI 10.1109/TCSI.2018.2878598
   Dzwonkowski M, 2015, IEEE T IMAGE PROCESS, V24, P4614, DOI 10.1109/TIP.2015.2467317
   El Assad S, 2016, SIGNAL PROCESS-IMAGE, V41, P144, DOI 10.1016/j.image.2015.10.004
   Farwa S, 2020, MULTIMED TOOLS APPL, P1
   Hayat U, 2019, SIGNAL PROCESS, V155, P391, DOI 10.1016/j.sigpro.2018.10.011
   Hill L.S., 1929, The American Mathematical Monthly, V36, P306
   Hua ZY, 2018, SIGNAL PROCESS, V144, P134, DOI 10.1016/j.sigpro.2017.10.004
   Hua ZY, 2017, INFORM SCIENCES, V396, P97, DOI 10.1016/j.ins.2017.02.036
   Huang H, 2020, MULTIMED TOOLS APPL, P1
   Kahn D., 1996, The Codebreakers: The comprehensive history of secret communication from ancient times to the internet
   Kamrani A, 2020, MULTIMED TOOLS APPL, P1
   Kannammal A, 2012, COMM COM INF SC, V330, P349
   Karmakar J, 2020, MULTIMED TOOLS APPL, P1
   Koblitz N, 2000, DESIGN CODE CRYPTOGR, V19, P173, DOI 10.1023/A:1008354106356
   Kumar M, 2016, SIGNAL PROCESS, V125, P187, DOI 10.1016/j.sigpro.2016.01.017
   Laiphrakpam DS, 2018, MULTIMED TOOLS APPL, V77, P8629, DOI 10.1007/s11042-017-4755-1
   Laiphrakpam DS, 2017, OPTIK, V147, P88, DOI 10.1016/j.ijleo.2017.08.028
   Li L, 2012, SIGNAL PROCESS, V92, P1069, DOI 10.1016/j.sigpro.2011.10.020
   Ma S, 2019, IEEE ACCESS, V7, P30344, DOI 10.1109/ACCESS.2019.2901302
   MILLER VS, 1986, LECT NOTES COMPUT SC, V218, P417, DOI 10.1007/3-540-39799-x_31
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P18985, DOI 10.1007/s11042-017-4420-8
   Ostad-Sharif A, 2019, INT J COMMUN SYST, V32, DOI 10.1002/dac.3913
   Parvees MYM, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0809-1
   Rahman MNA, 2013, INT J SECUR APPL, V7, P179
   Ravichandran D, 2016, COMPUT BIOL MED, V72, P170, DOI 10.1016/j.compbiomed.2016.03.020
   Saeednia S, 2000, CRYPTOLOGIA, V24, P353, DOI 10.1080/01611190008984253
   Soualmi A, 2018, ARAB J SCI ENG, P1
   Soualmi A, 2018, ARAB J SCI ENG, V43, P7893, DOI 10.1007/s13369-018-3246-7
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Vincent J, 2018, 1 5 MILLION AFFECTED
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu JH, 2018, SIGNAL PROCESS, V142, P292, DOI 10.1016/j.sigpro.2017.06.014
   Wu XL, 2017, IEEE ACCESS, V5, P6429, DOI 10.1109/ACCESS.2017.2692043
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Zefreh EZ, 2020, MULTIMED TOOLS APPL, P1
   Zhang LB, 2015, MATH PROBLEMS ENG
   Zhang XQ, 2019, MULTIMED TOOLS APPL, V78, P7841, DOI 10.1007/s11042-018-6496-1
   Zhang YS, 2014, COMMUN NONLINEAR SCI, V19, P74, DOI 10.1016/j.cnsns.2013.06.031
   Zhou YC, 2015, IEEE T CYBERNETICS, V45, P2001, DOI 10.1109/TCYB.2014.2363168
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 53
TC 30
Z9 31
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2081
EP 2107
DI 10.1007/s11042-020-09775-9
EA SEP 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000568478700007
DA 2024-07-18
ER

PT J
AU Sun, YM
   Zhang, Y
   Liu, SD
   Lu, WJ
   Li, XG
AF Sun, Yemei
   Zhang, Yan
   Liu, Shudong
   Lu, Weijia
   Li, Xianguo
TI Image super-resolution using supervised multi-scale feature extraction
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; Multi-scale feature extraction; Supervised; Vanishing
   gradients
AB Image super-resolution using deep convolutional networks have recently achieved great successes. However, previous studies have failed to consider the spatial information by simply using a single-size filter, and they do not take full advantage of hierarchical features from low-resolution images, thereby these results are unsatisfactory. In this paper, the supervised convolutional network with multi-scale feature extraction is presented to further improve accuracy. First, the spatial information of the image can be better utilized by different filter sizes. This enhances the adaptability of the network. Second, dense connections are introduced to alleviate the vanishing-gradient problem and accelerate the convergence speed. Third, by adding auxiliary supervised connections to these intermediate layers, they provide additional regularization and increase the backpropagation gradient signal. Extensive experiments on the open challenge datasets confirm the effectiveness of proposed network. Our algorithm can restore high-quality high-resolution images quickly and outperform other methods by a large margin.
C1 [Sun, Yemei; Zhang, Yan; Liu, Shudong; Lu, Weijia] Tianjin Chengjian Univ, Sch Comp & Informat Engn, Tianjin, Peoples R China.
   [Li, Xianguo] Tianjin Key Lab Optoelect Detect Technol & Syst, Tianjin, Peoples R China.
C3 Tianjin Chengjian University
RP Zhang, Y (corresponding author), Tianjin Chengjian Univ, Sch Comp & Informat Engn, Tianjin, Peoples R China.
EM yanzhang0910@163.com
FU Scientific Research Project of Tianjin Municipal Education Commission
   [2019KJ105]; Tianjin Key Laboratory of Optoelectronic Detection
   Technology and System Open Project [2019LODTS006]
FX This work was supported by the Scientific Research Project of Tianjin
   Municipal Education Commission [grant number 2019KJ105] and Tianjin Key
   Laboratory of Optoelectronic Detection Technology and System Open
   Project[2019LODTS006].The authors also acknowledge the anonymous
   reviewers for their helpful comments on the manuscript.
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Al-Gheethi AAS, 2019, WATER SCI TECHNOL LI, V87, P1, DOI 10.1007/978-3-319-90269-2_1
   [Anonymous], 2018, IEEE T IMAGE PROCESS
   Bevilacqua M, 2013, INT CONF DIGIT SIG
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Freedman G, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1944846.1944852
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hu SY, 2020, MULTIMED TOOLS APPL, V79, P1427, DOI 10.1007/s11042-019-08241-5
   HUANG JB, 2015, PROC CVPR IEEE, P5197, DOI DOI 10.1109/CVPR.2015.7299156
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Lai W-S, 2017, PROC CVPR IEEE, P624, DOI DOI 10.1109/CVPR.2017.618
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Peleg T, 2014, IEEE T IMAGE PROCESS, V23, P2569, DOI 10.1109/TIP.2014.2305844
   Sajjadi MSM, 2017, IEEE I CONF COMP VIS, P4501, DOI 10.1109/ICCV.2017.481
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Yang CY, 2013, IEEE I CONF COMP VIS, P561, DOI 10.1109/ICCV.2013.75
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang KB, 2012, IEEE T IMAGE PROCESS, V21, P4544, DOI 10.1109/TIP.2012.2208977
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
NR 39
TC 4
Z9 4
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 1995
EP 2008
DI 10.1007/s11042-020-09488-z
EA SEP 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000568184100011
DA 2024-07-18
ER

PT J
AU Mohanty, SK
   Rup, S
AF Mohanty, Subrata Kumar
   Rup, Suvendu
TI An adaptive background modeling for foreground detection using
   spatio-temporal features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Background modeling; Foreground detection; Local binary pattern;
   Spatio-temporal local binary pattern; Background subtraction (BGS)
ID MOVING OBJECT DETECTION; DETECTION ALGORITHM; ROBUST-PCA; SUBTRACTION;
   TRACKING; SURVEILLANCE; CLASSIFICATION; PEOPLE
AB Background modeling is a well accepted foreground detection technique for many visual surveillance applications like remote sensing, medical imaging, traffic monitoring, crime detection, machine/robot vision etc. Regardless of simplicity of foreground detection concept, no conventional algorithms till date seem to be able to concurrently address the key challenges like illumination variation, dynamic background, low contrast and noisy sequences. To mitigate this issue, this paper proposes an improved scheme for foreground detection particularly addresses all the aforementioned key challenges. The suggested scheme operates as follows: First, a spatio-temporal local binary pattern (STLBP) technique is employed to extract both spatial texture feature and temporal motion feature from a video frame. The present scheme modifies the change detection rule of traditional STLBP method to make the features robust under challenging situations. The improvisation in change description rule reflects that to extract STLBP features, the mean of the surrounding pixels is chosen instead of a fixed center pixel across a local region. Further, in many foreground detection algorithms a constant learning rate and constant threshold value is considered during background modeling which in turn fails to detect a proper foreground under multimodal background conditions. So to address this problem, an adaptive formulation in background modeling is proposed to compute the learning rate (alpha(b)) and threshold value (T-p) to detect the foreground accurately without any false labeling of pixels under challenging environments. The performance of the proposed scheme is evaluated through extensive simulations using different challenging video sequences and compared with that of the benchmark schemes. The experimental results demonstrate that the proposed scheme outperforms significant improvements in terms of both qualitative as well as quantitative measures than that of the benchmark schemes.
C1 [Mohanty, Subrata Kumar; Rup, Suvendu] Int Inst Informat Technol, Dept Comp Sci & Engn, Image & Video Proc Lab, Bhubaneswar 751003, Orissa, India.
C3 International Institute of Information Technology, Bhubaneswar
RP Mohanty, SK (corresponding author), Int Inst Informat Technol, Dept Comp Sci & Engn, Image & Video Proc Lab, Bhubaneswar 751003, Orissa, India.
EM subrata@iiit-bh.ac.in; suvendu@iiit-bh.ac.in
RI Rup, Suvendu/AAQ-6535-2021
OI Mohanty, Subrata Kumar/0000-0002-7494-427X
CR [Anonymous], 2016, BME SCI STUD C
   [Anonymous], 2014, HDB BACKGROUND MODEL
   Ashraphijuo M, 2018, IEEE SIGNAL PROC LET, V25, P343, DOI 10.1109/LSP.2017.2780983
   Azizpour H, 2012, LECT NOTES COMPUT SC, V7572, P836, DOI 10.1007/978-3-642-33718-5_60
   Biao Y, 2015, OPTIK, V126, P4586, DOI 10.1016/j.ijleo.2015.08.064
   Bilodeau GA, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P106, DOI 10.1109/CRV.2013.29
   Bouwmans Thierry, 2011, Recent Patents on Computer Science, V4, P147, DOI 10.2174/1874479611104030147
   Bouwmans T., 2008, Recent Patents Comput. Sci., V1, P219
   Bouwmans T, 2017, COMPUT SCI REV, V23, P1, DOI 10.1016/j.cosrev.2016.11.001
   Bouwmans T, 2014, COMPUT SCI REV, V11-12, P31, DOI 10.1016/j.cosrev.2014.04.001
   Bouwmans T, 2014, COMPUT VIS IMAGE UND, V122, P22, DOI 10.1016/j.cviu.2013.11.009
   Bouwmans Thierry, 2019, ARXIV190103577
   Chakrabort S, 2017, NEUROCOMPUTING, V226, P35, DOI 10.1016/j.neucom.2016.11.016
   Chen BH, 2014, IEEE T MULTIMEDIA, V16, P837, DOI 10.1109/TMM.2014.2298377
   Chiranjeevi P, 2012, J VIS COMMUN IMAGE R, V23, P948, DOI 10.1016/j.jvcir.2012.06.004
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Davis JW, 2007, COMPUT VIS IMAGE UND, V106, P162, DOI 10.1016/j.cviu.2006.06.010
   Elgammal A, 2000, EUR C COMP VIS, P751, DOI DOI 10.1007/3-540-45053-X_48
   Feng Jiashi, 2013, Advances in Neural Information Processing Systems, P404
   Goehner K, 2015, P IEEE INT C E-SCI, P187, DOI 10.1109/eScience.2015.10
   Goyal K, 2018, COMPUT ELECTR ENG, V70, P275, DOI 10.1016/j.compeleceng.2016.05.017
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   Hadi RA, 2017, ARAB J SCI ENG, V42, P817, DOI 10.1007/s13369-016-2351-8
   Hadiuzzaman M, 2017, SIGNAL IMAGE VIDEO P, V11, P1245, DOI 10.1007/s11760-017-1081-z
   Han G, 2017, INT J MACH LEARN CYB, V8, P1839, DOI 10.1007/s13042-016-0562-7
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Hofmann Martin., 2012, 2012 IEEE COMPUTER S, P38, DOI DOI 10.1109/CVPRW.2012.6238925
   Hong WZ, 2015, P NATL ACAD SCI USA, V112, pE5351, DOI 10.1073/pnas.1515982112
   Hou YL, 2011, IEEE T SYST MAN CY A, V41, P24, DOI 10.1109/TSMCA.2010.2064299
   Huang SC, 2013, IEEE T NEUR NET LEAR, V24, P1920, DOI 10.1109/TNNLS.2013.2270314
   Huang SC, 2011, IEEE T CIRC SYST VID, V21, P1, DOI 10.1109/TCSVT.2010.2087812
   Javed S., 2014, P 2014 C RES AD CONV, P105, DOI DOI 10.1145/2663761.2664195
   John E, 2019, TLS-TIMES LIT SUPPL, P38
   Karnowski J, 2015, 2015 IEEE WINTER APPLICATIONS AND COMPUTER VISION WORKSHOPS (WACVW), P51, DOI 10.1109/WACVW.2015.10
   Kim K, 2004, IEEE IMAGE PROC, P3061
   Lee B., 2002, IMAGE VISION COMPUT, P315
   Li Q, 2016, J NANOMATER, V2016, DOI 10.1155/2016/3942671
   Liu YT, 2019, PROC CVPR IEEE, P6462, DOI 10.1109/CVPR.2019.00663
   MCFARLANE NJB, 1995, MACH VISION APPL, V8, P187, DOI 10.1007/BF01215814
   Mei LQ, 2017, 2017 NINTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P1, DOI 10.1109/ICACI.2017.7974476
   Moudgollya R, 2019, MULTIMED TOOLS APPL, V78, P22537, DOI 10.1007/s11042-019-7575-7
   Muniruzzaman S., 2016, J BUILT ENV TECHNOL, V1, P111
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Panda DK, 2018, J VIS COMMUN IMAGE R, V56, P52, DOI 10.1016/j.jvcir.2018.07.014
   Panda DK, 2018, IET IMAGE PROCESS, V12, P1832, DOI 10.1049/iet-ipr.2017.0595
   Pang SN, 2016, INT J APPL PATTERN R, V3, P324, DOI 10.1504/IJAPR.2016.082245
   Perrett T, 2017, IEEE T INTELL TRANSP, V18, P321, DOI 10.1109/TITS.2016.2567540
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   Quesada J, 2016, IEEE IMAGE PROC, P3822, DOI 10.1109/ICIP.2016.7533075
   Roy A., 2010, ESA, P157
   Shen WJ, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10050742
   Sobral A, 2015, 2015 12TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Vaswani N, 2018, IEEE SIGNAL PROC MAG, V35, P32, DOI 10.1109/MSP.2018.2826566
   Wang HZ, 2005, INT CONF ACOUST SPEE, P1017
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Wu MJ, 2010, AEU-INT J ELECTRON C, V64, P739, DOI 10.1016/j.aeue.2009.05.004
   Yaghoobi EN., 2018, PLOS ONE, V13, P1
   Yang D, 2018, IEEE T IMAGE PROCESS, V27, P1112, DOI 10.1109/TIP.2017.2768828
   Yousif H, 2017, IEEE INT SYMP CIRC S
   Zhang SP, 2008, IEEE IMAGE PROC, P1556, DOI 10.1109/ICIP.2008.4712065
   Zhong BN, 2009, IEEE IMAGE PROC, P3193
   Zhong ZF, 2017, IEEE T INTELL TRANSP, V18, P1109, DOI 10.1109/TITS.2016.2597441
NR 66
TC 3
Z9 3
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 1311
EP 1341
DI 10.1007/s11042-020-09552-8
EA SEP 2020
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566871700006
DA 2024-07-18
ER

PT J
AU Choi, YS
   Kang, JG
   Joo, JWJ
   Jung, JW
AF Choi, Yong-Sik
   Kang, Jin-Gu
   Joo, Jong Wha J.
   Jung, Jin-Woo
TI Real-time Informatized caption enhancement based on speaker
   pronunciation time database
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Informatized caption; Speaker pronunciation time; IBM Watson API; Speech
   to text translation
ID CENTRAL-LIMIT-THEOREM; NETWORKS
AB IBM Watson is one of the representative tools for speech recognition system which can automatically generate not only speech-to-text information but also speaker ID and timing information, which is called as Informatized Caption. However, if there is some noise in the voice signal to the IBM Watson API, the recognition performance is significantly decreased. It can be easily found in movies with background music and special sound effects. This paper aims to improve the inaccuracy problem of current Informatized Captions in noisy environments. In this paper, a method of modifying incorrectly recognized words and a method of enhancing timing accuracy while updating database in real time are suggested based on the original caption and Informatized Caption information. Experimental results shows that the proposed method can give 81.09% timing accuracy for the case of 10 representative animation, horror and action movies.
C1 [Choi, Yong-Sik] Dongguk Univ, Dept Artificial Intelligence, 30 Pildong Ro 1 Gil, Seoul 04620, South Korea.
   [Kang, Jin-Gu; Joo, Jong Wha J.; Jung, Jin-Woo] Dongguk Univ, Dept Comp Sci & Engn, 30 Pildong Ro 1 Gil, Seoul 04620, South Korea.
C3 Dongguk University; Dongguk University
RP Jung, JW (corresponding author), Dongguk Univ, Dept Comp Sci & Engn, 30 Pildong Ro 1 Gil, Seoul 04620, South Korea.
EM jwjung@dongguk.edu
RI Kang, Jin-Gu/AAA-7289-2020
OI Kang, Jin-Gu/0000-0003-4262-7840
FU MSIT(Ministry of Science and ICT), Korea, under the ITRC(Information
   Technology Research Center) support program [IITP-2020-2020-0-01789];
   National Research Foundation of Korea(NRF) - Korea government(MSIT)
   [2020R1F1A1074974]; KIAT(Korea Institute for Advancement of Technology)
   - Korea Government (MOTIE Ministry of Trade Industry and Energy)
   [N0001884]; AURI(Korea Association of University, Research institute and
   Industry) - Korea Government(MSS : Ministry of SMEs and Startups)
   [S2938281]; MSIT(Ministry of Science and ICT), Korea [2016-000017]
FX This research was partially supported by the MSIT(Ministry of Science
   and ICT), Korea, under the ITRC(Information Technology Research Center)
   support program(IITP-2020-2020-0-01789) supervised by the IITP(Institute
   of Information & Communications Technology Planning & Evaluation), the
   National Research Foundation of Korea(NRF) grant funded by the Korea
   government(MSIT) (No. 2020R1F1A1074974), the KIAT(Korea Institute for
   Advancement of Technology) grant funded by the Korea Government (MOTIE
   Ministry of Trade Industry and Energy). (No. N0001884, HRD program for
   Embedded Software R&D), the AURI(Korea Association of University,
   Research institute and Industry) grant funded by the Korea
   Government(MSS : Ministry of SMEs and Startups). (No.S2938281, HRD
   program for Enterprise linkages R&D), the MSIT(Ministry of Science and
   ICT), Korea, under the National Program for Excellence in SW supervised
   by the IITP(Institute of Information & Communications Technology
   Planning & Evaluation)(2016-000017).
CR [Anonymous], 2018, ARXIV180409671
   [Anonymous], ENGL LIST TEST AUD
   Ban F, 2018, INT J SOCIAL HUMANIS, V3, P34, DOI [DOI 10.1504/IJSHC.2018.095011, 10.1504/IJSHC.2018.095011]
   Choi YW, 2017, ATMOS-KOREA, V27, P105, DOI 10.14191/Atmos.2017.27.1.105
   Choi YS, 2018, INT J NATURAL LANGUA, V7, P1, DOI [10.5121/ijnlc.2018.7101, DOI 10.5121/IJNLC.2018.7101]
   Choi YS, 2018, COMPUTER SCI INFORM, P105
   Chowdhury GG, 2003, ANNU REV INFORM SCI, V37, P51, DOI 10.1002/aris.1440370103
   Drigas Athanasios S., 2009, International Journal of Social and Humanistic Computing, V1, P175, DOI 10.1504/IJSHC.2009.031006
   Ferrucci DA, 2012, IBM J RES DEV, V56, DOI 10.1147/JRD.2012.2184356
   KIPNIS C, 1986, COMMUN MATH PHYS, V104, P1, DOI 10.1007/BF01210789
   Kiumarsi B, 2018, IEEE T NEUR NET LEAR, V29, P2042, DOI 10.1109/TNNLS.2017.2773458
   Mata J, 2018, OPT SWITCH NETW, V28, P43, DOI 10.1016/j.osn.2017.12.006
   ROSENBLATT M, 1956, P NATL ACAD SCI USA, V42, P43, DOI 10.1073/pnas.42.1.43
   Russell S., 2016, Artificial intelligence a modern approach
   Shahamiri SR, 2014, NEUROCOMPUTING, V129, P199, DOI 10.1016/j.neucom.2013.09.040
   Shickel B, 2018, IEEE J BIOMED HEALTH, V22, P1589, DOI 10.1109/JBHI.2017.2767063
   Stallings W, 2006, DATA COMPUTER COMMUN, P92
   Tan WK, 2018, ACAD RADIOL, V25, P1422, DOI 10.1016/j.acra.2018.03.008
NR 18
TC 0
Z9 1
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35667
EP 35688
DI 10.1007/s11042-020-09590-2
EA SEP 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000566318900002
OA hybrid
DA 2024-07-18
ER

PT J
AU Malakar, S
   Ghosh, M
   Chaterjee, A
   Bhowmik, S
   Sarkar, R
AF Malakar, Samir
   Ghosh, Manosij
   Chaterjee, Agneet
   Bhowmik, Showmik
   Sarkar, Ram
TI Offline music symbol recognition using Daisy feature and quantum Grey
   wolf optimization based feature selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music symbol recognition; Daisy descriptor; Quantum Grey wolf
   optimization; Feature selection
AB Handwritten music symbol recognition is considered by the research fraternity as a critical research problem. It becomes more critical when the symbols are collected from handwritten music sheets in offline mode. Most of the research findings, available in the literature, have tried to recognize the said symbols using various shape based features. But this approach limits system performance when we dealt with lookalike symbols such as half note, eight note and quarter note. To encounter this, in the present work we have used a texture based feature descriptor, called Daisy, for the said purpose. Though Daisy descriptor yields reasonably good recognition accuracy, but it generates a high dimensional feature vector. Hence, in this work, Quantum concept inspired Grey Wolf Optimization, named as QGWO, has been applied to select optimal feature subset from this high dimensional feature vector. We have applied the proposed method on six different standard music symbol datasets that include HOMUS, Capitan_score_uniform, Capitan_score_non-uniform, Fornes, Rebelo_real and Rebelo_synthetic datasets. On these datasets we have achieved recognition accuracies 93.07%, 99.22%, 99.20%, 99.49% and 100.00% respectively with 39.63%, 49.75%, 42.50%, 67.62%, 54.37% and 71.25% of actual feature dimension (i.e., 800) respectively. Additionally, we have compared our results with some state-of-the-art methods along with two recent deep learning based models, and it has been found that the present approach outperforms those.
C1 [Malakar, Samir] Asutosh Coll, Dept Comp Sci, Kolkata 700026, India.
   [Ghosh, Manosij; Chaterjee, Agneet; Sarkar, Ram] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, India.
   [Bhowmik, Showmik] Ghani Khan Choudhury Inst Engn & Technol, Dept Comp Sci & Engn, Malda 732141, India.
C3 Jadavpur University
RP Bhowmik, S (corresponding author), Ghani Khan Choudhury Inst Engn & Technol, Dept Comp Sci & Engn, Malda 732141, India.
EM malakarsamir@gmail.com; manosij1996@gmail.com; agneet257@gmail.com;
   showmik.cse@gmail.com; ramjucse@gmail.com
RI Sarkar, Ram/AAX-3822-2020; Malakar, Samir/A-8021-2017; Bhowmik,
   Showmik/M-4248-2017
OI Sarkar, Ram/0000-0001-8813-4086; Malakar, Samir/0000-0003-4217-2372;
   Bhowmik, Showmik/0000-0003-3971-5807
CR [Anonymous], 2016, P 17 INT SOC MUSIC I
   [Anonymous], 1989, Simulated annealing and Boltzmann machines: A stochastic approach to combinatorial optimization and neural computing
   Bera SK, 2020, J INTELL SYST, V29, P688, DOI 10.1515/jisys-2018-0105
   Bhowmik S, 2019, IEEE T IMAGE PROCESS, V28, P1443, DOI 10.1109/TIP.2018.2878959
   Brandellero A, 2014, INT J HERIT STUD, V20, P224, DOI 10.1080/13527258.2013.779294
   Calvo-Zaragoza J, 2017, EXPERT SYST APPL, V72, P395, DOI 10.1016/j.eswa.2016.10.041
   Calvo-Zaragoza J, 2014, INT C PATT RECOG, P3038, DOI 10.1109/ICPR.2014.524
   Chanda S, 2014, INT CONF FRONT HAND, P405, DOI 10.1109/ICFHR.2014.74
   Chattopadhyay A., 2018, INFORM SCI SYSTEMS C, P1, DOI DOI 10.1109/CISS.2018.8362307
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dorigo M., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), P1470, DOI 10.1109/CEC.1999.782657
   Emary E, 2015, ADV INTELL SYST, V334, P1, DOI 10.1007/978-3-319-13572-4_1
   Fornes A., 2007, Graphics Recognition, V5046, P51
   George SE, 2003, COMPUT MUSIC J, V27, P70, DOI 10.1162/014892603322022673
   Hassanat ABA, 2018, PLOS ONE, V13, DOI [10.1371/journaL.pone.0207772, 10.1371/journal.pone.0207772]
   Jeong YW, 2010, IEEE T POWER SYST, V25, P1486, DOI 10.1109/TPWRS.2010.2042472
   Lee S.-W., 2016, Ivey Publishing, DOI [DOI 10.1109/IGCC.2016.7892600, DOI 10.1109/IEDM.2016.7838026]
   Malakar S., 2010, IJCCT, V2, P120
   Malakar S, 2020, NEURAL COMPUT APPL, V32, P2533, DOI 10.1007/s00521-018-3937-8
   Meng K, 2010, IEEE T POWER SYST, V25, P215, DOI 10.1109/TPWRS.2009.2030359
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Nawade SA, 2018, 2018 INTERNATIONAL CONFERENCE ON SMART COMPUTING AND ELECTRONIC ENTERPRISE (ICSCEE)
   Oh J, 2017, INT J DOC ANAL RECOG, V20, P79, DOI 10.1007/s10032-017-0281-y
   Okamoto M, 1999, PATTERN RECOGN, V32, P1115, DOI 10.1016/S0031-3203(98)00153-8
   Pacha A, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P795, DOI 10.1109/ICMLA.2017.00-60
   Pinheiro Pereira RM, 2016, P 22 BRAZ S MULT WEB, P191
   Pugin L., 2006, P INT C MUSIC INFORM, P53
   Rebelo A, 2010, INT J DOC ANAL RECOG, V13, P19, DOI 10.1007/s10032-009-0100-1
   Salesi S, 2017, PROCEEDINGS OF 2017 2ND INTERNATIONAL CONFERENCE ON KNOWLEDGE ENGINEERING AND APPLICATIONS (ICKEA), P6, DOI 10.1109/ICKEA.2017.8169893
   Sarkar S, 2018, 2 INT C COMP INT COM
   Shi W, 2010, 2010 INTERNATIONAL CONFERENCE ON E-EDUCATION, E-BUSINESS, E-MANAGEMENT AND E-LEARNING: IC4E 2010, PROCEEDINGS, P255, DOI 10.1109/IC4E.2010.22
   Todd Reed K., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P803, DOI 10.1109/ICPR.1996.547279
   Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77
   Trehub SE, 2015, PHILOS T R SOC B, V370, P59, DOI 10.1098/rstb.2014.0096
   Valero-Mas JJ, 2017, SOFT COMPUT, V21, P5703, DOI 10.1007/s00500-016-2148-4
NR 36
TC 11
Z9 11
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32011
EP 32036
DI 10.1007/s11042-020-09638-3
EA AUG 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000562697400002
DA 2024-07-18
ER

PT J
AU Caro, K
   Encinas-Monroy, IA
   Amado-Sanchez, VL
   Islas-Cruz, OI
   Ahumada-Solorza, EA
   Castro, LA
AF Caro, Karina
   Encinas-Monroy, Ivan Alejandro
   Amado-Sanchez, Veronica Lizeth
   Islas-Cruz, Oscar Ivan
   Ahumada-Solorza, Edgar Armando
   Castro, Luis A.
TI Using a Gesture-based videogame to support eye-hand coordination and
   pre-literacy skills of children with down syndrome
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gesture-based videogame; Down syndrome; Eye-hand coordination; Literacy
   skills
ID YOUNG-CHILDREN; EXERGAME; FITNESS; ADULTS; IPAD
AB Children with Down syndrome (DS) have deficits in eye-hand coordination skills. Deficits in eye-hand coordination could negatively impact the acquisition of literacy skills. This paper presents the evaluation of BeeSmart, a gesture-based videogame for supporting eye-hand coordination and pre-literacy skills. The aim of this work is to investigate whether BeeSmart has the potential to support eye-hand coordination and pre-literacy skills of children with DS. A 10-week study with seven children with DS and two psychotherapists is presented. The results indicate thatBeeSmartwas perceived as a potential tool to support eye-hand coordination and pre-literacy skills. Three out of seven participants improved their eye-hand coordination and pre-literacy skills to some degree. The evaluation study also revealed some improvements that should be made to BeeSmart, such as a reward counter for children with DS with a higher cognitive level. More game sessions with BeeSmart is required to investigate at what degree ofBeeSmartimproves eye-hand coordination and pre-literacy skills of children with DS.
C1 [Caro, Karina] Autonomous Univ Baja California UABC, Ensenada, Baja California, Mexico.
   [Encinas-Monroy, Ivan Alejandro; Amado-Sanchez, Veronica Lizeth; Islas-Cruz, Oscar Ivan; Ahumada-Solorza, Edgar Armando; Castro, Luis A.] Sonora Inst Technol ITSON, Obregon, Sonora, Mexico.
RP Caro, K (corresponding author), Autonomous Univ Baja California UABC, Ensenada, Baja California, Mexico.
EM karina.caro.co@gmail.com; ivanencinasm@gmail.com;
   veronicaamado4@gmail.com; oislas03@gmail.com; eahumadasolorza@gmail.com;
   luis.castro@acm.org
RI Castro, Luis A./E-7568-2011
OI Castro, Luis A./0000-0002-1196-4919; Caro, Karina/0000-0003-2868-9885
FU Sonora Institute of Technology (ITSON) through the PROFAPI program
FX The authors thank all the participants and staff from CENTRO DOWN. This
   research was partially funded by the Sonora Institute of Technology
   (ITSON) through the PROFAPI program.
CR Afyouni I., 2017, Proceedings of the 22nd International Conference on Intelligent User Interfaces Companion, P133, DOI DOI 10.1145/3030024.3040977
   Sanchez VLA, 2017, LECT NOTES COMPUT SC, V10653, P43, DOI 10.1007/978-3-319-71940-5_4
   BADILLO JIMENEZ V.T., 2014, INT J ED, V4, P1
   Beery KE, 2004, BEERY VMI BEERYBUKTE
   Berg P, 2012, PEDIATR PHYS THER, V24, P78, DOI 10.1097/PEP.0b013e31823e05e6
   Bos C., 2002, Strategies for teaching students with learning and behavior problems
   Campbell DT., 1963, EXPT QUASIEXPERIMENT
   Cano S, 2015, P XVI INT C HUM COMP, P18
   Caro K, 2017, INT J HUM-COMPUT ST, V105, P12, DOI 10.1016/j.ijhcs.2017.03.005
   Chai Z, 2015, J SPEC EDUC, V48, P268, DOI 10.1177/0022466913517554
   Deckers SRJM, 2016, CHILD LANG TEACH THE, V32, P293, DOI 10.1177/0265659016630775
   deDiego-Cottinelli A, 2010, 9TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC2010), P278
   Deterding S., 2011, P 15 INT AC MINDTREK, P9, DOI [DOI 10.1145/2181037.2181040, 10.1145/2181037.2181040]
   Felix VG, 2017, BRIT J EDUC TECHNOL, V48, P611, DOI 10.1111/bjet.12426
   Haro B.P.M., 2012, P 4 MEX C HUM COMP I, P28, DOI [10.1145/2382176.2382183, DOI 10.1145/2382176.2382183]
   Hernandez Hamilton A, 2013, Proceedings of CHI'13, P1261, DOI [10.1145/2470654, DOI 10.1145/2470654, 10.1145/2470654.2466164]
   Hilton CL, 2014, AM J OCCUP THER, V68, P57, DOI 10.5014/ajot.2014.008664
   Holtzblatt K., 2005, RAPID CONTEXTUAL DES
   Hutchison A, 2012, READ TEACH, V66, P15, DOI 10.1002/TRTR.01090
   IJsselsteijn W.A., MARKET LETT, V27, P361
   Iosa M, 2015, TOP STROKE REHABIL, V22, P306, DOI 10.1179/1074935714Z.0000000036
   Jadán-Guerrero J, 2015, SENSORS-BASEL, V15, P14845, DOI 10.3390/s150714845
   Johansson-Sköldberg U, 2013, CREAT INNOV MANAG, V22, P121, DOI 10.1111/caim.12023
   Kashyap M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P61, DOI 10.1109/ICRCICN.2015.7434210
   Knights S, 2016, DEV NEUROREHABIL, V19, P135, DOI 10.3109/17518423.2014.923056
   Kumin L, 2012, J USABILITY STUD, V7, P118
   Lerslip S., 2016, Global Journal of Health Science, V8, P60, DOI DOI 10.5539/GJHS.V8N12P60
   Macias A., 2017, INT C SMART OBJ TECH, P92
   Mareeuw FAV, 2017, BMC HEALTH SERV RES, V17, DOI 10.1186/s12913-017-2228-x
   Ozmun J.C., 1998, Understanding motor development: Infants, children, adolescents, adults
   Parette HP, 2008, EARLY CHILD EDUC J, V36, P233, DOI 10.1007/s10643-008-0275-y
   Rahman S.A. R. A., 2010, World Applied Sciences Journal, V10, P254
   Read Janet C., 2008, Cognition, Technology & Work, V10, P119, DOI 10.1007/s10111-007-0069-9
   Sanghavi R., 2005, J INDIAN OCCUPATIONA, V27, P33, DOI DOI 10.1016/J.SBSPRO.2014.01.1201
   Silva V, 2017, J INTELL DISABIL RES, V61, P755, DOI 10.1111/jir.12384
   Spano M, 1999, Eur J Paediatr Neurol, V3, P7, DOI 10.1053/ejpn.1999.0173
   Strauss E, 1998, CLIN ORTHOP RELAT R, P2
   Thompson D, 2010, SIMULAT GAMING, V41, P587, DOI 10.1177/1046878108328087
   Troncoso MV, 1999, SINDROME LECT ESCRIT
   Varuzza C, 2015, RES DEV DISABIL, V37, P135, DOI 10.1016/j.ridd.2014.11.011
   Wuang YP, 2011, RES DEV DISABIL, V32, P312, DOI 10.1016/j.ridd.2010.10.002
NR 41
TC 6
Z9 7
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34101
EP 34128
DI 10.1007/s11042-020-09452-x
EA AUG 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000561518100005
DA 2024-07-18
ER

PT J
AU Shahamiri, SR
   Thabtah, F
AF Shahamiri, Seyed Reza
   Thabtah, Fadi
TI An investigation towards speaker identification using a
   single-sound-frame
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic speaker identification; Feature extraction; MFCC; Deep neural
   networks
ID ARTIFICIAL NEURAL-NETWORKS; RECOGNITION; FEATURES; EXTRACTION;
   TRANSFORM; ENERGY; SYSTEM; SET
AB Traditional neural network-based speaker identification (SI) studies employ a combination of acoustic features extracted from sequential sounds to present the speakers' voice biometrics in which several sound segments before and after the current segment are stacked and fed to the network. Although this method is particularly important for speech recognition tasks where words are constructed from sequential sound segments, and successful recognition of words depends on the previous phonetic sequences, SI systems should be able to operate based on the distinctive speaker features available in an individual sound segment and identify the speaker regardless of the previously uttered sounds. This paper investigates this hypothesis by proposing a novel text-independent SI model trained at sound level. In order to achieve this, the investigation was conducted by first studying the best distinguishable configuration of coefficients in a single acoustic segment, then to identify the best frame length to overlapping ratio, and finally measuring the reliability of conducting SI using only a single sound segment. Overall more than one hundred SI systems were trained and evaluated, in which results indicate that performing SI using a single acoustic sound frame decreases the complexity of SI and facilitates it since the classifier requires to learn fewer number of acoustic features in compare to the traditional stacked-based approaches.
C1 [Shahamiri, Seyed Reza] Univ Auckland, Fac Engn, Dept Elect Comp & Software Engn, Auckland, New Zealand.
   [Thabtah, Fadi] Manukau Inst Technol, Sch Digital Technol, Auckland, New Zealand.
C3 University of Auckland; Manukau Institute of Technology
RP Shahamiri, SR (corresponding author), Univ Auckland, Fac Engn, Dept Elect Comp & Software Engn, Auckland, New Zealand.
EM admin@rezanet.com; fadi.fayez@manukau.ac.nz
RI Shahamiri, Seyed Reza/G-4389-2011
OI Shahamiri, Seyed Reza/0000-0003-1543-5931
CR Ahmad KS, 2015, ICAPR 2015 2015 8 IN, DOI 10.1109/ICAPR.2015.7050669
   Almaadeed N, 2015, IET BIOMETRICS, V4, P18, DOI 10.1049/iet-bmt.2014.0011
   Biagetti G, 2016, SMART INNOV SYST TEC, V57, P465, DOI 10.1007/978-3-319-39627-9_41
   Chandra M, 2015, ADV INTELL SYST, V328, P529, DOI 10.1007/978-3-319-12012-6_58
   Chollet F, 2015, KERAS
   Daqrouq K, 2012, COMPUT ELECTR ENG, V38, P1467, DOI 10.1016/j.compeleceng.2012.04.014
   Dhonde SB, 2017, ADV INTELL SYST, V468, P791, DOI 10.1007/978-981-10-1675-2_78
   Do H, 2011, ICASSP IEEE INT C AC, DOI 10.1109/ICASSP.2011.5947588
   Dutta M, 2015, ADV INTELL SYST, V327, P377, DOI 10.1007/978-3-319-11933-5_41
   Fan X, 2011, IEEE T AUDIO SPEECH, V19, P1408, DOI 10.1109/TASL.2010.2091631
   Hansen JHL, 2015, IEEE SIGNAL PROC MAG, V32, P74, DOI 10.1109/MSP.2015.2462851
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Islam MA, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0158520
   Kockmann M, 2011, SPEECH COMMUN, V53, P1172, DOI 10.1016/j.specom.2011.01.007
   Kusy B, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS (IPSN 2009), P109
   Lu H, 2011, LECT NOTES COMPUT SC, V6696, P188, DOI 10.1007/978-3-642-21726-5_12
   Lukic Y., 2016, 2016 IEEE 26 INT WOR, P1, DOI DOI 10.1109/MLSP.2016.7738816
   Maina CW, 2010, 2010 44 ANN C INF SC, DOI 10.1109/CISS.2010.5464893
   Matejka P, 2016, INT CONF ACOUST SPEE, P5100, DOI 10.1109/ICASSP.2016.7472649
   Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382
   Nagaraja BG, 2013, J INTELL SYST, V22, P241, DOI 10.1515/jisys-2013-0038
   Nakagawa S, 2012, IEEE T AUDIO SPEECH, V20, P1085, DOI 10.1109/TASL.2011.2172422
   Qi P, 2011, URAI 2011 2011 8 INT, DOI 10.1109/URAI.2011.6145927
   REYNOLDS DA, 1995, IEEE T SPEECH AUDI P, V3, P72, DOI 10.1109/89.365379
   Richardson F, 2015, IEEE SIGNAL PROC LET, V22, P1671, DOI 10.1109/LSP.2015.2420092
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Saeed K, 2007, IEEE T IND ELECTRON, V54, P887, DOI 10.1109/TIE.2007.891647
   Shahamiri SR, 2014, IEEE T NEUR SYS REH, V22, P1053, DOI 10.1109/TNSRE.2014.2309336
   Shahamiri SR, 2014, ADV ENG INFORM, V28, P102, DOI 10.1016/j.aei.2014.01.001
   Shahamiri SR, 2014, NEUROCOMPUTING, V129, P199, DOI 10.1016/j.neucom.2013.09.040
   Sinith MS, 2010, ICALIP 2010 2010 INT, DOI 10.1109/ICALIP.2010.5684389
   Tirumala SS, 2017, EXPERT SYST APPL, V90, P250, DOI 10.1016/j.eswa.2017.08.015
   Tirumala SS, 2017, ACM INT C P SER, DOI 10.1145/3163080.3163097
   Xiaojia Zhao, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3997, DOI 10.1109/ICASSP.2014.6854352
   Yu H, 2014, CONF REC ASILOMAR C, P500, DOI 10.1109/ACSSC.2014.7094494
   Zhang ZF, 2015, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-015-0056-7
NR 36
TC 7
Z9 8
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31265
EP 31281
DI 10.1007/s11042-020-09580-4
EA AUG 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000561259400003
DA 2024-07-18
ER

PT J
AU Li, GL
   Rana, MNA
   Sun, JH
   Song, YL
   Qu, JF
AF Li, Guoliang
   Rana, Mohammad N. A.
   Sun, Jinhong
   Song, Yinglei
   Qu, Junfeng
TI Real-time image enhancement with efficient dynamic programming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image enhancement; Objective function; Dynamic programming; Real-time
   applications
ID CONTRAST ENHANCEMENT
AB Image enhancement is a problem of fundamental importance in the area of low level image processing. The goal of image enhancement is to significantly improve the visual effects of images or to obtain the fine details that are invisible in degraded images. In this paper, a new accurate image enhancement algorithm is developed to efficiently perform image enhancement with a dynamic programming approach. Specifically, an objective function is developed for the mappings between an original image and its enhanced versions to evaluate the effectiveness of enhancement. The objective function is then optimized by a dynamic programming algorithm to achieve the optimal enhancement effect. It is also shown that the computation efficiency of this dynamic programming algorithm can be significantly improved when certain conditions are satisfied. Testing results show that this new algorithm can efficiently generate images with significantly improved effectiveness of enhancement and is thus potentially useful for real-time applications. An implementation of the algorithm in MATLAB is freely available at the link: https://github.com/yinglei2020/YingleiSong.
C1 [Li, Guoliang; Rana, Mohammad N. A.; Sun, Jinhong; Song, Yinglei] Jiangsu Univ Sci & Technol, Sch Elect & Informat Sci, Zhenjiang 212003, Jiangsu, Peoples R China.
   [Qu, Junfeng] Clayton State Univ, Dept Comp Sci & Informat Technol, Morrow, GA 30260 USA.
C3 Jiangsu University of Science & Technology; University System of
   Georgia; Clayton State University
RP Song, YL (corresponding author), Jiangsu Univ Sci & Technol, Sch Elect & Informat Sci, Zhenjiang 212003, Jiangsu, Peoples R China.
EM syinglei2013@163.com
RI Li, Guoliang/M-6614-2014
OI Song, Yinglei/0000-0003-3982-7657
CR Abdelwahab AA, 2007, RAD SCI C
   Ahmad J, 2019, J REAL-TIME IMAGE PR, V16, P227, DOI 10.1007/s11554-018-0784-x
   [Anonymous], 2016, INT C ADV INTELLIGEN
   Azetsu T, 2019, OPT REV, V26, P283, DOI 10.1007/s10043-019-00499-2
   BOCKSTEIN IM, 1986, J OPT SOC AM A, V3, P735, DOI 10.1364/JOSAA.3.000735
   Chandran AK, 2019, J REAL-TIME IMAGE PR, V16, P971, DOI 10.1007/s11554-016-0584-0
   Coullon H, 2017, 2017 IEEE 5TH INTERNATIONAL CONFERENCE ON FUTURE INTERNET OF THINGS AND CLOUD (FICLOUD 2017), P183, DOI 10.1109/FiCloud.2017.51
   Dixit A.K., 2019, INT J COMPUT SCI ENG, V7, P263
   Florea C, 2009, APPL SOFT COMPUT, V9, P1139, DOI 10.1016/j.asoc.2009.02.011
   Gharbi M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073592
   Gupta B, 2019, MULTIDIM SYST SIGN P, V30, P1829, DOI 10.1007/s11045-019-00630-1
   Hummel R.A., 1975, COMPUT VISION GRAPH, V4, P209, DOI [10.1016/0146-664X(75)90009-X, DOI 10.1016/0146-664X(75)90009-X]
   Jaya VL, 2013, INT J COMPUTER APPL, V79
   Kumar JR, 2013, APSIPA T SIGNAL INFO, V2, pe6
   Lee S, 2006, OPT ENG, V45, DOI 10.1117/1.2174802
   Lee S, 2007, IEEE T CIRC SYST VID, V17, P199, DOI 10.1109/TCSVT.2006.887078
   Lee S, 2006, PATTERN RECOGN LETT, V27, P1054, DOI 10.1016/j.patrec.2005.12.004
   Li QM, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12030446
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Munteanu C., 2001, Applied Computing Review, V9, P8, DOI 10.1145/570142.570146
   Panetta KA, 2008, IEEE T SYST MAN CY B, V38, P174, DOI 10.1109/TSMCB.2007.909440
   Park J, 2018, ARXIV180404450V2
   Ramponi G, 1996, J ELECTRON IMAGING, V5, P353, DOI 10.1117/12.242618
   Su XP, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/824787
   Talebi H, 2018, IEEE INT CONF COMPUT
   Tang JS, 2003, IEEE SIGNAL PROC LET, V10, P289, DOI 10.1109/LSP.2003.817178
   Tao L, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Thakur N., 2011, International Journal of Computer Applications, V15, P10, DOI 10.5120/1921-2565
   TUBBS JD, 1987, PATTERN RECOGN, V20, P617, DOI 10.1016/0031-3203(87)90031-8
   WANG DCC, 1983, COMPUT VISION GRAPH, V24, P363, DOI 10.1016/0734-189X(83)90061-0
   Watson A. B., 1993, DIGITAL IMAGES HUMAN
   Wyszecki G., 1982, COLOR SCI
NR 32
TC 6
Z9 6
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30883
EP 30903
DI 10.1007/s11042-020-09586-y
EA AUG 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000560297300010
DA 2024-07-18
ER

PT J
AU Mukherjee, S
   Sanyal, G
AF Mukherjee, Srilekha
   Sanyal, Goutam
TI Image steganography with N-puzzle encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; N-puzzle encryption; Mid position value(MPV); Peak signal
   to noise ratio (PSNR); Similarity measure
ID CAPACITY
AB Security, when referred to the context of data/information, is indeed a very vulnerable and necessary entity at present. Rigorous researches are cropping up for the betterment of the secured globe. Primarily, the term 'Steganography' has been in limelight to cater the extreme need of protection of sensitive and confidential data. This paper presents a two level steganographic approach of masking the secret data. This is done to facilitate data hiding and hence ensures a covert communication. On the whole, the targeted goal of this methodology is to maintain a trade-off between payload, imperceptibility and robustness. The first stage of the procedure imposes the Arnold transformation on the canier image. The output of this stage is a scrambled image. This scrambling of pixel data bits disrupts the normal orientation of the resident pixels. Next, an N-puzzle based technique is applied on the scrambled image to promote a strategy of encryption. The concept of N-puzzle problem stands to be the base of this step. Post this stage, the output generated is a ftwther encrypted image. Thereafter, the insertion technique of Mid Position Value (MPV) is applied to embed bits from the secret image within the above generated form of cover/carrier. After the procedure of insertion, the application of reverse N-puzzle encryption technique followed by the inverse Arnold transform fosters the final stego-image. This, on the whole, results in reverting back to the normal orientation of the original input image. All of the given experimental results highlight the outcome of the whole methodology. On this context, several of the quantitative as well as qualitative benchmark parameters have been analyzed. The results computed shows that the quality is well maintained. The generated stego is imperceptible. It also supports the non-detectability of secret data. The payload promoted in this procedure is quite high. Thus, the trade-off between the security parameters is maintained.
C1 [Mukherjee, Srilekha; Sanyal, Goutam] Natl Inst Technol, Dept CSE, Durgapur, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Durgapur
RP Sanyal, G (corresponding author), Natl Inst Technol, Dept CSE, Durgapur, India.
EM srilekha.mukherjee3@gmail.com; nitgsanyal@gmail.com
RI Mukherjee, Srilekha/ABA-7026-2020
CR Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Abdulla AA, 2014, PROC SPIE, V9120, DOI 10.1117/12.2050518
   Al-Taani AT, 2009, INT J COMPUT INF SCI, V3, P574
   [Anonymous], 2017, 2017 IEEECIC INT C C
   [Anonymous], 2010, IMAGE PROCESSING THE
   Ash S, 2015, 2015 SECOND INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING AND COMMUNICATION ENGINEERING ICACCE 2015, P471, DOI 10.1109/ICACCE.2015.74
   Banerjee I, 2015, INT J ELECTRON SECUR, V7, P345
   CHANDRAMOULI R, 2003, IWDW, P35
   Dukkipati A, 2012, APPL MATH COMPUT, V218, P11674, DOI 10.1016/j.amc.2012.05.052
   ELAYAN MA, 2016, ICISP, V9680, P317, DOI DOI 10.1007/978-3-319-33618-3_32
   Ferzli R, 2010, P SPIE, VVIII
   Garg P, 2020, MULTIMED TOOLS APPL, V79, P25921, DOI 10.1007/s11042-020-09262-1
   Hansen BE, 2015, ECONOMET THEOR, V31, P337, DOI 10.1017/S0266466614000322
   Huang P, 2008, J MULTIMED, V3
   Jiang CL, 2020, MULTIMED TOOLS APPL, V79, P693, DOI 10.1007/s11042-019-07874-w
   Joshi A, 2013, NANOTECHNOLOGY, V24, DOI 10.1088/0957-4484/24/45/455705
   Kanan HR, 2014, EXPERT SYST APPL, V41, P6123, DOI 10.1016/j.eswa.2014.04.022
   Kang N, 2017, AM J TRANSL RES, V9, P2000
   Koo HI, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013020
   Lan T, 2000, ICIP
   Ma S, 2019, INT J HIGH PERFORM C, V56, P33
   Mukherjee Srilekha, 2017, International Journal of Computers and Applications, V39, P59, DOI 10.1080/1206212X.2016.1273624
   Mukherjee S, 2015, COMPUTING SUSTAINABL
   MUKHERJEE S, 2015, TENCON IEEE REGION, pN1582
   Mukherjee S, 2018, INT C COMP INT DAT S
   Mukherjee S, 2018, MULTIMED TOOLS APPL
   Mukherjee S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P406, DOI 10.1109/ICRCICN.2015.7434273
   Nagpal KD, 2015, INT J RECENT INNOVAT, V3, P776
   Potdar VM, 2004, 2004 2ND IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS, P223, DOI 10.1109/INDIN.2004.1417333
   Safarpour M, 2016, CORRABS160100299, V1601
   Sanchetti A, 2012, INT J INNOVATIVE TEC, V2
   Sharma M, 2020, MULTIMED TOOLS APPL, V79, P355, DOI 10.1007/s11042-019-08079-x
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P3469
   Soleymani SH, 2017, MULTIMED TOOLS APPL, V76, P20847, DOI 10.1007/s11042-016-4009-7
   Subhedar MS, 2020, MULTIMED TOOLS APPL, V79, P1865, DOI 10.1007/s11042-019-08221-9
   Thakur S, 2020, MULTIMED TOOLS APPL, V79, P4263, DOI 10.1007/s11042-018-6691-0
   Vreugdenhil J, 2009, IEEE INT SYMP CIRC S, P734, DOI 10.1109/ISCAS.2009.5117853
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yamaguchi Y., 2015, INT J INF COMMUN TEC, V7, P25
   Yin ZX, 2016, INT J EMBED SYST, V8, P249, DOI 10.1504/IJES.2016.076118
   Yuksel M, 2009, ABS09110089 CORR
NR 42
TC 3
Z9 3
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29951
EP 29975
DI 10.1007/s11042-020-09522-0
EA AUG 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000559430400010
DA 2024-07-18
ER

PT J
AU Chhikara, S
   Kumar, R
AF Chhikara, Sonam
   Kumar, Rajeev
TI MI-LFGOA: multi-island levy-flight based grasshopper optimization for
   spatial image steganalysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganalysis; Feature reduction; Feature selection; Optimization
ID STEGANOGRAPHY
AB A few rich models of steganalysis have been developed that produce high dimensional feature sets for good detection accuracy with high computational cost and time. This paper inspires by the multi-layered concept with a metaheuristic method for reducing the dimensions of feature set and computational cost with maintained detection accuracy. We use Grasshopper Optimization algorithm (GOA) as a baseline for feature reduction, due to its advantage of giving good global optima. While for improving random walk of grasshoppers for balancing local and global solution search in parallel, we use Levy-Flight to modify the GOA which is named as Levy-Flight Grasshopper Optimization algorithm (LFGOA). To reduce the general redundant features without affecting detection accuracy, we preprocess the original feature set with PCA followed by LFGOA for further reduction in dimensions of resultant feature set with improved detection accuracy. This same proposed model is executed at different levels (Multi-Islands) with a different set of the population to get better results than single level LFGOA. The proposed framework is named as Multi-Island Levy Flight Grasshopper Optimization (MI-LFGOA). On the ground of BOSS base 1.01 image database which consists of 10,000 grayscale images, we investigate the proposed steganalysis method for two rich model's feature sets (34671-D SRM and 686-D SPAM) with different classifiers. The experimental results show that MI-LFGOA is a promising method which achieves 92% to 96% reduction in features dimension while the detection accuracy of the steganalysis is maintained in comparison to other feature selection methods for steganalysis.
C1 [Chhikara, Sonam; Kumar, Rajeev] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi 110067, India.
C3 Jawaharlal Nehru University, New Delhi
RP Kumar, R (corresponding author), Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi 110067, India.
EM rajeevkumar.cse@gmail.com
RI Kumar, Rajeev/I-3506-2019
OI Kumar, Rajeev/0000-0001-5545-6919; Kumar, Rajeev/0000-0003-0233-6563
CR Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Avcibas I, 2003, IEEE T IMAGE PROCESS, V12, P221, DOI 10.1109/TIP.2002.807363
   Bansal S, 2020, ARTIF INTELL REV, V53, P5589, DOI 10.1007/s10462-020-09829-2
   Bao ZK, 2020, J AMB INTEL HUM COMP, V11, P1889, DOI 10.1007/s12652-019-01345-8
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Cao B, 2017, IEICE T INF SYST, VE100D, P1144, DOI 10.1587/transinf.2017EDL8011
   Chechkin A. V., 2008, Introduction to the Theory of Levy Flights, P129, DOI [DOI 10.1002/9783527622979.CH5, 10.1002/9783527622979.ch5]
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen CH, 2008, IEEE INT SYMP CIRC S, P3029, DOI 10.1109/ISCAS.2008.4542096
   Chhikara RR, 2018, INT J MACH LEARN CYB, V9, P821, DOI 10.1007/s13042-016-0610-3
   Chhikara RR, 2016, INT J MACH LEARN CYB, V7, P1195, DOI 10.1007/s13042-015-0448-0
   Christaline JA, 2017, J COMPUT SCI-NETH, V21, P182, DOI 10.1016/j.jocs.2017.06.014
   Chutani S, 2018, MULTIMED TOOLS APPL, V77, P7447, DOI 10.1007/s11042-017-4656-3
   Davidson J, 2010, LECT NOTES COMPUT SC, V6387, P118, DOI 10.1007/978-3-642-16435-4_10
   Derrac J, 2011, SWARM EVOL COMPUT, V1, P3, DOI 10.1016/j.swevo.2011.02.002
   Dumitrescu S, 2003, IEEE T SIGNAL PROCES, V51, P1995, DOI 10.1109/TSP.2003.812753
   Filler T, 2010, IEEE T INF FOREN SEC, V5, P705, DOI 10.1109/TIFS.2010.2077629
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Genc HM, 2007, P 15 EUR SIGN PROC C, P970, DOI [10.1109/SIU.2007.4298772, DOI 10.1109/SIU.2007.4298772]
   Guettari N, 2016, IEEE IMAGE PROC, P2742, DOI 10.1109/ICIP.2016.7532858
   Holub V, 2015, IEEE T INF FOREN SEC, V10, P219, DOI 10.1109/TIFS.2014.2364918
   Holub V, 2013, IEEE T INF FOREN SEC, V8, P1996, DOI 10.1109/TIFS.2013.2286682
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Huang Wei, 2012, Journal of Software, V23, P1869, DOI 10.3724/SP.J.1001.2012.04107
   Jackson JE, 2003, USERS GUIDE PRINCIPA, DOI 10.1002/0471725331
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Ker AD, 2005, IEEE SIGNAL PROC LET, V12, P441, DOI 10.1109/LSP.2005.847889
   Khashandarag AS, 2011, COMM COM INF SC, V176, P247
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Kodovsky J, 2012, PROC SPIE, V8303, DOI 10.1117/12.907495
   Kodovsky J, 2010, PROC SPIE, V7541, DOI 10.1117/12.838768
   Kumar R, 2002, EVOL COMPUT, V10, P283, DOI 10.1162/106365602760234117
   Kumar R., 1997, Second International Conference on Genetic Algorithms in Engineering Systems: Innovations and Applications (Conf. Publ. No.446), P19, DOI 10.1049/cp:19971149
   Leach KN, 2002, SE SYM SYS THRY, P239, DOI 10.1109/SSST.2002.1027042
   Li SP, 2007, LECT NOTES COMPUT SC, V4493, P382
   Lissovoi A, 2018, ALGORITHMICA, V80, P1634, DOI 10.1007/s00453-017-0377-2
   Liu Q, 2011, P 13 ACM MULT WORKSH, DOI 10.1145/2037252.2037267
   Lu JC, 2014, DIGIT INVEST, V11, P57, DOI 10.1016/j.diin.2013.12.001
   Luo XY, 2008, SIGNAL PROCESS, V88, P2138, DOI 10.1016/j.sigpro.2008.03.016
   Luo XY, 2010, SCI CHINA INFORM SCI, V53, P634, DOI 10.1007/s11432-010-0044-6
   Ma HP, 2019, SWARM EVOL COMPUT, V44, P365, DOI 10.1016/j.swevo.2018.04.011
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Pathak Y, 2019, MULTIMED TOOLS APPL, V78, P1473, DOI 10.1007/s11042-018-6155-6
   Pevny T, 2007, PROC SPIE, V6505, DOI 10.1117/12.696774
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Rossi L, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/382310
   Saremi S, 2017, ADV ENG SOFTW, V105, P30, DOI 10.1016/j.advengsoft.2017.01.004
   Scrucca L, 2017, R J, V9, P187
   Shi YQ, 2007, LECT NOTES COMPUT SC, V4437, P249
   Song X., 2015, P ACM WORKSH INF HID, P15, DOI DOI 10.1145/2756601.2756608
   Tan SQ, 2012, IEEE SIGNAL PROC LET, V19, P336, DOI 10.1109/LSP.2012.2194702
   Whitley D, 1998, J COMPUTING INFORM T, V7, P33
   Xia B. B, 2012, IMPROVE STEGANALYSIS, V2, P243
   Yang XS, 2012, ENG COMPUTATION, V29, P464, DOI 10.1108/02644401211235834
   Yang XS, 2009, LECT NOTES COMPUT SC, V5792, P169, DOI 10.1007/978-3-642-04944-6_14
   Zhang XP, 2010, IEEE SIGNAL PROC LET, V17, P635, DOI 10.1109/LSP.2010.2049415
   Zhao XX, 2009, WKDD: 2009 SECOND INTERNATIONAL WORKSHOP ON KNOWLEDGE DISCOVERY AND DATA MINING, PROCEEDINGS, P84, DOI 10.1109/WKDD.2009.105
NR 60
TC 12
Z9 12
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29723
EP 29750
DI 10.1007/s11042-020-09328-0
EA AUG 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000567227300003
DA 2024-07-18
ER

PT J
AU Huang, JC
AF Huang, Jinchao
TI Image super-resolution reconstruction based on generative adversarial
   network model with double discriminators
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image super-resolution reconstruction; Generative adversarial network;
   Double discriminators; KL divergence; Combination loss function
AB To improve the reconstruction accuracy and efficiency for image super-resolution, this paper proposes a novel image super-resolution reconstruction algorithm based on generative adversarial network model with double discriminators (SRGAN-DD). For the proposed super-resolution reconstruction algorithm, we add a new discriminator based on SRGAN model, and combine the Kullback-Leibler (KL) divergence and reverse KL divergence as the uniform objective function to train such two discriminators. By using the complementary statistical characteristics from such two KL divergences, the proposed SRGAN-DD model will effectively disperse the estimated density in multiple modes, and the problem of network collapsed during reconstruction will be effectively avoided, so the robustness and efficiency of the model training is improved. For the part of model loss function design, the loss function to construct content loss by Charbonnier loss function is applied. Then, we design the perception loss and style loss by using the feature maps from middle layers of deep neural network models to achieve a combination loss function. At last, the deconvolutional operation is introduced into the network model for image reconstruction to reduce the reconstruction time complexity. To validate the feasibility and effectiveness, three groups of experiments are conducted to compare the proposed SRGAN-DD model with state-of-the-arts algorithms. Experimental results have shown that the proposed algorithm achieves the best performance on both objective and subjective judgment indicators. With the combination of loss function, the reconstructed images show less effect of artifacts and less influence of noises. The proposed SRGAN-DD model shows significant gains in perceived quality in reconstructing images.
C1 [Huang, Jinchao] Longyan Univ, Coll Math & Informat Engn, Longyan 364000, Fujian, Peoples R China.
C3 Longyan University
RP Huang, JC (corresponding author), Longyan Univ, Coll Math & Informat Engn, Longyan 364000, Fujian, Peoples R China.
EM huangjinchao2017@163.com
FU Education and scientific research project for young and middle-aged
   teachers in Fujian province [JT180523]
FX This work was supported by the Education and scientific research project
   for young and middle-aged teachers in Fujian province (No. JT180523).
   The author wants to thank the members of College of Mathematics and
   Information Engineering in Longyan University for their proofreading
   comments. The author is very grateful to the anonymous reviewers for
   their constructive comments which have helped significantly in revising
   this work.
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Bordes A, 2009, J MACH LEARN RES, V10, P1737
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Gao J, 2018, CHIN ACAD LIBRARY, P1, DOI 10.1007/978-3-662-56701-2
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guangcheng W, 2018, J INFORM HIDING MULT, V9, P496
   Han W, 2017, MULTIMED TOOLS APPL, V76, P11143, DOI 10.1007/s11042-016-3656-z
   Hao-Xian W, 2014, J INFORM HIDING MULT, V5, P690
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hensel M, 2017, ADV NEUR IN, V30
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Gulrajani I, 2017, ADV NEUR IN, V30
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai W-S, 2017, PROC CVPR IEEE, P624, DOI DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li C, 2016, IEEE INT SEMICONDUCT
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Lin ZC, 2004, IEEE T PATTERN ANAL, V26, P83, DOI 10.1109/TPAMI.2004.1261081
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Schulter S, 2015, PROC CVPR IEEE, P3791, DOI 10.1109/CVPR.2015.7299003
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Nguyen TD, 2017, ADV NEUR IN, V30
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang YX, 2016, LECT NOTES COMPUT SC, V9910, P616, DOI 10.1007/978-3-319-46466-4_37
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Zeiler MD, 2011, IEEE I CONF COMP VIS, P2018, DOI 10.1109/ICCV.2011.6126474
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhao FJ, 2019, MULTIMEDIA SYST, V25, P109, DOI 10.1007/s00530-017-0580-7
   Zhijiang Wang, 2015, Journal of Nanomaterials, V2015, DOI 10.1155/2015/412071
   Zhou F, 2012, IEEE T IMAGE PROCESS, V21, P3312, DOI 10.1109/TIP.2012.2189576
NR 44
TC 5
Z9 5
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29639
EP 29662
DI 10.1007/s11042-020-09524-y
EA AUG 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000559640300003
DA 2024-07-18
ER

PT J
AU Tuncer, T
   Dogan, S
   Abdar, M
   Plawiak, P
AF Tuncer, Turker
   Dogan, Sengul
   Abdar, Moloud
   Plawiak, Pawel
TI A novel facial image recognition method based on perceptual hash using
   quintet triple binary pattern
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Quintet triple binary pattern; Perceptual hash;
   Machine learning; Biometrics
ID BRAIN STORM OPTIMIZATION; ROBUST FACE RECOGNITION; FEATURE DESCRIPTOR;
   FEATURE-SELECTION; NEURAL-NETWORKS; 3D FACE; ALGORITHM; OCCLUSION
AB Image classification (categorization) can be considered as one of the most breathtaking domains of contemporary research. Indeed, people cannot hide their faces and related lineaments since it is highly needed for daily communications. Therefore, face recognition is extensively used in biometric applications for security and personnel attendance control. In this study, a novel face recognition method based on perceptual hash is presented. The proposed perceptual hash is utilized for preprocessing and feature extraction phases. Discrete Wavelet Transform (DWT) and a novel graph based binary pattern, called quintet triple binary pattern (QTBP), are used. Meanwhile, the K-Nearest Neighbors (KNN) and Support Vector Machine (SVM) algorithms are employed for classification task. The proposed face recognition method is tested on five well-known face datasets: AT&T, Face94, CIE, AR and LFW. Our proposed method achieved 100.0% classification accuracy for the AT&T, Face94 and CIE datasets, 99.4% for AR dataset and 97.1% classification accuracy for the LFW dataset. The time cost of the proposed method isO(nlogn). The obtained results and comparisons distinctly indicate that our proposed has a very good classification capability with short execution time.
C1 [Tuncer, Turker; Dogan, Sengul] Firat Univ, Technol Fac, Dept Digital Forens Engn, Elazig, Turkey.
   [Abdar, Moloud] Deakin Univ, Inst Intelligent Syst Res & Innovat IISRI, Geelong, Vic, Australia.
   [Plawiak, Pawel] Cracow Univ Technol, Fac Comp Sci & Telecommun, Dept Informat & Commun Technol, Warszawska 24 St,F-3, PL-31155 Krakow, Poland.
   [Plawiak, Pawel] Polish Acad Sci, Inst Theoret & Appl Informat, Baltycka 5, PL-44100 Gliwice, Poland.
C3 Firat University; Deakin University; Cracow University of Technology;
   Polish Academy of Sciences; Institute of Theoretical & Applied
   Informatics of the Polish Academy of Sciences
RP Plawiak, P (corresponding author), Cracow Univ Technol, Fac Comp Sci & Telecommun, Dept Informat & Commun Technol, Warszawska 24 St,F-3, PL-31155 Krakow, Poland.; Plawiak, P (corresponding author), Polish Acad Sci, Inst Theoret & Appl Informat, Baltycka 5, PL-44100 Gliwice, Poland.
EM plawiak@pk.edu.pl
RI Abdar, Moloud/B-8451-2017; DOGAN, Sengul/W-4854-2018; Pławiak,
   Paweł/K-8151-2013; TUNCER, Turker/W-4846-2018; DOGAN,
   Sengul/ABG-1141-2020; TUNCER, Türker/ABG-1146-2020
OI DOGAN, Sengul/0000-0001-9677-5684; Pławiak, Paweł/0000-0002-4317-2801;
   DOGAN, Sengul/0000-0001-9677-5684; 
CR Abate AF, 2007, PATTERN RECOGN LETT, V28, P1885, DOI 10.1016/j.patrec.2006.12.018
   Abdar M, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1343-0
   Abdullah MFA, 2014, EXPERT SYST APPL, V41, P6131, DOI 10.1016/j.eswa.2014.04.006
   Abusham EEA, 2011, LECT NOTES COMPUT SC, V6762, P169
   Akbarian B, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101878
   Alkeshuosh AH, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER AND APPLICATIONS (ICCA), P306, DOI 10.1109/COMAPP.2017.8079784
   [Anonymous], 2016, Advances in Face Detection and Facial Image Analysis
   Basiri ME, 2009, IEEE C EVOL COMPUTAT, P2561, DOI 10.1109/CEC.2009.4983263
   Basu DK, 2020, NEUROCOMPUTING, V408, P273, DOI [DOI 10.1016/J.NEUCOM.2019.10.117, 10.1016/j.neucom.2019.10.117]
   Chakraborty S, 2018, IEEE T CIRC SYST VID, V28, P171, DOI 10.1109/TCSVT.2016.2603535
   Chakraborty S, 2017, COMPUT ELECTR ENG, V62, P92, DOI 10.1016/j.compeleceng.2017.06.013
   Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644, DOI 10.1109/TPAMI.2002.1114855
   Dehmer M, 2017, INFORM SCIENCES, V418, P575, DOI 10.1016/j.ins.2017.08.009
   Deng WH, 2019, IEEE T PATTERN ANAL, V41, P758, DOI 10.1109/TPAMI.2018.2800008
   Ding CX, 2016, IEEE T PATTERN ANAL, V38, P518, DOI 10.1109/TPAMI.2015.2462338
   Ding LY, 2010, IEEE T PATTERN ANAL, V32, P2022, DOI 10.1109/TPAMI.2010.28
   Du LS, 2019, NEUROCOMPUTING, V340, P133, DOI 10.1016/j.neucom.2019.02.053
   El Merabet Y, 2018, PATTERN RECOGN, V76, P303, DOI 10.1016/j.patcog.2017.11.005
   Fathi A, 2016, J VIS COMMUN IMAGE R, V38, P65, DOI 10.1016/j.jvcir.2016.02.010
   Fernández A, 2011, OPT LASER ENG, V49, P1177, DOI 10.1016/j.optlaseng.2011.05.003
   Gupta Shreya, 2020, Computer Vision and Machine Intelligence in Medical Image Analysis. International Symposium, ISCMM 2019. Advances in Intelligent Systems and Computing (AISC 992), P13, DOI 10.1007/978-981-13-8798-2_2
   Huang J, 2019, CHIN CONT DECIS CONF, P5697, DOI [10.1109/ccdc.2019.8832457, 10.1109/CCDC.2019.8832457]
   Hung TY, 2014, IEEE IMAGE PROC, P239, DOI 10.1109/ICIP.2014.7025047
   Jabid T, 2012, INT J INNOV COMPUT I, V8, P2423
   Jain N, 2018, PATTERN RECOGN LETT, V115, P101, DOI 10.1016/j.patrec.2018.04.010
   Kabacinski R, 2011, ELECTRON LETT, V47, P1127, DOI 10.1049/el.2011.1441
   Kagawade VC, 2019, IMAGE VISION COMPUT, V83-84, P39, DOI 10.1016/j.imavis.2019.02.001
   Kar A, 2020, APPL INTELL, V50, P698, DOI 10.1007/s10489-019-01545-x
   Kas M, 2018, EXPERT SYST APPL, V114, P119, DOI 10.1016/j.eswa.2018.07.035
   Kaya Y, 2015, APPL SOFT COMPUT, V34, P728, DOI 10.1016/j.asoc.2015.06.009
   Kim Y, 2020, IEEE ACCESS, V8, P20160, DOI 10.1109/ACCESS.2020.2968944
   Klöpper B, 2009, DETC 2008: PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATIONAL IN ENGINEERING CONFERENCE, VOL 3, PTS A AND B, P47
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Krol M, 2008, COMPUTER RECOGNITION, P791
   Liang Y, 2017, SIGNAL PROCESS-IMAGE, V57, P84, DOI 10.1016/j.image.2017.05.004
   Liao MM, 2020, NEUROCOMPUTING, V373, P35, DOI 10.1016/j.neucom.2019.09.025
   Liu L, 2016, INFORM SCIENCES, V358, P56, DOI 10.1016/j.ins.2016.04.021
   Liu SG, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102763
   Luo XL, 2019, PATTERN RECOGN, V93, P283, DOI 10.1016/j.patcog.2019.04.027
   Lv JJ, 2016, NEUROCOMPUTING, V216, P735, DOI 10.1016/j.neucom.2016.08.036
   Martinez A.M., 1998, AR FACE DATABASE CVC
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Masi I, 2018, SIBGRAPI, P471, DOI 10.1109/SIBGRAPI.2018.00067
   Moustafa AA, 2020, SIGNAL IMAGE VIDEO P, V14, P1027, DOI 10.1007/s11760-020-01635-1
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Nemati S, 2009, EXPERT SYST APPL, V36, P12086, DOI 10.1016/j.eswa.2009.04.023
   Vu NS, 2012, IEEE T IMAGE PROCESS, V21, P1352, DOI 10.1109/TIP.2011.2166974
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojala T., 2001, Advances in Pattern Recognition - ICAPR 2001. Second International Conference. Proceedings (Lecture Notes in Computer Science Vol.2013), P397
   Ou WH, 2018, PATTERN RECOGN LETT, V107, P41, DOI 10.1016/j.patrec.2017.07.006
   Ou WH, 2014, PATTERN RECOGN, V47, P1559, DOI 10.1016/j.patcog.2013.10.017
   Peng F, 2020, J VIS COMMUN IMAGE R, V66, DOI 10.1016/j.jvcir.2019.102746
   Plawiak P, 2020, INFORM SCIENCES, V516, P401, DOI 10.1016/j.ins.2019.12.045
   Plawiak P, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105740
   Plawiak P, 2014, INT J AP MAT COM-POL, V24, P165, DOI 10.2478/amcs-2014-0013
   Pourpanah F, 2019, APPL SOFT COMPUT, V80, P761, DOI 10.1016/j.asoc.2019.04.037
   Pourpanan F, 2019, NEUROCOMPUTING, V333, P440, DOI 10.1016/j.neucom.2019.01.011
   Priya RV, 2020, NEURAL COMPUT APPL, V32, P3165, DOI 10.1007/s00521-018-3940-0
   Rajput S., 2016, INT J FDN COMPUTER S, V6, P55
   Rakshit RD, 2018, EXPERT SYST APPL, V92, P82, DOI 10.1016/j.eswa.2017.09.038
   Ramya R, 2020, HUMAN BEHAVIOUR ANAL, P1
   Riccio D, 2007, PATTERN RECOGN LETT, V28, P1907, DOI 10.1016/j.patrec.2006.12.017
   Rzecki K, 2017, INFORM SCIENCES, V415, P70, DOI 10.1016/j.ins.2017.05.041
   Sam Yin Yee, 2020, Advances in Electronics Engineering. Proceedings of the ICCEE 2019. Lecture Notes in Electrical Engineering (LNEE 619), P315, DOI 10.1007/978-981-15-1289-6_29
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   SHI YB, 1994, DISCRETE MATH, V133, P249, DOI 10.1016/0012-365X(94)90031-0
   Song KC, 2015, J VIS COMMUN IMAGE R, V33, P323, DOI 10.1016/j.jvcir.2015.09.016
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Tadeusiewicz R, 2015, BIO-ALGORITHMS MED-S, V11, P135, DOI 10.1515/bams-2015-0021
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tang ZJ, 2018, APPL MATH COMPUT, V321, P721, DOI 10.1016/j.amc.2017.11.017
   Tuncer T, 2019, KNOWL-BASED SYST, V186, DOI 10.1016/j.knosys.2019.104923
   Vazquez-Fernandez E, 2016, IMAGE VISION COMPUT, V55, P31, DOI 10.1016/j.imavis.2016.03.018
   Vishwakarma VP, 2020, MULTIMED TOOLS APPL, V79, P11503, DOI 10.1007/s11042-019-08537-6
   Vu NS, 2012, PATTERN RECOGN, V45, P2478, DOI 10.1016/j.patcog.2011.12.021
   Wang JW, 2018, INFORM SCIENCES, V435, P69, DOI 10.1016/j.ins.2017.12.057
   Weeks AR., 1996, FUNDAMENTALS ELECT I
   Wen Zhen-kun, 2010, Proceedings of the 2010 Fourth International Conference on Genetic and Evolutionary Computing (ICGEC 2010), P709, DOI 10.1109/ICGEC.2010.180
   Xu Z, 2019, NEUROCOMPUTING, V355, P1, DOI 10.1016/j.neucom.2018.09.056
   Yang B, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P167
   Youbi Z, 2018, 2018 INTERNATIONAL CONFERENCE ON SIGNAL, IMAGE, VISION AND THEIR APPLICATIONS (SIVA)
   Zhou LF, 2018, PATTERN RECOGN, V78, P43, DOI 10.1016/j.patcog.2018.01.003
   Zhou LJ, 2020, MULTIMED TOOLS APPL, V79, P675, DOI 10.1007/s11042-019-08157-0
   Zhou XZ, 2019, INFORM FUSION, V48, P84, DOI 10.1016/j.inffus.2018.07.011
   Zimei Li, 2020, Advances in Intelligent Information Hiding and Multimedia Signal Processing. Proceedings of the 15th International Conference on IIH-MSP in conjunction with the 12th International Conference on FITAT. Smart Innovation, Systems and Technologies (SIST 157), P333, DOI 10.1007/978-981-13-9710-3_35
   Zomorodi-moghadam M, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12485
NR 87
TC 14
Z9 15
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29573
EP 29593
DI 10.1007/s11042-020-09439-8
EA AUG 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000567227300002
OA hybrid
DA 2024-07-18
ER

PT J
AU Hmood, AK
   Suen, CY
AF Hmood, Ali K.
   Suen, Ching Y.
TI Statistical edge-based feature selection for counterfeit coin detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pattern recognition; Forensics; Counterfeit coin detection; Edge
   statistical features
AB The number of counterfeit coins released into circulation is persistently increasing. According to official reports, the mass majority of these coins are circulated in the European Union member countries. This paper presents a robust method for counterfeit coin detection based on coin stamp differences between genuine and counterfeit coins. A set of measures based on edge differences are proposed in this paper. The proposed method compares theedge width,edge thickness,number of horizontal and vertical edges, andtotal number of edgesbetween a test coin and a set of genuine reference coins. The method extends the measures to generate adefect mapby subtracting the test coin image from the reference coins to count the number of pixels in small regions of the coin. Additionally, theSignal-to-Noise Ratio (SNR),Mean Square Error (MSE), andStructural Similarity (SSIM)which are well-known measures to track the differences between two images are also applied to the coin image. The sets of features are then placed into index space where each vector represents the features of one test coin and a reference coin. The final feature vector represents the features set of one test coin and is computed by averaging the feature value of vectors in the index space. This feature vector is used to train a classifier to learn the edge feature differences between the two classes. The proposed method achieved precision and recall rates as high as 99.6% and 99.3% respectively, demonstrating the effectiveness and robustness of the selected edge features in authenticating coins. The method was evaluated on a real-life dataset of Danish coins as part of a collaborative effort.
C1 [Hmood, Ali K.; Suen, Ching Y.] Concordia Univ, Ctr Pattern Recognit & Machine Intelligence CENPA, Sch Engn & Comp Sci, Montreal, PQ H3G 1M8, Canada.
C3 Concordia University - Canada
RP Hmood, AK (corresponding author), Concordia Univ, Ctr Pattern Recognit & Machine Intelligence CENPA, Sch Engn & Comp Sci, Montreal, PQ H3G 1M8, Canada.
EM ali.al-frajat@concordia.ca; suen@cse.concordia.ca
RI Hmood, ALI K/E-3284-2010
FU NSERC, Natural Sciences and Engineering Research Council of Canada
FX This research was supported by a research grant from NSERC, Natural
   Sciences and Engineering Research Council of Canada. The authors would
   like to thank the Danish police department for providing access to their
   genuine and counterfeit coins evidence. The authors also express their
   gratitude to the forensic company in Montreal, Ultra Forensic
   Technology, for providing access to their ultimately helpful specialized
   scanner in capturing such high-quality coin images.
CR [Anonymous], 1998, STAT LEARNING THEORY
   Attar A, 2016, MULTIMED TOOLS APPL, V75, P7407, DOI 10.1007/s11042-015-2663-9
   Cai SL, 2019, MULTIMED TOOLS APPL, V78, P29121, DOI 10.1007/s11042-018-6581-5
   Chen X., 2016, J NETW INTELL, V1, P83
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   Denker A, 2004, NUCL INSTRUM METH B, V226, P163, DOI 10.1016/j.nimb.2004.03.015
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Feng YB, 2020, KNOWL-BASED SYST, V188, DOI 10.1016/j.knosys.2019.105047
   Gagg CR, 2007, ENG FAIL ANAL, V14, P1144, DOI 10.1016/j.engfailanal.2006.11.063
   Gavrijaseva A, 2015, ELEKTRON ELEKTROTECH, V21, P54, DOI 10.5755/j01.eee.21.3.10384
   Hmood Ali K., 2018, Pattern Recognition and Image Analysis, V28, P569, DOI 10.1134/S1054661818040028
   Hmood A. K., 2018, Lang. Process. Pattern Recognition, Intell. Syst., P169
   Hmood AK, 2018, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE (ICPRAI 2018), P688
   Hmood AK, 2018, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE (ICPRAI 2018), P273
   Hmood AK, 2017, LECT NOTES COMPUT SC, V10317, P153, DOI 10.1007/978-3-319-59876-5_18
   Hmood AK, 2010, INT J PHYS SCI, V5, P1054
   Li J.-B., 2014, Kernel Learning Algorithms for Face Recognition
   Liu L, 2020, EXPERT SYSTEMS APPL, V159
   Liu L, 2017, IEEE T INF FOREN SEC, V12, P1227, DOI 10.1109/TIFS.2017.2656478
   Rad M. Sharifi, 2016, LNCS, P178
   Robitaille Jesse, 2015, CANADIAN COIN NEWS
   Sun K., 2015, P 28 ISCA INT C COMP, P165
   The European Technical and Scientific Centre, 2016, PROT EUR COINS 2016
   Tresanchez M, 2009, SENSORS-BASEL, V9, P7083, DOI 10.3390/s90907083
   Uliyan DM, 2016, EXPERT SYST APPL, V64, P1, DOI 10.1016/j.eswa.2016.07.026
   Wang JP, 2011, MACH VISION APPL, V22, P87, DOI 10.1007/s00138-009-0197-8
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
NR 27
TC 2
Z9 2
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 28621
EP 28642
DI 10.1007/s11042-020-09447-8
EA AUG 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000556182200001
DA 2024-07-18
ER

PT J
AU Tan, WC
   Isa, NAM
   Mohamed, M
AF Tan, Weng Chun
   Mat Isa, Nor Ashidi
   Mohamed, Mahaneem
TI Automated human sperm tracking using mean shift-collision detection and
   modified covariance matrix method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE In vitro fertilisation; Collision; Mean shift tracking; Modified
   covariance matrix
AB In vitro fertilisation (IVF) is a popular technique in assisted reproductive technology. The success of IVF mainly depends on the selection of the correct sperm in human semen sample. Sperm tracking plays an important role in selecting the active-moving sperm. One of the major challenges in sperm tracking is the collision of sperm cases during tracking. To solve this issue, mean shift-collision detection and modified covariance matrix (MS-CDMCM) is proposed. Specifically, MS-CDMCM detects collision and generates a new covariance matrix based on the collision condition. Then, this new covariance matrix will form a new tracked region to continue the tracking process. Results show that the proposed method is a more accurate and robust tracking method than other state-of-the-art sperm tracking methods. The proposed method produces significantly low error values, such as MAE, MSE and RMSE, according to the quantitative analysis when compared with ground truth images. The proposed method is expected to be implemented in sperm motility assessment in the future.
C1 [Tan, Weng Chun; Mat Isa, Nor Ashidi] Univ Sains Malaysia, Imaging & Intelligent Syst Res Team ISRT, Sch Elect & Elect Engn, Nibong Tebal 14300, Penang, Malaysia.
   [Mohamed, Mahaneem] Univ Sains Malaysia, Dept Physiol, Sch Med Sci, Kubang Kerian 16150, Malaysia.
C3 Universiti Sains Malaysia; Universiti Sains Malaysia
RP Isa, NAM (corresponding author), Univ Sains Malaysia, Imaging & Intelligent Syst Res Team ISRT, Sch Elect & Elect Engn, Nibong Tebal 14300, Penang, Malaysia.
EM jasontwc89@gmail.com; ashidi@usm.my; mahaneem@usm.my
RI Mohamed, Mahaneem/F-1159-2011; Tan, Jason/AAS-6418-2021; Mat Isa, Nor
   Ashidi/I-7826-2017
OI Mat Isa, Nor Ashidi/0000-0002-2675-4914
FU Universiti Sains Malaysia [1001/PELECT/8014030]; Ministry of Higher
   Education
FX This study is supported by the Universiti Sains Malaysia through the
   Research University Grants (RUI) entitled 'Development of Automated
   Intelligent Karyotyping System for Classifying Abnormal Chromosome'
   1001/PELECT/8014030 and by the Ministry of Higher Education under the
   MyPhD Scholarship. Credits are given to Nur Syuhada Mohd Nafis for her
   assistance in taking the sperm videos.
CR Beya O, 2015, 2015 11TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P155, DOI 10.1109/SITIS.2015.111
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Dong XP, 2017, IEEE T MULTIMEDIA, V19, P763, DOI 10.1109/TMM.2016.2631884
   Eckhorn R, 1990, NEURAL COMPUT, V2, P293, DOI 10.1162/neco.1990.2.3.293
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Forti G, 1998, J CLIN ENDOCR METAB, V83, P4177, DOI 10.1210/jc.83.12.4177
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Ghamisi P, 2012, EXPERT SYST APPL, V39, P12407, DOI 10.1016/j.eswa.2012.04.078
   Haddad S, 2015, RENEW SUST ENERG REV, V43, P635, DOI 10.1016/j.rser.2014.11.083
   Hidayatullah P, 2015, 2015 INT C INF TECHN, P1, DOI [10.1109/ICITSI.2015.7437674, DOI 10.1109/ICITSI.2015.7437674]
   Imani Yoones, 2014, J Med Signals Sens, V4, P35
   Jati G, 2016, INT C ADV COMP SCI I, P530, DOI 10.1109/ICACSIS.2016.7872796
   KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532
   Lu Z, 2011, IEEE T BIO-MED ENG, V58, P2102, DOI 10.1109/TBME.2011.2146781
   Mahapatra SK, 2016, INT C MICR COMP COMM, V2016, P9, DOI [10.1109/MicroCom.2016.7522416, DOI 10.1109/MICROCOM.2016.7522416]
   Murray KS, 2012, FERTIL STERIL, V98, P1428, DOI 10.1016/j.fertnstert.2012.07.1130
   Ning J, 2012, IET COMPUT VIS, V6, P52, DOI 10.1049/iet-cvi.2010.0112
   Sorensen L, 2008, PROC SPIE, V6914, DOI 10.1117/12.771135
   Tan WC, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162985
   WHO, 2000, WHO Air Quality Guidelines for Europe, V91, P91
   Yenkie KM, 2013, IEEE T BIO-MED ENG, V60, P3003, DOI 10.1109/TBME.2012.2227742
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
NR 22
TC 1
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 28551
EP 28585
DI 10.1007/s11042-020-09396-2
EA AUG 2020
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000556182200004
DA 2024-07-18
ER

PT J
AU Chuang, JC
   Hu, YC
   Chen, CM
   Yin, ZX
AF Chuang, Jun-Chou
   Hu, Yu-Chen
   Chen, Chia-Mei
   Yin, Zhaoxia
TI Adaptive grayscale image coding scheme based on dynamic multi-grouping
   absolute moment block truncation coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image compression; Absolute moment block truncation coding; Adaptive
   pixel grouping; Block prediction technique; Entropy coding
ID DATA HIDING SCHEME; TAMPER DETECTION; COMPRESSION; BTC; ALGORITHM;
   RECOVERY
AB Multi-Grouping Absolute Moment Block Truncation Coding (MGAMBTC) technique improve the image quality of Absolute Moment Block Truncation Coding (AMBTC) by adaptively dividing pixels in a block into groups according to block activity. This study found that the bit rate can be reduced further if there is some similarity among the blocks. Therefore, this study proposes a block prediction scheme that exploits the intra-block similarity of neighboring blocks. If a similar encoded block is found, its position code will be stored to encode the block; otherwise, it is encoded with the proposed improved MGAMBTC (iMGAMBTC). The proposed iMGAMBTC employs an entropy-based indicator generation mechanism to reduce the bit rate, and the evaluation demonstrates that the proposed scheme enhances the compression performance of AMBTC and MGAMBTC efficiently.
C1 [Chuang, Jun-Chou] Providence Univ, Dept Comp Sci & Commun Engn, 200 Chung Chi Rd, Taichung 43301, Taiwan.
   [Hu, Yu-Chen] Providence Univ, Dept Comp Sci & Informat Management, 200 Chung Chi Rd, Taichung 43301, Taiwan.
   [Chen, Chia-Mei] Natl Sun Yat Sen Univ, Dept Informat Management, Kaohsiung 80424, Taiwan.
   [Yin, Zhaoxia] Anhui Univ, Sch Comp Sci & Technol, Key Lab Intelligent Comp & Signal Proc, Minist Educ, Hefei 230601, Peoples R China.
C3 Providence University - Taiwan; Providence University - Taiwan; National
   Sun Yat Sen University; Anhui University
RP Hu, YC (corresponding author), Providence Univ, Dept Comp Sci & Informat Management, 200 Chung Chi Rd, Taichung 43301, Taiwan.
EM lzchung@pu.edu.tw; ychu@pu.edu.tw; cmchen@mis.nsysu.edu.tw;
   yinzhaoxia@ahu.edu.cn
RI Hui, Yu/JOZ-3598-2023; Yin, Zhaoxia/HRD-7425-2023; Hu,
   Yu-Chen/AAT-5264-2020
OI Yin, Zhaoxia/0000-0003-0387-4806; Hu, Yu-Chen/0000-0002-5055-3645
FU Ministry of Science and Technology, Taiwan, R.O.C.
   [106-2410-H-126-006-MY2, 108-2410-H-020-MY2]
FX This research was partially supported by the Ministry of Science and
   Technology, Taiwan, R.O.C. under project number 106-2410-H-126-006-MY2
   and 108-2410-H-020-MY2.
CR Alniacik U, 2011, PROCEEDINGS OF THE 6TH INTERNATIONAL SCIENTIFIC SYMPOSIUM ON BUSINESS ADMINISTRATION: GLOBAL ECONOMIC CRISIS AND CHANGES, P1
   Arnavut Ziya, 2014, 2014 IEEE Western New York Image and Signal Processing Workshop (WNYISPW), P11, DOI 10.1109/WNYIPW.2014.6999476
   Chang CC, 1998, IEEE T CONSUM ELECTR, V44, P1201
   Chang CC, 2018, MULTIMED TOOLS APPL, V77, P9039, DOI 10.1007/s11042-017-4800-0
   Chang IC, 2015, SIGNAL PROCESS, V108, P376, DOI 10.1016/j.sigpro.2014.09.036
   CHEN DP, 1990, IEEE T COMMUN, V38, P2137, DOI 10.1109/26.64656
   CHEN LG, 1994, IEEE T CIRC SYST VID, V4, P92, DOI 10.1109/76.276177
   Chen W.-L., 2014, INT J SIGNAL PROCESS, V7, P65, DOI DOI 10.14257/IJSIP.2014.7.1.07
   Dacles MDI, 2018, 2018 2ND INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (ICDSP 2018), P137, DOI 10.1145/3193025.3193042
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Dhara BC, 2004, PATTERN RECOGN, V37, P2131, DOI 10.1016/j.patcog.2004.02.008
   FRANTI P, 1994, COMPUT J, V37, P308, DOI 10.1093/comjnl/37.4.308
   Giudice O, 2018, IEEE IMAGE PROC, P1138, DOI 10.1109/ICIP.2018.8451221
   Hu YC, 2008, IMAGING SCI J, V56, P254, DOI 10.1179/174313108X2995.14
   Hu YC, 2013, OPTO-ELECTRON REV, V21, P137, DOI 10.2478/s11772-013-0078-6
   Hu YC, 2011, OPTO-ELECTRON REV, V19, P104, DOI 10.2478/s11772-010-0073-0
   Hu Y. C., 2018, 3 INT C COMP COMM SY
   Hu YC, 2013, IMAGING SCI J, V61, P80, DOI 10.1179/1743131X11Y.0000000043
   Hu YC, 2004, J ELECTRON IMAGING, V13, P871, DOI 10.1117/1.1785158
   Hu YC, 2003, ELECTRON LETT, V39, P1377, DOI 10.1049/el:20030884
   Hu YC, 2003, OPT ENG, V42, P1964, DOI 10.1117/1.1576776
   Hu YC, 2017, MULTIMED TOOLS APPL, V76, P15435, DOI 10.1007/s11042-016-3847-7
   Hu YC, 2014, OPT ENG, V53, DOI 10.1117/1.OE.53.9.093104
   Hu YC, 2013, SIGNAL PROCESS, V93, P2432, DOI 10.1016/j.sigpro.2013.03.034
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Lin YH, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19091974
   Lo CC, 2014, INT J SECUR APPL, V8, P301, DOI 10.14257/ijsia.2014.8.2.31
   NASIOPOULOS P, 1991, IEEE T COMMUN, V39, P1245, DOI 10.1109/26.134014
   Olsen SI, 2000, PATTERN RECOGN LETT, V21, P1141, DOI 10.1016/S0167-8655(00)00075-1
   Pinho AJ, 2004, IEEE T IMAGE PROCESS, V13, P1411, DOI 10.1109/TIP.2004.836168
   Qin C, 2018, IEEE MULTIMEDIA, V25, P36, DOI 10.1109/MMUL.2018.112142509
   Qiu XM, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9010017
   RAO YVR, 1995, IEEE T COMMUN, V43, P2010, DOI 10.1109/26.387439
   Singh D, 2019, MULTIMED TOOLS APPL, V78, P4197, DOI 10.1007/s11042-017-5454-7
   Tsou CC, 2008, IMAGING SCI J, V56, P217, DOI 10.1179/174313108X281335
   WU YY, 1992, IEEE J SEL AREA COMM, V10, P952, DOI 10.1109/49.139000
   Xiang ZY, 2019, MULTIMED TOOLS APPL, V78, P7895, DOI 10.1007/s11042-018-6030-5
   Xu Y, 2018, AAAI C ART INT
NR 38
TC 6
Z9 6
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 28189
EP 28205
DI 10.1007/s11042-020-09325-3
EA AUG 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000554436800008
DA 2024-07-18
ER

PT J
AU Elkorany, AS
   Elsharkawy, ZF
AF Elkorany, Ahmed S.
   Elsharkawy, Zeinab F.
TI Automated optimized classification techniques for magnetic resonance
   brain images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Pattern recognition; Artificial neural networks;
   Multi-verse optimizer; Moth-flame optimizer; Salp swarm algorithm
ID MOTH-FLAME OPTIMIZATION; TUMOR-DETECTION; SEGMENTATION; ALGORITHM;
   SYSTEM
AB This paper presents automatic tumor detection and classification approaches for brain magnetic resonance images (MRI). These approaches are based on hybrid-optimized classification techniques and classify brain MRI to healthy, benign or malignant. The proposed system implements three-optimization techniques combined with Artificial Neural Network (ANN). Multi-Verse Optimizer (MVO), Moth-Flame Optimizer (MFO) and Salp Swarm Algorithm (SSA) are used and compared to examine how these techniques could be successfully employed to enhance the classification accuracy via selecting the optimal parameters of ANN. The proposed techniques are applied to the Harvard database and BRATS challenge dataset to evaluate the performance via Receiver Operation Characteristics (ROC) analysis. The approaches are tested against geometric transformations such as scaling, rotation and warping to show how much the proposed system resists these transformations. Experimentally, the proposed algorithms achieve the highest classification accuracy as compared to the other published ones. Also, the MVO-ANN algorithm outperforms the other proposed algorithms.
C1 [Elkorany, Ahmed S.] Menoufia Univ, Dept Elect & Elect Comm Engn, Fac Elect Engn, Menoufia 32952, Egypt.
   [Elkorany, Ahmed S.] Minist Higher Educ & Sci Res, High Inst Elect Engn, Belbeis, Elsharkia, Egypt.
   [Elsharkawy, Zeinab F.] Atom Energy Author, Nucl Res Ctr, Engn Dept, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University; Ministry of Higher
   Education & Scientific Research (MHESR); Egyptian Knowledge Bank (EKB);
   Egyptian Atomic Energy Authority (EAEA)
RP Elsharkawy, ZF (corresponding author), Atom Energy Author, Nucl Res Ctr, Engn Dept, Cairo, Egypt.
EM zeinab_elsharkawy@yahoo.com
RI Elkorany, Ahmed S./HNI-8465-2023; KHALIFA, AHMED khalifa/HKF-2246-2023;
   Elkorany, Ahmed S./AFS-0613-2022
OI Elkorany, Ahmed S./0000-0003-3400-2971; KHALIFA, AHMED
   khalifa/0000-0002-2918-7572; Elkorany, Ahmed S./0000-0003-3400-2971;
   Elsharkawy, Zeinab/0000-0002-6167-8435
CR Abd El Aziz M, 2017, EXPERT SYST APPL, V83, P242, DOI 10.1016/j.eswa.2017.04.023
   Abd-Ellah MK, 2016, INT C MICROELECTRON, P73, DOI 10.1109/ICM.2016.7847911
   Abdullah HN, 2015, 2015 8TH INTERNATIONAL CONFERENCE ON INTELLIGENT NETWORKS AND INTELLIGENT SYSTEMS (ICINIS), P21, DOI 10.1109/ICINIS.2015.29
   Ahmed HM, 2018, APPL OPTICS, V57, pB25, DOI 10.1364/AO.57.000B25
   Al-Madi N, 2019, INT J MACH LEARN CYB, V10, P3445, DOI 10.1007/s13042-019-00931-8
   Amin J, 2020, PATTERN RECOGN LETT, V139, P118, DOI 10.1016/j.patrec.2017.10.036
   Amin J, 2018, FUTURE GENER COMP SY, V87, P290, DOI 10.1016/j.future.2018.04.065
   Anitha R, 2017, INT J IMAG SYST TECH, V27, P354, DOI 10.1002/ima.22238
   [Anonymous], 2010, Leonardo J Sci, DOI DOI 10.4018/JSSCI.2011040102
   [Anonymous], 2017, INT C COMP INT DAT S, DOI DOI 10.1109/ICCIDS.2017.8272635
   Arunkumar N, 2019, SOFT COMPUT, V23, P9083, DOI 10.1007/s00500-018-3618-7
   Ben George E, 2015, IEEE GCC CONF EXHIB
   Benson CC, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P187, DOI 10.1109/ICACCI.2016.7732045
   Bhakat S, 2019, ADV INTEL SYST COMPU, V851, P85
   Bhuvaneswari KS, 2017, J EXP THEOR ARTIF IN, V29, P663, DOI 10.1080/0952813X.2016.1212106
   Chaplot S, 2006, BIOMED SIGNAL PROCES, V1, P86, DOI 10.1016/j.bspc.2006.05.002
   Devkota B, 2018, PROCEDIA COMPUT SCI, V125, P115, DOI 10.1016/j.procs.2017.12.017
   Dong H, 2017, COMM COM INF SC, V723, P506, DOI DOI 10.1007/978-3-319-60964-5_44
   El-Dahshan ESA, 2010, DIGIT SIGNAL PROCESS, V20, P433, DOI 10.1016/j.dsp.2009.07.002
   Fink JR, 2015, J NUCL MED, V56, P1554, DOI 10.2967/jnumed.113.131516
   Gudigar A, 2019, FUTURE GENER COMP SY, V90, P359, DOI 10.1016/j.future.2018.08.008
   He X, 2015, IEEE INT WORK SIGN P, P685, DOI 10.1109/SPAWC.2015.7227125
   Kalpana R, 2020, MICROPROCESS MICROSY, V72, DOI 10.1016/j.micpro.2019.102903
   Karthikeyan K, 2017, ENRGY PROCED, V117, P583, DOI 10.1016/j.egypro.2017.05.153
   Kaur T, 2019, MULTIMED TOOLS APPL, V78, P21853, DOI 10.1007/s11042-019-7498-3
   Liang DZ, 2015, International Conference on Mechanics, Building Material and Civil Engineering (MBMCE 2015), P983
   med.harvard.edu/, ABOUT US
   microdicom, MICRODICOM
   Ming-Chi Wu, 2016, 2016 2nd International Conference on Information Management (ICIM), P47, DOI 10.1109/INFOMAN.2016.7477532
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Mirjalili S, 2015, KNOWL-BASED SYST, V89, P228, DOI 10.1016/j.knosys.2015.07.006
   Mirjalili S, 2016, NEURAL COMPUT APPL, V27, P495, DOI 10.1007/s00521-015-1870-7
   Mishra S, 2019, EVOL INTELL, V12, P647, DOI 10.1007/s12065-019-00266-x
   Nayak DR, 2018, NEUROCOMPUTING, V282, P232, DOI 10.1016/j.neucom.2017.12.030
   Nema S, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101641
   Patil DO, 2019, ARAB J SCI ENG, V44, P9143, DOI 10.1007/s13369-019-03989-2
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Preetha R, 2014, 2014 WORLD CONGRESS ON COMPUTING AND COMMUNICATION TECHNOLOGIES (WCCCT 2014), P30, DOI 10.1109/WCCCT.2014.26
   Preethi G, 2014, 2014 INTERNATIONAL CONFERENCE ON GREEN COMPUTING COMMUNICATION AND ELECTRICAL ENGINEERING (ICGCCEE)
   Rufus NHA, 2018, INT J IMAG SYST TECH, V28, P77, DOI 10.1002/ima.22258
   Sasikanth S, 2018, INT J IMAG SYST TECH, V28, P64, DOI 10.1002/ima.22257
   Sayed GI, 2018, APPL INTELL, V48, P3462, DOI 10.1007/s10489-018-1158-6
   Selvapandian A, 2018, COMPUT METH PROG BIO, V166, P33, DOI 10.1016/j.cmpb.2018.09.006
   Shastri AA, 2018, EXPERT SYST APPL, V99, P71, DOI 10.1016/j.eswa.2018.01.024
   smir.ch/BRATS, ABOUT US
   Ural B, 2017, P 6 MICCAI BRATS CHA, P284
   Virupakshappa, 2020, MULTIMED TOOLS APPL, V79, P3571, DOI 10.1007/s11042-018-6176-1
   Wang Y, 2019, COMPUT MED IMAG GRAP, V75, P56, DOI 10.1016/j.compmedimag.2019.04.001
   Yadav G, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2392, DOI 10.1109/ICACCI.2014.6968381
   Yang TJ, 2019, BIOCYBERN BIOMED ENG, V39, P613, DOI 10.1016/j.bbe.2019.06.003
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22589, DOI 10.1007/s11042-017-4703-0
   Zhang YD, 2013, SCI WORLD J, DOI 10.1155/2013/130134
NR 52
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27791
EP 27814
DI 10.1007/s11042-020-09306-6
EA JUL 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000553718200005
DA 2024-07-18
ER

PT J
AU Huang, YF
   Hsieh, YS
AF Huang, Yin-Fu
   Hsieh, Yun-Shin
TI Image retrieval based on AND/OR-construction models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data mining; Image retrieval; Locality sensitive hashing; Kmeans; Deep
   learning
ID SELECTION; CODES
AB With the rapid development of the Internet, finding desired images from numerous images has become an important research topic. In this paper, we propose an image retrieval system facilitating retrieval time and accuracy. Since the performance of image retrieval is deeply influenced by image features and retrieval methods. Five different types of features and five different methods are used to find the best combination for an image retrieval system. First, we segment out the main object in an image and then extract its features. Next, relevant features are selected from the original feature set for facilitating image retrieval, using the SAHS algorithm. Then, five methods based on AND/OR-construction are proposed to build the image retrieval model, using the relevant features. Finally, the experimental results not only show that our methods are more effective than the other state-of-the-art methods but also present some observations never explored by the previous research.
C1 [Huang, Yin-Fu; Hsieh, Yun-Shin] Natl Yunlin Univ Sci & Technol, Dept Comp Sci & Informat Engn, 123 Univ Rd,Sect 3, Touliu 640, Yunlin, Taiwan.
C3 National Yunlin University Science & Technology
RP Huang, YF (corresponding author), Natl Yunlin Univ Sci & Technol, Dept Comp Sci & Informat Engn, 123 Univ Rd,Sect 3, Touliu 640, Yunlin, Taiwan.
EM huangyf@yuntech.edu.tw; s5351413@gmail.com
OI Huang, Yin-Fu/0000-0001-6665-0135
CR [Anonymous], NIPS
   Bober M, 2001, IEEE T CIRC SYST VID, V11, P716, DOI 10.1109/76.927426
   Chang SF, 2001, IEEE T CIRC SYST VID, V11, P688, DOI 10.1109/76.927421
   Chaudhari R., 2012, International Journal of Advanced Research in Electrical, Electronics and Instrumentation Engineering, V1, P386
   Choudhary R, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2404, DOI 10.1109/ICACCI.2014.6968394
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   Geem ZW, 2001, SIMULATION, V76, P60, DOI 10.1177/003754970107600201
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Guiasu Silviu., 1977, Information theory with new applications
   Hall MA, 1998, AUST COMP S, V20, P181
   Huang YF, 2014, LECT NOTES ELECTR EN, V308, P159, DOI 10.1007/978-3-642-54900-7_23
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Khosla G, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P12
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466
   Kulis B, 2009, IEEE T PATTERN ANAL, V31, P2143, DOI 10.1109/TPAMI.2009.151
   Lankton S, 2009, SPARSE FIELD METHODS, P1
   Lankton S, 2008, IEEE T IMAGE PROCESS, V17, P2029, DOI 10.1109/TIP.2008.2004611
   Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035
   Li ZC, 2015, IEEE T IMAGE PROCESS, V24, P5343, DOI 10.1109/TIP.2015.2479560
   Lin GS, 2014, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2014.253
   Liu W, 2011, HASH GRAPHS P 28 INT
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Noh H, 2017, IEEE I CONF COMP VIS, P3476, DOI 10.1109/ICCV.2017.374
   Norouzi M.E., 2011, ICML
   Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566
   Shen FM, 2016, IEEE T IMAGE PROCESS, V25, P5610, DOI 10.1109/TIP.2016.2612883
   Shen FM, 2015, IEEE I CONF COMP VIS, P4148, DOI 10.1109/ICCV.2015.472
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Shen FM, 2013, PROC CVPR IEEE, P1562, DOI 10.1109/CVPR.2013.205
   Srivastava P, 2014, INT CONF CONTR AUTO, P159, DOI 10.1109/ICCAIS.2014.7020550
   Tang JH, 2018, IEEE T NEUR NET LEAR, V29, P6154, DOI 10.1109/TNNLS.2018.2816743
   Tzelepi M, 2018, NEUROCOMPUTING, V275, P2467, DOI 10.1016/j.neucom.2017.11.022
   Wang J, 2013, IEEE I CONF COMP VIS, P3032, DOI 10.1109/ICCV.2013.377
   Wei XS, 2017, IEEE T IMAGE PROCESS, V26, P2868, DOI 10.1109/TIP.2017.2688133
   Weiss Y., 2008, NIPS, V1, P4
   XIA Y, 2015, PROC CVPR IEEE, P3332
   Yao CW, 2013, NEUROCOMPUTING, V101, P52, DOI 10.1016/j.neucom.2012.06.035
   Zhan S, 2016, NEUROCOMPUTING, V187, P19, DOI 10.1016/j.neucom.2015.07.130
   Zhang J, 2019, IEEE T CIRC SYST VID, V29, P212, DOI 10.1109/TCSVT.2017.2771332
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
NR 44
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27293
EP 27320
DI 10.1007/s11042-020-09274-x
EA JUL 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000552190000007
DA 2024-07-18
ER

PT J
AU Khashan, OA
   AlShaikh, M
AF Khashan, Osama A.
   AlShaikh, Muath
TI Edge-based lightweight selective encryption scheme for digital medical
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Selective encryption; Medical image security; Edge detection; One-time
   pad; Chaotic map
ID CHAOTIC MAPS; TRANSFORM; EFFICIENT
AB Securing digital medical images is increasingly becoming a major concern due to the rapid growth of the amount of medical images transferred over a network and stored on the web servers. However, the enormous size of multimedia and the huge volume of exchanging medical images have motivated the development of low computational complexity methods. This paper presents a lightweight selective encryption scheme to encrypt the edge maps of medical images. The edge map is firstly extracted by an edge detection method. Then, a chaotic map is used to generate a large key space. We propose a one-time pad algorithm to respectively encrypt the significant detected image blocks. The experimental results have proven that the proposed encryption scheme provides an acceptable percentage of encrypted image data. It can also effectively perform image encryption and decryption in a lightweight manner, which makes the scheme a good candidate for real time applications. Moreover, the security analysis demonstrates that our scheme has a robust resistance against various security attacks.
C1 [Khashan, Osama A.; AlShaikh, Muath] Saudi Elect Univ, Coll Comp & Informat, Riyadh 11673, Saudi Arabia.
C3 Saudi Electronic University
RP Khashan, OA (corresponding author), Saudi Elect Univ, Coll Comp & Informat, Riyadh 11673, Saudi Arabia.
EM o.khashan@seu.edu.sa; m.alshaikh@seu.edu.sa
RI Khashan, Osama A./AAB-7303-2021
OI Khashan, Osama A./0000-0003-1965-1869; AlShaikh,
   Muath/0000-0001-5550-7659
CR Abdmouleh MK, 2017, I C COMP GRAPH IM VI, P79, DOI 10.1109/CGiV.2017.10
   Akkasaligar PT, 2020, INF SECUR J, V29, P91, DOI 10.1080/19393555.2020.1718248
   AlShaikh M, 2017, MULTIMED TOOLS APPL, V76, P8937, DOI 10.1007/s11042-016-3499-7
   [Anonymous], MATH PROBL ENG
   [Anonymous], 2011, INT GEOPHYS SERIES
   [Anonymous], 1970, PICTURE PROCESSING P
   Bhatnagar G, 2012, DIGIT SIGNAL PROCESS, V22, P648, DOI 10.1016/j.dsp.2012.02.005
   Cao WJ, 2017, SIGNAL PROCESS, V132, P96, DOI 10.1016/j.sigpro.2016.10.003
   Chabaud F., 1995, LECT NOTES COMPUT SC, V950, P356
   Chen L, 2015, COMPUT BIOL MED, V65, P69, DOI 10.1016/j.compbiomed.2015.07.024
   Darwish SM, 2019, MULTIMED TOOLS APPL, V78, P19229, DOI 10.1007/s11042-019-7256-6
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Jain B, 2003, PHYS REV LETT, V91, DOI 10.1103/PhysRevLett.91.141302
   Juels A, 2005, LECT NOTES COMPUT SC, V3621, P293
   Kar M, 2020, IETE TECH REV, V37, P12, DOI 10.1080/02564602.2018.1544855
   Khan JS, 2019, MULTIDIM SYST SIGN P, V30, P943, DOI 10.1007/s11045-018-0589-x
   Khan MA, 2017, J MOD OPTIC, V64, P531, DOI 10.1080/09500340.2016.1246680
   Khashan O.A., 2018, Int. J. Netw. Secur., V20, P1053
   Khashan OA, 2015, FRONT INFORM TECH EL, V16, P28, DOI 10.1631/FITEE.1400133
   Khashan OA, 2014, J ZHEJIANG U-SCI C, V15, P435, DOI 10.1631/jzus.C1300262
   Khashan OA, 2013, PROC TECH, V11, P288, DOI 10.1016/j.protcy.2013.12.193
   Krishnamoorthi R, 2017, MULTIMED TOOLS APPL, V76, P1217, DOI 10.1007/s11042-015-3027-1
   Kulsoom A, 2016, MULTIMED TOOLS APPL, V75, P1, DOI 10.1007/s11042-014-2221-x
   Laouamer Lamri, 2015, Journal of Innovation in Digital Ecosystems, V2, P1, DOI 10.1016/j.jides.2015.10.001
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Li CQ, 2018, IEEE ACCESS, V6, P75834, DOI 10.1109/ACCESS.2018.2883690
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu Y, 2019, IEEE T INF FORENSICS, P1
   Mou J, 2021, MOBILE NETW APPL, V26, P1849, DOI 10.1007/s11036-019-01293-9
   Moumen A, 2015, NONLINEAR DYNAM, V82, P1475, DOI 10.1007/s11071-015-2253-4
   Noura M, 2018, MULTIMED TOOLS APPL, V77, P31397, DOI 10.1007/s11042-018-6051-0
   Pavithra V, 2020, SMART MED DATA SENSI, P76
   Prabhu P, 2019, L N COMPUT VIS BIOME, V31, P103, DOI 10.1007/978-3-030-04061-1_10
   Rehman AU, 2015, MULTIMED TOOLS APPL, V74, P4655, DOI 10.1007/s11042-013-1828-7
   Riad K, 2019, IEEE ACCESS, V7, P86384, DOI 10.1109/ACCESS.2019.2926354
   Som S, 2019, MULTIMED TOOLS APPL, V78, P10373, DOI 10.1007/s11042-018-6539-7
   Steinebach M, 2001, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P49, DOI 10.1109/ITCC.2001.918764
   Tang Z., 2019, SHOCK VIB, V2019, P1
   Tong XJ, 2015, IMAGING SCI J, V63, P263, DOI 10.1179/1743131X15Y.0000000006
   Ullah I, 2013, 2013 2ND NATIONAL CONFERENCE ON INFORMATION ASSURANCE (NCIA), P125, DOI 10.1109/NCIA.2013.6725336
   Wang L.-T., 1987, 24th ACM/IEEE Design Automation Conference Proceedings 1987, P2, DOI 10.1145/37888.37889
   Wen WY, 2015, OPT COMMUN, V341, P131, DOI 10.1016/j.optcom.2014.12.026
   WOLF A, 1985, PHYSICA D, V16, P285, DOI 10.1016/0167-2789(85)90011-9
   Wu LB, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/2595273
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Zhang YS, 2013, OPT LASER TECHNOL, V54, P1, DOI 10.1016/j.optlastec.2013.04.029
   Zhou YC, 2009, IEEE ENG MED BIO, P3707, DOI 10.1109/IEMBS.2009.5334799
NR 49
TC 23
Z9 23
U1 4
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26369
EP 26388
DI 10.1007/s11042-020-09264-z
EA JUL 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000548495600005
DA 2024-07-18
ER

PT J
AU Pereira, J
   Monteiro, J
   Silva, J
   Estima, J
   Martins, B
AF Pereira, Jorge
   Monteiro, Joao
   Silva, Joel
   Estima, Jacinto
   Martins, Bruno
TI Assessing flood severity from crowdsourced social media photos with deep
   neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Flood detection and severity estimation; Crowdsourced images; Image
   classification; Deep learning; Convolutional neural networks
AB The use of social media data in disaster and crisis management is increasing rapidly. Particularly in connection to flooding events, geo-referenced images shared by citizens can provide situational awareness to emergency responders, as well as assistance to financial loss assessment, giving information that would otherwise be very hard to collect through conventional sensors or remote sensing. Moreover, recent advances in computer vision and deep learning can perhaps support the automated analysis of these data. In this paper, focusing on ground-level images taken by humans during flooding events, we evaluate the use of deep convolutional neural networks for (a) discriminating images showing direct evidence of a flood, and (b) estimating the severity of the flooding event. Considering distinct datasets (i.e., the European Flood 2013 dataset, and data from different editions of the MediaEval Multimedia Satellite Task), we specifically evaluated models based on the DenseNet and EfficientNet neural network architectures, concluding that these classification models can achieve a very high accuracy on this task, thus having a clear potential to complement other sources of information (e.g., satellite imagery) related to flooding events.
C1 [Pereira, Jorge; Martins, Bruno] Univ Lisbon, IST INESC ID, Lisbon, Portugal.
   [Monteiro, Joao] Univ Lisbon, IST INESC ID, Porto Salvo, Portugal.
   [Silva, Joel; Estima, Jacinto] INESC ID, Lisbon, Portugal.
   [Estima, Jacinto] Univ Europeia, Lisbon, Portugal.
C3 Universidade de Lisboa; INESC-ID; Universidade de Lisboa; INESC-ID;
   INESC-ID; Universidade de Lisboa; Universidade Europeia
RP Pereira, J (corresponding author), Univ Lisbon, IST INESC ID, Lisbon, Portugal.
EM jorge.m.s.pereira@tecnico.ulisboa.pt;
   joao.miguel.monteiro@tecnico.ulisboa.pt; dinis.joel@gmail.com;
   jacinto.estima@universidadeeuropeia.pt;
   bruno.g.martins@tecnico.ulisboa.pt
RI Estima, Jacinto/J-5367-2013
OI Estima, Jacinto/0000-0001-8837-4637; da Silva Pereira, Jorge
   Miguel/0000-0002-3056-681X
FU Fundacao para a Ciencia e Tecnologia (FCT) [PTDC/EEI-SCR/1743/2014,
   PTDC/CTA-OHR/29360/2017, PTDC/CCI-CIF/32607/2017]; INESC-ID multi-annual
   funding from the PIDDAC programme [UIDB/50021/2020]; NVIDIA Corporation;
   Fundação para a Ciência e a Tecnologia [PTDC/CTA-OHR/29360/2017,
   PTDC/EEI-SCR/1743/2014, PTDC/CCI-CIF/32607/2017] Funding Source: FCT
FX This research was supported through Fundacao para a Ciencia e Tecnologia
   (FCT), namely through the project grants PTDC/EEI-SCR/1743/2014
   (Saturn), PTDC/CTA-OHR/29360/2017 (RiverCure), and
   PTDC/CCI-CIF/32607/2017 (MIMU), as well as through the INESC-ID
   multi-annual funding from the PIDDAC programme with reference
   UIDB/50021/2020. We also gratefully acknowledge the support of NVIDIA
   Corporation, with the donation of the two Titan Xp GPUs used in our
   experiments.
CR Agarap A.F., 2018, Deep Learning using Rectified Linear Units (ReLU)
   Ahmad K, 2017, P MEDIAEVAL WORKSH
   AHMAD S, 2017, MED WORKSH DUBL IR
   Avgerinakis K, 2017, P MEDIAEVAL WORKSH
   Bischke B, 2019, P MEDIAEVAL WORKSH
   Bischke B, 2017, P MEDIAEVAL WORKSH
   Bischke B, 2018, P MEDIAEVAL WORKSH
   Chandru R, 2017, IEEE INT C INTELL TR
   Chaudhary P, 2019, ISPRS ANN PHOTOGRAMM, V4, DOI DOI 10.5194/ISPRS-ANNALS-IV-2-W5-5-2019
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Cian F, 2018, REMOTE SENSING ENV, V209
   DAO MS, 2017, P MED WORKSH DUBL IR
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fu X, 2017, P MEDIAEVAL WORKSH
   Geetha M, 2017, P INT C COMM SIGN PR
   Giannakeris P, 2018, PROCEEDINGS 2018 IEEE 13TH IMAGE, VIDEO, AND MULTIDIMENSIONAL SIGNAL PROCESSING WORKSHOP (IVMSP)
   Gong J, 2018, CEHUI XUEBAO, V47
   Guan Q., 2018, ARXIV PREPRINT ARXIV
   HANIF M, 2017, P MED WORKSH DUBL IR
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Katharopoulos A, 2019, ARXIV190503711
   Khan S., 2018, SYNTHESIS LECT COMPU, V8, P1, DOI DOI 10.2200/S00822ED1V01Y201712COV015
   Kingma D. P., 2014, arXiv
   Kornblith S, 2019, PROC CVPR IEEE, P2656, DOI 10.1109/CVPR.2019.00277
   Li L, 2015, ISPRS J PHOTOGRAMMET, V101
   Li Y, 2019, ISPRS J PHOTOGRAMM, V152, P178, DOI 10.1016/j.isprsjprs.2019.04.014
   Lopez-Fuentes L, 2017, P MEDIAEVAL WORKSH
   Lopez-Fuentes L, 2017, IEEE INT CONF FUZZY
   Lorini V., 2019, ARXIV190410876
   Malinowski R, 2015, REMOTE SENSING, V7
   Mouratidis A, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8030108
   Narayanan R, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND NETWORKING TECHNOLOGIES (ICCCNT
   Nogueira K, 2018, IEEE GEOSCIENCE REMO, V15
   Nogueira K., 2017, MediaEval
   Pereira Jorge, 2019, DENSE U NET MO UNPUB
   Petrasova A., 2017, Open Geospatial Data, Software and Standards, V2, DOI [DOI 10.1186/S40965-017-0019-2, 10.1186/s40965-017-0019-2]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Reuter HI, 2007, INT J GEOGR INF SCI, V21, P983, DOI 10.1080/13658810601169899
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   See L, 2019, FRONT EARTH SC-SWITZ, V7, DOI 10.3389/feart.2019.00044
   Shen X, 2019, REMOTE SENSING, V11
   Smith LN, 2017, IEEE WINT CONF APPL, P464, DOI 10.1109/WACV.2017.58
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tadono T., 2014, ISPRS ANN PHOTOGRAMM, V2, P71, DOI DOI 10.5194/ISPRSANNALS-II-4-71-2014
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tkachenko N, 2017, P MEDIAEVAL WORKSH
   Witherow MA, 2018, COMPUTER METHODBIO
   Wu JH, 2015, SENSORS, V15
   Xie J, 2018, ARXIV181201187
   Zhang L, 2018, ARXIV181109885
   Zhang You, 2014, Aquatic Biology, V23, P15
   Zhao Z, 2017, P MEDIAEVAL WORKSH
NR 55
TC 20
Z9 23
U1 1
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26197
EP 26223
DI 10.1007/s11042-020-09196-8
EA JUL 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000547805500003
DA 2024-07-18
ER

PT J
AU Gomaa, A
   Abdelwahab, MM
   Abo-Zahhad, M
AF Gomaa, Ahmed
   Abdelwahab, Moataz M.
   Abo-Zahhad, Mohammed
TI Efficient vehicle detection and tracking strategy in aerial videos by
   employing morphological operations and feature points motion analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Morphological operations; Aerial surveillance; Remote sensing; KLT
   tracker; K-means clustering; Vehicle detection and tracking
ID PERFORMANCE EVALUATION; MULTIPLE
AB Real-time automatic detection and tracking of moving vehicles in videos acquired by airborne cameras is a challenging problem due to vehicle occlusion, camera movement, and high computational cost. This paper presents an efficient and robust real-time approach for automatic vehicle detection and tracking in aerial videos that employ both detections and tracking features to enhance the final decision. The use of Top-hat and Bottom-hat transformation aided by the morphological operation in the detection phase has been adopted. After detection, background regions are eliminated by motion feature points' analysis of the obtained object regions using a combined technique between KLT tracker and K-means clustering. Obtained object features are clustered into separate objects based on their motion characteristic. Finally, an efficient connecting algorithm is introduced to assign the vehicle labels with their corresponding cluster trajectories. The proposed method was tested on videos taken in different scenarios. The experimental results showed that the recall, precision, and tracking accuracy of the proposed method were about 95.1 %, 97.5%, and 95.2%, respectively. The method also achieves a fast processing speed. Thus, the proposed approach has superior overall performance compared to newly published approaches.
C1 [Gomaa, Ahmed] Natl Res Inst Astron & Geophys NRIAG, Helwan 11731, Egypt.
   [Gomaa, Ahmed; Abdelwahab, Moataz M.; Abo-Zahhad, Mohammed] Egypt Japan Univ Sci & Technol, Elect & Commun Engn Dept, Alexandria 21934, Egypt.
   [Gomaa, Ahmed] Kyushu Univ, Ctr Japan Egypt Cooperat Sci & Technol, Nishi Ku, Fukuoka 8190395, Japan.
   [Abo-Zahhad, Mohammed] Assiut Univ, Elect & Elect Engn Dept, Fac Engn, Assiut 71511, Egypt.
C3 Egyptian Knowledge Bank (EKB); National Research Institute of Astronomy
   & Geophysics - NRIAG; Egyptian Knowledge Bank (EKB); Egypt-Japan
   University of Science & Technology; Kyushu University; Egyptian
   Knowledge Bank (EKB); Assiut University
RP Gomaa, A (corresponding author), Natl Res Inst Astron & Geophys NRIAG, Helwan 11731, Egypt.; Gomaa, A (corresponding author), Egypt Japan Univ Sci & Technol, Elect & Commun Engn Dept, Alexandria 21934, Egypt.; Gomaa, A (corresponding author), Kyushu Univ, Ctr Japan Egypt Cooperat Sci & Technol, Nishi Ku, Fukuoka 8190395, Japan.
EM ahmed.gomaa@ejust.edu.eg; moataz.abdelwahab@ejust.edu.eg;
   mohammed.zahhad@ejust.edu.eg
RI Gomaa, Ahmed/W-9060-2019
OI Gomaa, Ahmed/0000-0003-0130-9088
FU Egyptian Ministry of Higher Education (MoHE), Cairo, Egypt; Egypt Japan
   University of Science and Technology (E-JUST), Alexandria, Egypt
FX This work was supported in part by the Egyptian Ministry of Higher
   Education (MoHE), Cairo, Egypt, and in part by the Egypt Japan
   University of Science and Technology (E-JUST), Alexandria, Egypt.
CR Abdelwahab MA, 2015, IEEE INT SYM MULTIM, P65, DOI 10.1109/ISM.2015.77
   Al-Kaff A, 2015, LECT NOTES COMPUT SC, V9520, P739, DOI 10.1007/978-3-319-27340-2_91
   Alkanat T, 2015, INT JOINT C COMP VIS, P240
   [Anonymous], P C INF SCI SYST
   Barth A, 2009, IEEE T INTELL TRANSP, V10, P560, DOI 10.1109/TITS.2009.2029643
   Bouguet, 2001, INTEL CORP, V5, P4, DOI DOI 10.1109/HPDC.2004.1323531
   Cao XB, 2018, IEEE T CYBERNETICS, V48, P90, DOI 10.1109/TCYB.2016.2625320
   Cao XB, 2013, NEUROCOMPUTING, V99, P38, DOI 10.1016/j.neucom.2012.05.026
   Collins R., 2005, PROC IEEE INT WORKSH, V2, P35
   Gao T, 2012, MULTIMED TOOLS APPL, V58, P1, DOI 10.1007/s11042-010-0676-y
   Gao Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1879, DOI 10.1145/3343031.3350861
   Gao ZF, 2020, IEEE INTERNET THINGS, V7, P4092, DOI 10.1109/JIOT.2019.2963701
   Gomaa A, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19204588
   Gomaa A, 2018, MIDWEST SYMP CIRCUIT, P222, DOI 10.1109/MWSCAS.2018.8624022
   Hess R, 2009, PROC CVPR IEEE, P240, DOI 10.1109/CVPRW.2009.5206801
   Jiang XL, 2016, INTEG COMMUN NAVIG
   Kalantar B, 2017, IEEE T GEOSCI REMOTE, V55, P5198, DOI 10.1109/TGRS.2017.2703621
   Kanistras K., 2015, Handbook of Unmanned Aerial Vehicles, P2643
   Kasturi R, 2009, IEEE T PATTERN ANAL, V31, P319, DOI 10.1109/TPAMI.2008.57
   Ke RM, 2017, IEEE T INTELL TRANSP, V18, P890, DOI 10.1109/TITS.2016.2595526
   Kent P, 2012, PROC SPIE, V8546, DOI 10.1117/12.965300
   Niknejad HT, 2012, IEEE T INTELL TRANSP, V13, P748, DOI 10.1109/TITS.2012.2187894
   Noh S, 2016, IEEE T INTELL TRANSP, V17, P323, DOI 10.1109/TITS.2015.2466652
   Rad R, 2005, PATTERN RECOGN LETT, V26, P1597, DOI 10.1016/j.patrec.2005.01.010
   REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177
   Rosenbaum D, 2010, INT ARCH PHOTOGRAMM, V38, P469
   Su A, 2015, J APPL REMOTE SENS, V9, DOI 10.1117/1.JRS.9.096063
   Tang Y, 2017, MULTIMED TOOLS APPL, V76, P5817, DOI 10.1007/s11042-015-2520-x
   Teutsch Michael, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P26, DOI 10.1109/CVPRW.2015.7301396
   Teutsch M., 2012, 2012 15th International Conference on Information Fusion (FUSION 2012), P1988
   Teutsch M, 2017, OPT ENG, V56, DOI 10.1117/1.OE.56.8.083102
   Nguyen VD, 2019, IEEE T INTELL TRANSP, V20, P3634, DOI 10.1109/TITS.2018.2877200
   Wan EA, 2002, KALMAN FILTERING NEU, DOI [10.1002/0471221546.ch7, DOI 10.1002/0471221546, 10.1002/0471221546]
   Yang S, 2014, MULTIMED TOOLS APPL, V72, P1561, DOI 10.1007/s11042-013-1453-5
   Yao YY, 2020, MULTIMED TOOLS APPL, V79, P9645, DOI 10.1007/s11042-017-4820-9
   Yu XR, 2015, OPTIK, V126, P2485, DOI 10.1016/j.ijleo.2015.06.024
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zheng ZZ, 2013, IEEE J-STARS, V6, P2338, DOI 10.1109/JSTARS.2013.2266131
NR 38
TC 30
Z9 30
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26023
EP 26043
DI 10.1007/s11042-020-09242-5
EA JUL 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000546865300001
DA 2024-07-18
ER

PT J
AU Shen, JJ
   Lee, CF
   Hsu, FW
   Agrawal, S
AF Shen, Jau-Ji
   Lee, Chin-Feng
   Hsu, Fang-Wei
   Agrawal, Somya
TI A self-embedding fragile image authentication based on singular value
   decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image authentication; Fragile watermarking; Singular value
   decomposition; Self-embedding authentication; Steganography
ID WATERMARKING SCHEME; TAMPER DETECTION; ROBUST; SVD; LOCALIZATION;
   ALGORITHM; SECURE
AB Nowadays, image authentication techniques are widely applied to digital multimedia to address their fraudulent and illegal use. Digital multimedia plays a vital role in various real time applications and therefore, there is a need for the development of more powerful and robust algorithms in order to strengthen their security. In this paper, we proposed a self-embedding fragile image authentication method based on Singular Value Decomposition (SVD). First the original image was divided into non-overlapping blocks and thereafter, each block was further divided into two parts: upper part and bottom part. After block separation, SVD was performed to generate the authentication information for both upper and bottom parts of each block, which were concatenated to generate the authentication code. We performed a series of attacking experiments on the original image to test the robustness of the proposed method. The recovered imperceptibility of the proposed scheme was measured using False Positive Rate (FPR), False Negative Rate (FNR), Peak Signal to Noise Ratio (PSNR), and Structural Similarity (SSIM). It was found that our method not only surpassed previous methods in PSNR but FNR and FPR as well. The experimental results showed an excellent visual imperceptibility against a variety of attacks. The proposed method detected image tampering precisely, and even after massive tampering, it was able to recover the tampered image with high quality.
C1 [Shen, Jau-Ji; Hsu, Fang-Wei] Natl Chung Hsing Univ, Dept Management Informat Syst, Taichung, Taiwan.
   [Lee, Chin-Feng; Agrawal, Somya] Chaoyang Univ Technol, Dept Informat Management, Taichung, Taiwan.
C3 National Chung Hsing University; Chaoyang University of Technology
RP Lee, CF (corresponding author), Chaoyang Univ Technol, Dept Informat Management, Taichung, Taiwan.
EM jjshen@nchu.edu.tw; lcf@cyut.edu.tw; davidhsu1115@gmail.com;
   asomya@gm.cyut.edu.tw
FU Ministry of Science and Technology of the Republic of China [MOST
   106-2221-E-324-006 -MY2]
FX This research was partially supported by the Ministry of Science and
   Technology of the Republic of China under the Grant [MOST
   106-2221-E-324-006 -MY2].
CR Ababneh S, 2009, J VIS COMMUN IMAGE R, V20, P303, DOI 10.1016/j.jvcir.2009.03.010
   Ansari IA, 2016, INT J MACH LEARN CYB, V7, P1225, DOI 10.1007/s13042-015-0455-1
   Benrhouma O, 2015, NONLINEAR DYNAM, V79, P1817, DOI 10.1007/s11071-014-1777-3
   Bravo-Solorio S, 2011, SIGNAL PROCESS, V91, P728, DOI 10.1016/j.sigpro.2010.07.019
   Chamlawi R, 2010, COMPUT ELECTR ENG, V36, P578, DOI 10.1016/j.compeleceng.2009.12.003
   Chen F, 2017, MULTIMED TOOLS APPL, V76, P9681, DOI 10.1007/s11042-016-3574-0
   Chen F, 2014, MULTIMED TOOLS APPL, V72, P41, DOI 10.1007/s11042-012-1332-5
   Chen WC, 2009, EXPERT SYST APPL, V36, P1300, DOI 10.1016/j.eswa.2007.11.018
   Chen Y. H., 2015, INT J NETWORK SECURI, V17, P439
   Chin-Feng Lee, 2011, Journal of Multimedia, V6, P277, DOI 10.4304/jmm.6.3.277-284
   Dadkhah S, 2014, SIGNAL PROCESS-IMAGE, V29, P1197, DOI 10.1016/j.image.2014.09.001
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Dhole VS, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P752, DOI 10.1109/ICCUBEA.2015.150
   Di YF, 2016, KSII T INTERNET INF, V10, P5268, DOI 10.3837/tiis.2016.12.008
   El'arbi M, 2014, IET IMAGE PROCESS, V8, P619, DOI 10.1049/iet-ipr.2013.0646
   Hsu CS, 2016, MEASUREMENT, V88, P287, DOI 10.1016/j.measurement.2016.03.053
   Lee CF, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19102267
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Li CL, 2015, MULTIMED TOOLS APPL, V74, P10581, DOI 10.1007/s11042-014-2188-7
   Lo CC, 2014, SIGNAL PROCESS, V98, P174, DOI 10.1016/j.sigpro.2013.11.028
   Lou DC, 2000, IEEE T CONSUM ELECTR, V46, P31, DOI 10.1109/30.826378
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Qi XJ, 2015, J VIS COMMUN IMAGE R, V30, P312, DOI 10.1016/j.jvcir.2015.05.006
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Rey C, 2002, EURASIP J APPL SIG P, V2002, P613, DOI 10.1155/S1110865702204047
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Singh D, 2016, J VIS COMMUN IMAGE R, V38, P775, DOI 10.1016/j.jvcir.2016.04.023
   Tai WL, 2018, SIGNAL PROCESS-IMAGE, V65, P11, DOI 10.1016/j.image.2018.03.011
   Tiwari A, 2017, AEU-INT J ELECTRON C, V78, P114, DOI 10.1016/j.aeue.2017.05.027
   Tsai P, 2005, IMAGING SCI J, V53, P149, DOI 10.1179/136821905X50406
   Umamageswari A, 2014, J ENG RES-KUWAIT, V2, P87, DOI 10.7603/s40632-014-0015-y
   Wang CY, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8040548
   Wu WC, 2016, J VIS COMMUN IMAGE R, V38, P18, DOI 10.1016/j.jvcir.2016.02.005
   Xiang LY, 2018, CMC-COMPUT MATER CON, V55, P541, DOI 10.3970/cmc.2018.03510
   Yin ZX, 2016, COGN COMPUT, V8, P890, DOI 10.1007/s12559-016-9408-6
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang X, 2007, IEEE SIGNAL PROC LET, V14, P727, DOI 10.1109/LSP.2007.896436
NR 40
TC 4
Z9 4
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25969
EP 25988
DI 10.1007/s11042-020-09254-1
EA JUL 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000546532400004
DA 2024-07-18
ER

PT J
AU Wang, XH
   Pang, YJ
   Ma, XC
AF Wang, Xiaohong
   Pang, Yunjie
   Ma, Xiangcai
TI Real distorted images quality assessment based on multi-layer visual
   perception mechanism and high-level semantics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IQA; Real distorted; K-means; High-level semantics
ID NETWORKS
AB Most of the existing image quality assessment (IQA) methods are directed to artificially synthesized distorted images, in which the types and characteristics of distortion are different from those in the real world. In view of the fact that the existing non-reference IQA methods can not accurately evaluate the quality of the real distortion image, combined with the theoretical analysis of multi-layer visual perception mechanism, we propose a real image distortion IQA method based on image underlying features and high-level semantics. Considering non-linear hierarchical structure of human visual perception, firstly, k-means clustering algorithm is performed according to the underlying feature indexs of the image so that the used image database can be divided into several groups, which aims to improve the accuracy of predicted quality score. Secondly, the deep convolutional neural network (DCNN) is used to extract the first-grade high-level semantic features in each group. Then, second-grade high-level semantic features that can provide better representation of image features are obtained by performing multiple statistical functions on first-grade high-level semantics. Besides, we establish an effective high-capacity regressor with high-level semantics and subjective mean opinion scores (MOS) values of the human eyes. The experimental results show that the proposed model on the KonIQ-10 k image database can predict the quality score effectively and achieve a high consistency with the corresponding MOS value, which is helpful for the subsequent image enhancement.
C1 [Wang, Xiaohong; Pang, Yunjie] Univ Shanghai Sci & Technol, Shanghai 200093, Peoples R China.
   [Ma, Xiangcai] Shanghai Publishing & Printing Coll, Shanghai 200093, Peoples R China.
C3 University of Shanghai for Science & Technology
RP Wang, XH (corresponding author), Univ Shanghai Sci & Technol, Shanghai 200093, Peoples R China.
EM wang_keyan@163.com; pyj2223@163.com
FU Shanghai Education Development Foundation; Shanghai Municipal Education
   Commission
FX This work was supported by Shanghai Education Development Foundation and
   Shanghai Municipal Education Commission.
CR Bianco S, 2018, SIGNAL IMAGE VIDEO P, V12, P355, DOI 10.1007/s11760-017-1166-8
   Bosse S, 2016, IEEE IMAGE PROC, P3773, DOI 10.1109/ICIP.2016.7533065
   Cai WW, 2020, IEEE ACCESS, V8, P48451, DOI 10.1109/ACCESS.2020.2979348
   Dosovitskiy A, NIPS
   FAN D, 2017, IEEE ICC
   Fan D.-P., 2018, ENHANCED ALIGNMENT M
   Fan DP, 2019, IEEE INT C COMP VIS
   Gao F, 2017, NEUROCOMPUTING, V257, P104, DOI 10.1016/j.neucom.2017.01.054
   Ghadiyaram D, 2015, PROC SPIE, V9394, DOI 10.1117/12.2084807
   Hawkins J, 2006, FUTURE AI
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He N., 2017, J BEIJING I GRAPHIC, V25, P47
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kang L, 2014, PROC CVPR IEEE, P1733, DOI 10.1109/CVPR.2014.224
   Kim J, 2017, IEEE J-STSP, V11, P206, DOI 10.1109/JSTSP.2016.2639328
   Li DQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P378, DOI 10.1145/3123266.3123322
   Lin H., 2018, CORR
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   [刘玄玄 Liu Xuanxuan], 2015, [光学技术, Optical Technology], V41, P280
   [卢鹏 Lu Peng], 2018, [计算机应用研究, Application Research of Computers], V35, P3508
   Mansouri A, 2019, SIGNAL PROCESSING IM
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Siahaan E, 2016, IEEE INT SYM MULTIM, P307, DOI [10.1109/ISM.2016.0067, 10.1109/ISM.2016.54]
   Simonyan K, 2014, COMPUTER SCI A VERY
   Sun C, 2016, VISUAL COMMUNICATION
   Sun J, 2017, MINE WATER ENVIRON, V36, P310, DOI 10.1007/s10230-017-0428-6
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tang M, 2018, RES REAL IMAGE QUALI
   Varga D, 2018, IEEE INT CON MULTI
   Wang YX, 2016, LECT NOTES COMPUT SC, V9910, P616, DOI 10.1007/978-3-319-46466-4_37
   Yang L, 2017, RES NONREFERENCE QUA
   Yang L, 2016, IEEE INT C IM PROC
   Yo HF, 2020, IEEE T GEOSCI REMOTE, V58, P1281, DOI 10.1109/TGRS.2019.2945591
   Yu SD, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0176632
   Zhang Richard, 2018, CVPR 2018
NR 39
TC 4
Z9 4
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25905
EP 25920
DI 10.1007/s11042-020-09222-9
EA JUL 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000546532400003
DA 2024-07-18
ER

PT J
AU Avola, D
   Cinque, L
   Foresti, GL
   Pannone, D
AF Avola, Danilo
   Cinque, Luigi
   Foresti, Gian Luca
   Pannone, Daniele
TI Homography vs similarity transformation in aerial mosaicking: which is
   the best at different altitudes?
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unmanned Aerial Vehicles (UAVs); Aerial mosaicking; Image registration;
   Homography; Similarity transformation; Johnson's criteria
ID IMAGE; VEHICLE
AB Aerial image mosaicking of an area of interest is the process of combining multiple images, of an area with overlapping regions, into a single comprehensive view. In this process, image registration, i.e., the operation of geometric transformation to align and overlay two or more images of the same scene taken from different viewpoints, starting from their common parts, plays a key role in terms of artifacts reduction. In the current state-of-the-art, image registration of aerial images is usually performed through the use of the homography transformation. This occurs because these images are frequently acquired at high altitudes (more than 100 meters) and the homography has always provided excellent performance. The recent widespread of Unmanned Aerial Vehicles (UAVs) has enabled the development of several applications where mosaics are used as reference images for high precision tasks, including Detection, Recognition, and Identification (hereinafter DRI) of people and objects. These tasks need to acquire images at very low altitudes (below 50 meters), in which the homography tends to introduce artifacts during the registration process. Therefore, a different transformation able to limit how an image can be morphed, i.e., the similarity transformation, is necessary to perform the image registration, thus improving the overall accuracy of the obtained mosaics. In this paper, for the first time in literature, a comparison between the homography and similarity transformations is performed. In particular, the comparison is carried out by using three recently released public datasets, i.e., NPU Drone-Map, senseFly, and UAV Mosaicking and Change Detection (UMCD), containing challenging aerial video sequences acquired at high and low altitudes. The experimental tests have pointed out the direct relationship among best image transformation, UAV altitude, and spatial resolution, required to accomplish the DRI tasks reported above.
C1 [Avola, Danilo; Cinque, Luigi; Pannone, Daniele] Sapienza Univ, Dept Comp Sci, Via Salaria 113, I-00198 Rome, Italy.
   [Foresti, Gian Luca] Univ Udine, Dept Math Comp Sci & Phys, Via Sci 206, I-33100 Udine, Italy.
C3 Sapienza University Rome; University of Udine
RP Avola, D (corresponding author), Sapienza Univ, Dept Comp Sci, Via Salaria 113, I-00198 Rome, Italy.
EM avola@di.uniroma1.it; cinque@di.uniroma1.it; gianluca.foresti@uniud.it;
   pannone@di.uniroma1.it
RI Pannone, Daniele/ABD-2058-2021
OI PANNONE, DANIELE/0000-0001-6446-6473
CR Abraham R, 2013, INT C ADV COMPUT COM, P63, DOI 10.1109/ACCT.2013.47
   Abughalieh KM, 2019, MULTIMED TOOLS APPL, V78, P9149, DOI 10.1007/s11042-018-6508-1
   Ammour N., 2017, REMOTE SENSING, V9, P1
   [Anonymous], 2018, LOW LEVEL FEATURE DE
   Avola Danilo, 2019, Pattern Recognition Applications and Methods. 7th International Conference, ICPRAM 2018. Revised Selected Papers: Lecture Notes in Computer Science (LNCS 11351), P186, DOI 10.1007/978-3-030-05499-1_10
   Avola D., 2017, 2017 14th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS), P1
   Avola D, 2020, IEEE T SYST MAN CY-S, V50, P2139, DOI 10.1109/TSMC.2018.2804766
   Avola D, 2017, LECT NOTES COMPUT SC, V10484, P694, DOI 10.1007/978-3-319-68560-1_62
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bejiga MB, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9020100
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Bu SH, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4564, DOI 10.1109/IROS.2016.7759672
   Camargo Aldo, 2010, Proceedings 2010 IEEE Southwest Symposium on Image Analysis & Interpretation (SSIAI), P25, DOI 10.1109/SSIAI.2010.5483926
   Chen J, 2018, CHIN CONTR CONF, P4265, DOI 10.23919/ChiCC.2018.8483513
   Chen YN, 2017, INT J BIOMETEOROL, V61, P1055, DOI 10.1007/s00484-016-1285-x
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Dhana Lakshmi M., 2019, Proceedings of the International Conference on ISMAC in Computational Vision and Bio-Engineering 2018 (ISMAC-CVB).Lecture Notes in Computational Vision and Biomechanics (LNCVB 30), P595, DOI 10.1007/978-3-030-00665-5_59
   Fang S, 2017, IEEE T NEUR NET LEAR, V28, P1095, DOI 10.1109/TNNLS.2016.2522440
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fu K., 2018, ARXIV181105625
   Ghosh D, 2016, J VIS COMMUN IMAGE R, V34, P1, DOI 10.1016/j.jvcir.2015.10.014
   Guo T, 2012, INT ARCH PHOTOGRAMM, V39-B1, P485
   He B., 2015, Sensors (Switzerland), V16, P1, DOI DOI 10.3390/s16010001
   Huang YD, 2008, KAM: 2008 INTERNATIONAL SYMPOSIUM ON KNOWLEDGE ACQUISITION AND MODELING, PROCEEDINGS, P663, DOI 10.1109/KAM.2008.73
   Johnson J, 1985, P SPIE, P513
   Li J, 2020, IEEE T IMAGE PROCESS, V29, P1902, DOI 10.1109/TIP.2019.2946102
   Li J, 2015, IEEE T PATTERN ANAL, V37, P2428, DOI 10.1109/TPAMI.2015.2424870
   Li J, 2010, INT J COMPUT VISION, V90, P150, DOI 10.1007/s11263-010-0354-6
   Lipinski D, 2016, IEEE SYST J, V10, P1263, DOI 10.1109/JSYST.2015.2487449
   Liu F, 2019, MULTIMED TOOLS APPL, V78, P27933, DOI 10.1007/s11042-019-07864-y
   Liu YS, 2017, 2017 32ND YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), P1048, DOI 10.1109/YAC.2017.7967565
   Oettershagen P, 2018, J FIELD ROBOT, V35, P612, DOI 10.1002/rob.21765
   Piciarelli C, 2019, IEEE T IND INFORM, V15, P3289, DOI 10.1109/TII.2018.2873237
   Prathap KSV, 2016, INT CONF COMP COMMUN
   Ren WL, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.015001
   Sakla W, 2017, IEEE WINT CONF APPL, P916, DOI 10.1109/WACV.2017.107
   Sun S, 2013, INT CONF SMART GRID, P13, DOI 10.1109/SmartGridComm.2013.6687926
   Wang S, 2018, IEEE 2018 INTERNATIONAL CONGRESS ON CYBERMATICS / 2018 IEEE CONFERENCES ON INTERNET OF THINGS, GREEN COMPUTING AND COMMUNICATIONS, CYBER, PHYSICAL AND SOCIAL COMPUTING, SMART DATA, BLOCKCHAIN, COMPUTER AND INFORMATION TECHNOLOGY, P1707, DOI 10.1109/Cybermatics_2018.2018.00285
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei QL, 2017, 2017 INTERNATIONAL CONFERENCE ON VISION, IMAGE AND SIGNAL PROCESSING (ICVISP), P46, DOI 10.1109/ICVISP.2017.13
   Wischounig-Strucl D, 2015, MACH VISION APPL, V26, P885, DOI 10.1007/s00138-015-0699-5
   Zhang M, 2017, FRONT IMMUNOL, V8, P1, DOI 10.3389/fimmu.2017.00942
   Zhang YH, 2017, MEMET COMPUT, V9, P231, DOI 10.1007/s12293-016-0219-9
   Zhao J, 2019, IEEE PHOTONICS J, V11, DOI 10.1109/JPHOT.2019.2893934
   Zhou ZY, 2018, IEEE T IND INFORM, V14, P2705, DOI 10.1109/TII.2018.2794320
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 47
TC 5
Z9 5
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18387
EP 18404
DI 10.1007/s11042-020-08758-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000587677800049
DA 2024-07-18
ER

PT J
AU Mehta, R
   Gupta, K
   Yadav, AK
AF Mehta, Rajesh
   Gupta, Keshav
   Yadav, Ashok Kumar
TI An adaptive framework to image watermarking based on the twin support
   vector regression and genetic algorithm in lifting wavelet transform
   domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE LTSVR; LWT; QR; GA; Image watermarking
ID SYSTEM; SVD
AB A novel adaptive gray scale image watermarking approach based on the combination of machine learning (ML) algorithms in wavelet domain is presented. Based upon fuzzy entropy information, non-overlapping and significant regions are selected. Lifting wavelet transform (LWT) is performed on selected significant regions in order to obtain low frequency sub band and underwent through the QR factorization. Prominent low frequency features of each region are supplied as input features for the training purpose of Lagrangian twin support vector regression (LTSVR) model. Then the optimal value of watermark scaling factor (strength) obtained using genetic algorithm (GA) is used to embed the watermark in the test data of output wavelet coefficient obtained by trained LTSVR. Arnold transformation is performed for the security of watermark along with the imperceptibility and robustness. The experimental results as well as the comparison between traditional methods and the proposed one showed a significant improvement in robustness in terms of image processing attacks which makes it suitable for implementing copyright protection applications.
C1 [Mehta, Rajesh; Gupta, Keshav] Thapar Inst Engn & Technol, CSED, Patiala, Punjab, India.
   [Yadav, Ashok Kumar] Amity Sch Engn & Technol, Dept Comp Sci & Engn, Noida, India.
C3 Thapar Institute of Engineering & Technology; Amity University Noida
RP Mehta, R (corresponding author), Thapar Inst Engn & Technol, CSED, Patiala, Punjab, India.
EM rajesh.mehta@thapar.edu; keshavgupta0997@gmail.com; akyadav1@amity.edu
RI Gupta, Keshav/HSF-6769-2023; Yadav, Ashok Kumar/P-6865-2016
OI Gupta, Keshav/0000-0003-2097-7436; Yadav, Ashok
   Kumar/0000-0003-1054-4442
CR Agarwal C, 2015, EGYPT INFORM J, V16, P83, DOI 10.1016/j.eij.2015.01.002
   Ali M, 2015, EXPERT SYST APPL, V42, P2392, DOI 10.1016/j.eswa.2014.10.045
   Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   [Anonymous], 2015, INT J MACH LEARN CYB, DOI DOI 10.1007/S-13042-015-0331-Z
   Ansari IA, 2017, PATTERN RECOGN LETT, V94, P228, DOI 10.1016/j.patrec.2016.12.010
   Avci E, 2009, EXPERT SYST APPL, V36, P3077, DOI 10.1016/j.eswa.2008.01.027
   Balasundaram S, 2014, NEURAL NETWORKS, V51, P67, DOI 10.1016/j.neunet.2013.12.003
   Balasundaram S, 2013, NEURAL COMPUT APPL, V22, pS257, DOI 10.1007/s00521-012-0971-9
   Chu WC, 2003, IEEE T MULTIMEDIA, V5, P34, DOI 10.1109/TMM.2003.808816
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   Eyadat M, 2005, PATTERN RECOGN LETT, V26, P1405, DOI 10.1016/j.patrec.2004.11.027
   Fan WB, 2005, LECT NOTES ARTIF INT, V3802, P838
   Jagadeesh B, 2016, SOFT COMPUT, V20, P3679, DOI 10.1007/s00500-015-1729-y
   Klir G., 1995, Fuzzy sets and fuzzy logic, V4
   Lingling Wu, 2009, 2009 1st International Conference on Information Science and Engineering (ICISE 2009), P1164, DOI 10.1109/ICISE.2009.347
   Mangasaian OL, 2001, J MACH LEARN RES, V1, P161, DOI 10.1162/15324430152748218
   Mehta R, 2018, INT J MACH LEARN CYB, V9, P145, DOI 10.1007/s13042-015-0329-6
   Mehta R, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P340, DOI 10.1109/ICIIP.2013.6707612
   Nikolaidis N, 1998, SIGNAL PROCESS, V66, P385, DOI 10.1016/S0165-1684(98)00017-6
   Peng H, 2010, J SYST SOFTWARE, V83, P1470, DOI 10.1016/j.jss.2010.03.006
   Peng XJ, 2010, NEURAL NETWORKS, V23, P365, DOI 10.1016/j.neunet.2009.07.002
   Petitcolas FAP, 2000, IEEE SIGNAL PROC MAG, V17, P58, DOI 10.1109/79.879339
   Rawat S, 2012, SIGNAL PROCESS, V92, P1480, DOI 10.1016/j.sigpro.2011.12.006
   Shen RM, 2005, J SYST SOFTWARE, V78, P1, DOI 10.1016/j.jss.2005.02.013
   Su Liyun, 2006, Wuhan University Journal of Natural Sciences, V11, P1657, DOI 10.1007/BF02831844
   Tang XH, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P1509
   Wang SM, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INFORMATION PROCESSING AND 2008 INTERNATIONAL PACIFIC WORKSHOP ON WEB MINING AND WEB-BASED APPLICATION, P598, DOI 10.1109/ISIP.2008.149
   Yadav A, 2016, NETWORKING COMMUNICA, P115
   Yadav AK, 2016, MULTIMED TOOLS APPL, V75, P9371, DOI 10.1007/s11042-016-3381-7
   Yao Z, 2019, IEEE T CYBERNETICS, V99, P1
   Zhang SQ, 2006, J PHYS CONF SER, V48, P696, DOI 10.1088/1742-6596/48/1/131
   Zhou Y, 2018, IEEE C EVOL COMPUTAT, P1833, DOI 10.1109/CEC.2018.8477691
NR 33
TC 12
Z9 13
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18657
EP 18678
DI 10.1007/s11042-020-08634-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000587677800062
DA 2024-07-18
ER

PT J
AU Belda, R
   de Fez, I
   Arce, P
   Guerri, JC
AF Belda, Roman
   de Fez, Ismael
   Arce, Pau
   Carlos Guerri, Juan
TI Look ahead to improve QoE in DASH streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive bitrate streaming (ABR); Dynamic adaptive streaming over HTTP
   (DASH); Quality of experience (QoE); Video multimethod assessment fusion
   (VMAF); ExoPlayer
ID VIDEO; QUALITY
AB When a video is encoded with constant quality, the resulting bitstream will have variable bitrate due to the inherent nature of the video encoding process. This paper proposes a video Adaptive Bitrate Streaming (ABR) algorithm, called Look Ahead, which takes into account this bitrate variability in order to calculate, in real time, the appropriate quality level that minimizes the number of interruptions during the playback. The algorithm is based on the Dynamic Adaptive Streaming over HTTP (DASH) standard for on-demand video services. In fact, it has been implemented and integrated into ExoPlayer v2, the latest version of the library developed by Google to play DASH contents. The proposed algorithm is compared to the Muller and Segment Aware Rate Adaptation (SARA) algorithms as well as to the default ABR algorithm integrated into ExoPlayer. The comparison is carried out by using the most relevant parameters that affect the Quality of Experience (QoE) in video playback services, that is, number and duration of stalls, average quality of the video playback and number of representation switches. These parameters can be combined to define a QoE model. In this sense, this paper also proposes two new QoE models for the evaluation of ABR algorithms. One of them considers the bitrate of every segment of each representation, and the second is based on VMAF (Video Multimethod Assessment Fusion), a Video Quality Assessment (VQA) method developed by Netflix. The evaluations presented in the paper reflect: first, that Look Ahead outperforms the Muller, SARA and the ExoPlayer ABR algorithms in terms of number and duration of video playback stalls, with hardly decreasing the average video quality; and second, that the two QoE models proposed are more accurate than other similar models existing in the literature.
C1 [Belda, Roman; de Fez, Ismael; Arce, Pau; Carlos Guerri, Juan] Univ Politecn Valencia, Inst Telecommun & Multimedia Applicat iTEAM, Camino Vera, Valencia 46022, Spain.
C3 Universitat Politecnica de Valencia
RP Belda, R (corresponding author), Univ Politecn Valencia, Inst Telecommun & Multimedia Applicat iTEAM, Camino Vera, Valencia 46022, Spain.
EM robelor@iteam.upv.es; isdefez@iteam.upv.es; paarvi@iteam.upv.es;
   jcguerri@dcom.upv.es
RI Arce, Pedro/L-1268-2014; Belda, Román/IAM-8676-2023; Guerri, Juan
   Carlos/K-9659-2014
OI de Fez, Ismael/0000-0002-1337-1973; Guerri, Juan
   Carlos/0000-0002-5807-1923; Arce, Pau/0000-0001-5726-9228; Belda,
   Roman/0000-0003-2244-2371
FU Universitat Politecnica de Valencia (Ayudas para contratos de acceso al
   sistema espanol de Ciencia, Tecnologia e Innovacion, en estructuras de
   investigacion de la Universitat Politecnica de Valencia) [PAID-10-18];
   Universitat Politecnica de Valencia ("Tecnologias de distribucion y
   procesado de informacion multimedia y QoE") [20180810]
FX This work is supported by the PAID-10-18 Program of the Universitat
   Politecnica de Valencia (Ayudas para contratos de acceso al sistema
   espanol de Ciencia, Tecnologia e Innovacion, en estructuras de
   investigacion de la Universitat Politecnica de Valencia) and by the
   Project 20180810 from the Universitat Politecnica de Valencia
   ("Tecnologias de distribucion y procesado de informacion multimedia y
   QoE").
CR Akhshabi S, 2012, SIGNAL PROCESS-IMAGE, V27, P271, DOI 10.1016/j.image.2011.10.003
   Bampis CG, 2019, IEEE T CIRC SYST VID, V29, P2256, DOI 10.1109/TCSVT.2018.2868262
   Barman N, 2019, IEEE ACCESS, V7, P30831, DOI 10.1109/ACCESS.2019.2901778
   Belda R, 2013, THESIS
   Belda R, 2018, IEEE INT SYM BROADB
   Chen JW, 2014, THIRTEENTH WUHAN INTERNATIONAL CONFERENCE ON E-BUSINESS, 2014, P1
   Citizens Equal, 2016, Medium.15 June
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dai H, 2011, ACTA HORTIC, P169, DOI 10.17660/ActaHortic.2011.913.20
   Ghadiyaram D, 2019, IEEE T CIRC SYST VID, V29, P183, DOI 10.1109/TCSVT.2017.2768542
   Ghent University, 2019, 4G LTE BANDW LOGS
   Hu WF, 2017, 2017 16TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS 2017), P569
   Institute of Telecommunications and Multimedia Applications website, 2019, LOOK AH DEM
   ISO/IEC, 2014, Rep. 23009-1. ISO/IEC JTCI/SC29/WG11
   Juluri P, 2016, IEEE IFIP NETW OPER, P129, DOI 10.1109/NOMS.2016.7502805
   Juluri P, 2015, IEEE INT CONF COMM, P1765, DOI 10.1109/ICCW.2015.7247436
   Kua J, 2017, IEEE COMMUN SURV TUT, V19, P1842, DOI 10.1109/COMST.2017.2685630
   Lee S, 2015, I SYMP CONSUM ELECTR, P126, DOI 10.1109/ICCE.2015.7066348
   Li J, 2014, INTERNATIONAL CONFERENCE ON COMPUTER, NETWORK SECURITY AND COMMUNICATION ENGINEERING (CNSCE 2014), P187
   Li SN, 2011, IEEE T MULTIMEDIA, V13, P935, DOI 10.1109/TMM.2011.2152382
   Mobile Video Service Performance Study, 2015, MOBILE VIDEO SERVICE
   Mok R.K., 2012, P 3 MULTIMEDIA SYSTE, P11
   Moldovan C, 2017, 2017 29TH INTERNATIONAL TELETRAFFIC CONGRESS (ITC 29), VOL 3, P1, DOI [10.23919/ITC.2017.8065802, 10.1109/ITC.2017.15]
   Muller C., 2012, 4th ACM Workshop on Mobile Video (MoVID), P37, DOI DOI 10.1145/2151677.2151686
   Nguyen T, 2015, 2015 INTERNATIONAL CONFERENCE ON COMMUNICATIONS, MANAGEMENT AND TELECOMMUNICATIONS (COMMANTEL), P189, DOI 10.1109/ComManTel.2015.7394285
   Qin YY, 2018, CONEXT'18: PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON EMERGING NETWORKING EXPERIMENTS AND TECHNOLOGIES, P366, DOI 10.1145/3281411.3281439
   Samain J, 2017, IEEE T MULTIMEDIA, V19, P2166, DOI 10.1109/TMM.2017.2733340
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Shuai Y, 2016, P INT C CONS EL BERL, P1, DOI [10.1109/ICCE-Berlin.2016.7684742., DOI 10.1109/ICCE-BERLIN.2016.7684742]
   Tavakoli S, 2016, IEEE J SEL AREA COMM, V34, P2141, DOI 10.1109/JSAC.2016.2577361
   van der Hooft J, 2016, IEEE COMMUN LETT, V20, P2177, DOI 10.1109/LCOMM.2016.2601087
   Yarnagula HK, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3311749
   Yu L, 2017, IEEE T BROADCAST, V63, P523, DOI 10.1109/TBC.2017.2687698
   Zhou C, 2016, IEEE T MULTIMEDIA, V18, P738, DOI 10.1109/TMM.2016.2522650
   Zhou YP, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P9, DOI 10.1109/VCIP.2014.7051491
NR 35
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 25143
EP 25170
DI 10.1007/s11042-020-09214-9
EA JUN 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000544580400003
OA Green Published
DA 2024-07-18
ER

PT J
AU Togay, C
AF Togay, Cengiz
TI A practical key agreement scheme for videoconferencing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE WebRTC; Videoconferencing; Key agreement; Media sharing; Java smart card
AB Recently, videoconferencing is becoming more and more pervasive as a consequence of new concerns about privacy and security. The media should be encrypted through the utilization of actual encryption algorithms and group key agreement schemes. In this study, a new key agreement scheme based on Java smart cards is proposed and applied on Web-based real-time communication (WebRTC)-based videoconferencing. In WebRTC, symmetric keys are generated using pseudorandom number generators and shared by two standard protocols, namely, Source Description RTCP Packet (SDES) and Datagram Transport Layer Security (DTLS), through a signaling server. In both methods, the key exchange is open to cryptanalytic attacks, and the administrator of the signaling server can compromise media. This qualitative study aims to investigate privacy during WebRTC-based videoconferencing with respect to symmetric encryption algorithm, randomness of the encryption key, overall security strength, key agreement scheme, and time required to start a conversation. Herein, a new key agreement scheme based on Java smart cards is proposed. The scheme utilizes AES-256 algorithm in GCM mode for media encryption. By means of this approach, the set-up time of a conference is reduced to 562 ms (compared to 1754 ms for the RSA-based approach) for 367 users, and the security strength is increased to 256-bit (as against 112-bit for RSA 2048-bit). A secure random key generator for smart cards is utilized for a key generation instead of pseudorandom number generators. The proposed approach also includes a safety mechanism for smart card failures. We utilize the AVISPA (The Automated Validation of Internet Security Protocols and Applications) tool to test the safety of the proposed scheme.
C1 [Togay, Cengiz] Uludag Univ, Engn Fac, Comp Engn Dept, Bursa, Turkey.
C3 Uludag University
RP Togay, C (corresponding author), Uludag Univ, Engn Fac, Comp Engn Dept, Bursa, Turkey.
EM ctogay@uludag.edu.tr
OI Togay, Cengiz/0000-0001-5739-1784
CR Alexander AL, 2009, NSS: 2009 3RD INTERNATIONAL CONFERENCE ON NETWORK AND SYSTEM SECURITY, P95, DOI 10.1109/NSS.2009.90
   [Anonymous], 2006, RFC4568
   [Anonymous], 2010, RFC5766
   [Anonymous], 2010, RFC5245
   [Anonymous], 2013, RFC6904
   [Anonymous], 2015, RFC7622
   [Anonymous], 2012, RFC6347
   Barnes RL, 2014, IEEE INTERNET COMPUT, V18, P11, DOI 10.1109/MIC.2014.106
   Ben Farah MA, 2020, NONLINEAR DYNAM, V99, P3041, DOI 10.1007/s11071-019-05413-8
   Ben Farah MA, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105777
   Boorghany A, 2014, INT ISC CONF INFO SE, P49, DOI 10.1109/ISCISC.2014.6994021
   Candan OM, 2018, IEEE INT CONF COMM
   Daldal B, 2016, IEEE IFIP NETW OPER, P780, DOI 10.1109/NOMS.2016.7502898
   DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638
   Dzurenda P, 2017, ANN CONF PRIV SECUR, P365, DOI 10.1109/PST.2017.00050
   GitHub, 2018, OP SOURC SEC RTP LIB
   Kelsey J, 1998, LECT NOTES COMPUT SC, V1372, P168
   Mayes K, 2017, SMART CARDS TOKENS S, P226
   NIST, 2020, NIST Special Publication, V800-175B
   Petit-Huguenin M., 2019, RFC5389
   Pietilainen H, 1997, THESIS HELSINKI TU
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Romain C, 2013, INT CONF INTELL NEXT, P31, DOI 10.1109/ICIN.2013.6670891
   Savari M., 2012, 2012 International Conference on Cyber Security, Cyber Warfare and Digital Forensic (CyberSec), P49, DOI 10.1109/CyberSec.2012.6246121
   Symantec, 2013, SA73 TURKTRUST MIS I
   Sys M, 2017, E BUSINESS TELECOMMU, P123, DOI [10.1007/978-3-030-11039-0_7, DOI 10.1007/978-3-030-11039-0_7]
   THAWTE, 2018, SPOOF SERV SERV COMM
   Togay C, 2016, PCTTR2015000241 ENCR
   Togay C, 2016, 2016 24TH SIGNAL PROCESSING AND COMMUNICATION APPLICATION CONFERENCE (SIU), P1621, DOI 10.1109/SIU.2016.7496066
   Togay C, 2014, SIG PROCESS COMMUN, P256, DOI 10.1109/SIU.2014.6830214
   W3 1.0, 2018, REAL TIM COMM BROWS
NR 31
TC 0
Z9 0
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 23711
EP 23728
DI 10.1007/s11042-020-09136-6
EA JUN 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000539857100003
DA 2024-07-18
ER

PT J
AU Sartipi, S
   Kalbkhani, H
   Shayesteh, MG
AF Sartipi, Shadi
   Kalbkhani, Hashem
   Shayesteh, Mahrokh G.
TI Diagnosis of schizophrenia from R-fMRI data using Ripplet transform and
   OLPP
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer-aided diagnosis (CAD); Functional magnetic resonance imaging
   (fMRI); Orthogonal locality preserving projection (OLPP); Ripplet
   transform; Schizophrenia
ID COMPUTER-AIDED DIAGNOSIS; FEATURE-SELECTION METHOD; RADON-TRANSFORM;
   CLASSIFICATION; ALGORITHM; FEATURES; NETWORKS; CURVES; FAMILY
AB Schizophrenia is a severe brain disease that influences the behaviour and thought of person. These effects may fail in achieving the expected levels of interpersonal, academic, or occupational functioning. Although the underlying mechanism is not yet clear, the early detection of schizophrenia is an attractive and challenging research area. There are differences in brain connections of patients and healthy people. This study presents a new computer-aided diagnosis (CAD) method to diagnose schizophrenia (SZ) patients from normal control (NC) people by using the rest-state functional magnetic resonance imaging (R-fMRI) data. fMRI data has a huge dimension, and extracting efficient features is still an open challenge for a schizophrenia diagnosis. In the proposed method, at first orthogonal locality preserving projection (OLPP) is used to reduce the number of time points in R-fMRI scans. Then, an independent component analysis (ICA) algorithm is employed to estimate the independent components (ICs). Next, orthogonal Ripplet-II transform is applied to each IC to extract features. Afterward, a two-sample T-test is implemented on the extracted features to find the most discriminative features. Then, the number of selected features is reduced by applying OLPP. Finally, a test subject is classified into SZ or NC using a linear support vector machine (SVM) classifier. The proposed method is evaluated on the NAMIC and COBRE databases. The results demonstrate that the introduced method significantly outperforms previously presented methods.
C1 [Sartipi, Shadi; Shayesteh, Mahrokh G.] Urmia Univ, Dept Elect Engn, Orumiyeh, Iran.
   [Kalbkhani, Hashem] Urmia Univ Technol, Fac Elect Engn, Orumiyeh, Iran.
   [Shayesteh, Mahrokh G.] Sharif Univ Technol, Dept Elect Engn, ACRI, Wireless Res Lab, Tehran, Iran.
C3 Urmia University; Urmia University of Technology; Sharif University of
   Technology
RP Shayesteh, MG (corresponding author), Urmia Univ, Dept Elect Engn, Orumiyeh, Iran.; Shayesteh, MG (corresponding author), Sharif Univ Technol, Dept Elect Engn, ACRI, Wireless Res Lab, Tehran, Iran.
EM st_sh.sartipi@urmia.ac.ir; h.kalbkhani@uut.ac.ir;
   m.shayesteh@urmia.ac.ir
RI Sartipi, shadi/GNM-6389-2022; Kalbkhani, Hashem/AFU-4862-2022
OI Kalbkhani, Hashem/0000-0003-2431-4920
CR Algunaid RF, 2018, BIOMED SIGNAL PROCES, V43, P289, DOI 10.1016/j.bspc.2018.02.018
   Anderson A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00520
   Arribas JI, 2010, IEEE T BIO-MED ENG, V57, P2850, DOI 10.1109/TBME.2010.2080679
   Ashburner J., 2012, SPM8 manual
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Boehm O, 2011, INT J MACH LEARN CYB, V2, P125, DOI 10.1007/s13042-011-0030-3
   Buckley PF, 2009, SCHIZOPHRENIA BULL, V35, P383, DOI 10.1093/schbul/sbn135
   Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945
   Calhoun VD, 2008, HUM BRAIN MAPP, V29, P828, DOI 10.1002/hbm.20581
   Castro E, 2011, NEUROIMAGE, V58, P526, DOI 10.1016/j.neuroimage.2011.06.044
   Chatterjee I, 2018, MULTIMED TOOLS APPL, V77, P26991, DOI 10.1007/s11042-018-5901-0
   Chung F. R. K., 1997, Spectral graph theory
   Chyzhyk D, 2015, NEURAL NETWORKS, V68, P23, DOI 10.1016/j.neunet.2015.04.002
   COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9
   CORMACK AM, 1981, P AM MATH SOC, V83, P325, DOI 10.2307/2043520
   CORMACK AM, 1982, P AM MATH SOC, V86, P293, DOI 10.2307/2043399
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Demirci O, 2008, NEUROIMAGE, V39, P1774, DOI 10.1016/j.neuroimage.2007.10.012
   Du W, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00145
   FUSAR-POLI P., 2009, Journal of Psychiatry Neuroscience: JPN
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hsieh TH, 2014, 2014 INTERNATIONAL SYMPOSIUM ON COMPUTER, CONSUMER AND CONTROL (IS3C 2014), P1203, DOI 10.1109/IS3C.2014.312
   Huettel SA., 2004, Functional magnetic resonance imaging
   Hyvarinen A, 1997, NEURAL COMPUT, V9, P1483, DOI 10.1162/neco.1997.9.7.1483
   Hyvarinen A., 1998, FASTICA MATLAB TOOLB
   Jahmunah V, 2019, ARTIF INTELL MED, V100, DOI 10.1016/j.artmed.2019.07.006
   Juneja A, 2018, MULTIMED TOOLS APPL, V77, P3963, DOI 10.1007/s11042-017-4404-8
   Juneja A, 2018, COMPUT METH PROG BIO, V155, P139, DOI 10.1016/j.cmpb.2017.12.001
   Juneja A, 2016, BIOMED SIGNAL PROCES, V27, P122, DOI 10.1016/j.bspc.2016.02.009
   Kalbkhani H, 2013, BIOMED SIGNAL PROCES, V8, P909, DOI 10.1016/j.bspc.2013.09.001
   Kim J, 2020, J NEUROSCI METH, V338, DOI 10.1016/j.jneumeth.2020.108688
   Logothetis NK, 2001, NATURE, V412, P150, DOI 10.1038/35084005
   Nayak DR, 2018, MULTIMED TOOLS APPL, V77, P22705, DOI 10.1007/s11042-017-5281-x
   Nayak DR, 2018, NEUROCOMPUTING, V282, P232, DOI 10.1016/j.neucom.2017.12.030
   Pardo PJ, 2006, SCHIZOPHR RES, V87, P297, DOI 10.1016/j.schres.2006.05.007
   Patel P, 2016, TENTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS AND IMAGE PROCESSING (ICVGIP 2016), DOI 10.1145/3009977.3010050
   Poldrack RA, 2012, NEUROIMAGE, V62, P1216, DOI 10.1016/j.neuroimage.2011.08.007
   Pouyan AA, 2015, BIOCYBERN BIOMED ENG, V35, P45, DOI 10.1016/j.bbe.2014.08.001
   Qureshi MNI, 2019, ARTIF INTELL MED, V98, P10, DOI 10.1016/j.artmed.2019.06.003
   Salman MS, 2019, NEUROIMAGE-CLIN, V22, DOI 10.1016/j.nicl.2019.101747
   Sartipi S, 2017, 2017 10TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND ELECTRONICS ENGINEERING (ELECO), P557
   Savio A, 2015, NEUROCOMPUTING, V164, P154, DOI 10.1016/j.neucom.2015.01.079
   Shinkareva SV, 2006, NEUROIMAGE, V33, P63, DOI 10.1016/j.neuroimage.2006.06.032
   Srinivasagopalan S, 2019, J EXP THEOR ARTIF IN, V31, P803, DOI 10.1080/0952813X.2018.1563636
   Wang L, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (ICIA), P455, DOI 10.1109/ICInfA.2014.6932699
   Xiang YZ, 2020, FRONT BIOENG BIOTECH, V7, DOI 10.3389/fbioe.2019.00479
   Xu J, 2010, PROC SPIE, V7744, DOI 10.1117/12.863013
   Yang B, 2019, IEEE ACCESS, V7, P109956, DOI 10.1109/ACCESS.2019.2933550
   Zhou Nina, 2007, Genomics Proteomics & Bioinformatics, V5, P242, DOI 10.1016/S1672-0229(08)60011-X
NR 50
TC 5
Z9 5
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 23401
EP 23423
DI 10.1007/s11042-020-09122-y
EA JUN 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000538977500003
DA 2024-07-18
ER

PT J
AU Ding, MJ
   Xu, X
   Zhang, F
   Xiao, ZT
   Liu, YB
   Geng, L
   Wu, J
   Wen, J
   Wang, M
AF Ding, Mingjun
   Xu, Xu
   Zhang, Fang
   Xiao, Zhitao
   Liu, Yanbei
   Geng, Lei
   Wu, Jun
   Wen, Jia
   Wang, Meng
TI Saliency detection via background prior and foreground seeds
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency detection; Background prior; Cellular automata; Foreground
   seeds; Biased Gaussian filtering
ID GEODESIC PROPAGATION; OBJECT; MODEL
AB As an image pre-processing technology, saliency detection (DS) can be used in a wide variety of visual tasks. A bottom-up method of DS via background prior and foreground seeds is proposed. To highlight the object and suppress the background noise, two saliency maps are obtained by using the background prior and foreground seeds. First, we use global colour and spatial distance matrices to compute a background saliency map. To evenly emphasize the saliency region, the single-layer cellular automata is used to refine the background-based saliency map. Second, a set of foreground seeds is obtained from the refined background-based saliency map. Then, the foreground-based saliency map is calculated based on the foreground seeds and refined by biased Gaussian filtering. The proposed method could emphasize the foreground target, as well as restrain the background noise. The experiment results show that our method has good ability in saliency detection.
C1 [Ding, Mingjun; Xu, Xu; Zhang, Fang; Xiao, Zhitao; Liu, Yanbei; Geng, Lei; Wu, Jun; Wen, Jia] Tianjin Polytech Univ, Sch Elect & Informat Engn, Tianjin 300387, Peoples R China.
   [Ding, Mingjun; Xu, Xu; Zhang, Fang; Xiao, Zhitao; Liu, Yanbei; Geng, Lei; Wu, Jun; Wen, Jia; Wang, Meng] Tianjin Key Lab Optoelect Detect Technol & Syst, Tianjin 300387, Peoples R China.
C3 Tiangong University
RP Zhang, F (corresponding author), Tianjin Polytech Univ, Sch Elect & Informat Engn, Tianjin 300387, Peoples R China.; Zhang, F (corresponding author), Tianjin Key Lab Optoelect Detect Technol & Syst, Tianjin 300387, Peoples R China.
EM zhangfang@tjpu.edu.cn
RI Liu, Yanbei/IQR-5059-2023; geng, lei/KEZ-8801-2024; wang,
   Xiaoming/KBB-8854-2024
OI Geng, Lei/0000-0002-5010-2596
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P742, DOI 10.1109/TIP.2014.2383320
   Chen XW, 2012, LECT NOTES COMPUT SC, V7574, P553, DOI 10.1007/978-3-642-33712-3_40
   Ding YY, 2011, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2011.5995445
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Guo CL, 2008, PROC CVPR IEEE, P2908
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78
   Li Q, 2014, IEEE T IMAGE PROCESS, V23, P4812, DOI 10.1109/TIP.2014.2358193
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Lu H., 2016, CONCURR COMP-PRACT E, V29, P6
   Lu HM, 2018, FUTURE GENER COMP SY, V82, P142, DOI 10.1016/j.future.2018.01.001
   Mahadevan V, 2009, PROC CVPR IEEE, P1007, DOI 10.1109/CVPRW.2009.5206573
   Marchesotti L, 2009, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2009.5459467
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Ng AY, 2002, ADV NEUR IN, V14, P849
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40
   Sun J, 2011, IEEE I CONF COMP VIS, P1511, DOI 10.1109/ICCV.2011.6126409
   von Neumann J., 1951, CEREBRAL MECH BEHAV, P1
   Wang JP, 2015, NEUROCOMPUTING, V152, P359, DOI 10.1016/j.neucom.2014.10.056
   Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Xiao HX, 2018, IEEE T MULTIMEDIA, V20, P3239, DOI 10.1109/TMM.2018.2830098
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   YANG JM, 2012, PROC CVPR IEEE, P2296, DOI [DOI 10.1109/CVPR.2012.6247940, 10.1109/CVPR.2012.6247940]
   Zhang F, 2018, ACTA AUTOMAT SIN, P44, DOI [10.16383/j.aas.2018.c170535, DOI 10.16383/J.AAS.2018.C170535]
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhang PP, 2017, IEEE I CONF COMP VIS, P212, DOI 10.1109/ICCV.2017.32
   Zhang XS, 2018, DES AUTOM EMBED SYST, V22, P243, DOI 10.1007/s10617-018-9209-0
NR 41
TC 4
Z9 4
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14849
EP 14870
DI 10.1007/s11042-019-7728-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900030
DA 2024-07-18
ER

PT J
AU Lu, X
   Ding, HW
   Yang, ZJ
   Bao, LY
   Wang, LQ
   Liu, QL
AF Lu, Xu
   Ding, Hongwei
   Yang, Zhijun
   Bao, Liyong
   Wang, Liqing
   Liu, Qianlin
TI Implementation and performance analysis of random multiple access
   protocol with variable collision length of multimedia video information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Video information; Random multiple access; Multiple
   priority; 1-persistent CSMA; Variable collision length
ID MAC PROTOCOL; THROUGHPUT; SYSTEMS
AB In recent years, multimedia video services have developed rapidly. However, the increasing number and variety of videos is likely to cause packet loss and delay during video transmission. Therefore, how to use channel resources more effectively becomes an urgent problem to be solved. This paper improves the existing random multiple access protocol and designs the 1-persistent CSMA (Carrier Sense Multiple Access) protocol with variable collision length. At the same time, considering the different requirements of different video services, multi-priority 1-persistent CSMA random multiple access control protocol with variable collision length is proposed, which sets different priorities and then competes fairly. Finally, the paper analyzes the performance of the multimedia video service access algorithm: the 1-persistent CSMA access protocol with variable collision length is higher than the traditional 1-persistent CSMA throughput, the performance is better, at the same time, in the case of a relatively high arrival rate, the advantage of throughput is more obvious.
C1 [Lu, Xu; Ding, Hongwei; Yang, Zhijun; Bao, Liyong; Wang, Liqing; Liu, Qianlin] Yunnan Univ, Sch Informat, Kunming 650091, Yunnan, Peoples R China.
C3 Yunnan University
RP Ding, HW (corresponding author), Yunnan Univ, Sch Informat, Kunming 650091, Yunnan, Peoples R China.
EM dhw1964@163.com
CR Bae YH, 2014, IEEE T MOBILE COMPUT, V13, P497, DOI 10.1109/TMC.2012.254
   Buratti C, 2016, IEEE T VEH TECHNOL, V65, P251, DOI 10.1109/TVT.2015.2391302
   Cao XH, 2015, IEEE T WIREL COMMUN, V14, P5261, DOI 10.1109/TWC.2015.2435006
   Casares-Giner V, 2017, 2017 IEEE 5TH INTERNATIONAL CONFERENCE ON FUTURE INTERNET OF THINGS AND CLOUD (FICLOUD 2017), P18, DOI 10.1109/FiCloud.2017.38
   Chan DS, 2013, IEEE T COMMUN, V61, P266, DOI 10.1109/TCOMM.2012.120512.110285
   Chen L, 2018, IEEE ACCESS, V6, P15408, DOI 10.1109/ACCESS.2018.2794354
   Chen S, 2015, CHIN J CANCER, V34, DOI 10.1186/s40880-015-0001-2
   Chowdhury MS, 2014, IEEE WIREL COMMUN LE, V3, P257, DOI 10.1109/WCL.2014.021714.140008
   El Bouchti A, 2012, INT CONF MULTIMED, P657, DOI 10.1109/ICMCS.2012.6320296
   Ge XH, 2014, IEEE T VEH TECHNOL, V63, P2127, DOI 10.1109/TVT.2014.2310773
   Jian X, 2017, IEEE INTERNET THINGS, V4, P21, DOI 10.1109/JIOT.2016.2614007
   [金喜龙 Jin Xilong], 2018, [计算机应用研究, Application Research of Computers], V35, P874
   Joo C, 2013, IEEE T MOBILE COMPUT, V12, P647, DOI 10.1109/TMC.2012.26
   Lee JH, 2017, WIRELESS PERS COMMUN, V95, P2575, DOI 10.1007/s11277-016-3938-9
   Lian YP, 2008, J ZHEJIANG UNIV-SC A, V9, P1406, DOI 10.1631/jzus.A0720123
   Liao W, 2018, COMMUNICATION TECHNO, V51, P2153
   Mu W, 2018, CHINESE J ELECTRON, V46, P276
   Sarkar S, 2015, IEEE T COMPUT, V64, P2912, DOI 10.1109/TC.2015.2389806
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Sun XH, 2016, IEEE T WIREL COMMUN, V15, P5947, DOI 10.1109/TWC.2016.2574715
   Tadayon N, 2014, IEEE T VEH TECHNOL, V63, P849, DOI 10.1109/TVT.2013.2279858
   Uddin MF, 2014, IEEE ACM T NETWORK, V22, P80, DOI 10.1109/TNET.2013.2243163
   Wang X, 2014, WOOD FIBER SCI, V46, P109
   Wu D, 2014, IEEE T VEH TECHNOL, V63, P2093, DOI 10.1109/TVT.2014.2311580
   Xu Z, 2018, MODERN ELECT TECHNOL, V41, P34
   YANG Hai-gang, 2010, J ELECT INFORM TECHN, V32, P3
   Yu Ji-bo, 2011, Computer Engineering, V37, P282, DOI 10.3969/j.issn.1000-3428.2011.13.093
   Zhang Hui, 2008, Journal of China Institute of Communications, V29, P94
   [张人上 Zhang Renshang], 2015, [计算机应用研究, Application Research of Computers], V32, P1861
   Zhang X, 2017, I IEEE EMBS C NEUR E, P66, DOI 10.1109/NER.2017.8008293
   Zhang Y, 2011, 2011 INT C EL OPT 20, P666
   [周润 Zhou Run], 2017, [西北工业大学学报, Journal of Northwestern Polytechnical University], V35, P683
   Zhou SM, 2017, FLUID PHASE EQUILIBR, V440, P45, DOI 10.1016/j.fluid.2017.03.002
NR 33
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16547
EP 16571
DI 10.1007/s11042-019-7606-4
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600042
DA 2024-07-18
ER

PT J
AU Saeedzarandi, M
   Nezamabadi-pour, H
   Saryazdi, S
   Jamalizadeh, A
AF Saeedzarandi, Mansoore
   Nezamabadi-pour, Hossein
   Saryazdi, Saeid
   Jamalizadeh, Ahad
TI Image denoising in undecimated dual-tree complex wavelet domain using
   multivariate <i>t</i>-distribution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; MAP estimator; Undecimated dual-tree complex wavelet
   transform; Heavy-tail characteristic; Multivariate t-distribution
ID SCALE MIXTURES; TRANSFORM; MODELS; REMOVAL; SIGNAL
AB Denoising of natural images is a basic problem in image processing. The present paper proposes a new algorithm for image denoising based on the maximum a-posteriori (MAP) estimator in undecimated dual-tree complex wavelet transform. The undecimated dual-tree complex wavelet transform (UDT-CWT), along with the directional selectivity of the dual-tree complex wavelet transform (DT-CWT), offers exact translational invariance property through removing the down-sampling of filter outputs together with the up-sampling of the complex filter pairs of DT-CWT. These properties are very important in image denoising. The performance of the MAP estimator depends strongly on the probability of noise-free wavelet coefficients. In our proposed denoising method, multivariate t-distribution is applied as the prior probability of noise-free coefficients. The t-distribution can accurately model the statistics of wavelet coefficients, which have peaky and heavy-tailed characteristics. On the other hand, the multivariate model makes it possible to take into account the dependencies of wavelet coefficients and their neighbors. Also, in our work, the necessary parameters of the multivariate distribution will be estimated in a locally-adaptive way to improve the denoising results via using the correlations among the amplitudes of neighbor coefficients. Simulation results delineate that the proposed algorithm outperforms state-of-the-art denoising algorithms in the literature.
C1 [Saeedzarandi, Mansoore; Nezamabadi-pour, Hossein; Saryazdi, Saeid] Shahid Bahonar Univ Kerman, Dept Elect Engn, IDPL, Kerman, Iran.
   [Jamalizadeh, Ahad] Shahid Bahonar Univ Kerman, Fac Math & Comp, Dept Stat, Kerman, Iran.
C3 Shahid Bahonar University of Kerman (SBUK); Shahid Bahonar University of
   Kerman (SBUK)
RP Saeedzarandi, M (corresponding author), Shahid Bahonar Univ Kerman, Dept Elect Engn, IDPL, Kerman, Iran.
EM m_saeedzarandi@eng.uk.ac.ir; nezam@uk.ac.ir; saryazdi@uk.ac.ir;
   A.Jamalizadeh@uk.ac.ir
RI Saryazdi, Saeid/GQZ-0186-2022; Saryazdi, Saeid/GQY-9790-2022;
   Nezamabadi-pour, Hossein/AAB-4009-2019; Saryazdi, Saeid/D-4488-2015
OI Saryazdi, Saeid/0000-0002-4577-1971; Nezamabadi-pour,
   Hossein/0000-0002-3350-7348; Saryazdi, Saeid/0000-0002-4577-1971
CR Achim A, 2004, IEEE IMAGE PROC, P1225
   Achim A, 2001, IEEE T MED IMAGING, V20, P772, DOI 10.1109/42.938245
   Bartholomew D, 2011, WILEY SER PROBAB ST, P1, DOI 10.1002/9781119970583
   Basso RM, 2010, COMPUT STAT DATA AN, V54, P2926, DOI 10.1016/j.csda.2009.09.031
   Bohning D., 2000, COMPUTER ASSISTED AN
   CASELLA G, 2007, MATRIX ALGEBRA THEOR
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1522, DOI 10.1109/83.862630
   Chen G, 2012, IET IMAGE PROCESS, V6, P756, DOI 10.1049/iet-ipr.2010.0408
   Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544
   Cui LH, 2014, INT J ADV ROBOT SYST, V11, DOI 10.5772/57294
   Deledalle CA, 2012, J MATH IMAGING VIS, V43, P103, DOI 10.1007/s10851-011-0294-y
   Donoho DL, 1995, J AM STAT ASSOC, V90, P1200, DOI 10.1080/01621459.1995.10476626
   Fadili MM, 2005, IEEE T IMAGE PROCESS, V14, P231, DOI 10.1109/TIP.2004.840704
   Fowler JE, 2005, IEEE SIGNAL PROC LET, V12, P629, DOI 10.1109/LSP.2005.853048
   Gai S, 2015, MULTIMED TOOLS APPL, V74, P1107, DOI 10.1007/s11042-013-1812-2
   Hill PR, 2015, SIGNAL PROCESS-IMAGE, V35, P61, DOI 10.1016/j.image.2015.04.010
   Hill PR, 2014, SIGNAL PROCESS, V105, P464, DOI 10.1016/j.sigpro.2014.03.028
   Hill P, 2012, IEEE IMAGE PROC, P1205, DOI 10.1109/ICIP.2012.6467082
   HILL PR, BMVC 2002, P1
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Kaur S, 2014, INT J SCI STUDY, V2, P66
   Khmag A, 2018, MULTIMED TOOLS APPL, V77, P20065, DOI 10.1007/s11042-017-5425-z
   Kotz S., 2004, MULTIVARIATE T DISTR
   Lasmar NE, 2014, IEEE T IMAGE PROCESS, V23, P2246, DOI 10.1109/TIP.2014.2313232
   LIANG M, 2014, SCI CHINA SER F, V57, P1
   Luisier F, 2007, IEEE T IMAGE PROCESS, V16, P593, DOI 10.1109/TIP.2007.891064
   Mihçak MK, 1999, IEEE SIGNAL PROC LET, V6, P300, DOI 10.1109/97.803428
   MIN D, 2015, SIGNAL PROCESS, V109, P25
   Naimi H, 2015, J KING SAUD UNIV-COM, V27, P40, DOI 10.1016/j.jksuci.2014.03.015
   Om H, 2015, SIGNAL IMAGE VIDEO P, V9, P191, DOI 10.1007/s11760-013-0434-5
   Om H, 2014, OPT LASER TECHNOL, V57, P252, DOI 10.1016/j.optlastec.2013.07.018
   Pi-Erh Lin, 1972, Journal of Multivariate Analysis, V2, P339, DOI 10.1016/0047-259X(72)90021-8
   Pizurica A, 2006, IEEE T IMAGE PROCESS, V15, P654, DOI 10.1109/TIP.2005.863698
   Po DDY, 2006, IEEE T IMAGE PROCESS, V15, P1610, DOI 10.1109/TIP.2006.873450
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   RABANI H, 2006, VAFA DM WAVELET BASE
   Rabbani H, 2006, 2006 IEEE 12TH DIGITAL SIGNAL PROCESSING WORKSHOP & 4TH IEEE SIGNAL PROCESSING EDUCATION WORKSHOP, VOLS 1 AND 2, P203, DOI 10.1109/DSPWS.2006.265407
   Rabbani H, 2008, SIGNAL PROCESS, V88, P158, DOI 10.1016/j.sigpro.2007.07.016
   Robert C., 2013, MONTE CARLO STAT MET
   Sadreazami H, 2016, SIGNAL PROCESS, V128, P459, DOI 10.1016/j.sigpro.2016.05.018
   Saeed M, 2019, CRIT REV FOOD SCI, V59, P3293, DOI 10.1080/10408398.2018.1489368
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Sendur L, 2002, IEEE SIGNAL PROC LET, V9, P438, DOI 10.1109/LSP.2002.806054
   Simoncelli E.P., 1999, Bayesian Inference in Wavelet-Based Models, P291, DOI DOI 10.1007/978-1-4612-0567-8
   Su CC, 2015, IEEE SIGNAL PROC LET, V22, P21, DOI 10.1109/LSP.2014.2345765
   Sutour C, 2014, IEEE T IMAGE PROCESS, V23, P3506, DOI 10.1109/TIP.2014.2329448
   Tan S, 2007, INT J COMPUT VISION, V75, P209, DOI 10.1007/s11263-006-0019-7
   Wang J, 2017, DISPLAYS, V46, P37, DOI 10.1016/j.displa.2016.12.003
   Wang J, 2015, INFORMS J COMPUT, V27, P193, DOI 10.1287/ijoc.2014.0616
   Wang XY, 2011, J MATH IMAGING VIS, V39, P245, DOI 10.1007/s10851-010-0238-y
   Wang XH, 2018, IEEE ACCESS, V6, P66007, DOI 10.1109/ACCESS.2018.2876447
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   YAN C, INT C INT SCI BIG DA, P196
   Zeng WL, 2018, MULTIMED TOOLS APPL, V77, P20863, DOI 10.1007/s11042-017-5497-9
   Zhang L, 2010, PATTERN RECOGN, V43, P1531, DOI 10.1016/j.patcog.2009.09.023
NR 55
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22447
EP 22471
DI 10.1007/s11042-020-08954-y
EA MAY 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000534853600001
DA 2024-07-18
ER

PT J
AU Wang, SW
   Lan, L
   Zhang, X
   Luo, ZG
AF Wang, Shiwei
   Lan, Long
   Zhang, Xiang
   Luo, Zhigang
TI GateCap: Gated spatial and semantic attention model for image captioning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic attention; Spatial attention; Context gate
AB Visual attention has been widely used in deep image captioning models for its capacity of selectively aligning visual features to the corresponding words, i.e., the word-to-region alignment. In many cases, existing attention modules may not highlight task-related image regions for lack of high-level semantics. To advance captioning model, it is non-trivial for image captioning to effectively leverage high-level semantics. To defeat such issues, we propose a gated spatial and semantic attention captioning model (GateCap) which adaptively fuses spatial attention features with semantic attention features to achieve this goal. In particular, GateCap brings into two novel aspects: 1) spatial and semantic attention features are further enhanced via triple LSTMs in a divide-and-fuse learning manner, and 2) a context gate module is explored to reweigh spatial and semantic attention features in a fair manner. Benefitting from them, GateCap could reduce the side effect of the word-to-region misalignment at a time step over subsequent word prediction, thereby possibly alleviating emergence of incorrect words during testing. Experiments on MSCOCO dataset verify the efficacy of the proposed GateCap model in terms of quantitative and qualitative results.
C1 [Wang, Shiwei; Luo, Zhigang] Natl Univ Def Technol, Sci & Technol Parallel & Distributed Proc, Changsha 410073, Peoples R China.
   [Wang, Shiwei; Lan, Long; Zhang, Xiang; Luo, Zhigang] Natl Univ Def Technol, Coll Comp, Changsha 410073, Peoples R China.
   [Lan, Long; Zhang, Xiang] Natl Univ Def Technol, Inst Quantum Informat, State Key Lab High Performance Comp, Changsha 410073, Peoples R China.
C3 National University of Defense Technology - China; National University
   of Defense Technology - China; National University of Defense Technology
   - China
RP Lan, L (corresponding author), Natl Univ Def Technol, Coll Comp, Changsha 410073, Peoples R China.; Lan, L (corresponding author), Natl Univ Def Technol, Inst Quantum Informat, State Key Lab High Performance Comp, Changsha 410073, Peoples R China.
EM long.lan@nudt.edu.cn; zhangxiang08@nudt.edu.cn; zgluo@nudt.edu.cn
RI Zhang, Xiangyu/ABC-2896-2021
OI Zhang, Xiangyu/0000-0003-3716-4722; Lan, Long/0000-0002-4238-8985
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   [Anonymous], MAT MULTIMODAL ATTEN
   [Anonymous], 2016, ARXIV161107450
   Bird S., 2009, NATURAL LANGUAGE PRO
   Biswas P, 2005, I CONF VLSI DESIGN, P651
   Cai DL, 2018, LEC NO MULTI IND ENG, P499, DOI 10.1007/978-3-319-59280-0_40
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Cheng ZZ, 2017, IEEE I CONF COMP VIS, P5086, DOI 10.1109/ICCV.2017.543
   Fang F, 2018, MULTIMED TOOLS APPL, V77, P31159, DOI 10.1007/s11042-018-6228-6
   Gan Z, 2017, PROC CVPR IEEE, P1141, DOI 10.1109/CVPR.2017.127
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   JIN J, 2015, ARXIV150606272
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kingma D. P., 2014, arXiv
   Li LH, 2017, AAAI CONF ARTIF INTE, P4133
   Lin CY, 2004, ROUGE PACKAGE AUTOMA
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Mao J, 2014, CELL DEATH DIS, V5, DOI 10.1038/cddis.2013.515
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parikh, 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299087
   Pedersoli M, 2017, IEEE I CONF COMP VIS, P1251, DOI 10.1109/ICCV.2017.140
   Qiu ZF, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P225, DOI 10.1145/3077136.3080842
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   REN Z, 2017, PROC CVPR IEEE, P1151, DOI DOI 10.1109/CVPR.2017.128
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang Z, 2016, INT CONF ACOUST SPEE, P3236, DOI 10.1109/ICASSP.2016.7472275
   Yao T, 2017, PROC CVPR IEEE, P5263, DOI 10.1109/CVPR.2017.559
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Yu Y, 2017, PROC CVPR IEEE, P3261, DOI 10.1109/CVPR.2017.347
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
   Zhou Luowei, 2016, ARXIV1606046212
NR 36
TC 8
Z9 8
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11531
EP 11549
DI 10.1007/s11042-019-08567-0
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400012
DA 2024-07-18
ER

PT J
AU Wu, CR
   Wang, C
   Zhou, YP
   Wu, D
   Chen, M
   Wang, JH
   Qin, J
AF Wu, Canrui
   Wang, Chen
   Zhou, Yipeng
   Wu, Di
   Chen, Min
   Wang, Jessie Hui
   Qin, Jing
TI Exploiting user reviews for automatic movie tagging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Auto-tagging; Movie tagging; Tag propagation
ID ANNOTATION
AB Auto-tagging movies with apt keywords/tags is essential and indispensable for online video providers. Tagged keywords are beneficial for movie promotion and recommendation. Currently, a popular approach is to propagate tags between similar videos identified by checking image similarity, which in principle takes each video as a sequence of frames. This approach is applicable for short video clips, however it is inefficient in processing long videos such as commercial movies, because it is very rare for two commercial movies to share a large portion of similar frames even if they belong to the same genre. In this work, we propose a novel scheme to auto-tag movies with two major steps. In the first step, we only consider popular movies with tremendous amount of attentions from online users, and we tag them by extracting keywords from user reviews. In the second step, unpopular movies are tagged by propagating the tags of similar popular movies to them. The similarity is evaluated based on multiple quantified attributes, including the movie summary, the title, the country, the genre and the tags, instead of frames to avoid expensive computation cost. To evaluate the performance of our scheme, we conduct experiments using data crawled from Douban, one of the largest movie rating websites in China. Experiment results demonstrate the superiority of our scheme by significantly improving tagging performance (in terms of Precision, Recall and F-Score) in comparison to baseline schemes.
C1 [Wu, Canrui; Wang, Chen; Wu, Di] Sun Yat Sen Univ, Dept Comp Sci, Guangzhou, Peoples R China.
   [Wu, Canrui; Wang, Chen; Wu, Di] Sun Yat Sen Univ, Key Lab Machine Intelligence & Adv Comp, Minist Educ, Guangzhou, Peoples R China.
   [Zhou, Yipeng] Macquarie Univ, Dept Comp, Sydney, NSW, Australia.
   [Chen, Min] Huazhong Univ Sci & Technol, Comp Sci & Engn, Wuhan, Peoples R China.
   [Chen, Min] King Abdulaziz Univ, Jeddah, Saudi Arabia.
   [Wang, Jessie Hui] Tsinghua Univ, Inst Network Sci & Cyberspace, Beijing, Peoples R China.
   [Wang, Jessie Hui] Beijing Natl Res Ctr Informat Sci & Technol, Beijing, Peoples R China.
   [Qin, Jing] Hong Kong Polytech Univ, Sch Nursing, Kowloon, Hong Kong, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University; Macquarie University;
   Huazhong University of Science & Technology; King Abdulaziz University;
   Tsinghua University; Hong Kong Polytechnic University
RP Wang, JH (corresponding author), Tsinghua Univ, Inst Network Sci & Cyberspace, Beijing, Peoples R China.; Wang, JH (corresponding author), Beijing Natl Res Ctr Informat Sci & Technol, Beijing, Peoples R China.
EM jessiewang@tsinghua.edu.cn
RI Qin, Jing/J-9807-2016; Wang, Zhaoming/HGC-4553-2022; wu,
   di/IYS-9217-2023; Qin, Jing/JMC-1371-2023; Wu, Di/HNP-3772-2023
OI Qin, Jing/0000-0002-7059-0929; Zhou, Yipeng/0000-0003-1533-0865
CR André B, 2012, IEEE T MED IMAGING, V31, P1276, DOI 10.1109/TMI.2012.2188301
   [Anonymous], 2009, Proceedings of the 18th international conference on World wide web, DOI [10.1145/1526709.1526758, DOI 10.1145/1526709.1526758]
   [Anonymous], INT C KNOWL MAN
   [Anonymous], INT C MACH LEARN
   [Anonymous], 9 INT C INT SYST DES
   [Anonymous], IEEE INT C AC
   [Anonymous], IEEE INT C COMP VIS
   Ballan L, 2015, MULTIMED TOOLS APPL, V74, P1443, DOI 10.1007/s11042-014-1976-4
   Chen Z., 2010, P 19 INT C WORLD WID, P1079
   El Aouad S, 2016, LECT NOTES COMPUT SC, V9944, P193, DOI 10.1007/978-3-319-46140-3_15
   Jeong Won-Ki., 2011, 2011 IEEE International Conference on Computational Photography ICCP, P1
   Mihalcea R., 2004, P 2004 C EMPIRICAL M, P404, DOI DOI 10.3115/1219044.1219064
   Moxley E, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P685, DOI 10.1109/ICME.2008.4607527
   Park J, 2011, IEEE MULTIMEDIA, V18, P78, DOI 10.1109/MMUL.2010.6
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   San Pedro J, 2011, ACM T INFORM SYST, V29, DOI 10.1145/1993036.1993037
   Sevil SG, 2010, MULTIMED TOOLS APPL, V49, P81, DOI 10.1007/s11042-009-0394-5
   Shan MK, 1998, INTERNATIONAL WORKSHOP ON MULTI-MEDIA DATABASE MANAGEMENT SYSTEMS- PROCEEDINGS, P90, DOI 10.1109/MMDBMS.1998.709508
   Shen JL, 2016, MULTIMEDIA SYST, V22, P99, DOI 10.1007/s00530-014-0399-4
   Siersdorfer S, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P395, DOI 10.1145/1571941.1572010
   Tian F, 2018, MULTIMED TOOLS APPL, V77, P3473, DOI 10.1007/s11042-017-5170-3
   Tran H-T, 2013, EXTRACTION GESTION C, P461
   Vijayanarasimhan S, 2012, LECT NOTES COMPUT SC, V7576, P496, DOI 10.1007/978-3-642-33715-4_36
   Yu HF, 2014, PR MACH LEARN RES, V32
   Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019
   Zhang XM, 2012, WORLD WIDE WEB, V15, P233, DOI 10.1007/s11280-011-0132-6
   Zhao WL, 2010, IEEE T MULTIMEDIA, V12, P448, DOI 10.1109/TMM.2010.2050651
NR 27
TC 6
Z9 6
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11399
EP 11419
DI 10.1007/s11042-019-08513-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400006
DA 2024-07-18
ER

PT J
AU Jha, G
   Cecotti, H
AF Jha, Ganesh
   Cecotti, Hubert
TI Data augmentation for handwritten digit recognition using generative
   adversarial networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Neural networks; Classification; Generative
   adversarial networks
ID CHARACTER-RECOGNITION
AB Supervised learning techniques require labeled examples that can be time consuming to obtain. In particular, deep learning approaches, where all the feature extraction stages are learned within the artificial neural network, require a large number of labeled examples to train the model. Various data augmentation techniques can be performed to overcome this issue by taking advantage of known variations that have no impact on the label of an example. Typical solutions in computer vision and document analysis and recognition are based on geometric transformations (e.g. shift and rotation) and random elastic deformations of the original training examples. In this paper, we consider Generative Adversarial Networks (GAN), a technique that does not require prior knowledge of the possible variabilities that exist across examples to create novel artificial examples. In the case of a training dataset with a low number of labeled examples, which are described in a high dimensional space, the classifier may generalize poorly. Therefore, we aim at enriching databases of images or signals for improving the classifier performance by designing a GAN for creating artificial images. While adding more images through a GAN can help, the extent to which it will help is unknown, and it may degrade the performance if too many artificial images are added. The approach is tested on four datasets on handwritten digits (Latin, Bangla, Devanagri, and Oriya). The accuracy for each dataset shows that the addition of GAN generated images in the training dataset provides an improvement of the accuracy. However, the results suggest that the addition of too many GAN generated images deteriorates the performance.
C1 [Jha, Ganesh; Cecotti, Hubert] Calif State Univ Fresno Fresno State, Coll Sci & Math, Dept Comp Sci, 2576 E San Ramon MS ST 109, Fresno, CA 93740 USA.
RP Cecotti, H (corresponding author), Calif State Univ Fresno Fresno State, Coll Sci & Math, Dept Comp Sci, 2576 E San Ramon MS ST 109, Fresno, CA 93740 USA.
EM hcecotti@csufresno.edu
CR Baird HenryS., 1990, Proceedings of the IAPR Workshop on Syntactic and Structural Pattern Recognition, P38
   Battacharya U, 2005, PROC INT CONF DOC, P789
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bhowmik TK, 2006, ICIT 2006: 9TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, PROCEEDINGS, P105
   Chaudhuri BB, 1998, PATTERN RECOGN, V31, P531, DOI 10.1016/S0031-3203(97)00078-2
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Dieleman S, 2015, MON NOT R ASTRON SOC, V450, P1441, DOI 10.1093/mnras/stv632
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   GUHA R, 2019, INT J PATTERN RECOGN
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Kamble Parshuram M., 2017, International Journal of Imaging and Robotics, V17, P95
   Kamble PM, 2015, PROCEDIA COMPUT SCI, V45, P266, DOI 10.1016/j.procs.2015.03.137
   KAMBLE PM, 2016, INT C REC TRENDS IM, P93
   Keysers D, 2007, IEEE T PATTERN ANAL, V29, P1422, DOI 10.1109/TPAMI.2007.1153
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Leung MKK, 2014, BIOINFORMATICS, V30, P121, DOI 10.1093/bioinformatics/btu277
   Li W, 2016, SWARM INTELL-US, V10, P211, DOI 10.1007/s11721-016-0126-1
   Lucic M, 2018, ADV NEUR IN, V31
   Ma JS, 2015, J CHEM INF MODEL, V55, P263, DOI 10.1021/ci500747n
   OBAIDULLAH SM, 2019, DOCUMENT PROCESSING
   Pal U, 2004, PATTERN RECOGN, V37, P1887, DOI 10.1016/j.patcog.2004.02.003
   Pardeshi R, 2014, INT CONF FRONT HAND, P375, DOI 10.1109/ICFHR.2014.69
   Razali N. M., 2011, J. Stat. Model. and Anal., V2, P21, DOI DOI 10.1515/BILE-2015-0008
   Reed S, 2016, PR MACH LEARN RES, V48
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Santosh KC, 2012, PATTERN RECOGN LETT, V33, P331, DOI 10.1016/j.patrec.2011.09.040
   Schawinski K, 2017, MON NOT R ASTRON SOC, V467, pL110, DOI 10.1093/mnrasl/slx008
   SCHMIDHUBER J, 1992, NEURAL COMPUT, V4, P863, DOI 10.1162/neco.1992.4.6.863
   Simard P, 1991, P 4 INT C NEURAL INF, P895
   Simard PY, 2003, PROC INT CONF DOC, P958
   Ukil S, 2020, NEURAL COMPUT APPL, V32, P2829, DOI 10.1007/s00521-019-04111-1
   Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768
NR 35
TC 11
Z9 12
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35055
EP 35068
DI 10.1007/s11042-020-08883-w
EA APR 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000528521300003
DA 2024-07-18
ER

PT J
AU Thayammal, S
   Priyadarsini, S
   Selvathi, D
AF Thayammal, S.
   Priyadarsini, S.
   Selvathi, D.
TI Edge preserved multispectral image compression using PCA and hybrid
   transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE PCA; Shearlet transform; Tetrolet transform; Sparse approximation
AB In multispectral image compression, it is difficult to obtain sparse approximation for images with rich details. The existing methods produce better results under some constraints on image content. In order to obtain robust multispectral image compression, the Principal Component Analysis (PCA) method is used to reduce the spectral redundancy and the sparse approximation is obtained by using Extended Shearlet Transform (EST) and Tetrolet Transform(TT). The anisotropic property of EST is used to preserve smooth images with global structures of an image whereas the TT is used to preserve the local structures. The performance of proposed method is compared with the existing methods in terms of rate distortion and information preservation perspectives. The Compression Ratio (CR) and Peak Signal to Noise Ratio (PSNR) are used as rate-distortion measure. The Mean Structural Similarity Index Metric (MSSIM) and Kappa coefficient (K) are information preservation measures. The simulation results show that the proposed EPMI-HT method outperforms the existing hybrid methods for all kinds of image content at high CR with retaining edge information.
C1 [Thayammal, S.] Kalasalingam Inst Technol, Dept ECE, Krishnankoil 626126, Tamilnadu, India.
   [Priyadarsini, S.] PSR Engn Coll, Dept CSE, Sivakasi 626140, Tamilnadu, India.
   [Selvathi, D.] Mepco Schlenk Engn Coll, Dept ECE, Sivakasi 626005, Tamilnadu, India.
C3 Mepco Schlenk Engineering College
RP Thayammal, S (corresponding author), Kalasalingam Inst Technol, Dept ECE, Krishnankoil 626126, Tamilnadu, India.
EM thaya.psr@gmail.com
RI Selvathi, D./S-9745-2019
OI Selvathi, D./0000-0003-1159-3879; S, Priyadarsini/0000-0001-5325-1338;
   SUBBURAJ, THAYAMMAL/0000-0001-7094-905X
CR Alsayyh MM, 2012, INFORM KNOWLEDGE MAN, V2, P10
   Bansal Nikita., 2013, Journal of Global Research in Computer Sciences, V4, P13
   Du Q, 2007, IEEE GEOSCI REMOTE S, V4, P201, DOI 10.1109/LGRS.2006.888109
   Dwivedi A., 2006, P 9 SID, P492
   Gurpreet K, 2015, IOSR J ELECT ELECT E, V10, P53
   Hagag A, 2017, OPTIK, V131, P1023, DOI 10.1016/j.ijleo.2016.11.172
   Krommweh J, 2010, J VIS COMMUN IMAGE R, V21, P364, DOI 10.1016/j.jvcir.2010.02.011
   Lee C, 2015, IEEE GEOSCI REMOTE S, V12, P1491, DOI 10.1109/LGRS.2015.2409897
   Lim WQ, 2010, IEEE T IMAGE PROCESS, V19, P1166, DOI 10.1109/TIP.2010.2041410
   Niteesh B, 2016, INT J INNOVATIVE RES, V4, P6522
   Pejoski S, 2015, IEEE SIGNAL PROC LET, V22, P1566, DOI 10.1109/LSP.2015.2414443
   Sathik M. M., 2011, SIGNAL IMAGE PROCESS, V2, P165
   Shi CP, 2014, IEEE J-STARS, V7, P4949, DOI 10.1109/JSTARS.2014.2319304
   Shiwangi S, 2016, INT J ADV RES COMPUT, V6, P312
   Sriram B, 2012, J THEOR APPL INF TEC, V41, P175
   Su CK, 2005, IEE P-VIS IMAGE SIGN, V152, P752, DOI 10.1049/ip-vis:20050004
NR 16
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 20133
EP 20148
DI 10.1007/s11042-020-08829-2
EA APR 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000526210000003
DA 2024-07-18
ER

PT J
AU Gao, YA
   Wang, JX
   Zhang, LP
AF Gao, Yanan
   Wang, Jianxin
   Zhang, Liping
TI Robust ROI localization based on image segmentation and outlier
   detection in finger vein recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Outlier detection; ROI localization; Finger vein
   recognition
ID AUTHENTICATION; REGION; FUSION; IRIS
AB Finger vein is deemed to be a promising biological trait for individual identification. However, partially due to non-uniform collection devices and non-standard collection process, original images are polluted by lots of unfavourable factors. These negative effects increase the burden on image matching. Therefore, Region of Interest (ROI) localization plays an important role in finger vein recognition. Considering that the previous techniques are not common for all kinds of images, we propose a set of methods to obtain the ROI, which is able to remove most of negative factors, preserve more vein information and keep the stability of vein feature with less cost and fewer manual thresholds. More specifically, we propose Simplified Statistical Region Merging (SSRM) with dynamical adjustment of precision parameter to segment an image into finger body and background area. Next, in order to ensure the edge be qualified and further correct the skew angle, the novel Directional Linkage Clustering Method (DLCM) and Parameter Selection (PS) are introduced. Compared with the previous work, the number of thresholds used during the whole process is reduced to only four. The identification EER in experiments is reduced to 0.0476 on all the images in three public databases, which indicates that our method is more superior than the compared methods and performs better in the individual identification.
C1 [Gao, Yanan; Wang, Jianxin] Beijing Forestry Univ, Sch Informat Sci & Technol, Beijing 100083, Peoples R China.
   [Zhang, Liping] Chinese Acad Sci, Inst Semicond, Beijing 100083, Peoples R China.
C3 Beijing Forestry University; Chinese Academy of Sciences; Institute of
   Semiconductors, CAS
RP Wang, JX (corresponding author), Beijing Forestry Univ, Sch Informat Sci & Technol, Beijing 100083, Peoples R China.
EM gaoyn1709@163.com; wangjx@bjfu.edu.cn; zliping@semi.ac.cn
RI Zhang, Liping/ABC-7060-2021; Wang, Jianxin/AAM-4441-2020; Gao,
   Yanan/GXG-9743-2022
OI Zhang, Liping/0000-0001-6508-3757; Gao, Yanan/0000-0002-3641-5449
FU National Key R&D Program of China [2018YFC1603302]
FX This work was supported by National Key R&D Program of China
   (2018YFC1603302). We are grateful to the editor and anonymous reviewers
   for their comments in improving the quality of our article.
CR Agnihotri M, 2019, ICPRAM: PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS, P778, DOI 10.5220/0007568007780785
   [Anonymous], ICCICT2012
   [Anonymous], 2015, PROC INT C BIOMETRIC
   Brindha S., 2017, INT J RENEW ENERGY T, V4, P1298
   Ehteshami NSM, 2012, 2012 SIXTH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), P1147, DOI 10.1109/ISTEL.2012.6483159
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   Harinarayan R., 2011, 2011 Proceedings of International Conference on Emerging Trends in Electrical and Computer Technology (ICETECT 2011), P631, DOI 10.1109/ICETECT.2011.5760194
   Hui Zou, 2016, Journal of Physics: Conference Series, V680, DOI 10.1088/1742-6596/680/1/012001
   Jinfeng Yang, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P374
   Kalluri HK, 2012, LECT NOTES COMPUT SC, V7332, P217, DOI 10.1007/978-3-642-31020-1_26
   Khellat-Kihel S, 2016, APPL SOFT COMPUT, V42, P439, DOI 10.1016/j.asoc.2016.02.008
   Liang M., 2013, MATH PROBL ENG, V2013, P1
   Lu Y, 2017, FUTURE GENER COMP SY, V77, P149, DOI 10.1016/j.future.2017.07.013
   Lu Y, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P410, DOI 10.1109/CISP.2013.6744030
   Lu Y, 2013, SENSORS-BASEL, V13, P14339, DOI 10.3390/s131114339
   Ma H, 2019, INFRARED PHYS TECHN, V97, P149, DOI 10.1016/j.infrared.2018.12.021
   Matsuda Y, 2016, MACH VISION APPL, V27, P237, DOI 10.1007/s00138-015-0745-3
   Nock R, 2004, IEEE T PATTERN ANAL, V26, P1452, DOI 10.1109/TPAMI.2004.110
   Peng JY, 2014, INT C WAVEL ANAL PAT, P176, DOI 10.1109/ICWAPR.2014.6961311
   Qiu XW, 2018, IEEE T INF FOREN SEC, V13, P465, DOI 10.1109/TIFS.2017.2756598
   Rosdi BA, 2011, SENSORS-BASEL, V11, P11357, DOI 10.3390/s111211357
   Shaheed K, 2018, INFORMATION, V9, DOI 10.3390/info9090213
   Shin YW, 2010, PHYS REV B, V82, DOI 10.1103/PhysRevB.82.193101
   Sun ZN, 2014, ADV COMPUT VIS PATT, P103, DOI 10.1007/978-1-4471-6524-8_6
   Syazana-Itqan K, 2016, INDIAN J SCI TECHNOL, V9, P32, DOI [10.17485/ijst/2016/v9i32/99276, DOI 10.17485/ijst/2016/v9i32/99276]
   Tizhoosh HR, 2016, I S BIOMED IMAGING, P1185, DOI 10.1109/ISBI.2016.7493478
   Wang M, 1856, INT J PATTERN RECOGN, V32, P2
   WANG M, 2017, MULTIMED TOOLS APPL, V76, p14,93, DOI DOI 10.1007/s11042-016-4285-2
   Xi XM, 2017, PATTERN RECOGN, V66, P26, DOI 10.1016/j.patcog.2016.11.002
   Xie S, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P206, DOI 10.1109/ICIVC.2017.7984547
   Yang JF, 2019, NEUROCOMPUTING, V328, P171, DOI 10.1016/j.neucom.2018.02.098
   Yang JF, 2017, PATTERN RECOGN, V66, P34, DOI 10.1016/j.patcog.2017.01.008
   Yang JF, 2014, INFORM SCIENCES, V268, P33, DOI 10.1016/j.ins.2013.10.009
   Yang JF, 2012, PATTERN RECOGN LETT, V33, P1569, DOI 10.1016/j.patrec.2012.04.018
   Yang JF, 2012, SENSORS-BASEL, V12, P3627, DOI 10.3390/s120303627
   Yang L, 2015, INT CONF BIOMETR, P444, DOI 10.1109/ICB.2015.7139108
   Yang L, 2014, NEUROCOMPUTING, V135, P218, DOI 10.1016/j.neucom.2013.12.029
   Yang L, 2013, SENSORS-BASEL, V13, P3799, DOI 10.3390/s130303799
   Yang WM, 2014, APPL MECH MATER, V556-562, P5085, DOI 10.4028/www.scientific.net/AMM.556-562.5085
   Yin Y, 2011, DECIS ENG, P269
NR 40
TC 13
Z9 13
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 20039
EP 20059
DI 10.1007/s11042-020-08865-y
EA APR 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000526354300004
DA 2024-07-18
ER

PT J
AU Wang, XF
   Li, SJ
   Wu, WQ
AF Wang, Xiaofan
   Li, Shengjie
   Wu, Wanqing
TI Effects of medical biofeedback trainings on acute stress by hybridizing
   heart rate variability and brain imaging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain lateralization; Biofeedback; Event-related fMRI; Heart rate
   variability; Resonant frequency training
ID OBJECT DETECTION; MANAGEMENT; EXERCISE
AB In this study, active and arousal elements of emotion associated with acute stress were systematically investigated with respect to the relations between the brain activity and autonomic nervous system. In this regard, we examined the differences in short-term heart rate variability (HRV) with respect to time-frequency domain characteristics, nonlinear features, and heart rhythm patterns, when breathing volitionally in a resonant frequency (RF) respiratory with International Affective Picture Systems (IAPS) triggered negative stimulus. In this regard, a sample-based event-related functional magnetic resonance imaging (efMRI) experiments were performed to verify the dynamic changes in brain lateralisation, and 105 healthy right-handed subjects participated in the HRV study while eight of them were randomly chosen to perform small sample based efMRI test. The experimental results suggest that when experiencing negative emotions, RF-based volitional breathing is sufficient to facilitate coherence of autonomic nervous system (ANS) performance, and shifted the brain activation toward left lateralized neural activity. In combination with the previous research on cerebral correlates of emotion, this study validated the feasibility of applying HRV biofeedback in the regulation of negative emotion in healthcare settings.
C1 [Wang, Xiaofan; Li, Shengjie] Xian Univ Technol, Sch Comp Sci & Engn, Xian, Peoples R China.
   [Wu, Wanqing] Sun Yat Sen Univ, Sch Biomed Engn, Guangzhou 510006, Peoples R China.
C3 Xi'an University of Technology; Sun Yat Sen University
RP Wu, WQ (corresponding author), Sun Yat Sen Univ, Sch Biomed Engn, Guangzhou 510006, Peoples R China.
EM wuwanqing@mail.sysu.edu.cn
RI Wu, Wanqing/I-2929-2019
OI Wu, Wanqing/0000-0003-0932-8785
CR Demaree HA, 2004, PERS INDIV DIFFER, V36, P457, DOI 10.1016/S0191-8869(03)00109-0
   Dong JG, 2016, EXP THER MED, V11, P1531, DOI 10.3892/etm.2016.3104
   Gianaros PJ, 2004, PSYCHOPHYSIOLOGY, V41, P521, DOI 10.1111/1469-8986.2004.00179.x
   Gross MJ, 2016, APPL PSYCHOPHYS BIOF, V41, P263, DOI 10.1007/s10484-015-9330-9
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Jimenez Morgan S, 2017, APPL PSYCHOPHYS BIOF, V42, P1
   Kim T, 2012, MED PHYS, V39, P6921, DOI 10.1118/1.4761866
   Koenig J, 2016, NEUROSCI BIOBEHAV R, V64, P288, DOI 10.1016/j.neubiorev.2016.03.007
   Lehrer PM, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00756
   Lehrer PM, 2000, APPL PSYCHOPHYS BIOF, V25, P177, DOI 10.1023/A:1009554825745
   Pirbhulal S, 2018, COMPUT ELECTR ENG, V71, P546, DOI 10.1016/j.compeleceng.2018.08.004
   Pirbhulal S, 2018, IEEE T BIO-MED ENG, V65, P2751, DOI 10.1109/TBME.2018.2815155
   Prinsloo GE, 2014, PHYSICIAN SPORTSMED, V42, P88, DOI 10.3810/psm.2014.05.2061
   Windthorst P, 2017, J PSYCHOSOM RES, V93, P6, DOI 10.1016/j.jpsychores.2016.11.014
   Wu WQ, 2019, IEEE J BIOMED HEALTH, V23, P703, DOI 10.1109/JBHI.2018.2832069
   Wu WQ, 2015, IEEE SENS J, V15, P7087, DOI 10.1109/JSEN.2015.2470638
   Wu W, 2012, SENSORS-BASEL, V12, P13225, DOI 10.3390/s121013225
   Xiao F, 2016, TSINGHUA SCI TECHNOL, V21, P397, DOI 10.1109/TST.2016.7536717
   Xiao F, 2016, PEER PEER NETW APPL, V9, P936, DOI 10.1007/s12083-015-0354-y
   Xiao X, 2019, IEEE ACCESS, V7, P80421, DOI 10.1109/ACCESS.2019.2923464
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang H, 2017, INT J PSYCHOPHYSIOL, V120, P148, DOI 10.1016/j.ijpsycho.2017.08.002
   Zhu H, 2017, IEEE J SEL AREA COMM, V35, P1090, DOI 10.1109/JSAC.2017.2679578
NR 25
TC 4
Z9 4
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10141
EP 10155
DI 10.1007/s11042-019-08004-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600022
DA 2024-07-18
ER

PT J
AU Zhang, C
   Ou, B
   Tang, D
AF Zhang, Cheng
   Ou, Bo
   Tang, Dan
TI An improved VLC mapping method with parameter optimization for
   reversible data hiding in JPEG bitstream
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; JPEG bitstream; VLC mapping; Parameter
   optimization
ID SCHEME; PREDICTION; FRAMEWORK; IMAGES
AB The typical reversible data hiding (RDH) method for JPEG bitstream is conducted by building the mapping between the used VLCs and the unused VLCs, and will not modify the standard coding conventions. So, it can ensure not only the perfect decoding after data embedding but also preserve the file size well. However, the capacity is limited. One reason is that the variable length codes (VLC) are not fully utilized. Moreover, there lacks of an efficient optimization for the mapping design, and the existing solution is to examine various possible choices. In this paper, we propose an improved VLC mapping design and devise a method for the parameter optimization. The proposed mapping design is motivated by taking more alternative solutions into account to find the optimal mapping and increase the capacity. We redefine the optimization objective and introduce some optimization rules to prune the solution space. We investigate the mapping results and use a more flexible parameter setting to reduce the complexity. The experimental results show that, the proposed method can increase the capacity and cost a relatively low time complexity.
C1 [Zhang, Cheng; Ou, Bo; Tang, Dan] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
C3 Hunan University
RP Ou, B (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
EM zcheng@hnu.edu.cn; oubo@hnu.edu.cn; dtang@hnu.edu.cn
RI cheng, zhang/IUO-9683-2023; OU, BO/L-2212-2013; Tang, Dan/V-6478-2019
OI cheng, zhang/0000-0001-5669-162X; Ou, Bo/0000-0001-6936-9955
FU National Science Foundation of China [61872128, 61772189]; Hunan
   Provincial Natural Science Foundation of China [2018JJ3078]; Fundamental
   Research Funds for the Central Universities
FX This work was supported by the National Science Foundation of China
   (Nos. 61872128, 61772189), the Hunan Provincial Natural Science
   Foundation of China under grant No. 2018JJ3078 and the Fundamental
   Research Funds for the Central Universities.
CR Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Alrehily Ashwag, 2018, International Journal of Computer Network and Information Security, V10, P28, DOI 10.5815/ijcnis.2018.05.04
   Celik MU, 2006, IEEE T IMAGE PROCESS, V15, P1042, DOI 10.1109/TIP.2005.863053
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Chia-Chen Lin, 2010, Journal of Software, V5, P1, DOI 10.4304/jsw.5.2.214-224
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Di FQ, 2019, MULTIMED TOOLS APPL, V78, P34541, DOI 10.1007/s11042-019-08109-8
   Hu YJ, 2013, J SYST SOFTWARE, V86, P2166, DOI 10.1016/j.jss.2013.03.102
   Huang FJ, 2016, IEEE T CIRC SYST VID, V26, P1610, DOI 10.1109/TCSVT.2015.2473235
   Lee S, 2006, IEEE INT C MULT EXP
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Ma XX, 2015, J VIS COMMUN IMAGE R, V28, P71, DOI 10.1016/j.jvcir.2015.01.012
   Mobasseri BG, 2010, IEEE T IMAGE PROCESS, V19, P958, DOI 10.1109/TIP.2009.2035227
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Nikolaidis A, 2016, MULTIMED TOOLS APPL, V75, P1869, DOI 10.1007/s11042-014-2377-4
   Nikolaidis A, 2015, IET IMAGE PROCESS, V9, P560, DOI 10.1049/iet-ipr.2014.0689
   Ou B, 2016, J VIS COMMUN IMAGE R, V39, P12, DOI 10.1016/j.jvcir.2016.05.005
   Ou B, 2016, J VIS COMMUN IMAGE R, V38, P328, DOI 10.1016/j.jvcir.2016.03.011
   Ou B, 2013, J SYST SOFTWARE, V86, P2700, DOI 10.1016/j.jss.2013.05.077
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Peng F, 2012, SIGNAL PROCESS, V92, P54, DOI 10.1016/j.sigpro.2011.06.006
   Pizzolante R, 2018, COMPUT SECUR, V74, P384, DOI 10.1016/j.cose.2017.06.003
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Qian ZX, 2012, J SYST SOFTWARE, V85, P309, DOI 10.1016/j.jss.2011.08.015
   Qin C, 2019, IEEE T CIRC SYST VID, V29, P3341, DOI 10.1109/TCSVT.2018.2878026
   Qin C, 2018, SIGNAL PROCESS, V153, P109, DOI 10.1016/j.sigpro.2018.07.008
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Qiu YQ, 2018, J VIS COMMUN IMAGE R, V52, P86, DOI 10.1016/j.jvcir.2018.02.005
   Qiu YQ, 2016, IEEE SIGNAL PROC LET, V23, P130, DOI 10.1109/LSP.2015.2504464
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang C, 2010, IEEE INT C INF PROC
   Wang JX, 2014, J VIS COMMUN IMAGE R, V25, P1425, DOI 10.1016/j.jvcir.2014.04.005
   Wang K, 2013, J SYST SOFTWARE, V86, P1965, DOI 10.1016/j.jss.2013.03.083
   Wang YL, 2018, IEEE ACCESS, V6, P8882, DOI 10.1109/ACCESS.2018.2810058
   Weng SW, 2018, MULTIMED TOOLS APPL, V77, P13419, DOI 10.1007/s11042-017-4959-4
   Xie X.-Z., 2018, MULTIMED TOOLS APPL, P1
   Xuan G, 2007, INT C IM AN REC
   Zhang WM, 2015, IEEE T IMAGE PROCESS, V24, P294, DOI 10.1109/TIP.2014.2358881
   Zhang WM, 2013, IEEE T IMAGE PROCESS, V22, P2775, DOI 10.1109/TIP.2013.2257814
   Zhang XP, 2013, IEEE T MULTIMEDIA, V15, P316, DOI 10.1109/TMM.2012.2229262
   Zhenxing Qian, 2018, IEEE Transactions on Dependable and Secure Computing, V15, P1055, DOI 10.1109/TDSC.2016.2634161
NR 47
TC 7
Z9 8
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19045
EP 19062
DI 10.1007/s11042-020-08809-6
EA MAR 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000520637400001
DA 2024-07-18
ER

PT J
AU Kim, DY
   Kim, S
AF Kim, Dae-Young
   Kim, Seokhoon
TI Incoming Traffic Control of Fronthaul in 5G Mobile Network for Massive
   Multimedia Services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fronthaul; Mobile network; Traffic control; Multimeida services; Mobile
   edge cloud
ID C-RAN; ENERGY; CLOUD
AB The cloud radio access network (C-RAN) is composed of optical networks and is known to a fronthaul network. In the fronthaul network, remote radio heads (RRHs) connect to a baseband processing unit (BBU) and BBUs connect to the BBU pool in the 5G core network. Multimedia traffic in radio is transmitted to the core network through the fronthaul network. Although the fronthaul is an optical network, bandwidth of the fronthaul is insufficient for mobile multimedia services because mobile multimedia services are based on large amounts of data. Therefore, it is necessary to control the bandwidth usage in the fronthaul. In 5G mobile networks, RRHs can use a mobile edge computing (MEC) server as an edge cloud and can perform complicated operations in the MEC using knowledge of fronthaul. The proposed method controls incoming traffic to the fronthaul network using knowledge according to the network condition in the fronthaul. When the bandwidth of the fronthaul becomes full due to a large amount of traffic, incoming traffic to the fronthaul network is controlled. The MEC server acts as a buffer for incoming multimedia traffic. Through the proposed method, transmission efficiency for massive multimedia traffic in the fronthaul can be improved. The performance is validated through computer simulation.
C1 [Kim, Dae-Young] Daegu Catholic Univ, Sch Comp Software, Gyongsan 38430, South Korea.
   [Kim, Seokhoon] Soonchunhyang Univ, Dept Comp Software Engn, Asan 31538, South Korea.
C3 Catholic University of Daegu; Soonchunhyang University
RP Kim, S (corresponding author), Soonchunhyang Univ, Dept Comp Software Engn, Asan 31538, South Korea.
EM kimdy81@cu.ac.kr; seokhoon@sch.ac.kr
OI Kim, Dae-Young/0000-0003-4901-3075
FU Basic Science Research Program through the National Research Foundation
   of Korea(NRF) - Ministry of Education [NRF-2017R1D1A1B03032777];
   Soonchunhyang University Research Fund
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Education(NRF-2017R1D1A1B03032777), and this work was supported by the
   Soonchunhyang University Research Fund.
CR Afrin M, 2017, SUSTAINABILITY-BASEL, V9, DOI 10.3390/su9112127
   Bin Zikria Y, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10103626
   Checko A, 2016, J COMMUN NETW-S KOR, V18, P162, DOI 10.1109/JCN.2016.000025
   Cisco, 2016, CISC VIS NETW IND GL
   Cisco, 2017, CISC VIS NETW IND GL
   Feng L, 2018, MULTIMED TOOLS APPL, V77, P877, DOI 10.1007/s11042-016-4299-9
   Frank H, 2016, P 11 INT NETW C INC
   Hailu DH, 2018, OPT SWITCH NETW, V30, P40, DOI 10.1016/j.osn.2018.06.003
   Hu YC, 2015, 11 ETSI
   International Telecommunication Union (ITU), 2015, Y3600 ITUT
   Jin Y, 2019, MULTIMED TOOLS APPL, V78, P8911, DOI 10.1007/s11042-018-6680-3
   Kim DY, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.4406
   Kim DY, 2018, P 10 INT C INT C INT
   Kim S, 2018, COMPUT COMMUN, V118, P40, DOI 10.1016/j.comcom.2017.09.001
   MacDougall MH, 1987, SIMULATING COMPUTER
   Mach P, 2017, IEEE COMMUN SURV TUT, V19, P1628, DOI 10.1109/COMST.2017.2682318
   Mao YY, 2017, IEEE COMMUN SURV TUT, V19, P2322, DOI 10.1109/COMST.2017.2745201
   Palau CE, 2011, MULTIMED TOOLS APPL, V53, P591, DOI 10.1007/s11042-010-0516-0
   Ross SM, 2001, INLAND FISHES MISSIS
   Tran TX, 2017, IEEE COMMUN MAG, V55, P54, DOI 10.1109/MCOM.2017.1600863
   Trivedi KS, 2002, PROBABILITY STAT REL
   Wang S., 2015, BMVC
   Yu H, 2017, SUSTAINABILITY-BASEL, V9, DOI 10.3390/su9101848
   Zhang K, 2016, IEEE ACCESS, V4, P5896, DOI 10.1109/ACCESS.2016.2597169
   Zhang WW, 2014, IEEE NETWORK, V28, P67, DOI 10.1109/MNET.2014.6963807
NR 25
TC 2
Z9 2
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34443
EP 34458
DI 10.1007/s11042-020-08793-x
EA MAR 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000563173700002
DA 2024-07-18
ER

PT J
AU Jain, H
   Joshi, S
   Gupta, G
   Khanna, N
AF Jain, Hardik
   Joshi, Sharad
   Gupta, Gaurav
   Khanna, Nitin
TI Passive classification of source printer using text-line-level geometric
   distortion signatures from scanned images of printed documents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Printer forensics; Printer classification; Intrinsic signature;
   Geometric distortion; Questioned documents; Image analysis
ID DIGITAL FORENSICS; IDENTIFICATION; SECURITY
AB In this digital era, one thing that still holds the convention is a printed archive. Printed documents find their use in many critical domains such as contract papers, legal tenders and proof of identity documents. As more advanced printing, scanning and image editing techniques are becoming available, forgeries on these legal tenders pose a severe threat. Ability to efficiently and reliably identify source printer of a printed document can help a lot in reducing this menace. During printing procedure, printer hardware introduces certain distortions in printed characters' locations and shapes which are invisible to naked eyes. These distortions are referred as geometric distortions. Their profile (or signature) is generally unique for each printer and can be used for printer classification purpose. This paper proposes a set of features for characterizing text-line-level geometric distortions and presents a novel system to use them for identification of the origin of a printed document. Detailed experiments performed on a set of 14 printers demonstrate that the proposed system achieves performance of the state of the art system based on geometric distortion and gives much higher accuracy under small training size constraint. A classifier trained using 1 page/printer/font with 3 different fonts and 14 printers achieves 98.85% average classification accuracy.
C1 [Jain, Hardik; Joshi, Sharad; Gupta, Gaurav; Khanna, Nitin] Indian Inst Technol Gandhinagar IITGN, Elect Engn, Multimedia Anal & Secur MANAS Lab, Gandhinagar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Gandhinagar
RP Khanna, N (corresponding author), Indian Inst Technol Gandhinagar IITGN, Elect Engn, Multimedia Anal & Secur MANAS Lab, Gandhinagar, India.
EM hrdkjain@g@mail.com; sharad.joshi@iitgn.ac.in; gaurav_gupta@iitgn.ac.in;
   nitinkhanna@iitgn.ac.in
RI Joshi, Sharad/AAY-6565-2021; Jain, Hardik/Q-3413-2019; Jain,
   Hardik/AHI-7334-2022; Khanna, Nitin/A-2068-2013; Joshi,
   Sharad/AAY-7264-2021
OI Jain, Hardik/0000-0001-9499-8040; Jain, Hardik/0000-0001-9499-8040;
   Khanna, Nitin/0000-0001-7571-9130; Joshi, Sharad/0000-0001-9114-519X
CR Ali GN, 2003, IS&T'S NIP19: INTERNATIONAL CONFERENCE ON DIGITAL PRINTING TECHNOLOGIES, P511
   [Anonymous], P 9 IEEE INT C UB ME
   Bulan O, 2009, INT CONF ACOUST SPEE, P1401, DOI 10.1109/ICASSP.2009.4959855
   Cao Y, 2003, PATTERN RECOGN LETT, V24, P1871, DOI 10.1016/S0167-8655(03)00010-2
   Chambers J, 2015, MULTIMED TOOLS APPL, V74, P4013, DOI 10.1007/s11042-013-1809-x
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chiang PJ, 2011, IEEE T INF FOREN SEC, V6, P946, DOI 10.1109/TIFS.2011.2156789
   Chiang PJ, 2010, STUD COMPUT INTELL, V282, P145
   Chiang PJ, 2009, IEEE SIGNAL PROC MAG, V26, P72, DOI 10.1109/MSP.2008.931082
   Elkasrawi S, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P146, DOI 10.1109/DAS.2014.48
   Ferreira A, 2017, IEEE T INFORM FORENS
   Ferreira A, 2015, FORENSIC SCI INT, V247, P105, DOI 10.1016/j.forsciint.2014.11.030
   Gebhardt J, 2013, PROC INT CONF DOC, P479, DOI 10.1109/ICDAR.2013.102
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hao JY, 2015, 2015 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING, P856, DOI 10.1109/ChinaSIP.2015.7230526
   HIRSCHBERG DS, 1977, J ACM, V24, P664, DOI 10.1145/322033.322044
   Joshi S, 2018, IEEE T INF FOREN SEC, V13, P1603, DOI 10.1109/TIFS.2017.2779441
   Kee E, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P3, DOI 10.1145/1411328.1411332
   Kilby E, 2016, CONFEDERATION EUROPE
   Lampert CH, 2007, INT C COMP INT SEC I, V1, P639
   Low SH, 1998, IEEE T COMMUN, V46, P372, DOI 10.1109/26.662643
   Merrill RA, 2003, ANAL BIOANAL CHEM, V376, P1272, DOI 10.1007/s00216-003-2073-0
   Mikkilineni AK, 2005, PROC SPIE, V5681, P430, DOI 10.1117/12.593796
   Mikkilineni AK, 2011, P SOC PHOTO-OPT INS, P78
   Mikkilineni AK, 2010, P SOC PHOTO-OPT INS, P75
   Mikkilineni AK, 2004, INT SOC OPTICS PHOTO, P455
   Oliver J.F., 2002, PROC ISTS NIP18 INT, V18, P218
   Pollard S., 2015, HDB DIGITAL FORENSIC, P442, DOI [10.1002/9781118705773.ch12, DOI 10.1002/9781118705773.CH12]
   Nguyen QT, 2018, SIGNAL PROCESS-IMAGE, V62, P129, DOI 10.1016/j.image.2018.01.003
   Schreyer M, 2009, P INF FACHW INF K 27, V8, P39
   Shaffer DK, 2009, SPIE SCANNING MICROS, P73
   Shang SZ, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.2.023008
   Sharma A., 2012, SPIE NEWSROOM
   Sharma A, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2011, DOI 10.1145/3097983.3098186
   Sharma A, 2011, PROCEEDINGS OF THE 18TH ACM CONFERENCE ON COMPUTER & COMMUNICATIONS SECURITY (CCS 11), P99
   Smith R, 2007, PROC INT CONF DOC, P629, DOI 10.1109/icdar.2007.4376991
   Szabó L, 2009, ENVIRON SCI POLICY, V12, P257, DOI 10.1016/j.envsci.2009.01.011
   Tsai MS, 2016, INT J ADV MANUF TECH, V87, P279, DOI 10.1007/s00170-016-8444-4
   Tsai MJ, 2018, MULTIMED TOOLS APPL, V77, P27543, DOI 10.1007/s11042-018-5938-0
   Tsai MJ, 2018, MULTIMED TOOLS APPL, V77, P8729, DOI 10.1007/s11042-017-4771-1
   Tsai MJ, 2017, 2017 IEEE 3RD INTERNATIONAL CONFERENCE ON COLLABORATION AND INTERNET COMPUTING (CIC), P54, DOI 10.1109/CIC.2017.00019
   Tsai MJ, 2015, IEEE INT SYMP CIRC S, P2800, DOI 10.1109/ISCAS.2015.7169268
   Tsai MJ, 2014, MULTIMED TOOLS APPL, V73, P2129, DOI 10.1007/s11042-013-1642-2
   Tsai MJ, 2013, IEEE INT SYMP CIRC S, P2347, DOI 10.1109/ISCAS.2013.6572349
   Tsai MJ, 2011, IEEE INT SYMP CIRC S, P2633
   Wu YB, 2009, IEEE IMAGE PROC, P2909, DOI 10.1109/ICIP.2009.5413420
   ZHU B, 2003, P 10 ACM C COMP COMM, P145
NR 47
TC 9
Z9 9
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7377
EP 7400
DI 10.1007/s11042-019-08508-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000523441100022
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Rini, C
   Perumal, B
   Rajasekaran, MP
AF Rini, C.
   Perumal, B.
   Rajasekaran, M. Pallikonda
TI Automatic knee joint segmentation using Douglas-Rachford splitting
   method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Knee joint segmentation; Cartilage region; Proximal splitting method;
   Anisotropic filter; Douglas-Rachford algorithm
ID MAGNETIC-RESONANCE IMAGES; CARTILAGE SEGMENTATION; ARTICULAR-CARTILAGE;
   OSTEOARTHRITIS; BONE; PROGRESSION; EXTRACTION; THICKNESS; SYMPTOMS; 3-D
AB In the medical field, magnetic resonance imaging (MRI) scans are widely used for conducting research in osteoarthritis and to study about the disease of a patient. Still the MRI scans provide the details of the knee joint image of a patient, it is difficult to perform quantification of bone, cartilage, and meniscus regions. A fully automatic segmentation is required to segment knee joint, cartilage images from the MRI scan is necessary to reduce manual intervention. In this work, an automatic segmentation technique based on the proximal splitting method is presented. Douglas-Rachford splitting algorithm is employed in this paper. The knee joint structures are analyzed and the cartilage region is segmented. Then the quantization of the cartilage region is performed in which several morphological measures are computed. These measures are used to find out the growth of OA and the effects of drugs on OA.
C1 [Rini, C.; Perumal, B.; Rajasekaran, M. Pallikonda] Kalasalingam Acad Res & Educ, Dept Elect & Commun Engn, Srivilliputtur 626126, Tamil Nadu, India.
C3 Kalasalingam Academy of Research & Education
RP Rini, C (corresponding author), Kalasalingam Acad Res & Educ, Dept Elect & Commun Engn, Srivilliputtur 626126, Tamil Nadu, India.
EM rinisuresh2006@gmail.com; palanimet@gmail.com; m.p.raja@klu.ac.in
RI B, perumal/AAF-9029-2021; B, PERUMAL/ABA-3855-2021
OI M, Pallikonda Rajasekaran/0000-0001-6942-4512; ,
   perumal/0000-0003-4408-9396
CR Ababneh SY, 2011, MED IMAGE ANAL, V15, P438, DOI 10.1016/j.media.2011.01.007
   [Anonymous], INT C MED IM COMP CO
   [Anonymous], 15 IEEE INT C IM PRO
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], P 9 INT C HYBR INT S
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], INFORM COMMUNICATION
   [Anonymous], IEEE 15 INT S BIOM I
   [Anonymous], P 10 INT C CONTR AUT
   [Anonymous], P IEEE INT WORKSH MO
   [Anonymous], INT C MED IM COMP CO
   Berthiaume MJ, 2005, ANN RHEUM DIS, V64, P556, DOI 10.1136/ard.2004.023796
   Carballido-Gamio J, 2004, IEEE T MED IMAGING, V23, P36, DOI 10.1109/TMI.2003.819929
   Ding C, 2007, OSTEOARTHR CARTILAGE, V15, P479, DOI 10.1016/j.joca.2007.01.003
   Dodin P, 2011, MED BIOL ENG COMPUT, V49, P1413, DOI 10.1007/s11517-011-0838-8
   Dodin P, 2010, IEEE T BIO-MED ENG, V57, P2699, DOI 10.1109/TBME.2010.2058112
   DOUGLAS J., 1956, Trans. Amer. Math. Soc., V82, P421, DOI [10.1090/S0002-9947-1956-0084194-4, DOI 10.1090/S0002-9947-1956-0084194-4]
   Eckstein F, 2006, NMR BIOMED, V19, P822, DOI 10.1002/nbm.1063
   Felson DT, 2007, ARTHRITIS RHEUM-US, V56, P2986, DOI 10.1002/art.22851
   Fripp J, 2007, PHYS MED BIOL, V52, P1617, DOI 10.1088/0031-9155/52/6/005
   Ghosh S, 2000, P ANN INT IEEE EMBS, V22, P3174, DOI 10.1109/IEMBS.2000.901563
   Grau V, 2004, IEEE T MED IMAGING, V23, P447, DOI 10.1109/TMI.2004.824224
   Guermazi A, 2009, MED CLIN N AM, V93, P101, DOI 10.1016/j.mcna.2008.08.003
   Kauffmann C, 2003, IEEE T BIO-MED ENG, V50, P978, DOI 10.1109/TBME.2003.814539
   Liu L, 2008, LECT NOTES COMPUT SC, V5241, P296, DOI 10.1007/978-3-540-85988-8_36
   Liukkonen MK, 2017, COMPUT METHOD BIOMEC, V20, P1453, DOI 10.1080/10255842.2017.1375477
   Loeuille D, 2005, ARTHRITIS RHEUM-US, V52, P3492, DOI 10.1002/art.21373
   Muneeswaran V., 2019, Smart Intelligent Computing and Applications. Proceedings of the Second International Conference on SCI 2018. Smart Innovation, Systems and Technologies (SIST 104), P693, DOI 10.1007/978-981-13-1921-1_67
   Muneeswaran V, 2019, J SUPERCOMPUT, V75, P3158, DOI 10.1007/s11227-017-2230-4
   Muneeswaran V., 2019, Microelectronics, Electromagnetics and Telecommunications. Proceedings of the Fourth ICMEET 2018. Lecture Notes in Electrical Engineering (LNEE 521), P651, DOI 10.1007/978-981-13-1906-8_66
   Pelletier JP, 2008, OSTEOARTHR CARTILAGE, V16, pS8, DOI 10.1016/j.joca.2008.06.007
   Peterfy CG, 2008, OSTEOARTHR CARTILAGE, V16, P1433, DOI 10.1016/j.joca.2008.06.016
   Raynauld JP, 2004, ARTHRITIS RHEUM, V50, P476, DOI 10.1002/art.20000
   Ringenbach A, 2012, BIOMED ENG-BIOMED TE, V57, DOI 10.1515/bmt-2012-4500
   Shan L, 2012, 2012 9TH IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI), P1028, DOI 10.1109/ISBI.2012.6235733
   Tamez-Peña JG, 2012, IEEE T BIO-MED ENG, V59, P1177, DOI 10.1109/TBME.2012.2186612
   Tang JS, 2006, IEEE T BIO-MED ENG, V53, P896, DOI 10.1109/TBME.2006.872816
   Williams TG, 2010, IEEE T MED IMAGING, V29, P1541, DOI 10.1109/TMI.2010.2047653
   Yin Y, 2010, IEEE T MED IMAGING, V29, P2023, DOI 10.1109/TMI.2010.2058861
NR 39
TC 3
Z9 3
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6599
EP 6621
DI 10.1007/s11042-019-08303-8
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900052
DA 2024-07-18
ER

PT J
AU Hariharan, K
   Raajan, NR
AF Hariharan, K.
   Raajan, N. R.
TI Performance enhanced hyperspectral and multispectral image fusion
   technique using ripplet type-II transform and deep neural networks for
   multimedia applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; Ripplet transforms; Ripplet type-II transform; Deep neural
   network (DNN)
ID RADON-TRANSFORM; CURVES; FAMILY
AB Multispectral and hyper spectral image fusion aspires to improve the spectral information and spatial details. Previous fusion algorithms have concentrated on spectral information and spatial details, but those fused images have missed its sharpening. This paper is introduced the ripple type-II (RT-II) transform and deep neural network (DNN). RT -II transform can be decomposed both multispectral and hyper spectral images, then DNN are used for recognize the complementary features and sharpened the decomposed images. Then applied the fused rules for fuse the both images and applied inverse RT -II transform to get fused image. In this paper, the proposed method gets better entropy, standard deviation (SD), Correlation Coefficient (CC), Edge-Dependent Fusion Quality Index (EDFQI), Edge Based Similarity Measure (EBSM), Structural similarity (SSIM) as compared with other methods. The best way of analyzing the concepts of date and image fusion methods is to perform fusion based analysis in multimedia based tools.so that an end user can understand easily. The aspects like video, sound, text, animation, graphics have been elucidated by means of multimedia tools.
C1 [Hariharan, K.] SASTRA Deemed Univ, Sch Comp, Thanjavur, India.
   [Raajan, N. R.] SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Hariharan, K (corresponding author), SASTRA Deemed Univ, Sch Comp, Thanjavur, India.
EM harikalyan87@gmail.com; nrraajan@gmail.com
RI KALUVAN, HARIHARAN/AAP-8754-2020; Renga Raajan,
   Narasimhan/IST-5582-2023; KALYANARAMAN, HARIHARAN/AAD-5448-2021; N R,
   Dr. RAAJAN/HDN-4829-2022
OI KALUVAN, HARIHARAN/0000-0001-7540-6724; KALYANARAMAN,
   HARIHARAN/0000-0002-7072-8860; N R, Dr. RAAJAN/0000-0002-9537-1140
CR Amro I, 2010, INFORMATION OPTICS AND PHOTONICS: ALGORITHMS, SYSTEMS, AND APPLICATIONS, P247, DOI 10.1007/978-1-4419-7380-1_20
   Choi M, 2005, IEEE GEOSCI REMOTE S, V2, P136, DOI 10.1109/LGRS.2005.845313
   Choi Y., 2014, INT J INFORM TECHNOL, V2, P23
   CORMACK AM, 1981, P AM MATH SOC, V83, P325, DOI 10.2307/2043520
   CORMACK AM, 1982, P AM MATH SOC, V86, P293, DOI 10.2307/2043399
   Deng CZ, 2009, 2009 INTERNATIONAL CONFERENCE ON ENVIRONMENTAL SCIENCE AND INFORMATION APPLICATION TECHNOLOGY, VOL III, PROCEEDINGS,, P451, DOI 10.1109/ESIAT.2009.222
   Dong LM, 2015, NEUROCOMPUTING, V159, P268, DOI 10.1016/j.neucom.2015.01.050
   Dong ZY, 2013, COMPUT GEOSCI-UK, V60, P134, DOI 10.1016/j.cageo.2013.07.002
   Duan Chang., 2014, INT J SIGNAL PROCESS, V7, P361
   Geng P, 2016, MULTIMED TOOLS APPL, V75, P10583, DOI 10.1007/s11042-014-1942-1
   González-Audícana M, 2004, IEEE T GEOSCI REMOTE, V42, P1291, DOI 10.1109/TGRS.2004.825593
   Huang W, 2015, IEEE GEOSCI REMOTE S, V12, P1037, DOI 10.1109/LGRS.2014.2376034
   Jia Y, 2010, INT ARCH PHOTOGRAMM, V38, P314
   Murtagh F, 1998, MULTISCALE TRANSFORM, P1
   Pohl C, 1998, INT J REMOTE SENS, V19, P823, DOI 10.1080/014311698215748
   Shi H, 2010, 7 IEEE INT C FUZZ SY, P2313
   Starck JL, 2004, REDUNDANT MULTISCALE, P1
   Wang QF, 2011, PROCEDIA ENGINEER, V24, P182, DOI 10.1016/j.proeng.2011.11.2623
   Xu JHC, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTER AND COMPUTATIONAL SCIENCES (ICCCS), P271, DOI 10.1109/ICCACS.2015.7361364
   Yao W., 2008, International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, P1261
   Zheng YZ, 2007, PROCEEDINGS OF THE 5TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P362
NR 21
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3561
EP 3570
DI 10.1007/s11042-018-6174-3
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700024
DA 2024-07-18
ER

PT J
AU Raja, GM
   Thaha, M
   Latha, R
   Karthikeyan, A
AF Raja, G. Madasamy
   Thaha, Mohamed
   Latha, R.
   Karthikeyan, A.
TI Texture classification using optimized local ternary patterns with
   nonlinear diffusion as pre-processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texture classification; Optimized local ternary patterns (OLTP); Texture
   dataset; Nonlinear anisotropic diffusion
ID SEGMENTATION
AB The main focus of this paper is to improve the performance of the texture model Optimized Local Ternary Patterns (OLTP), which is known as one of the successful variants of the texture model Local Binary Patterns (LBP), a well known method for texture analysis and its applications. Generally preprocessing is used in digital image processing for reducing the unwanted noise and disturbances in such a way that it improves the quality of the image. Preprocessing not only removes the distortions but also enhances the features of the image for further processing. To achieve better recognition accuracy, the texture model OLTP was combined with a preprocessing method that uses nonlinear diffusion method as a preprocessing tool in this paper, with the hope that this idea will surely improve the local feature description and texture classification process. This nonlinear diffusion method uses two newly developed edge stopping functions for preprocessing. This proposed method is tested with two standard texture datasets namely Brodatz Dataset and Usptex dataset. The results show that the use of the preprocessing step really improved the texture classification accuracy.
C1 [Raja, G. Madasamy] Vel Tech Multi Tech Dr Rangarajan Dr Sakunthala E, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Thaha, Mohamed] JNN Inst Engn, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Latha, R.] KSK Coll Engn & Technol, Dept Elect & Commun Engn, Kumbakonam, India.
   [Karthikeyan, A.] Vel Tech Multi Tech Dr Rangarajan Dr Sakunthala E, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
C3 Vel Tech Multi Tech Dr.Rangarajan Dr.Sakunthala Engineering College; Vel
   Tech Multi Tech Dr.Rangarajan Dr.Sakunthala Engineering College
RP Raja, GM (corresponding author), Vel Tech Multi Tech Dr Rangarajan Dr Sakunthala E, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM anushpriya2004@gmail.com; thkadiri@gmail.com; lathagopal26@gmail.com;
   a.karthik1982@gmail.com
RI Rajagopalan, Dr. Latha/N-3893-2016; A, Karthikeyan/AAB-9651-2019
OI Rajagopalan, Dr. Latha/0000-0002-9874-3341; A,
   Karthikeyan/0000-0001-6290-6770; RAJA, MADASAMY/0000-0002-8410-4733;
   Thaha, Mohammed/0000-0002-8623-7388
CR Backes AR, 2012, PATTERN RECOGN, V45, P1984, DOI 10.1016/j.patcog.2011.11.009
   Bhateja V, 2016, COMPUT METH PROG BIO, V129, P125, DOI 10.1016/j.cmpb.2016.01.007
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   COHEN FS, 1991, IEEE T PATTERN ANAL, V13, P192, DOI 10.1109/34.67648
   Cula OG, 2001, IEEE C COMP VIS PATT
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Jain AK, 1996, IEEE T PATTERN ANAL, V18, P195, DOI 10.1109/34.481543
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Kim KI, 2002, IEEE T PATTERN ANAL, V24, P1542, DOI 10.1109/TPAMI.2002.1046177
   LAINE A, 1993, IEEE T PATTERN ANAL, V15, P1186, DOI 10.1109/34.244679
   Ma WY, 1998, J AM SOC INFORM SCI, V49, P633, DOI 10.1002/(SICI)1097-4571(19980515)49:7<633::AID-ASI5>3.0.CO;2-N
   Neiva MB, 2018, INT J MOD PHYS C, V29, DOI 10.1142/S0129183118500717
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliver CJ, 2000, IEEE T GEOSCI REMOTE, V38, P1095, DOI 10.1109/36.841988
   PANJWANI DK, 1995, IEEE T PATTERN ANAL, V17, P939, DOI 10.1109/34.464559
   Perona P., 1994, GEOMETRY DRIVEN DIFF, V1, P72
   Prabhu V, 2018, MULTIMED TOOLS APPL, V77, P10375, DOI 10.1007/s11042-018-5792-0
   Raghu PP, 1997, IEEE T IMAGE PROCESS, V6, P1376, DOI 10.1109/83.624953
   Raja G. Madasamy, 2013, Journal of Computer Science, V9, P1, DOI 10.3844/jcssp.2013.1.15
   Ramsey MC, 1999, J AM SOC INFORM SCI, V50, P826, DOI 10.1002/(SICI)1097-4571(1999)50:9<826::AID-ASI11>3.0.CO;2-H
   Rao AR, 1996, VISION RES, V36, P1649, DOI 10.1016/0042-6989(95)00202-2
   Sadasivam V., 2014, INT J COMPUTER APPL, V95, P22
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Thambusamy V., 2018, IntJPureApplMath, V118, P3681, DOI DOI 10.3390/CANCERS14092132
   Wei LS, 2018, COMPUT MATH METHOD M, V2018, DOI 10.1155/2018/8145713
NR 26
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3831
EP 3846
DI 10.1007/s11042-019-7197-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700040
DA 2024-07-18
ER

PT J
AU Priyanka
   Singh, G
   Singh, K
AF Priyanka
   Singh, Gurinder
   Singh, Kulbir
TI An improved block based copy-move forgery detection technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy-move forgery; Classification; Clustering; Geometric transformations
ID EFFICIENT; TRANSFORM
AB With the increase in demand for identification of authenticity of the digital images, researchers are widely studying the image forgery detection techniques. Copy-move forgery is amongst the commonly used forgery, which is performed by copying a part of an image and then pasting it on the same or different image. This results in the concealing of image content. Most of the existing copy-move forgery detection techniques are subjected to degradation in results, under the effect of geometric transformations. In this paper, a Discrete Cosine Transformation (DCT) and Singular Value Decomposition (SVD) based technique is proposed to detect the copy-move image forgery. DCT is used to transform the image from the spatial domain to the frequency domain and SVD is used to reduce the feature vector dimension. Combination of DCT and SVD makes the proposed scheme robust against compression, geometric transformations, and noise. For classification of images as forged or authentic, Support Vector Machine (SVM) classifier is used on the feature set. Once the image is detected as forged, then for the localization of forged region, K-means clustering is used on the feature vector. According to the distance threshold, similar blocks are identified and marked. The application of SVD provides stability and invariance from geometric transformations. Evaluation of the proposed scheme is done with and without post-processing operations on the images, both at the pixel level and image level. The proposed scheme outperforms the various state-of-the-art techniques of Copy-Move Forgery Detection (CMFD) in terms of accuracy, precision, recall and F-1 parameters. Moreover, the proposed scheme also provides better results against rotation, scaling, noise and JPEG compression.
C1 [Priyanka; Singh, Gurinder; Singh, Kulbir] Thapar Inst Engn & Technol, Dept Elect & Commun Engnh, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Singh, G (corresponding author), Thapar Inst Engn & Technol, Dept Elect & Commun Engnh, Patiala, Punjab, India.
EM ksingh@thapar.edu
RI Singh, Kulbir/T-7453-2019
OI Singh, Kulbir/0000-0001-8070-3395; Singh, Gurinder/0000-0002-1325-9164
CR Al-Qershi OM, 2018, MULTIMED TOOLS APPL, V77, P31807, DOI 10.1007/s11042-018-6201-4
   Alahmadi A, 2017, SIGNAL IMAGE VIDEO P, V11, P81, DOI 10.1007/s11760-016-0899-0
   Alhussein M, 2016, UKSIM INT CONF COMP, P196, DOI 10.1109/UKSim.2016.39
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], COLUMBIA IMAGE SPLIC
   [Anonymous], IM MAN DAT
   Ardizzone E., 2010, Proceedings of the 2nd acm workshop on multimedia in forensics, security and intelligence, P59
   Bashar M, 2010, IEEE Trans Image Process, DOI 10.1109/TIP.2010.2046599
   Bayram S, 2009, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.2009.4959768
   Bravo-Solorio S, 2011, SIGNAL PROCESS, V91, P1759, DOI 10.1016/j.sigpro.2011.01.022
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Davarzani R, 2013, FORENSIC SCI INT, V231, P61, DOI 10.1016/j.forsciint.2013.04.023
   Fadl SM, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P253, DOI 10.1109/VCIP.2014.7051552
   Fattah SA, 2014, MIDWEST SYMP CIRCUIT, P801, DOI 10.1109/MWSCAS.2014.6908536
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Hsu HC, 2012, PROC INT CONF ANTI
   Huang HY, 2019, EURASIP J IMAGE VIDE, V68, P1
   Lee JC, 2015, INFORM SCIENCES, V321, P250, DOI 10.1016/j.ins.2015.03.009
   Li GH, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1750
   Li L., 2013, J. Inf. Hiding Multimedia Signal Process., V4, P46
   Li YA, 2013, FORENSIC SCI INT, V224, P59, DOI 10.1016/j.forsciint.2012.10.031
   Lin C, 2019, MULTIMED TOOLS APPL, V78, P30081, DOI 10.1007/s11042-018-6922-4
   Liu YQ, 2018, MULTIMED TOOLS APPL, V77, P18269, DOI 10.1007/s11042-017-5374-6
   Lynch G, 2013, INFORM SCIENCES, V239, P253, DOI 10.1016/j.ins.2013.03.028
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Muhammad G, 2013, 2013 IEEE EUROCON, P1580
   Muhammad G, 2014, MACH VISION APPL, V25, P985, DOI 10.1007/s00138-013-0547-4
   Prakash CS, 2019, MULTIMED TOOLS APPL, V78, P23535, DOI 10.1007/s11042-019-7629-x
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Ryu SJ, 2010, INFORM HIDING, V2010, P51
   Shivakumar B., 2011, Int J Comput Sci Issues (IJCSI), V8, P199
   Singh VK, 2011, INT J ADV SCI TECHNO, V35, P93
   Uliyan DM, 2015, IEEE CONF OPEN SYST, P7, DOI 10.1109/ICOS.2015.7377269
   Zhang YS, 2015, NONLINEAR DYNAM, V82, P1831, DOI 10.1007/s11071-015-2280-1
   Zhao J, 2013, FORENSIC SCI INT, V233, P158, DOI 10.1016/j.forsciint.2013.09.013
   Zhong JL, 2019, MULTIMED TOOLS APPL, P1
NR 36
TC 23
Z9 24
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13011
EP 13035
DI 10.1007/s11042-019-08354-x
EA JAN 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000509165900004
DA 2024-07-18
ER

PT J
AU Zhuang, PX
   Ding, XH
AF Zhuang, Peixian
   Ding, Xinghao
TI Underwater image enhancement using an edge-preserving filtering Retinex
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater enhancement; Edge-preserving filtering; Retinex-based
   variational; l2 prior; Alternative optimization
ID GRADIENT DOMAIN; RESTORATION; RECOVERY
AB We develop a novel edge-preserving filtering retinex algorithm for single underwater image enhancement, in which gradient domain guided image filtering (GGF) priors of reflection and illumination are embedded into a retinex-based variational framework for promoting image structures and reducing artifacts or noise. We transform an underwater image enhancement issue into a two-phase objective function. We first employ a general retinex-based method to generate guidance reflection and illumination, and then we use GGF to fuse fine structures of guidance reflection and illumination into ideal reflection and illumination. Meanwhile, the l2 norm is efficiently imposed on GGF priors which measure gradient errors between latent and ideal estimations of reflection and illumination. Then we derive an efficient optimization scheme to address the proposed model, which is fast implemented on pixel-wise operations and requires no prior knowledge about imaging conditions. Final experiments demonstrate the effectiveness of the proposed method in structures promotion, artifacts or noise suppression, naturalness and color preservation. Compared with several leading methods, the proposed method yields better subjective results and objective assessments. Furthermore, the utility of our method is extended for enhancing sandstorm and low illumination images.
C1 [Zhuang, Peixian] Nanjing Univ Informat Sci & Technol, Jiangsu Technol & Engn Ctr Meteorol Sensor Networ, Sch Elect & Informat Engn, Jiangsu Key Lab Meteorol Observat & Informat Proc, Nanjing 210044, Peoples R China.
   [Ding, Xinghao] Xiamen Univ, Sch Informat Sci & Engn, Fujian Key Lab Sensing & Comp Smart City, Xiamen 361005, Peoples R China.
C3 Nanjing University of Information Science & Technology; Xiamen
   University
RP Zhuang, PX (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Technol & Engn Ctr Meteorol Sensor Networ, Sch Elect & Informat Engn, Jiangsu Key Lab Meteorol Observat & Informat Proc, Nanjing 210044, Peoples R China.
EM zhuangpeixian0624@163.com
FU National Natural Science Foundation of China [61701245]; Startup
   Foundation for Introducing Talent of NUIST [2243141701030]; Priority
   Academic Program Development of Jiangsu Higher Education Institutions
FX The authors would like to thank the anonymous reviewers for their
   valuable comments. The authors also would like to thank Chongyi Li, Miao
   Yang, Arcot Sowmya, Karen Panetta and Chen Gao for providing their
   available source codes and related materials. This work was supported in
   part by the National Natural Science Foundation of China under Grant
   61701245, in part by The Startup Foundation for Introducing Talent of
   NUIST 2243141701030, in part by A Project Funded by the Priority
   Academic Program Development of Jiangsu Higher Education Institutions.
CR Ancuti C., 2012, PROC CVPR IEEE, P81, DOI DOI 10.1109/CVPR.2012.6247661
   Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Chen C, 2016, LECT NOTES COMPUT SC, V9906, P576, DOI 10.1007/978-3-319-46475-6_36
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Deng LJ, 2018, IEEE T IMAGE PROCESS, V27, P4330, DOI 10.1109/TIP.2018.2839531
   Drews PLJ, 2016, IEEE COMPUT GRAPH, V36, P24, DOI 10.1109/MCG.2016.26
   Fang S, 2013, J COMPUT, V8, P904, DOI 10.4304/jcp.8.4.904-911
   Farhadifard F, 2015, INT SYMP IMAGE SIG, P48, DOI 10.1109/ISPA.2015.7306031
   Fu XY, 2017, I S INTELL SIG PROC, P789, DOI 10.1109/ISPACS.2017.8266583
   Fu XY, 2014, IEEE IMAGE PROC, P4572, DOI 10.1109/ICIP.2014.7025927
   Fu XY, 2015, IEEE T IMAGE PROCESS, V24, P4965, DOI 10.1109/TIP.2015.2474701
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Gu K, 2018, IEEE T NEUR NET LEAR, V29, P1301, DOI 10.1109/TNNLS.2017.2649101
   Gu K, 2017, IEEE T CYBERNETICS, V47, P4559, DOI 10.1109/TCYB.2016.2575544
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hitam Muhammad Suzuri, 2013, 2013 INT C COMPUTER
   Huang Y, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2360122
   Iqbal Kashif, 2007, IAENG International Journal of Computer Science, V34, P239
   Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276497, 10.1145/1239451.1239547]
   Kou F, 2015, IEEE T IMAGE PROCESS, V24, P4528, DOI 10.1109/TIP.2015.2468183
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Li ZG, 2015, IEEE T IMAGE PROCESS, V24, P120, DOI 10.1109/TIP.2014.2371234
   Liu QG, 2013, IEEE T IMAGE PROCESS, V22, P4652, DOI 10.1109/TIP.2013.2277798
   Liu X, 2017, COMPUT VIS IMAGE UND, V162, P23, DOI 10.1016/j.cviu.2017.08.002
   Lu HM, 2013, IEEE IMAGE PROC, P3412, DOI 10.1109/ICIP.2013.6738704
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Panetta K, 2016, IEEE J OCEANIC ENG, V41, P541, DOI 10.1109/JOE.2015.2469915
   Patel VM, 2012, IEEE T IMAGE PROCESS, V21, P94, DOI 10.1109/TIP.2011.2159803
   Peng YT, 2018, IEEE T IMAGE PROCESS, V27, P2856, DOI 10.1109/TIP.2018.2813092
   Peng YT, 2017, IEEE T IMAGE PROCESS, V26, P1579, DOI 10.1109/TIP.2017.2663846
   Schechner YY, 2007, IEEE T PATTERN ANAL, V29, P1655, DOI 10.1109/TPAMI.2007.1141
   Schettini R, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/746052
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Wen HC, 2013, IEEE INT SYMP CIRC S, P753, DOI 10.1109/ISCAS.2013.6571956
   Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
NR 40
TC 58
Z9 61
U1 2
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 17257
EP 17277
DI 10.1007/s11042-019-08404-4
EA JAN 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000516956700001
DA 2024-07-18
ER

PT J
AU Song, WR
   Zheng, JY
   Wu, YH
   Chen, CH
   Liu, F
AF Song, Wanru
   Zheng, Jieying
   Wu, Yahong
   Chen, Changhong
   Liu, Feng
TI Video-based person re-identification using a novel feature extraction
   and fusion technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Video; Feature representation; Hand-crafted;
   Deep-learned
ID REPRESENTATION; RECOGNITION
AB Person re-identification has received extensive attention in the academic community. In this paper, a novel multiple feature fusion network (MPFF-Net) is proposed for video-based person re-identification. The proposed network is used to obtain the robust and discriminative feature representation for describing the pedestrian in the video, which contains the hand-crafted and deep-learned parts. First, the image-level features of all consecutive frames are extracted. Then the hand-crafted branch uses these descriptors to obtain the average feature of the video and the information of frame-to-frame differences. The deep-learned branch is based on the bidirectional LSTM (BiLSTM) network. It is responsible for aggregating frame-wise representations of human regions and yielding sequence-level features. Furthermore, the problem of misalignment is taken into account in this branch. Finally, the hand-crafted and deep-learned parts are considered to be complementary, and the fusion of them can help to capture the complete information of the video. Extensive experiments are conducted on the iLIDS-VID, PRID2011 and MARS datasets. The results demonstrate that the proposed algorithm outperforms state-of-the-art video-based re-identification methods.
C1 [Song, Wanru; Zheng, Jieying; Wu, Yahong; Chen, Changhong; Liu, Feng] Nanjing Univ Posts & Telecommun, Jiangsu Key Lab Image Proc & Image Commun, Nanjing, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Liu, F (corresponding author), Nanjing Univ Posts & Telecommun, Jiangsu Key Lab Image Proc & Image Commun, Nanjing, Peoples R China.
EM songwanruu@163.com; jieyingzheng15@yahoo.com; wuyahonghaha@163.com;
   chenchh@njupt.edu.cn; liuf@njupt.edu.cn
RI chen, changhong/V-1382-2018
FU National Natural Science Foundation of China [61471201, 61501260];
   Priority Academic Program Development of Jiangsu Higher Education
   Institutions; Postgraduate Research & Practice Innovation Program of
   Jiangsu Province [KYCX18 0890]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61471201 and Grant 61501260, and in part
   by the Priority Academic Program Development of Jiangsu Higher Education
   Institutions and in part by Postgraduate Research & Practice Innovation
   Program of Jiangsu Province KYCX18 0890.
CR [Anonymous], 2010, BRIT MACHINE VISION
   [Anonymous], VIEWPOINT INVARIANT
   Bedagkar-Gala A, 2014, IMAGE VISION COMPUT, V32, P270, DOI 10.1016/j.imavis.2014.02.001
   Boulgouris NV, 2005, IEEE SIGNAL PROC MAG, V22, P78, DOI 10.1109/MSP.2005.1550191
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Dai J, 2019, IEEE T IMAGE PROCESS, V28, P1366, DOI 10.1109/TIP.2018.2878505
   Gao Y, 2017, IEEE T IMAGE PROCESS, V26, P2545, DOI 10.1109/TIP.2017.2675341
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Gong SG, 2014, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-1-4471-6296-4_1
   He ZP, 2019, MULTIMED TOOLS APPL, V78, P5863, DOI 10.1007/s11042-018-6408-4
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Huang WJ, 2018, AAAI CONF ARTIF INTE, P2273
   Kan SC, 2019, IEEE T IMAGE PROCESS, V28, P5809, DOI 10.1109/TIP.2019.2901407
   Ksibi S, 2019, MULTIMED TOOLS APPL, V78, P1583, DOI 10.1007/s11042-018-6200-5
   Kviatkovsky Igor, 2013, IEEE Trans Pattern Anal Mach Intell, V35, P1622, DOI 10.1109/TPAMI.2012.246
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li TZ, 2018, MULTIMED TOOLS APPL, V77, P21393, DOI 10.1007/s11042-017-5541-9
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu CX, 2012, LECT NOTES COMPUT SC, V7583, P391, DOI 10.1007/978-3-642-33863-2_39
   Liu H., 2017, IEEE T CIRCUITS SYST, V1, DOI [DOI 10.1109/TCSVT.2016.2637798, 10.1109/TCSVT.2016.2637798]
   Liu Hao, 2016, ARXIV160604404
   Liu K, 2015, IEEE I CONF COMP VIS, P3810, DOI 10.1109/ICCV.2015.434
   Liu YG, 2019, J VIS COMMUN IMAGE R, V58, P46, DOI 10.1016/j.jvcir.2018.11.023
   Liu Z, 2019, IEEE T CIRC SYST VID, V29, P3646, DOI 10.1109/TCSVT.2018.2883995
   Luo Y, 2016, IEEE T IMAGE PROCESS, V25, P414, DOI 10.1109/TIP.2015.2495116
   Luo Y, 2015, IEEE T KNOWL DATA EN, V27, P3111, DOI 10.1109/TKDE.2015.2445757
   Luo Y, 2015, IEEE T IMAGE PROCESS, V24, P2355, DOI 10.1109/TIP.2015.2421309
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152
   McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Prosser B., 2010, P BRIT MACH VIS C BM, DOI DOI 10.5244/C.24.21
   Roth PM, 2012, LARGE SCALE METRIC L, P2288
   Wang F, 2018, PATTERN RECOGNITION
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Wu S, 2016, The Metallogenic Mechanism of Distal Contact Pb-Zn-ag Vines in Shizhuyuan Ore District, Hunan Province, China, V2016, P1
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Xu SJ, 2017, IEEE I CONF COMP VIS, P4743, DOI 10.1109/ICCV.2017.507
   Yan YC, 2016, LECT NOTES COMPUT SC, V9910, P701, DOI 10.1007/978-3-319-46466-4_42
   You JJ, 2016, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2016.150
   Zhang W, 2019, IEEE T NEUR NET LEAR, V30, P3847, DOI 10.1109/TNNLS.2019.2899588
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zheng Liang., 2016, Person re-identification: Past, present and future
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
   Zheng ZD, 2019, IEEE T CIRC SYST VID, V29, P3037, DOI 10.1109/TCSVT.2018.2873599
   Zhou KY, 2019, IEEE I CONF COMP VIS, P3701, DOI 10.1109/ICCV.2019.00380
   Zhou SP, 2019, IEEE T IMAGE PROCESS, V28, P4671, DOI 10.1109/TIP.2019.2908065
   Zhu Xiaoke., 2016, Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, P3552
   Zhu XY, 2016, IEEE T MAGN, V52, DOI 10.1109/TMAG.2016.2519465
NR 50
TC 4
Z9 4
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12471
EP 12491
DI 10.1007/s11042-019-08432-0
EA JAN 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000507701400001
DA 2024-07-18
ER

PT J
AU Alipour, N
   Behrad, A
AF Alipour, Neda
   Behrad, Alireza
TI Semantic segmentation of JPEG blocks using a deep CNN for non-aligned
   JPEG forgery detection and localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE JPEG forgery detection and localization; Image forensics; Deep
   convolutional neural network; Semantic pixel-wise segmentation
ID COPY-MOVE FORGERY; COMPRESSION; FILTER
AB In this paper, a new approach is proposed for non-aligned JPEG forgery detection and localization. Our method is based on the semantic pixel-wise segmentation of JPEG blocks using a deep neural network. Semantic segmentation is the process of assigning each pixel of an image to a class label. We train a deep Convolutional Neural Network (CNN) to segment the boundaries of JPEG blocks. The trained deep CNN can accurately detect block boundaries related to various JPEG compressions. Therefore, non-aligned JPEG forgeries can be easily detected and localized by detecting irregularities in the segmented block boundaries. The proposed approach can detect and localize JPEG forgeries with the same and different quantization matrices as well as image forgeries with several compression stages. We tested the proposed algorithm with various forged and authentic images and compared the results with the state-of-the-art approaches. Experimental results showed that the proposed CNN-based algorithm performs well for non-aligned JPEG forgery detection and localization.
C1 [Alipour, Neda; Behrad, Alireza] Shahed Univ, Dept Elect Engn, Tehran, Iran.
C3 Shahed University
RP Behrad, A (corresponding author), Shahed Univ, Dept Elect Engn, Tehran, Iran.
EM nedalipur@gmail.com; behrad@shahed.ac.ir
RI Behrad, Alireza/F-8795-2018
OI Behrad, Alireza/0000-0002-1990-6668
CR Abdel-Basset M, 2020, MULTIMED TOOLS APPL, V79, P5419, DOI [10.1007/s11042-018-6266-0, 10.1007/s11042-018-5840-9]
   Amerini I, 2017, IEEE COMPUT SOC CONF, P1865, DOI 10.1109/CVPRW.2017.233
   Aung A, 2011, J SIGNAL PROCESS SYS, V64, P319, DOI 10.1007/s11265-010-0492-7
   Badrinarayanan V., 2017, TPAMI, DOI DOI 10.1109/TPAMI.2016.2644615
   Barni M, 2017, J VIS COMMUN IMAGE R, V49, P153, DOI 10.1016/j.jvcir.2017.09.003
   Bianchi T., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P1929, DOI 10.1109/ICIP.2011.6115848
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P842, DOI 10.1109/TIFS.2011.2170836
   Bianchi Tiziano, 2011, 2011 IEEE INT WORKSH, P1, DOI DOI 10.1109/WIFS.2011.6123159
   Bulò SR, 2014, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.2014.18
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chierchia G, 2014, IEEE T INF FOREN SEC, V9, P554, DOI 10.1109/TIFS.2014.2302078
   Dang-Nguyen D.T., 2015, P ACM MULT SYST C, P219
   Emam M, 2018, J FORENSIC SCI, V63, P102, DOI 10.1111/1556-4029.13456
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Gao Z, 2018, J VIS COMMUN IMAGE R, V56, P305, DOI 10.1016/j.jvcir.2018.10.007
   Hou Q, 2018, ARXIV180309859
   Huang FJ, 2010, IEEE T INF FOREN SEC, V5, P848, DOI 10.1109/TIFS.2010.2072921
   Korus P, 2016, IEEE T IMAGE PROCESS, V25, P1312, DOI 10.1109/TIP.2016.2518870
   Laouamer Lamri, 2015, Journal of Innovation in Digital Ecosystems, V2, P1, DOI 10.1016/j.jides.2015.10.001
   Li B., 2017, ARXIV
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li JX, 2018, MULTIMED TOOLS APPL, V77, P31895, DOI 10.1007/s11042-018-6175-2
   Li K, 2019, FRONT COMPUT SCI-CHI, V13, P1116, DOI 10.1007/s11704-018-6442-4
   Li K, 2017, APPL MATH SER B, V32, P294, DOI 10.1007/s11766-017-3466-8
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Liu QG, 2011, IEEE T INF FOREN SEC, V6, P1111, DOI 10.1109/TIFS.2011.2139209
   Liu Y., 2018, ARXIV180402864
   Liu Yun, 2019, arXiv preprint arXiv:1903.12476
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   MARRA F, 2016, 2016 IEEE INT WORKSH, P1
   Mayer O, 2016, INT CONF ACOUST SPEE, P2024, DOI 10.1109/ICASSP.2016.7472032
   Nasiri M, 2019, J VIS COMMUN IMAGE R, V58, P323, DOI 10.1016/j.jvcir.2018.12.007
   Nasiri M, 2018, MULTIMED TOOLS APPL, V77, P31363, DOI 10.1007/s11042-018-6225-9
   Pan YT, 2019, NEUROCOMPUTING, V332, P137, DOI 10.1016/j.neucom.2018.12.025
   Park D, 2018, IEEE TRANSP ELECT C, P656, DOI 10.1109/ITEC.2018.8450124
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P3948, DOI 10.1109/TSP.2005.855406
   Rawat S, 2011, AEU-INT J ELECTRON C, V65, P840, DOI 10.1016/j.aeue.2011.01.016
   Saadat S, 2015, J FORENSIC SCI, V60, P1451, DOI 10.1111/1556-4029.12853
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Shang SM, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P550, DOI 10.1109/ICDSP.2016.7868618
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Taimori A, 2017, MULTIMED TOOLS APPL, V76, P7749, DOI 10.1007/s11042-016-3409-z
   Taimori A, 2016, J MATH IMAGING VIS, V54, P269, DOI 10.1007/s10851-015-0602-z
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wang Q, 2016, EURASIP J INF SECUR, DOI 10.1186/s13635-016-0047-y
   Wang XY, 2018, PATTERN ANAL APPL, V21, P451, DOI 10.1007/s10044-016-0588-1
   Yang JQ, 2014, IEEE T INF FOREN SEC, V9, P1933, DOI 10.1109/TIFS.2014.2359368
   Zeiler Matthew D, 2012, ARXIV12125701
   Zhang CX, 2010, LECT NOTES COMPUT SC, V6314, P708, DOI 10.1007/978-3-642-15561-1_51
   Zhang H, 2017, ALGORITHMS, V10, DOI 10.3390/a10010027
   Zhang W, 2009, IEEE INT CON MULTI, P1042, DOI 10.1109/ICME.2009.5202676
   Zhang Ya-Qin, 2002, Video processing and communications, V1
   Zhao B, 2019, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2019), DOI 10.1145/3331453.3361281
NR 55
TC 11
Z9 12
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 8249
EP 8265
DI 10.1007/s11042-019-08597-8
EA JAN 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000505414100003
DA 2024-07-18
ER

PT J
AU Salimi, L
   Haghighi, A
   Fathi, A
AF Salimi, Ladan
   Haghighi, Amir
   Fathi, Abdolhossein
TI A novel watermarking method based on differential evolutionary algorithm
   and wavelet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Optimization; DE algorithm; DWT; Authentication
ID DISCRETE WAVELET; ROBUST; SCHEME; CLASSIFICATION
AB In this paper, a new Watermarking method based on the optimization framework and discrete wavelet transform (DWT) is presented. In this method, first, the watermark image is divided into several blocks. Then, using differential evolution (DE) algorithm, an appropriate location for each of these blocks is found in the cover image. In the proposed method, the results of the DE algorithm, which is needed for the reconstruction phase are also embedded as a vector in the cover image under the wavelet domain. Also, to achieve the highest PSNR in the reconstruction phase, the optimal values for Alpha-blending coefficients (used in the embedding and extraction process) are determined with the multi-objective DE-based optimization algorithm. Several experiments are presented to illustrate the imperceptibility and robustness of the proposed algorithm against different types of attacks, including salt and pepper, Gaussian, median filtering, rescaling, compression, and rotation. The obtained results are also compared with state-of-the-art methods and show the superiority of the proposed method in most cases.
C1 [Salimi, Ladan; Haghighi, Amir] Razi Univ, Dept Math, Fac Sci, Kermanshah 67149, Iran.
   [Fathi, Abdolhossein] Razi Univ, Dept Comp Engn & Informat Technol, Kermanshah, Iran.
C3 Razi University; Razi University
RP Haghighi, A (corresponding author), Razi Univ, Dept Math, Fac Sci, Kermanshah 67149, Iran.
EM a.haghighi@razi.ac.ir
RI Fathi, Abdolhossein/ABH-8117-2020
OI Fathi, Abdolhossein/0000-0003-0387-5518; Haghighi,
   Amir/0000-0001-8928-9557
CR AL-Nabhani Y, 2015, J KING SAUD UNIV-COM, V27, P393, DOI 10.1016/j.jksuci.2015.02.002
   Alnazzawi T, 2019, INT J ADV COMPUT SC, V10, P191
   Chang ZY, 2018, J FORESTRY RES, V29, P1789, DOI 10.1007/s11676-017-0572-7
   Chen ZG, 2018, IEEE T MULTIMEDIA, V20, P1973, DOI 10.1109/TMM.2018.2794985
   Ernawan F, 2020, VISUAL COMPUT, V36, P19, DOI 10.1007/s00371-018-1567-x
   Ernawan F, 2018, IEEE ACCESS, V6, P20464, DOI 10.1109/ACCESS.2018.2819424
   Fan FL, 2018, GEO-SPAT INF SCI, V21, P311, DOI 10.1080/10095020.2018.1523341
   Fatahbeygi A, 2019, J INF SECUR APPL, V45, P71, DOI 10.1016/j.jisa.2019.01.005
   Gangadhar Y, 2018, BIOMED SIGNAL PROCES, V43, P31, DOI 10.1016/j.bspc.2018.02.007
   Ghafoor A., 2012, RADIOENGINEERING, V21, P1246
   Jagadeesh B, 2015, PROCEDIA COMPUT SCI, V46, P1618, DOI 10.1016/j.procs.2015.02.095
   Liu XL, 2018, IEEE T CIRC SYST VID, V28, P1047, DOI 10.1109/TCSVT.2016.2633878
   Moosazadeh M, 2019, J INF SECUR APPL, V47, P28, DOI 10.1016/j.jisa.2019.04.001
   Ramamurthy N, 2013, INT J COMPUT SCI NET, V13, P111
   Rasti P, 2016, J VIS COMMUN IMAGE R, V38, P838, DOI 10.1016/j.jvcir.2016.05.001
   Seetha C, 2013, PROCEDIA COMPUT SCI, V21, P302, DOI 10.1016/j.procs.2013.09.040
   Singh AK, 2018, FUTURE GENER COMP SY, V86, P926, DOI 10.1016/j.future.2016.11.023
   Singh RK, 2015, PROCEDIA COMPUT SCI, V54, P612, DOI 10.1016/j.procs.2015.06.071
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Taheri A, 2014, INT J ENHANC RES SCI, V3, P184
   Tan Y, 2019, IEEE ACCESS, V7, P25026, DOI 10.1109/ACCESS.2019.2896304
   Thanki R, 2019, J INF SECUR APPL, V46, P231, DOI 10.1016/j.jisa.2019.03.017
   Yao YZ, 2019, SIGNAL PROCESS, V164, P386, DOI 10.1016/j.sigpro.2019.06.034
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhu YF, 2015, INT J SMART SENS INT, V8, P199
NR 25
TC 18
Z9 19
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11357
EP 11374
DI 10.1007/s11042-019-08455-7
EA JAN 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000505414100001
DA 2024-07-18
ER

PT J
AU Jeromel, A
   Zalik, B
AF Jeromel, Aljaz
   Zalik, Borut
TI An efficient lossy cartoon image compression method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cartoon images; Image compression; Chain codes; String transformations
ID CHAIN CODE
AB This paper introduces a new lossy approach for compression of cartoon images. The image is firstly partitioned into regions of roughly the same colour. The chain codes are then determined of all regions. The sequence of the obtained chain code symbols is transformed with the Burrows-Wheeler Transform, Move-To-Front transform, and compressed with Run-Length Encoding. In the final step, an arithmetic encoder may be used to compress the obtained binary stream additionally. The proposed algorithm is asymmetric, meaning that the decompression does not reverse all the steps of the compression procedure. The experimental results have shown that the described method produces considerably better compression ratios than JPEG, JPEG2000, WebP, SPIHT, PNG, and two of the algorithms specialised in compression of cartoon images: the algorithm using quad-tree, and RS-LZ algorithm.
C1 [Jeromel, Aljaz; Zalik, Borut] Fac Elect Engn & Comp Sci, Koroska Cesta 46, SI-2000 Maribor, Slovenia.
C3 University of Maribor
RP Jeromel, A (corresponding author), Fac Elect Engn & Comp Sci, Koroska Cesta 46, SI-2000 Maribor, Slovenia.
EM aljaz.jeromel@um.si
OI Jeromel, Aljaz/0000-0003-3502-2229
FU Slovenian Research Agency [J2-8176, P2-0041]
FX This work was supported by the Slovenian Research Agency under Grants
   J2-8176 and P2-0041.
CR Adjeroh D., 2008, The Burrows-Wheeler Transform:: Data Compression, Suffix Arrays, and Pattern Matching
   [Anonymous], THESIS
   BODDEN E., 2007, Arithmetic coding revealed
   Boutell T, 2003, PORTABLE NETWORK GRA
   Bribiesca E, 1999, PATTERN RECOGN, V32, P235, DOI 10.1016/S0031-3203(98)00132-0
   ELIAS P, 1987, IEEE T INFORM THEORY, V33, P3, DOI 10.1109/TIT.1987.1057251
   Freeman H., 1961, IRE T ELECTRON COMPU, V10, P260, DOI [DOI 10.1109/TEC.1961.5219197, 10.1109/TEC.1961.5219197]
   Howard P. G., 1992, Image and text compression, P85
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Li ZJ, 2009, 2009 ASIA-PACIFIC CONFERENCE ON INFORMATION PROCESSING (APCIP 2009), VOL 2, PROCEEDINGS, P545, DOI 10.1109/CSIE.2009.672
   López-Valdez HH, 2016, DIGIT SIGNAL PROCESS, V51, P73, DOI 10.1016/j.dsp.2016.01.007
   Rabbat Richard, 2010, CHROMIUM BLOG
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Said Amir, 2003, Handbook, Lossless Compression Khalid Sayood, P101
   Salomon D, 2010, DATA COMPRESSION COM
   Sánchez-Cruz H, 2005, OPT ENG, V44, DOI 10.1117/1.2052793
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   Torbert S, 2016, APPL COMPUTER SCI, P2
   Tsai YC, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P456, DOI 10.1109/MMSP.2006.285350
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zalik B, 2016, J VIS COMMUN IMAGE R, V38, P186, DOI 10.1016/j.jvcir.2016.03.001
   Zalik B, 2016, DIGIT SIGNAL PROCESS, V53, P1, DOI 10.1016/j.dsp.2016.03.002
NR 23
TC 11
Z9 11
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 433
EP 451
DI 10.1007/s11042-019-08126-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600018
OA hybrid
DA 2024-07-18
ER

PT J
AU Kashef, SMI
   Abd El Hafez, AAA
   Sarhan, NI
   El-Shal, AO
   Ata, MM
   Ashour, AS
   Dey, N
   Abd Elnaby, MM
   Sherratt, RS
AF Kashef, Shaima Mostafa Ibrahim
   Abd El Hafez, Amal Ali Ahmed
   Sarhan, Naglaa Ibrahim
   El-Shal, AWatif Omar
   Ata, Mohamed Maher
   Ashour, Amira S.
   Dey, Nilanjan
   Abd Elnaby, Mustafa M.
   Sherratt, R. Simon
TI Automated image analysis system for renal filtration barrier integrity
   of potassium bromate treated adult male albino rat
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Potassium bromate; Glomerular filtration barrier; Renal recovery;
   Morphometrics; Morphological operations; Euclidean distance
ID SEGMENTATION; TISSUE
AB Potassium bromate (KBrO3) is a potent nephrotoxic agent that leads to a significant decrease in the activities of renal antioxidant capacity, antioxidant loss and restoration of the renal dysfunction. Several measurements are used to examine the kidney status, including the base width of the foot, the slit pore diameter, and the glomerular basement membrane thickness of the kidney. In this work, morphometric analysis based on image processing is carried out to assess the filtration barrier integrity parameters, which indicates the degree of recovery against the nephrotoxic effect of the KBrO3 on the renal cortex of adult male albino rat and assesses the capability of the renal cortex to recover after its cessation. The morphometric methods based proposed image analysis system enabled the identification of the renal status of different groups, namely the control, potassium bromate affected, and the recovered groups, according to the variation of the measured parameters is a powerful tool. The proposed image analysis system provided a radical geometric morphometrics, which includes morphological operations and structuring element processes in order to identify the glomerular filtration barrier and the feet for further measurements in each case study. The results established that the average lengths of the feet in the histological microscopic images are 465.2397 nm, 278.189 nm, and 393.2347 nm for the control, KBrO3 affected rats and the recovered rats; respectively.
C1 [Kashef, Shaima Mostafa Ibrahim; Abd El Hafez, Amal Ali Ahmed; Sarhan, Naglaa Ibrahim; El-Shal, AWatif Omar] Tanta Univ, Dept Histol Dept, Fac Med, Tanta, Egypt.
   [Ata, Mohamed Maher] MISR Higher Inst Engn & Technol, Mansoura, Egypt.
   [Ashour, Amira S.; Abd Elnaby, Mustafa M.] Tanta Univ, Dept Elect & Elect Commun Engn, Fac Engn, Tanta, Egypt.
   [Dey, Nilanjan] Techno India Coll Technol, Dept Informat Technol, Rajarhat, India.
   [Sherratt, R. Simon] Univ Reading, Dept Biomed Engn, Reading RG6 6AY, Berks, England.
C3 Egyptian Knowledge Bank (EKB); Tanta University; Egyptian Knowledge Bank
   (EKB); Tanta University; University of Reading
RP Ashour, AS (corresponding author), Tanta Univ, Dept Elect & Elect Commun Engn, Fac Engn, Tanta, Egypt.
EM amirasashour@yahoo.com
RI Deyab, Mustafa/B-4350-2019; Ata, Mohamed Maher/AAD-2112-2021; Ashour,
   Amira S./T-5454-2019; Kashef, Shaimaa/JKJ-4824-2023
OI Deyab, Mustafa/0000-0001-8281-1840; Ata, Mohamed
   Maher/0000-0003-4151-9717; Ashour, Amira S./0000-0003-3217-6185; Kashef,
   Shaimaa/0000-0002-3228-2677
CR Ahmad MK, 2012, FOOD CHEM, V134, P980, DOI 10.1016/j.foodchem.2012.03.004
   Ahmed SS, 2017, MED BIOL ENG COMPUT, V55, P101, DOI 10.1007/s11517-016-1508-7
   Altoom NG, 2017, SAUDI J BIOL SCI
   [Anonymous], 2016, Int J Electr Comput Eng
   [Anonymous], 2004, AUTOMATED CANC DIAGN
   Callahan PG, 2018, ULTRAMICROSCOPY, V186, P49, DOI 10.1016/j.ultramic.2017.11.004
   Dimkpa D., 2012, Tropical Journal of Medical Research, V16, P20
   El-Gerbed MSA, 2014, TOXICOL IND HEALTH, V30, P160, DOI 10.1177/0748233712448115
   Guha M, 2007, FASEB J, V21, P3355, DOI 10.1096/fj.06-6713com
   HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7
   Hassan I, 2019, ENVIRON SCI POLLUT R, V26, P9966, DOI 10.1007/s11356-019-04443-4
   Hemalatha S, 2017, INT J AMBIENT COMPUT, V8, P58, DOI 10.4018/IJACI.2017070104
   Humphries SM, 2016, MED BIOL ENG COMPUT, V54, P899, DOI 10.1007/s11517-015-1445-x
   Kayser K, 2006, DIAGN PATHOL, V1, DOI 10.1186/1746-1596-1-10
   Kriti, 2016, INTEL SYST REF LIBR, V96, P159, DOI 10.1007/978-3-319-21212-8_7
   Li JJ, 2007, KIDNEY INT, V72, pS36, DOI 10.1038/sj.ki.5002384
   Li ZR, 2017, NEURAL COMPUT APPL, V28, P613, DOI 10.1007/s00521-016-2707-8
   Peter SJ, 2017, BIOMED PHARMACOTHER, V88, P11, DOI 10.1016/j.biopha.2017.01.032
   Rangan GK, 2007, NEPHROLOGY, V12, P553, DOI 10.1111/j.1440-1797.2007.00855.x
   Roy P, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTROL, INSTRUMENTATION, COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICCICCT), P1182, DOI 10.1109/ICCICCT.2014.6993140
   Satapathy SC, 2018, NEURAL COMPUT APPL, V29, P1285, DOI 10.1007/s00521-016-2645-5
   Sertel O, 2009, IEEE ENG MED BIO, P1433, DOI 10.1109/IEMBS.2009.5332910
   Sharma K, 2017, INT J AMBIENT COMPUT, V8, P52, DOI 10.4018/IJACI.2017040104
   Shiloh R, 2018, ULTRAMICROSCOPY, V189, P46, DOI 10.1016/j.ultramic.2018.03.016
   Succar L, 2016, INT J NEPHROL RENOV, V9, P297, DOI 10.2147/IJNRD.S113071
   Wright SI, 2015, ULTRAMICROSCOPY, V159, P81, DOI 10.1016/j.ultramic.2015.08.001
   Zhang Y, 2011, CHEM-BIOL INTERACT, V189, P186, DOI 10.1016/j.cbi.2010.12.011
NR 27
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7559
EP 7575
DI 10.1007/s11042-019-08589-8
EA DEC 2019
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000504164400003
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Kumar, A
   Bhadauria, HS
   Singh, A
AF Kumar, Anuj
   Bhadauria, H. S.
   Singh, Annapurna
TI Semi-supervised OTSU based hyperbolic tangent Gaussian kernel fuzzy
   C-mean clustering for dental radiographs segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Otsu thresholding; Fuzzy C-means clustering; Dental radiographs; Kernel;
   Semi-supervised fuzzy clustering
ID X-RAY IMAGES; MEANS ALGORITHM; FRACTURE; CANALS
AB Dental periapical X-ray image (DXRI) segmentation is an important process to examine dental images towards diagnosing medical systems is an essential operation within practical dentistry for periodontitis recognition. However, traditional clustering algorithms in image processing frequently accept deficiencies in finding teeth sample boundaries and parameters. The presentation related to clustering is improved while further data produced with the user. In DXRI segmentation, semi supervised fuzzy clustering which is a new collective scheme. Initially, pre-processing is done for the input X-Ray image in order to minimize error. Specifically, Otsu's method divide the dental X-Ray image into background and foreground regions. Here, the chosen FCM to separate the teeth regions commencing on the preceding steps. A Semi-supervised Hyperbolic Tangent Gaussian kernel Fuzzy C-Means algorithm (HTGkFCM) is preferred so as to increase an outcome that is optimum than compared to the traditional methods. So, current method is less sensitive to noise with robustness. Real datasets for the implementation on the proposed framework with cluster validity computation such as, Davies-Bouldin (DB), Segmentation Accuracy (SA), Simplified Silhouete Width Criterion (SSWC), processing time, PBM and Mean Absolute Error (MAE). So the proposed work has been enhanced in terms of 7%, 2%, 5%, 6%, 3% and 30% than the state-of-the-art works. Simulation outcome shows the quality of clustering in the framework have higher accuracy and more reliable than other clustering methods.
C1 [Kumar, Anuj; Bhadauria, H. S.; Singh, Annapurna] Govind Ballabh Pant Engn Coll, Dept Comp Sci & Engn, Garhwal, Uttarakhand, India.
RP Kumar, A (corresponding author), Govind Ballabh Pant Engn Coll, Dept Comp Sci & Engn, Garhwal, Uttarakhand, India.
EM dranujdhiman@gmail.com
RI Kumar, Anuj/AAT-6097-2020
OI Kumar, Anuj/0000-0001-8493-1539
CR Ahmad AS, 2010, IEEE EMBS C, P400
   Ahmad SAB, 2015, 2015 IEEE 6TH CONTROL AND SYSTEM GRADUATE RESEARCH COLLOQUIUM (ICSGRC), P87, DOI 10.1109/ICSGRC.2015.7412470
   Ali M, 2018, EXPERT SYST APPL, V91, P434, DOI 10.1016/j.eswa.2017.09.027
   [Anonymous], 2002, ORAL RADIOL
   [Anonymous], POVERTY GENDER MIGRA
   Aoki EM, 2015, J ENDODONT, V41, P1555, DOI 10.1016/j.joen.2015.06.015
   Baldwin D, 2004, COMPUT PHYS COMMUN, V162, P203, DOI 10.1016/j.cpc.2004.07.002
   Bandyopadhyay O, 2016, COMPUT METH PROG BIO, V123, P2, DOI 10.1016/j.cmpb.2015.09.013
   Barone S, 2015, COMPUT MED IMAG GRAP, V43, P112, DOI 10.1016/j.compmedimag.2015.01.005
   Barton DJ, 2003, ORAL SURG ORAL MED O, V96, P223, DOI 10.1016/S1079-2104(03)00061-1
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Bhatia A, 2014, ADV COMPUTING COMMUN
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Deng L, 2016, INT SYMP PARA DISTR, P1, DOI 10.1109/ISPDC.2016.9
   Grira N, 2008, PATTERN RECOGN, V41, P1834, DOI 10.1016/j.patcog.2007.10.004
   Gumus E, 2016, SIGNAL IMAGE VIDEO P, V10, P1073, DOI 10.1007/s11760-016-0861-1
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Huang CC, 2015, J DENT SCI, V10, P227, DOI 10.1016/j.jds.2015.01.002
   Kaufman L., 2009, FINDING GROUPS DATA
   Son LH, 2016, EXPERT SYST APPL, V46, P380, DOI 10.1016/j.eswa.2015.11.001
   Ludlow J, 2011, ORAL RADIOLOGY ENDOD, V91, P109
   Norouzi A., 2014, INT J MED HLTH BIOME, V8, P182
   Pakhira MK, 2004, PATTERN RECOGN, V37, P487, DOI 10.1016/j.patcog.2003.06.005
   Phen-Lan Lin, 2012, 2012 International Conference on Machine Learning and Cybernetics (ICMLC 2012). Proceedings, P1821, DOI 10.1109/ICMLC.2012.6359652
   puram K, 2011, IEEE T FUZZY SYST, V3, P29
   Rodrigues ÉO, 2016, COMPUT METH PROG BIO, V123, P109, DOI 10.1016/j.cmpb.2015.09.017
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Stokbro K, 2016, INT J ORAL MAX SURG, V45, P8, DOI 10.1016/j.ijom.2015.07.010
   van Dael M, 2016, POSTHARVEST BIOL TEC, V112, P205, DOI 10.1016/j.postharvbio.2015.09.020
   Wang YM, 2015, INT J ORAL MAX SURG, V44, P1197, DOI 10.1016/j.ijom.2015.03.014
   Yang MS, 2008, PATTERN RECOGN LETT, V29, P1713, DOI 10.1016/j.patrec.2008.04.016
   Yasunori E, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3, P1119, DOI 10.1109/FUZZY.2009.5277177
   Yin XS, 2012, KNOWL-BASED SYST, V35, P304, DOI 10.1016/j.knosys.2012.05.016
   Yu LJ, 2008, PROCEEDINGS OF FIRST JOINT INTERNATIONAL PRE-OLYMPIC CONFERENCE OF SPORTS SCIENCE AND SPORTS ENGINEERING, VOL I, P6
   Zhang DQ, 2004, ARTIF INTELL MED, V32, P37, DOI [10.1016/j.artmed.2004.01.012, 10.1016/j.artmed. 2004.01.012]
   Zhao M., 2006, 2005 IEEE Engineering in Medicine and Biology 27th Annual Conference, P654
   Zhou C, 2015, CYB TECHN AUT CONTR
NR 37
TC 11
Z9 12
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2745
EP 2768
DI 10.1007/s11042-019-08268-8
EA DEC 2019
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000500178200001
DA 2024-07-18
ER

PT J
AU Aguilar, IA
   Sementille, AC
   Sanches, SRR
AF Aguilar, Ivan A.
   Sementille, Antonio C.
   Sanches, Silvio R. R.
TI A low-cost virtual studio based on Augmented Reality for video
   production
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual studio; Augmented Reality; Scene composition; Production
   pipeline
ID ARCHITECTURE
AB Film, television, and Internet productions have generated content that combines real and virtual elements in the same scene. In a traditional production pipeline, virtual elements are inserted only in the post-production stage, and consequently, these elements are only visualized after every editing process is finalized. This approach can cause problems in situations such as ones where an actor acts alongside virtual characters, due to the lack of precise reference for gaze direction, for example. Such a problem, in the traditional production pipeline, can be identified only in the post-production stage. This can make production more expensive if there is a need to recruit the actors again and reassemble the infrastructure. Costs can also be avoided if part of the production team can follow along with certain retakes or even the entire production stage remotely. In addition, if the generated content can be quickly refined and made available to all the staff still in the production stage, the post-production stage can be considerably simplified. In this paper, we present a low-cost virtual studio called ARStudio that offers a set of functionalities similar to those of professional virtual studios. In addition, our system allows the production team to remotely follow the production stage and allows content refinements to be carried out quickly through tools, usually used in the post-production stage, that are integrated into the system.
C1 [Aguilar, Ivan A.; Sementille, Antonio C.] Univ Estadual Paulista, Bauru, SP, Brazil.
   [Sanches, Silvio R. R.] Univ Tecnol Fed Parana, Cornelio Procopio, Brazil.
C3 Universidade Estadual Paulista; Universidade Tecnologica Federal do
   Parana
RP Sanches, SRR (corresponding author), Univ Tecnol Fed Parana, Cornelio Procopio, Brazil.
EM silviosanches@utfpr.edu.br
RI Aguilar, Ivan Abdo/AAO-4316-2020; Sanches, Silvio RR/J-6357-2013
OI Sanches, Silvio/0000-0003-3635-7477; Aguilar, Ivan/0000-0002-8735-4041;
   Sementille, Antonio Carlos/0000-0002-4337-514X
CR [Anonymous], 2015, P 6 ACM MULTIMEDIA S, DOI DOI 10.1145/2713168.2713195
   Barbosa ECB, 2015, THESIS
   Blonde L, 1996, IEEE MULTIMEDIA, V3, P18, DOI 10.1109/93.502291
   Boutaba R, 2002, MULTIMED TOOLS APPL, V16, P99, DOI 10.1023/A:1013245819429
   Cho H, 2017, P IEEE VIRT REAL ANN, P353, DOI 10.1109/VR.2017.7892322
   De Gaspari Tiago, 2014, P 13 ACM SIGGRAPH IN, P17, DOI [10.1145/2670473.2670491, DOI 10.1145/2670473.2670491]
   de Goussencourt T, 2015, IEEE IMAGE PROC, P4146, DOI 10.1109/ICIP.2015.7351586
   Feng CX, 2019, 2019 2ND IEEE CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2019), P480, DOI 10.1109/MIPR.2019.00097
   Gibbs S, 1998, IEEE MULTIMEDIA, V5, P18, DOI 10.1109/93.664740
   Hach Thomas, 2017, Motion Imaging Journal, V126, P43, DOI 10.5594/JMI.2016.2632398
   Helzle VA, 2015, DIGITAL REPRESENTATI
   HIT Lab NZ, 2018, ARTOOLKIT
   Hughes JF., 2014, Computer Graphics: Principles and Practice, V3
   Industrial Light & Magic, 2018, OPENEXR
   Méndez R, 2018, MULTIMED TOOLS APPL, V77, P18999, DOI 10.1007/s11042-017-5353-y
   Microsoft, 2018, KIN TOOLS RES
   Natural Point, 2018, NAT POINT
   Northam L, 2012, ACM SIGGRAPH 2012 PO, DOI 10.1145/2342896.2343036
   Owen CB, 2006, HDB VIDEO DATABASES
   Owens J., 2012, TELEVISION PRODUCTIO
   Reinhard E., 2006, High Dynamic Range Imaging, P187
   Rosenegger D, 2010, MOL BRAIN, V3, DOI 10.1186/1756-6606-3-9
   Sanches S. R. R., 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P49, DOI 10.1109/WACV.2012.6163037
   Sanchez-Gordon S., 2013, Proceedings of the International Conference on Information Technology Based Higher Education and Training ITHET, P1
   Saraiji Y, 2019, UNITYCAM
   SHIMODA S, 1989, IEEE T BROADCAST, V35, P357, DOI 10.1109/11.40835
   The Vuforia Engine Team, 2019, VUFORIA DEV PORTAL
   Thomas G, 2006, INT WORKSH MIX REAL, P31
   Trottnow J, 2015, CVMP 2015: PROCEEDINGS OF THE 12TH EUROPEAN CONFERENCE ON VISUAL MEDIA PRODUCTION, DOI 10.1145/2824840.2824851
   Ultrahaptics Ltd, 2018, LEAP MOT
   Unity Technologies, 2019, Unity
   Van Den Bergh F., 1999, South African Computer Journal, P155
   Wojdala A, 1998, IEEE MULTIMEDIA, V5, P50, DOI 10.1109/93.664742
   Yang K, 2015, MULTIMED TOOLS APPL, V74, P11631, DOI 10.1007/s11042-014-2253-2
NR 34
TC 3
Z9 3
U1 5
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33899
EP 33920
DI 10.1007/s11042-019-08064-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600059
DA 2024-07-18
ER

PT J
AU Ameur, M
   Habba, M
   Jabrane, Y
AF Ameur, Mustapha
   Habba, Maryam
   Jabrane, Younes
TI A comparative study of nature inspired optimization algorithms on
   multilevel thresholding image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial tree algorithm; Particle swarm optimization; Genetic
   algorithm; Cultural algorithm; Cuckoo search algorithm; Levine and Nazif
   intra class uniformity criterion; Multilevel image thresholding
ID PSO
AB In this paper, five successful nature inspired algorithms; the artificial tree algorithm (AT), the particle swarm optimization (PSO), the genetic algorithm (GA), the cultural algorithm (CA), and the cuckoo search algorithm (CS) have been compared on multilevel image thresholding. The segmentation process is based on the Levine and Nazif intra class uniformity criterion which is seen as an optimization problem. The comparison performances are in terms of the value of the objectif function, the peak signal to noise ratio (PSNR) and the computation time. Empirical results over different benchmark images for different threshold numbers reveal the robustness, the reliability and the rapidity of the cultural algorithm (CA).
C1 [Ameur, Mustapha; Habba, Maryam; Jabrane, Younes] Cadi Ayyad Univ, GECOS Lab, Marrakech, Morocco.
C3 Cadi Ayyad University of Marrakech
RP Jabrane, Y (corresponding author), Cadi Ayyad Univ, GECOS Lab, Marrakech, Morocco.
EM m.ameur@uca.ma; habba.maryam@gmail.com; y.jabrane@uca.ma
RI Jabrane, Younes/AAT-1693-2020; Jabrane, Younes/AAJ-6778-2020
OI Jabrane, Younes/0000-0002-5067-6784
FU Excellence Research Scholarships program of CNRST-Morocco
FX This work is supported by the Excellence Research Scholarships program
   of CNRST-Morocco.
CR Altay EV, 2019, ADV INTELL SYST, V759, P163, DOI 10.1007/978-981-13-0341-8_15
   Ameur M, NEW MULTILEVEL UNPUB
   Ameur M, 1 INT C SIGN AUT TEL
   [Anonymous], ARAB J SCI ENG
   [Anonymous], 2009, NABIC 2009 WORLD C 2
   Arya M, 2018, ADV INTELL SYST, V632, P1, DOI 10.1007/978-981-10-5520-1_1
   Bhakat Sudeshna, 2019, Smart Innovations in Communication and Computational Sciences. Proceedings of ICSICCS-2018. Advances in Intelligent Systems and Computing (AISC 851), P85, DOI 10.1007/978-981-13-2414-7_9
   Bingul Z, 2018, OPTIM CONTR APPL MET, V39, P1431, DOI 10.1002/oca.2419
   Bujok P, 2019, SWARM EVOLUTIONARY C
   Civicioglu P, 2013, ARTIF INTELL REV, V39, P315, DOI 10.1007/s10462-011-9276-0
   Das Sunanda, 2019, Recent Trends in Signal and Image Processing. ISSIP 2017. Advances in Intelligent Systems and Computing (AISC 727), P151, DOI 10.1007/978-981-10-8863-6_16
   Gao B, 2018, IEEE T IMAGE PROCESS, V27, P2160, DOI 10.1109/TIP.2017.2783627
   Gautam A, 2019, ADV INTELL SYST, V740, P383, DOI 10.1007/978-981-13-1280-9_36
   Habba M, 2017, INT C IEEE 2017 WIR, P1
   Habba M, 2018, OPTIK, V168, P446, DOI 10.1016/j.ijleo.2018.04.045
   Khan AG., 2019, SURVEY RECENT ARCHIT, P1
   Kumar S, 2013, COMPUTER METHODS MAT, V13, P135
   Kumar SN, 2019, INTEL SYST REF LIBR, V150, P1, DOI 10.1007/978-3-319-96002-9_1
   LEVINE MD, 1985, IEEE T PATTERN ANAL, V7, P155, DOI 10.1109/TPAMI.1985.4767640
   Li QQ, 2017, ENG APPL ARTIF INTEL, V65, P99, DOI 10.1016/j.engappai.2017.07.025
   Luthra I, 2017, 2017 INTERNATIONAL CONFERENCE OF ELECTRONICS, COMMUNICATION AND AEROSPACE TECHNOLOGY (ICECA), VOL 2, P143, DOI 10.1109/ICECA.2017.8212781
   Mlakar U, 2016, EXPERT SYST APPL, V65, P221, DOI 10.1016/j.eswa.2016.08.046
   Nath S, 2018, PERFORMANCE COMP PSO
   Pare S, 2019, ADV INTELL SYST COMP, V748, P71, DOI 10.1007/978-981-13-0923-6_7
   Rapaka S, 2018, IET IMAGE PROCESS, V12, P1721, DOI 10.1049/iet-ipr.2016.0917
   Reynolds R.G., 1994, P 3 ANN C EVOLUTIONA, P131, DOI DOI 10.1142/9789814534116
   Sparavigna A. C., 2015, International Journal of Sciences, V4, P40, DOI 10.18483/ijSci.613
   Pham TX, 2018, APPL SOFT COMPUT, V65, P230, DOI 10.1016/j.asoc.2018.01.003
   Vardhini K.K., 2016, INDIAN J SCI TECHNOL, V9, P1
   Varsha S, 2018, IEEE INT C SYST COMP, P1
   Wang MW, 2018, PROC SPIE, V10615, DOI 10.1117/12.2302922
   Ye ZW, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20040239
NR 32
TC 14
Z9 14
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34353
EP 34372
DI 10.1007/s11042-019-08133-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800007
DA 2024-07-18
ER

PT J
AU Biyani, RS
   Patre, BM
   Kulkarni, UV
AF Biyani, R. S.
   Patre, B. M.
   Kulkarni, U. V.
TI Retinal vessel segmentation using enhanced fuzzy min-max neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diabetic retinopathy; Vessel segmentation; Hyperbox; Fuzzy min-max
   neural network
ID BLOOD-VESSELS; IMAGES; GABOR
AB Automated segmentation of retinal vessels plays a pivotal role in early diagnosis of ophthalmic disorders. In this paper, a blood vessel segmentation algorithm using an enhanced fuzzy min-max neural network supervised classifier is proposed. The input to the network is an optimal 11-D feature vector which consists of spatial as well as frequency domain features extracted from each pixel of a fundus image. The essence of the method is its hyperbox classifier which performs online learning and gives binary output without any need of post-processing. The method is tested on publicly available databases DRIVE and STARE. The results are compared with the existing methods in the literature. The proposed method exhibits efficient performance and can be implemented in computer aided screening and diagnosis of retinal diseases. The method attains an average accuracy, sensitivity and specificity of 95.73%, 74.75% and 97.81% on DRIVE database and 95.51%, 74.65% and 97.11% on STARE database, respectively.
C1 [Biyani, R. S.; Patre, B. M.] Shri Guru Gobind Singhji Inst Engn & Technol, Dept Instrumentat Engn, Nanded, Maharashtra, India.
   [Kulkarni, U. V.] Shri Guru Gobind Singhji Inst Engn & Technol, Dept Comp Sci & Engn, Nanded, Maharashtra, India.
C3 Shri Guru Gobind Singhji Institute of Engineering & Technology; Shri
   Guru Gobind Singhji Institute of Engineering & Technology
RP Biyani, RS (corresponding author), Shri Guru Gobind Singhji Inst Engn & Technol, Dept Instrumentat Engn, Nanded, Maharashtra, India.
EM biyanirupalis@gmail.com; bmpatre@yahoo.com; uvkulkarni@sggs.ac.in
RI Kulkarni, Uday Vasantrao/ABH-1977-2020; Patre, Balasaheb/ABH-2028-2020
OI Patre, Balasaheb/0000-0002-9095-8970
CR Abramoff Michael D, 2010, IEEE Rev Biomed Eng, V3, P169, DOI 10.1109/RBME.2010.2084567
   [Anonymous], 2015, IDF Diabetes Atlas, V7
   [Anonymous], 2009, PEARSON ED INDIA
   Asghari M. H., 2015, INT J BIOMEDICAL IMA, V2015, P1, DOI DOI 10.1155/2015/687819
   Frangi AF, 1998, LECT NOTES COMPUT SC, V1496, P130, DOI 10.1007/BFb0056195
   Franklin SW, 2014, APPL SOFT COMPUT, V22, P94, DOI 10.1016/j.asoc.2014.04.024
   Fraz MM, 2012, IEEE T BIO-MED ENG, V59, P2538, DOI 10.1109/TBME.2012.2205687
   Gabrys B, 2000, IEEE T NEURAL NETWOR, V11, P769, DOI 10.1109/72.846747
   Hoover A, 2000, IEEE T MED IMAGING, V19, P203, DOI 10.1109/42.845178
   Kovesi P.D., 1999, Videre: Journal of Computer Vision Research, V1
   Lupascu CA, 2010, IEEE T INF TECHNOL B, V14, P1267, DOI 10.1109/TITB.2010.2052282
   Marín D, 2011, IEEE T MED IMAGING, V30, P146, DOI 10.1109/TMI.2010.2064333
   Mohammed MF, 2015, IEEE T NEUR NET LEAR, V26, P417, DOI 10.1109/TNNLS.2014.2315214
   Mookiah MRK, 2013, COMPUT BIOL MED, V43, P2136, DOI 10.1016/j.compbiomed.2013.10.007
   NIEMEIJER M, 2004, SPIE MED IMAGING, V24, P648
   Ricci E, 2007, IEEE T MED IMAGING, V26, P1357, DOI 10.1109/TMI.2007.898551
   Roychowdhury S, 2015, IEEE J BIOMED HEALTH, V19, P1118, DOI 10.1109/JBHI.2014.2335617
   SIMPSON PK, 1992, IEEE T NEURAL NETWOR, V3, P776, DOI 10.1109/72.159066
   Sinthanayothin C, 1999, BRIT J OPHTHALMOL, V83, P902, DOI 10.1136/bjo.83.8.902
   Soares JVB, 2006, IEEE T MED IMAGING, V25, P1214, DOI 10.1109/TMI.2006.879967
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Vega R, 2015, COMPUT BIOL MED, V58, P20, DOI 10.1016/j.compbiomed.2014.12.016
   Wang SL, 2015, NEUROCOMPUTING, V149, P708, DOI 10.1016/j.neucom.2014.07.059
   You XG, 2011, PATTERN RECOGN, V44, P2314, DOI 10.1016/j.patcog.2011.01.007
   Zhu CZ, 2017, COMPUT MED IMAG GRAP, V55, P68, DOI 10.1016/j.compmedimag.2016.05.004
NR 25
TC 0
Z9 0
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35053
EP 35073
DI 10.1007/s11042-019-08061-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800036
DA 2024-07-18
ER

PT J
AU Buono, P
   Balducci, F
AF Buono, Paolo
   Balducci, Fabrizio
TI MonitorApp: a web tool to analyze and visualize pollution data detected
   by an electronic nose
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visualization; Clustering; Workflow; Air quality
AB The analysis of air quality data may reveal the quality of life and can prevent dangers for the citizen health. Assuming that some chemical compounds in the air produce a bad smell, people may detect that something is going wrong acting as sensors that alerts potential risks. This work presents a visual analytics approach to support air quality experts in the analysis of data produced by electronic nose devices. The approach consists in setting workflows to manage and transform raw data offering clustering and visualization techniques to analyze such information. The analysis is supported by calendar, map and line graph visualization techniques also maneuvering the clustering attributes. The interactive map is used to show the position of monitoring stations in order to support making hypothesis related to the data source locations.
C1 [Buono, Paolo; Balducci, Fabrizio] Univ Bari Aldo Moro, Bari, Italy.
C3 Universita degli Studi di Bari Aldo Moro
RP Balducci, F (corresponding author), Univ Bari Aldo Moro, Bari, Italy.
EM paolo.buono@uniba.it; fabrizio.balducci@uniba.it
RI Balducci, Fabrizio/K-5023-2019; Buono, Paolo/E-9803-2014
OI Balducci, Fabrizio/0000-0003-1174-4323; 
CR Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   [Anonymous], 2010, EUROGRAPHICS
   [Anonymous], 2012, MACHINE LEARNING STR
   Buono P, 2018, IEEE INT CON INF VIS, P198, DOI 10.1109/iV.2018.00043
   Buono Paolo, 2012, P 18 INT C DISTR MUL, P54
   Ceneda D, GUIDING VISUALIZATIO
   Ceneda D, GUIDED VISUAL EXPLOR
   de Carvalho MB, 2016, IEEE INT CONF INF VI, P399, DOI 10.1109/IV.2016.65
   Ghazi S, 2016, P ANN HICSS, P172, DOI 10.1109/HICSS.2016.29
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Kandel S, 2011, INFORM VISUAL, V10, P271, DOI 10.1177/1473871611415994
   Kappe C, 2018, EGU GEN ASS C, V20, P10206
   Kappe CP, 2018, IEEE T VISUALIZATION, V1, P1
   Keim DA, 2000, IEEE T VIS COMPUT GR, V6, P59, DOI 10.1109/2945.841121
   Kern M, 2018, IEEE T VIS COMPUT GR, V1
   Li H, 2016, ATMOSPHERE-BASEL, V7, DOI 10.3390/atmos7030035
   Lin X, 2012, ICCAD-IEEE ACM INT, P1
   Makridakis S, 1997, J FORECASTING, V16, P147, DOI 10.1002/(SICI)1099-131X(199705)16:3<147::AID-FOR652>3.0.CO;2-X
   Malik A., 2010, 2010 IEEE International Conference on Technologies for Homeland Security (HST 2010), P222, DOI 10.1109/THS.2010.5655057
   Pearce T. C., 2006, HDB MACHINE OLFACTIO
   Rajesh B, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON CIRCUIT, POWER AND COMPUTING TECHNOLOGIES (ICCPCT-2014), P1312, DOI 10.1109/ICCPCT.2014.7054852
   Razip AMM, 2014, IEEE PAC VIS SYMP, P169, DOI 10.1109/PacificVis.2014.54
   Sarikaya A, 2018, IEEE T VIS COMPUT GR, V1
   Scott SM, 2006, MICROCHIM ACTA, V156, P183, DOI 10.1007/s00604-006-0623-9
   Sharma G, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P668, DOI 10.1109/ICDMW.2015.190
   Van Wijk J. J., 1999, Proceedings 1999 IEEE Symposium on Information Visualization (InfoVis'99), P4, DOI 10.1109/INFVIS.1999.801851
   Wang S., 2010, P INT JOINT C NEUR N, P1, DOI [DOI 10.1109/IJCNN.2010.5596702, 10.1109/ISPACS.2010.5704770]
   Zhou MJ, 2016, J MAPS, V12, P156, DOI 10.1080/17445647.2016.1187095
NR 28
TC 2
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33023
EP 33040
DI 10.1007/s11042-019-7676-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600019
DA 2024-07-18
ER

PT J
AU Del Fatto, V
   Dignos, A
   Raimato, G
   Maccioni, L
   Borgianni, Y
   Gamper, J
AF Del Fatto, Vincenzo
   Dignos, Anton
   Raimato, Guerriero
   Maccioni, Lorenzo
   Borgianni, Yuri
   Gamper, Johann
TI Visual time period analysis: a multimedia analytics application for
   summarizing and analyzing eye-tracking experiments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data visualization; Period data; Multimedia analytics; Multimedia
   application
ID VISUALIZATION; DATABASES
AB Recently, an increasing need for sophisticated multimedia analytics tools has been observed, which is triggered by a rapid growth of multimedia collections and by an increasing number of scientific fields embedding images in their studies. Although temporal data is ubiquitous and crucial in many applications, such tools typically do not support the analysis of data along the temporal dimension, especially for time periods. An appropriate visualization and comparison of period data associated with multimedia collections would help users to infer new information from such collections. In this paper, we present a novel multimedia analytics application for summarizing and analyzing temporal data from eye-tracking experiments. The application combines three different visual approaches: TIME. DIFF, visual-information-seeking mantra, and multi-viewpoint. A qualitative evaluation with domain experts confirmed that our application helps decision makers to summarize and analyze multimedia collections containing period data.
C1 [Del Fatto, Vincenzo; Dignos, Anton; Raimato, Guerriero; Gamper, Johann] Free Univ Bozen Bolzano, Fac Comp Sci, Bolzano, Italy.
   [Maccioni, Lorenzo; Borgianni, Yuri] Free Univ Bozen Bolzano, Fac Sci & Technol, Bolzano, Italy.
C3 Free University of Bozen-Bolzano; Free University of Bozen-Bolzano
RP Del Fatto, V (corresponding author), Free Univ Bozen Bolzano, Fac Comp Sci, Bolzano, Italy.
EM vincenzo.delfatto@unibz.it
RI Gamper, Johann/B-9521-2017; Dignös, Anton/AAV-5131-2021; Gamper,
   Johann/GYV-0915-2022; maccioni, lorenzo/ABF-5762-2021
OI Gamper, Johann/0000-0002-7128-507X; Dignös, Anton/0000-0002-7621-967X;
   Del Fatto, Vincenzo/0000-0003-1084-4701
FU project VCTP (RTD call 2017) of the Free University of Bozen-Bolzano;
   project EYE-TRACK (CRC call 2017) of the Free University of
   Bozen-Bolzano
FX This work was supported in part by the projects VCTP (RTD call 2017) and
   EYE-TRACK (CRC call 2017) of the Free University of Bozen-Bolzano.
CR Aigner W, 2005, NINTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P457, DOI 10.1109/IV.2005.97
   Aigner W, 2008, IEEE T VIS COMPUT GR, V14, P47, DOI 10.1109/TVCG.2007.70415
   Aigner W, 2006, ARTIF INTELL MED, V37, P203, DOI 10.1016/j.artmed.2006.04.002
   Andre P, 2007, UIST 2007: PROCEEDINGS OF THE 20TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P101
   Ankerst M, 2008, LECT NOTES COMPUT SC, V4404, P312, DOI 10.1007/978-3-540-71080-6_19
   [Anonymous], 2012, P 20 ACM INT C MULTI
   [Anonymous], 2010, MASTERING INFORM AGE
   Behrend Andreas, 2014, Advances in Intelligent Systems and Computing, V312, P159
   Bohlen M., 2009, Encyclopedia of Database Systems, P2924, DOI DOI 10.1007/978-0-387-39940-9386
   Bohlen Michael H., 2018, Business Intelligence and Big Data. 7th European Summer School, eBISS 2017. Tutorial Lectures. Lecture Notes in Business Information Processing (LNBIP 324), P51, DOI 10.1007/978-3-319-96655-7_3
   Bohlen MH, 2018, LIPICS, V120
   Burch M, 2015, IEEE INT CONF INF VI, P163, DOI 10.1109/iV.2015.38
   CHEN H, 2005, DG O, P229
   Chinchor NA, 2010, IEEE COMPUT GRAPH, V30, P52, DOI 10.1109/MCG.2010.92
   Chittaro L, 2003, DATA KNOWL ENG, V44, P239, DOI 10.1016/S0169-023X(02)00137-4
   Combi C, 2012, ARTIF INTELL MED, V54, P75, DOI 10.1016/j.artmed.2011.10.004
   De Chiara Davide, 2012, Web and Wireless Geographical Information Systems. Proceedings 11th International Symposium, W2GIS 2012, P72, DOI 10.1007/978-3-642-29247-7_7
   De Chiara D, 2012, VISUALIZING GEOGRAPH
   De Chiara D, 2011, J VISUAL LANG COMPUT, V22, P173, DOI 10.1016/j.jvlc.2011.02.001
   de Rooij O, 2010, IEEE COMPUT GRAPH, V30, P42, DOI 10.1109/MCG.2010.66
   Del Fatto V, 2018, IV2018, P7
   Dignös A, 2019, PROC VLDB ENDOW, V12, P639, DOI 10.14778/3311880.3311882
   Dignös A, 2013, PROC INT CONF DATA, P1304, DOI 10.1109/ICDE.2013.6544930
   Dignos A., 2012, SIGMOD C, P433
   Dignös A, 2016, ACM T DATABASE SYST, V41, DOI 10.1145/2967608
   Fischer F, 2012, IEEE SYM VIS CYB SEC, P80
   Gregersen H, 1999, IEEE T KNOWL DATA EN, V11, P464, DOI 10.1109/69.774104
   Hochheiser H., 2004, Information Visualization, V3, P1, DOI 10.1057/palgrave.ivs.9500061
   Jensen CS, 1999, IEEE T KNOWL DATA EN, V11, P36, DOI 10.1109/69.755613
   Jensen M.., 2003, VISUALIZING COMPLEX
   Kaptelinin Victor., 2007, Beyond the Desktop Metaphor: Designing Integrated Digital Environments
   Keim D.A., 2008, Lecture Notes In Computer Science
   Kulkarni K., 2011, ACM SIGMOD REC, V41, P34
   Lee JH, 2019, CURR MED RES OPIN, V35, P1111, DOI 10.1080/03007995.2018.1560134
   Liu TY, 2014, COMPUT GRAPH-UK, V39, P117, DOI 10.1016/j.cag.2013.11.014
   Luo X., 2010, Proceedings of the 2010, P1165, DOI 10.1145/1774088.1774336
   Maccioni L, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11051226
   Mahlknecht G, 2017, SSDBM
   Mahlknecht G, 2017, INFORM SYST, V70, P2, DOI 10.1016/j.is.2016.08.002
   Meghdadi AH, 2013, IEEE T VIS COMPUT GR, V19, P2119, DOI 10.1109/TVCG.2013.168
   Melton J, 2006, DATABASE LANGUAGE SQ, P105
   Olsson J, 2009, DIGIT INVEST, V6, pS78, DOI 10.1016/j.diin.2009.06.008
   Plaisant C., 1996, Human Factors in Computing Systems. Common Ground. CHI 96 Conference Proceedings, P221, DOI 10.1145/238386.238493
   Richter HA, 1999, 9930 GITGVU
   Schueller G, 2015, 2015 18TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P1238
   Seltmann M., 2016, P 4 INT C TECHN EC E, P985, DOI [10.1145/3012430.3012636, DOI 10.1145/3012430.3012636]
   Seyfert M, 2017, P 33 SPRING C COMP G
   Shmueli G, 2006, DECIS SUPPORT SYST, V42, P1521, DOI 10.1016/j.dss.2006.01.001
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Silva SF, 2000, PROCEEDINGS OF THE FIRST INTERNATIONAL CONFERENCE ON WEB INFORMATION SYSTEMS ENGINEERING, VOL I, P310, DOI 10.1109/WISE.2000.882407
   Steele J., 2010, BEAUTIFUL VISUALIZAT
   Tominski C., 2004, Proceedings of the 2004 ACM symposium on Applied computing, P1242, DOI [10.1145/967900.968153, DOI 10.1145/967900.968153]
   Weber M, 2001, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2001, PROCEEDINGS, P7, DOI 10.1109/infvis.2001.963273
   Yang J, 2010, IEEE COMPUT GRAPH, V30, P32, DOI 10.1109/MCG.2010.93
   Zahálka J, 2014, IEEE CONF VIS ANAL, P3, DOI 10.1109/VAST.2014.7042476
   Zhou X, 2006, LECT NOTES COMPUT SC, V4080, P676
NR 56
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 32779
EP 32804
DI 10.1007/s11042-019-07950-1
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600010
DA 2024-07-18
ER

PT J
AU Li, PQ
   Deng, XL
   Zhang, LY
   Gan, JZ
   Li, JY
   Li, YG
AF Li, Pengqing
   Deng, Xuelian
   Zhang, Leyuan
   Gan, Jiangzhang
   Li, Jiaye
   Li, Yonggang
TI Sparse learning based on clustering by fast search and find of density
   peaks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Truncation distance; Sparse learning; Local density; Density peaks;
   Clustering algorithm
ID ALGORITHM; SEGMENTATION; ROBUST
AB Clustering by fast search and find of density peaks (CFSFDP) is a novel clustering algorithm proposed in recent years. The algorithm has the advantages of low computational complexity and high accuracy. However, the truncation distance d(c) needs to be determined according to user experience. Aiming to overcome these drawbacks, this paper proposes a new algorithm named Sparse learning based on clustering by fast search and find of density peaks (SL-CFSFDP). Compared to CFSFDP, the proposed algorithm can obtain d(c) automatically, and it uses sparse learning to determine the neighbors of each data point, removing irrelevant data points at the same time. SL-CFSFDP combines the local density and the distance delta(i) to automatically determine cluster centers, after which the remaining data points are assigned to clusters according to the local density and distance delta(i). Extensive experimental results on both synthetic and benchmark datasets show that SL-CFSFDP is superior to DBSCAN and CFSFDP.
C1 [Li, Pengqing; Deng, Xuelian; Zhang, Leyuan; Gan, Jiangzhang; Li, Jiaye; Li, Yonggang] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Guangxi, Peoples R China.
   [Deng, Xuelian] Guangxi Univ Chinese Med, Coll Publ Hlth & Management, Nanning, Peoples R China.
C3 Guangxi Normal University; Guangxi University of Chinese Medicine
RP Deng, XL (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Guangxi, Peoples R China.; Deng, XL (corresponding author), Guangxi Univ Chinese Med, Coll Publ Hlth & Management, Nanning, Peoples R China.
EM 1263647631@qq.com; 2183451435@qq.com; 846390062@qq.com;
   1960412020@qq.com; 373167293@qq.com; 574717541@qq.com
RI wang, zhenhui/JMQ-0550-2023; Zhang, Leyuan/KEJ-5622-2024; Liu,
   Gui/JHU-8707-2023
FU China Key Research Program [2016YFB1000905]; National Natural Science
   Foundation of China [61836016]; Natural Science Foundation of China
   [61876046, 61573270, 81701780, 61672177]; Project of Guangxi Science and
   Technology [GuiKeAD17195062]; Guangxi Natural Science Foundation
   [2015GXNSFCB139011, 2017GXNSFBA198221]; Guangxi Collaborative Innovation
   Center of Multi-Source Information Integration and Intelligent
   Processing; Guangxi High Institutions Program of Introducing 100
   High-Level Overseas Talents; Guangxi Key Lab of Multisource Information
   Mining Security [18-A-01-01]; National Natural Science Foundation of
   Guangxi [2016GXNS-FAA380098]; Guangxi Key Lab of Multi-source
   Information Mining Security [MIMS18-09]
FX This work is partially supported by the China Key Research Program
   (Grant No: 2016YFB1000905); the Key Program of the National Natural
   Science Foundation of China (Grant No: 61836016); the Natural Science
   Foundation of China (Grants No: 61876046, 61573270, 81701780 and
   61672177); the Project of Guangxi Science and Technology
   (GuiKeAD17195062); the Guangxi Natural Science Foundation (Grant No:
   2015GXNSFCB139011, 2017GXNSFBA198221); the Guangxi Collaborative
   Innovation Center of Multi-Source Information Integration and
   Intelligent Processing; the Guangxi High Institutions Program of
   Introducing 100 High-Level Overseas Talents; the Project of Guangxi
   Science and Technology (GuiKeAD17195062) the Guangxi Collaborative
   Innovation Center of Multi-Source Information Integration and
   Intelligent Processing; the Research Fund of Guangxi Key Lab of
   Multisource Information Mining & Security (18-A-01-01); the National
   Natural Science Foundation of Guangxi (No. 2016GXNS-FAA380098) and
   Research Fund of Guangxi Key Lab of Multi-source Information Mining &
   Security (MIMS18-09).
CR [Anonymous], DENSITY BASED CLUSTE
   [Anonymous], 2018, IEEE T KNOWL DATA EN
   [Anonymous], 2018, IEEE Transactions on Cybernetics
   [Anonymous], 2018, IEEE Trans. Image Process
   Bandyopadhyay S, 2003, IEEE INFOCOM SER, P1713
   Charikar M, 2017, PROCEEDINGS OF THE TWENTY-EIGHTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P841
   Dasgupta S, 2016, ACM S THEORY COMPUT, P118, DOI 10.1145/2897518.2897527
   Duan L, 2016, INT C NATURAL COMPUT, V9, P44
   Elhamifar Ehsan, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2790, DOI 10.1109/CVPRW.2009.5206547
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Hu H, 2014, PROC CVPR IEEE, P3834, DOI 10.1109/CVPR.2014.484
   Hu RY, 2017, NEUROCOMPUTING, V220, P130, DOI 10.1016/j.neucom.2016.05.081
   Khan SS, 2013, EXPERT SYST APPL, V40, P7444, DOI 10.1016/j.eswa.2013.07.002
   Lei C, 2018, MULTIMED TOOLS APPL, V77, P29605, DOI 10.1007/s11042-017-5381-7
   Li CG, 2017, IEEE T IMAGE PROCESS, V26, P2988, DOI 10.1109/TIP.2017.2691557
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Lu CY, 2012, LECT NOTES COMPUT SC, V7578, P347, DOI 10.1007/978-3-642-33786-4_26
   Lv YH, 2016, NEUROCOMPUTING, V171, P9, DOI 10.1016/j.neucom.2015.05.109
   Park HS, 2009, EXPERT SYST APPL, V36, P3336, DOI 10.1016/j.eswa.2008.01.039
   Rao PS., 2015, Int J Comput Appl, V120, P36
   Rodriguez A, 2014, SCIENCE, V344, P1492, DOI 10.1126/science.1242072
   Shen YC, 2017, 2017 SECOND INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS ENGINEERING (ICISE), P32, DOI 10.1109/ICISE.2017.11
   Song J, 2018, IEEE Trans Neural Netw Learning Sys, P1
   Tan J, 2012, AASRI PROC, V1, P14, DOI 10.1016/j.aasri.2012.06.004
   Topchy AP, 2004, FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P225, DOI 10.1109/ICDM.2004.10100
   Tran TN, 2013, CHEMOMETR INTELL LAB, V120, P92, DOI 10.1016/j.chemolab.2012.11.006
   Wang MM, 2016, NEUROCOMPUTING, V179, P219, DOI 10.1016/j.neucom.2015.11.091
   Wang S, 2003, IEEE T PATTERN ANAL, V25, P675, DOI 10.1109/TPAMI.2003.1201819
   Wang SL, 2016, CHINESE J ELECTRON, V25, P397, DOI 10.1049/cje.2016.05.001
   Xia C, 2017, CHINA COMPUT COMMUN
   Xu J, 2016, INFORM SCIENCES, V373, P200, DOI 10.1016/j.ins.2016.08.086
   Xu Y, 2016, IEEE T IMAGE PROCESS, V25, P850, DOI 10.1109/TIP.2015.2510498
   Zhang JM, 2015, CHIN CONTR CONF, P3791, DOI 10.1109/ChiCC.2015.7260226
   Zhang SC, 2018, IEEE T NEUR NET LEAR, V29, P1774, DOI 10.1109/TNNLS.2017.2673241
   Zhao YC, 2006, IEEE T KNOWL DATA EN, V18, P231, DOI 10.1109/TKDE.2006.30
   Zheng W, 2020, PATTERN RECOGN LETT, V132, P4, DOI 10.1016/j.patrec.2018.06.029
   Zheng W, 2018, MULTIMED TOOLS APPL, V77, P29739, DOI 10.1007/s11042-017-5272-y
   Zhu XF, 2019, IEEE T KNOWL DATA EN, V31, P1532, DOI 10.1109/TKDE.2018.2858782
   Zhu XF, 2018, IEEE T KNOWL DATA EN, V30, P517, DOI 10.1109/TKDE.2017.2763618
   Zhu XF, 2017, IEEE T BIG DATA, V3, P405, DOI 10.1109/TBDATA.2017.2735991
   Zhu XF, 2017, IEEE T MULTIMEDIA, V19, P2033, DOI 10.1109/TMM.2017.2703636
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
   Zhu XF, 2011, IEEE T KNOWL DATA EN, V23, P110, DOI 10.1109/TKDE.2010.99
NR 45
TC 6
Z9 6
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33261
EP 33277
DI 10.1007/s11042-019-07885-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600031
DA 2024-07-18
ER

PT J
AU Sotoodeh, M
   Moosavi, MR
   Boostani, R
AF Sotoodeh, Mahmood
   Moosavi, Mohammad Reza
   Boostani, Reza
TI A structural based feature extraction for detecting the relation of
   hidden substructures in coral reef images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color texture descriptors; Coral reef images; Integrative co-occurrence
   matrix (ICM); Local binary pattern (LBP); Feature extraction;
   Macrostructure texture information
ID LOCAL BINARY PATTERN; INVARIANT TEXTURE CLASSIFICATION; COLOR;
   RETRIEVAL; SCALE
AB In this paper, we present an efficient approach to extract local structural color texture features for classifying coral reef images. Two local texture descriptors are derived from this approach. The first one, based on Median Robust Extended Local Binary Pattern (MRELBP), is called Color MRELBP (CMRELBP). CMRELBP is very accurate and can capture the structural information from color texture images. To reduce the dimensionality of the feature vector, the second descriptor, co-occurrence CMRELBP (CCMRELBP) is introduced. It is constructed by applying the Integrative Co-occurrence Matrix (ICM) on the Color MRELBP images. This way we can detect and extract the relative relations between structural texture patterns. Moreover, we propose a multiscale LBP based approach with these two schemes to capture microstructure and macrostructure texture information. The experimental results on coral reef (EILAT, EILAT2, RSMAS, and MLC) and four well-known texture datasets (OUTEX, KTH-TIPS, CURET, and UIUCTEX) show that the proposed scheme is quite effective in designing an accurate, robust to noise, rotation and illumination invariant texture classification system. Moreover, it makes an admissible tradeoff between accuracy and number of features.
C1 [Sotoodeh, Mahmood; Moosavi, Mohammad Reza; Boostani, Reza] Shiraz Univ, Dept Elect & Comp Engn, Shiraz, Iran.
   [Sotoodeh, Mahmood] Utah State Univ, Dept Comp Sci, Logan, UT 84322 USA.
C3 Shiraz University; Utah System of Higher Education; Utah State
   University
RP Sotoodeh, M (corresponding author), Shiraz Univ, Dept Elect & Comp Engn, Shiraz, Iran.; Sotoodeh, M (corresponding author), Utah State Univ, Dept Comp Sci, Logan, UT 84322 USA.
EM mahmood.sotoodeh@aggiemail.usu.edu; smmosavi@shirazu.ac.ir;
   boostani@shirazu.ac.ir
RI Sotoodeh, Mahmood/AAA-6461-2022; Boostani, Reza/ABC-5999-2021
OI Sotoodeh, Mahmood/0000-0002-7717-5381; Boostani,
   Reza/0000-0003-0055-4452; Moosavi, Mohammad R./0000-0002-9296-9382
CR [Anonymous], PEERJ PREPRINTS
   [Anonymous], PROC CVPR IEEE
   [Anonymous], EXPERT SYST APPL
   [Anonymous], 2016, P 2016 INT C OPT IM
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 1997, NONPARAMETRIC TEXTUR
   [Anonymous], CORAL REEF DATASET V
   [Anonymous], 2015, ARXIV151109067
   [Anonymous], 2014, 2014 IEEE SENS SYST
   [Anonymous], MULTIMED TOOLS APPL
   Bala A, 2016, ENG SCI TECHNOL, V19, P101, DOI 10.1016/j.jestch.2015.06.008
   Beijbom O, 2012, PROC CVPR IEEE, P1170, DOI 10.1109/CVPR.2012.6247798
   Bewley MS, 2015, SPRINGER TRAC ADV RO, V105, P3, DOI 10.1007/978-3-319-07488-7_1
   Bewley M. S, 2012, P AUSTR C ROB AUT
   Bianconi F, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3651210
   Caputo B, 2010, IMAGE VISION COMPUT, V28, P150, DOI 10.1016/j.imavis.2009.05.005
   Fathi A, 2012, PATTERN RECOGN LETT, V33, P1093, DOI 10.1016/j.patrec.2012.01.017
   Gómez-Ríos A, 2019, EXPERT SYST APPL, V118, P315, DOI 10.1016/j.eswa.2018.10.010
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hayman E, 2004, LECT NOTES COMPUT SC, V2034, P253
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu L, 2014, IEEE T IMAGE PROCESS, V23, P3071, DOI 10.1109/TIP.2014.2325777
   Liu L, 2016, IEEE T IMAGE PROCESS, V25, P1368, DOI 10.1109/TIP.2016.2522378
   Liu L, 2012, IMAGE VISION COMPUT, V30, P86, DOI 10.1016/j.imavis.2012.01.001
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Loya Y, 2004, CORAL HEALTH AND DISEASE, P1
   Mahmood A, 2016, IEEE IMAGE PROC, P519, DOI 10.1109/ICIP.2016.7532411
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Marcos MSA, 2008, ENVIRON MONIT ASSESS, V145, P177, DOI 10.1007/s10661-007-0027-2
   Mary NAB, 2018, WIRELESS PERS COMMUN, V98, P2427, DOI 10.1007/s11277-017-4981-x
   Mary NAB, 2017, J VIS COMMUN IMAGE R, V49, P225, DOI 10.1016/j.jvcir.2017.09.008
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Padmavathi G., 2010, Proceedings of the 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P983, DOI 10.1109/CISP.2010.5646932
   Palm C, 2004, PATTERN RECOGN, V37, P965, DOI 10.1016/j.patcog.2003.09.010
   Pican N, 1998, OCEANS'98 - CONFERENCE PROCEEDINGS, VOLS 1-3, P424, DOI 10.1109/OCEANS.1998.725781
   Pietikäinen M, 2000, PATTERN RECOGN, V33, P43, DOI 10.1016/S0031-3203(99)00032-1
   Pizarro O., 2008, OCEANS 2008, P1
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sabins F.F., 2007, Remote sensing: principles and interpretation
   Shakoor MH, 2018, MULTIMED TOOLS APPL, V77, P21481, DOI 10.1007/s11042-017-5440-0
   Shakoor MH, 2018, MULTIMED TOOLS APPL, V77, P2561, DOI 10.1007/s11042-017-4394-6
   Shihavuddin ASM, 2013, REMOTE SENS-BASEL, V5, P1809, DOI 10.3390/rs5041809
   Simonyan K., 2014, Very Deep Convolutional Networks for Large-Scale Image Recognition
   Stokes MD, 2009, LIMNOL OCEANOGR-METH, V7, P157, DOI 10.4319/lom.2009.7.157
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhao Y, 2013, NEUROCOMPUTING, V106, P68, DOI 10.1016/j.neucom.2012.10.017
   Zhu ZQ, 2015, PATTERN RECOGN, V48, P2592, DOI 10.1016/j.patcog.2015.01.001
NR 59
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34513
EP 34539
DI 10.1007/s11042-019-08050-w
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800013
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Sikha, OK
   Soman, KP
   Kumar, SS
AF Sikha, O. K.
   Soman, K. P.
   Kumar, S. Sachin
TI VMD-DMD coupled data-driven approach for visual saliency in noisy images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient region detection; Saliency for noisy images; VMD; DMD
ID MODEL
AB Human visual system is endowed with an innate capability of distinguishing the salient regions of an image. It do so even in the presence of noise and other natural disturbances. Conventional8 computational saliency models in the literature assume that the input images are clean, though an explicit treatment of noise is missing. In this paper, we propose a coupled data-driven approach for estimating saliency map for a noisy input using Variational Mode Decomposition (VMD) and Dynamic Mode Decomposition(DMD. Variational Mode Decomposition (VMD) is a well received technique explored for denoising in the literature. VMD modes with high entropy (randomness) are removed and the residual modes are employed to generate a scalar valued saliency map. The proposed method is compared against seven state-of-the-art methods over a wide range of noise strengths. The submitted approach furnished comparable results with respect to state-of-the art methods for clean and noisy images in terms of various benchmark performance measures.
C1 [Sikha, O. K.] Amrita Vishwa Vidyapeetham, Amrita Sch Engn Coimbatore, Ctr Computat Engn & Networking CEN, Dept Comp Sci & Engn, Coimbatore, Tamil Nadu, India.
   [Soman, K. P.; Kumar, S. Sachin] Amrita Vishwa Vidyapeetham, Amrita Sch Engn Coimbatore, Ctr Computat Engn & Networking CEN, Coimbatore, Tamil Nadu, India.
C3 Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Coimbatore;
   Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Coimbatore
RP Sikha, OK (corresponding author), Amrita Vishwa Vidyapeetham, Amrita Sch Engn Coimbatore, Ctr Computat Engn & Networking CEN, Dept Comp Sci & Engn, Coimbatore, Tamil Nadu, India.
EM ok_sikha@cb.amrita.edu
OI S, Sachin Kumar/0000-0002-3298-0539
CR [Anonymous], THESIS
   [Anonymous], [No title captured]
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   [Anonymous], 2009, IEEE INT C COMP VIS
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833
   Borji A, 2013, IEEE T IMAGE PROCESS, V22, P55, DOI 10.1109/TIP.2012.2210727
   Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Dragomiretskiy K, 2015, LECT NOTES COMPUT SC, V8932, P197, DOI 10.1007/978-3-319-14612-6_15
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Kim C, 2013, J VISION, V13, DOI 10.1167/13.4.5
   Kutz JN, 2017, US Patent, Patent No. [9,674,406, 9674406]
   Lahmiri S, 2014, BIOMED CIRC SYST C, P340, DOI 10.1109/BioCAS.2014.6981732
   Le Meur O, 2007, VISION RES, V47, P2483, DOI 10.1016/j.visres.2007.06.015
   Liu YY, 2016, SIGNAL PROCESS, V125, P349, DOI 10.1016/j.sigpro.2016.02.011
   Mohan N., 2016, INT J ELECT COMPUTER, V6, P151, DOI DOI 10.11591/IJECE.V6I1.8592
   Murray N, 2011, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2011.5995506
   Pankaj D, 2016, INDIAN J SCI TECHNOL, V9, P45, DOI DOI 10.17485/ijst/2016/v9i45/99068
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Peters RJ, 2005, VISION RES, V45, P2397, DOI 10.1016/j.visres.2005.03.019
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Sikha O, 2017, J COMPUTATIONAL SCI
   Sikha O. K., 2019, SIGNAL IMAGE VIDEO P, V1
   Tavakoli HR, 2011, LECT NOTES COMPUT SC, V6688, P666, DOI 10.1007/978-3-642-21227-7_62
   Wang J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330512
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang JM, 2012, PROC CVPR IEEE, P2296, DOI 10.1109/CVPR.2012.6247940
   Zhang J, 2019, VISUAL SALIENCY PIXE, P95
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
NR 33
TC 2
Z9 2
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 1951
EP 1970
DI 10.1007/s11042-019-08297-3
EA NOV 2019
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000496214300002
DA 2024-07-18
ER

PT J
AU Subhedar, MS
   Mankar, VH
AF Subhedar, Mansi S.
   Mankar, Vijay H.
TI Secure image steganography using framelet transform and bidiagonal SVD
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganography; Bidiagonal singular value decomposition; Framelet
   transform; Wavelet and contourlet based steganalysis
ID DISCRETE WAVELET TRANSFORM; SCHEME; CAPACITY
AB Steganography and steganalysis are the prominent research fields in information hiding paradigm. This work presents a novel framelet transform based image steganography scheme that hides a secret image into cover image. Perfect reconstruction, sparsity, and stability enables framelet transform to be considered as suitable decomposition technique to obtain transform coefficients. The scheme also benefits from bidiagonal singular value decomposition. Secret information is embedded in singular values of framelet coefficients and stego is obtained. A variety of experiments is conducted to judge the efficacy of proposed method. Simulation results prove that stego images possess better visual quality and are robust to several popular image processing operations. Security performance of proposed method is investigated using various steganalysis schemes that include Gabor filter based, wavelet based and contourlet based steganalysis. Detection accuracy is found to be poor in all cases and confirms the undetectability.
C1 [Subhedar, Mansi S.] Pillai HOC Coll Engn & Technol, Dept Elect, Telecommun, Rasayani 410207, Maharashtra, India.
   [Mankar, Vijay H.] Govt Polytech, Dept Elect, Telecommun, Nagpur 441206, Maharashtra, India.
RP Subhedar, MS (corresponding author), Pillai HOC Coll Engn & Technol, Dept Elect, Telecommun, Rasayani 410207, Maharashtra, India.
EM mansi_subhedar@rediffmail.com
RI Mankar, Vijay H/G-2293-2012; Subhedar, Mansi/ABE-4740-2020
OI Subhedar, Mansi/0000-0002-4628-354X
CR Al Ataby AA, 2011, P 4 INT C DEV ESYSTE, DOI [10.1109/DeSE.2011.13, DOI 10.1109/DESE.2011.13]
   Al-Ataby A, 2010, INT ARAB J INF TECHN, V7, P358
   Al-Taai Hadeel N., 2008, American Journal of Applied Sciences, V5, P1522, DOI 10.3844/ajassp.2008.1522.1527
   Anderson RJ, 1998, IEEE J SEL AREA COMM, V16, P474, DOI 10.1109/49.668971
   [Anonymous], 2011, J. Inform. Hid. Multimed. Signal Process.
   [Anonymous], IEEE C SYST APPL TEC
   [Anonymous], MULTIPLE RGB IMAGE S
   [Anonymous], 2 INT C KNOWL BAS EN
   [Anonymous], ACM WORKSH INF HID M
   Banoci V., 2011, 21 INT C RAD EL, P1, DOI [10.1109/RADIOELEK.2011.5936455, DOI 10.1109/RADIOELEK.2011.5936455]
   Borra Surekha, 2019, Smart Health, V12, P35, DOI 10.1016/j.smhl.2018.02.001
   Denemark T, 2017, IEEE T INF FOREN SEC, V12, P2308, DOI 10.1109/TIFS.2017.2705625
   Duan X, 2018, ABS180203528 CORR
   Fakhredanesh M, 2019, MULTIMED TOOLS APPL, V78, P18475, DOI 10.1007/s11042-019-7238-8
   Ghasemi E, 2011, INT MULT ENG COMP SC, VI
   Ghosh E, 2019, EMERGING TECHNOLOGIE, V814
   Gulve AK, HINDAWI MATH PROBLEM, V2015
   Hemalatha S., 2013, INT J CRYPTOGRAPHY I, V3, P17
   JIA RQ, 1994, P EDINBURGH MATH SOC, V37, P271, DOI 10.1017/S0013091500006076
   Kanan HR, 2014, EXPERT SYST APPL, V41, P6123, DOI 10.1016/j.eswa.2014.04.022
   Li Y, 2020, MULTIMED TOOLS APPL, V79, P9665, DOI 10.1007/s11042-017-5557-1
   Luo Y, 2015, ISPRS INTERNATIONAL WORKSHOP ON SPATIOTEMPORAL COMPUTING, P19, DOI 10.5194/isprsannals-II-4-W2-19-2015
   Lyu S, 2003, LECT NOTES COMPUT SC, V2578, P340
   Maheswari SU, 2015, AEU-INT J ELECTRON C, V69, P539, DOI 10.1016/j.aeue.2014.11.004
   Mostafa R, 2015, 2015 IEEE SEVENTH INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INFORMATION SYSTEMS (ICICIS), P300, DOI 10.1109/IntelCIS.2015.7397238
   Muhammad N, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1534-1
   Ogiela MR, 2015, SOFT COMPUT, V19, P3331, DOI 10.1007/s00500-015-1728-z
   Rabie T, 2018, MULTIMED TOOLS APPL, V77, P23673, DOI 10.1007/s11042-018-5713-2
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P6473, DOI 10.1007/s11042-016-3301-x
   Raftari N., 2012, 2012 6th Asia Modelling Symposium (AMS 2012), P87, DOI 10.1109/AMS.2012.15
   Saidi M, 2017, MULTIMED TOOLS APPL, V76, P13493, DOI 10.1007/s11042-016-3722-6
   Sajasi S, 2015, APPL SOFT COMPUT, V30, P375, DOI 10.1016/j.asoc.2015.01.032
   Sajedi H, 2010, J SIGNAL PROCESS SYS, V61, P367, DOI 10.1007/s11265-010-0460-2
   Simmons G. J., 1984, Advances in Cryptology. Proceedings of Crypto 83, P51
   Subhedar MS, 2016, COMPUT ELECTR ENG, V54, P406, DOI 10.1016/j.compeleceng.2016.04.017
   Subhedar MS, 2014, COMPUT SCI REV, V13-14, P95, DOI 10.1016/j.cosrev.2014.09.001
   Subramanian M, 2018, J COMPUT NETW COMMUN, V2018, DOI 10.1155/2018/8695103
   Thabit R, 2015, DIGIT SIGNAL PROCESS, V38, P77, DOI 10.1016/j.dsp.2014.12.005
   Thanki R, 2018, J INF SECUR APPL, V40, P92, DOI 10.1016/j.jisa.2018.03.004
   Xiao M, 2015, P SPIE MULT IM ACQ P, V9811
NR 40
TC 19
Z9 19
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 1865
EP 1886
DI 10.1007/s11042-019-08221-9
EA NOV 2019
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NR2UN
UT WOS:000495944500006
DA 2024-07-18
ER

PT J
AU Zhu, XY
   Xiao, Y
   Zheng, Y
AF Zhu, Xianyi
   Xiao, Yi
   Zheng, Yan
TI 2D freehand sketch labeling using CNN and CRF
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 2D sketch labeling; Stroke classification; Convolutional neural network;
   Conditional random field; Connected graph creation
ID CLASSIFICATION
AB Accurate and fast sketch segmentation and labeling is a hard task, since sketches have much fewer features than natural images. This paper proposes a novel hybrid approach for fast automatic sketch labeling, which is based on convolutional neural network (CNN) and conditional random field (CRF). Firstly, we design a CNN for stroke classification. The CNN is equipped with larger first layer filters and larger pooling, which is suitable for extracting descriptive features from strokes. Secondly, we integrate each stroke with its host sketch to construct a more informative input for the CNN model. Finally, we leverage the spatio-temporal relations among strokes in the same sketch to create a connected graph, based on which we apply a CRF model to further refine the result of the CNN. We evaluate our method on two public benchmark datasets. Experimental results demonstrate that our method achieves the state-of-the-art level on both accuracy and runtime.
C1 [Zhu, Xianyi; Xiao, Yi] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha, Hunan, Peoples R China.
   [Zheng, Yan] Hunan Univ, Coll Elect & Informat Engn, Changsha, Hunan, Peoples R China.
C3 Hunan University; Hunan University
RP Xiao, Y (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha, Hunan, Peoples R China.
EM yixiao_csee@hnu.edu.cn
FU National Key R&D Program of China [2018YFB0203904]; NSFC from PRC
   [61872137, 61502158, 61803150]; Hunan NSF [2017JJ3042, 2018JJ3067]
FX The work is supported by the National Key R&D Program of China
   (2018YFB0203904), NSFC from PRC (61872137, 61502158, 61803150), Hunan
   NSF (2017JJ3042, 2018JJ3067).
CR BESAG J, 1986, J R STAT SOC B, V48, P259
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540
   Fan LB, 2013, COMPUT GRAPH FORUM, V32, P157, DOI 10.1111/cgf.12223
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   He JY, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P448, DOI 10.1145/3123266.3123321
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu M, 2017, MULTIMED TOOLS APPL, V76, P23567, DOI 10.1007/s11042-016-4112-9
   Huang Z, 2014, ACM T GRAPHIC, V33, DOI [10.1145/2661229.2661280, 10.1145/2661228.2661280]
   Kim B, 2018, COMPUT GRAPH FORUM, V37, P329, DOI 10.1111/cgf.13365
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lafferty John, 2001, INT C MACH LEARN ICM
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li B, 2017, MULTIMED TOOLS APPL, V76, P26603, DOI 10.1007/s11042-016-4187-3
   Li L, 2019, IEEE COMPUT GRAPH, V39, P38, DOI 10.1109/MCG.2018.2884192
   Li S. Z., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P361, DOI 10.1007/BFb0028368
   Li YH, 2018, MULTIMED TOOLS APPL, V77, P2921, DOI 10.1007/s11042-017-4446-y
   Liu LC, 2018, IEEE T IMAGE PROCESS, V27, P4345, DOI 10.1109/TIP.2018.2831454
   Liu LC, 2017, PATTERN RECOGN, V64, P314, DOI 10.1016/j.patcog.2016.10.034
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Mark S, 2015, UGM MATLAB CODE UNDI
   Noris G, 2012, COMPUT GRAPH FORUM, V31, P2516, DOI 10.1111/j.1467-8659.2012.03224.x
   Qi YG, 2015, PROC CVPR IEEE, P1856, DOI 10.1109/CVPR.2015.7298795
   Qi YG, 2013, IEEE IMAGE PROC, P270, DOI 10.1109/ICIP.2013.6738056
   Qin J, 2017, PROC CVPR IEEE, P6728, DOI 10.1109/CVPR.2017.712
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Sangkloy P, 2017, PROC CVPR IEEE, P6836, DOI 10.1109/CVPR.2017.723
   Sangkloy P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925954
   Sarvadevabhatla RK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P10, DOI 10.1145/3123266.3123270
   Schneider RG, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2898351
   Seddati O, 2017, MULTIMED TOOLS APPL, V76, P22333, DOI 10.1007/s11042-017-4799-2
   Shang C., 2018, ARXIV PREPRINT ARXIV
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tan GH, 2016, MULTIMED TOOLS APPL, V75, P10213, DOI 10.1007/s11042-015-3160-x
   Tompson Jonathan, 2014, ARXIV14062984, DOI DOI 10.5555/2968826.2969027
   Wan L, 2018, MULTIMED TOOLS APPL, V77, P13753, DOI 10.1007/s11042-017-4987-0
   Wang C., 2016, P 2016 ACM MULT C, P988, DOI 10.1145/2964284.2964299
   Wang CL, 2018, INT CONF CLOUD COMPU, P360, DOI 10.1109/CCIS.2018.8691250
   Wang C, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3115432
   Wang C, 2016, MULTIMED TOOLS APPL, V75, P9255, DOI 10.1007/s11042-016-3380-8
   Wang SH, 2020, NEURAL COMPUT APPL, V32, P665, DOI 10.1007/s00521-018-3924-0
   Wang Z, 2012, PROCEEDING OF THE IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P626, DOI 10.1109/ICInfA.2012.6246889
   Xu BX, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601128
   Xu K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461968
   Yin W., 2009, Gurobi mex: A matlab interface for gurobi
   [于谦 Yu Qian], 2015, [高分子通报, Polymer Bulletin], P1
   Zhang HB, 2016, IEEE INT CONF ELECTR, P6, DOI 10.1109/ICEIEC.2016.7589675
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22821, DOI 10.1007/s11042-018-5765-3
   Zheng Y, 2019, J VIS COMMUN IMAGE R, V58, P53, DOI 10.1016/j.jvcir.2018.11.028
   Zhou SZ, 2018, COMPUT GRAPH-UK, V73, P80, DOI 10.1016/j.cag.2018.03.002
NR 50
TC 14
Z9 16
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 1585
EP 1602
DI 10.1007/s11042-019-08158-z
EA NOV 2019
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000493973000001
DA 2024-07-18
ER

PT J
AU Hooda, R
   Mittal, A
   Sofat, S
AF Hooda, Rahul
   Mittal, Ajay
   Sofat, Sanjeev
TI Automated TB classification using ensemble of deep architectures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tuberculosis classification; Medical image analysis; Deep-learning;
   Chest radiograph
ID BRAIN-TUMOR SEGMENTATION; CHEST RADIOGRAPHS; PULMONARY TUBERCULOSIS;
   DETECT TUBERCULOSIS; ABNORMALITIES; COMBINATION; FEATURES; TEXTURE;
   FUSION
AB Tuberculosis (TB) is an infectious disease that mainly affects the lung region. Its initial screening is mostly performed using chest radiograph, which is also recommended by the World Health Organization. To help the radiologists in diagnosing this disease, different computer-aided diagnosis (CAD) systems have been developed. However, the development of these systems are still in the early phases as it is extremely challenging to automatically detect TB. This is due to extreme variations in the impact caused by TB on the CXR. In this study, a deep-learning-based TB detection system has been presented which achieves significantly high accuracy. The proposed method is an ensemble of three standard architectures namely AlexNet, GoogleNet and ResNet. The significant contribution of the study is to train these architectures from scratch and creating an ensemble suited to perform TB classification. The proposed method is trained and evaluated on a combined dataset formed using publicly available standard datasets. The ensemble attains the accuracy of 88.24% and area under the curve is equal to 0.93, which eclipses the performance of most of the existing methods.
C1 [Hooda, Rahul; Sofat, Sanjeev] Deemed Be Univ, Punjab Engn Coll, Dept Comp Sci & Engn, Chandigarh, India.
   [Mittal, Ajay] Panjab Univ, UIET, Dept Comp Sci & Engn, Chandigarh, India.
C3 Punjab Engineering College (Deemed University); Panjab University
RP Mittal, A (corresponding author), Panjab Univ, UIET, Dept Comp Sci & Engn, Chandigarh, India.
EM r89hooda@gmail.com; ajaymittal@pu.ac.in; sanjeevsofat@pec.ac.in
CR [Anonymous], SPIE MED IMAGING
   [Anonymous], SPIE MED IMAGING
   [Anonymous], P PATT REC ASS S AFR
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 2006, P WSEAS INT C SIGN S
   Arzhaeva Y, 2009, LECT NOTES COMPUT SC, V5762, P724, DOI 10.1007/978-3-642-04271-3_88
   Bar Y, 2018, COMP M BIO BIO E-IV, V6, P259, DOI 10.1080/21681163.2016.1138324
   Bar Y, 2015, I S BIOMED IMAGING, P294, DOI 10.1109/ISBI.2015.7163871
   Cao Y, 2016, 2016 IEEE FIRST INTERNATIONAL CONFERENCE ON CONNECTED HEALTH: APPLICATIONS, SYSTEMS AND ENGINEERING TECHNOLOGIES (CHASE), P274, DOI 10.1109/CHASE.2016.18
   Chen H, 2016, AAAI CONF ARTIF INTE, P1160
   Ciresan DC, 2013, LECT NOTES COMPUT SC, V8150, P411, DOI 10.1007/978-3-642-40763-5_51
   Ebrahimian H, 2014, 2014 IEEE CONFERENCE ON BIOMEDICAL ENGINEERING AND SCIENCES (IECBES), P729, DOI 10.1109/IECBES.2014.7047604
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Girardi Dominic, 2016, Brain Inform, V3, P133, DOI 10.1007/s40708-016-0038-2
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heo SJ, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16020250
   Hogeweg L, 2015, IEEE T MED IMAGING, V34, P2429, DOI 10.1109/TMI.2015.2405761
   Hogeweg L, 2010, LECT NOTES COMPUT SC, V6363, P650
   Holzinger A, 2016, LECT NOTES COMPUT SC, V9817, P81, DOI 10.1007/978-3-319-45507-5_6
   Holzinger Andreas, 2016, Brain Inform, V3, P119, DOI 10.1007/s40708-016-0042-6
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jaeger S, 2014, QUANT IMAG MED SURG, V4, P475, DOI 10.3978/j.issn.2223-4292.2014.11.20
   Jaeger S, 2014, IEEE T MED IMAGING, V33, P233, DOI 10.1109/TMI.2013.2284099
   Jaeger S, 2012, IEEE ENG MED BIO, P4978, DOI 10.1109/EMBC.2012.6347110
   JAGOE AR, 1976, IEEE T COMPUT, V25, P95, DOI 10.1109/TC.1976.5009212
   Karargyris A, 2016, INT J COMPUT ASS RAD, V11, P99, DOI 10.1007/s11548-015-1242-x
   Lakhani P, 2017, RADIOLOGY, V284, P574, DOI 10.1148/radiol.2017162326
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Maduskar P, 2016, MED IMAGE ANAL, V28, P22, DOI 10.1016/j.media.2015.09.004
   Melendez J, 2016, IEEE T MED IMAGING, V35, P1013, DOI 10.1109/TMI.2015.2505672
   Mohd Rijal Omar, 2012, 2012 IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI), P341, DOI 10.1109/BHI.2012.6211583
   PAUL JL, 1974, IEEE T BIO-MED ENG, VBM21, P444, DOI 10.1109/TBME.1974.324332
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Prasoon A, 2013, LECT NOTES COMPUT SC, V8150, P246, DOI 10.1007/978-3-642-40763-5_31
   Ratnasari NR, 2013, INT C INSTR COMMUN, P65, DOI 10.1109/ICICI-BME.2013.6698466
   Roth HR, 2015, LECT NOTES COMPUT SC, V9349, P556, DOI 10.1007/978-3-319-24553-9_68
   Roth HR, 2015, PROC SPIE, V9413, DOI 10.1117/12.2081420
   Shen R, 2010, IEEE T BIO-MED ENG, V57, P2646, DOI 10.1109/TBME.2010.2057509
   Shiraishi J, 2000, AM J ROENTGENOL, V174, P71, DOI 10.2214/ajr.174.1.1740071
   Simonyan K., 2014, 14091556 ARXIV
   Song J, 2018, IEEE Trans Neural Netw Learning Sys, P1
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Song J, 2016, IEEE T IMAGE PROCESS, V25, P4999, DOI 10.1109/TIP.2016.2601260
   SUTTON RN, 1972, IEEE T COMPUT, VC 21, P667, DOI 10.1109/T-C.1972.223572
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan JH, 2012, J MED SYST, V36, P2751, DOI 10.1007/s10916-011-9751-9
   van Ginneken B, 2002, IEEE T MED IMAGING, V21, P139, DOI 10.1109/42.993132
   Wang HB, 2014, J MED IMAGING, V1, DOI 10.1117/1.JMI.1.3.034003
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   World Health Organization (WHO), 2016, GLOB TUB REP 2016
   Xu T, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-3
   Xuanhan Wang, 2017, IEEE Signal Processing Letters, V24, P510, DOI 10.1109/LSP.2016.2611485
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
NR 56
TC 22
Z9 22
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31515
EP 31532
DI 10.1007/s11042-019-07984-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000024
DA 2024-07-18
ER

PT J
AU Qin, J
   Shen, XJ
   Chen, HP
   Lv, YD
   Zhang, XL
AF Qin, Jun
   Shen, Xuanjing
   Chen, Haipeng
   Lv, Yingda
   Zhang, Xiaoli
TI A fusion algorithm for medical structural and functional images based on
   adaptive image decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image fusion; Image decomposition; Color distortion; Texture
   perseveration
ID TRANSFORM; CT; INFORMATION; TRADEOFF
AB Multimodal medical image fusion has been widely used as a powerful tool in the clinical applications because of its ability of enriching information of medical images. In this paper, a novel fusion algorithm dedicated to medical structural and functional image fusion. In the algorithm, textures from functional images are separated from the smooth component in structural images; then we need to segment the source images into two parts function-informative and function-uninformative regions by judging whether each pixel in the functional image contains informative color (black pixel is meaningless); then get the smooth version of fused image by filling the function-informative region with the color from functional image and filling the function-uninformative region with smooth component in structural images; finally, smooth version of fused image and textures from the functional image are combined to get the final fused image. The attractive features of the algorithms include its ability of both color and texture reservation and low time consumption. Experimental results demonstrate that the proposed method can obtain state-of-the-art performance for medical structural and functional image fusion.
C1 [Qin, Jun; Shen, Xuanjing; Chen, Haipeng; Lv, Yingda; Zhang, Xiaoli] Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Jilin, Peoples R China.
   [Qin, Jun; Shen, Xuanjing; Chen, Haipeng; Lv, Yingda; Zhang, Xiaoli] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China.
C3 Jilin University; Jilin University
RP Chen, HP (corresponding author), Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Jilin, Peoples R China.; Chen, HP (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China.
EM chenhp@jlu.edu.cn
RI Zhang, Xiaoli/ABC-2210-2021
FU National Natural Science Foundation of China [61672259, 61602203,
   61876070, 61801190]; Outstanding Young Talent Foundation of Jilin
   Province [20180520029JH]; China Postdoctoral Science Foundation
   [2017M611323]
FX The work was supported by National Natural Science Foundation of China
   (Grant No. 61672259, 61602203, 61876070, 61801190), Outstanding Young
   Talent Foundation of Jilin Province (Grant No. 20180520029JH) and China
   Postdoctoral Science Foundation (Grant No. 2017M611323). We would also
   like to thank http://www.med.harvard.edu/aanlib/home.html for providing
   us the source medical images.
CR Ali F. E., 2008, Progress In Electromagnetics Research C, V3, P215, DOI 10.2528/PIERC08041305
   Avola D, 2019, MULTIMED TOOLS APPL, V78, P5919, DOI 10.1007/s11042-018-6875-7
   Bhatnagar G, 2015, NEUROCOMPUTING, V157, P143, DOI 10.1016/j.neucom.2015.01.025
   Bhatnagar G, 2013, IEEE T MULTIMEDIA, V15, P1014, DOI 10.1109/TMM.2013.2244870
   Bhatnagar G, 2013, EXPERT SYST APPL, V40, P1708, DOI 10.1016/j.eswa.2012.09.011
   Calvi GG, 2018, EUR SIGNAL PR CONF, P2623, DOI 10.23919/EUSIPCO.2018.8553605
   Chen T, 2005, INT GEOSCI REMOTE SE, P1150
   Choi M, 2006, IEEE T GEOSCI REMOTE, V44, P1672, DOI 10.1109/TGRS.2006.869923
   Daneshvar S, 2010, INFORM FUSION, V11, P114, DOI 10.1016/j.inffus.2009.05.003
   Das S, 2013, IEEE T BIO-MED ENG, V60, P3347, DOI 10.1109/TBME.2013.2282461
   Das S, 2012, MED BIOL ENG COMPUT, V50, P1105, DOI 10.1007/s11517-012-0943-3
   Ding M, 2013, INFRARED PHYS TECHN, V57, P56, DOI 10.1016/j.infrared.2012.12.014
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Girardi Dominic, 2016, Brain Inform, V3, P133, DOI 10.1007/s40708-016-0038-2
   González-Audícana M, 2004, IEEE T GEOSCI REMOTE, V42, P1291, DOI 10.1109/TGRS.2004.825593
   Harikumar V, 2014, IEEE J-STARS, V7, P1771, DOI 10.1109/JSTARS.2013.2287891
   Holzinger A, 2016, LECT NOTES COMPUT SC, V9817, P81, DOI 10.1007/978-3-319-45507-5_6
   Holzinger Andreas, 2016, Brain Inform, V3, P119, DOI 10.1007/s40708-016-0042-6
   James AP, 2014, INFORM FUSION, V19, P4, DOI 10.1016/j.inffus.2013.12.002
   Jinno T, 2012, IEEE T IMAGE PROCESS, V21, P358, DOI 10.1109/TIP.2011.2160953
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Li HF, 2012, OPT COMMUN, V285, P91, DOI 10.1016/j.optcom.2011.08.078
   Li ST, 2013, IEEE T GEOSCI REMOTE, V51, P4779, DOI 10.1109/TGRS.2012.2230332
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li ST, 2012, IEEE T BIO-MED ENG, V59, P3450, DOI 10.1109/TBME.2012.2217493
   Li ST, 2012, IEEE T CONSUM ELECTR, V58, P626, DOI 10.1109/TCE.2012.6227469
   Lischinski D, 2006, ACM T GRAPHIC, V25, P646, DOI 10.1145/1141911.1141936
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Liu ZD, 2014, EXPERT SYST APPL, V41, P7425, DOI 10.1016/j.eswa.2014.05.043
   Liu Z, 2014, OPT COMMUN, V331, P169, DOI 10.1016/j.optcom.2014.06.012
   Maintz J B, 1998, Med Image Anal, V2, P1, DOI 10.1016/S1361-8415(01)80026-8
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pajares G, 2004, PATTERN RECOGN, V37, P1855, DOI 10.1016/j.patcog.2004.03.010
   Petrovic V, 2005, OPT ENG, V44, DOI 10.1117/1.2009764
   Petrovic V, 2007, INFORM FUSION, V8, P208, DOI 10.1016/j.inffus.2005.05.001
   Piella G, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P173
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Qu GH, 2001, OPT EXPRESS, V9, P184, DOI 10.1364/OE.9.000184
   Singh S, 2015, BIOMED SIGNAL PROCES, V18, P91, DOI 10.1016/j.bspc.2014.11.009
   Suh JW, 2012, MED PHYS, V39, P533, DOI 10.1118/1.3672167
   Tian J, 2012, SIGNAL PROCESS, V92, P2137, DOI 10.1016/j.sigpro.2012.01.027
   Tu TM, 2007, IEEE GEOSCI REMOTE S, V4, P302, DOI 10.1109/LGRS.2007.894143
   Wan T, 2008, IEEE IMAGE PROC, P1308, DOI 10.1109/ICIP.2008.4712003
   Wang L, 2014, INFORM FUSION, V19, P29, DOI 10.1016/j.inffus.2013.04.005
   Wang L, 2014, INFORM FUSION, V19, P20, DOI 10.1016/j.inffus.2012.03.002
   Wang QZ, 2015, INFORM FUSION, V26, P103, DOI 10.1016/j.inffus.2015.01.001
   Wang Z., 2006, Modern Image Quality Assessment, DOI 10.2200/S00010ED1V01Y200508IVM003
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wang ZB, 2008, INFORM FUSION, V9, P176, DOI 10.1016/j.inffus.2007.04.003
   Wong A, 2008, PATTERN RECOGN LETT, V29, P173, DOI 10.1016/j.patrec.2007.08.018
   Xu ZP, 2014, INFORM FUSION, V19, P38, DOI 10.1016/j.inffus.2013.01.001
   Yang L, 2008, NEUROCOMPUTING, V72, P203, DOI 10.1016/j.neucom.2008.02.025
   Zhang XL, 2014, SIGNAL PROCESS, V102, P64, DOI 10.1016/j.sigpro.2014.02.024
NR 53
TC 4
Z9 4
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 32605
EP 32629
DI 10.1007/s11042-019-07968-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000068
DA 2024-07-18
ER

PT J
AU Yu, ZY
   Wang, J
   Lu, GD
AF Yu, Zhiyong
   Wang, Jin
   Lu, Guodong
TI Optimized self-adapting contrast enhancement algorithm for wafer contour
   extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Self-adapting; Wafer; Edge extraction; Contrast enhancement; Defect
   detection
ID DEFECT DETECTION; IMAGES
AB The aim is to design a self-adapting contrast enhancement algorithm that can remove the background noise and divide the foreground and background very well. For the self-adapting contrast enhancement algorithm, we looked for all background RGB pixel values, and found the minimum values in the RGB components so that partial derivative =255/min(I-pixel(R,G,B)). The results were compared to classical contrast enhancement techniques. Five steps to extract the wafer contour, respectively, were the preservation filter, self-adapting contrast enhancement, closing morphological operation, image binarization based on the Otsu method and using the first derivative extract contour. The results of contour extraction were compared with the traditional Canny, Sobel and Scharr algorithms using different parameter values. The experiment results showed that the self-adapting contrast enhancement algorithm could remove the background noise effectively compared to traditional methods. In comparison with the Canny, Sobel and Scharr algorithms, the first derivative after the original image filtering by optimized self-adapting contrast enhancement algorithm was better at extracting wafer contours. Therefore, we concluded that the wafer self-adapting contrast enhancement algorithm method was correct and feasible. The theories in this paper could be applied to image processing in the agricultural, industrial, and military fields.
C1 [Yu, Zhiyong; Wang, Jin; Lu, Guodong] Zhejiang Univ, State Key Lab Fluid Power & Mechatron Syst, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Wang, J (corresponding author), Zhejiang Univ, State Key Lab Fluid Power & Mechatron Syst, Hangzhou 310027, Zhejiang, Peoples R China.
EM dwjcom@zju.edu.cn
FU National Key R&D Program of China [2017YFB1301203]; National Natural
   Science Foundation of China [51775492]; Robotics Institute of Zhejiang
   University [K11808]
FX This work was supported by the National Key R&D Program of China
   (No.2017YFB1301203), National Natural Science Foundation of China
   (No.51775492) and Robotics Institute of Zhejiang University under Grant
   K11808.
CR ABDOU IE, 1979, P IEEE, V67, P753, DOI 10.1109/PROC.1979.11325
   Abdulrahman H, 2017, CONTOURS GROUND TRUT
   [Anonymous], 1983, Finding Edges and Lines in Images
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Aytekin Ç, 2015, IEEE T SYST MAN CY-S, V45, P1101, DOI 10.1109/TSMC.2014.2388435
   Boaventura A. G., 2009, METHOD EVALUATE PERF
   Bosseboeuf A, 2017, 2017 5TH INTERNATIONAL WORKSHOP ON LOW TEMPERATURE BONDING FOR 3D INTEGRATION (LTB-3D), P19, DOI 10.23919/LTB-3D.2017.7947415
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chen GH, 2017, U.S. Patent, Patent No. [9,816,940, 9816940]
   Chen H, 2017, U.S. Patent, Patent No. [9,766,186, 9766186]
   Fredj AH, 2016, INT DES TEST SYMP, P308, DOI 10.1109/IDT.2016.7843060
   Gao L, 2015, U.S. Patent Application, Patent No. [14/612,192, 14612192]
   Hiner D, 2015, ELEC COMP C, P17, DOI 10.1109/ECTC.2015.7159565
   Joshi M. A., 2018, DIGITAL IMAGE PROCES
   Karimi MH, 2014, ISA T, V53, P834, DOI 10.1016/j.isatra.2013.11.015
   Kim S, 2017, J SEMICOND TECH SCI, V17, P86, DOI 10.5573/JSTS.2017.17.1.086
   Koch C, 2015, ADV ENG INFORM, V29, P196, DOI 10.1016/j.aei.2015.01.008
   Kwon BK, 2015, INT J PRECIS ENG MAN, V16, P965, DOI 10.1007/s12541-015-0125-y
   Kwon OS, 2014, AUTOMAT CONSTR, V46, P74, DOI 10.1016/j.autcon.2014.05.005
   Kyeremateng NA, 2017, NAT NANOTECHNOL, V12, P7, DOI [10.1038/nnano.2016.196, 10.1038/NNANO.2016.196]
   Lakcher A, 2017, METROLOGY INSPECTION, V10145
   Lee C, 2017, U.S. Patent, Patent No. [9,601,393, 9601393]
   Liu D, 2017, SCRIPTA MATER, V128, P57, DOI 10.1016/j.scriptamat.2016.10.006
   Liu M.-Y., 2017, NIPS
   Liu XM, 2015, INT CONF ACOUST SPEE, P2274, DOI 10.1109/ICASSP.2015.7178376
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Malloy M, 2015, PROC SPIE, V9423, DOI 10.1117/12.2175535
   Ren RX, 2018, IEEE T CYBERNETICS, V48, P929, DOI 10.1109/TCYB.2017.2668395
   Sadykova D, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2366, DOI 10.1109/ICACCI.2017.8126200
   Selvi SST., 2017, J ENV NANOTECHNOL, V6, P79, DOI [10.13074/jent.2017.03.171241, DOI 10.13074/JENT.2017.03.171241]
   Shifrin E, 2016, U.S. Patent, Patent No. [9,355,208, 9355208]
   Singh K, 2014, PATTERN RECOGN LETT, V36, P10, DOI 10.1016/j.patrec.2013.08.024
   Sobel I., 1968, STANF ART PROJ, P271
   Sonka M., 2014, Image processing, analysis, and machine vision
   van Dokkum PG, 2001, PUBL ASTRON SOC PAC, V113, P1420, DOI 10.1086/323894
   Vincent O., 2009, P INFORMING SCI IT E, P97
   WANG DM, 1995, PATTERN RECOGN, V28, P1783, DOI 10.1016/0031-3203(95)00036-Y
NR 38
TC 5
Z9 6
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 32087
EP 32108
DI 10.1007/s11042-019-08019-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000048
DA 2024-07-18
ER

PT J
AU Wu, J
   Ren, XX
   Xiao, ZT
   Zhang, F
   Geng, L
   Zhang, SH
AF Wu, Jun
   Ren, Xingxing
   Xiao, Zhitao
   Zhang, Fang
   Geng, Lei
   Zhang, Shihao
TI Research on fundus image registration and fusion method based on
   nonsubsampled contourlet and adaptive pulse coupled neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fundus fusion; Nonsubsampled contourlet; Regional energy;
   Simplified-pulse coupled neural network; Particle swarm optimization
ID TRANSFORM
AB We present a registration and fusion method of fluorescein fundus angiography image and color fundus image which combines Nonsubsampled Contourlet (NSCT) and adaptive Pulse Coupled Neural Network (PCNN). Firstly, we register two images by Speeded Up Robust Features (SURF) feature points, the nearest neighbor and the next nearest neighbor distance ratio method to eliminate the spatial difference between the source images. Secondly, we use Random Sample Consensus (RANSAC) algorithm to achieve precise matching of feature points. Then, according to the transformation parameters obtained by RANSAC algorithm, we perform spatial transformation on the floating image to complete the registration. Finally, we obtain the low-frequency sub-band and high-frequency sub-band of the image to be fused by NSCT decomposition. The low-frequency sub-band is fused by the regional energy. The high-frequency sub-bands are studied using a simplified-PCNN model and the Particle Swarm Optimization algorithm. The link strength of the simplified-PCNN is an improved Laplacian energy and the images are fused based on the number of times the pixels are ignited. The proposed method has higher average gradient (AG) value and information entropy (IE) value and lower relative global dimensional synthesis error (ERGAS) than the existing fusion methods of the fundus image. The fusion image can accurately synthesize the image information, clarify the performance of the details, and has better spectral quality in the spectral range. The image of fused provides an effective reference for the clinical diagnosis of fundus diseases.
C1 [Wu, Jun; Ren, Xingxing; Xiao, Zhitao; Zhang, Fang; Geng, Lei; Zhang, Shihao] Tianjin Polytech Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
   [Wu, Jun; Ren, Xingxing; Xiao, Zhitao; Zhang, Fang; Geng, Lei; Zhang, Shihao] Tianjin Key Lab Optoelect Detect Technol & Syst, Tianjin, Peoples R China.
C3 Tiangong University
RP Xiao, ZT (corresponding author), Tianjin Polytech Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.; Xiao, ZT (corresponding author), Tianjin Key Lab Optoelect Detect Technol & Syst, Tianjin, Peoples R China.
EM wujun@tjpu.edu.cn; dianxinrxx@163.com; xiaozhitao@tjpu.edu.cn;
   zhangfang@tjpu.edu.cn; genglei@tjpu.edu.cn
RI geng, lei/KEZ-8801-2024
OI Geng, Lei/0000-0002-5010-2596
FU National Natural Science Foundation of China [61771340]; Tianjin Science
   and Technology Major Projects and Engineering [17ZXHLSY00040,
   17ZXSCSY00060, 17ZXSCSY00090]
FX This work was supported by the National Natural Science Foundation of
   China, under grant No. 61771340; Tianjin Science and Technology Major
   Projects and Engineering, under grant No. 17ZXHLSY00040, No.
   17ZXSCSY00060 and No. 17ZXSCSY00090.
CR Candes E. J., 1999, RIDGELETS THEORY APP
   Chen JA, 2010, IEEE T BIO-MED ENG, V57, P1707, DOI 10.1109/TBME.2010.2042169
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Dai W, 2016, J ELECT, V08, P1932
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Eberhart R.C., 2001, MORGAN KAUFMANN SERI, V2001, P475
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Goshtasby AA, 2007, INFORM FUSION, V8, P114, DOI 10.1016/j.inffus.2006.04.001
   Guo F, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S0218001417570063
   He F, 2017, ACTA OPT SINICA, V2017, P175
   Izhikevich EM, 1999, IEEE T NEURAL NETWOR, V10, P499, DOI 10.1109/72.761707
   Ju J, 2016, IEICE T INF SYST, VE99D, P1729, DOI 10.1587/transinf.2015EDL8265
   Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968
   Li Xin'e, 2013, Infrared and Laser Engineering, V42, P3096
   [廖勇 Liao Yong], 2014, [计算机工程与应用, Computer Engineering and Application], V50, P142
   [罗天健 Luo Tianjian], 2015, [中国图象图形学报, Journal of Image and Graphics], V20, P95
   Maia GA, 2004, IEEE T GEOSCI REMOTE, V2004, P1291
   Miri MS, 2016, BIOMED OPT EXPRESS, V7, P5252, DOI 10.1364/BOE.7.005252
   Nencini F, 2007, INFORM FUSION, V8, P143, DOI 10.1016/j.inffus.2006.02.001
   Santosh KC, 2018, INT J MACH LEARN CYB, V9, P993, DOI 10.1007/s13042-016-0623-y
   Santosh KC, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416570020
   Song Jianhui, 2016, Computer Engineering and Applications, V52, P186, DOI 10.3778/j.issn.1002-8331.1405-0198
   Song Ruixia, 2016, Journal of Computer Aided Design & Computer Graphics, V28, P2134
   Sun Y, 2017, J ALGORITHMS COMPUT, V11, P163, DOI 10.1177/1748301816689686
   Wu J, 2017, INT J ENG INVENTIONS
   Yang Li-Cai, 2009, Chinese Journal of Biomedical Engineering, V28, P12
   Zhou DG, 2014, SOFT COMPUT, V18, P557, DOI 10.1007/s00500-013-1077-8
NR 27
TC 1
Z9 1
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 34795
EP 34812
DI 10.1007/s11042-019-08194-9
EA OCT 2019
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000489940100002
DA 2024-07-18
ER

PT J
AU Koivunen-Niemi, L
   Masoodian, M
AF Koivunen-Niemi, Laura
   Masoodian, Masood
TI Visualizing narrative patterns in online news media
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Temporal visualization; Co-occurrence visualization; Multimedia content;
   Time-sets; Visual design; Journalism
ID SET; TELEVISION
AB News media play an important role in shaping social reality, and their multimedia narrative content, in particular, can have widespread repercussions in the public's perception of past and present phenomena. Being able to visually track changes in media coverage over time could offer the potential for aiding social change, as well as furthering accountability in journalism. In this paper, we explore how visualizations could be used to examine differences in online media narrative patterns over time and across publications. While there are existing means of visualizing such narrative patterns over time, few address the aspect of co-occurrence of variables in media content. Comparing co-occurrences of variables chronologically can be more useful in identifying patterns and possible biases in media coverage than simply counting the individual occurrences of those variables independently. Here, we present a visualization, called time-sets, which has been designed to support temporal comparisons of such co-occurrences. We also describe an interactive prototype tool we have developed based on time-sets for analysis of multimedia news datasets, using an illustrative case study of news articles published on three online sources over several years. We then report on a user study we have conducted to evaluate the time-sets visualization, and discuss its findings.
C1 [Koivunen-Niemi, Laura; Masoodian, Masood] Aalto Univ, Sch Arts Design & Architecture, Espoo, Finland.
C3 Aalto University
RP Masoodian, M (corresponding author), Aalto Univ, Sch Arts Design & Architecture, Espoo, Finland.
EM laura.koivunen-niemi@alumni.aalto.fi; masood.masoodian@aalto.fi
OI Masoodian, Masood/0000-0003-3861-6321
FU Aalto University
FX Open access funding provided by Aalto University.
CR Aigner W., 2011, HUMAN COMPUTER INTER, DOI DOI 10.1007/978-0-85729-079-3
   Alsallakh B, 2016, COMPUT GRAPH FORUM, V35, P234, DOI 10.1111/cgf.12722
   Angus D, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0038014
   Angus D, 2012, IEEE T VIS COMPUT GR, V18, P988, DOI 10.1109/TVCG.2011.100
   [Anonymous], 1981, Graphics and Graphic Information-Processing
   [Anonymous], 1994, ACM Transactions on Computer-Human Interaction, DOI [10.1145/180171.180173, DOI 10.1145/180171.180173]
   Bullinaria JA, 2007, BEHAV RES METHODS, V39, P510, DOI 10.3758/BF03193020
   Chapman P, 2014, LECT NOTES COMPUT SC, V8578, P146, DOI 10.1007/978-3-662-44043-8_18
   Choi J., 2009, International Communication Gazette, V71, P525, DOI https://doi.org/10.1177/1748048509339788
   CLEVELAND WS, 1985, SCIENCE, V229, P828, DOI 10.1126/science.229.4716.828
   Fahmy ShahiraS., 2011, International Communication Gazette, V73, P216, DOI [10.1177/1748048510393656, DOI 10.1177/1748048510393656]
   Friendly M, 2008, STAT SCI, V23, P502, DOI 10.1214/08-STS268
   Gan Faith., 2005, Gazette: The International Journal for Communication Studies, V67, P441, DOI DOI 10.1177/0016549205056052
   Gottfried B, 2015, J SPAT INT SCI, P3, DOI 10.5311/JOSIS.2015.10.187
   Gottfried B, 2014, J VISUAL LANG COMPUT, V25, P518, DOI 10.1016/j.jvlc.2014.04.003
   Huang Y., 2011, International Communication Gazette, V73, P732, DOI DOI 10.1177/1748048511420091
   Humphries B, 2017, CAN J PUBLIC HEALTH, V108, pE381, DOI [10.17269/CJPH.108.5904, 10.17269/cjph.108.5904]
   Jensen KB, 2012, HANDBOOK OF MEDIA AND COMMUNICATION RESEARCH: QUALITATIVE AND QUANTITATIVE METHODOLOGIES, 2ND EDITION, P171
   Kim D., 2009, The International Communication Gazette, V71, P283, DOI DOI 10.1177/1748048509102182
   Koivunen L, 2018, THESIS
   Lex A, 2014, IEEE T VIS COMPUT GR, V20, P1983, DOI 10.1109/TVCG.2014.2346248
   Lim J, 2019, INT COMMUN GAZ, V81, P89, DOI 10.1177/1748048518759194
   Luz S, 2019, INFORM VISUAL, V18, P297, DOI 10.1177/1473871618754343
   Luz S, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, AVI 2014, P293, DOI 10.1145/2598153.2598187
   Luz S, 2011, IEEE INT CONF INF VI, P182, DOI 10.1109/IV.2011.53
   Mahony I., 2010, INT COMMUN GAZ, V72, P739, DOI [10.1177/1748048510380813, DOI 10.1177/1748048510380813]
   Maier S, 2010, J MASS COMMUN Q, V87, P548, DOI 10.1177/107769901008700307
   Masoodian M, 2018, IEEE INT CON INF VIS, P85, DOI 10.1109/iV.2018.00025
   Rodgers P, 2015, ACM T COMPUT-HUM INT, V22, DOI 10.1145/2810012
   Rodgers P, 2014, J VISUAL LANG COMPUT, V25, P134, DOI 10.1016/j.jvlc.2013.08.006
   Sadana R, 2014, IEEE T VIS COMPUT GR, V20, P1993, DOI 10.1109/TVCG.2014.2346249
   Sheehan S, 2018, AVI'18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON ADVANCED VISUAL INTERFACES, DOI 10.1145/3206505.3206547
   Stromback J., 2008, INT COMMUN GAZ, V70, P547, DOI [10.1177/1748048508096398, DOI 10.1177/1748048508096398]
   Tufte E.R., 2000, Visual explanations, V4th
NR 35
TC 4
Z9 4
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 919
EP 946
DI 10.1007/s11042-019-08186-9
EA OCT 2019
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000492481400002
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Liu, AN
   Zhao, ZY
   Zhang, CQ
   Su, YT
AF Liu, Anan
   Zhao, Zhengyu
   Zhang, Chengqian
   Su, Yuting
TI Smooth filtering identification based on convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital forensics; Spatial smooth filtering; Convolutional neural
   network; Deep learning; Discrete Fourier transform; JPEG compression
ID IMAGE; TRACES; MODEL
AB The increasing prevalence of digital technology brings great convenience to human life, while also shows us the problems and challenges. Relying on easy-to-use image editing tools, some malicious manipulations, such as image forgery, have already threatened the authenticity of information, especially the electronic evidence in the crimes. As a result, digital forensics attracts more and more attention of researchers. Since some general post-operations, like widely used smooth filtering, can affect the reliability of forensic methods in various ways, it is also significant to detect them. Furthermore, the determination of detailed filtering parameters assists to recover the tampering history of an image. To deal with this problem, we propose a new approach based on convolutional neural networks (CNNs). Through adding a transform layer, obtained distinguishable frequency-domain features are put into a conventional CNN model, to identify the template parameters of various types of spatial smooth filtering operations, such as average, Gaussian and median filtering. Experimental results on a composite database show that putting the images directly into the conventional CNN model without transformation can not work well, and our method achieves better performance than some other applicable related methods, especially in the scenarios of small size and JPEG compression.
C1 [Liu, Anan; Zhao, Zhengyu; Su, Yuting] Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
   [Zhang, Chengqian] Southwest Petr Univ, Sch Elect Engn & Informat, Chengdu 610500, Sichuan, Peoples R China.
C3 Tianjin University; Southwest Petroleum University
RP Su, YT (corresponding author), Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
EM liuanan@tju.edu.cn; zyzhao2014@tju.edu.cn; zhangcqj@tju.edu.cn;
   ytsu@tju.edu.cn
RI Zhao, Zhengyu/GYD-5093-2022
FU National Natural Science Foundation of China [61572356, 61472275,
   61303208]; Tianjin Research Program of Application Foundation and
   Advanced Technology [15JCYBJC16200]; China Scholarship Council
   [201506255073]; Elite Scholar Program of Tianjin University
   [2014XRG-0046]
FX This work was supported in part by the National Natural Science
   Foundation of China (61572356, 61472275, 61303208), the Tianjin Research
   Program of Application Foundation and Advanced Technology
   (15JCYBJC16200), a grant from the China Scholarship Council
   (201506255073), and a grant from the Elite Scholar Program of Tianjin
   University (2014XRG-0046).
CR [Anonymous], 2014, ASIA PACIFIC SIGNAL
   [Anonymous], COMPUTER SCI
   [Anonymous], 2010, J MACH LEARN RES
   Bahrami K, 2015, IEEE T INF FOREN SEC, V10, P999, DOI 10.1109/TIFS.2015.2394231
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Cao G, 2010, IEEE INT CON MULTI, P89, DOI 10.1109/ICME.2010.5583869
   Chen CL, 2013, IEEE T IMAGE PROCESS, V22, P4699, DOI 10.1109/TIP.2013.2277814
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Chen JY, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P898, DOI 10.1145/2964284.2964314
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Gloe T., 2010, Proceedings of the ACM Symposium on Applied Computing, P1584, DOI DOI 10.1145/1774088.1774427
   HEYGSTER G, 1982, COMPUT VISION GRAPH, V19, P148, DOI 10.1016/0146-664X(82)90105-8
   Huang HC, 2015, OPT MATER, V46, P1, DOI 10.1016/j.optmat.2015.03.019
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Justusson B.I., 1981, Median Filtering: Statistical Properties
   Kang XG, 2013, IEEE T INF FOREN SEC, V8, P1456, DOI 10.1109/TIFS.2013.2273394
   Kirchberg M., 2010, System Sciences (HICSS), 2010 43rd Hawaii International Conference on, P1
   Kirchner M, 2008, IEEE T INF FOREN SEC, V3, P582, DOI 10.1109/TIFS.2008.2008214
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu X, 2013, PROC CVPR IEEE, P492, DOI 10.1109/CVPR.2013.70
   Liu ZG, 2016, EXPERT SYST APPL, V63, P173, DOI 10.1016/j.eswa.2016.06.033
   Liu ZG, 2014, EXPERT SYST APPL, V41, P7691, DOI 10.1016/j.eswa.2014.06.026
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P480, DOI 10.1109/TIFS.2010.2051426
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Salakhutdinov R., 2009, AISTATS
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10
   Song XM, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2832907
   Stamm MC, 2011, IEEE T INF FOREN SEC, V6, P1050, DOI 10.1109/TIFS.2011.2119314
   Stamm MC, 2010, IEEE T INF FOREN SEC, V5, P492, DOI 10.1109/TIFS.2010.2053202
   VELLEMAN PF, 1980, J AM STAT ASSOC, V75, P609, DOI 10.2307/2287657
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang W, 2016, IEEE MULTIMEDIA, V23, P80, DOI 10.1109/MMUL.2016.69
   Yuan HD, 2011, IEEE T INF FOREN SEC, V6, P1335, DOI 10.1109/TIFS.2011.2161761
   Zhang B, 2015, ACM T MULTIM COMPUT, V12, DOI 10.1145/2750780
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2016, IEEE T IMAGE PROCESS, V25, P553, DOI 10.1109/TIP.2015.2502147
   Zhang LM, 2016, IEEE T CYBERNETICS, V46, P258, DOI 10.1109/TCYB.2015.2400821
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T CYBERNETICS, V44, P1408, DOI 10.1109/TCYB.2013.2285219
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P2235, DOI 10.1109/TIP.2014.2311658
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P802, DOI 10.1109/TIP.2012.2223226
   Zhang N, 2014, PROC CVPR IEEE, P1637, DOI 10.1109/CVPR.2014.212
   Zhang YJ, 2014, IEEE SIGNAL PROC LET, V21, P275, DOI 10.1109/LSP.2013.2295858
   Zhou BL, 2014, ADV NEUR IN, V27
NR 50
TC 21
Z9 24
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 26851
EP 26865
DI 10.1007/s11042-016-4251-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000002
DA 2024-07-18
ER

PT J
AU Seo, J
   Yoo, K
   Choi, S
   Kim, YA
   Han, S
AF Seo, Jiwan
   Yoo, Karam
   Choi, Seungjin
   Kim, Yura Alex
   Han, Sangyong
TI The latent learning model to derive semantic relations of words from
   unstructured text data in social media
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Latent learning; Review to rating; Word representation; Recommendation
ID SYSTEM
AB Unstructured text data is very important in many applications because it reflects the thought of the people who create this data. However, it is difficult to realize the latent information as it was hidden on the unstructured text data. This paper proposes a latent learning method to construct the lexical structure to constitute the relations between the latent meaning and words. The established lexical structure derived the useful information from unstructured text data and this information and this information can be used for various application. This paper describes how to predict a rating from user-written reviews which is one of unstructured text data. And it also provides visualization information of the semantic lexical structures as the result of analysis. As a result, the proposed method easily quantifies the semantic relations of words and it shows good performance on prediction of ratings from unstructured text data. The proposed method can contribute to analyzing the unstructured text data in various perspectives on latent meaning of words.
C1 [Seo, Jiwan; Yoo, Karam; Choi, Seungjin; Kim, Yura Alex; Han, Sangyong] Chung Ang Univ, Dept Comp Sci & Engn, 47 Heukeok Ro, Seoul, South Korea.
C3 Chung Ang University
RP Han, S (corresponding author), Chung Ang Univ, Dept Comp Sci & Engn, 47 Heukeok Ro, Seoul, South Korea.
EM hansy@cau.ac.kr
OI Seo, Jiwan/0000-0003-3463-8822
FU Basic Science Research Program through the National Research Foundation
   of Korea(NRF) - Ministry of Science, ICT and future Planning [NRF -
   2015R1A2 A2A01005304]; Chung-Ang University
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Science, ICT and future Planning (NRF - 2015R1A2 A2A01005304) and this
   research was supported by the Chung-Ang University Graduate Research
   Scholarship in 2015.
CR Alghunaim A, 2015, A vector space approach for aspect-based sentiment analysis
   [Anonymous], 2014, COLING 2014, 25th International Conference on Computational Linguistics, Proceedings of the Conference: Technical Papers, August 23-29, 2014, Dublin, Ireland
   [Anonymous], 2010, ELECTRON J DIFF 0707
   [Anonymous], 2010, LREC 10
   Benton A, 2016, AAAI CONF ARTIF INTE, P2892
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bo Pang, 2008, Foundations and Trends in Information Retrieval, V2, P1, DOI 10.1561/1500000001
   He RN, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P507, DOI 10.1145/2872427.2883037
   Kilgarriff A, 2000, JSTOR
   Koren Y, 2011, RECOMMENDER SYSTEMS HANDBOOK, P145, DOI 10.1007/978-0-387-85820-3_5
   Li F., 2011, 22 INT JOINT C ART I
   Lu J, 2015, DECIS SUPPORT SYST, V74, P12, DOI 10.1016/j.dss.2015.03.008
   McAuley J, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P43, DOI 10.1145/2766462.2767755
   McAuley Julian, 2013, RECSYS
   Meng L., 2013, Int. J. Hybrid Inf. Technol, V6, P1
   Mikolov T, 2013, ICLR WORKSHOP POSTER
   MOORE TE, 1982, J MARKETING, V46, P38, DOI 10.2307/3203339
   Qiu GA, 2011, COMPUT LINGUIST, V37, P9, DOI 10.1162/coli_a_00034
   Ramage Daniel., 2009, EMNLP, DOI DOI 10.3115/1699510.1699543
   Rosen-Zvi Michal., 2004, UAI
   Seo J, 2013, J WIREL MOBILE NETW, V4, P108
   Seo J, 2016, INT J COMPUT MATH, V93, P308, DOI 10.1080/00207160.2014.944693
   Sivic J, 2005, IEEE I CONF COMP VIS, P370
   Tang DY, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1340
   Tang DY, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1555
   Tsang ASL, 2009, EUR J MARKETING, V43, P1269, DOI 10.1108/03090560910989876
   Wang H, 2010, Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P783, DOI [DOI 10.1145/1835804.1835903, 10.1145/1835804.1835903]
NR 27
TC 2
Z9 2
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28649
EP 28663
DI 10.1007/s11042-018-6211-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700017
DA 2024-07-18
ER

PT J
AU Cao, YJ
   Lin, C
   Pan, YJ
   Zhao, HJ
AF Cao, Yi-Jun
   Lin, Chuan
   Pan, Yi-Jian
   Zhao, Hao-Jun
TI Application of the center-surround mechanism to contour detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Center-surround mechanism; Surround suppression; Contrast information;
   Contour detection
ID CLASSICAL RECEPTIVE-FIELD; DETECTION MODEL; EDGE-DETECTION; BOUNDARY
   DETECTION; SEGMENTATION; LUMINANCE; CONTRAST; COLOR
AB Physiological studies have revealed that the center-surround mechanism widely exists in the primary stages of the human visual system, such as the retina, lateral geniculate nucleus (LGN), and primary visual cortex (V1). In retina ganglion cells (RGC) and the LGN, the mechanism is well known to have two types: center "on" and center "off." However, this mechanism in V1 is shown as classical receptive field (CRF) stimulation and surrounding non-CRF suppression. Although these two manifestations differ in function and appear in different areas of the visual pathway, from the perspective of computational simulation, they simply compute the differences between the center and its surrounding information. In the past decade, many bio-inspired computational models have demonstrated that the center-surround mechanism is good at extracting salient contours while suppressing textures. Based on this mechanism, we propose a method for extracting local center-surround contrast information from nature images by using a normalized difference of Gaussian (DoG) function and a sigmoid activated function. Compared with previous contour detection models (especially bio-motivated ones), the proposed method can efficiently suppress textures more quickly and accurately. More importantly, the proposed algorithm yields even better contour detection, yet the computational complexity is similar to the classical Canny operator.
C1 [Cao, Yi-Jun; Lin, Chuan; Pan, Yi-Jian; Zhao, Hao-Jun] Guangxi Univ Sci & Technol, Coll Elect & Informat Engn, Donghuan Rd 268, Liuzhou, Guangxi, Peoples R China.
C3 Guangxi University of Science & Technology
RP Lin, C (corresponding author), Guangxi Univ Sci & Technol, Coll Elect & Informat Engn, Donghuan Rd 268, Liuzhou, Guangxi, Peoples R China.
EM chuanlin@gxust.edu.cn
RI luo, chuan/IVH-5370-2023; lin, chuan/HIK-1290-2022; lin,
   chuan/JBJ-7047-2023; lin, chuan/HHD-2571-2022
OI lin, chuan/0000-0003-1779-1753; Cao, Yi-Jun/0000-0002-1934-2698
FU National Natural Science Foundation of China [61866002]; Guangxi Natural
   Science Foundation [2018GXNSFAA138122, 2015GXNSFAA139293]; Innovation
   Project of Guangxi Graduate Education [YCSW2018203]; Innovation Project
   of GuangXi University of Science and Technology Graduate Education
   [GKYC201706, GKYC201803]
FX The authors appreciate the helpful and constructive comments received
   from the anonymous reviewers of an earlier draft of this paper. This
   work was supported by the National Natural Science Foundation of China
   (Grant No. 61866002), Guangxi Natural Science Foundation (Grant No.
   2018GXNSFAA138122 and Grant No. 2015GXNSFAA139293), Innovation Project
   of Guangxi Graduate Education (Grant No. YCSW2018203), and Innovation
   Project of GuangXi University of Science and Technology Graduate
   Education (Grant No. GKYC201706 and Grant No. GKYC201803). The funders
   had no role in the study design; in the collection, analysis, or
   interpretation of data; in the writing of the report; or in the decision
   to submit the article for publication.
CR ALLMAN J, 1985, ANNU REV NEUROSCI, V8, P407, DOI 10.1146/annurev.ne.08.030185.002203
   Arandiga F, 2010, IMAGE VISION COMPUT, V28, P553, DOI 10.1016/j.imavis.2009.09.002
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Azzopardi G, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098424
   Azzopardi G, 2012, BIOL CYBERN, V106, P177, DOI 10.1007/s00422-012-0486-6
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Coen-Cagli R, 2012, PLOS COMPUT BIOL, V8, DOI 10.1371/journal.pcbi.1002405
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cour T, 2005, PROC CVPR IEEE, P1124
   Dollar P., 2006, 2006 IEEE COMP SOC C, V2, P1964, DOI DOI 10.1109/CVPR.2006.298
   Fitzpatrick D, 2000, CURR OPIN NEUROBIOL, V10, P438, DOI 10.1016/S0959-4388(00)00113-6
   Grigorescu C, 2003, IEEE T IMAGE PROCESS, V12, P729, DOI 10.1109/TIP.2003.814250
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574, DOI 10.1113/jphysiol.1959.sp006308
   Jones HE, 2001, J NEUROPHYSIOL, V86, P2011, DOI 10.1152/jn.2001.86.4.2011
   Kapadia MK, 2000, J NEUROPHYSIOL, V84, P2048, DOI 10.1152/jn.2000.84.4.2048
   Konishi S, 2003, IEEE T PATTERN ANAL, V25, P57, DOI 10.1109/TPAMI.2003.1159946
   Kovesi P.D., 1999, Videre: Journal of Computer Vision Research, V1
   Li CY, 1996, NEWS PHYSIOL SCI, V11, P181
   LI CY, 1994, VISION RES, V34, P2337, DOI 10.1016/0042-6989(94)90280-1
   Lin C, 2018, IET COMPUT VIS, V12, P863, DOI 10.1049/iet-cvi.2017.0661
   Lin C, 2018, IET IMAGE PROCESS, V12, P993, DOI 10.1049/iet-ipr.2017.0679
   Lin C, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.4.043018
   Lindgren JT, 2008, J VISION, V8, DOI 10.1167/8.12.6
   Liu Y, 2017, PROC CVPR IEEE, P5872, DOI 10.1109/CVPR.2017.622
   Mairal J, 2008, LECT NOTES COMPUT SC, V5304, P43, DOI 10.1007/978-3-540-88690-7_4
   Mante V, 2005, NAT NEUROSCI, V8, P1690, DOI 10.1038/nn1556
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   MORRONE MC, 1987, PATTERN RECOGN LETT, V6, P303, DOI 10.1016/0167-8655(87)90013-4
   Papari G, 2011, PATTERN RECOGN, V44, P1999, DOI 10.1016/j.patcog.2010.08.013
   Papari G, 2011, IMAGE VISION COMPUT, V29, P79, DOI 10.1016/j.imavis.2010.08.009
   RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239
   Ren XH, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 4, PROCEEDINGS, P533, DOI 10.1109/CISP.2008.485
   Spratling MW, 2013, IEEE T IMAGE PROCESS, V22, P1629, DOI 10.1109/TIP.2012.2235850
   Tang QL, 2007, PATTERN RECOGN, V40, P3100, DOI 10.1016/j.patcog.2007.02.009
   Tang QL, 2016, PATTERN RECOGN, V60, P51, DOI 10.1016/j.patcog.2016.05.009
   Wei H, 2013, NEUROCOMPUTING, V103, P247, DOI 10.1016/j.neucom.2012.09.027
   Xiao J, 2014, ELECTRON LETT, V50, P359, DOI 10.1049/el.2013.3657
   Yang KF, 2015, FRONT NEURAL CIRCUIT, V9, DOI 10.3389/fncir.2015.00030
   Yang KF, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2425538
   Yang KF, 2014, IEEE T IMAGE PROCESS, V23, P5020, DOI 10.1109/TIP.2014.2361210
   Yang KF, 2013, PROC CVPR IEEE, P2810, DOI 10.1109/CVPR.2013.362
   Zeng C, 2011, NEUROCOMPUTING, V74, P1527, DOI 10.1016/j.neucom.2010.12.022
   Zeng C, 2011, NEUROIMAGE, V55, P49, DOI 10.1016/j.neuroimage.2010.11.067
   Zhang XS, 2016, IEEE T IMAGE PROCESS, V25, P1219, DOI 10.1109/TIP.2016.2516953
NR 45
TC 13
Z9 13
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 25121
EP 25141
DI 10.1007/s11042-019-7722-1
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900066
DA 2024-07-18
ER

PT J
AU Hu, ZZ
   Zhao, B
AF Hu, Zhaozheng
   Zhao, Bin
TI Minimal vision system for linear camera self-calibration and 3D
   reconstruction using translation platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Minimal vision system; Active vision; Linear camera self-calibration;
   Translation motion; 3D reconstruction
ID MODEL
AB Camera calibration and 3D reconstruction are two crucial steps in computer vision. With the progress of robot and autonomous rover systems, zooming cameras are widely applied, where online calibration and 3D reconstruction are becoming more and more important. This paper proposed a minimal vision system that consists of a translation platform and an un-calibrated camera mounted on. With this minimal system, we can linearly calibrate the camera online and reconstruct 3D structures from three un-calibrated images by utilizing translation motions. The two images generated by translating the camera to allow the recovery of scene depths. Depths are then analyzed by error analysis models and are utilized to determine the infinite homography between the third image and any of the two translated images. The intrinsic parameters are then calibrated linearly from the computed infinite homography. Camera motion estimation and 3D reconstruction are then readily determined from the intrinsic calibration results. We also proposed a two-step optimization method to refine both the calibration and 3D reconstruction results by minimizing the overall back-projection errors across the three images within a tiny-scale bundle adjustment framework. The proposed method has been validated with both simulation and real image data. The results demonstrate that the proposed minimal linear system can solve the online camera self-calibration problem and the reconstruction of 3D structure. The paper suggests a framework of minimal linear system by using an un-calibrated camera and a low-cost translation platform to address the problems of linear self-calibration of camera, motion estimation, 3D reconstruction, and optimization, in a practical, easy, and accurate way.
C1 [Hu, Zhaozheng] Wuhan Univ Technol, ITS Res Ctr, Wuhan 430063, Hubei, Peoples R China.
   [Zhao, Bin] Hebei Univ Technol, Sch Informat Engn, Tianjin 300401, Peoples R China.
C3 Wuhan University of Technology; Hebei University of Technology
RP Hu, ZZ (corresponding author), Wuhan Univ Technol, ITS Res Ctr, Wuhan 430063, Hubei, Peoples R China.
EM zzhu@whut.edu.cn
RI Hu, Zhaozheng/AGC-2475-2022
OI Hu, Zhaozheng/0000-0002-7204-2459
FU National Natural Science Foundation of China (NSFC) [51679181]; National
   Key R&D Program of China [2018YFB1600801]; Major Project of Technical
   Innovation of Hubei Province [2016AAA007]; Science-technology Programs
   Prior Funds for Overseas Chinese Talents of Hubei Province [2016-12]
FX The work presented in this paper was funded by the National Natural
   Science Foundation of China (NSFC) (No. 51679181), National Key R&D
   Program of China (2018YFB1600801), the Major Project of Technical
   Innovation of Hubei Province (No. 2016AAA007), and the
   Science-technology Programs Prior Funds for Overseas Chinese Talents of
   Hubei Province (2016-12).
CR Basso F, 2018, IEEE T ROBOT, V34, P1315, DOI 10.1109/TRO.2018.2853742
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Ge KL, 2016, IEEE T IMAGE PROCESS, V25, P726, DOI 10.1109/TIP.2015.2507984
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Hartley RI, 1994, 3 EUR C COMP VIS
   Houssineau J, 2016, IEEE T SIGNAL PROCES, V64, P2934, DOI 10.1109/TSP.2016.2523454
   Hu ZZ, 2007, PATTERN RECOGN, V40, P2826, DOI 10.1016/j.patcog.2006.12.020
   Hu ZZ, 2015, MULTIMED TOOLS APPL, V74, P9547, DOI 10.1007/s11042-014-2134-8
   Hui BW, 2013, IEEE T INSTRUM MEAS, V62, P2567, DOI 10.1109/TIM.2013.2256815
   Kottari K, 2017, MULTIMED TOOLS APPL, V77, P1
   Liu JY, 2014, IEEE T INSTRUM MEAS, V63, P3076, DOI 10.1109/TIM.2014.2324792
   Liu Y, 2016, 3RD INTERNATIONAL CONFERENCE ON EDUCATION REFORM AND MODERN MANAGEMENT, 2016, P201
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu YZ, 2015, APPL OPTICS, V54, P3470, DOI 10.1364/AO.54.003470
   Lourakis MIA, 2009, ACM T MATH SOFTWARE, V36, DOI 10.1145/1486525.1486527
   Ma S.D., 1996, IEEE T ROBOT AUTOMAT, V12, P114, DOI DOI 10.1109/70.481755
   MAYBANK SJ, 1992, INT J COMPUT VISION, V8, P123, DOI 10.1007/BF00127171
   Panahandeh G, 2015, IEEE T INSTRUM MEAS, V64, P75, DOI 10.1109/TIM.2014.2329388
   Ramalingam S, 2017, IEEE T PATTERN ANAL, V39, P1309, DOI 10.1109/TPAMI.2016.2592904
   Vasconcelos F, 2017, IEEE T PATTERN ANAL, P1
   Wang L, 2004, IEEE T PATTERN ANAL, V26, P275, DOI 10.1109/TPAMI.2004.1262199
   Wang Q., 2011, INSTRUMENTATION MEAS, P1
   Xue JP, 2012, APPL OPTICS, V51, P3811, DOI 10.1364/AO.51.003811
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhao Y, 2012, APPL OPTICS, V51, P3338, DOI 10.1364/AO.51.003338
NR 27
TC 2
Z9 2
U1 1
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25731
EP 25751
DI 10.1007/s11042-019-7666-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700023
DA 2024-07-18
ER

PT J
AU Khan, A
   Sarfaraz, A
AF Khan, Ahmed
   Sarfaraz, Aaliya
TI FFT-ETM based distortion less and high payload image steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information hiding; IS (Image Steganography); Covert Communication; PVD
   (Pixel Value Difference); FEM (Frequency Entropy Matching)
ID WATERMARKING; ROBUST; AUTHENTICATION; INFORMATION; TECHNOLOGY;
   SELECTION; MODEL
AB This paper is presenting a novel high capacity based imperceptible and robust image steganography technique for obscured communication. A considerable literature studied on this domain reveals distortion that drastically affects image quality. These techniques obscure covert data in most significant bits or least significant bits of host image via easy or unsystematic replacement. Such schemes are vulnerable to malevolent attacks like sample pair method, chi-square test, and quality of host image especially badly affected by MSB replacement. Furthermore, such schemes are lacking in carrying maximum covert information as the number of host image pixels and covert image pixels has the ratio 8:1. In our proposed scheme robust and imperceptibility feature is injected using insignificant pixel value divergence of host and a high capacity covert image. We have proposed frequency entropy method that compares frequencies of covert image and host image in FFT (Fast Fourier Transform) domain. The eminent rate of frequency ETM (Entropy Threshold Match) leads to good image quality and information carrying capability. Moreover, our proposed technique also encrypts the secret image in frequency domain with multi flipped permutated random key vector that provides robustness. Therefore, experiments exhibit that this scheme has improved signal to noise ratio and BPP (bits per pixel) in contrast to existing schemes.
C1 [Khan, Ahmed; Sarfaraz, Aaliya] COMSATS Univ, Dept Comp Sci, Islamabad, Pakistan.
C3 COMSATS University Islamabad (CUI)
RP Khan, A (corresponding author), COMSATS Univ, Dept Comp Sci, Islamabad, Pakistan.
EM ahmd_iub4849@yahoo.com; engr_aaliya@yahoo.com
CR Abdul W, 2017, IEEE ACCESS, V5, P5531, DOI 10.1109/ACCESS.2017.2693438
   Al-Haj A, 2015, IET INFORM SECUR, V9, P365, DOI 10.1049/iet-ifs.2014.0245
   Andalibi M, 2015, IEEE T IMAGE PROCESS, V24, P5060, DOI 10.1109/TIP.2015.2476961
   Bhowmik D, 2016, IEEE ACCESS, V4, P8002, DOI 10.1109/ACCESS.2016.2627241
   Bose A., 2017, IEEE SENS LETT, V1, P1
   Cao ZH, 2015, J RETAIL CONSUM SERV, V26, P1, DOI 10.1016/j.jretconser.2015.04.005
   Chakraborty S, 2017, MULTIMED TOOLS APPL, V76, P7973, DOI 10.1007/s11042-016-3449-4
   Chang CS, 2017, IEEE T IMAGE PROCESS, V26, P3921, DOI 10.1109/TIP.2017.2706502
   El-Bendary MAM, 2017, MULTIMED TOOLS APPL, V76, P26463, DOI 10.1007/s11042-016-4177-5
   Gao GY, 2018, IEEE SIGNAL PROC LET, V25, P1099, DOI 10.1109/LSP.2018.2844562
   Guo Yuanfang, 2018, ARXIV180102768
   Huang YS, 2015, CHINESE J ELECTRON, V24, P518, DOI 10.1049/cje.2015.07.014
   Juarez-Sandoval O, 2018, IET BIOMETRICS, V7, P305, DOI 10.1049/iet-bmt.2017.0145
   Khan A, 2014, ADV COMPUTER SCI ITS, V3, P525
   Khan A, 2018, SOFT COMPUT, P1
   Khan A., 2015, SCI INT, V27, P6091
   Khan A., 2017, SCI INT, V29, P361
   Khan A., 2015, J SCI, V4, P426
   Khan A., 2016, SCI INT, V28, P4451
   Khan A, 2018, INT J SECUR APPL, V12, P19, DOI 10.14257/ijsia.2018.12.3.03
   Lin ZX, 2018, IEEE T INF FOREN SEC, V13, P2372, DOI 10.1109/TIFS.2018.2819122
   Liu S, 2017, IET IMAGE PROCESS, V11, P815, DOI 10.1049/iet-ipr.2016.0862
   Liu XL, 2018, IEEE T CIRC SYST VID, V28, P1047, DOI 10.1109/TCSVT.2016.2633878
   Loan NA, 2018, IEEE ACCESS, V6, P19876, DOI 10.1109/ACCESS.2018.2808172
   Ma ZF, 2017, CHINA COMMUN, V14, P156, DOI 10.1109/CC.2017.7961371
   Martínez S, 2018, IEEE ACCESS, V6, P29715, DOI 10.1109/ACCESS.2018.2841020
   Mehra I, 2018, IET IMAGE PROCESS, V12, P432, DOI 10.1049/iet-ipr.2017.0666
   Miri A, 2018, MULTIMED TOOLS APPL, V77, P13133, DOI 10.1007/s11042-017-4935-z
   Nazir LA, 2015, IEEE ACCESS, V16, P19876
   Nie XS, 2018, IEEE T INF FOREN SEC, V13, P1509, DOI 10.1109/TIFS.2018.2790953
   Noor R, 2018, WIRELESS PERS COMMUN, P1
   Noor R., 2019, SOFT COMPUT, P1
   Preda RO, 2015, ELECTRON LETT, V51, P1873, DOI 10.1049/el.2015.2522
   Qin Z, 2018, IEEE CLOUD COMPUT, V5, P48
   Roldan LR, 2016, IEEE LAT AM T, V14, P1050, DOI 10.1109/TLA.2016.7437257
   Saidi M, 2017, MULTIMED TOOLS APPL, V76, P13493, DOI 10.1007/s11042-016-3722-6
   Sarfaraz A, 2018, WIRELESS PERS COMMUN, V103, P2995, DOI 10.1007/s11277-018-5989-6
   Sarreshtedari S, 2015, IEEE-ACM T AUDIO SPE, V23, P1917, DOI 10.1109/TASLP.2015.2456431
   Shahdoosti HR, 2018, IET IMAGE PROCESS, V12, P751, DOI 10.1049/iet-ipr.2017.0898
   Siddiqa A, 2015, ELECTRON LETT, V51, DOI 10.1049/el.2015.0247
   Unno H, 2017, IEEE T IND APPL, V53, P5966, DOI 10.1109/TIA.2017.2726499
   Unno H, 2017, IEEE T IND APPL, V53, P596, DOI 10.1109/TIA.2016.2604217
   Wang YH, 2017, IET IMAGE PROCESS, V11, P822, DOI 10.1049/iet-ipr.2016.0927
   Wang YG, 2018, IEEE T IMAGE PROCESS, V27, P2063, DOI 10.1109/TIP.2018.2795745
   Wei Q., 2017, MULTIMED TOOLS APPL, V25, P1
   Wei YN, 2017, MAT SCI SEMICON PROC, P1, DOI DOI 10.1016/J.MSSP.2017.11.007
   Wu HZ, 2017, IEEE T CIRC SYST VID, V27, P1620, DOI 10.1109/TCSVT.2016.2556585
   Zong TR, 2015, IEEE T CIRC SYST VID, V25, P717, DOI 10.1109/TCSVT.2014.2363743
   Zope-Chaudhari S, 2015, IEEE J-STARS, V8, P5388, DOI 10.1109/JSTARS.2015.2475169
NR 49
TC 7
Z9 8
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25999
EP 26022
DI 10.1007/s11042-019-7664-7
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700034
DA 2024-07-18
ER

PT J
AU Rehman, AU
   Malik, AK
   Raza, B
   Ali, W
AF Rehman, Anwar Ur
   Malik, Ahmad Kamran
   Raza, Basit
   Ali, Waqar
TI A Hybrid CNN-LSTM Model for Improving Accuracy of Movie Reviews
   Sentiment Analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Natural Language Processing (NLP); Sentiment Analysis; CNN; LSTM
AB Nowadays, social media has become a tremendous source of acquiring user's opinions. With the advancement of technology and sophistication of the internet, a huge amount of data is generated from various sources like social blogs, websites, etc. In recent times, the blogs and websites are the real-time means of gathering product reviews. However, excessive number of blogs on the cloud has enabled the generation of huge volume of information in different forms like attitudes, opinions, and reviews. Therefore, a dire need emerges to find a method to extract meaningful information from big data, classify it into different categories and predict end user's behaviors or sentiments. Long Short-Term Memory (LSTM) model and Convolutional Neural Network (CNN) model have been applied to different Natural Language Processing (NLP) tasks with remarkable and effective results. The CNN model efficiently extracts higher level features using convolutional layers and max-pooling layers. The LSTM model is capable to capture long-term dependencies between word sequences. In this study, we propose a hybrid model using LSTM and very deep CNN model named as Hybrid CNN-LSTM Model to overcome the sentiment analysis problem. First, we use Word to Vector (Word2Vc) approach to train initial word embeddings. The Word2Vc translates the text strings into a vector of numeric values, computes distance between words, and makes groups of similar words based on their meanings. Afterword embedding is performed in which the proposed model combines set of features that are extracted by convolution and global max-pooling layers with long term dependencies. The proposed model also uses dropout technology, normalization and a rectified linear unit for accuracy improvement. Our results show that the proposed Hybrid CNN-LSTM Model outperforms traditional deep learning and machine learning techniques in terms of precision, recall, f-measure, and accuracy. Our approach achieved competitive results using state-of-the-art techniques on the IMDB movie review dataset and Amazon movie reviews dataset.
C1 [Rehman, Anwar Ur; Malik, Ahmad Kamran; Raza, Basit; Ali, Waqar] COMSATS Univ Islamabad CUI, Dept Comp Sci, Islamabad, Pakistan.
C3 COMSATS University Islamabad (CUI)
RP Malik, AK (corresponding author), COMSATS Univ Islamabad CUI, Dept Comp Sci, Islamabad, Pakistan.
EM it.anwaar@gmail.com; ahmad.kamran@comsats.edu.pk;
   basit.raza@comsats.edu.pk; waqarali199@ymail.com
RI Raza, Basit/V-5424-2019
OI Raza, Basit/0000-0001-6711-2363; Rehman, Anwar Ur/0000-0002-9384-8988;
   Ali, Waqar/0000-0003-2089-0429; Malik, Ahmad Kamran/0000-0001-5569-5629
FU COMSATS University Islamabad (CUI), Islamabad, Pakistan [CUI/ORICPD/19]
FX This work is funded by the COMSATS University Islamabad (CUI),
   Islamabad, Pakistan, CUI/ORICPD/19.
CR Ain QT, 2017, INT J ADV COMPUT SC, V8, P424
   Al-Smadi M, 2019, INT J MACH LEARN CYB, V10, P2163, DOI 10.1007/s13042-018-0799-4
   Amolik A., 2016, INT J ENG TECHNOLOGY, V7, P1
   [Anonymous], 2008, PROC INT C MACHINE L
   Cheng ZY, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3291060
   Cheng ZY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3748
   Cheng ZY, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P639, DOI 10.1145/3178876.3186145
   Conneau A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P1107
   Elghazaly T, 2016, P ACM INT C INT THIN, P11
   Fang X, 2015, Journal of Big Data, V2, P5, DOI 10.1186/s40537-015-0015-2
   Govindarajan M., 2013, International Journal of Advanced Computer Research, V3, P139
   HAO H, 2014, PROCEEDINGS OF THE 2
   Hassan A, 2018, IEEE ACCESS, V6, P13949, DOI 10.1109/ACCESS.2018.2814818
   Himelboim I, 2017, SOC MEDIA SOC, V3, DOI 10.1177/2056305117691545
   Islam J, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCES ON BIG DATA AND CLOUD COMPUTING (BDCLOUD 2016) SOCIAL COMPUTING AND NETWORKING (SOCIALCOM 2016) SUSTAINABLE COMPUTING AND COMMUNICATIONS (SUSTAINCOM 2016) (BDCLOUD-SOCIALCOM-SUSTAINCOM 2016), P124, DOI 10.1109/BDCloud-SocialCom-SustainCom.2016.29
   Kaur Amandeep, 2013, Journal of Emerging Technologies in Web Intelligence, V5, P367, DOI 10.4304/jetwi.5.4.367-371
   Li G, 2010, AIP CONF PROC, V1233, P893, DOI 10.1063/1.3452297
   Liao SY, 2017, PROCEDIA COMPUT SCI, V111, P376, DOI 10.1016/j.procs.2017.06.037
   Liu YM, 2015, INT SYM COMPUT INTEL, P358, DOI 10.1109/ISCID.2015.217
   Manek AS, 2017, WORLD WIDE WEB, V20, P135, DOI 10.1007/s11280-015-0381-x
   McCallum A., 1998, AAAI 98 WORKSH LEARN, V752, P41, DOI DOI 10.1109/TSMC.1985.6313426
   Ouyang X, 2015, CIT/IUCC/DASC/PICOM 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY - UBIQUITOUS COMPUTING AND COMMUNICATIONS - DEPENDABLE, AUTONOMIC AND SECURE COMPUTING - PERVASIVE INTELLIGENCE AND COMPUTING, P2363, DOI 10.1109/CIT/IUCC/DASC/PICOM.2015.349
   Pang B, 2005, P 43 ANN M ASS COMP, P115, DOI [10.3115/1219840.1219855, DOI 10.3115/1219840.1219855]
   Ruangkanokmas P, 2016, P INT CONF INTELL, P9, DOI 10.1109/ISMS.2016.9
   Sanguansat P, 2016, INT CONF KNOWL SMART, P175, DOI 10.1109/KST.2016.7440526
   Severyn A, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P959, DOI 10.1145/2766462.2767830
   Singh J, 2017, HUM-CENT COMPUT INFO, V7, DOI 10.1186/s13673-017-0116-3
   Srivastava A, 2014, 2014 11TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS (ITNG), P502, DOI 10.1109/ITNG.2014.99
   Syed AZ, 2010, LECT NOTES ARTIF INT, V6437, P32, DOI 10.1007/978-3-642-16761-4_4
   Tripathy A, 2015, PROCEDIA COMPUT SCI, V57, P821, DOI 10.1016/j.procs.2015.07.523
   Wang S., PROC
NR 31
TC 121
Z9 130
U1 4
U2 103
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26597
EP 26613
DI 10.1007/s11042-019-07788-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700058
DA 2024-07-18
ER

PT J
AU Zhang, HF
   Long, Y
   Shao, L
AF Zhang, Haofeng
   Long, Yang
   Shao, Ling
TI Zero-shot leaning and hashing with binary visual similes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Zero-shot learning; Zero-shot hashing; Visual similes; Binary annotation
AB Conventional zero-shot learning methods usually learn mapping functions to project image features into semantic embedding spaces, in which to find the nearest neighbors with predefined attributes. The predefined attributes including both seen classes and unseen classes are often annotated with high dimensional real values by experts, which costs a lot of human labors. In this paper, we propose a simple but effective method to reduce the annotation work. In our strategy, only unseen classes are needed to be annotated with several binary codes, which lead to only about one percent of original annotation work. In addition, we design a Visual Similes Annotation System (ViSAS) to annotate the unseen classes, and build both linear and deep mapping models and test them on four popular datasets, the experimental results show that our method can outperform the state-of-the-art methods in most circumstances.
C1 [Zhang, Haofeng] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing, Jiangsu, Peoples R China.
   [Long, Yang] Newcastle Univ, Sch Comp, Open Lab, Newcastle Upon Tyne, Tyne & Wear, England.
   [Shao, Ling] Incept Inst Artificial Intelligence IIAI, Abu Dhabi, U Arab Emirates.
C3 Nanjing University of Science & Technology; Newcastle University - UK
RP Zhang, HF (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing, Jiangsu, Peoples R China.
EM zhanghf@njust.edu.cn; yang.long@ieee.org; ling.shao@ieee.org
RI Shao, Ling/D-3535-2011
OI Shao, Ling/0000-0002-8264-6117
FU National Natural Science Foundation of China [61872187]; Major Special
   Project of Core Electronic Devices, High-end Generic Chips and Basic
   Software [2015ZX01041101]; MRC [MR/S003916/1] Funding Source: UKRI
FX This work was supported by National Natural Science Foundation of China
   (No. 61872187) and the Major Special Project of Core Electronic Devices,
   High-end Generic Chips and Basic Software (No. 2015ZX01041101).
CR Akata Z, 2016, PROC CVPR IEEE, P59, DOI 10.1109/CVPR.2016.14
   Akata Z, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2487986
   Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911
   Al-Halah Ziad., 2017, CVPR
   [Anonymous], 2016, P 25 INT JOINT C ART
   [Anonymous], 2016, TOMCCAP, DOI DOI 10.1016/J.YMPEV.2016.12.037
   [Anonymous], ACM MM
   [Anonymous], 2010, CALTECH USCD BIRDS
   [Anonymous], 2008, P ADV NEUR INF PROC
   [Anonymous], WWW
   [Anonymous], 2017, CVPR
   [Anonymous], 2017, CVPR
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2018, IEEE Transactions on Cybernetics
   [Anonymous], 2017, CVPR
   [Anonymous], 2017, CVPR
   [Anonymous], 2017, ACM MM
   [Anonymous], 2013, ICLR WORKSH POST
   [Anonymous], IJCAI
   [Anonymous], 2015, PROC CVPR IEEE
   BARTELS RH, 1972, COMMUN ACM, V15, P820, DOI 10.1145/361573.361582
   Bucher M, 2016, LECT NOTES COMPUT SC, V9909, P730, DOI 10.1007/978-3-319-46454-1_44
   Buchmann J, 2017, QUANTUM SCI TECHNOL, V2, DOI 10.1088/2058-9565/aa69cd
   Changpinyo S, 2016, PROC CVPR IEEE, P5327, DOI 10.1109/CVPR.2016.575
   Cheng ZY, 2016, SIGNAL PROCESS, V124, P13, DOI 10.1016/j.sigpro.2015.10.037
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Fu YW, 2016, PROC CVPR IEEE, P5337, DOI 10.1109/CVPR.2016.576
   Fu YW, 2014, LECT NOTES COMPUT SC, V8690, P584, DOI 10.1007/978-3-319-10605-2_38
   Guo YC, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1767
   Guo YC, 2016, AAAI CONF ARTIF INTE, P3494
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jiang B, 2017, PROC CVPR IEEE, P550, DOI 10.1109/CVPR.2017.66
   Kodirov E, 2015, IEEE I CONF COMP VIS, P2452, DOI 10.1109/ICCV.2015.282
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Li JJ, 2017, IEEE T CYBERNETICS, V47, P3516, DOI 10.1109/TCYB.2016.2565898
   Liu Y, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2490
   Long Y., 2017, CVPR
   Long Y, 2017, IEEE WINT CONF APPL, P907, DOI 10.1109/WACV.2017.106
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Nie LQ, 2014, ACM T INFORM SYST, V32, DOI 10.1145/2559157
   Norouzi M., 2014, ICLR
   Patterson G, 2014, INT J COMPUT VISION, V108, P59, DOI 10.1007/s11263-013-0695-z
   Qiao RZ, 2016, PROC CVPR IEEE, P2249, DOI 10.1109/CVPR.2016.247
   Romera-Paredes B, 2015, PR MACH LEARN RES, V37, P2152
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Socher R., 2013, ADV NEURAL INFORM PR, V26, P935, DOI DOI 10.1007/978-3-319-46478-7
   Xian YQ, 2016, PROC CVPR IEEE, P69, DOI 10.1109/CVPR.2016.15
   Yang Y, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1286, DOI 10.1145/2964284.2964319
   Zhang HF, 2019, INFORM SCIENCES, V470, P43, DOI 10.1016/j.ins.2018.08.048
   Zhang HF, 2018, IEEE T IMAGE PROCESS, V27, P1626, DOI 10.1109/TIP.2017.2781422
   Zhang ZM, 2015, IEEE I CONF COMP VIS, P4166, DOI 10.1109/ICCV.2015.474
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
NR 55
TC 10
Z9 10
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24147
EP 24165
DI 10.1007/s11042-018-6842-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900020
DA 2024-07-18
ER

PT J
AU Chen, Y
   Wang, HX
   Wu, HZ
   Liu, Y
AF Chen, Yi
   Wang, Hongxia
   Wu, Hanzhou
   Liu, Yong
TI Reversible video data hiding using zero QDCT coefficient-pairs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Embedding capacity; Reversible data hiding; Zero QDCT coefficient-pairs;
   Mapping rules; H; 264; AVC video stream
ID FRAME ERROR CONCEALMENT; STEGANOGRAPHY; ALGORITHM
AB H.264/Advanced Video Coding (AVC) is one of the most commonly used video compression standard currently. In this paper, we propose a Reversible Data Hiding (RDH) method based on H.264/AVC videos. In the proposed method, the macroblocks with intra-frame 4 x 4 prediction modes in intra frames are first selected as embeddable blocks. Then, the last zero Quantized Discrete Cosine Transform (QDCT) coefficients in all 4 x 4 blocks of the embeddable macroblocks are paired. In the following, a modification mapping rule based on making full use of modification directions are given. Finally, each zero coefficient-pair is changed by combining the given mapping rule with the to-be-embedded information bits. Since most of last QDCT coefficients in all 4 x 4 blocks are zero and they are located in high frequency area. Therefore, the proposed method can obtain high embedding capacity and low distortion.
C1 [Chen, Yi; Liu, Yong] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 611756, Sichuan, Peoples R China.
   [Wang, Hongxia] Sichuan Univ, Coll Cybersecur, Chengdu 610064, Sichuan, Peoples R China.
   [Wu, Hanzhou] Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.
C3 Southwest Jiaotong University; Sichuan University; Chinese Academy of
   Sciences; Institute of Automation, CAS
RP Chen, Y (corresponding author), Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 611756, Sichuan, Peoples R China.; Wang, HX (corresponding author), Sichuan Univ, Coll Cybersecur, Chengdu 610064, Sichuan, Peoples R China.
EM yichen.research@gmail.com; hxwang@scu.edu.cn; wuhanzhou_2007@126.com;
   liuyongresearch@163.com
RI Wu, Hanzhou/AAL-3361-2021
OI Wu, Hanzhou/0000-0002-1599-7232; Chen, Yi/0000-0003-4272-7956
CR Al-Ghamdi M, 2019, MULTIMED TOOLS APPL, V78, P16283, DOI 10.1007/s11042-018-6977-2
   Al-Otaibi Nouf A., 2014, Lecture Notes on Information Theory, V2, P151, DOI 10.12720/lnit.2.2.151-157
   Al-Qurashi GA, 2018, J COMPUTER SCI COMPU, V8, P87
   Alanizy N., 2018, J RES ENG APPL SCI J, V3, P118, DOI DOI 10.46565/JREAS.2018.V03I04.001
   Alassaf N, 2019, MULTIMED TOOLS APPL, V78, P32633, DOI 10.1007/s11042-018-6801-z
   [Anonymous], 2010, INT J SIGNAL IMAGE P
   [Anonymous], 2018, J Inf Secur Cybercrimes Res (JISCR), DOI DOI 10.26735/16587790.2018.006
   [Anonymous], 2018, H 264 AVC REFERENCE
   [Anonymous], 2018, J COMPUT SCI COMPUT, DOI DOI 10.20967/JCSCM.2018.03.002
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Chen Y, 2018, LECT NOTES COMPUT SC, V11066, P99, DOI 10.1007/978-3-030-00015-8_9
   Chen Y, 2018, MULTIMED TOOLS APPL, V77, P20157, DOI 10.1007/s11042-017-5411-5
   Chung KL, 2010, IEEE T CIRC SYST VID, V20, P1643, DOI 10.1109/TCSVT.2010.2077577
   Dragoi IC, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549458
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Fallahpour M, 2015, SECUR COMMUN NETW, V8, P2947, DOI 10.1002/sec.1221
   Fallahpour M, 2014, IEEE T INSTRUM MEAS, V63, P1057, DOI 10.1109/TIM.2014.2299371
   Gutub A, 2018, J. Comput. Hardw. Eng, V1, P1
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Gutub A, 2019, MULTIMED TOOLS APPL, V78, P5591, DOI 10.1007/s11042-017-5293-6
   Hu YJ, 2008, IEEE T MULTIMEDIA, V10, P1500, DOI 10.1109/TMM.2008.2007341
   Jung KH, 2017, MULTIMED TOOLS APPL, V76, P13127, DOI 10.1007/s11042-016-3739-x
   Kim H, 2018, MULTIMED TOOLS APPL, V77, P8043, DOI 10.1007/s11042-017-4698-6
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Liu P, 2017, MULTIMEDIA SYST, V23, P485, DOI 10.1007/s00530-015-0500-7
   Liu YX, 2016, NEUROCOMPUTING, V188, P63, DOI 10.1016/j.neucom.2014.10.109
   Ma XJ, 2017, IEEE T CLOUD COMPUT, V5, P510, DOI 10.1109/TCC.2015.2469651
   Ma XJ, 2010, IEEE T CIRC SYST VID, V20, P1320, DOI 10.1109/TCSVT.2010.2070950
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Rabbani M, 2002, SIGNAL PROCESS-IMAGE, V17, P3, DOI 10.1016/S0923-5965(01)00024-8
   Samira B, 2012, INT CONF SIGN PROCES, P1682, DOI 10.1109/ICoSP.2012.6491904
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xu DW, 2016, SIGNAL PROCESS-IMAGE, V47, P369, DOI 10.1016/j.image.2016.08.003
   Xu DW, 2014, J VIS COMMUN IMAGE R, V25, P410, DOI 10.1016/j.jvcir.2013.12.008
   Zhang WM, 2016, IEEE T MULTIMEDIA, V18, P1469, DOI 10.1109/TMM.2016.2569497
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
   Zhou JT, 2016, IEEE T CIRC SYST VID, V26, P441, DOI 10.1109/TCSVT.2015.2416591
NR 41
TC 9
Z9 9
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23097
EP 23115
DI 10.1007/s11042-019-7635-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400041
DA 2024-07-18
ER

PT J
AU Cheng, DS
   Shi, DM
   Tian, F
   Liu, XF
AF Cheng, Dansong
   Shi, Daming
   Tian, Feng
   Liu, Xiaofang
TI A level set method for image segmentation based on Bregman divergence
   and multi-scale local binary fitting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Level set; Image segmentation; Bregman divergence; Multi-scale local
   binary fitting
ID ACTIVE CONTOURS DRIVEN; REGION; MUMFORD; ENERGY
AB Image segmentation is an important processing in many applications such as image retrieval and computer vision. The level set method based on local information is one of the most successful models for image segmentation. However, in practice, these models are at risk for existence of local minima in the active contour energy and the considerable computing-consuming. In this paper, a novel region-based level set method based on Bregman divergence and multi-scale local binary fitting(MLBF), called Bregman-MLBF, is proposed. Bregman-MLBF utilizes both global and local information to formulate a new energy function. The global information by Bregman divergence which can be approximated by the data-dependent weighted L-2 - norm, not only accelerates the contour evolution, especially, when the contour is far away from object boundaries but also boosts the robustness to the initial placement. The local information is used to improve the capability of coping with intensity inhomogeneity and to attract the contour to stop at the object boundaries. The experiments conducted on synthetic images, real images and benchmark image datasets have demonstrated that Bregman-MLBF outperforms the piece-wise constant (PC) model in handling intensity inhomogeneity and is more effective than the local binary fitting model and more robust than the local and global intensity fitting model.
C1 [Cheng, Dansong; Shi, Daming] Harbin Inst Technol, Sch Comp Sci & Technol, 92 West Dazhi St, Harbin 150001, Heilongjiang, Peoples R China.
   [Tian, Feng] Bournemouth Univ, Fac Sci & Technol, Poole, Dorset, England.
   [Liu, Xiaofang] Harbin Inst Technol, Sch Elect Engn & Automat, Harbin, Heilongjiang, Peoples R China.
C3 Harbin Institute of Technology; Bournemouth University; Harbin Institute
   of Technology
RP Liu, XF (corresponding author), Harbin Inst Technol, Sch Elect Engn & Automat, Harbin, Heilongjiang, Peoples R China.
EM liuxf@hit.edu.cn
RI Cheng, Dan/ITT-7298-2023
FU National Natural Science Foundation of China [61402133,61672190]
FX This research was supported by the National Natural Science Foundation
   of China (Grant No.61402133,61672190).
CR Akram F, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174813
   Beauchemin M., 1998, CAN J REMOTE SENS, V24, P3, DOI [10.1080/07038992.1998.10874685, DOI 10.1080/07038992.1998.10874685]
   Bregman L. M., 1967, USSR COMP MATH MATH, V7, P200, DOI [10.1016/0041-5553(67)90040-7, DOI 10.1016/0041-5553(67)90040-7]
   Chai TY, 2016, TECHNOLOGIES APPL AR, P506
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Cheng D, 2007, CHINESE HIGH TECHNOL, V12, P24
   Cheng Dan-song, 2007, Journal of the Harbin Institute of Technology, V39, P435
   Ding K, 2018, INT C GRAPH IM PROC, P100
   Jia WJ, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0884-3
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Lampert CH, 2016, SEED EXPAND CONSTRAI
   Lankton S, 2008, IEEE T IMAGE PROCESS, V17, P2029, DOI 10.1109/TIP.2008.2004611
   Leung T., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P544, DOI 10.1007/BFb0055689
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Liu L, 2017, MULTIMED TOOLS APPL, V76, P12233, DOI 10.1007/s11042-016-3624-7
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Niu YF, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (ICCIA), P308, DOI 10.1109/CIAPP.2017.8167228
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Papandreou G, 2015, IEEE I CONF COMP VIS, P1742, DOI 10.1109/ICCV.2015.203
   Paul G, 2013, INT J COMPUT VISION, V104, P69, DOI 10.1007/s11263-013-0615-2
   PRATT WK, 1978, IEEE T SYST MAN CYB, V8, P796, DOI 10.1109/TSMC.1978.4309867
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033
   Varshney S.S., 2009, International Conference on Methods and Models in Computer Science, P1
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Wang L, 2009, COMPUT MED IMAG GRAP, V33, P520, DOI 10.1016/j.compmedimag.2009.04.010
   Wang L, 2009, SIGNAL PROCESS, V89, P2435, DOI 10.1016/j.sigpro.2009.03.014
   Zhou Y, 2015, NEUROCOMPUTING, V156, P199, DOI 10.1016/j.neucom.2014.12.061
NR 30
TC 4
Z9 5
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 20585
EP 20608
DI 10.1007/s11042-018-6949-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400002
DA 2024-07-18
ER

PT J
AU Huang, CW
   Jiang, H
AF Huang, Chengwei
   Jiang, Hao
TI Image indexing and content analysis in children's picture books using a
   large-scale database
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual database; Picture book; Image indexing; Object recognition;
   Robotics
ID RETRIEVAL
AB In this paper we introduce a visual database for children's picture book and we also present an intelligent robot trained on this database. Firstly, a large-scale image dataset is built that contains image samples of book pages. It can be used to verify image indexing algorithms and content recognition algorithms. Secondly, we study the state-of-the-art algorithms in image matching and object recognition. Several approaches are presented and compared from the aspects of computational efficiency and recognition accuracy. In order to improve the speed we proposed a novel hierarchical algorithm for fast search. Finally, using this large-scale database we are able to build a robot that can read children's picture books and initial experimental results are presented. We can see that both the training database and the algorithms are promising, yet there are still a few open challenges concerning the costs and robustness.
C1 [Huang, Chengwei; Jiang, Hao] Fandou Informat Technol Co Ltd, Shenzhen, Peoples R China.
RP Huang, CW (corresponding author), Fandou Informat Technol Co Ltd, Shenzhen, Peoples R China.
EM huangcw@fandoutech.com.cn; jiangh@fandoutech.com.cn
RI Huang, Chengwei/AER-6849-2022; Jiang, Hao/O-9601-2014
OI Huang, Chengwei/0000-0001-9060-6361
CR [Anonymous], IEEE INT WORKSH INF
   [Anonymous], 2014, CoRR
   [Anonymous], 2013, CORR
   [Anonymous], DET PEOPL CUB ART WO
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Cai Hongping, 2015, ARXIV150500110
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong JM, 2015, PROC CVPR IEEE, P5097, DOI 10.1109/CVPR.2015.7299145
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jian MW, 2018, MULTIMED TOOLS APPL, V77, P29099, DOI 10.1007/s11042-018-6122-2
   Jian MW, 2018, MULTIMED TOOLS APPL, V77, P14343, DOI 10.1007/s11042-017-5032-z
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Jian MW, 2014, SIGNAL PROCESS, V100, P9, DOI 10.1016/j.sigpro.2014.01.004
   Jian MW, 2014, INFORM SCIENCES, V262, P1, DOI 10.1016/j.ins.2013.12.001
   Krizhevsky Alex., 2012, u International Conference on Neural Information Processing Systems - Volume, V1
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Simonyan K, 2015, IEEE INT C ICLR
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Wang XY, 2014, MULTIMED TOOLS APPL, V68, P545, DOI 10.1007/s11042-012-1055-7
   Yang J, 2007, LECT NOTES COMPUT SC, V4663, P197
   Zhang T, 2015, MULTIMED TOOLS APPL, V74, P9365, DOI 10.1007/s11042-014-2110-3
NR 23
TC 6
Z9 6
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 20679
EP 20695
DI 10.1007/s11042-019-7440-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400006
DA 2024-07-18
ER

PT J
AU Zhu, HJ
   Yang, TF
   Yang, P
   He, LB
   Wang, GH
AF Zhu, Haijiang
   Yang, Tengfei
   Yang, Ping
   He, Longbiao
   Wang, Guanghui
TI 3D reconstruction for ultrasonic C-scan images of tissue-mimicking
   phantom based on an improved K-nearest neighbor filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D reconstruction; Edge points predicting; Ultrasonic C-scan image;
   Tissue-mimicking phantom
ID DAMAGE IDENTIFICATION; BRAIN MRI; SEGMENTATION
AB Although the ultrasonic C-scan technique has been extensively applied in nondestructive testing (NDT) in recent years, 3D reconstruction from ultrasonic C-scan images has not been well addressed. This paper develops a novel and efficient 3D reconstruction technique based on an improved K-nearest neighbor filtering for ultrasonic C-scan data of the tissue-mimicking phantoms. An edge-points-predicting approach based on K-nearest neighbor filtering is first proposed to predict the undetected edge points and to reduce the noise points for 2D ultrasonic images. Then, the 3D model is reconstructed from the clean edges by utilizing the surface rendering algorithm. The proposed approach is validated using the ultrasonic C-scan data of a liver model embedded in a tissue-mimicking phantom. The comparisons with other methods are presented in the experiments. The results demonstrate the effectiveness and the significantly improved reconstruction results of the proposed approach.
C1 [Zhu, Haijiang; Yang, Tengfei] Beijing Univ Chem Technol, Coll Informat Sci & Technol, CO, Beijing 100029, Peoples R China.
   [Yang, Ping; He, Longbiao] Natl Inst Metrol, Acoust Lab, CO, Beijing 100029, Peoples R China.
   [Wang, Guanghui] Univ Kansas, Dept Elect Engn & Comp Sci, Lawrence, KS 66045 USA.
C3 Beijing University of Chemical Technology; National Institute of
   Metrology China; University of Kansas
RP Zhu, HJ (corresponding author), Beijing Univ Chem Technol, Coll Informat Sci & Technol, CO, Beijing 100029, Peoples R China.; Wang, GH (corresponding author), Univ Kansas, Dept Elect Engn & Comp Sci, Lawrence, KS 66045 USA.
EM zhuhj@mail.buct.edu.cn; ghwang@ku.edu
RI Wang, Guang/JFS-8374-2023
OI Zhu, Haijiang/0000-0002-0609-3610
FU National Natural Science Foundation of China [61672084]; Fundamental
   Research Funds for the Central Universities [XK1802-4]
FX This work was supported in part by the National Natural Science
   Foundation of China under grant No. 61672084 and the Fundamental
   Research Funds for the Central Universities under grant No. XK1802-4.
CR Angelopoulou A, 2015, NEUROCOMPUTING, V150, P16, DOI 10.1016/j.neucom.2014.03.078
   Barry CD, 1997, ULTRASOUND MED BIOL, V23, P1209, DOI 10.1016/S0301-5629(97)00123-3
   Baselice F, 2017, ULTRASOUND MED BIOL, V43, P2065, DOI 10.1016/j.ultrasmedbio.2017.05.006
   Cai SL, 2019, MULTIMED TOOLS APPL, V78, P29121, DOI 10.1007/s11042-018-6581-5
   Chen Y, 2014, MED IMAGE ANAL, V18, P1, DOI 10.1016/j.media.2013.08.003
   Chikmurge D, 2018, ADV INTELL SYST, V632, P185, DOI 10.1007/978-981-10-5520-1_18
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Ferrante E, 2017, MED IMAGE ANAL, V39, P101, DOI 10.1016/j.media.2017.04.010
   Ghose S, 2017, PHYS MED BIOL, V62, P2950, DOI 10.1088/1361-6560/aa508a
   Huang QH, 2009, COMPUT MED IMAG GRAP, V33, P100, DOI 10.1016/j.compmedimag.2008.10.006
   Jaffar MA, 2012, INT J COMPUT INT SYS, V5, P494, DOI 10.1080/18756891.2012.696913
   Kainz B, 2015, IEEE T MED IMAGING, V34, P1901, DOI 10.1109/TMI.2015.2415453
   Karaman M, 2009, IEEE T MED IMAGING, V28, P1051, DOI 10.1109/TMI.2008.2010936
   Katunin A, 2015, ARCH CIV MECH ENG, V15, P251, DOI 10.1016/j.acme.2014.01.010
   Katunin A, 2015, COMPOS STRUCT, V127, P1, DOI 10.1016/j.compstruct.2015.02.080
   Kerr W, 2017, COMPUT MED IMAG GRAP, V58, P23, DOI 10.1016/j.compmedimag.2017.03.002
   Khvostikov A, 2015, INT CONF IMAG PROC, P440, DOI 10.1109/IPTA.2015.7367183
   Kim D, 2015, IEEE T MED IMAGING, V34, P167, DOI 10.1109/TMI.2014.2350962
   Kim K, 2010, IEEE T MED IMAGING, V29, P146, DOI 10.1109/TMI.2009.2030679
   Kuklisova-Murgasova M, 2012, MED IMAGE ANAL, V16, P1550, DOI 10.1016/j.media.2012.07.004
   Kumar A, 2007, BARC NEWSLETTER, V31, P14989
   Kuo JW, 2016, IEEE T MED IMAGING, V35, P427, DOI 10.1109/TMI.2015.2477395
   Mederos B., 2005, Proc. Geometry Processing (Eurographics/ ACM SIGGRAPH), P53
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Moon H, 2016, COMPUT VIS IMAGE UND, V151, P101, DOI 10.1016/j.cviu.2015.12.009
   Poudel P, 2017, MED IMAGING 2017 IMA
   Quan EM, 2010, IEEE T MED IMAGING, V29, P916, DOI 10.1109/TMI.2009.2039799
   Rim Y, 2013, BIOMED ENG ONLINE, V12, DOI 10.1186/1475-925X-12-39
   Rodtook A, 2018, PATTERN RECOGN, V79, P172, DOI 10.1016/j.patcog.2018.01.032
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Solberg OV, 2007, ULTRASOUND MED BIOL, V33, P991, DOI 10.1016/j.ultrasmedbio.2007.02.015
   Toonkum P, 2011, ULTRASONICS, V51, P136, DOI 10.1016/j.ultras.2010.07.003
   Verma Jyoti, 2017, Pattern Recognition and Image Analysis, V27, P574, DOI 10.1134/S1054661817030294
   Wang JP, 2009, COMPUT MED IMAG GRAP, V33, P235, DOI 10.1016/j.compmedimag.2009.01.001
   Wen TX, 2015, NEUROCOMPUTING, V168, P104, DOI 10.1016/j.neucom.2015.06.009
   Wronkowicz Angelika, 2015, International Journal of Image, Graphics and Signal Processing, V7, P1, DOI 10.5815/ijigsp.2015.11.01
   Xu Q, 2012, IEEE T MED IMAGING, V31, P1682, DOI 10.1109/TMI.2012.2195669
   Zheng XJ, 2017, BIOMED RES INT, V2017, DOI 10.1155/2017/1962181
NR 38
TC 1
Z9 1
U1 3
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23597
EP 23616
DI 10.1007/s11042-019-7686-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400062
DA 2024-07-18
ER

PT J
AU Al-khafajiy, M
   Kolivand, H
   Baker, T
   Tully, D
   Waraich, A
AF Al-khafajiy, Mohammed
   Kolivand, Hoshang
   Baker, Thar
   Tully, David
   Waraich, Atif
TI Smart hospital emergency system: Via mobile-based requesting services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart hospital; Emergency systems; e-Health; m-Health; WebRTC; Mobile
   health; Emergency; Emergency delay
AB In recent years, the UK's emergency call and response has shown elements of great strain as of today. The strain on emergency call systems estimated by a 9 million calls (including both landline and mobile) made in 2014 alone. Coupled with an increasing population and cuts in government funding, this has resulted in lower percentages of emergency response vehicles at hand and longer response times. In this paper, we highlight the main challenges of emergency services and overview of previous solutions. In addition, we propose a new system call Smart Hospital Emergency System (SHES). The main aim of SHES is to save lives through improving communications between patient and emergency services. Utilising the latest of technologies and algorithms within SHES is aiming to increase emergency communication throughput, while reducing emergency call systems issues and making the process of emergency response more efficient. Utilising health data held within a personal smartphone, and internal tracked data (GPU, Accelerometer, Gyroscope etc.), SHES aims to process the mentioned data efficiently, and securely, through automatic communications with emergency services, ultimately reducing communication bottlenecks. Live video-streaming through real-time video communication protocols is also a focus of SHES to improve initial communications between emergency services and patients. A prototype of this system has been developed. The system has been evaluated by a preliminary usability, reliability, and communication performance study.
C1 [Al-khafajiy, Mohammed; Kolivand, Hoshang; Baker, Thar; Tully, David; Waraich, Atif] Liverpool John Moores Univ, Dept Comp Sci, 3 Byrom St, Liverpool L3 3AF, Merseyside, England.
C3 Liverpool John Moores University; University of Liverpool
RP Al-khafajiy, M (corresponding author), Liverpool John Moores Univ, Dept Comp Sci, 3 Byrom St, Liverpool L3 3AF, Merseyside, England.
EM M.D.Alkhafajiy@2016.ljmu.ac.uk; H.Kolivand@ljmu.ac.uk;
   T.Baker@ljmu.ac.uk; D.A.Tully@ljmu.ac.uk; A.I.Waraich@ljmu.ac.uk
RI Al-khafajiy, Mohammed/K-9348-2018; Baker, Thar/H-6073-2019; Kolivand,
   Hoshang/F-4736-2011; Kolivand, Hoshang/B-2501-2016
OI Al-khafajiy, Mohammed/0000-0001-6561-0414; Baker,
   Thar/0000-0002-5166-4873; Kolivand, Hoshang/0000-0001-5460-5679
CR American red cross, 2014, 1 AID AM RED CROSS
   [Anonymous], 2011, Daily Mail
   [Anonymous], 2016, TELEGRAPH
   [Anonymous], 1938, DAILY MAIL
   [Anonymous], 2010, The Telegraph
   BTPLC, 2014, BT TOD NEW 999 SERV
   Catarinucci L, 2015, IEEE INTERNET THINGS
   De Pessemier T, 2018, MULTIMEDIA TOOLS APP
   EmergencySMS, 2012, SMS EM SERV
   Garnet R, 1985, TELEPHONE ENTERPRISE, P1876
   Holland G, 2010, BBC LONDON
   House of Commons, 2003, HOAX CALLS
   Huh JH, 2018, J SUPERCOMPUTING
   Hussain A, 2015, J SYSTEMS SOFTWARE
   ICE, 2010, CAS EM ICE
   Jiang WC, 2017, MULTIMED TOOLS APPL, V76, P20317, DOI 10.1007/s11042-017-4779-6
   Johnston Kylie, 2012, BMC Res Notes, V5, P652, DOI 10.1186/1756-0500-5-652
   Miori V, 2017, GLOBAL INTERNET THIN, P1, DOI DOI 10.1109/GI0TS.2017.8016215
   Moskowitz, 2014, LLC EMERGENCY MED CT
   Munro J, 2000, BMJ CLIN RES, V321
   NHS, 2012, LOND AMB SERV WHAT H
   Rodriguez-Gil L, 2018, MULTIMED TOOLS APPL, V77, P6471, DOI 10.1007/s11042-017-4556-6
   Sahoo B. P. S., 2012, P INT C GEOSP TECHN
   Snooks H, 2002, BRIT MED J
   Standard The Evening, 2011, STANDARD EVENING
   Tang Y, 2015, J COMPUTERS TAIWAN
   Tongyu Zhu, 2010, Proceedings of the 2010 Sixth International Conference on Networked Computing and Advanced Information Management (NCM 2010), P107
   Vidul AP, 2015, ADV COMPUTING COMMUN
   Wang CS, 2015, PEER TO PEER NETWORK
   Wang E, 2014, MULTIMED TOOLS APPL, V73, P1597, DOI 10.1007/s11042-013-1656-9
   Woolf Nicky., 2016, DDOS ATTACK DISRUPTE
   Workforce and Facilities Team, 2015, AMB SERV ENGL 2014 1
   Yuanfeng D, 2016, J NETW COMPUT APPL, V69
   Zubaydi F, 2015, IEEE 15 INT C BIOINF
NR 34
TC 12
Z9 13
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 20087
EP 20111
DI 10.1007/s11042-019-7274-4
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800053
OA hybrid, Green Accepted
DA 2024-07-18
ER

PT J
AU Gul, E
   Ozturk, S
AF Gul, Ertugrul
   Ozturk, Serkan
TI A novel hash function based fragile watermarking method for image
   integrity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fragile image watermarking; SHA-256; Image integrity
ID AUTHENTICATION SCHEME; TAMPER DETECTION; WAVELET; ROBUST; LOCALIZATION;
   INFORMATION; REGION
AB In recent years, tampering and altering of digital images have become easier with the rapid development of computer technologies such as digital image editing tools. Therefore, verification of image integrity and tamper detection of digital images have become a great challenge. Fragile watermarking is the most widely used method for protecting the integrity and content authenticity of the image. In this paper, by using SHA-256 hash function, a novel block based fragile watermark embedding and tamper detection method is proposed. In watermark embedding phase, host image is divided into 32x32 non-overlapped blocks. Each 32x32 block is then divided into four 16x16 nonoverlapped sub-blocks. The entire hash value of the first three sub-blocks is generated as a watermark using SHA-256 hash function. The generated 256-bit binary watermark is embedded into the least significant bits (LSBs) of the fourth sub-block and watermarked image is obtained. In tamper detection phase, the detection of tampered block has been performed by comparing the hash value obtained from the three sub-blocks with the extracted watermark from the fourth sub-block of the watermarked image. The performance of the proposed method has been evaluated by applying linear and nonlinear attacks to the different regions of the watermarked images. Experimental results show that the proposed method detects all the tampered regions of the attacked images and high visual quality of watermarked images has been obtained.
C1 [Gul, Ertugrul] Nigde Omer Halisdemir Univ, Dept Comp Engn, TR-51240 Nigde, Turkey.
   [Gul, Ertugrul; Ozturk, Serkan] Erciyes Univ, Dept Comp Engn, TR-38039 Kayseri, Turkey.
C3 Nigde Omer Halisdemir University; Erciyes University
RP Gul, E (corresponding author), Nigde Omer Halisdemir Univ, Dept Comp Engn, TR-51240 Nigde, Turkey.; Gul, E (corresponding author), Erciyes Univ, Dept Comp Engn, TR-38039 Kayseri, Turkey.
EM ertugrulgul@erciyes.edu.tr; serkan@erciyes.edu.tr
RI GUL, ERTUGRUL/AAC-4451-2021; Ozturk, Serkan/B-4673-2013
OI GUL, ERTUGRUL/0000-0002-5591-3435; 
CR AlAhmad MA, 2014, INT CONF ADV COMPUT, P250, DOI [10.1109/CICSYN.2013.81, 10.1109/ACSAT.2013.56]
   Ali M, 2018, MULTIMED TOOLS APPL, V77, P11751, DOI 10.1007/s11042-017-4815-6
   Ali SA., 2017, J ENG APPL SCI, V12, P1582
   [Anonymous], 2017, 2017 INT C EL COMP T
   Aparna P, 2018, J INTELL SYST, V27, P115, DOI 10.1515/jisys-2017-0266
   Aslantas V, 2007, LECT NOTES COMPUT SC, V4628, P358
   Aslantas V, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P241, DOI 10.1109/ICME.2008.4607416
   Aslantas V, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P269, DOI 10.1109/ICME.2008.4607423
   Aslantas V, 2009, OPT COMMUN, V282, P2806, DOI 10.1016/j.optcom.2009.04.034
   Bravo-Solorio S, 2011, SIGNAL PROCESS, V91, P728, DOI 10.1016/j.sigpro.2010.07.019
   Christlein V, 2012, ARXIV12083665
   Das S, 2013, COMPUT METH PROG BIO, V111, P662, DOI 10.1016/j.cmpb.2013.05.027
   Fatema Mariya, 2018, International Conference on Wireless, Intelligent, and Distributed Environment for Communication. WIDECOM 2018. Lecture Notes on Data Engineering and Communications Technologies (LNDECT 18), P1, DOI [10.1080/1206212X.2018.1517713, 10.1007/978-3-319-75626-4_1]
   Ghosal SK, 2014, J INF SECUR APPL, V19, P272, DOI 10.1016/j.jisa.2014.07.004
   Hong WE, 2017, SIGNAL PROCESS-IMAGE, V58, P111, DOI 10.1016/j.image.2017.07.001
   Hsu CS, 2010, OPT COMMUN, V283, P1737, DOI 10.1016/j.optcom.2009.12.073
   Hu YC, 2016, FUTURE GENER COMP SY, V62, P92, DOI 10.1016/j.future.2016.04.001
   Khor HL, 2017, J DIGIT IMAGING, V30, P328, DOI 10.1007/s10278-016-9930-9
   Kumar C, 2018, MULTIMED TOOLS APPL, V77, P3597, DOI 10.1007/s11042-017-5222-8
   Lee SJ, 2001, ISIE 2001: IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS PROCEEDINGS, VOLS I-III, P272, DOI 10.1109/ISIE.2001.931796
   Li CT, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2712445
   Li CL, 2015, MULTIMED TOOLS APPL, V74, P10581, DOI 10.1007/s11042-014-2188-7
   Li CL, 2013, MULTIMED TOOLS APPL, V64, P757, DOI 10.1007/s11042-011-0974-z
   Li ZH, 2006, ACTA ELECT SIN, V34, P12
   Loukhaoukha K., 2011, J Inf Hiding Multim Signal Process, V2, P303
   Lu CS, 2003, IEEE T MULTIMEDIA, V5, P161, DOI 10.1109/TMM.2003.811621
   MeenakshiDevi P., 2009, Journal of Computer Sciences, V5, P831, DOI 10.3844/jcssp.2009.831.837
   Navas K A, 2007, SYSTEM SIGNALS IMAGE, P237
   Nazari M, 2017, MULTIMED TOOLS APPL, V76, P16107, DOI 10.1007/s11042-016-3897-x
   Nguyen TS, 2016, AEU-INT J ELECTRON C, V70, P1055, DOI 10.1016/j.aeue.2016.05.003
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Pandey R, 2016, MULTIMED TOOLS APPL, V75, P14381, DOI 10.1007/s11042-016-3536-6
   Parekh M, 2018, ADV INTELL SYST, V710, P519, DOI 10.1007/978-981-10-7871-2_50
   Patel H.A., 2018, ADV COMPUTER COMPUTA, P455, DOI DOI 10.1007/978-981-10-3773-3_44
   Peng Yin HHY, 2001, CLASSIFICATION VIDEO
   Publications (FIPS) FIPS, 2008, PUBL FIPS, P20899
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Qin C, 2017, MULTIMED TOOLS APPL, V76, P2267, DOI 10.1007/s11042-015-3218-9
   Qin C, 2016, INFORM SCIENCES, V373, P233, DOI 10.1016/j.ins.2016.09.001
   Qin C, 2012, SIGNAL PROCESS, V92, P1137, DOI 10.1016/j.sigpro.2011.11.013
   Singh AK, 2017, MULTIMED SYST APPL, P159, DOI 10.1007/978-3-319-57699-2_7
   Singh AK, 2014, P NATL A SCI INDIA A, V84, P345, DOI 10.1007/s40010-014-0140-x
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P953, DOI 10.1007/s11042-015-3010-x
   Singh P., 2013, INT J ENG INNOV TECH, V2, P165
   Singh P, 2017, MULTIMED TOOLS APPL, V76, P6389, DOI 10.1007/s11042-015-3198-9
   Singh RK, 2015, PROCEDIA COMPUT SCI, V54, P612, DOI 10.1016/j.procs.2015.06.071
   Sreenivas K, 2017, INT J MACH LEARN CYB
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P8781, DOI 10.1007/s11042-016-3522-z
   Trivedy S, 2017, IJST-T ELECTR ENG, V41, P103, DOI 10.1007/s40998-017-0021-9
   Tsai P, 2005, IMAGING SCI J, V53, P149, DOI 10.1179/136821905X50406
   Ustubioglu A, 2017, J DIGIT IMAGING, V30, P665, DOI 10.1007/s10278-017-9960-y
   Vasu S., 2012, Proceedings of the 2012 International Conference on Communication Systems and Network Technologies (CSNT 2012), P85, DOI 10.1109/CSNT.2012.28
   Verma VS, 2015, EXPERT SYST APPL, V42, P8184, DOI 10.1016/j.eswa.2015.06.041
   Wahid M., 2018, P INT C ENG EM TECHN, P1, DOI [10.1109/ICEET1.2018.8338621, DOI 10.1109/ICEET1.2018.8338621]
   Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369
   Weber A. G., 1997, USC-SIPI Report, V315
   Yu M, 2015, AEU-INT J ELECTRON C, V69, P361, DOI 10.1016/j.aeue.2014.10.006
   Zhang H, 2017, J INF PROCESS SYST, V13, P385, DOI 10.3745/JIPS.03.0070
   Zhang XP, 2009, SIGNAL PROCESS, V89, P675, DOI 10.1016/j.sigpro.2008.10.001
   Zhang XP, 2015, MULTIMED TOOLS APPL, V74, P5767, DOI 10.1007/s11042-014-1882-9
   Zheng PP, 2014, NEUROCOMPUTING, V142, P520, DOI 10.1016/j.neucom.2014.04.005
NR 62
TC 45
Z9 45
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 17701
EP 17718
DI 10.1007/s11042-018-7084-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200018
DA 2024-07-18
ER

PT J
AU Huang, F
   Huang, BR
AF Huang, Fay
   Huang, Bo-Ru
TI Stereoscopic oil paintings from RGBD images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stroke-based rendering; Painterly rendering; Stereo painting synthesis
AB Stroke-based rendering is one of the major approaches for creating synthetic paintings, but with only a minor attention so far to stereo painting synthesis. In this article, a fully automatic stereoscopic oil-painting synthesis algorithm is proposed, which takes a photograph and a depth map as input, and generates a pair of oil-painting style, stereo-viewable paintings. Common drawbacks of existing stroke-based rendering results are impressions of repetition and flatness due to the regularity of the used 2D stroke patterns. To reduce these impressions, the proposed approach introduces the concepts of a defocused image, a complexity map, a point map, and a direction map. Those maps serve as important references for decision making and thus, are the foundation for the entire painting simulation process. The key feature of making the developed stroke-based algorithm different from others is that it generates a unique 3D brushstroke according to the characteristics of a local image region. This has greatly reduced the undesirable machine-like appearance in the resulting image. Moreover, a comfortable stereo-viewing experience is assured by the proposed stereo painting and hole-filling strategies. Experimental results show that the proposed algorithm is applicable to a wide variety of image subjects and different depth distributions.
C1 [Huang, Fay; Huang, Bo-Ru] Natl Ilan Univ, Dept Comp Sci & Informat Engn, Yilan, Taiwan.
C3 National Ilan University
RP Huang, F (corresponding author), Natl Ilan Univ, Dept Comp Sci & Informat Engn, Yilan, Taiwan.
EM fay@niu.edu.tw
RI Li, Mengqi/AAG-6804-2021
FU Ministry of Science and Technology, Taiwan [MOST 104-2221-E-197-020-MY2]
FX This study was funded by the Ministry of Science and Technology, Taiwan
   (MOST 104-2221-E-197-020-MY2). Fay Huang is a member of Chinese Image
   Processing and Pattern Recognition Society (IPPR, Taiwan). She worked as
   a postdoctoral fellow at Institute of Information Science, Academic
   Sinica, Taiwan, from 2003 to 2004. She was also a consultant of Smart
   System Institute, Institute for Information Industry, Taiwan, in 2017.
   Bo-Ru Huang declares that he has no conflict of interest.
CR [Anonymous], 2014, Proceedings of the 27th Annual ACM Symposium on User Interface Software and Technology. UIST'14, DOI 10.1145/2642918.2647415
   [Anonymous], 2015, ARXIV150806576 CORR
   [Anonymous], 2012, P INT S NONPH AN REN
   Bac S, 2007, COMPUT GRAPH FORUM, V26, P571, DOI 10.1111/j.1467-8659.2007.01080.x
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chang W.-H., 2015, J INFORM HIDING MULT, V6, P29
   Chen XW, 2012, COMPUT GRAPH FORUM, V31, P1425, DOI 10.1111/j.1467-8659.2012.03138.x
   Gooch B., 2002, 2 INT S NONPHOTOREAL, P83
   Guo CE, 2007, COMPUT VIS IMAGE UND, V106, P5, DOI 10.1016/j.cviu.2005.09.004
   Hertzmann A., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P453, DOI 10.1145/280814.280951
   Howard I, 1995, OXFORD PSYCHOL SERIE, V29
   Kang HW, 2006, VISUAL COMPUT, V22, P814, DOI 10.1007/s00371-006-0066-7
   Kim Y, 2014, IEEE T VIS COMPUT GR, V20, P957, DOI 10.1109/TVCG.2014.17
   Lee H, 2011, COMPUT GRAPH-UK, V35, P81, DOI 10.1016/j.cag.2010.11.008
   Lee KJ, 2007, VISUAL COMPUT, V23, P873, DOI 10.1007/s00371-007-0142-7
   Litwinowicz P., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P407, DOI 10.1145/258734.258893
   Liu D.W., 2016, THESIS
   Meier B. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P477, DOI 10.1145/237170.237288
   SHIRAISHI M, 2000, P 1 INT S NONPH AN R, P53, DOI DOI 10.1145/340916.340923
   Stavrakis E, 2008, THESIS
   Wang B, 2004, IEEE T VIS COMPUT GR, V10, P266, DOI 10.1109/TVCG.2004.1272726
   Ware C, 1998, IEEE T SYST MAN CY A, V28, P56, DOI 10.1109/3468.650322
   Zeng K, 2009, ACM T GRAPHIC, V29, DOI 10.1145/1640443.1640445
   Zhang W, 2012, IEEE T IMAGE PROCESS, V21, P873, DOI 10.1109/TIP.2011.2162739
NR 24
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18249
EP 18270
DI 10.1007/s11042-019-7167-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200041
DA 2024-07-18
ER

PT J
AU Khan, A
   Ahmad, M
   Naqvi, N
   Yousafzai, F
   Xiao, J
AF Khan, Asad
   Ahmad, Muhammad
   Naqvi, Nuzhat
   Yousafzai, Faisal
   Xiao, Jing
TI Photographic painting style transfer using convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Photographics Painting Style (PPS); Non-Photorealistic Rendering (NPR);
   Photorealistic Rendering (PR); Digital painting; Example-based painting
AB We propose a novel automatic photographic painting style technique with a single example image by using Convolutional Neural Networks (CNN). The photographic painting style is a challenging problem in the research community. Even though, researchers have been trying to obtain good results on painting style, but not much has been done on photographic stylization. Portrait painting techniques are mainly designed for the graphite style and/or are based on image analogies; an example painting as well as its original unpainted version are required. This preceding issue is a motivation of our proposed methods. As a result, our method extends the limits of their domain of applicability. We present a novel multi-convolutional-learning technique that is developed for both images (NPR/PR) labeling, style transmission and elevating a particular unified CNN model per weight sharing. A new painting technique is generated that follows the example style in the example image and maintains the integrity of facial structures. We believe this novel interpretation connects these two important research fields and could enlighten future researches. Moreover, our proposed technique is not restricted to headshot images or specific styles as our method can also change the photographic painting style in the wild.
C1 [Khan, Asad; Xiao, Jing] South China Normal Univ, Sch Comp Sci, Guangzhou, Guangdong, Peoples R China.
   [Ahmad, Muhammad] Innopolis Univ, Inst Robot, Dept Comp Sci, Innopolis, Russia.
   [Naqvi, Nuzhat] Univ Sci & Technol China, Sch Elect Engn & Informat Sci, Hefei, Anhui, Peoples R China.
   [Yousafzai, Faisal] Natl Univ Sci & Technol NUST, Mil Coll Engn, Islamabad, Pakistan.
C3 South China Normal University; Innopolis University; Chinese Academy of
   Sciences; University of Science & Technology of China, CAS; National
   University of Sciences & Technology - Pakistan
RP Xiao, J (corresponding author), South China Normal Univ, Sch Comp Sci, Guangzhou, Guangdong, Peoples R China.
EM asadustc@gmail.com; xiaojing@scnu.edu.cn
RI Ahmad, Muhammad/X-6113-2019; Li, Mengqi/AAG-6804-2021; Khan,
   Asad/HNR-9080-2023; xiao, jing/HRB-7391-2023
OI Ahmad, Muhammad/0000-0002-3320-2261; Khan, Asad/0000-0002-1261-0418
FU National Natural Science Foundation of China [61202296, 61872153];
   National Science Foundation of Guangdong province [2018A030313318]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 61202296, 61872153) and the National Science Foundation
   of Guangdong province No. 2018A030313318.
CR Ashikhmin M, 2003, IEEE COMPUT GRAPH, V23, P38, DOI 10.1109/MCG.2003.1210863
   Ashikhmin M., 2001, P 2001 S INT 3D GRAP, P217, DOI DOI 10.1145/364338.364405
   Chen H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P433, DOI 10.1109/ICCV.2001.937657
   Chen H., 2002, Proceedings of the Tenth ACM International Conference on Multimedia, P171
   Chen Hong, 2003, Chinese Journal of Computers, V26, P147
   Chen Hong., 2004, P 3 INT S NONPHOTORE, P95, DOI DOI 10.1145/987
   Collomosse JP, 2005, LECT NOTES COMPUT SC, V3449, P437
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Gooch B, 2004, ACM T GRAPHIC, V23, P27, DOI 10.1145/966131.966133
   Gu S, 2018, 180504103 CORR
   Hafeez KA, 2011, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2011-117
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Hertzmann A., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P453, DOI 10.1145/280814.280951
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim S, 2009, 2009 INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING, P41, DOI 10.1109/ASONAM.2009.59
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kwatra V, 2005, ACM T GRAPHIC, V24, P795, DOI 10.1145/1073204.1073263
   Kyprianidis JE, 2013, IEEE T VIS COMPUT GR, V19, P866, DOI 10.1109/TVCG.2012.160
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lee H., 2010, Proceedings of the 8th International Symposium on Non-Photorealistic Animation and Rendering, P43
   Li C, 2016, PROC CVPR IEEE, P2479, DOI 10.1109/CVPR.2016.272
   Li YT, 2017, ADV NEUR IN, V30
   Liao J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073683
   Lu M, 2017, IEEE I CONF COMP VIS, P2488, DOI 10.1109/ICCV.2017.270
   McKone E, 2007, TRENDS COGN SCI, V11, P8, DOI 10.1016/j.tics.2006.11.002
   Meng Meng., 2010, P INT C MULTIMEDIA M, P931
   Pinheiro PHO, 2013, 13062795 CORR
   Ruder M, 2016, LECT NOTES COMPUT SC, V9796, P26, DOI 10.1007/978-3-319-45886-1_3
   Selim A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925968
   Shih YC, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601137
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sinha P, 2006, P IEEE, V94, P1948, DOI 10.1109/JPROC.2006.884093
   Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Song J, 2016, IEEE T IMAGE PROCESS, V25, P4999, DOI 10.1109/TIP.2016.2601260
   Tompson Jonathan, 2014, ARXIV14062984, DOI DOI 10.5555/2968826.2969027
   Ulyanov D, 2016, PR MACH LEARN RES, V48
   Wang B, 2004, IEEE T VIS COMPUT GR, V10, P266, DOI 10.1109/TVCG.2004.1272726
   Wang TH, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.36
   Wang X, 2 STREAM 3 D CONVNET, P1
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P1955, DOI 10.1109/TPAMI.2008.222
   Wang XH, 2017, IEEE SIGNAL PROC LET, V24, P510, DOI 10.1109/LSP.2016.2611485
   Zeng K, 2009, ACM T GRAPHIC, V29, DOI 10.1145/1640443.1640445
   Zhu CY, 1997, ACM T MATH SOFTWARE, V23, P550, DOI 10.1145/279232.279236
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
NR 51
TC 3
Z9 4
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19565
EP 19586
DI 10.1007/s11042-019-7270-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800029
DA 2024-07-18
ER

PT J
AU Li, ZF
   Zheng, ZL
   Lin, FL
   Leung, H
   Li, Q
AF Li, Zhifei
   Zheng, Zhonglong
   Lin, Feilong
   Leung, Howard
   Li, Qing
TI Action recognition from depth sequence using depth motion maps-based
   local ternary patterns and CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action recognition; Depth motion maps; Convolutional neural
   network; Local ternary pattern
ID POSE
AB This paper presents a method for human action recognition from depth sequences captured by the depth camera. The main idea of the method is the action mapping image classification via convolutional neural network (CNN) based approach. Firstly, we project the raw frames onto three orthogonal Cartesian planes and stack the results into three still images (corresponding to the front, side, and top views) to form the Depth Motion Maps (DMMs). Secondly, Local Ternary Pattern (LTP) is introduced as an image filter for DMMs, thus to improve the distinguishability of similar actions. Finally, we apply CNN to action recognition by classifying corresponding LTP-encoded images. Experimental results on the popular and challenging benchmark MSR-Action 3D and MSR-Gesture dataset show the effectiveness of the presented method and meet real-time action recognition task requirements.
C1 [Li, Zhifei; Zheng, Zhonglong; Lin, Feilong] Zhejiang Normal Univ, Dept Comp Sci & Technol, Jinhua, Zhejiang, Peoples R China.
   [Li, Zhifei; Leung, Howard; Li, Qing] CITYU, Dept Comp Sci, Hong Kong, Peoples R China.
C3 Zhejiang Normal University
RP Li, ZF (corresponding author), Zhejiang Normal Univ, Dept Comp Sci & Technol, Jinhua, Zhejiang, Peoples R China.; Li, ZF (corresponding author), CITYU, Dept Comp Sci, Hong Kong, Peoples R China.
EM zjnulzf@163.com; zhonglong@zjnu.edu.cn; bruce_lin@zjnu.cn;
   howard@cityu.edu.hk; itqli@cityu.edu.hk
RI Lin, Feilong/GRN-9551-2022; Li, Qing/JMH-1365-2023; zheng,
   yi/JOZ-7204-2023
OI Lin, Feilong/0000-0003-0981-3721; Li, Qing/0000-0003-3370-471X; 
FU Zhejiang Provincial Top Key Discipline of Computer Software and Theory;
   National Natural Science Foundation of China [61170109, 61672467];
   National Science Foundation of Zhejiang Province, China [2015C31095]
FX The authors thank the anonymous reviewers for valuable comments. This
   work is mainly supported by grants from Zhejiang Provincial Top Key
   Discipline of Computer Software and Theory, National Natural Science
   Foundation of China (No. 61170109, 61672467), and National Science
   Foundation of Zhejiang Province (No. 2015C31095), China.
CR Aggarwal JK, 2014, PATTERN RECOGN LETT, V48, P70, DOI 10.1016/j.patrec.2014.04.011
   [Anonymous], COMPUT ANIMATION VIR
   Chen CJ, 2015, SMALL, V11, P613, DOI 10.1002/smll.201400642
   Chen C, 2015, IEEE WINT CONF APPL, P1092, DOI 10.1109/WACV.2015.150
   Chen C, 2016, J REAL-TIME IMAGE PR, V12, P155, DOI 10.1007/s11554-013-0370-1
   Guo P, 2014, MULTIMED TOOLS APPL, V68, P827, DOI 10.1007/s11042-012-1084-2
   Hattori H, 2018, INT J COMPUT VISION, V126, P1027, DOI 10.1007/s11263-018-1077-3
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jia XF, 2012, INT C PATT RECOG, P3001
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kurakin A, 2012, EUR SIGNAL PR CONF, P1975
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Reily B, 2018, AUTON ROBOT, V42, P1281, DOI 10.1007/s10514-017-9692-3
   Shen ZQ, 2017, IEEE I CONF COMP VIS, P1937, DOI 10.1109/ICCV.2017.212
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang PC, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1119, DOI 10.1145/2733373.2806296
   Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Xiang Li, 2013, Journal of Software, V8, P659, DOI 10.4304/jsw.8.3.659-665
   Yang JC, 2018, IEEE CONSUM ELECTR M, V7, P64, DOI 10.1109/MCE.2017.2776500
   Yang R, 2015, LECT NOTES COMPUT SC, V9007, P37, DOI 10.1007/978-3-319-16814-2_3
   Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342
   Zhao WT, 2012, INT C APPL ROBOT POW, P557, DOI 10.1109/CARPI.2012.6356377
NR 27
TC 21
Z9 21
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19587
EP 19601
DI 10.1007/s11042-019-7356-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800030
DA 2024-07-18
ER

PT J
AU Nadeem, M
   Hussain, A
   Munir, A
AF Nadeem, Muhammad
   Hussain, Ayyaz
   Munir, Asim
TI Fuzzy logic based computational model for speckle noise removal in
   ultrasound images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ultrasound imaging; Image despeckling; Image restoration; Fuzzy
   uncertainty modelling; Non local mean; Fuzzy similarity based
   non-local-mean; Local statistics
ID FILTER; ENHANCEMENT; REDUCTION; ALGORITHM
AB High level of uncertainty is always present due to impulsive noise in ultrasonic images, which may put negative effect on image interpretation, quantitative measurement and diagnostic purposes. In order to deal with this uncertainty, fuzzy modelling is being used which is very helpful in distinguishing noise from edges and other critical details present in the image. In this study, a novel fuzzy logic based non-local mean filter is proposed to model the speckle noise and to restore the degraded image using Fuzzy Uncertainty Modelling (FUM), smoothed by local statistic based information while preserving the image details for low and highly speckled ultrasound images. Proposed denoising technique acquires the local parameters to find distinct similar and non-similar non-local regions using FUM. These homogenous regions are first smoothed through local statistical information and then used to restore the selected noisy pixels using fuzzy logic based noise removal process. The study evaluates the performance of the proposed technique on different real and simulated data sets, and compares the numerical values with existing state of art filters using standard well known global quantitative measure like signal to noise ratio (SNR) and a local error measure - structural similarity index measure (SSIM). Visual and quantitative results demonstrate that the proposed technique outperforms the existing state of the art filters in removing speckle noise while preserving the edges and other important details present in the image.
C1 [Nadeem, Muhammad; Hussain, Ayyaz; Munir, Asim] Int Islamic Univ, Dept Comp Sci & Software Engn, Islamabad, Pakistan.
C3 International Islamic University, Pakistan
RP Hussain, A (corresponding author), Int Islamic Univ, Dept Comp Sci & Software Engn, Islamabad, Pakistan.
EM nadeem@iiu.edu.pk; ayyaz.hussain@iiu.edu.pk; asim@iiu.edu.pk
OI Nadeem, Muhammad/0000-0001-9290-5461
CR Abd-Elmoniem KZ, 2002, IEEE T BIO-MED ENG, V49, P997, DOI 10.1109/TBME.2002.1028423
   Ambrosanio M, 2018, EMBEC NBC 2017 EMBE, V65
   [Anonymous], 2017, AAAI C ART INT
   Bamber JC, 1980, PHYS MED BIOL, V25
   Baselice F, 2017, ULTRASOUND MED BIOL, V43, P2065, DOI 10.1016/j.ultrasmedbio.2017.05.006
   Binaee K, 2011, MACH VIS IM PROC MVI, P1
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chaudhry A, 2007, INT J IMAG SYST TECH, V17, P224, DOI 10.1002/ima.20105
   Chen Y, 1996, ULTRASONIC IMAGING, V18, P122, DOI 10.1006/uimg.1996.0007
   Coupé P, 2009, IEEE T IMAGE PROCESS, V18, P2221, DOI 10.1109/TIP.2009.2024064
   FROST VS, 1982, IEEE T PATTERN ANAL, V4, P157, DOI 10.1109/TPAMI.1982.4767223
   Ghesu FC, 2017, IEEE T PATTERN ANAL
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Javed SG, 2017, MULTIMEDIA TOOLS APP
   Jensen J. A., 1996, 10 NORD BALT C BIOM
   JENSEN JA, 1992, IEEE T ULTRASON FERR, V39, P262, DOI 10.1109/58.139123
   Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044
   Kim J, 2018, PRECIS FUTURE MED, V2, P37, DOI 10.23838/pfm.2018.00030
   Krissian K, 2007, IEEE T IMAGE PROCESS, V16, P1412, DOI 10.1109/TIP.2007.891803
   KUAN DT, 1985, IEEE T PATTERN ANAL, V7, P165, DOI 10.1109/TPAMI.1985.4767641
   Lan X, 2018, AAAI C ART INT
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   LEE JS, 1980, IEEE T PATTERN ANAL, V2, P165, DOI 10.1109/TPAMI.1980.4766994
   Lu L, 2017, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-3-319-42999-1
   Maier A, 2018, ARXIV181005401V1
   Masood S, 2014, APPL SOFT COMPUT, V21, P107, DOI 10.1016/j.asoc.2014.03.006
   Nirschl JJ, 2017, ELS MIC SOC BOOK SER, P179, DOI 10.1016/B978-0-12-810408-8.00011-0
   Sharif M, 2016, SIGNAL IMAGE VIDEO P, V10, P215, DOI 10.1007/s11760-014-0729-1
   Sharif M, 2015, MULTIMED TOOLS APPL, V74, P5533, DOI 10.1007/s11042-014-1867-8
   Singh K, 2017, COMPUT METH PROG BIO, V148, P55, DOI 10.1016/j.cmpb.2017.06.009
   Tay PC, 2010, IEEE T IMAGE PROCESS, V19, P1847, DOI 10.1109/TIP.2010.2044962
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu J, 2014, SIGNAL IMAGE VIDEO P, V8, P349, DOI 10.1007/s11760-012-0297-1
   Yang J, 2016, NEUROCOMPUTING, V195, P88, DOI 10.1016/j.neucom.2015.05.140
   Yu YJ, 2002, IEEE T IMAGE PROCESS, V11, P1260, DOI 10.1109/TIP.2002.804279
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
NR 36
TC 19
Z9 19
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18531
EP 18548
DI 10.1007/s11042-019-7221-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200053
DA 2024-07-18
ER

PT J
AU Ajili, I
   Ramezanpanah, Z
   Mallem, M
   Didier, JY
AF Ajili, Insaf
   Ramezanpanah, Zahra
   Mallem, Malik
   Didier, Jean-Yves
TI Expressive motions recognition and analysis with learning and
   statistical methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Expressive motion recognition; Laban movement analysis; Random decision
   forest; Human perception; Features importance
ID MOVEMENTS; EMOTIONS
AB This paper proposes to recognize and analyze expressive gestures using a descriptive motion language, the Laban Movement Analysis (LMA) method. We extract body features based on LMA factors which describe both quantitative and qualitative aspects of human movement. In the direction of our study, a dataset of 5 gestures performed with 4 emotions is created using the motion capture Xsens. We used two different approaches for emotions analysis and recognition. The first one is based on a machine learning method, the Random Decision Forest. The second approach is based on the human's perception. We derive the most important features for each expressed emotion using the same methods, the RDF and the human's ratings. We compared the results obtained from the automatic learning method against human perception in the discussion section.
C1 [Ajili, Insaf; Ramezanpanah, Zahra; Mallem, Malik; Didier, Jean-Yves] Univ Paris Saclay, Univ Evry, IBISC, F-91025 Evry, France.
C3 Universite Paris Saclay; Universite Paris Cite
RP Ajili, I (corresponding author), Univ Paris Saclay, Univ Evry, IBISC, F-91025 Evry, France.
EM insaf.bouzayaniajili@univ-evry.fr; zahra.ramezanpanah@univ-evry.fr;
   abdelmalik.mallem@univ-evry.fr; jeanyves.didier@univ-evry.fr
RI MALLEM, Malik/P-6389-2017
OI MALLEM, Malik/0000-0002-2471-7028
FU Strategic Research Initiatives project iCODE, University Paris Saclay
FX This study was funded by the Strategic Research Initiatives project
   iCODE, University Paris Saclay.
CR Ajili I, 2017, IEEE ROMAN, P1115, DOI 10.1109/ROMAN.2017.8172443
   Ajili I, 2017, PROCEDIA COMPUT SCI, V112, P554, DOI 10.1016/j.procs.2017.08.168
   Amaya K, 1996, PROC GRAPH INTERF, P222
   [Anonymous], 1975, BODILY COMMUNICATION
   [Anonymous], LECT NOTES COMPUT SC
   [Anonymous], VISUAL COMPUTER
   [Anonymous], 2013, Proceedings of the ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games, I3D'13
   Aristidou A, 2014, LMA BASED MOTION RET, P207
   Barakova EI, 2010, PERS UBIQUIT COMPUT, V14, P457, DOI 10.1007/s00779-009-0263-2
   Barber CB, 1996, ACM T MATH SOFTWARE, V22, P469, DOI 10.1145/235815.235821
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chen LS, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P423, DOI 10.1109/ICME.2000.869630
   Chi D, 2000, COMP GRAPH, P173, DOI 10.1145/344779.352172
   Cimen G, 2013, COMPUT ANIMAT VIRT W, V24, P355, DOI 10.1002/cav.1509
   de Gelder B, 2009, PHILOS T R SOC B, V364, P3475, DOI 10.1098/rstb.2009.0190
   De Silva L. C., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P332, DOI 10.1109/AFGR.2000.840655
   Durupinar F, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2983620
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   Kamaruddin N, 2010, IEEE INT VEH SYM, P238, DOI 10.1109/IVS.2010.5548124
   Kanade T., 2000, P 4 IEEE INT C AUT F, P46, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]
   Kleinsmith A, 2013, IEEE T AFFECT COMPUT, V4, P15, DOI 10.1109/T-AFFC.2012.16
   KWON YH, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P762, DOI 10.1109/CVPR.1994.323894
   Lanitis A, 2004, IEEE T SYST MAN CY B, V34, P621, DOI 10.1109/TSMCB.2003.817091
   Liu Y, 2016, ARXIV161101872 CORR
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lourens T, 2010, ROBOT AUTON SYST, V58, P1256, DOI 10.1016/j.robot.2010.08.006
   Masuda M, 2010, 2010 IEEE RO-MAN, P324, DOI 10.1109/ROMAN.2010.5598692
   Montepare J, 1999, J NONVERBAL BEHAV, V23, P133, DOI 10.1023/A:1021435526134
   Pantic M, 2003, P IEEE, V91, P1370, DOI 10.1109/JPROC.2003.817122
   Ramanathan N, 2006, IEEE T IMAGE PROCESS, V15, P3349, DOI 10.1109/TIP.2006.881993
   Shafir T, 2016, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.02030
   Tavakol M, 2011, INT J MED EDUC, V2, P1, DOI [10.5116/ijme.4d27.32ff, 10.5116/ijme.4dfb.8dfd]
   von Laban R., 1980, The Mastery of Movement
   Wallbott HG, 1998, EUR J SOC PSYCHOL, V28, P879, DOI 10.1002/(SICI)1099-0992(1998110)28:6<879::AID-EJSP901>3.0.CO;2-W
   Zacharatos H., 2013, MIG 13, P61
   Zhao LW, 2005, GRAPH MODELS, V67, P1, DOI 10.1016/j.gmod.2004.08.002
NR 37
TC 6
Z9 6
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16575
EP 16600
DI 10.1007/s11042-018-6893-5
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500038
DA 2024-07-18
ER

PT J
AU Birajdar, GK
   Patil, MD
AF Birajdar, Gajanan K.
   Patil, Mukesh D.
TI Speech and music classification using spectrogram based statistical
   descriptors and extreme learning machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IIR-CQT spectrogram; Nonsubsampled contourlet transform; Generalized
   Gaussian distribution; Chaos crow search algorithm; ELM classifier
ID GENERALIZED GAUSSIAN DENSITY; MAXIMUM A-POSTERIORI; CONTOURLET
   TRANSFORM; IMAGE RETRIEVAL; NEURAL-NETWORKS; TEXT DETECTION;
   DISCRIMINATION; ALGORITHMS; FEATURES; DESIGN
AB This article proposes a novel feature extraction approach for speech/music classification based on generalized Gaussian distribution descriptors extracted from IIR-CQT spectrogram representation. IIR-CQT spectrogram visual representation provides superior temporal resolution at high frequencies and better spectral resolution for low frequencies compared to the conventional short-time Fourier transform analysis which provides uniform frequency resolution. Multi-level decomposition of the spectrogram image is then performed using the Nonsubsampled Contourlet Transform (NSCT) which a fully shift-invariant, multi-scale, and multi-direction expansion that can preserve the edges of the textural pattern of speech and music. The generalized Gaussian distribution (GGD) parameters are produced using maximum likelihood estimation (MLE) from the NSCT subbands to create the image feature descriptor. Chaos crow search algorithm is employed to chose the most relevant feature sub-set and to discard redundant features and finally the extreme learning machine classifier categorizes input audio segment into speech/music. The experimental results show that the proposed feature descriptor is effective and performs better compared to the existing approaches in the speech/music classification. In addition, mismatched training and testing results are also presented.
C1 [Birajdar, Gajanan K.] Ramrao Adik Inst Technol, Dept Elect Engn, Navi Mumbai 400706, Maharashtra, India.
   [Patil, Mukesh D.] Ramrao Adik Inst Technol, Dept Elect & Telecommun Engn, Navi Mumbai 400706, Maharashtra, India.
RP Birajdar, GK (corresponding author), Ramrao Adik Inst Technol, Dept Elect Engn, Navi Mumbai 400706, Maharashtra, India.
EM gajanan.birajdar@rait.ac.in
RI Birajdar, Gajanan/Z-1937-2018; Patil, Mukesh/W-5472-2019
OI Birajdar, Gajanan/0000-0003-3531-3958; Patil, Mukesh/0000-0002-0232-723X
CR Alam J, 2017, EUR SIGNAL PR CONF, P101, DOI 10.23919/EUSIPCO.2017.8081177
   Anandhi D, 2018, COMPUT ELECTR ENG, V65, P139, DOI 10.1016/j.compeleceng.2017.04.002
   [Anonymous], 2018, IEEE Trans. Multimed.
   [Anonymous], 2000, WILEY SERIES PROBABI
   Askarzadeh A, 2016, COMPUT STRUCT, V169, P1, DOI 10.1016/j.compstruc.2016.03.001
   Bartlett PL, 1997, ADV NEURAL INFORMATI, P134
   Cancela P., 2009, P INT SOC MUS INF RE, P309
   Chacko BP, 2012, INT J MACH LEARN CYB, V3, P149, DOI 10.1007/s13042-011-0049-5
   Costa YMG, 2017, APPL SOFT COMPUT, V52, P28, DOI 10.1016/j.asoc.2016.12.024
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Devanna H, 2019, CLUSTER COMPUT, V22, P11193, DOI 10.1007/s10586-017-1351-0
   Didiot E, 2010, COMPUT SPEECH LANG, V24, P341, DOI 10.1016/j.csl.2009.05.003
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822
   El-Maleh K, 2000, INT CONF ACOUST SPEE, P2445, DOI 10.1109/ICASSP.2000.859336
   Feng YQ, 2003, 2003 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-5, PROCEEDINGS, P2085, DOI 10.1109/ICMLC.2003.1259848
   Fuchs G, 2015, EUR SIGNAL PR CONF, P569, DOI 10.1109/EUSIPCO.2015.7362447
   Ghosal A., 2011, Proceedings of the Second International Conference on Emerging Applications of Information Technology (EAIT 2011), P49, DOI 10.1109/EAIT.2011.19
   Ghosal A, 2017, INT C COMP SCI ENG, P71
   Ghosal A, 2009, 2009 THIRD INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL 3, PROCEEDINGS, P435, DOI 10.1109/IITA.2009.427
   Guo JM, 2015, IEEE T INTELL TRANSP, V16, P1989, DOI 10.1109/TITS.2014.2386535
   Hirvonen T, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P135, DOI 10.1109/ISM.2014.27
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Huang XD, 2018, MULTIMED TOOLS APPL, V77, P7033, DOI 10.1007/s11042-017-4619-8
   Jensen Richard., 2008, COMPUTATIONAL INTELL, DOI 10.1002/9780470377888
   Kacprzak S, 2013, SPEECH MUSIC DISCRIM
   Kacprzak S, 2017, INT CONF SYST SIGNAL, DOI 10.1109/IWSSIP.2017.7965606
   Karpagachelvi S, 2012, NEURAL COMPUT APPL, V21, P1331, DOI 10.1007/s00521-011-0572-z
   Khan MKS, 2006, MULTIMEDIA SYST, V12, P55, DOI 10.1007/s00530-006-0034-0
   Khonglah BK, 2016, DIGIT SIGNAL PROCESS, V48, P71, DOI 10.1016/j.dsp.2015.09.005
   Kos M, 2013, DIGIT SIGNAL PROCESS, V23, P659, DOI 10.1016/j.dsp.2012.10.008
   Krupinski R, 2006, SIGNAL PROCESS, V86, P205, DOI 10.1016/j.sigpro.2005.05.003
   Lan Y, 2013, NEURAL COMPUT APPL, V22, P417, DOI 10.1007/s00521-012-0946-x
   Lavner Y, 2009, EURASIP J AUDIO SPEE, DOI 10.1155/2009/239892
   Lee CC, 2012, MULTIDIM SYST SIGN P, V23, P423, DOI 10.1007/s11045-011-0167-y
   Li Y, 2017, KNOWL INF SYST, V53, P551, DOI 10.1007/s10115-017-1059-8
   Lim C, 2012, IET SIGNAL PROCESS, V6, P335, DOI 10.1049/iet-spr.2011.0139
   Lim C, 2015, MULTIMED TOOLS APPL, V74, P5375, DOI 10.1007/s11042-014-1859-8
   Liu Q, 2016, NEURAL COMPUT APPL, V27, P59, DOI 10.1007/s00521-014-1549-5
   Luo FF, 2017, NEUROCOMPUTING, V260, P313, DOI 10.1016/j.neucom.2017.04.052
   Miao JY, 2016, PROCEDIA COMPUT SCI, V91, P919, DOI 10.1016/j.procs.2016.07.111
   Muñoz-Expósito JE, 2007, ENG APPL ARTIF INTEL, V20, P783, DOI 10.1016/j.engappai.2006.10.007
   Nanni L, 2017, PATTERN RECOGN LETT, V88, P49, DOI 10.1016/j.patrec.2017.01.013
   Nanni L, 2016, EXPERT SYST APPL, V45, P108, DOI 10.1016/j.eswa.2015.09.018
   Pikrakis A, 2008, IEEE T MULTIMEDIA, V10, P846, DOI 10.1109/TMM.2008.922870
   Po DDY, 2006, IEEE T IMAGE PROCESS, V15, P1610, DOI 10.1109/TIP.2006.873450
   Qu HJ, 2007, LECT NOTES COMPUT SC, V4683, P493
   Rashno A, 2017, NEUROCOMPUTING, V226, P66, DOI 10.1016/j.neucom.2016.11.030
   Reyes NR, 2010, ENG APPL ARTIF INTEL, V23, P151, DOI 10.1016/j.engappai.2009.06.006
   Ruiz-Reyes N, 2009, MULTIMED TOOLS APPL, V41, P253, DOI 10.1007/s11042-008-0228-x
   Salaken SM, 2017, NEUROCOMPUTING, V267, P516, DOI 10.1016/j.neucom.2017.06.037
   Saunders J, 1996, INT CONF ACOUST SPEE, P993, DOI 10.1109/ICASSP.1996.543290
   Sayed GI, 2019, NEURAL COMPUT APPL, V31, P171, DOI 10.1007/s00521-017-2988-6
   Scheirer E, 1997, INT CONF ACOUST SPEE, P1331, DOI 10.1109/ICASSP.1997.596192
   Sell Gregory, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2489, DOI 10.1109/ICASSP.2014.6854048
   Sharan RV, 2015, NEUROCOMPUTING, V158, P90, DOI 10.1016/j.neucom.2015.02.001
   SHENSA MJ, 1992, IEEE T SIGNAL PROCES, V40, P2464, DOI 10.1109/78.157290
   Shirazi J, 2010, MULTIMED TOOLS APPL, V50, P415, DOI 10.1007/s11042-009-0416-3
   Tsipas N, 2017, MULTIMED TOOLS APPL, V76, P25603, DOI 10.1007/s11042-016-4315-0
   VARANASI MK, 1989, J ACOUST SOC AM, V86, P1404, DOI 10.1121/1.398700
   Wan C, 2015, LECT NOTES COMPUT SC, V9010, P218, DOI 10.1007/978-3-319-16634-6_17
   Wang MJ, 2017, NEUROCOMPUTING, V267, P69, DOI 10.1016/j.neucom.2017.04.060
   Wang WQ, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P1325
   Wu Q, 2010, COMPUT SPEECH LANG, V24, P257, DOI 10.1016/j.csl.2009.04.009
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yang GC, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/262819
   Yu S., 2012, Journal of Computational Information Systems, V8, P9055
   Zhang H, 2016, IEEE INT SYMP SIGNAL, P1, DOI 10.1109/ISSPIT.2016.7885999
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
   Zhao JW, 2014, NEURAL COMPUT APPL, V24, P1317, DOI 10.1007/s00521-013-1356-4
   Zhou HP, 2008, PROCEEDINGS OF THE 6TH CONFERENCE OF BIOMATHEMATICS, VOLS I AND II, P170
NR 74
TC 14
Z9 15
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 15141
EP 15168
DI 10.1007/s11042-018-6899-z
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700045
DA 2024-07-18
ER

PT J
AU Chanu, PR
   Singh, KM
AF Chanu, P. Roji
   Singh, Kh. Manglem
TI A two-stage switching vector median filter based on quaternion for
   removing impulse noise in color images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quaternion; Chromaticity; Convolution; Impulse; Laplacian; Vector median
ID REDUCTION
AB This paper presents a novel two-stage filtering algorithm for removing impulse noise in color images. Quaternion theory is used to represent the intensity and chromaticity differences of two color pixels. Use of quaternion treats color pixels as vectors and processes color images as single unit rather than as separated color components. This preserves the existing correlation and three dimensional vector natures of the color channels. In the first stage of noise detection, the color pixels are sorted and assigned a rank based on the aggregated sum of color pixel differences with other pixels inside the filtering window. The central pixel is considered as probably corrupted by an impulse if its rank is bigger than a predefined rank. In the second stage, the probably corrupted candidate is again checked for an edge or an impulse by using four Laplacian convolution kernels. If the minimum difference of these four convolution is larger than a predefined threshold, then the central pixel is regarded as an impulse. For filtering, we extend the size of the sliding window to cover more pixels information. The noisy pixel is replaced by output of weighted vector median filter implemented using the quaternion distance. More weight is assigned to those pixels belonging to the direction of minimum difference. Experimental results indicate the improved performance of the proposed filter in suppressing the impulse noise while retaining the original image details comparing against other well-known filters.
C1 [Chanu, P. Roji] NIT Nagaland, Dept Elect & Commun Engn, Nagaland, India.
   [Singh, Kh. Manglem] NIT Manipur, Dept Comp Sci & Engn, Imphal, Manipur, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Nagaland; National Institute of Technology (NIT System);
   National Institute of Technology Manipur
RP Chanu, PR (corresponding author), NIT Nagaland, Dept Elect & Commun Engn, Nagaland, India.
EM rojichanu@gmail.com; manglem@gmail.com
RI Singh, Khumanthem/AFZ-2177-2022
OI Singh, Khumanthem/0000-0002-6698-1185
CR ASTOLA J, 1990, P IEEE, V78, P678, DOI 10.1109/5.54807
   Bai T, 2017, IEEE ACCESS, V5, P23133, DOI 10.1109/ACCESS.2017.2766603
   Cai CH, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P816, DOI 10.1109/ICIP.2000.899834
   Celebi ME, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2772639
   Chanu R, 2016, INT J COMPUT SCI NET, V16, P66
   Chen P, 2017, IEEE T WIREL COMMUN, V16, P6165, DOI 10.1109/TWC.2017.2720580
   El Mehdi C, 2017, P 2017 INT SYST COMP
   Evans CJ, 2000, IEEE IMAGE PROC, P541, DOI 10.1109/ICIP.2000.901015
   Geng X, 2012, SIGNAL PROCESS, V92, P150, DOI 10.1016/j.sigpro.2011.06.015
   Jia YB, 2015, QUATERNIONS ROTATION, V477, P57
   Jian MW, 2018, MULTIMED TOOLS APPL, V77, P14343, DOI 10.1007/s11042-017-5032-z
   Jian MW, 2018, J VIS COMMUN IMAGE R, V53, P31, DOI 10.1016/j.jvcir.2018.03.008
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Jin L., 2010, ELECT IMAG, V19
   Jin LH, 2007, IEEE SIGNAL PROC LET, V14, P397, DOI 10.1109/LSP.2006.887840
   Karakos D. G., 1995, Proceedings. International Conference on Image Processing (Cat. No.95CB35819), P171, DOI 10.1109/ICIP.1995.529067
   Lazhar K, 1999, OPT ENG, V38
   Liu HQ, 2017, IEEE ACCESS, V5, P21193, DOI 10.1109/ACCESS.2017.2759142
   Lukac R., 2003, International Journal of Applied Mathematics and Computer Science, V13, P369
   Lukac R, 2004, MULTIDIM SYST SIGN P, V15, P169, DOI 10.1023/B:MULT.0000017024.66297.a0
   Lukac R, 2003, LECT NOTES COMPUT SC, V2652, P1117
   Lukac R, 2003, PATTERN RECOGN LETT, V24, P1889, DOI 10.1016/S0167-8655(03)00016-3
   Lukac R, 2006, J VIS COMMUN IMAGE R, V17, P1, DOI 10.1016/j.jvcir.2005.08.007
   Marium A, 2018, J ELECTRON IMAGING, V27, P123
   Palacios-Enriquez A, 2018, CIRC SYST SIGNAL PRO, V35, P1
   PERLMAN SS, 1987, IEEE T COMMUN, V35, P646, DOI 10.1109/TCOM.1987.1096834
   Plataniotis KN, 1996, SIGNAL PROCESS, V55, P93, DOI 10.1016/S0165-1684(96)00122-3
   Ruchay Alexey, 2017, P 6 INT C AN IM SOC, P280
   Sangwine SJ, 2000, IEE P-VIS IMAGE SIGN, V147, P89, DOI 10.1049/ip-vis:20000211
   Shi LL, 2007, COMPUT VIS IMAGE UND, V107, P88, DOI 10.1016/j.cviu.2006.11.014
   Smolka B, 2015, J REAL-TIME IMAGE PR, V10, P289, DOI 10.1007/s11554-012-0307-0
   Smolka B, 2010, PATTERN RECOGN LETT, V31, P484, DOI 10.1016/j.patrec.2009.09.012
   Subakan ON, 2011, INT J COMPUT VISION, V91, P233, DOI 10.1007/s11263-010-0388-9
   Syamala JP, 2014, ADV INTELLIGENT SYST, V249
   Trahanias PE, 1993, IEEE T IMAGE PROCESS, V2, P528, DOI 10.1109/83.242362
   Wang GH, 2014, SIGNAL PROCESS, V102, P216, DOI 10.1016/j.sigpro.2014.03.027
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yasushi A, 2018, P 6 IIAE INT C IND A
   Youngjin Y, 2007, P SPIE INT SOC OPT E
NR 39
TC 13
Z9 13
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 15375
EP 15401
DI 10.1007/s11042-018-6925-1
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700054
DA 2024-07-18
ER

PT J
AU Ghadi, M
   Laouamer, L
   Nana, L
   Pascu, A
AF Ghadi, Musab
   Laouamer, Lamri
   Nana, Laurent
   Pascu, Anca
TI A blind spatial domain-based image watermarking using texture analysis
   and association rules mining
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Texture analysis; Association rules mining;
   Authentication; Robustness
ID INTERBLOCK PREDICTION; ADDITIVE WATERMARKING; DCT; ROBUST; SCHEME
AB In aims to ensure images authentication, this paper proposes a blind spatial domain-based image watermarking using texture analysis and association rules mining. The idea is to identify the strongly textured locations in the host image for inserting the watermark. Indeed, texture is correlated with the Human Visual System (HVS). It can therefore be helpful in designing a watermarking approach to enhance the imperceptibility and the robustness. Here a solution is proposed in which four gray-scale histogram based-image features (DC, skewness, kurtosis, and entropy) are chosen as input data for designing association rules. Subsequently, the Apriori algorithm is applied to mine the relationships between the selected features. The higher significant relationships between the selected features are used to identify the strongly textured blocks for watermark embedding. Two strong parameters (lift and confidence) computed using association rules mining were used to design a means of blind watermarking. The experimental results show that interesting ratios of imperceptibility, robustness and embedding rate with low execution time can be obtained by this approach.
C1 [Ghadi, Musab; Laouamer, Lamri; Nana, Laurent; Pascu, Anca] Univ Bretagne Loire, CNRS, Univ Brest, Lab STICC, CS 93837,6 Ave Le Gorgeu, F-29238 Brest 3, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite de
   Bretagne Occidentale
RP Ghadi, M (corresponding author), Univ Bretagne Loire, CNRS, Univ Brest, Lab STICC, CS 93837,6 Ave Le Gorgeu, F-29238 Brest 3, France.
EM Mohammed-Alghadi.Musabqassem@univ-brest.fr; lamri_laouamer@yahoo.fr;
   Laurent.Nana@univ-brest.fr; Anca.Pascu@univ-brest.fr
OI Al-Ghadi, Musab/0000-0001-5076-2511
CR Abdelhakim AM, 2017, EXPERT SYST APPL, V72, P317, DOI 10.1016/j.eswa.2016.10.056
   Aggarwal C.C., 2014, FREQUENT PATTERN MIN, DOI DOI 10.1007/978-3-319-07821-2
   AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074
   [Anonymous], 1998, TEXTURE ANAL METHODS
   [Anonymous], SOFT COMPUT
   Ben-Messaoud R, 2006, IEEE C INN INF TECHN, P1
   Bouslimi D, 2012, IEEE T INF TECHNOL B, V16, P891, DOI 10.1109/TITB.2012.2207730
   Cox I. J., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P6, DOI 10.1109/ITCC.2000.844175
   Das A., 2015, Guide to signals and patterns in image processing: foundations, methods and applications
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Djenouri Y, 2017, INFORM SCIENCES, V420, P1, DOI 10.1016/j.ins.2017.08.043
   Dubey YK, 2016, BIOCYBERN BIOMED ENG, V36, P413, DOI 10.1016/j.bbe.2016.01.001
   Findik O, 2011, INT J INNOV COMPUT I, V7, P4905
   Ghadi M., 2017, IEEE INT WORKSH SIGN, P1
   Ghadi M, 2016, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON MANAGEMENT OF DIGITAL ECOSYSTEMS (MEDES 2016), P73, DOI 10.1145/3012071.3012101
   Ghadi M, 2016, SECUR COMMUN NETW, V9, P5203, DOI 10.1002/sec.1690
   Ghadi M, 2016, MULTIMED TOOLS APPL, V75, P3425, DOI 10.1007/s11042-014-2443-y
   Haddada LR, 2017, SIGNAL PROCESS-IMAGE, V55, P23, DOI 10.1016/j.image.2017.03.008
   Hahsler Michael, 2015, TECHNICAL REPORT
   Han JL, 2016, J AMB INTEL HUM COMP, V7, P37, DOI 10.1007/s12652-015-0298-3
   Hsu LY, 2017, J VIS COMMUN IMAGE R, V46, P33, DOI 10.1016/j.jvcir.2017.03.009
   Hsu LY, 2015, J VIS COMMUN IMAGE R, V32, P130, DOI 10.1016/j.jvcir.2015.07.017
   Hu HT, 2016, AEU-INT J ELECTRON C, V70, P172, DOI 10.1016/j.aeue.2015.11.003
   Jovanoski V., 2001, EPIA 01, P44
   Kalra GS, 2015, MULTIMED TOOLS APPL, V74, P6849, DOI 10.1007/s11042-014-1932-3
   Khalili M, 2015, OPTIK, V126, P4367, DOI 10.1016/j.ijleo.2015.08.042
   Korn F, 1998, P 24 VLDB C NEW YORK
   Kumar V., 2006, Introduction to Data Mining
   Kumara S, 2017, J COMPUT SCI-NETH, V19, P121, DOI 10.1016/j.jocs.2016.11.009
   Maggi FM, 2018, INFORM SYST, V74, P136, DOI 10.1016/j.is.2017.12.002
   Moosazadeh M, 2017, OPTIK, V140, P975, DOI 10.1016/j.ijleo.2017.05.011
   Nikolaidis A, 2003, IEEE T IMAGE PROCESS, V12, P563, DOI 10.1109/TIP.2003.810586
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Petitcolas FAP, 1998, LECT NOTES COMPUT SC, V1525, P218
   Sirkaya-Turk E, 2011, RES METHODS LEISURE
   Sudhir R., 2015, COMPUTER ENG INTELLI, V2, P44
   Taniar David, 2008, DATA MINING KNOWLEDG
   Thanki R, 2017, ENG SCI TECHNOL, V20, P1366, DOI 10.1016/j.jestch.2017.06.001
   Umbaugh S, 2011, J ELECTRON IMAGING, V20, P335
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P6229, DOI 10.1007/s11042-016-3311-8
   Wang YL, 2004, PATTERN RECOGN LETT, V25, P1681, DOI 10.1016/j.patrec.2004.06.012
   Wang Z, 2005, STRUCTURAL SIMILARIT
   Yamaç M, 2016, DIGIT SIGNAL PROCESS, V48, P188, DOI 10.1016/j.dsp.2015.09.017
   Yang HF, 2015, MULTIMED TOOLS APPL, V74, P1725, DOI 10.1007/s11042-013-1714-3
   Zaidan BB, 2017, SOFTWARE PRACT EXPER, V47, P1365, DOI 10.1002/spe.2465
   Zebbiche K, 2018, MULTIMED TOOLS APPL, V77, P21281, DOI 10.1007/s11042-017-5451-x
   Zhang Y., 2013, International Journal of Intelligence Science, V3, P1, DOI DOI 10.4236/IJIS.2013.32009
NR 47
TC 19
Z9 19
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 15705
EP 15750
DI 10.1007/s11042-018-6851-2
PG 46
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500001
DA 2024-07-18
ER

PT J
AU Liang, Y
   Li, K
   Zhang, J
   Wang, MH
   Lin, C
AF Liang, Yun
   Li, Ke
   Zhang, Jian
   Wang, Meihua
   Lin, Chen
TI Robust visual tracking via identifying multi-scale patches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-scale patches; Visual tracking; Kernelized correlation filters;
   Gaussian mixture model; Hough vote
ID OBJECT TRACKING
AB The complex changes of target and its surroundings introduce several tracking challenges, such as occlusion, deformation and so on. Many challenges coexist in a video which makes tracking still under successfully solved. The present trackers deal with coexisting challenges in a common model for all components of target. However, different components often undergo different challenges at the same time, while some with deformation and others with occlusion. The common model cannot adapt to these challenges simultaneously. An effective method is to separately deal with the challenges. This paper proposes a new robust tracker via separately tracking and identifying the multi-scale patches of target to cope with the coexisting challenges. It is achieved by three respects. Firstly, we define a new basic tracker by introducing the gaussian mixture model into Kernelized Correlation Filters (KCF). For the KCF is very sensitive to the similar surroundings, we construct a regular term and a loss function via the gaussian mixture model to optimize the classifier formed by KCF. Secondly, we define a new appearance representation model of target by multi-scale patches. To deal with the different variations of patches, we separately construct and update their appearance representations. Thirdly, with the tracked result of each patch computed by our basic tracker, we use the structure information and the Hough Vote to decide the target. Then, our method improves the accuracy by rejecting the failed tracked patches. Many experiments have been achieved on the Tracking Benchmark, and the quantitative and qualitative evaluations show that the proposed tracker performs better than most of the present trackers.
C1 [Liang, Yun; Wang, Meihua] South China Agr Univ, Coll Math & Informat, Guangzhou 510642, Guangdong, Peoples R China.
   [Li, Ke] Zhengzhou Sch Surveying & Mapping, Zhengzhou 450052, Henan, Peoples R China.
   [Zhang, Jian] Zhejiang Int Studies Univ, Sch Sci & Technol, Hangzhou 310012, Zhejiang, Peoples R China.
   [Lin, Chen] Xiamen Univ, Dept Comp Sci, Xiamen 361005, Fujian, Peoples R China.
C3 South China Agricultural University; Zhejiang International Studies
   University; Xiamen University
RP Liang, Y (corresponding author), South China Agr Univ, Coll Math & Informat, Guangzhou 510642, Guangdong, Peoples R China.
EM sdliangyun@163.com
RI Li, Ke/HZM-6170-2023; Lin, Chen/GRR-2799-2022
OI Li, Ke/0000-0002-7873-1554; 
FU National Natural Science Fund of China [61772209, 61472335]; Science and
   Technology Planning Project of Guangdong Province [2016A050502050,
   2014A050503057]; National Key R&D Program of China [2017YFB0503500];
   Zhejiang Provincial Natural Science Foundation of China [LY17F020009]
FX We are grateful to all the reviewers for their valuable suggestions. We
   also greatly appreciate Professor Meihua Wang for her useful discussion
   and many helps in improving the manuscript. This work was supported in
   part by the National Natural Science Fund of China (61772209, 61472335)
   and the Science and Technology Planning Project of Guangdong Province
   (2016A050502050, 2014A050503057), the National Key R&D Program of China
   (2017YFB0503500) and the Zhejiang Provincial Natural Science Foundation
   of China (LY17F020009).
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.465
   Bibi A, 2016, LECT NOTES COMPUT SC, V9910, P419, DOI 10.1007/978-3-319-46466-4_25
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chen DP, 2013, IEEE I CONF COMP VIS, P1113, DOI 10.1109/ICCV.2013.142
   Choi J, 2017, PROC CVPR IEEE, P4828, DOI 10.1109/CVPR.2017.513
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui Z, 2016, PROC CVPR IEEE, P1449, DOI 10.1109/CVPR.2016.161
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Fan H, 2017, IEEE COMPUT SOC CONF, P2217, DOI 10.1109/CVPRW.2017.275
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Godec M, 2013, COMPUT VIS IMAGE UND, V117, P1245, DOI 10.1016/j.cviu.2012.11.005
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   Hare S, 2012, PROC CVPR IEEE, P1894, DOI 10.1109/CVPR.2012.6247889
   He SF, 2013, PROC CVPR IEEE, P2427, DOI 10.1109/CVPR.2013.314
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hu ZP, 2017, MULTIMED TOOLS APPL, V76, P21265, DOI 10.1007/s11042-016-4068-9
   Huang Z., 2017, P IEEE C COMP VIS PA, P4021, DOI DOI 10.1109/CVPR.2017.510
   Jack V, 2017, P 30 IEEE C COMP VIS, P5000
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kwon J, 2013, IEEE T PATTERN ANAL, V35, P2427, DOI 10.1109/TPAMI.2013.32
   Li Y, 2015, PROC CVPR IEEE, P353, DOI 10.1109/CVPR.2015.7298632
   Liao XPL, 2017, MULTIMED TOOLS APPL, V76, P21073, DOI 10.1007/s11042-016-4001-2
   Liu S, 2016, PROC CVPR IEEE, P4312, DOI 10.1109/CVPR.2016.467
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Mohanapriya D, 2017, MULTIMED TOOLS APPL, V76, P25731, DOI 10.1007/s11042-017-4409-3
   Ning JF, 2016, PROC CVPR IEEE, P4266, DOI 10.1109/CVPR.2016.462
   Pan Z, 2017, MULTIMED TOOLS APPL, V76, P16989, DOI 10.1007/s11042-016-3647-0
   Quan W, 2017, MULTIMED TOOLS APPL, V76, P24299, DOI 10.1007/s11042-016-4147-y
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Wang FS, 2017, MULTIMED TOOLS APPL, V76, P13087, DOI 10.1007/s11042-016-3699-1
   Wang LJ, 2016, PROC CVPR IEEE, P1373, DOI 10.1109/CVPR.2016.153
   Wang ZP, 2017, MULTIMED TOOLS APPL, V76, P12181, DOI 10.1007/s11042-016-3289-2
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yang F, 2014, IEEE T IMAGE PROCESS, V23, P1639, DOI 10.1109/TIP.2014.2300823
   Yun S, 2017, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2017.148
   Zhang L, 2014, IEEE T PATTERN ANAL, V36, P756, DOI 10.1109/TPAMI.2013.221
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
NR 45
TC 3
Z9 3
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14195
EP 14230
DI 10.1007/s11042-018-6760-4
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700005
OA Bronze
DA 2024-07-18
ER

PT J
AU Sharma, M
   Jalal, AS
   Khan, A
AF Sharma, Mukta
   Jalal, Anand Singh
   Khan, Aamir
TI Emotion recognition using facial expression by fusing key points
   descriptor and texture features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion recognition; Facial expression; Human-computer-interaction
ID LOCAL BINARY PATTERNS; CLASSIFICATION; SEQUENCES; SCALE
AB Emotions have a great significance in human-to-human and in human-to-computer communication and interaction. In this paper, an effective and novel approach to recognize the emotions using facial expressions by the fusion of duplex features is proposed. The proposed approach broadly have three phases, phase-I: ROIs extraction, phase-2:Fusion of duplex features and phase-III: Classification. The proposed approach also gives a novel eye center detection algorithm to detect centres of the eyes. The outcome of the algorithm is further contribute to locate and partition the facial components. The hybrid combination of duplex features also gives the importance of fusion of features over individual features. The proposed approach classify the 5 basic emotions i.e. angry, happy, sad, disgust, surprise. The proposed method also raise the issue of high misclassification rate of emotions in higher age groups (>40) and successfully overcomes it. The proposed approach and its outcome evaluation is validated by using four datasets: the dataset created by us including 2500 images of 5 basic emotions (angry, happy, sad, disgust, surprise) having 500 images per emotions, CK+ dataset, MMI dataset and JAFEE dataset. Experimental results shows that the proposed work significantly improves the recognition rate (approx. 97%, 88%, 86%, 93%) and reduces the misclassification rate (approx.1.4%, 7.6%, 6.6%, 2.7%) even for the subjects of higher age group.
C1 [Sharma, Mukta; Jalal, Anand Singh; Khan, Aamir] GLA Univ, Dept Comp Engn & Applicat, Mathura, India.
C3 GLA University
RP Sharma, M (corresponding author), GLA Univ, Dept Comp Engn & Applicat, Mathura, India.
EM mukta.24sharma@gmail.com; anandsinghjalal@gmail.com
RI ; Khan, Mohd Aamir/L-1280-2018
OI Jalal, Anand/0000-0002-7469-6608; Khan, Mohd Aamir/0000-0003-2219-9084
CR Abdiansah A., 2015, INT J COMPUT APPL, V128, P28
   Agrawal DD, 2014, INT J COMPUT VISION, V44, P365, DOI 10.1504/IJCVR.2014.065571
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Akamatsu S, 1998, P 3 INT C AUT FAC GE, P14, DOI DOI 10.5281/ZENODO.3451524
   Alphonse AS, 2017, J VIS COMMUN IMAGE R, V49, P459, DOI 10.1016/j.jvcir.2017.10.008
   [Anonymous], 2017, MULTIMED TOOLS APPL
   [Anonymous], 2016, COMPUTER VISION PATT
   Bartlett M, 2003, CVPR WORKSH CVPR HCI
   Bartlett MS, 2005, PROC CVPR IEEE, P568
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Chen C, 2016, SIGNAL IMAGE VIDEO P, V10, P745, DOI 10.1007/s11760-015-0804-2
   Chen C, 2015, IEEE WINT CONF APPL, P1092, DOI 10.1109/WACV.2015.150
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   Drews P., 2011, Proceedings of the 2011 9th IEEE International Conference on Industrial Informatics (INDIN 2011), P305, DOI 10.1109/INDIN.2011.6034893
   Edwards G. J., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P581, DOI 10.1007/BFb0054766
   Ekman P., 1978, Facial action coding system
   Gbèhounou S, 2016, J VIS COMMUN IMAGE R, V38, P276, DOI 10.1016/j.jvcir.2016.03.009
   Gu WF, 2012, PATTERN RECOGN, V45, P80, DOI 10.1016/j.patcog.2011.05.006
   Guo X, 2018, J VIS COMMUN IMAGE R, V50, P65, DOI 10.1016/j.jvcir.2017.11.007
   Hadid A, 2004, P 2004 IEEE COMP VIS, DOI DOI 10.1109/CVPR.2004.1315246
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   Huang LH, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060483
   Jun-Da Txia, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P885, DOI 10.1109/IIH-MSP.2009.142
   Li W, 2015, IEEE T GEOSCI REMOTE, V53, P3681, DOI 10.1109/TGRS.2014.2381602
   Liang JZ, 2016, SIGNAL IMAGE VIDEO P, V10, P1441, DOI 10.1007/s11760-016-0950-1
   Liao S, 2006, IEEE IMAGE PROC, P665, DOI 10.1109/ICIP.2006.312418
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Moeini A, 2017, J VIS COMMUN IMAGE R, V45, P20, DOI 10.1016/j.jvcir.2017.02.007
   Mohammadi MR, 2014, J VIS COMMUN IMAGE R, V25, P1082, DOI 10.1016/j.jvcir.2014.03.006
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pantic M, 2006, IEEE T SYST MAN CY B, V36, P433, DOI 10.1109/TSMCB.2005.859075
   Sanchez-Mendoza D, 2015, PATTERN RECOGN LETT, V67, P66, DOI 10.1016/j.patrec.2015.06.007
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   VALSTAR M., 2005, COMPUTER VISION PATT, P76, DOI DOI 10.1109/CVPR.2005.457
   Valstar M., 2010, Proceedings of 3rd intern. workshop on EMOTION (satellite of LREC): Corpora for research on emotion and affect, P65
   Valstar M, 2006, IEEE C COMP VIS PATT
   Vapnik V., 1999, NATURE STAT LEARNING
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Xie XD, 2009, PATTERN RECOGN, V42, P1003, DOI 10.1016/j.patcog.2008.08.034
   Zhang W, 2015, PATTERN RECOGN, V48, P3191, DOI 10.1016/j.patcog.2015.04.012
NR 44
TC 18
Z9 19
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16195
EP 16219
DI 10.1007/s11042-018-7030-1
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500021
DA 2024-07-18
ER

PT J
AU Yuan, D
   Lu, XH
   Li, DH
   Liang, YY
   Zhang, XM
AF Yuan, Di
   Lu, Xiaohuan
   Li, Donghao
   Liang, Yingyi
   Zhang, Xinming
TI Particle filter re-detection for visual tracking via correlation filters
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Correlation filter; Particle filter redetection; Scale
   evaluation
ID OBJECT TRACKING; RECOGNITION
AB Most of the correlation filter based tracking algorithms can achieve good performance and maintain fast computational speed. However, in some complicated tracking scenes, there is a fatal defect that causes the object to be located inaccurately, which is the trackers excessively dependent on the maximum response value to determine the object location. In order to address this problem, we propose a particle filter redetection based tracking approach for accurate object localization. During the tracking process, the kernelized correlation filter (KCF) based tracker can locate the object by relying on the maximum response value of the response map; when the response map becomes ambiguous, the tracking result becomes unreliable correspondingly. Our redetection model can provide abundant object candidates by particle resampling strategy to detect the object accordingly. Additionally, for the target scale variation problem, we give a new object scale evaluation mechanism, which merely considers the differences between the maximum response values in consecutive frames to determine the scale change of the object target. Extensive experiments on OTB2013 and OTB2015 datasets demonstrate that the proposed tracker performs favorably in relation to the state-of-the-art methods.
C1 [Yuan, Di; Lu, Xiaohuan; Li, Donghao; Liang, Yingyi] Harbin Inst Technol Shenzhen, Sch Comp Sci & Technol, Shenzhen, Peoples R China.
   [Zhang, Xinming] Harbin Inst Technol Shenzhen, Sch Sci, Shenzhen, Peoples R China.
C3 Harbin Institute of Technology; Harbin Institute of Technology
RP Yuan, D; Liang, YY (corresponding author), Harbin Inst Technol Shenzhen, Sch Comp Sci & Technol, Shenzhen, Peoples R China.; Zhang, XM (corresponding author), Harbin Inst Technol Shenzhen, Sch Sci, Shenzhen, Peoples R China.
EM dyuanhit@gmail.com; luxiaohuanok@126.com; lidh@hit.edu.cn;
   liangyingyi002@foxmail.com; xinmingxueshu@hit.edu.cn
RI Liang, Yingyi/AAB-7976-2020; Yuan, Di/Q-6521-2019
OI Liang, Yingyi/0000-0001-8196-2348; Yuan, Di/0000-0001-9403-1112
FU National Natural Science Foundation of China [61672183]; Shenzhen
   Research Council [JCYJ20170413104556946, JCYJ20170815113552036,
   JCYJ20160226201453085]; Science and Technology Planning Project of
   Guanddong Province [2016B090918047]; Shenzhen Medical Biometrics
   Perception and Analysis Engineering Laboratory
FX This study was supported by by the National Natural Science Foundation
   of China (Grant No. 61672183), the Shenzhen Research Council (Grant No.
   JCYJ20170413104556946, JCYJ20170815113552036, JCYJ20160226201453085), by
   Science and Technology Planning Project of Guanddong Province (Grant No.
   2016B090918047), and by Shenzhen Medical Biometrics Perception and
   Analysis Engineering Laboratory.
CR [Anonymous], INT C MACH LEARN CHA
   [Anonymous], IEEE T CIRC SYST VID
   [Anonymous], INT C UB ROB AMB INT
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Cehovin L, 2014, IEEE WINT CONF APPL, P540, DOI 10.1109/WACV.2014.6836055
   Chen WS, 2006, INT J PATTERN RECOGN, V20, P189, DOI 10.1142/S0218001406004600
   Chen ZJ, 2017, IEEE T CYBERNETICS, V47, P3706, DOI 10.1109/TCYB.2016.2577718
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Danelljan Martin, 2014, P BRIT MACH VIS C 20
   Fazli S, 2009, 2009 SECOND INTERNATIONAL CONFERENCE ON MACHINE VISION, PROCEEDINGS, ( ICMV 2009), P89, DOI 10.1109/ICMV.2009.47
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Gao J, 2014, LECT NOTES COMPUT SC, V8691, P188, DOI 10.1007/978-3-319-10578-9_13
   Ge Q, 2017, IEEE T IMAGE PROCESS, V26, P3098, DOI 10.1109/TIP.2016.2639781
   Guo ZH, 2016, IEEE T IMAGE PROCESS, V25, P687, DOI 10.1109/TIP.2015.2507408
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   He ZY, 2008, NEUROCOMPUTING, V71, P1832, DOI 10.1016/j.neucom.2007.10.017
   He ZY, 2017, IEEE T CYBERNETICS, V47, P354, DOI 10.1109/TCYB.2016.2514714
   He ZY, 2016, IEEE T IMAGE PROCESS, V25, P3698, DOI 10.1109/TIP.2016.2570553
   He ZY, 2015, KNOWL-BASED SYST, V86, P21, DOI 10.1016/j.knosys.2015.04.018
   He ZY, 2010, INTEGR COMPUT-AID E, V17, P157, DOI 10.3233/ICA-2010-0338
   He ZY, 2010, INT J COMPUT VISION, V87, P235, DOI 10.1007/s11263-009-0256-7
   He ZY, 2009, SIGNAL PROCESS, V89, P1501, DOI 10.1016/j.sigpro.2009.01.021
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hong S, 2015, PR MACH LEARN RES, V37, P597
   Isard M, 1998, CONDENSATION CONDITI, P5
   Jing XY, 2016, PATTERN RECOGN, V59, P14, DOI 10.1016/j.patcog.2016.01.023
   Jing XY, 2015, PROC CVPR IEEE, P695, DOI 10.1109/CVPR.2015.7298669
   Lai ZH, 2016, IEEE T NEUR NET LEAR, V27, P723, DOI 10.1109/TNNLS.2015.2422994
   Lai ZH, 2014, IEEE T NEUR NET LEAR, V25, P1942, DOI 10.1109/TNNLS.2013.2297381
   Li X, 2016, KNOWL-BASED SYST, V113, P88, DOI 10.1016/j.knosys.2016.09.014
   Li X, 2014, KNOWL-BASED SYST, V71, P409, DOI 10.1016/j.knosys.2014.08.019
   Li XH, 2017, IEEE CONF COMPUT, P462, DOI 10.1109/INFCOMW.2017.8116420
   Li Y, 2015, PROC CVPR IEEE, P353, DOI 10.1109/CVPR.2015.7298632
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liu Q, 2017, KNOWL-BASED SYST, V134, P189, DOI 10.1016/j.knosys.2017.07.032
   Liu S, 2016, PROC CVPR IEEE, P4312, DOI 10.1109/CVPR.2016.467
   Liu T, 2015, PROC CVPR IEEE, P4902, DOI 10.1109/CVPR.2015.7299124
   Ma X, 2016, KNOWL-BASED SYST, V106, P26, DOI 10.1016/j.knosys.2016.05.028
   Mai T.N.T., 2016, INT C COMP SCI ITS A, P246
   Mozhdehi RJ, 2017, IEEE IMAGE PROC, P3650, DOI 10.1109/ICIP.2017.8296963
   Ou WH, 2018, MULTIMED TOOLS APPL, V77, P10569, DOI 10.1007/s11042-017-4672-3
   Ou WH, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.3.033006
   Ou WH, 2016, NEUROCOMPUTING, V204, P116, DOI 10.1016/j.neucom.2015.09.133
   Ou WH, 2014, PATTERN RECOGN, V47, P1559, DOI 10.1016/j.patcog.2013.10.017
   Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466
   Qian JY, 2011, IEEE SENS J, V11, P2301, DOI 10.1109/JSEN.2011.2121058
   Shi XS, 2016, IEEE T PATTERN ANAL, V38, P2130, DOI 10.1109/TPAMI.2015.2501810
   Valmadre J., 2017, P IEEE C COMP VIS PA, P2805
   Van Trees Harry L., 2007, A Tutorial on Particle Filters for Online Nonlinear/NonGaussian Bayesian Tracking, P723, DOI [10.1109/9780470544198.ch73, DOI 10.1109/9780470544198.CH73]
   Wu F, 2016, PATTERN RECOGN, V50, P143, DOI 10.1016/j.patcog.2015.08.012
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yi SY, 2017, PATTERN RECOGN, V61, P524, DOI 10.1016/j.patcog.2016.08.025
   Yi SY, 2015, SIGNAL PROCESS, V110, P178, DOI 10.1016/j.sigpro.2014.09.020
   Yong Yu, 2010, 2010 Proceedings of 3rd International Congress on Image and Signal Processing (CISP 2010), P1508, DOI 10.1109/CISP.2010.5647068
   You XH, 2015, SIGNAL PROCESS, V111, P308, DOI 10.1016/j.sigpro.2014.09.019
   Zhang KH, 2016, IEEE T IMAGE PROCESS, V25, P1779, DOI 10.1109/TIP.2016.2531283
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zhang SP, 2017, IEEE T CIRC SYST VID, V27, P421, DOI 10.1109/TCSVT.2016.2539860
   Zhang SP, 2015, IEEE T CIRC SYST VID, V25, P1749, DOI 10.1109/TCSVT.2015.2406194
   Zhang TZ, 2017, PROC CVPR IEEE, P4819, DOI [10.1109/CVPR.2017.512, 10.1109/ICCV.2017.469]
   Zhang TZ, 2016, PROC CVPR IEEE, P3880, DOI 10.1109/CVPR.2016.421
   Zhao YR, 2018, PROCEEDINGS OF THE 2018 2ND INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND COMMUNICATION ENGINEERING (ICTCE 2018), P154, DOI [10.1145/3291842.3291895, 10.1016/j.patcog.2018.01.012]
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zhou H, 2016, IET INT RAD C, P31
   Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152
NR 69
TC 46
Z9 47
U1 1
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14277
EP 14301
DI 10.1007/s11042-018-6800-0
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Mei, SH
   Min, WQ
   Duan, H
   Jiang, SQ
AF Mei, Shuhuan
   Min, Weiqing
   Duan, Hua
   Jiang, Shuqiang
TI Instance-level object retrieval via deep region CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Faster R-CNN; Deep learning; Instance-level object retrieval; Instre
ID IMAGE; VOCABULARY; FEATURES; SEARCH
AB Instance retrieval is a fundamental problem in the multimedia field for its various applications. Since the relevancy is defined at the instance level, it is more challenging comparing to traditional image retrieval methods. Recent advances show that Convolutional Neural Networks (CNNs) offer an attractive method for image feature representations. However, the CNN method extracts features from the whole image, thus the extracted features contain a large amount of background noisy information, leading to poor retrieval performance. To solve the problem, this paper proposed a deep region CNN method with object detection for instance-level object retrieval, which has two phases, i.e., offline Faster R-CNN training and online instance retrieval. First, we train a Faster R-CNN model to better locate the region of the objects. Second, we extract the CNN features from the detected object image region and then retrieve relevant images based on the visual similarity of these features. Furthermore, we utilized three different strategies for feature fusing based on the detected object region candidates from Faster R-CNN. We conduct the experiment on a large dataset: INSTRE with 23,070 object images and additional one million distractor images. Qualitative and quantitative evaluation results have demonstrated the advantage of our proposed method. In addition, we conducted extensive experiments on the Oxford dataset and the experimental results further validated the effectiveness of our proposed method.
C1 [Mei, Shuhuan; Duan, Hua] Shandong Univ Sci & Technol, Coll Math & Syst Sci, Qingdao 266590, Shandong, Peoples R China.
   [Mei, Shuhuan; Min, Weiqing; Jiang, Shuqiang] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
   [Jiang, Shuqiang] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
C3 Shandong University of Science & Technology; Chinese Academy of
   Sciences; Institute of Computing Technology, CAS; Chinese Academy of
   Sciences; University of Chinese Academy of Sciences, CAS
RP Duan, H (corresponding author), Shandong Univ Sci & Technol, Coll Math & Syst Sci, Qingdao 266590, Shandong, Peoples R China.
EM shuhuan.mei@vipl.ict.ac.cn; weiqing.mei@vipl.ict.ac.cn;
   huaduan59@163.com; sqjiang@ict.ac.cn
FU National Natural Science Foundation of China [61532018, 61322212,
   61602437, 61672497, 61472229, 61202152]; Beijing Municipal Commission of
   Science and Technology [D161100001816001]; Beijing Natural Science
   Foundation [4174106]; Lenovo Outstanding Young Scientists Program;
   National Program for Special Support of Eminent Professionals; National
   Program for Support of Top-notch Young Professionals; China Postdoctoral
   Science Foundation [2016M590135, 2017T100110]; Science and Technology
   Development Fund of Shandong Province of China [2016ZDJS02A11,
   ZR2017MF027]; Taishan Scholar Climbing Program of Shandong Province;
   SDUST Research Fund [2015TDJH102]
FX This work was supported in part by the National Natural Science
   Foundation of China (61532018,61322212, 61602437, 61672497, 61472229 and
   61202152), in part by the Beijing Municipal Commission of Science and
   Technology (D161100001816001), in part by Beijing Natural Science
   Foundation (4174106), in part by the Lenovo Outstanding Young Scientists
   Program, in part by National Program for Special Support of Eminent
   Professionals and National Program for Support of Top-notch Young
   Professionals, and in part by China Postdoctoral Science Foundation
   (2016M590135, 2017T100110). This work was also supported in part by
   Science and Technology Development Fund of Shandong Province of China
   (2016ZDJS02A11 and ZR2017MF027), the Taishan Scholar Climbing Program of
   Shandong Province, and SDUST Research Fund (2015TDJH102).
CR [Anonymous], 2016, INT C LEARNING REPRE
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], IEEE T MULTIMEDIA
   [Anonymous], 2017, IEEE C COMP VIS PATT
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], PROC CVPR IEEE
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2014, ITE Trans.Media Technol. Appl.
   [Anonymous], 2014, P 31 INT C INT C MAC
   [Anonymous], 2016, P IEEE CVF INT C COM
   Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207
   Babenko A, 2015, IEEE I CONF COMP VIS, P1269, DOI 10.1109/ICCV.2015.150
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Chandrasekhar V, 2015, IEEE DATA COMPR CONF, P333, DOI 10.1109/DCC.2015.54
   Chen DM, 2015, IEEE T MULTIMEDIA, V17, P1019, DOI 10.1109/TMM.2015.2427744
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Duan LY, 2015, IEEE T MULTIMEDIA, V17, P828, DOI 10.1109/TMM.2015.2419973
   Duan LY, 2014, IEEE T MULTIMEDIA, V16, P346, DOI 10.1109/TMM.2013.2293063
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hong RC, 2017, IEEE T IMAGE PROCESS, V26, P4128, DOI 10.1109/TIP.2017.2710635
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2014, PROC CVPR IEEE, P3310, DOI 10.1109/CVPR.2014.417
   Ji RR, 2013, IEEE T MULTIMEDIA, V15, P153, DOI 10.1109/TMM.2012.2225035
   Jiang YG, 2013, IEEE T MULTIMEDIA, V15, P442, DOI 10.1109/TMM.2012.2231061
   Kalantidis Yannis, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P685, DOI 10.1007/978-3-319-46604-0_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Panda J, 2013, IEEE I CONF COMP VIS, P1257, DOI 10.1109/ICCV.2013.159
   Radenovic F, 2016, LECT NOTES COMPUT SC, V9905, P3, DOI 10.1007/978-3-319-46448-0_1
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sang JT, 2012, IEEE T MULTIMEDIA, V14, P883, DOI 10.1109/TMM.2012.2188782
   Simonyan K., 2014, 14091556 ARXIV
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Hoang T, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1600, DOI 10.1145/3123266.3123417
   Wang S, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2700292
   Xie Y, 2013, NEUROCOMPUTING, V119, P478, DOI 10.1016/j.neucom.2013.03.004
   Zhou W., 2010, P 18 ACM INT C MULTI, P511
   Zhou WG, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2422956.2422960
NR 43
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13247
EP 13261
DI 10.1007/s11042-018-6427-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900028
DA 2024-07-18
ER

PT J
AU Abughalieh, KM
   Sababha, BH
   Rawashdeh, NA
AF Abughalieh, Karam M.
   Sababha, Belal H.
   Rawashdeh, Nathir A.
TI A video-based object detection and tracking system for weight sensitive
   UAVs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Object tracking; Tracking algorithms; Aerial video
   processing; Keypoint detector; Background subtraction; UAV; OpenCV
AB The capability of detecting and tracking targets can play a significant role in mobile robot navigation systems. Visual tracking systems may control the direction and speed of motion of a robot to keep the target in its field of view either by moving the robot itself or the vision sensors. In this work, a compact size tracking and guiding system that could be mounted on weight-sensitive UAV platforms is presented. The system combines a motion detection technique that could be used with non-static cameras in addition to color filtering to detect and track objects in the field of view of a UAV. This hybrid system provides a reliable tracking system for low resolution images taken by a UAV camera. The proposed system implements keypoint detection algorithms including SIFT, SURF and FAST, a motion detection method using frame subtraction and object detection algorithms using color back projection in a hybrid approach that utilizes the best of each algorithm and avoids heavy usage of computing resources. Keypoint detectors SURF, SIFT and FAST are tested and implemented for the purpose of image alignment and frame subtractions. Experimental tests showed the system's ability to detect and track low detailed targets. The system is tested on a UAV using a Raspberry Pi 2 mini-computer running OpenCV libraries and was able to process eleven frames per second implementing object detection and tracking. The test objects were mainly cars monitored from different altitudes through a UAV downward pointing camera.
C1 [Abughalieh, Karam M.; Sababha, Belal H.] Princess Sumaya Univ Technol, Comp Engn Dept, Amman 11941, Jordan.
   [Rawashdeh, Nathir A.] German Jordanian Univ, Dept Mechatron Engn, Amman 11180, Jordan.
C3 Princess Sumaya University for Technology; German-Jordanian University
RP Sababha, BH (corresponding author), Princess Sumaya Univ Technol, Comp Engn Dept, Amman 11941, Jordan.
EM k.ghalieh@psut.edu.jo; bsababha@ieee.org; nathir.rawashdeh@gju.edu.jo
RI Rawashdeh, Nathir A/GRF-1037-2022; Sababha, Belal/GRX-3582-2022;
   Rawashdeh, Nathir/ABG-7012-2020
OI Rawashdeh, Nathir A/0000-0002-9118-9317; Sababha,
   Belal/0000-0001-8586-2352; Rawashdeh, Nathir/0000-0002-9118-9317
FU King Abdullah I School of Graduate Studies and Scientific Research at
   Princess Sumaya University for Technology (PSUT)
FX This work was funded by King Abdullah I School of Graduate Studies and
   Scientific Research at Princess Sumaya University for Technology (PSUT).
CR 3D Robotics, 3 SUPPORT IRIS PORTA
   Abughalieh K, 2014, INF COMM SYST ICICS
   Ali S, 2006, DEF SEC S INT SOC OP
   [Anonymous], 2011, INT J SMART HOME
   [Anonymous], 2011, Video Tracking: Theory and Practice
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Boudjit K, 2015, 2015 12 INT C
   Bradski GR, 1998, INTEL TECHNOL J
   Chen P, 2018, IEEE T INTELL TRANSP, V19, P131, DOI 10.1109/TITS.2017.2750091
   CHI Z, 2015, TIP, V26, P2005, DOI DOI 10.1109/TIP.2017.2669880
   Cokun M, 2015, 9 INT C INT ENG INTE
   Collins R., 2005, PROC IEEE INT WORKSH, V2, P35
   Fabian J, 2014, IEEE-ASME T MECH, V19, P249, DOI 10.1109/TMECH.2012.2228010
   Gil A, 2010, MACH VISION APPL, V21, P905, DOI 10.1007/s00138-009-0195-x
   Kalantar B, 2017, IEEE T GEOSCI REMOTE, V55, P5198, DOI 10.1109/TGRS.2017.2703621
   Kim BG, 2006, IMAGE VISION COMPUT, V24, P1319, DOI 10.1016/j.imavis.2006.04.008
   Lang H, 2010, 8 IEEE INT C CONTRL
   Li ZR, 2010, MACH VISION APPL, V21, P677, DOI 10.1007/s00138-009-0206-y
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luis M, 2006, ROB AUT 2006 ICRA 20
   Martínez C, 2014, MACH VISION APPL, V25, P1283, DOI 10.1007/s00138-014-0617-2
   Minaeian S, 2018, IEEE T INTELL TRANSP, V19, P497, DOI 10.1109/TITS.2017.2782790
   R. P. FOUNDATION, RASPBERRY PI 2 MODEL
   Rawashdeh NA, 2017, J VIB CONTROL, V23, P827, DOI 10.1177/1077546315586492
   Richards B, 2014, IEEE SENS J
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Saripalli S, 2003, IEEE T ROBOTIC AUTOM, V19, P371, DOI 10.1109/TRA.2003.810239
   Sirmaçek B, 2009, IEEE T GEOSCI REMOTE, V47, P1156, DOI 10.1109/TGRS.2008.2008440
   Snavely N, 2008, CVPR, V1
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   The Robotics Institute School of Computer Science Carnegie Mellon University, VIVID TRACK EV WEB S
   Thumser P, 2017, EARTH SURF PROC LAND, V42, P2439, DOI 10.1002/esp.4199
   Valasek J, 2016, J AEROSP INFORM SYST, V13, P10, DOI 10.2514/1.I010198
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang S, 2005, AC SPEECH SIGN PROC
   Zhang S, 2015, IEEE SENS J, V15, P2679, DOI 10.1109/JSEN.2014.2382174
NR 36
TC 18
Z9 19
U1 3
U2 54
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 9149
EP 9167
DI 10.1007/s11042-018-6508-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800068
DA 2024-07-18
ER

PT J
AU Liu, XJ
   Lu, W
   Huang, T
   Liu, HM
   Xue, YJ
   Yeung, YL
AF Liu, Xianjin
   Lu, Wei
   Huang, Tao
   Liu, Hongmei
   Xue, Yingjie
   Yeung, Yuileong
TI Scaling factor estimation on JPEG compressed images by cyclostationarity
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensics; Image resampling detection; Scaling factor estimation
ID EXPOSING DIGITAL FORGERIES; AUTHENTICATION; FORENSICS; STEP
AB Scaling factor estimation is one of the most important topics in image forensics. The existing methods mainly employ the peak of the Fourier spectrum of the variance on image difference to detect the scaling factor. However, when the image is compressed, there will be additional stronger peaks which greatly affect the detection ability. In this paper, a novel method to estimate the scaling factor on JPEG compressed images in the presence of image scaling before the compression is proposed. We find the squared image difference can more effectively obtain the resampling characteristics, and we will mathematically show its periodicity. To further improve the detection ability, we analyze the flat block. It also produces periodic peaks in the spectrum, meanwhile which are enhanced by JPEG compression. To solve this problem, a method based on interpolation on the flat block is developed to remove these influences. The experimental results demonstrate that the proposed detection method outperforms some state-of-the-art methods.
C1 [Liu, Xianjin; Lu, Wei; Huang, Tao; Liu, Hongmei; Xue, Yingjie; Yeung, Yuileong] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangdong Key Lab Informat Secur Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Lu, Wei] Chinese Acad Sci, State Key Lab Informat Secur, Inst Informat Engn, Beijing 100093, Peoples R China.
C3 Sun Yat Sen University; Chinese Academy of Sciences; Institute of
   Information Engineering, CAS
RP Lu, W (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangdong Key Lab Informat Secur Technol, Guangzhou 510006, Guangdong, Peoples R China.; Lu, W (corresponding author), Chinese Acad Sci, State Key Lab Informat Secur, Inst Informat Engn, Beijing 100093, Peoples R China.
EM liuxj48@mail2.sysu.edu.cn; luwei3@mail.sysu.edu.cn
RI Wang, Guang/JFS-8374-2023; Huang, Tao/ITU-9131-2023
OI Lu, Wei/0000-0002-4068-1766
FU National Natural Science Foundation of China [U1736118]; National Key
   R&D Program of China [2017YFB0802500]; Natural Science Foundation of
   Guangdong [2016A030313350]; Special Funds for Science and Technology
   Development of Guangdong [2016KZ010103]; Key Project of Scientific
   Research Plan of Guangzhou [201804020068]; Fundamental Research Funds
   for the Central Universities [16lgjc83, 17lgjc45]
FX This work is supported by the National Natural Science Foundation of
   China (No. U1736118), the National Key R&D Program of China (No.
   2017YFB0802500), the Natural Science Foundation of Guangdong (No.
   2016A030313350), the Special Funds for Science and Technology
   Development of Guangdong (No. 2016KZ010103), the Key Project of
   Scientific Research Plan of Guangzhou (No. 201804020068), the
   Fundamental Research Funds for the Central Universities (No. 16lgjc83
   and No. 17lgjc45).
CR [Anonymous], 2016, MULTIMEDIA TOOLS APP
   Battiato S, 2012, IEEE T INF FOREN SEC, V7, P1105, DOI 10.1109/TIFS.2012.2194285
   Bianchi T, 2012, IEEE INT WORKS INFOR, P127, DOI 10.1109/WIFS.2012.6412637
   Birajdar GH, 2014, AEUE INT J ELECT COM, V68
   Chen CL, 2017, IEEE T IMAGE PROCESS, V26, P2811, DOI 10.1109/TIP.2017.2682963
   Chen CL, 2014, IEEE SIGNAL PROC LET, V21, P890, DOI 10.1109/LSP.2014.2320503
   Chen J, 2018, BINARY IMAGE STEGANA
   Chen LK, 2013, J VIS COMMUN IMAGE R, V24, P244, DOI 10.1016/j.jvcir.2013.01.008
   Chen LK, 2012, INT J DIGIT CRIME FO, V4, P49, DOI 10.4018/jdcf.2012010104
   Dalgaard N, 2010, IEEE IMAGE PROC, P1753, DOI 10.1109/ICIP.2010.5652358
   David V., 2011, Workshop on Information Forensics and Security, P1
   Feng B, 2015, ROBUST IMAGE WATERMA, V41
   Feng XY, 2012, IEEE T MULTIMEDIA, V14, P536, DOI 10.1109/TMM.2012.2191946
   Gallagher AC, 2005, 2nd Canadian Conference on Computer and Robot Vision, Proceedings, P65, DOI 10.1109/CRV.2005.33
   Gloe T., 2010, ACM S APPL COMP, P1584, DOI DOI 10.1080/15567281.2010.531500
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   Johnson M.K., 2005, Proceedings of the 7th Workshop on Multimedia and Security, P1
   Kao YT, 2012, IEEE T IMAGE PROCESS, V21, P3443, DOI 10.1109/TIP.2012.2191562
   Kirchner M, 2010, MM&SEC 2010: 2010 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, PROCEEDINGS, P13
   Kirchner M, 2009, IEEE INT WORKS INFOR, P21, DOI 10.1109/WIFS.2009.5386489
   Kirchner M, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P11, DOI 10.1145/1411328.1411333
   Li LJ, 2013, ADV MATER RES-SWITZ, V797, P569, DOI 10.4028/www.scientific.net/AMR.797.569
   Lin ZX, 2017, SIGNAL PROCESS-IMAGE, V57, P134, DOI 10.1016/j.image.2017.05.012
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Ma Y, 2019, IEEE T CONTR SYST T, V27, P1788, DOI 10.1109/TCST.2018.2819965
   Mahdian B, 2008, IEEE T INF FOREN SEC, V3, P529, DOI 10.1109/TIFS.2004.924603
   Nataraj L, 2009, IEEE IMAGE PROC, P1493, DOI 10.1109/ICIP.2009.5414609
   Nguyen HC, 2013, LECT NOTES COMPUT SC, V8099, P113
   Panchal UH, 2015, INT CONF COMM SYST, P591, DOI 10.1109/CSNT.2015.165
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P3948, DOI 10.1109/TSP.2005.855406
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Qian RH, 2012, IEEE INT CONF MULTI, P61, DOI 10.1109/ICMEW.2012.18
   SATHE VP, 1993, IEEE T SIGNAL PROCES, V41, P131, DOI 10.1109/TSP.1993.193133
   Stamm MC, 2013, IEEE ACCESS, V1, P167, DOI 10.1109/ACCESS.2013.2260814
   Vyas C, 2014, IEEE I C COMP INT CO, P1191
   Wei WM, 2010, IEEE T INF FOREN SEC, V5, P507, DOI 10.1109/TIFS.2010.2051254
   Wolberg G, 1994, Digital image warping
   Xue F, 2017, SIGNAL PROCESS-IMAGE, V57, P76, DOI 10.1016/j.image.2017.05.008
   Yang F, 2017, ENG APPL ARTIF INTEL, V59, P73, DOI 10.1016/j.engappai.2016.12.022
   Zhang F, 2018, MULTIMEDIA TOOLS APP
   Zhang Q, 2018, MULTIMEDIA TOOLS APP
   Zhang QB, 2016, J VIS COMMUN IMAGE R, V40, P449, DOI 10.1016/j.jvcir.2016.07.013
   Zhang Y, 2018, SIGNAL PROCESSING
   Zhu N, 2016, NEUROCOMPUTING, V204, P33, DOI 10.1016/j.neucom.2015.06.113
   2010, INTERNATIONAL CONFER, P1745
   2015, EUR SIGN PROC C, P2067
   2012, INTERNATIONAL WORKSH, P205
   2017, IEEE T INF FOREN SEC, V12, P2115, DOI DOI 10.1109/TIFS.2017.2699638
NR 48
TC 6
Z9 7
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 7947
EP 7964
DI 10.1007/s11042-018-6411-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HY5JK
UT WOS:000468163900001
DA 2024-07-18
ER

PT J
AU Premkumar, R
   Anand, S
AF Premkumar, R.
   Anand, S.
TI Secured and compound 3-D chaos image encryption using hybrid mutation
   and crossover operator
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Genetic algorithm; Crossover; Mutation; Image encryption; 3-D chaotic
   map
ID DNA-SEQUENCE OPERATION; ALGORITHM; PERMUTATION
AB History, for us, today is data. Events and emotions of the worn centuries have been recorded as data- extremely vulnerable data, which can be easily tampered with. With this being said, it becomes vital for a proper encryption algorithm to assist passage of secure data thorough the web. This paper exclusively concentrates on gray scale images and their subsequent protection by the proposition of a synchronous transformation and substitution system. A Secure and compound 3-D Chaos based image encryption (SCIE) based hybrid methodology based on genetic algorithm has been discussed thoroughly. Here permutation is attained by using arithmetic crossover, multipoint crossovers operator and substitution by combined mutation operators. In this technique 3-D Compound Sine and ICMIC (CSI) map is used to generate key stream. Encryption is done by using hybrid operators with secret key. Unified Average Change Intensity (UACI), correlation coefficient, histogram, Net Pixel Change Rate (NPCR) and entropy were some of the measures which were taken into account to analyse the performance of the recommended algorithm. Upon experimentation of the same, appreciable protection of real- time images has been achieved.
C1 [Premkumar, R.] Mt Zion Coll Engn & Technol, Dept Elect & Commun Engn, Pudukkottai, Tamil Nadu, India.
   [Anand, S.] Mepco Coll Engn, Dept Elect & Commun Engn, Sivakasi, Tamil Nadu, India.
C3 Mepco Schlenk Engineering College
RP Premkumar, R (corresponding author), Mt Zion Coll Engn & Technol, Dept Elect & Commun Engn, Pudukkottai, Tamil Nadu, India.
EM premvlsi@gmail.com; sanand@mepcoeng.ac.in
RI S, Anand/S-7812-2019; R, Dr Premkumar/AAM-8667-2020
OI S, Anand/0000-0002-0307-1942; R, Dr Premkumar/0000-0002-8489-283X
CR Congyang Chen, 2015, Algorithms and Architectures for Parallel Processing. 15th International Conference, ICA3PP 2015. Proceedings: LNCS 9528, P578, DOI 10.1007/978-3-319-27119-4_40
   DAS S, 2015, COMPUTER, V10, P729, DOI DOI 10.1007/978-3-319-11933-5_82
   Dworak K, 2016, STUD COMPUT INTELL, V642, P3, DOI 10.1007/978-3-319-31277-4_1
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   Enayatifar Rasul, 2012, INT J ELECT COMMUNIC, V10, P807
   Fister I, 2016, APPL MATH COMPUT, V283, P181, DOI 10.1016/j.amc.2016.02.034
   Guesmi R, 2016, MULTIMED TOOLS APPL, V75, P4753, DOI 10.1007/s11042-015-2501-0
   Hu Ting, 2017, CHAOTIC IMAGE CRYPTO, V10, P234
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Jalesh K, 2015, SECURING CONTENT DOC, V978, P1091, DOI [10.1109/ICACCI.2015.7275755, DOI 10.1109/ICACCI.2015.7275755]
   Kumar J, 2016, J INF SECUR APPL, V30, P105, DOI 10.1016/j.jisa.2016.08.004
   Li CQ, 2016, SIGNAL PROCESS, V118, P203, DOI 10.1016/j.sigpro.2015.07.008
   Pareek NK, 2016, SOFT COMPUT, V20, P763, DOI 10.1007/s00500-014-1539-7
   Premkumar R, 2016, J MED IMAG HEALTH IN, V6, P2012, DOI 10.1166/jmihi.2016.1966
   Ravichandran Dhivya, 2015, COMPUT BIOL MED, V10, P1
   Saranya MR, 2015, ALGORITHM ENHANCED I, V978, P1, DOI [10.1109/SPICES.2015.7091462, 10.1109/ SPICES.2015.7091462, DOI 10.1109/SPICES.2015.7091462]
   Tang Zhenjun, 2015, OPT LASER ENG, V10, P1
   Wang Bin, 2016, OPTIK, V10, P1, DOI DOI 10.1016/J.IJLE0.2016.01.015
   Wang GG, 2016, MULTIMED TOOLS APPL, P1, DOI DOI 10.1504/01C.2016.10002274
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2016, NONLINEAR DYNAM, V83, P333, DOI 10.1007/s11071-015-2330-8
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Xu L, 2015, OPT LASER ENG, V10, P17
   Yadav AK, 2016, MULTIMED TOOLS APPL, V75, P9371, DOI 10.1007/s11042-016-3381-7
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang XP, 2014, SIGNAL PROCESS-IMAGE, V29, P902, DOI 10.1016/j.image.2014.06.012
   Zhang YS, 2014, OPTIK, V125, P1562, DOI 10.1016/j.ijleo.2013.09.018
   Zhao XC, 2016, EXPERT SYST APPL, V64, P11, DOI 10.1016/j.eswa.2016.07.023
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 30
TC 26
Z9 26
U1 2
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 9577
EP 9593
DI 10.1007/s11042-018-6534-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400004
DA 2024-07-18
ER

PT J
AU Shivani, S
   Tiwari, S
AF Shivani, Shivendra
   Tiwari, Shailendra
TI Simulation of intelligent target hitting in obstructed path using
   physical body animation and genetic algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Genetic algorithm; Physical body animation; Collision detection;
   Collision response; Intelligent target hitting
ID VEHICLE
AB Nowadays there are many real-time applications such as robotic motion, driver-less vehicle, intelligent target shooter(bullets and missiles), traffic routing in which human intervention is avoided. This paper proposes an exciting and generalized approach for intelligent target hitting in an obstructed path using physical body animation and genetic algorithm. This approach uses the concepts of the genetic algorithm to train the object for finding the right path to target and concepts of physical body animation to provide the motion and to react as per the collision with obstacles. Physical body animation provides a very natural feel of a real-time environment as we deal with all the external natural forces such as gravity, wind resistance the object and so on. Proposed approach deals not only with the static target but also deals with the dynamic target during the simulation.
C1 [Shivani, Shivendra; Tiwari, Shailendra] Trinity Coll Dublin, Dublin, Ireland.
   [Shivani, Shivendra; Tiwari, Shailendra] Thapar Inst Engn & Technol, Patiala, Punjab, India.
C3 Trinity College Dublin; Thapar Institute of Engineering & Technology
RP Shivani, S (corresponding author), Trinity Coll Dublin, Dublin, Ireland.; Shivani, S (corresponding author), Thapar Inst Engn & Technol, Patiala, Punjab, India.
EM shivanis@tcd.ie; tiwaris@tcd.ie
RI Tiwari, Shailendra/ABF-3873-2021; Shivani, Shivendra/AFN-2368-2022
OI Tiwari, Shailendra/0000-0001-7209-0437; Shivani,
   Shivendra/0000-0002-5931-6603
CR Bakdi A, 2017, ROBOT AUTON SYST, V89, P95, DOI 10.1016/j.robot.2016.12.008
   Baraff D, 1994, P ACM SIGGRAPH 94
   Benbouabdallah K, 2013, IJCSI INT J COMPUTER, V10, P1694
   Bender J, 2014, COMPUT GRAPH FORUM, V33, P246, DOI 10.1111/cgf.12272
   Chen YB, 2017, NEUROCOMPUTING, V266, P445, DOI 10.1016/j.neucom.2017.05.059
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Dingliana J, 2000, EUROGRAPHICS, V19
   Elhoseny M., 2017, J COMPUT SCI
   Frâncu M, 2017, COMPUT GRAPH-UK, V69, P12, DOI 10.1016/j.cag.2017.09.004
   [龚龚 Gong Yan], 2013, [交通运输系统工程与信息, Journal of Transporation Systems Engineering & Information Technology], V13, P94
   Greiff M, 2017, IFAC PAPERSONLINE, V50, P11670, DOI 10.1016/j.ifacol.2017.08.1677
   Huang ZP, 2015, MULTIMED TOOLS APPL, V74, P7569, DOI 10.1007/s11042-014-1992-4
   Huang ZP, 2014, MULTIMED TOOLS APPL, V71, P1283, DOI 10.1007/s11042-012-1273-z
   Jin JC, 2017, ADV ENG SOFTW, V114, P348, DOI 10.1016/j.advengsoft.2017.08.005
   Kim H, 2017, OCEAN ENG, V142, P616, DOI 10.1016/j.oceaneng.2017.07.040
   Lin CJ, 2016, COMPUT ELECTR ENG, V56, P748, DOI 10.1016/j.compeleceng.2015.05.019
   Liu Y, 2015, IJCAI 2015
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Macklin M, 2014, ACM T GRAPHIC, V33, DOI [10.1145/280/109/2601152, 10.1145/2601097.2601152]
   Man KF, 1996, IEEE T IND ELECTRON, V43, P519, DOI 10.1109/41.538609
   McCall J, 2005, J COMPUT APPL MATH, V184, P205, DOI 10.1016/j.cam.2004.07.034
   Mohammed MA, 2017, J COMPUT SCI-NETH, V21, P255, DOI 10.1016/j.jocs.2017.04.003
NR 23
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 9763
EP 9790
DI 10.1007/s11042-018-6575-3
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400012
DA 2024-07-18
ER

PT J
AU Wei, WC
   Lu, Y
   Rhoden, E
   Dey, S
AF Wei, Wenchuan
   Lu, Yao
   Rhoden, Eric
   Dey, Sujit
TI User performance evaluation and real-time guidance in cloud-based
   physical therapy monitoring and guidance system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic time warping; Gesture segmentation; Motion data alignment;
   Physical therapy; Real-time guidance
AB The effectiveness of traditional physical therapy may be limited by the sparsity of time a patient can spend with the physical therapist (PT) and the inherent difficulty of self-training given the paper/figure/video instructions provided to the patient with no way to monitor and ensure compliance with the instructions. In this paper, we propose a cloud-based physical therapy monitoring and guidance system. It is able to record the actions of the PT as he/she demonstrates a task to the patient in an offline session, and render the PT as an avatar. The patient can later train himself by following the PT avatar and getting real-time guidance on his/her device. Since the PT and user (patient) motion sequences may be misaligned due to human reaction and network delays, we propose a Gesture-Based Dynamic Time Warping algorithm that can segment the user motion sequence into gestures, and align and evaluate the gesture sub-sequences, all in real time. We develop an evaluation model to quantify user performance based on different criteria provided by the PT for a task, trained with offline subjective test data consisting of user performance and physical therapist scores. Moreover, we design three types of guidance which can be provided after each gesture based on user score, and conduct subjective tests to validate their effectiveness. Experiments with multiple subjects show that the proposed system can effectively train patients, give accurate evaluation scores, and provide real-time guidance which helps the patients learn the tasks and reach the satisfactory score with less time.
C1 [Wei, Wenchuan; Lu, Yao; Dey, Sujit] Univ Calif San Diego, Dept Elect & Comp Engn, Mobile Syst Design Lab, La Jolla, CA 92093 USA.
   [Rhoden, Eric] Univ Calif San Diego, Dept Rehabil Serv, La Jolla, CA 92093 USA.
C3 University of California System; University of California San Diego;
   University of California System; University of California San Diego
RP Wei, WC (corresponding author), Univ Calif San Diego, Dept Elect & Comp Engn, Mobile Syst Design Lab, La Jolla, CA 92093 USA.
EM wenchuan@ucsd.edu
RI Lu, Yao/R-2982-2017
FU National Science Foundation [IIS-1522125]
FX This work is funded by the National Science Foundation under grant
   number IIS-1522125.
CR Alexiadis Dimitrios S., 2011, P 19 ACM INT C MULT
   Ali Z, 2017, IEEE ACCESS, V5, P3900, DOI 10.1109/ACCESS.2017.2680467
   Ananthanarayan S, 2013, P SIGCHI C HUM FACT
   Anderson Fraser, 2013, P 26 ANN ACM S US IN
   [Anonymous], 2007, INFORM RETRIEVAL MUS
   [Anonymous], 1994, KDD WORKSHOP
   Bau O, 2008, P 21 ANN ACM S US IN
   Catarinucci L, 2015, IEEE INTERNET THINGS, V2, P515, DOI 10.1109/JIOT.2015.2417684
   Chang CY, 2012, PERVASIVE COMPUTING
   Chang YJ, 2011, RES DEV DISABIL, V32, P2566, DOI 10.1016/j.ridd.2011.07.002
   Choden P, 2017, KNOWLEDGE SMART TECH
   Dey Sujit, 2013, P 1 INT WORKSH MOB C
   Doyle J, 2010, 2010 4 INT C PERV CO
   Freeman E, 2009, BMC PUBLIC HEALTH, V9, DOI 10.1186/1471-2458-9-383
   Gwet K.L., 2008, INTRARATER RELIABILI
   Jack D, 2001, IEEE T NEUR SYS REH, V9, P308, DOI 10.1109/7333.948460
   Kahol Kanav, 2004, P 6 IEEE INT C AUT F
   Kim D, 2007, PATTERN RECOGN, V40, P3012, DOI 10.1016/j.patcog.2007.02.010
   Lange B, 2011, ENG MED BIOL SOC EMB
   Lu Y, 2015, IEEE J-STSP, V9, P517, DOI 10.1109/JSTSP.2015.2396475
   Ma SQ, 2016, INT J GEOMECH, V16, DOI 10.1061/(ASCE)GM.1943-5622.0000484
   Mirelman A, 2010, GAIT POSTURE, V31, P433, DOI 10.1016/j.gaitpost.2010.01.016
   Nkosi MT, 2010, CLOUD COMPUTING TECH
   Seber G.A, 2012, LINEAR REGRESSION AN
   Sodhi R, 2012, P SIGCHI C HUM FACT
   Tang R., 2015, P 33 ANN ACM C HUM F
   Wei W, 2015, P WIR HLTH WH 15 BET
   Yang Z, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0644-9
   Yurtman A, 2014, INFORM SCI SYSTEMS S
NR 29
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 9051
EP 9081
DI 10.1007/s11042-017-5278-5
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800064
DA 2024-07-18
ER

PT J
AU Bok, K
   Park, Y
   Yoo, J
AF Bok, Kyoungsoo
   Park, Yonghun
   Yoo, Jaesoo
TI An efficient continuous k-nearest neighbor query processing scheme for
   multimedia data sharing and transmission in location based services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Location based service; Continuous query; Moving object; Nearest
   neighbor; Grid index
ID MOVING-OBJECTS
AB The continuous k-nearest neighbor query is one of the most important query types to share multimedia data or to continuously identify transportable users in LBS. Various methods have been proposed to efficiently process the continuous k-NN query. However, most of the existing methods suffer from high computation time and larger memory requirement because they unnecessarily access cells to find the nearest cells on a grid index. Furthermore, most methods do not consider the movement of a query. In this paper, we propose a new processing scheme to process the continuous k nearest neighbor query for efficiently support multimedia data sharing and transmission in LBS. The proposed method uses the patterns of the distance relationships among the cells in a grid index. The basic idea is to normalize the distance relationships as certain patterns. Using this approach, the proposed scheme significantly improves the overall performance of the query processing. It is shown through various experiments that our proposed method outperforms the existing methods in terms of query processing time and storage overhead.
C1 [Bok, Kyoungsoo; Yoo, Jaesoo] Chungbuk Natl Univ, Sch Informat & Commun Engn, Chungdae Ro 1, Cheongju 28644, Chungbuk, South Korea.
   [Park, Yonghun] NetReCa Inc, Orange, CA USA.
C3 Chungbuk National University
RP Yoo, J (corresponding author), Chungbuk Natl Univ, Sch Informat & Commun Engn, Chungdae Ro 1, Cheongju 28644, Chungbuk, South Korea.
EM ksbok@chungbuk.ac.kr; yhpark1119@gmail.com; yjs@chungbuk.ac.kr
OI YOO, JAESOO/0000-0001-9926-9947
FU MSIT (Ministry of Science, ICT), Korea, under the ITRC (Information
   Technology Research Center) support program [IITP-2018-2013-1-00881];
   National Research Foundation of Korea (NRF) - Korea government (MSIP)
   [2016R1A2B3007527]; ICT R&D program of MSIT/IITP [B0101-15-0266]
FX This research was supported by the MSIT (Ministry of Science, ICT),
   Korea, under the ITRC (Information Technology Research Center) support
   program (IITP-2018-2013-1-00881) supervised by the IITP (Institute for
   Information & communication Technology Promotion), by the National
   Research Foundation of Korea (NRF) grant funded by the Korea government
   (MSIP) (No. 2016R1A2B3007527), and by the ICT R&D program of MSIT/IITP.
   [B0101-15-0266, Development of High Performance Visual BigData Discovery
   Platform for Large-Scale Realtime Data Analysis].
CR [Anonymous], 2006, PROC 32 ANN INT C VE
   [Anonymous], P ACM C INF KNOWL MA
   [Anonymous], P INT C MOB MULT COM
   [Anonymous], 2004, P ACM SIGMOD
   [Anonymous], P INT DAT ENG APPL S
   Bok K, 2017, CLUSTER COMPUT, V20, P1167, DOI 10.1007/s10586-017-0801-z
   Cheema MA, 2007, LECT NOTES COMPUT SC, V4443, P863
   Choi KS, 2009, P INT C UBIQ INFORM, P5, DOI 10.1109/ICUT.2009.5405699
   Gao L., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P485, DOI 10.1145/584792.584872
   Guting R. H., 2010, IEEE DATA ENG B, V33, P56
   Tran HTT, 2017, MULTIMED TOOLS APPL, V76, P2557, DOI 10.1007/s11042-016-3249-x
   Huang YK, 2013, INT CON ADV INFO NET, P854, DOI 10.1109/AINA.2013.14
   Kalashnikov DV, 2004, DISTRIB PARALLEL DAT, V15, P117, DOI 10.1023/B:DAPD.0000013068.25976.88
   Li GH, 2011, LECT NOTES COMPUT SC, V6612, P65, DOI 10.1007/978-3-642-20291-9_9
   Lin YP, 2011, MACH VISION APPL, V22, P505, DOI 10.1007/s00138-010-0264-1
   Liu C., 2013, INT J DISTRIB SENS N, P1
   Lu W, 2012, PROC VLDB ENDOW, V5, P1016, DOI 10.14778/2336664.2336674
   Mouratidis K, 2005, SIGMOD, P634, DOI DOI 10.1145/1066157.1066230
   Mouratidis K, 2007, IEEE T KNOWL DATA EN, V19, P789, DOI [10.1109/TKDE.2007.1020., 10.1109/TKDE.2007.1020]
   Nutanong S, 2008, PROC VLDB ENDOW, V1, P1095, DOI 10.14778/1453856.1453973
   Prabhakar S, 2002, IEEE T COMPUT, V51, P1124, DOI 10.1109/TC.2002.1039840
   Raghuwanshi G, 2017, MULTIMED TOOLS APPL, V76, P13741, DOI 10.1007/s11042-016-3747-x
   Soldo F, 2011, IEEE T PARALL DISTR, V22, P1085, DOI 10.1109/TPDS.2010.173
   Tongyu Zhu, 2010, Proceedings 10th International Conference on Intelligent Systems Design and Applications (ISDA 2010), P1412, DOI 10.1109/ISDA.2010.5687108
   Wang HJ, 2011, IEEE T KNOWL DATA EN, V23, P1065, DOI 10.1109/TKDE.2010.171
   Wang XY, 2005, LECT NOTES COMPUT SC, V3739, P345
   Wang YQ, 2014, INFORM SYST, V44, P1, DOI 10.1016/j.is.2014.02.003
   Wu Huafeng, 2006, Advances in Multimedia Modeling. 13th International Multimedia Modeling Conference, MMM 2007. Proceedings (Lecture Notes in Computer Science Vol.4351), P635
   Wu KL, 2005, Proceedings of MobiQuitous 2005, P261
   Wu KL, 2004, PROCEEDINGS OF MOBIQUITOUS 2004, P226
   Xiong XP, 2005, PROC INT CONF DATA, P643
   Yonghun Park, 2010, IEEE International Conference on Sensor Networks, Ubiquitous and Trustworthy Computing (SUTC 2010), P434, DOI 10.1109/SUTC.2010.64
   Yu XH, 2005, PROC INT CONF DATA, P631
   Zhang C., 2012, EDBT, P38, DOI [10.1145/2247596.2247602, DOI 10.1145/2247596.2247602]
   Zheng BH, 2001, LECT NOTES COMPUT SC, V2121, P97
NR 35
TC 5
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5403
EP 5426
DI 10.1007/s11042-018-6433-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100019
DA 2024-07-18
ER

PT J
AU Ding, ZY
   Song, L
   Zhang, XT
   Xu, Z
AF Ding, Zhengyan
   Song, Lei
   Zhang, Xiaoteng
   Xu, Zheng
TI Selective deep ensemble for instance retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Instance retrieval; Vehicle and pedestrian; Selective deep ensemble
AB In public security systems, visual instance retrieval has an explosive growing requirement, especially for large-scale image or video databases. Due to its wide range of applications in surveillance scenario, this paper aims at the retrieval tasks centered around 'vehicle and 'pedestrian' targets. Many previous CNN-based methods have not exploited the ensemble abilities of different models, which achieve limited accuracy since a certain kind of deep architecture is not comprehensive. On the other hand, some features in the original deep representation are useless for retrieval tasks, while the attention-aware compact representation will be much more efficient and effective. To address the above problems, we propose a Selective Deep Ensemble (SDE) framework to combine various models and features in a complementary way, inspired by the attention mechanism. It is demonstrated that a large improvement can be acquired with slight increase on computation cost. Finally, we evaluate the performance on three public instance-retrieval datasets, VehicleID, VeRi and Market-1501, outperforming state-of-the-art methods by a large margin.
C1 [Ding, Zhengyan; Song, Lei; Zhang, Xiaoteng; Xu, Zheng] Minist Publ Secur, Res Inst 3, Shanghai 201204, Peoples R China.
   [Song, Lei; Xu, Zheng] Shenzhen Univ, Shenzhen Key Lab Media Secur, Shenzhen, Peoples R China.
   [Song, Lei; Xu, Zheng] Guangxi Key Lab Cryptog & Informat Secur, Shenzhen, Peoples R China.
   [Song, Lei; Xu, Zheng] Shenzhen Univ, Shenzhen Key Lab Media Secur, Guilin, Peoples R China.
   [Song, Lei; Xu, Zheng] Guangxi Key Lab Cryptog & Informat Secur, Guilin, Peoples R China.
C3 Ministry of Public Security (China); Shenzhen University; Shenzhen
   University
RP Song, L (corresponding author), Minist Publ Secur, Res Inst 3, Shanghai 201204, Peoples R China.; Song, L (corresponding author), Shenzhen Univ, Shenzhen Key Lab Media Secur, Shenzhen, Peoples R China.; Song, L (corresponding author), Guangxi Key Lab Cryptog & Informat Secur, Shenzhen, Peoples R China.; Song, L (corresponding author), Shenzhen Univ, Shenzhen Key Lab Media Secur, Guilin, Peoples R China.; Song, L (corresponding author), Guangxi Key Lab Cryptog & Informat Secur, Guilin, Peoples R China.
EM dzy_wlw@163.com; songlei9312@126.com; zxt_wlw@126.com;
   xuzheng@shu.edu.cn
FU National Natural Science Foundation of China [61402116, 61403084];
   Program of Science and Technology Commission of Shanghai Municipality
   [15530701300, 15XD1520200, 17511106803]; IoT Program of Ministry of
   Industry and Information Technology of China; Key Project of the
   Ministry of Public Security [2014JSYJA007]; Project of the Key
   Laboratory of Embedded Systemand ServiceComputing, Ministry of
   Education, Tongji University [ESSCKF 201503]; Shanghai Rising-Star
   Program [17QB1401000]; Special Fund for Basic RAMP;D Expenses of Central
   Level Public Welfare Scientific Research Institutions [C17384]; National
   Key RAMP;D program of China [2016YFC0801304, 2017YFC0803705];
   CCF-Venustech Open Research Fund [CCF-VenustechRP2017006]; Guangxi Key
   Laboratory of Cryptography and Information Security [GCIS201719]
FX The authors of this paper are members of Shanghai Engineering Research
   Center of Intelligent Video Surveillance. Dr. Lei Song is also a
   visiting researcher with Shenzhen Key Laboratory of Media Security,
   Shenzhen University, Shenzhen 518060, China. Our research was sponsored
   by following projects: the National Natural Science Foundation of China
   (61402116. 61403084); Program of Science and Technology Commission of
   Shanghai Municipality (No. 15530701300, No. 15XD1520200, No.
   17511106803); 2012 IoT Program of Ministry of Industry and Information
   Technology of China; Key Project of the Ministry of Public Security (No.
   2014JSYJA007); the Project of the Key Laboratory of Embedded Systemand
   ServiceComputing, Ministry of Education, Tongji University (ESSCKF
   201503); Shanghai Rising-Star Program(17QB1401000); the Special Fund for
   Basic R&D Expenses of Central Level Public Welfare Scientific Research
   Institutions (C17384); National Key R&D program of China
   (2016YFC0801304, 2017YFC0803705), supported by CCF-Venustech Open
   Research Fund (Grant No. CCF-VenustechRP2017006), and supported by
   Guangxi Key Laboratory of Cryptography and Information Security (No.
   GCIS201719).
CR [Anonymous], 2016, PROC INT C LEARN REP
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2016, ARXIV
   [Anonymous], ARXIV170700809
   [Anonymous], 2017, ARXIV170803918
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], ADV NEUR INFORM PROC
   [Anonymous], ARXIV170300196
   [Anonymous], 2017, ARXIV170802386
   [Anonymous], 2017, P IEEE INT C COMP VI
   [Anonymous], 2016, Residual Networks Behave Like Ensembles of Relatively Shallow Networks
   [Anonymous], 2016, ARXIV161203144
   [Anonymous], 2016, CORR
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hu J., 2017, CoRR
   Joe Yue-Hei Ng, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P53, DOI 10.1109/CVPRW.2015.7301272
   Kalantidis Yannis, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P685, DOI 10.1007/978-3-319-46604-0_48
   Liu HY, 2016, PROC CVPR IEEE, P2167, DOI 10.1109/CVPR.2016.238
   Liu XC, 2016, LECT NOTES COMPUT SC, V9906, P869, DOI 10.1007/978-3-319-46475-6_53
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Radenovic F, 2016, LECT NOTES COMPUT SC, V9905, P3, DOI 10.1007/978-3-319-46448-0_1
   Razavian A. S., 2016, ITE Trans. Media Technol. Appl., V4, P251, DOI [DOI 10.3169/MTA.4.251, 10.3169/mta.4.251]
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Sermanet P., 2 INT C LEARN REPR
   Simonyan K., 2015, P 3 INT C LEARN REPR
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Yandex Artem Babenko, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1269, DOI 10.1109/ICCV.2015.150
   Zhang YH, 2017, IEEE INT CON MULTI, P1386, DOI 10.1109/ICME.2017.8019491
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
NR 33
TC 3
Z9 4
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5751
EP 5767
DI 10.1007/s11042-018-5967-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100037
DA 2024-07-18
ER

PT J
AU He, ZP
   Jung, COO
   Fu, QT
   Zhang, ZD
AF He, Zhangping
   Jung, Cheolkon
   Fu, Qingtao
   Zhang, Zhendong
TI Deep feature embedding learning for person re-identification based on
   lifted structured loss
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Deep learning; Triplet loss; Lifted structured
   loss; Convolutional neural networks
AB Person re-identification (re-id) aims at matching the same individual in videos captured by multiple cameras, and much progress has been made in recent years due to large scale pedestrian data sets and deep learning-based techniques. In this paper, we propose deep feature embedding learning for person re-id based on lifted structured loss. Triplet loss is commonly used in deep neural networks for person re-id. However, the triplet loss-based framework is not able to make full use of the batch information, and thus needs to choose hard negative samples manually that is time-consuming. To address this problem, we adopt lifted structured loss for deep neural networks that makes the network learn better feature embedding by minimizing intra-class variation and maximizing inter-class variation. Extensive experiments on Market-1501, CUHK03, CUHK01 and VIPeR data sets demonstrate the superior performance of the proposed method over state-of-the-arts in terms of the cumulative match curve (CMC) metric.
C1 [He, Zhangping; Jung, Cheolkon; Fu, Qingtao; Zhang, Zhendong] Xidian Univ, Sch Elect Engn, 2 South Taibai Rd, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Jung, COO (corresponding author), Xidian Univ, Sch Elect Engn, 2 South Taibai Rd, Xian 710071, Shaanxi, Peoples R China.
EM zhengzk@xidian.edu.cn
OI Zhang, Zhendong/0000-0001-5872-5176
FU National Natural Science Foundation of China [61271298]; International
   S, T Cooperation Program of China [2014DFG12780]
FX An earlier version of this paper was presented in the 2018 IEEE
   Conference on Acoustics, Speech, and Signal Processing (ICASSP),
   Calgary, Alberta, Canada, April 15-20, 2018 [13]. This work was
   supported by the National Natural Science Foundation of China (No.
   61271298) and the International S, T Cooperation Program of China (No.
   2014DFG12780).
CR [Anonymous], 2014, P IEEE C COMP VIS PA
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], ARXIV161105244ZZ
   [Anonymous], 2016, ARXIV
   [Anonymous], 2017, ARXIV170503332
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], PROC CVPR IEEE
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2017, TIP, DOI DOI 10.1109/TIP.2017.2700762
   [Anonymous], PROC IEEE INTERNATIO
   [Anonymous], 2007, P IEEE INT WORKSH PE
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2016, CORR
   Barbosa IB, 2018, COMPUT VIS IMAGE UND, V167, P50, DOI 10.1016/j.cviu.2017.12.002
   Chen DP, 2016, PROC CVPR IEEE, P1268, DOI 10.1109/CVPR.2016.142
   Chen SZ, 2016, IEEE T IMAGE PROCESS, V25, P2353, DOI 10.1109/TIP.2016.2545929
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Guo CC, 2014, INT C PATT RECOG, P3540, DOI 10.1109/ICPR.2014.609
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ZP, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1957, DOI 10.1109/ICASSP.2018.8462118
   Karen S, 2014, P ICLR
   Khamis S, 2015, LECT NOTES COMPUT SC, V8927, P134, DOI 10.1007/978-3-319-16199-0_10
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Leibe B., 2017, ARXIV170307737CS
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu X, 2012, PATTERN RECOGN, V45, P4204, DOI 10.1016/j.patcog.2012.05.019
   Nanda AJ, 2017, IEEE ACCESS, V5, P6471, DOI 10.1109/ACCESS.2017.2686438
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Shi HL, 2016, LECT NOTES COMPUT SC, V9905, P732, DOI 10.1007/978-3-319-46448-0_44
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Subramaniam A, 2016, ADV NEUR IN, V29
   Varior Rahul Rama, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhang Y, 2016, PROC CVPR IEEE, P1278, DOI 10.1109/CVPR.2016.143
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
NR 47
TC 9
Z9 10
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5863
EP 5880
DI 10.1007/s11042-018-6408-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100042
DA 2024-07-18
ER

PT J
AU Muniyappan, S
   Rajendran, P
AF Muniyappan, S.
   Rajendran, P.
TI Contrast Enhancement of Medical Images through Adaptive Genetic
   Algorithm (AGA) over Genetic Algorithm (GA) and Particle Swarm
   Optimization (PSO)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive Genetic Algorithm (AGA); Particle Swarm Optimization (PSO);
   Genetic Algorithm (GA); Image Enhancement(IE); Medical Image(MI);
   Mutation; Peak Signal-To-Noise Ratio (PSNR); Second Derivative based
   Measure of Enhancement (SDME); Mean Squared Error (MSE); Structural
   Similarity Index (SSIM); Mean Structural Similarity Index (MSSIM);
   Average Difference (AD); Maximum Difference (MD); Normalized Absolute
   Error (NAE); Structural Content (SC); Histogram equalization(HE);
   Wireless Capsule Endoscopy(WCE)
AB Assessment of images after processing is a significant step for determining how good the images are being analyzed. Quality of image is usually estimated with the help of image quality metrics. Unfortunately, most of the commonly used metrics cannot sufficiently portray the visual aspect of the enhanced image. In this proposed system, an approach for medical image enhancement is presented. Here adaptive genetic algorithm is proposed for medical image contrast enhancement. Initially, the chromosomes having gene value of the image gray levels have been generated. After that the fitness function will be calculated for each generated chromosome based on the image edge and their overall intensity values. The selected best chromosomes which have the high fitness value will be given to crossover and mutation operation. In GA the adaptive property is introduced by including adaptive crossover and mutation operations. The proposed method is compared with two different types of optimization algorithms such as Genetic algorithm (GA) and Particle swarm optimization (PSO) that ensure accuracy and quality of medical images in proposed adaptive genetic algorithm (AGA). The experimental solutions are got with the help of metrics like PSNR, SDME, MSE, SSIM, MSSIM, AD, MD, NAE, PSO and SC which proves the proposed algorithm, produces better results as compared to the existing algorithms.
C1 [Muniyappan, S.] Anna Univ, Sarder Patel Rd,Old Highways Bldg, Chennai 600025, Tamil Nadu, India.
   [Rajendran, P.] Knowledge Inst Technol, Dept Comp Sci & Engn, KIOT Campus, Salem, Tamil Nadu, India.
C3 Anna University; Anna University Chennai
RP Muniyappan, S (corresponding author), Anna Univ, Sarder Patel Rd,Old Highways Bldg, Chennai 600025, Tamil Nadu, India.
EM muniyappan.phd@gmail.com
RI Rajendran, P.Selvi/CAE-9476-2022
CR Al-Ameen Z., 2012, INT J BIOSCIENCE BIO, V4, P63
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], 2016, P 25 INT JOINT C ART
   Chaira T, 2012, APPL SOFT COMPUT, V12, P1259, DOI 10.1016/j.asoc.2011.12.011
   Chang DC, 1998, IEEE T MED IMAGING, V17, P518, DOI 10.1109/42.730397
   Cheung WK, ATTENUATION CORRECTI
   Gatos B, 2006, PATTERN RECOGN, V39, P317, DOI 10.1016/j.patcog.2005.09.010
   Gouhar GK, 2011, EGYPT J RADIOL NUC M, V42, P451, DOI 10.1016/j.ejrnm.2011.08.003
   Goyaland S, 2011, J GLOB RES COMPUT SC, V2, P93
   Huang KQ, 2006, COMPUT VIS IMAGE UND, V103, P52, DOI 10.1016/j.cviu.2006.02.007
   Huang KQ, 2005, IMAGE VISION COMPUT, V23, P51, DOI 10.1016/j.imavis.2004.07.005
   Huang KQ, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P721
   Jagatheeswari P, 2009, P INT C MAN MACH SYS, P1
   KHELLAF A, 1991, IEEE T MED IMAGING, V10, P589, DOI 10.1109/42.108593
   Kwok NM, 2006, P IEEE INT C AUT SCI, P7
   LAN X, 2015, TIP, V24, P5826, DOI DOI 10.1109/TIP.2015.2481325
   Lan XY, 2017, AAAI CONF ARTIF INTE, P4118
   Lan XY, 2014, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2014.156
   Li BP, 2012, J VIS COMMUN IMAGE R, V23, P222, DOI 10.1016/j.jvcir.2011.10.002
   Li S, 2015, PROCEEDINGS OF 2015 IEEE INTERNATIONAL CONFERENCE ON GREY SYSTEMS AND INTELLIGENT SERVICES (GSIS), P521, DOI 10.1109/GSIS.2015.7301912
   Medukonduru P, 2015, P INT C IND INSTR CO, P28
   Meylan L, 2006, IEEE T IMAGE PROCESS, V15, P2820, DOI 10.1109/TIP.2006.877312
   Panetta KA, 2008, IEEE T SYST MAN CY B, V38, P174, DOI 10.1109/TSMCB.2007.909440
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Shyu MS, 1998, PATTERN RECOGN, V31, P871, DOI 10.1016/S0031-3203(97)00073-3
   Starck JL, 2003, IEEE T IMAGE PROCESS, V12, P706, DOI 10.1109/TIP.2003.813140
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Sundaram M, 2011, APPL SOFT COMPUT, V11, P5809, DOI 10.1016/j.asoc.2011.05.003
   Yu ZY, 2004, IEEE IMAGE PROC, P1001
NR 29
TC 18
Z9 18
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 6487
EP 6511
DI 10.1007/s11042-018-6355-0
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700004
DA 2024-07-18
ER

PT J
AU Vijayan, M
   Ramasundaram, M
AF Vijayan, Midhula
   Ramasundaram, Mohan
TI A fast DGPSO-motion saliency map based moving object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Center surround difference; Dimensionality based grouping particle swarm
   optimization; Foreground segmentation; Local difference pattern; Motion
   saliency map
ID BACKGROUND SUBTRACTION; TRACKING; SURVEILLANCE; ALGORITHM; PATTERNS;
   SYSTEM; MODEL
AB The rapid development in the field of computer vision has encouraged researchers to develop vision systems for moving object detection in embedded surveillance applications. The model requires a fast processing algorithm with minimum complexity, which also consumes less memory for computation. This paper proposes a fast moving object detection algorithm to aid foreground segmentation in embedded applications. Dimensionality based Grouping Particle Swarm Optimization-Motion Saliency Map, a variant of the PSO framework combined with saliency map technique is proposed to achieve tighter object detection. The presented technique utilizes the concept of saliency map followed by shadow removal, partial occlusion detection, and Local Difference Pattern based removed object detection. Dimensionality based Grouping Particle Swarm Optimization-Saliency Map of the background model and Dimensionality based Grouping Particle Swarm Optimization-Saliency Map of the incoming frame are used to construct Motion Saliency Map. The proposed model produces a tighter object region compared to the existing naive saliency map based methods. An enhanced texture feature extraction strategy, named as Local Difference Pattern is proposed for removed object detection. This presented moving object detection method is simple and efficient. It consumes less memory for computation. Hence, the algorithm is suitable for embedded surveillance applications. The experimental results show the effectiveness of the proposed method in terms of average processing time in addition to qualitative, and quantitative analyses.
C1 [Vijayan, Midhula; Ramasundaram, Mohan] NIT, Dept Comp Sci & Engn, Tiruchirappalli 620015, Tamil Nadu, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Vijayan, M (corresponding author), NIT, Dept Comp Sci & Engn, Tiruchirappalli 620015, Tamil Nadu, India.
EM midhula91@gmail.com; rmohan@nitt.edu
RI R, Mohan/V-6077-2019
OI Vijayan, Midhula/0000-0002-2578-6463
CR [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   [Anonymous], 2004, Proceedings of the Pan-Sydney area workshop on Visual information processing
   Balcilar M, 2016, SIGNAL IMAGE VIDEO P, V10, P85, DOI 10.1007/s11760-014-0705-9
   Braham M, 2016, INT CONF SYST SIGNAL, P113
   Chen ZZ, 2014, COMPUT VIS IMAGE UND, V122, P35, DOI 10.1016/j.cviu.2014.01.004
   Choudhury SK, 2016, IEEE ACCESS, V4, P6133, DOI 10.1109/ACCESS.2016.2608847
   Dou JF, 2017, SIGNAL IMAGE VIDEO P, V11, P407, DOI 10.1007/s11760-016-0975-5
   Eberhart RC, 2001, IEEE C EVOL COMPUTAT, P81, DOI 10.1109/CEC.2001.934374
   El Maadi A, 2015, IETE J RES, V61, P308, DOI 10.1080/03772063.2015.1017614
   GAO Z, 1987, TPAMI, V36, P1975, DOI DOI 10.1109/TPAMI.2014.2314663
   Gemignani G, 2016, IEEE T IMAGE PROCESS, V25, P5239, DOI 10.1109/TIP.2016.2605004
   Han XH, 2013, INT CONF BIOMED, P846, DOI 10.1109/BMEI.2013.6747059
   Heikkila Marko., 2004, BMVC, P1
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jodoin JP, 2014, IEEE WINT CONF APPL, P885, DOI 10.1109/WACV.2014.6836010
   Lee BY, 2014, IOP C SER EARTH ENV, V18, DOI 10.1088/1755-1315/18/1/012020
   Lee G, 2015, IEEE SIGNAL PROC LET, V22, P1619, DOI 10.1109/LSP.2015.2417592
   Li CL, 2018, MULTIMED TOOLS APPL, V77, P13557, DOI 10.1007/s11042-017-4975-4
   Lin HH, 2011, IEEE T IMAGE PROCESS, V20, P822, DOI 10.1109/TIP.2010.2075938
   Ma Y.-F., 2002, P INT C IM PROC, pI
   Maddalena L, 2009, LECT NOTES COMPUT SC, V5807, P422
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   Pan Z, 2017, MULTIMED TOOLS APPL, V76, P16989, DOI 10.1007/s11042-016-3647-0
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   Ramírez-Alonso G, 2016, NEUROCOMPUTING, V175, P990, DOI 10.1016/j.neucom.2015.04.118
   Sajid H, 2017, IEEE T IMAGE PROCESS, V26, P3249, DOI 10.1109/TIP.2017.2695882
   Seidel F, 2014, MACH VISION APPL, V25, P1227, DOI 10.1007/s00138-013-0555-4
   Seo JW, 2016, SIGNAL IMAGE VIDEO P, V10, P29, DOI 10.1007/s11760-014-0697-5
   Sheikh Y, 2005, IEEE T PATTERN ANAL, V27, P1778, DOI 10.1109/TPAMI.2005.213
   St-Charles PL, 2016, IEEE T IMAGE PROCESS, V25, P4768, DOI 10.1109/TIP.2016.2598691
   St-Charles PL, 2015, IEEE WINT CONF APPL, P990, DOI 10.1109/WACV.2015.137
   St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Subudhi BN, 2012, INT CONF INTELL SYST, P95, DOI 10.1109/ISDA.2012.6416519
   Sun YP, 2015, IEEE T IMAGE PROCESS, V24, P2515, DOI 10.1109/TIP.2015.2419075
   Tong YB, 2011, COGN COMPUT, V3, P241, DOI 10.1007/s12559-010-9094-8
   Wang Y., 2014, P IEEE C COMP VIS PA, P387, DOI 10.1109/ICIP40778.2020.9190887
   Woo JW, 2010, INT J CONTROL AUTOM, V8, P948, DOI 10.1007/s12555-010-0503-2
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Yuan Q, 2015, IEEE T AUTOMAT CONTR, V60, P1760, DOI 10.1109/TAC.2014.2381454
   Zeng Z, 2017, IEEE T FUZZY SYST, V25, P584, DOI 10.1109/TFUZZ.2016.2566811
   Zhao ZJ, 2015, IEEE T IMAGE PROCESS, V24, P2841, DOI 10.1109/TIP.2015.2427519
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
NR 43
TC 5
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7055
EP 7075
DI 10.1007/s11042-018-6459-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700029
DA 2024-07-18
ER

PT J
AU Wang, XY
   Qin, XM
   Liu, CM
AF Wang, Xingyuan
   Qin, Xiaomeng
   Liu, Chuanming
TI Color image encryption algorithm based on customized globally coupled
   map lattices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Chaos; Customized globally coupled map lattices; High
   level security
ID CHAOS; PERMUTATION
AB In this paper, we proposed a color image encryption scheme based on chaos and Customized Globally Coupled Map Lattices, which is firstly brought out by our research group. The presented algorithm consists of four steps. Firstly, decompose RGB image to three channels red, green and blue. A simple but useful logistic map is used to generate a key image that has the same size with the original image. Secondly, regard the red channel, green channel, blue channel and the key image as a whole image, then shuffle this image. After that, segment shuffled image to four same size images, named A, B, C and D. Finally, conduct the confusion operations and then choose one image as key image from these four parts. Combine the rest three parts, cipher image is obtained. Experimental results and data analysis demonstrate that the proposed algorithm has the strong capacity of resisting typical attacks and the good security.
C1 [Wang, Xingyuan] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
   [Wang, Xingyuan; Qin, Xiaomeng; Liu, Chuanming] Dalian Univ Technol, Fac Elect Informat & Elect Engn, Dalian 116024, Peoples R China.
C3 Dalian Maritime University; Dalian University of Technology
RP Wang, XY (corresponding author), Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.; Wang, XY (corresponding author), Dalian Univ Technol, Fac Elect Informat & Elect Engn, Dalian 116024, Peoples R China.
EM wangxy@dlut.edu.cn; qinxiaomeng502@163.com
RI Wang, Xing-yuan/I-6353-2015
FU National Natural Science Foundation of China [61672124, 61370145];
   Password Theory Project of the 13th Five-Year Plan National Cryptography
   Development Fund [MMJJ20170203]
FX This research is supported by the National Natural Science Foundation of
   China (Nos: 61672124 and 61370145), the Password Theory Project of the
   13th Five-Year Plan National Cryptography Development Fund (No:
   MMJJ20170203).
CR Bakhshandeh A, 2013, OPT LASER ENG, V51, P665, DOI 10.1016/j.optlaseng.2013.01.001
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   El Assad S, 2016, SIGNAL PROCESS-IMAGE, V41, P144, DOI 10.1016/j.image.2015.10.004
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Fouda JSAE, 2014, COMMUN NONLINEAR SCI, V19, P578, DOI 10.1016/j.cnsns.2013.07.016
   George RT, 2014, 2014 FIRST INTERNATIONAL CONFERENCE ON COMPUTATIONAL SYSTEMS AND COMMUNICATIONS (ICCSC), P203, DOI 10.1109/COMPSC.2014.7032648
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Hussain I, 2014, NONLINEAR DYNAM, V76, P1355, DOI 10.1007/s11071-013-1214-z
   Jain A, 2015, MULTIMED TOOLS APPL, V74, P1, DOI DOI 10.1007/s11042-013-1647-x
   Kadir A, 2014, OPTIK, V125, P1671, DOI 10.1016/j.ijleo.2013.09.040
   Kumar M, 2016, SIGNAL PROCESS, V125, P187, DOI 10.1016/j.sigpro.2016.01.017
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Norouzi B, 2014, MULTIMEDIA SYST, V20, P45, DOI 10.1007/s00530-013-0314-4
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Seyedzadeh SM, 2015, NONLINEAR DYNAM, V81, P511, DOI 10.1007/s11071-015-2008-2
   Wang XY, 2015, ENTROPY-SWITZ, V17, P3877, DOI 10.3390/e17063877
   Wang XY, 2016, NONLINEAR DYNAM, V84, P1595, DOI 10.1007/s11071-015-2590-3
   Wang XY, 2015, OPT COMMUN, V342, P51, DOI 10.1016/j.optcom.2014.12.043
   Wang XY, 2015, NONLINEAR DYNAM, V79, P1141, DOI 10.1007/s11071-014-1729-y
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zhang YQ, 2014, PHYSICA A, V402, P104, DOI 10.1016/j.physa.2014.01.051
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
NR 30
TC 37
Z9 37
U1 2
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 6191
EP 6209
DI 10.1007/s11042-018-6326-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100056
DA 2024-07-18
ER

PT J
AU Zhang, YN
   Liu, S
AF Zhang, Yanning
   Liu, Shuai
TI A real-time distributed cluster storage optimization for massive data in
   internet of multimedia things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of multimedia things; Massive data; Real time; Distributed
   optimization; Cluster storage
AB With the rapid growth of massive data in the Internet of Multimedia Things, there are some problems of insufficient storage space and unbalanced load in the current methods. For the problem of massive real-time data storage, a distributed cluster storage optimization method is proposed. Considering the impact of replica cost and the generation of intermediate data on the replica layout, a replica generation and storage strategy is given with consideration of cost and storage space. In the data center, the data sensitivity and data access frequency is used as migration factors to achieve massive data migration. The improved collaborative evolution method is used to code the task scheduling particle swarm in massive data storage to obtain the optimal solution, and achieve massive real-time data distributed cluster storage for the Internet of things. The experimental results showed that the cost of data management by this method was only between 10 and 15, which showed that this method can effectively improve data access speed, reduce storage space, lower cost and better load balancing.
C1 [Zhang, Yanning] Beijing Polytech, Telecommun Engn Inst, Beijing, Peoples R China.
   [Liu, Shuai] Inner Mongolia Univ, Coll Comp Sci, Hohhot, Peoples R China.
   [Liu, Shuai] Inner Mongolia Key Lab Social Comp & Data Proc, Hohhot 010012, Peoples R China.
   [Liu, Shuai] Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Jilin, Peoples R China.
C3 Beijing Polytechnic; Inner Mongolia University
RP Liu, S (corresponding author), Inner Mongolia Univ, Coll Comp Sci, Hohhot, Peoples R China.; Liu, S (corresponding author), Inner Mongolia Key Lab Social Comp & Data Proc, Hohhot 010012, Peoples R China.; Liu, S (corresponding author), Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Jilin, Peoples R China.
EM cs.liu.shuai@gmail.com
RI Liu, Shuai/AAX-1239-2021; Liu, Shuai/AAB-1960-2019; Liu,
   Shuai/P-3939-2017
OI Liu, Shuai/0000-0001-9909-0664; Liu, Shuai/0000-0001-9909-0664
FU Programs of National Natural Science Foundation of China [61502254];
   Program for Yong Talents of Science and Technology in Universities of
   Inner Mongolia Autonomous Region [NJYT-18-B10]; Open Funds of Key
   Laboratory of Symbolic Computation and Knowledge Engineering of Ministry
   of Education [93K172018K07, CJGX2016-KYYZK003]
FX This work is supported by Programs of National Natural Science
   Foundation of China (No: 61502254), Program for Yong Talents of Science
   and Technology in Universities of Inner Mongolia Autonomous Region
   (Grant No. NJYT-18-B10), Open Funds of Key Laboratory of Symbolic
   Computation and Knowledge Engineering of Ministry of Education (Grant
   No. 93K172018K07. Research on mass real time data storage system of
   Internet of things (No. CJGX2016-KYYZK003).
CR Chao YU, 2016, INFORM TECHNOLOGY IN, V12, P82
   Chen B, 2015, MACH LEARN, V100, P677, DOI 10.1007/s10994-015-5524-x
   Cherubini G, 2016, COMPUTER, V49, P43, DOI 10.1109/MC.2016.117
   El-Rabiaey MA, 2016, J LIGHTWAVE TECHNOL, V34, P3726, DOI 10.1109/JLT.2016.2582838
   Guo Hui-yun, 2017, Computer Engineering and Science, V39, P641, DOI 10.3969/j.issn.1007-130X.2017.04.005
   Hu CH, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/601528
   Ishii T, 2015, JPN J APPL PHYS, V54, DOI 10.7567/JJAP.54.09MA04
   Kaneko K, 2015, PERFORM EVALUATION, V87, P37, DOI 10.1016/j.peva.2015.01.004
   Kang LL, 2018, THE DIGITAL WORLD, P135
   [李又玲 Li Youling], 2017, [计算机工程, Computer Engineering], V43, P13
   Lin Zhigui, 2016, Computer Engineering, V42, P32, DOI 10.3969/j.issn.1000-3428.2016.12.007
   Liu S, 2013, INT J DISTRIB SENS N, DOI 10.1155/2013/281707
   [马蕾 Ma Lei], 2016, [计算机仿真, Computer Simulation], V33, P465
   Pan Z, 2017, MULTIMED TOOLS APPL, V76, P16989, DOI 10.1007/s11042-016-3647-0
   Wijetunge CD, 2015, BIOINFORMATICS, V31, P3198, DOI 10.1093/bioinformatics/btv356
   Xu Z, 2015, GEOPHYS J INT, V202, P381, DOI 10.1093/gji/ggv146
   Yang CT, 2016, COMPUTING, V98, P93, DOI 10.1007/s00607-014-0399-4
   Yang G, 2014, INT J DISTRIBUTED SE
   Zhang Y, 2015, PROTEOMICS, V15, P1419, DOI 10.1002/pmic.201400428
   Zhao D, 2016, APPL PHYS LETT, V108, DOI 10.1063/1.4953199
NR 20
TC 6
Z9 7
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5479
EP 5492
DI 10.1007/s11042-018-7006-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100023
DA 2024-07-18
ER

PT J
AU Deng, LB
   Li, DM
AF Deng, Lianbing
   Li, Daming
TI RETRACTED: Multimedia data stream information mining algorithm based on
   jointed neural network and soft clustering (Retracted article. See SEP,
   2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Multimedia; Data Stream; Information Mining; Neural Network; Soft
   Clustering; GPU; Systematic Design
AB As one non-surveillance study method, soft clustering is well applied in the data mining, the imagery processing, the pattern recognition, the spatial remote sensing technology and the characteristic extraction and so on state-of-the-art applications in many domains all have the widespread application. Inspired by the combination of neural network and soft computing model, in this paper, we propose the novel multimedia data stream information mining model based on jointed neural network and soft clustering. In the self-training process, we train a learner on a tagged sample set and then use the learner to mark an unlabeled sample that it considers to be highly reliable and add the newly labeled sample to the original training set, then use this new training set to re-train the learner and repeat the above process until the iteration condition is terminated. To better play to the performance of the main processor and then save address space resources with the wishbone protocol implementation the separation of the high-low speed hierarchical interconnection structure GPU is applied. Experimental result proves the effectiveness of the proposed model.
C1 [Deng, Lianbing] Zhuhai Da Hengqin Sci & Technol Dev Co Ltd, Zhuhai, Peoples R China.
   [Li, Daming] Zhuhai Da Hengqin Sci & Technol Dev Co Ltd, Postdoctoral Programme, Zhuhai, Peoples R China.
   [Li, Daming] City Univ Macau, Xian Xing Hai, Macau, Peoples R China.
C3 City University of Macau
RP Li, DM (corresponding author), Zhuhai Da Hengqin Sci & Technol Dev Co Ltd, Postdoctoral Programme, Zhuhai, Peoples R China.; Li, DM (corresponding author), City Univ Macau, Xian Xing Hai, Macau, Peoples R China.
EM lidaming@yahoo.com
RI zhang, meng/JMB-0951-2023; zhang, min/IYI-9869-2023
CR Agarwal S, 2017, MULTIMED TOOLS APPL, V76, P1073, DOI 10.1007/s11042-015-3103-6
   Ahmad W, 2014, PAC RIM C MULT
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], HESITANT FUZZY CLUST
   [Anonymous], 2014, SENS TRANSDUCERS
   Avila S, 2013, COMPUT VIS IMAGE UND, V117, P453, DOI 10.1016/j.cviu.2012.09.007
   Baughman AK, 2015, MULTIMEDIA DATA MINI, P3
   Bi C, 2014, CLOUD COMP INT SYST
   Boutaba R, 2014, CLUSTER COMPUT, V17, P723, DOI 10.1007/s10586-014-0349-0
   Bouyer A, 2015, INT J COMMUN NETW DI, V14, P400, DOI 10.1504/IJCNDS.2015.069675
   Chen JH, 2015, IEEE T NEUR NET LEAR, V26, P2291, DOI 10.1109/TNNLS.2014.2377477
   Chu C-T, 2016, NEXT GEN EL ISNE 201
   Ciolini A, 2015, MULT EXP WORKSH ICME
   Dil EA, 2016, J IND ENG CHEM, V34, P186, DOI 10.1016/j.jiec.2015.11.010
   Fan Y, 2013, ISPDI 2013 5 INT S P
   Fan Y-N, 2014, SYST INF ICSAI 2014
   Feng X, 2016, 54 ANN M ASS COMP LI
   Huang BT, 2017, MULTIMED TOOLS APPL, V76, P20099, DOI 10.1007/s11042-017-4396-4
   Law T, 2017, INT J COMPUT VISION, V121, P111
   Li T, 2014, IEEE T MULTIMEDIA, V16, P1185, DOI 10.1109/TMM.2014.2325693
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Melin P, 2014, APPL SOFT COMPUT, V21, P568, DOI 10.1016/j.asoc.2014.04.017
   Meng FR, 2017, MULTIMED TOOLS APPL, V76, P895, DOI 10.1007/s11042-015-3083-6
   Menon N, 2015, COMM SIGN PROC ICCSP
   Model ARIMA Based Time Series Forecasting, 2016, RECENT ADV ELECTR EL, V9, P104
   Mu M, 2015, IEEE MULTIMEDIA
   Papadopoulos S, 2014, COMPUTER, V47, P84, DOI 10.1109/MC.2014.135
   Nguyen QH, 2017, MULTIMED TOOLS APPL, V76, P2645, DOI 10.1007/s11042-015-3204-2
   Roy SD, 2015, SOCIAL MULTIMEDIA SI, P19
   Sakai Y, 2015, NETW BAS INF SYST NB
   Shi WY, 2016, CIRC SYST C DCAS 201
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Sridhar S, 2017, MULTIMED TOOLS APPL, V76, P815, DOI 10.1007/s11042-015-3066-7
   Tian YH, 2016, IEEE MULTIMEDIA, V23, P12
   Velmurugan T, 2014, APPL SOFT COMPUT, V19, P134, DOI 10.1016/j.asoc.2014.02.011
   Wang H, 2014, TOOLS ART INT ICTAI
   Wang H, 2013, ADV COMP INT ICACI 2
   Wang JR, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/248680
   Wang JX, 2017, MULTIMED TOOLS APPL, V76, P2495, DOI 10.1007/s11042-015-3223-z
   Wang N, 2013, P ADV NEURAL INFORM
   Wang T, 2016, IEEE T NEUR NET LEAR, V27, P416, DOI 10.1109/TNNLS.2015.2411671
   Wu TY, 2017, PROC SPIE, V10225, DOI 10.1117/12.2266095
   Zhang S, 2017, ARXIV170204854
   Zhou KL, 2014, SCI CHINA INFORM SCI, V57, DOI 10.1007/s11432-014-5146-0
   Zweig S, 2016, ARXIV161109803
NR 45
TC 6
Z9 6
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4021
EP 4044
DI 10.1007/s11042-017-4964-7
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200009
DA 2024-07-18
ER

PT J
AU Lan, HX
   Zhuang, TH
   Meng, ZY
   Zu, X
AF Lan, Hongxing
   Zhuang, Tianhui
   Meng, Zhiyi
   Zu, Xu
TI RETRACTED: Chinese regional economic cooperative development model based
   on network analysis and multimedia data visualization (Retracted
   article. See SEP, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Network analysis; Multimedia; Data visualization; Algorithm analysis;
   Regional economy; Collaborative development; Mode; Data preprocessing
ID PERFORMANCE
AB Since the reform and opening up, China's economic development has been accelerating. In the current world economic system, China occupies a very important position. However, there is a phenomenon of uneven economic growth among different regions, namely, there are large differences in economic growth rates and economic development levels between different provinces and cities. In recent years, a large number of studies have shown that China's regional economic growth has obvious spatial correlation. In this paper, we adopt the method of network analysis to study and explain the spatial correlation of regional economic growth. Multimedia mining is a combination of data mining technology and multimedia technology. It is a cross-disciplinary field of knowledge discovery, data mining, artificial intelligence, machine learning, database technology, and multimedia technology. Therefore, data visualization technology can be used to study the coordinated development model of regional economy. Multimedia data visualization is an evolving concept whose boundaries are constantly expanding, mainly referring to technologically advanced technical methods that allow the use of graphics, image processing, computer vision, and user interfaces. Visualize data by expressing, modeling, and displaying stereo, surface, attributes, and animations. Compared with special technical methods such as stereo modeling, the technical methods covered by data visualization are much broader. The simulation results prove that the propose model can obtain the better overall perforamcne.
C1 [Lan, Hongxing; Zhuang, Tianhui; Meng, Zhiyi; Zu, Xu] Sichuan Agr Univ, Sch Business, Yaan, Peoples R China.
C3 Sichuan Agricultural University
RP Lan, HX (corresponding author), Sichuan Agr Univ, Sch Business, Yaan, Peoples R China.
EM lanhongxing65@163.com
CR Ahmad J, 2018, FUTURE GENER COMP SY, V81, P314, DOI 10.1016/j.future.2017.11.002
   Allen TT, 2017, DECIS ANAL, V14, P250, DOI 10.1287/deca.2017.0360
   [Anonymous], CLUST COMPUT
   [Anonymous], THESIS
   Bermejo C, 2017, IEEE INT CON DIS, P169, DOI 10.1109/ICDCSW.2017.62
   Cornia Marcella, 2017, 2017 IEEE International Conference on Multimedia and Expo: Workshops (ICMEW), P309, DOI 10.1109/ICMEW.2017.8026277
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Hu Y, 2017, FUEL CELLS, V17, P3, DOI 10.1002/fuce.201600172
   Kamilaris A, 2018, PROGR IS, P39, DOI 10.1007/978-3-319-65687-8_4
   Kaur J, 2017, CMC-COMPUT MATER CON, V53, P23
   Legrady G, 2017, LEONARDO, V50, P200, DOI 10.1162/LEON_a_01228
   Li T, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3017678
   Liem CCS, 2017, IEEE MULTIMEDIA, V24, P20, DOI 10.1109/MMUL.2017.20
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Papoutsoglou G, 2017, NUCLEIC ACIDS RES, V45, pW270, DOI 10.1093/nar/gkx448
   Parker NN, 2017, TRACMTR17008
   Rahman H.U., 2018, Handbook of Research on Big Data Storage and Visualization Techniques, P228
   Ritter D, 2017, IEEE INT ENTERP DIST, P103, DOI 10.1109/EDOC.2017.23
   Schoning J, 2017, P 12 INT JOINT C COM
   Song Y, 2017, MULTIMED TOOLS APPL, V76, P10083, DOI 10.1007/s11042-016-3599-4
   Tang ZJ, 2018, CMC-COMPUT MATER CON, V55, P331, DOI 10.3970/cmc.2018.02222
   Wang YM, 2019, CLUSTER COMPUT, V22, P1189, DOI 10.1007/s10586-017-1199-3
   WU C, 2018, MATERIALS, V54, P269, DOI DOI 10.3970/CMC.2018.054.269
   Yamamoto R, 2017, COMP INT SSCI 2017 I, P1
   Yin CY, 2017, NEUROCOMPUTING, V256, P49, DOI 10.1016/j.neucom.2016.07.079
NR 27
TC 4
Z9 4
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4743
EP 4765
DI 10.1007/s11042-018-6870-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200042
DA 2024-07-18
ER

PT J
AU Wang, T
   Qin, RX
   Chen, Y
   Snoussi, H
   Choi, C
AF Wang, Tian
   Qin, Ruoxi
   Chen, Yang
   Snoussi, Hichem
   Choi, Chang
TI A reinforcement learning approach for UAV target searching and tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Trajectory planning; Cooperative object searching and tracking;
   Reinforcement learning
AB Owing to the advantages of Unmanned Aerial Vehicle (UAV), such as the extendibility, maneuverability and stability, multiple UAVs are having more and more applications in security surveillance. The object searching and trajectory planning become the important issues of uninterrupted patrol. We propose an online distributed algorithm for tracking and searching, while considering the energy refueling at the same time. The quantum probability model which describes the partially observable target positions is proposed. Moreover, the upper confidence tree algorithm is derived to resolve the best route, with the assistance of teammate learning model which handles the nonstationary problems in distributed reinforcement learning. Experiments and the analysis of the different situations show that the proposed scheme performs favorably.
C1 [Wang, Tian; Qin, Ruoxi; Chen, Yang] Beihang Univ, Sch Automat Sci & Elect Engn, Beijing, Peoples R China.
   [Snoussi, Hichem] Univ Technol Troyes, Inst Charles Delaunay, LM2S, UMR STMR 6279 CNRS, Troyes, France.
   [Choi, Chang] Chosun Univ, Comp Engn, Gwangju, South Korea.
C3 Beihang University; Universite de Technologie de Troyes; Chosun
   University
RP Choi, C (corresponding author), Chosun Univ, Comp Engn, Gwangju, South Korea.
EM wangtian@buaa.edu.cn; ruoxiqin@yahoo.com; chenyangwiz@buaa.edu.cn;
   hichem.snoussi@utt.fr; enduranceaura@gmail.com
RI Choi, Chang/U-7208-2019; Wang, Tianyi/A-1441-2016
OI Choi, Chang/0000-0002-2276-2378; 
FU National Natural Science Foundation of China [61503017, U1435220];
   Aeronautical Science Foundation of China [2016ZC51022]; SURECAP CPER
   project; Platform CAPSEC - Region Champagne-Ardenne; FEDER, the
   Fundamental Research Funds for the Central Universities
   [YWF-14-RSC-102]; National Research Foundation of Korea (NRF) - Ministry
   of Science, ICT and Future Planning [2015R1C1A1A02037515]
FX This work is partially supported by the National Natural Science
   Foundation of China (61503017, U1435220), the Aeronautical Science
   Foundation of China (2016ZC51022), the SURECAP CPER project and the
   Platform CAPSEC funded by Region Champagne-Ardenne and FEDER, the
   Fundamental Research Funds for the Central Universities
   (YWF-14-RSC-102). Also, this research was supported by Basic Science
   Research Program through the National Research Foundation of Korea (NRF)
   funded by the Ministry of Science, ICT and Future Planning
   (2015R1C1A1A02037515).
CR Alexis K, 2016, AUTON ROBOT, V40, P631, DOI 10.1007/s10514-015-9485-5
   [Anonymous], 2017, IEEE Trans. Ind. Informat.
   Artieda J, 2009, J INTELL ROBOT SYST, V55, P299, DOI 10.1007/s10846-008-9304-8
   Bo-bo Meng, 2010, Proceedings of the 2010 International Conference on Intelligent Computation Technology and Automation (ICICTA 2010), P1106, DOI 10.1109/ICICTA.2010.235
   Chen C.-C., 2017, FUTURE GENERATION CO
   Chen C, 2017, COMPUT COMMUN, V111, P176, DOI 10.1016/j.comcom.2017.08.010
   Chen HD, 2013, IEEE T AERO ELEC SYS, V49, P840, DOI 10.1109/TAES.2013.6494384
   Choi C, 2013, NEUROCOMPUTING, V122, P24, DOI 10.1016/j.neucom.2012.12.058
   Claus C, 1970, 15 NAT 10 C ART INT, P746
   Gosavi A, 2009, INFORMS J COMPUT, V21, P178, DOI 10.1287/ijoc.1080.0305
   Greenstein G., 1998, AM J PHYS, V66, P455, DOI DOI 10.1119/1.18888
   Hausamann D, 2005, AIRCR ENG AEROSP TEC, V77, P352, DOI 10.1108/00022660510617077
   Huang H, 2017, NAT SCI REP, V7, P1, DOI DOI 10.1038/srep45555
   Iwashita Y., 2013, BMVC, V1, P6
   Lin S, 2017, AUTON ROBOT, V41, P881, DOI 10.1007/s10514-016-9564-2
   Liu BY, 2014, IEEE T AUTON MENT DE, V6, P286, DOI 10.1109/TAMD.2014.2362682
   Ma LL, 2013, P AMER CONTR CONF, P5386
   Medhane DV, 2017, IEEE T SUSTAINABLE C
   Murphy RR, 2011, J INTELL ROBOT SYST, V64, P77, DOI 10.1007/s10846-010-9514-8
   Oreifej O, 2010, PROC CVPR IEEE, P709, DOI 10.1109/CVPR.2010.5540147
   Prokaj J, 2014, PROC CVPR IEEE, P1186, DOI 10.1109/CVPR.2014.155
   Quintero S. A. P., 2015, AM CONTR C
   Ragi S, 2013, IEEE T AERO ELEC SYS, V49, P2397, DOI 10.1109/TAES.2013.6621824
   Robin C, 2016, AUTON ROBOT, V40, P729, DOI 10.1007/s10514-015-9491-7
   Sang Y., 2015, GUID NAV CONTR C
   Shu TM, 2015, PROC CVPR IEEE, P4576, DOI 10.1109/CVPR.2015.7299088
   Silver D., 2010, ADV NEURAL INFORM PR, P2164, DOI DOI 10.5555/2997046.2997137
   Su X, 2016, EURASIP J WIREL COMM, DOI 10.1186/s13638-016-0732-z
   Su XF, 2016, EVID-BASED COMPL ALT, V2016, DOI 10.1155/2016/7279361
   Walha A, 2015, MULTIMED TOOLS APPL, V74, P6745, DOI 10.1007/s11042-014-1928-z
   Yang YY, 2017, ADV MATER SCI ENG, V2017, DOI 10.1155/2017/2939057
   Yeh MC, 2016, MULTIMED TOOLS APPL, V75, P16117, DOI 10.1007/s11042-015-2921-x
   Yu HL, 2015, IEEE-ASME T MECH, V20, P541, DOI 10.1109/TMECH.2014.2301459
   Zhu SQ, 2013, J INTELL ROBOT SYST, V69, P417, DOI 10.1007/s10846-012-9737-y
NR 34
TC 57
Z9 62
U1 7
U2 80
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4347
EP 4364
DI 10.1007/s11042-018-5739-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200023
DA 2024-07-18
ER

PT J
AU Gourrame, K
   Douzi, H
   Harba, R
   Riad, R
   Ros, F
   Amar, M
   Elhajji, M
AF Gourrame, Khadija
   Douzi, Hassan
   Harba, Rachid
   Riad, Rabia
   Ros, Frederic
   Amar, Meina
   Elhajji, Mohamed
TI A zero-bit Fourier image watermarking for print-cam process
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Print-cam; Perspective deformation; Fourier domain;
   Smartphones
ID RESISTANT
AB Smartphone watermarking has many potential applications but also many challenging issues such as being able to withstand print-cam attacks. These include perspective deformations that can strongly deform the freehandedly digitized image. In this paper, we present the design of an image watermarking for print-cam process in the context of an industrial security application for identity images. The method uses watermarking based on the Fourier transform and a specific correction pre-process. These corrections combine frame-based perspective rectification of the freehandedly captured images, a Wiener filter to decrease image blurring and adjustments to reduce color degradations. Results show that the Fourier watermarking method gives better results than state of the art of existing watermarking methods often chosen to cope with print-cam attacks. Fourier watermarking provides a total error rate of 1%, which is compatible with the targeted industrial application. The error of the other methods is at best 25%. Finally, no noticeable difference was found between the two smartphones tested (iPhone 6 and Samsung S5), in terms of error rate, for the proposed method.
C1 [Gourrame, Khadija; Douzi, Hassan; Riad, Rabia; Amar, Meina; Elhajji, Mohamed] Ibn Zohr Univ, IRF SIC Lab, BP 8106, Agadir 80000, Morocco.
   [Gourrame, Khadija; Harba, Rachid; Riad, Rabia; Ros, Frederic; Amar, Meina] Orleans Univ, PRISME Lab, 12 Rue Blois, F-45067 Orleans, France.
C3 Ibn Zohr University of Agadir
RP Gourrame, K (corresponding author), Ibn Zohr Univ, IRF SIC Lab, BP 8106, Agadir 80000, Morocco.; Gourrame, K (corresponding author), Orleans Univ, PRISME Lab, 12 Rue Blois, F-45067 Orleans, France.
EM khadija.gourrame@edu.uiz.ac.ma
RI ROS, Frédéric/V-2884-2019; GOURRAME, Khadija/KPA-5735-2024; Riad,
   R./AAB-4051-2020; El HAJJI, Mohamed/AHE-4167-2022
OI ROS, Frédéric/0000-0001-9954-8399; Riad, R./0000-0001-8626-213X; El
   HAJJI, Mohamed/0000-0002-0327-8249
FU project PPR2-CNRST: Prototype Development for authentication systems
   based on face biometrics
FX This work was supported by project PPR2-CNRST: Prototype Development for
   authentication systems based on face biometrics.
CR Al-Otum H, 2018, MULTIMED TOOLS APPL, V77, P15625, DOI 10.1007/s11042-017-5138-3
   [Anonymous], INFORM HIDING
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Cheung V, 2004, COLOR TECHNOL, V120, P19
   Cox IJ., 2007, DIGITAL WATERMARKING
   Delgado-Guillen LA, 2013, MIDWEST SYMP CIRCUIT, P1363, DOI 10.1109/MWSCAS.2013.6674909
   Gourrame K, 2016, LECT NOTES COMPUT SC, V9680, P356, DOI 10.1007/978-3-319-33618-3_36
   Grossberg MD, 2004, IEEE T PATTERN ANAL, V26, P1272, DOI 10.1109/TPAMI.2004.88
   Hancock P., 2008, Psychological image collection at stirling (PICS)
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Horiuchi T, 2009, P APSIPA ASC 2009 AS, P765
   Katayama A., 2004, P 3 INT C MOB UB MUL, P109
   Keskinarkaus A, 2006, LECT NOTES COMPUT SC, V4283, P82
   Kim W, 2006, LECT NOTES COMPUT SC, V4261, P106
   Le NT, 2017, OPT COMMUN, V390, P144, DOI 10.1016/j.optcom.2016.12.073
   Lin CY, 2001, IEEE T IMAGE PROCESS, V10, P767, DOI 10.1109/83.918569
   Liu JC, 2011, OPT ENG, V50, DOI 10.1117/1.3529430
   Mateos J, 2016, IEEE IMAGE PROC, P2678, DOI 10.1109/ICIP.2016.7532845
   Nakamura T., 2004, P 3 INT C MOB UB MUL, P101
   Nguyen PB, 2009, LECT NOTES COMPUT SC, V5879, P561, DOI 10.1007/978-3-642-10467-1_50
   Ouyang JL, 2015, COMPUT ELECTR ENG, V46, P419, DOI 10.1016/j.compeleceng.2015.03.004
   Pereira S, 2000, IEEE T IMAGE PROCESS, V9, P1123, DOI 10.1109/83.846253
   Poljicak A, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3609010
   Pramila Anu, 2008, Proceedings of the Fifth IASTED International Conference on Signal Processing, Pattern Recognition, and Applications, P60
   Pramila A, 2007, P FINN SIGN PROC S O
   Pramila A, 2017, MULTIMED TOOLS APPL, V76, P16063, DOI 10.1007/s11042-016-3895-z
   Pramila A, 2012, SIGNAL IMAGE VIDEO P, V6, P211, DOI 10.1007/s11760-011-0211-2
   Riad R, 2016, ADV ELECTR COMPUT EN, V16, P23, DOI 10.4316/AECE.2016.04004
   Riadi R, 2014, 2014 SECOND WORLD CONFERENCE ON COMPLEX SYSTEMS (WCCS), P705, DOI 10.1109/ICoCS.2014.7060967
   Takeshita S., 2017, INT C SOFTW ENG ART, P201
   Takeuchi S, 2005, IEEE ICCE, P411, DOI 10.1109/ICCE.2005.1429892
   Thongkor K., 2012, P 2012 9 INT C EL EN, V1618, P1
   Thongkor K, 2014, 2014 14TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES (ISCIT), P479, DOI 10.1109/ISCIT.2014.7011959
   Wu D, 2009, SIGNAL PROCESS, V89, P2415, DOI 10.1016/j.sigpro.2009.05.016
   Yan Q, 2001, IEEE T INFORM THEORY, V47, P1368, DOI 10.1109/18.923720
   Yeung MM, 1998, J ELECTRON IMAGING, V7, P578, DOI 10.1117/1.482612
NR 36
TC 15
Z9 16
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 2621
EP 2638
DI 10.1007/s11042-018-6302-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700060
DA 2024-07-18
ER

PT J
AU Minewaki, S
   Iwahashi, M
   Kobayashi, H
   Yoshida, T
   Kiya, H
AF Minewaki, Sayaka
   Iwahashi, Masahiro
   Kobayashi, Hiroyuki
   Yoshida, Taichi
   Kiya, Hitoshi
TI Near lossless coding of sparse histogram images based on zero-skip
   quantization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data compression; Image coding; Quantization; Jpeg
ID EMBEDDED COMPRESSION ALGORITHM; LOW-COMPLEXITY; REDUCTION; SYSTEM
AB This paper introduces a zero-skip quantization (ZS.Q) scheme for the near lossless coding of sparse histogram images. Increases in the range of pixel values and various tone mapping operations on those pixel values mean that the histogram bins often contain no pixels. Recently, this sparseness of the histogram was used to increase the lossless coding performance by introducing histogram packing. This approach was extended to lossy coding by combining spatial quantization and lossless coding. However, such methods do not satisfy the near lossless (NL) condition. In contrast, conventional NL coding such as the JPEG-LS standard satisfies the NL condition, but does not use the histogram sparseness. In this paper, a simple ZS.Q procedure is introduced that uses the histogram sparseness to increase coding efficiency under the NL condition. The proposed method has the following advantages: 1) It guarantees the maximum quantization error is less than some threshold; 2) It can be combined with an arbitrary lossless encoder, such as lossless JPEG 2000 or lossless JPEG-LS; 3) Coding errors do not accumulate under repeat encoding and decoding.
C1 [Minewaki, Sayaka] Yuge Coll, Natl Inst Technol, Yuge 1000, Ochi, Ehime 7942593, Japan.
   [Iwahashi, Masahiro; Yoshida, Taichi] Nagaoka Univ Technol, Kamitomioka 1603-1, Nagaoka, Niigata 9402188, Japan.
   [Kobayashi, Hiroyuki] Tokyo Metropolitan Coll Ind Technol, Shinagawa Ku, Higashi Ooi 1-10-40, Tokyo 1400011, Japan.
   [Kiya, Hitoshi] Tokyo Metropolitan Univ, Asahigaoka 6-6, Hino, Tokyo 1910065, Japan.
C3 Nagaoka University of Technology; Tokyo Metropolitan University
RP Minewaki, S (corresponding author), Yuge Coll, Natl Inst Technol, Yuge 1000, Ochi, Ehime 7942593, Japan.
EM minewaki@vos.nagaokaut.ac.jp; iwahshi@vos.nagaokaut.ac.jp;
   hkob@s.metro-cit.ac.jp; yoshida@vos.nagaokaut.ac.jp; kiya@sd.tmu.ac.jp
FU Japan Society for the Promotion of Science [23560445]; Grants-in-Aid for
   Scientific Research [23560445, 16K18104] Funding Source: KAKEN
FX This work was supported in part by a Japan Society for the Promotion of
   Science Grant-in-Aid KAKENHI Grant Number 23560445.
CR Adams MD, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P53, DOI 10.1109/ICIP.2000.899223
   [Anonymous], 2004, 16000 6 INDOOR AIR P, P1
   [Anonymous], 1999, 1449511999 ISOIEC
   [Anonymous], 2012, P 2012 AS PAC SIGN I
   [Anonymous], 2006, ELCVIA ELECT LETT CO
   Asif MT, 2015, IEEE T INTELL TRANSP, V16, P1817, DOI 10.1109/TITS.2014.2374335
   Bazhyna A, 2008, IEEE T CONSUM ELECTR, V54, P1492, DOI 10.1109/TCE.2008.4711192
   Beerten J, 2015, IEEE GEOSCI REMOTE S, V12, P1775, DOI 10.1109/LGRS.2015.2425548
   Britanak V., 2006, Discrete Cosine and Sine Transforms: General Properties, Fast Algorithms and Integer Approximations
   Chen YJ, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P844, DOI 10.1109/ICIP.2000.899842
   Ching-Yen Chien, 2009, 2009 IEEE 13th International Symposium on Consumer Electronics (ISCE), P144, DOI 10.1109/ISCE.2009.5157025
   Chou CH, 2008, IET IMAGE PROCESS, V2, P304, DOI 10.1049/iet-ipr:20080034
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Chuah S, 2013, IEEE T IMAGE PROCESS, V22, P5271, DOI 10.1109/TIP.2013.2286324
   Ferreira PJSG, 2002, IEEE SIGNAL PROC LET, V9, P259, DOI 10.1109/LSP.2002.803018
   Fujiyoshi M, 2015, ASIAPAC SIGN INFO PR, P1280, DOI 10.1109/APSIPA.2015.7415481
   Grecos C, 2001, IEEE T CONSUM ELECTR, V47, P466, DOI 10.1109/30.964135
   Heidrich Wolfgang, ERIK REINHARD
   Iwahashi M, 2004, IEEE IMAGE PROC, P2507
   Iwahashi M., 2005, P IEEE INT C IM PROC, P269
   Iwahashi M., 2013, 2013 AS PAC SIGN INF, P1
   Iwahashi M, 2011, P IEEE VIS COMM IM P, P1
   Iwahashi M, 2013, IEEE IMAGE PROC, P1651, DOI 10.1109/ICIP.2013.6738340
   Iwahashi M, 2013, INT CONF ACOUST SPEE, P1340, DOI 10.1109/ICASSP.2013.6637869
   Iwahashi M, 2012, INT CONF ACOUST SPEE, P1361, DOI 10.1109/ICASSP.2012.6288143
   Iwahashi M, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P205, DOI 10.1109/PCS.2012.6213328
   Iwahashi M, 2012, IEEE T SIGNAL PROCES, V60, P2648, DOI 10.1109/TSP.2012.2187289
   Jeong HW, 2012, EAI OPINION REV SERI, V2012, P1, DOI DOI 10.1109/ISCE.2012.6241723
   Ke LG, 1998, IEEE T IMAGE PROCESS, V7, P225, DOI 10.1109/83.660999
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P813, DOI 10.1109/83.923277
   Nasr-Esfahani E, 2008, INT CONF ACOUST SPEE, P1197, DOI 10.1109/ICASSP.2008.4517830
   Penna B, 2006, IEEE GEOSCI REMOTE S, V3, P125, DOI 10.1109/LGRS.2005.859942
   Pinho AJ, 2002, IEEE SIGNAL PROC LET, V9, P5, DOI 10.1109/97.988715
   Poomrittigul S, 2013, APSIPA T SIGNAL INF, V2, P1, DOI [10.1017/ATSIP.2013.3, DOI 10.1017/ATSIP.2013.3]
   Qian SE, 2006, IEEE T AERO ELEC SYS, V42, P851, DOI 10.1109/TAES.2006.248183
   Santa-Cruz D, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P49, DOI 10.1109/ICIP.2000.899222
   Son CH, 2010, IEEE T CONSUM ELECTR, V56, P2421, DOI 10.1109/TCE.2010.5681123
   Sun XL, 2013, SCI REP-UK, V3, DOI 10.1038/srep01069
   Taquet J, 2012, IEEE T IMAGE PROCESS, V21, P2641, DOI 10.1109/TIP.2012.2186147
   van der Schaar M, 2000, IEEE T CONSUM ELECTR, V46, P923, DOI 10.1109/30.920442
   Ward G, 2005, P COL IM C AR NOV, P1
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Wu XL, 2000, IEEE T IMAGE PROCESS, V9, P536, DOI 10.1109/83.841931
   Wu XL, 1996, INT CONF ACOUST SPEE, P1890, DOI 10.1109/ICASSP.1996.544819
   Xiong ZX, 2003, IEEE T MED IMAGING, V22, P459, DOI 10.1109/TMI.2003.809585
   Xu RF, 2005, IEEE COMPUT GRAPH, V25, P57, DOI 10.1109/MCG.2005.133
   Yng TLB, 2008, IEEE T CONSUM ELECTR, V54, P1453, DOI 10.1109/TCE.2008.4637640
NR 47
TC 8
Z9 8
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 27
EP 45
DI 10.1007/s11042-017-5082-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500003
DA 2024-07-18
ER

PT J
AU Pradhan, J
   Pal, AK
   Banka, H
AF Pradhan, Jitesh
   Pal, Arup Kumar
   Banka, Haider
TI Principal texture direction based block level image reordering and use
   of color edge features for application of object based image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color edge map; Content-based image retrieval (CBIR); Object cropping;
   Principal texture direction; Saliency map
ID ROTATION; CLASSIFICATION; HISTOGRAMS; EXTRACTION; TRANSFORM; MODEL
AB In this paper, the authors have presented a novel content-based image retrieval (CBIR) scheme based on the combination of color, shape, and texture visual image features. Initially, the combined features of color and shape are derived from the object region of an image using the proposed color edge map approach. This approach is suitable to extract both the color and shape based features simultaneously from image object region. We have preserved more information associated with the object region and some significant information from the background region for enabling better retrieval efficiency. In the subsequent stage, we have extracted texture features from the preprocessed image. This preprocessed image is obtained after decomposition of an image into non-overlapping blocks followed by reordering all blocks based on their principal texture direction. The notion supports the variation present on image data can be controlled by rearranging each block as per their principal direction and some texture based parameters derived from the preprocessed image. The final feature vector consists of color, shape, and texture-related features in their correct proportions. Proposed CBIR scheme is extensively tested using four coral image databases (i.e. 1,000 color images from 10 different classes, 10,000 color images from 20 different classes, 7,200 images from 100 different classes and 17,125 images from 20 different classes). Experimental results show that the proposed CBIR scheme has better retrieval efficiency in terms of precision and recall than other related schemes.
C1 [Pradhan, Jitesh; Pal, Arup Kumar; Banka, Haider] Indian Inst Technol ISM, Dept Comp Sci & Engn, Dhanbad, Bihar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Pradhan, J (corresponding author), Indian Inst Technol ISM, Dept Comp Sci & Engn, Dhanbad, Bihar, India.
EM jitpradhan02@gmail.com; arupkrpal@gmail.com; haider.banka@gmail.com
RI Pal, Arup Kumar/I-2496-2016
OI Pradhan, Jitesh/0000-0002-6264-4093
CR Burger W, 2009, PRINCIPALS DIGITAL I
   Campisi P, 2004, IEEE T IMAGE PROCESS, V13, P782, DOI 10.1109/TIP.2003.822607
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chan YK, 2004, J SYST SOFTWARE, V71, P65, DOI 10.1016/S0164-1212(02)00140-1
   Das Gupta R, 2013, PATTERN RECOGN, V46, P3256, DOI 10.1016/j.patcog.2013.05.026
   Dimitrovski I, 2016, INFORM SCIENCES, V329, P851, DOI 10.1016/j.ins.2015.05.012
   Do MN, 2002, IEEE T MULTIMEDIA, V4, P517, DOI 10.1109/TMM.2002.802019
   dos Santos JM, 2017, MULTIMED TOOLS APPL, V76, P16855, DOI 10.1007/s11042-016-3955-4
   ElAlami ME, 2014, APPL SOFT COMPUT, V14, P407, DOI 10.1016/j.asoc.2013.10.003
   ElAlami ME, 2011, KNOWL-BASED SYST, V24, P23, DOI 10.1016/j.knosys.2010.06.001
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   GUDIVADA VN, 1995, ACM T INFORM SYST, V13, P115, DOI 10.1145/201040.201041
   Guo JM, 2015, IEEE T IMAGE PROCESS, V24, P1010, DOI 10.1109/TIP.2014.2372619
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Huang PW, 2003, PATTERN RECOGN, V36, P665, DOI 10.1016/S0031-3203(02)00083-3
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jafari-Khouzani K, 2005, IEEE T PATTERN ANAL, V27, P1004, DOI 10.1109/TPAMI.2005.126
   Ko B, 2005, IEEE T MULTIMEDIA, V7, P105, DOI 10.1109/TMM.2004.840603
   Kokare M, 2005, IEEE T SYST MAN CY B, V35, P1168, DOI 10.1109/TSMCB.2005.850176
   Kurtz C, 2014, MED IMAGE ANAL, V18, P1082, DOI 10.1016/j.media.2014.06.009
   Liapis S, 2004, IEEE T MULTIMEDIA, V6, P676, DOI 10.1109/TMM.2004.834858
   Lin CH, 2009, IMAGE VISION COMPUT, V27, P658, DOI 10.1016/j.imavis.2008.07.004
   Liu GH, 2008, PATTERN RECOGN, V41, P3521, DOI 10.1016/j.patcog.2008.06.010
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   Luo JB, 2006, IEEE T IMAGE PROCESS, V15, P1443, DOI 10.1109/TIP.2006.871081
   Mahani MAN, 2012, IRAN J FUZZY SYST, V9, P69
   Manjunath B.S., 2002, INTRO MPEG 7
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Mehtre BM, 1997, INFORM PROCESS MANAG, V33, P319, DOI 10.1016/S0306-4573(96)00069-6
   Mezaris V, 2004, EURASIP J APPL SIG P, V2004, P886, DOI 10.1155/S1110865704401188
   Milanese R, 1999, J VIS COMMUN IMAGE R, V10, P186, DOI 10.1006/jvci.1999.0411
   Min R, 2009, PATTERN RECOGN, V42, P147, DOI 10.1016/j.patcog.2008.07.001
   Moghaddam HA, 2005, PATTERN RECOGN, V38, P2506, DOI 10.1016/j.patcog.2005.05.010
   Nene SA, 1996, TECHNICAL REPORT CUC, V6, P6
   Nezamabadi-Pour H, 2004, PATTERN RECOGN LETT, V25, P1547, DOI 10.1016/j.patrec.2004.05.019
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Palm C, 2004, PATTERN RECOGN, V37, P965, DOI 10.1016/j.patcog.2003.09.010
   Pass G, 1999, MULTIMEDIA SYST, V7, P234, DOI 10.1007/s005300050125
   Raghuwanshi G, 2016, DIGIT SIGNAL PROCESS, V48, P50, DOI 10.1016/j.dsp.2015.09.003
   Rajapakse J, 2002, NEUROCOMPUTING, V49, P439
   Rao M.B., 2011, INT J COMPUT APPL, V18, P40, DOI [10.5120/2285-2961, DOI 10.5120/2285-2961]
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Shahbahrami A., 2008, P 19 ANN WORKSH CIRC
   Shrivastava N, 2014, INFORM SCIENCES, V259, P212, DOI 10.1016/j.ins.2013.08.043
   Subrahmanyam M, 2013, COMPUT ELECTR ENG, V39, P762, DOI 10.1016/j.compeleceng.2012.11.023
   Sun JD, 2006, PATTERN RECOGN LETT, V27, P1122, DOI 10.1016/j.patrec.2005.12.014
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769
   Varish N, 2015, INT C SIGN PROC COMM, P1, DOI DOI 10.1109/ICSCN.2015.7219922
   Varish N, 2017, MULTIMED TOOLS APPL, V76, P15885, DOI 10.1007/s11042-016-3882-4
   Wang LZ, 1998, IEEE T IMAGE PROCESS, V7, P196, DOI 10.1109/83.660996
   Wang M, 2013, IEEE T GEOSCI REMOTE, V51, P2874, DOI 10.1109/TGRS.2012.2217397
   Xiang Sean Zhou, 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P570, DOI 10.1109/ICIP.1999.822959
   Yihong Gong, 1994, Proceedings of the International Conference on Multimedia Computing and Systems (Cat. No.94TH0631-2), P121, DOI 10.1109/MMCS.1994.292444
   Youssef SM, 2012, COMPUT ELECTR ENG, V38, P1358, DOI 10.1016/j.compeleceng.2012.05.010
   Zeng S, 2016, NEUROCOMPUTING, V171, P673, DOI 10.1016/j.neucom.2015.07.008
   Zhang RM, 2015, IEEE T IMAGE PROCESS, V24, P4766, DOI 10.1109/TIP.2015.2467315
NR 60
TC 14
Z9 14
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1685
EP 1717
DI 10.1007/s11042-018-6246-4
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700021
DA 2024-07-18
ER

EF